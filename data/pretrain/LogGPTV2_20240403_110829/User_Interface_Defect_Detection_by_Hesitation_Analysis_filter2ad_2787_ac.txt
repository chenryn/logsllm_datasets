tasks using the interface to which they were randomly as-
signed. Data from one of those tasks, called the Jack task,
was used for this study. Of the seven tasks, the Jack task
was chosen because it caused users the most difﬁculty.
Users were presented with task statements in a Web
browser. They were able to consult the task statement at
any time during their performance of a task. The task state-
ment given to users for the Jack task was:
The group ProjectE is working on projectE-
data.txt, so everyone in ProjectE can read, write,
or delete it. Jack (username: jack) has just been
reassigned to another project and must not be al-
lowed to change the ﬁle’s contents, but should be
allowed to read it. Make sure that effective now,
Jack can read the ﬁle projectEdata.txt, but in no
way change its contents.
Characteristics of the ﬁle-permissions task domain that
may affect the results of the hesitation detector include:
(cid:127) Goal-oriented. Users had a clear goal to accomplish,
so this task was unlike, for example, browsing the Web
or watching a video. Goal-oriented tasks require users
to keep making progress; hesitations do not further
task completion.
(cid:127) Very little typing. At most, participants typed a few
one-word usernames, so most hesitations detected in
this study were hesitations in mouse usage.
(cid:127) Short time-to-completion. Users took 169 seconds
on average to complete the Jack task. The short task
time allowed users to stay focused on the task, thus
removing the potential for false alarms due to taking
breaks, daydreaming, and the like.
(cid:127) Limited text to read. Textual labels on the interfaces
were limited to a few words (three or less), so the po-
tential for false alarms due to users’ reading long pas-
sages of text was minimal.
Many common tasks, such as system conﬁguration, vot-
ing, and image manipulation, share these characteristics, so
the results obtained by this study would be expected to gen-
eralize to a large class of interfaces and tasks.
4.2 Hesitation detection
A hesitation detector was implemented according to the
algorithm sketched in section 2.1. The sensitivity parame-
ter, which represents the minimum number of standard de-
viations a hesitation must be from the average pause length,
was varied over a range of sensitivities from 0.5 to 24.0 in
steps of 0.5. Mouse and keyboard logs for each user were
provided as input to the detector.
4.3 Ground-truth determination
Ground truth was determined by a usability expert, who
examined the video and audio logs collected from each of
the 23 users during the user study. The criteria listed in
section 2.2 (user statements, silence and inactivity, toggling,
Help access, and questions to the experimenter) were used
to identify periods of user difﬁculty. For each period of user
difﬁculty, the onset and offset times were noted.
The expert’s rating of ground-truth user difﬁculty was
validated by two auxiliary raters’ judgments of difﬁculty in
6 of the 23 data streams. This validation step was necessary
because, although the criteria were designed to be as objec-
tive as possible, some subjectivity remains (most notably in
the judgment of what user statements indicate confusion).
The two auxiliary raters did not rate all 23 data streams
because of the large time investment involved in doing so.
However, the six data streams they did rate were balanced
in their total length and in the interface used. Two were of
short duration (less than 100 seconds), two were of medium
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:11:35 UTC from IEEE Xplore.  Restrictions apply. 
False alarms
Hits
Hesitations
Ground truth
0
25
50
75 100 125 150 175 200 225 250 275 300 325 350 375
Elapsed time (s)
Figure 1: Timelines showing ground truth, hesitations, hits, and false alarms for one 364-second user session. The dark black
regions indicate where these respective events occurred over the course of the 364 seconds.
duration (between 100 and 150 seconds), and two were of
long duration (greater than 150 seconds). For each of these
pairs of data streams, one was from an XP user and one
was from a Salmon user. Within these constraints, the six
data streams for validation were chosen at random. Three
timelines, one from each rater, were laid out for each of the
six validation data streams. The timelines were divided into
discrete, one-second-long blocks, and a binary value was
assigned to each block: 1 if the rater determined that the
user was having difﬁculty during that block, and 0 if not.
The auxiliary raters’ judgments of difﬁculty were then com-
pared, block-by-block, for agreement with the expert’s rat-
ings of difﬁculty. Within the six data streams, all three raters
agreed for 68.9% of the data streams, while the expert had
80.0% agreement with the ﬁrst auxiliary rater and 79.4%
agreement with the second. For two raters, 70% agreement
is generally considered acceptable, so the expert’s judgment
was deemed valid for determining ground truth.
4.4 Accuracy computation
Accuracy was measured in terms of hit rate and false-
alarm rate. Recall the deﬁnitions of hit rate and false-alarm
rate from section 2.3. The hit rate is deﬁned as the per-
centage of all periods of user difﬁculty during which the
hesitation detector ﬁnds any genuine hesitation. Note that,
by this deﬁnition, the hesitation need not cover the entire
duration of the difﬁculty period to be considered a hit; it is
assumed that as long as some portion of the difﬁculty period
is detected, a human analyst will ﬁnd the full extent of the
difﬁculty during the diagnosis stage. Note also that multi-
ple hesitations may occur during the same period of difﬁ-
culty; in this case, only one hit is counted. Hit rate, then,
is simply the number of hits divided by the total number
of distinct periods of difﬁculty identiﬁed by the expert. To
measure false-alarm rate, two timelines were laid out – one
representing the hesitation detector’s output, and one rep-
resenting ground truth. These timelines were divided into
discrete, one-second-long blocks. Each block on the detec-
tor’s timeline was assigned a binary value: 1, if the detec-
tor classiﬁed the block as part of a hesitation; 0, otherwise.
Each block on the rater’s timeline was also assigned a bi-
nary value: 1, if the rater designated the block as part of a
period of user difﬁculty; 0, if not. A false alarm occurred
whenever a block in the detector’s timeline had a value of
1 but the corresponding block in the rater’s timeline was
0. False-alarm rate was computed as the number of false
alarms divided by the total number of blocks in the rater’s
timeline with a value of 0.
Figure 1 shows timelines for ground truth, hesitations
(as output by the detector with sensitivity set to 2.0), hits,
and false alarms for one 364-second user session. The ﬁg-
ure shows ﬁve distinct periods of user difﬁculty consuming
145 seconds, indicated by dark black regions on the ground-
truth timeline. Dark black regions on the hesitations time-
line indicate regions the detector classiﬁed as hesitations.
At least one hesitation coincided with each of four of the
ﬁve periods of difﬁculty. These four periods of difﬁculty are
marked as dark black regions on the hits timeline. For this
user, the detector’s hit rate is 4/5 = 80%. Twenty-nine one-
second blocks were classiﬁed as hesitations by the detec-
tor, but designated as periods of non-difﬁculty in the ground
truth, are marked as dark black regions on the false-alarms
timeline. Since this user experienced 219 seconds of non-
difﬁculty, the false alarm rate for this user is 29/219 = 13%.
5 Results
In the 23 data streams, there were 3389 total seconds of
user data. According to the ground truth, users had difﬁ-
culty during 999 of these 3389 seconds, or 29.5% of the
time. There were 66 distinct periods of user difﬁculty, and
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:11:35 UTC from IEEE Xplore.  Restrictions apply. 
)
%
(
e
t
a
R
t
i
H
100
90
80
70
60
50
40
30
20
10
0
 t=1.0
 t=0.5
 t=2.0
 t=3.0
 t=4.0
 t=6.0
 t=8.0
 t=9.0
 t=10.0
 t=12.0
 t=16.0
 t=20.0
 t=24.0
10 20 30 40 50 60 70 80 90 100
False Alarm Rate (%)
Figure 2: Receiver operating characteristic (ROC) curve for
the hesitation detector applied to both Salmon and Windows
interfaces’ data. Points on the curve show detector accuracy
at different sensitivities (t = threshold). The sensitivity rep-
resents the number of standard deviations beyond the mean
a pause must be to be classiﬁed as a hesitation.
2390 seconds of non-difﬁculty. These latter two numbers
are the denominators for the hit rate and false-alarm rate
computations, respectively.
The receiver operating characteristic (ROC) curve in Fig-
ure 2 shows the main result of this paper. Each point on an
ROC curve represents the accuracy of the hesitation detec-
tor for a particular value of the sensitivity parameter. The
ROC curve shows how hit rate and false-alarm rate can be
traded off, depending on the demands of a particular appli-
cation. Representative points on the combined curve show
that a 100% hit rate can be achieved if a 63% false alarm
rate is tolerable, a 92% hit rate if a 35% false alarm rate is
tolerable, an 86% hit rate if a 24% false alarm rate is tolera-
ble, and all the way down to a 6.1% hit rate if no false alarms
are tolerable. For some applications, a low false-alarm rate
may be more important than detecting every period of user
difﬁculty, while other applications may require detecting as
many periods of difﬁculty as possible, regardless of false-
alarm rate.
The ROC curve in Figure 2 shows results of the hesi-
tation detector applied to both interfaces’ data combined.
ROC curves for the detector applied to the Salmon data and
the Windows data separately are very similar to one another,
as well as to the combined curve; they are not shown sepa-
rately, because they would crowd the ﬁgure. The similarity
of the curves for the two different interfaces suggests that
the hesitation detection results are reasonably generalizable
to different interface designs.
6 Discussion
Although the detector results may appear disappointing
at ﬁrst, they are in fact quite good when considered in the
context of intended use. For example, analysts can spend
less than 13% of typical analysis time, while still detecting
more than 80% of the problem cases.
An example of hesitation detection applied to interface
defect detection provides a concrete idea of how time can
be saved by using hesitation detection. Suppose user data,
namely mouse, keyboard, screen video, and think-aloud au-
dio, have been collected from laboratory user-test sessions.
If a usability analyst were to go through the video and audio
media, searching for instances of user difﬁculty, it would
take at least as long as the entire length of the media. (This
is a very conservative estimate.
In fact, Nielsen [19] es-
timates it takes 3 to 10 times as long as the entire length
of the media; for this study, it took roughly 10 times as
long as the media for the expert to generate ground truth.)
Now suppose that instead of examining the entire media,
a hesitation detector was applied, and the usability analyst
only inspected those portions of the media ﬂagged by the
detector as potential instances of user difﬁculty. Suppose,
also, that the analyst needed to watch 5 seconds preced-
ing each period ﬂagged by the detector to understand the
context in which the hesitation occurred. (This 5-second
ﬁgure is roughly what the authors have found is necessary
in their own experience.) Although the hesitation detector
may miss some instances of user difﬁculty, the same defect
that caused a missed instance may be detected elsewhere.
The measures of interest are the percentage of all defects
detected and the amount of time saved by using the detec-
tor. Because some defects are manifested multiple times,
and because of the 5 seconds needed by an analyst to gain
context, the raw hit rate and false-alarm rate from the ROC
curve do not quite give the full story.
Table 1 shows, for values of the sensitivity parameter
from 2.0 to 6.0, the percentage of all defects detected (tak-
ing into account multiple manifestations of the same de-
fect), the amount of time an analyst would save using the
detector (taking into account the 5 seconds of prior context
needed), and the hit and false-alarm rates from the com-
bined ROC curve. It can be seen from the table, for exam-