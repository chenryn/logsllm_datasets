title:The Deforestation of L2
author:James Murphy McCauley and
Mingjie Zhao and
Ethan J. Jackson and
Barath Raghavan and
Sylvia Ratnasamy and
Scott Shenker
The Deforestation of L2
James McCauley
UC Berkeley / ICSI
Mingjie Zhao
UESTC / ICSI
Ethan J. Jackson
UC Berkeley
Barath Raghavan
ICSI
Sylvia Ratnasamy
UC Berkeley / ICSI
Scott Shenker
UC Berkeley / ICSI
ABSTRACT
A major staple of layer 2 has long been the combination of
ﬂood-and-learn Ethernet switches with some variant of the
Spanning Tree Protocol. However, STP has signiﬁcant short-
comings – chieﬂy, that it throws away network capacity by
removing links, and that it can be relatively slow to recon-
verge after topology changes. In recent years, attempts to
rectify these shortcomings have been made by either making
L2 look more like L3 (notably TRILL and SPB, which both in-
corporate L3-like routing) or by replacing L2 switches with
“L3 switching” hardware and extending IP all the way to
the host. In this paper, we examine an alternate point in
the L2 design space, which is simple (in that it is a sin-
gle data plane mechanism with no separate control plane),
converges quickly, delivers packets during convergence, uti-
lizes all available links, and can be extended to support both
equal-cost multipath and efﬁcient multicast.
CCS Concepts
•Networks → Network protocol design; Link-layer proto-
cols;
Keywords
L2 routing, spanning tree
1 Introduction
Layer 2 was originally developed to provide local connectiv-
ity while requiring little conﬁguration. This plug-and-play
property ensures that when new hosts arrive (or move), there
is no need to (re)conﬁgure the host or manually (re)conﬁgure
switches with new routing state. This is in contrast to IP (L3)
where one must assign an IP address to a newly arriving host,
Permission to make digital or hard copies of all or part of this work for personal
or classroom use is granted without fee provided that copies are not made or
distributed for proﬁt or commercial advantage and that copies bear this notice
and the full citation on the ﬁrst page. Copyrights for components of this work
owned by others than ACM must be honored. Abstracting with credit is per-
mitted. To copy otherwise, or republish, to post on servers or to redistribute to
lists, requires prior speciﬁc permission and/or a fee. Request permissions from
permissions@acm.org.
SIGCOMM ’16, August 22-26, 2016, Florianopolis , Brazil
c(cid:13) 2016 ACM. ISBN 978-1-4503-4193-6/16/08. . . $15.00
DOI: http://dx.doi.org/10.1145/2934872.2934877
and either its address or the routing tables must be updated
when it moves to a new subnet. Even though L3 has devel-
oped various plug-and-play features of its own (e.g., DHCP),
L2 has traditionally played an important role in situations
where the initial conﬁguration, or ongoing reconﬁguration
due to mobility, would be burdensome. As a result, L2 re-
mains widely used in enterprise networks and a variety of
special cases such as temporary networks for events, wireless
or virtual server networks with a high degree of host mobil-
ity, and small networks without dedicated support staff.
Because it must seamlessly cope with newly arrived hosts,
a traditional L2 switch uses ﬂooding to reach hosts for which
it does not already have forwarding state. When a new host
sends trafﬁc, the switches “learn” how to reach the sender
by recording the port on which its packets arrived. To make
this ﬂood-and-learn approach work, the network maintains
a spanning tree, which removes links from the network in
order to make looping impossible. The lack of loops plays
two essential roles: (i) it enables ﬂooding (otherwise loop-
ing packets would bring down the network) and (ii) it makes
learning simple (because there is only one path to each host).
This approach, ﬁrst developed by Mark Kempf and Radia
Perlman at DEC in the early 80s [20,29], is the bedrock upon
which much of modern networking has been built. Remark-
ably, it has persisted through major changes in networking
technologies (e.g., dramatic increases in speeds, the death of
multiple access media) and remains a classic case of elegant
design. However, users now demand better performance and
availability from their networks, and this approach is widely
seen as having two important drawbacks:
• The use of a spanning tree reduces the bisection band-
width of the network to that of a single link, no matter
what the physical topology is.
• When a link on the spanning tree fails, the entire tree
must be reconstructed. While modern spanning tree pro-
tocol variants are vastly improved over the earlier in-
carnations, we continue to hear anecdotal reports that
spanning tree convergence time is a recurring problem
in practice, particularly in high-performance settings.1
1In fact, the network administrators at our own institution
have restricted the network to a tree topology so that they
can turn off STP and avoid its large delays.
497
In this paper we present a new approach to L2, called the
All conneXion Engine or AXE, that retains the original goal
of plug-and-play, but can use all network links (and can even
support ECMP for multipath) while providing extremely fast
recovery from failures (only packets already on the wire or
in the queue destined for the failed link are lost when a link
goes down).2 AXE is not a panacea, in that it does not na-
tively support ﬁne-grained trafﬁc engineering, though (as we
discuss later) such designs can be implemented on top. How-
ever, we see AXE as being a fairly general replacement in
current Ethernets and other high-bandwidth networks where
trafﬁc engineering for local delivery is less important.
We recognize that there is a vast body of related work
in this area, which we elaborate in Section 6, but now we
merely note that none of the other designs combine AXE’s
features of plug-and-play, near-instantaneous recovery from
failures, and ability to work on general topologies. We also
recognize that redesigning L2 is not the most pressing prob-
lem in networking. However, L2 is perhaps the most widely
used form of routing (in terms of the number of installations,
not the number of hosts) and its performance is now seen as
a growing problem (as evinced by the number of modiﬁca-
tions and extensions vendors now deploy). What we present
here is the ﬁrst substantial rethinking of L2 that not only im-
proves its performance (in terms of available bandwidth and
failure recovery), but also entirely removes the need for any
control plane at this layer; this is in stark contrast to STP and
to many of the redesigns discussed in Section 6.
In the next section, we describe AXE’s design, starting
with a simpliﬁed clean design with provable correctness prop-
erties under ideal conditions, and moving on to a practical
version that is more robust under non-ideal conditions. We
then describe an implementation of AXE in P4 (Section 3)
and extensions to support multicast (Section 4) before eval-
uating AXE’s performance through simulation in Section 5.
We end with a discussion of related work in Section 6.
2 Design
Traditional L2 involves two separate processes: (i) creating
a tree (via STP or its variants) and (ii) forwarding packets
along this tree via a ﬂood-and-learn approach. In AXE, we
only use a single mechanism – ﬂood-and-learn – in which
ﬂooded packets are prevented from looping not with a span-
ning tree, but with the use of switch-based packet deduplica-
tion. Packet deduplication enables one to safely ﬂood packets
on any topology because duplicate packets are detected and
dropped by the AXE switches instead of following an end-
less loop. This allows AXE to utilize all network links, and
removes the need for a complicated failure recovery process
(like STP) when links go down.
But these advantages come at the cost of a more subtle
learning process. Without a spanning tree, packets can ar-
rive along more than one path, so AXE must actively choose
which of these options to learn. Furthermore, in the presence
of failures, some paths may become obsolete – necessitating
2AXE was ﬁrst introduced in workshop form [25]. Here we
present an extended treatment.
they be “unlearned” to make way for better ones.
To give a clearer sense of the ideas underlying AXE, we
ﬁrst present a clean version of the algorithm in Section 2.1
that has provable properties under ideal conditions. We then
present a more practical version in Sections 2.2-2.4 that bet-
ter addresses the non-ideal conditions found in real deploy-
ments. Both designs use the standard Ethernet src and dst ad-
dresses and additionally employ an AXE packet header with
four more ﬁelds: the “learnable” ﬂag L, the “ﬂooded” ﬂag F,
a hopcount HC, and a nonce (used by the deduplication algo-
rithm). We make no strong claims as to the appropriate size
of the HC and nonce ﬁelds, but for the sake of rough esti-
mation, note that if the entire additional header were 32 bits,
one could allocate two bits for the ﬂags, six for HC (allowing
up to 64 hops), and the remaining 24 for the nonce. In order
to maintain compatibility with unmodiﬁed hosts, we expect
this header to be applied to packets at the ﬁrst hop switch
(which might be a software virtual switch if AXE were to
be deployed in, e.g., a virtualized datacenter). In addition,
switches enforce a maximal HC (deﬁned by the operator) to
prevent unlimited looping in worst-case scenarios.
As we discuss more fully in Section 2.3, each switch uses a
deduplication ﬁlter to detect (and then drop) duplicate pack-
ets based on the triplet . While there are a
number of ways to construct such a ﬁlter, here we use a hash-
table-like data structure that can experience false negatives
but no false positives (i.e., no non-duplicates are dropped by
the ﬁlter, but occasional duplicates may be forwarded).
The forwarding entries in a switch’s learning table are in-
dexed by an Ethernet address and contain the arrival port
and the HC of the packet from which this state was learned
(which are the port one would use to reach the host with the
given address and the number of hops to reach it if a packet
followed the reverse path).
Finally, note that AXE pushes the envelope for fast fail-
ure response, but does not make any innovation in the realm
of fast failure detection. Instead, AXE can leverage any ex-
isting detection techniques, from higher level protocols like
CFM [11] and BFD [19] to hardware-based techniques with
failure detection times on the order of microseconds [7].
2.1 Clean Algorithm
Recall that the traditional Ethernet approach involves ﬂood-
ing and learning: (i) a packet is ﬂooded when it arrives at a
switch with no forwarding state for its destination address,
and (ii) an arriving packet from a host establishes a forward-
ing entry toward that host. The approach can be so simple
due to the presence of a nontrivial control plane algorithm –
STP – which prunes the effective topology to a tree. Because
it operates on a general topology without any control plane
protocol, the clean version of AXE is slightly more compli-
cated and can be summarized as follows:
Header insertion and host discovery: When a packet
arrives without an AXE header, a header is attached with
HC=1, the L ﬂag set, and the F ﬂag unset. If there is no for-
warding state for the source, an entry is created and the F
ﬂag is set. The ﬁrst step merely initializes the header; the
second step is how switches learn about their attached hosts
498
(and the subsequent ﬂood informs the rest of the network
how to reach this host).
Flooding: When a packet with the F ﬂag set arrives, it is
ﬂooded out all other ports. When a packet with the F ﬂag
unset arrives at a switch with no forwarding state for its des-
tination or for which the forwarding state is invalid (e.g., its
link has failed), the F ﬂag is set, and the packet is ﬂooded.
The ﬂooded packets have the L ﬂag set only if the ﬂood orig-
inated at the ﬁrst hop (i.e., HC=1). The ﬂooding behavior is
similar to traditional learning algorithms, with the addition
of the explicit ﬂooding and learning ﬂags.
Learning and unlearning: Switches learn how to reach
the source from ﬂooded packets with the L ﬂag set, and un-
learn (erase) state for the destination whenever they receive
a ﬂood packet with the L ﬂag unset. While traditional learn-
ing approaches learn how to reach the source host from all
incoming packets, in AXE we can only reliably learn from
packets ﬂooded from the ﬁrst hop (since packets ﬂooded
from elsewhere might have taken circuitous paths, as we dis-
cuss below). Moreover, when switches learn from ﬂooded
packets, they choose the incoming copy that has the smallest
HC. When a ﬂooded packet arrives with the L ﬂag unset, it
indicates that there is a problem reaching the destination (be-
cause the ﬂood originated somewhere besides the ﬁrst hop,
as might happen with a failed link); this is why switches un-
learn forwarding state when such packets arrive.
Wandering packets: When the HC of a nonﬂooded packet
reaches the limit, the packet is ﬂooded (with the F ﬂag set and
the L ﬂag unset) and local state for the destination is erased.
If the forwarding state has somehow created a loop, erasing
the state locally ensures that the loop is broken. Flooding the
packet (with the L ﬂag unset) will cause all forwarding state
to the destination host to be erased (so the next packet sent
by that host will be ﬂooded from the ﬁrst hop, and the correct
forwarding state learned).
Algorithm 1 shows pseudocode of this clean algorithm,
which processes a single packet p at a time and consults the
learning table Table by calling a Lookup() method with the
desired Ethernet address. Lookup() returns False if there is
no table entry corresponding to the address. The operation
Table.Learn() inserts the appropriate updated state in the ta-
ble, and Table.Unlearn() removes the state. IsPortDown() re-
turns True if the output port passed to it is unavailable (e.g.,
the link has failed). The IsDuplicate value (obtained from the
deduplication ﬁlter) indicates whether the switch has already
seen a copy of that packet (as duplicates of a packet may ar-
rive on multiple ports if the topology contains cycles). Out-
put() sends a packet via a speciﬁed port, and Flood() sends a