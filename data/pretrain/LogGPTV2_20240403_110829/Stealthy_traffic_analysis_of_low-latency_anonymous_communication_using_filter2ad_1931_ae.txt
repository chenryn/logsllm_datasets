linking; our attacks, however, do not require the compromise
of any relays in the Tor network.
223Cor=0.936 Mean(s1)=465.1 Mean(s2) = 463.0
Cor=0.413 Mean(s1)=465.1 Mean(s2) = 463.0
Cor=-0.97 Mean(s1)=65.37 Mean(s2) = 63.02
Stream 1 (s1)
Stream 2 (s2)
)
s
p
b
K
(
t
u
p
h
g
u
o
r
h
T
 1500
 1000
 500
 0
Stream 1 (s1)
Stream 2 (s2)
)
s
p
b
K
(
t
u
p
h
g
u
o
r
h
T
 2500
 2000
 1500
 1000
 500
 0
Stream 1 (s1)
Stream 2 (s2)
)
s
p
b
K
(
t
u
p
h
g
u
o
r
h
T
 300
 250
 200
 150
 100
 50
 0
 0
 20
 40
 60
 80
 100  120
 40
 50
 60
 70
 80
 90
 100
 0
 10
 20
 30
 40
 50
Samples (5 second interval)
Samples (0.5 second interval)
Samples (2 second interval)
(a)
(b)
(c)
Figure 10: (a) Positive correlation between streams. (b) Batching eﬀect when sampling every 0.5 seconds.
(c) Batching eﬀect when sampling every 2 seconds.
Tor implements stream-level throttling within circuits. This
end-to-end ﬂow control works as follows: each stream is ini-
tially allowed to send 500 of Tor’s 512-byte cells (also called
the packaging window ). Upon successful reception of pack-
ets, the packaging window is incremented in blocks of 50
cells. Observe that if a stream is waiting for the packag-
ing window to be incremented, then another stream that is
being multiplexed on the same circuit can hog the circuit
(batching eﬀect) for a small time interval.
While the streams share the throughput fairly, ﬂow- and
congestion-control mechanisms in Tor result in batching be-
havior, where one stream may monopolize the circuit for
some period of time, while the other streams lie idle. We
can see this mutually exclusive use of the circuit by two
streams when we sample the throughput at smaller time
scales, as can be seen in Figures 10(b) and 10(c). We note
that the length of the batches seems to be a multiple of
25 KB, corresponding to 50 of Tor’s 512-byte cell, matching
our intuition that 50-cell packaging window increments are
responsible for the batching eﬀect. This also means that
the time scales necessary to observe this eﬀect will vary de-
pending on the throughput of the ﬂow: in Figure 10(b), the
mean throughput value is 450 Kbps and we observe the be-
havior sampling every 0.5 seconds, whereas in Figure 10(c),
the mean throughput value is 66 Kbps, and we observe the
behavior sampling every 2 seconds.
Based on these observations, we propose the following al-
gorithm to infer whether the streams are coming from the
same client:
1. We ﬁrst check for strong correlation at macro-level
time scales, as done in previous sections.
2. We deﬁne our micro-level time scale to be
Throughput(KBps)
3. We check for the batching eﬀect at micro-level timescales.
25 KB
Namely, we compute the fraction of time when only
one stream is active out of the total time that either
stream is active, which shows the degree of “mutual
exclusivity” between the two streams.
4.2 Results
To see how well the algorithm works, we performed an
experiment in which a single client connects to two servers
under our control, located in two diﬀerent geographical lo-
cations, and simultaneously downloads data. Since the con-
nections were made simultaneously, the two streams were
multiplexed over the same Tor circuit. We performed a to-
tal of 225 runs between November 2010 and February 2011.
95% CI
e
t
a
r
r
o
r
r
e
r
e
v
o
s
s
o
r
C
 0.3
 0.25
 0.2
 0.15
 0.1
 0.05
 0
 0  60  120 180 240 300 360 420 480 540
Time duration (in seconds)
Figure 11: Stream linkability attack: crossover error
rate as a function of time.
To check for false positives in our attack, we repeated the
experiment with downloads by two diﬀerent clients using
separate circuits that have a common exit relay. We per-
formed 225 iterations of this experiment in April 2011.
Recall that the tradeoﬀ between false positives and false
negatives is governed by the choice of the threshold values
for correlation and mutual exclusiveness. As the threshold
values are increased, the false positives decrease, but the
false negatives increase. We plot the crossover error rate as
a function of the communication duration in Figure 11. We
can see that as the time duration is increased, the accuracy
of our attack quickly improves. Even at a small duration of
120 seconds, our mean crossover error rate is less than 5%,
which gets reduced to 1.3% beyond 300 seconds (with a 95%
conﬁdence interval of less than 4%).
Hopper et al. [24] analyzed a similar attack scenario, where
latency information was used to determine if the same client
is communicating with two servers. However, the crossover
error rate in their attack was 17% even when the communi-
cation duration was 10 minutes. Note that throughput and
latency provide orthogonal sources of information, and it
may be interesting to combine our attacks with latency at-
tacks to further improve accuracy. Finally, we also study the
scenario where client Alice is communicating simultaneously
on 3 streams, but only two of the destination endpoints are
colluding. We found that the crossover error rate in this case
was higher than the previous scenario, but still less than 8%
when the communication duration is 300 seconds.
5. DISCUSSION
We discuss some issues and ramiﬁcations of our attacks:
224Countermeasures: We now consider some possible ways
to defend Tor users against our attacks. First, the circuit
throughput ﬁngerprinting attack relies on the existence of a
shared bottleneck relay along the two paths. One counter-
measure might be to use better load balancing within the
Tor network. For example, preferring paths through higher
capacity relays may make it more likely that the bottle-
neck is outside the Tor network. While it may be diﬃcult
to completely eliminate all bottlenecks within the Tor net-
work, it may be possible to avoid making more sensitive
relays as bottlenecks, for example by setting up paths such
that guard relays are not the bottlenecks. In addition, mul-
tipath forwarding has been shown to give more even load
balance in conventional networks [23]. Using multipath for-
warding could reduce the number of bottlenecks by evenly
distributing traﬃc over multiple paths, as well as “average
out” short-term variations in throughput that arise from any
single path. Also, since our attacks take some time to reli-
ably associate the circuits, endpoints may periodically cycle
through a small set of circuits, to reduce the amount of time
they spend sharing a bottleneck with a malicious circuit.
Another approach might be to change the eﬀects that the
bottleneck relay has on traﬃc. For example, relays may
intentionally use an uneven rate allocation across ﬂows, or
inject spurious cross-traﬃc, to decouple throughput corre-
lations in circuits they carry. Next, the stream linkability
attack is based on Tor’s intra-stream scheduling mechanism.
To avoid this attack, Tor users may wish to perform heuris-
tics at the client side to prevent circuit re-use for sensitive
ﬂows. In addition, better stream multiplexing algorithms [5]
(e.g., algorithms that share bandwidth on a ﬁner granular-
ity) could eliminate the batching eﬀects that we observed.
Alternative schemes to measure throughput: Our
current attacks measure throughput by simply forwarding
TCP traﬃc through the Tor relays. However, much work
has been done in the networking community in the area of
throughput probing, and it may be possible to leverage these
techniques for improved performance. For example, instead
of just monitoring ﬂow throughput, techniques exist to mon-
itor total capacity of the bottleneck link, by sending pack-
ets with precise timings [27, 29]. In situations where these
techniques can be applied, correlation may be simpliﬁed, by
revealing how much total capacity there is in nodes partici-
pating in the underlying channel. In addition, some of these
techniques can measure throughput within short bursts of
packets (e.g., packet pairs and packet trains [27, 29]), which
may improve correlation for sessions of short duration.
Resource requirements: Our primary attacks are stealthy
and do not require the attacker to congest Tor relays. Thus,
the only cost incurred by an attacker is to create circuits
to narrow the set of relays present in a circuit. To get a
loose upper bound on the attacker’s resource requirements,
we note that the average throughput through a Tor relay
from our study of 2,104 relays (Figure 1) is 226 KBps. Con-
sider the very extreme case where the attacker simultane-
ously constructs one-hop circuits through each of the Tor
relays in the entire network. The attacker would need to
send 464.36 MBps (1632.51 GB per hour) of traﬃc. While
this amount is higher than typical edge node bandwidth,
the attacker may be able to acquire such bandwidth by us-
ing botnet hosts, or a hosted infrastructure such as Amazon
EC2. Using EC2 pricing of $0.12 per GB, the attacker could
send traﬃc for one hour with a cost of $196 (volume pric-
ing for bandwidth in EC2 would reduce this cost for longer
monitoring periods).
Impact of bulk traﬃc throttling: Recently, Tor imple-
mented a mechanism that enables relay operators to throttle
bulk traﬃc connections using a token bucket rate limiting
system on traﬃc coming from non-relays. The rate limiting
takes into account the burst rate and the long term through-
put rate of a connection. The mechanism was ﬁrst imple-
mented in Tor-0.2.2.15-alpha, and thus did not impact our
initial experiments conducted throughout November of 2010.
However, as new versions of Tor were deployed throughout
early 2011, we noticed that some of the attacker’s probe cir-
cuits were getting throttled after roughly 300 seconds of high
rate transfer down to a set limit of about 20 KBps. Note that
the attacker can easily overcome the eﬀects of throttling on
its probe circuits by opening a new probe circuit when the
current circuit begins to be throttled.
Ethics: Given that throughput information can leak in-
formation about clients, we conducted our study with some
caution.
In our experiments, we only attack the circuits
created by our own experimental tool to avoid collecting in-
formation about non-participating clients. We also avoided
launching large-scale attacks; we focus most of our experi-
ments on only 25 Tor relays. All throughput data we col-
lected was stored with strong encryption on machines be-
hind a ﬁrewalled network. While analyzing traﬃc on a
guard relay, we only recorded data pertaining to the distri-
bution of burst sizes and gap times for the interactive traﬃc
model (data-minimization). All other collected data (includ-
ing outputs of various intermediate steps) was discarded to
maintain the privacy of Tor users.
6. CONCLUDING REMARKS
To the best of our knowledge, our work comprises the
ﬁrst study of throughput attacks on anonymity systems. We
presented attacks to identify Tor relays used by an existing
connection, as well as techniques to identify the relationship
between two streams, solely by monitoring their through-
put. This calls into question, existing proposals to make ob-
served bandwidth information public [32, 42, 45]. Our tech-
niques are stealthy (cannot be detected by Tor users/relays)
and low cost (do not require Tor relays to be congested).
Moreover, our attacks use threat models and resource re-
quirements that diﬀer signiﬁcantly from attacks using other
ﬂow features. Overall, our study highlights the complexity
of designing anonymous communication systems.
Acknowledgments
We are grateful to Roger Dingledine for helpful discussions
about Tor and for his guidance in shepherding our paper.
We would like to thank Eugene Vasserman for suggesting the
mechanism to probe Tor relays. This paper beneﬁtted from
discussions with George Danezis, Amir Houmansadr, Qiyan
Wang, Giang Nyugen, Sonia Jahid and Xun Gong. Finally,
we would like to thank the anonymous reviewers for their
invaluable feedback on earlier drafts of this paper. This work
was supported in part by NSF CNS 08-31488, 09-53655, 10-
40391 and an International Fulbright S&T Fellowship.
7. REFERENCES
[1] http://netfiles.uiuc.edu/mittal2/www/
throughput-fingerprinting.html.
225[2] Cisco Systems, Inc., Cisco IOS Netﬂow.
http://www.cisco.com/en/US/products/ps6601/products_
ios_protocol_group_home.html.
[3] Symantec data loss prevention.
http://www.symantec.com/business/products/family.
jsp?familyid=data-loss-prevention.
watermark to detect correlated network ﬂows. In NDSS
(2011).
[27] Hu, N., Li, L., Mao, Z., Steenkiste, P., and Wang, J. A
measurement study of Internet bottlenecks. INFOCOM
(2005).
[28] I2P. I2P anonymous network.
[4] Abbott, T., Lai, K., Lieberman, M., and Price, E.
http://www.i2p2.de/index.html, 2003.
Browser-based attacks on Tor. In PETS (2007).
[29] Jacobson, V. Pathchar. http:
[5] AlSabah, M., Bauer, K., Goldberg, I., Grunwald, D.,
McCoy, D., Savage, S., and Voelker, G. DefenestraTor:
Throwing out windows in Tor. Tech. rep., University of
Waterloo, 2011.
[6] Back, A., Goldberg, I., and Shostack, A. Freedom
systems 2.1 security issues and analysis. White paper, Zero
Knowledge Systems, Inc., May 2001.
[7] Back, A., M¨oller, U., and Stiglic, A. Traﬃc analysis
attacks and trade-oﬀs in anonymity providing systems. In
IH (2001).
[8] Berthold, O., Federrath, H., and K¨ohntopp, M.
Project “anonymity and unobservability in the Internet”. In
10th Conf. on Computers, Freedom and Privacy (2000).
[9] Berthold, O., Federrath, H., and K¨opsell, S. Web
MIXes: A system for anonymous and unobservable Internet
access. In Proceedings of Designing Privacy Enhancing
Technologies: Workshop on Design Issues in Anonymity
and Unobservability (2000).
[10] Borisov, N., Danezis, G., Mittal, P., and Tabriz, P.
Denial of service or denial of security? How attacks on
reliability can compromise anonymity. In CCS (2007).
[11] Chakravarty, S., Stavrou, A., and Keromytis, A. D.
Traﬃc analysis against low-latency anonymity networks
using available bandwidth estimation. In ESORICS (2010).
[12] Chaum, D. Untraceable electronic mail, return addresses,
and digital pseudonyms. CACM 24, 2 (1981).
[13] Danezis, G. Statistical disclosure attacks: Traﬃc
conﬁrmation in open environments. In Proceedings of
Security and Privacy in the Age of Uncertainty,
(SEC2003) (2003).
[14] Danezis, G., Dingledine, R., and Mathewson, N.
Mixminion: Design of a Type III anonymous remailer
protocol. In IEEE S&P (2003).
[15] Diaz, C., Seys, S., Claessens, J., and Preneel, B.
Towards measuring anonymity. In PETS (2002).
[16] Dingledine, R., Mathewson, N., and Syverson, P. Tor:
The second-generation onion router. In USENIX Security
(2004).
[17] Edman, M., and Syverson, P. AS-awareness in Tor path
selection. In CCS (2009).
[18] Emulab. EMULAB - Network Emulation Testbed Home.
https://www.emulab.net/.
[19] Evans, N. S., Dingledine, R., and Grothoff, C. A
practical congestion attack on Tor using long paths. In
USENIX Security (2009).
[20] Feamster, N., and Dingledine, R. Location diversity in
anonymity networks. In WPES (2004).
[21] Fisher, R. On the probable error of a coeﬃcient of
correlation deduced from a small sample. Metron (1921).
[22] Gulcu, C., and Tsudik, G. Mixing E-mail with Babel. In
NDSS (1996).
[23] He, J., Suchara, M., Bresler, M., Rexford, J., and
Chiang, M. Rethinking Internet traﬃc management: From
multiple decompositions to a practical protocol. In CoNext
(2007).
[24] Hopper, N., Vasserman, E. Y., and Chan-Tin, E. How
much anonymity does network latency leak? In CCS
(2007).
[25] Hopper, N., Vasserman, E. Y., and Chan-TIN, E. How
much anonymity does network latency leak? ACM Trans.
Inf. Syst. Secur. (2010).
[26] Houmansadr, A., and Borisov, N. SWIRL: A scalable
//www.caida.org/tools/utilities/others/pathchar/.
[30] Kesdogan, D., Agrawal, D., and Penz, S. Limits of
anonymity in open environments. In IH (2002).
[31] Koblas, D., and Koblas, M. R. SOCKS. In UNIX
Security III Symposium (1992).
[32] Loesing, K. Measuring the Tor network from public
directory information. In HotPets (2009).
[33] Mclachlan, J., and Hopper, N. Don’t clog the queue!
Circuit clogging and mitigation in P2P anonymity schemes.
In FC (2008).
[34] Mittal, P., Khurshid, A., Juen, J., Caesar, M., and
Borisov, N. Stealthy traﬃc analysis of low-latency
anonymous communication using
throughput-ﬁngerprinting, 2011. Available at
http://netfiles.uiuc.edu/mittal2/www/
throughput-fingerprinting.pdf.
[35] Mittal, P., Paxson, V., Sommer, R., and Winterrowd,
M. Securing mediated trace access using black-box
permutation analysis. In HotNets (2009).
[36] M¨oller, U., Cottrell, L., Palfrader, P., and
Sassaman, L. Mixmaster Protocol—Version 2. IETF
Internet Draft, July 2003.
[37] Murdoch, S. J. Hot or not: Revealing hidden services by
their clock skew. In CCS (2006).
[38] Murdoch, S. J., and Danezis, G. Low-cost traﬃc analysis
of Tor. In IEEE S&P (2005).
[39] Murdoch, S. J., and Zieli´nski, P. Sampled traﬃc analysis
by Internet-exchange-level adversaries. In PETS (2007).
[40] Overlier, L., and Syverson, P. Locating hidden servers.
In IEEE S&P (2006).
[41] Padhye, J., Firoiu, V., Towsley, D., and Kurose, J.
Modeling tcp throughput: a simple model and its empirical
validation. SIGCOMM Comput. Commun. Rev. 28
(October 1998), 303–314.
[42] Perry, M. Torﬂow: Tor network analysis. In HotPets
(2009).
[43] Raymond, J.-F. Traﬃc analysis: Protocols, attacks, design
issues, and open problems. In Designing Privacy
Enhancing Technologies (2000).
[44] Serjantov, A., and Danezis, G. Towards an information
theoretic metric for anonymity. In PET (2002).
[45] Snader, R., and Borisov, N. Eigenspeed: Secure
peer-to-peer bandwidth evaluation. In IPTPS (2009).
[46] Syverson, P., Tsudik, G., Reed, M., and Landwehr, C.
Towards an analysis of onion routing security. In Designing
Privacy Enhancing Technologies (2000), pp. 96–114.
[47] Syverson, P. F., Goldschlag, D. M., and Reed, M. G.
Anonymous connections and onion routing. Security and
Privacy, IEEE Symposium on 0 (1997).
[48] The Tor Project. Tor metrics portal.
http://metrics.torproject.org/.
[49] The Tor Project. Who uses Tor.
http://www.torproject.org/about/torusers.html.en.
Accessed Februrary 2011.
[50] Wright, M., Adler, M., Levine, B. N., and Shields, C.
An analysis of the degradation of anonymous protocols. In
NDSS (2002).
[51] Wright, M., Adler, M., Levine, B. N., and Shields, C.
Defending anonymous communication against passive
logging attacks. In IEEE S&P (2003).
226