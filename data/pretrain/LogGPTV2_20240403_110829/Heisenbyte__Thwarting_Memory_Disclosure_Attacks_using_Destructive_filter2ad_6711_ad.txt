structive code read operations while allowing legitimate data
reads in executable memory to function properly, we need to
maintain separate code and data views for each executable
memory page we are protecting. We leverage the EPT to
Figure 7: Using EPT to maintain separate code and
data views transparently.
transparently redirect the use of any guest virtual address to
the desired view at runtime. In Figure 7(a), before a target
process is being protected, an identity EPT mapping of the
guest physical to host machine memory is maintained.
After identifying the guest physical memory pages to pro-
tect, we add a duplicate page in the host machine address
space. Any subsequent instructions being executed are redi-
rected to the code copy memory page shown at the bottom
of Figure 7(b). This guest physical page is conﬁgured to be
execute-only using EPT.
Destructive reads into executable memory With
the executable pages conﬁgured to trigger a VM exit upon
a data read, our #EPT violation handler in the host mode
component of the driver can intervene and mediate at these
events. At each #EPT read violation, we overwrite the data
read address within our code copy page with a random byte.
This constitutes the destructive nature of our code reads.
Since there are legitimate data reads into executable mem-
ory from the kernel, especially during PE loading, we per-
form the byte garbling only when the read operation origi-
nates from user-space.
Next we edit the EPT entry to have read/write/execute
access and redirect the read operation to read from the orig-
inal code page, now intended exclusively to service data read
requests, as shown in Figure 7(c). To restore the memory
protection, we set the single-step trap ﬂag in the EFLAGS
so that a VM exit is triggered immediately after the instruc-
tion performing the read operation. At this point, we restore
the EPT permissions to execute-only to resume operation.
Virtual Addr Space(Target Process)DataGuest PhysicalAddr SpaceHost MachineAddr SpaceDataData(a) original EPT identity mapping with no monitoringVirtual Addr Space(Target Process)DataGuest PhysicalAddr SpaceHost MachineAddr SpaceDataData(b) during execution of instructions within the executable memoryVirtual Addr Space(Target Process)DataGuest PhysicalAddr SpaceHost MachineAddr SpaceDataData(c) data reads into the executable memory RWX RW_ RW____X RWX RW_CodeDataCodeDataCodeDataCodeDataCodeDataCodeDataCodeDataCodeDataCodeDataCodeDataCOPYCodeDataCOPY5. EVALUATION
In this section, we demonstrate the utility of Heisenbyte
in stopping attacks that use static and dynamic memory
disclosure bugs. We evaluate the performance and memory
overhead of our system. Our experiments are done on 32-bit
Windows 7 running on a quad-core Intel i7 processor with
2GB RAM. As our prototype does not handle SMP systems,
we conﬁgure the system to use only one physical core.
5.1 Security Effectiveness
5.1.1 Memory Disclosure Attack on Static Code
We use the Internet Explorer (IE) 9 memory disclosure
vulnerability (CVE-2013-2551) presented by Snow et al. [22].
This is a fairly powerful heap overwrite vulnerability involv-
ing a Javascript string object.
It enables an adversary to
perform arbitrary memory read and write operations repeat-
edly without causing IE to crash. On our test setup, we
craft an exploit that leverages this memory disclosure bug
as a memory read and write primitive.
As ASLR is enabled by default – Window’s ASLR is a
coarse-grained form that changes only the base addresses of
the shared libraries at load time –, the exploit has to look for
suitable code reuse “gadgets” to string together as an attack
payload. To demonstrate that our system works with an
exploit that uses disclosed executable memory contents, we
craft our exploit to dynamically locate a stack pivot ROP
gadget.
The exploit begins by ﬁrst leaking the virtual table pointer
associated with the vulnerable heap object. This pointer
contains an address in the code page of VGX.dll shared li-
brary. Using the memory read primitive, the exploit scans
backwards in memory for the PE magic signature MZ to
search for the PE header of the shared library.
It is noteworthy that at this point, if IE uses any code
within the range of bytes the exploit has scanned, IE will
crash due to the corruption of legitimate code by the destruc-
tive code reads. However, in a real deployment, as defenders,
we do not want to rely on such opportunistic crashes. We
assume that the exploit avoids scanning executable memory
during this stage and only reads non-executable memory.
When the exploit ﬁnds the PE header of the library, it can
then derive the base address of user32.dll by parsing the
import address table in the PE header. The shared library
user32.dll contains a set of ROP gadgets that are found
oﬄine. With this, the exploit can construct its ROP pay-
load by adjusting the return addresses of the pre-determined
ROP gadgets with the base address of user32.dll. To sim-
ulate the dynamic discovery of “gadgets” in a dynamic code
reuse exploit, we craft the exploit to perform a 4-byte mem-
ory scan at the location of the stack pivot gadget, and then
redirect execution to that stack pivot gadget.
While our actual system uses a randomized byte to garble
the code, we use a ﬁxed 0xCC byte (i.e. a debug trap) for
the code corruption in this experiment. This allows us to be
sure that any crash is directly caused by our destructive code
reads. When control ﬂow is redirected to the stack pivot
gadget, IE crashes at the address of the stack pivot with a
debug trap. This demonstrates that Heisenbyte stems the
further progress of the exploit as a result of corrupted byte
caused by the exploit’s executable memory read.
Furthermore, we conﬁgure the Windbg debugger to au-
tomatically launch upon application crash. When the de-
Figure 8: SPEC2006 execution overhead.
bugger is invoked at the crash address at the location of the
stack pivot, the debugger displays and disassembles the orig-
inal byte sequence of the stack pivot gadget in user32.dll.
As the debugger reads memory as data read operations, the
original bytes at that code address are shown. It is appar-
ent that what gets executed is diﬀerent from what gets read.
This further demonstrates that Heisenbyte correctly main-
tains separate code and data views of executable memory.
5.1.2 Memory Disclosure Attack on Dynamic Code
At the time of writing, we are aware of only one pub-
licly available exploit [19] that uses an integer overﬂow bug
to achieve memory read/write capability on the JIT code
cache of mobile Chrome. However, this exploit only works
on ARM devices, so we cannot use this for our evaluation.
To evaluate our system on memory disclosure attack on
dynamically generated code, we create a vulnerable program
that mimics the behavior of JIT engine in the creation of dy-
namic executable buﬀers. Our program allocates a readable
and writable buﬀer and copies into this buﬀer a pre-compiled
set of instructions that uses a jump table. This is similar
to the behavior of legacy JIT engines that emit native code
containing both code and data in the dynamic buﬀer.
With the code cache ready to execute, our program makes
the dynamic buﬀer executable by changing the permission
access to readable/executable, and executes the buﬀer from
the base address of the buﬀer. The program functions cor-
rectly with Heisenbyte running. Since the jump tables in
the dynamic buﬀer are only ever used as data in the life-
time of the buﬀer, Heisenbyte properly supports the normal
functionality of the simulated JIT-ed code.
To simulate an attack that scans the memory of the dy-
namic code region for code reuse gadgets, we create an ex-
ploit to leverage a memory disclosure bug we have designed
into the program. The exploit uses this bug to read the ﬁrst
four bytes of the dynamic buﬀer and redirects execution con-
trol to the start of the dynamic buﬀer. Like in the case of
the experiment with IE9, the vulnerable program crashes at
the base address of the dynamic buﬀer as a result of the
destructive code reads induced by Heisenbyte.
5.2 Performance Overhead
5.2.1 Execution Overhead
We measure the slowdown caused by various components
of Heisenbyte using the SPEC2006 integer benchmark pro-
400.perlbench401.bzip2403.gcc429.mcf445.gobmk456.hmmer458.sjeng464.h264ref471.omnetpp473.astar483.xalancbmk010203040506070RuntimeOverhead(%)VirtualizationDestructiveCodeReadsgrams. Since our solution works on and rewrites binaries,
we ﬁrst compile the programs and work with the compiled
binaries assuming no source code is available. We compile
the SPEC2006 programs with Microsoft Visual Studio 2010
compiler using the default linker and compilation ﬂags. As
the compiler does not support the C99 feature, e.g. type
_complex, we cannot successfully compile 462.libquantum.
We thus use only 11 out of 12 SPEC2006 integer applica-
tions for our evaluation. For all the tests, we restart each set
of runs on a rebooted system, perform 3 iterations using the
base reference input and take the median measurements.
We evaluate the execution slowdown caused by Heisenbyte
to an originally non-virtualized system. The overhead of
Heisenbyte comprise two main sources, namely the overhead
as a result of virtualizing the entire system at runtime, and
the overhead of incurring two VM exits for each destructive
code read operation. Separating the measurements for the
two allows us to evaluate the overhead net of virtualization
when Heisenbyte is deployed on existing virtualized systems
(they are already occurring the virtualization overhead).
To measure the overhead caused by purely virtualizing
the system, we run the SPEC benchmarks with the Heisen-
byte driver loaded, but without protecting any binaries or
shared libraries. Compared to a baseline system, the vir-
tualization overhead ranges from 0% (401.bzip2) to 9.6%
(429.mcf). The virtualization overhead is highly dependent
on the execution proﬁle of the programs. We attribute the
high overhead for 401.bzip2 to the paging operations per-
formed by Intel EPT hardware page walker. On average,
the geometric mean of the virtualization overhead caused
by Heisenbyte is 1.8% across all the programs.
With the measurements for the virtualization overhead,
we can now measure the overhead of the destructive code
reads due to the incomplete removal of legitimate data from
the executable memory pages. We conﬁgure Heisenbyte to
protect the SPEC binaries and all the shared DLL libraries
used by SPEC, and compare the execution time to the base-
line. The variance in this overhead is huge, depending on
how much legitimate data is not removed by the binary
rewriting. The destructive code read overhead ranges from
0% (401.bzip2) to 62% (400.perlbench), with an average
of 16.5% across the programs. This overhead is a direct con-
sequence of the imperfect removal of legitimate data from
the executable memory pages at the binary rewriting stage.
The higher the frequency a program accesses such legitimate
data in the memory pages, the greater the overhead incurred
by the destructive codes. The average of the combined vir-
tualization and destructive code read overhead is 18.3%.
In this work, we choose to be very conservative in the
types of data that we relocate out of the executable sections
during the binary rewriting to show that the system can
still tolerate the incomplete relocation of all data from the
executable sections. This overhead can be further reduced
with a more aggressive strategy in removing the data.
5.2.2 Resident Memory Overhead
As discussed in § 4.2.2, Heisenbyte requires keeping the
executable memory pages resident in physical memory when
conﬁguring the EPT permissions and monitoring for data
reads to these pages. Here we evaluate how much more
physical memory overhead introducing Heisenbyte causes.
We measure this by tracking the peak Resident set size (RSS)
of a process over entire program execution. RSS measures
Figure 9: Memory overhead in terms of peak RSS.
the size of process memory that remains resident in the RAM
or physical memory. We inject a proﬁling thread to our
processes to log the current maximum RSS as the process
runs every 20 seconds. Figure 9 shows a modest increase of
0.8% on average in the peak RSS across all the programs.
6. DISCUSSION
Code leaks via side channels While Heisenbyte thwarts
the use of the disclosed gadgets found by directly scanning
executable memory with a memory disclosure bug, it does
not protect against attacks that indirectly leak the locations
of code reuse gadgets through side channels, such as tim-
ing channels [20, 9]. Comprehensive protection against side
channel leaks is generally recognized as a prohibitively chal-
lenging tasks in the general context, and not just pertaining
to the disclosure of executable memory.
Our work focuses on protecting client-side COTS binaries
prevalent on Windows systems. Most of these programs are
not tolerant of crashes. Furthermore, exploiting these user
applications is time-sensitive. For example, an attacker loses
the opportunity to exploit the system once its exploit invokes
a crash on IE or takes too long. These aforementioned rea-
sons make existing side channel-based memory disclosure
attacks on this class of binaries challenging. Therefore, we
do not consider this type of attacks in our work.
Size of garbled code At present, Heisenbyte disregards
the operand size of the instruction performing the reads into
the executable memory, and performs destructive code reads
of only one byte. An adversary who uses data reads of four
bytes to scan the memory can potentially exploit this. Gar-
bling only one byte will give the adversary the potential to
use the remaining three bytes from the data reads. To tackle
this problem, Heisenbyte can easily be extended to handle
code reads using diﬀerent operand sizes. We can maintain
three hashtables, each storing the opcodes used for 1-byte,
2-byte and 4-byte operands. Whenever a code read hap-
pens, Heisenbyte can look up the hashtable to determine
eﬃciently the size of operand and destroy the same number
of bytes accordingly.
Support for ﬁne-grained ASLR Heisenbyte requires
ﬁne-grained ASLR to ensure that the layout of code cannot
be inferred with partial reads into the non-executable sec-
tions [20, 9]. Fine-grained ASLR can be extended in Heisen-
byte in a number of ways. For example, since we are rewrit-
ing the binaries, ﬁne-grained ASLR such as in-place code