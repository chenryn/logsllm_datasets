with implicit ﬂows. Implicit ﬂows occur when control ﬂow inﬂu-
ences the possible values of data. For example, information may be
implicitly passed along branches of the form if(x==0) y=1;
else y=0; which allows the user to inﬂuence the value of y by
modifying the value of x. Taint tracking systems usually do not
consider y tainted even if x is tainted. Although such cases result
in implicit information ﬂows that are theoretically exploitable, the
majority of attacks depend on direct ﬂow of data [16, 10], which
our system does guard against.
Our system also does not defend against attacks that are not
based on information ﬂows in program code. For example, dis-
tributed denial of service attacks can harm systems without creat-
ing any individually anomalous information ﬂows. Information can
also be leaked via covert timing channels, which we also do not de-
tect, although our requirement for source code limits the ability of
malicious developers to introduce malicious code. Finally, our so-
lution only defends against attacks, not arbitrary memory errors. A
buggy program can still experience segmentation faults and other
errors using only untainted data.
4.5.4 Defending the Enforcement Mechanism
The design of our system makes it difﬁcult in practice for an
attacker to subvert the enforcement mechanism itself. First, like
other compiler-based systems [48, 31], the original program is writ-
ten before the enforcement code is added, so the original program
cannot directly access enforcement data. Moreover, unlike taint
tracking systems that track taintedness using stack-allocated vari-
ables or ﬁxed addresses [48], all of our structures are dynamically
allocated on the heap and concealed behind function calls. Point-
ers to enforcement data never appear in application code, so the
attacker cannot obtain a pointer to our enforcement data without
sophisticated heap attacks. Thus, the attacker will not be able cor-
rupt enforcement data without ﬁrst hijacking the program by ex-
ploiting some vulnerability that the user’s security policy does not
guard against. Attacks that the user’s policy do guard against are
prevented.
For additional protection, our mechanism can be easily com-
bined with various defenses against memory errors. For example,
address space randomization [7] or heap randomization [6] can be
used to defend our system against corruption attacks.
5. EVALUATION
In this section, we evaluate the effectiveness of our system by
using it to prevent format string attacks and ﬁle disclosure vulnera-
bilities. We verify attack prevention, measure static code expan-
sion, and measure runtime overhead for ﬁve open-source server
programs and four compute-bound SPECint 2000 benchmarks. Since
our system is a source-to-source translator, we compile the en-
hanced C programs using gcc-3.3 on Linux with the default
compiler options and optimization levels that were supplied by the
original developers of the benchmark programs. The programs are
then run on a 2.4 GHz Pentium 4 with 1 GB of RAM, running Linux
2.6.17. For each benchmark, we use the program’s documentation
and examples to run the program with a reasonable conﬁguration.
5.1 Taint Analysis for Server Programs
We evaluate our system with a taint checking policy that prevents
the use of tainted format strings in exploitable functions. This strict
policy is similar to that enforced in the TaintCheck system [37].
Our policy distrusts all inputs that can be under user-control, in-
cluding the ﬁle system and environmental variables. Our policy is
signiﬁcantly stronger than the default “trust everything except net-
work input” policy used by some other systems [37, 39] for servers.
This stronger policy is necessary to detect uses of tainted data that
are cached in the ﬁle system, an actual problem in one of our bench-
marks, as we discuss in Section 5.1.1.
We apply our system to ﬁve commonly-used open source server
programs: pfingerd, muh, wu-ftpd, BIND, and apache. These
programs are, respectively, a ﬁnger daemon, an IRC proxy, an FTP
server, a name server, and a web server. Several are widely de-
ployed and typically run in privileged mode, so their robustness
and integrity are critical.
We use our system to produce a modiﬁed version of each pro-
gram that contains additional code to perform dynamic taint track-
ing.
In our tables, we refer to this version as DDFA. The actual
analysis time, while not negligible, is no worse than four minutes
for apache, our largest benchmark with nearly 67K lines of code,
and thus does not pose a serious obstacle to deployment.
Finally, we note that these programs were selected in part be-
cause our static data ﬂow analysis identiﬁed potential vulnerabili-
ties in them. Our test programs were selected from a suite of open-
source server programs that was previously used for static pro-
gram checking research [23]. For nine other programs in this suite,
our compiler analysis determines that there are no improper uses
of tainted data and therefore no instrumentation whatsoever is re-
quired. These programs include BlackHole, privoxy, sqlite,
and pureftpd, and indeed there are no known applicable tainted-
data attacks against our tested versions in the CVE database. For
these nine programs, our system does not modify the program and
therefore exhibits 0% runtime overhead and 0% code expansion.
Only a system that performs a static interprocedural taint analy-
sis can achieve these overheads. We have chosen to exclude these
nine programs from our results and to instead focus on those pro-
grams that have possible vulnerabilities, but these results neverthe-
less highlight an important advantage of our approach.
Version Exploit Ref
Detected
Program
pfingerd 0.7.8
2.05c
muh
2.6.0
wu-ftpd
4.9.4
bind
NISR16122002B Yes
CAN-2000-0857 Yes
Yes
CVE-2000-0573
CVE-2001-0013
Yes
Table 2: Evaluation of our system’s ability to detect actual attacks. All
attacks are detected successfully.
Program
pfingerd
muh
wu-ftpd
bind
apache
Average Code Expansion
Original
49655
59880
205487
215669
552114
DDFA Code Overhead
49655
0%
1.01%
60488
1.22%
207997
1.90%
219765
0.43%
554514
0.91%
Table 3: The static code expansion required for dynamic taint track-
ing, as measured by compiled binary size (bytes).
5.1.1
Security Evaluation
We ﬁrst evaluate our system’s ability to detect attacks. Four of
our benchmark programs contain known vulnerabilities that are ex-
ploitable. For example, pfingerd improperly trusts hostnames,
while muh does not properly check format strings when reading
or writing log ﬁles. The SITE EXEC format string vulnerability
in wu-ftpd is actually the ﬁrst discovered format string vulnera-
bility [13]. BIND improperly writes requests to syslog when an
authoritative nameserver is malicious. Our particular conﬁguration
of apache (core only without optional modules) does not contain
any known format string vulnerabilities; it is included because our
static analysis was not able to completely eliminate that possibility.
To test whether our system correctly detects the use of tainted
data, we send malicious input to the instrumented programs. Ta-
ble 2 shows the vulnerable programs, shows the vulnerability in
question, and indicates that in each case our system successfully
detects these attacks. In each case, it detects that tainted data is
about to be used improperly and identiﬁes the potentially malicious
data.
The case of muh deserves special attention. The vulnerability ex-
ists because muh writes logged messages verbatim to disk. Later,
when a user requests log information, muh reads the message back
from disk and prints it directly using printf. Thus, if the origi-
nal message contained dangerous format speciﬁers, muh could be
compromised when the message is printed back. If the policy is to
trust local ﬁles, then this attack will go undetected, which can be
a serious problem in servers that cache data on disk. Several taint
tracking systems trust local ﬁles by default [37, 39]; their perfor-
mance when applying our more aggressive policy is unknown but
likely to be worse due to the greater presence of tainted data. Our
system can enforce this stronger policy without fear of incurring
signiﬁcant additional overhead because our interprocedural analy-
sis can frequently prove that most uses of local ﬁle data are safe.
5.1.2 Code Expansion
Because our system adds instrumentation to the source program,
it introduces some static code expansion over unmodiﬁed code. We
measure this expansion by comparing the sizes of the original and
modiﬁed binary executables. Binary code size provides a more ac-
curate measure of code overhead than source code size, because the
Program
pfingerd
muh
wu-ftpd
bind
apache
Average Overhead
Original
3.07s
11.23ms
2.745MB/s
3.580ms
6.048MB/s
3.19s
11.23ms
2.742MB/s
3.566ms
6.062MB/s
DDFA Runtime Overhead
3.78%
0.0%
0.10%
-0.38%
-0.24%
0.65%
Table 4: Runtime overhead for performing dynamic taint tracking on
server programs. This table shows the response time or throughput
overhead for our DDFA system running on a 100mbps ethernet net-
work.
binary code size includes the effects of standard compiler optimiza-
tions.
From Table 3, we see that the average code expansion for our
benchmarks is less than 1%. In several cases, the compiled binary
size does not actually increase because the added code falls in the
padding that gcc adds. To place our results in context, LIFT with
hot path optimizations can at least double the size of the code due to
the need to maintain separate “fast” and “check” copies [39], while
compiler-based systems like GIFT [31] report 30-60% increases in
binary size.
5.1.3 Runtime Overhead
The tracking of data ﬂows incurs a runtime cost. For our set
of server programs, we measure this cost by measuring server re-
sponse time or throughput, as appropriate for the particular pro-
gram.
The pfingerd, muh, and bind servers deal with short re-
quests, so the end user is most directly impacted by increases in
response time. For these programs, we measure the time between
the sending of the request and the receipt of the entire response,
averaged over one hundred requests. On the other hand, wu-ftpd
and apache are used to serve ﬁles of varying sizes, so the pri-
mary metric of concern to end users is throughput (MB/sec). We
measure throughput by downloading ﬁles with sizes uniformly dis-
tributed among 4KB, 8KB, 16KB, and 512KB over one minute.
To avoid local resource contention, our benchmarking client runs
on a different machine from the server, interacting over a local
100mbps Ethernet connection. As shown in Table 4, our solution
has an average overhead of 0.65%. In all instances, the overhead is
lost within the noise. In fact, in three instances, average server per-
formance actually improves by small amounts when we perform
taint tracking. This improvement may be due to differences in
memory layout induced by our runtime system and the resulting
effect on cache performance. As a point of comparison, the pre-
vious fastest compiler-based and dynamically optimized systems
report server application overhead of 3-7% [48] and 6% [39], re-
spectively.
5.2 Taint Analysis for Compute-Bound Appli-
cations
In this section, we evaluate our system’s performance on compute-
bound applications by applying the format string policy to four
SPECint 2000 benchmarks, with all I/O marked as tainted. These
benchmarks were chosen because it was possible to inject realistic
format string vulnerabilities into them, a task that can be challeng-
ing for the other SPECint benchmarks.
In each case, our static
analysis determines that the programs contain no such vulnerabil-
ity. Thus, our true overhead for these examples is 0%.
To study the performance impact that our system would have on
Program Code Expansion Overhead
51.35%
gzip
0.44%
vpr
-0.32%
mcf
0.25%
crafty
Average
12.93%
0.0%
0.0%
0.0%
0.36%
0.09%
Table 5: Runtime overhead for performing dynamic taint tracking on
compute-bound programs. These versions of the SPECint benchmarks
were modiﬁed to introduce a format string vulnerability.
Program
pfingerd
muh
bind
Average
Code Expansion Response time
0%
2.13%
-1.38%
0.25%
0%
2.67%
0.10%
0.92%
Table 6: Servers augmented by our system to guard against ﬁle dis-
closure vulnerabilities exhibit negligible overhead and code expansion.
compute-bound programs that do contain vulnerabilities, we man-
ually insert a vulnerability into each of the benchmarks. To ensure
that these injected vulnerabilities are realistic and representative of
real vulnerabilities, we use the following guidelines in selecting the
locations for the artiﬁcial vulnerabilities. (1) We choose locations
where actual printf/scanf calls are being made, ensuring that
our injected vulnerability appears at a location where it might be
possible. (2) We preferentially choose calls that operate on charac-
ter data, eliminating unrealistic vulnerabilities, such as the use of