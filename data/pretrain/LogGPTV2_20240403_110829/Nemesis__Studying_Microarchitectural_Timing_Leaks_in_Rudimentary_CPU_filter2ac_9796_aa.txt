title:Nemesis: Studying Microarchitectural Timing Leaks in Rudimentary CPU
Interrupt Logic
author:Jo Van Bulck and
Frank Piessens and
Raoul Strackx
Nemesis: Studying Microarchitectural Timing Leaks in
Rudimentary CPU Interrupt Logic
Jo Van Bulck
imec-DistriNet, KU Leuven
PI:EMAIL
Frank Piessens
imec-DistriNet, KU Leuven
PI:EMAIL
Raoul Strackx
imec-DistriNet, KU Leuven
PI:EMAIL
ABSTRACT
Recent research on transient execution vulnerabilities shows that
current processors exceed our levels of understanding. The promi-
nent Meltdown and Spectre attacks abruptly revealed fundamental
design flaws in CPU pipeline behavior and exception handling logic,
urging the research community to systematically study attack sur-
face from microarchitectural interactions.
We present Nemesis, a previously overlooked side-channel at-
tack vector that abuses the CPU’s interrupt mechanism to leak
microarchitectural instruction timings from enclaved execution
environments such as Intel SGX, Sancus, and TrustLite. At its core,
Nemesis abuses the same subtle microarchitectural behavior that
enables Meltdown, i.e., exceptions and interrupts are delayed until
instruction retirement. We show that by measuring the latency
of a carefully timed interrupt, an attacker controlling the system
software is able to infer instruction-granular execution state from
hardware-enforced enclaves. In contrast to speculative execution
vulnerabilities, our novel attack vector is applicable to the whole
computing spectrum, from small embedded sensor nodes to high-
end commodity x86 hardware. We present practical interrupt timing
attacks against the open-source Sancus embedded research proces-
sor, and we show that interrupt latency reveals microarchitectural
instruction timings from off-the-shelf Intel SGX enclaves. Finally,
we discuss challenges for mitigating Nemesis-type attacks at the
hardware and software levels.
CCS CONCEPTS
• Security and privacy → Side-channel analysis and counter-
measures;
KEYWORDS
Controlled-channel; microarchitecture; enclave; SGX; Meltdown
ACM Reference Format:
Jo Van Bulck, Frank Piessens, and Raoul Strackx. 2018. Nemesis: Studying
Microarchitectural Timing Leaks in Rudimentary CPU Interrupt Logic. In
CCS ’18: 2018 ACM SIGSAC Conference on Computer & Communications
Security, Oct. 15–19, 2018, Toronto, ON, Canada. ACM, New York, NY, USA,
18 pages. https://doi.org/10.1145/3243734.3243822
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
CCS ’18, October 15–19, 2018, Toronto, ON, Canada
© 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-5693-0/18/10...$15.00
https://doi.org/10.1145/3243734.3243822
1 INTRODUCTION
Information security is essential in a world with a growing num-
ber of ever-connected embedded sensor nodes, mixed-criticality
systems, and remote cloud computing services. Today’s computing
platforms isolate software components belonging to different stake-
holders with the help of a sizeable privileged software layer, which
in turn may be vulnerable to both logical bugs and low-level vulner-
abilities. In response to these concerns, recent research and industry
efforts developed Protected Module Architectures (PMAs) [45, 66]
to safeguard security-sensitive application components or enclaves
from an untrusted operating system. PMAs enforce isolation and
attestation primitives directly in hardware, or in a small hypervisor,
so as to ensure protected execution with a minimal Trusted Comput-
ing Base (TCB). The untrusted operating system is prevented from
accessing enclaved code or data directly, but continues to manage
shared platform resources such as system memory or CPU time.
Enclaved execution is a particularly promising security paradigm in
that it has been explicitly applied to establish trust in both low-end
embedded microcontrollers [7, 15, 16, 41, 53, 68] as well as in higher-
end desktop and server processors [14, 17, 33, 46, 47, 65]. With the
arrival of the Software Guard eXtensions (SGX) [3, 48] in recent
Intel x86 processors, strong hardware-enforced PMA guarantees
are now available on mainstream consumer hardware.
PMAs pursue a black box view on protected modules. That is, a
kernel-level attacker should only be able to observe input-output
behavior, and is prevented from accessing a module’s private mem-
ory directly. While such interactions are generally well-understood
at the architectural level, including successful TCB verification ef-
forts [19, 39], enclave-internal behavior may still leak through the
CPU’s underlying microarchitectural state. Over the past decade,
microarchitectural side-channels have received considerable atten-
tion from academics [2, 23, 58, 80], but their disruptive real-world
impact only recently became clear with the Meltdown [44], Spec-
tre [40], and Foreshadow [71] attacks that rely on side-channels
to steal secrets from the microarchitectural transient execution
domain. We therefore argue that it is essential for the research
community to deepen its understanding in microarchitectural CPU
behavior and to identify potential side-channel attack vectors. In
this respect, recent research on controlled-channels [79] has shown
that conventional side-channel analysis changes drastically when
PMAs are targeted, for the operating system itself has become an
untrusted agent. The increased attacker capabilities bring about
two major consequences.
First, with an untrusted operating system, an adversary gains
full control over the unprotected part of the application, and over
system events such as interrupts, page faults, cache flushes, sched-
uling decisions, etc. These types of events introduce considerable
noise in traditional cross-application, or even cross-virtual machine
side-channels. Noise is traditionally compensated for with statis-
tical analysis over data acquired from multiple runs of the victim
program. In a controlled-channel setting on the other hand, one
prevailing research line is exploring the possibility of amplifying
conventional side-channels so as to extract sensitive information
in a single run, with limited noise. Recent work on Intel SGX plat-
forms has practically demonstrated such side-channel amplification
for the usual suspects: CPU caches [8, 25, 31, 51, 62] and branch
prediction machinery [18, 42]. These results have prompted Intel to
release an official statement, arguing that “in general, these research
papers do not demonstrate anything new or unexpected” [38].
A second, more profound consequence of the PMA attacker
model, however, is the emergence of an entirely new class of side-
channels that were never considered relevant before. To date only
page table-based attacks [64, 75, 77, 79] have been identified as one
such innovative controlled-channel for high-end MMU-based archi-
tectures. By carefully revoking access rights on protected memory
pages and observing the associated page accesses, an adversar-
ial operating system is able to extract large amounts of sensitive
data (cryptographic keys, full text, and images) from SGX enclaves.
Several authors [13, 20, 43, 67, 70, 74] have since expressed their
concerns on controlled-channel vulnerabilities in a PMA setting.
An important research question therefore is to determine which
novel controlled-channels exist, and to what extent they endanger
the PMA protection model.
This paper contributes to answering this question. We present an
innovative class of Nemesis1 controlled-channel attacks that exploit
subtle timing differences in the rudimentary fetch-decode-execute
operation of programmable instruction set processors. We abuse
the key microarchitectural property that hardware interrupts/faults
are only served upon instruction retirement, after the currently
executing instruction has completed, which can take a variable
amount of CPU cycles depending on the instruction type and the
microarchitectural state of the processor. Where Meltdown-type
“fault latency” attacks [44, 71] exploit this time window in modern
out-of-order processors to transiently leak unauthorized memory
through a microarchitectural covert channel, Nemesis-type inter-
rupt latency attacks abuse a more fundamental observation that
equally affects non-pipelined processors. Namely, that delaying
interrupt handling until instruction retirement introduces a subtle
timing difference that by itself reveals side-channel information
about the interrupted instruction and the microarchitectural state
when the interrupt request arrived. Intuitively, an untrusted operat-
ing system can exploit this timing measurement when interrupting
enclaved instructions to differentiate between secret-dependent pro-
gram branches, or to extract information for different side-channel
analyses (e.g., trace-driven cache [1], address translation [75], or
false dependency [50] timing attacks).
We are the first to recognize the threat caused by instruction
set architectures with variable interrupt latency. Previous PMA
research has overlooked this subtle attack vector, claiming for in-
stance that “timing of external interrupts does not depend on se-
crets within compartments, and does not leak confidential infor-
mation” [20]. We show that Nemesis attacks affect a wide range of
1 From the ancient Greek goddess of retribution who inevitably intervenes to balance
out good and evil; an inescapable agent much like a pending interrupt request.
security architectures, covering the whole computing spectrum. In
this, we are the first to identify a remotely exploitable microarchitec-
tural side-channel vulnerability that is both applicable to embedded,
as well as higher-end enclaved execution environments.
Summarized, the main contributions of this paper are:
• We leverage interrupt latency as a novel, non-conventional
side-channel to extract information from enclaved applica-
tions, thereby advancing microarchitectural understanding.
• We present the first controlled-channel attack vector for
embedded enclaved execution processors, and extract full
application secrets in practical Sancus attack scenarios.
• We provide clear evidence that interrupt latency reveals
microarchitectural instruction timings on modern Intel SGX
processors, and illustrate Nemesis’s increased instruction-
granular potential in macrobenchmark evaluation scenarios.
• We explain how naive hardware-level defense strategies can-
not defend against advanced Nemesis-style interrupt attack
variants, demonstrating the consequential impact of our find-
ings for provably side-channel resistant processors.
Our attack framework and evaluation scenarios are available as
free software at https://github.com/jovanbulck/nemesis.
2 BACKGROUND AND BASIC ATTACK
We first refine the threat model and the class of security architec-
tures affected by our side-channel. Next, we explain how interrupt
latency can be leveraged in ideal conditions to extract sensitive
data from secure enclaves.
2.1 Attacker Model and Assumptions
The adversary’s goal is to derive information regarding the internal
state of an enclaved application. In this respect, trusted computing
solutions including Intel SGX have been explicitly put forward to
protect sensitive computations on an untrusted attacker-owned
platform, both in an untrustworthy cloud environment [6, 61],
as well as to enforce enterprise right management on consumer
hardware [32, 56]. Analogous to previous enclaved execution at-
tacks [30, 42, 75, 79], we therefore consider an adversary with
(i) access to the (compiled) source code of the victim application,
and (ii) full control over the Operating System (OS) and unpro-
tected application parts. This means she can modify BIOS options,
load kernel drivers, configure hardware devices such as timers,
and control scheduling decisions. Note that although PMAs can be
leveraged [26, 61] to protect the confidentiality of sensitive code,
this is not the default case in the security architectures analyzed in
this work and for many of the PMA use cases [6, 32, 66].
At the architectural level, we assume the untrusted OS can se-
curely interrupt and resume enclaves. Such interruptible isolated ex-
ecution is supported by a wide range of mature embedded [7, 15, 41]
as well as higher-end [14, 17, 33, 48, 65] PMAs that employ a trusted
security monitor to preserve the confidentiality and integrity of
a module’s internal state in the presence of asynchronous inter-
rupt events. In this paper we focus exclusively on hardware-level
security monitors, but our timing channel may also be relevant
for architectures where enclave interruption proceeds through a
small trusted software layer [7, 14, 19, 33]. We assume that enclaves
can be interrupted repeatedly within the same run, and for the
Fetch
Decode
Execute
no
Jump?
no
PC++
yes
IRQ?
yes
PC = IDT[irq]
Secure IRQ logic
Figure 1: A processor fetches, decodes, and executes the in-
struction referred by the Program Counter (PC) register.
CLK
INS
IRQ
TSC
INS
IRQ
TSC
JZ
x
JZ
x
INST1
IRQ logic
ISR
x+1
x+2
x+2+1
. . .
x+y+2
2 execute cycles
hardware latency
x+y+3
∆TSC
INST2
IRQ logic
ISR
x+1
x+2
3 execute cycles
x+3
x+3+1
. . .
x+y+3
x+y+4
hardware latency
Intel SGX application scenarios, can be made to process the same
secret-dependent input repeatedly over multiple invocations.
Importantly, in contrast to previous controlled-channel attacks
referenced above, our attack vector does not necessarily require
advanced microarchitectural CPU features, such as paging, caching,
branch prediction, or out-of-order execution. Instead, Nemesis-
type interrupt timing attacks only assume a generic stored program
computer with a multi-cycle instruction set, where each individual
instruction is uninterruptible (i.e., executes to completion). This
is the most widespread case for major embedded (e.g., TI MSP430,
Atmel AVR) as well as higher-end (e.g., x86, openRISC, RISC-V)
instruction set architectures.
2.2 Fetch-Decode-Execute Operation
Figure 1 summarizes the basic operational process of a CPU, tradi-
tionally referred to as the fetch-decode-execute operation. A dedi-
cated Program Counter (PC) register holds the address of the next
instruction to fetch from memory. PC is automatically incremented
after every instruction in the program, and can be explicitly changed
by means of jump instructions. Hardware devices furthermore have
the ability to halt execution of the current program by means of
Interrupt Requests (IRQs) that notify the processor of some asyn-
chronous external event that requires immediate attention. When-
ever the current instruction has completed, before fetching the next
one, the processor checks if there are IRQs pending. If so, the PC is
loaded from a predetermined location in the Interrupt Descriptor
Table (IDT) that holds the address of the corresponding Interrupt
Service Routine (ISR). Typical processor architectures only take
care of storing the minimal execution context (e.g., PC and sta-
tus register) before vectoring to the ISR. The trusted OS interrupt
handling code then stores any remaining CPU registers as needed.
However, when interrupting a protected module, the PMA hard-
ware is responsible to securely store and clear all CPU registers,
which is abstracted in the “secure IRQ logic” block of Fig. 1.
While the simplified fetch-decode-execute description above is
representative for a class of low-end CPUs such as the TI MSP430
[69], optimizations found in modern higher-end processors consid-
erably increase the complexity. A pipelined architecture improves
throughput by parallelizing the fetch-decode-execute stages of sub-
sequent instructions. In case of a complex instruction set such as
Intel x86 [13, 36], individual instructions are first split into smaller
micro-ops during the decode stage. Thereafter, an out-of-order en-
gine schedules the micro-ops to available execution units, which