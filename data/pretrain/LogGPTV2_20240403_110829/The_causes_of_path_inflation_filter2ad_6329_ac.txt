the reference distance between city pairs. We map the reference
distance into bins – distances less than 20 ms are mapped to 5 ms
bins (0–5, 5–10, 10–15, and 15–20); distances between 20 and 60
ms are mapped to 10 ms bins (20–30, 30–40, 40–50, 50–60); and
longer distances are mapped to 20 ms bins. We use this binning in
all similar graphs in this paper. It helps us to study the variation
of inﬂation with the reference cost, as well as provide a sense of
relative inﬂation. We found that the results are robust to bin sizes as
long as the bins are small enough to expose effects that are present
in a small latency range, and large enough to have sufﬁcient data
points to permit meaningful statistical measures.
The graph plots the median, mean, and 95th percentile of data
points in each bin. We see that paths between most pairs of ge-
ographically close cities are inﬂated only by a small amount, in-
dicating that these cities are usually connected by short paths. The
jump around 40 ms represents cities that are on different continents;
such cities are forced to reach each other by one of a few inter-
continental links that exist in the intra-domain topology. The right
end of the graph represents city pairs in Europe and Asia/Australia
that have to traverse the USA. Since we ﬁltered out city pairs that
were not seen together in a trace, this is not an artifact of most of our
vantage points being in the USA; our data contained intra-domain
paths that went from Europe to Asia through the USA, observed
from European vantage points.
Topological inﬂation among the tier-1 ISPs was higher compared
to the other ISPs; the mean inﬂation was 4 ms for the former and
2 ms for the latter. This is largely a result of the tier-1 ISPs having
more POPs over a larger geographic area, which makes it more dif-
ﬁcult for them to connect all pairs with a good set of links. We
observed no signiﬁcant correlation between topological inﬂation
and the ISP’s geographic presence, suggesting that ISPs use sim-
ilar topological designs on various continents.
4.2
Inferring Intra-domain Routing Policy
We next turn to the task of inferring intra-domain routing pol-
icy. We discovered that many paths observed in our dataset deﬁed
simple models based on hop count and link latency. Moreover,
we did not have access to other factors, such as link capacity, that
may inﬂuence intra-domain routing policy. Hence, instead of try-
ing to guess the policy intent of each individual ISP, we sought a
universally applicable model of intra-domain routing. We assumed
that the routing is weighted shortest path with some unknown set
of edge weights. Since we are dealing with POP-level topologies,
these weights are different from the router-level link weights that
ISPs use, but they serve a similar purpose.
In this section, we
outline a constraint-based approach to infer these weights; the ap-
proach is described in detail in our extended abstract [18].
Our approach takes the intra-domain topology and the set of
paths observed over it as input, yielding edge weights that are con-
sistent with the observed paths. The approach is based on the ob-
servation that the weight of an observed path (the sum of the edge
weights) must be less than or equal to that of any alternate path
between the same pair of nodes; otherwise, that path would have
been preferred. This observation is translated into a set of con-
straints. For instance, if a path ABC was observed between A
and C, and ADEC is an alternate path, we set up the constraint
wAB + wBC ≤ wAD + wDE + wEC. Similar constraints are
set up for all observed and alternate paths, and the solution to the
constraint system yields a set of edge weights that model observed
routing.
Some paths in the dataset may have been observed due to tran-
sient events such as failures. In the basic scheme described above,
such paths may lead to an inconsistent constraint system. We use
constraint hierarchies [4] to account for this possibility. We as-
sociate an error variable with every observed path and set up con-
straints such that the error variable represents the weight of the path
above the least weight path. In the example above, the constraint
becomes wAB + wBC − eABC ≤ wAD + wDE + wEC.
Since the set of weights that model a given routing pattern is
not unique, we also include constraints that minimize the devia-
tion of the weight of an edge from its latency. The corresponding
constraint is wAB − |e(cid:1)
AB| = latAB. It assumes that the latency
and weight of an edge are related, and all things being equal, the
weight increases with latency. This extension was not present in
the previous paper [18].
We solve the constraint system while minimizing the sum of pri-
oritized error variables [21]. The priority of a path’s error variable
is the number of times the path was seen, which means that tran-
sient paths are given very low priority. Edge error variables have
very low priority to favor agreement with observed routing over
similarity to link latency. Of the multiple weight settings that de-
scribe routing, we obtain the one that reﬂects the best correlation
of weights and latencies.
We evaluated our inferred weights for their ability to characterize
intra-domain routing in comparison to a pure latency-based model,
in which an edge’s latency is used as its weight. The left graph in
Figure 4 shows, for each ISP, the percentage of observed paths that
were least weight compared to the percentage that were shortest
latency. The ISPs are sorted based on the success of weights in
describing their routing. For many ISPs, weights describe routing
much more closely.
The inferred weights not only ﬁt the observed paths well, they
also predict paths between cities for which no path was observed.
We evaluated this by using half of our dataset to infer weights and
analyzing how well these weights describe the complete dataset.
To halve the dataset, we randomly removed all the paths between
t
i
f
t
a
h
t
s
h
t
a
p
d
e
v
r
e
s
b
o
f
o
%
100
80
60
40
20
0
t
i
f
t
a
h
t
s
h
t
a
p
d
e
v
r
e
s
b
o
f
o
%
100
80
60
40
20
0
weights
latencies
20
40
60
ISP index
all paths
half paths
20
40
60
ISP index
Figure 4: The success of the inferred weights in describing the
observed routing. Each point along the x-axis corresponds to an
ISP. The y-axis values depict the percentage of observed paths
that were least cost. The left graph compares weights with la-
tencies, and the right graph compares the weights inferred us-
ing the complete dataset with those inferred using half of it.
half of the city pairs. Removing individual paths would have just
reduced the count of observations. The right graph in Figure 4 com-
pares the success of the weights in describing the complete dataset
when inferred using the complete dataset versus using only half of
it. The weights inferred using half of the dataset predict routing
nearly as well. We conclude that the inferred weights provide us
with a concise and accurate model of ISP routing that is predictive
beyond the paths present in the dataset used to infer it.
4.3 Impact of Intra-domain Routing Policy
We now analyze how intra-domain policy contributes to path in-
ﬂation by measuring the inﬂation of least weight paths over shortest
latency (geographic distance) paths. As in Section 4.1, we exclude
networks that employ virtual circuit technologies and city pairs not
observed together in a trace.
Figure 5 shows the results of the analysis. The overall median,
mean, and 95th percentile were 0, 1, and 4 ms. The CDF on the
left shows that 80% of the intra-domain paths are not inﬂated at all.
This suggests that intra-domain trafﬁc engineering is not inconsis-
tent with latency-sensitive routing; ISPs try to minimize latency
while tweaking weights to balance trafﬁc across backbone links.
The graph on the right plots inﬂation as a function of the shortest
path latency using the binning described in Section 4.1. (The cost
of the shortest path is used for binning.) Additive inﬂation rises as
the shortest path latency increases. This makes intuitive sense, as
there are more acceptable paths between these cities to pick from,
allowing more opportunity for trafﬁc engineering. Closer investiga-
tion of paths beyond 50 ms revealed that most appear to be caused
by attempts to balance load across two or more transcontinental
links. The decrease towards the right end of the graph is an arti-
fact of having very few city pairs in that bin, most of which take an
almost straight path through the topology.
As with topology, we found differences between tier-1 and other
networks, but not between ISPs in different parts of the world.
The inﬂation from intra-domain routing policy was higher for tier-1
ISPs; the mean was 1.2 ms compared to 0.3 ms for the other net-
works. This is most likely because tier-1 networks are bigger and
have more redundant paths that allow trafﬁc engineering.
5. PEERING FACTORS
In this section, we study the additional inﬂation that occurs when
the source and destination connect to adjacent ISPs. First, we con-
sider the peering topology – the union of all peering points between
two ISPs. Geographically spread peering links provide more direct
paths. Second, we consider the peering policy – the selection of
which peering link to use to reach a destination.
s
h
t
a
p
f
o
n
o
i
t
c
a
r
f
e
v
i
t
a
l
u
m
u
C
1.0
0.8
0.6
0.4
0.2
0.0
95%
mean
median
)
s
m
(
n
o
i
t
a
l
f
n
i
e
v
i
t
i
d
d
A
10
8
6
4
2
0
0
5
10
15
20
Additive inflation (ms)
0
50
100
Latency of shortest path (ms)
Figure 5: Path inﬂation due to intra-domain routing policy,
when compared to shortest latency paths. The left graph shows
the CDF of additive inﬂation, and the right one shows additive
inﬂation as function of the latency of the shortest path.
s
h
t
a
p
f
o
n
o
i
t
c
a
r
f
e
v
i
t
a
l
u
m
u
C
1.0
0.8
0.6
0.4
0.2
0.0
1 ISP
2 ISP
0
5
10
15
20
25
Additive inflation (ms)
2 ISP 95%
1 ISP 95%
2 ISP median
1 ISP median
)
s
m
(
n
o
i
t
a
l
f
n
i
e
v
i
t
i
d
d
A
40
30
20
10
0
20
40
0
Latency of direct link (ms)
60
80
Figure 6: The cost of crossing an ISP boundary compared to
intra-domain paths. The left graph shows the CDF of additive
inﬂation over a hypothetical direct link between the city pair
for paths that cross an ISP boundary (2 ISP) and intra-domain
paths (1 ISP). The right graph shows the variation of median
and 95th percentile inﬂation with the baseline hypothetical dis-
tance between the city pair.
5.1
Impact of Peering Topology
We measure the impact of peering topology by comparing paths
that traverse two ISPs to those that stay within the same ISP. To
isolate peering topology, we select optimal paths that cross two
ISPs – the intra-domain portions use least-weight paths from the
last section, but the peering link is chosen to minimize overall path
latency. Our traceroutes, however, may not have exposed some
optimal peering links that exist in the topology. To limit the result-
ing over-estimation of path inﬂation due to topology, we exclude
cities in the upstream ISP from which we observed no path to the
downstream ISP. Although the true optimal peering link may not
be known, this exclusion ensures that at least chosen peering links
are present.
The left graph of Figure 6 shows the CDFs of inﬂation compared
to a hypothetical direct link for both intra-domain (1 ISP) paths
and paths that cross a single ISP boundary (2 ISP). The difference
between the two is noticeable but small, suggesting the presence of
many peering links between adjacent ISPs. More interesting effects
appear in the right plot, which shows the variation of inﬂation with
the distance between source and destination. Nearby city pairs can
have signiﬁcant inﬂation if packets must travel from the source to
a peering point and back to the destination.
Inﬂation from peering topology is least between networks with
more peering points, such as tier-1 ISPs and networks in the same
continent. Crossing boundaries between two tier-1 ISPs causes less
inﬂation than when a smaller network is involved; the mean inﬂa-
tion compared to a hypothetical direct link was 4 ms between tier-1
ISPs and 7 ms otherwise. Crossing boundaries between two ISPs
in the same continent is less costly than that between ISPs located
s
r
i
a
p
P
S
I
f
o
n
o
i
t
c
a
r
f
e
v
i
t
a
l
u
m
u
C
1.0
0.8
0.6
0.4
0.2
0.0
0.2
1.0
0.0
Fraction paths routed "early"
0.4
0.6
0.8
Figure 7: The prevalence of the early-exit routing policy. For
those ISP pairs where we observed more than one peering link,
this graph shows the fraction of paths we observed that were
routed to the earliest exit. The median is 57%, meaning that
most ISP pairs choose the early exit most of the time.
in different continents (a mean of 5 ms in the former, and 9 ms in
the latter).
In summary, we found that the peering topology does not inﬂate
paths signiﬁcantly. We next study the policies that govern the selec-
tion of peering points, then quantify how successful those policies
are in ﬁnding short paths.
5.2 Characterizing Peering Policy
Since the peering topology between ISPs appears to be sufﬁcient
to support paths with little inﬂation in latency, the next potential
source of inﬂation is routing policy over these links. For example,
path inﬂation occurs when the selected peering point is to the east,