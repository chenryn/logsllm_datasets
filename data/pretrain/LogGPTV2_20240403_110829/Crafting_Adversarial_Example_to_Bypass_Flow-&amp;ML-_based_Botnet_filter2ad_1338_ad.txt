has its own unique features, so the flows of different families also
differ in terms of certain characteristics. For example, the ppf of
Trickbot is 8.66, while that of HTBot is 28.34. Therefore, we guess
that the influences produced by different actions should be different
for each family, so each botnet family’s dominant actions should
202Crafting Adversarial Example to Bypass Flow-&ML- based Botnet Detector via RL
RAID ’21, October 6–8, 2021, San Sebastian, Spain
Table 6: Dominant action of the BotCatcher-SARSA agent
Action No. Menti Rbot Murio Virut Miuref Neris HTBot Dridex Trickbot Geodo
0.06
0.05
0.01
0.07
0.08
0.03
0.01
0.27
0.06
0.02
0.15
0.01
0.16
0.04
0.00
0.06
0.07
0.06
0.00
0.00
0.21
0.19
0.12
0.21
0.00
0.00
0.08
0.00
0.03
0.00
0.03
0.09
0.02
0.02
0.26
0.00
0.01
0.35
0.01
0.09
0.03
0.04
0.02
0.00
0.02
0.14
0.04
0.08
0.01
0.01
0.00
0.55
0.05
0.01
0.08
0.00
0.06
0.01
0.02
0.00
0.00
0.31
0.00
0.34
0.00
0.00
0.06
0.00
0.19
0.00
0.00
0.42
0.00
0.00
0.00
0.00
0.02
0.32
0.02
0.07
0.15
0.00
0.02
0.00
0.00
0.01
0.32
0.01
0.19
0.01
0.00
0.12
0.00
0.00
0.00
0.01
0.03
0.29
0.49
0.01
0.00
0.02
0.02
0.04
0.00
0.01
0.00
0.10
0.20
0.01
0.07
0.02
1
2
3
4
5
6
7
8
9
10
11
12
13
14
0.51
0.01
0.01
0.00
0.00
0.09
0.01
0.02
0.00
0.00
0.00
0.20
0.07
0.07
0.29
0.03
0.01
0.01
0.03
0.01
0.00
0.13
0.02
0.01
0.04
0.01
0.12
0.29
Storm Waledac
0.01
0.01
0.06
0.01
0.01
0.82
0.01
0.03
0.01
0.01
0.01
0.01
0.01
0.01
0.06
0.06
0.28
0.04
0.02
0.02
0.02
0.01
0.01
0.01
0.24
0.08
0.03
0.12
be different. To test this hypothesis, during the test, we record the
action list taken by the agent and count the frequency of each action.
Table 6 shows the result under the BotCatcher-SARSA instance,
where the action number corresponds to that described in section 3.
From Table 6, we can find that there are large differences in the
distributions and the dominant actions of different families, and
these are often related to the characteristics and main functions of
different family flows.
Taking Rbot and Menti family as examples, by statistics, we
obtain that the median of the Rbot family’s duration is 9.02 s, while
that of the Menti family is 2.91 s. At the same time, we can see
from Table 6 that the action chanдetimestamp’s impact on the Rbot
samples (0.02) is significantly less than that on the Menti samples
(0.51). That is, family flows with short durations may be affected
more by the chanдetimestamp action than family flows with long
durations. Therefore, we determine that the influences of actions on
different families are closely related to the statistical characteristics
or image characteristics of each family.
that can mislead the detector by exploring the feature set that the
detector depending on to add perturbations to these features in a
targeted manner. Second, the current actions have a large impact
on the botnet flow, and we could reduce the perturbations through
an iterative method.
We believe the framework proposed in this paper can promote
the research of adversarial botnet flow examples and have a positive
impact on the botnet detection field.
ACKNOWLEDGMENTS
This work is supported by the Youth Innovation Promotion Associ-
ation CAS (No.2019163), the National Natural Science Foundation
of China (No.61902396), the Strategic Priority Research Program
of Chinese Academy of Sciences (No. XDC02040100), the Key Lab-
oratory of Network Assessment Technology at Chinese Academy
of Sciences and Beijing Key Laboratory of Network security and
Protection Technology.
6 CONCLUSION
In this paper, we propose a general RL-based framework to craft ad-
versarial botnet flow examples,so as to launch black box adversarial
attacks against ML-based botnet flow detectors.
To ensure that the original malicious functions of the botnet flow
will not be affected when modifying the botnet flow, we design
an action space with 14 functionality-preserving actions. These
actions can change some important transport layer characteristics
but will not affect the application layer information that contains
malicious functions. We select 14 botnet families to build a new
botnet dataset for evaluating our method. Through experiments,
we prove that ML-based botnet detectors are indeed susceptible to
adversarial attacks, and our system can obtain considerable evasion
rates for different botnet detection models with fewer queries.
Although we achieve remarkable performance, our methods can
be improved in some ways. First, we can explore additional actions
REFERENCES
[1] 2008. https://en.wikipedia.org/wiki/Conficker
[2] 2008. https://en.wikipedia.org/wiki/Gh0st_RAT
[3] 2011. SplitCap. https://www.netresec.com/?page=SplitCap.
[4] Abdullah Al-Dujaili, Alex Huang, Erik Hemberg, and Una-May O’Reilly. 2018.
Adversarial deep learning for robust detection of binary encoded malware. In
2018 IEEE Security and Privacy Workshops (SPW). IEEE, 76–82.
[5] Manos Antonakakis, Tim April, Michael Bailey, Matt Bernhard, Elie Bursztein,
Jaime Cochran, Zakir Durumeric, J. Alex Halderman, Luca Invernizzi, Michalis
Kallitsis, Deepak Kumar, Chaz Lever, Zane Ma, Joshua Mason, Damian Menscher,
Chad Seaman, Nick Sullivan, Kurt Thomas, and Yi Zhou. 2017. Understanding the
Mirai Botnet. In 26th USENIX Security Symposium (USENIX Security 17). USENIX
Association, Vancouver, BC, 1093–1110. https://www.usenix.org/conference/
usenixsecurity17/technical-sessions/presentation/antonakakis
[6] Giovanni Apruzzese and Michele Colajanni. 2018. Evading botnet detectors
based on flows and random forest with adversarial samples. In 2018 IEEE 17th
International Symposium on Network Computing and Applications (NCA). IEEE,
1–8.
[7] Shumeet Baluja and Ian Fischer. 2018. Learning to Attack: Adversarial Transfor-
mation Networks.. In AAAI, Vol. 1. 3.
[8] Yoshua Bengio, Pascal Lamblin, Dan Popovici, and Hugo Larochelle. 2007. Greedy
layer-wise training of deep networks. In Advances in neural information processing
203RAID ’21, October 6–8, 2021, San Sebastian, Spain
Wang and Liu, et al.
[33] Matthias Plappert. 2016. keras-rl. https://github.com/keras-rl/keras-rl.
[34] Shahbaz Rezaei and Xin Liu. 2019. Deep learning for encrypted traffic classifica-
tion: An overview. IEEE communications magazine 57, 5 (2019), 76–81.
[35] M. Rigaki and S. Garcia. 2018. Bringing a GAN to a Knife-Fight: Adapting Malware
Communication to Avoid Detection. In 2018 IEEE Security and Privacy Workshops
(SPW). 70–75. https://doi.org/10.1109/SPW.2018.00019
[36] Markus Ring, Daniel Schlör, Dieter Landes, and Andreas Hotho. 2018. Flow-based
Network Traffic Generation using Generative Adversarial Networks. Computers
& Security 82 (12 2018). https://doi.org/10.1016/j.cose.2018.12.012
[37] Sherif Saad, Issa Traore, Ali Ghorbani, Bassam Sayed, David Zhao, Wei Lu, John
Felix, and Payman Hakimian. 2011. Detecting P2P botnets through network
behavior analysis and machine learning. In 2011 Ninth annual international
conference on privacy, security and trust. IEEE, 174–180.
[38] Elizabeth Stinson and John C Mitchell. 2008. Towards Systematic Evaluation of
the Evadability of Bot/Botnet Detection Methods. WOOT 8 (2008), 1–9.
[39] Richard S Sutton and Andrew G Barto. 2018. Reinforcement learning: An intro-
duction. MIT press.
[40] Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
Ian Goodfellow, and Rob Fergus. 2013. Intriguing properties of neural networks.
arXiv preprint arXiv:1312.6199 (2013).
[41] Pablo Torres, Carlos Catania, Sebastian Garcia, and Carlos Garcia Garino. 2016.
An analysis of recurrent neural networks for botnet detection behavior. In 2016
IEEE biennial congress of Argentina (ARGENCON). IEEE, 1–6.
[42] Wei Wang, Ming Zhu, Xuewen Zeng, Xiaozhou Ye, and Yiqiang Sheng. 2017. Mal-
ware traffic classification using convolutional neural network for representation
learning. In 2017 International Conference on Information Networking (ICOIN).
IEEE, 712–717.
[43] Di Wu, Binxing Fang, Xiang Cui, and Qixu Liu. 2018. BotCatcher:Botnet detection
system based on deep learning. Infocomm-journal 39, 8 (2018), 18–28.
[44] Xiapu Luo, E. W. W. Chan, and R. K. C. Chang. 2008. TCP covert timing channels:
Design and detection. In 2008 IEEE International Conference on Dependable Systems
and Networks With FTCS and DCC (DSN). 420–429. https://doi.org/10.1109/DSN.
2008.4630112
systems. 153–160.
[9] Battista Biggio, Igino Corona, Davide Maiorca, Blaine Nelson, Nedim Šrndić,
Pavel Laskov, Giorgio Giacinto, and Fabio Roli. 2013. Evasion attacks against
machine learning at test time. In Joint European conference on machine learning
and knowledge discovery in databases. Springer, 387–402.
[10] Leyla Bilge, Davide Balzarotti, William Robertson, Engin Kirda, and Christopher
Kruegel. 2012. Disclosure: detecting botnet command and control servers through
large-scale netflow analysis. In Proceedings of the 28th Annual Computer Security
Applications Conference. 129–138.
[11] Wieland Brendel, Jonas Rauber, and Matthias Bethge. 2017. Decision-based
adversarial attacks: Reliable attacks against black-box machine learning models.
arXiv preprint arXiv:1712.04248 (2017).
[12] Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schul-
man, Jie Tang, and Wojciech Zaremba. 2016. Openai gym. arXiv preprint
arXiv:1606.01540 (2016).
[13] Nicholas Carlini and David Wagner. 2017. Towards evaluating the robustness
of neural networks. In 2017 ieee symposium on security and privacy (sp). IEEE,
39–57.
[14] Hung Dang, Yue Huang, and Ee-Chien Chang. 2017. Evading classifiers by
morphing in the dark. In Proceedings of the 2017 ACM SIGSAC Conference on
Computer and Communications Security. 119–133.
[15] Sukhpreet Singh Dhaliwal, Abdullah-Al Nahid, and Robert Abbas. 2018. Effective
intrusion detection system using XGBoost. Information 9, 7 (2018), 149.
[16] Jérôme François, Shaonan Wang, Thomas Engel, et al. 2011. BotTrack: tracking
botnets using NetFlow and PageRank. In International Conference on Research in
Networking. Springer, 1–14.
[17] Sebastian Garcia, Martin Grill, Jan Stiborek, and Alejandro Zunino. 2014. An
empirical comparison of botnet detection methods. computers & security 45
(2014), 100–123.
[18] Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. 2014. Explaining and
harnessing adversarial examples. arXiv preprint arXiv:1412.6572 (2014).
[19] Kathrin Grosse, Nicolas Papernot, Praveen Manoharan, Michael Backes, and
Patrick McDaniel. 2017. Adversarial examples for malware detection. In European
Symposium on Research in Computer Security. Springer, 62–79.
[20] Guofei Gu, Roberto Perdisci, Junjie Zhang, and Wenke Lee. 2008. Botminer:
Clustering analysis of network traffic for protocol-and structure-independent
botnet detection. (2008).
[21] Weiwei Hu and Ying Tan. 2017. Generating adversarial malware examples for
black-box attacks based on gan. arXiv preprint arXiv:1702.05983 (2017).
[22] Bojan Kolosnjaji, Ambra Demontis, Battista Biggio, Davide Maiorca, Giorgio
Giacinto, Claudia Eckert, and Fabio Roli. 2018. Adversarial malware binaries:
Evading deep learning for malware detection in executables. In 2018 26th European
Signal Processing Conference (EUSIPCO). IEEE, 533–537.
[23] Satoshi Kondo and Naoshi Sato. 2007. Botnet traffic detection techniques by C&C
session classification using SVM. In International Workshop on Security. Springer,
91–104.
[24] Alexey Kurakin, Ian Goodfellow, and Samy Bengio. 2016. Adversarial machine
learning at scale. arXiv preprint arXiv:1611.01236 (2016).
[25] Zilong Lin, Yong Shi, and Zhi Xue. 2019.
versarial Networks for Attack Generation against
arXiv:1809.02077 [cs.CR]
IDSGAN: Generative Ad-
Intrusion Detection.
[26] Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A Rusu, Joel Veness,
Marc G Bellemare, Alex Graves, Martin Riedmiller, Andreas K Fidjeland, Georg
Ostrovski, et al. 2015. Human-level control through deep reinforcement learning.
Nature 518, 7540 (2015), 529–533.
[27] Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Omar Fawzi, and Pascal
Frossard. 2017. Universal adversarial perturbations. In Proceedings of the IEEE
conference on computer vision and pattern recognition. 1765–1773.
[28] Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal Frossard. 2016.
Deepfool: a simple and accurate method to fool deep neural networks. In Proceed-
ings of the IEEE conference on computer vision and pattern recognition. 2574–2582.
[29] Carlos Novo and Ricardo Morla. 2020. Flow-Based Detection and Proxy-Based
Evasion of Encrypted Malware C2 Traffic. In Proceedings of the 13th ACM
Workshop on Artificial Intelligence and Security (Virtual Event, USA) (AISec’20).
Association for Computing Machinery, New York, NY, USA, 83–91.
https:
//doi.org/10.1145/3411508.3421379
[30] Nick Pantic and Mohammad I. Husain. 2015. Covert Botnet Command and
Control Using Twitter (ACSAC 2015). Association for Computing Machinery,
New York, NY, USA, 10 pages. https://doi.org/10.1145/2818000.2818047
[31] Nicolas Papernot, Patrick McDaniel, Ian Goodfellow, Somesh Jha, Z Berkay
Celik, and Ananthram Swami. 2017. Practical black-box attacks against machine
learning. In Proceedings of the 2017 ACM on Asia conference on computer and
communications security. 506–519.
[32] Nicolas Papernot, Patrick McDaniel, Somesh Jha, Matt Fredrikson, Z Berkay Celik,
and Ananthram Swami. 2016. The limitations of deep learning in adversarial
settings. In 2016 IEEE European symposium on security and privacy (EuroS&P).
IEEE, 372–387.
204