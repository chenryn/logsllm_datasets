The Psychology of Computer Insecurity
Peter Gutmann
University of Auckland
Why can’t users get security right?
Users are idiots
• Developers build security applications
• Users apply them incorrectly
• Users are idiots
• QED
Why can’t users get security right?
OK, so users are irrational
Definition: “Rational”
• How geeks wish that users would behave
Definition : “Irrational”
• ¬ ( How geeks wish that users would behave )
Users are “irrational” simply because they don’t behave in 
the manner arbitrarily tagged “rational” that’s defined as 
“How users should be using my software, dammit!”
• This type of “rational” behaviour does sometimes exist… 
in people with psychiatric disorders
• (Later slides will go into this in more detail)
Why can’t users get security right? (ctd)
The field of psychology provides a great deal of insight 
into how people deal with security, but this resource is 
rarely used
The heavenly laws of logic and probability rule the realm of 
sound reasoning: psychology is assumed to be irrelevant.  
Only if mistakes are made are psychologists called in to 
explain how wrong-wired human minds deviate from these 
laws […] Many textbooks present first the laws of logic and 
probability as the standard by which to measure human 
thinking, then data about how people actually think.  The 
discrepancy between the two makes people appear to be 
irrational
— Gerd Gigerenzer, 
“Adaptive Thinking: Rationality in the Real World”
How Users Make Decisions
Economic decision-making model (Bayesian decision-
making-model) is based on standard economic thinking
• Goes back to (at least) John von Neumann’s work on game 
theory in the 1940s
Assumes that people always know what they want and will 
choose the optimal course for getting it
[This model] took its marching orders from standard American 
economics, which assumes that people always know what 
they want and choose the optimal course of action for getting it
— Baruch Fischhoff, 
“Decision making in complex systems”
How Users Make Decisions (ctd)
The formalisation of this model, Subjective Expected 
Utility (SEU) theory, makes the following assumptions 
about the decision-making process
1. The decision-maker has a utility function that allows them to 
rank their preferences based on future outcomes
2. The decision-maker has a full and detailed overview of all 
possible alternative strategies
3. The decision-maker can estimate the probability of 
occurrence of outcomes for each alternative strategy
4. The decision-maker will choose between alternatives based 
on their subjective expected utility
How Users Make Decisions (ctd)
To apply the SEU model, execute the following algorithm
for each possible decision alternative
x = all possible consequences of making a 
decision (which includes recursive 
evaluation of any carry-on effects);
p(x) = quantitative probability for x;
U(x) = subjective utility of each 
consequence;
p(x) × U(x) = probability multiplied by 
subjective utility;
SEU total =   p(xi) × U(xi);
n
i 0
SEU Example
Certificate dialog designed for SEU-based decision making
SEU Example
Case study: Evaluate the possibility of a server
misconfiguration
SEU Example (ctd)
Can evaluate this based on an evaluation in turn of
• The competence of the remote system’s administrators
• The chances that they’ve made an error
• The chances of a software bug
• …
Assign probabilities and utilities to each of these
• Competence of admins = 0.6
• Subjective utility = 0.85
• …
SEU Example (ctd)
Assign weights to other factors
• Risk of credit card info being phished/misused
• Risk of identity theft
• … other negative outcomes …
• Mitigating factors like credit card consumer protection 
measures
• Intangible factors like the satisfaction of making a purchase
– (Emotional trauma of not making a purchase if it’s 
someone’s birthday)
(Rather lengthy and tedious, particularly since it’s an 
arbitrarily recursive process)
SEU Example (ctd)
Evaluate the sum total to get the selective expected utility 
for this option
• Then repeat for all other possible options
Finally, pick the option with the highest subjective 
expected utility value
SEU Example (ctd)
There was a tiny 
flaw in the plan
What was that, sir?
It was bollocks
Fixing the SEU Model
This method of decision-making requires total omniscience
• This is a quality that’s generally lacking in humans
OK, so we’ll patch the model by introducing the concept of 
stopping rules
• Bail out when it’s obvious that there’s no (cost-effective) 
benefit to going any further
Fixing the SEU Model (ctd)
How do we decide when to stop?
• Use the SEU model to tell us
Oops
• The stopping-rule patch attempts to model limited 
search by assuming total omniscience
If stopping rules were practical, you wouldn’t be 
reading this but would be in Las Vegas applying 
the stopping rule “Stop playing just before you 
start losing”
How Users Really Make Decisions
Two approaches to determining how things really work
1. Empirical evaluation
•
Examine what users do in practice
2. Conceptual modelling
•
Take a set of conceptual models and see which one best 
approximates reality
How Users Really Make Decisions (ctd)
In the 1980s the US DoD sponsored research into 
improving battlefield decision-making
• Found that people under pressure don’t use anything remotely 
like the economic decision-making model
People under pressure don’t weigh up the relative merits of 
a set of options and choose the most optimal one
• They don’t even make a choice from a cut-down subset
They generate one option at a time and take the first one 
that works
How Users Really Make Decisions (ctd)
In evolutionary terms, if a lion turns up in front of a 
monkey, it runs up the first tree it sees rather than 
stopping to think about it at length
• It’s better to be wrong than to be eaten
Model is called the singular evaluation model 
• And various other things: Recognition-primed decision 
making, heuristic decision making, the take-the-best heuristic, 
…
• (Shows independent reproducibility, if not consistent 
nomenclature)
How Users Really Make Decisions (ctd)
Singular evaluation is used when
• The decision-maker is under pressure
– Computer users being prevented from getting a job done are 
automatically in the “under pressure” category
• The conditions are dynamic
– The situation may change by the time you’ve performed a 
long detailed analysis
• The goals are ill-defined
– Most users have little grasp of the implications of security-
related choices
This is almost a mirror image of the SEU theoretical 
model!
How Users Really Make Decisions (ctd)
Other researchers examined the problem from a conceptual 
modeling angle
• Which conceptual model best matches how humans make 
decisions under pressure?
The best conceptual model to actual human behaviour was 
singular evaluation (under a heuristic name)
• Both empirical and conceptual-modelling approaches reached 
the same conclusion
How Users Really Make Decisions (ctd)
Simple heuristics are popular because it’s very difficult to 
learn from feedback from complex decision-making 
processes
• Diffusive reinforcement provides insufficient information to 
single out any one strategy as being particularly effective
• False correlations and biased attributions of success lead to 
superstition-based decision support
Popularity of “systems” for gambling and stock trading is 
because participants like to think that they’re doing 
something that’s better than just guessing
How Users Really Make Decisions (ctd)
Gambling-based decision-making relies on obvious 
feedback and provides instant gratification
• Coin toss/die roll
• Immediate feedback
Security decision-making doesn’t work this way
• No immediate feedback
• No obvious feedback
• Silent failures
How Users Really Make Decisions (ctd)
Result: Any action that fails to trigger immediate negative 
feedback appears to be a win
• This is one reason why users dismiss warning dialogs
How Users Really Make Decisions (ctd)
When there’s no immediately obvious choice, people’s 
decision-making abilities go downhill rapidly
• Look for some arbitrary distinction, no matter how useless, and 
go by that
– “All of these DVD players are near-identical.  I’ll get this 
one because it has a karaoke function and the others don’t”
• Procrastinate
• Decide based on irrational emotions
This is an appalling way to perform security-related 
decision making!
How Users Really Make Decisions (ctd)
Any form of strong emotion (not just job stress) causes 
inflexible thinking/decision-making
• External stimuli reduce our ability to gather information and 
use working memory to sort out the information that we have
Example: Soldiers were trained on how to safely exit a 
plane
• Overheard a (rehearsed) conversation among the pilots 
discussing how the plane was about to crash
• Had great difficulty in recalling their instructions
– (… and needed a change of underwear afterwards)
• Soldiers who weren’t exposed to the conversation fared much 
better
How Users Really Make Decisions (ctd)
These limits on reasoning ability are exploited by stage 
magicians, who anticipate how observers will reason and 
then choose ways of doing things that fall outside our 
ability to think of possibilities
• Distraction and misdirection also play a role
Example: How to make an item disappear
• Ask a bunch of people to list all the explanations that they’d 
have for how the disappearance worked
• Come up with a way of doing it that doesn’t involve any of 
these expectations
• (If the item that disappears is someone else’s money or 
valuables then you didn’t learn this strategy here)
It’s not a Bug, it’s a Feature!
The ability to sort out relevant details from the noise is 
what makes it possible for humans to function
The entire human sensory/information-processing system 
acts as a series of filters to reduce the vast flow of 
incoming information to the small amount that’s actually 
needed
• Did you notice the sensation of the clothes on your skin before 
you read this bit?
Selective attention processes allow things like the cocktail 
party phenomenon/source separation problem
It’s not a Bug, it’s a Feature! (ctd)
Imagine if humans couldn’t take shortcuts in reasoning
• They’d never get anything done
AI researchers have already run into this problem
• Programs had to mechanistically grind through vast numbers of 
implications to come to a conclusion
Known in AI as the frame problem: How do you frame a 
problem so that it’s practically solvable?
• In problem-solving literature it’s called analysis paralysis
May be a cause of OCD in humans
• People become trapped in a labyrinth of implications
• OCD is a means of dealing with the anxiety that results
It’s not a Bug, it’s a Feature! (ctd)
Researchers have run into the problem of analysis paralysis 
when evaluating browser security indicators
• Users were asked to switch off heuristic decision-making and 
carefully verify security indicators to check the validity of a 
site
This is the standard “best-practice” advice given to users
It’s not a Bug, it’s a Feature! (ctd)
Researchers had to abort the experiment
• Users spent “absurd amounts of time” trying to verify the site’s
legitimacy
Switching off singular evaluation lead to a false-positive 
rate of 63%
• Even with singular evaluation switched off, users still failed to 
detect 36% of false sites
It’s not a Bug, it’s a Feature! (ctd)
There is one small class of people who use the SEU model 
for decision-making
• People who have sustained damage to the frontal lobes of the 
brain
The medical term for this when it’s done deliberately as 
part of a medical procedure is “lobotomy”
It’s not a Bug, it’s a Feature! (ctd)
Neurology professor Antonio Damasio’s account of SEU 
decision making in a patient with ventromedial
prefrontal lobe damage:
For the better part of a half-hour, the patient enumerated 
reasons for and against [the two possible dates for his next 
appointment ...] he was now walking us through a tiresome 
cost-benefit analysis, an endless outlining and fruitless 
comparison of options and possible consequences.  It took 
enormous discipline to listen to all of this without pounding on
the table and telling him to stop
It’s not a Bug, it’s a Feature! (ctd)
In extreme cases overanalysis can cause a complete failure 
to function
• People suffering from somatising catatonic conversion are 
paralysed by the overhead of having to analyse in infinite detail 
every decision that they make
Evaluating Heuristic Reasoning
Researchers have run detailed evaluations of the relative 
performances of different conceptual models
Tests involved applying various strategies to deciding 
which of two objects scored higher for given criteria
• City populations
• High school dropout rates
• Homelessness rates
• House prices
• Professor’s salaries
• Obesity at age 18
• Fish fertility (!!)
• …
Evaluating Heuristic Reasoning (ctd)
Information available to guide the decision included (for 
the example of house prices)
• Current property taxes
• Number of bathrooms
• Number of bedrooms
• Property size
• Total living area
• Garage space
• Age of the house
• … various other factors, up to 18 in total …
• (Different strategies used different numbers of factors)
Evaluating Heuristic Reasoning (ctd)
Example of heuristic reasoning applied to the city 
population problem
• For non-US citizens: Does San Diego have a larger population 
than San Jose? 
• For US citizens: Does Munich have a larger population than 
Dortmund?
People tend to choose San Diego/Munich because they’ve 
heard of them
• Better-known → bigger
– Hosting a major beer festival doesn’t hurt either
• (People do this without even thinking about it)
Evaluating Heuristic Reasoning (ctd)
When researchers compared this with full-blown multiple 
regression analysis using all 18 factors, M-R was only 
slightly better than the simple heuristic!
This can’t be right…
• Researchers hired independent programming teams in the US 
and Germany to reproduce the results
Published all of their data so that others could replicate it
• Others got the same result
It’s not a Bug, it’s a Feature! (ctd)
Why did simple heuristics perform as well as multiple 
linear regression?
• Linear regression makes use of large numbers of free 
parameters and assumes that each is relevant
• Problem is known as overfitting
• Simple heuristics reduce overfitting by filtering out noise
It’s not a Bug, it’s a Feature! (ctd)
Overfitting problem was confirmed by investigating how 
the models handled new data after being fed the training 
data set (generalisation)
• Performance of linear regression dropped by 12%
– c.f. an IDS trained with Lincoln Labs test data
Simple heuristics was left as the overall winner
It’s not a Bug, it’s a Feature! (ctd)
Another experiment compared a Bayesian network to 
simple heuristics
• The ultimate expression of the economic decision-making 
model
Full-blown Bayesian network performed only marginally 
better than the simple heuristics, but at a massively 
higher cost
It’s not a Bug, it’s a Feature! (ctd)
OK, sometimes this can be a bit of a bug…
• Marketers exploit it through techniques like brand recognition
– Active penetration attack on the human decision-making 
process
• Consumers use heuristic decision making to choose recognised
brands over unrecognised ones
– See later slides on geeks vs. normal humans for more on 
this
(Fraudsters and marketers figured this out empirically long 
before psychologists had explored it)
Conseq.of the Decision-making Process
Psychologists distinguish between two types of actions 
taken in response to a situation
Controlled processes
• Slow and costly in terms of mental effort
• Provide a great deal of flexibility in handling unexpected 
situations
Automatic processes
• Quick, little mental overhead
• Acting on autopilot, little control or flexibility
Conseq.of the Decision-making Process (ctd)
Example: Novice vs. experienced drivers
• Novice driver has to manually and consciously check mirrors, 
change gears, …
• Experienced driver performs these as an automatic process
• Novice drivers deal with this by load-shedding
– Sacrifice driving speed for steering control
This effect is particularly nasty when it occurs with 
complex control systems
• Aircraft cockpits (situational awareness problem)
• Nuclear reactors
• …
Conseq.of the Decision-making Process (ctd)
You can experience load-shedding during a controlled 
process yourself by writing the weekday repeatedly on a 
piece of paper
• At some point start counting backwards from 100
• Look at what happens to your handwriting quality or speed
– This is your brain load-shedding
Now try it again, but this time sign your name (automatic 
process)
Conseq.of the Decision-making Process (ctd)
Automatic processes are people acting on autopilot
• Once the correct stimulus is presented, it’s very hard to stop