# 大型互联网公司数据安全实践
##### 译文声明
本文是翻译文章
译文仅供参考，具体内容表达以及含义原文为准。
作者：鹏飞（坏牙崩克）美团安全部数据安全负责人，负责集团旗下全线业务的数据安全保护。
相信很多企业都面临数据泄漏的问题，例如用户投诉注册后收到了很多骚扰电话，内部员工频繁接到到猎头电话骚扰，业务上的竞争对手准确地掌握了公司的经营数据动态等。而这些泄漏事件的追查难度又非常大。如下图，用户的一个购买行为，沿途可能经过若干路径，每个路径下面又包含N多分叉。最终交易成功，可能会被几百个服务调用，这些服务同时又对应到后台，最终可能有几千人会看到，究竟是谁泄漏了，如同大海捞针。
按照数据安全生命周期理论，从数据采集、传输、存储、处理、交换和销毁去评估和保护，这一路下来，成本非常高。在大型企业里，业务种类可能上万种，而且每天都在发生变化，如果严格按照这个理论去套现实，成本非常巨大，实现可能性也很小。对于业务复杂度较高的企业，迫切需要新的方法来指导。所以业界也出现了一些其他的理论，例如“以数据为中心的安全”、“数据安全治理模型”等。本文不准备变成一个纯理论的研究，而是谈一谈在实践中的数据安全。
思路的逻辑上，我们将数据安全分为四个阶段，分别是识别、保护、检测、响应。识别是为了发现重点，进而对其进行保护，很多公司的数据安全可能就到此为止了。但其实更核心的检测领域，由于难度大、成本高、误报多，往往流于形式浮于表面，做一些看起来炫酷的大盘，业界近年来提到的SIEM、UEBA，实际落地情况差强人意，就是现状的一种体现，检测领域需要重度深入到风险场景，深入刻画，反复训练，精准识别。而在响应领域，则需要对黑灰产有认知，建立多方沟通渠道，响应方向是对自己防护和检测能力的验证，每一个真实case后面，都反映着一连串的现存问题，通过响应手段，避免安全人员自嗨。
## 0x00 识别
面对大规模复杂系统，更需要快速的识别出重点。传统上的数据安全领域，识别的认知是在敏感数据层面，但对于敏感行为、敏感人群做的不多。这会导致不够聚焦，管控面太大以至于被淹没，难以突出高风险重点。用风险来驱动安全建设，能够快速抓住重点，且得到业务方的积极配合。
  * 敏感数据识别
几乎在每一个数据安全讨论上，都会提到数据分类分级的问题。数据种类如此复杂多样，如何进行数据梳理，正确地分类分级？笔者曾经看到过有公司把自己的数据分为7级，并详细规定了每个数据是什么，试图用一个完整事无巨细的框架对数据进行解释。一个过于复杂的方法，成本高，更容易出漏洞，同时在大型公司，数据每分每秒都在产生新的类型，又如何能够全部囊括？即使能够穷举一切，又如何能保证这个策略能够得到有效执行？回答这个问题，实际上需要回答的是数据安全的策略是什么，所谓策略，就是要有选择的重点，不同阶段可以有不同策略。例如要防止大规模个人数据泄漏，或者是要防止核心知识产权泄漏等，这些策略指引了数据分类分级的方向。从实战角度说，各行业规范都会是一些大而全的东西，这需要分阶段选择重点来解决，而重点在于风险产生的影响。
定义之后则是技术上能够自动发现敏感数据及其流转，这里分为两层，一是数据的位置，二是数据类型的识别。在海量数据的状态下，需要多维度的发现能力，而不仅仅是在数据库层面进行识别。汇总则形成数据地图类产品，掌握数据资产的分布，对敏感数据进行标记跟踪，为后面的防护提供基础。
  * 特权操作识别
除了对数据的识别，还需要有对特权操作的识别，特权操作的来源则是各类业务、系统日志。以往大家关注的焦点可能是类似于数据库dump之类的操作行为，但特权不仅只是这些内容，还包括一些敏感业务操作行为，例如查询用户的订单记录，在某些场景下也是敏感操作。
  * 敏感人群识别
数据泄漏一定和人有关系。有一些人群，掌握敏感数据，且容易受到外部诱惑，这是要识别的对象。例如外包、待离职人员、合作伙伴等。另外要提的是，黑产、竞对也都会有意识的打入内部渗透，当这些人伪装后应聘成功，带来的泄漏影响面极大，传统的背调对这种问题无能为力，这就需要有更好的方法识别，这部分涉密不展开，读者可展开想象。
## 0x01 数据保护
数据保护层则主要由若干防护组件组成，互联网企业数据保护参见赵彦《互联网企业数据安全体系建设》https://tech.meituan.com/2018/05/24/data-security-system-construction.html和《互联网公司数据安全保护新探索》https://tech.meituan.com/2018/05/20/data-security-protection-new-exploration.html，这里不再赘述，主要谈一下实践上一些注意事项。
  * 数据收口
数据保护的一个重点是要对数据出口进行集中化，分散点过多则会导致管理成本急剧提升。在数据的流向上，越早对数据进行统一集中管理，效果越佳，成本也越低。下图给出了在各个位置可以进行集中收口的选择，由于很多业务都是已经运行了多年，改造成本高，且数据统一收口，安全部门独立推动难度较大，因此建议在合适的时机介入。
  * 指标收敛
衡量安全工作的好坏，要看风险的收敛程度。要实现风险收敛，是一个数据化运营的工作。这方面笔者的另一位同事职业欠钱也有专门文章《我理解的安全运营》讲述https://zhuanlan.zhihu.com/p/39467201。在数据安全上可参考的关键指标有：规模泄漏绝对值、人均泄漏数据量、主动发现率、收敛率等。围绕核心指标，还会有一些分解，例如功能覆盖率、场景覆盖率、误报率、收敛时长、数据覆盖率等。
业界有一些同学用安全能力覆盖作为核心指标，笔者认为不可取。安全能力是手段，而降低风险才是目标。
  * 业界对标
所谓对标，是把自己的水平和业界最佳实践进行比较。在互联网公司，国外会看Google、Amazon等，对标考虑的是质量、时间、成本。对标的好处一是知道自己的差距在哪，在业界里的水平如何。另外对标能够开展快速建设，向业界头部看齐。在数据安全领域，对标要考虑国内外情况差别。例如国外实际上很少有所谓终端透明加密产品，一般是DLP、磁盘加密，这里反映的是国情不同，国外对员工是信任机制，但如果触犯，后果极其严重。国内相对司法处罚较轻，且对企业造成损失较大，因此更倾向于控制。
## 0x02 检测
检测能力是数据安全的核心，也是数据驱动数据安全的一个落地性体现。其主要框架如下图：
很多同学可能一眼看出来，这是一个UEBA（用户实体行为分析）。通过分析检测数据中人类行为的模式，实现威胁洞察。其特点在于关注人、设备、行为，通过关联分析、基线模型、罕见度等模型发现风险。最底层是基础数据，基础数据的来源可以有很多，传统意义上的DLP、流量数据之外，增加了设备和业务操作维度的大量数据，这些数据能够提供更广阔的风险分析点。这一层的难点是数据如何采集、高质量的清洗，从而简化成本、统一数据口径。这是一个基础工作，取决于数据治理的程度。
上面一层是特征提取，目的是多维组合，减少明细，可为上层各模型快速使用。这里需要将各种变量提前计算，并且提供快速的组合能力，这部分主要是以风险为导向做变量。