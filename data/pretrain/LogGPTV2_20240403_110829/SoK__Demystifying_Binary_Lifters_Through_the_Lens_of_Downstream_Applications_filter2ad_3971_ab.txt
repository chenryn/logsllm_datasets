McSema [87], deﬁnes a runtime module of three elements
(mem, pc, state) in its generated LLVM IR code, where
mem represents memory and global data regions, pc denotes
the program counter, and state maintains registers and CPU
ﬂags. Memory load and store are converted into querying and
updating mem in the lifted IR code, respectively.
Reﬁnement: From Emulation-Style IR to High-Level
IR. While the emulation style lifting is straightforward, ex-
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:56:18 UTC from IEEE Xplore.  Restrictions apply. 
1101
Input BinaryRecoverFunctionBoundaryStatic/DynamicBinaryLiftersLinebyLineIRLiftingMachineCode&DataAddRuntimeModuleOptimizationPassesRefinementLLVMIROutputDynamicStaticFig. 2. A case study comparing LLVM IR lifted by McSema with LLVM IR compiled by clang. Both IR code has been extensively simpliﬁed for readability.
Compiling and executing the lifted IR gives correct outputs, meaning that the lifted IR can smoothly pass existing functionality check research [38], [66].
isting research has pointed out considerable drawbacks in
the lifted IR code. For example, while the source code (and
compiled LLVM IR code) mostly uses local variables for
computation, the lifted IR code likely accesses a global array
(e.g., mem in the McSema case) maintained by the runtime
module to mimic the usage of physical stack in machine code.
This inconsistency is often referred to as the “virtual stack vs.
physical stack” issue in literatures [19], [47].
To reﬁne the lifted IR code and make it (visually) closer to
the compiled IR, modern lifters can implement analysis passes
or heuristics to recover local variables and variable types;
successfully recovered local variables deprecate the necessity
of maintaining a global array to mimic physical memory stack
accesses. Precisely recovered variable types also assist static
analysis (see Sec. VI-B). Nevertheless, we note that not every
lifter has fully implemented such reﬁnement procedures, as
we will show in Sec. VI. See case studies in Sec. III.
Since each execution trace only partially covers the pro-
gram, dynamic lifters usually merge multiple IR traces to-
gether. To this end, extra branch conditions and control transfer
statements are added. PHI nodes [123] deﬁned by LLVM IR,
which stitch data ﬂow propagations from different execution
paths, are also inserted at control merge points.
Optimization. Lifters usually leverage optimization passes
provided by the LLVM toolchain to optimize the lifted code.
As aforementioned, each machine instruction is usually lifted
into a routine function call to a sequence of IR statements,
leading to very lengthy IR programs. Optimization enables
to inline each function call, where considerable statements
(e.g., updating a CPU ﬂag) could be further optimized away
given that they are “dead.” We notice that some lifters (e.g.,
RetDec [68]) could even implement its own optimization
passes to make the lifted IR code more concise [8], [6], [7].
III. MOTIVATING EXAMPLE
Fig. 2(a) presents a simple C code that sums the ﬁrst 60
elements of an array. We use clang, the C frontend of the
LLVM framework, to compile and emit LLVM IR code (see
Fig. 2(b)). We use a popular static lifter, McSema [87], to
lift the corresponding executable and present the lifted LLVM
IR in Fig. 2(c). As observed, compiled IR code preserves
most of the structure of the source code. In contrast, the
lifted IR code represents the computation in a dramatically
different way due to the following observations. 1) McSema
uses utility functions to emulate the computation of each
machine instruction. For example, memory loading is lifted
into a callsite to read mem in Fig. 2(c). 2) McSema uses
several globals to represent program runtime, i.e., State that
consists of general-purpose CPU registers and CPU ﬂags. 3)
McSema also uses an array (i.e., Mem in Fig. 2(c)) to mimic
the access of the x86 memory stacks.
While local variables are frequently used in compiled IR
code, e.g., the variable c in Fig. 2(b), McSema uses local
variables to represent registers (e.g., at the beginning of main
in Fig. 2(c)), and updates the global state s before ﬁnishing
function execution. Correspondingly, an array access in the
original C code (e.g., a[k] in Fig. 2(a)) is converted into
querying the global array via some utility functions, which
mimics how the x86 stack is accessed in the machine code.
We emphasize that compiling and executing the lifted
IR code gives correct outputs. Hence, existing research on
either testing or formally verifying the correctness of binary
lifters [66], [38], [113] would not deem the lifted IR code
“specious.” Nevertheless, given the dramatically different rep-
resentations, one could further question how good can the
lifted IR code support downstream security applications and
transformations, and what are the limitations of that. To date,
a thorough study regarding this point is still missing.
Emulation-Style IR (EIR) vs. High-Level IR (HIR). Fig. 2
compares compiled-IR with McSema-generated IR. Findings
in Sec. VI will show that popular static and dynamic lifters
can generate either emulation-style IR (i.e., Fig. 2(c)) or more
high-level IR code that is comparable to compiled IR code in
Fig. 2(b). Reﬁnement in Sec. II has clariﬁed the process of
going from an emulation-style IR to high-level IR. To ease
the presentation, LLVM IR compiled from source code by
clang is referred to as compiled IR (CIR). LLVM IR yielded
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:56:18 UTC from IEEE Xplore.  Restrictions apply. 
1102
(b)LLVMIRgeneratedbyClang(c)LLVMIRliftedbyMcSema(a)OriginalCcodedefine i32 main() {          a = alloca[100xi32];//allocatelocalarrayreturnfoo(a, 60);}define i32 foo(i32* a, i32 b) {cmp= icmpsgti32b, 0brcmp, labelfor.body, labelfor.endfor.body:idx= phi i64 [idx.next], [0]addr= getelementptr(a,idx);c+=loadaddr;cond= icmpeq i32idx.next, b;brcond, label for.end, label for.bodyfor.end:returnc;}int main(){int a[100];intc=foo(a,60);returnc;}int foo(int a[], int b) {intk,c; for(k=0;k<b;k++)c+=a[k];returnc;}State= {enumArch,i64Regs[], i8Flags,...}define Mem main(State*s,PCpc,Memmem){//preparelocalvariablesforCPUregisterseax= s.Regs[0];ebx= s.Regs[1];...Memmem1=foo(s, pc + 12,mem);eax= s.Regs[0];//loadreturnvalue// updateglobalstatess.Regs[0]=eax;s.Regs[1]=ebx;...returnmem1;}define Mem foo(State*s,PCpc,Memmem){//loadarrayawithoffsetk;kisineaxebx= _read_mem(mem, esi+ eax);//storec(inebx)ontopofthestackMemmem1 = _write_mem(mem, esp, ebx);(c)LLVMIRliftedbyMcSema(con’d)eax= __read_memory(mem, esi+ eax);}define i32_read_mem(Memmem,i32offset){...}define Mem_write_mem(Memmem,i32offset){...}by lifters following the emulation paradigms is referred to as
emulation-style IR (EIR), whereas LLVM IR yielded by lifters
going through further reﬁnement as high-level IR (HIR).
Transformations Involved in Emitting EIR and HIR. With
manual efforts in studying lifter codebase, we put transforma-
tions used during lifting into three categories: 1 optimizations
offered by the LLVM framework, 2 simple optimizations
developed by lifters, and 3 transformations recovering high-
level program features developed by lifters. 1 simpliﬁes lifted
IR code in a functionality-preserving manner. 2 , e.g., re-
moving bloated utility functions, should also be functionality-
preserving if implemented correctly. However, 3 tackles a
challenging task of recovering information (e.g., type) lost
during compilation. According to our manual study, lifters
emitting EIR (e.g., McSema; see Sec. V-A) leverage 1 and
2 . However, lifters emitting HIR typically employ 1 , 2 ,
and 3 to generate high-level code. This explains the core
difﬁculty of producing HIR that is functional preserving; see
our empirical evaluation on correctness in Sec. VI-E.
IV. STUDY OVERVIEW
Sec. III has clariﬁed that we aim to study how good can the
lifted IR code support downstream security applications and
transformations, and what are the limitations of that. We now
clarify several aspects and present our study overview.
Correctness vs. Expressiveness. Functionality correctness is a
critical aspect to assess binary lifters. Functionality-preserving
lifters can, in principle, support to (semi-)automatically ﬁx a
bug in legacy code or to migrate legacy code — with the
end result again being a functional executable. We measure
correctness of popular binary lifters and present corresponding
discussions in Sec. VI-E: the results are promising and inspir-
ing. However, we clarify that measuring correctness should not
be the primary focus of this SoK paper due to the following
reasons. 1) Existing works have launched testing and formal
veriﬁcation toward binary lifters [66], [38], from where we can
gain an in-depth understanding on the correctness of lifters.
2) We believe that supporting static code analysis, which
typically does not require to recompile and execute the lifted
IR, is of equal importance with correctness. Particularly, our
discriminability study in Sec. IV-B measures lifters’ support
of similarity analysis, which is a very actively-studied ﬁeld
(e.g., [51], [120], [116], [74], [124], [44], [46]). Similarly, the
security community has devoted signiﬁcant efforts to advanc-
ing decompilation (e.g., [59], [91], [97], [122]), and we explore
lifters’ support of decompilation in this work. 3) Generating
ﬂawless high-level code is a well-known challenge for reverse
engineering (not
in
principle, need to equip the “re-assembleable disassembling”
scheme which is not mature [110], [108], [43], [52]. To date,
decompiled C/C++ code mainly serves (human-based) process
of analysis and comprehension, not for recompilation.
lifters). To do so, binary lifters,
just
We fully agree that functionality-preserving binary lifters
can extensively promote binary ﬁxing, patching, and legacy
code migration. However, these tasks, in general, can also be
done on assembly code [41], [111]. In all, LLVM IR excels
in promoting (static) analysis. The LLVM community has
taken years of effort to develop analysis infrastructures; re-
implementing those infrastructures on assembly code can take
a huge effort. More importantly, assembly code does not have
type or other high-level code information, which makes itself
less analysis-friendly compared with LLVM IR.
Measuring IR Expressiveness. To measure correctness, ex-
isting works have used straightforward approaches involving
testing or formal veriﬁcation [38], [66], [113]. However, the
formulation of oracles or speciﬁcations relevant to our goal
— to study how good can the lifted IR support security tasks
and transformations and what are the limitations of that —
would be challenging, recondite, and perhaps impossible. For
example, while “structuredness” of lifted IR code may be
(partially) reﬂected by counting recovered functions, function
information may not be the key to security analysis, such as
buffer overﬂow detection. It may also be infeasible to compute
the syntactic similarity between lifted IR and compiled IR
for use as an oracle. This is due to the fact that lifters may
implement different code-generation templates and tactics,
thus producing syntactically different IR codes that provide
comparable support for downstream tasks.
This research tackles the aforementioned challenge in a
pragmatic way. We employ three downstream applications
and quantify how lifted IR code supports these representative
tasks. These applications proﬁle the quality of lifted IR code
from conceptually different aspects. More importantly, they
are the building blocks of many real-world security, systems,
and software re-engineering applications. This way, we ensure
the inclusion of our study and the credibility of our ﬁndings.
Assessing Upper-Bound Quality Using Compiled
IR. Aligned with existing works [19],
[47], we deem
that compiler-generated IR denotes the upper bound quality
of
time, empirically
benchmarks “how far we are” from this perspective. Hence,
instead of deﬁning how good the lifted IR should be
w.r.t. downstream tasks (which is obscure), we check whether
lifted and compiled IR have close performance. We now
introduce three representative downstream tasks.
A. Pointer Analysis
lifted IR. This study,
for
the ﬁrst
Pointer analysis establishes which pointers can point to the
same variables or memory objects. Pointer analysis is the
cornerstone of most data and control ﬂow analyses, and it
enables many security applications. Hence, the ﬁrst part of
this study examines whether pointer analysis can be launched
in a fool-proof manner using lifted IR code. This reveals the
overall difﬁculty of performing rigorous static analysis using
lifted LLVM IR code.
We leverage the state-of-the-art LLVM pointer analysis
library, SVF [102], [103]. SVF performs sparse value ﬂow
analysis to iteratively construct value ﬂow and pointer analysis
results. We use the default ﬂow-sensitive pointer analysis [102]
provided by SVF. Each pair of pointers is assessed by SVF,
which determines whether they are MustAlias, MayAlias,
or NoAlias. That is, whether they always, may, or never
point to the same data region, respectively.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:56:18 UTC from IEEE Xplore.  Restrictions apply. 
1103
Variable recovery is a prerequisite of pointer analysis.
SecondWrite [19], [47] has developed fully ﬂedged variable
recovery techniques, which demonstrated promising results
almost a decade ago. Our preliminary study ﬁnds that some
binary lifters (e.g., RetDec [68] and mctoll [80]) re-
cover a reasonable number of variables. This indicates that
benchmarking these binary lifters in terms of pointer analysis
is well-timed. Furthermore, LLVM pointer-analysis facilities,
including SVF, are highly demanding and have been widely-
adopted in security research [32], [62], [64], [31], [65], [54].
to process e and produce a piece of lifted IR code, namely
p(cid:48)
ir. Given pir and p(cid:48)
ir both derived from p, we feed them into
downstream tasks and manually inspect potentially deviated
analysis results. We aggregate the harvested information to
deduce empirical ﬁndings.
We study unobfuscated ELF executable: reverse engineering
is error-prone for obfuscated code. Sec. VI presents detailed
evaluation when compiling e with clang (ver. 10.0) and no
optimization. Sec. VII and Sec. VIII further explore cross-
compiler, cross-optimization, and cross-architecture settings.
B. Discriminability Analysis
The second thrust focuses on measuring the discriminability
of IR code by quantifying the feasibility of determining the
(dis)similarity of two pieces of IR code that implement the
same or different tasks. Holistically, discriminability is the
base of various similarity-based security applications. For
instance, malware clustering and code plagiarism detection
are usually conducted by analyzing the (dis)similarity between
unknown software and samples of known software [118],
[109], [75], [20], [112], [16], [30].
We extend a code embedding tool, ncc [26], that was
developed in the LLVM framework. Code embedding tech-
niques convert code into numerical vectors, such that similar
codes are separated by a shorter cosine distance in numerical
space than dissimilar codes. Thus, ncc comprehends LLVM
IR code by constructing a so-called “contextual ﬂow graph,”
which simultaneously incorporates IR data ﬂow and control
ﬂow features. It then uses graph neural network (GNN)-based
embedding models [125] to extract a numerical vector for each
IR program. ncc also provides an algorithm classiﬁcation
model of the extracted numerical vectors, which is trained on
the POJ-104 dataset [82]. The POJ-104 dataset contains 44,912
C/C++ programs that
implement entry-level programming
assignments for 104 different tasks (e.g., merge sort vs. two
sum). Higher classiﬁcation accuracy indicates that it is easier
to decide the (dis)similarity of two LLVM IR programs.
C. C Decompilation
C decompilers are commonly used as the basis of many
including off-the-shelf
security and systems applications,
software security hardening, vulnerability detection, cross-
architecture code reuse, and proﬁling [55], [67], [107], [37],
[63]. In general, C decompilers lift executables into (cus-
tomized) IR, and conduct a set of analysis passes to re-
cover high-level control structures (e.g.,
loops) and code
patterns [28]. The RetDec framework [68] provides a de-
compiler, called llvmir2hll, to convert LLVM IR code
into C source code. This decompiler has been shown to have
comparable accuracy with commercial tools [76]. We measure
whether compiled IR and lifted IR code can induce decompiled
C code of similar quality.
V. STUDY SETUP
Given a C program p, we use clang to compile and
emit LLVM IR code pir. We then directly compile p into
an executable e. We use either static or dynamic binary lifters
TABLE I
BINARY LIFTERS USED IN THE STUDY.
Tool Name
McSema [87]
McSema0 [87]
mctoll [80]
RetDec [68]
BinRec [18]
A. Binary Lifters
Information
Developed by Trail of Bits, Inc.
Disable all LLVM optimizations used by McSema
Developed by Microsoft
Developed by Avast
Published at EuroSys ’20
Table I reports four static and dynamic binary lifters that
are evaluated in our study.
McSema. We benchmark McSema, a famous static lifter
that has been developed for about a decade by Trail of
Bits. McSema performs typical emulation-style lifting, i.e., it
generates emulation-style IR (EIR), as introduced in Sec. III.
We report IR samples lifted by McSema in Fig. 2(c): its lifted
IR code manifests a distinct execution mode compared with
compiled IR code. Each machine instruction is emulated in
LLVM IR code, and the execution context, including values
of registers and memory, are passed through function callsites
(see main and foo in Fig. 2(c)).
McSema takes decompilation and binary patching (with
the end result re-emitting working binaries) as its main fea-
tures. Aligned with our research motivation introduced in
Sec. IV, McSema also champions to re-use existing LLVM-
based passes and maintain one set of LLVM passes to analyze
both source/binary code [87], However, our study reveals that
it lacks fool-proof support for static analysis tasks. McSema
uses a number of LLVM optimization passes to make the lifted
program more succinct. To reveal how compiler optimizations
could affect the performance of downstream applications, we
conﬁgure McSema to disable all imposed optimization passes
(referred as McSema0). McSema needs a disassembler as the