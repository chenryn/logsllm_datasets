@sshleifer \- sorry to ping you here on this. Would be amazing if you find
some time to explain the Pegasus tokenizer a bit.
A couple of things I don't understand:
  * In the official Pegasus Tokenizer and from reading the paper it seems that exactly 2 mask tokens are necessary.  
See https://github.com/google-
research/pegasus/blob/master/pegasus/ops/pretrain_parsing_ops.cc#L66  
a) ID=2 seems to correspond to the sentence mask token, called `[MASK_1]` and  
b) ID=3 seems to correspond to the word mask token, called `[MASK_2]`
=> Why don't we have `[MASK_1]` and `[MASK_2]` tokens in the tokenizer's
special tokens? I would actually add them at the id's 2 and 3 instead of
having `unk_2` and `unk_3` there. Wdyt?
  * Why do we call the tokens unk_2 - unk_104 ? Why unk? And why aren't those part of the `special_tokens_map` \- is this on purpose?
  * Why does Pegasus inherit from the Reformer Tokenizer -> I don't really see what they have in common...
Would be awesome if you could take 10min to reply :-)