               DMS(mem_limit  for troubleshooting tips.n");
      } else {
        SAYF("n" cLRD "[-] " cRST
             "Hmm, looks like the target binary terminated before we could complete an"
             "    handshake with the injected code. There are %s probable explanations:nn"
             "%s"
             "    - The current memory limit (%s) is too restrictive, causing an OOMn"
             "      fault in the dynamic linker. This can be fixed with the -m option. An"
             "      simple way to confirm the diagnosis may be:nn"
    #ifdef RLIMIT_AS
             "      ( ulimit -Sv $[%llu  for troubleshooting tips.n",
             getenv(DEFER_ENV_VAR) ? "three" : "two",
             getenv(DEFER_ENV_VAR) ?
             "    - You are using deferred forkserver, but __AFL_INIT() is nevern"
             "      reached before the program terminates.nn" : "",
             DMS(mem_limit exec_us *
q->len;`即测试用例执行的时间以及输入长度的乘积，注释说希望找到更快或者规模更小的用例，一旦当前的`fav_factor`比`top_rated[i]`要小就会更新这个表，将原来的winner的`tc_ref--`，当前的插入表中。
至此，我们以及将`perform_dry_run`中的函数分析完毕。
下面会调用`cull_queue`函数，函数前的注释说我们已经进入了第二个阶段，即用`routine`来遍历`top_rated
entry`，不断寻找之前没见到过的bytes并且将它们标为`favored`。函数首先判断sore_changed是不是为真,之后拿贪心算法找能够遍历到所有节点的最小测试集合，比如有三个节点n0,n1,n2,n3和3个测试用例s1,s2,s3。`top_rated[0]=s0,top_rated[s2]=s2`且`s0覆盖n0,n1;s1覆盖n2`其中初始化`temp_v=[1,1,1,1]`，1就表示对应节点没有访问到，初始化为都没访问到。开始先判断`temp_v[0]=1`，说明没访问到，之后就去看`top_rated[0]`，发现为1，说明存在一个用例能访问到这个`n0`，因此进一步查看这个用例，得到其覆盖范围`trace_mini=[1,1,0]`故据此更新`temp_v=[0,0,1]`，往下看n1，访问过了，再看n2仍未访问到，再去看top_rated得到s2，再看s2的覆盖范围更新temp_v，就这样标注s0和s1为favored，如果他俩还没有被fuzz，还要`pending_favored++`。完成上述操作之后将无用的用例标为冗余。
    /* The second part of the mechanism discussed above is a routine that
       goes over top_rated[] entries, and then sequentially grabs winners for
       previously-unseen bytes (temp_v) and marks them as favored, at least
       until the next run. The favored entries are given more air time during
       all fuzzing steps. */
    static void cull_queue(void) {
      struct queue_entry* q;
      static u8 temp_v[MAP_SIZE >> 3];
      u32 i;
      if (dumb_mode || !score_changed) return;
      score_changed = 0;
      memset(temp_v, 255, MAP_SIZE >> 3);
      queued_favored  = 0;
      pending_favored = 0;
      q = queue;
      while (q) {
        q->favored = 0;
        q = q->next;
      }
      /* Let's see if anything in the bitmap isn't captured in temp_v.
         If yes, and if it has a top_rated[] contender, let's use it. */
      for (i = 0; i > 3] & (1 > 3;
          /* Remove all bits belonging to the current entry from temp_v. */
          while (j--) 
            if (top_rated[i]->trace_mini[j])//这里是之前提到的取反操作
              temp_v[j] &= ~top_rated[i]->trace_mini[j];
          top_rated[i]->favored = 1;
          queued_favored++;
          if (!top_rated[i]->was_fuzzed) pending_favored++;
        }
      q = queue;
      while (q) {//标记冗余用例
        mark_as_redundant(q, !q->favored);
        q = q->next;
      }
    }
再往后就是一个大的循环，也是AFL最最核心的部分，循环开始依然是用`cull_queue`对队列进行筛选，如果一个`cycle`都没有新发现尝试更换策略，最终调用`skipped_fuzz
= fuzz_one(use_argv);`这个函数里对测试用例做了变异，下面一节着重分析这个函数AFL的变异策略
## fuzz_one && 变异策略
开始先根据标志位跳过一些测试用例。如果fuzz过或者没有`queue_cur->favored`标志，会有99%的概率被跳过；如果fuzzed&&no-favored，有90%概率跳过，如果没有fuzz过，有75%概率跳过。
之后打开文件，将内容map到in_buf上。
    /* Probabilities of skipping non-favored entries in the queue, expressed as
       percentages: */
    #define SKIP_TO_NEW_PROB    99 /* ...when there are new, pending favorites */
    #define SKIP_NFAV_OLD_PROB  95 /* ...no new favs, cur entry already fuzzed */
    #define SKIP_NFAV_NEW_PROB  75 /* ...no new favs, cur entry not fuzzed yet */
假如之前校准的时候有错误，则还会进行一次校准`CALIBRATION`，当然校准错误的次数有上限，为三次。
下面一步为`TRIMMING`,调用方式为`u8 res = trim_case(argv, queue_cur,
in_buf);`这个函数主要是用来调整测试用例大小的。起始以文件的`1/16`大小，一直到`1/1024`为步长，依次删除文件的某一步长(`write_with_gap函数`)，将得到的check_sum同原来的比较，如果相同说明这部分不会影响测试的结果，删除这部分。
之后调用`calculate_score`为这次测试的质量进行打分，这个分数在之后的`havoc_stage`使用。
下面就是主要的变异策略。
`BITFLIP`就是按位翻转，有多种翻转位数/步长的操作，值得一提的是，如果一段连续的序列翻转之后都不会改变(原执行路径破坏)，则可以将这段序列识别为一个`token`。程序会记录下来为后面变异做准备。之后调用`common_fuzz_stuff`测试变异后的文件。在8/8模式下，会生成一个eff_map。这个表的意义是如果我们翻转一整个比特都不能得到1(同原执行路径不同)，那么这个字节很有可能属于`data`而非`metadata(元数据)`。因而在之后的变异中会跳过这些无用的字节。
    if (cksum != queue_cur->exec_cksum) {
            eff_map[EFF_APOS(stage_cur)] = 1;
            eff_cnt++;
          }
`ARITHMETIC`是对数据做加减运算，同样有多种步长/翻转长度模式。这次变换就会利用刚才的eff_map筛选，加减的上限为35，变换过程中还会对数据大小端进行判断。
    /* Maximum offset for integer addition / subtraction stages: */
    #define ARITH_MAX           35
`INTERESTING`是做插入/替换等变换，替换成的数字是一些interesting_val，可以看到下面都是一些容易整数溢出的数字。替换的大小也有8/16/32bit
    /* Interesting values, as per config.h */
    static s8  interesting_8[]  = { INTERESTING_8 };
    static s16 interesting_16[] = { INTERESTING_8, INTERESTING_16 };
    static s32 interesting_32[] = { INTERESTING_8, INTERESTING_16, INTERESTING_32 };
    /* List of interesting values to use in fuzzing. */
    #define INTERESTING_8 
      -128,          /* Overflow signed 8-bit when decremented  */ 
      -1,            /*                                         */ 
       0,            /*                                         */ 
       1,            /*                                         */ 
       16,           /* One-off with common buffer size         */ 
       32,           /* One-off with common buffer size         */ 
       64,           /* One-off with common buffer size         */ 
       100,          /* One-off with common buffer size         */ 
       127           /* Overflow signed 8-bit when incremented  */
    #define INTERESTING_16 
      -32768,        /* Overflow signed 16-bit when decremented */ 
      -129,          /* Overflow signed 8-bit                   */ 
       128,          /* Overflow signed 8-bit                   */ 
       255,          /* Overflow unsig 8-bit when incremented   */ 
       256,          /* Overflow unsig 8-bit                    */ 
       512,          /* One-off with common buffer size         */ 
       1000,         /* One-off with common buffer size         */ 
       1024,         /* One-off with common buffer size         */ 
       4096,         /* One-off with common buffer size         */ 
       32767         /* Overflow signed 16-bit when incremented */
    #define INTERESTING_32 
      -2147483648LL, /* Overflow signed 32-bit when decremented */ 
      -100663046,    /* Large negative number (endian-agnostic) */ 
      -32769,        /* Overflow signed 16-bit                  */ 
       32768,        /* Overflow signed 16-bit                  */ 
       65535,        /* Overflow unsig 16-bit when incremented  */ 
       65536,        /* Overflow unsig 16 bit                   */ 
       100663045,    /* Large positive number (endian-agnostic) */ 
       2147483647    /* Overflow signed 32-bit when incremented */
`DICTIONARY`是替换/插入token到原文件中，共有`user extras (over)/user extras (insert)/auto
extras (over)`。其中替换是有上限的，数量高于上限就按概率替换。
`HAVOC`综合之前的变异方式，引用[Seebug](https://paper.seebug.org/496/#fork-server)一篇文章
> 随机选取某个bit进行翻转  
>  随机选取某个byte，将其设置为随机的interesting value  
>  随机选取某个word，并随机选取大、小端序，将其设置为随机的interesting value  
>  随机选取某个dword，并随机选取大、小端序，将其设置为随机的interesting value  
>  随机选取某个byte，对其减去一个随机数  
>  随机选取某个byte，对其加上一个随机数  
>  随机选取某个word，并随机选取大、小端序，对其减去一个随机数  
>  随机选取某个word，并随机选取大、小端序，对其加上一个随机数  
>  随机选取某个dword，并随机选取大、小端序，对其减去一个随机数  
>  随机选取某个dword，并随机选取大、小端序，对其加上一个随机数  
>  随机选取某个byte，将其设置为随机数  
>  随机删除一段bytes  
>  随机选取一个位置，插入一段随机长度的内容，其中75%的概率是插入原文中随机位置的内容，25%的概率是插入一段随机选取的数  
>  随机选取一个位置，替换为一段随机长度的内容，其中75%的概率是替换成原文中随机位置的内容，25%的概率是替换成一段随机选取的数  
>  随机选取一个位置，用随机选取的token（用户提供的或自动生成的）替换  
>  随机选取一个位置，用随机选取的token（用户提供的或自动生成的）插入
完成上述变异之后会进入`SPLICING`，将2个seed文件随机位置分割开，将当前文件的头同另一个文件的尾拼起来，中间还会检查选取的两个文件的差异性以及拼接之后的文件的变异性。之后再给havoc继续折腾，测试，这个seed搞完再换cycle的下一个，一直到一个cycle结束。
然后就是另一个cycle，新的变异(因为上次变异可能找到了新的路径，cull_queue就是发掘新的路径)
    locate_diffs(in_buf, new_buf, MIN(len, target->len), &f_diff, &l_diff);
        if (f_diff ]
[]
[]
[]
[]
[]
[]
[]
[]