### Performance and Fairness Analysis

#### Slowdowns and Performance Focus
The average and worst-case slowdowns are both limited to 10%, indicating that Hopper's emphasis on performance does not significantly impede job execution. 

#### Probe Ratio in Decentralized Scheduling
An essential aspect of decentralized scheduling is the probe ratio, which is the ratio of the number of queued requests at workers to the number of tasks in a job. A higher probe ratio reduces the likelihood of a task being stuck in the queue of a busy machine but also increases messaging overhead. While the power-of-two choices [38] and Sparrow [36] recommend a probe ratio of 2, our analysis in §5 suggests a probe ratio of 4 is more effective.

**Figure 11: Impact of Probe Ratios on Job Completion**
- **Observations**: As the probe ratio increases from 2, the benefits of Hopper's scheduling and straggler mitigation result in gains up to a ratio of 4. At utilizations of 70% and 80%, a probe ratio of 3.5 also performs well. However, at 90% utilization, gains start to decline even at a probe ratio of 2.5.
- **Conclusion**: Higher probe ratios are generally beneficial, but the benefits diminish at very high utilizations.

### Centralized Hopper's Improvements

To demonstrate that Hopper is suitable for both decentralized and centralized systems, we evaluated it in a centralized setting using Hadoop and Spark prototypes. The results show significant improvements, with gains of approximately 50% for both workloads, and individual job bins improving by up to 80%.

**Figure 12: Centralized Hopper’s Gains Over SRPT**
- **Facebook and Bing Workloads**: Hopper achieves substantial gains, particularly for Spark, due to its shorter task durations and higher sensitivity to stragglers. This leads to more speculative copies, making Hopper's scheduling more critical.

#### DAG Length and Data Locality
- **DAG of Tasks**: Hopper's gains are consistent across varying DAG lengths, as shown in Figure 12. Spark jobs, with fast in-memory map phases, are bottlenecked by intermediate data communication, while Hadoop jobs are less constrained by data transfer and spend more time in the map phase. This difference is captured by the parameter α, as described in §6.3.
- **Data Locality**: Using a relaxation heuristic, we achieve data locality by allowing any k subsequent jobs (as a percentage of total jobs). A small relaxation of k = 3% significantly improves locality in Spark, with gains peaking around this value and then declining beyond k = 7%. Hadoop results follow a similar trend.

**Figure 13: Impact of Locality Allowance (k)**
- **Spark and Hadoop**: Even when enhancing a centralized SRPT scheduler with the locality heuristic, the gains do not exceed 20% compared to SRPT without the heuristic. This indicates that Hopper's primary benefits come from coordinated speculation and scheduling.

### Conclusions

Hopper, the first speculation-aware job scheduler, provides significant performance improvements in both centralized and decentralized settings. Deployed on a 200-machine cluster, Hopper achieves job speedups of 66% in decentralized settings and 50% in centralized settings compared to state-of-the-art schedulers. Hopper is compatible with all current speculation algorithms and incorporates data locality, fairness, and task DAGs, making it a unified speculation-aware scheduling framework.

### Acknowledgments

We thank Michael Chien-Chun Hung, Shivaram Venkataraman, Masoud Moshref, Niangjun Chen, Qiuyu Peng, and Changhong Zhao for their insightful discussions. We also thank the anonymous reviewers and our shepherd, Lixin Gao, for their thoughtful suggestions. This work was supported in part by the National Science Foundation (NSF) with Grants (CNS-1319820, CNS-1423505).

### References

[References listed here as per the original text]

This revised version aims to improve clarity, coherence, and professionalism by structuring the content, providing clear headings, and ensuring smooth transitions between sections.