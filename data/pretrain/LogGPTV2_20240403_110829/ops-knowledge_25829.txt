User: It seems a very common use case but so hard to do in Hadoop (it is possible with WholeFileRecordReader class).
Is it at all possible in Dumbo or Pig?
Does anyone knows a way to process whole files as map tasks using Dumbo or Pig?
Assistant: WholeFileRecordReader means not split the input file? If so, define mapred.min.split.size to a very large value, both mapreduce and Pig will take it.