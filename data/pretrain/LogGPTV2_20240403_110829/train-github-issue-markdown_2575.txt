#### Description
The gradient of tsne blows up on Mac platform, whereas on Linux it works fine.
#### Steps/Code to Reproduce
    from sklearn import manifold, datasets
    data = datasets.load_digits()
    X = data['data']
    n_components = 2
    tsne = manifold.TSNE(n_components=n_components, init='pca', perplexity=30, 
                             random_state=0, verbose=0)
    Y = tsne.fit_transform(X)
#### Expected Results
On Linux it's like:
    [t-SNE] Computing pairwise distances...
    [t-SNE] Computing 25 nearest neighbors...
    [t-SNE] Computed conditional probabilities for sample 1000 / 1797
    [t-SNE] Computed conditional probabilities for sample 1797 / 1797
    [t-SNE] Mean sigma: 6.575750
    [t-SNE] Iteration 25: error = 1.5046589, gradient norm = 0.0049618
    [t-SNE] Iteration 50: error = 1.3538314, gradient norm = 0.0032258
    [t-SNE] Iteration 75: error = 1.2344432, gradient norm = 0.0039027
    [t-SNE] Iteration 100: error = 1.1257976, gradient norm = 0.0020792
    [t-SNE] KL divergence after 100 iterations with early exaggeration: 1.125798
    [t-SNE] Iteration 125: error = 1.0774719, gradient norm = 0.0021276
    [t-SNE] Iteration 150: error = 1.0245292, gradient norm = 0.0012681
    [t-SNE] Iteration 175: error = 0.9789007, gradient norm = 0.0012602
    [t-SNE] Iteration 200: error = 0.9449817, gradient norm = 0.0015506
    [t-SNE] Iteration 225: error = 0.9181468, gradient norm = 0.0011456
    [t-SNE] Iteration 250: error = 0.8979204, gradient norm = 0.0008980
    [t-SNE] Iteration 250: gradient norm 0.000898. Finished.
    [t-SNE] Error after 250 iterations: 0.897920
#### Actual Results
However, on Mac it throws a NaN error:
    [t-SNE] Computing pairwise distances...
    [t-SNE] Computing 91 nearest neighbors...
    [t-SNE] Computed conditional probabilities for sample 1000 / 1797
    [t-SNE] Computed conditional probabilities for sample 1797 / 1797
    [t-SNE] Mean sigma: 8.121136
    [t-SNE] Iteration 25: error = 2.9662576, gradient norm = 147135766419682099200.0000000
    [t-SNE] Iteration 25: error difference 0.000000. Finished.
    ---------------------------------------------------------------------------
    ValueError                                Traceback (most recent call last)
     in ()
          5 tsne = manifold.TSNE(n_components=n_components, init='pca', perplexity=30, 
          6                          random_state=0, verbose=3)
    ----> 7 Y = tsne.fit_transform(X)
    /Users/luyuwang/anaconda/lib/python2.7/site-packages/sklearn/manifold/t_sne.pyc in fit_transform(self, X, y)
        894             Embedding of the training data in low-dimensional space.
        895         """
    --> 896         embedding = self._fit(X)
        897         self.embedding_ = embedding
        898         return self.embedding_
    /Users/luyuwang/anaconda/lib/python2.7/site-packages/sklearn/manifold/t_sne.pyc in _fit(self, X, skip_num_points)
        792                           X_embedded=X_embedded,
        793                           neighbors=neighbors_nn,
    --> 794                           skip_num_points=skip_num_points)
        795 
        796     @property
    /Users/luyuwang/anaconda/lib/python2.7/site-packages/sklearn/manifold/t_sne.pyc in _tsne(self, P, degrees_of_freedom, n_samples, random_state, X_embedded, neighbors, skip_num_points)
        856         opt_args['it'] = it + 1
        857         params, kl_divergence, it = _gradient_descent(obj_func, params,
    --> 858                                                       **opt_args)
        859         if self.verbose:
        860             print("[t-SNE] KL divergence after %d iterations with early "
    /Users/luyuwang/anaconda/lib/python2.7/site-packages/sklearn/manifold/t_sne.pyc in _gradient_descent(objective, p0, it, n_iter, objective_error, n_iter_check, n_iter_without_progress, momentum, learning_rate, min_gain, min_grad_norm, min_error_diff, verbose, args, kwargs)
        387     for i in range(it, n_iter):
        388         new_error, grad = objective(p, *args, **kwargs)
    --> 389         grad_norm = linalg.norm(grad)
        390 
        391         inc = update * grad  129     a = np.asarray_chkfinite(a)
        130 
        131     # Only use optimized norms if axis and keepdims are not specified.
    /Users/luyuwang/anaconda/lib/python2.7/site-packages/numpy/lib/function_base.pyc in asarray_chkfinite(a, dtype, order)
       1213     if a.dtype.char in typecodes['AllFloat'] and not np.isfinite(a).all():
       1214         raise ValueError(
    -> 1215             "array must not contain infs or NaNs")
       1216     return a
       1217 
    ValueError: array must not contain infs or NaNs
#### Versions
Darwin-15.6.0-x86_64-i386-64bit  
('Python', '2.7.12 |Anaconda custom (x86_64)| (default, Jul 2 2016, 17:43:17)
\n[GCC 4.2.1 (Based on Apple Inc. build 5658) (LLVM build 2336.11.00)]')  
('NumPy', '1.12.1')  
('SciPy', '0.19.0')  
('Scikit-Learn', '0.19.dev0')