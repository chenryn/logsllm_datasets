title:Undermining Information Hiding (and What to Do about It)
author:Enes G&quot;oktas and
Robert Gawlik and
Benjamin Kollenda and
Elias Athanasopoulos and
Georgios Portokalidis and
Cristiano Giuffrida and
Herbert Bos
Undermining Information Hiding  
(and What to Do about It)
Enes Göktaş, Vrije Universiteit Amsterdam; Robert Gawlik and Benjamin Kollenda,  
Ruhr Universität Bochum; Elias Athanasopoulos, Vrije Universiteit Amsterdam;  
Georgios Portokalidis, Stevens Institute of Technology; Cristiano Giuffrida  
and Herbert Bos, Vrije Universiteit Amsterdam
 https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/goktas
This paper is included in the Proceedings of the 25th USENIX Security SymposiumAugust 10–12, 2016 • Austin, TXISBN 978-1-931971-32-4Open access to the Proceedings of the 25th USENIX Security Symposium is sponsored by USENIX Undermining Information Hiding
(And What to do About it)
Enes Gökta¸s1 Robert Gawlik2 Benjamin Kollenda2 Elias Athanasopoulos1
Georgios Portokalidis3 Cristiano Giuffrida1 Herbert Bos1
1 Computer Science Institute, Vrije Universiteit Amsterdam, The Netherlands
2 Horst Görtz Institut for IT-Security (HGI), Ruhr-Universität Bochum, Germany
3 Department of Computer Science, Stevens Institute of Technology
Abstract
In the absence of hardware-supported segmentation,
many state-of-the-art defenses resort to “hiding” sensi-
tive information at a random location in a very large ad-
dress space. This paper argues that information hiding
is a weak isolation model and shows that attackers can
ﬁnd hidden information, such as CPI’s SafeStacks, in
seconds—by means of thread spraying. Thread spraying
is a novel attack technique which forces the victim pro-
gram to allocate many hidden areas. As a result, the at-
tacker has a much better chance to locate these areas and
compromise the defense. We demonstrate the technique
by means of attacks on Firefox, Chrome, and MySQL. In
addition, we found that it is hard to remove all sensitive
information (such as pointers to the hidden region) from
a program and show how residual sensitive information
allows attackers to bypass defenses completely.
We also show how we can harden information hiding
techniques by means of an Authenticating Page Mapper
(APM) which builds on a user-level page-fault handler
to authenticate arbitrary memory reads/writes in the vir-
tual address space. APM bootstraps protected applica-
tions with a minimum-sized safe area. Every time the
program accesses this area, APM authenticates the ac-
cess operation, and, if legitimate, expands the area on
demand. We demonstrate that APM hardens informa-
tion hiding signiﬁcantly while increasing the overhead,
on average, 0.3% on baseline SPEC CPU 2006, 0.0% on
SPEC with SafeStack and 1.4% on SPEC with CPI.
1
Introduction
Despite years of study, memory corruption vulnera-
bilities still lead to control-ﬂow hijacking attacks to-
day. Modern attacks employ code-reuse techniques [9,
34] to overcome broadly deployed defenses, like data-
execution prevention (DEP) [5] and address-space layout
randomization (ASLR) [30]. Such attacks are still pos-
sible primarily because of address leaks, which are used
to discover the location of useful instruction sequences,
called gadgets, that can be chained together to perform
arbitrary computations [34].
In response, researchers have been exploring various
directions to put an end to such attacks. A promising
solution is code-pointer integrity (CPI) [24] that aims to
prevent the hijacking of code pointers, and therefore tak-
ing control of the program. The separation of code point-
ers from everything else can be done by employing hard-
ware or software-enforced isolation [39,42], or by hiding
the region where pointers are stored, which is a faster al-
ternative, than software-based isolation, when hardware-
based isolation is not available. This information hiding
(IH) is achieved by placing the area where code point-
ers are stored at a random offset in memory and ensuring
that the pointer to that area cannot be leaked (e.g., by
storing it in a register). For example, safe versions of the
stack, referred to as safe stacks, that only include return
addresses are protected this way both by CPI and ASLR-
guard [26]. This type of IH is also adopted by other de-
fenses [7, 15] that aim to prevent attacks by eliminating
data leaks, which would enable the location of gadgets,
while it has also been adopted in shadow stack [13, 41]
and CFI [27, 43] research.
Reliance on information hiding is, however, problem-
atic. Recently published work [18] developed a memory
scanning technique for client applications that can sur-
vive crashes. It exploits the fact that browsers, includ-
ing Internet Explorer 11 and Mozilla Firefox, tolerate
faults that are otherwise critical, hence, enabling mem-
ory scanning to locate “hidden” memory areas. Before
that researchers demonstrated that it was possible to lo-
cate CPI’s safe region, where pointers are stored [17], if
IH is used instead of isolation.
In this paper, we reveal two new ways for defeating in-
formation hiding, which can be used to expose the “hid-
den” critical areas used by various defenses and subvert
them. The ﬁrst is technique caters to multithreaded appli-
cations, which an attacker can cause a process to spawn
USENIX Association  
25th USENIX Security Symposium  105
multiple threads. Such applications include browsers that
now support threads in Javascript and server applications
that use them to handle client connections. By causing
an application to spawn multiple threads, the attacker
“sprays” memory with an equal number of stacks and
safe stacks. As the address space ﬁlls with these stacks,
the probability of “striking gold” when scanning memory
increases dramatically. We incorporate this technique,
which we coin thread spraying, in the memory scanning
attack described above [18] and show that we can locate
safe regions, such as the safe stacks used by CPI and
ASLR-guard and parallel shadow stacks [14], in seconds
instead of tens of minutes. The second approach utilizes
bookkeeping data of various standard libraries in Linux
such as the POSIX threads library and glibc. Our inves-
tigation reveals several pointers that can lead to safe re-
gions in information kept to manage thread local storage
(TLS) and thread-control blocks (TCB). Isolating these
leftover pointers with a better implementation might be
possible. However, at the time of writing, there is no al-
gorithm for assessing if all sensitive pointers are properly
removed. We therefore argue that a sound implementa-
tion which excludes all pointers that can lead to a safe
region from the rest of the process is challenging.
These two new attack vectors demonstrate that it is
surprisingly hard to use information hiding to replace
strong isolation. Nevertheless, it is possible to further
harden IH and mitigate these attacks. We propose and
develop a technique that aims to shift the odds back in
favor of the defender. Our solution is based on two obser-
vations: ﬁrst, only a small part of the memory allocated
to safe areas is actually used, and, second, safe areas
are usually accessed using well-deﬁned instrumentation-
induced instruction patterns that are distinguishable from
application code. For example, under CPI only a small
part of the safe region and stacks allocated by CPU is
actually used, and, on x86-64 architectures, the gs seg-
ment register and the RSP register are used to access the
safe region and safe stacks, respectively.
Building on these observations, we introduce APM
(Authenticating Page Mapper), an IH hardening strategy
that veriﬁes that all the ﬁrst accesses to inactive pages
in safe areas follow legitimate and unforgeable execu-
tion patterns, increasing in this fashion the entropy of
IH. APM is implemented as a user-level page-fault han-
dler, exploiting the same page “trapping” technique used
by mechanisms like checkpoint/restart [31], hot patch-
ing [4], and ATL+DEP [1]. To further improve security,
APM artiﬁcially inﬂates the virtual memory region re-
served for safe areas. In particular, it decreases the num-
ber of accessible pages on a shadow stack to the min-
imum, but reserves many (initially inaccessible) addi-
tional pages that serve as tripwire. All illegitimate ac-
cesses to non-accessible pages trigger an alarm. Like-
wise, we offset the stack pointer by a random number of
bytes.
In summary, we make the following contributions:
1. We introduce a new attack vector, called thread spray-
ing, that reduces the entropy of information hiding
techniques by creating many threads and ﬁlling up
the memory space with safe areas such as safe stacks.
We demonstrate the practicality of thread spraying
for browsers (Firefox and Chrome) and the MySQL
server, all protected with CPI’s SafeStack, and show
that we can ﬁnd the hidden stacks in seconds.
2. We analyze in detail the strength of information hid-
ing techniques used in state-of-the-art defenses and
show that existing solutions are not free of pointers to
safe areas. Our results enable an adversary to utilize
these pointers to compromise the safe area.
3. We propose a new IH hardening strategy to improve
information hiding by means of a user-level page fault
handler that increases the entropy signiﬁcantly, makes
pages accessible on demand, and vets all ﬁrst-time ac-
cesses to pages—greatly increasing the probability of
detecting an attack. We evaluate the solution using
a variety of applications as well as the SPEC bench-
marks and show that the performance impact is very
low (on average 0.3% on baseline SPEC, 0.0% on
SPEC with SafeStack, 1.4% on SPEC with full CPI
and barely measurable in browser benchmarks).
2 Threat Model
In this paper, we assume a determined attacker that aims
at exploiting a software vulnerability in a program that
is protected with state-of-the-art defenses (e.g., CPI [24]
or ASLR-Guard [26]), and that has the capabilities for
launching state-of-the-art code-reuse attacks [11,16,20].
We also assume that the attacker has a strong primitive,
such as an arbitrary read and write, but the arbitrary read
should not be able to reveal the location of a code pointer
that could be overwritten and give control to the attacker,
unless the safe area is somehow discovered. Under this
threat model, we discuss in Sections 3 and 4 a number
of possible strategies that can leak the safe area to the
attacker. Later in this paper, we propose to harden IH
using a technique that can effectively protect the safe area
with a small and practical overhead.
3 Background and Related Work
In the following, we review relevant work on information
hiding. We discuss both attacks and defenses to provide
an overview of related work and hint at potential weak-
nesses. We show that prior work has already bypassed
106  25th USENIX Security Symposium 
USENIX Association
2
several IH approaches, but these attacks all targeted de-
fenses that hide very large areas (such as the 242 byte safe
area in CPI [17], or all kernel memory [22]). It is a com-
mon belief that smaller regions such as shadow stacks are
not vulnerable to such attacks [26]. Later, we show that
this belief is not always true.
Information Hiding
3.1
Many new defenses thwart advanced attacks by separat-
ing code pointers from everything else in memory. Al-
though the speciﬁcs of the defenses vary, they all share
a common principle:
they must prevent malicious in-
puts from inﬂuencing the code pointers (e.g., return ad-
dresses, function pointers, and VTable pointers). For this
reason, they isolate these pointers from the protected pro-
gram in a safe area that only legitimate code can access
in a strictly controlled fashion.
In principle, software-
based fault isolation (SFI [39]) is ideal for applying this
separation. However, without hardware support, SFI still
incurs nontrivial performance overhead and many de-
fenses therefore opted for (IH) as an alternative to SFI.
The assumption is that the virtual address space is large
enough to hide the safe area by placing it in a random
memory location. Since there is no pointer from the pro-
tected program referencing explicitly the safe area, even
powerful information disclosure bugs [35] are useless. In
other words, an attacker could potentially leak the entire
layout of the protected process but not the safe area.
In recent years, this topic received a lot of attention
and many systems emerged that rely (at least optionally)
on IH. For example, Opaque CFI [27] uses IH for pro-
tecting the so called Bounds Lookup Table (BLT) and
Oxymoron [7] uses IH for protecting the Randomization-
agnostic Translation Table (RaTTle).
Isomeron [15]
needs to keep the execution diversiﬁer data secret while
StackArmor [41] isolates particular (potentially vulnera-
ble) stack frames. Finally, CFCI [44] needs to hide, when
segmentation is not available, a few MBs of protected
memory. Although all these systems rely on IH for a dif-
ferent purpose, they are vulnerable to memory scanning
attacks which try to locate these regions in a brute-force
manner (as shown in Section 4). Since the Authenticat-
ing Page Mapper that we propose in this paper hardens
IH in general, it directly improves the security of all these
systems—irrespective of their actual goal.
3.2 ASLR and Information Leaks
Arguably the best known IH technique is regular Address
Space Layout Randomization (ASLR). Coarse-grained
ASLR is on by default on all major operating systems.
It randomizes memory on a per-module basis. Fine-
grained ASLR techniques that additionally randomize
memory on the function and/or instruction level were
proposed in the literature [19, 29, 40], but have not re-
ceived widespread adoption yet.
In practice, bypassing standard (i.e., coarse-grained,
user-level) ASLR implementations is now common.
From an attacker’s point of view, disclosing a single
pointer that points into a program’s shared library is
enough to de-randomize the address space [36]. Even
ﬁne-grained ASLR implementations cannot withstand
sophisticated attacks where the attacker can read code
with memory disclosures and assemble a payload on the
ﬂy in a JIT-ROP fashion [35].
For kernel-level ASLR, we view kernel memory as an-
other instance of information to hide. From user space,
the memory layout of the kernel is not readable and
kernel-level ASLR prevents an attacker from knowing
the kernel’s memory locations. However, previous work
showed that it is possible to leak this information via a
timing side channel [22].
In general, leaking information by abusing side chan-
nels is a viable attack strategy. Typically, an attacker uses
a memory corruption to put a program in such a state that
she can infer memory contents via timings [10,17,33] or
other side channels [8]. This way, she can even locate
safe areas to which no references exist in unsafe mem-
ory.
In the absence of memory disclosures, attackers may
still bypass ASLR using Blind ROP (BROP) [8], which
can be applied remotely to servers that fork processes
several times.
In BROP, an attacker sends data that
causes a control transfer to another address and then ob-
serves how the service reacts. Depending on the data sent
the server may crash, hang, or continue to run as normal.
By distinguishing all different outcomes, the attacker can
infer what code executed and identify ROP gadgets.
In this paper, we speciﬁcally focus on safe stacks
(which are now integrated in production compilers) and
review recent related solutions below.
3.3 Code-Pointer Integrity (CPI)
CPI is a safety property that protects all direct and indi-
rect pointers to code [24]. CPI splits the address space
in two. The normal part and a signiﬁcantly large safe
area that stores all code pointers of the program. Ac-
cess to the safe area from the normal one is only possi-
ble through CPI instructions. Additionally, CPI provides
every thread with a shadow stack, namely SafeStack, be-
yond the regular stack. The SafeStack is used for stor-
ing return addresses and proven-safe objects, while the
regular stack contains all other data. SafeStacks are rel-
atively small but they are all contained in a large safe
area, which is hidden at a random location in the virtual
address space.
USENIX Association  
25th USENIX Security Symposium  107
3
Evans et al. showed how to circumvent CPI and ﬁnd
the safe area by probing using a side channel [17]. De-
pending on how the safe area is constructed, this attack
may require the respawn-after-a-crash property to pull
off the attack. This property is only available in (some)
servers. Moreover, it is fragile, as it is very easy for an
administrator to raise an alarm if the server crashes often.
In Section 4, we will introduce an attack that demon-
strates how we can efﬁciently locate CPI’s SafeStack in
the context of web browsers.
3.4 ASLR-Guard
ASLR-Guard [26] is a recent defense that aims at pre-
venting code-reuse attacks by protecting code addresses
from disclosure attacks. It does so by introducing a se-
cure storage scheme for code pointers and by decoupling
the code and data regions of executable modules. A core
feature is its shadow stack that it uses to separate com-
pletely the code pointers from the rest of the data. To efﬁ-
ciently implement this idea, again two separate stacks are
used. First, the so called AG-stack which holds only code
addresses is used by function calls and returns, exception
handlers, etc. The second stack is used for any data op-
eration and ensures that all code pointers and pointers to
the AG-stack are encrypted. As a result, an adversary
has no way of leaking the location of code images. We
discuss the security of this design in Section 4.4.
3.5 Discussion
Information hiding has grown into an important building
block for a myriad of defenses. While several attacks
on the randomization at the heart of IH are described in
the literature, it is still believed to be a formidable ob-
stacle, witness the growing list of defenses that rely on
it. Also, since the attacks to date only managed to ﬁnd
secret information occupying a large number of pages, it
seems reasonable to conclude, as the authors of ASLR-
Guard [26] do, that smaller safe areas are not so vulnera-
ble to probing attacks. In this paper, we show that this is
not always true.
4 Breaking Modern Information Hiding
In this section, we introduce two approaches towards un-
covering the hidden information. First, we show how-
ever careful developers of IH approaches are, pointers
to the safe area may still be unexpectedly present in the
unsafe area. While this may not represent fundamental
problems, there are other issues. Speciﬁcally, we show
that an attacker may signiﬁcantly reduce the large ran-
domization entropy for secret data like shadow stacks by
making the program spawn many threads in a controlled
way, or corrupting the size of the stacks that the program
spawns.
4.1 Neglected Pointers to Safe Areas
Safe stack implementations are an interesting target for
an attacker and the ability to locate them in a large vir-
tual address space would yield a powerful attack prim-
itive. As an example, consider CPI’s SafeStack imple-
mentation that is now available in the LLVM compiler
toolchain. Recall that the safe stack implementation of
CPI moves any potential unsafe variables away from the
native stack to make it difﬁcult to corrupt or to gather
the exact address of that stack. Any references to the
safe stack in global memory that the attacker could leak
would therefore break the isolation of SafeStack.
Ide-
ally for an attacker, such pointers would be available
in program-speciﬁc data structures, but we exclude this
possibility here and assume that no obvious information
disclosure attacks are viable. However, even though the
authors diligently try to remove all such pointers, the
question is whether there are any references left (e.g., in
unexpected places).
For this reason, we analyzed the implementation and
searched for data structures that seemed plausible can-
didates for holding information about the location of
stacks. In addition, we constructed a way for an attacker
to locate said stacks without relying on guessing. In par-
ticular, we examined in detail the Thread Control Block