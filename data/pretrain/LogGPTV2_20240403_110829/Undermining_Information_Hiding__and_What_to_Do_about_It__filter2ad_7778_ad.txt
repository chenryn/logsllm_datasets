5.4
We inﬂate safe areas by allocating more virtual address
space than it is needed for the area. For example, when
a new safe stack is allocated, we can request 10 times
the size the application needs. The effect of this inﬂa-
tion is that a larger part of the address space becomes
“eligible” for memory-access authentication, amplifying
our detection surface. Inﬂation is lightweight, since the
kernel only allocates pages and page-table entries after a
page is ﬁrst accessed.
We implement our
inﬂation strategy for SafeS-
tack (CPI’s safe region is naturally “inﬂated” given
the full memory shadowing approach used). To in-
ﬂate thread stacks, our pthread_create() wrap-
per sets the stack size to a higher value (using
pthread_attr_setstacksize()). For the main
stack, initialized by the kernel, we implement inﬂation
by increasing the stack size (using setrlimit()) be-
fore the application begins executing. Similar to CPI, we
rely on the mmap()’s MAP_NORESERVE ﬂag to avoid
overcommitting a large amount of virtual memory in typ-
ical production settings.
To randomize the placement of each safe stack within
the inﬂated virtual memory area, we randomize the initial
value of RSP (moving it upward into the inﬂated area)
while preserving the base address of the stack and the
TCB in place. Since the base address of each stack is
saved in memory (as we describe in Section 4), a memory
leak can exﬁltrate its base address. Our randomization
strategy can mitigate such leaks by moving the safe stack
working set to a random offset from the base address and
exposing guided probing attacks to a large trip hazard
surface in between.
6 Evaluation
In this section, we report on experimental results of our
APM prototype. We evaluate the our solution in terms of
performance, entropy gains (reducing the likelihood at-
tackers will hit the target region), and detection guaran-
tees provided by APM coped with our inﬂation strategy
(authenticating memory accesses to the target region and
raising alerts).
We performed our experiments on an HP Z230 ma-
chine with an intel i7-4770 CPU 3.40GHz and running
Ubuntu 14.04.3 LTS and Linux kernel v4.3. Unless oth-
erwise noted, we conﬁgured APM with the default in-
ﬂation factor of 10x. We repeated all our experiments 5
times and report the median (with little variations across
runs).
Performance To evaluate the APM’s performance we
run the SPEC2006 suite, which includes benchmarks
with very different memory access patterns. For each
benchmark, we prepared three versions: (1) the origi-
nal benchmark, denoted as BL (Baseline), (2) the bench-
mark compiled with CPI’s SafeStack only, denoted as
SS, and (3) the benchmark compiled with full CPI sup-
port, denoted as CPI. Table 2 presents our results. Note
that perlbench and povray fail to run when com-
piled with CPI, as also reported by other researchers [17].
Therefore, results for these particular cases are excluded
from the table.
Not surprisingly, the overhead imposed by APM in all
benchmarks and for all conﬁgurations (i.e., either com-
piled using SafeStack or full CPI) is very low. The geo-
metric mean performance overhead increase is only 0.3%
for BL+APM, 0.0% for SS+APM and 1.4% CPI+APM.
To conﬁrm our performance results, we evalu-
ated the APM-induced overhead on Chrome (version
45.0.2454.93) and Firefox (version 38.0.5) by running
popular browser benchmarks—also used in prior work in
the area [21, 23]—i.e., sunspider, octane, kraken, html5,
balls and linelayout. Across all the benchmarks, we ob-
served essentially no overhead (0.01% and 0.56% ge-
USENIX Association  
25th USENIX Security Symposium  115
11
BL
Apps
133.8 sec
astar
82.6 sec
bzip2
229.4 sec
dealII
19.2 sec
gcc
53.6 sec
gobmk
51.6 sec
h264ref
113.7 sec
hmmer
lbm
248.5 sec
libquantum 274.1 sec
mcf
237.4 sec
349.0 sec
milc
306.8 sec
namd
358.8 sec
omnetpp
263.9 sec
perlbench
121.3 sec
povray
sjeng
397.8 sec
136.0 sec
soplex
410.6 sec
sphinx3
xalancbmk
189.0 sec
geo-mean
BL + APM
SS
1.004x
1.003x
1.008x
0.978x
1.001x
1.000x
0.996x
1.002x
1.004x
1.031x
1.009x
1.000x
0.994x
1.004x
1.005x
1.004x
1.001x
0.987x
1.020x
1.003x
1.003x
1.002x
1.009x
0.982x
1.020x
1.009x
1.001x
1.001x
1.015x
0.998x
0.991x
1.001x
1.017x
1.084x
1.092x
1.047x
1.000x
0.997x
1.042x
1.016x
SS + APM CPI
0.971x
1.039x
0.887x
1.368x
1.046x
1.028x
1.063x
1.154x
1.231x
1.046x
1.012x
1.031x
1.377x
——
——
1.033x
1.000x
1.149x
1.679x
1.111x
1.002x
1.008x
1.013x
0.988x
1.018x
1.013x
0.996x
1.002x
1.013x
0.989x
0.997x
0.997x
1.044x
1.091x
1.093x
1.051x
0.951x
0.995x
1.055x
1.016x
CPI + APM
0.985x
1.055x
0.897x
1.440x
1.046x
1.031x
1.066x
1.159x
1.227x
1.045x
1.023x
1.030x
1.472x
——
——
1.031x
0.997x
1.138x
1.782x
1.125x
Table 2: SPEC CPU 2006 benchmark results. We present the overhead of hardening state-of-the art defenses with APM. BL and SS refer to
baseline and safe stack (respectively), and CPI refers to CPI’s safe area.
ometric mean increas on Chrome and Firefox, respec-
tively). These results conﬁrm that, while APM may in-
troduce a few expensive page faults early in the execu-
tion, once the working set of the running programs is
fully loaded in memory, the steady-state performance
overhead is close to zero. We believe this property makes
APM an excellent candidate to immediately replace tra-
ditional information hiding on today’s production plat-
forms.
Entropy Gains With APM in place, it becomes signif-
icantly harder for an adversary to locate a safe area hid-
den in the virtual address space. To quantify the entropy
gains with APM in place, we ran again the SPEC2006
benchmarks in three different conﬁgurations, including
a parallel shadow stack [14] other than SafeStack and
full CPI. We present results for a parallel shadow stack
to generalize our results to arbitrary shadow stack im-
plementations in terms of entropy gains. A parallel
shadow stack is an ideal candidate for generalization,
since its shadow memory-based implementation con-
sumes as much physical memory as a regular stack,
thereby providing a worst-case scenario for our entropy
gain guarantees.
For each conﬁguration, we evaluated the entropy with
and without APM in place and report the resulting gains.
The entropy gain is computed as log2(V MM/PMM),
where VMM is the Virtual Mapped Memory size (in
pages) and PMM is the Physical Mapped Memory size
(in pages). To mimic a worst-case scenario for our en-
tropy gains, we measured PMM at the very end of our
benchmarks, when the program has accessed as much
memory as possible resulting in the largest resident set
(and lowest entropy gains). Table 3 presents our results.
Once again, as also reported by other researchers [17],
perlbench and povray are excluded from the CPI
conﬁguration.
As expected, our results in Table 3 show that lower
stack usage (i.e., lower PMM) results in higher entropy
gains. Even more importantly, the entropy gains for
CPI-enabled applications are substantial. In detail, we
gain 11 bits of entropy even in the worst case (i.e.,
xalancbmk). In other cases, (e.g., bzip2) the entropy
gains go up to 28 bits of entropy.
We ﬁnd our experimental results extremely encourag-
ing, given that, without essentially adding overhead to
CPI’s fastest (but low-entropy) implementation, our tech-
niques can provide better entropy than the slowest (prob-
abilistic) CPI implementation [25]. SafeStack’s entropy
gains are, as expected, signiﬁcantly lower than CPI’s, but
generally (only) slightly higher than a parallel shadow
stack. In both cases, the entropy gains greatly vary across
programs, ranging between 2 and 11 bits of entropy. This
is due to the very different memory access patterns ex-
hibited by different programs. Nevertheless, our strategy
is always effective in nontrivially increasing the entropy
for a marginal impact, providing a practical and immedi-
ate improvement for information hiding-protected appli-
cations in production.
116  25th USENIX Security Symposium 
USENIX Association
12
Parallel Shadow Stack
VMM PMM EG
DG
SafeStack
VMM PMM EG
DG
CPI’s (safe region)
VMM PMM
EG
DG
Apps
2048
astar
2048
bzip2
2048
gcc
2048
gobmk
2048
h264ref
2048
hmmer
lbm
2048
libquantum 2048
mcf
2048
2048
milc
2048
namd
2048
omnetpp
2048
perlbench
2048
povray
sjeng
2048
2048
soplex
2048
sphinx3
xalancbmk
2048
3
4
112
27
5
3
2
1
2
2
10
34
491
7
132
3
12
496
> 9 bits
9 bits
> 4 bits
> 6 bits
> 8 bits
> 9 bits
10 bits
11 bits
10 bits
10 bits
> 7 bits
> 5 bits
> 2 bits
> 8 bits
> 3 bits
> 9 bits
> 7 bits
> 2 bits
99.99 % 2048
99.98 % 2048
99.45 % 2048
99.87 % 2048
99.98 % 2048
99.99 % 2048
99.99 % 2048
100.00 % 2048
99.99 % 2048
99.99 % 2048
99.95 % 2048
99.83 % 2048
97.60 % 2048
99.97 % 2048
99.36 % 2048
99.99 % 2048
99.94 % 2048
97.58 % 2048
2
1
8
7
2
2
1
2
2