title:Reliability of flat XOR-based erasure codes on heterogeneous devices
author:Kevin M. Greenan and
Ethan L. Miller and
Jay J. Wylie
International Conference on Dependable Systems &Networks: Anchorage, Alaska, June 24-27 2008
Reliability of flat XOR-based erasure codes on heterogeneous devices
Kevin M. Greenan*! Ethan L. Miller! and Jay J. Wylie*
PI:EMAIL, PI:EMAIL, PI:EMAIL
Abstract
XOR-based erasure codes are a computationally(cid:173)
efficient means of generating redundancy in storage sys(cid:173)
tems. Some such erasure codes provide irregularfault toler(cid:173)
ance: some subsets offailed storage devices ofa given size
lead to data loss, whereas other subsets offailed storage de(cid:173)
vices ofthe same size are tolerated. Many storage systems
are composed ofheterogeneous devices that exhibit different
failure and recovery rates, in which different placements(cid:173)
mappings oferasure-coded symbols to storage devices-of
aliat XOR-based erasure code lead to different reliabilities.
We have developed redundancy placement algorithms that
utilize the structure offlat XOR-based erasure codes and a
simple analytic model to determine placements that max(cid:173)
imize reliability. Simulation studies validate the utility of
the simple analytic reliability model and the efficacy ofthe
redundancy placement algorithms.
1. Introduction
Erasure codes such as replication, RAID 5, and Reed(cid:173)
Solomon codes are the means by which storage systems
are typically made reliable. Reed-Solomon codes and other
maximum distance separable (MDS) codesk, provide the
best tradeoff between fault tolerance and space-efficiency,
but are computationally the most demanding type of erasure
code. In addition to these traditional erasure codes, there are
a number of proposals for novel, non-MDS erasure codes
that exclusively use XOR operations to generate redundancy
(e.g., [9, 10, 23]). Such xOR-based codes can be compu(cid:173)
tationally more efficient than MDS codes, but offer an ir(cid:173)
regular tradeoffbetween performance, space-efficiency, and
fault tolerance.
Methods to evaluate the space-efficiency and perfor(cid:173)
mance tradeoff for xOR-based codes are well under(cid:173)
stood [19, 11, 18]. However, some xOR-based erasure
some subsets of
codes exhibit irregular fault tolerance:
failed storage devices of a given size lead to data loss,
whereas other subsets of failed storage devices of the same
size are tolerated. There have been many recent advances in
understanding the fault tolerance [12, 23] and concomitant
reliability [20, 13, 8] of such codes. However, all of these
advances assume a homogeneous set of storage devices that
all fail and recover at similar rates.
The contributions ofthis work are fourfold. First, we de(cid:173)
fine a novel reliability problem in storage systems, the re(cid:173)
dundancy placementproblem. Given a storage system com(cid:173)
prised of heterogeneous storage devices with known failure
and recovery rates, how should erasure-coded symbols be
mapped to devices to maximize reliability? The redundancy
placement problem is trivial for MDS codes because they ex(cid:173)
hibit regular fault tolerance-an m-tolerant MDS code will
never lose data if m devices fail and always lose data if
m + 1 devices fail-so all placements have the same reli(cid:173)
ability. For non-MDS codes though, the redundancy place(cid:173)
ment problem is non-trivial to solve. Second, we propose
a simple analytic model related to mean time to data loss
(MTTDL). The model is called the Relative MTTDL Esti(cid:173)
mate (RME), and it allows the relative reliability of differ(cid:173)
ent placements to be compared in a computationally effi(cid:173)
cient manner. Third, we propose two redundancy place(cid:173)
ment algorithms that use the structure of the xOR-based
erasure code and the RME to determine a placement that
maximizes (estimated) reliability. Fourth, we empirically
demonstrate, via simulation, that the RME correctly orders
different placements with regard to their reliability, and that
the redundancy placement algorithms identify placements
that maximize reliability.
The outline of the paper is as follows. In §2 and §3 we
provide background on erasure codes, replica placement al(cid:173)
gorithms, and our prior work. We describe the RME and our
redundancy placement algorithms in §4; we evaluate them
in §5. We discuss the limitations of our work in §6 and then
conclude in §7.
2. Background
*Hewlett-Packard Labs
tVCSC. Supported by the Petascale Data Storage Institute under De(cid:173)
partment of Energy award DE-FC02-06ER25768.
An erasure code consists of n symbols, k of which
are data symbols, and m of which are parity symbols (re-
1-4244-2398-9/08/$20.00 ©2008 IEEE
147
DSN 2008: Greenan et al.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:15:09 UTC from IEEE Xplore.  Restrictions apply. 
International Conference on Dependable Systems & Networks: Anchorage, Alaska, June 24-27 2008
dundant symbols). We only consider systematic erasure
codes-eodes that keep the original data symbols and solely
add parity symbols-because their use is generally consid(cid:173)
ered a necessity to ensure good common case performance.
A maximum distance separable (MDS) code uses m
redundant symbols to tolerate all erasures of size m or
less [17]. Many MDS codes generate redundancy using k
Galois field multiplies and k - 1 XORs per parity sym(cid:173)
bol (e.g., Vandermonde Reed-Solomon codes). A Galois
field multiplication operation can be transformed into mul(cid:173)
tiple XOR operations (e.g., Cauchy Reed-Solomon codes).
Parity-check array codes are another class of MDS codes
that only use XOR operations to generate redundancy (e.g.,
RAID 4, EVENODD [3], and Row-Diagonal Parity [4]).
Hafner has categorized the construction of array codes
codes with parity symbols in
as HoVer constructions:
both/either Horizontal and/or Vertical dimensions of the ar(cid:173)
ray [10]. The class of codes we study are horizontal codes.
We go beyond this, and refer to the codes we study as flat
codes: horizontal xOR-based codes comprised of exactly
one row (i.e., exactly one symbol, data or parity, per disk).
Flat codes are distinct from most parity-check array codes
which require multiple rows of symbols; RAID 4 is the ex(cid:173)
ception because it is both a parity-check array code and a
flat code.
The impact of erasure code choice on performance is a
well-studied area [11]. In the grid storage community, the
read overhead of certain classes of xOR-based erasure code
is of interest. Plank et al. analyzed the read overhead of
moderate-sized xOR-based codes using Monte Carlo meth(cid:173)
ods [19] and of small-sized codes using deterministic meth(cid:173)
ods [18].
A replica placement algorithm maps replicas to devices.
Traditionally, this is done to improve performance:
to re(cid:173)
duce response time of accesses, to balance load, and for
distributed caching. We exclusively consider the replica
placement problem as it pertains to reliability. We use the
term redundancy placement rather than replica placement
because our emphasis is on the placement of erasure-coded
data and parity symbols.
Our work on redundancy placement differs substantially
from prior work on replica placement. In traditional RAID
(erasure-coded) storage systems, many stripes of size n are
placed on N > n devices for performance reasons (e.g.,
parity declustering to reduce recovery time [1 ]). Thomasian
and Blaum evaluate the reliability impact of various poli(cid:173)
cies for mirrored disks [22], and Lian et al. [15] evaluate
the difference in reliability between random and sequen(cid:173)
tial placement policies for erasure-coded data. Both studies
only consider homogeneous devices. In contrast, the com(cid:173)
petitive hill climbing replica placement algorithm places
many distinct files, each replicated n times, on N hetero(cid:173)
geneous servers in a manner that maximizes the availability
of the least available file [5]. The Multi-Object Assignment
Toolkit (MOAT) places many distinct objects, each repli(cid:173)
cated n times, on N heterogeneous devices to maximize
the availability of multi-object operations in the face of cor(cid:173)
related failures [24].
Replica placement algorithms place n replicas on N > n
devices. Our redundancy placement algorithms place n
erasure-coded symbols on n heterogeneous devices. The
non-MDS nature of flat xOR-based codes makes the re(cid:173)
dundancy placement problem both novel and non-trivial.
There are other non-MDS xOR-based codes, e.g., Weaver
codes [9].
There are many techniques beyond simple redundancy
to improve storage system reliability, such as checksums,
snapshots, scrubbing, auditing, and backup to tape. How(cid:173)
ever, questions such as where to place backup copies or
checksums to maximize reliability are outside of the scope
of this work. Such questions require different models to
answer that necessarily include metrics other than reliabil(cid:173)
ity, such as cost and performance. The work of Gaonkar
et al. [7] automates the design of storage solutions that
meet cost, performance, and reliability requirements. Their
approach essentially solves a replica placement problem
across heterogeneous tiers of storage that employ distinct
reliability mechanisms.
3. Reliability of flat XOR-based codes
In this section, we describe our recent work on evalu(cid:173)
ating the reliability of flat xOR-based codes. First, we re(cid:173)
view the Minimal Erasures List (MEL), a fault tolerance
metric for flat codes [23]. Second, we discuss the Fault
Tolerance Vector (Frv), another fault tolerance metric for
flat codes. Finally, we review the High-Fidelity Reliability
(HFR) Simulator, a Monte Carlo reliability simulator, es(cid:173)
pecially designed to simulate the reliability of (flat) XOR(cid:173)
based codes [8]. The redundancy placement algorithms we
have developed use the structure of the MEL to make place(cid:173)
ment decisions. The Frv is used for comparison purposes
in the evaluation section. The HFR Simulator is used to val(cid:173)
idate the efficacy of the redundancy placement algorithms.
Traditionally, the Hamming distance is used to describe
the fault tolerance of an erasure code: a code tolerates all
sets of erasures smaller than the Hamming distance. The
Hamming distance completely describes the fault tolerance
ofMDS codes, since all erasures at or beyond the Hamming
distance result in data loss. Flat erasure codes can be non(cid:173)
MDS: they tolerate some sets of erasures at and beyond the
Hamming distance. We previously developed the Minimal
Erasures (ME) Algorithm to efficiently analyze a flat era(cid:173)
sure code and characterize its fault tolerance [23].
Consider the following definitions: A set oferasures is a
set of erased symbols; an erasure pattern is a set of erasures
1-4244-2398-9/08/$20.00 ©2008 IEEE
148
DSN 2008: Greenan et al.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:15:09 UTC from IEEE Xplore.  Restrictions apply. 
International Conference on Dependable Systems & Networks: Anchorage, Alaska, June 24-27 2008
that results in at least one data symbol being irrecoverable;
and, a minimal erasure is an erasure pattern in which ev(cid:173)
ery erasure is necessary and sufficient for it to be an erasure
pattern. The ME Algorithm determines the minimal era(cid:173)
sures list (MEL) of an erasure code:
the list of the code's
minimal erasures, which completely describes the fault tol(cid:173)
erance ofan erasure code. The MEL can be transformed into
a minimal erasures vector MEV in which the ith element is
the total number of minimal erasures of size i in the MEL.
The length of the shortest minimal erasure in the MEL is
the Hamming distance of the code, and so the first non-zero
entry in the MEV corresponds to the Hamming distance.
We now present two flat codes in detail to provide exam(cid:173)
ples ofminimal erasures, the MEL, and the MEV. We denote
each code by (k,m)-NAME where k is the number of data
symbols, m is the number of parity symbols, and NAME is
the class of the code. Every code is described by a listing
of m bitmaps, one for each parity symbol, displayed as an
integer. Since we only consider systematic codes, the par(cid:173)
ity symbols are 8k, ... ,8n -1. A bitmap describes the data
symbols that participate in a parity equation and is an in(cid:173)
teger in the range [1, ... ,2 k - 1]. For instance, consider
(4,4)-RAID 10 specified by the parity bitmaps (1,2,4,8).
The first parity symbol for this code, 84, is simply a replica
of 80 and so the bitmap is 1 (i.e., 84 = 80 because 1 = 2°).
A more complex example is (5,3)-FLATwith parity bitmaps
(7,11,29). The first parity symbol for this code, 85, has
bitmap 7 because it is computed as the XOR of data sym(cid:173)
bols 80, 81, and 82 (i.e., 85 = 80 EB 81 EB 82 because
7 = 2° + 21 + 22
).
The (4,4)-RAID 10 code is an example of a common
RAID technique that simply replicates each data symbol.
RAID 10 is a flat erasure code that tolerates any single
disk failure. The MEL for the code is {(80, 84), (81,85),
(83, 87)} and the MEV is (0,4,0,0). The MEL
(82,86),
for (4,4)-RAID 10 is intuitive: whenever any pair of de(cid:173)
vices that store the same replicated symbol fails, data is
lost. The MEV simply summarizes the count of minimal
erasures of each size up to m. The MEL for (5,3)-FLAT is
{(84,87), (80,81,84), (80,81,87), (80,82,86), (80,83,85),
(82,85,87),
(81,82,83),
(0,1,10).
(83,84,86),
This code better illustrates the irregularity that non-MDS
flat codes can exhibit. There is no obvious structure or
symmetry to the sets of device failures which lead to data
loss.
(83,86,87)}, and,
the MEV is
(81,85,86),
(82,84,85),
The Fault Tolerance Vector (FTV) indicates the proba(cid:173)
bility that data is lost given some number of failures. To
construct the FTV, the MEL is transformed into the erasures
list (EL). The erasures list consists of every erasure pattern
for a code. The EL is a super set of the MEL, and every ele(cid:173)
ment in it is either a minimal erasure or a super set ofat least
one minimal erasure. The erasures vector (EV) is to the EL
what the MEV is to the MEL, and is easily determined given
the EL. Finally, the EV is transformed into the FTV. Let the
ith entry of the EV be ei. For a code with n symbols, the
ith entry of the FTV is ei/ (7). The FTV is the complement
of the conditional probabilities vector described by Hafner
and Rao [13].
The High-Fidelity Reliability (HFR) Simulator [8] is sim(cid:173)
ilar to the simulator developed by Elerath and Pecht [6].
Both are Monte Carlo reliability simulators that simulate
disk failure, disk recovery, sector failure, and sector scrub(cid:173)
bing, and both can use Weibull distributions for such failure
and recovery rates. However, the HFR Simulator is high-
fidelity in the sense that it simulates the reliability of non(cid:173)
MDS erasure codes that can tolerate two or more disk fail(cid:173)
ures, with regard to both disk and sector failures. It is non(cid:173)
trivial to extend the methods of Elerath and Pecht in this
manner.
The difficulty in simulating non-MDS codes is in effi(cid:173)
ciently determining if a specific set of failures leads to data
loss. The HFR Simulator has two modes of bookkeeping
that allow it to efficiently determine if a set of device fail(cid:173)
ures leads to data loss: via the MEL, and via the FTV. Using
the MEL permits the HFR Simulator to accurately determine
if a specific set of failures leads to data loss. Therefore, it
is the method we must use to simulate the reliability of a
redundancy placement of a flat code on heterogeneous de(cid:173)
vices. The FTV is a coarse-grained metric that does not
capture the details of a specific placement of symbols on
heterogeneous devices; however, it describes the fault toler(cid:173)
ance of the median placement and so is used for compara(cid:173)
tive purposes in §5.
4. Redundancy placement algorithms
We have developed two redundancy placement algo(cid:173)
rithms that identify placements of erasure-coded symbols
on heterogeneous storage devices with known failure and
repair rates which maximize reliability. One redundancy
placement algorithm is based on brute force computation
and the other is based on simulated annealing.
More formally, let S be the set of symbols in the erasure
code and D be the configuration (set of heterogeneous de(cid:173)