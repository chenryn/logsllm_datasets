# Dependable Initialization of Large-Scale Distributed Software

**Authors:**
- Jennifer Ren
- Rick Buskens
- Oscar J. Gonzalez

**Affiliation:**
Bell Laboratories, Lucent Technologies

**Emails:**
- reny@lucent.com
- rbuskens@lucent.com
- ojgonzale@lucent.com

## Abstract

Most documented efforts in fault-tolerant computing address the problem of recovering from failures that occur during normal system operation. However, before a system can begin performing its duties, it must first successfully complete initialization. For large-scale distributed systems, which may take hours to initialize, a key challenge is tolerating failures that occur during initialization while still completing the process in a timely manner.

In this paper, we present a dependable initialization model that captures the architecture of the system and the interdependencies among its components. We show that overall system initialization may sometimes complete more quickly if recovery actions are deferred rather than immediately initiated upon failure detection. This observation leads us to introduce a recovery decision function that dynamically assesses when to take recovery actions. We then describe a dependable initialization algorithm that combines the dependable initialization model with the recovery decision function to achieve fast initialization.

Experimental results demonstrate that our algorithm incurs lower initialization overhead compared to a conventional initialization algorithm. To our knowledge, this work is the first formal study of the challenges of initializing a distributed system in the presence of failures.

## 1. Introduction

Initialization refers to the process of starting up a system and bringing it to a point where it can begin performing its normal functions. For a system consisting of a single software component, initialization is a straightforward procedure involving creating the component and setting its initial state. However, as the number of system components and their interactions increase, initialization complexity grows due to interdependencies between components. These interdependencies require that initialization actions be properly sequenced to ensure that all conditions are met.

A key challenge for systems with multiple components is to initialize the system as quickly as possible while respecting these interdependencies. For large-scale distributed systems consisting of hundreds or thousands of components (such as in grid computing), naive approaches (e.g., initializing components one at a time) could result in initialization times that take hours. Additionally, failures may occur during initialization, complicating the process further. Restarting the entire initialization procedure from the beginning may not be desirable due to lengthy initialization times, but reinitializing only the failed components may not lead to a successfully initialized system due to dependencies on the failed components.

Traditional fault tolerance research suggests using rollback recovery for failures during initialization. While this approach can be effective, it does not fully optimize recovery actions. Since all state information introduced during initialization is either hard-coded, derived from configuration data, or determined from initialization actions, this state can be easily recreated if a component fails. However, certain operations (e.g., closing a broken communication channel) are still required. This implies that some completed initialization activities may need to be repeated as part of recovery, while others can be skipped.

This paper examines dependable distributed initialization for software systems, where the goal is to bring a distributed system to a point where it can, as quickly as possible, begin performing its normal functions, despite failures that may occur during the initialization procedure. We present a dependable initialization model that captures both the system architecture and the interdependencies among initialization tasks. Using this model, we describe an algorithm for constructing an initialization sequencing graph that allows skipping tasks that do not need to be re-executed as part of failure recovery. We show that deferring recovery activities after a failure is detected can sometimes lead to shorter initialization times. To capture this, we introduce a recovery decision function that dynamically assesses whether recovery actions should be taken immediately or deferred. We then describe a dependable initialization algorithm that combines the dependable initialization model and the recovery decision function to achieve fast initialization. Experimental results demonstrate the effectiveness of our algorithm compared to a conventional initialization algorithm.

The remainder of the paper is organized as follows: Section 2 provides an overview of the system model and the dependable initialization model, proposes a recovery decision function, and describes our dependable initialization algorithm. Section 3 presents experimental results. Section 4 revisits our assumptions. Section 5 discusses related work. Finally, Section 6 concludes the paper.

## 2. Dependable Distributed Initialization

### 2.1. System Model and Assumptions

We model the hardware components of a distributed system as a collection of processors interconnected via a communication network. The system software is modeled as a collection of processes that execute on the processors. Processes represent the smallest execution units that can be started from within an operating system shell. Each process contains one or more application components, which are the atomic units of initialization and recovery in our work. To simplify understanding, we assume that each component has exactly one dedicated thread of execution.

We decompose initialization into a collection of interdependent units of work, called tasks, involving processors, processes, and components. This enables us to identify independent initialization tasks that can execute in parallel, helping to minimize overall system initialization time.

We assume that a centralized coordinator synchronizes initialization and recovery activities for all tasks. It constructs an initialization graph that contains the processors, processes, components, tasks, and their interdependencies. The coordinator triggers the execution of tasks and receives notifications once tasks are completed.

We initially make simplifying assumptions about the failure model. Specifically, we assume that processors and processes fail by crashing ("fail silent") and that application components fail either by crashing or by not responding (e.g., due to deadlocks). Failure of a process is modeled as the failure of all of its components; similarly, failure of a processor is modeled as the failure of all components within all processes executing on the processor. We also assume that network partitions do not occur during system initialization and that failure detection is accurate. These assumptions are made to simplify the discussion, and a more realistic set of assumptions would be used in practice (see Section 4 for further discussion).

### 2.2. Modeling Initialization Dependencies

We model initialization dependencies using an interdependency graph, a directed acyclic graph (DAG) where an arc connects an initialization task \( T_i \) to another task \( T_j \) if there is a dependency of \( T_j \) on \( T_i \). This implies that \( T_i \) must be executed before \( T_j \) can be executed. We call \( T_i \) the parent of \( T_j \), and \( T_j \) is the child of \( T_i \). If \( T_j \) has multiple dependencies, all tasks on which \( T_j \) depends must complete before \( T_j \) can be executed. This allows us to model dependencies within and between components contained in the same or different processes running on the same or different processors.

Dependencies between tasks identify the sequence in which the tasks must be executed. If no failures occur, correct initialization sequencing is achieved by executing a child task as soon as all of its parent tasks have executed. Independent tasks may be executed in parallel. To capture the fact that recovery actions do not require some initialization tasks to be re-executed, we distinguish different types of dependencies. For simplicity, we identify two types of dependencies: sequential and operational.

- **Sequential Dependency**: A sequential dependency of task \( T_j \) on task \( T_i \) simply requires that \( T_j \) cannot execute before \( T_i \) completes. There are no requirements for the component associated with \( T_i \) to remain failure-free during the execution of \( T_j \). An example is where \( T_i \) writes some data to permanent storage that is subsequently accessed by \( T_j \). If the component associated with \( T_i \) fails during the execution of \( T_j \), \( T_j \) can continue execution (assuming the data on permanent storage is not corrupted).

- **Operational Dependency**: An operational dependency of task \( T_j \) on task \( T_i \) specifies that \( T_j \) cannot execute before \( T_i \) completes and that the component associated with \( T_i \) must remain failure-free during the execution of \( T_j \). An example is where \( T_i \) populates a specific region of memory that is accessed by \( T_j \). If the component associated with \( T_i \) fails during the execution of \( T_j \), the contents of the memory region populated by \( T_i \) may be corrupt. For these types of dependencies, recovery actions will require re-executing \( T_i \) before \( T_j \) is re-executed.

Graphically, we represent the tasks as nodes in a graph, with dependencies represented as arcs. We place the label 'S' on an arc to indicate a sequential dependency and 'O' to indicate an operational dependency. Refer to Figure 1. For convenience, we label each task with an identifier that represents a unique initialization task for a specific entity (component or process). The shaded boxes represent fault containment boundaries—components may fail on their own; a process failure implies that all of its components fail; a processor failure implies that all processes executing on the processor fail.

### 2.3. Handling Failures During Initialization

We now describe how to use the interdependency graph to derive a new sequence of initialization activities that enable efficient recovery from failures that occur during initialization. Clearly, all tasks associated with entities that fail must be re-executed. For those entities that remain fault-free, the types of dependencies in the interdependency graph identify which additional initialization tasks are impacted by the failure.

The challenge lies not in identifying initialization tasks impacted by a failure, but in identifying the set of initialization tasks already completed or in progress that must be re-executed. For this purpose, we introduce a recovery graph. A recovery graph is a recomputed interdependency graph containing initialization tasks that must be re-executed in order to complete the initialization process.

Figure 1 shows a small system consisting of three processes and four components (for simplicity, we do not show the processors). Components A and B exist within process P1, component C exists within process P2, and component D exists within process P3. Task P1-0 creates P1, and tasks A1 and B1 create components A and B, respectively. Therefore, task P1-0 must execute before A1 and B1. If a practical system where a failure of component A might require restarting process P1, there must be an operational dependency between tasks P1-0 and A1 (as shown). Once task A1 is executed, task A2 can execute. If task A2 depends only on the successful execution of task A1 and not on any data generated by task A1, then the type of dependency between tasks A1 and A2 is a sequential dependency (this is marked in the figure).

[Figure 1: Interdependency Graph Example]

## 3. Experimental Results

[Insert detailed experimental results here, comparing the performance of the dependable initialization algorithm with a conventional initialization algorithm.]

## 4. Revisiting Assumptions

[Discuss the assumptions made in the model and their implications. Provide a more realistic set of assumptions and discuss how they would affect the results.]

## 5. Related Work

[Discuss related work in the field of fault-tolerant distributed systems and initialization. Compare and contrast the approaches and highlight the contributions of this paper.]

## 6. Conclusion

[Summarize the key findings and contributions of the paper. Discuss the potential for future work and the broader impact of the research.]

---

**Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04)**
**0-7695-2052-9/04 $ 20.00 © 2004 IEEE**
**Authorized licensed use limited to: Tsinghua University. Downloaded on March 20, 2021, at 11:51:18 UTC from IEEE Xplore. Restrictions apply.**