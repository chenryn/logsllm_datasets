program slicing on Smali code [43]. DroidTrace [63] presents
ptrace based dynamic analysis with forward execution capa-
bility. DroidTrace monitors selected system calls of the target
process, and classiﬁes the behaviors through the system call
sequences. Rasthofer combines program slicing and dynamic
execution [51] to further extract values from obfuscated
samples, which include reﬂected function calls, sensitive
values in native code, dynamically loaded code, and other anti-
analysis techniques. Similar works include DeGuard [39] and
TIRO [60]. To extract the cryptographic key of a TLS connec-
tion, DroidKex [54] applies fast extraction of ephemeral data
from the memory of a running process. It then performs partial
reconstruction on the semantics of data structures. ARTIST
provides an Android Runtime Instrumentation Toolkit [42],
which monitors the execution of Java and native code. ARTIST
parses OAT executable ﬁles in memory to ﬁnd classes and meth-
ods of interest, and locate internal structures of the Android
Runtime. AndroidSlicer combines asynchronous slicing for
data modeling and control dependencies in the callbacks [37].
It can locate instructions responsible for model loading/unload-
ing, and track responsible parts based on app inputs. Similarly,
CredMiner investigates the prevalent unsafe uses of developer
credentials [64]. It leverages data ﬂow analysis to identify the
raw form of the embedded credential. Our work also combines
static and dynamic analysis on Android apps, however, with
a different goal of machine learning model extraction.
Prior work on machine learning model extraction focuses
on learning-based techniques targeting ML-as-a-service.
Tramer et. al proposes stealing machine learning models
via prediction APIs [57], since ML-as-a-service may accept
partial feature vectors as inputs and include conﬁdence values
with predictions. Then, Wang et. al [59] extend the attacks by
USENIX Association
30th USENIX Security Symposium    1969
stealing hyperparameters. Other work includes stealing the
functionality of the models [45, 50], querying the gradient to
reconstruct the models [49], exploratory attacks to reverse engi-
neer the classiﬁers [52], and side channel attacks to recover the
models [38]. Our work is orthogonal to these study by targeting
on-device model inference, assuming the attackers having
physical access to the mobile devices running model inference.
Model extraction paves the road for adversarial machine
learning. Prior work [44, 47] fooling the models or bypassing
the check is mostly under the black-box threat model. Once
ML models become white-box, attackers can easily craft
adversarial examples to deceive the learning systems. Our
study shows white-box adversarial machine learning is a real
threat to on-device ML models.
To protect machine learning model as an intellectual
property, watermark technique has been used to detect
illegitimate model uses [36, 62]. Moreover, ﬁngerprinting
has been used to protect model integrity. Chen et al. encodes
ﬁngerprint [40] in DNN weights so that the models can be
attested to make sure it is not tampered or modiﬁed. Our
research supports it with the ﬁnding that model plagiarism is
a realistic problem especially for mobile platforms.
10 Conclusion
We carry out a large scale security analysis of machine learn-
ing model protection on 46,753 Android apps from both the
Chinese and the US app markets. Our analysis shows that on-
device machine learning is gaining popularity in every category
of mobile apps, however, 41% of them are not protecting their
models. For those are, many suffer from weak protection mech-
anisms, such as using the same encrypted model for multiple
apps, and even the encrypted models can be easily recovered
with our unsophisticated analysis. Our impact analysis shows
that model leakage can ﬁnancially beneﬁt attacks with as high
as millions of dollars, and allow attackers to evade model-based
authentication and access user private information. Attackers
both technically can and ﬁnancially are motivated to steal mod-
els. We call for research into robust model protection.
Acknowledgment
The authors would like to thank the paper shepherd Prof.
Konrad Rieck and the anonymous reviewers for their insightful
comments. This project was supported by the National Science
Foundation (Grant#: CNS-1748334) and the Army Research
Ofﬁce (Grant#: W911NF-18-1-0093). Any opinions, ﬁndings,
and conclusions or recommendations expressed in this paper
are those of the authors and do not necessarily reﬂect the views
of the funding agencies.
References
[1] A brief guide to mobile AI chips.
https:
//www.theverge.com/2017/10/19/16502538/
mobile-ai-chips-apple-google-huawei-qualcomm.
[2] Amazon SageMaker Ground Truth pricing. https://aws.
amazon.com/sagemaker/groundtruth/pricing/.
[3] Amazon SageMaker Pricing. https://aws.amazon.com/
sagemaker/pricing/.
[4] Android ml. https://developer.android.com/ml.
[5] Apache MXNet | A ﬂexible and efﬁcient library for deep
learning. https://mxnet.apache.org/.
[6] Apple
core ml.
https://developer.apple.com/
documentation/coreml/core_ml_api/personalizing_a_
model_with_on-device_updates.
[7] Artiﬁcial Intelligence + GANs can create fake celebrity
faces. https://medium.com/datadriveninvestor/artiﬁcial-
intelligence-gans-can-create-fake-celebrity-faces-
44fe80d419f7.
[8] Caffe2 -a lightweight, modular, and scalable deep learn-
ing framework. https://github.com/facebookarchive/
caffe2.
[9] Converting model
https:
//mace.readthedocs.io/en/latest/user_guide/advanced_
usage.html.
to C++ code.
[10] Core ML | Apple Developer Documentation.
https://developer.apple.com/documentation/coreml.
[11] Dynamic instrumentation toolkit for developers, reverse-
engineers, and security researchers. https://frida.re/.
[12] Entropy(information theory).
https://en.wikipedia.
org/wiki/Entropy_(information_theory)#Entropy_as_
information_content.
[13] Face++ - Cognitive Services. https://www.faceplusplus.
com/.
[14] Face++ pricing details
- mobile sdk.
//www.faceplusplus.com/pricing-details/#ofﬂine.
[15] Intel R(cid:13) Software Guard Extensions.
//software.intel.com/en-us/sgx.
https:
https:
[16] MegaFace and MF2: Million-Scale Face Recognition.
http://megaface.cs.washington.edu/.
[17] Megvii’s
Competitors, Revenue, Number
Employees, Funding and Acquisitions.
//www.owler.com/company/megvii.
of
https:
1970    30th USENIX Security Symposium
USENIX Association
[18] Netron. https://lutzroeder.github.io/netron/.
[19] Online Protobuf Decoder. https://protogen.marcgravell.
com/decode.
[20] Over
1.5
Datasets.
a-data-lakes-worth-of-audio-datasets-b45b88cd4ad.
Audio
https://towardsdatascience.com/
Labeled
TB’s
of
[21] Paddle-lite github. https://github.com/PaddlePaddle/
Paddle-Lite.
[22] Protocol Buffers Encoding Rule. https://developers.
google.com/protocol-buffers/docs/encoding#simple.
[23] Salary
for
the Machine
Learning
Engineer.
https://www.linkedin.com/salary/machine-learning-
engineer-salaries-in-san-francisco-bay-area-at-xnor-ai.
has
[24] SenseTime
customers
ners. https://www.forbes.com/sites/bernardmarr/2019/06/17/meet-
the-worlds-most-valuable-ai-startup-chinas-
sensetime/.
700+
part-
and
[25] Strip visible string in ncnn. https://github.com/Tencent/
ncnn/wiki.
[26] Tencent ncnn github. https://github.com/Tencent/ncnn.
[27] TensorFlow. https://www.tensorﬂow.org/.
[28] TF Trusted. https://github.com/dropoutlabs/tf-trusted.
[29] The CMU Multi-PIE Face Database. http://www.cs.cmu.
edu/afs/cs/project/PIE/MultiPie/Multi-Pie/Home.html.
[30] Unity Asset Store - The Best Assets for Game Making.
https://assetstore.unity.com/?category=tools%2Fai&
orderBy=1.
[31] Video Dataset Overview - Sortable and search-
https:
of video dataset.
compilation
able
//www.di.ens.fr/~miech/datasetviz/.
[32] Xiaomi mace github. https://github.com/XiaoMi/mace.
[33] ARM
TrustZone
in
https://medium.com/@nimronagy/
arm-trustzone-on-android-975bfe7497d2, 2019.
Android.
[34] SenseTime. https://www.sensetime.com/, 2019.
[35] The AppInChina App Store
Index.
//www.appinchina.co/market/app-stores/, 2019.
https:
[36] Yossi Adi, Carsten Baum, Moustapha Cisse, Benny
Pinkas, and Joseph Keshet. Turning your weakness
into a strength: Watermarking deep neural networks by
backdooring. In 27th {USENIX} Security Symposium
({USENIX} Security 18), pages 1615–1631, 2018.
[37] Tanzirul Azim, Arash Alavi, Iulian Neamtiu, and Rajiv
Gupta. Dynamic slicing for android. In 2019 IEEE/ACM
41st International Conference on Software Engineering
(ICSE), pages 1154–1164. IEEE, 2019.
[38] Lejla Batina, Shivam Bhasin, Dirmanto Jap, and Stjepan
Picek. Csi neural network: Using side-channels to
recover your artiﬁcial neural network information. arXiv
preprint arXiv:1810.09076, 2018.
[39] Benjamin Bichsel, Veselin Raychev, Petar Tsankov, and
Martin Vechev. Statistical deobfuscation of android
applications. In Proceedings of the 2016 ACM SIGSAC
Conference on Computer and Communications Security,
pages 343–355, 2016.
[40] Huili Chen, Cheng Fu, Bita Darvish Rouhani, Jishen
Zhao, and Farinaz Koushanfar.
DeepAttest: An
End-to-End Attestation Framework for Deep Neural
Networks. 2019.
[41] Yi Chen, Wei You, Yeonjoon Lee, Kai Chen, XiaoFeng
Wang, and Wei Zou. Mass discovery of android trafﬁc im-
prints through instantiated partial execution. In Proceed-
ings of the 2017 ACM SIGSAC Conference on Computer
and Communications Security, pages 815–828, 2017.
[42] Lukas Dresel, Mykolai Protsenko, and Tilo Müller. Artist:
the android runtime instrumentation toolkit. In 2016
11th International Conference on Availability, Reliability
and Security (ARES), pages 107–116. IEEE, 2016.
[43] Johannes Hoffmann, Martin Ussath, Thorsten Holz, and
Michael Spreitzenbarth. Slicing droids: program slicing
for smali code. In Proceedings of the 28th Annual ACM
Symposium on Applied Computing, pages 1844–1851,
2013.
[44] Ling Huang, Anthony D Joseph, Blaine Nelson, Ben-
jamin IP Rubinstein, and J Doug Tygar. Adversarial
In Proceedings of the 4th ACM
machine learning.
workshop on Security and artiﬁcial intelligence, pages
43–58. ACM, 2011.
[45] Matthew Jagielski, Nicholas Carlini, David Berthelot,
Alex Kurakin, and Nicolas Papernot. High-ﬁdelity
extraction of neural network models. arXiv preprint
arXiv:1909.01838, 2019.
[46] Roland Kunkel, Do Le Quoc, Franz Gregor, Sergei
Arnautov, Pramod Bhatotia, and Christof Fetzer. Ten-
sorSCONE: A Secure TensorFlow Framework using
Intel SGX. arXiv preprint arXiv:1902.04413, 2019.
[47] Alexey Kurakin, Ian Goodfellow, and Samy Bengio.
Adversarial machine learning at scale. arXiv preprint
arXiv:1611.01236, 2016.
USENIX Association
30th USENIX Security Symposium    1971
[48] Juhyun Lee, Nikolay Chirkov, Ekaterina Ignasheva,
Yury Pisarchyk, Mogan Shieh, Fabio Riccardi, Raman
Sarokin, Andrei Kulik, and Matthias Grundmann.
On-Device Neural Net Inference with Mobile GPUs.
https://arxiv.org/abs/1907.01989, 2019.
[49] Smitha Milli, Ludwig Schmidt, Anca D Dragan, and
Moritz Hardt. Model reconstruction from model
explanations. arXiv preprint arXiv:1807.05185, 2018.
[50] Tribhuvanesh Orekondy, Bernt Schiele, and Mario Fritz.
Knockoff nets: Stealing functionality of black-box mod-
els. In Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition, pages 4954–4963, 2019.
[51] Siegfried Rasthofer, Steven Arzt, Marc Miltenberger,
and Eric Bodden. Harvesting runtime values in android
applications that feature anti-analysis techniques.
In
NDSS, 2016.
[52] Tegjyot Singh Sethi and Mehmed Kantardzic. Data
driven exploratory attacks on black box classiﬁers in ad-
versarial domains. Neurocomputing, 289:129–143, 2018.
[53] Mark Slee, Aditya Agarwal, and Marc Kwiatkowski.
Thrift: Scalable Cross-Language Services Implemen-
tation. Technical report.
[54] Benjamin Taubmann, Omar Alabduljaleel, and Hans P
Reiser. Droidkex: Fast extraction of ephemeral tls keys
from the memory of android apps. Digital Investigation,
26:S67–S76, 2018.
[55] Shruti Tople, Karan Grover, Shweta Shinde, Ranjita
Bhagwan, and Ramachandran Ramjee.
Privado:
Practical and secure DNN inference. arXiv preprint
arXiv:1810.00602, 2018.
[56] Florian Tramer and Dan Boneh. Slalom: Fast, veriﬁable
and private execution of neural networks in trusted
hardware. arXiv preprint arXiv:1806.03287, 2018.
[57] Florian Tramèr, Fan Zhang, Ari Juels, Michael K Reiter,
and Thomas Ristenpart. Stealing machine learning mod-
els via prediction apis. In 25th {USENIX} Security Sym-
posium ({USENIX} Security 16), pages 601–618, 2016.
[58] Stavros Volos, Kapil Vaswani, and Rodrigo Bruno. Gravi-
ton: Trusted execution environments on GPUs. In 13th
{USENIX} Symposium on Operating Systems Design
and Implementation ({OSDI} 18), pages 681–696, 2018.
[59] Binghui Wang and Neil Zhenqiang Gong. Stealing
hyperparameters in machine learning. In 2018 IEEE
Symposium on Security and Privacy (SP), pages 36–52.
IEEE, 2018.
[60] Michelle Y Wong and David Lie. Tackling runtime-
based obfuscation in android with {TIRO}.
In 27th
{USENIX} Security Symposium ({USENIX} Security
18), pages 1247–1262, 2018.
[61] Mengwei Xu, Jiawei Liu, Yuanqiang Liu, Felix Xiaozhu
Lin, Yunxin Liu, and Xuanzhe Liu. A First Look at Deep
Learning Apps on Smartphones. The World Wide Web
Conference on - WWW ’19, (May):2125–2136, 2019.
[62] Jialong Zhang, Zhongshu Gu, Jiyong Jang, Hui Wu,
Marc Ph Stoecklin, Heqing Huang, and Ian Molloy.
Protecting intellectual property of deep neural networks
with watermarking. In Proceedings of the 2018 on Asia
Conference on Computer and Communications Security,
pages 159–172. ACM, 2018.
[63] Min Zheng, Mingshen Sun, and John CS Lui. Droidtrace:
A ptrace based android dynamic analysis system with
In 2014 international
forward execution capability.
wireless communications and mobile computing
conference (IWCMC), pages 128–133. IEEE, 2014.
[64] Yajin Zhou, Lei Wu, Zhi Wang, and Xuxian Jiang. Har-
vesting developer credentials in android apps. In Proceed-
ings of the 8th ACM Conference on Security & Privacy
in Wireless and Mobile Networks, pages 1–12, 2015.
Appendix A Keywords
for Different ML
Frameworks
Table A1: ML Framework Keywords
Framework Magic
Words
TensorFlow tensorﬂow
MXnet
Mace
mxnet
libmace,
mace_input
ulstracker,
ulsface
ULS
Caffe
NCNN
SenseTime
Framework Magic
Words
caffe
ncnn
sensetime,
st_mobile
neuralnetwork,
lstm,
rnn
Other
cnn,
Note: “TensorFlow Lite” and “TensorFlow” are merged into
one framework.
1972    30th USENIX Security Symposium
USENIX Association