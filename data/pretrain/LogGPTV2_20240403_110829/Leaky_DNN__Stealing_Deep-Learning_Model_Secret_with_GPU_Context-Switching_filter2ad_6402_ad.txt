we set T Hgap (minimum number of N OP per gap) to 6,
Rmin (minimum ratio of operations for an iteration) to 0.8,
and Rmax (maximum ratio) to 1.2. To notice, those numbers
can be adjusted based on the targeted GPU.
Evaluation metrics. We consider the accuracy as the main
metrics to evaluate the prediction. As an example, for conv
ops, we assume there are N conv ops in the victim model,
and their positions on the ground-truth OpSeq are L =. Attacker speculates there are M conv ops
N .
and P of them correctly match L. The accuracy is P
B. Iteration Splitting
This step needs to achieve high accuracy to ensure the
data for the later stages are usable. We tested this step using
the same training and testing models. We count the number
of NOP, ops and the correctly identiﬁed ones for computing
accuracy. Table VI shows the result. As we can see,
the
accuracy is quite high (all over 94%). In addition, we found
9
RESULT FOR ITERATION SPLITTING. CUST. IS SHORT FOR CUSTOMIZED.
TABLE VI
Model
Cust. MLP
ZFNet
VGG16
# Ops (Accuracy)
Op
NOP
203,721 (99.201%)
BUSY 204,914 (99.139%)
NOP
716,600 (94.687%)
BUSY 470,346 (96.316%)
NOP
721,117 (96.456%)
BUSY 514,180 (94.084%)
our heuristics based on T Hgap, Rmin and Rmax are quite
effective to identify gaps between iterations. We rarely detect
gaps as false positives. Achieving high accuracy at this task
also helps us to obtain many “clean” iterations (covers the
entire OpSeq) for the voting task. We use 5 iterations for
voting. Besides, we also evaluated different batch (16 to 512)
and image size (32 to 384) and found their impact is quite
small: on VGG16, the accuracy of identifying NOP ranges
from 96% to 98%.
C. Op Inference
Table VII shows the accuracy of this step. The number of
predicted ops are counted before op collapsing. The accuracy
for customized MLP, ZFNet and VGG16 are in average 90%.
The effectiveness of MoSConS is lower for VGG16 so we
look into its false predictions. We found that most errors occur
at ops like BiasAdd and activation, which is less important
than conv. These errors are also easy to correct because they
show up together at a ﬁxed pattern within the entire OpSeq.
For example, a model usually uses the same type of activation
function. All conv are followed by BiasAdd. Given that our
inference model rarely makes mistakes on key ops like conv
and MatMul, the attacker can correct those misclassiﬁed ops
easily. Also, we found there are alignment issues of ops when
reaching the end of OpSeq. Such issues can be partially
resolved with op collapsing and syntax correction.
D. Hyper-parameter Inference
We evaluated the prediction accuracy for hyper-parameters.
We are able to cover 5 of the 6 sensitive hyper-parameters
deﬁned in Section II. Because some hyper-parameters under
the tested models have constant or limited values, we vary
those hyper-parameters on the proﬁled and tested models just
for this evaluation step. Below are the test settings.
• Filter size. We change the ﬁlter size of VGG19 and
AlexNet to 7 different value (1x1, 3x3, 5x5, 7x7, 9x9,
11x11 and 13x13) under different layers and predict if
those values can be correctly identiﬁed.
• Number of ﬁlters. We vary the number of ﬁlters from
64 to 4096, multiplying 2 on VGG19 and AlexNet.
• Number of neurons. We vary the number of neurons
from 64 to 16384, multiplying by 2 on a customized MLP.
• Stride. We change the stride size from 1 to 4 on VGG19
and AlexNet.
• Optimizer. As the optimizer is implemented as a cuDNN
op, we evaluated whether this can be predicted as well
ACCURACY FOR OP INFERENCE (C= C O N V, B=BI A SAD D, R=RELU, P=PO O L I N G, M=MA TMU L, T=TA N H, S=SI G M O I D). PRE V. AND W/ VT. ARE SHORT
Model
Cust.
MLP
ZFNet
VGG
16
Phase
Pre Vt.
W/ Vt.
Pre Vt.
W/ Vt
Pre Vt.
W/ Vt.
95% 87% 98% 92% 54% -
97% 98% 88% 86% 91% -
82% 99% 77% 73% 88% -
86% 100% 87% 77% 83% -
T
S
Overall
R
98% 98% 98%
97.05%
100% 97% 100% 99.38%
86.25%
92.96%
84.75%
85.81%
-
-
-
-
FOR PRE-VOTING AND WITH VOTING.
TABLE VII
B
-
-
P
-
-
C
-
-
M
97%
99%
TABLE VIII
OVERALL ACCURACY FOR HYPER-PARAMETER PREDICTION.HP1, HP2,
HP3, HP4, HP5 REFER TO THE NUMBER OF FILTERS, FILTER SIZE, THE
NUMBER OF NEURONS, STRIDE AND OPTIMIZER.
Hyper-parameters
Accuracy(%)
HP1
95.71
HP2
88.1
HP3
96.58
HP4
95.89
HP5
92.63
(regarded as model hyper-parameter). Three optimizers
(Adagrad, Adam and GD) are tested.
After the different hyper-parameter values are proﬁled to
train Mhp, we test Mhp on our three tested models. Table VIII
shows the accuracy, ranging from 88.1% to 95.89%. The
accuracy of ﬁlter size is lower, mainly because different values
have little impact on op’s execution time, making the observed
readings more indistinguishable.
E. Layer Sequence Inference
We evaluate to what extent attackers can recover the whole
layer sequence (including hyper-parameters) with the right
order. In this case, continuous identical ops are collapsed to
one op and layers can be derived based on op combinations.
As such, even there are misaligned ops causing errors in op
inference (e.g., ground-truth and the predicted sequence are
CCBR and CCCBR, resulting in 3 misclassiﬁed ops), those
errors can be corrected easily. Table IX shows the results, we
listed 2 rows (ground-truth and predicted structure) for each
model.
We took a closer look at the false predictions and found
they are usually caused by ops with very short execution time.
Speciﬁcally, a VGG16 training iteration (the feed-forward
phase) lasts around 7000 ms, consisting of 130 ops. On aver-
age, an op lasts 54 ms (7000/130). In contrast, each spy kernel
only lasts for 16-19ms. Therefore by expectation, the attacker
can sample each op three times. Nonetheless, the 10 shortest
ops last less than 5 ms, meaning that multiple layers would
be squeezed in one spy sample. Fortunately, those short ops
are usually BiasAdd or activation functions like ReLu that
are less critical than conv. The layers can still be correctly
identiﬁed even when those short ops are misclassiﬁed. We
apply model syntax to edit some incorrect layers, and the ﬁnal
results are shown in the “Predicted structure” row. MoSConS
is able to achieve 100% accuracy following the right layer
sequence for customized MLP and ZFNet, 95.2% for VGG16.
For hyper-parameter prediction, the accuracy is 100%, 76.9%,
and 82.8%.
10
F. Performance Impact of the Attack.
We force GPU context-switching by running spy concur-
rently with the victim. As a result, the performance of the
victim DNN is expected to decrease because of the context-
switching penalties. We assess the performance impact by
comparing the victim’s execution time with and without spy
running. To be noticed is that we launch slow-down attacks
with more spy kernels, further dampening the victim’s perfor-
mance.
In our slow-down attack settings, there are 8 kernels used
by the spy program and it takes 20.9 seconds for the victim to
run one VGG16 iteration. In contrast, when no spy is running,
the victim’s execution time is 431.18ms, indicating 48.5 times
slow down. The number of kernels employed by the spy can
be used to adjust the ratio of slow-down. Speciﬁcally, with
only one kernel, the victim’s execution time is 637.78ms. As
described in Section IV, as training takes hours or days, the
slow-down attack is not easily noticeable.
VI. DISCUSSION
Limitations. 1) We evaluated MoSConS on Nvidia GeForce
GTX 1080 TI. Due to the expense and timing constraints,
we did not experiment with other GPUs. Also, to avoid legal
issues, we did not test MoSConS on the public cloud. On
the other hand, we believe our attack should be effective on
other GPUs and cloud if the same scheduling and context
switching mechanisms are used and the performance counters
can be read by the spy. 2) Due to spy’s low sampling rate,
misclassiﬁcations are prone to occur when an op takes a short
time. We launched slow-down kernels to alleviate this issue
but for the ops that are too short (like ReLu) or executed
at the end of the iteration, the inference accuracy drops. We
will investigate how to address this issue as the next step.
3) MoSConS can reveal some critical hyper-parameters but
not all deﬁned by a model, e.g., shortcut. In addition, the
hyper-parameters not seen by the adversary before cannot be
recovered. 4) So far, MoSConS is designed to infer a model
secret from a single GPU. We will expand MoSConS to multi-
GPU and distributed-learning settings. 5) We tested MoSConS
with two users sharing the same GPU. When more users are
active, the accuracy of MoSConS is expected to decrease
as the kernel execution becomes more non-deterministic. 6)
MoSConS is not supposed to be effective on RNN models
due to their very different designs. 7) MoSConS is effective
on victim models of reasonable complexity, like VGG16. It
is expected to be effective when the model size grows, e.g.,
OVERALL RESULT (EXPLANATION OF OTHER LETTERS ARE IN TABLE VII). RED LETTERS ARE MISCLASSIFICATIONS. ORANGE LETTERS ARE ABOUT
VERY SHORT OPS (FINISHED WITHIN 0.8MS). AccuracyL AND AccuracyHP ARE ACCURACY FOR THE LAYERS AND HYPER-PARAMETERS.
TABLE IX
Model
Cust. MLP
ZFNet
VGG16
Ground-truth
Predicted structure
M64,R − M512,T − M1024,S − M2048,R − M8192,T − OptimizerGD
M64,R − M512,T − M1024,S − M2048,R − M8192,T − OptimizerGD
C7,96,2,R − P − C5,256,2,R − P − C3,512,1,R − C3,1024,1,R − C3,512,1,R − P −
M4096,R − M4096,R − M1000,R − OptimizerAdam
C7,96,2,R − P − C3,256,2,R − P − C3,96,1,R − C3,1024,1,R − C3,512,1,X − P −
M4096,X − M4096,X − M1000,X − OptimizerAdam
C3,64,1,R − C3,64,1,R − P − C3,128,1,R − C3,128,1,R − P − C3,256,1,R − C3,256,1,R −
C3,256,1,R − P − C3,512,1,R − C3,512,1,R − C3,512,1,R − P − C3,512,1,R − C3,512,1,R −
C3,512,1,R − P − M4096,R − M4096,R − M1000,R − OptimizerAdam
C3,64,1,R − C3,64,1,R − P − C3,128,1,R − C3,128,1,R − P − C3,256,1,R − C3,64,1,R −
C3,256,1,R − P − C3,512,1,R − C3,512,1,R − C3,128,1,R − X − C3,512,1,R − C5,256,1,P −
C3,512,1,X − P − M4096,X − M4096,X − M1000,X − OptimizerAdam
AccuracyL AccuracyHP
100.0%
100.0%
100.0%
76.9%
95.2%
82.8%
VGG19. However, for more complex models like ResNet50
with shortcuts, MoSConS is unlikely to infer the model
structure accurately.
Potential defense. To protect
the model secret against
MoSConS,
the intuitive approach is to restrict access to
CUPTI. However, as described in Section II-D, even though
Nvidia released a patch [47] as mitigation, it can be bypassed.
As such, we believe more principled defense mechanisms
are needed. Reducing the precision of CUPTI can interfere
with the spy, but again it could introduce side-effect to the
legitimate applications. Alternatively, GPU can run a daemon
process that detects anomalous contention [10]. In addition,
time-sliced scheduler and warp
the GPU schedulers (e.g.,
scheduler) could be enhanced to protect
the critical GPU
applications (e.g., TensorFlow) and reduce the frequency of
preemption by other suspicious applications. We will imple-
ment and evaluate those potential defense mechanisms.
VII. RELATED WORKS
The research about model stealing with side-channel [5],
[13], [23]–[25], [41], [63], [65] has been summarized in
[41] is closest to our work
Section I. Naghibijouybari et al.
on GPU but only the neuron number of the input
layer
is recovered. For this task, MoSConS can infer the neuron
number of every layer. Below we review other related works.
Conﬁdentiality of machine learning. Our research studies
how machine-learning conﬁdentiality can be breached from
hardware side. Another direction is to look into the weakness
of machine-learning algorithms. Research showed that
the
information about data providers [14], [15], properties of the
training data [3], [17], membership of a sample [20], [34],
[56], model parameters [48], [59], [61] can be inferred when
the model developer publishes its model or allows public API
access. An interesting future work could be combining the
attacks at algorithm and hardware layers.
Information leakage on GPU. GPU is widely used for en-
cryption and graph rendering besides machine learning. Prior
works showed that encryption key can be inferred through
timing and power side-channels [27], [28], [35], [50]. Websites
visited by a user can be inferred as well [32], [41], [68] GPU
side-channels have also been exploited for key loggers [30],
row-hammer attacks [16] and building cover-channels [40].
CPU port contention. Our attack introduces contention
on GPU units for information leakage attacks. A similar
contention-based attack has been explored under CPU exe-
cution port [2], [6], showing secrets from OpenSSL can be
leaked. Our study extends the research of contention-based
side-channel by investigating different hardware, i.e., GPU.
VIII. CONCLUSION
In this paper, we systematically analyzed the issue of