inapplicable against Hypnoguard, as no secrets are processed
before the correct password is entered. For such an example
attack on Xbox, see [29], which only applies to architectures
with LDT (HyperTransport) bus, not Intel’s FSB.
However, more advanced hardware attacks may allow di-
rect access to the DRAM bus, and even extraction of TPM
secrets with an invasive decapping procedure (e.g., [59], see
also [26] for more generic physical attacks on security chips).
Note that the PC platform (except the TPM chip to some
extent) cannot withstand such attacks, as components from
diﬀerent manufactures need to operate through common in-
terfaces (vs. more closed environment such as set-top boxes).
With TPMs integrated into the Super I/O chip, and specif-
ically, with ﬁrmware implementation of TPM v2.0 (fTPM
as in Intel Platform Trust Technology), decapping attacks
may be mitigated to a signiﬁcant extent (see the discussion
in [50] for discrete vs. ﬁrmware TPMs). Hypnoguard should
be easily adapted to TPM v2.0.
8. RELATED WORK
In this section, we primarily discuss related work on mem-
ory attacks and preventions. Proposals for addressing change
of physical possession (e.g., [55, 17]) are not discussed, as
they do not consider memory attacks.
Protection against cold-boot and DMA attacks. So-
lutions to protecting keys exposed in system memory have
been extensively explored in the last few years, apparently,
due to the feasibility of cold-boot attacks [25]. There have
been proposals based on relocation of secret keys from RAM
to other “safer” places, such as SSE registers (AESSE [43]),
debug registers (TRESOR [45]), MSR registers (Amne-
sia [56]), AVX registers (PRIME [18]), CPU cache and debug
registers (Copker [23]), GPU registers (PixelVault [63]), and
debug registers and Intel TSX (Mimosa [24]).
A common limitation of these solutions is that speciﬁc
cryptographic operations must be oﬄoaded from the pro-
tected application to the new mechanism, mandating per-
application changes. They are also focused on preventing
leakage of only cryptographic keys, which is fundamentally
limited in protecting RAM content in general. Also, some
solutions do not consider user re-authentication at wakeup-
time (e.g., [18, 23]). Several of them (re)derive their master
secret, or its equivalent, from the user password, e.g., [43,
45]; this may even allow the adversary to directly guess the
master secret in an oﬄine manner.
Memory encryption. An ideal solution for memory ex-
traction attacks would be to perform encrypted execution:
instructions remain encrypted in RAM and are decrypted
right before execution within the CPU; see XOM [36] for an
early proposal in this domain, and Henson and Taylor [27]
for a comprehensive survey. Most proposals for memory en-
cryption deal with data in use by an active CPU. Our use
of full memory encryption involves the sleep state, when the
CPU is largely inactive. Most systems require architectural
changes in hardware/OS and thus remain largely unadopted,
or designed for specialized use cases, e.g., bank ATMs. Us-
ing dedicated custom processors, some gaming consoles also
implement memory encryption to some extent, e.g., Xbox,
Playstation. Similar to storing the secrets in safer places,
memory encryption schemes, if implemented/adopted, may
address extraction attacks, but not user re-authentication.
Forced hibernation. YoNTMA [34] automatically hiber-
nates the machine, i.e., switch to S4/suspend-to-disk, when-
ever it detects that the wired network is disconnected, or
the power cable is unplugged. In this way, if the attacker
wants to take the computer away, he will always get it in a
powered-oﬀ state, and thus memory attacks are mitigated.
A persistent attacker may preserve the power supply by us-
ing oﬀ-the-shelf hardware tools (e.g., [39]). Also, the at-
tacker can perform in-place cold-boot/DMA attacks.
BitLocker. Microsoft’s drive encryption tool BitLocker
can seal the disk encryption key in a TPM chip, if avail-
able. Components that are measured for sealing include:
the Core Root of Trust Measurement (CRTM), BIOS, Op-
tion ROM, MBR, and NTFS boot sector/code (for the full
list, see [42]).
In contrast, Hypnoguard measures compo-
nents that are OS and BIOS independent (may include the
UEFI ﬁrmware in later motherboard models). In its most
secure mode, Microsoft recommends to use BitLocker with
multi-factor authentication such as a USB device containing
a startup key and/or a user PIN, and to conﬁgure the OS to
use S4/suspend-to-disk instead of S3/suspend-to-RAM [41].
In this setting, unattended computers would always resume
from a powered-oﬀ state (cf. YoNTMA [34]), where no se-
crets remain in RAM; the user needs to re-authenticate with
the PIN/USB key to restore the OS.
BitLocker’s limitations include the following. (1) It un-
dermines the usability of sleep modes as even with faster
SSDs it still takes several seconds to hibernate (approx. 18
seconds in our tests with 8GB RAM in Windows 10 ma-
chine with Intel Core-i5 CPU and SSD). Wakeup is also
more time-consuming, as it involves the BIOS/UEFI POST
screen before re-authentication (approx. 24 seconds in our
tests). On the other hand, RAM content remains unpro-
tected if S3 is used. (2) It is still vulnerable to password
guessing to some extent, when used with a user PIN (but
not with USB key, if the key is unavailable to the attacker).
Based on our observation, BitLocker allows many attempts,
before forcing a shutdown or entering into a TPM lockout
(manufacturer dependent). A patient adversary can slowly
test many passwords. We have not tested if oﬄine password
guessing is possible. (3) BitLocker is not designed for coer-
cive situations, and as such, it does not trigger key deletion
through a deletion password or fail counter. If a user is cap-
tured with the USB key, then the disk and RAM content
can be easily accessed. (4) Users also must be careful about
the inadvertent use of BitLocker’s online key backup/escrow
feature (see e.g., [4]).
Recreating trust after S3 sleep. To re-establish a se-
cure state when the system wakes up from S3, Kumar et
al. [35] propose the use of Intel TXT and TPM for recreat-
ing the trusted environment, in the setting of a VMM with
multiple VMs. Upon notiﬁcation of the S3 sleep, the VMM
cascades the event to all VMs. Then each VM encrypts
its secrets with a key and seal the key with the platform
state. The VMM also encrypts its secrets and seals its con-
text. Thereafter, the VMM loader (hierarchically higher
than the VMM) encrypts the measurement of the whole
memory space of the system with a key that is also sealed.
At wakeup-time, all checks are done in the reversed order.
If any of the measurements diﬀer, the secrets will not be
unsealed. This proposal does not consider re-authentication
at wakeup-time and mandates per-application/VM modiﬁ-
cations. More importantly, sealing and unsealing are per-
formed for each sleep-wake cycle for the whole operating
context: VMM loader, VMM, VMs. Depending on how the
context being sealed is deﬁned, this may pose a severe perfor-
mance issue, as TPM sealing/unsealing is time-consuming;
according to our experiment, it takes more than 500ms to
process only 16 bytes of data.
Unlocking with re-authentication at S2/3/4 wakeup.
When waking up from one of the sleep modes, a locked de-
vice such as an FDE hard drive, may have already lost its
security context (e.g., being unlocked) before sleep. Ro-
driguez and Duda [51] introduced a mechanism to securely
re-authenticate the user to the device by replacing the origi-
nal wakeup vector of the OS with a device speciﬁc S3 wakeup
handler. The user is prompted for the credential, which is di-
rectly used to decrypt an unlock key from memory to unlock
the device (e.g., the hard drive). This approach does not use
any trusted/privileged execution environment, such as Intel
TXT/AMD SVM. Without the trusted measurement (i.e.,
no sealed master key), the only entropy comes from the user
password, which may allow a feasible guessing attack.
Secure deallocation. To prevent exposure of memory-
bound secrets against easy-to-launch warm-reboot attacks,
Chow et al. [10] propose a secure deallocation mechanism
(e.g., zeroing freed data on the heap) to limit the lifetime
of sensitive data in memory. This approach avoids modiﬁ-
cations in application source, but requires changes in com-
pilers, libraries, and OS kernel in a Linux system (and also
cannot address cold-boot attacks). Our solution is also eﬀec-
tive against warm-reboot attacks, but requires no changes
in applications and the OS stack.
Relevant proposals on mobile platforms. Considering
their small sizes and versatile functionalities, mobile devices
are more theft-prone and more likely to be caught with sen-
sitive data present when the user is coerced. CleanOS [58] is
proposed to evict sensitive data not in active use to the cloud
and only retrieve the data back when needed. Sensitive in-
formation is pre-classiﬁed and encapsulated into sensitive
data objects (SDOs). Access to SDOs can be revoked in the
case of device theft and audited in normal operations. Tin-
Man [69] also relies on a trusted server, but does not decrypt
conﬁdential data in the device memory to avoid physical
attacks. Keypad [19], a mobile ﬁle system, provides ﬁne-
grained access auditing using a remote server (which also
hosts the encryption keys). For lost devices, access can be
easily revoked by not releasing the key from the server. All
these proposals require a trusted third party. Also, under
coercion, if the user is forced to cooperate, sensitive data
will still be retrieved. Moreover, the protected secrets in
Hypnoguard might not be suitable for being evicted as they
may be used often, e.g., an FDE key.
Gracewipe.
For handling user secrets in the trusted
execution environment, we follow the methodology from
Gracewipe [70], which operates at boot-time and thus can
rely on BIOS and tboot.
In contrast, Hypnoguard oper-
ates during the sleep-wake cycle, when no BIOS is active,
and tboot cannot be used for regular OSes (tboot assumes
TXT-aware OS kernel). Gracewipe assumes that the at-
tacker can get physical possession of a computer, only when
it is powered-oﬀ, in contrast to Hypnoguard’s sleep state,
which is more common. Gracewipe securely releases sensi-
tive FDE keys in memory, but does not consider protecting
such keys against memory extraction attacks during sleep-
wake. Gracewipe addresses an extreme case of coercion,
where the data-at-rest is of utmost value. We target unat-
tended computers in general, and enable a wakeup-time se-
cure environment for re-authentication and key release.
Intel SGX. Intel Software Guard Extensions (SGX [3]) al-
lows individual applications to run in their isolated context,
resembling TXT with similar features but ﬁner granular-
ity (multiple concurrent secure enclaves along with the in-
secure world). Memory content is fully encrypted outside
the CPU package for SGX-enabled applications. Consider-
ing the current positioning of Hypnoguard, we believe that
TXT is a more preferable choice, as running either the pro-
tected programs or the entire OS in SGX would introduce
per-application/OS changes. TXT also has the advantage
of having been analyzed over the past decade, as well as its
counterpart being available in AMD processors (SVM).
9. CONCLUDING REMARKS
As most computers, especially, laptops, remain in sleep
while not actively used, we consider a comprehensive list
of threats against memory-resident user/OS data, security-
sensitive or otherwise. We address an important gap left
in existing solutions: comprehensive conﬁdentiality protec-
tion for data-in-sleep (S3), when the attacker has physical
access to a computer in sleep. We design and implement
Hypnoguard, which encrypts the whole memory very quickly
before entering sleep under a key sealed in TPM with the
integrity of the execution environment. We require no per-
application changes or kernel patches. Hypnoguard enforces
user re-authentication for unlocking the key at wakeup-time
in a TXT-enabled trusted environment. Guessing attacks
bypassing Hypnoguard are rendered ineﬀective by the prop-
erties of TPM sealing; and guessing within Hypnoguard will
trigger deletion of the key. Thus, Hypnoguard along with
a boot-time protection mechanism with FDE support (e.g.,
BitLocker, Gracewipe [70]) can enable eﬀective server-less
guessing resistance, when a computer with sensitive data is
lost/stolen. We plan to release the source code of Hypno-
guard at a later time, and for now it can be obtained by
contacting the authors.
Acknowledgements
This paper was signiﬁcantly improved by the insightful com-
ments and suggestions from the anonymous reviewers of
CCS 2016, USENIX Security 2016 and EuroSys 2016, as
well as Jonathan McCune. We also appreciate the help we
received from the members of Concordia’s Madiba Security
Research Group. The second author is supported in part by
an NSERC Discovery Grant.
10. REFERENCES
[1] ACPI.info. Advanced conﬁguration and power
interface speciﬁcation. Revision 5.0a (Nov. 13, 2013).
http://www.acpi.info/spec.htm.
[2] AMD. AMD64 architecture programmer’s manual
volume 2: System programming. Technical article
(May 2013). http://developer.amd.com/wordpress/
media/2012/10/24593 APM v21.pdf.
[3] Anati, I., Gueron, S., Johnson, S. P., and
Scarlata, V. R. Innovative technology for CPU
based attestation and sealing. In Hardware and
Architectural Support for Security and Privacy
(HASP’13) (Tel-Aviv, Israel, June 2013).
[4] ArsTechnica.com. Microsoft may have your
encryption key; here’s how to take it back. News
article (Dec. 29, 2015).
[5] Blass, E.-O., and Robertson, W.
TRESOR-HUNT: Attacking CPU-bound encryption.
In ACSAC’12 (Orlando, FL, USA, Dec. 2012).
[6] B¨ock, B. Firewire-based physical security attacks on
windows 7, EFS and BitLocker. Secure Business
Austria Research Lab. Technical report (Aug. 13,