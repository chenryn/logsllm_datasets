Step 3: Enumerating gadget headers. Once we have the
complete list of intersection templates from all the
combinations of given machine templates, we then enu-
merate all the possible gadget headers from the inter-
section templates. We store the headers into a database
with the branch-oﬀset for each machine. We can pre-
compute the gadget header databases and simply fetch
the gadget headers from the database without addi-
tional computation in the future.
4.2 Disassemble and Gadget-Gen
Figure 6: Constructing gadgets and linking them
into a PIP.
RG disassembles programs into a sequence of instructions,
builds a control ﬂow graph, then performs gadget generation
on the CFG basic blocks, as shown in Figure 6.
gadget-gen takes a list of programs [(b1, m1), (b2, m2), ...]
for diﬀerent architectures and outputs a single gadget. Let
|bi| denote the length of bi. Then a suitable gadget header
may have a jump to b1 just after the header, to b2 at oﬀset
|h| + |b1|, to b3 at oﬀset |h| + |b1| + |b2|, and so on. When
|bi| is large, it becomes hard to ﬁnd an appropriate gadget
header, e.g., in our experiment, when |bi| was megabytes in
size it became diﬃcult to ﬁnd a header with a large enough
jump target oﬀset. Basic blocks, instead of whole programs,
make it much more likely RG can ﬁnd an appropriate header.
Optionally, RG can operate at the per-instruction level (by
changing the disassembler to return instructions instead of
basic blocks). The per-instruction level requires more gad-
gets, which in turn creates somewhat larger and slower PIPs.
Additionally, we discuss another possible way of construct-
ing PIP in § 8, which does not require RG to perform the dis-
assemble and gadget-gen steps even though |bi| is larger
than the jump oﬀset.
4.3 Merge
merge takes a list of gadgets, and constructs the ﬁnal PIP
by ensuring each instruction jumps to the next appropriate
gadget, and that each input program terminates appropri-
ately by inserting an appropriate exit call at the end of
the last gadgets. Abstractly, merge also takes each input
program as a sequence of instructions. merge uses this se-
quence to ﬁx up conditional jumps. In RG, we take the CFG
generated by disassemble since we already generated con-
trol ﬂow information to ﬁnd basic blocks. Figure 6 depicts
linking up gadgets.
For each gadget, RG does the following:
• Fixes direct jump targets for machine mi. RG changes
the oﬀset of direct jump instruction, so it points to the
bx86bARMbMIPSbx86BBlock1bARMBBlock1bMIPSBBlock1bx86BBlock2bARMBBlock2bMIPSBBlock2...GadgetHeaderInput Binaries:...bx86BBlock1bx86BBlock2bx86BBlockn...GadgetHeader552ARM r0
x86
ebx
ARM r8
x86
t
r1
ecx
r9
t
r2
edx
r10
t
r3
t
r11
ebp
r4
t
r12
t
r5
edi
r13
esp
r6
esi
r14
t
r7
eax
r15
eip
Table 1: x86-ARM register mapping table.
x86
ADD r32, Imm
AND r32i, r32j
CMP r32i, r32j
INT 0x80
JMP r32
PUSH Imm
ARM
ADD ri, ri, #Imm
AND ri, ri, rj
CMP ri, rj
SVC 0x0
MOV r15, ri
LDR rt, [r15]
.word 0xea000000
.word Imm
STR rt,[r13,#-0x4]!
Table 2: Partial x86-to-ARM instruction mapping
table.
target gadget in the control ﬂow graph for the original
mi program.
• Fixes conditional branch targets for machine mi. This
involves two steps: one for the branch target that
would be executed if the branch predicate is true, and
the other for the fall-through semantics when the branch
predicate is false. RG handles the former by changing
the oﬀset of the branch instruction to point to the ap-
propriate next gadget in the CFG, and the latter by
appending a direct jump to the next gadget in sequen-
tial execution.
4.4 PI Translation
RG works at the binary level, thus cannot simply recom-
pile b1. Binary-level solutions are attractive in security be-
cause it allows us to translate malware for machine m1 into
PIPs for multiple machines. The following is RG’s general
algorithm for solving the PI translation challenge:
1. Precompute register and instruction mapping tables
from m1 to the desired architectures.
2. Translate each instruction in the input binary (b1, m1)
(cid:48)(cid:48) , m3), ....
3. Run the PIP generation algorithm on the output of
to the desired machines (b1, m1), (b1(cid:48) , m2), (b1
step 2.
RG currently implements the mapping from x86 to ARM.
We focus on static interpretation from x86 to ARM because
previous work has not focused on these architectures, e.g.,
UQBT [7] and DAISY [9], yet, in our problem setting, ARM
is an important domain. Currently, RG does not handle typ-
ical problems for static binary translation, such as indirect
jump address problem, but we discuss possible directions in
§ 8.
RG takes care of the ABI diﬀerences between operating
systems on diﬀerent architectures. In Linux on x86, a sys-
tem call is accomplished by ﬁrst placing the relevant system
call number in the eax register and the arguments in ebx,
ecx, edx registers, and then issuing an int 0x80 instruc-
tion. However, in Linux on ARM, a system call is accom-
plished by placing the system call number in the r7 register,
and arguments are passed by r0, r1, r2 registers. Thus,
we match each register accordingly when we generate the
register mapping table. A partial description of RG’s regis-
ter mapping is shown in Table 1, where “t” means that the
corresponding register on ARM can be used as temporary
register.
The instruction mapping table is generated for the atomic
operations, such as add and mov on x86. Table 2 shows
typical instructions as mapped by RG. The table contains
the semantically equivalent operation mappings between two
machines. For example, mov r32d, r32s in x86 is mapped
into mov r32d, r32d, r32s, where the subscript d means
destination and s means source. The push immediate in
particular becomes the sequence of ARM instructions, as
shown in the table.
4.5 Polymorphism
One of the signiﬁcant application domains for PIPs is gen-
erating multi-platform malware. In such domains, syntax-
based signatures are typically the most widely deployed de-
fense mechanisms. We have adapted RG to generate poly-
morphic PIPs, in order to evade syntax-based signature de-
fenses.
RG is the ﬁrst platform to generate PIPs, where there
is control ﬂow between gadgets. As a result, RG can be
augmented to generate polymorphic variants in a number of
typical ways. Consider the following examples:
• Changing jump oﬀsets for gadgets, i.e., we can move
gadget body code bi to diﬀerent oﬀsets by using diﬀer-
ent headers with appropriate jump target oﬀsets.
• Padding gadgets and programs with semantic nops.
• Reordering how blocks are laid out as a sequence of
bytes. Compilers lay out basic blocks on disk via a
compiler trace generation algorithm [3]. 5 However,
there is no single canonical layout, as any permutation
of basic blocks is valid. This approach requires that we
ﬁx up jump targets in a way similar to what is already
performed by Merge.
• Flipping branch conditionals. We can simply change
the branch type and ﬂip the oﬀset, e.g., change jo to
jno on x86 and ﬁx up the appropriate jump targets.
Alternatively, we can negate the branch conditional (as
above) and negate the branch conditional.
• Replacing instructions with semantically equivalent ones.
RG already analyzes the type of instructions via trans-
lation. We can build a similar table for translating in-
structions to semantically equivalent variants, e.g., by
replacing all x86 multiplications by 2 with left shifts
by 1.
We also note that, by deﬁnition, behavior-based detection
is not straight-forward, as a PIP may have benign behaviors
under one platform, but malicious behaviors when executed
on another.
4.6 Platform-Independent Code Injection
A second signiﬁcant domain for PIPs is shellcode. In real
scenarios, we must consider two important properties: the
size of the shellcode, and removing NULL bytes.
The size of shellcode string is important because many
attacks require that both ﬁt within a limited amount of
space. Currently, RG uses only a single gadget when cre-
ating PI shellcodes, in order to minimize the overhead due
to gadget headers. Suppose we are given shellcodes (b1, m1)
for a vulnerable server on m1, and (b2, m2) for the sample
vulnerable server running on m2 (potentially produced via
5The concept of trace here should not be confused with dy-
namic execution traces. In this context, trace generation is
purely a static analysis.
553translation). RG will produce a single PI shellcode h||b1||b2,
instead of disassembling b1 and b2 and introducing head-
ers for each instruction or block. In our experiments, this
is suﬃcient to produce real PI shellcode. Nonetheless, it is
possible that the resulting multi-gadget PI shellcode is larger
than the size of the writable memory, and our shellcode may
not work while the minimum-sized one would. We leave as
future work optimizations to address this issue.
A second issue is that shellcodes typically cannot have
NULL bytes, but PIP generation may introduce them. RG
handles this by performing an additional processing step
that replaces any NULL bytes introduced by gadget gener-
ation (e.g., in the gadget header) with semantic equivalents
that do not contain NULL bytes. For example, the ARM en-
coding for instructions using r0 will introduce NULL bytes.
In order to generate shellcode free of NULL bytes, we en-
code the shellcode and prepend a corresponding decoder at
the beginning of the shellcode to eliminate the NULL bytes,
as seen in [10].
5.
IMPLEMENTATION
RG is currently implemented in about 5k lines of a mix-
ture of C++ and Ruby. RG uses the GNU Binutils opcode
library to decode the binary string into the assembly lan-
guage. RG consists of three command-line programs. The
gadget ﬁnder program ﬁnds all the possible 4-byte, 8-byte,
and 12-byte gadget headers 6 and constructs the table in a
MySQL database. The PI generator program merges two
binary programs that run on diﬀerent architectures into a
single ELF binary. The PI translator program takes an x86
binary and outputs a PI program for x86 and ARM.
6. EVALUATION
We evaluated our techniques and RG for PIP generation
on three diﬀerent platforms: x86 (IA32), ARM (speciﬁcally,
ARM7TDMI), and MIPS (speciﬁcally, MIPS32). We fo-
cused on these platforms because, currently, they appear to
be the most popular in typical security-relevant scenarios.
We performed PI translation on x86 and ARM.
Our evaluation highlights three signiﬁcant points:
1. Section 6.2 shows that while there are a large num-
ber of headers (e.g., up to 66,092 4-byte headers for
ARM and x86), they are relatively rare to ﬁnd (e.g.,
66,092 is about 0.0015% of the total possible 32-bit se-
quences). Our template-based strategy was necessary
to eﬃciently explore such a large state space. Headers
must be at least 12-bytes for tri-platform gadgets, but
4 byte headers exist for bi-platform gadgets. One inter-
esting point is we found valid headers for architectures
that use diﬀerent endianness, e.g., MIPS little endian
and ARM big endian.
2. Section 6.3 shows that RG can ﬁnd a Turing-complete
set of gadgets and create realistic PIP by creating
PIPs at the instruction level for a CPU-intensive pro-
gram demonstrating conditional and looping control
ﬂow (Prime Checker), the standard “hello world” pro-
gram, and a number of popular shellcode used in prac-
tice.
6We choose the size of gadget header as multiple of four,
because the size of a single instruction of MIPS and ARM
is four.
Architectures
x86 + ARM
x86 + MIPS
ARM + MIPS
x86 + ARM + MIPS
# of valid instructions
815,891,149
908,451,552
1,918,735,696
528,989,737
Table 3: Count of 32-bit numbers successfully de-
coded as an instruction on multiple platforms.
3. Section 6.4 demonstrates that RG can be used to create
steganographic malware that is safe on ARM, but a
virus on x86.
Machines. PIP generation and translation steps were per-
formed on an Intel Pentium D CPU 2.80GHz with 4GB of
RAM. We tested the resulting PIPs on a Nokia’s N800 and
Apple’s iPhone for ARM, SGI’s O2 for MIPS, and the above
Intel machine for x86. All the machines were running on the
Linux (Debian) or Linux equivalent OS, e.g. Maemo in N800
is based on the Debian Linux. In order to test performance,
we compared the running time of all PIPs on the x86 hard-
ware above using QEMU version 0.9.1.
6.1 Instruction Validity
We ﬁrst calculated the approximate instruction density
for each architecture. We enumerated all instructions up