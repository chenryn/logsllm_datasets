smaller than those injected into CEToolbox; and the runtime
overhead of PhotoGallery is lower than that of CEToolbox.
Tp App Perf.
(sec) Overhead
208
115
227
152
12.4%
6.4%
8.6%
7.8%
To understand the reason why the runtime overhead of
CatLog is particular higher than others’, we examined its source
code. CatLog is an app showing a scrolling view of the Android
“Logcat” system log, which has multiple reading log procedures
that read logs line by line to examine the context of logs
(e.g., similar to text searching). The reading log procedures
are usually coded as highly repetitive loop statements (e.g.,
while((line=read.readLine())!=null)). If one or more nodes are
placed within the highly repetitive loop, they will be executed
as many times as the loop iterates, which will greatly sacriﬁce
the performance. Although during the injection, we utilize
Traceview to exclude the “hot” methods, we do not exclude
the highly repetitive loops. Indeed, in many cases, the nodes
do not need to execute over and over again if all they do is to
repeat the same self-checking or response action.
To improve the performance, one can opt for a smarter
injection strategy. One strategy is to avoid injecting nodes
within the performance-sensitive code segments. For instance,
one can generate the CFGs of each candidate method, and then
exclude the highly repetitive loops so that none of the nodes will
be injected into these loops. In this way, one can quantitatively
evaluate the trade-off between the runtime overhead and the
resilience based on the demand. Another strategy is to declare a
boolean variable for each node to make sure that it will execute
only once. We adopted the second strategy and generated
another set of the protected apps containing exactly the same
number of the detection and response nodes except that in
this case each node would execute only once. We redid the
experiment and calculated the new runtime overhead; the new
result for CatLog is reduced to 8.2%.
From the results, we can see that SSN incurs relatively small
runtime overhead to the protected apps, and thus is efﬁcient to
defend apps against repackaging.
VIII. DISCUSSION
Impacts. SSN is the ﬁrst work reported in the open
literature that prevents repackaged apps from working on user
devices without relying on authorities. It builds a complex
stochastic stealthy network of defences into apps, such that
repackaged apps cannot run successfully on user devices. Unlike
repackaging detection techniques based on code similarity
comparison that can be easily evaded by various obfuscations,
SSN can resist this kind of evasion attacks. No matter whether
an app is obfuscated by attackers in order to bypass the code
similarity checking, as long as it has been built with the
repackage-prooﬁng protection before releasing, the repackaged
app cannot run successfully on user devices, which limits its
559
propagation as well as its harms to the ﬁnancial security of
app developers and user privacy. Thus, repackage-prooﬁng that
stops repackaged apps from working is a promising direction
in defeating the prevalent repackaging attacks.
Limitations. There are several limitations of SSN. First,
although SSN has good resiliency to many evasion attacks
(as showed in our evaluation), we do not guarantee that
determined attackers cannot disable our protection from an
app. For example, the attacker may spend much effort and time
monitoring the app’s execution to identify the code region for
the detection nodes. Or he may leverage a better taint analysis
techniques (if available) to taint both the communication
mediums and packages.xml, to obtain the tainted data ﬂow
revealing the injected nodes.
Attackers can inspect the app code manually to pinpoint
the nodes and make any code modiﬁcations necessary to
disable/remove them. Note that attackers do not need to remove
every last node to successfully repackage an app. As long as
they ensure that the repackaged app can work properly long
enough (e.g., one hour, or longer), they tend to be satisﬁed.
Each time after removing a node, attackers need to conﬁrm
the functionality of the app is not broken and the node is
successfully bypassed.
However, because of the stochastic response mechanism,
they cannot be sure. Moreover, we can also selectively inject
many spurious nodes to confuse attackers and increase their
uncertainty. Furthermore, as multiple nodes are injected in terms
of the execution paths, attackers have to iterate this attack as
many times to visit sufﬁcient execution paths for guaranteeing
the safety of republishing the app. To increase their risks, we
can opt for injecting nodes that notify users the app has been
repackaged and may be dangerous, into infrequently executed
paths or methods. This way, even only those nodes are remained,
and activated only once or twice a day or month, there is still
chance that users are informed of the danger and report it to
Google Play, which then removes the repackaged app from all
user devices. We leave these as our future work.
Another limitation is that attackers can conduct hijacking
vtable attacks, which either overwrite a virtual table pointer or
manipulate a virtual function pointer, to bypass the repackaging
checking. We refer the reader to Section VI-C for details. There
exist many techniques addressing this problem in the literature
that can be adopted [55], [31], [23], [40].
It is widely recognized that any software-based protection
can be bypassed as long as a determined attacker is willing to
spend time and effort, which is also true with our protection.
We assume attackers are interested in repackaging an app only
if it is cost-effective, for example, when the cost of repackaging
is less than that of developing the app themselves.
IX. RELATED WORK
runtime, which needs no hash value comparison. Cappaert
et al. [5] also propose an approach which enciphers code at
runtime, relying on other code as key information; this way, any
tampering will cause the code to be decrypted with a wrong
key and produce incorrect code.
B. Self-checksumming based approaches.
Chang et al. [6] deﬁne small pieces of code called guards,
to compute checksums over code fragments. However, the code
checking operation has to involve a call to a custom class loader,
and thus can be easily found and bypassed; moreover, the guards
are hard to automatically constructed and the maintenance
cost is very high. Horne et al. [26] extend this technique
and utilize testers and correctors that redundantly test for
changes in the executable code as it is running and report
modiﬁcations. Tsang et al. [11] implement a large number
of lightweight protection units to protect any critical regions
of a program from being modiﬁed. This protection scheme
supports non-deterministic execution of functions, resulting in
different execution paths and nondeterministic tamper responses.
Our stochastic response mechanism is inspired by it and has
a similar fashion. Jakubowski et al. [29] present software
integrity checking expressions, which are program predicates, to
dynamically check whether or not a program is in a valid state.
Jakubowski et al. [30] further propose a scheme to transform
programs into tamper-tolerant versions that use self-correcting
operation as a response against attacks; it chops a program into
blocks, which are duplicated, individualized, and rearranged.
C. Oblivious hashing based approaches.
Chen et al. [10] propose oblivious hashing that implicitly
computes a hash value based on the actual execution of the
code to verify the runtime behaviour of the software; however,
it requires pre-computation of expected hash values under
all possible inputs; thus, it can only be applied to relatively
simple functions that produce deterministic hash values. Chen
et al. [7] propose a tamper-prooﬁng software technology for
stack-machine based languages, such as Java, by improving
oblivious hashing. Jacob et al. [28] present an approach which
overlaps a program’s basic blocks so that they share instruction
bytes to improve the tamper-resistance.
One work we know of aiming to improve the stealthiness of
the tamper-response mechanism is that of Tan et al. [48]. They
introduce a delayed and controlled tamper response technique
which makes it difﬁcult to detect tamper responses; the delayed
failures are achieved by corrupting a global pointer at well-
chosen locations. Although their technique is more tamper-
resistant than others that directly cause programs to fail, it still
reveals information to attackers for ﬁnding tamper responses.
Unlike their approach, we attempt to cause the delayed logical
malfunctions, such that it is very difﬁcult to ﬁnd the failure
points, as well as trace back to the protection code.
A. Code encryption and decryption based approaches.
Aucsmith [3] proposes an approach utilizing cryptographic
methods to decrypt and encrypt code blocks before and after
each execution round. However, this method cannot be done in
a stealthy way in bytecode and does not scale well because of
the time taken by encryption and decryption. Wang et al. [50]
propose a dynamic integrity veriﬁcation mechanism designed to
prevent modiﬁcation of software. The mechanism utilizes multi-
blocking encryption technique to encrypt and decrypt code at
X. CONCLUSION
To the best of our knowledge, there is no study that
investigates repackage-prooﬁng to prevent repackaged apps
from working on user devices. In this paper, we conduct a
preliminary ﬁrst-step study on the problem and introduce a
repackage-prooﬁng technique called SSN, Stochastic Stealthy
Network, which provides a reliable and stealthy protection for
Android apps. We have developed a prototype. Our experimental
results show that SSN is effective and efﬁcient.
560
XI. ACKNOWLEDGEMENT
This work was supported in part by NSF CCF-1320605,
NSF CNS-1422594, NSF CNS-1223710, and ARO W911NF-
13-1-0421 (MURI).
REFERENCES
[1] Adbi, https://github.com/crmulliner/adbi.
[2] Apktool, https://ibotpeaches.github.io/Apktool/.
[3] D. Aucsmith, “Tamper resistant software: An implementation,” in
Information Hiding, 2005.
[4] R. Bhoraskar, S. Han, J. Jeon, T. Azim, S. Chen, J. Jung, S. Nath,
R. Wang, and D. Wetherall, “Brahmastra: Driving apps to test the
security of third-party components,” in USENIX Security, 2014.
J. Cappaert, B. Preneel, B. Anckaert, M. Madou, and K. D. Bosschere,
“Towards tamper resistant code encryption: Practice and experience,” in
ISPEC, 2008.
[5]
[6] H. Chang and M. J. Atallah, “Protecting software code by guards,” in
Security and Privacy in Digital Rights Management, 2002.
[7] H.-Y. Chen, T.-W. Hou, and C.-L. Lin, “Tamper-prooﬁng basis path by
using oblivious hashing on Java,” in Information Hiding, 2007.
[8] K. Chen, P. Liu, and Y. Zhang, “Achieving accuracy and scalability
simultaneously in detecting application clones on Android markets,” in
ICSE, 2014.
[9] K. Chen, P. Wang, Y. Lee, X. Wang, N. Zhang, H. Huang, WeiZou, and
P. Liu, “Finding unknown malice in 10 seconds: Mass vetting for new
threats at the Google-Play scale,” in USENIX Security, 2015.
[10] Y. Chen, R. Venkatesan, M. Cary, R. Pang, S. Sinha, and M. H.
Jakubowski, “Oblivious hashing: A stealthy software integrity veriﬁcation
primitive,” in Information Hiding, 2002.
[11] H. chung Tsang, M.-C. Lee, and C.-M. Pun, “A robust anti-tamper
protection scheme,” in ARES, 2011.
[12] C. Collberg, G. Myles, and A. Huntwork, “SandMark–A tool for software
protection research,” IEEE Security and Privacy, 2003.
[13] C. S. Collberg and C. Thomborson, “Watermarking, tamper-prooﬁng,
and obfuscation-tools for software protection,” TSE, 2002.
J. Crussell, C. Gibler, and H. Chen, “Attack of the clones: Detecting
cloned applications on Android markets,” in ESORICS, 2012.
[14]
[15] ——, “Scalable semantics-based detection of similar Android applica-
tions,” in ESORICS, 2013.
[16] C.
Davies,
http://www.slashgear.com/95-android-game-piracy-
experience-highlights-app-theft-challenge-15282064/.
[17] DDMS, http://developer.android.com/tools/debugging/ddms.html.
[18] L. Deshotels, “Inaudible sound as a covert channel in mobile devices,”
in USENIX WOOT, 2014.
[19] W. Enck, P. Gilbert, B.-G. Chun, L. P. Cox, J. Jung, P. McDaniel, and
A. N. Sheth, “TaintDroid: An information-ﬂow tracking system for
realtime privacy monitoring on smartphones,” in OSDI, 2010.
[20] F-Droid, “Free and Open Source Software Apps for Android,” https://f-
droid.org/.
[21] A. P. Felt, E. Chin, S. Hanna, D. Song, and D. Wagner, “Android
permissions demystiﬁed,” in CCS, 2011.
[22] W. Gasior and L. Yang., “Exploring covert channel in Android platform,”
in CyberSecurity, 2012.
[23] R. Gawlik and T. Holz, “Towards automated integrity protection of C++
virtual function tables in binary programs,” in ACSAC, 2014.
[24] S. Hanna, L. Huang, E. Wu, S. Li, C. Chen, and D. Song, “Juxtapp: A
scalable system for detecting code reuse among Android applications,”
in DIMVA, 2013.
[25] A. Henderson, A. Prakash, L. K. Yan, X. Hu, X. Wang, R. Zhou,
and H. Yin, “Make it work, make it right, make it fast: building a
platform-neutral whole-system dynamic binary analysis platform,” in
ISSTA, 2014.
[26] B. Horne, L. Matheson, C. Sheehan, and R. E. Tarjan, “Dynamic self-
checking techniques for improved tamper resistance,” in Proceedings of
the 1st ACM Workshop on Digital Rights Management (DRM), 2002.
[27] H. Huang, S. Zhu, P. Liu, and D. Wu, “A framework for evaluating
mobile app repackaging detection algorithms,” in Trust and Trustworthy
Computing, 2013.
561
[28] M. Jacob, M. H. Jakubowski, and R. Venkatesan, “Towards integral
binary execution: Implementing oblivious hashing using overlapped
instruction encodings,” in Proceedings of the 2007 ACM Multimedia
and Security Workshop, 2007.
[29] M. H. Jakubowski, P. Naldurg, V. Patankar, and R. Venkatesan, “Software
integrity checking expressions (ICEs) for robust tamper detection,” in
Information Hiding, 2007.
[30] M. H. Jakubowski, N. Saw, and R. Venkatesan, “Tamper-tolerant
software: Modeling and implementation,” in IWSEC, 2009.
[31] D. Jang, Z. Tatlock, and S. Lerner, “SAFEDISPATCH: Securing C++
virtual calls from memory corruption attacks,” in NDSS, 2014.
[32] Y.-C. Jhi, X. Wang, X. Jia, S. Zhu, P. Liu, and D. Wu, “Value-based
program characterization and its application to software plagiarism
detection,” in ICSE, 2011.
[33] H. S. Karlsen, E. R. Wognsen, M. C. Olesen, and R. R. Hansen, “Study,
formalisation, and analysis of Dalvik bytecode,” in the 7th Workshop on
Bytecode Semantics, Veriﬁcation, Analysis and Transformation, 2012.
[34] T. Lengauer and R. E. Tarjan, “A fast algorithm for ﬁnding dominators
in a ﬂowgraph,” in TOPLAS, 1979.
[35] C. Linn and S. Debray, “Obfuscation of executable code to improve
resistance to static disassembly,” in CCS, 2003.
[36] D. Low, “Protecting Java code via code obfuscation,” in Crossroads’98.
[37] Z. P. Ltd, “Java obfuscator–Zelix KlassMaster,” http://www.zelix.com/
klassmaster/features.html.
[38] L. Luo, J. Ming, D. Wu, P. Liu, and S. Zhu, “Semantics-based
obfuscation-resilient binary code similarity comparison with applications
to software plagiarism detection,” in FSE, 2014.
[39] A. Machiry, R. Tahiliani, and M. Naik, “Dynodroid: An input generation
system for Android apps,” in FSE, 2013.
[40] M. R. Miller and K. D. Johnson, “Using virtual table protections to
prevent the exploitation of object corruption vulnerabilities,” 2012, US
Patent App. 12/958, 668.
[41] Monkey,
concepts.html.
http://developer.android.com/tools/help/monkeyrunner_
[42] R. Potharaju, A. Newell, C. Nita-Rotaru, and X. Zhang, “Plagiarizing
smartphone applications: attack strategies and defense techniques,” in
ESSoS, 2012.
[43] ProGuard, http://proguard.sourceforge.net.
[44] Randoop, https://code.google.com/p/randoop/.
[45] C. Ren, K. Chen, and P. Liu, “Droidmarking: Resilient software
watermarking for impeding Android application repackaging,” in ASE’14.
[46] Robotium, https://code.google.com/p/robotium/.
[47] Shielf4J, http://shield4j.com/.
[48] G. Tan, Y. Chen, and M. H. Jakubowski, “Delayed and controlled failures
in tamper-resistant systems,” in Information Hiding, 2006.
[49] Traceview, http://developer.android.com/tools/help/traceview.html.
[50] P. Wang, S. kyu Kang, and K. Kim, “Tamper resistant software through
dynamic integrity checking,” in SCIS, 2005.
[51] R. Xu, H. Saïdi, and R. Anderson, “Aurasium: Practical policy enforce-
ment for Android applications,” in USENIX Security, 2012.
[52] W. Yang, Y. Zhang, J. Li, J. Shu, B. Li, W. Hu, and D. Gu, “AppSpear:
Bytecode decrypting and DEX reassembling for packed android malware,”
in Research in Attacks, Intrusions, and Defenses, 2015.
yGuard, https://www.yworks.com/en/products_yguard_about.html.
[53]
[54] M. Yue, W. H. Robinson, L. Watkins, and C. Corbett, “Constructing
timing-based covert channels in mobile networks by adjusting cpu
frequency,” in HASP, 2014.
[55] C. Zhang, C. Song, K. Z. Chen, Z. Chen, and D. Song, “VTint: Protecting
virtual function tables’ integrity,” in NDSS, 2015.
[56] Y. Zhang, X. Luo, and H. Yin, “DexHunter: Toward extracting hidden
code from packed android applications,” in ESORICS, 2015.
[57] W. Zhou, X. Zhang, and X. Jiang, “AppInk: watermarking android apps
for repackaging deterrence,” in ASIA CCS, 2013.
[58] W. Zhou, Y. Zhou, X. Jiang, and P. Ning, “Detecting repackaged smart-
phone applications in third-party android marketplaces,” in CODASPY,
2012.
[59] Y. Zhou and X. Jiang, “Dissecting Android malware: Characterization
and evolution,” in S&P, 2012.