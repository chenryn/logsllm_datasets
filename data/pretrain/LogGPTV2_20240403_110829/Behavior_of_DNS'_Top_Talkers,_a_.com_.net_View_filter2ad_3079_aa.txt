title:Behavior of DNS' Top Talkers, a .com/.net View
author:Eric Osterweil and
Danny McPherson and
Steve DiBenedetto and
Christos Papadopoulos and
Daniel Massey
Behavior of DNS’ Top Talkers, a .com/.net View
Eric Osterweil1, Danny McPherson1, Steve DiBenedetto2,
Christos Papadopoulos2, and Dan Massey2
1 Verisign Labs
2 Colorado State University
Abstract. This paper provides the ﬁrst systematic study of DNS data
taken from one of the 13 servers for the .com/.net registry. DNS’ generic
Top Level Domains (gTLDs) such .com and .net serve resolvers from
throughout the Internet and respond to billions of DNS queries every day.
This study uses gTLD data to characterize the DNS resolver population
and proﬁle DNS query types. The results show a small and relatively
stable set of resolvers (i.e. the top-talkers) constitute 90% of the overall
traﬃc. The results provide a basis for understanding for this critical
Internet service, insights on typical resolver behaviors and the use of IPv6
in DNS, and provides a foundation for further study of DNS behavior.
1
Introduction
The Domain Name System (DNS) [9] is one of the Internet’s core protocols and
is essential to looking up Internet resources. The DNS translates names to IP
addresses, identiﬁes the SMTP servers for email addresses, and provides a wide
range of other mappings. Virtually every Internet application depends on some
form of DNS data, and this makes it critical Internet infrastructure.
In addition, the DNS is also quite ﬂexible and extensible. It has been extended
to include security extensions[4] and the IETF has multiple working groups
investigating new uses [1,2]. Researchers are investigating both DNS behaviors
and the potential impact of design changes[11,3,7,5]. Characterizing the use of
the DNS at the top level can be quite useful for anyone trying to understand
the global DNS or add new extensions to this critical service. However, there are
still many aspects of the DNS that have yet to be investigated. These missing
pieces are not simply corner cases. To the contrary, top level DNS domains such
as .com and .net are some of the largest and most widely used DNS zones, but
relatively little is known about their characteristics and the characteristics of
their client resolvers. In fact, due to the caching behavior of DNS, large TLD
zones see more traﬃc diversity than even the root zone. Thus, observations from
the largest TLDs (.com and .net) oﬀer the greatest aggregate view of global
DNS traﬃc. We discuss this further in Section 2. There are no proﬁles of the
resolvers contacting these TLDs and no proﬁles to provide even basic information
such as the types, names, and frequencies of queries.
In this paper we present the ﬁrst study of all resolver query traﬃc seen by
g.gtld-servers.net (G GTLD), a unicast instance of one of the 13 sites serving
N. Taft and F. Ricciato (Eds.): PAM 2012, LNCS 7192, pp. 211–220, 2012.
c(cid:2) Springer-Verlag Berlin Heidelberg 2012
212
E. Osterweil et al.
the two largest TLDs in the Internet today: .com and .net. Our study uses data
collected from the second quarter of 2011. To address conﬁdentiality restrictions,
we do not list speciﬁc dates in the graphs. By observing queries at the G GTLD
server, one obtains a view of resolvers from throughout the Internet and observes
clients ranging from the caching recursive resolvers of large ISPs to smaller stub
client DNS tools running on end systems. The data volume to this single instance
of the 13 .com/.net name server set was in excess of 900 million queries and
roughly 900 thousand unique sources per day. These numbers represent typical
daily traﬃc counts and do not include any large attack traﬃc. To the best of
our knowledge, this is the largest study of resolver traﬃc and query patterns to
date. We use this query traﬃc to create empirical proﬁles of all resolvers seen.
2 Background
The domain names in DNS form a tree-like hierarchical name space in which
each node is called a domain. At the top of the tree, the root domain delegates
authority to Top Level Domains (TLDs) like .com, .net, .org, and .edu. The
.edu domain then delegates authority to create the colostate.edu domain,
.com delegates authority to create verisigninc.com domain, and so forth. The
repository of information that makes up the domain database is divided up into
logical name spaces called zones, which each belongs to a single administrative
authority and are each served by a set of authoritative name servers. The multiple
servers for each zone provide redundancy and fault tolerance.
Clients that query for DNS information are called resolvers. Typically, an
end system (desktop, laptop, smartphone, etc.) is called a stub resolver and
only implements a very small portion of the DNS resolution process. These
stubs are typically conﬁgured with the address of one or more local caching
resolvers, to which they send all of their queries. The local caching resolver
is conﬁgured with the IP addresses of the DNS root servers and if no other
information is cached, the caching resolver starts by send a query to the root
server. For example, to ﬁnd the IP address for www.verisigninc.com, a caching
resolver will ﬁrst query a root server and the root server will refer the caching
resolver to the .com servers. The caching resolver will then query one of the .com
servers (for the entire domain name, www.verisigninc.com) who will refer the
caching resolver to the verisigninc.com servers. Finally, the caching resolver
will query one of the verisigninc.com servers who return the desired address
for www.verisigninc.com (in the form of Resource Records, RRs).
Throughout this process, it is important to note a resolver may have the
authoritative servers for popular TLDs in cache. The caching resolver learns
of the .com servers upon its ﬁrst query to (cid:2)anything(cid:3).com and should cache
this information for two days (the TTL value speciﬁed in the RR). Thus in our
example above, the caching resolver almost certainly does not start the query
for www.verisigninc.com at the root servers. Instead, the caching resolver has
Behavior of DNS’ Top Talkers, a .com/.net View
213
cached the authoritative servers for .com and begins by querying one of these
servers. This means that client resolvers will forward the ﬁrst query for a Second
Level Domain (SLD) to the Top Level Domain. Thus, traﬃc to .com will show
a view of all active sub domains of .com. By contrast, none of these queries are
sent to the root, because recursive resolvers will have already cached .com (a
more speciﬁc match). This is why the largest TLDs (.com and .net) see much
more traﬃc that even the root zone.
3 Proﬁling Resolvers
For the second quarter of 2011, we examined all DNS query traﬃc sent to g.gtld-
servers.net (G GTLD); one of the authoritative name servers sites for .com and
.net. This site is unicast from a preﬁx that is announced from California, in the
USA. During this study we recorded pcap ﬁles from a SPAN port. Query types
include A, AAAA, MX and all other DNS RR types that were actually seen. Query
names were fully qualiﬁed DNS domain names such as www.somezone.com.
As one might expect, the G TLD server receives queries from millions of
sources including institutional DNS resolvers, mail servers, polling systems, bot-
nets, laptop users typing commands like dig, and so forth. In order better un-
derstand both DNS operations and the nature of query sources, we examined a
set of DNS-speciﬁc features to help us quantiﬁably proﬁle the resolvers observed
in our study. Based on the scope of the .com and .net TLDs, we believe that
these results provide the largest, most diverse, and perhaps the most detailed
proﬁle of global resolver behavior to date.
3.1 What We Can Observe
Due to the fact that our data is taken from a very large TLD registry, we gener-
ally do not expect to see end systems such as web browsers or smart phones in
our study. This is because these stub resolvers typically send their queries to a
local caching resolver. This local caching resolver will either service the request
from its cache (if it can), or forward the request to the TLD (and then serve
future requests for that name from its cache). Mapping between end system
addresses and caching resolver addresses is of interest to services such as con-
tent distribution networks, and remains an open and active area of research[8].
However, our study does not make eﬀort to map caching resolvers back to stubs.
While we will not see every caching resolver in the Internet, we do expect to
see a large portion of the full list of caching resolvers that send traﬃc to .com
or .net. In Section 2 we explained that resolvers query TLDs while looking for
referrals. However, even though our data is only taken from one of the 13 sites
that comprise these TLDs, we still claim that over time we will observe queries
from almost all caching resolvers. This is because of a behavior we call polling
and pinning.
214
E. Osterweil et al.
There are several main variants of DNS resolvers that are commonly deployed
today: ISC’s BIND, NLnet Labs’ unbound, PowerDNS, and Microsoft’s DNS.
Each of these servers attempts to provide its users with the fastest possible reso-
lution. One way they do this is to measure (or poll ) the Round Trip Time (RTT)
to each authoritative name server for each DNS zone they query. Generally, they
each have an algorithm to choose (or pin themselves to) a speciﬁc name server
for each zone that appears to be responding the fastest. Furthermore, the polling
process is generally ongoing so that the resolvers can adapt to changing network
conditions and in some types of servers, the polling volume and frequency is
amortized on existing query traﬃc. As a result, we expect that over time, every
resolver that uses this approach will send at least polling queries to our moni-
tored G GTLD site, and sometimes polling will result in a resolver changing its
selection and re-pinning itself to a new server.
(a) This resolver periodically sends bursts as
it pins/unpins itself to the G server.
(b) This resolver polls brieﬂy and then 2 days
later pins itself to G with a diurnal pattern.
Fig. 1. Pinning and polling behavior of two resolvers
For example, Figure 1(a) shows the polling behavior of one resolver over the
course of ﬁve days. Figure 1(b) shows a resolver that had been seen polling at
a very low rate and volume for two days before re-pinning itself from another
server instance to G GTLD. We can see that server selection does occur, but
the approach for selecting an authoritative server is implementation dependent
and even varies between versions of the same implementation[6]. Some imple-
mentations may simply select a preferred server and pin themselves to the server
without polling the zone’s other authoritative servers. A complete discussion of
server selection is beyond the scope of this paper, but more information can be
found in [12,10].
3.2 Who Talks to the G GTLD Server?
Figures 2(a) and 2(b) provide a high level overview of the sources sending queries
to the G GTLD server. Figure 2(a) is a Hilbert graph showing the location of
all sources that contacted the G GTLD server during one example ten minute
Behavior of DNS’ Top Talkers, a .com/.net View
215
(a) Location of Sources Querying G (b) Cumulative Number of Sources Sending Queries
Fig. 2. Who is querying g.gtld-servers.net
(a) Resolver Query Rates: A relatively small
number of resolvers account for 90% of all
(b) A static top-talkers list (rather than
rolling) accounts for less of the overall traﬃc
Queries
after 10 days (note the the y-oﬀset from 0)
Fig. 3. Query rates and top-talkers
period. This Hilbert graph divides the Internet IPv4 address space into /16
address blocks. The color indicates the volume of coming from that address
block. The large empty spaces correspond to unallocated or inactive address.
For example, the upper right corner of the graph corresponds to the multicast
address space; which should not be used as the source in any DNS queries. The
main point of the ﬁgure is that, even in a relatively short ten minute span, the
G GTLD server does indeed serve the global Internet. This ﬁgure is very similar
during other periods.
The top curve in Figure 2(b) shows the cumulative number of source addresses
over a 20 day period. We can see that initially there is a brief super-linear learn-
ing phase. This is a cold-cache artifact of our measurements, and shows that
some query sources have longer inter-query periods, and take longer to appear in
our measurements. By contrast, active caching resolvers from campus networks,
216
E. Osterweil et al.
organizations, and ISPs are frequently querying the .com and .net zones and
quickly appear in our data set. Caching resolvers that serve smaller user bases
send less frequent queries and likely make up the population of resolvers that
take longer to appear. Inactivity due to time of day and caching resolver polling
behavior (discussed above) can also delay the time it takes for the G GTLD
server to observe the ﬁrst query from a caching resolver.
Following the initial learning phase, the ﬁgure shows there is a constant growth
of unique IP sources. Even 20 days into the study, the G GTLD server continues
to discover new resolvers at a rapid pace (note the log scale). There are many
legitimate explanations for resolvers growth such as a network administrator
conﬁguring a new resolver, a user may use the dig command to send a query
directly to G GTLD server, a DNS monitoring tool may query G GTLD server.
There are also illegitimate behaviors in this growth such as bots directed to send
attack traﬃc and attacks using spoofed addresses. As one may expect, a large
portion of the “slow to appear” legitimate sources send a very small amount of
traﬃc; many as little as a single query. In contrast, resolvers that send a high
volume of queries during some period are classiﬁed as top-talkers and we examine
this group in more detail.
3.3 Query Volume and Top-Talkers
While the set of all resolvers numbers in the millions and continues to grow
in our study, Figure 3(a) shows 90% of the overall traﬃc is generated by just
under 40,000 resolvers. This indicates that the large-scale behavior seen at the
.com/.net TLDs is dictated by a relatively small number of query sources.
We call these resolvers top-talkers. The lower ﬂat line in Figure 2(b) shows the
cumulative number of top-talkers and indicates that top-talkers are discovered
quickly. The set of top-talkers is also dynamic, as the behaviors of resolvers
change over time. There are long term structural changes where new resolvers are
added, old resolvers are retired, users migrate, and new services are provisioned.
In addition, there are observable shorter term patterns as load changes due to
the time of day, the day of the week, and even due to routing changes. To account
for the long term structural changes and shorter term patterns, we developed
a rolling list of top-talkers where at any given moment the list is based on the
previous seven days of data.
In order to see the dynamism in this list, we ﬁrst compared two top-talkers
list from diﬀerent months. At the beginning of one month, the top-talker list
included 39,304 source IP addresses. At the beginning of the following month,
the top-talker list included 39,936 sources. 30,071 of the sources were common
to both lists. Next, a separate examination (seen in Figure 3(b)) found that the