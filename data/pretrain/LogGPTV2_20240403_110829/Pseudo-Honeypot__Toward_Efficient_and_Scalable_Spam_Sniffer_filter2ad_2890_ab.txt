speciﬁc, we take the Twitter social network as an example to
present its system design and fully explore its advantages. As
shown in Figure 1, our system design consists of the following
core components: i) Pseudo-honeypot selection, ii) Pseudo-
honeypot monitoring, iii) Feature extraction, iv) Ground truth
data labeling, and v) Spammer classiﬁcation.
III. PSEUDO-HONEYPOT SYSTEM DESIGN IN TWITTER
SOCIAL NETWORK
In this section, we offer an in-depth study of the pseudo-
honeypot by designing efﬁcient mechanisms for spam and
spammer gathering in Twitter social networks.
A. Challenges of Selecting Pseudo-honeypot
One critical step in constructing the pseudo-honeypot net-
work is to ﬁnd suitable user accounts with attributes which
437
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:55:53 UTC from IEEE Xplore.  Restrictions apply. 
  Spammer Detection Phase (Sections IV and V)Pseudo-honeypot Construction Phase (Section III)Pseudo-honeypot selectionTwitter streamingIdentify attributes for pseudo-honeypot Pseudo-honeypot monitoringFeature extractionBuild machine learning modelClassificationUpdate attributes for pseudo-honeypotData labeling on small datasetsBuild advanced pseudo-honeypotATTRIBUTE CATEGORIES OF PSEUDO-HONEYPOT SELECTION.
TABLE I
Category
Attributes
C1: Proﬁle-based
C2: Hashtag-based
C3: Trending-based
friends count, followers count,
total friends and followers,
ratio of friend and followers,
account age (days), lists count,
favorites count, statuses count,
average of lists per day,
average of favorites per day,
average of statues per day
entertainment, general, business,
tech, education, environment,
social, astrology, no hashtag
trending-up topics,
trending-down topics,
popular tweets, no-trending topics
[24], [38] as the sample examples to demonstrate pseudo-
honeypot’s feasibility and advantages, by grouping them into
the following three categories.
• Proﬁle-based attributes contain personal information pre-
sented by concrete labels in Twitter. As shown in Cate-
gory C1 of Table I, we extract 11 most critical social
attributes to characterize user’s proﬁles in Twitter.
• Hashtag-based attributes identify messages on some spe-
ciﬁc topics that cluster tweets into different groups. In our
system design, we mainly consider eight types of hash-
tags as outlined in C2 of Table I, namely, entertainment,
general, business, tech, education, environment, social,
astrology and no hashtag.
• Trending-based attributes represent the trending of dis-
cussed topics in tweets. They reﬂect the changes of users’
interests in some topics with the attributes of trending up
or down (in C3 of Table I), which can highly impact some
spammer’s strategies.
C. Constructing Pseudo-honeypot
We use the attribute set as shown in Table I to select a
collection of accounts, with each account satisfying at least
one attribute. The pseudo-honeypot takes selected accounts as
parasitic bodies and monitor the posted tweets and behavioral
patterns crossing these accounts. Note that the operation of
pseudo-honeypot should always stay transparent to the har-
nessed user accounts. This can be achieved by leveraging
the popular Twitter APIs (e.g., RESTful or Streaming API)
that are available to developers.1 Such APIs can help pseudo-
honeypot to monitor account activities (i.e., posted tweets
and behavioral patterns) while staying invisible to them. Til
now, our pseudo-honeypot has been constructed with similar
spammer attraction as that of the honeypot, while offering the
advantages of ﬂexible attribute selections and lowered chances
to be recognized by spammers.
1Most social networks provide such APIs, for example, Reddit API in
Reddit, Tumblr API in Tumblr, Search API in Facebook/Instagram/Google+,
and so on.
D. Improving Pseudo-honeypot Performance
In Twitter, one account may not keep attracting spammers’
interests for an extended time period. According to our obser-
vation, if one account has more recent activities, it has a higher
potential in attracting spammers. Thus, it is essential for our
system to have high portability for improving its efﬁciency of
spammers capturing by building pseudo-honeypot only over
active accounts. To explore the portability property, we deﬁne
a user’s status as either Active or Dormant. If a user account
posts new tweets and brings lots of mentions/replies in a
certain time interval, it is referred to as in the Active Status.
On the other hand, if a user does not post new tweets for a
certain time duration, or it posts new tweets but brings few
or no mentions/replies, it is called in the Dormant Status. To
maintain high efﬁciency, we aim to make pseudo-honeypot
stay only over the Active users.
E. Pseudo-honeypot Monitoring
The pseudo-honeypot network has been constructed with
aforementioned steps, able to start monitoring tweets and
users’ behavioral patterns. Currently, we collect only the direct
interactive behaviors, instead of all streaming passing through
the associated accounts, to reduce the processing workload
of the pseudo-honeypot network. Many direct interactive be-
haviors can be explored and utilized by pseudo-honeypot if
needed. In this design, we only take “mentions” behaviors
as an example. The advantages of this design are twofold.
First, most information in streaming tweets is benign, so it
is expensive to remove them among all streams. Second, the
streams with “mention” may include the most severe spammer
behaviors and provide much valuable information to garner
spammers.
The tweets we collected can be classiﬁed into three cat-
egories: (1) pseudo-honeypot accounts’ activities, including
posts, retweets, and quotes; (2) other normal accounts men-
tioning the pseudo-honeypot accounts; (3) spammers mention-
ing pseudo-honeypot accounts. Category (1) belongs to normal
behaviors if the users are not spammers. But, based on our
pseudo-honeypot selection approach, the selected accounts can
be spammers. Thus, the tweets in Category (1) may be spam
messages. Category (2) reﬂects the normal behaviors, while
Category (3) contains anomaly network behaviors. Our goal
is to identify the spams under Category (1) and differentiate
Category (3) from Category (2).
F. Ethical Considerations
Since pseudo-honeypot employs normal accounts as the
carriers, we should put strict restrictions on its operation. One
restriction is that it is not allowed to mine secret information
of users. All monitored and collected information should be
visible to the public. Another restriction is that it is disallowed
to perform social activities or conduct any interaction with the
carriers or other accounts, so as not to interrupt Twitter users.
As we employ Twitter APIs (i.e., Streaming and Restful), these
two restrictions can be readily met as Twitter APIs apply the
Developer Agreement and Policy of Twitter [32] to regulate
438
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:55:53 UTC from IEEE Xplore.  Restrictions apply. 
API use by developers. The Twitter API’s privacy policy is
fully observed by our pseudo-honeypot system. As a result, the
pseudo-honeypot mechanism is considered to be both ethical
and legal.
IV. PSEUDO-HONEYPOT SPAM DETECTOR
To evaluate pseudo-honeypot performance, it is infeasible
to check all collected tweets manually. Instead, we adopt the
machine learning-based approach to design a pseudo-honeypot
spam detector so as to analyze spam messages from Categories
(1), (2), and (3). Our detector includes three components.
First, we extract a rich set of features that can reﬂect tweets’
characteristics. Next, we use diversiﬁed methods to label a
ground truth data for training to cover the major types of
spams. In the end, we employ the machine learning algorithms
to classify the collected tweets.
A. Feature Extraction
To understand tweets’ characteristics that reﬂect spams
or spammers’ attributes, we extract a total of 58 features
categorized as follows.
Account Proﬁle. We aim to extract a rich set of accounts
information that is included in tweets. A user is deﬁned as the
sender if posting tweets to (or retweeting from) others, and
as the receiver if mentioned by others. We extract 16 proﬁle
features from sender accounts. These features include friends
count, followers count, age, status count, average statuses,
list count, average lists, average favourites, favorites count,
veriﬁed status, default proﬁle image, screen name length,
name length, description length, description emoji count, and
description digits count. Similarly, the same 16 features are
extracted from receiver accounts.2 Note here, these proﬁle fea-
tures can be extracted from tweet’s JavaScript Object Notation
(JSON).
Tweet Contents. By analyzing tweet contents, we extract 8
statistic features, including if the tweet is repeated, tweet status
(i.e., tweet, retweet, quote), tweet source (web, mobile, third-
party, others), hashtag count, mention count, content length,
content emoji count, and content digits count.
User Behaviors. To reﬂect user’s behavioral patterns, we
extract a total of 18 features, which are described next.
• Reciprocity count: The number of conversations between
a sender and a receiver.
• Sender (or receiver) tweet distribution: The percentages
of the tweet, retweet, and quote from the same sender (or
to the same receiver). This includes a total of 6 features
at the sender and receiver.
• Sender (or receiver) tweet source distribution: The per-
centage of tweets under each tweet source (web, mobile,
third party, and others) associated with a sender (or a
receiver). This includes a total of 8 features at the sender
and receiver.
2We consider only those receivers who are pseudo-honeypot nodes or have
mentioned the pseudo-honeypot, since all other account information cannot
be singled out.
• Mention time: Once a user updates a new post, assuming
at Tpost, it will take a certain time for other users to see
this update (assuming at Tmention) and then react to this
update after a period. We deﬁne mention time fm as the
time interval between these two activities, i.e.,
fm = Tmention − Tpost.
The importance of this feature stems from considering the
reaction time differences of normal users and of spam-
mers. For normal users, the mention time is relatively
longer since users need time to read the post and reply to
it. For spammers, however, they target the victims and
start spam behaviors with little consideration to tweet
contents, thus incurring a short time for reaction.
• Average tweet intervals: This feature calculates the aver-
age intervals of any two neighboring tweets. The average
intervals of tweets sending (or received) from a sender
(or by a receiver) are expressed by:
(cid:80)(Ti+1 − Ti)
,
Nu
t =
where Ti denotes the time when a sender (or receiver)
sends (or receives) a tweet and Nu denotes the total
number of tweets that have been sent (or received).
• Environment score: Inspired by spammers’ interests in
various attributes, the group likelihood score pi is used
to denote the probability of an attribute i in attracting
spammer’s interests. With such score, we deﬁne a new
feature, named environment score fscore, to express the
contribution of an attribute to spam identiﬁcation, which
can be calculated as follows:
(cid:26) max(pi), ∀pi ∈ Pattr,
fscore =
τ,
otherwise,
where Pattr denotes the set of probability values with re-
spect to all attributes. That is, the highest group likelihood
score in this set will be selected as the environment score,
i.e., fscore = max(pi),∀pi ∈ Pattr. If Pattr = ∅, there is
no spam found yet within a group of attributes. Then, we
set the score as a small constant value τ, i.e., fscore = τ.
Note that both Pattr and fscore will be updated once new
spams are found by any attribute.
B. Ground Truth Labeling
Ground truth labeling is used for training data based on
selected features. However, the lack of reliable ground truth is
known as a challenge for real-world data. To acquire a reliable
ground truth dataset, we ﬁrst rely on preprocessing below
to obtain the roughly labeled data: 1) checking suspended
accounts, 2) clustering-based approach, and 3) the rule-based
method. After that, we perform manual checking on such
roughly labeled data to reﬁne a reliable ground truth dataset.
This method can signiﬁcantly reduce the labeling cost while
maintaining good reliability.
Suspended Account. Twitter suspends the user accounts
that violate Twitter rules [33] to maintain a clean social
439
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:55:53 UTC from IEEE Xplore.  Restrictions apply. 
environment. The ﬂagged twitter accounts can help us to
label a portion of data in the ground truth dataset. Notably,
a suspended account is not necessary a spam account, but
our manual checking in the last step can further ﬁlter these
accounts.
Clustering Based Method. To label the remaining dataset, we
employ the clustering method, which has been widely applied
[5], [21], [24], [25] to detect the spammer campaigns and near-
duplicate tweets. Our clustering is based on four types of data,
i.e., proﬁle image, screen name, user description, and tweet
contents, where the ﬁrst three are from the user proﬁles [30],
[13] and the last one is from tweets [24].
First, we cluster users with similar images into the same
group. This method is plausible since a spam campaign
typically uses similar images in the proﬁle even they have
different URLs [13]. The dHash (Different Hash) algorithms
[28] can be utilized to dig the similar images as follows:
• Reduce the original image into a constant size (i.e., 9*9)
by removing high frequencies and detailed information
of the image and then transforming color into grayscale.
• Compare the adjacent pixels in the image. If one pixel is
greater (or smaller) than the next one (considering both
horizontal and vertical directions), we set it to 1 (or 0).
We then transform these binary values into hexadecimal
values and concatenate the two 64-bit values together to
get a 128-bit hash.
• Calculate the difference of any two images (128-bit
i.e., d(h1, h2) =
hash) by using Hamming distance,
(cid:80) XOR(h1, h2).
For any two images, if their Hamming distance is smaller than
a threshold (i.e., 5), we put them into the same group.
Second, we group together the users with speciﬁc patterns
in their screen names. A spam campaign typically registers its
accounts with automatic naming patterns which have relatively
limited variability [30]. We may adopt the similar regular
expression method [19] that has a low false-positive rate in
URL pattern [36], text template [23], or merchant patterns
[30] to extract user screen names. Then, we match each screen
name to a sequence Σ-Seq by a pre-deﬁned character classes
Σ = {p{Lu}, p{Ll}, p{N}, p{P}}, where p{Lu} p{Ll},
p{N}, and p{P} indicate the uppercase, lowercase, numeric
characters, and punctuation characters, respectively. We keep
those groups that have 5 or more members in a sequence.
Third, we cluster users by analyzing their descriptions. We
process a user description by removing its URL, emoji, stop
words, and special characters, before employing the MinHash
algorithm [26] to ﬁnd near-duplicate descriptions among all
users. We consider two descriptions identical if their minimum
hash values of the tri-grams shinglings are the same.
In the end, we set a 1-day time window to check near-
duplicated tweets. We ﬁlter out tweet contents that are less
than 20 characters to check the duplication.
After we group the user accounts and tweets, we label
spammers and spams via the following criteria: If a user in
one group is suspended by Twitter, we label all users in this
group as spammers; If a tweet in one group is labeled as a
spammer, we label its users and all tweets in this group as
spammers and spams, respectively.
Rule-Based Method. This is a complementary step to la-
bel the remaining dataset. Speciﬁcally, we set the following
rules/policies to label the spams and non-spams.
• A tweet is labeled as spam if it falls into one of the
following conditions: 1) has malicious URL; 2) includes
repetitive information; 3) includes deceptive information;
4) has pertinence purpose; 5) includes many meaningless
tweets; 6) has relevant
information on free or quick
money gain; 7) includes adult content; 8) is an automatic
tweet from bots/app with the malicious purpose; 9) is
from malicious promoters; 10) is friend inﬁltrators. 11)