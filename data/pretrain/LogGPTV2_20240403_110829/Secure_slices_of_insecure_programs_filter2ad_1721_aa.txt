title:Secure slices of insecure programs
author:Salvador Cavadini
Secure Slices of Insecure Programs
Salvador Cavadini
INRIA Sophia Antipolis - Méditerranée
2004 route des lucioles
Sophia Antipolis, France
PI:EMAIL
ABSTRACT
This paper deals with the problem of protect the conﬁden-
tiality of data manipulated by sequential programs. In this
context, secure information ﬂow refers to the guarantee that
program executions are free of non authorized ﬂows of secret
information into public channels. There are two established
means to enforce information ﬂow policies: static analyses,
that are performed at compile time and guarantee that all
program executions are free of unauthorized ﬂows; and run-
time monitoring, that dynamically detects and neutralizes
invalid ﬂows for the current run.
Both approaches have their advantages and disadvantages.
The main disadvantages of static information ﬂow control
(IFC) is, that it does not diﬀerentiate between secure and
insecure executions of the same program, therefore whole
programs are rejected in presence of possible invalid ﬂows.
On the contrary, dynamic IFC rejects insecure executions
only. This analysis precision comes at the price of the exe-
cution overload that imposes the dynamic tracking of infor-
mation ﬂow.
This work presents secure slicing, a technique that stat-
ically transforms probably insecure (interfering) programs
into secure (non-interfering) ones. Our approach combines
static analysis of information ﬂow and program transfor-
mation:
if invalid ﬂows are detected, instead of rejecting
the whole program, we transform it to eliminate the invalid
ﬂows. This way, we alleviate drawbacks of static and dy-
namic approaches: neither we reject full programs nor we
impose run-time overhead. The resulting program can be
seen as a secure slice of the source program that can be
executed without risk of information leaks.
In this work we also show that secure slices can be com-
puted for programs that intentionally release secret infor-
mation, and that the technique can be applied to real pro-
gramming languages such as Java.
Categories and Subject Descriptors
D.4.6 [Operating Systems]: Security and Protection—In-
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ASIACCS ’08, March 18-20, Tokyo, Japan
Copyright 2008 ACM 978-1-59593-979-1/08/0003 ...$5.00.
formation ﬂow control ; F.3.2 [Logics and Meanings of
Programs]: Semantics of Programming Languages—Pro-
gram analysis
General Terms
Languages, Security, Veriﬁcation
Keywords
information ﬂow, non-interference, program dependences,
program slicing
1.
INTRODUCTION
There is an urgent need for software applications with
strong conﬁdentiality guarantees. Protecting sensitive in-
formation —e.g., credit card data, personal medical infor-
mation, military secrets— has become an important aspect
of software. The problem is not new but it has acquired high
relevance due to ubiquity of computing systems.
This paper deals with the problem of protect the conﬁden-
tiality of data manipulated by sequential programs. Usually,
a conﬁdentiality policy labels certain variables as being se-
cret to enforce the independence between values outputted
by the program and initial values of secret variables. This is
semantically interpreted by non-interference [10], a property
ensuring that secret data will not be observable on public
channels.
In this context, secure information ﬂow refers to the guar-
antee of absence of non authorized ﬂows to public channels
in the program execution. Roughly speaking, there are two
approaches to enforce information ﬂow policies: static, and
dynamic information ﬂow control (IFC).
The development of non-interference certiﬁcation mech-
anisms based on static IFC is a well-studied ﬁeld; a large
body of literature —surveyed in [27]— reﬂects the consider-
able attention that this area has received from the research
community.
A certiﬁcation mechanism provides a guarantee that the
execution of a program is non-interfering; in fact, IFC is
made before the execution of the program and all program
executions are warranted to be non-interfering. If an invalid
ﬂow —i.e., an information ﬂow of secure data into a pub-
lic channel— is detected, the certiﬁcation mechanism rejects
the whole program as insecure. For example, the following
program is rejected by certiﬁcation mechanisms because the
value of secret variable is, possibly, printed out by the out-
put command:
112
( public=0) then
public:=secret
1 i f
2
3 e l s e skip endif ;
4 output ( public )
On the other hand, dynamic IFC —a.k.a. information ﬂow
monitoring— detects invalid ﬂows during program execu-
tion. Information ﬂow monitors exploit precise information
about executed program commands to detect invalid ﬂows
in the current execution, so only insecure executions are re-
jected. For example, executions of the above program are
rejected only when command 4 is to be executed after com-
mand 2.
Both approaches have their own advantages and disadvan-
tages. Static IFC does not impose run-time penalization but
it is less precise —more spurious invalid ﬂows are informed—
than dynamic IFC. The main disadvantage of static IFC is
that it does not diﬀerentiate between secure and insecure
executions of the same program therefore whole programs
are rejected in presence of possible invalid ﬂows.
Contrarily, dynamic IFC only rejects insecure executions.
This analysis precision comes at the price of the execution
time overload that imposes dynamic tracking of information
ﬂows.
If an IF monitor deduces that an execution is not secure,
either it rejects the program or alters the regular behaviour
of the program to obtain a secure execution. Note that the
rejection of a program during its execution can produce an
information leak. For example, in the following program:
( secret=0) then
output ( 1 )
1 i f
2
3 e l s e skip endif ;
4 output ( 0 )
the execution of command 2 is insecure because it leaks the
value of variable secret (if command 2 is executed then the
value of secret is 0).
If after detecting the imminent in-
formation leak, the IF monitor aborts program execution it
will also leak the value of secret because the attacker knows
that the monitor only halts if secret is 0.
Other alternative is to alter regular execution on the ﬂy
[18]. When the monitor detects the imminent leakage of
secure values, it appropriately modiﬁes program behaviour
to avoid the invalid ﬂow. This way the monitor preserves the
security of the execution at the cost of changing the program
semantics when necessary.
Contribution. This work presents secure slicing, a static
technique to transform probably insecure (interfering) pro-
grams into secure (non-interfering) ones. Our approach com-
bines static analysis of information ﬂow and program trans-
formation:
if invalid ﬂows are detected, instead of reject
the whole program, we transform it suitably to eliminate
the invalid ﬂows. The new program is secure and, probably
preserves the semantics of non-interfering executions of the
original program; therefore —as with IF monitors— we can
safely execute a program that, originally, was insecure. The
resulting program can be seen as a secure slice of the source
program.
To produce a secure slice we apply the same transforma-
tions that IF monitors use when they need to alter program
behaviour to keep it secure. The diﬀerence is that these
transformations are not made at run-time but at compile-
time and using statically computed information about the
(cid:104)S1, µ1, ov1(cid:105) −→ (cid:104)µ2, ov2(cid:105)
(cid:104)S2, µ2, ov2(cid:105) −→ (cid:104)µ3, ov3(cid:105)
(cid:104)S1 ; S2, µ1, ov1(cid:105) −→ (cid:104)µ3, ov3(cid:105)
(cid:104)skip, µ, ov(cid:105) −→ (cid:104)µ, ov(cid:105)
(cid:104)x := e, µ, ov(cid:105) −→ (cid:104)µ[x(cid:55)→e], ov(cid:105)
µ(e) (cid:54)= 0
(cid:104)S1, µ, ov(cid:105) −→ (cid:104)µ1, ov1(cid:105)
(cid:104)if (e) then S1 else S2 endif, µ, ov(cid:105) −→ (cid:104)µ1, ov1(cid:105)
µ(e) = 0
(cid:104)S2, µ, ov(cid:105) −→ (cid:104)µ2, ov2(cid:105)
(cid:104)if (e) then S1 else S2 endif, µ, ov(cid:105) −→ (cid:104)µ2, ov2(cid:105)
µ1(e) (cid:54)= 0
(cid:104)S, µ1, ov1(cid:105) −→ (cid:104)µ2, ov2(cid:105)
(cid:104)while (e) do S wend, µ2, ov2(cid:105) −→ (cid:104)µ3, ov3(cid:105)
(cid:104)while (e) do S wend, µ1, ov1(cid:105) −→ (cid:104)µ3, ov3(cid:105)
(cid:104)while (e) do S wend, µ, ov(cid:105) −→ (cid:104)µ, ov(cid:105)
µ(e) = 0
(cid:104)output(e), µ, ov(cid:105) −→ (cid:104)µ, ov :: µ(e)(cid:105)
Figure 1: Language’s natural semantics
ﬂows in the program. This way, we alleviate two main draw-
backs of static and dynamic approaches: neither we reject
full programs nor impose run-time overhead.
A distinguishing feature of our technique w.r.t. recent
work on IF monitors is its ability to compute secure slices
from programs intentionally releasing secret information —
a.k.a. declassiﬁcation—. We also show that our technique
can be applied to real programming languages such as Java.
Contents. This work is organized as follows:
in Section 2
we brieﬂy introduces the notions of program dependences,
information ﬂow, and program slicing. Section 3 introduces
the deﬁnition of secure slice, shows how it can be computed
from a dependence graph, and how declassiﬁcation is sup-
ported. Section 4 shows how secure slicing can be applied
in practice over real programming languages. Related work
is overviewed in Section 5. Finally, Section 6 concludes.
2. PRELIMINARIES
2.1 Language
Although the proposals of this paper can be applied to
real programming languages, for the sake of clarity, we will
work with a small imperative programming language with
the following syntax:
S ::= S;S | skip | x:=e
if (e) then S else S endif
|
| while (e) do S wend
|
output (e)
Expressions e in the language must be deterministic and
without side eﬀects.
Language semantics, given by the rules of Figure 1, is
quite standard except for the statement output(e) used to
represent outputs to public channels while outputs to secret
channels are ignored, consequently, they are not included in
113
program listings.
It is important to remark that we con-
sider program state not directly accessible; this means that
memory values can not be known unless they are published
through output statements.1
Program states are represented as pairs of the form (cid:104)µ, ov(cid:105),
where memory µ : X (cid:55)→ V is a mapping from program vari-
ables (X ) to values (V), and ov ∈ V (cid:63) is a string representing
the values outputted through the public channel.
We write −→(cid:63) the transitive closure of the transition rela-
tion −→ deﬁned by the rules at Figure 1. The evaluation of a
program P from initial (cid:104)µ, ε(cid:105) to ﬁnal state (cid:104)µ(cid:48), ov(cid:105) —where
ε represents the empty string— is (cid:104)P, µ, ε(cid:105) −→(cid:63) (cid:104)µ(cid:48), ov(cid:105),
noted (cid:104)P, µ, ε(cid:105) ⇓ (cid:104)µ(cid:48), ov(cid:105) or simply (cid:104)P, µ, ε(cid:105) ⇓ ov if the ﬁnal
memory is not of interest.
2.2 Information ﬂow
The classical way to enforce secure information ﬂow is by
labelling certain variables as being secret and only allow-
ing ﬂows of secret data into secret output channels. This
way, the independence between public outputs and secret
data is guaranteed. This public/secret scheme of security
can be extendend to a richer lattice of security where more
than two levels are allowed [6]; then the ordering relation
on security levels determines what is a valid ﬂow of infor-
mation, i.e. information at level l of security can only ﬂow
to output channels at level l(cid:48) such that l(cid:48) is equal or higher
than l. This is semantically interpreted by non-interference
property [10].
Formally, given a set S ⊆ X of secret variables,2 a pro-
gram P is non-interfering if and only if all memory pairs
µ1, µ2 such that ∀x ∈ X \ S : µ1(x) = µ2(x) satisfy
(cid:104)P, µ1, ε(cid:105) ⇓ ov1 and (cid:104)P, µ2, ε(cid:105) ⇓ ov2 implies ov1 = ov2
In other words, P is non-interfering if and only if for
all pairs of memories diﬀering only in the values of secret
variables —a.k.a.
low-equal memories— the executions of
the program with these two memories produce the same se-
quence of outputted values.
Lampson has noted that programs can transmit informa-
tion to the environment not only through channels explicitly
declared in the program —e.g., output statements— but
through what he calls covert channels: program running
time, power consumption, etc. [16]. The present work is cir-
cumscribed to information ﬂow analysis of explicit channels.
2.3 Program Dependences
It’s possible to distinguish several kinds of dependences a-
mong program statements but they can be coarsely grouped
in two categories: data, and control dependences.
Infor-
mally, if statement y uses a variable deﬁned at statement x,
then y is data dependent on x. If the execution of statement
y is controlled by the value of an expression x, then y is
control dependent on x. In general, if y depends on x we will
say that y is the dependent and x the dependee.
Program dependences are usually modeled by a directed
graph where nodes represent statements and expressions,
1Note that this restriction does not imply a lose of generality,
if required, output statements printing out the value of each
public variable can be added at any place in the program.
2Without lose of generality, a security lattice of two elements
(Low → High) will be used through the paper; secret vari-
ables are labeled with High and public output channels are
said to be Low.
1 i f
2
3
( l1<=0) then
l2 :=h ;
output ( l1 ) ;
output ( l2 )
4
5 e l s e
6
i f
( h ) then
l3 := 0 ;
output ( l1 )
7
8
9
10
11
e l s e
l1 := 1
endif ;
output ( l1 )
12
13 endif
Figure 2: Example program and its (partial) depen-
dence graph.
and edges represent dependency relations: if the statement
represented by node y depends on the statement represented
by x, then there is an edge from x to y in the graph.
There are well known algorithms to compute intra and
interprocedural dependences and to build the correspond-
ing dependence graphs [9, 14, 24]. Figure 2 shows a pro-
gram and its dependence graph.3 Node numbers indicate
the associated program statement and output statements
are represented by boldfaced nodes. Gray node h repre-
sents the initial value of the secret variable h, this kind of
node will be referred as initialization nodes; dashed edges
represent data dependences and continuous edges represent
control dependences. The special node entry corresponds
to whatever external condition causes the program to begin
execution.
We note x → y an edge from node x to node y in the
dependence graph. When necessary, we will diﬀerentiate
between data and control edges, noted x d→ y and x c→ y
respectively. A path x → . . . → y in the dependence graph
is written x (cid:179) y.
Due to the imprecision of dependency analysis —the com-
putation of exact dependences is undecidable— dependence
graphs are a conservative model of the dependences in a pro-
gram, this means that dependence graphs may contain too
many edges but never too few. In other words, dependences
graphs are safe approximations to the actual program de-
pendences.
2.4
Information Flow Analysis based on De-
pendence Graphs
Information ﬂow is naturally related to dependences be-
tween program statements: if statement y directly or indi-
rectly depends on statement x, then information could ﬂow
from x to y, noted x ; y. If y does not depend on x, then it
is guaranteed that information can not ﬂow from x to y [1,
32], noted x (cid:54); y. In other terms, if there is no dependence
path from x to y, then information can not ﬂow from x to
y, symbolically:
(cid:54) ∃x (cid:179) y =⇒ x (cid:54); y
Information is made public only through output statements,
3In the examples, we use h to name secret variables.
114
thus we are only interested in ﬂows from initialization nodes
of secret variables h to output statements o:
(cid:54) ∃h (cid:179) o =⇒ h (cid:54); o
That is, if it does not exist a dependence path from an
initialization node h to an output statement o, then a ﬂow
from h to o is impossible at run-time. Therefore, given a
program P and a set S of secret variables,
∀o ∈ P, h ∈ S :(cid:54) ∃h (cid:179) o =⇒ P is non-interfering
To identify possible invalid ﬂows it is suﬃcient to build
the dependence graph for the program and check if there is
a dependence path from secret data to output statements.
If that is the case, the analyzed program is possibly inse-
cure;4 on the contrary, if there is no path from secure data