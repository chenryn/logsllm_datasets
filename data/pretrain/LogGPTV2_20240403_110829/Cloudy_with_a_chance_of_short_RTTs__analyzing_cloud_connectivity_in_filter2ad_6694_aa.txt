title:Cloudy with a chance of short RTTs: analyzing cloud connectivity in
the internet
author:The Khang Dang and
Nitinder Mohan and
Lorenzo Corneo and
Aleksandr Zavodovski and
J&quot;org Ott and
Jussi Kangasharju
Cloudy with a Chance of Short RTTs
Analyzing Cloud Connectivity in the Internet
The Khang Dang♮†
Nitinder Mohan♮†
Jörg Ott♮
Lorenzo Corneo♯
Jussi Kangasharju♭
Aleksandr Zavodovski♯
♮Technical University of Munich ♯Uppsala University
♭University of Helsinki
†Equal contribution
ABSTRACT
Cloud computing has seen continuous growth over the last decade.
The recent rise in popularity of next-generation applications brings
forth the question: “Can current cloud infrastructure support the
low latency requirements of such apps?” Specifically, the interplay
of wireless last-mile and investments of cloud operators in setting
up direct peering agreements with ISPs globally to current cloud
reachability and latency has remained largely unexplored.
This paper investigates the state of end-user to cloud connec-
tivity over wireless media through extensive measurements over
six months. We leverage 115,000 wireless probes on the Speed-
checker platform and 195 cloud regions from 9 well-established
cloud providers. We evaluate the suitability of current cloud infras-
tructure to meet the needs of emerging applications and highlight
various hindering pressure points. We also compare our results to
a previous study over RIPE Atlas. Our key findings are: (i) the most
impact on latency comes from the geographical distance to the dat-
acenter; (ii) the choice of a measurement platform can significantly
influence the results; (iii) wireless last-mile access contributes sig-
nificantly to the overall latency, almost surpassing the impact of the
geographical distance in many cases. We also observe that cloud
providers with their own private network backbone and direct peer-
ing agreements with serving ISPs offer noticeable improvements in
latency, especially in its consistency over longer distances.
CCS CONCEPTS
• Networks → Public Internet; Network measurement.
KEYWORDS
Cloud connectivity, Last-mile latency, Peering, Edge computing
ACM Reference Format:
The Khang Dang, Nitinder Mohan, Lorenzo Corneo, Aleksandr Zavodovski,
Jörg Ott and Jussi Kangasharju. 2021. Cloudy with a Chance of Short RTTs:
Analyzing Cloud Connectivity in the Internet. In ACM Internet Measurement
Conference (IMC ’21), November 2–4, 2021, Virtual Event, USA. ACM, New
York, NY, USA, 18 pages. https://doi.org/10.1145/3487552.3487854
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
IMC ’21, November 2–4, 2021, Virtual Event, USA
© 2021 Association for Computing Machinery.
ACM ISBN 978-1-4503-9129-0/21/11...$15.00
https://doi.org/10.1145/3487552.3487854
1 INTRODUCTION
Cloud computing has become the core enabler for an ever-increasing
growth of networked services on the Internet over the past decade [21].
Cloud providers have made significant investments to expand their
global footprint, not just by deploying datacenters in new loca-
tions [9] but also installing private backbones interconnecting vast
geographical regions [8, 29, 90], deploying Point-of-Presence (PoPs)
at Intenet eXchange Points (IXPs) [2] and colocation facilities [47]
closer to their customers [67]. Due to these advancements in the
backbone, the cloud infrastructure was able to handle the sudden
rise in user traffic as the majority population moved to work-from-
home model around the globe in 2020 [31].
Beyond improving cloud computing infrastructure, interest has
recently grown in “edge computing”, a paradigm deploying compute
servers closer to the users and outside the managed cloud infrastruc-
ture, e.g., on ISP premises [28] or in city-owned buildings [53]. The
trend of edge computing is primarily driven by a widespread belief
that the current cloud infrastructure is too sparsely deployed to sup-
port the latency requirements of next-generation mission-critical
applications [23], such as AR/VR [56], autonomous vehicles [49], etc.
However, the cloud infrastructure has improved dramatically since
the inception of edge computing in 2009 [72]. Along with advances
in the backbone, cloud hypergiants have also invested heavily in
installing new datacenters in previously under-provisioned loca-
tions [76]. Furthermore, many new small-to-medium-sized cloud
providers, such as Vultr, Linode, DigitalOcean, etc., have entered the
market and focus their services on specific geographical regions.
However, the growth in the cloud ecosystem has remained largely
unnoticed by researchers. This can be primarily attributed to a
shortage of impartial studies that investigate the state of cloud
reachability and the factors that impact it globally. Few previous
works in this space are either out-of-date since they do not cap-
ture the recent expansion of cloud infrastructure [48], cover only
a limited set of cloud providers [8], or use vantage points that do
not consider users in home environments using wireless connectiv-
ity [22]. In this paper, we plug this gap in research by providing a
well-rounded, comprehensive analysis of cloud connectivity rep-
resentative of the majority of real Internet users across the globe.
Specifically, we make the following key contributions in this paper:
(1) We conduct a large-scale measurement study spanning over six
months targeting the compute cloud regions of nine major cloud
providers with a global presence - totalling 195 datacenters deployed
in 28 countries (§3.1). We use 115,000 probes in 140 countries from
the commercial measurement platform Speedchecker [52] as our
vantage points. Speedchecker probes are end-user mobile devices
62
IMC ’21, November 2–4, 2021, Virtual Event, USA
Dang and Mohan et al.
deployed in thousands of networks across the globe (§3.2). Our
vantage point selection allows us to assess cloud connectivity from
ASes that are estimated to host 95.6% of the world’s Internet users.
We measure user-to-cloud latency (ping) and path (traceroute)
over TCP and ICMP, respectively. We find that the geographical
location of the datacenter has the most impact on cloud access
latency as users in under-provisioned continents (like Africa or
South America) get significantly worse performance than North
America or Europe. For large parts of Africa and South America,
traversing long undersea cables to reach datacenters in neighbour-
ing better-provisioned continents can result in lower overall latency
compared to relying on limited in-continent options.
(2) We compare our Speedchecker measurements to the previous
reachability experiments conducted over 8000+ RIPE Atlas probes
deployed in 184 countries targeting the same cloud regions (§4.2).
We find that the Atlas probes achieve significantly lower latency in
all continents (except South America, due to skewed probe distribu-
tion in countries hosting datacenters) almost consistently. Further
investigation reveals the primary contributing factors to be (a) the
wired nature of last-mile access of Atlas hardware probes; and (b)
often managed (and non-residential) deployment locations of the
probes. As a result, we find that the choice of measurement plat-
form significantly affects the measurement results and analyses
outcomes as RIPE Atlas may not accurately represent the connec-
tivity of typical Internet users. On the other hand, the results over
RIPE Atlas are a good yardstick for estimating cloud reachability
for enterprise (non-residential) customers of cloud providers.
(3) As the Speedchecker probes use WiFi or cellular connections
to access the Internet, we also isolate the impact of a wireless
last-mile on overall cloud access latency (§5). We find that for a
large majority of the population, wireless last-mile still acts as the
primary bottleneck in user’s path to cloud - taking almost 40-50% of
the total median latency globally. Compared to measurements from
RIPE Atlas probes using wired connections, wireless can account
for 2-3× additional latency. Since future applications will continue
to rely on wireless medium irrespective of computing being handled
by cloud or edge, the last-mile will make support for latency-critical
applications quite problematic. Interestingly, we find that the type
of wireless access (WiFi vs. cellular) does not have a significant
impact on end-to-end latency as both connection types show similar
variations in last-mile.
(4) We identify different types of interconnections that exist be-
tween ISPs and cloud providers and quantify the performance dif-
ferences caused by them (§6). Our client-facing peering analysis
reveals that the inbound traffic towards big-3 hypergiant cloud
providers (Amazon, Microsoft, and Google) avoids the public Inter-
net paths altogether, thanks to direct peering agreements between
these providers and the majority of serving ISPs globally. However,
our findings show that latency performance benefits of setting up
direct peering are limited in developed continents like Europe as
public Internet is well-provisioned and offers minimal overhead.
On the other hand, in developing regions such as Asia, direct (or
private) peering, along with the use of private WAN, results in sig-
nificant improvement in latency variations – allowing connections
to achieve consistent latencies even while traversing large geograph-
ical distances. As a result, the approach seems to be the best fit in
63
continents where a cloud provider intends to deliver a consistent
quality-of-service to its clients despite limited motivation to deploy
new datacenters.
To foster reproducibility, we publish our collected dataset of 3.8M
ping and 7+M traceroute measurements at [60] and scripts at [25].
Additionally, readers can find other supporting datasets related to
our study at https://cloudreachability.github.io/.
2 BACKGROUND & RELATED WORK
2.1 Cloud Access over the Internet
Significant efforts have been made over the years to understand the
connectivity and latencies within the Internet at different levels.
Researchers have focused on mapping an accurate representation of
the Internet topology at router level [10, 11], AS-level [35, 57], and
PoP-level [77]. Based on these works, several studies have shined a
light on how recent advancements in cloud expansion - with the
rise of IXPs [2, 46] and cloud-owned private WANs [8, 29] - have
resulted in the “flattening” of traditionally hierarchical Internet
topology [9]. The endeavours to reduce overheads of the transit
Internet backbone have also been fuelled by significant competition
within new and existing cloud providers, all contending to control
the multi-billion-dollar cloud services market [36].
However, despite these advancements assisting cloud infrastruc-
ture, efforts to evaluate global cloud access latency have remained
fairly limited. Related works on the subject were either conducted
before the growth of cloud networks [48] or focused on a single
cloud provider [45]. Others have concentrated on either analyz-
ing the impact of private WAN from within the cloud network to
client ISP [9] or for providing multi-cloud inter-connectivity [92].
ThousandEyes annual report in 2019 [86] compared latency for
five different cloud providers, but only utilized 98 vantage points
- all hosted in datacenters. Corneo et al. [22] conducted a global
cloud reachability study targeting nine different cloud providers
globally (same as this study) but over RIPE Atlas platform [81].
However, RIPE Atlas is known to be influenced by deployment
biases as many vantage points are hosted within managed infras-
tructures, e.g., premises of network service providers, educational
institutes, etc. [12, 14, 78] – hence not accurately representing the
connectivity of real Internet users globally.
The study by Arnold et al. [8] is most noteworthy to us. The
focus of author’s work was to isolate (possible) latency gains when
using cloud provider’s private WAN compared to the public Inter-
net. The authors used Speedchecker probes [52] as vantage points
(same as this study) and targeted their 22 VM-based endpoints (11
using private WAN and 11 using public Internet) deployed in two
hypergiant cloud networks - Amazon and Google. In contrast to [8],
the focus of this study is to analyze the reachability and impact of
cloud expansion for Internet users across the globe. As a result, we
use 195 compute cloud regions operated by nine different providers
(with a mix of hypergiants and small providers) as endpoints. As
such, our study presents a broader overview and gives us an accu-
rate insight into real Internet user metrics when they connect to
the cloud for accessing a myriad of networked services.
Since we aim to understand if the growth in current cloud in-
frastructure is feasible for supporting the latency requirements of
mission-critical applications for Internet users globally, we use the
Cloudy with a Chance of Short RTTs
IMC ’21, November 2–4, 2021, Virtual Event, USA
following QoE directives [59] when discussing the latency aspects
of this study (§4). Motion-to-Photon (MTP) is the delay between
user input, and it’s reflecting on the display, which is estimated to
be ≈ 20 ms. Keeping below this threshold is a strict requirement for
immersive applications like AR and VR to avoid motion sickness
and dizziness. Human Perceivable Latency (HPL) of ≈ 100 ms
is the threshold when a user starts to experience lags - and is in-
fluential for applications such as cloud gaming. Human Reaction
Time (HRT) denotes the delay difference between a visual stimu-
lus and the associated motor response and is estimated to be ≈ 250
ms. The threshold guides the operation of applications involving
human-controlled tasks like remote surgery.
2.2 Last-Mile Latencies
The “last-mile” is generally regarded as the segment connecting the
end-user to its ISP, either via wired or wireless access technology.
Previous efforts have focused on studying the characteristics of
fixed broadband at a large scale [18, 33, 83, 87]. In [13], the authors
investigated last-mile latency from residential probes in Europe
and the United States, not including latencies within the home
network. Despite the fixed connection to the managed backhaul,
previous studies on the topic have revealed last-mile to be the
primary congestion and latency bottleneck [33].
While significant efforts have been made to analyze isolated
characteristics of wireless technology [75, 84], there is a significant
lack of visibility in understanding the impact of wireless on Inter-
net connectivity at a large scale. The reason for this is primarily
two-fold. Firstly, studies on this topic rely heavily on specialized
monitoring methods, such as deploying custom hardware [70], us-
ing third-party datasets [83], designing trusted toolchains [68], or
setting up large-scale operational networks [82]. Secondly, there
is a lack of publicly-accessible global measurement platforms that