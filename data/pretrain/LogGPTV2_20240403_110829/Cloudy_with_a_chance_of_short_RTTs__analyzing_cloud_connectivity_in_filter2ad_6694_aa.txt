# Cloudy with a Chance of Short RTTs: Analyzing Cloud Connectivity in the Internet

**Authors:**
- The Khang Dang†
- Nitinder Mohan†
- Jörg Ott
- Lorenzo Corneo♯
- Aleksandr Zavodovski♯
- Jussi Kangasharju♭

**Affiliations:**
- ♮Technical University of Munich
- ♯Uppsala University
- ♭University of Helsinki
- †Equal contribution

## Abstract

Cloud computing has experienced continuous growth over the past decade. The recent surge in next-generation applications raises the question: "Can current cloud infrastructure support the low latency requirements of these applications?" Specifically, the interplay between wireless last-mile access and the global peering agreements established by cloud operators to enhance reachability and reduce latency remains largely unexplored.

This paper investigates end-user to cloud connectivity over wireless media through extensive measurements over six months. We leverage 115,000 wireless probes on the Speedchecker platform and 195 cloud regions from nine well-established cloud providers. Our study evaluates the suitability of current cloud infrastructure for emerging applications and highlights various pressure points. We also compare our results with a previous study using RIPE Atlas. Our key findings are: (i) geographical distance to the datacenter is the most significant factor affecting latency; (ii) the choice of measurement platform can significantly influence the results; (iii) wireless last-mile access contributes substantially to overall latency, often surpassing the impact of geographical distance. Additionally, we observe that cloud providers with their own private network backbone and direct peering agreements with ISPs offer noticeable improvements in latency, especially in consistency over longer distances.

## CCS Concepts
- **Networks → Public Internet; Network Measurement**

## Keywords
- Cloud connectivity
- Last-mile latency
- Peering
- Edge computing

## ACM Reference Format
The Khang Dang, Nitinder Mohan, Lorenzo Corneo, Aleksandr Zavodovski, Jörg Ott, and Jussi Kangasharju. 2021. Cloudy with a Chance of Short RTTs: Analyzing Cloud Connectivity in the Internet. In *ACM Internet Measurement Conference (IMC '21)*, November 2–4, 2021, Virtual Event, USA. ACM, New York, NY, USA, 18 pages. https://doi.org/10.1145/3487552.3487854

## Permission Notice
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.

## IMC '21, November 2–4, 2021, Virtual Event, USA
© 2021 Association for Computing Machinery.
ACM ISBN 978-1-4503-9129-0/21/11...$15.00
https://doi.org/10.1145/3487552.3487854

## 1. Introduction

Cloud computing has become a core enabler for the rapid growth of networked services on the Internet over the past decade [21]. Cloud providers have invested significantly in expanding their global footprint, deploying datacenters in new locations [9] and installing private backbones to interconnect vast geographical regions [8, 29, 90]. They have also deployed Points-of-Presence (PoPs) at Internet Exchange Points (IXPs) [2] and colocation facilities [47] closer to their customers [67]. These advancements in the backbone enabled the cloud infrastructure to handle the sudden rise in user traffic as the majority of the population shifted to a work-from-home model globally in 2020 [31].

In addition to improving cloud computing infrastructure, there has been growing interest in "edge computing," which deploys compute servers closer to users, outside the managed cloud infrastructure, such as on ISP premises [28] or in city-owned buildings [53]. This trend is driven by the belief that the current cloud infrastructure is too sparsely deployed to support the latency requirements of next-generation mission-critical applications [23], such as AR/VR [56] and autonomous vehicles [49].

However, the cloud infrastructure has improved dramatically since the inception of edge computing in 2009 [72]. Along with advances in the backbone, cloud hypergiants have heavily invested in new datacenters in previously under-provisioned locations [76]. Additionally, many small-to-medium-sized cloud providers, such as Vultr, Linode, and DigitalOcean, have entered the market, focusing on specific geographical regions.

Despite these developments, the growth in the cloud ecosystem has remained largely unnoticed by researchers. This can be attributed to a lack of impartial studies investigating the state of cloud reachability and the factors impacting it globally. Previous works in this area are either outdated [48], cover only a limited set of cloud providers [8], or do not consider users in home environments using wireless connectivity [22]. This paper fills this gap by providing a comprehensive analysis of cloud connectivity representative of the majority of real Internet users across the globe.

Specifically, we make the following key contributions in this paper:
1. We conduct a large-scale measurement study spanning six months, targeting the compute cloud regions of nine major cloud providers with a global presence, totaling 195 datacenters in 28 countries (§3.1). We use 115,000 probes in 140 countries from the commercial measurement platform Speedchecker [52] as vantage points. Speedchecker probes are end-user mobile devices deployed in thousands of networks globally (§3.2). Our vantage point selection allows us to assess cloud connectivity from ASes that host 95.6% of the world’s Internet users. We measure user-to-cloud latency (ping) and path (traceroute) over TCP and ICMP, respectively. We find that the geographical location of the datacenter has the most significant impact on cloud access latency, with users in under-provisioned continents (like Africa or South America) experiencing significantly worse performance than those in North America or Europe. For large parts of Africa and South America, traversing long undersea cables to reach datacenters in better-provisioned neighboring continents can result in lower overall latency compared to relying on limited in-continent options.

2. We compare our Speedchecker measurements to previous reachability experiments conducted over 8,000+ RIPE Atlas probes deployed in 184 countries targeting the same cloud regions (§4.2). We find that the Atlas probes achieve significantly lower latency in all continents (except South America, due to skewed probe distribution in countries hosting datacenters) almost consistently. Further investigation reveals the primary contributing factors to be (a) the wired nature of last-mile access of Atlas hardware probes; and (b) the often managed (and non-residential) deployment locations of the probes. As a result, we find that the choice of measurement platform significantly affects the measurement results and analyses outcomes, as RIPE Atlas may not accurately represent the connectivity of typical Internet users. On the other hand, the results over RIPE Atlas are a good yardstick for estimating cloud reachability for enterprise (non-residential) customers of cloud providers.

3. Since the Speedchecker probes use WiFi or cellular connections to access the Internet, we also isolate the impact of a wireless last-mile on overall cloud access latency (§5). We find that for a large majority of the population, wireless last-mile still acts as the primary bottleneck in the user’s path to the cloud, accounting for almost 40-50% of the total median latency globally. Compared to measurements from RIPE Atlas probes using wired connections, wireless can account for 2-3 times additional latency. Since future applications will continue to rely on wireless medium irrespective of whether computing is handled by the cloud or edge, the last-mile will make supporting latency-critical applications quite problematic. Interestingly, we find that the type of wireless access (WiFi vs. cellular) does not have a significant impact on end-to-end latency, as both connection types show similar variations in last-mile.

4. We identify different types of interconnections between ISPs and cloud providers and quantify the performance differences caused by them (§6). Our client-facing peering analysis reveals that inbound traffic towards the big three hypergiant cloud providers (Amazon, Microsoft, and Google) avoids public Internet paths altogether, thanks to direct peering agreements between these providers and the majority of serving ISPs globally. However, our findings show that the latency performance benefits of setting up direct peering are limited in developed continents like Europe, where the public Internet is well-provisioned and offers minimal overhead. On the other hand, in developing regions such as Asia, direct (or private) peering, along with the use of private WAN, results in significant improvement in latency variations—allowing connections to achieve consistent latencies even while traversing large geographical distances. As a result, this approach seems to be the best fit in continents where a cloud provider intends to deliver a consistent quality-of-service to its clients despite limited motivation to deploy new datacenters.

To foster reproducibility, we publish our collected dataset of 3.8 million ping and 7+ million traceroute measurements at [60] and scripts at [25]. Additionally, readers can find other supporting datasets related to our study at https://cloudreachability.github.io/.

## 2. Background & Related Work

### 2.1 Cloud Access over the Internet

Significant efforts have been made over the years to understand the connectivity and latencies within the Internet at different levels. Researchers have focused on mapping an accurate representation of the Internet topology at the router level [10, 11], AS-level [35, 57], and PoP-level [77]. Based on these works, several studies have highlighted how recent advancements in cloud expansion, with the rise of IXPs [2, 46] and cloud-owned private WANs [8, 29], have resulted in the "flattening" of traditionally hierarchical Internet topology [9]. The endeavors to reduce overheads of the transit Internet backbone have also been fueled by significant competition among new and existing cloud providers, all contending to control the multi-billion-dollar cloud services market [36].

Despite these advancements, efforts to evaluate global cloud access latency have remained fairly limited. Related works on the subject were either conducted before the growth of cloud networks [48] or focused on a single cloud provider [45]. Others have concentrated on analyzing the impact of private WAN from within the cloud network to client ISP [9] or for providing multi-cloud inter-connectivity [92]. The ThousandEyes annual report in 2019 [86] compared latency for five different cloud providers but only utilized 98 vantage points—all hosted in datacenters. Corneo et al. [22] conducted a global cloud reachability study targeting nine different cloud providers globally (same as this study) but over the RIPE Atlas platform [81]. However, RIPE Atlas is known to be influenced by deployment biases, as many vantage points are hosted within managed infrastructures, e.g., premises of network service providers, educational institutes, etc. [12, 14, 78]—hence not accurately representing the connectivity of real Internet users globally.

The study by Arnold et al. [8] is particularly noteworthy. Their focus was to isolate (possible) latency gains when using a cloud provider's private WAN compared to the public Internet. The authors used Speedchecker probes [52] as vantage points (same as this study) and targeted their 22 VM-based endpoints (11 using private WAN and 11 using public Internet) deployed in two hypergiant cloud networks—Amazon and Google. In contrast, our study aims to analyze the reachability and impact of cloud expansion for Internet users across the globe. We use 195 compute cloud regions operated by nine different providers (with a mix of hypergiants and small providers) as endpoints. Thus, our study presents a broader overview and provides accurate insights into real Internet user metrics when they connect to the cloud for accessing a myriad of networked services.

Since we aim to understand if the growth in current cloud infrastructure is feasible for supporting the latency requirements of mission-critical applications for Internet users globally, we use the following Quality of Experience (QoE) directives [59] when discussing the latency aspects of this study (§4):
- **Motion-to-Photon (MTP):** The delay between user input and its reflection on the display, estimated to be ≈ 20 ms. Keeping below this threshold is a strict requirement for immersive applications like AR and VR to avoid motion sickness and dizziness.
- **Human Perceivable Latency (HPL):** The threshold when a user starts to experience lags, estimated to be ≈ 100 ms, and is influential for applications such as cloud gaming.
- **Human Reaction Time (HRT):** The delay difference between a visual stimulus and the associated motor response, estimated to be ≈ 250 ms. This threshold guides the operation of applications involving human-controlled tasks like remote surgery.

### 2.2 Last-Mile Latencies

The "last-mile" is generally regarded as the segment connecting the end-user to their ISP, either via wired or wireless access technology. Previous efforts have focused on studying the characteristics of fixed broadband at a large scale [18, 33, 83, 87]. In [13], the authors investigated last-mile latency from residential probes in Europe and the United States, excluding latencies within the home network. Despite the fixed connection to the managed backhaul, previous studies on the topic have revealed the last-mile to be the primary congestion and latency bottleneck [33].

While significant efforts have been made to analyze isolated characteristics of wireless technology [75, 84], there is a significant lack of visibility in understanding the impact of wireless on Internet connectivity at a large scale. This is primarily due to two reasons. First, studies on this topic rely heavily on specialized monitoring methods, such as deploying custom hardware [70], using third-party datasets [83], designing trusted toolchains [68], or setting up large-scale operational networks [82]. Second, there is a lack of publicly accessible global measurement platforms that provide comprehensive data on wireless last-mile performance.