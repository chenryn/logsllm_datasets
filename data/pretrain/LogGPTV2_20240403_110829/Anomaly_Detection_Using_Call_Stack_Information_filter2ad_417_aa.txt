title:Anomaly Detection Using Call Stack Information
author:Henry Hanping Feng and
Oleg M. Kolesnikov and
Prahlad Fogla and
Wenke Lee and
Weibo Gong
Anomaly Detection Using Call Stack Information
Henry Hanping Feng1, Oleg M. Kolesnikov2, Prahlad Fogla2, Wenke Lee2, and Weibo Gong1
1 Department of Electrical and Computer Engineering
2 College of Computing
University of Massachusetts
{hfeng, gong}@ecs.umass.edu
Amherst, MA 01003
Georgia Institute of Technology
Atlanta, GA 30332
{ok, prahlad, wenke}@cc.gatech.edu
Abstract
The call stack of a program execution can be a very good
information source for intrusion detection. There is no prior
work on dynamically extracting information from call stack
and effectively using it to detect exploits. In this paper, we
propose a new method to do anomaly detection using call
stack information. The basic idea is to extract return ad-
dresses from the call stack, and generate abstract execu-
tion path between two program execution points. Experi-
ments show that our method can detect some attacks that
cannot be detected by other approaches, while its conver-
gence and false positive performance is comparable to or
better than the other approaches. We compare our method
with other approaches by analyzing their underlying prin-
ciples and thus achieve a better characterization of their
performance, in particular, on what and why attacks will be
missed by the various approaches.
1
Introduction
A lot of research has focused on anomaly detection by
learning program behavior. Most of the methods proposed
were based on modeling system call traces. However, there
has not been much improvement on system call based meth-
ods recently in part because system calls themselves only
provide limited amount of information.
Invoking system
calls is only one aspect of program behavior. We can also
use other aspects, such as the information contained in the
call stack, for intrusion detection purposes.
There is prior work on using ﬁnite state automata (FSA)
to model program behavior. Wagner et al.
proposed
to statically generate a non-deterministic ﬁnite automa-
ton (NDFA) or a non-deterministic pushdown automaton
(NDPDA) from the global control-ﬂow graph of the pro-
gram [17]. The automaton was then used to monitor the
program execution online. Sekar et al. proposed to gener-
ate a compact deterministic FSA by monitoring the program
execution at runtime [16]. Both methods were proposed as
system-call-based. However, what is really appealing is that
both implicitly or explicitly used the program counter in-
formation to construct states. The program counter (PC)
indicates the current execution point of a program. Because
each instruction of a program corresponds to a distinct PC,
this location information may be useful for intrusion detec-
tion.
In addition to the current PC, a lot of information can
be obtained about the current status and the history (or the
future, depending on how it is interpreted) of program exe-
cution from the call stack, particularly in the form of return
addresses. Thus, the call stack can be a good information
source for intrusion detection. However, to the best of our
knowledge, there is no prior work on dynamically extract-
ing information from the call stack and effectively using this
information to detect exploits.
In this paper, we propose a new anomaly detection
method, called VtPath, that utilizes return address informa-
tion extracted from the call stack. Our method generates
the abstract execution path between two program execu-
tion points, and decides whether this path is valid based on
what has been learned on the normal runs of the program.
We also developed techniques to handle some implementa-
tion issues that were not adequately addressed in [16], us-
ing techniques that are much simpler than those described
in [17].
Based on our understanding of the principles behind Vt-
Path and the approaches in [17, 16], we believe the VtPath
method can detect some attacks that cannot be detected by
the other approaches. We developed several attacks in our
experiments to verify that this is indeed the case. Our ex-
perimental results also show that the VtPath method has
similar convergence and false positive performance as the
deterministic FSA based approach.
Another contribution of this paper is that we attempt to
compare the various approaches by analyzing their under-
lying principles and thus achieve a better characterization
of their performance, particularly on what and why attacks
Proceedings of the 2003 IEEE Symposium on Security and Privacy (SP(cid:146)03) 
1081-6011/03 $17.00 ' 2003 IEEE 
will be missed by the various approaches.
The rest of the paper is organized as follows. Section
2 describes the related research. Section 3 presents the Vt-
Path method. Section 4 discusses important implementation
issues. Section 5 presents experimental evaluation results.
Section 6 presents the comparison of the VtPath method to
other approaches. Section 7 summarizes the paper and dis-
cusses future work.
2 Related Work
The callgraph model Wagner et al. proposed character-
izes the expected system call traces using static analysis of
the program code [17]. The global control-ﬂow graph is
naturally transformed to a NDFA. This automaton is non-
deterministic because in general which branch of choices
will be taken cannot be statically predicted. The NDFA can
then be used to monitor the program execution online. The
operation of the NDFA is simulated on the observed system
call trace non-deterministically. If all the non-deterministic
paths are blocked at some point, there is an anomaly. It was
stated that there were no false alarms because all possible
execution paths were considered in the automaton.
Wagner et al. pointed out that the callgraph model allows
some impossible paths. Basically, if a function is called
from one place but returns to another, the model will al-
low the impossible path, which should not occur in any
normal run. We refer to this as the impossible path prob-
lem. To solve it, Wagner et al. proposed a complex push-
down automaton model, called the abstract stack model, in
which the stack forms an abstract version of the program
call stack. Namely, everything but the return addresses is
abstracted away. We use a similar virtual stack structure
for our method, but we avoid the complex generation and
simulation of pushdown automata. In addition, our method
dynamically extracts information from call stack at runtime,
while both of the above models only dynamically monitor
system calls.
One main problem of the above models is that the mon-
itor efﬁciency is too low for many programs. The moni-
tor overhead is longer than 40 minutes per transaction for
half of the programs in their experiments [17]. This is
because of the complexity of pushdown automata and the
non-determinism of the simulation. Also, too much non-
determinism may impair the ability to detect intrusions.
This problem is not well addressed in the paper. There may
be scalability problem too because of the human efforts in
reﬁning models for some libraries.
Gifﬁn et al.
reﬁned the ideas behind the above mod-
els [7]. Their approach applies static analysis on binary
executables, so it is not dependent on any programming lan-
guage, but on working platforms. They developed many op-
timization and obfuscation techniques to improve the preci-
sion and efﬁciency. In particular, “inserting null calls” is
their main technique to largely decrease the degree of non-
determinism and help solve the impossible path problem,
and consequently, increase the precision. This technique
requires the rewriting of the executables and the change of
the call name space. This may be appropriate for remote
execution systems, which is the application context of their
approach. However, this technique may be inappropriate
or undesired under the common host-based anomaly detec-
tion environment. In addition, Gifﬁn et al. reported high
efﬁciency (low overhead) in their experiments. They added
large delay per real system call to simulate network round
trip time (RTT), and small delay (4 magnitudes lower than
the simulated RTT delay) for each null call inserted. It is
possible that most of the run time was spent on the simu-
lated RTT delay, and the relative overhead appeared small
even if many null calls were added. In particular, the net-
work delay for thousands of null calls inserted is only com-
parable to the delay for one real system call. The relative
overhead may not appear so small under the common host-
based anomaly detection environment with no network de-
lay involved.
The method proposed by Sekar et al. does not have the
problems related to non-determinism. Instead of statically
analyzing the source code or binary, the method (we call it
the FSA method) generates a deterministic FSA by monitor-
ing the normal program executions at runtime. Each distinct
program counter at which a system call is made is a state.
System calls are used as the labels for transitions. The FSA
can then be used to monitor the program execution online.
If the stack crashes, or a state or transition does not exist,
there may be an anomaly. There are false positives also be-
cause some legal transitions or states may never occur dur-
ing training. Because each transition is deterministic, the ef-
ﬁciency is high and the method will not miss intrusions due
to non-determinism. The FSA method also suffers from the
impossible path problem mentioned earlier in this section.
This problem was not addressed in the paper. Also, some
implementation issues were not adequately addressed. The
way DLLs were handled is so simple that some intrusions
on the DLLs may be missed. We will have a more detailed
discussion on these issues later in the paper.
Ashcraft et al. proposed to use programmer-written com-
piler extensions to catch security holes [1]. Their basic
idea is to ﬁnd violations of some simple rules using system-
speciﬁc static analysis. One example of these rules is “inte-
gers from untrusted sources must be sanitized before use”.
While we agree that their method or this kind of methods
can be very useful in ﬁnding programming errors, we do not
think it is a panacea that can solve all the problems. A lot
of security requirements are subtle and cannot be described
in simple rules. For example, their range checker can only
guarantee “integers from untrusted sources are checked for
Proceedings of the 2003 IEEE Symposium on Security and Privacy (SP(cid:146)03) 
1081-6011/03 $17.00 ' 2003 IEEE 
range”, but not “checked for the right range”, because “the
right range” is very subtle and too instance-speciﬁc to be
developed for each instance of untrusted integers. As a re-
sult, sometimes we can decide whether an action should be
permitted only by checking whether this action occurs be-
fore in normal situations. We think dynamic monitoring
based anomaly detection methods, such as our method and
the FSA method, are still important even if there are many
static bug removers. In fact, these two kinds of approaches
are good complements to each other. The static methods
can remove many logically obvious bugs, and because we
cannot remove all the bugs, dynamic monitoring can help
detect the exploits on the remaining holes. Another problem
with Ashcraft’s approach is that the rules have to be system-
speciﬁc because “one person’s meat is another person’s poi-
son”. The human efforts to develop these rules may not be
as easy. If the rules developed are not precise enough to
generate low false positives, the programmers will just think
of some ways to bypass the rule checking.
There are many methods that only model system call
traces. The N-gram method models program behavior us-
ing ﬁxed-length system call sequences [8, 5]; data min-
ing based approaches generate rules from system call se-
quences [12, 11]; Hidden Markov Model (HMM) and Neu-
ral Networks were used [19, 6]; algorithms originally devel-
oped for computational biology were also introduced into
this area. In [20], Wespi et al. presented a novel technique
to build a table of variable-length system call patterns based
on the Teiresias algorithm. Teiresias algorithm was initially
developed for discovering rigid patterns in unaligned bio-
logical sequences [14, 4]. This algorithm is quite time and
space consuming when applied on long traces containing
many maximal patterns. Wespi et al. announced that their
method worked better than N-gram. However, N-gram gen-
erated the highest scores it could possibly generate on all
their intrusion traces. This may suggest the attacks they
chose are inherently easy to detect. So although Wespi’s
method generated higher looking scores, this does not nec-
essarily mean it works better.
Cowan et al. proposed a method, called StackGuard, to
detect and prevent buffer overﬂow attacks [2, 3]. Stack-
Guard is a compiler technique for providing code pointer
integrity checking to the return address. The basic idea is
to place a “canary” word next to the return address on the
stack, and check if this word was modiﬁed before the func-
tion returns. This is a good idea and may work well with
buffer overﬂow attacks, but it is not effective in detecting
many other kinds of attacks.
All methods described above have their advantages and
disadvantages. In the next section, we will develop a new
method that combines some advantages of the automaton
based methods while avoiding their problems. Our method
trains the model by monitoring at runtime, so it is closer to
the FSA method.
3 The VtPath Model
Although closely related, our method has many prop-
erties that the FSA method does not possess. It uses call
stack history as well as the current PC information. This
can help detect more intrusions.
It explicitly lists which
function boundaries a transition traverses. This makes the
model more precise. Our method is able to handle many im-
plementation issues, such as signal handling. These issues
were not considered for the FSA method. Also, our method
handles DLL functions just like statically linked functions.
This avoids the potential problems for the FSA method re-
lated to its unnecessary simpliﬁcation. Our model is called
VtPath because one main concept we use is called virtual
path.
3.1 Background
Each instruction corresponds to a distinct program
counter. However, it is neither necessary nor possible in
efﬁciency to follow all these program counters. The FSA
method records the program counter information at each
system call. This is a good choice because system calls
are where the program interacts with the kernel. In our ap-
proach, we also record program counter information at each
system call.
In the future, we may record information at
other places as well, for example, when each jump or func-
tion call instruction is executed. We make the following
assumption:
Assumption The program counter and call stack can be