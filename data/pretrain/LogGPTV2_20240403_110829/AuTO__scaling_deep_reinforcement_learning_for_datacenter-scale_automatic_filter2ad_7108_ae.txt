### Median Response Time and Impact on sRLA
The median response time is 25.14 ms. However, in high-load scenarios, this can increase significantly. To understand the impact on the response latency of sRLA, we conducted an experiment where we varied the response time (ms) from 100 ms (used in the previous experiments) to 1000 ms and measured the corresponding response latency. Our findings indicate that the average response time only slightly increases for larger values of ms. This is because ms determines the input layer size, which affects only the matrix size of link weights between the input layer and the first hidden layer. Moreover, if AuTO employs more complex DNNs in the future, the response latency can be reduced using parallelization techniques proposed for DRL [6, 25, 27, 39].

### CS Scalability
Our testbed is relatively small, so the NIC capacity of the CS server is not fully saturated. Using the same parameter settings as in the previous experiments (ยง6.1.3), the bandwidth of monitoring flows is 12.40 Kbps per server. Assuming a 1 Gbps network interface, the CS server should support up to 80,640 servers, which is sufficient for typical production datacenters [50, 54]. We aim to achieve higher scalability through the following methods:
1. **Link Capacity**: The 1 Gbps link capacity was chosen to mimic the experimental environment. In current production datacenters, the typical bandwidth per server is usually 10 Gbps or higher [50, 54].
2. **Hardware Acceleration**: We expect CS to utilize GPUs or other hardware accelerators [46] to speed up computations.
3. **Flow Compression and Sampling**: We can reduce the bandwidth requirement of monitoring flows by implementing compression and/or sampling in PS.

### PS Overhead
End-host overhead refers to the additional work required for each flow to collect information and enforce actions. This overhead can be measured by CPU utilization and throughput reduction when PS is running. During our experiments, we measured both metrics and reran the flows without enabling MM and EM. We found that the throughput degradation is negligible, and the CPU utilization is less than 1%. Since EM is similar to the tagging module in PIAS [8], our results confirm that both the throughput and CPU overhead are minimal, consistent with PIAS.

### Related Works
There have been continuous efforts on Traffic Optimization (TO) in datacenters, exploring three main categories: load balancing, congestion control, and flow scheduling. We focus on proposals using machine learning techniques.

#### Routing and Load Balancing
RL-based techniques [13] have been used for routing and load balancing on the Internet since the 1990s. However, these are switch-based mechanisms, which are difficult to implement at line rate in modern datacenters with >10 GbE links. RL techniques are also used for adaptive video streaming in Pensieve [37].

#### Congestion Control
Machine learning techniques [59] have been employed to optimize parameter settings for congestion control. These parameters are fixed given a set of traffic distributions and do not adapt during runtime.

#### Flow Scheduling
CODA [61] uses unsupervised clustering algorithms to identify flow information without application modifications. However, its scheduling decisions are still made by a heuristic algorithm with fixed parameters.

### Concluding Remarks
Inspired by recent successes of DRL in solving complex online control problems, we aimed to enable DRL for automatic TO. Our experiments showed that the latency of current DRL systems is a major obstacle to TO at the scale of current datacenters. We addressed this by exploiting the long-tail distribution of datacenter traffic. We developed a two-level DRL system, AuTO, mimicking the Peripheral & Central Nervous Systems in animals, to solve the scalability problem. We deployed and evaluated AuTO on a real testbed, demonstrating its performance and adaptiveness to dynamic traffic in datacenters. AuTO is a first step towards automating datacenter TO, and we hope many software components in AuTO can be reused in other DRL projects in datacenters.

For future work, while this paper focuses on employing RL for flow scheduling and load balancing, we plan to develop RL algorithms for congestion control and task scheduling. Additionally, we will explore potential improvements mentioned in ยง5&6 and investigate applications of RL beyond datacenters, such as WAN bandwidth management.

### Acknowledgements
This work is supported in part by Hong Kong RGC ECS-26200014, GRF-16203715, CRF-C703615G, and China 973 Program No.2014CB340300. We thank the anonymous SIGCOMM reviewers and our shepherd David Andersen for their constructive feedback and suggestions.

### References
[References remain the same as provided in the original text.]