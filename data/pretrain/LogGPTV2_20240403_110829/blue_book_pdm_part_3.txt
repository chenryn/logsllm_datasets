build features. The idea is taken from Haskell's
[stack](https://docs.haskellstack.org).
However, unlike `stack`, by default, PDM won't use global project automatically
if a local project is not found. Users should pass `-g/--global` explicitly to
activate it, since it is not very pleasing if packages go to a wrong place. But
PDM also leave the decision to users, just set the config `auto_global` to
`true`.
If you want global project to track another project file other than
`~/.pdm/global-project`, you can provide the project path via
`-p/--project ` option.
Warning: Be careful with `remove` and `sync --clean` commands when global
project is used, because it may remove packages installed in your system Python.
# Configuration
All available configurations can be seen
[here](https://pdm.fming.dev/configuration/#available-configurations).
## [Dependency specification](https://pdm.fming.dev/pyproject/pep621/#dependency-specification)
The `project.dependencies` is an array of dependency specification strings
following the [PEP 440](https://www.python.org/dev/peps/pep-0440/) and
[PEP 508](https://www.python.org/dev/peps/pep-0508/).
Examples:
```toml
dependencies = [ "requests", "flask >= 1.1.0", "pywin32; sys_platform == 'win32'", "pip @ https://github.com/pypa/pip.git@20.3.1",]
```
### [Editable requirement](https://pdm.fming.dev/pyproject/pep621/#editable-requirement)
Beside of the normal dependency specifications, one can also have some packages
installed in editable mode. The editable specification string format is the same
as
[Pip's editable install mode](https://pip.pypa.io/en/stable/cli/pip_install/#editable-installs).
Examples:
```
dependencies = [
    ...,
    # Local dependency
    "-e path/to/SomeProject",
    # Dependency cloned
    "-e git+http://repo/my_project.git#egg=SomeProject"
]
```
Note: About editable installation. One can have editable installation and normal
installation for the same package. The one that comes at last wins. However,
editable dependencies WON'T be included in the metadata of the built artifacts
since they are not valid PEP 508 strings. They only exist for development
purpose.
### [Optional dependencies](https://pdm.fming.dev/pyproject/pep621/#optional-dependencies)
You can have some requirements optional, which is similar to `setuptools`'
`extras_require` parameter.
```toml
[project.optional-dependencies]
socks = [ "PySocks >= 1.5.6, != 1.5.7, = 1.2.2, = 1.0.1, ]`
section, with the same format of `[project.scripts]`:
```toml
[project.entry-points.pytest11]
myplugin = "mypackage.plugin:pytest_plugin"
```
## [Include and exclude package files](https://pdm.fming.dev/pyproject/tool-pdm/#include-and-exclude-package-files)
The way of specifying include and exclude files are simple, they are given as a
list of glob patterns:
```toml
includes = [ "**/*.json", "mypackage/",]
excludes = [ "mypackage/_temp/*",]
```
In case you want some files to be included in sdist only, you use the
`source-includes` field:
```toml
includes = [...]
excludes = [...]
source-includes = ["tests/"]
```
Note that the files defined in `source-includes` will be **excluded**
automatically from non-sdist builds.
### [Default values for includes and excludes](https://pdm.fming.dev/pyproject/tool-pdm/#default-values-for-includes-and-excludes)
If you don't specify any of these fields, PDM also provides smart default values
to fit the most common workflows.
- Top-level packages will be included.
- `tests` package will be excluded from **non-sdist** builds.
- `src` directory will be detected as the `package-dir` if it exists.
If your project follows the above conventions you don't need to config any of
these fields and it just works. Be aware PDM won't add
[PEP 420 implicit namespace packages](https://www.python.org/dev/peps/pep-0420/)
automatically and they should always be specified in `includes` explicitly.
## [Determine the package version dynamically](https://pdm.fming.dev/pyproject/pep621/#determine-the-package-version-dynamically)
The package version can be retrieved from the `__version__` variable of a given
file. To do this, put the following under the `[tool.pdm]` table:
```toml
[tool.pdm.version]
from = "mypackage/__init__.py"
```
Remember set `dynamic = ["version"]` in `[project]` metadata.
PDM can also read version from SCM tags. If you are using `git` or `hg` as the
version control system, define the `version` as follows:
```toml
[tool.pdm.version]
use_scm = true
```
In either case, you MUST delete the `version` field from the `[project]` table,
and include `version` in the `dynamic` field, or the backend will raise an
error:
```toml
dynamic = [ "version",]
```
## [Cache the installation of wheels](https://pdm.fming.dev/usage/project/#cache-the-installation-of-wheels)
If a package is required by many projects on the system, each project has to
keep its own copy. This may become a waste of disk space especially for data
science and machine learning libraries.
PDM supports _caching_ the installations of the same wheel by installing it into
a centralized package repository and linking to that installation in different
projects. To enabled it, run:
```bash
pdm config feature.install_cache on
```
It can be enabled on a project basis, by adding `--local` option to the command.
The caches are located under `$(pdm config cache_dir)/packages`. One can view
the cache usage by `pdm cache info`. But be noted the cached installations are
managed automatically. They get deleted when not linked from any projects.
Manually deleting the caches from the disk may break some projects on the
system.
Note: Only the installation of _named requirements_ resolved from PyPI can be
cached.
## [Working with a virtualenv](https://pdm.fming.dev/usage/project/#working-with-a-virtualenv)
Although PDM enforces PEP 582 by default, it also allows users to install
packages into the virtualenv. It is controlled by the configuration item
`use_venv`. When it is set to `True` (default), PDM will use the virtualenv if:
- A virtualenv is already activated.
- Any of `venv`, `.venv`, `env` is a valid virtualenv folder.
Besides, when `use-venv` is on and the interpreter path given is a venv-like
path, PDM will reuse that venv directory as well.
For enhanced virtualenv support such as virtualenv management and auto-creation,
please go for [pdm-venv](https://github.com/pdm-project/pdm-venv), which can be
installed as a plugin.
## [Use PDM in Continuous Integration](https://pdm.fming.dev/usage/advanced/#use-pdm-in-continuous-integration)
Fortunately, if you are using GitHub Action, there is
[pdm-project/setup-pdm](https://github.com/marketplace/actions/setup-pdm) to
make this process easier. Here is an example workflow of GitHub Actions, while
you can adapt it for other CI platforms.
```yaml
Testing:
  runs-on: ${{ matrix.os }}
  strategy:
    matrix:
      python-version: [3.7, 3.8, 3.9, 3.10]
      os: [ubuntu-latest, macOS-latest, windows-latest]
  steps:
    - uses: actions/checkout@v1
    - name: Set up PDM
      uses: pdm-project/setup-pdm@main
      with:
        python-version: ${{ matrix.python-version }}
    - name: Install dependencies
      run: |
        pdm sync -d -G testing
    - name: Run Tests
      run: |
        pdm run -v pytest tests
```
Note: Tips for GitHub Action users, there is a
[known compatibility issue](https://github.com/actions/virtual-environments/issues/2803)
on Ubuntu virtual environment. If PDM parallel install is failed on that machine
you should either set `parallel_install` to `false` or set env
`LD_PRELOAD=/lib/x86_64-linux-gnu/libgcc_s.so.1`. It is already handled by the
`pdm-project/setup-pdm` action.
Note: If your CI scripts run without a proper user set, you might get permission
errors when PDM tries to create its cache directory. To work around this, you
can set the HOME environment variable yourself, to a writable directory, for
example:
````
```bash
export HOME=/tmp/home
```
````
# How does it work
## [Why you don't need to use virtualenvs](https://frostming.com/2021/01-22/introducing-pdm/)
When you develop a Python project, you need to install the project's
dependencies. For a long time, tutorials and articles have told you to use a
virtual environment to isolate the project's dependencies. This way you don't
contaminate the working set of other projects, or the global interpreter, to
avoid possible version conflicts.
### [Problems of the virtualenvs](https://frostming.com/2021/01-22/introducing-pdm/#the-problems-with-virtual-environments)
Virtualenvs are confusing for people that are starting with python. They also
use a lot of space, as many virtualenvs have their own copy of the same
libraries. They help us isolate project dependencies though, but things get
tricky when it comes to nested venvs. One installs the virtualenv manager(like
Pipenv or Poetry) using a venv encapsulated Python, and creates more venvs using
the tool which is based on an encapsulated Python. One day a minor release of
Python is out and one has to check all those venvs and upgrade them if required
before they can safely delete the out-dated Python version.
Another scenario is global tools. There are many tools that are not tied to any
specific virtualenv and are supposed to work with each of them. Examples are
profiling tools and third-party REPLs. We also wish them to be installed in
their own isolated environments. It's impossible to make them work with
virtualenv, even if you have activated the virtualenv of the target project you
want to work on because the tool is lying in its own virtualenv and it can only
see the libraries installed in it. So we have to install the tool for each
project.
The solution has been existing for a long time. PEP 582 was originated in 2018
and is still a draft proposal till the time I copied this article.
Say you have a project with the following structure:
```
.
├── __pypackages__
│   └── 3.8
│       └── lib
└── my_script.py
```
As specified in the PEP 582, if you run `python3.8 /path/to/my_script.py`,
`__pypackages__/3.8/lib` will be added to `sys.path`, and the libraries inside
will become import-able in `my_script.py`.
Now let's review the two problems mentioned above under PEP 582. For the first
problem, the main cause is that the virtual environment is bound to a cloned
Python interpreter on which the subsequent library searching based. It takes
advantage of Python's existing mechanisms without any other complex changes but
makes the entire virtual environment to become unavailable when the Python
interpreter is stale. With the local packages directory, you don't have a Python
interpreter any more, the library path is directly appended to `sys.path`, so
you can freely move and copy it.
For the second, once again, you just call the tool against the project you want
to analyze, and the `__pypackages__` sitting inside the project will be loaded
automatically. This way you only need to keep one copy of the global tool and
make it work with multiple projects.
`pdm` installs dependencies into the local package directory `__package__` and
makes Python interpreters aware of it with
[a very simple setup](#how-we-make-pep-582-packages-available-to-the-python-interpreter).
### [How we make PEP 582 packages available to the Python interpreter](https://pdm.fming.dev/usage/project/#how-we-make-pep-582-packages-available-to-the-python-interpreter)
Thanks to the
[site packages loading](https://docs.python.org/3/library/site.html) on Python
startup. It is possible to patch the `sys.path` by executing the
`sitecustomize.py` shipped with PDM. The interpreter can search the directories
for the nearest `__pypackage__` folder and append it to the `sys.path` variable.
# [Plugins](https://pdm.fming.dev/plugin/write/)
PDM is aiming at being a community driven package manager. It is shipped with a
full-featured plug-in system, with which you can:
- Develop a new command for PDM.
- Add additional options to existing PDM commands.
- Change PDM's behavior by reading dditional config items.
- Control the process of dependency resolution or installation.
If you want to write a plugin, start
[here](https://pdm.fming.dev/plugin/write/#write-your-own-plugin).
# Issues
- You can't still
  [run `mypy` with `pdm`](https://github.com/pdm-project/pdm/issues/811) without
  virtualenvs. pawamoy created a
  [patch](https://github.com/python/mypy/issues/10633#issuecomment-974840203)
  that is supposed to work, but I'd rather use virtualenvs until it's supported.
  Once it's supported check the
  [vim-test](https://github.com/vim-test/vim-test/issues/606) issue to see how
  to integrate it.
- It's not yet supported by
  [dependabot](https://github.com/dependabot/dependabot-core/issues/3190). Once
  supported add it back to the cookiecutter template and spread it.
# References
- [Git](https://github.com/pdm-project/pdm/)
- [Docs](https://pdm.fming.dev/)