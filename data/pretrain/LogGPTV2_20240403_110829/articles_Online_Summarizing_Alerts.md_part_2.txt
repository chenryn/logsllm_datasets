influenceofnoisyalerts.Finally,eWarnbuildsaclassificationmodel 3
viamachinelearningandgeneratesaninterpretablereportforits
2
prediction.eWarnhasbeenappliedtotwolargecommercialbanks
inpractice,whichprovesitspracticabilityandeffectiveness. 1 0
3 MOTIVATION 0
Time
In this section, we use an illustrative example to motivate our
𝑡𝑡1𝑡𝑡2 𝑡𝑡3 𝑡𝑡4 𝑡𝑡5 𝑡𝑡6
approach.Table1showsanalertsnippetofalargecommercial
Figure1:Theoccurrenceseriesofcorrelatedalerts.
bank,A,inwhichthealerts,𝑒 1,𝑒 2,···,𝑒 5,areallcausedbythe
samefailure,“NTPstarterror”.Byremovingvariableparameters
andstopwordsfromcontents,thesealertscanbeclassifiedinto Thestraightforwardapproachistomeasurethesimilarityof
threetypes,𝐸 1,𝐸 2,and𝐸 3.Alertsofthesametypehavethesame twooccurrenceseriesusingEuclideanDistance(ED)orDynamic
parsedcontent.InTable1,𝑒 1and𝑒 3belongto𝐸 1,𝑒 2and𝑒 4belong TimeWarping(DTW).However,althoughthetwooccurrencese-
to𝐸 2,and𝑒 5belongsto𝐸 3. riesinFigure1aresimilarin[𝑡 1,𝑡 2]and[𝑡 3,𝑡 4],theyhavedifferent
Ourstudyaimstoautomaticallysummarizesuchalertsintoa shapesin[𝑡 5,𝑡 6].Thisisbecausetheoccurrenceofalertsisaffected
group,namedasincident,therebyreducingthenumberofalertsan- bymanyfactors,likealertdetectionmechanism,failureseverity,
alyzedbymaintenanceengineers.Tominethecorrelationbetween failureduration,andsoon.Anotheralternativeistominefrequent
alerts,inthispaper,weleveragetwotypesofalertinformation, patterns(orsequences)[10,12,28].Buttheycanonlyfindincidents
semanticinformationandbehaviorinformation. withfrequentalerttypes.Theinfrequentones,althoughmoreim-
portant,willbemissed.
3.1 SemanticInformation Inthispaper,weproposeadatadrivenmodel,ABR(AlertBe-
AsshowninTable1,contentsofthealertof𝐸 2and𝐸 3havesome haviorRepresentation),torepresentthebehaviorinformationofan
alert.InspiredbySkip-Gram[19],ABRcapturethecommonality
commonkeywords,suchas“NTP”and“start”,whichrevealsthe
betweentheoccurrenceseriesofcorrelatedalerts.Moreover,ABR
commonsemanticinformationbetweenalerts.However,mining
utilizesthesupervisedlearningtoleveragetheexpertknowledge.
suchcommonsemanticinformationisnottrivial,becauseitisoften
Theadvantageisthateventheoccurrenceseriesofcorrelatedalerts
thatcorrelatedalertshaveonlyafewcommonwordsandmost
isnotintuitivelysimilar,ABRisstillabletocapturetheircommon
wordsintheircontentsaredifferent.Therefore,popularapproaches,
behaviorinformation.
likeJaccard[31]andWord2Vec[19],mayfailtocapturesuchfaint
commonsemanticinformation.
3.3 CombiningSemanticandBehavior
Toattacksuchproblem,inthispaper,weproposeadeeplearn-
Information
ingbasedmodel,namedASR(AlertSemanticsRepresentation),to
extractthe semanticinformationofalerts. ASRnot onlymines Afterextractingthesemanticinformationandthebehaviorinfor-
thecontextualinformationofeachalertword,butalsoconsiders mationofthealert,itischallengingtoeffectivelycombinethem
ICSE’22,May21–29,2022,Pittsburgh,PA,USA JiaChen,PengWang,andWeiWang
Table1:Asnippetofanalertsequence
No. ID Timestamp Content
𝑒 1 𝐸 1 2018/5/118:00 Thereisn’teffectiveconfigurationin/var/opt/conf/bank_name_check.conf,pleaseretouchthefile.
𝑒 2 𝐸 2 2018/5/118:01 RunningNTPstart-upcheckscriptfailed,tried1time(s).
𝑒 3 𝐸 1 2018/5/118:01 Thereisn’teffectiveconfigurationin/var/opt/conf/bank_name_check.conf,pleaseretouchthefile.
𝑒 4 𝐸 2 2018/5/118:02 RunningNTPstart-upcheckscriptfailed,tried2time(s).
𝑒 5 𝐸 3 2018/5/118:03 TheNTPdaemonserverhasnotbeenstartcorrectly.
tofinallydeterminethecorrelationbetweenalerts.Thenaiveap- result,thealertcontentcontainsthesemanticinformationofthe
proachistoconsidersemanticinformationandbehaviorinforma- alert,andtheoccurrenceseriescontainsthebehaviorinformation
tionseparately.Giventwoalerts,computingthesimilaritybetween ofthealert.
theirsemanticinformationorbehaviorinformation,aslongasone Forconvenience,wedefinetheparsedalertsequenceas𝑆 =
similarityexceedsthethreshold,thesetwoalertsareconsidered [𝑒 1,𝑒 2,···,𝑒 𝑛].Foranalert,𝑒 𝑖(1≤𝑖 ≤𝑛),thetimestampisdenoted
ascorrelated.However,duetothecomplexityandvarietyofthe as𝑡 𝑖.Wehaveasetofalerttypes,{𝐸 1,𝐸 2,···,𝐸 𝑚},andeachalert
alertmechanism,itisinfeasibletomanuallysettheappropriate belongtoonealerttype.𝑊 𝑖 (|𝑊 𝑖| = 𝑙 𝑖)recordsthewordsinthe
thresholdforalertsofallpossiblefailures. contentof𝑒 𝑖.Theoccurrenceseriesof𝑒 𝑖isreferredtoas𝐹 ∈R⌈ 𝛼𝛽 ⌉.
𝑖
Weproposeaneuralnetwork,calledACT(AlertCorrelaTion),to
combinethetwotypesofalertinformationfromASRandABR,and
4.2 Overview
determinethecorrelationbetweenalerts.Inthetrainingstage,we
TheobjectiveofOASistoutilizethesemanticandbehaviorinfor-
generateasetofalertpairs,eachofwhichhasalabel,correlatedor
mationofalertstosummarizealertsonline.Asaresult,alertsare
uncorrelated.TheACTnetworkautomaticallylearnstheoptimal
groupedintodifferentincidentsbyOAS,andeachincidentcontains
combinationmechanismfromthelabelleddata.
alertsofthesamesystemfailure.Inadditiontoreducethenumber
ofalerts,comparedtoasinglealertthatonlyfocusesonalocal
3.4 Supervisedvs.UnsupervisedApproach
phenomenonofafailure,anincidentcanreflectthewholeimpact
Unlikethestateofarts[13,31],weutilizesupervisedlearningap- ofthefailure,therebyhelpingmaintenanceengineersefficiently
proachestosummarizealerts.Wemakethischoiceduetofollowing locateandfixthefailure.
reasons.First,inmanycompanies,thelabelleddataiseasytoobtain. Figure2showsanoverviewofOAS.OAScontainsfourmain
Failurereportsarenaturallabelleddata[31].Eachfailurereport components,alertsemanticsrepresentation(ASR),alertbehavior
includesrelatedalerts,thefailureinformation,andsoon.Therefore, representation(ABR),alertcorrelation(ACT),andonlinesummariz-
anytwoalertsbelongingtoonefailurereportcanbeconsidered ing.OAShastwostages,trainingstageandsummarizingstage.In
ascorrelated.Second,incidentrecognitionisasubjectivetask.It thetrainingstage,OAStrainsthealertrepresentationmodels,ASR
mayhappenthatdifferentexpertshaveoppositeopinionsaboutthe andABR,andthealertcorrelationmodel,ACT,offlineaccordingto
correlationbetweenalerts,whichisinfluencedbythemaintenance thehistoryalertsequence.Inthesummarizingstage,basedonthe
systemandmechanism.Thus,thesupervisedapproachismore trainedmodels,OASsummarizesthenewlyreportedalertonline
appealingtomaintenanceengineers. byatimewindow.
4 BACKGROUNDANDAPPROACH 4.2.1 TrainingStage. AsshownintheleftpartofFigure2,alerts
intrainingdatasetarefirstparsedtogetalertcontentsandalert
OVERVIEW
occurrencesseries.Foreach𝑒 𝑖 inthetrainingdataset,weobtain
Inthissection,wepresentthenecessarybackgroundknowledge otheralertsinwindow[𝑡 𝑖 −𝑤,𝑡 𝑖]thatbelongtothesamefailure
andgivetheapproachoverview. with𝑒 𝑖.Supposethereexist𝑐 𝑖 alertscorrelatedto𝑒 𝑖 during[𝑡 𝑖 −
𝑤 1, ≤𝑡 𝑖] 𝑗, ≤wh 𝑐i 𝑖c )h .Aa lr ee rtd se cn oo rt re ed laa ts ed𝑅 𝑖 to= 𝑖[𝑒 c𝑟 a1𝑖 n,𝑒 b𝑟 2𝑖 e,· c· o· ll, e𝑒 c𝑟 t𝑐𝑖 d], f( r1 om≤ h𝑟𝑖 𝑗 ist≤ or𝑛 y,
4.1 AlertPreprocessing 𝑒 e𝑖
Givenanalertsequence,wefirstpreprocessalertsinfoursteps. failurereports.Itshouldbenotedthat𝑅 𝑖 maynotbeacomplete
Inthefirststep,weremovevariablesinthealertcontent.There set that contains all the alerts correlated to𝑒 𝑖. In fact, even an
arenumerousworksonparsingalerts[1,8,29].AsDrain[8]is experienceddomainexpertcannotguaranteethatineachofhis
apopularonlineparser,weadoptitastheparserofOAS.Inthe failurereports,allalertsbelongingtothereportedfailurearefound.
secondstep,wefurtherremovestopwordsfromthealertcontent, Ourapproachestrytolearngeneralrelationshipsbetweenavailable
sincestopwords,suchas"the","a",and"and",donotcarrymuch correlatedalerts,andapplythemtothenewlyreportedalertin
specificsemanticinformation.Inthethirdstep,accordingtoalert onlinealertstream.
contents,wegroupalertsintodifferenttypes,andthusalertsofthe Then,wetrainthesemanticsrepresentationmodel,ASR,and
sametypehavethesamealertcontent.Inthelaststep,foranalert, thebehaviorrepresentationmodel,ABR.SinceASRandABRhave
weformitsoccurrenceseriesbycountingthenumberofalertsof nodependency,theycanbetrainedseparately.Finally,wetrainthe
thesametypeper𝛼 minutesinthepast𝛽 minutes(𝛼 < 𝛽).Asa alertcorrelationmodel,ACT,tomeasurethecorrelationbetween
OnlineSummarizingAlertsthroughSemanticandBehaviorInformation ICSE’22,May21–29,2022,Pittsburgh,PA,USA
time wndow
Summarizing
history alerts alert content words (Alert A SS emR antics alert content words 𝒕𝒕 :𝒊𝒊 r− aw𝒘𝒘 a, l𝒕𝒕 e𝒊𝒊 rt egatS
𝑡𝑡 𝑡𝑡𝑡𝑡1 2 3: : :r r r ra a a a…w w w …a a a al l l le e e er r r rt t t 𝑒𝑒 𝑒𝑒 𝑒𝑒1 2 paa rle sr int ag lert𝑊𝑊 o𝐹𝐹c1 1c, ,𝑊𝑊 u𝐹𝐹r22 r,, 𝐹𝐹e𝑊𝑊 n3,c3 …e,… s,e𝐹𝐹, r𝑛𝑛𝑊𝑊 ie𝑛𝑛 R R(Ae elp per rre etAs Be eBn neRt tha aat tvi io oion nr) (Alert CA oC rrT elaTion) sumo mnl ai rn ie z ing 𝑊𝑊 a𝐹𝐹l𝑖𝑖𝑖𝑖 er𝑊𝑊 o𝑖𝑖𝑖𝑖 −− cc11 u,, 𝐹𝐹𝑊𝑊 r𝑖𝑖r−𝑖𝑖 e− 2n2 ,c, …e… ,s, 𝐹𝐹e𝑊𝑊 𝑗𝑗ri𝑗𝑗 espaa rle sr int g 𝑡𝑡 𝑡𝑡𝑖𝑖 𝑖𝑖− −𝑡𝑡 3 1𝑗𝑗 : : : :r r r ra a a aw w w w… a a a a… l l l le e e er r r rt t t 𝑒𝑒 𝑒𝑒 𝑒𝑒𝑗𝑗 𝑖𝑖 𝑖𝑖− −3 gniniarT sledom niart Stage
w t 3 s s ) t𝐹𝐹 𝑡𝑡 𝑖𝑖 − 2 t 𝑒𝑒 𝑖𝑖 − 2 1
𝑡𝑡𝑛𝑛: 𝑒𝑒𝑛𝑛
newl𝑡𝑡y𝑖𝑖 reported a𝑒𝑒l𝑖𝑖ert
Figure2:ThearchitectureofOAS.
alertsbytheminedsemanticandbehaviorinformationfromASR wordandhowtocalculatethecontributionofthealertwordtothe
andABR. overallalertsemantics.
AsshowninFigure3,foreachwordinthealertcontent,ASR
4.2.2 SummarizingStage. AsshownintherightpartofFigure2, adoptsawordembeddingmodel,namedCBOW(ContinuousBag-
forthenewlyreportedalertinthesummarizingstage,𝑒 𝑖,afteritis of-Words)[19],tominethecontextualinformationoftheword,
parsed,wecandirectlyextractitssemanticandbehaviorinforma- andutilizesIDF(InverseDocumentFrequency)[14,17]tocalculate
tionbytherepresentationmodels,ASRandABR,whicharetrained thesemanticcontributionoftheword.Morespecifically,inCBOW,
inthetrainingstage.Then,wemeasurethecorrelationbetween aneuralnetworkistrainedtominethecontextualinformationof
thenewlygeneratedalert,𝑒 𝑖,andpreviouslyreportedalertsduring awordbyextractingthecommonsemanticsbetweentheword
aspecifiedtimewindow,[𝑡 𝑖−𝑤,𝑡 𝑖].Accordingtoalertcorrelations anditsadjacentwords.IDFisawidelyusedfactortomeasurethe
foundbyACT,weproposeasummarizingstrategytoonlinegroup semanticimportanceofawordtothedocument,whichiscalcu-
thenewlyreportedalert,𝑒 𝑖,anditscorrelatedalertintoanincident. latedbydividingthetotalnumberofdocumentsbythenumberof
documentsthatcontainthetargetword.InASR,thedocumentis
5 ALERTREPRESENTATION referredtotheconcatenatecontentsofcorrelatedalertsinhistory
alerts.
Weproposetwoapproaches,ASR(AlertSemanticsRepresentation)
andABR(AlertBehaviorRepresentation),torepresenttheseman-
ticandbehaviorinformationofalertsrespectively.Asshownin
semantic
Figure2,extractingthesemanticrepresentationandthebehav- representation
iorrepresentationareindependent,thusthereisnodependency
𝒔𝒔𝒊𝒊
betweenASRandABR.
SUM
5.1 SemanticsRepresentation
contextual semantic
Alertsbelongingtothesamesystemfailurearelikelytohavesimilar information contribution
semanticinformation.Althoughtherearesomeexistingapproaches
thatcanbeusedtorepresentthesemanticinformationofalerts,
𝒊𝒊 𝒊𝒊
suchasJaccard[13,31],wordembedding[7,18],andtopicdistilla- 𝒗𝒗𝑷𝑷 𝒖𝒖𝑷𝑷
tion[33],theycannotextractthecompletesemanticsofthealert. .𝒊𝒊 .𝒊𝒊
𝒗𝒗. .𝑷𝑷 𝒖𝒖. .𝑷𝑷
TheJaccard-basedapproachnaivelycorrelatesalertswithsame
words,ignoringthecommonsemanticsbetweendifferentwords.