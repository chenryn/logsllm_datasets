Yes
machine-config, sdn, multus-*
create pods, update validatingwebhook-
configurations
Antrea
Yes
antrea-agent
patch nodes, patch pods, update services, 
update services/status
Calico
No
—
—
Cilium
Yes
cilium
update nodes, update pods, delete pods
Weave Net
No
—
—
12
Prisma by Palo Alto Networks | Kubernetes Privilege Escalation: Excessive Permissions in Popular Platforms | White Paper
Container Escape Blast Radius
Based on the identified powerful DaemonSets, in 50% of the Kubernetes platforms reviewed a single 
container escape was enough to compromise the entire cluster. In another 12.5%, a container escape 
was likely enough to take over some clusters. For 12.5% of platforms, a container escape was enough to 
compromise the entire cluster given a recommended feature was enabled.
Figure 9: Impact of container escape in the analyzed Kubernetes platforms
Yes
50%
25%
No
12.5%
Likely In Some Clusters
12.5%
With Certain Features
Container Escape == Cluster Admin?
Table 4: Impact of Container Escape Across Analyzed Platforms
Platform
Escape == Admin
Attack
Prerequisite
AKS
Yes
Acquire Token → Manipulate AuthN/Z
—
EKS
Likely in some clusters
Steal Pods
A stealable powerful pod
GKE
With Dataplane v2
Steal Pod / RCE → Acquire token → Manip-
ulate AuthN/Z
Dataplane v2 enabled
OCP
Yes
Acquire Token
—
Antrea
Yes
Steal Pods / RCE → Acquire token → 
 Manipulate AuthN/Z
—
Calico
No
—
—
Cilium
Yes
Steal Pod / RCE -→ Acquire token → Ma-
nipulate AuthN/Z
—
Weave Net
No
—
—
In some platforms, DaemonSets possessed admin-equivalent permissions, meaning that abusing them 
to acquire admin privileges was straightforward. In other platforms, DaemonSets weren't powerful 
enough to become full admins by themselves, but they did possess permissions that allowed them to 
take over other pods. In most of these platforms, because admin-equivalent pods were installed by 
default, attackers could still abuse the platform's DaemonSets to acquire admin privileges. 
In Antrea, for example, the antrea-agent DaemonSet wasn't powerful enough to acquire admin privileg-
es by itself, but it did possess powerful permissions allowing it to take over other pods. Because Antrea 
installs an admin-equivalent pod by default, the antrea-controller, antrea-agent's permissions could still 
have been exploited to acquire admin privileges by abusing them to compromise the antrea-controller pod.
13
Prisma by Palo Alto Networks | Kubernetes Privilege Escalation: Excessive Permissions in Popular Platforms | White Paper
If your clusters rely on one of the impacted platforms, please don’t panic. Here’s why:
1. 
To abuse powerful DaemonSets, attackers first need to compromise and then escape a container. 
Best practices and active defenses can prevent that.
2. 
Several platforms have already released versions that de-privilege powerful DaemonSets. 
3. 
Best practice hardenings can prevent certain attacks. For example, an allow-list policy for container 
images can hinder lateral movement attacks that abuse the ‘patch pods’ permission to replace the 
image of an existing pod with an attacker-controlled one.
4. 
That being said, if you run multitenant clusters, you’re at greater risk.
A “Likely in Some Clusters” in the “Escape == Admin” column signifies that there’s a prerequisite for 
a container escape to be enough to compromise the entire cluster, but that it’s likely to be met in some 
clusters. For example, an attacker abusing a powerful DaemonSet that can Steal Pods can only acquire 
cluster admin privileges if there’s an admin-equivalent pod to steal in the cluster. 
In EKS for example, there isn’t such a pod by default. Still, based on the sheer number of popular Ku-
bernetes add-ons that install admin-equivalent pods, it’s likely that this prerequisite is met in many 
clusters in-the-wild. Some popular projects that install admin-equivalent pods by default include 
ingress-nginx, cert-manager, Kynvero, traefik, and aws-load-balancer.
It's worth noting that with Cilium, there were two popular installation methods. The table above pertains 
to the one documented as the default—the cilium-cli. While the default Helm installation also deployed 
the same powerful DaemonSet that can take over other pods, it didn't deploy an admin-equivalent pod 
that can be targeted by it. Accordingly, when Cilium was installed via Helm, a container escape was only 
enough to compromise the entire cluster given the user installed an admin-equivalent pod (or, in other 
words, "Likely in Some Clusters"). 
Powerful Kubelets in Popular Platforms
While the majority of Kubernetes distributions and managed services have adopted the NodeRestriction 
admission controller, some still run powerful Kubelets. Powerful Kubelets introduce the same security risks 
as powerful DaemonSets—compromised nodes can escalate privileges and take over the rest of the cluster. 
Below is a breakdown of powerful Kubelets across the analyzed managed services and distributions.
Table 5: Powerful Kubelets Across Analyzed Managed Services and Distributions
Platform
Type
Powerful Kubelets
AKS
Managed Service
Yes
EKS
Managed Service
No
GKE
Managed Service
No
OCP
Distribution
No
Fixes and Mitigations by Affected Platforms
We reported the identified powerful DaemonSets and Kubelets to affected vendors and open source 
projects between December 2021 and February 2022. The vast majority of platforms pledged to strip 
powerful permissions from their Daemonsts, and some of them have already done so. From the original 
62.5%, only 25% still run powerful DaemonSets.
Table 6: Fixes and Mitigations by Affected Platforms
Platform
Had Powerful DaemonSets
Fixed
Had Powerful Kubelets
Fixed
AKS
Yes
No
Yes
WIP
EKS
Yes
Yes, from Kubernetes v1.18
No
—
GKE
With Dataplane v2
Yes, from v1.23.4-gke.900, 13022$ Bounty
No
—
OCP
Yes
WIP set for v4.11, possible backports
No
—
Antrea
Yes
Yes, v1.6.1 alongside an admission policy
No
—
Calico
No
—
No
—
Cilium
Yes
Yes, v1.12.0-rc2, some fixes backported
No
—
Weave Net
No
—
No
—
14
Prisma by Palo Alto Networks | Kubernetes Privilege Escalation: Excessive Permissions in Popular Platforms | White Paper
Platforms addressed powerful DaemonSets through a variety of techniques. Most applied one or more of 
these three solutions:
1. 
Remove: Certain permissions were deemed unnecessary, or too widely scoped, and were simply 
removed.
2. 
Relocate: Move the functionality that required the powerful permissions from DaemonSets 
 running on all nodes to deployments that run on few, or to the control plane.
 3. 
Restrict: Release admission policies that limit powerful DaemonSets to a number of safe and 
 expected operations.
According to the improvements above, the number of platforms where a single container escape is 
enough to compromise the entire cluster dropped from 50% to just 25%. Keep in mind that this number 
pertains to Kubernetes-native attacks and doesn’t cover possible platform-specific privilege escalations.
Figure 10: Impact of container escape in the analyzed Kubernetes platforms following fixes
75%
No
Yes
25%
Container Escape == Cluster Admin?
Stripping existing permissions can be challenging. We’d like to thank the vendors and open source 
projects mentioned in this report for their effort to remove powerful DaemonSets and Kubelets from 
their platforms.
Toward Better Node Isolation
One step at a time, Kubernetes is moving toward stronger node isolation. This effort started with the 
NodeRestriction admission controller and is slowly inching forward with every powerful permission 
removed from a popular DaemonSet. Complete node isolation is unlikely in the near future: some low 
severity attacks will likely remain, and certain nodes will need to host powerful pods. That being said, 
better node isolation is certainly possible. At the very least, clusters shouldn't host powerful credentials 
on every node. Removing Trampoline DaemonSets can ensure the majority of nodes are unprivileged.
Some powerful permissions will be harder to drop, in part due to the lack of fine-grained access control 
for certain operations. This shouldn't be seen as an "all or nothing" issue though. Even when certain 
permissions cannot be easily stripped, it's still a welcomed improvement when a DaemonSet that could 
previously acquire admin tokens is now only able to launch meddler-in-the-middle attacks.
Identifying Powerful Permissions
Whether you use a mentioned platform or not, if you run Kubernetes, your clusters likely host powerful 
pods. The first step of addressing risky permissions is identifying them. The following tools can be used 
to identify powerful permissions in running clusters and in Kubernetes manifests.
15
Prisma by Palo Alto Networks | Kubernetes Privilege Escalation: Excessive Permissions in Popular Platforms | White Paper
Figure 11: rbac-police alerts on excessive permissions of service accounts, pods, and nodes
Out of the box, rbac-police is equipped with more than 20 policies that each hunt for a different set of 
powerful permissions. It’s also 100% customizable though. You can write your own policies that search 
for any pattern in Kubernetes RBAC—powerful permissions we’ve missed, permissions that only affect 
certain platforms, or ones related to CRDs (Custom Resources Definitions). If you end up writing a policy, 
please consider contributing it.
Supported commands for rbac-police are as follows:
• rbac-police eval evaluates the RBAC permissions of services accounts, pods, and nodes through 
built-in or custom Rego policies.
• rbac-police collect retrieves the RBAC permissions of services accounts, pods, and nodes in a clus-
ter. Useful for saving a RBAC snapshot of the cluster for multiple evaluations with different options.
• rbac-police expand presents the RBAC permissions of services accounts, pods, and nodes in a 
slightly more human friendly format. Useful for manual drilldown.
For fine-tuned evaluation, rbac-police provides a variety of options, including: 
• --only-sa-on-all-nodes to evaluate only service accounts that exist on all nodes. Useful for identi-
fying powerful DaemonSets.
• --namespace, --ignored-namespaces to scope evaluation to a single namespace; ignore certain 
namespaces.