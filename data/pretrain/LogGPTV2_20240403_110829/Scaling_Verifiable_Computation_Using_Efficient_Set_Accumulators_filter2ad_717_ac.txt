correctly ordered, and (3) each sequential pair of entries in
transcript T is coherent, i.e., each LOAD returns the value of
the previous STORE (or the default if no such STORE exists).
Check (1) is implemented with a routing network [18, 118].
Costs and functionality. Roughly speaking, for tiny mem-
ories linear scan is cheapest; otherwise, BCGT-style RAM
is.5 In more detail, assume a memory of size 2m, accessed
k times. For a linear scan, each RAM operation costs O(2m)
constraints. (i.e., 2m copies of constraints encoding condi-
tional assignment). For Pantry, each LOAD entails m copies
of constraints encoding a collision-resistant hash function
and each STORE entails 2m such copies, where such hash
functions entail a few hundred to a few thousand constraints
(§6; [15, 32, 79]). For BCGT, each RAM operation costs
O(logk) constraints for the routing network, O(m) constraints
for address comparison, and O(1) constraints for coherence
checking, all with good constants [116, Fig. 5].
Although Pantry-style RAM is costly, it offers functionality
that the other two do not: the ability to pass the full state of a
large RAM from one computation to another. Pantry accom-
plishes this by including in X the Merkle root corresponding
to the initial RAM state; this has constant size (usually one
element of Fp). In contrast, BCGT and linear scan would both
require 2m values in X for a 2m-sized RAM; as discussed
above, this would incur 2m cost for V in veriﬁcation. (Prior
work [15, 16] uses this approach to partially initialize RAM.)
3 Swap sequences via batched operations
In this section, we deﬁne a new primitive, which we call
MultiSwap, that exposes a sequential update semantics for
RSA accumulators (§2.1). MultiSwap takes an accumulator
and a list of pairs of elements, removing the ﬁrst element from
each pair and inserting the second. The key property of this
primitive is that it is deﬁned in terms of batched insertions and
removals. In Section 4, we show how these batched operations
are efﬁciently implemented as a system of constraints (§2.2).
In more detail, let S and S(cid:48) be multisets, and let
(x1,y1), . . . , (xn,yn) be a sequence of operations, called swaps,
that replaces each xi by yi in order: (x1,y1) applied to S pro-
duces some new set S1 = S (cid:12){x1}(cid:93){y1}; then (x2,y2) ap-
plied to S1 produces S2 = S1 (cid:12){x2}(cid:93){y2}, etc. Our goal is to
verify that when the above sequence is applied to S, the result
5An exception is a computation with an enormous number of memory
accesses where Pantry would win. But the number of accesses to reach this
asymptote is well beyond the reach of practical proof systems.
USENIX Association
29th USENIX Security Symposium    2079
is S(cid:48) = Sn. Recall from Section 2.1 that RSA accumulators ad-
mit efﬁcient batched insertions (deletions are analogous; §4).
Our question is: how can we use this un-ordered primitive to
implement one with ordered semantics?
Consider the following naïve solution: ﬁrst verify the
deletions, then verify the insertions. In other words, verify
that there exists some Smid such that S (cid:12) {xi} = Smid and
Smid (cid:93){yi} = S(cid:48). The problem with this approach is that it
does not permit certain valid sequences, i.e., those in which
a later swap deletes an item inserted by an earlier swap. (To
see why, notice that Smid only exists if all xi ∈ S.)
∃Smid :
S(cid:93){yi} = Smid ∧ Smid (cid:12){xi} = S(cid:48)
Instead, our solution ﬁrst veriﬁes all the insertions, and then
veriﬁes all the deletions, irrespective of the order in which the
operations are listed. In other words, it veriﬁes the predicate
(6)
(Note that Smid (cid:12){xi} = S(cid:48) is equivalent to S(cid:48) (cid:93){xi} = Smid.)
Intuitively, Equation (6) holds just when each element of an
unordered multiset of swaps {(xi,yi)} can be applied to S in
some order to produce S(cid:48). As we discuss below, this multiset
may include cycles, subsets of swaps that have no net effect.
We now give a precise semantics for MultiSwap. Let
MultiSwap(S,σ,S(cid:48)) denote the predicate that holds just when
Equation (6) is satisﬁed. Let σ denote an unordered multiset
of swaps {(xi,yi)}. A swap (xi,yi) is valid for S(cid:63) if xi ∈ S(cid:63).
We say that σ is sequentially consistent with respect to S if
there exists some ordering on σ such that all swaps are valid
when applied in that order starting from S. Furthermore, we
say that σ produces S(cid:48) from S if S(cid:48) is the product of such
an application order to S, and we say that σc is a cycle if it
comprises {(c0,c1), (c1,c2), . . . , (cn,c0)}.
Lemma 1. MultiSwap(S,σ,S(cid:48)) holds if and only if there exist
i and cycle-free σ(cid:48) ⊆ σ such that
any number of cycles σc
i , σ(cid:48) is sequentially consistent with respect to S,
and σ(cid:48) produces S(cid:48) from S.
σ = σ(cid:48) (cid:93)(cid:85)
i σc
The proof of Lemma 1 is in Appendix A. Section 5 applies
MultiSwap to problems that need sequential semantics for
batched veriﬁable state updates.
4 Batched operations from constraints
In the previous section we described how the MultiSwap
primitive is built from batched insertions and removals. In
this section we describe these batched operations, the prim-
itives that they are built on, and how those primitives are
implemented as a set of constraints C (§2.2).
Recall (§2.1) that RSA accumulators support batched in-
sertions through an interactive protocol whose ﬁnal check is
Q(cid:96) ·(cid:74)S(cid:75)∏i H∆(yi) mod (cid:96) =(cid:74)S(cid:93){yi}(cid:75)
where(cid:74)·(cid:75) denotes a digest; S, the initial multiset; (cid:96), a random
prime challenge; {yi}, the inserted elements; H∆, a division-
intractable hash function; and Q, a witness from P . Removing
(7)
H∆
H∆
...
H∆
Hp
(cid:96)
/k
y1
y2
...
yk
(cid:74)S(cid:75)
(cid:74)S(cid:48)(cid:75)
Q
1
×
×
...
×
expG
expG
mod
mod
...
mod
×G
?
=
Figure 1: Insertion proof veriﬁcation procedure (§4), which
checks that Q is a valid Wesolowski proof (§2) for the ex-
ponentiation(cid:74)S(cid:48)(cid:75) =(cid:74)S(cid:75)∏i H∆(yi) on challenge (cid:96). To do so, it
computes (cid:96) = Hp(y1, . . . ,yk) (purple box, bottom left), com-
putes ∏i H∆(yi) mod (cid:96) (red and blue boxes, top), computes
the LHS of the veriﬁcation equation (cyan boxes, bottom
right), and checks that equation (black box, bottom right). H∆
is a division-intractable hash function (§4.2), Hp is a hash to
a prime (§4.1), and G is an RSA quotient group (§2).
elements {xi} is similar, except that S (cid:12){xi} is regarded as
the initial multiset and S the ﬁnal one.6
To instantiate this interactive protocol in constraints, we
apply the Fiat-Shamir heuristic [55], i.e., C computes the
challenge (cid:96) by hashing all of the inputs to the protocol.7
Figure 1 illustrates the insertion proof’s veriﬁcation procedure.
MultiSwap requires two proofs (one for insertion and one for
removal); for this purpose, we hash all inputs to both proofs
to derive a common challenge, as is standard [50].
In the rest of this section we explain how to efﬁciently
implement the blocks of Figure 1 in constraints. In particular,
we explain how to implement Hp, the prime hash function
used to compute (cid:96) (§4.1) and H∆, the division-intractable hash
function used to hash each element (§4.2). We also describe
optimizations for multiprecision operations (§4.3). Finally,
we discuss P ’s cost for generating the witness input Z to
C (§2.2), notably, the digests S(cid:93){yi} and S (cid:12){xi} and the
corresponding witnesses Q for insertion and removal (§4.4).
6Proofs of non-membership (§2.1) use similar primitives; we do not
discuss them in detail because they are not necessary for MultiSwap.
7This requires that we model the concrete hash function that outputs (cid:96) as
a random oracle [8]; similar assumptions are common in practice.
2080    29th USENIX Security Symposium
USENIX Association
Iteration, i
max. pi bitwidth
bhi
bni
0
32
21
11
1
63
20
11
2
124
49
12
3
245
108
13
4
322
63
14
Figure 2: Bitwidths for recursive primality proofs in our sys-
tem. While the bhi sum to 261, there are only 256 bits of
entropy because each hi has its high bit ﬁxed to 1 (§4.1).
rounds sufﬁce for 256 bits of entropy using the parameters
listed in Figure 2. C generates hi by hashing the input to Hp
with a hash function H modeled as a random oracle.
Each iteration yields a prime approximately twice as wide
as the prior iteration’s; meanwhile, the cost of each iteration
is dominated by an exponentiation. This means that our ap-
proach has cost less that that of two exponentiations modulo
the ﬁnal prime. In contrast, using Miller-Rabin to check a
264-bit prime (which has roughly 256 bits of entropy) would
require 80 exponentiations modulo that prime to give ≈2−80
probability of outputting a composite (because Miller-Rabin
is a probabilistic primality test). Our approach thus saves more
than an order of magnitude and provably outputs a prime.
One ﬁnal optimization is to force the most signiﬁcant bit of
each hi to 1; this establishes a lower bound on each pi and on
(cid:96) (which is the ﬁnal pi). As we discuss in Section 4.3, having
this lower bound reduces the cost of modular reductions. The
tradeoff is a small loss in entropy, namely, 1 bit per iteration.
Even so, four rounds sufﬁce to produce a 322-bit prime9 with
256 bits of entropy.
4.2 Division-intractable hashing
Coron and Naccache show [48] that a hash function H that
outputs sufﬁciently large integers is division intractable when
modeled as a random oracle. Informally, this is because in
any randomly-selected set of large (say, 2000 bit) numbers,
each element has a distinct, moderately sized (say, 200 bit)
prime factor with high probability.
4.1 Hashing to primes
The hash function Hp (Fig. 1) generates the challenge (cid:96) used
in the Wesolowski proofs of batch insertion and removal.
These proofs are sound when P has negligible probability of
guessing the factors of (cid:96) before evaluating Hp [120]. In the
non-interactive setting, one way to ensure this is by choosing (cid:96)
at random from the ﬁrst 22λ primes (Fn. 1, §2). In our context,
however, a more efﬁcient approach is for Hp to output slightly
larger primes that are guaranteed by construction to have 2λ
bits of entropy.8 Soundness is identical.
In standard settings (i.e., outside of constraints), a typical
approach (§8) for hashing to a random prime is rejection
sampling. Here, the input is fed to a collision-resistant hash
whose output seeds a pseudorandom generator (PRG), then
the PRG’s outputs are tested in sequence until a prime is
found. Verifying correct execution requires, at the very least,
testing primality of the purported output. This is typically
done with a probabilistic primality test like Miller-Rabin [98].
Such tests, however, generally require many iterations for
soundness, where each iteration involves an exponentiation
modulo the prime being tested. This would be far too costly
if implemented directly in constraints.
Instead, we take advantage of advice from P (§2.2). At a
high level, P helps to recursively construct a Pocklington cer-