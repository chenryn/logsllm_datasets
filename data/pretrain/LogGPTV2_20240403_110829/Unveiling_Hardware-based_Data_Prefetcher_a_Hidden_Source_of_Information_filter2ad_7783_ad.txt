eration. We confirmed this through program analysis on the library
by means of reverse-engineering and debugging. This observation
leads to a conclusion that cache activities on those lines (e.g., Line#1
and #2 in Fig.1) are actually introduced by the hardware-based data
prefetching mechanism.
Validation of our reasoning. As described in Section 2.2, each
Intel core is equipped with four kinds of hardware prefetchers with
various cache prefetching strategies at different locations. These
prefetchers can be controlled independently by four bits of the MSR
with address 0x1a4 (see more details in Section 2.2). In order to
validate our reasoning about the effect of cache prefetching, we
check whether these prefetchers affect the secret-dependent cache
activities near the lookup table by utilizing the MSR, and if so, figure
out which one actually does.
In the system setup with Intel Xeon E5-2620v4, we conducted
the procedure described in Section 3.1 for both versions of the
OpenSSL library with each bit of the MSR being manipulated. The
experimental results are presented in Fig. 2. The graph in the figure
shows the number of lines identified to have secret-dependent cache
traces (i.e., the score σ is more than 0.9) according to the value of the
MSR 0x1a4. Note that each MSR value represents the combination
of status of the hardware prefetchers. For instance, the value of 0xF
indicates that all the prefetchers are disabled, and the value of 0x0
indicates that all prefetchers are enabled.
0240123456789abcdefNumber of  lines with σ> 0.9The value of MSR 0x1a4OpenSSL	1.0.1eOpenSSL	1.1.0g	Session 2A: Side Channel 1 CCS’18, October 15-19, 2018, Toronto, ON, Canada137Table 3: Access patterns with a regular stride at the first load instruction of GF2m_Sqare in the sequence of Madd operations
(on the left side) and the input value on the 20-th invocation (on the right side)
Sequence
20
22
25
26
44
55
Access pattern (indices of SQR_tb lookups)
0 → 4 → 5 → 8 → 9 → a → a → 2 → d
0 → c → 9 → 8 → 7 → 8 → 2 → 5 → d
0 → 0 → 2 → 3 → 1 → 4 → 7 → e → a
0 → d → 1 → 9 → 7 → 5 → a → a → 6
0 → 4 → 8 → 8 → 5 → d → a → 2 → f
0 → 8 → e → 1 → 7 → 8 → 9 → c → 6
Stride Direction
Forward
Backward
Forward
Backward
Forward
Forward
8
8
24
16
32
8
Input of GF2m_Sqare at sequence 20
X8:01306E5A75514CF1
X6:5F1EADE8248BFB8B
X4:98BC1F8FF8E0E86E
X2:A034E951A17B407E
X0:D09768D838984148
X7:474F813861F0EE7C
X5:82459457243E0058
X3:A11D81BEC146C7D1
X1:2C4D730E4550C751
We can clearly observe the difference between the values ranging
from 0x0 to 0x7 and the values ranging from 0x8 to 0xF. With MSR
values of more than 0x7, no cache activities are observed on the lines
near SQR_tb, which results in the decrement of the number of lines
by 2 in the graph. This indicates that hardware prefetchers actually
have an effect on the cache activities and produce secret-dependent
cache traces on the relevant memory lines. Furthermore, we can
learn from the result that among the four kinds of prefetchers, IP-
based stride prefetcher, whose control bit corresponds to Bit #3 in
the MSR, solely affects the memory lines near SQR_tb.
4 ANALYSIS ON STRIDE PREFETCHING
In this section, we consider the behavior of the IP-based stride
prefetcher in Intel processors, which has been identified in the
previous section as a hidden source of observable cache activities.
Concretely, we examine its impact on producing cache traces on
a couple of memory lines adjacent to the squaring lookup table
(SQR_tb) when performing scalar point multiplication.
As described in Section 2.2, the IP-based stride prefetcher basi-
cally follows a strategy of detecting the stride on load operations
in a loop structure. However, any details of the behavior of the
prefetcher, i.e., under what conditions the prefetching is triggered
and what memory line is fetched into the cache, are publicly un-
known. Hence, we have to infer the behaviors through observations
from in-depth experiments.
Experimental analysis. The prefetching activity is observed on
memory lines near the SQR_tb lookup table, which is used by the
GF2m_Sqare algorithm (Algorithm 5). The squaring algorithm
is one of the primitive operations for both Madd (Line 7 in Algo-
rithm 4) and Mdouble (Lines 2,3,5,6 in Algorithm 3) algorithms.
Hence, when running the Montgomery ladder multiplication, a
series of GF2m_Sqare operations is necessarily invoked for the
computation of each bit of the scalar.
Given an input X ∈ GF(2m), the GF2m_Sqare algorithm com-
putes the squaring of X by iterative lookups to SQR_tb through
a loop. Specifically, for each iteration of the loop, 16 lookups to
SQR_tb occur in total, each of which is indexed by four bits of
a word Xi (Lines 5 to 20 in Algorithm 5). In machine code, each
table lookup is translated into a load instruction to fetch a word
from the memory. The memory address of the word is calculated
from the base address of SQR_tb and the corresponding index. The
number of iterations of the loop is determined by w, the length
of X in a word. For instance, with the sect571r1 curve, an input
Figure 3: Average memory access time on Line#1 and Line#2
after execution of the first load instruction of GF2m_Sqare
in the sequence of Madd operations (measured on Xeon E5-
2620v4)
X of GF2m_Sqare is 571 bits in length, which results in w = 9
iterations of the loop.
We demonstrate how to examine the behavior of the stride
prefetcher in the squaring algorithm. Our approach is, in short,
to analyze the observed prefetching activities by comparing it to
the ground truth of memory access patterns on SQR_tb lookups.
First, we obtain the full sequence of input data of the GF2m_Sqare
algorithm during execution to use as the ground truth. For this,
we run the Montgomery ladder multiplication algorithm with a
fixed point P1 in the sect571r1 curve. We choose an arbitrary scalar
k of 60 bits in length as another input. While running the algo-
rithm, the values of input X are traced on every invocation of the
GF2m_Sqare algorithm. From this trace, we can get the actual
memory access patterns of every load instruction corresponding to
SQR_tb lookups. More specifically, the access patterns for 16 load
instructions are collected for each invocation of GF2m_Sqare.
Once the memory access patterns have been collected, we look
for patterns among them that have a regular stride with confidence
c = 2 (i.e., patterns containing at least three consecutive accesses
with constant stride). We choose c = 2 when searching the patterns
since it is the minimal condition to have a regular stride.
Table 3 shows the searching result for the first load instruction
(Line 5 in Algorithm 5) of the GF2m_Sqare operation. The re-
sult was obtained when the squaring operation was invoked by
Session 2A: Side Channel 1 CCS’18, October 15-19, 2018, Toronto, ON, Canada138Figure 5: Invocations of GF2m_Sqare (SQR) in a 1-bit pro-
cessing sequence of the Montgomery ladder multiplication
as shown in Table 3. Line#1 is located on the left side of SQR_tb,
which is at a lower address than the address of the lookup table. It
is inferred from the observation that IP-based stride prefetching is
triggered when a regular stride with c = 2 is detected, and if it is in
a backward direction, an adjacent memory line at a lower address
is fetched to the cache.
The observation at the other line also conforms to our inference.
For Line#2, which is located on the right side of SQR_tb, four low
peaks are observed at sequences 20, 25, 44, and 55. All these peaks
are matched to sequences in Table 3 that have regular strides with
c = 2 in a forward direction, which triggers the prefetcher to fetch
an adjacent line at an address higher than SQR_tb.
Dynamic behavior of the prefetcher. It is worth noting that se-
quences 20 and 55 in Fig.3 show relatively high average memory
access time than the other sequences with low peaks. Since most
parts of the IP-based stride prefetcher in Intel processors have not
been disclosed yet, we have a certain amount of uncertainty about
the behavior of the prefetcher. However, from observing the dis-
tributions of access times on several sequences, which are shown
in Fig. 4, we believe that the stride prefetcher does not behave in
a deterministic way. For instance, sequences 20 and 55, shown in
Fig.4(a) and Fig.4(d), respectively, follow a distribution that is quite
different from that of the other sequences, shown in Fig.4(b) and
Fig.4(c), in which almost every memory access results in a cache hit.
This implies that the decision of prefetching is made based on not
only the observed access patterns but also unknown dynamic mech-
anism (e.g., using a history buffer or a probabilistic model), which
should be further investigated in a future work. The analysis on the
uncertain behavior would require a more systematic approach. One
possible direction is to reverse-engineer the internal workings of
the hardware prefetcher by using hardware performance counters
via Intel Performance Monitoring Unit [27, 28], which provides lots
of useful information on internal states of the processor.
5 CACHE PROFILING ON SCALAR BITS
The analysis shown in the previous section implies that the behavior
of the stride prefetcher during execution of the Montgomery ladder
multiplication is dependent on the input of a scalar. That is, each 1-
bit processing sequence of the loop in the multiplication algorithm
shows an unique prefetching behavior according to the value of the
bit of the scalar. In this section, we present our findings in detail.
Furthermore, we show that cache activities due to prefetching can
be used for distinguishing between the executions of branchless
Montgomery ladder multiplication with two different scalars.
Figure 4: Distributions of access times for sequences that
have a regular stride with c = 2 (The dashed line represents
the mean of the distribution)
Madd (Line 7 in Algorithm 4). Given the length of the scalar k
(i.e., 60 bits), we have 59 access patterns in total for the first load
instruction. Among them 6 patterns are identified to have a regular
stride (underlined in Table 3). For instance, the input of X at the
20-th invocation of GF2m_Sqare (i.e., Sequence 20) is given on
the right side of Table 3. Its value consists of 9 words (X8 - X0),
and the most significant 4 bits of each word are used as a lookup
index to SQR_tb at the first load instruction. The access pattern
at sequence 20 has sequential accesses with indices 0x8, 0x9, and
0xa that form a regular stride of 8 bytes. The sequence of indices
is incremental; therefore, the stride is in a forward direction. The
next access pattern, found at sequence 22, has accesses with indices
0x9,0x8, and 0x7 that form a regular stride in a backward direction.
These identified access patterns will serve as the ground truth for
analysis on the observed cache activities.
Now, we examine the cache traces observed on two memory lines,
Line#1 at 0x1ec000 and Line#2 at 0x1ec100, located at both sides
of SQR_tb. In the original implementation of OpenSSL library, the
GF2m_Sqare algorithm has more than a dozen load instructions
that affect the cache activities simultaneously on those lines. To
infer the prefetching behavior for an individual instruction, we
dismantle the observed cache traces. In this case, we focus on the
cache activities caused by the first load instruction. For this purpose,
the remaining load instructions in the implementation are modified
so that they no longer affect the cache activities on those lines while
permitting the multiplication to work correctly.
Fig. 3 shows the average memory access time measured on Line#1
and Line#2 at the end of every execution of Madd operation during
the multiplication. A time sequence that takes shorter cycles for
access than the others indicates that the line is prefetched to the
cache at that time. From the graph, we observe a total of 6 sequences
that show shorter access times on those lines. For Line#1, there
are a couple of low peaks at sequence 22 and 26, both of which
have access patterns with regular strides in a backward direction,
MaddMULMULMULADDSQRMULADDSQRSQRMULSQRSQRADDMdoubleMaddMULMUL…𝑖-thscalar bit(𝑖+1)-thscalar bitt1t2t3t4t5TimeProbeMULSession 2A: Side Channel 1 CCS’18, October 15-19, 2018, Toronto, ON, Canada139Table 4: An example of measurements for the first 20 iter-
ations of the Montgomery ladder multiplication (measured
on Xeon E5-2620v4)
Slot Cache hit ratio (ρ)
Line#2
15.99
41.17
20.04
84.05
24.06
83.54
3.79
82.66
81.17
31.67
Line#1
73.58
20.97
84.88
66.95
79.3
83.44
29.81
20.34
4.89
72.58
1
2
3
4
5
6
7
8
9
10
Slot Cache hit ratio (ρ)
Line#2
25.47
11
66.89
12
13
77.82
41.94
14
68.6
15
29.28
16
17
67.98
81.65
18
81.03
19
20
76.07
Line#1
73.71
25.98
58.58
40.64
70.38