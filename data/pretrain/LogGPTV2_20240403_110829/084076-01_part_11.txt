metadata:
name: claim1
spec:
accessModes:
- ReadWriteOnce
storageClassName: fast
resources:
requests:
storage: 30Gi
注 意
storageClassName要与上述创建的StorageClass名字相同。
之后会自动创建一个PV与该PVC进行绑定，然后Pod即可挂载使用。
（2）定义GFS动态预配置
可以参考3.1节定义一个GFS的StorageClass：
apiVersion: storage.K8S.io/v1
kind: StorageClass
metadata:
name: gluster-heketi
provisioner: kubernetes.io/glusterfs
parameters:
resturl: "http://10.111.95.240:8080"
restauthenabled: "false"
之后定义一个PVC：
120 | 再也不踩坑的Kubernetes实战指南
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
name: pvc-gluster-heketi
spec:
accessModes: [ "ReadWriteOnce" ]
storageClassName: "gluster-heketi"
resources:
requests:
storage: 1Gi
PVC 一旦被定义，系统便发出 Heketi 进行相应的操作，在 GFS 集群上创建 brick，再创建并
启动一个volume。
然后定义一个Pod使用该存储卷：
apiVersion: v1
kind: Pod
metadata:
name: pod-use-pvc
spec:
containers:
- name: pod-use-pvc
image: busybox
command:
- sleep
- "3600"
volumeMounts:
- name: gluster-volume
mountPath: "/pv-data"
readOnly: false
volumes:
- name: gluster-volume
persistentVolumeClaim:
claimName: pvc-gluster-heketi
claimName为上述创建的PVC的名称。
2.2.13 Service
Service 主要用于 Pod 之间的通信，对于Pod 的IP 地址而言，Service 是提前定义好并且是不
变的资源类型。
1. 基本概念
Kubernetes Pod具有生命周期的概念，它可以被创建、删除、销毁，一旦被销毁就意味着生命
周期的结束。通过ReplicaSet能够动态地创建和销毁Pod，例如进行扩缩容和执行滚动升级。每个
Pod都会获取到它自己的IP地址，但是这些IP地址不总是稳定和可依赖的，这样就会导致一个问
题：在Kubernetes集群中，如果一组Pod（比如后端的Pod）为其他Pod（比如前端的Pod）提供
服务，那么如果它们之间使用Pod的IP地址进行通信，在Pod重建后，将无法再进行连接。
为了解决上述问题，Kubernetes 引用了 Service 这样一种抽象概念：逻辑上的一组 Pod，即一
第2章 Docker及Kubernetes基础 | 121
种可以访问Pod的策略——通常称为微服务。这一组Pod能够被Service访问到，通常是通过Label
Selector（标签选择器）实现的。
举个例子，有一个用作图片处理的backend（后端），运行了3个副本，这些副本是可互换的，
所以frontend（前端）不需要关心它们调用了哪个backend副本，然而组成这一组backend程序的
Pod实际上可能会发生变化，即便这样frontend也没有必要知道，而且也不需要跟踪这一组backend
的状态，因为Service能够解耦这种关联。
对于Kubernetes集群中的应用，Kubernetes提供了简单的Endpoints API，只要Service中的一
组 Pod 发生变更，应用程序就会被更新。对非 Kubernetes 集群中的应用，Kubernetes 提供了基于
VIP的网桥的方式访问Service，再由Service重定向到backend Pod。
2. 定义Service
一个Service在Kubernetes中是一个REST对象，和Pod类似。像所有REST对象一样，Service
的定义可以基于POST方式，请求APIServer创建新的实例。例如，假定有一组Pod，它们暴露了
9376端口，同时具有app=MyApp标签。此时可以定义Service如下：
kind: Service
apiVersion: v1
metadata:
name: my-service
spec:
selector:
app: MyApp
ports:
- protocol: TCP
port: 80
targetPort: 9376
上述配置创建一个名为my-service的Service对象，它会将请求代理到TCP端口为9376并且
具有标签app=MyApp的Pod上。这个Service会被分配一个IP地址，通常称为ClusterIP，它会被
服务的代理使用。
需要注意的是，Service能够将一个接收端口映射到任意的targetPort。默认情况下，targetPort
将被设置为与Port字段相同的值。targetPort可以设置为一个字符串，引用backend Pod的一个端口
的名称。
Kubernetes Service能够支持TCP和UDP协议，默认为TCP协议。
3. 定义没有Selector的Service
Service抽象了该如何访问Kubernetes Pod，但也能够抽象其他类型的backend，例如：
 希望在生产环境中访问外部的数据库集群。
 希望Service指向另一个NameSpace中或其他集群中的服务。
 正在将工作负载转移到Kubernetes集群，和运行在Kubernetes集群之外的backend。
在任何这些场景中，都能定义没有Selector的Service：
kind: Service
apiVersion: v1
metadata:
122 | 再也不踩坑的Kubernetes实战指南
name: my-service
spec:
ports:
- protocol: TCP
port: 80
targetPort: 9376
由于这个Service没有Selector，就不会创建相关的Endpoints 对象，可以手动将Service映射
到指定的Endpoints：
kind: Endpoints
apiVersion: v1
metadata:
name: my-service
subsets:
- addresses:
- ip: 1.2.3.4
ports:
- port: 9376
注 意
Endpoint IP 地址不能是 loopback（127.0.0.0/8）、link-loca（l 169.254.0.0/16）或者link-local
多播地址（224.0.0.0/24）。
访问没有Selector的Service与有Selector的Service的原理相同。请求将被路由到用户定义的
Endpoint，该示例为1.2.3.4:9376。
ExternalName Service是Service的特例，它没有Selector，也没有定义任何端口和Endpoint，
它通过返回该外部服务的别名来提供服务。
比 如 当 查 询 主 机 my-service.prod.svc 时 ， 集 群 的 DNS 服 务 将 返 回 一 个 值 为
my.database.example.com的CNAME记录：
kind: Service
apiVersion: v1
metadata:
name: my-service
namespace: prod
spec:
type: ExternalName
externalName: my.database.example.com
4. VIP和Service代理
在Kubernetes集群中，每个节点运行一个kube-proxy进程。kube-proxy负责为Service实现了
一种VIP（虚拟IP）的形式，而不是ExternalName的形式。在Kubernetesv 1.0版本中，代理完全
是userspace。在Kubernetesv 1.1版中新增了iptables代理，从Kubernetesv 1.2版起，默认是iptables
代理。从Kubernetesv 1.8版开始新增了ipvs代理，生产环境建议使用ipvs模式。
在Kubernetesv 1.0版中Service是4层（TCP/UDP over IP）概念，在Kubernetesv 1.1版中新增
了Ingress API（beta版），用来表示7层（HTTP）服务。
第2章 Docker及Kubernetes基础 | 123
（1）iptables代理模式
这种模式下kube-proxy会监视Kubernetes Master对Service对象和Endpoints对象的添加和移
除。对每个Service它会创建iptables规则，从而捕获到该Service的ClusterIP（虚拟IP）和端口的
请求，进而将请求重定向到Service的一组backend中的某个Pod上面。对于每个Endpoints对象，
它也会创建iptables规则，这个规则会选择一个backend Pod。
默认的策略是随机选择一个 backend，如果要实现基于客户端 IP 的会话亲和性，可以将
service.spec.sessionAffinity的值设置为ClusterIP（默认为None）。
和userspace代理类似，网络返回的结果都是到达Service的IP:Port请求，这些请求会被代理
到一个合适的 backend，不需要客户端知道关于 Kubernetes、Service 或 Pod 的任何信息。这比
userspace代理更快、更可靠，并且当初始选择的Pod没有响应时，iptables代理能够自动重试另一
个Pod。
（2）ipvs代理模式
在此模式下，kube-proxy监视Kubernetes Service和Endpoint，调用netlink接口以相应地创建
ipvs规则，并定期与Kubernetes Service和Endpoint同步ipvs规则，以确保ipvs状态与期望保持一
致。访问服务时，流量将被重定向到其中一个后端Pod。
与iptables类似，ipvs基于netfilter钩子函数，但是ipvs使用哈希表作为底层数据结构并在内
核空间中工作，这意味着 ipvs 可以更快地重定向流量，并且在同步代理规则时具有更好的性能，
此外，ipvs为负载均衡算法提供了更多的选项，例如：
 rr 轮询
 lc 最少连接
 dh 目标哈希
 sh 源哈希
 sed 预计延迟最短
 nq 从不排队
5. 多端口Service
在许多情况下，Service可能需要暴露多个端口，对于这种情况Kubernetes支持Service定义多
个端口，但使用多个端口时，必须提供所有端口的名称，例如：
kind: Service
apiVersion: v1
metadata:
name: my-service
spec:
selector:
app: MyApp
ports:
- name: http
protocol: TCP
port: 80
targetPort: 9376
- name: https
protocol: TCP
124 | 再也不踩坑的Kubernetes实战指南
port: 443
targetPort: 9377
6. 发布服务/服务类型
对于应用程序的某些部分（例如前端），一般要将服务公开到集群外部供用户访问。这种情
况下都是用Ingress通过域名进行访问。
Kubernetes ServiceType（服务类型）主要包括以下几种：
 ClusterIP 在集群内部使用，默认值，只能从集群中访问。
 NodePort 在所有节点上打开一个端口，此端口可以代理至后端 Pod，可以通过 NodePort
从集群外部访问集群内的服务，格式为NodeIP:NodePort。
 LoadBalancer 使用云提供商的负载均衡器公开服务，成本较高。
 ExternalName 通过返回定义的CNAME 别名，没有设置任何类型的代理，需要1.7 或更
高版本kube-dns支持。
以NodePort为例。如果将type字段设置为NodePort，则Kubernetes将从--service-node-port-range
参数指定的范围（默认为30000-32767）中自动分配端口，也可以手动指定NodePort，并且每个节
点将代理该端口到Service。
一般格式如下：
kind: Service
apiVersion: v1
metadata:
labels:
K8S-app: kubernetes-dashboard
name: kubernetes-dashboard
namespace: kube-system
spec:
type: NodePort
ports:
- port: 443
targetPort: 8443
nodePort: 30000
selector:
K8S-app: kubernetes-dashboard
常用的服务访问是NodePort和Ingress（关于Ingress参看2.2.14节），其他服务访问方式详情
参看以下网址：
https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types
2.2.14 Ingress
Ingress 为 Kubernetes 集群中的服务提供了入口，可以提供负载均衡、SSL 终止和基于名称的
虚拟主机，在生产环境中常用的Ingress有Treafik、Nginx、HAProxy、Istio等。
1. 基本概念
在Kubernetesv 1.1版中添加的Ingress用于从集群外部到集群内部Service的HTTP和HTTPS
第2章 Docker及Kubernetes基础 | 125
路由，流量从Internet到Ingress 再到Services最后到Pod 上，通常情况下，Ingress 部署在所有的
Node节点上。
Ingress可以配置提供服务外部访问的URL、负载均衡、终止SSL，并提供基于域名的虚拟主
机。但Ingress不会暴露任意端口或协议。
2. 创建一个Ingress
创建一个简单的Ingress如下：
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
name: simple-fanout-example
annotations:
nginx.ingress.kubernetes.io/rewrite-target: /
spec:
rules:
- host: foo.bar.com
http:
paths:
- path: /foo
backend:
serviceName: service1
servicePort: 4200
- path: /bar
backend:
serviceName: service2
servicePort: 8080
上述host定义该Ingress的域名，将其解析至任意Node上即可访问。
如果访问的是foo.bar.com/foo，则被转发到service1的4200端口。
如果访问的是foo.bar.com/bar，则被转发到service2的8080端口。
（1）Ingress Rules
 host：可选，一般都会配置对应的域名。
 path：每个路径都有一个对应的serviceName和servicePort，在流量到达服务之前，主机和
路径都会与传入请求的内容匹配。
 backend：描述Service和Port的组合。对Ingress匹配主机和路径的HTTP与HTTPS请求
将被发送到对应的后端。
（2）默认后端
没有匹配到任何规则的流量将被发送到默认后端。默认后端通常是Ingress Controller的配置选
项，并未在Ingress资源中指定。
3. Ingress类型
（1）单域名
单个域名匹配多个path到不同的service：
apiVersion: extensions/v1beta1
kind: Ingress
126 | 再也不踩坑的Kubernetes实战指南
metadata:
name: simple-fanout-example
annotations:
nginx.ingress.kubernetes.io/rewrite-target: /
spec:
rules:
- host: foo.bar.com
http:
paths:
- path: /foo
backend:
serviceName: service1
servicePort: 4200
- path: /bar
backend:
serviceName: service2
servicePort: 8080
此时，访问foo.bar.com/foo到service1的4200。访问foo.bar.com/bar到service2的8080。
（2）多域名
基于域名的虚拟主机支持将HTTP流量路由到同一IP地址的多个主机名：
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
name: name-virtual-host-ingress