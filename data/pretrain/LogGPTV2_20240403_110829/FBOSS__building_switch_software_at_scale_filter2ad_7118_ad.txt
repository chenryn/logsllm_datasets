sights for human operators to ease the debugging process. The
remediation process is as follows. Once a failure is detected,
the remediation system automatically categorizes each failure
to a set of known root causes, applies remediations if needed,
and logs the details of the outage to a datastore. The auto-
matic categorization and remediation of failures allows us to
focus our debugging efforts on undiagnosed errors rather than
repeatedly debugging the same known issues. Also, the exten-
sive log helps us drive insights like isolating a rare failure to
a particular hardware revision or kernel version.
In summary, our approach has the following advantages:
Flexible Data Model. Traditionally, supporting a new type
of data to collect or modifying an existing data model requires
modifications and standardization of the network management
protocols and then time for vendors to implement the stan-
dards. In contrast, since we control the device, monitoring
data dissemination via FBOSS and the data collection mecha-
nism through the management system, we can easily define
and modify the collection specification. We explicitly define
the fine-grained counters we need and instrument the devices
to report those counters.
Improved Performance. Compared to conventional moni-
toring approaches, FBOSS has better performance as the data
transfer protocol can be customized to reduce both collection
time and network load.
Remediation with Detailed Error Logs. Our system al-
lows the engineers to focus on building remediation mecha-
nisms for unseen bugs, which consequently improves network
stability and debugging efficiency.
7 EXPERIENCES
While the experiences of operating a data center network
with custom switch software and hardware has been mostly
satisfactory, we faced outages that are previously unseen and
are unique to our development and deployment model.
7.1 Side Effect of Infrastructure Reuse
For improved efficiency, our data centers deploy a network
topology with a single ToR switch, which implies that the
ToR switches are a single point of failure for the hosts in
the rack. As a result, frequent FBOSS releases made on the
ToR switches need to be non-disruptive to ensure availability
of the services running on those hosts. To accomplish this,
we use an ASIC feature called "warm boot". Warm boot
allows FBOSS to restart without affecting the forwarding
tables within the ASIC, effectively allowing the data plane to
continue to forward traffic while the control plane is being
restarted. Although this feature is highly attractive and has
allowed us to achieve our desired release velocity, it also
greatly complicates the state management between FBOSS,
routing daemons, switch SDK and the ASIC. Thus, we share
a case where warm boot and our code reuse practices have
resulted in a major outage.
Despite the fact that we have a series of testing and moni-
toring process for new code deployments, it is inevitable for
bugs to leak into data center-wide deployments. The most dif-
ficult type of bugs to debug are the ones that appear rarely and
inconsistently. For example, our BGP daemon has a graceful
restart feature to prevent warm boots from affecting the neigh-
bor devices when BGP sessions are torn down by FBOSS
restarts or failures [38]. The graceful restart has a timeout
before declaring BGP sessions are broken, which effectively
puts a time constraint on the total time a warm boot oper-
ation can take. In one of our deployments, we found that
the Kerberos [7] library, which FBOSS and many other soft-
ware services, use to secure communication between servers,
caused outages for a small fraction of switches in our data
center. We realized that the reason for the outages is that
the library often took a long time to join the FBOSS agent
thread. Since the timing and availability constraints for other
software services are more lenient than FBOSS’s warm boot
requirements, existing monitors were not built detect such
rare performance regressions.
Takeaway: Simply reusing widely-used code, libraries or
infrastructure that are tuned for generic software services may
not work out of the box with switch software.
7.2 Side Effect of Rapid Deployment
During the first few months of our initial FBOSS deploy-
ment, we occasionally encountered unknown cascading out-
ages of multiple switches. The outage would start with a
single device and would spread to nearby devices, resulting in
very high packet loss within a cluster. Sometimes the network
would recover on its own, sometimes not. We realized that
the outages were more likely to occur if a deployment would
go awry, yet they were quite difficult to debug because we
FBOSS: Building Switch Software at Scale
SIGCOMM ’18, August 20–25, 2018, Budapest, Hungary
Figure 11: Overview of cascading outages seen by a failed ToR switch within a backup group.
had deployed a number of new changes simultaneously as it
was our initial FBOSS deployment.
We eventually noticed that the loss was usually limited to a
multiple of 16 devices. This pointed towards a configuration
in our data center called backup groups. Prior to deploying
FBOSS, the most common type of failure within our data
center was a failure of a single link leading to a black-holing
of traffic [36]. In order to handle such failures, a group (il-
lustrated on the left side of Figure 11) of ToR switches are
designated to provide backup routes if the most direct route
to a destination becomes unavailable. The backup routes are
pre-computed and statically configured for faster failover.
We experienced an outage where a failure of a ToR resulted
in a period where packets ping pong between the backup ToRs
and the aggregation switches, incorrectly assuming that the
backup routes are available. This resulted in a loop in the
backup routes. The right side of Figure 11 illustrates the
creation of path loops. The loop eventually resulted in huge
CPU spikes on all the backup switches. The main reason
for the CPU spikes was because FBOSS was not correctly
removing the failed routes from the forwarding table and was
also generating TTL expired ICMP packets for all packets
that had ping-ponged back and forth 255 times. Given that
we had not seen this behavior before, we had no control
plane policing in place and sent all packets with TTL of 0 to
the FBOSS agent. The rate the FBOSS agent could process
these packets was far lower than the rate we were receiving
the frames, so we would fall further and further behind and
starve out the BGP keep-alive and withdraw messages we
need for the network to converge. Eventually BGP peerings
would expire, but since we were already in the looping state,
it often made the matters worse and caused the starvation to
last indefinitely. We added a set of control plane fixes and the
network became stable even through multiple ToR failures.
Takeaway: A feature that works well for conventional
networks may not work well for networks deploying FBOSS.
This is a side effect of rapid deployment, as entire switch
outages are more frequently than in conventional networks.
Thus, one must be careful in adopting features that are known
to be stable in conventional networks.
7.3 Resolving Interoperability Issues
Although we developed and deployed switches that are
built in-house, we still need the switches and FBOSS to inter-
operate with different types of network devices for various rea-
sons. We share our experiences where the design of FBOSS
allowed an interoperability issue to be quickly resolved.
When configuring link aggregation between FBOSS and
a particular line of vendor devices, we discovered that flap-
ping the logical aggregate interface on the vendor device
could disable all IP operations on that interface. A cursory
inspection revealed that, while the device had expectantly
engaged in Duplicate Address Detection (DAD) [50] for the
aggregate interface’s address, it had unexpectedly detected a
duplicate address in the corresponding subnet. This behavior
was isolated to a race condition between LACP and DAD’s
probe, wherein an artifact of the hardware support for link
aggregation could cause DAD’s Neighbor Solicitation packet
to be looped back to the vendor switch. In accordance with
the DAD specification, the vendor device had interpreted the
looped back Neighbor Solicitation packet as another node
engaging in DAD for the same address, which the DAD spec-
ification mandates should cause the switch to disable IP oper-
ation on the interface on which DAD has been invoked. We
also found that interconnecting the same vendor device with
a different vendor’s switch would exhibit the same symptom.
Flapping of interfaces is a step performed by our network
operators during routine network maintenance. To ensure that
the maintenance could still be performed in a non-disruptive
manner, we modified the FBOSS agent to avoid the scenario
described above. In contrast, in response to our report of this
bug to the vendor, whose switch exhibited the same behavior
as ours, the vendor recommended the other vendors to im-
plement an extension to DAD. By having entire control over
our switch software, we were able to quickly provide what’s
necessary for our network.
SIGCOMM ’18, August 20–25, 2018, Budapest, Hungary
S. Choi et al.
Takeaway: Interoperability issues are common in net-
works with various network devices. FBOSS allows us to
quickly diagnose and fix the problem directly, instead of wait-
ing for vendor updates or resorting to half-baked solutions.
8 DISCUSSION
Existing Switch Programming Standards. Over time,
many software standards have been proposed to open up vari-
ous aspects of the software on the switch. On the academic
side, there are decades of approaches to open various aspects
of switches, including active networking [35], FORCES [32],
PCE [26], and OpenFlow [40]. On the industry side, upstart
vendors have tried to compete with incumbents on being more
open (e.g., JunOS’s SDK access program, Arista’s SDK pro-
gram) and the incumbents have responded with their own
open initiatives (e.g., I2RS, Cisco’s OnePK). On both the
academic and industry sides, there also are numerous control
plane and management plane protocols that similarly try to
make the switch software more programmable/configurable.
Each of these attempts have their own set of trade-offs and
subset of supported hardware. Thus, one could argue that
some synthesis of these standards could be “the one perfect
API” that gives us the functionalities we want. So, why didn’t
we just use/improve upon one of these existing standards?
The problem is that these existing standards are all “top
down": they are all additional software/protocols layered on
top of the existing vendor software rather than entirely re-
placing it. That means that if ever we wanted to change the
underlying unexposed software, we would still be limited by
what our vendors would be willing to support and on their
timelines. By controlling the entire software stack “bottom
up", we can control all the possible states and code on the
switch and can expose any API anyway we want at our own
schedule. Even more importantly, we can experiment with the
APIs we expose and evolve them over time for our specific
needs, allowing us to quickly meet our production needs.
FBOSS as a Building Block for Larger Switches. While
originally developed for ToR, single-ASIC style switches,
we have adapted FBOSS as a building block to run larger,
multi-ASIC chassis switches as well. We have designed and
deployed our own chassis-based switch with removable line
cards that supports 128x100Gbps links with full bisection
connectivity. Internally, this switch is composed of eight line
cards each with their own CPU and ASIC, connected in a
logic CLOS topology to four fabric cards also with their own
CPU and ASIC.
We run an instance of FBOSS on each of the twelve (eight
line cards plus four fabric cards) CPUs and have them peer
via BGP internally to the switch, logically creating a single
high-capacity switch that runs the aggregation layers of our
data centers. While appearing to be a new hardware design,
the data plane of our switches follows closely conventional
vendor-sourced chassis architectures. The main difference is
that we do not deploy additional servers to act as supervisor
cards and instead leverage our larger data center automation
tooling and monitoring. While this design does not provide
the same single logical switch abstraction that is provided by
conventional vendor switches, it allows us to jump to larger
switch form factors with no software architectural changes.
Implicit and Circular Dependency. One subtle but impor-
tant problem we discovered when trying to run our switches
like a server was hidden and implicit circular dependencies
on the network. Specifically, all servers on our fleet run a
standard set of binaries and libraries for logging, monitoring,
and etc. By design, we wanted to run these existing software
on our switches. Unfortunately, in some cases, the software
built for the servers implicitly depended on the network and
when the FBOSS code depended on them, we created a circu-
lar dependency that prevented our network from initializing.
Worse yet, these situations would only arise during other er-
ror conditions (e.g., when a daemon crash) and were hard to
debug. In one specific case, we initially deployed the FBOSS
onto switches using the same task scheduling and monitoring
software used by other software services in our fleet, but we
found that this software required access to the production
network before it would run. As a result, we had to decouple
our code from it and write our own custom task scheduling
software to specifically manage FBOSS deployments. While
this was an easier case to debug, as each software package
evolves and is maintained independently, there is a constant
threat of well-meaning but server focused developers adding
a subtle implicit dependency on the network. Our current
solution is to continue to fortify our testing and deployment
procedures.
9 FUTURE WORK
Partitioning FBOSS Agent. FBOSS agent currently is a
single monolithic binary consisting of multiple features. Sim-
ilar to how QSFP service was separated to improve switch
reliability, we plan to further partition FBOSS agent into
smaller binaries that runs independently. For example, if state
observers exist as external processes that communicates with
FBOSS agent, any events that can overwhelms the state ob-
servers no long brings FBOSS agent down with it.
Novel Experiments. One of our main goals for FBOSS is
to allow more and faster experimentation. We are currently ex-
perimenting with custom routing protocols, stronger slow path
isolation (e.g., to deal with buggy experiments), micro-burst
detection, macro-scale traffic monitoring, big data analytic of
low-level hardware statistics to infer failure detection, and a
host of other design elements. By making FBOSS open source
and our research more public, we hope to aid researchers with
FBOSS: Building Switch Software at Scale
SIGCOMM ’18, August 20–25, 2018, Budapest, Hungary
tools and ideas to directly implement novel research ideas on
production ready software and hardware.
Programmable ASIC Support. FBOSS is designed to
easily support multiple types of ASICs simultaneously. In
fact, FBOSS successfully iterated through different versions
of ASICs without any huge design changes. With the recent