to track the origin of crashes. Although several efforts 
have  been  made  to  improve  the  capabilities  of  crash 
origin 
remain 
untraceable  or  are  detected  incorrectly.  Whenever  an 
experiment  caused  a  crash,  the  minidump  files  were 
inspected  to  evaluate  their  identification  capabilities. 
Four main categories of results were considered:  
identification, 
errors 
still 
some 
Identification OK (M1): The minidump file correctly 
identifies the faulty driver as the source of the crash. 
Identification  ERROR  (M2):  The  minidump  file 
identifies other module as the cause of failure.  
Unidentified  (M3):  The  minidump  file  could  not 
identify  either  the  driver  or  other  module  as  the 
source of the crash. 
Memory  Corruption  (M4):  The  minidump  file 
detected a memory corruption. 
2.4  Experimental Setup 
Since  the  experiments  were  likely  to  cause  system 
hangs  or  crashes,  and  sometimes 
these  crashes 
corrupted files, we had to utilize two machines in order 
to automate most of the tasks (see Figure 2). The target 
machine hosts the OS under test and the DD workload, 
and  the  controller  machine  is  in  charge  of  selecting 
which  tests  should  be  carried  out,  collecting  data  and 
rebooting the target whenever needed.  
is 
the 
removes 
informed  of  each  step  of 
After  booting  the  targeting  machine,  DevInject 
contacts DevController to find out which driver should 
be used in the next experiment. Then, DevInject loads 
the driver, triggers the fault, checks the outcome and, if 
driver. 
everything  went  well, 
DevController 
the 
experiment,  so  that  it  can  tell  DevInject  what  actions 
should be performed. This way, the target file system is 
not used to save any intermediate results or keep track 
of  the  experience,  since  it  might  end  up  being 
corrupted. The target file system is however utilized to 
store  the  minidump  files  and  the  corrupted  files  that 
were  found.  After  a  reboot,  DevInject  transfers  to 
DevController this information using FTP. 
3  Experimental Results 
All measurements were taken on a prototype system 
composed  by  two  x86  PCs  linked  by  an  Ethernet 
network.  The  target  machine  was  a  DELL  Optiplex 
computer with 512Mb and 2 disks. Three OS versions 
and two distinct file systems, FAT32 and NTFS, were 
evaluated.  The 
different 
configurations (Vista was not tested with FAT32). The 
exact OS versions were: Windows XP Kernel Version 
2600  (SP  2),  built:  2600.xpsp_sp2_gdr.050301-1519, 
Windows  Server  2003  Kernel  Version  3790  (SP  1), 
built: 3790.srv03_sp1_rtm.050324-1447 and Windows 
Vista 
5600, 
built: 
5600.16384.x86fre.vista_rc1.060829-2230. 
outcome  was 
Version 
Kernel 
five 
Microsoft  provides  an  equivalent  Device  Driver 
Toolkit  for  all  OS.  Consequently,  the  same  set  of 
drivers could be used to test the various OS.  In every 
target  configuration  the  initial  conditions  were  the 
same, the OS were configured to produce similar types  
Target Machine 
FTP Client 
Script 
DevInject 
Trigger 
                     OS 
Driver 
Fault 
OS 
Controller Machine 
FTP Server       
Files  
Instructions 
Log 
     DevController 
Next DD 
Log 
Figure 2: Injecting erroneous input. 
of dump files, and the DevInject tool was basically the 
only user application running. 
We  decided  to  carry  out  the  experiments  without 
load  to ensure that results were highly repeatable, and 
therefore to increase the accuracy to the conclusions. In 
the  near future, we intend to complement  our analysis 
with  loaded  systems,  by  employing  some  standard 
workload.  
3.1  Observed Failure Modes 
The  observed  failure  modes  are  displayed in Table 
5.  The  first  three  columns  present  the  function 
identifier  ID,  its  alias  name  and  the  number  of 
experiments carried out with each function. The failure 
modes 
the  various  OS  configurations  are 
represented  in  the next  four groups of  columns, under 
the headings FM1 to FM4. Each column group presents 
one value for each OS configuration. 
for 
indicating  a  high 
In the 20 functions that were tested, several of them 
were able to deal at least with a subset of the erroneous 
input.  There  were  however  a  few  cases  where  results 
were  extremely  bad, 
level  of 
vulnerability. By computing the formula FM1/#DD for 
each  FM1  entry,  one  can  have  an  idea  about  the 
relative robustness of the functions (see Figure 3). Only 
two  functions  were  100%  immune  to  the  injected 
faults,  9-ZwClose  and 18-QryKey. On the other  hand, 
eight  functions  had  zero  or  near  zero  capabilities  to 
deal with the faults.  
One  reason  for  this  behavior  is  that  some  of  these 
functions are so efficiency dependent (e.g., 4-CompReq 
and  14-AcqLock)  that  developers  have  avoided  the 
implementation  of  built  in  checks.  Another  reason  is 
related to the nature of the function, which in the case 
of  3-BugCheck  is  to  bring  down  the  system  in  a 
controlled  manner,  when  the  caller  discovers  an 
unrecoverable inconsistency. 
Table 5: Observed failure modes. 
ID  Alias 
#DD 
FM1: Execution OK 
XP 
V 
FM4: Crash & FCorrupt 
V 
Fat  Ntfs  Fat  Ntfs  Ntfs  Fat Ntfs  Fat  Ntfs  Ntfs  Fat  Ntfs  Fat  Ntfs  Ntfs  Fat  Ntfs  Fat  Ntfs  Ntfs 
9 
FM3: Crash 
2003 
FM2: Hangs 
2003 
2003 
2003 
XP 
XP 
XP 
V 
V 
9 
9 
9 
9 
3 
2 
3 
3 
12 
3 
0 
6 
0 
6 
0 
6 
0 
6 
0 
0 
0 
0 
0 
0 
0 
0 
12  12 
1  InitStr 
0 
2  AllocPool  440  416  416  416  416  420  0 
0 
3  BugCheck  12 
0 
0 
4  CompReq 
0 
51 
0 
5  CreateDev  96  48  48  48  48  48 
0 
0 
6  DeleteDev 
4 
0 
18 
7  InitEvt 
6 
8  WaitObj 
36  18  18  18  18  18 
0 
0 
3 
3 
9  ZwClose 
0 
0 
9 
10  CallDrv 
0 
1 
16 
11  FreePool 
12  SetEvt 
24 
9 
0 
0 
2 
3 
13  InitLock 
2 
0 
8 
14  AcqLock 
0 
1 
48 
15  RelLock 
3 
16  DerefObj 
0 
0 
17  OpenKey 
155  104  104  104  104  104  0 
315  315  315  315  315  315  0 
18  QryKey 
1 
9 
19  AttachDev 
0 
48  18  18  27  27  24 
20  memset 
0 
Total 
1310 951  951  970  970  960  3 
Total / # DD  (%) 
3 
3 
0 
0 
1 
1 
18  18 
2 
2 
0 
0 
1 
1 
2 
2 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
72,6  72,6  74,0  74,0  73,3  0,2  0,2  0,2  0,2  0,2  12,5  27,2  11,8  25,7  26,5  14,7  0,0  13,9  0,0  0,0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
2 
0 
0 
0 
0 
0 
0 
0 
0 
0 
1 
0 
0 
3  164  356  155  337  347  192  0  182  0 
2 
1 
14  24  13  24  20  10 
6 
6 
12 
51  26  51  51  51 
0 
48  48  19 
29  48 
4 
4 
4 
0 
4 
4 
12  12 
8 
12 
15  18 
18  18 
3 
0 
0 
0 
0 
0 
9 
9 
0 
9 
9 
15  15  14 
1 
15 
15  18 
6 
3 
1 
1 
1 
0 
2 
6 
6 
4 
18  45  12  47  47  27 
1 
0 
25  51  47  51  51  26 
0 
0 
0 
2 
6 
8 
22  30  12  21  24 
8 
1 
11 
9 
25 
40 
2 
5 
16 
0 
5 
7 
1 
1 
4 
35 
1 
4 
0 
6 
9 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
2 
0 
0 
0 
0 
1 
0 
3 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
2 
0 
0 
0 
0 
1 
0 
3 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
2 
0 
0 
0 
0 
1 
0 
3 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 