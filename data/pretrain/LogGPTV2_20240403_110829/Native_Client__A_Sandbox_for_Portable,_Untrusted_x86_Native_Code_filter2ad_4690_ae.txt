A further advantage of expressing sandboxing directly in
machine code is that it does not require a trusted compiler.
This greatly reduces the size of the trusted computing
base [61], and obviates the need for cryptographic signatures
from the compiler. Apart from simplifying the security
implementation, this has the further beneﬁt in Native Client
of opening the system to 3rd-party tool chains.
Compared to Native Client, CFI [1] provides ﬁner-grained
control ﬂow integrity. Whereas our system only guarantees
indirect control ﬂow will target an aligned address in the text
segment, CFI can restrict a speciﬁc control transfer to a fairly
arbitrary subset of known targets. While this more precise
control is possibly useful in some scenarios, such as insuring
integrity of translation from a high-level language, it is not
useful for Native Client, since we intend to permit quite
arbitrary control ﬂow, even hand-coded assembler, as long
as execution remains in known text and targets are aligned.
At the same time, CFI overhead is a factor of three higher
on average (15% vs. 5% on SPEC2000), not surprising
since its instrumentation sequences are much longer than
Native Client’s, both in terms of size and instruction count.
XFI [19] adds data sandboxing to CFI control ﬂow checks,
with additional overhead. By contrast Native Client gets data
integrity for free from x86 segments.
Other recent systems have explored mechanisms for en-
abling safe side effects with measured trust. NaCl resource
descriptors are analogous to capabilities in systems such as
EROS [55]. Singularity channels [30] serve an analogous
role. DTrace [11], Systemtap [49] and XFI [19] have related
mechanisms.
A number of projects have explored isolating untrusted
kernel extensions. SPIN and VINO take different approaches
to implementing safety. SPIN chose a type-safe language,
Modula-3 [47], together with a trusted compiler tool chain,
for implementing extensions. VINO, like Native Client and
the original work by Wahbe et al., used software fault
isolation based on sandboxing of machine instructions. Like
Native Client, VINO used a modiﬁed compilation toolchain
to add sandboxing instructions to x86 machine code, using
C++ for implementing extensions. Unlike Native Client,
VINO had no binary validator, relying on a trusted compiler.
We note that a validator for VINO would be more difﬁcult
than that of Native Client, as its validator would have had
to enforce data reference integrity, achieved in Native Client
with 80386 segments.
The Nooks system [58] enhances operating system kernel
reliability by isolating trusted kernel code from untrusted
device driver modules using a transparent OS layer called
the Nooks Isolation Manager (NIM). Like Native Client,
NIM uses memory protection to isolate untrusted modules.
As the NIM operates in the kernel, x86 segments are not
available. The NIM instead uses a private page table for
each extension module. To change protection domains, the
NIM updates the x86 page table base address, an operation
that has the side effect of ﬂushing the x86 Translation
Lookaside Buffer (TLB). In this way, NIM’s use of page
tables suggests an alternative to segment protection as used
by Native Client. While a performance analysis of these
two approaches would likely expose interesting differences,
the comparison is moot on the x86 as one mechanism is
available only within the kernel and the other only outside
the kernel. A critical distinction between Nooks and Native
Client is that Nooks is designed only to protect against
unintentional bugs, not abuse. In contrast, Native Client must
be resistant to attempted deliberate abuse, mandating our
mechanisms for reliable x86 disassembly and control ﬂow
integrity. These mechanisms have no analog in Nooks.
There are many environments based on a virtual-machine
architecture that provide safe execution and some fraction of
native performance [3], [6], [7], [20], [28], [39], [53], [63].
While recognizing the excellent fault-isolation provided by
these systems, we made a deliberate choice against virtu-
alization in Native Client, as it is generally inconsistent
with, or irrelevant to, our goals of OS neutrality, browser
neutrality, and peak native performance.
More recently, kernel extensions have been used for
operating system monitoring. DTrace [11] incorporated a
VM interpreter into the Solaris kernel for safe execution, and
provided a set of kernel instrumentation points and output
facilities analogous to Native Client’s safe side effects.
Systemtap [49] provides similar capabilities to DTrace, but
uses x86 native code for extensions rather than an interpreted
language in a VM.
6.3. Trust with Authentication
Perhaps the most prevalent example of using native code
in web content is Microsoft’s ActiveX [15]. ActiveX controls
rely on a trust model to provide security, with controls
cryptographically signed using Microsoft’s proprietary Au-
thenticode system [43], and only permitted to run once a
user has indicated they trust the publisher. This dependency
on the user making prudent trust decisions is commonly
exploited. ActiveX provides no guarantee that a trusted
control
itself is not
inherently malicious, defects in the control can be exploited,
often permitting execution of arbitrary code. To mitigate this
issue, Microsoft maintains a blacklist of controls deemed
unsafe [42]. In contrast, Native Client is designed to prevent
such exploitation, even for ﬂawed NaCl modules.
is safe, and even when the control
90
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:17:16 UTC from IEEE Xplore.  Restrictions apply. 
7. Conclusions
This paper has described Native Client, a system for
incorporating untrusted x86 native code into an application
that runs in a web browser. In addition to creating a barrier
against undesirable side effects, NaCl modules are portable
both across operating systems and across web browsers, and
supports performance-oriented features such as threading
and vectorization instructions. We believe the NaCl inner
sandbox is extremely robust; regardless we provide addi-
tional redundant mechanisms to provide defense-in-depth.
In our experience we have found porting existing
Linux/gcc code to Native Client
is straightforward, and
that
the performance penalty for the sandbox is small,
particularly in the compute-bound scenarios for which the
system is designed.
By describing Native Client here and making it available
as open source, we hope to encourage community scrutiny
and contributions. We believe this feedback together with
our continued diligence will enable us to create a system
that achieves a superior level of safety than previous native
code web technologies.
Acknowledgments
Many people have contributed to the direction and the
development of Native Client; we acknowledge a few of
them here. The project was conceived based on an idea from
Matt Papakipos. Jeremy Lau, Brad Nelson, John Grabowski,
Kathy Walrath and Geoff Pike have made valuable contri-
butions to the implementation and evaluation of the system.
Thanks also to Danny Berlin, Chris DiBona, and Rebecca
Ward. We thank Sundar Pichai and Henry Bridge for their
role in shaping the project direction. We’d also like to thank
Dick Sites for his thoughtful feedback on an earlier version
of this paper.
References
[1] M. Abadi, M. Budiu, U. Erlingsson, and J. Ligatti. Control-
ﬂow integrity: Principles, implementations, and applications.
In Proceedings of the 12th ACM Conference on Computer
and Communications Security, November 2005.
[2] M. Accetta, R. Baron, W. Bolosky, D. Golub, R. Rashid,
A. Tevanian, and M. Young. Mach: A new kernel foundation
for UNIX development. pages 93–112, 1986.
[3] A. Adl-Tabatabai, G. Langdale, S. Lucco, and R. Wahbe. Ef-
ﬁcient and language-independent mobile programs. SIGPLAN
Not., 31(5):127–136, 1996.
[4] Advanced Micro Devices. AMD64 Architecture Program-
mer’s Manual, Volume 1: Application Programming. Ad-
vanced Micro Devices, September 2007. Publication number:
24592.
[5] Autoconf. http://www.gnu.org/software/autoconf/.
91
[6] P. Barham, B. Dragovic, K. Fraser, S. Hand, A. Ho, R. Neuge-
bauer, I. Pratt, and A. Warﬁeld. Xen and the art of virtu-
In 19th ACM Symposium on Operating Systems
alization.
Principles, pages 164–177, 2003.
[7] E. Bugnion, S. Devine, K. Govil, and M. Rosenblum. Disco:
Running commodity operating systems on scalable multipro-
cessors. ACM Transactions on Computer Systems, 15(4):412–
447, November 1997.
[8] Bullet physics SDK. http://www.bulletphysics.com.
[9] J. Burns. Developing secure mobile applications for an-
droid. http://isecpartners.com/ﬁles/iSEC Securing Android
Apps.pdf, 2008.
[10] K. Campbell, L. Gordon, M. Loeb, and L. Zhou.
The
economic cost of publicly announced information security
breaches: empirical evidence from the stock market. Journal
of Computer Security, 11(3):431–448, 2003.
[11] B. Cantrill, M. Shapiro, and A. Leventhal. Dynamic instru-
mentation of production systems. In 2004 USENIX Annual
Technical Conference, June 2004.
[12] D. R. Cheriton. The V distributed system. Communications
of the ACM, 31:314–333, 1988.
[13] F. B. Cohen. Defense-in-depth against computer viruses.
Computers and Security, 11(6):565–584, 1993.
[14] J. Crawford and P. Gelsinger. Programming 80386. Sybex
Inc., 1991.
[15] A. Denning. ActiveX Controls Inside Out. Microsoft Press,
May 1997.
[16] Directorate for Command, Control, Communications and
Computer Systems, U.S. Department of Defense Joint Staff.
Information assurance through defense-in-depth. Technical
report, Directorate for Command, Control, Communications
and Computer Systems, U.S. Department of Defense Joint
Staff, February 2000.
[17] J. R. Douceur, J. Elson, J. Howell, and J. R. Lorch. Leverag-
ing legacy code to deploy desktop applications on the web.
In Proceedings of the 2008 Symposium on Operating System
Design and Implementation, December 2008.
[18] M. Eisler (editor). XDR: External data representation. Internet
RFC 4506, 2006.
[19] U. Erlingsson, M. Abadi, M. Vrable, M. Budiu, and G. Nec-
ula. XFI: Software guards for system address spaces.
In
OSDI ’06: 7th Symposium on Operating Systems Design And
Implementation, pages 75–88, November 2006.
[20] B. Ford. VXA: A virtual architecture for durable compressed
archives. In USENIX File and Storage Technologies, Decem-
ber 2005.
[21] B. Ford and R. Cox. Vx32: Lightweight user-level sandboxing
on the x86. In 2008 USENIX Annual Technical Conference,
June 2008.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:17:16 UTC from IEEE Xplore.  Restrictions apply. 
[22] The GNU compiler collection. http://gcc.gnu.org.
[23] GNU binutils. http://www.gnu.org/software/binutils/.
[40] S. McCamant and G. Morrisett. Efﬁcient, veriﬁable binary
sandboxing for a CISC architecture. Technical Report MIT-
CSAIL-TR-2005-030, 2005.
[24] I. Goldberg, D. Wagner, R. Thomas, and E. A. Brewer.
A secure enviroment for untrusted helper applications.
In
Proceedings of the 6th USENIX Security Symposium, 1996.
[41] S. McCamant and G. Morrisett. Evaluating SFI for a CISC
In 15th USENIX Security Symposium, August
architecture.
2006.
[25] D. Golub, A. Dean, R. Forin, and R. Rashid. UNIX as an
In Proceedings of the Summer 1990
application program.
USENIX Conference, pages 87–95, 1990.
[26] Google Inc.
protobuf/.
Protocol buffers.
http://code.google.com/p/
[27] Google Inc. Android—an open handset alliance project. http:
//code.google.com/android, 2007.
[28] J. Gosling, B. Joy, G. Steele, and G. Bracha. The Java
Language Speciﬁcation. Addison-Wesley, 2000.
[29] B. Gough and R. Stallman. An Introduction to GCC. Network
Theory, Ltd., 2004.
[30] G. Hunt, J. Larus, M. Abadi, M. Aiken, P. Barham, M. Fah-
ndrich, C. Hawblitzel, O. Hodson, S. Levi, N. Murphy,
B. Steensgaard, D. Tarditi, T. Wobber, and B. Zill. An
overview of the Singularity project. Technical Report MSR-
TR-2005-135, Microsoft Research, October 2005.
[31] Intel Corporation. Intel Pentium processor invalid instruction
http://support.intel.com/support/processor/
errata overview.
pentium/ppiie/index.html.
[32] Intel Corporation. Intel 64 and IA-32 Architectures Software
Developers Manual, Volume 1: Basic Architecture.
Intel
Corporation, August 2007. Order Number: 253655-024US.
[33] S. Ioannidis and S. M. Bellovin. Building a secure web
browser. In USENIX Annual Technical Conference, FREENIX
Track, pages 127–134, 2001.
[34] S. Ioannidis, S. M. Bellovin, and J. M. Smith. Sub-operating
systems: A new approach to application security. In Proceed-
ings of the 10th ACM SIGOPS European Workshop, 2002.
[35] Jam 2.1 user’s guide. http://javagen.com/jam/.
[36] C. Jensen and D. Hagimont. Protection wrappers: a simple
and portable sandbox for untrusted applications. In Proceed-
ings of the 8th ACM SIGOPS European Systems Conference,
pages 104–110, 1998.
[37] W. Joy, E. Cooper, R. Fabry, S. Lefﬂer, K. McKusick, and
D. Mosher.
4.2 BSD system manual. Technical report,
Computer Systems Research Group, University of California,
Berkeley, 1983.
[42] Microsoft Corporation. The kill-bit faq - part 1 of 3. Microsoft
Security Vulnerability Research and Defense (Blog).
[43] Microsoft Corporation.
Signing and checking code
with Authenticode. http://msdn.microsoft.com/en-us/library/
ms537364(VS.85).aspx.
[44] Microsoft Corporation. Structured exception handling. http:
//msdn.microsoft.com/en-us/library/ms680657(VS.85).aspx,
2008.
[45] G. Morrisett, K. Crary, N. Glew, and D. Walker. Stack-
Journal of Functional
based typed assembly language.
Programming, 12(1):43–88, 2002.
[46] G. Necula. Proof carrying code. In Principles of Program-
ming Languages, 1997.
[47] G. Nelson (editor).
Prentice-Hall, 1991.
System Programming in Modula-3.
[48] Netscape Corporation.
Gecko plugin API
reference.
http://developer.mozilla.org/en/docs/Gecko Plugin API
Reference.
[49] V. Prasad, W. Cohen, F. Eigler, M. Hunt, J. Keniston, and
J. Chen. Locating system problems using dynamic instru-
mentation. In 2005 Ottawa Linux Symposium, pages 49–64,
July 2005.
[50] N. Provos. Improving host security with system call policies.
In USENIX Security Symposium, August 2003.
[51] J. Reinders.
Intel Thread Building Blocks. O’Reilly &
Associates, 2007.
[52] J. G. Richard West. User-level sandboxing: a safe and efﬁcient
mechanism for extensibility. Technical Report TR-2003-014,
Boston University, Computer Science Department, Boston,
MA, 2003.
[53] J. Richter. CLR via C#, Second Edition. Microsoft Press,
2006.
[54] M. Savage. Cost of computer viruses top $10 billion already
this year. ChannelWeb, August 2001.
[55] J. Shapiro, J. Smith, and D. Farber. EROS: a fast capability
system. In Symposium on Operating System Principles, pages
170–185, 1999.
[38] K. Kaspersky and A. Chang. Remote code execution through
Intel CPU bugs. In Hack In The Box (HITB) 2008 Malaysia
Conference.
[56] C. Small. MiSFIT: A tool for constructing safe extensible
C++ systems. In Proceedings of the Third USENIX Confer-
ence on Object-Oriented Technologies, June 1997.
[39] T. Lindholm and F. Yellin.
The Java Virtual Machine
Speciﬁcation. Prentice Hall, 1999.
[57] B. Stroustrup. The C++ Programming Language: Second
Edition. Addison-Wesley, 1997.
92
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:17:16 UTC from IEEE Xplore.  Restrictions apply. 
[58] M. Swift, M. Annamalai, B. Bershad, and H. Levy. Recover-
ing device drivers. In 6th USENIX Symposium on Operating
Systems Design and Implementation, December 2004.
[59] D. Tarditi, G. Morrisett, P. Cheng, C. Stone, R. Harper, and
P. Lee. TIL: a type-directed optimizing compiler for ML. In
PLDI ’96: Proceedings of the ACM SIGPLAN 1996 confer-
ence on Programming language design and implementation,
pages 181–192, New York, NY, USA, 1996. ACM.
[60] W. Tarreau. ptrace documentation. http://www.linuxhq.com/
kernel/v2.4/36-rc1/Documentation/ptrace.txt, 2007.
[61] U. S. Department of Defense, Computer Security Center.
Trusted computer system evaluation criteria, December 1985.
[62] R. Wahbe, S. Lucco, T. E. Anderson, and S. L. Graham. Efﬁ-
cient software-based fault isolation. ACM SIGOPS Operating
Systems Review, 27(5):203–216, December 1993.
[63] C. Waldspurger. Memory resource management in VMware
ESX Server. In 5th Symposium on Operating Systems Design
and Implementation, December 2002.
[64] Document Object Model (DOM) Level 1 Speciﬁcation. Num-
ber REC-DOM-Level-1-19981001. World Wide Web Consor-
tium, October 1998.
93
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:17:16 UTC from IEEE Xplore.  Restrictions apply.