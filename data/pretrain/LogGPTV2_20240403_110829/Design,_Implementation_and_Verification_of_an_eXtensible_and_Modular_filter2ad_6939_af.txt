quality attributes – but also to make such analysis more
tractable [59]. Our work reafﬁrms these ideas, and demon-
strates concretely the synergy between – and importance of
– architecture and analysis in the context of developing an
integrity-protected hypervisor.
The idea of an interface constrained adversary [33], [60]
has been used to model and verify security properties of a
number of systems. In particular, pinning down the attacker’s
interface enables systematic and rigorous reasoning about
security guarantees. This idea appears in our work as well.
Speciﬁcally, restricting the attacker’s interface to a set of
intercept handlers is crucial for the feasibility of DRIVE.
A number of projects have used software model checking
and static analysis to ﬁnd errors in source code, without
a speciﬁc attacker model. Some of these projects [61]–[63]
target a general class of bugs. Others focus on speciﬁc types
of errors, e.g., Kidd et al. [64] detect atomic set serializ-
ability violations, while Emmi et al. [65] verify correctness
of reference counting implementation. All these approaches
require abstraction, e.g., random isolation [64] or predicate
abstraction [65], to handle source code, and therefore, are
unsound and/or incomplete. In contrast, we focus on a
methodology to develop a hypervisor that achieves a speciﬁc
security property against a well-deﬁned attacker.
Finally, there has been several projects on verifying se-
curity of operating system and hypervisor implementations.
Neumann et al. [66], Rushby [67], and Shapiro and We-
ber [68] propose verifying the design of secure systems by
manually proving properties using a logic and without an
explicit adversary model. A number of groups [18]–[20]
have employed theorem proving to verify security properties
of OS implementations. Barthe et al. [69] formalized an
idealized model of a hypervisor in the Coq proof assistant
and Alkassar et al. [70], [71] and Baumann et al. [72] anno-
tated the C code of a hypervisor and utilized the VCC [21]
veriﬁer to prove correctness properties. Approaches based
on theorem proving are applicable to a more general class
of properties, but also require considerable manual effort.
For example, the seL4 veriﬁcation [20] shows a form of
functional correctness, essentially relating the C implemen-
tation with a high level speciﬁcation and required several
man years effort. Since the high-level speciﬁcation does not
include an explicit adversary that is trying to break memory
integrity, the veriﬁcation does not imply the security property
of interest to us. In contrast, our approach is more automated
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:54:03 UTC from IEEE Xplore.  Restrictions apply. 
but we focus on a speciﬁc security property (memory
integrity) with an explicit adversary model. However, since
we do not verify full functional correctness, we cannot, for
example, claim that our system will not crash.
VIII. CONCLUSION AND FUTURE WORK
We propose an eXtensible and Modular Hypervisor
Framework (XMHF) which strives to be a comprehensible
and ﬂexible platform for building hypervisor applications
(“hypapps”). XMHF is based on a design methodology
that enables automated veriﬁcation of hypervisor memory
integrity. In particular, the automated veriﬁcation was per-
formed on the actual source code of XMHF – consisting
of 5208 lines of C code – using the CBMC model checker
We believe that XMHF provides a good starting point for
research and development on hypervisors with rigorous and
“designed-in” security guarantees. Given XMHF’s features
and performance characteristics, we believe that
it can
signiﬁcantly enhance (security-oriented) hypervisor research
and development.
One direction for future work is modular veriﬁcation of
the XMHF core composed with hypapps. Another direction
is to extend DRIVE to other security properties such as
secrecy. A challenge here is that for such a property, the
attacker’s interface is much less well-deﬁned compared to
memory integrity, due to the possibility of covert channels
etc. Yet another direction is to include support for concurrent
execution within XMHF and the hypapps. The question here
is whether, or how, we can still guarantee memory integrity.
Acknowledgements. We thank our shepherd, William
Enck, for his help with the ﬁnal version of this paper, as well
as the anonymous reviewers for their detailed comments.
We also want to thank Adrian Perrig, Virgil Gligor and
Zongwei Zhou for stimulating conversations on XMHF. This
work was partially supported by NSF grants CNS-1018061,
CCF-0424422, CNS-0831440, and an AFOSR MURI on
Science of Cybersecurity. Copyright 2012 Carnegie Mellon
University and IEEE3.
REFERENCES
[1] C. Chen, P. Maniatis, A. Perrig, A. Vasudevan, and V. Sekar,
“Towards veriﬁable resource accounting for outsourced com-
putation,” in Proc. of ACM VEE, 2013.
[2] A. Vasudevan, B. Parno, N. Qu, V. D. Gligor, and A. Perrig,
“Lockdown: Towards a safe and practical architecture for
security applications on commodity platforms,” in Proc. of
TRUST, Jun. 2012.
[3] Z. Wang, C. Wu, M. Grace, and X. Jiang, “Isolating commod-
ity hosted hypervisors with hyperlock,” in Proc. of EuroSys
2012.
3This material is based upon work funded and supported by the De-
partment of Defense under Contract No. FA8721-05-C-0003 with Carnegie
Mellon University for the operation of the Software Engineering Institute,
a federally funded research and development center. This material has been
approved for public release and unlimited distribution. DM-0000090
[4] Z. Zhou, V. D. Gligor, J. Newsome, and J. M. McCune,
“Building veriﬁable trusted path on commodity x86 comput-
ers,” in Proc. of IEEE S&P, May 2012.
[5] F. Zhang, J. Chen, H. Chen, and B. Zang, “CloudVisor:
retroﬁtting protection of virtual machines in multi-tenant
cloud with nested virtualization,” in Proc. of SOSP, 2011.
[6] A. Vasudevan, N. Qu, and A. Perrig, “Xtrec: Secure real-time
execution trace recording on commodity platforms,” in Proc.
of IEEE HICSS, Jan. 2011.
[7] J. M. McCune, Y. Li, N. Qu, Z. Zhou, A. Datta, V. Gligor,
and A. Perrig, “TrustVisor: Efﬁcient TCB reduction and
attestation,” in Proc. of IEEE S&P, May 2010.
[8] A. Fattori, R. Paleari, L. Martignoni, and M. Monga, “Dy-
namic and transparent analysis of commodity production
systems,” in Proc. of IEEE/ACM ASE 2010.
[9] L. Litty, H. A. Lagar-Cavilla, and D. Lie, “Hypervisor sup-
port for identifying covertly executing binaries,” in Proc. of
USENIX Security Symposium, 2008.
[10] A. Seshadri, M. Luk, N. Qu, and A. Perrig, “SecVisor: A
tiny hypervisor to provide lifetime kernel code integrity for
commodity OSes,” in Proc. of SOSP, 2007.
[11] X. Xiong, D. Tian, and P. Liu, “Practical protection of kernel
integrity for commodity os from untrusted extensions,” in
Proc. of of NDSS 2011.
[12] L. Singaravelu, C. Pu, H. Haertig, and C. Helmuth, “Reducing
TCB complexity for security-sensitive applications: Three
case studies,” in Proc. of EuroSys, 2006.
[13] R. Ta-Min, L. Litty, and D. Lie, “Splitting Interfaces: Making
Trust Between Applications and Operating Systems Conﬁg-
urable,” in Proc. of SOSP, 2006.
[14] A. Dinaburg, P. Royal, M. Sharif, and W. Lee, “Ether:
malware analysis via hardware virtualization extensions,” in
Proc. of of ACM CCS 2008.
[15] D. Quist, L. Liebrock, and J. Neil, “Improving antivirus
accuracy with hypervisor assisted analysis,” J. Comput. Virol.,
vol. 7, no. 2, May 2011.
[16] M. I. Sharif, W. Lee, W. Cui, and A. Lanzi, “Secure in-vm
monitoring using hardware virtualization,” in Proc. of ACM
CCS, 2009.
[17] X. Chen, T. Garﬁnkel, E. C. Lewis, P. Subrahmanyam, C. A.
Waldspurger, D. Boneh, J. Dwoskin, and D. R. K. Ports,
“Overshadow: A virtualization-based approach to retroﬁtting
protection in commodity operating systems,” in Proc. of
ASPLOS, Mar. 2008.
[18] B. J. Walker, R. A. Kemmerer, and G. J. Popek, “Speciﬁ-
cation and veriﬁcation of the UCLA Unix security kernel,”
Communications of the ACM (CACM), vol. 23, no. 2, 1980.
[19] C. L. Heitmeyer, M. Archer, E. I. Leonard, and J. D. McLean,
“Formal speciﬁcation and veriﬁcation of data separation in a
separation kernel for an embedded system,” in Proc. of ACM
CCS, 2006.
[20] G. Klein, K. Elphinstone, G. Heiser, J. Andronick, D. Cock,
P. Derrin, D. Elkaduwe, K. Engelhardt, R. Kolanski, M. Nor-
rish, T. Sewell, H. Tuch, and S. Winwood, “seL4: formal
veriﬁcation of an OS kernel,” in Proc. of SOSP, 2009.
[21] E. Cohen, M. Dahlweid, M. A. Hillebrand, D. Leinenbach,
M. Moskal, T. Santen, W. Schulte, and S. Tobies, “VCC:
A Practical System for Verifying Concurrent C,” in Proc. of
TPHOLs, 2009.
[22] E. Clarke, D. Kroening, and F. Lerda, “A Tool for Checking
ANSI-C Programs,” in Proc. of TACAS, 2004.
[23] Intel Corporation, “Intel 64 and IA-32 Architectures Software
Developer’s Manual Combined Volumes:1, 2A, 2B, 2C, 3A,
3B, and 3C,” 2011.
[24] Advanced Micro Devices, “AMD64 architecture program-
mer’s manual: Volume 2: System programming,” AMD Pub-
443
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:54:03 UTC from IEEE Xplore.  Restrictions apply. 
lication no. 24594 rev. 3.11, Dec. 2005.
[25] ARM Limited, “Virtualization extensions architecture speci-
ﬁcation,” http://infocenter.arm.com, 2010.
[26] M. Abadi, M. Budiu, ´U. Erlingsson, and J. Ligatti, “Control-
Flow Integrity principles, implementations and applications,”
TISSEC, vol. 13, no. 1, 2009.
[27] L. Jia, D. Garg, and A. Datta, “Compositional security
for higher-order programs,” Carnegie Mellon University,
Tech. Rep. CMU-CyLab-13-001, 2013, online at http://www.
andrew.cmu.edu/user/liminjia/compositional.
[28] M. Ben-Yehuda, M. D. Day, Z. Dubitzky, M. Factor,
N. Har’El, A. Gordon, A. Liguori, O. Wasserman, and B.-
A. Yassour, “The turtles project: design and implementation
of nested virtualization,” in Proc. of OSDI 2010.
[29] RedHat, “KVM – kernel based virtual machine,” http://www.
redhat.com/f/pdf/rhev/DOC-KVM.pdf, 2009.
[30] P. Karger and D. Safford, “I/O for virtual machine monitors:
Security and performance issues,” IEEE Security and Privacy,
vol. 6, no. 5, 2008.
[31] N. Elhage, “Virtunoid: Breaking out of kvm,” Defcon, 2011.
[32] Z. Wang and X. Jiang, “Hypersafe: A lightweight approach
to provide lifetime hypervisor control-ﬂow integrity,” in Proc.
of IEEE S&P, 2010.
[33] A. Datta, J. Franklin, D. Garg, and D. Kaynar, “A logic of
secure systems and its application to trusted computing,” in
Proc. of IEEE S&P, 2009.
[34] T. Ball, E. Bounimova, V. Levin, R. Kumar, and J. Lichten-
berg, “The static driver veriﬁer research platform,” in Proc.
of CAV, 2010.
[35] J. Alglave, D. Kroening, and M. Tautschnig, “Partial or-
ders for efﬁcient bmc of concurrent software,” CoRR, vol.
abs/1301.1629, 2013.
[36] J. Franklin, S. Chaki, A. Datta, and A. Seshadri, “Scalable
Parametric Veriﬁcation of Secure Systems: How to Verify
Reference Monitors without Worrying about Data Structure
Size,” in Proc. of IEEE S&P, 2010.
[37] J. Franklin, S. Chaki, A. Datta, J. M. McCune, and A. Vasude-
van, “Parametric Veriﬁcation of Address Space Separation,”
in Proc. of POST, 2012.
[38] T. A. Henzinger, R. Jhala, R. Majumdar, and G. Sutre, “Lazy
Abstraction,” in Proc. of POPL, 2002.
[39] E. M. Clarke, D. Kroening, N. Sharygina, and K. Yorav,
“SATABS: SAT-Based Predicate Abstraction for ANSI-C,” in
Proc. of TACAS, 2005.
[40] D. Kroening and G. Weissenbacher, “Interpolation-Based
Software Veriﬁcation with Wolverine,” in Proc. of CAV, 2011.
[41] E. M. Clarke, O. Grumberg, S. Jha, Y. Lu, and H. Veith,
“Counterexample-guided abstraction reﬁnement for symbolic
model checking,” Journal of the ACM, vol. 50, no. 5, 2003.
[42] T. Ball and S. K. Rajamani, “Automatically Validating Tem-
poral Safety Properties of Interfaces,” in Proc. of SPIN, 2001.
[43] S. Graf and H. Sa¨ıdi, “Construction of Abstract State Graphs
with PVS,” in Proc. of CAV, 1997.
[44] T. Shinagawa, H. Eiraku, K. Tanimoto, K. Omote,
S. Hasegawa, T. Horie, M. Hirano, K. Kourai, Y. Oyama,
E. Kawai, K. Kono, S. Chiba, Y. Shinjo, and K. Kato,
“Bitvisor: a thin hypervisor for enforcing i/o device security,”
in Proc. of ACM SIGPLAN/SIGOPS VEE 2009.
[45] J. Szefer, E. Keller, R. B. Lee, and J. Rexford, “Eliminating
the hypervisor attack surface for a more secure cloud,” in
Proc. of ACM CCS, 2011.
[46] E. Keller, J. Szefer, J. Rexford, and R. B. Lee, “Nohype:
virtualized cloud infrastructure without the virtualization,” in
Proc. of ISCA, 2010.
[47] P. Barham, B. Dragovic, K. Fraser, S. Hand, T. Harris, A. Ho,
R. Neugebauer, I. Pratt, and A. Warﬁeld, “Xen and the art of
virtualization,” in Proc. of SOSP, 2003.
[48] VMware Corporation, “VMware ESX, bare-metal hypervisor
for virtual machines,” http://www.vmware.com, Nov. 2008.
[49] U. Steinberg and B. Kauer, “Nova: a microhypervisor-based
secure virtualization architecture,” in Proc. of the Eurosys.
[50] J. Rutkowska and R. Wojtczuk, “Qubes os architecture,” http:
//qubes-os.org, 2010.
[51] R. Wojtczuk, “Detecting and preventing the Xen hypervisor
subversions,” Invisible Things Lab, 2008.
[52] “Elevated privileges,” CVE-2007-4993, 2007.
[53] “Multiple integer overﬂows allow execution of arbitrary
code,” CVE-2007-5497, 2007.
[54] R. Wojtczuk and J. Rutkowska, “Xen 0wning trilogy,” Invis-
ible Things Lab, 2008.
[55] R. Wojtczuk, “Subverting the Xen hypervisor,” Invisible
Things Lab, 2008.
[56] B. Ford, G. Back, G. Benson, J. Lepreau, A. Lin, and
O. Shivers, “The ﬂux oskit: A substrate for os and language
research,” in Proc. of ACM SOSP 1997.
[57] M. Shaw and D. Garlan, Software architecture - perspectives
on an emerging discipline. Prentice Hall, 1996.
[58] L. Bass, P. Clements, and R. Kazman, Software Architecture
in Practice. Addison Wesley, 2003.
[59] K. Wallnau, “Volume III: A Technology for Predictable
Assembly from Certiﬁable Components,” Software Engineer-
ing Institute, Carnegie Mellon University, Technical report
CMU/SEI-2003-TR-009, 2003.
[60] D. Garg, J. Franklin, D. K. Kaynar, and A. Datta, “Composi-
tional System Security with Interface-Conﬁned Adversaries,”
ENTCS, vol. 265, 2010.
[61] S. Hallem, B. Chelf, Y. Xie, and D. Engler, “A system and
language for building system-speciﬁc, static analyses.”
[62] H. Chen and D. Wagner, “MOPS: an infrastructure for ex-
amining security properties of software,” in Proc. of CCS,
2002.
[63] J. Yang, P. Twohey, D. R. Engler, and M. Musuvathi, “Using
model checking to ﬁnd serious ﬁle system errors,” in Proc.
of OSDI, 2004.
[64] N. Kidd, T. Reps, J. Dolby, and M. Vaziri, “Finding
Concurrency-Related Bugs Using Random Isolation,” in Proc.
of VMCAI, 2009.
[65] M. Emmi, R. Jhala, E. Kohler, and R. Majumdar, “Verifying
Reference Counting Implementations,” in Proc. of TACAS,
2009.
[66] P. Neumann, R. Boyer, R. Feiertag, K. Levitt, and L. Robin-
son, “A provably secure operating system: The system, its
applications, and proofs.” SRI International, Tech. Rep., 1980.
[67] J. M. Rushby, “Design and Veriﬁcation of Secure Systems,”
in Proc. of SOSP, 1981.
[68] J. S. Shapiro and S. Weber, “Verifying the EROS Conﬁnement
Mechanism,” in Proc. of IEEE S&P, 2000.
[69] G. Barthe, G. Betarte, J. D. Campo, and C. Luna, “Formally
Verifying Isolation and Availability in an Idealized Model of
Virtualization,” in Proc. of FM, 2011.
[70] E. Alkassar, M. A. Hillebrand, W. J. Paul, and E. Petrova,
“Automated Veriﬁcation of a Small Hypervisor,” in Proc. of
VSTTE, vol. 6217, 2010.
[71] E. Alkassar, E. Cohen, M. A. Hillebrand, M. Kovalev, and
W. J. Paul, “Verifying shadow page table algorithms,” in Proc.
of FMCAD, 2010.
[72] C. Baumann, H. Blasum, T. Bormer, and S. Tverdyshev,
“Proving memory separation in a microkernel by code level
veriﬁcation,” in Proc. of AMICS, 2011.
444
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:54:03 UTC from IEEE Xplore.  Restrictions apply.