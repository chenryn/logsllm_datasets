such as the implementation of the cryptographic function,
the hardware supporting the program, the accuracy of the
timing measurements, etc.. In 1996, Paul Kocher published
the ﬁrst timing attack on RSA implementation [20]. Boneh
and Brumley demonstrated a practical timing attack against
SSL-enabled network servers in 2003, where they recovered
USENIX Association
30th USENIX Security Symposium    719
a server’s private key based on the RSA execution time differ-
ence [8]. In fact, timing attacks are not only practical against
RSA, but to other crypto algorithms, including ElGamal and
the Digital Signature Algorithm [29].
Architecture side channel attack. Micro-architecture side
channels are side channels that use shared CPU architec-
ture resources to infer a victim program’s behaviors. Most
micro-architecture side channels exploit timing differences to
infer the victim program’s behaviors. Some commonly used
shared resources in micro-architecture side channels include
Branch Target Buffer (BTB), Cache (L1, L2, L3 cache), Trans-
lation Look-aside Buffer (TLB) and the CPU internal load-
/store buffers, etc.. Some representative micro-architecture
side-channel techniques include Flush+Reload attacks [38],
Prime+Probe attack [28], utag attacks [24] and Flush+Flush
attacks [14]. Those existing works show that architecture side
channels can be exploited and used to break conﬁdentiality in
a local or cloud setting.
Constant-time Cryptography. Constant-time cryptography
implementations [7] are widely used in mainstream cryptogra-
phy library to mitigate timing attacks, the design of constant-
time functions is used to reduce or eliminate data-dependent
timing information. Speciﬁcally, Constant-time implementa-
tions are making the execution time independent of the secret
variables, therefore, do not leak any secret information to tim-
ing analysis. To achieve constant execution time, there are
three rules to follow. First, the control-ﬂow paths cannot de-
pend on the secret information. Second, the accessed memory
addresses can not depend on the secret information. Third, the
inputs to variable-time instructions such as division and mod-
ulus cannot depend on the secret information. There are a few
tools developed assessing the constant-time implementations,
including ImperialViolet [21], dudect [30], ct-verif [1].
2.3 Advanced Programmable Interrupt Con-
troller
AMD processors provide an Advanced Programmable Inter-
rupt Controller (APIC) for software to trigger interrupts [2].
Each CPU core is associated with one APIC, and several
interrupt resources are supported, including APIC timer, per-
formance monitor counter, and I/O interrupts. In the APIC
timer mode, a programmable 32-bit APIC-timer counter can
be used by software to generate APIC interrupts. Two modes
(periodic and one-shot mode) are supported. In the one-shot
mode, the counter can be set to a software-deﬁned initial value
and decrease with a clock rate. Once the counter reaches zero,
an APIC interrupt is generated on this CPU core. In the pe-
riod mode, the counter is automatically initialized to the initial
value after reaching zero; an interrupt is generated every time
the counter reaches zero.
The APIC is used in SGX-Step [34] to single-step the
enclave program on Intel SGX [10]. SGX-Step builds a user-
space APIC interrupt handler to intercept every APIC timer
interrupt. Meanwhile, SGX-Step sets a one-shot APIC timer
with a ﬁxed value right before ERESUME. The ﬁxed timer
value is conﬁgured so that an APIC timer interrupt is gener-
ated after a single instruction is executed inside the enclave.
These steps are repeated to a single step every instruction
inside the enclave. SGX-Step can achieve a single-step ratio
of around 98% under a machine-speciﬁc ﬁxed counter value.
However, as far as we know, no research has studied the APIC
timer on the SEV platform to single-step SEV VMs.
3 The CIPHERLEAKS Attack
This section explores the side-channel leakage caused by
SEV’s XEX mode encryption and demonstrates its conse-
quences when applied on the encrypted VMSA page. We
particularly construct two attack primitives: execution state
inference and plaintext recovery.
3.1 The Ciphertext Side Channel
We consider a scenario where the victim VM is a SEV-SNP
protected VM hosted by a malicious hypervisor. We assume
SEV properly protects the integrity of the encrypted VM
memory as well as the VMSA pages. As such, all prior known
attacks against SEV and SEV-ES (such as [15, 22, 23, 26,
27, 35]) are not applicable in our setting. The goal of the
CIPHERLEAKS attack is to steal secrets from the victim VM.
Denial-of-service attacks and speculative execution attacks
are out-of-scope.
3.1.1 Root Cause Analysis
Because SEV’s memory encryption engine uses 128-bit XEX-
mode AES encryption, each 16-byte aligned memory blocks
in the VMSA is independently encrypted with the same
AES key. Since each 16-byte plaintext is ﬁrst XORed with
a physical-address-speciﬁc 16-byte value (a.k.a., the output
of the tweak function) before encryption, the same plaintext
may yield different ciphertext when placed in a different phys-
ical address. However, the same 16-byte plaintext is always
encrypted into the same ciphertext when placed in the same
physical address. Most importantly, SEV (including SEV-ES
and SEV-SNP) does not prevent the hypervisor from read
accessing the ciphertext of the encrypted memory (which is
different from SGX).
This observation forms the foundation of our ciphertext
side channel: By monitoring the changes in the ciphertext of
the victim VM, the adversary is able to infer the changes of
the corresponding plaintext. This ciphertext side channel may
seem innocuous at ﬁrst glance, but when applied to certain
encrypted memory regions, it may be exploited to infer the
execution of the victim VM.
720    30th USENIX Security Symposium
USENIX Association
3.1.2 CIPHERLEAKS: VMSA Inferences
The CIPHERLEAKS attack is a category of attacks that exploit
the ciphertext side channel by making inferences on the ci-
phertext of the VMSA. We ﬁrst explain in more details the
VMSA structure and then outline an overview of attack.
VMSA structure. Before SEV-ES, the register states were di-
rectly saved into VMCB during the VMEXITs without hiding
their states from the hypervisor, which gives the hypervisor
a chance to inspect the internal states of the VM’s execu-
tion or change the control ﬂow of software inside the VM [].
AMD ﬁxes this unencrypted-register-state vulnerability by
encrypting the registers during VMEXITs. In SEV-ES and
SEV-SNP, the register states are encrypted and then saved
into VMSA during VMEXITs. SEV-ES and SEV-SNP add
additional conﬁdentiality and integrity protection of the saved
register values in VMSA.
• Conﬁdentiality. The VMSA is a 4KB page-aligned memory
region speciﬁed by the VMSA pointer in VMCB’s offset
108h [2]. All register states saved in the VMSA are also
encrypted with the VM encryption key Kvek.
• Integrity. To prevent the hypervisor from tampering VMSA,
SEV-ES calculates the hash of the VMSA region before
VMEXITs and stores the measurement into a protected mem-
ory region. Upon VMRUN, the hardware checks the integrity
of the VMSA to prevent any modiﬁcation of the VMSA data.
Instead of performing such integrity checks, SEV-SNP pre-
vents the hypervisor from writing to the guest VM’s memory
(including VMSA pages) via RMP permission checks.
Overview of CIPHERLEAKS. Our CIPHERLEAKS attack ex-
ploits the ciphertext side channel on the encrypted VMSA
during VMEXITs. During an AE VMEXIT, all guest register
values are stored in the VMSA, which is an encrypted memory
page [2]. The encryption of the VMSA page also follows the
same rule as other encrypted memory pages. Moreover, as the
physical address of the VMSA page is chosen by the hyper-
visor and remains the same during the guest VM’s life cycle,
the hypervisor can monitor speciﬁc offsets of the VMSA to
infer changes of any 16-byte plaintext. Some saved registers
and their offset in the VMSA are listed in Table 1.
Some 16-byte memory blocks store two 8-byte register val-
ues. For instance, CR3 and CR0 are stored at offset 0x150. If
either of the two registers changes its value, the corresponding
ciphertext will change. Because CR0 does not change very
frequently, in most cases, the ciphertext of this block differs
because the CR3 value changes, which can infer a context
switch has taken place inside the victim VM. Thus, the cipher-
text pair of (CR0, CR3) can be used as identiﬁers of processes
inside the victim VM. For other cases, like the (RBX, RDX)
and (R10, R11) pairs, as both registers are subject to frequent
changes, it is only possible to learn that the value of one (or
both) of the two registers has changed. The adversary may
learn which register has changed if she knows the executed
Table 1: Ciphertext of registers collected in the VMSA. If the
content at a speciﬁc offset is 8 bytes, it means the remaining
8 bytes are reserved.
Offset
150h
170h
1D8h
1F8h
240h
308h
310h
320h
330h
340h
350h
360h
370h
Size
16 bytes
16 bytes
8 bytes
8 bytes
8 bytes
8 bytes
16 bytes
8 bytes
16 bytes
16 bytes
16 bytes
16 bytes
16 bytes
Content
CR3 & CR0
RFLAGS & RIP
RSP
RAX
CR2
RCX
RBP
RDX & RBX
RSI & RDI
R8 & R9
R10 & R11
R12 & R13
R14 & R15
binary code between the two VMEXITs.
Some 16-byte memory blocks only store values for a single
8-byte register (e.g., RAX and RCX), and the remaining 8
bytes are reserved. Reserved ﬁelds are all 0s, so they never
change. Therefore, from Table 1, we can see that it is possible
to construct one-to-one mappings from the ciphertext to the
plaintext for the values of RAX, RCX, RSP, RBP, and CR2.
3.2 Execution State Inference
We next describe two attack primitives of CIPHERLEAKS, one
in Section 3.2 and the other in Section 3.3.1. First, we show
the use of the ciphertext side channel to infer the execution
states of processes inside the guest VM, which helps locate the
physical address of targeted functions and infer the executing
function of a process.
3.2.1 Attack Primitives
To infer the execution states of the encrypted VM, one could
follow the steps below:
•  At time t0, the hypervisor clears the present bits (P bits)
of all memory pages in the victim VM’s NPT. The next
memory access from the victim VM will trigger a VMEXIT
caused by a nested page fault (NPF).
•  During VMEXITs, the hypervisor reads and records the
ciphertext blocks in the victim VM’s VMSA, as well as
the timestamp and VMEXIT’s EXITCODE. Before VM-
RUN, The hypervisor needs to reset the P bit of the faulting
page so that the victim VM may continue execution. How-
ever, she may choose to clear the P bit again later to trigger
more VMEXITs. This step is similar to controlled channel
attacks [32, 37].
•  The hypervisor collects a sequence of ciphertext blocks
and timestamps. By comparing the ciphertext of the CR3 and
CR0 ﬁelds, the hypervisor may associate each observation
to a particular process in the victim VM. Therefore, changes
USENIX Association
30th USENIX Security Symposium    721
Table 2: Information revealed from NPF error code.
Bit
Bit 0 (P)
Bit 1 (RW)
Bit 2 (US)
Bit 3 (RSV)
Bit 4 (ID)
Bit 6 (SS)
Bit 32
Bit 33
Bit 37
Description
Cleared to 0 if the nested page was non-present.
Set to 1 if it was a write access.
Set to 1 if it was a user access.
Set to 1 if reserved bits were set.
Set to 1 if it was a code fetch.
Set to 1 if it was a shadow stack access.
Set to 1 if it was a ﬁnal physical address.
Set to 1 if it was a page table.
Set to 1 if it was a supervisor shadow stack page.
in the ciphertext blocks belonging to the same process can
be collected to infer its execution states.
The NPF’s error code passed to the hypervisor via VMCB’s
EXITINFO2 ﬁeld reveals valuable information for the side-
channel analysis. For example, as shown in Figure 1b, error
code 0x100000014 always means the NPF is caused by an
instruction fetch. The NPF error code is speciﬁed in Table 2.
The ciphertext itself is meaningless, but the fact that it
changes matters. We use a vector whose size is the same as
the number of registers we monitor to represent value changes
in the ciphertext. A value +1 in the vector indicates that
the corresponding register has changed since the last NPF.
Therefore, a sequence of such vectors can be collected.
With the information described above, the hypervisor is
able to proﬁle the applications through a training process.
3.2.2 Examples
One example of such attack primitives is locating the physical
address of targeted functions in the victim. Next, we illustrate
such attacks using the example shown in Figure 1. We target
at two callq instructions ( and  ) in the caller function.
We assume the hypervisor has some pre-knowledge of the
application code running in the guest VM and the hypervisor
begins to monitor the application, by clearing the P bits, before
the two call instructions (e.g., before ). In handling each
NPFs, the hypervisor collects the ciphertext of those saved
registers listed in Table 1 as well as the NPF’s error code.
The hypervisor then collects a sequence of ciphertext
blocks as shown in Figure 1b. The callq instruction at 
touches a new instruction page that contains the code of
sum(). Therefore it triggers an NPF. Compared to the pre-
vious snapshot, the changes of the ciphertext of RIP, RSP,
RBP, and RDI are observed; the ciphertext of CR3 and RAX
remains unchanged. When sum() returns, the return value is
stored in RAX. The ciphertext changes of the RAX register
will be observed in the next NPF (at  ), where RIP will also
change. In this way, the hypervisor can locate the physical
address of the functions and trace the control ﬂow of the
target application. In particular, NPF1 reveals the physical
address of function sum(), NPF2 reveals the physical address
of expand().
(a) C source code with assembly code.
(b) Ciphertext blocks.
Figure 1: Example about the ciphertext changes in NPFs.