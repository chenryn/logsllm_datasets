title:Efficient RAM and control flow in verifiable outsourced computation
author:Riad S. Wahby and
Srinath T. V. Setty and
Zuocheng Ren and
Andrew J. Blumberg and
Michael Walfish
Efficient RAM and Control Flow in Verifiable Outsourced Computation
Riad S. Wahby⋆, Srinath Setty†, Zuocheng Ren†, Andrew J. Blumberg†, and Michael Walfish⋆
⋆New York University
{rsw,mwalfish}@cs.nyu.edu
†The University of Texas at Austin
{srinath@cs,ren@cs,blumberg@math}.utexas.edu
Abstract—Recent work on proof-based verifiable computa-
tion has resulted in built systems that employ tools from
complexity theory and cryptography to address a basic
problem in systems security: allowing a local computer to
outsource the execution of a program while providing the
local computer with a guarantee of integrity and the re-
mote computer with a guarantee of privacy. However, sup-
port for programs that use RAM and control flow has been
problematic. State of the art systems either restrict the use
of these constructs (e.g., requiring static loop bounds), in-
cur sizeable overhead on every step, or pay tremendous
costs when the constructs are invoked.
This paper describes Buffet, a built system that solves
these problems by providing inexpensive “a la carte” RAM
and dynamic control flow. Buffet composes an elegant
prior approach to RAM with a novel adaptation of tech-
niques from the compilers literature. Buffet allows the pro-
grammer to express programs in an expansive subset of C
(disallowing only “goto” and function pointers), can han-
dle essentially any example in the verifiable computation
literature, and achieves the best performance in the area
by multiple orders of magnitude.
1 Introduction
How can a client outsource a computation to a server and then
check that the server executed correctly?1 And can this be
done in a way that allows the server to supply private inputs
and keep them confidential? Variants of this problem have
been around for decades [10]; today, cloud computing is a
particularly pertinent use case. Indeed, because cloud providers
are large-scale, we cannot assume that execution is always
correct; because they are opaque, we cannot assume that the
causes of incorrect execution (corruption of data, hardware
faults, malice, and more) are readily detectable. And many
common cloud applications involve private server input that
must remain confidential (e.g., database interactions).
Classical solutions to this problem depend on potentially
undesirable assumptions or restrictions. For example, replica-
tion [29, 30, 56] assumes that replica failures are not correlated
(which does not hold in homogeneous cloud platforms). Au-
diting [47, 60] assumes that failures follow a most-or-none
distribution. Trusted hardware and attestation [63, 67, 68] as-
sumes that the hardware is not faulty (and sometimes requires
1Checking that a given program is expressed correctly is program verification,
which is a different but complementary problem.
Permission to freely reproduce all or part of this paper for noncommercial purposes is
granted provided that copies bear this notice and the full citation on the first page. Repro-
duction for commercial purposes is strictly prohibited without the prior written consent
of the Internet Society, the first-named author (for reproduction of an entire paper only),
and the author’s employer if the paper was prepared within the scope of employment.
NDSS ’15, 8–11 February 2015, San Diego , CA, USA
Copyright 2015 Internet Society, ISBN 1-891562-38-X
http://dx.doi.org/10.14722/ndss.2015.23097
a global root of trust). Tailored solutions exist (see [62, 71, 76]
for surveys) but only for restricted classes of computations.
Over the last few years, a new solution has emerged, called
proof-based verifiable computation [78], that gives comprehen-
sive guarantees, makes few or no assumptions about the server,
and applies generally [16, 19, 28, 33, 37, 40, 52, 62, 69–74, 76].
Although the details differ, all of these works are based on so-
phisticated cryptographic and complexity-theoretic machinery:
probabilistically checkable proofs (PCPs) [7, 8], efficient argu-
ments [21, 22, 26, 40, 41, 46, 49] (including zero-knowledge
variants), interactive proofs [9, 44, 45, 54], etc. To be clear, it
had long been known that this machinery was relevant to veri-
fying outsourced computations [10]; the work of proof-based
verifiable computation has been refining the theory and building
systems around it.
Indeed, publications in this area have showcased dramatic
performance and usability improvements relative to naive im-
plementations of the theory: factors-of-a-trillion speedups; com-
pilers; and sophisticated implementations on smart phones, on
GPUs, and across distributed servers. As a notable example, re-
cent work [37], building on [40, 62], compiles zero-knowledge
applications (that preserve the confidentiality of the server’s
private inputs) into a form that is practical for real use.
All of this work has taken place in the context of built sys-
tems that have two major components: a front-end translates
programs into the formalism required by a cryptographic and
complexity-theoretic back-end. In more detail, the front-end
translates a computation that is expressed in a high-level lan-
guage into a system of equations, or set of constraints; a so-
lution to these constraints corresponds to a valid execution of
the computation. The back-end is a probabilistic proof pro-
tocol [43] (particularly an interactive argument [46, 49] or a
non-interactive argument [21, 23, 40, 62]) by which the server
(or prover) convinces the client (or verifier) that it holds a
solution to the constraints.
The guiding intuition for the area is that the theoretical ad-
vantages of the back-end proof protocol should result in pow-
erful systems: the prover can keep its solution private (when
using zero-knowledge variants), and the verifier handles only
a short certificate, the checks of which are in principle very
efficient. However, there is overhead from the front-end, the
back-end, and their interaction. This overhead manifests most
prominently in setup costs incurred by the verifier and the costs
paid by both verifier and prover for each input-output instance
that the verifier wishes to check.
After a great deal of work, there is now a single approach to
the back-end: in all of the recent systems [16, 19, 28, 37, 52,
62, 70], the core probabilistically checkable encoding is the
remarkable construction of GGPR [40] (or is based on it [52]).
This encoding has slashed prover costs and verifier setup costs—
though neither cost is low by usual systems standards. Further-
more, there has been a real victory: the verifier’s per-instance
costs are genuinely inexpensive. In fact, under certain usage
models [14, 28, 34], the verifier’s total costs (amortized setup
plus incremental) can be considered practical.
The front-end has also been a locus of activity, but the situa-
tion there is far less clear. Currently, there is a tradeoff between
programmability and costs [19, §5.4; 78, Fig. 2], specifically the
verifier’s setup and the prover’s costs. These costs are driven by
the number of constraints required to represent a computation.
The tradeoff is clear from the two major front-end approaches.
One approach is BCTV [19], which is currently the state
of the art in an elegant line of work [15, 16]. Here, the con-
straints represent the unrolled execution of a general-purpose
MIPS-like CPU, called TinyRAM [17]; one of the inputs to
the constraints is a program expressed in this CPU’s assembly
language. In BCTV, the representation of RAM operations uses
a clever technique [15] based on permutation networks (§2.3).
A principal advantage of BCTV is that the programmer can
use standard C (to produce the assembly program); this is
the best programmability in the verifiable computation litera-
ture. Furthermore, BCTV allows the verifier’s setup work to
be reused across different computations. The principal disad-
vantage is cost. For a computation that takes t program steps,
the constraints include t copies of the simulated CPU’s fetch-
decode-execute loop; that is, every program step incurs the cost
(in number of constraints) of the CPU’s fetch-decode-execute
logic. On top of that, each of those t steps brings additional
constraints to verify RAM operations.
The other front-end approach is to require the programmer
to write in a subset of C that is carefully restricted to allow
a line-by-line translation from the program to constraints; for
each line of code, the resulting constraints contain designated
logic to verify that line. The state of the art here is embodied in
Pantry [28], which builds on, and includes the functionality of,
its predecessors: Pinocchio [62] and Zaatar [70].2 Often, the
representation that arises is very concise; for example, adding
two variables costs only one constraint. An important exception
is RAM: each load or store results in multiple invocations of a
cryptographic hash function, each of which is translated into
constraints. Although this technique is far less expensive (for all
but the smallest memories) than prior RAM representations [62,
70, 72], the technique is still costly in absolute terms.
Pantry’s advantages are roughly the inverse of BCTV’s. De-
pending on the computation, Pantry can handle executions of
comparatively long lengths. Also, it pays for RAM operations
only when they are used. On the other hand, the price of those
RAM operations, in number of constraints, is very high—far
higher than BCTV’s per-operation cost [19, §5; 28, §8.1]. Fur-
thermore, the subset of C that is exposed to the programmer
lacks key constructs, most notably data dependent control flow.
2There is recent work at the forefront of performance that handles set operations
efficiently [52], using the same line-by-line compilation approach. There is
also a cousin of this approach represented by a different line of work [33, 73,
74, 76]. But these works are targeted to particular classes of computations so
fall outside of our focus. (See Section 6.)
2
This analogy is inexact, but if a Pantry constraint representa-
tion is like an ASIC, then BCTV is like a CPU that is controlled
with software. Unfortunately, in the context of verifiable com-
putation, both the cost of BCTV’s generality and the restriction
on Pantry’s programmability present severe obstacles to prac-
ticality. This state of affairs raises a natural question: Can we
achieve excellent programmability (that is, present the program-
mer with a language that is very close to standard C) together
with an efficient translation into constraints? To that end, this
paper makes the following contributions:
1. We design and build a new system, called Buffet, that an-
swers the above question in the affirmative. Buffet incorpo-
rates the following technical innovations:
• Buffet composes BCTV’s RAM abstraction with the line-
by-line compilation approach of Pantry, resulting in a
Pantry-BCTV hybrid approach to RAM (§3).
• Buffet achieves nearly the expressiveness of BCTV with-
out an underlying CPU abstraction, by adapting loop flat-
tening techniques from the compilers literature (§4). Buf-
fet supports all of C except goto and function pointers.
2. We develop a conceptual framework for understanding
Pantry and BCTV as points on the same design spectrum,
thereby providing a unified description of the state of the art
verifiable computation approaches (§3.3, §4.3). The result-
ing perspective directly enabled the design of Buffet.
3. We carry out a three-way performance comparison, based
on implementations of Buffet, BCTV, and Pantry (§5). Be-
sides experimentally evaluating Buffet, this study carefully
compares Pantry and BCTV, which is the first detailed com-
parison of these approaches.
The result is the best of both worlds: Buffet has the best
performance in the literature (orders of magnitude better than
BCTV and Pantry) and supports almost all of standard C.
There are some disadvantages to Buffet, compared to BCTV.
Buffet has worse amortization behavior in terms of what com-
putations the setup cost can be reused over. Moreover, Buffet
does not provide a machine abstraction, which could hinder
higher-level programmability. However, as discussed in Sec-
tion 7, we believe that both issues are more pronounced in
principle than they will be in practice.
The most significant limitation of Buffet is one that is en-
demic to this research area: in every system released so far,
the prover overhead and setup costs are still too high to be
considered truly practical. Nevertheless, we regard Buffet as
substantial progress: we believe that it is close to optimal, at
least until the next breakthrough on the back-end occurs.
2 Background
This section presents the general
framework in which
Pantry [28] and BCTV [16, 19] operate, and then gives de-
tails on each of them. Parts of this description are influenced by
prior work [19, 62, 70, 76, 78]; most notably, there are textual
debts to Pantry [28]. Our description is tailored to the problem
of verifying outsourced deterministic computations [39, 44].
However, Buffet itself and many of the prior systems (includ-
ing BCTV, Pantry, and Pinocchio [62]) handle a more general
problem—a zero-knowledge proof of knowledge [21, 40]—in
which the prover can supply inputs to the computation and
keep them private (for example, a private database for which
the verifier knows a digest [19, 28, 62]).
2.1 Overview and framework
Existing systems (BCTV, Pantry, etc.) enable the following. A
client, or verifier V, sends a program Ψ, expressed in a high-
level language, to a server, or prover P. V sends input x to P and
receives output y, which is supposed to be Ψ(x). V also receives
a short certificate that it can efficiently and probabilistically
check to determine whether y is in fact Ψ(x). There are no
assumptions about whether and how P malfunctions, though
there is an assumed computational bound on P. The guarantees
are probabilistic, over V’s random choices. They are as follows.
End-to-end Completeness: If y = Ψ(x), then a correct P makes
V accept y with probability 1. End-to-end Soundness: If y ̸=
Ψ(x), then V’s checks pass with less than ϵ probability, where
ϵ is very small. The existing systems work in three steps:
1. Compile, produce constraints. V and P compile the pro-
gram into a system of equations over a set of variables,
including x and y. The equations have a solution if and only
if y = Ψ(x).
2. Solve. P identifies a solution.
3. Argue. P convinces V that it has indeed identified a solution,
which establishes for V that y = Ψ(x).
This paper’s focus is the front-end (steps 1 and 2); the Pantry
and BCTV instantiations of this component are described in
Sections 2.2 and 2.3, respectively.
As a consequence of this focus, we fix a common back-end
(step 3) for all systems under investigation. We can standard-
ize this way because Buffet, Pantry, and BCTV (and many
prior systems for verifiable computation) are modular: their
front-ends can work with each other’s back-ends. Our com-
mon back-end is the Pinocchio protocol [62] (as implemented
and optimized by libsnark [3]).3 Pinocchio is a descendant of
GGPR [40],which we summarize below; details and formal
definitions appear elsewhere [19, 23, 40, 62, 70].
For our purposes, GGPR is a zero-knowledge SNARK (Suc-
cinct Non-interactive Argument of Knowledge) with prepro-
cessing [21, 40], which is to say that it is a protocol with the
following structure and properties. There are two parties, a veri-
fier and prover; the input to the protocol is a set of equations (or
constraints)4 C, to which the prover purportedly holds a solu-
tion (or satisfying assignment), z. In the verifiable computation
context, the constraints and solution are generated by steps 1
and 2 above. In a separate setup phase, the verifier, or some
entity that the verifier trusts, follows a randomized algorithm to
3An alternative is Zaatar’s back-end [70], which we have tested and run with
our Pantry, BCTV, and Buffet front-end implementations. This back-end [46,
71, 72] includes a linear PCP constructed from GGPR’s QAP formalism [40].