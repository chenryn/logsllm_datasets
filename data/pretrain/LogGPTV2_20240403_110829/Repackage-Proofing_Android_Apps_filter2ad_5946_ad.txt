We then evaluated the effectiveness of SSN. We want to
understand: (1) whether or not SSN can prevent the repackaged
apps from running successfully on user devices, and (2) the
percentage of the repackaged apps that are deterred from
working properly.
For each app, we ﬁrst utilized SSN to build a repackage-
prooﬁng protection, and signed it using the original certiﬁcate
to generate the apk ﬁle. These apk ﬁles are the protected apps.
Next, we used Apktool [2] to repackage these protected apps
and resigned it using a new certiﬁcate. After that, we obtained
a set of repackaged apps. We installed these repackaged apps
on our Nexus emulator, and tested each of them.
The results show that all of the repackaged apps could
not run successfully on the device. Some repackaged apps
crashed once they were launched, while some others could
be launched but incurred various malfunctions and worked
abnormally. Therefore, SSN successfully deterred all of the
repackaged apps from working properly. We also evaluated the
impact of the injected protection code on the functionality of
the protected apps, which is presented in Section VII-E.
D. Resiliency
To analyze an app,
1) Resiliency to Static Analysis: Attackers may statically
analyze the protected app to identify the detection nodes and
response nodes. Note that our assumption is that attackers can
only get the apk ﬁles, but cannot obtain the source code, which
is reasonable in practice. Moreover, we also assume that the
end users are legitimate ones and will not modify the apk ﬁles.
the attacker has to ﬁrst utilize a
disassembler (e.g., apktool, baksmali) to disassemble the apk
ﬁle and generate the smali ﬁles containing Dalvik bytecode.
In the following, we assume that he has obtained the smail
ﬁles. Then the attacker may statically scan the smail ﬁles for
some essential functions (e.g., getPublicKey, getCertiﬁcate, etc.).
However, because we use string manipulation and Reﬂection to
hide the signatures of these functions, it prevents the attacker
from ﬁnding them. The attacker may also scan the smali ﬁles for
similar code segments if he has identiﬁed one node. However,
because the constructed nodes are distinct and are applied on
code obfuscation, the resulted nodes are difﬁcult to be identiﬁed
on the basis of another one. One more sophisticated attack is
to adopt taint analysis to taint the communication mediums or
packages.xml, so that whenever they are accessed, the location
(a) Main interface
(b) Puzzle interface
Fig. 4. Examples of OpenSudoku when it works normally.
(a) Main interface 1
(b) Main interface 2
(c) Main interface 3
(d) Puzzle interface
Fig. 5. Examples of OpenSudoku when malfunctions occur.
of the nodes could be identiﬁed. The related evaluation results
are presented in Section VII-D3.
2) Resiliency to Dynamic Analysis: An alternative attack
is to dynamically execute and monitor the app to identify the
injected nodes. To identify the detection nodes, one option
is to combine debugging tools and automated test
input
generators to execute the app and observe its behaviour, and
then pause the app to start debugging once a failure is noticed.
A more advanced way is to hook some essential functions (e.g.,
getPublicKey) to learn when the hooked functions are activated
so as to identify the code regions for the detection nodes. We
conducted three user studies in the following. Attackers may
also adopt dynamic taint analysis to taint the communication
mediums or packages.xml. We present the related evaluation
results in Section VII-D3.
We now consider how attackers identify the response nodes.
Utilizing taint analysis is one option. Another option is to ﬁnd
the failure points, and then trace back to the response nodes.
However, because our stealthy-modiﬁcation mechanism causes
the delayed logical malfunctions which leave little noticeable
trace behind, it is very difﬁcult to identify the failure points,
let along to trace back to the response nodes.
Examples of stochastic logical malfunctions. Fig. 4 and
Fig. 5 show the screenshots of OpenSudoku when it works
normally and abnormally, respectively. From Fig. 5, we can
see that when OpenSudoku is repackaged, it only incurs
logical malfunctions; speciﬁcally, Fig. 5(a), (b) and (c) show
the screenshots when OpenSudoku is subjected to stochastic
responses; different malfunctions are incurred at different times.
Besides these, there are some other stochastic malfunctions. For
instance, when an attacker selects a puzzle, a different one may
557
TABLE II.
SURVIVING PROTECTION NODES OF EACH APP.
% of
Total # of Total # of
% of
App
LOC Det. nodes Res. nodes Surviving
CatLog
5667
PhotoGallery 2011
OpenSudoku 6079
CEToolbox
2422
378
137
404
168
231
90
253
194
Surviving
Det. nodes Res. nodes
82.3%
78.9%
81.4%
75.0%
89.6%
76.3%
80.1%
82.9%
be presented at a different time; or when an attacker selects a
cell in the puzzle interface and types a number into the cell,
a different number may be typed into an arbitrary cell at a
different time. These stochastic malfunctions greatly frustrate
attackers and maximize the workload. Other apps suffered from
similar or different kinds of stochastic malfunctions. Due to
limited space, we do not present them here.
Case studies. We now seek to understand how quickly
an attacker can identify a node, and how many nodes can be
identiﬁed in a given time, based on simple dynamic analysis.
In principle, it depends on many factors (e.g., the attacker’s
skill, the complexity of an app, the automated tools available,
etc.) and cannot be easily quantiﬁed.
We conducted three case studies. For each app, we generated
its protected apk by SSN. To begin, we asked three human
players to play these apks to conﬁrm that the functionalities
of these apps were still held. Then we provided these apks to
another three human testers who did not know our certiﬁcate
but know SSN’s techniques, to analyze the apks separately
for twenty-four hours and try to break the repackage-prooﬁng
protection built into the apps. The three human testers have
three, two, and one years of Android development experiences,
respectively. They are skilled in the debugging tools such
as DDMS [17] and test input generators such as Monkey,
Randoop [44], Robotium [46] and Brahmastra [4]. After
twenty-four hours, they repackaged these apps using their
own certiﬁcate (a new one) to generate the repackaged apps.
Finally, we asked the previous three human player once again
to play these repackaged apps for one hour; if the app works
properly for one hour, we consider it has been successfully
repackaged. Note that we do not require every nodes have to
be disabled/removed to achieve successful repackaging. Instead,
we claim that an app is successfully repackaged as long as it
can work properly for one hour.
Table II shows the results of four sample apps, CatLog,
PhotoGallery, OpenSudoku, and CEToolbox, from the category
of Development, Multimedia, Game, and Science&Education,
respectively. Other apps have shown similar results and are not
included here. In Table II, the percentage of surviving nodes is
the average percentage among the three human testers. We can
see that even after twenty-four hours, almost four-ﬁfths of the
detection and response nodes are still not being identiﬁed.
Moreover, none of the apps was successfully repackaged
reported by the three players.
We then asked the three testers for their experience. They
indicated that at ﬁrst they tried to statically scan the apps
but few useful information was obtained. They then had to
dynamically execute the apps to observe their behaviour with
the help of the debugging tools and test input generators; but
unfortunately, they encountered different malfunctions each
time. Moreover, the malfunctions caused the apps to work
abnormally and they did not know where the malfunctions
started. Thus they had to inspect the bytecode carefully using
the debugging tools and try to understand the work ﬂow of the
apps which cost them a lot of time. When they had identiﬁed
558
a detection node or response node, they tried to ﬁgure out the
ﬁnal variable that was used as the communication medium.
They then adopted the taint analysis tools (e.g., TaintDroid [19])
to taint it and hoped to ﬁnd the detection and response nodes
easily; however, this did not work. Next, they set a watch
window in the debugging tool to watch this variable at runtime
to detect its modiﬁcation; however, because the ﬁnal variable
was declared in the R class which was out of the scope chain for
debugging, the watch window did not work. Therefore, they had
to set multiple conditional exceptions in the code which would
suspend the execution once the ﬁnal variable was modiﬁed, and
then gradually shorten the searching range. The entire process
was very laborious, error-prone and time-consuming.
During their analysis, we also recorded the number of the
identiﬁed nodes for every two hours. We found that the numbers
were decreased during the twenty-four hours, indicating that
the difﬁculty in detecting nodes was increasing. It is intuitive
as the more nodes existed, the easier for triggering one, causing
more nodes being executed in a certain time, and vise verse.
Thus, we infer that less nodes would be detected after the
twenty-four hours analysis.
Advanced dynamic analysis attacks. Attackers may per-
form more advanced dynamic analysis attacks. For instance,
they may utilize ptrace to control the execution of a process,
but to carry out it requires sufﬁcient knowledge of low-level
programming. Moreover, the rationale is that only one process
can attach to a target process at the same time. To prevent
attackers using ptrace, we can let the app attaches to itself at
runtime; this way, ptrace cannot attach to it [56], [52]. Attackers
may leverage existing binary instrumentation tools such as
Adbi [1] and DECAF [25] to monitor some essential functions
(e.g., getPublicKey), and use automated test input generators
such as Monkey and Brahmastra to automatically execute the
app, so that when these functions are activated, the locations of
the corresponding nodes can be logged. However, some patches
on these tools are needed to achieve this goal; in addition, most
automated test input generators can only cover partial execution
paths of an app [39], [45], [51]. Thus, the attacker still needs to
analyze many traces and inspect the code manually to uncover
the other nodes.
3) Resiliency to Taint Analysis: Attackers can also adopt
taint analysis to taint the communication mediums or pack-
ages.xml, to discover the injected nodes.
Communication mediums. To apply taint analysis, the
attacker must identify the ﬁnal variables used as the communica-
tion mediums. We assume he ﬁnds one through some ways. For
static taint analysis, since we adopt string manipulation on the
ﬁnal variable’s name at runtime and transform that to Reﬂection
for accessing the variable, it is difﬁcult to detect the data ﬂow
between the sources and sinks (the places where the source
is accessed), given the string is unknown statically. Moreover,
static taint propagation usually makes the program end up
with many false tainted values, and leads to high computation
overheads and large memory consumptions. Thus, static taint
analysis is impractical to counterattack our technique.
With respect to dynamic taint analysis, we utilized Taint-
Droid [19] and DECAF [25]. TaintDroid is a dynamic taint
tracking and analysis system capable of tracking sensitive
data. DECAF is a dynamic binary analysis platform based on
QEMU. Assume the communication medium is a ﬁnal variable
str. For TaintDroid, we ﬁrst added Taint.addTaintString(str,
Taint.TAINT_MIC) at the beginning of the create method in the
main activity so that once the app started, str would be tainted.
Then we inserted the log statements after each detection and
response node to check whether or not TaintDroid could detect
str was accessed. Next we employed Monkey to execute the
app for one hour, and checked the log; however, nothing was
logged. The reason is that the communication medium is a
resource in the R class and is accessed by Reﬂection based
on strings of its name after manipulated. Similar results were
obtained from DECAF.
The packages.xml ﬁle. Attackers may attempt to taint
packages.xml which contains the public key to reveal the
detection nodes. As we use PackageManager to extract the
public key, the ﬁle name is not explicitly stated in the detection
nodes (see the code snippet in Section III-A2). Thus, static
taint analysis is ineffectual under such circumstances.
For dynamic analysis by TaintDroid, we ﬁrst added
Taint.addTaintFile(intFd, Taint.TAINT_MIC) at the beginning
of the create method in the main activity, where intFd is
a ﬁle descriptor of packages.xml, and then checked whether
TaintDroid could identify intFd was accessed. However,
TaintDroid failed to do so. The reason is that instead of
directly reading the public key from packages.xml, we adopt
PackageManager. The public key is extracted by getPublicKey
from sun.security.x509.X509CertImpl in JDK that TaintDroid
does not taint track.
In this evaluation, we used two state-of-the-art taint analysis
tools. However, a better taint analysis may successfully taint
both the communication mediums and packages.xml, which we
recognize is possible theoretically. However, it still requires
attackers to inspect the code manually to pinpoint the protection
nodes and disable/remove them. As the nodes are obfuscated
and woven into the surrounding code without identiﬁable
boundaries,
increases the investment cost for attackers.
Furthermore, because multiple nodes are injected in terms
of the execution paths, attackers have to iterate this attack as
many times to visit sufﬁcient execution paths for insuring the
safety of republishing the app. The cost may be high and no
longer be attractive for attackers.
it
E. Side Effects
We further evaluated the side effects of SSN on the apps,
from the following two aspects: the impact on the functionality,
and the impact on the runtime overhead.
1) Impact on the Functionality: The normal operations of
an app should remain intact after protected. To evaluate it, we
utilized SSN to build repackage-prooﬁng protection into each
app, to generate the protected app. We then asked three human
players to play these protected apps for two hours to check
whether they could run successfully. All they reported were
positive results. Therefore, the protection code injected by SSN
has no impact on the functionalities of the apps.
2) Impact on the Runtime Overhead: The application
runtime overhead introduced by SSN comes from two major
types of computations: (1) the reading public key certiﬁcate
procedure by PackageManager, and (2) the Reﬂection operation
modifying the value of a ﬁnal variable. To evaluate the runtime
overhead, we utilized Monkey to generate a sequence of 10,000
user events, and fed the same user events to both the apps
with and without the protection code embedded three times
to measure the average running time. We denote the average
running time of the original app and the protected app as
To and Tp, respectively; the runtime overhead is calculated
by (Tp − To)/To. Table III shows the runtime overhead with
respect to the four apps. Results with other apps are similar
and are not included here due to the space limitation.
App
CatLog
TABLE III.
RUNTIME OVERHEAD.
To
(sec)
185
PhotoGallery 108
OpenSudoku
209
CEToolbox
141
From Table III, we
can see that the runtime
overhead has a pos-
itive correlation with
the number of the de-
tection and response
nodes injected (how-
ever, CatLog is an exception). For example, the amount of
the detection and response nodes injected into PhotoGallery is