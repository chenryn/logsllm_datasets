title:Detecting, validating and characterizing computer infections in the
wild
author:Elias Raftopoulos and
Xenofontas A. Dimitropoulos
Detecting, Validating and Characterizing
Computer Infections in the Wild
Elias Raftopoulos
ETH Zurich
Zurich, Switzerland
PI:EMAIL
Xenofontas Dimitropoulos
ETH Zurich
Zurich, Switzerland
PI:EMAIL
ABSTRACT
Although network intrusion detection systems (IDSs) have
been studied for several years, their operators are still over-
whelmed by a large number of false-positive alerts. In this
work we study the following problem: from a large archive of
intrusion alerts collected in a production network, we want
to detect with a small number of false positives hosts within
the network that have been infected by malware. Solving
this problem is essential not only for reducing the false-
positive rate of IDSs, but also for labeling traces collected
in the wild with information about validated security inci-
dents. We use a 9-month long dataset of IDS alerts and
we ﬁrst build a novel heuristic to detect infected hosts from
the on average 3 million alerts we observe per day. Our
heuristic uses a statistical measure to ﬁnd hosts that exhibit
a repeated multi-stage malicious footprint involving speciﬁc
classes of alerts. A signiﬁcant part of our work is devoted
to the validation of our heuristic. We conduct a complex
experiment to assess the security of suspected infected sys-
tems in a production environment using data from several
independent sources, including intrusion alerts, blacklists,
host scanning logs, vulnerability reports, and search engine
queries. We ﬁnd that the false positive rate of our heuris-
tic is 15% and analyze in-depth the root causes of the false
positives. Having validated our heuristic, we apply it to our
entire trace, and characterize various important properties of
9 thousand infected hosts in total. For example, we ﬁnd that
among the infected hosts, a small number of heavy hitters
originate most outbound attacks and that future infections
are more likely to occur close to already infected hosts.
Categories and Subject Descriptors
C.2.0 [Computer-Communication Networks]: [General
Security and Protection]; C.2.3 [Network Operations]:
[Network Monitoring]
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
IMC’11, November 2–4, 2011, Berlin, Germany.
Copyright 2011 ACM 978-1-4503-1013-0/11/11 ...$10.00.
General Terms
Measurement, Security, Veriﬁcation
Keywords
Network Security, Intrusion Detection, Alert Correlation,
Malware, Snort, J-Measure
1.
INTRODUCTION
Evaluating and improving network defenses necessitates
the use of realistic traces, like IDS alerts, from production
networks labeled with information about validated security
incidents. Although this is a well-known and long-held prob-
lem, presently the community is largely lacking both real-
world security data and systematic techniques for evaluating
network defenses. Given a database of IDS alerts, it is crit-
ical to ﬁnd and validate security incidents in order to build
benchmarks for evaluating network defenses. Motivated by
this problem, in this work we introduce a heuristic to detect
and propose an approach to validate active infections in our
infrastructure. An infection is simply a client or a server
with malicious software, which, in our context, leaves a net-
work trace detectable by an IDS sensor. For example, the
malware could be a trojan, worm, spyware, backdoor, etc.
The second problem that motivates our work is IDS false-
positive reduction in the context of extrusion detection. Mod-
ern malware increasingly involve the user in their propaga-
tion by leveraging various social engineering techniques that
bypass intrusion prevention measures. For this reason, se-
curity administrators need tools for detecting hosts within
their network, i.e., extrusion detection, that are already in-
fected by malware. Detecting extrusions from IDS alerts
bears the challenge of reducing the large number of false
positives IDSs are known to generate, e.g., ﬁgures of 99%
false positives have been reported in the literature [33].
Our ﬁrst contribution is a heuristic for ﬁnding infected
hosts from IDS alerts. Our heuristic uses an information
theoretic measure, called J-Measure, to identify statistically
signiﬁcant temporal associations between a selected pool of
alerts. In this manner, it ﬁnds hosts that exhibit a recurring
multi-stage alert trace. To validate that hosts with this foot-
print are indeed infected, we conduct a complex experiment:
over a period of approximately one month we remotely as-
sess a number of live suspected infections on unmanaged
hosts within a production environment. Using six inde-
pendent security-related information sources, namely IDS
alerts, blacklists, threat reports, host scanning logs, vulner-
ability reports and search engine queries, we conclude that
29our heuristic reduces the amount of false positives to ap-
proximately 15%. In addition, we analyze the root causes of
the false positives and draw insights for ﬁltering them out.
Then, we apply our heuristic to 832 million alerts collected
over a period of 9 months and identify 12,915 diﬀerent in-
fections on 9,163 out of the of the 91,512 distinct hosts that
generated IDS alerts. We characterize the extracted infec-
tions and make a number of important observations:
• Out of a total of 91 thousand distinct active hosts we
observed during the 9-month period, approximately
9% exhibited signs of infections at least once during
their lifetime.
• The probability of infection for a server and a client
during a speciﬁc day is 0.18% and 0.37%, respectively.
• Infections drastically increase the attractiveness of in-
fected hosts to further inbound attacks.
• A small percentage of hosts are popular sources and
In particular, 5% of the internal
targets of attacks.
hosts account for more than 70% of the total recorded
attacks originating from the intranet.
In addition,
servers are much more preferable targets than clients.
• Healthy hosts closer in terms of IP address distance to
infected hosts are much more likely to become infected.
• The infection points exhibit diurnal patterns.
• Our time series analysis shows that server infections
are almost independent in time, while client infections
are consistently more bursty and this is more evident
for aggregation time-scales above two minutes.
In summary, in this work we make the following contri-
butions:
1. Detection: We introduce a heuristic for detecting
infections that uses a statistical correlation measure,
namely the J-Measure, to ﬁnd hosts that produce a
recurring multi-stage alert footprint involving speciﬁc
classes of alerts.
2. Validation: We introduce a methodolgy and conduct
a complex experiment to systematically validate sus-
pected live infections on unmanaged hosts within a
production environment. We ﬁnd that the false posi-
tive rate of our heuristic is 15%.
3. Characterization: We characterize 9,163 infections
over a period of 9 months. To the best of our knowl-
edge, this is the ﬁrst characterization of a very large
number of infections.
Generator ID, 
Signature ID,
Signature 
Revision # Alert
Description
Snort Classification (e.g.,
Attempted Privilege Gain)
Decoded Datagram 
(e.g., TCP header)
Alert Severity, i.e., High (1), 
Medium (2) or Low (3)
Datagram
Length
/
ƐĐƌ
ůĂƐƐ WƌŝŽƌŝƚǇ
dŝŵĞƐƚĂŵƉ
/WŚĞĂĚĞƌ
Őŵ>ĞŶ
ĂƚĂŐƌĂŵ ZĞĨĞƌĞŶĐĞƐ
^ƌĐ/W
^ƌĐWŽƌƚ Ɛƚ/W ƐƚWŽƌƚ
WƌŽƚŽ
dd>
dK^
/ /Ɖ>ĞŶ
External References
(e.g., Mitre’s CVE 
database)
Figure 1: Snort Alert Full Format
2.
IDS DATA
Our dataset is comprised of raw IDS alerts triggered in
the main campus of ETH Zurich by a Snort [47] sensor,
which is placed between the edge router of the campus and
the network ﬁrewall. The sensor monitors all the upstream
and downstream traﬃc of the campus. It uses the oﬃcial
Snort signature ruleset and the Emerging Threats (ET) rule-
set [19], which are the two most commonly-used Snort rule-
sets. As of April 2011 the two rulesets have a total of 37,388
distinct signatures to detect malicious activities.
The collected alerts have the standard full Snort format
shown in Figure 1. For example, the following is an actual
high priority alert (with anonymized IP addresses) about a
suspected MySQL bot:
[**] [1:2001689:7] ET WORM Potential MySQL bot scanning for SQL server [**]
[Classification: A Network Trojan was detected] [Priority: 1]
01/01-22:04:51.319793 aaa.bbb.ccc.ddd:41276 -> xxx.yyy.zzz.hhh:3306
TCP TTL:61 TOS:0x0 ID:14368 IpLen:20 DgmLen:44 DF
******S* Seq: 0xC2A22307
Win: 0x16D0
Ack: 0x0
TcpLen: 24
The ﬁelds we use are the unique rule identiﬁcation num-
ber, the rule description, the timestamp that denotes when
the alert was triggered, the IPs and ports of the communi-
cating hosts, the default rule classiﬁcation, which indicates
the type of suspected malicious activity, and the rule prior-
ity, which provides a severity rank. The complete raw alerts
as generated by Snort are sent every hour to our collection
and archiving infrastructure.
5
x 10
Low Priority
Medium Priority
High Priority
4
3.5
3
2.5
2
1.5
1
0.5
s
t
r
e
a
l
f
o
e
m
u
o
V
l
0
0
20
40
60
80
100
Time (hours)
120
140
160
The remainder of this paper is structured as follows. In
Section 2 we describe the IDS alert traces we used in our
experiments. We introduce our heuristic in Section 3 and
describe our validation experiments and results in Section 4.
Then, we characterize a number of interesting properties of
the identiﬁed infections in Section 5. Finally, we review
related work in Section 6, we discuss our ﬁndings in Section 7
and conclude our paper in Section 8.
Figure 2: Volume of low, medium, and high priority
alerts per hour during a period of a week
The dataset is both large and rich. During the 9 month
period we study, spanning from January 1st 2010 to Septem-
ber 22nd 2010, our monitoring ran on a 24/7 basis with
only minor interruptions (corresponding to approximately
99% availability), capturing more than 832 million alerts
30Table 1: Classtype frequency of rules in sql.rules
#
691
293
52
22
4
3
2
2
Classiﬁcation
misc-activity
successful-recon-limited
attempted-admin
attempted-user
unsuccessful-user
shellcode-detect
suspicious-login
misc-attack
Description
Miscellaneous activity
Information leak
Attempted administrator privilege gain
Attempted user privilege gain
Unsuccessful user privilege gain
Executable code was detected
An attempted login using a suspicious username was detected
Miscellaneous attack
from 91,512 thousand internal IPs. Figure 2 illustrates the
amount of alerts that we collect during a regular week. On
an hourly basis we record on average more than 130 thou-
sand alerts. The vast majority of these alerts have low prior-
ity and usually correspond to policy violations that are not
directly related to security incidents. However, a signiﬁcant
portion, approximately 6%, consists of high priority alerts.
To identify unique host infections, we restrict our analysis
to hosts with static IP addresses and exclude alerts from dy-
namic IP address ranges. We distinguish between dynamic
and static subnets using a catalog maintained by our net-
work administrators that documents each campus subnet.
Additionally, this information enables us to ﬁnd whether a
subnet accommodates server or client machines. The ex-
cluded alerts originating from dynamic IP address ranges,
correspond to less than 17% of the total active internal IPs
in our data. The fact that most hosts use static IP addresses
is important as it enables us to track and characterize their
behavior over time.
3. METHODOLOGY
3.1 Alert Bundling
The ﬁrst challenge that we need to deal with is that se-
curity events often trigger spurts of very similar alerts. For
example, certain types of port scanning targeting a range
of destination ports will generate a large number of almost
identical alerts that only diﬀer in the destination port and
timestamp ﬁelds. Besides, malware often change slightly
their behavior in order to evade detection. Snort rulesets
often include diﬀerent signatures for each diﬀerent malware
version. When the malicious behavior is manifested, mul-
tiple versions of the same signature may be triggered in a
very short time window. For example, we observe spurts of
the alert ”ET DROP Known Bot C&C Server Traﬃc group
(X)” that only diﬀer in the version number X. Such spurts of
almost identical alerts are not desirable, since they defuse a
single event into multiple segments. Alert bundling groups
spurts of very similar alerts into a single aggregate alert.
Compared to diﬀerent forms of alerts aggregation, which
have been studied in the literature [51], alert bundling aims
at aggregating spurts of almost identical alerts instead of
creating groups of much more diverse alerts that correspond
to the same aggregate multi-stage incident. Alert bundling
is useful as it reduces the amount of alerts that need to be
processed and facilitates the statistical analysis of diﬀerent
events.
We perform alert bundling over three ﬁelds, source/de-
stination ports and alert ID. We generalize the port ﬁelds
from a numerical value to {privileged,ephemeral}, based on
whether the port number is below or above 1024, respec-
tively. We also generalize alert IDs that correspond to dif-
ferent ﬂavors of the same malware into a single alert ID by
ignoring the version number. We then merge alerts trig-