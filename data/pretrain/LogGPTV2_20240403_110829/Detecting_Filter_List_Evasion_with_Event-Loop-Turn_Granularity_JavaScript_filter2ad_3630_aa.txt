title:Detecting Filter List Evasion with Event-Loop-Turn Granularity JavaScript
Signatures
author:Quan Chen and
Peter Snyder and
Ben Livshits and
Alexandros Kapravelos
2021 IEEE Symposium on Security and Privacy (SP)
Detecting Filter List Evasion With Event-Loop-Turn
Granularity JavaScript Signatures
Quan Chen
North Carolina State University
PI:EMAIL
Peter Snyder
Brave Software
PI:EMAIL
Ben Livshits
Brave Software
PI:EMAIL
Alexandros Kapravelos
North Carolina State University
PI:EMAIL
7
0
0
0
0
.
1
2
0
2
.
1
0
0
0
4
P
S
/
9
0
1
1
.
0
1
:
I
O
D
|
E
E
E
I
1
2
0
2
©
0
0
.
1
3
$
/
1
2
/
5
-
4
3
9
8
-
1
8
2
7
-
1
-
8
7
9
|
)
P
S
(
y
c
a
v
i
r
P
d
n
a
y
t
i
r
u
c
e
S
n
o
m
u
i
s
o
p
m
y
S
E
E
E
I
1
2
0
2
Abstract—Content blocking is an important part of a per-
formant, user-serving, privacy respecting web. Current content
blockers work by building trust labels over URLs. While useful,
this approach has many well understood shortcomings. Attackers
may avoid detection by changing URLs or domains, bundling
unwanted code with benign code, or inlining code in pages.
The common ﬂaw in existing approaches is that they eval-
uate code based on its delivery mechanism, not its behavior.
In this work we address this problem by building a system
for generating signatures of the privacy-and-security relevant
behavior of executed JavaScript. Our system uses as the unit of
analysis each script’s behavior during each turn on the JavaScript
event loop. Focusing on event loop turns allows us to build
highly identifying signatures for JavaScript code that are robust
against code obfuscation, code bundling, URL modiﬁcation, and
other common evasions, as well as handle unique aspects of web
applications.
This work makes the following contributions to the problem of
measuring and improving content blocking on the web: First, we
design and implement a novel system to build per-event-loop-turn
signatures of JavaScript behavior through deep instrumentation
of the Blink and V8 runtimes. Second, we apply these signatures
to measure how much privacy-and-security harming code is
missed by current content blockers, by using EasyList and
EasyPrivacy as ground truth and ﬁnding scripts that have the
same privacy and security harming patterns. We build 1,995,444
signatures of privacy-and-security relevant behaviors from 11,212
unique scripts blocked by ﬁlter lists, and ﬁnd 3,589 unique scripts
hosting known harmful code, but missed by ﬁlter lists, affecting
12.48% of websites measured. Third, we provide a taxonomy of
ways scripts avoid detection and quantify the occurrence of each.
Finally, we present defenses against these evasions, in the form
of ﬁlter list additions where possible, and through a proposed,
signature based system in other cases.
As part of this work, we share the implementation of our
signature-generation system, the data gathered by applying that
system to the Alexa 100K, and 586 AdBlock Plus compatible
ﬁlter list rules to block instances of currently blocked code being
moved to new URLs.
I. INTRODUCTION
Previous research has documented the many ways content
blocking tools improve privacy, security, performance, and
user experience online (e.g., [25], [13], [24], [28]). These tools
are the current stage in a long arms race between communities
that maintain privacy tools, and online trackers who wish to
evade them.
Initially, communities identiﬁed domains associated with
tracking, and generated hosts ﬁles that would block communi-
cation with these undesirable domains. Trackers, advertisers,
Addressing this mismatch requires a solution that is able to
© 2021, Quan Chen. Under license to IEEE.
DOI 10.1109/SP40001.2021.00007
1715
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:12:35 UTC from IEEE Xplore.  Restrictions apply. 
and attackers reacted by moving tracking resources to domains
that served both malicious and user-serving code, circumvent-
ing host based blocking. In response, content blocking com-
munities started identifying URLs associated with undesirable
code, to distinguish security-and-privacy harming resources
from user-desirable ones, when both were served from the
same domain, such as with content delivery networks (CDNs).
URL-based blocking is primarily achieved through the
crowd-sourced generation of ﬁlter lists containing regular-
expression style patterns that determine which URLs are
desirable and which should be blocked (or otherwise granted
less functionality). Popular ﬁlter lists include EasyList (EL)
and EasyPrivacy (EP). The non-ﬁlter-list based web privacy
and security tools (e.g., Privacy Badger, NoScript, etc.) also
use URL or domain-level determinations when making access
control decisions.
However, just as with hosts-based blocking, URL-based
blocking has several well known weaknesses and can be
easily circumvented. Undesirable code can be moved to one-
off, rare URLs, making crowdsourced identiﬁcation difﬁcult.
Furthermore, such code can be mixed with benign code in a
single ﬁle, presenting content blockers with a lose-lose choice
between allowing privacy or security harm, or a broken site.
Finally, unwanted code can also be “inlined” in the site (i.e.,
injected as text into a  element), making URL level
determinations impossible.
Despite these well known and simple circumventions, the
privacy and research community lacks even an understanding
of the scale of the problem, let alone useful, practical defenses.
Put differently, researchers and activists know they might be
losing the battle against trackers and online attackers, but
lack measurements to determine if this is true, and if so,
by how much. Furthermore,
the privacy community lacks
a way of providing practical (i.e., web-compatible) privacy
improvements that are robust regardless of how the attackers
choose to deliver their code.
Fundamentally, the common weakness in URL-based block-
ing tools is, at its root, a mismatch between the targeted
behavior (i.e., the privacy-and-security harming behavior of
scripts), and the criteria by which the blocking decisions are
made (i.e., the delivery mechanism). This mismatch allows
for straightforward evasions that are easy for trackers to
implement, but difﬁcult to measure and defend against.
identify the behaviors already found to be harmful, and base
the measurement tool and/or the blocking decisions on those
behaviors. A robust solution must target a granularity above
individual feature accesses (since decisions made at this level
lack the context to distinguish between benign and malicious
feature use) but below the URL level (since decisions at this
level lack the granularity to distinguish between malicious and
benign code delivered from the same source). An effective
strategy must target harmful behavior independent of how it
was delivered to the page, regardless of what other behavior
was bundled in the same code unit.
In this work, we address the above challenges through the
design and implementation of a system for building signatures
of privacy-and-security harming functionality implemented in
JavaScript. Our system extracts script behaviors that occur in
one JavaScript event loop turn [26], and builds signatures
of these behaviors from scripts known to be abusing user
privacy. We base our ground truth of known-bad behaviors on
scripts blocked by the popular crowdsourced ﬁlter lists (i.e.,
EL and EP), and generate signatures to identify patterns in how
currently-blocked scripts interact with the DOM, JavaScript
APIs (e.g., the Date API, cookies, storage APIs, etc), and
initiate network requests. We then use these signatures of
known-bad behaviors to identify the same code being delivered
from other URLs, bundled with other code, or inlined in a site.
We generate per-event-loop-turn signatures of known-bad
scripts by crawling the Alexa 100K with a novel instrumented
version of the Chromium browser. The instrumentation covers
Chromium’s Blink layout engine and its V8 JavaScript engine,
and records script interactions with the web pages into a graph
representation, from which our signatures are then generated.
We use these signatures to both measure how often attackers
evade ﬁlter lists, and as the basis for future defenses.
In total we build 1,995,444 high-conﬁdence signatures of
privacy-and-security harming behaviors (deﬁned in Section III)
from 11,212 scripts blocked by EasyList and EasyPrivacy. We
then use our browser instrumentation and collected signatures
to identify 3,589 new scripts containing identically-performing
privacy-and-security harming behavior, served from 1,965 do-
mains and affecting 12.48% of websites. Further, we use these
signatures, along with code analysis techniques from existing
research, to categorize the method trackers use to evade ﬁlter
lists. Finally, we use our instrumentation and signatures to
generate new ﬁlter list rules for 720 URLs that are moved
instances of known tracking code, which contribute to 65.79%
of all instances of ﬁlter list evasion identiﬁed by our approach,
and describe how our tooling and ﬁndings could be used to
build defenses against the rest of the 34.21% instances of ﬁlter
list evasions.
A. Contributions
This work makes the following contributions to improving
the state of web content blocking:
1) The design and implementation of a system for gener-
ating signatures of JavaScript behavior. These signatures
are robust to popular obfuscation and JavaScript bundling
tools and rely on extensive instrumentation of the Blink
and V8 systems.
2) A web-scale measurement of ﬁlter list evasion, gener-
ated by measuring how often privacy-sensitive behaviors
of scripts labeled by EasyList and EasyPrivacy are re-
peated by other scripts in the Alexa 100K.
3) A quantiﬁed taxonomy of ﬁlter list evasion techniques
generated by how often scripts evade ﬁlter lists by chang-
ing URLs, inlining, or script bundling.
4) 586 new ﬁlter list rules for identifying scripts that
are known to be privacy-or-security related, but evade
existing ﬁlter lists by changing URLs.
B. Research Artifacts and Data
As part of this work we also share as much of our re-
search outcomes and implementation as possible. We share
the source of our Blink and V8 instrumentation, along with
build instructions. Further, we share our complete dataset of
applying our JavaScript behavior signature generation pipeline
to the Alexa 100K, including which scripts are encountered,
the execution graphs extracted from each measured page, and
our measurements of which scripts are (or include) evasions
of other scripts.
Finally, we share a set of AdBlock Plus compatible ﬁlter list
additions to block cases of websites moving existing scripts to
new URLs (i.e., the subset of the larger problem that can be
defended against by existing tools) [5]. We note many of these
ﬁlter list additions have already been accepted by existing ﬁlter
list maintainers, and note those cases.
II. PROBLEM AREA
This section describes the evasion techniques that existing
content blocking tools are unable to defend against, and which
the rest of this work aims to measure and address.