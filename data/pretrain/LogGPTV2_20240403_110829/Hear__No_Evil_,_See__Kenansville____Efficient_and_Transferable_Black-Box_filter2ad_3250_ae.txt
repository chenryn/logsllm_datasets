In contrast, the Google (Normal) model seems to be least
vulnerable with the highest cosine similarity of 0.78. To better
characterize the phenomenon, we use the cosine similarity
value to estimate the number of words that the attack effects.
We do so by assuming a sentence comprised of 10 words each.
Perturbing a single phoneme can force Wit to mistranscribe the
next seven words. However, only two of the next 10 words
will be mistranscribed by the Google (Normal) model. This
robustness of the Google (Normal) model might be due to its
recurrent layers being less weighted towards the previously
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:09:39 UTC from IEEE Xplore.  Restrictions apply. 
720
engowawaeeyuwuxshaoaauhayeremenihoyahehaxriychwax-haxngrixhhmyzsjhtlvngthkhvfelpddxdhbnxzhPhonemes020406080100Attack Success (%)Google (Normal)bchzhngemenenghhhvihaeaaawayahowuhuwuxeraxrax-hniyehaogshvtzmlaxweypixrelsknxydxfoyjhddhthPhonemesAttack Success (%)WitStopsAffricatesFricativesNasalsSemivowels_and_GlidesVowelsFig. 7: Success rate of our attack against a Automatic Voice Identiﬁcation (AVI) system. When perturbing a single phoneme
in the entire audio sample, an adversary has a greater chance of succeeding with an SSA attack rather than a DFT attack.
Additionally, similar to the observation in Figure 5 vowels are more vulnerable than other phonemes.
Figure 10 shows the relative amount of perturbation neces-
sary in order to force an AVI misclassiﬁcation. The SSA attack
requires a relatively high perturbation for every phoneme. In
contrast, the DFT attack requires a smaller degree of pertur-
bation (except for some vowels). This implies that the DFT
attack can be conducted stealthily by intelligently selecting
certain phonemes. The less perturbation required, the more
stealthy the attack. However, because the SSA attack requires
larger degree of perturbations for most phonemes, the level of
stealth is lower. ¡¡¡¡¡¡¿¿¿¿¿¿
C. Transferability
Table III shows results of the transferability experiments
using the SSA-based attack. Overall, the attack has the highest
transfer probability when a ‘harder’ model is used to generate
attack audio samples. The Google (Phone) model had the
highest average threshold across samples which, as discussed
in Section IV-E, translated to the highest transfer probability.
In contrast, a weaker model will have a lower threshold and
thus be less likely to transfer. This can be seen when treating
Sphinx as the baseline model in Table III. The table shows
that in the worst case attack audio generated for the Google
(Phone) the model will also be effective against any other
model at least 42% of the time. This ensures a high probability
of success even in the extreme case when the adversary does
not know which model the victim will be employing. By
generating attack samples on a stronger model, an adversary
can expect an attack to transfer well as long as the victim
model is weaker. Finding a weaker model is trivial. As long
as the adversary has sufﬁcient queries,
they can compare
transcription rates for a candidate audio sample between the
two models.
D. Detection
For the detection experiments, we created set of 266 adver-
sarial samples, perturbed using the DFT technique, while the
benign set consisted of 534 unperturbed audio samples. Of the
adversarial samples provided to the Google Speech API, 20%
did not produce any transcription. This was true both the entire
audio samples and their corresponding partition. This means
that the WER for these samples was 0, which introduced a
bias to our results. Though this is perfect for the attacker, but
it introduces bias in our results. Speciﬁcally, because there
Fig. 8: The attack audio was sent over the cellular network
and recorded on a mobile end-point. The ﬁgure above shows
the percentage of the attack audio that was still mistranscribed
even after being passed over the cellular network.
are two benign cases in which the WER will be zero, benign
audio or very noisy audio. We discarded these audio samples
from our adversarial set to remove this bias in our results. In
the real world, an attacker can merely reduce the attack factor
to prevent the model from producing no transcription. Next,
we calculated the AUC scores for the samples. In our case,
the AUC value was 0.527, which is far lower than the AUC
value of 0.936 reported by the authors for the attacks they
tested. This means even though the temporal based detection
can do an excellent job of detecting other attacks, it is highly
inaccurate for detecting our attack samples.
E. Over-Cellular
Next, we test our attacks for use over a cellular network.
We run previously successful attack audio samples over the
cellular network before passing them again to the target
models. The rate of success for this experiment is shown in
Figure 8 plotted against the DFT and SSA-based attacks for
each model. If our attack were to be used over a cellular
connection, having near real-time performance is important.
There are two sources of the potential delay. The ﬁrst source
is our attack calculating the DFT of the original audio sample.
While we do not conduct our own time evaluation, Danielsson
et al. showed that calculating a DFT on a commodity Android
platform took approximately 0.5 ms for a block size of
4096 [42]. The second source of delay involves searching
for the word/phoneme that the attacker wants to apply the
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:09:39 UTC from IEEE Xplore.  Restrictions apply. 
721
tdwiyowjhawhhnguwuhaymkpoyhvixeythuxshehldxaegnzaxrahsihaxrverybaadhax-haoelnxenemfzhchPhonemes0102030Attack Success (%)Azure DFT Attackoyngtaeiyereyuxowayehixwshjhklawaadaxrruwuhmndxelpenthsgzaxihahyaohvdhvbax-hhhnxemfzhchPhonemesAzure SSA AttackStopsAffricatesFricativesNasalsSemivowels_and_GlidesVowelsperturbation. To do so, the attacker will ﬁrst need to search for
the speciﬁc word or phoneme. Fortunately, real-time phoneme
and word localization is a well-studied research area, which
offers potential for optimization of the attack in future work.
We refer interested readers to the work by Arik et al. [44],
and Ito and Donaldson [45].
The DFT-based attack managed to be more successful
across the mobile network than the SSA-based attack and
was only consistently ﬁltered by the Deep Speech and Wit
models. Overall, the models react differently based on the
transformation. Wit performs best under DFT transforms and
worst under SSA transforms, while the opposite is true for
Deep Speech 1 and Google (Normal) model. Sphinx is equally
vulnerable to both transformation methods.
An intuition for these results can be formed by considering
the task each transformation is performing. When transforming
with the DFT, the attack audio sample forms around pieces of
weighted cross-correlations from the original audio sample. In
contrast, the SSA is built as a sum of interpretable principal
components. Although SSA may be able to produce ﬁne-
grained perturbations to the signal, the granularity of per-
turbations is lost during the mobile network’s compression.
This effect is expected to be ampliﬁed for higher amounts
of compression, although such a scenario also limits the
perceptibility of benign audio.
F. Amazon Turk Listening Tests
In order to evaluate the transcription done by MTurk work-
ers, we initially manually classiﬁed the transcriptions as either
correct or incorrect. Table IV shows a side by side comparison
of original and attack transcription of the perturbed portion of
the audio sample. Transcriptions which had either a missing
word, a missing sentence, or an additional word not present
in the audio were marked as incorrect. At the end of this
classiﬁcation task, the inter-rater agreement value, Cohen’s
kappa was found to be 0.901, which is generally considered
to be ‘very good’ agreement among individual raters. Our
manual evaluation found only 11% of the transcriptions to
be incorrect. More speciﬁcally, we found that incorrect tran-
scriptions mostly had missing sentences from the beginning
of the played audio sample, but the transcriptions did not
contain any misinterpreted words. Our subjective evaluation
did not consider wrong transcription of perturbed vs. non-
perturbed portion of the audio, rather we only evaluated human
comprehension of the audio sample.
In addition to subjective evaluation, we ran a phoneme-level
edit distance test on transcriptions to compare the level of
transcription accuracy between perturbed and non-perturbed
audio samples. We used this formula for phoneme edit dis-
tance, φ: φ = δ
L, where δ is the Levenshtein edit distance
between phonemes of two transcriptions (original transcription
and MTurk worker’s transcription) for a word and L is
the phoneme length of non-perturbed, normal audio for the
word [11]. We deﬁned accuracy as 1 when φ = 0, indicating
exact match between two transcriptions. For any other value
φ > 0, we deﬁned it as ‘in-accuracy’ and assigned a value of 0.
Original Transcription
How are you?
How’s work going?
I am really sorry
to hear that.
Attack Transcription
How are you
posmothdro?
I am relief for you
to hear that.
TABLE IV: Example of the attacked audio which was played
to MTurk Workers and the corresponding transcriptions.
Accuracy (Perturbed)
Male
91.8%
(56/61)
Female
100%
(61/61)
Accuracy (Benign)
Female
Male
98.36%
98.36%
(60/61)
(60/61)
TABLE V: Transcription accuracy results of MTurk workers
for benign and perturbed audios between Male and Female
speakers.
In Table V, we present transcription accuracy results between
perturbed and non-perturbed audio across our ﬁnal sample size
of 61. We also ran a paired sample t-test, using the individual
accuracy score for perturbed and benign audio transcriptions,
with the null hypothesis that participants’ accuracy levels were
similar for both cases of transcriptions. Our results showed
participants had better accuracy transcribing non-perturbed
audio samples (mean = 0.98, SD = 0.13) than for perturbed
audio (mean = 0.90, SD = 0.30). At a signiﬁcance level of
p < 0.01, our repeated-measures t-test found this difference
not to be signiﬁcant, t(60) = −2.315, p = 0.024. Recall that
our chosen signiﬁcance level (p < 0.01) was not arbitrary,
rather it was chosen during our sample size calculation for
this study. Together, this suggests that our word level audio
perturbation create no obstacle for human comprehension in
telecommunication tasks, thus supporting our null hypothesis.
VI. DISCUSSION
A. Phoneme vs. Word Level Perturbation
Our attack aims to force a mistranscription while still
being indistinguishable from the original audio to a human
listener. Our results indicate that at both the phoneme-level
and the word-level, the attack is able to fool black-box models
while keeping audio quality intact. However, the choice of
performing word-level or phoneme-level attacks is dependent
on factors such as attack success guarantee, audible distortion,
and speed. The adversary can achieve guaranteed attack suc-
cess for any word in the dictionary if word-level perturbations
are used. However, this is not always true for a phoneme-
level perturbation, particularly for phonemes which are pho-
netically silent. An ASR system may still properly transcribe
the entire word even if the chosen phoneme is maximally
perturbed. Phoneme-level perturbations may introduce less
human-audible distortion to the entire word, as the human
brain is well suited to interpolate speech and can compensate
for a single perturbed phoneme. In terms of speed, creating
word-level perturbations is signiﬁcantly slower than creating
phoneme-level perturbations. This is because a phoneme-level
attack requires perturbing only a fraction of the audio samples
needed when attacking an entire word.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:09:39 UTC from IEEE Xplore.  Restrictions apply. 
722
B. Steps to Maximize Attack Success
E. Controlling transcriptions for the Untargeted Attack
An adversary wishing to launch an attack robust Over-
Cellular against an ASR system would be best off using the
DFT-based phoneme-level attack on vowels, as it guarantees
a high level of attack success. Our transferability results show
that an attacker can generate samples for a known ‘hard’
model such as Google (Phone) using 15 iterations of the
attack that can transfer to any unknown ASR model with
high conﬁdence. From our ASR poisoning results, we observe
that an adversary does not have to perturb every word to earn
100% mistranscription of the utterance. Instead, the attacker
can perturb a vowel of every other word in the worst case, and
every ﬁfth word in the best case. The ASR poisoning effect will
ensure that the non-perturbed words are also mistranscribed.
surviving the compression of a cellular network, which will
enable the success of our attack over lossy and noisy mediums.
Contrary to an ASR system attack, an adversary looking to
execute an evasion attack on an AVI system should use the
SSA-based phoneme-level attack. Similar to ASR poisoning,
we observe that an adversary does not have to perturb the
entire sentence to cause a misidentiﬁcation, but rather just
a single phoneme of a word in the sentence. Based on our
results, the attacker would need to perturb on average one
phoneme every 8 words (33 phoneme) to ensure a high
likelihood of attack success. The attack audio samples are
generated in an identical manner for both the ASR and AVI
system attacks, thus the AVI attack audio should also be robust
against lossy and noisy mediums (e.g., a cellular network).
C. Zero Query Case
Using the above information, an attacker can tune the attack
ensure success without having query access to the model (i.e.,
the attack can succeed with zero queries to the target). Our
experimental setup required at most 15 queries. The algorithm
would stop if a successful audio sample was generated without
completing the full 15 queries. As a result, an attacker can run
the our algorithm locally for 15 iterations to produce samples
that can exploit any model with high conﬁdence.
D. Why the Attack Works
Our attacks exploit the fundamental difference in how the
human brain and ASR/AVI process speech. Speciﬁcally, our
attack discards low intensity components of an audio sample
which the human brain is primed to ignore. The remaining
components are enough for a human listener to correctly
interpret the perturbed audio sample. On the other hand, the