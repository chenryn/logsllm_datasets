words, as well as clicking on links on the web pages to sim-
ulate normal user activity.
With our default policy, as expected, we were able to in-
duce false positives on 5 of the web pages. For instance, a
search query for the string “” on Slashdot8 caused
benign data to be returned page to be marked quarantined.
We conﬁrmed that these arise because our client-side proxy
server marks trusted code as untrusted which subsequently
raises alarms when interpreted as code by the browser. In
principle, we expect that full-implementation with a taint-
aware server side component would eliminate these false
positives inherent in the client-side proxy server approxi-
mation.
We also report that even with the client-side proxy server
approximation, we did not raise false positives in certain
cases where the IE 8 Beta XSS ﬁlter did. For instance, we
do not raise false positives when searching for the string
“javascript:” on Google search engine. This is because our
DSI enforcement is parser context aware—though all occur-
rences of “javascript:” are marked untrusted in the HTTP
response page, our browser did not raise an alert as un-
trusted data was not interpreted as code.
8http://slashdot.org
Figure 12: Increase in CPU overhead averaged over 5 runs
for different page sizes for a DSI-enabled web server using
PHPTaint [38].
cheat sheet [12] that worked in Konqueror 3.5.9. Of the 92
attack vectors outlined therein, only 25 worked in a vanilla
Konqueror 3.5.9 browser. We conﬁgured the policy to allow
only ,  and  HTML tags and and href at-
tributes. No modiﬁcations were made to the phpBB appli-
cation code. Our prototype nulliﬁed all 25 XSS attacks.
7.2.2 Performance
Browser Performance. To measure the browser perfor-
mance overhead, we compared the page load times of our
modiﬁed version of Konqueror 3.5.9 and the vanilla version
of Konqueror 3.5.9. We evaluated against the test bench-
mark internally used at Mozilla for browser performance
testing, consisting of over 350 web pages of popular web
pages with common features including HTML, JavaScript,
CSS, and images[24]. No data on this web pages was
marked untrusted. We measured a performance overhead
of 1.8% averaged over 5 runs of the benchmark.
We also measured the performance of loading all the
pages from the XSSed dataset consisting of 5,328, with un-
trusted data marked with serialization delimiters. We ob-
served a similar overhead of 1.85% when processing web
pages with tainted data.
Web page (or code) size increase often translates to in-
creased corporate bandwidth consumption, and is important
to characterize in a cost analysis. For the XSSed dataset, our
instrumentation with delimiters of length ℓ = 10 increased
the page size by less than 1.1% on average for all the web
pages with marked untrusted data.
Server Performance. We measured the CPU overhead
for the phpBB application running on a DSI compliant web
server with PHPTaint enabled. This was done with ab
(ApacheBench), a tool provided with Apache to measure
Figure 11: Percentage of responses completed within a certain timeframe. 1000 requests on a 10 KB document with (a) 10
concurrent requests and (b) 30 concurrent requests.
8 Comparison with Existing XSS Defenses
We outline the criteria for analytically comparing differ-
ent XSS defenses ﬁrst, and then discuss each of the existing
defenses next providing a summary of the comparison in
Figure 13.
8.1 Comparison Criteria
To concretely summarize the strengths and weaknesses
of various XSS defense techniques, we present a defender-
centric taxonomy of adaptive attacks to characterize the
ability of current defenses against current attacks as well as
attacks in the future that try to evade the defenses. Adaptive
attackers can potentially target at least the avenues outlined
below.
• Browser inconsistency. Inconsistency in assumptions
made by the server and client lead to various attacks as
outlined in the Section 1.
• Lexical Polymorphism. To evade lexical sanitization,
attackers may ﬁnd variants in lexical entities.
• Keyword Polymorphism. To evade keyword ﬁlters, at-
tackers may ﬁnd different syntactic constructs to by-
pass these. For instance, in the Samy worm [32],
to inject a restricted keyword innerHTML, the at-
tacker used a semantically equivalent construct “eval
(’inner’+’HTML’)”.
• Multiple Injection Vectors. Attacker can inject non-
script based elements.
• Breaking static structural integrity. To speciﬁcally
evade conﬁnement based schemes, attacker can break
out of the static conﬁnement regions on the web page.
• Breaking dynamic structural integrity. Attacks may
target breaking the structure of the dynamically exe-
cuting client-side code, as discussed in Section 2.
Defense against each of the above adaptive attack cate-
gories serves a point of comparing existing defenses. In ad-
dition to these, we analytically compare the potential effec-
tiveness of techniques to defend against stored XSS attacks.
We also characterize whether a defense mechanism enables
ﬂexible server-side speciﬁcation of policies or not. This is
important because ﬁxation of policies often results in false
positives, especially for content-rich untrusted data, which
can be a serious impediment to the eventual deployability
of an approach.
8.2 Existing Techniques
Figure 13 shows the comparative capabilities of exist-
ing defense techniques at a glance on the basis of criteria
outlined earlier in this section. We describe current XSS
defenses and discuss some of their weaknesses.
8.2.1 Purely server-side defenses
Input Validation and sanitization. Popular server side
languages such as PHP provide standard sanitization func-
tions, such as htmlspecialchars. However, the code
logic to check validity is often concentrated at the input in-
terface of the server, and also distributed based on the con-
text where untrusted data gets embedded. This mechanism
serves as a ﬁrst line of defense in practice, but is not ro-
bust as it places excessive burden on the web developer for
its correctness. Prevalence of XSS attacks today shows that
these mechanisms fail to safeguard against both static and
dynamic DSI attacks.
Techniques
Purely Server-side
BI
P MV S DSI D DSI
ST
FP
Input Validation & Sanitization
Server Output browser-independent policies (using taint-tracking)
Server Output Validation browser-based policies (XSS-GUARD [5])
X
X
X
X
X
X
X
X
X
X
X
X
X
X X
X X
X
X X
X
X
X
X
X
X
X X
X X
X
X X
X X
X X
X X
X X
X X
X X
X X
X
Purely Browser Side
Sensitive Information Flow Tracking
Global Script Disabling
Personal Firewalls with URL Blocking
GET/POST Request content based URL blocking
Browser-Server Cooperation Based
Script Content Whitelisting (BEEP)
Region Conﬁnement Script Disabling (BEEP)
PLI with Server-speciﬁed policy enforcement
BI
P
MV
Not susceptible to browser-server inconsistency bugs
Designed to easily defeats lexical and keyword polymorphism based attacks
Designed for comprehensiveness against multiple vectors and attack goals (Flash objects as scripting vectors,
iframes insertion for phishing, click fraud).
Designed to easily defeat evasion attacks that break static DSI (attacks such as 1,2 in Section 2).
Designed to easily defeat evasion attacks that break dynamic DSI (attacks such as 3,4 in Section 2).
Can potentially deal with stored XSS attacks.
Allows ﬂexible server conﬁgurable policies (important to eliminate false positives for content-rich untrusted data)
S DSI
D DSI
ST
FP
Figure 13: Various XSS Mitigation Techniques Capabilities at a glance. Columns 2 - 6 represent security properties, and
columns 7-9 represent other practical issues. A ‘X’ denotes that the mechanism demonstrates the property.
Browser-independent Policy Checking at Output. Taint-
tracking [44, 25, 27, 30] on the server-side aims to central-
ize sanitization checks at the output interface with the use
of taint metadata. Since the context of where untrusted data
are being embedded can be arbitrary, the policy checking
becomes complicated especially when dealing with attacks
that affect dynamic DSI. The primary reason is the lack of
semantics of client side behavior in the policy checking en-
gine at the interface. Another problem with this approach
is that the policy checks are not speciﬁc to the browser that
the client uses and can be susceptible to browser-server in-
consistency bugs.
Browser-based Policy Checking at Output. To mitigate
the lack of client-side language semantics at the server
output interface, XSS-GUARD [5] employs a complete
browser implementation on the server output.
In princi-
ple, this enables XSS-GUARD to deal with both static and
dynamic DSI attacks, at the expense of signiﬁcant perfor-
mance overheads. However, this scheme conceptually still
suffers from browser inconsistency bugs as a different tar-
get browser may be used by the client than the one checked
against. Our technique enables the primary beneﬁts of XSS-
GUARD without high performance overheads and making
the policy enforcement consistent with the client browser.
8.2.2 Purely client-side defenses
Sensitive information ﬂow tracking. Vogt et. al. propose
sensitive information ﬂow tracking [39] in the browser to
identify spurious cross-domain sensitive information trans-
fer as a XSS attack. This approach is symptom targeted and
limited in its goal, and hence does not lend easily to other
attack targets outlined in the introduction. It also requires
moderately high false positives in normal usage. This stems
from the lack of speciﬁcation of the intended policy by the
web server.
Script Injection Blocking. Several techniques are focused
on stopping script injection attacks. For instance, the Fire-
fox NoScript extension block scripts globally on web sites
the user does not explicitly state as trusted. Many web sites
do not render well with this extension turned on, and this re-
quires user intervention. Once allowed, all scripts (includ-
ing those from attacks) can run in the browser.
Personal Firewalls with URL blocking. Noxes [18] is a
client-side rule based proxy to disallow users visiting po-
tentially unsafe URL using heuristics. First, such solutions
are not designed to distinguish trusted data generated by the
server from user-generated data. As a result, they can have
high false negatives (Noxes treats static links in the page
as safe) and have false positives [18] due to lack of server-
side conﬁguration of policy to be enforced. Second, they
are largely targeted towards sensitive information stealing
attacks.
GET/POST Request content based URL blocking. Sev-
eral proposals aim to augment the web browser (or a local
proxy) to block URLs that contain GET/POST data with
known attack characters or patterns. The most recent is an
implementation of this is the XSS ﬁlter in Internet Explorer
(IE) 8 Beta [14]. First, from our limited experiments with
the current implementation, this approach does not seem
to detect XSS attacks based on the parsing context. This
raises numerous false positives, one instance of which we
describe in Section 7. Second, their design does not allow
conﬁgurable server speciﬁed policies, which may disallow
content-rich untrusted data.
In general, ﬁxed policies on
the client-side with no server-side speciﬁcation either raise
false positives or tend to be too speciﬁc to certain attack vec-
tors (thus resulting in false negatives). Finally, our prelimi-
nary investigation reveals that they currently do not defend
against integrity attacks, as they allow certain non-script
based attack vectors (such as forms) to be injected in the
web page. We believe this is an interesting avenue and a
detailed study of the IE 8 mechanism would be worthwhile
to understand capabilities of such defenses completely.
8.2.3 Client-server cooperative defenses
This paradigm for XSS defense has emerged to deal with
the inefﬁciencies of purely client and server based mecha-
nisms. Jim et al. have recently proposed two approaches
in BEEP [15]—whitelisting legitimate scripts and deﬁning
regions that should not contain any scripting code.
Whitelisting of legitimate scripts. First, they target only
script-injection based vectors and hence are not designed to
comprehensively defend against other XSS vectors. Sec-
ond, this mechanism does not thwart attacks (such as attack
4 in Figure 3) violating dynamic DSI that target unsafe us-
age of data by client-side code. Their mechanism checks
the integrity and authenticity of the script code before it
executes, but does not directly extend to attacks that deal
with the safety of data usage. Our technique enforces a dy-
namic parser-level conﬁnement to ensure that data is not
interpreted as code in client-side scripting code.
Region-based Script Disabling. BEEP outlined a tech-
nique to deﬁne regions of the web page that can not con-
tain script code, which allows ﬁner-grained region-based
script disabling than those possible by already supported
browser mechanisms [28]. First, their isolation mechanism
using JavaScript string quoting to prevent static DSI attacks
against itself. As discussed in Section 4.1, this mechanism
can be somewhat tricky to enforce for content-rich untrusted
data which allows HTML entities in untrusted data. Second,
this mechanism does not deal with dynamic DSI attacks by
itself, because region based script blocking can not be ap-
plied to script code regions.
9 Discussion
DSI enforcement using a client-server architecture offers
a strong basis for XSS defense in principle. However, we
discuss some practical concerns for a full deployment of this
scheme. First, our approach requires both client and server
participation in implementing our enhancements. Though
we can minimize the developer effort for such changes, our
technique requires both web servers and clients to collec-
tively upgrade to enable any protection.
Second, a DSI-compliant browser requires quarantine bit
tracking across operations of several languages. If imple-
mented for JavaScript, this would prevent attacks vectors
using JavaScript, but not against attacks that using other
languages. Uniform cross-component quarantine bit track-
ing is possible in practice, but it would require vendors of
multiple popular third party web plugins (Flash, Flex, Sil-
verlight, and so on) to cooperate and enhance their language
interpreters or parsers. Automatic techniques to facilitate
such propagation and cross-component dynamic quarantine
bit propagation at the binary level for DSI enforcement are
interesting research directions for future work that may help
address this concern.
Third, it is important to account for end-user usability.