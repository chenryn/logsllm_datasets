code and link the object ﬁles with the musl libc library gen-
erated from the same source. As a result, the system call
sequences are almost the same across the binaries on different
architecture, with the exception of a few thread initialization
functions such as set_tid_address(int *tidptr). In this
case, we just ignore performing comparisons on such sys-
tem call executions.
In addition, the system call numbers
(and some names) are different in ARM64 and x86_64 ar-
chitectures and therefore cannot be directly mapped across
multi-ISA nodes. For instance, the ARM64 Linux kernel has
replaced the open system calls with openat. This is also the
case for several other system calls with "at" sufﬁx. Conse-
quently, we cannot forward a system call directly across ma-
chines using its number on any particular architecture. Instead,
we maintain a system call number translation table, so that
any system call (number) being sent to the counterpart node
for simulation will be translated to the corresponding system
call number ﬁrst. In our current MVX engine implementation,
we do not handle multi-threaded applications. However, we
believe a deterministic multi-threading library [47] can be
used in HeterSec to solve that issue.
We implemented two types of multi-ISA MVX where the
monitor resides (1) in a separate process using ptrace to
check the application and (2) in the kernel as a Linux ker-
nel module. The ptrace-version MVX monitor is used as
the developing mode, as it is easier to debug the monitor
code without rebooting the operating systems. Similar to
some existing MVX works, the ptrace version MVX uses
the ptrace parent process as the MVX monitor, leveraging
ptrace primitives to intercept and simulate the system calls.
It implements a shared ring buffer to pass events (e.g., the
syscall return values, or the modiﬁcations of data structures)
between nodes using a FIFO queue policy in order to maintain
sequential consistency. The kernel module version of MVX
can be used for deployment because of the better performance.
The MVX engine in the kernel intercepts the system calls by
wrapping and instrumenting the system call handlers. It also
registers the MVX engine code with the HeterSec message
layer for fast cross-node messaging. As a result of moving
the implementation inside the kernel scope, the system call
interception cost and communication latency are both lower
than the ptrace-based prototype (in Section 4.2).
Implementation
3.5
We implemented a prototype of HeterSec on a x86_64 and
ARM64 machine pair, connected using a Mellanox ConnectX-
4 InﬁniBand network. The synchronized address space was
implemented by placing hooks in the page table handler in the
kernel virtual memory subsystem (e.g., hooking the vma and
pte operations [17]). When the protected process is executed
on the follower OS, the follower OS kernel handles the page
fault by fetching pages from the master OS. The master OS
kernel maintains a vma server and page server which work
together to serve the missing pages for the follower OS and
invalidate dirty pages (those replicated pages being written).
Thus any updates on HeterSec protected process space are
synchronized across machine boundaries. HeterSec uses a
fast in-kernel message handling layer to send messages across
nodes. Since it directly involves the kernel network drivers
(e.g., RDMA over Gigabit Inﬁniband), the cost of switching
between user-space and kernel-space is eliminated. Sending
messages back and forth are relatively cheap between nodes.
For example, the round-trip latency averages 17µs on RDMA
in our micro-benchmark test, as described in Section 4.2.
We also implemented the system call RPC server to commu-
nicate over a fast message handling layer which similarly rides
on RDMA over Inﬁniband. Similar to cross-node page and
VMA handling, the master OS kernel registers a system call
server in the message handling layer. The ﬁrst time a process
issues the sys_hscall system call (either an MTD or MVX),
both master and follower kernels will mark that process as
a HeterSec process (we introduce a ﬂag in task_struct).
For system calls that manipulate cross-node state (e.g., ﬁle,
socket and event poll), the follower OS kernel veriﬁes the ﬁle
descriptor against the VDT to decide whether to invoke the
remote system call handler in the master OS or execute them
locally. Note that the follower kernel will only check system
calls of HeterSec processes, any other processes will be free
from this inspection.
To enable cross-ISA program state transformation, we
leverage the open source Popcorn compiler [4–6] to embed all
the ISA related metadata into the executable. Such informa-
tion includes the ISA speciﬁc instructions, the state relocation
mapping, as well as the ISA-switching points. The state relo-
cation mapping is used at each ISA-switch point, with which
a translation library transfers the currently running process
state (e.g., register states, stack slots, etc.) from one ISA to
another. The compiler was built on LLVM, and all the ISA
speciﬁc code instrumentation was implemented as several
USENIX Association
23rd International Symposium on Research in Attacks, Intrusions and Defenses    433
middle-end and backend passes. When compile applications
into ISA-speciﬁc binaries, we use the same LLVM IR to gen-
erate the assembly code for each architecture. Therefore, the
stack variables in different architecture can be mapped based
on the same origin in IR.
4 Evaluation
In this section, we evaluate the HeterSec prototype as well as
its two applications in terms of the security beneﬁts and the
performance overhead. All the experiments were evaluated
on an x86_64 and ARM64 machine pair. The x86_64 server
contains an Intel Xeon E5-2620v4 CPU with the clock speed
of 2.1GHz. The ARM64 server contains a Cavium ThunderX
CPU (ARMv8.1) with clock speed of 2.0GHz. The two ma-
chines are equipped with 32GB and 128GB of DRAM respec-
tively, and they are connected using Mellanox ConnectX-4
InﬁniBand with a bandwidth of up to 56 Gbps.
4.1 Security Analysis
Similar to existing diversiﬁcation-based defense systems, Het-
erSec also leverages randomized and unknown target process
address information (a.k.a ASLR) for the baseline security.
However, heterogeneous-ISA based approaches could bring
an additional layer of ISA diversity for the process, making it
harder for attackers to generate payloads that ﬁt both architec-
tures. Similar to most of the existing diversiﬁcation systems,
we assume the attackers have remote access to the target
process with a known interface (e.g., connection sockets).
However, HeterSec provides a black box of ISA diversiﬁed in-
stances to attackers. With HeterSec, we can leverage the ISA
divergent hardware and compilation toolchain to generate pro-
gram instances with differing instruction sets. The generated
application instances also possess different calling conven-
tions, variable register usages, and differential stack layouts.
For example, ARM64 allows at most 8 general-purpose regis-
ters (x0 - x7) to be used for passing function call parameters;
while x86_64 only has at most 6 general-purpose registers
for passing parameters. In terms of the system call, ARM64
uses x8 register for system call number and x0 for system
call return value; while x86_64 uses rax for both system call
number and return value. Furthermore, most security essential
system calls have different system call numbers in the two
architectures (e.g., the system call number of execve is 59
on x86_64 and 221 on ARM64). This altogether brings extra
difﬁculties for attackers to launch an attack by, for example,
return oriented programming.
One observation is that stack operations behave differently
on ARMv8 and x86_64. ARMv8 stores the frame pointer
(FP) and the link register (LR) both on the lowest address
of the stack frame. Whereas x86_64 pushes the instruction
pointer (RIP) and the stack base pointer (RBP) into the high-
est address of the stack frame. The slight difference in control
pointer location will make it hard for most of the stack based
control ﬂow hijacks to work on both instances. To further
prove that the ISA diversiﬁed instances will have differing
memory layouts, we wrote a tool utilizing ptrace and cap-
stone [65] to dump the code and data pointers of a running pro-
cess. We examined the potential pointers in .data, .stack,
and .heap, and found 7846 pointers in the x86_64 version
of lighttpd while there were 10385 pointers in a lighttpd web
server running on ARM64. Despite the large number of point-
ers found in each binary we only found 3 pointers which had
overlapping addresses between the two lighttpd processes
running on these different ISAs. In the above mentioned ex-
periment, we only examined the pointers with their relative ad-
dresses from the base of code segment. That means in reality,
there will be almost zero chance of overlapping pointers, since
ASLR disturbs the base code addresses of those program in-
stances [2]. In addition, we also examined some real-world ex-
ploits on HeterSec environment. One example is CVE-2013-
2028, in which an integer overﬂow and a buffer overﬂow in
the Nginx ngx_http_read_discarded_request_body()
function are used to gain control over the execution ﬂow
and carry out ROP attacks [10]. To trigger the vulnerability
an attacker ﬁrst sends a HTTP chunked request with a large
chunked length, resulting in a negative integer to be casted to
an unsigned size_t type. Subsequently this causes a recv
call to read in a value larger than the buffer size from the
client, leading to a buffer overﬂow. We ran a ROP attack
script leveraging the CVE-2013-2028 buffer overﬂow [74]
and while it was able to execute and trigger the vulnerabil-
ity on an x86_64 machine, the script failed on the ARM64
machine and caused the Nginx process to crash and restart.
The stack layouts between architectures differ therefore the
address at which the overﬂow gains control over the program
control ﬂow are not the same.
Another interesting beneﬁt of a multi-ISA security system
is that it could potentially raise the bar for micro-architecture
attacks [37, 46]. This is due to the fact multiple attack primi-
tives have to be implemented differently on different architec-
tures. For example, cache timing measurement and cache ﬂush
have different implementation details. In terms of cache tim-
ing measurement, attackers could use an unprivileged rdtsc
instruction on x86_64 hardware. However, the similar perfor-
mance counter is only accessible in kernel space on both
ARMv7 and ARMv8 processors. Similarly, attackers can
directly ﬂush the cache line with clflush on x86_64, but
have to carefully construct a memory access footprint that de-
feats the cache replacement policy in order to ﬂush the cache
line on ARM processors [45]. The run-time cache layout
and timing diversities increases the cost to launch such at-
tacks. Besides the diversiﬁed instance memory layout and the
micro-architecture behaviors, multi-ISA software diversiﬁca-
tion could also allows the protected process to hybridize the
architecture speciﬁc features for increased security. For exam-
ple, the protected process running on x86_64 can potentially
434    23rd International Symposium on Research in Attacks, Intrusions and Defenses
USENIX Association
switch to ARMv8 and validate whether the pointers were
modiﬁed by attackers with ARMv8 pointer authentication,
while still making use of the Intel MPK or MPX hardware
features to secure memory page accesses and check bound-
aries [43, 50, 54, 77].
4.2 Performance Evaluation
To evaluate the performance impact on multi-ISA security
applications, we ﬁrst report the costs involved in cross-node
operations such as remote system calls and ISA-switches.
Next, we evaluated HeterSec with real-world applications.
Micro-benchmark To get a breakdown of these costs, we
implemented a simple micro-benchmark to execute code re-
motely on the follower node, which triggers 100,000 ISA-
switches. We measured the network latency on an ARM64
machine node using a x86_64 node as the follower. As shown
in Table 1, a remote system call like getpid() imposes an
additional ∼17.6 µs overhead when being called compared
with the native execution of the getpid() system call. The
primary reason for this overhead is the unavoidable com-
munication cost brought by the dual-node architecture. The
result matches the raw network ping-pong micro-benchmark
(∼17.62 µs), in which we wrote a simple kernel module send-
ing 100,000 short messages back and forth between the two
machines. Interestingly, this cross-node network latency is
much smaller than the network latency observed using Linux
ping command (∼112 µs). This is because the HeterSec mes-
saging APIs are implemented in the kernel, thus it avoids the
complicated TCP/IP network stack and the user/kernel con-
text switch cost. We also observed the ISA switching cost (∼
504.85 µs) in our micro-benchmark is higher than a remote
system call, this is mainly caused by the cross-ISA program
state transformation and the page synchronization.
Table 1: The cost (in µs) of remote system call and ISA-switch
compared to local getpid() system call on x86_64.
Latency (in µs)
0.47± 0.01
18.09± 0.36
17.62± 0.33
112± 15
504.85± 4.70
Operations
getpid()
remote getpid()
raw network ping-pong
ping latency
ISA-switch
Application Benchmarks We selected the nbench bench-
mark suite [12], two web server applications – Nginx and
Lighttpd, an in-memory database Redis server and a ﬁle com-
pression utility GNU gzip. We used nbench to measure the
performance of HeterSec on CPU and memory intensive
workloads. Nbench is a compute, FPU and memory inten-
sive benchmark suite containing some common computation
Figure 4: Performance of nbench with the probability of
20%, 40%, 60%, 80% and 100% to switch to the counterpart
ISA respectively. The numbers are normalized with zero ISA
switch, execution on the x86_64 node.
workloads, such as string sorting and neural network back
propagation. We measured the performance overhead of using
multi-ISA hardware under the security scenarios mentioned in
Section 3.4 and reported the performance overhead incurred.
We ﬁrst measured the performance impact of running
nbench under variable probabilities to switch to the coun-
terpart node with different ISA (lthe MTD scenario). In the
experiment, we started the nbench program on the x86_64
node; the code will be executed randomly on each node af-
terwards. We measured the execution time of each test case
and normalized to zero probability of ISA-switch (all code
executed on x86_64 node). We show the normalized perfor-
mance overhead numbers in y-axis of Figure 4. As expected,
the performance decreases as the probability to perform an
ISA-switch increases. This is because the ISA-switch is a rela-
tively expensive operation; the higher chance of ISA-switches
during application execution, the more overall performance
overhead each application could have. When the ﬁrst time pro-
gram execution switches to the counter part node, HeterSec
kernels have to load the code and setup the kernel data struc-
ture. This explains the reason that some benchmarks lose 50%
performance even under 20% chance of ISA-switch. Overall,
execution transfer across nodes contributes mainly for the per-
formance degradation. Since the nbench is CPU and memory
intensive, any latency incurred during the execution will have
signiﬁcant impact on relative performance.
To prove the feasibility of HeterSec on real-world appli-
cations, we evaluated the performance impact of executing
Nginx and Redis in HeterSec MTD mode. Nginx and Redis
are applications which are used in various commodity systems
and best reﬂect the types of overheads which would be seen
when deploying HeterSec in the ﬁeld. We used ApacheBench
to generate the HTTP requests to the web servers and queried
for a web page of 4 KB size for 1 million times. We ﬁrst run
ApacheBench on a laptop located in the same LAN of the
USENIX Association
23rd International Symposium on Research in Attacks, Intrusions and Defenses    435
0%10%20%30%40%50%60%70%80%90%20%40%60%80%100%Relative PerformanceProbability of ISA-switchNumeric SortString SortBitﬁeldFP EmulationFourierAssignmentIDEAHuﬀmanNeural NetLU DecompositionFigure 5: Performance of Nginx (requests/s) with variable
probabilities to switch ISAs at every ISA-switching point.
Figure 6: Performance of Redis (SET instructions/s) with
variable probabilities to switch ISAs at every ISA-switching
point.
target HeterSec machine pair. The laptop and the target ma-
chine pair are connected using a 10Gbps Ethernet with about
0.4 ms latency. We also run our test with artiﬁcial network