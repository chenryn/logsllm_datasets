### Optimizing Confidence Intervals and Parameter Estimation

To compute a worst-case version of confidence intervals, the interval for one parameter must be examined based on the current values of the other parameters. For example, in the given scenario, the confidence interval for \(\beta\) is between 0.43 and 0.64 when \(\alpha = 4000\).

Instead of starting with a large rectangle that surely contains the zero level and reducing it step by step, our algorithm takes a different approach. We begin with a point-sized rectangle that is certainly within the confidence interval, specifically the maximum likelihood point, and gradually expand this rectangle until it encompasses the entire zero level.

The algorithm consists of a main loop that iterates through all parameters. For each parameter, the current lower and upper confidence bounds are checked for positive points. If a positive point is found, the algorithm extends from this point with a finite step size in the corresponding direction until the confidence function yields values less than or equal to zero. This shifts the confidence bound to the new value. The algorithm terminates if no positive points are found on any boundary during a loop iteration. An open issue is whether there are still positive points on the boundaries and, if so, how to find them.

To address the question of whether there are positive points on a boundary, we can reduce it to determining if the maximum value of the confidence function on that boundary is greater than zero. A local optimization algorithm, as described in Section IV-A.1, can be used to find the point that maximizes the confidence function on the boundary. However, since the number of local optima typically increases when one parameter is fixed, a global optimization method is often necessary.

One approach is to use an evolution strategy on each boundary. Additionally, for distributions with up to three parameters, interval arithmetic can be applied. This involves full recursive splitting, where the midpoint of each boundary is used as the splitting point. If the confidence function at the midpoint is positive, the splitting can stop, and the confidence bound can be improved. If the midpoint is negative, the splitting continues until all intervals yield a maximum value less than zero or a positive midpoint is found.

The challenge with this algorithm is that, with real data, about seven to eight splitting recursions are needed to reduce the interval size sufficiently. In a three-dimensional case, each boundary is a two-dimensional rectangle split into four boxes, resulting in \(4^7 = 16384\) boxes after seven recursions. In a six-dimensional case, such as with the bathtub distribution, each boundary is split into 32 boxes per step, leading to \(32^7 = 34,359,738,368\) boxes. This makes the investigation impractical due to memory and runtime constraints.

For distributions with more than three parameters, a heuristic algorithm is employed. The heuristic focuses on the box with the maximum interval value, as it is most likely to contain the maximum function value. This reduces the number of boxes to investigate, but introduces some inaccuracy. Experiments show that the inaccuracy is usually on the order of the step size used. Therefore, the inaccuracy (slightly smaller confidence intervals) can be mitigated by choosing a slightly larger step size.

### ParEs Tool and Examples

This section introduces ParEs, a tool for parameter estimation, and demonstrates its application with examples.

#### ParEs-Tool

ParEs is a GUI-based Java tool designed to estimate parameters from field data, even for users without extensive statistical experience. Data sources include ODBC-databases, manual input, or selection from a tree-structure of car components. After selecting the data source, the user must choose the assumed distribution (an automatic distribution identification feature is under development). The user can then select the estimation algorithm and provide start values, which can be computed automatically or set manually. The tool allows for the computation of point estimation and confidence intervals either together or separately, with a χ²-goodness-of-fit test to guide the decision on the distribution's correctness. The results are presented as parameter values with confidence bounds and typical plots like CDF, PDF, hazard rate, or regression lines. The tool also exports the resulting parameters as tagged data for use in other tools.

#### Examples

To demonstrate the accuracy of the methods, we use generated data for the given distributions, with a 95% confidence level. For the Weibull example, 50 failures were generated, and for the bathtub distribution, 500 failures were used. The time for evaluating the likelihood function depends linearly on the number of failures and suspensions. Enlarging the sample size generally increases the runtime, though fewer iterations may be needed with more information, leading to sublinear runtime growth.

In practice, at least 15 to 20 representative failures are needed for reasonable estimates. The first example is a three-parameter Weibull distribution, with results shown in Table I. The second example is a bathtub distribution, with results in Table II. The plots of the hazard rates for both cases are provided in Figures 8 and 9, respectively.

### Conclusion and Future Work

This paper demonstrates how parameter estimation procedures can extract distribution parameters from field data for input modeling. The methods have been adapted to new distribution types and data modes, with a focus on usability for standard users. While runtime can be optimized, the current weakness is the need for manual distribution selection. Future work aims to automate this process using parametric and non-parametric statistical tests, similar to those in the ExpertFit tool.