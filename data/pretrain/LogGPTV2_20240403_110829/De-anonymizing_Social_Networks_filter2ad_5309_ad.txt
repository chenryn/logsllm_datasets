Node degrees. The mapping scores as described above are
biased in favor of nodes with high degrees. To compensate
for this bias, the score of each node is divided by the square
root of its degree. The resemblance to cosine similarity4 is
not superﬁcial: the rationale is the same.
Revisiting nodes. At the early stages of the algorithm,
there are few mappings to work with, and therefore the
algorithm makes more errors. As the algorithm progresses,
the number of mapped nodes increases and the error rate
goes down. Thus the need to revisit already mapped nodes:
the mapping computed when revisiting a node may be
different because of the new mappings that have become
available.
Reverse match. The algorithm is completely agnostic
about the semantics of the two graphs. It does not matter
whether G1 is the target graph and G2 is the auxiliary graph,
or vice versa. Each time a node u maps to v, the mapping
4. The cosine similarity measure between two sets X and Y is deﬁned
when neither is empty: cos(X, Y ) = |X∩Y |
√|X||Y |
.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:17:29 UTC from IEEE Xplore.  Restrictions apply. 
scores are computed with the input graphs switched. If v
gets mapped back to u, the mapping is retained; otherwise,
it is rejected.
The following pseudocode describes the algorithm in
detail. theta is a parameter that controls the tradeoff
between the yield and the accuracy.
function propagationStep(lgraph, rgraph, mapping)
for lnode in lgraph.nodes:
scores[lnode] = matchScores(lgraph, rgraph, mapping, lnode)
if eccentricity(scores[lnode]) < theta: continue
rnode = (pick node from right.nodes where
scores[lnode][node] = max(scores[lnode]))
scores[rnode] = matchScores(rgraph, lgraph, invert(mapping), rnode)
if eccentricity(scores[rnode]) < theta: continue
reverse_match = (pick node from lgraph.nodes where
scores[rnode][node] = max(scores[rnode]))
if reverse_match != lnode:
continue
mapping[lnode] = rnode
function matchScores(lgraph, rgraph, mapping, lnode)
initialize scores = [0 for rnode in rgraph.nodes]
for (lnbr, lnode) in lgraph.edges:
if lnbr not in mapping: continue
rnbr = mapping[lnbr]
for (rnbr, rnode) in rgraph.edges:
if rnode in mapping.image: continue
scores[rnode] += 1 / rnode.in_degree ˆ 0.5
for (lnode, lnbr) in lgraph.edges:
if lnbr not in mapping: continue
rnbr = mapping[lnbr]
for (rnode, rnbr) in rgraph.edges:
if rnode in mapping.image: continue
scores[rnode] += 1 / rnode.out_degree ˆ 0.5
return scores
function eccentricity(items)
return (max(items) - max2(items)) / std_dev(items)
until convergence do:
propagationStep(lgraph, rgraph, seed_mapping)
Complexity. Ignoring revisiting nodes and reverse matches,
the complexity of the algorithm is O(|E1|d2), where d2 is
a bound on the degree of the nodes in V2. To see this, let
µpart be the partial mapping computed at any stage of the
algorithm. For each u ∈ V1 and each v adjacent to u such
that v ∈ domain(µpart), the algorithm examines each of the
neighbors of µpart(v), giving an upper bound of |E1|d2.
Assuming that a node is revisited only if the number of
already-mapped neighbors of the node has increased by at
least 1, we get a bound of O(|E1|d1d2), where d1 is a bound
on the degree of the nodes in V1. Finally, taking reverse
mappings into account, we get O((|E1| + |E2|)d1d2).
6. Experiments
We used data from three large online social networks in
our experiments. The ﬁrst graph is the “follow” relationships
on the Twitter microblogging service, which we crawled in
late 2007. The second graph is the “contact” relationships
on Flickr, a photo-sharing service, which we crawled in late
2007/early 2008. Both services have APIs that expose a
mandatory username ﬁeld, and optional ﬁelds name and
location. The latter is represented as free-form text. The
ﬁnal graph is the “friend” relationships on the LiveJournal
182
blogging service; we obtained it from the authors of [51].
The parameters of the three graphs are summarized below.
In computing the average degree, the degree of a node is
counted as the sum of its in- and out-degrees.
Network
Twitter
Flickr
LiveJournal
Nodes Edges Av. Deg
37.7
224K
32.2
3.3M
5.3M
29.3
8.5M
53M
77M
6.1. Seed identiﬁcation
To demonstrate feasibility of seed identiﬁcation, we ran
the algorithm of Section 5.1 with the LiveJournal graph as its
target. Recall from Section 4.3 that the auxiliary information
needed to create seed mappings comes from the users of
the target network. Therefore, we can evaluate feasibility of
seed identiﬁcation simply by measuring how much auxiliary
information is needed to identify a unique node in the
target graph. We emphasize that our main de-anonymization
algorithm needs only a handful of such nodes.
For simplicity, we assume that the attacker only has access
to the undirected graph, where an edge is included only if
it is symmetrical in the original graph. This underestimates
the re-identiﬁcation rate, because the attacker would have
more information if directionality of edges were considered.
We synthetically generate auxiliary information for seed
identiﬁcation starting from randomly sampled cliques. To
sample a clique of size k, we start from a random node and,
at every stage, randomly pick a node which is adjacent to
all the nodes picked so far. If there is no such node, we start
over.
This method does not sample uniformly from all
the
cliques in the graph; the distribution of selected nodes is
much more equitable. If we sample a k-clique uniformly,
it is susceptible to anomalies in the graph that make the
result meaningless. If the graph has a large clique, or even
a large dense subgraph, then almost every k-clique sampled
will belong to this large clique or subgraph.
Given a clique (speciﬁcally, a 4-clique), we assume that
the attacker knows the degrees of these 4 nodes as well as
the number of common neighbors of each of the 6 pairs.
The auxiliary information may be imprecise, and the search
algorithm treats a 4-clique in the target graph as a match as
long as each degree and common-neighbor count matches
within a factor of 1 ± ǫ, where ǫ is the error parameter
(intuitively, the higher the error, the noisier the auxiliary
information and the lower the re-identiﬁcation rate). Figure 1
shows how re-identiﬁcation rate decreases with noise. Recall
that we allow at most one match, and so the attacker
never makes an error as long as his assumptions about the
imprecision of his auxiliary information are correct.
This experiment establishes that seed identiﬁcation is
feasible in practice. If anything, it underestimates how easy
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:17:29 UTC from IEEE Xplore.  Restrictions apply. 
• Derive E′ from E by adding edges.
• Derive E′′ from E′ by randomly deleting edges.
• Project E and E′′ on V1 and V2, respectively, to obtain
E1 and E2.
The best way to add edges is to use link prediction, which
will result in plausible fake edges. Instead of choosing a
speciﬁc link prediction algorithm, we perform the following
(Procedure B):
• Make two copies of E and independently delete edges
at random from each copy.
• Project the copies on V1 and V2, respectively, to get E1
and E2.
It should be clear that Procedure B produces more plau-
sible edges than even the best concrete link prediction
algorithm. If the link prediction algorithm is perfect, i.e., if
the edge additions accomplish the reverse of random edge
deletion, then the two procedures are more or less equivalent
(E′ in Procedure A corresponds to E in Procedure B; E
and E′′ in Procedure A correspond to the two perturbed
copies in Procedure B). If the link prediction is not perfect,
then Procedure B is better in the sense that it leads to
more realistic noise, and thus makes the task of our de-
anonymization algorithm harder.
This leaves the question of what fraction β of edges
to remove to get an edge overlap of αE. The fraction of
common edges is (1 − β)2, while the fraction of edges left
in at least one of the copies is 1 − β2, giving (1−β)2
1−β2 = αE,
which yields β = 1−αE
as the only valid solution. Note that
1+αE
the edge overlap is calculated for the subgraphs formed by
the overlapping nodes. The overlap between E1 and E2 is
much lower.
Results. We investigated the impact that the number of
seeds has on the ability of the propagation algorithm to
achieve large-scale re-identiﬁcation, and also its robustness
to perturbation.
Figure 2 shows that the selection of seeds determines
whether propagation step dies out or not (cf. phase tran-
sition [74]), but whenever large-scale propagation has been
achieved, the re-identiﬁcation rate stays remarkably constant.
We ﬁnd that when the algorithm dies out, it re-identiﬁes no
more than a few dozen nodes correctly.
We performed a further experiment to study the phase
transition better. A run is classiﬁed as successful if it re-
identiﬁes at least 1,000 nodes. Figure 3 shows the resulting
probabilities of large-scale propagation. The phase transition
is somewhat less sharp than might appear from Figure 2,
although the window is almost completely in the range
[15,45].
It must be noted that the number of seeds required to
trigger propagation depends heavily on the parameters of
the graph and the algorithm used for seed selection. We
therefore caution against reading too much into the numbers.
What this experiment shows is that a phase transition does
Figure 1. Seed identiﬁcation
this is to do in the real world, where the attacker can use aux-
iliary information other than degrees and common-neighbor
counts. Searching based on the structure of the target users’
graph neighborhoods allows re-identiﬁcation with just two or
even a single node, although this is algorithmically complex.
6.2. Propagation
6.2.1. Robustness against perturbation and seed selec-
tion. The most remarkable feature of our propagation al-
gorithm is that it achieves “viral,” self-reinforcing, large-
scale re-identiﬁcation regardless of the number of seeds,
as long as the latter is above a (low) threshold. To study
this behavior, we carried out an experiments on pairs of
subgraphs, over 100,000 nodes each, of a real-world social
network. In each experiment, one of the subgraphs was used
as the auxiliary information, the other as the target. The
graphs were artiﬁcially perturbed by adding different levels
of noise to achieve various degrees of edge overlap.
Perturbation strategy. Given a real network graph G =
(V, E), our goal is to sample subsets V1, V2 of V such
that V1 and V2 have an overlap of αV . Overlap is mea-
sured in terms of the Jaccard Coefﬁcient, which is de-
ﬁned for two sets X and Y if one of them is non-empty:
JC(X, Y ) = |X∩Y |
if each of two sets shares
3 . We
half its members with the other,
simply partition V randomly into three subsets VA, VB, VC
of size 1−αV
|V |, respectively, and set
V1 = VA ∪ VB and V2 = VB ∪ VC .
|V |, αV |V |, 1−αV
the overlap is 1
|X∪Y | . Thus,
2
2
We use one subgraph as the auxiliary information and
the other as the anonymous target graph. As mentioned
in Section 2, we believe that introducing noise via edge
deletions and additions is the only realistic method of
perturbing the edges. Our goal is to simulate the effect of
perturbation on the target graph as follows (Procedure A):
183
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:17:29 UTC from IEEE Xplore.  Restrictions apply. 
Figure 2. The fraction of nodes re-identiﬁed depends
sharply on the number of seeds. Node overlap: 25%;
Edge overlap: 50%
Figure 4. Effect of noise. Node overlap: 25%; Number
of seeds: 50
matches in either the username, or name ﬁeld. Once a
match is found, we compute a score based on a variety
three ﬁelds (username, name and
of heuristics on all
location). If the score is too low, we reject the match as
spurious.
• For usernames, we use the length to measure the likeli-
hood that a username match is spurious. The rationale
is that a username such as “tamedfalcon213” is more
likely to be identifying than “joe”.
• For names, we use the length of the names, as well as
the frequency of occurrence of the ﬁrst and last names.
Rarer names indicate a stronger match.
• For locations, we use heuristics such as two-letter state
abbreviations.
This resulted in around 27,000 mappings, which we
will call µ(G). Since these mappings were computed with
a completely different information than used by the de-
anonymization algorithm, errors in the ground truth can only
degrade the reported performance of our de-anonymization
algorithm. We picked a random sample of the mappings and
veriﬁed by human inspection that the error rate is well under
5%.
Of course, some of those who use both Flickr and Twitter
may use completely different usernames and names on the
two services and are thus not included in our ground-truth
mappings. This has no effect on the reported performance of
our algorithm. When it does recognize two nodes as belong-
ing to the same user, it is rarely wrong, and, furthermore, it
can successfully re-identify thousands of users.
It is possible that our algorithm has a better performance
on the nodes where the ground truth is known than on other
nodes. For example, users who acquire distinctive usernames
on both websites might be habitual early adopters of web
services. Thus, the numbers below must be interpreted with
Figure 3. The phase transition in more detail. Node
overlap: 25%; Edge overlap: 50%
happen and that it is strongly dependent on the number of
seeds. Therefore, the adversary can collect seed mappings
incrementally until he has enough mappings to carry out
large-scale re-identiﬁcation.
Figure 4 shows that imprecision of the auxiliary infor-
mation decreases the percentage of nodes re-identiﬁed, but
cannot prevent large-scale re-identiﬁcation.
6.2.2. Mapping between two real-world social networks.
As our main experiment, we ran our propagation algorithm
with the graph of Flickr as the auxiliary information and the
anonymous graph of Twitter as the target.
Ground truth. To verify our results, we had to determine
the ground truth, i.e., the true mapping between the two
graphs. We produced ground-truth mappings based on exact
184
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:17:29 UTC from IEEE Xplore.  Restrictions apply. 
caution.
Our seed mapping consisted of 150 pairs of nodes selected
randomly from µ(G), with the constraint that the degree of
each mapped node in the auxiliary graph is at least 80. More
opportunistic seed selection can lower the number of seeds
required.
The accuracy of our algorithm on µ(G) (weighted by
centrality—see Section 4.5) is summarized below:
• 30.8% of the mappings were re-identiﬁed correctly,
12.1% were identiﬁed incorrectly, and 57% were not
identiﬁed.
• 41% of the incorrectly identiﬁed mappings (5% overall)
were mapped to nodes which are at a distance 1 from