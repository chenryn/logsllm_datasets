The resampling on the tactics prediction resulted in an overall increase of
the recall, but also a decrease in precision and, thus, in F0.5 score. Only a few
models (e.g. Extra Trees and Random Forest) improve because of the resampling.
The Logistic Regression model does also increase its F0.5 macro-averaged score
when paired with TF-IDF, which is the maximum obtained in the resampling
evaluation. On the techniques prediction, similarly, the recall increases, while the
precision and the F0.5 score decrease. The only improvements in performance are
for models which performed very poorly without resampling.
Even though all metrics are essential, we want to give equal importance to
each label. Thus looking at the macro-averaged F0.5 scores, the binary relevance
Linear SVC with a TF-IDF weighted text representation stands out compared
to the other models, for both tactics and techniques predictions.
5 Post-processing of classiﬁcation results
From the analysis presented in the previous section, we select the binary rele-
vance Linear SVC model with TF-IDF weighted bag-of-words. To improve its
results, we now try to take advantage of diﬀerent properties of the “Enterprise”
ATT&CK framework such as the relationships between tactics and techniques.
It is worth noting that, an eﬀect of this property might have already been tested
in classiﬁcation models involving classiﬁer chains. However, this issue does not
concern the selected SVC model that can, therefore, beneﬁt from this additional
information.
5.1 Undertaken approaches
Relationships between tactics and techniques Given the relationship be-
tween each technique and the tactic it belongs to, we use this property of the
framework in the following ways:
Direct mapping from techniques to tactics This approach deﬁnes the tactics of
a report based on the classiﬁcation over the techniques. Because each technique
belongs to one or more tactics, we can consider simple post-processing rules
adding tactics to labels. For example, if a technique T e1 is a label of a given
report and T e1 belongs to tactic T a1, then T a1 is also a label of the report.
10
V. Legoy et al.
Tactics as features Since the prediction of techniques underperformed the one
on tactics, we can use the results from the classiﬁcation by tactics to improve
the one by techniques. In this case, we use the results of the tactics prediction as
features for the classiﬁcation by techniques. This is close to the classiﬁer chain
method, but it solely uses the tactics prediction to inﬂuence the techniques one.
Conﬁdence propagation Here, we want to use the method described in Ayoade et
al. [2] (as well as Wu et al.’s work [32]). The idea behind this approach is to use
the conﬁdence score of each technique and the conﬁdence score of the associated
tactics to create boosting factors. Each boosting factors are multiplied to each
associated tactic conﬁdence score, and this ensemble is added to the pre-existing
technique conﬁdence score. Based on the associated tactics conﬁdence score, the
techniques’ conﬁdence score increases or decreases, thus impacting the ﬁnal pre-
dictions. To apply this method, it is worth noting that, Scikit-learn’s Linear SVC
required us to use the decision function scores instead of the conﬁdence scores
of the classiﬁer as directly normalising the conﬁdence scores (not automatically
performed in the library) would have worsened model’s performance.
(cid:8)T aR
Input:
R /* report
i , ...T eR
k
present in the R
(cid:9) /* all tactics and techniques predicted as being
T ex /* one of the techniques
T ay /* one of the tactics
p(T ex ∈ R) /* the probability of T ex being predicted for R
p(T ay ∈ R) /* the probability of T ay being predicted for R
Output:
(cid:9) /* updated ensemble of tactics and techniques being
(cid:8)T aR
i , ...T eR
k
present in the R
Data:
th ∈ R /* classification threshold
a, b, c, d ∈ R /* defined thresholds
begin
if T ex → T ay then
(cid:8)T aR
(cid:8)T aR
if p(T ex ∈ R) > a > th and b < p(T ay ∈ R) < th then
i , ...T eR
k
tactics and techniques being present in the R
(cid:9) + = T ay /* adding T ay to the ensemble of
(cid:9)− = T ex /* removing T ex to the ensemble of
i , ...T eR
k
tactics and techniques being present in the R
if th < p(T ex ∈ R) < c and p(T ay ∈ R) < d < th then
*/
*/
*/
*/
*/
*/
*/
*/
*/
*/
*/
Algorithm 1. Hanging node approach
Automated Retrieval of TTPs from Threat Reports
11
Hanging node This approach is based on the observation that for 30% of the
techniques predicted in a report, not all related tactics were predicted, meaning
that either the techniques or the tactics were incorrectly identiﬁed. The analysis
of the distribution of the conﬁdences’ frequency shows that false predictions tend
to be closer to the “successful” classiﬁcation threshold (especially when it comes
to tactics). The Hanging node approach tries to leverage this aspect by consid-
ering all conﬁdence scores when adding tactics or removing techniques from the
labels. As presented in Algorithm 1, for a connected pair “tactic-technique”, if
the technique is predicted with a high conﬁdence score, while the tactic is not
predicted, but with a conﬁdence score close to the classiﬁcation threshold th,
then we can add the tactic to the tactics and techniques labeling the report. On
the contrary, if the techniques are present, with a conﬁdence score near to the
classiﬁcation threshold th and the tactic is not predicted for the report, with
a low conﬁdence score, then we can remove the techniques from the predicted
labels. The thresholds a, b, c, d were deﬁned after testing diﬀerent values and
comparing the improvement in classiﬁcation performance.
According to our tests, a classiﬁcation threshold of th = 0.5 and thresholds
a = 0.55, b = 0.05, c = 0.95, d = 0.30, allow the highest macro-averaged
F0.5 score. As we use the Linear SVC from Scikit-learn, we deﬁned the conﬁ-
dence score by scaling the decision function scores using min-max scaling with
min = − 1 and max = 1.
Further similar strategies based on relationships between techniques and tac-
tics are diﬃcult to implement, as several techniques correspond to the same tac-
tics. Adding a technique if a related tactic is also present in the report would be
misguided, as the high probability could be due to another technique. Similarly,
removing a tactic, if a related technique is absent, would be disadvantageous for
basically the same reason.
Relationships between techniques Always based on the ATT&CK frame-
work structure, we can compute joint probabilities between a couple of tech-
niques based on their common appearances within the same malware, tool or
group. Using these probabilities, we decided to test three diﬀerent methods to
improve techniques predictions.
Rare association rules This approach follows the work of Benites and Sapozh-
nikova [5], based on a selection of association rules between techniques. The
ﬁrst step is to calculate the Kulczynski measure [15] for each pair of techniques.
These values are forming a curve from which we can determine the variance. If
this variance is low, the threshold to decide on the pairing rules based on their
Kulczynski measure is based on the median of diﬀerences between neighbour
values. If this variance is high, it is based on the average of the values slightly
lower than the mean of this curve.
Steiner tree association rules This approach has been described by Soni et
al. [28], and focuses on a formulation of the label coherence as a Steiner Tree Ap-
proximation problem [10]. Once the techniques prediction is performed, for each
12
V. Legoy et al.
report, we create a directed tree [21] in which edges have weights corresponding
to the conditional probabilities between the two nodes and the direction is given
by the following criterion:(cid:26)T ei → T ej, p(T ei|T ej) ≤ p(T ej|T ei),
T ei ← T ej,
otherwise.
Then, we use Edmond’s algorithm [8] to obtain a reduced tree and a limited
number of connections between techniques. Based on the predictions of the clas-
siﬁcation, we search the graph for techniques which descend from the predicted
techniques with the K highest weights. In our tests, we found that K = 15 is
the value maximizing the success of this pre-processing strategy.
Knapsack This approach also comes from the paper of Soni et al. [28] but, this
time, the authors consider the label assignment as a resource allocation problem.
In this case, we solve the 0-1 Knapsack problem [20], in which a new label is
selected if its conditional probability (based on the predicted labels) increases
the overall log-likelihood.
5.2 Results and discussion
Table 4 shows the ﬁnal results of all our post-processing approaches. To better
investigate the eﬀects of post-processing approaches we also applied those assum-
ing a perfect match of techniques (when predicting the tactics) and vice-versa
(Table 5). For all results, we use a new baseline given by the pure classiﬁcation
without any post-processing.
Table 4: Comparison of post-processing approaches for tactics and techniques.
Approaches
Tactics
Inde.
1.a.
1.d.
Techniques
Inde.
1.b.
1.c.
1.d.
2.a.
2.b.
2.c.
Precision
Micro
Recall
F0.5
Precision
Macro
Recall
F0.5
65.64% ±3.76% 64.69% ±3%
63.32% ±6.42% 52.34% ±5.08%
57.49% ±5.41%
59.60% ±2.89% 68.04% ±3.06% 61.08% ±3.42% 54.41% ±2.97%
65.38% ±2.87% 60.26% ±3.2% 58.50% ±3.68% 59.47% ±2.29%
60.45% ±3.8%
47.94% ±5.87%
61.28% ±3.12% 55.42% ±3.2%
54.59% ±3%
35.17% ±6%
37.18% ±6.75% 29.79% ±5.91%
31.55% ±5%
33.07% ±7.11% 38.17% ±5.41% 33.69% ±6.2%
32.19% ±6.05% 29.27% ±6.2%
33.70% ±6.79% 36.26% ±5.16%
37.06% ±6.77% 29.79% ±5.99%
33.98% ±5.92% 33.88% ±6%
35.02% ±5.32% 28.84% ±6.9%
31.97% ±4.31% 24.70% ±6.29%
28.14% ±6.72%
25.06% ±6.09%
22.67% ±5.94%
22.74% ±6.3%
22.38% ±5.72%
28.19% ±4.99% 26.06% ±5.69%
31.34% ±5.23% 32.35% ±6.68% 22.21% ±4.89%
33.89% ±5.76% 28.08% ±6.8%
25.18% ±5.22%
22.67% ±5.91%
34.93% ±5.34% 28.84% ±6.94%
33.68% ±%5.02
28.38% ±6.88%
23.60% ±5.9%
27.52% ±6.03%
25.20% ±5.78%
25.06% ±6.11%
24.80% ±6.06%
When it comes to tactics prediction, the independent classiﬁcation is the
best. This might be related to the fact that techniques predictions had worse
results than tactics ones and thus any post-processing depending on these last
Automated Retrieval of TTPs from Threat Reports
13
Table 5: Comparison of post-processing approaches for tactics and techniques
(considering a perfect techniques and tactics predictions respectively).
Approaches
Tactics
Inde.
1.a.
1.d.
Techniques
Inde.
1.b.
1.c.
1.d.
Precision
Micro
Recall
F0.5
Precision
Macro
Recall
F0.5
65.64% ±3.76%
100% ±0%
68.09% ±4.02% 72.37% ±2.97% 68.84% ±3.24% 63.32% ±3.1%
65.38% ±2.87% 60.26% ±3.2%
100% ±0%
100% ±0%
64.69% ±3%
100% ±0%
58.50% ±3.68% 59.47% ±2.29%
100% ±0%
66.29% ±4%
100% ±0%
63.54% ±2.08%
37.18% ±6.75% 29.79% ±5.91% 35.02% ±5.32% 28.84% ±6.9%
51.54% ±5.01% 55.90% ±4.23% 52.24% ±4.4% 41.05% ±3.94% 39.04% ±5.13% 38.35% ±3.16%
36.51% ±8%
38.40% ±7%
48.75% ±4.13% 38.14% ±7.54% 34.21% ±7.43% 37.12% ±4.13% 32.36% ±6.24%
22.40% ±6.22% 25.23% ±6.37%
28.39% ±6.14% 35.44% ±5.42% 29.14% ±7.1%
22.67% ±5.94% 25.06% ±6.09%
could decrease results on the tactics. However, considering a perfect techniques
prediction, both post-processing approaches would help improve the tactics clas-
siﬁcation. The approach “Direct mapping from techniques to tactics” would have
a perfect performance, as it is purely rule-based. However, it is unlikely that the
techniques prediction would improve without the tactic prediction improving.
Because of that, approach “Hanging node” seems to be the most promising ap-
proach to improve the independent classiﬁcation.
For what concerns techniques prediction, the independent classiﬁcation started
with a lower baseline. The use of the approaches “Conﬁdence propagation” and
“Hanging node” are likely possible improvements. In all cases, except for the
approach “Hanging node”, the F0.5 score changed mainly due to lower precision
and increased recall related to the addition of techniques to the predicted set. In
this case, the F0.5 score increasing in “Hanging node” is especially interesting, as
it is due to the decrease of false-positive and, thus, the increase of the precision.
Approaches relying on the relationship between techniques are close to the
classiﬁcation without post-processing. From these results, we conclude that these
approaches might not well adapt to our problem or to the data we use. Approach
“Rare association rules” could probably ﬁt better in a hierarchical environment
with known conditional probabilities. It is also possible that the ground truth
we used is incomplete, as, even though it is based on data collected and analysed
by experts, it represents only a sample of malware, tools and campaigns being
observed in the past years.
If tactics prediction were perfect, and without any change in the prediction
of techniques, approach “Tactics as features” would have the highest score for
all metrics. Once again, we cannot choose an approach based on this test and
the results from Table 5, since the techniques prediction would probably improve
with the perfect tactics prediction. However, since all approaches are better or