P10
P20
Pt
P35
P35
P47
Pd Unit vals
P10 alu 1
10
P47 alu2
30
Stq7
vaIt vald Addr
20
20
.
30
600
600 Ox10
Figure 3. An example Instruction Trace Buffer (ITB).
For each instruction retired by the faulty core in diagnosis(cid:173)
mode, the ITB records information pertaining to 1) decoded
instruction information, 2) some microarchitectural resources
used by the instruction, and 3) the data values used by the
instruction.
this purpose, we propose to use an Instruction Trace
Buffer or ITB, illustrated in Figure 3. Since diagnosis is
not performance-critical,
the ITB could be implemented
entirely in memory or in cache. For better efficiency, we
propose an on-chip hardware FIFO buffer that is periodi(cid:173)
cally flushed to memory.
On the faulty core, the ITB is responsible for storing
three types of information for each retired instruction: the
decoded instruction information, the microarchitectural re(cid:173)
sources used by the retiring instruction, and the data values
of the retiring instruction. The decoded information of
each instruction includes the instruction opcode, the source
operands, and the destination operands. The microarchi(cid:173)
tectural resources usage information refers to microarchi(cid:173)
tectural structures (e.g., decoder, functional units, source
and destination physical registers, etc.) that were used by
the retiring instruction. The data values of the retiring
instruction corresponds to the source values, destination
value, and the virtual address used in the case of a load,
store, or branch. Figure 3 gives an example of an ITB for
a small retirement trace from a faulty core.
Populating the fields of the ITB: Since the ITB is
populated only in the rare event of a fault, we propose
to populate the ITB with additional circuitry that taps into
current microarchitectural structures for this information.
An entry in the ITB is allocated once the instruction is
decoded, with decode information from the decoder. When
the instruction is allocated a ROB entry, and added to an is(cid:173)
sue queue, microarchitecture-Ievel usage information (such
as the physical registers used, ROB entry occupied, ALU
used, etc.) can be populated. When the instruction writes
its result, the data values corresponding to the instruction
(destination register value and address) can be stored. If,
however, the instruction is flushed, the corresponding entry
from the ITB must be discarded as the trace accounts only
for retiring instructions.
While the ITB and its upstream and downstream logic
would incur area overhead, they are only activated during
diagnosis after a rare event of a detection. During fault-free
execution, these modules can be power-gated to reduce the
power and performance overhead during normal operations.
This is in contrast to previous methods of obtaining such
information by adding bits that flow along with the instruc(cid:173)
tions throughout the pipeline [2].
Diagnosis granularity and size of ITB: The granularity at
which TBFD can diagnose a faulty microarchitectural unit
is governed by the level of detail at which information is
recorded in the ITB, which in-tum determines the size of
the lIB. The fields to record in the ITB can be determined
based on the level of repair supported by hardware. For
example, if the hardware only supports replacing an entire
array, as opposed to individual entries in the array, the ITB
needs to only record the fact that this array was accessed,
and not the specific entry in the array that was accessed. In
our simulations, we assume that fine-grain reconfiguration
is supported for the parts of the front-end, meta-datapath,
and datapath which may contain faults (Section 3.4) and
record their usage information in the ITB.
Test-trace generation and analysis: On the fault-free core,
the firmware performs the golden execution from the faulty
core's checkpoint, comparing instructions from the golden
and faulty executions. On a misbehaved instruction, it needs
to corrupt the golden state and enhance the faulty trace
with bits to indicate the source of the misbehavior, thereby
generating the test-trace. These bits are best implemented as
extensions to the ITB. Since the golden execution is already
emulated in software,
it is unlikely to benefit from any
acceleration due to hardware support of the ITB. Therefore,
the additional bits above need not be implemented in the
hardware FIFO for the ITB, and can simply be maintained
in software. Finally, the analysis algorithm is invoked on
the generated test trace - this algorithm works entirely in
software.
3.6. Alternative Strategy for TBFD
The TBFD description above suggests that
the fault(cid:173)
free core's state is synchronized to the faulty core's bad
state when a mismatch occurs between the two executions.
We also considered an alternative where the faulty core
is synchronized to the fault-free core's good state when a
mismatch is encountered. We refer to this alternative as
the "patching" (versus corrupting) execution. A possible
advantage of this alternative is that in diagnosis mode, the
faulty core is made to go through the original program
rather than potentially arbitrary code and data, while still
communicating the impact of the fault on this code. We
1-4244-2398-9/08/$20.00 Â©2008 IEEE
27
DSN 2008: Li et al.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:17:28 UTC from IEEE Xplore.  Restrictions apply. 
International Conference on Dependable Systems &Networks: Anchorage, Alaska, June 24-27 2008
implemented this method and did not find better diagnosis
coverage than the corrupting method. We preferred the
corrupting method since it is much easier to implement
as follows.
In the corrupting version we chose, we did not have to
execute the fault-free and faulty cores in synchrony. In fact,
the entire faulty trace could be generated before the fault(cid:173)
free core started execution. The firmware on the fault-free
core took care of corrupting the fault-free execution. In the
patching version, this is not possible because the firmware
cannot run on the faulty core. The faulty core must instead
run roughly synchronized with the fault-free core. It must
send the results of its instructions to the fault-free core and
the fault-free core must send back any patches if needed.
This is clearly much more complex and higher overhead
than the corrupting version. Additionally,
it requires the
faulty core to patch the register file with data from the
fault-free core while not knowing whether the path for
overwriting the register file is fault-free.
It is interesting to note that the patching mode closely
resembles the scheme proposed by Bower et al. where
the DIVA checker is essentially the fault-free core that
patches the architectural state of the faulty core [2]. While
this is feasible in a tightly coupled scenario like DIVA,
it requires too tight
in a general multicore environment,
lockstepping of two cores to be widely deployable.
4. Experimental Methodology
4.1. Simulation Environment
We use a full system simulation environment compris(cid:173)
ing the Wisconsin GEMS microarchitectural and memory
timing simulators [7]
in conjunction with the Virtutech
Simics full system functional simulator [18]. Together,
these simulators provide cycle-by-cycle microarchitecture(cid:173)
level timing simulation of a real workload (6 SpecInt2000
and 4 SpecFP2000) running on a real operating system (full
Solaris-9 on SPARC V9 ISA) on a modem out-of-order
superscalar processor and memory hierarchy (Table 1).
The GEMS + Simics infrastructure is based on the
timing-first approach for simulation [8]. In this approach,
the cycle-accurate GEMS timing simulator first executes
an instruction. When this instruction is ready to retire, the
functionally accurate Simics executes the same instruction.
The resulting states are compared for coherence and in the
case that they don't match (which may arise because GEMS
implement a small subset of infrequently used
does not
instructions in the SPARC ISA), the timing simulator's state
is updated with that from the functional simulator which is
assumed to be accurate.
For our fault injections, we inject a single fault into the
timing simulator's microarchitectural state and propagate it
as the faulty values are read through the system. When a
mismatch in the architectural state of the functional and
the timing simulator is detected, the functional simulator
Base Processor Parameters
Frequency
Fetch!decode/execute/retire
Functional units
Integer FU latencies
FP FU latencies
Reorder buffer size
Register file size
Load-store queue
2.0GHz
4 per cycle
2 Int add/mul, lInt div
2 Load, 2 Store, 1 Branch
2 FP add, 1 FP mult
1 FP div/Sqrt
1 add, 4 mul, 24 div
4 default, 7 mul, 12 div
128
256 integer, 256 FP
64 entries
Base Memory Hierarchy Parameters
Data L1/lnstruction L1
L 1 hit latency
L2 (Unified)
L2 hit/miss latency
16KB each
1 cycle
1MB
6/80 cycles
Table 1. Parameters of the simulated processor.
Table 2. Fault injection locations.
(Simics) is corrupted if it is due to the injected fault. Oth(cid:173)
erwise, the value is read from Simics to GEMS, upholding
the timing-first paradigm.
4.2. Faults Diagnosed
The focus of this study is to diagnose the permanent
faults that are detected by the SWAT system. We injected
11 ,200 stuck-at and dominant-0 and dominant-1 bridging
faults in various microarchitectural components (listed in
Table 2) in 40 random points (in both time and space)
during application execution. The injected faults are then
simulated for 10M instructions in detailed timing simula(cid:173)
tion during which the low-cost software-symptom detectors
in the SWAT system detect these faults. This methodology
is identical to that in [6].
The detection techniques achieve a high coverage by
detecting 95% of the non-masked faults, detecting approx(cid:173)
imately 8500 faults. These faults are subject to diagnosis
using our TBFD algorithm, to identify the faulty microar(cid:173)
chitectural component.
4.3. Implementation Assumptions
Emulating fault-free execution: We emulate the fault(cid:173)
free execution by exploiting the inherent dual execution
mode prevalent in our simulation because of the timing(cid:173)
first simulation paradigm. When a fault
the
faulty execution is rolled back and replayed in the GEMS
timing simulator, as it would in a real system. For the fault(cid:173)
free execution, we use the Simics functional simulator that
runs in parallel with the timing simulation. Copying the
state corrupted in the timing simulator due to the fault to
is detected,
1-4244-2398-9/08/$20.00 Â©2008 IEEE
28
DSN 2008: Li et al.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:17:28 UTC from IEEE Xplore.  Restrictions apply. 
International Conference on Dependable Systems & Networks: Anchorage, Alaska, June 24-27 2008
100%
~ 80%
:Im
La.
"C
Q)
~60%
Q)
C
'0
&40%
Sc
Q)
~
~20%
0%
No
Mismatch
iCorrect
Type
Decoder INT ALU
Reg
Dbus
Int Reg
ROB
RAT
AGEN Overall
Figure 4. Effectiveness of microarchitecture-Ievel fault diag(cid:173)
nosis. The figure shows the ability of the diagnosis algorithm
to accurately diagnose detected faults. Overall, 98% of the
detected faults are accurately diagnosed as either (1) the
correct non-array structure or the correct entry within an
array structure (the Unique stack); or (2) within one of two
non-array structures or entries of array structures (Among
2); or (3) the correct array structure type but not the correct
entry within the structure (Correct Type).
the functional simulator corresponds to synchronizing the
fault-free and faulty execution values. This process allows
detection of misbehaved instructions as soon as they retire;
therefore, the test-trace is also immediately generated and
saved to a simulated ITB.
Checkpointing: In our simulations, fault-free checkpoints
are recorded at the beginning of the execution, prior to
fault injection. Rollback is implemented by reloading the
register state, the TLB state, and rolling back the changes
in the cache and memory state (similar to SafetyNet [17]).
Trace length: We run the faulty and the fault-free execu(cid:173)
tions for up to 30 million instructions from the checkpoint.
For efficiency, we invoke the TBFD analysis every 10,000
instructions collected in the ITB. If the algorithm finds the
unique faulty structure, we terminate the simulation.
5. Results
Figure 4 presents the results indicating the effectiveness
of the diagnosis for faults in different microarchitectural
structures. In each bar, the Unique stack represents cases
that the diagnosis process correctly and uniquely diagnoses
the faulty non-array structure or the faulty entry within an
array structure. The Among 2 stack represents cases that
the diagnosis diagnoses 2 potentially faulty units and one of
them is truly faulty. The Correct Type stack shows the cases
where the diagnosis does not diagnose the faulty array entry
(e.g., RAT entry), but the faulty array structure (e.g., RAT)
is correctly diagnosed. The No Mismatch stack represents
cases where no misbehaved instruction is found for 30M
instructions. The Incorrect stack shows the cases where
the diagnosis process diagnoses one or more structures as
faulty, none of which is the actual faulty structure. The
height of each bar is normalized to all the cases on which
the diagnosis procedure is invoked (i.e., all faults detected
within 10M instructions as discussed in Section 4.2).
Of all detected faults, our trace-based diagnosis correctly