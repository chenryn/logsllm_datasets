Self-Supervised Log Parsing
SashoNedelkoski1,3,JasminBogatinovski1,3,AlexanderAcker1,JorgeCardoso2,and
OdejKao1
1 DistributedSystems,TUBerlin,Berlin,Germany
nedelkoski, jasmin.bogatinovski, alexander.acker,
PI:EMAIL 0202
2 DepartmentofInformaticsEngineering/CISUC,UniversityofCoimbra,Portugal
PI:EMAIL
3 Equalcontribution
raM
Abstract. Logs are extensively used during the development and maintenance
ofsoftwaresystems.Theycollectruntimeeventsandallowtrackingofcodeexe- 71
cution,whichenablesavarietyofcriticaltaskssuchastroubleshootingandfault
detection. However, large-scale software systems generate massive volumes of
semi-structured log records, posing a major challenge for automated analysis. ]GL.sc[
Parsingsemi-structuredrecordswithfree-formtextlogmessagesintostructured
templatesisthefirstandcrucialstepthatenablesfurtheranalysis.Existingap-
proachesrelyonlog-specificheuristicsormanualruleextraction.Theseareoften
specializedinparsingcertainlogtypes,andthus,limitperformancescoresand
generalization.WeproposeanovelparsingtechniquecalledNuLogthatutilizes
aself-supervisedlearningmodelandformulatestheparsingtaskasmaskedlan-
1v50970.3002:viXra
guagemodeling(MLM).Intheprocessofparsing,themodelextractssummariza-
tionsfromthelogsintheformofavectorembedding.Thisallowsthecouplingof
theMLMaspre-trainingwithadownstreamanomalydetectiontask.Weevaluate
the parsing performance of NuLog on 10 real-world log datasets and compare
theresultswith12parsingtechniques.TheresultsshowthatNuLogoutperforms
existingmethodsinparsingaccuracywithanaverageof99%andachievesthe
lowesteditdistancetothegroundtruthtemplates.Additionally,twocasestudies
areconductedtodemonstratetheabilityoftheapproachforlog-basedanomaly
detection in both supervised and unsupervised scenario. The results show that
NuLogcanbesuccessfullyusedtosupporttroubleshootingtasks.
Theimplementationisavailableathttps://github.com/nulog/nulog.
Keywords: log parsing · transformers · anomaly detection · representation learning ·
ITsystems
1 Introduction
Current IT systems are a combination of complex multi-layered software and hard-
ware. They enable applications of ever-increasing complexity and system diversity,
where many technologies such as the Internet of Things (IoT), distributed processing
frameworks,databases,andoperatingsystemsareused.Thecomplexityanddiversity
ofthesystemsrelatetohighmanagingandmaintenanceoverheadfortheoperatorsto
2 S.Nedelkoskietal.
a point where they are no longer sufficient to holistically operate and manage these
systems. Therefore, service providers are deploying various measures by introducing
additional AI solutions for anomaly detection, error analysis, and recovery to the IT
ecosystem [13]. The foundation for these data-driven troubleshooting solutions is the
availabilityofdatathatdescribethestateofthesystems.Thelargevarietyoftechnolo-
gies leads to diverse data compelling the developed methods to generalize well over
differentapplications,operatingsystems,orcloudinfrastructuremanagementtools.
Onespecificdatasource–thelogs,arecommonlyusedtoinspectthebehaviorof
anITsystem.Theyrepresentinteractionsbetweendata,files,services,orapplications,
which are typically utilized by the developers, DevOps teams, and AI methods to un-
derstandsystembehaviorstodetect,localize,andresolveproblemsthatmayarise[12].
The first step for understanding log information and their utilization for further auto-
matedanalysisistoparsethem.Thecontentofalogrecordisanunstructuredfree-text
writtenbysoftwaredevelopers,whichmakesitdifficulttostructure.Itisacomposition
ofconstantstringtemplatesandvariablevalues.Thetemplateisthelogginginstruction
(e.g. print(), log.info()) from which the log message is produced. It records a specific
system event. The general objective of a log parser is the transformation of the un-
structured free-text into a structured log template and an associated list of variables.
Forexample,thetemplate”Attemptingclaim:memory(cid:104)∗(cid:105)MB,disk(cid:104)∗(cid:105)GB,vcpus(cid:104)∗(cid:105)
CPU” is associated with the variable list [”2048”, ”20, ”1”]. Here, (cid:104)∗(cid:105) denotes the
position of each variable and is associated with the positions of the values within the
list.Thevariablelistcanbeemptyifatemplatedoesnotcontainvariableparts.
Traditionallogparsingtechniquesrelyonregularexpressionsdesignedandmain-
tained by human experts. Large systems consisting of diverse software and hardware
components render it intricate to maintain this manual effort. Additionally, frequent
softwareupdatesnecessitateconstantcheckingandadjustingofthesestatements,which
is a tedious and error-prone task. Related log parsing methods [2,4,6,20] depend on
parse trees, heuristics, and domain knowledge. They are either specialized to perform
wellonlogsfromspecificsystemsorcanreliablyparsedatawithalowvarietyofunique
templates.Analyzingtheperformanceofexistinglogparsingmethodsonavarietyof
diverse systems reveals their lack of robustness to produce consistently good parsing
results. This implies the necessity to choose a parsing method for the application or
systemathandandincorporatingdomain-specificknowledge.OperatorsoflargeITin-
frastructures would end up with the overhead of managing different parsing methods
fortheircomponentswhereofeachneedtobeaccordinglyunderstood.Basedonthis,
westatethatlogparsingmethodshavetobeaccurateonlogdatafromvarioussystems
rangingfromsingleapplicationsovermobileoperatingsystemstocloudinfrastructure
managementplatformswiththeleasthumanintervention.
Contribution.Weproposeaself-supervisedmethodforlogparsingNuLog,which
utilizesthetransformerarchitecture[1,17].Self-supervisedlearningisaformofunsu-
pervisedlearningwherepartsofthedataprovidesupervision.Tobuildthemodel,the
learningtaskisformulatedsuchthatthepresenceofawordonaparticularpositionin
alogmessageisconditionedonitscontext.Thekeyideaforparsingisthatthecorrect
predictionofthemaskedwordmeansthatthewordisapartofthelogtemplateother-
wise,itisaparameterofthelog.Theadvantagesofthisapproacharethatitcanproduce
Self-SupervisedLogParsing 3
both a log template and a numerical vector sumarization, while domain knowledge is
notneeded.Throughexhaustiveexperimentation,weshowthatNuLogoutperformsthe
previousstateoftheartlogparsingmethodsandachievesthebestscoresoverall.The
modelisrobustandgeneralizeswellacrossdifferentdatasets.Further,weillustratetwo
use cases, supervised and unsupervised, on how the model can be coupled with and
fine-tuned for downstream tasks like anomaly detection. The results suggest that the
knowledgeobtainedduringthemaskedlanguagemodelinginforthelogparsingphase
isusefulasagoodpriorknowledgeforthedownstreamtasks.
2 RelatedWork
Automated log parsing is important due to its practical relevance for the maintenance
and troubleshooting of software systems. A significant amount of research and devel-
opment for automated log parsing methods has been published in both industry and
academia[5,19].Parsingtechniquescanbedistinguishedinvariousaspects,including
technological,operationmode,andpreprocessing.InFig.1,wegiveanoverviewofthe
existingmethods.
Clustering The main assumption in these methods is that the message types co-
incide in similar groups. Various clustering methods with proper string matching dis-
tanceshavebeenused.LKE[3]appliesweightededitdistancewithhierarchicalclus-
tering to do log key extraction and a group splitting strategy to fine-tune the obtained
log groups. LogSig [15] is a message signature-based algorithm that searches for the
most representative message signatures, heavily utilizing domain knowledge to deter-
mine the number of clusters. SHISO [9] is creating a structured tree using the nodes
generatedfromlogmessageswhichenablesareal-timeupdateofnewlogmessagesif
a match with previously existing log templates fails. LenMa [14] utilizes a clustering
approachbasedonsequencesofwordlengthsappearinginthelogs.LogMine[4]cre-
atesahierarchyoflogtemplates,thatallowstheusertochoosethedescriptionlevelof
interest.
Frequentpatternminingassumesthatamessagetypeisafrequentsetoftokens
thatappearthroughoutthelogs.Theproceduresinvolvecreatingfrequentsets,grouping
thelogmessages,andextractionofmessagetypes.Representativeparsersforthisgroup
areSLCT,LFA,andLogCluster[10,11,18].
Evolutionaryisthelastcategory.ItsmemberMoLFI[8]usesanevolutionaryap-
proachtofindtheParetooptimalsetofmessagetemplates.
Log-structure heuristics methods produce the best results among the different
adoptedtechniques[5,19].Theyusuallyexploitdifferentpropertiesthatemergefrom
thestructureofthelog.Thestate-of-the-artDrain[6]assumesthatatthebeginningof
the logs the words do not vary too much. It uses this assumption to create a tree of
fixeddepthwhichcanbeeasilymodifiedfornewgroups.Otherparsingmethodsinthis
groupareIPLoMandAEL[7,18]
Longest-commonsub-sequenceusesthelongestcommonsubsequencealgorithm
to dynamically extract log patterns from incoming logs. Here the most representative
parserisSpell[2].
4 S.Nedelkoskietal.
Our method relates to the novel Neural category in the taxonomy of log pars-
ing methods. Different from the current state-of-the-art heuristic-based methods, our
method does not require any domain knowledge. Through empirical results, we show
thatthemodelisrobustandapplicabletoarangeoflogtypesindifferentsystems.We
believethatinfuturethiscategorywillhavethemostinfluenceconsideringtheadvances
ofdeeplearning.
3 NeuralLogParsing
3.1 Preliminaries
We define the logs as sequences of temporally ordered unstructured text messages
L = (l : i = 1,2,...), where each message l is generated by a logging instruction
i i
(e.g. printf(), log.info()) within the software source code, and i is its positional index
within the sequence. The log messages consist of a constant and an optional varying
part,respectivelyreferredtoaslogtemplateandvariables.Wedefinelogtemplatesand
variablesastuplesEV = ((e ,v ) : e ∈ E, i = 1,2,...),whereEisthefinitesetof
i i
alllogeventtemplates,K =|E|isthenumberofalluniquetemplatesandv isalistof
i
variablesfortherespectivelyassociatedtemplate.Theyareassociatedwithitsoriginal
logmessagebythepositionalindexi.
Thesmallestinseparablesingletonobjectwithinalogmessageisatoken.Eachlog
messageconsistsofaboundedsequenceoftokens,t =(t : t∈T, j =1,2,...,|t |),
i j i
whereTisasetofalltokens,jisthepositionalindexofatokenwithinthelogmessage
l ,and|t |isthetotalnumberoftokensinl .Fordifferentl ,|t |canvary.Dependingon
i i i i i
theconcretetokenizationmethod,tcanbeaword,wordpiece,orcharacter.Therefore,
tokenizationisdefinedasatransformationfunctionT :l →t ,∀i.
i i
With respect to our proposed log parsing method, the notions of context and em-
beddingvectorareadditionallyintroduced.Givenatokent ,itscontextisdefinedby
j
a preceding and subsequent sequence of tokens, i.e. a tuple of sequences: C(t ) =
j
((t ,t ,...,t ),(t ,t ,...,t )), where a < j < b. An embedding vector is
a a+1 j−1 j+1 j+2 b
a d-dimensional real valued vector representation s ∈ Rd of either a token or a log
message.
We establish a requirement and a property for the proposed log parsing method:
Requirement 1 Given a temporally ordered sequence of log messages L, generated
fromanunknownsetEofdistinctlogtemplates,thelogparsingmethodshouldprovide
amappingfunctionf :L→EV.
1
Log Parsers
Frequent Clustering Log-structure Longest- Evolutionary Neural
pattern - LKE heuristics common -MoLFI -NuLog