s
m
(
e
m
T
i
Proposition 2. If the monitor follows the protocol, then
(cid:12)(cid:12)(cid:12) (Z)i, j ∈ Cpk(m)(cid:1) =
P(cid:0)(Z)i, j = c
(cid:12)(cid:12)(cid:12)(cid:0)Z(cid:48)(cid:1)
P(cid:0)(cid:0)Z(cid:48)(cid:1)
i, j ∈ Cpk(m)(cid:1) =
i, j = c
1
|Cpk(m)|
|Cpk(m)|
1
for any i ∈ [2], j ∈ [χ], m ∈ Zr, and c ∈ Cpk(m).
Proof. This is immediate since +pk ensures that for c1 ∈
Cpk(m1) and c2 ∈ Cpk(m2), c1 +pk c2 outputs a ciphertext c
(cid:3)
chosen uniformly at random from Cpk(m1 + m2).
6.5 Performance
We implemented the protocol of Fig. 5 to empirically eval-
uate its computation and communication costs. The imple-
mentation is available at https://github.com/k3coby/
pcr-go.
Parameters: In our implementation, we instantiated the un-
derlying cuckoo ﬁlter with bucket size χ = 4, as recommended
by Fan et al. [16]. We chose ﬁngerprints of length 224 bits to
achieve a low false-positive probability, i.e., about 2−221. For
the underlying partially homomorphic encryption scheme, we
chose exponential ElGamal (e.g., see [10]) implemented in
the elliptic-curve group secp256r1 [6] to balance performance
and security (roughly equivalent to 3072-bit RSA security or
128-bit symmetric security).
Experiment setup: Our prototype including cuckoo ﬁlters
and cryptography, were implemented in Go. We ran the ex-
periments reported below on two machines with the same
operating system and hardware speciﬁcation: Ubuntu 20.04.1,
AMD 8-core processor (2.67GHz), and 72GiB RAM. These
machines played the role of the target and the monitor. We re-
port all results as the means of 50 runs of each experiment and
report relative standard deviations (rsd) in the ﬁgure captions.
Results: We report the computation time of pcrQueryGen,
pcrRespGen, and pcrReveal in Fig. 6. As shown in Fig. 6a,
the computation time of pcrQueryGen is linear in the target’s
set size (i.e., k +1). One takeaway here is that even if the num-
ber of honeywords is relatively large, e.g., k = 1000, it only
takes the target about 100ms to generate a query with four
logical CPU cores. Moreover, since a query is generated only
when choosing to monitor an account at a monitor, the target
can choose when to incur this cost. Fig. 6b shows that the
computational cost of PCR response generation is essentially
1 core
2 cores
4 cores
103
102
101
100
10
8
6
4
2
0
24
26
28
210
24
26
28
210
k + 1
(a) pcrQueryGenpk(X)
(rsd < 0.10)
(b) pcrRespGenpk(e,Y)
(rsd < 0.10)
)
s
m
(
e
m
T
i
5
4
3
2
1
0
24
26
28
210
103
102
101
100
k + 1
24
26
28
210
(c) arg
e(cid:48)∈X
pcrRevealsk(e(cid:48)
(rsd < 0.20)
,(cid:104)Z,Z(cid:48)(cid:105)) = ⊥
(d) arg
e(cid:48)∈X
pcrRevealsk(e(cid:48)
(rsd < 0.65)
,(cid:104)Z,Z(cid:48)(cid:105)) (cid:44) ⊥
Figure 6: Runtimes of pcrQueryGenpk(X), pcrRespGenpk(e,
Y), and arge(cid:48)∈X pcrRevealsk(e(cid:48), (cid:104)Z,Z(cid:48)(cid:105)) when = ⊥ and when
(cid:44) ⊥, as functions of k + 1 with varying numbers of logical
CPU cores.
unchanged regardless of k. This is important so that the com-
putational burden on the monitors does not increase even
if the target grows its number of honeywords per account.
Another observation from Fig. 6b is that it only takes less
than 9ms for the monitor, with even a single logical core, to
produce a response when a failed login attempt occurs.
The computation time of arge(cid:48)∈X pcrRevealsk(e(cid:48),(cid:104)Z,Z(cid:48)(cid:105)) is
shown in Figs. 6c–d in two separate cases: when for all e(cid:48) ∈ X
is pcrRevealsk(e(cid:48),(cid:104)Z,Z(cid:48)(cid:105)) = false (and so the result = ⊥,
Fig. 6c) and when for some e(cid:48) ∈ X, pcrRevealsk(e(cid:48),(cid:104)Z,Z(cid:48)(cid:105)) =
true (i.e., the result (cid:44) ⊥, Fig. 6d). We report these cases sep-
arately since they have signiﬁcantly diﬀerent performance
characteristics. Again, we expect the former to be the com-
mon case. This operation takes constant time in the former
case, since the target needs only to test if any of the 2χ ci-
phertexts (e.g., 8 ciphertexts with χ = 4) are encryptions of
zeros. In our experiments for Fig. 6d, the element e(cid:48) for which
pcrRevealsk(e(cid:48),(cid:104)Z,Z(cid:48)(cid:105)) = true was randomly picked from X,
and the target immediately returned once e(cid:48) was identiﬁed. So
the position of e(cid:48) in X has a large impact on the computation
time for each run, yielding an increased relative standard de-
viation. Since the target on average performs approximately
isEq operations to identify e(cid:48) in this case, the cost is
k+1
2
linear in the target’s set size, as shown in Fig. 6d.
USENIX Association
30th USENIX Security Symposium    851
102
101
100
103
)
B
K
(
e
z
i
s
e
g
a
s
s
e
M
200
message m1
message m2
As shown in Fig. 7, the query (message m1) is of size lin-
ear in the target’s set size, while the response (m2) size is
constant (≈ 1KB). These communication and storage costs
are quite manageable. For example, even 100,000 monitoring
requests would require only about 32GB of storage at the
monitor when k + 1 = 4096.
Performance example:
To put
these perfor-
mance results in context,
consider the strontium
credential
harvesting
attacks launched against
over
organiza-
tions from September
2019 to June 2020.
Microsoft [33] reported
that their most aggres-
sive attacks averaged
335 login attempts per
hour per account
for
hours or days at a time, and that organizations targeted in
these attacks saw login attempts on an average of 20% of
their total accounts. So, if all of a target’s monitors had
been attacked simultaneously by strontium, then 20% of the
target’s monitoring requests would have been triggered to
generate responses to the target. Suppose that in the steady
state, the target had maintained a total of x active monitoring
requests across all of its monitors.
Figure 7: Message size as a
function of R’s password set
size for a (rsd < 0.01)
28
k + 1
24
26
210
We now consider two scenarios. First, if monitors would
not have limited the number of incorrect logins per account
that induced monitoring responses, then each triggered mon-
itoring request would have induced an average of 335 mon-
itoring responses per hour. As such, the target would have
averaged (20%)(335)(x) = 67x monitoring responses per hour,
67
3600 x monitoring responses per second. Since in our ex-
or
periments, processing each monitoring response averaged
≈ 0.002s on a 2-core computer (Fig. 6c), this computer could
have sustained the processing load that would have been in-
(0.002)(67) ≈ 26,865 mon-
duced on the target provided that x < 3600
itoring requests. Even if all x monitoring requests had been
active at the same monitor, this monitor (using the same type
of computer) could have sustained generating responses as
(0.005)(67) ≈ 10,746, since generating responses
long as x <
on a 2-core computer averaged ≈ 0.005s (Fig. 6b). If the x
monitoring requests had been spread across even only three
monitors, however, the bottleneck would have been the target.
The second scenario we consider is one in which monitors
would have limited the number of incorrect logins per ac-
count that induced a monitoring response, as recommended
in Sec. 5.4. If each monitor would have limited the number
of consecutive incorrect logins (and so monitoring responses)
to 100 per account [19, Section 5.2.2], then the target would
have averaged (20%)(100)(x) = 20x monitoring responses
per hour and, using reasoning similar to that above, could
3600
3600
have absorbed the induced processing load provided that x <
= 90,000 monitoring requests. And, in the extreme
(0.002)(20)
case that the same monitor held all x monitoring requests,
the monitor (using the same type of computer) could have
sustained generating responses for x <
= 36,000
monitoring requests.
(0.005)(20)
3600
7 Discussion
In this section we discuss various risks associated with Am-
nesia. The ﬁrst is a general risk associated with Amnesia,
and the others are speciﬁc to the distributed defenses against
credential stuﬃng proposed in Sec. 5.
Password reset: Because detection happens in Amnesia
when the legitimate user logs into her account at the target
after the attacker has, the attacker can try to interfere with
breach detection by changing the account password upon
gaining access to the account. The legitimate user will be
locked out of her account and so will presumably be forced
to reset her password, but this will not serve as unequivocal
evidence of the breach; after all, users reset their passwords all
the time, due to simply forgetting them [22]. As such, target
sites should utilize a backup authentication method (e.g., a
code sent to a contact email or phone for the account) before
enabling password reset.
Denial-of-service attacks: There are mainly two potential
ways of launching denial-of-service (DoS) attacks against a
target: one in which the attacker submits login attempts at
a high rate to a benign monitor to induce monitor responses
to the target, and one in which a malicious monitor directly
sends responses to the target at a high rate. The former DoS
should be diﬃcult for an attacker to perform eﬀectively, since
it requires the attacker to know or predict where the target
will send monitoring requests and for what accounts. While
we have not prescribed a speciﬁc strategy by which a target
deploys monitor requests, such a strategy would need to be
unpredictable; otherwise, rather than using this knowledge to
conduct DoS, the attacker could instead use it to sidestep the
accounts at sites while they are monitored, to avoid alerting
the target to its breach. Another reason the former DoS will
likely be ineﬀective is that, as discussed in Sec. 5.4, a target
that can be breached repeatedly must rely on monitors to slow
stuﬃng attacks to identify a user’s reused password. These
defenses will correspondingly help defend the target from
this type of DoS. The latter DoS against a target, i.e., by a
malicious monitor, would alert the target that this monitor
is either conducting DoS or not implementing these slowing
defenses. In either case, the target can remove this monitor
from its list of monitors and drop responses from it.
As any site, a monitor should deploy state-of-the-art de-