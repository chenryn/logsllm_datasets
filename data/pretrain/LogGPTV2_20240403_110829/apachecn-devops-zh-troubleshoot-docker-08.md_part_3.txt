```
将 Kubernetes 提供者设置为 vSphere，并将 Kubernetes 集群部署在 ESX。这将包含一个 Kubernetes 主服务器和四个 Kubernetes 从数据存储中上传的扩展的`kube.vmdk`中派生的迷你服务器:
```
$ cd kubernetes
$ KUBERNETES_PROVIDER=vsphere cluster/kube-up.sh
```
这将显示四个虚拟机的 IP 地址列表。如果您当前正在开发 Kubernetes，您可以使用这种集群部署机制以下列方式测试新代码:
```
$ cd kubernetes
$ make release
$ KUBERNETES_PROVIDER=vsphere cluster/kube-up.sh
```
可以使用以下命令关闭集群:
```
$ cluster/kube-down.sh
```
![Kubernetes setup troubleshooting](img/image_08_004.jpg)
部署在虚拟空间上的 Kubernetes 主节点/节点
# 立方吊舱部署
现在，在下面的示例中，我们将部署两个 NGINX 复制 pod(RC-pod)，并通过服务公开它们。要了解 Kubernetes 网络，请参考下图了解更多详细信息。在这里，应用可以通过虚拟 IP 地址公开，而要代理的请求(pod(负载平衡器)的副本)由服务处理:
![Kubernetes pod deployment](img/image_08_005.jpg)
库本内斯与 OVS 大桥联网
1.  在 Kubernetes 主文件中，创建一个新文件夹:
    ```
    $ mkdir nginx_kube_example
    $ cd nginx_kube_example
    ```
2.  在您选择的编辑器中创建 YAML 文件，该文件将用于部署 NGINX 吊舱:
    ```
    $ vi nginx_pod.yaml
    apiVersion: v1
    kind: ReplicationController
    metadata:
     name: nginx
    spec:
     replicas: 2
     selector:
     app: nginx
     template:
     metadata:
     name: nginx
     labels:
     app: nginx
     spec:
     containers:
     - name: nginx
     image: nginx
     ports:
     - containerPort: 80
    ```
3.  使用`kubectl:`
    ```
    $ kubectl create -f nginx_pod.yaml
    ```
    创建 NGINX 吊舱
4.  在前面的 pod 创建过程中，我们已经创建了 NGINX pod 的两个副本，其详细信息如下所示:
    ```
    $ kubectl get pods
    NAME          READY     REASON    RESTARTS   AGE
    nginx-karne   1/1       Running   0          14s
    nginx-mo5ug   1/1       Running   0          14s
    $ kubectl get rc
    CONTROLLER   CONTAINER(S)   IMAGE(S)   SELECTOR    REPLICAS
    nginx        nginx          nginx      app=nginx   2
    ```
5.  The container on the deployed minion can be listed as follows:
    ```
            $ docker ps
            CONTAINER ID        IMAGE                                   COMMAND
            CREATED             STATUS              PORTS               NAMES
            1d3f9cedff1d        nginx:latest                            "nginx -g 
            'daemon of   41 seconds ago      Up 40 seconds
            k8s_nginx.6171169d_nginx-karne_default_5d5bc813-3166-11e5-8256-
            ecf4bb2bbd90_886ddf56
            0b2b03b05a8d        nginx:latest                            "nginx -g 
            'daemon of   41 seconds ago      Up 40 seconds
    ```
6.  使用 YAML 文件部署 NGINX 服务，以便在主机端口`82` :
    ```
    $ vi nginx_service.yaml
    apiVersion: v1
    kind: Service
    metadata:
     labels:
     name: nginxservice
     name: nginxservice
    spec:
     ports:
     # The port that this service should serve on.
     - port: 82
     # Label keys and values that must match in order to receive traffic for 
            this service.
     selector:
     app: nginx
     type: LoadBalancer
    ```
    上公开 NGINX pod
7.  使用`kubectl:`
    ```
    $kubectl create -f nginx_service.yaml
    services/nginxservice
    ```
    创建 NGINX 服务
8.  NGINX 服务可以列举如下:
    ```
            $ kubectl get services
            NAME           LABELS                                   SELECTOR    IP(S)
            PORT(S)
            kubernetes     component=apiserver,provider=kubernetes        
            192.168.3.1    443/TCP
            nginxservice   name=nginxservice                        app=nginx   
            192.168.3.43   82/TCP
    ```
9.  现在通过服务可以访问 NGINX 服务器测试页面，网址如下:`http://192.168.3.43:82`
# 在生产环境中部署 Kubernetes
在本节中，我们将介绍一些重要的要点和概念，这些要点和概念可用于在生产中部署 Kubernetes。
*   **Exposing Kubernetes services**: Once we deploy the Kubernetes pods, we expose them using services. The Kubernetes service is an abstraction, which defines a set of pods and a policy to expose them as a microservice. The service gets its own IP address, but the catch is that this address only exists within the Kubernetes cluster, which means the service is not exposed to the Internet. It's possible to expose the service directly on the host machine port, but once we expose the service on the host machine, we get into port conflicts. It also voids Kubernetes benefits and makes it harder to scale the deployed service:
    ![Deploying Kubernetes in a production environment](img/image_08_006.jpg)
    通过外部负载平衡器公开的 Kubernetes 服务
    一种解决方案是添加一个外部负载平衡器，如 HAProxy 或 NGINX。这为每个 Kubernetes 服务配置了一个后端，并将流量代理到单个 pods。与 AWS 部署类似，Kubernetes 集群可以部署在 VPN 内部，AWS 外部负载平衡器可以用于公开每个 Kubernetes 服务:
*   **Support upgrade scenarios in Kubernetes**: In the case of an upgrade scenario, we need to have zero downtime. Kubernetes' external load balancer helps to achieve this functionality in cases of service deployment through Kubernetes. We can start a replica cluster running the new version of the service, and the older cluster version will serve the live requests. As and when the new service is ready, the load balancer can be configured to switch load to the new version. By using this approach, we can support a zero-runtime upgrade scenario for enterprise products:
    ![Deploying Kubernetes in a production environment](img/image_08_007.jpg)
    Kubernetes 部署中支持的升级方案
*   **Make the Kubernetes-based application deployment automatic**: With the help of a deployer, we can automate the process of testing, as well as deploying the Docker containers in production. In order to do so, we need to have a build pipeline and deployer, which pushes the Docker image to a registry such as Docker Hub after successful build. Then, the deployer will take care of deploying the test environment and invoke the test scripts. After successful testing, the deployer can also take care of deploying the service in the Kubernetes production environment:
    ![Deploying Kubernetes in a production environment](img/image_08_008.jpg)
    Kubernetes 应用部署管道
*   **了解资源限制**:了解启动 Kubernetes 集群时的资源限制，配置每个 pod 上的资源请求和 CPU/内存限制。大多数容器在生产环境中由于缺乏资源或内存不足而崩溃。容器应该经过良好的测试，并且应该为生产环境中的 pod 分配适当的资源，以便成功部署微服务。
*   **监控库本内斯集群**:库本内斯集群应该借助日志记录进行持续监控。日志记录工具，如 Graylog、Logcheck 或 Logwatch，应该与 Apache Kafka 一起使用，Apache Kafka 是一个从容器中收集日志并将其导向日志记录工具的消息传递系统。在卡夫卡的帮助下，很容易索引日志，以及处理巨大的流。Kubernetes 复制品完美无缺。如果有任何 pod 崩溃，Kubernetes 服务会重新启动它们，并根据配置保持副本数量始终正常运行。用户喜欢了解的一个方面是失败背后的真正原因。Kubernetes 指标和应用指标可以发布到时间序列存储，如 InfluxDB，它可以用来跟踪应用错误，并测量负载、吞吐量和其他统计数据，以执行故障后分析。
*   **Kubernetes 中的持久存储** : Kubernetes 有卷的概念，可以处理持久数据。我们希望在 Kubernetes 的生产部署中使用持久性存储，因为容器在重新启动时会丢失数据。卷由多种实现支持，例如主机、NFS 或使用云提供商卷服务。Kubernetes 还提供了两个 API 来处理持久存储:
*   **持久卷(PV)** :这是一种在集群中调配的资源，其行为就像节点是集群资源一样。Pods 根据需要从持久卷请求资源(CPU 和内存)。它通常由管理员提供。
*   **持久卷认领(PVC)** :一个 PVC 消耗 PV 资源。它是用户对存储的请求，类似于 pod。pod 可以根据需要请求不同级别的资源(CPU 和内存)。
# 调试不可解问题
在本节中，我们将讨论一些 Kubernetes 故障排除问题:
1.  The first step to debug the Kubernetes cluster is to list the number of nodes, using the following command:
    ```
    $ kubetl get nodes
    ```
    此外，验证所有节点都处于就绪状态。
2.  查看日志，找出部署的 Kubernetes 集群中的问题
    ```
     master:
     var/log/kube-apiserver.log - API Server, responsible for serving the API
            /var/log/kube-scheduler.log - Scheduler, responsible for making scheduling 
        decisions
            /var/log/kube-controller-manager.log - Controller that manages replication 
        controllers
     Worker nodes: 
     /var/log/kubelet.log - Kubelet, responsible for running containers on the 
        node
            /var/log/kube-proxy.log - Kube Proxy, responsible for service load 
        balancing 
    ```
3.  If the pod stays in the pending state, use the following command:
    ```
    $ cluster/kubectl.sh describe pod podname
    ```
    这将列出事件，并可能描述最后发生在吊舱上的事情。
4.  要查看所有集群事件，请使用以下命令:
    ```
    $ cluster/kubectl.sh get events
    ```
如果`kubectl`命令行无法到达`apiserver`进程，请确保设置了`Kubernetes_master`或`Kube_Master_IP`。确保`apiserver`进程在主数据库中运行，并检查其日志:
*   如果您能够创建复制控制器，但看不到面板:如果复制控制器没有创建面板，请检查控制器是否正在运行并查看日志。
*   如果`kubectl`永远挂起或吊舱处于等待状态:
    *   检查主机是否被分配到 pod，如果没有，则当前正在为它们安排一些任务。
    *   检查 kubelet 是否指向豆荚的`etcd`中的正确位置，以及`apiserver`是否使用了奴才的相同名称或 IP。
    *   如果出现问题，请检查 Docker 守护程序是否正在运行。此外，检查 Docker 日志，确保防火墙没有阻止从 Docker Hub 获取映像。
*   `apiserver`流程报告:
*   同步容器时出错:`Get http://:10250/podInfo?podID=foo: dial tcp :10250:` **连接被拒绝**:
    *   这意味着吊舱还没有被安排
    *   检查调度程序日志，查看它是否正常运行
    *   无法连接到容器
    *   尝试在服务端口或吊舱的 IP 地址远程登录到迷你主机
*   使用以下命令检查容器是否在 Docker 中创建:
    ```
     $ sudo docker ps -a
    ```
*   如果您没有看到容器，问题将出在 pod 配置、映像、Docker 或 kubelet 上。如果您看到容器每 10 秒钟创建一次，那么问题出在容器创建上，或者容器的过程失败了。
*   X.509 证书已过期或尚未生效。
检查客户端和服务器上的当前时间是否匹配。使用`ntpdate`进行一次性时钟同步。
# 总结
在本章中，我们学习了在 Kubernetes 的帮助下管理 Docker 容器。Kubernetes 在 Docker 编排工具中有不同的视角，其中每个 pod 将获得一个唯一的 IP 地址，pod 之间的通信可以在服务的帮助下进行。我们已经介绍了许多部署场景，以及在裸机、AWS、vSphere 或使用 Minikube 上部署 Kubernetes 时的故障排除问题。我们还研究了有效部署 Kubernetes 吊舱和调试 Kubernetes 问题。最后一部分帮助在生产环境中部署 Kubernetes，该环境具有负载平衡器、Kubernetes 服务、监控工具和持久存储。在下一章中，我们将介绍 Docker 卷以及如何在生产环境中有效地使用它们。