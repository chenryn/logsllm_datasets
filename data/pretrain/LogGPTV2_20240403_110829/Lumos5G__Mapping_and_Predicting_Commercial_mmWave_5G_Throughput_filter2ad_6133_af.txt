Group ⇓
L
L+M
T+M
L+M+C
T+M+C
L
L+M
T+M
L+M+C
T+M+C
KNN
RF [20]
OK6 [26]
GDBT
Seq2Seq
Regression (Metrics – MAE RMSE)
285 362
229 303
252 326
223 311
228 320
300 378
256 330
173 253
162 241
163 241
0.67
0.74
0.73
0.75
0.73
0.61
0.68
0.70
0.72
0.75
316 442
NA
NA
NA
NA
0.63
NA
NA
NA
NA
225 314
127 186
115 173
109 166
100 154
0.78
0.90
0.91
0.92
0.92
Classification (Metric – Weighted average F1-score)
208 273
74 144
52 109
49 112
57 119
0.73
0.93
0.95
0.96
0.95
Model: History based Harmonic Mean (HM) [38, 64]
Regression (Metric – MAE RMSE )
Classification (Metric – Weighted average F1 score)
231 340
0.73
Past Throughput
Past Throughput
Airport area, using the data collected from UEs connected to North
panel, we train a T+M model. We then use that model to test the
features associated with the South panel, and achieve a decent
weighted average F1-score (w-avgF1) of 0.71. When the UE-Panel
distance is less than 25m, the w-avgF1 further increases to 0.91 as
there exists high environmental similarity between the North and
South panels within this range.
Feature Importance Analysis. We use GDBT’s capability of
reporting the features’ global importance to understand how each
individual feature contributes to the final prediction outcome.
Overall, we find that no single feature or feature group alone
dominates in predicting 5G throughput. We include a more detailed
analysis of global feature importance in Appendix A.2. The results
further support our argument that various factors and their complex
interplay collectively affect 5G throughput.
6.3 Comparison with Existing Models
We now compare the performance of our ML models used in
Lumos5G with several baseline models that have been proposed
in the literature for 3G/4G performance prediction: (1) Classic
ML: Random Forest (RF) [20], KNN; (2) Analytical: Ordinary
Kriging (OK) [26], Harmonic Mean (HM) [38, 64]. While HM is
used for short-term predictions, others have been used in the short
and long term prediction contexts.
To compare classification-based models, we again use weighted
average F1-score (w-avgF1) as the metric, while MAE and RMSE
are used for regression. We combine all the data (i.e., the Global
dataset discussed earlier) and evaluate our models against these
baselines. Table 9 shows a summary of the results. The results
clearly show the superiority of GDBT and Seq2Seq models over
the baseline models across all the feature groups. For instance,
our regression models are able to achieve 27% to 79% reduction in
MAE, while classification models show an improvement of 9% to
6Ordinary Kriging (OK) is a grid interpolation algorithm, hence can only work on
L feature group. For other feature groups, OK is therefore not applicable (NA).
37% in the weighted average F1-score. History-based models such
as Harmonic Mean (HM) – that typically use the immediate past
throughput observations to make future predictions in real-time –
also suffer due to the wild and frequent fluctuations in mmWave
5G throughput. The superiority of Lumos5G mostly stems from
two reasons: (1) judicious feature selection by considering diverse
impact factors affecting 5G throughput, and (2) the expressiveness
of the ML models themselves, e.g., the “deep” nature of the Seq2Seq
model (§5.2). Results for other areas can be found in Appendix A.3.
7 RELATED WORK
Various ML-based or analytical models have been proposed for
3G/4G cellular networks. For example, Margolies et al. [43]
incorporate UE mobility prediction in channel state estimation
for 3G resource scheduling. Schulman et al. [56] consider UE
signal strength measurement for energy-aware scheduling of
user data sessions. Chakraborty et al. [26] employ Ordinary
Kriging (OK)-based geospatial
interpolation that relies on
strong spatial correlations to build spectrum maps, whereas
Alimpertis et al. [20] use Random Forest (RF) models to predict LTE
signal strengths and build campus-wide (or city-wide) 4G signal
strength maps. A similar effort is also seen in [54] which studies
the key information needed for 4G throughput prediction. An
LSTM-based deep learning model is proposed in [45] for predicting
3G/4G throughput at the immediate next time slot only. Several of
these studies have pointed out that location-alone is insufficient
to predict 3G/4G signal strengths/throughput performance; other
factors such as mobility, indoor/outdoor, etc. must be accounted for.
In the case of mmWave 5G throughput prediction, there are far more
complex factors at play, and 5G throughput prediction is far harder
than 3G/4G prediction. For example, due to various obstructions in
an environment, there are far less spatial correlations. We cannot
rely on geospatial interpolation alone to build 5G throughput maps.
As we have shown earlier, the existing ML models proposed in the
literature do not perform as well as our methods. To demonstrate
the key differences between 5G and 3G/4G performance prediction,
we have conducted a comparative study details of which can be
found in Appendix A.4.
Our work further differs from existing 3G/4G ML models in sev-
eral other aspects. All existing models use a fixed set of features
for prediction (some of which may be missing or inaccessible by
UE). Instead, by introducing primary and composed feature groups,
Lumos5G framework enables to select and compose feature groups
that can be readily collected and relevant to the current use case
and context. Furthermore, we consider two classes of ML models
in conjunction with feature grouping. This allows us to take advan-
tage of the more powerful Seq2Seq for higher prediction accuracy,
while employing light-weight, interpretable GDBT to investigate
the feature importance and build best “explainable” ML models
for 5G throughput prediction. In addition, by considering location-
agnostic tower-based features, we have shown there is potential in
developing transferable ML models that are location-independent.
8 DISCUSSION
Next, we discuss the limitations of our work and also highlight the
possible future extensions.
Lumos5G: Mapping and Predicting Commercial mmWave 5G Throughput
IMC ’20, October 27–29, 2020, Virtual Event, USA
8.1 Limitations of Our Work
With the goal to build ML models for throughput prediction,
our study relies primarily on the measurement of key UE-side
factors affecting 5G throughput performance, as well as other
exogenous information (e.g., 5G tower and panel locations) that
can be gathered. We do not heavily utilize PHY-layer features due
to two reasons: (1) no ability yet to unlock bootloaders (thus no
root access) for mmWave-based 5G smartphone models supported
by US carriers, (2) Android 10’s 5G-NR APIs for accessing signal
strength (e.g., getCsiRsrp() or getDbm(), see [4] for API details)
did not always provide meaningful data, hence not highly reliable.
Our study is also limited to one smartphone device model. Ideally,
UE device model should also be included as an input feature (say,
part of a feature group called “Static Features”). Undoubtedly, differ-
ent device models and their specifications such as processor/RAM,
5G modem capabilities [7, 10, 18], antenna design [36], etc. will
likely have high impact on the 5G throughput performance. Study-
ing the impact of device model will be left as part of our future
work. We are also unable to account for the impact of other “un-
controllable” factors such as radio resource contention7 at RAN
or congestion at the wired core network/Internet. Our study also
reveals other research opportunities, including: (1) transferability
of our proposed ML models across different areas; (2) temporal gen-
eralizability of such models over ultra-short (daily), short (seasonal)
and long (yearly) timescales; and (3) sensitivity of the models to
inaccuracies in input feature values. A more comprehensive study
on these aspects is left as part of future work.
While we have conducted extensive measurements and experi-
ments at various locations (both indoor and outdoor) in a large U.S.
city and downloaded over 35,000 GBs of data using 5G network,
the coverage of our study is still limited. Clearly, there is a need
for a much larger corpus of data with increased user participation
in data collection – highlighting the importance of crowdsourced
platforms [48]. Nonetheless, our study demonstrates the feasibility
of predicting mmWave throughput performance with a reasonable
accuracy based primarily on UE-side factors.
8.2 Need for Collaborative Efforts
Lumos5G and its ML models are designed to predict 5G throughput
with an emphasis on aiding applications using 5G services on UE.
Many of the features required by our proposed models such as
user location, mobility speeds, etc. might not always be available to
application developers. This raises questions on how such models
can be built or who will build them. Mobile carriers are plausible
candidates, as they already collect UE-side data such as the tower
UEs are connected to, radio signal strength, user data usage, etc.
for billing and resource management purposes. Additionally, as
mmWave signals are highly directional in nature [41, 52], carriers
providing mmWave-based 5G service need to track user movement
for beam forming and mobility management purposes. More impor-
tantly, carriers also have knowledge about their 5G network such
as the location/properties of 5G panels/services, bands supported
by their 5G network (e.g., low-/mid-/high- band or multiband),
carrier’s back-haul capacity, UE congestion around the tower, etc.
7A simple and preliminary study on the impact of the number of UEs over individual
UE’s 5G data rate is included in Appendix A.1.4.
With all such information already available, 5G carriers can clearly
adopt/adapt Lumos5G framework and build similar ML models.
User-Carrier Collaborative & Crowdsourced Platforms. We
further suggest a user-carrier collaborative approach to tackle the
challenges posed by 5G networks to reap the benefits offered by
5G. For example, channel state, handoff, and other information ob-
tained at 5G towers can be used by 5G carriers for better throughput
prediction which can be fed back to 5G-aware applications through
APIs provided by mobile OSes such as Android, e.g., via the MOWIE
mechanism proposed in [65]. Likewise, UE can provide application
information such as its demands to 5G towers that can aid carri-
ers in resource allocation and scheduling. Recognizing such needs,
several formal efforts [1, 5] are underway, but are not yet fully
operational. Conventionally, cellular providers have relied on their
own radio signal quality testing, congestion, and coverage mapping
to help configure and manage their radio access networks (RANs).
The complexity of mmWave 5G and future multiband 5G [14, 15]
makes such operations far more costly, if not impractical. We be-
lieve a user-carrier collaborative, crowdsourced platform is the most
promising avenue to realize our envisaged 5G throughput map-
ping, bringing benefits to all stake holders – from 5G carriers to
users/customers to application developers and providers.
Building 5G-Aware Apps. Our study points out both the op-
portunities and challenges in building 5G-aware apps. In particular,
to tackle high bandwidth variability, new mechanisms are called for.
Our preliminary study shows that existing adaptive bitrate adap-
tion (ABR) algorithms based on throughput measurement alone
do not work well for ultra-HD (e.g., 8K) video streaming over 5G.
Using Lumos5G for throughput prediction, we propose new rate
adaptation algorithms with layered video coding, “content bursting”
and multi-radio switching mechanisms. Clearly, fully exploring the
issues in developing 5G-aware apps warrants another paper.
9 CONCLUDING REMARKS
We have conducted a first-of-its-kind study on understanding the
predictability of mmWave 5G throughput. Despite mmWave 5G’s
fast attenuation and its sensitivity to environment/mobility, we find
that it is indeed feasible to predict its throughput, both qualitatively