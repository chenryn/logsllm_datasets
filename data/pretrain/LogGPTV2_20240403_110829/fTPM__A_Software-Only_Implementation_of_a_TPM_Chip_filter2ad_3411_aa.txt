title:fTPM: A Software-Only Implementation of a TPM Chip
author:Himanshu Raj and
Stefan Saroiu and
Alec Wolman and
Ronald Aigner and
Jeremiah Cox and
Paul England and
Chris Fenner and
Kinshuman Kinshumann and
Jork L&quot;oser and
Dennis Mattoon and
Magnus Nystr&quot;om and
David Robinson and
Rob Spiger and
Stefan Thom and
David Wooten
fTPM: A Software-Only Implementation  
of a TPM Chip
Himanshu Raj, ContainerX; Stefan Saroiu, Alec Wolman, Ronald Aigner, Jeremiah Cox,  
Paul England, Chris Fenner, Kinshuman Kinshumann, Jork Loeser, Dennis Mattoon, 
Magnus Nystrom, David Robinson, Rob Spiger, Stefan Thom, and David Wooten, Microsoft
 https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/raj
This paper is included in the Proceedings of the 25th USENIX Security SymposiumAugust 10–12, 2016 • Austin, TXISBN 978-1-931971-32-4Open access to the Proceedings of the 25th USENIX Security Symposium is sponsored by USENIX fTPM: A Software-only Implementation of a TPM Chip
Himanshu Raj∗, Stefan Saroiu, Alec Wolman, Ronald Aigner, Jeremiah Cox,
Paul England, Chris Fenner, Kinshuman Kinshumann, Jork Loeser, Dennis Mattoon,
Magnus Nystrom, David Robinson, Rob Spiger, Stefan Thom, and David Wooten
Microsoft
Abstract: Commodity CPU architectures, such as
ARM and Intel CPUs, have started to offer trusted com-
puting features in their CPUs aimed at displacing dedi-
cated trusted hardware. Unfortunately, these CPU archi-
tectures raise serious challenges to building trusted sys-
tems because they omit providing secure resources out-
side the CPU perimeter.
This paper shows how to overcome these challenges
to build software systems with security guarantees sim-
ilar to those of dedicated trusted hardware. We present
the design and implementation of a ﬁrmware-based TPM
2.0 (fTPM) leveraging ARM TrustZone. Our fTPM is the
reference implementation of a TPM 2.0 used in millions
of mobile devices. We also describe a set of mechanisms
needed for the fTPM that can be useful for building more
sophisticated trusted applications beyond just a TPM.
1
Introduction
In recent years, commodity CPU architectures have
started to offer built-in features for trusted computing.
TrustZone on ARM [1] and Software Guard Extensions
(SGX) [25] on Intel CPUs offer runtime environments
strongly isolated from the rest of the platform’s soft-
ware, including the OS, applications, and ﬁrmware. With
these features, CPU manufacturers can offer platforms
with a set of security guarantees similar to those pro-
vided via dedicated security hardware, such as secure co-
processors, smartcards, or hardware security tokens.
Unfortunately, the nature of these features raises se-
rious challenges for building secure software with guar-
antees that match those of dedicated trusted hardware.
While runtime isolation is important, these features omit
many other secure resources present in dedicated trusted
hardware, such as storage, secure counters, clocks, and
entropy. These omissions raise an important question:
Can we overcome the limitations of commodity CPU se-
∗Currently with ContainerX.
curity features to build software systems with security
guarantees similar to those of trusted hardware?
In this work, we answer this question by implement-
ing a software-only Trusted Platform Module (TPM) us-
ing ARM TrustZone. We demonstrate that the low-level
primitives offered by ARM TrustZone and Intel SGX can
be used to build systems with high-level trusted comput-
ing semantics. Second, we show that these CPU security
features can displace the need for dedicated trusted hard-
ware. Third, we demonstrate that these CPU features can
offer backward compatibility, a property often very use-
ful in practice. Google and Microsoft already offer op-
erating systems that leverage commodity TPMs. Build-
ing a backwards compatible TPM in software means that
no changes are needed to Google and Microsoft operat-
ing systems. Finally, we describe a set of mechanisms
needed for our software-only TPM that can also be use-
ful for building more sophisticated trusted applications
beyond just a TPM.
This paper presents ﬁrmware-TPM (fTPM), an end-
to-end implementation of a TPM using ARM TrustZone.
fTPM provides security guarantees similar, although not
identical, to a discrete TPM chip. Our implementation
is the reference implementation used in all ARM-based
mobile devices running Windows including Microsoft
Surface and Windows Phone, comprising millions of mo-
bile devices. fTPM was the ﬁrst hardware or software
implementation to support the newly released TPM 2.0
speciﬁcation. The fTPM has much better performance
than TPM chips and is fully backwards compatible: no
modiﬁcations are required to the OS services or applica-
tions between a mobile device equipped with a TPM chip
and one equipped with an fTPM; all modiﬁcations are
limited only to ﬁrmware and drivers.
To address the above question, this paper starts with
an analysis of ARM TrustZone’s security guarantees. We
thoroughly examine the shortcomings of the ARM Trust-
Zone technology needed for building secure services,
whether for fTPM or others. We also examine Intel’s
USENIX Association  
25th USENIX Security Symposium  841
1
SGX and show that many of TrustZone’s shortcomings
remain present.
We present three approaches to overcome the limi-
tations of ARM TrustZone: (1) provisioning additional
trusted hardware, (2) making design compromises that
do not affect TPM’s security and (3) slightly changing
the semantics of a small number of TPM 2.0 commands
to adapt them to TrustZone’s limitations. Based on these
approaches, our implementation uses a variety of mech-
anisms, such as cooperative checkpointing, fate sharing,
and atomic updates, that help the fTPM overcome the
limitations of commodity CPU security features. This
paper demonstrates that these limitations can be over-
come or compensated for when building a software-only
implementation of a dedicated trusted hardware compo-
nent, such as a TPM chip. The fTPM has been deployed
in millions of mobile devices running legacy operating
systems and applications originally designed for discrete
TPM chips.
Finally, this paper omits some low-level details of our
implementation and a more extensive set of performance
results. These can be found in the fTPM technical re-
port [44].
2 Trusted Platform Module: An Overview
Although TPMs are more than a decade old, we are see-
ing a resurgence of interest in TPMs from both industry
and the research community. TPMs have had a mixed
history, in part due to the initial perception that the pri-
mary use for TPMs would be to enable digital rights
management (DRM). TPMs were seen as a mechanism
to force users to give up control of their own machines
to corporations. Another factor was the spotty security
record of some the early TPM speciﬁcations: TPM ver-
sion 1.1 [52] was shown to be vulnerable to an unsophis-
ticated attack, known as the PIN reset attack [49]. Over
time, however, TPMs have been able to overcome their
mixed reputation, and are now a mainstream component
available in many commodity desktops and laptops.
TPMs provide a small set of primitives that can offer
a high degree of security assurance. First, TPMs offer
strong machine identities. A TPM can be equipped with
a unique RSA key pair whose private key never leaves
the physical perimeter of a TPM chip. Such a key can ef-
fectively act as a globally unique, unforgeable machine
identity. Additionally, TPMs can prevent undesired (i.e.,
malicious) software rollbacks, can offer isolated and se-
cure storage of credentials on behalf of applications or
users, and can attest the identity of the software running
on the machine. Both industry and the research commu-
nity have used these primitives as building blocks in a
variety of secure systems. This section presents several
such systems.
2.1 TPM-based Secure Systems in
Industry
Microsoft. Modern versions of the Windows OS use
TPMs to offer features, such as BitLocker disk en-
cryption, virtual smart cards, early launch anti-malware
(ELAM), and key and device health attestations.
BitLocker [37] is a full-disk encryption system that
uses the TPM to protect the encryption keys. Because
the decryption keys are locked by the TPM, an attacker
cannot read the data just by removing a hard disk and
installing it in another computer. During the startup
process, the TPM releases the decryption keys only af-
ter comparing a hash of OS conﬁguration values with a
snapshot taken earlier. This veriﬁes the integrity of the
Windows OS startup process. BitLocker has been of-
fered since 2007 when it was made available in Windows
Vista.
Virtual smart cards [38] use the TPM to emulate the
functionality of physical smart cards, rather than requir-
ing the use of a separate physical smart card and reader.
Virtual smart cards are created in the TPM and offer sim-
ilar properties to physical smart cards – their keys are not
exportable from the TPM, and the cryptography is iso-
lated from the rest of the system.
ELAM [35] enables Windows to launch anti-malware
before any third-party drivers or applications. The anti-
malware software can be ﬁrst- or third-party (e.g., Mi-
crosoft Windows Defender or Symantec Endpoint Pro-
tection). Finally, Windows also uses the TPM to con-
struct attestations of cryptographic keys and device boot
parameters [36]. Enterprise IT managers use these attes-
tations to assess the health of devices they manage. A
common use is to gate access to high-value network re-
sources based on its attestations.
Google. Modern versions of Chrome OS [22] use
TPMs for a variety of tasks,
including software and
ﬁrmware rollback prevention, protecting user data en-
cryption keys, and attesting the mode of a device.
Automatic updates enable a remote party (e.g.,
Google) to update the ﬁrmware or the OS of devices
that run Chrome OS. Such devices are vulnerable to “re-
mote rollback attacks”, where a remote attacker replaces
newer software, through a difﬁcult-to-exploit vulnerabil-
ity, with older software, with a well-known and easy-to-
exploit vulnerability. Chrome devices use the TPM to
prevent software updates to versions older than the cur-
rent one.
eCryptfs [14] is a disk encryption system used by
Chrome OS to protect user data. Chrome OS uses the
TPM to rate limit password guessing on the ﬁle system
encryption key. Any attempt to guess the AES keys re-
quires the use of a TPM, a single-threaded device that
842  25th USENIX Security Symposium 
USENIX Association
2
is relatively slow. This prevents parallelized attacks and
limits the effectiveness of password brute-force attacks.
Chrome devices can be booted into one of four dif-
ferent modes, corresponding to the state of the devel-
oper switch and the recovery switch at power on. These
switches may be physically present on the device, or they
may be virtual, in which case they are triggered by cer-
tain key presses at power on. Chrome OS uses the TPM
to attest the device’s current mode to any software run-
ning on the machine, a feature used for reporting policy
compliance.
More details on the additional ways in which Chrome
devices make use of TPMs are described in [22].
2.2 TPM-Based Secure Systems in
Research
[33], TrustVisor
The research community has proposed many uses for
TPMs in recent years.
• Secure VMs for the cloud: Software stacks in typi-
cal multi-tenant clouds are large and complex, and thus
prone to compromise or abuse from adversaries includ-
ing the cloud operators, which may lead to leakage of
security-sensitive data. CloudVisor [58] and Credo [43]
are virtualization-approaches that protect the privacy and
integrity of customer’s VMs on commodity cloud infras-
tructure, even when the virtual machine monitor (VMM)
or the management VM becomes compromised. These
systems require TPMs to attest to cloud customers the
secure conﬁguration of the hosts running their VMs.
• Secure applications, OSs and hypervisors:
Flicker
lever-
age the TPM to provide various (but limited) forms
of runtimes with strong code and data integrity and
conﬁdentiality.
Code running in these runtimes is
protected from the rest of the OS. These systems have
small TCBs because they exclude the bulk of the OS.
• Novel secure functionality: Pasture [30] is a secure
messaging and logging library that provides secure of-
ﬂine data access. Pasture leverages the TPM to pro-
vide two safety properties: access-undeniability (a user
cannot deny any ofﬂine data access obtained by his de-
vice without failing an audit) and veriﬁable-revocation
(a user who generates a veriﬁable proof of revocation
of unaccessed data can never access that data in the fu-
ture). These two properties are essential to an ofﬂine
video rental service or to an ofﬂine logging and revo-
cation service.
[32], Memoir
[41]
rations match the policy.
cTPM [9] extends the TPM functionality across sev-
eral devices as long as they are owned by the same user.
cTPM thus offers strong user identities (across all of her
devices), and cross-device isolated secure storage.
Finally, mobile devices can leverage a TPM to offer
new trusted services [19, 31, 28]. One example is trusted
sensors whose readings have a high degree of authen-
ticity and integrity. Trusted sensors enable new mobile
apps relevant to scenarios in which sensor readings are
very valuable, such as ﬁnance (e.g., cash transfers and
deposits) and health (e.g., gather health data) [48, 56].
Another example is enforcing driver distraction regula-
tions for in-car music or navigation systems [28].
2.3 TPM 2.0: A New TPM Speciﬁcation
The Trusted Computing Group (TCG) recently deﬁned
the speciﬁcation for TPM version 2.0 [54]. This newer
TPM is needed for two key reasons. First, the crypto
algorithms in TPM 1.2 [55] have become inadequate. For
example, TPM 1.2 only offers SHA-1 and not SHA-2;
SHA-1 is now considered weak and cryptographers are
reluctant to use it. Another example is the introduction
of ECC with TPM 2.0.
The second reason is the lack of an universally-
accepted reference implementation of the TPM 1.2 spec-
iﬁcation. As a result, different TPM 1.2 implementations
exhibit slightly different behaviors. The lack of a refer-
ence implementation also keeps the TPM 1.2 speciﬁca-
tion ambiguous. It can be difﬁcult to specify the exact
behavior of cryptographic protocols in English. Instead,
with TPM 2.0 the speciﬁcation is the same as the refer-
ence implementation. The speciﬁcation consists of sev-
eral documents describing the behavior of the codebase,
and these documents are derived directly from the TPM
2.0 codebase, thereby ensuring uniform behavior.
Recently, TPM manufacturers have started to release
discrete chips implementing TPM 2.0. Also, at least one
manufacturer has released a ﬁrmware upgrade that can
update a TPM 1.2 chip into one that implements both
TPM 2.0 and TPM 1.2. Note that although TPM 2.0 sub-
sumes the functionality of TPM 1.2, it is not backwards
compatible. A BIOS built to use a TPM 1.2 would not
work with a TPM 2.0-only chip. A list of differences
between the two versions is provided by the TCG [53].
3 Modern Trusted Computing Hardware
Policy-sealed data [47] relies on TPMs to provide a
new abstraction for cloud services that lets data be sealed
(i.e., encrypted to a customer-deﬁned policy) and then
unsealed (i.e., decrypted) only by hosts whose conﬁgu-
Recognizing the increasing demand for security, mod-
ern CPUs have started to incorporate trusted computing
features, such as ARM TrustZone [1] and Intel Software
Guard Extensions (SGX) [25]. This section presents
USENIX Association  
25th USENIX Security Symposium  843
3
the background on ARM TrustZone (including its short-
comings); this background is important to the design of
fTPM. Later, Section 12 will describe Intel’s SGX and
its shortcomings.
3.1 ARM TrustZone
ARM TrustZone is ARM’s hardware support for trusted
computing.
It is a set of security extensions found
in many recent ARM processors (including Cortex A8,
Cortex A9, and Cortex A15). ARM TrustZone provides
two virtual processors backed by hardware access con-
trol. The software stack can switch between the two
states, referred to as “worlds”. One world is called se-
cure world (SW), and the other normal world (NW).
Each world acts as a runtime environment with its own
resources (e.g., memory, processor, cache, controllers,
interrupts). Depending on the speciﬁcs of an individual
ARM SoC, a single resource can be strongly partitioned
between the two worlds, can be shared across worlds,
or assigned to a single world only. For example, most
ARM SoCs offer memory curtaining, where a region of
memory can be dedicated to the secure world. Similarly,
processor, caches, and controllers are often shared across
worlds. Finally, I/O devices can be mapped to only one
world, although on certain SoCs this mapping can be dy-
namically controlled by a trusted peripheral.
• Secure monitor: The secure monitor is an ARM pro-
cessor mode that enables context switching between the
secure and normal worlds. A special register determines
whether the processor core runs code in the secure or
non-secure worlds. When the core runs in monitor mode
the processor is considered secure regardless of the value
of this register.
An ARM CPU has separate banks of registers for each
of the two worlds. Each of the worlds can only access
their separate register ﬁles; cross-world register access is
blocked. However, the secure monitor can access non-
secure banked copies of registers. The monitor can thus
implement context switches between the two worlds.
• Secure world entry/exit: By design, an ARM plat-
form always boots into the secure world ﬁrst. Here, the
system ﬁrmware can provision the runtime environment
of the secure world before any untrusted code (e.g., the
OS) has a chance to run. For example, the ﬁrmware allo-
cates secure memory for TrustZone, programs the DMA
controllers to be TrustZone-aware, and initializes any se-
cure code. The secure code eventually yields to the nor-
mal world where untrusted code can start executing.
The normal world uses a special ARM instruction
called smc (secure monitor call) to transfer control into
the secure world. When the CPU executes the smc in-
struction, the hardware switches into the secure monitor,
which performs a secure context switch into the secure
world. Hardware interrupts can trap directly into the
secure monitor code, which enables ﬂexible routing of
those interrupts to either world. This allows I/O devices
to map their interrupts to the secure world if desired.
• Curtained memory: At boot time, the software run-
ning in the secure monitor can allocate a range of phys-
ical addresses to the secure world only, creating the ab-
straction of curtained memory – memory inaccessible to
the rest of the system. For this, ARM adds an extra con-
trol signal for each of the read and write channels on the
main memory bus. This signal corresponds to an extra
bit (a 33rd-bit on a 32-bit architecture) called the non-
secure bit (NS-bit). These bits are interpreted whenever
a memory access occurs. If the NS-bit is set, an access
to memory allocated to the secure world fails.
3.2 Shortcomings of ARM TrustZone
Although the ARM TrustZone speciﬁcation describes
how the processor and memory subsystem are protected
in the secure world and provides mechanisms for secur-
ing I/O devices, the speciﬁcation is silent on how many
other resources should be protected. This has led to frag-
mentation – SoCs offer various forms of protecting dif-
ferent hardware resources for TrustZone, or no protec-
tion at all. While there may be major differences between
the ARM SoCs offered by different vendors, the observa-
tions below held across all the major SoCs vendors when