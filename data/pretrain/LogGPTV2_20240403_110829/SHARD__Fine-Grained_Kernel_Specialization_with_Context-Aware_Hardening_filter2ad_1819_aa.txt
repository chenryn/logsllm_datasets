title:SHARD: Fine-Grained Kernel Specialization with Context-Aware Hardening
author:Muhammad Abubakar and
Adil Ahmad and
Pedro Fonseca and
Dongyan Xu
SHARD: Fine-Grained Kernel Specialization with Context-Aware Hardening
Muhammad Abubakar
Adil Ahmad
Pedro Fonseca
Dongyan Xu
Department of Computer Science and CERIAS, Purdue University
{mabubaka, ahmad37, pfonseca, dxu}@purdue.edu
Abstract
With growing hardware complexity and ever-evolving user re-
quirements, the kernel is increasingly bloated which increases
its attack surface. Despite its large size, for speciﬁc applica-
tions and workloads, only a small subset of the kernel code
is actually required. Kernel specialization approaches exploit
this observation to either harden the kernel or restrict access to
its code (debloating) on a per-application basis. However, ex-
isting approaches suffer from coarse specialization granularity
and lack strict enforcement which limits their effectiveness.
This paper presents SHARD, a practical framework to en-
force ﬁne-grain kernel specialization. SHARD specializes at
both the application and system call levels to signiﬁcantly
restrict the kernel code exposed to attackers. Furthermore,
SHARD introduces context-aware hardening to dynamically
enable code hardening during suspicious execution contexts.
SHARD implements an instance of a context-aware hardening
scheme using control-ﬂow integrity (CFI), which provides
near-native performance for non-hardened executions and
strong security guarantees. Our analysis of the kernel attack
surface reduction with SHARD as well as concrete attacks
shows that SHARD exposes 181× less kernel code than the
native kernel, an order of magnitude better than existing work,
and prevents 90% of the evaluated attacks. Our evaluation
shows that the average performance overhead of SHARD on
real-world applications is moderate—10% to 36% on NG-
INX, 3% to 10% on Redis, and 0% to 2.7% on the SPEC CPU
2006 benchmarks.
1 Introduction
Operating system kernels have seen an exponential growth
during the last two decades. The Linux kernel, for instance,
grew from 2.4 million [15] lines of source code in 2001 to
a staggering 27.8 million lines of source code in 2020 [14].
This growth is in large part a consequence of an increasingly
diverse range of functions (e.g., supporting many devices) im-
plemented by modern kernels. Unfortunately, because larger
kernels increase the trusted computing base (TCB), systems
have become increasingly vulnerable to attacks that exploit
kernel defects to take complete control of the machine.
A promising approach to minimize any software codebase
is by specialization through debloating [21, 31, 47, 50], which
retains a small part of the codebase required for speciﬁc work-
loads and prevents the rest of the code from running. In the
context of the kernel, debloating the kernel code for speciﬁc
applications [30, 36], can reduce the kernel code to 8.89% of
its native size and prevent attackers from exploiting many ker-
nel vulnerabilities without hindering application functionality.
However, because kernels are so large, even such kernel code
reduction leaves vulnerable a signiﬁcant part of the kernel,
which can be exploited by attackers.
This paper proposes, SHARD, a practical framework for
dynamic kernel specialization that implements ﬁne-grained
specialization. Unlike previous work that limits the granu-
larity of specialization to the application level, SHARD goes
signiﬁcantly beyond by specializing the kernel at the system
call level for each target application, which further constraints
the amount of kernel code that an attacker can leverage. As
a result, SHARD exposes 181× less kernel code, on average,
than the native linux kernel, which is an order of magnitude
better than existing work on kernel debloating [30].
At a high-level, SHARD ﬁrst identiﬁes the kernel code re-
quired to execute a system call by a speciﬁc application and
then, during run-time, it ensures that only that kernel code is
allowed to run when the application invokes the same system
call. By proﬁling Linux with real-world applications, we con-
cluded that in the majority of cases, two system calls share
less than half of the kernel code that they execute. This low-
overlap is expected because the kernel implements several
classes of services (e.g., ﬁle operations, network operation,
process management) using distinct code. Hence, ﬁne-grained
specialization, at the system call and application-level, signiﬁ-
cantly reduces the amount of kernel code exposed to attackers
at any given point.
In addition to employing ﬁne-grained specialization,
SHARD also addresses the challenge of identifying the parts of
the kernel that a system call, invoked by a speciﬁc application,
should be allowed to execute, i.e., the kernel coverage of sys-
tem calls. Dynamic proﬁling of applications [30,36–38,53,62]
and static program analysis techniques [29,42,56,61] are com-
mon techniques used to identify the coverage of legitimate
execution (e.g., code that does not subvert the control-ﬂow
of the kernel) but these techniques are either incomplete or
unsound when applied to complex systems, such as the kernel.
As a result of these limitations, prior specialization techniques
compromise the security guarantees by either (a) only log-
ging executions that reach unexpected code [30], instead of
strictly enforcing specialization, which makes them ineffec-
tive at preventing attacks, or (b) overestimating the code that
should be allowed to execute, which signiﬁcantly increases
the amount of code that attackers can use.
SHARD implements context-aware hardening, a new tech-
nique to address the limitations of program analysis and dy-
namic proﬁling techniques on complex code, such as kernels.
Context-aware hardening dynamically hardens kernel code for
suspicious executions, i.e., proﬁling or static analysis could
not determine that the execution should be allowed or not.
Because kernel code that falls under this class, even though
representing more than half of the kernel, only rarely executes,
context-aware hardening is a low-cost solution, unlike full-
system hardening, that enables strict debloating enforcement.
Context-aware hardening allows SHARD to dynamically
switch between hardened and non-hardened code according
to the specialization policy during a system call execution.
SHARD implements a speciﬁc context-aware hardening mech-
anism using ﬁne-grained control-ﬂow integrity (CFI) [20].
However, dynamic switching between CFI hardened and non-
hardened code versions is challenging. First, CFI uses integer-
based indexing at indirect call sites instead of function point-
ers, which must be consistent with non-hardened code ver-
sions to allow switching; therefore, non-hardened execution
would also be impacted (i.e., up to 40% overhead [29]). Sec-
ond, the switch from non-hardened to hardened code execu-
tion requires a special CFI check; since non-hardened code
does not ensure CFI during the transition. SHARD deals with
these challenges through a modiﬁed CFI instrumentation,
which relies on function addresses, and a custom CFI check
using Last Branch Record (LBR), ensuring secure transitions
from non-hardened to hardened code execution.
SHARD relies on an ofﬂine analysis, to determine kernel
coverage, and an online phase, during which the system is
protected. During the ofﬂine analysis, SHARD analyzes the
kernel to determine per-system call code coverage (i.e., re-
quired kernel code) for speciﬁc, benign application workloads.
SHARD achieves this using two program analysis approaches
— dynamic proﬁling, which may under-approximate coverage,
and static analysis, which may over-approximate the coverage.
During the online phase, SHARD uses a VMX-based mon-
itor to transparently enforce kernel debloating and context-
aware hardening. Importantly, SHARD does not require man-
Spec.
S A Ratio
Protection
Strict
Type
Kernel
Instr. Overhead
Coarse CFI* Manual
3-40%
Manual 200-2400%
Isolation
N/A
N/A
 
 
Specialized hardening
SplitKernel [39]
Full
ProxOS [52]
N/A
Dynamic debloating
FACECHANGE [30]   11.3×
  11.3×
Multi-K [36]
Static debloating
  4-5×
Kurmus et al [38]

  6.5-7.5× 
Kuo et al [37]
  181×
SHARD [this work]


Debl.
Debl.
Debl.
Debl.
Auto
Manual
Manual
N/A
0-40%
0-0.5%
0%
0%
3-36%
 Debl. + Fine CFI* Auto
Table 1: Comparison of SHARD with prior kernel specialization
work. Table compares the granularity of specialization ("Spec"), sys-
tem call-level ("S") and application-level ("A"); Ratio, strictness and
type of kernel protection; kernel instrumentation required; and the
application overhead. SplitKernel [39] implements stack exhaustion
and stack clearance checking, alongside coarse CFI, as hardening.
SHARD implements Fine CFI according to the context-aware policy.
ual modiﬁcations to the kernel source code, instead it employs
compile-time instrumentation to transparently introspect ker-
nel state required by the specialization policies.
We evaluated SHARD’s effectiveness on two popular appli-
cations, the Redis key-value store and the NGINX web server.
Our evaluation shows that SHARD reduces, on average, the
number of kernel instructions accessible to 0.49% for Redis
and 0.60% for NGINX, compared to the native Linux kernel.
Similarly, the number of ROP gadgets is reduced to 0.55%
and 0.60% respectively. In addition, SHARD protects the ker-
nel against 90% of the attack scenarios in our experiments by
preventing the execution of the vulnerable code or the exploit
payload. We found that the average overhead of SHARD is
only 3-10% across the redis-benchmark test suite for Redis
and 10-36% across varying request sizes for NGINX, despite
reducing the code by 181×, an order of magnitude better than
previous work and strictly enforcing specialization. Finally,
on the SPEC CPU integer workloads, we observe a small
overhead of only 0-2.7%.
This paper makes the following main contributions:
• Fine-grained specialization, a kernel specialization
scheme that operates at the system call and application
level to increase specialization effectiveness.
• Context-aware hardening, a general approach to selec-
tively harden code during system calls to provide strict
and efﬁcient specialization enforcement.
• The design of SHARD, the ﬁrst ﬁne-grained specializa-
tion framework for commodity unmodiﬁed kernels.
• An evaluation of SHARD on real-world applications and
real-world exploits and vulnerabilities.
The rest of the paper is organized as follows: §2 provides
background on kernel specialization and motivates SHARD.
§6 describes the threat model of SHARD. §7 and §8 describe
the design and implementation of SHARD. §9 provides a secu-
limits their effectiveness.
Coarse specialization. Existing kernel hardening and de-
bloating specialization approaches are coarse because they
only create a single kernel-view for the entire application.
As a result, existing approaches do not prevent a system call
invocation from using the kernel code that should only be ac-
cessed through other system calls by the application. Hence,
they have a low protection ratio (i.e., the ratio of baseline
to exposed instructions) that unnecessarily exposes a large
quantity of code for attack purposes.
To demonstrate the security impact of this limitation, we
devise an experiment employing single-view kernel special-
ization for two popular applications, the NGINX [16] web
server and the Redis [17] key-value store. In this experiment,
the applications can only access the required kernel code, as
determined through dynamic proﬁling of application work-
loads (refer to §7.2 for the proﬁling details). Figure 1 shows
what portion of the entire proﬁled kernel code is executed by
the system calls invoked by NGINX and Redis. The results
show that in both applications 80% of the system calls utilize
less than 15% of the proﬁled kernel code at a time. This result
demonstrates that further restricting which code can execute
given the application proﬁle and the system call context can
signiﬁcantly reduce the available code for attacks.
Limited debloating enforcement. Kernel debloating tech-
niques require an accurate analysis phase (refer to §2) to pro-
vide strict debloating enforcement within the kernel. However,
program analysis techniques are not complete and accurate
on complex code, such as kernel code which extensively uses
aliasing [22, 29, 42, 44, 56, 61], so they either under-estimate
or over-estimate the kernel code required by the target appli-
cations. Existing schemes that under-estimate do not strictly
enforce debloating [30, 36] but instead log suspicious execu-
tions, which does not prevent attacks and is hard to diagnose.
In contrast, existing schemes that over-estimate allow strict
enforcement but offer reduced debloating ratio and hence,
limited effectiveness [37, 38].
In general, existing schemes analyze the kernel for debloat-
ing specialization either using (a) static call graph generation
or (b) dynamic workload-based proﬁling. The static tech-
nique constructs a call graph of the kernel and identiﬁes the
kernel code that is reachable for each system call. However,
this technique fails to precisely resolve indirect call sites
(e.g., function pointers) and data-dependent paths; therefore,
it over-estimates the required kernel code and might allow
illegitimate executions during run-time.
On the other hand, dynamic proﬁling executes a represen-
tative application workload (e.g., test suites and benchmarks)
and traces all kernel code executed by the workload. However,
the proﬁled code coverage of such workloads is only 6% to
73% of the application’s code [36]. Therefore, at run-time,
an application might trigger a system call path that was not
proﬁled but is legitimate. Existing approaches do not provide
Figure 1: Distribution of instructions executed by each system call
made by Nginx and Redis. Numbers are normalized to the total
number of instructions required by each application and system calls
are sorted from highest to lowest.
rity analysis. §10 discusses the performance evaluation.§11,
§12 and §13 discuss limitations, related work, and conclude.
2 Background on Kernel Specialization
Kernel specialization approaches to improve system security
rely on either hardening [39, 52] or debloating (i.e., mini-
mizing) [30, 36, 36, 38, 62]. Hardening approaches generate
two versions of the kernel and during run-time ensure that
untrusted applications (i.g., target applications) use the hard-
ened version of the kernel while trusted application use the
native kernel version, without performance overhead.
Debloating approaches only allow the execution of kernel
code that a certain application, or group of applications, re-
quires. The remaining code of the kernel is either completely
removed statically [37, 38, 53], retained in the binary but ob-
fuscated [30], or made inaccessible at run-time [36, 62]. By
minimizing the accessible code, debloating reduces the attack
surface for code reuse attacks [47, 50], i.e., attacks reusing
existing code sequences such as ROP gadgets [49], and can
generally reduce vulnerabilities in software [21, 36, 37].
Previous debloating work enforces kernel specialization
either at compile-time [37, 38, 53] or run-time [30, 36, 62].
Both approaches rely on an analysis phase to identify rele-
vant kernel code for a set of applications, by executing the
applications under representative workloads or by using static
analysis techniques, such as control-ﬂow graph analysis. After
analysis, compile-time approaches statically compile a cus-
tom conﬁgured kernel containing only the required kernel fea-
tures. While run-time approaches create multiple versions of
the kernel (e.g., one kernel version for each target application)
and dynamically switch the system’s kernel-view whenever
the executed application changes.
2.1 Limitations of Existing Approaches
Despite extensive work on specialization techniques [30, 36–
38, 53, 62], existing kernel specialization techniques, as sum-
marized in Table 1, are limited to coarse specialization and
do not provide strict debloating enforcement, which seriously
0.00.20.40.60.81.0SystemCalls01020304050RequiredInstructions(%)NginxRedisstrict enforcement in such cases (i.e., only log suspicious ex-
ecution paths for ofﬂine analysis [30]). Hence, a potentially
reachable code path is exploitable.
3 Fine-grained System Call Specialization
SHARD employs ﬁne-grained specialization by providing dif-
ferent kernel-views depending on the application running
and the currently executing system call. Since the kernel im-
plements unique system calls for distinct services, such as
process management and device I/O, system calls providing
orthogonal services do not share much code with each other.
Hence, by specializing the kernel-view for an application at
each system call, the amount of kernel code exposed to the
attacker at any point is signiﬁcantly reduced which further
restricts the attacker’s ability to construct ROP chains and
exploit vulnerabilities.
To validate ﬁne-grained specialization, consider the assem-
bly instruction overlap between the top 10 system calls with
largest coverage, invoked by NGINX and Redis during proﬁl-
ing, shown in Table 2. We observe that system calls providing
distinct services do not share much kernel code. For exam-
ple, in the case of Redis, read, which implements ﬁle and
network I/O operations, shares only 6.8% (4.9k out of 72.1k)
of its instructions with exit_group, which exits all process
threads. Similarly, in case of NGINX, recvfrom which re-
ceives network packets, shares only 9.6% (5.1k out of 53k) of
its instructions with write, which writes to local ﬁle. Given
the disparity in kernel code coverage across system calls,
system call-level specialization provides an opportunity to
signiﬁcantly reduce exposure to attacks.
However, a system call-only specialization (i.e., agnostic