title:CAROL: Confidence-Aware Resilience Model for Edge Federations
author:Shreshth Tuli and
Giuliano Casale and
Nicholas R. Jennings
CAROL: Conﬁdence-Aware Resilience Model for
Edge Federations
Shreshth Tuli∗, Giuliano Casale∗ and Nicholas R. Jennings∗†
∗Department of Computing, Imperial College London, UK
Emails: {s.tuli20, g.casale}@imperial.ac.uk, PI:EMAIL
†Loughborough University
2
2
0
2
r
a
M
4
1
]
C
D
.
s
c
[
1
v
0
4
1
7
0
.
3
0
2
2
:
v
i
X
r
a
Abstract—In recent years, the deployment of large-scale Inter-
net of Things (IoT) applications has given rise to edge federations
that seamlessly interconnect and leverage resources from multiple
edge service providers. The requirement of supporting both
latency-sensitive and compute-intensive IoT tasks necessitates ser-
vice resilience, especially for the broker nodes in typical broker-
worker deployment designs. Existing fault-tolerance or resilience
schemes often lack robustness and generalization capability in
non-stationary workload settings. This is typically due to the
expensive periodic ﬁne-tuning of models required to adapt them
in dynamic scenarios. To address this, we present a conﬁdence
aware resilience model, CAROL, that utilizes a memory-efﬁcient
generative neural network to predict the Quality of Service (QoS)
for a future state and a conﬁdence score for each prediction.
Thus, whenever a broker fails, we quickly recover the system by
executing a local-search over the broker-worker topology space
and optimize future QoS. The conﬁdence score enables us to
keep track of the prediction performance and run parsimonious
neural network ﬁne-tuning to avoid excessive overheads, further
improving the QoS of the system. Experiments on a Raspberry-
Pi based edge testbed with IoT benchmark applications show
that CAROL outperforms state-of-the-art resilience schemes by
reducing the energy consumption, deadline violation rates and
resilience overheads by up to 16, 17 and 36 percent, respectively.
Index
Terms—Edge
Federations;
Service Resilience;
Conﬁdence-Aware; Generative Models; Deep Learning
I. INTRODUCTION
The ﬁfth industrial revolution, named Industry 5.0, marks a
signiﬁcant shift in the technological backbone of industrial
applications such as the Internet of Things (IoT) and Artiﬁ-
cial Intelligence (AI) [1]. It allows end-to-end integration of
sensors and actuators close to the user with geographically
distributed servers via a large number of intermediary smart
edge nodes [2]. Such frameworks enable the deployment of
latency-critical and compute-intensive AI-based IoT applica-
tions on edge devices for low response time and large-scale
service delivery. It achieves this by the collective adoption of
edge federations that bring together the software, infrastructure
and platform services of multiple edge computing environ-
ments. Unifying the computational devices of multiple service
providers enables such paradigms to accommodate sudden
spikes in user demands [3]. However, due to the distributed
nature of such environments, centralized management of their
resources is susceptible to service downtimes in high workload
settings. Thus, most edge federations employ a broker-worker
1
topology with multiple broker nodes managing the system [4].
Here, the brokers receive tasks from the users and delegate
processing to one of the worker nodes within their control,
referred to as local edge infrastructures (LEIs). This leads the
processing bottlenecks in such systems, i.e., the broker nodes,
play a vital part in resilient service delivery.
Challenges. The key challenge addressed in this paper is
dealing with the diverse effects of byzantine node failures,
such as increased task response time and violations of Service
Level Objectives (SLOs), requiring different remediation steps
to maintain system performance and reduce service downtime.
This is motivated by the excessive load that AI-based IoT
applications put on the limited computational capacity and
working memory (up to 8GB) of edge devices [5]. Higher
computational
load translates to increased task processing
times and SLO violation rates. Excessive memory load is
typically dealt with using storage mapped virtual memory,
which in most settings is a network-attached disk [6]. This
also leads to higher response times due to time-consuming
data transfers over congested backhaul edge networks [7]. All
these issues lead to persistent resource contention and faulty
behavior that adversely affects system QoS. Furthermore,
without resource intensive cloud backends to rely on in edge
federations, it becomes challenging to deploy modern deep
learning based management solutions in resource constrained
edge devices. In typical broker-worker federations, if a worker
node fails, a broker could act as a worker and complete the
task or allocate the same task to another worker [4], [8],
[9]. However, if a broker fails, all active tasks within the
LEI and all incoming tasks that are sent to the broker are
impacted. This makes broker resilience crucial in large-scale
deployments. However, the problem of broker resilience is
hard as maintaining hot-redundancy by replicating running
task instances makes edge nodes more susceptible to fail-
ures [10]. The difﬁculty primarily arises from the critical need
for result delivery with low latency and high accuracy [11]. A
vital parameter that controls this is the number of brokers in
the system. For a ﬁxed number of devices in the system, a high
broker count translates into having fewer workers, reducing the
average throughput of the system. Low broker count can cause
bottlenecks and contentions, increasing fault frequency. So we
need to consider both the increase or decrease of the number
of brokers in the system. Furthermore, the statistical moments
and correlations of the workload characteristics are non-
stationary and vary over time, requiring continuous steps to
adapt management models. This imposes additional overheads
and impacts QoS [12].
Existing solutions. Many recent works [13], [18]–[20]
aim to provide effective fault tolerance or system resilience
by leveraging heuristics, meta-heuristics or AI models. The
heuristic and meta-heuristic methods often perform poorly
in dynamic settings where workload characteristics and SLO
demands are non-stationary [19], [20]. AI-based methods typi-
cally utilize reinforcement learning (RL) or neural networks as
surrogate models to predict future system states and estimate
their QoS. The predicted QoS values indicate the chances
of future broker or worker breakdowns and proactively man-
age the broker-worker topology to avoid service downtimes.
These methods leverage fault-aware scheduling [17], pre-
emptive migration based load-balancing [18] or auto-scaling
techniques [20]. RL or surrogate models trained on large
datasets enable such techniques to be effective even in unseen
settings by exploration and neural network ﬁne-tuning. This
is a process where the model utilizes the data generated
during execution to update the neural network parameters
in an online fashion. However, these solutions have several
limitations. Most AI-based approaches are designed for cloud
setups with GPUs for faster training of the underlying neural
networks and result generation [23]. To deploy these models in
resource-constrained edge settings, various model compression
and parameter neural network splitting are required, adversely
impacting their performance [6]. This also impacts the periodic
model ﬁne-tuning, increasing the training times in distributed
neural network settings [24]. Together, these factors mean that
neural network ﬁne-tuning process consumes large portions of
the computational and memory resources of edge devices. This
impacts the execution of the management tasks running in the
broker nodes, further leading to contentions in broker nodes.
To resolve this, there is a need for a lightweight solution that
parsimoniously ﬁne-tunes AI methods.
Key insights and our contributions. For a lightweight
broker resilience model, we develop a method that uses a
neural network to predict system QoS and also indicates when
to ﬁne-tune the network to adapt to non-stationary settings.
The novel insight is using a generative network as a surrogate
model to optimize QoS. Unlike prior work that use traditional
feed-forward or recurrent neural networks to predict QoS [17],
[19], using speciﬁc generative models not only allows us to
estimate QoS of future states, but also an indicator of the
prediction conﬁdence. Examples of such a generative network
with low memory footprint are recently-proposed models by
the AI theory community such as Generative Optimization
Networks (GONs) [25] or SpareVAEs [26], which provide an
alternative to Generative Adversarial Networks (GANs) [27]
or Variational Auto-encoders (VAEs) [28] with much lower
memory footprint and therefore suitable for edge execution.
Models with a reduced footprint of this kind pave the way to
the use of GAN-type methods in edge devices with resource
footprint constraints. In our recent work [29], we have demon-
strated an application of GONs to decentralized fault-tolerance
ﬁnding up to 82% improvement in service-level compliance
when a local edge infrastructure runs a GON in its broker to
detect faults within its edge devices. Contrary to that work, we
focus here instead on the application of GONs to the problem
of broker resilience, which is not touched upon in [29].
In the proposed work, an ofﬂine trained GON model with
labelled data generated from a system with similar behavior
as that of the training dataset would typically give high
conﬁdence scores, whereas as the system behavior changes,
the conﬁdence score declines (more details in Section III). Dy-
namic thresholding techniques allow us to decide conﬁdence
thresholds below which we ﬁne-tune the network parameters.
Thus, we only run ﬁne-tuning measures when required, sig-
niﬁcantly reducing overheads and improving system QoS. In
this work we present CAROL: Conﬁdence Aware Resilience
Model for edge federations. CAROL is the ﬁrst system that
uses a GON in edge brokers to reactively run topology
optimization to optimize system QoS. The GON model is
trained using log traces on DeFog benchmarks [30]. Extensive
experiments on a Raspberry-Pi based federated edge cluster
show that CAROL performs best in terms of QoS metrics.
To test the generalization of the model, we test on different
benchmarks as workloads, namely AIoT [31]. Speciﬁcally,
CAROL reduces energy consumption, SLO violation rates
and resilience overheads by up to 16, 17 and 36 percent,
respectively, compared to state-of-the-art baselines.
II. RELATED WORK
We list in Table I the prior work, dividing such methods into
two classes: heuristic and meta-heuristic methods (rows 1-5
of Table I) and AI-based methods (rows 6-10). Many of these
methods use simple strategies to deal with broker failures or
are unable to efﬁciently adapt in non-stationary environments.
Heuristic and Meta-heuristic methods. Most fault pre-
vention techniques for cloud and edge computing employ
some form of heuristics or meta-heuristic approaches. Methods
like DYVERSE [13] use dynamic vertical scaling in multi-
tenant edge systems to manage resources assigned to IoT
applications to improve scalability. It uses an ensemble of three
heuristics (system-aware, community-aware and workload-
aware) to dynamically allocate priority scores to the active
applications in the system. DYVERSE uses AI-based face
detection and online game workload to validate in a controlled
edge computing environment. However, for broker failures, it
allocates the worker with the least CPU utilization as the next
broker of the same LEI. Federated Distributed MapReduce
(FDMR) [16] is another MapReduce based framework that
uses integer linear programming for fault-tolerant distributed
task scheduling. Another approach, namely Distributed IoT
Service Provisioning (DISP) [14] technique, balances load
across edge and fog nodes by comparing CPU utilization and
response time metrics for each node. However, due to the
modeling limitations, such methods do not scale for real-time
operations, making them unsuitable for mission-critical edge
applications. A similar approach, Load Balancing Mechanism
2
COMPARISON OF RELATED WORKS WITH DIFFERENT PARAMETERS ((cid:88)MEANS THAT THE CORRESPONDING FEATURE IS PRESENT).
TABLE I
Work
IoT
Approach
DYVERSE [13]
DISP [14]
LBM [15]
FDMR [16]
ECLB [17]
LBOS [18]
ELBS [19]
FRAS [20]
TopoMAD [21]
StepGAN [22]
CAROL
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
Heuristic
Heuristic
Heuristic
Meta-Heuristic
Meta-Heuristic
RL
Surrogate Model
Surrogate Model
Reconstruction
Reconstruction
Surrogate Model
Consider Broker
QoS
Performance parameters