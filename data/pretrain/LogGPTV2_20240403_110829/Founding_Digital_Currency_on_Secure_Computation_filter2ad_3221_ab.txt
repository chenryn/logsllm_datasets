The parties involved in PDC are the n Ledger Servers
S1, . . . , Sn, the Identity Veri(cid:12)cation Server(s), V , and the
users; an individual user is denoted U . For the protocols
used in this paper, the threshold of corruption for the Ledger
Servers is t  2γ+κ,
where γ is the number of bits needed to represent the total
amount of coins in circulation and κ is a security parameter.
We use both Shamir single secret sharing [42] and Franklin-
Yung batch sharing [28]. To share a single secret s, a party
selects a degree t polynomial that is uniformly random sub-
ject to f (0) = s and sends to each server Si the point f (i).
To batch-share a collection of secrets s(1), . . . , s(ℓ), a party
selects a polynomial g of degree d = ℓ + t − 1 such that
g(−k) = s(k) for k = 1, . . . , ℓ and g(−ℓ − k) is random for
k = 1, . . . , t, and then sends to each server Si the point g(i).
We set the batch size ℓ to n − 3t.
For both single secret sharing and batch sharing, the Berle
kamp-Welch algorithm [5] is used to interpolate polynomials
whenever interpolation is needed in the proposed protocols.
We assume a public key signature and encryption scheme.
The operations of encrypting using key K and signing us-
ing the private key corresponding to K are denoted EncK
and SigK . By abuse of notation, we write SigV to denote
signatures using party V ’s private key. We assume secure,
authenticated channels between all parties, as well as an
authenticated broadcast channel. In practice, a broadcast
channel would likely be implemented via a broadcast proto-
col; our timing analysis in the full version [23] assumes t + 1
3communication rounds for broadcast, which can be achieved
using, e.g., the broadcast protocol in [29].
The PDC scheme requires the use of cryptographic proto-
cols from the MPC literature. In particular, it requires a pro-
tocol for secret sharing (denoted Share), for generating secret
sharings of random values (Random), for generating secret
sharings of zero values (Zero), for multiplying shared val-
ues (Mult), for publicly opening sharings (Open), for proac-
tively refreshing secret sharings (Refresh, see details in Sec-
tion 3.4.3), and for secure comparison (Compare). Except
for secure comparison, we require protocols that can per-
form these operations with both single-sharings and batch-
sharings. The batch sharing versions of the protocols will be
subscripted with B (i.e., the protocol for generating a batch
sharing of all zeros is ZeroB). Any protocols that perform
these tasks will work for PDC, so long as the corruption
threshold for the protocols is not lower than t and the pro-
tocols are unconditionally secure.3 In particular, we could
use the comparison protocol of [24], the proactive refresh
protocol of [4], and use [21] for the other protocols. There
is no Zero protocol in [21], but the secret sharing protocol
in [21] can be modi(cid:12)ed to do this. The protocols in [21] are
for single secret sharings, but they can easily be modi(cid:12)ed to
work with batch sharings.
3.3 Adversary Model
We assume a fully malicious adversary that corrupts the
Ledger Servers in a Byzantine manner, i.e., corrupted Ledger
Servers may behave arbitrarily. The adversary is mobile so
any number of Ledger Servers may be corrupted over the
course of the protocol. The adversary is limited in how
many Ledger Servers may be corrupt at any one time as
follows: The computation is divided into phases. The pe-
riod between consecutive executions of the proactive refresh
protocol is one phase; the refresh protocol itself is considered
to be in both adjacent phases. The adversary is allowed to
corrupt and decorrupt Ledger Servers at will, so long as no
more than t Ledger Servers are corrupted in any phase. See
section 3.4.3 for a discussion of how long term security is
maintained against a mobile adversary.
We assume that the Identity Veri(cid:12)cation Server is always
passively corrupted, but never maliciously corrupted; this is
necessary to guarantee that users cannot generate addresses
without providing valid identities. Any number of users may
be statically corrupted, meaning that the adversary decides
at the outset of the protocol which users she wants to cor-
rupt, and cannot corrupt users during protocol execution.
3.4 Ledger Details
3.4.1 Overview of Ledger
We require two ledgers to be maintained by the Ledger
Servers. The (cid:12)rst ledger keeps track of the balance in each
address, and the second records transaction history; these
are called the balance ledger and transaction ledger, respec-
tively.
For the balance ledger, an individual entry for Ledger
Server Si will be of the form (A, D(i), b(i), c), where A is
the address, D(i) is a share of the identity associated with
the address, b(i) is a share of the current balance stored in
the address, and c is a counter that keeps track of how many
3By \unconditionally secure," we mean that the protocols
do not make any computational hardness assumptions.
transactions have been sent from address A (not counting
transactions to A). The counter c is used when transferring
coins to prevent double-spending attacks.
Entries in the transaction ledger are stored in one of two
formats. Initially, the transaction values are shared among
the Ledger Servers using normal single secret sharing. Once
the number of secret-shared ledger entries is at least ℓ, groups
of ℓ secret sharings are converted into individual batch shar-
ings of size ℓ. Batch sharing reduces the amount of data the
Ledger Servers need to store, and considerably reduces the
cost of proactively refreshing the transaction ledger. Details
of the conversion from secret sharings to batch sharings are
given in Section 3.4.3. The protocol that achieves such con-
version is one of the main contributions of this paper and
can be used in other secure computation contexts.
An individual secret-shared transaction ledger entry for
Ledger Server Si will be of the form (Afrom, Ato, c, B, s(i)),
where Afrom is the sending address, Ato is the receiving ad-
dress, c is a counter indicating that this was the cth trans-
action from address Afrom, B is the number of the block
in which the transaction was processed, and s(i) is a share
of the amount sent. An individual batch-shared transac-
tion ledger entry for Ledger Server Si will be of the form
{(A(k)
to , c(k),
B(k)) is the data corresponding to the transaction value
stored in batch location k in the polynomial s.
to , c(k), B(k))}ℓ
from, A(k)
(
)
k=1, s(i)
, where (A(k)
from, A(k)
3.4.2 Ledger Server Synchronization and Communi-
cation
Most existing secret sharing and MPC protocols assume
a synchronous network setting. Real computer networks,
such as the Internet, are asynchronous; synchronous proto-
cols can work in an asynchronous setting assuming loosely
synchronized clocks and bounded message delays, as shown
in [33]. Any institution operating a Ledger Server will (pre-
sumably) have ample technological resources to provide ac-
curate clocks and bandwidth su(cid:14)cient to ensure messages
arrive in a timely manner. However, there is no way to guar-
antee even loose synchrony on the part of the clients that use
PDC. To coordinate Ledger Servers with clients, data from
clients will be collected into blocks. There is a (cid:12)xed time
interval, M , that de(cid:12)nes the length of each block of data.
Assuming the operation of the system begins at time zero,
the data an individual Ledger Server receives between times
0 and M goes into the (cid:12)rst block, and in general, the data
received between times (T − 1) · M and T · M goes into the
T th block. Once the Ledger Servers (cid:12)nish collecting data
for an individual block, they broadcast the contents of their
block to all the other Ledger Servers.
If one of the Ledger Servers receives a secret share of some
data, it will need to be sure that a su(cid:14)cient number of the
other servers have received shares of the same data before
processing that data. So when the Ledger Servers broad-
cast their blocks of data, each will look at the blocks of the
other Ledger Servers to determine if enough of the shares
have been received by the servers.
If enough shares have
been received, the Ledger Servers will process the data in a
synchronous fashion.
We assume that the delay for transmission from user to
Ledger Server is less than M (which we assume to be a
couple of seconds). In the case that network latency or ma-
licious intent causes the client’s shares to arrive at di(cid:11)erent
4servers at di(cid:11)erent times, the delay may be enough that the
shares are collected into the T th block for some servers and
the (T + 1)th block for other servers. To account for this
possibility, messages will not be processed in the (cid:12)rst block
in which they are broadcast. Instead, they will be carried
over into the next block and re-broadcast. Messages cannot
be retained inde(cid:12)nitely, so no message is broadcast in more
than 2 (consecutive) blocks for an individual Ledger Server.
If a Ledger Server broadcasts a message in two consecutive
blocks, and there are still not enough shares from the other
Ledger Servers in the second block, the message is deleted.
Due to the lack of synchrony between the users and the
Ledger Servers, each protocol that the user engages in with
the Ledger Servers is broken into two protocols: a user
part and a server part. When the user wants to perform
some action, she runs the user protocol. The servers col-
lect messages from users as a part of the main protocol,
the Ledger Server Loop described in Section 3.7. When the
user’s data is broadcast in a block, the servers then engage
in the server part of the protocol. We use a subscript of
U to denote the user part of the protocol and a subscript
of S to denote the server part of the protocol. So for in-
stance, when a user wants to initialize an address, the user
runs Initialize AddressU ; once the Ledger Servers are ready to
process the received data, they run Initialize AddressS. We
refer to the two protocols together as Initialize Address.
3.4.3 Ensuring Long-term Conﬁdentiality by Proac-
tively Refreshing the Ledgers
In standard multiparty computation protocols, it is as-
sumed that an adversary can corrupt no more than a (cid:12)xed
fraction of the parties performing the computation. How-
ever, it is more realistic to assume that a sophisticated ad-
versary could eventually corrupt every party given a long
enough period of time. In the proactive security model, an
adversary can corrupt any number of parties, but can only
corrupt a (cid:12)xed fraction in any given time; such an adversary
is called a mobile adversary in [38]. Since safeguarding the
ledger of a digital currency is highly critical, we argue that
one should design the ledger to be secure in the proactive
security model.
Protocols for proactively refreshing shared secrets proceed
in two phases. In the (cid:12)rst phase, a secret s shared with a
polynomial P (such that P (0) = s) is updated by setting
P ← P + Q, where Q is a polynomial of the same degree as
P which is random subject to the constraint that Q(0) = 0.4
Thus if an adversary learns no more than a threshold num-
ber of shares for the old P , this will give her no information
about the secret when combined with shares of the new P ,
because the shares are independently distributed. In the sec-
ond phase, parties who had previously been corrupted and
may have lost or corrupted data (either due to alteration of
memory by malware or by a hard reboot to remove malware)
recover the lost shares by interacting with the other parties.
There are multiple proposals for proactive refresh schemes
[30, 41, 4]. We provide an instantiation of PDC with the
scheme from [4], as it only assumes secure channels, whereas
the other two schemes use the discrete logarithm assump-
tion. Although in practice secure channels would be imple-
mented with a public key infrastructure (PKI), we would like
to assume only a generic PKI instead of discrete logarithm-
4If P is a batch sharing, then Q will be a sharing of a batch
of all zeros.
based PKI. When refreshing the ledger we utilize the pro-
tocol from [4] (called Block-Redistribute) with a threshold of
t < (1/3 − ϵ) and a batch size of ℓ = n − 3t, but we do
not use player virtualization, and we do not require that ℓ
be a power of two as in [4]. Although the protocol in [4]
was designed for refreshing batch sharings, it can easily be
modi(cid:12)ed to refresh secret sharings as well.
Recall that all entries in the transaction ledger are initially
secret-shared. Before we describe how the Ledger Servers
coordinate proactive refresh, we (cid:12)rst present a new proto-
col for converting secret sharings into batch sharings, Con-
vert Sharings, which is one of the main contributions of this
paper. We note that since the ledger is only expected to
grow in size, converting secret-shared values into batched
secret-shared values saves storage requirements and speeds
up the proactive-refresh process.
′
.
The following protocol takes as input a group of poly-
nomials that share secrets in batches of size ℓ and out-
puts a group of polynomials that share the same secrets
in batches of size ℓ
In our PDC scheme, this protocol
will be used to convert Shamir sharings (i.e., sharings with
ℓ = 1) into sharings of batch size greater than 1. For this
protocol, we use the notation [X] to denote the set of in-
tegers from 1 to X. Thus the Cartesian product [X] × [Y ]
is {(x, y) : 1 ≤ x ≤ X, 1 ≤ y ≤ Y }. The protocol Con-
vert Sharings uses a set Corr to keep track of which parties
may be corrupt. In step 10, when one party accuses another,
the parties make a worst-case assumption that both parties
are corrupt. Note that this set is distinct from any set of
disputes which may be used in the MPC sub-protocols.
Convert Sharings
b
a
a }(a,k)∈[ℓ′]×[K] of batch size ℓ.
Parties: S1, . . . , Sn.
Input: Each Ledger Server holds shares of batch shar-
ing polynomials {H (k)
Output: Each Ledger Server holds shares of batch
sharing polynomials {V (k)
}(b,k)∈[ℓ]×[K] of batch size ℓ
′
that contain the same secrets as did the H (k)
a .
1. Set Corr = ∅.
2. The servers use RandomB to generate polynomials
H (K+1)
]. (These
polynomials are used for masking and will be dis-
carded later.)
of degree d = ℓ + t − 1 for a ∈ [ℓ
′
+ t − 1 such that U (k)
3. Each Si selects polynomials {U (k)
}k∈[K+1] of degree
a (i) for all
] × [K + 1] and shares them via ShareB.
4. The servers invoke Random K times to generate K
′
d
(a, k) ∈ [ℓ
sharings of random values {r(k)}k∈[K].
{r(k)}k∈[K].
6. De(cid:12)ne eHa and eUi for (a, i) ∈ [ℓ
5. The servers invoke Open K times to publicly reveal
(−a) = H (k)
= ℓ
′
′
i
i
7. Each server sends all their shares of eHa and eUi to
Each server locally computes their shares of these
polynomials.
each other server for each (a, i) ∈ [ℓ
that this is not done using broadcast.)
] × [n]. (Note
′
∑
∑
eHa =
eUi =
′
] × [n] by
a + H (K+1)
i + U (K+1)
a
.
i
K
k=1 r(k)H (k)
k=1 r(k)U (k)
K
5′
] × [n].
] × [n].
9. Each server uses Berlekamp-Welch on the shares of
8. Each server uses Berlekamp-Welch on the shares
of eUi received in the previous step to interpolate
eUi(−a) for each (a, i) ∈ [ℓ
eHa to interpolate eHa(i) for each (a, i) ∈ [ℓ] × [n].
10. Each Sj checks if eUi(−a) = eHa(i) for each (a, i) ∈
If this does not hold for some eUi, then
11. Each server erases all their shares of eHa and eUi,
′
[ℓ
Sj broadcasts (Sj, J’accuse, Si). All servers add Si
and Sj to Corr. (After a server is added to Corr, any
further accusations from that server are ignored.)
] × [K + 1], and
shares of H (k)
shares of U (K+1)
12. De(cid:12)ne G to be the set of the (cid:12)rst n − 2t servers
not in Corr. Let {z1, . . . , zn−2t} denote the set of
indices of servers in G. Let λb,i denote the Lagrange
coe(cid:14)cients for interpolating the evaluation at −b of
∑
a degree-d polynomial from the shares of servers in