title:Moats and Drawbridges: An Isolation Primitive for Reconfigurable Hardware
Based Systems
author:Ted Huffmire and
Brett Brotherton and
Gang Wang and
Timothy Sherwood and
Ryan Kastner and
Timothy E. Levin and
Thuy D. Nguyen and
Cynthia E. Irvine
Moats and Drawbridges: An Isolation Primitive
for Reconﬁgurable Hardware Based Systems
†
Ted Huffmire(cid:1), Brett Brotherton
‡
†
Ryan Kastner
, Timothy Levin
†
, Timothy Sherwood(cid:1),
, Gang Wang
‡
‡
, Thuy Nguyen
, and Cynthia Irvine
(cid:1) University of California, Santa Barbara
Department of Computer Science
{huffmire,sherwood}@cs.ucsb.edu
Santa Barbara, CA 93106
†
University of California, Santa Barbara
Department of Electrical and Computer Engineering
Santa Barbara, CA 93106
{bbrother,wanggang,kastner}@ece.ucsb.edu
‡
Naval Postgraduate School
Department of Computer Science
{levin,tdnguyen,irvine}@nps.edu
Monterey, CA 93943
Abstract
1
Introduction
Blurring the line between software and hardware, re-
conﬁgurable devices strike a balance between the raw high
speed of custom silicon and the post-fabrication ﬂexibility
of general-purpose processors. While this ﬂexibility is a
boon for embedded system developers, who can now rapidly
prototype and deploy solutions with performance approach-
ing custom designs, this results in a system development
methodology where functionality is stitched together from
a variety of “soft IP cores,” often provided by multiple ven-
dors with different levels of trust. Unlike traditional soft-
ware where resources are managed by an operating system,
soft IP cores necessarily have very ﬁne grain control over
the underlying hardware. To address this problem, the em-
bedded systems community requires novel security primi-
tives which address the realities of modern reconﬁgurable
hardware. We propose an isolation primitive, moats and
drawbridges, that are built around four design properties:
logical isolation, interconnect traceability, secure reconﬁg-
urable broadcast, and conﬁguration scrubbing. Each of
these is a fundamental operation with easily understood for-
mal properties, yet maps cleanly and efﬁciently to a wide va-
riety of reconﬁgurable devices. We carefully quantify the re-
quired overheads on real FPGAs and demonstrate the utility
of our methods by applying them to the practical problem of
memory protection.
Reconﬁgurable hardware, such as a Field Programmable
Gate Array (FPGA), provides a programmable substrate
onto which descriptions of circuits can be loaded and exe-
cuted at very high speeds. Because they are able to provide
a useful balance between performance, cost, and ﬂexibil-
ity, many critical embedded systems make use of FPGAs
as their primary source of computation. For example, the
aerospace industry relies on FPGAs to control everything
from satellites to the Mars Rover. Their circuit-level ﬂexi-
bility allows system functionality to be updated arbitrarily
and remotely. Real-time and military projects, such as the
Joint Strike Fighter, make frequent use of FPGAs because
they provide both high-performance and well-deﬁned tim-
ing behavior, but they do not require the costly fabrication
of custom chips.
FPGA technology is now the leading design driver for
almost every single foundry1 meaning that they enjoy the
beneﬁts of production on a massive scale (reduced cost, bet-
ter yield, difﬁcult to tamper with), yet developers are free
to deploy their own custom circuit designs by conﬁguring
the device in the appropriate ways. This has signiﬁcantly
lowered the primary impediment to hardware development,
cost, and as such we are now seeing an explosion of recon-
ﬁgurable hardware based designs in everything from face
1A foundry is a wafer production and processing plant available on a
contract basis to companies that do not have wafer fab capability of their
own
recognition systems [39], to wireless networks [42], to in-
trusion detection systems [20], to supercomputers [5]. In
fact it is estimated that in 2005 alone there were over 80,000
different commercial FPGA designs projects started. [36]
Unfortunately, while the economics of the semiconductor
industry has helped to drive the widespread adoption of re-
conﬁgurable devices in a variety of critical systems, it is
not yet clear that such devices, and the design ﬂows used to
conﬁgure them, are actually trustworthy.
Reconﬁgurable systems are typically cobbled together
from a collection of exiting modules (called cores) in order
to save both time and money. Although ideally each of these
cores would be formally speciﬁed, tested, and veriﬁed by a
highly trusted party, in reality, such a development model
cannot hope to keep up with the exponential increases in cir-
cuit area and performance made possible by Moore’s Law.
Unlike uni-processor software development, where the pro-
gramming model remains ﬁxed as transistor densities in-
crease, FPGA developers must explicitly take advantage of
denser devices through changes in their design. Given that
embedded design is driven in large part by the demand for
new features and the desire to exploit technological scaling
trends, there is a constant pressure to mix everything on a
single chip: from the most critical functionality to the latest
fad. Each of these cores runs “naked” on the reconﬁgurable
device (i.e., without the beneﬁt of an operating system or
other intermediate layer), and it is possible that this mixing
of trust levels could be silently exploited by an adversary
with access to any point in the design ﬂow (including de-
sign tools or implemented cores). In an unrestricted design
ﬂow, even answering the question of “are these two cores
capable of communication” is computationally difﬁcult to
answer.
Consider a more concrete example, a system with two
soft-processor cores and an AES encryption engine shar-
ing a single FPGA. Each of these three cores requires ac-
cess to off-chip memory to store and retrieve data. How
can we ensure that the encryption key for one of the pro-
cessors cannot be obtained by the other processor by either
reading the key from external memory or directly from the
encryption core itself? There is no virtual memory on these
systems, and after being run through an optimizing CAD
tool the resulting circuit is a single entangled mess of gates
and wires. To prevent the key from being read directly from
the encryption core itself, we must ﬁnd some way to iso-
late the encryption engine from the other cores at the gate
level. To protect the key in external memory, we need to
implement a memory protection module, we need to en-
sure that each and every memory access goes through this
monitor, and we need to ensure that all cores are commu-
nicating only through their speciﬁed interfaces. To ensure
these properties hold at even the lowest levels of implemen-
tation (after all the design tools have ﬁnished their transfor-
mations), we argue that slight modiﬁcations in the design
methods and tools can enable the rapid static veriﬁcation
of ﬁnished FPGA bitstreams2. The techniques presented in
this paper are steps towards a cohesive reconﬁgurable sys-
tem design methodology that explicitly supports cores with
varying levels of trust and criticality – all sharing a single
physical device.
Speciﬁcally, we present the idea of Moats and Draw-
bridges, a statically veriﬁable method to provide isolation
and physical interface compliance for multiple cores on a
single reconﬁgurable chip. The key idea of the Moat is to
provide logical and physical isolation by separating cores
into different areas of the chip with “dead” channels be-
tween them that can be easily veriﬁed. Note that this does
not require a specialized physical device; rather, this work
only assumes the use of commercially available commodity
parts. Given that we need to interconnect our cores at the
proper interfaces (Drawbridges), we introduce interconnect
tracing as a method for verifying that interfaces carrying
sensitive data have not been tapped or routed improperly to
other cores or I/O pads. Furthermore, we present a tech-
nique, conﬁguration scrubbing, for ensuring that remnants
of a prior core do not linger following a partial reconﬁgura-
tion of the system to enable object reuse. Once we have a
set of drawbridges, we need to enable legal inter-core com-
munication. We describe two secure reconﬁgurable com-
munication architectures that can be easily mapped into the
unused moat areas (and statically checked for isolation), and
we quantify the implementation trade-offs between them
in terms of complexity of analysis and performance. Fi-
nally, to demonstrate the efﬁcacy of our techniques, we ap-
ply them to a memory protection scheme that enforces the
legal sharing of off-chip memory between multiple cores.
2 Reconﬁgurable Systems
As mentioned in Section 1, a reconﬁgurable system is
typically constructed piecemeal from a set of existing mod-
ules (called cores) in order to save both time and money;
rarely does one design a full system from scratch. One
prime example of a module that is used in a variety of con-
texts is a soft-processor. A soft-processor is simply a con-
ﬁguration of logical gates that implements the functionality
of a processor using the reconﬁgurable logic of an FPGA.
A soft-processor, and other intellectual property (IP) cores3
such as AES implementations and Ethernet controllers, can
2bitstreams are the term for the detailed conﬁguration ﬁles that encode
the exact implementation of a circuit on reconﬁgurable hardware – in many
ways they are analogous to a statically linked executable on a traditional
microprocessor
3Since designing reconﬁgurable modules is costly, companies have
developed several schemes to protect this valuable intellectual property,
which we discuss in Section 6.
be assembled together to implement the desired function-
ality. Cores may come from design reuse, but more often
than not they are purchased from third party vendors, gen-
erated automatically as the output of some design tool, or
even gathered from open source repositories. While indi-
vidual cores such as encryption engines may be formally
veriﬁed [30], a malicious piece of logic or compromised
design tool may be able to exploit low level implementa-
tion details to quietly eavesdrop on, or interfere with, trusted
logic. As a modern design may implement millions of logi-
cal gates with tens of millions of interconnections, the goal
of this paper is to explore design techniques that will allow
the inclusion of both trusted and untrusted cores on a single
chip, without the requirement that expensive static veriﬁca-
tion be employed over the entire ﬁnished design. Such ver-
iﬁcation of a large and complex design requires reverse en-
gineering, which is highly impractical because many com-
panies keep details about their bit-streams proprietary.
Increasingly we are seeing reconﬁgurable devices
emerge as the ﬂexible and high-performance workhorses
inside a variety of high performance embedded computing
systems [4, 9, 11, 22, 35, 45], but to understand the potential
security issues, we need to build on an understanding of at
least a simpliﬁed modern FPGA design ﬂow. In this section
we describe a modern device, a typical design ﬂow, and the
potential threats that our techniques are expected to handle.
2.1 Reconﬁgurable Hardware
FPGAs lie along a continuum between general-purpose
processors and application-speciﬁc integrated circuits
(ASICs). While general purpose processors can execute any
program, this generality comes at the cost of serialized ex-
ecution. On the other hand, ASICs can achieve impressive
parallelism, but their function is literally hard wired into the
device. The power of reconﬁgurable systems lies in their
ability to ﬂexibly customize an implementation down at the
level of individual bits and logic gates without requiring
a custom piece of silicon. This can often result in perfor-
mance improvements on the order of 100x as compared to,
per unit silicon, a similar microprocessor [7, 10, 50].
The growing popularity of reconﬁgurable logic has
forced practitioners to begin to consider security implica-
tions, but as of yet there is no set of best design practices to
guide their efforts. Furthermore, the resource constrained
nature of embedded systems is perceived to be a challenge
to providing a high level of security [26].
In this paper
we describe a set of low level methods that a) allow effec-
tive reasoning about high level system properties, b) can be
supported with minimal changes to existing tool ﬂows, c)
can be statically veriﬁed with little effort, d) incur relatively
small area and performance overheads, and e) can be used
with commercial off-the-shelf parts. The advantage of de-
veloping security primitives for FPGAs is that we can im-
mediately incorporate our primitives into the reconﬁgurable
design ﬂow today, and we are not dependent on the often re-
luctant industry to modify the design of their silicon.
2.2 Mixed-Trust Design Flows
Figure 1 shows a few of the many different design ﬂows
used to compose a single modern embedded system. The
reconﬁgurable implementation relies on a large number of
sophisticated software tools that have been created by many
different people and organizations. Soft IP cores, such as an
AES core, can be distributed in the form of Hardware De-
scription Language (HDL), netlists4 or a bitstream. These
cores can be designed by hand, or they can be automatically
generated by computer programs. For example, the Xil-
inx Embedded Development Kit (EDK) [53] software tool
generates soft microprocessors from C code. Accel DSP
[17] translates MATLAB [48] algorithms into HDL, logic
synthesis translates this HDL into a netlist, a synthesis tool
uses a place-and-route algorithm to convert this netlist into
a bitstream, with the ﬁnal result being an implementation of
a specialized signal processing core.
Given that all of these different design tools produce a set
of inter-operating cores, you can only trust your ﬁnal system
as much as you trust your least-trusted design path. If there
is a critical piece of functionality, e.g. a unit that protects
and operates on secret keys, there is no way to verify that
this core cannot be snooped on or tampered without a set of
isolation strategies.
The subversion of design tools could easily result in ma-
licious hardware being loaded onto the device. In fact, ma-
jor design tool developers have few or no checks in place
to ensure that attacks on speciﬁc functionality are not in-
cluded. However, just to be clear, we are not proposing
a method that makes possible the use of subverted design
tools on a trusted core. Rather, we are proposing a method
by which small trusted cores, developed with trusted tools
(perhaps using in-house tools which are not fully optimized
for performance5) can be safely combined with untrusted
cores.
2.3 Motivating Examples
We have already discussed the example of a system with
two processor cores and an encryption core. The goal of our
methods is to prevent the encryption key for one of the pro-
cessors from being obtained by the other processor by either
4Essentially a list of logical gates and their interconnections
5FPGA manufacturers such as Xilinx provide signed cores that can be
trusted by embedded designers, while those freely available cores obtained
from sources such as OpenCores are considered to be less trustworthy. The
development of a trusted tool chain or a trusted core is beyond the scope
of this paper.
HDL
Logic
Netlist
Synthesis
Accel
DSP
HDL
Logic
Netlist
Synthesis
Place
and
Route
Place
and
Route
Bitstream
Bitstream
Soft
DSP
Core
MATLAB
Algorithms
MATLAB