如果要解决的问题没有足够多的训练数据，可以找一个相同任务类型的神经网络，利用其已经训练完成的隐藏层参数，根据需要修改输出层，并输入我们自己的训练数据，对模型进行微调，这样可以有效利用别人已经预训练好的模型来解决我们的问题
![20231025221555](/assets/20231025221555.png)
- 基于样本的迁移学习：通过调整源域中原始样本的权重系数，使之和目标域匹配，进而应用在目标域中
- 基于特征的迁移学习：通过特征变换使得源域数据与目标域数据处在同一个特征空间之上，再在这个公共空间上进行学习
- 基于模型的迁移学习：假设源任务和目标任务共享一些参数或者一些先验分布，将在训练数据上训练好的成熟模型应用到目标域上解决问题
- 基于关系的迁移学习：如果源域和目标域之间共享了某种相似关系，那就可以将源域上的逻辑关系网络应用到目标域上
## 强化学习
不必告诉算法 每个输入 x 的正确输出 y 是什么，而是要指定一个奖励函数，告诉它何时表现良好，何时表现不佳。 算法的工作是自动弄清楚如何选择好的动作
要解决的问题要多种状态$S(s_1,s2,..,s_n)$ 每个状态都有属于它的奖励$r$，奖励通过奖励函数计算得到：$R(s_i) = r_i$。算法需要根据一个策略$\pi$ 求解当前所处状态应该采取什么行动$a$，即$\pi(s_n) = a$，算法所能最终得到的回报是与折扣因子$\gamma$有关，即最终回报 = $r_1 + \gamma r_2 + \gamma^2 r_3 + ...$
### 状态操作值函数
$Q(s,a)$返回在状态s下，使用a行动，能获取到的最大回报，并且通过这个行动跟这个状态，后续也是最优解
贝尔曼方程：
$$
Q(s,a)=R(s)+\gamma\max_{a^{\prime}}Q(s^{\prime},a^{\prime})
$$
- $s^{\prime}$ 是采取行动$a$后达到的状态
- $a^{\prime}$ 是要到达$s^{\prime}$所要采取的行动
方程的第一部分也被称为即时奖励，第二部分是从当前状态开始，能得到的最大奖励
这样可以通过贝尔曼方程来创建神经网络的训练数据：
$$
x = (s,a) \\
y = R(s)+\gamma\max_{a^{\prime}}Q(s^{\prime},a^{\prime})
$$
让神经网络算出最优的Q函数，这样就可以在当前状态$s$下，应该采取什么行动$a$
![深度强化学习](/assets/20231028204303.png)
### ϵ-贪婪策略
前期收集训练数据时，我们并不知道采取什么行动比较好，一种方式是不管当前状态如何，都采取随机行动。
一种被称为$\epsilon$贪婪策略的方法，定义一个参数$\epsilon$，每次，你有$1-\epsilon$的几率总是选择使得$Q(s,a)$最大的$a$，同时，另外$\epsilon$的几率就是随机做出行动$a$
### 随机环境
对于某些问题，下一个状态可能是随机的，此时强化学习的目标就从选择最大回报变成使得预期的回报尽可能大
### 连续状态空间
有些问题的状态取值可能不是离散的，而是一个有连续值的向量
## 概率图模型
用图论表现随机变量之间的条件依赖关系的建模方法
- 参数学习：在已知图模型结构的前提下估计其参数，也就是节点之间的条件概率
- 结构学习：在图模型完全未知的情况下先确定其结构，再根据结构来计算参数
### 贝叶斯网络
```mermaid
stateDiagram-v2
  a --> c
  a --> b
  b --> d
  b --> c
  c --> e
```
$$
p(A,B,C,D,E)=p(A)\cdot p(B|A) \cdot p(C|B,A)\cdot p(D|B)\cdot p(E|C)
$$
### 马尔可夫随机场
无向图模型，它的每个顶点表示一个随机变量，每条边则表示随机变量之间的依赖关系
和贝叶斯网络相比，马尔可夫随机场侧重于表示随机变量之间的相互作用
### 高斯网络
由高斯型连续随机变量构成的概率图模型统称为高斯网络
### 高斯过程
由出现在连续域上的无穷多个随机变量所组成的随机过程
### 隐马尔可夫模型
由隐藏的状态序列和可见的观测序列构成，能够对时序依赖关系建模
### 线性动态系统
假设一个传感器被用于测量未知的物理量 z，但测量结果 x 会受到零均值高斯噪声的影响，如果可以对 z 进行多次重复测量的话，就可以通过求解这些结果的平均来平滑掉随机噪声的影响
如果考虑上 z 在不同时间点的时变特性，如果变量本身并不会出现多少波动。这时就可以将平滑窗口的长度，也就是用于求平均的测量结果的数目取得大一些，以取得更好的抑制随机噪声的效果，而如果变量本身是快速变化的，这时就要适当地调小平滑窗口，同时给相距较近的测量结果赋予更大的平滑权重
### 推断
利用图结构表示的概率分布计算查询变量的概率
- 精确推断
- 近似推断
## 集群智能
由众多简单个体组成的群体能够通过相互之间的简单合作来实现某些功能，完成某些任务
当构成一个系统的基本单元数量极为庞大时，将这些个体看作一个整体，就会有一些全新的属性、规律或模式自发地冒出来，这种现象就称为“涌现”（emergence）
蚁群算法：
- 信息素的更新： 蚂蚁在路径上释放信息素，路径上信息素浓度高低表示路径的优劣。经过的蚂蚁会根据路径上信息素浓度对路径进行评估和选择。
- 路径选择： 蚂蚁在搜索过程中遵循两个基本规则
  - 正向规则（Exploitation）： 蚂蚁倾向于选择信息素浓度高的路径，因为这些路径可能是更优的选择。
  - 反向规则（Exploration）： 为了保证搜索的广度和多样性，蚂蚁也会随机选择路径，有时会选择信息素浓度低的路径。
- 信息素挥发： 信息素在时间上会逐渐挥发。这样做是为了保证蚂蚁能够重新探索路径，不会陷入局部最优解
## 知识图谱
由大量的概念实体以及它们之间的关系共同构成的语义网络
知识图谱可以根据已有实体的概念、属性和关系为新的概念自动生成属性；也可以明确不同新实体之间的关系
知识推理可以分为归纳和演绎两类
## 流形学习
用于处理高维数据的降维和可视化。这类方法的目标是在保持数据的局部结构和流形特性的同时，将高维数据映射到一个低维空间，从而揭示数据的内在结构
## 数据挖掘
### 基本流程
商业理解是数据挖掘项目成功的关键之一，因为这有助于确保项目从一开始就是针对商业目标而设计的。
数据理解和数据准备是数据挖掘的重要前提，因为数据质量对于最终的模型效果至关重要。
模型建立和模型评估是数据挖掘的核心步骤，这是构建和测试模型的关键阶段。
上线发布是数据挖掘项目的最终目标，因为这意味着模型已经被应用到商业实践中，并且提供了有价值的商业洞察。
监控和维护是确保数据挖掘结果持续有效的关键步骤，因为数据和商业需求都在不断变化，需要定期评估和更新模型
数据挖掘背后的数学原理：
- 概率论与数理统计：提供了数据建模和推断的理论基础
- 线性代数：特别是矩阵与向量
- 图论：来描述数据的结构关系
- 最优化方法：解决优化问题的工具
### 数据挖掘的任务
- 分类（Classification）：分类是将数据划分到不同的类别或标签中的任务。它通常用于有标记的数据，即每个数据都有一个预先定义好的标签。分类的目标是构建一个模型，该模型可以根据数据中的特征将未标记的数据分配到正确的类别中。
- 聚类（Clustering）：聚类是将数据划分为具有相似特征的组或簇的任务。聚类是一种无监督学习，即数据没有预先定义的标签或类别。聚类的目标是在数据中发现内在的结构或模式，并将数据分组为具有相似特征的组。
- 预测（Prediction）：预测是使用历史数据中的模式和关系来预测未来数据的任务。预测通常用于连续型数据，即数值型数据，而不是分类数据。预测的目标是构建一个模型，该模型可以使用历史数据来预测未来数据。
- 关联分析（Association Analysis）：关联分析是发现数据之间关系的任务。它通常用于交易数据，例如购物篮数据。关联分析的目标是发现数据中的频繁项集和关联规则，这些规则可以揭示数据之间的关系和模式。
## 度量学习
将 k 近邻算法和 k 均值算法这些基于距离的方法推广一步，得到的就是相似性学习（similarity learning）和它的变种度量学习（metric learning）
度量学习就是通过定义合适的距离度量或相似性度量来完成特定的分类或者回归任务，算法尝试学习一个合适的度量函数，使得在学得的度量下，相似的样本之间的距离较小，而不相似的样本之间的距离较大
## 算法选择
- 问题的类型： 首先要明确问题的类型，包括监督学习或无监督学习。监督学习问题可分为回归和分类问题，而无监督学习问题可能涉及特征工程和数据挖掘。
  - 回归问题算法选择： 针对回归问题，可以选择线性回归、决策树、随机森林、XGBoost、朴素贝叶斯和神经网络等算法。选择时考虑数据集大小、特征维度、训练时间和模型可解释性等因素。
  - 分类问题算法选择： 针对分类问题，可以根据问题性质选择适当的算法。逻辑回归可作为基准算法，决策树常用于投资和银行贷款等决策，而对于类别不平衡问题，随机森林是一种推荐的选择。朴素贝叶斯适用于文本分类等问题，而SVM适用于疾病诊断等多种分类问题。
选择算法时的其他考量因素：
1. 训练数据大小： 数据量较小时可选择高偏差、低方差的算法，如线性回归和朴素贝叶斯；数据足够大时可选择低偏差、高方差的算法，如KNN、决策树和神经网络。
2. 特征数量： 大量特征可使用SVM，也可通过PCA和特征选择来降低维度。深度学习适用于处理巨大特征量的问题。
3. 性能和可解释性的权衡： 需要在模型性能和可解释性之间进行权衡，选择适合业务目标的算法，如线性模型对可解释性较好，而灵活模型（如神经网络）对准确性较好。
4. 速度或训练时间： 实际应用中，选择算法时需考虑算法的训练时间，特别是对于在线应用。一些简单而迅速的算法如朴素贝叶斯可能更适合这些场景。
5. 数据的线性程度： 对于线性数据，逻辑回归和支持向量机等算法表现较好；对于复杂数据集，可选择核SVM、随机森林、XGBoost和神经网络等。
深度学习应用： 对于大数据时代的分类问题，深度学习神经网络是一种强大的解决方案，特别适用于非结构化数据，如语音识别、计算机视觉和自然语言处理等。