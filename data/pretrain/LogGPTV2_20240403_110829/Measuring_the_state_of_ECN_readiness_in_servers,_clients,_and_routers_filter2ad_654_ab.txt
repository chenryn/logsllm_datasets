21 ( 3.8%)
1 ( 0.2%)
we show with our traceroute measurements that something
along the path likely is improperly clearing the ECN bits.
(We discuss some of the causes for this misbehavior in later
sections.) We believe that all major operating systems im-
plement ECN functionality correctly
Since we set CE on the client’s packet that contained the
HTTP request (and all potential retransmissions), we expect
to see a ECE in all traces where the web server responded
with a HTTP status message. The analysis of CWR however
is dependent upon the number of data packets we receive
from the server since some data packets will already be in
ﬂight by the time the server receives the ﬁrst ECE message
(which we only send in response to data packets from the
server). We attempt to maximize the number of packets a
server sends by setting the TCP’s maximum segment size
option to 300. We also turn oﬀ all segmentation and receive
oﬄoad features in Linux.
We report on full ECN functionality tests from a single
vantage point at MIT, but have conducted limited testing
from other vantage points, in particular from non-Internet2
connected networks. We describe the ECN tests of paths
that we run from > 125 PlanetLab [25] locations below.
3.2 Mobile Infrastructure
ECN can be particularly beneﬁcial in wireless environ-
ments where loss does not necessarily indicate congestion.
We therefore seek to characterize the ECN capabilities and
behavior of web server side wireless-speciﬁc infrastructure by
obtaining a population of servers dedicated to hosting con-
tent for wireless mobile devices, e.g. cellular smartphones.
We note that the content provided from a web server to a
client is often tailored to the properties of the client device,
especially for mobile devices. Additionally, mobile devices
are frequently redirected to a diﬀerent, dedicated server for
mobile content. We leverage this common practice to obtain
a population of servers dedicated to serving mobile content
for subsequent ECN analysis.
For all domains in the Alexa 1M population, we issue ﬁve
diﬀerent HTTP GET queries, each with a distinct “User-
Agent” HTTP header string. The user agent string mimics a
desktop, and four diﬀerent mobile phones. If the queried web
server returns an HTTP 3xx redirect to a location diﬀerent
than the desktop query for any of the phone queries, we
record the location. For example, a query from a desktop
to www.bloomberg.com is not redirected, while a query from
a phone user agent is redirected to mobile.bloomberg.com;
these hostnames correspond to diﬀerent IP addresses.
Using this technique, we ﬁnd ∼82,000 sites performing
HTTP redirection on the basis of the user agent. Of those,
7,422 redirect to distinct mobile infrastructure, i.e. redirect
to a URL that resolves to a diﬀerent IP address. We use the
later population for analysis of mobile web sites.
3.3 Client Testing
Understanding client-side ECN support is important for
several reasons, notably since clients represent “eyeballs” in
the network, i.e. humans sensitive to congestion. However,
while prior work (§2) investigates the prevalence of server-
side ECN, client-side support has received little attention.
Maier et al. observe a negligible number of hosts initiating
ECN capable TCP in a large residential broadband network
[19]. The lack of ECN in Maier’s study is unsurprising as
operating systems that support ECN, with typical default
settings, did not and still do not negotiate ECN for outgoing
connections. Because passive measurements provide only a
limited view into client-side ECN capabilities, we develop a
new hybrid passive/active method.
Our technique measures a large section of two peer-to-
peer (P2P) networks – where nodes act as both clients and
servers – to capture the ECN behavior of a population of
Internet clients. We build BitTorrent and Gnutella crawlers
on an ECN-enabled measurement host under our control.
Our BitTorrent [9] crawler discovers torrents via aggregated
RSS feeds, connects to the torrent’s tracker(s), and obtains
a list of torrent peer IP addresses. The crawler attempts
a BitTorrent handshake with each peer, thereby initiating
ECN and sending data segments without transferring con-
tent. Simultaneously, we capture all packets for analysis.
For Gnutella, we use an existing crawler [27].
Our crawlers negotiate ECN for all connections to remote
nodes in the P2P network, the majority of which reside in
residential networks. By observing the behavior of the nego-
tiation, and subsequent response to synthetic ECN signals
introduced using the aforementioned iptables rules (§3.1),
we gain insight on the prevalence of ECN on an end-to-end
basis in the Internet.
3.4 End-to-End ECN Path Testing
If a router does not have any features turned on that lever-
age the ECN ﬁeld, it should not modify the ECN ﬁeld in any
way. From conversations with network operators, none re-
ported turning on ECN markings. However, we leverage
traceroute to identify links where the ECN bits in the IP
header are being modiﬁed. ICMP TTL-exceeded messages
include the ﬁrst 28B of the packet that expired, the so-called
ICMP “quotation.” This quotation provides path-level vis-
ibility into the ECN ﬁeld. We make use of this feature by
setting the ECT code point in a series of tests from our Plan-
etLab nodes to the web server populations described above.
173While most ICMP quotations are reliable and accurate, like
[20] we ﬁnd some small evidence of quotation error.
Filtering diﬀerences raise the question of which type of
probe (ICMP, UDP, TCP-SYN, TCP-ACK) should test a
path. We did not ﬁnd any apparent diﬀerences in how
routers responded to packets with the ECN ﬁeld set in a
comparison of probe types to a 10,000 node sample set.
Therefore we used Scamper’s [18] ICMP-paris traceroute
mode [3] (even though ICMP packets would not normally
be ECN marked) since it was likely to discover more hops.
4. RESULTS
4.1 Server results
Table 1 provides our results of ECN testing to the web
server populations in September of 2011. Where applicable,
we include results from previous studies in 2004 [21] and
2008 [17] for comparison purposes. The number of servers
which negotiated ECN rose to between 14% to 17% in all web
server populations. A possible ECN SYN blackhole existed
in less than 0.6% of tests. But we caution that this may
over-estimate the percentage as false positives could occur
both in our methodology and the previous studies if a lossy
link happened to drop the ECN enabled SYN packets but
not the subsequent SYN packets without ECN. Deﬁnitively
identifying ECN blackholes would require repeated probing
of the same server with both ECN and non-ECN SYNs.
The rest of the table rows report various ways in which
the ECN congestion feedback loop can be broken. We con-
servatively report on not receiving a CWR in response to
ECE only if we receive more than 10 data packets from the
server i.e. we receive a subsequent ﬂight of packets after the
server must have received ECE notiﬁcations. The variation
across diﬀerent populations is striking – the ECN ﬁeld in the
IP header on ﬂows to and from university networks is be-
ing cleared 25.2% and 28.5% of the time respectively.2 This
is far higher than the comparable percentages of paths to
Alexa web hosts – 3.8% outbound and 11.3% inbound.
In limited testing from diﬀerent vantage points, the per-
centages of ECN capable servers across target populations
remained consistent. The results characterizing the bro-
ken ECN feedback loop showed more variation. This is ex-
pected given that these results depend upon the network
path between our measurement vantage points and the tar-
get servers. Our traceroute measurements below shed addi-
tional light on these variations.
4.2 Client-side results
Table 2 shows that fewer clients negotiated ECN on in-
coming connections; 4.2% to less than 0.1% depending on
population. To better understand this discrepancy, we em-
ploy stack ﬁngerprinting to the TCP SYN/ACK packets [5]
to infer the operating system of the client. Table 3 shows a
striking diﬀerence between the ECN capable and non-ECN
capable populations: the vast majority of ECN capable hosts
are Linux (88.4%).
4.3 End-to-End ECN Paths
We collected two sets traces to determine where on the
path the ECT codepoint was cleared, and related aspects.
The ﬁrst trace set includes one randomly-chosen destination
2When there is no ECE for a CE, either the outbound CE
could be being cleared or the inbound ECE.
Table 2: Client Population Data
Population
Hosts classiﬁed
ECN-capable
Not ECN-capable
ECT in non-ECN ﬂow
no ECT in ECN ﬂow
no ECE for CE
no CWR for ECE
Gnutella
126,984 (100%)
106 (0.1%)
126,878 (99.9%)
2,153 (1.7%)
44 (42%)
10 ( 9%)
0 (0.0%)
BitTorrent
16,602 (100%)
701 ( 4.2%)
15,901 (95.8%)
452 ( 2.8%)
117 ( 17%)
167 ( 24%)
0 (0.0%)
Table 3: Inferred O/S of Client Populations
O/S
Gnutella
(All)
29.9%
BT
(ECN)
0.0%
4.4%
88.4%
7.14%
Gnutella
(ECN)
0.0%
29.5%
46.6%
23.9%
BT
(All)
24.6%
8.9%
7.0%
59.5%
Windows
Mac/BSD 3.9%
Linux
1.1%
Other
65.1%
from each of the globally routable BGP preﬁxes ((cid:3) 367,000)
in order to touch all origin AS’s and be broadly represen-
tative of Internet paths. The second trace set represents
“popular” destinations, and thus used the 542,000 unique
addresses from the Alexa top 1 million [1]. For the preﬁx-
traces, we used 127 PlanetLab nodes, from 29 countries and
5 continents, to initiate the traces. And for the website-
traces, we were able to use some additional nodes for a total
of 140. Each PlanetLab node executed a trace to each of the
destinations, for a total of 117 million traces collected.
Percent of Traces which passed the ECT codepoint
The location of any devices that modify the ECT codepoint
relative to our tracing vantage points is important. At one
extreme, ECT is cleared on 100% of the traces originating
from particular PlanetLab nodes due to all traces passing
through a misbehaving device at the ﬁrst or second hop.
Traces from these nodes are not reﬂective of the whole In-
ternet, but are relevant for the clients at that location.
ICMP ﬁltering behavior impacts our macro analysis as
well. For a few vantage points, the vast majority of their
traces are blocked after a few hops, and for the hops that did
respond, the ECT codepoint remained set; thus these traces
could be grouped with those that preserved the codepoint,
though in reality farther along the path the codepoint might
have been cleared.
Across all traces, the ECT codepoint is unmodiﬁed for
83% and 82% of the popular website and preﬁx traces re-
spectively. Restricting the analysis to those traces where all
hops respond, including the destinations, does not qualita-
tively aﬀect our results, yielding 84% and 80% respectively.
To remove the impact of nodes where the ECT codepoint
is cleared on almost all of the traces, if we omit the 20% of
nodes that had the fewest traces where the ECT remained
set, then for each of remaining nodes, the ECT codepoint
remained set on 94% to 98% of the website-traces and 90%
to 99% of the preﬁx-traces.
Location on the path where the ECT codepoint is cleared
When the ECT codepoint is modiﬁed, we wish to attribute
such misbehavior to an interface hop on the path. However,
there is ambiguity in identifying the responsible device. For
example, while sending probes with ECT set, suppose inter-
face hops 1-4 respond with ICMP TTL exceeded quotations
174n
o
i
t
c
a
r
F
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0
 0
CDF of interface-hop on path at which ECT code point is cleared
website-traces; last hop ECT is set
website-traces; first hop ECT is cleared
prefix-traces;  last hop ECT is set