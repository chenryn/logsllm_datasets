customer satisfaction. The customer’s expectations and satisfaction can be translated into
the quality of service rendered. Equally importantly, QoS is needed as a basis for
contracts that govern e-commerce activities between trading partners.
Workflow systems should be viewed as more than just automating or mechanizing
tools. They can also be used to analyze, reshape, and reengineer the way business is done.
One way to achieve these objectives is through QoS analysis involving such QoS metrics
as, time, cost, reliability, and fidelity .At runtime, if the monitoring of a workflow
indicates the presence of unsatisfactory QoS metrics, strategies can be employed to
redesign, reengineer, or dynamically adapt the workflow .
For organizations, being able to characterize workflows based on their QoS has three
direct advantages. First, it allows organizations to translate their vision into their business
processes more efficiently, since workflow can be designed according to QoS metrics.
Second, it allows for the selection and execution of workflows based on their QoS in
order to better fulfill customers’ expectations. Third, it also makes possible the
monitoring and control of workflows based on QoS, setting up compensation strategies
when undesired metrics are identified, or use it as a tool to manage contract
commitments.
The requirement of process QoS management is a new challenge for workflow
systems. While QoS has been a major concern for networking, rea-ltime applications, and
middleware, few research groups have concentrated their efforts on enhancing workflow
systems to support workflow quality of service (QoS) capabilities or a subset of them.
Most of the research carried out to extend the functionality of workflow systems QoS has
93
only been done in the time dimension, which is only one of hte dimensions under the
QoS umbrella. Furthermore, the solutions and technologies presented are still preliminary
and limited (Eder, Panagos et al. 1999).
Our work in this area started with the definition of a QoS model for workflows
(Cardoso, Miller et al. 2002). The model includes four dimensions: time, cost, reliabiltiy,
and fidelity. These dimensions allow for the specification of no-nfunctional QoS metrics
and for the computation of overall workflow QoS based on individual task QoS.
This paper enumerates and describes the enhancements that need to be made to
workflow systems to support processes constrained by QoS requirements, such as e-
commerce workflows. The enhancements include the development and support of a
comprehensive QoS model and the implementation of methodologies (a mathematical
model and simulation) to compute and predict workflow QoS. We have developed a
stochastic workflow reduction algorithm (SWR) for the step-by-step computation of QoS
metrics. Our work has been carried out for the METEOR system to allow the
specification, computation, and management of QoS. The support of QoS requires the
modification and extension of several workflow system components, and the
development of additional modules. While the implementation was made for the
METEOR system, and the development is based on a specific conceptual model, the
main ideas presented in this study can be applied to the vast majority of workflow
systems available (Aalst, Barros et al. 2002).
This paper is structured as follows. In section 3.3, we present the related work that
has been done in the context of QoS management. In section 3.4, we briefly describe our
QoS model and each of its dimensions. These descriptions will allow for a better
understanding of QoS implementation. Section 3.5 is extensive and describes the
modification of existing workflow system components and the creation of new modules
that have been developed to support the workflow QoS concept. Each of workflow
components and new modules are analyzed individually. Section3 .6 explains how QoS
94
can be computed, as based on QoS tasks. We briefly present the idea behind one
algorithm that we have developed, and we also describe how simulation techniques can
be used to compute workflow QoS. Finally, section 3.7 presents our conclusions.
3.3 RELATED WORK
While QoS has been a major concern for networking (Cruz 1995; Georgiadis, Guerin et
al. 1996), real-time applications (Clark, Shenker et al. 1992) and middleware (Zinky,
Bakken et al. 1997; Frlund and Koistinen 1998; Hiltunen, Schlichtinge t al. 2000), few
research groups have concentrated their efforts on enhancing workflow systems to
support workflow quality of service (QoS) specifications and management.
The work found in the literature on quality of service for WfMS is limited. The
Crossflow project (Klingemann, Wäsch et al. 1999; Damen, Derks et al. 2000; Grefen,
Aberer et al. 2000) has made an early contribution by considering time and cost. In their
approach, a continuous-time Markov chain (CTMC) is used to calculate the time and cost
associated with workflow executions. While the research on QoS for WfMS is limited,
the research on time management, which is one component of workflow QoS, has been
more active and productive. Eder (1999) and Pozewaunig (1997) extend CMP and PERT
by annotating workflow graphs with time. At process build-time, instantiation-time, and
runtime the annotations are used to check the validity of time constraints. A significant
limitation of their approach is that only direct acyclic graphs (DAG) can be modeled,
especially because many rea-lworld workflows have cyclic graphs. Cycles are in general
used to represent re-work actions or repetitive activities within a workflow. Reichert
(1998) and Dadam (2000) also recognize time as an important aspect of workflow
execution. In their approach, it is possible to specify a deadline involving minimal and
maximal durations for execution of each task. At runtime, the workflow system monitors
the specified deadlines and notifies users when deadlines are missed. The system also
checks if minimal and maximal time distances between tasks are followed according to
95
initial specifications. Marjanovic and Orlowska (1999) describe a workflow model
enriched by modeling constructs and algorithms that check the consistency of workflow
temporal constraints. Their work mainly focuses on how to manage workflow changes,
while at the same time accounting for temporal constraints. Son and Kim( 2001) present a
solution for the deadline allocation problem based on queuing networks. Their work also
uses graph reduction techniques, but applied to queuing networks.
Recently, researchers have been interested in QoS in the area of Web services. In the
DAML-S (DAML-S 2001) specification, use of an ontology allows and facilitates
process interoperability between trading partners involved in e-commerce activities. The
specification includes tags to specify the quality of service parameters, such as quality
guarantees, quality rating, and degree of quality. While DAML-S has identified
specifications for Web service and business processes as a key specification component,
the QoS model which should be adopted needs to be significantly improved to supply a
realistic solution to its users. One current limitation of the DAML-S’ QoS model is that it
does not provide a detailed set of classes and properties that represent QoS metrics. The
QoS model needs to be extended to allow for a precise characterization of each
dimension. Furthermore, a model to compute overall QoS of process specified as
composition of Web Services is not provided. The addition of concepts that represent the
minimum, average, maximum, and distribution functions associated with dimension, such
as cost and duration, will allow for the implementation of algorithms for the automatic
computation of QoS metrics of processes, as based on sub-processes’ QoS metrics.
3.4 WORKFLOW QUALITY OF SERVICE
In the work presented here, workflow QoS represents the quantitative and qualitative
characteristics of a workflow application which is necessary to achieve a set of initial
requirements. Workflow QoS addresses the non-functional issues of workflows, rather
than workflow process operations. Quantitative characteristics can be evaluated in terms
96
of concrete measures such as workflow execution time, cost, etc. Kobielus (1997)
suggests that dimensions such as time, cost and quality should be a criteriat hat workflow
systems should include and might benefit from. Qualitative characteristics specify the
expected services offered by the system, such as security and faul-ttolerance mechanisms.
QoS should be seen as an integral aspect of workflows, and therefore it should be
embedded in workflow specifications and WfMSs.
Quality of service can be characterized along various dimensions. We have
investigated related work to decide which dimensions would be relevant in composing
our QoS model. Our research targeted two distinct areas: operations management in
organizations (Garvin 1988; Stalk and Hout 1990; Rommel 1995) and quality of service
for software systems, which include networking (Cruz 1995; Georgiadis, Guerin et al.
1996; Nahrstedt and Smith 1996), middleware areas (Zinky, Bakken et al. 1997; Frlund
and Koistinen 1998; Hiltunen, Schlichtinge t al. 2000), and real-time applications (Clark,
Shenker et al. 1992). The study of those two areas is important, since workflow systems
are widely used to model organizational business processes, and since workflow systems
are themselves software systems.
3.4.1 QOS MODEL
Weikum (1999) divided information services QoS into three categories: system centric,
process centric, and information centric. Based on previous studies and on our experience
in the workflow domain, we have constructed a QoS model that includes system and
process categories. Our model is composed of four dimensions: time, cost, fidelity, and
reliability.
Time (T) is a common and universal measure of performance. For workflow systems, it
can be defined as the total time needed by an instance in order to transform a set of inputs
into outputs. Task response time (T) corresponds to the time an instance takes to be
97
processed by a task. The task response time can be broken down into major components
which include: process time, queuing delay, setup delay, and synchronization delay .
Cost (C) represents the cost associated with the execution of workflow tasks. During
workflow design, prior to workflow instantiation, and during workflow execution it is
necessary to estimate the cost of the execution to guarantee that financial plans are
followed. Task cost is the cost incurred when a task t is executed; it can be broken down
into major components, which include realization cost and enactment cost.
We view Fidelity (F) as a function of effective design; it refers to an intrinsic property or
characteristic of a good produced or of a service rendered. Fidelity reflects how well a
product is being produced and how well a service is being rendered. Fidelity is often
difficult to define and measure because it can be subjective. Nevertheless, the fidelity of
workflows should be predicted when possible and carefully controlled when needed.
Workflow tasks have a fidelity vector dimension composed by a set of fidelity attributes
(F(t).a) to reflect, qualify, and quantify task operations. Each fidelity attribute refers to a
i
property or characteristic of the product being created, transformed, or analyzed. Fidelity
attributes are used by the workflow system to compute how well workflows, instances,
and tasks are meeting user specifications. For automatic tasks (Kochut, Sheth et al. 1999)
the fidelity can be set automatically. For a human task, we must really on the person in
charge of the task realization to set the fidelity attributes.
Task Reliability (R) corresponds to the likelihood that the components will perform
when the user demands them; it is a function of the failure rate. Depending on the
workflow system and task conceptual model, tasks instances can be placed into different
states, typically described by a state transition diagram (task structure) during their
execution. Two final states exist. One represents the success of a task realization, and the
98
other represents the failure of a task realization. The reliability dimension is a function of
the number of times the success state is reached and the number of times the failure state
is reached.
3.5 WORKFLOW QOS IMPLEMENTATION
The QoS model that we have developed is being implemented for the METEOR
workflow management system. The METEOR project is represented by both a research
system (METEOR 2002), and a suite of commercial systems that provide an open system
based, high-end workflow management solution, as well as an enterprise application
integration infrastructure. The work discussed in this paper is part of the research system
and is not part of any commercial product yet.
METEOR’s architecture includes four services: Enactment, Manager, Builder, and
Repository. The enactment service includes two systems: ORBWork (Kochut, Sheth et
al. 1999) and WebWork (Miller, Palaniswami et al. 1998). The task of the enactment
service is to provide an execution environment for processing workflow instances. Both
ORBWork and WebWork use fully distributed implementations. WebWork, an entirely
Web-based enactment service, is a comparatively ligh-tweight implementation that is
well-suited for less complex applications that involve limtied data exchange and do not
need to be dynamically changed. ORBWork is targeted for more demanding, mission-
critical enterprise applications requiring high salability, robustness and dynamic
adaptation. The current version of ORBWork has been designed to address a variety of
shortcomings found in today's workflow systems. It supports interoperability standards
such as JFLOW (OMG 1998) and SWAP (Swenson 1998). Although we started with the
use of open standards such as Java and CORBA to make it a good candidate for
interoperating with existing systems from a variety of distributed and heterogeneous
computing environments, recently a Java-only version (replacing CORBA with RMI) has
also been completed. With recently added modules, it also includes a repository for reuse
99
(Song 2001), dynamic changes (Chen 2000) at the instance level and an exception-
handling mechanism (Luo 2000). ORBWork has been used in prototyping and deploying
workflow applications in various domains, such as bio-informatics (Hall, Miller et al.
2000), healthcare (Anyanwu, Sheth et al. 1999), telecommunications (Luo 2000), defense
(Kang, Froscher et al. 1999), and university administration( CAPA 1997).
In this section we describe the components that make up the METEOR system and
the components that have been modified, extended, and created to enable QoS
management. Changes have been made to four services: the Enactment, the Manager, the
Builder, and the Repository. These components and their relationship to the overall
workflow system are illustrated in Figure 3-1.
Simulation System
Task QOS Estimator
uses QQooSS MMooddeell
BB
CCoosstt
AApppplliiccaattiioonn
AA NN11 EE NN22 FF FFiiddeelliittyy DDiimmeennssiioonnss
uses
TTiimmee SSyysstteemm
BBuuiillddeerr Instance Level CC DD RReelliiaabbiilliittyy DDiimmeennssiioonnss
BBB Control Flow Create and Manage
AAA NNN111 EEE NNN222 FFF Data flow Workflow schema workflow instances
QoS metrics DDBBLLoogg
CCC DDD Monitor QoS
Schema Level Load
uses WWWooorrrkkkffflllooowww
WfMS Enactment Workflow TTTaaassskkksss
RReeppoossiittoorryy components Manager Service Monitor Instance TTTrrraaannnsssiiitttiiiooonnnsss uses
QoS Data QQQoooSSS IIInnnssstttaaannnccceeesss
Workflow Level
CORBA server, communications,
OS, Hardware, etc.
Infrastructure Level
Figure 3-1 – QoS Management Architecture
100
3.5.1 ENACTMENT SERVICE
In this section we describe the modifications that have been made to the ORBWork
enactment system. The components analyzed include task schedulers, task managers, and
monitors.
In ORBWork enactment service, task schedulers, task managers, and tasks are
responsible for managing runtime QoS metrics. From the implementation point of view,
we divide the management of the QoS dimensions into two classes: the system and the
application dimensions. The system dimensions (time and reliability) are the
responsibility of task schedulers, while the application dimensions (cost and fidelity) are
the responsibility of task managers and tasks. Since task schedulers decide the starting
time of task execution and are notified when tasks are complete, they set the time
dimension of the QoS. Additionally, the supervision of tasks completion puts them in
charge of managing the reliability dimension. These two dimensions are called system
dimensions because it is a system component (the enactment system) that is responsible
for registering the time and reliability metrics at runtime. For the cost and fidelity
dimensions, task managers are the candidate components since they include the necessary
functions to initialize tasks with estimated QoS metrics. The cost and fidelity dimensions
are called application dimensions since they are manipulated and modified by a task
realization.
3.5.1.1 TASK SCHEDULERS
ORBWork follows a fully distributed scheduling strategy. The scheduling responsibilities
are shared among a number of participating task schedulers, according to workflow
definitions. The distributed schedulers maintain a workflow data specification that has
been received during workflow installation. Each task scheduler provides a wel-l
constrained subset of the HTTP protocol and thus implements a lightweight, local Web
server. The scheduler accesses workflow specifications through the HTTP protocol,
101
directly from specification files or from the repository. Each set of task specifications
includes input dependency (input transitions), output transitions with their associated
conditions, and date objects that are sent into and out of the task. As discussed
previously, task schedulers are responsible for managing the time and reliability
dimensions. We discuss each one of these separately in the following section.s
Managing Time
In section 3.4 we have classified task response time (T) as the time an instance takes to be
processed by a task. Task response time is composed of two major components: delay
time (DT) and process time (PT). Delay time is further broken down into queuing delay
(QD) and setup delay (SD). This makes the response time of a task t represented as
followed:
T(t) = DT(t) + PT(t) = QD(t) + SD(t) + PT(t)
Another important time metric is the synchronization delay (SyncD). This measure
corresponds to the time and-join tasks spend waiting for all the incoming transitions to be
enabled. The SyncD(t) of a task t is the difference of the time t registered when all the
b
incoming transitions of task t are enabled and the time t registered when the first
a
incoming transition was enabled, i.e. t - t . This measure gives valuable information that
b a
can be used to re-engineer business processes to increase their time efficiency.
To efficiently manage the time dimension, workflow system smust register values
for each of the functions involved in the calculation of task response time (T). The time
dimension has its values set according to the task structure illustrated in Figure 3-2. Each
state has been mapped to one of the functions that compose the time dimension.
ORBWork system follows this task structure to represent workflow task execution
behavior (Krishnakumar and Sheth 1995). To more effectively support QoS management,
102
the original structure has been extended, with the inclusion of the Pre-Init, as shown in
Figure 3-2.