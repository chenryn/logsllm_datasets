are tuned manually. With the exception of Sec. 5.3, measurements
in Sec. 5 were all taken using single-counter measurement cam-
paigns in order to achieve the highest resolution possible. Sec. 5.3
and Sec. 6 included multiple counters per measurement campaign,
but one campaign per set of experimental results.
In this paper, we mainly focus on three sets of counters. We
briefly describe them and list their single-instance sampling rate
here.
Figure 3: CDF of µburst durations at a 25 µs granularity.
Byte count. The primary set we use measures the cumulative
number of bytes sent/received per switch port. We use these byte
counts to calculate throughput. As mentioned above, our framework
can poll a single instance of these counters every 25 µs with low
sampling loss. When a sample miss does occur, we can still calculate
throughput accurately using the sample’s timestamp and byte count.
At these timescales, we can measure the network at a granularity
much smaller than even a single RTT.
Packet size. Similar to byte count, we also collect a histogram
of the packet sizes sent/received at each switch port. The ASIC
bins packets into several buckets that we list in Sec. 5.3. These can
typically be polled at the same granularity as byte counters.
Peak buffer utilization. The third set measures the buffer utiliza-
tion of the switch. For this counter, we take the peak utilization of
the buffer since the last measurement so that we do not miss any
congestion events, and we reset the counter after reading it. Thus,
even when the sampling loop misses a sampling period, our results
will still reflect bursts. This counter takes much longer to poll than
byte or packet size counters (50 µs).
4.2 Data set
Network architecture. The data center we study uses a conven-
tional 3-tier Clos network and is described in [4]. Machines are
organized into racks and connected to a Top-of-Rack (ToR) switch
via 10 Gbps Ethernet links. Each ToR is, in turn, connected by ei-
ther 40 Gbps or 100 Gbps links to an aggregation layer of “fabric”
switches. The fabric switches are then connected to a third layer of
switches, called “spines”. The entire structure forms a multi-rooted
tree, with the spine switches as the roots of the tree, and the ToRs
as the leaves.
Due to current deployment restrictions, we concentrate on ToR
switches for this study and leave the study of other network tiers
to future work. Prior work and our own measurements show that
the majority of loss occurs at ToR switches and that they tend
to be more bursty (lower utilization and higher loss) than higher-
layer switches [19]. Most of these drops occur in the ToR-server
direction (∼90% in the data center we measured). In that sense, ToR
measurements most likely represent a worst case over all switches
in the data center.
Workload. Our data set spans a few applications, but a distinctive
aspect of the data center we measured is that servers typically have
a single role. In particular, we focus on three applications that show
IMC ’17, November 1–3, 2017, London, United Kingdom
Q. Zhang et al.
web page using data from many remote sources.
a diverse set of behaviors and are among the most prevalent types
of machines in the data center.
• Web: These servers receive web requests and assemble a dynamic
• Cache: These servers serve as an in-memory cache of data used
by the web servers. Some of these servers are leaders, which
handle cache coherency, and some are followers, which serve
most read requests [15].
• Hadoop: Unlike the previous two categories, these servers are
not part of the interactive path. Instead, Hadoop servers are used
for offline analysis and data mining.
See [4] for a more detailed description of each application’s traffic
patterns.
As entire racks are typically dedicated to each of these roles, even
when measuring at a ToR level, our results can isolate the behavior
of different classes of applications. Our measurements span a total
of 30 racks, consisting of 10 racks for each application type over
the course of 24 hours. Due to data retention limitations, storing all
samples of all counters over 24 hours was not feasible, so for each
rack, we pick a random port, and pick a random 2-minute interval
for every hour throughout the day. Diurnal patterns are therefore
captured within our data set. In total, we sampled 720 two-minute
intervals, each with around 5 million data points, totaling 250 GB.
The full data would have taken hundreds of terabytes.
5 PORT-LEVEL BEHAVIOR
We begin our analysis by studying the fine-grained behavior of
individual ports before proceeding in Sec. 6 to consider the interac-
tions between ports in a switch. From fine-grained behavior, our
goal is to observe and characterize the bursty nature of data center
networks.
5.1 Existence of µbursts
In Sec. 3, we noted that coarse-grained measurements of data center
networks suggest bursty behavior on very small timescales. To
test this hypothesis, we measure the duration of bursts at 25 µs
granularity. As in [8], we say that a switch’s egress link is hot
if, for the measurement period, its utilization exceeds 50%. An
unbroken sequence of hot samples indicates a burst.1 We can see a
few interesting results from the measurements shown in Fig. 3.
High utilization is indeed short-lived. A significant fraction
of these bursts are only one sampling period long. The 90th per-
centile duration is less than 200 µs for all three rack types, with
Web racks having the lowest 90th percentile burst duration at 50 µs
(two sampling periods). Hadoop racks have the longest tail of the
three, but even then, almost all bursts concluded within 0.5 ms. The
results indicate that bursts not only exist, almost all high utilization
at the edge of the data center network is part of a µburst. Con-
gestion events observed by less granular measurements are likely
collections of smaller µbursts.
Bursts are correlated. While a significant portion of bursts last for
less than a sampling period, these high-utilization intervals do tend
to be correlated. We can demonstrate this using a simple likelihood
1We choose to define a burst by throughput rather than buffer utilization as buffers
in our switches are shared and dynamically carved, making pure byte counts a more
deterministic measure of burstiness.
Figure 4: CDF of the time between bursts at a 25 µs granularity.
ratio test. First, we create a two-state first-order Markov model. We
classify each 25 µs interval as ‘hot’ (xt = 1) or not (xt = 0) based
on its utilization level. Then, we count consecutive occurrences of
same-state intervals or flipped intervals. This allows to compute
the MLE (Maximum Likelihood Estimates) of its transition matrix,
p(xt = a|xt−1 = b) = count(xt =a,xt−1=b)
count(xt−1=b)
, shown in Tab. 2.
p(xt |xt−1)
xt−1 = 0
xt−1 = 1
Web
Cache
Hadoop
xt = 0
0.997
0.641
xt = 1
0.003
0.359
xt = 0
0.984
0.279
xt = 1
0.016
0.721
xt = 0
0.958
0.345
xt = 1
0.042
0.655
Table 2: Transition Matrix for Burst Markov Model
Given this Markov model, we can then compute the likelihood
ratio of r = p(xt =1|xt−1=1)
p(xt =1|xt−1=0). If burst intervals are independently
arriving, we would expect r ≈ 1 because it would imply the prob-
ability of seeing the next burst is the same whether the previous
time period saw a burst or not. The actual ratios are much higher,
indicating that high utilization samples are correlated:
rweb = 0.359/0.003 = 119.7
rcache = 0.721/0.016 = 45.1
rhadoop = 0.655/0.042 = 15.6
(1)
(2)
(3)
Fine-grained measurements are needed to capture certain
behaviors. Our results also confirm our intuition that fine-grained
measurements are needed to accurately measure bursty behavior.
They also offer a potential explanation for the skewed behavior
found in Sec. 3 and prior studies. In fact, it is possible that our 25 µs
measurement granularity is itself too coarse as over 60% of Web
and Cache bursts terminated within that period. Faster networks
will likely increase the necessary granularity. Unfortunately, the
sampling rate is fundamentally limited by latency between the CPU
and the ASIC, suggesting that additional hardware support may be
necessary for fine-grained measurements in the future.
5.2 Time between µbursts
The time between µbursts is just as interesting as the bursts them-
selves. Fig. 4 shows a CDF of the duration of these inter-burst
periods. Unlike our measurements of µbursts and their duration,
inter-burst periods have a much longer tail. It is still the case that
most inter-burst periods are small, particularly for Cache and Web
High-Resolution Measurement of Data Center Microbursts
IMC ’17, November 1–3, 2017, London, United Kingdom
(a) Inside Burst
(b) Outside Burst
Figure 5: Normalized histogram of packet size distribution over a
100 µs periods inside/outside a period of high utilization.
racks where 40% of inter-burst periods last less than 100 µs, but
when idle periods are persistent, they tend to be measured on the
order of hundreds of milliseconds—several orders of magnitude
larger than burst durations. From this data, we can also see that the
arrival rate of µbursts is not a homogeneous/constant-rate Poisson
process. We tested that using a Kolmogorov-Smirnov goodness of
fit test on the inter-arrival time with exponential distribution, and
got a p-value close to 0, allowing us to reject the null hypothesis
that the burst arrivals are Poisson.
5.3 Packet size distribution
The overall packet size distribution of our traffic conforms to prior
work: Hadoop sees mostly full-MTU packets, while Web and Cache
sees a wider range of packet sizes [6, 18].
Interestingly, however, burst and non-burst periods can some-
times differ substantially in their makeup. This effect varies from
application to application, but generally speaking, bursty periods
tend to include more large packets than non-bursty periods. Fig. 5
compares the two cases using packet size histograms for the three
rack types we measured. Packets were binned by their size into sev-
eral ranges and polled alongside the total byte count of the interface
in order to classify the samples.
The increase in large packets during bursts exists, but is not
very pronounced in Hadoop, where the vast majority of packets are
always large. Cache servers see a relative large-packet increase of
about 20%, but smaller packets still dominate measurements. Web
servers see a large relative increase of about 60% coming from all
other packet sizes. The material packet-level difference between
packets inside and outside bursts suggests that bursts at the ToR
layer, even in the Hadoop case, are often a result of application-
behavior changes, rather than random collisions.
Figure 6: CDF of link utilization at a 25 µs granularity.
5.4 High-resolution network utilization
Taking the links as a whole (both burst and non-burst periods),
we find that different applications have different utilization pat-
terns, but that all of them are extremely long tailed (Fig. 6). As
such, our choice of 50% as a high-utilization threshold generates
similar results compared to other possible thresholds—when bursts
occur, they are generally intense, particularly for Hadoop, which
spends 10% of sampling periods at close to 100% utilization. Further
demonstrating the burstiness of network traffic, we find that Cache
and Hadoop have multimodal utilization at this granularity. Of the
three types, Hadoop ports spend the most time in bursts at ∼15%.
6 CROSS-PORT BEHAVIOR
Given observations of the bursty behavior of individual links in
data center networks, we now delve into the synchronized behavior
of those ports. Conceptually, each switch’s ports can be split into
two classes: uplinks and downlinks. The uplinks connect the rack
to the rest of the data center, and modulo network failures, they are
symmetric in both capacity and reachability. Downlinks connect to
individual servers, which in our data set all serve similar functions.
The granularity of our measurements allows us to explore the rela-
tionships between these ports at the scale of individual congestion
events.
6.1 Efficacy of network load balancing
ToR switches use Equal-Cost MultiPath (ECMP) to spread load over
each of their four uplinks. In principle, a per-packet, round-robin
protocol would perfectly balance outgoing traffic. In practice, how-
ever, typical ECMP configurations introduce at least two sources
of potential imbalance in order to avoid TCP reordering: (1) ECMP
operates on the level of flows, rather than packets, and (2) it uses
consistent hashing, which cannot guarantee optimal balance.
Uplinks are unbalanced at small timescales. High-resolution
measurements allow us to more accurately quantify how much
these differ from optimal. The instantaneous efficacy of load bal-
ancing has implications for drop- and latency-sensitive protocols
like RDMA and TIMELY [13]. Fig. 7a shows the mean absolute de-
viation (MAD) of the four uplinks within a sampling period (40 µs