what adversary gains from it, and how it is performed. As MSGs
represent a set of Windows APIs, and each API description can
be obtained from MSDN, MSG Classifier performs MSG-to-MITRE
ATT&CK techniques by leveraging mainly API descriptions from
MSDN and descriptions of MITRE ATT&CK techniques. The MSG
Classifier represents each API and MITRE technique as a vector
and uses these vectors for real-time MSG to MITRE classification.
Figure 5 and Figure 6 show the process of the vector representation
extraction, and MSG to MITRE classification, respectively. In this
section, we describe the MSG Classifier’s data, components, and
classification process.
Data Collection: MSG Classifier maps MSG to a MITRE tech-
nique using MITRE techniques’ descriptions, APIs’ descriptions,
and Stack Overflow Windows-related question-answer pairs. Stack
Overflow is a website where programmers ask questions regarding
code implementation, and users post answers to their questions.
Since APIs’ descriptions are a low-level description of Windows
actions, while MITRE techniques are high-level attack descriptions,
Stack Overflow was leveraged to fill this knowledge gap. For ex-
ample, a MITRE technique description can mention the "taking
a screenshot" action. However, no API description mentions this
action since taking a screenshot is a higher-level action and needs
several APIs to be achieved. Therefore, Stack Overflow questions re-
garding taking a screenshot in Windows are leveraged by extracting
APIs from users’ highly rated answers.
Our data collection consists of 525 MITRE enterprise techniques,
7,241 APIs, and 10,289 Stack Overflow question-answer pairs, where
the answer contains at least one API. We only include Stack Over-
flow questions with Windows-related tags, such as winapi and
win32, and excluded questions with irrelevant tags such as Pow-
ershell and .Net. We extract all APIs from the answers by first
tokenizing the code part in the answers and only retrieve tokens
that match an API from our API list.
Preprocessing: MITRE techniques’ descriptions, APIs’ descrip-
tions, and Stack Overflow questions contain many non-essential
words that can negatively affect mapping. These words are called
stop words and are defined as words that frequently occur in a
text but with no contribution to its meaning. Examples of stop
words are to-do verbs and prepositions(e.g., about, in, and below).
Our list of stop words is the same list defined by the NLTK [19]
library. We also added to the list some domain-specific words such
as "windows" and "c." We also cleaned out low occurring words
which occur less than a predefined threshold that we denote as
minimum word frequency. Low occurring words expand the space
complexity of our task while not contributing to the overall results.
Finally, we filter out punctuation and numbers, lemmatize verbs to
their base form, and convert all text to lowercase.
RegOpenKeyRegQueryValueRegCloseKeyCreateToolhelp32SnapshotProcess32FirstProcess32NextFindFirstFileCreateFileGetFileTypeSetFilePointerReadFileCloseHandleG1G2G3ReadFilePre-processingAPI descriptions and question titles merging MITREATT&CKMSDNStack OverflowPre-processingSub-techniques mergingTF-IDFKeywordselecion Word2vecMITRE techniquesvector representation APIs vector representation EnrichingTF-IDFAPI text descriptionsMITRE text descriptions678SODA: A System for Cyber Deception Orchestration and Automation
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
predefined threshold. We denote these words as keywords. Second,
we enrich each description using a Word2vec model we trained on
MITRE technique descriptions, API descriptions, and Stack Over-
flow questions. Word2vec [36] is a word embedding model that rep-
resents words by vectors of multiple dimensions based on their co-
occurrence. In Word2vec vector representation, words that highly
co-occur in the training text will get similar vectors. This Word2vec
behavior helps us to find words similar to words in API full descrip-
tion. We enrich each API full description by adding words similar
to the description’s keywords with a similarity above a predefined
threshold. Third, we extract the TF-IDF score from the enriched
descriptions, which will output a vector for each API similar to the
MITRE technique vector we mentioned before.
Classification: When MSG Classifier gets an MSG as an input,
it generates a vector representation of the MSG by computing the
average of the APIs’ vectors of the MSG. When computing the
average vector, all elements with a value of zero are discarded. For
example, if an MSG containing 3 APIs and the values of the first
element of each API’s vector are 20%, 30%, and 0, the first element
of the generated vector will have a value of 25%. MSG Classifier
then calculates the cosine similarity between the average vector
and all MITRE techniques’ vectors. The higher the similarity, the
more likely the MSG belongs to a technique. MSG Classifier outputs
all MITRE techniques ranked by their similarity to the MSG. The
MSG is then mapped to the highest-ranked technique.
3.3 Deception Factory Synthesis
In this section, we enumerate all possible Deception Ploys for dif-
ferent malicious behaviors, strategies and 4D deception goals. It is
possible to create a Deception Playbook that covers all the ploys we
listed. However, we choose to break down these ploys and create
profiles based on the co-occurrence of different behaviors. After
finishing these profiles, we utilize the mapped MSGs to develop
WinAPI hooks. WinAPI hooks enable us to intercept malware exe-
cution and change the response as we desire. We state the details
in the following sections.
3.3.1 4D Deception Goals and Strategies. An attacker can be
deceived in multiple ways. To design a deception framework we
need to consider 4D deception goals: diversion, distortion, deple-
tion, and discovery (Details can be found in Appendix A). Since
we implement the deception through API hooking, there are four
ways we can respond to the malware: FakeFailure, FakeSuccess, Fa-
keExecute, and NativeExecute. We call these approaches Deception
Strategies (more details about them are in Appendix B).
3.3.2 Deception Ploy Creation. Given 4D deception goals and
four deception strategies, we can design sixteen possible deception
techniques (or deception ploys) for each malicious behavior. How-
ever, not all of these techniques will make sense. Therefore, firstly,
we create all possible deception techniques, then we verify each
technique and filter out those that do not make sense. For example,
the user can choose only one ploy for each malicious behavior.
For better understanding, we explain the creation, verification and
filtration process with Table 1.
Let’s say the malware behavior is “Stealing from credential files"
if we want to deceive this behavior with the FakeFailure strategy,
Figure 6: MSG to MITRE technique classification
MITRE and API text representation: We represent each MIT
-RE technique by its main description and its procedure examples’
description. A technique’s procedure examples are a brief descrip-
tion of malicious entities that uses the corresponding technique
and their way of using it. For techniques that have sub techniques,
we merged all the sub techniques’ descriptions and appended them
to the parent technique’s description.
We represent each API by three types of text: the API description
taken from MSDN, all Stack Overflow questions’ titles in which the
API exists in the answers, and words that form the API name. For
example, words that form the API CreateFile are Create and File.
We merged all these texts for each API and used them as API text
representation. We denote the new merged API description as API
full description.
MITRE vector representation: We represent each MITRE tech-
nique by a vector. Each index of the vector corresponds to a word
and its value is the TF-IDF score of the word. A TF-IDF score re-
flects the importance of a word in a document in comparison to
other documents. This importance is measured based on the word’s
frequency in the current document compared to other documents.
The TF-IDF score of a word w in a document d from the set of
documents S is:
Where:
tf-idf(w,d,S) = tf (w,d).idf(w,S)
tf (w,d) = loд(1 + f req(w, d))
idf (w,S) = loд(
count(d ∈ S : w ∈ d))
N
Here, freq(w,d) is the number of times the word w appears in
document d, count(d ∈ S : w ∈ d) is the number of documents in
which the word w appears and N is the number of documents in
S. Therefore, the TF score corresponds to the frequency of a word
occurrence in a document, and the IDF score corresponds to the
number of documents that contain the word. The TF score is directly
proportional to the frequency of occurrence, while the IDF score is
inversely proportional to the number of documents that contain
the word.
The vector representation V of a MITRE technique m1:
Vm1 = [tf-idf(w1, dm1 , S), tf-idf(w2, dm1 , S), ..., tf-idf(wn, dm1 , S)]
We only keep the highest scored words in each technique repre-
sentation and set other words’ scores to zero.
API vector representation: We extract each API vector rep-
resentation in three steps: keywords extraction, enriching, and
TF-IDF extraction. First, we calculate the TF-IDF score of all words
in each API full description and extract nouns with a score above a
Computeaveragevector MSGMITRE techniquesvector representation APIs vector representation Compute MSG andtechniquessimilarities  MITRE techniques ranked679ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Sajid, et al.
Malware
Behavior
Stealing from
credentials files
Mapped MSG (API Sequence)
1) Search file and steal: FindFirstFile, PathFileExist, CreateFile,
GetFileSize, VirtualAlloc, ReadFile, CloseHandle, VirtualFree,
FindNextFile, FindClose
2) Read sensitive file (known file). CreateFile, ReadFile
3) Steal from the browsers. CreateFile, GetFileSize,
VirtualAlloc, ReadFile, CryptUnprotectData, CreateFile,
WriteFile, CloseHandle
Strategy
FakeFaliure
Deception Goal
D1 D2 D3 D4
-
✓
-
-
✓
✓
✓
✓
FakeSuccess
-
FakeExecute
✓
NativeExecute
-
-
-
-
Deception Actions
Diversion: pretend the File doesn’t exist by
returning false when PathFileExist is called
1) Depletion: replace sensitive file reading with
static HoneyFile containing Honey Credentials.
2) Discovery: watch out for Exfiltration.
1) Diversion: forward the execution to HoneyFactory
(false target).
2) Depletion: communicate with HoneyFactory. Ask
for HoneyFile containing Honey Credentials. Replace
sensitive data with the content of HoneyFile.
3) Discovery: watch out for Exfiltration.
-
✓ Discovery: watch out for Exfiltration
Table 1: Deception ploy creation and verification (D1 = diversion, D2 = distortion, D3 = depletion, D4 = discovery).
we can only achieve Diversion. The deception action would be to
pretend the sensitive file doesn’t exist on the system; therefore, we
divert the malware to no target. Now, if the deception strategy is
FakeSuccess, we can achieve only Depletion and Discovery. In
the case of Depletion, the credential files can be leveraged to feed
the attacker fake login credentials and deplete her resources and
effort. An even better scheme is to create an encrypted version of an
invalid password and forward it to the attacker, which will burden
the attacker to decrypt the password, hence further depleting the
attacker’s resources. Since we provide the fake credentials and the
malware performs read operations on them, the malware will likely
try to exfiltrate the data to the attacker. Hence, this strategy also
enables us to Discover another malicious behavior of the malware.
This is how we identify all possible combinations of Deception
Strategies and Goals that are valid and create deception actions for
them. These valid deception actions are considered deception ploys
and later used to create Deception Playbook.
3.3.3 Deception Playbook Creation. We perform frequent item-
set mining to identify highly associated MSGs, and then we use
such MSGs to create Deception Playbook profiles. For example,
let’s say deception ploys (or deception techniques) T1,T2,T3, ...,T6
are created for malicious behaviors B1, B2, B3, ..., B6, respectively. If
B1, B2 and B3 are in a frequent itemset then we can create a profile
P1 containing T1,T2 and T3. If the victim is hit by malware having
behaviors B1, B2 and B3, we can deploy P1 to deceive the malware.
Frequent itemset mining is a data mining approach that identifies
items that appear frequently together. A set of items (in our case,
malicious behaviors) is considered frequent if it satisfies a minimum
threshold value for support and confidence. The support is an indica-
tion of how frequent the set of malicious behaviors appears in the
dataset. Confidence is the likelihood that if one behavior appears
then the other behavior also appears. Let B = {B1, B2, B3, ..} be a
set of n binary attributes called Malware Behaviors (items), then
Support and Confidence can be defined as:
Support(B) = N umber of malwar e in which B appears
T otal number of Malwar e in the dataset
Con f idence(B1 → B2) = Suppor t(B1∪B2)
Suppor t(B1)
The frequent pattern mining technique is used to discover rela-
tionships between different items (malware behaviors) in a dataset
(malware dataset). These relationships are represented in the form
of association rules. Let L = {L1, L2, L3, ...} be a set of log files col-
lected from malware as execution traces. Each log in L represents
a unique malware from our dataset and contains a subset of the
Malware Behaviors (items) in B. An association rule is defined as
an implication of the form B1 → B2 where B1, B2 ∈ B, and the
strength of the association between B1 and B2 can be measured
by Con f idence(B1 → B2) defined above. We leveraged APRIORI, a
well establish algorithm, to find frequent itemsets (malware behav-
iors) and association rules. We calculate support and confidence for
extracted MSGs and identify frequent malware behavior sets that
are above the threshold value. Deception ploys for those highly
associated MSGs are grouped and stored as profiles.
Deception Playbook accommodates all the created profiles and
only the appropriate profile is deployed. Furthermore, SODA allows
users to create custom profiles. Profiles indicate which deception
ploys to be activated. Upon profile/creation or selection, a configu-
ration file (in JSON format) is generated and later used by WinAPI
hooks to decide which ploys to activate.
3.3.4 Deception Factory Implementation. The deception fac-
tory is the implementation of the actions under the deception play-
book. The deception actions are implemented using WinAPI hook-
ing (also known as API hooking). Our API hooks are created as DLL
files (we call it End-Point DLL) and injected into malware via the
DLL injection approach. API hooking is a well-known approach to
intercept API calls invoked by the targeted executable, allowing us
to monitor or modify API response. We implemented API hooking
using EasyHook [5]. In Appendix A, we describe how API hooking
works.
How deception technique works inside the hooks: To de-
ceive a particular malicious behavior, we hook some of the WinAPIs
(MSG) mapped to it. Deception ploys are implemented and embed-
ded inside these hooks. Let’s discuss how the deception technique
is implemented inside API hooks using Table 1, where the malicious
behavior is Stealing from credentials files. To be more specific, we
focus on the deception action “providing a HoneyFile containing
Honey Credentials from the HoneyFactory" where the strategy
is FakeExecute and Deception Goal is Depletion. Now let’s fo-
cus on the mapped MSG for this behavior: CreateFile-GetFileSize-
VirtualAlloc-ReadFile-CloseHandle-CryptUnprotectData-CreateFile-
WriteFile-CloseHandle. To realize our deception technique, we don’t
need to hook all of these APIs but only CreateFile, ReadFile and
CryptUnprotectData. Let’s explain how the deception is imple-
mented inside the API hook using Figure 7.
The variable known_sensitive_files_browsers stores a list
of known browser files that the attackers target for credential steal-
ing (at line 1). To recognize what malicious behavior is about to
occur, we used the variable malicious_behavior. Each malicious
behavior has an assigned ID, which we set to this variable for
680SODA: A System for Cyber Deception Orchestration and Automation
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Figure 7: A code snippet: How the deception technique is
implemented inside API hooks
internal tracking. When the CreateFile API is called, we check
which file the malware opened (at line 6). If the file is marked as
a sensitive file at line 1, we set malicious_behavior as 5 (ID for
stealing credentials from browsers). It means there is a high possi-
bility of malicious behavior “stealing credentials from browsers"
to take place. We assign the current file handle to the variable
Handle_under_observation as any operation on this file han-
dle is suspicious. On the next ReadFile invocation, we check the
file handle to confirm the malware performs a read operation on
the target file (at line 20). The ReadFile operation assigns the
data read from the sensitive file to lpBuffer. The data held by
lpBuffer is critical because it contains the credentials. However,
the data is encrypted, so the malware calls CryptUnprotectData
to decrypt data that reveals the credentials as plaintext. Therefore,
when CryptUnprotectData is invoked, we check whether the data
to be decrypted is the same as the buffer_under_observation
(at line 33), if same, we communicate with HoneyFactory through
REST API and ask for a HoneyFile containing HoneyCredentials (at
line 38). CryptUnprotectData decrypts data and stores the data in
pDataOut->pbData. We replace this pbData buffer with the con-
tent of the HoneyFile received from the HoneyFactory (at line 41).
Ultimately, the malware gets the HoneyCredentials instead of the
actual user credentials. Note that at the start of each detour function
(lines 5, 18, and 30), we check if the API belongs to the activated
ploys, based on a configuration file.
Honey Factory (HF) Creation: SODA often depends on ex-
ternal HoneyFactory (HF) to deceive malware, mainly when the
Deception Strategy is FakeExecute. Since deception ploys are pre-
defined and their actions are known, we create HF offline depending
on the requirement of these actions/ploys. The HF consist of honey
files, credentials, passwords, decoy user accounts, email accounts,