To provide such an attestation, the attestor executes
the PAL as described above. When the legacy OS re-
sumes, it can request a quote of PCRs 17 and 18 from the
TPM. It must also provide the TPM with a nonce from
the veri(cid:2)er, which provides freshness and replay preven-
tion. The TPM will produce a signature over the nonce
and the values stored in the PCRs. Using the TPM’s
AIK (Attestation Identity Key), the veri(cid:2)er can check
the authenticity of the quote, and use its knowledge of
the PAL and its inputs and outputs to verify that the val-
ues in PCRs 17 and 18 correspond to their expected val-
ues. Thus, the veri(cid:2)er can be satis(cid:2)ed that the PAL ran
with the appropriate protections, even though the quote
itself was requested from the TPM by the untrusted OS.
Multiple Invocations. While some PALs may only re-
quire one invocation (e.g., generating a user’s SSH key-
pair), many applications may require multiple invoca-
tions. For example, an SSL server might wish to use
a PAL that creates a public keypair and then on future
invocations uses that keypair to establish an SSL con-
nection. Multiple invocations can also be used to break
a long-running PAL into shorter pieces, thus achieving
a rough form of cooperative multi-tasking with the OS.
A PAL can secure data between invocations by using
the TPM to seal its data under the value of PCR 17 (en-
suring the data will be available only when PCR 17 con-
tains this value). Since PCR 17 is reset by the SKINIT
instruction and then immediately extended with the hash
of the PAL, only a future invocation of the same PAL
using SKINIT can produce the same value for PCR 17.
Thus, no other PALs will be able to access its secrets.
A PAL can even choose to seal its secrets so that
a different PAL can access them. For instance, a key-
generation PAL might seal the resulting keys so that a
separate key-usage PAL could access them. This can
be accomplished by having the (cid:2)rst PAL seal its secrets
under the value of PCR 17 that would result from reset-
ting the PCR and then extending it with a measurement
(hash) of the second PAL.
Secure Communication. Remote parties may wish to
communicate securely with a PAL executing on another
machine. By creating a secure channel between the PAL
and the remote party, the secrecy and integrity of infor-
mation passed between them can be protected, even if all
of the other software on the host has been compromised.
We need not include communication software (such as
network drivers) in the PAL’s TCB, since we can use
multiple invocations of a PAL to process data from the
remote party while letting the untrusted OS manage the
encrypted network packets.
Figure 2 illustrates a protocol for securely conveying
a public key from the PAL to a remote party. This proto-
col is similar to one developed at IBM for linking remote
attestation to secure tunnel endpoints [8]. The PAL gen-
erates a keypair fKPAL; K (cid:0)1
PALg within its secure exe-
cution environment. It seals the private key K (cid:0)1
PAL un-
der the value of PCR 17 so that only the identical PAL
invoked in the secure execution environment can ac-
cess it. Note that the PAL developer may extend other
application-dependent data into PCR 17 before sealing
the private key. This ensures the key will be released
only if that application-dependent data is present.
The nonce value sent by the remote party for the TPM
quote operation is also provided as an input to the PAL
for extension into PCR 18. This provides the remote
party with a different freshness guarantee: that the PAL
was invoked in response to the remote party’s request.
Otherwise, a malicious OS may be able to fool multiple
remote parties into accepting the same public key.
As with all output parameters, the public key KPAL
is extended into PCR 18 before it is output to the ap-
plication running on the untrusted host. The application
generates a TPM quote over PCRs 17 and 18 based on
the nonce from the remote party. The quote allows the
remote party to determine that the public key was indeed
generated by a PAL running in the secure execution en-
vironment. The remote party can use the public key to
create a secure channel to future invocations of the PAL.
5 Open Problems
While our architecture meets the goals from Sec-
tion 3.1, a number of challenges remain.
Malicious or Malfunctioning PALs.
In this work,
we have primarily focused on a scenario in which the
PAL is trusted, but the OS or other applications may
be subverted. However, a malicious (or malfunction-
ing) PAL poses a threat to a legitimate OS, since by
default, the PAL has access to the entire memory con-
tents of the system and need not return control to the OS.
Thus, without further protections in place, a legitimate
OS should launch only PALs it trusts.
Several methods exist by which a legitimate OS could
gain con(cid:2)dence in the trustworthiness of a PAL. For
example, since each PAL should be relatively small, it
may be possible to apply various formal analysis tech-
niques [6] to gain con(cid:2)dence in it. Alternately, the OS
could require each PAL to be accompanied by a proof
of its safety [15].
4
Remote
has AIKserver,
expected hash(PAL jj shim) = ^H
Party (RP):
RP:
generate nonce
RP ! App:
nonce
App ! PAL: nonce
PAL:
extend(PCR18; nonce)
generate fKPAL; K (cid:0)1
PALg
extend(PCR18; h(KPAL))
seal(PCR17; K (cid:0)1
extend(PCR17; ?)
extend(PCR18; ?)
PAL)
PAL ! App: KPAL
App:
App ! RP:
RP:
q; KPAL
q   quote(nonce; f17; 18g)
if (:Verify(AIKserver; q; nonce)
_ q:PCR17 6= h(h(0jj ^H)jj?)
_ q:PCR18 6=
h(h(h(0jjnonce)jjh(KPAL))jj?)
RP:
) then abort
has authentic KPAL
knows server ran SEA
Figure 2. Protocol to generate and convey the public
key KPAL to a remote party (RP). Note that the mes-
sages between the application (App) and the PAL can
safely travel through the untrusted portion of the appli-
cation and the OS kernel. ? denotes a well-known value
which signals the end of extensions performed within
the SEA.
At the cost of a slight expansion in the TCB, we could
implement protections to constrain a PAL dynamically
and limit the damage it can cause. These controls might
take the form of running the PAL in CPU privilege ring
3 (only the shim would execute in ring 0) and using seg-
mentation and/or page table permissions to constrain its
memory accesses or employing various forms of soft-
ware fault isolation [22].
Of course, a malicious PAL could be invoked by
an already-compromised OS, potentially bypassing the
protections described above. However, since the SKINIT
instruction is privileged, only code operating at ring 0
can launch a PAL. Since code at that level already con-
trols the entire system, malicious code at ring 0 need not
launch a malicious PAL to conduct an attack.
Slow PALs. While we envision PALs as small pieces
of code that rapidly execute and return, one can imagine
the need for longer running PALs. Since we leave the
OS suspended while the PAL executes, a long-running
PAL may cause the OS to miss large chunks of time.
While we have not yet determined all of the effects
this might have, it could potentially interfere with I/O
or scheduling code in the OS. As discussed in Sec-
5
tion 4.2, using multiple SKINIT invocations to break a
long-running PAL into several shorter PALs may alle-
viate this problem. Determining the modi(cid:2)cations nec-
essary to allow the OS to adapt to long-running PALs is
a direction for future work.
Program Separation.
Ideally, the PAL should consist
of the minimal amount of code necessary to carry out a
security-sensitive task. Rather than including an entire
application in the PAL, we would like to separate out
only the security-sensitive portion. In the SSH example,
we would include the password handling routines, but
exclude the portions that encrypt and decrypt network
packets. Such program separation can be performed
manually [11, 12, 14, 16, 20], but researchers have also
developed techniques for automatically decomposing a
program into a security-sensitive portion and a less sen-
sitive remainder [3,5,25]. Fortunately, security-sensitive
code often involves cryptographic computation that does
not rely on sophisticated operating system services and
hence it can easily be packaged into a PAL.
User Interaction. While much of our early design
focuses on a scenario in which a server uses SEA to
perform security-sensitive operations with a client com-
puter serving as a remote veri(cid:2)er, SEA could also sig-
ni(cid:2)cantly improve the security of client computers. For
example, our architecture would enable an application
that allows a user to securely enter her password regard-
less of what other software or malware might be resident
on the PC. However, secure entry is not enough; the user
must also be careful not to enter her password into an in-
secure application. For example, malware might try to
convince the user that the secure password application
had been launched and thereby capture her password.
Thus, we plan to explore techniques for constructing a
secure path from a PAL to the user, i.e., convince the
user to enter her password or other sensitive information
if and only if the secure password application is running.
6 Related Work
Researchers previously achieved some of the proper-
ties provided by our architecture using specialized se-
cure coprocessors [11, 24]. While our work does not
achieve the same level of physical tamper-resistance,
it provides the same strong software guarantees using
modern commodity hardware.
Early schemes for attesting to a platform’s software
state include the entire software stack (e.g., BIOS, boot-
loader, OS) [2, 14, 18], making it dif(cid:2)cult to extract
meaningful guarantees from the resulting attestations.
Property-based attestation has been proposed [17] as a
mechanism for providing meaningful attestations; un-
fortunately, evaluating software for the various proper-
ties of interest remains an open problem.
[7] S. Garriss, R. C·aceres, S. Berger, R. Sailer, L. van Doorn, and
X. Zhang. Towards trustworthy kiosk computing. In Workshop
on Mobile Computing Systems and Applications, Feb. 2006.
[8] K. Goldman, R. Perez, and R. Sailer. Linking remote attestation
to secure tunnel endpoints. Technical Report RC23982, IBM,
June 2006.
[9] D. Grawrock. The Intel Safer Computing Initiative: Building
Blocks for Trusted Computing. Intel Press, 2006.
[10] Intel Corporation. LaGrande technology preliminary architec-
ture speci(cid:2)cation. Intel Publication no. D52212, May 2006.
[11] S. Jiang, S. Smith, and K. Minami. Securing web servers against
insider attack. In Proceedings of the IEEE Computer Security
Applications Conference, 2001.
[12] D. Kilpatrick. Privman: A library for partitioning applications.
In USENIX Annual Technical Conference, 2003.
[13] D. Magenheimer. Xen/IA64 code size stats. Xen devel-
oper’s mailing list: http://lists.xensource.com/,
Sept. 2005.
[14] J. Marchesini, S. W. Smith, O. Wild,
J. Stabiner, and
A. Barsamian. Open-source applications of TCPA hardware. In
the IEEE Computer Security Applications Conference, 2004.
[15] G. C. Necula and P. Lee. Safe kernel extensions without run-time
checking. In Proceedings of OSDI, Oct. 1996.
[16] N. Provos, M. Friedl, and P. Honeyman. Preventing privilege
escalation. In the USENIX Security Symposium, Aug. 2003.
[17] A.-R. Sadeghi and C. St¤uble. Property-based attestation for com-
puting platforms: caring about properties, not mechanisms. In
the Workshop on New Security Paradigms, Sept. 2004.
[18] R. Sailer, X. Zhang, T. Jaeger, and L. van Doorn. Design and
implementation of a TCG-based integrity measurement architec-
ture. In Proceedings of the USENIX Security Symposium, 2004.
[19] L. Singaravelu, C. Pu, H. Haertig, and C. Helmuth. Reducing
TCB complexity for security-sensitive applications: Three case
studies. In Proceedings of ACM EuroSys, 2006.
[20] R. Ta-Min, L. Litty, and D. Lie. Splitting interfaces: Making
trust between applications and operating systems con(cid:2)gurable.
In Proceedings of OSDI, Nov. 2006.
[21] Trusted Computing Group. Trusted platform module main spec-
i(cid:2)cation. http://www.trustedcomputinggroup.org,
Mar. 2006. Version 1.2, Revision 94.
[22] R. Wahbe, S. Lucco, T. Anderson, and S. Graham. Ef(cid:2)cient
software-based fault isolation. In SOSP, Dec. 1993.
[23] D. A. Wheeler.
Available at:
linux-kernel-cost.html, Oct. 2004.
Linux kernel 2.6:
It’s worth more!
http://www.dwheeler.com/essays/
[24] B. S. Yee. Using Secure Coprocessors. PhD thesis, Carnegie
Mellon University, 1994.
[25] S. Zdancewic, L. Zheng, N. Nystrom, and A. Myers. Secure
program partitioning. ACM Transactions on Computer Systems,
20(3):283(cid:150)328, Aug. 2002.
Other researchers have leveraged VMMs to execute
security-sensitive code in isolation [19, 20]. Garriss
et al. employ the new SKINIT instruction to eliminate
the BIOS and the bootloader from their attestations and
TCB [7], but as suggested in the original design [9], af-
ter the SKINIT, they launch a standard OS or VMM.
Thus, application security depends on these large layers
of code.
7 Conclusion and Future Work
In this work, we propose a Secure Execution Archi-
tecture (SEA) for executing code with strong hardware-
based isolation guarantees. We also describe how to
convince a remote party that protected execution oc-
curred and how to construct secure communication
channels to the security-sensitive code, but various inter-
esting questions remain open. Compared with modern
operating systems (or even VMMs), our approach adds a
minuscule amount of code to an application’s TCB, pro-
vides (cid:2)ne-grained, meaningful attestations, and allows
application writers to focus on the security of their own
code instead of worrying about the safety of the many
layers of code beneath them.
We are continuing to explore the open problems de-
scribed above, and we are in the (cid:2)nal stages of imple-
menting SEA and employing it for various applications.
Acknowledgments
The authors would like to thank Mark Luk, Leendert
van Doorn, and Elsie Wahlig for their generous support
and helpful suggestions. Michael Abd-El-Malek, Scott
Garriss, James Newsome, and Diana Parno provided in-
valuable editing assistance. The feedback and comments
from Michael Steiner and our anonymous reviewer were
much appreciated.
References
[1] Advanced Micro Devices. AMD64 architecture programmer’s
manual: Volume 2: System programming. AMD Publication no.
24594 rev. 3.11, Dec. 2005.
[2] W. Arbaugh, D. Farber, and J. Smith. A reliable bootstrap archi-
tecture. In Proceedings of the IEEE Symposium on Research in
Security and Privacy, May 1997.
[3] D. Balfanz. Access Control for Ad-hoc Collaboration. PhD the-
sis, Princeton University, 2001.
[4] P. R. Barham, B. Dragovic, K. A. Fraser, S. M. Hand, T. L. Har-
ris, A. C. Ho, E. Kotsovinos, A. V. Madhavapeddy, R. Neuge-
bauer, I. A. Pratt, and A. K. War(cid:2)eld. Xen 2002. Technical Re-
port UCAM-CL-TR-553, University of Cambridge, Jan. 2003.
[5] D. Brumley and D. Song. Privtrans: Automatically partitioning
programs for privilege separation. In Proceedings of the USENIX
Security Symposium, Aug. 2004.
[6] S. Chaki, E. Clarke, A. Groce, S. Jha, and H. Veith. Modular
veri(cid:2)cation of software components in C. IEEE Transactions on
Software Engineering, 30(6), 2004.
6