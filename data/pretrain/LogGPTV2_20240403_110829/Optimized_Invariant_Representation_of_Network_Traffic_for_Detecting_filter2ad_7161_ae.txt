Malicious
Legitimate
50
40
30
20
10
0
-10
-20
-30
-40
-80
-100
-80
-60
-40
-20
0
Dimension 1
20
40
60
80
100
-50
-60
-40
-20
0
20
Dimension 1
40
60
80
Figure 5: Graphical projection of feature vectors of the
baseline ﬂow-based representation into two dimensions
using t-SNE transformation. Feature vectors from 32
different malware categories are displayed. Due to high
variability of ﬂow-based feature values, legitimate and
malicious samples are scattered without any clear sep-
aration. The results show that the ﬂow-based represen-
tation is suitable for training classiﬁers specialized on a
single malware category, which often leads to classiﬁers
with high precision and low recall.
Figure 6: Graphical projection of feature vectors of the
proposed representation into two dimensions using t-
SNE transformation. Thanks to the invariant properties,
malicious bags from various categories are grouped to-
gether, as they have similar dynamics modeled by the
representation. Most of the legitimate bags are concen-
trated on the left-hand side, far from the malicious bags.
This shows that training a classiﬁer with the proposed
representation will achieve higher recall with compara-
ble precision.
Features applied on URL, path, query, ﬁlename
length; digit ratio
lower/upper case ratio; ratio of digits
vowel changes ratio
ratio of a character with max occurrence
has a special character
max length of consonant/vowel/digit stream
number of non-base64 characters
has repetition of parameters
Other Features
number of bytes from client to server
number of bytes from server to client
length of referer/ﬁle extension
number of parameters in query
number of ’/’ in path/query/referer
Table 3: List of selected ﬂow-based features extracted
from proxy logs. We consider these features as base-
line (as some features were used in previously published
work), and compare it with the proposed representation.
Table 4 from Appendix A describes an important fact
about the URLs from individual malicious bags. As you
can see, URLs within each malicious bag are similar to
each other (as opposed to most of legitimate bags). This
small non-zero variability of ﬂow-based feature values is
captured by the proposed representation using both types
of histograms. The variability is very general but also
descriptive feature, which increases the robustness of the
representation to further malware changes and variants.
8.2 Evaluation on Real Network Trafﬁc
This section shows the beneﬁts of the proposed approach
of learning the invariant representation for two-class
classiﬁcation problem in network security. Feature vec-
tors described in Section 8.1 correspond to input feature
vectors {x1, . . . ,x m} deﬁned in Section 3. These vectors
are transformed into the proposed representation of his-
˜S ;θ ), as described in Section 4. We have
tograms φ ( ˜X;
evaluated two types of invariant representations. One
with predeﬁned number of equidistant bins (e.g. 16, 32,
etc.) computed as described in Section 4, and one when
the representation is learned together with the classiﬁer
to maximize the separability between malicious and le-
gitimate trafﬁc (combination of Section 4 and 5). For the
representation learning, we used 256 bins as initial (and
most detailed) partitioning of the histograms. During the
learning phase, the bins were merged together, creating
12.7 bins per histogram on average.
Both approaches are compared with the baseline ﬂow-
based representation used in previously published work,
where each sample corresponds to a feature vector com-
puted from one ﬂow. Results of a widely used signature-
based security device are also provided (see Table 2)
to demonstrate that the positive samples included in the
evaluation pose a real security risk, as majority of them
USENIX Association  
25th USENIX Security Symposium  817
11
lambda=0.00010, trnerr=2.4%, tsterr=14.8%
lambda=0.01000, trnerr=10.4%, tsterr=13.5%
feature x
y
e
r
u
t
a
e
f
y
e
r
u
t
a
e
f
t
i
h
g
e
w
2
1.5
1
0.5
0
-0.5
-1
-1.5
-2
1
0.5
0
t
i
h
g
e
w
50
100 150 200 250 300 350 400
feature
feature x
-0.5
-1
50
100 150 200 250 300 350 400
feature
Figure 7: Visualization of the proposed method of learn-
ing the invariant representation on 2-dimensional syn-
thetic data. Figures in the left row show the decision
boundaries of two class classiﬁer learned from the bins
for two different values of parameter λ (0.0001, 0.01)
which controls the number of emerging bins (the corre-
sponding weights are shown in the right row). With in-
creasing λ the data are represented with less bins and the
boundary becomes smoother and less over-ﬁtted to the
training data.
was not detected. Maximum number of ﬂows for each
bag was 100, which ensures that the computational cost
is controlled and does not exceed predeﬁned limits.
Two-dimensional projection of the feature vectors for
the ﬂow-based and the proposed representation is illus-
trated in Figures 5 and 6 respectively. Bags from 32 mali-
cious categories are displayed with red circles, while the
legitimate bags are denoted with green circles. The pro-
jections show that the ﬂow-based representation is suit-
able for training classiﬁers specialized on a single mal-
ware category. In case of the proposed representation,
malicious bags from various categories are grouped to-
gether and far from the legitimate trafﬁc, which means
that the classiﬁers will have higher recall and compara-
ble precision with the ﬂow-based classiﬁers.
Next, we will show the properties of the proposed
method of learning the representation to maximize the
separation between positive and negative samples (see
Section 5 for details). Figure 7 visualizes the proposed
method on synthetic 2-dimensional input data. The input
2D point (x,y) ∈ R2 is represented by 4-dimensional fea-
ture vector (x2,y2,x + y,x− y). Each of the 4 features is
then represented by a histogram with 100 bins (i.e. each
feature is represented by 100 dimensional binary vector
will all zeros but a single one corresponding to the active
bin). Figures in the top row show the decision bound-
aries of two-class classiﬁers learned from data. The bot-
found 130 bins
0.15
0.1
0.05
0
l
e
u
a
v
t
-0.05
i
h
g
e
w
-0.1
-0.15
-0.2
50
100
150
200
250
Figure 8: Weights (blue bars) and derived bins of a his-
togram (red line) for a standard SVM and one of the in-
variant features. Since the bins are equidistant and pre-
deﬁned at the beginning, the resulting histogram (deﬁned
by the red line) has complicated structure, leading most
probably to complex boundary and over-ﬁtted results (as
shown in Figure 7 on the left hand side).
found 18 bins
l
e
u
a
v
t
i
h
g
e
w
0.4
0.3
0.2
0.1
0
-0.1
-0.2
-0.3
-0.4
50
100
150
200
250
Figure 9: Weights (blue bars) and derived bins of a his-
togram (red line) for the proposed bin optimization. In
this case, the weights show a clear structure and the de-
rived histogram has only 18 bins. The decision boundary
is in this case smoother and the classiﬁer trained from
this representation will be more robust. Green dashed
lines also show how the histogram bins would look like
if they are positioned equidistantly (16 bins).
tom row shows the weights of the linear classiﬁer corre-
sponding to the bins (in total 400 weights resulting from
100 bins for each out of 4 features). The columns corre-
spond to the results obtained for different setting of the
parameter λ which controls the number of emerging bins
and thus also the complexity of the decision boundary.
With increasing λ the data are represented with less bins
and the boundary becomes smoother. Figure 7 shows the
principle of the proposed optimization process. The bins
of the representation are learned in such a way that it
is much easier for the classiﬁer to separate negative and
positive samples and at the same time control the com-
818  25th USENIX Security Symposium 
USENIX Association
12
feature indexfeature indexe
t
a
R
e
v
i
t
i
s
o
P
e
u
r
T
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
ROC Curve for Test Data
flow-based
bag mean
bag variance
bag combined
optimized bag combined
ROC Curve for Test Data - Log Scale
flow-based
bag mean
bag variance
bag combined
optimized bag combined
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
t
e
a
R
e
v
i
t
i
s
o
P
e
u
r
T
0
0.2
0.4
0.6
False Positive Rate
0.8
1
0
10-5
10-4
10-3
10-2
False Positive Rate
10-1
100
Figure 10: ROC curves of SVM classiﬁer on test data for ﬁve types of representations (logarithmic scale on the right).
Flow-based representation shows very unsatisfactory results showing that ﬂow-based approach cannot be applied in
practice to detect unseen malware variants. The combination of feature values with feature differences histogram (bag
combined) led to signiﬁcantly better efﬁcacy results. These results were further exceeded when the parameters of the
invariant representation were learned automatically from the training data (optimized bag combined).
plexity of the classiﬁer.
Figures 8 and 9 show the bins and weights learned
from the training set of real network trafﬁc. The blue ver-
tical lines represent learned weights associated with 256
bins of a histogram computed on a single input feature.
The red lines show new bins derived from the weights by
merging those neighboring bins which have the weights
with the same sign. Figure 8 shows the weights and the
derived bins for a standard SVM which has no incentive
to have similar weights. The histogram derived from the
SVM weights reduces the number of bins from 256 to
130. Figure 9 shows the results for the proposed method
which enforces the similar weights for neighboring bins.
In this case, the weights exhibit a clear structure and the
derived histogram has only 18 bins. The decision bound-
ary is in this case smoother and the classiﬁer trained from