ing to the primary  view  V8. Finally,  S2 partitions  and SI 
reenters  the new  primary  view  V10.  If  wchg(V10) is  de- 
livered before reconfiguration  for S3 and S4 is completed, 
then there would be a primary view in which no member is 
able to process transactions.  A further sub-protocol capable 
of discovering this situation is necessary. 
This complexity is induced because  a member of a pri- 
mary view is not necessarily an “up-to-date member”. Only 
5.1. EVS 
EVS replaces the notion  of a view  by  the notion of en- 
riched  view, also called e-view.  An  e-view is a view  with 
additional  structural  information.  Sites in  an  e-view  are 
grouped  into  non-overlapping  subviews  and  subviews are 
grouped  into  non-overlapping  subview-sets.  Figure  2  de- 
picts  examples  where  the  outer  ovals  denote  views,  the 
dashed  ovals  indicate  subview-sets and  the  inner  squares 
denote subviews.  As before, a view  change notifies about 
a  change in  the  composition  of  the  e-view  (sites  that  ap- 
pear  to  be  reachable)  and  such  changes  are  performed 
automatically  by  the  system.  Additionally,  EVS  intro- 
duces  e-view  change  events  that  notify  about  a  change 
in  the  structure  of  the  e-view  in  terms  of  subviews  and 
subview-sets  (dashed  arrows  in  the  figure  indicate  e-view 
changes).  In  contrast to view changes, e-view changes are 
requested  by  the  application through  dedicated primitives. 
These  primitives  will  allow  us  to  encapsulate  reconfigu- 
ration:  Subview-SetMerge (subview-set-list) 
creates a new subview-set that is the union of the subview- 
sets given  in  subview-set-list  (e.g.,  the  e-view EV4 is  in- 
stalled as a result  of  a Subview-SetMerge(); note that  this 
e-view differs from the previous one in structure but not in 
composition).  SubviewMerge (subview-list )  cre- 
ates a new subview that is the union of the subviews given 
in subview-list.  The subviews in subview-list must belong 
to the same subview-set and the resulting subview belongs 
to the  subview-set containing the input subviews (e.g., the 
e-view EV5 is installed as a result of a Subview-Merge()). 
The characteristics of EVS are summarized as  follows: 
The system maintains the structure of e-views across view 
changes (in EV3, S3  and SO, SI, SZ, respectively,  are still 
in  their own  subviews and subview-sets).  E-view changes 
between two consecutive view  changes are totally  ordered 
by  all sites in the  view.  Finally,  if  a site installs an e-view 
ew  and then sends a message m, then any site that delivers 
m delivers it after installing ev. Note, that the original defi- 
nition of EVS [4] does not consider total order and uniform 
delivery. However, accommodating these properties will be 
simple since they are orthogonal to the properties of EVS. 
124 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:01:57 UTC from IEEE Xplore.  Restrictions apply. 
Figure 2. Example of  EVS 
5.2. Reconfiguration Using EVS 
Transaction  processing  will  be  allowed  only  within  a 
“primary  subview”,  i.e.,  the  subview  with  a  majority  of 
sites.  Sites whose current  subview  is  not  primary  do not 
process  transactions  (but  might enqueue transaction  mes- 
sages  if  they  are  currently  in  a  reconfiguration  process). 
Figure 2  illustrates  the main  idea.  At  EVO  we  assume all 
sites  to  have  identical  copies of  the  database,  they  are  in 
the  same subview  and  this  subview  is  a  primary  subview. 
Then S3  leaves  the primary view because of  a partition  or 
failure  and re-enters  in  EV3.  Note  that S3  is not  a mem- 
ber  of  the  primary  subview  but  remains  in  its  own  sub- 
view  and  subview-set.  Reconfiguration  is  initiated  by  the 
peer site, say SO, in the primary subview which submits the 
Subview-SetMerge message. When the corresponding 
e-view change is delivered (EV4), each site knows that re- 
configuration  has started.  So  starts transferring data to Ss, 
following any of the solutions presented  previously.  When 
the transfer  is completed and S3  is able to process transac- 
tions autonomously, SO submits the SubviewMerge. The 
delivery of the corresponding e-view change (EV5), which 
includes S3  in the primary subview, represents the final syn- 
chronization point, i.e.,  all sites know that  Ss  has  the cor- 
rect  database state and  executes  transactions  by  itself.  In 
other words,  reconfiguration  is  encapsulated within  the  e- 
view changes EV4 and EV5. 
In  short,  a  primary  view  is  represented differently  de- 
pending  on  whether  transaction  processing  is  enabled  in 
that  view or not, the  former being  the  case only  when  the 
view contains a primary subview.  Moreover, the represen- 
tation  indicates  which  sites can process transactions (those 
in the primary  subview) and which  sites are being brought 
up-to-date  (those whose subview is not primary  but whose 
subview-set  contains a  primary  subview).  The  resulting 
framework enables simpler algorithms with  respect  to  vir- 
tual synchrony as it was depicted in Figure 1 : 
A joining node enters the primary  view as a result of a 
decision  taken by the system, but it is the database sys- 
tem that decides when to issue the Subviewset-Merge() 
for starting the data transfer.  This can be any time after 
the view change, e.g., when the workload  is low. 
When  a  site joins  a  primary  view,  it  realizes  locally, 
whether there is an operational primary subview or not. 
In the first case, it can remain  quiet waiting  for a peer 
site. In the latter case a creation protocol has to be run. 
When a peer site S,  fails (i.e., leaves the primary  view 
and primary  subview) before the data transfer to a join- 
ing  site  Sj  has  completed,  the  sites  remaining  in  the 
primary  subview will  realize  locally that  Sj is not  yet 
up-to-date:  Sj  will be member of the their subview-set 
but not of their subview. 
When a site Sj enters the primary  subview, all sites in 
the view know that Sj is up-to-date and operational. 
When a peer site S, fails and the view excluding S,  is 
still  primary  but there is no longer  a primary  subview, 
all sites in the primary subview realize locally that trans- 
action processing must be suspended. 
The handling of  view  changes and  e-view  changes by 
any  site  S  in  the  primary  subview  can  be  summarized 
as  follows  (Mysubview-Set and  Mysubview  refer  to  the 
subview-set and subview of S): 
I.  View change excluding or including new sites: 
1. New sites:  for each new subview-set sv-s in the view: 
(i) choose deterministically a peer site S,  in the primary 
subview (S, will be the peer site for all sites in sv-s); (ii) if 
S  = S,,  then issue whenever appropriate a 
Subview-SetMerge(MySubview-Set,sv-s). 
2. Site S,  left  the  view and  S,  was  the peer  for  a  site 
S,:  Determine deterministically the  new peer site  5’6. 
If  S  = SL  then:  If  S and S,  are  in different subview- 
sets, then issue a Subview-SetMerge (Mysubview- 
Set, Subview-Set-of-Sj) when appropriate (S, left 
the primary subview before initiating the merge); other- 
wise, resume the data transfer (S and Sj are already in 
the same subview-set but not yet in the same subview). 
3.  A site Sj for which S  was the peer site left the view: stop 
the data transfer to S,. 
4.  S  has left the primary subview (thus the primary  view): 
stop processing transactions and stop any data transfer 
to recovering sites for which S is the peer site (this may 
occur as a result of  partitions). 
II. E-view change  notifying about  the  merging  of  subview- 
sets:  for  each  new subview sw in the  subview-set of  S: 
if S  is the peer site S,  (determined in step l.l), then start 
data transfer to all sites in sv. 
Ill.  E-view change notifying about the merging of  subviews: 
Recovery of  the merged sites is completed. 
Moreover, when the data transfer for all sites of a subview 
SY for  which  S acts  as  peer  site  is  completed,  S  issues 
Subview-Merge(MySubview,sv). 
The behavior  of the joining site Sj  depends on the spe- 
cific reconfiguration  algorithm.  With  all proposed options 
except  for lazy data transfer, Sj  discards transactions until 
it  is in  the same subview-set as the primary  subview (start 
of reconfiguration).  Then it starts enqueueing transactions 
125 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:01:57 UTC from IEEE Xplore.  Restrictions apply. 
and applies them after its database is up-to-date. With lazy 
data  transfer, the  delimiter transaction  T d  will  be  a  trans- 
action  delivered  between  the  Subview-SetMerge and  the 
SubviewMerge event.  The protocol  guarantees  that join- 
ing sites will receive the current database state and join the 
primary  subview as long as there exists a primary  subview 
for sufficiently long time (given by I. 1, 1.2,11, and the Sub- 
viewMerge).  Also, only sites of the primary  subview exe- 
cute transactions and their databases are always up-to-date. 
6. Conclusions 
This paper provides an in-detail discussion  of online re- 
configuration  in  replicated  database  systems  using  group 
communication.  The focus on the paper  is on  two  impor- 
tant issues: efficient data transfer and fault-tolerance. 
In  regard  to data transfer  we propose  several protocols 
with  which  we depict the main  alternatives  for a database 
supported  data  transfer  and  the  most  important  issues  to 
consider: determining the data that must be transferred, ex- 
ploiting information available within the database (e.g., ver- 
sion  numbers, log), maintaining  additional  information  to 
fasten recovery, allowing for high concurrency, etc. 
We  do not  provide  a  final  statement which  of  the  data 
transfer solutions to choose. First, for some of them specific 
characteristics of  the  underlying database  system  must  be 
given. If these features are not provided they have to be im- 
plemented and integrated into the database system. This can 
be very difficult and might not pay  off.  But  the efficiency 
of the solutions also depends on parameters like the size of 
the database, the percentage of data items updated since the 
recovering site failed, etc. We are planning to explore these 
issues by a real implementation based on Postgres-R  [ 141. 
Making the data transfer a task of the database introduces 
problems in regard to fault-tolerance.  Since reconfiguration 
is not  an  atomic operation, simple virtual  synchrony does 
not reflect sufficiently the  state of the different  sites in the 
system.  EVS,  in  contrast, promotes a  programming style 
in  which  the  notion  of  “up-to-date” member  depends on 
the membership of the primary subview, not of the primary 
view.  Using EVS we are able to encapsulate the reconfig- 
uration  process,  and the  database  system  receives  a more 
realistic picture of what is happening in the system. 
References 
[I]  D. Agrawal, G. Alonso, A.  El  Abbadi, and  1.  Stanoi.  Ex- 
ploiting atomic broadcast in replicated databases.  In P roc. 
of  Euro-Par, Passau, Germany, 1997. 
[2]  Y. Amir.  Replication  Using  Group Communication  over 
a  Partioned  Network.  PhD  thesis,  Hebrew  University of 
Jerusalem, 1995. 
[3]  Y. Amir, G. V.  Chockler, D. Dolev, and R. Vitenberg.  Effi- 
cient state transfer in partitionable environments. In Proc. of 
the ERSADS Seminar, Zinal, Switzerland, 1997. 
[4]  0. Babaoglu, A. Bartoli, and G. Dini.  Enriched view  syn- 
chrony:  A  programming paradigm  for  partitionable asyn- 
chronous distributed systems.  lEEE Transactions on Com- 
puters, 46(6):642-658, June 1997. 
[5] 0. Babaoglu, R. Davoli, L. Giachini, and P.  Sabattini.. The 
inherent cost  of  strong-partial view-synchronous communi- 
cation.  In J.-M. HClary and M. Raynal, editors, Distributed 
Algorithms, Lecture Notes in Computer Science, pages 72- 
86. Springer Verlag, 1995. 
[6]  0. Babaoglu, R.  Davoli, and  A.  Montresor.  Group com- 
munication in partitionable systems: Specification and algo- 
rithms.  Technical Report UBLCS-98- I ,  Dept. of  Computer 
Science, University of  Bologna, Apr.  1998.  To  appear in 
IEEE Transactions for Software Engineering. 
[7]  A.  Bartoli. 
Handling  membership changes  in  replicated 
databases based on group communication. Technical report, 
Facolta di Ingegneria, Universita di Trieste, 2000. 
[8]  A.  Bartoli, B. Kemme, and 0. Babaoglu. Online reconfigu- 
ration in replicated databases. Technical report, University 
de Bologna, Italy, 2000. 
[9]  P.  A. Bernstein, V.  Hadzilacos, and N. Goodman.  Concur- 
rency Control and Recovery in Database Systems.  Addison 
Wesley, Massachusetts, 1987. 
101  K. Birman, R. Cooper, T. Joseph, K. Marzullo, M. Makpan- 
gou, K. Kane, E Schmuck, and M. Wood. The ISlS - system 
manual,  Version  2.1,  Technical report, Dept. of Computer 
Science, Cornell University, Sept. 1993. 
1 I ]   M. Buretta. Data Replication.  Wiley Computer Publ., 1997. 
121  J. Holliday, D. Agrawal, and A. E. Abbadi. The performance 
of database replication with  group multicast.  In  Proc.  of 
FTCS, Madison, Wisconsin, 1999. 
131  B. Kemme.  Database Replication for Clusters of  Worksta- 
tions. PhD thesis, ETH Zurich, 2000. 
141  B.  Kemme  and  G.  Alonso.  Don’t be  lazy,  be  consistent: 
Postgres-R, a  new  way  to  implement database replication. 
In Proc. of VLDB, Cairo, Egypt, 2000. 
151  B.  Kemme  and  G.  Alonso.  A  new  approach to  develop- 
ing and implementing eager database replication protocols. 
ACM Transactions on Database Systems, September 2000. 
[I61 L.  E. Moser,  P.  M.  Melliar-Smith, D.  A.  Agarwal,  R.  K. 
Budhia, and C. A. Lingley-Papadopoulos. Totem:  A fault- 
tolerant multicast group communication system. Communi- 
cations of  the ACM, 39(4):54-63,  1996. 
[17]  M.  PatiAo-Martinez,  R.  JimCnez-Peris,  B.  Kemme,  and 
G. Alonso. Scalable replication in database clusters. In Proc. 
of  DISC, Toledo, Spain, 2000. 
[I81  E Pedone, R. Guerraoui, and A. Schiper. Exploiting atomic 
In  Proc.  of  Euro-Par, 
broadcast  in  replicated databases. 
Southampton, England, 1998. 
[19]  D. Powell and other. Group communication (special issue). 
Communications of  the ACM, 39(4):50-97, April  1996. 
[20]  C. Pu  and  A. Leff.  Replica control in distributed systems: 
An asynchronous approach.  In Proc. of  SIGMOD, Denver, 
Colorado, 1991. 
[21]  I.  Stanoi, D. Agrawal, and  A. El  Abbadi.  Using  broadcast 
primitives in replicated databases. In Proc. of  ICDCS, Ams- 
terdam, Holland, 1998. 
[22]  A.  Vaysburd.  Building  Reliable  Interoperable  Distributed 
Objects with the Maestro Tools. PhD thesis, Cornell Univer- 
sity, 1998. 
126 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:01:57 UTC from IEEE Xplore.  Restrictions apply.