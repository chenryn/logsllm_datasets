title:PrivSyn: Differentially Private Data Synthesis
author:Zhikun Zhang and
Tianhao Wang and
Ninghui Li and
Jean Honorio and
Michael Backes and
Shibo He and
Jiming Chen and
Yang Zhang
PrivSyn: Differentially Private Data Synthesis
Zhikun Zhang, Zhejiang University and CISPA Helmholtz Center for 
Information Security; Tianhao Wang, Ninghui Li, and Jean Honorio, 
Purdue University; Michael Backes, CISPA Helmholtz Center for 
Information Security; Shibo He and Jiming Chen, Zhejiang University and 
Alibaba-Zhejiang University Joint Research Institute of Frontier Technologies; 
Yang Zhang, CISPA Helmholtz Center for Information Security
https://www.usenix.org/conference/usenixsecurity21/presentation/zhang-zhikun
This paper is included in the Proceedings of the 30th USENIX Security Symposium.August 11–13, 2021978-1-939133-24-3Open access to the Proceedings of the 30th USENIX Security Symposium is sponsored by USENIX.PrivSyn: Differentially Private Data Synthesis
Zhikun Zhang1,2 Tianhao Wang3 Ninghui Li3
Jean Honorio3 Michael Backes2
Shibo He1,4
Jiming Chen1,4 Yang Zhang2
1Zhejiang University 2CISPA Helmholtz Center for Information Security 3Purdue University
4Alibaba-Zhejiang University Joint Research Institute of Frontier Technologies
Abstract
In differential privacy (DP), a challenging problem is to gen-
erate synthetic datasets that efﬁciently capture the useful in-
formation in the private data. The synthetic dataset enables
any task to be done without privacy concern and modiﬁcation
to existing algorithms. In this paper, we present PrivSyn, the
ﬁrst automatic synthetic data generation method that can han-
dle general tabular datasets (with 100 attributes and domain
size > 2500). PrivSyn is composed of a new method to auto-
matically and privately identify correlations in the data, and a
novel method to generate sample data from a dense graphic
model. We extensively evaluate different methods on multiple
datasets to demonstrate the performance of our method.
1 Introduction
Differential privacy (DP) [21] has been accepted as the de
facto notion for protecting privacy. Companies and govern-
ment agencies use DP for privacy-preserving data analysis.
Uber implements Flex [30] that answers data SQL queries
with DP. LinkedIn builds Pinot [45], a DP platform that en-
ables analysts to gain insights about its members’ content
engagements. Within the government, the US census bureau
plans to publish the 2020 census statistics with DP [5].
Previous work on DP mostly focuses on designing tailored
algorithms for speciﬁc data analysis tasks. This paradigm is
time consuming, requires a lot of expertise knowledge, and
is error-prone. For example, many algorithms have been pro-
posed for mining frequent itemset [34, 38, 50]. Some of them
incorrectly use the Sparse Vector Technique (SVT) and results
in non-private algorithm being incorrectly proven to satisfy
DP, see, e.g., [40] for an analysis of incorrect usage of SVT.
To answer SQL queries under the constraint of DP, the SQL
engine needs to be patched [30]. For another example, to train
a differentially private deep neural network, the stochastic gra-
dient descent step is modiﬁed [3]. Moreover, this paradigm
does not scale: more tasks lead to worse privacy guarantee as
each task reveals more information about the private data.
One promising solution to address this problem is gen-
erating a synthetic dataset that is similar to the private
dataset while satisfying differential privacy. As additional
data analysis tasks performed on the published dataset are
post-processing, they can be performed without additional
privacy cost. Furthermore, existing algorithms for performing
data analysis do not need to be modiﬁed.
The most promising existing method for private genera-
tion of synthetic datasets uses probabilistic graphical models.
PrivBayes [53] uses a Bayesian network. It ﬁrst privately de-
termines the network structure, then obtains noisy marginals
for the Conditional Probability Distribution of each node.
More recently, PGM, which uses Markov Random Fields,
was proposed in [41]. In 2018, NIST hosted a Differential
Privacy Synthetic Data Challenge [43], PGM achieves the
best result. Approaches that do not use probabilistic graphical
models, such as [4, 11, 13, 27–29, 46, 49, 54], either are com-
putationally inefﬁcient or have poor empirical performance.
PrivBayes and PGM have two limitations. First, as a graph-
ical model aims to provide a compact representation of joint
probability distributions, it is sparse by design. Once a struc-
ture is ﬁxed, it imposes conditional independence assumptions
that may not exist in the dataset. Second, since each model is
sparse, the structure is data dependent and ﬁnding the right
structure is critically important for the utility. Bayesian Net-
works are typically constructed by iterative selection using
mutual information metrics. However, mutual information
has high sensitivity, and cannot be estimated accurately under
DP. PrivBayes introduces a low-sensitivity proxy for mutual
information, but it is slow (quadratic to the number of users
in the dataset) to compute. In [41], no method for automati-
cally determining the graph structure is provided. In the NIST
challenge, manually constructed graph networks are used for
PGM.
Our Contributions. In this paper, we propose PrivSyn, for
differentially private synthetic data generation. The ﬁrst novel
contribution is that, instead of using graphical models as the
summarization/representation of a dataset, we propose to use
a set of large number of low-degree marginals to repre-
USENIX Association
30th USENIX Security Symposium    929
sent a dataset. For example, in the experiments, given around
100 attributes, our method uses all one-way marginals and
around 500 two-way marginals. A two-way marginal (speci-
ﬁed by two attributes) is a frequency distribution table, show-
ing the number of records with each possible combination of
values for the two attributes. At a high level, graphical models
can be viewed as a parametric approach to data summariza-
tion, and our approach can be viewed as a non-parametric one.
The advantage of our approach is that it makes weak assump-
tions about the conditional independence among attributes,
and simply tries to capture correlation relationships that are
in the dataset.
This method is especially attractive under DP for several
reasons. First, since counting the number of records has a
low sensitivity of 1, counting queries can be answered accu-
rately. Second, since a marginal issues many counting queries
(one for each cell) with the same privacy cost of one counting
query, it is arguably the most efﬁcient way to extract informa-
tion from a dataset under DP. Third, using either advanced
composition theorem [19] or zero-Concentrated DP [14], the
variance of noises added to each marginal grows only linearly
with the number of marginals under the same privacy bud-
get. Furthermore, when one attribute is included in multiple
marginal, one can use averaging to reduce the variance. As a
result, one can afford to get a large number of marginals with
reasonable accuracy.
There are two main challenges for using a set of marginals
for private data synthesis. The ﬁrst challenge is how to select
which marginals to use. Using too many marginals (such as
all 2-way marginals) results in higher noises, and slow down
data synthesis. The second challenge is how to synthesize the
dataset given noisy marginals.
The second contribution is that we propose a new method
to automatically and privately select the marginals. We
ﬁrst propose a metric InDif (stands for Independent Dif-
ference) that measures the correlation between pairwise at-
tributes. InDif is easy to compute and has low global sensitiv-
ity. Given InDif scores, we then propose a greedy algorithm
that selects the pairs to form marginals.
The third contribution is that we develop a method that
iteratively update a synthetic dataset to make it match
the target set of marginals. When the number of attribute
is small enough so that the full contingency table can be
stored and manipulated directly, one can use methods such
as multiplicative update [8] to do this. However, with tens or
even over one hundred attributes, it is infeasible to represent
the full contingency table.
The key idea underlying our approach is to view the dataset
being synthesized as a proxy of the joint distribution to be
estimated, and directly manipulate this dataset. In particular,
given a set of noisy marginals, we start from a randomly gen-
erated dataset where each attribute matches one-way marginal
information in the set, and then gradually “massage” the syn-
thetic dataset so that its distribution is closer and closer to
each pairwise marginal. We model this problem as a network
ﬂow problem and propose Graduate Update Method (short
for GUM), a method to “massage” the dataset to be consis-
tent with all the noisy marginals. We believe that GUM can
be of independent interest outside the privacy community.
Essentially, it can be utilized more broadly as a standalone
algorithm and it allows us to generate synthetic dataset from
dense graphical models.
To summarize, the main contributions of this paper are:
the dataset.
marginals that capture sufﬁcient correlations.
• A simple yet efﬁcient method to capture correlations within
• A new method to automatically and privately select
• A data synthesis algorithm GUM that can also be used
• An extensive evaluation which demonstrates the perfor-
mance improvement of the proposed method on real-world
dataset and helps us understand the intuition of different
techniques.
standalone to handle dense graphical models.
Roadmap. In Section 2, we present background knowledge
of DP and composition theorem, and formally deﬁne the data
synthesis problem. We then introduce a general framework of
private data synthesis in Section 3. We present our proposed
marginal selection method and data synthesis method in Sec-
tion 4 and Section 5, respectively. Experimental results are
presented in Section 6. We discuss related work in Section 7
and limitations in Section 8. Finally, we provide concluding
remarks in Section 9.
2 Preliminaries
2.1 Differential Privacy
Differential privacy [22] is designed for the setting where
there is a trusted data curator, which gathers data from
individual users, processes the data in a way that satisﬁes
DP, and then publishes the results. Intuitively, the DP notion
requires that any single element in a dataset has only a limited
impact on the output.
Deﬁnition 1 ((ε,δ)-Differential Privacy). An algorithm A sat-
isﬁes (ε,δ)-differential privacy ((ε,δ)-DP), where ε > 0,δ ≥
0, if and only if for any two neighboring datasets D and D(cid:48),
we have
∀T ⊆Range(A) : Pr [A(D) ∈ T ] ≤ eε Pr(cid:2)A(D(cid:48)) ∈ T(cid:3) + δ,
where Range(A) denotes the set of all possible outputs of the
algorithm A.
In this paper we consider two datasets D and D(cid:48) to be
neighbors, denoted as D (cid:39) D(cid:48), if and only if either D = D(cid:48) +r
or D(cid:48) = D + r, where D + r denotes the dataset resulted from
adding the record r to the dataset D.
930    30th USENIX Security Symposium
USENIX Association
2.2 Gaussian Mechanism
There are several approaches for designing mechanisms that
satisfy (ε,δ)-differential privacy. In this paper, we use the
Gaussian mechanism. The approach computes a function f
on the dataset D in a differentially privately way, by adding
to f (D) a random noise. The magnitude of the noise depends
on ∆ f , the global sensitivity or the (cid:96)2 sensitivity of f . Such a
mechanism A is given below:
(cid:16)
(cid:17)
A(D) = f (D) + N
0,∆2
f σ2I
where
∆ f = max
(D,D(cid:48)):D(cid:39)D(cid:48)|| f (D)− f (D(cid:48))||2.
In the above, N (0,∆2
f σ2I) denotes a multi-dimensional ran-
dom variable sampled from the normal distribution with mean
0 and standard deviation ∆ f σ, and σ =
2ln 1.25
δ /ε.
(cid:113)
2.3 Composition via Zero Concentrated DP
For a sequential of k mechanisms A1, . . . ,Ak satisfying (εi,δi)-
DP for i = 1, . . . ,k respectively, the basic composition re-
sult [25] shows that the privacy composes linearly, i.e., the se-
quential composition satisﬁes (∑k
i δi)-DP. When εi = ε
and δi = δ, the advanced composition bound from [19] states
kδ + δ(cid:48))-DP.
that the composition satisﬁes (ε(cid:112)2k log(1/δ(cid:48)) + kε(eε − 1),
i εi,∑k
To enable more complex algorithms and data analysis task
via the composition of multiple differentially private build-
ing blocks, zero Concentrated Differential Privacy (zCDP for
short) offers elegant composition properties. The general idea
is to connect (ε,δ)-DP to Rényi divergence, and use the useful
property of Rényi divergence to achieve tighter composition
property. In another word, for ﬁxed privacy budget ε and δ,
zCDP can provide smaller standard deviation for each task
compared to other composition techniques. Formally, zCDP
is deﬁned as follows:
Deﬁnition 2 (Zero-Concentrated Differential Privacy
(zCDP) [14]). A randomized mechanism A is ρ-zero
concentrated differentially private (i.e., ρ-zCDP) if for any
two neighboring databases D and D(cid:48) and all α ∈ (1,∞),
log(cid:0)E(cid:104)
e(α−1)L(o)(cid:105)(cid:1) ≤ ρα
Dα(A(D)||A(D(cid:48)))
∆
=
1
α− 1
Where Dα(A(D)||A(D(cid:48))) is called α-Rényi divergence be-
tween the distributions of A(D) and A(D(cid:48)). Lo is the pri-
vacy loss random variable with probability density function
f (x) = log Pr[A(D)=x]
Pr[A(D(cid:48))=x] .
zCDP has a simple linear composition property [14]:
Theorem 1. Two randomized mechanisms A1 and A2 satisfy
ρ1-zCDP and ρ2-zCDP respectively, their sequential compo-
sition A = (A1,A2) satisﬁes (ρ1 + ρ2)-zCDP.
The following two theorems restate the results from [14],
which are useful for composing Gaussian mechanisms in
differential privacy.
Theorem 2.
2(cid:112)ρlog(1/δ),δ)-differentially private for any δ > 0.
If A provides ρ-zCDP, then A is (ρ +
Theorem 3. The Gaussian mechanism which answers f (D)
with noise N (0,∆2
f σ2I) satisﬁes ( 1
2σ2 )-zCDP.
Given ε and δ, we can calculate the amount of noise for
each task using Theorem 1 to Theorem 3. In particular, we
ﬁrst use Theorem 2 to compute the total ρ allowed. Then
we use Theorem 1 to allocate ρi for each task i. Finally, we
use Theorem 3 to calculate σ for each task. Compared with
(ε,δ)-DP, zCDP provides a tighter bound on the cumulative
privacy loss under composition, making it more suitable for
algorithms consist of a large number of tasks.
2.4 Problem Deﬁnition
In this paper, we consider the following problem: Given a
dataset Do, we want to generate a synthetic dataset Ds that
is statistically similar to Do. Generating synthetic dataset Ds
allows data analyst to handle arbitrary kinds of data analysis
tasks on the same set of released data, which is more general
than prior work focusing on optimizing the output for speciﬁc
tasks (e.g., [3, 36, 44, 52]).
More formally, a dataset D is composed of n records each
having d attributes. The synthetic dataset Ds is said to be
similar to Do if f (Ds) is close to f (Do) for any function f . In
this paper, we consider three statistical measures: marginal
queries, range queries, and classiﬁcation models. In particular,
a marginal query captures the joint distribution of a subset of
attributes. A range query counts the number of records whose
corresponding values are within the given ranges. Finally, we
can also use the synthetic dataset to train classiﬁcation models
and measure the classiﬁcation accuracy.
3 A Framework of Private Data Synthesis