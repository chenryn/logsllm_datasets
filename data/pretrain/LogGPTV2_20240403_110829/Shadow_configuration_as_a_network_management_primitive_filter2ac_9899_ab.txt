We support three modes of shadow bandwidth control:
• Priority: real trafﬁc has higher priority than shadow;
• Partition: each conﬁguration is allocated a portion of bandwidth;
• Packet cancellation.
Priority and partition modes can be useful, for example, when the
payload must be carried end-to-end to include the responses of end
hosts and servers or when evaluating deep-packet inspection. In the
partition mode, the network operator can specify non-work con-
serving scheduling for shadow packets to provide “scaled-down”
testing bandwidth and arrival processes.
Packet cancellation is designed to allow an operator to conduct
stress tests on the shadow conﬁguration to reveal issues under higher
load. The operator can certainly try to wait for a time period when
the real trafﬁc is low. However, there may not exist such a time
period, or the real trafﬁc load that the operator would like to dupli-
cate for testing happens only when the real trafﬁc is relatively high.
Packet cancellation has the following two objectives:
• Performance of the real trafﬁc is not severely degraded;
• Performance measurements taken from shadow packets should
be close to the measurements that would be observed if the shadow
conﬁguration were the only active conﬁguration.
Packet cancellation is presented in Section 5.
3.2 Run-time Shadow Management
Our next layer provides two main functions:
• It provides a run-time and management environment for real and
shadow conﬁgurations and routing processes (e.g., multiplexing
of control packets, CPU and bandwidth management). We dis-
cuss one implementation in Section 7, including a technique for
exchanging information with routers outside a srnet (e.g., with
BGP) that presents a single consistent view to the outside world.
• It provides a commitment capability to smoothly swap the con-
ﬁgurations, which is important for many usage scenarios. This is
especially desirable because the convergence process is a major
source of disruption: reconvergence after a conﬁguration change
can cause network outages [1] or additional conﬁguration er-
rors [30]. We present our commitment protocol in Section 6.
3.3 Conﬁguration Management Layer
This layer provides multiple utilities to take advantage of and
control the capability of shadow conﬁgurations. We have imple-
mented the following tools:
• Conﬁguration user interface (cui): the operator is presented with
two command-line terminals, one real and the other shadow. Us-
ing this interface, a network operator issues traditional router
commands such as traceroute and ping. Additional com-
mands are provided to control our commitment protocol.
• Shadow trafﬁc control (stc): the operator is allowed to specify
shadow trafﬁc (e.g., real trafﬁc to be duplicated to the shadow
conﬁguration and intensity of generated shadow trafﬁc) and col-
lect traces.
We have also investigated other useful tools:
• Shadow conﬁguration analysis using FIB (scaf): a tool to detect
routing loops and reachability issues. We give more detail on
this tool in Section 4.
• Shadow regression tester (srt): a tool to play test cases (e.g.,
reachability of important applications at important locations).
• Conﬁguration delta debugging (cdb): a tool based on the obser-
vation that by comparing the FIB and performance of the real
conﬁguration with the shadow conﬁguration, we can automate a
large fraction of conﬁguration diagnosis.
4. SHADOW ANALYSIS USING FIB
In this and the next two sections, we present the details of shadow
conﬁguration analysis using FIB, packet cancellation, and shadow
commitment. They are presented in this order as this is a common
order in many usage scenarios.
4.1 Objectives and Overview
erator can analyze { fibs
packet forwarding.
With the availability of a shadow conﬁguration, the network op-
i}i before they become installed for real
In particular, we investigate how to detect forwarding loops us-
ing the collection of FIB states. As made evident by measurement
results [24] and online detection algorithms [51], forwarding loops
happen frequently in real networks. Since routing loops can cause
unnecessary load and dropped packets, detecting loops caused by
a new conﬁguration before its actual deployment can have great
value. Our system computes the set of destination addresses as
well as routers present in the loop, providing the network operator
with detailed information from which she can debug the problem.
We also detect reachability issues, another common type of con-
ﬁguration errors [33,53]. Some reachability issues can be extremely
challenging to detect using any static analysis or simulation tools
because they depend on software implementation. For example, the
Cisco document [10] reports a common OSPF routing problem be-
fore Cisco IOS Release 12.1(3) related with forwarding addresses.
The reachability issue noted was caused by the software implemen-
tation of a Cisco-speciﬁc optimization, and thus can be difﬁcult to
isolate using only conﬁguration ﬁles. By looking directly at the FIB
states, our system can bypass detailed modeling and abstractions,
and provide the network operator useful reachability information to
help debug the problem.
Note that for presentation clarity, we consider only unicast ad-
dresses; we assume that there exists a unique nexthop in each FIB
for a single destination address. Also note that it is straightforward
to add other forwarding mechanisms (e.g., label switched paths) to
our analysis.
4.2 Representative IP Addresses
A major complexity in reachability and forwarding loop anal-
ysis is that FIB lookup in modern routers is implemented using
longest preﬁx matching, and different routers in the same network
may have different sets of destination IP preﬁxes.
To use existing efﬁcient graph algorithms to check reachability
and forwarding loops, we ﬁrst pre-process FIBs to compute repre-
sentative IP addresses. With representative IP addresses, FIB anal-
ysis is done on individual IP addresses, without the need to handle
longest preﬁx matching.
Consider a simple example where each FIB table in the network
consists of the following destination IP preﬁxes: a default route
(i.e., 0.0.0.0/0), 10.1.0.0/16, and 10.1.0.0/24. Then if we verify that
there is no reachability or routing loop problem for each IP address
in the set {0.0.0.0, 10.1.0.0, 10.1.1.0, 10.2.0.0}, then the network
has no reachability or routing loop problem.
The algorithm findrepip (Figure 3) computes the set A of repre-
sentative IP addresses for a network. The algorithm computes the
set Ai of representative addresses for each FIB fibs
i . The set A for
the whole network is obtained by merging the Ai’s. To make the
merging efﬁcient using a priority queue, the algorithm maintains
each Ai to be sorted.
When processing each entry in fibs
i , the algorithm adds to Ai up
to two addresses. The ﬁrst is the beginning address of the desti-
nation preﬁx associated with the entry, and the second is the be-
ginning address of the next range that could come after the entry’s
destination preﬁx.
4.3 Computing Reachability and Loops
Once the set of representative addresses is found, each address
can be analyzed using standard graph algorithms to detect reacha-
bility issues and forwarding loops:
1. Reachability: (1) set of routers Ra that can reach address a;
and (2) set of routers Wa with FIB entries for address a but
cannot reach address a;
2. Forwarding loops: sets of routers La participating in forward-
ing loops for address a.
i
i do
ﬁndrepip({ fibs
i}
i) – Compute representative address set A
01. foreach fibs
i do
02. Ai ← /0 //sorted rep addr for fibs
foreach entry e in fibs
03.
Ai ← Ai ∪{min{e.addr_range}}
04.
if max{e.addr_range} (cid:5)= 222.255.255.255 then
05.
Ai ← Ai ∪{1 + max{e.addr_range}}
06.
endif
07.
08. endfor
09. endfor
10. // Merge rep addr into single sorted list
11. A ← priority_queue_merge({Ai}i)
12. return A
Figure 3: Algorithm for computing representative addresses
given { fibs
i}.
5. SHADOW PACKET CANCELLATION
With a consistent and reachable forwarding state, the network
operator next might ask, “If I adopt this alternate conﬁguration on
my network, how will it perform?” Such a question is important
when deploying new services such as voice or streaming media, or
when the operator may want to evaluate the likely impacts of the
new conﬁguration on service level agreements.
At this point, the reader might suggest that since the operator
already has the FIBs of the shadow conﬁguration, she may com-
pute or simulate the performance characteristics using a trafﬁc de-
mand matrix. This is certainly a feasible approach and our system
can support it. Such computation- or simulation-based approaches,
however, implicitly rely on a model for packet processing inside
each router for features such as QoS or any particular queue man-
agement techniques. New techniques such as trafﬁc shaping or dif-
ferentiated services would require modiﬁcations to the model [12].
On the other hand, enabling direct measurements allows processing
within the routers to be treated as a black box.
5.1 Overview
Recall that the objectives of packet cancellation are that (a) both
real and shadow trafﬁc are forwarded according to their original
queue management schemes, and (b) shadow packets are (typi-
cally) only delayed by other shadow packets while real packets are
(typically) only delayed by other real packets.
This mode uses two techniques: packet (payload) cancellation
and a virtual clock. The key insight is that the payload of shadow
data packets may not always need to be transmitted; that is, when
the focus of an evaluation is on network performance metrics such
as delay, the shadow data packets then are not intended to be re-
ceived by end hosts. Thus, we need only to (1) retain the informa-
tion relevant to forwarding the trafﬁc within the network, and (2)
know the correct payload size so that gathered performance mea-
surements remain meaningful.
Given the preceding insight, we allow a router to append the
header of a shadow packet to a real packet before it is transmitted
over the link. The input interface at the receiving router removes
the appended shadow header, and processes it accordingly. If the
shadow trafﬁc is delayed too much by the real trafﬁc, we can ap-
pend multiple shadow headers to catch up with the delay.
5.2 Shadow Data Packet Cancellation
We now describe how our scheme processes shadow data pack-
ets. At the output interface, shadow packets and real packets are
separated into two queues, Qs and Qr. This also allows the shadow
conﬁguration and real conﬁguration to deﬁne different queue sizes
and queuing disciplines. When it is time to transmit the next packet,
the line card applies the algorithm shown in Figure 4.
Speciﬁcally, if Qs is empty, send head(Qr), the head of the real
packet queue; otherwise, extract the headers of the shadow pack-
ets that should be transmitted and combine them with head(Qr).
if not virtual_clock_expired(peek(Qs))
break
p ← append(p,ip_hdr(dequeue(Qs))
p ← dequeue(Qr) // Select real packet
// Append shadow packet headers
for 1 . . .MAX_CANCELLABLE do
pktsched() – packet cancellation and scheduling.
01. if not empty(Qr) then
02.
03.
04.
05.
06.
07.
08.
09.
10. elseif not empty(Qs) then
11.
12.
13.
14. endif
Figure 4: Packet cancellation and scheduling.
// Send shadow packet if available
if virtual_clock_expired(peek(Qs))
transmit(dequeue(Qs))
endfor
transmit(p)
IP1
P
ayload
IP2
IP1
Payload
IP2
Payload
IP1
IP2
Figure 5: Shadow packet header combined with a real packet
for transmission on a single link.
We may extract multiple (up to MAX_CANCELLABLE, set to 3
in our implementation) shadow packets to “piggyback” on a real
packet due to packet payload sizes and previous delay of shadow
packets. To determine whether a shadow packet should be trans-
mitted or piggybacked, the shadow queue maintains a virtual clock.
The virtual clock estimates whether the transmission of a shadow
packet should be started (virtual_clock_expired) if there were only
shadow trafﬁc.
Note that it is important that when extracting headers from a
shadow packet, we extract all IP headers to allow the scheme to
work properly when tunnels or VPNs are conﬁgured.
If any IP
header that must be interpreted is encrypted, the scheme may not
work. The TCP/UDP header, if it exists, should also be extracted
since it may be required for packet ﬁltering (e.g., in Cisco’s policy
routing, NetFlow sampling, and ﬁrewalls). In a simple IP network
without tunnels or VPNs, the extracted headers will consist of a
single IP header and a TCP/UDP header, and will typically be 40
or 28 bytes in size.
There is one additional piece in the scheme. It must be possi-
ble for the incoming interface at the receiving router to determine
whether it is receiving a single packet or combined packet. If the
link-layer payload is larger than length indicated by the IP header,
the router strips off the appended headers, verifying their IP ver-
sion, header length, and optionally the checksum.
Figure 5 shows how a shadow payload can be canceled with a
real packet for transmission over a link. The shadow header is ex-
tracted at the receiving interface and forwarded independently.
With packet cancellation, it is possible that the full size of the
transmitted frame becomes larger than the next interface’s MTU,
causing the packets to be silently dropped at the next hop. To
handle this, one could simply decrease the MTU to accommodate
the additional canceled packets. To avoid additional fragmentation,
one could instead increase the MTU, but internally process packets
(i.e., handle fragmentation) at the routers according to the original
MTU.
Further consideration is required when operating on Ethernet. To
provide intuition, the algorithm in Figure 4 might ﬁll in all “whites-
pace” left by real trafﬁc with full shadow packets, causing the link
utilization to approach 100% and causing large delay variations.
One simple way to solve the problem is to always transmit only the
shadow header and set a timer to throttle shadow queue transmis-
sion rate when the real queue is empty. In our implementation, we
found that the available timers are too inaccurate to retain the ap-
propriate packet delay variations. Thus, we adopt the heuristic that
even when the real queue is empty, only the shadow packet header
is transmitted if link utilization is above a certain threshold (we use
85%). Since a previous hop may have trimmed a shadow packet,
it may be necessary to expand the packet and zero-ﬁll the payload
when below the threshold.
5.3 Shadow Control Packet Forwarding
We previously considered only shadow data packets. Packet can-
cellation cannot be applied to shadow control packets, such as route
advertisements, SNMP messages, or ICMP packets. For safety and
because control packets can originate from many places (routing
processes, ARP, ICMP, etc.), we opt to explicitly mark a shadow
packet that can be canceled (e.g., in generated testing trafﬁc) with a
PD bit, indicating that its payload is dropable. We process shadow
control packets using a separate queue.
5.4 Overhead and Perturbation Analysis
FIB Lookup
One potential bottlebeck is FIB lookup instead of bandwidth. Since
a combined packet received in packet cancellation mode contains
multiple headers that might require separate lookups, it is crucial