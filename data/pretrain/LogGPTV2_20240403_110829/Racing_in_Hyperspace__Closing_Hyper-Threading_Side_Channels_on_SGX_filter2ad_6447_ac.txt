sub %rax, %r9
cmp $1, %r9
; continuous number?
cmova %r11, %r10
add %r10, %rcx
shl $b_count, %rbx
; bit length of $count
mov %rax, %r9
; record the last number
31
32
33
34
35
36
37
38
39
40
41 :
42
43
44
45
46
47
48
mov (%r8), %rax
49
dec %rsi
50
cmp $end0, %rsi
51
jne .L0
52
; finish 1 co-location test
53
54 :
· · · ; release lock 1
55
dec %rdx
56
cmp $0, %rdx
57
jne .sync0
58
nop
mov (%r8), %rax
mov (%r8), %rax
.
.
.
mov $colocation_count, %rdx
xor %rcx, %rcx
; co-location test counter
· · · ; release lock 0
mfence
mov $0, (sync_addr1)
mov %rdx, (sync_addr0)
cmp %rdx, (sync_addr1)
je .sync3
jmp .sync2
.sync3:
.sync2:
1 :
2
3
4
5 :
6
7
8
9
10
11
12
13
14
15 :
mov $begin1, %rsi
16
mov $1, %rbx
17
mfence
18
mov $addr_v, %r8
19
20 :
21
22 :
23
24 :
25
26
27
28
29
30
mov (%r8), %rax
.L2:
mov $0, %r10
mov $0, %r11
cmp $end0, %rax
; a data race happens?
cmovg %rbx, %r10
sub %rax, %r9
mov %rax, %r9
mov %rsi, (%r8)
; record the last number
cmp $1, %r9
; continuous number?
cmova %r11, %r10
add %r10, %rcx
shl $b_count, %rbx
; bit length of $count
31
32
33
34
35
36
37
38
39 :
40
41 :
mov (%r8), %rax
42
lfence
43
mov (%r8), %rax
44
lfence
45
mov (%r8), %rax
46
lfence
47
mov (%r8), %rax
48
lfence
49
mov (%r8), %rax
50
lfence
51
dec %rsi
52
cmp $end1, %rsi
53
jne .L2
54
; finish 1 co-location test
55
56 :
· · · ; acquire lock 1
57
dec %rdx
58
cmp $0, %rdx
59
jne .sync2
60
Fig. 2. Co-location detection code.
from each others’ sync_addr. If the values match (i.e.,
they are in the same round), T0 and T1 begin the current
round of co-location test.
3. At the beginning of each round, set the test index %rsi
to b0 + k for T0 and to b1 + k for T1. Therefore, T0 will
write b0 + k, b0 + k− 1, b0 + k− 2, ··· , b0 + 1 to the shared
variable; T1 will write b1 + k, b1 + k − 1, b1 + k − 2, ··· ,
b1 +1. [b0, b0 +k] does not overlap with [b1, b1 +k] so either
thread, when writes its %rsi to V and reads from it, knows
whether it receives the input from the other thread. After
that, initialize the address of shared variable V in %r8.
4. For T0, store the content of %rsi to V, determine whether
a data race happens, and update %rcx if so. For T1,
determine whether a data race happens, update %rcx if
so, and then store %rsi to V. A data race is counted if
and only if contiguous values written by the other thread
are read from V, which indicates that the two threads run
at the same pace.
5. Record the data race in a counter using the conditional
move (i.e., CMOV) instruction. This avoids ﬂuctuations in
the execution time due to conditional branches.
6. Execute the padding instructions to (1) make the execution
time of T0 and T1 roughly the same; (2) increase the inter-
val between the store instruction and the load instruction;
(3) create non-linear distortion in the execution time when
being manipulated (see discussions in Sec. V).
7. Decrease %rsi by 1 and check whether it hits b0 (for T0)
or b1 (for T1), which indicates the end of the current round.
If so, go to step 8. Otherwise, go to step 4.
8. Decrease %rdx by 1 and check whether it becomes 0. If
so, all rounds of tests ﬁnish; Otherwise, go to step 2.
The time for one data race test for thread T0 and T1 is
LD ST
T0
T1
LD ST
LD ST
LD ST
t
Fig. 3. The basic idea of the data race design. Monitoring the memory
operations of the two threads on V. LD: load; ST: store.
roughly the same when both threads are running on the same
physical core. As shown in Fig. 3, when the two threads are
co-located, since the interval from load to store (line 22
to 24 for T0, line 22 to 39 for T1) is much shorter than the
interval between store and load (line 24 to 52 then jump
to 21 for T0, line 39 to 54, including the serializing instruction
lfence, then jump to 21 for T1), there is a high probability
that the store operation from the other thread will fall into
the interval between the store and load. As a result, each
thread becomes much more likely to see the other’s data than
its own. In contrast, when the two threads are not co-located,
the communication time between the two physical cores is
longer than the interval between store and load: that is,
even when one thread’s store is performed in the other’s
store to load interval, the data of the store will not
be seen by the other due to the delay caused by the cache
coherence protocol. Therefore, data races will not happen.
Testing co-location via statistical hypothesis testing. To
determine whether two threads are co-located on the same
physical core, we perform the following hypothesis test.
During each round of a co-location test, k samples are
collected by each thread. We consider the k samples as k − 1
unit tests; each unit test consists of two consecutive samples:
if both samples observe data races (and the observed counter
values are also consecutive), the unit test passes; otherwise
it fails. We take the i-th (i = 1, 2, . . . , k − 1) unit test from
each round (of the n rounds), and then consider this n unit
184
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:38:29 UTC from IEEE Xplore.  Restrictions apply. 
tests as n independent Bernoulli trials. Then, we have k − 1
groups of Bernoulli trials. We will conduct k − 1 hypothesis
tests for each of the two threads as follows, and consider the
co-location test as passed if any of the k − 1 hypothesis tests
accepts its null hypothesis:
We denote the j-th unit test as a binary random variable Xj,
where j = 1, 2, . . . , n; Xj = 1 indicates the unit test passes,
and Xj = 0 otherwise. We assume when the two threads
are co-located, the probability of each unit test passing is p.
Therefore, when they are co-located, P (Xj = 1) = p. We
denote the actual ratio of passed unit tests in the n tests as ˆp.
The null and alternative hypotheses are as follows:
H0: ˆp ≥ p; the two threads are co-located.
H1: ˆp < p; the two threads are not co-located.
Because Xj is a test during round j and threads T0 and
T1 are synchronized before each round, we can consider
X1, X2,··· , Xn independent random variables. Therefore, the
j=1 Xj, follows a
sum of n random variables, i.e., X =
Binomial distribution with parameters n and p. The mean of
the Binomial distribution is E(X) = np and the variance is
D(X) = np(1−p). When n is large, the distribution of X can
be approximated by a normal distribution N (np, np(1 − p)).
Let the signiﬁcance level be α. Then
(cid:2)n
(cid:5)
(cid:3)
P r
= α.
< −uα
(cid:4)
X − np
np(1 − p)
(cid:4)
np(1 − p).
X < np − uα
We will reject H0 and decide that the two threads are not
co-located, if
In our prototype implementation, we parameterized n, p,
and α. For example, when n = 256 and α = 0.01, uα = 2.33.
From the measurement results given in Table V (Sec. V), the
probabilities for T0 and T1 to see data races with co-location
are p0 = 0.969 and p1 = 0.968, respectively. So we have for
both T0 and T1
P r [X < 242] = 0.01.
In other words, in the hypothesis test, we reject the null
hypothesis if less than 242 unit tests (out of the 256 tests)
pass in T0 (or T1).
Here the probability of a type I error (i.e., falsely rejecting
the null hypothesis) is about 1%. The probability of a type
II error is the probability of falsely accepting H0 when
the alternative hypothesis H1 is true. For example, when
X follows a normal distribution of N (np, np(1 − p)) and
p = 0.80, the probability of a type II error in T0 and T1
will be (let Z = X−np
np(1−p)
√
∼ N (0, 1)):
(cid:3)(cid:3)(cid:3) X ∼ N (np, np(1 − p))
(cid:4)
(cid:3)(cid:3)(cid:3) Z ∼ N (0, 1)
(cid:7)
< 0.01%.
(cid:2)
(cid:5)
X ≥ 242
(cid:6)
Z ≥
P r
= P r
242 − 256 · 0.80
256 · 0.80 · (1 − 0.80)
Practical considerations. The above calculation only provides
us with theoretic estimates of the type I and type II errors
185
I0
load
I1
load
T0
T1
I0
store
I1
store
Fig. 4. The model of thread T0 and thread T1. •: load; (cid:2): store.
of the hypothesis tests. In practice, because system events
cannot be truly random and independent, approximation has to
be made. Particularly, the two threads are only synchronized
between rounds, and the k samples in each round are collected
without re-synchronization. Therefore, although samples in
different rounds can be considered independent, the k samples
within the same round may be dependent. Second, within
each round, a truly random variable X requires T0 and T1
to start to monitor data races uniformly at random, which is
difﬁcult to achieve in such ﬁne-grained data race measure-
ments. We approximate the true randomness using the pseudo-
randomness introduced in the micro-architecture events (e.g.,
data updates in the L1 cache reﬂected in memory reads) during
the synchronization. To account for the dependence between
unit tests in the same round and the lack of true randomness
of each unit test, we select the i-th unit test from each round
to form the i-th n-sample hypothesis test, and consider the
co-location test as passed if any of the k − 1 hypothesis tests
accepts its null hypothesis. We will empirically evaluate how
this design choice impacts the type I errors and type II errors
in Sec. V-C.
V. SECURITY ANALYSIS OF CO-LOCATION TESTS
In this section, we provide an analysis on the security of the
co-location tests. To do so, we ﬁrst establish the relationship
between the execution time of the communicating threads and
the data race probability. We next empirically estimate the
execution time of the threads under a variety of execution
conditions that the adversary may create (e.g., Priming caches,
disabling caching, adjusting CPU frequencies, etc.) and then
apply the measurement results to analytically proof that, under
all attacker-created conditions we have considered, the data
race probability cannot reach the same level as that when the
two threads are co-located. Finally, we empirically performed
attacks against our proposed scheme and demonstrated that
none of the attacks could pass the co-location tests.
A. Security Model
To establish the relationship between the execution time of
the communicating threads and the probability of data races,
we ﬁrst construct execution models of thread T0 and thread T1
(see their code snippets in Fig. 2). Particularly, we abstract the
execution of T0 and T1 as sequences of alternating load and
store operations on the shared variable V. After each load or
store operation, some delays are introduced by the padding
w, where w ∈ {store, load} and
instructions. We use I i
i ∈ {0, 1} to denote a code segment between two instructions
for thread Ti: when w is load, the segment is from load
to store (line 22 to 24 for T0, line 22 to 39 for T1; see
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:38:29 UTC from IEEE Xplore.  Restrictions apply. 
Fig. 2); when w is store,
the segment begins with the
store instruction and ends with the ﬁrst load encountered