USENIX Association
100102101Number of machines(log scaled)0.20.30.40.50.60.70.80.91.0Ratio of malwareNumber of machines needed to capture all tokensFile nameFile PathCMDresults can be found in Figures 7b and 7c.
Our results suggest that an analyst should analyze
the malware in 3 random virtual machines to cap-
ture most of the ﬁle names, 4 for CMD line and 7
for ﬁle path. A possible way to generate such ran-
dom machines, instead using the same machines
for all malware, may be to use a random vm gen-
erator like SecGen [45] with the features proposed
by Miramirkhani et al. [35].
5.2 How Soon Should We Re-Execute?
We now investigate the re-execution interval needed to
achieve the best coverage in the wild. This is more difﬁ-
cult to measure, as it represents a trade-off. If you re-execute
the sample too early, you may learn little and your signature
may not catch the behavior that the malware will exhibit in
the future. But if you re-execute the sample too far in the
future, than your initial model might get outdated before you
re-analyze the sample.
For this analysis, we take a ﬁrst execution trace during the
ﬁrst week of appearance of the malware. Then we collect a
second trace on the same machine, varying the time between
one and four weeks in the future. We then use the tokens
extracted from the ﬁrst execution to match all malware ex-
ecutions until we re-execute the sample. From that time on,
we incorporate the information of the second execution and
update the signature to be used for future executions.
Figure 8 shows the results for the ﬁlename tokens. While
the median detection does not change much, re-executing after
three weeks provide more beneﬁts (the minimum detection
and the 25 percentile are much higher, which suggests that
for some malware this makes a big difference).
For the ﬁle path the difference in the re-execution interval
is smaller, which means that we need more machines to get
better detection. However, even in this case we still notice
a slightly smaller range when re-executing on the 4th week,
which means some malware show a different behavior around
that time. The results are the same for command line argu-
ments, where in week 4 we have a more impactful increase
in detection, suggesting that malware will be spawning new
processes or using different parameters one month from their
ﬁrst appearance.
An analyst should re-execute a sample between 3–4
weeks apart. However, having multiple executions
in different days provides less useful information
about the malware behavior than having different
executions on different machines.
5.3 Hunting for the Most Invariant Artifacts
As we showed in previous sections the number of ﬁle cre-
ations is not a good metric to proﬁle a malware sample due
to variability. Similarly, the same ﬁle name doesn’t appear in
Figure 6: CDF of number of machines and the amount of
malware values. After 4-5 machines we start to get
diminishing returns in the number of new malware ﬁle path
tokens discovered.
impact of the ﬁrst 8 machines in the amount of tokens we
are extracting. We observe that after 7 machines the return of
investment becomes small, as for the top 50% of the malware
samples we already extracted 68% of the tokens. When also
check the other parameters and we noticed similar correlation
between the amount of tokens extracted and the detection rate
in Figure 7, which makes sense since having all the malware
tokens means we have 100% detection.
While counting the new tokens can give an idea of how
many traces we need to compensate for the diversity of be-
haviors, it does not tell us whether those tokens are sufﬁcient
or not to detect malware in the wild. Therefore, we conducted
a second experiment. Here we use the tokens extracted from
one execution to match the malware traces collected in other
machines. If the combination of the tokens can cover all the
other executions of the same sample, then we conclude that
one execution is sufﬁcient (in theory) to extract a perfect sig-
nature. If instead the extracted tokens cannot achieve 100%
coverage, we add a second trace collected on a different (ran-
domly chosen) machine in the same week (as for the moment
we want to study the machine impacts and not the time impact)
and we re-iterate the process. Since the result is dependent on
the select machines, we repeat the experiments ten times and
report the average.
From the boxplot in Figure 7a we can see that while for
some malware one execution might be enough, in average
the ﬁlenames extracted from one trace cover 82% of the ex-
ecutions and the value decreases to 77% if we use path in-
formation. However, the execution traces collected on three
different machines are sufﬁcient to achieve the highest cov-
erage when using ﬁle name as the parameter. Similarly we
ﬁnd that it takes four machines to saturate the coverage for
the command line and seven for the ﬁle path. The respective
USENIX Association
30th USENIX Security Symposium    3497
1 8 2  3   4   5  6    7 Number of sandbox machines per malware sample0.0Amount of malware tokenAmount of malicious file path tokens extracted per machines1.00.80.60.40.2(a)
(b)
(c)
Figure 7: Detection coverage of tokens obtained by combining multiple execution traces The detection rate/coverage of ﬁle
names or extensions reaches the maximum after 3 to 4 machines while for ﬁle path we need about 7 machines to capture all the
malware tokens.
ﬁle name using the dot(.) delimiter and remove the known
benign extensions to obtain highly performing malware ﬁle
extension signatures. Random tokens happen more often in
ﬁle names than any other parameter, which means that an an-
alyst should have more than 1 execution to remove the tokens
that appear only once.
We noticed that malware tends to write to non-random and
non-benign paths. However, there is no clear trend to which
subdirectories and on which level are invariant to the malware,
therefore, an analyst will need multiple values to construct a
signature based on the ﬁle path. While we couldn’t identify
a heuristic to pick the better path tokens we noticed that on
average, for all malware, 25% of non-benign subdirectory
names (tokens) appear in all the machines. This means that
an analyst will achieve a better detection using a subdirectory
name to detect malicious ﬁle write than the ﬁle name, exten-
sion or even command line of process creation. Our study
reveals a source for constructing high-performance detection
rules using ﬁle extension tokens, which future generations of
malware may no longer posess. We also reveal the success of
ﬁle path tokens in constructing a malware detection signature.
6 Discussion and Limitations
Impact on State-of-the-Art Solutions. In our paper, we per-
formed an extensive analysis about behavioral variability on
malware, concluding that to observe the complete behavior
of malware it is necessary to run the malware on several
machines repeatedly over time. We conduct two further exper-
iments to illustrate the impact of our results on state-of-the-art
solutions.
First we reproduce the experiments conducted in one of
the most cited behavioral malware clustering techniques [5].
Such clustering techniques commonly rely on only one exe-
cution trace per sample. Note that our goal here is not to call
into question the results of the prior work, but to demonstrate
Figure 8: Total ﬁlename signature coverage for
re-execution intervals. A periodic execution of every 3
weeks yields the highest coverage across all malware.
all machines. Using more than 1 ﬁle name to proﬁle malware
seems like the right choice. While using both variant and
invariant features is not going to affect the performance of
the detector, we need intuition to be sure we have an invari-
ant in our signature. In this section, we measure the covered
machines that individual tokens can detect the malware on.
For this we extract the malware tokens in the ﬁrst week and
compare their performance to executions happening in the
following weeks, to simulate the scenario where an analyst
creates a signature with 1 token and deploys it. We show the
average effectiveness of each token. We don’t remove the
random tokens to show the amount of randomness that an
analyst has to deal with for each parameter.
We measure the ﬁle name token coverage for ﬁle writes.
The results show that most of the tokens are random and hav-
ing more than 1 machine allows the analyst to remove them.
We noticed that the tokens with the highest coverage were the
extensions, therefore we encourage the analysts to split the
3498    30th USENIX Security Symposium
USENIX Association
152                         3                         4Number of sandbox machines per malware sample0.00.20.40.60.81.0Detection rate in the wildCoverage of the extracted filename signatures0.00.20.40.60.81.0Detection rate in the wildCoverage of the extracted file path signatures123 4 5 6Number of sandbox machines per malware sample78152                         3                         4Number of sandbox machines per malware sample0.00.20.40.60.81.0Detection rate in the wildCoverage of the extracted Command line           signatures152                         3                         4Time difference from first sandbox execution0.60.70.80.91.0Combined detection rate in the wildCoverage of the filename signatures from 2 executionsthe effects of variability in a typical malware-clustering ex-
periment. When evaluating this technique on our data, which
consists of several executions of the same malware samples,
we observe that one third of the samples exhibit sufﬁcient
variability in behavior that their traces were scattered among
multiple clusters, thus decreasing the accuracy of mapping
samples to the correct family. This suggests that we must be
cautious when drawing conclusions from clustering exper-
iments, as the results may be inaccurate if the experiment
utilizes a single trace per sample. The details of this experi-
ment can be found in Appendix A.1.
In a second experiment, we assess the impact of behavioral
variability on the accuracy of anomaly-detection approaches.
In this case, we selected AccessMiner [29], a popular solution
for building models based on benign execution alone. It is
interesting to note that although variability was not explicitly
discussed by the authors, Accessminer correctly accounted
for it by including multiple execution of benign software
collected from different real-world machine.
Again, we repeated the experiments by following the tech-
nique explained in the paper (the details can be found in
Appendix A.2), training the AccessMiner model with a pro-
gressively increasing number of traces from benign ﬁles in
our dataset. Our results suggest that behavioral variability of
benign programs also impact the detection rate and that only
few executions are insufﬁcient to build and accurate model.
Moreover, our experiment shows that to improve the accuracy
of the models and reduce false alarms, it is necessary to also
include lower-reputation and low-prevalence benign ﬁles to
the dataset. In the original AccessMiner paper, only traces
from popular benign ﬁles behavior were incorporated into the
anomaly detector.
Alternative Solutions to Account for Behavioral Variabil-
ity. Our ﬁndings suggest that the more accurate way to collect
information about malware behavior is to record program
executions on real end-user machines. However, the main
drawback of this solution is that known malware needs to
be blocked to guarantee the user security, and thus the data
collection is limited to ﬁles that other methods cannot classify
one way or another.
Other options exist for researchers to account for the behav-
ioral variability of malware. For instance, Multipath Explo-
ration, proposed by Moser et al. [36], allows to automatically
explore multiple execution paths of the malware binary in the
same system. As this method is capable of triggering hidden
functionalities, it can replace the need to observe the behav-
ior over different machines and at different points in time.
However, this solution is complex and has a very high per-
formance overhead, which makes it unsuitable for large-scale
experiments.
Similarly, Symbolic execution could be used to trigger unob-
served behaviors during malware analysis, such as in the case
of time-triggered malware [15]. While this can also help an
analyst to tackle the issue of behavior variability, similarly to
the multipath exploration solution, symbolic execution is difﬁ-
cult to scale due to the large overhead and the state explosion
problems [53].
A more practical solution consists in running the samples
on different VMs, with different conﬁgurations. While still re-
source intensive, this method has comparably lower overhead
than the previous approaches, making it is easier to apply to
a large number of samples. As we showed in section 5, we
suggest running the malware in at least three (and for better
coverage even seven) different VMs to capture signiﬁcant
machine-induced variability. We also suggest the analyst to
re-execute the samples at least every three weeks to capture
any time-induced variability.
Threats to validity and limitations. Our study carries some
limitations due to the nature of the data that was provided
by the security vendor. The data was collected from users
who have installed the AV product, who might be in general
more careful with the security of their computers and, there-
fore, might be less exposed to attacks. Although we cannot
rule out the possibility of selection bias, the large size of the
population in our study, the large fraction of malware (9.15%
of the unknown samples that could not be classiﬁed with
other means), and the large spectrum of variability that we
observed in the experiments, suggest that our results have a
broad applicability.
Our data consists of executions of Windows PE ﬁles and
therefore, our ﬁndings might not apply to the behavior of pro-
grams that run on other platforms (Linux [14], Android [55],
IoT, etc.). Another unfortunate limitation is that the data does
not contain network events. Previous work [43], however, has
already shown the existence of a high variability in the net-
work events and discussed its impact on the overall behavior
of malware. Since our goal is not to establish a root cause for
the behavior variability, the lack of network data does not im-
pact our main ﬁndings. We expect to actually observe higher
variability on network events.
All samples in our dataset were not ﬂagged neither as be-
nign nor malicious at the time of their collection. Therefore,
the data does not include popular benign programs and mal-
ware that can be detected by traditional means (i.e., AV En-
gines). While this might be seen as a limitation because easier
to label programs might not show similar variability on their
behavior, the set of samples we analyzed also make our study
more unique in its nature. We only analyze those programs
that need to be detected by looking at the behavior. In reality,
samples that can be identiﬁed simply by other means, such
as static signatures, do not require a behavioral analysis in
the ﬁrst place. Even if our measurement does not capture the
variability of those samples, the impact on behavioral detec-
tion would have been irrelevant. Moreover, since our goal
is to study variations in the runtime behavior, the analysis
can only be performed if a sample is executed multiple times,
USENIX Association
30th USENIX Security Symposium    3499
both in the same environment and across a different set of
machines. Therefore, polymorphic samples (in which each
SHA-256 hash is only observed once) cannot be included in
our analysis.
A recent work [46] has shown that for the vast majority
of malware samples its impossible to identify a family name,
owing to the use of generic signatures and to inconsistencies
among the AV labels. Our clustering experiment provides
further insight into this challenge. As we were unable to ﬁnd
a family name for most of the samples in our dataset, we did
not study the behavior variability across malware families.
When measuring the time variability, some actions may not
re-occur. For example, the malware might not recreate ﬁles
already created in the previous runs, resulting in a signiﬁcant
number of missing events in following runs. However, our
results show that during the re-executions of the same sample
we often observe new events, thus conﬁrming the existence
of variability over time.
Finally, our study might have missed malware that can
compromise the kernel of the operating system to evade the
AV data collection component. This is common to all studies
performed on AV telemetry, and since we do not have control
over the execution environment we cannot verify the extent
of this problem.
7 Related Work
Many prior works explore malware behavior and evolution
over time [4, 8, 28] as well as their effects on the accuracy of
malware detectors [19, 38]. Our work is also inspired by prior
work that establish differences in malware behavior across
different sandbox [6, 20, 22] or on behavior that remains dor-
mant [9, 13, 25, 47]. Prudent practices have been proposed
when dealing with behavioral data, such as reporting on the
exact OS version used for the analysis, which is assumed to
affect the observed malicious behavior [43]. Some effort has
been made by Lindorfer et al. to detect the existence of one
of the factors that affect the behavior of malware: the environ-
mental bias [31]. Our work does not aim at detecting malware
that show such biases, but instead focus on measuring which
parts of the behavior are more prone to environment sensitiv-
ity and to which extent. We also differ from this paper, since
we are not trying to establish a causal relationship for our
results. Pendlebury et al. show that time is another factor af-
fecting the behavior of malware, which they observe through
the deteriorating performance of a behavioral classiﬁer [38].
We also measure the effect of time, but look at changes in the
behavior instead of at the precision of a classiﬁer.
Finally, while a large body of research has been dedicated
to the construction of complex detection models (such as ML
classiﬁers [5, 11, 24, 54]), in but our work we focus on sim-
ple token-based rules like those used by SIEM systems [44]
and other rule-based detection models [10, 51], because these
tokens are the building blocks for more elaborate signatures.
8 Conclusions
It has been known, for over a decade, that malware samples
can change their behavior on different hosts and at different
points in time, but no study has yet measured this variability
in the real world. In this paper, we report the ﬁrst analysis of
malware, PUP and benign-sample behavior in the wild, using
execution traces collected from 5.4M real hosts from around
the world. We show that malware exhibits more variability
than benign samples, In particular, we ﬁnd that, for at least
50% of the malware, 30% of the actions observed in an execu-
tion will not appear in other machines. While there is a lower
variability in benign actions, the parameters of these actions
are often different. In fact most of the parameters (except
for ﬁle extension) for all the 3 classes of programs have few
values in common across machines. We further show that, for
malware that can still execute 2 or more weeks from their
ﬁrst appearance, the variability is lower and so is their detec-
tion rate. We then assess the prevalence of invariant parameter
tokens that are commonly used to derive behavior based signa-
tures for malware. Even though action parameters that appear
in every machine execution are uncommon in malware—50%
of the malware samples have only 8% of parameters in com-
mon across all executions—we show that we can use 3 to 7
machines to collect parameter tokens that appear in more than
90% of the executions. Our results also suggest that analysts
should re-execute the malware samples 3 weeks after ﬁrst
receiving them to update their behavior models. The ﬁndings
have important implications for malware analysts and sand-
box operators, and they emphasize the unique insights that
we can gain by monitoring malware behavior at scale, on real
hosts.
Acknowledgements
We thank Sandeep Bhatkar and Omer Yampel for helping
us understand the behavior data, the anonymous reviewers
and SangHyun Hong for their constructive feedback. This
research was partially supported by A. James & Alice B.
Clark Foundation, the US Department of Defense, and by the
European Research Council (ERC) under the Horizon 2020
research and innovation program (grant agreement No 771844