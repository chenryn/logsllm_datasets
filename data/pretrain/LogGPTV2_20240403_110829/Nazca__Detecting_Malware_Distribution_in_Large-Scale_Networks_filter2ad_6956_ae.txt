looking for abuse, and shut them down quickly once these
abuses are discovered.
C. How Can a Cyber-criminal Evade Nazca?
There are several evasions a cyber-criminal might attempt
to escape Nazca detection. One is using an encrypted protocol.
We already discussed the advantages and drawback of HTTPS.
Using a custom encryption protocol is possible, but such a
channel might not be allowed through corporate ﬁrewalls.
Therefore it is inconvenient for the cyber-criminals as it limits
the basin of potential victims. A smarter solution would be
piggybacking on popular software channels, such as Skype.
This would defeat a system like Nazca, but it has a limited
victim pool. Moreover, it is in the interest of the service
provider to detect and prevent misuse of their service, as giving
a free pass to malicious activities hurts their customers and
ultimately their business.
Another way to reduce the chance to be detected by Nazca
is to keep very small, independent malicious infrastructures.
In this case, while our detection step would be ineffective, a
technique like the Dedicated Malware Hosts Detection should
identify these structures.
13
The best evasion technique that we envision is to keep
on creating new, independent malware infrastructures, quickly
rotating through them. Nazca needs to process several con-
nections to the malware infrastructure before being able to
identify it (although this number is fairly small; we have
detected infrastructures with ﬁve connections). If the cyber-
criminal has moved on to a completely different infrastructure
by the time that Nazca can detect
it, he will avoid the
negative consequences of detection (e.g., blocking connections
to his domains). However, the two infrastructures have to be
completely independent; i.e., different domains, hosts, URL
structures and ﬁles. Moreover, the clients that the new infras-
tructure contacts have to be new. Otherwise, after a couple
of iterations of this infrastructure hopping, the infected clients
would become very noticeable in our graph, and Nazca would
ﬂag connections to previously-unseen domains from these
clients. This is quite challenging for the cyber-criminal, and
it increases his operational cost, while decreasing the average
timespan and number of infections.
Another evasion technique is to skip being processed
by Nazca altogether, by distributing malware disguised as a
multimedia ﬁle. We have seen simple cases of this kind of
cloaking, where malware was distributed with a GIF image
header (Nazca, running without whitelisting, detected this
attack as they were mutating the images). More advanced cases
might also use steganography to improve stealthiness. If the
popularity of these attacks increases, Nazca will need to drop
its preﬁlter on images and accept a performance loss and a
probable increase in false detections. Ultimately, steganalysis
detectors might become a necessity to combat this trend.
D. What is the Minimum Scale of the Network on Which Nazca
Can Operate?
There are two factors in play here: the timespan of obser-
vation and the number of clients in the trafﬁc. Before being
operational, Nazca must observe enough trafﬁc to learn and
tune the various thresholds. The more data is collected, the
more precise Nazca is. In the training dataset, with 8,813
clients, Nazca was performing detections after observing less
than six hours of trafﬁc. In smaller networks, this learning
period will be longer, inversely proportional to the number of
users.
In addition to the need for this initial
learning phase,
to achieve successful detections Nazca must observe a few
interactions with the malware distribution networks. Hence,
the number of users in the trafﬁc must be large enough to
have a sufﬁcient view over these distribution infrastructures.
In our datasets, 7.17% of the clients have come into contact
with distribution infrastructures. To give a reference point, we
identiﬁed several distribution infrastructures using the trafﬁc
of 50 infected clients in our dataset, which have been chosen
randomly. Considering the fraction of infected clients in our
dataset, Nazca could operate with 700 clients. With less than
that, Nazca’s performance gradually degrades.
Due to the sensitive nature of ISP trafﬁc data, it was not
possible for us to obtain a similar dataset from other ISPs. We
are currently developing a self-contained version of Nazca,
that ISPs can deploy, so that we can have a validation of our
system in diverse conditions.
E. What is Nazca Space/Time Performance?
In our experiments, we have run the Candidate Selection
in real time with trafﬁc collection, on a four-cores server with
12 GB of memory. This stage is the critical one in terms
of performance, as it reduces 20-fold the number of entities
(URLs/domains/hosts) to be processed by the Detection stage.
Thanks to this reduction, in the Detection stage, we generate
only 40/58 non-trivial graphs (i.e., graphs with more than 10
nodes) in our 2/7-days dataset. We build graphs incrementally
every six hours. A graph can take up to ten minutes to build
from scratch (this time includes all incremental updates). The
cumulative build time of trivial graphs is under ﬁve minutes.
For every connection, Nazca keeps the source and des-
tination IP addresses and TCP port,
the HTTP
User-Agent, and an MD5 hash of the payload and its
mime type. To keep our database size in check, we perform a
few optimizations, such as deduplicating strings and keeping
pointers to them. To give an idea of the space requirements of
Nazca, the training dataset data, containing up to 10 kilobytes
of every connection, requires 470 GB of storage. Nazca’s
database representation of it takes 4.92 GB. Considering the
number of clients, this accounts for 286 KB of data per client
per day. Nazca does not need to keep more than a few days of
data, as it can operate with a sliding time window of collected
data. These space requirements can be further lowered using
a system such as Time Machine [4].
the URL,
F. How Can Nazca be Used?
Nazca produces as output a set of web downloads (a ﬁle
and the URL it was downloaded from). This information can be
used to augment blacklists and prevent additional clients from
contacting the infection/C&C hosts. The network administrator
will also be aware of all the clients that might have contracted
the infection, and can initiate the appropriate cleanup actions.
G. Can Nazca Beneﬁt from Third-party Blacklists?
The blacklist records could be added to the candidates
selected in the Candidate Selection Step, so that we have a
richer set of candidates from which to generate the malicious
neighborhood graphs, giving us more insight on the malicious
activities they represent.
VIII. RELATED WORK
Malware detection To identify malicious web pages, re-
searchers have essentially adopted three strategies: (i) visiting
them with honeyclients, (ii) statically/dynamically analyzing
their content, and (iii) studying the set of malware distribution
paths leading to their exploitation backends.
With honeyclients, such as CAPTURE-HPC [15] and
PHONEYC [16], researchers have visited these web pages with
vulnerable browsers in virtual machines, looking for signs of
infection in the guest system. This approach has very low false
positives, but does not scale as each page has to be tested with
an exploding variety of browser conﬁgurations [17]. Moreover,
this approach is vulnerable to ﬁngerprinting and evasions [1],
yielding a high number of false negatives.
A more efﬁcient solution is to perform some form of
content analysis of the page, recognizing patterns known
14
to be malicious [18], [19], or perform static [20] or dy-
namic [21] analysis of the JavaScript code. All these solutions
are getting diminishing returns, as cyber-criminals thicken their
code obfuscation and perfect their ability to ﬁngerprint the
analysis platforms. Researchers hence are now considering
these evolving evasions against their systems as a sign of
maliciousness [22].
Malware distribution infrastructures To overcome the short-
comings of the previous solutions, researchers have been
invested in studying [23] and detecting malicious paths as a
whole, from the initial landing pages to the infection page.
Previous works have studied the infrastructures and economies
of malvertising [24], Search-Engine Optimization [25], and
spam [26]. Infections paths targeting surﬁng crowds have been
passively detected analyzing the redirection chains in network
trafﬁc [11], or actively through honeyclients [27], [10]. Other
researchers have proposed reputation-based systems to detect
malicious downloads, such as in POLONIUM [28], where
belief propagation in a tera-scale graph is used to compute
the reputation of billions of downloaded executables from
an initial seed of known benign and malicious ﬁles, and in
CAMP [29], where the same objective is achieved inside the
browser with minimal network requests. Nazca differs from
all these approaches because it generates graphs containing all
the heterogeneous entities involved in the malware distribution
network instead of focusing on a particular class (e.g., ﬁles in
CAMP and POLONIUM), thus giving a more complete view of
the attackers’ systems and the lifecycle of the infected hosts.
For example, none of these systems could detect the totality
of the complex and heterogeneous infection network shown in
Figure 3.
Once an entry point to these malicious network infrastruc-
tures has been found, it can be used to further explore these
networks, discovering their structure and interconnections, and
thus detecting more malware sources. Researchers have done
so by crawling in WEBCOP [30] and by exploiting the search
engines’ indexes to reach further into these networks to obtain
a more complete view in EVILSEED [8].
A recent in-depth study of dedicated malicious infrastruc-
tures by Zhou [9] explores the malicious neighborhoods of
an initial set of dedicated malware-spreading hosts through
crawling. It uses graph mining to classify Hostname-IP clusters
as topologically-dedicated hosts. Like Polonium and Nazca,
it is based on the observation that there is a higher density
of interconnections among malicious infrastructures than with
the rest of the web. Nazca, in contrast to Zhou’s crawlers,
passively inspects users’ activity and hence cyber-criminals’
countermeasures such as cloaking, domains takedowns and
parking (when run on the live trafﬁc) are not effective against
it. Moreover, Nazca does not need an initial seed of malicious
hosts to expand from. We speculate that Zhou’s work, being
actively crawling, can gain a more comprehensive view of
those infections that Nazca only sees sporadically. Finally,
Nazca can monitor and correlate the whole infection process,
including long-running infections on live clients, which gives
Nazca an insight also on the Command & Control servers
that the malware is in contact with. Given the pros and cons,
we speculate that a collaboration between the two systems
would give the best insight in malware distribution networks,
with Nazca providing the malicious seed to bootstrap Zhou’s
expansion process.
IX. CONCLUSION
We analyzed how successful drive-by download exploits
download and install malware programs. In particular, we
developed Nazca, a system that monitors network trafﬁc and
distinguishes between downloads of legitimate and malicious
programs. To make this distinction, the system observes trafﬁc
from many clients in a large-scale network. We use a number
techniques to identify a set of suspicious downloads. More
precisely, we look at instances where downloads exhibit be-
haviors that are typically associated with malicious activity
that attempts to avoid traditional defenses. We then aggregate
suspicious connections into a malicious neighborhood graph.
This graph puts activity into context and allows us to focus
on malicious entities that appear related (and hence, close to-
gether). This approach removes false positives and also paints
a better picture of ongoing malware distribution campaigns.
We evaluated our system on nine days of ISP trafﬁc, during
which Nazca detected almost ten million ﬁle downloads.
ACKNOWLEDGMENTS
This work was supported in part by the Ofﬁce of Naval
Research (ONR) under grant N000140911042, the National
Science Foundation (NSF) under grants CNS-0905537 and
CNS-0845559, and Secure Business Austria.
REFERENCES
[1] A. Kapravelos, M. Cova, C. Kruegel, and G. Vigna, “Escape from mon-
key island: Evading high-interaction honeyclients,” in IEEE Conference
on Detection of Intrusions and Malware, and Vulnerability Assessment
(DIMVA), 2011, pp. 124–143.
iMPERVA, “Assessing the effectiveness of antivirus solutions,” Tech.
Rep.
[2]
[3] A. Gostev, “The darker side of online virus scanners,” http://www.
securelist.com/en/weblog?weblogid=208187473.
[4] S. Kornexl, V. Paxson, H. Dreger, A. Feldmann, and R. Sommer,
“Building a time machine for efﬁcient recording and retrieval of high-
volume network trafﬁc,” in ACM Internet Measurement Conference
(IMC), 2005.
[6]
[5] Microsoft, “Pre-installed malware in production lines spurs mi-
crosoft’s 3322.org takedown,” http://www.infosecurity-magazine.com/
view/28215/.
J. Caballero, C. Grier, C. Kreibich, and V. Paxson, “Measuring pay-
per-install: The commoditization of malware distribution.” in USENIX
Security Symposium, 2011.
I. S. S. Lab, “Anubis: Analyzing unknown binaries,” http://anubis.
iseclab.org/.
[7]
[8] L. Invernizzi, P. M. Comparetti, S. Benvenuti, C. Kruegel, M. Cova,
and G. Vigna, “Evilseed: A guided approach to ﬁnding malicious web
pages,” in IEEE Symposium on Security and Privacy, 2012.
[9] Z. Li, S. Alrwais, Y. Xie, F. Yu, M. S. Valley, and X. Wang, “Finding
the linchpins of the dark web: a study on topologically dedicated hosts
on malicious web infrastructures,” in IEEE Symposium on Security and
Privacy, 2013.
[10] S. Lee and J. Kim, “Warningbird: Detecting suspicious urls in twitter
stream,” in IEEE Symposium on Network and Distributed System
Security (NDSS), 2012.
[11] G. Stringhini, C. Kruegel, and G. Vigna, “Shady paths: Leveraging
surﬁng crowds to detect malicious web pages,” in ACM Conference on
Computer and Communications Security (CCS), 2013.
[12] C. Seifert and R. Steenson, “Capture-honeypot client (capture-hpc),”
https://projects.honeynet.org/capture-hpc.
15
[22] A. Kapravelos, Y. Shoshitaishvili, M. Cova, C. Kruegel, and G. Vigna,
“Revolver: An automated approach to the detection of evasive web-
based malware,” in USENIX Security Symposium, 2013.
[23] C. Grier, L. Ballard, J. Caballero, N. Chachra, C. J. Dietrich,
K. Levchenko, P. Mavrommatis, D. McCoy, A. Nappa, A. Pitsillidis
et al., “Manufacturing compromise:
the emergence of exploit-as-a-
service,” in Proceedings of the 2012 ACM conference on Computer
and communications security. ACM, 2012, pp. 821–832.
[24] M. H. Moore, Know your enemy. Cambridge University Press, 2010.
[25] L. Lu, R. Perdisci, and W. Lee, “Surf: detecting and measuring search
poisoning,” in ACM conference on Computer and Communications
Security (CCS), 2011, pp. 467–476.
[26] D. S. Anderson, C. Fleizach, S. Savage, and G. M. Voelker, “Spam-
scatter: Characterizing internet scam hosting infrastructure,” in USENIX
Security Symposium, 2007.
J. Zhang, C. Seifert, J. W. Stokes, and W. Lee, “ARROW: Generating
signatures to detect drive-by downloads,” in International World Wide
Web Conference (WWW), 2011.
[27]
[28] D. H. Chau, C. Nachenberg, J. Wilhelm, A. Wright, and C. Faloutsos,
“Polonium: Tera-scale graph mining and inference for malware detec-
tion,” in SIAM International Conference on Data Mining (SDM), 2011.
[29] M. A. Rajab, L. Ballard, N. Lutz, P. Mavrommatis, and N. Provos,
“CAMP: Content-agnostic malware protection,” in IEEE Network and
Distributed Systems Security Symposium (NDSS), 2013.
J. W. Stokes, R. Ansersen, C. Seifert, and K. Chellapilla, “WebCop:
Locating neighborhoods of malware on the web,” in USENIX Workshop
on Large-Scale Exploits and Emergent Threats, 2010.
[30]
[13] S. Takashi Katsuki, “Malware targeting windows 8 uses google docs,”
http://www.symantec.com/connect/blogs/malware-targeting-windows-
8-uses-google-docs.
[14] C.
a
“Killing with
Squared,
cloud
chaining
core
attacks,”
http://www.cybersquared.com/killing-with-a-borrowed-knife-chaining-
core-cloud-service-proﬁle-infrastructure-for-cyber-attacks/.
borrowed
for
knife
cyber
service
proﬁle
infrastructure
[15] C. Seifert and R. Steenson, “Capture-honeypot client (capture-hpc),”
pp. Available at https://projects. honeynet. org/capture–hpc, 2006.
J. Nazario, “Phoneyc: A virtual client honeypot,” in USENIX conference
on Large-scale exploits and emergent threats: botnets, spyware, worms,
and more, 2009.
[16]
[18]
[17] Y.-M. Wang, D. Beck, X. Jiang, R. Roussev, C. Verbowski, S. Chen,
and S. King, “Automated web patrol with strider honeymonkeys,” in
IEEE Symposium on Network and Distributed System Security (NDSS),
2006, pp. 35–49.
J. Ma, L. K. Saul, S. Savage, and G. M. Voelker, “Beyond blacklists:
learning to detect malicious web sites from suspicious urls,” in ACM
SIGKDD International Conference on Knowledge discovery and Data
Mining, 2009, pp. 1245–1254.
J. P. John, F. Yu, Y. Xie, A. Krishnamurthy, and M. Abadi, “deseo:
Combating search-result poisoning.” in USENIX Security Symposium,
2011.
[19]
[20] C. Curtsinger, B. Livshits, B. Zorn, and C. Seifert, “Zozzle: Low-
overhead mostly static javascript malware detection,” in USENIX Se-
curity Symposium, 2011.
[21] C. Kolbitsch, B. Livshits, B. Zorn, and C. Seifert, “Rozzle: De-cloaking
internet malware,” in IEEE Symposium on Security and Privacy, 2012,
pp. 443–457.
16