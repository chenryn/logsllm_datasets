(MF Resistance). For a DB authenti-
cation scheme DB, a (t, qv, qp, qobs)-MF adversary A wins
against DB if the veriﬁer accepts A in one of the qv adversary-
veriﬁer sessions sid, which does not have any critical phase
tainted by a prover-adversary session sid∗. Thus, the MF-
DB(A) that A
resistance is deﬁned as the probability AdvMF
wins this game.
We now prove that TREAD is MF-resistant.
Theorem 3. If the challenges are drawn randomly from
a uniform distribution by the veriﬁer, E is an IND-CCA2-
secure encryption scheme and S is EUF-CMA-secure, then
TREAD is MF-resistant and
AdvM F
TREAD(λ) ≤ q2
p
22n +AdvEUF-CMA
S
(λ)+AdvIND-CCA2
E
(λ)+
4
(cid:18) 3
(cid:19)n
The prover and veriﬁer oracles are simulated as deﬁned in
Section 2, except that after generating e, the prover adds an
entry to a witness list WL containing (e, α||β).
The proof of the above theorem is more complex than for
previous ones.
It can be reduced to the security analysis
of a simpler version of the protocol, using the game-hopping
technique formalized by Shoup in [23]. In essence, the initial
security game Γ0 is reduced to a ﬁnal game in which the ad-
versary has no information (other than by guessing) about
the values α and β before the DB phase. This is done by
reducing his means of attacks at each game (e.g. by forbid-
ding the reuse of nonces from prover oracles), while showing
that the resulting loss is negligible. More formally, if P r[Γi]
represents the winning probability of the adversary A in the
game Γi, the transition between Γi and Γi+1 is such that
| Pr[Γi] − Pr[Γi+1]| ≤ λ, in which λ is a negligible function
of λ.
Proof. We start from the initial game Γ0 as given in
Deﬁnition 5 and build the following sequence of games.
Γ1: In this game, no value α||β is outputted more than once
i
by the prover oracle.
In the ith session, the probability to have a collision
with any of the previous i − 1 α||β values is bounded
22·n . If A runs qp prover sessions, the probability
by
of a collision for a given session is bounded by qp
22·n .
From the union bound, the probability that a collision
qp
22·n , which
p/22n. Thus, using Shoup’s
p/22n, which is
occurs at least once is bounded by (cid:80)qp
is in turn bounded by q2
diﬀerence lemma, | Pr[Γ0] − Pr[Γ1]| ≤ q2
negligible.
i=0
Γ2: This game aborts if σp was not generated by the prover
oracle, and S.vervk(σp, α||β) (cid:54)= 0.
In this game, we rule out the possibility that A pro-
duces a valid signature without the key, which is triv-
ially forbidden by the EUF-CMA resistance of S. The
reduction simply consists in starting EUF-CMA experi-
ments (one for each prover) with a challenger and using
queries to the corresponding signing oracle to generate
the signatures of a prover. Then, if A sends a valid
signature on behalf of one of the provers, we can re-
turn it to the challenger and win the EUF-CMA exper-
iment. From the Shoup’s diﬀerence lemma, we have
|P r[Γ1] − P r[Γ2]| ≤ AdvEUF-CMA
(1λ), which is negligi-
ble by hypothesis.
S
Γ3: In this game, e is replaced by the encryption of a random
string (of equal length).
This transition is based on indistinguishability, aiming
at removing any leakage of α||β from e by making α||β
only appear during the DB phase. We prove that the
probability  = P r[Γ3] − P r[Γ2] is negligible by build-
ing a distinguisher B such that its advantage against
the IND-CCA2 experiment is polynomial in . Hence,
if  is non-negligible, we reach a contradiction. By as-
sumption, the advantage of any adversary against the
IND-CCA2 experiment on E is negligible.
To build B, we replace E.encek(α||β||idprv(P )||σp) by a
string given by the IND-CCA2 challenger. Using the
adversary A, the distinguisher B can be built as fol-
lows.
808Prover simulation: B generates two challenge mes-
sages: m0 = (δ||idprv(P )||S.sigsk(δ||idprv(P ))) and
m1 = (α||β|| S.sigsk(α||β||idprv(P ))), in which α||β
and δ are random binary strings of length 2n.
Then, he sends them to the challenger to obtain
cb, the encryption of mb (depending on a random
bit b picked by the challenger before the experi-
ment). He also adds (cb, α||β) to the list WL. Af-
terwards, he sends cb as the initial message and
uses α||β during the challenge-response phase.
Veriﬁer simulation: When the veriﬁer oracle gets
the initial message e, he reads the tuple (e, α||β)
in WL and uses the corresponding α||β to verify
the responses.
If no such tuple exists, he is al-
lowed to use the decryption oracle on e (as it is
not a challenge cb). As Γ2 enforces that only in-
valid or prover-generated signatures are contained
in e, either A loses for sending an invalid signa-
ture or e is a new encryption for values contained
In the latter case, B
in one of the challenges.
readily obtains the bit b by verifying whether the
decryption of e corresponds to m0 or m1.
Return value: B returns OutV.
If b = 1, B simulates Γ2 (e is the encryption of α||β). In
this case, B wins if OutV = 1. By deﬁnition, P r[OutV =
1] in Γ2 = P r[Γ2]. Otherwise, if b = 0, then B sim-
In this case, B
ulates Γ3 (e is the encryption of δ).
returns 0 if A loses (i.e., with probability 1 − P r[Γ3]).
The winning probability of B is then P r[Γ2]+1−P r[Γ3]
=
, giving an advantage of  = P r[Γ2]−
1+(P r[Γ2]−P r[Γ3])
P r[Γ3]. It follows that any signiﬁcant diﬀerence in the
probabilities of the two games can be transformed into
an IND-CCA2 advantage. Thus, from the diﬀerence
lemma, we have |P r[Γ2] − P r[Γ3]| ≤ AdvIND-CCA2
(λ),
which is negligible by hypothesis.
E
2
2
We are left to prove that P r[Γ3] is negligible. First remark
that in Γ3, A has absolutely no way to predict the value ri
for any round i (as neither αi nor βi appears before round
i). Hence, A can either try to guess ci or ri. His success
probability in the second case is 1
2 . In the ﬁrst case, he suc-
ceeds if he guesses the challenge properly (as he can obtain
the response from the prover), but also if he makes a wrong
guess for the challenge but guesses correctly the other re-
sponse. The corresponding probability is 1
4 for
each round. As there are n such rounds, P r[Γ3] ≤(cid:0) 3
2 · 1 + 1
(cid:1)n.
2 = 3
2 · 1
4
3.4 Distance Hijacking
One of our contribution extends the distance-fraud (DF)
model in the DFKO framework to take into account distance-
hijacking (DH) attacks [14]. In DF attacks, the adversary
is a malicious prover who aims at authenticating from a
distance greater than dmax. In DH attacks, the adversary at-
tempts to do the same, but he uses the unintentional help of
a legitimate prover located close to the veriﬁer. The remote
adversary may initiate the DB protocol and let a nearby
prover complete the DB phase.
Although the DH attacks are generally real threats against
most the DB protocols, they do not represent a realistic
threat against DB protocols preserving anonymity. Indeed,
such attacks make only sense if the veriﬁer may diﬀerentiate
between two provers. For instance, if a remote member of a
legitimate group X initiates the DB protocol and a nearby
prover of the same group involuntarily completes the DB
phase, the veriﬁer would simply conclude that a member
of X has just been authenticated. He would end up with
the same conclusion if the nearby prover has completed the
scheme without any intervention from the remote party.
To capture DH in the DFKO framework, consider an ad-
versary (here a malicious prover) able to use the help of an
honest prover in the veriﬁer’s proximity. In the DB phase,
he commits to a response in advance (before the challenge
of that round) and sends this commitment. These commit-
ments do not refer to cryptographic commitments (with the
hiding and binding properties), but rather to the prover’s
choice with regards to a response, which he must transmit
to the veriﬁer. In any phase, he commits to a special message
Prompt, triggering the response by a nearby honest prover.
If the adversary either (1) fails to commit or prompt for
one speciﬁc phase, or (2) sends a diﬀerent value than com-
mitted after receiving the time-critical responses, he taints
the phase and the session. More formally, when the ad-
versary opens a veriﬁer-adversary session sid, he also opens
two associated dummy sessions sidCommit for committed re-
sponses and sidPrompt for the responses prompted from the
prover. Technically, such an adversary is more powerful than
in a typical DH attack [8], since the adversary can intercept
time-critical responses that are sent by the honest prover,
and replace them with his own committed responses. The
formal deﬁnition of tainted phases is as follows.
Definition 6
(Tainted Session (DH)). A time-crit-
ical round Πsid[k, k + 1] = (mk, mk+1), for some k ≥ 1 and
mk sent by the veriﬁer, of an adversary-veriﬁer session sid
is tainted if one of the following conditions holds.
• The maximal j with ΠsidCommit [j] = (sid, k + 1, m(cid:48)
k+1) for
k+1 (cid:54)= Prompt and marker(sid, k) > marker(sidCommit, j)
m(cid:48)
satisﬁes m(cid:48)
k+1 (cid:54)= mk+1 (or no such j exists).
• The maximal j with ΠsidCommit [j] = (sid, k + 1, m(cid:48)
k+1 = Prompt satisﬁes mk+1 (cid:54)= mPrompt
m(cid:48)
denotes the message mk+1 in sidPrompt.
k+1) for
k+1 , in which mPrompt
k+1
This deﬁnition rules out some potential actions of the ad-
versary. Afterwards, the game-based deﬁnition of DH resis-
tance notion can be stated as follows.
Definition 7
(DH Resistance). For a DB authenti-
cation scheme DB with DB threshold tmax, a (t, qp, qv, qobs)-
DH adversary A (with idA) wins against DB if the veriﬁer
accepts idA in one of qv adversary-veriﬁer sessions without
any critical round being tainted. Thus, the DH resistance is
DB(A) that A wins this game.
deﬁned as the probability AdvDH
The following theorem covers both DH and DF resistance.
The idea is that a DF can be seen as a special case of DH in
which the adversary does not use nearby provers. The proof
consists in showing that the responses corresponding to an
initial message e∗ sent by the adversary have a negligible
probability to match those of any nearby honest prover.
Theorem 4. If the challenges are drawn from a uniform
distribution, TREAD is DH resistant and
(cid:18) 3
(cid:19)n
4
.
AdvDH
TREAD(λ) ≤
The proof of this theorem is provided in Appendix B.1.
8093.5 Privacy
We now establish that the public-key instance of our pro-
tocol preserves the privacy of the provers against external
eavesdroppers. In particular, an adversary who intercepts
information transmitted during the protocol cannot infer
the identity of the prover from the information he has seen.
Otherwise, he would be able to break the security of the
encryption scheme.
The private construction is an instance of TREAD using
E = PKE and S = S-SIG, for a public key encryption PKE
and a digital signature scheme S-SIG.
In such protocols,
idpub(P ) is set to null. Since all the information allowing to
identify the prover is encrypted, only the veriﬁer can learn
his identity. This property [19] has been formalized as fol-
lows:
Definition 8
(Privacy Protection). Let DB be a
DB scheme. The privacy experiment ExpPrivA,DB(λ) for an ad-
versary A on DB is deﬁned as follows. A interacts with a
challenger who runs the algorithm DB.gen(1λ) to generate
the set-up and sends all the public set-up parameters to A.
During the experiment, the adversary A has access to the
following oracles:
DB.Joinc(·): On input i, it returns a public/secret key pair
(pki, ski) of the new prover Pi using DB.join(λ).
DB.Prover(·): On input i, it simulates a session by the prover
Pi using ski.
DB.Veriﬁer simulates a session by the veriﬁer V using skv.
Afterwards, A sends the pair of provers (i0, i1) to the chal-
lenger who picks b $← {0, 1}. Hereafter, A has now access to
the following challenge oracle:
DB.Proverb simulates a session by the prover Pib using skib .
Finally, A returns b(cid:48). If b = b(cid:48), the challenger returns 1,
which means that the guess of A is correct, while otherwise
he outputs 0.
We deﬁne A’s advantage on this experiment as
(cid:12)(cid:12)(cid:12)(cid:12)Pr[ExpPrivA,DB(λ) = 1] − 1
2
(cid:12)(cid:12)(cid:12)(cid:12)
AdvPrivA,DB(λ) =
and the advantage on the privacy experiment as
{AdvPrivA,DB(λ)}.