### Symbolic Computation for Variable Values and Its Applicability

SherLog employs symbolic computation to determine the values of variables along the inferred path. This information is directly applicable for programmers in diagnosing issues. Designed as a general tool, SherLog does not require prior knowledge of the system (e.g., log structure). Its validity heavily depends on the information obtainable from system logs. The approach is tailored for single-machine, non-concurrent programs where log information is self-enclosed in a unique source. For distributed and multi-process applications, different considerations may apply.

### X-Ray: Diagnosing Performance Anomalies

Attariyan et al. [6] introduce X-Ray, a tool for diagnosing performance anomalies in production software. X-Ray implements performance summarization, a technique that associates execution costs with fine-grained operations (such as system calls) and assigns these costs to root causes using control flow analysis at the event level. The output is a ranked list of root causes based on associated performance costs. X-Ray is designed to identify configuration errors and user input problems. During evaluation, it was able to identify the first root cause in 16 out of 17 tests across four server frameworks (Apache, Postfix, PostgreSQL, and lighttpd), with an average runtime overhead of 2.3% in production and an average identification time of 2 minutes.

### CloudPD: Automatic Fault Signatures for Cloud Failures

Sharma et al. [127] present CloudPD, which automatically constructs fault signatures from past failures in cloud environments. These signatures, composed of tracked variable pairs and thresholds, are used at runtime to diagnose problems identified by a behavioral modeling engine (see Section 4.3.1). CloudPD can diagnose various cloud and VM-related anomalies, such as invalid resource sizing, faulty VM reconfiguration, or workload mix changes. The accuracy of their approach ranges from 83% to 88%, depending on the benchmark used.

### HHMM for Resource Anomaly Diagnosis

Samir et al. [124] use Hierarchical Hidden Markov Models (HHMM) to associate resource anomalies with root causes in clustered resource environments, at the container, node, and cluster levels. Markov models are constructed and trained using the Baum-Welch algorithm with response time sequences as observations. The approach is evaluated in terms of accuracy and compared to two other algorithms. Predictions from the identification step are also fed into a recovery component for automatic healing (see Section 4.5.3).

### TAN Model for Failure Diagnosis

The TAN model described by Cohen et al. [31] (see Sections 4.2.2 and 4.3.1) correlates observable metrics with SLO violations. If the same input metrics are measured during diagnosis, the probabilistic model can provide a list of metrics correlating with specific events or problems. While this information may not always constitute the final diagnosis, it supports human diagnosis with viable hypotheses and evidence.

### Other Tools Supporting Root Cause Analysis (RCA)

This section analyzes smart software tools that, although they do not diagnose or localize faulty behavior, assist operators and developers in investigating detected problems and can be seen as ancillary resources for the main RCA task [3]. These tools may include information retrieval mechanisms to quickly gather evidence of recurrent problems, or dependency models for distributed systems to understand causal relationships between events and components, accelerating future diagnoses.

#### Causal Path Dependencies in Distributed Systems

Aguilera et al. [3] describe several approaches to identify performance problems in distributed systems by analyzing causal path dependencies between black-box components. Causal path patterns are extracted from message traces using two different algorithms: one applying a search heuristic on single messages to identify nested call pairs, and the other based on signal processing. The algorithms are compared in different applicability scenarios and tested on both synthetic and real traces. While the offline analysis does not directly focus on failures, it can be useful for IT operators seeking to acquire a component dependency model, which can be valuable for diagnosing failures.

#### Machine Learning for Software Failure Classification

Podgurski et al. [120] propose using machine learning algorithms to classify and group software failures to facilitate error prioritization and diagnosis. Programs are instrumented to collect execution profile data, which are then used to train a logistic regression classifier to predict failure causes. Feature coefficients obtained during training are used to select relevant features for clustering, where related failures are grouped using the k-medoids algorithm. In the experimental phase, failures collected from three large compiler programs are grouped according to the described method, and the corresponding clusters are visualized. The evaluation shows that for a large number of clusters (≥71%), the majority of failures originating from the same cause were assigned to the same cluster.

### Remediation

Based on the problem-specific knowledge gathered during the diagnosis step, such as the identification of root causes or the isolation of a faulty component, a sequence of automatic repair actions, referred to as remediation, can be initiated. Remediation approaches are often linked with service desk management concepts like ticket routing or solution recommendation. Compared to prevention, prediction, detection, and diagnosis tasks, remediation has received fewer scientific contributions linked to AI. This is possibly because, once the nature of the underlying problem is clarified through diagnosis, the recovery steps are almost immediately identifiable and attainable without complex models. We categorize the available contributions into three categories: incident triage, solution recommendation, and recovery.

#### Incident Triage

Incident triage involves categorizing reported problems, often for assignment to the correct expert resolution group [126, 158]. Triage can also be used to select suitable diagnosis and remediation algorithms.

**Resolution Sequence Mining:**
Shao et al. [126] propose mining resolution sequences to improve future ticket routing and speed up recovery. Ticket routing sequences are analyzed using a Markov Model, from which several routing algorithms are developed and tested for effectiveness, robustness, and applicability. The mean number of steps to resolve tickets is reduced from 3.94 to 2.58 (−34.52%) on 2,634 tickets. The approach is entirely based on the observation of resolution sequences and does not rely on ticket content.

**Hierarchical Ticket Classification:**
Zeng et al. [158] propose Kilo to classify ticket data on multiple levels by analyzing symptom descriptions. Their work deals with the ticket labeling problem from a hierarchical perspective, assigning tickets to increasingly specific subclasses in a tree hierarchy. The classification algorithm, based on Bayesian decision theory, introduces a new hierarchical loss function to minimize the expected misclassification risk when making non-leaf predictions in the tree label structure. A greedy prediction algorithm is deployed to perform hierarchical classification, integrating available domain expert knowledge in the form of prior probabilities.

#### Solution Recommendation

These approaches provide implementations for recommending solutions to occurring problems, often based on past incident history and the annotation of solutions in a previous resolution window. Therefore, these approaches mostly operate as retrieval systems similar to those described for root-cause analysis in Section 4.4.3.

**Similarity-Based Algorithms:**
Zhou et al. [166] propose similarity-based algorithms to suggest the resolution of repeating problems from incident tickets. The basic approach retrieves k ticket resolution suggestions using a k-NN approach. Similarity between tickets is evaluated based on a mixture of numerical, categorical, and textual data, with individual and aggregate similarity measures defined. The basic solution is extended to handle false-positive tickets, classifying each ticket as real or false using a binary classifier with a k-NN approach and weighing ticket importance based on the prediction outcome. The final solution recommendation considers both importance and similarity. The paper also incorporates ideas for improving feature extraction, such as topic discovery and metric learning.

**Cognitive Framework for Recovery Actions:**
Wang et al. [140] propose a cognitive framework based on ontologies to construct domain-specific knowledge and suggest recovery actions for tickets in IT service management. The approach analyzes free-form text in summary and resolution descriptions, extracts domain-specific phrases using language processing techniques, and develops an ontology model to provide definitions, classes, and interconnecting relations of keywords. The model is then used to recommend resolution actions by matching concept patterns extracted in incoming and historical tickets via similarity functions (such as the Jaccard distance). The experimental phase tests the extracting accuracy of concept patterns, reaching 86.2% for the prediction of required actions.

**Natural Language Processing for Repair Actions:**
Facebook [82] deploys natural language processing techniques to predict repair actions from closed tickets. Up to five repair actions are recommended by analyzing raw text logs as input features, with accuracy ranging from 50% to 80%. The paper also illustrates other in-house failure management systems, including an online anomaly detection algorithm and an automatic repair engine.

#### Recovery

Recovery approaches take direct and independent actions toward resolving a diagnosed problem. According to our mapping study, no distinctive contribution has been proposed to perform direct recovery actions with AI. The closest match is the work of Samir et al. [124], where a combined detection/RCA/remediation framework uses HHMM to associate detected anomalies with root causes. The last step of their pipeline performs recovery actions based on the insights obtained in the identification step, with specific recovery actions defined for each failure case. The efficiency of the recovery step is assessed via MTTR and recovery rate.

In a broader sense, preventive actions that do not require diagnosis information can also be considered as recovery. This includes reactive mechanisms applied in combination with online failure prediction mechanisms (described in Section 4.2) to perform data migration or checkpointing preemptively [33, 78].

### Conclusion

#### Current and Future Trends in Failure Management

In the previous sections, we described many AI contributions to deal with failures in AIOps. In this final section, we focus on the big picture, analyzing the current status of failure management in AIOps and examining the currently open challenges and suggesting future directions for research.

AIOps has shown a steady growth trend in recent years, with at least 100 contributions proposed annually over the last five years. This growth is expected to continue due to increasing demand for reliability and efficiency in large-scale computing systems. The evolution of cloud technologies (e.g., virtualization, monitoring tools) will provide ample space for future improvements and the experimentation of new techniques. To meet these expectations, the field must provide a solid ground for experimentation, based on more formal standardization of problems and a stronger attitude toward benchmarks for comparison and evaluation. Efforts in creating standard problems and benchmark datasets would be rewarding.

The analysis of topics and tasks in the current AIOps landscape, as observed and described in Section 4, allows us to investigate possible future directions. Table 8 shows how...