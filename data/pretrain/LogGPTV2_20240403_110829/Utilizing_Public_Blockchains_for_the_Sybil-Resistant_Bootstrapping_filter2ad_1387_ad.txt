user incrementally establishes the next hop of her new circuit based
on her selected peers’ advertisements. She contacts the new peer
through her partially established circuit and attempts to hand over
control to the Tor client through the connector. If this handover of
control fails, e.g., due to an invalid advertisement, she terminates
the connection to that peer and selects a replacement privacy peer.
Although an honest majority among privacy peers reduces the
overhead of such security back-offs, enabling privacy peers to build
up a positive reputation across consecutive peer advertisements
promises to further reduce respective risks for users.
Incentives. If honest providers of onion routers must be compen-
sated for investing their resources to periodically solve PoW puzzles
and advertise themselves in AnonBoot, cryptocurrency-based ser-
vice fees are a promising means for creating operator incentives.
However, on-chain payments bear high risks of implicitly recording
information about users’ circuits irrevocably. We thus propose that
users and privacy peers create anonymous unidirectional micropay-
ment channels [18]. Although micropayment channels require an
on-chain setup, users can protect their privacy due to the concur-
rent setup transactions of all users. This way, users can pay peers
who advertise themselves via AnonBoot for their service.
5.2 Shuffling Networks and Cryptotumblers
AnonBoot’s main advantage is to provide a medium for bootstrap-
ping distributed anonymity services and to ensure their privacy
peers’ independence through its PoW puzzles and secure peer elec-
tion. Privacy-aware users thus gain the opportunity to rely on
secure on-demand anonymization for, e.g., message shuffling or
increasing their financial privacy.
Benefits. Distributed systems that outsource responsibility to a set
of peers typically rely on secure multi-party computation (SMC) [1,
55]. Unfortunately, scalability limitations of those SMC protocols
hinder distributing responsibility among large sets of privacy peers.
Without carefully selecting the responsible privacy peers, insider
adversaries thus can gain power and cause harm relatively easily.
However, our considered use cases of anonymous message disclo-
sure and tumbling cryptocurrencies lack a trustworthy peer selec-
tion process, and adversaries are highly incentivized to attack such
systems. For example, an adversary could easily spawn numerous
interconnected privacy peers, and thereby mimic a distributed cryp-
totumbler, tricking users into participation. AnonBoot provides the
ingredients to cryptographically ensure through its Sybil-resistant
peer repository and locally verifiable peer election that an adversary
cannot bootstrap malicious services. Hence, privacy-aware users
reduce their individual risks when utilizing distributed anonymity
services bootstrapped via AnonBoot.
Peer Advertisements. The capabilities privacy peers need to ad-
vertise highly depend on the provided anonymity service. Similarly
to our previous use case, privacy peers should facilitate the users’
browsability of anonymity services by advertising supported poli-
cies or security parameters. However, AnonBoot does not consider
the service-specific capabilities during its peer election but requires
the service identifier used (cf. Section 4.2) to ensure compatibility
among privacy peers advertising the same service.
Bootstrapping Phase. Privacy peers are partitioned by the identi-
fier of the anonymity service they advertise to ensure compatibility
during the bootstrapping process. By locally replaying the peer
election, each privacy peer gets to know (a) whether it was elected
to provide a service, (b) which peers are elected to bootstrap the
same service instance, and (c) the peer’s logical position within the
new network. Hence, privacy peers can independently configure
and bootstrap the anonymity service. Currently, we take a conser-
vative approach and declare services stale after a couple of pulses
to mitigate the impact of privacy peer churn and malicious services
bootstrapped by chance. However, conceptually, AnonBoot also
supports bootstrapping long-lived anonymity services.
Incentives. Since these use cases do not prohibit a direct connec-
tion between users and elected privacy peers, we can simplify our
payment scheme proposed in Section 5.1 and instead require users
to pay an upfront fee (e.g., as proposed by CoinParty [55]). We
argue that the increased security provided by AnonBoot is worth
compensating the privacy peer’s efforts of solving PoW puzzles.
Takeaway. In conclusion, AnonBoot provides a viable medium for
bootstrapping anonymity services from a diverse set of available
applications as it simultaneously mitigates malicious influences
and compensates honest operators if privacy peers.
6 SECURITY DISCUSSION
We assess AnonBoot’s robustness against adversaries by discussing
the implications of incorporating PoW into peer advertisements
and arguing that active adversaries cannot bias the peer election.
6.1 Proof of Work Against Sybil Attacks
Requiring a PoW in each peer advertisement hampers an adver-
sary’s effort to control large portions of the peer repository and
thus his overall influence. However, the choice of the PoW scheme
is paramount for AnonBoot’s resilience against Sybil attacks. We
thus highlight the need for an appropriate PoW scheme but leave
its final instantiation to be adapted to users’ needs in future work.
Particularly, AnonBoot’s PoW scheme must ensure that opera-
tors can only create peer advertisements at rates corresponding to
their number of physical devices controlled while not excluding
honest operators using commodity hardware. While specialized
hardware is known to provide huge advantages for CPU-bound PoW
schemes such as Bitcoin’s scheme, memory-bound PoW schemes
such as Ethereum’s Ethash [42, 51], Cuckoo Cycle [47], Equihash [5],
or RandomX [41], which was recently adopted by Monero [40], are
promising candidates to be adapted for utilization with AnonBoot.
For instance, based on openssl speed, we observe that a server
(two Intel Xeon Silver 4116, 187.39 GiB RAM) outperforms a com-
modity desktop PC (Intel Core 2 Q9400 CPU, 7.67 GiB RAM) by two
orders of magnitude for Bitcoin’s HASH256-based PoW scheme.
Further, Bitcoin mining hardware [7] reportedly outperforms our
commodity PC by eight orders of magnitude, which clearly under-
lines the potential advantage of adversaries relying on specialized
hardware to forge advertisements using CPU-bound PoW schemes.
Contrarily, initial measurements using Ethash (via geth’s CPU-
based mining) and RandomX indicate that the same server only
achieves a mere 7.5× (12.7×) speed-up over the desktop PC in terms
of achievable hash rate using this PoW scheme. Thus, relying on
memory-hard PoW schemes is preferable to prevent adversaries
with powerful devices or, e.g., a botnet, from increasing their influ-
ence on the peer repository in an incommensurate manner [5].
Finally, we address the challenge of steering the PoW puzzles’ dif-
ficulty to account for improvements in hardware capabilities. In con-
trast to cryptocurrency mining, AnonBoot’s peer advertisements
have no inherent concurrency, i.e., the size of the peer repository
does not influence the required difficulty for the PoW. Assuming an
honest majority, we can expect that privacy peers have an interest
in keeping an appropriate PoW difficulty for security reasons. Thus,
we can dedicate unused bits in the peer advertisements (cf. Sec-
tion 4.2) to enable voting on increasing the difficulty. Privacy peers
would then update their local threshold for accepting the PoW in
peer advertisements based on votes of the (honest) majority.
Takeaway. Utilizing a simple CPU-bound PoW scheme for our
puzzles would significantly impact AnonBoot’s security proper-
ties. Contrarily, memory-bound PoW schemes constitute a secure
building block to maintain a Sybil-resistant peer repository. As for
existing systems, such as Tor or Bitcoin, the reliability of Anon-
Boot’s peer repository then depends on maintaining an honest ma-
jority, either on a voluntary basis or through operator incentives.
Finally, we can further leverage this honest majority to implement
a self-regulated adaption of the puzzles’ difficulty.
Figure 7: The success rate of an adversary to 1/3-infiltrate ser-
vices by chance can be kept below the robustness threshold
T1/3 for fR ≤ 30%, i.e., peer election remains robust for rele-
vant scenarios involving SMC-based anonymity services.
6.2 Security of Bootstrapped Services
The core design goal of AnonBoot is to securely bootstrap dis-
tributed anonymity services. We have already shown that Anon-
Boot can maintain a Sybil-resistant peer repository, i.e., adversaries
cannot control a disproportional fraction of the peer repository.
However, adversaries can still enter the peer repository as long as
they can create a valid PoW. We now highlight that AnonBoot’s peer
election is robust against adversarial bias and that bootstrapped
anonymity services can tolerate a share of adversarial privacy peers.
Security of Local Peer Selection. Anonymity services which
rely on local peer selection only require the Sybil resistance pro-
vided by AnonBoot’s peer repository (cf. Section 6.1). However, pri-
vacy peers are not always treated equally: For example, in Tor, users
change their first relays, i.e., guard nodes, only infrequently [26]
and they can only use exit nodes that support their requests [16]. By
encoding the privacy peers’ capabilities accordingly (cf. Section 4.2),
users can respect these properties when establishing circuits. The
peer repository hence constitutes a secure alternative to current
directory services provided by trusted third parties.
Robustness of Peer Election. AnonBoot’s peer election must
properly protect its users, i.e., bootstrap secure anonymity services.
To assess the influence of an adversary, we consider his chance of
infiltrating an anonymity service during peer election based on the
share of privacy peers he controls. An adversary successfully infil-
trates an anonymity service if he controls a share fS ≥ tI of that ser-
vice’s privacy peers, exceeding its infiltration threshold tI , i.e., he can
defy the service’s underlying security guarantees. E.g., a malicious
adversary infiltrates any SMC-based anonymity service when con-
trolling fS ≥ 1/3 of the peers [4]. Under this notation, we consider
peer election to be robust if adversaries cannot increase their chance
of infiltrating services beyond their share fR of privacy peers in the
peer repository. More formally, assuming that no adversarial share
of the peer repository exceeds a threshold tR, we define a robustness
measure R(tI , tR) = 1−Pr(fS ≥ tI | fR ≤ tR). We further define that
the peer election is robust iff Pr(fS ≥ tI | fR ≤ tR) ≤ tR =: TI holds,
i.e., TI = tR can be interpreted as a robustness threshold against
tI -infiltration. For instance, an adversary controlling up to fR ≤ 10%
of the peer repository should only have a chance of TI = 10% to
tI -infiltrate an anonymity service.
Figure 7 highlights AnonBoot’s robustness regarding SMC-based
anonymity services, i.e., tI =1/3 [4], which can tolerate up to ⌊n/3⌋
05101520253033.335404550Adversary-controlledPeersfR[%]0102030405060708090100AdversarySuccessRate[%]Shareof1/3-InﬁltratedNetworks(1000PeersinRepository)4privacypeers16privacypeers31privacypeers100privacypeersrobustnessthresholdexpectedshareadversary-controlled privacy peers. For desired networks consist-
ing of 4, 16, 31, and 100 peers (i.e., tI = 1, 5, 10, 33) respectively,
we measured the success of an adversary controlling a growing
share fR of the peer repository to infiltrate anonymity services
by chance due to our peer election. To extract entropy from the
pulse’s spawn blocks, we rely on the Merkle tree root. More secure
entropy extraction can be achieved by applying more sophisticated
randomness extractors [10]. For our evaluation, we assume a peer
repository consisting of 1000 peers, randomly elect peers for 100 000
anonymity services for each scenario, and count the number of
1/3-infiltrated services. We also highlight the robustness threshold
for comparison and provide the expected shares of 1/3-infiltrated
services based on combinatoric considerations.
Our evaluation reveals two major findings: First, our peer elec-
tion is fair in that it almost perfectly yields the expected distribution
of 1/3-infiltrated services when electing honest and dishonest peers
uniformly at random. Second, the peer election remains robust as
long as the adversary controls fR ≤ 25% of the peer repository. For
a growing power of the adversary, AnonBoot cannot guarantee
robustness, although larger anonymity services yield better pro-
tection if the adversary controls a share of at most fR ≤ 30%. For
all fR ≥ 1/3, AnonBoot is not robust anymore as the adversary can
infiltrate most SMC-based services. However, in those cases, his
control of the peer repository exceeds the infiltration threshold for
SMC-based services; thus, we consider the peer repository insecure.
AnonBoot relies on entropy from the host blockchain to seed
its PRNG for peer election. Adversaries are thus tempted to influ-
ence the seed by interfering with the on-chain data to increase
their chances of infiltrating anonymity services. Our rationale for
AnonBoot’s robustness only holds if we can effectively prevent
such interference. As we described in Section 4.3, we include user-
submitted entropy into the seed derivation to ensure that seeds are
not entirely determined by the miners of AnonBoot’s host block-
chain. However, by incorporating the spawn block, we, in return,
drastically limit the capabilities of an adversary. Namely, the ad-
versary must (a) successfully mine the spawn block Si for pulse Pi,
while (b) crafting this block to yield, in conjunction with the user-
supplied entropy, a biased pre-image of a favorable seed, which
is (c) derived from a cryptographic hash function. Assuming that
no adversary possesses the computing power to control the host
blockchain, we deem this kind of attack economically infeasible as
honest mining is more profitable for the adversary. In the future,
we could also adapt AnonBoot to consider multiple consecutive
spawn blocks to further thwart the influence of adversaries.
Security of Handover Process. For most anonymity services,
AnonBoot requires indirection through the connector when first
establishing connections. During this handover process, each par-
ticipant’s connector has to authenticate all privacy peers based on
the public key previously announced in the respective peer adver-
tisements. Hence, users only connect to privacy peers controlled by
operators that created valid and distinct peer advertisement. The
adversary thus cannot launch Sybil attacks through this indirection.
Denial of Service (DoS). Due to our secure local peer selection,
robust peer election, and secure handover primitives, the security
of utilizing bootstrapped anonymity services only depends on the
security guarantees offered by those services. While AnonBoot
prevents adversaries from infiltrating anonymity services with
high probability, distributed services are still prone to DoS attacks,
effectively preventing proper anonymization. However, we argue
that the anonymity services currently covered by AnonBoot can
cope with such attacks: First, AnonBoot allows for the efficient
creation of circuits for anonymity networks. Hence, the limited
influence of single stalling relays does not significantly impede the
users’ privacy. Second, CoinParty, our investigated cryptotumbler,
detects and excludes stalling peers as long as adversaries did not
infiltrate at least 1/3 of the peers of the CoinParty instance’s mixing
network [55]. Finally, while traditional shuffling networks do not
provide protection against DoS attacks, extending them with the
measures taken by CoinParty achieves the same level of protection.
Thus, our peer election does not directly thwart DoS attacks, but
their impact on our considered anonymity services is highly limited.
Takeaway. In conclusion, the peer election yields trustworthy
anonymity services as long as the majority of eligible privacy peers
contribute honestly to providing these services, which we ensure
through our Sybil-resistant peer repository and operator incentives.
7 PERFORMANCE EVALUATION
We demonstrate AnonBoot’s feasibility by discussing its required
synchronization times and its impact on its host blockchain.
7.1 Time Overheads
To continually monitor AnonBoot’s state, participants should main-
tain a local copy of its host blockchain. However, we only rely on
the correctness of the host blockchain’s PoW as AnonBoot’s trust
anchor. Hence, while constrained devices may rely on a trusted
source to provide a correct state, e.g., a trusted IoT gateway [20],
more powerful devices preferably maintain their AnonBoot state
themselves. We again consider Bitcoin as our working example for
a host blockchain and highlight how initial synchronization with
AnonBoot differs from a full synchronization with Bitcoin. Since
the validity of peer advertisements typically expires in AnonBoot,
as with block-pruning approaches [29] participants only have to
download and verify the chain of Bitcoin’s block headers and pro-