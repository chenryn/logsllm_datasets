5100/Y
5100/Y
9314/Y
17565/Y
17732/Y
17465/Y
-/N
-/N
-/N
-/N
-/Y
-/Y
-/Y
-/Y
-/Y
0.10
0.10
0.10
0.10
0.10
0.10
0
0.10
1
(s)
1
2
3
4
5
6
7
8
9
0.27
0.27
0.27
0.26
0.04
0.07
0.12
0.12
0.11
1453.12
1456.43
1448.53
1378.62
209.21
725.19
2674.77
2680.25
2306.93
(KB)
592440
592536
592604
657436
662080
1336808
2375564
2667132
3565964
Figure 2: Experimental evaluation of single runs of the algorithm reduce
we may expect that indexing of predicates that are nested
deeper in the policy would improve performance more. The
results of Experiments 1–5 verify this expectation. For ex-
ample, indexing the table of the predicate send (Experi-
ment 2), which appears only in the restriction of the top-level
quantiﬁer of ϕHIPAA does not improve the running time at
all over the baseline without any indexing (Experiment 1)
because during the execution of reduce on ϕHIPAA, the send
table is not accessed randomly. Instead, it is scanned linearly
to instantiate the top-level quantiﬁer in ϕHIPAA. Adding an
index on the table tagged (Experiment 3), which is nested
under two quantiﬁers, improves performance slightly over
indexing send alone. Indexing attr in db (Experiment 4),
which is nested very deep under quantiﬁers in the policy
results in a noticeable improvement in performance. When
we index all other tables in our database, of which six corre-
spond to predicates that are nested very deep under quan-
tiﬁers in the policy formula, we notice a large improvement
in performance (Experiment 5).
Experiments 5, 6 and 8 measure the impact of log size on
audit time for fully indexed tables. As expected, both the
overall audit time and the per-disclosure audit time increase
as the size of the logs increases.
Experiments 7–9 measure the eﬀect of changing the ra-
tio of policy violating disclosures to policy compliant disclo-
sures. As can be seen, the average time per disclosure de-
creases slightly when more disclosures are violations. This
is because the main body of ϕHIPAA contains conjunctions
after the outermost quantiﬁer. For an instance of the quan-
tiﬁer corresponding to a policy violation, reduce terminates
as soon as any one formula in the conjunction reduces to
false. On the other hand, for an instance of the quantiﬁer
corresponding to a policy compliant disclosure, the entire
formula must be reduced.
Consequently, an experiment without policy violations (e.g.,
Experiment 7) measures the worst case performance of au-
dit. Even this performance is very practical — for a database
of size 15MB containing 21,684 disclosures without any vio-
lations, reduce can audit each disclosure in an average time
of 0.12s.
In the second set of experiments, we simulate a run of
our algorithm with three iterations on progressively larger
logs, and measure the size of the residual formula after each
iteration. The input to the ﬁrst iteration is the formula
ϕHIPAA and a log containing 5401 disclosures.
Figure 3 summarizes the evaluation results. The ﬁrst col-
umn is the size of a textual rendering of the policy formula
that is the input of reduce, and the second column is the
size of the resulting output formula. The remaining columns
document the running times, memory consumption, the size
of the log in an iteration, and the number of disclosures in
the log. The output formulas are quite large, e.g., after the
ﬁrst run, the output formula has a size 4,654.07 KB. The
output formula is large because for each disclosure in the
log, most of the policy formula is replicated in the output,
but owing to a large number of SUBJ atoms in ϕHIPAA,
these replicated formulas are not eliminated completely (67
out of the 84 clauses contain SUBJ atoms [15]). Although
large output formulas slow subsequent iterations, such auto-
matic iterations are not the intended application of reduce.
Instead, we expect that our reduce algorithm will be used
with an interactive front-end that allows an auditor to se-
lect speciﬁc subformulas of interest (e.g., those pertaining to
disclosures by a speciﬁc agent) and run the reduce algorithm
only on them. The front-end may also allow the auditor to
provide information about subjective atoms and record such
information for subsequent use.
6. RELATED WORK
Runtime Monitoring with Temporal Logic. A lot of
prior work addresses the problem of runtime monitoring of
policies expressed in Linear Temporal Logic (LTL) [32, 3,
29, 31, 9, 5] and its extensions [30, 5, 31]. Although sim-
ilar in the spirit of enforcing policies, the intended deploy-
ment of our work is diﬀerent: We assume that system logs
are accumulated independently and given to our algorithm,
whereas an integral component of runtime monitoring is ac-
cumulation of system logs on the ﬂy. Our assumption about
the availability of system logs ﬁts practical situations like
health organizations, which collect transmission, disclosure
and other logs to comply with regulations such as HIPAA
even if no computerized policy enforcement mechanism is in
place.
Comparing only the expressiveness of the logic, our work
is more advanced than all existing work on policy enforce-
ment. First, LTL can be encoded in our logic easily [15]. Sec-
ond, we allow expressive quantiﬁcation in our logic, whereas
prior work is either limited to propositional logic [32, 3, 29],
or, when quantiﬁers are considered, they are severely re-
stricted [30, 5, 31]. A recent exception to such syntactic
restrictions is the work of Basin et al. [9], to which we com-
pare in detail below. Third, no prior work considers the
possibility of incompleteness in structures, which our reduce
algorithm takes into account.
Recent work by Basin et al. [9] considers runtime monitor-
ing over an expressive fragment of Metric First-order Tem-
poral Logic. Similar to our work, Basin et al. allow quantiﬁ-
cation over inﬁnite domains, and use a form of mode analysis
(called a safe-range analysis) to ensure ﬁniteness during en-
Policy size Residual policy Ave. Time per Total time Memory used
(KB)
39.52
4654.07
9369.32
size (KB)
4654.07
9369.32
19186.84
disclosure(s)
0.04
0.75
2.99
(s)
209.68
8193.76
65009.30
(KB)
662080
4063472
4033484
(MB)
3.98
7.68
15.1
Log size Number of
disclosures
5401
10866
21742
Figure 3: Experimental evaluation of iterative runs of the algorithm reduce
forcement. However, Basin et al.’s mode analysis is weaker
than ours; in particular, it cannot relate the same variable
in the input and output positions of two diﬀerent conjuncts
of a restriction and requires that each free variable appear in
at least one predicate with a ﬁnite model. As a consequence,
some policies such as the HIPAA policy ϕHIPAA from Sec-
tion 5, whose top-level restriction (send(p1, p2, m, τ ) ∧
purp(m, u)) contains a variable u not occurring in any pred-
icate with a ﬁnite model, cannot be enforced in their frame-
work, but can be enforced in ours.
Formal Frameworks for Policy Audit. Cederquist et
al. [12] present a proof-based system for a-posteriori audit,
where policy obligations are discharged by constructing for-
mal proofs. The leaves of proofs are established from logs,
but the audit process only checks that an obligation has
been satisﬁed somewhere in the past. Further, there is no
systematic mechanism to instantiate quantiﬁers in proofs.
However, using connectives of linear logic, the mechanism
admits policies that rely on use-once permissions.
Iterative Enforcement. The idea of iteratively rewrit-
ing the policy over evolving logs has been considered pre-
viously [29, 32], but only for propositional logic where the
absence of quantiﬁers simpliﬁes the problem considerably.
Bauer et al. [3] use a diﬀerent approach for iterative enforce-
ment: they convert an LTL formula with limited ﬁrst-order
quantiﬁcation to a B¨uchi automaton and check whether the
automaton accepts the input log. Further, they also use
a three-valued semantic model similar to ours, but assume
that logs record all information about past events (past-
completeness). Three-valued structures have also been con-
sidered in work on generalized model checking [11, 19]. How-
ever, the problems addressed in that line of work are diﬀer-
ent; the objective there is to check whether there exist ex-
tensions of a given structure in which a formula is satisﬁed
(or falsiﬁed).
Barth et al. [6] present two
Compliance Checking.
formal deﬁnitions of compliance of an action with a policy,
called strong and weak compliance. An action is strongly
compliant with a policy given a trace if there exists an ex-
tension of the trace that contains the action and satisﬁes the
policy. We do not consider strong compliance in this paper.
An action is weakly compliant with a policy in Propositional
LTL (PLTL) given a trace if the trace augmented with the
action satisﬁes the present requirements of the policy. How-
ever, a weakly compliant action might incur unsatisﬁable fu-
ture requirements. The technical deﬁnition is stated in terms
of a standard tableau construction for PLTL [24] that syn-
tactically separates present and future requirements. Our
correctness property for reduce generalizes weak compliance
to a richer class of policies and structures: PLTL can be
encoded in our policy logic, the residual formula generalizes
future requirements, and past-complete traces are a special
case of our partial structures.
In a related paper, Barth et al. [7] present an algorithm
that examines audit logs to detect policy violations and iden-
tify agents to blame for policy violations. While our audit
algorithm can be used to detect violations of a much richer
class of policies than the propositional logics considered by
Barth et al., it does not identify agents to be blamed for
violations.
Lam et al. [22] represent policy requirements of a part
of the HIPAA Privacy Rule in an extension of Prolog with
stratiﬁed negation, called pLogic, and use it to implement
a compliance checker for a medical messaging system. The
compliance checker makes decisions about legitimacy of mes-