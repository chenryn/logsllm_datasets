door to veriﬁably secure operating systems.
Bugs and warnings are not distributed evenly through-
out the kernel. Of the eleven bugs we found in Linux
2.4.23, all but two are in device drivers. Since there are
about 1500KLOC in drivers and 700KLOC in the rest
of the kernel, this represents a defect rate of about one
bug per 200KLOC for driver code and about one bug
per 400KLOC for the rest of the kernel. (Caveat: These
numbers must be taken with a grain of salt, because the
sample size is very small.) This suggests that the core
kernel code is more carefully vetted than device driver
code. On the other hand, the bugs we found are not
just in “obscure” device drivers: we found four bugs in
the core of the widely used PCMCIA driver subsystem.
Warnings are also more common in drivers. In our ﬁle-
by-ﬁle experiment with 2.4.23, 196 of the 264 unique
warnings were in driver ﬁles.
Finally, we discovered a signiﬁcant amount of bug
turnover. Between Linux kernels 2.4.20 and 2.4.23, 7
user/kernel security bugs were ﬁxed and 5 more intro-
duced. This suggests that even stable, mature, slowly
changing software systems may have large numbers of
undiscovered security holes waiting to be exploited.
6 False Positives
We analyzed the false positives from our experiment
with Linux kernel 2.4.23. This investigation serves two
purposes.
First, since it is impossible to build a program veriﬁ-
cation tool that is simultaneously sound and complete,5
any system for developing provably secure software
must depend on both program analysis tools and pro-
grammer discipline. We propose two simple rules, based
on our false positive analysis, that will help software de-
velopers write veriﬁably secure code.
Second, our false positive analysis can guide future
reasearch in program veriﬁcation tools. Our detailed
classiﬁcation shows tool developers the programming
idioms that they will encounter in real code, and which
ones are crucial for a precise and useful analysis.
Source
User ﬂag
Address of array
Non-subtyping
C type misuse
Field uniﬁcation
Field update
Open structure
Temporary variable
User-kernel assignment
Device buffer access
FS Tricks
Frequency Useful
50 Maybe
24
20
19
18
15
5
4
3
2 Maybe None
2 Maybe None
Fix
Pass two pointers instead of from user ﬂag
Yes Don’t take address of arrays
No Enable subtyping
Yes Declare explicit, detailed types
No None
No None
Yes Use C99 open structure support
Yes Don’t re-use temporary variables
Yes
Set user pointers to NULL instead
Table 3: The types of false positives CQUAL generated and the number of times each false positive occurred. We
consider a false positive useful if it tends to indicate source code that could be simpliﬁed, clariﬁed, or otherwise
improved. Where possible, we list a simple rule for preventing each kind of false positive.
Our methodology was as follows. To determine the
cause of each warning, we attempted to modify the ker-
nel source code to eliminate the warning while pre-
serving the functionality of the code. We kept careful
notes on the nature of our changes, and their effect on
CQUAL’s output. Table 3 shows the different false posi-
tive sources we identiﬁed, the frequency with which they
occurred, and whether each type of false positives tended
to indicate code that could be simpliﬁed or made more
robust. The total number of false positives here is less
than 264 because ﬁxing one false positive can eliminate
several others simultaneously. The extended version of
this paper explains each type of false positive, and how
to avoid it, in detail.
Based on our experiences analyzing these false positives,
we have developed two simple rules that can help future
programmers write veriﬁably secure code. These rules
are not speciﬁc to CQUAL. Following these rules should
reduce the false positive rate of any data-ﬂow oriented
program analysis tool.
Rule 1 Give separate names to separate logical entities.
Rule 2 Declare objects with C types that closely reﬂect
their conceptual types.
As an example of Rule 1, if a temporary variable some-
times holds a user pointer and sometimes holds kernel
pointer, then replace it with two temporary variables,
one for each logical use of the original variable. This
will make the code clearer to other programmers and,
with a recent compiler, will not use any additional mem-
ory. 6 Reusing temporary variables may have improved
performance in the past, but now it just makes code more
confusing and harder to verify automatically.
As an example of the second rule, if a variable is concep-
tually a pointer, then declare it as a pointer, not a long
or unsigned int. We actually saw code that declared
a local variable as an unsigned long, but cast it to a
pointer every time the variable was used. This is an ex-
treme example, but subtler applications of these rules are
presented in the extended version of this paper.
Following these rules is easy and has almost no impact
on performance, but can dramatically reduce the num-
ber of false positives that program analysis tools like
CQUAL generate. From Table 3, kernel programmers
could eliminate all but 37 of the false positives we saw
(a factor of 4 reduction) by making a few simple changes
to their code.
7 Related Work
CQUAL has been used to check security properties in
programs before. Shankar, et al., used CQUAL to ﬁnd
format string bugs in security critical programs[11], and
Zhang, et al., used CQUAL to verify the placement of
authorization hooks in the Linux kernel[16]. Broadwell,
et al. used CQUAL in their Scrash system for eliminating
sensitive private data from crash reports[2]. Elsman, et
al. used CQUAL to check many other non-security appli-
cations, such as Y2K bugs[4] and Foster, et al. checked
correct use of garbage collected “ init” data in the
Linux kernel[6].
Linus Torvalds’ program checker, Sparse, also uses
type qualiﬁers to ﬁnd user/kernel pointer bugs[12].
Sparse doesn’t support polymorphism or type inference,
though, so programmers have to write hundreds or even
thousands of annotations. Since Sparse requires pro-
grammers to write so many annotations before yielding
any payoff, it has seen little use in the Linux kernel.
As of kernel 2.6.0-test6, only 181 ﬁles contain Sparse
user/kernel pointer annotations. Sparse also requires ex-
tensive use of type qualiﬁer casts that render its results
completely unsound. Before Sparse, programmers had
to be careful to ensure their code was correct. After
Sparse, programmers have to be careful that their casts
are also correct. This is an improvement, but as we saw
in Section 5, bugs can easily slip through.
Yang, et al. developed MECA[15], a program check-
ing tool carefully designed to have a low false positive
rate. They showed how to use MECA to ﬁnd dozens of
user-kernel pointer bugs in the Linux kernel. The essen-
tial difference between MECA and CQUAL is their per-
spective on false positives: MECA aims for a very low
false positive, even at the cost of missing bugs, while
CQUAL aims to detect all bugs, even at the cost of in-
creasing the false positive rate. Thus, the designers of
MECA ignored any C features they felt cause too many
false positives, and consequently MECA is unsound:
it makes no attempt to deal with pointer aliasing, and
completely ignores multiply-indirected pointers. MECA
uses many advanced program analysis features, such as
ﬂow-sensitivity and a limited form of predicated types.
MECA can also be used for other kinds of security anal-
yses and is not restricted to user/kernel bugs. This re-
sults in a great bug-ﬁnding tool, but MECA can not be
relied upon to ﬁnd all bugs.
In comparison, CQUAL
uses principled, semantic-based analysis techniques that
are sound and that may prove a ﬁrst step towards formal
veriﬁcation of the entire kernel, though CQUAL’s false
alarm rate is noticeably higher.
CQUAL only considers the data-ﬂow in the program
being analyzed, completely ignoring the control-ﬂow
aspects of the program. There are many other tools
that are good at analyzing control-ﬂow, but because
the user/kernel property is primarily about data-ﬂow,
control-ﬂow oriented tools are not a good match for
ﬁnding user/kernel bugs. For instance, model checkers
like MOPS[3], SLAM[1], and BLAST[8] look primar-
ily at the control-ﬂow structure of the program being
analyzed and thus are excellent tools for verifying that
security critical operations are performed in the right or-
der, but they are incapable of reasoning about data val-
ues in the program. Conversely, it would be impossible
to check ordering properties with CQUAL. Thus tools
like CQUAL and MOPS complement each other.
There are several other ad-hoc bug-ﬁnding tools that use
simple lexical and/or local analysis techniques. Exam-
ples include RATS[9], ITS4[13], and LCLint[5]. These
tools are unsound, since they don’t deal with pointer
aliasing or any other deep structure of the program.
Also, they tend to produce many false positives, since
they don’t support polymorphism, ﬂow-sensitivity, or
other advanced program analysis features.
8 Conclusion
We have shown that type qualiﬁer inference is an effec-
tive technique for ﬁnding user/kernel bugs, but it has the
potential to do much more. Because type qualiﬁer in-
ference is sound, it may lead to techniques for formally
verifying the security properties of security critical soft-
ware. We have also described several reﬁnements to the
basic type inference methodology. These reﬁnements
dramatically reduce the number of false positives gen-
erated by our type inference engine, CQUAL, enabling
it to analyze complex software systems like the Linux
kernel. We have also described a heuristic that improves
error reports from CQUAL. All of our enhancements
can be applied to other data-ﬂow oriented program anal-
ysis tools. We have shown that formal software analysis
methods can scale to large software systems. Finally, we
have analyzed the false positives generated by CQUAL
and developed simple rules programmers can follow to
write veriﬁable code. These rules also apply to other
program analysis tools.
Our research suggests many directions for future re-
search.
First, our false positive analysis highlights
several shortcomings in current program analysis tech-
niques. Advances in structure-handling would have a
dramatic effect on the usability of current program anal-
ysis tools, and could enable the development of veri-
ﬁed security software. Several of the classes of false
positives derive from the ﬂow-insensitive analysis we
use. Adding ﬂow-sensitivity may further reduce the
false-positive rate, although no theory of simultaneously
ﬂow-, ﬁeld- and context-sensitive type qualiﬁers cur-
rently exists. Alternatively, researchers could investigate
alternative programming idioms that enable program-
mers to write clear code that is easy to verify correct.
Currently, annotating the source code requires domain-
speciﬁc knowledge, so some annotations may acciden-
tally be omitted. Methods for checking or automatically
deriving annotations could improve analysis results.
Our results on Linux 2.4.20 and 2.4.23 suggest that
widely deployed, mature systems may have even more
latent security holes than previously believed. With
sound tools like CQUAL, researchers have a tool to mea-
sure the number of bugs in software. Statistics on bug
counts in different software projects could identify de-
velopment habits that produce exceptionally buggy or
exceptionally secure software, and could help users eval-
uate the risks of deploying software.
Availability
The extended version of this paper is available from
http://www.cs.berkeley.edu/~rtjohnso/.
CQUAL is open source software hosted on SourceForge,
and is available from
http://www.cs.umd.edu/~jfoster/cqual/.
Acknowledgements
We thank Jeff Foster for creating CQUAL and help-
ing us use and improve it. We thank John Kodumal
for implementing an early version of polymorphism in
CQUAL and for helping us with the theory behind many
of the improvements we made to CQUAL. We thank the
anonyous reviewers for many helpful suggestions.
Notes
1In Linux, the system call foo is implemented in the kernel by a
function sys foo.
2In C, the nonconst qualiﬁer is an implicit default.
3This is standard deductive inference notation. The notation
A1 A2
· · · An
B
means that, if A1, A2, . . . An are all true, then B is true.
4Although it’s not important for this discussion, the deﬁnition of a
valid path is given in the extended version of this paper.
5This is a corollary of Rice’s Theorem.
6The variables can share the same stack slot.
References
[1] Thomas Ball and Sriram K. Rajamani. The SLAM
Project: Debugging System Software via Static
Analysis.
In Proceedings of the 29th Annual
ACM SIGPLAN-SIGACT Symposium on Principles
of Programming Languages, pages 1–3, Portland,
Oregon, January 2002.
[2] Pete Broadwell, Matt Harren, and Naveen Sastry.
Scrash: A System for Generating Secure Crash In-
formation. In Proceedings of the 12th Usenix Se-
curity Symposium, Washington, DC, August 2003.
[3] Hao Chen and David Wagner. MOPS: an infras-
tructure for examining security properties of soft-
ware.
In Proceedings of the 9th ACM Confer-
ence on Computer and Communications Security,
pages 235–244, Washington, DC, November 18–
22, 2002.
[4] Martin Elsman, Jeffrey S. Foster, and Alexander
Aiken. Carillon—A System to Find Y2K Prob-
lems in C Programs, 1999. http://bane.cs.
berkeley.edu/carillon.
[5] David Evans.
LCLint User’s Guide, February
1996.
[6] Jeff Foster, Rob Johnson, John Kodumal, and Alex
Aiken. Flow-Insensitive Type Qualiﬁers. ACM
Transactions on Programming Languages and Sys-
tems. Submitted for publication.
[7] Jeffrey Scott Foster. Type Qualiﬁers: Lightweight
Speciﬁcations to Improve Software Quality. PhD
thesis, University of California, Berkeley, Decem-
ber 2002.
[8] Thomas A. Henzinger, Ranjit Jhala, Rupak Ma-
jumdar, and Gregoire Sutre. Lazy abstraction. In
Symposium on Principles of Programming Lan-
guages, pages 58–70, 2002.
[9] Secure Software Inc.
RATS download page.
http://www.securesw.com/auditing_
tools_download.htm.
[10] George Necula, Scott McPeak, and Westley
CCured: Type-Safe Retroﬁtting of
Weimer.
Legacy Code. In Proceedings of the 29th Annual
ACM SIGPLAN-SIGACT Symposium on Principles
of Programming Languages, pages 128–139, Port-
land, Oregon, January 2002.
[11] Umesh Shankar, Kunal Talwar, Jeffrey S. Foster,
and David Wagner. Detecting Format String Vul-
nerabilities with Type Qualiﬁers. In Proceedings of
the 10th Usenix Security Symposium, Washington,
D.C., August 2001.
[12] Linus Torvalds. Managing kernel development,
November 2003. http://www.linuxjournal.
com/article.php?sid=7272.
[13] John Viega, J.T. Bloch, Tadayoshi Kohno, and
Gary McGraw. ITS4: A Static Vulnerability Scan-
ner for C and C++ Code.
In 16th Annual Com-
puter Security Applications Conference, December
2000. http://www.acsac.org.
[14] David Wagner, Jeffrey S. Foster, Eric A. Brewer,
and Alexander Aiken. A First Step Towards Au-
tomated Detection of Buffer Overrun Vulnerabil-
ities.
In Networking and Distributed System Se-
curity Symposium 2000, San Diego, California,
February 2000.
[15] Junfeng Yang, Ted Kremenek, Yichen Xie, and
Dawson Engler. MECA: an extensible, expressive
system and language for statically checking secu-
rity properties.
In Proceedings of the 10th ACM
conference on Computer and communication secu-
rity, pages 321–334. ACM Press, 2003.
[16] Xiaolan Zhang, Antony Edwards, and Trent Jaeger.
Using CQUAL for Static Analysis of Authoriza-
tion Hook Placement. In Proceedings of the 11th
Usenix Security Symposium, San Francisco, CA,
August 2002.