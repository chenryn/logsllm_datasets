2.6%
41.3%
31.0%
27.7%
20.9%
34.7%
26.0%
18.4%
47.6%
52.4%
67.0%
12.0%
5.0%
13.1%
2.9%
18.5%
40.0%
41.6%
23.7%
38.8%
23.5%
14.1%
Figure 2: Problem severity, organized by targeting mech-
anism (Pilot 1).
Table 3: Respondent demographics, Pilot 1, compared to
2015 U.S. Census ﬁgures [41]
Figure 3: Problem severity, organized by human or algo-
rithmic decision (Pilot 1).
ing the severity of the various scenarios. The most no-
ticeable pattern was that scenarios that targeted based on
behavior (e.g., browsing history), rather than explicit de-
mographics, were generally rated less problematic (see
Figure 2).
Third, we had hypothesized that whether a human or an
algorithm made the decision to target the advertisement
would play an important role in respondents’ perceptions
of the scenario. We were surprised that we did not ﬁnd
evidence for this in the pilot, but we decided to include it
in our subsequent studies in hopes of conﬁrming (or not)
its lack of importance (see Figure 3).
5 Main Study
Based on the results from Pilot 1, we designed our ﬁnal
survey. Below, we detail the content of this ﬁnal sur-
vey and the results of our generation and validation of
regression models for analysis of this data.
5.1 Final Survey Instrument
Our ﬁnal survey contrasted demographic and behavioral
explanations, as well as human and algorithmic decisions.
Because there is confusion about which entity in the com-
plex advertising ecosystem makes decisions that can have
discriminatory outcomes, and because we were explicitly
interested in asking questions about responsibility, we
included a factor locating the decision-making either at
Systemy (the company placing the ad) or Bezo (the ad
network). We did not include the local news site as a po-
tential decision-maker because it did not seem to provide
particularly interesting results in Pilot 1. As discussed in
Figure 1: Problem severity, organized by target (Pilot 1).
One key goal was to develop a smaller set of issues to
focus on in the follow-up studies.
First, we considered the issue of who was targeted in
the scenario, that is, which group of people beneﬁted from
or was shortchanged by the discriminatory advertising.
We found that the scenarios that targeted race were more
likely to be considered problematic than the other targets
that we considered: age, political aﬃliation, and health
condition (see Figure 1). Opinions about which groups
are targeted touch on a range of cultural and sociological
issues that are not likely to be unique to online targeted
advertising; as such, these opinions were not of primary
interest to our research question, which mainly concerns
how diﬀerent explanations for discriminatory outcomes
aﬀect people’s attitudes. Therefore, we decided to limit
future scenarios to targeting race, in the interest of pro-
voking more dramatic reactions that might allow us to
identify interesting explanation-based diﬀerences.
Second, we considered respondents’ responses regard-
USENIX Association
26th USENIX Security Symposium    939
Target Mechanism
White
Asian
Black
Behavior
Demographics Algorithm Ad Network
Decider
Human
Entity
Advertiser
Table 4: Variables included in the scenarios for the ﬁnal
survey instrument.
Section 4, we limited the targeted groups to only consider
race.
The ﬁnal set of 24 scenarios (demographic vs. behav-
ioral × human vs. algorithmic × two entities × three target
groups) is detailed in Table 4.
The text of the scenario shown to the respondents was:
Systemy is a local technology ﬁrm that devel-
ops software. They are expanding and want to
hire new employees. Systemy contracts with
Bezo Media, an online advertising network,
which places Systemy’s job ad on a local news
website. [explanation]. As a result, the ad is
shown more frequently to [target] individuals
than [opposite of target] individuals.
The explanations shown to the respondents can be found
in Table 5.
Because the scenario wording remained very close to
the wording as used in Pilot 1, we did no further cognitive
interviews.
5.2 Pilot 2: Training Data Generation
Before running the ﬁnal collection of data with this sur-
vey, we conducted one additional pilot survey. This pilot
generated training data that we used to test a variety of
potential regression models without worrying about ero-
sion of statistical conﬁdence due to multiple testing. Such
testing allowed us to narrow down the breadth of potential
covariates to only the most relevant.
5.2.1 Respondents
As the goal of Pilot 2 was to create training data for se-
lecting a ﬁnal set of regression models to be conﬁrmed
with a larger data collection, we considered it suﬃcient to
collect a smaller, less diverse—and also less expensive—
sample. We deployed our four- to ﬁve-minute survey to
191 respondents using Amazon’s Mechanical Turk crowd-
sourcing service (MTurk).1 MTurk has been shown to
provide adequate data quality, but also to be younger and
more educated than the general population [24, 26]. We
required respondents to have an approval rate of at least
85% on the MTurk service and reside in the U.S., and
1https://www.mturk.com
Metric
Male
Female
Caucasian
Hispanic
Asian
African American
Other
Up to H.S.
Some college
B.S. or above
18–29 years
30–49 years
50–64 years
65+ years
MTurk Census
48.2%
48.2%
51.8%
51.8%
64.0%
81.2%
4.7%
16.0%
5.4%
4.7%
12.0%
7.3%
2.6%
2.1%
13.6%
41.3%
31.0%
32.5%
27.7%
53.9%
20.9%
26.6%
53.1%
34.7%
26.0%
16.7%
3.6%
18.4%
Table 6: Respondent demographics for Pilot 2, compared
to ﬁgures from the 2015 U.S. Census [41].
we compensated them $0.75 each. To avoid duplicate re-
spondents, each participant’s unique MTurk identiﬁcation
number was recorded and duplicate IDs were prevented
from completing the survey again. Detailed demographics
can be found in Table 6.
5.2.2 Analysis and Results
Because the majority of our survey questions were Likert
scales, we primarily analyze our data using logistic regres-
sion, which measures how several diﬀerent input factors
correlate with a step increase in the output Likert vari-
able being studied [23]. This allows us to examine how
both our experimental factors and demographic covari-
ates correlate with respondents’ reactions to the presented
scenario.
For the degree of responsibility and problem questions,
we generated an initial model including the experimental
factors (the target, mechanism, decider, and entity vari-
ables from Table 4); participant demographic covariates
including age, gender, ethnicity, and education level; and
pairwise interactions between various factors. We then
compared a variety of models using subsets of these co-
variates, looking for the best ﬁt according to the lowest
Akaike Information Criterion (AIC) [4]. (We included the
experimental factors in every model we considered.)
For each question, multiple models were very close in
AIC value. From among those with near-minimal AIC for
each of the ﬁve questions, we selected a ﬁnal model that
included the four experimental factors—target, mecha-
nism, decider, and entity—along with the demographic
covariates that appeared most relevant. No pairwise inter-
actions were included in the ﬁnal model. The ﬁnal set of
factors and covariates is summarized in Table 7. For each
940    26th USENIX Security Symposium
USENIX Association
Targets:
Explanations:
• Are/be white
• Are/be Asian
• Are/be black
• An employee at Systemy places an order with Bezo Media to show the ad more often to people who have recently visited
technology-interest websites. The employee predicts, based on prior experience, that people who recently visited a technology-
interest website will be more likely to read and click on the ad. Individuals who are [target] tend to visit more technology-
interest websites than individuals of other races.
• Systemy uses an algorithm to decide how to place its ads. The algorithm places an order with Bezo Media to show the ad more
often to people who have recently visited technology-interest websites. The algorithm predicts, based on prior data, that people
who have recently visited a technology-interest website will be more likely to read and click on the ad. Individuals who are
[target] tend to visit more technology-interest websites than individuals of other races.
• Systemy uses an algorithm to decide how to place its ads. The algorithm places an order with Bezo Media to show the ad more
often to people who are [target] than individuals of other races. The algorithm predicts, based on prior data, that [target]
people will be more likely to read and click on the ad.
• An employee at Systemy places an order with Bezo Media to show the ad more often to people who are [target] than individuals
of other races. The employee predicts, based on prior experience, that [target] people will be more likely to read and click on
the ad.
• Bezo Media uses an algorithm to decide when to show which ads. The algorithm shows the ad more often to people who have
recently visited technology-interest websites. The algorithm predicts, based on prior data, that people who had recently visited
a technology-interest website will be more likely to read and click on the ad. Individuals who are [target] tend to visit more
technology-interest websites than individuals of other races.
• An employee at Bezo Media decides to show the ad more often to people who have recently visited technology-interest websites.
The employee predicts, based on prior experience, that people who recently visited a technology-interest website will be more
likely to read and click on the ad. Individuals who are [target] tend to visit more technology-interest websites than individuals
of other races.
• An employee at Bezo Media decides to show the ad more often to people who are [target] than individuals of other races. The
employee predicts, based on prior experience, that [target] people will be more likely to read and click on the ad.
• Bezo Media uses an algorithm to decide when to show which ads. The algorithm shows the ad more often to people who are
[target] than individuals of other races. The algorithm predicts, based on prior data, that [target] people will be more likely to
read and click on the ad.
Table 5: Scenarios in the ﬁnal survey instrument. Each participant viewed one explanation, with one targeted group
ﬁlled in as receiving more of the targeted ads.
question, we excluded respondents who gave “don’t know”
responses to that question from the associated regression
analysis.
5.3 Final Survey Results
To validate the regression model developed during Pilot 2,
we conducted a ﬁnal, larger-scale data collection with our
ﬁnal survey instrument. To promote both high data quality
and broad generalizability in our results, with reasonable
cost, we deployed our survey with both MTurk and SSI.
We again required Turkers to have 85% approval and
compensated them $0.75; we again paid SSI $3.00 per
completion. Respondents from both the ﬁrst and second
pilot study were excluded from participation in this survey.
To account for diﬀerences in the two samples, we added
sample provider as a covariate to our regression model
(shown at the bottom of Table 7).
Table 8 summarizes the results.
5.3.1 Respondents
We collected responses from 535 MTurk respondents and
372 SSI respondents, for a total of 907. Demographics for
the two samples are shown in Table 9, with U.S. Census
data for comparison [41].
The 16 respondents who reported their race as “other”
were excluded from the dataset, because the small sample
frequently prevented the regression model from converg-
ing. All further results are therefore reported for the
remaining 891 respondents, or for slightly fewer when
respondents answered “don’t know” to certain questions.
USENIX Association
26th USENIX Security Symposium    941
Factor
Target
Mechanism
Decider
Entity
Age
Education
Description
The ethnicity receiving more ads in the scenario. White, Asian, or Black.
Decision made based on either the demographics or the behavior of the targeted group.
Whether the targeting decision was made by an algorithm or a human.
Entity making the decision: Either the ad network or the advertiser.
Of respondent. Continuous.
Of respondent. High school diploma or less, Some college (HS+), Bachelor’s Degree and
up (BS+)
Of respondent. White, Black, Hispanic or Latino, Asian, or Other
Ethnicity
Sample Provider Amazon’s Mechanical Turk and SSI
Baseline
White
Demographics
Algorithm
Ad network
n/a
High school or less
White
MTurk
Table 7: Factors used in the regression models for problem, responsibility, ethics, and believability. The sample provider
factor was used in the main study only, not in Pilot 2.
Factor
T-Asian
T-Black
Behavior
Human
Advertiser
Age of respondent
HS+
BS+
R/E-Asian
R/E-Black
R/E-Hisp. or Lat.
SSI
Ad network
Advertiser
News site
End user
Severity Respons. Ethical Respons. Ethical Respons. Ethical Respons. Ethical
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
Table 8: Summary of regression results.
behavior, compared to baseline, as appropriate.
T- indicates the race of the targeted group, while R/E indicates the race or ethnicity of the respondent.
indicates a signiﬁcant increase in severity, in responsibility, or in unethical
indicates a signiﬁcant decrease, and – indicates no signiﬁcant eﬀect.
5.3.2 Model Validation
5.3.3 Severity of Problem
To verify that the set of factors and covariates we selected
in Pilot 2 were also reasonable for our ﬁnal data, we ver-
iﬁed that the error rate when applying this regression to
the ﬁnal dataset was within the conﬁdence interval of the
error rate observed on our training data (e.g. the Pilot 2
data). More speciﬁcally, we bootstrapped [15] root mean
square error (RMSE) [31] conﬁdence intervals from the