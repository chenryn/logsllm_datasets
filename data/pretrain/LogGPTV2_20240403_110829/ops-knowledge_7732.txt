User: I'm looking to start using a key/value store for some side projects (mostly as a learning experience), but so many have popped up in the recent past that I've got no idea where to begin.  Just listing from memory, I can think of:

CouchDB
MongoDB
Riak
Redis
Tokyo Cabinet
Berkeley DB
Cassandra
MemcacheDB

And I'm sure that there are more out there that have slipped through my search efforts.  With all the information out there, it's hard to find solid comparisons between all of the competitors.  My criteria and questions are:

(Most Important) Which do you recommend, and why?
Which one is the fastest?
Which one is the most stable?
Which one is the easiest to set up and install?
Which ones have bindings for Python and/or Ruby?

Edit:
So far it looks like Redis is the best solution, but that's only because I've gotten one solid response (from ardsrk).  I'm looking for more answers like his, because they point me in the direction of useful, quantitative information.  Which Key-Value store do you use, and why?
Edit 2:
If anyone has experience with CouchDB, Riak, or MongoDB, I'd love to hear your experiences with them (and even more so if you can offer a comparative analysis of several of them)
Assistant: As the others said, it depends always on your needs. I for example prefer whatever suits my applications best.
I first used memcached to have fast read/write access. As Java API IÂ´ve used SpyMemcached, what comes with an very easy interface you can use for writing and reading data. Due to memory leaks (no more RAM) I was required to look for another solution, also I was not able scale right, just increase the memory for a single process seemed to be not an good achievement. 
After some reviewing I saw couchbase, it comes with replication, clustering, auto-failover, and a community edition (MS Windows, MacOs, Linux). And the best thing for me was, the Java client of it implements also SpyMemcached, so I had almost nothing else to do as setup the server and use couchbase instead of memcached as datastore. Advantage? Sure, my data is now persistent, replicated, and indexed. It comes with a webconsole to write map reduce functions for document views in erlang. 
It has Support for Python, Ruby, .Net and more, easy configuration through the webconsole and client-tools. It runs stable. With some tests I was able to write about 10k per second for 200 - 400 byte long records. Reading Performance was way higher though (both tested locally). Have a lot of fun making your decision.