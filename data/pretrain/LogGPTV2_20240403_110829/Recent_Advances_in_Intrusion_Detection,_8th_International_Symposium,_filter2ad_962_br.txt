3   Payload Based Anomaly Detection 
3.1   Overview of the PAYL Sensor 
The  PAYL  sensor  is  based  on  the  principle  that  zero-day  attacks  are  delivered  in 
packets whose data is unusual and distinct from all prior “normal content” flowing to 
or from the victim site. We assume that the packet content is available to the sensor 
for modeling2. We compute a normal profile of a site’s unique content flow, and use 
this information to detect anomalous data. A “profile” is a model or a set of models 
that represent the set of data seen during training. Since we are profiling content data 
flows, the method must be general to work across all sites and all services, and it must 
be efficient and accurate. Our initial design of PAYL uses a “language independent” 
methodology, the statistical distribution of n-grams [2] extracted from network packet 
datagrams. This methodology requires no parsing, no interpretation and no emulation 
of the content. 
An n-gram is the sequence of n adjacent byte values in a packet payload. A sliding 
window  with  width  n  is  passed  over  the  whole  payload  one  byte  at  a  time  and  the 
frequency of each n-gram is computed. This frequency count distribution represents a 
statistical centroid or model of the content flow. The normalized average frequency and 
the  variance of each gram  are computed. The first implementation of PAYL  uses  the 
byte  value  distribution  when  n=1.  The  statistical  means  and  variances  of  the  
1-grams are stored in two 256-element vectors. However, we condition a distinct model 
on the port (or service) and on packet length, producing a set of statistical centroids that 
in total provides a fine-grained, compact and effective model of a site’s actual content 
flow. Full details of this method and its effectiveness are described in [20]. 
The first packet of CRII illustrates the 1-gram data representation implemented in 
PAYL.  Figure  1  shows  a  portion  of  the  CRII  packet,  and  its  computed  byte  value 
distribution  along  with  the  rank  ordered  distribution  is  displayed  in  Figure  2,  from 
which  we  extract  a  Z-string.  The  Z-string  is  a  the  string  of  distinct  bytes  whose 
frequency in the data is ordered from most frequent to least, serving as representative  
2  Encrypted  channels  can  be  treated  separately  in  various  ways,  such  as  the  use  of  a  host-
sensor that captures content at the point of decryption, or by using a decryption/re-encryption 
proxy server. For the present paper, we simply assume the data is available for modeling. 
232 
K. Wang, G. Cretu, and S.J. Stolfo 
GET./default.ida?XXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXX
XXXXXXXXXXXXXXXXXXXXXX
XXXXXX%u9090%u6858%ucbd3%u7
801%u9090%u6858%ucbd3%u7801%u
9090%u6858%ucbd3%u7801%u9090%
u9090%u8190%u00c3%u0003%u8b00
%u531b%u53ff%u0078%u0000%u0 
Fig.  1.  A  portion  of  the  first  packet  of 
CodeRed II 
Fig.  2.  CRII  payload  distribution  (top  plot) 
and its rank order distribution (bottom plot) 
of  the  entire  distribution,  ignoring  those  byte  values  that  do  not  appear  in  the  data. 
The rank ordered distribution appears similar to the Zipf distribution, and hence the 
name Z-string. The Z-string representation provides a privacy-preserving summary of 
payload that may be exchanged between domains without revealing the true content. 
Z-strings  are  not  used  for  detection,  but  rather  for  message  exchange  and  cross 
domain correlation of alerts. We describe this further in section 5. 
To  compare  the  similarity  between  test  data  at  detection  time  and  the  trained 
models  computed  during  the  training  period,  PAYL  uses  simplified  Mahalanobis 
distance [20]. Mahalanobis distance weights each variable, the mean frequency of a 
1-gram, by its standard deviation and covariance. The distance values produced by the 
models are then subjected to a threshold test. If the distance of a test datum is greater 
than the threshold, PAYL issues an alert for the packet. There is a distinct threshold 
setting for each centroid computed automatically by PAYL during a calibration step. 
To calibrate the sensor, a sample of test data is measured against the centroids and an 
initial threshold setting is chosen. A subsequent round of testing of new data updates 
the threshold settings to calibrate the sensor to the operating environment. Once this 
step  converges,  PAYL  is  ready  to  enter  detection  mode.  Although  the  very  initial 
results of testing PAYL looked quite promising, we devised several improvements to 
the modeling technique to reduce the percentage of false positives.  
3.2   New PAYL Features: Multiple Centroids 
PAYL  is  a  fully  automatic,  “hands-free”  online  anomaly  detection  sensor.  It  trains 
models  and  determines  when  they  are  stable;  it  is  self-calibrating,  automatically 
observes itself, and updates its models as warranted. The most important new feature 
implemented  in  PAYL  over  our  prior  work  is  the  use  of  multiple  centroids,  and 
ingress/egress correlation. In the first implementation, PAYL computes one centroid 
per length bin, followed by a stage of clustering similar centroids across neighboring 
bins. We previously computed a model Mij for each specific observed packet payload 
ij , k(cid:149)1. 
length i of each port j. In this newer version, we compute a set of models Mk
Hence,  within  each  length  bin,  multiple  models  are  computed  prior  to  a  final 
clustering stage. The clustering is now executed across centroids within a length bin, 
Anomalous Payload-Based Worm Detection and Signature Generation 
233 
and  then  again  across  neighboring  length  bins.  This  two  stage  clustering  strategy 
substantially reduces the memory requirements for models while representing normal 
content flow more accurately and revealing anomalous data with greater clarity. 
Since there might be different types of payload sent to the same service, e.g., pure 
text,  .pdf,  or  .jpg,  we  used  an  incremental  online  clustering  algorithm  to  create 
multiple centroids to model the traffic with finer granularity. This modeling idea can 
be extended to include centroids for different media that may be transmitted in packet 
flows.  Different  file  and  media  types  follow  their  own  characteristic  1-gram 
distribution; including models for standard file types can help reduce false positives. 
(See [8] for a detailed analysis of this approach.)   
The multi-centroid strategy requires a different test  methodology. During testing, 
an  alert  will  be  generated  by  PAYL  if  a  test  packet  matches  none  of  the  centroids 
within  its  length  bin.  The  multi-centroid  technique  produces  more  accurate  payload 
models and separates the anomalous payloads in a more precise manner.  
3.3   Data Diversity Across Sites  
A  crucial  issue  we  study  is  whether  or  not  payload  models  are  truly  distinct  across 
multiple  sites.  This  is  an  important  question  in  a  collaborative  security  context.  We 
have claimed that the monoculture problem applies not only to common services and 
applications, but also  to  security  technologies. Hence,  if  a site  is blind  to  a  zero-day 
attack this implies that many other sites are blind to the same attack. Researchers are 
considering  solutions  to  the  monoculture  problem  by  various  techniques  that 
“diversify” implementations. We conjecture that the content data flow among different 
sites  is  already  diverse  even  when  running  the  exact  same  services.  In  our  previous 
work  we have shown that byte distributions differ for each port and length. We also 
conjecture  that  it  should  be  different  for  each  host.  For  example,  each  web  server 
contains different URLs,  implements  different  functionality  like  web  email or  media 
uploads,  and  the population of  service  requests and  responses  sent  to and  from  each 
site may differ, producing a diverse set of content profiles across all collaborating hosts 
and  sites.  Hence,  each  host  or  site’s  profile  will  be  substantially  different  from  all 
others. A zero-day attack that may appear as normal data at one site, will likely not 
appear  as  normal  data  at  other  sites  since  the  normal  profiles  are  different.  We  test 
whether or not this conjecture is true by several experiments.  
One of the most difficult aspects of doing research in this area is the lack of real-
world  datasets  available  to  researchers  that  have  full  packet  content  for  formal 
scientific  study3.  Privacy  policies  typically  prevent  sites  from  sharing  their  content 
data. However, we were able to use data from three sources, and show the distribution 
for each. The first one is an external commercial organization that wishes to remain 
anonymous,  which  we  call  EX.  The  others  are  the  two  web  servers  of  the  CS 
Department of Columbia, www.cs.columbia.edu and www1.cs.columbia.edu; we call 
these two datasets W and W1, respectively. The following plots show the profiles of 
the traffic content flow of each site. 
3  Fortunately,  HS  ARPA  is  working  to  provide  data  to  researchers  through  the  PREDICT 
project; see www.predict.org.  
234 
K. Wang, G. Cretu, and S.J. Stolfo 
Fig. 3. Example byte distribution for payload 
length 249 of port 80 for the three sites EX, 
W, W1, in order from top to bottom  
Fig. 4. Example byte distribution for payload 
length  of  1380  of  port  80  for  the  three  sites 
EX, W, W1 
The plots display the payload distributions for different packet payload lengths i.e. 
249  bytes  and  1380  bytes,  spanning  the  whole  range  of  possible  payload  lengths  in 
order to give a general view of the diversity of the data coming from the three sites. 
Each byte distribution corresponds to the first centroid that is built for the respective 
payload lengths. We observe from the above plots that there is a visible difference in 
the byte distributions among the sites for the same length bin. This is confirmed by 
the  values  of  Manhattan  distances  computed  between  the  distributions,  with  results 
displayed in Table 1. 
Table  1. The Manhattan distance between the byte distributions of the profiles computed for 
the three sites, for three length bins  
MD(EX, W) 
MD(EX,W1) 
MD(W,W1) 
249 bytes 
940 bytes 
1380 bytes 
0.4841 
0.3710 
0.3689 
0.6723 
0.8120 
0.5972 
0.2533 
0.4962 
0.6116 
The content traffic among the sites is quite different. For example, the EX dataset 
is more complex containing file uploads of different media types (pdf, jpg, ppt, etc. ) 
and webmail traffic; the W dataset contain less of this type of traffic while W1 is the 
simplest, containing almost no file uploads. Hence, each of the  site-specific payload 
models is diverse, increasing the likelihood that a worm payload will be detected by at 
least one of these sites. To avoid detection, the worm exploit would have to be padded 
in such a way that its content description would appear to be normal concurrently for 
all of these sites.  
Mimicry attacks are possible if the attacker has access to the same information as 
the victim. In the case of application payloads, attackers (including worms) would not 
know the distribution of the normal flow to their intended victim. The attacker would 
need to sniff each  site  for a long period of time and analyze the traffic in the same 
fashion as the detector described herein, and would also then need to figure out how 
Anomalous Payload-Based Worm Detection and Signature Generation 
235 
to pad their poison payload to mimic the normal model. This is a daunting task for the 
attacker who would have to be clever indeed to guess the exact distribution as well as 
the threshold logic to deliver attack data that would go unnoticed. Additionally, any 
attempt to do this via probing, crawling or other means is very likely to be detected.  
Besides  mimicry  attack,  clever  worm  writers  may  figure  a  way  to  launch  'training 
attacks' [6] against anomaly detectors such as PAYL. In this case, the worm may send a 
stream of content  with increasing diversity to  its next victim  site  in order to train the 
content sensor to produce models where its exploit no longer would appear anomalous. 
This as well is a daunting task for the worm. The worm would be fortunate indeed to 
launch  its  training  attack  when  the  sensor  is  in  training  mode  and  that  a  stream  of 
diverse data would go unnoticed while the sensor is in detection mode. Furthermore, the 
worm would have to be extremely lucky that each of the content examples it sends to 
train the sensor would produce a "non-error" response from the intended victim. Indeed, 
PAYL  ignores  content  that  does  not  produce  a  normal  service  response.  These  two 
evasion  techniques,  mimicry  and  training  attack,  is  part  of  our  ongoing  research  on 
anomaly detection, and a formal treatment of the range of "counter-evasion" strategies 
we are developing is beyond the scope of this paper. 
3.4   Worm Detection Evaluation 
In  this  section,  we  provide  experimental  evidence  of  the  effectiveness  of  PAYL  to 
detect  incoming  worms.  In  our  previous  RAID  paper  [20],  we  showed  PAYL’s 
accuracy  for  the  DARPA99  dataset,  which  contains  a  lot  of  artifacts  that  make  the 
data  too  regular  [9].  Here  we  report  how  PAYL  performs  over  the  three  real-world 
datasets using known worms available for our research. Since all three datasets were 
captured from real traffic, there is no ground truth, and measuring accuracy was not 
immediately  possible.  We  thus  needed  to  create  test  sets  with  ground  truth,  and  we 
applied Snort for this purpose.  
Each dataset  was split  into two distinct chronologically-ordered portions, one for 
training and the other for testing, following the 80%-20% rule. For each test dataset,  
Fig. 5. ROC of PAYL detecting incoming worms, false positive rate restricted to less than 0.5% 
236 
K. Wang, G. Cretu, and S.J. Stolfo 
we first created a clean set of packets free of any known worms still flowing on the 
Internet as background radiation. We then inserted the same set of worm traffic into 
the cleaned test set using tcpslice. Thus, we created ground truth in order to compute 
the accuracy and false positive rates. 
The worm set includes CodeRed, CodeRed II, WebDAV, and a worm that exploits 
the IIS Windows media service, the nsiislog.dll buffer overflow vulnerability (MS03-
022).  These  worm  samples  were  collected  from  real  traffic  as  they  appeared  in  the 
wild,  from  both  our  own  dataset  and  from  a  third-party.  Because  PAYL  only 
considers  the  packet  payload,  the  worm  set  is  inserted  at  random  places  in  the  test 
data.  The  ROC  plots  in  Figure  5  show  the  result  of  the  detection  rate  versus  false 
positive rate over varying threshold settings of the PAYL sensor.   
The detection rate and false positive are both based on the number of packets. The 
test set contains 40 worm packets although there are only 4 actual worms in our zoo. 
The plots show the results for each data set, where each graphed line is the detection 
rate  of  the  sensor  where  all  4  worms  were  detected.  (This means  more  than  half  of 
each the worm’s packets were detected as anomalous content.) From the plot we can 
see that although the three sites are quite different in payload distribution, PAYL can 
successfully  detect  all  the  worms  at  a  very  low  false  positive  rate.  To  provide  a 
concrete example we measured the average false alerts per hour for these three sites. 
For 0.1% false positive rate, the EX dataset has 5.8 alerts per hour, W1 has 6 alerts 
per hour and W has 8 alerts per hour. 
We manually checked the packets that were deemed false positives. Indeed, most 
of  these  are  actually  quite  anomalous  containing  very  odd  abnormal  payload.  For 
example, in the EX dataset, there are weird file uploads, in one case a whole packet 
containing nothing but a repetition of a character with byte value E7 as part of a word 
file.  Other  packets  included  unusual  HTTP  Get  requests,  with  the  referrer  field 
padded with many “Y” characters (via a product providing anonymization).  
We note that some worms might fragment their content into a series of tiny packets 
to  evade  detection.  For  this  problem,  PAYL  buffers  and  concatenates  very  small 
packets of a session prior to testing. 
We  also  tested  the  detection  rate  of  the  W32.Blaster  worm  (MS03-026)  on  TCP 
port 135 port using real RPC traffic inside Columbia’s CS department. Despite being 
much  more  regular  compared  to  HTTP  traffic,  the  worm  packets  in  each  case  were 
easily detected  with zero false positives. Although at first  blush, 5-8 alerts per hour 
may seem too high, a key contribution of this paper is a method to correlate multiple 
alerts to extract from the stream of alerts true worm events. 
4   Worm Propagation Detection and Signature Generation by 
Correlation 
In  the  previous  section,  we  described  the  results  using  PAYL  to  detect  anomalous 
packet  content.  We  extended  the  detection  strategy  to  model  both  inbound  and 
outbound traffic from a protected host, computing models of content flows for ingress 
and  egress  packets.  The  strategy  thus  implies  that  within  a  protected  LAN,  some 
infected internal host will begin a propagation sending outbound anomalous packets. 
Anomalous Payload-Based Worm Detection and Signature Generation 
237 
When  this  occurs  for  any  host  in  the  LAN,  we  wish  to  inoculate  all  other  hosts  by 
generating and distributing worm packet signatures to other hosts for content filtering. 
We  leverage  the  fact  that  self-propagating  worms  will  start  attacking  other 
machines  automatically  by  replicating  itself,  or  at  least  the  exploit  portion  of  its 
content, shortly after a host is infected. (Polymorphic worms may randomly pad their 
content,  but  the  exploit  should  remain  intact.)  Thus  if  we  detect  these  anomalous 
egress  packets  to  port  i  that  are  very  similar  to  those  anomalous  ingress  traffic  to  
port  i,  there  is  a  high  probability  that  a  worm  that  exploits  the  service  at  port  i  has 
started its propagation.  Note that these are the very first packets of the propagation, 
unlike  the  other  approaches  which  have  to  wait  until  the  host  has  already  shown 
substantial amounts of unusual scanning and probing behavior. Thus, the worm may 
be stopped at its very first propagation attempt from the first victim even if the worm 
attempts to be slow and stealthy to avoid detection by probe detectors. We describe 
the  ingress/egress  correlation  strategy  in  the  following  section.  We  note,  however, 
that  the  same  strategy  can  be  applied  to  ingress  packets  flowing  from  arbitrary 
(external)  sources  to  internal  target  IP's.  Hence,  ingress/ingress  anomalous  packet 
correlation may be viewed as a special case of this strategy. 
Careful treatment of port-forwarding protocols and services, such as P2P and NTP 
(Port  123)  is  required  to  apply  this  correlation  strategy,  otherwise  normal  port 
forwarding  may  be  misinterpreted  as  worm  propagations.  Our  work  in  this  area 
involves two strategies, truncation of packets (focusing on control data) and modeling 
of the content of media [8]. This work is beyond the scope of this paper due to space 
limitations, and will be addressed in a future paper.  
4.1   Ingress and Egress Traffic Correlation 
When PAYL detects some incoming anomalous traffic to port i, it generates an alert 
and places the packet content on a buffer list of “suspects”. Any outbound traffic to 
port  i  that  is  deemed  anomalous  is  compared  to  the  buffer.  The  comparison  is 
performed against the packet contents and a string similarity score is computed. If the 
score is higher than some threshold, we treat this as possible worm propagation and 
block or delay this outgoing traffic. This is different from the common quarantining 
or  containment  approaches  which  block  all  the  traffic  to  or  from  some  machine. 
PAYL  will  only  block  traffic  whose  content  is  deemed  very  suspicious,  while  all 
other traffic may proceed unabated maintaining critical services.  
There are many possible  metrics  which can apply to decide the similarity of two 
strings. The several approaches we have considered, tested and evaluated include: 
String  equality  (SE):  This  is  the  most  intuitive  approach.  We  decide  that  a 
propagation has started only if the egress payload is exactly the same as the ingress 
suspect packet. This metric is very strict and good at reducing false positives, but too 
sensitive to any tiny change in the packet payload. If the worm changes a single byte 
or just changes its packet fragmentation, the anomalous packet correlation will miss 
the propagation attempt. (The same is true when comparing thumbprints of content.) 
Longest  common  substring  (LCS):  The  next  metric  we  considered  is  the  LCS 
approach. LCS is less exact than SE, but avoids the fragmentation problem and other 
small  payload  manipulations.  The  longer  the  LCS  that  is  computed  between  two 
238 
K. Wang, G. Cretu, and S.J. Stolfo 
packets, the greater the confidence that the suspect anomalous ingress/egress packets 
are more similar. The main shortcoming of this approach is its computation overhead 
compared to string equality, although it can also be implemented in linear time [3]. 
Longest  common  subsequence  (LCSeq):  This  is  similar  to  LCS,  but  the  longest 
common subsequence need not be contiguous. LCSeq has the advantage of being able 
to detect polymorphic worms, but it may introduce more false positives. 
For  each  pair  of  strings  that  are  compared,  we  compute  a  similarity  score,  the 
higher the score, the more similar the strings are to each other. For SE, the score is  
0 or 1, where 1 means equality. For both LCS and LCSeq, we use the percentage of 
the  LCS  or  LCSeq  length  out  of  the  total  length  of  the  candidate  strings.  Let’s  say 
string s1 has length L1, and string s2 has length L2, and their LCS/LCSeq has length C. 
We compute the similarity  score as 2*C/( L1+  L2). This normalizes the score in the 
range of [0…1], where 1 means the strings are exactly equal. We show how well each 
of these measures work in Section 4.3. 