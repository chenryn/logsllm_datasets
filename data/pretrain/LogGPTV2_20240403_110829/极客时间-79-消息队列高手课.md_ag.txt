## RocketMQ 中的分布式事务实现在 RocketMQ中的事务实现中，增加了事务反查的机制来解决事务消息提交失败的问题。如果Producer 也就是订单系统，在提交或者回滚事务消息时发生网络异常，RocketMQ的 Broker 没有收到提交或者回滚的请求，Broker 会定期去 Producer上反查这个事务对应的本地事务的状态，然后根据反查结果决定提交或者回滚这个事务。为了支撑这个事务反查机制，我们的业务代码需要实现一个反查本地事务状态的接口，告知RocketMQ 本地事务是成功还是失败。在我们这个例子中，反查本地事务的逻辑也很简单，我们只要根据消息中的订单ID，在订单库中查询这个订单是否存在即可，如果订单存在则返回成功，否则返回失败。RocketMQ会自动根据事务反查的结果提交或者回滚事务消息。这个反查本地事务的实现，并不依赖消息的发送方，也就是订单服务的某个实例节点上的任何数据。这种情况下，即使是发送事务消息的那个订单服务节点宕机了，RocketMQ依然可以通过其他订单服务的节点来执行反查，确保事务的完整性。综合上面讲的通用事务消息的实现和 RocketMQ 的事务反查机制，使用 RocketMQ事务消息功能实现分布式事务的流程如下图：![](Images/03970b743c0f4625676095e4a5f58b29.png){savepage-src="https://static001.geekbang.org/resource/image/11/7a/11ea249b164b893fb9c36e86ae32577a.jpg"}
## 小结我们通过一个订单购物车的例子，学习了事务的 ACID四个特性，以及如何使用消息队列来实现分布式事务。然后我们给出了现有的几种分布式事务的解决方案，包括事务消息，但是这几种方案都不能解决分布式系统中的所有问题，每一种方案都有局限性和特定的适用场景。最后，我们一起学习了 RocketMQ的事务反查机制，这种机制通过定期反查事务状态，来补偿提交事务消息可能出现的通信失败。在Kafka 的事务功能中，并没有类似的反查机制，需要用户自行去解决这个问题。但是，这不代表 RocketMQ 的事务功能比 Kafka更好，只能说在我们这个例子的场景下，更适合使用 RocketMQ。Kafka对于事务的定义、实现和适用场景，和 RocketMQ有比较大的差异，后面的课程中，我们会专门讲到 Kafka 的事务的实现原理。
## 思考题课后，我建议你最好能通过写代码的方式，把我们这节课中的订单购物车的例子，用RocketMQ 完整地实现出来。然后再思考一下，RocketMQ的这种事务消息是不是完整地实现了事务的 ACID四个特性？如果不是，哪些特性没有实现？欢迎在留言区与我分享讨论。感谢阅读，如果你觉得这篇文章对你有一些启发，也欢迎把它分享给你的朋友。![](Images/4daea3d1a08e48460d8df87c2a766cef.png){savepage-src="https://static001.geekbang.org/resource/image/de/23/de0a489e6b4fa9a49450bf9197593423.jpg"}
# 05 \| 如何确保消息不会丢失?你好，我是李玥。这节课我们来聊聊丢消息的事儿。对于刚刚接触消息队列的同学，最常遇到的问题，也是最头痛的问题就是丢消息了。对于大部分业务系统来说，丢消息意味着数据丢失，是完全无法接受的。其实，现在主流的消息队列产品都提供了非常完善的消息可靠性保证机制，完全可以做到在消息传递过程中，即使发生网络中断或者硬件故障，也能确保消息的可靠传递，不丢消息。绝大部分丢消息的原因都是由于开发者不熟悉消息队列，没有正确使用和配置消息队列导致的。虽然不同的消息队列提供的API不一样，相关的配置项也不同，但是在保证消息可靠传递这块儿，它们的实现原理是一样的。这节课我们就来讲一下，消息队列是怎么保证消息可靠传递的，这里面的实现原理是怎么样的。当你熟知原理以后，无论你使用任何一种消息队列，再简单看一下它的API和相关配置项，就能很快知道该如何配置消息队列，写出可靠的代码，避免消息丢失。
## 检测消息丢失的方法我们说，用消息队列最尴尬的情况不是丢消息，而是消息丢了还不知道。一般而言，一个新的系统刚刚上线，各方面都不太稳定，需要一个磨合期，这个时候，特别需要监控到你的系统中是否有消息丢失的情况。如果是 IT基础设施比较完善的公司，一般都有分布式链路追踪系统，使用类似的追踪系统可以很方便地追踪每一条消息。如果没有这样的追踪系统，这里我提供一个比较简单的方法，来检查是否有消息丢失的情况。``{=html}**我们可以利用消息队列的有序性来验证是否有消息丢失。**原理非常简单，在Producer 端，我们给每个发出的消息附加一个连续递增的序号，然后在 Consumer端来检查这个序号的连续性。如果没有消息丢失，Consumer收到消息的序号必然是连续递增的，或者说收到的消息，其中的序号必然是上一条消息的序号+1。如果检测到序号不连续，那就是丢消息了。还可以通过缺失的序号来确定丢失的是哪条消息，方便进一步排查原因。大多数消息队列的客户端都支持拦截器机制，你可以利用这个拦截器机制，在Producer 发送消息之前的拦截器中将序号注入到消息中，在 Consumer收到消息的拦截器中检测序号的连续性，这样实现的好处是消息检测的代码不会侵入到你的业务代码中，待你的系统稳定后，也方便将这部分检测的逻辑关闭或者删除。如果是在一个分布式系统中实现这个检测方法，有几个问题需要你注意。首先，像 Kafka 和 RocketMQ 这样的消息队列，它是不保证在 Topic上的严格顺序的，只能保证分区上的消息是有序的，所以我们在发消息的时候必须要指定分区，并且，在每个分区单独检测消息序号的连续性。如果你的系统中 Producer 是多实例的，由于并不好协调多个 Producer之间的发送顺序，所以也需要每个 Producer分别生成各自的消息序号，并且需要附加上 Producer 的标识，在 Consumer端按照每个 Producer 分别来检测序号的连续性。Consumer 实例的数量最好和分区数量一致，做到 Consumer和分区一一对应，这样会比较方便地在 Consumer 内检测消息序号的连续性。
## 确保消息可靠传递讲完了检测消息丢失的方法，接下来我们一起来看一下，整个消息从生产到消费的过程中，哪些地方可能会导致丢消息，以及应该如何避免消息丢失。你可以看下这个图，一条消息从生产到消费完成这个过程，可以划分三个阶段，为了方便描述，我给每个阶段分别起了个名字。![](Images/c93fd53349eca97fc16ec1c7b7832a04.png){savepage-src="https://static001.geekbang.org/resource/image/81/05/81a01f5218614efea2838b0808709205.jpg"}-   **生产阶段**: 在这个阶段，从消息在 Producer    创建出来，经过网络传输发送到 Broker 端。-   **存储阶段**: 在这个阶段，消息在 Broker    端存储，如果是集群，消息会在这个阶段被复制到其他的副本上。-   **消费阶段**: 在这个阶段，Consumer 从 Broker    上拉取消息，经过网络传输发送到 Consumer 上。**1. 生产阶段**在生产阶段，消息队列通过最常用的请求确认机制，来保证消息的可靠传递：当你的代码调用发消息方法时，消息队列的客户端会把消息发送到Broker，Broker收到消息后，会给客户端返回一个确认响应，表明消息已经收到了。客户端收到响应后，完成了一次正常消息的发送。只要 Producer 收到了 Broker的确认响应，就可以保证消息在生产阶段不会丢失。有些消息队列在长时间没收到发送确认响应后，会自动重试，如果重试再失败，就会以返回值或者异常的方式告知用户。**你在编写发送消息代码时，需要注意，正确处理返回值或者捕获异常，就可以保证这个阶段的消息不会丢失。**以Kafka 为例，我们看一下如何可靠地发送消息：同步发送时，只要注意捕获异常即可。    try {    RecordMetadata metadata = producer.send(record).get();    System.out.println(" 消息发送成功。");} catch (Throwable e) {    System.out.println(" 消息发送失败！");    System.out.println(e);}异步发送时，则需要在回调方法里进行检查。这个地方是需要特别注意的，很多丢消息的原因就是，我们使用了异步发送，却没有在回调中检查发送结果。    producer.send(record, (metadata, exception) -> {    if (metadata != null) {        System.out.println(" 消息发送成功。");    } else {        System.out.println(" 消息发送失败！");        System.out.println(exception);    }});**2. 存储阶段**在存储阶段正常情况下，只要 Broker在正常运行，就不会出现丢失消息的问题，但是如果 Broker出现了故障，比如进程死掉了或者服务器宕机了，还是可能会丢失消息的。**如果对消息的可靠性要求非常高，可以通过配置 Broker参数来避免因为宕机丢消息。**对于单个节点的 Broker，需要配置 Broker参数，在收到消息后，将消息写入磁盘后再给 Producer返回确认响应，这样即使发生宕机，由于消息已经被写入磁盘，就不会丢失消息，恢复后还可以继续消费。例如，在RocketMQ 中，需要将刷盘方式 flushDiskType 配置为 SYNC_FLUSH 同步刷盘。如果是 Broker 是由多个节点组成的集群，需要将 Broker集群配置成：至少将消息发送到 2个以上的节点，再给客户端回复发送确认响应。这样当某个 Broker宕机时，其他的 Broker 可以替代宕机的Broker，也不会发生消息丢失。后面我会专门安排一节课，来讲解在集群模式下，消息队列是如何通过消息复制来确保消息的可靠性的。**3. 消费阶段**消费阶段采用和生产阶段类似的确认机制来保证消息的可靠传递，客户端从Broker 拉取消息后，执行用户的消费业务逻辑，成功后，才会给 Broker发送消费确认响应。如果 Broker没有收到消费确认响应，下次拉消息的时候还会返回同一条消息，确保消息不会在网络传输过程中丢失，也不会因为客户端在执行消费逻辑中出错导致丢失。你在编写消费代码时需要注意的是，**不要在收到消息后就立即发送消费确认，而是应该在执行完所有消费业务逻辑之后，再发送消费确认。**同样，我们以用 Python 语言消费 RabbitMQ消息为例，来看一下如何实现一段可靠的消费代码：    def callback(ch, method, properties, body):    print(" [x] 收到消息 %r" % body)    