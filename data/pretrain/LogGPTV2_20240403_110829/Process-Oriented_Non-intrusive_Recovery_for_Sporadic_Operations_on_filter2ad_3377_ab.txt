8.1  Case Study 1-Recovery for Rolling Upgrade Operation on Cloud .................. 91 
8.1.1 
Recovery Points Determination ................................................................ 91 
8.1.2  Workload of Resource Space Determination ............................................ 92 
8.1.3  Workload of Expected Resource State Templates Generation ................. 93 
8.1.4 
Recovery Satisfying Requirements ........................................................... 93 
8.2  Case Study 2-Recovery for Installation Operation on Cloud ......................... 104 
8.2.1 
Recovery Points Determination .............................................................. 104 
8.2.2  Workload of Resource Space Determination .......................................... 104 
8.2.3  Workload of Expected Resource State Templates Generation ............... 105 
8.2.4 
Recovery Satisfying Requirements ......................................................... 105 
8.3  Case Study 3-Recovery for Scale-up Operation on Cloud ............................. 113 
8.3.1 
Recovery Points Determination .............................................................. 113 
8.3.2  Workload of Resource Space Determination .......................................... 114 
8.3.3  Workload of Expected Resource State Templates Generation ............... 115 
8.3.4 
Recovery Satisfying Requirements ......................................................... 115 
8.4  Case Study 4-Recovery for Scale-down Operation on Cloud ........................ 123 
8.4.1 
Recovery Points Determination .............................................................. 123 
8.4.2  Workload of Resource Space Determination .......................................... 124 
8.4.3  Workload of Expected Resource State Templates Generation ............... 125 
iii 
8.4.4 
Recovery Satisfying Requirements ......................................................... 125 
8.5  Case Study 5-Recovery for Migration Operation on Cloud ........................... 133 
8.5.1 
Recovery Points Determination .............................................................. 134 
8.5.2  Workload of Resource Space Determination .......................................... 134 
8.5.3  Workload of Expected Resource State Templates Generation ............... 135 
8.5.4 
Recovery Satisfying Requirements ......................................................... 135 
8.6  Comparison between POD-Recovery and Other Cloud Recovery Methods . 148 
8.7 
Summary and Discussion ............................................................................... 150 
8.8 
Threats to Validity .......................................................................................... 151 
Chapter 9.  Conclusion .............................................................................................. 152 
9.1  Contributions of Thesis .................................................................................. 152 
9.2 
Implications of Proposed Recovery Method .................................................. 154 
9.3 
Limitations of Recovery Framework ............................................................. 154 
9.4  Directions for Future Research ....................................................................... 155 
References ..................................................................................................................... 157 
iv 
List of Figures 
Fig. 1.  Rolling Upgrade Operation. ................................................................................ 10 
Fig. 2.  Rollback Recovery Categories............................................................................ 22 
Fig. 3.  Disaster Recovery with Cloud Computing. ........................................................ 24 
Fig. 4.  Asynchronous Replication in Remus. ................................................................. 26 
Fig. 5.  Remus High-level Architecture. ......................................................................... 26 
Fig. 6.  System Architecture of FTCloud. ....................................................................... 28 
Fig. 7.  Coordinate Chart for Dimensions in Taxonomy. ............................................... 40 
Fig. 8.  Cloud Activities and Life Cycle Phases. ............................................................ 41 
Fig. 9.  Level 1 Classification for Cloud Recovery Methods.......................................... 43 
Fig. 10.  Level 2 Classification for Cloud Recovery Methods. ...................................... 43 
Fig. 11.  Asgard Rolling Upgrade Operation. ................................................................. 44 
Fig. 12.  Overview of POD-Recovery. ............................................................................ 54 
Fig. 13.  Generalized Recovery Workflow. .................................................................... 56 
Fig. 14.  CloudTrail Log. ................................................................................................ 61 
Fig. 15.  Operation Resource Space Determination. ....................................................... 62 
Fig. 16.  Cloud Resource Determined for Rolling Upgrade. .......................................... 62 
Fig. 17.  Resource State Capturing Algorithm. ............................................................... 63 
Fig. 18.  Expected Resource State Templates Generation. ............................................. 65 
Fig. 19.  Sample Expected Resource State Templates. ................................................... 66 
Fig. 20.  Eight Recovery Patterns.................................................................................... 70 
Fig. 21.  AI-Planning based Recovery Plan Generation. ................................................ 76 
Fig. 22.  Recovery Action Impact Analysis. ................................................................... 80 
Fig. 23.  Workload-Response Time Model. .................................................................... 83 
Fig. 24.  Pareto Set Search Based Selection Algorithm. ................................................. 86 
Fig. 25.  User Constraints Based Selection Algorithm. .................................................. 87 
Fig. 26.  Experimental Environment. .............................................................................. 91 
Fig. 27.  Determining Recovery Points for Rolling Upgrade Operation. ....................... 92 
Fig. 28.  Workload of Resource Space Generation for Rolling Upgrade Operation. ..... 93 
Fig. 29.  Workload of Expected Resource State Templates Generation for Rolling 
Upgrade Operation. ......................................................................................................... 93 
Fig. 30.  Determining Recovery Points for Installation Operation. .............................. 104 
Fig. 31.  Workload of Resource Space Determination for Installation Operation. ....... 105 
v 
Fig. 32.  Workload of Expected Resource State Templates Generation for Installation 
Operation. ...................................................................................................................... 105 
Fig. 33.  Determining Recovery Points for Scale-up Operation. .................................. 114 
Fig. 34.  Workload of Resource Space Determination for Scale-up Operation. ........... 114 
Fig. 35.  Workload of Expected Resource State Templates Generation for Scale-up 
Operation. ...................................................................................................................... 115 
Fig. 36.  Determining Recovery Points for Scale-down Operation. ............................. 124 
Fig. 37.  Workload of Resource Space Determination for Scale-down Operation. ...... 124 
Fig. 38.  Workload of Expected Resource State Templates Generation for Scale-down 
Operation. ...................................................................................................................... 125 
Fig. 39.  Determining Recovery Points for Migration Operation. ................................ 134 
Fig. 40.  Workload of Resource Space Determination for Migration Operation. ......... 135 
Fig. 41.  Workload of Expected Resource State Templates Generation for Migration 
Operation. ...................................................................................................................... 135 
vi 
List of Tables 
Table 1.  Cloud APIs Failure Rates ................................................................................. 12 
Table 2.  Existing Cloud Recovery Strategies ................................................................ 40 
Table 3.  Mapping between Asgard Operational Steps and Cloud APIs ........................ 45 
Table 4.  Asgard’s Built-in Error Handling Mechanism ................................................. 47 
Table 5.  Regular Expressions Matching ........................................................................ 67 
Table 6.  AI-Planning for Eight Recovery Patterns ........................................................ 75 
Table 7.  Recovery Action Generated for Rewind & Replay ......................................... 77 
Table 8.  Recovery Evaluation Metrics ........................................................................... 78 
Table 9.  Faults injected for Rolling Upgrade Operation ................................................ 94 
Table 10.  Recovery Time for Rolling Upgrade ............................................................. 95 
Table 11.  Faults injected for Rolling Upgrade Operation .............................................. 97 
Table 12.  Recovery Impact for Rolling Upgrade ........................................................... 98 
Table 13.  Faults injected for Rolling Upgrade Operation .............................................. 99 
Table 14.  Recovery Monetary Cost for Rolling Upgrade ............................................ 100 
Table 15.  Recovery without Known Causes ................................................................ 101 
Table 16.  Handling False Positives of Error Detection ............................................... 102 
Table 17.  Recovery Time of “Recovery for Recovery” ............................................... 103 
Table 18.  Faults injected for Installation ..................................................................... 106 
Table 19.  Recovery Time for Installation .................................................................... 107 
Table 20.  Faults injected for Installation ..................................................................... 108 
Table 21.  Recovery Impact for Installation.................................................................. 109 
Table 22.  Faults injected for Installation ..................................................................... 110 
Table 23.  Recovery Monetary Cost for Installation ..................................................... 110 
Table 24.  Recovery without Known Causes ................................................................ 111 
Table 25.  Handling False Positives of Error Detection ............................................... 112 
Table 26.  Recovery Time of “Recovery for Recovery” ............................................... 113 
Table 27.  Faults injected for Scale-up Operation......................................................... 116 
Table 28.  Recovery Time for Scale-up ........................................................................ 117 
Table 29.  Faults injected for Scale-up Operation......................................................... 118 
Table 30.  Recovery Impact for Scale-up...................................................................... 119 
Table 31.  Faults injected for Scale-up Operation......................................................... 120 
Table 32.  Recovery Monetary Cost for Scale-up ......................................................... 120 
vii 
Table 33.  Recovery without Known Causes ................................................................ 121 
Table 34.  Handling False Positives of Error Detection ............................................... 122 
Table 35.  Recovery Time of “Recovery for Recovery” ............................................... 123 
Table 36.  Faults injected for Scale-down Operation .................................................... 126 
Table 37.  Recovery Time for Scale-down ................................................................... 127 
Table 38.  Faults injected for Scale-down Operation .................................................... 128 
Table 39.  Recovery Impact for Scale-down ................................................................. 129 
Table 40.  Faults injected for Scale-down Operation .................................................... 130 
Table 41.  Recovery Monetary Cost for Scale-down .................................................... 130 
Table 42.  Recovery without Known Causes ................................................................ 131 
Table 43.  Handling False Positives of Error Detection ............................................... 132 
Table 44.  Recovery Time of “Recovery for Recovery” ............................................... 133 
Table 45.  Faults injected for Migration Operation....................................................... 136 
Table 46.  Recovery Time for Migration ...................................................................... 137 
Table 47.  Faults injected for Migration Operation....................................................... 139 
Table 48.  Recovery Impact for Migration.................................................................... 140 
Table 49.  Faults injected for Migration Operation....................................................... 142 
Table 50.  Recovery Monetary Cost for Migration ....................................................... 142 
Table 51.  Recovery without Known Causes ................................................................ 144 
Table 52.  Handling False Positives of Error Detection ............................................... 146 
Table 53.  Recovery Time of “Recovery for Recovery” ............................................... 147 
Table 54.  Comparison between POD-Recovery and Other Existing Cloud Recovery 
Methods ......................................................................................................................... 150 
viii 
Glossary of Terms 
SLA (Service Level Agreement): It is defined as an official commitment that prevails 
between a service provider and the customer. Particular aspects of the service – quality, 
availability,  responsibilities –  are  agreed  between  the  service  provider  and  the  service 
user. 
DevOps  (Development  and  Operations):  It  is  a  culture,  movement  or  practice  that 
emphasizes the collaboration and communication of both software developers and other 
information-technology  (IT)  professionals  while  automating  the  process  of  software 
delivery and infrastructure changes. 
API  (Application  Programming  Interface):  It  is  a  set  of  subroutine  definitions, 
protocols, and tools for building software and applications. 
AWS (Amazon Web Services): It offers a suite of cloud-computing services that make 
up an on-demand computing platform. 
EC2  (Elastic  Compute  Cloud):  It  forms a central  part of  Amazon's  cloud-computing 
platform (Amazon Web Services), by allowing users to rent virtual computers on which 
to run their own computer applications. 
IaaS  (Infrastructure  as  a  Service):  It  refers  to  online  services  that  abstract  the  user 
from  the  details  of  infrastructure  like  physical  computing  resources,  location,  data 
partitioning, scaling, security, backup, etc. 
PaaS  (Platform  as  a  Service):  It  is  a  category  of  cloud  computing  services  that 
provides  a  platform  allowing  customers  to  develop,  run,  and  manage  applications 
without  the  complexity  of  building  and  maintaining  the  infrastructure  typically 
associated with developing and launching an app. 
SaaS  (Software  as  a  Service): It is  a software licensing and delivery model in which 
software  is  licensed  on  a  subscription  basis  and  is  centrally  hosted.  It  is  sometimes 
referred to as "on-demand software". It is typically accessed by users using a thin client 
via a web browser. 
ix 
VM (Virtual Machine): It is an emulation of a computer system. Virtual machines are 
based on computer architectures and provide functionality of a physical computer. Their 
implementations may involve specialized hardware, software, or a combination. 
KVM  (Kernel-based  Virtual  Machine):  It  is  a  virtualization  infrastructure  for  the 
Linux kernel that turns it into a hypervisor. 
LC (Launch Configuration): It is a template that an Auto Scaling group uses to launch 
EC2 instances. 
ASG (Auto Scaling Group): It contains a collection of EC2 instances that share similar 
characteristics and are treated as a logical grouping for the purposes of instance scaling 
and management. 
ELB  (Elastic  Load  Balancer):  It  refers  to  the  cloud  component  that  distributes 
incoming  application  traffic  across  multiple  EC2  instances  in  multiple  Availability 
Zones. 
AMI (Amazon Machine Image): It is a special type of virtual appliance that is used to 
create a virtual machine within the Amazon Elastic Compute Cloud (EC2). It serves as 
the basic unit of deployment for services delivered using EC2. 
BPEL  (Business  Process  Execution  Language): It is  a standard executable language 
for specifying actions within business processes with web services. 
RTO (Recovery Time Objective): It refers to a time boundary on how long it can take 
for an application to come back online after a failure occurs. It is the targeted duration 
of  time  and  a  service  level  within  which  a  business  process  must  be  restored  after  a 
disaster  (or  disruption)  in  order  to  avoid  unacceptable  consequences  associated  with  a 
break in business continuity. 
RPO  (Recovery  Point  Objective):  It  is  the  maximum  targeted  period  in  which  data 
might be lost from an IT service due to a major incident. 
DR  (Disaster  Recovery):  It  refers  to  recovering  from  the  disasters  for  datacentres. 
Disasters  could  either  mean  the  naturally  disastrous  conditions  (such  as  earthquakes, 
tornados, etc.) or mean manually incurred disasters (such as datacentre power outages). 
x 
Chapter 1.  Introduction & Background 
In  this  chapter,  we  first  present  a  research  overview  to  briefly  describe  the  problem  my  PhD 
research  addresses,  the  proposed  solution,  how  we  evaluate  the  solution,  the  experimental 
results  and  the  research  contributions  (section  1.1).  Then  we  provide  background  information 
for our research, covering: 1) fundamental knowledge of cloud computing (section 1.2.1); 2) the 
definition of sporadic operations on cloud (section 1.2.2); 3) discussion about errors and failures 
in  sporadic  operations  on  cloud  (section  1.2.3);  4)  the  illustration  of  how  to  detect  failures  in 
sporadic  operations  using  our  existing  failure  detection  and  diagnosis  framework  and  how 
recovery is triggered (section 1.2.4). 
1.1  Research Overview 
In this section, we first present the problem statement, the research aim and outcome. Then we 
clarify the research contributions of this thesis. Finally we describe the structure of the thesis. 
1.1.1  Problem Statement 
Sporadic  operations  on  cloud  refer  to  the  deployment  or  maintenance  operations  which  are 
relatively  less  frequent  and  regular  than  normal  activities  like  transactions  in  an  e-commerce 
application  (J.  Humble  and  D.  Farley,  2010;  L.  Bass,  I.  Weber  and  L.  Zhu,  2015).  Sporadic 
operations  on  cloud  applications,  such  as  installation,  upgrade  and  reconfiguration,  are  error-
prone  (L.  Bass,  I.  Weber  and  L.  Zhu,  2015).  This  is  because  of  several  reasons  such  as  the 
uncertainty  of  cloud  APIs  and  cloud  resources  (Q.  Lu,  et  al.,  2013).  Gartner  research  (R.  J. 
Colville and G. Spafford, 2010) has pointed out that the majority of cloud errors and failures are 
those  that  happen  during  cloud  operations  (R.  J.  Colville  and  G.  Spafford,  2010).  As  such, 
handling  these  errors  and  failures  is  a  necessity  for  sporadic  operations  on  cloud  and  how  to 
recover  from  them  has  nowadays  become  a  heavy  research focus (D.  Oppenheimer  and  D.  A. 
Patterson,  2002).  Automated  recovery  from  failures  during  sporadic  operations  on  cloud  has 
become increasingly important because of the need to manage the uncertainty on cloud and the 
highly  variable  SLA  (Service  Level  Agreement)  of  cloud  based  systems  (J.  Humble  and  D. 
Farley, 2010). Further, as the practice of DevOps (Development & Operations) becomes more 
prevalent,  it  is  commonplace  that  an  increasing  number  of  modern  IT  organizations  make 
frequent system builds and deployments on a daily basis (L. Bass, I. Weber and L. Zhu, 2015). 
Continuous deployments of automated systems cannot afford service downtime and this means 
that  manual  recovery  from  errors  and  failures  which  occur  during  the  frequently  conducted 
sporadic  operations  is  not  an  acceptable  solution  because  it  is  usually  time-consuming  and 
inefficient and could lengthen service downtime of the system (J. Humble and D. Farley, 2010). 
1 
There are several existing automated recovery mechanisms (H. Chang, et al., 2013; C. Colombo, 
et  al.,  2013)  to  recover  from  those  errors  and  failures  during  sporadic  operations  on  cloud. 
However,  these  existing  methods  have  several  drawbacks  and  do  not  recover  from  errors  and 
failures in a fine-grained manner. For instance, exception handling mechanisms usually perform 
recovery by gracefully  exiting from the operation or by providing a certain amount of waiting 
time  (H.  Chang,  et  al.,  2013),  and  they  are  faced  with  the  challenge  of  needing  to  cater  for 
various exceptions from different systems and platforms in a unified way (X. Xu, et al., 2014). 
Another  example  is  that  existing  recovery  mechanisms  for  long  running  transactions  (C. 
Colombo,  et  al.,  2013)  have  relatively  low  efficiency  when  capturing  the  states  of  cloud 
resources,  because  they  usually  need  to  capture  the  full  states  of  all  the  cloud  resources  no 
matter  whether  the  resources  are  required  by  the  target  cloud  systems  and  operations  or  not. 
This state capturing mechanism also influences the efficiency of generating state transition plans 
for  recovery.  Moreover,  the  recovery  methods  for  long  running  transactions  are  usually 
application-specific  and  hence  it  is  hard  to  generalize  them  to  cater  for  different  types  of 
sporadic  operations  on  cloud.  These  gaps  in  existing  cloud  recovery  methods  embody  the 
necessity of a new and fine-grained recovery methodology for cloud operations and hence have 
motivated this research. 
Based on what has been discussed above, the problem that my PhD research is trying to address 
is  that  sporadic  operations  on  cloud  are  error-prone  due  to  several  reasons  such  as  cloud 
uncertainty  and  instability,  but  existing  cloud  operational  recovery  methods  are  unable  to 
recover  from  cloud  operational  failures  in  a  fine-grained  manner.  Hence,  my  PhD  research 
proposes  and  evaluates  a  fine-grained  recovery  methodology  to  sufficiently  handle  failures  in 
sporadic operations on cloud. 
1.1.2  Research Aim and Research Outcome 
To place our research in context, we first completed a literature review on the existing recovery 
methods  for  cloud  and  then  we  made  taxonomy  for  these  cloud  recovery  methods.  In  the 
taxonomy,  existing  cloud  recovery  methods  are  categorized  into  four  categories:  1)  Recovery 
for Normal Activities in Design Phase; 2) Recovery for Normal Activities in Runtime Phase; 3) 
Recovery  for  Sporadic  Activities  in  Design  Phase;  4)  Recovery  for  Sporadic  Activities  in 
Runtime  Phase.  The  main  purpose  of  figuring  out  such  taxonomy  is  to  clarify  which  existing 
cloud  recovery  methods  should  be  focused  on  by  our  research.  Specifically,  the  research  is 