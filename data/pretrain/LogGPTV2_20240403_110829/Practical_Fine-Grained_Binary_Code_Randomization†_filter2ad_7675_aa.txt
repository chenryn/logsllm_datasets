title:Practical Fine-Grained Binary Code Randomization†
author:Soumyakant Priyadarshan and
Huan Nguyen and
R. Sekar
Practical Fine-
Grained Binary Code Randomization†
Soumyakant Priyadarshan
Stony Brook University, USA
PI:EMAIL
Huan Nguyen
Stony Brook University, USA
PI:EMAIL
R. Sekar
Stony Brook University, USA
PI:EMAIL
ABSTRACT
Despite its effectiveness against code reuse attacks, fine-grained
code randomization has not been deployed widely due to compati-
bility as well as performance concerns. Previous techniques often
needed source code access to achieve good performance, but this
breaks compatibility with today’s binary-based software distribu-
tion and update mechanisms. Moreover, previous techniques break
C++ exceptions and stack tracing, which are crucial for practical de-
ployment. In this paper, we first propose a new, tunable randomiza-
tion technique called LLR(k) that is compatible with these features.
Since the metadata needed to support exceptions/stack-tracing can
reveal considerable information about code layout, we propose a
new entropy metric that accounts for leaks of this metadata. We
then present a novel metadata reduction technique to significantly
increase entropy without degrading exception handling. This enables
LLR(k) to achieve strong entropy with a low overhead of 2.26%.
KEYWORDS
Binary instrumentation, Code randomization, Code reuse exploits,
Exception compatibility.
ACM Reference Format:
Soumyakant Priyadarshan, Huan Nguyen, and R. Sekar. 2020. Practical Fine-
Grained Binary Code Randomization†. In Annual Computer Security Appli-
cations Conference (ACSAC 2020), December 7–11, 2020, Austin, USA. ACM,
New York, NY, USA, 14 pages. https://doi.org/10.1145/3427228.3427292
1 INTRODUCTION
With widespread adoption of data execution prevention (DEP) on
modern operating systems, attackers have shifted their focus from
code injection to code reuse attacks, e.g., return-oriented program-
ming (ROP) [47] and jump-oriented programming (JOP) [7]. Ex-
isting defenses against code reuse attacks fall into two broad cate-
gories: control-flow integrity (CFI) [2, 15, 36, 52, 61, 64] and fine-
grained code randomization [6, 11, 14, 16, 18, 26, 30, 31, 38, 55, 57,
62]. Although the deterministic nature of CFI is attractive, as a
code-reuse defense, CFI has a few drawbacks:
• Use of CFI-permitted gadgets: With CFI, attackers are uncon-
strained if they target “legitimate gadgets,” i.e., gadgets that
are reachable as per the policy enforced by CFI. In contrast,
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
ACSAC 2020, December 7–11, 2020, Austin, USA
© 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-8858-0/20/12...$15.00
https://doi.org/10.1145/3427228.3427292
fine-grained code randomization hides the location of every
gadget, thus requiring extra work (e.g., information leaks)
before any of them can be used in an attack.
• Lack of graceful degradation: If CFI instrumentation leaves
out some modules or code fragments, attackers can initiate a
ROP attack from these fragments. Once initiated, such an at-
tack is free to use unintended gadgets anywhere, including
modules that have the CFI instrumentation. This is be-
cause CFI checks are applied only on legitimate instructions,
e.g., intended returns, rather than unintended ones1. This
contrasts with randomization, where weaknesses introduced
by an unrandomized code module are limited to the gadgets
within that module.
• Compatibility: Higher precision (aka fine-grained) CFI [15,
36, 52] suffers from compatibility problems on complex code.
Coarse-grained CFI [1, 2, 61, 64] poses fewer compatibility
challenges, but is more easily defeated. Code randomization
typically faces far fewer compatibility problems than CFI
techniques.
These factors have prompted substantial research on fine-grained
code randomization. Early works [6, 30] targeted the static ROP
threat model, where the attacker has a copy of the victim’s binary
code. By statically analyzing this code, he/she can identify gadgets
that can be used in an attack. Code reuse attacks have since evolved
to use dynamic probing of victim process code and/or data memory
by leveraging memory disclosure vulnerabilities:
• (Direct) JIT-ROP attacks [50] rely on the identification of
• Indirect disclosure ROP attacks leak just the data memory —
gadgets on the fly by disclosing victim’s code memory.
specifically, code pointers stored in data memory.
Like many recent works, we rely on execute-only code for thwart-
ing direct JIT-ROP. The new techniques developed in this paper are
thus aimed at the static ROP and indirect disclosure ROP threat mod-
els.
1.1 Motivation: Deployable Code Randomization
Despite advances in new code randomization techniques, they are
not widely deployed due to several concerns described below.
Need for Source Code. Many code randomization techniques rely
on a modified compiler [6, 14, 31] or special compiler options
[18, 30, 57] (e.g., debug or relocation flags) that aren’t enabled on
production binaries. This makes them incompatible with today’s
dominant software deployment and update mechanisms, which
1The attacker can use any gadget beginning in the middle of a legitimate instruction,
as long as the indirect control flow instructions in the gadget are unintended.
†The first two authors contributed equally to this work, which was supported by ONR
(N00014-17-1-2891). Third author’s work was also supported by NSF (CNS-1918667).
401ACSAC 2020, December 7–11, 2020, Austin, USA
Soumyakant Priyadarshan, Huan Nguyen, and R. Sekar
involve the distribution of binary code . Even open-source software
is predominantly distributed in binary format for convenience.
Performance. A low overhead is critical for the deployment of
security hardening measures. Often, a 5% or lower threshold is
quoted. While techniques that rely on some level of compiler sup-
port [14, 18, 30, 31, 57] have met this threshold, most binary-based
techniques (e.g., [16, 26, 62]) tend to have higher overheads.
Compatibility with stack tracing and C++ exceptions. A chief
concern for deployed software is the support for error handling and
reporting. Unfortunately, existing fine-grained code randomization
techniques don’t support these features. While this incompatibility
may be acceptable for a proof-of-concept implementation, it is not a
viable option for platform-wide deployment. In particular, libraries
need to be compatible, or else exceptions and stack traces are broken
for every application that uses them.
Some techniques (e.g., Readactor [14]) are incompatible because
they violate a key assumption behind these mechanisms: that func-
tion bodies are contiguous. Many others [6, 11, 16, 18, 26, 30, 55,
57, 62] are incompatible because they fail to maintain the metadata
used by these mechanisms. More importantly, none of the previ-
ous techniques have considered the security implications of
this metadata. In particular, both stack tracing and exception han-
dling operate from the “stack unwinding” information stored in
the eh_frame section of Linux binaries. This section records the
addresses of the first and last instructions of (almost) every function
in the binary. It is important to note that this information is present
in stripped binaries, and is stored in readable memory at runtime.
Moreover, this information is not limited to C++, as stack traces
are needed for C-code as well. We found that this information is
present for 95% of the code on Ubuntu Linux.
Since attackers have proven adept at leaking information stored
in readable memory, it is necessary to develop randomization tech-
niques that are secure despite such leaks. In particular, many exist-
ing techniques derive the bulk of their randomness from permuting
the order of functions. The availability of eh_frame information
defeats the security of such schemes.
1.2 Approach Overview and Contributions
In this paper, we present Stony Brook Static Binary Randomizer
(SBR) that provides the following key features:
• Compatibility with exceptions and stack traces;
• Compatibility with COTS binaries, including low-level li-
braries such as the system loader (ld) and the C-library
(glibc);
• Support for code written in multiple languages, including
C, C++, Fortran and hand-written assembly, and compiled
using multiple compilers (e.g., gcc, llvm and gfortran); and
• Low runtime overhead.
SBR has been tested on 640MB of binaries. (This is about 2/3rd
the size of all binaries on Ubuntu Desktop 18.04.) We plan to open-
source SBR in a few months. Our main contributions are as follows.
Stack-unwinding-compatible randomization. We present a new
technique called LLR(k) that provides the following benefits:
• Each leaked code pointer reveals the locations of just k more
instructions. As a result, attackers need to leak many pointers
before they have sufficient gadgets for an effective payload.
• Users can easily make security vs performance trade-offs by
tuning k. Larger k values yield better performance, while
smaller k values offer increased security. Moreover, LLR(k)
can be seamlessly combined with other randomization tech-
niques.
• Our experimental results show that k = 16 achieves good
security (in the form of high entropy) with a low over-
head of 2.26%.
Unwinding Block Entropy and Reduced EH-Metadata. We show
that the metadata used for C++ exceptions and stack-tracing reveals
a lot of fine-grained information about instruction locations.
• We define a new entropy metric, unwinding block entropy, to
quantify the difficulty of attacks that exploit this metadata.
• We develop a novel approach for reducing the metadata such
that C++ exceptions would continue to work seamlessly, and
with the same performance as before.
• We show that this metadata reduction has a major impact
on our new entropy metric, increasing it by 8x.
Comparison of randomizing transformations. We present a robust
implementation of SBR that scales to complex binaries on 64-bit
x86/Linux systems. It randomizes all code, including executables
and all libraries. Using this implementation, we present a detailed
experimental evaluation of the security vs performance trade-off
offered by previous randomization techniques and our new LLR(k).
1.3 Paper Organization
Sec. 2 provides the background on stack unwinding, our threat
model, and previous randomization techniques. Our new LLR(k)
technique is introduced in Sec. 3. A new unwinding metadata opti-
mization is described in Sec. 4. Our new entropy metrics are pre-
sented in Sec. 5, followed by our binary instrumentation approach
in Sec. 6. Implementation and evaluation are the topics of Sec. 7
and 8, followed by discussion, related work, and conclusions in
Sec. 9, 10 and 11.
2 BACKGROUND AND THREAT MODEL
2.1 C++ Exception and Stack Tracing
Compatibility
Modern C++ compilers and runtime systems implement a “zero
overhead” (aka “zero cost”) exception model. This model is aimed
at eliminating runtime overheads for any program that raises no
exceptions, even if it includes code that uses exceptions. This is
achieved by avoiding proactive book-keeping at runtime for excep-
tion handling. Instead, the compiler generates tables that include
all the information necessary to process exceptions at runtime. This
table is stored in read-only data sections in the binary that we will
collectively refer to as EH-metadata.
On GNU/Linux, stack tracing also uses EH-metadata, so this
metadata is included in code generated from many languages, in-
cluding C. Even hand-written assembly in many system libraries
contains EH-metadata. The vast majority of binary code on Linux
systems is covered by EH-metadata — for instance, 95% of all the
code in /bin and /lib/x86_64-linux-gnu on Ubuntu 18.04 Linux.
402Practical Fine-Grained Binary Code Randomization
ACSAC 2020, December 7–11, 2020, Austin, USA
An operation central to exception processing as well as stack
tracing is stack unwinding. This operation involves restoring the
values of callee-saved registers, and restoring the stack pointer to
its value when the current function was entered. On completion
of unwinding, the stage is set for returning to the caller. The caller
may in turn perform its own unwinding and return to its caller, and
so on. For C++ programs, unwinding stops when it reaches a catch
block for the current exception, or the outermost stack frame.
EH-metadata specifies: (a) the start and end locations of each
function, (b) the beginning and end of each unwinding block, and (c)
the operations for unwinding. An unwinding block may correspond
to a try-block in a C++ program, or to instructions that change
the stack pointer and/or callee-saved registers. The operations for
unwinding a block are usually specified as a delta over a previous
unwinding block, thus revealing dependencies between them. More
details on EH-metadata can be found in [37, 42].
ment.
Key Implications and Requirements for Code Randomization.
• Exception metadata needs to be updated after code move-
• This metadata reveals a lot of information useful to attackers:
(1) the start and end address of each function,
(2) the start and end of each unwinding block, and
(3) the dependence between unwinding blocks.
Our investigation shows that across a range of Linux/x86_64
binaries, an average function contains about a dozen unwind-
ing blocks. So, unless care is taken, EH-metadata can leak a lot of
information about code locations, thereby greatly degrading the
effectiveness of code randomization. To address this threat, we need
• new code randomization techniques that can provide ade-
• new metadata optimization techniques that minimize the
amount of EH-metadata without impacting the functionality
or performance of exception handling (Sec. 4), and
• new entropy metrics that assess the security provided by
code randomization in the face of EH-metadata leaks (Sec. 5).
quate security despite such leaks (Sec. 3),
2.2 Threat Model and Security Goals
Our threat model is similar to previous work, with the key difference
that attackers are aware of SBR’s compatibility with stack traces
and exceptions and hence may:
to speed up their attack, and/or
• leverage the fact that function bodies are contiguous in order
• target EH-metadata specifically and disclose it. This is pos-
sible because this metadata is present in stripped binaries,
and is stored in readable memory at runtime. Moreover, it
typically covers 95% of all functions, including most C-code
and assembly.
With these differences in mind, we outline the three threat models
considered in code randomization research.
Static ROP.. Although this threat model mentions ROP [47] specif-
ically, it is intended to include other code reuse attacks that rely on
existing code snippets such as JOP [7]. This threat model assumes
that (a) the attacker is able to exploit a vulnerability in the victim
program to hijack its control flow to start the execution of a gadget
chain, and (b) the locations of these gadgets are determined on
the basis of an attacker’s prior knowledge of the victim program’s
binary. All code randomization techniques aim to take away (b),
but don’t always do it completely. For instance, compiler-based
techniques don’t randomize low-level code written in assembly.
Our goal is to defeat static ROP by ensuring that the attacker
has no knowledge of any part of the binary code that executes at
runtime, and by introducing large entropy into this binary.
JIT-ROP.. The JIT-ROP threat model assumes that the victim
program has a memory corruption vulnerability that provides (i)
an arbitrary read capability, and (ii) an ability to hijack control-
flow. It also assumes the availability of a scripting environment
that (i) executes attacker-provided scripts, and (ii) can exercise
these vulnerabilities. State-of-art defense against JIT-ROP relies on
execute-only (i.e., non-readable) code. Since this technique imposes
very low overheads and is also very strong due to its reliance on
hardware memory protection, our approach will simply rely on this
technique to protect against JIT-ROP. (Note that our techniques are
compatible with execute-only code.)
Indirect (only) Disclosure ROP.. This threat model assumes that
the victim program has a memory corruption vulnerability that en-
ables an attacker to read arbitrary memory locations. It also assumes
the availability of another vulnerability that enables control-flow
hijack. Finally, it assumes that code is protected from reads, so the
attacker cannot use leaked pointers to search the code for usable
gadgets. Instead, she targets gadgets that are adjacent to the leaked
code address, or at a short distance from it. Attackers may very well
use gadgets at the leaked pointers. Preventing such reuse is hard,
and is outside the scope of code randomization. Instead, our goal
is to prevent attackers from using leaked pointers to identify (the
locations of) additional usable gadgets.
The availability of EH-metadata greatly increases useful in-
formation that may be leaked by indirect disclosures.
2.3 Common Randomizing Transformations
In this section, we summarize most of the fine-grained randomizing
transformations that have been proposed before. These transfor-
mations proceed in two phases. The first phase determines how a
function body is split into a set of partitions. In the second phase,
the partitions are permuted, and jumps introduced as needed to
preserve the original control-flow. Since the second phase is similar
for all transformations, we focus on the first phase below.
• Function Reordering (FR): Proposed in the earliest works
on code randomization [6, 30], this technique does not change
function bodies at all — it simply permutes the order of func-
tions in the code section. This achieves high entropy against
static ROP threat model, but FR is insufficient if code pointers
or stack-unwinding information can be leaked.
• ZeroJmp (ZJR): Koo et al [31] proposed to align code splits
at locations terminating with unconditional jump instruc-
tions. With this alignment, no new jumps are introduced for
randomization; instead, we simply adjust the targets of exist-
ing jumps after permuting the blocks. As a result, Koo et al
achieved nearly zero overhead for this technique. We show,
however, that ZJR is relatively weak against adversaries that
can leak code pointers.
403ACSAC 2020, December 7–11, 2020, Austin, USA
Soumyakant Priyadarshan, Huan Nguyen, and R. Sekar
• Basic Block Randomization (BBR): This technique splits
function bodies at basic block boundaries. A basic block is
an instruction sequence with no incoming control trans-
fers except to the first instruction, and no outgoing control
transfers except through the last instruction.
• Pointer-Hiding Randomization (PHR): Readactor [14] in-
troduced a pointer hiding defense against indirect disclosure
attacks. Specifically, for every indirectly called function, they
introduce a corresponding trampoline that then jumps to
that function. It is only the trampoline address that is stored
in memory. Since the trampoline is located randomly, it re-
veals no information about possible gadgets at the beginning
of the target functions. To protect return addresses, each
call is replaced with a jump to a trampoline for that call-site,
with the trampoline making a call to the target function. As
a result, the return address only leaks the location of the
trampoline.
Random placement of call-site trampolines will break stack-
unwinding. So, we consider a modification of Readactor’s
technique that locates the trampoline at a random location
within the body of the caller. In addition, code blocks between
successive calls are permuted. We call this variant as PHR.
• Phantom Blocks (PB): Instead of relying purely on permuta-
gaps between blocks of original code. By randomly varying
the size of phantom blocks, entropy can be further increased.
Moreover, these blocks can be made into “traps” by filling
them with invalid code. This will cause any jumps into these
blocks to terminate the victim program.
Note that PB does not create new splits in the function body
— instead, it relies on other schemes such as BBR or PHR.
• One-side Pointer Hiding (OPHR): Note that call-site tram-
polines of PHR require one jump into the trampoline, and
a second jump out of the trampoline. Performance can be
improved by removing one of these jumps. There is also a
security cost, because the gadget location are hidden only
on one side of the call: the side that contains a jump.
tion, phantom blocks were introduced in kR(cid:98)X [40] to create
Specifically, kR(cid:98)X relies on the PHR variant described next.
3 LLR(k): LENGTH LIMITING
RANDOMIZATION
Existing randomization techniques outlined above do not satisfac-
torily address indirect disclosure ROP that leverages EH-metadata:
• PHR can stop attackers from computing additional gadgets