title:SoK: A Framework for Unifying At-Risk User Research
author:Noel Warford and
Tara Matthews and
Kaitlyn Yang and
Omer Akgul and
Sunny Consolvo and
Patrick Gage Kelley and
Nathan Malkin and
Michelle L. Mazurek and
Manya Sleeper and
Kurt Thomas
2022 IEEE Symposium on Security and Privacy (SP)
SoK: A Framework for Unifying At-Risk User Research
Noel Warfordࢩ, Tara Matthews†, Kaitlyn Yangࢩ, Omer Akgulࢩ, Sunny Consolvo†,
Patrick Gage Kelley†, Nathan Malkinࢩ, Michelle L. Mazurekࢩ, Manya Sleeper†, and Kurt Thomas†
ࢩUniversity of Maryland, †Google
3
4
6
3
3
8
9
.
2
2
0
2
.
4
1
2
6
4
P
S
/
9
0
1
1
.
0
1
:
I
O
D
|
E
E
E
I
2
2
0
2
©
0
0
.
1
3
$
/
2
2
/
9
-
6
1
3
1
-
4
5
6
6
-
1
-
8
7
9
|
)
P
S
(
y
c
a
v
i
r
P
d
n
a
y
t
i
r
u
c
e
S
n
o
m
u
i
s
o
p
m
y
S
E
E
E
I
2
2
0
2
Abstract—At-risk users are people who experience risk factors
that augment or amplify their chances of being digitally attacked
and/or suﬀering disproportionate harms. In this systematization
work, we present a framework for reasoning about at-risk users
based on a wide-ranging meta-analysis of 95 papers. Across the
varied populations that we examined (e.g., children, activists,
people with disabilities), we identiﬁed 10 unifying contextual
risk factors—such as marginalization and access to a sensitive
resource—that augment or amplify digital-safety risks and their
resulting harms. We also identiﬁed technical and non-technical
practices that at-risk users adopt to attempt to protect themselves
from digital-safety risks. We use this framework to discuss
barriers that limit at-risk users’ ability or willingness to take
protective actions. We believe that researchers and technology
creators can use our framework to identify and shape research
investments to beneﬁt at-risk users, and to guide technology
design to better support at-risk users.
I. INTRODUCTION
Anyone can experience attacks related to their security, pri-
vacy, or safety online (i.e., digital safety), but at-risk users have
risk factors that augment or amplify their chances of being
digitally attacked and/or suﬀering disproportionate harms. For
example, some activists are surveilled by government actors
due to their work [59, 90]; people who are LGBTQ+ face
elevated risk of harassment by anonymous attackers on social
media [15, 16]; and women in repressive regions experience
pervasive sexual harassment online and sometimes severe
consequences from their community as a result [88, 109].
A growing body of research has explored how the digital-
safety needs of at-risk users may be unmet by existing security,
privacy, and safety threat models that tend to focus on a
mythical “average user.” A common recommendation from
researchers in this space is to consider at-risk users during the
technology creation process (e.g., [13, 25, 63, 97, 108, 124]).
However, for technology creators, it can be bewildering to con-
sider dozens of diﬀerent at-risk populations, each with disjoint
and sometimes contradictory digital-safety needs. Accordingly,
we argue that there is a need for synthesis: to organize what is
known into a framework that can be used to reason about at-
risk users’ risks and needs, and to identify gaps in knowledge
for future work.
We systematically identiﬁed and reviewed 95 papers focused
on the digital-safety experiences of at-risk populations and
developed a framework that can be used to reason about four
research questions regarding at-risk users:
RQ1: Contextual risk factors. What factors—such as a
person’s situation in society, relationships, or per-
sonal circumstances—contribute to digital-safety
risks for at-risk users?
RQ2: Interactions. How do these contextual risk factors
interact to elevate the risk or severity of digital-
safety attacks for at-risk users?
RQ3: Protective practices. What protective practices are
common across at-risk users when attempting to
address their digital-safety risks?
RQ4: Barriers. What barriers do at-risk users encounter
in protecting themselves from digital-safety risks?
Based on an analysis across 31 distinct population cate-
gories (e.g., journalists, refugees, older adults), we identiﬁed
10 contextual risk factors that cross-cut at-risk populations,
yielding a set of circumstances that technology creators and
researchers can consider in research, design, and development.
We also found that at-risk users currently rely on varied, often
ad-hoc protective practices, ranging from leaning on social
connections to relying on a patchwork of technical strategies
to try to minimize risks and harms. We provide an at-risk
framework comprised of these contextual risk factors and
protective practices, which we use to discuss barriers that
limit or prevent at-risk users from enacting digital protections,
and to show how competing priorities, a lack of digital safety
awareness, and broken technology assumptions compound the
challenges at-risk users face.
We advocate for technology creators and researchers to
consider at-risk users’ needs in risk modeling and design.
Our framework provides a blueprint for addressing these issues
through research, education support, and technology creation,
to better ensure that at-risk users can engage safely online, and
in the process, to improve digital safety for everyone.
II. WHO ARE AT-RISK USERS?
In this paper, we use at-risk user as an umbrella term for
anyone with risk factors that augment or amplify their chances
of being attacked digitally and/or suﬀering disproportionate
harms from an attack. We refer to groups of at-risk users as
at-risk populations. Due to a lack of consensus in the literature
on how to refer to such users or populations, we chose these
terms with the goal of drawing focus to external risks these
users face.
A. Previous taxonomies of attacks, threats, and harms
Previous systematizations developed frameworks to broadly
categorize attacks, threats, and harms, although none capture
how these elements overlap or diﬀer across distinct at-risk
populations. In particular, Scheuerman et al. [92] and Thomas
© 2022, Noel Warford. Under license to IEEE.
DOI 10.1109/SP46214.2022.00116
2344
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:11:21 UTC from IEEE Xplore.  Restrictions apply. 
et al. [103] developed frameworks for understanding classes
of harms that may result from digital-safety attacks, such
as reputational harm, ﬁnancial harm, reduced sexual safety,
reduced physical safety, and coercion. Scheuerman et al. [92]
also provided a framework for assessing the severity of threats
based on such harms. Thomas et al. [103], Sambasivan et
al. [88], and Levy and Schneier [57] detailed how attacks
vary based on the capabilities of attackers, such as having
intimate access to a target, or privileged access to a target’s
devices or data. Our at-risk framework diﬀers in that we
isolate the contextual risk factors that can make at-risk users
particularly vulnerable to such attacks, threats, or harms. We
also document common protective practices at-risk users adopt
and discuss barriers they face to staying safe.
B. Value of focusing on at-risk users
The challenges experienced by at-risk users can be inor-
dinately complex, reﬂecting broader, societal “structural in-
equalities and social norms” [35, 65]. These inequalities, which
vary globally, mean that particular care is required to integrate
at-risk users’ experiences and identities into the technology
creation process [48, 65, 111].
We advocate for increased focus on at-risk users’ needs by
technology creators and researchers during threat modeling,
research, design, and development. Accounting for at-risk
users can also elevate the digital safety of all users by making
“more pronounced the need[s] that many of us have” [29].
Providing better digital-safety tools and guarantees can have
far-reaching impact both to at-risk users and general users.
Additionally, providing choices and controls for at-risk users
who know intimately the digital-safety threats they face can
also beneﬁt general users who may desire similar protections.
III. METHODS
We synthesize 95 research papers from a cross-section
of computer science conferences. Here, we discuss how we
identiﬁed and analyzed these papers.1
A. Paper selection
Our dataset for this analysis was 95 papers describing
digital-safety-related issues for various at-risk populations. We
collected papers from ﬁve years (2016–2020) of conferences
spanning the security, privacy, and human-computer inter-
action (HCI) communities: CCS, CHI, CSCW, IEEE S&P,
NDSS, PETS, SOUPS, and USENIX Security. We ﬁrst gath-
ered links to every paper from these conferences on DBLP.2
From those links, we collected paper titles, abstracts, and
publication dates, resulting in 6,534 papers.
To reﬁne this list, three researchers independently read titles
and abstracts for each paper and marked them as ‘relevant’ to
our research questions or not. At this stage, we interpreted
relevance broadly, selecting any paper even slightly within
scope. Papers that no researcher marked as relevant were
removed. Papers marked as relevant by only one researcher
1Additional method details can be found at https://arxiv.org/abs/2112.07047
2See https://dblp.uni-trier.de/search
were reviewed by a fourth researcher and discussed. This
process identiﬁed 127 potentially relevant papers.
Authors with extensive experience working with at-risk
populations added 12 papers from other sources and/or from
outside the target date range, in order to cover a broader range
of populations, for a total of 139 potentially relevant papers.
B. Codebook development
Our goal was to identify contextual risk factors, protective
practices, and other patterns discussed by the papers in our
dataset. As a ﬁrst step, we inductively built a codebook by
analyzing, in detail, a subset of papers well-aligned with our
research questions. Most of the core concepts in our framework
were identiﬁed at this stage, although inductive reﬁnement
continued throughout our analysis.
To select this initial subset, we extracted from the dataset
an initial list of populations (e.g., survivors of intimate part-
ner abuse [63], refugees [96], activists [25], children [124],
etc.). We also synthesized an initial list of risk factors, for
example, attributes of the population or the threats they faced
that contributed to their digital-safety-related risks. We then
selected our subset to ensure each population and risk factor on
our list was represented, making sure to include some papers
that combined multiple risk factors (e.g., low-income African
American New York City residents [31] and foster teens [12]).
This process yielded 27 papers.
We next analyzed these 27 papers and inductively built our
codebook. We used the speciﬁc population discussed in each
paper3 as a unit of analysis [102]. One of four researchers
read and summarized each paper. The full team used these
summaries to iteratively build and reﬁne our codebook [102],
which included categories for risk factors, protective practices,
and barriers to protection. We met throughout the process to
develop, discuss, and reﬁne codes. These detailed summaries
also enabled us to examine relationships between codes and
memo early ideas on themes [17].
C. Full analysis
Next, we used the codebook to analyze the remaining papers
Because our initial paper selection steps were deliberately
inclusive, we continued to reﬁne the dataset during this phase.
Any researcher could ﬂag a paper for possible exclusion if
it did not address any of our research questions; determina-
tions were made after discussion. Our ﬁnal analyzed dataset
included 95 papers.
We randomly selected 20% of the remaining papers, which
two researchers independently coded, making minor updates
to the codebook as needed. The researchers assigned codes to
each paper and memoed additional relevant details and con-
text [17]. After completing this 20% sample, the researchers
calculated agreement using Krippendorﬀ’s  before discussing
and resolving all disagreements. The researchers then repeated
3For example, Simko et al. [96] reported on interviews with refugees and
associated caseworkers; we treated this as two populations.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:11:21 UTC from IEEE Xplore.  Restrictions apply. 
22345
this procedure on another random 20%. Once suﬃcient relia-
bility was reached, the researchers split the remaining papers
between them to complete coding.
For the contextual risk factors and protective practices, we
obtained  = [0.88, 1.00] after the second round of coding, and
for the barriers,  = 0.83 after the third round. As these are
above the standard threshold of 0.8 for reliability [51], we then
proceeded to individual coding. After coding all papers, the
entire research team met to review the results, identify second-