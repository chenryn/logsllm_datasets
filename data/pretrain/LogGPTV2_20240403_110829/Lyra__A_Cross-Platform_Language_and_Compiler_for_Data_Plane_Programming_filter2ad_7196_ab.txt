ip = ipv4.src_ip;
if(_LOOKUP1)
ip = ipv4.dst_ip;
control int {
program int {
} // P4
} // NPL
}
}
}
Figure 1 shows an example for a programmable DCN that has
five types of ASICs (ToR and Agg layers are fully programmable)
and two data plane programs.
(i) INT [2]: INT was originally proposed to collect and report
network state by inserting the critical metadata in the packet header.
As shown in Figure 1(b), given a packet 𝑝, each programmable
switch 𝑘 on the path inserts a metadata to 𝑝’s header by computing
eg𝑘(𝑝) − ing𝑘(𝑝), where ing𝑘(𝑝) and eg𝑘(𝑝) denote the ingress time
stamp and egress time stamp of 𝑝 on 𝑘, respectively. In particular,
INT contains three algorithms: ingress INT, transit INT, and egress
INT. Ingress INT identifies the packets of interest, and inserts a
probe header and the metadata (see ToR𝑖 in Figure 1(b)). Transit
INT only inserts the metadata. Egress INT inserts the metadata,
and mirrors the received packet for post analyzing. In our example,
network programmers are required to deploy ingress and egress INT
on ToR switches, and deploy transit INT on aggregation switches.
(ii) Stateful L4 load balancer (LB) [32]: The L4 LB maps the
packets destined to a service with a virtual IP (or VIP), to a set of
servers holding the service with multiple destination IPs (or DIPs).
In Figure 1 example, network programmers are required to deploy
the LB in the scope {Agg 3, Agg 4, ToR 3, and ToR 4} to balance the
table check_dst_ip {
enable_int = 1;
}
}
traffic from core switches to servers S5-S8. A stateful L4 LB has two
tables, VIPTable and ConnTable, as shown in Figure 1(c). For a given
connection’s packet 𝑐, if 𝑐’s VIP hits one of the items in ConnTable,
𝑐 is directly forwarded to the corresponding DIP; otherwise, the LB
identifies the DIP pool based on 𝑐’s VIP in the VIPTable, and installs
this ⟨VIP, DIP⟩ pair to ConnTable. For example, in Figure 1(c), all
the subsequent packets of the connection matching ⟨1.1.1.1:1234,
2.0.0.1:80, TCP⟩ in ConnTable get forwarded to 10.0.0.2:20.
If network programmers develop, deploy and maintain the above
two data plane programs with P4 (on Tofino and Silicon One) and
NPL (on Trident-4), three problems stem from the complexity in
both the languages and ASIC architecture.
Problem 1: Portability. It is hard to migrate a low-level pro-
gram from one ASIC to another. In Figure 1, initially, the network
programmers develop ingress and egress INT programs in P4 on
ToR switches. Despite that all ToR switches support P4, network
programmers have to develop INT programs for each ASIC be-
cause Tofino-032Q, Tofino-064Q, and Silicon One have quite dif-
ferent pipeline architectures and resource constraints. For exam-
ple, Tofino-064Q and Tofino-032Q have 12 and 24 match-action
units (MAUs) [7] and different memory sizes respectively, caus-
ing Tofino-032Q’s INT program in P4 that uses 18 MAUs compiles
unsuccessfully on Tofino-064Q, let alone on Cisco’s Silicon One;
so, per model tuning is a must. Even worse, in the aggregation
layer, the programmers rewrite the programs in NPL, because P4
ToR 1Tofino-064QTofino-032QS1S2S3S4ConnectionDIPfrom 1.1.1.1:1234to 2.0.0.1:80TCP10.0.0.2:20… … VIPDIP2.0.0.1:8010.0.0.1:2010.0.0.2:202.0.0.2:8010.0.1.3:33......from 1.1.1.1:1234to 2.0.0.1:80TCPfrom 1.1.1.1:1234to 10.0.0.2:20TCPmisshitinstallConnTableVIPTableToR iTofinoTrident-4Agg iAgg jToR jIn-Band Network Telemetry (INT)Stateful L4 Load BalancerL2 & L3 & TCP HeaderProbe HeaderToR j MetadataAgg j MetadataAgg i MetadataToR i MetadataPayloadL2 & L3 & TCP HeaderPayloadL2 & L3 & TCP HeaderProbe HeaderToR i MetadataPayloadL2 & L3 & TCP HeaderProbe HeaderAgg i MetadataToR i MetadataPayloadL2 & L3 & TCP HeaderProbe HeaderAgg j MetadataAgg i MetadataToR i MetadataPayloadTrident-4Silicon One(a)(b)(c)ToR 2Agg 1Trident-4Trident-4Agg 2ToR 3Silicon OneSilicon OneS5S6S7S8ToR 4Agg 3Trident-4Trident-4Agg 4Core 1TomahawkCore 2TomahawkCore kTomahawkSIGCOMM ’20, August 10–14, 2020, Virtual Event, NY, USA
Gao et al.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
>HEADER:
header_type int_probe_hdr_t { // Define header type
bit[8] hop_count;
...
}
packet in_pkt { fields { ... } }
>PIPELINES:
pipeline[INT]{int_in -> int_transit -> int_out};
pipeline[LB]{loadbalancer};
algorithm loadbalancer { // Define load balancer
load_balancing();
}
algorithm int_in { // Ingress INT
global bit[32][1024] packet_counter; // global variable
int_filtering();
if (int_enable) {
add_int_probe_header();
add_int_md_hdr();
}
}
algorithm int_transit { ... } // Transit INT
algorithm int_out { ... } // Engress INT
>FUNCTIONS:
func add_int_md_hdr() {
extern dict[128]
↩→ add_int_md_hdr_filter;
if (int_probe_hdr.msg_type in add_int_md_hdr_filter) {
add_header(int_md_hdr);
int_md.queue_len = get_queue_len();
int_info(int_info);
...
}
}
func load_balancing() {
extern dict[1024] conn_table;
extern dict[1024] vip_table;
hash = crc32_hash(ipv4.srcAddr, ipv4.dstAddr, ipv4.
↩→ protocol, tcp.srcPort, tcp.dstPort);
if (hash in conn_table) {
ipv4.dstAddr = conn_table[hash];
}
...
}
...
Figure 4: Lyra program for our motivating example.
cross-platform, network-wide programming language is missing at
present. This is our fundamental motivation to build Lyra.
2.2 Overview of Lyra Program & Workflow
Lyra enables programmers to efficiently program data plane. For ex-
ample, the network programmers can write a Lyra program shown
in Figure 4 for the case in Figure 1. By taking in this program, Lyra
compiler generates eight pieces of chip-specific code that compile
successfully on Agg 1-4 and ToR 1-4, while meeting the functional
correctness specified by the input Lyra program.
Lyra’s workflow. Figure 3 presents Lyra’s workflow. First, Lyra
takes as input: (1) a high-level Lyra program, (2) an algorithm scope
describing each algorithm’s placement, and (3) DCN topology and
configurations. Then, Lyra’s front-end generates a context-aware
intermediate representation (or context-aware IR), with important
information such as instruction dependency and deployment con-
straints. Finally, Lyra’s back-end uses the context-aware IR to syn-
thesize conditional implementations for different languages (e.g., P4
and NPL), and encodes various constraints in the form of SMT for-
mula. We solve the formula to get a solution that can be translated
into multiple pieces of chip-specific code.
Figure 3: Lyra workflow overview.
and NPL have different language features and ASIC architectures.
For example, Figure 2 shows the clear difference between the two
languages in implementing the flow filter function of INT—P4 has
to use two tables for matching both source and destination IPs,
while NPL uses one table with two lookups.
Problem 2: Extensibility. Low-level languages focus on how to
program individual ASICs, but a program is usually required to run
on top of multiple ASICs in a distributed setting. In Figure 1 exam-
ple, the programmers now need to deploy the stateful LB program
on Agg 3, Agg 4, ToR 3, and ToR 4. At the beginning, they only
need to write an NPL program implementing ConnTable, 𝑇𝑐, and
VIPTable, 𝑇𝑣, on both Agg 3 and Agg 4. As the number of traffic
connections increases, the programmers expand the size of 𝑇𝑐 by
modifying the NPL program. However, the new NPL program com-
piles unsuccessfully because the total size of 𝑇𝑣 and the expanded
ConnTable 𝑇 ′
𝑐 exceeds the resource constraints of Trident-4 ASIC.
The programmers, therefore, decide to move the VIPTable from
Agg 3 and Agg 4 to ToR 3 and ToR 4 by writing another P4 pro-
gram for 𝑇𝑣. It takes many hours for the programmers to make sure:
(1) the P4 program compiles well on Silicon One ASICs, and (2)
ConnTable and VIPTable can work together across switches. As
the number of connections continues to grow, the programmers
expand 𝑇 ′
𝑐 no
longer fit in a Trident-4 ASIC. In this tough case, the programmers
have to carefully split 𝑇 ′′
𝑐1 and
𝑇 ′′
𝑐2+𝑇𝑣 compilable on the corresponding ASICs, while coordinating
correctly. Obviously, the programmers spend a lot of effort and time
in the above depressing process.
Problem 3: Composition. It is non-trivial to make multiple low-
level programs co-exist well in a DCN. For example, in Figure 1,
any particular combination of INT and LB programs may result
in a complete restructure of each program and its deployment
arrangements. For example, once the programmers move too many
entries of ConnTable to the ToR switches, the program may not
compile successfully because of not only VIPTable but also ingress
and egress INT programs. As the number of deployed programs
increases, it would be much harder to find a “fittable” deployment.
Summary. The problems of portability, extensibility, and composi-
tion fundamentally undermine the manageability of programmable
DCNs, since network programmers will get trapped into endless
program reconstructions and numerous hardware details in daily
operations. The root cause of this dilemma is the direct use of
low-level, chip-specific programming languages, since a high-level,
𝑐 , making 𝑇 ′′
𝑐2, and make sure 𝑇 ′′
𝑐 again to get a bigger ConnTable, 𝑇 ′′
into 𝑇 ′′
𝑐1 and 𝑇 ′′
𝑐
Lyra ProgramChecker(Sec. 4.1)Topology & Configuration- IR instructions- Instruction dependency- Deployment constraintsSMTformulaSMT SolverPreprocessor(Sec. 4.2)Code Analyzer(Sec. 4.3)Lyra's Front-End… ...P4 Code(ToR1)NPL Code(Agg1)P4 Code(ToR3)Encoding(Sec. 5.4 - 5.6)Lyra's Back-EndLyra  CompilerAlgorithm Scope>_[ToR | -][Agg* | +]Synthesizer(Sec. 5.2 & 5.3)- Conditional    Implementation- ConstraintsTranslator(Sec. 5.7)SIGCOMM ’20, August 10–14, 2020, Virtual Event, NY, USA
the programmer needs to reduce the original 48-bit variable com-
parison to two 32-bit variable comparisons; on the contrary, the
programmer can use Lyra to directly write if(smac == dmac)
rather than handling the above low-level details in person, and
then Lyra compiler can automatically generate P4 code according
to the underlying ASICs’ restrictions. In Figure 5(b), the program-
mer implements a set of simple bitwise operations by introducing
multiple actions and tables in both P414 and P416 for assignment,
bitwise left shift and bitwise inclusive OR, due to the sequential
read-write dependency of ASIC-X. Using Lyra, on the other hand,
the programmer only needs to write: v16 = (v8_a « 8 | v8_b).
The above examples are similar to the memory allocation situ-
ations in C and assembly languages. If using assembly languages
(e.g., ARM and x86), we pay attention not only to the low-level
instructions (e.g., MOV and PUSH), but also to the usage of register
and memory; on the contrary, we can use higher-level C language
to express memory allocation by just writing a malloc.
3.2 Lyra’s Programmable Model
Lyra introduces a new programming model named one big pipeline,
or OBP. This programming model treats each data plane program
involving multiple algorithms as a single pipeline covering these al-
gorithms. OBP aims to avoid low-level details such as table-oriented
grammar (like P4). In Figure 1, INT is an OBP consisting of three
algorithms: ingress INT, transit INT, and egress INT, and stateful
L4 LB is another OBP. We can implement these two OBPs in a Lyra
program that must consist of three parts: (1) pipeline specification,
and (2) function, and (3) header definition.
Pipelines & algorithm definition (Line 8 in Figure 4). The OBP
allows the programmers to treat what they want to deploy as
a single pipeline that contains one or more algorithms. We use
pipeline to define an OBP, and use algorithm to specify each
algorithm in the OBP. In our motivating example, as an OBP, INT
has three algorithms: (1) int_in (defined in Lines 16-22 in Figure 4),
(2) int_transit (Line 23), and (3) int_out (Line 24), correspond-
ing to ingress, transit, and egress INT, respectively. On the other
hand, the stateful LB is another OBP which only has one algorithm,
defined in Lines 13-15 in Figure 4. In Lyra, we recursively specify
all the algorithms in an OBP. In Figure 4 example, we define these
two OBPs in Lines 9-10, respectively. Using the OBP abstraction,
the programmers only need to focus on what algorithms should be
involved in an OBP.
Function definition. An algorithm (e.g., int_in) may contain
multiple functions. In Lyra, the definition of each function is similar
to the C language. In Figure 4, Lines 36-43 define the only function
for the LB algorithm. Lyra also offers many predefined library-