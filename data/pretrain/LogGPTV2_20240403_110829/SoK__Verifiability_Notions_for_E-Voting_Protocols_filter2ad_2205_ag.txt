[18])
Universal
[18])
veriﬁability
(B,
veriﬁability
(B,
E2E veriﬁability (B, [18])
Veriﬁability goal (Intuition)
Flexible γ, with γk (k ≥ 0) being one example
γ∗
0 (The votes of all eligible (honest and dishonest)
voters who submit valid ballots are counted.)
γθ,k,Extr (θ,k ≥ 0) (Either (i) the published result
differs on less than k positions from the correct re-
sult (as extracted by Extr), or (ii) less than θ many
honest voters successfully cast their ballots, or (iii)
at least one of these honest voters complains if she
veriﬁes the ﬁnal result.)
γSV (If Reg or B are honest, then (i) the votes
of all honest voters who check are counted, and
(ii) further honest votes can only be dropped (not
manipulated), and (iii) only votes of eligible voters
are counted.)
γWV (If Reg and B are honest,
achieved.)
γIV (All honest voters’ valid ballots are pairwise
different.)
γUV ((Tally, P) published on B and Tally =
correct tally(B))
γIV ∧ γUV
then γ0
is
γIUV (γ0 and all honest voters’ ballots are pairwise
different.)
γIV (The ballots of all honest voter who check are
on B.)
γUV (The votes of all honest voters whose ballots
are on B are counted. Non-eligible voters are
allowed.)
γE2E (The votes of all honest voter who check are
counted. Non-eligible voters are allowed.)
Veriﬁability
tolerance
General trust
assumptions
Protocol classes
Yes
Yes
Yes
No
No
No
No
No
No
No
No
No
Flexible
hon(B)
hon(B)
Flexible
No speciﬁc structure required.
Assumes personal bulletin board for each protocol
participant. Only ”yes” or ”no” choices possible.
Otherwise no speciﬁc protocol structure.
Assumes speciﬁc (Setup, Cast, Tally, Result,
Verify) protocol structure. Requires extraction
property.
Assumes speciﬁc (Setup, Credential, Vote,
VerifyVote, Valid, Board, Tally, Verify)
protocol structure. Tally function with partial
tallying property.
hon(B)
Assumes speciﬁc (Setup, Vote, Tally, Verify)
protocol structure. Requires extraction property.
∧
hon(B)
(cid:6)
n
i=1 hon(Vi)
hon(B)
Requires bulletin board B. Assumes that all voters
verify. Otherwise no speciﬁc protocol structure.
Assumes speciﬁc structure and extraction
property for the deﬁnition of individual and
universal veriﬁability. Requires bulletin board B
for the E2E veriﬁability deﬁnition, otherwise no
speciﬁc protocol structure.
Table description: We group associated deﬁnitions. For each goal we have extracted from the deﬁnition, we include a short informal description.
The third column (”Veriﬁability tolerance”) states whether or not the associated veriﬁability deﬁnition allows for some tolerance: ”Yes” if δ ≥ 0
is allowed, ”No” if δ = 0 is required, with δ as in Deﬁnition 1. The fourth column (”General trust assumptions”) describes which protocol
participants are assumed to be always honest (besides the judge and the scheduler) and in the ﬁfth column (”Protocol classes”) requirements on
the protocol structure are listed, where extraction property is the requirement that single ballots and their content (i.e. the plain vote) can be
extracted from the bulletin board B.
result, for new classes of protocols often new deﬁnitions are
necessary.
Clearly, it is desirable for a veriﬁability deﬁnition to be
applicable to as many protocols as possible. It provides not
only reusability, but also comparability: by applying the same
deﬁnition to different protocols and protocol classes we can
clearly see the differences in the level and nature of veriﬁability
they provide. A very minimal set of assumptions on the
protocol structure is sufﬁcient to express a meaningful notion
of veriﬁability, as illustrated by the deﬁnition in Section IV and
also by the instantiation of the KTV framework given below.
Note, however, that some additional assumptions on the
protocol structure allow one to express some speciﬁc properties,
such as universal veriﬁability, which, as discussed in the
previous sections, on their own do not capture end-to-end
veriﬁability, but may be seen as valuable additions.
Static versus dynamic corruption. We observe that most of
the studied veriﬁability deﬁnitions focus on static corruption,
except the deﬁnitions in Sections VI and VII, which capture the
dynamic corruption of voters. In general, modeling dynamic
corruption can yield stronger security guarantees. In the context
of veriﬁability, one could, for example, provide guarantees not
only to honest voters but also to certain corrupted voters. If
a voter is corrupted only late in the election, e.g., when the
voting phase, one might still want to guarantee that her vote is
counted. None of the existing deﬁnitions provide this kind of
guarantee so far. We brieﬂy discuss how this can be captured
in the KTV framework in Section X-B.
Binary versus quantitative veriﬁability. As discussed in
Section III-B, the probability δ (see Deﬁnition 1) that under
realistic assumptions some cheating by an adversary remains
undetected may be bigger than 0 even for reasonable protocols:
often some kind of partial and/or probabilistic checking is
carried out, with Benaloh audits (see Section VII-G) being an
example. These checks might fail to detect manipulations with
some non-negligible probability. Still, as we have seen when
casting the different veriﬁability notions in the KTV framework,
most of the studied deﬁnitions assume the veriﬁability tolerance
to be δ = 0. This yields a binary notion of veriﬁability which,
as explained, outright rejects reasonable protocols.
In contrast, the deﬁnitions studied in the KTV framework
(including Section IV) as well as the ones in Sections V and
VI , allow for measuring the level of veriﬁability. This gives
more expressiveness and allows one to establish meaningful
791791
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:17:36 UTC from IEEE Xplore.  Restrictions apply. 
veriﬁability results for (reasonable) protocols which do not
provide perfect veriﬁability.
Goals. As pointed out in Section IV, the goal γ0, which,
among others, requires that all the ballots cast by honest voters
are correctly tallied and make it to the ﬁnal result is very strong
and typically too strong. In order to satisfy this goal very strong
trust assumptions are necessary, for instance, the assumptions
taken in the deﬁnition of weak veriﬁability in Section VII.
From the previous sections,
two main and reasonable
approaches for deﬁning a goal emerged, which one could
characterize as quantitative and qualitative, respectively:
Quantitative. In Section IV, a family of goals γk, k ≥ 0,
together with a non-zero tolerance level δ is considered;
a similar approach is taken in Section VI, but see the
discussion in this section. This approach, among others,
captures that the probability that more than k votes of
honest voters can be changed without anybody noticing
should be small, i.e., bounded by δ. To be more precise
and allow for stronger guarantees, this approach could be
combined with an aspect of the goal deﬁned for strong
veriﬁability, namely the distinction between votes that
are manipulated and those that are “just” dropped (see
Section VII).
Qualitative. In Section VII (“strong veriﬁability”), the protocol
goal (as cast in the KTV framework), among others,
stipulates that votes of voters who verify their receipt are
contained in the ﬁnal result. To be general, this approach
should also be combined with a non-zero tolerance level
δ (which, however, was not captured in the original
deﬁnition). The reason is that checks (such as Benaloh
challenges) might not be perfect, i.e., manipulation might
go undetected with some probability.
In both cases, votes of dishonest voters were restricted to be
counted at most once (no ballot stufﬁng).
The quantitative approach, on the one hand, provides overall
guarantees about the deviation of the published result from the
correct one and measures the probability δ that the deviation
is too big (bigger than k) but nobody notices this. On the
other hand, it does not explicitly require that voters who check
their receipts can be sure (up to some probability) that their
votes were counted. But, of course, to prove veriﬁability of a
system w.r.t. this goal, one has to take into account whether
or not voters checked, and more precisely, the probabilities
thereof. These probabilities also capture the uncertainty of the
adversary about whether or not speciﬁc voters check, and by
this, provides protection even for voters who do not check.
The qualitative approach explicitly provides guarantees for
those honest voters who verify their receipts. On the one hand,
this has the advantage that one does not need to consider
probabilities of voters checking or not, which simpliﬁes the
analysis of systems. On the other hand, such probabilities of
course play an important role for measuring the overall security
of a system, an aspect this simpler approach abstracts away.
Nevertheless, it provides a good qualitative assessment of a
system.
Interestingly, one could in principle combine both ap-
proaches, i.e., consider the intersection of both goals. While
this would give voters also in the quantitative approach direct
guarantees (in addition to the aspect of making a distinction
between manipulating and dropping votes, mentioned above
already), it would typically not really change the analysis and
792792
its result: as mentioned, in the quantitative analysis one would
anyway have to analyze and take into account the guarantees
offered when checking receipts.
Below, we provide concrete instantiations for both ap-
proaches in the KTV framework.
Ballot stufﬁng. Not all deﬁnitions of veriﬁabiltiy rule out
ballot stufﬁng, even though ballot stufﬁng, if unnoticed, can
dramatically change the election result. Some deﬁnitions go
even further and abstract away from this problem by assuming
that there are only honest voters (see trust assumptions below).
Clearly, allowing undetected ballot stufﬁng makes a veriﬁa-
bility deﬁnition too weak. We recommend that a veriﬁability
deﬁnition should exclude undetected ballot stufﬁng. It might
also be useful to capture different levels of ballot stufﬁng in
order to distinguish systems where it is very risky to add even
a small number of ballots from those where adding such a
small number is relatively safe. The goals discussed above, as
mentioned, both require that no ballot stufﬁng is possible at
all.
Trust assumptions. Some veriﬁability deﬁnitions assume
some protocol participants to be always honest, for example
the bulletin board (Sections V, VI, VIII, Appendix A, B),
or all voters (Appendix A) or all voter supporting devices
(Sections VIII, VII), or some disjunctions of participants
(Section VII); the deﬁnition discussed in Section IV does not
make such assumptions. We think that veriﬁability deﬁnitions
which rely on the unrealistic assumption that all voters are
honest are too weak. The other trust assumptions might
be reasonable depending on the threat scenario. A general
veriﬁability deﬁnition should be capable of expressing different
trust assumptions and make them explicit; embedding trust
assumptions into a deﬁnition not only makes the deﬁnition less
general, but also makes the assumptions more implicit, and
hence, easy to overlook.
Individual and universal veriﬁability.
In Section VIII and
Appendix B, deﬁnitions of individual and universal veriﬁability
were presented. We already pointed out that the split-up of
end-to-end veriﬁability into sub-properties is problematic. In
fact, K¨usters et al. [39] have proven that, in general, individual
and universal veriﬁability (even assuming that only eligible
voters vote) do not imply end-to-end veriﬁability, e.g. for
ThreeBallot [45]. For the deﬁnitions of individual and universal
veriﬁability presented in Section VII, it was shown in [18]
that they imply end-to-end veriﬁability under the assumption
that there are no clashes [39]. However, the notion of end-to-
end veriﬁability considered there is too weak since it allows
ballot stufﬁng. For the deﬁnitions of individual and universal
veriﬁability in Section VIII no such proof was provided, and
therefore, it remains unclear whether it implies end-to-end
veriﬁability. (In fact, technically these deﬁnitions, without some
ﬁxes applied, do not provide end-to-end veriﬁability as pointed
out in Section VIII.)
The (combination of) notions of individual and universal
veriﬁability (and other properties and subproperties, such as
eligibility veriﬁability, cast-as-intended, recorded-as-cast, and
counted-as-recorded) should not be used as a replacement for
end-to-end veriﬁability per se since they capture only speciﬁc
aspects rather than the full picture. Unless formally proven that
their combination in fact implies end-to-end veriﬁability they
might miss important aspects, as discussed above. Therefore,
the security analysis of e-voting systems should be based on the
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:17:36 UTC from IEEE Xplore.  Restrictions apply. 
notion of end-to-end veriﬁability (as, for example, concretely
deﬁned below). Subproperties could then possibly be used as
useful proof techniques.
B. Exempliﬁed Instantiation of the Guideline
We now demonstrate how the guidelines given above can be
put into practice, using, as an example, the KTV framework. By
this, we obtain a solid, ready-to-use deﬁnition of veriﬁability.