### No User Interaction
Our crawlers do not interact with the page, meaning we can only identify gadgets in code that is executed by default when the page loads.

### No Authentication
Our crawlers do not authenticate to the pages under test. As a result, we may miss results in authenticated sections of an application, significantly reducing the potential coverage of crawled web applications.

### Verification Does Not Focus on Mitigation Bypasses
In our study, we do not artificially add, modify, or remove any specific XSS mitigations from the crawled websites. We only verify that a data flow from a non-executing source can execute arbitrary code via a gadget, even in the presence of a given mitigation. This approach is taken because some mitigations, such as Web Application Firewalls (WAF) or Content Security Policy (CSP), require non-trivial configuration and can break functionality if applied automatically. Additionally, exploits need to be adapted to specific mitigation techniques. By focusing on the code execution aspect, we can more efficiently verify gadgets.

### False-Negative-Prone XSS Simulation Approach
In a real-world mitigation setting, the initial XSS attack should be blocked by preventing the execution of the injected code. However, even if the original injection is stopped, a gadget can still potentially execute the injected content, effectively bypassing the mitigation. For example, while script elements are initially blocked by CSP, they remain in the DOM and gadgets may reintroduce them, triggering them again. To avoid false-positive findings, we only generate exploits that do not trigger JavaScript execution by default. For instance, we use the `xmp` plaintext tag to transform the payload into a form that cannot execute by default. While this approach removes false positives, it may introduce a considerable number of false negatives, as changing the tag name (e.g., from `div` to `xmp`) might prevent the exploit from triggering the gadget correctly.

### Limitation Summary
These limitations should be considered when interpreting the following sections. Most importantly, the presented results are lower bounds. If deep crawling, user interaction, and less restrictive verification were applied, the resulting numbers would likely be higher.

## 5.4 Results

This section is divided into several subsections. After reporting on general crawling results, we present numbers and statistics about the detected data flows. Then, we report on the results of our automatic gadget verification and finally discuss the results in the context of XSS mitigation techniques.

### 5.4.1 Crawling Results
Our initial data set consisted of the Alexa top 5000 websites. By following first-level links, we crawled 647,085 web pages on the same domains or subdomains, which ultimately contained 37,232 different subdomains and 4,557 second-level domains. The number of second-level domains is lower than 5000 due to some entries in the Alexa Top Sites file redirecting to the same domain based on geolocation. For example, `google.it`, `google.de`, and `google.fr` all redirect to `google.com`. Additionally, some websites were not reachable or timed out during crawling, possibly due to regional CDNs. For all remaining pages, we collected data flows using our taint engine.

### 5.4.2 Taint Results
On average, we measured 7.67 sink calls per crawled URL and around 450 sink calls aggregated per second-level domain. In total, we counted 4,352,491 sink calls with data resulting from 4,889,568 unique sources within the DOM. Grouped by second-level domain, sink, and source, we measured 22,379 unique combinations.

### 5.4.3 Mitigation Results
We relate these results to XSS mitigations, particularly CSP 'unsafe-eval', CSP 'strict-dynamic', and HTML sanitizers.

#### Content Security Policy - 'unsafe-eval'
While 'unsafe-inline' almost completely removes the protection capabilities of a CSP policy, 'unsafe-eval' was previously seen as more secure. However, our study implies that this belief should be reconsidered. Gadgets can be used as an indirect way to reach an execution sink. If DOM content gets evaluated by default, an attacker can inject the code as a DOM node to abuse the eval-gadget and execute arbitrary code. In our data set, 47.76% of all second-level domains contained a data flow that ended within a JavaScript execution function. During our crawl, we unintentionally bypassed Tumblr’s CSP policy with a gadget bypassing its 'unsafe-eval' source expression.

#### Content Security Policy - 'strict-dynamic'
The 'strict-dynamic' source expression was added to CSP to increase the usability of nonce-based policies. It enables automatic trust propagation to child scripts. If a nonced, and thus legitimate, script appends a child script element to the DOM, the child script would be blocked unless the parent script propagates the nonce. When 'strict-dynamic' is enabled, trust is automatically propagated to non-parser-inserted script elements. Attackers may use gadgets to bypass CSP by injecting DOM content into a script element or a library function (e.g., jQuery.html) that creates and appends new script elements. In our data set, 73.03% of all second-level domains contained at least one data flow with the described characteristics. For example, we detected a gadget capable of bypassing 'strict-dynamic' in Facebook’s fbevents.js library.

#### Content Security Policy - Summary
Given the numbers and examples provided, we believe that 'unsafe-eval' and 'strict-dynamic' considerably weaken a CSP policy. Great care should be taken when using these source expressions.

#### HTML Sanitizers
Sanitizers aim to remove potentially malicious content by defining a known-good list of tags and attributes and removing anything else from a provided string. Our data set showed that 78.30% of all second-level domains had at least one data flow from an HTML attribute into a security-sensitive sink, with 59.51% exhibiting such flows from `data-` attributes. Furthermore, 15.67% executed data from `id` attributes and 10% from `class` attributes. Based on these numbers, we recommend revisiting the sanitization approach towards blocking `data-` attributes.

### 5.4.4 Gadget Results
Based on the identified data flows, we generated 1,762,823 gadget-based exploit candidates and validated 285,894 gadgets on 906 (19.88%) of all second-level domains.

## 6 Summary & Discussion
Our study has demonstrated that data flows from the DOM into security-sensitive functions are very frequent in modern applications and frameworks. In fact, 81.85% of all second-level domains exhibited at least one relevant data flow. We have shown that we can detect these flows and generate exploits capable of bypassing all modern XSS mitigations. In a fully automated fashion, we detected and verified gadgets on 19.88% of all second-level domains. However, due to our methodology, we believe this is just a lower bound for the real extent of the problem. By applying deeper crawling, authentication, user interaction, and a less conservative testing approach, the numbers would undoubtedly increase.

Given these results, we believe that current XSS mitigations are not well aligned with modern applications, frameworks, and vulnerabilities. We see three different ways to address the issue of script gadgets:

### 6.1 Fix the Mitigation Techniques
Making mitigation techniques gadget-aware is challenging due to the variety of expression languages, frameworks, libraries, and instances of user-land code. However, specific mitigations, such as HTML sanitizers, could start to filter `data-`, `id`, or `class` attributes.

### 6.2 Fix the Applications
Another approach is to fix the applications themselves. Popular libraries and frameworks could aim to remove gadgets to safeguard their users. However, given the extent of the problem, addressing this at scale is unlikely.

### 6.3 Shift from Mitigation to Isolation and Prevention Techniques
Due to our study's results, we believe the focus of web security engineers should shift from mitigation techniques towards isolation and prevention techniques. Promising proposals include Sandboxed Iframes, Suborigins, and Isolated Scripts. Additionally, the web needs to focus on XSS prevention techniques, such as providing secure-by-default APIs and language-based security concepts.

## 7 Related Work
### Client-Side XSS
While the source of the initial content injection can be caused by all classes of XSS, gadget-based attacks are rooted in insecure client-side data flows caused by JavaScript. The closest related class of vulnerabilities is client-side XSS, also known as DOM-based XSS. Previous studies have shown the prevalence of this type of XSS and proposed taint tracking-based protection mechanisms. However, most of our exploits have hybrid data flows spanning both the client and server, making taint-based techniques insufficient.

### Circumventing XSS Mitigations
The topic of undermining the protective capabilities of XSS mitigations has been explored previously. Zalewski outlined potential future directions in his essay "Postcards from the post-XSS world," touching on emerging techniques such as content infiltration, whitelist abuse, and web code reuse attacks. Research on browser-based XSS filters and Content Security Policy (CSP) has also exposed inherent weaknesses, motivating the design of various XSS mitigations.

## 8 Conclusion
In this paper, we comprehensively explored code-reuse attacks in web pages using script gadgets. Our empirical study uncovered that script gadgets are omnipresent in modern web code. Current XSS mitigations are unable to handle XSS attacks that leverage script gadgets, and there is no straightforward upgrade path to adapt current mitigation approaches. The high variance of script gadget form and functionality, due to the growing amount of custom client-side code and new client-side frameworks, prevents a comprehensive adaptation to address the problem.

This leads to a conundrum for the future of client-side web security. The last 15 years of difficulty in addressing XSS suggest that secure coding practices alone are insufficient. Sophisticated isolation techniques, safe code abstractions, and secure-by-default browser APIs may offer a way forward. Regardless of the paradigm, the next generation of XSS countermeasures must be capable of handling unexpected client-side execution and data flows caused by legitimate script gadgets.