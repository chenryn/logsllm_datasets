Let St = {st1, . . . , st(cid:96)} be the ordered sequence of statements in Linear(S), and let Π = {π1, . . . , πm}
be (a set of) multi-party protocols and let Σ = {σ1, . . . , σq} be (a set) of secret sharing schemes (in typical
10
scenarios such as [DSZ15; MR18; Cha+17; B¨us+18] q = m.) Note that sharings and protocols are very
diﬀerent objects: A protocol is a collection of interactive algorithms to be executed among multiple parties,
whereas a sharing scheme is a way to encode/distribute messages (typically protocol inputs and outputs)
among those parties. Additionally, although in the literature, protocols are assigned a unique sharing scheme,
this does not need to be the case. Therefore, for most generality, in the following we give the deﬁnition of
the cost model for arbitrary sets of protocols and sharings.
The cost model C takes into account running each node/simple-statement, plus the cost of conversions
between sharings. Formally a cost model C for a given (St, Π, Σ) is a set containing the following (cid:96) · m + q2
elements:
sti) ∈ B × Π × Z≥0, where intuitively, cπj
For each (i, j) ∈ [(cid:96)] × [m]: the triple (sti, πj, cπj
sti corresponds to
the cost of emulating in a ﬂow statement sti with protocol πj.
For each (i, j) ∈ Σ2: the triple (σi, σj, cσi2σj ) ∈ Σ × Σ × Z≥0, where intuitively, cσi2σj is the cost of
securely converting a sharing according to scheme σi into a sharing according to σj.
For brevity, and without loss of generality, whenever the sequence St, and set Π are clear from the context
we might use cπj
sti and cσi2σj instead of the setup of triples. Note that those costs are generic, in the sense
that they may be instantiated towards minimization of run time, or towards minimization of data transfer.
Furthermore, in all existing works on protocol mixing—including ours—each protocol πi is associated with
a single sharing scheme σi; in such cases, in slight abuse of notation, we will denote the conversion cost from
σi to σj as cπi2πj (instead of cσi2σj ). In fact, to further simplify our notation and consistently with the ABY
notation, for the three ABY protocol πA, πB, and πY, and for X, Z ∈ {A, B, Y} we will use cX2Z to denote the
conversion cost cπX 2πZ
from the sharing corresponding to πX (which we will refer to as Sharing X) to the
sharing corresponding πZ (which we will refer to as Sharing Z).
Generalized Cost Model: Amortization and Parallelization The above cost model does not account for the
beneﬁts of amortization and parallelization, and it therefore applies only to linearized code. Therefore, in
the following we refer to as the simple (or linearized) cost model. The OPA deﬁnition and solver from
Sections 4.2 and 5, respectively, are actually for linearized MPC. However, in Section 6 we extend our
treatment to natural schedulers and show how to (provably) optimally take advantage of amortization for
such schedulers. In fact, our implementation and benchmarks do use this scheduler. For completeness, we
discuss below how to generalize the cost model to account also for amortization.
sti) is generalized to a triple (sti, πj, fc
To derive a generalized cost model we modify the simple cost model as follows: every triple of the type
: N → Z≥0 is the amortized execution
(sti, πj, cπj
cost function, which on input (cid:96) ∈ N outputs the amortized cost fc
((cid:96)) of computing (cid:96) parallel copies of
sti with protocol πj. Similarly, every triple of the type (σi, σj, cσi2σj ) is replaced by a triple of the type
(σi, σj, fcσi2σj (·)), where fcσi2σj : N → Z≥0 is the amortized conversion cost function, which on input (cid:96) ∈ N
outputs the amortized cost fcσi2σj ((cid:96)) of converting (cid:96) sharings according to σi into sharings according to σj.
Using the same simpliﬁed notation as above, for X, Z ∈ {A, B, Y} we will use fcX2Z to denote the function
fcπX 2πZ from the sharing corresponding to πX to the sharing corresponding πZ. Naturally the costs of the
simple model corresponds to the output of the above functions on input (cid:96) = 1.
πj
sti
(·)), where fc
πj
sti
πj
sti
4.2 OPA for Linearized MPC
Having speciﬁed the (simple) cost model C we can now give a formal deﬁnition of the OPA problem. Here we
discuss the OPA problem for linearized MPC, which we term linearized OPA8 for which we give an eﬃcient
solver in the following section. The more general (non-linearized) case is then treated in §6.
To deﬁne linearized OPA we ﬁrst need to introduce the notion of a protocol assignment. Informally, a
protocol assignment is deﬁned on the sequence St = {st1, . . . , st(cid:96)} which is the CFG of Linear(S); it speciﬁes
what protocol should be assigned to each statement (node) sti. More concretely, a protocol assignment PA
8 Wherever clear from the context we might drop the adjective linearized and refer to the problem as OPA.
11
is a sequence of pairs of the type (st1, π1), . . . , (st|St|, π|St|), where (sti, πj) ∈ PA means that statement sti
is assigned protocol πj.
Clearly, the execution cost includes the sum of the costs of individual statements sti ∈ Linear(S). However,
we must take into account conversion cost—if PA assigns protocol πX to sti, which deﬁnes variable x, and
it assigns protocol πZ to stj which uses x, then PA entails conversion of x from Sharing X to Sharing Z.
Formalizing the above is somewhat tricky as we need to know usage dependencies between the statements
to place conversion points. Recall that def-use chains are pairs of the form (d, u) where d and u are nodes in
the control-ﬂow graph and u uses d. We need to place share conversion of deﬁnition d if there is at least one
use u that requires it. Importantly, since we consider Linear(S), each d executes exactly once and therefore,
a conversion can be placed immediately after d is executed. Informally, the execution cost is
(cid:80)
st +(cid:80)
st cπ
d cπi2πj
where the ﬁrst summation term accounts for the execution cost of all program statements, per the protocol π
assigned by PA to st, and the second term accounts for necessary conversions: as stated earlier, a conversion
at d is necessary if at least one use of d is assigned a diﬀerent protocol. Below, we formally deﬁne the cost
function that captures execution and conversion costs.
Let integer variables a(sti,πj ) ∈ {0, 1} denote whether sti ∈ Linear(S) is assigned protocol πj: a(sti,πj ) = 1
if (sti, πj) ∈ PA; a(sti,πj ) = 0 otherwise.
Let integer variables x(sti,πj ,πk) ∈ {0, 1} denote whether protocol assignment PA entails conversion of
the deﬁnition at node sti from (the sharing associated with) protocol πj into protocol πk. x(sti,πj ,πk) = 1
if it entails conversion, that is, there is at least one use of the variable deﬁned at sti that requires πk.
x(sti,πj ,πk) = 0 otherwise.
More precisely, let statement sti deﬁne variable x. Protocol assignment PA entails conversion of the
deﬁnition at node sti from πj into πk if and only if there exist node stl that uses x and
(a(stl,πk) − a(sti,πk)) · a(sti,πj ) = 1
The above equation (which is linear if and only if m = 2) states that the use statement stl is assigned πk
by PA (we have a(stl,πk) = 1), while the deﬁnition at statement sti is assigned πj (we have a(sti,πk) = 0
and a(sti,πj ) = 1) .
Therefore, the OPA problem becomes: ﬁnd protocol assignment PA and values of variables a(sti,πj ) ∈
{0, 1} and x(sti,πj ,πk) ∈ {0, 1} that minimize the objective function:
(cid:80)
sti +(cid:80)
a(sti,πj ) · cπj
sti,πj
x(sti,πj ,πk) · cπj 2πk (1)
sti,πj ,πk
subject to constraints
and
(cid:88)
πj∈Π
a(sti,πj ) = 1 for each node i
(2)
x(sti,πj ,πk) ≥ (a(stl,πk) − a(sti,πk)) · a(sti,πj )
(3)
for each def-use chain (sti, stl).
The ﬁrst term in the summation captures statement execution cost, and the second term captures con-
version cost. Note also, that we simplify the problem by assuming that each statement is assigned exactly
one protocol. 9 The assumption renders the problem cleaner. Speciﬁcally, a(stl,πk) − a(sti,πk) = 1 implies
conversion from πi at the deﬁnition to a πk at the use. If we allowed that a statement is assigned more than
πj∈Π a(sti,πj ) ≥ 1, then it would not be straightforward to capture conversion at the
one protocols, i.e., (cid:80)
deﬁnition: as more than one protocol at the deﬁnition can be used to convert to the protocol required at the
9 In some cases, it may be beneﬁcial to assign more than one protocol, e.g., πY and πA to the same statement, and
perform the computation with each protocol.
12
use, we would need to take the convert from the available protocol with minimal conversion cost to πk. In
the case of 2 protocols, which is our goal in this paper, we can relax this assumption.
We say that protocol assignment PA induces variable assignments a and x when those assignments satisfy
constraints (2) and (3).
The above integer program is non-linear if we allow for arbitrary protocols, but becomes linear if we
restrict it to two protocols, i.e., m = 2. For notational simplicity, we give the deﬁnition of the problem for
πi = πY and πi = πA, i.e., the (optimized) Yao and Arithmetic protocol from the ABY framework. This is
without loss of generality, and our treatment can be trivially applied to any combination of two protocols.
We further simplify notation by using asti to denote (the indicator variable) that PA assigns πA to sti,
and ysti to denote that it assigns πY to sti. We use xsti to denote that the deﬁnition at sti requires Y2A
conversion, and zsti to denote that sti requires A2Y conversion.
The (2-protocol, linearized) OPA problem becomes: ﬁnd a protocol assignment PA that minimizes
(cid:80)
sti∈St (asti · cA
(cid:80)
sti∈St (xsti · cA2Y + zsti · cY 2A)
+ ysti · cY
+
sti
)
sti
where
and
asti + ysti ≥ 1 for each node sti
xsti ≥ astl − asti for each def-use (sti, stl)
zsti ≥ ystl − ysti for each def-use (sti, stl)
From now on, we will denote this problem as IP Linear(S).
For our purposes constraint xsti ≥ astl − asti is equivalent to xsti ≥ (astl − asti ) · ysti.
In §5 we show how to eﬃciently solve the above linear integer program, as well as a related more eﬃcient
one deﬁned directly on MPC-source programs. Then in §6 we extend our treatement to a natural class of
non-linearized (i.e., parallelized) MPC-source programs. The extension to m > 2 is an interesting direction
for future research.
5 Solving the Linearized OPA
We now describe our eﬃcient linearized-OPA solver for two protocols (m = 2). Recall a solution to linearized
OPA is a solution to IP Linear(S) deﬁned in the previous section, which in turn describes an optimal protocol
(and share conversion) assignment for the linearized (straight-line) code. Formally, in this section we prove
the following theorem:
Theorem 1. Let IP Linear(S) be the integer program corresponding to the linearized OPA problem deﬁned
above, and let LP Linear(S) be its LP relaxation. The optimal solution to LP Linear(S) is integral, and therefore
also the optimal solution to IP Linear(S).
In a nutshell, the above theorem is proved by showing that the constraint matrix of LP Linear(S) satisﬁes a
property known as total unimodularity (cf. Deﬁnition 2); a theorem from combinatorial optimization implies
then that its solution is in fact integral [Sch03].
We remark that although theoretically interesting, and against what was previously conjectured, having
an eﬃcient (polynomial) solver for IP Linear(S) does not necessarily yield a practical MPC protocol mixer.
Indeed, since in linearized MPC loops are entirely unrolled, the corresponding representation might end up
having millions of statements and therefore millions of constraints, hindering scalability of the LP Linear(S)
solver.
Therefore, we devise a solver that solves a smaller integer program over MPC-source, denoted by
IP CMPC(S). We stress that existing frameworks compute protocol assignments, at most as optimal as a
solution to IP CMPC(S); indeed, in ABY, the manual protocol assignment is made on the source code, which is
essentially MPC-source. In fact, in Theorem 3 we prove that this is always the case under natural conditions
13
on the optimal assignment computed by IP Linear(S). Since st nodes in Linear(S) that map to the same n
in CMPC(S) appear in identical contexts of execution in diﬀerent iterations of the loop, we conjecture that
the above statement holds even unconditionally, i.e., if a protocol assignment is optimal in one context, the
same assignment will be optimal in the other. We note in passing that although making the treatment more
involved, devising such a scalable solver is essential for deriving a practical solution to the problem. Addi-
tionally, following the same structure of the proof of unimodularity of the constraint matrix of IP CMPC(S),
we can directly devise a proof of unimodularity of the constraint matrix of IP Linear(S), thereby proving the
result above.
The remainder of this section is organized as follows: In §5.1 we describe IP CMPC(S), where §5.1 describes
the parameters of the IP CMPC(S) integer program, and §5.1 and §5.1 describe the constraints and objective
function. As in the previous section, to keep notation simple we focus on the two protocols, namely arithmetic
(πA) and Yao-based (πY). In §5.2 we prove our main result that due to the structure of IP CMPC(S) its LP
relaxation yields an integral solution; this means that we can use standard eﬃcient LP solvers to solve
IP CMPC(S); ﬁnally, in §5.3 we prove that the solution to IP CMPC(S), under natural conditions, is also a
solution to IP Linear(S). Due to limited space, the proofs have been moved to Appendix D.
5.1 Deﬁning IP CMPC(S)
IP CMPC(S) is an integer program over MPC-source. It entails a signiﬁcantly smaller number of variables and
constraints, and therefore accepts a more scalable solver. (There are O(N ) nodes in MPC-source compared
to O(bDN ) nodes in Linear(S), where b is the maximum loop bound and D is the loop nesting depth.) When
no amortization is considered, the costs of executing and converting all st ∈ Linear(S) that map to the same
n ∈ CMPC(S) is the same. As we show in §5.3, if we constrain IP Linear(S) to the same ast and yst for all st
that map to the same n ∈ CMPC(S), the optimal solution of IP CMPC(S) is the optimal solution of IP Linear(S)
as well.
The Cost Model for IP CMPC(S)
Since we do not have parallelization/amortization, IP CMPC(S) has a simple cost model as deﬁned in the
previous section. Concretely,
(1)
n denotes the cost to run node n ∈ CMPC(S) using πA.
cA
cY
n denotes the cost to run node n using πY.
cA2Y denotes the cost to run A2Y conversion.
cY 2A denotes the cost to run Y2A conversion.
(2)
(3)
(4)
Variables and Constraints We follow [Cho+07] to deﬁne variables and constraints. Let variables an and
yn be integers in the interval {0, 1}, as in IP Linear(S) we deﬁned in §4.2. They denote whether node n executes
with πA (using Arithmetic sharing) or with πY (using Yao sharing). an = 1 if n runs using Arithmetic sharing,
and an = 0 if n runs using πY sharing. To enforce that each node must execute at least once, we introduce
constraint
an + yn ≥ 1
(1)
Let integer program variable x(d,u) ∈ {0, 1} denote whether (d, u) requires Y2A conversion of x, that is, d
computes x using πY sharing only, but u, which uses x, computes using Arithmetic sharing, and thus requires
conversion of x to Arithmetic. Analogously, let z(d,u) ∈ {0, 1} denote whether (d, u) requires A2Y conversion.
z(d,u) = 1 if it does, and z(d,u) = 0 if it does not. Intuitively, the following constraints would account for this:
x(d,u) ≥ au − ad