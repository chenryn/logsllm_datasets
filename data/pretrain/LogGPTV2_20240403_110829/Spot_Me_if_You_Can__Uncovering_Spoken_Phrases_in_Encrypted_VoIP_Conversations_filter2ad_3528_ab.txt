phrases in encrypted trafﬁc possible. To illustrate
the patterns that occur in the stream of packet sizes
when a certain word is spoken, we examined the
sequences of packets generated by encoding sev-
eral utterances of the words “artiﬁcial” and “intel-
ligence” from the TIMIT corpus [10]. We repre-
sent the packets for each word visually in Figures 3
and 4 as a data image—a grid with bit rate on the
y-axis and position in the sequence on the x-axis.
Starting with a plain white background, we darken
the cell at position (x, y) each time we observe a
packet encoded at bit rate y and position x for the
given word.
In both graphs, we see several dark
gray or black grid cells where the same packet size
is consistently produced across different utterances
of the word, and in fact, these dark spots are closely
related to the phonemes in the two words. In Fig-
ure 3, the bit rate in the 2nd - 5th packets (the “a”
in artiﬁcial) is usually quite high (35.8kbps), as we
would expect for a vowel sound. Then, in packets
12 - 14 and 20 - 22, we see much lower bit rates for
the fricative “f” and affricative “sh”. Similar trends
are visible in Figure 4; for example, the “t” sound
maps consistently to 24.6 kbps in both words.
In the next section we detail how an eavesdrop-
per who knows the phonetic transcription of her tar-
get phrase can compute the expected sequence of
packet sizes that will be transmitted when a VoIP
caller speaks the phrase. We also discuss how she
can use this sequence to recognize the phrase when
is spoken in a conversation.
3 Spotting Phrases with Proﬁle HMMs
Our goal in this work is to recognize spoken
words or phrases in encrypted VoIP conversations,
using only minimal knowledge of what the actual
audio content of the phrase should sound like. In
fact, the techniques we develop here do not require
knowledge of the identity of the speaker or any
examples of the audio produced by speaking the
target word or phrase. However, for ease of ex-
position, we begin the discussion of our machine
learning techniques by ﬁrst addressing a much
easier scenario, where the attacker does have ac-
cess to several recordings of the target phrase be-
ing spoken, though not necessarily by the target
speaker. Later, we show how these techniques can
be adapted to handle the more challenging case
where the attacker may have no recordings of the
words in the phrase she wishes to detect.
38
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:12:02 UTC from IEEE Xplore.  Restrictions apply. 
3.1 How to recognize a previously
seen word or phrase
If we assume that the same sequence of packet
sizes is produced each time a given word is spoken,
then the problem of identifying instances of that
word can be reduced to a substring matching prob-
lem. However, human speech is known to exhibit a
high degree of variability, and the adaptive com-
pression performed by the codec may contribute
additional variance to the resulting stream of packet
sizes. To handle this variation, we can instead ap-
ply matching algorithms from the speech recogni-
tion and bioinformatics communities.
In both of
these areas, techniques based on hidden Markov
models [20] have proven to be also be extremely
useful [40, 7]—especially when the training data
itself may exhibit high variability.
In particular, the common bioinformatics prob-
lem of searching a protein database for fragments
of known protein families is similar in many ways
to searching a stream of packet sizes for instances
of a word or phrase. Proteins are made up of 20 dif-
ferent amino acids; in wideband mode, the Speex
codec produces 21 distinct packet sizes. There
may be signiﬁcant variation between proteins in the
same family or between different utterances of the
same phrase. Therefore, in this paper, we adapt
proﬁle hidden Markov model techniques [8], which
were originally developed for performing multi-
ple sequence alignment of protein families and for
searching protein databases [16], to the task of ﬁnd-
ing words and phrases in encrypted VoIP. The gen-
eral outline of our strategy is as follows: (1) build
a proﬁle HMM for the target phrase; (2) transform
the proﬁle HMM into a model suitable for perform-
ing searches on packet sequences; and (3) apply
Viterbi decoding [37] on the stream of packets to
ﬁnd subsequences of packets that match the proﬁle.
We elaborate on each of these steps below.
Building a Proﬁle HMM A proﬁle HMM [7]
(Figure 5) consists of three interconnected chains
of states, which describe the expected packet
lengths at each position in the sequence of en-
crypted VoIP packets for a given phrase. The Match
Figure 5. Proﬁle HMM [7]
states, shown in Figure 5 as squares, represent the
expected distribution of packet sizes at each posi-
tion in the sequence. Insert states, shown as dia-
monds, and Delete states, shown as circles, allow
for variations from the typical sequence. The Insert
states emit packets according to a uniform distribu-
tion or some other distribution that represents the
overall frequencies of packet sizes in VoIP streams,
and thus they allow for additional packets to be “in-
serted” in the expected sequence. Delete states are
silent, meaning that they simply transition to the
next state without emitting any packets; doing so
allows for packets that are normally present to be
omitted from the sequence.
Initially, the Match
states’ emission probabilities are set to a uniform
distribution over packet sizes, and the transition
probabilities in the model are set so as to make the
Match states the most likely state in each position.
Given an initial model and a set of example se-
quences of packets for the target phrase, there is
a well-known Expectation-Maximization [5] algo-
rithm due to Baum and Welch [3] that uses dynamic
programming to iteratively improve the model’s pa-
rameters to better represent the given training se-
quences. This algorithm is guaranteed to ﬁnd a
locally optimal set of parameters that maximizes
the likelihood of the model given the training se-
quences. Unfortunately, parameters chosen via this
method are not guaranteed to be globally optimal,
and often the difference between local optima and
the global optimum is substantial. Therefore, we
apply simulated annealing [15] in the Baum-Welch
algorithm to decrease the risk of not progressing
out of a local optimum. After this algorithm has
converged, we apply Viterbi training [38] to the re-
39
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:12:02 UTC from IEEE Xplore.  Restrictions apply. 
position is much more likely than the others.
To ﬁnd instances of our target phrase in the se-
quence of packets from a VoIP conversation, we use
the Viterbi algorithm [37] to ﬁnd the most likely
sequence of states in the model to explain the ob-
served packet sizes. Each subsequence of states
which belong to the proﬁle part of the model is
called a hit, and is potentially an instance of the tar-
get phrase. To evaluate the goodness of each hit, we
compare the likelihood of the packet lengths given
the proﬁle model, versus their likelihood under the
overall distribution from the Random state. More
formally, we calculate the log odds score for a hit
consisting of packet lengths !i, ...,! j, as
scorei,j = log P (!i, ...,! j|P rof ile)
P (!i, ...,! j|Random)
(1)
Intuitively, this score tells us how well the pack-
ets match our model, and we discard any hit whose
score falls below a given threshold. We return to
how to set these thresholds in Section 4.
3.2 Recognizing phrases without
example utterances
In the previous section, we made the simplify-
ing assumption that the adversary could build her
models using several audio recordings of each word
or phrase she wanted to detect. However, in prac-
tice, this assumption is far from realistic. Because
of the distribution of words in natural language,
even in very large corpora, there will be many
words that occur only a few times, or not at all.
The speech recognition community has developed
efﬁcient techniques for constructing word models
without the need for labeled training examples of
every word.
In this section, we show how simi-
lar strategies can be applied to our task of spotting
words in encrypted VoIP, even when the eavesdrop-
per has never actually heard any of the words in the
target phrase.
The techniques in this section rest on the idea
that all spoken words in a language are formed by
concatenating phonemes, much like words in writ-
ten language are formed by making strings of let-
ters. In a phonetic acoustic model of speech (c.f.,
Figure 6. Search HMM [7]
sulting model to further reﬁne its parameters for use
in searching streams of packets for the given target
phrase. While this last step is not guaranteed to ﬁnd
an optimal set of parameters, it does maximize the
contribution of the most likely sequences of states
to the model’s likelihood, and it is widely used in
bioinformatics applications for training the models
used in searching protein databases [7].
Searching with a Proﬁle HMM In an encrypted
VoIP call, packets for the target phrase will be sur-
rounded by packets that comprise the rest of the
conversation. To isolate the target phrase from its
surroundings, we add 5 new states to the standard
proﬁle HMM to create a search HMM (Figure 6).
The most important new state is the Random state,
shown in Figure 6 as a diamond because it, like the
Insert states, emits packets according to a uniform
or other “random” distribution. When we search
a stream of packets, the Random state will match
packets that are not part of the phrase of interest,
and the states in the proﬁle part of the model will
match the packets in the target phrase. Two new
silent states, called the Proﬁle Start and Proﬁle End
states, are shown in Figure 6 as circles. They al-
low for transitions between the Random state and
the proﬁle part of the model. Because we want
to ﬁnd only instances of the entire target phrase,
transitions from the Proﬁle Start state are weighted
such that the transition to the Match state in the ﬁrst
40
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:12:02 UTC from IEEE Xplore.  Restrictions apply. 
Chapter 3 of [12]), small, proﬁle-like HMMs are
trained to represent the sounds that correspond to
each phoneme. Then, to construct a word HMM,
the HMMs for the phonemes used to pronounce
the word are concatenated to form a long, proﬁle-
like chain of states that represents the sequence of
sounds in the word. Similarly, phrase HMMs are
constructed by concatenating word models. Typi-
cally, the sequence of phonemes used to pronounce
each word is taken from a phonetic pronunciation
dictionary such as [14], although they may also be
taken from the pronunciatons given in a standard
English dictionary. Because these pronunciation
dictionaries are relatively easy to create and can
be stored as plain text ﬁles, it is much easier and
cheaper to obtain a large-vocabulary pronunciation
dictionary than to obtain a corpus of speech record-
ings for the same words.
Building phrase models from phonemes One
straightforward method for building our word and
phrase models from phonemes would be to train
a proﬁle HMM for the packets produced by each
phoneme, and then concatenate phoneme models in
the proper order to construct word HMMs. Phrase
HMMs could be similarly constructed by concate-
nating word HMMs. The main shortcoming of this
technique is that words often have several different
possible pronunciations. These differences could
be attributed to variation between dialects or be-
tween individual speakers, or because of the con-
text of the surrounding words.
Instead, to build our models, we use a heuris-
tic that simultaneously retains the simplicity and
efﬁciency of the basic proﬁle HMM topology and
the techniques outlined in the previous section, yet
captures a wide range of pronunciations for each
word. This novel approach affords us great ﬂex-
ibility in ﬁnding an essentially unlimited number
of phrases. We use a phonetic pronunciation dic-
tionary, together with a library of examples of the
packet sequences that correspond to each phoneme,
to generate a synthetic training set for the phrase in
question. Then, using this synthetic training set in
place of actual instances of the phrase, we can train
a proﬁle HMM and use it to search VoIP conversa-
tions just as described in Section 3.1.
To generate one synthetic sequence of packets
for a given phrase, we begin by splitting the phrase
into a list of one or more words. For each word
in the list, we replace it with the list of phonemes
taken from a randomly-selected pronunciation of
the word from our phonetic pronunciation dictio-
nary. For example, given the phrase “the bike”, we
look up “the” and “bike” in our pronunciation dic-
tionary and get the phonemes “dh ah” and “b ay k”,
giving us a sequence of 5 phonemes: “dh, ah, b, ay,
k”. Then, for each of the phonemes in the resulting
list, we replace it with one example sequence of
packets sizes taken from our library for the given
phoneme.
Improved Phonetic Models Because the sounds
produced in a phoneme can vary signiﬁcantly de-
pending on the phonemes that come immediately
before and immediately after, it is essential that we
estimate packet distributions based on the diphones
(pairs of consecutive phonemes) or triphones (three
consecutive phonemes), rather than the individual
phonemes in the phrase. To do so, we start by
grouping the phonemes in the phrase into groups of
three, so that the triphones overlap by one phoneme
on each end. So, for example, from our sequence
of phonemes
dh, ah, b, ay, k
we get the triphones
(dh, ah, b), (b, ay, k)
We then check the resulting list of triphones to
make sure that we have sufﬁcient examples in our
library for each triphone in the list. If the library
contains too few examples of one of the triphones,
we split it into two overlapping diphones. So, in
our example, if we have no examples of the tri-
phone (dh, ah, b), we replace it with the diphones
(dh, ah) and (ah, b), giving us the sequence
(dh, ah), (ah, b), (b, ay, k)
Similarly, we replace any diphones lacking sufﬁ-
cient training data with single phonemes. As this
small example illustrates, this technique allows us
41
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:12:02 UTC from IEEE Xplore.  Restrictions apply. 
Figure 7. Overview of training and detection process
to use a better phonetic model, using triphones, for
sequences of phonemes for which we have several
examples in our library, yet allows a great deal of
ﬂexibility for combinations of words or sounds that
we have not seen before. For instance, if the train-
ing corpus in our example does not contain “the
bike”, but it does have examples of people saying
“the” (dh, ah), “a bird” (ah, b, er, d), and “bicam-
eral” (b, ay, k, ae, m, ax, r, ax, l), we can still derive
a good model for the packets that will occur when
a VoIP caller says “the bike”.
Putting it all together To identify a phrase with-
out using any examples of the phrase or any of
its constituent words, we apply this concatenative
synthesis technique to generate a few hundred syn-
thetic training sequences for the phrase. We use
these sequences to train a proﬁle HMM for the
phrase and then search for the phrase in streams
of packets, just as in the previous section. An
overview of the entire training and detection pro-
cess is given in Figure 7.
4 Evaluation
To evaluate our phrase spotting technique, we
focus our efforts on assessing the impact of various
features of the underlying audio on phrase spotting
performance, and examine the ability of an attacker
to detect the presence of phrases in an encrypted
packet stream. In our experiments, we use audio
recordings from the TIMIT continuous speech cor-
pus [10], one of the most widely used corpora in the
speech recognition community. The TIMIT corpus
contains 6,300 phonetically rich English sentences
spoken by a total of 630 people—462 speakers ran-
domly selected by the corpus’ creators as a training
set and the remaining 168 speakers designated as a
test set. Speakers in the data set include males and
females with eight distinct regional dialects from
across the continental United States. Both the test
and training sets include all gender and region com-
binations.
One of the most appealing features of TIMIT for
our evaluation is that it includes time-aligned pho-
netic transcriptions of each sentence, denoting the
start and end of each phoneme. After encoding the
audio in the training set with Speex in wideband
VBR mode, we use these phonetic transcriptions
to build our library of packet sequences that corre-
spond to each phoneme, diphone, and triphone in
the training set.
Experimental Setup To evaluate the effective-
ness of our phrase spotting techniques, we use the
TIMIT training data to build HMMs to search for
122 target sentences. We simulate VoIP conversa-
tions for each of the speakers in the TIMIT test set
by taking two copies of each of the speaker’s sen-
tences, and concatenating all of them in a random
order. We create ﬁve of these simulated conversa-
tions for each speaker to minimize any impact of
the sentences’ location in the conversation on the
performance of our algorithms.
We then encode the simulated conversations
with wideband Speex in VBR mode and use the
HMMs to search for instances of each phrase