randomized in Windows’ ASLR implementation and must be
known by an attacker. Since the PA and VA for bits 30 to 0 are
identical in the kernel region, it is also sufﬁcient to know bits
16 to 12 of the physical address. This bit range overlaps with
the L3 cache index. In other words: if the L3 cache index is
known, then an attacker can tell the virtual base address of the
kernel.
We used cache probing to extract parts of the physical address
of the system call handler KiFastCallEntry. The offset
from this function to the kernel’s base address is static and
known. If we know the address of this function, then we also
know the base address of the kernel (and HAL).
We performed the following steps for all cache sets i:
1) Execute sysenter with an unused syscall number.
2) Evict cache set i using the eviction buffer.
3) Execute sysenter again and measure the duration.
The unused syscall number minimizes the amount of executed
kernel mode code since it causes the syscall handler to imme-
diately return to user mode with an error. Step 1 makes sure
that the syscall handler is present in the caches. Step 2 tries to
evict the syscall handler code from the cache. Step 3 measures
if the eviction was successful. If we hit the correct set i, then
the second sysenter takes considerably longer and from i
we can deduce the lower parts of the physical address of the
syscall handler. Along with the address of the kernel region,
this yields the complete virtual address of the syscall handler,
and thus the base of the entire kernel and the HAL.
We performed extensive tests on the machine powered by
an Intel i7-870 (Bloomﬁeld) processor. We executed the cache
probing attack 180 times; the machine was rebooted after each
test and we waited for a random amount of time before the
measurements took place to let the system create artiﬁcial noise.
Figure 5 shows the cache probing measurements. The x-axis
consists of the different L3 cache sets (8, 192 in total) and
the y-axis is the duration of the second system call handler
invocation in CPU clocks, after the corresponding cache set
was evicted. The vertical dashed line indicates the correct value
where the system call handler code resides. There is a clear
cluster of high values at this dashed line, which can be used to
extract the correct cache set index and thus parts of the physical
(and possibly virtual) address. We were able to successfully
determine the correct syscall handler address in each run and
there were no false positives. The test is fast and generally takes
less than one second to ﬁnish.
3) Discussion: For successful cache probing attacks, an
adversary needs to know the physical addresses of the eviction
buffer, at least those bits that specify the cache set. Furthermore,
she somehow has to ﬁnd out the corresponding virtual address
of the kernel module from its physical one. This problem is
currently solved by using large pages for the buffer, since
under Windows those always have the lowest bits set to 0.
Therefore, their ﬁrst byte always has a cache index of 0 and
all following ones can be calculated from that. However, this
method does not work with Sandybridge processors, since there
we need to know the complete physical address as input to the
hash function that decides on which cache slice an address is
mapped. Furthermore, allocating large pages requires a special
right under Windows (MEM_LARGE_PAGES), which ﬁrst has
Figure 5. Cache probing results for Intel i7-870 (Bloomﬁeld)
198
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:55:20 UTC from IEEE Xplore.  Restrictions apply. 
space multiple times and only use the observed minimal access
time for each page to reduce measurement inaccuracies. Figure 6
shows measurement results on an Intel i7-950 (Lynnﬁeld) CPU
for eight measurements, which we found empirically to yield
precise results. The dots show the minimal value (in CPU
clocks) observed on eight runs. The line at the bottom indicates
which pages are actually allocated in kernel space; a black bar
means the page is allocated. As one can see, there is a clear
correlation between the timing values and the allocation that
allows us to infer the kernel memory space.
We developed an algorithm that reconstructs the allocation
from the timing values. In the simplest case, we can introduce
a threshold value that differentiates allocated from unallocated
pages. In the above example, we can classify all timing val-
ues below 5, 005 clocks as allocated and all other values as
unallocated as indicated by the dashed line. This yields a high
percentage of correct classiﬁcations. Depending on the actual
CPU model, this approach might induce insufﬁcient results due
to inevitable overlap of timing values and thus other recon-
struction algorithms are necessary. We implemented a second
approach that aims at detecting transitions from allocated to
unallocated memory by looking at the pitch of the timing curve,
a straightforward implementation of a change point detection
(CPD) algorithm [40]. Further measurement results and ﬁgures
displaying the results are shown in Appendix B.
1) Evaluation Results: We evaluated our double page fault
based approach on the three Intel CPUs and the virtual machine,
Table 2 shows a summary of the results. We employed the
threshold algorithm on CPU (1) and the CPD algorithm on
platforms (2)–(4). The numbers shown in the table are the
average out of ten runs for each machine. Between each run, we
rebooted the operating system to make sure that the kernel space
allocation varies. We took a snapshot of the allocation with the
help of a custom driver before we started the measurements to
obtain a ground truth of the memory layout. Since the allocation
might change while the measurements are running, the correct-
to be acquired somehow. One possible way to overcome this
problem is to exploit an application that already possesses this
right.
In case of non-Sandybridge processors, large pages are not
needed per se. It is only necessary to know the physical start
address of the eviction buffer. More generically,
is only
necessary to know parts of the physical base address of one
user space address, since this can then be used to align the
eviction buffer. Our experiments have shown that these parts of
the physical base address of the common module ntdll, which
is always mapped to user space, is always constant (even after
reboots). Though the concrete address varies depending on the
hardware and loaded drivers and is thus difﬁcult to compute,
the value is deterministic.
it
B. Second Attack: Double Page Fault
The second attack allows us to reconstruct the allocation of
the entire kernel space from user mode. To achieve this goal,
we take advantage of the behavior of the TLB cache. When we
refer to an allocated page, we mean a page that can be accessed
without producing an address translation failure in the MMU;
this also implies that the page must not be paged-out.
The TLB typically works in the following way: whenever
a memory access results in a successful page walk due to a
TLB miss, the MMU replaces an existing TLB entry with the
translation result. Accesses to non-allocated virtual pages (i.e.,
the present bit in the PDE or PTE is set to zero) induce a page
fault and the MMU does not create a TLB entry. However, when
the page translation was successful, but the access permission
check fails (e.g., when kernel space is accessed from user mode),
a TLB entry is indeed created. Note that we observed this
behavior only on Intel CPUs and within the virtual machine.
In contrast, the AMD test machine acted differently and never
created a TLB entry in the mentioned case. The double page
fault method can thus not be applied on our AMD CPU.
The behavior on Intel CPUs can be exploited to reconstruct
the entire kernel space from user mode as follows: for each
kernel space page p, we ﬁrst access p from user mode. This
results in a page fault that is handled by the operating system
and forwarded to the exception handler of the process. One of
the following two cases can arise:
• p refers to an allocated page: since the translation is
successful, the MMU creates a TLB entry for p although
the succeeding permission check fails.
• p refers to an unallocated page: since the translation fails,
the MMU does not create a TLB entry for p.
Directly after the ﬁrst page fault, we access p again and
measure the time duration until
is
delivered to the process’s exception handler. Consequently, if
p refers to an allocated kernel page, then the page fault will be
delivered faster due to the inherent TLB hit.
this second page fault
Due to the many performance optimizations of modern CPUs
and the concurrency related to multiple cores, a single measure-
ment can contain noise and outliers. We thus probe the kernel
Figure 6.
(Lynnﬁeld) CPU
Example of double page fault measurements for an Intel i7-950
199
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:55:20 UTC from IEEE Xplore.  Restrictions apply. 
CPU model
(1) i7-870 (Bloomﬁeld)
(2) i7-950 (Lynnﬁeld)
(3) i7-2600 (Sandybr.)
(4) VMware on (1)
Correctness
96.42%
99.69%
94.92%
94.98%
Runtime
17.27 sec (8 it.)
18.36 sec (8 it.)
65.41 sec (32 it.)
72.93 sec (32 it.)
RESULTS FOR DOUBLE PAGE FAULT TIMINGS
Table II
CPU model
(1) i7-870 (Bloomﬁeld)
(2) i7-950 (Lynnﬁeld)
(3) i7-2600 (Sandybridge)
(4) VMware on (1)
(1) with signatures of (2)
Matches
21
9
5
18
9
Code size
7,431 KB
4,184 KB
1,696 KB
7,079 KB
2,312 KB
EVALUATION OF ALLOCATION SIGNATURE MATCHING
Table III
ness slightly decreases because of this effect. Nevertheless, we
were able to successfully reconstruct the state of at least 94.92%
of all pages in the kernel space on each machine. With the
help of memory allocation signatures (a concept we introduce
next) such a precision is easily enough to exactly reconstruct
the location of many kernel components.
The average runtime of the measurements varies between 18
and 73 seconds and is therefore within reasonable bounds. One
iteration is one probe of the entire kernel space with one access
per page. As noted above, we empirically found that more than
eight iterations on Nehalem CPUs do not produce better results.
For Sandybridge and VMware, more iterations yielded more
precise results, mainly due to the fact that there was more noise
in the timings.
2) Memory Allocation Signatures: The double page fault
timings yield an estimation for the allocation map of the kernel
space, but do not determine at which concrete base addresses
the kernel and drivers are loaded to. However, the allocation
map can be used, for example, to spot the kernel region (i.e.,
the memory area in which the kernel and HAL are loaded) due
to the large size of this region, which can be detected easily.
One could argue that, since the virtual size of each driver is
known, one could ﬁnd driver load addresses by searching for
allocated regions which are exactly as big as the driver image.
This does not work for two reasons: ﬁrst, Windows kernel space
ASLR appends most drivers in speciﬁc memory regions and thus
there is usually no gap between two drivers (see Section II-A).
Second, there are gaps of unallocated pages inside the driver
images as we explain next.
it
In contrast to the kernel region, Windows drivers are not
mapped using large pages but using the standard 4 KB page
granularity. Code and data regions of drivers are unpageable
by default. However,
is possible for developers to mark
certain sections inside the driver as pageable to reduce the
memory usage of the driver. Furthermore, drivers typically have
a discardable INIT section, that contains the initialization code
of the driver which only needs to be executed once. All code
pages in the INIT section are freed by Windows after the driver
is initialized. Code or data in pageable sections that are never or
rarely used are likely to be unallocated most of the time. Along
with the size and location of the INIT section, this creates
a memory allocation signature for each driver in the system.
We can search for these signatures in the reconstructed kernel
space allocation map to determine the actual load addresses of
a variety of drivers.
We evaluated the signature matching on all three Intel CPUs
and the virtual machine. At ﬁrst, we took a snapshot of
the kernel space with the help of a custom driver. Then we
created signatures for each loaded driver. A signature essentially
consists of a vector of boolean values that tell whether a page
in the driver was allocated (true) or paged-out (false). Note that
this signature generation step can be done by an attacker in
advance to build a database of memory allocation signatures.
In the next step, we rebooted the machine, applied the double
page fault approach, and then matched the signatures against
the reconstructed kernel space allocation map. To enhance the
precision during the signature matching phase, we performed
two optimizations: ﬁrst, we rule out signatures that contain less
than ﬁve transitions from allocated to paged-out memory to
avoid false positives. Second, we require a match of at least
96% for a signature, which we empirically found to yield the
best results.
The results are shown in Table 3. On machine (1),
the
signature matching returns the exact load addresses of 21 drivers
(including big common drivers such as win32k.sys and
ndis.sys); 141 drivers are loaded in total and 119 signatures
were ruled out because they held too few transitions. Hence
only one signature had a too low match ratio. All identiﬁed
base addresses are correct, there are no false positives. Most of
the other drivers could not be located since they are too small
and their signatures thus might produce false positives. The 21
located drivers hold 7, 431 KB of code, which is easily enough
to mount a full ROP attack as explained previously [35], [36].
Similar results hold for the other CPUs.
To assess whether the signatures are also portable across
different CPUs, we took the signatures generated on machine
(2) and applied them to machine (1). The operating system and
driver versions of both machines are identical. This yields 9 hits
with 2, 312 KB of code. This experiment shows that the different
paging behavior in drivers is not fundamentally affected by
differing hardware conﬁgurations.
3) Discussion: Although the double page fault measurements
only reveal which pages are allocated and which are not, this
still can be used to derive precise base addresses as we have
shown by using the memory allocation signature matching.
Furthermore, the method can be used to ﬁnd large page regions
(especially the kernel region).
C. Third Attack: Address Translation Cache Preloading
In the previous section we have described an approach to
reconstruct the allocation map of the complete kernel space.
200
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:55:20 UTC from IEEE Xplore.  Restrictions apply. 
that
the fact
While it is often possible to infer the location of certain drivers
from that, without driver signatures it only offers information
about
there is something located at a certain
memory address and not what. However, if we want to locate a
certain driver (i.e., obtain the virtual address of some piece of
code or data from its loaded image), we can achieve this with
our third implementation approach: ﬁrst we ﬂush all caches (i.e.,
address translation and instruction/data caches) to start with a
clean state. After that, we preload the address translation caches
by indirectly calling into kernel code, for example by issuing a
sysenter operation. Finally, we intentionally generate a page
fault by jumping to some kernel space address and measure the
time that elapses between the jump and the return of the page
fault handler. If the faulting address lies in the same memory
range as the preloaded kernel memory, a shorter time will elapse
due to the already cached address translation information.
Flushing all caches from user mode cannot be done directly
since the invlpg and invd/wbinvd are privileged instruc-
tions. Thus, this has to be done indirectly by accessing sufﬁ-
ciently many memory addresses to evict all other data from the
cache facilities. This is trivial for ﬂushing the address translation
and L1 caches, since only a sufﬁcient number of virtual memory
addresses have to be accessed. However, this approach is not
suitable for L2/L3 caches, since these are physically indexed
and we do not have any information about physical addresses
from user mode. Anyway, in practice the same approach as
described above works if the eviction buffer is chosen large
enough. We have veriﬁed for Windows operating systems that
large parts of the physical address bits of consecutively allocated