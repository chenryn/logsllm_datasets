networks, decision trees, neural networks), we have chosen the support vector
machines approach for their superior ability to process high dimensional
Monitoring SIP Traﬃc Using Support Vector Machines
317
data [3,4]. SVM is a relatively novel (1995) technique for data classiﬁcation
and exploration. It has demonstrated good performance in many domains like
bioinformatics and pattern recognition (e.g. [5] and [6]). SVM has been used
in network-based anomaly detection and has demonstrated better performance
than neural networks in term of accuracy and processing proﬁciency [7]. In the
next section, we give a short description of the SVM concept and methodology.
4 Support Vector Machines
Principle. Given a set of couples S = (−→
xl , yl)1≤l≤p, with yl ∈ {−1, +1}, which
denotes the correct classiﬁcation of the training data, the SVM method tries to
distinguish between the two classes by mean of a dividing hyperplane which has
as equation −→
−→
x + b = 0. If the training data are linearly separable, the solution
consists in maximizing the margin between the two hyperplanes, −→
−→
x + b = +1
and −→
−→
x + b ≥ +1 (1) or
−→
−→
x + b ≤ −1 (2). This is equivalent to minimizing the module |−→
w| because
the distance between the two mentioned hyperplanes is 2/|−→
w .
w|. The resulting
quadratic problem where the conditions (1) and (2) are aggregated is formulated
as:
−→
x + b = −1, such that for all points either −→
w .
w .
w .
w .
Find −→
so that yl(−→
w and b to minimize 1
−→
xl) + b ≥ 1∀(−→
2
w .
−→
w .
−→
w
xl , yl) ∈ S
The non linear separation has a similar formulation except that we replace the
dot product by a non-linear kernel function. The kernel function takes the data
set to a transformed feature space where it searches the optimal classiﬁer. The
transformation may be non-linear and the transformed space high dimensional.
The maximum-margin hyperplane in the high-dimensional feature space may be
non-linear in the original input space. The following kernels can be used :
z ) = −→
– linear Kl(−→
−→
−→
−→
– polynomial Kd(−→
−→
x .
z + r)d , γ > 0
z ) = (γ
−→
– radial basis function krbf (−→
z ) = exp(−γ|−→
x .
x ,
– sigmoid ks(−→
−→
−→
−→
x ,
z + r), γ > 0 and r  0
x − −→
−→
z
x ,
x ,
C-SVC. For the general case where the data S is not separable, the solution
allows some points to be mislabeled by the separating hyperplane. This method,
so called soft margin, is expressed by the introduction of slack variables ξl where
ξl measures the degree of misclassiﬁcation of a point xl. The objective function
is then increased by a function which penalizes non-zero ξl, and the optimization
becomes a trade oﬀ between a large margin, and a small error penalty.
318
M. Nassar, R. State, and O. Festor
Find −→
so that
(cid:3)
w , b and ξ to minimize 1
2
−→
(cid:2)
w + C
yl(−→
−→
xl) + b ≥ 1 − ξl,∀(−→
l ξl
xl, yl) ∈ S
ξl ≥ 0, ∀l
−→
w .
w .
5 Monitoring SIP
We aim to detect anomalies within a SIP traﬃc capture, demonstrate the accu-
racy of the learning machine to identify attacks and non-attacks and distinguish
between diﬀerent types of attacks. We have performed an extensive analysis on
oﬄine VoIP traces in order to assess the performance of our approach.
We use the popular LibSVM tool [8] which contains several algorithms for
classiﬁcation and regression. In addition, the tool provides support for multi-
class classiﬁcation and probability estimates (so a test vector xi seems to be
of class i with a probability pi) as well as support for one class SVM training.
LibSVM is bound to other several tools such as an algorithm that performs a
grid search over the SVM parameters space and optimizes their values by cross
validation (divide the data into n subsets, for i going from 1 until n, learn over all
the subsets except subset number i then test over subset number i). At the end,
we can measure the test accuracy for each subset. The aggregation of all results
is the accuracy given by the selected parameters. In Fig. 3 we illustrate this tool’s
ﬂow. The data we use in this study originates from two diﬀerent sources. The
ﬁrst source is traﬃc from a real-world VoIP provider and it is supposed to be
completely normal. The second source is signaling traﬃc from a small test-bed
installed by us to generate diﬀerent forms of SIP attacks. We have three types
of data ﬁles: clean and normal trace, clean attack trace, and mixed trace which
is a normal trace where attack is injected.
To be processed by the SVM tool, each data ﬁle is cut into slices and entered
into the analyzer. For each slice, the analyzer evaluates a set of predeﬁned fea-
tures (38 variables are deﬁned in our study) and builds a vector for the LibSVM.
All vectors are assembled in one ﬁle and annotated as either attack vector or
normal vector. In Fig. 4, this process is shown for a mixed trace.
Fig. 3. SVM Flow Chart
Fig. 4. Analysis Flow Chart
Monitoring SIP Traﬃc Using Support Vector Machines
319
Fig. 5. Long Term Statistics over Real World Traces
5.1 Normal Traﬃc
The input data is a SIP trace from a two days continuous capture at a real
world VoIP provider server. We performed a preliminary long term analysis of
the traces with a two hours step. We depict the results in the four charts of
Fig. 5. If we consider the distribution of diﬀerent SIP messages, we can remark
the following:
– The two main components of the traﬃc are the OPTIONS messages in the
ﬁrst place and then the REGISTER messages.
– Some methods are absent from the capture such a MESSAGE, PRACK and
UPDATE.
– Some methods like NOTIFY have constant statistics over all periods of the
day which reveal SIP devices remaining always connected and periodically
sending notiﬁcations.
– The three main components of the call signalling (INVITE, BYE and ACK)
have practically constant ratios over all the slots, with an average ratio
#IN V IT E/#BY E = 2.15 and #IN V IT E/#ACK = 0.92.
Response distribution is dominated by the 2nd response class (most of them be-
long to OPTIONS and REGISTER transactions). 3xx, 5xx and 6xx are very rare
while informational responses (1xx) follow INVITE messages because they are
exclusively used in INVITE transactions (the average ratio #IN V IT E/#1xx =
0.59 can be explained by the fact that a call probably regroups one 100 Trying
and one 180 Ringing so two 1xx responses). Average inter-request arrival and
average inter-response arrival seem to be constant over all periods and they
are about 20 ms. While average inter-request carrying SDP bodies which are
exchanged in call dialogs move inversely to the quadruple (INVITE-BYE-ACK-
1xx) curve, they reach 3s in quiet hours and decrease to 0.5s in rush hours.
320
M. Nassar, R. State, and O. Festor
Fig. 6. Testbed of Attack Generation
5.2 The Testbed
The testbed consists of one OpenSER server and three other machines: the
ﬁrst machine plays the role of the attacker and uses a number of hacking tools
(scanning, ﬂooding, SPIT). The two other machines play the role of victims
where one hundred SIP bots are equally distributed and running. The bots are
programmable SIP agents and are controlled by an IRC channel1. All SIP bots
and a GrandStream hardphone are registered to the OpenSER server and all
machines belong to the same domain. Traces of attacks performed by the attacker
machine are collected at the OpenSER server.
6 Performance and Accuracy
All experiments are done in a machine which has an Intel Pentium 4 CPU
3.40GHz and 2GB RAM memory running a Linux kernel 2.6.18-1. In term of
performance, experiments show that a ﬁle containing 2449 slices/vectors of 38
features takes between 196 and 994 ms in the SVM prediction stage (depending
on the used kernel).
Coherence Test
The ﬁrst question we addressed was how many of the normal traces are self-
similar and consistent. For example, is traﬃc from 22:00 to 02:00 from a day
similar to traﬃc of the same period in another day? To test the coherence be-
tween two given traces, we used the following procedure: the analyzer evaluates
feature vectors from each trace. Vectors are then labeled with respect to the
origin trace and scaled. We make a 2-fold training test over all the vectors. In
a 2-fold test, training is done over one part of the ﬁle and the testing is per-
formed over the second. We deﬁne the coherence to be indirect proportional
to the resulting accuracy of the 2-fold cross training. As long as the SVM can
not distinguish between the two traces, they are tagged to the same class. In
Table 1, we summarize some results:
1 http://www.loria.fr/∼nassar/readme.html
Monitoring SIP Traﬃc Using Support Vector Machines
321
Table 1. Coherence Test for two Successive Days
06-10 10-14 14-18 18-22
Day 1
06-10 10-14 14-18 18-22
Day 2
Accuracy(%) 55.91 53.72 52.83 56.90
Table 2. Coherence Test for Diﬀerent Periods of the Same Day
02-06 02-06 02-06 02-06 22-02
Day 1
Day 1
06-10 10-14 14-18 18-22 22-02
Accuracy(%) 51.82 62.79 63.72 63.76 60.80
We tested the coherence of a period with respect to other periods. In Table 2,
we show the results of the same procedure for a period of 2-6 of Day 1 compared
to other periods of the same day. SVM is not able to label 50% of vectors in
the correct class while proceeding with the same period of two successive days
and 40% of vectors during diﬀerent periods of the same day. The second table
reveals that period 02-06 is more coherent with neighboring periods (06-10 and
22-02) than with other periods of the day. In conclusion, the coherence of the
data is acceptable.
Multi-Class Detection Experiment
We also tested SVM’s ability to distinguish between diﬀerent classes of traﬃc:
for instance traces coming form diﬀerent VoIP platforms. We built a group of
four traces, each representing a diﬀerent traﬃc class : normal traﬃc, a burst
of ﬂooding DoS, a trace generated by the KIF stateful fuzzer [9], and a trace
generated by an unknown testbed as shown in Table 3. The size of the analyzed
slice is ﬁxed to 30 messages. After analysis, a 2-fold training/testing cross test is
performed over all respectively labeled vectors (2449 vectors). The test Accuracy
is deﬁned as the percentage of correctly classiﬁed vectors over all test vectors.
When the RBF (Radial Basis Function) kernel is used with default parameters
(C=1 and γ = 1/38), the accuracy is 98.24%.
Table 3. Multi-Class SIP Traﬃc Data Set
Trace Normal DoS
6076
SIP pkts
Duration 8.6(min) 3.1(min) 50.9 (min) 83.7(day)
KIF Unknown
2305
57960
7033
Comparison between Diﬀerent Kernel Experiments
The RBF kernel is a reasonable ﬁrst choice if one can assume that the classes are
not linearly separable and because it has few numerical settings (small number of
322
M. Nassar, R. State, and O. Festor
Table 4. Testing Results for Diﬀerent Kernels
Kernel