7.63
8.89
10.95
11.23
Table 2: Parameters for the compressed representation of the road networks for each city: n is the number of nodes
in each network, d and ν are the number of columns and the precision, respectively, in the routing matrices A(ne),
B(ne), A(nw), B(nw) of the compressed representation, and τ is the maximum number of bits needed to represent an
element in the products A(ne)(B(ne))T and A(nw)(B(nw))T . The last column gives the compression factor attained
for each network (ratio of size of uncompressed representation to size of compressed representation).
Figure 4: Average time needed to compress the next-hop routing matrix and the resulting compression factor for
networks constructed from subgraphs of the road network of Los Angeles.
an 8-core 2.3 GHz Intel Core i7 CPU, 16 GB of RAM, and an Nvidia GeForce GT 750M GPU. The
preprocessing and compression times for the diﬀerent networks are summarized in Table 1. A description
of the compressed representation of the routing matrices for each network is given in Table 2.
In Figure 4, we show the time needed to compress a single component of the next-hop routing matrix,
as well as the resulting compression factor, for subgraphs of the road network for Los Angeles. The
compression is quite eﬀective, and the achievable compression factor increases with the size of the network.
Moreover, even though the sizes of the next-hop routing matrices increase quadratically in the number
of nodes in the graph, the optimization time remains modest. For graphs with 7000 nodes (and 350,000
optimization variables), ﬁnding a compact representation that perfectly reconstructs the next-hop matrix
completes in under 10 minutes. Since we compress both the ne and nw components of the routing matrix,
the total time to both preprocess and compress the shortest path information for the full city of Los Angeles
is just over 15 minutes. Lastly, we note that the preprocessing time for each network is small: orienting
the edges and computing all-pairs shortest paths via Dijkstra’s algorithm completes in under 10 seconds.
Performance on road networks. Next, we measure the run-time and bandwidth requirements of our
private routing protocol from Figure 3. Table 2 gives the number of columns d, and the precision ν of
the compressed representation of the networks for the diﬀerent cities. In addition, we also compute the
maximum number of bits τ needed to encode an element in the products A(ne)(B(ne))T and A(nw)(B(nw))T .
From Theorem 4.5, a malicious client can successfully cheat with probability at most R·2−µ, where µ is the
18
0246810120100200300400500600010002000300040005000600070008000Compression FactorCompression Time (s)Nodes in GraphCompression Time (s)Compression FactorCity
San Francisco
Washington, D.C.
Dallas
Los Angeles
Client Computation (s)
Total Time (s)
(Single Round) Total PIR OT GC Total PIR
1.44 ± 0.16
0.80
1.64 ± 0.13
1.00
2.91 ± 0.19
2.11
4.75 ± 0.22
3.62
0.35
0.38
0.45
0.55
0.88
1.07
2.19
3.70
0.31
0.34
0.41
0.51
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
Server Computation (s)
OT
0.08
0.08
0.08
0.08
Bandwidth (KB)
Upload Download
51.74
52.49
55.50
57.01
36.50
37.51
39.52
43.53
Table 3: Performance benchmarks (averaged over at least 90 iterations) for a single round of the private routing
protocol described in Figure 3 on road networks for diﬀerent cities. The “Total Time” column gives the average
runtime and standard deviation for a single round of the protocol (including network communication times between
a client and a server on Amazon EC2). The PIR, OT, and GC columns in the table refer to the time to perform
the PIR for the aﬃne encodings, the time to perform the OT for the garbled circuit encodings, and the time needed
to evaluate the garbled circuit, respectively. The bandwidth measurements are taken with respect to the client
(“upload” refers to communication from the client to the server)
City
San Francisco
Washington, D.C.
Dallas
Los Angeles
R
97
120
126
165
Oﬄine Setup
Online Setup
Total Online
Total Online
Time (s) Band. (MB) Time (s) Band. (MB)
Time (s)
Bandwidth (MB)
0.135
0.170
0.174
0.223
49.08
60.72
63.76
83.49
0.73
0.76
0.92
1.00
0.021
0.023
0.027
0.028
140.39
197.48
371.44
784.34
8.38
10.57
11.72
16.23
Table 4: End-to-end performance benchmarks for the private routing protocol in Figure 3 on road networks for
diﬀerent cities. For each network, the number of iterations R is set to the maximum length of the shortest path
between two nodes in the network. The oﬄine computation refers to the server preparation and garbling of the R
circuits for evaluating the neighbor-computation function from Figure 2. The oﬄine computation time just includes
the computational cost and does not include the garbled circuit download time. The online setup measurements
correspond to computation and communication in the “Setup” phase of the protocol in Figure 3. The “Total Online
Time” and “Total Online Bandwidth” columns give the total end-to-end time (including network communication)
and total communication between the client and server in the online phase (navigation component) of the protocol.
statistical security parameter, and R is the total number of rounds in the protocol. For each network in our
experiments, we set the number of rounds R to be the maximum length over all shortest paths between any
source-destination pair in the network. This ensures both correctness (at the end of the protocol execution,
the client obtains the complete shortest path from its source to its destination) as well as hides the length
of the requested shortest path from the server (since the number of rounds in the protocol is independent
of the client’s input). Next, recall the relation between µ and the order p of the ﬁnite ﬁeld for the aﬃne
encodings: p > 2τ +µ+1. In our experiments, we ﬁx p = 261 − 1, and R is at most 28 = 256. This choice
of parameters translates to µ ranging from 36 to 41, or analogously, a failure probability of 2−33 for the
smaller networks to 2−28 for larger networks. Using larger ﬁelds will reduce this probability, but at the
expense of performance.
To reduce the communication in each round of the protocol in Figure 3, we note that it is not necessary
for the server to prepare and send a garbled circuit to the client on each round of the routing protocol. Since
the neighbor-computation circuit is independent of the state of the protocol execution, the circuits can be
generated and stored long before the protocol execution begins. Thus, in an oﬄine phase, the server can
prepare and transmit to the client a large number of garbled circuits. During the online protocol execution,
on the rth round, the server just sends the encodings corresponding to its input to the client; it does not
send the description of the garbled circuit. This signiﬁcantly reduces the communication cost of each round
19
of the online protocol. We note that even if the routing matrices A(ne), B(ne), A(nw), B(nw) changed (for
instance, due to updates in traﬃc or weather conditions in the network) during the protocol execution, as
long as the bound τ on the bit-length of entries in the products A(ne)(B(ne))T and A(nw)(B(nw))T remain
ﬁxed, the client and server do not have to redo this oﬄine setup phase. We describe our extension for
supporting live updates to the routing information in greater detail in Section 6.
We run the server on a compute-optimized Amazon EC2 instance (running Ubuntu 14.04 with a 32-
core 2.7 GHz Intel Xeon E5-2680v2 processor and 60 GB of RAM) to model the computing resources of
a cloud-based map provider. The throughput of our protocol is bounded by the PIR computation on the
server’s side. We use up to 60 threads on the server for the PIR computation. All other parts of our system
are single-threaded. For the client, we use a laptop running Ubuntu 14.04 with a 2.3 GHz Intel Core i7
CPU and 16 GB of RAM. The connection speed on the client is around 50 Mbps. Both client and server
support the AES-NI instruction set, which we leverage in our implementation.
First, we measure the cost of one round of the private navigation protocol. We assume that the client
has already downloaded the garbled circuits prior to the start of the protocol. Table 3 gives the total
computation time and bandwidth per round of the routing protocol. When measuring the total time, we
measure the end-to-end time on the client, which includes the time for the network round trips. Table 3 also
gives a breakdown of the computation in terms of each component of the protocol: PIR for the arithmetic
circuit encodings, OT for the garbled circuit encodings, and garbled-circuit evaluation for computing the
next-hop.
We also measure the total end-to-end costs for a single shortest path query. As noted earlier, we set
the number of rounds R for each network to be the maximum length of any shortest path in the network.
Irrespective of the client’s source or destination, the client and server always engage in exactly R rounds
of the private navigation protocol. Table 4 shows the total computation time and bandwidth required to
complete a shortest-path query in the diﬀerent networks. In the end-to-end benchmarks, we also measure
the oﬄine costs of the protocol, that is, the time needed for the server to garble R neighbor-computation
circuits and the amount of communication needed for the client to download the circuits. In addition,
we measure the computation and bandwidth needed in the online setup phase of the routing protocol
(Figure 3).
In our protocol, the online setup phase of the protocol consists of three rounds of interaction. First, the
server sends the client the public description of the map. Then the client OTs for the source and destination
keys for the ﬁrst round of the protocol, which requires two rounds of communication. As shown in Table 4,
the online setup procedure completes in at most a second and requires under 30 KB of communication in
our example networks.
Next, we consider the performance of each round of the protocol. From Table 3, the most compu-
tationally intensive component of our protocol is computing the responses to the PIR queries.
In our
implementation, we use a Paillier-based PIR, so the server must perform O(n) modular exponentiations
on each round of the protocol. While it is possible to use a less computationally-intensive PIR such
as [MBFK14], the bandwidth required is much higher in practice. Nonetheless, our results demonstrate
that the performance of our protocol is within the realm of practicality for real-time navigation in cities
like San Francisco or Washington, D.C.
Lastly, we note that the oﬄine costs are dominated essentially by communication. With hardware
support for AES, garbling 100 neighbor-computation circuits on the server completes in just a quarter of a
second. While garbling is fast, the size of each garbled circuit is 518.2 KB. For city networks, we typically
require 100-150 circuits for each shortest-path query; this corresponds to 50-100 MB of oﬄine download
prior to the start of the navigation protocol. The experimental results, however, indicate that the number
of garbled circuits required for an end-to-end execution grows sublinearly in the size of the graph. For
example, the total number of rounds (and correspondingly, the number of required garbled circuits) for a
graph with 1800 nodes is just under 100, while for a graph with almost four times more nodes, the number
20
of rounds only increases by a factor of 1.7. We also note that each neighbor-computation circuit consists
of just under 50,000 non-XOR gates. In contrast, generic protocols for private navigation that construct a
garbled circuit for Dijkstra’s algorithm yield circuits that contain hundreds of millions to tens of billions
of non-XOR gates [CMTB13, CLT14, LWN+15].
Finally, we see that despite needing to pad the number of rounds to a worst-case setting, the total cost
of the protocol remains modest. For the city of Los Angeles, which contains over 7000 nodes, a shortest-
path query still completes in under 15 minutes and requires just over 16 MB of total bandwidth. Moreover,
since the path is revealed edge-by-edge rather than only at the end of the computation, the overall protocol
is an eﬃcient solution for fully-private navigation.
Comparison to other approaches for private navigation. Many protocols [DK05, LLLZ09, XSS14]
have been proposed for private navigation, but most of them rely on heuristics and do not provide strong
security guarantees [DK05, LLLZ09], or guarantee privacy only for the client’s location, and not the server’s
routing information [XSS14]. A diﬀerent approach to fully-private navigation is to leverage generic mul-
tiparty computation techniques [Yao86, GMW87]. For instance, a generic protocol for private navigation
is to construct a garbled circuit for a shortest-path algorithm and apply Yao’s protocol. This approach
is quite expensive since the entire graph structure must be embedded in the circuit. For instance, Liu
et al. [LWN+15] demonstrate that a garbled circuit for evaluating Dijkstra’s algorithm on a graph with
just 1024 nodes requires over 10 billion AND gates. The bandwidth needed to transmit a circuit of this
magnitude quickly grows to the order of GB. In contrast, even for a larger graph with 1800 nodes, the total
online and oﬄine communication required by our protocol is under 60 MB (and the online communication
is under 10 MB). Carter et al. [CMTB13, CLT14] describe methods for reducing the computational and
communicational cost of Yao’s protocol by introducing a third (non-colluding) party that facilitates the
computation. Even with this improvement, evaluating a single shortest path on a graph of 100 nodes still
requires over 10 minutes of computation. As a point of comparison, our protocols complete in around 2-3
minutes for graphs that are 15-20 times larger. Evidently, while the generic tools are powerful, they do not
currently yield a practical private navigation protocol. We survey additional related work and techniques
in Section 7.
6 Extensions
In this section, we describe several extensions to our protocol: supporting navigation between cities,
handling updates to the routing information, and updating the source node during the protocol execution
(for instance, to accommodate detours and wrong turns).
Navigating between cities. The most direct method for supporting navigation across a multi-city
region is to construct a network that spans the entire region and run the protocol directly. However, since
the server’s computation in the PIR protocols grows as O(nd log p), where n is the number of nodes in the
graph, d is the number of columns in the compressed representation, and p is the order of the ﬁnite ﬁeld
used for the aﬃne encodings, this can quickly become computationally infeasible for the server.
An alternative method that provides a performance-privacy trade-oﬀ is to introduce a series of publicly-
known waypoints for each city. For example, suppose a user is navigating from somewhere in Los Angeles
to somewhere in San Diego.
In this case, the user would ﬁrst make a private routing request to learn
the fastest route from her current location to a waypoint in Los Angeles. Once the user arrives at the
waypoint in Los Angeles, she requests the fastest route to a waypoint in San Diego. This second query is
performed entirely in the clear, so the user reveals to the server that she is traveling from Los Angeles to
San Diego. Once the user arrives at a waypoint in San Diego, she makes a ﬁnal private routing request
21
to learn the fastest route to her destination. In this solution, the server only obtains a macro-view of the
user’s location: it learns only the user’s source and destination cities, and no information about the user’s
particular location within the city. As we have demonstrated, the protocol in Figure 3 is able to handle
real-time navigation for a single city; thus, using this method of waypoints, we can also apply our protocol
to navigation between cities with limited privacy loss.
Live updates to routing information. Routing information in road networks is dynamic, and is inﬂu-
enced by current traﬃc conditions, weather conditions, and other external factors.
Ideally, the edges
revealed in an iterative shortest-path protocol should always correspond to the shortest path to the
destination given the current network conditions.
It is fairly straightforward to allow for updates to
the routing information in our protocol. Speciﬁcally, we observe that the compressed routing matrices
A(ne), A(nw), B(ne), B(nw) need not be ﬁxed for the duration of the protocol. As long as the total number
of columns d, the bound on the bit-length τ of the values in the matrix products A(ne) · (B(ne))T and
A(nw) · (B(nw))T , and the total number of rounds R in the protocol remain ﬁxed, the server can use a dif-
ferent set of routing matrices on each round of the protocol. Therefore, we can accommodate live updates