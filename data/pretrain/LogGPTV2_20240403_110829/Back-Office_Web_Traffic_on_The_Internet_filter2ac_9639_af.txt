in terms of requests sent. We estimate that, at this vantage point,
crawling accounts for roughly 155 million requests/hour and that
the most active crawlers issue up to 910K requests/hour. Naturally,
the number of bytes received is larger than the number sent. Over-
all, we estimate that all together crawlers fetch roughly 3.8 TB per
hour. However, not all are equally active, and we even see some
fetching content from only a single IP.
Content delivery proxies: On average, the proxies show the
lowest activity per individual IP. This observation applies to both
bytes and trafﬁc. However, due to their large number, they con-
tribute signiﬁcantly to back-ofﬁce trafﬁc. This category of IPs ex-
hibits the largest variation in behavior, and some of the heavy hit-
ters in this category compete with those in the other categories.
Summary
Real-time bidding is very prominent and relies on many small trans-
actions involving a fairly small set of organizations and hosts. As
each end-user request may trigger multiple bid requests, RTB sig-
niﬁcantly contributes to the number of back-ofﬁce transactions. Crawl-
ing, on the other hand, happens on a coarser-grain time scale and
is executed by a limited number of organizations that constantly
fetch content from a diverse set of mainly Web hosting providers.
While CDPs have a diverse proﬁle, our analysis illustrates that a
single end-user request to a CDN front-end server can involve a
chain of proxies. These connections remain entirely hidden to the
end users.
8. A CDN’S PERSPECTIVE
Until now, we have analyzed back-ofﬁce Web trafﬁc from our
vantage points in ISPs and IXPs. In this section, we present a com-
plementary perspective provided by vantage points inside a com-
mercial CDN. A CDN can be viewed as a high-bandwidth low-
latency conduit that facilitates data exchanges between end users
and different points of origin. As seen in previous sections, they
266(cid:7)(cid:1)(cid:1)(cid:2)
(cid:12)
(cid:2)
(cid:3)
(cid:3)
(cid:2)
(cid:9)
(cid:11)
(cid:5)
(cid:10)
(cid:3)
(cid:6)
(cid:7)
(cid:6)
(cid:5)
(cid:2)
(cid:6)
(cid:5)
(cid:8)
(cid:4)
(cid:7)
(cid:9)
(cid:8)
(cid:7)
(cid:6)
(cid:5)
(cid:2)
(cid:4)
(cid:3)
(cid:2)
(cid:1)
(cid:6)(cid:1)(cid:2)
(cid:5)(cid:1)(cid:2)
(cid:4)(cid:1)(cid:2)
(cid:3)(cid:1)(cid:2)
(cid:1)(cid:2)
(cid:27)(cid:17)(cid:21)(cid:16)(cid:12)(cid:28)(cid:8)(cid:29)(cid:30)(cid:31)(cid:25)(cid:16)(cid:10)(cid:32)(cid:12)(cid:21)(cid:33)
(cid:27)(cid:17)(cid:21)(cid:16)(cid:12)(cid:28)(cid:8)(cid:29)(cid:30)(cid:31)(cid:25)(cid:20)(cid:34)(cid:35)(cid:10)(cid:11)
(cid:8)(cid:29)(cid:30)(cid:28)(cid:36)(cid:16)(cid:10)(cid:13)(cid:10)(cid:17)
(cid:8)(cid:29)(cid:30)(cid:28)(cid:37)(cid:17)(cid:23)(cid:38)(cid:26)(cid:33)(cid:16)(cid:26)
(cid:8)(cid:9)(cid:10)(cid:11)(cid:12)(cid:13)(cid:14)
(cid:22)(cid:14)(cid:17)(cid:23)(cid:14)(cid:17)
(cid:15)(cid:16)(cid:12)(cid:17)(cid:18)(cid:19)(cid:20)(cid:16)(cid:21)
(a) Trafﬁc volumes.
(cid:24)(cid:20)(cid:17)(cid:10)(cid:11)(cid:9)
(cid:25)(cid:12)(cid:16)(cid:10)(cid:26)
(cid:14)
(cid:1)
(cid:8)
(cid:10)
(cid:13)
(cid:12)
(cid:5)
(cid:1)
(cid:1)
(cid:8)
(cid:12)
(cid:7)
(cid:5)
(cid:2)
(cid:11)
(cid:1)
(cid:2)
(cid:7)
(cid:9)
(cid:8)
(cid:7)
(cid:6)
(cid:5)
(cid:4)
(cid:3)
(cid:2)
(cid:1)
(cid:10)
(cid:1)(cid:2)(cid:5)
(cid:1)(cid:2)(cid:4)
(cid:1)(cid:2)(cid:3)
(cid:1)(cid:2)(cid:2)
(cid:1)(cid:2)(cid:1)
(cid:22)(cid:12)(cid:16)(cid:11)(cid:7)(cid:23)(cid:3)(cid:24)(cid:25)(cid:26)(cid:20)(cid:11)(cid:5)(cid:27)(cid:7)(cid:16)(cid:28)
(cid:22)(cid:12)(cid:16)(cid:11)(cid:7)(cid:23)(cid:3)(cid:24)(cid:25)(cid:26)(cid:20)(cid:15)(cid:29)(cid:30)(cid:5)(cid:6)
(cid:3)(cid:24)(cid:25)(cid:23)(cid:31)(cid:11)(cid:5)(cid:8)(cid:5)(cid:12)
(cid:3)(cid:24)(cid:25)(cid:23)(cid:32)(cid:12)(cid:18)(cid:33)(cid:21)(cid:28)(cid:11)(cid:21)
(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)
(cid:10)(cid:11)(cid:7)(cid:12)(cid:13)(cid:14)(cid:15)(cid:11)(cid:16)
(cid:17)(cid:9)(cid:12)(cid:18)(cid:9)(cid:12)
(cid:19)(cid:15)(cid:12)(cid:5)(cid:6)(cid:4)
(cid:20)(cid:7)(cid:11)(cid:5)(cid:21)
(b) CDN-EndUsers Fan in, Others Fan Out.
Figure 8: Front-ofﬁce and back-ofﬁce trafﬁc at a large CDN.
are one of the major contributors to back-ofﬁce Web trafﬁc. This
section delves into the details of the data set provided by a large
commercial CDN and highlights a few ways this data can used to
characterize back-ofﬁce Web trafﬁc.
8.1 CDN Dataset
The analysis in this section is based on server logs from the
CDN’s edge, or front-end, servers. Each log line records the de-
tails of an exchange of data where the edge server is one of the
endpoints. Thus, the logs capture the interactions between the edge
server and the end users, i.e., front-ofﬁce Web trafﬁc, as well as the
interactions with other CDN servers and origin servers, i.e., back-
ofﬁce Web trafﬁc.
We obtained the server logs from all servers at one cluster in each
of ﬁve different cities: Chicago, Frankfurt, London, Munich, and
Paris.6 Note that there may be multiple clusters at each city, and
we selected only one of the larger clusters in each city. CDNs also
deploy multiple servers at each cluster, e.g., for load-balancing, and
servers at each cluster offer a diverse set of services ranging from
Web-site delivery to e-commerce to video streaming. We selected
clusters of servers conﬁgured to handle Web trafﬁc, and our logs
measure Web trafﬁc of more than 350TB in volume.
8.2 Front-ofﬁce vs. back-ofﬁce CDN trafﬁc
The primary focus of a CDN is to serve content to the user as efﬁ-
ciently as possible. Therefore, one should expect CDN front-ofﬁce
trafﬁc to dominate CDN back-ofﬁce trafﬁc in volume. As not all
content is cacheable [8], up to date, or popular, some content has to
be fetched from other servers. Moreover, many CDNs, e.g., Aka-
mai [54], create and maintain sophisticated overlays to interconnect
their edge servers and origin servers to improve end-to-end perfor-
mance, to by-pass network bottlenecks, and to increase tolerance to
network or path failures. Hence, a CDN edge server may contact,
besides origin servers, other CDN servers located either in the same
cluster, with back-ofﬁce Web trafﬁc routed over a private network,
or in a different cluster at the same or different location, with the
back-ofﬁce Web trafﬁc routed over a private or public network.
With the knowledge of the IP addresses used by the CDN’s in-
frastructure, we can differentiate the intra-CDN Web trafﬁc from
the trafﬁc between the CDN servers and end users (CDN-EndUsers),
and CDN servers and origin servers (CDN-Origin). Furthermore,
within the class of intra-CDN Web trafﬁc, we can differentiate
the trafﬁc between servers in the same cluster from that between
servers in different clusters; trafﬁc between servers in the same
6A small fraction of servers at each location did not respond to our
requests to retrieve the logs, but this should not affect the analysis.
(cid:17)
(cid:15)
(cid:16)
(cid:10)
(cid:11)
(cid:15)
(cid:7)
(cid:6)
(cid:11)
(cid:11)
(cid:14)
(cid:15)
(cid:14)
(cid:13)
(cid:10)
(cid:6)
(cid:7)
(cid:13)
(cid:6)
(cid:14)
(cid:13)
(cid:12)
(cid:11)
(cid:10)
(cid:9)
(cid:8)
(cid:7)
(cid:6)
(cid:5)
(cid:4)
(cid:3)
(cid:2)
(cid:1)
(cid:1)(cid:8)
(cid:1)(cid:2)(cid:3)(cid:7)
(cid:1)(cid:2)(cid:3)(cid:6)
(cid:1)(cid:2)(cid:3)(cid:5)
(cid:1)(cid:2)(cid:3)(cid:4)
(cid:1)(cid:2)
(cid:1)(cid:8)
(cid:12)(cid:20)(cid:2)(cid:7)(cid:5)(cid:21)(cid:22)
(cid:23)(cid:14)(cid:5)(cid:6)(cid:17)(cid:24)(cid:25)(cid:14)(cid:4)
(cid:26)(cid:22)(cid:6)(cid:27)(cid:22)(cid:6)
(cid:28)(cid:25)(cid:6)(cid:2)(cid:7)(cid:20)
(cid:29)(cid:5)(cid:14)(cid:2)(cid:3)
(cid:1)(cid:8)(cid:2)(cid:2)(cid:2)
(cid:1)(cid:8)(cid:2)(cid:2)(cid:2)(cid:2)
(cid:1)(cid:8)(cid:2)
(cid:1)(cid:8)(cid:2)(cid:2)
(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)(cid:10)(cid:8)(cid:4)(cid:11)(cid:8)(cid:8)(cid:6)(cid:9)(cid:12)(cid:1)(cid:13)(cid:9)(cid:3)(cid:8)(cid:14)(cid:15)(cid:8)(cid:14)(cid:3)(cid:9)(cid:16)(cid:17)(cid:18)(cid:19)
Figure 9: Content volume by distance (Intra-CDN) at a large
CDN.
cluster uses high-capacity low-latency links and is routed over a
private network (Intra-CDN/Private). We note that this trafﬁc does
not qualify as back-ofﬁce Web trafﬁc routed over the public Inter-
net, which is the main focus of this paper. But in order to properly
account for the publicly-routed back-ofﬁce trafﬁc that we are inter-
ested in, we must be able to separate out the Intra-CDN/Private traf-
ﬁc. Note also that since this category of back-ofﬁce Web trafﬁc is
not routed via the public Internet it does not accrue any peering cost
or hosting cost. Our classiﬁcation scheme partitions the Web trafﬁc
identiﬁed via the logs into four categories: (1) CDN-EndUsers, (2)
Intra-CDN/Public, (3) Intra-CDN/Private, and (4) CDN-Origin.
Figure 8(a) shows the proportion of trafﬁc observed in each of
the above four categories at the ﬁve different locations (or clusters).
Not surprisingly, we see that most trafﬁc is, as expected, CDN-
EndUsers trafﬁc. We still observe at least 25% back-ofﬁce trafﬁc at
each location. Of the ﬁve clusters, Paris is the most efﬁcient from
the perspective of the content provider, with more than 70% of the
trafﬁc in the CDN-EndUsers category, and CDN-Origin trafﬁc very
low (around 1%).
Frankfurt is an oddball. At Frankfurt, the end-user trafﬁc ac-
counts for less than 12%. After discussions with the CDN opera-
tor, we learned that servers in the Frankfurt cluster cache content
from origin servers for other edge servers in nearby clusters. The
high-volume of Intra-CDN/Public trafﬁc (about 55%) is indicative
of this role for the servers in the Frankfurt cluster. Besides reducing
the latency involved in fetching the content from the origin servers,
this practice limits the number of servers that have to fetch content
from the origin servers. The trafﬁc at other locations show signiﬁ-
cant volumes in both the Intra-CDN/Public and Intra-CDN/Private
categories. These statistics are indicative of the reliance on cooper-
ative caching with the CDN.
267Recall from Section 7.2 that there is a wide range of diversity in
the number of hops over which an HTTP request is forwarded, as
well as the distances to the ﬁnal server. Using the actual locations
of each CDN server as ground truth, we computed the distances for
all Intra-CDN data exchanges. Figure 9 plots the resulting ECDF of
the distances for the Intra-CDN/Public trafﬁc weighted by the con-
tent size. The cluster in Frankfurt, in addition to serving end-user
trafﬁc, acts as a caching hub, as explained previously. Figure 9 pro-
vides further evidence of Frankfurt’s role as a caching hub. About
20% of the trafﬁc to the cluster in Frankfurt is being transferred
over trans-continent links.7 Contrast this with the cluster in Mu-
nich which receives around 2% of it’s intra-CDN trafﬁc via trans-
continent links; discussion with the CDN operator conﬁrmed that
Munich does not serve as a caching hub. Figure 9 also reveals that a
substantial fraction of the trafﬁc travels only a short distance. This
is expected, since in large metropolitan areas, like those selected
for our study, edge servers are located at multiple data centers in
the same city.
8.3 CDN back-ofﬁce: Characteristics
Previously, we observed that the hosts’ fan out, i.e., the number
of hosts contacted by a host, can vary signiﬁcantly. Accordingly,
we may ask if fan out varies among the different classes of back-
ofﬁce CDN trafﬁc. Not surprisingly, it turns outs that the number
of unique end-user addresses to which the edge servers deliver con-
tent, i.e., the fan in, is larger than the combined number of CDN and
origin servers from which they fetch content, i.e., the fan out.
Figure 8(b) shows the number of unique connections observed
in the different trafﬁc categories at each location. From the ﬁg-
ure, we see that the number of unique connections in the back-
ofﬁce trafﬁc categories (Intra-CDN/Private, Intra-CDN/Public, and
CDN-origin) is two orders of magnitude less than that in the CDN-
EndUsers category; note that the y-axis is plotted using a log scale.
Moreover, the Intra-CDN/Private category mainly captures intra-
cluster data exchanges and thus the fan out is even smaller. Finally,
although the number of unique connections in the CDN-Origin cat-
egory is smaller, it is equivalent in order of magnitude to the con-
nection count in the Intra-CDN/Public category.
Aggregating the trafﬁc volume by server addresses in both the
CDN-Origin as well as the Intra-CDN/Public category reveals that
the trafﬁc is not uniformly distributed across all servers; rather there
are heavy hitters. 20% of the origin servers contribute to more than
96% of the content delivered to the CDN’s edge servers. A simi-
lar trend manifests in the Intra-CDN/Public category; 20% of the
CDN’s servers account for over 94% of the trafﬁc volume moved
from different servers in the CDN’s infrastructure to the front-end,
or edge, servers. These ﬁgures hint at the impact of the varying
popularity and cacheability of content on the trafﬁc patterns within
the CDN infrastructure.
9. AN END-USER’S PERSPECTIVE
Improving the end-user experience can lead to a signiﬁcant in-
crease in revenues [39] and drive up user engagement [23, 41].
These beneﬁts have catalyzed the competition among service com-
panies to offer faster access to content in order to improve the end-
user experience. Two “straightforward” ways of improving the
end-user experience that can be implemented by ISPs are to (a)
upgrade access networks, and to (b) improve the Internet’s middle
mile (backbones, peering points, and/or transit points); both ap-
proaches, however, are expensive.
7We assume that distances of 6000 km or more indicate trans-
continent links.
y
t
i
s
n
e
d
y
t
i
l
i
b
a
b
o
r
p