ism of the execution, therefore, the framework should be able
to execute the program in a completely deterministic way, in-
dependently of the OS.
• Stop, store and continue execution: The protocol requires
the ability to execute a program for a given number of steps,
stop its execution and store its current state to a ﬁle. Later,
we need to be able to continue the program execution from
any previously stored state.
At ﬁrst, it seems obvious we can use a debugger. However,
this is not the common functionality most debuggers provide.
We require the ability to continue from any previously stored
state, whereas a normal debugger stops on a pre-determined
state and can continue execution only from that state.
• Simulate an instruction:
In order to implement the last
step of the protocol (VerifyReducedStep()), the client should
be able to simulate any instruction given the instruction’s
operands.
When we were looking for candidate high-level languages we
had two key observations:
• Since our client has to simulate one instruction by itself, we
prefer to work with a language that has simple instructions.
By simple we mean that any single instruction takes a small
and bounded amount of time to compute, as opposed to, for
example, a single line of Java code which can theoretically
hide a very heavy computation.
Ideally, we would like to
work with something that is similar to RISC assembly or Java
Bytecode.
• Interpreted languages like Java and Python have complex in-
terpreters that have their own internal states, which are usu-
ally not deterministic. E.g., their native code cache or their
internal memory management processes like the Garbage Col-
lector. Therefore, storing a state of an interpreted-language
program requires subtle changes of its interpreter to some-
how make it more deterministic.
In addition, there are many non deterministic events that depend
on the operating system, e.g., many OS interfaces return handles
to some of the OS internal structures like a pointer to an opened
ﬁle. Since most operating system calls are also non-deterministic,
we require that the program will not make any non-deterministic
operating system or standard library calls. We remark that this re-
striction can be bypassed by writing function stubs that preserve
that determinism of the program. Currently, we implemented such
stubs only for the essential malloc() and free() functions.
See Section 4.5 for further discussion. Similarly, multi-threading
could ruin the determinism, so we require that our delegated pro-
gram use only one thread.
4.2 Adaptation of the Protocol for X86
We decided to implement the prototype directly with X86 assem-
bly, for stand-alone programs. We believe that using X86 assembly
is both cleaner to use and general for further development (e.g.,
using C++ programs instead of only C).
Instead of the Turing Machine’s transitions table, the computa-
tion is described by assembly instructions. Each step of the proto-
col is now an execution of a single X86 instruction. When the client
needs to compute a single step by himself, he should be able to ex-
ecute a single X86 instruction given the needed registers and mem-
ory. We remark that some X86 instructions are non-deterministic
by deﬁnition (e.g. CPUID, RDTSC) and we assume the program
does not use them (this can be restricted during build).
The equivalent of a Turing Machine state is the current values
of all the CPU registers (e.g., eax, ebx, etc). We initialize those
registers before the execution of the program.
Last, we replace the Turing Machine working tapes with the pro-
cess’ stack and heap memories. We assume these memories are
initialized to zero, which is the equivalent of an empty tape. Un-
der reasonable assumptions on the cloud operating system we can
work with ﬁxed base-addresses for those memories and therefore
get fully deterministic memory operations (i.e., even pointers to
the memory will have deterministic addresses for each execution
of the program).
The reduced-conﬁguration equivalence in this model would be
the values of all CPU registers (the equivalent to the Turing Ma-
chine’s state and head position) and two hash values. Those hash
values are the root values of the Merkle Hash Trees of the current
stack and heap memories.
The proof of correctness of the resulting protocol is similar to
the proof of protocol from Section 3.3.
4.3 System Architecture
The client has a source code in C of a program prog.exe that
he wishes to delegate. The programmer does not have to write his
program in some new or restricted language, he can write his pro-
gram in the same way he writes any C program. For simplicity of
the description here we assume that the input to the program is part
of the program itself (hard-coded) and that the result of the pro-
gram is an integer. Speciﬁcally, we assume there is a function with
the prototype int client_program(). Those restrictions can
be easily eliminated (e.g., by using a pre-allocated buffers for in-
put/output before/after the program execution).
Given the source code, the client builds the program using a sup-
plied makeﬁle. This makeﬁle basically links the program with a
wrapper code, sets the code base-address to be static and statically
links all libraries. We set the code base-address to be static so the
operating system’s loader will load the program to the same mem-
ory address for all executions. Similarly, since shared libraries can
be loaded to any memory address, we statically link all libraries so
they will be (again) loaded to speciﬁc memory addresses.
The wrapper code corresponds to the Turing Machine initializa-
tion. It initializes to zero all the general use registers and the re-
quired stack memory, it allocates a large amount of memory to be
used as the program heap and calls client_program(). Also,
the makeﬁle links a code for malloc() and free() that uses the
pre-allocated memory instead of the regular heap. Here we use the
fact that Windows allocates large memory segments (e.g. 2 GB) in
almost deterministic addresses. See Figure 1 for a pseudo-code of
the wrapper function.
After the client builds his program with the supplied makeﬁle,
he sends the executable to each of the servers. Now, the protocol
itself starts.
450int main(){
int i;
int result;
void *heap;
char *stack;
/* Init stack memory
*/
/* STACK_SIZE is usually 2^20 */
_asm{
mov stack, esp
}
for(i=0;i<STACK_SIZE;i++){
*(stack-i) = 0;
}
/* Init heap memory
/* HEAP_SIZE is usually 2^30
heap = calloc(HEAP_SIZE);
/* Init all registers
_asm{
mov eax,0
mov ebx,0
...
/* Setting esp to be the
start of a memory page
mov eax, esp
and eax, 0xfff
sub esp, eax
}
/* Execute original program
_asm{
call client_program()
mov result, eax
*/
*/
*/
*/
*/
}
}
Figure 1: Quin wrapper function.
The prototype consists of three main tools: QuinExecuter,
QuinClient and QuinServer. The client runs the QuinCl-
ient on his machine and the servers run QuinServer and Qui-
nExecuter on their machines. QuinExecuter is a tool for ex-
ecuting a program for a given number of instructions. It can store
the program state or continue execution from a previously stored
state. QuinClient and QuinServer are python implementa-
tions of the protocol itself.
The Merkle Hash Tree is computed with granularity of a 4Kbyte
(a page-size), i.e., the lowest level of the tree are hashes of 4Kbyte
segments. (This is why our wrapper function moves the esp regis-
ter to the beginning of a page.)
4.3.1 QuinExecuter
For executing a program for a given number of instructions, we
need a way to count in real-time the number of executed instruc-
tions. There are several ways to do that:
• Use the CPU internal instructions counters:
this is a very
efﬁcient method, but requires to change the OS in order to
differentiate between our instructions and other OS instruc-
tions.
• Extend the compiler: instead of emitting the programmer’s
code as is, add to it few assembly instructions that increment
a counter before each original assembly instruction.
The downside is that we have to do it for every high level
language compiler although the protocol itself works with
the assembly instructions.
• Use OS debug API: execute the program step-by-step. Since
it is out-of-process debugging, it is very inefﬁcient.
• Static instrumentation: given an executable, transform it to a
new executable with the other needed instructions (i.e., that
increment a counter).
• Dynamic instrumentation: similar to static instrumentation,
but done in run-time.
Our method of choice is to use a dynamic instrumentation tool,
speciﬁcally Intel’s PIN [17]. Although dynamic instrumentation
has potential for substantial overheads over static instrumentation,
PIN has many beneﬁts for our use. PIN is very efﬁcient (compared
to other dynamic instrumentation frameworks), very convenient for
rapid development, well supported by Intel, and most importantly,
works the same in Windows and Linux environments. PIN runs
the program inside a Virtual Machine and uses Just-In-Time (JIT)
compilation of the instrumented code. The PIN developer writes
a piece of code that is called a PIN-tool, which is a description of
where to instrument and what code to put there. In order to run
the PIN-tool, only four binary ﬁles are needed (.exe and .dll
ﬁles), and no setup is required. The PIN-tool itself is another .dll
binary.
QuinExecuter is basically a PIN-tool. The naive way to
get our goal is that QuinExecuter adds instrumented code for
counting steps and checking whether we reached the needed num-
ber of steps. This would be the main overhead of our implementa-
tion, as for each executed instruction of the original executable we
add code that increments a 64 bit counter and checks whether this
counter reached some threshold. This means that for each assem-
bly instruction of the original program we add around 10-15 new
assembly instructions. Our implementation actually uses a simple
heuristic to reduce this overhead. Instead of adding the code for
each instruction, we add the code only once for each basic-block (a
sequence of code with only one entry point and one exit point). For
each basic block we increment the counter according to the basic
block’s number of instructions. Since we want to be correct with
a granularity of a single instruction, when we get close enough to
our threshold (say, 500 instructions below the threshold), we re-
instrument the code and add our code before each instruction (as
in the naive way). We note that since we are interested in precise
granularity for all types of computations, this heuristic seems to
have the best tradeoff between efﬁciency and accuracy.
After it reaches the needed number of steps, it dumps the current
state of the memories (we separate the stack and the heap for efﬁ-
ciency) and all the registers values to a ﬁle. When requested, it can
do the opposite, start a new process, restore a state from a given ﬁle
and continue the execution of the process from this state. The way
it does those operations is by reading and writing directly the stack
and the heap whenever needed.
In order to handle memory, we use the following two methods:
• For stack memory: In order to get full determinism, all
memory should be initialized before use. Since the operat-
ing system do not initialize the stack by itself, our wrapper
function does it before the call to client_program().
We use the maximal stack size that is deﬁned during the pro-
gram linkage.
• For heap memory: As already noted, we implemented our
own malloc() and free(). Those functions uses a pre-
allocated memory, and stores its state in a pre-deﬁned mem-
ory areas, so when needed to dump or restore a state, our
PIN-tool can work directly with those internal structures.
For the protocol itself, we deﬁne the maximal size of the heap
memory to be constant (e.g., 230 bytes). As this memory is
451pre-allocated, we set this memory to zero before the execu-
tion of client_program().
QuinExecuter is implemented in C and Assembly, and uses
several low-level techniques in order to get efﬁcient instrumented
code.
We note that since we assume the client has the source-code of
the delegated program, we could have chosen to change the build
process in order to create a different executable that can directly
give us the above functionalities. However, our future goal is to re-
place the use of our makeﬁle (that adds the wrapper function) with
another binary instrumentation, in a way that our PIN-tool could
work directly with any stand-alone executable (e.g. commodity
software). This PIN-tool will ﬁnd main() and wrap it with our
wrapper function using instrumentation. In addition, it will locate
malloc() and free() and replace them with our implementa-
tion of those functions.
4.3.2 QuinServer
QuinServer is a pure Python program that takes an executable
as input and implements the server side of the protocol. It is a state-
machine. It waits for the client’s connection and then waits for his
commands. The ﬁrst command the server receives is RUN, and,
as a response, the server executes QuinExecuter with the input
executable and returns its result to the client, including the return-
ing value of client_program(), the number of steps of the
execution and several other low-level information on the execution
itself. Then, if the client decides to proceed to the binary search
stage (in case of inconsistency between the servers’ answers), the
server receives the command GetReducedState i. As a response,
the server now sends the values of all CPU registers and two hash
values. Those hash values are the root values of the Merkle Hash
Trees of the current stack and the current heap. This command is
received for all the binary search requested conﬁgurations.
After the client ﬁnishes the binary search stage, it simulates one
instruction based on the registers that the servers sent for the ng
step. In case the simulated instruction requires to use some mem-
ory, either from the stack or the heap, the client sends the command
GetMemory i, address. Then, the server sends the memory value
of the requested address, augmented with a Merkle Hash Tree proof
that this value is consistent with the root values it sent before (for
step i).
4.3.3 QuinClient
QuinClient is a python program that implements the client
part of the protocol. It connects to the servers, sends the command
RUN to all of them and compares their answers. In case of con-
sistency, it can output the correct result of client_program()
and quit.
In case of inconsistency, it executes the binary search
and ﬁnds the step where the servers disagree (by using the GetRe-
ducedState i command). Then, it simulates the instruction for step
ng using an open-source X86 emulator called PyEmu [3]. In order
to support the use of PyEmu in our prototype, we implemented a
new object that encapsulates the veriﬁable memory accesses using
the GetMemory i command. When PyEmu needs some memory
page, QuinClient asks one of the servers for it. The server sends
that page along with Merkle Hash Tree proof for this page. Then,
QuinClient veriﬁes that proof and feeds PyEmu with the re-
ceived page. Last, QuinClient uses the emulation result (the
written memory data and the values of the registers) to compute
the correct reduced conﬁguration for step nb, compares it to the
servers’ answers and declares the correct output. We remark that
PyEmu does not support the full X86 instruction set, but it does
support the instructions most compilers generate. (Also, it is easy
to add other instructions if needed.) Quin inherits this limitation.
4.4 Evaluation
We conducted several experiments with our Quin prototype in or-
der to test the practicality of our protocol. We separated the evalua-
tion of the protocol and the evaluation of our main tool, QuinExe-