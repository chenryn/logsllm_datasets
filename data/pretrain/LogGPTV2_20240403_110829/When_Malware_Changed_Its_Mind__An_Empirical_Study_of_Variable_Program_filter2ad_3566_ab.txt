tify whether similar parameters are chosen (e.g., create a ﬁle
with the same ﬁlename) or on contrary, the parameters are
randomized or very different among executions, therefore,
malware detection signatures should not incorporate them.
We also perform IQR measurements on the count of unique
parameter values,to get a precise picture of what, and how,
changes across multiple executions.
1An example is the authors’ ﬁleserver, which stored so many ﬁles at one
time that it crashed our backup service.
Figure 1: A sample signature from SIGMA.
2.2 Finding Behavioral Invariants
As we introduced in the previous section, actions are a com-
mon abstraction to represent units of behavior. On top of that,
researchers have proposed many different models to build sig-
natures by expressing patterns over sets of actions. While the
literature of models is very rich, ranging from simple ngrams
or ordered bags [10] to complex graph-based structures [24],
the industry still lacks a common framework for expressing
and sharing behavioral models (the role that Yara [3] plays
for static signatures).
To the best of our knowledge, the only available resource
that contains a sufﬁciently-large set of signatures of this kind
is provided by SIGMA [44], a project that proposes a lan-
guage to express patterns for log analysis. As OS audit logs
contain information about the interaction of each process with
the environment (something equivalent in nature to system
calls or the abstract actions in our model) the language used
to express SIGMA rules allows analysts to write Yara-like
pattern over the runtime events of a sample.
By reviewing previous papers and the SIGMA ruleset, we
found that a common building block of all these signatures is
the ability to check for the presence of an action and match
a portion of the its parameters (typically through a regular
expression). For instance, Canali et al. [10] use the action
type and the full parameter value to create complex signatures.
Similarly Trinius et al. construct a representation of malware
behavior that uses the action type and parts of the parameters
to create a behavior proﬁle for their malware and Trinius
et al. [51] use an exact match on their proposed features.
This is also the case for SIGMA rules, as the one reported in
Figure 1, which matches a process creation action in which
the command line parameter matches the speciﬁed pattern.
Our goal is not to create signatures nor to evaluate different
signature models. Instead, we want to measure which constant
elements exist across multiple executions, with the assump-
tion that any good signature would need to build upon these
elements and avoid using information from other transient
behaviors.
For this reason, we break down each parameter value in a
set of tokens according to classic windows delimiters [49]—
such as backslashes for directories and spaces for command-
line arguments—and study the evolution of each token both
3490    30th USENIX Security Symposium
USENIX Association
sigma/rules/windows/process_creation/win_apt_apt29_thinktanks.ymlFlorian Rothrefactor: moved rues from 'apt' folder in respective folders03ecb3bon Feb 10 contributors21 lines (21 sloc)  674 BytesBlametitle: APT29id: 033fe7d6‐66d1‐4240‐ac6b‐28908009c71fdescription: This method detects a suspicious powershell command line combination as used by APT29 in a campaign against US think tareferences:    ‐ https://cloudblogs.microsoft.com/microsoftsecure/2018/12/03/analysis‐of‐cyberattack‐on‐u‐s‐think‐tanks‐non‐profits‐public‐secttags:    ‐ attack.execution    ‐ attack.g0016    ‐ attack.t1086author: Florian Rothdate: 2018/12/04 logsource:category: process_creationproduct: windowsdetection:selection:CommandLine: '*‐noni ‐ep bypass $*'condition: selectionfalsepositives:    ‐ unknownlevel: criticalsigma/win_apt_apt29_thinktanks.yml at master ꞏ Neo23x0/sigmahttps://github.com/Neo23x0/sigma/blob/master/rules/windows/process_c...1 of 16/9/2020, 7:31 PMNum. samples
Num. machines
Num. executions
PUP
Mal
2424
1621
0.5M 0.9M
1.1M 2M
Ben
22443
4M
4.5M
Table 1: Dataset summary.
individually and aggregated with other tokens extracted from
the execution traces. As an example, we observed that around
70% of the SIGMA rules contain at least one of such token,
conﬁrming their role of building blocks for more complex
signatures.
3 Dataset
The dataset we are using is a collection of 7.6M execution
traces that the AV vendor has collected across 5.4M real users
during the year of 2018. The data is collected by a component
of the AV engine that is responsible for behavior-based detec-
tion. This component records high-level behavioral data about
the executed programs until they terminate or until the system
is able to classify them as either benign or malicious and
kill. For the sake of validity, our data only includes programs
that terminate normally. Therefore, unlike data collected from
sandboxes, our data is not limited to few minutes of execu-
tion and because the traces are collected from real users, they
do not suffer from the limitations introduced by synthetic
analysis environment. Our data does not consist of malware
samples that were executed intentionally for data collection,
but samples that at the time of collection were not yet known
to be malicious or pup and were able to evade the static mal-
ware detection solution installed on the computers. Our data
is a reﬂection of the set of threats with which the behavioral
detection components need to combat.
Dataset coverage statistics. Each item in our data consists
of a sequence of behavioral actions performed by a sample
together with SHA-256 hash of the sample, an anonymous
machine identiﬁer and a timestamp. Thanks to the unique
SHA-256 hashes of the samples, we were able to query Virus-
Total (VT) in the following year (2019) of the data collection
and identify the corresponding labels assigned to those sam-
ples by various AV engines. While we labeled the samples
that were consistently labeled as benign by all AV products,
we label samples as malicious or PUP using AVClass [46], a
state-of-the-art technique for massive malware labeling. From
the VT reports obtained in August 2019, AVClass identiﬁed
22,443 benign, 2,424 malware and 1,621 PUP samples, as
listed in Table 1. We perform our variability analysis on exe-
cution ﬂows we were able to label with high conﬁdence and
those that were observed in at least 10 machines. This ex-
perimentally chosen threshold made it possible to accurately
Windows 7
Windows 10
Windows 8.1
Windows Server
Windows XP
Other Windows Versions
Ratio
56%
35%
3.1%
2.6%
2%
1.3%
Table 2: OS version distribution.
measure variability of the sample sample across different
machines. 85% of the samples were executed between 10
and 100 machines, rest were observed in more than 100. The
data was collected from computers from across 133 countries:
USA(48%) and China (14%) have the largest fraction of our
data points.
In Table 2 we show the distribution of the Operating Sys-
tems for the machines in our dataset. The vast majority of
machines run the Windows 7 build 7601 and the rest run a
ﬂavor of Windows 8.1 or 10. 55% of the executions happen
less than one week apart, while respectively 12%, 6%, 4%
and 3% are executions that were collected after the second,
third, fourth and ﬁfth week from the initial recorded execution.
On the 11% of the samples’ re-execution happens 9 weeks
after the ﬁrst appearance of the malware. As a matter of fact,
we measure the time variability for the executions happening
during the ﬁrst 4 weeks after the ﬁrst appearance, covering
over 80% of the executions. For instance, a crypto miner sam-
ple ﬁrst appeared on April 5th and within 7 days we had 47
executions from 35 machines. During the next 7 days we
captured 18 executions, 4 of which on new machines. In the
3rd week we record the last 7 executions, none of which from
any new machines.
Execution statistics. An execution trace is composed of
multiple actions. The actions are heuristically-deﬁned be-
havior units such as ﬁle creation/modiﬁcation, registry key
creation/modiﬁcation, mutex creation etc. In addition to those
common behaviors analyzed largely by the literature, we also
have some behavioral actions that were deﬁned by the security
vendor such as disable Windows defender, disable updates,
change ﬁrewall options, keylogging, change IE settings etc.
In table 3 we show the top 8 action types in our dataset
which corresponds to 87% of the whole data. On average,
per execution trace we identiﬁed 150 actions out of which
39 are ﬁle creations. In our study, due to space constraints
we present the action level variability analysis for a subset of
these actions. To this end, we set the following criteria:
1. Action occurs in any execution in more than 25% of
the machines. To measure a non-zero machine variabil-
ity of a certain action with IQR, it is necessary to observe
it at least 25% of the machine.
USENIX Association
30th USENIX Security Symposium    3491
Ratio of dataset
File Create
Mutex Create
Registry Set
ProcessLoad
PECreation
RegistryKeyCreated
DirectoryCreated
ServiceCreation
Others
26%
20%
14%
8%
6%
6%
4%
2%
14%
Table 3: Ratio of action types over all the dataset.
2. More than 1 action appears in the executions. If the
action happens only once in executions, it is not possible
to measure its variability (the only possible result could
be 0 or 1.
7 of the actions in Table 3 meets this criteria. More details
for other actions in our dataset are provided in Tables 8 and 7
in Appendix.
Ethical Considerations. As mentioned earlier, we did not
distribute or launch any samples on the user machines; instead,
all the executions in our data set were triggered by the users,
and the malware and PUPs we report reﬂect real-world attacks
agains those machines. The anti-virus detects and blocks
all the malicious samples known at the time and collects
execution traces for samples that remain suspicious, in a last-
resort effort to discover unknown malware. In consequence,
we do not cause any harm to the machines in our study that
would not have occurred without the anti-virus product and
our data collection. Moreover, future updates to the anti-virus
will clean the infected hosts once the malware is discovered,
owing to the data collection. The behavioral analysis data
was collected from users who opted in sharing their data.
Necessary anonymization actions are taken to preserve the
privacy of the customers. None of the data ﬁelds in the dataset
contains any identiﬁable information.
4 Behavior Variability in the Wild
In this section, we analyze the variability we observed in
the behavior of malware, PUP, and benign programs when
executed on different end-user machines. We measure both the
action variability and the parameter variability, as discussed
in Section 2.1. We ﬁrst conduct these measurements across
space (the differences among a sample’s execution traces on
different machines) and time (the differences among its traces
in different weeks).
In our data, some executions contain duplicates (i.e., the
same action type with the same parameter value). This could
happen for example when a sample opens the same ﬁle mul-
tiple times. As these operations are idempotent with respect
to the our behavioral speciﬁcations, deﬁned in Section 2.1,
we perform deduplication on our data before we apply the
variability analysis.
4.1 Machine Variability
We start by measuring the variability of executions of the
same sample across different machines. Our goal here is to
understand whether this phenomenon exists and if it does, on
which type of executables it is more prevalent. We only look
at executions of a sample that happen max one week apart
to identify variability that happen only due to being run on
different machines not due to time.
4.1.1 Action Variability
We analyze action variability through IQR and MAD. In or-
der to understand the impact of the outliers on the results,
we also look at the difference among 90-10 and 99-1 per-
centiles. Figure 2 illustrates the distribution of IQR variabil-
ity, across all actions (Figure 2a) and only for the two most
common actions we observed in our dataset: ﬁle creation (Fig-
ure 2b) and registry modiﬁcation (Figure 2c). The numbers
between parentheses for each category is the number of sam-
ples that we use for our variability analysis. Because not all
samples had ﬁle creation or registry key modiﬁcation actions
in their executions, these numbers are lower than the total
number of samples (Table 6 in the appendix provides a de-
tailed breakdown of action variability). The separate boxplots
for malware, PUP and benign samples allow us to compare the
action-variability distributions within these categories and to
assess the extent of these differences. To conﬁrm these visual
observations we compare these empirical distributions using
pairwise U-tests [33], a non-parametric method for inferring
whether the samples are likely drawn from distinct distribu-
tions. In the paper, we report differences that are statistically
signiﬁcant at p  59 actions longer that its bottom 25% traces, for half of the
malware samples in our dataset. In contrast, the median IQRs
are 19.25 and 8 actions for PUP and benign, respectively. We
observe similar trends with the MAD measurements. While
3492    30th USENIX Security Symposium
USENIX Association
(a)
(b)
(c)
Figure 2: IQR action variability for all actions and the two most common actions in our dataset.
the average difference from the median for malware is 35.5
actions, for PUP and benign, it is 10.3 and 2.9 respectively.
This leads to the question where does this variability come
from? When breaking down the variability according to action
types, we observe a striking difference for ﬁle creation actions
(Figure 2b). The median IQR for malware is 15× larger than
for PUP and benign samples, and the bulk of the distribution
includes much larger values. In contrast, the variability dis-
tributions for PUP and benign samples do not appear to be
different for ﬁle-creation actions, while PUPs exhibit more
variability for registry-modiﬁcation actions (Figure 2c). This
suggests that malware classiﬁcation solutions based on ﬁle
creation actions could lead to inaccurate results, as the high
variability among the execution traces of a sample may place
some of these traces in different clusters; we investigate this
in more depth in Section 6. Conversely, a malware detector
able to observe executions on multiple hosts could utilize
ﬁle-creation variability as an indicator of malicious behavior.
Case study. We refer back to the Ramnit sample in Section 2
At least 25% of the executions occur on Windows 7 machines
where the malware is running with user privileges. Therefore,
the malware runs a privilege escalation exploit causing a large
number of mutex creations. The rest of the executions happen
in different OS version or with admin privileges, thus the
executions are shorter. The action variability is affected by
the longer executions showing an IQR of 34, which is the
number of mutex creations.
There is a signiﬁcant variability on the behavior of
malware among different machines. When malware
detection solutions rely on data collected only from
one sample up to 200 (med. 59) behaviors could be
underrepresented in the detection model.
Even though malware still shows a signiﬁcantly higher
variability when expressing the variability in terms of the
90–10 and 99–1 percentile ranges instead of the IQR, the
action-variability distribution of malware becomes harder to
distinguish from the PUP and benign distributions This is
not surprising as these measures are not as robust to outliers
75th percentile
PUP
e
l
i
F
E
P
M
R
Path
Name
Ext.
Path
Name
Ext.
Key Path
Key Name
Value
D
Path
RC
Path
MC Name
P
CMD line
Median
PUP
1
2
1
-
-
-
1
2