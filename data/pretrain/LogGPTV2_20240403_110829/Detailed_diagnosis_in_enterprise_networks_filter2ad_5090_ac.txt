represents a trade-o(cid:11)—bigger bins have lower overhead of capturing
component state but limit our ability to diagnose short-lived faults.
ˆe value of a variable represents some aspect of the component be-
havior during that time bin. ˆe number of variables and their mean-
ings vary across components. Table ʇ shows a subset of aspects that
are currently included for each component type.
A process is identi(cid:12)ed by its complete command line, rather than
the process ID. Such identi(cid:12)cation ensures that across machine re-
boots and process restarts, process instances with the same command
line (e.g., c : \mssql\bin\sqlservr.exe− ssqlexpress) are considered to
be the same functional component [ʆʃ].
Process state is a union of two parts. ˆe (cid:12)rst part captures
generic, application-independent aspects such as resources con-
sumed and tra(cid:14)c exchanged. We maintain tra(cid:14)c information per
port and also log which other processes this process communicates
with, which is used for dependency graph generation. ˆe second
part of process state consists of application speci(cid:12)c variables and re-
(cid:8)ects di(cid:11)erent aspects of current application experience such as frac-
tion of failed requests, number of requests of a certain type, etc. In-
cluding it in the process state lets us diagnose application speci(cid:12)c ab-
normalities without application knowledge.
We describe in §ʉ how various component state variables are cap-
tured, including how application-speci(cid:12)c variables are captured with-
out application knowledge.
5.2 Generating the dependency graph
We model the network as a dependency graph among compo-
nents in which there is an edge from a component to each of its di-
rectly dependent components. We automatically generate this graph
using a set of templates, one template per component type. Figure ʇ
shows the set of templates we have currently de(cid:12)ned. A template has a
component type in the center, surrounded by other component types
that impact it directly. Edges in the real dependency graph corre-
spond to edges in the templates. For instance, if the template for a
machine shows that it depends on its processes, we introduce an edge
from each of its processes to it.
ˆe templates in Figure ʇ can be easily interpreted. ˆey show
that a machine depends on its processes and its con(cid:12)guration. An
application process depends on its con(cid:12)guration, its NbrSet, its host
machine, and the con(cid:12)guration of the machine. While a process re-
lies on other processes on the machine because of resource sharing,
we do not include that dependency directly in the templates. For non-
communicating processes, that dependency is indirect, mediated by
the machine. We currently ignore inter-process interaction that does
not involve exchanging IP packets (e.g., through shared memory).
IP communication is captured using NbrSet. ˆe NbrSet of a process
depends on local and remote (cid:12)rewall con(cid:12)gurations, the processes
it is communicating with and the network paths. Finally, a network
path between two machines depends on all machines that inject traf-
(cid:12)c into it and the amount of other tra(cid:14)c, that is, tra(cid:14)c from hosts
outside the monitored network.
247In our current templates, con(cid:12)guration components do not de-
pend on anything else. If con(cid:12)guration changes explain the e(cid:11)ect be-
ing diagnosed, we identify the con(cid:12)guration component as the cul-
prit, without attempting to identify what changed the con(cid:12)guration.
Extending NetMedic to remember what modi(cid:12)ed the con(cid:12)guration
can enable such identi(cid:12)cation if needed [ʆʃ].
We can see from the templates that the resulting dependency
graphs can be quite complex with a diverse set of dependencies and
many cycles, e.g., Processʄ → NbrSet of Processʅ → Processʅ →
NbrSet of Processʄ → Processʄ. ˆe next section describes how we
perform an accurate diagnosis over this graph.
5.3 Diagnosis
Diagnosis takes as input the (one-minute) time bin to analyze and
the time range to use as historical reference. ˆis time range does not
need to be contiguous or adjacent to the time bin of interest. We only
assume that it is not dominated by the fault being diagnosed. For
instance, if a con(cid:12)guration fault occurs at night but its e(cid:11)ect is ob-
served the next morning, NetMedic needs historical reference before
the fault (e.g., the previous morning) to diagnose the e(cid:11)ect. Option-
ally, the operator can also specify one or more a(cid:11)ected components
whose abnormal behavior is of interest. If le(cid:13) unspeci(cid:12)ed, we identify
such components automatically as all that are behaving abnormally.
ˆe output of the system is a ranked list of components that are im-
pacting each a(cid:11)ected component of interest. ˆere is a separate list
for each a(cid:11)ected component.
Diagnosis proceeds in three steps (Figure ʆ). First, we determine
the extent to which various components and variables are statistically
abnormal. Second, we compute weights for edges in the dependency
graph. ˆird, we use edge weights to compute path weights and pro-
duce a ranked list of likely culprits.
5.3.1 Computing abnormality
Given historical values of a variable, we want to detect how ab-
normal its value is at the time of diagnosis. For purposes that will
become clear later, we need a (cid:12)ne-grained measure of abnormality in
addition to a simple binary decision as to whether a variable is ab-
normal. While the semantics of some variables may be known, most
have application-speci(cid:12)c, undocumented semantics. Our goal is not
to cra(cid:13) a perfect detector but to design a simple one that works well
in practice without knowing semantics before hand.
For abnormality computation, we assume that the values of the
variable approximate the normal distribution. Per the central limit
theorem, this is a reasonable assumption because the values of our
variables tend to be sums or averages (e.g., memory usage) over the
sampling time bin. If µ and σ are the variable’s mean and standard
deviation over the historical time range, the abnormality of value v at
the time of diagnosis is |erf( v−µ
)|, where erf(.) is the error function.
σ√2
ˆe formula is double the probability of seeing values between µ and
v in a normal distribution with parameters µ and σ. It ranges from ʃ
to ʄ, and the higher end of the range corresponds to values that are
far from the mean, i.e., towards the tails of the normal distribution.
Given the abnormality for each variable, the abnormality of a
component is the maximum abnormality across its variables.
ˆe abnormality values computed above are used in two ways.
ˆey can be used directly, for instance, as multiplicative factors. ˆis
usage is robust to the exact method for computing abnormality as
long as the (cid:12)rst order trend of the variable values are captured such
that less likely values have higher abnormality.
ˆe abnormality values are also used to make a binary decision
as to whether a variable or component is abnormal. For this deci-
sion, we use a threshold of ʃ.@. Like all binary decisions of abnor-
mality, we face a trade-o(cid:11) between (cid:8)agging a non-existent abnor-
mality and missing a real one. We prefer the former because our edge
weight computation assumes that normally behaving components do
not impact others. ˆus, declaring potentially abnormal components
Process 1
Process K
Machine config
Machine
Machine
Application 
process
NbrSet
Machine config
Application config
Path to Nbr 1
Nbr 1 process
Path to Nbr K
Nbr K process
Nbr 1 firewall
NbrSet
Nbr K firewall
Local firewall
Machine 1
Machine K
Path
Other Traffic
Figure ʇ. ˆe templates used by NetMedic to automatically gener-
ate the dependency graph.
as normal is less desirable than the other way around. Our chosen
threshold re(cid:8)ects this preference.
5.3.2 Computing edge weights
Let S and D be the source and destination of a dependency edge.
If either S or D is behaving normally, it is unlikely that S is impacting
D and we assign a low weight to the edge. ˆe exact value of the edge
weight is not critical in this case. However, since computing path
weights involves multiplying edge weights, edge weights of zero are
brittle in the face of errors. Hence, we use an edge weight of ʃ.ʄ in
our experiments.
If both S and D are abnormal, we use their joint historical behav-
ior to determine the edge weight. Let Snow and Dnow be their respec-
tive states during the time bin of diagnosis. We (cid:12)rst divide the his-
tory where both components co-exist into K equal-sized chunks, each
consisting of one or more time bins. Within each chunk we identify
the time bin in which S was in a state most similar to Snow. We then
compute how similar on average D was to Dnow during those times.
More precisely:
E(S → D) =
∑K
k=1(1−|Dtk − Dnow|)× wk
∑K
k=1 wk
,
(ʄ)
where tk is the time bin in chunk k where the state of S was most sim-
ilar, and |Dtk − Dnow| is the di(cid:11)erence between the two state vectors.
ˆe di(cid:11)erencing of two states (explained below) produces a number
between ʃ and ʄ.
ˆe term wk is a relative weighting factor for di(cid:11)erent chunks.
We specify wk = 1−|Stk − Snow| if |Stk − Snow| ≤ δ; it is ʃ otherwise.
ˆis speci(cid:12)cation places a higher weight on historical states that are
more similar. And it excludes chunks of time where the most similar
source state di(cid:11)ers by more than δ. Because historical states that di(cid:11)er
more already have a lower weight, the main reason for this cuto(cid:11) is
to avoid computing the probability based on dissimilar states alone.
Our experiments use a relaxed δ of 1/3.
Dividing the history into K disjoint chunks and looking for the
most similar state in each helps base the weight computation on a
diverse set of time windows. Alternately, we could pick K time bins
where the source state was most similar. But this method could bias
results to temporally close bins that may be dependent, leading to a
less e(cid:11)ective factoring out of other aspects that impact the destina-
tion state. We (cid:12)nd that even small values of K su(cid:14)ce for accurate
diagnosis. We use K = min(10, number of time bins in history) for ex-
periments in this paper.
When no usable historical information exists, e.g., because of in-
su(cid:14)cient history or because similar source states do not exist, we as-
sign a high weight of ʃ.@ to the edge. ˆis assignment assumes that
a fault is more likely to stem from a component that was not seen
in a similar state previously. It has the desired behavior of assuming
impact rather than exonerating possibly responsible components.
ˆe basic procedure for di(cid:11)erencing states: When computing
state di(cid:11)erences, our intent is to get a robust measure of how dif-
ferently a component is behaving at di(cid:11)erent points in time. State
248di(cid:11)erences are based on di(cid:11)erences in the values of individual vari-
ables. ˆe di(cid:11)erence between two state vectors with L variables is
∑L
i=1 |di|/L, where di is the di(cid:11)erence of the i-th variable normalized
by the observed range. ˆat is, di = (vi
min), where
vi
tk and vi
now are the values of the variable at the two time bins, and
vi
max and vi
min are the maximum and minimum values observed across
all time. Normalization means that the di(cid:11)erence for each variable is
between ʃ and ʄ. It ensures that a variable does not dominate because
its values are drawn from a bigger range.
max − vi
tk − vi
now)/(vi
Con(cid:12)guration components are handled di(cid:11)erently for computing
state di(cid:11)erences. ˆe di(cid:11)erence is zero if the values of all variables
are identical. It is one otherwise. For con(cid:12)guration components, any
change in the value of even a single variable could represent a signif-
icant functional shi(cid:13). We thus err on the side of deeming every such
change as signi(cid:12)cant.
Robust weight assignment with unknown variable semantics:
ˆe procedure above is a starting point; while it works well in some
cases, it is not robust to the presence of a large and diverse set of vari-
ables in component states. ˆe underlying problem is that it equally
emphasizes all variables, irrespective of the fault being diagnosed,
the uniqueness of the information represented by that variable, or
whether the variable is relevant for interaction with the neighbor un-
der consideration. Equal emphasis on all variables dilutes state di(cid:11)er-
ences, which hinders diagnosis. For instance, even when a runaway
process is consuming ʄʃʃʂ of the CPU, its state may appear similar
to other times if the vast majority of its state variables are unrelated
to CPU usage.
If we knew variable semantics, we could pick and choose those
that matter to the fault being diagnosed. We now describe exten-
sions to the basic procedure that create a similar e(cid:11)ect without re-
quiring knowledge of variable semantics. ˆe simplest of our exten-
sions leverages the abnormality of variables and the others are based
on automatically inferring the relevant properties of state variables.
Instead of treating the variables
a) Weigh variables by abnormality:
equally, we use abnormality of a variable as the relative weight in the
state di(cid:11)erence. ˆis weighting biases the state di(cid:11)erence towards
variables related to the e(cid:11)ect currently being diagnosed. For instance,
while diagnosing an e(cid:11)ect related to CPU usage, the abnormality of
aspects related to CPU usage will be higher.
b) Ignore redundant variables: We ignore variables that represent
redundant information with respect to other variables of the compo-
nent. ˆis extension helps prevent an over-representation of certain
aspects of the component’s behavior. For instance, our machines ex-
port used as well as available memory, each in units of bytes, kilo-
bytes, and megabytes. If we include all six variables, the state dif-
ferences will be biased towards memory-related aspects, making it
harder to diagnose other aspects.
To discover variables that are not redundant, we want to look for
independent components [ʄʇ]. Instead of running a full-blown inde-
pendent component analysis, we approximate via a simple heuristic
that works well in our setting. We compute linear correlation be-
tween pairs of variables in the component and then identify cliques
of variables such that the Pearson correlation coe(cid:14)cient between ev-
ery pair of variables is above a threshold (0.8). We select one variable
to represent each clique and deem others to be redundant.
c) Focus on variables relevant to interaction with neighbor: Among
the remaining variables, we ignore those that are irrelevant to inter-
action with the neighbor under consideration. For instance, while
considering the impact of a machine on an application process, we
exclude variables for error codes that the process receives from a peer
process. By reducing the noise from irrelevant variables, this exclu-
sion makes weight assignment more robust.
We infer whether a variable is relevant to interaction with the
neighbor by checking if it is correlated to any of the neighbor’s vari-
ables. Speci(cid:12)cally, we compute the linear correlation between this
variable and each variable of the neighbor. We consider the variable
relevant if the Pearson correlation coe(cid:14)cient is greater than a thresh-
old (0.8) for any neighbor variable. Linear correlation does not cap-
ture all kinds of relationships but is easy to compute and works well
for the kinds of variables that we see in practice.
1 |di|· ai · ri)/(∑L
ˆe state di(cid:11)erence for non-con(cid:12)guration components a(cid:13)er ap-
plying these three extensions is (∑L
1 ai · ri), where L and
di are as before and ai is abnormality of the variable. ˆe term ri is
a binary indicator that denotes if the i-th variable is included in the
computation. It is ʄ if the variable is relevant to interaction with the
neighbor and represents non-redundant information.
Some variables in machine
d) Account for aggregate relationships:
state (e.g., CPU usage) are sums of values of process variables. Simi-
larly, some variables in server process state (e.g., incoming tra(cid:14)c) are
sums of values across its client processes. We discover and account
for such relationships when computing state di(cid:11)erences. ˆe follow-
ing discussion is in the context of a machine and its processes. ˆe
same procedure is used for server and its client processes.
If the variable values of di(cid:11)erent components were synchronized
in time, discovering aggregate relationships would be easy. ˆe sum
of the values of appropriate process variables would be exactly the
value of a machine variable. But because variables values may be
sampled at di(cid:11)erent times, the sum relationship does not hold pre-
cisely. We thus use an indirect way to infer which machine variables
are aggregates. We instantiate virtual variables whose values repre-
sent the sum of identically named process variables; one virtual vari-
able is instantiated per name that is common to all processes. Even
though we do not know their semantics, variables have names (e.g.,
“CPU usage”), and a name refers to the same behavioral aspect across
processes. We then check if any machine state variable is highly cor-
related (with coe(cid:14)cient > ʃ.@) with a virtual variable. If so, we con-
clude that the machine variable is an aggregate of the corresponding
process variables.
We use aggregate relationships in several ways. First, we replace
the variable value in the machine with that of the virtual variable, i.e.,
sum of values of the corresponding process variable. Second, when
computing the edge weight from a machine to its process, we subtract
the contribution of the process itself. Speci(cid:12)cally, as a pre-processing
step before searching for similar machine states, the value of each
aggregate variable in the machine state at each time bin is reduced
by the value of its corresponding process variable. ˆe remaining
process is as before.
Such pre-processing lets us compute the state of the process’s en-
vironment without its own in(cid:8)uence. Without it, we may not (cid:12)nd a
similar machine state in history and hence falsely assign a high weight
for the machine-to-process edge. Consider a case where a runaway
process starts consuming ʄʃʃʂ CPU. If such an event has not hap-
pened before, we will not (cid:12)nd similar machine states in the history
with ʄʃʃʂ CPU usage. Instead, by discounting the impact of the pro-
cess, we will likely (cid:12)nd similar machine states and (cid:12)nd that it is only
the process that is behaving di(cid:11)erently. ˆese (cid:12)ndings will correctly
lead to a low weight on the machine-to-process edge.
Finally, when estimating the impact of a process on the machine,
if similar process states are not found, we assign weight based on the
contribution of the process. ˆat is, we do not use the default high
weight. For each aggregate variable, we compute the fraction that the
process’s value represents in the aggregate value. ˆe maximum such
fraction is used as the weight on the edge. ˆis modi(cid:12)cation helps by
not blaming small processes just because they are new. Arrival of new
processes is common, and we do not wish to impugn such processes
unless they also consume a lot of resources.
5.3.3 Ranking likely causes
We now describe how we use the edge weights to order likely
causes. ˆe edge weights help connect likely causes to their observed
e(cid:11)ects through a sequence of high weight edges. However, unlikely
249A
H
L