图3
 从图3中可以估算出丢包时的拥塞点大约为前5个包所携带的字节数。只要按这个方法随机找出多个拥塞点，就大概能选定合适的窗口值了。
方案3．图2中的Wireshark截图显示重传的包为5190、5192、5194……5230 （20个），而且这些重传包都是连续的（图4显示了其中的一部分）。
图4
但是当我检查接收方的网络包时，发现其实只有5190的原始包是真正丢失了，其他的包都到达了接收方，所以没必要重传。那为什么发送方要重传这么多呢？这是因为发送方发现5190的原始包丢失后，无法确定后续的其他包是否也丢了，只好选择全部重传。而接收方虽然知道丢了哪些包，却没有任何机制可以告知发送方。这个问题其实在1996年的RFC 2018中就已经给出了解决方案，它就是Selective Acknowledgment，简称SACK。在接收方和发送方都启用SACK的情况下，接受方可以告诉发送方“我没收到的只是5190的原始包，但是我收到了其他的。”因此发送方只需重传5190即可。在启用了SACK的网络包中，我们能在Dup Ack包里看到这些信息。图5是在一个启用SACK的环境中抓的包，最底部就是SACK信息。
图5
把图5中的“Ack=991851”和“SACK=992461-996175”两个信息综合起来，发送方就知道991851～992460的包没有收到，而后面的992461～996175的包反
 而已经收到了。
因为本案例中存在大量不必要的重传，而且Dup Ack包中也没有SACK信息，已经足以说明SACK没有启用。我决定先不限制发送窗口，把SACK打开再说。是否启用SACK是在TCP三次握手时协商决定的，如图6中方框内的参数所示。只要双方中有一方没有发“SACK_PERM=1”，那该连接建立之后就不会用到 SACK。
图6
我们分别检查了DataDomain和AIX，果然发现AIX上默认关闭了SACK。于是客户在AIX上运行了“no -p -o sack=1”命令，读性能立即就飙升到90MB/s以上，远远超过项目需求。有了这个结果，我也不考虑方案1和方案2了，毕竟都有副作用。
在他们询问我的名字前，我已经关上车门，只留下一个伟岸的背影，深藏功与名。其实心里还有一个怨念：为什么他们就可以午睡？
棋逢对手
很多IT圈的前辈都有过苦不堪言的经历，尤其是在运维部门。为了挽救系统，不少人曾经在冰冷的机房连续工作十多个小时，旁边还站着咆哮的上司。我从来没有做过一线工程师，所以没有经历过什么惊心动魄的时刻。如果要跟读者分享一个印象最深刻的案例，我首先想到的是一个不算紧急，却特别考验人的问题，至今想起来还心有余悸。
那是一位澳洲客户的文件服务器，它同时为多台Linux应用服务器提供NFS访问。系统在实施阶段非常顺利，于是便择日上线了。不幸的是到了生产环境中，应用服务器访问文件时偶尔会卡一下，而且这症状的出现是不定时的、稍纵即逝的。谁也不知道接下来是什么时候，发生在哪台应用服务器上。经验丰富的系统管理员已经检查过应用服务器、文件服务器和网络设备的所有日志，可惜没有发现有价值的信息。
老油条的工程师都知道，这类问题是最“令人讨厌”的，因为既无报错信息，也不知道何时会重现，根本无从入手。大家宁愿处理丢数据或者宕机的紧急事故，也不愿意去接手这类问题。可怜的系统管理员不时被他的用户埋怨，然后再把压力转移到售后工程师身上。一线的售后工程师扛了一个礼拜没有解决，只好升级到二线。二线工程师撑了一个礼拜也没有收获，最终找到了我。大家可以想象当时那位系统管理员已经有多么沮丧。
问题到了我这里就没法再升级了，只能硬着头皮接下来。我是这样分析该症状的。
1．访问文件时感到卡，可能是文件服务器负载过重，导致了响应慢；也可能是网络拥塞，发生了连续多次的重传。
2．虽然无法预测问题发生的时间，但如果在业务繁忙时抓个网络包，应该多
 少能看到一些端倪。
当我把这个想法告诉系统管理员时，得到的回答却让我颇感意外：“存储上的网络包我已经抓过了，分析下来一点问题都没有。”—在我以往接触过的客户中，不要说分析网络包了，很多人连抓包都不会。这个分析可靠吗？还没等我开口，他似乎看透了我的心思，“网络包上传到FTP了，你也分析一下吧。”
用Wireshark打开网络包之后，我习惯性地试了“性能问题三板斧”。
1．单击Statistics-->Summary。从Avg.MBit/sec看到，那段时间的流量不高，所以该存储的负担似乎并不重（见图1）。
图1
2．单击Statistics-->Service Response Time-->ONC-RPC-->Program:NFS Version:3--> Create Stat，可以看到各项操作的Service Response Time都不错（见图2），这进一步说明该存储并没有过载。
图2
 3．单击Analyze-->Expert Info Composite，从Error和Warning里都没有看到报错，这说明网络没有问题（见图3）。假如有重传、乱序之类的现象，应该能在这个窗口里看到。
图3
分析结果让我有些失望—这个系统看起来如此健康，完全不像是会卡的样子，接下来该怎么处理？看来一定要在出问题的时刻抓到包，舍此之外，别无他途了。我小心翼翼地给管理员写了一封邮件，把分析结果详细地告诉他，并且提出再次抓包的请求。
等待回复时很是忐忑，因为有可能收到一堆抱怨，没想到等来的竟是一个惊喜—他表示遇到一位懂Wireshark的合作者非常愉快，并且准备写一个程序来抓到我需要的包。这个程序会不停地打开文件，当出现卡的症状时，记录时间点并且自动停止抓包。碰到如此讲道理又懂技术的客户，简直让人如沐春风。
好消息接踵而至，几天后网络包真的抓到了，还记录了出问题的时间点。我满怀希望地又试了三板斧，预感这次一定能看到某些迹象，比如特别长的Service Response Time之类的。没想到一番忙活之后，竟然和之前的分析结果一模一样—什么迹象都没看到。
不会是漏抓了吧？考虑到这位管理员的表现非常靠谱，应该不至于犯这样的小错误，我宁愿相信是自己看得不够仔细。就在此时，我又收到一封邮件。原来他也分析完了，一样没有发现什么问题。同时也强调自己没有漏抓，相信问题一定就隐藏在包里。
我不由得会心一笑：好默契的回复！今天算是遇到对手了，这是我工作这么多年来第一次碰到如此厉害的角色。既然三板斧没有用，只能采用笨办法了。我
 先根据问题发生的时间点过滤出前后2秒钟的所有包，然后逐个检查。这下果然看到一个意想不到的包：如图4中的包号 440354所示，NFS服务器172.16.2.80给客户端172.16.2.102发了一个Portmap请求，咨询其NLM进程的端口号。更异常的是这个请求竟然没有得到回复。
图4
NLM我是听说过的，是Network Lock Manager的简称。客户端用它来锁定服务器上的文件，从而避免和其他客户端发生访问冲突。一般都是由客户端查询服务器的NLM端口，这种反方向的状况我还是第一次见到。这个Portmap请求出现在这里虽然有点突兀，不过似乎可以忽略，因为我想不出它跟访问文件卡有什么联系。
遍历了所有包之后，仍然一无所获。我几乎想放弃了，沮丧的感觉就像交卷时还解不出最后一道大题。但要真正放弃又不甘心，毕竟投入了这么多时间了，而且也对不起这么配合的系统管理员。我之所以至今对这个案例如此印象深刻，就是因为工作以来第一次感觉问题这么棘手。
纠结了一天之后，我还是决定从头再来，这次要更细致地分析每一个包。既然目前唯一发现的异常就是那个关于NLM的Portmap查询，那就从它开始吧。我收集了一些资料，重温了一遍NLM的工作原理（虽然我以前懂过，但细节性的东西一段时间没有接触，是很容易忘记的），然后把NLM工作过程总结如下。
1．客户端甲→NLM_LOCK_MSG request→NFS服务器（甲尝试锁定一个文件）客户端甲←NLM_LOCK_RES granted ←NFS服务器（服务器同意了这个锁定）
2．客户端乙→NLM_LOCK_MSG request→NFS服务器（乙尝试锁定同一个文件）
客户端乙←NLM_LOCK_RES blocked←NFS服务器（因为该文件已经被
 甲锁定，所以服务器让乙等着）
3．客户端甲→NLM_UNLOCK_MSGrequest→NFS服务器（甲尝试释放锁）客户端甲←NLM_UNLOCK_RES granted←NFS服务器（服务器同意释放）
4．客户端乙←NLM_GRANTED_MSG←NFS服务器（服务器主动把锁给了乙）客户端乙→NLM_GRANTED_RES accept→NFS服务器（乙接受了）
Wireshark里看到的那个Portmap请求，发生在上面的哪个步骤呢？应该在第三步和第四步之间。就在找到答案的一刹那，我恍然大悟，一下子知道问题出在哪了。
1．第三步之后，服务器要通过Portmap查询乙的NLM端口号（也就是那个诡异的包），得到回复后才能进入第四步。
2．假如查询端口号失败，则第四步无法进行，也就意味着服务器没有办法把锁给乙。
3．由于乙得不到锁，所以只能继续等到超时为止。这对于应用程序来说，就是卡住了。
4．该问题只发生在多个客户端同时访问同一文件的情况下，所以表现为偶发症状。
5．乙没有响应Portmap查询，很可能是包被防火墙拦截了。
我来不及写邮件，就迫不及待地抓起电话，把分析结果告诉南半球的系统管理员。他也非常兴奋，很快就修改了防火墙设置，从此再也没有用户报告过卡的现象。
事情是否到此结束了呢？这个症状的确结束了。不过用户又反馈了另一个症状，这一次连Wireshark都无能为力，最后还是Patrick专门写了段脚本才解决的。由于这个新问题没有多少借鉴意义，所以本书略过不讲。但是写脚本所用到的tshark工具非常有用，我们将在《学无止境》一文中详加介绍。
学无止境
当你用Wireshark解决了一个又一个难题时，再谦虚的人也会自信心膨胀，以为没有什么问题是解决不了的。可惜这只是错觉，因为Wireshark的确有它的应用极限。
我是什么时候意识到这一点的呢？大概两年前我碰到过这样一个问题：接收方不时回复“TCP Window=0”给发送方，导致发送方只能停下来等待。整个传输过程的Sequence Number曲线类似于图1所示，其中水平部分表明接收方当时正在发“TCP Window=0”。
图1
为了给客户出一份专业的分析报告，我需要统计出“TCP Window=0”所导致的停滞总共有多少毫秒。通过图1的横坐标来统计显然不够精确，所以我不得不把所有的问题包过滤出来，逐段统计停滞的时间。像图1这样只有两段停滞时间
 的情况还好，碰到有几十段的时候就很费时了。
为什么我要人工地去做如此简单的重复劳动呢？这明显更适合由程序来完成，但是Wireshark没有提供这项功能。几天后我随口向Patrick提起了这个问题，没想到他立即分享给我一段脚本。我只需要运行以下命令，该脚本就可以把总停滞时间计算出来了。
$ tshark -n -r  -z
'proto,colinfo,frame.time_relative,frame.time_relative' -z
'proto,colinfo,tcp.ack && (tcp.srcport ==  && tcp.dstport ==
),tcp.ack' -z 'proto,colinfo,tcp.window_size && (tcp.srcport ==
 && tcp.dstport == ),tcp.window_size'|awk -f
 指的就是Patrick分享的脚本。由于篇幅所限，我就不把脚本内容贴出来了，这也不是本文的重点。我们真正要关注的是上面用到的tshark命令，它相当于Wireshark的命令行版本。和图形界面相比，命令行有一些先天的优势。
• 如上例所示，命令行的输出可以通过awk之类的方式直接处理，这是图形界面无法实现的。有一些高手之所以说tshark的功能比Wireshark强大，也大多出于这个原因。
• 编辑命令虽然费时，但是编辑好之后可以反复使用，甚至可以写成一个软件。比如我经常需要进行性能调优，那就可以写一段程序来完成本书多次提到过的三板斧（Summary, Service Response Time和Expert Info Composite）。拿到一个性能相关的包之后，直接运行该程序就可以得到三板斧结果，这比起用Wireshark快多了。