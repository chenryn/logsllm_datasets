An experiment can experience the following events: preload,
start, swapin, swapout, swapmod and destroy. Events
preload, start and destroy can occur only once during ex-
periment’s lifetime, while others can occur multiple times. Each
event is processed by one or more testbed scripts and can result
in a success or a failure. Figure 2 shows the state diagram of an
experiment, where state transitions occur on successful events. A
preload event leads to experiment’s virtual topology being stored
swapmod
swapout
swapmod
Figure 2: Experiment state diagram
4. DATA
We analyze eight years of data about DeterLab’s operation col-
lected from its inception in February 2004 until February 2012. As
of February 2012, DeterLab had 154 active research projects (556
research users), 38 active class projects (1,336 users) and 11 active
internal projects (95 users). The testbed consisted of 346 general
PCs, and some special-purpose hardware. Half of the nodes are lo-
cated at UCS/ISI, and other half at UC Berkeley. Table 2 shows the
features of DeterLab’s PCs.
DeterLab runs Emulab’s software for experiment control [24],
which means that all testbed management events such as node al-
Event
preload
start
swapin
swapmod
swapout
destroy
total
Count
10,472
16,043
101,275
36,819
75,156
22,575
262,340
Frequency
4%
6.1%
38.6%
14%
28.7%
8.6%
100%
Table 1: Frequency of experimental events in the dataset
CPU Mem Interf. Count
(GHz)
2.133
2.133
(GB)
Type Disk
(GB)
250
250
72
72
36
36
36
238
1
2
3
4
5
6
7
8
3
3
3
3
3
1.8
4
4
2
2
2
2
2
4
4
4
4
5
4
5
9
5
63
63
32
32
61
60
4
31
Table 2: DeterLab’s node types as of Jan 2011
497Source
DB
DB
FS
Data
events
errors
Meaning
Time, experiment, project, size, exit code for each event.
Time, experiment, cause and error message for each error.
/usr/testbed/expinfo Virtual topology, testbed resource snapshot, and resource allocation log for all
successful and for some unsuccessful resource allocation requests.
Table 3: Types of data analyzed to recreate the experimental events and state of the testbed
location, release, user account creation, etc. are issued from one
control node called boss and recorded in a database there. Ad-
ditionally, some events create ﬁles in the ﬁle system on the boss
node. We analyze a portion of database and ﬁle system state on
this node that relates to resource allocations. We have database
records about testbed events and any errors that occurred during
processing of these events. We further have ﬁles describing virtual
topologies and testbed state snapshots that were given to the alloca-
tion software – assign – and the allocation logs showing which
physical nodes were assigned to each experiment instance. The vir-
tual topology encodes user desires about the nodes they want, their
conﬁguration and connectivity. The testbed state snapshot gives
a list of currently available nodes on the testbed, along with their
switch connectivity, supported operating system images, features
and feature weights (see Section 5 for explanation of these terms).
Such snapshots are created on each attempted start, swapin or
swapmod. The complete list of our data is shown in Table 3.
In our investigation we found that both database and ﬁle system
data can be inconsistent or missing. This can occur for several rea-
sons:
1. Different scripts may handle the same event and may gener-
ate database entries. It is possible for a script to behave in
an unexpected manner or overlook a corner case, leading to
inconsistent information. For example, for a small number
of experiments we found that database entries show consecu-
tive successful swapin events, which is an impossible state
transition. We believe that this occurs because one script
processes the event and records a success before the event
fully completes. In a small number of cases another script
detects a problem near the end of resource allocation and re-
verts the experiment’s state to deﬁned but does not update the
database.
2. State transitions can be invoked manually by testbed opera-
tions staff, without generating recorded testbed events. For
example, we found a small number of experiments in allo-
cated state according to the database, while ﬁle system state
indicated that they returned the resources to the testbed. This
can occur when testbed operations staff manually evicts sev-
eral or all experiments to troubleshoot a testbed problem.
3. Testbed policies and software evolve, which may lead to dif-
ferent recording of an event over time. For example in 2004–
2006, when a user’s request for experiment modiﬁcation had
a syntax error this was recoded in the database. This practice
was abandoned in later Emulab software releases. Similarly,
when a user’s request for experiment modiﬁcation failed due
to temporary lack of testbed resources, this request and test-
bed’s state snapshot were recorded in the ﬁle system on the
boss node. This practice was abandoned in early 2007 mak-
ing it difﬁcult to understand and troubleshoot resource allo-
cation errors.
4. In a small number of cases software generating unique iden-
tiﬁers for ﬁle names storing virtual topology and testbed state
snapshot had low randomness leading to newer ﬁles overwrit-
ing older ones within the same experiment. This means that
ﬁle system state for some instances is missing.
During our analysis, we detect and either correct or discard entries
with inconsistencies. We also attempt to infer missing data wher-
ever possible, by combining the database and the ﬁle system infor-
mation.
Suggestion 1: Testbeds need better software development prac-
tices that start from a system model and verify that developed code
matches the model, e.g., through model checking and unit testing.
While it is impossible to eliminate all bugs in a large codebase, a
systematic tying of code to requirements and models would help
eliminate inconsistencies in record-keeping and even facilitate au-
tomated detection and forensics of testbed problems.
5. TESTBED MAPPING PROBLEM
We now explain some speciﬁcs of testbed operation that relate to
resource allocation, using Figure 3 to illustrate them. Many of the
concepts in this Section were ﬁrst introduced in [20].
TESTBED
A1 A2 B1 B2
s3
C6
C5
C1 C2 C3 C4
1Gb
s2
s1
1Gb
VIRTUAL TOPOLOGY
n1
2
1Gb
1Gb
1
n3
n2
2
1Gb
1Gb
1
1
n4
n5
A1 - A:1, pc:1, delay:2, pcvm:10 - OS-1:0, OS-2:0, ﬁrewallable:2 , fast:1
…
B1 - B:1, pc:1, delay:2, pcvm:20 - OS-1:0, ﬁrewallable:2, hosts-netfpga:5 
…
C1 - C:1 pc:1, delay:2                 - OS-2:0, hosts-netfpga:5 
n1, n2 - pc, OS-1
n3, n4, n5 - B | C
nodetype: limit
feature: weight
pclass1: A1, A2
pclass2: B1, B2
pclass3: C1, C2, C3, C4
pclass4: C5, C6
n1: pclass1, pclass2
n2: pclass2
n3, n4, n5: pclass2, pclass3, pclass4
Figure 3: Illustration of the network testbed mapping problem
Over time network testbeds acquire nodes of different hardware
types leading to heterogeneity. Types can differ in number of net-
work interfaces, processor speed, memory size, disk space, etc. In
Figure 3 the drawing on the left shows a sample testbed architec-
ture. There are three hardware types: A, B and C, with 2, 2 and
6 nodes respectively. Each physical node is connected to a switch.
Because a single switch has a limited number of ports a testbed may
have multiple switches connected by limited-bandwidth links, each
hosting a subset of nodes. In Figure 3 there are three switches –
s1, s2 and s3 – with interswitch links shown as thick lines between
them. Often nodes of the same type are connected to the same
switch. Sometimes it is beneﬁcial to connect different node types
to the same switch (e.g., nodes of type A and B are connected to s1)
or to connect some nodes to two different switches (e.g., nodes C5
498and C6 connect to s1 and s3). DeterLab has instances of all three
node-to-switch connection types in its current architecture.
Users submit their experiment conﬁguration requests to the test-
bed as a virtual topology. One such topology is shown in the right
drawing in Figure 3. A resource allocation algorithm attempts to
solve the testbed mapping problem [20]. It starts from the virtual
topology and a snapshot of the testbed state and attempts to ﬁnd the
best selection of hardware that satisﬁes experimenter-imposed and
testbed-imposed constraints.
Testbed-imposed constraints consist of limitations on available
nodes of any given type, limitations on number of node interfaces,
and limited interswitch link bandwidth. Experimenter-imposed con-
straints are encoded in the virtual topology as desires and consist of:
(1) Node type constraints – a virtual node must be mapped to spe-
ciﬁc hardware type, (2) OS constraints – a virtual node must run
speciﬁc OS, (3) Connectivity constraints – a virtual node should
have speciﬁc number of network interfaces and must be connected
to another node by a link of speciﬁc bandwidth. Node type and OS
constraints are encoded explicitly by annotating nodes in the virtual
topology, and the connectivity constraints are implied in the topol-
ogy’s architecture. For example, in Figure 3, explicit constraints
request nodes n1 and n2 to be of type pc and run OS 1, while nodes
n3, n4 and n5 should be of type B or C. Implicit connectivity con-
straints require that n2 be mapped to a node with at least 3 network
interfaces, n1 to a node with at least 2 interfaces, and the rest to
nodes with at least 1 interface. Each link is required to have 1 Gbit
bandwidth. This limits the number of virtual links that can be al-
located to an interswitch link and in turn invalidates some mapping
of virtual to physical nodes that would oversubscribe interswitch
bandwidth. Emulab software further lets users specify ﬁxed map-
pings: virtual nodes that map to speciﬁc physical nodes (e.g. a
user may request n1 to be mapped to A1). This sometimes helps
assign algorithm to ﬁnd a solution, where it would otherwise
miss it. We elaborate on reasons for ﬁxed mappings in the next
Section.
The notion of the node type [20] extends beyond simple hardware
types in two ways. First, a physical node can “satisfy” multiple
node types and may host multiple instances of the same type. For
example, node A1 (see annotations at the bottom left in Figure 3)
can host one virtual node of type A, one virtual node of type pc,
two virtual nodes of type delay, or ten virtual nodes of type pcvm
(virtual machine installed on a physical node). Second, a user can
specify a vclass – a set of node types instead of the single type for
any virtual node, e.g.
in Figure 3 a user has asked for nodes n3,
n4 and n5 to be either of type B or of type C. vclasses can be hard
– requiring that all nodes be assigned to the same node type from
vclass (e.g., all are B or all are C) – and soft – allowing mixed
type allocations, from the same vclass (e.g., each could be B or
C). In DeterLab’s operation we have only encountered use of soft
vclasses. Corresponding to experimenter’s desires, physical nodes
have features. For example, in Figure 3 there are the following
features: (1) OS 1 runs on types A and B, (2) OS 2 runs on types
A and C, (3) ﬁrewallable feature is supported by types A and B, (4)
hosts-netfpga feature is supported by types B and C. Each feature
is accompanied by a weight that is used during resource allocation
process to score and compare different solutions.
Testbeds create base OS images for all their users, for popular OS
types like Linux, Windows and Free BSD. Over time testbed staff
creates newer versions of base images but the old ones still remain
on the testbed and are used, we believe due to inertia. Testbeds
further allow users to create custom disk images as a way of saving
experimental state between allocations. These images are rarely
upgraded to new OS versions. As testbeds grow, old custom and
base images cannot be supported by new hardware. Thus virtual
topologies with such images can be allocated only to a portion of
the testbed and OS desires turn into mapping constraints.
Suggestion 2: Testbeds need mechanisms that either provide
state saving without disk imaging, or help users to upgrade their
custom images automatically to new OS versions. Experiment spec-
iﬁcations (virtual topologies) should also be upgraded automati-
cally to use newer base OS images. This would eliminate OS-based
constraints and improve allocation success.
An acceptable solution to the testbed mapping problem meets all
experimenter-imposed and testbed-imposed constraints. We note
that honoring an interswitch bandwidth constraint is a choice and
not a must. Testbed software can allocate any number of virtual
links onto the interswitch substrate, but if it oversubscribes this sub-
strate and if experimenters generate full-bandwidth load on the vir-
tual links they may experience lower than expected performance.
In our example in Figure 3 it is possible to allocate links n2-n4
and n2-n5 on the same 1 Gbit interswitch link, but if the experi-
menter sends 1 Gbit of trafﬁc on each of them at the same time half
of the trafﬁc will be dropped. There are two choices when evalu-
ating if interswitch bandwidth constraint is met: (1) evaluation can
be done only within the same experiment assuming no other experi-
ment uses the same interswitch link, and (2) evaluation can be done
taking into account all experiments that use the same interswitch
link.
In practice, solution (1) is chosen because it improves the
resource allocation success rate. Risk of violating experimenter’s
desires is minimal because the incidence of multiple experiments
using the same interswitch link and generating high trafﬁc at the
same time is low.
The best solution to the testbed mapping problem is such that
minimizes interswitch bandwidth consumption and minimizes un-
wanted features on selected physical nodes – these are the features
that are present on the nodes but were not desired by the experi-
menter. Doing so improves the chance of success for future alloca-
tions. In face of these allocation goals the testbed mapping problem
becomes NP-hard, because the number of possible solutions is too
large to be exhaustively searched for the best one.
6. WHY ALLOCATIONS FAIL