service
Controlled  
DNS servers
Training  
Dataset
Feature 
Extraction
Whois
 DNS
Controlled 
clients
RESIP 
service
Controlled 
 web servers
RESIP 
Candidates
Classifier
RESIP
The Inﬁltration Framework
Residential IP Classiﬁer
Fig. 2: Our methodology framework.
Host Fingerprinter
Liveness Checker
Relay Profiler
   Host Proﬁling
leaf inetnum object whose IP range covers that IP, its direct
owner as the organization and person objects associated with
its direct inetnum, and its loose owner as all organizations and
persons who share the same contact information as the direct
owner. In our research, we collected the IP Whois databases
from all 5 RIRs everyday since December 2015 using their
RDAP and bulk access APIs [40] [46][23][24][45][44]. Those
historical IP Whois databases were used to generate features
for our residential IP classiﬁer (§III-B).
III. METHODOLOGY AND DATASET
As shown in Figure 2, the methodology behind our study
on RESIP consists of three important parts: an inﬁltration
framework (§III-A) for gaining insider’s views of RESIP
services, a classiﬁer (§III-B) for identifying residential IPs, and
a host proﬁling system (§III-C) for ﬁngerprinting the proxy
hosts. We elaborate them as follows.
A. Inﬁltration Framework
Our inﬁltration framework includes a client, which is a web
crawler sending labeled requests through a RESIP service to
its target site, a target server, which is a website receiving
the client’s requests forwarded by RESIPs, and our own
authoritative DNS server, which is utilized to ﬁnd out whether
DNS resolving happens on the RESIP hosts or on the gateway,
and further discover these resolvers. This framework is also
illustrated in Figure 2.
We found 17 RESIP services either through search engines
or from Blackhat SEO forums [31]. Among them, 5 (Table I)
were picked out based upon their claimed scale (> 100K
IPs), service models (SOCKS or not, pay by month or trafﬁc,
etc.), popularity (heavily promoted online), and the time they
were discovered (earliest ones). All 5 services support relaying
HTTP/HTTPS trafﬁc and ProxyRack also supports SOCKS4
and SOCKS5 protocols. We then purchased those ﬁve RESIP
services, and ran our crawler to periodically visit our server
with pre-registered domains through these services. Our server
recorded each labeled request and extracted its source IP, which
was considered to be the address of the RESIP provided by the
service. For this purpose, each request produced by our crawler
was labeled to avoid recording the requests from other parties,
since they may not carry RESIP IPs (e.g., Man in the Middle
players record our trafﬁc and replay it ). Also, this approach
forces the RESIP to query our DNS server, exposing its resolver.
In our framework, a client sends requests to specially crafted
subdomains (as part of the HTTP request URL) with the
following pattern: uuid.timestamp.providerId.gwId.raap-xx.site,
where uuid is a dynamically generated UUID, timestamp is the
client’s current Unix timestamp, providerId uniquely identiﬁes
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:44:47 UTC from IEEE Xplore.  Restrictions apply. 
the RESIP service provider, gwId represents the type of the
proxy gateway (S, NS or HS) and raap-xx.site represents a
set of domains registered for our website, with xx describing
various geo-locations (us, eu, etc.). In this way, each request
targets at a unique subdomain. Moreover, such crafted requests,
once being proxied by the RESIP device, became more likely
to be captured by our industry partner’s anomalous trafﬁc
gathering module (data collected by the module elaborated
in §III-D) due to their newly registered domains carrying the
patterns produced by DGA (Domain Generation Algorithms).
Through such collected data, we were able to locate the RESIP
devices and analyze the trafﬁc they proxied (See §IV-C).
Upon receiving a DNS query for such a domain, our DNS
server employed a regular expression to check the pattern of
the subdomain, and if correct, resolved it to the IP addresses of
our controlled servers. In this way, for each successful request,
three log records were generated by the entities under our
control: the client (our crawler), the target server, and the DNS
server as illustrated in Figure 2. Here the client recorded the
labeled request URL, the target server kept the RESIP’s IP,
and also the DNS server logged the RESIP’s DNS resolver.
Correlating those logs provides us a comprehensive view of a
RESIP’s operations, and can also help discover related trafﬁc
traces from other sources when they were captured by network
monitors (see §IV). As shown in Table I, all RESIP services
except Luminati resolve domain names on RESIPs rather than
gateways while Luminati can do this on either site through
conﬁguration. We came to this conclusion since our DNS server
received queries issued by over 82K DNS resolvers from these
RESIP services in our study.
During our study, we carefully designed our methodology
to ensure that our inﬁltration and proﬁling are less detectable
by the RESIP services. For this purpose, we deployed multiple
crawlers and target servers on Amazon EC2 instances and
Aliyun instances located in European, US, South America,
Singapore and China, to generate trafﬁc from diverse sources.
Further, we used AES-CBC with a 128-bit key to encrypt
all trafﬁc between our crawlers and the targets, to prevent
potential content inspection. Another implementation issue is
the presence of multiple gateways and the different models
they are running (S, HS and NS; see §II and Table I). For
example, GeoSurf and ProxyRack all run sticky gateways; as
a result, our server would not see any new proxy host during
a given period of time (1 to 10 minutes); therefore our crawler
was implemented to only request once for a while, depending
on the sticky time given by the service. For the providers
with non-sticky and half-sticky gateways, our implementation
took different strategies to generate requests. When there were
multiple gateways, we chose a different one for each request
in order to reduce redundant requests and cover more RESIPs.
Besides, in case RESIP services assigned different gateways
to different users, we registered for each service at least two
distinct user accounts and found that each account was always
linked to the same set of gateways.
Result and evaluation. In total, we ran up to 20 daily crawling
jobs, each producing about 50,000 requests, from Jun. 06
Date(s)
Geosurf
Provider
Proxies Online
Price
$25/Gb
Payment
07/06-11/24
Paypal
09/17-10/22
$300/month Paypal
$40/month Bitcoin 09/18-11/24
$500/month Paypal
09/25-11/01
IAPS Security $500/month Bitcoin 09/23-11/01
ProxyRack
Luminati
Gateway DNS
HS
S/HS
S/NS
HS
HS
R
R
R
R/G
R
TABLE I: RESIP services purchasing details. HS: half-sticky; S:
sticky; NS: non-stick; R: RESIP; G: gateway.
Label
resi-clean
resi-clean
resi-noisy
resi-noisy
resi-noisy
Source
Manual
Device Search Engine
Trace My IP
Filtered IP Whois
IoT Botnets
Public Clouds
Alexa Top1M
Commercial Proxies
Public Proxies
# IPs
79
# /16 # /8 Training
25
79
394
89,345
37,480
19
13,525 195
11,402 213
23,264,961
31
1,699,291 20,112 200
99
14,365 213
44
14,004 204
442,989
968
71
9,921
0
0
0
5,000
4,481
519
0
non-resi-clean 53,716,321
non-resi-clean
non-resi-clean
non-resi-noisy
148,509
519
TABLE II: Datasets for training and testing the residential IP classiﬁer.
to Nov. 24 2017. Our study captured 6,183,876 different
RESIP IPs by issuing 62 million requests. Before Sep. 15,
we only ran 2 crawling jobs on a single service, Proxies
Online. Then starting from Sep. 17, we gradually purchased
at least one-month service from all 5 RESIP providers and
ran up to 20 crawling jobs daily using 200+ threads to collect
RESIP information from all of them. After one month, we
have gathered enough RESIPs from Luminati. Meanwhile, our
measurement results revealed that IAPS Security was just a
reseller of Luminati’s service, and Geosurf and Proxies Online
actually share the same infrastructure. Given the above ﬁndings,
we then stopped crawling the expensive providers, including
IAPS Security, Geosurf, and Luminati, but still kept the jobs
on Proxies Online and ProxyRack until Nov. 24. Overall, we
spent $2800 in purchasing and inﬁltrating those services.
B. Residential IP Classiﬁer
While RESIP service providers claim to utilize residential
hosts for relaying their customers’ trafﬁc, little is known about
whether the proxies they use are indeed located in residential
networks. Determining whether an IP is residential can be
complicated, particularly when the same ISP can also allocate
IP blocks to data centers. Although some commercial service
(e.g., Maxmind GeoIP2 Precision Insights Service [33]) allows
queries on IP’s labels such as residential or cellular for a fee
(e.g., $50 for 25K IPs), it cannot scale to a large number
of queries (6.2M in our research) and its methodologies are
not open (so less known about their reliability). So in our
research, we built a new classiﬁer on top of a set of features
that characterize residential IPs. Following we elaborate the
technique, particularly, our approaches to collect clean ground
truth, select robust features, and train and evaluate the classiﬁer.
Finding groundtruth. Finding clean labeled residential IPs
is challenging due to the absence of public data and the
dynamic IP allocation performed by ISPs. To address this
issue, we came up with a series of robust methodologies to
obtain 4 labeled datasets: residential-clean (resi-clean), non-
residential-clean (non-resi-clean), residential-noisy (resi-noisy),
and non-residential-noisy (non-resi-noisy). Such groundtruth is
summarized in Table II.
(cid:18)(cid:18)(cid:25)(cid:25)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:44:47 UTC from IEEE Xplore.  Restrictions apply. 
The resi-clean set contained 79 IPs of the personal devices
under our control, which were connected to 11 ISPs in 3
countries for identifying these addresses. To ﬁnd other “clean”
IPs, we came up with an idea that leverages device search
engines (e.g., Shodan [48], Zoomeye [52] etc.) to search
for the network devices typically only utilized in residential
environments. Examples include smart home systems such as
Amazon Echo [27], Google Home [35], Philips Hue Lights [41],
home-related gateways like residential ADSL gateway and
broadband residential gateway, and others. A complete list
of keywords used in such device queries is presented in
Appendix IX-A. These queries return IPs for both devices
discovered online and related applications. The former was
added to our resi-clean dataset as groundtruth. In this way, we
successfully harvested 89,345 residential IPs distributed across
13,525 /16 and 195 /8 network blocks. This data collection
was done automatically, which we believe itself is a technical
contribution.
We further applied several weaker heuristics to build the resi-
noisy dataset. Despite being noisy, the dataset is still useful in
validating our classiﬁer. Speciﬁcally, its data comes from three
sources. (1) We used the query logs of Trace My IP [51], an IP
tracing service helping visitors to ﬁnd their devices’ IPs. The
IPs recorded by the logs were selected as potential residential
IPs when the ISPs involved are known to be residential Internet
service providers (e.g., AT&T and Comcast), queries are from
the OSes for consumer devices (e.g., Android and IOS) and
common browsers, and the IPs are not labeled as bot or spider.
(2) We looked up the owner objects for the 79 clean residential
IPs in the IP Whois dataset (see § II), and considered other IPs
under those owner objects as residential IPs. This is because as
a common practice, ISPs (such as AT&T) typically register the
same set of owner objects to manage the IP blocks serving the
same purposes. For example, AT&T registers the owner object
ATTMO-3 [28] for AT&T Mobility LLC [29] to manage all
IPs for mobile usage. (3) We also included the IPs detected
from two emerging botnet campaigns Hajime [12] and IoT
Reaper [13] that utilize compromised IoT devices (see §III-D),
as home IoT devices are much more likely to be compromised
than enterprise IoT devices. In total, the resi-noisy dataset
contained 25,001,529 IPs.
The non-resi-clean data were collected from cloud providers,
high-proﬁle websites (Alexa top 1M websites), and commercial
proxies (details in Appendix IX-A). We gathered 54,031,298
such IPs distributed across 14,610 /16 and 213 /8 network
blocks. The non-resi-noisy dataset
involved the IPs from
publicly available proxies (e.g., Tor relays and public free
proxies) as detailed in § III-D. The data is noisy since some
such proxy services like Tor also recruit home servers to relay
trafﬁc [50]. This dataset included 148,509 IPs in 14,004 /16
and 204 /8 networks.
Feature selection and extraction. We selected a set of
unique features to train a classiﬁer to identify residential IPs.
Unlike non-residential IPs, residential IPs are typically directly
assigned and managed by an ISP (instead of being re-assigned
to a business) [66]. Also, ISPs tend to reserve stable IP blocks
(belonging to the same inetnum) for home users, while the
network blocks given to the business could be more volatile,
changing hands over multiple owners during a given period
of time [66]. Furthermore, non-residential IPs are more likely
to host web services. For example, among 442,989 IPs for
the Alexa Top 1M domains, 29% (128,531) are found in our
Public Cloud dataset while only 0.01% (36) are also in our
resi-clean dataset. Based upon such observations, we leveraged
a total 35 features related to IP Whois records or Active DNS
records to capture residential IPs’ characteristics. Due to the
space limit, we here just elaborate some of them and the rest
is presented in Appendix IX-A.
• An Active DNS feature. As an example, the connection
between non-residential IPs and web services can be captured
by the average number of TLD+3 domains per IP in the direct
inetnum (§II). Intuitively, this feature describes the number of