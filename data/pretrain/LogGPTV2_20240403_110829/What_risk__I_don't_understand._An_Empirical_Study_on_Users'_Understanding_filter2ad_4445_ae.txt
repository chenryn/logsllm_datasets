other methods). From their comments, we find that people with IT
background read the security articles more carefully and spent more
time reading the explanations in the provided pop-ups compared
to people without IT background.
The significance test shows that only the accuracy achieved
with our tool between people with different IT backgrounds shows
a statistically large difference (p < 0.001). It indicates that users
with IT background face as much difficulty as normal users do in
comprehending security issues. Still, people with IT background un-
derstand technical articles significantly better than people without
IT background when both of them use our tool.
Based on Experiment 2, we conclude that:
• Our tool can help users understand security texts better, with
• Users have difficulty in understanding ambiguous terms;
• Users with IT background show significantly better performance
in understanding security texts only when they use our tool.
30% improvement;
5 DISCUSSION
5.1 Implications
For Researchers. Our user studies were based on the texts ex-
tracted from security blogs. Blogs report the latest security trends
and advancements, including news, hacks, discoveries, vulnerabili-
ties and their solutions. If users sufficiently comprehend security
articles, they are more likely to take reasonable actions to minimise
risks when they face a threat. Future research may also explore
other online and user-friendly public resources such as videos to
raise users’ security awareness and understanding. Our findings
can also inspire researchers to complement this line of work from
alternative viewpoints, for example, difficulty level measures for
technical terms, automatic self-explanations for security articles, or
replacing technical terms with commonly used explanatory phrases.
For IT Practitioners. Our findings suggest users with IT back-
ground do not have much more cybersecurity knowledge than users
without IT background. This is consistent with other research which
showed that they are likely to share confidential forms or down-
load unreliable software without consulting security specialists
[24]. Intermedia’s Insider Risk Report [28] revealed that tech-savvy
workers are more likely to create security risks. IBM’s 2016 Cyber
Security Intelligence Index also found that of all cyber-attacks re-
ported, 60% of them were caused by insiders, among which 25%
were the result of employee negligence [47]. It also reported that IT
workers usually overestimate their ability to defend against attacks.
Security awareness programs for IT employees are also consid-
ered as highly important. Our tool can assist in enhancing users’
awareness and understanding.
For Educators. Our survey results revealed that users have only
limited security knowledge to protect themselves from attacks. Ed-
ucating users can help them perform better in risk perception and
understanding. Blogs are widely accessible and provide end users
with timely information. Our tool was designed with educational
purposes in mind, to help users increase their security knowledge.
With friendly integration to browsers, a convenient reading assis-
tant promotes users’ interest in security news and articles. Addi-
tionally, security descriptions are usually too technical and difficult
for home users such as security advice and privacy policy statement.
Our findings suggest that, without appropriate explanation, users
tend to skip the keywords, which might be the crucial hints. With
aid tools, such as our pop-up dictionary, users can quickly get the
point of security advice and follow its instructions.
5.2 Limitations
User study. Our SC Corpus was generated by human annotations
from 200 representative articles with an average length of 1,000
words each. Due to our limited budget, we only recruited 597 crowd-
workers to annotate the terms. Future work can employ more arti-
cles and annotators to build a larger corpus. The sample set in our
study might not have the same population diversity as found in
more massive sample sets. But our analysis revealed the significant
difference between randomly divided groups. This study is instruc-
tive for future work to involve a larger number of participants.
Tool Development. The tool we developed is simple but proven
to be effective. However, there is still room for improvement. Firstly,
our pop-up windows were limited in size. A few terms have rela-
tively long descriptions, and they were cut at the end. Future work
can extract the most informative words or sentences to shorten
the descriptions. Secondly, our tool might not do well for newly
created terms since it was designed based on the SC corpus from
the user study. As we used more than 40 thousand technical articles
from 2014 to the present, our tool can still be used in the major-
ity of current security articles. Future work can detect new terms
based on similarity to our knowledge base. The last limitation is in
the evaluation. With using our tool, the terms highlighted in the
articles could serve bias users, as it draws more attention to these
terms compared to the rest text. As there is no real incentive for the
participants to answer correctly, the results might not reflect their
best efforts. Future research should consider real-world practice.
6 CONCLUSION
In this paper, we studied users’ understanding of security and how
well they comprehend the security related articles. We found that
most participants had difficulty understanding the technical terms
of the articles related to security. Based on a crowdsourcing task, we
generated a security-centric corpus with more than five thousand
terms. We also developed a tool to help users understand security
articles by displaying meanings for technical terms in pop-ups.
An experiment demonstrated the pop-up explanations greatly im-
proved users’ security understanding. Our analysis also revealed
users with IT background did not understand security articles better
or faster than people without IT background. Users’ misconceptions
of cybersecurity issues may hinder security controls application or
lead to misuse of security measures.
Inspired by our findings, we proposed several future research
directions. A larger number of crowdworkers can be employed to
annotate more security articles to generate a broader and richer
security-centric corpus. Future research should attempt to create
refined meanings for the terms. Since end users have different levels
of education, one solution is to provide them with personalised
explanations. Instead of plain texts, visual aids such as infographics
can also be studied to explain security knowledge in a user-friendly
way.
REFERENCES
[1] Yasemin Acar, Sascha Fahl, and Michelle L Mazurek. 2016. You are not your
developer, either: A research agenda for usable security and privacy research
beyond end users. In SecDev’16. IEEE, 3–8.
[2] Alessandro Acquisti, Idris Adjerid, Rebecca Balebako, Laura Brandimarte, Lor-
rie Faith Cranor, Saranga Komanduri, Pedro Giovanni Leon, Norman Sadeh,
Florian Schaub, Manya Sleeper, et al. 2017. Nudges for privacy and security:
understanding and assisting users’ choices online. Comput. Surveys 50, 3 (2017),
44.
[3] Bonnie Brinton Anderson, C Brock Kirwan, Jeffrey L Jenkins, David Eargle,
Seth Howard, and Anthony Vance. 2015. How polymorphic warnings reduce
habituation in the brain: Insights from an fMRI study. In CHI’15. ACM, 2883–2892.
[4] Apple. cited Nov 2019. Mac Dictionary. https://support.apple.com/en-au/guide/
dictionary/dictionary-user-guide-dic34880/mac.
[5] Nalin Asanka Gamagedara Arachchilage and Steve Love. 2013. A game design
framework for avoiding phishing attacks. Computers in Human Behavior 29, 3
(2013), 706–714.
[6] Nalin Asanka Gamagedara Arachchilage, Steve Love, and Konstantin Beznosov.
2016. Phishing threat avoidance behaviour: An empirical investigation. Computers
in Human Behavior 60 (2016), 185–197.
[7] Maria Bada, Angela M Sasse, and Jason RC Nurse. 2019. Cyber security awareness
campaigns: Why do they fail to change behaviour? arXiv preprint arXiv:1901.02672
(2019).
[8] Lingfeng Bao, Zhenchang Xing, Xin Xia, and David Lo. 2018. VT-Revolution:
Interactive Programming Video Tutorial Authoring and Watching System. IEEE
Transactions on Software Engineering (2018).
[9] David M Blei, Andrew Y Ng, and Michael I Jordan. 2003. Latent dirichlet allocation.
Journal of machine Learning research 3, Jan (2003), 993–1022.
[10] Pew Research Center. cited Nov 2019. What Internet Users Know about Technol-
ogy and the Web. https://www.pewinternet.org/2014/11/25/web-iq/.
[11] Netwrix Corporation. cited Nov 2019. 2017 IT Risks Report. https://www.netwrix.
com/2017itrisksreport.html.
[12] Damien Cram and Béatrice Daille. 2016. Terminology extraction with term
variant detection. In Proceedings of ACL-2016 System Demonstrations. 13–18.
[13] Lorrie F Cranor. 2008. A framework for reasoning about the human in the loop.
(2008).
statistics. OpenIntro.
[14] David M Diez, Christopher D Barr, and Mine Cetinkaya-Rundel. 2012. OpenIntro
[15] W Keith Edwards, Erika Shehan Poole, and Jennifer Stoll. 2008. Security automa-
tion considered harmful?. In Proceedings of the 2007 Workshop on New Security
Paradigms. ACM, 33–42.
[16] Lisa Maszkiewicz Rock Stevens Everest Liu Dhruv Kuchhal Elissa M. Redmiles,
Miraida Morales and Michelle L. Mazurek. 2015. First Steps Toward Measuring
the Readability of Security Advice. In Workshop on Technology and Consumer
Protection.
[17] Michael Fagan and Mohammad Maifi Hasan Khan. 2016. Why do they do what
they do?: A study of what motivates users to (not) follow computer security
advice. In SOUPS’16. 59–75.
[18] Adrienne Porter Felt, Alex Ainslie, Robert W Reeder, Sunny Consolvo, Somas
Thyagaraja, Alan Bettes, Helen Harris, and Jeff Grimes. 2015. Improving SSL
warnings: Comprehension and adherence. In CHI’15. ACM, 2893–2902.
[19] Darja Fišer, Vit Suchomel, and Miloš Jakubícek. 2016. Terminology Extraction
for Academic Slovene Using Sketch Engine. RASLAN 2016 Recent Advances in
Slavonic Natural Language Processing (2016), 135.
[20] Dinei Florêncio, Cormac Herley, and Paul C Van Oorschot. 2014. An administra-
tor’s guide to internet password research. In LISA’14. 44–61.
[21] Alain Forget, Sarah Pearman, Jeremy Thomas, Alessandro Acquisti, Nicolas
Christin, Lorrie Faith Cranor, Serge Egelman, Marian Harbach, and Rahul Telang.
2016. Do or do not, there is no try: user engagement may not improve security
outcomes. In SOUPS’16. 97–111.
[22] Google. cited Nov 2019. Google Dictionary. https://chrome.google.com/webstore/
detail/google-dictionary-by-goog/mgijmajocgfcbeboacabfgobmjgjcoja?hl=en.
[23] Brij Gupta, Dharma P Agrawal, and Shingo Yamaguchi. 2016. Handbook of
research on modern cryptographic solutions for computer and cyber security. IGI
Global.
[24] David R Hannah and Kirsten Robertson. 2015. Why and how do employees break
and bend confidential information protection rules? Journal of Management
Studies 52, 3 (2015), 381–413.
[25] Marian Harbach, Markus Hettig, Susanne Weber, and Matthew Smith. 2014.
Using personal examples to improve risk communication for security & privacy
decisions. In CHI’14. ACM, 2647–2656.
[26] Anna Hätty, Simon Tannert, and Ulrich Heid. 2017. Creating a gold standard
corpus for terminological annotation from online forum data. In LOTKS’17.
[27] Adele E Howe, Indrajit Ray, Mark Roberts, Malgorzata Urbanska, and Zinta
Byrne. 2012. The psychology of security for the home computer user. In 2012
IEEE Symposium on Security and Privacy. IEEE, 209–223.
[28] Intermedia. cited Nov 2019. Intermedia’s 2015 Insider Risk Report. https://www.
intermedia.net/report/riskiestusers.
[29] Iulia Ion, Rob Reeder, and Sunny Consolvo. 2015. "... No one Can Hack My Mind":
Comparing Expert and Non-Expert Security Practices.. In SOUPS’15, Vol. 15.
1–20.
[30] Iacovos Kirlappos and M Angela Sasse. 2011. Security education against phishing:
IEEE Security & Privacy 10, 2 (2011),
A modest proposal for a major rethink.
24–32.
[31] Katharina Krombholz, Wilfried Mayer, Martin Schmiedecker, and Edgar Weippl.
2017. " I Have No Idea What I’m Doing"-On the Usability of Deploying {HTTPS}.
In USENIX Security’17. 1339–1356.
[32] Xiaojing Liao, Kan Yuan, XiaoFeng Wang, Zhou Li, Luyi Xing, and Raheem
Beyah. 2016. Acing the IOC game: Toward automatic discovery and analysis of
open-source cyber threat intelligence. In CCS’16. ACM, 755–766.
[33] Christopher Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven Bethard,
and David McClosky. 2014. The Stanford CoreNLP natural language processing
toolkit. In Proceedings of 52nd annual meeting of the association for computational
linguistics: system demonstrations. 55–60.
[34] Stephen Mayhew and Dan Roth. 2018. Talen: Tool for annotation of low-resource
entities. In Proceedings of ACL 2018, System Demonstrations. 80–86.
[35] Susan E McGregor, Polina Charters, Tobin Holliday, and Franziska Roesner. 2015.
Investigating the computer security practices and needs of journalists. In USENIX
Security’15. 399–414.
[36] Nikki McNeil, Robert A Bridges, Michael D Iannacone, Bogdan Czejdo, Nicolas
Perez, and John R Goodall. 2013. Pace: Pattern accurate computationally efficient
bootstrapping for timely discovery of cyber-security concepts. In ICMLA’13,
Vol. 2. IEEE, 60–65.
[37] Medium. cited Nov 2019. Read Time and You. https://blog.medium.com/read-
time-and-you-bc2048ab620c.
[38] Alena Naiakshina, Anastasia Danilova, Christian Tiefenau, Marco Herzog, Sergej
Dechand, and Matthew Smith. 2017. Why do developers get password storage
wrong?: A qualitative usability study. In CCS’17. ACM, 311–328.
[39] Anand Narasimhamurthy. 2005. Theoretical bounds of majority voting perfor-
mance for a binary classification problem. IEEE Transactions on Pattern Analysis
and Machine Intelligence 27, 12 (2005), 1988–1995.
[40] Eyal Peer, Joachim Vosgerau, and Alessandro Acquisti. 2014. Reputation as a
sufficient condition for data quality on Amazon Mechanical Turk. Behavior
research methods 46, 4 (2014), 1023–1031.
[41] Carol Peters. 2005. Multilingual Information Access for Text, Speech and Images:
5th Workshop of the Cross-Language Evaluation Forum, CLEF 2004, Bath, UK,
September 15-17, 2004, Revised Selected Papers. Vol. 3491. Springer Science &
Business Media.
[42] Emilee Rader and Rick Wash. 2015. Identifying patterns in informal sources of
security information. Journal of Cybersecurity 1, 1 (2015), 121–144.
[43] Paul Rayson and Roger Garside. 2000. Comparing corpora using frequency pro-
filing. In Proceedings of the workshop on Comparing corpora-Volume 9. Association
for Computational Linguistics, 1–6.
[44] Elissa M Redmiles, Sean Kross, and Michelle L Mazurek. 2016. How i learned to
be secure: a census-representative survey of security advice sources and behavior.
In CCS’16. ACM, 666–677.
[45] Elissa M Redmiles, Amelia R Malone, and Michelle L Mazurek. 2016. I think
they’re trying to tell me something: Advice sources and selection for digital
security. In Proceedings of S&P’16. IEEE, 272–288.
[46] Radim Řehůřek and Petr Sojka. 2010. Software Framework for Topic Modelling
with Large Corpora. In Proceedings of the LREC 2010 Workshop on New Challenges
for NLP Frameworks. ELRA, Valletta, Malta, 45–50. http://is.muni.cz/publication/
884893/en.
[47] IBM X-Force® Research. cited Nov 2019. Reviewing a year of serious data
breaches, major attacks and new vulnerabilities. https://www.triscal.com.br/wp-
content/uploads/2018/08/file_seguranca-ibm-xforce-cyber_index-2016.pdf.
[48] Leonard Richardson. cited Nov 2019. Beautiful Soup. https://www.crummy.com/
software/BeautifulSoup.
[49] Michael Röder, Andreas Both, and Alexander Hinneburg. 2015. Exploring the
space of topic coherence measures. In WSDM’15. ACM, 399–408.
[50] Dale C Rowe, Barry M Lunt, and Joseph J Ekstrom. 2011. The role of cyber-
security in information technology education. In SIGITE’11. ACM, 113–122.
[51] Scott Ruoti, Tyler Monson, Justin Wu, Daniel Zappala, and Kent Seamons. 2017.
Weighing context and trade-offs: How suburban adults selected their online
security posture. In SOUPS’17. 211–228.
[52] Dominik Sacha, Hansi Senaratne, Bum Chul Kwon, Geoffrey Ellis, and Daniel A
Keim. 2016. The role of uncertainty, awareness, and trust in visual analytics.
IEEE transactions on visualization and computer graphics 22, 1 (2016), 240–249.
[53] Yukiko Sawaya, Mahmood Sharif, Nicolas Christin, Ayumu Kubota, Akihiro
Nakarai, and Akira Yamada. 2017. Self-confidence trumps knowledge: A cross-
cultural study of security behavior. In CHI’17. ACM, 2202–2214.