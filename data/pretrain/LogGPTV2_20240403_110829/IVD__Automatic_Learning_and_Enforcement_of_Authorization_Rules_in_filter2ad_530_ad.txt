Algorithm 4: Pseudocode algorithm describing IVD’s
HiveQL invariant ratiﬁcation data pipeline.
conveniently supports the visitor pattern, making it easy to add
new code to examine each database request.
The logged information for a request includes the invariant
category, a mapping from values to sets of properties (local
or global) that had those values, and the invariants that were
checked when performing this request. The checked invariants
are later used to determine how many times an invariant has
been evaluated and decide whether it is ready to be ratiﬁed.
For efﬁciency purposes, we do not attempt to infer potential
new invariants at this point but instead defer the task to the
invariant inference engine.
While the invariant category and the local properties are
directly available in the request, the request sampler may have
to query the graph database to retrieve global properties. How-
ever, because the actual logging is performed after responding
to the web request, the request sampler does not introduce any
user-noticeable delay.
The invariant checker’s main implementation decision re-
gards the storage of its invariants. Since the invariants are
checked at every database write, with any delays being per-
ceived as slower database replies, efﬁciency is critical. Our
implementation keeps a copy of the invariants in each web
server’s memory. When this is not feasible or economical, a
distributed in-memory store such as Memcached can be used
as an alternative.
B. Invariant Inference Engine
The invariant inference engine is built on top of Face-
book’s data warehousing and analytics infrastructure [15],
which mainly consists of three open-source systems: Scribe,
responsible for collecting and aggregating the request sampler
and invariant violation logs, Apache Hadoop [16], responsible
for storing them, and Apache Hive [17], responsible for
querying the data. The inference engine’s embodiment is a
set of HiveQL queries and Python scripts that deﬁne data
pipelines for transforming (a) the raw logs into invariants, and
(b) invariants under evaluation into ratiﬁed invariants.
The main challenge in designing the invariant inference
engine was to formulate its algorithms in a fashion suited
to HiveQL’s data manipulation statements. The pseudocode
for the algorithm is shown in Algorithm 3. The code ﬁrst
splits the log data by invariant category (line 1) and for
each category, concurrently, computes the equality invariants
by ﬁnding the sets of local and global properties that were
always equal. For this, it ﬁrst checks that sufﬁcient requests
are available to conﬁdently create invariants (line 2). If the
condition is met, it iterates through all requests, and for each
of them iterates through its set of equal properties (lines 5–7).
rq.equal properties is itself a set of sets; each of its elements
contains two or more properties that had the same value
when the database operation occurred. Since some of these
elements may form an invariant while others may only appear
incidentally, all possible pairs of elements are computed and
added to the all eq pairs list (line 6). Finally, the pairs which
appeared in every request are output (line 10).
Invariants that use the association existence predicate are
more challenging to infer. The logged information from the
request sampler does not contain all the graph associations
that exist between identiﬁers from the logged data because ob-
taining this information in real time can introduce substantial
overhead in database requests. Therefore, the inference engine
ﬁrst obtains the relationships between the user logged-in at the
time of the database request and the objects involved in the
request by querying the graph database post-hoc. Association
invariants are then created when an association of the same
type exists for all log entries corresponding to an invariant
category. While this ofﬂine analysis is not precise due to
changes that may have happened to the graph since the logs
were collected, it can only lead to missed invariants, and
not false positives, thanks to the evaluation period that the
invariants go through.
1101
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:23:44 UTC from IEEE Xplore.  Restrictions apply. 
The invariant ratiﬁcation data pipeline takes all invariants
that were sufﬁciently evaluated—both in terms of number of
days and number and requests—without ever being violated
and marks them as ready to be enforced. Algorithm 4 describes
the invariant ratiﬁcation process. All invariant categories are
processed concurrently; for each category and each request
associated with it (line 1),
the algorithm adds the invari-
ants that were checked to the map checked, along with the
date on which the request occurred (lines 4–6), to be later
used by the ratiﬁcation check (lines 8–11). Invariants that
caused violations in any request for the current
invariant
category are ignored (line 5). Having all the invariants that
always held and the the number of times they were evalu-
ated, MeetsRatiﬁcationThreshold decides whether the invariant
should be ratiﬁed (lines 9–11). The ratiﬁcation requires a
minimum of 500 requests evaluated every day for at least ﬁve
of the past seven days. In addition, we require a minimum
number of distinct values to be taken by the properties involved
in the invariant, as we describe in more detail in §IV-D.
The inference engine is designed to be autonomous and
resilient to workload changes and transient failures. The execu-
tion of the data pipelines is managed by an internal framework
which takes a job’s speciﬁcation and automatically provides
scheduling, monitoring, alerting, and simple reliability features
such as automatic retries. Hive allows scaling the amount
of data that we process through its MapReduce model by
allocating more mappers or reducers, as needed, based on
the amount of data collected. Finally, the pipelines are de-
signed such that each execution is independent of previous
executions, mitigating potential cascading failures. By virtue
of this design, the code automatically picks up new invariant
categories and infers new invariants when new features are
added to Facebook, and purges invariants if the features they
were associated with are no longer used.
In addition to the daily invariant computations, we perform
hourly sampling rate adjustments. To determine the sampling
rate, we estimate the number of requests that will be made for
each invariant category by looking at the category’s history.
First, the request logger writes to each log entry the current
sampling rate for its invariant category. We then approximate
for each invariant category the total number of requests that
happened during period T as
(cid:3)
N ≈
1/RL
L logged during T
where RL is the sampling rate attached to log entry L. There
are different options for choosing the period on which to
base the estimation: the previous hour, the same time on the
previous day or the same time the previous week. To be able
to adjust quickly to new trafﬁc, and because our workload is
seldom bursty, we use the previous three hours, which in our
experience results in daily counts close to our targeted number
of samples.
C. Data Distribution
IVD needs to transfer large amounts of data between its
central inference engine and the distributed components: logs
from the request sampler and invariant enforcer, invariants
to the invariant enforcer, and sampling rates to the request
sampler. We use separate mechanisms for each of them.
For transferring logs we leverage Scribe [15], Facebook’s
dedicated logging infrastructure. Scribe offers an API to de-
scribe the data types to be logged, and automatically creates
the needed boilerplate code and initializes the Hadoop data
store. We refer the interested reader to the original paper for
further details.
Distributing the invariants is done by leveraging Facebook’s
quasi-continuous deployment model. Our implementation pig-
gybacks on the infrastructure that sends application updates to
the web servers. Besides code, the updates also include new
web server cache data to be loaded on server restart, which
is where we bundle our invariants. The frequency of updates
is higher than the daily invariant computation, making this
distribution model effective for our use case.
Coupling application updates with invariant updates has the
added beneﬁt of leveraging the canarying process used for
testing web application code to also test the code’s interaction
with newly-ratiﬁed invariants. This protects against deploying
invariants that would signiﬁcantly affect Facebook’s operation,
either because of bugs in IVD or due to adverse interaction that
were not triggered during previous testing.
Even if incorrect
invariants are deployed,
they can be
rapidly blacklisted. Conﬁgerator [18], a system built on top of
Zookeeper [19], offers propagation delays of seconds, which
allow prompt reaction in the event an incorrect
invariant
is detected in production systems. Conversely, this system
also allows manually adding new invariants to be enforced,
which can be an effective ﬁrst-line mitigation for bugs found
through other means, since writing and deploying an invariant
is signiﬁcantly faster than writing and deploying new code. In
addition, we use Conﬁgerator to distribute sampling rates.
D. Optimizations and Heuristics
Post-send processing. In order to minimize perceived
database response times, we keep a large part of IVD’s code
off the critical path. We do this by leveraging web server
functionality that allows registered callbacks to be executed
asynchronously after the HTTP response has been sent to
the user. All request sampler code executes in a post-send
processing context.
Enforcement excuses. We improve IVD’s precision by man-
ually specifying domain-speciﬁc rules that excuse violations,
i.e. allow requests to proceed even though they have violated
an invariant. As the excuses are checked just before a request
is about to be blocked, they have access to more information
than was available when the invariant was created, in particular
to the values that do not satisfy the invariant and much
of the application state. In addition, the excuses are rarely
executed since violations of ratiﬁed invariants are relatively
rare, affording them more thoroughness. IVD currently uses 17
1102
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:23:44 UTC from IEEE Xplore.  Restrictions apply. 
enforcement excuses that
target common classes of false
in §V-C. Due to
positives, as we discuss in more detail
their domain-speciﬁc nature, the enforcement excuses may
vary between OSNs, depending on the complexity of their
underlying data model. We believe Facebook has a relatively
complex model and other implementations will require fewer
enforcement excuses.
Distinct value count. The ratiﬁcation conditions (§IV-B)
include a minimum threshold for the number of distinct values
that the properties involved in the invariant have taken. This
avoids ratifying incidental invariants that represent version
numbers, image resolutions, timestamps, or that are currently
unused, e.g. ﬁelds always set to “0” or the empty string.
We empirically picked 1440 for the number of daily unique
values required to ratify an invariant, i.e. one per minute.
Since the values that we are interested in are authorization-
related—often user identiﬁers—the minimum threshold of dis-
tinct values has the side effect of limiting invariant generation
to features involving more than 1440 users every day. This
number can be easily customized based on the size of the
OSN and more weight can be given to user identiﬁers used
during internal testing.
V. EVALUATION
INVARIANT DETECTOR’s initial incarnation was deployed
at Facebook more than two years ago and has since detected
several critical vulnerabilities that have since been ﬁxed. In
this section we give an intuition on the amount of work IVD
does, show details on the invariants that it infers and ratiﬁes,
describe our experience with running IVD at Facebook’s scale,
and evaluate its effectiveness and performance.
A. IVD Deployment at Facebook
We begin with an overall picture of Facebook’s IVD setup to
give the reader a better sense of scale. IVD checks more than
10,000,000 peak database write requests per second and uses a
sample of roughly 500 million requests for the daily invariant
inference engine execution. At the time of our evaluation, the
inference engine produced 226,598 invariants that that were
put into evaluation mode, out of which 158,205 were ratiﬁed
at the end of the evaluation period.
In the following we look in more detail at the invariants
to understand (1) which predicates are most often inferred,
(2) which invariants fail evaluation and (3) which invariants
are eventually enforced. To present representative examples,
we rank the invariant predicates according to the number
of invariant categories they are associated with. Intuitively,
a predicate associated with more invariant categories applies
more broadly to changes that are made to the social graph.
Table I shows the top 10 predicates put into evaluation, the
number of invariant categories for which they have been put
into evaluation, and the number of categories for which they
were ratiﬁed. For example, the ﬁrst line can be read as: there
are 40,150 invariant categories, i.e. (ENDPOINT, OPERATION,
ATYPE, O1TYPE, O2TYPE) tuples, for which the predicate
“the association’s ﬁrst object was the logged-in user” held
Invariant Predicate
logged-in user = o1
logged-in user = o1.creator id
logged-in user = o2
logged-in user = o.owner id
logged-in user = o2.creator id
o1 = o2
logged-in user = o2.owner id
logged-in user = o1.owner id
o1 = o2.owner id
the logged-in user is an
administrator of Page o1
... 2192 more
Total
#Evaluated
Invariants
40,150
9,018
8,257
6,250
6,146
6,046
5,834
4,716
4,210
3,951
#Enforced
Invariants
27,144
6,738
5,781
5,621
4,691
4,695
4,106
3,404
3,112
2,590
226,598
158,205
TABLE I: Top 10 predicates by number of invariant categories
they are associated with. The numbers include both objects and
associations writes.
in all sampled requests whenever ENDPOINT performed OP-
ERATION on an association of type ATYPE between objects of
types O1TYPE and O2TYPE. Furthermore, the predicate passed
evaluation for 27,144 of the 40,150 invariant categories. As it
can be seen, all the top predicates reference common privacy-
related property names, which match against the logged-in
user (USER) or one of the objects involved in the request,
i.e. O1 or O2. These properties are common to many object
types, resulting in them being referenced in many invariant
categories. By contrast, predicates which appear in fewer
categories reference more speciﬁc properties, e.g. o1.user
= o2.job_data.owner_id.
The invariants which did not pass evaluation can be put
into two classes. First, there are invariants which did not hold
when tested against 100% of production requests. This reason
accounts for 30,098 invariants. Second, there are invariants
which always held but were not involved in a sufﬁciently
large and diverse number of requests for our system to have
conﬁdence in their correctness, as described in §IV-D. This
accounts for 55,557 invariants. Note that the same invariant
predicate may cause violations for one particular invariant
category, not meet ratiﬁcation threshold for another, and be
ratiﬁed for yet another.
The predicate that caused the most violations in our evalu-
ation step is o2 is a friend of the logged-in user. Intuitively,
this happens because users perform most of their interactions
with friends, resulting in the invariant being picked up initially.
However, many interactions are also valid for non-friends,
resulting in the invariant failing evaluation. A related example
is the predicate the logged-in user recently communicated with
o2. While that predicate usually holds, it is only an incidental
relationship and is not required. We see similar patterns in all
top 10 invariants ranked by number of violations caused in
the evaluation stage. We therefore conclude that checking the
invariants against all production requests, rather than against
a sample, is necessary for having a set of correct invariants.
The invariants which did not meet the ratiﬁcation volume
requirements either reference properties that take a limited set
of values or are related to features that are only available to
1103
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:23:44 UTC from IEEE Xplore.  Restrictions apply. 