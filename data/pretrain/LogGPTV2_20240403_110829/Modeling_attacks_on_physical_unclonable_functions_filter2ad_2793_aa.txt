title:Modeling attacks on physical unclonable functions
author:Ulrich R&quot;uhrmair and
Frank Sehnke and
Jan S&quot;olter and
Gideon Dror and
Srinivas Devadas and
J&quot;urgen Schmidhuber
Modeling Attacks on Physical Unclonable Functions
Ulrich Rührmair
Frank Sehnke
Computer Science Departm.
Computer Science Departm.
Computer Science Departm.
TU München
80333 München, Germany
PI:EMAIL
Gideon Dror
The Academic College of
Tel-Aviv-Jaffa
Tel-Aviv 61083, Israel
PI:EMAIL
TU München
80333 München, Germany
PI:EMAIL
Srinivas Devadas
Department of EECS
MIT
Cambrige, MA, USA
PI:EMAIL
Jan Sölter
TU München
80333 München, Germany
PI:EMAIL
Jürgen Schmidhuber
Computer Science Departm.
TU München
80333 München, Germany
PI:EMAIL
ABSTRACT
We show in this paper how several proposed Physical Un-
clonable Functions (PUFs) can be broken by numerical mod-
eling attacks. Given a set of challenge-response pairs (CRPs)
of a PUF, our attacks construct a computer algorithm which
behaves indistinguishably from the original PUF on almost
all CRPs. This algorithm can subsequently impersonate the
PUF, and can be cloned and distributed arbitrarily. This
breaks the security of essentially all applications and proto-
cols that are based on the respective PUF.
The PUFs we attacked successfully include standard Ar-
biter PUFs and Ring Oscillator PUFs of arbitrary sizes, and
XOR Arbiter PUFs, Lightweight Secure PUFs, and Feed-
Forward Arbiter PUFs of up to a given size and complexity.
Our attacks are based upon various machine learning tech-
niques, including Logistic Regression and Evolution Strate-
gies. Our work leads to new design requirements for secure
electrical PUFs, and will be useful to PUF designers and
attackers alike.
Categories and Subject Descriptors
C.3 [Special Purpose and Application-Based Systems]:
Smartcards; B.7.m [Integrated Circuits]: Miscellaneous;
E.3 [Data Encryption]: Code breaking
General Terms
Security, Theory, Design
Keywords
Physical Unclonable Functions, Machine Learning, Crypt-
analysis, Physical Cryptography
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’10, October 4–8, 2010, Chicago, Illinois, USA.
Copyright 2010 ACM 978-1-4503-0244-9/10/10 ...$10.00.
1.
INTRODUCTION
1.1 Motivation and Background
Electronic devices are now pervasive in our everyday life.
They are an accessible target for adversaries, which raises a
host of security and privacy issues. Classical cryptography
oﬀers several measures against these problems, but they all
rest on the concept of a secret binary key: It is assumed that
the devices can contain a piece of information that is, and
remains, unknown to the adversary. Unfortunately, it can be
diﬃcult to uphold this requirement in practice. Physical at-
tacks such as invasive, semi-invasive, or side-channel attacks,
as well as software attacks like API-attacks and viruses, can
lead to key exposure and full security breaks. The fact that
the devices should be inexpensive, mobile, and cross-linked
obviously aggravates the problem.
The described situation was one motivation that led to the
development of Physical Unclonable Functions (PUFs). A
PUF is a (partly) disordered physical system S that can be
challenged with so-called external stimuli or challenges Ci,
upon which it reacts with corresponding responses termed
RCi . Contrary to standard digital systems, a PUF’s re-
sponses shall depend on the nanoscale structural disorder
present in the PUF. This disorder cannot be cloned or re-
produced exactly, not even by its original manufacturer, and
is unique to each PUF. Assuming the stability of the PUF’s
responses, any PUF S hence implements an individual func-
tion FS that maps challenges Ci to responses RCi of the
PUF.
Due to its complex and disordered structure, a PUF can
avoid some of the shortcomings associated with digital keys.
For example, it is usually harder to read out, predict, or
derive its responses than to obtain the values of digital keys
stored in non-volatile memory. This fact has been exploited
for various PUF-based security protocols. Prominent exam-
ples including schemes for identiﬁcation and authentication
[1, 2], key exchange or digital rights management purposes
[3].
1.2 Strong PUFs, Controlled PUFs, and Weak
PUFs
There are several subtypes of PUFs, each with its own
applications and security features. Three major types, which
must explicitly be distinguished in this paper, are Strong
237PUFs [1, 2, 4] 1, Controlled PUFs [3], and Weak PUFs [4],
initially termed Physically Obfuscated Keys (POKs) [5].
1.2.1 Strong PUFs
Strong PUFs are disordered physical systems with a com-
plex challenge-response behavior and very many possible
challenges. Their security features are: (i) It must be im-
possible to physically clone a Strong PUF, i.e., to fabricate
a second system which behaves indistinguishably from the
original PUF in its challenge-response behavior. This re-
striction shall hold even for the original manufacturer of
the PUF. (ii) A complete determination/measurement of
all challenge-response pairs (CRPs) within a limited time
frame (such as several days or even weeks) must be impos-
sible, even if one can challenge the PUF freely and has un-
restricted access to its responses. This property is usually
met by the large number of possible challenges and the ﬁnite
read-out speed of a Strong PUF. (iii) It must be diﬃcult to
numerically predict the response RC of a Strong PUF to a
randomly selected challenge C, even if many other CRPs are
known.
Possible applications of Strong PUFs cover key establish-
ment [1, 7], identiﬁcation [1], and authentication [2]. They
also include oblivious transfer [8] and any protocols derived
from it, including zero-knowledge proofs, bit commitment,
and secure multi-party computation [8]. In said applications,
Strong PUFs can achieve secure protocols without the usual,
standard computational assumptions concerning the factor-
ing or discrete logarithm problem (albeit their security rests
on other, independent computational and physical assump-
tions). Currently known electrical, circuit-based candidates
for Strong PUFs are described in [9, 10, 11, 12, 13].
1.2.2 Controlled PUFs
A Controlled PUF as described in [3] uses a Strong PUF
as a building block, but adds control logic that surrounds the
PUF. The logic prevents challenges from being applied freely
to the PUF, and hinders direct read-out of its responses.
This logic can be used to thwart modeling attacks. However,
if the outputs of the embedded Strong PUF can be directly
probed, then it may be possible to model the Strong PUF
and break the Controlled PUF protocol.
1.2.3 Weak PUFs
Weak PUFs, ﬁnally, may have very few challenges — in
the extreme case just one, ﬁxed challenge. Their response(s)
RCi are used to derive a standard secret key, which is sub-
sequently processed by the embedding system in the usual
fashion, e.g., as a secret input for some cryptoscheme. Con-
trary to Strong PUFs, the responses of a Weak PUF are
never meant to be given directly to the outside world.
Weak PUFs essentially are a special form of non-volatile
key storage. Their advantage is that they may be harder to
read out invasively than non-volatile memory like EEPROM.
Typical examples include the SRAM PUF [14, 4], Butterﬂy
PUF [15] and Coating PUF [16]. Integrated Strong PUFs
have been suggested to build Weak PUFs or Physically Ob-
fuscated Keys (POKs), in which case only a small subset of
all possible challenges is used [5, 9].
One important aspect of Weak PUFs is error correction
and stability. Since their responses are processed internally
1Strong PUFs have also been referred to as Physical Ran-
dom Functions [5], or Physical One-Way Functions [6].
as a secret key, error correction must be carried out on-chip
and with perfect precision. This often requires the storage of
error-correcting helper data in non-volatile memory on the
chip. Strong PUFs usually allow error correction schemes
that are carried out by the external recipients of their re-
sponses.
1.3 Modeling Attacks on PUFs
Modeling attacks on PUFs presume that an adversary Eve
has, in one way or the other, collected a subset of all CRPs
of the PUF, and tries to derive a numerical model from this
data, i.e., a computer algorithm which correctly predicts the
PUF’s responses to arbitrary challenges with high probabil-
ity. If successful, this breaks the security of the PUF and of
any protocols built on it. It is known from earlier work that
machine learning (ML) techniques are a natural and power-
ful tool for such modeling attacks [5, 17, 18, 19, 20]. How
the required CRPs can be collected depends on the type of
PUF under attack.
Strong PUFs.
Strong PUFs usually have no protection mechanisms that
restricts Eve in challenging them or in reading out their re-
sponses. Their responses are freely accessible from the out-
side, and are usually not post-processed on chip [1, 9, 10,
11, 12, 13]. Most electrical Strong PUFs further operate at
frequencies of a few MHz [12]. Therefore even short physical
access periods enable the read-out of many CRPs. Another
potential CRP source is simple protocol eavesdropping, for
example on standard Strong PUF-based identiﬁcation pro-
tocols, where the CRPs are sent in the clear [1]. Eavesdrop-
ping on responses, as well as physical access to the PUF that
allows the adversary to apply arbitrary challenges and read
out their responses, is part of the established attack model
for Strong PUFs.
Controlled PUFs.
For any adversary that is restricted to non-invasive CRP
measurement, modeling attacks can be successfully disabled
if one uses a secure one-way hash over the outputs of the
PUF to create a Controlled PUF. We note that this requires
error correction of the PUF outputs which are inherently
noisy [3]. Successful application of our techniques to a Con-
trolled PUF only becomes possible if Eve can probe the
internal, digital response signals of the underlying Strong
PUF on their way to the control logic. Even though this is
a signiﬁcant assumption, probing digital signals is still eas-
ier than measuring continuous analog parameters within the
underlying Strong PUF, for example determining its delay
values. Physical access to the PUF is part of the natural
attack model on PUFs, as mentioned above.
Weak PUFs.
Weak PUFs are only susceptible to model building attacks
if a Strong PUF, embedded in some hardware system, is
used to derive the physically obfuscated key. This method
has been suggested in [5, 9]. In this case, the internal digital
response signals of the Strong PUF to injected challenges
have to be probed.
We stress that purely numerical modeling attacks, as pre-
sented in this paper, are not relevant for Weak PUFs with
just one challenge (such as the Coating PUF, SRAM PUF,
or Butterﬂy PUF). This does not necessarily imply that
238these PUFs are more secure than Strong PUFs or Controlled
PUFs, however. Other attack strategies can be applied, in-
cluding invasive, side-channel and virus attacks, but they are
not the topic of this paper. For example, probing the output
of the SRAM cell prior to storing the value in a register can
break the security of the cryptographic protocol that uses
these outputs as a key. We also note that attacking a Con-
trolled PUF via modeling attacks that target the underlying
Strong PUF requires substantially more signal probing than
breaking a Weak PUF that possesses just one challenge.
1.4 Our Contributions and Related Work
We describe successful modeling attacks on several known
electrical candidates for Strong PUFs,
including Arbiter
PUFs, XOR Arbiter PUFs, Feed-Forward Arbiter PUFs,
Lightweight Secure PUFs, and Ring Oscillator PUFs. Our
attacks work for PUFs of up to a given number of inputs (or
stages) or complexity. The prediction rates of our machine
learned models signiﬁcantly exceed the known or derived
stability of the respective PUFs in silicon in these ranges.
Our attacks are very feasible on the CRP side. They re-
quire an amount of CRPs that grows only linearly or log-
linearly in the relevant structural parameters of the attacked
PUFs, such as their numbers of stages, XORs, feed-forward
loops, or ring oscillators. The computation times needed
to derive the models (i.e., to train the employed ML algo-
rithms) are low-degree polynomial, with one exception: The
computation times for attacking XOR Arbiter and Lightweight
Secure PUFs grow, in approximation for medium number of
XORs and large number of stages, super-polynomial in the
number of XORs. But the instability of these PUFs also in-
creases exponentially in their number of XORs, whence this
parameter cannot be raised at will in practical applications.
Still, it turns out that the number of stages in these two
types of PUFs can be increased without signiﬁcant eﬀect
on their instability, providing a potential lever for making
these PUFs more secure without destroying their practical-
ity. Our work thus also points to design requirements by
which the security of XOR Arbiter PUFs and Lightweight
Secure PUFs against modeling attacks could be upheld in
the near future.
Our results break the security of any Strong PUF-type
protocol that is based on one of the broken PUFs. This
includes any identiﬁcation, authentication, key exchange or
digital rights management protocols, such as the ones de-
scribed in [1, 2, 6, 7, 11]. Under the assumptions and attack
scenarios described in Section 1.3, our ﬁndings also restrict
the use of the broken Strong PUF architectures within Con-
trolled PUFs and as Weak PUFs, if we assume that digital
values can be probed.
Related Work on Modeling Attacks.
Earlier work on PUF modeling attacks, such as [11, 17,
18, 19], described successful attacks on standard Arbiter
PUFs and on Feed-Forward Arbiter PUFs with one loop.
But these approaches did not generalize to Feed-Forward
Arbiter PUFs with more than two loops. The XOR Arbiter
PUF, Lightweight PUF, Feed-Forward Arbiter PUF with
more than two Feed-Forward Loops, and Ring Oscillator
PUF have not been cryptanalyzed thus far. No scalability
analyses of the required CRPs and computation times had
been performed in previous works.
Entropy Analysis vs. Modeling Attacks.
Another useful approach to evaluate PUF security is en-
tropy analysis. Two variants exist: First, to analyze the in-
ternal entropy of the PUF. This is similar to the established
physical entropy analysis in solid-state systems. A second
option is to analyze the statistical entropy of all challenge-
response pairs of a PUF; how many of them are indepen-
dent?
Entropy analysis is a valuable tool for PUF analysis, but
it diﬀers from our approach in two aspects. First, it is non-
constructive in the sense that it does not tell you how to
break a PUF, even if the entropy score is low. Modeling
attacks, to the contrary, actually break PUFs. Second, it
is not clear if the internal entropy of a circuit-based Strong
PUF is a good estimate for its security. Equivalently, is
the entropy of an AES secret key a good estimate of the
AES security? The security of a Strong PUF comes from
an interplay between its random internal parameters (which
can be viewed as its entropy), and its internal model or
internal functionality. It is not the internal entropy alone
that determines the security. As an example, compare an 8-
XOR, 256-bit XOR PUF to a standard PUF with bitlength
of 8 · 256 = 2048. Both have the same internal entropy, but
very diﬀerent security properties, as we show in the sequel.
1.5 Organization of the Paper
The paper is organized as follows. We describe the method-
ology of our ML experiments in Section 2.
In Sections 3
to 7, we present our results for various Strong PUF candi-
dates. They deal with Arbiter PUFs, XOR Arbiter PUFs,
Lightweight Arbiter PUFs, Feed-Forward Arbiter PUFs and
Ring Oscillator PUFs, in sequence. We conclude with a sum-
mary and discussion of our results in Section 8.
2. METHODOLOGY SECTION
2.1 Employed Machine Learning Methods
2.1.1 Logistic Regression
Logistic Regression (LR) is a well-investigated supervised
machine learning framework, which has been described, for
example, in [21]. In its application to PUFs with single-bit
outputs, each challenge C = b1 · ·· bk is assigned a proba-
bility p (C, t | (cid:2)w) that it generates a output t ∈ {−1, 1} (for
technical reasons, one makes the convention that t ∈ {−1, 1}
instead of {0, 1}). The vector (cid:2)w thereby encodes the relevant
internal parameters, for example the particular runtime de-
lays, of the individual PUF. The probability is given by the