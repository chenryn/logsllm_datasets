• Minimized interaction renders illegal activities harder
for law enforcement to monitor.
In some cases, as
for the key-theft and calling-card CSCs we present, a
criminal can set up a contract and walk away, allowing
it to execute autonomously with no further interaction.
• Enriched transactions with external state broaden the
scope of possible CSCs to, e.g., physical crimes (ter-
rorism, arson, murder, etc.).
As decentralized smart contract systems typically in-
herit the anonymity (pseudonymity) of Bitcoin, they of-
fer similar secrecy for criminal activities. Broadly speak-
ing, therefore, there is a risk that the capabilities enabled
by decentralized smart contract systems will enable new
underground ecosystems and communities.
2.2 Digital cash and crime
Bitcoin and smart contracts do not represent the earli-
est emergence of cryptocurrency. Anonymous e-cash
was introduced in 1982 in a seminal paper by David
Chaum [30]. Naccache and von Solms noted that anony-
mous currency would render “perfect crimes” such as
kidnapping untraceable by law enforcement [61]. This
observation prompted the design of fair blind signatures
or “escrow” for e-cash [24, 62], which enables a trusted
third party to link identities and payments. Such linkage
is possible in classical e-cash schemes where a user iden-
tiﬁes herself upon withdraw of anonymous cash, but not
pseudonymous cryptocurrencies such as Bitcoin.
Ransomware has appeared in the wild since 1989 [16].
A major cryptovirological [64] “improvement” to ran-
somware has been use of Bitcoin [47], thanks to which
CryptoLocker ransomware has purportedly netted hun-
dreds of millions of dollars in ransom [23]. Assassi-
nation markets using anonymous digital cash were ﬁrst
proposed in a 1995-6 essay entitled “Assassination Poli-
tics” [17].
There has been extensive study of Bitcoin-enabled
crime, such as money laundering [54], Bitcoin theft [52],
and illegal marketplaces such as the Silk Road [32].
Meiklejohn et al. [52] note that Bitcoin is pseudony-
mous and that mixes, mechanisms designed to confer
anonymity on Bitcoins, do not operate on large volumes
of currency and in general today it is hard for criminals
to cash out anonymously in volume.
On the other hand, Ron and Shamir provide evidence
that the FBI failed to locate most of the Bitcoin holdings
of Dread Pirate Roberts (Ross Ulbricht), the operator of
the Silk Road, even after seizing his laptop [59]. M¨oser,
B¨ohome, and Breuker [54] ﬁnd that they cannot success-
fully deanonymize transactions in two of three mixes un-
der study, suggesting that the “Know-Your-Customer”
principle, regulators’ main tool in combatting money
laundering, may prove difﬁcult to enforce in cryptocur-
rencies.
Increasingly practical proposals to use NIZK
proofs for anonymity in cryptocurrencies [18, 34, 53],
some planned for commercial deployment, promise to
make stronger anonymity available to criminals.
3 Notation and Threat Model
We adopt the formal blockchain model proposed by
Kosba et al. [45]. As background, we give a high-level
4
description of this model in this section. We use this
model to specify cryptographic protocols in our paper;
these protocols encompass criminal smart contracts and
corresponding user-side protocols.
Protocols in the smart contract model. Our model
treats a contract as a special party that is entrusted to
enforce correctness but not privacy, as noted above. (In
reality, of course, a contract is enforced by the network.)
All messages sent to the contract and its internal state
are publicly visible. A contract interacts with users and
other contracts by exchanging messages (also referred to
as transactions). Money, expressed in the form of ac-
count balances, is recorded in the global ledger (on the
blockchain). Contracts can access and update the ledger
to implement money transfers between users, who are
represented by pseudonymous public keys.
3.1 Threat Model
We adopt the following threat model in this paper.
• Blockchain: Trusted for correctness but not privacy.
We assume that the blockchain always correctly stores
data and performs computations and is always avail-
able. The blockchain exposes all of its internal states
to the public, however, and retains no private data.
• Arbitrarily malicious contractual parties. We assume
that contractual parties are mutually distrustful, and
they act solely to maximize their own beneﬁt. Not only
can they deviate arbitrarily from the prescribed proto-
col, they can also abort from the protocol prematurely.
• Network inﬂuence of the adversary. We assume that
messages between the blockchain and players are de-
livered within a bounded delay, i.e., not permanently
dropped.
(A player can always resend a transaction
dropped by a malicious miner.) In our model, an ad-
versary immediately receives and can arbitrarily re-
order messages, however.
In real-life decentralized
cryptocurrencies, the winning miner determines the or-
der of message processing. An adversary may collude
with certain miners or inﬂuence message-propagation
among nodes. As we show in Section 5, for key-theft
contracts, message-reordering enables a rushing attack
that a commission-fair CSC must prevent.
The formal model we adopt (reviewed later in this sec-
tion and described in full by Kosba et al. [45]) captures
all of the above aspects of our threat model.
3.2 Security deﬁnitions
For a CSC to be commission-fair requires two things:
• Correct deﬁnition of commission-fairness. There is no
universal formal deﬁnition of commission fairness: It
is application-speciﬁc, as it depends on the goals of
5
the criminal (and perpetrator). Thus, for each CSC, we
specify in the paper appendix a corresponding deﬁni-
tion of commission-fairness by means of a UC-style
ideal functionality that achieves it.
Just specifying
a correct ideal functionality is itself often challeng-
ing! We illustrate the challenge in Section 5 and Ap-
pendix D with a naive-key functionality that represents
seemingly correct but in fact ﬂawed key-theft contract.
• Correct protocol implementation. To prove that a
CSC is commission-fair, we must show that its (real-
world) protocol emulates the corresponding ideal func-
tionality. We prove this for our described CSCs in
the standard Universally Composable (UC) simula-
tion paradigm [26] adopted in the cryptography litera-
ture, against arbitrarily malicious contractual counter-
parties as well as possible network adversaries. Our
protocols are also secure against aborting adversaries,
e.g., attempts to abort without paying the other party.
Fairness in the presence of aborts is well known in
general to be impossible in standard models of dis-
tributed computation [33]. Several recent works, show
that a blockchain that is correct, available, and aware
of the progression of time can enforce ﬁnancial fair-
ness against aborting parties [21, 45, 15]. Speciﬁcally,
when a contract lapses, the blockchain can cause the
aborting party to lose a deposit to the honest parties.
3.3 Notational Conventions
We now explain some notational conventions for writing
contracts. Appendix A gives a warm-up example.
• Currency and ledger. We use ledger[P] to denote
party P’s balance in the global ledger. For clarity,
variables that begin with a $ sign denote money, but
otherwise behave like ordinary variables.
Unlike in Ethereum’s Serpent language, in our for-
mal notation, when a contract receives some $amount
from a party P, this is only message transfer, and no
currency transfer has taken place at this point. Money
transfers only take effect when the contract performs
operations on the ledger, denoted ledger.
• Pseudonymity. Parties can use pseudonyms to ob-
In particular, a party can
tain better anonymity.
generate arbitrarily many public keys.
In our nota-
tional system, when we refer to a party P, P de-
notes the party’s pseudonym. The formal blockchain
model [45] we adopt provides a contract wrapper man-
ages the pseudonym generation and the message sign-
ing necessary for establishing an authenticated chan-
nel to the contract. These details are abstracted away
from the main contract program.
• Timer. Time progresses in rounds. At the beginning
of each round, the contract’s Timer function will be
invoked. The variable T encodes the current time.
• Entry points and variable scope. A contract can
have various entry points, each of which is invoked
when receiving a corresponding message type. Thus
entry points behave like function calls invoked upon
receipt of messages.
All variables are assumed to be globally scoped, with
the following exception: When an entry point says
“Upon receiving a message from some party P,” this
allows the registration of a new party P. In general,
contracts are open to any party who interacts with
them. When a message is received from P (without
the keyword “some”), party P denotes a ﬁxed party –
and a well-formed contract has already deﬁned P.
This notational system [45] is not only designed for
convenience, but is also endowed with precise, formal
meanings compatible with the Universal Composability
framework [26]. We refer the reader to [45] for formal
modeling details. While our proofs in the paper appen-
dices rely on this supporting formalism, the main body
can be understood without it.
4 CSCs for Leakage of Secrets
As a ﬁrst example of the power of smart contracts, we
show how an existing type of criminal contract deployed
over Bitcoin can be made more robust and functionally
enhanced as a smart contract and can be practically im-
plemented in Ethereum.
Among the illicit practices stimulated by Bitcoin is
payment-incentivized leakage, i.e., public disclosure, of
secrets. The recently created web site Darkleaks [3] (a
kind of subsidized Wikileaks) serves as a decentralized
market for crowdfunded public leakage of a wide variety
of secrets, including, “Hollywood movies, trade secrets,
government secrets, proprietary source code, industrial
designs like medicine or defence, [etc.].”
Intuitively, we deﬁne commission-fairness in this set-
ting to mean that a contractor C receives payment iff it
leaks a secret in its entirety within a speciﬁed time limit.
(See Appendix E for a formal deﬁnition.) As we show,
Darkleaks highlights the inability of Bitcoin to support
commission-fairness. We show how a CSC can in fact
achieve commission-fairness with high probability.
4.1 Darkleaks
In the Darkleaks system, a contractor C who wishes to
sell a piece of content M partitions it into a sequence of
n segments {mi}n
i=1. At a time (block height) Topen pre-
speciﬁed by C, a randomly selected subset Ω ⊂ [n] of
k segments is publicly disclosed as a sample to entice
donors / purchasers—those who will contribute to the
purchase of M for public leakage. When C determines
that donors have collectively paid a sufﬁcient price, C
decrypts the remaining segments for public release. The
parameter triple (n,k,Topen) is set by C (where n = 100
and k = 20 are recommended defaults).
To ensure a fair exchange of M for payment without
direct interaction between parties, Darkleaks implements
a (clever) protocol on top of the Bitcoin scripting lan-
guage. The main idea is that for a given segment mi of M
that is not revealed as a sample in Ω, donors make pay-
ment to a Bitcoin account ai with public key pki. The
segment mi is encrypted under a key κ = H(pki) (where
H = SHA-256). To spend its reward from account ai, C
is forced by the Bitcoin transaction protocol to disclose
pki; thus the act of spending the reward automatically
enables the community to decrypt mi.
We give further details in Appendix F.1.
Shortcomings and vulnerabilities. The Darkleaks pro-
tocol has three major shortcomings / vulnerabilities that
appear to stem from fundamental functional limitations
of Bitcoin’s scripting language when constructing con-
tracts without direct communication between parties.
The ﬁrst two undermine commission-fairness, while the
third limits functionality.1
1. Delayed release: C can refrain from spending pur-
chasers’ / donors’ payments and releasing unopened seg-
ments of M until after M loses value. E.g., C could with-
hold segments of a ﬁlm until after its release in theaters,
of an industrial design until after it is produced, etc.
2. Selective withholding: C can choose to forego pay-
ment for selected segments and not disclose them. For
example, C could leak and collect payment for all of a
leaked ﬁlm but the last few minutes (which, with high
probability, will not appear in the sample Ω), signiﬁ-
cantly diminishing the value of leaked segments.
3. Public leakage only: Darkleaks can only serve to leak
secrets publicly. It does not enable fair exchange for pri-
vate leakage, i.e., for payment in exchange for a secret
M encrypted under the public key of a purchaser P.
Additionally, Darkleaks has a basic protocol ﬂaw:
4. Reward theft: In the Darkleaks protocol, the Bitcoin
private key ski corresponding to pki is derived from mi;
speciﬁcally ski = SHA-256(mi). Thus, the source of M
(e.g., the victimized owner of a leaked ﬁlm) can derive
ski and steal rewards received by C. (Also, when C claims
a reward, a malicious node that receives the transaction
can decrypt mi, compute ski = SHA-256(mi), and po-
tentially steal the reward by ﬂooding the network with a
competing transaction [38].)
1That these limitations are fundamental is evidenced by calls for
new, time-dependent opcodes. One example is CHECKLOCKTIMEV-
ERIFY; apart from its many legitimate applications, proponents note
that it can facilitate secret leakage as in Darkleaks [37].
6
This last problem is easily remedied by generating the
i=1 of segment encryption keys pseudorandomly
set {κi}n
or randomly, which we do in our CSC designs.
Remark: In any protocol in which goods are represented
by a random sample, not just Darkleaks, C can insert a
small number of valueless segments into M. With non-
negligible probability, these will not appear in the sample
Ω, so Ω necessarily provides only a weak guarantee of
the global validity of M. The larger k and n, the smaller
the risk of such attack.
4.2 A generic public-leakage CSC
We now present a smart contract that realizes public
leakage of secrets using blackbox cryptographic prim-
itives.
(We later present efﬁcient realizations.) This
contract overcomes limitation 1. of the Darkleaks pro-
tocol (delayed release) by enforcing disclosure of M at
a pre-speciﬁed time Tend—or else immediately refund-
ing buyers’ money. It addresses limitation 2. (selective
withholding) by ensuring that M is revealed in an all-or-
nothing manner. (We later explain how to achieve private
leakage and overcome limitation 3.)
Again, we consider settings where C aims to sell M for
public release after revealing sample segments M∗.
Informal protocol description.
Informally, the proto-
col involves the following steps:
• Create contract. A seller C initializes a smart con-
tract with the encryption of a randomly generated mas-
ter secret key msk. The master secret key is used
to generate (symmetric) encryption keys for the seg-
ments {mi}n
i=1. C provides a cryptographic commit-
ment c0 := Enc(pk, msk,r0) of msk to the contract. (To
meet the narrow technical requirements of our security
proofs, the commitment is an encryption with random-
ness r0 under a public key pk created during a trusted
setup step.) The master secret key msk can be used to
decrypt all leaked segments of M.
• Upload encrypted data. For each i ∈ [n], C generates
encryption key κi := PRF(msk,i), and encrypts the i-th
segment as cti = encκi[mi]. C sends all encrypted seg-
ments {cti}i∈[n] to the contract (or, for efﬁciency, pro-
vides hashes of copies stored with a storage provider,
e.g., a peer-to-peer network). Interested purchasers /
donors can download the segments of M, but cannot
decrypt them yet.
• Challenge. The contract generates a random challenge
set Ω ⊂ [n], in practice based on the hash of the most
recent currency block or some well known randomness
source, e.g., the NIST randomness beacon [9].
• Response. C reveals the set {κi}i∈Ω to the contract, and
gives ZK proofs that the revealed secret keys {κi}i∈Ω
are generated correctly from the msk encrypted as c0.
• Collect donations. During a donation period, potential