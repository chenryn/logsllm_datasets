scheduled in the previous turn.
In our packet scheduling algorithm, the bin size is a mul-
tiple of the warp size in the GPU. The packets in an active
bin will be grouped together and become a work-group when
the OpenCL kernel launches to the GPU. Each work-item
in a work-group processes a packet.
When the packet scheduler categorizes the packets in to
the wait bins by their crypto algorithms and lengths, it cat-
egorizes the packets in the leftover queue ﬁrst, and then
moves on to the received packets (step 1 and 2 in Figure 6).
When a packet is processed by the packet scheduler, it
searches for a bin labeled with the packet’s algorithm and
length range. For example, labels for the crypto algorithms
include
AES-CBC-decryption,
HMAC-SHA1, AES-CBC-encryption+HMAC-SHA1, AES-
CBC-decryption+HMAC-SHA1, etc. In addition, labels for
the length ranges include [LB, 255], [256, 511], [512, 767],
AES-CBC-encryption,
1259[768, 1023], [1024, 1279], [1280, U B], where LB and U B are
the lower and upper bounds of packet lengths in IPsec.
If successful, the packet scheduler inserts the packet in the
bin found. Otherwise, it inserts the packet in an empty bin
and labels the bin with the packet’s algorithm and length
range. If there is no empty bin available, the packet is in-
serted to the leftover queue. As a result, each bin is ﬁlled
with the packets of the same algorithm and the same length
range.
(cid:12)
(cid:86)
(cid:80)
(cid:11)
(cid:3)
(cid:72)
(cid:80)
(cid:55)
(cid:76)
(cid:3)
(cid:3)
(cid:79)
(cid:72)
(cid:81)
(cid:85)
(cid:72)
(cid:46)
(cid:47)
(cid:38)
(cid:81)
(cid:72)
(cid:83)
(cid:50)
(cid:20)(cid:17)(cid:27)
(cid:20)(cid:17)(cid:25)
(cid:20)(cid:17)(cid:23)
(cid:20)(cid:17)(cid:21)
(cid:20)
(cid:19)(cid:17)(cid:27)
(cid:19)(cid:17)(cid:25)
(cid:19)(cid:17)(cid:23)
(cid:19)(cid:17)(cid:21)
(cid:19)
AES(cid:882)CBC+HMAC(cid:882)SHA1
AES(cid:882)CBC
HMAC(cid:882)SHA1
(cid:25)(cid:23)
(cid:21)(cid:24)(cid:25)
(cid:51)(cid:68)(cid:70)(cid:78)(cid:72)(cid:87)(cid:3)(cid:86)(cid:76)(cid:93)(cid:72)
(cid:24)(cid:20)(cid:21)
(cid:20)(cid:19)(cid:21)(cid:23)
Figure 7: Average OpenCL kernel execution time
for 2048 packets.
At the time of the OpenCL kernel completion, the IPsec
thread switches the roles of the active bins and the wait
bins. Then, it launches the OpenCL kernel to process the
active bins. Before the OpenCL kernel launch, it sorts the
active bins in a decreasing order by their estimated GPU
processing time to help the GPU hardware scheduler (step
3 in Figure 6).
The bin processing time is estimated by the bin’s crypto
algorithm and packet length range. After measuring IPsec
processing time on the GPU (i.e., OpenCL kernel execution
time) with diﬀerent packet sizes and crypto algorithms, we
use the result to estimate processing time for each bin. Fig-
ure 7 shows a result of measuring IPsec processing time on
the GPU with diﬀerent packet sizes and crypto algorithms.
The OpenCL kernel execution time is proportional to the
packet length varying from 64B to 1024B.
Zhang et al. [32] propose a software solution to avoid
control ﬂow divergence. Similar to PIPSEA, their solution
groups GPU threads to avoid control ﬂow divergence. How-
ever, it does not provide a method to resolve the load im-
balance between GPU threads. It neither sorts the groups
nor uses bins to achieve the load balance.
3.4 Effects of Packet Scheduling
As a result of our packet scheduling algorithm, each bin is
ﬁlled with the packets of the same crypto algorithm and the
same length range. In addition, bins are sorted in a decreas-
ing order by their estimated processing time on the GPU.
Note that the bin size is a multiple of the warp size in the
GPU, and each bin becomes a work-group of the OpenCL
kernel.
Avoiding control-ﬂow divergence. If packets in a work-
group execute diﬀerent crypto algorithms, they will take dif-
ferent execution paths. As a result, signiﬁcant control-ﬂow
divergence occurs. As mentioned in Section 2.2, the control-
ﬂow divergence is one of major performance factors in GPU
programming[4, 27].
By grouping incoming packets of the same crypto algo-
rithm in to a work-group together, we fully eliminate control-
ﬂow divergence caused by diﬀerent crypto algorithms. In ad-
dition, by grouping incoming packets of similar lengths in to
the same work-group, we minimize control-ﬂow divergence
caused by conditional branches (e.g., loop exit conditions)
on the packet length in a crypto algorithm.
Avoiding inter-work-group load imbalance. As men-
tioned in Section 2.2, the GPU hardware dynamically as-
signs work-groups to idle CUs in the GPU, and a work-
group that has a smaller ID value has a priority over an idle
CU. By sorting bins in a decreasing order of their estimated
processing time, the ﬁrst bin in the sorted order maps to
the work-group of the smallest ID when the OpenCL kernel
launches. This implements a variation of the LPTF (Longest
Processing Time First) algorithm. It avoids the load imbal-
ance on CUs caused by diﬀerent amounts of work between
diﬀerent work-groups.
Optimality consideration. Assigning work-groups to mul-
tiple CUs can be mapped to a multiprocessor scheduling
problem. Note that our scheduling approach achieves a near-
optimal solution. Since this problem is known to be NP-
complete[9], we use an algorithm that gives a near-optimal
solution to boost the speed.
LPTF sorts the tasks by its processing time and assigns
them to the processor with the least amount of assigned
tasks. Similarly, our packet scheduler sorts the bins by its
estimated processing time, and the hardware scheduler as-
signs them to idle CUs one by one. LPTF is known to
achieve an upper bound less than 4/3 of the minimum pro-
cessing time [10].
Avoiding intra-work-group load imbalance. On the
other hand, if a work-group consists of packets with multiple
lengths, the processing time of the work-group is determined
by the longest packet in the batch because the processing
time of a crypto algorithm is typically proportional to the
packet length (Figure 7). By grouping incoming packets of
similar lengths in to the same work-group, we minimize such
load imbalance between work-items in a work-group.
Packet reordering problem. Packet reordering occurs
naturally by the network environment, such as route change,
parallelism within a router, packet retransmission, etc. The
packet reordering problem may adversely aﬀect the perfor-
mance and eﬃciency of the packet destination that needs to
correct the order of packets.
Our implementation makes some packets reordered be-
cause the packets enqueued to the leftover queue are pro-
cessed and transmitted later than their peers. However, we
expect that the degree of reordering is not signiﬁcant be-
cause our implementation preferentially schedules the pack-
ets in the leftover queue in the next OpenCL kernel launch.
We observe that only less than 0.0001% of packets are re-
ordered using 128 bins.
3.5 OpenCL Kernel Optimization
Assuming that packet I/O is fast enough, the OpenCL ker-
nel execution time determines the throughput of IPsec gate-
way and the round-trip latencies of IPsec packets. Thus,
we optimize the OpenCL kernel as much as possible con-
sidering important performance factors of GPUs, such as
global memory access coalescing, control-ﬂow divergence,
1260Processor
RAM
NIC
OS
Software
Processor
GPU
RAM
NIC
OS
Software
APU system
AMD RX-421BD APU
(4 x86 cores, 8 GPU cores)
2 x 8 GB (DDR4 2133 MHz)
Intel X710DX4 (4-port 10GbE)
CentOS 6.5
AMD OpenCL SDK 3.0
Intel DPDK 2.1
dGPU system
2 x Intel Xeon CPU E5-2680 v3
(total 24 x86 cores)
2 x AMD FirePro S9100 or
2 x AMD Radeon R9 Nano
16 x 16 GB (DDR4 2133 MHz)
2 x Intel X710DX4 (total 8-port 10GbE)
CentOS 6.5
AMD OpenCL SDK 3.0
Intel DPDK 2.1
Table 1: System conﬁguration.
occupancy, vectorized accesses to the global memory, and
exploiting the local memory[4, 27].
Our packet scheduling algorithm enables PIPSEA to im-
plement all IPsec crypto algorithms in one monolithic OpenCL
kernel that is launched repeatedly by the IPsec thread. It
performs all functions of IPsec including packet header pro-
cessing, encryption, decryption, and authentication. Each
work-item in the kernel handles a packet. Each work-group
handles the packets contained in a bin.
For cipher algorithms, we focus on AES-CBC that is one
of the most widely used cipher algorithm for IPsec. We also
implement HMAC-SHA1, a commonly used authentication
algorithm in IPsec. Other crypto algorithms in IPsec, such
as AES-CTR, 3DES, AES-GCM, HMAC-SHA256, etc. can
be easily added to the OpenCL kernel.
3.6 Tuning Parameters
Number of bins and bin size. The number of wait bins
times the bin size is the total number of packets that are
processed by one OpenCL kernel launch (i.e., chunk size).
This signiﬁcantly aﬀects the packet round-trip latency and
the throughput. Thus, both the number of the bins and the
bin size are tuning parameters.
Granularity of packet length ranges. The granular-
ity of the packet length range is also a tuning parameter,
and it is closely related to the number of bins. The ﬁner the
length range, the more the reduction of the intra-work-group
load imbalance and control-ﬂow divergence. However, ﬁne-
grained length range increases the number of bins and gives
more bin searching overhead to the packet scheduler. More-
over, if we ﬁx the number of bins available, the ﬁne-grained
length range makes more packets to go to the leftover queue.
4. EVALUATION
This section describes the performance evaluation result
of PIPSEA. In addition, we discuss the cost eﬀectiveness of
our proposal.
4.1 Methodology
System conﬁguration. PIPSEA is built with an x86-
based AMD embedded APU processor, 16 GB of RAM, and
one Intel NIC with four 10GbE ports. Since PIPSEA runs
also on dGPUs as long as they support the HSA, we run
PIPSEA on two types of dGPUs: a professional high-end
dGPU (AMD FirePro S9100) and a gaming GPU (AMD
Radeon R9 Nano). Table 1 summarizes the speciﬁcation of
the system.
Packet generation. To evaluate PIPSEA, we use a DPDK-
based packet generator. It is directly connected to PIPSEA
via the four-port 10GbE NIC. Its role is both the source
and the sink of packets. It produces up to 40 Gbps network
traﬃc that contains packets with various types of lengths,
such as ﬁxed lengths, uniform random lengths, and lengths
that follow a speciﬁc network traﬃc distribution pattern.
For the packets that follow a speciﬁc network traﬃc dis-
tribution pattern, we choose IMIX (Internet Packet Mix)
that resembles the real-world traﬃc in the distribution of
packet lengths and deﬁned by Intel. It consists of 61.22% of
60-byte packets, 23.47% of 536-byte packets, and 15.31% of
1360-byte packets [14].
The packet generator also produces packets that have var-
ious types of source and destination IP addresses. They in-
clude ﬁxed addresses and uniform random addresses. By ex-
ploiting this feature, we evaluate PIPSEA with packets that
require randomly-mixed crypto algorithms for IPsec process-
ing.
Throughput and latency measurements. The packet
generator provides a feature to measure the round-trip la-
tency of a packet. After generating packets with time stamps,
it calculates the round-trip latency of the packets when it
receives them and stores the log in a ﬁle. We measure the
latency of PIPSEA using this feature.
PIPSEA performs both IPsec inbound and outbound pro-
cessing for decapsulation and encapsulation of ESPs (En-
capsulation Security Payloads), AHs (Authentication Head-
ers), and both. While the IPsec encapsulation increases the
packet size, the decapsulation decreases the packet size. To
be clear on the throughput metric, we measure the incom-
ing throughput, not the outgoing throughput of PIPSEA. In
addition, the packet size means the length of the ethernet
frame in bytes, including the frame check sequence (32-bit
CRC). In the IPsec decapsulation, the packet size is deﬁned
by the length of the plain packet excluding IPsec headers
and paddings.
RFC 2544 [5] describes benchmarking methodologies for
network interconnect devices. We faithfully follow RFC 2544
to measure the throughput and the latency of PIPSEA.
(cid:12)
(cid:86)
(cid:83)
(cid:69)
(cid:42)
(cid:11)
(cid:3)
(cid:87)
(cid:88)
(cid:83)
(cid:75)
(cid:74)
(cid:88)
(cid:82)
(cid:85)
(cid:75)
(cid:55)
(cid:23)(cid:19)
(cid:22)(cid:19)
(cid:21)(cid:19)
(cid:20)(cid:19)
(cid:19)
(cid:25)(cid:23)
(cid:21)(cid:24)(cid:25)
(cid:24)(cid:20)(cid:21)
(cid:51)(cid:68)(cid:70)(cid:78)(cid:72)(cid:87)(cid:3)(cid:54)(cid:76)(cid:93)(cid:72)
AES(cid:882)CBC(cid:3)encryption(cid:3)+(cid:3)HMAC(cid:882)SHA1
AES(cid:882)CBC(cid:3)encryption
HMAC(cid:882)SHA1
(cid:20)(cid:19)(cid:21)(cid:23)
(cid:20)(cid:21)(cid:27)(cid:19)
AES(cid:882)CBC(cid:3)decryption(cid:3)+(cid:3)HMAC(cid:882)SHA1
AES(cid:882)CBC(cid:3)decryption
Figure 8: The throughput of the crypto algorithms
with pre-generated packets in main memory.
1261Crypto algorithms used. We implement some of the
most widely used IPsec crypto algorithms in the OpenCL
kernel. We implement AES-128-CBC encryption/decryption
and HMAC-SHA1.
Figure 8 shows the throughput of the crypto algorithms
on the embedded APU without Packet I/O and IPsec header
processing. The crypto algorithms process pre-generated
packets stored in main memory, and the packets do not in-
clude any headers. Note that the packet size is just the pay-