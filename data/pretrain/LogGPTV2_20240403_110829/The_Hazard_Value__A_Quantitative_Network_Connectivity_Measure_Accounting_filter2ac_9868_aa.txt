title:The Hazard Value: A Quantitative Network Connectivity Measure Accounting
for Failures
author:Pieter Cuijpers and
Stefan Schmid and
Nicolas Schnepf and
Jir&apos;ı Srba
4
3
0
0
0
.
2
2
0
2
.
5
0
4
3
5
N
S
D
/
9
0
1
1
.
0
1
:
I
O
D
|
E
E
E
I
2
2
0
2
©
0
0
.
1
3
$
/
2
2
/
1
-
3
9
6
1
-
4
5
6
6
-
1
-
8
7
9
|
)
N
S
D
(
s
k
r
o
w
t
e
N
d
n
a
s
m
e
t
s
y
S
e
l
b
a
d
n
e
p
e
D
n
o
e
c
n
e
r
e
f
n
o
C
l
a
n
o
i
t
a
n
r
e
t
n
I
P
I
F
I
/
E
E
E
I
l
a
u
n
n
A
d
n
2
5
2
2
0
2
2022 52nd Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN)
The Hazard Value: A Quantitative Network
Connectivity Measure Accounting for Failures
Pieter Cuijpers∗†, Stefan Schmid‡, Nicolas Schnepf†§ and Jiˇrí Srba†
∗Eindhoven University of Technology, Netherlands
‡TU Berlin, Germany & University of Vienna, Austria
§Université de Lorraine, CNRS Inria, Loria, France
†Aalborg University, Denmark
Abstract—To meet their stringent requirements in terms of
performance and dependability, communication networks should
be “well connected”. While classic connectivity measures typically
revolve around topological properties, e.g., related to cuts, these
measures may not reﬂect well the degree to which a network
is actually dependable. We introduce a more reﬁned measure
for network connectivity, the hazard value, which is developed
to meet the needs of a real network operator. It accounts
for crucial aspects affecting the dependability experienced in
practice, including actual trafﬁc patterns, distribution of failure
probabilities, routing constraints, and alternatives for services
with preferences therein. We analytically show that the hazard
value fulﬁlls several fundamental desirable properties that make
it suitable for comparing different network topologies with one
another, and for reasoning about how to efﬁciently enhance the
robustness of a given network. We also present an optimised
algorithm to compute the hazard value and an experimental
evaluation against networks from the Internet Topology Zoo and
classical datacenter topologies, such as fat trees and BCubes.
This evaluation shows that the algorithm computes the hazard
value within minutes for realistic networks, making it practically
usable for network designers.
metric
Index Terms—network,
fault-tolerance, routing, resilience,
I. INTRODUCTION
Communication networks have become a critical infras-
tructure of our digital society, as also highlighted during the
ongoing pandemic. In order to meet the resulting stringent
dependability and performance requirements, networks should
be “well connected”. However, deﬁning the notion of con-
nectivity is challenging: while classic measures, related to
cuts [26], number of disjoint paths [3], expansion [1], [35], or
even risk management [36], provide interesting insights into
the topological robustness of a network, they do not account
for several additional aspects which matter in practice, and
their usefulness may hence be limited in speciﬁc scenarios.
We identify the following aspects of availability and de-
pendability to be of relevance to network service providers,
and aim to develop a more general notion of connectivity that
takes these aspects into account:
• Trafﬁc patterns. Trafﬁc patterns over a large network are
often skewed in practice. Certain endpoint pairs may need
to communicate much more frequently, or more reliably,
than others. For example, in datacenters, trafﬁc matrices
are often sparse [4], which implies that not all endpoint
pairs are equally important from a connectivity point of
view.
• Distribution of failure probabilities. With the increasing
scale of communication networks, failures are becom-
ing more likely [16]. These failures may either occur
randomly or depend on each other, e.g., in shared risk
link groups [31]. A practical connectivity measure should
hence account for link failures and reﬂect the likelihood
of corresponding failure scenarios and their effect on the
connectivity within the network.
• Routing constraints. Routing paths in networks are often
constrained, for example due to network policies and
business considerations [22], or due to the type of routing
mechanism that is being used. These constraints may
limit the connectivity within a network, even though the
underlying physical network may be highly connected.
• Alternatives for service and preferences therein. Net-
works often come with choice. First, services are typically
offered at multiple places, which is for example leveraged
by DNS anycast; other examples include key-value stores
which allow for replica selection and content distribution
applications [25], [33]. Redundancy may also be offered
in terms of different routes from a given entry point to
a given exit point, in terms of alternative entry and exit
points, or because a client requesting a trafﬁc ﬂow is
connected to multiple nodes. Given such alternatives, net-
work operators and their clients may have a preference for
one alternative over another. Using a different alternative
may inﬂuence the value of the service.
A. Operator’s Distributed Datacenter
As a use case and running example throughout this paper,
we consider a geographically distributed datacenter which we
obtained from our collaboration with a network operator1, see
Figure 1. The network consists of two sites, where each site
relies on a 3-level topology. The two sites (visually separated
via the dashed vertical line) are connected via two wide-
area links (using a Layer-2 network, so services/VMs can
be migrated transparently). In the lowest level of the left
site are the leaf switches li, in the middle level the spine
the top the datacenter edge router c
switches si, and at
1Namely NORDUnet, a network operator in the Nordic countries.
2158-3927/22/$31.00 ©2022 IEEE
DOI 10.1109/DSN53405.2022.00034
239
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:15:13 UTC from IEEE Xplore.  Restrictions apply. 
c
s2
(cid:2)3
s1
(cid:2)2
(cid:2)1
(cid:2)4
(cid:2)
1
(cid:2)
(cid:2)
c
(cid:2)
1
s
(cid:2)
2
(cid:2)
(cid:2)
2
s
(cid:2)
3
(cid:2)
(cid:2)
4
(cid:2)
Figure 1. Use case: geographically distributed datacenter network (two sites)
(henceforth simply called core switch); these switches are
(cid:2) on the right
connected to the corresponding switches l
site. Trafﬁc is usually either datacenter internal, i.e., originates
and terminates at the leaf switches (where the servers are
attached), or external, arriving/leaving through one of the core
switches from/to the Internet.
(cid:2)
i, s
(cid:2)
i, c
The operator is interested in knowing how failures can
affect the services provided by the network. This depends on
a number of parameters. First, connectivity is restricted due to
routing constraints: a typical routing constraint in networks
is to ensure valley freedom, i.e., trafﬁc inside the Layer-2
network could stay on the leaf switch, or be switched on
the spine switch; a packet between two leaf switches will
ﬁrst only travel up the network, up to a certain level, and
afterwards only travel down towards the destination. Second,
the possibility of alternative routes enhances the dependability
of a network. In our example, a leaf may route trafﬁc toward
the Internet through either of the two core switches; hence,
it is sufﬁcient if one of the two core switches is available.
However, network operators may specify preferences among
alternatives; for example, it may be preferable to route trafﬁc
(cid:2) because it is physically
through core switch c instead of c
closer, because it provides a higher bandwidth, because it is
part of a data replication group, or because of legislation or
ﬁnancial concerns. The preference among alternatives can also
be dependent on the demand and actual amount of trafﬁc
arising between endpoints. If there is a signiﬁcant demand
for trafﬁc between leaf pairs on the left site, but hardly any
trafﬁc in the right site, a link failure in the left site can have
more severe consequences than in the right site.
B. Our Contributions
We introduce a novel connectivity metric, the hazard value,
to assess the dependability of a network accounting for all the
above properties. As an input, this metric takes a description
of the network (a directed graph), a description of the routing
constraints (a regular language over sequences of links in the
graph), a probability distribution over possible link failure
scenarios, and a family of service weight functions that model
the preferences between routing alternatives mentioned earlier.
As an output, the hazard value returns the expected percentage
of the total service weight that is lost due to connectivity prob-
lems arising from node or link failures and routing constraints.
A network operator can use the hazard value to compare
different options to fortify a network. By comparing the
hazard value for different network topologies (e.g. adding
redundant links or nodes), routing strategies (e.g. enforcing
valley freedom or not), and measures that inﬂuence failure
probabilities (e.g. choosing more reliable hardware), one can
make quantitative statements about how much a certain fortiﬁ-
cation is expected to improve the dependability of a network.
In order to verify that the hazard value provides a suitable
metric for this purpose, we start out by proving a number of
desirable mathematical properties:
• it is a topological notion, meaning that isomorphic graphs
have equal hazard value;
• it is a compositional notion, in that the hazard value for a
given set of service weights is the same as the weighted
sum of the hazard values for each of the individual service
weights;
• it is monotonically decreasing when introducing addi-
tional links, and monotonically increasing when tighten-
ing the routing restrictions (adding link redundancy or
removing routing restrictions decreases the hazard);
• it is not strictly monotone, as the removal of links or
nodes that are not used to achieve any of the serviced
connections, does not affect the hazard value;
• it increases when independent sources of failure are added
to the failure model;
• and ﬁnally, the hazard value is a generalization of tradi-
tional connectivity, as assuming a non-zero service weight
between all pairs of nodes, and assuming that there is no
probability of failure, leads to a hazard value of 0 if and
only if the network is totally connected.
As a second step in verifying the usefulness of our met-
ric, we perform a number of experiments. We present an
efﬁcient way to compute the hazard value by restricting the
enumeration of failure scenarios to only those cuts that can
disconnect maximally rewarded pairs of nodes, and consider-
ing subsets of those cuts for reﬁnement of the approximation.
Even though we show that already deciding whether the
hazard value is equal to 0 is (in the worst-case) NP-hard, our
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:15:13 UTC from IEEE Xplore.  Restrictions apply. 
240
algorithmic approach renders the hazard value computationally
feasible for realistic scenarios from the Internet Topology Zoo
database [23] as well as some classical datacenter topologies
including fat-tree [6] and BCube [18]. The performance is par-
ticularly good if we consider failure probability distributions