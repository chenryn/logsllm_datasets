### Rolling Upgrade in Software Systems

In a rolling upgrade, a subset of instances running an older version of a software system are taken out of service and replaced with the same number of instances running a new version (T. Dumitras and P. Narasimhan, 2009). This technique is widely used in the industry for transitioning to a new software version (T. Dumitras and P. Narasimhan, 2009). The detailed procedure for Asgard's rolling upgrade operation is illustrated in Figure 11.

### Asgard Rolling Upgrade Error Handling

Asgard's rolling upgrade process involves calling relevant cloud API functions to perform the system upgrade. Table 3 outlines the mapping between each operational step and the corresponding cloud API functions (Asgard, 2013).

**Table 3: Mapping Between Asgard Operational Steps and Cloud APIs**

| Step | Cloud API |
|------|-----------|
| 1. Create New Launch Configuration | `CreateLaunchConfiguration` |
| 2. Update Auto Scaling Group | `UpdateAutoScalingGroup` |
| 3. Set User-Specified Rolling Policy | `PutScalingPolicy`, `UpdateAutoScalingGroup` |
| 4. Deregister Old Instance from ELB | `DeregisterInstancesFromLoadBalancer` |
| 5. Terminate Old Instance | `TerminateInstancesInAutoScalingGroup` |
| 6. Wait for ASG to Start New Instance | `RunInstances` |
| 7. Register New Instance with ELB | `RegisterInstancesWithLoadBalancer` |

Based on empirical studies (Q. Lu et al., 2013; Q. Lu et al., 2014) and considering potential interference from other teams (M. Fu et al., 2014; M. Fu et al., 2016), each step in the rolling upgrade process is prone to errors. Possible errors include:

- **Step 1 (Create New Launch Configuration):** The launch configuration might be deleted by another team.
- **Step 2 (Update Auto Scaling Group):** The auto scaling group's launch configuration might be changed by another team.
- **Step 3 (Set User-Specified Rolling Policy):** The rolling policy might be altered immediately by another team.
- **Step 4 (Deregister Old Instance from ELB):** The old instance may fail to deregister or take too long to deregister.
- **Step 5 (Terminate Old Instance):** The old instance may not terminate or take too long to terminate.
- **Step 6 (Wait for ASG to Start New Instance):** The new instance may fail to launch, enter the pending state, or reach the running state.
- **Step 7 (Register New Instance with ELB):** The new instance may fail to register or take too long to register.

### Asgard's Built-in Error Handling Mechanism

Asgard has a built-in error handling mechanism, but it is limited in its ability to recover from various types of errors and failures (Asgard, 2013; M. Fu, 2014). For some errors, the mechanism simply logs the issue and requires the operator to stop the current operation, exit gracefully, and restart the entire process. The details of Asgard's error handling mechanism are provided in Table 4.

**Table 4: Asgard’s Built-in Error Handling Mechanism**

| Rolling Upgrade Step | Errors | Error Rates | Asgard Error Handling |
|----------------------|--------|-------------|-----------------------|
| Create New Launch Configuration (Step 1) | Launch configuration deleted by another team | 0.6% | Log errors and notify operators |
| Update Auto Scaling Group (Step 2) | Auto scaling group’s launch configuration changed by another team | 0.6% | No action |
| Set User-Specified Rolling Policy (Step 3) | Rolling policy wrongly specified | 0.5% | No action |
| Deregister Old Instance from ELB (Step 4) | Old instance fails to deregister from ELB | 1.5% | No action |
| Terminate Old Instance (Step 5) | Old instance cannot be terminated | 3.9% | Log errors and wait for instances to terminate |
| Wait for ASG to Start New Instance (Step 6) | New instance fails to launch, become pending, or running | 3.1%, 1.7%, 1.9% | Log errors and wait for instances to start, become pending, or running |
| Register New Instance with ELB (Step 7) | New instance cannot be registered into the load balancer | 1.5% | No action |

### Non-Intrusive Recovery vs. Intrusive Recovery

There are three approaches to implementing a recovery method:
1. Without any information from the system.
2. Using routinely provided system information.
3. By modifying the system's source code (M. Fu et al., 2016).

The first two options are termed "non-intrusive recovery" because they do not require code modifications, while the third is "intrusive recovery." Non-intrusive recovery offers several advantages:
- It can handle errors from multiple systems using a wide range of information, such as logs and monitoring data.
- It is independent of programming languages.
- It can be easily turned off if needed.
- It spans multiple tools, making it more feasible in complex environments.

### Research Goals

The primary goal of this PhD research is to propose a non-intrusive and automated recovery methodology for sporadic operations in cloud environments. This method must meet a set of recovery requirements, such as satisfying the Recovery Time Objective (RTO). Existing recovery methods often fall short of these requirements, so a sub-goal is to ensure that the proposed methodology fulfills all the necessary recovery requirements.

### Research Questions

1. What are the requirements for a non-intrusive recovery method for sporadic operations on cloud?
2. How can the non-intrusive recovery method satisfy all the recovery requirements? What should the design of the recovery methodology be?
3. How can we justify that the proposed recovery methodology meets all the recovery requirements?

### Requirements for Non-Intrusive Recovery

Eight recovery requirements for non-intrusive recovery in cloud operations are derived from the literature and practical considerations:
1. **Runtime Recovery:** Recovery should be performed during the execution of the operation.
2. **Recovery Satisfying RTO:** Recovery time should not exceed the specified RTO.
3. **Reducing Negative Impact on Cloud System:** Recovery actions should minimize negative impact on the cloud system.
4. **Reducing Monetary Cost of Recovery:** Recovery should minimize monetary expenses.
5. **Recovery from Errors without Known Causes:** Recovery should be possible even when the cause of the error is unknown.
6. **Dealing with False Positives of Error Detection:** The recovery method should handle false positives.
7. **Recovering for Recovery Itself:** The recovery service should be able to recover from its own failures.
8. **Generalizability:** The recovery method should be applicable to other sporadic operations on cloud.

### Detailed Requirements

- **R1: Runtime Recovery:** Manual recovery typically involves stopping and rolling back the operation. Therefore, recovery should be performed at runtime.
- **R2: Recovery Satisfying RTO:** RTO specifies an upper bound on the time required for a failed step to recover.
- **R3: Reducing Negative Impact on Cloud System:** Recovery actions should minimize adverse effects on the cloud system.
- **R4: Reducing Monetary Cost of Recovery:** Recovery should minimize costs, especially those incurred by launching new instances.
- **R5: Recovery from Errors without Known Causes:** Recovery should be possible even if the error's cause is not known.
- **R6: Dealing with False Positives of Error Detection:** The recovery method should handle false positives detected by the error detection service.
- **R7: Recovering for Recovery Itself:** The recovery service should be robust enough to recover from its own failures.

By addressing these requirements, the proposed non-intrusive recovery methodology aims to provide a fine-grained and effective solution for sporadic operations in cloud environments.