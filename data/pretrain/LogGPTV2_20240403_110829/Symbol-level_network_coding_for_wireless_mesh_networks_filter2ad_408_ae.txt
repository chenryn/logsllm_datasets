### Impact of Mistake Rate

**Figure 13: Impact of Changing the Mistake Rate**
- **Description**: The figure illustrates how different mistake rate thresholds affect throughput. It shows that MIXIT performs well even with suboptimal threshold settings.
- **Method**: We evaluate the impact of the threshold for classifying clean symbols on throughput. As explained in §5, MIXIT can flexibly choose the threshold mistake rate (γ). We vary this threshold and compare the average throughput. For the Zigbee protocol, the PHY symbol is 4 bits long, while the MIXIT symbol size is 6 bytes.
- **Results**: Figure 13 plots the average throughput across all source-destination pairs for different mistake rates. Surprisingly, the average throughput increases as more errors are allowed through, peaking at around a 5% mistake rate. This may seem counterintuitive, but it is because a PHY symbol with a 5% chance of being in error has a 95% chance of being correct. In our topology, at a 5% mistake rate, the cost of correcting errors end-to-end balances the opportunity to exploit correct symbols, maximizing throughput.

The optimal mistake rate threshold depends on the network, and we assume that administrators will calibrate this parameter for their networks. A very high mistake rate, such as 30%, is not practical for any network. However, a wide range of mistake rate choices provides good throughput and outperforms packet-based opportunistic routing.

### Impact of Batch Size

**Figure 14: Impact of Batch Size**
- **Description**: The figure shows the cumulative distribution function (CDF) of the throughput achieved by MIXIT for different batch sizes, indicating that MIXIT is largely insensitive to batch sizes.
- **Method**: We evaluate the sensitivity of MIXIT’s throughput to batch size. Figure 14 plots the throughput for batch sizes of 8, 12, 16, and 32. The throughput is largely insensitive to the batch size, with a slight drop at lower batch sizes due to higher overhead.
- **Results**: A larger batch size allows MIXIT to amortize the overhead over a larger number of packets, increasing throughput. This insensitivity to batch sizes allows MIXIT to adjust the batch size to accommodate different transfer sizes. For transfers larger than 8 packets, MIXIT shows significant advantages. Shorter transfers can be sent using traditional routing.

### Multiple Flows

#### Throughput Comparison

**Figure 15: Average Throughput with Multiple Active Flows**
- **Description**: The figure shows the average throughput for MIXIT, MORE, and SPR with an increasing number of flows. MIXIT’s throughput gain generally increases with load, reaching up to 2.8× over MORE and 3.9× over SPR at its peak.
- **Method**: We run MIXIT, MORE, and SPR in sequence, varying the number of random active flows in the network. The setup is similar to the single-flow case. We run 50 experiments for each choice of the number of flows, with each experiment repeated 5 times, and calculate the average throughput for each run.
- **Results**: Figure 15 plots the average throughput for MIXIT, MORE, and SPR with an increasing number of flows. MIXIT’s throughput scales as the offered load increases until the network is saturated. MORE and SPR perform worse than MIXIT because they cannot exploit concurrency opportunities.

#### Impact of Congestion-Aware Forwarding

**Figure 16: The Role of Congestion-Aware Forwarding**
- **Description**: The figure highlights the importance of congestion-aware forwarding, particularly when the number of active flows is large.
- **Method**: We evaluate the impact of MIXIT’s congestion-aware forwarding component on performance. Node congestion is built into MIXIT’s routing algorithm using the backlog parameter Q(i), which represents the number of symbols queued up at node i yet to be transmitted. Nodes that are backlogged will not be assigned credits by their upstream parents, thus routing traffic around hotspots. We compare this scheme with one where the congestion-aware component is disabled (MIXIT-NCA).
- **Results**: Figure 16 plots the average throughput for MIXIT and MIXIT-NCA for an increasing number of flows. The figure shows that congestion-aware forwarding accounts for 30% of the throughput gain at high load. As load increases, the probability of local hotspots in the network also increases. MIXIT-NCA does not route around these hotspots, leading to lower throughput. MIXIT, on the other hand, adaptively routes around hotspots, increasing overall throughput.

### Conclusion

A key finding of MIXIT is that routers do not need to forward fully correct packets to achieve end-to-end reliability, and loosening this constraint significantly increases network throughput. With MIXIT, as long as each symbol in every transmitted packet is correctly received by some downstream node, the packet is highly likely to be delivered to the destination correctly. Designing a network with this property is challenging because it requires scalable coordination of overlapping symbol receptions and handling erroneous symbol propagation. MIXIT addresses these issues using a symbol-level network code with an end-to-end rateless error correction component.

Instead of relying on link-layer error detection and recovery, MIXIT treats the entire wireless network as a single logical channel, allowing component links to run at high error rates. This approach encourages an aggressive MAC protocol that greatly increases concurrency compared to CSMA. Although MIXIT exploits cross-layer information, its architecture is modular and layered, making it compatible with any radio and PHY that provide suitable confidence hints.

The gains from MIXIT may vary depending on the PHY and MAC used, but it can be applied in any multi-hop wireless network with the following properties:
1. **Computational Capabilities**: The coding/decoding algorithms in MIXIT are more demanding than traditional store-and-forward networks. In our proof-of-concept software implementation on software radios, the algorithms can achieve an effective throughput of up to 4.7 Mb/s. A hardware implementation using shift registers, similar to traditional Reed-Solomon (RS) hardware decoders, can achieve speeds of 80 Gigabits per second, suggesting that computational considerations will not limit the applicability of MIXIT at high data rates.
2. **Memory**: MIXIT’s nodes need to store packets from recent batches. The default batch size is 16, and typically there are two or three batches in flight, requiring storage space of roughly 70 KBytes, a modest amount for modern communication hardware.

MIXIT's ideas may be applicable in sensor networks to ship data to sink nodes, and in multicast data transmission in mesh networks, where all destinations require the same data.

### Acknowledgments

We thank Kyle Jamieson, Szymon Chachulski, and Robert Morris for their insightful comments. This work was supported by DARPA-CBMANET and the National Science Foundation under grants CNS-0627021, CNS-0721702, and CNS-0520032.

### References

[References are listed as provided, with no changes made.]