To support hypervisor-only analysis, we set up the initial fuzzing
inputs in such a way that the testing VM traps into the hypervisor
upon executing the first instruction. However, this cannot be guar-
anteed for new fuzzing inputs after they are mutated. To handle
this case, we use the Monitor Trap Flag (MTF) [32, Chap. 25.5.2]
provided by Intel VMX to force the testing VM to trap into the
hypervisor after executing the first instruction. When HyperFuzzer
detects an MTF VM exit from the testing VM, it simply removes
the fuzzing input from further analysis.
We use AFL [1] for graybox fuzzing and implement whitebox
fuzzing based on NSE. We use the Z3 SMT solver [22] in whitebox
fuzzing to do constraint solving. We implement HyperFuzzer as a
hybrid fuzzer by integrating whitebox fuzzing into the main fuzzing
loop of AFL. The pseudo code is shown in Figure 6. Specifically, we
modify AFL’s code to invoke whitebox fuzzing every time when
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
list interesting_input_queue;
void save_if_interesting(input)
{
coverage = test(input);
if (has_new_coverage(coverage))
interesting_input_queue.push_back(input);
}
void fuzz_one(input)
{
list new_white_inputs = WhiteboxFuzzing(input);
foreach (new_input in new_white_inputs)
save_if_interesting(new_input);
list new_gray_inputs = GrayboxFuzzing(input);
foreach (new_input in new_gray_inputs)
save_if_interesting(new_input);
}
void AFL(init_input_list)
{
foreach (init_input in init_input_list)
save_if_interesting(init_input);
while (true) {
foreach (input in interesting_input_queue)
fuzz_one(input);
}
}
Figure 6: Pseudo code for HyperFuzzer’s hybrid fuzzing.
AFL mutates an “interesting” input that triggers new code coverage.
The whitebox fuzzing runs symbolic execution using NSE on the
given input and generates some new fuzzing inputs. These new
fuzzing inputs are tested, and those that trigger new code coverage
are added into the queue of interesting fuzzing inputs. Note that
AFL initializes this queue by testing all initial fuzzing inputs.
5.2 Hypervisor Tracing
We record the control flow of the hypervisor using Intel PT [32,
Chap. 35]. We modify the Hyper-V hypervisor to enable the control
flow tracing for each virtual CPU. Specifically, we allocate a trace
buffer for each virtual CPU, and instrument the virtual CPU switch
routine to swap the trace buffers when a different virtual CPU is
scheduled onto the physical processor. We do not need to trace the
VM execution in HyperFuzzer, so we resume/pause Intel PT tracing
when the execution enters/leaves the hypervisor. Parsing an Intel
PT trace requires the hypervisor’s code. We retrieve the code pages
from the hypervisor memory dump (cf. Section 4.2.1).
5.3 Nimble Symbolic Execution
We implement NSE for Intel x86 ISA from scratch because exist-
ing symbolic execution engines require full execution traces and
cannot handle unknown values. Our prototype supports common
x86 instructions such as arithmetic, logical, memory access, AVX,
and branch instructions. It also has a basic understanding of other
Session 2A: Fuzzing and Bug Finding CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea371instructions (e.g., what are the source and destination operands)
and implements a default policy for instructions that are not spe-
cially handled (e.g., clear the value and symbolic expression of the
destination operand).
NSE initializes symbolic variables when it detects the hypervisor
accessing the VM state during instruction emulation. The values
of general-purpose registers in the VM fall through to the hypervi-
sor on the trap. Thus NSE simply marks them as symbolic in the
symbolic store and initializes the concrete store with their values
specified in the fuzzing input when starting the symbolic execu-
tion. To access a memory page in the VM, the hypervisor maps
the underlying physical page to its own address space. To handle
such memory accesses, NSE detects the invocation of the memory
mapping function during symbolic execution. Then it marks the
mapped page as symbolic in the symbolic store, and populates the
concrete store with the memory page’s content specified in the
fuzzing input. Finally, we need some special handling for system
registers that are passed by the hardware to the hypervisor through
the Virtual Machine Control Structure (VMCS) [32, Chap. 24]. To
access a field in VMCS, the hypervisor uses the dedicated VMREAD
instruction. NSE emulates this instruction to initialize the symbolic
expression and the concrete value for a system register when it is
accessed by the hypervisor.
NSE captures a memory dump of the hypervisor when it is re-
booted to leverage its internal state in dynamic symbolic execution.
First, NSE uses data stored in read-only memory pages directly
because they are not updated since the memory dump is captured.
Second, NSE uses data from writable pages in a conservative man-
ner. Specifically, NSE maintains a flag to track if a concrete value
or a symbolic expression contains data from writable pages in the
hypervisor memory dump. This has two benefits: it allows NSE
to recover more memory addresses used for input propagation,
and NSE can use the flag to ignore path constraints that contain
dynamic values from the hypervisor dump (see Section 4.2.1).
6 EVALUATION
In this section, we present our experimental results with Hyper-
Fuzzer. For evaluation purposes, we implement a baseline system
based on the Bochs emulator [3] that can collect full execution
traces of the hypervisor including both its control and data flows.
When running our experiments, we aim to answer the following
questions.
(1) Efficiency (§6.2):
• Run time (§6.2.1): How long does it take to run a single
• Throughput (§6.2.2): What is HyperFuzzer’s fuzzing through-
test?
put?
(2) Precision (§6.3):
• Completeness (§6.3.1): What fraction of input-dependent
• Divergences (§6.3.2): What fraction of inputs generated
conditional branches can NSE identify?
by NSE can correctly flip their targeted branches?
(3) Coverage (§6.4): How is HyperFuzzer’s code coverage com-
pared with graybox-only or whitebox-only fuzzing?
(4) Bugs (§6.5): Can HyperFuzzer find previously unknown vir-
tual CPU bugs in the Hyper-V hypervisor?
Hypercalls
Task Switch
APIC Emu.
MSR Emu.
Initial Expanded
1091
186
521
476
157
5
56
2
Table 3: The number of fuzzing inputs in the initial and ex-
panded fuzzing sets for different virtualization interfaces.
In the rest of this section, we first present our experimental
methodology, and then describe our experimental results in detail.
6.1 Experimental Methodology
6.1.1 Experiment Setup. We run all experiments on a workstation
with a quad-core Intel i7-6700K processor and 16GB RAM. We focus
our experiments on four virtualization interfaces: hypercalls, hard-
ware task switch [32, Chap. 7] emulation, advanced programmable
interrupt controller (APIC) emulation, and model-specific register
(MSR) emulation. We pick these interfaces because they either have
a big attack surface (e.g., hypercalls) or previously-reported bugs
(e.g., Task Switch). We do not cover all virtualization interfaces due
to the manual efforts required for understanding and constructing
initial fuzzing inputs for these.
We manually create a number of initial fuzzing inputs [12] for
Task Switch, APIC and MSR based on Intel Software Developer
Manual [32]. For instance, we have one fuzzing input for reading
and the other for writing an MSR. For hypercalls, we generate a
single initial fuzzing input for each hypercall API. Specifically, we
leverage an existing tool [5] to randomly generate parameters based
on the parameter’s type.
Our evaluation requires a large number of fuzzing inputs to
conduct the experiments. We run HyperFuzzer on the initial seed
fuzzing inputs for 120 minutes to generate a new set of fuzzing
inputs. In this new set, some inputs are generated by whitebox
symbolic executions, and others are generated by graybox random
mutations. We then keep all the new inputs that triggered new
code coverage, and discard others. We refer to the remaining set as
the expanded fuzzing set (see Table 3). Note that we divide fuzzing
inputs in the expanded fuzzing set based on the virtualization in-
terface it exercises for the purpose of evaluation. In practice, we
do not need to differentiate what virtualization interface a fuzzing
input exercises.
As described in §5.1, we implement HyperFuzzer by integrat-
ing the symbolic execution-based input generation into the main
fuzzing loop of AFL [1] that performs coverage-guided random
mutation. In the rest of this section, hybrid fuzzing refers to this
implementation, graybox fuzzing includes only AFL’s coverage-
guided random mutation, and whitebox fuzzing includes only the
symbolic-execution-based input generation.
6.1.2 Bochs-Based Baseline. We implement a baseline system based
on the Bochs emulator [3] for our experiments. We use this baseline
system to demonstrate HyperFuzzer’s performance improvement
(§6.2), and to provide the ground truth for evaluating NSE’s effec-
tiveness when only given a control-flow trace (§6.3). As shown
Session 2A: Fuzzing and Bug Finding CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea372Testing
HyperFuzzer
NSE
781.89
457.83
212.66
387.51
0.48
0.33
0.36
0.36
Bochs-Based Baseline
Testing
Triton [43]
683.73
690.94
696.31
687.87
4861.84
3499.39
2074.09
1871.94
Hypercalls
Task Switch
APIC Emu.
MSR Emu.
Table 4: The efficiency comparison between HyperFuzzer
and Bochs-based baseline system in performing a single test
and symbolic execution. Numbers in this table are in mil-
liseconds.
Hypercalls
Task Switch
APIC Emu.
MSR Emu.
Hybrid Graybox Whitebox
979.40
1369.95
1774.05
1171.24
2945.03
4378.22
3650.68
3967.35
35.63
106.88
210.85
76.67
Table 5: The throughput (# tests/sec) of hybrid, graybox and
whitebox fuzzing.
Input-Dep Branches New Inputs
Hypercalls
Task Switch
APIC Emu.
MSR Emu.
98.1%
98.8%
98.2%
98.3%
96.8%
98.9%
99.2%
99.2%
Table 6: The completeness evaluation of NSE. The percent-
ages listed are the fraction of input-dependent conditional
branches and new fuzzing inputs identified/generated by
NSE (based on the control flow and fuzzing input) compared
to the baseline set (based on full execution traces).
average run time for a single symbolic execution is between 212ms
and 782ms, while the baseline system is 4 to 10 times slower. The
ratio difference changes because both systems spend a significant
amount of time on constraint solving. However, HyperFuzzer is
still more efficient than the baseline system. We attribute this to
the implementation differences between the two systems.
6.2.2 Throughput. We evaluate HyperFuzzer’s throughput by run-
ning hybrid, graybox and whitebox fuzzing on the initial fuzzing
inputs for 120 minutes and reporting the average number of tests
per second in Table 5. We can see that hybrid fuzzing can run 1000’s
of tests per second, and graybox fuzzing’s throughput is 2 to 3 times
higher than that. The reported throughput for whitebox fuzzing is
higher than the number calculated based on the average run time of
symbolic execution. This is because not every tested fuzzing input
is passed to the symbolic execution in the allotted time (120 min-
utes). HyperFuzzer’s fuzzing throughput is 3 orders of magnitude
higher than the baseline system because only a small fraction of
fuzzing inputs that trigger new code coverage are tested with NSE.
Figure 7: The architecture of the Bochs-based baseline.
in Figure 7, we run the Hyper-V hypervisor inside Bochs and instru-
ment Bochs to enable dynamic symbolic execution for the hypervi-
sor. We choose Bochs because it emulates Intel’s modern hardware
virtualization extension (VMX) with high fidelity while other hard-
ware emulators (e.g., QEMU) either do not emulate VMX at all or in