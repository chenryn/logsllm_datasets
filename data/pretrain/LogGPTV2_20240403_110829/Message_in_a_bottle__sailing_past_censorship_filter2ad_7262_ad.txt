approach is vulnerable to a denial of service attack: Bob could
forge bogus pings claiming to be any arbitrary domain (blog
pings, just like emails, do not authenticate the sender), forcing
the Censor to add it to the blacklist. Iterating this attack, Bob
can de facto render the blacklist useless. To counter this, the
Censor will have to maintain a whitelist of allowed domains. This
is harmful to the regime, because of the social and economic costs
of over-blocking, and can be easily circumvented (as we discussed
in Section 5.1).
The Censor might want to block pings, or shut down ping
servers. This attack is irrelevant when the blog (or ping server) is
hosted outside the Censor’s jurisdiction.
The Censor might try to prevent Alice to post on any blog.
This requires both the ability to fingerprint a blog, and the
technological power to deeply inspect the network traffic to detect
and block posting. The cost of this attack increases as Alice
will most likely be using a TLS connection (i.e., https://) to
make the post, requiring the Censor to either man-in-the-middle
the connection or perform statistical timing attacks. Also, Alice
can create a post in a variety of ways, for example using client
applications or by email (as many blogging platforms support
that). The Censor therefore has to block all these vectors.
The Censor might try to coerce content hosts to drop miab
content. However, to do so, he needs to identify such content
(when deniability should prevent him from doing so). Also, the
Censor has to drop the content fast: Bob will fetch the blog after
just a few minutes, since blog pings are sent in real time.
The Censor might try to overwhelm miab by creating large
quantities of bogus messages. Bob should be able to provide a fair
service to its users by rate limiting blogs, and ban them when
they exhibit abusive behavior. Since Bob will first inspect the list
of pings, he will avoid fetching blogs that are over their quota or
blacklisted. Also, search engines will fetch the same blog pings
and will analyze and index their content. Since the Censor, to
create a large number of blog posts, will have to either generate
the content automatically or replay content, search engines should
detect his behavior and mark it as spam. Blog ping spam (or
sping) is already a problem that search engines are facing, since
pings are used in Search Engine Optimization campaigns. Because
of this, much research has been invested into detecting this type
of behavior. Bob could leverage that research by querying the
search engine for the reputation of blog or blog posts. Using
a combination of blacklists, rate limitation, and search engines
reputation systems, Bob is likely to thwart this attack.
The Censor might perform traffic analysis to distinguish regular
blog posts from miab ones. However, since the blog post is created
by a human, this is unlikely to be successful.
The Censor might re-encode images to remove any stegano-
graphic content. Since the censor cannot find all the entry points
Figure 4: Estimating the blacklist size, when target-
ing second-level domain names, fully-qualified domain
names, and IP addresses.
Bypassing the blacklist. These blacklists are cumbersome
in size. For example, according to Netcraft, during the time of our
experiment, there were 662, 959, 946 FQDNs running web servers
on the Internet [41]. In our experiment, we would have blacklisted
33, 361, 754 FQDNs, which is 5% of the ones found by Netcraft.
Blocking second level domains is also not practical.
In our
experiment, we blacklisted 1, 803, 345 of them, which account for
1.4% of the global domain registrations (which are 140, 035, 323,
according to DomainTools [18]). Note that our blacklists only
cover blogs that sent pings during our experiment. To better
quantify this, we checked the (hypothetical) blacklists’ coverage
on the pings that were emitted the day after we stopped updating
the blacklists. We found that the blacklist targeting FQDNs had
12% miss ratio, the one targeting second level domains had 11%
miss ratio, and the one targeting IP addresses had 11% miss ratio.
Even if the Censor chooses to pay the price of over-blocking
and enforces these blacklists, Bob and Alice can still communicate
through miab, thanks to a weakness in this blacklisting approach.
Bloggers usually associate multiple domain names/IP addresses
to their blog: on blogger.com, this is configurable in the “Basic
Settings” admin page. These domain names constitute the entry
points to the blog. Blog pings contain only one of these entry
points. Bob only needs one of these entry points to visit the blog.
Instead, the Censor needs each one of the entry points, because
he wants to prevent Alice from accessing her blog. So, Alice can
side-step the blacklist using an entry point not included in her
blog’s pings, which the Censor cannot easily discover.
6. SECURITY ANALYSIS
In this section, we discuss miab’s resilience against the attacks
that the Censor might mount to break the security properties
that miab guarantees: availability, deniability, and confidentiality.
Since we lack a formal verification of the security of the stegano-
graphic primitives, and the powers of a real Censor are unknown,
these goals are necessarily best effort.
Availability. The Censor might prevent Alice from sending
messages through miab. Our main argument against this is that
the Censor will be forced to ban a large part of the web, and
he is likely unwilling to do so because of the pushback from its
population and economic drawbacks. We will now describe in
more detail the attacks that the Censor might devise to limit
availability. For this discussion, we assume that deniability holds:
In particular, the Censor cannot detect content generated with
miab.
The Censor could block blogging platforms. In fact, this has
already been attempted: Kazakhstan has been banning blogging
platforms and social networks since 2008 [35]. In 2011, a court
established they contributed to the spread of religious terror-
to the blogs, he must re-encode every image crossing his country’s
borders (not only blogs). Moreover, miab can easily evolve and
hide the ciphertext in other parts of the post (e.g., in the text), or
use a steganographic system that can withstand re-encoding (see
also Section 3.2). For example, a technique to do so is used in the
shared-key steganographic scheme YASS [50], which can survive
a second compression, additive noise, and light filtering. The
steganographic primitive and channel (images, videos, or text)
can be chosen at will, and should be selected when deploying
miab, considering the particular Censor faced.
Unobtrusive deployment. With our proof-of-concept ap-
plication, we have demonstrated that it is possible to run a miab
instance on a single modern machine with a fast domestic In-
ternet connection. We recommend a 100Mbps connection, such
as the one provided by Comcast in the US, also considering the
fluctuations in the speed achievable at rush hours. Therefore,
any private citizen with some disposable income, and living in a
country with a modern offering for Internet connectivity, can run
a miab instance. Moreover, this burden is sustained only by Bob;
Alice has minimal requirements to participate in the protocol.
Deniability. The Censor might try to identify who is using
miab, thus compromising deniability.
The Censor might try to detect steganography. miab uses
steganography as a primitive, so its deniability relies on a good
steganographic algorithm, and will benefit from any advancement
in steganography. Also, the Censor will need to detect stegano-
graphic content with a very low fraction of false positives, because
of the vast prevalence of clean image in blog posts. For more
details, see in Section 3.2.
The Censor might try to detect anomalous blogging behavior.
Since Alice manually publishes the post, it will be difficult to
detect anomalous behavior in a single post (provided that the
message that Alice composes is innocuous). However, the Censor
might detect an anomaly if the posting frequency is higher than
the other blogs hosted on the same platform. Alice can mitigate
this risk by keeping under control her post rate. Also, Alice
can use a blogging platform that encourages frequent posts with
photos (e.g., a photoblog, like Instagram). Alice might also have
multiple online personas, each of which posts on a different blog.
The Censor might try to run an instance of miab to trick Alice
into communicating with him. This is a limitation common to any
system that relies on a public key to identify the receiving party.
This is mitigated by publishing Bob’s public key in a variety of
formats on the Internet, so that the Censor cannot find them and
block or alter them.
The Censor might try to perform a timing attack, correlating
the effect of the action specified in the miab message (in our
implementation, the posting of a new tweet) with the publishing of
a new post. We can mitigate this by letting the miab user specify
when he wants the aforementioned action to be taken, inserting
random delays and generating decoys (in our implementation,
tweeting a message that was not received).
The Censor might try to perform a replay attack. Let’s suppose
that the Censor suspects that Alice used miab to post a message M
to Twitter. To confirm his suspects, the Censor would collect blog
posts from Alice, and publish the same posts on a blog platform
under his control. If the same message M is tweeted when the
posts are re-published, the Censor’s suspicion is probably correct.
The Censor can repeat the process to rule out any remaining
doubt. Replay attacks can be thwarted by including a hash of
the URL of the blog post in the message. After receiving the
message, Bob will check that the hashed URL in the message
matches with the one of the post, and will discard the message if
the check fails. Also, Bob could keep a hash of the photo in a
Bloom filter, to avoid reuse.
Confidentiality. To break confidentiality, the Censor must get
access to the plaintext of the message that Alice sent. The message
is encrypted with a public key, of which only Bob knows the
private counterpart. Assuming that the cryptographic primitive
is secure, the Censor will not be able to read the message. Also,
the Censor might run an instance of miab to trick Alice, as we
discussed in the previous section.
7. RELATED WORK
There has been an extensive and ongoing discussion on anony-
mous and censorship-resistant communication. In this section,
we review the main directions of research, highlighting how they
measure against the goals that we have set for miab.
Anonymization proxies. The most established way to achieve
online anonymity is through proxies, possibly with encrypted
traffic [3,37]. In 2010, a report from Harvard’s Center for Internet
& Society [44] shows that 7 of the 11 tools with at least 250,000
unique monthly users are simple web proxies.
These systems focus on hiding the user identities from the
websites they are surfing to. They have a low latency, which
makes web surfing possible (which miab does not). In doing
so, they do not satisfy any of the goals of miab: They can be
blocked, since it is possible to discover the addresses of the proxies
and block them (low availability). Also, even if the traffic is
encrypted, the users cannot deny that they were using the system
(no deniability), and it is possible to mount fingerprinting and
timing attacks to peek into the users’ activity [10, 33].
One of the first systems that address deniability is Infranet [20].
Uncensored websites deploying Infranet would discreetly offer
censored content upon receiving HTTP traffic with steganographic
content. Availability is still an issue, since the Censor might
discover and block these websites, so the collaboration of a large
number of uncensored websites becomes essential.
Mix/onion networks. Mix networks (e.g., Mixminion [15]),
and Onion networks (e.g., Tor [17]), focus on anonymity and
unlinkability, offering a network of machines through which users
can establish a multi-hop encrypted tunnel. They also typically
have a low latency, which makes web surfing possible (in contrast
with miab). In some cases, depending on the location of the
proxies with respect to the Censor, it is possible to link sender and
receiver [7,40]. These systems do not typically provide deniability,
although Tor tries to mask its traffic as an SSL connection [55].
The availability of these systems depends on the difficulty to
enumerate their entry points, and their resistance to flooding [19].
Protecting the entry nodes has proven to be an arms race: For
example, the original implementation of Tor provided a publicly-
accessible list of addresses. These entry points were blocked in
China in 2009 [56]. In response, Tor has implemented bridges [52],
which is a variation on Feamster’s key-space hopping [21]. However,
these bridges have some limitations that can expose the address
of a bridge operator when he is visiting websites through Tor [38].
Also, distributing the bridges’ addresses without exposing them
to the Censor is theoretically impossible (since the Censor could
play Alice’s role, and Tor cannot distinguish one from the other).
However, it might be possible to increase the cost of discovering a
bridge so much that the Censor finds it impractical to enumerate
them. This problem remains very complex and, so far, none of
the approaches attempted has succeeded: Proof of this is the fact
that China has been blocking the vast majority of bridges since
2010, as the metrics published by Tor show [57].
An interesting variation on proxy-based censorship circumven-
tion is described in Fifield et al. [22]. Here, a group of Internet
users run an Adobe Flash application in their web browser. This
application creates a short-lived proxy (in their implementation,
the proxy is for the Tor network), so that these users can con-
tribute a part of their bandwidth to the network. These ephemeral
web proxies lower the barrier to set up a Tor proxy, and their
short lives make their enumeration more cumbersome. However,
a central part of this system is a special service, called the Facili-
tator, whose job is to keep track and distribute proxy addresses.
By sniffing the Facilitator’s traffic, the Censor can learn the
proxy addresses, as they get requested from the clients. The
authors point out that, once the system gets popular, keeping
a blacklist might be cumbersome, because of the sheer number
of available proxies. Also, as the author point out, the Censor
might flood proxy registrations, and exhaust the list of proxies
that the Facilitator keeps. This, also, might be mitigated by sheer
numbers, as the authors point out.
Anonymous publishing. Here, the focus is on publishing
and browsing content anonymously. Freenet [13] and Publius [60]
explore the use of peer-to-peer networks for anonymous publishing.
These systems deliver anonymity and unlinkability, but do not
provide deniability or availability, as the Censor can see where
the user is connecting, and block him. Another direction that is
being explored is to make it difficult for the Censor to remove
content without affecting legitimate content (Tangler [59]). This