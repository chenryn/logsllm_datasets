Session 7A: Privacy Attacks and Defenses for ML CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2152convergence to present the intuition behind our proposed gradi-
ent compression and aggregation algorithm TopAgg. Note that, as
directly analyzing the convergence of GAN is technically challeng-
ing [40] and beyond the scope of this paper, we focus on an abstract
model in which each teacher provides an unbiased gradient estima-
tor for SGD with loss function 𝐹𝑛(𝑥) given input 𝑥. We believe that
this is a plausible assumption since in our setting each teacher has
access to a random non-overlapped partition of the input data.
Understanding the convergence behavior of stochastic gradi-
ent descent in the context of differential privacy is a challenging
problem. At the first glance, the DP noise might look like just an-
other variance term over the stochastic gradient; however, it is
the other operations such as the normalization and clipping of
gradients that make the analysis much harder. In fact, it is not
until recently [15, 45, 53] that researchers developed some results
to analyze the behavior of DP-SGD with gradient norm clipping
(often limited to scaling 𝐿2 norm instead of truncating). In our con-
text, this problem becomes even more challenging, as we need to
consider not only element-wise gradient clipping, but also top-𝐾
compression, an operator that introduces bias, instead of variance
to our gradient estimator.
Setup and Assumptions. We focus on the following setting in
𝑛∈[𝑁 ] 𝐹𝑛(𝑥) over R𝑑.
𝑛(𝑥𝑡)), 𝑐), 𝜉𝑡) + N(0, 𝐴𝑘)(cid:1) , (2)
𝑁
which our goal is to minimize 𝑓 (𝑥) = 1
Recall that the update rule is
𝑥𝑡+1 = 𝑥𝑡 − 𝛾
𝑁
(cid:0)𝑄(clip(top-k(𝐹′

𝑛∈[𝑁 ]
for some constant 𝐴 > 0 and a clipping constant 𝑐 > 0, with clipping
performed coordinate-wise. Here we rephrased the stochastic sign
quantization using 𝑄(𝑥, 𝜉) = 𝜉(𝑥), when 𝑥 ≥ 0, and 𝑄(𝑥, 𝜉) =
−𝜉(−𝑥), when 𝑥  0 such that 1
𝑁
Furthermore, we assume bounded stochastic variance per coor-
dinate, meaning that for every 𝑖 ∈ [𝑑] there exists 𝜎𝑖 > 0 such
𝑖 , for all 𝑥 ∈ R𝑑. With re-
that 1
𝑁
spect to compression, we see that 𝑄 is unbiased in our case, i.e.
E𝜉 [𝑄(𝑥, 𝜉)] = 𝑥, for all 𝑥, and of bounded variance, i.e. E𝜉 [∥𝑄(𝑥, 𝜉)
−𝑥∥2(cid:3) ≤ ˜𝜎2, for some ˜𝜎 > 0, and all 𝑥. Finally, with respect to
𝑛(𝑥)(cid:13)(cid:13)2 ≤ 𝑀2.
𝑛∈[𝑁 ] |𝐹 ′
𝑛(𝑥) − ∇𝑓 (𝑥)|2 ≤ 𝜎2
top-k, we assume (see [5]) that there exists a non-increasing se-
quence 1 ≥ 𝜏1 ≥ . . . ≥ 𝜏𝑑 = 0, such that for all 𝑘 ∈ [𝑑] and all
𝑥 ∈ R𝑑, one has ∥𝐹 ′
𝑛(𝑥)∥. Given these
assumptions, we have the following result:
𝑛(𝑥)−top-k(𝐹 ′
𝑛(𝑥))∥ ≤ 𝜏𝑘∥𝐹 ′
Theorem 6. (Convergence of top-𝑘 Mechanism with/without Gradi-
ent Quantization) Suppose that the above assumptions hold, and let
𝑘 ∈ [𝑑]. Then after 𝑇 updates using the learning rate 𝛾, one has
(cid:18) min{𝑐, 1}
𝑑 + 2
(cid:19) 1
𝑇

𝑡∈[𝑇 ]
min{E∥∇𝑓 (𝑥𝑡) ∥2, E∥∇𝑓 (𝑥𝑡) ∥1}
≤ min{𝜏𝑘 𝑀2, 𝑐(𝑑 − 𝑘)𝑀} + 𝐿𝛾𝐴𝑘 + (𝑓 (𝑥0) − 𝑓 (𝑥∗))/(𝑇𝛾)
+ max{∥𝜎 ∥2 + ∥𝜎 ∥𝑀, 2∥𝜎 ∥1} + 2𝐿𝛾 ( ˜𝜎2 + min{𝑐2, 𝑀2}).
(3)
Moreover, if no quantization is used, i.e. 𝑄(𝑥, 𝜉) = 𝑥 for all x, then
one can improve the last term to 𝐿𝛾 min{𝑐2, 𝑀2}.
𝑛(𝑥)𝑖, 𝑐) = 𝑐 · sign(𝐹′
Proof Sketch. The full proof is given in Appendix D, whereas
here we explain main ingredients. Intuitively, clipping gradients
yields a dichotomy between gradient performing as the usual gra-
dient descent versus the signed gradient descent (as in [9]) of mag-
nitude 𝑐. We start with a well-known fact that 𝑓 having 𝐿-Lipschitz
gradients implies 𝑓 (𝑥𝑡+1) − 𝑓 (𝑥𝑡) ≤ ⟨∇𝑓 (𝑥𝑡), 𝑥𝑡+1 − 𝑥𝑡⟩ + 𝐿
2 ∥𝑥𝑡+1 −
𝑥𝑡 ∥2, which allows one to look at the convergence rate step by step.
Upon inserting the update rule (2), we split the argument into two
cases based on, for 𝑖 ∈ [𝑑] and 𝐴𝑖 := {𝑛 ∈ [𝑁 ] : |𝐹′
𝑛(𝑥) | ≥ 𝑐},
𝑛(𝑥)𝑖) · 1{𝑛 ∈ 𝐴𝑖 } + 𝐹′
clip(𝐹′
𝑛(𝑥) · 1{𝑛 ∉ 𝐴𝑖 }.
Using a proof by contradiction, we show that the error terms cannot
beat the main term for clipped and non-clipped gradients simulta-
neously. In doing so, the error terms on the RHS of (3) originate
from the following: min{𝜏𝑘 𝑀2, 𝑐(𝑑 − 𝑘)𝑀} comes from applying
the top-𝑘 mechanism on top of clipped gradients, 2𝐿𝛾𝐴𝑘 originates
from the variance of the noise attributed to differential privacy,
𝑓0,∗/𝑇𝛾 comes from the telescoping property when summing over
all steps. The term max{∥𝜎∥2 + ∥𝜎∥𝑀, 2∥𝜎∥1} comes from the clip-
ping dichotomy (also contributing to the term min{𝑐, 1} on the LHS),
whereas 2𝐿𝛾( ˜𝜎2 +min{𝑐2, 𝑀2}) is the variance of quantization step.
The without quantization case follows the similar approach, up to
the non-existence of randomness in the quantization case, yielding
a simpler proof.
Discussion: Why Does Top-K Help? The above result depicts
the following tradeoff. As 𝑘 gets smaller the error caused by top-𝑘
quantization gets larger, leading to two effects:
(1) The term min{𝜏𝑘 𝑀2, 𝑐(𝑑 − 𝑘)𝑀}, introduced through the
bias of top-𝑘 compression, gets larger;
(2) The 2𝐿𝛾𝐴𝑘 term, introduced by the differential privacy noise,
however, gets smaller.
Given a finite number of iterations 𝑇 , in the worst case the bias
introduced through the term 𝜏𝑘 dominates when the gradients
are evenly distributed over coordinates, yielding that the top-𝑘
compression can significantly slow down the convergence rate in
the worst case. However, previous works [5, 57] empirically verify
that under certain real distribution of gradient dimensions, the top-
𝑘 compression does not introduce a large bias, yielding justification
for top-𝑘 compression, especially when the original dimension 𝑑 is
of very high dimension. For example, if we assume that the gradient
follows the Weibull distribution 𝑊 (𝜌1, 𝜌2), for some 𝜌1 > 0 and 0 <
𝜌2 < 1, following recent work in gradient compression [18], then 𝜏𝑘
are, on expectation, distributed as 𝜏𝑘 ∝ exp (−(𝑘/𝜌1𝑑)𝜌2)−exp(−1),
which for small 𝜌2 grows significantly slower than the contribution
of the noise due to differential privacy (linear in 𝑘) decreases, as
𝑘 decreases. Thus, the convergence-privacy tradeoff for algorithm
TopAgg can be clearly characterized. It is obvious that given the
convergence guarantee, the compression step could save the privacy
budget and therefore improve the utility (i.e. smaller DP noise is
Session 7A: Privacy Attacks and Defenses for ML CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2153added) for training on high-dimensional data, as long as the chosen
𝑘 is not too small.
4.4 Discussion: TopAgg for SGD Training
In addition to the DP generative model, the proposed DP gradient
compression and aggregation algorithm TopAgg, which is a key
building block of DataLens, is also generalizable for the standard
DP SGD training by applying the gradient compression and aggre-
gation in the DP SGD training process. However, since the DP SGD
algorithm has already achieved high data utility, the improvement
with TopAgg is empirically marginal, and we will defer the details
on how to adapt TopAgg to training a differentially private deep
neural network and the corresponding evaluation in Appendix A.
5 EXPERIMENTAL EVALUATION
In this section, we present the experimental evaluation of DataL-
ens for generating differentially private data with high utility. We
compare DataLens with state-of-the-art differentially private gen-
erative models and evaluate the data utility and visual quality on
high-dimensional image data such as CelebA face and Places365 to
demonstrate the effectiveness and scalability of DataLens.
5.1 Experimental Setup
We compare the generated data utility of DataLens with three state-
of-the-art baselines: DP-GAN [59], PATE-GAN [62], GS-WGAN [13],
and G-PATE [37] on four image datasets.
Datasets. To demonstrate the advantage of DataLens as be-
ing able to generate high dimensional differentially private data, we
focuse on high dimensional image datasets, including MNIST [30],
Fashion-MNIST [58], CelebA datasets [36], and Places365 dataset [65].
MNIST and Fashion-MNIST dataset contain grayscale images of
28 × 28 dimensions. Both datsets have 60,000 training examples
and 10,000 testing examples. The CelebA dataset contains 202,599
color images of celebrity faces. We use the official preprocessed
version with face alignment and resize the images to 64 × 64 × 3.
Places365 dataset is consisted of 1.8M high resolution color im-
ages of diverse scene categories. We select three level-2 classes to
compose a dataset of size 120,000 and resize the images to 64×64×3.
We create two CelebA datasets based on different attributes:
CelebA-Gender is a binary classification dataset with gender as
the label, while CelebA-Hair uses three hair color attributes (black/
blonde/ brown) as classification labels. The training and testing set
is split following the official partition as [36]. Since DP-GAN and
PATE-GAN did not evaluate their framework on high dimensional
image datasets, we run their open-source code and compare with
the proposed DataLens framework.
Models. Both the teacher discriminator and the student gen-
erator of DataLens uses the same architecture as DC-GAN [47].
The latent variables sampled from Gaussian distribution are 50-
dimensional for MNIST, 50-dimensional (𝜀 = 1) and 64-dimensional
(𝜀 = 10) for Fashion-MNIST, 100-dimensional for CelebA datasets,
and 100-dimensional for Places365. For 𝜀 = 1, we set top-𝑘=200 for
MNIST and Fashion-MNIST, top-𝑘=700 for CelebA and Places365.
For 𝜀 = 10, we set top-𝑘=350 for MNIST and Fashion-MNIST, top-
𝑘=500 for CelebA, and top-𝑘=700 for Places365. Ablation studies
and discussions on comprehensive hyper-parameter analysis can
be found in Section 5.3.
Baselines.
For baseline models, DP-GAN uses standard WGAN
and adds Gaussian noise on the gradients during training to achieve
differential privacy. Both PATE-GAN and G-Pate leverage PATE
framework to generate differentially private images based on differ-
ent teacher aggregation strategies. Since DP-GAN and PATE-GAN
did not evaluate or report their frameworks on (high-dimensional)
image datasets, we run their open-source code of DP-GAN1 and
PATE-GAN2 and compare with our DataLens framework. For GS-
WGAN, we use its open-source implementation3 to train DP gener-
ative models. For large 𝜀 = 10, we can reproduce the performance
on MNIST and Fashion-MNIST. Under small 𝜀 = 1 setting, we tried
our best to tune the hyper-parameters of GS-WGAN; however, we
observe GS-WGAN is unable to converge given the limited privacy
constraints, especially when presented with higher-dimensional
data (CelebA, Places365) which is confirmed with the authors.
Evaluation Metrics. We follow standard evaluation pipelines
[13, 37, 62] and evaluate DataLens as well as baselines in terms of
data utility and visual quality under different privacy constraints.
Specifically, data utility is evaluated by training a classifier with
the generated data and testing the classifier on real test dataset.
We consider the testing accuracy on the test set as the indicator for
the utility of the synthetic data for downstream tasks. To evaluate
the visual quality of generated data for understanding purpose,
we consider Inception Score (IS) [31] and Frechet Inception Distance
(FID) [50], which are standard metrics of visual quality in GAN
literature. We also provide the images generated by DataLens in
Appendix Figure 4 for visualization.
5.2 Experimental Results
In this section, we evaluate DataLens on different datasets. We first
compare the generated data utility for DataLens and four other
state of the art DP generative model baselines. We then explore
the performance of DataLens under limited privacy budgets (i.e.,
𝜖 < 1), which is a challenging while important scenario. We then
evaluate the visual quality of the generated data, followed by a range
of ablation studies on the data-dependent and data-independent
privacy analysis, impacts of different hyper-parameters and com-
ponents in DataLens, as well as different compression methods.
We show that the proposed DataLens not only outperforms all
baselines, but also demonstrates additional advantages especially
when the privacy budget is small.
Data Utility Evaluation. We first compare DataLens with
four baselines under two privacy budget settings 𝜀 = 1, 𝛿 = 10−5
and 𝜀 = 10, 𝛿 = 10−5 on five high dimensional image datasets,
following the standard evaluation pipeline.
From Table 1, we can see that DataLens shows substantially
higher performance than all baseline methods especially when
𝜀 = 1. In particular, the performance improvement on MNIST under
𝜀 = 1 is more than 13%. Even for high dimensional datasets like
CelebA-Hair and Places365 whose dimensionality is 16 times larger
than MNIST, DataLens achieves 10% higher performance improve-
ment than the state of the art, which demonstrates its advantages
1Code at https://github.com/illidanlab/dpgan
2Code at https://bitbucket.org/mvdschaar/mlforhealthlabpub/src/master/alg/pategan/
3Code at https://github.com/DingfanChen/GS-WGAN
Session 7A: Privacy Attacks and Defenses for ML CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2154Table 1: Performance of different differentially private data generative models on Image Datasets: Classification accuracy of the model
trained on the generated data and tested on real test data under different 𝜀 (𝛿 = 10−5).
Methods DC-GAN (𝜀 = ∞)
𝜀
DP-GAN PATE-GAN G-PATE GS-WGAN DataLens
Dataset
MNIST
Fashion-MNIST
CelebA-Gender
CelebA-Hair
Places365
0.9653
0.8032
0.8149
0.7678
0.7404
𝜀 = 1
𝜀 = 10
𝜀 = 1
𝜀 = 10
𝜀 = 1
𝜀 = 10
𝜀 = 1
𝜀 = 10
𝜀 = 1
𝜀 = 10
0.4036
0.8011
0.1053
0.6098
0.5330
0.5211
0.3447
0.3920
0.3200
0.3292
0.4168
0.6667
0.4222
0.6218
0.6068
0.6535