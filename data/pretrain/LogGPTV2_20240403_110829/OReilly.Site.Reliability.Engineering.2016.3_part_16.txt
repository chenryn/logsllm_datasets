are unavailable.
4 Many non-SRE teams use a generator to stamp out the initial boilerplate and ongoing updates, and find the
generator much easier to use (though less powerful) than directly editing the rules.
5 Many other applications use their service protocol to export their internal state, as well. OpenLDAP exports it
through the cn=Monitor subtree; MySQL can report state with a SHOW VARIABLES query; Apache has its
mod_status handler.
6 https://golang.org/pkg/expvar/
7 The Borg Name System (BNS) is described in Chapter 2.
110 | Chapter 10: Practical Alerting from Time-Series Data
It’s interesting that varz is quite dissimilar to SNMP (Simple Networking Monitoring
Protocol), which “is designed […] to have minimal transport requirements and to
continue working when most other network applications fail” [Mic03]. Scraping tar‐
gets over HTTP seems to be at odds with this design principle; however, experience
shows that this is rarely an issue.8 The system itself is already designed to be robust
against network and machine failures, and Borgmon allows engineers to write
smarter alerting rules by using the collection failure itself as a signal.
Storage in the Time-Series Arena
A service is typically made up of many binaries running as many tasks, on many
machines, in many clusters. Borgmon needs to keep all that data organized, while
allowing flexible querying and slicing of that data.
Borgmon stores all the data in an in-memory database, regularly checkpointed to
disk. The data points have the form (timestamp, value), and are stored in chrono‐
logical lists called time-series, and each time-series is named by a unique set of labels,
of the form name=value.
As presented in Figure 10-1, a time-series is conceptually a one-dimensional matrix
of numbers, progressing through time. As you add permutations of labels to this
time-series, the matrix becomes multidimensional.
Figure 10-1. A time-series for errors labeled by the original host each was collected from
In practice, the structure is a fixed-sized block of memory, known as the time-series
arena, with a garbage collector that expires the oldest entries once the arena is full.
The time interval between the most recent and oldest entries in the arena is the hori‐
zon, which indicates how much queryable data is kept in RAM. Typically, datacenter
8 Recall in Chapter 6 the distinction between alerting on symptoms and on causes.
Storage in the Time-Series Arena | 111
and global Borgmon are sized to hold about 12 hours of data9 for rendering consoles,
and much less time if they are the lowest-level collector shards. The memory require‐
ment for a single data point is about 24 bytes, so we can fit 1 million unique time-
series for 12 hours at 1-minute intervals in under 17 GB of RAM.
Periodically, the in-memory state is archived to an external system known as the
Time-Series Database (TSDB). Borgmon can query TSDB for older data and, while
slower, TSDB is cheaper and larger than a Borgmon’s RAM.
Labels and Vectors
As shown in the example time-series in Figure 10-2, time-series are stored as sequen‐
ces of numbers and timestamps, which are referred to as vectors. Like vectors in linear
algebra, these vectors are slices and cross-sections of the multidimensional matrix of
data points in the arena. Conceptually the timestamps can be ignored, because the
values are inserted in the vector at regular intervals in time—for example, 1 or 10 sec‐
onds or 1 minute apart.
Figure 10-2. An example time-series
The name of a time-series is a labelset, because it’s implemented as a set of labels
expressed as key=value pairs. One of these labels is the variable name itself, the key
that appears on the varz page.
A few label names are declared as important. For the time-series in the time-series
database to be identifiable, it must at minimum have the following labels:
var
The name of the variable
job
The name given to the type of server being monitored
service
A loosely defined collection of jobs that provide a service to users, either internal
or external
9 This 12-hour horizon is a magic number that aims to have enough information for debugging an incident in
RAM for fast queries without costing too much RAM.
112 | Chapter 10: Practical Alerting from Time-Series Data
zone
A Google convention that refers to the location (typically the datacenter) of the
Borgmon that performed the collection of this variable
Together, these variables appear something like the following, called the variable
expression:
{var=http_requests,job=webserver,instance=host0:80,service=web,zone=us-west}
A query for a time-series does not require specification of all these labels, and a
search for a labelset returns all matching time-series in a vector. So we could return a
vector of results by removing the instance label in the preceding query, if there were
more than one instance in the cluster. For example:
{var=http_requests,job=webserver,service=web,zone=us-west}
might have a result of five rows in a vector, with the most recent value in the time-
series like so:
{var=http_requests,job=webserver,instance=host0:80,service=web,zone=us-west} 10
{var=http_requests,job=webserver,instance=host1:80,service=web,zone=us-west} 9
{var=http_requests,job=webserver,instance=host2:80,service=web,zone=us-west} 11
{var=http_requests,job=webserver,instance=host3:80,service=web,zone=us-west} 0
{var=http_requests,job=webserver,instance=host4:80,service=web,zone=us-west} 10
Labels can be added to a time-series from:
• The target’s name, e.g., the job and instance
• The target itself, e.g., via map-valued variables
• The Borgmon configuration, e.g., annotations about location or relabeling
• The Borgmon rules being evaluated
We can also query time-series in time, by specifying a duration to the variable expres‐
sion:
{var=http_requests,job=webserver,service=web,zone=us-west}[10m]
This returns the last 10 minutes of history of the time-series that matched the expres‐
sion. If we were collecting data points once per minute, we would expect to return 10
data points in a 10-minute window, like so:10
{var=http_requests,job=webserver,instance=host0:80, ...} 0 1 2 3 4 5 6 7 8 9 10
{var=http_requests,job=webserver,instance=host1:80, ...} 0 1 2 3 4 4 5 6 7 8 9
{var=http_requests,job=webserver,instance=host2:80, ...} 0 1 2 3 5 6 7 8 9 9 11
{var=http_requests,job=webserver,instance=host3:80, ...} 0 0 0 0 0 0 0 0 0 0 0
{var=http_requests,job=webserver,instance=host4:80, ...} 0 1 2 3 4 5 6 7 8 9 10
10 The service and zone labels are elided here for space, but are present in the returned expression.
Storage in the Time-Series Arena | 113
Rule Evaluation
Borgmon is really just a programmable calculator, with some syntactic sugar that ena‐
bles it to generate alerts. The data collection and storage components already
described are just necessary evils to make that programmable calculator ultimately fit
for purpose here as a monitoring system. :)
Centralizing the rule evaluation in a monitoring system, rather
than delegating it to forked subprocesses, means that computations
can run in parallel against many similar targets. This practice keeps
the configuration relatively small in size (for example, by removing
duplication of code) yet more powerful through its expressiveness.
The Borgmon program code, also known as Borgmon rules, consists of simple alge‐
braic expressions that compute time-series from other time-series. These rules can be
quite powerful because they can query the history of a single time-series (i.e., the time
axis), query different subsets of labels from many time-series at once (i.e., the space
axis), and apply many mathematical operations.
Rules run in a parallel threadpool where possible, but are dependent on ordering
when using previously defined rules as input. The size of the vectors returned by their
query expressions also determines the overall runtime of a rule. Thus, it is typically
the case that one can add CPU resources to a Borgmon task in response to it running
slow. To assist more detailed analysis, internal metrics on the runtime of rules are
exported for performance debugging and for monitoring the monitoring.
Aggregation is the cornerstone of rule evaluation in a distributed environment.
Aggregation entails taking the sum of a set of time-series from the tasks in a job in
order to treat the job as a whole. From those sums, overall rates can be computed. For
example, the total queries-per-second rate of a job in a datacenter is the sum of all the
rates of change11 of all the query counters.12
11 Computing the sum of rates instead of the rate of sums defends the result against counter resets or missing
data, perhaps due to a task restart or failed collection of data.
12 Despite being untyped, the majority of varz are simple counters. Borgmon’s rate function handles all the cor‐
ner cases of counter resets.
114 | Chapter 10: Practical Alerting from Time-Series Data
A counter is any nonmonotonically decreasing variable—which is
to say, counters only increase in value. Gauges, on the other hand,
may take any value they like. Counters measure increasing values,
such as the total number of kilometers driven, while gauges show
current state, such as the amount of fuel remaining or current
speed. When collecting Borgmon-style data, it’s better to use coun‐
ters, because they don’t lose meaning when events occur between
sampling intervals. Should any activity or changes occur between
sampling intervals, a gauge collection is likely to miss that activity.
For an example web server, we might want to alert when our web server cluster starts
to serve more errors as a percent of requests than we think is normal—or more tech‐
nically, when the sum of the rates of non-HTTP-200 return codes on all tasks in the
cluster, divided by the sum of the rates of requests to all tasks in that cluster, is greater
than some value.
This is accomplished by:
1. Aggregating the rates of response codes across all tasks, outputting a vector of
rates at that point in time, one for each code.
2. Computing the total error rate as the sum of that vector, outputting a single value
for the cluster at that point in time. This total error rate excludes the 200 code
from the sum, because it is not an error.
3. Computing the cluster-wide ratio of errors to requests, dividing the total error
rate by the rate of requests that arrived, and again outputting a single value for
the cluster at that point in time.
Each of these outputs at a point in time gets appended to its named variable expres‐
sion, which creates the new time-series. As a result, we will be able to inspect the his‐
tory of error rates and error ratios some other time.
The rate of requests rules would be written in Borgmon’s rule language as the
following:
rules >>
Rule Evaluation | 115
The rate() function takes the enclosed expression and returns the total delta divided
by the total time between the earliest and latest values.
With the example time-series data from the query before, the results for the
task:http_requests:rate10m rule would look like:13
{var=task:http_requests:rate10m,job=webserver,instance=host0:80, ...} 1
{var=task:http_requests:rate10m,job=webserver,instance=host2:80, ...} 0.9
{var=task:http_requests:rate10m,job=webserver,instance=host3:80, ...} 1.1
{var=task:http_requests:rate10m,job=webserver,instance=host4:80, ...} 0
{var=task:http_requests:rate10m,job=webserver,instance=host5:80, ...} 1
and the results for the dc:http_requests:rate10m rule would be:
{var=dc:http_requests:rate10m,job=webserver,service=web,zone=us-west} 4
because the second rule uses the first one as input.
The instance label is missing in the output now, discarded by the
aggregation rule. If it had remained in the rule, then Borgmon
would not have been able to sum the five rows together.
In these examples, we use a time window because we’re dealing with discrete points in
the time-series, as opposed to continuous functions. Doing so makes the rate calcula‐
tion easier than performing calculus, but means that to compute a rate, we need to
select a sufficient number of data points. We also have to deal with the possibility that
some recent collections have failed. Recall that the historical variable expression nota‐
tion uses the range [10m] to avoid missing data points caused by collection errors.
The example also uses a Google convention that helps readability. Each computed
variable name contains a colon-separated triplet indicating the aggregation level,
the variable name, and the operation that created that name. In this example, the left‐
hand variables are “task HTTP requests 10-minute rate” and “datacenter HTTP
requests 10-minute rate.”
Now that we know how to create a rate of queries, we can build on that to also com‐
pute a rate of errors, and then we can calculate the ratio of responses to requests to
understand how much useful work the service is doing. We can compare the ratio
rate of errors to our service level objective (see Chapter 4) and alert if this objective is
missed or in danger of being missed:
13 The service and zone labels are elided for space.
116 | Chapter 10: Practical Alerting from Time-Series Data
rules >>
Again, this calculation demonstrates the convention of suffixing the new time-series
variable name with the operation that created it. This result is read as “datacenter
HTTP errors 10 minute ratio of rates.”
The output of these rules might look like:14
{var=task:http_responses:rate10m,job=webserver}
{var=task:http_responses:rate10m,job=webserver,code=200,instance=host0:80, ...} 1
{var=task:http_responses:rate10m,job=webserver,code=500,instance=host0:80, ...} 0
{var=task:http_responses:rate10m,job=webserver,code=200,instance=host1:80, ...} 0.5
{var=task:http_responses:rate10m,job=webserver,code=500,instance=host1:80, ...} 0.4
{var=task:http_responses:rate10m,job=webserver,code=200,instance=host2:80, ...} 1
{var=task:http_responses:rate10m,job=webserver,code=500,instance=host2:80, ...} 0.1
{var=task:http_responses:rate10m,job=webserver,code=200,instance=host3:80, ...} 0
{var=task:http_responses:rate10m,job=webserver,code=500,instance=host3:80, ...} 0
{var=task:http_responses:rate10m,job=webserver,code=200,instance=host4:80, ...} 0.9
{var=task:http_responses:rate10m,job=webserver,code=500,instance=host4:80, ...} 0.1
{var=dc:http_responses:rate10m,job=webserver}
{var=dc:http_responses:rate10m,job=webserver,code=200, ...} 3.4
{var=dc:http_responses:rate10m,job=webserver,code=500, ...} 0.6
{var=dc:http_responses:rate10m,jobwebserver,code=!/200/}
{var=dc:http_responses:rate10m,job=webserver,code=500, ...} 0.6
{var=dc:http_errors:rate10m,job=webserver}
{var=dc:http_errors:rate10m,job=webserver, ...} 0.6
14 The service and zone labels are elided for space.
Rule Evaluation | 117
{var=dc:http_errors:ratio_rate10m,job=webserver}
{var=dc:http_errors:ratio_rate10m,job=webserver} 0.15
The preceding output shows the intermediate query in the
dc:http_errors:rate10m rule that filters the non-200 error codes.
Though the value of the expressions are the same, observe that the
code label is retained in one but removed from the other.
As mentioned previously, Borgmon rules create new time-series, so the results of the
computations are kept in the time-series arena and can be inspected just as the source
time-series are. The ability to do so allows for ad hoc querying, evaluation, and explo‐
ration as tables or charts. This is a useful feature for debugging while on-call, and if
these ad hoc queries prove useful, they can be made permanent visualizations on a
service console.
Alerting
When an alerting rule is evaluated by a Borgmon, the result is either true, in which
case the alert is triggered, or false. Experience shows that alerts can “flap” (toggle their
state quickly); therefore, the rules allow a minimum duration for which the alerting
rule must be true before the alert is sent. Typically, this duration is set to at least two
rule evaluation cycles to ensure no missed collections cause a false alert.
The following example creates an alert when the error ratio over 10 minutes exceeds
1% and the total number of errors exceeds 1:
rules  0.01
and by job, error
{var=dc:http_errors:rate10m,job=webserver} > 1
for 2m
=> ErrorRatioTooHigh
details "webserver error ratio at [[trigger_value]]"
labels {severity=page};
>>>
Our example holds the ratio rate at 0.15, which is well over the threshold of 0.01 in