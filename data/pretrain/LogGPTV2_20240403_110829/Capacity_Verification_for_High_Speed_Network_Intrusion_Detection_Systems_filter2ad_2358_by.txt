# Average Response Time

The figure below (Fig. 8) illustrates the average response time as the number of clients increases. The data structure used in this system enables very fast tests, representing a classic trade-off in favor of speed.

![Average Response Time](fig8_average_response_time.png)

**Figure 8. Average Response Time**

# Client Throughput Comparison

The following graph (Fig. 9) compares the client throughput as the number of clients varies. This visualization helps to understand the system's performance under different load conditions.

![Client Throughput](fig9_client_throughput.png)

**Figure 9. Client Throughput**

# Conclusion and Future Work

This paper presents an accurate method for detecting buffer overflow exploit code in Internet service requests. We have explained the structure and constraints of these attacks and discussed the techniques intruders use to evade common detection methods.

Our approach is based on the abstract execution of the packet payload to detect the presence of an exploit. A valid instruction chain is defined as a sequence of consecutive bytes in a request that represent executable processor instructions. The detection mechanism leverages the fact that requests containing buffer overflow code typically include longer instruction chains than regular requests. Our hypothesis has been verified by comparing results from regular HTTP and DNS requests with those containing exploit code.

The system's advantage lies in its ability to analyze and deny malicious requests before the service process is affected by a buffer overflow. It is also resistant to the evasion techniques discussed in Section 2. The performance impact of the detection mechanism has been evaluated by integrating it into the Apache web server.

Future work will focus on emulating additional instructions, such as SIMD and MMX operations. We will also investigate the benefits of performing a full emulation of the effects of the instructions, not just checking their basic executability, to detect buffer overflow exploits with self-modifying code. Additionally, we plan to collect experimental data for other protocols like FTP and NFS to validate the applicability of our proposed approach.

# References

1. AlephOne. Smashing the stack for fun and profit. Phrack Magazine, 49(14), 1996.
2. Debra Anderson, Thane Frivold, Ann Tamaru, and Alfonso Valdes. Next Generation Intrusion Detection Expert System (NIDES). SRI International, 1994.
3. The Apache Software Foundation. http://www.apache.org.
4. M. Bykova, S. Ostermann, and B. Tjaden. Detecting network intrusions via a statistical analysis of network packet characteristics. In Proceedings of the 33rd Southeastern Symposium on System Theory, 2001.
5. Crispin Cowan, Calton Pu, David Maier, Heather Hinton, Peat Bakke, Steve Beattie, Aaron Grier, Perry Wagle, and Qian Zhang. Automatic detection and prevention of buffer-overflow attacks. In 7th USENIX Security Symposium, January 1998.
6. Dorothy Denning. An intrusion-detection model. In IEEE Symposium on Security and Privacy, pages 118–131, Oakland, USA, 1986.
7. Laurent Eschenauer. Imsafe. http://imsafe.sourceforge.net, 2001.
8. Stephanie Forrest, Steven A. Hofmeyr, Anil Somayaji, and Thomas A. Longstaff. A sense of self for Unix processes. In Proceedings of the 1996 IEEE Symposium on Research in Security and Privacy, pages 120–128. IEEE Computer Society Press, 1996.
9. The GNU Compiler Collection. http://gcc.gnu.org.
10. A. Ghosh and A. Schwartzbard. A study in using neural networks for anomaly and misuse detection. In USENIX Security Symposium, 1999.
11. Judith Hochberg, Kathleen Jackson, Cathy Stallins, J. F. McClary, David DuBois, and Josephine Ford. NADIR: An automated system for detecting network intrusion and misuse. Computer and Security, 12(3):235–248, May 1993.
12. Intel. IA-32 Intel Architecture Software Developer’s Manual Volume 1-3, 2002. http://developer.intel.com/design/Pentium4/manuals/.
13. Home of K2. http://www.ktwo.ca.
14. Christopher Kruegel, Thomas Toth, and Clemens Kerer. Service Specific Anomaly Detection for Network Intrusion Detection. In Symposium on Applied Computing (SAC). ACM Scientific Press, March 2002.
15. Mudge. Compromised: Buffer-Overflows, from Intel to SPARC Version 8. http://www.l0pht.com, 1996.
16. Peter G. Neumann and Phillip A. Porras. Experience with EMERALD to date. In 1st USENIX Workshop on Intrusion Detection and Network Monitoring, pages 73–80, Santa Clara, California, USA, April 1999.
17. Phillip A. Porras and Peter G. Neumann. EMERALD: Event Monitoring Enabling Responses to Anomalous Live Disturbances. In Proceedings of the 20th NIS Security Conference, October 1997.
18. Martin Roesch. Snort - Lightweight Intrusion Detection for Networks. In USENIX Lisa 99, 1999.
19. SecurityFocus Corporate Site. http://www.securityfocus.com.
20. Jude Shavlik, Mark Shavlik, and Michael Fahland. Evaluating software sensors for actively profiling Windows 2000 computer users. In Recent Advances in Intrusion Detection (RAID), 2001.
21. E. Spafford. The Internet Worm Program: Analysis. Computer Communication Review, January 1989.
22. Stuart Staniford, James A. Hoagland, and Joseph M. McAlerney. Practical Automated Detection of Stealthy Portscans. In Proceedings of the IDS Workshop of the 7th Computer and Communications Security Conference, Athens, 2000.
23. Giovanni Vigna and Richard A. Kemmerer. NetSTAT: A Network-based Intrusion Detection System. In 14th Annual Computer Security Applications Conference, December 1998.
24. Giovanni Vigna and Richard A. Kemmerer. NetSTAT: A Network-based Intrusion Detection System. Journal of Computer Security, 7(1):37–71, 1999.
25. WebSTONE - Mindcraft Corporate Site. http://www.mindcraft.com.

---

# Introducing Reference Flow Control for Detecting Intrusion Symptoms at the OS Level

Jacob Zimmermann, Ludovic Mé, and Christophe Bidan  
{jacob.zimmermann, ludovic.me, christophe.bidan}@supelec.fr  
Supélec, France

## Abstract

This paper introduces a novel approach to policy-based detection of "attacks by delegation." These attacks exploit unpredictable behavior such as unknown side-effects, race-conditions, buffer overflows, and confused deputies to achieve illegal operations as legal consequences of legitimate operations. The proposed approach enforces restrictions on whether an operation can be executed as a consequence of another, to detect such attacks. We provide a proof-of-concept application to a Unix system and demonstrate its ability to detect new attack scenarios that seek the same intrusion goals.

## 1 Introduction

Enforcing a given security policy involves two main challenges: implementing the policy using existing mechanisms (e.g., access control, firewalls, authentication systems) and detecting policy violations (i.e., intrusions) and applying appropriate countermeasures. Current intrusion detection technology primarily relies on signature-based and anomaly-based detection methods, which, while effective, have limitations. Signature-based systems require active maintenance of attack databases and may not detect new attacks. Anomaly-based systems can generate false positives and struggle with legitimate but unplanned behavior.

To address these issues, sophisticated knowledge-based systems involving multiple IDSes and advanced alarm interpretation models have been proposed. However, this is a complex and expensive approach. Another method is policy-based detection, where the IDS detects anomalies that violate policy rules rather than learned "normal" behavior. For example, a policy might state that telnet should not be used or that ftp should be used only at certain times and on specific sites. The IDS would then verify if these constraints are respected and raise alarms when violations occur.

The challenge is that it can be difficult to determine whether a specific action violates the security policy. For instance, OS access-control primitives provide some form of policy-based intrusion detection, but attacks can still occur by exploiting side-effects, buffer overflows, or coordination between multiple subject identities. Therefore, a policy that states which operations are forbidden can be defeated by performing a series of individually legal operations that ultimately lead to the same illegal goal.

We propose that a security policy should be implemented in terms of what goals should not be achieved, regardless of the means. We aim to detect intrusion symptoms rather than intrusions themselves, focusing on attacks that attempt to achieve forbidden goals, such as buffer overflow exploits, side-effect exploits, and race condition exploits. Our proposed policy-based intrusion detection model is suitable for runtime detection of such attack symptoms and can handle new attack scenarios without requiring empirical profiles of "normal" behavior.

## 2 Model

### 2.1 References

A reference represents the capability to execute an elementary object method call within a specific operation domain. Unlike capabilities, references are not bound to a subject or an executing process but to a reference bag that represents the operations allowed in a domain.

**Definition:** Given an object \( o \), a method \( m \), and a reference bag \( S \), the reference \( R_S(o.m) \) is the capability to call method \( m \) on \( o \) within the domain represented by \( S \).

Thus, any possible system operation requires one or several references to be authorized. For example, in a Unix access control analogy, opening a file involves the file methods `openread` and `openwrite`. To be authorized in a domain associated with the reference bag \( S \), the operation `open(/etc/shadow, O_RDWR)` requires references \( R_S(/etc/shadow.openread) \) and \( R_S(/etc/shadow.openwrite) \). It also requires references \( R_S(/etc.openread) \) and \( R_S(/.openread) \), and so on. All these requirements must be met within the same reference bag \( S \) for the operation to be legal. Unlike the Chinese Wall model, where operation callers are explicitly bound to exclusive operation domains, in our approach, any reference bag \( S \) is a priori usable to perform the operation, allowing the caller to execute a potentially wide range of operations.

In the model, a real system object carries multiple states (e.g., contents, permissions, last write date), which are considered as separate objects.