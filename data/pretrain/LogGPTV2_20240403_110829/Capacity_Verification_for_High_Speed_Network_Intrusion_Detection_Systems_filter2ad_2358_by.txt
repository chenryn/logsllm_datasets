m
[
0.15
i
e
m
T
e
s
n
o
p
s
e
R
0.10
.
g
v
A
0.05
0.00
0
20
40
60
Nr. of clients
80
100
Fig. 8. Average Response Time
uncommon. In addition, this data structure makes very fast tests possible and
is a classical trade-oﬀ in favor of speed.
7 Conclusion and Future Work
This paper presents an accurate way of detecting buﬀer overﬂow exploit code
in Internet service requests. We explain the structure and constraints of these
attacks and discuss methods used by intruders to evade common detection tech-
niques.
290
T. Toth and C. Kruegel
Client Throughput Comparison
79
78
77
76
75
74
]
s
/
t
i
B
M
[
t
u
p
h
g
u
o
r
h
T
t
n
e
i
l
C
73
0
20
40
60
Nr. of clients
80
100
Fig. 9. Client Throughput
Our analysis approach bases on the abstract execution of the packet pay-
load to detect the sledge of an exploit. We deﬁne a valid instruction chain as
a number of consecutive bytes in a request that represent executable processor
instructions. The detection mechanism uses the fact that requests which contain
buﬀer overﬂow code include noticeably longer chains than regular requests. In
addition to the provision of theoretical support, our hypothesis has been veriﬁed
by comparing the results for regular HTTP and DNS requests to ones with exploit
code.
The system has the advantage that requests can be analyzed and denied a-
priori before the service process is aﬀected by a buﬀer overﬂow. It is also resistant
to the presented evasion techniques in Section 2. The performance impact of the
probe has been evaluated by integrating it into the Apache web server.
Further work will concentrate on emulating instructions that have not been
included yet (SIMD and MMX operations). We also investigate whether it is useful
to perform a ‘full’ emulation of the eﬀects of the instructions (not only to check
the basic executability) in order to detect buﬀer overﬂow exploits with a self
modifying sledge.
Additionally, we plan to collect experimental data for other protocols like
FTP and NFS to validate that our proposed approach is also applicable there.
References
1. AlephOne. Smashing the stack for fun and proﬁt. Phrack Magazine, 49(14), 1996.
2. Debra Anderson, Thane Frivold, Ann Tamaru, and Alfonso Valdes. Next Genera-
tion Intrusion Detection Expert System (NIDES). SRI International, 1994.
3. The Apache Software Foundation. http://www.apache.org.
Accurate Buﬀer Overﬂow Detection via Abstract Payload Execution
291
4. M. Bykova, S. Ostermann, and B. Tjaden. Detecting network intrusions via a
statistical analysis of network packet characteristics. In Proceedings of the 33rd
Southeastern Symposium on System Theory, 2001.
5. Crispin Cowan, Calton Pu, David Maier, Heather Hinton, Peat Bakke, Steve Beat-
tie, Aaron Grier, Perry Wagle, and Qian Zhang. Automatic detection and preven-
tion of buﬀer-overﬂow attacks. In 7th USENIX Security Symposium, January 1998.
6. Dorothy Denning. An intrusion-detection model. In IEEE Symposium on Security
and Privacy, pages 118–131, Oakland, USA, 1986.
7. Laurent Eschenauer. Imsafe. http://imsafe.sourceforge.net, 2001.
8. Stephanie Forrest, Steven A. Hofmeyr, Anil Somayaji, and Thomas A. Longstaﬀ.
A sense of self for Unix processes. In Proceedinges of the 1996 IEEE Symposium on
Research in Security and Privacy, pages 120–128. IEEE Computer Society Press,
1996.
9. The GNU Compiler Collection. http://gcc.gnu.org.
10. A. Ghosh and A. Schwartzbard. A study in using neural networks for anomaly and
misuse detection. In USENIX Security Symposium, 1999.
11. Judith Hochberg, Kathleen Jackson, Cathy Stallins, J. F. McClary, David DuBois,
and Josephine Ford. NADIR: An automated system for detecting network intrusion
and misuse. Computer and Security, 12(3):235–248, May 1993.
12. Intel. IA-32 Intel Architecture Software Developer’s Manual Volume 1-3, 2002.
http://developer.intel.com/design/Pentium4/manuals/.
13. Home of K2. http://www.ktwo.ca.
14. Christopher Kruegel, Thomas Toth, and Clemens Kerer. Service Speciﬁc Anomaly
Detection for Network Intrusion Detection. In Symposium on Applied Computing
(SAC). ACM Scientiﬁc Press, March 2002.
15. Mudge. Compromised: Buﬀer-Overﬂows, from Intel to SPARC Version 8.
http://www.l0pht.com, 1996.
16. Peter G. Neumann and Phillip A. Porras. Experience with EMERALD to date.
In 1st USENIX Workshop on Intrusion Detection and Network Monitoring, pages
73–80, Santa Clara, California, USA, April 1999.
17. Phillip A. Porras and Peter G. Neumann. EMERALD: Event Monitoring En-
abling Responses to Anomalous Live Disturbances. In Proceedings of the 20th NIS
Security Conference, October 1997.
18. Martin Roesch. Snort - Lightweight Intrusion Detection for Networks. In USENIX
Lisa 99, 1999.
19. SecurityFocus Corporate Site. http://www.securityfocus.com.
20. Jude Shavlik, Mark Shavlik, and Michael Fahland. Evaluating software sensors for
actively proﬁling Windows 2000 computer users. In Recent Advances in Intrusion
Detection (RAID), 2001.
21. E. Spaﬀord. The Internet Worm Program: Analysis. Computer Communication
Review, January 1989.
22. Stuart Staniford, James A. Hoagland, and Joseph M. McAlerney. Practical Au-
tomated Detection of Stealthy Portscans. In Proceedings of the IDS Workshop of
the 7th Computer and Communications Security Conference, Athens, 2000.
23. Giovanni Vigna and Richard A. Kemmerer. NetSTAT: A Network-based Intrusion
In 14th Annual Computer Security Applications Conference,
Detection System.
December 1998.
24. Giovanni Vigna and Richard A. Kemmerer. NetSTAT: A Network-based Intrusion
Detection System. Journal of Computer Security, 7(1):37–71, 1999.
25. WebSTONE - Mindcraft Corporate Site. http://www.mindcraft.com.
Introducing Reference Flow Control for
Detecting Intrusion Symptoms at the OS Level
Jacob Zimmermann, Ludovic M´e, and Christophe Bidan
{jacob.zimmermann, ludovic.me, christophe.bidan}@supelec.fr
Sup´elec, France
Abstract. This paper presents a novel approach to policy-based detec-
tion of “attacks by delegation”. By exploiting unpredictable behaviour
such as unknown side-eﬀects, race-conditions, buﬀer overﬂows, confused
deputies etc., these attacks aim at achieving their goals (i.e. executing
some illegal operation) as legal consequences of other legitimate opera-
tions. The proposed approach enforces restrictions on whether an opera-
tion can be executed as a consequence of another, in order to detect that
kind of attacks. We propose a proof-of-concept application to a Unix
system and show its ability to detect novel attack scenarii that seek the
same intrusion goals.
1 Introduction
To enforce a given security policy, one has to address two separate problems.
First, the policy has to be implemented using existing mechanisms: access con-
trol, ﬁrewall, authentication system, etc. Then, it is necessary to detect policy
violations, i.e. intrusions, and eventually apply appropriate counter-measures.
Current intrusion detection technology relies mostly on two approaches: signa-
ture based detection and anomaly based detection. These methods have proven
to be fairly eﬀective and are widely used. However, they suﬀer also from sev-
eral problems. A signature-based Intrusion Detection System requires an active
maintenance of its attack database. Novel attacks are generally not detected. An
anomaly-based IDS may generate a high amount of false positives, even if the ob-
served actions are perfectly legitimate [1,2]. In any case, dealing with legitimate
but unplanned behaviour is problematic.
These problems can be addressed in multiple ways. Sophisticated knowledge-
based systems involving multiple IDSes and advanced alarm interpretation mod-
els have been proposed [3,4,5,6,7]. Nevertheless this is a complex, expensive ap-
proach.
Another possible way to deal with these problems is policy-based detection
[8]. A policy-based IDS detects anomalies that violate policy rules rather than a
learned behaviour considered to be “normal”. For instance, a policy could state
that telnet should not be used at all, or that ftp should be used only at certain
hours and on speciﬁc sites. The IDS should then rely on a ﬁrewall-like module
to verify if these constraints are respected and raise an alarm when a violation
occurs.
A. Wespi, G. Vigna, and L. Deri (Eds.): RAID 2002, LNCS 2516, pp. 292–306, 2002.
c(cid:1) Springer-Verlag Berlin Heidelberg 2002
Introducing Reference Flow Control
293
The problem is that in many cases, it is actually hard to tell whether a speciﬁc
action violates the security policy or not. For instance, the OS access-control
primitives actually provide some form of policy-based intrusion detection, in the
sense that they can forbid operations that violate a given policy (in Unix, “users
other than root cannot read /etc/shadow”). Still, experience shows that attacks
are possible: for instance, by exploiting side-eﬀects such as buﬀer overﬂows or
coordination between multiple subject identities, one can gain supplementary
privileges to perform operations that should theoretically be forbidden to him.
Thus, a policy that states which operations are forbidden can be defeated by
performing series of operations that are not illegal per se, but which ultimately
lead to the same goals.
We believe that to overcome these problems, a security policy should be
implemented in terms of what goals should not be achieved, no matter how.
We propose to detect intrusion symptoms, rather than intrusions themselves.
We focus on intrusions where the attacker attempts to achieve some forbidden
goal, as opposed to denial-of-service attacks which are out of scope of our work.
Such attacks include buﬀer overﬂow exploits, side-eﬀects exploits, and race con-
ditions exploits. We propose a policy-based intrusion detection model suitable
for runtime detection of such attack symptoms. Our proposed approach is able
to deal with novel attack scenarii and requires no empirical proﬁle of “normal
behaviour”.
It is a known fact that the current weakness of intrusion detection techniques
is partly due to their lack of coherent theoretical foundations [2]. Research eﬀorts
to build well-deﬁned intrusion detection models started to appear only recently
[9]. We think that this kind of model is needed, and we propose one in this paper.
The model itself is described in section 2. In section 3, we discuss an appli-
cation of this model to intrusion detection in an usual Unix system. Section 4
presents our prototype implementation and practical examples.
2 Model
In this section, we describe the proposed approach to intrusion symptom detec-
tion.
To implement a given security policy in current operating systems, access
control mechanisms bind precise access rights to each subject. As long as the
subject executes operations speciﬁcally allowed by his rights, the security policy
is enforced. However, existing security ﬂaws may allow an attacker to modify
(and, most certainly, extend) his rights in an unpredictable way. For this very
reason, existing access control mechanisms alone are not able to prevent such
attacks.
To detect symptoms of these, we propose to deﬁne operation domains that
match a given security policy, i.e. sets of operations that can be executed and
combined in any way without the security policy being harmed. Any legal op-
eration (in the sense of the security policy) is thus permitted in at least one
operation domain. For instance, the operation “read /home/user/document.txt”
would be allowed in the domain deﬁned by user’s rights, whereas “write
294
J. Zimmermann, L. M´e, and C. Bidan
/etc/shadow” would be possible only in a domain that allows the password
to be changed. However, none of these two domains allows the operation “cp
/home/user/document.txt /etc/shadow”, executing this operation would involve
more than one domain, and thus is illegal.
More precisely, a computer system is modeled as a set of objects, each object
having a set of methods that allow to read or update the object’s state1. Thus any
possible system operation (for example, in the Unix system call sense) has precise
semantics in terms of elementary object methods. Bounding the capability to
perform an object method call to a conﬁned domain as described above restricts
in eﬀect the possible use of system operations: if all required privileges to perform
an operation exist but belong to diﬀerent operation domains, such operation is
by deﬁnition illegal. If attempted, it is the symptom of an intrusion.
We propose the “reference ﬂow control” model as a practical way to imple-
ment this approach.
2.1 References
A reference represents the capability to execute an elementary object method
call in some operation domain. Much like hidden capabilities [10], references
exist on their own and can be associated to processes, but their existence is not
tied to the execution of a process. Unlike a capability, a reference is not bound
to a subject or an executing processes but to a reference bag that represents the
operations allowed in a domain.
Deﬁnition: Given an object o, a method m and a reference bag S, the reference
RS(o.m) is the capability to call method m on o from within the domain
represented by S.
Thus, any possible system operation requires one or several references to be
authorized: for example, let us consider a Unix access control analogy, where
ﬁle opening is done through the ﬁle methods openread and openwrite. To be
authorized in a domain associated to the reference bag S, the operation
open(/etc/shadow, O RDWR)
a
a
and
reference RS(/etc/shadow.openread)
requires
reference
RS(/etc/shadow.openwrite). It also requires a reference RS(/etc.openread) in
order to access the shadow ﬁle in the /etc directory, a reference RS(/.openread),
and so on. All these requirements are met within the same reference bag S for
the operation to be legal. However, unlike the Chinese Wall model [11], where
operation callers are bound explicitly to exclusive operation domains according
to their behaviour, in our approach, any reference bag S is a priori usable
to perform the operation. This allows the caller to execute a potentially wide
1 The notion of state is used as an abstraction here. A real system object carries
actually more than one state: for example, a ﬁle object has a “contents” state, a
“permissions” state, a “last write date” state and so on. In the model, these would
be considered as separate objects.