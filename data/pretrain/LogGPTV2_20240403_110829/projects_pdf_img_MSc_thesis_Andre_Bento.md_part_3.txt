“Graphy OpenTracing processor (OTP)”, that processes and extracts metrics from
tracing data. The final Section 5.3 - Data Analysis Component presents the possi-
ble solution for the second component, namely “Data Analyser”, that handles data
produced by the first component and produces the analysis reports. Also, in the last
two sections presented, the used algorithms and methods in the implementations are
properly detailed and explained.
• In Chapter 6 - Research Objectives and Approach, the gathered results, correspond-
ing analysis and limitations of tracing data are presented. This chapter is divided
in three main sections. The first one, Section 6.1 - Anomaly Detection, the results
regarding the gathered observations on the extracted metrics of anomalous service
detectionarepresentedandexplained. Second, inSection6.2-TraceQualityAnaly-
sistheresultsobtainedfromthequalityanalysismethodsappliedtothetracingdata
set are presented and explained. The final Section 6.3 - Limitations of OpenTracing
Data we present the limitations felted when designing a solution to process tracing
data, more precisely OpenTracing data.
• Last, in Chapter 7 - Conclusion and Future Work, the main conclusions for this
research work are presented. To present this chapter, a reflection about the imple-
mented tools, methods produced and the open paths from this research are exposed.
Also a reflection of the main difficulties felted with this research regarding the han-
dlingoftracingdataarepresented. Afterthis,thefutureworkthatcanbeaddressed,
considering this work, is properly explained.
Next, Chapter 2 - State of the Art, the state of the field is covered with core concepts,
technologies and related work.
8
Chapter 2
State of the Art
In this Chapter, we discuss the core concepts regarding the project, the most modern
technology for the purpose today and related work in the area. All the information pre-
sented results from work of research through published articles, knowledge exchange and
web searching.
First, the main purpose of Section 2.1 - Concepts is to introduce and provide a brief
explanation about the core concepts to the reader. Second, Section 2.2 - Technologies, all
the relevant technologies are analysed and discussed. In the final Section 2.3 - Related
Work, published articles and posts of related work are presented and possible research
directions are discussed.
2.1 Concepts
The following concepts represents the baseline to understand the work related to this
research project. First an explanation of higher level of concepts that composes the title
of this thesis are presented in Subsections 2.1.1 and 2.1.2. The following Subsections 2.1.3
to 2.1.5, aim to cover topics related to previous concepts: Distributed Tracing, Graphs
and Time-Series.
2.1.1 Microservices
The term “micro web services” was first used by Dr. Peter Rogers during a conference
on cloud computing in 2005, and evolved later on to “Microservices” at an event for
software architects in 2011, where the term was used to describe a style of architecture
that many attendees were experimenting with at the time. Netflix and Amazon were
among the early pioneers of microservices [7].
Microservices is “an architectural style that structures an application as a collection
of loosely coupled services, which implement business capabilities” [1], [2].
This style of software development has a very long history and has being introduced
and evolving due to software engineering achievements in the later years regarding cloud
distributedcomputinginfrastructures,ApplicationProgrammingInterface(API)improve-
ments, agile development methodologies and the emergence of the recent phenomenon of
containerized applications. “A container is a standard unit of software that packages
up code and all its dependencies so the application runs quickly and reliably from one
9
Chapter 2
computing environment to another, communicating with others through an API” [8].
In Microservices, services are small, specifically calibrated to perform a single func-
tion, also each service is designed to be autonomous, resilient, minimal and composable.
This framework brings a culture of rapid iteration, automation, testing, and continuous
deployment, enabling teams to create products and deploy code exponentially faster than
ever before [9].
Until the rising of Microservices based architecture, the Monolithic architectural style
was the most used. This style has a the particularity of produce software composed all
in one piece. All features are bundled, packaged and deployed in a single tier application
using a single code base.
Figure 2.1 aims to give a comparison between both architectural styles, Monolithic
and Microservices, and provide an insight about the differences between them.
Figure 2.1: Monolithic and Microservices architectural styles [10].
Both styles presented have their own advantages and disadvantages. To briefly present
some of them, two examples are provided, one for each architectural style. First example:
if one team needs to develop a single process system, e.g., e-Commerce application, that
authorizes customer, takes an order, check products inventory, authorize payment and
ships ordered products. The best alternative is to use Monolithic architecture, because
they can develop every feature in a single software package due to the application sim-
plicity, however, if the client starts to demand hard changes and additional features in
the solution, the code base may tend to increase into “out of control”, leading to more
challenging and time consuming changes. Second example, if one team needs to develop
a complex and huge service that needs to scale, e.g., Video streaming service, the best
alternative is to use Microservices architecture, because they can tackle the problem of
complexity by decomposing the application into a set of manageable small services which
are much faster to develop and test by individual organized teams, and thus, it will be
easier to maintain the code base due to decoupling, however, it will be harder to monitor
10
State of the Art
and manage the entire platform due to additional complexity associated with distributed
systems.
Taking into consideration this increasing difficulty in monitoring and managing large
Microservice based platforms, one must be aware and observe system behaviour to be able
to control it. Therefore, in the next Subsection 2.1.2, the core concept of Observability
and Controlling Performance is explained.
2.1.2 Observability and Controlling Performance
This Subsection aims to provide an introduction to some theory concepts about Ob-
servability and Performance Controlling, regarding distributed software systems.
Observability is a meaningfully extension of the word observing. Observing is “to be
orbecomeawareof, especiallythroughcarefulanddirectedattention; tonotice’’[11]. The
term Observability comes from the world of engineering and control theory. Observability
is not a new term in the industry, however it has gain more focus in the last years due to
DevelopmentandOperations(DevOps)raising. Itmeansbydefinition“tomeasureofhow
wellinternalstatesofasystemcanbeinferredfromknowledgeofitsexternaloutputs”[12].
Therefore, ifourgoodoldsoftwaresystemsandapplicationsdonotadequatelyexternalize
their state, then even the best monitoring can fall short.
Controlling in control systems is “to manage the behaviour of a certain system” [13].
Controlling and Observability are dual aspects of the same problem [12], as we need to
have information to infer state and be able take action. E.g., When observing an expo-
nential increase in the Central Processing Unit (CPU) load, the system scales horizontally
invoking more machines and spreading the work between them to easy handle the work.
This is a clear and simple example that conjugates the terms presented, we have: values
that are observed “Observability” and action that leads to system control “Controlling
Performance”.
When we want to understand the working and behaviour of a system, we need to
watch it very closely and pay special attention to all details and information it provides.
Microservice based systems produce multiple types of information if instrumented. These
type of information are the ones mentioned in Chapter 1: Monitoring, Tracing and Log-
ging. In this thesis, the goal is to use tracing data thus, this type of produced information
is the one to focus.
In the next Subsection 2.1.3 - Distributed Tracing, the type of data mentioned before
is presented and explained in detail.
2.1.3 Distributed Tracing
Distributedtracing[14]isamethodthatcomesfromtraditionaltracing,butappliedto
adistributedsystematthework-flowlevel. Itprofilesandmonitorapplications, especially
thosebuiltusingmicroservicearchitecturesand, intheend, itcanbeusedtohelpDevOps
teams pinpoint where failures occur and why.
A number of tools and standards emerged from this concept. For example, the Open-
Tracing standard [15] follows the model proposed by Fonseca et al. [16], which defines
traces as a tree of spans representing scopes or units of work (i.e., thread, function, ser-
vice). These traces enable following such units of work through the system.
11
Chapter 2
OpenTracingusesdynamic,fixed-widthmetadatatopropagatecausalitybetweenspans,
meaning that each span has a trace identifier common to all spans of the same trace, as
well as a span identifier and parent identifier representing parent/child relationships be-
tween spans [17]. The standard defines the format for spans and the semantic [18], [19]
conventions for their content/annotations.
Figure 2.2 provides a clear insight about how spans are related to time and with each
other.
Time
Span A
Span B
Span C
Span D
Span E
Figure 2.2: Sample trace over time.
In Figure 2.2 there are a group of five spans spread through time that represents a
trace. A trace is a group of spans that share the same TraceID. A trace is a representation
of a data/execution path in the system. A span represents the logical unit of work in the
system. A trace can also be a span, if there is only one span presented in the trace. One
span can cause another.
Causality relationship between spans can be observed in Figure 2.2, where “Span A”
causes “Span B” and “Span E”, moreover, “Span B” causes “Span C” and “Span D”. From
this we say that “Span A” is parent of “Span B” and “Span E”. Likewise, “Span B” and
“Span E” are children of “Span A”. In this case, “Span A” does not have a parent, it
is an “orphan span” and therefore, is the root span and the origin of this whole trace.
Spans carry with them metadata like e.g., SpanID and ParentID, that allows to infer this
relationships.
Disposition of spans over time is another clear fact that can be observed from the
representation in Figure 2.2. Spans have a begin and an end in time. This causes them to
have a duration. Spans are spread through time, however they usually stay inside parent
boundaries, this means that the duration of a parent span always covers durations of their
children. Considering a parent and a child spans, if they are related, the parent span
always start before child span, also, the parent span always end after child span. Note
that nothing prevents multiple spans to start in the same exact moment. Span also carry
with them metadata like e.g., Timestamp and Duration, that allows to infer their position
in time and when they end.
AnexampleofaspancanbeanHypertextTransferProtocol(HTTP)calloraRemote
Procedure Call (RPC) call. We may think of the following cases to define each operation
12
State of the Art
inherent to each box presented in Figure 2.2: A - “Get user info”, B - “Fetch user data
from database”, C - “Connect to MySQL server”, D - “Can’t connect to MySQL server”
and E - “Send error result to client”.
In the data model specification, the creators of OpenTracing say that: “with a couple
of spans, we might be able to generate a span tree and model a directed graph of a portion
of the system” [15]. This is due to the causal relationships they represent. Apart from the
root span every other span must have a parent. Figure 2.3 provides an example of a span
tree.
Span A Root Span
Span B Span E
Span C Span D
Figure 2.3: Span Tree example.
Figure2.3containsaspantreerepresentationwithatracecontainingfivespans. Apart
from the root span every other span must have a parent. With this causal relationship,
a path through the system can be retrieved. For example, if every span processes in a
different endpoint represented by letters presented in the span tree, one may generate the
request path: A → B → D. This means that our hypothetical request passed through
machine A, B and D, or if it were services, the request passed from service A, to B and
finally to D. From this, we can generate the dependency graph of the system (explained
in the Subsection 2.1.4 - Graphs).
This type of data is extracted as trace files or streamed over transfer protocols like
e.g., HTTP, from technologies like Kubernetes [20], OpenStack [21], and other cloud or
distributed management system technologies that implements some kind of system or
code instrumentation using, for example, OpenTracing [22] or OpenCensus [23]. Tracing
contains some vital system details as they are the result of system instrumentation and
therefore, this data can be used as a resource to provide observability over the distributed
system.
As said before, from the causality relationship between spans we can generate a de-
pendency graph of the system. The next Subsection 2.1.4 - Graphs aims to provide a clear
understand of this concept and how they relate with distributed tracing.
13
Chapter 2
2.1.4 Graphs
From distributed tracing we can be able to extract the system dependency graph
from a representative set of traces. To introduce the concept of Graph, “A Graph is a
set of vertices and a collection of directed edges that each connects an ordered pair of
vertices” [24].
Taking the very common sense of the term and to provide notation, a graph, G, is an
ordered pair G = (V,E), where V are the vertices/nodes and E are the edges.
Graphs are defined by:
• Node: Are the entities in the graph. They can hold any number of attributes (key-
value pairs) called properties. Nodes can be tagged with labels, representing their
different roles in a domain. Node labels may also serve to attach metadata (such as
index or constraint information) to certain nodes;
• Edge(orRelationships): providedirected, named, semantically-relevantconnections
between two node entities;
• Property: canbeanykindofmetadataattachedtoacertainNodeoracertainEdge.
Also, there are multiple types of graphs, they can be:
1. Undirected-Graph: the set of edges without orientation between a pair of nodes;
2. Directed-Graph: the set of edges have one and only one direction between a pair of
nodes;
3. Multi-Directed-Graph: multiple edges have more than one connection between a
pair of nodes that represents the same relationship.
Figure 2.4 gives us a simple visual representation of what a graph really is for a more
clear understanding.
P P P
R R 10 R
G G G
H H H
3
A A A
Figure 2.4: Graphs types.
In Figure 2.4 three identical graphs are presented and each one is composed by five
nodes, however, they are not equal because each one has it own type. They belong respec-
tively to each type enumerated above. From left to right, the first graph is a Undirected-
Graph, the second one is a Directed-Graph and the last one is a Multi-Directed-Graph.
14
State of the Art
The last graph has some numbers in some edges. Every graph can have this anno-
tations. These can provide some information about the connection between the pair of
nodes. For example, in distributed systems context, if this graph represents our system
dependency graph, and nodes H and P hypothetical services, the edge between them
could represent calls between these two service and the notation number the number of
calls with respect to the edge direction. Therefore, in this case, we would have 10 requests
from incoming from P to H.
Figure 2.5 provides a clear insight about service dependency graphs.
110
Users API Users Database
190
240