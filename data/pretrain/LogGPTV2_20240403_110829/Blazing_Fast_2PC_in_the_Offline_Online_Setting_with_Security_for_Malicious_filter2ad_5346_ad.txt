5.49
5.55
4.39
6.25
N
8
32
128
1024
4096
Total number of
circuits
277
296
706
771
1995
2246
10843
36294
Number of eval
circuits per 2PC
19
17
15
13
12
10
9
7
Number of
circuits per 2PC
34.54
36.95
22.05
24.07
15.58
17.54
10.58
8.86
Table 1: Several sets of parameters for Lemma 2.2 with s = 40 (left) and s = 80 (right). Note the tradeoff between the total number
of circuits (which affects the ofﬂine stage efﬁciency) and the number of evaluation circuits per bucket (which affects the online stage
efﬁciency).
the cut-and-choose of C. We also implemented a program that re-
ceives a circuit C and calculates the encoding matrices E and E(cid:48),
used for protecting P2’s input from selective-OT attacks.
In contrast to [23], we have set the statistical security parameter
s to be such that the probability that an adversary cheats in a single
2PC execution is 2−s. (In [23], they set 2−s to be the probabil-
ity that an adversary cheats in at least one of the many executions
overall). Indeed, this is merely a different way of looking at the
parameters, but we believe that for most users, considering security
of a single execution is more natural.
Handling large inputs. Calculating a probe-resistant matrix ac-
cording to the algorithm of [30] is a very computation intensive task
when the input is large (e.g., 1000-bit long). Instead, when dealing
with long inputs, our system constructs the probe-resistant matrix
using a composition of smaller probe-resistant matrices (such that
each can be generated very efﬁciently). While this method results
in a slightly larger matrix used in the protocol (and, thus, more
OTs), it dramatically reduces the time needed for generating the
probe-resistant matrix (from hours to seconds).
Architecture. We use the SCAPI library [9, 1] for implementing
the high-level steps of the protocols, while using more optimized
C/C++ code for steps that are more computation intensive (e.g.,
computing the large amount of XORs of the probe-resistant ma-
trix). We use the OT-extension implementation of [3], a new SCAPI
garbling library that uses ﬁxed-key AES for garbling, as suggested
by [4], and the SCAPI wrapper of OpenSSL for AES and SHA-1.
The prototype is able to generate and evaluate many garbled cir-
cuits (and carry out other operations) in parallel, using multiple
threads.
In addition, before the online stage begins, all relevant
ﬁles are loaded to memory so once the interaction starts, no I/O de-
lays occur. (We do not include disk I/O time in our measurements
as in practice loading to memory should always occur before actual
inputs are received )
6. PERFORMANCE EVALUATION
Setup. We ran the prototype on two types of Amazon AWS in-
stances: c4.8xlarge (with 64GB RAM and 36 virtual 2.9GHz CPUs)
and c4.2xlarge (with 15GB RAM and 8 virtual 2.9GHz CPUs). On
both instances, garbling 1000 AES circuits in isolation took about
470 ms. Unless stated otherwise, all the tests in this section were
ran on the c4.8xlarge instances. We ran tests with LAN conﬁgu-
ration, where both parties were in the same AWS region and the
roundtrip was less than 1 ms, and with a WAN conﬁguration, where
the parties were in different regions (speciﬁcally, eu-west and us-
east) and the roundtrip was 75 ms.
We tested the prototype with the following circuits: (1) ADD:
receives two 32-bit integers and outputs their sum (the circuit has
127 AND gates); (2) AES: receives two 128-bit inputs and outputs
the encryption of the ﬁrst input using the second input as the key
(the circuit has 6800 AND gates); (3) SHA-1: receives two 256-bit
inputs and outputs the SHA-1 hash digest of the XOR of the two in-
puts (the circuit has 37300 AND gates); (4) SHA-256: receives two
256-bit inputs and outputs the SHA-256 hash digest of the XOR of
the two inputs (the circuit has 90825 AND gates).
Results. In the following, all experiments use the sets of parame-
ters from Table 1, and unless said otherwise, s = 40. See Table 2 for
the results of the implementation on these circuits; the online time
given is the average over all executions. We can see that, for exam-
ple, the total time it takes to evaluate a single AES (i.e.. the sum
of the online and ofﬂine stages timings) ranges from around 210ms
(for N = 32) to around 80ms (for N = 1024). See Table 3 for re-
sults with s = 80. In Table 4 we show an example of the effect of the
number of threads on the ofﬂine stage performance. Even though
performance is far from linear in the number of threads, it is clear
that parallelism helps, and we expect that further optimizations uti-
lizing multithreading will further improve performance. We also
ran these experiments for other settings and veriﬁed that this effect
is consistent. (For s = 80, the numbers are about 2-2.5 times larger.)
As discussed earlier, there is a tradeoff between the total number
of circuits and the number of evaluation circuits per online stage.
This affects the performance of the two stages. See Table 1 for
examples of those tradeoffs. In addition to the tests described in
Table 2, we also tested how this tradeoff is reﬂected in practice:
Instead of running AES with s = 80, N = 128 and bucket size 12,
we ran it with bucket size 10 which increases the total number of
circuits from 1995 to 2246; the ofﬂine running time was 310 ms per
2PC (with 9 threads) and the online running time was 31/16/17
ms for 1/5/9 threads (respectively). This is about 13% slower in
the ofﬂine phase and around 10% faster in the online phase, which
roughly matches the differences in the numbers of circuits and so
is as expected. Thus, it is possible to obtain different tradeoffs,
depending on whether it is more important to reduce the overall
cost or the online latency.
We also tested the prototype in the WAN conﬁguration, since
in many real-world scenarios the participating parties may be far
apart. Note that in these scenarios, the Yao-based approach has a
signiﬁcant advantage over TinyOT [26] and SPDZ [7] who have a
number of rounds that depends on the circuit depth. See Tables 5, 6
and 4 for the results of those tests. We note that our online phase re-
quires four rounds of interaction (two messages in each direction),
and since the roundtrip in our WAN conﬁguration is 75 ms, the cost
of our online stage cannot go below 150 ms. Our tests show that
in this case, the majority of the time spent is on communication,
and the cost of the actual steps of our protocol (i.e., excluding com-
munication) is very low. We remark that protocols which require a
585Online time per bucket
1 thread
5 threads
9 threads
Circuit
Number of buckets
Ofﬂine total Ofﬂine per bucket
ADD
AES
SHA-1
SHA-256
32
128
1024
32
128
1024
32
128
1024
32
128
1024
4266
9735
49590
6310
14539
75879
10042
24201
127555
14699
35243
210935
133
76
48
197
114
74
314
189
125
459
275
206
10
7
5
18
13
9
40
31
20
75
62
44
52
34
24
176
129
100
6
5
4
13
10
7
29
24
15
62
50
33
29
17
13
123
87
79
8
4
4
12
10
7
26
22
15
50
40
33
30
20
14
129
96
76
Table 2: Running times of the different circuits in LAN conﬁguration (in ms). For N = 32 we use buckets of 7 circuits of C and 20
of C(cid:48); for N = 128 we use buckets of 6 circuits of C and 14 of C(cid:48); for N = 1024 we use buckets of 4 circuits of C and 10 of C(cid:48) (C is the
main circuit and C(cid:48) is the auxiliary cheating-recovery circuit). Ofﬂine times are for execution with 9 threads.
Circuit
Number of buckets
Ofﬂine total Ofﬂine per bucket
AES
SHA-256
32
128
1024
32
128
1024
13901
35031
164937
29041
74120
662640
434
274
161
908
579
647
Online time per bucket
1 thread
5 threads
9 threads
Table 3: Running times for AES circuit in LAN conﬁguration for s = 80. For N = 32 we use buckets of 15 circuits of C and 46 of C(cid:48);
for N = 128 we use buckets of 12 circuits of C and 28 of C(cid:48); for N = 1024 we use buckets of 9 circuits of C and 20 of C(cid:48).
round of communication for every level of the circuit in the online
phase will perform poorly in this scenario. (For example, the best