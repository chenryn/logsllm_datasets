ğ‘’ğœ–0 + 1 +
1
=
+ 1,
where the last equality uses the identity ğ‘¥3 + 1 = (ğ‘¥ + 1)(ğ‘¥2 âˆ’ ğ‘¥ + 1).
This completes the proof of Lemma 6.2.
â– 
ğ‘’ğœ–0 (ğ‘’ğœ–0 + 1) =
ğ‘’ğœ–0
(ğ‘’ğœ–0)3 + 1
ğ‘’ğœ–0(ğ‘’ğœ–0 + 1) =
(ğ‘’ğœ–0 âˆ’ 1)2
D OMITTED DETAILS FROM SECTION 6
D.1 Omitted Details from Section 7.1
Before proving (40), first we show an important property of ğ¸ğ‘š
that we will use in the proof.
Lemma D.1. ğ¸ğ‘š is a non-increasing function of ğ‘š, i.e.,
M(Dâ€²(ğ‘›)
ğ‘š+1)(ğ’‰)
ğ‘š+1)(ğ’‰)
â‰¤ E
(cid:32)M(D(ğ‘›)
ğ‘›(cid:1) with |Dğ‘˜| = |Dâ€²
(cid:33)ğœ†
ğ‘˜ =(cid:0)ğ‘‘â€²
ğ’‰âˆ¼M(Dâ€²(ğ‘›)
ğ‘š )
(cid:33)ğœ† ,
(cid:32)M(D(ğ‘›)
ğ‘›, ğ‘‘ğ‘›(cid:1) and Dâ€²(ğ‘›)
ğ‘š )(ğ’‰)
ğ‘š )(ğ’‰)
M(D(ğ‘›)
(66)
=
(cid:0)ğ‘‘â€²
ğ‘›, ğ‘‘â€²
ğ‘›, . . . , ğ‘‘â€²
where, for any ğ‘˜ âˆˆ {ğ‘š, ğ‘š + 1}, D(ğ‘›)
ğ‘›, . . . , ğ‘‘â€²
Proof. Lemma D.1 follows from Lemma 5.3 in a straightforward
manner, as, unlike Lemma D.1, in Lemma 5.3 we consider arbitrary
pairs of neighboring datasets.
â– 
ğ‘˜| = ğ‘˜.
ğ‘˜
Here, steps (a) and (d) follow from the fact that ğ¸ğ‘š is a non-increasing
function of ğ‘š (see Lemma D.1). Step (b) follows from the Chernoff
bound. In step (c), we used that M(ğ‘‘ğ‘›) = R(ğ‘‘ğ‘›) and M(ğ‘‘â€²
R(ğ‘‘â€²
ğ‘›), which together imply that
ğ‘›) =
(cid:19)ğœ†(cid:35)
(cid:34)(cid:18)M(ğ‘‘ğ‘›)
M(ğ‘‘â€²
ğ‘›)
(cid:19)ğœ†(cid:35)
(cid:34)(cid:18)R(ğ‘‘ğ‘›)
R(ğ‘‘â€²
ğ‘›)
ğ¸0 = E
= E
â‰¤ ğ‘’ğœ–0ğœ†,
where the inequality follows because R is an ğœ–0-LDP mechanism.
â– 
D.2 Proof of Theorem 7.1
any ğœ† â‰¥ 2 (including the non-integral ğœ†), we have
Theorem (Restating Theorem 7.1). Let ğ‘š âˆˆ N be arbitrary. For
sup
ğ‘š)âˆˆDğ‘šsame
(Dğ‘š,Dâ€²
Eğ’‰âˆ¼M(Dğ‘š)
(cid:19)ğœ†(cid:35)
(cid:34)(cid:18)M(cid:0)Dâ€²
ğ‘š(cid:1) (ğ’‰)
(cid:19)
M (Dğ‘š) (ğ’‰)
(cid:18)
â‰¤ exp
ğœ†2 (ğ‘’ğœ–0 âˆ’ 1)2
.
ğ‘š
(67)
Proof. Fix an arbitrary ğ‘š âˆˆ N. Let (Dğ‘š, Dâ€²
ğ‘š) âˆˆ Dğ‘šsame and
ğµ) be the same as defined in the
1, . . . , ğ‘â€²
ğ’‘ = (ğ‘1, . . . , ğ‘ğµ), ğ’‘â€² = (ğ‘â€²
proof of Theorem 3.7 in Section 6.
(cid:170)(cid:174)(cid:172)ğœ†
ğ‘â€²
ğ‘—
ğ‘ ğ‘—
â„ ğ‘—
ğ‘š
M (Dğ‘š) (ğ’‰)
(cid:19)ğœ†(cid:35)
(cid:34)(cid:18)M(cid:0)Dâ€²
ğ‘š(cid:1) (ğ’‰)
(cid:169)(cid:173)(cid:171)1 + ğµâˆ‘ï¸
exp(cid:169)(cid:173)(cid:171)ğœ†(cid:169)(cid:173)(cid:171) ğµâˆ‘ï¸
â‰¤ Eğ’‰âˆ¼M(Dğ‘š)
= Eğ’‰âˆ¼M(Dğ‘š)
ğ‘â€²
ğ‘—
ğ‘ ğ‘—
ğ‘—=1
ğ‘—=1
â„ ğ‘—
ğ‘š
ğ‘â€²
ğ‘—
ğ‘ ğ‘—
ğ‘—=1
(cid:169)(cid:173)(cid:171) ğµâˆ‘ï¸
âˆ’ 1(cid:170)(cid:174)(cid:172)ğœ†
 ,
âˆ’ 1(cid:170)(cid:174)(cid:172)(cid:170)(cid:174)(cid:172)
â„ ğ‘—
ğ‘š
(68)
In (68), ğ’‰ is distributed according toM(Dğ‘š) = Hğ‘š(R(ğ‘‘), . . . , R(ğ‘‘)),
where the first equality uses (32) and the last inequality follows
from 1 + ğ‘¥ â‰¤ ğ‘’ğ‘¥.
where Hğ‘š denotes the shuffling operation on ğ‘š elements and range
of R is equal to [ğµ]. Since all the ğ‘š data points are identical, and
all clients use independent randomness for computing R(ğ‘‘), we
can assume, w.l.o.g., that M(Dğ‘š) is a collection of ğ‘š i.i.d. random
variables ğ‘‹1, . . . , ğ‘‹ğ‘š, where Pr [ğ‘‹ğ‘– = ğ‘—] = ğ‘ ğ‘— for ğ‘— âˆˆ [ğµ]. Thus, we
have (in the following, note that ğ’‰ = (â„1, . . . , â„ğµ) is a r.v.)
where 1{Â·} denotes the indicator r.v. Substituting from (69) into (68),
we get
â„ ğ‘— =
1{ğ‘‹ğ‘– =ğ‘— }
=
ğ‘—=1
1
ğ‘š
1
ğ‘š
ğ‘â€²
ğ‘—
ğ‘ ğ‘—
ğµâˆ‘ï¸
ğ‘šâˆ‘ï¸
ğµâˆ‘ï¸
exp(cid:169)(cid:173)(cid:171)ğœ†(cid:169)(cid:173)(cid:171) ğµâˆ‘ï¸
ğ‘—=1
ğ‘—=1
ğ‘–=1
ğ‘šâˆ‘ï¸
ğ‘–=1
ğ‘â€²
ğ‘—
ğ‘ ğ‘—
ğ‘â€²
ğ‘—
ğ‘ ğ‘—
(cid:34)
= Eğ‘‹1,...,ğ‘‹ğ‘š
exp
ğ‘šâˆ‘ï¸
ğ‘–=1
1
ğ‘š
ğ‘â€²
ğ‘‹ğ‘–
ğ‘ğ‘‹ğ‘–
,
(69)
1{ğ‘‹ğ‘– =ğ‘— } =
âˆ’ 1(cid:170)(cid:174)(cid:172)(cid:170)(cid:174)(cid:172)
(cid:32) ğœ†
(cid:32) ğ‘â€²
ğ‘šâˆ‘ï¸
â„ ğ‘—
ğ‘š
ğ‘š
ğ‘–=1
ğ‘‹ğ‘–
ğ‘ğ‘‹ğ‘–
(cid:33)(cid:33)(cid:35)
âˆ’ 1
E
ğ’‰âˆ¼M(Dâ€²(ğ‘›)
ğ‘š+1)
Eğ’‰âˆ¼M(Dğ‘š)
= Eğ’‰âˆ¼M(Dğ‘š)
Eğ’‰âˆ¼M(Dâ€²)
Now we can prove (40).
Proof of (40).
(cid:34)(cid:18) M(D)(ğ’‰)
âˆ‘ï¸
âˆ‘ï¸
M(Dâ€²)(ğ’‰)
=
ğ‘š<âŒŠ(1âˆ’ğ›¾)ğ‘(ğ‘›âˆ’1)âŒ‹
(a)â‰¤ ğ¸0
(cid:19)ğœ†(cid:35)
â‰¤ ğ‘›âˆ’1âˆ‘ï¸
ğ‘š=0
ğ‘ğ‘šğ¸ğ‘š +
ğ‘ğ‘šğ¸ğ‘š
âˆ‘ï¸
âˆ‘ï¸
ğ‘šâ‰¥âŒŠ(1âˆ’ğ›¾)ğ‘(ğ‘›âˆ’1)âŒ‹
ğ‘š<âŒŠ(1âˆ’ğ›¾)ğ‘(ğ‘›âˆ’1)âŒ‹
ğ‘šâ‰¥âŒŠ(1âˆ’ğ›¾)ğ‘(ğ‘›âˆ’1)âŒ‹
ğ‘ğ‘šğ¸ğ‘š
ğ‘ğ‘š +
âˆ‘ï¸
âˆ‘ï¸
ğ‘šâ‰¥âŒŠ(1âˆ’ğ›¾)ğ‘(ğ‘›âˆ’1)âŒ‹
+
ğ‘šâ‰¥âŒŠ(1âˆ’ğ›¾)ğ‘(ğ‘›âˆ’1)âŒ‹
+ ğ¸(1âˆ’ğ›¾)ğ‘(ğ‘›âˆ’1) .
(b)â‰¤ ğ¸0ğ‘’âˆ’ ğ‘(ğ‘›âˆ’1)ğ›¾2
2
+
(c)â‰¤ ğ‘’ğœ–0ğœ†ğ‘’âˆ’ ğ‘(ğ‘›âˆ’1)ğ›¾2
2
(d)â‰¤ ğ‘’ğœ–0ğœ†ğ‘’âˆ’ ğ‘(ğ‘›âˆ’1)ğ›¾2
2
ğ‘ğ‘šğ¸ğ‘š
ğ‘ğ‘šğ¸ğ‘š
1
ğ‘š
ğµâˆ‘ï¸
ğ‘—=1
ğ‘â€²
ğ‘—
ğ‘ ğ‘—
ğ‘ğ‘šğ¸ğ‘š
Eğ’‰âˆ¼M(Dğ‘š)
Session 7D: Privacy for Distributed Data and Federated Learning CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea 2340(cid:18)ğ‘›
(cid:19)
distributed as a Binomial random variable Bin(ğ‘›, ğ‘). Thus, we have
M(D)(ğ‘˜) =
M(Dâ€²)(ğ‘˜) = (1 âˆ’ ğ‘)
ğ‘˜
ğ‘ğ‘˜(1 âˆ’ ğ‘)ğ‘›âˆ’ğ‘˜
(cid:19)
(cid:18)ğ‘› âˆ’ 1
ğ‘˜ âˆ’ 1
ğ‘ğ‘˜âˆ’1(1 âˆ’ ğ‘)ğ‘›âˆ’ğ‘˜
(cid:18)ğ‘› âˆ’ 1
(cid:19)
ğ‘˜
ğ‘
ğ‘
ğ‘›
=
=
=
=
âˆ’
ğ‘’ğœ–0
ğ‘›ğ‘’ğœ–0
(72)
ğ‘’ğœ–0
ğ‘›
ğ‘’ğœ–0 + 1
ğ‘˜
ğ‘›
ğ‘˜
ğ‘›
ğ‘˜
ğ‘›
ğ‘˜