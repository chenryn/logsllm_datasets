title:Packet caches on routers: the implications of universal redundant
traffic elimination
author:Ashok Anand and
Archit Gupta and
Aditya Akella and
Srinivasan Seshan and
Scott Shenker
Packet Caches on Routers: The Implications of
Universal Redundant Trafﬁc Elimination
Ashok Anand∗, Archit Gupta∗, Aditya Akella∗, Srinivasan Seshan† and Scott Shenker‡
∗UW-Madison, †CMU, ‡UC-Berkeley
{ashok,archit,akella}@cs.wisc.edu, PI:EMAIL, PI:EMAIL
ABSTRACT
Many past systems have explored how to eliminate redundant trans-
fers from network links and improve network efﬁciency. Several of
these systems operate at the application layer, while the more recent
systems operate on individual packets. A common aspect of these
systems is that they apply to localized settings, e.g. at stub network
access links.
In this paper, we explore the beneﬁts of deploying
packet-level redundant content elimination as a universal primitive
on all Internet routers. Such a universal deployment would imme-
diately reduce link loads everywhere. However, we argue that far
more signiﬁcant network-wide beneﬁts can be derived by redesign-
ing network routing protocols to leverage the universal deployment.
We develop “redundancy-aware” intra- and inter-domain routing al-
gorithms and show that they enable better trafﬁc engineering, reduce
link usage costs, and enhance ISPs’ responsiveness to trafﬁc varia-
tions. In particular, employing redundancy elimination approaches
across redundancy-aware routes can lower intra and inter-domain
link loads by 10-50%. We also address key challenges that may hin-
der implementation of redundancy elimination on fast routers. Our
current software router implementation can run at OC48 speeds.
Categories and Subject Descriptors: C.2.2 [Computer Communi-
cation Networks]: Routing Protocols
General Terms: Algorithms, Design, Measurement.
Keywords: Trafﬁc Redundancy, Routing, Trafﬁc Engineering.
1.
INTRODUCTION
The basic property that some of the content on the Internet is
highly popular results some data being repeatedly transferred across
the network. A number of existing systems attempt to improve the
efﬁciency of the network by eliminating these redundant transfers.
There is wide-spread agreement that these approaches offer signiﬁ-
cant beneﬁts in practice.
A common property of existing systems is that they typically op-
erate in a localized fashion by eliminating the redundant transfers
either on the link, or of the application, directly connected to the
system. The goal of this paper is to explore some of the implications
of network-wide deployment of redundancy elimination technology.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
SIGCOMM’08, August 17–22, 2008, Seattle, Washington, USA.
Copyright 2008 ACM 978-1-60558-175-0/08/08 ...$5.00.
A majority of the redundancy-elimination systems have employed
application-layer object caching to eliminate redundant data trans-
fers. For example, Web proxy caches are an application-layer ap-
proach to reduce the bandwidth usage of static Web content within
ISPs and at large stub networks. Numerous studies [25, 11] have ex-
plored the effectiveness of such designs. In recent years, a number
of systems, both commercial [3, 4, 1, 2] and non-commercial [24],
have been developed which operate below the application layer and
attempt to eliminate any redundant strings of bytes that appear on
the network. Such systems enjoy two beneﬁts. First, they are not
tied to a single application and can eliminate all forms of redundant
information. Second, past evaluations have shown that more redun-
dant information can be removed by focusing at the packet and byte
levels than at the object level.
In this paper, we consider the beneﬁts of deploying of packet-
level redundant content elimination as a primitive IP-layer service
across the entire Internet. We start with the assumption that all fu-
ture routers will have the ability to strip redundant content from
network packets on the ﬂy, by comparing packet contents against
those recently-forwarded packets which are stored in a cache. Rou-
ters immediately downstream can reconstruct full packets from their
own cache. Applying this technology at every link would provide
immediate performance beneﬁts by reducing the overall load on the
network. It also enables new functionality: for example, it simpli-
ﬁes application layer multicast by eliminating the need to be careful
about duplicate transmissions.
However, universal redundancy elimination can yield even greater
beneﬁts if existing protocols are redesigned with redundancy elimi-
nation in mind. In this paper, we describe how wide-spread deploy-
ment of redundancy elimination can be leveraged by ISPs to change
the way they compute routes giving rise to new and improved tech-
niques for managing network resources. We analyze the beneﬁts
of selecting routes which maximize the opportunity to eliminate re-
dundant content, versus routes which minimize hop count or other
cost functions; An example is shown in Figure 1.
We consider such “redundancy-aware” modiﬁcations to both intra-
and inter-domain routing.
In our proposed approaches, ISPs ﬁrst
compute estimates of how often content is replicated across diffe-
rent destinations—we call these estimates redundancy proﬁles—and
use these estimates in computing forwarding paths for their pack-
ets. We describe how ISP routers can compute redundancy proﬁles
in parallel with forwarding packets. We also describe how ISPs
can leverage centralized route control platforms (e.g. 4d [13] or
RCP [8]) to compute network-wide redundancy-aware routes in a
scalable and efﬁcient fashion. In contrast with current state-of-the-
art practices, our redundancy-aware approaches can allow ISPs bet-
ter control over link loads, and offer them greater ﬂexibility in meet-
ing trafﬁc engineering goals and in reacting to sudden trafﬁc surges.
Figure 1: In (a), we show shortest path routing where the net-
work carriers 18 packets in all). In (b), redundant packet elim-
ination is employed on the shortest paths resulting in 12 pack-
ets total, or a 33% reduction. In (c), we use redundancy-aware
routes which minimize the total number of packets carried by
the network resulting in 10 packets total, or a 44% reduction.
We have evaluated the full range beneﬁts arising from a uni-
versal deployment of redundancy elimination, and from using our
redundancy-aware route selection algorithms. Our evaluations use
Rocketfuel topologies and workloads from full packet traces col-
lected at a large US university as well as synthetic trafﬁc models
derived from the traces. When traditional shortest path routing is
used, we ﬁnd that applying redundancy elimination on all network
links brings down the network-wide utilization by 10-50%. In con-
trast, when redundancy-aware routing is employed, we ﬁnd that the
network-wide utilization is reduced by a further 10-25%. We also
study the effect of staleness of redundancy proﬁles on route qual-
ity. We ﬁnd that the beneﬁts from redundancy-aware routing are
signiﬁcant even when trafﬁc patterns change unexpectedly and the
route computation is unable to react to the change (as might happen
during ﬂash-crowd events). Overall, we ﬁnd that a wide-spread de-
ployment of redundancy elimination can be leveraged to obtain very
signiﬁcant network-wide beneﬁts. These beneﬁts can quickly than
offset the initial high cost of deployment.
We also consider some key challenges that may hinder the de-
ployment of packet-level redundancy elimination in today’s high-
speed routers. Starting from the algorithm in [24], we make key
enhancements to the design of packet caches and to cache lookup
algorithms in order to reduce both the total amount of storage re-
quired and the number of memory accesses incurred per packet. We
have implemented these improvements in Click [18]. Our simplis-
tic implementation offers a throughput of 1Gbps in software on a
1.8GHz Linux box. We argue that, with better hardware support,
the throughput of the software implementation can easily exceed
2.5Gbps. Even higher throughputs can be attained in hardware.
This paper is structured as follows. In Section 2, we discuss a
prior approach for packet-level redundancy elimination and outline
the issues we consider in this paper. In Sections 3 and 4, we present
redundancy-aware intra- and inter-domain routing, respectively. In
Section 5, we present a measurement study of key properties of
redundant content observed in real packet traces.
In Section 6,
we evaluate the beneﬁts of universal redundancy elimination and
redundancy-aware routing. In Section 7, we present our software
router implementation of packet-level redundancy elimination. We
discuss related work in Section 8 and conclude in Section 9.
2. BACKGROUND
In this section, we present a brief outline of a popular mechanism
for packet-level redundancy elimination, and review current prac-
tices in routing and trafﬁc engineering. We then discuss the chal-
lenges in updating routing to leverage a universal deployment of
redundancy elimination. We end with a preliminary empirical study
which points to the likely beneﬁts of modifying routing in this way.
Figure 2: Packet-level redundancy detection.
2.1 Algorithm for Redundancy Elimination
We describe a fast algorithm for identifying chunks of redundant
content across packets. This algorithm has been employed in var-
ious forms in the past, e.g., for detecting duplicates in a ﬁle sys-
tem [16, 19] and for detecting worms [22]. The algorithm we dis-
cuss here was ﬁrst conceived by Spring et. al [24] who applied it to
remove redundant content from access links. Their approach oper-
ates at access routers, as packets enter or leave a stub network.
For every packet going in a particular direction, the algorithm
computes a set of ﬁngerprints by applying a hash function to each
64 byte sub-string of the packet’s payload. This choice of sub-string
size offers good performance in practice [24]. Thus, for an S-byte
packet (S ≥ 64), a total of S − 63 ﬁngerprints are obtained. Rather
than use an MD5 hash, the algorithm uses a sliding hash function
called Rabin ﬁngerprint [20], which signiﬁcantly cuts down the hash
computation time per packet [24]. A subset of these ﬁngerprints are
selected at random per packet as its representative ﬁngerprints.
Representative ﬁngerprints of all the packets observed over some
past interval of time are stored in a ﬁngerprint store at the router.
The packet payloads are stored in a packet store. Pointers are stored
from each ﬁngerprint to the corresponding packet (Figure 2).
After computing representative ﬁngerprints for an arriving packet,
each ﬁngerprint is checked against the ﬁngerprint store to check if
the ﬁngerprint already exists there. If a match is found, this means
that the incoming packet has a 64 byte sub-string that matches with
an in-cache packet. The matching packet is retrieved and the 64B
match region is expanded left and right to obtain the region of over-
lap between the two packets. The new packet is inserted into the
packet store, and the mapping in the ﬁngerprint store is updated
so that the matching ﬁngerprint points to the new packet. The re-
maining representative ﬁngerprints of the arriving packet are also
inserted into the ﬁngerprint store.
In some situations, more than
one representative ﬁngerprint of the incoming packet can observe a
match; this means that different regions of the arriving packet have
matched with distinct regions of one or more cached packets.
Each match region is removed from the incoming packet and
replaced with a shim which encodes the redundant content in the
packet. The shim provides the ﬁngerprint which caused the match,
and byte range for the matching in-cache packet. The shim can be
used by a downstream router to reconstruct the packet from its own
local cache. It is assumed that that the cache on the downstream
router is consistent with the upstream cache.
2.2 Intra and Inter-domain Routing
ISPs make intra-domain routing decisions on the basis of a packet’s
destination IP address. Since selecting static routes per destina-
tion (e.g., always using paths with small hop counts) could impact
their ability to control the load on network links, many ISPs em-
ploy trafﬁc engineering (TE) techniques. These involve estimat-
ing expected volume of trafﬁc between different locations (PoPs) in
a network [17] and computing routes so as to spread load evenly
across network links. Although ISPs are known to overprovision
their links, trafﬁc engineering is crucial to manage resources in the
face of trafﬁc variations.
When selecting inter-domain routes, ISPs attempt both to reduce
usage costs of expensive inter-domain links and to minimize the
impact of inter-domain trafﬁc on intra-domain links. Typically, ISPs
statically select the most cost-effective AS as the next hop for a
destination. Packets are sent to the next hop either along the early-
exit route or, in some cases, along an exit point that is chosen based
on mutual agreements with the neighbor.
Meeting network-wide trafﬁc engineering objectives effectively
is very challenging today (in part because of the difﬁculty in predict-
ing trafﬁc volumes accurately). In particular, current intra-domain
routing and TE practices cannot easily adjust to variations in trafﬁc
volumes. The variations could cause the load on intra-domain links
to increase beyond acceptable limits. Similarly, the load on expen-
sive and congested inter-domain links can increase signiﬁcantly as
well. In both cases, this could lead to a violation of TE objectives
and of service level agreements (SLAs) with neighboring networks.
Applying redundancy elimination on network links improves the
effective utilization of the links and provides ISPs greater ﬂexibility
in meeting their network-wide objectives. The ﬂexibility is further
enhanced when routing and trafﬁc engineering are modiﬁed to lever-
age link-level redundancy elimination.
2.3 Toward Redundancy-Aware Routing
We assume that redundancy elimination approaches such as the
one described in Section 2.1 are applied on input and output port
of Internet routers in a hop-by-hop manner. An upstream router
removes redundant content as a packet leaves it, while the router
immediately downstream reconstructs the packet as soon as it ar-
rives (assuming the packet has redundant content). All routers cache
packets that they have forwarded or received over a ﬁxed short in-
terval of time (e.g., 10s). Upstream and downstream packet caches
should be the same size and the routers must employ the same hash
functions and random seeds to ensure consistency.
To leverage a universal deployment of redundancy elimination
and improve network-wide utilization, ISPs must change the way
routes are computed today, as well as how routers act on packets.
In particular, ISPs must perform three key tasks: (1) ISPs must
ﬁrst track how packet content is replicated across different points
in their network; We call this information the “Trafﬁc Redundancy
Proﬁle”; (2) Based on the network-wide proﬁle, ISPs must then con-
struct intra and inter-domain forwarding paths which maximize the
likelihood of duplicate data traversing the same network links and,
at the same time, allow ISPs to meet their network-wide objectives;
We call this “Redundancy-Aware Route Computation”. And, (3)
Router-level redundancy elimination techniques must operate on ev-
ery packet at every router along network paths.
Our goal is to systematically understand how ISPs may imple-
ment these tasks, and show that ISPs can obtain signiﬁcant beneﬁts
in terms of controlling the loads on their links, being able to meet
their TE objectives satisfactorily, being better prepared for sudden
trafﬁc variations, and reducing usage costs and congestion on inter-
domain links. Next, we discuss initial measurements which point to
the potential beneﬁts of employing redundancy-aware routes.
Preliminary Study. We conducted a preliminary measurement
study where we tracked packets originating from a high volume /24
preﬁx owned by a large US university (the packets are headed for
the commercial Internet). Trafﬁc from the university enters its pri-
mary ISP at Chicago. We analyzed this trafﬁc using the algorithm
in Section 2.1 and found that 45% of the packet contents were du-
plicated for a 150s trafﬁc snapshot using a packet store that could
hold all packets in the snapshot; that is, the ratio of the total size
of the matched regions in all packets to the total size of all packets
was 0.45. Further, we dissected the /24 trafﬁc leaving the primary
ISP’s network from its New York, Washington DC and Boston PoPs.
About 22% of the packet contents leaving New York were dupli-
cated in the 150s snapshot. The fraction was 18% for DC and 2%
for Boston. Also, the shortest paths from Chicago (close to where
the university is located) to these cities were non-overlapping. Thus,
simply employing redundancy elimination techniques in a hop-by-
hop manner can yield savings of 2-22% (when only considering the
bytes due to the /24) on the intra-domain links of the primary ISP.
Interestingly, 10% and 9% of the contents of packets going to
New York also appeared in packets going to Boston and Washing-
ton DC. Thus, if packets to Boston and Washington DC are routed
via New York (this does not cause signiﬁcant path inﬂation) and
then redundancy elimination applied, the overall utilization of the
network links can be brought down even further.
3.
INTRA-DOMAIN ROUTING
In this section, we present our redundancy-aware intra-domain
routing approach which can help ISPs manage link loads more ef-
fectively and reduce overall network utilization. As mentioned ear-
lier, the ISP gathers information on how content is duplicated within
its network over a certain interval of time, and construct routes
which maximize the potential for redundancy elimination. We as-
sume that all ISP routers employ redundancy elimination.
To begin with, we assume that the ISP has perfect and timely
knowledge of the prevailing patterns of redundancy in its network
and that it can conﬁgure redundancy-aware paths within the net-
work in a negligible amount of time. We also assume that packets
are duplicated in full, if at all. We start with a simple setting where
we consider packets originate from a single PoP in an ISP. We ex-
tend this to a network-wide setting and construct redundancy-aware
intra-domain routes between all pairs of PoPs in the ISP.
Following this, we discuss practical issues in redundancy-aware
intra-domain routing, such as fast approaches for estimating the
redundancy patterns, accounting for partial replication of content
across packets, and computing redundancy-aware routes.
3.1 A Single PoP
We use the following abstract model to develop our approach. We
represent the ISP using a graph G = (V, E). We focus on trafﬁc
originating from a single ISP PoP, denoted by S (∈ V ). We refer
to S as the source or ingress. Nodes D1, D2, . . . , Dm ∈ V denote
the egress PoPs or destinations through which trafﬁc originating at
S exits the ISP. Other vertices in V represent ISP backbone routers.
We now model duplicated packets within the trafﬁc originating
from S. Suppose that N distinct packets {P1, P2, . . . , PN} origi-
nate at S over a certain time duration T . All other packet originating
at S in this interval are duplicates of the N distinct packets. Each
distinct packet Pi can have one or more “copies”. We use the term
“copy” in a loose sense: speciﬁcally, we consider the original dis-
tinct packet to be the ﬁrst copy. Some copies of the distinct packet
Pi may all be destined for the same destination Dj, while other
copies may be headed for other destinations.
We assume that the ISP has all information regarding destinations
of the different packet copies. Speciﬁcally, the ISP has a list of
constants cpyi,j deﬁned so that cpyi,j = 1 if a copy of distinct
packet Pi is destined for egress Dj. For instance, say that distinct
packet P1 originating at S has four copies overall, two of which are
destined for PoP D1 and one each for PoPs D3, D5. Then, cpy1,1 =
cpy1,3 = cpy1,5 = 1, and cpy1,j = 0 for all other destinations Dj.
We call this list of cpy’s the redundancy proﬁle for the trafﬁc
originating from S in the time interval T . In practice, an ISP can
compute the proﬁles as packets enter its network (Section 3.3.2).
Next, we show how the ISP can use the redundancy proﬁle to com-
pute redundancy-aware routes from S to the different Djs. We ﬁrst
deﬁne a few variables which we employ in explaining our approach.
We refer to the trafﬁc going from S to a particular destination
within the time interval T as a single ﬂow. For each ﬂow j (i.e.,
the trafﬁc to destination Dj), we deﬁne variables rtej,e such that
rtej,e = 1 if the redundancy-aware route from S to Dj goes through
edge e, and rtej,e = 0 otherwise. Binary values for rtej,e ensure
that all trafﬁc between S and Dj is routed along one path.
We use a variable F Pi,e for an edge e and distinct packet Pi to de-
note the footprint of the copies of Pi on edge e. The footprint is the
amount of resources consumed on edge e when the copies of Pi are
routed toward their respective destinations using redundancy-aware