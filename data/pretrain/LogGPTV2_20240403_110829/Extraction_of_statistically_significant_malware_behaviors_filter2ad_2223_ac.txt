stolen information to a ﬁle and sending it over the internet
respectively. SS4 resulted from creating a mutex to avoid
infecting the same computer twice. SS5 and SS6 resulted
from adding/modifying registry keys. SS7 was induced by
checking a process’s privilege.
It is important to note that the creation of the silver stan-
dard graphs is a noisy process due to the conversion of a
textual description to a system call list and its automated
Figure 3: Components of a silver standard graph of a sample
in the Banbra family
matching to subgraphs of malware SDGs. Another compli-
cation is that malware does not always perform malicious
activity every time it is run. Note, however, that the alter-
native is a manual inspection, which is also noisy and which
risks introducing experimenter bias.
4.3 Evaluation of Extracted Subgraphs
We evaluate the subgraphs extracted by our framework
using the Kruskal-based algorithm (Algorithm 1). We can
measure two quantities for these subgraphs: their p-values
and their similarities to the silver standard graphs.
To measure the similarity between a subgraph S extracted
from a malware sample and the corresponding silver stan-
dard graph Sag for that sample, we use F1, precision, and
recall scores deﬁned in the following way. Precision is the
fraction of distinct edges in S that are also in Sag, recall is
the fraction of distinct edges in Sag that also appear in S,
and F1 is the harmonic mean of precision and recall.
4.3.1 Correlation between p-values and F1 scores
The silver standard graphs were constructed with the help
of textual descriptions of malware behavior. The computa-
tion of p-values does not have access to this information.
Thus the next set of experiments are designed to measure
the level of agreement between the p-value of an extracted
subgraph and the F1 similarity score (between that sub-
graph and the silver standard graph).
We used a train/holdout/evaluation data partition as de-
scribed in Section 4.1. We used the evaluation set for ex-
tracting subgraphs and computing p-values. For reference,
the evaluation set contained executables from the malware
families Rbot, Downloader, Mydoom, LdPinch, Gaobot, On-
LineGames, Hupigon, Stration, and Banbra;
it also con-
tained the goodware openOﬃceWriter, 7zip, Bitcomet, Speed-
Fan installation, openOﬃceDraw, Chrome, mysql, winrar,
and AVG Antivirus.
For each malware sample, we ran the subgraph mining
algorithm. We computed the p-value of the returned sub-
graph along with its F1 similarity to that sample’s silver
standard graph. Ideally, the similarity score would be high
and the p-value would be low (to indicate statistical signiﬁ-
cance). Thus, the p-value of the extracted subgraph should
be negatively correlated with the F1 score.
For a quantitative assessment, we calculated Pearson cor-
relation between p-values (using the permutation method)
74
Malware
Stration
OnLineGames
Rbot
Hupigon
Banbra
Gaobot
Downloader
LdPinch
Mydoom
Correlation
-0.4123
-0.1643
-0.0289
0.5666
-0.6952
-0.3932
-0.1136
-0.2201
-0.2365
Table 2: Correlations between p-values and F1 scores of
malware samples.
and F1 scores in all malware families in the evaluation set.
The results are shown in Table 2. With the exception of the
Hupigon family, all correlations are indeed negative. The
reason that Hupigon samples had a positive correlation was
the following. This family is classiﬁed by McAfee[15] as
a backdoor.
In general, a backdoor will simply provide a
hacker with a convenient access point to a machine to en-
able future malicious activities. Without a command from
a hacker, we suspected that our backdoor samples will not
exhibit much malicious behavior. To check this, we divided
the Hupigon samples into two groups: the signiﬁcant sam-
ples, from which our framework extracted subgraphs with
low p-values, and the non-signiﬁcant samples (i.e., the rest
of the samples). There were only 2 signiﬁcant samples and
their exhibited behaviors consisted of: 1) checking access
tokens of other processes (possibly with an attempt to use
memory of another process), 2) sending data over the net-
work, and 3) checking a mutant (windows terminology for
a mutex) and creating one if it didn’t exist. There were 28
non-signiﬁcant samples and 24 of them only exhibited the
third behavior, which was part of their extracted subgraphs
and which is not necessarily malicious.
We can perform a similar experiment with goodware. From
each SDG we can extract a subgraph and compute its p-
value. We can also compute its F1 score with respect to the
best matching silver standard graph out of all malware sam-
ples.
In this case, the correlation should not be negative.
The average correlation was 0.3348.
4.3.2 Comparison of p-value computations
Recall that we presented three methods for computing
p-values: empirical, resampling, and permutation p-values.
Empirical p-values with respect to the goodware reference
population have similar interpretations to false-positive rates
(i.e., how many goodware training samples exhibit more sus-
picious behavior), while empirical p-values with respect to
the malware reference population compare a sample’s behav-
ior to typical malware behavior. Resampling p-values are an
approximation to empirical p-values, can be computed with-
out storing the training data, and can be preferable when
the size of the training data is small. Both empirical and
resampling p-values are aﬀected by how many suspicious
edges (i.e., edges more often associated with malware) there
are relative to the reference population and by how clus-
tered those edges are. On the other hand, permutation p-
values only consider the how clustered those edges are and
are essentially designed to measure whether such edges are
grouped together in a manner that is not random (e.g., they
are chained together for a common purpose).
Table 3 shows average p-values of subgraphs from mal-
ware and goodware families using the empirical, resampling,
and permutation techniques. For the case of empirical and
resampling, we show p-values with respect to malware and
goodware reference populations.
Since malware does not always exhibit malicious behav-
ior in every execution, the purpose of this table is not to
highlight malicious activity (this will be done in Section
4.3.3, where we focus speciﬁcally on samples that have low
p-values). Instead, the primary purpose of this table is to
highlight agreement/disagreement between these three ap-
proaches. For example, we notice that average p-values with
respect to goodware reference populations are lower than
with respect to malware populations (e.g., because behav-
ior that is atypical for goodware is not necessarily atypical
for malware). We also note that the average p-value of mal-
ware samples is generally lower than the average p-values for
goodware samples, even though malware does not always ex-
hibit malicious behavior. There are two malware families,
Hupigon and Gaobot, that have higher p-values than the
other malware families. They are both backdoors [15] with
similar behavior. The explanation for their high p-values is
similar to the discussion of Hupigon in Section 4.3.1.
Note that several goodware have low permutation p-values:
SpeedFan installation, Chrome, 7zip, and winrar. For Speed-
Fan installation and Chrome, the p-values are signiﬁcant. As
discussed in Section 3.2.2, the cause is due to a concentra-
tion of positive edges. For example, SpeedFan installation
contained a very large connected component that consisted
of positive edges. The system calls involved various virtual
memory and process management functions that are only
slightly more indicative of malware (in our training data)
and hence many edges had small but positive edge weights.
The empirical and resampling p-values were not signiﬁcant
because of these edge magnitudes. Note that both malware
and goodware SDGs contain edges with positive weights and
edges with negative weights. As Figure 4 shows, the posi-
tive edge magnitudes in SpeedFan installation are generally
smaller than is typical even for goodware.
Figure 4: Cumulative distribution function of positive edge
weights in SpeedFan installation and the average cumula-
tive distribution function of positive edge weights in train-
ing goodware. The cumulative distribution function that
increases fastest is the one that has more of the smaller val-
ues (i.e. more edges with smaller positive weights).
75
Family
Permutation
Kruskal-based subgraph extraction
Empirical
Resampling
Goodware-reference Malware-reference Goodware-reference Malware-reference
Stration
OnLineGames
Rbot
Hupigon
Banbra
Gaobot
Downloader
LdPinch
Mydoom
AVG Antivirus
Bitcomet
SpeedFan installation
mysql
Chrome
7zip
winrar
openOﬃceDraw
openOﬃceWriter
e
r
a
w
l
a
M
e
r
a
w
d
o
o
G
0.0736
0.0900
0.0131
0.7035
0.2088
0.7255
0.0419
0.1109
0.0013
0.6590
1.0000
0.0000
0.9710
0.0000
0.1447
0.1400
1.0000
1.0000
0.4719
0.4719
0.0612
0.4722
0.1244
0.5778
0.3066
0.2536
0.1707
0.8502
0.8014
0.5071
0.4634
0.2648
0.2190
0.2997
0.9992
0.9022
0.9286
0.9286
0.1939
0.9550
0.5134
0.9087
0.7355
0.6897
0.6386
0.9992
0.9907
0.9684
0.9831
0.9022
0.7572
0.9511
1.0000
1.0000
0.4977
0.5170
0.0707
0.5103
0.2323
0.4644
0.3640
0.2759
0.2967
0.1800
0.7067
0.7973
0.6900
0.5700
0.4907
0.7667
0.9870
0.9862
0.9405
0.9525
0.1280
0.9483
0.5192
0.9250
0.7646
0.8263
0.8733
0.7300
1.0000
1.0000
1.0000
0.9022
0.9560
1.0000
1.0000
1.0000
Table 3: Average p-values of subgraphs extracted by the Kruskal-based algorithm. Permutation, empirical, and resampling
p-values are described in Section 3.2.2. Note that malware samples do not always perform malicious activity in every execution.
Family
Stration
OnLineGames
Rbot
Hupigon
Banbra
Gaobot
Downloader
LdPinch
Mydoom
F1
0.4505
0.3041
0.4075
0.2759
0.4534
0.3884
0.3813
0.3862
0.4362
Precision Recall
0.7279
0.4977
0.4144
0.2857
0.6212
0.3675
0.4324
0.3198
0.3563
0.3836
0.2351
0.5347
0.2667
0.4490
0.4163
0.3869
0.4984
0.5625
Table 4: Average F1, precision and recall scores between the
silver standard and extracted subgraphs with permutation
p-values ≤ 0.05
Similarity scores of signiﬁcant subgraphs
4.3.3
Next, we computed similarity scores of signiﬁcant sub-
graphs with respect to the silver standard graphs. The re-
sults are shown in Table 4. We extracted a subgraph for each
executable in each malware family using the Kruskal-based
algorithm. We kept the subgraphs that were statistically
signiﬁcant (i.e. permutation p-values ≤ 0.05) and computed
the similarity of these subgraphs to the silver standard.
As an example of the types of subgraphs returned by the