# 16 揭开神秘的“位移主题”面纱

大家好，我是胡夕。今天我们要探讨的主题是 Kafka 中一个非常重要的内部主题——`__consumer_offsets`，它在 Kafka 源码中被称为**位移主题**（OffsetsTopic）。为了便于讨论，本文将统一使用“位移主题”来指代 `__consumer_offsets`。

### 位移主题的背景与引入原因

首先，我们需要了解一下位移主题被引入的背景及其原因。在老版本的 Consumer 中，位移管理依赖于 Apache ZooKeeper。Consumer 会自动或手动地将位移数据提交到 ZooKeeper 中保存，当 Consumer 重启后，可以从 ZooKeeper 中读取位移数据，从而继续从上次停止的地方消费消息。这种设计减少了 Broker 端需要持有的状态空间，有利于实现高伸缩性。

然而，ZooKeeper 并不适合高频写操作。因此，从 Kafka 0.8.2.x 版本开始，社区开始考虑修改这种设计，并最终在新版本 Consumer 中推出了全新的位移管理机制，包括新的位移主题。

### 新版本 Consumer 的位移管理机制

新版本 Consumer 的位移管理机制相对简单：**将 Consumer 的位移数据作为普通的 Kafka 消息提交到 `__consumer_offsets` 主题中**。这个主题的主要作用是保存 Kafka 消费者的位移信息。该过程不仅要求高持久性，还支持高频写操作。Kafka 的主题设计天然满足这两个条件，因此使用 Kafka 主题来保存位移是一个自然而然的选择。

需要注意的是，尽管位移主题是一个普通的 Kafka 主题，但其消息格式是由 Kafka 定义的，用户不能随意修改。Kafka Consumer 提供了 API 来帮助提交位移，用户不应自行编写 Producer 向该主题发送消息，否则可能导致 Broker 崩溃。

### 位移主题的消息格式

位移主题的消息格式可以理解为一个键值对（KV 对），其中 Key 和 Value 分别表示消息的键和消息体，在 Kafka 中它们都是字节数组。

- **Key**：包含三个部分：
  - **Group ID**：标识唯一的 Consumer Group。
  - **Topic 名称**：标识消费者订阅的主题。
  - **分区号**：标识消费者提交位移的分区。

- **Value**：除了位移值外，还包括一些元数据，如时间戳和用户自定义的数据，以帮助 Kafka 执行后续操作，例如删除过期位移消息。

此外，位移主题还有两种特殊的消息格式：
1. **用于保存 Consumer Group 信息的消息**。
2. **tombstone 消息**（墓碑消息）：用于删除过期位移甚至整个 Group。这些消息的特点是消息体为空（null）。

### 位移主题的创建

通常情况下，当 Kafka 集群中的第一个 Consumer 程序启动时，Kafka 会自动创建位移主题。默认情况下，该主题有 50 个分区和 3 个副本。这些设置可以通过 Broker 端参数 `offsets.topic.num.partitions` 和 `offsets.topic.replication.factor` 进行调整。

### 位移主题的应用

位移主题主要用于 Kafka Consumer 提交位移。Consumer 可以选择自动提交位移或手动提交位移：
- **自动提交位移**：通过设置 `enable.auto.commit=true`，Consumer 会在后台定期提交位移，提交间隔由 `auto.commit.interval.ms` 控制。
- **手动提交位移**：通过设置 `enable.auto.commit=false`，开发者需要显式调用 `consumer.commitSync()` 等方法来提交位移。

### 位移主题的消息删除策略

为了避免位移主题无限膨胀，Kafka 使用 **Compact 策略** 删除过期消息。对于同一个 Key 的两条消息 M1 和 M2，如果 M1 的发送时间早于 M2，则 M1 被视为过期消息并被删除。Kafka 提供了专门的后台线程 LogCleaner 来定期巡检待 Compact 的主题。

## 小结

今天，我们详细探讨了 Kafka 中神秘的位移主题 `__consumer_offsets`，包括其引入背景、作用、消息格式、创建方式以及管理策略。这对我们了解 Kafka 特别是 Kafka Consumer 的位移管理非常重要。实际上，将元数据以消息形式存入 Kafka 内部主题的做法越来越流行，例如 Kafka 事务也采用了类似的方法。

## 开放讨论

请思考一下，与 ZooKeeper 方案相比，位移主题可能有哪些劣势？欢迎写下你的思考和答案，我们一起讨论。

如果你觉得有所收获，也欢迎把文章分享给你的朋友。

![](https://static001.geekbang.org/resource/image/c8/bf/c89da43deab85fe7cb06acec867aa5bf.jpg)

# 17 消费者组重平衡能避免吗？

大家好，我是胡夕。今天我们要探讨的主题是：消费者组重平衡（Rebalance）能否避免？

### Rebalance 的原理与用途

Rebalance 是让一个 Consumer Group 下的所有 Consumer 实例就如何消费订阅主题的所有分区达成共识的过程。在 Rebalance 过程中，所有 Consumer 实例共同参与，在协调者组件的帮助下，完成订阅主题分区的分配。然而，在整个过程中，所有实例都不能消费任何消息，因此对 Consumer 的 TPS 影响很大。

### 协调者（Coordinator）

协调者在 Kafka 中称为 Coordinator，专门为 Consumer Group 服务，负责执行 Rebalance 以及提供位移管理和组成员管理等。Consumer 在提交位移时，实际上是向 Coordinator 所在的 Broker 提交位移。同样地，当 Consumer 应用启动时，也是向 Coordinator 发送各种请求，由 Coordinator 负责执行注册、成员管理等操作。

### Coordinator 的确定

Kafka 通过以下步骤确定某个 Consumer Group 的 Coordinator：
1. 计算 Group ID 的哈希值。
2. 将哈希值对位移主题的分区数取模，确定负责该 Group 数据的分区。
3. 找出该分区 Leader 副本所在的 Broker，即为对应的 Coordinator。

### Rebalance 的弊端

Rebalance 存在以下几点弊端：
1. **影响 Consumer 端 TPS**：Rebalance 期间，Consumer 无法进行消息消费。
2. **Rebalance 很慢**：特别是当 Group 下成员很多时，Rebalance 时间可能很长。
3. **Rebalance 效率不高**：每次 Rebalance 时，之前的分配方案不会被保留，导致效率低下。

### 如何避免 Rebalance

要避免 Rebalance，我们需要从 Rebalance 发生的时机入手：
- **组成员数量发生变化**。
- **订阅主题数量发生变化**。
- **订阅主题的分区数发生变化**。

后两个通常是运维主动操作，难以避免。因此，我们主要讨论因组成员数量变化引发的 Rebalance。

#### 组成员增加
增加 Consumer 实例的操作通常是计划内的，不属于不必要的 Rebalance。

#### 组成员减少
关键在于避免 Consumer 实例被 Coordinator 错误地认为已停止而被踢出 Group。这种情况通常发生在以下几种情况：
- **未能及时发送心跳**：通过设置 `session.timeout.ms` 和 `heartbeat.interval.ms` 参数来控制。
- **消费时间过长**：通过设置 `max.poll.interval.ms` 参数来控制。
- **GC 表现不佳**：频繁的 Full GC 导致长时间停顿，触发 Rebalance。

### 推荐配置

- **session.timeout.ms = 6s**：更快地定位挂掉的 Consumer。
- **heartbeat.interval.ms = 2s**：保证在判定为“dead”之前至少发送 3 轮心跳。
- **max.poll.interval.ms**：根据业务处理逻辑设置，留出充足的时间。

### 小结

总之，我们需要避免因参数或逻辑不合理导致的组成员意外离组或退出的情况。通过合理设置相关参数，可以大幅度降低生产环境中的 Rebalance 数量，从而整体提升 Consumer 端 TPS。

## 开放讨论

请分享你在业务场景中遇到的 Rebalance 频率、原因以及应对措施。我们一起来讨论是否有更好的解决方案。

如果你觉得有所收获，也欢迎把文章分享给你的朋友。

![](https://static001.geekbang.org/resource/image/c8/bf/c89da43deab85fe7cb06acec867aa5bf.jpg)