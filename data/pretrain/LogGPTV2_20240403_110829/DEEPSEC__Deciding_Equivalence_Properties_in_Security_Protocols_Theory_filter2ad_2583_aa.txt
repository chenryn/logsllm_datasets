title:DEEPSEC: Deciding Equivalence Properties in Security Protocols Theory
and Practice
author:Vincent Cheval and
Steve Kremer and
Itsaka Rakotonirina
2018 IEEE Symposium on Security and Privacy
DEEPSEC: Deciding Equivalence Properties in Security Protocols
Theory and Practice
Vincent Cheval, Steve Kremer, Itsaka Rakotonirina
Inria & LORIA
Abstract—Automated veriﬁcation has become an essential part
in the security evaluation of cryptographic protocols. Recently,
there has been a considerable effort to lift the theory and
tool support that existed for reachability properties to the
more complex case of equivalence properties. In this paper
we contribute both to the theory and practice of this ver-
iﬁcation problem. We establish new complexity results for
static equivalence, trace equivalence and labelled bisimilarity
and provide a decision procedure for these equivalences in
the case of a bounded number of sessions. Our procedure is
the ﬁrst to decide trace equivalence and labelled bisimilarity
exactly for a large variety of cryptographic primitives—those
that can be represented by a subterm convergent destructor
rewrite system. We implemented the procedure in a new tool,
DEEPSEC. We showed through extensive experiments that it
is signiﬁcantly more efﬁcient than other similar tools, while at
the same time raises the scope of the protocols that can be
analysed.
1. Introduction
The use of automated, formal methods has become
indispensable for analysing complex security protocols, such
as those for authentication, key exchange and secure channel
establishment. Nowadays there exist mature, fully automated
such analysers; among others AVISPA [11], ProVerif [17],
Scyther [33], Tamarin [45] or Maude-NPA [44]. These tools
operate in so-called symbolic models, rooted in the seminal
work by Dolev and Yao [35]: the attacker has full control
of the communication network, unbounded computational
power, but cryptography is idealised. This model is well
suited for ﬁnding attacks in the protocol logic, and tools have
indeed been extremely effective in discovering this kind of
ﬂaw or proving their absence.
While most works investigate reachability properties, a
recent trend consists in adapting the tools—and the un-
derlying theory—for the more complex indistinguishability
properties. Such properties are generally modelled as a
behavioural equivalence (bisimulation or trace equivalence)
in a dedicated process calculus such as the Spi [6] or applied
pi calculus [5]. A typical example is real-or-random secrecy:
after interacting with a protocol, an adversary is unable
to distinguish the real secret used in the protocol from a
random value. Privacy-type properties can also be expressed
as such: anonymity may be modeled as the adversary’s
inability to distinguish two instances of a protocol executed
by different agents; vote privacy [34] has been expressed as
indistinguishability of the situations where the votes of two
agents have been swapped or not; unlinkability [8] is seen
as indistinguishability of two sessions, either both executed
by the same agent A, or by two different agents A and B.
Related work. The problem of analysing security protocols
is undecidable in general but several decidable subclasses
have been identiﬁed. While many complexity results are
known for trace properties [36], [42], the case of behavioural
equivalences remains mostly open. When the attacker is
an eavesdropper and cannot interact with the protocol, the
indistinguishability problem—static equivalence—has been
shown PTIME for large classes of cryptographic primi-
tives [3], [27], [29]. For active attackers, bounding the
number of protocol sessions is often sufﬁcient to obtain
decidability [42] and is of practical interest: most real-life
attacks indeed only require a small number of sessions.
In this context Baudet [14], and later Chevalier and Rusi-
nowtich [24], showed that real-or-random secrecy was coNP
for cryptographic primitives that can be modelled as sub-
term convergent rewrite systems, by checking whether two
constraint systems admit the same set of solutions. These
procedures do however not allow for else branches, nor
do they verify trace equivalence in full generality. In [23],
Cheval et al. have used Baudet’s procedure as a black box to
verify trace equivalence of determinate processes. This class
of processes is however insufﬁcient for most anonymity
properties. Finally, decidability results for an unbounded
number of sessions were proposed in [26], [25], but with
severe restrictions on processes and equational theories.
Tool support also exists for verifying equivalence prop-
erties. We start discussing tools that are limited to a bounded
number of sessions. The SPEC tool [46], [47] veriﬁes a
sound symbolic bisimulation, but is restricted to particular
cryptographic primitives (pairing, encryption, signatures and
hash functions) and does not allow for else branches. The
APTE tool [20] covers the same primitives but allows else
branches and decides trace equivalence exactly. On the
contrary, the AKISS tool [19] allows for user-deﬁned cryp-
tographic primitives. Partial correctness of AKISS is shown
for primitives modelled by an arbitrary convergent rewrite
system that has the ﬁnite variant property [28]. Termination
is additionally shown for subterm convergent rewrite sys-
tems. However, AKISS does only decide trace equivalence
© 2018, Vincent Cheval. Under license to IEEE.
DOI 10.1109/SP.2018.00033
529
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:38:36 UTC from IEEE Xplore.  Restrictions apply. 
for a class of determinate processes; for other processes
trace equivalence can be both over- and under-approximated
which proved to be sufﬁcient on many examples. The recent
SAT-EQUIV tool [30] uses a different approach: it relies on
Graph Planning and SAT solving to verify trace equivalence,
rather than a dedicated procedure. The tool is extremely
efﬁcient and several orders of magnitude faster than other
tools. It does however not guarantee termination and is
currently restricted to pairing and symmetric encryption
and only considers a class of simple processes (a subclass
of determinate processes) that satisfy a type-compliance
condition. These restrictions severely limit its scope.
Other tools support veriﬁcation of equivalence prop-
erties, even for an unbounded number of sessions. This
is the case of ProVerif [15], Tamarin [13] and Maude
NPA [44] which all allow for user-deﬁned cryptographic
primitives. However, given that the underlying problem is
undecidable, these tools may not terminate. Moreover, they
only approximate trace equivalence by verifying the more
ﬁne-grained diff-equivalence. This equivalence is too ﬁne-
grained on many examples. While some recent improve-
ments on ProVerif [21], [16] helps covering more protocols,
general veriﬁcation of trace equivalence is still out of scope.
For instance, the veriﬁcation by Arapinis et al. [10] of
unlinkability in the 3G mobile phone protocols required
some “tricks” and approximations of the protocol to avoid
false attacks. In [31], Cortier et al. develop a type system and
automated type checker for verifying equivalences. While
extremely efﬁcient,
this tool only covers a ﬁxed set of
cryptographic primitives (the same as SPEC and APTE) and
veriﬁes an approximated equivalence, similar to the diff-
equivalence. A different approach has been taken by Hirschi
et al. [38],
identifying sufﬁcient conditions provable by
ProVerif for verifying unlinkability properties, implemented
in the tool Ukano, a front-end to the ProVerif tool. Ukano
does however not verify equivalence properties in general.
Contributions. We signiﬁcantly improve the theoretical
understanding and the practical veriﬁcation of equivalence
when the number of protocol sessions is bounded. We
emphasise that even in this setting, the system under study
has an inﬁnite state space due to the term algebra modelling
cryptographic primitives. Our work targets the wide class of
cryptographic primitives that can be represented by a sub-
term convergent rewriting system. Concretely, we provide
1) new tight complexity results for static equivalence (∼),
trace equivalence (≈t) and labelled bisimilarity (≈(cid:2));
2) a novel procedure for deciding trace equivalence and
labelled bisimilarity for the class of cryptographic
primitives modelled by a destructor subterm convergent
rewrite system;
3) an implementation of our procedure for trace equiva-
lence in a new tool called DEEPSEC (DEciding Equiv-
alence Properties for SECurity protocols).
We detail the three contributions below.
Complexity. We provide the ﬁrst complexity results for
deciding trace equivalence and labelled bisimilarity in the
applied pi calculus, without any restriction on the class of
protocols (other than bounding the number of sessions).
In particular, our results are not restricted to determinate
processes, allow for else branches and do not approximate
equivalence. Let us also highlight one small, yet substantial
difference with existing work: we do not consider cryp-
tographic primitives (rewrite systems) as constants of the
problem. As most modern veriﬁcation tools allow for user-
speciﬁed primitives [17], [45], [44], [19], our approach
seems to better ﬁt this reality. Typically, all existing pro-
cedures for static equivalence can only be claimed PTIME
because of this difference and are actually exponential in
the sizes of signature or equational theory. Our complexity
results are summarised in ﬁg. 1. All our lower bounds hold
for subterm convergent rewrite systems (destructor or not)
and even for the positive fragment (without else branches).
En passant, we present results for the pi calculus1: although
investigated in [18], complexity was unknown when re-
stricted to a bounded number of sessions. Still, our main
result is the coNEXP completeness (and in particular, the
decidability) of trace equivalence and labelled bisimilarity
for destructor subterm convergent rewrite systems.
Pure pi calculus
LOGSPACE
Π2 complete
∼
≈t
≈(cid:2)
Applied pi calculus
(destr.) subterm convergent
coNP complete
coNEXP complete
coNEXP complete
PSPACE complete
Figure 1: Summary of complexity results.
Decision procedure. We present a novel procedure based
on a symbolic semantics and constraint solving. Unlike most
other work, our procedure decides equivalences exactly, i.e.
without approximations. Moreover, it does not restrict the
class of processes (except for replication), nor the use of
else branches, and is correct for any cryptographic primitives
that can be modelled by a subterm convergent destructor
rewrite system (see section 2). The design of the procedure
did greatly beneﬁt from our complexity study, and was
developed in order to obtain tight complexity upper bounds.
Tool implementation. We implemented our procedure for
trace equivalence in a new tool, DEEPSEC. While still a pro-
totype, DEEPSEC was carefully engineered. The tool output
is available in pretty printed html format and allows to step
through an attack, if any is found. DEEPSEC can also dis-
tribute the computation, thus exploiting multicore architec-
tures or clusters of computers to their fullest. Finally, we in-
tegrated several classical optimisations for trace-equivalence
analysis, e.g. partial order reductions (POR) [12]. This has
appeared to reduce the search space dramatically, making
the tool scale well in practice despite the high theoretical
complexity (coNEXP).
Through extensive benchmarks, we compare DEEPSEC
to other tools limited to a bounded number of protocol ses-
sions: APTE, SPEC, AKISS and SAT-EQUIV. Our tool is sig-
1. These results are detailed in the full version [1].
530
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:38:36 UTC from IEEE Xplore.  Restrictions apply. 
niﬁcantly more efﬁcient—by several orders of magnitude—
than APTE, SPEC and AKISS, even though DEEPSEC covers
a strictly larger class of protocols than APTE and SPEC. Be-
sides, its performance are comparable to SAT-EQUIV, which
still outperforms DEEPSEC when the number of parallel pro-
cesses signiﬁcantly increase. This gap in performance seems
unavoidable as DEEPSEC operates on a much larger class of
protocols (more primitives, else branches, no limitation to
simple processes, termination guaranteed).
Part of the benchmarks consists of classical authentica-
tion protocols and focuses on demonstrating scalability of
the tool when augmenting the number of parallel protocol
sessions. The other examples include more complex proto-
cols, such as Abadi and Fournet’s anonymous authentication
protocol [5], the protocols implemented in the European
passport [37], the AKA protocol used in 3G mobile tele-
phony, as well as the Prˆet-`a-Voter [43] and the Helios [7]
e-voting protocols.
Additional details and proofs are given in the companion
technical report [2]. Implementation-related ﬁles are freely
available at [1].
2. Model
First, we present our model of cryptographic protocols
which is mostly inspired from the applied pi calculus [4].
2.1. Messages and cryptographic primitives
Data as terms. Cryptographic operations are modelled by
symbols of ﬁxed arity F = {f/n, g/m, . . .} forming a ﬁnite
signature. We partition F in two sets:
• constructors Fc: model cryptographic constructions
(encryption, signature, hash, . . . );
• destructors Fd: model inversions or operations that
may fail depending on the structure of their argument
(decryption, signature veriﬁcation, . . . ).
Example 1. The signature F = Fc∪Fd deﬁned below mod-
els standard cryptographic primitives: symmetric encryption
(senc and sdec), asymmetric encryption (pk, aenc and adec),
concatenation ((cid:5)(cid:6), proj1 and proj2) and hash (h).
Fc = {senc/2, aenc/2, pk/1, (cid:5)·,·(cid:6)/2, h/1}
Fd = {sdec/2, adec/2, proj1/1, proj2/1}
Function symbols are naturally intended to be applied
to some arguments. Atomic data—typically communicating
channels, randomness, keys—are modelled by an inﬁnite
set of so-called names N = {a, b, c, . . .}. This provides an
abstraction of low-level data whose structure is not relevant
at the protocol level. To separate public from secret data,
we partition names into two sets N = Npub (cid:7) Nprv. As
usual we deﬁne terms as the smallest set containing N
and closed under application of symbols to other terms.
E.g. if k ∈ Nprv models a decryption key, aenc(m, pk(k))
models the ciphertext obtained after encrypting m with the
corresponding public key. The set of terms built from atoms
in N by applying functions of F is denoted by T (F, N).
Behaviours as rewriting. The behaviour of symbols is
modelled by rewriting. For that, we assume an inﬁnite set of
variables X = {x, y, z, . . .} whose elements may be used as
atoms in terms. A substitution σ is a mapping from variables
to terms, homomorphically extended to a mapping from
terms to terms. Postﬁx convention tσ instead of σ(t) and
set notation σ = {x1 (cid:9)→ σ(x1); . . . ; xn (cid:9)→ σ(xn)} are the
norm; in particular we use set operators ∪ and ⊆ for domain
extension and the extension ordering, respectively.
A rewriting system R is then a ﬁnite binary relation
on terms. A pair ((cid:3), r) ∈ R is called a rewriting rule,
written (cid:3) → r and assumed to verify (cid:3) ∈ T (F,X ) and
r ∈ T (Fc, vars((cid:3))). By extension, we also use notation
t → s (“ t rewrites to s ”) when t and s are related by
the closure of R under substitution and term context. The
reﬂexive transitive closure of this relation is written →(cid:3).
Example 2. This rewriting system deﬁnes the behaviors of
the previously-introduced primitives:
sdec(senc(x, y), y) → x
adec(aenc(x, pk(y)), y) → x
proj1((cid:5)x, y(cid:6)) → x
proj2((cid:5)x, y(cid:6)) → y
The absence of rules for hash h models one-wayness.
Rewriting is however Turing-complete and restrictions
are needed to get decidability results. The ﬁrst natural
limitation is to consider only convergent systems—ensuring
existence and uniqueness of an irreducible term reachable
from t, called its normal form and written t↓. Most of the
time, we will also work under the assumptions that R is
• subterm, meaning that for all (cid:3) → r ∈ R, r is either
a strict subterm of (cid:3) or a ground term—that is a term
without variables—in normal form;
• destructor, meaning that for all (cid:3) → r ∈ R, (cid:3) is
of the form g(u1, . . . , un) where g ∈ Fd and ui
is a constructor term—that is a term whose function
symbols are all constructors.
Subterm convergent rewriting systems has been intro-
duced in [3] and is classical in protocol analysis. It indeed
includes a lot of standard primitives (see previous examples).
Sizes. The size of term t—its number of symbols—is written
|t|. Some of our complexity results are also stated w.r.t.
a succinct representation of terms as DAGs with maximal
sharing—which may be exponentially more concise. If st(t)
is the set of subterms of t, |t|dag = |st(t)| is thus the size
of its DAG representation. This deﬁnition is easily lifted to
sets and sequences of terms (with common sharing).
2.2. Processes
We model protocols as parallel processes that may ex-
change messages, modelled as terms. Plain processes are
deﬁned by the following grammar
P, Q := 0
null