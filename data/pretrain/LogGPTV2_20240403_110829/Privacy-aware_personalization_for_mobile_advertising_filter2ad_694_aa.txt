title:Privacy-aware personalization for mobile advertising
author:Michaela Hardt and
Suman Nath
Privacy-Aware Personalization for Mobile Advertising
Michaela Hardt
Twitter Inc.
∗
San Francisco, CA, USA
PI:EMAIL
Suman Nath
Microsoft Research
Redmond, WA, USA
PI:EMAIL
ABSTRACT
Mobile advertising is an increasingly important driver in the Inter-
net economy. We point out fundamental trade-offs between impor-
tant variables in the mobile advertisement ecosystem. In order to
increase relevance, ad campaigns tend to become more targeted and
personalized by using context information extracted from user’s in-
teractions and smartphone’s sensors. This raises privacy concerns
that are hard to overcome due to the limited resources (energy and
bandwidth) available on the phones. We point out that in the ab-
sence of a trusted third party, it is impossible to maximize these
three variables—ad relevance, privacy, and efﬁciency—in a single
system. This leads to the natural question: can we formalize a com-
mon framework for personalized ad delivery that can be instanti-
ated to any desired trade-off point? We propose such a ﬂexible
ad-delivery framework where personalization is done jointly by the
server and the phone. We show that the underlying optimization
problem is NP-hard and present an efﬁcient algorithm with a tight
approximation guarantee.
Since tuning personalization rules requires implicit user feed-
back (clicks), we ask how can we, in an efﬁcient and privacy-
preserving way, gather statistics over a dynamic population of mo-
bile users? This is needed for end-to-end privacy of an ad system.
We propose the ﬁrst differentially-private distributed protocol that
works even in the presence of a dynamic and malicious set of users.
We evaluate our methods with a large click log of location-aware
searches in Microsoft Bing for mobile. Our experiments show that
our framework can simultaneously achieve reasonable levels of pri-
vacy, efﬁciency, and ad relevance and can efﬁciently support a high
churn rate of users during the gathering statistics that are required
for personalization.
Categories and Subject Descriptors
K.6.5 [Management of Computing and Information Systems]:
Security and Protection; C.2.4 [Computer-Communication Net-
works]: Distributed Systems
∗Work done while at Microsoft Research.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’12, October 16–18, 2012, Raleigh, North Carolina, USA.
Copyright 2012 ACM 978-1-4503-1651-4/12/10 ...$15.00.
General Terms
Algorithms, Security
Keywords
targeted advertising, privacy, distributed systems
1.
INTRODUCTION
Mobile advertising is an increasingly important driver in the In-
ternet economy. Experts project that US mobile advertising spend-
ing, which increased 41.2% to $1.2 billion in 2011 compared with
2010, will ‘explode’ in coming years due to prevalence of smart-
phones, geolocation, and increasingly tech-savvy consumers [11].
To maximize the return of this huge advertisement spending, Inter-
net advertisers increasingly work to provide more targeted and per-
sonalized advertising. Online ads can be personalized on desktops
as well [30, 44]; however, the potential is signiﬁcantly greater for
mobile advertisement, thanks to modern smartphone’s capability
of inferring users activities and context such as location and trans-
portation mode from various sensors [34]. An online advertiser can
use users’ contexts and activities, along with their browsing and
click history, to show ads preferentially to the users who are more
likely to be inﬂuenced by the ads. If a user who likes Italian food
(inferred from her past browsing history) is found to be walking
(inferred from the accelerometer sensor data) alone (inferred from
the audio data) around lunch time, she can be shown ads of popular
(inferred from other users’ past locations) Italian restaurants within
walking distance of her current location (inferred from the GPS).
Such highly targeted advertising can signiﬁcantly increase the suc-
cess of an ad campaign in terms of the number of resulting views,
clicks or purchases on an advertised web page.
However, such personalization raises serious privacy concerns.
Personalized services rely on private and possibly sensitive infor-
mation about a user’s preferences and current and past activities.
Such information might allow for identiﬁcation of the user and her
activities. Current advertisement systems require users to com-
pletely trust these systems to not do anything bad with the infor-
mation. This trust can easily be violated, as for instance in a con-
ﬁrmed case where a Google employee spied on the accounts of four
underage teens for months before the company was notiﬁed of the
abuses [6]. Hence, a user may not be willing to share information
useful for personalization. In the previous example, the user may
not be willing to reveal the fact that she is out of the ofﬁce during
business hours. Clicks on ads personalized based on private data
can also leak information about the user [21, 29].
A personalized ad delivery system has three main components
involving private user data: statistics gathering to learn personal-
ization rules by interpreting users’ contexts and clicks as implicit
662relevance feedback, ad delivery to select the best ad for a user based
on her current context, and billing advertisers to collect money for
impressions or clicks. Each component leads to privacy concerns
that must be addressed to ensure end-to-end privacy. In this paper,
we focus on the ﬁrst two components. (We refer readers to [42] for
a private billing component.)
Privacy-Aware Ad Delivery. Current advertising systems such
as Google, Yahoo!, and Microsoft as well as many research pro-
posals efﬁciently personalize ads by collecting personal data at a
server [30, 44]. To address the privacy concerns of such server-
only personalization, several prior work proposed client-only solu-
tions that keeps personal information at the client device and per-
forms personalization at the client [39]. Several recently proposed
systems such as Privad [22] and Repriv [15] started to explore
the interesting space between server-only and client-only solutions.
Repriv [15] allows users to control how much data is shared with
the server. The personalization is carried out based on this limited
information at the server-side. Privad [22] places a proxy between
server and client to achieve anonymity of personalization requests.
The above systems optimize for various design goals and raise
one natural question: are there any fundamental trade-offs in the
design space of personalized ad delivery that these systems present?
We answer this by formalizing the task of delivering personalized
ads from a server to a client as an optimization problem with three
important variables: (1) privacy, i.e., how much information about
the user’s context is shared with the server, (2) communication ef-
ﬁciency, i.e., how few ads are sent to the client, and (3) utility, i.e.,
how useful the displayed ads are to the user in terms of revenue and
relevance. We show in Section 3 that, in the absence of any trusted
third party, it is impossible to maximize all three design goals si-
multaneously. The aforementioned previous works on personalized
ad delivery present various discrete points in the trade-off space: a
server-only solution achieves optimal efﬁciency at the cost of pri-
vacy or utility, while a client-only solution ensures optimal privacy
but sacriﬁces efﬁciency or utility.
This fundamental trade-off leads to another important question:
can we formalize a common framework for personalized ad deliv-
ery that can be instantiated to any desired trade-off point? We
provide an afﬁrmative answer to the above question with a hy-
brid framework where the personalization is done jointly by the
ad server and the client. In our framework, we formalize the task
of ad delivery as an optimization problem involving the three vari-
ables between a user and the ad server. Users can decide how much
information about their sensor readings or inferred contexts they
are willing to share with the server. Based on this limited informa-
tion, the server selects a set of ads or search results, with bounded
communication overhead, and sends them to the client. The client
then picks and displays the most relevant ad based on all the private
information. A key challenge in this framework is to choose the set
of ads sent by the server and the ad displayed at the client in a
way that maximizes utility (i.e., revenue) given constraints on efﬁ-
ciency (i.e., maximum communication cost) and privacy (i.e., max-
imum information disclosure). In other instantiations, our frame-
work can optimize a combination of revenue and efﬁciency given a
constraint on privacy. Such a ﬂexible framework is extremely use-
ful in practice as different systems may have different priorities on
these variables. We show that the optimization problem is NP-hard
and present an efﬁcient greedy algorithm for hybrid personalization
with tight approximation guarantees.
Note that several existing advertising systems such as Privad
and location based services [10, 28, 47] use a similar principle
as our framework:
the client releases limited information (e.g.,
broad interest category, cloaked region), the server chooses a set
of ads/results to disseminate to the client, and ﬁnally the client
chooses the most suitable ad/result based on private information.
Our contribution is to formally analyze the framework and to show
how to operate in a desired point in the vast trade-off space of pri-
vacy, efﬁciency, and utility. We achieve the latter by letting the
user and server ﬂexibly choose constraints on privacy, efﬁciency,
and utility. In doing so, existing personalization solutions become
special cases of our ﬂexible framework; and the framework can be
conﬁgured to explore other attractive points in the trade-off space.
Privacy-Preserving Statistics Gathering. Personalized ads are
chosen based on historical information about which ads users in a
context clicked on i.e., context-dependent click-through rates (CTRs)
of ads. However, estimating CTRs constitutes a big privacy chal-
lenge: users are often unwilling to reveal their exact contexts and
even their clicks as they leak information about their contexts. We
need to address this challenge in order to ensure end-to-end pri-
vacy of the overall ad service. One might use a distributed privacy-
preserving aggregation protocol [1, 12, 37, 40] to compute such
statistics. However, these are unsuitable for a large population of
mobile users where a small fraction of users can become unavail-
able during the course of computing CTRs. For example, a user
may turn off her mobile device any time or may want to answer
an aggregation query only at a convenient time when her phone is
being charged and connected through a local WiFi network. An-
other user might decline to participate in the exchange of certain
messages in the protocol. Yet another user might leave or join
the community of mobile users. Existing protocols [1, 12, 37,
40] do not efﬁciently handle such dynamics (more details in Sec-
tion 5.5), making them unsuitable for estimating CTRs from mo-
bile users. Then, how can we, in an efﬁcient and privacy-preserving
way, gather statistics over a dynamic population?
We answer this with a novel aggregation protocol to compute
CTRs from a highly dynamic population without a trusted server.
To the best of our knowledge, this is the ﬁrst differentially-private
protocol that computes accurate aggregations efﬁciently even when
a fraction of participants become unavailable or behave maliciously.
Note that our results can be applied to personalize not just on-
line advertising but also other online services based on users’ ﬁne-
grained contextual information including local search. For con-
creteness, we consider advertising throughout the paper.
In summary, we make the following contributions:
We have evaluated our algorithm with a large trace of location-
aware searches in Microsoft Bing for mobile. To the best of our
knowledge, this is the ﬁrst empirical study of ad-serving trade-offs
between privacy, efﬁciency, and utility with real trace. Our results
show that the trade-offs between privacy, efﬁciency, and utility are
not very strong in practice and reasonable levels of all these three
goals can be achieved simultaneously. Results also show that hy-
brid personalization achieves much better trade-offs than server-
only and client-only personalization. Finally, our statistics gather-
ing algorithm efﬁciently handles large churns of users.
(cid:73) We formalize a hybrid personalization framework with three op-
timization variables: privacy, efﬁciency, and utility. We show that
the optimization problem of personalizing ads based on private con-
texts is NP-hard and present an efﬁcient greedy algorithm with a
tight approximation guarantee (Sec. 3).
(cid:73) We develop a differentially-private protocol for estimating statis-
tics required for personalization without a trusted server. In contrast
to existing protocols, our protocol can efﬁciently handle a dynamic
set of participating users (Sec. 4).
(cid:73) We evaluate effectiveness and robustness of our solution on a
large click log of location-aware searches in Microsoft Bing for
663been used in location-based systems [3, 9, 45] to protect location
privacy. The privacy of a generalized context is measured as (1)
its number of descendants and (2) its ratio of non-sensitive descen-
dants to sensitive descendants. The user can specify a minimum
privacy requirement and we choose an appropriate cut in the con-
text hierarchy so that (1) and (2) are satisﬁed and each leaf node has
exactly one ancestor on the cut to which it is generalized, before it
is sent off to the server. This introduces uncertainty of an adversary
about whether the user is in a sensitive context or not.
Figure 1 illustrates our framework. The server periodically com-
putes various click-through-rates (CTRs) over the entire population
ofﬂine. A CTR of an ad is deﬁned as the number of clicks on the
ad divided by the number of times it is shown (impressions). These
CTR values are used to estimate relevance of ads to various con-
texts. During ad-delivery time, the user’s phone determines her
context to be doing Yoga in Dolores Park in San Francisco. How-
ever, the user decides to share only the fact that she is exercising.