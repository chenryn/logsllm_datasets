, 
· · · · · ·t:· · · ·  . 
...... 'J 
, : 
... ........ .,. ..... . . ...... : ...... . . ... : ..... . 
· 
· 
· 
. 
. 
. 
0.0 L- __    __    ___ 
0.4 
0.0 
0.2 
  __    __  --' 
0.6 
0.8  1.0 
False Positive Rate 
Taken as a whole, our analyses 
indicate 
that the exam­
realtime reputation information 
information 
are not robust enough to be used in produc­
true if additional 
aux­
from 
points in the DNS hierarchy 
[3]) is 
ined approaches 
tion environments. 
This is particularly 
(e.g., 
iliary 
various 
network vantage 
not being used to help address 
when dealing with the complexities 
where friend or foe can be easily confused. 
these techniques 
anomalous 
behavior 
use of algorithmically 
undermines 
all make the fallacious 
this assumption. 
of network traffic­
issues that arise 
to malicious 
real-world 
assumption 
that 
generated 
activity 
equates 
and so the 
names for benign purposes 
Moreover, 
V. OUR ApPROACH 
Fig. 4: ROC Curves for Jaccard Index, Edit Distance 
and 
KL Divergence 
using the daily dataset 
and CDN filtering. 
A. Shortcomings 
of Existing 
Methods 
of a KL-based classifier 
classification 
within a few minutes. 
The 
on the order of a few 
per­
decisions 
Overall, 
the application 
however, 
well, providing 
is that it required 
formed reasonably 
for all the domain clusters 
problem, 
hundred domain names in each cluster 
results. 
may take several 
threshold 
in Table ill; in particular, 
hours before a cluster 
to achieve 
required 
meets the minimum 
given 
the classification 
results 
during a one week period we 
To see why this is problematic, 
we note that it 
and performance 
issues inherent 
we present 
hypothesis 
a lightweight 
testing 
which 
of a domain 
rather than properties 
The intuition 
behind our 
host tends to "scan" the 
To address 
to classify 
approaches, 
based on sequential 
traffic patterns 
clients. 
is that a compromised 
the accuracy 
in the aforementioned 
algorithm 
examines 
name in  order 
approach 
DNS namespace 
server. 
unique second-level 
than a benign host. As a result, 
using sequential 
bots based on online observations 
In doing so, it generates 
domains that elicit 
hypothesis 
testing 
looking for a valid command and control 
more NX responses 
the problem lends itself 
clients 
[28] to classify 
of unique NX responses. 
in Figure 5. In Step 0, 
to 
as 
a relatively 
high number of 
we reduce the amount of data we analyze by over 90%, 
retaining 
Next, we extract 
and zone of the domain name from each 
client IP address 
packet (Step 8) and then filter NX responses 
only NX response 
packets. 
the 
for well-known 
to provide 
accurate 
The general 
idea is illustrated 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:50:42 UTC from IEEE Xplore.  Restrictions apply. 
DNS Packets 
DODD 
Capture NX 
Responses 
Yo D-.j.EI 
8-
[]-J 
I 
Packets 
DNS Zones 
Extract Client IPs and 
H  pothes's Test 
y 
,--------------------------------------
I 
I 
I 
Filter Benign  NX 
-   8  00 
I 
00-. -I 
I I 
...  V  ... 
I I 
I 
I 
I I 
IP#@\....DNS 
I 
I 
I :-- - - - - - - - - - - - - - - -  - ------- -
8-a:," 
1--
dent 
" 
DB  Benign,  Bot, 
8 
0 
Update Client Score 
Classify Host 
Benign 
Pending 
Zone 
0 
Fig. 5: High-level 
overview 
of the our workflow. 
A(Y) =  Pr[YIHll =  IT Pr[YiIHll  (2) 
Pr[YIHol i=1 Pr[YiIHol 
and Pr[YIHil 
where Y is the vector of events observed 
of event stream Y 
given Hi is true. The score is  then compared to an upper 
(171) and a lower threshold, 
If A(Y) ::; 1]0 
(1]0). 
then we accept Ho (i.e., 
A(Y) ?: 1]1 we accept HI (i.e., 
1]0 < A(Y) < 1]1 then we are in the pending state and must 
the host is benign) , and if 
If 
the probability 
mass function 
represents 
threshold 
wait for another 
observation. 
the host is malicious). 
I is benign. 
I is  a bot. 
success 
and updates a test 
and failure 
are calculated 
The thresholds 
values a and f3 which represent 
set to a =  0.01 and f3 =  0.99. The upper bound threshold 
the desired 
The parameters 
rates respectively. 
based on user selected 
f31se positive 
true positive 
are typically 
and 
is c31culated 
as: 
domain names (Step 8). The zone information 
of 
domain names are used to adjust the client's 
(benign) 
the remaining 
score. The score is adjusted 
the client has seen the zone before (Step 0). Finally, 
up or down based on whether 
to both a benign threshold 
new score is compared 
threshold. 
classified; 
waiting 
If either threshold 
otherwise, 
the client 
for another 
NX response 
(Step 0). 
is crossed, 
remains in the pending state 
the 
and a bot 
then the client is 
classify 
as few outcomes as possible. 
the problem by considering 
a host as a bot or 
To 
two 
Our goal is to accurately 
benign while observing 
that end, we approach 
competing 
hypotheses, 
defined as follows: 
A sequential 
hypothesis HI =  the local client 
Null hypothesis Ho =  the local client 
Alternative 
outcomes (Yi, i =  1, ... n) in sequence 
score after each outcome. 
client I towards a benign threshold 
the score towards a bot threshold. 
a  success 
outcome as follows: 
hypothesis 
test observes 
and failure 
Success Yi =  1 Client I receives 
Failure Yi =  0 Client I receives 
zone it has 31ready 
seen. 
unique DNS zone. 
A success pushes the score for 
while a failure 
pushes 
In  our context, 
we define 
an NX response 
for a DNS 
while the lower bound is computed as: 
an NX response 
for a 
f3 1]1 =  -a 
I-f3 
1]0 =-­ I-a 
(3) 
(4) 
we consider  a 
For simplicity, 
DNS namespace 
the google. com zone is administered 
that is administered 
DNS zone as a portion 
of the 
by Google). 
by a single entity (e.g., 
as the probability 
The size of the step taken towards the thresholds 
decided by the v31ues 80 and 81. The v31ue of 80 is defined 
event while 81 is the probability 
80 and 81 are 
that a benign host generates 
event. More formally, 
that a malicious 
host 
a successful 
is 
generates 
defined as: 
a  successful 
Pr[Yi =  OIHol =  80, Pr[Yi =  IIHol =  1 -80 
Pr[Yi =  OIHll =  81, Pr[Yi =  IIHll 
=  1 -81 (1) 
A key ch31lenge 
in our setting 
is that because we monitor 
DNS responses, 
sessions) 
as 
since the 
DNS traffic, including 
queries 
mostly result 
of the bot. However, 
in successful 
client-side 
from web browsing 
intern31 
hosts, we see  311 
the benign queries (e.g., 
well as the malicious 
benign activities 
we can safely filter such traffic and focus on NX responses 
(where the bot has more of an impact). 
side effect of discarding 
thereby 
further 
zones, rather than fully qualified 
We focus on second-level 
randomized 
second-level 
difficult to blacklist 
allowing 
filter the traffic by only processing 
domains since most bots generate 
domains in order make it more 
We 
second level DNS 
them and to hamper take-down 
at higher network speeds. 
domain names (FQDNs). 
of DNS packets, 
the vast majority 
This strategy 
us to operate 
efforts. 
has the 
Using the distribution 
the sequenti31 
we c31culate 
ratio) 
as follows: 
of the Bernoulli 
hypothesis 
random variable, 
score (or likelihood 
We 31so take advantage 
of the fact that NX traffic 
access patterns 
for benign hosts follows 
a Zipf's distribution. 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:50:42 UTC from IEEE Xplore.  Restrictions apply. 
in our data are to 100 
lie in the tail of the 
Indeed, 
over 90% of NX responses 
unique zones. The bot DNS queries 
Zipf curve, hidden by the vast amounts of benign traffic. 
To quickly 
Zipf filter comprising 
matches using a perfect 
declared 
re-prove 
the most popular zones' and remove 
each time a client 
benign its state is reset, 
itself. 
hash. Finally, 
forcing 
sift through this mountain 
of data, we apply a 
is 
it to continuously 
Limitations: 
A straightforward 
evasive 
strategy 
is for 
across a large time window, 
a low and slow approach. 
While 
we believe 
that doing so drastically 
to communicate 
with its command­
in a clear win for defenders. 
to increase 
our state tracking 
server - resulting 
implementing 
a bot to spread its DNS queries 
essentially 
this is a viable strategy, 
slows a bot's ability 
and-control 
Another strategy 
overhead 
said, in modern networks 
detectable, 
address 
is  a significant 
for local hosts connecting 
especially 
registration 
concern, 
is to attempt 
by making DNS requests 
practical 
from spoofed IPs. That 
IP spoofing is readily 
when media access control 
(MAC) 
is enforced. 
Alternatively, 
one could enforce DNS over TCP 
if IP spoofing 
to internal 
resolvers. 
I 
I 
. 
 0.6 . . . . . . . . . . . .  
. v  u. 8 0.4 
0.2 
Benign (All NX) 
o.oLIIL --i- __ 
10° 
...  Benign (Unique NX) 
• Malicious  (All  NX) 
Malicious (Unique NX) 
i-=====2J 
103 
10' 
10' 
NX Record Count 
Fig. 6: NX zone counts for benign and malicious 
clients. 
VI. EVALUATION 
blacklists. 
Estimating 
that 
any hosts that did not  receive 
behavior. 
was created 
we excluded 
earlier, 
As such, 
exhibiting 
The white-list 
any connections 
and then discarded 
[3, 31, 32] discussed 
from white-listed 
Unlike the approaches 
To attain ground truth for the analyses 
we 
client IPs based on NX traffic patterns. 
NX zones (e.g., 
by manually 
the top 100 zones of domain names that elicit 
. We then cross-referenced 
well-known 
in identifying 
classify 
ground truth in  our case is a list of clients 
botnet-like 
that follow, 
NX responses, 
received 
NX responses 
senderbase.org). 
inspecting 
NX responses2
from the remaining 
While this approach 
it clearly 
is of little 
yet discovered 
address 
performed 
in March to see if any of those domains were now sink­
holed. And second, we hand-labeled 
on whether they had similar 
AGDs, generated 
names that followed 
character 
NX responses. 
clients 
clients 
was helpful 
help in identifying 
In the end, we found a total 255 clients: 
on March 18th, 101 on the 19th and 88 on the 20th. 
To 
two techniques. 
we 
in the wild on the date of our analysis. 
set and length of the domain name), 
lookups on domains that received 
of at least two or more domains 
(e.g., 
and received 
clients 
as existing 
this possibility, 
name structure 
new bots that were 
the remaining 
the domain names 
NX responses 
structural 
convention 
a sequence 
we applied 
known bots, 
a similar 
against 
First, 
66 
On Parameter Selection: 
Both 80 (the probability 
event) and 81 (the probabil­
in any real-world 
event) are parameters 
deployment. 
malicious 
host sees a success 
that a benign host sees a success 
ity that a 
that must be set appropriately 
Therefore, 
our sequential 
that these parameters 
relatively 
defined a  successful 
NX responses 
they must be calculated 
framework. 
for a zone it has already 
hypothesis 
computed from a 
small amount of traffic. Recall that in §V, we 
can be robustly 
for each deployment 
of 
Fortunately, 
we show 
contacted 
at least 
once in the past, and a failure 
response 
estimate 
on  a per-client 
successes 
is generated 
these parameters, 
and failures. 
for a zone not seen previously. 
we simply track NX responses 
basis for a set window of time, counting 
outcome every time a NX 
To 
From our empirical 
analyses, 
we find that the majority 
of 
and the AGD traffic comprises 
DNS traffic is in fact benign, 
less than 2% of the overall 
within most enterprise 
by simply computing 
for all NX traffic observed 
networks, 
the percent 
allowing 
of successful 
window of time. 
in  that 
traffic. We expect this to be true 
us to estimate 80 
connections 
81, on the other hand, is more difficult. 
If 
the percent 
is fortunate 
of successes 
enough to  have 
benign from malicious 
an oracle by which 
hosts and build 
an operator 
she could separate 
ground truth for her network, 
computing 
hosts. However, 
is difficult, 
by other means. In our work, we have found that by 
less than (j failure 
discarding 
of 81 from the 
we can achieve 
remaining 
generate 
then she could infer 81 by 
hence, 81 must be estimated 
in the real world, access to such an oracle 
This is based on the fact that bots tend to 
events than benign hosts. 
if not impossible; 
approximation 
far more failure 
a reasonable 
by malicious 
that generate 
generated 
all clients 
events, 
traffic. 
of 
Figure 6 offers insight 
testing 
percent 
into why the application 
makes sense in  our setting. 
of benign hosts receive 
for four or less unique zones, while 98% of 
for four or more hosts over a 
only NX traffic, 
hypothesis 
sequential 
Notice that ninety-five 
responses 
bots receive 
NX responses 
day. Hence, by monitoring 
delineation 
this observation, 
within our network. 
we set (j =  4 for the approximation 
of 81 
between benign and infected 