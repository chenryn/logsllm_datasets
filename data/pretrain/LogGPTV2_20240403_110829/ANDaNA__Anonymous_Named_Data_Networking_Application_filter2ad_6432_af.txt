[28] T. Koponen, M. Chawla, B. Chun, A. Ermolin-
skiy, K. Kim, S. Shenker, and I. Stoica. A
data-oriented (and beyond) network architecture.
ACM SIGCOMM Computer Communication Re-
view, 37(4):181–192, 2007.
[29] P. Mittal, A. Khurshid, J. Juen, M. Caesar, and
N. Borisov. Stealthy trafﬁc analysis of low-latency
anonymous communication using throughput ﬁn-
gerprinting. In The 18th ACM Conference on Com-
puter and communications security, 2011.
[30] U. M¨oller, L. Cottrell, P. Palfrader, and L. Sas-
IETF
saman. Mixmaster protocol — Version 2.
Internet Draft, 2003.
[31] S. Murdoch and R. Watson. Metrics for security
and performance in low-latency anonymity sys-
In Privacy Enhancing Technologies Wor-
tems.
shop, 2008.
[32] Named data networking project (NDN). http:
//named-data.org.
[33] NetInf: networkd of information project. http:
//www.netinf.org/.
[34] Open network lab. http://onl.wustl.edu.
[35] L. Overlier and P. Syverson. Locating hidden
servers. In IEEE Symposium on Security and Pri-
vacy. IEEE, 2006.
[36] PURSUIT - a fp7 european union project -. http:
//www.fp7-pursuit.eu/PursuitWeb/.
[37] M. Reiter and A. Rubin. Crowds: Anonymity for
web transactions. ACM Transactions on Informa-
tion and System Security, 1(1), 1998.
[38] M. Rennhard and B. Plattner.
Introducing mor-
phmix: Peer-to-peer based anonymous internet us-
age with collusion detection. In Workshop on Pri-
vacy in the Electronic Society, Washington, DC,
USA, 2002.
[39] M. Rennhard and B. Plattner. Practical anonymity
for the masses with morphmix. In Financial Cryp-
tography, 2004.
[40] A. Serjantov and P. Sewell. Passive attack analy-
sis for connection-based anonymity systems. Eu-
ropean Symposium on Research in Computer Se-
curity, 2003.
[41] V. Shmatikov and M. Wang. Timing analysis in
low-latency mix networks: Attacks and defenses.
European Symposium on Research in Computer
Security, 2006.
[42] The OpenSSL Project. OpenSSL: The open source
toolkit for SSL/TLS. www.openssl.org.
[43] M. Wright, M. Adler, B. Levine, and C. Shields.
The predecessor attack: An analysis of a threat to
anonymous communications systems. ACM Trans-
actions on Information and System Security (TIS-
SEC), 7(4), 2004.
[44] E. Wustrow, S. Wolchok, I. Goldberg, and J. A.
Halderman. Telex: Anticensorship in the network
infrastructure. In The 20th USENIX Security Sym-
posium, 2011.
A Security Proofs
Justiﬁcation of Claim 5.1: Suppose that Claim 5.1 is
false. Then, Adv can be used to construct an algorithm
Sim that breaks the CPA-secure encryption scheme E
as follows: Sim plays the CPA-security game with a
challenger, that selects a public key pk. Sim selects a
public key pk2 and initializes Adv, that eventually re-
turns two interests int0, int1 of its choice. Sim sends
c0 = Epk2(int0) and c1 = Epk2(int1) to the challenger,
that returns c∗ = Epk(cb) = Epk(Epk2(intb)). Sim sends
(c∗, c0, c1) to the challenger that eventually returns its
choice b(cid:48). Sim outputs b(cid:48) as its choice. The output of
Sim is b(cid:48) = b iff Adv guesses b(cid:48) correctly. Since Adv
guesses b(cid:48) correctly with non negligible advantage over
1/2, Sim breaks the CPA-security of E with non negli-
gible advantage. This violates the hypothesis of Claim
5.1, and, therefore, such Adv cannot exist.
Proof of Theorem 5.1 — Consumer Anonymity (sketch).
We prove that each condition in Theorem 5.1 implies
consumer anonymity:
1. Assume that, for each u(cid:48) (cid:54)= u there exists no con-
ﬁguration C(cid:48) ≡Adv C with respect to Adv such
that C(cid:48)(u(cid:48)) = C(u). Adv cannot determine that
C(u) /∈ C(cid:48) using only C2(u), C3(u) and C4(u): if
1(u(cid:48)) for some C(cid:48) ≡Adv C and u(cid:48) (i.e.
C1(u) = C(cid:48)
there exist an indistinguishable conﬁguration with
respect to Adv where a consumer different from u
sends an interest to C1(u) through interface ifC1(u)
and u, u(cid:48) ∈ A
), then there must exist a tu-
ple C(cid:48)(u(cid:48)) = C(u) since (a possibly compromised)
r cannot process interests coming from consumers
in the same anonymity set differently – that would
imply that they are not in the same anonymity set.
Therefore, for each conﬁguration C(cid:48) ≡Adv C, and
1(u(cid:48)) = C1(u) ⇒ ∃C(cid:48)(u(cid:48)) =
for each u(cid:48) (cid:54)= u ∃C(cid:48)
C(u).
1(u(cid:48)) (cid:54)= C1(u) for all C(cid:48) ≡Adv C
For this reason, C(cid:48)
1(u(cid:48)) = C1(u).C(u) /∈
and for all u(cid:48) (cid:54)= u, i.e. ∀C(cid:48)
C(cid:48). This is true if and only if Adv controls at
i ∈ pathC4(u) for which u(cid:48)
least one interface ifr
i ∈
is not in the anonymity set of ifr
i , i.e., ∃ifr
if C1(u)
i
i
i
=
pk1,pk2
=
2, p(cid:48), int1
pk1,pk(cid:48)
2
)
pk1,pk2
(i.e., condition 1 of
pk1,pk2 and int0
pk2, int1
(r1, r(cid:48)
2, p, p(cid:48), int0, int1.
pathC4(u) ∩ IFAdv s.t. u(cid:48) /∈ Aif r
Since this con-
tradicts the hypothesis, there must exist a conﬁgu-
ration C(cid:48) indistinguishable from C with respect to
Adv such that C(cid:48)(u(cid:48)) = C(u).
(cid:54)= u, Adv can
2. We assume that, for each u(cid:48)
from u from
distinguish between interests
those from u(cid:48)
theorem
5.1 does not hold). We show how to prove
theorem 5.1 by reduction. Assume that
there
exists an efﬁcient adversary Adv such that
CAdv = C \ {u, u(cid:48)} and RAdv = R \ {r1} (i.e.,
Adv compromised all entities, except u, u(cid:48) and r1).
Suppose that C(u) = (r1, r2, p, int0
),
C(u(cid:48))
for
some
r2, r(cid:48)
For each C(cid:48), Adv out-
puts: 1 on input of C and 0 on input of C(cid:48) with
non-negligible probability, where C(cid:48)(u) = C(u(cid:48))
and C(cid:48)(u(cid:48)) = C(u). In other words, there is no
conﬁguration for which C ≡Adv C(cid:48) holds. We
sketch how Adv can be used as a subroutine in a
simulator Sim that breaks Claim 5.1.
Sim creates a random network topology N and in-
puts it to Adv. Sim also inputs the information that
Adv would obtain by compromising all entities in
N except u, u(cid:48) and r1. As such, Sim also includes
intb
pk2 received from the chal-
lenger of Claim 5.1 to the input of Adv. Then, Sim
sends to Adv conﬁgurations C and C(cid:48), where C
is identical to C(cid:48), except that C(u) = C(cid:48)(u(cid:48)) and
C(u(cid:48)) = C(cid:48)(u), and C(u) (cid:54)= C(u(cid:48)). We have that
b = 1 iff Adv outputs 1. Since existence of Sim
violates Claim 5.1, Adv cannot exits.
(cid:54)= u, Adv can
distinguish between interests from u from those
from u(cid:48) (i.e., condition 1 of theorem 5.1 does
the ﬁrst router in u’s and
not hold) and that
u(cid:48)’s paths is compromised,
i.e., condition 2
of theorem 5.1 does not hold. We then prove
theorem 5.1 by reduction. Assume that
there
exists an efﬁcient adversary Adv such that
CAdv = C \ {u, u(cid:48)} and RAdv = R \ {r2} (i.e.,
Adv compromised all entities, except u, u(cid:48) and r2).
Suppose that C(u) = (r1, r2, p, int0
),
C(u(cid:48))
some
for
For each C(cid:48), Adv out-
r1, r(cid:48)
puts 1 on input of C, and 0 on input of C(cid:48), where
C(cid:48)(u) = C(u(cid:48)) and C(cid:48)(u(cid:48)) = C(u).
In other
words, there is no conﬁguration where C ≡Adv C(cid:48)
holds. We sketch how Adv can be used as a
subroutine in a simulator Sim to determine, given
intpk2 and int(cid:48)
Sim creates a random network topology N and in-
puts it to Adv. Sim also inputs the information
that Adv would obtain by compromising all enti-
3. We assume that, for each u(cid:48)
pk2, whether int = int(cid:48).
1, p, p(cid:48), int0, int1.
1, r2, p(cid:48), int1
(r(cid:48)
pk(cid:48)
)
1,pk2
ties in N except for u, u(cid:48) and r2. Sim interacts
with the challenger of Claim 5.1 setting the in-
nermost key of its challenge, denoted as pk2, to
⊥. Sim receives intb
pk1 for some int0, int1 of its
choice, and adds intb
to the
input of Adv. Then Sim sends to Adv conﬁgu-
rations C and C(cid:48), where C is identical to C(cid:48) ex-
cept that C(u) = C(cid:48)(u(cid:48)) and C(u(cid:48)) = C(cid:48)(u), and
C(u) (cid:54)= C(u(cid:48)). We have that b = 1 iff Adv outputs
1. Since the existence of Sim would violate Claim
5.1, Adv cannot exits.
and intb
, intb
pk1,pk2
pk2
pk2
=
int(cid:48)
and
2
pk1,pk(cid:48)
pk1,pk(cid:48)
to C except
Proof of Theorem 5.2 — Producer Anonymity (sketch).
We prove that each condition in Theorem 5.2 implies
producer anonymity:
1. Let C4(u(cid:48))
let C(cid:48)
that C(cid:48)(u) =
be
identical
(C1(u), C2(u), C3(u), C4(u(cid:48))) and C(cid:48)(u(cid:48)) =
(C1(u(cid:48)), C2(u(cid:48)), C3(u(cid:48)), C4(u)).
In other words,
C(cid:48) is a conﬁguration where intpk1,pk2 is sent to
a producer different from p. In this setting, Adv
can only distinguish C(cid:48) and C by distinguishing
C(cid:48)(u) and C(cid:48)(u(cid:48)). Claim 5.1 guarantees that
Adv that observes intpk1,pk2 and int(cid:48)
cannot
determine which corresponds to int and which –
to int(cid:48). Moreover, Assumption 5.1 prevents Adv
from linking the output of non-compromised router
C1(u) with intpk1,pk2 and int(cid:48)
. Therefore,
C ≡Adv C(cid:48).
and let
pk1,pk(cid:48)
C(cid:48) be identical
that C(cid:48)(u) =
(C1(u), C2(u), C3(u), C4(u(cid:48))) and C(cid:48)(u(cid:48)) =
(C1(u(cid:48)), C2(u(cid:48)), C3(u(cid:48)), C4(u)). We assume that
C1(u) and C1(u(cid:48)) are compromised.
In this set-
ting, Adv can only distinguish between C(cid:48) and C
by distinguishing C(cid:48)(u) and C(cid:48)(u(cid:48)). Claim 5.1
guarantees that any Adv that observes intpk1,pk2
and int(cid:48)
cannot determine which corresponds
to int and which – to int(cid:48). Moreover, Assumption
5.1 prevents Adv from linking the output of non-
compromised router C2(u) with intpk2 and int(cid:48)
.
pk(cid:48)
Therefore, C ≡Adv C(cid:48).
let C4(u(cid:48)) = int(cid:48)
to C except
2. Similarly,
pk1,pk(cid:48)
pk1,pk(cid:48)
2
2
2
2
2
B Performance Evaluation: Additional Results
Figure 3. Round trip time for transferring 1, 10 and 100MB of content over NDN (limited anonymity)
 0 20 40 60 80 100 120 0 0.5 1 1.5 2 2.5 3RTT (ms)Start Time (s) 0 20 40 60 80 100 120 0 2 4 6 8 10 12 14 16 18RTT (ms)Start Time (s) 0 20 40 60 80 100 120 0 20 40 60 80 100 120 140 160RTT (ms)Start Time (s)Figure 4. Round trip time for transferring 1, 10 and 100MB of content over ANDaNA (full anonymity).
 0 20 40 60 80 100 120 0 0.5 1 1.5 2 2.5 3RTT (ms)Start Time (s) 0 20 40 60 80 100 120 0 2 4 6 8 10 12 14 16 18RTT (ms)Start Time (s) 0 20 40 60 80 100 120 0 20 40 60 80 100 120 140 160RTT (ms)Start Time (s)