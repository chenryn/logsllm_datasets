circle, and triangle, at three different feed rates (15, 22.5, and
30 mm/sec). The increase in head travel speed changes the spec-
trogram in a systematic way.
are important for both additive and subtractive manufacturing, and
must be speciﬁed to control machines as disparate as a 3D printer
and a CNC mill. Further, while prior research in the manufactu-
ring community has concluded that many aspects of fabrication
have inherent acoustic signatures, no signatures that specify these
parameters have been established in previous work.
We describe tool head location and direction with respect to the
platform of a machine, which deﬁnes an implicit XY plane and an
associated Z axis. Different machines have different constraints in
traversing this space, and reconstruction can take advantage of these
constraints to simplify the task. For example, a typical 3D printer
builds up an object in horizontal layers. At any given layer, the
printer head moves in an XY plane and can trace any angle in that
plane with respect to the X axis. The printer slowly works its way
up the Z axis, emitting a characteristic sound from this movement.
Further, in an object with multiple layers, each layer must either
overlap the previous layer or have its own support material, so
a layer’s shape is constrained by the previous layer. Likewise, a
subtractive manufacturing operation generally removes material
adjacent to material it has already removed, and subtractive methods
typically also work in layers. We take advantage of this layer-focused
machine behavior by restricting our attention to the XY plane for a
ﬁxed value of Z, i.e., a given layer. Our reference and training data
and validation experiments use nearly-planar objects: 3D prints two
layers thick and shallow cuts with the mill.
Any planar ﬁgure that can be manufactured by machines like
CNC mills and 3D printers can be speciﬁed as a sequence of tool
head movements to be made at particular angles to the X axis for
particular straight-line distances (with curves described by short
tangential segments). We reconstruct both these angles and the
distances. As it can be hard to visualize the tool head trajectories and
phone placements we discuss, readers may wish to refer to the videos
of our printer and mill in action, and an example reconstruction
session, at https://goo.gl/FijZ9T.
The 3D printer head can travel at different speeds (feed rates). As
shown in Figure 3, the printer’s audio signature for a particular angle
changes in a systematic way as the feed rate changes. Zooming in on
these high-resolution ﬁgures, we see that the pattern in the ﬁgure’s
three spectrograms compresses in time and shifts up in frequency as
885overlapping Hanning windows is a standard technique in audio pro-
cessing that helps to reduce the noise in the signal by smoothing it
out. The use of 2048 frequency points gave sufﬁcient resolution for
reconstruction.
When recordings are made in a manufacturing environment, the
audio contains background noise whose energy spreads across all
frequency bands, and in general the background noise energy tends
to decrease as the frequency increases. We found that for recon-
struction to succeed, it is important to reduce this background noise,
especially at low frequencies, to emphasize the useful content of the
audio signal. Thus the third step in building the audio library is to
perform noise normalization in the frequency domain. We estimate
the background noise covariance matrix Rnn based on a portion
of the recording when the machine is idle. Assuming noise is un-
correlated across frequencies, we use Rnn to normalize the signal
spectrogram as follows:
(cid:32)
(cid:112)diag(Rnn) + 
1
Xwhite = diag
(cid:33)
× X,
Figure 4: Raw sensor data from the three axes of the accelero-
meter and magnetometer while 3D printing a square. The rea-
dings vary predictably, providing additional information not
fully captured in audio recordings. We found readings from the
magnetometer to be more accurate than those from the accele-
rometer in explaining tool head movement.
the feed rate increases, though the human eye quickly recognizes
that the high-level pattern is unaffected. For this reason, we focus
on the printer’s default feed rate of 30 mm/sec.
Figures 4 and 5 show example data from the phone accelerometer,
magnetometer, and microphone. The reconstruction method uses
audio and magnetometer data when both are available and just audio
otherwise. When multiple reconstructed objects are consistent with
the results produced by signal processing and machine learning, the
reconstruction method uses a search process, domain constraints,
and human assistance to rule out unlikely and impossible reconstruc-
tions.
We reconstruct the angle of travel of the machine tool head by
comparing its audio to examples in a prerecorded reference library.
We found that angles that are just a few degrees apart have very
different audio signatures, so the recordings for the library need to
include each angle that might be used to fabricate a target object.
These recordings could be obtained from a similar machine model
that the attacker plans to use to fabricate stolen designs or processes.
Alternatively, as discussed in Section 4, the necessary calibration
pattern could be hidden in the design of an object fabricated on a
machine belonging to the victim or a third party, and recorded in an
attack launched speciﬁcally to gather that information for the library.
The result is a library of audio signatures that the machine produces
for each angle of movement.
To build an audio signature library, we ﬁrst use a cell phone to
record the sound that the machine produces when it moves along
potential angle of interest. In this study, we used 1 degree of resolu-
tion, recording angles from 0 to 359 degrees. The sampling rate of
the cell phone recording was 44100 samples/second, the default.
The second step is to transform the recorded audio from the ti-
me domain to the frequency domain using a short time Fourier
transform (STFT), and then produce a magnitude spectrogram. We
used the Matlab function spectrogram for this purpose, with a Hann
(Hanning) window of length 2048 samples, an overlap of 25% bet-
ween successive windows, and 2048 frequency points. The use of
where X is the magnitude spectrogram for the recording, and  =
1 × e−8 is a constant used to avoid dividing by zero. To further
reduce the effect of background noise and unwanted interference
in the library, we average all the frames of the signal of the same
angle along the time dimension of the spectrogram. The result is 360
frames, corresponding to the 360 angles of movement illustrated in
Figure 6. Each frame is the audio signature of the machine head at a
particular angle across frequencies.
Figure 6 shows that most of the information needed to decide what
angle the machine is moving at is concentrated at low frequency
bands. Further, signal artifacts such as aliasing are visible at high
frequency bands. Therefore we select only frequencies below a
cutoff frequency fc for further processing, saving the results in the
reference library. We also record the domain constraints speciﬁc to
that machine, such as its platform size and the value of fc.
After these signal processing steps, the audio of each 3D prin-
ter angle a appears very similar to that of the three other angles
created by mirroring the given angle in each quadrant of the plane
(±a, 180±a); this introduces ambiguity into reconstruction. Simi-
larly, each mill angle sounds like 15 other angles, produced by
mirroring across the X and Y axes and the ±45 and ±135 degree
lines. We suspect that more sophisticated audio signal processing
techniques that can pick out the secondary tones visible in our spec-
trograms (and audible to a keen ear) can be used to tell these angles
apart, but that remains for future work, and we rely on two other
disambiguation techniques described later: magnetometer data and
a search process that exploits domain constraints. For simplicity, the
discussion that follows is written as though the library contains just
one reference angle audioclip for each set of ambiguous angles, e.g.,
only ﬁrst quarter angles for the 3D printer. However, for ease of
incorporating new domain constraints and information from other
sensors, our actual implementation retains reference data for all
angles.
With the reference library in hand and a target object to recon-
struct from its fabrication audio, we begin by cleaning up the audio
by applying the same ﬁrst four signal processing steps as for refe-
rence audioclips: deﬁne overlapping frames, produce a magnitude
spectrogram, normalize with respect to background noise, and retain
only the relevant frequency band. Then we ﬁnd the most likely angle
for each frame of the cleaned-up audio by comparing it to all of
the reference library’s angle frames and ﬁnding the one it is most
correlated with. More precisely, we use a custom matched ﬁlter
886Figure 5: A comparison of the spectrograms from the 3D printer recorded locally (center top), the CNC mill recorded locally (center
bottom), and the CNC mill recorded on the other end of a phone call (right column). The right column compares three phone call
recordings: no speech (right top), speech 2 ft from the recording microphone (right center), and speech directly at the receiving
microphone (right bottom). The annotations illustrate how the spectrograms correspond to the fabrication processes. The spectro-
grams from recordings of the fabrication of the same turbine blade shape display a trace in a consistent shape, even across different
machines; each contains sufﬁcient information to reconstruct the shape. Additionally, while speech overlaps with the frequencies that
indicate machining, the traces are not fully obscured.
Figure 6: Example magnitude spectrograms for audio data: juxtaposed magnitude spectrograms of 360 different angles of machine
head travel with a 3D printer (left) and CNC mill (right). This data is used in a reference library during reconstruction.
function3 to compute the correlation between the audio frame and
each of the reference library frames; this is a standard technique
for comparing two audio samples. The result is one value for each
combination of a target audio frame and a library angle. For each
target audio frame, we select the library angle with the highest cross
correlation value for that frame: this is our best guess angle for that
moment of the fabrication. Then we present the results to the user,
as shown in Figure 7’s screenshot of our interactive reconstruction
framework. The screen shows the spectrogram of the target audio,
aligned along the time axis with a matched ﬁlter visualization, where
the height of each match head indicates the reference library angle
selected for that frame in the audio. When magnetometer data is not
available, this completes the automated signal processing phase of
the reconstruction.
Next, the search phase begins, with optional human assistance to
3For an explanation of matched ﬁlters, see goo.gl/Nrjojv.
steer the framework’s search process. To prepare for this role, a user
requires only brief training in how to recognize changes of angles
and the start/stop of tool work in audio magnitude spectrograms.
In our current framework implementation, the user has two tasks.
First is to click on the points in the audio at which the tool head
changes its angle; these points can be seen quite easily as the edges
of the vertical bars in the spectrogram. The identiﬁed points divide
the manufactured object into a series of straight-line tool head runs,
which we call segments. From watching a video of the 3D printer,
framework users learned several constraints that were useful to
them during segmentation. The ﬁrst two are generic to 3D printing:
the printer begins and ends each run with a particular movement
sequence; and the printer fabricates a 1-layer bounding box around
all the closed ﬁgures it will subsequently construct during the run.
Users also observed a third constraint speciﬁc to the 2-layer objects
we were building: after fabricating the ﬁrst layer of an object, the
887Figure 7: In-progress reconstruction of a 3D-printed star, with spectrogram above and matched ﬁlter beneath. Changes of tool head
direction are visible as yellowish vertical bars in the spectrogram. The audio has been segmented and the search for a reconstruction
that satisﬁes domain constraints is underway. The reconstruction at the lower right will be automatically rejected because it is not a
closed ﬁgure; the ﬁrst erroneous angle is off by 180 degrees, and its mirror image will be considered later in the search.
Figure 8: Segmented audio magnitude spectrogram, magnetometer signal in the X dimension, and regression lines for each segment.
The 3D printer is fabricating a 2-layer diamond shape, and the sign of the slope of each regression line indicates whether the angle
for that segment lies above or below the printer platform’s X axis. The magnitude of a segment’s peaks indicates how far forward
on the platform that segment’s fabricated line lies, which can be helpful for establishing a canonical orientation for the object being
manufactured.
888tool head retraces its path in reverse to construct the second layer.
Together, these three constraints helped the user identify the ﬁrst
and last segment of each fabricated object.
The duration of each segment multiplied by the machine’s feed
rate gives the physical length of each linear segment in the recon-
structed shape, so the accuracy of segmentation affects the accuracy
of the ﬁnal reconstruction. In our experiments, we did not focus on
trying to get segment lengths exactly right. We expect that signal
processing techniques can be used to automate segmentation in the
future, and may be more accurate than a human.
The interactive framework automatically shows the user-selected
segment boundaries superimposed on the spectrogram and its ac-
companying matched ﬁlter timeline. The most common matched
ﬁlter head height in a segment is the best guess angle for that seg-
ment. For example, the third and tenth segments of the audio in
Figure 7 will have only one suggested angle, while the sixth and
seventh will have two.
The user’s second task is to provide optional guidance to speed
up the search process. For example, suppose that the ﬁrst choice
angles for all segments do not produce a reconstruction. While the
search process can automatically identify the segments with the most
uncertainty in the matches, and automatically identify the second
most likely angle for each, the user can also guide this process by
clicking on the matched ﬁlter head heights (angles) that she would
like the search to consider next. This ﬂexibility is particularly useful
when the framework does not have a full set of domain constraints.
For example, we implemented a domain constraint that the tool head
must move at different angles in adjacent segments. Without this
constraint, the framework might assign the same angles to segments
6 and 7 in Figure 7, but the user could click to force the use of
different angles.
Each matched ﬁlter head height may correspond to several dif-
ferent mirrored angles in the reference library. Thus in our experi-
ments, a k-sided 3D-printed object has an audio-only reconstruction
search space of roughly 4k potential objects. (When magnetometer
readings are available, the search space shrinks to roughly 2k, as
explained below.) Fortunately, manufacturing domain constraints
allow us to prune away most of the search space. We implemented
two constraints generic to 3D printing. The ﬁrst constraint is that a
layer should not cross over itself. More precisely, each segment in
a layer should intersect exactly two other segments, one at each of
its endpoints, except that the ﬁrst and last can intersect either one
or two other segments. The second constraint is that at the end of
a segment, the printer head should change its angle of travel rather
than continuing in a straight line or (unless it is the end of a layer)
doubling back on itself. We implemented a third constraint speciﬁc
to the kinds of objects we were building: each object layer should
form a closed ﬁgure in the plane. The framework automatically
explores the search space not eliminated by these constraints and
displays the resulting reconstructions to the user, who can accept or
reject them. If unhappy with all the reconstructions shown, the user
can click on additional matched ﬁlter head heights for a segment, so
that additional angles will be considered.
In theory, a phone’s magnetometers could tell us whether each
nearby motor in a machine is accelerating, decelerating, or holding
steady, and for how long; from that information we could determine
the exact path the tool head traces. In practice, however, we only
found magnetometer data useful for reliably distinguishing between
angles a and −a for the 3D printer. This means that when we have
both magnetometer and audio data for a fabrication run on the 3D
printer, each angle appears very similar to only one other angle,
its mirror image across the X axis. In other words, de facto, with
the phone located near the corner of the printer, its magnetometer
registers the machine platform’s forward and back movement during
fabrication, but does not pick up a signal from the machine’s other
motors and movements.
To illustrate the disambiguation, consider the example three-
dimensional magnetometer signal in Figure 8, which was recorded