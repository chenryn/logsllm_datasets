# Concurrency and I/O Wait Analysis

- **Concurrency (1/100) % vs. I/O Wait %**: 
  - This metric compares the percentage of I/O wait time to the concurrency level, with a focus on a 1/100 ratio.

- **Dense Searches % CPU Utilization vs. Concurrency (1/100)**:
  - This metric measures the CPU utilization during dense searches at different concurrency levels, specifically at a 1/100 ratio.

- **Dense Searches + Indexing % CPU Utilization vs. Concurrency (searching 1/100)**:
  - This metric evaluates the CPU utilization when both dense searches and indexing are performed, again at a 1/100 concurrency ratio.
  - **Indexing Throughput vs. Concurrency (searching 1/100)**: 
    - This metric assesses the indexing throughput while searching at a 1/100 concurrency ratio, comparing the performance with and without indexing enabled.

## Dense Search Test Conclusions

- **Dense workloads are CPU-bound**:
  - Workloads such as reporting and trending are primarily limited by CPU performance.
  - **Impact of Indexing**:
    - While indexing is active, the throughput decreases by approximately 40%, but the search time increases only marginally.
    - Faster disks may not significantly improve performance because most of the time in dense searches is spent on CPU tasks, such as decompressing raw data and processing SPL.
    - **Improvement Suggestions**:
      - Increasing the number and speed of CPUs would enhance overall performance.

## Rare Searches Analysis

- **Rare Searches % CPU Utilization vs. Concurrency (1/M, 1/100M)**:
  - This metric measures the CPU utilization for rare searches at different concurrency levels, specifically 1/M and 1/100M.
  - **I/O Reads/s (sar) and I/O Wait %**:
    - These metrics track the I/O reads per second and the I/O wait percentage during rare searches.

- **Rare Searches + Indexing % CPU Utilization vs. Concurrency (1/M, 1/100M)**:
  - This metric evaluates the CPU utilization when both rare searches and indexing are performed, at 1/M and 1/100M concurrency levels.
  - **I/O Reads/s (sar) and I/O Wait %**:
    - These metrics also track the I/O reads per second and the I/O wait percentage during these operations.

## Rare Search Conclusions

- **Rare workloads are I/O-bound**:
  - Investigative and ad-hoc workloads are primarily limited by I/O performance.
  - **Impact of Indexing**:
    - When indexing is enabled, search times increase significantly, and indexing throughput is also negatively affected.
    - **Bloom Filters**:
      - Bloom filters, which are special data structures, help by indicating with 100% certainty that a term does not exist in a bucket, thus allowing the search process to skip that bucket.
      - In the case of 1/100M searches, bloom filters save I/O, which in turn improves indexing throughput.
    - **CPU Consumption**:
      - During 1/100M searches with indexing enabled, CPU consumption is higher.
      - **Improvement Suggestions**:
        - Faster disks would significantly help, but more CPUs would not have a substantial impact.

## Determining CPU or I/O Bound Searches

- **Guidelines**:
  - **CPU-Bound**:
    - Commands like `command.search.rawdata`, `.kv`, `.typer`, and `.calcfields` are generally CPU-bound.
  - **I/O-Bound**:
    - The `command.search.index` command is typically I/O-bound.

## Top Takeaways and Recap

### Indexing
- **Distribute**:
  - Splunk scales horizontally.
- **Tune Event Breaking and Timestamp Extraction**:
  - Proper tuning can improve performance.
- **Faster CPUs**:
  - Faster CPUs will enhance indexing performance.

### Searching
- **Dense Search Workloads**:
  - **CPU-Bound**:
    - Dense searches perform better with indexing than rare searches.
- **Rare Search Workloads**:
  - **I/O-Bound**:
    - Rare searches do not play well with indexing.
    - **Bloom Filters**:
      - Bloom filters significantly help by saving I/O.
    - **Faster Disks**:
      - Faster disks, especially SSDs, will help.
    - **More CPUs**:
      - More CPUs will not have a significant impact.

### Performance Optimization
- **Avoid Generality**:
  - Optimize for the expected use case.
- **Add Hardware**:
  - Add more distribution, faster CPUs, and faster disks (SSDs) as needed.

## Additional Resources
- **Architecting and Sizing Your Splunk Deployment**
- **Jiffy Lube Quick Tune-Up for Your Environment**
- **Splunk Monitoring Console**

## Testing Disclaimer
1. Testing was conducted on arbitrary datasets.
2. The testing environment was a "closed course" (lab) setting.
3. Results should not be interpreted out of context.

## Thank You
- For any feedback, please contact: [Your Email Address]

---

Copyright Â© 2014 Splunk Inc.