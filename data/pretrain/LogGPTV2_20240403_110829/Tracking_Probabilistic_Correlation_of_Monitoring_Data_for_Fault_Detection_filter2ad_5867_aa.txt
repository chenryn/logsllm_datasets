title:Tracking Probabilistic Correlation of Monitoring Data for Fault Detection
in Complex Systems
author:Zhen Guo and
Guofei Jiang and
Haifeng Chen and
Kenji Yoshihira
Tracking Probabilistic Correlation of  
Monitoring Data for Fault Detection in Complex Systems  
Zhen Guo* 
Guofei Jiang, Haifeng Chen, Kenji Yoshihira 
Robust and Secure System Group 
NEC Laboratories America 
 Princeton, NJ 08540 
Email: {gfj,haifeng,kenji}@nec-labs.com
systems,  databases,  servers  and networking  devices,  a  
single fault could cause the whole service down. While 
building  a  fault-free  system  of  such  complexity  is 
unrealistic,  it  is  very  desirable  to  have  effective  fault 
detection and  isolation methods  in  operational  system 
management.  Studies  [1]  have  shown  that  the  time 
taken to detect and isolate faults is a major contributor 
to  mean  time  to  repair  (MTTR),  defined  to  be  the 
average amount of time required to resolve problems. 
For  example,  on  November  1,  2005,  trading  on  the 
Tokyo stock market was suspended for four hours after 
its  IT  systems  failed.  Therefore,  effective  fault 
detection  and  isolation  is  critical  for  improving  the 
reliability and availability of mission critical systems. 
is  often  scattered 
Meanwhile, large amount of monitoring data can be 
collected  from  distributed  systems  for  fault  analysis 
such  as  software  log  files,  system  audit  events  and 
network  traffic  statistics.  In  fact  this  monitoring  data 
can be regarded as the observables of the internal states 
of  dynamic  systems.  However,  given  the  distributed 
nature  of  complex  information  systems,  evidence  of 
fault  occurrence 
in  various 
monitoring  data  collected  across  distributed  systems 
and observation time. Therefore, one challenge is how 
to  correlate  the  monitoring  data  effectively  for  fault 
analysis.  Internet  services  have  large  number  of  user 
requests  everyday  and  much  of  the  monitoring  data 
reacts to the volume of user requests accordingly when 
user  requests  flow  through  the  system.  For  example, 
network traffic volume and number of web server log 
entries change in accordance with the volume of user 
requests.  Therefore  we  can  model  the  correlation 
between various monitoring data collected at multiple 
points  for  fault  analysis.  Recently  we  proposed  to 
model  and  track  transaction  flow  dynamics  for  fault 
detection  in  complex  systems  [2].  We  calculated  the 
flow  intensity  from  monitoring  data  to  measure  the 
intensity with which various monitoring data responds 
to the volume of user requests. Segments of distributed 
Dept. of Electrical & Computer Engineering 
New Jersey Institute of Technology 
 Newark, NJ 07102 
Email: PI:EMAIL 
Abstract 
to 
Due 
their  growing  complexity, 
it  becomes 
extremely  difficult  to  detect  and  isolate  faults  in 
complex  systems.  While  large  amount  of  monitoring 
data  can  be  collected  from  such  systems  for  fault 
analysis,  one  challenge  is  how  to  correlate  the  data 
effectively  across  distributed  systems  and  observation 
time.  Much  of  the  internal  monitoring  data  reacts  to 
the  volume  of  user  requests  accordingly  when  user 
requests flow through distributed systems. In this paper, 
we  use  Gaussian  mixture  models  to  characterize 
probabilistic  correlation  between 
flow-intensities 
measured at multiple points. A novel algorithm derived 
from  Expectation-Maximization  (EM)  algorithm  is 
proposed  to  learn  the  “likely”  boundary  of  normal 
data relationship, which is further used as an oracle in 
anomaly  detection.  Our  recursive  algorithm  can 
adaptively  estimate  the  boundary  of  dynamic  data 
relationship  and  detect  faults  in  real  time.  Our 
approach is tested in a real system with injected faults 
and the results demonstrate its feasibility.  
1.  Introduction 
The  prevalence  of  Internet  services  such  as 
Google.com  and  Amazon.com  has  dramatically 
changed  our  daily  life.  Due  to  the  growing  scale  and 
complexity  of  the  information  systems  underlying 
Internet  services,  there  are  unprecedented  needs  to 
ensure  their  operational  reliability  and  availability. 
Minutes  of  service  downtime  can  lead  to  severe 
revenue  loss  and  users’  dissatisfaction.  While  a  large 
Internet  service  usually  consists  of  thousands  of 
components  such   as  application  software,  operating   
______________________________________________ 
* The work was performed when the author worked with   
Dr. Guofei Jiang as a summer Intern at NEC Labs.
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:26:44 UTC from IEEE Xplore.  Restrictions apply. 
flow 
systems are regarded as input-output dynamic systems 
and  linear  regression  models  are  used  to  characterize 
the  correlation  among  various 
intensities 
measured at multiple points across the system. Further 
these models are used as oracles in model-based fault 
detection  and 
such 
correlations  could  have  linear  property,  some  other 
measurements may only have probabilistic relationship 
among  them  due  to  many  uncertainties  embedded  in 
systems such as caching. In this paper, we extend our 
previous  work  and  propose  to  model  and  track  such 
relationships  with  Gaussian  Mixture  Models  (GMMs) 
for fault detection.                   
isolation.  While  many  of 
they  also  manifest 
is  employed 
flow 
to  describe 
intensities  calculated 
Tracking probabilistic relationship for fault analysis 
is essentially an anomaly detection problem.  In general, 
an underlying model is learned or extracted from given 
data  samples  and  then  a  new  data  point  is  evaluated 
against  the  model  to  derive  its  deviation  score.  In 
practice,  run-time  faults  are  rare 
in  operational 
environments  and 
themselves 
differently in various situations. Therefore it’s usually 
difficult  to  characterize  faults  directly  in  complex 
systems.  Conversely,  we  have  sufficient  monitoring 
data  collected  from  endless  business  transactions  to 
model normal  system  behavior.  In  this paper, a  finite 
the  probability 
GMM 
distribution  of 
from 
monitoring data. A new variant of EM algorithm [3][4] 
is  used  to  learn  the  parameters  of  Gaussian  mixtures 
and  further  estimate  a  boundary  of  normal  data 
distribution. In fact we use this boundary to distinguish 
outliers from normal data points, i.e., detect the outliers 
with  extremely  low  probability  density.  Our  fault 
detection algorithm is derived from an online recursive 
EM algorithm so that it can adapt to system and load 
changes.  In  addition,  we  propose  a  procedure  to 
automatically 
and  validate  probabilistic 
relationships  between  each  pair  of  monitoring  data. 
Our  approach  is  tested  in  a  real  system  with  injected 
faults and the results demonstrate its feasibility. 
2.  Related work 
search 
r3 
There  is  much  work  about  fault  detection  and 
isolation  in  telecommunication  network  management. 
Yemini et al. [5] proposed a “Codebook” approach for 
high speed and robust event correlation. Chao et al. [6] 
developed  an  automated  fault  diagnosis  system  using 
hierarchical reasoning and alarm correlation. Recently, 
Benveniste et al.[7] employed a net unfolding approach 
originating  from  the  Petri  net  research  for  distributed 
fault diagnosis. All these methods collect and correlate 
events  to  locate  faults  based  on  known  dependency 
knowledge  between  faults  and  symptoms.  While  this 
knowledge can be derived from network topology  for 
telecommunication  network,  it  is  very  difficult  to 
obtain  such  kind  of  knowledge  in  large  and  complex 
information systems.  
[2]  proposed 
The Berkeley Recovery-Oriented Computing (ROC) 
group  modified  the  JBoss  middleware  to  trace  user 
requests  in  the  J2EE  platform,  and  developed  two 
methods to use collected traces for fault detection and 
diagnosis [1]. However, with regard to huge volume of 
user visits, it is difficult to monitor, collect and analyze 
the  trace  of  each  individual  user  request.  Based  on 
commonly available monitoring data such as log files, 
track 
recently  we 
transaction  flow  dynamics  for  fault  detection 
in 
complex  systems.  However,  we  only  employed  linear 
characterize 
regression  models 
dynamic 
to 
relationships  among  flow 
intensities  measured  at 
multiple  points.  In  this  paper  we  propose  to  use 
Gaussian mixtures to model probabilistic relationships 
of  monitoring  data  and  further  use  these  models  for 
fault  detection.  As  illustrated  in  our  experiments,  due 
to system dynamics and uncertainties, we believe that 
some  measurements  may  only  have  weak  and 
probabilistic correlation rather than linear relationship.         
to  model  and 
then  detects  failures  by 
Vaarandi  [8] applied  clustering  algorithms to  mine 
event logs for fault detection. The work first constructs 
clusters by grouping event logs based on their message 
characters  and 
tracking 
anomalous events which do not belong to any existing 
clusters. Based on Gaussian mixtures, Yamanishi et al. 
[9] developed an online unsupervised outlier detection 
engine named Smartsifter and it was used for intrusion 
detection  in  computer  security.  Though  Gaussian 
mixtures are also used to model data relationship in our 
work,  we  apply  a  new  variant  of  recursive  EM 
algorithm  that  is  able  to  tune  the  number  of  clusters 
dynamically.  Meanwhile,  we  track  the  probabilistic 
relationship  among  monitoring  data  rather  than  their 
real  values  so  that  we  have  a  thoroughly  different 
approach for outlier detection.  
3.  Probabilistic relationship 
Many  Internet  services  employ  multi-tier  system 
architecture  to  integrate  their  components.  Typical 
three-tier  architecture  is  illustrated  in  Figure  1  and  it 
includes web servers, application servers and database 
servers.  A  web  server  acts  as  the  system  interface  to 
handle  requests  and  responses  from/to  clients.  An 
application  server  supports  specific  application  and 
business  logic  for  Internet  services.  Database  servers 
are  the  back-end  servers  for  persistent  data  storage. 
Much  monitoring  data  can  be  collected  from  such 
systems for fault analysis. For example, the access logs 
of  web  server  include  every  HTTP  requests  from 
clients.  The  runtime  monitoring  data  of  application 
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:26:44 UTC from IEEE Xplore.  Restrictions apply. 
servers such as the numbers of threads and EJBs can be 
monitored via Java Management Extension (JMX) [10]. 
Many tools are also available to collect network traffic 
statistics and OS audit data such as CPU and memory 
usage.   
r1 
Web  
logs 
r2 
r3 
JMX 
logs 
Database 
logs 
User 
Request
Web 
Server 
App 
Server 
Database 
Server 
Figure 1.  Typical three-tier systems 
The rich set of monitoring data collected at multiple 
points  enables  us  to  analyze  their  correlations  across 
distributed systems. In Figure 1, r1, r2 and r3 indicate 
three different correlations between related monitoring 
data.  For  example,  r1  could  represent  the  correlation 
between the volume of user requests and the number of 
Java threads running on the application server. In this 
( )x t and 
paper,  we  select  pairs  of  such  measurements,
( )y t
,  to  form  a  set  of  two-dimensional  variables: 
,  which  correspond to  data  points  in  a  2-D 
x t
y t
( ( ),   ( ))
space as shown in Figure 2. As mentioned above, much 
of  monitoring  data  reacts  to  the  intensity  of  user 
requests accordingly  when user requests flow through 
the system. Here we use flow intensity to measure the 
intensity  with  which  various  internal  monitoring  data 
responds  to  the  volume  of  user  requests.  Since  these 
measurements  are  affected  by  the  same  factor  –  user 
loads,  we  believe  that  there  is  much  correlation 
between 
to 
system  dynamics  and  uncertainties,  some  correlations 
may only be characterized with probabilistic models.  
these  measurements.  Meanwhile,  due 
If we consider a system component as a black box, 
the correlation between the monitoring data measured 
at  the  input  and  output  of  the  component  could  well 
reflect the constraints that the monitored system bears. 
As  an  engineered  system,  the  constraints  could  be 
imposed  by  many  factors  such  as  hardware  capacity, 
application  software  logic  and  system  architecture. 
After some faults occur inside the component, some of 
such constraints could be  violated and we may detect 
such  faults  by  continuously  tracking  the  correlation 
between  the  input  and  output  measurements.  In  this 
paper, we use GMMs to approximate the probabilistic 
correlation  between  flow  intensity  measurements.  A 
probability density boundary is determined by tracking 
the  mass  characteristics  of  historical  measurements. 
Since the probability density of a data point inside the 
boundary  is  always  greater  than  that  outside  the 
boundary, we detect anomalies by determining whether 
a  new  data  point  locates  outside  of  the  correlation 
boundary,  i.e.,  determining  whether  the  probability 
density 
is less than the selected 
p x t
( ( ),
y t
( ))
. 
p
boundary
Figure 2.  Correlation of monitoring data 
4.  Gaussian mixture models 
Figure  3  shows  an  example  of  the  correlation 
between memory and number of Java threads used in 
the middleware server. The samples are collected from 
a real  system,  which  will  be  introduced  in  Section 8. 
From  the  scatter  plot in  Figure  3,  we  notice  that  data 
points can be clustered together around several centers 
with  compact  cluster  size.  We  apply  a  GMM  to 
characterize  such  relationship  because  many  flow 
intensity  measurements  are  likely  to  follow  Gaussian 
distribution.  As mentioned  above,  the  volume  of  user 
requests is the major factor that affects the intensity of 
internal  monitoring  data.  The 
intensity 
measurements are most likely to respond to the current 
level of user loads accordingly but are also affected by 
some uncertainties. Therefore, given a certain volume 
of  user  requests,  these  measurements  are  likely  to 
follow  Gaussian  distribution  and  their  mean  values 
could  well  correspond  to  the  current  intensity  of 
workloads.  Meanwhile,  due to  varying  workloads,  we 
may need multiple Gaussian distributions to capture the 
mass characteristics of measurements. This is our early 
motivation for using GMMs in this work.         
flow 
Figure 3.  Correlation between number of Java threads 
and memory usage 
In a GMM, we use the following probability density 
function  p  to approximate the real data distribution:  
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:26:44 UTC from IEEE Xplore.  Restrictions apply. 
p z
(
i
G
= ∑
θ α
j
)
=
1
j
p z
(
j
i
|
µ
,
j
Σ
)
j
In this paper, we only consider the correlation between 
each pair of measurements. Though we can use GMMs 
to correlate high dimensional data, such correlation is 
not helpful in locating faults. Therefore data points are 
}
two-dimensional  vectors  denoted  by,  { } {
=
, 
(
)
≤ ≤
 where  N  is  the  number  of  data  samples.  In 
i N
1
the  number  of  mixtures 
Equation 
α α are  the  unknown  proportions  of  these 
and 1,...,
(1),  G  is 
x y
z
G
i
i
i
,
mixtures.  Thus  we  have
G
=∑
α
j
1
. 
=
1
j
p z µ Σ
,
j
(
|
i
j
)
j
, 
denotes the j-th two-dimensional Gaussian distribution 
Σ , i.e.,  
with its mean value 
j
µ
j
µ and covariance matrix 
j
−
−
exp{
µ
)'
j
p z
(
j
θ
)
j
)}
Σ
−
=
−
1
z
z
(
(
|
j
1/ 2
1
2
1
π
Σ
2
j
,
}
u
i
{(
≤ ≤
i G
θ α=
,
i
Σ  
),
Denote  the  mixture  parameter  set  by 
i
.  As  shown  in  Equation (1),  the  probability 
1
density of a data point is a weighted mixture of the G  
Gaussian  distributions.  Given  data  samples,  the  well 
known EM algorithm  [3]  can  be  used  to  estimate  the 
optimal parameter set  $θ that maximally approximates 
the real data distribution.  
5. Model-based fault detection 
µ
Σ
)'
( )p z
µ
))
1/ 2
the  values  of 
( )m z
For  two-dimensional  Gaussian  distributions  shown 
in Equation (2), the Mahalanobis distance is defined as 
−
z
m z
z
. For a specific Gaussian 
( )
, 
its  squared 
distribution 
Mahalanobis  distance, 
,  are  approximately  Chi-