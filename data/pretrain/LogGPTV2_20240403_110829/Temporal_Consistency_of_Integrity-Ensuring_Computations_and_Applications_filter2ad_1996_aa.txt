title:Temporal Consistency of Integrity-Ensuring Computations and Applications
to Embedded Systems Security
author:Xavier Carpent and
Karim Eldefrawy and
Norrathep Rattanavipanon and
Gene Tsudik
Temporal Consistency of Integrity-Ensuring Computations and
Applications to Embedded Systems Security
Karim Eldefrawy
SRI International
Xavier Carpent
University of California, Irvine
PI:EMAIL
PI:EMAIL
Norrathep Rattanavipanon
University of California, Irvine
PI:EMAIL
ABSTRACT
Assuring integrity of information (e.g., data and/or software) is
usually accomplished by cryptographic means, such as hash func-
tions or message authentication codes (MACs). Computing such
integrity-ensuring functions can be time-consuming if the amount
of input data is large and/or the computing platform is weak. At the
same time, in real-time or safety-critical settings, it is often imprac-
tical or even undesirable to guarantee atomicity of computing a
time-consuming integrity-ensuring function. Meanwhile, standard
correctness and security definitions of such functions assume that
input data (regardless of its size) remains consistent throughout
computation. However, temporal consistency may be lost if another
process interrupts execution of an integrity-ensuring function and
modifies portions of input that either or both: (1) were already
processed, or (2) were not processed yet. Lack of temporal consis-
tency might yield an integrity result that is non-sensical or simply
incorrect. Such subtleties and discrepancies between (implicit) as-
sumptions in definitions and implementations can be a source of
inconsistenceies, which might lead to vulnerabilities.
In this paper, we systematically explore the notion of tempo-
ral consistency of cryptographic integrity-ensuring functions. We
show that its lack in implementations of such functions can lead
to inconsistent results and security violations in protocols and sys-
tems using them, e.g., remote attestation, remote updates and secure
resets. We consider several mechanisms that guarantee temporal
consistency of implementations of integrity-ensuring functions in
embedded systems with a focus on remote attestation. We also
assess performance of proposed mechanisms on two commodity
hardware platforms: I.MX6-SabreLite and ODROID-XU4.
KEYWORDS
embedded system security; remote attestation; temporal consis-
tency
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
ASIA CCS ’18, June 4–8, 2018, Incheon, Republic of Korea
© 2018 Association for Computing Machinery.
ACM ISBN 978-1-4503-5576-6/18/06...$15.00
https://doi.org/10.1145/3196494.3196526
Gene Tsudik
University of California, Irvine
PI:EMAIL
1 INTRODUCTION
Computation over a large amount of input data is never instanta-
neous. Even if input size is moderate, computation can take a long
time, e.g., if it involves cryptographic primitives, or takes place
on a slow (low-end) processor. Assuring atomicity (i.e., uninter-
ruptibility) of computation might be impractical or even unsafe if
the underlying system provides critical or real-time service. Mean-
while, if computation is cryptographic in nature and its purpose
is to ensure integrity, the result must be temporally consistent. In
other words, it must, at least1, reflect the exact state of input data
at some point in time. These two requirements are potentially con-
flicting: if integrity-related computation is interruptible, its input
might change, such that the result is inconsistent (i.e., wrong) or
non-sensical, i.e., it might correspond to the state of input that
did not exist at any one time. This issue has been surprisingly
under-appreciated in the security research literature.
More generally, we argue that temporal consistency is important
in computing any integrity-ensuring function, e.g., checksums for
error detection, and not only security-relevant ones such as hash
functions, MACs and digital signatures. All these functions are
designed to operate on static input data, which is assumed by their
standard (security) definitions.
This discrepancy between (implicit) theoretical assumptions and
implementations is especially relevant in the context of Remote
Attestation (RA). RA is a security service for remotely assessing
integrity of software and memory (as well as other types of stor-
age) in embedded devices. RA is typically realized as an interaction
between a trusted entity (verifier) and an untrusted, potentially
malware-infected, remote device (prover). Upon a request by veri-
fier, prover computes a measurement of its internal state and returns
the result to verifier for validation. The measurement procedure is
essentially an integrity-ensuring function with additional security
(particulars of which depend on the specific flavor of RA) to pre-
vent malware from falsifying results. Consistency is of paramount
concern for RA, since a measurement result must faithfully reflect
the state of prover’s memory at some point. (NOTE: Hereafter, we
use consistency as a shorthand for temporal consistency). Looking
at prior RA literature, it is unclear exactly at what time – or time
interval – this must hold:
(1) Time when verifier’s request is sent to prover?
(2) Time when verifier’s request is received by prover?
1We say “at least” to mean that the definition of temporal consistency can be expanded
to encompass an interval of time, rather than a single point in time.
(3) Time at prover at the very start of its measurement?
(4) Time at prover at the very end of its measurement?
(5) Any time (or interval) between the last two?
(6) The entire period between start and end measurement?
Although this list is not exhaustive, it enumerates the obvious
choices.
As an illustrative example, consider a sensor/actuator fire alarm
application running on “bare-metal” in a low-end embedded de-
vice. This application periodically checks the value of a sensor and
triggers an alarm whenever that value exceeds a certain threshold.
Given its safety-critical function, software integrity of this device is
periodically checked using RA. Upon receipt of a request from the
verifier, the measurement process interrupts the application and
takes over. The measurement process must run uninterrupted in
order to accurately reflect current state of prover’s software. One
obvious downside of uninterrupted measurement is that the critical
application is dormant during this process, even if a real fire occurs.
Whereas, if we favor the critical application and allow the mea-
surement process to be interrupted, another problem arises. Sup-
pose that the device is infected by migratory malware – the type
of malware that can move itself around – as a whole, or in pieces –
in device’s memory and other storage, in order to evade detection.
Such malware can interrupt the measurement process, e.g., half-
way through, and move itself (by copying and erasing) to segments
of memory that have been already covered by the measurement
process. This way, the final measurement result would reflect a
benign (malware-free) state and, upon receiving and checking it,
the verifier would not detect any malware presence. For a more
detailed discussion of migratory malware, we refer to Appendix D
and E.
Although dangers of migratory malware were anticipated
in the design of some software-based attestation methods, e.g.,
Viper and Pioneer [21, 34], tradeoffs between uninterruptibility
(and atomicity) and integrity measurement consistency have
not been considered in hardware and hybrid attestation designs.
Despite their drawbacks, software-based attestation techniques
are inherently less vulnerable to migratory malware, since their
measurement process involves precise timing which would be
noticeably skewed by migratory malware (due to the latter’s efforts
of copying and erasing). However, as we discuss later, they are also
unsuitable for remote attestation where fluctuating network delays
influence overall timing. Thus, the main goal of this paper is to (1)
investigate uninterruptibility/consistency tradeoffs, and (2) design
techniques offering a range of concrete consistency guarantees for
integrity-ensuring computations, while allowing varying degrees
of interruptibility.
Contributions: This paper makes several advances:
(1) First systematic study of temporal consistency in crypto-
graphic integrity-ensuring functions. We show that lack
thereof can yield incorrect (including malicious) or non-
sensical results.
(2) Design and evaluation of several mechanisms that ensure
temporal consistency in the context of embedded systems,
with a focus on applicability to secure remote attestation.
(3) As part of this work, we develop a new security game that
captures temporal consistency in the context of remote
attestation. This security definition may be of independent
interest. (See Appendix A).
Outline: Section 2 overviews remote attestation and discusses
the importance of temporal consistency. Section 3 introduces our
model and notation as well as supporting mechanisms. Section 4
describes several techniques to ensure temporal consistency in re-
mote attestation for embedded and IoT devices. Section 5 describes
implementation and performance evaluation of mechanisms pro-
posed in Section 4. Section 6 discusses related work, and Section 7
concludes the paper.
2 TEMPORAL CONSISTENCY
State-of-the-art in stealthy malware has been advancing at an im-
pressive rate. Malware that erases itself after performing an in-
tended task, typically after stealing credential or financial assets,
has been discovered in recent years [39]. Malware that utilizes re-
sources (CPU and GPU) on personal computers for computationally
heavy (e.g., cryptographic) tasks, mainly to mine cryptocurrencies,
has also been reported [25]. Sophistication of malware has increased
even more in the realm of Cyber-Physical Systems (CPS), Embedded
Systems (ES), and, most recently, Internet-of-Things (IoT). Notable
examples include Stuxnet [20, 36] and Duqu [6]. A recent SANS
Institute survey [16] about IoT threat vectors and concerns lists
malware as the second most highly cited concern (26%), the main
justification being fear of IoT devices spreading malware into enter-
prises. The first concern (31%) was patching and updating software,
and the third was denial-of-service (13%).
2.1 Remote Attestation
In recent years, Remote Attestation (RA) emerged as a distinct se-
curity service for detecting malware on CPS, ES and IoT devices.
RA involves verification of current internal state (i.e., RAM or flash)
of an untrusted remote hardware platform (prover or Prv) by a
trusted entity (verifier or Vrf). RA can help the latter establish
a static or dynamic root of trust in Prv and can also be used to
construct other security services, such as software updates [33] and
secure deletion [28]. Many RA techniques with different assump-
tions, security features and complexities, have been proposed for
the single-prover scenario.
Prior RA results can be divided into three approaches: hardware-
based, software-based, and hybrid. Hardware-based approaches
typically rely on security provided by a Trusted Platform Mod-
ule (TPM) [15]. Despite resisting all, except physical, attacks, the
hardware-based approach is not suitable for low-end and legacy
embedded devices due to its added complexity and costs.
Software-based RA techniques offer a very low-cost alternative.
Pioneer [34] is a prominent example of this approach. Its main tool is
the use of a one-time special checksum function that covers memory
(to be attested) in an unpredictable (rather than contiguous) fashion.
Any interference with (or emulation of) the computation of this
checksum is detectable by extra latency that would be incurred by
migratory malware trying to avoid being “caught” by the checksum.
Unfortunately, security of this approach is uncertain after several
attacks on software-based RA schemes (e.g., [5]) were demonstrated.
Another problem with the software-based approach is its strong
Verifier
Prover
r
e
q
tvs
tpr tcs
resp
tce tps
tvr
Figure 1: Timeline for a typical remote attestation scheme. Verifier’s request is sent at tvs and received at tpr. Computation starts at tcs and
ends at tce. Report is sent at tps and received at tvr.
assumptions about adversarial capabilities, which are unrealistic in
many real networked settings. However, it is the only attestation
option for legacy devices.
Hybrid (software-hardware) RA co-designs have been pro-
posed to overcome limitations of purely software-based techniques.
SMART [11] is the first hybrid RA architecture with minimal hard-
ware modifications to existing micro-controller units (MCUs). In
addition to requiring uninterruptible non-malleable attestation code
and attestation keys in read-only memory (ROM), SMART requires
hard-wired MCU access control rules to allow access to secret keys
only to SMART attestation code. Attestation is performed within
Prv’s ROM-resident attestation code by computing a cryptographic
checksum (e.g., an AES-based CBC-MAC or an SHA2-based HMAC)
over a memory region and returning the result to Vrf. Notably,
SMART requires atomic (uninterruptible) execution of its ROM-
resident attestation code. However, this design feature was moti-
vated by the need to mitigate code-reuse attacks (such as ROP [29])
and not by consistency of computing the measurement. Follow-on
designs, such as TrustLite [19] and TyTAN [2], enhance SMART
with secure interrupt handling.
In this paper, we assume that the measuring process (MP) on
Prv is realized as a keyed integrity-ensuring function computed
over a part (or all) of Prv’s memory, in a “protected” execution
environment. Exact protection depends on the specific security
architecture.
2.2 RA Blueprint
A typical RA scheme operates as follows:
time tvs
(1) Vrf sends a challenge-bearing attestation request to Prv at
(2) Prv receives it at time tpr
(3) Computation of MP starts at time tcs
(4) Computation of MP ends at time tce
(5) Prv sends the attestation report to Vrf at time tps
(6) Vrf receives it at time tvr
The timeline for this sequence of events is shown in Figure 1. Com-
putation of MP (in gray) may be deferred due to networking delays,
Vrf’s request authentication, or termination of the previously run-
ning task. However, typically, tpr ≈ tcs and tce ≈ tps. Also, Prv
has no control over tvs and tvr. Consequently, hereafter we only
consider ts (cid:66) tcs (with tcs = tpr) and te (cid:66) tce (with tps = tce).
As discussed in Section 1, MP may require time-consuming
computations. The exact time it takes depends on the size of Prv’s
memory, its computational capability, and the underlying crypto-
graphic function(s). As a sample hardware platform, we consider
MP running an ODROID-XU4 [7] – a single-board computer repre-
sentative of medium-to-low-end embedded systems. In most cases,
(keyed) hashing2 is the dominant computation, unless memory to
be attested is very small, or the signature algorithm is particularly
expensive. Figure 2 shows the costs of these operations, for vari-
ous attested memory sizes and cryptographic algorithms3. Above
1MB, MP takes longer than 0.01sec, and the cost of most signature
algorithms become comparatively insignificant. Results show that
even hashing a reasonable amount of memory incurs a significant
delay. For example, it takes about 0.9s to measure just 100MB on
ODROID-XU4. Its entire RAM (2GB) can be measured in about 14s.
In a safety-critical setting, this is definitely too long for MP to run
uninterrupted.
As mentioned earlier, recent hybrid RA architectures, such as
TrustLite [19] and TyTAN [2], permit tasks to be interrupted. While
this allows for time-critical processes to run and preserve Prv’s
critical functionality, attestation results might be inconsistent. In-