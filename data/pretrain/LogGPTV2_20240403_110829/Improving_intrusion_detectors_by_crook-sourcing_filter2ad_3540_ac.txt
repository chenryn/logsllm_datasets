represents a linear transformation from the input feature space to
the metric embedding space. A weight Œ±(‚Ñì) ‚àà [0, 1] is assigned to
E‚Ñì, measuring its importance in OAML.
t )||2 ‚â™ ||F(xt ) ‚àí F(x‚àí
E0E1L1L(0)L0L0E2L(1)L(2)Constraint StreamAdaptive Metric NetworkHedgeHedgeHedgeTotal LossLossùû™0ùû™1ùû™2ACSAC ‚Äô19, December 9‚Äì13, 2019, San Juan, PR, USA
F. Araujo, G. Ayoade, K. Al-Naami, Y. Gao, K.W. Hamlen, and L. Khan
For a triplet constraint (xt , x +
metric embedding f (‚Ñì)(x‚àó
t , x‚àí
t ) that arrives at time t, its
t ) generated by E‚Ñì is
(‚Ñì)(x
‚àó
t ) = h
(‚Ñì)
(‚Ñì)
Figure 5: Web traffic generation and testing harness
and test datasets from real web traffic for our experiments. Then
we discuss our experimental setup and investigate the effects of
different attack classes and varying numbers of attack instances on
the predictive power and accuracy of the intrusion detection. Finally,
we assess the performance impact of the deception monitoring
mechanism that captures network packets and system events.
All experiments were performed on a 16-core host with 24 GB
RAM running 64-bit Ubuntu 16.04. Regular and honey-patched
servers were deployed as LXC containers [53] running atop the host
using the official Ubuntu container image. Red teaming validation
was performed on a similar environment deployed on AWS.
6.1 Experimental Framework
Figure 5 shows an overview of our evaluation framework, inspired
by related work [9, 13]. It streams encrypted legitimate and mali-
cious workloads (both simulated and real) onto a honey-patched
web server, resulting in labeled audit streams and attack traces
(collected at decoys) for training set generation. This strategy facil-
itates the reproducibility of our experiments while allowing for the
validation of our approach in a realistic setting.
Legitimate workload. In order to collect normal data, we used
both real user interactions with a web browser and automated
simulation of various user actions on the browser. For the real user
interaction, we monitored and recorded web traffic from users in a
local area network over a two-day period, resulting in more than
30GB of audit pcap data. The recorded sessions are replayed by our
framework and include users exhibiting normal browsing activities,
such as accessing social media websites, search engines, online
shopping websites, web email, video sharing, and news websites.
For the simulated interaction, normal traffic is created by au-
tomating complex user actions on a typical web application, leverag-
ing Selenium [67] to automate user interaction with a web browser
(e.g., clicking buttons, filling out forms, navigating a web page).
We generated web traffic for 12 different user activities (each re-
peated 200 times with varying data feeds), including web page
browsing, e-commerce website navigation, blog posting, and in-
teracting with a social media web application. The setup included
a CGI web application and a PHP-based Wordpress application
hosted on a monitored Apache web server. To enrich the set of user
activities, the Wordpress application was extended with Buddypress
and Woocommerce plugins for social media and e-commerce web
activities, respectively.
f
Œò
t denotes any anchor (xt ), positive (x +
(2)
where h(‚Ñì) = œÉ(W (‚Ñì)h(‚Ñì‚àí1)), with ‚Ñì ‚â• 1, ‚Ñì ‚àà N, and h(0) = x‚àó
t .
Here x‚àó
t ), or negative (x‚àí
t )
instance, and h(‚Ñì) represents the activation of the ‚Ñìth hidden layer.
Learned metric embedding f (‚Ñì)(x‚àó
t ) is limited to a unit sphere (i.e.,
|| f (‚Ñì)(x‚àó
t )||2 = 1) to reduce the search space and accelerate training.
t , x‚àí
t ),
we first retrieve the metric embedding f (‚Ñì)(x‚àó
t ) from the ‚Ñìth metric
model using Eq. 2. A local loss L(‚Ñì) for E‚Ñì is evaluated by calculating
the similarity and dissimilarity errors based on f (‚Ñì)(x‚àó
t ). Thus, the
overall loss introduced by this triplet is given by
During the training phase, for every arriving triplet (xt , x +
Loverall(xt , x +
t , x
‚àí
t ) =
(‚Ñì) ¬∑ L(‚Ñì)(xt , x +
t , x
‚àí
t )
Œ±
(3)
L
‚Ñì=0
Parameters Œò(‚Ñì), Œ±(‚Ñì), and W (‚Ñì) are learned during the online
learning phase. The final optimization problem to solve in OAML
at time t is therefore:
minimize
Œò(‚Ñì),W (‚Ñì),Œ±(‚Ñì)
subject to
Loverall
(‚Ñì)(x
|| f
‚àó
t )||2 = 1,‚àÄ‚Ñì = 0, . . . , L.
(4)
We evaluate the similarity and dissimilarity errors using an adaptive-
bound triplet loss (ABTL) constraint [30] to estimate L(‚Ñì) and update
parameters Œò(‚Ñì), W (‚Ñì) and Œ±(‚Ñì).
5 IMPLEMENTATION
We developed an implementation of DeepDig for 64-bit Linux (ker-
nel 3.19). It consists of two main components: (1) The monitoring
controller performs server monitoring and attack trace extraction
from decoys. It consists of about 350 lines of Node.js code, and
leverages tcpdump, editcap, and sysdig for network and system call
tracing and preprocessing. (2) The attack detection component is
implemented as two Python modules: the feature extraction mod-
ule, comprising about 1200 lines of code and feature generation;
and the classifier component, comprising 230 lines of code that
references the Weka [33] wrapper for LIBSVM [18]. The OAML
components comprise about 500 lines of Python code referencing
the PyTorch [65] library.
The source-code modifications required to honey-patch vulnera-
bilities in Apache HTTP, Bash, PHP, and OpenSSL consist of a mere
35 lines of C code added or changed in the original server code,
showing that the required deceptive capabilities can be added to
production-level web services with very little effort. (The forking
framework [4, 5] is fixed, and thus not included in this count.)
6 EVALUATION
A central goal of our research is to quantitatively measure the
impact of embedded deception on IDS accuracy. Our evaluation
approach therefore differs from works that seek to measure absolute
IDS accuracy, or that do not separate the impact of deception from
the rest of the detection process. We first present our evaluation
framework, which we harness to automatically generate training
honey-patched serverattack trafficattack automationnormal trafficdata sourcesactivitiesSelenium clientnetworkmonitoring(pcap)system monitoring(scap)exploitsattack labelingnormalworkloadattackworkloadBBCNewsBBCNewsPIIPIIElectronicRecordsElectronicRecordstraffic replayauditpcapattack tracesscappcapscappcapattack tracesscappcapaudit streamscappcapscappcapaudit streamscappcapattack tracesscappcapaudit streamscappcapnormalworkloadrecordedweb traffichoney-patched serverattack trafficattack automationnormal trafficdata sourcesactivitiesSelenium clientnetworkmonitoring(pcap)system monitoring(scap)exploitsattack labelingnormalworkloadattackworkloadBBCNewsPIIElectronicRecordstraffic replayauditpcapattack tracesscappcapaudit streamscappcapnormalworkloadrecordedweb trafficred teaminghoney-patched serverattack trafficattack automationnormal trafficdata sourcesactivitiesSelenium clientnetworkmonitoring(pcap)system monitoring(scap)exploitsattack labelingnormalworkloadattackworkloadBBCNewsPIIElectronicRecordstraffic replayauditpcapattack tracesscappcapaudit streamscappcapnormalworkloadrecordedweb trafficred teamingImproving Intrusion Detectors by Crook-sourcing
ACSAC ‚Äô19, December 9‚Äì13, 2019, San Juan, PR, USA
To create realistic interactions with the web applications, our
framework feeds from online data sources, such as the BBC text
corpus [32], online text generators [60] for personally identifiable
information (e.g., usernames, passwords), and product names to
populate web forms. To ensure diversity, we statistically sampled
the data sources to obtain user input values and dynamically gener-
ated web content. For example, blog title and body are statistically
sampled from the BBC text corpus, while product names are picked
from the product names data source.
Attack workload. Attack traffic is generated based on real-world
vulnerabilities. Table 2 lists 22 exploits for nine well-advertised,
high-severity vulnerabilities. These include CVE-2014-0160 (Heart-
bleed), CVE-2014-6271 (Shellshock), CVE-2012-1823 (improper han-
dling of query strings by PHP in CGI mode), CVE-2011-3368 (im-
proper URL validation), CVE-2014-0224 (Change Cipher specifi-
cation attack), CVE2010-0740 (Malformed TLS record), CVE-2010-
1452 (Apache mod_cache vulnerabilty), CVE-2016-7054 (Buffer over-
flow in openssl with support for ChaCha20-Poly1305 cipher suite),
and CVE-2017-5941 (Node.js error handling vulnerability). In addi-
tion, nine attack variants exploiting CVE-2014-6271 (Shellshock)
were created to carry out different malicious activities (i.e., different
attack payloads), such as leaking password files, dropping malware,
and invoking bash shells on the remote server. These vulnerabilities
are important as attack vectors because they range from sensitive
data exfiltration to complete control and remote code execution.
Similarly, we generated attack traffic using CVE-2017-5941 as an
additional remote execution attack and executed 6 attack payloads.
The post-infection payloads executed tasks such as tool acquisition
from remote host, basic environment reconnaissance (e.g., active
scanning with Nmap, passive inspection of system logs), remote
password file access, root certificate exfiltration, and attempts at
gaining access to other machines in the network.
Red teaming. To validate our results, we conducted a small-scale
penetration testing experiment using a red team composed of grad-
uate students in cyber security who were tasked with performing
reconnaissance and attacking a collection of monitored web server
instances deployed on AWS. The deployment comprised unpatched
and honey-patched web servers exposing (real or apparent) Shell-
shock vulnerabilities. Special care was taken not to open unpatched
software to the broad Internet. The attack team was composed
by 10 students with basic (e.g., script-kidding) to advanced skills
(e.g., penetration testing, reverse engineering) in offensive security.
After a preliminary leveling and preparation, each student spent an
average of 45 minutes completing the exercise on their own time.
Students were not permitted to repeat any exercise more than once.
Network and system data was collected over a span of 3 days and
used as testing and control data.
After successfully completing the initial infection, observed data
show that students performed different malicious activities, such as
searching for password files, printing user sessions on the system,
listing network interfaces, injecting boot loaders, and installing root
kits. For example, collected attack samples included modification of
rc.local to launch a listening process in the background at boot
time, network traffic redirection through iptables, file exfiltration
over the network, file deletions and access permission modification,
and cleanup of event logs and shell history to cover attack paths. No
Table 2: Summary of attack workload
#
1
2
3
Attack Type
CVE-2014-0160
CVE-2012-1823
CVE-2011-3368
4‚Äì10
CVE-2014-6271
11
CVE-2014-6271
12
CVE-2014-6271
13
CVE-2014-0224
14
CVE-2010-0740
15
CVE-2010-1452
16
CVE-2016-7054
17‚Äì22 CVE-2017-5941‚àó
‚àóused for testing only, as n-day vulnerability.
Description
Information leak
System remote hijack
Port scanning
System hijack (7 variants)
Remote Password file read
Remote root directory read
Session hijack and information leak Openssl
Openssl
DoS via NULL pointer dereference
Apache
DoS via request that lacks a path
Openssl
DoS via heap buffer overflow
System hijack (6 variants)
Node.js
Software
Openssl
PHP
Apache
Bash
Bash
Bash
students were able to distinguish honey-patched from unpatched
web servers during the experiment.
Noise injection. Rather than testing with existing, publicly avail-
able intrusion datasets (which are inappropriate evaluations of
DeepDig, since they lack concept-relevance for deception and
are generally stripped of raw packet data), our evaluation inter-
leaves attack and normal traffic following prior work on defense-in-
depth [13], and injects benign payloads as data into attack packets
to mimic evasive attack behavior. The generated traffic contains
attack payloads against recent CVEs for which we created and
tested realistic exploits, and our framework automatically extracts
labeled features from the monitoring network and system traces to
(re-)train the classifiers.
Dataset. Web traffic was generated from a separate host to avoid
interference with the test bed server. To account for operational
and environmental differences, our framework simulated different
workload profiles (according to time of day), against various target
configurations (including different background processes and server
workloads), and network settings, such as TCP congestion controls.
In total, we generated 42 GB of (uncompressed) network packets and
system events over a period of three weeks. After feature extraction,
the training data comprised 1800 normal instances and 1600 attack
instances. Monitoring or testing data consisted of 3400 normal and
attack instances gathered at unpatched web servers, where the
distribution of normal and attack instances varies per experiment.
Detection accuracy. Using this dataset, we trained the classifiers
presented in ¬ß4 and assessed their individual performance against
test streams containing both normal and attack workloads. In the
experiments, we measured the true positive rate (tpr), where true
positive represents the number of actual attack instances that are
classified as attacks; false positive rate (fpr), where false positive
represents the number of actual benign instances classified as at-
tacks; accuracy (acc); and F2 score of the classifier, where the F2
score is interpreted as the weighted average of the precision and
recall, reaching its best value at 1 and worst at 0. We also calculated
a base detection rate (bdr) to estimate the success of intrusion detec-
tion (¬ß6.3). An RBF kernel with Cost = 1.3√ó 105 and Œ≥ = 1.9√ó 10‚àí6
was used for SVM [62]. OAML employed a ReLU network with
n=200, L=1, and k=5 (defined in ¬ß4.3).
To evaluate the accuracy of intrusion detection, we verified each
classifier after incrementally training it with increasing numbers
of attack classes. Each class consists of 100 distinct variants of a
single exploit, as described in ¬ß6.1, and an n-class model is one
trained with up to n attack classes. For example, a 3-class model is
ACSAC ‚Äô19, December 9‚Äì13, 2019, San Juan, PR, USA