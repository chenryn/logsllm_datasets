(in the continuous case) follows by comparing the empirical
and the true loss function at their respective argmaxes. For
instance, supposing that ˆ(cid:8)x,x(cid:2) (ˆt) ≥ (cid:8)x,x(cid:2) (t
∗
) holds, we have
|ˆx,x(cid:2) − x,x(cid:2),C| = (cid:8)x,x(cid:2) (ˆt) − (cid:8)x,x(cid:2) (t
∗
)
(cid:9)(cid:12)
=(cid:8)x,x(cid:2) (ˆt) − (cid:8)x,x(cid:2) (ˆt) + (cid:8)x,x(cid:2) (ˆt) − (cid:8)x,x(cid:2) (t
∗
=OP
+ [(cid:8)x,x(cid:2) (ˆt) − (cid:8)x,x(cid:2) (t
Non-negativity follows from ˆ(cid:8)x,x(cid:2) (ˆt) ≥ (cid:8)x,x(cid:2) (t
∗
), while the
decay rate in the second equality follows from (29). Since
[(cid:8)x,x(cid:2) (ˆt) − (cid:8)x,x(cid:2) (t
)] is non-positive, it must also hold that
)] ≥ 0.
ln(n)n
− β
(cid:11)
2β+1
∗
∗
)
|(cid:8)x,x(cid:2) (ˆt) − (cid:8)x,x(cid:2) (t
∗
)| = OP
− β
2β+1
ln(n)n
.
(cid:9)(cid:12)
(cid:11)
Reversing the roles of empirical and true loss can be used to
treat the case ˆ(cid:8)x,x(cid:2) (ˆt) ≤ (cid:8)x,x(cid:2) (t
). Part ii) of the proposition
also follows from (29), as
∗
|x,x(cid:2),C − (cid:8)x,x(cid:2) (ˆt)| = (cid:8)x,x(cid:2) (t
=[(cid:8)x,x(cid:2) (t
) − ˆ(cid:8)x,x(cid:2) (ˆt)] + [ˆ(cid:8)x,x(cid:2) (ˆt) − (cid:8)x,x(cid:2) (ˆt)].
) − (cid:8)x,x(cid:2) (ˆt)
∗
∗
) ≥
In the ﬁrst step we have used that x,x(cid:2),C = (cid:8)x,x(cid:2) (t
∗ ∈ M. We can now treat the two terms
(cid:8)x,x(cid:2) (ˆt) because t
on the right separately. The ﬁrst term in the square brackets
∗
decays at the desired rate according to Proposition 1 part i)
and the second part according to the second identity in (29).
This shows Proposition 1 in the continuous case.
min
t∈Uζ (M)
sup
We now show that Lemma 1 holds. We begin with two
technical observations: For any, sufﬁciently small ζ > 0 there
exist positive constants κ, ρ > 0, such that simultaneously
fx(t) ∧ fx(cid:2) (t) ≥ ρ > 0
(30)
(cid:8)x,x(cid:2) (t) − κ,
t∈C\Uζ (M)
(cid:8)x,x(cid:2) (t)  0 (otherwise the assumption supt∈C (cid:8)x,x(cid:2) (t) ∈
(0,∞) would be violated). Now fx ∧ fx(cid:2)
is a continuous
function on the closed (thus compact) set M and it therefore
attains its (positive) minimum. Therefore, for some ˜ρ > 0 it
holds that mint∈M fx(t) ∧ fx(cid:2) (t) ≥ ˜ρ. Now let t ∈ Uζ(M)
and ˜t ∈ M, s.t. |t − ˜t| ≤ ζ. According to (C1) it holds that
fx(t) ∧ fx(cid:2) (t)
≥fx(˜t) ∧ fx(cid:2) (˜t) − |fx(t) ∧ fx(cid:2) (t) − fx(˜t) ∧ fx(cid:2) (˜t)|
≥˜ρ − a|˜t − t|β ≥ ˜ρ − aζ β.
Here we have used for the second inequality that the minimum
of two β-H¨older continuous functions is again β-H¨older
(where we have called the constant a). In the last step we have
used that |t − ˜t| ≤ ζ. It is now obvious that with sufﬁciently
small ζ, say ζ  ζ
for all n ∈ N, showing (31). In the following we assume that
κ, ρ, ζ are chosen such that (30) and (31) hold.
(cid:11)
(cid:2) ∈ (0, ρ) it holds that
: ∀t ∈ Uζ(M)
We now prove part i) of Lemma 1. To show this, we ﬁrst
˜fx(t) ∧ ˜fx(cid:2) (t) > ρ
(cid:2)
notice that for any ﬁxed ρ
= 1,
(cid:9)
(32)
lim
n→∞ P
where ˜fx(t), ˜fx(cid:2) (t) are the KDEs deﬁned in (8), Section II-B.
(32) is a direct consequence of the uniform consistency of
KDEs (see (11)). Now recall the deﬁnition of the truncated
KDE ˆfx := ˜fx ∨ τ. Since τ → 0 and (32) holds, it follows
for all t ∈ Uζ(M) simultaneously that ˆfx(t) = ˜fx(t), with
probability converging to 1. Consequently, the deﬁnition of
the empirical loss implies with probability converging to 1
ˆ(cid:8)x,x(cid:2) (t) = | ln( ˜fx(t)) − ln( ˜fx(cid:2) (t))|,
∀t ∈ Uζ(M).
This means that to establish part i) of the Lemma, it sufﬁces
to show(cid:2)(cid:2)| ln( ˜fx(t)) − ln( ˜fx(cid:2) (t))|
− | ln(fx(t)) − ln(fx(cid:2) (t))|(cid:2)(cid:2) = OP
(cid:9)(cid:12)
ln(n)n
(cid:11)
.
− β
2β+1
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:21:54 UTC from IEEE Xplore.  Restrictions apply. 
418
By the triangle inequality we can show the desired rate sepa-
rately for | ln( ˜fx(t))− ln(fx(t))| and | ln( ˜fx(cid:2) (t))− ln(fx(cid:2) (t))|.
We restrict ourselves to the ﬁrst term (the second one follows
by analogous arguments). By the mean value theorem it
follows that
| ln( ˜fx(t)) − ln(fx(t))| =
| ˜fx(t) − fx(t)|
ξ(t)
,
(33)
where ξ(t) is a number between ˜fx(t), fx(t). The numerator
is of order
| ˜fx(t) − fx(t)| = OP
sup
t
− β
2β+1
ln(n)n
,
(34)
(cid:9)(cid:12)
(cid:11)
where we have used the uniform approximation of kernel
density estimators, from (11). The denominator is bounded
away from 0, with probability converging to 1, as the bound
ξ(t) ≥ fx(t) − | ˜fx(t) − fx(t)| ≥ ρ − oP (1),
(35)
holds uniformly for t ∈ Uζ(M). Here we have used the lower
bound (30) of the density fx on Uζ(M). Together (34) and
(35) imply the desired rate for the right side of (33). By our
above arguments, this shows part i) of Lemma 1.
Next we prove part ii) of Lemma 1. Let us therefore deﬁne
pointwise in t the truncated density
(cid:19)
f (τ )
x (t) :=
fx(t),
τ,
if
else
ˆfx(t) > τ,
and analogously the function f
cated loss
(τ )
x(cid:2)
. Therewith deﬁne the trun-
(cid:8)
(τ )
x,x(cid:2) (t) := | ln(f (τ )
x (t)) − ln(f
(36)
By deﬁnition it holds for any τ > 0 and any t, that (cid:8)x,x(cid:2) (t) ≥
x,x(cid:2) (t) (“=” if ˆfx(t), ˆfx(cid:2) (t) > τ and “≥” else). Now for any
(cid:8)
t ∈ C \ Uζ(M) we consider the following decomposition
x(cid:2) (t))|.
(τ )
(τ )
(cid:8)x,x(cid:2) (s) − ˆ(cid:8)x,x(cid:2) (t) = A1 + A2 + A3 + A4,
(37)
sup
s∈C
where A1 := sup
s∈C
(cid:8)x,x(cid:2) (s) −
(cid:8)x,x(cid:2) (s)
s∈C\Uζ (M)
sup
(cid:8)x,x(cid:2) (s) −
x,x(cid:2) (s) − (cid:8)
(τ )
(cid:8)
sup
s∈C\Uζ (M)
(τ )
x,x(cid:2) (t)
(τ )
x,x(cid:2) (s)
(cid:8)
A2 :=
sup
s∈C\Uζ (M)
A3 :=
sup
s∈C\Uζ (M)
x,x(cid:2) (t) − ˆ(cid:8)x,x(cid:2) (t).
(τ )
A4 :=(cid:8)
Now A1 ≥ κ holds according to (31). Furthermore A2 ≥ 0
due to the inequality (cid:8)x,x(cid:2) (s) ≥ (cid:8)
x,x(cid:2) (s) and A3 ≥ 0 because
t ∈ C \ Uζ(M). Finally we turn to A4 and show that it is
uniformly in t of order oP (1). Using the triangle inequality,
we can upper bound A4 by
(τ )
| ln(f (τ )
x (t)) − ln( ˆfx(t))| + | ln(f
(τ )
x(cid:2) (t)) − ln( ˆfx(cid:2) (t))|.
| ln(f (τ )
(cid:2)
Both terms can be treated analogously and so we focus on the
ﬁrst one. If ˆfx(t) ≤ τ it is equal to 0 and thus we consider the
case where ˆfx(t) > τ. According to the mean value theorem
x (t)) − ln( ˆfx(t))| =
|f
(τ )
x (t) − ˆfx(t)|
ξ(cid:2)(t)
,
(38)
(τ )
x (t) and ˆfx(t). Just as before, the
(t) lies between f
where ξ
numerator is uniformly of order
|fx(t) − ˜fx(t)| = OP
(cid:9)(cid:12)
sup
t∈C
(cid:11)
− β
2β+1
ln(n)n
,
and the denominator is (asymptotically) bounded away from
0, as
(cid:2)
|fx(t) − ˜fx(t)|) ≥ τ + oP (τ ).
(t) = ˆfx(t) + OP (sup
t∈C
ξ
x (t)−
In both cases we have used that if ˆfx(t) > τ we have f τ
ˆfx(t) = fx(t) − ˜fx(t). Furthermore we have used for the
denominator the approximation rate (11) and that according
to (C3)
(cid:11)
(cid:9)(cid:12)
OP
− β
2β+1
ln(n)n
= oP (τ ).
These arguments imply that the right side of (38) is uniformly
in t of order oP (τ )/[τ + oP (τ )] = oP (1). By our above
arguments we now have A1 + A2 + A3 + A4 ≥ κ + oP (1),
which implies by (37) part ii) of Lemma 1 (if we replace κ
by 2κ in the above calculations).
D. Proof of Theorem 2
max
As with Proposition 1, we only show Theorem 2 for
continuous algorithms and d = 1 (extensions to d > 1 are
straightforward). The proof rests on the asymptotic normality
∗
of ˆ(cid:8)
(ˆtmax), where the point ˆtmax and the ran-
xmax,x(cid:2)
∗
domness in the estimator ˆ(cid:8)
max are independent. In the
xmax,x(cid:2)
discrete case, the proof is much simpler, as ˆtmax is eventually
max and hence it is easy
an element of the argmax of (cid:8)xmax,x(cid:2)
to establish an asymptotically vanishing bias. This is not so in
the continuous case, where ˆtmax is only close to the argmax
(as we have seen above) and the bias has to be controlled by
an undersmoothing procedure.
In the following proof, we conﬁne ourselves to part i) of the
theorem (as the convergence in part ii) follows by similar
but simpler techniques). For clarity of presentation, we will
assume that there exists a unique b
∗ ∈ {1, ..., B}, s.t.
1,C, ..., xB ,x(cid:2)
B ,C).
(39)
xb∗ ,x(cid:2)
b∗ ,C = max(x1,x(cid:2)
b,C by ˆxb,x(cid:2)
Recall that the MPL algorithm consists of two steps: First the
algorithm creates B pairs of samples with n elements each, to
b. According to Proposition 1,
approximate xb,x(cid:2)
these estimates are consistent and therefore with probability
∗ (where bmax is
converging to 1 it holds that bmax = b
∗ is de-
an estimator deﬁned in the MPL algorithm and b
ﬁned in (39)). For simplicity we will subsequently assume
(cid:2)
b∗ ) (formally we can do this
that (xmax, x
∗}). Next recall
by conditioning of the event {bmax = b
that from the ﬁrst step of MPL we get empirical estimates
(cid:2)
max) = (xb∗ , x
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:21:54 UTC from IEEE Xplore.  Restrictions apply. 
419
∗
1 , ..., X
ˆ(cid:8)xmax,x(cid:2)
max of the loss function and ˆtmax of the location of
maximum privacy violation. These estimates are based on
samples X1, ..., Xn ∼ fxmax, Y1, ..., Yn ∼ fx(cid:2)
max. We will
use these esimators in our subsequent discussion and it is
important to keep them distinct from the randomness in the
second part of the algorithm.
In the second step, MPL generates fresh samples of size N
max. The corresponding
X
density estimates, generated by the TKDE algorithm are
∗
∗
xmax and ˆf
denoted by ˆf
max (to distinguish them from the
x(cid:2)
estimators from the ﬁrst step of the algorithm). Notice that
these density estimators use the same kernel K as in the ﬁrst
step, but bandwidth hmax of a smaller size (the asymptotic rate
is described in Condition (C4)). Correspondingly we deﬁne the
loss based on the ∗-samples
N ∼ fxmax, Y
∗
N ∼ fx(cid:2)
∗
∗
1 , ..., Y
∗
ˆ(cid:8)
xmax,x(cid:2)
max
xmax (t) − ˆf
(t) := | ˆf
∗
∗
x(cid:2)
(cid:9)
(t)|.
(cid:11)
We point out that by the choices of n, N and the bandwidth
hmax (see Condition (C4)) it holds that
1√
N hmax
2β+1 = o
(cid:12)
ln(n)n
− β
(40)
.
max
Now consider the decomposition
(cid:12)
(cid:3)
N hmax
sup
t∈C
=:B1 + B2 + B3
(cid:8)xmax,x(cid:2)
max (t) − ˆ(cid:8)
∗
xmax,x(cid:2)
max
(ˆtmax)
(41)
(cid:4)
where
B1 :=
B2 :=
(cid:12)
(cid:12)
(cid:12)
N hmax
N hmax
B3 :=
N hmax
(cid:3)
(cid:3)
(cid:3)
(cid:8)xmax,x(cid:2)
sup
t∈C
ˆ(cid:8)xmax,x(cid:2)
(cid:8)xmax,x(cid:2)
max (t) − ˆ(cid:8)xmax,x(cid:2)
max (ˆtmax) − (cid:8)xmax,x(cid:2)
max (ˆtmax) − ˆ(cid:8)
∗