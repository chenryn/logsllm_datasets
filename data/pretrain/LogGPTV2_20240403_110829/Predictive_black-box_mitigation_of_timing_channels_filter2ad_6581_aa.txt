title:Predictive black-box mitigation of timing channels
author:Aslan Askarov and
Danfeng Zhang and
Andrew C. Myers
Predictive Black-Box Mitigation of Timing Channels
Aslan Askarov
PI:EMAIL
Danfeng Zhang
PI:EMAIL
Andrew C. Myers
PI:EMAIL
Department of Computer Science
Cornell University
Ithaca, NY 14853
ABSTRACT
We investigate techniques for general black-box mitigation of tim-
ing channels. The source of events is wrapped by a timing miti-
gator that delays output events so that they contain only a bounded
amount of information. We introduce a general class of timing miti-
gators that can achieve any given bound on timing channel leakage,
with a tradeoff in system performance. We show these mitigators
compose well with other mechanisms for information ﬂow control,
and demonstrate they are effective against some known timing at-
tacks.
Categories and Subject Descriptors: C.2.0 [Computer Commu-
nication Networks]: General—Security and protection
General Terms: Security
Keywords: Timing channels, mitigation, information ﬂow
1.
INTRODUCTION
Controlling timing channels is difﬁcult but important. The dif-
ﬁculty has long been recognized [20, 9, 27], but their importance
has been reinforced by recent work that shows timing channels can
quickly leak sensitive information. Attacks exploit the timing of
cryptographic operations [17, 4], of cache operations [26], and of
web server responses [2]. These attacks work even without coop-
eration of any software on the system being timed. If the system
contains malicious code or hardware (e.g., [30]), timing can also be
exploited as a robust covert channel [21].
In complex computing systems, different computations affect
each others’ timing through shared resources such as caches, the
processor, the disk, and the network. The precise time of an event
may depend on many pieces of sensitive information and compu-
tation. Therefore, timing measurements act as a kind of antenna
receiving signals from throughout the system. The combined sig-
nal might be analyzed by a sufﬁciently clever adversary to learn
about any of the information inﬂuencing timing.
A useful distinction to draw is between internal and external tim-
ing channels. Internal timing channels occur when time is explic-
itly or implicitly measured from within the system that contains
timing channels. External timing channels are measured from out-
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’10, October 4–8, 2010, Chicago, Illinois, USA.
Copyright 2010 ACM 978-1-4503-0244-9/10/10 ...$10.00.
side the system, and are therefore less easy to control. A variety of
methods have been proposed for mitigating or preventing internal
timing channels (e.g., [14, 1, 33]); this paper focuses on external
timing channels, where the adversary has more power: the ability
to accurately time externally visible behavior of the system. Prior
techniques for preventing timing channels fall into two camps. One
approach that has not proved effective in general is to add random
delays to timing-sensitive operations [11] or to timing measure-
ments [14]. Randomness adds noise to the timing signal, reducing
but not eliminating the bandwidth of the timing channel. Further,
stealthy timing channels robust to noise can be constructed [21].
A better, non-random method is to pad the run time of sensitive
operations to a ﬁxed time, or to a multiple of a ﬁxed time. Padding
mitigates timing leaks but does not eliminate them entirely if the
padded operation can take more than the allotted quantum of time.
For cryptographic operations, a correlation between sensitive input
and the run time can also be addressed by blinding techniques [5,
17] that unpredictably change the input, but blinding is not appli-
cable to general computations.
This paper introduces a more general scheme for mitigating tim-
ing channels. Unlike cryptographic blinding, this scheme applies to
a broad class of computing systems and computations. It does not
prevent timing leaks, which seems to be impossible in the general
case. Rather, it bounds the amount of information leaked through
the timing channel as a function of elapsed time. We show that sim-
ple mitigation schemes can ensure that no more than log2(t) bits of
information are leaked, where t is the running time (all logarithms
in this paper are base 2). Further, an arbitrary bound on information
leakage can be enforced, down to as low as O(log(t)). However,
tighter bounds have a price: they can reduce system throughput and
increase system latency, particularly if the system has unpredictable
behavior.
This paper makes the following contributions:
1. It introduces a novel, principled way to mitigate external tim-
ing channels.
2. This mitigation scheme is shown to enforce a speciﬁed bound
on the amount of information leaked.
3. The new mitigation scheme is demonstrated to defeat some
timing attacks discovered in prior work, and to provide good
performance in some cases.
4. Total leakage is shown to be bounded when timing mitiga-
tion is combined with other information ﬂow control mecha-
nisms.
The rest of the paper is structured as follows. Section 2 in-
troduces a simple version of the mitigation scheme. This simple
297Figure 1: System overview
scheme is an instance of a more general framework for provable
mitigation, deﬁned in Section 3. Section 4 empirically explores
how mitigation scheme affects the performance of the underlying
system. The scheme is shown in Section 5 to defend against some
known timing attacks. Related work is discussed in Section 6, and
Section 7 concludes.
2. SOME SIMPLE MITIGATION SCHEMES
2.1 System model
We begin with a simple model of a computing system that pro-
duces externally observable events whose timing may be a chan-
nel. Because the mitigation scheme works regardless of the inter-
nal details of computation, the computing system is treated simply
as a black-box source of events. As depicted in Figure 1, the event
source generates events that are delayed by the mitigation mecha-
nism so that their times of delivery convey less information. Delay-
ing events while preserving their order is the only behavior of the
mitigator that we consider.
We ignore for now the attributes of events other than time. These
attributes include the actual content of an event and also the choice
of communication medium (e.g., different networks, or even visual
displays or sound) over which it can be conveyed. Both content and
choice of medium can be viewed as storage channels [20], which
we assume are controlled by other means. Therefore we assume
that the only information requiring control is encoded in the times
at which events arrive from the source. This separate treatment of
timing and storage channels is justiﬁed in Section 3.5.
We assume the attacker observes delayed events and knows the
design of the mitigator though not its internal state. The goal of
the attacker is to communicate information from inside the event
source to the outside. Therefore the attacker consists of two parts:
an insider that controls the timing of source events, and an exter-
nal observer that attempts to learn sensitive information from this
timing channel. The content of the events may also be observable
to the attacker, which motivates our choice to not have the mitiga-
tor generate dummy events. The observer may combine informa-
tion from both the content and timing of messages. In real world
this corresponds to attacker-controlled software that communicates
seemingly benign messages on a storage channel, but transmits sen-
sitive information using timing.
As shown in the ﬁgure, it is useful to allow the mitigation sys-
tem to buffer events in a queue so the event source can run ahead,
generating more events without waiting. We consider adding input
events to the system model in Section 3.6.
2.2 Quantizing time
A very simple mitigation scheme that has been explored in prior
work [13, 11, 4] permits events to leave the mitigator only at sched-
uled times that are multiples of a particular time quantum q. We
refer to the times when events are permitted as slots, which in this
case occur at times q, 2q, etc. Without loss of generality, let us use
q = 1 to analyze this scheme.
Suppose we allow the system to run for time T , and during that
time there is an event ready to be delivered in every slot except that
at some point the event source may stop producing events (effec-
tively, it terminates). The total number of events delivered must be
an integer between 0 and T . Because all the slots ﬁlled with events
precede all the empty slots, the external observer can make at most
T + 1 possible distinct observations. According to information the-
ory, the maximum amount of information that can be transmitted by
one of T + 1 possible observations is achieved when the possible
observations are uniformly distributed. This value, in bits, is the
log base 2 of the number of possible observations, or log(T + 1).
For q (cid:54)= 1, it is log( T +1
q ).
2.3 A basic mitigation scheme
An asymptotically logarithmic bound on leakage sounds appeal-
ing, but in general we cannot count on the event source to ﬁll every
slot with an event. In the general case, maximum leakage from the
simple quantizing approach is one bit per quantum, leading to an
unpleasant tradeoff between security and performance.
However, a sublinear (in fact, polylogarithmic) bound is achiev-
able even if the event source misses some slots. Perhaps the sim-
plest way to achieve this is to double the quantum q every time a
slot is missed. Doubling the quantum ensures that in time T there
can be at most log(T + 1) misses. Effectively, the event source is
penalized for irregular behavior. For the penalty will be effective,
the multiplicative factor need not be 2; the number of misses will
grow logarithmically for any multiplicative factor greater than 1.
We can represent all behaviors of the resulting system as strings
constructed from the symbols e (for an event that ﬁlls a slot) and −
(for a missed slot). A given string generated by the regular expres-
sion (e|−)∗ precisely determines the times at which events emerge
from the mitigator, so the distinct strings correspond exactly to the
possible external timing observations. Therefore, the maximum of
the expected number of bits of information transmitted by time T is
the log base 2 of the number of strings that can be observed within
time T . These strings contain at most log(T +1) occurrences of −.
Between and around these occurrences are consecutive sequences
of between 0 and T ﬁlled slots (e’s), as suggested by this ﬁgure:
Each sequence of e’s falls into a different epoch with its own
characteristic quantum. There are at most log(T + 1) + 1 epochs,
so the number of possible strings observable within time T is at
most (T + 1)log(T +1)+1. The maximum information content of the
timing channel is the log of this number, or log(T + 1) · (log(T +
1) + 1) = log2(T + 1) + log(T + 1). This is bounded above by
(1+) log2 T where  can be made arbitrarily small for sufﬁciently
large T . With the more careful combinatorial analysis given in the
appendix, we can show leakage is bounded by O(log T (log T −
log log T )). In either case, timing leakage is O(log2(T )), which is
a slowly growing function of time.
2.4 Slow-doubling mitigation
Doubling on every miss performs poorly if the event source is
quiescent for long periods. The quantum-doubling scheme can be
reﬁned further to accommodate quiescent periods, by doubling the
quantum only when a missed slot follows a ﬁlled slot (that is, a −
after an e). With this mitigator, no performance penalty is suffered
eventsource      mitigatorbuffersourceeventsdelayedeventseeeeeeeeeeeeee..eeeeeeeat most log(T+1) occurrences of  0..T occurrences of  e  per epochq=1q=2...298by an event source that is initially quiescent, but then generates all
its output in a rapid series of events.
In this case we have epochs consisting of sequences like “−−−−”
and “eeee”. There can be at most 2 log(T + 1) epochs, and there
can be at most T strings per epoch, so the information content of
the channel is no more than 2 log(T ) log(T + 1) ≤ (2 + ) log2 T .
Thus, slow doubling gives much more ﬂexibility without changing
asymptotic information leakage.
In the next section we see that both the fast and slow doubling
schemes are instances of a more general framework for epoch-
based timing mitigation, enabling further important reﬁnements such
as adaptively reducing the quantum.
3. GENERAL EPOCH-BASED MITIGATION
The common feature of the mitigation schemes introduced thus
far is that the mitigator divides time into epochs. During each epoch
the mitigator operates according to a ﬁxed schedule that predicts the
future behavior of the event source. As long as the schedule pre-
dicts behavior accurately, the event source leaks no timing informa-
tion except for the length of the epoch. However, a misprediction
by the mitigator causes it to construct a new schedule; because this
choice is in general observable by the adversary, some information
leaks.
We can describe the mitigation schemes seen so far in these
terms. For example, the slow doubling scheme has “e” epochs in
which the mitigator predicts there will be an event ready for slots
spaced at the current quantum q. It also has “−” epochs in which
the mitigator predicts there will be no event ready for slots spaced
at the quantum q. On a mispredicted slot (a miss) during an “e”
epoch, the mitigator switches to a “−” epoch with a doubled quan-
tum.
Let us now explore this framework more formally, to enable gen-
erating and analyzing a variety of mitigation schemes that meet
speciﬁed bounds on timing channel transmission.
3.1 Mitigation
The mitigator is oblivious to the content of the events and does
not alter their content. From the mitigator’s point of view, source
events and delayed events are considered as timestamps at which
the events are received and delivered respectively.
Let source events be denoted by a monotonic sequence s1 . . . sn,
where 0 ≤ s1 and each si speciﬁes when the i-th event is received
by the mitigator. We denote the mitigator by M. Given a sequence
of source events s1 . . . sn, let M(s1 . . . sn) be the sequence of pos-
sibly delayed timestamps d1 . . . dm produced by the mitigator. The
sequence is again monotonically increasing; also, we have m ≤ n
and si ≤ di. The last inequality means the mitigator cannot pro-
duce events before they are received from the source.
A mitigation scheme is online if the delayed sequence does not
depend on timing or contents of future source messages. In this
work we are only interested in online mitigation schemes.
Timing leakage.
Because timing of the events may depend on the sensitive data
at the source, any variation in observed event timing creates an in-
formation channel. The larger the number of different observable
variations, the more information can be transmitted over this chan-
nel. When events are mitigated, the number of possible sequences
of events that a mitigator M can deliver by time T is
M(T ) = |{d1 . . . dm = M(s1 . . . sn) | dm ≤ T}|
The amount of information that can be leaked by such mitigator,
when the running time is bounded by T , is a logarithm of M(T ).
DEFINITION 1
(LEAKAGE OF THE MITIGATOR). Given a mit-
igator M, let leakage of M be log M(T ).
This deﬁnition implicitly assumes that the mitigator can control
the timing of events with perfect precision, but also credits the ad-
versarial observer with perfect measurement abilities. More real-
istically, we can assume that the mitigator can control timing to at
least the measurement precision of the observer, in which case the
above formula still bounds leakage.
Bounding leakage.
We specify the security requirements for timing leakage as a
bound, expressed as a function on running time T .
DEFINITION 2