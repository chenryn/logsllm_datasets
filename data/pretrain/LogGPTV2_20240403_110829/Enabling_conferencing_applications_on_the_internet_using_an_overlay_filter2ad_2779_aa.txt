# Enabling Conferencing Applications on the Internet Using an Overlay Multicast Architecture

**Authors:**
- Yang-hua Chu
- Sanjay G. Rao
- Srinivasan Seshan
- Hui Zhang

**Carnegie Mellon University**
- {yhchu, sanjay, srini+, hzhang}@cs.cmu.edu

## Abstract

In response to the significant scalability and deployment challenges associated with IP Multicast, we and other researchers have advocated for an alternative architecture that pushes all multicast functionality to the edge of the network. This architecture, referred to as End System Multicast, has several potential advantages but also raises concerns about performance. While initial simulation results in static environments are promising, they do not fully address the demanding performance requirements of real-world applications in a dynamic and heterogeneous Internet environment.

This paper explores how Internet environments and application requirements can influence the design of End System Multicast. We focus on audio and video conferencing, which are critical applications with stringent performance needs. We conduct an extensive evaluation study on a wide-area test-bed consisting of approximately twenty hosts distributed globally. Our results show that it is crucial to adapt to both latency and bandwidth when constructing overlays optimized for conferencing applications. Incorporating simple techniques into current self-organizing protocols to enable dynamic adaptation to these metrics significantly improves performance. Our findings indicate that End System Multicast is a promising architecture for supporting high-performance conferencing applications in a dynamic and heterogeneous Internet environment.

**Funding Acknowledgment:**
- This research was supported by DARPA under contract number F30602-99-1-0518 and by NSF under grant numbers Career Award NCR-9624979, ANI-9730105, ITR Award ANI-0085920, and ANI-9814929. Additional support was provided by Intel. The views and conclusions in this document are those of the authors and should not be interpreted as representing the official policies of DARPA, NSF, Intel, or the U.S. government.

**Copyright Notice:**
- Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee, provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.
- SIGCOMM’01, August 27-31, 2001, San Diego, California, USA.
- Copyright 2001 ACM 1-58113-411-8/01/0008 ...$5.00.

## 1. Introduction

Over the past decade, researchers have explored how group communication applications, such as audio and video conferencing, multi-party games, content distribution, and broadcasting, can be supported using IP Multicast. However, despite its initial proposal over ten years ago, IP Multicast has not been widely deployed due to fundamental issues related to scalability and the lack of higher-layer functionalities like reliability and congestion control. Recently, there has been a reevaluation of whether IP is the appropriate layer for multicast routing. A growing number of researchers [2, 3, 6, 9] have proposed an alternative architecture where all multicast-related functions, including group management and packet replication, are implemented at end systems. This architecture, known as End System Multicast, involves end systems participating in a multicast group self-organizing into an overlay structure using a completely distributed protocol. These end systems aim to optimize the efficiency of the overlay by adapting to network dynamics and considering application-level performance.

While End System Multicast offers several potential benefits, a key concern is its performance. Recent studies have shown that the performance penalty of using overlays can be acceptably low, but these studies were primarily conducted using simulations in static and controlled environments [2, 3, 9]. The Internet, however, is dynamic, heterogeneous, and unpredictable. In this paper, we address the feasibility of an overlay architecture in meeting the demanding end-to-end performance requirements of real-world applications in such an environment.

We focus on audio and video conferencing, a class of applications with stringent performance requirements. Despite the development of excellent tools like vic [10], vat [8], and rat [7], these applications are not ubiquitously deployed due to the limited availability of IP Multicast. Conferencing applications require high sustained throughput and low latencies.

To meet these performance requirements, we demonstrate that self-organizing protocols must adapt to both latency and bandwidth. We present techniques that enable dynamic adaptation to these metrics while remaining resilient to network noise and inaccuracies. We incorporate these techniques into Narada, a self-organizing protocol we previously introduced [3]. Although we use Narada, our techniques can be applied to other self-organizing protocols and may benefit other classes of group communication applications.

We evaluate our techniques on a wide-area test-bed comprising twenty machines distributed across North America, Asia, and Europe. Our results show that our techniques provide good performance from both the application and network perspectives. The end-to-end bandwidth and latency achieved by each receiver along the overlay are comparable to the unicast path from the source to that receiver. When our techniques are incorporated into Narada, applications see improvements of over 30–40% in both throughput and latency. The overhead of our approach is restricted to 10–15% for groups of up to twenty members.

The rest of the paper is organized as follows:
- Section 2 provides an overview of End System Multicast and self-organizing protocols.
- Section 3 discusses important performance issues for self-organizing protocols in supporting conferencing applications.
- Section 4 presents our techniques for addressing these issues.
- Sections 5, 6, and 7 detail our evaluation methodology and results.
- Finally, Sections 8, 9, and 10 discuss our results, related work, and summarize our findings.

## 2. End System Multicast

In End System Multicast, nodes participating in a multicast group, or proxies acting on their behalf, organize themselves into overlay spanning trees for data delivery. Each link in the tree corresponds to a unicast path between two end systems in the underlying Internet. For example, Figure 1(a) shows a physical network with routers R1 and R2 and end systems A, B, C, and D. Figure 1(b) illustrates an overlay tree rooted at source A, and Figure 1(a) shows how this overlay tree maps onto the physical network.

End System Multicast comes in two architectural flavors: peer-to-peer and proxy-based. In peer-to-peer architectures, all functionality is pushed to the end hosts participating in the multicast group. In proxy-based architectures, organizations deploy proxies at strategic locations on the Internet, and end hosts receive data using plain unicast from nearby proxies.

End System Multicast offers several advantages over IP Multicast:
- It requires no network-level support for multicast, pushing all functionality to the edge.
- It avoids per-group state in routers, thus addressing scalability concerns.
- Deployment is straightforward, as no changes are needed to the network infrastructure.
- Higher-layer features like error, flow, and congestion control can be simplified by deploying application intelligence at internal splitting points of the overlay tree.

Despite these advantages, a fundamental challenge is providing a method for nodes to self-organize into an efficient overlay network. Recent research has focused on designing self-organizing protocols for End System Multicast [2, 3, 6, 9]. These protocols typically consist of two components: (i) a group management component to ensure the overlay remains connected, and (ii) an overlay optimization component to maintain the quality of the overlay over time. Overlay optimization involves obtaining network information through active measurements and passive monitoring. As more information becomes available or network conditions change, the overlay can be modified by adding good links and dropping poor ones.

Two basic methods have emerged for constructing overlay spanning trees:
- Direct construction: Members explicitly select their parents from among the members they know. Yoid [6] and Overcast [9] use this approach.
- Two-step construction: Protocols like Gossamer [2] and Narada [3] first construct a richer connected graph (a mesh) and then build (reverse) shortest path spanning trees from the mesh. While a mesh could theoretically include all possible N * (N - 1) overlay links for a group of N members, protocols typically keep the meshes sparse to reduce overhead. The quality of the final spanning trees depends on the quality of the initial mesh. For further discussion, see [3, 6].

## 3. Conferencing Applications and Overlay Design

A key feature of End System Multicast is its ability to support application-customizable protocols and architectural decisions. In this section, we examine the interaction between End System Multicast and conferencing applications. We begin by reviewing the distinguishing characteristics of conferencing applications:

- **Performance Requirements:** Conferencing applications require low latencies and high sustained bandwidth between the source and receivers. In contrast, broadcasting and file transfer applications are primarily interested in bandwidth, with latency being less of a concern.
- **Graceful Degradation:** Conferencing applications can tolerate some loss through a degradation in application quality, unlike file transfer applications that require reliable data delivery.
- **Session Lengths:** Conferences are generally long-lived, lasting tens of minutes. File transfer and software downloading applications, on the other hand, may be short-lived.
- **Group Characteristics:** Conferences typically involve small groups of tens to hundreds of participants with dynamic membership. Broadcasting and content delivery applications often deal with much larger groups.
- **Source Transmission Patterns:** Conferencing applications usually have a single source transmitting data at a fixed rate, although any member can be the source. Large-scale broadcasting applications have a single static source throughout the session.

Many features of conferencing applications are well-suited to existing End System Multicast techniques. Self-organizing protocols use self-improving algorithms that incrementally produce better overlays by learning network path characteristics and adapting to network dynamics. The small group sizes and long session durations of conferences align well with this approach.

Some aspects of conferencing applications allow for relatively straightforward application-specific solutions. For example, the graceful degradation of media streams enables the use of hop-by-hop congestion control protocols. Congestion control on each individual overlay link can be ensured by running TCP-friendly protocols for streaming media applications [1, 5, 14]. An overlay node can adapt to a bandwidth mismatch between upstream and downstream links by dropping packets. Figure 2 illustrates an overlay tree where A is the source. Links A-B and C-D cannot sustain the source rate of 5 Mbps, so nodes A and C reduce the rate using an appropriate packet drop policy.

The performance requirements of conferencing applications are a key aspect that existing End System Multicast systems struggle to support. In this paper, we focus on addressing this issue by incorporating techniques in self-organizing protocols to support:
- **Optimizing for Dual Metrics:** Overlay links need to be chosen to simultaneously ensure high bandwidth and low latencies from every source to each receiver.
- **Optimizing for Dynamic Metrics:** Internet latencies and available bandwidth are dynamic, and the overlay needs to adapt to long-term variations in path characteristics while being resilient to network noise and inaccuracies. Frequent changes to the overlay topology could result in instability and transient performance degradation.

## 4. Conferencing-Optimized Overlays

In this section, we present a set of techniques to help self-organizing protocols address the challenges of supporting conferencing applications. While we believe our ideas can be easily incorporated into all End System Multicast protocols, we demonstrate them using the Narada protocol [3]. Narada is a mesh-based protocol that runs a distance vector algorithm extended with path information on top of the mesh. It uses a DVMRP-like algorithm for constructing the spanning trees for data delivery. For more details, see [3].

### 4.1 Dealing with Dual and Dynamic Metrics

Constructing an overlay optimized for both latency and bandwidth is challenging. We have been inspired by the work of Wang and Crowcroft [15] on routing with multiple metrics in the Internet. One approach is to optimize the overlay for a single mixed metric that combines both bandwidth and latency. However, it is unclear how this function can individually reflect the bandwidth and latency requirements of the application. Another approach is to treat the two metrics explicitly and equally, making changes to the overlay if either the bandwidth or latency improves. However, this can lead to oscillations when confronted with conflicting options, one with better latency and the other with better bandwidth but poorer latency.

Instead, we consider both bandwidth and latency explicitly but prioritize bandwidth over latency, reflecting the application's semantics better. In Narada, we choose multiple routing metrics in the distance vector protocol running on the mesh: the available bandwidth and the latency of the overlay link. The routing protocol uses a variant of the shortest widest path algorithm presented in [15]. Each member tries to pick the widest (highest bandwidth) path to every other member. If there are multiple paths with the same bandwidth, the member picks the shortest (lowest latency) path among them.

Both available bandwidth and latency are dynamic, leading to stability concerns when used as routing metrics. We address these concerns with the following techniques:

- **Latency:** We filter raw estimates of the overlay link latency using an exponential smoothing algorithm. The advertised link latency remains unchanged until the smoothed estimate differs significantly from the currently advertised latency.
- **Available Bandwidth:** We filter raw estimates of the available bandwidth of an overlay link using an exponential smoothing algorithm to produce a smoothed estimate. Instead of using the smoothed estimate directly, we define discretized bandwidth levels. The smoothed estimate is rounded down to the nearest bandwidth level for routing purposes. For example, a mesh link with a smoothed estimate of 600 Kbps may be advertised as having a bandwidth of 512 Kbps in a system with levels corresponding to 512 Kbps and 1024 Kbps. To prevent oscillations when the smoothed estimate is close to a bandwidth level, we use a simple hysteresis algorithm. We move down a level immediately when the smoothed estimate falls below the current level, but only move up a level if the estimate significantly exceeds the next level.

Given that conferencing applications often have a fixed source rate, the largest level in the system is set to the source rate. Discretization of bandwidth and the choice of a maximum bandwidth level ensure that all overlay links fall into a small set of equivalence classes with respect to bandwidth. This discretized bandwidth metric not only enhances stability in routing but also allows latency to become a determining factor when different links have similar but not identical bandwidth.

With a good quality mesh, the mechanisms described above aim to construct overlay trees that ensure good bandwidth and latencies between every source and recipient. We retain the basic mechanisms in the Narada protocol to improve the quality of the mesh itself. Members probe non-neighbors at random and may add a new link to the mesh if the utility gain of adding the link exceeds a threshold. They monitor existing links and drop them if the cost of dropping the link falls below a threshold. The utility gain and cost are computed based on the number of members whose performance improves (or degrades) in terms of bandwidth and latency if the mesh link is added (or dropped), and the significance of the improvement (or degradation).

### 4.2 Metric Estimation

In this section, we describe how we collect raw estimates of the latency and bandwidth of overlay links, which are used by the routing algorithms presented in Section 4.1. We use different mechanisms for collecting these estimates for links in the mesh and for links that are not.

Members determine the latencies of links in the mesh by periodically (currently every 200 milliseconds) exchanging packets.