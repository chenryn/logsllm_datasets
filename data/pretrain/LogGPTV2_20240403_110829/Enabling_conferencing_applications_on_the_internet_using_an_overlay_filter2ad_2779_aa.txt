title:Enabling conferencing applications on the internet using an overlay
muilticast architecture
author:Yang Chu and
Sanjay G. Rao and
Srinivasan Seshan and
Hui Zhang
Enabling Conferencing Applications on the Internet using
an Overlay Multicast Architecture ∗
Yang-hua Chu, Sanjay G. Rao, Srinivasan Seshan and Hui Zhang
Carnegie Mellon University
{yhchu, sanjay, srini+, hzhang}@cs.cmu.edu
ABSTRACT
In response to the serious scalability and deployment con-
cerns with IP Multicast, we and other researchers have ad-
vocated an alternate architecture for supporting group com-
munication applications over the Internet where all multi-
cast functionality is pushed to the edge. We refer to such an
architecture as End System Multicast. While End System
Multicast has several potential advantages, a key concern
is the performance penalty associated with such a design.
While preliminary simulation results conducted in static en-
vironments are promising, they have yet to consider the chal-
lenging performance requirements of real world applications
in a dynamic and heterogeneous Internet environment.
In this paper, we explore how Internet environments and
application requirements can inﬂuence End System Multi-
cast design. We explore these issues in the context of audio
and video conferencing: an important class of applications
with stringent performance requirements. We conduct an
extensive evaluation study of schemes for constructing over-
lay networks on a wide-area test-bed of about twenty hosts
distributed around the Internet. Our results demonstrate
that it is important to adapt to both latency and bandwidth
while constructing overlays optimized for conferencing ap-
plications. Further, when relatively simple techniques are
incorporated into current self-organizing protocols to enable
dynamic adaptation to latency and bandwidth, the perfor-
mance beneﬁts are signiﬁcant. Our results indicate that
End System Multicast is a promising architecture for en-
abling performance-demanding conferencing applications in
a dynamic and heterogeneous Internet environment.
∗
This research was sponsored by DARPA under contract
number F30602-99-1-0518, and by NSF under grant num-
bers Career Award NCR-9624979 ANI-9730105, ITR Award
ANI-0085920, and ANI-9814929. Additional support was
provided by Intel. Views and conclusions contained in this
document are those of the authors and should not be inter-
preted as representing the oﬃcial policies, either expressed
or implied, of DARPA, NSF, Intel or the U.S. government.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee.
SIGCOMM’01, August 27-31, 2001, San Diego, California, USA..
Copyright 2001 ACM 1-58113-411-8/01/0008 ...$5.00.
1.
INTRODUCTION
Over the last decade, researchers have studied how group
communication applications like audio and video conferenc-
ing, multi-party games, content distribution, and broadcast-
ing can be supported using IP Multicast[4]. However, over
ten years after its initial proposal, IP Multicast is yet to
be widely deployed due to fundamental concerns related to
scalability, and support for higher layer functionality like
reliability and congestion control. Recently, there has been
a reevaluation by the research community of whether IP is
indeed the right layer to support multicast-routing related
functionality. A growing number of researchers [2, 3, 6, 9]
have advocated an alternate architecture, where all multi-
cast related functionality, including group management and
packet replication, is implemented at end systems. We refer
to such an architecture as End System Multicast. In this
architecture, end systems participating in a multicast group
self-organize into an overlay structure using a completely
distributed protocol. Further, end systems attempt to op-
timize the eﬃciency of the overlay by adapting to network
dynamics and considering application level performance.
While End System Multicast can have several potential
advantages, a key concern is the performance of such an
approach. While several recent works have demonstrated
that the performance penalty of using overlays can be ac-
ceptably low, these studies have been conducted primarily
using simulation experiments, static metrics and controlled
environments [2, 3, 9]. However, Internet environments, the
target of these overlay architectures, are dynamic, heteroge-
neous and unpredictable. In this paper we focus on a key
question regarding the feasibility of an overlay architecture:
can such an architecture satisfy the demanding end-to-end
performance requirements of real world applications in such
an environment?
We study this question in the context of an important
class of applications: audio and video conferencing. Inter-
net based conferencing applications have received a great
amount of attention in the last decade, during which ex-
cellent tools like vic[10], vat[8] and rat[7] were developed.
Yet, these tools are not ubiquitously deployed today due to
the limited availability of IP Multicast. Conferencing ap-
plications have stringent performance requirements, and are
among the most challenging to support. They not only re-
quire a high sustained throughput between the source and
receivers, but also require low latencies.
In order to meet these performance requirements, we show
that it is necessary for self-organizing protocols to adapt to
both latency and bandwidth metrics. We present techniques
by which such protocols can adapt to dynamic metrics like
available bandwidth and latency, and yet remain resilient to
55Figure 1: Example of End System Multicast
network noise and inaccuracies inherent in the measurement
of these quantities. We demonstrate our ideas by incorpo-
rating them into Narada, a self-organizing protocol that we
presented in [3]. While we have chosen to use Narada, we
believe that the techniques we present can be incorporated
into other self-organizing protocols. In addition, although
our techniques take advantage of some of the unique char-
acteristics of conferencing applications, we believe that they
could beneﬁt other classes of group communication applica-
tions as well.
We evaluate our techniques by testing the redesigned Nar-
ada protocol on a wide-area test-bed. Our test-bed com-
prises twenty machines that are distributed around North
America, Asia and Europe. Our results demonstrate that
our techniques can provide good performance, both from the
application perspective and from the network perspective.
With our scheme, the end-to-end bandwidth and latency
attained by each receiver along the overlay is comparable
to the bandwidth and latency of the unicast path from the
source to that receiver. Further, when our techniques are in-
corporated into Narada, applications can see improvements
of over 30–40% in both throughput, and latency. Finally,
the costs of our approach can be restricted to 10–15% for
groups of up to twenty members.
The rest of the paper is organized as follows. We be-
gin by providing an overview of End System Multicast and
self-organizing protocols in Section 2. Section 3 presents
important performance issues that self-organizing protocols
need to address to support conferencing applications. Our
techniques for tackling these issues are presented in Section
4. Sections 5, 6 and 7 present our evaluation methodology
and results. Finally, we discuss our results, present related
work, and summarize in Sections 8, 9, and 10.
2. END SYSTEM MULTICAST
In End System Multicast, nodes participating in a multi-
cast group, or proxies that operate on their behalf, organize
themselves into overlay spanning trees for data delivery. The
tree is an overlay in the sense that each link corresponds to
an unicast path between two end systems in the underlying
Internet. For instance, consider Figure 1(a), which depicts
a physical network where R1 and R2 are routers, and A, B,
C and D are end systems. Figure 1(b) shows an overlay tree
rooted at source A, while Figure 1(a) also shows how this
overlay tree maps on to the underlying physical network.
End System Multicast occurs in two distinct architectural
ﬂavors: peer-to-peer architectures and proxy based architec-
tures. In the former, all functionality is pushed to the end
hosts actually participating in the multicast group.
In a
proxy based architecture on the other hand, an organization
that provides value added services deploys proxies at strate-
gic locations on the Internet. End hosts attach themselves
to proxies near them and receive data using plain unicast.
The End System Multicast architecture provides several
advantages over IP Multicast. First, it requires absolutely
no network level support for multicast, and all multicast
functionality is pushed to the edge. By avoiding per-group
state in routers, the inherent scaling concerns introduced
by IP Multicast are avoided. Further, deployment is not
an issue, as no change is required to network infrastructure.
Finally, we believe that solutions for supporting higher layer
features such as error, ﬂow and congestion control can be
signiﬁcantly simpliﬁed by deploying application intelligence
at internal splitting points of an overlay tree.
While End System Multicast has several advantages, a
fundamental challenge is providing a method for nodes to
self-organize into an overlay network that eﬃciently for-
wards multicast packets. There has been a spurt of activity
in the design of self-organizing protocols for End System
Multicast in the last year [2, 3, 6, 9]. These self-organizing
protocols primarily consist of two components: (i) a group
management component; and (ii) an overlay optimization
component. The group management component ensures
that the overlay remains connected in the face of dynamic
group membership and failure of members. The overlay op-
timization component ensures that the quality of the overlay
remains good over time. Overlay optimization involves ob-
taining network information using a variety of techniques
such as active measurements and passive monitoring of per-
formance. As more information is available about the net-
work, or as network conditions change, the overlay can be
modiﬁed by the addition of good links and the dropping of
poor links.
Two basic methods have emerged for the construction of
overlay spanning trees for data delivery. One approach is
to construct the tree directly - that is, members explicitly
select their parents from among the members they know.
Yoid [6] and Overcast [9] adopt this approach. An alternate
approach which protocols such as Gossamer [2] and Narada
[3] use, is to construct trees in a two-step process. First they
construct a richer connected graph termed a mesh. Second,
they construct (reverse) shortest path spanning trees of the
mesh, each tree rooted at the corresponding source using
well-known routing algorithms. While in the extreme case,
a mesh could consist of all possible N ∗ (N − 1) overlay links
in a group consisting of N members, typically protocols try
to keep the meshes sparse in order to keep the overhead of
routing low. Given that the ﬁnal spanning trees are con-
structed from among the overlay links present in the mesh,
it becomes important to construct a good quality mesh in
the ﬁrst place. The reader is referred to [3, 6] for further
discussion of the tree-ﬁrst and mesh-ﬁrst approaches.
3. CONFERENCING APPLICATIONS AND
OVERLAY DESIGN
A key feature of End System Multicast is that it enables
application customizable protocols and architectural deci-
sions. In this section, we study the interaction between End
System Multicast and conferencing applications. We begin
by reviewing the following distinguishing characteristics of
conferencing applications:
• Performance requirements: Conferencing applications re-
quire low latencies, and need to sustain high bandwidth
between the source and receivers.
In contrast, broadcast-
ing and ﬁle transfer applications are primarily interested in
bandwidth, and latency is not a concern.
• Gracefully degradable: Conferencing applications deal with
Figure 2: Architectural framework for supporting
conferencing applications
media streams that can tolerate loss through a degradation
in application quality. This is in contrast to ﬁle transfer ap-
plications that require reliable data delivery.
• Session lengths: Conferences are generally long lived, last-
ing tens of minutes. In contrast, applications like ﬁle trans-
fer and software downloading may be short-lived, lasting for
the duration of the transfer.
• Group characteristics: Conferences usually involve small
groups, consisting of tens to hundreds of participants. Mem-
bership can be dynamic. Again, this is in contrast to ap-
plications like broadcasting, and content delivery that may
deal with much larger group sizes.
• Source transmission patterns: Typically, conferencing ap-
plications have a source that transmits data at a ﬁxed rate.
While any member can be the source, there is usually a
single source at any point in time. In contrast, large scale
broadcasting applications have a single static source through-
out a session.
Several conferencing application features are well suited
to existing End System Multicast techniques. For example,
self-organizing protocols employ self-improving algorithms,
and incrementally produce better overlays by learning net-
work path characteristics and adapting to network dynam-
ics. The small group sizes and long session durations of
conferences match such an approach.
Some aspects of conferencing applications enable relatively
straight-forward application-speciﬁc solutions to existing prob-
lems. For example, the graceful degradation of media streams
allows us to build a system that employs a hop-by-hop con-
gestion control protocol. Congestion control on each indi-
vidual overlay link is ensured by running some TCP-friendly
protocol for streaming media applications [1, 5, 14]. An
overlay node adapts to a bandwidth mismatch between the
upstream and downstream links by dropping packets. Fig-
ure 2 shows an example of an overlay tree, where A is the
source. Links A-B and C-D cannot sustain the source rate
of 5 Mbps, and consequently nodes A and C reduce the rate
using some appropriate packet drop policy.
The performance requirements of conferencing applica-
tions are one key aspect that existing End System Multi-
cast systems cannot support.
In this paper, we focus on
addressing this key issue by incorporating techniques in self-
organizing protocols to support the following:
• Optimizing for dual metrics: Overlay links need to be
chosen in such a manner as to simultaneously ensure high
bandwidth and low latencies from every source to each re-
ceiver.
• Optimizing for dynamic metrics: Internet latencies and
available bandwidth are dynamic, and the overlay needs to
adapt to long-term variations in path characteristics. Yet, it
needs to be resilient to network noise and inaccuracies that
is inherent in the measurement of these quantities. Frequent
changes to overlay topology could result in instability and
transient performance degradation.
4. CONFERENCING OPTIMIZED OVERLAYS
In this section, we present a set of techniques that help
self-organizing protocols deal with the challenges of support-
ing conferencing applications. While we believe our ideas
can easily be incorporated into all End System Multicast
protocols, we choose to demonstrate them on the Narada
protocol [3]. Narada is a mesh-based protocol, and runs a
distance vector algorithm extended with path information
on top of the mesh. It leverages a DVMRP-like algorithm
for constructing the spanning trees for data delivery. Fur-
ther details of Narada can be found in [3].
4.1 Dealing with dual and dynamic metrics
Constructing an overlay optimized for both latency and
bandwidth can be diﬃcult. In designing heuristics for tack-
ling this problem, we have been motivated by the work done
by Wang and Crowcroft [15] in the context of routing on mul-
tiple metrics in the Internet. A ﬁrst choice is to optimize the
overlay for a single mixed metric that is a function of both
bandwidth and latency. However, it is not clear how this
function can individually reﬂect the bandwidth and latency
requirements of the application. A second approach is to
treat the two metrics explicitly and with equal importance.
Thus, a change would be made to the overlay if either the
bandwidth or the latency improves as a result of that change.
However, this approach could lead to oscillations when con-
fronted with two conﬂicting options, one with better latency,
and the other with better bandwidth but poorer latency.
Instead, we consider both bandwidth and latency explicitly,
but prioritize bandwidth over latency. We believe that this
prioritization reﬂects the application semantics better.
We incorporate this idea in Narada, by choosing multi-
ple routing metrics in the distance vector protocol running
on the mesh - the available bandwidth and the latency of
the overlay link. The routing protocol uses a variant of
the shortest widest path algorithm presented in [15]. Every
member tries to pick the widest (highest bandwidth) path
to every other member.
If there are multiple paths with
the same bandwidth, the member picks the shortest (lowest
latency) path among all these.
Both available bandwidth and latency are dynamic in na-
ture, and using them as routing metrics leads to serious
concerns of instability. We deal with the stability concerns
using techniques in the design of the routing metrics de-
scribed below:
• Latency: We ﬁlter raw estimates of the overlay link latency
using an exponential smoothing algorithm. The advertised
link latency is left unchanged until the smoothed estimate
diﬀers from the currently advertised latency by a signiﬁcant
amount.
• Available bandwidth: We ﬁlter raw estimates of the avail-
able bandwidth of an overlay link using an exponential smoo-
thing algorithm, to produce a smoothed estimate. Next, in-
stead of using the smoothed estimate as a routing metric,
we deﬁne discretized bandwidth levels. The smoothed es-
timate is rounded down to the nearest bandwidth level for
routing purposes. Thus, a mesh link with a smoothed es-
timate of 600 Kbps may be advertised as having a band-
width of 512 Kbps, in a system with levels corresponding
to 512 Kbps and 1024 Kbps. To tackle possible oscillations
if the smoothed estimate is close to a bandwidth level, we
employ a simple hysteresis algorithm. Thus, while we move
down a level immediately when the smoothed estimate falls
below the current level, we move up a level only if the esti-
mate signiﬁcantly exceeds the bandwidth corresponding to
the next level.
Given that conferencing applications often have a ﬁxed
source rate, the largest level in the system is set to the source
rate. Discretization of bandwidth and choice of a maximum
bandwidth level ensure that all overlay links can fall in a
small set of equivalence classes with regard to bandwidth.
This discretized bandwidth metric not only enables greater
stability in routing on the overlays, but also allows latency
to become a determining factor when diﬀerent links have
similar but not identical bandwidth.
Given a good quality mesh, the mechanisms described
above seek to construct overlay trees that ensure good band-
width and latencies between every source and the recipients.
We retain the basic mechanisms presented in the Narada
protocol to improve the quality of the mesh itself. Mem-
bers probe non-neighbors at random, and may add a new
link to the mesh if the utility gain of adding the link ex-
ceeds a threshold. Members monitor existing links, and
drop them if the cost of dropping the link falls below a
threshold. The utility gain, and cost are computed based
on the number of members to which performance improves
(degrades) in bandwidth and latency if the mesh link were
added (dropped), and the signiﬁcance of the improvement
(degradation).
4.2 Metric Estimation
In this section, we present details of how we collect raw es-
timates of the latency and bandwidth of overlay links. These
estimates are used by the routing algorithms presented in
Section 4.1. We use diﬀerent mechanisms for collecting
bandwidth and latency estimates for links in the mesh, and
for links that are not.
Members determine latencies of links in the mesh by peri-
odically (currently every 200 milliseconds) exchanging pack-