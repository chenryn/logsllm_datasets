title:Back-Office Web Traffic on The Internet
author:Enric Pujol and
Philipp Richter and
Balakrishnan Chandrasekaran and
Georgios Smaragdakis and
Anja Feldmann and
Bruce MacDowell Maggs and
Keung-Chi Ng
Back-Ofﬁce Web Trafﬁc on The Internet
Enric Pujol
TU Berlin
PI:EMAIL
Georgios Smaragdakis
MIT / TU Berlin / Akamai
PI:EMAIL
Philipp Richter
TU Berlin
PI:EMAIL
Balakrishnan Chandrasekaran
Duke University
PI:EMAIL
Anja Feldmann
TU Berlin
PI:EMAIL
Bruce Maggs
Duke / Akamai
PI:EMAIL
Keung-Chi Ng
Akamai
PI:EMAIL
ABSTRACT
Although trafﬁc between Web servers and Web browsers is read-
ily apparent to many knowledgeable end users, fewer are aware of
the extent of server-to-server Web trafﬁc carried over the public
Internet. We refer to the former class of trafﬁc as front-ofﬁce In-
ternet Web trafﬁc and the latter as back-ofﬁce Internet Web trafﬁc
(or just front-ofﬁce and back-ofﬁce trafﬁc, for short). Back-ofﬁce
trafﬁc, which may or may not be triggered by end-user activity, is
essential for today’s Web as it supports a number of popular but
complex Web services including large-scale content delivery, so-
cial networking, indexing, searching, advertising, and proxy ser-
vices. This paper takes a ﬁrst look at back-ofﬁce trafﬁc, measuring
it from various vantage points, including from within ISPs, IXPs,
and CDNs. We describe techniques for identifying back-ofﬁce traf-
ﬁc based on the roles that this trafﬁc plays in the Web ecosystem.
Our measurements show that back-ofﬁce trafﬁc accounts for a sig-
niﬁcant fraction not only of core Internet trafﬁc, but also of Web
transactions in the terms of requests and responses. Finally, we dis-
cuss the implications and opportunities that the presence of back-
ofﬁce trafﬁc presents for the evolution of the Internet ecosystem.
Categories and Subject Descriptors
C.2.3 [Computer-Communication Networks]: Network Opera-
tions.
Keywords
Network measurement; the Web; content delivery; online adver-
tisements; real-time bidding; crawlers.
1.
INTRODUCTION
The Web has not only revolutionized the way people publish, ac-
cess, and search for content but, some would argue (e.g.,
[49]),
has also evolved to become the new “narrow waist” of the Internet.
Indeed, the HTTP protocol provides a common interface that many
popular Internet applications rely on, including video, social net-
working, e-commerce, and software delivery. These applications
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
IMC ’14, November 5–7, 2014, Vancouver, BC, Canada.
Copyright 2014 ACM 978-1-4503-3213-2/14/11 ...$15.00.
http://dx.doi.org/10.1145/2663716.2663756.
org. A
S2
S1
org. B
S3
S4
org. C
front-ofﬁce trafﬁc
back-ofﬁce trafﬁc
Figure 1: Front- vs. back-ofﬁce Internet Web trafﬁc.
are often supported by advertisements, which are also delivered via
HTTP.
Although an end user typically views a Web page as a unit, re-
cent studies [17, 36] demonstrate that a single Web page often con-
tains links to objects that are delivered by a large and diverse set
of servers. For example, the creation of a single Web page may in-
volve several Web companies as, e.g., parts of the Web page may be
under the control of a content provider, a Web advertiser, a video
streamer, a search engine, and/or a social network. Furthermore,
even fetching an individual part of a Web page may involve many
parties. For example, when an end user requests Web content,
the delivery involves not only the servers that receive HTTP re-
quests from the end user’s browser, but also a whole service ecosys-
tem consisting of proxies, content delivery networks (CDNs), ad-
sellers, ad-bidders, back-end servers or databases, crawler bots, etc.
Thus, “there is more to content delivery than is visible to the
eye,” and, consequently, this paper explores the distinction between
front-ofﬁce and back-ofﬁce Web trafﬁc. The ﬁrst refers to the traf-
ﬁc involving end users directly. The second refers to Web trafﬁc
exchanged between machines (e.g., the front-ofﬁce servers and any
other server which is part of the Web service ecosystem). Figure 1
depicts this distinction. Note that not all back-ofﬁce Web trafﬁc
travels over the public Internet. Some is carried over private back-
bones or within data centers. In this paper, we focus on back-ofﬁce
Web trafﬁc on the public Internet. For short, we henceforth use the
term “front-ofﬁce trafﬁc” to refer to front-ofﬁce Web trafﬁc carried
on the public Internet and similarly for “back-ofﬁce trafﬁc.”
In contrast to back-ofﬁce trafﬁc, front-ofﬁce trafﬁc has long been
studied, e.g., [8, 14, 17, 26, 27, 45, 47]. While there is some related
work on Machine-to-Machine trafﬁc in speciﬁc environments, e.g.,
in cellular networks [52] and within data centers [12, 13, 34], we
are not aware of studies of back-ofﬁce Web trafﬁc on the public
Internet. Liang et al. studied security-related aspects arising from
CDN back-end communication [44] and for some speciﬁc other
services, e.g., DNS, Gao et al. have characterized the correspond-
ing Machine-to-Machine trafﬁc [31].
The reason why previous work has focused mainly on front-
ofﬁce trafﬁc is that end-user Quality of Experience (QoE) can be
analyzed by observing front-ofﬁce trafﬁc, but back-ofﬁce trafﬁc is
257often opaque. Today, more and more Web services also depend on
some back-ofﬁce communication over the public Internet e.g., to
assemble Web pages, to perform search queries, to place advertise-
ments, to conduct database transactions, to dynamically generate
personalized content, Thus, service QoE now also depends criti-
cally on the architecture and performance of the back-ofﬁce, which
relies increasingly on the public Internet. This complexity makes
measuring and characterizing back-ofﬁce trafﬁc challenging.
Among the difﬁculties faced in studying back-ofﬁce trafﬁc is that
it is rarely present on the network links connecting end users to the
Internet. Instead, back-ofﬁce trafﬁc can generally only be observed
on backbone or inter-domain links. However, existing studies of
inter-domain and/or backbone trafﬁc [32, 42, 50] have not sepa-
rated front-ofﬁce and back-ofﬁce Web trafﬁc.
Indeed, the back-
ofﬁce trafﬁc component for any individual link depends highly on
whether the link is on any of the routes between the involved servers.
Thus, to observe this trafﬁc requires a variety of vantage points. In
this paper we analyze data collected from two IXPs, multiple links
of a Tier-1 ISP, and a major CDN.
Web services that involve back-ofﬁces include content delivery,
search, and advertisements. We focus on these because content de-
livery is responsible for a signiﬁcant fraction of all Internet trafﬁc,
while advertisements (and in particular those in response to search)
are responsible for a signiﬁcant fraction of Internet revenues.
According to recent studies [32, 42, 48] CDN trafﬁc accounts for
more than 50% of Web trafﬁc. This percentage is expected to fur-
ther increase in part due to the increasing trafﬁc volume attributed
to video delivery [23]. Since CDNs operate sophisticated back-
ofﬁces with distributed server infrastructures, some of this trafﬁc is
back-ofﬁce trafﬁc, which may or may not be routed via the pub-
lic Internet depending on whether the CDN operates its own back-
bone [37] or not [54]. The rationale for this distributed infrastruc-
ture is the need to improve the end-user experience, react to ﬂash
crowds, mitigate attacks, and reduce the cost of content delivery
using economies of scale [7, 43, 46]. CDNs are aware of the need
to constantly improve communication between their front-end and
back-end servers [28, 43, 54].
Search is one of the essential Internet Web services. Without
search, the Internet would hardly be usable for most end users as
their desired content would be difﬁcult to locate. Search relies on
a back-end database which is typically populated by crawling the
Internet. For this purpose, search providers including Google and
Microsoft operate distributed server infrastructures that crawl the
Web. Web crawlers (also known as crawl bots), are orchestrated
to partition the Web and index different parts of it to more efﬁ-
ciently cover it. Once the crawler bots have collected their data,
they upload it to the back-end where it is processed in large data
centers [11], where massively parallel indexing algorithms are used
to enable fast search queries [19]. To deliver search results they rely
on overlays and/or the above mentioned CDNs [22]. Thus, search
engines contribute to back-ofﬁce Web trafﬁc.
To monetize their content, most Web sites rely on targeted on-
line advertisements.
In 2013, online advertising revenues in the
United States were estimated to be $42.8 billion [2], an increase
of 17% over the previous year. The increasing revenue stream of
Web advertisement has given rise to another innovative part of the
Web ecosystem: ad-sellers, ad-bidders, and ad-brokers—the ad-
networks [10, 59]. These parties negotiate placement of advertise-
ments in today’s Web. In many instances, the selection of an ad-
vertisement does not take place until an end user visits a Web page
where advertisement space is available. At this point, an auctioneer
contacts the potential advertisers with information about the visi-
tor’s proﬁle and a bidding process is initiated, but hidden from the
user. Thus, a visit of an end user to a Web page may trigger a
number of back-ofﬁce connections. Advertisement content is often
delivered via a CDN.
Thus, back-ofﬁce Web Trafﬁc is one of the principle but yet
largely unexplored components of today’s Web. The contributions
of this paper are:
(cid:129) We introduce the notion of back-ofﬁce Web trafﬁc and show
that its contribution ranges on average from 10% to 30% per
vantage point and can even exceed 40% for some time pe-
riods. The vantage points include two major IXPs, multiple
backbone links from a major ISP, and a number of server
clusters from a major CDN. We explore the reasons that dif-
ferent levels of contributions are seen at different vantage
points.
(cid:129) Our methodology allows us to identify and classify different
types of back-ofﬁce trafﬁc including proxy services, crawl-
ing, and advertisement bidding.
(cid:129) Our analysis demonstrates that back-ofﬁce trafﬁc character-
istics differ from front-ofﬁce characteristics. Moreover, they
vary enough by service that individual services can be iden-
tiﬁed.
(cid:129) We ﬁnd, for example, that at one of the IXPs auctioneers
have a 22% share of the back-ofﬁce requests but only 1%
of the bytes, while crawlers contribute respectively roughly
10% and 15% to both.
(cid:129) Our analysis of data from a major CDN conﬁrms what we
observe in the wild: CDNs deploy sophisticated back-ofﬁce
infrastructures, and back-ofﬁce Web trafﬁc is signiﬁcant.
(cid:129) Given the volume of back-ofﬁce trafﬁc on the Internet and its
importance for end-user QoE, we identify implications of our
analysis on network protocols design and co-location strate-
gies.
2. BACK-OFFICE COMMUNICATION
In this section we provide a brief overview of the typical (i.e., ex-
pected) communication patterns of Web services that create back-
ofﬁce trafﬁc. Hereby, we distinguish four different cases: (a) prox-
ies/intermediaries, (b) CDN services, (c) auctioneers, and (d) crawlers.
Figure 2 provides an illustration of the expected exchange of HTTP
messages. Note, however, that our analysis (Section 7) unveils
richer and more complex communication patterns than those shown
in the ﬁgure.
(a) Proxies/Intermediaries: An intermediary is a network entity
that acts as both a client and a server. As shown in Figure 2(a), a
Web proxy is an intermediary that acts as a client with the main pur-
pose of forwarding HTTP(S) requests. Thus, Web proxies send and
receive requests in a temporally correlated fashion. Forward and re-
verse Web proxies evaluate requests, check if they can be satisﬁed
locally, and contact a remote server only if necessary. When in-
termediaries act as clients, they create back-ofﬁce trafﬁc, but when
intermediaries act as servers, the trafﬁc they create can be either
front- or back-ofﬁce trafﬁc. We describe how to differentiate these
two cases in Section 6.
(b) CDN Servers: CDNs typically operate front-end servers
(i.e., reverse proxies) close to the end user as well as back-end
servers. Back-end servers either host the content in data centers
or are closer to the origin content server, depending on the CDN’s
deployment and operation strategy [46, 35, 57, 37, 18, 5, 3]. If
the front-end does not have a requested object available locally, it
fetches the object from another front-end, a back-end, or the origin
server. Since the overall content delivery time has a direct impact
on application performance, e-commerce revenue, and end user
engagement [39, 23, 41], a number of optimizations for creating
258HTTP GET/POST
HTTP GET/POST
Web Proxy
(a) Proxies/Intermediaries
HTTP
GET/POST
Ad Publisher
Ad Exchange
Auctioneer
HTTP GET
(c) Ad Exchanges - Auctioneers and Bidders
S1
S3
S2
S4
Advertiser/Bidder A
Advertiser/Bidder B
Advertiser/Bidder C
CDN
Front-End
Server
Back-End
Server
HTTP GET
HTTP GET
(b) CDN Servers
Web 
Crawler
HTTP GET
(d) Crawlers
Content Origin
Server
S1
S3
S2
S4
front-ofﬁce Web requests
back-ofﬁce Web requests
Figure 2: Back-ofﬁce Web Trafﬁc: typical HTTP requests made by Web proxies, CDNs, ad-exchanges, and crawlers.
overlays to improve end-to-end performance and for task sharing
between front-end and back-end servers are deployed by today’s
CDNs [43, 54, 28, 40, 21].
(c) Ad Exchanges – Auctioneers and Bidders: As shown in
Figure 2(c), advertisement exchanges consist of (i) publishers that
sell advertisement space (ad space) on their Web pages, as well as
(ii) advertisers that buy ad space on these Web pages. An exchange
acts as a common platform to bring publishers and advertisers to-
gether. The matching between offered ad space on a Web site and
interested advertisers is often performed using real-time bidding
(RTB). Once an end user visits a Web page where ad space is avail-
able, the ad exchange auctioneer contacts the potential advertisers
(i.e., the bidders), and provides information about the visitor to start
a bidding process among the interested parties [10, 59, 55, 9].1 A
number of sophisticated tools together with visitor information sup-
pliers optimize the bidding process for both the advertisers and the
publishers. Hence, if RTB is used to place ads on a website, the
visit of a Web page by an end user may trigger a large number of
requests in the background. The ﬁnal advertisement content is typ-
ically delivered via CDNs [9]. We note that today’s Web advertise-
ment ecosystem is complex and may involve many different types
of back-ofﬁce trafﬁc, caused by a variety of different actors.
In
this paper, we solely focus on RTB-related activity, i.e., back-ofﬁce
trafﬁc as a result of auctioneers interacting with bidders.
(d) Crawlers: Web crawlers continuously index the Web. To op-
timize crawling, each crawl bot is typically responsible for indexing
a small part of the Web [11]. Indexing involves requesting the Web
page as well as following embedded links [38, 16]. Web crawlers
typically issue an order of magnitude more Web queries than reg-
ular end users. Best practices among the major search engines en-
sure that crawlers have appropriate reverse DNS entries along with
well-speciﬁed user agents in order to avoid being blocked by Web
sites.
Hereafter, we refer to back-ofﬁce Web trafﬁc as all Web traf-
ﬁc that is not exchanged between end users and servers. This in-
cludes trafﬁc exchanged between intermediaries and Web servers