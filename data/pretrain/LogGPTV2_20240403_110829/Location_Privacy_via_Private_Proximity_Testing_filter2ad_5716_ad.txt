Correctness. We state a generalized form of the Berlekamp
Massey decoding algorithm from [24]:
Theorem 1 (Berlekamp-Massey decoding) There is an
algorithm BM such that, given k pairs (xi, yi) over a ﬁeld
F and a degree parameter d
• if there exists a polynomial p that passes through at
least k+d
2 of the points, BM outputs p
• otherwise BM outputs ⊥
The proof of correctness now continues.
Case 1. When Alice and Bob are nearby, there are at
least t + 2(n − t) = 2n − t points on the polynomial. Sub-
stituting k = n + 2(n − t) = 3n − 2t and d = n − 1
in Theorem 1, we ﬁnd that the condition is satisﬁed, and
therefore Bob succeeds in ﬁnding a polynomial.
Case 2. When Alice and Bob are far apart, we start with
the observation that |A(cid:48) ∩ B(cid:48)| < n − t w.h.p. (speciﬁcally,
with probability at least 1 − ( n2
N )n−t). This is a matter of
bounding probabilities and we omit the proof. By construc-
tion this implies |A ∩ B| < t. This means that there are
fewer than 2n − t points on the polynomial p, and by The-
orem 1, Bob will fail to ﬁnd an appropriate polynomial.
This completes the proof of correctness.
Security. We show that when Alice and Bob are far apart,
Alice has information theoretic security. We argue as fol-
lows: let us give Bob some auxiliary information: speciﬁ-
cally, which of his location features are common with Alice.
In spite of this extra information, Bob has 2(n− t) + t(cid:48) < n
points from a polynomial of degree n − 1, and therefore his
view of the protocol is statistically indistinguishable from
random.
Using the location itself. As presented, this protocol does
not use the location co-ordinates. This might be desirable
in practice due to the poor coverage of GPS in indoor en-
vironments (where location tags are abundant), or to enable
location features on devices such as laptops that do not have
GPS capabilities. Alternately, the protocol could be modi-
ﬁed to treat the x and y location co-ordinates as two of the
location features.
Collusion resistance. This protocol is not secure when
multiple instances are run with the two sets of inputs be-
ing dependent. Therefore, only location tags that are com-
pletely time-varying (i.e., independent in each epoch) will
work. Among the types of tags that we have empirically
studied, that boils down to WiFi broadcast packets. It also
means that the protocol needs to be run synchronously, even
though there is only a single message sent.
To achieve collusion resistance, each of Alice’s execu-
tions of the protocol with her different friends must use
different location tags. Given the abundance of broadcast
packets in our experiment5, this is feasible. We can use
a hash function to ensure that in each instance a random
subset of location features are used. This would work as
follows:
The protocol instance between players i and j uses only
location features f for which H(i, j, η, f ) = 0 where η is
the epoch and H is a hash function modeled as a random
oracle with range {1, . . . k}, k being (say) 20. This way,
if Bob and Carol collude against Alice, Alice is still safe
20 of the features used in the two
because on average only 1
protocol instances are common.
However this protocol is not cryptographically com-
posable; therefore if sufﬁciently many (speciﬁcally, Ω(k))
friends collude then security will be lost.
5
Implementation
We have built a prototype implementation on the An-
droid platform. The proximity detector is a “background
activity” that alerts the user when one or more friends are
nearby. Protocols 1 and 2 have been implemented. In this
section we describe some of the implementation details.
On the client we use Bouncy Castle, the standard cryp-
tography toolkit for Android. Unfortunately, Bouncy Castle
does not yet support Elliptic Curve Cryptography, so we
implemented Protocol 1 over Z∗
p with a length of 1024 bits.
We implemented our own server in Python. The server acts
as a router in protocol 1; in either protocol, there is no big
integer arithmetic on the server.
Grid. We allow the grid size to be user-conﬁgurable with
pre-deﬁned defaults of 10m, 100m and 1000m. There is no
conﬂict is the grid sizes of a pair of users don’t match. The
protocols are asymmetric, and in each instance of the pro-
tocol the “receiver” quantizes his location according to the
“sender’s” grid size. Since the sender gets no information
at the end of the protocol, the receiver can do so without
worrying about security.
Since the Earth is round and the tessellation in discussed
Section 2.5 assumes a plane world, we divide the Earth into
5If there are 300s in an epoch, the number of usable location features is
around 4,500.
strips (corresponding to 1◦ latitude each). The curvature of
the Earth within a single strip is small enough to ignore.
This allows us to keep the size of the grid cells approxi-
mately the same everywhere, but there is a small error prob-
ability at the boundary between two of the strips (because
the cells on either side of the strip don’t line up).
Synchronization. Recall that protocol 1 needs to run ev-
ery few minutes (epochs) in a synchronized manner. The
epoch duration in our implementation is ﬁxed globally at 5
minutes.
All communication is through HTTP. We chose to es-
chew a “push” infrastructure such as Comet and instead
adopted the following solution. For each round, each de-
vice ﬁrst performs computations and sends the results to the
server; then it waits for a ﬁxed time interval (30s) from the
start of the round for the other devices to ﬁnish their send
steps. Then the device downloads the data from the server
that it is supposed to receive in that round.
5.1 SocialKeys: key exchange over social net-
works
Conventional PKI using certiﬁcate authorities is too
heavyweight for the needs of most users. A well known us-
ability evaluation of PGP in 1999 concluded that it is nearly
unusable for the majority [48]. While the software has im-
proved since then, the underlying architectural and design
issues remain.
SocialKeys embraces the idea that public keys must be
associated with the digital identities that people already own
and use, i.e., their social network accounts, rather than re-
quiring the creation of new identities for cryptographic pur-
poses. While this is not a new idea, we go one step fur-
ther by enabling such an association for existing social net-
works, even though none of them support such a capability.
We achieve this not by relying on a third-party service, but
rather by repurposing social network features in unintended
ways.
By ofﬂoading the establishment of trust between users
to the social network, SocialKeys obviates the need for a
“key manager”. As a consequence, it is almost completely
transparent to the user.
Currently we have implemented key distribution over
Facebook as well as an Android “service” that exposes an
API that any SocialKeys-aware applications can use. Sup-
port for other popular social networks as well as extensions
for Firefox (to enable secure web mail, including Facebook
messages) and Pidgin (to enable secure instant messaging)
are potential future extensions. We are exploring the possi-
bility of tighter integration with a couple of social networks.
That said, the SocialKeys architecture is interoperate with
OpenID or any other social network.
While SocialKeys aims to be more user friendly than a
traditional PKI, it is probably not as secure. The two main
weaknesses are trust in the identities represented by social
networking proﬁles and the difﬁculty of key revocation.
Verifying the identity of a social proﬁle is not foolproof
[46] and this remains a topic of research [45]. However,
in the context of a social network-based application that al-
ready relies on the trustworthiness of friends’ proﬁles, we
do not lose security by leveraging the same social network
for key distribution.
Architecture of client application
• On the user’s ﬁrst interaction with SocialKeys, the
client application generates a public/private key pair.
The user is asked for a password; in addition to this
password, they are also presented with three random
dictionary words to memorize. Each dictionary word
has around 16 bits of entropy, and therefore we can
get a 80-bit security level starting with a reasonably
strong password with around 32 bits of entropy. The
password is generated according to PKCS 5 (RFC
2898) [25], with an iteration count of 1000.
To set up SocialKeys on a new device, the user re-
enters the password and dictionary words from their
ﬁrst setup. This ensures that the same key pair is re-
produced.
• The public key can be uploaded to the social network
in one of two ways: 1. directly, encoded as a URL;
2 by pointing to a key server. Currently only the ﬁrst
method is implemented. An example of such a URL is
given below:
https://socialkeys.org/pubkey?alg=DH
&keylen=1024&p=oakley&g=2&key=LlI+lKCAIE...
The latter approach is more complex to implement but
has some advantages in that it is more extensible and
avoids URL length limits. We decided that it was
overkill for our purposes.
• Most social networks allow the user to specify one or
more “websites” in her proﬁle. We make use of this
feature to store the key.
• The client application lives as an Android background
process and exposes an API that allows it to receive the
identity of any Facebook user (or any supported iden-
tity). On receiving an identity the client downloads the
public key of that identity and computes and returns a
shared secret key.
• Once an identity has been seen by SocialKeys it is peri-
odically polled and the key is kept up to date. Currently
this is the only revocation mechanism. The Facebook
API allows retrieving the public keys of all of one’s
friends with a single query, so it ends up being quite
efﬁcient in practice.
5.2 Evaluation
Performance. We calculated the CPU time required to run
Protocol 1 and Protocol 2 with 100 (mutual) friends, i.e., the
protocol was executed in both directions. Protocol 1 took
46.2 ± 1.4 seconds and Protocol 2 took 3.0 ± 0.3 seconds.
The device we used was a Motorola Droid, with a ARM
Cortex-A8 500MHz processor.
Note that the epoch for Protocol 1 is 5 minutes, so we
can easily handle several hundred friends (although the bat-
tery life may be a concern; we have not tested this aspect.)
Also, we have not implemented any of the optimizations de-
scribed in Section 3.1 for computing exponentiations. Fur-
thermore, as mentioned earlier Elliptic Curve Cryptogra-
phy libraries are not yet available on the Android platform.
Once we are able to switch to ECC, we expect to be able to
see a signiﬁcant speedup. For Protocol 2, the CPU load is
far lower.
6 Discussion
Proximity testing in the peer-to-peer model. The previ-
ous discussion describes proximity testing using a client-
server model, but a peer-to-peer model might also yield
interesting results. For example, each node could simply
broadcast its identity to all neighboring nodes. If the broad-
cast is in the clear then this scheme allows proximity testing
between complete strangers, but provides no privacy what-
soever. With a suitable encryption scheme, however, it can
provide private proximity testing between friends only. Be-
cause this approach is passive on the receiving end, it would
use less bandwidth than a server-based approach.
However, there are some notable difﬁculties compared to
a server-based approach. First, it is difﬁcult to control the
granularity of proximity testing; granularity is simply equal
to the broadcast radius on the channel used and it is not
possible to implement different granularities for different
friends. More importantly, such a peer-to-peer mechanism
has a signiﬁcant security drawback.
Imagine an attacker
that records and uploads all the broadcasts from a particular
area. Alice can use this data to see if any of her friends
passed through that area (and when), even though she was
not there herself.
Thus, a peer-to-peer broadcast might serve as a nice
complement to the client-server protocols we have devel-
oped — users might be comfortable broadcasting in some
situations but not in others. Due to the challenges with this
design we do not pursue it here.
Leaking the result of proximity testing to the server. In
the protocol of Section 3.2, the server remains oblivious to
the result of the proximity test. It is tempting to design pro-
tocols in which the server does learn the result, because it
can be made even more efﬁcient.
However, the outcome of pairwise proximity testing can
be much more revealing than is at ﬁrst apparent, especially
when combined with auxiliary information. Suppose the
server has auxiliary information about the work locations
of most of the users. Then it can match the proximity-
testing adjacency graph with the adjacency graph of known
work locations to essentially learn the locations of all the
users. Highly robust algorithms for matching/inferring such
graphs are known [33, 11].
7 Related Work
Location privacy. A non-technical discussion of the issues
around location privacy is provided by Blumberg and Eck-
ersley [5].
The work closest to ours is perhaps by Zhong, Gold-
berg and Hengartner who study three protocols for privacy-
preserving proximity detection in the two party setting [51].
The main difference is that they require the users to learn the
mutual distance, which necessitates computationally expen-
sive cryptography. Their work builds on Atallah and Du’s
study of secure multi-party computational geometry [2].
A privacy-aware friend locator was studied in [47]. Un-
fortunately the technique used therein has many ﬂaws in-
cluding the fact that the server always learns the result of
proximity testing.
There is a large body of work on using anonymization for
location privacy. The work of Gruteser and Grunwald [17]
kicked off a long line of papers in this area. Another
seminal work is by Beresford and Stajano who introduced
“mix zones” [4]. For examples of more recent work, see
[23, 28, 44].
This approach has several potential limitations including
the highly identifying nature of location information [16]
and the limited location resolution resulting from the ob-
fuscation or quantization needed for anonymization. At any
rate, since the application we have in mind is fundamentally
social in nature, pseudonymous identities are not suitable.
Ghinita et al. show how to use Private Information Re-
trieval in Location-based services such as search [15].
Location tags were introduced by Qiu et al. in [37, 36].
There were signiﬁcant differences from our use of location
tags: they studied signals such as Loran which are not avail-
able on consumer devices, and they require location tags to
be stable with time.
There is a body of work on location-based encryption.
Some of it assumes the existence of tamper-proof (“anti-
spoof”) hardware [43]. Other work such as [41] is more
rigorous and involves securely verifying the location of the
receiver based on timing or strength of electromagnetic sig-
nals.
Many papers have studied security and privacy issues in
vehicular communications. Ad-hoc networks of proximate
vehicles have been studied in [50, 39]. Another line of work
aims to mitigate the privacy issues in tracking and monitor-
ing of vehicles; see for example [35].
PET and Private set intersection. Fagin, Naor and Win-
kler discuss numerous protocols for PET with a focus on
protocols that can be executed by humans [12].
Freedman, Nissim and Pinkas described a private set in-