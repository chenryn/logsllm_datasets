nearest neighbor with probability 1‚àíŒ¥, without requiring brute-
force distance comparisons between vectors.
) time and O(N 1+œÅ(cid:48)
Proof. See Appendix D.
(cid:4)
1
Bounded false-positives (in the worst case). The consequence
of Proposition 1 is that while we can bound false-positives to
any Œ¥, this comes with the cost of increasing the number of
(cid:7). Because k is a function of the
hash tables L, since L =(cid:6)p‚àík
LSH sensitivity, we need to ensure that the difference between
p1 and p2 is sufÔ¨Åciently large to result in reasonable values
of k and L. We describe such LSH families in Appendix C.
In our evaluation (Section VIII), we show that on real data,
we can have false positive probability less than 0.05 with
k = 2. This guarantees that all collisions are within cR from
the query (i.e., all collisions are near neighbors), with high
probability. Additionally, in Section IV-C, we describe a trick
called LSH multi-probing which amortizes the number of hash
tables required to retrieve L candidates.
Finding the nearest neighbor. We are now left with the
problem of Ô¨Ånding the nearest neighbor within the set of
all cR-neighbors. Our idea for doing so is based on a
Fig. 3: Illustration of using multiple radii (R) to search for the nearest
neighbor. Left: Each of the dotted regions represents a different hash
function radius. Right: The candidate result with the smallest Ri is
the nearest neighbor, in this case the bucket corresponding to R2.
Comparison-free ANN search data structure
BUILD(DB,H1, . . . ,HL) ‚Üí (T1, . . . , TL, h1, . . . , hL):
takes as input a set of N vectors v1, . . . , vN and L hash
families Hi corresponding to a radix RL ‚â§ Ri ‚â§ RL.
1: Sample random hi from Hi, for i ‚àà {1, . . . , L}.
2: Use hi to build Ti by hashing each vector v1, . . . , vN .
3: Output the similarity search data structure consisting of
L hash tables T1, . . . , TL and LSH functions h1, . . . , hL.
QUERY(T1, . . . , TL, h1, . . . , hL, q) ‚Üí ID; as in Figure 9.
1: Compute (Œ±i,1 . . . Œ±i,(cid:96)) ‚Üê multiprobe(hi, (cid:96), q). and
2: x ‚Üê min i with nonempty B, or 0 if no such i exists.
3: if x (cid:54)= 0 then output any Œ≥ s.t. vŒ≥ ‚àà BŒ±x; else output 0.
retrieve buckets BŒ±i,j from Ti.
Fig. 4: ANN search data structure with no direct comparisons.
bucketing technique of Ahle et al. [48], which resembles radix
sorting [54]. A radix sort does not perform direct comparisons,
which aligns well with our goals. We repeatedly apply the data
structure of Proposition 1 on a series of increasing neighbor
radii, retrieving a set of candidates from each radius [48].
The ANN is then chosen at random from the Ô¨Årst non-empty
candidate set (see Figure 3 for an illustration of this process).
C. LSH multi-probing
The number of tables as given by Proposition 1 can become
very large due to the ampliÔ¨Åcation. However, we the number
of tables can be decreased through an optimization called
LSH multi-probing. The idea behind LSH multi-probing is
the following: if the bucket to which the query hashes to in a
table is empty, then it is likely that ‚Äúadjacent‚Äù buckets in the
table contain a collision (due to the locality property) [61, 69].
To exploit this observation, each hash table is probed on (cid:96)
keys which ‚Äúsurround‚Äù the query. In turn, this reduces the
number of hash tables required (the original motivation of multi-
probing [61]) to Ô¨Ånd a non-empty candidate. An additional
appealing property of multi-probing is that it allows us to apply
batching techniques when processing queries which heavily
amortizes processing time for the servers (see Section V-A).
We deÔ¨Åne the multiprobing function that outputs (cid:96) hashes for a
function h and query q as multiprobe(h, (cid:96), q) ‚Üí (Œ±1 . . . Œ±(cid:96)).
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:00:59 UTC from IEEE Xplore.  Restrictions apply. 
5915
R10 -4 - ./ $"#*-R2R4R1R2R3R4R5*''$.$*)./ #-$3 - $"#*-.R3R5D. The comparison-free ANN data structure
V. PROTOCOL
Our new ANN data structure (presented in Figure 4) merges
the above ideas to eliminate the brute-force step present in the
LSH-based data structure of Gionis et al. [43]. The client can
simply select any element from the Ô¨Årst non-empty candidate
set. This data structure can be further adapted to suppress
database leakage, as we explain in the next section.
We now describe the details of the high-level ideas covered
in Section IV. We Ô¨Årst formalize the necessary building-blocks
in Section V-A (distributed point functions and our oblivious
masking technique) and then present the full ANN search
protocol in Section V-B.
A. Building blocks
E. Database privacy and suppressing leakage
In this section we explain how the ideas of Section IV-B
are useful to suppress database leakage. Our approach is a
combination of three changes applied to QUERY in Figure 4.
We recall that a simple strawman protocol achieving client
privacy can be constructed by having the client privately retrieve
colliding buckets through PIR [29].
Capping buckets. Our Ô¨Årst observation is that we only need
to retrieve one element from the data structure of Figure 4.
As such, we can limit each hash bucket to only contain one
vector without affecting the success of the protocol. Any non-
empty bucket will remain non-empty. This will ensure that
no information is revealed (to either party) by the size of the
bucket returned to the client.
Existing tool: Distributed Point Functions. A point function
PŒ± is a function that evaluates to 1 on a single input Œ± in
its domain and evaluates to 0 on all other inputs j (cid:54)= Œ±. A
distributed point function (DeÔ¨Ånition 2) is a point function
that is encoded into a pair of keys which are used to obtain a
secret-shared evaluation of PŒ± on a given input j.
DeÔ¨Ånition 2 (Distributed Point Function (DPF) [20, 21, 42]).
Fix any positive integer n. Let Fp be a Ô¨Ånite Ô¨Åeld (e.g., integers
mod prime p), and let Œª be a security parameter. A DPF consists
of two (possibly randomized) algorithms:
‚Ä¢ Gen(1Œª, Œ± ‚àà {1, . . . , 2n}) ‚Üí (kA, kB) takes as input an
index Œ± and outputs two evaluation keys kA and kB,
‚Ä¢ Eval(k, j) ‚Üí vj ‚àà Fp takes as input an evaluation key k
and index j ‚àà {1, . . . , 2n} and outputs a Ô¨Åeld element vj.
Hiding the vectors. Because the client selects the Ô¨Årst non-zero
ID from the candidate set using the data structure described
in Figure 4, it does not need access to the raw vectors. As
such, we can modify each hash table (BUILD; Figure 4) to
only store the IDs of each vector. The client can still query
the hash tables using PIR but now only obtains a candidate
set of IDs (absent the vectors). If each vector in the database
is d dimensional and the number of hash tables is L =
N
(Section II), then roughly speaking, this simple change reduces
N ¬∑ log N + d)
leakage from O(
bits (each ID is at least log N bits and O(d) bits are leaked
implicitly by the inference that the neighbor features are similar
to the query; see Section VII for more details).
‚àö
N ¬∑ log N ¬∑ d) bits to O(
‚àö
‚àö
‚àö
Hiding the candidate set. Compared to the ideal leakage of
N ¬∑ log N + d) bits is far
O(log N + d) bits, the leakage of O(
from optimal. We eliminate (most of) the additional leakage by
designing a special ‚Äúoblivious masking‚Äù transformation which
hides all-but-one non-zero candidate ID from the client. From
the masked candidate set ÀúC, the client is able to extract at
‚àö
most one ID that collided with its query. This further reduces
N¬∑log N +d) bits down to O(log N +d) bits
leakage from O(
(since only one ID is revealed), which matches the asymptotic
leakage of the baseline functionality. We provide details on
the oblivious masking transformation in Section V-A, and a
formal leakage analysis in Section VII.
With these three leakage-suppressing steps, our protocol
achieves close to optimal concrete database leakage per
query. Importantly, the leakage guarantees hold in the face
of malicious clients that may deviate from protocol in an
attempt to learn more than an honest client (Section VII).
These algorithms must satisfy correctness and privacy:
Correctness. A DPF is correct if for all pairs of keys generated
according to Gen,
Pr
Eval(kA, j) + Eval(kB, j) =
if j = Œ±
1,
0, otherwise.
= 1.
(cid:40)
(cid:35)
(cid:34)
Privacy. A DPF is private if each individual evaluation key
output by Gen is pseudorandom (i.e., reveals nothing about Œ±
to a computationally bounded adversary). Formally, this means
that there exists an efÔ¨Åcient simulator Sim that can generate
an indistinguishable view for each generated DPF key, without
knowledge of the input Œ± [20, 42].
Application: Private Information Retrieval. DPFs form the basis
for efÔ¨Åcient two-server private information retrieval [20, 21,
28, 29]. Consider a key-value table T with N keys, replicated
on two servers. Let each key in T be in the set {1, . . . , 2n}
and let the corresponding values be in the Ô¨Åeld Fp. To retrieve
the value under key Œ± in T the client generates DPF keys by
running Gen(1Œª, Œ±) and sends one key to each server. Each
server locally evaluates the DPF key with each item Œ±i for
i = 1, . . . , N to obtain the secret-share of PŒ±(Œ±i) on input Œ±i.
Each server then locally multiplies the resulting secret-share
by the associated value T (Œ±i), and outputs the sum of all N
component-wise products. That is, each server computes:
T (Œ±j)¬∑Eval(k, Œ±j)
= T (Œ±i)¬∑[1]+
T (Œ±j)¬∑[0]
.
N(cid:88)
(cid:16)
j=1,j(cid:54)=i
(cid:17)
N(cid:88)
(cid:16)
j=1
(cid:17)
Because PŒ±(Œ±i) = 1 only when Œ± = Œ±i, the resulting
sum (computed in the Ô¨Åeld Fp) is a secret-share of T (Œ±i).
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:00:59 UTC from IEEE Xplore.  Restrictions apply. 
6916
Summing the shares received from each server, the client
recovers the desired entry in T . Observe that DPFs achieve
symmetric PIR [41] (analogous to oblivious transfer [71]),
which guarantees that the answer consists of at most one value
in T . Additionally, modern DPF [20, 21] constructions achieve
key size of n(Œª+2) bits (logarithmic in the evaluation domain).
That is, privately querying a hash table with n-bit hash keys
requires only n(Œª+2) bits of communication and O(N n) work
on the server; where N is the number of non-empty buckets.
New tool: Oblivious Masking. The core of our leakage
suppression technique (described at a high level
in Sec-
tion IV-E) hinges on the ability to reveal only the Ô¨Årst non-zero
value in a secret-shared vector. Because the vector is secret-
shared (in some prime order Ô¨Åeld Fp where p (cid:29) N), this
transformation must only involve afÔ¨Åne operations: addition
and scalar multiplication of shares [16, 77]. The idea is to
recursively compute a randomized sum, moving from left
to right. For a secret-shared input vector [v] ‚àà FL
let
p ,
z ‚àà {1, . . . , L} be the index of the Ô¨Årst non-zero element in v.
The randomized sums map each element vi to 0 for i  z. Crucially, this
process does not affect the Ô¨Årst non-zero element, vz. We will
use this property to mask all-but-one result from a sequence
of PIR query answers.
Algorithm 1: ObliviousMasking
Input: Secret-shared vector [v] ‚àà FL
p and randomness rand.
Output: Secret-shared vector [y] = ([y1], . . . , [yL]) ‚àà FL
p .
Procedure:
1: for i ‚àà {1, . . . , L}:
1.1: Sample ri ‚Üê rand.
1.2: Set [yi] ‚Üê [vi] + ri ¬∑(cid:16)(cid:80)i‚àí1
j=0[vj]
(cid:17)
.
2: Output y ‚àà FL
p .
Claim 1. Let v ‚àà FL
p be any vector and let z ‚àà {1, . . . , L} be
the Ô¨Årst non-zero element of v. Let [v] be an additive secret-
sharing of v. Algorithm 1 outputs a secret-shared vector [y]
such that yi = vi for i ‚â§ z and a uniformly random element
of Fp for i > z.
Proof. The proof follows by examining the three possible cases
for each value in y as a function of v.
1) for i  z, yi = vi + ri
(cid:80)i‚àí1
j=0 0 = 0 ‚àà Fp,
(cid:80)i‚àí1
j=z+1 vj ‚àà
(cid:80)z‚àí1
(cid:80)z‚àí1
j=0 0 = vz ‚àà Fp,
j=0 0 + rivz + ri
Fp.
Case (1) ensures that all zeroes remain zeroes. Case (2) ensures
that the Ô¨Årst non-zero element is mapped to itself. Case (3)
ensures that all subsequent elements are uniformly random in
Fp. To see why (3) holds, observe that vz (cid:54)= 0, so ri ¬∑ vz is a
uniformly random element of Fp given ri is uniformly random.
It then follows that the sum is uniformly random in Fp. Finally,
correctness of the computation over secret-shares follows from
all operations performed above being linear (additions and
scalar multiplications) over the input secret-share of v [16]. (cid:4)
New tool: Partial Batch Retrieval. LSH multi-probing
requires retrieving multiple hash table buckets (called a batch)
through PIR. A na√Øve way to approach this problem is to
issue (cid:96) separate PIR queries‚Äîone per bucket‚Äîwhich incurs a
factor of (cid:96) processing overhead on the servers. Partial Batch
Retrieval (PBR) (inspired by probabilistic batch codes [7, 8])
makes it possible for the client to efÔ¨Åciently retrieve multiple
values without any increase in server-side processing time.
PBR is inspired by, but distinct from, batch codes [51]. With
PBR, only a fraction of requested values are returned, which
is Ô¨Åne for our probabilistic setting but may not be in others.
We compare PBR with batch codes (and their probabilistic
variants) in Section VI.
The main idea. A simple PBR scheme can be realized by
dividing the hash table keys into m ‚â• (cid:96) partitions at random.
If all (cid:96) multi-probes fall into a unique partition, then it sufÔ¨Åces
for the client to issue m PIR queries, with each query retrieving
one bucket from each partition. The total server processing
time to compute PIR answers remains the same. To see this,
observe that for a hash table of N hash keys, each partition only