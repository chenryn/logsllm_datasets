::: para
另外，需要维护的资源组越少，意味着性能更佳。
:::
::: para
当然，如果 GFS2
文件系统太小，则可能会造成空间溢出，也会造成一定影响。请在决定文件系统大小前考虑自身使用情况。
:::
:::
::: section
::: titlepage
## [⁠]{#ch-considerations.html#s2-blocksize-gfs2}2.1.2. 块大小：默认（4K）块是首选 {.title}
:::
::: para
从 Red Hat Enterprise Linux 6 开始，`mkfs.gfs2`{.command}
命令会尝试根据设备拓扑估算最佳块大小。通常，4K 块是首选块大小，因为 4K
是 Linux 的默认页大小（内存）。与其他文件系统不同，GFS2 使用 4K
内核缓存执行其大多数操作。如果您的块大小为
4K，则内核操作缓存的动作就少。
:::
::: para
建议您使用可形成最高性能的默认块大小。
:::
:::
::: section
::: titlepage
## [⁠]{#ch-considerations.html#s2-journalnumber-gfs2}2.1.3. 日志数：每个挂载的节点一个日志 {.title}
:::
::: para
GFS2
要求集群中每个需要挂载该文件系统的节点都有一个日志。例如：如果您有一个有
16 个节点的集群，但只需要在其中的 2
个节点中挂载该文件系统，那么您就只需要两个日志。如果您需要挂载第三个节点，您总是可以使用`gfs2_jadd`{.command}
命令添加日志。在 GFS2 中您可以随时添加日志。
:::
:::
::: section
::: titlepage
## [⁠]{#ch-considerations.html#s2-journalsize-gfs2}2.1.4. 日志大小：默认（128MB）通常是最佳选择 {.title}
:::
::: para
在运行 `mkfs.gfs2`{.command} 命令生成 GFS2
文件系统时要指定日志的大小。如果没有指定大小，则默认为
128MB，这对大多数应用程序都是最佳选择。
:::
::: para
有些系统管理员可能认为 128MB 太大，并尝试将该日志大小减小到
8MB，或者保守地保留为
32MB。虽然可能正常工作，但仍会严重影响性能。与许多日志文件系统一样，每次
GFS2
写入元数据时，都会在元数据到位前提交到日志中。这样是为保证如果系统崩溃或者断电，则可恢复所有元数据，因为挂载时会自动使用日志替换。但如果使用
8MB
的日志，则无法记录太多的文件系统活动，同时当日志写满后，性能就会下降，因为
GFS2 必须等待写入存储。
:::
::: para
一般推荐使用默认日志大小，即 128MB。如果文件系统太小（比如说
5GB），128MB 的日志就不太合适。如果文件系统较大，且有充分的空间，使用
256MB 日志可能会改进性能。
:::
:::
::: section
::: titlepage
## [⁠]{#ch-considerations.html#s2-rgsize-gfs2}2.1.5. 资源组大小和数量 {.title}
:::
::: para
使用 `mkfs.gfs2`{.command} 命令创建 GFS2
文件系统时，它将存储分成统一的片段，即资源组。它尝试估算最佳资源组大小（范围在32MB
到 2GB 之间）。您可以使用 `mkfs.gfs2`{.command} 命令的 `-r`{.command}
选项覆盖默认值。
:::
::: para
最佳资源组大小取决于如何使用该文件系统。请注意该文件会有多满，或者是否会被严重分割成碎片。
:::
::: para
请尝试不同大小的资源组查看最佳性能。最好是在产品中部署 GFS2
前在测试集群中进行试验。
:::
::: para
如果文件系统有太多资源组（每个都太小），则块分配会浪费太多时间搜索数以万计（或者十万计）的资源组才能找到空余的块。您的系统越满，则需要搜索的资源组越多，且它们都需要集群范围锁。这就会降低性能。
:::
::: para
如果您的文件系统只有很少几个资源组（每个都很大），块分配可能会更频繁地访问同一资源组锁，这样也会影响性能。例如：如果您有一个
10GB 文件系统，分成 5 个 2GB
的资源组，您集群中的节点会比将同一文件系统分成 320 个资源组，每个 32MB
更频繁地访问那 5
个资源组。尤其是在文件系统快满的时候更为严重，因为每个块分配可能都必须在找到可用块之前查看几个资源组。GFS2
尝试从两个方面解决这个问题：
:::
::: {.itemizedlist xmlns:d="http://docbook.org/ns/docbook"}
-   ::: para
    首先，当资源组全满时，它会记住并尝试避免在今后的分配中检查它（除非某个块是从该资源组中释放的）。如果从不删除文件，竞争会不那么严重。但如果应用程序不断在快满的文件系统中删除块并分配新块，竞争将会非常激烈，并严重影响性能。
    :::
-   ::: para
    其次，当在现有文件系统中添加新块时（例如：附加），GFS2
    会尝试将同一资源组中的新块放在一起作为文件。这样做可提高性能：在旋转的磁盘中，如果它们放在一起则所需时间较少。
    :::
:::
::: para
最糟糕的情况是在有中央目录时，则所有节点都在该目录中创建文件，因为所有节点将不断尝试锁定同一资源组。
:::
:::
:::
::: section
::: titlepage
# [⁠]{#ch-considerations.html#s1-filefragment-gfs2}2.2. 文件系统碎片 {.title}
:::
::: para
Red Hat Enterprise Linux 6.4 引进了 GFS2
中改进文件系统碎片管理的方法。在Red Hat Enterprise Linux 6.4
中，同时写入的结果是产生较少的文件碎片，并籍此获得更好的性能。
:::
::: para
虽然 Red Hat Enterprise Linux 中没有用于 GFS2
的碎片清除工具，您可以通过文件碎片工具识别它们，将其复制到临时文件中，并重新命名该临时文件以替换原始文件，这样就可以清除碎片。（只要写入是按顺序进行的，这个步骤还可以用于
Red Hat Enterprise Linux 6.4 以前的版本。）
:::
:::
::: section
::: titlepage
# [⁠]{#ch-considerations.html#s1-blockallocate-gfs2}2.3. 块分配问题 {.title}
:::
::: para
本小节提供与在 GFS2
文件系统中进行块分配相关的问题概述。尽管那些只写入数据的应用程序通常不在乎如何或者在哪里分配块，但稍微了解一些块分配的只是可帮助您优化性能。
:::
::: section
::: titlepage
## [⁠]{#ch-considerations.html#s2-fullfs-gfs2}2.3.1. 在文件系统中保留空余空间 {.title}
:::
::: para
当 GFS2
文件系统接近写满时，块分配程序就很难为新要分配的块找到剩余空间。结果是分配程序放弃的块就会尝试挤进资源组的末端，或者挤入更像文件碎片的小片中。这个文件碎片就可能造成性能问题。另外，当
GFS2 快满时，GFS2
块分配程序会花更多的时间搜索多个资源组，并增加锁定竞争，这在有足够剩余空间的文件系统中是不必要的。这也会造成性能问题。
:::
::: para
鉴于以上这些原因，我们建议您不要在 85%
已满的系统中运行文件系统，但这个限制值根据负载的不同而有所变化。
:::
:::
::: section
::: titlepage
## [⁠]{#ch-considerations.html#s2-nodeallocate-gfs2}2.3.2. 尽可能让每个节点分配其自身文件 {.title}
:::
::: para
由于分布式锁定管理器（DLM）的工作方式，如果所有文件都是由一个节点分配，而其他节点需要向那些文件中添加块，就会造成更多的锁定竞争。
:::
::: para
在 GFS（版本
1）中，所有锁定都是由中央锁定管理器进行管理，其任务是控制整个集群的锁定。这就造成统一锁定管理器（GULM）可能会出问题，因为这是一个单点失败。GFS2
的替换锁定方案 DLM
是在整个集群中分布锁定。如果集群中的任意节点失败，其锁定会由其他节点恢复。
:::
::: para
使用
DLM，第一个锁定资源（比如文件）的节点成为该节点的"主锁定"。其他节点可以锁定那个资源，但它们必须首先向主锁定要求授予权限。每个节点都知道哪个锁定是哪个节点的主锁定，且每个节点都知道它为哪个节点发放了锁定授权。锁定主节点中的锁比锁定其他节点中的锁要快得多，因为后者必须停止并请求主锁定的授权。
:::
::: para
因为在很多文件系统中，GFS2
分配程序会尝试将同一文件中块放在一起以减少磁头的移动，并极大提高性能。将块分配到文件的节点很可能需要为新的块使用并锁定同一资源组（除非那个资源组中所有的块都在使用中）。如果锁定包含将其数据分配到数据块的资源组，则系统将运行更迅速（即如果您让首先打开该文件的节点执行所有新块写入操作，则系统运行会更迅速）。
:::
:::
::: section
::: titlepage
## [⁠]{#ch-considerations.html#s2-preallocate-gfs2}2.3.3. 尽可能预先分配 {.title}
:::
::: para
如果预先分配文件，就可以同时避免块分配，文件系统的运行也更有效。GFS2
较新的版本包含 `fallocate`{.command}(1)
系统调用，您可以使用这个命令预先分配数据块。
:::
:::
:::
::: section
::: titlepage
# [⁠]{#ch-considerations.html#s1-deploy-gfs2}2.4. 集群注意事项 {.title}
:::
::: para
决定您系统中包含的节点数时，请注意在高可用性和性能之间要有所取舍。如果有大量的节点，则很难形成大规模负载。因此，Red
Hat 不支持在超过 16 个节点的集群文件系统部署中使用 GFS2。
:::
::: para
Deploying a cluster file system is not a \"drop in\" replacement for a
single node deployment. We recommend that you allow a period of around
8-12 weeks of testing on new installations in order to test the system
and ensure that it is working at the required performance level. During
this period any performance or functional issues can be worked out and
any queries should be directed to the Red Hat support team.
:::
::: para
我们建议考虑部署集群的客户在部署前请Red Hat
支持团队审核其配置，这样可以避免之后可能存在的支持问题。
:::
:::
::: section
::: titlepage
# [⁠]{#ch-considerations.html#s1-usage-gfs2}2.5. 用法注意事项 {.title}
:::
::: para
本小节提供关于 GFS2 常规推荐用法。
:::
::: section
::: titlepage
## [⁠]{#ch-considerations.html#s2-recommendedmount-gfs2}2.5.1. 挂载选项：noatime 和 nodiratime {.title}
:::
::: para
通常建议使用 `noatime`{.option} 和 `nodiratime`{.option} 挂载 GFS2
文件系统。这让 GFS2 每次访问时花较少的时间更新磁盘节点。
:::
:::
::: section
::: titlepage
## [⁠]{#ch-considerations.html#s2-DLMtablesize-gfs2}2.5.2. DLM 调试选项：增加 DLM 表格大小 {.title}
:::
::: para
DLM 设备几个标签在集群的节点间管理、协调以及传递锁定信息。增大 DLM
标签的容量应该可以提高性能。在 Red Hat Enterprise Linux 6.1
以及之后的版本中，已增大这些标签的默认容量，但您可以使用以下命令手动增加这些标签的容量：
:::
``` screen
echo 1024 > /sys/kernel/config/dlm/cluster/lkbtbl_size
echo 1024 > /sys/kernel/config/dlm/cluster/rsbtbl_size
echo 1024 > /sys/kernel/config/dlm/cluster/dirtbl_size
```
::: para
这些命令将在重启后失效，因此您必须将其添加到一个启动脚本中，并在挂载任意
GFS2 文件系统前执行这些脚本，否则这些更改将被忽略，且没有任何提示。
:::
::: para
有关 GFS2 节点锁定的详情请参考 [第 2.9 节 "GFS2
节点锁定"](#ch-considerations.html#s1-ov-lockbounce){.xref}。
:::
:::
::: section
::: titlepage
## [⁠]{#ch-considerations.html#s2-vfstuning-gfs2}2.5.3. VFS 调试选项：搜索和测试 {.title}
:::
::: para
与其他所有 Linux 系统类似，GFS2
位于顶层的虚拟文件系统（VFS）中。您可以调节 VFS 层以改进底层 GFS2
性能，方法是使用 `sysctl`{.command}(8) 命令。例如：可根据情况调整
`dirty_background_ratio`{.literal} 和 `vfs_cache_pressure`{.literal}
值。要使用当前值，则需要使用以下命令：
:::
``` screen
sysctl -n vm.dirty_background_ratio
sysctl -n vm.vfs_cache_pressure
```
::: para
以下命令可调整这些数值：
:::
``` screen
sysctl -w vm.dirty_background_ratio=20
sysctl -w vm.vfs_cache_pressure=500
```
::: para
您可以永久性更改这些参数值，方法是编辑 `/etc/sysctl.conf`{.filename}
文件。
:::
::: para
要找到您使用案例的最佳值，您需要搜索各种 VFS
选项，并在部署到产品中以前，在测试集群节点中进行测试。
:::
:::
::: section
::: titlepage
## [⁠]{#ch-considerations.html#s2-selinux-gfs2-gfs2}2.5.4. SELinux：不要在 GFS2 中使用 SELinux {.title}
:::