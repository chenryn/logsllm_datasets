363,540
375,348
BCC
Cash
29.9% 127.1%
30.1% 124.2%
28.6% 135.9%
29.8% 125.6%
29.9% 145.2%
30.4% 146.5%
Table 2. The binary code size comparison among
GCC, BCC, and Cash for the test suite. GCC num-
bersareinbytesandnumbersfor Cash andBCCare
intermsofpercentageincreaseswithrespecttoGCC.
Programsarecompiledwithstaticlinking.
There are two reasons why the binary size of a pro-
gram with bound checking is larger than one without bound
checking. First, the bound checking instructions take addi-
tional space. Second, pointer representation require mul-
tiple words. BCC incurs both overheads, whereas Cash
only needs to bear the second cost. Table 2 shows that the
code size overhead of the applications compiled by the Cash
compiler is within 31% of that of GCC, whereas BCC’s
code is more than 120%.
4.3 Network Applications
Because one of the applications of bound checking is to
stop remote attacks that that exploit buffer overﬂow vulner-
ability, we apply Cash to a set of popular network applica-
tions that are known to have such a vulnerability. The list of
applications and their characteristics are shown in Table 3.
At the time of writing this paper, BCC still cannot correctly
compile these network applications. because of a BCC
bug [4] in the nss (name-service switch) library, which is
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Lines of Array-Using
Program
Name
Qpopper-4.0
Apache-1.3.20
Sendmail-8.11.3
Wu-ftpd-2.6.1
Pure-ftpd-1.0.16b
Bind-8.3.4
Code
32104
51974
73612
28055
22693
46844
Loops
67
355
217
138
45
734
> 3
Arrays
1 (0.9%)
12 (0.5%)
24 (1.4%)
1 (0.4%)
1 (0.5%)
22 (0.6%)
Table 3. Characteristicsofa set ofpopularnetwork
applications that are known to have buffer overﬂow
vulnerability.Thesourcecodelinecountincludesall
thelibrariesusedintheprograms,excludinglibc.
needed by all network applications. Because of this bug, the
bounds-checking code BCC generates will cause spurious
bounds violations in nss parse service list, which
is used internally by the GNU C library’s name-service
switch. Therefore, for network applications, we only com-
pare the results from Cash and GCC.
Name
Program Latency
Penalty
6.5%
3.3%
9.8%
2.5%
3.3%
4.4%
Qpopper
Apache
Sendmail
Wu-ftpd
Pure-ftpd
Bind
Throughput
Penalty
6.1%
3.2%
8.9%
2.4%
3.2%
4.3%
Space
Overhead
60.1%
56.3%
44.8%
68.3%
63.4%
53.6%
Table 4. The latency/throughput penalty and space
overheadofeachnetworkapplicationcompiledunder
Cash when compared withthe baselinecase without
boundchecking.
To evaluate the performance of network applications, we
used two client machines (one 300-MHz Pentium-2 with
128MB memory and the other 1.5-GHz Pentium-4 with 256
MB memory), that continuously send 2000 requests to a
server machine (1.1-GHZ Pentium-3 with 512 MB mem-
ory) over a 100Mbps Ethernet link. The server machine’s
kernel was modiﬁed to record the creation and termination
time of each forked process. The throughput of a network
application running on the server machine is calculated by
dividing 2000 with the time interval between creation of the
ﬁrst forked process and termination of the last forked pro-
cess. The latency is calculated by taking the average of the
CPU time used by the 2000 forked processes. The Apache
web server program is handled separately in this study. We
conﬁgured Apache to handle each incoming request with a
single child process so that we could accurately measure the
latency of each Web request.
We measured the latency of the most common opera-
tion for each of these network applications when the bound
checking mechanism in Cash is turned on and turned off.
The operation measured is sending a mail for Sendmail, re-
trieving a web page for Apache, getting a ﬁle for Wu-ftpd,
answering a DNS query for Bind, and retrieving mails for
Qpopper. For network applications that can potentially in-
volve disk access, such as Apache, we warmed up the ap-
plications with a few runs before taking the 10 measure-
ments used in computing the average. The latency penalty
for these applications ranges from 2.5% (Wu-ftpd) to 9.8%
(Sendmail), and the throughput penalty ranges from 2.4%
(Wu-ftpd) to 8.9% (Sendmail), as shown in Table 4.
In
general, these numbers are consistent with the results from
micro-benchmarking, and demonstrate that Cash is indeed
a highly efﬁcient bound checking mechanism that is appli-
cable to a wide variety of applications. The space overhead
results in Table 4 are higher than those in Table 2.
A major concern early in the Cash project is that the
number of segment registers (currently 3) is so small as
to cause frequent fall-back to software bound check. Be-
cause Cash only checks array references within loops, a
small number of segment registers is a problem only when
the body of a loop uses more than 3 arrays/buffers. That
is, the limit on the number of simultaneous array uses is
per loop, not per function, or even per program. To iso-
late the performance cost associated with this problem, we
measure the number of loops that involve array references,
and the number of loops that involve more than 3 distinct
arrays (called spilled loops) during the execution of these
network applications, and the results are shown in Table 3.
The percentage numbers within the parenthesis provide the
percentage of loop iterations that are executed in the exper-
iments and that belong to spilled loops. The percentage of
static loops in each application that use more than 3 arrays
is below 3.5% for all applications except Sendmail, which
is at 11%. Unsurprisingly, Sendmail also carries the highest
latency and throughput penalty.
4.4 Other Performance Factors
Another potential
issue is the number of segments
needed in an entire application, because the total number
of segments available is 8191. Our results show that the
total number of segments used is within 10 segments for
the micro-benchmark applications, 163 segments for the
macro-benchmark, and 292 for the network applications.
Therefore, the budget, 8191, seems more than sufﬁcient
for many applications. Another hidden performance cost is
increased pointer variable copying overhead due to multi-
word pointer representation. However, for most numeri-
cal programs that require array bound checking, pointer as-
signments are never sufﬁciently frequent to cause noticeable
performance problems.
One major concern is the overhead associated with LDT
modiﬁcation. Among all 18 tested applications, Toast
makes the most requests (415,659 calls) to allocate seg-
ments.
223,781 of them (or 53.8% hit ratio) can ﬁnd
a matched segment in the 3-entry cache and 191,878 re-
quests actually need to go into the kernel through the
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
cash modify ldt call gate to modify the LDT. Each
call gate invocation takes 253 cycles, which means that it
takes 50,464K cycles for the 191,878 calls, and this is rela-
tively insigniﬁcant as compared with Toast’s total run time
(4,727,612K cycles). Therefore, the overhead of the Toast
application compiled under Cash is still very small (4.6%)
though it makes so many segment allocation requests.
5 Conclusion
Although array bound checking is an old problem, it has
seen revived interest recently out of concerns on security
breaches exploiting array bound violation. Despite its ro-
bustness advantage, most real-world programs do not incor-
porate array bound checking, and the main hurdle is its per-
formance cost. Whereas almost all previous research in this
area focused on static analysis techniques to reduce redun-
dant bound checks and thus minimize the checking over-
head, this work took a completely different approach that re-
lies on hardware features available in the X86 architecture,
which accounts for more than 90% of the worldwide PC
market. The main idea of our approach is to organize array
reference instructions in such a way that the segment limit
check mechanism in the X86 architecture’s virtual mem-
ory hardware effectively performs array bound check. As a
result, the proposed approach, called Cash, does not incur
any per-array-reference overhead most of the time, because
bound checking is done by the segmentation hardware for
free. However, there are per-program overhead, per-array
overhead, and per-array-use overhead associated with the
Cash approach. We have successfully built a Cash pro-
totype based on the bound-checking GCC compiler under
Red Hat Linux 7.2. The current Cash prototype can check
bounds for array pointers as well as general pointers. The
empirical performance measurements from running a set of
numerical kernels that use array references extensively on
the Cash prototype demonstrate that the Cash approach can
reduce the array bound checking overhead of a set of pop-
ular network applications to under 9.8% compared with the
baseline case that does not perform any bound checking.
Although the Cash approach reduces the array bound
checking overhead to an unprecedentedly low level, it relies
on a speciﬁc hardware feature of the X86 architecture, and
thus is not as portable as other software-only approaches.
We recognize this limitation. However, we believe that the
X86 architecture has a long life time ahead, especially in
view of the recent announcement that Intel is planning to
develop a 64-bit version of its X86 architecture that will
evolve in parallel with its Itanium line.
Acknowledgment
This research is supported by NSF awards SCI-0401777,
CNS-0410694 and CNS-0435373 and Rether Networks Inc.
References
[1] Bruce Perens. Electric fence: a malloc() debugger for linux and unix.
http://perens.com/FreeSoftware/.
[2] Chris Bentley, Scott A. Watterson, and David K. Lowenthal. A com-
parison of array bounds checking on superscalar and vliw architec-
tures. submitted to the annual IEEE Workshop on Workload Charac-
terization, September 2002.
[3] Crispan Cowan, et al. Stackguard: Automatic adaptive detection and
prevention of buffer-overﬂow attacks. In Proc. 7th USENIX Security
Conference, pages 63–78, San Antonio, Texas, Jan 1998.
[4] GCC. Bounds-checkinggcc. http://www.gnu.org/software/gcc/projects
/bp/main.html.
[5] Glenn Pearson. Array bounds checking with turbo c. Dr. Dobb’s
Journal of Software Tools, 16(5):72, 74, 78–79, 81–82, 104–107,
May 1991.
[6] Harish Patil and Charles N. Fischer. Efﬁcient run-time monitoring
using shadow processing. In Proceedings of Automated and Algo-
rithmic Debugging Workshop, pages 119–132, 1995.
[7] Hongwei Xi and Frank Pfenning. Eliminating array bound checking
through dependent types. SIGPLAN Conference on Programming
Language Design and Implementation, pages 249–257, 1998.
[8] Hongwei Xi and Songtao Xia. Towards array bound check elimina-
tion in java virtual machine language. In Proceedings of CASCON
’99, pages 110–125, Mississauga, Ontario, November 1999.
[9] Intel.
IA-32
Intel Architecture
oper’s Manual Volume
Instruction
http://www.intel.com/design/Pentium4/manuals/.
2:
Software Devel-
Set Reference.
[10] Intel.
Ia-32
volume
intel
3:
manual.
http://developer.intel.com/design/pentium4/manuals/245472.htm.
System
architecture
software
programming
developer’s
guide.
[11] J. M. Asuru. Optimization of array subscript range checks. ACM
letters on Programming Languages and Systems, 1(2):109–118,June
1992.
[12] R. W. M. Jones and P. H. J. Kelly. Backwards-compatible bounds
checking for arrays and pointers in c programs. In Proceedings of Au-
tomated and Algorithmic Debugging Workshop, pages 13–26, 1997.
[13] P. Kolte and M. Wolfe. Elimination of redundant array subscript
range checks. SIGPLAN Conference on Programming Language De-
sign and Implementation, pages 270–278, 1995.
[14] Manish Prasad and Tzi-cker Chiueh. A binary rewriting approach
In in Proceedings of 2003
to stack-based buffer overﬂow attacks.
USENIX Conference, June 2003.
[15] Rajiv Gupta. A fresh look at optimizing array bound checking. SIG-
PLAN Conference on Programming Language Design and Imple-
mentation, pages 272–282, 1990.
[16] Rajiv Gupta. Optimizing array bound checks using ﬂow analysis.
ACM Letters on Programming Languages and Systems, 2(1-4):135–
150, March-December 1993.
[17] Rastislav Bodik and Rajiv Gupta and Vivek Sarkar. Abcd: eliminat-
ing array bounds checks on demand. SIGPLAN Conference on Pro-
gramming Language Design and Implementation, pages 321–333,
2000.
[18] Tzi-cker Chiueh and Fu-Hau Hsu. Rad: A compiler time solution to
buffer overﬂow attacks. In in Proceedings of International Confer-
ence on Distributed Computing Systems (ICDCS), Phoenix, Arizona,
April 2001.
[19] Tzi-cker Chiueh and Ganesh Venkitachalam and Prashant Pradhan.
Integrating segmentation and paging protection for safe, efﬁcient and
transparent software extensions. In in Proceedings of 17th ACM Sym-
posium on Operating Systems Principles, Charleston, SC, December
1999.
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE