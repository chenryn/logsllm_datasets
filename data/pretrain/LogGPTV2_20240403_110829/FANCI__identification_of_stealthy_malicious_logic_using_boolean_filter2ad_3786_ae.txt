mentary.
• FANCI does not remove the need for standard code inspection/re-
view practices. Consider as an example an attack where a malicious
designer includes hundreds of backdoor-like circuits. Each of these
circuits could turn on given a variety of rare triggers, with only one
of them having a useful malicious payload. Thus, FANCI would
ﬂag all of them, mostly generating false positives. We would call
this type of attack False Positive Flooding. However, in addition to
3We leave out the full proof as it is out of scope for this venue.
705the area bloat this would cause, it would be obvious in basic code
inspection that this was not a reasonable design. FANCI speciﬁ-
cally targets small, well-hidden backdoors, which are the type that
are able to evade testing and code inspection.
• Functional analysis only applies to designs or discrete representa-
tions of designs. Functional analysis alone does not protect against
backdoors inserted physically into a device by a malicious foundry,
unless a functional representation can be reverse engineered from
the device via decapping, which is not easy. We would call these
types of attacks Physical or Parametric Backdoors. Functional
analysis is one piece of hardware security and must exist as part of
the larger security scope, which includes validation, code inspec-
tion and foundry-level techniques in addition to runtime methods
Our approach also works well against sequential backdoors but
with limitations. Sequential backdoors are trigged not by one com-
binational input but by a stream of small inputs over time. In other
words, they are triggered by the combination of an input and a
speciﬁc internal state. Hypothetically, a sequential backdoor that
makes use of an extremely large and contrivedly deep state ma-
chine might be able to evade detection or at least made detection
more difﬁcult. We would call an attack of this type a Pathological
Pipeline Backdoor. The idea is that by stretching out the back-
door trigger computation over a long stretch of logic, it makes the
control value data more noisy and potentially more difﬁcult to in-
terpret. For example, if an input needs to determine an ultimate
output with 1
232 probability, this can be done with two sequential
components, each with a probability of 1
216 of turning on. The con-
trol value from beginning to end will still be 1
232 , but there will be
many intermediate control values, and the overall metrics might not
be as clean.
This scenario is one of the many cases where we ﬁnd that FANCI
is complementary to standard validation practices. While basic
tests would be likely to catch an extremely large backdoor, FANCI
is more likely to catch small, well-hidden backdoors. As we can see
in Table 3, practical backdoors tend to have relatively small critical
path lengths, and none of the backdoors we have encountered have
used deep pipelining. In the table, we use path length (in number of
gates) as a proxy for the depth and size of a backdoor trigger com-
putation. These results could be interpreted as merely commentary
on the speciﬁc types of backdoors that benchmark designers choose
to build, or they could be interpreted as broadly representative of
the way attackers build malicious circuits. Without a wider array
of benchmarks, we cannot say for certain. However, it appears that
the crucial part of a backdoor – even a relatively complex backdoor
– tends to be composed of only a few gates, and this is good for
security engineers.
Table 3: Average Length of Backdoor Critical Paths in
TrustHub Benchmarks
TrustHub Benchmark Group Average Backdoor Path Length
RS232
s15850
s35932
s38417
4.9
5.0
4.4
4.0
6. RELATED WORK
Hardware design backdoor detection, identiﬁcation, categoriza-
tion and protection are areas that have recently grown in interest.
Hardware designs have been demonstrated to be highly vulnera-
ble [1, 4]. Reese et al. evaluated how lightweight and stealthy
one can make practical backdoors [12]. In recent years, there has
been work both in design-time and in-the-ﬁeld or runtime protec-
tion schemes.
Hicks et al. proposed a runtime method for averting backdoors [5].
This method has been shown to detect backdoors, thus raising the
bar for the cleverness of hardware attacks. However, it is also vul-
nerable to sophisticated attacks, as demonstrated by Sturton et
al. [9] and discussed in Section 4. The three key differences be-
tween our work and theirs: 1) our detection technique is exclu-
sively design-time, 2) we do not rely on a validation suite to iden-
tify suspicious circuits, and 3) we provide a continuous measure of
suspiciousness as opposed to a binary metric used by Hicks et al.
Also in the area of runtime techniques, Waksman and Sethumad-
havan designed TrustNet [6], a methodology for integrating prop-
erty checkers into hardware designs that can ensure that a wide ar-
ray of properties are upheld at runtime. Waksman and Sethumadha-
van also developed a technique for disabling digital hardware back-
doors at runtime, which identiﬁes possible trigger sources and pre-
vents backdoor triggers from reaching malicious logic [7, 8]. Their
work identiﬁes the notion of a trigger as a rare signal that does not
ﬁre during validation testing. Our work with FANCI is comple-
mentary to that prior work, in part because it lessens the burden of
trust on validation teams.
There has also been prior work in related areas of hardware supply-
chain security, including the detection of physical backdoors added
during fabrication [13, 14, 15, 16] and detecting actively running
backdoors [17, 18]. This work generally assumes a trusted design,
called a golden model, which we and others endeavor to make more
of a reality.
The concept of inﬂuence of input variables over truth tables and
boolean functions has been approached from a theoretical perspec-
tive at least as far back as 1988 [19]. As far as we know, we are
the ﬁrst to apply these concepts to hardware security. Our work
does not rely on formal veriﬁcation or require manual inspection or
understanding of the inner-workings of designs.
7. CONCLUSIONS
The ability to identify and understand hardware backdoors at de-
sign time using static analysis mitigates the dangers of integrat-
ing third-party intellectual property components into hardware. We
presented a concept called control value, which describes how wires
within a design affect other wires. Using the idea of control value,
we developed a methodology for identifying suspicious wires that
have the capability to carry backdoor trigger signals. Speciﬁcally,
we look at the inﬂuence wires have over intermediate outputs within
a circuit and identify those wires that have an abnormally low de-
gree of inﬂuence. Our method is scalable and approximate; to
achieve our goals, we build truth tables of intermediate outputs in
the circuit of interest and compute the control value by randomly
sampling rows in the truth table. Using a tool we developed, called
FANCI, we examined 18 TrustHub benchmarks. We were able to
identify triggers in each of these benchmarks, obtaining low false
positives rates (ﬂagging less than 10 wires per design on average)
in the process.
FANCI is the ﬁrst tool for checking the security of third-party
soft IP and regular hardware designs prior to fabrication. Similar
to software static analysis tools, we envision FANCI being used as
706Figure 7: Histograms of the triviality values from three of the modules in the FabScalar core design we used. The y-axis shows the
number of wires in each category, and the x-axis shows a logarithmic scale of the triviality values for the wires. Triviality scales from
one to zero (going left to right), so the logarithmic values scale from zero to negative inﬁnity.
a ﬁrst line of defense for enhancing hardware security. It is com-
plementary to runtime techniques for protecting against hardware
attacks and also to standard testing practices. Additionally, it has
fewer trust requirements as compared with previously existing run-
time detection/protection techniques. While our tool is not theoret-
ically guaranteed to ﬁnd all backdoors, it is likely that backdoors
that evade FANCI have to break the digital abstraction or have to
be non-stealthy and thus detectable through normal means. Our
experimental results support the claim that this methodology could
be applied to real-world designs today. As designs get more com-
plex and time to market shrinks, tools like FANCI that can target
backdoors prior to fabrication are critical to the development of
trustworthy systems.
ACKNOWLEDGEMENTS
We thank anonymous reviewers and members of the Computer Ar-
chitecture and Security Technologies Lab (CASTL) at Columbia
University for their feedback on this work. This work was sup-
ported by grants FA 99500910389 (AFOSR), FA 865011C7190
(DARPA), FA 87501020253 (DARPA), CCF/TC 1054844 (NSF)
and gifts from Microsoft Research, WindRiver Corp, Xilinx and
Synopsys Inc. This work is also supported through an Alfred P.
Sloan Foundation Fellowship and the Department of Defense ND-
SEG Fellowship. Opinions, ﬁndings, conclusions and recommen-
dations expressed in this material are those of the authors and do
not necessarily reﬂect the views of the US Government or commer-
cial entities.
APPENDIX
In Figure 7, we include some example histograms of the triviality
values we found for wires in six of the modules from FabScalar, the
benign microprocessor core that we tested with FANCI. In a normal
design, most of the wires have values that are not extremely small,
with values between 1
2 being very common. To make the
results easier to read, we have combined the values between zero
and 1
2 and one. For example, 0.1 and
0.9 are plotted together, as are 0.7 and 0.3. Semantically, we care
about the distance from 1
2 , so this is the easiest way to understand
the data.
2 with the values between 1
8 and 1
To take the example of the DecodePISA module, which experi-
enced slightly lower triviality values than the other example mod-
ules, it turns out that most of the lower values belong to higher or-
der bits of a 128-bit output packet called DecodedPacket0. Without
knowing the intention of the original designer, it seems likely that
these upper order bits are not always being used efﬁciently. How-
ever, the control values are not so low as to merit real suspicion.
In addition to serving as a security method, these types of observa-
tions may also be useful for regular debugging and optimization by
trusted designers.
As we can see in the histograms, the vast majority of wires are
bunched up on the left side, having relatively normal values (closer
to 1
2 then to the extremes of zero or one). In FabScalar, we rarely
see wires with values even less than 2−10, which is still a rela-
tively benign value (corresponding to roughly a one in one thousand
chance of a certain behavior occurring). We can also see that while
the values are mostly close to 2−1 = 1
2 , the actual distributions
vary from module to module. This is to be expected, as module
designs are complex, and it is rare for two different modules to be
exactly the same.
707References
References
[1] Sally Adee. The Hunt for the Kill Switch. IEEE Spectrum
Magazine, 45(5):34–39, 2008.
[2] Marianne Swanson, Nadya Bartol, and Rama Moorthy.
Piloting Supply Chain Risk Management Practices for
Federal Information Systems. In National Institute of
Standards and Technology, page 1, 2010.
[3] United Stated Department of Defense. High Performance
Microchip Supply, February 2005.
[4] Samuel T. King, Joseph Tucek, Anthony Cozzie, Chris Grier,
Weihang Jiang, and Yuanyuan Zhou. Designing and
Implementing Malicious Hardware. In Proceedings of the
1st Usenix Workshop on Large-Scale Exploits and Emergent
Threats, pages 5:1–5:8, Berkeley, CA, USA, 2008. USENIX
Association.
[5] Matthew Hicks, Samuel T. King, Milo M. K. Martin, and
Jonathan M. Smith. Overcoming an Untrusted Computing
Base: Detecting and Removing Malicious Hardware
Automatically. In Proceedings of the 31st IEEE Symposium
on Security and Privacy, pages 159–172, 2010.
[6] Adam Waksman and Simha Sethumadhavan. Tamper
Evident Microprocessors. In Proceedings of the 31st IEEE
Symposium on Security and Privacy, pages 173–188,
Oakland, California, 2010.
[7] Adam Waksman and Simha Sethumadhavan. Silencing
Hardware Backdoors. In Proceedings of the 2011 IEEE
Symposium on Security and Privacy, pages 49–63, Oakland,
California, 2011.
[8] Adam Waksman, Julianna Eum, and Simha Sethumadhavan.
Practical, Lightweight Secure Inclusion of Third-Party
Intellectual Property. In Design and Test, IEEE, pages 8–16,
2013.
[12] Trey Reece, Daniel Limbrick, Xiaowen Wang, Bradley
Kiddie, and William Robinson. Stealth Assessment of
Hardware Trojans in a Microcontroller. In Proceedings of
the 2012 International Conference on Computer Design,
pages 139–142, 2012.
[13] Sheng Wei, Kai Li, Farinaz Koushanfar, and Miodrag
Potkonjak. Provably Complete Hardware Trojan Detection
Using Test Point Insertion. In Proceedings of the
International Conference on Computer-Aided Design,
ICCAD ’12, pages 569–576, New York, NY, USA, 2012.
ACM.
[14] Dakshi Agrawal, Selçuk Baktir, Deniz Karakoyunlu, Pankaj
Rohatgi, and Berk Sunar. Trojan Detection using IC
Fingerprinting. In IEEE Symposium on Security and Privacy,
pages 296–310, 2007.
[15] Mainak Banga, Maheshwar Chandrasekar, Lei Fang, and
Michael S. Hsiao. Guided Test Generation for Isolation and
Detection of Embedded Trojans in ICS. In GLSVLSI ’08:
Proceedings of the 18th ACM Great Lakes symposium on
VLSI, pages 363–366, New York, NY, USA, 2008. ACM.
[16] Jie Li and J. Lach. At-Speed Delay Characterization for IC
Authentication and Trojan Horse Detection. In
Hardware-Oriented Security and Trust, 2008. HOST 2008.
IEEE International Workshop on, pages 8–14, June 2008.
[17] Mainak Banga and Michael S. Hsiao. A Region Based
Approach for the Identiﬁcation of Hardware Trojans. In
Hardware-Oriented Security and Trust, 2008. HOST 2008.
IEEE International Workshop on, pages 40–47, June 2008.
[18] Hassan Salmani, Mohammad Tehranipoor, and Jim
Plusquellic. New Design Strategy for Improving Hardware
Trojan Detection and Reducing Trojan Activation Time. In
Hardware-Oriented Security and Trust, 2009. HOST ’09.
IEEE International Workshop on, pages 66 –73, 2009.
[9] Cynthia Sturton, Matthew Hicks, David Wagner, and
[19] Jeff Kahn, Gil Kalai, and Nathan Linial. The Inﬂuence of
Variables on Boolean Functions (Extended Abstract). pages
68–80, 1988.
Samuel T. King. Defeating UCI: Building Stealthy and
Malicious Hardware. In Proceedings of the 2011 IEEE
Symposium on Security and Privacy, SP ’11, pages 64–77,
Washington, DC, USA, 2011. IEEE Computer Society.
[10] Mohammad Tehranipoor, Ramesh Karri, Farinaz Koushanfar,
and Miodrag Potkonjak. TrustHub. http://trust-hub.org.
[11] Niket K. Choudhary, Salil V. Wadhavkar, Tanmay A. Shah,
Hiran Mayukh, Jayneel Gandhi, Brandon H. Dwiel, Sandeep
Navada, Hashem H. Najaf-abadi, and Eric Rotenberg.
Fabscalar: Composing Synthesizable RTL Designs of
Arbitrary Cores within a Canonical Superscalar Template. In
Computer Architecture (ISCA), 2011 38th Annual
International Symposium on, pages 11–22. IEEE, 2011.
708