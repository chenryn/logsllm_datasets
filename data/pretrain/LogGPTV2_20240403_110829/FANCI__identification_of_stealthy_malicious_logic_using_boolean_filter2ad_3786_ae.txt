### FANCI and Standard Code Inspection Practices

FANCI does not replace the need for standard code inspection and review practices. Consider an attack where a malicious designer embeds hundreds of backdoor-like circuits, each activated by a variety of rare triggers, with only one circuit containing a useful malicious payload. In such a scenario, FANCI would flag all these circuits, generating a high number of false positives. This type of attack can be referred to as "False Positive Flooding." However, in addition to the area bloat this would cause, it would be evident through basic code inspection that this design is not reasonable. FANCI specifically targets small, well-hidden backdoors, which are the types that typically evade testing and code inspection.

### Functional Analysis and Physical Backdoors

Functional analysis is applicable to designs or discrete representations of designs. It does not protect against backdoors inserted physically into a device by a malicious foundry, unless a functional representation can be reverse-engineered from the device via decapping, which is a complex process. We refer to these types of attacks as "Physical or Parametric Backdoors." Functional analysis is just one aspect of hardware security and should be part of a broader security framework that includes validation, code inspection, and foundry-level techniques, in addition to runtime methods.

### Sequential Backdoors

Our approach also works effectively against sequential backdoors, though with some limitations. Sequential backdoors are triggered not by a single combinational input but by a sequence of small inputs over time. In other words, they are activated by the combination of an input and a specific internal state. Hypothetically, a sequential backdoor that uses an extremely large and contrivedly deep state machine might evade detection or at least make detection more challenging. We call this type of attack a "Pathological Pipeline Backdoor." The idea is that by stretching out the backdoor trigger computation over a long stretch of logic, it makes the control value data noisier and potentially more difficult to interpret. For example, if an input needs to determine an ultimate output with a probability of \(2^{-32}\), this can be achieved with two sequential components, each with a probability of \(2^{-16}\) of turning on. The overall control value remains \(2^{-32}\), but there will be many intermediate control values, making the metrics less clean.

### Complementary to Standard Validation Practices

This scenario highlights how FANCI complements standard validation practices. While basic tests are likely to catch extremely large backdoors, FANCI is more effective at identifying small, well-hidden backdoors. As shown in Table 3, practical backdoors tend to have relatively short critical path lengths, and none of the backdoors we have encountered have used deep pipelining. In the table, we use path length (in number of gates) as a proxy for the depth and size of a backdoor trigger computation. These results could reflect the specific types of backdoors chosen by benchmark designers or may be broadly representative of how attackers build malicious circuits. Without a wider array of benchmarks, we cannot be certain. However, it appears that the crucial part of a backdoor, even a relatively complex one, tends to be composed of only a few gates, which is beneficial for security engineers.

**Table 3: Average Length of Backdoor Critical Paths in TrustHub Benchmarks**

| TrustHub Benchmark Group | Average Backdoor Path Length |
|--------------------------|-------------------------------|
| RS232                    | 4.9                           |
| s15850                   | 5.0                           |
| s35932                   | 4.4                           |
| s38417                   | 4.0                           |

### Related Work

Hardware design backdoor detection, identification, categorization, and protection have recently gained significant interest. Hardware designs have been shown to be highly vulnerable [1, 4]. Reese et al. evaluated how lightweight and stealthy practical backdoors can be [12]. Recent years have seen advancements in both design-time and in-the-field or runtime protection schemes.

Hicks et al. proposed a runtime method for detecting and averting backdoors [5]. This method has been shown to detect backdoors, raising the bar for the sophistication of hardware attacks. However, it is also vulnerable to sophisticated attacks, as demonstrated by Sturton et al. [9] and discussed in Section 4. The key differences between our work and theirs are: 1) our detection technique is exclusively design-time, 2) we do not rely on a validation suite to identify suspicious circuits, and 3) we provide a continuous measure of suspiciousness rather than a binary metric used by Hicks et al.

In the area of runtime techniques, Waksman and Sethumadhavan designed TrustNet [6], a methodology for integrating property checkers into hardware designs to ensure a wide array of properties are upheld at runtime. They also developed a technique for disabling digital hardware backdoors at runtime by identifying possible trigger sources and preventing backdoor triggers from reaching malicious logic [7, 8]. Their work identifies the notion of a trigger as a rare signal that does not fire during validation testing. Our work with FANCI complements their prior work, as it reduces the burden of trust on validation teams.

There has also been prior work in related areas of hardware supply-chain security, including the detection of physical backdoors added during fabrication [13, 14, 15, 16] and detecting actively running backdoors [17, 18]. This work generally assumes a trusted design, called a golden model, which we and others aim to make more of a reality.

The concept of the influence of input variables over truth tables and Boolean functions has been explored theoretically since at least 1988 [19]. To the best of our knowledge, we are the first to apply these concepts to hardware security. Our work does not rely on formal verification or require manual inspection or understanding of the inner workings of designs.

### Conclusions

The ability to identify and understand hardware backdoors at design time using static analysis mitigates the risks of integrating third-party intellectual property components into hardware. We introduced the concept of control value, which describes how wires within a design affect other wires. Using control value, we developed a methodology for identifying suspicious wires capable of carrying backdoor trigger signals. Specifically, we examine the influence of wires on intermediate outputs within a circuit and identify those with abnormally low degrees of influence. Our method is scalable and approximate; to achieve our goals, we build truth tables of intermediate outputs in the circuit of interest and compute the control value by randomly sampling rows in the truth table. Using a tool we developed, called FANCI, we examined 18 TrustHub benchmarks. We were able to identify triggers in each of these benchmarks, achieving low false positive rates (flagging fewer than 10 wires per design on average).

FANCI is the first tool for checking the security of third-party soft IP and regular hardware designs before fabrication. Similar to software static analysis tools, we envision FANCI being used as a first line of defense for enhancing hardware security. It complements runtime techniques for protecting against hardware attacks and standard testing practices. Additionally, it has fewer trust requirements compared to existing runtime detection and protection techniques. While our tool is not theoretically guaranteed to find all backdoors, it is likely that backdoors that evade FANCI either break the digital abstraction or are non-stealthy and thus detectable through normal means. Our experimental results support the claim that this methodology can be applied to real-world designs today. As designs become more complex and time-to-market shrinks, tools like FANCI that can target backdoors before fabrication are critical to the development of trustworthy systems.

### Acknowledgements

We thank anonymous reviewers and members of the Computer Architecture and Security Technologies Lab (CASTL) at Columbia University for their feedback on this work. This work was supported by grants FA 99500910389 (AFOSR), FA 865011C7190 (DARPA), FA 87501020253 (DARPA), CCF/TC 1054844 (NSF), and gifts from Microsoft Research, WindRiver Corp, Xilinx, and Synopsys Inc. This work is also supported through an Alfred P. Sloan Foundation Fellowship and the Department of Defense ND-SEG Fellowship. Opinions, findings, conclusions, and recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the US Government or commercial entities.

### Appendix

In Figure 7, we include example histograms of the triviality values we found for wires in six modules from FabScalar, the benign microprocessor core tested with FANCI. In a normal design, most wires have values that are not extremely small, with values between 0.5 being very common. To make the results easier to read, we have combined the values between zero and 0.5 and one. For example, 0.1 and 0.9 are plotted together, as are 0.7 and 0.3. Semantically, we care about the distance from 0.5, so this is the easiest way to understand the data.

For the DecodePISA module, which experienced slightly lower triviality values than the other example modules, most of the lower values belong to higher-order bits of a 128-bit output packet called DecodedPacket0. Without knowing the intention of the original designer, it seems likely that these upper-order bits are not always being used efficiently. However, the control values are not so low as to merit real suspicion. In addition to serving as a security method, these types of observations may also be useful for regular debugging and optimization by trusted designers.

As shown in the histograms, the vast majority of wires are bunched up on the left side, having relatively normal values (closer to 0.5 than to the extremes of zero or one). In FabScalar, we rarely see wires with values even less than \(2^{-10}\), which is still a relatively benign value (corresponding to roughly a one in one thousand chance of a certain behavior occurring). We can also see that while the values are mostly close to \(2^{-1} = 0.5\), the actual distributions vary from module to module. This is expected, as module designs are complex, and it is rare for two different modules to be exactly the same.

### References

[1] Sally Adee. The Hunt for the Kill Switch. IEEE Spectrum Magazine, 45(5):34–39, 2008.
[2] Marianne Swanson, Nadya Bartol, and Rama Moorthy. Piloting Supply Chain Risk Management Practices for Federal Information Systems. In National Institute of Standards and Technology, page 1, 2010.
[3] United States Department of Defense. High Performance Microchip Supply, February 2005.
[4] Samuel T. King, Joseph Tucek, Anthony Cozzie, Chris Grier, Weihang Jiang, and Yuanyuan Zhou. Designing and Implementing Malicious Hardware. In Proceedings of the 1st Usenix Workshop on Large-Scale Exploits and Emergent Threats, pages 5:1–5:8, Berkeley, CA, USA, 2008. USENIX Association.
[5] Matthew Hicks, Samuel T. King, Milo M. K. Martin, and Jonathan M. Smith. Overcoming an Untrusted Computing Base: Detecting and Removing Malicious Hardware Automatically. In Proceedings of the 31st IEEE Symposium on Security and Privacy, pages 159–172, 2010.
[6] Adam Waksman and Simha Sethumadhavan. Tamper Evident Microprocessors. In Proceedings of the 31st IEEE Symposium on Security and Privacy, pages 173–188, Oakland, California, 2010.
[7] Adam Waksman and Simha Sethumadhavan. Silencing Hardware Backdoors. In Proceedings of the 2011 IEEE Symposium on Security and Privacy, pages 49–63, Oakland, California, 2011.
[8] Adam Waksman, Julianna Eum, and Simha Sethumadhavan. Practical, Lightweight Secure Inclusion of Third-Party Intellectual Property. In Design and Test, IEEE, pages 8–16, 2013.
[12] Trey Reece, Daniel Limbrick, Xiaowen Wang, Bradley Kiddie, and William Robinson. Stealth Assessment of Hardware Trojans in a Microcontroller. In Proceedings of the 2012 International Conference on Computer Design, pages 139–142, 2012.
[13] Sheng Wei, Kai Li, Farinaz Koushanfar, and Miodrag Potkonjak. Provably Complete Hardware Trojan Detection Using Test Point Insertion. In Proceedings of the International Conference on Computer-Aided Design, ICCAD ’12, pages 569–576, New York, NY, USA, 2012. ACM.
[14] Dakshi Agrawal, Selçuk Baktir, Deniz Karakoyunlu, Pankaj Rohatgi, and Berk Sunar. Trojan Detection using IC Fingerprinting. In IEEE Symposium on Security and Privacy, pages 296–310, 2007.
[15] Mainak Banga, Maheshwar Chandrasekar, Lei Fang, and Michael S. Hsiao. Guided Test Generation for Isolation and Detection of Embedded Trojans in ICS. In GLSVLSI ’08: Proceedings of the 18th ACM Great Lakes symposium on VLSI, pages 363–366, New York, NY, USA, 2008. ACM.
[16] Jie Li and J. Lach. At-Speed Delay Characterization for IC Authentication and Trojan Horse Detection. In Hardware-Oriented Security and Trust, 2008. HOST 2008. IEEE International Workshop on, pages 8–14, June 2008.
[17] Mainak Banga and Michael S. Hsiao. A Region Based Approach for the Identification of Hardware Trojans. In Hardware-Oriented Security and Trust, 2008. HOST 2008. IEEE International Workshop on, pages 40–47, June 2008.
[18] Hassan Salmani, Mohammad Tehranipoor, and Jim Plusquellic. New Design Strategy for Improving Hardware Trojan Detection and Reducing Trojan Activation Time. In Hardware-Oriented Security and Trust, 2009. HOST ’09. IEEE International Workshop on, pages 66–73, 2009.
[9] Cynthia Sturton, Matthew Hicks, David Wagner, and Samuel T. King. Defeating UCI: Building Stealthy and Malicious Hardware. In Proceedings of the 2011 IEEE Symposium on Security and Privacy, SP ’11, pages 64–77, Washington, DC, USA, 2011. IEEE Computer Society.
[19] Jeff Kahn, Gil Kalai, and Nathan Linial. The Influence of Variables on Boolean Functions (Extended Abstract). Pages 68–80, 1988.
[10] Mohammad Tehranipoor, Ramesh Karri, Farinaz Koushanfar, and Miodrag Potkonjak. TrustHub. http://trust-hub.org.
[11] Niket K. Choudhary, Salil V. Wadhavkar, Tanmay A. Shah, Hiran Mayukh, Jayneel Gandhi, Brandon H. Dwiel, Sandeep Navada, Hashem H. Najaf-abadi, and Eric Rotenberg. Fabscalar: Composing Synthesizable RTL Designs of Arbitrary Cores within a Canonical Superscalar Template. In Computer Architecture (ISCA), 2011 38th Annual International Symposium on, pages 11–22. IEEE, 2011.