analyzing Web server logs for malicious external requests less
robust, as only a very small portion of websites in our dataset
is pursuing this method. However, it does conﬁrm the ﬁndings
of Han et al. [17] and Cova et al. [9], who also observed a neg-
ligible portion of phishing kits with resources loaded from the
target organization. These authors studied attacker behavior
on honeypot domains, which is based on the assumption that
attackers hijack domains to use for phishing. Although our
measurement methodology is not perfectly suited to ﬁnd such
hijacked domains – as these domains often already have TLS
certiﬁcates – we did ﬁnd 18 of them. All of these domains in-
clude the full FQDN of the target organization as subdomains
and have a slightly longer uptime of 72 hours on average.
Evasion techniques As explained in Section 4, some phish-
ing kits deploy evasion techniques to prevent detection by anti-
Figure 10: CDF of a phishing domain uptime (n = 1,288),
domains with multiple certiﬁcates issued excluded
Figure 11: Histogram of kit installation hours (n = 1,363)
3768    30th USENIX Security Symposium
USENIX Association
0255075100125150175Time online (h)0.000.250.500.751.00Fraction01234567891011121314151617181920212223Time of the day (UTC+1)050100FrequencyFigure 12: Boxplot of timestamps in the end-to-end life cycle of the identiﬁed phishing domains (n = 818)
phishing services such as APWG [14] and Google SafeBrows-
ing [20]. These techniques, often referred to as cloaking, allow
phishers to show a different page to a potential victim than
to a crawler [21, 53]. Although our methodology is focused
on detecting the use of speciﬁc phishing kits in the wild and
not to identify cloaking, we did observe such evasion tech-
niques many times. In fact, 946 (69%) of the detected phishing
domains returned a blank screen – and no favicon – to our
crawler when we visited the domain, meaning that the phish-
ing website detected us and deployed cloaking techniques.
However, our phishing kit detection was still possible because
these websites returned a successful response for the ﬁles
included in the ﬁngerprint. The phishing kit responsible for
most of these cloaking activities was again the uAdmin kit,
which combined some server-side and client-side cloaking.
On the server-side, it checked the IP address with a block list
and created a random path for every visitor, as explained in
Section 4.2. On the client-side, it deployed a simple JavaScript
timeout to evade non-JavaScript crawlers. The combination
of both techniques is shown in Listing 1.
7 External validation
To benchmark and validate our methodology, we compare
our results with data from the APWG eCrime Exchange
(eCX) [15]. This repository contains phishing activity from
all over the world, including many Dutch phishing domains.
A comparison shows that our methodology covers a much
broader spectrum of phishing domains, capturing known dif-
ferentiations in the phishing landscape. In total, only 77 phish-
ing domains detected using our methodology, overlap with the
APWG database, meaning that 1,286 domains are not listed in
their repository. By comparing the date on which a phishing
domain was initially detected by our crawler with the data it
was submitted to the eCX, we ﬁnd that our method was able
to identify phishing domains much faster. In 76 out of the
77 cases (99%), our crawler detected the phishing domains
faster than APWG, with a median time difference of 11.3
hours (almost half a day) earlier. Interestingly, the domains
that overlap with the eCX repository had clearly more bank
names included in their domain name. 61 of the domains
(79%) overlapping with eCX contained a reference to a bank,
whereas only 44% had this in the complete dataset.
This external validation shows that our methodology has the
potential to detect phishing websites very swiftly which could
save unsuspecting people from this kind of fraud.
8 Throwing out the bait
In the previous sections of this paper, we have unraveled the
characteristics of every step in the end-to-end life cycle of a
phishing campaign, except for the last step: sending out the
text messages, e-mails or social media posts, the so-called bait.
Although our measurement system does not contain the input
data necessary to thoroughly analyze this step of the life cycle,
the authors are among the target population of phishers and
thus regularly receive the thrown out bait themselves. During
our data collection period, we collected these messages and
looked into the ones that contained links to domains in our
dataset. This allows us to show the complete timeline of events
in a phishing campaign life cycle. We discuss an example in
the following section.
Verify your identity Within the ﬁrst two weeks of our re-
search, we received a text message seemingly originating from
DigiD, the ofﬁcial Dutch digital identity service. The mes-
sage shown in Figure 14, stated that a suspicious login was
detected and that immediate action was necessary to prevent
cancellation of the account. This is a prime example of the
scarcity and consistency luring techniques as described in Sec-
tion 2.1. The link included in the message directed victims
to https://deblokkeren-digid.xyz, a type IV domain
made with a phishing kit belonging to the uAdmin family.
This website was registered only six hours before the mes-
sage was received and fully operational just three hours later.
On the website, potential victims were asked to verify their
identity by logging into their online bank account. Multiple
options are displayed on the decoy page as shown in Fig-
ure 13a, allowing the victim to choose their preferred bank.
Upon clicking on one of the buttons, the victim is redirected
to yet another phishing page as shown in Figure 13b, which
mimics the chosen bank’s login screen. That page eventu-
ally captures the login credentials of the victim. The use of
the DigiD decoy page is a prime example of the technique
depicted in Figure 1. Within a day, only 12 hours later, the
domain was taken ofﬂine.
USENIX Association
30th USENIX Security Symposium    3769
1101001000Time since domain registration (h)Domain offlineKit installedDomain online(a)
(b)
Figure 13: Landing (decoy) page in 13a: indicating that veriﬁcation through a bank account is necessary to prevent account
deactivation and the actual phishing page in 13b after clicking on a bank of choice on which user credentials are harvested
SMS Message – 17-09-2020 21:32 (translated)
[My DigiD] There has been a suspicious login in
your My DigiD account. Verify this directly to pre-
vent cancellation of your My DigiD account through:
https://deblokkeren-digid.xyz/inloggen
Figure 14: Text message demanding DigiD veriﬁcation and
corresponding timeline of deblokkeren-digid.xyz
9 Related work
Earlier work on phishing involves many different points of
view and subjects. Ranging from creating robust domain
detection methods [5, 12, 13, 27, 32, 45], phishing kit analy-
sis [9, 17, 38], evasion techniques [21, 53] to research focused
on victim behavior [49]. Much effort has been devoted to
the creation of robust detection techniques, but less is known
about the life cycle, ecosystem and actors behind such at-
tacks. Only a limited number of researchers have investigated
this part of phishing [35, 39], which we deem essential to
fully understand the ecosystem and to be able to create robust
countermeasures.
Analysis on phishing kits Early work on phishing kits in
2008 by Cova et al. [9] focused on the analysis of ‘free’ phish-
ing kits. They noticed that packages containing easy-to-deploy
phishing websites often contained backdoors which exﬁltrated
the gathered information also to third parties and that 100%
of the investigated kits were written in the PHP language.
In their PhishEye study, Han et al. [17] share insights into
live phishing websites created by deploying phishing kits
on honeypot domains. Using their sandboxed approach, they
were able to lure phishers into installing phishing kits on
their honeypot servers of which the behavior was closely
monitored. The authors analyzed both phisher and victim
actions on the phishing website, showed that phishing kits
are only active for less than 10 days since their installation
and that most of the victims share the same country of origin.
During their 5 months analysis period (Sep 2015 – Jan 2016),
they collected 643 unique phishing kits of which 74% were
correctly installed by 471 distinct attackers. Additionally, they
discovered that only 10 phishing kits loaded the resources
directly from the website of the targeted organization.
Measurements on live phishing domains
In recent work,
Oest et al. [38] analyzed .htaccess ﬁles – commonly used
on Apache Web servers – to capture the evasive behavior
of phishers. These ﬁles allow phishers to protect themselves
against anti-phishing or search engine crawlers. Their paper
states that deny IP and User-Agent ﬁlters are the most prevail-
ing blacklisting technologies, whilst the allow IP ﬁlter type
is often used to target speciﬁc countries. Additionally, they
proposed a new high-level classiﬁcation scheme for phishing
URLs that builds upon the work of Garera et al. [12]. This tax-
onomy categorizes phishing URLs into ﬁve categories with
different hiding and lure strategies. We also used that taxon-
omy to classify the URLs detected by our measurements in
Section 5.1.
The work closest to ours is from the same authors, who
continued their research by investigating the end-to-end life
cycle of phishing attacks in 2020. This work relied on the
observation that a substantial proportion of phishing pages
make requests for Web resources to the websites that the at-
tackers impersonate [39]. A unique collaboration with a large
payment provider enabled them to link such Web requests to
3770    30th USENIX Security Symposium
USENIX Association
17-Sep 15:0917-Sep 20:0918-Sep 01:0918-Sep 06:09Domain name registredTLS Certificate issuedDomain crawled and onlineDomain offlineSMS receivedthe phishing websites they are originating from. This gave the
authors an in-depth look into phishing campaigns from the
moment the attacker installs the phishing page to the moment
victims disclose their credentials. They found that the average
phishing attack spans 21 hours and that modern Web browsers
display a warning for a detected domain after 16 hours. Oest
et al. [39] called the gap between the launch of the attack
and detection by anti-phishing bodies the ‘golden hours’ of
phishing, in which the attackers gather 38% of their phished
credentials. As our work shared a similar goal – analyzing
the end-to-end life cycle of a phishing campaign – we share
a number of ﬁndings. Namely, the use of extensive use of
server-side cloaking, victim-speciﬁc paths and the presence
of MITM-proxies in phishing kits. Additionally, our conclu-
sions regarding the duration of an average phishing attack
are comparable. However, there are also notable differences.
Their work is focused on one single organization and includes
both HTTP and HTTPS trafﬁc whereas our work focuses
on the entire Dutch ﬁnancial sector, but was limited to do-
mains served over HTTPS only. Furthermore, they relied on
the assumption that phishing domains load resources directly
from the target website, whereas we discovered that only a
negligible portion of domains in our analysis did so.
10 Discussion
Limitations Analyzing a phenomenon like phishing always
brings its inherent limitations and so does this study. As all
other work on this topic, our methodology is only able to cap-
ture part of the phishing landscape. We identify the following
limitations:
We are aware of the fact that by our choice of methodology,
we are limited to phishing domains secured by HTTPS con-
nections only. Yet we believe, as 78% of all phishing in 2020
is delivered through HTTPS according to the APWG [16] and
the fact that Oest et al. [39] concluded that phishing served
over HTTPS was three times more effective, the effects of that
concise decision to be limited. Also note that our approach re-
sults in our ability to identify type III and IV phishing domains
only, and thus miss the three other types. Another limitation of
this work is that we are limited to identifying known phishing
kits. Phishing domains that do not match any of our prede-
ﬁned ﬁngerprints are simply not marked as phishing. Besides
these missing kits, phishers could also change the ﬁle names
or structure of their phishing kits, which would also render
our detection methodology less effective. However, the main
advantage of phishing kits is that they are easy to deploy for
any criminal that wants to go phishing. Therefor, we do not
expect that phishers that deploy these kits are either capable
or willing to make numerous changes each time they deploy
a new phishing website. On the other hand, our ﬁngerprinting
methodology also has a detection advantage for websites that
deploy certain cloaking strategies. As explained in Section 4.1,
some phishing websites ban IP ranges or User-Agents known
to be used by anti-phishing services through PHP scripts on
the homepage, or show a different landing page depending on
the country of origin. These methods make detection based on
the characteristics of the page – e.g., login forms, bank icons,
etc. – rather difﬁcult. However, searching for known ﬁles –
our ﬁngerprints – on such domains bypasses these evasion
methods and results in a robust detection of a phishing kit.
We started our crawling infrastructure three months be-
fore data collection started, which allowed us to carefully
examine the domains missed by our crawler. As explained in
Section 3.4, we created ﬁngerprints based on source code of
live phishing websites missed by our crawling during testing.
So even without obtaining the actual phishing kit, we were
able to create robust ﬁngerprints.
Unfortunately, the largest limitation is in missing data we
do not see. As explained in Section 5.1, many domain names
do not contain references to bank names, but only use com-
mon words. Before data collection started, we added 78 of
such words to our suspicious keywords list, but we have
deﬁnitely missed some. As these domains did not reached
the threshold set in our domain detector, they remain unde-
tected. The validation with eCrime Exchange data in Sec-
tion 7 showed that such domains are less prevalent in this
anti-phishing repository and it is therefore important to in-
clude such words. We identify the validation with only one
data source also as a limitation of our work, but leave valida-
tion with more datasets for future work.
Public policy takeaways Taking decisive action on phish-
ing is complex. Ironically, the standardized notice-and-
takedown (NTD) procedure, that banks generally outsource
to the security industry, has resulted in a game of whack-a-
mole, leaving the police chasing these criminals often empty
handed. And, as concluded by Moore & Clayton [35] in 2017,
website removal is only part of the answer to phishing, but
is not fast enough to completely mitigate the problem. If and
when phishing campaigns are reported to law enforcement
agencies (LEA), phishing domains are often already taken
down, making attribution of the actors behind phishing cam-
paigns near to impossible. Therefore, implementing a system
as presented in this paper would be very beneﬁcial for LEA
investigations.
With WhatsApp and text messages being a popular deliv-
ery mechanism [37], the interaction with victims has sped
up, highlighting the need for early-stage detection even more.
This paper presented a measurement methodology leveraging
the increasing use of phishing kits and TLS certiﬁcates in the
phishing scene to make early-stage detection possible. This
would open a window where phishers have their phishing gear
ready, but have not yet thrown out the bait. Our ﬁndings pin-
point clear choke points in using phishing kits in campaigns,
which law enforcement agencies in turn might exploit for dis-
ruption before a takedown occurs. Our measurements of the
life cycle of campaigns using phishing kits, shows a pattern
USENIX Association
30th USENIX Security Symposium    3771
wherein a persistent time gap exists between domain registra-
tion, deployment and sending out the bait. This is a window of
opportunity that can be used to take preventive action, when
the campaign did not make any victims yet. Leveraging our
methodology, kit ﬁngerprints can be used to automate detec-
tion of domains where a kit is ready to be deployed. We show
that the use of these kits is widespread in the Dutch phish-
ing landscape and have found that distinct families of kits
exist, wherein certain common characteristics are identiﬁed
– likely because the source code of one kit has evolved into
the next. When these characteristics relate to a vulnerability
– e.g., the standard admin password is ‘password’ and the
control panel can be approached via a typical subdomain –
this brings novel opportunities for automated exploitation for
law enforcement purposes towards attribution rather than dis-
ruption. Having a clear picture of the popularity of phishing
kits could assist LEA in prioritizing their anti-phishing efforts
to dominant kits. Interventions – e.g., exploiting a vulnerabil-
ity – on these kits would immediately impact a large portion
of campaigns. Next, these shared traits can also be used to
keep track of the phishing landscape. For instance, uAdmin al-
lows for multiple domains contacting the same control panel,
making in-depth analysis possible on these domains to ﬁnd
new, related campaigns or actors.
A system like ours could complement the threat intelli-
gence process of many organizations, especially ﬁnancial