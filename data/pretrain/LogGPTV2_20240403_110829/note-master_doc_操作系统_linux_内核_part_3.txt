- kmalloc能分配的大小有限,vmalloc和malloc能分配的大小相对较大 
- vmalloc比kmalloc要慢。
尽管在某些情况下才需要物理上连续的内存块，但是很多内核代码都用kmalloc来获得内存，而不是vmalloc。这主要是出于性能的考虑。vmalloc函数为了把物理内存上不连续的页转换为虚拟地址空间上连续的页，必须专门建立页表项。糟糕的是，通过vmalloc获得的页必须一个个地进行映射，因为它们物理上是不连续的，这就会导致比直接内存映射大得多的TLB抖动，vmalloc仅在不得已时才会用--典型的就是为了获得大块内存时。
## 文件系统
### 硬盘文件系统
> 每个文件都会对应一个 inode；一个文件夹就是一个文件，也对应一个 inode
![2022103117555](/assets/2022103117555.webp)
![间接块间接访问](/assets/2022103117710.webp)
![Extents](/assets/20221031173637.webp)
位图：用来记录哪些块是空闲，哪些块已经被使用
![文件系统的格式](/assets/20221031173826.webp)
![目录的存储](/assets/20221031173939.webp)
![软硬链接的存储](/assets/20221031174018.webp)
### 虚拟文件系统
![2022111171821](/assets/2022111171821.webp)
#### 挂载
想要操作文件系统，第一件事情就是注册文件系统：
```c
register_filesystem(&ext4_fs_type);
static struct file_system_type ext4_fs_type = {
  .owner    = THIS_MODULE,
  .name    = "ext4",
  .mount    = ext4_mount,
  .kill_sb  = kill_block_super,
  .fs_flags  = FS_REQUIRES_DEV,
};
```
如果一种文件系统的类型曾经在内核注册过，这就说明允许你挂载并且使用这个文件系统
```c
struct dentry *
mount_fs(struct file_system_type *type, int flags, const char *name, void *data)
{
  struct dentry *root;
  struct super_block *sb;
......
  root = type->mount(type, flags, name, data);
......
  sb = root->d_sb;
......
}
```
#### 打开文件
### 文件缓存
- 缓存 I/O：大多数文件系统的默认 I/O 操作都是缓存 I/O
  - 读操作：先查缓存，没有再读磁盘
  - 写操作：批量写到内存，再统一刷到磁盘，或者显式调用sync
- 直接 IO：就是应用程序直接访问磁盘数据，而不经过内核缓冲区，从而减少了在内核缓存和用户程序之间数据复制
![2022111191419](/assets/2022111191419.webp)
## 输入输出系统
除了常规的软硬件IO控制，Linux通过文件系统接口屏蔽驱动程序的差异
操作设备，都是基于文件系统的接口
- /sys/devices 是内核对系统中所有设备的分层次的表示
- /sys/dev 目录下一个 char 文件夹，一个 block 文件夹，分别维护一个按字符设备和块设备的主次号码 (major:minor) 链接到真实的设备 (/sys/devices 下) 的符号链接文件
- /sys/block 是系统中当前所有的块设备
- /sys/module 有系统中所有模块的信息
![202211214577](/assets/202211214577.webp)
### 字符设备
工作的条件：
- 要有设备驱动程序的 ko 模块，里面有模块初始化函数、中断处理函数、设备操作函数。这里面封装了对于外部设备的操作，初始化函数在加载驱动被调用，会在内核维护所有字符设备驱动的数据结构 cdev_map 里面注册自己的设备号
- /dev 目录下有一个文件表示这个设备，里面有inode存储设备号，可以通过设备号在 cdev_map 中找到设备驱动程序
- 打开一个字符设备文件和打开一个普通的文件有类似的数据结构，有文件描述符、有 struct file、指向字符设备文件的 dentry 和 inode，写一个字符设备文件会变成读写外部设备
### 块设备
![2022113162443](/assets/2022113162443.png)
## 进程间通信
- 消息模型
- 共享内存模型
- 信号量
### 管道模型
- 命令之间的 | 
- 手动创建管道 mkfifo hello
管道是内核里面的一串缓存
### 信号
中断要注册中断处理函数，但是中断处理函数是在内核驱动里面的，信号也要注册信号处理函数，信号处理函数是在用户态进程里面的。
用户进程对信号的处理方式：
- 执行默认操作
- 捕获并覆写默认操作
- 忽略
```c
// 设置信号处理的方式
int sigaction(int signum, const struct sigaction *act,
                     struct sigaction *oldact);
```
![2022113191142](/assets/2022113191142.webp)
![信号处理流程](/assets/2022114163242.png)
### IPC机制
![共享内存与信号量](/assets/2022117153354.webp)
使用之前都要生成 key，然后通过 key 得到唯一的 id，并且都是通过 xxxget 函数，这三种进程间通信机制是使用统一的机制管理起来的，都叫 ipcxxx
```c
struct ipc_namespace {
......
  struct ipc_ids  ids[3];
......
}
#define IPC_SEM_IDS  0
#define IPC_MSG_IDS  1
#define IPC_SHM_IDS  2
#define sem_ids(ns)  ((ns)->ids[IPC_SEM_IDS])
#define msg_ids(ns)  ((ns)->ids[IPC_MSG_IDS])
#define shm_ids(ns)  ((ns)->ids[IPC_SHM_IDS])
```
```c
struct ipc_ids {
  int in_use;
  unsigned short seq;
  struct rw_semaphore rwsem;
  struct idr ipcs_idr;
  int next_id;
};
struct idr {
  struct radix_tree_root  idr_rt;
  unsigned int    idr_next;
};
```
![202211716251](/assets/202211716251.webp)
![共享内存机制](/assets/2022117161126.webp)
![信号量机制](/assets/2022117161221.webp)
## 网络系统
### socket
一些关于socket的系统调用：
- 服务端和客户端都调用 socket，得到文件描述符
- 服务端调用 listen，进行监听
- 服务端调用 accept，等待客户端连接
- 客户端调用 connect，连接服务端
- 服务端 accept 返回用于传输的 socket 的文件描述符
- 客户端调用 write 写入数据
- 服务端调用 read 读取数据。
在创建socket时，有三个参数：
- family：地址族，不是所有的 Socket 都要通过 IP 进行通信，还有其他的通信方式
  - AF_UNIX Unix domain sockets
  - AF_INET Internet IP Protocol
- type
  - SOCK_STREAM 面向数据流的，协议 IPPROTO_TCP 属于这种类型
  - SOCK_DGRAM 面向数据报的，协议 IPPROTO_UDP、IPPROTO_ICMP 属于这种类型
  - SOCK_RAW 原始的 IP 包，IPPROTO_IP 属于这种类型
![三次握手过程](/assets/2022117175133.webp)
![不同类型的socket的内核数据结构及其对应的实现函数](/assets/2022117175244.webp)
有一种机制，就是当一些网络包到来触发了中断，内核处理完这些网络包之后，我们可以先进入主动轮询 poll 网卡的方式，主动去接收到来的网络包。如果一直有，就一直处理，称为 NAPI
![发送](/assets/2022118152126.png)
![接收](/assets/2022118161546.png)
### Netfilter
可以在内核处理网络包的过程中插入 hook 函数。这些函数可以截获数据包，对数据包进行干预。例如做一定的修改
![](/assets/202352514037.webp)
内核模块 ip_tables 在这五个节点上埋下函数，从而可以根据规则进行包的处理。按功能可分为四大类：连接跟踪（conntrack）、数据包的过滤（filter）、网络地址转换（nat）和数据包的修改（mangle）
![](/assets/202352514357.webp)
## 虚拟化
- 完全虚拟化
- 硬件辅助虚拟化：大部分指令直接在CPU上执行，少部分指令让物理机转述执行
- 半虚拟化：通过加载驱动，GuestOS 知道自己是虚拟机，所以数据会直接发送给半虚拟化设备，经过特殊处理（例如排队、缓存、批量处理等性能优化方式），最终发送给真正的硬件
![半虚拟化](/assets/2022118191017.webp)
![CPU虚拟化](/assets/202211915545.png)
![内存虚拟化](/assets/2022119151126.webp)
![存储虚拟化](/assets/2022119152436.webp)
![网络虚拟化](/assets/2022119153034.jpg)
## 容器化
### namespace
为了隔离不同类型的资源，Linux 内核里面实现了以下几种不同类型的 namespace：
- UTS，对应的宏为 CLONE_NEWUTS，表示不同的 namespace 可以配置不同的 hostname
- User，对应的宏为 CLONE_NEWUSER，表示不同的 namespace 可以配置不同的用户和组
- Mount，对应的宏为 CLONE_NEWNS，表示不同的 namespace 的文件系统挂载点是隔离的
- PID，对应的宏为 CLONE_NEWPID，表示不同的 namespace 有完全独立的 pid，也即一个 namespace 的进程和另一个 namespace 的进程，pid 可以是一样的，但是代表不同的进程
- Network，对应的宏为 CLONE_NEWNET，表示不同的 namespace 有独立的网络协议栈
```sh
# 离开当前的 namespace，创建且加入新的 namespace，然后执行参数中指定的命令
unshare --mount --ipc --pid --net --mount-proc=/proc --fork /bin/bash
```
还可以通过函数操作 namespace：
```c
// 创建一个新的进程，并把它放到新的 namespace 中
int clone(int (*fn)(void *), void *child_stack, int flags, void *arg);
// 用于将当前进程加入到已有的 namespace 中
int setns(int fd, int nstype);
// 使当前进程退出当前的 namespace，并加入到新创建的 namespace
int unshare(int flags);
```
### cgroup
定义了下面的一系列子系统，每个子系统用于控制某一类资源，本质上就是一系列配置，在内核运行的各个节点可以被读取，从而进行限制
- CPU 子系统，主要限制进程的 CPU 使用率
- cpuacct 子系统，可以统计 cgroup 中的进程的 CPU 使用报告
- cpuset 子系统，可以为 cgroup 中的进程分配单独的 CPU 节点或者内存节点
- memory 子系统，可以限制进程的 Memory 使用量
- blkio 子系统，可以限制进程的块设备 IO
- devices 子系统，可以控制进程能够访问某些设备
- net_cls 子系统，可以标记 cgroups 中进程的网络数据包，然后可以使用 tc 模块（traffic control）对数据包进行控制
- freezer 子系统，可以挂起或者恢复 cgroup 中的进程
![流程](/assets/20221110162924.png)