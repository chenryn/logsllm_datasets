t
e
c
S
a
f
e
B
r
o
w
si
n
g
T
r
e
n
d
M
ic
r
o
error
unknown
safe
bad
s
L
R
U
d
e
n
n
a
c
s
f
o
%
 100
 80
 60
 40
 20
 0
C
A
M
P
M
a
l
w
a
r
e
D
o
m
S
it
e
A
d
vis
o
r
a
i
n
L
is
t
error
unknown
safe
bad
S
y
m
a
n
t
e
c
S
a
f
e
B
r
o
w
si
n
g
T
r
e
n
d
M
ic
r
o
Fig. 13.
flagged as benign by CAMP.
The graph shows how different web services classify URLs
Fig. 14.
flagged as malicious by CAMP.
The graph shows how different web services classify URLs
The Fake AV binaries were primarily hosted on the free
domain provider uni.me. Free domain providers allow third
parties to register many domain names at low cost, and are
frequently abused by adversaries seeking to distribute malware.
This particular campaign registered domains matching the
following pattern
[srv|www|server|update]NN.dict.uni.me
where dict corresponds to a random English word. Each
domain was active for only a short period of time. To estimate
domain lifetime, we take the client|host 1 day aggregates
from February and compute the lifetime as the difference in
time between the last observed download request and the first.
The median lifetime for a domain was 406 seconds, and the
90th percentile was 1749 seconds. Some of the domains were
active simultaneously. Table II provides examples of domains
employed in the campaign, along with the time of the first
request we observed for that domain and its estimated lifetime.
Over the two week period, we observed over 13, 000 unique
domains on uni.me involved in this campaign.
We observe that the high frequency of domain changes
thwarts simple blacklisting-based approaches. The maintainers
of the blacklist would need to be able to fetch the content,
analyze it, and push out
list updates within minutes. We
noticed that even fetching the content would be challenging,
as each domain stopping resolving properly after a short time
period.
The campaign not only switched domains, but also changes
the binaries that were served as indicated by their changing
content hash. We observed that the binaries served by each
host changed approximately every 10 minutes. We fetched
and analyzed several samples, and they all offered the same
functionality, a Fake Anti-Virus that hijacks the user’s system
and refuses to release it until a registration fee is paid. We
submitted one of the samples to VirusTotal and only one of
40 AV engines identified it as malware.
This particular malware hijacks the user’s machine by
setting the execution environment for all essential system
Time of first appearance
2012/02/18 15:02:00
2012/02/18 15:02:02
2012/02/18 15:02:05
2012/02/18 15:02:06
2012/02/18 15:02:15
2012/02/18 15:02:26
2012/02/18 15:02:38
2012/02/18 15:02:50
2012/02/18 15:02:53
2012/02/18 15:02:57
Life (sec)
632
330
629
587
246
25
560
693
575
1258
TABLE II
Host(.uni.me)
srv62.specialarmor
srv76.specialarmor
www12.fuelwire
server78.fuelwire
www82.fuelwire
update96.fuelwire
server45.specialarmor
server52.specialarmor
www77.fuelwire
www92.specialarmor
THIS TABLE LISTS EXAMPLE DOMAINS FOR A FAKE AV CAMPAIGN AND
THEIR CORRESPONDING LIFETIME.
processes to run in a debugger that points to a dummy process.
This is achieved by setting the registry key
HKLM\software\microsoft\windows nt\
currentversion\image file execution
options\msa.exe\Debugger:svchost.exe
This prevents key processes from performing meaningful tasks
rendering the machine unusable. The Fake AV binary provides
a mechanism to ‘‘fix’’ the problem once the software is
registered for a fee.
As the domains for this campaign rotated quickly, our
analysis pipeline fetched only a few samples. We observed
over 900 distinct content hashes resulting in binaries with
identical behavior. In total, we saw over 41, 000 different
binaries exhibiting similar behavior.
When the campaign first started and we had not yet fetched
these samples, CAMP replied with an unknown verdict, thus
still protecting our users from these downloads. In general,
when we cannot fetch the binaries that our users download, due
to e.g. one-time URLs, the unknown verdict offers protection.
In the future, CAMP could be updated to use the lack of
ability to fetch content from an URL as a feature by itself.
The browser could also be changed to allow users to upload
files. This would facilitate analysis of campaigns that host
executables on one-time URLs.
While this campaign aggressively switched domains and
changes binaries, it did not rotate IP addresses as frequently.
We observed it across only five IPs during a two week period:
95.143.37.145, 46.21.154.155, 194.28.114.103,
194.28.114.102, and 217.116.198.33. Our hypothe-
sis is that the adversaries behind the campaign focused on
domain rotation to avoid widely-deployed blacklists and binary
mutation to avoid AV engines, but were not concerned with IP
rotation as there are few widely-deployed IP-based blacklists.
to any operating system and to any content type that can be
labeled. For example, with an accurate labeling mechanism
for browser add-ons, CAMP could render reputation-based
verdicts when a browser add-on is downloaded.
While CAMP is currently only available in Google Chrome,
we plan on making the service available to all web browsers
once we have gained more operational understanding of the
system and have further improved CAMP’s detection rates.
VI. DISCUSSION
VII. CONCLUSION
Blacklist-based approaches in which web browsers block
content from known malicious sites offer some protection
against malware, but suffer from a knowledge gap when ad-
versaries frequently switch to new domains or repack binaries.
Blacklists are still effective in protecting web browsers in
situations where it is not possible to quickly rotate domains,
e.g., when using a compromised web site to drive traffic.
A potentially more resilient approach leverages whitelists
so that web browsers download content only from trusted
sites. Unfortunately, such a whitelist is never going to be
complete either, resulting in legitimately benign content not
being available to web users. CAMP bridges the gap between
blacklists and whitelists by augmenting both approaches with
a reputation system that is applied to unknown content. As our
evaluation has shown, CAMP does not suffer from significant
false positives, but could benefit from higher detection rates.
Utilizing more traditional machine learning approaches in
addition to the binary circuit currently employed by CAMP
may improve detection. However, the ability for humans to
reason about detection verdicts is important to our deployment
and additional research is required to better reason about the
large models generated by machine learning approaches.
The performance of CAMP depends significantly on the
mechanism used for labeling binary samples. Any improve-
ment to detection rates in the binary classifier will directly
translate to improved detection in CAMP. Our current binary
classifier is conservative and has the explicit goal of not
tolerating any false positives. However, it is conceivable that
in the context of CAMP, we could tolerate a small number of
false positives to improve overall detection. Instead of using
a binary analysis platform, we posit that binaries could also
be labeled by AV engines, for example, by taking a majority
vote to determine if a binary is malicious or not.
One of CAMP’s important properties is to minimize the
impact on user privacy while still providing protection. To
achieve this goal, the browser leverages a whitelist to limit
the number of decisions which require server interaction. Even
when the browser does ask the server for a decision, only
a small set of features is sent. These features are stored for
up to two weeks, and afterwards only aggregated information
is stored, but no longer than a few months. Despite severely
limiting the data available to the system, our evaluation shows
that CAMP exhibits high accuracy rates.
While the content-agnostic nature of CAMP helps to reduce
its privacy impact, it also means that CAMP can be applied
Although browsers have become more secure, the world
wide web continues to be a significant contributer to malware
infections. Many of the defenses available to users such as
blacklists or AV engines face challenges as adversaries can
evade detection by frequently changing hosting domains or
mutating their malware binaries until
they are no longer
detected.
This paper introduced CAMP, a content-agnostic malware
protection system, which employs a reputation system that
detects malware independently of the actual binary contents.
CAMP protects browser users from malware downloads while
also minimizing the impact on user privacy. To get a reputa-
tion decision for a binary download, the web browser contacts
CAMP’s servers which automatically build reputation for
downloads and render reputation-based verdicts. If a download
is deemed malicious, the web browser displays a warning to
the user and offers to delete the downloaded file.
We provided a detailed overview of CAMP’s design and
architecture and discussed in detail all the components that
constitute the reputation system. At its core, the reputation met-
ric is calculated via a binary circuit that receives its input from
statistical aggregates. The statistical aggregates are computed
based on features derived from web browser requests and
contain information on how often they occurred in a malicious
context compared to the total number of occurrences.
In this paper, we performed an extensive six month evalu-
ation of CAMP consisting of over 200 million unique users
of Google Chrome and millions of daily reputation decisions.
We showed that our content-agnostic detection approach is
both accurate, with an accuracy of close to 99% relative to
proprietary VM-based dynamic analysis, and well performing,
processing requests in less than 130 ms on average.
In comparing CAMP with the current state of practice, we
demonstrated that CAMP outperforms Anti-Virus, as well as
various web services, e.g. McAfee’s Site Advisor, Symantec’s
Safeweb, etc. Furthermore, CAMP augments Google’s Safe
Browsing API, flagging 5 million malware downloads per
month that were not previously identified.
ACKNOWLEDGEMENTS
The authors would like to thank Michael Bailey for helpful
suggestions for this paper. We also thank our shepherd Lenx
Wei for his valuable suggestions to improve this paper.
[25] N. Provos, P. Mavrommatis, M. A. Rajab, and F. Monrose. All Your
iFRAMEs Point to Us. In USENIX Security Symposium, pages 1--16,
2008.
[26] Z. Qian, Z. M. Mao, Y. Xie, and F. Yu. On network-level clusters for
spam detection. In NDSS. The Internet Society, 2010.
[27] M. Rajab, L. Ballard, N. Jagpal, P. Mavrommatis, D. Nojiri, N. Provos,
Trends in circumventing web-malware detection.
and L. Schmidt.
Technical report, Google, Tech. Rep., July 2011.
[28] M. A. Rajab, L. Ballard, P. Mavrommatis, N. Provos, and X. Zhao. The
Nocebo Effect on the Web: An Analysis of Fake Anti-Virus Distribution.
In Proceedings of the 3rd USENIX Workshop on Large-Scale Exploits
and Emergent Threats (LEET), April 2010.
[29] C. Reis, A. Barth, and C. Pizano. Browser security: lessons from google
chrome. Queue, 7(5):3, 2009.
[30] P. Royal, M. Halpin, D. Dagon, R. Edmonds, and W. Lee. Polyunpack:
Automating the hidden-code extraction of unpack-executing malware.
In Computer Security Applications Conference, 2006. ACSAC’06. 22nd
Annual, pages 289--300. IEEE, 2006.
[31] C. Song, P. Royal, and W. Lee. Impeding automated malware analysis
with environment-sensitive malware. In Proceedings of the 7th USENIX
conference on Hot Topics in Security, HotSec’12, pages 4--4, Berkeley,
CA, USA, 2012. USENIX Association.
[32] H. Wang, C. Grier, A. Moshchuk, S. King, P. Choudhury, and H. Venter.
The multi-principal os construction of the gazelle web browser.
In
Proceedings of the 18th conference on USENIX security symposium,
pages 417--432. USENIX Association, 2009.
[33] H. Yin, D. Song, M. Egele, C. Kruegel, and E. Kirda. Panorama:
Capturing System-wide Information Flow for Malware Detection and
Analysis.
In Proceedings of the 14th ACM Conference of Computer
and Communication Security, October 2007.
REFERENCES
[1] VirusTotal. https://www.virustotal.com/.
[2] M. Antonakakis, R. Perdisci, D. Dagon, W. Lee, and N. Feamster.
In Proceedings of
Building a Dynamic Reputation System for DNS.
the 19th USENIX Security Symposium (August 2010).
[3] M. Antonakakis, R. Perdisci, W. Lee, N. Vasiloglou II, and D. Dagon.
Detecting malware domains at the upper dns hierarchy. In Proceedings
of the 20th USENIX Security Symposium, USENIX Security, volume 11,
2011.
[4] A. Averbuch, M. Kiperberg, and N. Zaidenberg. An efficient vm-based
software protection. In Network and System Security (NSS), 2011 5th
International Conference on, pages 121--128. IEEE, 2011.
[5] L. Bilge, E. Kirda, C. Kruegel, and M. Balduzzi. Exposure: Finding
malicious domains using passive dns analysis. In NDSS. The Internet
Society, 2011.
[6] Bit9. Bit9 Global Software Registry. http://www.bit9.com/products/
bit9-global-software-registry.php, July 2012.
[7] J. Caballero, C. Grier, C. Kreibich, and V. Paxson. Measuring Pay-per-
Install: The Commoditization of Malware Distribution. In Proceedings
of the the 20th USENIX Security Symposium, San Francisco, CA, August
2011.
[8] F. Chang, J. Dean, S. Ghemawat, W. Hsieh, D. Wallach, M. Burrows,
T. Chandra, A. Fikes, and R. Gruber. Bigtable: A distributed storage
system for structured data. ACM Transactions on Computer Systems
(TOCS), 26(2):1--26, 2008.
[9] M. Christodorescu, S. Jha, S. Seshia, D. Song, and R. Bryant. Semantics-
IEEE Symposium on Security and Privacy,
aware malware detection.
pages 32--46, 2005.
[10] R. Colvin. Stranger Danger - Introducing SmartScreen Application
http://blogs.msdn.com/b/ie/archive/2010/10/13/
Reputation.
stranger-danger-introducing-smartscreen-application-reputation.aspx,
October 2010.
[11] CoreTrace. Application Whitelisting: A New Security Paradigm. http:
//www.coretrace.com/, July 2008.
[12] M. Cova, C. Leita, O. Thonnard, A. Keromytis, and M. Dacier. An
In Recent Advances in Intrusion
analysis of rogue av campaigns.
Detection, pages 442--463. Springer, 2010.
[13] C. Curtsinger, B. Livshits, B. Zorn, and C. Seifert. Zozzle: Fast and
In USENIX Security
precise in-browser javascript malware detection.
Symposium, 2011.
[14] J. Dean and S. Ghemawat. Mapreduce: Simplified data processing on
In Proceedings of the Sixth Symposium on Operating
large clusters.
System Design and Implementation, pages 137--150, Dec 2004.
[15] P. Ferrie. Attacks on More Virtual Machine Emulators. Symantec White
Paper, 2007.
[16] Google. Google Safe Browsing API.
safebrowsing/, July 2012.
http://code.google.com/apis/
[17] C. Grier, S. Tang, and S. King. Secure web browsing with the op web
browser. In Security and Privacy, 2008. SP 2008. IEEE Symposium on,
pages 402--416. Ieee, 2008.
[18] S. Hao, N. A. Syed, N. Feamster, A. G. Gray, and S. Krasser. De-
tecting spammers with snare: spatio-temporal network-level automatic
reputation engine. In Proceedings of the 18th conference on USENIX
security symposium, SSYM’09, pages 101--118, Berkeley, CA, USA,
2009. USENIX Association.
[19] K. Hoffman, D. Zage, and C. Nita-Rotaru. A survey of attack and
defense techniques for reputation systems. ACM Computing Surveys
(CSUR), 42(1):1, 2009.
[20] C. Kanich, N. Weaver, D. McCoy, T. Halvorson, C. Kreibich,
K. Levchenko, V. Paxson, G. Voelker, and S. Savage. Show me the
money: Characterizing spam-advertised revenue. In Proceedings of the
20th USENIX Security Symposium, San Francisco, CA, 2011.
[21] L. Lu, V. Yegneswaran, P. Porras, and W. Lee. Blade: an attack-agnostic
approach for preventing drive-by malware infections. In Proceedings of
the 17th ACM conference on Computer and communications security,
pages 440--450. ACM, 2010.
[22] McAfee. McAfee Site Advisor. http://www.siteadvisor.com/, July 2012.
[23] Norton. Norton Safe Web. http://safeweb.norton.com, July 2012.
[24] J. Oberheide, E. Cooke, and F. Jahanian. Cloudav: N-version Antivirus
in the Network Cloud. In Proceedings of the 17th conference on Security
symposium, pages 91--106. USENIX Association, 2008.