during the FORCUM process. This kind of error will cause
inconvenience to a user and must be ﬁxed by marking the
corresponding cookies as useful. CookiePicker attempts to
achieve a very low rate on this kind of error, so that it does
not cause any inconvenience to users. This requirement is
achieved by two means. One one hand, for those visited
pages, the decision algorithms of CookiePicker attempt to
make sure that each useful persistent cookie can be identi-
ﬁed and marked as useful. On the one hand, since Cook-
iePicker is designed with very low running cost, a longer
running period (or periodically running) of the FORCUM
process is affordable, thus training accuracy can be further
improved.
CookiePicker provides a simple recovery button for
backward error recovery in the tuning process. In case a
user notices some malfunctions or some strange behaviors
on a Web page, the cookies disabled by CookiePicker in
this particular Web page view can be re-marked as useful
via a simple button click. Note that once the cookie set of
a Web site becomes stable after the training and tuning pro-
cesses, those disabled useless cookies will be removed from
the Web browser’s cookie jar.
4. HTML Page Difference Detection
In this section, we present two complementary mecha-
nisms for online detecting the HTML Web page differences
between the enabled and disabled cookie usages.
In the
ﬁrst mechanism, we propose a restricted version of Sim-
ple Tree Matching algorithm [23] to detect the HTML doc-
ument structure difference. In the second mechanism, we
propose a context-aware visual content extraction algorithm
to detect the HTML page visual content difference. We call
these two mechanisms as Restricted Simple Tree Match-
ing (RSTM) and Context-aware Visual Content Extraction
(CVCE), respectively. Intuitively, RSTM focuses on detect-
ing the internal HTML document structure difference, while
CVCE focuses on detecting the external visual content dif-
ference perceived by a user. In the following, we present
these two mechanisms and explain how they are comple-
mentarily used.
4.1. Restricted Simple Tree Matching
As mentioned in Section 3, in a user’s Web browser, the
content of an HTML Web page is naturally parsed into a
DOM tree before it is rendered on the screen for display.
Therefore, we resort to the classical measure of tree edit
distance introduced by Tai [17] to quantify the difference
between two HTML Web pages. Since the DOM tree parsed
from the HTML Web page is rooted (document node is the
only root), labeled (each node has node name), and ordered
(the left-to-right order of sibling nodes is signiﬁcant), we
only consider rooted labeled ordered tree. In the following,
we will ﬁrst review the tree edit distance problem; then we
will explain why we choose top-down distance and detail
the RSTM algorithm; and ﬁnally we will use Jaccard simi-
larity coefﬁcient to deﬁne the similarity metric of a normal-
ized DOM tree.
4.1.1. Tree Edit Distance
, let |T| and
For two rooted labeled ordered trees T and T (cid:1)
|T (cid:1)| denote the numbers of nodes in trees T and T (cid:1)
, and
let T [i] and T (cid:1)[j] denote the ith and jth preorder traversal
nodes in trees T and T (cid:1)
, respectively. Tree edit distance is
deﬁned as the minimum cost sequence of edit operations to
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007transform T into T (cid:1)
[17]. The three edit operations used in
transformation include: inserting a node into a tree, delet-
ing a node from a tree, and changing one node of a tree into
another node. Disregarding the order of the edit operations
being applied, the transformation from T to T (cid:1)
can be de-
scribed by a mapping as deﬁned in [17].
Since the solution of the generic tree edit distance prob-
lem has high time complexity, researchers have investigated
the constrained versions of the problem. By imposing con-
ditions on the three edit operations mentioned above, a
few different tree distance measures have been proposed
and studied in the literature: alignment distance [8], iso-
lated subtree distance [18], top-down distance [15, 23], and
bottom-up distance [20]. The description and comparison
of these algorithms are beyond the scope of this paper, see
[2] and [20] for details.
4.1.2. Top-Down Distance
:
Because RSTM belongs to the top-down distance approach,
we review the deﬁnition of top-down distance and explain
why we choose this measure for our study.
Deﬁnition 3. A mapping (M, T, T (cid:1)) from T to T (cid:1)
, is
top-down if it satisﬁes the condition that for all i, j such
that T [i] and T (cid:1)[j] are not the roots, respectively, of T and
T (cid:1)
if pair (i, j) ∈ M then (parent(i), parent(j)) ∈ M .
The top-down distance problem was introduced by
Selkow [15]. In [23], Yang presented a O(|T| · |T (cid:1)|) time-
complexity top-down dynamic programming algorithm,
which is named as the Simple Tree Matching (STM) algo-
rithm.
As we mentioned earlier, our goal is to effectively detect
noticeable HTML Web page difference between the enabled
and disabled cookie usages. The measure of top-down dis-
tance captures the key structure difference between DOM
trees in an accurate and efﬁcient manner, and ﬁts well to
our requirement. In fact, top-down distance has been suc-
cessfully used in a few Web-related projects. For exam-
ple, Zhai and Liu [25] used it for extracting structured data
from Web pages; and Reis et al. [14] applied it for au-
tomatic Web news extraction. In contrast, bottom-up dis-
tance [20], although can be more efﬁcient in time complex-
ity (O(|T| + |T (cid:1)|)), falls short of being an accurate met-
ric [19] and may produce a far from optimal result [1] for
HTML DOM tree comparison, in which most of the differ-
ences come from the leaf nodes.
4.1.3. Restricted Simple Tree Matching
Based on the original STM algorithm [23], Figure 2 il-
lustrates, RSTM, our restricted version of STM algorithm.
if the roots of the two trees A and B contain different symbols then
return(0);
currentLevel > maxLevel then
return(0);
endif
currentLevel = level + 1;
if A and B are leaf or non-visible nodes or
Algorithm: RSTM(A, B, level)
1.
2.
3.
4.
5.
6.
7.
8.
9. m = the number of ﬁrst-level subtrees of A;
10. n = the number of ﬁrst-level subtrees of B;
Initialization, M [i, 0] = 0 for i = 0, ..., m;
11.
M [0, j] = 0 for j = 0, ..., n;
12.
13.
14.
15.
for i = 1 to m do
endif
for j = 1 to n do
M [i, j] = max(M [i, j − 1], M [i − 1, j],
M [i − 1, j − 1] + W [i, j]);
16.
17.
where W [i, j] = RSTM(Ai, Bj , currentLevel)
where Ai and Bj are the ith and jth
ﬁrst-level subtrees of A and B, respectively
endfor
18.
19. endfor
20. return (M [m, n] + 1);
Figure 2: The Restricted Simple Tree Matching Algorithm.
Other than lines 4 to 8 and one new parameter level, our
RSTM algorithm is similar to the original STM algorithm.
Like the original STM algorithm, we ﬁrst compare the roots
of two trees A and B. If their roots contain different sym-
bols, then A and B do not match at all. If their roots con-
tain same symbols, we use dynamic programming to recur-
sively compute the number of pairs in a maximum match-
ing between trees A and B. Figure 3 gives two trees, in
which each node is represented as a circle with a single let-
ter inside. According to the preorder traversal, the four-
teen nodes in tree A are named from N1 to N14, and
the eight nodes in tree B are named from N15 to N22.
The ﬁnal computed return result by using STM algorithm
or RSTM algorithm is the number of matching pairs for
a maximum matching. For example, STM algorithm will
return “7” for the two trees in Figure 3, and the seven
matching pairs are {N1, N15}, {N2, N16}, {N6, N18},
{N7, N19}, {N5, N17}, {N11, N20}, and {N12, N22}.
There are two reasons why a new parameter level is intro-
duced in RSTM. First, some Web pages are very dynamic.
From the same Web site, even if a Web page is retrieved
twice in a short time, there may exist some differences be-
tween the retrieved contents. For example, if we refresh
Yahoo home page twice in a short time, we can often see
some different advertisements. For CookiePicker, such dy-
namics on a Web page are just noises and should be differ-
entiated from the Web page changes caused by the enabled
and disabled cookie usages. This kind of noises, although
very annoying, has a distinct characteristic that they often
appear at the lower level of the DOM trees.
In contrast,
the Web page changes caused by enabling/disabling cook-
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007N1 a
N15
a
N2
b
N3
c
N4
b
N5
c
N16
b
N17
c
d
N6
e
N7
f
N8
e
N9
d
N11
g
N10
d
N18
e
N19
N20
g
f
N21
h
N12
i
j
N13
N14
(a)
h
N22
(b)
Figure 3: (a) Tree A, (b) Tree B.
ies are often so obvious that the structural dissimilarities are
clearly reﬂected at the upper level of the DOM trees. By us-
ing the new parameter level, the RSTM algorithm restricts
the top-down comparison between the two trees to a certain
maximum level. Therefore, equipped with the parameter
level, RSTM not only captures the key structure dissimilar-
ity between DOM trees, but also reduces leaf-level noises.
The second reason is that the O(|T| · |T (cid:1)|) time com-
plexity of STM is still too expensive to use online. Even
with C++ implementation, STM will spend more than one
second in difference detection for some large Web pages.
However, as shown in Section 5, the cost of the RSTM al-
gorithm is low enough for online detection.
The newly-added conditions at line 5 of the RSTM algo-
rithm restrict that the mapping counts only if the compared
nodes are not leaves and have visual effects. More speciﬁ-
cally, all the comment nodes are excluded in that they have
no visual effect on the displayed Web page. Script nodes
are also ignored because normally they do not contain any
visual elements either. Text content nodes, although very
important, are also excluded due to the fact that they are
leaf nodes (i.e., having no more structural information). In-
stead, text content will be analyzed in our Context-aware
Visual Content Extraction (CVCE) mechanism.
4.1.4. Normalized Top-Down Distance Metric
Since the return result of RSTM (or STM) is the number
of matching pairs for a maximum matching, based on the
Jaccard similarity coefﬁcient that is given in Formula 1, we
deﬁne the normalized DOM tree similarity metric in For-
mula 2.
J(A, B) =
|A ∩ B|
|A ∪ B|
RST M (A, B, l)
N T reeSim(A, B, l) =
N (A, l) + N (B, l) − RST M (A, B, l)
(1)
(2)
The Jaccard similarity coefﬁcient J(A, B) is deﬁned as
the ratio between the size of the intersection and the size
of the union of two sets.
In the deﬁnition of our nor-
malized DOM tree similarity metric N T reeSim(A, B, l),
RST M(A, B, l) is the returned number of matched pairs
cT ext = context+SEPARATOR+node.value;
S = S ∪ {cT ext};
Algorithm: contentExtract(T, context)
Initialization, S = ∅; node = T.root;
1.
if node is a non-noise text node then
2.
3.
4.
5.
6.
7.
8.
9.
elseif node is an element node then
currentContext = context+“:”+node.name;
n = the number of ﬁrst-level subtrees of T ;
for j = 1 to n do
S = S∪contentExtract(Ti , currentContext);
where Ti is the ith ﬁrst-level subtrees of T ;
endfor
10.
11. endif
12. return (S);
Figure 4: The Text Content Extraction Algorithm.
by calling RSTM on trees A and B for upper l levels.
N(A, l) and N(B, l) are the numbers of non-leaf visible
nodes at upper l levels of trees A and B, respectively.
Actually N(A, l) = RST M(A, A, l) and N(B, l) =
RST M(B, B, l), but N(A, l) and N(B, l) can be com-
puted in O(n) time by simply preorder traversing the upper
l levels of trees A and B, respectively.
4.2. Context-aware Visual Content Extrac-
tion
The visual contents on a Web page can be generally clas-
siﬁed into two groups: text contents and image contents.
Text contents are often displayed as headings, paragraphs,
lists, table items, links, and so on. Image contents are of-
ten embedded in a Web page in the form of icons, buttons,
backgrounds, ﬂashes, video clips, and so on. Our second
mechanism mainly uses text contents, instead of image con-
tents, to detect the visual content difference perceived by
users. Two reasons motivate us to use text contents rather
than image contents. First, text contents provide the most
important information on Web pages, while image contents
often serve as supplements to text contents.
In practice,
users can block the loading of various images and browse
most of the Web page in text mode only. Second, the sim-