over the probabilities of all values in O. Let us write P (o|s) for the
probability of observation o given secrets s. Köpf and Smith [13]
show that the min-entropy channel capacity from S to O is equal
o∈O maxs∈S P (o|s). This capacity is maximized when
P (o|s) = 1 at all o, in which case it is equal to log(n). Therefore
log(n) is a conservative bound on this measure of leakage as well.
to logP
3. Predictions for interactive systems
The system model described in Section 2.2 permits a great deal
of ﬂexibility in constructing predictions. We now begin to explore
the possibilities.
Throughout the rest of the paper we assume that the mitigator
has an internal state, denoted by St. In the simplest schemes, the
state only records the number of epochs N, that is, St = N. But
more complex internal state is possible, as discussed in Section 4.2.
3.1
Inputs, outputs, and idling
For simplicity, we assume that inputs to and outputs from the in-
teractive system correspond one-to-one: each input has one output
and vice versa. If inputs can cause multiple output events, this can
be modeled by introducing a schedule for delivering the multiple
outputs as a batch.
Many services generate output events only as a response to some
external input. In the absence of inputs, such systems are idle and
produce no output. If the predictor cannot take this into account
when generating predictions, the failure to generate output pro-
duces gratuitous mispredictions. With generalized predictive miti-
gation, these mispredictions can be avoided.
For example, consider applying the original predictive mitiga-
tion scheme to a service that reliably generates results in 10ms. If
the service is idle for an hour, the series of ensuing mispredictions
will inﬂate the interval between predicted outputs to more than an
hour, slowing the underlying service by more than ﬁve orders of
magnitude. Clearly this is not acceptable.
Consider inputs arriving at times inp1, inp2, . . . inpn, . . . , where
each inpi is the time of input i. We assume that the mitigator has
some public state St, and that this state always includes the index
of the current mitigation epoch, denoted by N. Let the prediction
for events for state St be described by a function p(St), where p
gives a bound on how long it is expected to take to compute an
answer to a request in state St.
Whenever the structure of the mitigator state is understood, we
use more concrete notation. For example, in the simple mitigator
we have St = N, so we we write p(N ) for p(St). Simple fast
doubling has the prediction function p(N ) = 2N−1. For more
complex predictors, p might depend on other (public) parameters as
well. If SN (0) is the time of the start of the N-th epoch, subsequent
event i in epoch N is predicted to occur at time SN (i):
SN (i) = max(inpi, SN (i − 1)) + p(N )
The two terms in the above expression correspond to the pre-
dicted start of the computation for event i and the predicted amount
of time it takes to compute the output, respectively. To predict the
start of computation for event i, we take the later of two times: the
time input i is available, and the time event i − 1 is delivered.
3.2 Multiple input and output channels
Now let us consider mitigation on multiple channels, where re-
quests on different channels may be handled in parallel.
565There are at least two reasonable concurrency models. The ﬁrst
model assumes that every request type has an associated process
and that processes handling requests of one type do not respond to
requests of other types. The second model assumes a shared pool
of worker processes that can handle requests of any type as they
become available.
In either model, the mitigator is permitted to use some informa-
tion about which channel an input request arrives on and about the
content of the request. This information about the channel and the
request is considered abstractly to be the request type of the re-
quest. There is a ﬁnite set of request types numbered 1, . . . , R.
Requests coming at time inp with request type r are represented
as a pair (inp, r). A request history is a sequence of requests
(inp1, r1) . . . (inpi, ri) . . . , where inpi is the time of request i,
and ri is the type of the request: 1 ≤ ri ≤ R.
The mitigator makes predictions separately for each request type;
however, with multiple request types, an epoch is a period of time
during which predictions are met for all request types. A mispre-
diction for one request type causes an epoch transition for the mit-
igator, and may change predictions for every request type. We de-
note the prediction for computation when mitigator is in state St
on request type r by a function p(St, r). When the state consists
only of the number of epochs (St = N), we simply write p(N, r).
3.2.1
In the case where each request type has its own individual pro-
Individual processes per request type
cess, the prediction for output event i is
SN (i) = max(inpi, SN (j)) + p(N, ri)
where j is the index of the previous request of type ri; that is,
j = max{j0 | j0 < i ∧ ri = rj0}. Hence SN (j) is the prediction
of the previous request of type ri. We deﬁne SN (j) to be zero
when there are no previous requests of the same type.
Example. Consider a simple system with two request types A and
B (for clarity we index request types with letters), and consider a
mitigator with these prediction functions p(N, r) for N = 1:
N p(N, A)
1
10
p(N, B)
100
Assume the following input history: (2, A), (4, B), (6, A), and
(30, B). That is, two inputs of type A arrive at times 2 and 6, and
two of type B arrive at times 4 and 30.
The inputs (2, A) and (4, B) are the ﬁrst requests of the corre-
sponding types. The predictions for these requests are
S1(1) = max(2, 0) + 10 = 12
S1(2) = max(4, 0) + 100 = 104
For the next request of type A, the prediction is
S1(3) = max(6, 12) + 10 = 22
This prediction takes into account the amount of time it would take
for the process for request type A to ﬁnish processing the last input
and then to delay the message for p(1, A). Similarly, the predicted
output time for the fourth request (30, B) is
S1(4) = max(30, 104) + 100 = 204
3.2.2 Shared worker pool
For a shared pool of worker processes, predictions must be de-
rived more carefully. Suppose the system has at least n worker
processes that handle input requests. To compute a prediction for
input request i that arrives at time inpi with type ri, the mitigator
needs to know two terms: when the handling of that request will
start, and an estimate of how long it takes to complete the request.
We assume that the completion estimate is given by p(N, r) and fo-
cus instead on the ﬁrst term. The main challenge is to predict when
a worker will be available to process a request. For this we intro-
duce a notion of worker predictions. Intuitively, worker predictions
are a data structure internal to the mitigator that allows it to predict
when different requests will be picked up by worker processes.
Concretely, worker predictions are n sets W1, . . . , Wn in which
every Wm contains pairs of the form (i, q). When (i, q) ∈ Wm, it
means request i is predicted to be delivered at time q by worker m.
Therefore, a given index i appears in at most one of the sets Wm.
The function avail(W ) predicts when a worker described by set W
will be available, by choosing the time when the worker should
deliver its last message.
max{q | (i, q) ∈ W}
0
if W 6= ∅
otherwise
(
avail(W ) ,
In the initial state of worker predictions, all sets
We describe next the algorithm for computing worker predictions.
Initialization.
Wm (for 1 ≤ m ≤ n) are empty.
Prediction. Given an event i with input time inpi and request
type ri, the prediction SN (i) is computed as follows:
Therefore, we ﬁnd j such that avail(Wj) = min1≤m≤n{avail(Wm)}
1. The earliest available worker j is predicted to handle request i.
2. Since worker j is assumed to handle request i, we make the
following prediction q for the i-th output:
q = max(inpi, avail(Wj)) + p(N, ri)
The prediction for SN is SN (i) = q.
3. Finally, worker predictions are updated with prediction (i, q):
Wj := Wj ∪ {(i, q)}
Misprediction. When a misprediction occurs, the mitigator re-
sets the state of worker predictions. Consider a misprediction at
time τN , which deﬁnes the start time of epoch N. We reset the
state of worker predictions as follows:
1. For every worker m, we ﬁnd the earliest undelivered request
i0; that is, request received before the misprediction but not deliv-
ered by the mitigator at τN :
0
i
= min{i | (i, q) ∈ Wm ∧ inpi < τN ≤ q}
2. If such i0 cannot be found, that is, the set in the previous equa-
tion is empty, we set Wm to ∅. Otherwise, we let q0 = τN +
p(N, ri0 ) and set Wm = {(i0, q0)}.
3. Note that the above step resets the state of each Wm in the
worker predictions. Using these reinitialized states, we can com-
pute predictions for the unhandled requests, i.e., all requests j with
predicted time q such that q ≥ τN according to the steps 1) and 2)
described in Prediction.
An example using shared worker pool is presented in the Ap-
pendix.
4. Leakage analysis
As in [14], we can use a combinatorial analysis to bound how
much information leaks via predictive mitigation in interactive sys-
tems. One difference is that we take into account the interactive na-
ture of our model and derive bounds based on the number of input
requests and the elapsed time. To conservatively estimate leakage
we bound the number of possible timing variations that an adver-
sary can observe, as a function of the running time T and the length
566of the input history M. Per Section 2.3, the leakage is at most the
log of the number of possible observations.
We show that a leakage bound of O(log T × log M ) can be at-
tained, with a constant factor that depends on the choice of penalty
policy. When there is a worst-case execution time for every request,
a tighter bound of O(log M ) can be derived.
4.1 Bounding the number of variations
To bound the number of possible timing variations, we need to
know three values: (1) the number of timing variations within each
epoch, (2) the number of variations introduced by the schedule se-
lector, and (3) the number of epochs.
Let us consider the number of variations within each epoch. Be-
cause messages within a single epoch are delivered according to
predictions, the only source of variations within an individual epoch
is whether there is a misprediction, and if so, when the mispredic-
tion occurs. This can be speciﬁed by the length of the epoch. When
the mitigator has received at most M messages, the length of any
single epoch can be at most M + 1.
When the mitigator transitions from epoch n to epoch n + 1, it
chooses the schedule for the next epoch. Since the predictor can
rely on public information, the “schedule” is actually an algorithm
parameterized by public inputs. However, this algorithm may be
chosen based on non-public inputs, in which case the choice of
schedule may convey additional information to the adversary. Fol-
lowing [14], we denote by ΛN the number of possible schedules
when transitioning between epochs n and n + 1.
Its value de-
pends on the details of the schedule selector. For simple mitigation
schemes, where the choice of the next schedule does not depend on
secrets, we have ΛN = 1. For adaptive mitigation [14], where the
choice of schedule depends on internal state such as the size of the
mitigator’s message buffer, ΛN may be greater than one.
Consider a mitigator that at time T has received at most M re-
quests and reached at most N epochs. The number of possible
timing variations of such a mitigator is at most
(M + 1)N · Λ1 . . . ΛN
Measured in bits, the corresponding bound on leakage is the loga-
rithm of the number of variations:
N · log(M + 1) +
log Λi
NX
i=1
NX
havePN
i=1 log Λi = 0.
Note that for the simple doubling scheme, because Λi = 1, we also
We can enforce an arbitrary enforcing bound on leakage. Denote
by B(T, M ) the amount of information permitted to be leaked by
the mitigator. Enforcing bound B(T, M ) is satisﬁed if the mitiga-
tor ensures this inequality holds:
N · log(M + 1) +
log Λi ≤ B(T, M )
i=1
This equation requires a relationship between the number of epochs,
the elapsed time, and the number of received messages. The exact
nature of this relationship is determined by penalty policies.
4.2 Penalty policies
Recall that the function p(St, r) predicts a bound on computa-
tion time for request type r in state St. The intuition is that the
more mispredictions have happened in the past (as recorded in St),
the larger is the value of p(St, r). The computation is penalized by
delivering its response later.
Designing a penalty policy function opens up a space of possibil-
ities. The question is how mispredictions on different request types
are interconnected—for example, whether a particular request type
should be penalized for mispredictions on other request types, and
if so, then how much.
On one side of the spectrum, we can use a global penalty pol-
icy that penalizes all request types when a misprediction occurs. If
all request types are penalized, it becomes harder to trigger mis-
predictions on any of them in future. Therefore, this policy pro-
vides a tight bound on N. Intuitively, an adversary gains no ad-
ditional power to leak information by switching between request
types. However, performance of all request types is hurt by mis-
predictions on any request type.
On the other end of the spectrum is a local penalty policy in
which request types are not penalized by mispredictions on other
types. This improves performance but offers weaker bounds on
leakage. To see this, assume that the number of mispredictions a
single request type can make is N. Since penalties are not shared
between request types, with R types, as many as R × N mispre-
dictions can occur. Timing leakage might be high if R is large; in-
tuitively, the adversary can attack each request type independently.
Aiming for more control of the tradeoff between security and
performance, we explore penalty policies that ﬁll in the space be-
tween the global and local penalty policies. The key insight is that
the request types with few mispredictions contribute little to total
leakage, so they should share little penalty. This insight brings an
l-level grace period policy. In a l-level grace period policy, request
type r is only penalized by other types when the number mispre-
dictions on r is greater than l.
For more complex penalty policies, leakage analysis becomes
more challenging. In Section 4.4, we present an efﬁcient and pre-
cise way of bounding N for some penalty policies.