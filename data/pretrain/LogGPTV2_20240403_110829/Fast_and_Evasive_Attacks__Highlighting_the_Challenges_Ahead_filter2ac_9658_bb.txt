Section 6. Conclusions and some open research issues are discussed in Section 7.
2 Model and Terminology
This section presents our risk-assessment model and discusses some aspects of
parameter estimation and learning.
2.1 Security State Estimation
The use of Hidden-Markov Models (HMMs) as a method for estimating the risk
of a network was proposed in [1]. An HMM enables the estimation of a hidden
state based on observations that are not necessarily accurate. An important
feature of this model is that it is able to model the probability of false positives
and false negatives associated with the observations. The method is based on
Rabiner’s work on HMMs [13].
Assume that each host h can be modeled by N diﬀerent states, i.e., S =
{s1, . . . , sN}. The security state of a host changes over time, and the sequence
of states visited by a host is denoted X = x1, . . . , xT , where xt ∈ S. Each host
is monitored by a number of sensors k ∈ K h
L, where L is the number of
sensors for host h. A sensor generates observation messages from the observation
symbol set V k = {vk
}, where M is the number of messages for sensor
k. The sequence of observed messages is denoted Y = y1, . . . , yT , where yt ∈ V
is the observation message received at time t. The HMM for each host consists
of a state transition probability matrix P, an observation probability matrix Q,
and an initial state distribution π. The HMM is denoted λ = (P, Q, π).
1 , . . . , K h
1 , . . . , vk
M
Using Hidden Markov Models to Evaluate the Risks of Intrusions
147
The hosts modeled in this paper are assumed to have four possible security
states S = {G, P, A, C}, which are deﬁned as follows:
– Good (G): The host is not subject to any attacks.
– Probed (P): The host is subject to probing or mapping activity. This state
can lead to a reduction in availability, and it increases the probability of an
attack.
– Attacked (A): The host is being attacked by one or more parties. This state
can lead to a reduction in availability, and it increases the probability of a
compromise.
– Compromised (C): The host has been compromised. This state may result
in loss of conﬁdentiality, integrity, and availability.
Figure 1 shows the Markov model for the security states of the hosts. The
edge from one node to another represents the fact that when a host is in the
state indicated by the source node it can transition to the state indicated by the
destination node. Note that the graph is fully connected, which indicates that it
is possible to transition from any security state to any other security state.
The state transition probability matrix P describes the probabilities of transi-
tions between the states of the model. Each entry, pij, describes the probability
that the model will transfer to state sj at time t + 1 given that it is in state si
at time t, i.e., pij = P (xt+1 = sj|xt = si), 1 ≤ i, j ≤ N.
The observation probability matrix Q describes the probabilities of receiving
diﬀerent observations given that the host is in a certain state. Each entry, qn(m),
represents the probability of receiving the observation symbol vk
m at time t, given
|xt = sn), 1 ≤ n ≤
that the host is in state sn at time t, i.e., qn(m) = P (yk
N, 1 ≤ k ≤ K, 1 ≤ m ≤ M.
t = vk
m
G
P
A
C
Fig. 1. Markov model for hosts
Consider examples of a university network and a military network to see how
values are assigned to the model parameters.
Example 1. In a university network, we can assume that there are high volumes
of probing and a fair amount of attack attempts. The security level for hosts is
also varying, and a system compromise is a likely scenario for some hosts. Con-
sequently, the transitions to state P , A, and C are relatively likely. In addition,
because the traﬃc in university networks is heterogeneous and changing over
time, we assume that it is hard to conﬁgure and maintain accurate IDS sen-
sors. Therefore, we have to assume that there is a high number of false positives
148
A. ˚Arnes et al.
and negatives. This is modeled by increasing the probabilities of receiving an
observation that indicates a false positive or a false negative and decreasing the
probability of receiving an accurate observation in the matrix Q. For example,
qG(4), which represents the probability of receiving an observation indicating
a compromised alert when the system is actually in the good state, has to be
increased to represent the false positive probability. P and Q can for example
be set as follows:
⎛
⎞
⎜⎜⎝pGG pGP pGA pGC
⎟⎟⎠ =
⎛
⎜⎜⎝qG(1) qG(2) qG(3) qG(4)
pP G pP P pP A pP C
pAG pAP pAA pAC
pCG pCP pCA pCC
qP (1) qP (2) qP (3) qP (4)
qA(1) qA(2) qA(3) qA(4)
qC(1) qC(2) qC(3) qC(4)
⎛
⎞
⎜⎜⎝0.95 0.02 0.02 0.01
⎟⎟⎠ ,
⎛
⎞
⎞
⎜⎜⎝0.7 0.1 0.1 0.1
⎟⎟⎠ =
⎟⎟⎠ .
0.02 0.95 0.02 0.01
0.02 0.02 0.94 0.02
0.01 0.01 0.01 0.97
0.1 0.7 0.1 0.1
0.1 0.1 0.7 0.1
0.1 0.1 0.1 0.7
P =
Q =
In this simple example, the values in the bottom left corner of the Q matrix
represent false negatives, whereas the values in the top right represent false
positives. The diagonal represents the probability of accurate detections. Also,
in such a network, the initial state distribution π has to take into consideration
the probability that a system is already under attack or even compromised:
π = {0.65, 0.2, 0.1, 0.05}.
Example 2. In a military grade system, we can assume that the security level
is very high, and the probability of attacks is low, as the system is not known
to the public. This implies that the probability of transition to P and A should
be low, but P should still take into account the possibility of random scanning.
Due to the high level of security, the probabilities of transition to state C should
be extremely low. The observation probabilities should represent the fact that
the traﬃc is regulated, and that the IDSs and logging systems are conﬁgured to
be highly accurate. The initial state can be assumed to be π = {1, 0, 0, 0}. The
following are example transition and observation probability matrices:
⎛
⎜⎝0.995 0.002 0.002 0.001
0.02 0.959 0.02 0.001
0.02 0.02 0.958 0.002
0.01 0.01 0.01 0.97
⎞
⎟⎠ , Q =
⎛
⎜⎝0.97 0.01 0.01 0.01
0.01 0.97 0.01 0.01
0.01 0.01 0.97 0.01
0.01 0.01 0.01 0.97
⎞
⎟⎠ .
P =
2.2 Risk Assessment
Each of the states for a host is associated with a cost vector C, indicating the
potential consequences of the state in question. The total risk Rh,t for host h at
time t is
N(cid:2)
Rh,t =
γt(i)C(i)
(1)
where γt(i) is the probability that the host is in security state si at time t, N is
the number of security states, and C(i) is the cost value associated with state si.
i=1
Using Hidden Markov Models to Evaluate the Risks of Intrusions
149
Example 3. A university network usually consists of a large number of hosts,
including student laptops, workstations, web servers, student record databases,
and staﬀ ﬁle servers. For the purpose of network management, the servers are
the most valuable assets, and a compromise of staﬀ data or student records
could have very negative consequences. Example cost vectors could be: Claptop =
{0, 1, 2, 5}, Cworkstation = {0, 2, 5, 10}, Cwebserver = {0, 2, 5, 20}, CstudentDB =
{0, 5, 20, 50}, and Cf ileserver = {0, 5, 10, 25}. If the current security state distri-
bution for the student record database is {0.8, 0.15, 0.05, 0}, then the risk for
that asset at time t is RstudentDB,t = 0.8 ∗ 0 + 0.15 ∗ 5 + 0.05 ∗ 20 = 1.75. The
same security state distribution for a student laptop would result in the risk
Rlaptop,t = 0.25.
The total risk for an entire network at time t can be expressed as
H(cid:2)
Rnw,t =
Rh,t
(2)
h=1
where H is the number of hosts in the network. By using the sum of the risk
of all hosts, it is possible to see aggregate peaks of risk activity where the risk
of several hosts are simultaneously increased. A property of this deﬁnition of
network risk is that security incidents that only involve a few hosts may not
impact the total risk of a large network to a noticeable degree. Also, the risk can
only be interpreted by using knowledge of the normal risk level of the system,
as well as the maximum risk of the system. A limitation of this deﬁnition of
network risk is that it does not consider dependencies between hosts. This is not
covered in this paper, but left for further work.
The average risk for a network can be expressed as
Rnw,t =
Rnw,t
H
.
(3)
As opposed to (2), the average risk for a network is a normalized value for a given
network. If a high percentage of the hosts in a network are subject to security
incidents, the average risk for the network can be expected to vary signiﬁcantly
over time. Note that Rnw,t is system-dependent, as the HMMs and cost vectors
of diﬀerent hosts vary.
In a traditional risk assessment context, one would expect risk to stay at the
most critical security state once that state has been reached. This paper focuses
on real-time risk assessment, and the model proposed in this paper is intended
to be used as a real-time tool for risk management. That is, we are interested in
representing the level of risk activity; therefore, the HMMs used in the examples
allow the risk to gradually decrease, even if the host in question has been assessed
to be in state C. The arrival of new alerts indicating a less critical state also
decreases the risk of a host. This is done in order to avoid a situation where
an increasing number of hosts are assessed to have the maximum risk possible.
Another possible approach is outlined in Section 5.
150
A. ˚Arnes et al.
2.3 Alert Prioritization
Each processed alert is assigned a priority according to the risk of the involved
hosts. If a host is assessed to have a high risk, all alerts involving that host will
receive a high priority, whereas a low risk host will receive a low priority. The
alert receives a prioritization number according to the host with the highest risk
number. The priority Pa for an alert a at time t can be determined as follows
(4)
where h1 is the source IP address and h2 is the destination IP address of the
alert a.
Example 4. In a network with both high and low value hosts, the priority of an
alert is decided by the current risk of the aﬀected host, which is in turn a function
of the cost vector and the estimated security state. An alert a1 at time t for the
student database in Example 3 would receive a priority Pa1 = 1.75, whereas an
alert a2 for the student laptop would receive priority Pa2 = 0.25. If both the
source and destination address of an alert are monitored by the risk assessment
system, the priority is assigned to be the higher of the two risk values.
Pa = max(Rh1,t, Rh2,t),
2.4 Parameter Estimation and Learning
The estimation of the appropriate values for the model parameters P, Q, π, and
for the cost vector C can be determined using either training algorithms or ex-
pert knowledge, supported by an appropriate methodology. Notably, a uniform
initial distribution of the P and π parameters is adequate as a basis for train-
ing the parameters, according to [13]. The initial parameters can alternatively
be determined using a risk assessment methodology, such as [2]. These method-
ologies provide a framework for identifying threats and vulnerabilities and for
determining probabilities and consequences of risks.
Based on an HMM with initial parameters, there are several algorithms avail-
able for re-estimating the parameters (i.e., training the models). There is, how-
ever, no analytical solution to the re-estimation problem, and there is no optimal
way of estimating the model parameters based on an observation sequence as
training data [13]. A standard approach for learning HMM parameters is the
Baum-Welch method, which uses iteration to select HMM parameters to maxi-
mize the probability of an observation sequence.
3 System Architecture and Implementation
This section discusses the architecture of the real-time risk assessment system
and how it is integrated into the STAT framework. Some implementation details
are also presented.
3.1 System Architecture
The risk-assessment system receives input events from multiple intrusion detec-
tion sensors throughout the protected network. Both host-based and network-
based sensors are supported. The alerts generated by the sensors are either in
Using Hidden Markov Models to Evaluate the Risks of Intrusions
151
the IDMEF format [3] or in a format native to the sensor. Native alert formats
are converted into IDMEF alerts before further processing. Intrusion detection
alerts from the sensors are collected by the MetaSTAT collector [17,18] through
network connections. MetaSTAT then merges the diﬀerent alert streams and the
aggregate stream is fed to the risk-assessment system.
The output of the system is a stream of prioritized alerts. The main advantage
of this system is that the security administrator can easily identify the most
important alerts by sorting them by the prioritization value. By handling the
important alerts ﬁrst, the administrator can make more eﬃcient use of his time.
The system is implemented as a set of modules in the STAT framework [17,18].
Figure 2 is an overview of the architecture. The system consists of three diﬀerent
modules: Alert Classiﬁcation, Spoof Detection, and Risk Analysis. The operation
of each of the modules is explained in detail below.
Fig. 2. Overview of the System Architecture
The classiﬁcation module augments the incoming alerts with a classiﬁcation
attribute. The classiﬁcation assigned to a given alert is dependent on the im-
pact that the attack referenced in the alert has on the network. The system
utilizes the following classes of attacks: successful recon limited, successful user,
and successful admin.
The IDMEF standard speciﬁes an optional classiﬁcation attribute, and the
classiﬁcation module uses this attribute if it is set by the intrusion detection
sensor. Unfortunately, most sensors do not provide a value for the classiﬁcation
attribute. When the classiﬁcation module encounters alerts with no classiﬁca-
tion, the missing attribute is looked up in a database. The database contains
a mapping from sensor-type/alert-name tuples to the corresponding class. The
mapping database can be created manually by looking at the rules of the de-
ployed intrusion detection sensors and classifying each rule as either referring
to a successful recon limited, successful user, or successful admin attack. The
database can also be created automatically if the rules of the intrusion detection
sensors contain a CVE id, which is often the case. The CVE database can be
queried for the description of the attack and the classiﬁcation can be ﬁlled in
from the description.
A problem that may occur is that some alerts do not contain the real IP of the
host that caused the IDS alert to be generated. This happens when the attacker
152
A. ˚Arnes et al.
host spoofs the source IP of the packets that are part of the attack. A network
IDS monitoring the attack traﬃc sees the attack coming from the spoofed IP
and reports the spoofed IP as the attacker. The spoof detection module detects
spoofed alerts and attempts to infer the real IP of the attacker.
Spoof detection can be performed by keeping track of what IP addresses each
host is utilizing. An anti-spooﬁng tool, such as arpwatch, can be utilized to
create a database of what IPs are associated with each Ethernet address. When
the spoof detection module of the risk assessment system receives an alert, the
database is consulted to check if the attacker IP contained in the alert matches
the Ethernet address in the alert. Some of the problems with this approach are
that most intrusion detection alerts do not contain Ethernet addresses and that
packets with spoofed Ethernet addresses would not be detected. Another way of
performing spoof detection is to check whether the IPs referenced in the alert
are part of the protected network. If neither the attacker nor the victim is part of
the protected network, the attack must either be spoofed or an outside attacker
is attacking another outsider using the protected network. Since most networks