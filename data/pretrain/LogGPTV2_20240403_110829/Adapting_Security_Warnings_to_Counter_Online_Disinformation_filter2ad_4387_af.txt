conveying risk of harm. Future work on the role of friction in disinformation
warnings could also shed light on this issue.
harm—may be the predominant cause of warning behavioral
effects. We did not test friction as a mechanism of effect in our
crowdworker study, and our results do not conclusively rule
out the mechanisms of effect we did examine. But our results
are strongly suggestive, and friction merits further study.
Future work could also evaluate other types of interstitial
warnings and interstitial warnings in other contexts, especially
social media. Platforms are already deploying warning popups
that a user must dismiss, as well as warning overlays that
obscure content until the user clicks [111, 112].
Another promising direction is evaluating how interstitial
warnings interact with factors known to impact warning adher-
ence and receptivity to disinformation. These factors include
repetition of warnings [10, 15, 18, 20, 103], user age and
digital literacy [113, 114], user tendency toward cognitive
reﬂection [110, 115, 116], repeated exposure to inaccurate
information [19, 83], and whether that information aligns with
user political preferences [114, 117, 118].
A ﬁnal direction for future study is exploring possible unin-
tended consequences of interstitial disinformation warnings.
These warnings could create an implied truth effect [87], gen-
erally undermine trust in online content [83]), cause concern
about the warning provider, or lead to warning fatigue [20].
5.2
Informing Platform Disinformation Warnings
Interstitial warnings can be effective tools for countering
disinformation. Compared to contextual warnings, interstitial
designs are much more noticeable for users and much more
capable of informing users about disinformation. Platforms
that use contextual warnings for disinformation should be
aware that their warnings may have minimal effects.
Going forward, platforms should follow evidence-based ap-
proaches for developing and deploying disinformation warn-
ings. By conducting internal evaluations, collaborating with
independent researchers, and releasing data, platforms can
signiﬁcantly advance their ability to counter disinformation
with warnings—just like software vendors have done for over
a decade to advance security warnings [10, 13–15, 17, 19].
Acknowledgments
We thank Marshini Chetty and Elissa Redmiles for valuable
early feedback on this work. Simone Fischer-Hübner provided
thoughtful shepherding for our paper.
i1i2i3i4h1h2h3h4Warning Design−2−1012InformativenessScoreLiberalsi1i2i3i4h1h2h3h4Warning Design−2−1012InformativenessScoreConservativesi1i2i3i4h1h2h3h4Warning Design−2−1012HarmScoreLiberalsi1i2i3i4h1h2h3h4Warning Design−2−1012HarmScoreConservativesReferences
[1]
Samantha Bradshaw and Philip N. Howard. The Global Disinfor-
mation Order: 2019 Global Inventory of Organised Social Media
Manipulation. Tech. rep. University of Oxford, Sept. 26, 2018. URL:
https://comprop.oii.ox.ac.uk/wp- content/uploads/
sites/93/2019/09/CyberTroop-Report19.pdf.
[2] Diego A. Martin, Jacob N. Shapiro, and Michelle Nedashkovskaya.
“Recent Trends in Online Foreign Inﬂuence Efforts”. In: Journal
of Information Warfare (JIW) 18 (3 2019). URL: https://esoc.
princeton.edu/publications/trends-online-influence-
efforts.
[3] Adam Mosseri. Addressing Hoaxes and Fake News. Facebook
Newsroom. Dec. 15, 2016. URL: https://about.fb.com/news/
2016/12/news- feed- fyi- addressing- hoaxes- and- fake-
news/ (visited on 06/03/2020).
Justin Kosslyn and Cong Yu. Fact Check Now Available in Google
Search and News Around the World. Google Ofﬁcial Blog. July
2017. URL: https://www.blog.google/products/search/
fact- check- now- available- google- search- and- news-
around-world/ (visited on 03/05/2020).
[4]
[5] Microsoft Bing. Bing Adds Fact Check Label in SERP to Sup-
port the ClaimReview Markup. Bing Blogs. Sept. 14, 2017. URL:
https://www.blog.google/products/search/fact-check-
now-available-google-search-and-news-around-world/
(visited on 03/05/2020).
[6] Davey Alba and Kate Conger. Twitter Moves to Target Fake
Videos and Photos. New York Times. Feb. 2020. URL: https :
/ / www . nytimes . com / 2020 / 02 / 04 / technology / twitter -
fake - videos - photos - disinformation . html (visited on
04/18/2020).
Taylor Hatmaker. Twitter Adds a Warning Label Fact-Checking
Trump’s False Voting Claims. TechCrunch. May 26, 2020. URL:
https : / / techcrunch . com / 2020 / 05 / 26 / twitter - trump -
labels-fact-checking-tweet/ (visited on 06/03/2020).
[7]
[8] Min Wu, Robert C Miller, and Simson L Garﬁnkel. “Do Security
Toolbars Actually Prevent Phishing Attacks?” In: Proceedings of
the 2006 ACM SIGCHI Conference on Human Factors in Comput-
ing Systems (CHI). Apr. 2006. DOI: 10.1145/1124772.1124863.
Serge Egelman, Lorrie Faith Cranor, and Jason Hong. “You’ve
Been Warned: An Empirical Study of the Effectiveness of Web
Browser Phishing Warnings”. In: Proceedings of the 2008 ACM
SIGCHI Conference on Human Factors in Computing Systems
(CHI). Apr. 2008. DOI: 10.1145/1357054.1357219.
[9]
[10] Devdatta Akhawe and Adrienne Porter Felt. “Alice in Warningland:
A Large-Scale Field Study of Browser Security Warning Effective-
ness”. In: Proceedings of the 22nd USENIX Security Symposium
(USENIX Security). Aug. 2013. URL: https://dl.acm.org/
doi/10.5555/2534766.2534789.
Joshua Sunshine et al. “Crying Wolf: An Empirical Study of SSL
Warning Effectiveness”. In: Proceedings of the 18th USENIX Se-
curity Symposium (USENIX Security). Aug. 2009. URL: https:
//dl.acm.org/doi/abs/10.5555/1855768.1855793.
[11]
[12] Marian Harbach et al. “Sorry, I Don’t Get It: An Analysis of Warn-
ing Message Texts”. In: Proceedings of the 17th International
Conference on Financial Cryptography and Data Security (FC).
Vol. 7859. Lecture Notes in Computer Science (LNCS). Apr. 2013.
DOI: 10.1007/978-3-642-41320-9_7.
[13] Adrienne Porter Felt et al. “Experimenting at Scale with Google
Chrome’s SSL Warning”. In: Proceedings of the 2014 ACM
SIGCHI Conference on Human Factors in Computing Systems
(CHI). Apr. 2014. DOI: 10.1145/2556288.2557292.
[14] Adrienne Porter Felt et al. “Improving SSL Warnings: Comprehen-
sion and Adherence”. In: Proceedings of the 2015 ACM SIGCHI
Conference on Human Factors in Computing Systems (CHI). Apr.
2015. DOI: 10.1145/2702123.2702442.
Joel Weinberger and Adrienne Porter Felt. “A Week to Remember:
The Impact of Browser Warning Storage Policies”. In: Proceedings
of the 12th Symposium On Usable Privacy and Security (SOUPS).
June 2016. URL: https://dl.acm.org/doi/abs/10.5555/
3235895.3235898.
[15]
[16] Malkin, Nathan and Mathur, Arunesh and Harbach, Marian and
Egelman, Serge. “Personalized Security Messaging: Nudges for
Compliance with Browser Warnings”. In: Proceedings of the Eu-
roUSEC 2017 – The 2nd European Workshop on Usable Security.
Apr. 2017. DOI: 10.14722/eurousec.2017.23008.
[17] Robert W. Reeder et al. “An Experience Sampling Study of User
Reactions to Browser Warnings in the Field”. In: Proceedings of the
2018 ACM SIGCHI Conference on Human Factors in Computing
Systems (CHI). Apr. 2018. DOI: 10.1145/3173574.3174086.
Serge Egelman and Stuart E. Schechter. “The Importance of Being
Earnest (in Security Warnings)”. In: Proceedings of the 17th Inter-
national Conference on Financial Cryptography and Data Security
(FC). Vol. 7859. Lecture Notes in Computer Science (LNCS). Apr.
2013. DOI: 10.1007/978-3-642-39884-1_5.
[18]
[19] Hazim Almuhimedi et al. “Your Reputation Precedes You: History,
Reputation, and the Chrome Malware Warning”. In: Proceedings
of the 10th Symposium On Usable Privacy and Security (SOUPS).
June 2014. URL: https://dl.acm.org/doi/10.5555/3235838.
3235848.
[20] Cristian Bravo-Lillo et al. “Harder to Ignore? Revisiting Pop-Up
Fatigue and Approaches to Prevent It ”. In: Proceedings of the 10th
Symposium On Usable Privacy and Security (SOUPS). June 2014.
URL: https : / / dl . acm . org / doi / abs / 10 . 5555 / 3235838 .
3235847.
[21] Mustafa Emre Acer et al. “Where the Wild Warnings Are: Root
Causes of Chrome HTTPS Certiﬁcate Errors”. In: Proceedings
of the 24th ACM SIGSAC Conference on Computer and Commu-
nications Security (CCS). Oct. 2017. DOI: 10.1145/3133956.
3134007.
[22] Michela Del Vicaro et al. “The Spreading of Misinformation On-
line”. In: Proceedings of the National Academy of Sciences (PNAS)
113 (3 Jan. 2016). DOI: 10.1073/pnas.1517441113.
[23] Hunt Allcott and Matthew Gentzkow. “Social Media and Fake
News in the 2016 Election”. In: Journal of Economic Perspectives
(JEP) 31.2 (2017). DOI: 10.1257/jep.31.2.211.
[24] Hunt Allcott, Matthew Gentzkow, and Chuan Yu. “Trends in the
Diffusion of Misinformation on Social Media”. In: Research and
Politics 6 (2 2019). DOI: 10.1177/2053168019848554.
Peter Burger et al. “The Reach of Commercially Motivated Junk
News on Facebook”. In: PLoS One 14 (8 Aug. 2019). DOI: 10.
1371/journal.pone.0220446.
[25]
[26] Andrew M. Guess, Brendan Nyhan, and Jason Reiﬂer. “Exposure
to Untrustworthy Websites in the 2016 US Election”. In: Nature
Human Behavior (Mar. 2020). DOI: 10.1038/s41562-020-0833-
x.
[27] Arkaitz Zubiaga et al. “Analysing How People Orient to and Spread
Rumours in Social Media by Looking at Conversational Threads”.
In: PLoS One 11 (3 Mar. 2016). DOI: 10.1371/journal.pone.
0150989.
Philip N. Howard et al. Social Media, News and Political Informa-
tion During the US Election: Was Polarizing Content Concentrated
in Swing States? 2018. arXiv: 1802.03573 [cs.SI].
[28]
[30]
[29] Chengcheng Shao et al. “The Spread of Low-Credibility Content
by Social Bots”. In: Nature Communications (Nov. 2018). DOI:
10.1038/s41467-018-06930-7.
Soroush Vosoughi, Deb Roy, and Sinan Aral. “The Spread of True
and False News Online”. In: Science 359.6380 (Mar. 9, 2018). DOI:
10.1126/science.aap9559.
Srijan Kumar, Robert West, and Jure Leskovec. “Disinformation
on the Web: Impact, Characteristics, and Detection of Wikipedia
Hoaxes”. In: Proceedings of the 25th World Wide Web Conference
(WWW). Apr. 2016. DOI: 10.1145/2872427.2883085.
[31]
[32] Daniel Bush and Alex Zaheer. Bing’s Top Search Results Con-
tain an Alarming Amount of Disinformation. Stanford Internet
Observatory Blog. Dec. 27, 2019. URL: https://cyber.fsi.
stanford.edu/io/news/bing-search-disinformation (vis-
ited on 05/15/2020).
[33] Adam Fourney et al. “Geographic and Temporal Trends in Fake
News Consumption During the 2016 US Presidential Election”.
In: Proceedings of the 26th ACM International Conference on
Information and Knowledge Management (CIKM). Nov. 2017.
DOI: 10.1145/3132847.3133147.
[34] Chengcheng Shao et al. “Anatomy of an Online Misinformation
Network”. In: PLoS One 13 (4 Apr. 2018). DOI: 10 . 1371 /
journal.pone.0196087.
[35] Adam Badawy, Kristina Lerman, and Emilio Ferrara. “Who Falls
for Online Political Manipulation?” In: Companion Proceedings of
the The Web Conference (WWW) 2019. May 2019. DOI: 10.1145/
3308560.3316494.
[36] Alexandre Bovet and Hernán A. Makse. “Inﬂuence of Fake News in
Twitter During the 2016 US Presidential Election”. In: Nature Com-
munications (Jan. 2019). DOI: 10.1038/s41467-018-07761-2.
[37] Nir Grinberg et al. “Fake News on Twitter During the 2016 U.S.
Presidential Election”. In: Science 363.6425 (Jan. 25, 2019). DOI:
10.1126/science.aau2706.
Emilio Ferrara. “Disinformation and Social Bot Operations in the
Run Up to the 2017 French Presidential Election”. In: First Monday
22 (8 Aug. 2017). DOI: 10.2139/ssrn.2995809.
[38]
[39] Michele Cantarella, Nicolò Fraccaroli, and Roberto Volpe. Does
Fake News Affect Voting Behaviour? Tech. rep. DEMB Working
Paper Series n.146, June 12, 2019. URL: https://papers.ssrn.
com/sol3/papers.cfm?abstract_id=3402913.
[40] Kate Starbird et al. “Ecosystem or Echo-System? Exploring
Content Sharing Across Alternative Media Domains”. In: AAAI-
ICWSM2018. URL: https://www.aaai.org/ocs/index.php/
ICWSM/ICWSM18/paper/view/17836.
[41] Andreas Vlachos and Sebastian Riedel. “Identiﬁcation and Ver-
iﬁcation of Simple Claims about Statistical Properties”. In: Pro-
ceedings of the 2015 Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP). Sept. 2015. URL: https:
//www.aclweb.org/anthology/D15-1312.pdf.
James Thorne and Andreas Vlachos. “An Extensible Framework
for Veriﬁcation of Numerical Claims”. In: Proceedings of the Soft-
ware Demonstrations of the 15th Annual Meeting of the Associa-
tion for Computational Linguistics (ACL). Apr. 2017. URL: https:
//www.aclweb.org/anthology/E17-3010.pdf.
[42]
[43] Naeemul Hassan et al. “Toward Automated Fact-Checking: De-
tecting Check-worthy Factual Claims by ClaimBuster”. In: Pro-
ceedings of the 23rd ACM SIGKDD International Conference on
Knowledge Discovery in Data Mining (KDD). July 2017. DOI:
10.1145/3097983.3098131.
[44]
[45]
James Thorne and Andreas Vlachos. “Automated Fact Checking:
Task Formulations, Methods and Future Directions”. In: Proceed-
ings of the 27th International Conference on Computational Lin-
guistics (COLING). Aug. 2018. URL: https : / / www . aclweb .
org/anthology/C18-1283.
James Thorne et al. “FEVER: A Large-Scale Dataset for Fact Ex-
traction and VERiﬁcation”. In: Proceedings of the 2018 Conference
of the North American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies (NAACL HLT).
(Long paper). June 2018. DOI: 10.18653/v1/N18-1074.
[46] Hannah Rashkin et al. “Truth of Varying Shades: Analyzing Lan-
guage in Fake News and Political Fact-Checking”. In: Proceedings
of the 2017 Conference on Empirical Methods in Natural Language
Processing (EMNLP). Sept. 2017. DOI: 10.18653/v1/D17-1317.
[47] Martin Potthast et al. “A Stylometric Inquiry into Hyperpartisan
and Fake News”. In: Proceedings of the 56th Annual Meeting of the
Association for Computational Linguistics (ACL). (Long paper).
July 2016. DOI: 10.18653/v1/P18-1022.
[48] Benjamin D. Horne and Siebl Adali. “This Just In: Fake News
Packs a Lot in Title, Uses Simpler, Repetitive Content in Text
Body, More Similar to Satire than Real News”. In: Proceedings of
the 11th International Conference on Weblogs and Social Media
(ICWSM). May 2017. URL: https://aaai.org/ocs/index.
php/ICWSM/ICWSM17/paper/view/15772.
[49] Austin Hounsel et al. “Identifying Disinformation Websites Using
Infrastructure Features”. In: 10th USENIX Workshop on Free and
Open Communications on the Internet (FOCI). Aug. 11, 2020.
URL: https : / / www . usenix . org / conference / foci20 /
presentation/hounsel.
Fan Yang et al. “Automatic Detection of Rumor on Sina Weibo”. In:
Proceedings of the 2012 ACM Workshop on Automated Decision
Making for Active Cyber Defense (SafeConﬁg). Aug. 2012. DOI:
10.1145/2350190.2350203.
[50]
[52]
[51] Ke Wu, Song Yang, and Kenny Q Zhu. “False Rumors Detection
on Sina Weibo by Propagation Structures”. In: Proceedings of the
31st International Conference on Data Engineering (ICDE). Apr.
2015. DOI: 10.1109/ICDE.2015.7113322.
Zhe Zhao, Paul Resnick, and Qiaozhu Mei. “Enquiring Minds:
Early Detection of Rumors in Social Media from Enquiry Posts”.
In: Proceedings of the 24th World Wide Web Conference (WWW).
May 2015. DOI: 10.1145/2736277.2741637.
Jing Ma, Wei Gao, and Kam-Fai Wong. “Detect Rumors in Mi-
croblog Posts Using Propagation Structure via Kernel Learning”.
In: Proceedings of the 55th Annual Meeting of the Association for
Computational Linguistics (ACL). (Long paper). Aug. 2017. DOI:
10.18653/v1/P17-1066.
[53]