0.07. Our set of benign audio samples consisted of 534 benign
audio samples. The audio samples for both the benign and
adversarial sets were taken from the TIMIT dataset. Similar
to the authors, we use Word Error Rate (WER) as a measure
of transcription similarity and calculate and report the Area
Under Curve (AUC) value. AUC values lie between 0.5 and
1. A perfect detector will return an AUC of 1, while a detector
that randomly guesses returns an AUC of 0.5.
G. Over-Cellular
The Over-Cellular environment simulates a more realistic
scenario where an adversary’s attack samples have to travel
through a noisy and lossy channel before reaching the target
system. Additionally, this environment accurately models one
of the most common mediums used for transporting human
voice – the telephony network. In our case, we did this by
sending the audio through AT&T’s LTE network and the
Internet via Twilio [43] to an iPhone 6. The attacker’s audio
is likely to be distorted while passing through the cellular
network due to jitter, packet loss, and the various codecs
used within the network. The intuition for testing in this
environment is to ensure that our attacks are robust against
these kinds of distortions.
H. MTurk Study Design
In order to measure comprehension of perturbed phone
call audio, we conducted an IRB approved online study. We
ran our study using Amazon’s Mechanical Turk (MTurk)
crowdsourcing platform. All participants were between the
Fig. 4: Success transcriptions against our word-level attack
plotted against increasing distortion, calculated using Mean
Square Error (MSE). The SSA-based word-level attack sees
a faster, sharper decrease in the successful transcriptions than
the DFT-based word-level attack, noted by its ability to reach
50% attack success (solid black line) across all models within
a smaller span of distortion. This means 50% of the words
in the dataset were mistrascribed by the target ASR. In every
case, the test set accuracy falls considerably before reaching
the GSM baseline distortion (dashed red line).
ages of 18 and 55 years old, located in the United States,
and had an approval rating for task completion of more than
95%. During our study, each participant was asked to listen to
audio samples over the phone. Parts of the audio sample had
been perturbed, while others had been left unaltered1. The
audio samples were delivered via an automated phone call
to each of our participants. The participants were asked to
transcribe the audio of a pre-recorded conversation that was
approximately one minute long. After the phone call was done,
participants answered several demographic questions which
concluded the study. We paid participants $2.00 for completing
the task. Participants were not primed about the perturbation of
the pre-recorded audio, which prevented introducing any bias
during transcription. In order to make our study statistically
sound, we ran a sample size calculation under the assumption
of following parameter values: an effect size of 0.05, type-I
error rate of 0.01, and statistical power of 0.8. Under these
given values, our sample size was calculated to be 51 and we
ended up recruiting 89 participants in MTurk. Among these
89, 23 participants started but did not complete the study
and 5 participants had taken the study twice. After discarding
1We invite the readers to listen to the perturbed audio samples for
themselves: https://sites.google.com/view/transcript-evasion
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:09:39 UTC from IEEE Xplore.  Restrictions apply. 
718
020406080100Successful Transcriptions(%)DFT Attack0.00000.00250.00500.00750.01000.01250.01500.0175Mean Squared Error Between Original and Attack Audio020406080100Successful Transcriptions(%)SSA AttackSphinxDeepSpeech-1WitGoogle (Normal)Google (Phone)2) Phoneme Perturbations: Our evaluation of the phoneme
level attacks exposed several trends (Figures 5 and 11). For
brevity, only Google (Normal) and Wit.
Figure 5 shows the relationship between phonemes and
attack success. Lower bars correspond to a greater percentage
of attack examples that were incorrectly transcribed by the
model. According to the ﬁgure, vowels are more sensitive to
perturbations than other phonemes. This pattern was consis-
tently present across all the models we evaluated. There are
a few possible explanations for this behavior. Vowels are the
most common phonemes in the English language and their
formant frequencies are highly structured. It is possible these
two aspects in tandem force the ASR system to over-ﬁt to the
speciﬁc formant pattern during learning. This would explain
why vowel perturbations cause the model to mistranscribe.
Similarly, Figure 11 shows the distortion thresholds needed
for each phoneme to cause a phrase mistranscription. The
longer the bar, the greater the required threshold. For the DFT-
based attack experiment, shown in Figure 11(a), we observe
that the vowels require a lower threshold compared to the
other phonemes. This means that less distortion is required
for a vowel to trick the ASR system. In contrast, the SSA-
based attack experiments( Figure 11(b)), reveal that all of the
phonemes are equally vulnerable. In general, the SSA attacks
required a higher threshold than our previous DFT attack.
However, the MSE of the audio ﬁle after being perturbed when
compared to the original audio is still small. The average MSE
during these tests was 0.0067, which is an order of magnitude
less than the MSE of audio being sent over LTE (0.0181).
Our SSA attacks did not appear to expose any systemic
vulnerability in our models as the DFTs did. There exist two
likely causes for this: DFT’s use in ASR feature extraction and
SSA’s data dependence. ASR systems often use DFTs as part
of their feature extraction mechanisms, and thus the models
are likely learning some characteristics that are dependent on
the DFT. When our attack alters the DFT, we are directly
altering acoustic characteristics that will affect which features
the model is extracting and learning.
duplicate and incomplete data, our ﬁnal sample size consists
of 61 participants.
V. RESULTS
As outlined previously in Section IV-C, we evaluated our
attack in various different conﬁgurations in order to highlight
certain properties of the attack. To begin, we will evaluate our
attack against the speech to text capabilities of multiple ASR
systems in several different setups.
A. Attacks Against ASR systems
1) Word Level Perturbations: We study the effect of our
word-level attack against each model. We measure attack
success against distortion and compare the DFT and the SSA
attacks, (Figure 4). In this subsection, we discuss ﬁve target
models: Google (Normal), Google (Phone), Wit, DeepSpeech-
1 and Sphinx. Distortion is calculated using the MSE between
every normal audio sample and its adversarial counterpart.
We use the GSM audio codec’s average MSE as a baseline
for audio comprehension, as it is used by 2G cellular networks
(the most common globally). We denote this baseline with the
red, vertical dashed line (Figure 4). Thus, we consider any
audio with higher MSE than the baseline as incomprehensible
to humans. It is important to note that this assumption is
extremely conservative, since normal comprehensible phone
call audio often has larger MSE than our baseline.
As the distortion is iteratively increased using the word-
level attack, test set accuracy begins to diminish across all
models and all transforms (Figure 4). Models which decrease
slower, such as Google (Phone), indicate a higher robustness to
our attack. In contrast, weaker models, such as Deep Speech-
1, exhibit a sharper decline. For all transforms, the Google
(Phone) model outperforms the Google (Normal) model. This
indicates that training the Google (Phone) model on noisy
audio data exhibits a rudimentary form of adversarial training.
However, all attacks are eventually successful to at least 85%
while retaining audio intelligibility.
Despite implementing more traditional machine learn-
ing techniques, Sphinx exhibits more robustness than Deep
Speech-1 across both attacks. This indicates that Deep Speech-
1 may be overﬁtting across certain words or phrases, and its
existing architecture is not appropriate for publicly available
training data. Due to the black-box nature of Wit and the
Google models, it is difﬁcult to compare them directly to
their white-box counterparts. Overall, Sphinx is able to match
Wit’s performance, which is also more robust than the Google
(Normal) model in the DFT attack.
Surprisingly, for the SSA attack Sphinx is able to outper-
form all models as distortion approaches the human percep-
tibility baseline. This may be a byproduct of the handcrafted
features and models built into Sphinx. Overall, the SSA-based
attack manages to induce less distortion, allowing all models
to fail with 50% (represented by the horizontal black line) or
less test set accuracy before 0.0100 calculated MSE. Manual
listening tests showed that there was no perceivable drop in
audio quality at this MSE.
Additionally, when SSA is used in our attack, we are
removing eigenvectors rather than speciﬁc frequencies like we
do with a DFT. These eigenvectors are made up of multiple
frequencies that are not unique to any one eigenvector. Thus,
the removal of an eigenvector does not guarantee the complete
removal of a given frequency from the original audio sample.
We believe the combination of these two factors results in our
SSA-based attack being equally effective against all phonemes.
Both Figures 5 and 11 provide information for an attacker to
maximize their attack success probability. Perturbing vowels at
a 0.5 threshold while using a DFT-based attack will provide the
highest probability for success because vowels are vulnerable
across all models. Even though the discard threshold applied
to vowels might vary from one model to another, choosing a
threshold value of 0.5 can guarantee both stealth and a high
likelihood of a successful mistranscription.
3) ASR Poisoning: As described in Section IV-C2, per-
turbing a single phoneme not only causes a mistranscription
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:09:39 UTC from IEEE Xplore.  Restrictions apply. 
719
Fig. 5: A comparison of attack success of our DFT-based phoneme-level attack against two ASR models. There is a clear
relationship between the which phoneme is attacked and the attack’s success. It is clear across all models that we evaluated
that vowels are more vulnerable to this attack than other phonemes.
Model
Google (Normal)
Wit
Original Transcription
The emperor had a mean Temper
then the chOreographer must arbitrate
she had your dark suit in Greasy wash water all year
masquerade parties tax one’S imagination
Attack Transcription
syempre Hanuman Temple
Democrat ographer must arbitrate
nope
stop
TABLE II: By only perturbing a single phoneme (bold faced and underlined), our attack forces ASR systems to completely
mistranscribe the resulting audio.
P (Sf→g)
Google
(Phone)
Google
(Normal)
Wit
Sphinx
Deep-Speech 1
From
(f)
Google
(Phone)
100%
To (g)
Google
(Normal) Wit Sphinx Deep-Speech 1
78% 83% 42%
87%
13%
6%
21%
3%
100% 65% 22%
10% 100% 14%
74% 81% 100%
31% 12%
7%
70%
52%
80%
100%
TABLE III: The probability of transferability P (Sf→g) calcu-
lated for each combination of the tested models. Only ‘harder’
models tend to transfer well to weaker models. The elements in
bold show the highest transferability successes. Model names
in the columns have been arranged in descending order of their
strength from harder to weaker.
transcribed content. It is also interesting to note that, despite
their common internal structure, Deep Speech-1 and Deep
Speech-2 are signiﬁcantly different in their vulnerability to this
effect. Deep Speech-1 and 2 have a cosine similarity score of
0.4 and 0.7, respectively. This difference could potentially be
attributed to different feature extraction mechanisms. While
Deep Speech-1 uses MFCCs,
its counterpart uses a CNN
feature extraction. This is because feature extraction using
MFCCs and CNNs produces varying results and might capture
divergent information about the signal.
B. Attacks Against AVI systems
Next, we observe our attacks’ effectiveness inducing errors
an AVI system. Figure 7 shows the attack success rate per
vowel for both SSA and DFT attacks. Similar to our attack
results against ASR models, attacks against the AVI system
exhibited higher success rate when attacking vowels. This
means an adversary wishing to maximize attack success should
focus on perturbing vowels.
Fig. 6: Cosine similarity between the transcriptions of the
original and the perturbed audio ﬁle. At a value of 0.5
(horizontal line) half of the sentence is incorrect. Attack audio
samples were generated by perturbing a single phoneme.
of the given word but also of the following words as well.
Results of this phenomena can be seen in Table II. We
further, characterize this numerically across each model for the
DFT-based attack in Figure 6, where higher values of cosine
similarity translate to lower attack mistranscription.
We observe a relationship between the model type and the
cosine similarity score. Of all the models tested, Wit is the
most vulnerable, given low average cosine similarity of 0.36.