99.99 98.79
99.99 87.75
99.99 89.00
99.99 94.58
99.99 88.59
99.99 99.97
99.99 99.98
99.99 99.98
99.99 99.99
99.98 99.98
99.99 82.50
99.98 66.88
99.99 65.64
99.98 76.92
99.94 66.62
99.98 87.92
99.99 78.80
99.98 75.32
99.97 85.31
99.99 76.50
99.99 99.99
99.99 99.95
99.99 99.95
99.99 94.61
99.99 93.04
99.99 99.81
99.99 98.79
99.98 97.38
99.99 99.46
99.98 97.49
Rec
Pre
88.80 99.70 Od
84.76 99.56 O1
85.84 93.45 O2
84.30 96.45 Ox
-
86.52 96.65
-
99.90 6.30
-
99.46 4.15
-
99.51 19.47
-
99.83 5.26
-
99.07 19.55
99.96 99.80 Od
99.88 99.11 O1
99.90 98.64 O2
99.84 99.35 Ox
-
99.85 96.49
99.60 63.26 Od
99.64 2.06
O1
99.69 17.77 O2
99.76 12.76 Ox
-
99.70 17.92
99.96 64.51 Od
99.68 51.31 O1
99.72 48.26 O2
99.73 16.23 Ox
-
99.73 37.78
99.96 64.88 Od
99.89 48.75 O1
99.90 54.31 O2
99.94 60.73 Ox
-
99.87 51.07
99.95 97.64 Od
99.79 99.23 O1
99.81 99.30 O2
99.77 99.78 Ox
-
99.84 99.75
Od
99.96 9.37
99.70 9.81
O1
99.69 11.73 O2
Ox
97.20 9.16
-
95.56 12.64
94.51 44.59 Od
O1
99.29 8.55
O2
99.24 9.23
Ox
91.09 8.59
-
99.24 8.90
99.61 99.34 Od
99.76 98.15 O1
99.87 98.03 O2
99.93 57.31 Ox
-
99.88 51.62
99.72 89.85 Od
99.50 72.01 O1
99.56 71.77 O2
99.37 77.51 Ox
-
99.65 71.79
-
-
-
-
-
-
-
-
Rec
Pre
98.04 99.98
98.96 99.97
97.58 99.97
97.57 99.97
-
-
-
-
-
-
99.79 97.49
99.83 99.32
99.84 95.41
99.82 96.16
-
99.88 96.01
99.86 90.40
99.88 92.12
99.87 92.09
-
99.88 96.01
99.86 90.40
99.88 92.12
99.87 92.09
-
99.97 93.02
99.97 93.42
99.96 90.31
99.96 90.17
-
98.96 99.92
99.33 99.90
98.66 99.88
98.64 99.88
-
99.98 71.44
99.96 78.95
99.90 70.49
99.90 70.47
-
99.21 86.25
99.82 78.60
98.50 75.78
98.48 75.60
-
-
-
-
-
-
-
-
-
-
-
-
-
Rec
Pre
86.84 99.83
83.84 99.84
83.73 99.82
83.73 99.82
-
-
-
-
-
-
94.82 83.20
95.06 97.47
95.81 75.07
94.18 78.30
-
94.84 65.05
95.04 73.67
95.80 72.00
94.10 69.34
-
94.84 65.05
95.04 73.67
95.80 72.00
94.10 69.34
-
98.67 14.50
98.10 18.94
98.14 17.80
98.14 17.80
-
90.01 99.37
87.71 99.16
87.55 99.20
87.55 99.20
-
98.97 30.24
98.54 50.87
97.48 42.41
97.45 38.75
-
46.59 30.00
92.87 46.21
42.78 44.73
45.74 38.44
-
-
-
-
-
-
-
-
99.80 99.98
99.82 99.96
99.84 99.89
99.82 99.90
-
99.61 99.23
99.76 99.74
99.51 98.96
99.52 99.22
-
-
-
94.83 99.54
95.08 99.39
95.83 96.44
94.20 96.66
-
94.84 96.61
95.14 96.04
95.93 93.26
94.32 96.94
-
-
Overall Performance: In Table V, we show the overall results
of instruction recovery. Note that we do not show the results
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:27:37 UTC from IEEE Xplore.  Restrictions apply. 
840
of PSI and UROBOROS as they are close to OBJDUMP.
In general,
the results of disassembly vary across tool
like
categories. Linear tools and linear-sweep aided tools,
OBJDUMP and ANGR, have every high coverage (99.95%+ recall).
Recursive tools have lower recovery rates and some can only
recover less than 80% of the instructions (BAP and RADARE2).
We also notice that the performance of recursive tools changes
across optimization levels and architectures. In particular,
nearly all recursive tools (ANGR-NS, GHIDRA-NE, DYNINST, BAP,
RADARE2) have reduced recovery as the optimization increases
and when analyzing X64 targets. This is because that opti-
mization levels and architectures affect the function matching
in recursive tools, further leading to missing of instructions.
Such results well comply with previous observations [5].
In the aspect of precision, we have an opposite observation.
Recursive tools have high precision (over 99.5%), regardless
of the compiler, architecture, and optimization level. Linear
tools are less precise. The precision of OBJDUMP, in the worst
case, drops to around 85%. This difference is mainly because
recursive tools mostly follow the control ﬂow, ensuring cor-
rectness. However, linear tools scan every byte and often run
into errors when data appears in code. For instance, OBJDUMP
produces the worst result in analyzing Openssl (precision:
85.35%) because Openssl has a lot of data in assembly ﬁles
and OBJDUMP wrongly identiﬁes the data as code.
Use of Heuristics: To augment
the correctness of linear
sweep, PSI introduces error detection and handling. In our
evaluation, PSI can analyze 971 of the X86 binaries on Linux
systems. On the binaries, the linear sweep produces over 10K
errors. PSI captures 26% of the errors leading to bad opcode
and other 6% resulting in invalid control transfers. However,
the public version of PSI has strict requirement of padding
patterns, preventing it from ﬁxing the errors. In summary,
PSI’s heuristic can capture 32% of the errors in linear sweep.
However, we are unable to report the detectable errors due to
PSI’s implementation restrictions.
In contrast, heuristics in recursive tools are mostly for
coverage enhancement. We measure the effectiveness of each
heuristic in turn. We start with pure recursive descent by
disabling function matching, linear scan in ANGR, xref aided
disassembly in GHIDRA and RADARE2. The results are shown
in Table XVIII in Appendix D. Unsurprisingly, all tools have
nearly perfect precision. However, without heuristics, the tools
have very low recall. ANGR, GHIDRA, DYNINST all have a
recall around 51% and RADARE2 recovers no more than 10%
of the code. We noted that GHIDRA still produces high recall
with Linux binaries. This is because GHIDRA uses exception
information to highly accurately identify functions (§ III-C).
On top of pure recursive descent, we in turn enable function
matching, linear scan, and the use of xrefs. With function
matching, recursive tools recover signiﬁcantly more functions
and code (see Table XIX in Appendix D). In particular, ANGR-
NS and DYNINST respectively identify 21.30% and 18.24%
more functions, leading to recovery of 36.44% and 26.65%
more code (comparing Table V and XVIII). Second, according
to the results of ANGR and ANGR-NS in Table V, linear scan
TABLE VI: Statistics of false positives in instruction recovery.
Pad, data, Func, Non-Ret, Jump-Tbl respectively represent
errors due to padding, data-in-code, wrong function matching,
non-returning functions, and wrong jump tables.
Tools
Objdump
Dyninst
Ghidra
Ghidra-NE
Angr
Angr-NS
Bap
Radare2
Percentage of False Positives (%)
Pad
71.7
0.0
0.0
0.0
10.5
0.0
0.0
0.0
Data
28.3
0.0
0.0
0.0
10.3
0.0
0.0
0.0
Func
0.0
36.2
18.2
6.4
76.3
70.2
89.0
96.5
Non-Ret
Jump-Tbl
0.0
39.9
65.4
61.7
2.9
29.1
0.8
2.2
0.0
23.8
3.0
5.9
0.0
0.7
0.0
1.3
Other
0.0
0.0
13.4
26.0
0.0
0.0
10.2
0.0
aids ANGR to recover 8.20% more instructions. Third, the
use of xrefs in GHIDRA leads to a 4.33% increase in code
coverage, as shown by the result of GHIDRA on Linux binaries
in Table V and XVIII
Understanding of Errors: In Table VI, we summarize the
statistic of false positives. For linear tools (e.g., OBJDUMP), all
the false positives are caused by misidentifying padding bytes
or data-in-code as code. For recursive tools, the most common
reasons of errors include (1) considering illegal
locations
as function entries; (2) missing non-returning functions and
assuming the calls to them fall through; (3) incorrect resolution
of jump tables. Beyond that, ANGR’s linear sweep incurs 21%
of the errors due to data in code; BAP and GHIDRA have a
few implementation ﬂaws, also leading to a group of errors.
The reasons of false negatives are consistent. All the false
negatives by linear tools are side-effects of false positives. For
recursive tools, most false negatives are caused by undetected
function: as shown in Table X, recursive tools averagely miss
25.0% of the functions. The remaining instructions are missed
mainly because certain jump tables are not resolved and false
positives over-run the legitimate instructions.
jumps/calls are trivial
2) Symbolization: In this evaluation, we measure the re-
covery of xrefs. Xrefs in direct
to
identify so we excluded them. We also excluded xrefs in
wrong instructions since such errors are rooted from incorrect
disassembly. Finally, we did not consider jump tables as they
are separately measured in § IV-B4.
Overall Performance: We summarize the overall performance
of symbolization in Table VII. In general, open-source tools
have much higher recovery rates (98.35% on average) than com-