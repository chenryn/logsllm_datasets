IEEE
Computer Society, 2017. [Online]. Available: http://ieeexplore.ieee.org/
xpl/mostRecentIssue.jsp?punumber=8048777
[10] M. Bun, C. Dwork, G. N. Rothblum, and T. Steinke, “Composable and
versatile privacy via truncated cdp,” in Proceedings of the 50th Annual
ACM SIGACT Symposium on Theory of Computing, 2018, pp. 74–86.
[11] M. Abadi, A. Chu, I. Goodfellow, H. B. McMahan, I. Mironov, K. Tal-
war, and L. Zhang, “Deep learning with differential privacy,” in ACM
Conference on Computer and Communications Security (CCS). ACM,
2016, pp. 308–318.
[12] C. L. Canonne, G. Kamath, and T. Steinke, “The discrete Gaussian for
differential privacy.” NeurIPS, 2020.
[27] J. Allen, B. Ding, J. Kulkarni, H. Nori, O. Ohrimenko, and S. Yekhanin,
“An algorithmic framework for differentially private data analysis on
trusted processors,” in Conference on Neural Information Processing
Systems (NeurIPS), 2019.
[28] T. Ristenpart, E. Tromer, H. Shacham, and S. Savage, “Hey, you, get
off of my cloud: Exploring information leakage in third-party compute
clouds,” in ACM Conference on Computer and Communications Secu-
rity (CCS), 2009.
[29] T. Van Goethem, C. P¨opper, W. Joosen, and M. Vanhoef, “Timeless
timing attacks: Exploiting concurrency to leak secrets over remote
connections,” in USENIX Security Symposium, 2020.
[30] G. Marsaglia and T. A. Bray, “A convenient method for generating
normal variables,” SIAM Review, vol. 6, no. 3, p. 260–264, 1964.
[31] G. Marsaglia and W. W. Tsang, “The ziggurat method for generating
random variables,” Journal of Statistical Software, vol. 5, no. 8, 2000.
[32] G. Marsaglia, “Generating a variable from the tail of the normal
distribution,” Technometrics, vol. 6, no. 1, pp. 101–102, 1964. [Online].
Available: https://doi.org/10.1080/00401706.1964.10490150
[33] D. Dua and C. Graff, “UCI machine learning repository,” 2017.
[Online]. Available: http://archive.ics.uci.edu/ml
[34] B. Balle and Y.-X. Wang, “Improving the Gaussian mechanism for
differential privacy: Analytical calibration and optimal denoising,” in
ACM Conference on Computer and Communications Security (CCS).
ICML, 2018, pp. 1–23.
[35] C. Dwork and A. Roth, “The algorithmic foundations of differential
privacy,” Found. Trends Theor. Comput. Sci., vol. 9, Aug. 2014.
[36] J. Hsu, M. Gaboardi, A. Haeberlen, S. Khanna, A. Narayan, B. C.
Pierce, and A. Roth, “Differential privacy: An economic method for
choosing epsilon,” in 2014 IEEE 27th Computer Security Foundations
Symposium.
IEEE, 2014, pp. 398–410.
[37] Y. LeCun and C. Cortes, “MNIST handwritten digit database,” 2010.
[38] Z. Bu, J. Dong, Q. Long, and W. J. Su, “Deep learning with Gaussian
[Online].
differential privacy,” CoRR, vol. abs/1911.11607, 2019.
Available: http://arxiv.org/abs/1911.11607
[39] V. Balcer and S. P. Vadhan, “Differential privacy on ﬁnite computers,”
in 9th Innovations in Theoretical Computer Science Conference,
ITCS 2018,
ser.
LIPIcs, A. R. Karlin, Ed., vol. 94.
Schloss Dagstuhl - Leibniz-
Zentrum f¨ur Informatik, 2018, pp. 43:1–43:21. [Online]. Available:
https://doi.org/10.4230/LIPIcs.ITCS.2018.43
January 11-14, 2018, Cambridge, MA, USA,
[40] P. Kairouz, Z. Liu, and T. Steinke, “The distributed discrete
gaussian mechanism for federated learning with secure aggregation,”
in Proceedings of
the 38th International Conference on Machine
Learning, ICML 2021, 18-24 July 2021, Virtual Event, ser. Proceedings
of Machine Learning Research, M. Meila and T. Zhang, Eds.,
vol. 139.
PMLR, 2021, pp. 5201–5212.
[Online]. Available:
http://proceedings.mlr.press/v139/kairouz21a.html
[41] J. V. Cleemput, B. Coppens, and B. De Sutter, “Compiler mitigations
for time attacks on modern x86 processors,” ACM Trans. Archit.
Code Optim., vol. 8, no. 4,
jan 2012. [Online]. Available: https:
//doi.org/10.1145/2086696.2086702
leaks using program repair,” in Proceedings of
[42] M. Wu, S. Guo, P. Schaumont, and C. Wang, “Eliminating timing
side-channel
the
27th ACM SIGSOFT International Symposium on Software Testing
and Analysis, ser. ISSTA 2018. New York, NY, USA: Association
for Computing Machinery, 2018, pp. 15–26.
[Online]. Available:
https://doi.org/10.1145/3213846.3213851
[43] A. Askarov, D. Zhang, and A. C. Myers, “Predictive black-box mit-
igation of timing channels,” in ACM Conference on Computer and
Communications Security (CCS), 2010, pp. 297–307.
[44] S. Sharma, A. Bag, and D. Mukhopadhyay, “Compact and secure generic
discrete gaussian sampler based on hw/sw co-design,” in 2020 Asian
Hardware Oriented Security and Trust Symposium (AsianHOST), 2020,
pp. 1–6.
[45] I. Gazeau, D. Miller, and C. Palamidessi, “Preserving differential privacy
under ﬁnite-precision semantics,” in Proceedings 11th International
Workshop on Quantitative Aspects of Programming Languages and
Systems, QAPL 2013, Rome, Italy, March 23-24, 2013, ser. EPTCS,
L. Bortolussi and H. Wiklicky, Eds., vol. 117, 2013, pp. 1–18. [Online].
Available: https://doi.org/10.4204/EPTCS.117.1
[46] C.
Ilvento, “Implementing the exponential mechanism with base-
2 differential privacy,” in ACM Conference on Computer and
Communications Security (CCS), ser. CCS ’20. New York, NY, USA:
[13] Google,
“Secure
noise
generation,”
https://github.com/google/
[Online]. Available: http://yann.lecun.com/exdb/mnist/
differential-privacy/blob/master/common docs/Secure Noise
Generation.pdf, 2020.
[14] “The Discrete Gaussian for Differential Privacy,” https://github.com/
IBM/discrete-gaussian-differential-privacy, 2020, [Online; accessed 01-
Dec-2021].
[15] C. Dwork, F. McSherry, K. Nissim, and A. Smith, “Calibrating noise
to sensitivity in private data analysis,” in Theory of Cryptography
Conference (TCC), 2006, pp. 265–284.
[16] C. Dwork and A. Roth, “The algorithmic foundations of differential
privacy,” Foundations and Trends in Theoretical Computer Science,
vol. 9, no. 3-4, pp. 211–407, 2014.
[Online]. Available: https:
//doi.org/10.1561/0400000042
[17] C. Dwork and G. N. Rothblum, “Concentrated differential privacy,”
CoRR, vol. abs/1603.01887, 2016. [Online]. Available: http://arxiv.org/
abs/1603.01887
[18] I. Mironov, “R´enyi differential privacy,” in 30th IEEE Computer
Security Foundations Symposium, CSF 2017, Santa Barbara, CA, USA,
August 21-25, 2017.
IEEE Computer Society, 2017, pp. 263–275.
[Online]. Available: https://doi.org/10.1109/CSF.2017.11
[19] R. Bassily, A. D. Smith, and A. Thakurta, “Private empirical risk min-
imization: Efﬁcient algorithms and tight error bounds,” in Symposium
on Foundations of Computer Science (FOCS), 2014.
[20] S. Song, K. Chaudhuri, and A. D. Sarwate, “Stochastic gradient descent
with differentially private updates,” in 2013 IEEE Global Conference on
Signal and Information Processing, Dec 2013, pp. 245–248.
[21] Y.-X. Wang, S. Fienberg, and A. Smola, “Privacy for free: Posterior sam-
pling and stochastic gradient Monte Carlo,” in International Conference
on Machine Learning (ICML), 2015.
[22] H. B. McMahan, D. Ramage, K. Talwar, and L. Zhang, “Learning differ-
entially private recurrent language models,” in International Conference
on Learning Representations (ICLR), 2018.
[23] L. Yu, L. Liu, C. Pu, M. Gursoy, and S. Truex, “Differentially private
model publishing for deep learning,” in IEEE Symposium on Security
and Privacy (S&P), 2019.
[24] J. M. Abowd, “The u.s. census bureau adopts differential privacy,” in
Proceedings of the 12th ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, ser. KDD ’18, 2018.
[25] N. Johnson, J. P. Near, and D. Song, “Towards practical differential
privacy for SQL queries,” PVLDB, vol. 11, no. 5, pp. 526–539, Jan.
2018.
[26] F. D. McSherry, “Privacy integrated queries: An extensible platform for
privacy-preserving data analysis,” in SIGMOD, 2009.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:38:32 UTC from IEEE Xplore.  Restrictions apply. 
486
Fig. 7: FP attack success rate on private count where the count
is protected with the Gauss go Gaussian sampler across σ ∈
[1, 128] with ﬁxed δ = 10−5 and function sensitivity ∆ = 1.
Baseline (random) attack success is 50%. Success rate peaks
at σ ∈ {20, 21, 22, 23, 24, 25, 26, 27}.
Fig. 8: Execution time of private sum over the credit attribute
of the German Credit Dataset [33], with Laplace II [3], over
a range of noise magnitudes, with  = 10 and sensitivity ∆ =
5000 (avg. over 50 million trials).
Association for Computing Machinery, 2020, pp. 717–742. [Online].
Available: https://doi.org/10.1145/3372297.3417269
[47] N. Holohan and S. Braghin, “Secure random sampling in differential
[Online]. Available:
privacy,” CoRR, vol. abs/2107.10138, 2021.
https://arxiv.org/abs/2107.10138
[48] J. Foll´ath, “Gaussian sampling in lattice based cryptography,” Tatra
Mountains Mathematical Publications, vol. 60, no. 1, pp. 1–23, 2015.
[Online]. Available: https://doi.org/10.2478/tmmp-2014-0022
[49] V. Lyubashevsky, C. Peikert, and O. Regev, “On ideal lattices and
learning with errors over rings,” J. ACM, vol. 60, no. 6, nov 2013.
[Online]. Available: https://doi.org/10.1145/2535925
[50] L. Ducas, A. Durmus, T. Lepoint, and V. Lyubashevsky, “Lattice signa-
tures and bimodal gaussians,” in Advances in Cryptology – CRYPTO
2013, R. Canetti and J. A. Garay, Eds. Berlin, Heidelberg: Springer
Berlin Heidelberg, 2013, pp. 40–56.
[51] L. Groot Bruinderink, A. H¨ulsing, T. Lange, and Y. Yarom, “Flush,
gauss, and reload – a cache attack on the bliss lattice-based signature
scheme,” in Cryptographic Hardware and Embedded Systems – CHES
2016, B. Gierlichs and A. Y. Poschmann, Eds.
Berlin, Heidelberg:
Springer Berlin Heidelberg, 2016, pp. 323–345.
[52] J. Howe, A. Khalid, C. Rafferty, F. Regazzoni, and M. O’Neill, “On
practical discrete gaussian samplers for lattice-based cryptography,”
IEEE Transactions on Computers, vol. 67, pp. 322–334, 2018.
[53] D. Micciancio and M. Walter, “Gaussian sampling over the integers:
Efﬁcient, generic, constant-time,” Cryptology ePrint Archive, Report
2017/259, 2017, https://ia.cr/2017/259.
[54] A. Karmakar, S. S. Roy, O. Reparaz, F. Vercauteren, and I. Verbauwhede,
“Constant-time discrete gaussian sampling,” IEEE Transactions on Com-
puters, vol. 67, no. 11, pp. 1561–1571, 2018.
[55] D. Lee, J. D. Villasenor, W. Luk, and P. H. W. Leong, “A hardware
Gaussian noise generator using the Box-Muller method and its error
analysis,” IEEE Trans. Computers, vol. 55, no. 6, pp. 659–671, 2006.
[Online]. Available: https://doi.org/10.1109/TC.2006.81
APPENDIX
A. Box-Muller Method
The Box-Muller method [55] is a computational method that
generates samples of the standard normal distribution from
uniformly distributed random values. It operates as follows:
1) Choose independent uniform random values x1 and x2
2) Set r2 ← −2 ln x1 and Θ ← 2πx2.
3) Return s1 ← r cos(Θ).
from (0, 1) using RandomFP.
This procedure can be used to generate two independent
normal samples: s1, as above, and s2 ← r sin(Θ).
B. DP Gradient Computation
We now recall how f and ∆f are determined for the DP-
SGD mechanism.
S(cid:88)
i=1
f (B) =
1
S
g(bi)
(4)
where B = [b1, b2, . . . , bS] and bi is a record in B, g calculates
per-record gradient with per-record clipping with respect to
clipping norm L. Note that since the model has d = 26, 010
parameters and each batch is used to update them all, f (B) ∈
Rd contains a gradient for each parameter of the model.
a) Sensitivity Analysis: The sensitivity of DP-SGD is the
maximum L2 distance between any pair of f (B) and f (B(cid:48)).
Clipping norm L dictates the largest L2 norm of any record
gradient. Thus, for any f (B) and f (B(cid:48)), we can have:
(cid:107)f (B(cid:48)) − f (B)(cid:107)2 ≤ 1
S
≤ 1
S
(cid:107)g(bc) − g(br)(cid:107)2
((cid:107)g(bc)(cid:107)2 + (cid:107)g(br)(cid:107)2) ≤ 2L
S
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:38:32 UTC from IEEE Xplore.  Restrictions apply. 
487
TABLE II: The range of attack rate and accuracy across  ∈ [1, 20]. Attack rate refers to the rate at which the attacker can
make a gues. Attack accuracy measures how many of these guesses are correct. The two implementations of polar method and
Box-Muller, Gauss numpy and Gauss pytorch, respectively, have different attack rates, though the accuracy of those guesses
is always above 89%. The attack rate and accuracy for Gauss go always stay above 76% and 99.9%, respectively.
Sensitivity
1
10
Gauss numpy
Gauss pytorch
Gauss go
attack rate
[1.7%, 78.2%]
[1.9%, 76.5%]
attack accuracy
[92.4%, 99.9%]
[89.6%, 99.9%]
attack rate
[4.3%, 92.8%]
[10.9%, 91.9%]
attack accuracy
[97.7%, 99.9%]
[99.5%, 99.9%]
attack rate
[76.4%, 89.6%]
[76.3%, 88.8%]
attack accuracy
[99.9%, 100%)
[99.9%, 100%)
where bc refers to the canary record and br refers to the record
replaced by bc. Since L = 1 and S = 64, the sensitivity of f
is 1/32.
DP-SGD then proceeds by computing
y = f (B) +
1
S
Z
i.i.d.∼ N (0, σ2L2), y ∈ Rd, and
where Z = [Z1, . . . , Zd]
Gauss pytorch is used to draw noise from N . Note that even
if some record is radically different from others in the batch
(e.g., like the canary used in DiﬀLabelCanary) its gradient is
clipped at L.
C. DP-SGD Discretization
In Section VIII-A, we implement DP-SGD with discrete
Gaussian by discretizing the gradient g ∈ Rd as described
in [40] who use discrete Gaussian for training models in
Federated Learning setting. The method proceeds as follows.
1) Clip g w.r.t. clipping norm L, g(cid:48) = g×min{1, L/(cid:107)g(cid:107)2}.
2) Scale g(cid:48) with discretization parameter 1/γ, so the dis-
cretization can be done on a ﬁner grid γZd. Then
randomly round each coordinate to the nearest integer,
z = Roundγ(g(cid:48)) so that z ∈ Zd.
3) Let G ∈ Zd consist of d independent samples from the
discrete Gaussian NZ(0, σ2/γ2).
4) Add discrete noise to z and undo discretization, z(cid:48) =
(z + G) × γ.
where Roundγ is the conditional randomized rounding func-
tion with discretization parameter γ. We refer the reader
to [40] for details about Roundγ.
D. Ablation study
Here we investigate the rate at which the attacker can make
a guess (attack rate) and how many of these guesses are correct
(attack accuracy). To this end, we simulate settings where
q = 0 and q(cid:48) = c and test two values of c: 1 and 10, meaning
the sensitivity ∆ of the underlying function is 1 and 10,
respectively. We take a range of values of  from 1 to 20 while
keeping a ﬁxed δ = 10−5. Table II shows that implementations
Gauss numpy and Gauss pytorch have different attack rates;
however, their attack accuracy is always at least 89%. For
Gauss go, we observe that the attack rate is not inﬂuenced
signiﬁcantly by  (at least 76%), and the attack accuracy is
always above 99.99%.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:38:32 UTC from IEEE Xplore.  Restrictions apply. 
488