ations based on this value would result in an alarm.
Naturally, there is an arms-race between rootkits that use
more sophisticated methods to obtain kernel addresses and
our detection system that relies on speciﬁcations of mali-
cious behavior. For current rootkits, our basic speciﬁcations
allow for reliable detection with no false positives (see Sec-
tion 4 for details). However, it might be possible to circum-
vent these speciﬁcations. In that case, it is necessary to pro-
vide more elaborate descriptions of malicious behavior.
Note that our behavioral speciﬁcations have the advantage
that they provide a general model of undesirable behavior.
That is, these speciﬁcations characterize an entire class of
malicious actions. This is different from ﬁne-grained spec-
iﬁcations that need to be tailored to individual kernel mod-
ules. In addition, behavioral speciﬁcations have the poten-
tial to detect previously unknown rootkits. In contrast to ap-
proaches that rely on anti-virus-like pattern matching tech-
niques, our tool can detect any kernel-level rootkit that satis-
ﬁes our assumptions.
3.2. Symbolic Execution
Based on the speciﬁcations introduced in the previous
section, the task of the analysis step is to statically check the
module binary for instructions that correspond to these spec-
iﬁcations. When such instructions are found, the module is
labeled as a rootkit.
We perform analysis on binaries using symbolic execu-
tion. Symbolic execution is a static analysis technique in
which program execution is simulated using symbols, such
as variable names, rather than actual values for input data.
The program state and outputs are then expressed as math-
ematical (or logical) expressions involving these symbols.
When performing symbolic execution, the program is basi-
cally executed with all possible input values simultaneously,
thus allowing one to make statements about the program be-
havior.
One problem with symbolic execution is the fact that it
is impossible to make statements about arbitrary programs
in general, due to the halting problem. However, when the
completeness requirement is relaxed, it is often possible to
obtain useful results in practice. Relaxing the completeness
requirement implies that the analysis is not guaranteed to de-
tect malicious instructions sequences in all cases. However,
this can be tolerated when most relevant instances are found.
In order to simulate the execution of a program, or, in our
case, the execution of a loadable kernel module, it is neces-
sary to perform two preprocessing steps.
First, the code sections of the binary have to be disas-
sembled. In this step, the machine instructions have to be
extracted and converted into a format that is suitable for
symbolic execution. That is, it is not sufﬁcient to simply
print out the syntax of instructions, as done by programs
such as objdump. Instead, the type of the operation and
its operands have to be parsed into an internal representa-
tion. The disassembly step is complicated by the complexity
of the Intel x86 instruction set, which uses a large number
of variable length instructions and many different address-
ing modes for backwards compatibility reasons.
In the second preprocessing step, it is necessary to ad-
just address operands in all code sections present. The rea-
son is that a Linux loadable kernel module is merely a stan-
Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC’04) 
1063-9527/04 $ 20.00 IEEE 
dard ELF relocatable object ﬁle. Therefore, many memory
address operands have not been assigned their ﬁnal values
yet. These memory address operands include targets of jump
and call instructions but also source and destination locations
of load, store, and move instructions.
For a regular relocatable object ﬁle, the addresses are ad-
justed by the linker. To enable the necessary link operations,
a relocatable object also contains, besides regular code and
data sections, a set of relocation entries. Note, however, that
kernel modules are not linked to the kernel code by a regular
linker. Instead, the necessary adjustment (i.e., patching) of
addresses is performed during module load time by a special
module loader. For Linux kernels up to version 2.4, most of
the module loader ran in user space; for kernels from version
2.5 and up, much of this functionality was moved into the
kernel. To be able to simulate execution, we perform a pro-
cess similar to linking and substitute place holders in instruc-
tion operands and data locations with the real addresses. This
has the convenient side-effect that we can mark operands that
represent forbidden kernel symbols so that the symbolic ex-
ecution step can later trace their use in write operations.
When the loadable kernel module has been disassembled
and the necessary address modiﬁcations have occurred, the
symbolic execution process can commence. To this end, an
initial machine state is created and execution starts with the
module’s initialization routine, called init module().
Handling Machine State The machine state represents a
snapshot of the system during symbolic execution. That is,
the machine state contains all possible values that could be
present in the processor registers and the memory address
space of the running process at a certain point during the ex-
ecution process. Given the notion of a machine state, an in-
struction can then be deﬁned as a function that maps one ma-
chine state into another one. This mapping will reﬂect the ef-
fect of the instruction itself (e.g., a data value is moved from
one register to another), but also implicit effects such as in-
crementing the instruction pointer.
When complete knowledge about the processor and mem-
ory state is available, and given the absence of any input and
external modiﬁcations of the machine state, it would be pos-
sible to deterministically simulate the execution of a mod-
ule. However, in our case, the complexity of such a com-
plete simulation would be tremendous. Therefore, we intro-
duce a number of simpliﬁcations that improve the efﬁciency
of the symbolic execution process, while retaining the abil-
ity to detect most malicious instruction sequences.
A main simpliﬁcation is the fact that we consider the ini-
tial conﬁguration of the memory content as unknown. This
means that whenever a value is taken from memory, a spe-
cial unknown token is returned. However, it does not imply
that all loads from memory are automatically transformed
into unknown tokens. When known values are stored at cer-
tain memory locations, these values are remembered and can
subsequently be loaded. This is particularly common for the
stack area when return addresses are pushed on the stack by
a call operation and later loaded by the corresponding return
instruction.
During symbolic execution, we can simulate the effect of
arithmetic, logic, and data transfer instructions. To this end,
the values of the operands are calculated and the required op-
eration is performed. When at least one of the operands is an
unknown token, the result is also unknown.
Another feature is a tainting mechanism that tags val-
ues that are related to the use of forbidden kernel symbols.
Whenever a forbidden symbol is used as an operand, even
when its value is unknown, the result of the operation is
marked as tainted. Whenever a tainted value is later used by
another instruction, its result becomes tainted as well. This
allows us to detect writes to kernel memory that are based on
the use of forbidden symbols.
For the initial machine state, we prepare the processor
state such that the instruction pointer register is pointing
to the ﬁrst instruction of the module’s initialization routine,
while the stack pointer and the base (i.e., frame) pointer reg-
ister refer to valid addresses on the kernel stack. All other
registers and the entire memory is marked as unknown.
Then, instructions are sequentially processed and the ma-
chine state is updated accordingly. For each data transfer, it
is checked whether data is written to kernel memory areas
that are not explicitly permitted by the white-list, or whether
data is written to addresses that are tainted because of the use
of forbidden symbols.
The execution of instructions continues until execution
terminates with the ﬁnal return instruction of the initializa-
tion function, or until a control ﬂow instruction is reached.
Handling Control Flow Control ﬂow instructions present
problems for our analysis when they have two possible suc-
cessor instructions (i.e., continuations). In this case, the sym-
bolic execution process must either select a continuation to
continue at, or a mechanism must be introduced to save the
current machine state at the control ﬂow instruction and ex-
plore both paths one after the other. In this case, the execu-
tion ﬁrst continues with one path until it terminates and then
backs up to the saved machine state and continues with the
other alternative.
The only problematic type of control ﬂow instructions are
conditional branches. This is because it is not always possi-
ble to determine the real target of such a branch operation
statically. The most common reason is that the branch con-
dition is based on an unknown value, and thus, both continu-
ations are possible. Neither unconditional jumps nor call in-
structions are a difﬁculty because both only have a single tar-
get instruction where the execution continues. Also, calls and
the corresponding return operations are not problematic be-
cause they are handled correctly by the stack, which is part
of the machine state.
Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC’04) 
1063-9527/04 $ 20.00 IEEE 
Because malicious writes can occur on either path after
a conditional branch, we chose to save the machine state
at these instructions and then consecutively explore both al-
ternative continuations. Unfortunately, this has a number of
problems that have to be addressed.
1:
branch (x)
2:
block A
3:
block B
4:
branch (y)
5:
block C
6:
block D
if (x) then
   block A;
else
   block B;
if (y) then
   block C;
else
   block D;
7:
block E
Figure 1. Example control ﬂow graph.
One problem is caused by the exponential explosion of
possible paths that need to be followed. Consider the case of
multiple branch instructions that are the result of a series of
if-else constructs in the corresponding source code (see Fig-
ure 1). After each if-else block, the control ﬂow joins. In this
example, the machine state needs to be saved at node 1, at
the branch(x) instruction. Then, the ﬁrst path is taken via
node 2. The machine state is saved a second time at node 4
and both the left and the right path are subsequently exe-
cuted (using the state previously saved at node 4). Then, the
execution process is rewinded to the ﬁrst check point, and
continues via the right path (i.e., via node 3). Again, the ma-
chine state needs to be saved at node 4, and both alterna-
tives are followed a second time. Thus a total of four paths
have to be explored as a result of only two branch instruc-
tions.
Also, it is possible that impossible paths are being fol-
lowed. If, in our example, both the branch(x) and the
branch(y) instructions evaluated to the same boolean
value, it would be impossible that execution ﬂows through
nodes 2 and 6, or through nodes 3 and 5. For our prototype,
the path explosion problem and impossible paths have not
caused any difﬁculties (refer to Section 4 for the evaluation
of our system). This is due to the limited size of the kernel
modules. Therefore, we save the machine state at every con-
ditional branch instruction and explore both alternative con-
tinuations.
Another problem is the presence of loops. Because the
machine state is saved at every branch instruction and both
alternatives are explored one after another, the existence of a
loop would prevent the execution process from terminating.
The reason is that both continuations of the branch that cor-
responds to the loop termination condition are explored (i.e.,
the loop body and the code path after the loop). When the
path that follows the loop body eventually reaches the loop
termination condition again, the state is saved a second time.
Then, as usual, both alternative continuations are explored.
One of these continuations is, of course, the loop body that
leads back to the loop termination condition, where the pro-
cess repeats.
To force termination of our symbolic execution process,
it is necessary to remove control ﬂow loops. Note that it is
not sufﬁcient to simply mark nodes in the control ﬂow that
have been previously processed. The reason is that nodes can
be legitimately processed multiple times without the exis-
tence of loops. In the example shown in Figure 1, the sym-
bolic execution processes node 4 twice because of the join-
ing control ﬂows from node 2 and node 3. However, no loop
is present, and the analysis should not terminate prematurely
when reaching node 4 for the second time.
Back-Edge
Figure 2. Control ﬂow graph with loop.
Instead, a more sophisticated algorithm based on the con-
trol ﬂow graph of the binary is necessary. In [1], a suitable
algorithm is presented that is based on dominator trees. This
algorithm operates on the control ﬂow graph and can detect
(and remove) the back-edges of loops. Simply speaking, a
back-edge is the jump from the end of the loop body back to
the loop header, and it is usually the edge that would be iden-
tiﬁed as the “loop-deﬁning-edge” by a human looking at the
control ﬂow graph. For example, Figure 2 shows a control
ﬂow graph with a loop and the corresponding back-edge.
Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC’04) 
1063-9527/04 $ 20.00 IEEE 
For our system, we ﬁrst create a control ﬂow graph of the
kernel module code after it has been preprocessed. Then, a
loop detection algorithm is run and the back-edges are de-
tected. Each conditional branch instruction that has a back-
edge as a possible continuation is tagged appropriately. Dur-
ing symbolic execution, no machine state is saved at these
instructions and processing continues only at the non-back-
edge alternative. This basically means that a loop is executed
at most once by our system. For future work, we intend to re-
place this simple approach by more advanced algorithms for
symbolic execution of loops. Note, however, that more so-
phisticated algorithms that attempt to execute a loop multi-
ple times will eventually hit the limits deﬁned by the halting
problem. Thus, every approach has to accept a certain de-
gree of incompleteness that could lead to incorrect results.
A last problem are indirect jumps that are based on un-
known values. In such cases, it might be possible to heuristi-
cally choose possible targets and speculatively continue with
the execution process there. In our current prototype, how-
ever, we simply terminate control ﬂow at these points. The
reason is that indirect jumps based on unknown values al-
most never occurred in our experiments.
4. Evaluation
The proposed rootkit detection algorithm was imple-
mented as a user space prototype that simulated the object
parsing and symbol resolution performed by the exist-
ing kernel module loader before disassembling the mod-
ule and analyzing the code for the presence of malicious
writes to kernel memory. The prototype implementa-
tion was evaluated with respect to its detection capabil-
ities and performance impact on production systems. To
this end, an experiment was devised in which the proto-
type was run on several sets of kernel modules. Detection
capability for each set was evaluated in terms of false pos-
itive rates for legitimate modules, and false negative rates
for rootkit modules. Detection performance was evalu-
ated in terms of the total execution time of the prototype
for each module analyzed. The evaluation itself was con-
ducted on a testbed consisting of a single default Fedora
Core 1 Linux installation on a Pentium IV 2.0 GHz work-
station with 1 GB of RAM.
4.1. Detection Results
For the detection evaluation, three sets of kernel mod-
ules were created. The ﬁrst set comprised the knark and
adore-ng rootkits, both of which were used during de-
velopment of the prototype. As mentioned previously, both
rootkits implement different methods of subverting the con-
trol ﬂow of the kernel: knark overwrites entries in the sys-
tem call table to redirect various system calls to its own han-
dlers, while adore-ng patches itself into the VFS layer of
the kernel to intercept accesses to the /proc ﬁle system.
Since each rootkit was extensively analyzed during the pro-
totype development phase, it was expected that all malicious
kernel accesses would be discovered.
The second set consisted of a set of seven additional pop-
ular rootkits downloaded from the Internet, described in Ta-
ble 1. Since these rootkits were not analyzed during the pro-
totype development phase, the detection rate for this group
can be considered a measure of the generality of the detec-
tion technique as applied against previously unknown root-
kits that utilize similar means to subvert the kernel as knark
and adore-ng.
The ﬁnal set consisted of a control group of legitimate
kernel modules, namely the entire default set of kernel mod-
ules for the Fedora Core 1 Linux x86 distribution. This
set includes 985 modules implementing various components
of the Linux kernel, including networking protocols (e.g.,
IPv6), bus protocols (e.g., USB), ﬁle systems (e.g., EXT3),
and device drivers (e.g., network interfaces, video cards). It
was assumed that no modules incorporating rootkit function-
ality were present in this set.
Table 2 presents the results of the detection evaluation for
each of the three sets of modules. As expected, all malicious
writes to kernel memory by both knark and adore-ng
were detected, resulting in a false negative rate of 0% for
both rootkits. All malicious writes by each evaluation root-
kit were detected as well, resulting in a false negative rate of
0% for this set. We interpret this result as an indication that
the detection technique generalizes well to previously un-
seen rootkits. Finally, no malicious writes were reported by