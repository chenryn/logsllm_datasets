K-S test
K-S test
Threshold
Prediction
K-S test
Figure 2: Predictor Component
Online testing: The online testing phase for a block of
data from an unauthenticated user begins much in the same
way as the training phase. It undergoes the same preprocess-
ing, with important data selected and parsed into features
making up a test vector D.
It then approaches the Pre-
dictor, wherein the following algorithm takes place (Figure
2). Let Di denote the current test vector generated by the
driver identiﬁcation system. Further let F denote the ﬁn-
gerprint vector. Upon obtaining Di, the predictor estimates
whether or not the user is legitimate by comparing F with
, where D1,
an augment test vector Di
D2,...,Di−1 are the previously collected test vectors.
j∈{1,2,...,i−1} Dj
(cid:2)(cid:3)(cid:2)
(cid:4)
Three metrics are examined after the comparison. The
ﬁrst and second metrics are the similarity calculations d1
and d2 between F and the augment test vector, as measured
by our two comparison tools. In both cases, lower numbers
indicate more similarity. The third metric is the length l of
the augment test vector, i.e., the number of test vectors that
form the augment test vector. For the test vector Di, the
length of the augment test vector is i.
For these three metrics we employ six thresholds. Met-
ric d1 is compared to thresholds t1 low and t1 high, while d1
is compared to t2 low and t2 high. Threshold tboth is com-
pared with the sum of d1 and d2. Finally, threshold tl is
used to limit l. Based on these metrics and thresholds, the
prediction generates the following decisions:
• If both d1 ≤ t1 low and d2 ≤ t2 low are true, the user is
temporarily authorized.
• If one of d1 ≤ t1 low and d2 ≤ t2 low is true, and d1 +
d2 ≤ t3, the user is temporarily authorized.
• In any other case, the user’s identity remains unknown.
• If either d1 > t1 high or d2 > t2 high at any time, then
the user is unauthorized.
If l < tl at this time, and the current driver has been tem-
porarily authorized or remains unknown, then the predictor
continues authentication. The next block of input data is
processed when it arrives to generate the new test vector
Di+1, and the predictor repeats this process to continue au-
(cid:4)
j∈{1,2,...,i} Dj
thentication, i.e., comparing F to Di+1
.
If l ≥ tl, and the above rules resulted in authorization,
the user is identiﬁed as the owner. Otherwise if the user
(cid:2)(cid:3)(cid:2)
428remains unknown, authorization fails and an alert is made.
Appropriate follow-up actions may be taken by the legiti-
mate user.
Comparison tools: We use the well-known Kolmogorov-
Smirnov (K-S) statistical test [18] as well as the total vari-
ation distance [19] to compare the ﬁngerprint and the aug-
ment test vectors. Speciﬁcally, both vectors are made up of
empirical probability distributions in the form of frequency
data stemming from the collected acceleration data. First,
each distribution from the augment test vector undergoes
the K-S test with the respective distribution from the ﬁn-
gerprint vector, returning a conclusion as to whether or not
the two portions of data are from the same distribution.
Second, the distance between the distributions is measured,
which provides an additional metric for their variation. The
diﬀerence between the vectors is ﬁnally calculated using the
total number of features (distributions) in the test vector
which fail the K-S test as well as the sum of their variations.
The speciﬁcs of this calculation and usage of both tests is
covered in 7.3.
5.3 Testing Logistics
We gathered our testing data on a few mobile devices with
the Android operating system, using as previously stated the
acceleration information of the vehicle, to generate our fea-
tures. Using this type of device and these features we were
able to identify users based on their driving data with good
accuracy, as detailed in Section 7 on Evaluation. One strat-
egy for obtaining a GPS location of one’s vehicle is suggested
in an article [20] on the Internet site “wikiHow” and involves
purchasing a smart phone with an elementary cell plan, and
installing it unobtrusively in the car. The idea is that upon
discovering a car theft, the phone’s information can be used
to access its GPS remotely to locate the car [20]. We pro-
pose that these two concepts can be combined:
install a
smart phone in the vehicle with our system implemented on
it, and have it text an alert to the owner’s personal phone
when we detect unauthorized use. This provides prompt
theft detection, owner notiﬁcation, and tracking capability
for recovery by the police. Also, this requires but the most
elemental of smart phones, which are steadily decreasing in
price, so this will be just as aﬀordable as other leading pro-
tection methods, with added beneﬁts.
A second strategy is to implement our theft detection sys-
tem into the car’s computer. While we carried out our test-
ing by using Android devices’ accelerometer and GPS data
to create our features, so we can only comment on the ac-
curacy of this platform, we believe an implementation in
the car’s computer operating system will perform similarly
well. In fact, it will allow for more direct measurement of
the driver’s acceleration preferences by monitoring gas and
brake pedal depression statistics, so similar or greater accu-
racy is likely. We leave this implementation to future work
as we found programming in an Android device was much
more practical than in a car’s computer for this initial re-
search. However, this will very likely change in the near
future as vehicles become smarter, so we are optimistic that
our system can be applied easily to cars in the future. An
exciting indication of this opportunity is the news that vehi-
cles from Audi, Honda, General Motors, and other compa-
nies are beginning to support the Android operating system
as the car’s OS [21].
5.4 False Alarm Handling
Biometric security systems which interface directly with
the owner of the protected system have the unique advan-
tage that the annoyance of false alarms can be minimized
entirely. As our proposed system notiﬁes its owner in the
case of an alarm, false alarms may occur without any impact
other than, say, an unnecessary text message received by the
owner. While driving, the owner should ignore text messages
regardless. This is just one possibility for an alert delivery
system; conceptually, a more appropriate alert method may
be discovered. More importantly, we provide the system
which determines an alert should be made to begin with,
and remark that any kind of alert generated by our system
is more eﬀective than no alert at all.
We strive to maintain low false alarm rates, and the accu-
racy we achieve reﬂects that. We also note that some users
may desire an even more stringent and secure authentication
test. In that context, we emphasize that the chance that the
system does not identify a thief can be minimized by ma-
nipulating the false alarm vs. mis-detection rates. This is
discussed in further detail in Section 7.3 on Threshold Size.
Similarly, we may lower our test thresholds, making the tests
more stringent, and decrease the time required to identify
theft. The resulting false alarm increase, with its very small
increase in annoyance, may be worth the added protection
to some users.
5.5 Mimicry Attacks
To successfully mimic another driver, avoiding detection
by our algorithm, requires a constant attention to several
complex factors. One must regulate each distribution in the
test vector to be the same as the corresponding one in the
ﬁngerprint vector. These distributions come from diﬀerent
sources and apply at diﬀerent velocity ranges. Furthermore,
the measure of ”sameness” is made according to two diﬀerent
tests combined through several diﬀerent rules. Each of these
factors compounds on each other, making it utterly implau-
sible to launch such attacks, even disregarding the diﬃculty
of accessing the data on the owner’s system to study.
6. DRIVING EVENTS AND METRICS
To illustrate the methodology used by our system to clas-
sify users, we begin by describing the collection of data which
we used to prove the concept viable, followed by the process-
ing of this data into elemental driving events.
6.1 Driving Event Types
We identiﬁed six general driving events encountered in a
typical drive:
increasing speed, maintaining speed (cruis-
ing), coasting, braking, turning, and changing lanes. These
are essentially self-explanatory for the high percentage of
the developed world familiar with driving or riding in ve-
hicles. We do however note a key observation that these
events are all types of acceleration, as shown in Figure 3.
Increasing speed is achieved by depressing the gas pedal and
causing positive acceleration along the y-axis of the vehicle.
To maintain speed, the driver keeps a constant depression of
the gas pedal or uses Cruise Control, which keeps a steady
zero acceleration. Coasting involves slight negative accel-
eration from release of the gas pedal and no application of
the brakes. In contrast to coasting, braking invokes a strong
negative acceleration with the car’s brakes. Turning encoun-
ters angular acceleration as force is applied along the x-axis
429Acceleration
d
e
e
p
s
y
x
Turning
Coasting
Braking
Changing lanes
Figure 3: Forces caused by each type of acceleration.
Not shown is cruising, which is deﬁned by a lack of
force.
of the car (perpendicular to the car’s facing direction). Fi-
nally, lane changes encounter, in comparison to full turning,
a slight angular acceleration at the beginning and end of the
movement.
With this in mind, human preferences in performing these
various events are a function of force tolerance, as well as
reasoning and sometimes necessity. For example, approach-
ing a red light with no traﬃc around, an individual will
brake according to comfort, perception of safety, and care
for vehicle integrity, all functions of force tolerance and rea-
son. Similarly, a driver may prefer to stop cruising and start
coasting some distance out from an impasse, such as a stop-
light or wall of traﬃc, to avoid wasting gas, while another
may continue at high speed until braking is obligatory. In
the event of traﬃc, outside inﬂuence is also a factor, caus-
ing some of these events to be more or less eﬀective than
others for identifying personal behavior patterns. It is im-
portant, then, to select those events for which there is the
least outside inﬂuence causing variation in a driver’s behav-
ior. Those events will have the features most unique to each
person. Refer to Feature Selection in Section 7 where this
process is exhibited.
6.2 Speed Effects on Events
We also expect variations in users’ behavior at diﬀerent
speeds. A mistake at high speed, for example, is more dan-
gerous than at low speed, and with this knowledge some
drivers may accept more risk at some speeds than others.
Also, environmental factors such as traﬃc, road conditions,
or weather could force a user to drive at a diﬀerent speed
than preferred. With a single partition holding all data,
a user might appear to favor the habits from the range of
speed most often traveled in, and potentially diﬀerent be-
havior from other speeds will be ignored. With multiple
partitions, the user’s behavior can be determined for each
speed range regardless of the fraction of time spent driving in
that range. We evaluate using speed ranges as sub-features
for our driving events, ultimately assembling our ﬁngerprint
and test vectors from the data on the events for each speed
range. This reduces the impact of the aforementioned envi-
ronmental factors for a more robust system.
As an example, consider Figure 4. Here, the top plot
shows the positive acceleration distributions for two drivers,
from data measured by an accelerometer. Their diﬀerence
is visible, but small. The distributions are farthest apart at
an acceleration of roughly 1.6 m/s2, where 92% of data for
y
t
i
l
i
b
a
b
o
r
P
e
v
i
t
l
a
u
m
u
C
1
0.8
0.6
0.4
0.2
0
−2
Driver 1
Driver 2
0
4
Acceleration Magnitude
2
y
t
i
l
i
b
a
b
o
r
P
e
v
i
t
l
a
u
m
u
C
y
t
i
l
i
b
a
b
o
r
P
e
v
i
t
l
a
u
m
u
C
1
0.8
0.6
0.4
0.2
0
1
0.8
0.6
0.4
0.2
0
−2
−2
Driver 1
Driver 2
0
4
Acceleration Magnitude
2
Driver 1
Driver 2
0
4
Acceleration Magnitude
2
y
t
i
l
i
b
a
b
o
r
P
e
v
i
t
l
a
u
m
u
C
y
t
i
l
i
b
a
b
o
r
P
e
v
i
t
l
a
u
m
u
C
1
0.8
0.6
0.4
0.2
0
1
0.8
0.6
0.4
0.2
0
−2
−2
Driver 1
Driver 2
0
4
Acceleration Magnitude
2
Driver 1
Driver 2
0
4
Acceleration Magnitude
2
Figure 4: Empirical Cumulative Distribution Func-
tions (ECDFs) of two users’ positive acceleration
data (top), followed by ECDFs of that data parti-
tioned by four velocity ranges (lower four charts)
Driver 1 is below this value. Compared to 82% for Driver 2,
there is a 10% diﬀerence here. The four plots below this show
the same two distributions separated by four velocity ranges
(0-20, 20-40, 40-60, and 60+ mph). The ﬁrst partition looks
similar to the full data plot, but the next three show marked
diﬀerences between their respective data and the full data