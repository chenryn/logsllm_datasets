只有两种方法可以管理这些 Swarm 主机和您正在创建的每个主机上的容器，但是首先，您需要了解一些关于它们的信息。
# 查找有关集群的信息
正如我们已经看到的，我们可以使用本地 Docker 客户端列出集群中的节点，因为它已经被配置为连接到 Swarm 管理器主机。我们可以简单地键入以下内容:
```
$ docker info
```
这将为我们提供大量关于主机的信息，正如您可以从下面的输出中看到的，我已经截断了该输出:
```
Containers: 0
 Running: 0
 Paused: 0
 Stopped: 0
Images: 0
Plugins:
 Volume: local
 Network: bridge host macvlan null overlay
 Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog
Swarm: active
 NodeID: uxgvqhw6npr9glhp0zpabn4ha
 Is Manager: true
 ClusterID: pavj3f2ym8u1u1ul5epr3c73f
 Managers: 1
 Nodes: 3
 Orchestration:
 Task History Retention Limit: 5
 Raft:
 Snapshot Interval: 10000
 Number of Old Snapshots to Retain: 0
 Heartbeat Tick: 1
 Election Tick: 10
 Dispatcher:
 Heartbeat Period: 5 seconds
 CA Configuration:
 Expiry Duration: 3 months
 Force Rotate: 0
 Autolock Managers: false
 Root Rotation In Progress: false
 Node Address: 192.168.99.100
 Manager Addresses:
 192.168.99.100:2377
Runtimes: runc
Default Runtime: runc
Init Binary: docker-init
containerd version: 468a545b9edcd5932818eb9de8e72413e616e86e
runc version: 69663f0bd4b60df09991c08812a60108003fa340
init version: fec3683
Kernel Version: 4.9.93-boot2docker
Operating System: Boot2Docker 18.06.1-ce (TCL 8.2.1); HEAD : c7e5c3e - Wed Aug 22 16:27:42 UTC 2018
OSType: linux
Architecture: x86_64
CPUs: 1
Total Memory: 995.6MiB
Name: swarm-manager
ID: NRV7:WAFE:FWDS:63PT:UMZY:G3KU:OU2A:RWRN:RC7D:5ESI:NWRN:NZRU
```
如您所见，在 Swarm 部分有关于集群的信息；但是，我们只能针对我们的客户端当前配置为与之通信的主机运行`docker info`命令。幸运的是，`docker node`命令是集群感知的，因此我们可以使用它来获取集群中每个节点的信息，例如:
```
$ docker node inspect swarm-manager --pretty
```
Assessing the `--pretty` flag with the `docker node inspect` command will render the output in the easy-to-read format you see as follows. If `-- pretty` is left out, Docker will return the raw `JSON` object containing the results of the query the `inspect` command runs against the cluster.
这将为我们的 Swarm 管理器提供以下信息:
```
ID: uxgvqhw6npr9glhp0zpabn4ha
Hostname: swarm-manager
Joined at: 2018-09-15 12:14:59.663920111 +0000 utc
Status:
 State: Ready
 Availability: Active
 Address: 192.168.99.100
Manager Status:
 Address: 192.168.99.100:2377
 Raft Status: Reachable
 Leader: Yes
Platform:
 Operating System: linux
 Architecture: x86_64
Resources:
 CPUs: 1
 Memory: 995.6MiB
Plugins:
 Log: awslogs, fluentd, gcplogs, gelf, journald, json-file, logentries, splunk, syslog
 Network: bridge, host, macvlan, null, overlay
 Volume: local
Engine Version: 18.06.1-ce
Engine Labels:
 - provider=virtualbox
```
运行相同的命令，但这次针对一个工作节点:
```
$ docker node inspect swarm-worker01 --pretty
```
这给了我们类似的信息:
```
ID: yhqj03rkfzurb4aqzk7duidf4
Hostname: swarm-worker01
Joined at: 2018-09-15 12:24:09.02346782 +0000 utc
Status:
 State: Ready
 Availability: Active
 Address: 192.168.99.101
Platform:
 Operating System: linux
 Architecture: x86_64
Resources:
 CPUs: 1
 Memory: 995.6MiB
Plugins:
 Log: awslogs, fluentd, gcplogs, gelf, journald, json-file, logentries, splunk, syslog
 Network: bridge, host, macvlan, null, overlay
 Volume: local
Engine Version: 18.06.1-ce
Engine Labels:
 - provider=virtualbox
```
但是如您所见，它缺少关于管理器功能状态的信息。这是因为工作节点不需要知道管理节点的状态；他们只需要知道他们被允许接受经理的指示。
通过这种方式，我们可以看到关于该主机的信息，例如容器的数量、主机上映像的数量、关于 CPU 和内存的信息，以及其他有趣的信息。
# 提升工作节点
假设您想要在单个管理器节点上执行一些维护，但是您想要维护集群的可用性。没问题；您可以将工作节点提升为管理节点。
当我们启动并运行本地三节点集群时，让我们将`swarm-worker01`提升为新经理。为此，请运行以下命令:
```
$ docker node promote swarm-worker01
```
执行以下命令后，您应该会收到一条消息，确认您的节点已立即升级:
```
Node swarm-worker01 promoted to a manager in the swarm.
```
通过运行以下命令列出节点:
```
$ docker node ls
```
这将向您显示，您现在有两个节点在`MANAGER STATUS`列中显示一些内容:
![](img/9bf51b6f-2de8-49c7-ad01-563f2199b316.png)
但是我们的`swarm-manager`节点仍然是主管理器节点。让我们看看做些什么。
# 降级管理器节点
您可能已经将两个和两个放在了一起，但是要将`demote`管理器节点转换为工作器，您只需运行以下命令:
```
$ docker node demote swarm-manager
```
同样，您将立即收到以下反馈:
```
Manager swarm-manager demoted in the swarm.
```
现在我们已经降级了节点，您可以通过运行以下命令来检查集群中节点的状态:
```
$ docker node ls
```
当您的本地 Docker 客户端仍然指向新降级的节点时，您将收到一条消息，声明如下:
```
Error response from daemon: This node is not a swarm manager. Worker nodes can't be used to view or modify cluster state. Please run this command on a manager node or promote the current node to a manager.
```
正如我们已经了解到的，使用 Docker Machine 更新我们的本地客户端配置以与其他节点通信是很容易的。要将本地客户端指向新的管理器节点，请运行以下命令:
```
$ eval $(docker-machine env swarm-worker01)
```
现在，外部客户端再次与管理器节点对话，请重新运行以下命令:
```
$ docker node ls
```
它应该按照预期列出节点:
![](img/0bf7fe15-6d01-4c87-ad79-c4b55d039cb5.png)
# 清空节点
要从我们的集群中临时删除一个节点以便我们可以执行维护，我们需要将该节点的状态设置为 Drain。让我们看一下清空我们以前的经理节点。为此，我们需要运行以下命令:
```
$ docker node update --availability drain swarm-manager
```
这将停止任何新任务，例如新容器的启动或对我们正在排出的节点执行。一旦新任务被阻止，所有正在运行的任务将从我们正在排出的节点迁移到状态为`ACTIVE`的节点。
从下面的终端输出可以看出，现在列出节点表明`swarm-manager`节点在`AVAILABILITY`列中被列为`Drain`:
![](img/b656b676-0f32-409d-835a-77c2021e4666.png)
现在，我们的节点不再接受新任务，所有正在运行的任务都已迁移到剩下的两个节点，我们可以安全地执行维护，例如重新启动主机。要重新启动 Swarm 管理器，请运行以下两个命令，确保您已连接到 Docker 主机(您应该会看到`boot2docker`横幅，如命令后面的截图所示):
```
$ docker-machine ssh swarm-manager
$ sudo reboot
```
![](img/1cb99ead-ce1e-44aa-aee0-5ccf89af0c0a.png)
主机重新启动后，运行以下命令:
```
$ docker node ls
```
应该显示该节点的`AVAILABILITY`为`Drain`。要将节点重新添加到集群中，只需运行以下命令将`AVAILABILITY`更改为活动状态:
```
$ docker node update --availability active swarm-manager
```
从下面的终端输出可以看出，我们的节点现在是活动的，这意味着可以对它执行新的任务:
![](img/b2d8703d-fc56-4745-8cff-087c167cdb54.png)