Gnucleus also performs worse than Mutella and LimeWire, but better than Gtk-
Gnutella. This is probably because the GWebCache list and the diﬀerent host
lists are not prioritized by age in the Gnucleus implementation.
Figure 2(b) shows the mean bootstrapping times for the three Linux-based
servents at the university location for diﬀerent times of the day. LimeWire and
Mutella perform almost the same throughout the day. Gtk-Gnutella, which does
not diﬀerentiate between ultrapeers and normal peers performs similar to Lime-
Wire and Mutella around noon or late afternoon, when there are more normal
peers online in the system. Early in the morning, with very few normal peers
28
P. Karbhari et al.
Gtk-Gnutella
Limewire
Mutella
1
0.8
0.6
0.4
0.2
s
t
n
e
m
i
r
e
p
x
e
f
o
n
o
i
t
c
a
r
F
0
0
200
400
Time (seconds)
600
800
Fig. 3. Time to receive ﬁrst queryhit
around, Gtk-Gnutella shows a higher mean bootstrapping time. This highlights
the importance of ultrapeer awareness on the part of a Gnutella servent.
Although we started multiple instances of Gnutella servents on the same local
area network, none of our peers were able to discover each other in any one of
our experiments over two weeks. This highlights the lack of Internet location
awareness in the GWebCache system and in the local host list of the servents.
In the next section, we discuss the importance of neighbor peers (resulting
from the bootstrapping process) in the search performance of peers.
4 Importance of Neighbor Peers
A peer gets access to the peer-to-peer network through its directly connected
neighbors. The peers that these neighbors have access to, within an N-hop ra-
dius (usually N=7), comprise the neighborhood of the peer. All query messages
originated by the peer will be forwarded to this neighborhood. The number of
peers in this neighborhood, the types of ﬁles shared, the number of ﬁles shared
amongst all these peers will reﬂect on the search performance of a peer.
We studied the eﬀect of neighbors on search performance of LimeWire, Mu-
tella and Gtk-Gnutella for the the 15 most popular search queries[2]. The per-
formance metric we considered is the time to get the ﬁrst response, which is the
time-lag from when the servent is bootstrapped and issues the query, to the time
when it gets the ﬁrst response. Figure 3 shows the CDF of this response time
for the top 15 queries issued by that servent during any experiment.
We found that there is usually a signiﬁcant variation in the time to get the
initial response. Limewire performs the best, primarily because during bootstrap-
ping it prioritizes ultrapeers, who usually have access to a larger neighborhood.
Mutella and Gtk-Gnutella perform worse, and take more than 5 minutes to give
a result, in about 10% of the experiments.
We conclude that for a good search experience it is very important to have
a set of good neighbors that provide access to many peers, sharing many ﬁles.
Bootstrapping in Gnutella: A Measurement Study
29
GWebCaches Found
Active GWebCaches Found
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
e
m
i
t
f
o
n
o
i
t
c
a
r
F
Hosts at all caches
Unique hosts at each cache
Unique hosts at all caches
100
200
Number of GWebCaches
300
400
0
0
2000
4000
6000
Update rate to all caches(hosts/hour)
8000
10000
12000
1
0.8
s
l
l
o
P
f
o
n
o
i
t
c
a
r
F
0.6
0.4
0.2
0
0
(a) Percentage of active caches
(b) CDF of hostlist update rate
Fig. 4. Cache and host list update rates in all GWebCaches
5 GWebCache Performance
We analyzed the performance of the GWebCache system with reference to the
properties of a good distributed caching infrastructure (e.g., suﬃcient total sy-
stem capacity, good load balancing, reliability of cached items, and physical or
topological proximity of cached items served). With this goal in mind, we per-
formed a measurement study of the system at two levels, globally and locally.
5.1 Global GWebCache System Performance
We studied the global GWebCache system by periodically crawling all the caches.
We sent requests in the format shown in Table 1 to each active cache, according
to the information required. We collected multiple traces over a ﬁve month period
(Apr-Sept 2003), with the goal of answering the following questions.
1. How many GWebCaches does the system comprise of? How many of the
reported caches are active at any time?
We retrieved the cache list every 30 minutes, starting with a seed GWebCache
and crawled the caches returned, until we had polled all reachable caches. We
also determined the number of active GWebCaches by sending Gnutella ping
messages to the crawled list.
Although we found URLs of 1638 unique GWebCaches in 5 months, only
one-fourth of them (403) were active at any time, and at most 220 of them were
active during a single poll. This is quite a low number of reachable GWebCa-
ches, potentially serving about 100000 active hosts4 at any time on the Gnutella
network, only 10% of which accept incoming connections. This indicates that
the GWebCache system might get overloaded.
Figure 4(a) shows the CDF of the number of GWebCaches found during each
of our polls, and the number of caches which were actually active (i.e. responded
to out Gnutella-level ping messages). Most of the time, only about 160 caches
4 As shown by the Limewire[5] hostcount, during the period of our study.
30
P. Karbhari et al.
1
s
e
h
c
a
C
b
e
W
G
f
o
n
o
i
t
c
a
r
F
0.8
0.6
0.4
0.2
0
0
10
20
Maximum rate
Mean rate
Host list
Cache list
1
s
e
h
c
a
C
b
e
W
G
f
o
n
o
i
t
c
a
r
F
0.8
0.6
0.4
0.2
80
90
100
0
0
5000
10000
20000
Request rate (requests/hour)
15000
25000
30000
30
40
Mean update rate (updates/hour)
50
60
70
(a) CDF of update rates
(b) CDF of request rates
Fig. 5. Update and Request rates at a single GWebCache
out of 280, or about 60% were active. This is because the GWebCache system
does not have any means of deleting an introduced cache. Since peers update
caches with URLs of caches they know of (probably even cached from previous
runs), without necessarily knowing whether they are alive or not, it is quite likely
that inactive caches are reported for a long time.
2. What are the access patterns for diﬀerent requests (cache list, host list, and
updates) at diﬀerent GWebCaches? What are the diﬀerences in access patterns
across diﬀerent GWebCaches and in the whole system?
We retrieved the statistics ﬁle every hour from each active GWebCache. The
statistics ﬁle gives the number of update requests and total requests for cache
and host lists the GWebCache received within the last hour.
Figure 5(a) shows the CDF of the mean update rates to the cache and host
lists (determined by analyzing lists retrieved in consecutive polls) at a single
GWebCache. About 80% of the GWebCaches get cache list update rates of 10
per hour or less, while a few caches receive very high update rates, upto 40
updates per hour. About 60% GWebCaches receive host list update rates of less
than 1 per minute, whereas others receive update rates almost twice as much.
Similarly, Figure 5(b) shows the CDF of the mean and maximum total request
rates (as reported by the statistics ﬁles) at a single GWebCache. About 90%
of the GWebCaches receive an average request rate of 3000 per hour or less,
whereas some caches receive extremely high loads of the order of 20000 requests
per hour on an average, with a maximum of 30000 requests per hour.
This points to the disparity in the type of GWebCaches in the system. Some
caches are very busy, with their lists evolving faster and receiving high request
rates, whereas others are relatively lightly loaded. The servents we studied have
some hardcoded GWebCaches, indicating that the request rates to these caches
could be very high. This suggests poor load balancing in the GWebCache system.
3. How does the host list at a single GWebCache and at all GWebCaches
evolve? What percentage of new hosts added to the GWebCaches are unique?
We retrieved the host list from the active GWebCaches every 5 minutes,
and studied its evolution at a particular cache and in the whole system. As
Bootstrapping in Gnutella: A Measurement Study
31
expected, the host list evolves much faster than the cache list in any GWebCache.
During a 15-day period in our study, we saw over 300000 unique IP address:port
combinations in all GWebCaches.
Figure 4(b) shows the CDF of the host update rates at all GWebCaches in
the system. The rightmost line shows the CDF of the host updates received at all
GWebCaches in the system. The dotted line shows the CDF of the host updates
with unique IP address:port combination at each cache. The leftmost curve with
the dashed line shows the CDF of the unique IP address:port combination seen
in the whole system. The average rate for unique IP address:port updates at
a particular GWebCache is lower than the actual update rate at that cache.
The update rate for IP address:port, unique throughout the system is much
lower, almost by a factor of 10. This suggests that the same hosts (presumably
ultrapeers) update the GWebCaches frequently with their IP addresses, leading
to a high replication rate of the same addresses in multiple caches.
4. In the host list returned by the GWebCaches, how many hosts are alive, how
many are accepting Gnutella-level connections, and how many are ultrapeers?
We sent Gnutella-level connect messages to the hosts in the host lists retur-
ned by the GWebCaches. If a TCP connection was established, we determined
that the host was alive. If a Gnutella-level connection was established, we deter-
mined that the host was accepting incoming connections. Out of the hosts that
responded with the proper pong response, we determined whether the host was
an ultrapeer or not, using a ﬁeld X-Ultrapeer: True/False in the response.
When we tried connecting to the hosts in the host lists retrieved, on an
average we found 50% peers online, 16% peers accepting incoming Gnutella-level
connections, and 14% ultrapeers. This shows that a surprisingly low number of
peers indicated in the GWebCaches are actually accepting incoming connections.
This could be a cause for the high bootstrapping times of servents in some
cases, where peers waste time trying to connect to oﬀ-line hosts returned by
the GWebCaches. The reliability of content served by the GWebCache system
is therefore questionable.
Our measurement methodology has several limitations. Since we polled the
GWebCaches starting with a seed GWebCache, we will miss caches in any dis-
connected components of the GWebCache system. Also, between the times we
retrieved the list and tried connecting to the peer, the peer could have gone
oﬄine. We assume that the information returned by the GWebCaches during
our polls is valid (i.e., the GWebCaches are not misconﬁgured or misbehaving).
5.2 Experience of a Local GWebCache
We set up a GWebCache locally by modifying a publicly available PHP script for
the GWebCache v0.7.5[9] to log request arrivals, and advertised it to the global
caching infrastructure. Our cache received update rates of about 7 per hour to
the host list and 4 per hour to the cache list, and request rates of about 15-20
per hour for the host list and 5-10 per hour for the cache list. Comparing these
rates to those of other GWebCaches seen earlier, we can see that our local cache
is used less frequently than the other GWebCaches.
32
P. Karbhari et al.
6 Conclusions
In conclusion, our study highlights the importance of understanding the perfor-
mance of the bootstrapping function as an integral part of a peer-to-peer system.
We ﬁnd that (1) Although servents implement a similar structure for the boot-
strapping algorithm, there is considerable variation among various implementa-
tions, that correlates to their bootstrapping performance. (2) The neighbors of
a peer play an important role in the search performance of the peer. Hence it
is important that the bootstrapping process results in good neighbors. (3) Even
though the GWebCache system is designed to operate as a truly distributed
caching system in keeping with the peer-to-peer system philosophy, it actually
operates more like a centralized infrastructure function, with some GWebCaches
handling a large volume of requests while others are idle. (4) The GWebCache
system is subject to signiﬁcant misreporting of peer and GWebCache availability
due to stale data and absence of validity checks. We further aim to analyze the
eﬀect of bootstrapping on the evolution of the Gnutella topology. These stu-
dies will lead to our ultimate goal of improving the bootstrapping process in
unstructured peer-to-peer networks like Gnutella.
References
1. Saroiu, S., Gummadi, P., Gribble, S.: A measurement study of peer-to-peer ﬁle
sharing systems. In: Proceedings of Multimedia Computing and Networking. (2002)
2. Chu, J., Labonte, K., Levine, B.: Availability and locality measurements of peer-
to-peer ﬁle systems. In: Proceedings of ITCom: Scalability and TraﬃcControl in
IP Networks. (2002)
3. Ng, T.E., Chu, Y., Rao, S., Sripanidkulchai, K., Zhang, H.: Measurement-based
optimization techniques for bandwidth-demanding peer-to-peer systems. In: Pro-
ceedings of IEEE Infocom. (2003)
4. Oram, A.: Peer-To-Peer: Harnessing the Power of Disruptive Technologies. O’Reilly
(2001)
5. LimeWire. (http://www.limewire.com)
6. Mutella. (http://mutella.sourceforge.net)
7. Gtk-Gnutella. (http://gtk-gnutella.sourceforge.net)
8. Gnucleus. (http://www.gnucleus.com)
9. Gnutella Web Caching System. (http://www.gnucleus.com/gwebcache)
10. Ultrapeer Speciﬁcations. (http://www.limewire.com/developer/Ultrapeers.html)
11. Windump. (http://windump.polito.it)