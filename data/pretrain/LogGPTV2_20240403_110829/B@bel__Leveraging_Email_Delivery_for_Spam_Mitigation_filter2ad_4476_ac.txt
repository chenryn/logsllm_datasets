machine). For example, some senders might start send-
ing the email content as soon as they receive a 354 reply,
even if they did not specify the sender and recipients of
the email yet.
Missing replies: These variations aim at exposing the be-
havior of a dialect when the server never sends a reply to
a command.
Message format variations. These variations repre-
sent changes in the format of the replies that the server
sends back to a client. As described in Section 2,
SMTP server replies to a client’s command have the
format CODE TEXT, where CODE repre-
sents the actual response to the client’s command, TEXT
provides human-readable information to the user, and
 is the line terminator. According to the
SMTP speciﬁcation, a client should read the data from
the server until it receives a line terminator, parse the
code to check the response, and pass the text of the reply
to the user if necessary (e.g., in case an error occurred).
Given the speciﬁcation, we craft reply variations in
four distinct ways to systematically study how a client
reacts to them:
Compliant replies: These reply variations comply with
the SMTP standard, but are seldom observed in a com-
mon conversation. For example, this technique might
vary the capitalization of the reply (uppercase/lower-
case/mixed case). The SMTP speciﬁcation states that re-
ply text should be case-insensitive.
Incorrect replies: The SMTP speciﬁcation states that re-
ply codes should always start with one of the digits 2, 3,
4, or 5 (according to the class of the status code), and
be three-digits long. These variations are replies that do
not comply with the protocol (e.g., a message with a re-
ply code that is four digits long). A client is expected
to respond with a QUIT command to these malformed
replies, but certain dialects behave differently.
Truncated replies: As discussed previously, the SMTP
speciﬁcation dictates how a client is supposed to handle
the replies it receives from the server. Of course, it is
not guaranteed that clients will follow the speciﬁcation
and process the entire reply. The reason is that the only
important information the client needs to analyze to de-
termine the server’s response is the status code. Some
dialects might only check for the status code, discarding
the rest of the message. For these reasons, we generate
variations as follows: For each reply, we ﬁrst separate it
into tokens as described in Section 3.1. Then, for each
token, we generate N different variations, where N is
the number of tokens in each reply. We obtain such vari-
ations by truncating the reply with a line terminator after
each token.
Incorrectly-terminated replies: From a practical point of
view, there is no need for a client to parse the full re-
ply until it reaches the line terminator. To assess whether
a dialect checks for the line terminator when receiving
a reply, we terminate the replies with incorrect termina-
tors. In particular, we use the sequences , ,
, and  as line terminators. For
each terminator, similar to what we did for truncated
replies, we generate 4N different variations of each re-
ply, by truncating the reply after every token.
We developed 228 variations to use for our active
probing. More precisely, we extracted the set of replies
that are contained in the Postﬁx 3 source code. Then, we
applied to them the variations described in this section,
and we injected them into a reference SMTP conversa-
tion. To this end, we used the sequence of server replies
from the conversation in Figure 1.
5 Matching Conversations to Dialects
After having learned the SMTP dialects for different
clients, we obtain a different state machine for each
client. Given a conversation between a client and a
server, we want to assess which dialect the client is
speaking. To do this, we merge all inferred dialect state
machines together into a single Decision State Machine
MD.
5.1 Building the Decision State Machine
We use the approach proposed by Wolf [46] to merge the
dialect state machines into a single state machine. Given
two dialects D1 and D2, the approach works as follows:
Step 1: We build the Cartesian product D1×D2. That is,
for each combination of states , where s1 is a
3A
open-source
http://www.postfix.org/
popular
Mail
Transfer
Agent:
Figure 4: An example of decision state machine
state in D1 and s2 is a state in D2, we build a new state
sD in the decision state machine MD.
The label of sD is a table with two columns. The ﬁrst
column contains the identiﬁer of one of the dialects sD
was built from (e.g., D1), and the second column con-
tains the label that dialect had in the original state (either
s1 or s2). Note that we add one row for each of the two
states that sD was built from. For example, the second
state of the state machine in Figure 4 is labeled with a
table containing the two possible message templates that
the clients C1 and C2 would send in that state (i.e., HELO
hostname and HELO domain).
We then check all the incoming transitions to s1 and s2
in the original state machines D1 and D2. For each com-
bination of transitions , where t1 is an incoming
transition for s1 and t2 is an incoming transition for s2,
we check if t1 and t2 have the same label. If they do, we
generate a new transition td, and add it to MD. The label
of td is the label of t1 and t2. The start state of td is the
Cartesian product of the start states of t1 and t2, respec-
tively, while the end state is sD. If the labels of s1 and
s2 do not match, we discard td. For example, a transition
t1 labeled as 250 OK and a transition t2 labeled as 553
Relaying Denied would not generate a transition in
MD. At the end of this process, if sD is not connected
to any other state, it will be not part of the decision state
machines MD, since that state would not be reachable if
added to MD.
Step 2: We reduce the number of states in MD by merg-
ing together states that are equivalent. To evaluate if two
states s1 and s2 are equivalent, we ﬁrst extract the set of
incoming transitions to s1 and s2. We name these sets
I1 and I2. Then, we extract the set of outgoing transi-
tions from s1 and s2, and name these sets O1 and O2.
We consider s1 and s2 as equivalent if |I1| = |I2| and
|O1| = |O2|, and if the edges in the sets I1 and I2, and
in O1 and O2 have the exact same labels.
If s1 and s2 are equivalent, we remove them from MD,
and we add a state sd to MD. The label for sd is a table
composed of the combined rows of the label tables of
s1 and s2. We then adjust all the transitions in MD that
had s1 or s2 as start states to start from sd, and all the
transitions that had s1 or s2 as end states to end at sd.
We iteratively run this algorithm on all the dialects we
learned, and we build the ﬁnal decision state machine
MD. As an example, Figure 4 shows the decision state
machine built from the two dialects in Figure 2. Wolf
shows how this algorithm produces nearly-minimal re-
sulting state machines [46]. Empirical results indicate
that this works well in practice and is enough for our
purposes. Also, as for the dialect state machines, the de-
cision state machine is non-deterministic. This is not a
problem, since we analyze different states in parallel to
make a decision as we explain in the next section.
5.2 Making a Decision
Given an SMTP conversation Con, we assign it to an
SMTP dialect by traversing the decision state machine
MD in the following way:
Step 1: We keep a list A of active states, and a list CD of
dialect candidates. At the beginning of the algorithm, A
only contains the initial state of MD, while CD contains
all the learned dialects.
Step 2: Every time we see a server reply r in Con, we
check each state sa in A for outgoing transitions labeled
with r. If such transition exists, we follow each of them
and add the end states to a list A(cid:48). Then, we set A(cid:48) as the
new active state list A.
Step 3: Every time we see a client command c in Con,
we check each state sa in A. If sa’s table has an entry
that matches c, and the identiﬁer for that entry is in the
dialect candidate list CD, we copy sa to a list A(cid:48). We
then remove from CD all dialect candidates whose table
entry in sa did not match c. We set A(cid:48) as the new active
state list A.
The dialects that are still in CD at the end of the pro-
cess are the possible candidates the conversation belongs
to.
If CD contains a single candidate, we can make a
decision and assign the conversation to a unique dialect.
5.3 Applying the Decision
The decision approach explained in the previous section
can be used in different ways, and for different purposes.
In particular, we can use it to assess to which client a
server is talking. Furthermore, we can use it for spam
mitigation, and close connections whenever a conversa-
tion matches a dialect spoken by a bot.
Similarly to what we discussed in Section 4, the de-
cision process can happen passively, or actively, by hav-
ing a server decide which replies to send to the client.
In the ﬁrst case, we traverse the decision state machine
for each reply, as described in Section 5.2, and end up
with a dialect candidate set at the end of the conversa-
tion. Consider, for example, the decision state machine
in Figure 4. By passively observing the SMTP conver-
sation, our approach is able to discard one of the two
dialects from the candidate set as soon as the client sends
the HELO message. If the commands of the remaining
candidate match the ones in the decision state machine
for that client until we observe the DATA command, we
can attribute the conversation to that dialect. Otherwise,
the conversation does not belong to any learned dialect.
As discussed in Section 4, passive observation gives
no guarantee to uniquely identify a dialect. In this con-
text, a less problematic use case is to deploy this ap-
proach for spam detection: once the candidate set CD
contains only bots, we can close the connection and clas-
sify this conversation as related to spam. As we will
show in Section 7, this approach works well in practice
on a real-world data set.
If passive observation is not
enough to identify a dialect, one can use active probing.
Gain heuristic. To perform active detection, we need
to identify “good” replies that we can send to achieve
our purpose (dialect classiﬁcation or spam mitigation).
More speciﬁcally, we need to ﬁnd out which replies can
be used to expose the deviations in different implementa-
tions. To achieve this goal, we use the following heuris-
tic: For each state ci in which a dialect i reaches the end
of a conversation (i.e., sends a DATA or QUIT command,
or just closes the connection), we assign a gain value gi
to the dialect i in that state. The gain value represents
how much it would help achieve our detection goal if
we reached that state during our decision process. Then,
we propagate the gain values backwards along the tran-
sitions of the decision state machine. For each state s,
we set the gain for i in that state as the maximum of the
gain values for i that have been propagated to that state.
To correctly handle loops, we continue propagating the
gain values until we reach a ﬁxed point. We then calcu-
late the gain for s as the minimum of the gains for any
dialect j in s. We do this to ensure that our decision is
safe in the worst-case scenario (i.e., for the client with
the minimal gain for that state). We calculate the initial
gain for a state in different ways, depending on the goal
of our decision process.
When performing spam mitigation, we want to avoid
a legitimate client from failing to send an email. For this
reason, we strongly penalize failure states for legitimate
clients, while we want to have high gains for states in
which spambots would fail. For each state in which a di-
alect reaches a ﬁnal state, we calculate the gain for that
state as follows: First, we assign a score to each client
with a ﬁnal label for that state (i.e., a QUIT, a DATA, or
a connection closed label). We want to give more impor-
tance to states that make bots fail, while we never want
to visit states that make legitimate clients fail. Also, we
want to give a neutral gain to states that make legitimate
clients succeed, and a slightly lower gain to states that
make bots succeed. To achieve this, we assign a score of
1 for bot failure states, a score of 0 for legitimate clients
failure states, a score of 0.5 for legitimate-client success
states, and a score of 0.2 for bot success states. Notice
that what we need here is a lattice of values that respect
the stated precedence; therefore, any set of numbers that
maintain this relationship would work.
When performing classiﬁcation, we want to be as ag-
gressive as possible in reducing the number of possible
dialect candidates. In other words, we want to have high
gains for states that allow us to make a decision on which
dialect is spoken by a given client. Such states are those
with a single possible client in them, or with different
clients, each one with a different command label. To
achieve this property, we set the gain for each state that
n, where n is the total num-
includes a ﬁnal label as G = d
ber of labels in that state, and d is the number of unique
labels.
Reply selection. At each iteration of the algorithm ex-
plained in Section 5.2, we decide which reply to send
by evaluating the gain for every possible reply from the
states in A. For all the states reachable in one transi-
tion from the states in A, we ﬁrst select the states Sa that
still have at least an active client in their label table. We
group together those states in Sa that are connected to
the active states by transitions with the same label. For
each label group, we pick the minimum gain among the
states in that group. We consider this number as the gain
we would get by sending that reply. After calculating the
gain for all possible replies, we send the reply that has
the highest gain associated to it. In case more than one
reply yields the same gain we pick one randomly.
6 The Botnet Feedback Mechanism
Modern spamming botnets typically use template-based
spamming to send out emails [22,31,38]. With this tech-
nique, the botnet C&C infrastructure tells the bots what
kind of emails to send out, and the bots relay back in-
formation about the delivery as they received it from the
SMTP server. This server feedback is an important piece
of information to the botmaster, since it enables him to
monitor if his botnet is working correctly.
Of course, a legitimate sender is also interested in in-
formation about the delivery process. However, she is
interested in different information compared to the bot-
master.