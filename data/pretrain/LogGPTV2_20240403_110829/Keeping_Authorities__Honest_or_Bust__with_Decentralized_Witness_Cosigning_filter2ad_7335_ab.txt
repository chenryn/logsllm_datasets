For example, an attacker impersonating a legitimate time
service might falsify the current time, to trick a client into
accepting an expired certiﬁcate or other stale credentials.
A timestamping authority [2], [63] enables a client to submit
a cryptographic hash or commitment to some document (e.g.,
a design to be patented), and replies with a signed statement
attesting that the document commitment was submitted at a
particular date and time. The client can later prove to a third-
party that the document existed at a historical date by opening
the cryptographic commitment and exhibiting the authority’s
timestamped signature on it. Virtual Notary [121] generalizes
timestamp services by offering users timestamped attestations
of automatically checkable online facts such as web page
contents, stock prices, exchange rates, etc. An attacker who
steals a timestamp service’s secret keys can forge pre-dated
timestamps on any document, however, and a notary’s secret
key similarly enables an attacker to create legitimate-looking
attestations of fake “facts.”
While witness cosigning incurs communication latencies
that likely preclude its use in ﬁne-grained clock synchro-
nization,
it can serve a complementary role of increasing
the security of coarse-grained timestamps, i.e., giving clients
greater certainty that a timestamp is not hours, days, or years
off. Section V-A later presents a prototype of such a service,
in which many witnesses efﬁciently sanity-check batches of
signed timestamps, ensuring that even an attacker who com-
promises the authority’s secret key cannot undetectably back-
date a timestamp beyond a limited time window.
528528
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:12:54 UTC from IEEE Xplore.  Restrictions apply. 
D. Directory Authorities
The Domain Name System (DNS) [98], [99] offers a critical
directory service for locating Internet hosts by name. Like
NTP, DNS initially included no cryptographic security; even
now the deployment of DNSSEC [6] is limited and weaknesses
remain [7]. The fact that DNSSEC is completely dependent
on the security of its Root Zone [9], which is centrally
managed by one organization, is a concern despite measures
taken to secure the Root Zone’s signing keys [71]. If Root
Zone signatures were witnessed and cosigned by all willing
operators of subsidiary top-level domains (TLDs), ensuring
rapid discovery of any misuse of the Root Zone’s keys,
concerns about DNSSEC’s centralization might be alleviated.
As another example, clients of the Tor anonymity sys-
tem [127] rely on a directory authority [128] to obtain a
list of available anonymizing relays. A compromised Tor
directory authority could give clients a list containing only
attacker-controlled relays, however, thereby de-anonymizing
all clients. To mitigate this risk, Tor clients accept a list
only if it
is signed by a majority of a small consensus
group, currently nine servers. Because these directory servers
and their private directory-signing keys represent high-value
targets for increasingly powerful state-level adversaries [62],
[67], it is questionable whether a small, relatively centralized
group offers adequate security. If Tor directory snapshots were
witness cosigned by a larger subset of the thousands of regular
Tor relays, the risk of semi-centralized directory servers being
silently compromised might be reduced.
E. Software Download and Update Authorities
App stores, community repositories, and automatic software
update services have become essential in patching security
vulnerabilities promptly. Update services themselves can be
attack vectors, however [13], [31], [105], [114]. Even when
updates are authenticated, code signing certiﬁcates are avail-
able on the black market [66], and software vendors have
even leaked their secret keys accidentally [97]. Governments
desiring backdoor access to personal devices [1], [24], as well
as resourceful criminals, might coerce or bribe vendors to sign
and send compromised updates to particular users. These risks
are exacerbated by the fact that automatic update requests can
amount to public announcements that the requesting host is un-
patched, and hence vulnerable [29]. By witness cosigning their
updates and checking cosignatures in auto-update mechanisms,
software vendors might alleviate such risks and ensure the
prompt detection of any improperly signed software update.
F. Public Randomness Authorities
Randomness authorities [103], [110] generate non-secret
random numbers or coin-ﬂips, which are useful for many
purposes such as lotteries, sampling, or choosing elliptic
curve parameters [79]. NIST’s Randomness Beacon [103],
for example, produces a log of signed, timestamped random
values from a hardware source. If compromised, however, a
randomness authority could deliberately choose its “random”
values as to win a lottery, or could look into the future
Authoritative statements: e.g. log records
1 record
2 record
3 record
each statement collectively
signed by both authority
and all or most witnesses
Authority
Witness
Cosigners
Fig. 1. CoSi protocol architecture.
to predict a lottery’s outcome [133]. In the wake of the
DUAL-EC-DRBG debacle [34], the NIST beacon has been
skeptically labeled “the NSANIST Randomness Beacon” [124]
and “Project ‘Not a backdoor’” [111]. While witness cosigning
alone would not eliminate all possibility of bias [20], [79],
witnesses could preclude randomness beacons from revising
history – and by mixing entropy provided by witnesses into
the result, witnesses can ensure that even a compromised
beacon cannot predict or exercise unrestricted control over
future “random” outputs.
III. SCALABLE COLLECTIVE SIGNING
This section presents CoSi, the ﬁrst collective signing pro-
tocol efﬁciently supporting large-scale groups. We ﬁrst outline
CoSi’s high-level principles of operation, then detail its design,
covering a number of challenges such as unavailable witnesses,
cothority certiﬁcate size, denial-of-service (DoS) risks and
mitigations, and statement validation by witnesses.
A. Architecture and Principles of Operation
Figure 1 illustrates CoSi’s conceptual architecture, consist-
ing of an authority who regularly signs statements of any kind
(e.g., chained log records in the example shown), and a group
of witness cosigners who participate in the signing of each
record. We also refer to the group of witnesses as a witness
cothority: a “collective authority” whose purpose is to witness,
validate, and then cosign the authority’s statements.
The authority serves as the CoSi protocol’s leader, deﬁning
and publishing the witness cothority’s composition, initiating
collective signing rounds, and proposing statements to be
signed such as timestamps, directories, or certiﬁcates. We
assume the witnesses to be reliable, independently-run servers
maintained by individuals or organizations who have agreed
to witness the leader’s authoritative statements. Realistic au-
thorities typically serve clients as well: e.g., users requesting
timestamps or certiﬁcates. In the basic CoSi architecture these
clients interact only with the authority (leader) so we will
ignore them for now, although Section V-A will illustrate how
529529
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:12:54 UTC from IEEE Xplore.  Restrictions apply. 
some types of authorities can leverage CoSi to distribute client
servicing load across the many witnesses.
We assume that the authority’s group of witnesses is ﬁxed or
changes slowly, and that all participants including cosignature
veriﬁers know both the authority’s and all witnesses’ public
keys. If the authority is a root CA that signs TLS certiﬁcates
to be veriﬁed by web browsers, for example, then the CA’s
root certiﬁcate shipped with the browser includes a list of the
public keys of the witnesses in addition to the CA’s own public
key. We assume the authority arranges for the witness list to
remain valid for a signiﬁcant time period – e.g., three years
or more, comparable to root certiﬁcate lifetimes – and that
software updates can handle witness list evolution just as for
root certiﬁcates. If the size of the authority’s root certiﬁcate
and its witness list becomes an issue, it may be compressed
into a cryptographic hash of that roster, at a cost of increased
signature sizes as discussed later in Section III-G. For security
reasons discussed later in Section III-D we require that the
public keys of the authority and all witnesses be self-signed
to prove knowledge of the corresponding secret key.
B. Threat Model
We assume both the authority (leader) and some number
of the authority’s witnesses may be malicious and colluding
in attempts to sign malicious statements secretly that unsus-
pecting victims (veriﬁers) will accept, without these malicious
statements being detected by honest witnesses. The CoSi
protocol does not assume or specify any particular global
cosignature veriﬁcation threshold, but from the perspective of a
client who demands at least f +1 cosignatures on a statement,
we assume the attacker controls at most f faulty witnesses.
We assume the authority (leader) is live and highly avail-
able: since it is the participant who wishes to produce wit-
nessed statements, CoSi makes no attempt to protect against
DoS by the leader. However, we assume that a threshold
number of witnesses may go ofﬂine at any time or even
engage in DoS attacks; this threshold is a policy parameter
deﬁned by the leader. Witnesses may also maliciously produce
incorrect messages deviating from the protocol, e.g., in attempt
to trick the leader into misbehavior. While for now we assume
simple numeric thresholds, clients can impose more complex
veriﬁcation predicates if desired (Section IV-A).
We assume the leader and all witnesses are generally able to
communicate with each other, apart from temporary communi-
cation outages. Unlike gossip-based transparency approaches,
however, we do not assume that clients verifying signatures
can communicate with any non-attacker-controlled parties.
C. Responsibilities of Cosigning Witnesses
The authority determines when to initiate a collective sign-
ing round, and broadcasts to all witnesses the statement to
be signed. Witnesses may, and ideally should, publish logs
of the statements they witness and cosign, thus serving a
transparency role similar to log servers in CT [76], [78]. If
the authority’s statements are already supposed to take the
form of a log as in the example in Figure 1, then each witness
might simply make available a public mirror of all or some
recent portion of the authority-generated log.
Witnesses may also, and ideally should, perform any readily
feasible syntactic and semantic correctness checks on the au-
thority’s proposed statements before “signing off” on them. If
the authority’s statements include a wall-clock timestamp, for
example, each witness may verify that the proposed timestamp
is not wildly different from the witness’s view of the current
time (e.g., is not minutes or hours off). If the authority’s
statements form a sequence-numbered, hash-chained log as in
Figure 1, each witness may verify that each of the authority’s
proposed log records contains a monotonically increasing
sequence number and the correct hash for the immediately
preceding log record, preventing a compromised authority
from reversing or rewriting history.1
Witnesses might check deeper application-speciﬁc invari-
ants as well, provided these checks are quick and automatic.
If the authority’s statements represent certiﬁcates, witnesses
may check them against any known issuance policies for
the relevant domain [126]. If the authority’s statements attest
certiﬁcate freshness [107] or represent directories of currently-
valid certiﬁcates as in CONIKS [89], witnesses may verify
that
these certiﬁcates do not appear on cached certiﬁcate
revocation lists (CRLs) [82]. If the authority’s statements form
a blockchain [102], then witnesses may check its validity:
e.g., that each transaction is properly formed, properly au-
thorized, and spends only previously-unspent currency [70].
If the authority’s statements represent software binaries [116],
then witnesses might even attempt to reproduce the proposed
binaries from developer-signed sources [16], provided the
authority allows the witnesses the time required (possibly
hours) to perform such builds during signing process.
For simplicity, we initially assume that witnesses never fail
or become disconnected, but relax this unrealistic assumption
later in Section III-F. We also defer until later performance
concerns such as minimizing collective signing latency.
D. Schnorr Signatures and Multisignatures
While CoSi could in principle build on many digital sig-
nature schemes that support efﬁcient public key and signa-
ture aggregation, we focus here on one of the simplest and
most well-understood schemes: Schnorr signatures [118] and
multisignatures [12], [93]. Many alternatives are possible:
e.g., Boneh-Lynn-Shacham (BLS) [19] requires pairing-based
curves, but offers even shorter signatures (a single elliptic
curve point), and a simpler protocol that may be more suitable
in extreme situations as discussed later in Section IV-E.
Schnorr signatures rely on a group G of prime order q in
which the discrete logarithm problem is believed to be hard;
in practice we use standard elliptic curves for G. Given a well-
known generator G of G, each user chooses a random secret
1 Even with these checks a faulty authority could still equivocate to
produce two or more divergent histories cosigned by disjoint subsets of honest
witnesses. Applying standard Byzantine consensus principles [33], however,
the above log consistency checks will preclude equivocation provided at most
f witnesses are faulty out of at least 3f +1 total, and provided veriﬁers check
that at least 2f + 1 witnesses have cosigned each statement.
530530
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:12:54 UTC from IEEE Xplore.  Restrictions apply. 
(cid:2)
i
key x < q, and computes her corresponding public key X =
Gx. We use multiplicative-group notation for consistency with
the literature on Schnorr signatures, although additive-group
notation may be more natural with elliptic curves.
(cid:3)
= GrX c and checking that c ?
Schnorr signing is conceptually a prover-veriﬁer or Σ-
protocol [40], which we make non-interactive using the Fiat-
Shamir heuristic [56]. To sign a statement S, the prover picks
a random secret v < q, computes a commit, V = Gv, and
sends V to the veriﬁer. The veriﬁer responds with a random
challenge c < q, which in non-interactive operation is simply a
cryptographic hash c = H(V (cid:3) S). The prover ﬁnally produces
a response, r = v−cx, where x is the prover’s secret key. The
challenge-response pair (c, r) is the Schnorr signature, which
anyone may verify using the signer’s public key X = Gx, by
= H(V (cid:2) (cid:3) S).
recomputing V (cid:2)
With Schnorr multisignatures [106], there are N signers
with individual secret keys x1, . . . , xN and corresponding
public keys X1 = Gx1 , . . . , XN = GxN . We compute an
aggregate public key X from the individual public keys as
xi. The N signers collectively sign a
X =
statement S as follows. Each signer i picks a random secret
vi < q, and computes a commit Vi = Gvi. One participant
(e.g., a leader) collects all N commits, aggregates them into
i Vi, and uses a hash function to
a collective commit V =
compute a collective challenge c = H(V (cid:3) S). The leader
distributes c to the N signers, each of whom computes and
returns its response share ri = vi − cxi. Finally, the leader
i ri, to form the
aggregates the response shares into r =
collective signature (c, r). Anyone can verify this constant-size
signature against the statement S and the aggregate public key
X via the normal Schnorr signature veriﬁcation algorithm.
i Xi = G
When forming an aggregate public key X from a roster
of individual public keys X1, . . . , XN , all participants must
validate each individual public key Xi by requiring its owner
i to prove knowledge of the corresponding secret key xi, e.g.,
with a zero-knowledge proof or a self-signed certiﬁcate. Other-
wise, a dishonest node i can perform a related-key attack [94]
against a victim node j by choosing Xi = Gxi X−1
, and
thereafter contribute to collective signatures apparently signed
by j without j’s actual participation.
(cid:3)
(cid:2)
j
While multisignatures are well-understood and formally
analyzed, to our knowledge they have so far been used or
considered practical only in small groups (e.g., N ≈ 10).
The next sections describe how we can make multisignatures
scale to thousands of participants, and address the availability
challenges that naturally arise in such contexts.
E. Tree-based Collective Signing
To make multisignatures scale to many participants, CoSi
distributes the communication and computation costs of mul-
tisignatures across a spanning tree analogous to those long
utilized in multicast protocols [32], [42], [131]. The leader
organizes the N witnesses into a spanning tree of depth
O(log N ) rooted at the leader, distributing both communica-
tion and computation to incur at most logarithmic costs per