possible value for wijâˆ’1: either xâ„“ if iâ„“ = ij, or yâ„“ if iâ„“ = ij âˆ’ 1.
Therefore, wijâˆ’1 is distributed uniformly over the remaining values,
of which there are at most N âˆ’ (j âˆ’ 1). Specifically wijâˆ’1 is equal to
xj, which is a function of all the previous replies y1, . . . , yjâˆ’1, with
probability at most
1
Overall,
Pr
H,x0
Nâˆ’j+1.
[A loses] â‰¥ T +1
â‰¥ T +1
j=1
(cid:18)
(cid:18)
j=1
(cid:19)
1 âˆ’ 1
N
âˆ’
N âˆ’ j + 1
1 âˆ’
2
N âˆ’ j + 1
.
1
(cid:19)
We note that this is a telescopic product, which simplifies to
(N âˆ’ T âˆ’ 2)(N âˆ’ T âˆ’ 1)
N(N âˆ’ 1)
â‰¥ N 2 âˆ’ (2T + 3)N
N 2
and therefore,
[A wins] â‰¤ 2T + 3
N
.
Pr
H,x0
â–¡
Theorem 4.2 establishes the difficulty of finding a preimage of
the last iterate of the hash chain. For T/Key, we also need to bound
the success probability of attacks that â€œguessâ€ a preimage of the
entire chain.
6
N
(cid:104)
Pr
h1, ...,hk âˆˆâ„±N
h[1,k]
Corollary 4.3. Let functions h1, . . . , hk âˆˆ [N] â†’ [N] be chosen
independently and uniformly at random. Let A be an algorithm that
gets oracle access to each of the functions {hi}k
i =1 and makes at most
T oracle queries overall. Then,
(cid:16)
A(h[1,k](x0))(cid:17)
= h[1,k](x0)(cid:105) â‰¤ 2T + 2k + 1
.
(cid:17)
(cid:16) T
x0âˆˆ[N]
Proof. Let A be an algorithm as in the statement of the corollary.
We use it to construct an algorithm Aâ€² that finds a preimage of the
last iterate of the hash chain (as in the statement of Theorem 4.2).
On input y, algorithm Aâ€² runs algorithm A to get a point z and
then computes and outputs zâ€² = h[1,kâˆ’1](z). If h[1,k](z) = h[1,k](x),
then hk(zâ€²) = h[1,k](x). Moreover, algorithm Aâ€² makes at most
T â€² = T + k âˆ’ 1 queries to its oracles. Therefore by Theorem 4.2, its
success probability is at most (2T â€² + 3)/N = (2T + 2k + 1)/N . â–¡
Optimality. One might ask whether the above lower bound is
tight. Perhaps composing k independent hash functions not only
avoids some of the problems associated with using a hash chain
derived by composing the same hash function, but actually results
in a function that is k times more difficult to invert than the basic
hash function. Ideally, one might have hoped that the probability
.
of inverting the hash chain in T queries would be at most O
However, this is not the case, because every iteration of the hash
chain introduces additional collisions and shrinks the domain of
the function at a rate of 1/k, where k = o(N) is the length of the
chain (see Lemma A.1 for a proof sketch). An attacker can use these
collisions to her advantage. Consider an attack that evaluates the
chain on T/k random points in its domain (at a total cost of T hash
computations). Lemma A.4 shows that a point in the image of the
hash chain has k preimages in expectation. Therefore, each of the
T/k randomly chosen points collides with the input under the chain
with probability k/N , and so the overall success probability of the
attack is roughly T/N .
4.2 Security of T/Key
Our threat model assumes the adversary can repeatedly gain ac-
cess to the server and obtain all information needed to verify the
password. The adversary can also obtain multiple valid passwords
at times of his choice. Finally, we allow the adversary to choose the
time when he makes his impersonation attempt. To mitigate pre-
processing attacks, we salt all our hash functions (in Section 8, we
discuss preprocessing attacks in more detail, including the extent
to which salting helps prevent them).
k N
Non-threats. First, we assume that there is no malware on the
phone or on the userâ€™s laptop. Otherwise, the userâ€™s session can
be hijacked by the malware, and strong authentication is of little
value. Second, because the channel between the laptop and the
authentication server is protected by TLS, we assume there is no
man-in-the-middle on this channel. Third, all TOTP schemes are
susceptible to an online phishing attack where the attacker fools the
user into revealing her short-lived one-time password to a phishing
site, and the attacker then immediately authenticates as the user,
within the allowable short window. This is a consequence of the
requirement for one-way communication with the authentication
token (the phone). Note however that the limited time window
makes the exploitation of credentials time-sensitive, which makes
the attack more complicated.
We begin by presenting a formal definition of security. Our defi-
nitions are based on standard definitions of identification protocols
(see, for example, [57]).
Definition 4.4 (Time-based One-Time Password Protocol). A one-
time password protocol is a tuple â„ = (pp, keygen, P, V) where
â€¢ Public parameter generator pp(1Î», k) â†’ n is a polynomial
time algorithm that takes as input the security parameter
in unary along with the maximal supported authentication
period k and outputs the password length n.
â€¢ Key generator keygen(n, k) â†’ (sk, vst) is a probabilistic
polynomial time algorithm that takes as input the parame-
ters, n and k, and outputs the proverâ€™s secret key sk and the
initial verifier state vst.
â€¢ Prover P(sk, t) â†’ pt is a polynomial time algorithm, which
takes as input the proverâ€™s secret key sk, and a time t âˆˆ [1, k],
and outputs a one-time password p.
â€¢ Verifier V(vst, p, t) â†’ (accept/reject, vstâ€²) is a polyno-
mial time algorithm, which takes as input the previous state
vst, a password p, and time t âˆˆ [1, k] and outputs whether
the password is accepted and the updated verifier state vstâ€².
For correctness, we require that when executed on monotonically
increasing values of t with the state vst properly maintained as de-
scribed above, the verifier V(vst, P(sk, t), t) always outputs accept.
We now proceed to define the security game, where we use the
random oracle model [4].
Attack Game 4.5. Let â„ be a time-based one-time password proto-
col, and let ğ’ª be a random oracle. Given a challenger and an adversary
A, the attack game runs as follows:
â€¢ Public Parameter Generation â€“ The challenger generates
n â† pp(1Î», k).
â€¢ Key Generation Phase â€“ The challenger generates
(vk, sk) â† keygenğ’ª(n, k), given access to the random oracle.
â€¢ Query Phase â€“ The adversary runs the algorithm A, which
is given the verifierâ€™s initial state vst as well as the ability to
issue the following types of (possibly adaptive) queries:
â€“ Password Queries: The adversary sends the challenger a time
value t.
The challenger generates the password p â† P ğ’ª(t, sk), feeds
it to the verifier to obtain (accept, vstâ€²) â† V ğ’ª(t, vst, p),
updates the stored verifier state to vstâ€², and sends p to the
adversary.
a point x, and the challenger replies with ğ’ª(x).
â€“ Random Oracle Queries: The adversary sends the challenger
The above queries can be adaptive, and the only restriction is
that the values of t for the password queries must be monoton-
ically increasing.
â€¢ Impersonation attempt â€“ The adversary submits an identifica-
tion attempt (tattack, pattack), such that tattack is greater than
all previously queried password values.
We say that the adversary A wins the game if V ğ’ª(vst, pattack, tattack)
outputs accept. We let AdvA(Î») denote the probability of the adver-
sary winning the game with security parameter Î», where the proba-
bility is taken over the random oracle as well as the randomness in
the key generation phase.
We are now ready to prove that T/Key is secure. Specifically,
given an adversary that makes at most T queries, we establish an
upper bound on the advantage the adversary can have in breaking
the scheme. We note that no such result was previously known for
the original S/Key scheme, and the key ingredient in our proof is
Theorem 4.2.
Theorem 4.6 (Security of T/Key). Consider the T/Key scheme
with password length n and maximum authentication period k. Let A
be an adversary attacking the scheme that makes at most T random
oracle queries. Then,
AdvA â‰¤ 2T + 2k + 1
2n
.
Proof. First, recall that our scheme uses a hash function H :
{0, 1}m â†’ {0, 1}m to get k functions h1, . . . , hk : {0, 1}n â†’
{0, 1}n, where hi(x) = H(tinit + k âˆ’ iâˆ¥idâˆ¥x)|n. In the random or-
acle model, we instantiate H using the random oracle, and so the
resulting k functions, h1, . . . , hk, are random and independent.
Without loss of generality, we assume that tinit = 0 and that the
latest password requested by the adversary is the top of the chain
pk (since the functions h1, . . . , hk are independent, any random
oracle or password queries corresponding to times earlier than the
latest requested password do not help the adversary to invert the
remaining segment of the chain).
By definition, the verifier accepts (tattack, pattack) if and only if
h[kâˆ’tattack+1,k](pattack) = h[1,k](sk). Therefore, if the adversary wins
the game, it must hold that at least one query qj âˆˆ R collides with
W . The proof then follows from Corollary 4.3.
â–¡
Concrete Security. With this result at hand, we compute the pass-
word length required to make T/Key secure. For moderate values
of k (say, negligible in 2n), to make our scheme as secure as a Î»-bit
random function, it is enough to set n = Î» + 2, since then, assuming
k < T ,
AdvA â‰¤ 2T + 2k + 1
2n
â‰¤ 4T
2Î»+2
= T
2Î»
.
For standard 128-bit security, we require passwords of length 130
bits.
5 CHECKPOINTING FOR EFFICIENT HASH
CHAIN TRAVERSAL
In our scheme, the client stores the secret sk, which is used as
the head of the hash chain. In the password generation phase, as
described in Section 3, the client must compute the value of the
node corresponding to the authentication time each time it wishes
to authenticate. A naive implementation would simply traverse the
hash chain from the head of the chain all the way to the appropriate
node. Since T/Key uses long hash chains, this approach could lead
to undesirable latency for password generation. To decrease the
number of hashes necessary to generate passwords, the client can
store several values (called â€œpebbles") corresponding to various
points in the chain.
7
There exist multiple techniques for efficient hash chain traversal
using dynamic helper pointers that achieve O(log n) computation
cost per chain link with O(log n) cells of storage [13, 33]. However,
there are two key differences between the goals of those schemes
and our requirements.
(1) These techniques all assume sequential evaluation of the
hash chain, whereas in our scheme, authentication attempts
are likely to result in an access-pattern containing arbitrary
gaps.
(2) Previous schemes aim to minimize the overall time needed
to take a single step along the hash chain, which consists
of two parts: the time needed to fetch the required value in
the hash chain, and the time needed to reposition the check-
points in preparation for fetching the future values. In our
setting, however, it makes sense to minimize only the time
needed to fetch the required hash value, potentially at the
cost of increasing the time needed to reposition the check-
points. This is reasonable since the gaps between a userâ€™s
authentication attempts provide ample time to reposition
the checkpoints, and it is the time to generate a password
that is actually noticeable to the user.
If the userâ€™s login behavior is completely unpredictable, we can
minimize the worst-case password generation time by placing the
checkpoints at equal distances from one another. We call this the
naÃ¯ve checkpointing scheme. However, in many real-world sce-
narios, user logins follow some pattern that can be exploited to
improve upon the naÃ¯ve scheme.
To model a userâ€™s login behavior, we consider a probability dis-
tribution that represents the probability that the user will next
authenticate at time t (measured in units of time slots) given that it
last authenticated at time 0. Additionally, we let each node in the
hash chain be indexed by its distance from the tail of the chain and
let â„“ be the index of the head of the chain (i.e., â„“ is the length of the
remaining part of the hash chain). In this model, valid future login
times are the integers {1, 2, . . . , â„“}, and each node in the hash chain
is indexed by the corresponding login time. By this, we mean that
the valid password at time t is the value at node t. This notation is
illustrated in Fig. 3.
1
0
Tail
Â· Â· Â·
Time
â„“ âˆ’ 1
â„“
Head
Figure 3: The hash chain with time-labeled nodes.
The problem is then to determine where to place q checkpoints,
0 â‰¤ c1 â‰¤ c2 â‰¤ . . . â‰¤ cq < â„“, in order to minimize the expected
computation cost of generating a password. We note that if the
client authenticates at time t and ci is the closest checkpoint to t
with ci â‰¥ t, then the computational cost of generating the password
is ci âˆ’ t. If no such checkpoint exists, then the cost is â„“ âˆ’ t. We do
not take into account the number of additional hash computations
required to reposition the checkpoints after generating a password.
In order to make the analysis simpler, we relax the model from
a â€œdiscreteâ€ notion of a hash chain to a â€œcontinuousâ€ one. By this,
we mean that we make the probability distribution modeling the
clientâ€™s next login time continuous and allow the checkpoints to
be stored at any real index in the continuous interval (0, â„“]. Ad-
ditionally, we allow authentications to occur at any real time in
F(t) =âˆ« t
(0, â„“]. Formally, let p(t) be the probability density function (pdf)
of this distribution with support over the positive reals and let
0 p(t)dt be its cumulative distribution function (cdf). We
can then express the computational cost C in terms of the check-
âˆ« c1
points by the formula
âˆ« c2
âˆ« â„“
(c2 âˆ’ t)p(t)dt + . . . +
(â„“ âˆ’ t)p(t)dt
C =
(c1 âˆ’ t)p(t)dt +
0
cq
= c1F(c1) + c2(F(c2) âˆ’ F(c1)) + . . . + â„“(F(â„“) âˆ’ F(cq)) âˆ’
c1
tp(t)dt .
âˆ« â„“
0
In order to determine the values of the ciâ€™s that minimize C, we
take the partial derivatives âˆ‚C
for each variable and set them equal
âˆ‚ci
to 0. This gives the following system of equations:
F(c1)
p(c1) = c2 âˆ’ c1
F(c2) âˆ’ F(c1)
= c3 âˆ’ c2
p(c2)
...
F(cq) âˆ’ F(cqâˆ’1)
p(cq)
= â„“ âˆ’ cq .
(1)
(2)
(3)
(4)
Solving these equations yields the values of the ciâ€™s that minimize
C, which we then round to the nearest integer, since checkpoints
can only be placed at integer coordinates. We refer to this as the
expectation-optimal solution.
Depending on the specific distribution, this system of equations
may or may not be numerically solvable. If necessary, one can
simplify the problem by replacing the set of dependent multivariate
equations with a set of independent univariate equations. This is
done using the following recursive approach. We first place a single