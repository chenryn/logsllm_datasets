The metric `maxImprove a_AW(u)` indicates the maximum improvement in a user's behavior, with values ranging from 0.75 to 1.0 (represented by the rightmost, white bars in the histograms) indicating significant improvement, and values from 0 to 0.25 (represented by the dark gray bars closest to the y-axis) indicating minimal improvement. Unfortunately, it appears that minimal improvement was more common. This is not entirely surprising, as even a single instance where a user mistakenly leaks their password can result in a high value for `maxLeaked a_AW(u)`, which cannot be offset by numerous mistake-free logins. However, we are encouraged by the users who showed substantial improvement.

Reflecting on these results, one key lesson is that training in a real-world deployment should perhaps require users to repeat logins where they would have leaked password characters to malware, had it been present. In our Attack-and-Warn system, we only warned users but allowed them to proceed to the course web page if they entered the correct password. We considered forcing users to repeat logins where they leaked characters, but we were concerned that such an approach might be too heavy-handed and could lead to participant withdrawal or instructor protest. In a security-conscious organization, however, this approach might be justified.

To further measure the training effect of the warning messages, we analyzed the exit questionnaire. The questionnaire included a question for each type of attack, asking whether the warning message helped the user avoid falling for the same attack in the future. A screenshot of the warning message was provided, along with a five-level Likert scale ranging from 1 (Strongly Disagree) to 5 (Strongly Agree), and an additional option for users who did not read the warning message. To test the null hypothesis that user responses and actual performance are not correlated, we compared the responses with the number of times the user saw the warning message. We first removed all users who never saw the warning message and then excluded those who did not read the message. On the remaining data, we conducted our analysis.