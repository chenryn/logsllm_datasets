title:Delving into internet streaming media delivery: a quality and resource
utilization perspective
author:Lei Guo and
Enhua Tan and
Songqing Chen and
Zhen Xiao and
Oliver Spatscheck and
Xiaodong Zhang
Delving into Internet Streaming Media Delivery: A Quality
and Resource Utilization Perspective
Lei Guo1, Enhua Tan1, Songqing Chen2, Zhen Xiao3, Oliver Spatscheck4, and Xiaodong Zhang1
1Department of Computer Science and Engineering
The Ohio State University
Columbus, OH 43210, USA
{lguo, etan, zhang}@cse.ohio-state.edu
3IBM T. J. Watson Research Center
19 Skyline Drive
Hawthorne, NY 10532, USA
PI:EMAIL
2Department of Computer Science
George Mason University
Fairfax, VA 22030, USA
PI:EMAIL
4AT&T Labs-Research
180 Park Ave.
Florham Park, NJ 07932, USA
PI:EMAIL
ABSTRACT
Modern Internet streaming services have utilized various
techniques to improve the quality of streaming media deliv-
ery. Despite the characterization of media access patterns
and user behaviors in many measurement studies, few stud-
ies have focused on the streaming techniques themselves,
particularly on the quality of streaming experiences they of-
fer end users and on the resources of the media systems
that they consume.
In order to gain insights into cur-
rent streaming services and thus provide guidance on de-
signing resource-eﬃcient and high quality streaming media
systems, we have collected a large streaming media work-
load from thousands of broadband home users and business
users hosted by a major ISP, and analyzed the most com-
monly used streaming techniques such as automatic protocol
switch, Fast Streaming, MBR encoding and rate adaptation.
Our measurement and analysis results show that with these
techniques, current streaming systems tend to over-utilize
CPU and bandwidth resources to provide better services to
end users, which may not be a desirable and eﬀective way
to improve the quality of streaming media delivery. Moti-
vated by these results, we propose and evaluate a coordina-
tion mechanism that eﬀectively takes advantage of both Fast
Streaming and rate adaptation to better utilize the server
and Internet resources for streaming quality improvement.
Categories and Subject Descriptors
C.2 [Computer Communication Networks]: Dis-
tributed Systems
General Terms
Measurement
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
IMC’06, October 25–27, 2006, Rio de Janeiro, Brazil.
Copyright 2006 ACM 1-59593-561-4/06/0010 ...$5.00.
Keywords
Traﬃc analysis, Multimedia streaming
1.
INTRODUCTION
The Internet has witnessed the surge of multimedia con-
tent from many application areas such as education, med-
ical research and practice, news media, and entertainment
industries [13]. Although the majority of media traﬃc on
the Internet is delivered via downloading, pseudo stream-
ing, and P2P techniques, streaming service is superior in
handling thousands of concurrent streams simultaneously,
ﬂexible responses to network congestion, eﬃcient bandwidth
utilization, and high quality performance [17]. Diﬀerent
from downloading or pseudo streaming small sized video
clips from a Web site such as YouTube [9], streaming long
duration and high quality media objects on the Internet has
several unique challenges. First, streaming services usually
require high and stable end-to-end bandwidth between a
media server and its clients. Due to the lack of Quality
of Service (QoS) guarantee on the packet switching based
Internet, the quality of Internet media streaming may sig-
niﬁcantly degrade due to bandwidth ﬂuctuations during a
streaming session, especially for delivering high quality video
such as HDTV. Second, the connection speed of Internet end
users ranges from slow dial-up connections to T1 or high
speed cable network services. Thus, a ﬁxed encoding rate
for a media object is not desirable for clients with diverse
network connections. Third, streaming media users always
expect a small startup latency. However, due to the dy-
namics on the media server load and network bandwidth, a
client may experience a prolonged startup delay. In addi-
tion, the ﬁlling of the client play-out buﬀer, which is used
to smooth jitter caused by network bandwidth ﬂuctuations,
further increases the user’s waiting time. With these chal-
lenges, a lot of studies have been conducted on the eﬀective
utilization of server and Internet resources to deliver high
quality streaming media.
Today, more than 90% of streaming media traﬃc on the
Internet is delivered either through Windows media services
or RealNetworks media services [17]. These commercial
streaming services have adopted various techniques to ad-
dress the above challenges and to satisfy the ever-increasing
quality demands of users, such as TCP and HTTP based
streaming, Fast Streaming, multiple bit rate (MBR) encod-
ing and rate adaptation. Due to the wide deployment of Net-
work Address Translation (NAT) routers and ﬁrewalls that
often prevent UDP packet transversal, TCP-based stream-
ing has been widely used and now accounts for the majority
of Internet streaming traﬃc [17, 26]. Fast Streaming [2]
is a group of techniques supported by the Windows media
service, which aggressively utilizes the Internet bandwidth
by delivering a media object at a rate much higher than
its encoding rate, in order to minimize the user perceived
startup latency and guard against potential network band-
width ﬂuctuations. MBR encoding is a technique that en-
codes a media object with multiple bit rates so that the
streaming server can deliver the same content with diﬀerent
quality to clients with diﬀerent network connections. MBR
encoding also enables dynamic stream switch among streams
of diﬀerent rates encoded in the object during a user session,
in order to adapt to the current bandwidth, which is called
Intelligent Streaming [4] in the Windows media service and
SureStream [7] in the RealNetworks media service.
In spite of the wide deployment of these techniques, exist-
ing measurement studies of Internet streaming media mainly
focus on the characterization of media access patterns and
user behaviors, such as [10, 12, 13, 15, 31], which is helpful
to the design of media delivery systems such as server clus-
ters and media proxies [11, 30]. However, the mechanisms
of the commonly and practically used streaming techniques
themselves and their eﬀects on improving Internet streaming
quality have not yet been thoroughly studied, which is nec-
essary to understand state-of-the-art of Internet streaming
media and to provide guidance on future Internet stream-
ing services. Despite several experimental studies in lab en-
vironments on the Windows and RealNetworks media sys-
tems [14, 22], to the best of our knowledge, to date, there is
no comprehensive study on the delivery quality and resource
utilization of these streaming techniques in the Internet en-
vironment. It is highly desirable for both streaming service
providers and system designers to be guided with an insight-
ful understanding of existing Internet streaming techniques.
In order to investigate Internet streaming quality and
the eﬃciency of resource utilization with the deployment
of these techniques, in this work, we have collected a 12-day
streaming media workload from a large ISP in the United
States. The workload covers thousands of broadband home
users and hundreds of business users who access both on-
demand and live streaming media. Through extensive anal-
ysis of the majority of TCP-based streaming traﬃc on the
Internet, we have the following observations:
(cid:129) We found that the overhead of protocol rollover plays
an important role in user perceived startup latency,
and thus may have aﬀected the way that media is
served by content providers. When UDP is not sup-
ported, the overhead of protocol rollover from UDP
to TCP contributes a non-trivial delay to the client
startup latency. More than 22% of protocol rollover is
longer than 5 seconds.
(cid:129) By aggressively utilizing the Internet network band-
width, Fast Streaming shows both positive and neg-
ative features. Although Fast Streaming can help
smooth re-buﬀering jitter, it over-supplies media data
to end users by about 55%, and consumes more CPU
resources, which leads to a longer server response time.
(cid:129) MBR-encoding is widely used in media authoring, and
nearly half of streaming video and audio objects on the
Internet are MBR-encoded. However, the rate adap-
tation functionality of MBR is poorly utilized, partic-
ularly when Fast Streaming is used.
(cid:129) Overall, on the Internet, about 13% of home and 40%
of business streaming sessions suﬀer various quality
degradations, such as rebuﬀering, thinning, or switch-
ing to a lower quality stream.
Our measurement and analysis results show that with
these techniques, current streaming services tend to over-
utilize CPU and bandwidth resources to provide better ser-
vice to end users, which may not be a desirable and eﬀective
way to improve the quality of streaming media delivery. Fur-
thermore, the Fast Streaming technique does not work with
rate adaptation, resulting in even worse user experiences
than normal TCP-based streaming upon long-term network
congestion. Motivated by these results, we propose Coordi-
nated Streaming, a mechanism that eﬀectively coordinates
caching and rate adaptation in order to improve streaming
quality with an eﬃcient utilization of the server and Internet
resources. The potential of such a mechanism in streaming
quality improvement is evaluated accordingly.
The remainder of this paper is organized as follows. Sec-
tion 2 describes our trace collection and processing method-
ology. Section 3 presents an overview of our collected work-
load. The measurement and analysis of the delivering qual-
ity and resource utilization of streaming media services are
performed in Sections 4, 5, and 6. The coordinating caching
and rate adaptation mechanism is discussed in Section 7.
Some related work is outlined in Section 8. Finally, we make
concluding remarks in section 9.
2. TRACE COLLECTION AND PROCESS-
ING METHODOLOGY
The prevailing streaming protocols on the Internet are
RTSP [25] and MMS [5].
In RTSP streaming, the client
and the server exchange streaming commands via RTSP,
running on TCP. The media data packets and stream-
ing control/feedback packets are delivered via RTP/RTCP
[24] (such as Windows and QuickTime media services) or
RDT [6] (RealNetworks media services), running on UDP
or TCP. In MMS streaming, all streaming commands and
control packets between a client and a server are exchanged
via MMS in the same TCP connection, and the media data
can be delivered over UDP or TCP. For both RTSP and
MMS streaming, when TCP is used to deliver media data,
the media and control packets are interleaved with RTSP
or MMS commands in a single TCP connection, instead of
using two separate TCP connections. In addition to RTSP
and MMS, media can also be streamed through HTTP [3].
Diﬀerent from HTTP downloading (also known as pseudo
streaming [17]), HTTP streaming uses the HTTP protocol
to deliver both RTSP commands and media data. In Mi-
crosoft HTTP streaming, the RTSP headers are embedded
in the Pragma headers of HTTP messages. In RealNetworks
and QuickTime HTTP streaming, the RTSP commands are
embedded in HTTP message bodies with the base64 encod-
ing format.
Table 1: Home User Workload Overview
Requests
Product Number of Traﬃc (GB)
TCP/UDP
5.86/0.89
0.79/2.26
0.00/0.082
28,210
9,139
244
Content
Type
on
demand
live
media
audio
video
audio
video
Type
WM
RM
QT
WM
RM
QT
WM
RM
QT
WM
RM
QT
67,002
12,117
113
1,499
1,164
4
950
643
6
151.21/20.64
6.25/17.31
0.01/0.34
5.36/6.69
0.25/2.39
0.00/0.14
13.50/2.85
5.69/3.09
0.00/0.003
audio
Content
Type
Requests
Table 2: Business User Workload Overview
Product Number of Traﬃc (GB)
TCP/UDP
3.67/0.01
3.03/0.04
0.00/0.001
21.18/3.31
3.94/0.42
0.00/0.01
5.56/0.01
4.46/1.05
5,762
1,057
9,725
1,285
493
350
on
demand
5
8
video
audio
live
media
video
–
50
7
–
–
0.65/0.00
0.20/0.00
–
Type
WM
RM
QT
WM
RM
QT
WM
RM
QT
WM
RM
QT
In this study, we collected streaming media packets in a
data center of a major ISP from 2005-04-29 15:00 (Friday)
to 2005-05-10 20:30 (Tuesday), using the Gigascope appli-
ance [16]. The data center hosts servers for thousands of
business companies, and provides Internet access services
for a large cable company. The Gigascope is running on a
site close to the end users (broadband home users and busi-
ness users). To collect streaming packets of RTSP/MMS
requests, Gigascope captures all TCP packets from/to ports
554-555, 7070-7071, 9070, and 1755. According to a recent
measurement study that collects RTSP/MMS packets based
on keyword matching [17], our port number selection covers
97.3% of the RTSP/MMS streaming requests 1. Meanwhile,
we also collected UDP streaming traﬃc via ports 5004-5005,
6970-6980, and 7000-7010, which are the most popular ports
for UDP streaming. For UDP streaming traﬃc over other
port numbers due to network address translation (NAT),
we calculate the traﬃc volume based on the summary infor-
mation that a client reports to its server when a streaming
session is terminated. Compared to existing studies that are
based on server logs [12, 15, 26, 27, 31], in which only the
summary information of streaming sessions is available, our
study is conducted at the packet level, which facilitates more
detailed analysis on the quality and the resource utilization
of various Internet streaming techniques.
The initial trace processing is as follows. We ﬁrst grouped
TCP packets by TCP connections, based on the IP ad-
dress, port number, and TCP SYN/FIN/RST ﬂag. Then
we extracted the RTSP/MMS commands from each stream-
ing request. Based on the analysis of these commands,
we identiﬁed and parsed media data and streaming control
packets from the TCP or corresponding UDP streams, and
dumped the corresponding RTP/RTCP, RDT, and MMS
packet headers. Finally, we identiﬁed home users and busi-
ness users in our traces based on IP preﬁx matching.
Our trace collection and processing methodology have
been validated by extensive experiments on various me-
dia server and player products, including Windows Media
Player and Windows Server 2003, Real Player and Helix
Server, QuickTime Player and Darwin Server. All these
products have extensions to the standard RTSP and RTP
protocols. Due to the lack of documentation, we reverse-
engineered proprietary protocols by capturing and analyzing
media traﬃc under diﬀerent environments, with the help of
1There are about 2.6% RTSP/MMS/HTTP streaming re-
quests using port 80 or 8080, which are hard to distinguish
from regular HTTP downloading traﬃc. We exclude this
traﬃc in this study.
tools such as tcpdump/windump, ethereal, and NIST Net
network emulator.
3. TRAFFIC OVERVIEW
We have captured 126 GB of streaming data (compressed
in gzip format) during the 12-day period.
In our work-
loads, there are 7,591 home users accessing 1,898 servers in
121,091 requests, and there are 219 business users accessing
911 servers in 18,742 requests. Both users and servers are
identiﬁed by their public IPs, and the real number of busi-
ness users would be much larger due to the usage of NAT
(a business IP may host up to 64 users as shown in Section
4.2).
3.1 Streaming trafﬁc by user communities
Table 1 and 2 show the traﬃc breakdowns based on the
content types (audio/video, live/on-demand) and media ser-
vice products in the home user and business user workloads,
respectively.
In these tables, WM, RM, and QT denote
Windows, RealNetworks, and QuickTime media services,
respectively.
In our workloads, most streaming traﬃc is
delivered over Windows media services (80.7% and 85.5%
of the requests in the home and business user workloads,
respectively), and RealNetworks is next (19.0% and 14.4%
of the requests in the home and business user workloads,
respectively). Only a small fraction of streaming traﬃc is
delivered over QuickTime. These tables also indicate that
TCP is responsible for the majority of streaming traﬃc on
the Internet, conﬁrming previous studies such as [17, 26].
In the home user workload, 2.20% and 31.05% of the re-
quests access live and on-demand audio objects, and 1.32%
and 65.43% of the requests access live and on-demand video
objects, respectively. Video is responsible for the majority
of streaming media requested by home users. In contrast,
in the business user workload, 4.50% and 58.77% of the re-
quests access live and on-demand audio, while 0.30% and
36.43% of the requests access live and on-demand video, re-
spectively. Audio is responsible for the majority of stream-
ing media requested by business users. In addition, although
the volume of live media traﬃc is far less than that of on-
demand media traﬃc in both workloads, compared to home
users, business users are more likely to access live media,
most of which is audio.
Figure 1(a) and Figure 2(a) show the distribution of ﬁle
length (in terms of playback duration) of on-demand au-
dio and video objects in each streaming session requested
by home and business users, respectively. These ﬁgures in-
dicate that business users tend to request audio and video
Biz
Home
 1
 0.8
 0.6
 0.4
 0.2
F
D
C
Biz
Home
 1
 0.8
 0.6
 0.4
 0.2
F
D
C
Biz
Home
 1
 0.8
 0.6
 0.4
 0.2