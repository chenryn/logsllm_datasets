87.40%
95.00%
94.80%
98.20%
97.10%
98.10%
82.60%
89.80%
72.30%
1.50%
1.40%
70.80%
92.90%
89.00%
94.20%
80.40%
80.60%
0.71%
34.70%
9.06%
14.40%
14.90%
Fig. 2. Percentage of malware instances in which listed behavior is observed
On Challenges in Evaluating Malware Clustering
249
The evidence above suggests to us that a different reason for the relatively poor ac-
curacy of BCHKK-algo and our plagiarism detectors on VXH-data is at work. One pos-
sible contributing factor is that BCHKK-data samples within the same reference cluster
tended to produce API-call sequences of more uniform length than did VXH-data sam-
ples in the same reference cluster. For example, the relative standard deviation of the
API sequence lengths per cluster in BCHKK-data, averaged over all clusters, is 23.5%
and 6.9% for traces produced by Anubis and CWSandbox, respectively, while this num-
ber is 130.5% for CWSandbox traces of VXH-data. However, in the following section
we focus our attention on another explanation for the poorer clustering performance on
VXH-data versus BCHKK-data, and that we believe is more generally instructive.
5 Effects of Cluster-Size Distribution
In seeking to understand the discrepancy between the precision and recall of the BCHKK-
algo (and plagiarism-detection) clustering on the BCHKK-data (Section 3) and VXH-
data datasets (Section 4), one attribute of these datasets that stood out to us is the dis-
tribution of cluster sizes in each. Speciﬁcally, the reference clustering for the BCHKK-
data is highly biased, in that it contains two large clusters comprising 48.5% and 27%
of the malware instances, respectively, and remaining clusters of size at most 6.7%. In
contrast, the VXH-data reference dataset is more evenly distributed; the largest cluster
in that dataset comprises only 14% of the instances. Figure 3 shows the cluster size
distribution of the reference clustering of each dataset; note that the x-axis is log-scale.
The reason that cluster size distribution matters can be seen from an example of
clustering 8 points in one of two extreme ways. If when clustering these 8 points, the
reference clustering D comprises two clusters, one of size 7 and one of size 1, then
any other clustering C of these 8 points into two clusters of size 7 and 1 is guaranteed to
yield prec(C,D) and recall(C,D) of at least 7/8. If, on the other hand, D comprises two
clusters of size 4 each, then another clustering C could yield prec(C,D) and recall(C,D)
= 36/70 of such clusterings do so. In this sense,
as low as 4/8, and in fact
(cid:8)
(cid:9)
8
4
(cid:9)(cid:8)
(cid:8)
4
2
(cid:9)
4
/
2
1
0.9
0.8
F
D
C
0.7
0.6
0.5
100
BCHKK−data
VXH−data
101
102
number of instances in one cluster
103
104
Fig. 3. Reference cluster-size distribution of BCHKK-data and VXH-data. Note that x-axis is
log-scale.
250
P. Li et al.
it is considerably “harder” to produce a clustering yielding good precision and recall
in the latter case, and a good precision and recall in the latter case is thus much more
signiﬁcant than in the former.
While providing insight, this combinatorial argument is too simplistic to illustrate
the effect that cluster size distribution plays in the BCHKK-algo clustering of the VXH-
data and BCHKK-data datasets. A more direct, but still coarse, indication of this effect
can be seen by downsampling the large clusters in the BCHKK-data dataset. Specif-
ically, we randomly removed malware instances from the two largest families in the
BCHKK-data reference clustering until they were each of size 200. After re-clustering
the remaining malware instances using BCHKK-algo with the same parameters, the re-
sulting F-measure averaged over 10 downsampling runs was only 0.815 (versus 0.956
before downsampling).
An alternative and more reﬁned view of the effects of signiﬁcance to the cluster-
ing results of BCHKK-algo for the VXH-data and BCHKK-data datasets can be seen
by illustrating the resilience of the clustering results to perturbations in the underly-
ing distance matrix. The heart of the BCHKK-algo clustering technique is the distance
measure that it develops, which is tuned to measure the activities of malware. As such,
one strategy in examining the potential for bias due to cluster-size distribution is to
introduce perturbations into the original BCHKK-algo distance matrices for the VXH-
data and BCHKK-data up to some limit, re-cluster the resulting distance matrix into the
same cluster-size distribution, and evaluate the rate at which the precision and recall
drop. Intuitively, if the precision and recall drop more quickly for the VXH-data than
for the BCHKK-data, then this supports the idea that minor errors in the BCHKK-algo
distance are more ampliﬁed (in terms of the effects on precision and recall) when the
clusters are distributed as in the VXH-data than when they are distributed as in the
BCHKK-data dataset. By the contrapositive, this will show that a high precision and
recall in the VXH-data case is more signiﬁcant.
In attempting to perform this analysis, however, some difﬁculties arise.
– The BCHKK-algo distance matrices for the VXH-data and BCHKK-data datasets
are different in that the VXH-data matrix results in precision and recall far below
that yielded by BCHKK-data. As such, the VXH-data matrix is already “decayed”
more from the best possible precision and recall than is that for the BCHKK-data;
introducing perturbations in an already decayed distance matrix will do little to
demonstrate the sensitivity of a highly accurate distance matrix to perturbations.
In order to start from good precision and recall, then, we adopt the testing VXH-
data matrix and BCHKK-data matrix (i.e., resulting from BCHKK-algo) as the
reference matrices, i.e., so that we start from precision and recall of 1.0. We then
measure the rate of degradation from this ideal as the perturbations are introduced
into the distance matrices, compared to these references.
– When re-clustering a perturbed distance matrix, the cluster-size distribution might
be altered, in that hierarchical clustering simply might not produce an identical
cluster-size distribution as the original from the perturbed distance matrix. For this
reason, we ﬁt a parameterized distribution to the reference cluster-size distribu-
tion and stop hierarchical clustering at the point that maximizes the p-value of a
chi-squared test between the test cluster-size distribution and the ﬁtted reference
On Challenges in Evaluating Malware Clustering
251
distribution. In general, we ﬁnd that a Weibull distribution with shape parameter
k = 0.7373 and scale parameter λ = 1.9887 is a good ﬁt for the reference cluster-
ing (i.e., the initial test clustering resulting from BCHKK-algo, as described above)
of the VXH-data dataset (p-value of 0.8817), and that the corresponding values for
the BCHKK-data are k = 0.4492 and λ = 5.1084 (p-value of 0.8763).
– Given that we have only a distance matrix, a method of perturbing it so that its
entries maintain properties of a distance (notably, satisfying the triangle inequality)
is necessary. To do this, we map the distance matrix into a d-dimensional space,
i.e., creating d-dimensional points to represent the malware instances, separated
according to the distances in the matrix. To then perturb the distances, we simply
move each point to a random spot in the ball of radius r centered at that point.
We can then produce the corresponding distance matrix for these perturbed points,
and re-cluster. By increasing r, we then increase the maximum perturbation to the
distances.
The results of this analysis are shown in Figure 4. In this ﬁgure, the x-axis shows the ra-
dius r within which we perturbed each point from its original position in d-dimensional
space. The y-axis shows the F-measure that resulted for each radius r, averaged over
ﬁve runs; standard deviations were negligible. As this ﬁgure shows, the cluster-size dis-
tributions characteristic of the VXH-data were indeed more sensitive to perturbations
in the underlying data than were those characteristic of the BCHKK-data. In addition,
in Figure 5 we show the p-values of chi-squared tests comparing the cluster-size distri-
bution of the clustering after perturbation and the ﬁtted (Weibull) reference cluster-size
distribution. The fact that these p-values are not signiﬁcantly decreasing indicates that
the cause of degradation in the F-measure was not primarily due to deviation from the
intended cluster-size distributions.
We also plot a “Downsized BCHKK-data” line in Figure 4 to control for the discrep-
ancy in the number of malware instances represented in the BCHKK-data and VXH-
data datasets. To do this, we randomly removed instances from BCHKK-data (irrespec-
tive of the reference clusters in which they fall) until the size of the data set is the
same as that of VXH-data, i.e., 1, 114 instances. Using the correspondingly downsized
1
0.95
e
r
u
s
a
e
m
−
F
0.9
0.85
0.8
BCHKK−data
VXH−data
Downsized BCHKK−data
0.75
0 .04 .08 .12 .16 .20 .24 .28 .32 .36 .40 .44 .48 .52 .56 .60 .64 .68 .72 .76 .80
perturbation limit (r)
Fig. 4. Tolerance to perturbations
252
P. Li et al.
l
e
u
a
v
−
p
1
0.9
0.8
0.7
0.6
0.5
e
r
u
s
a
e
m
−
F
0.6
0.5
0.4
0.3
0.2
0.1
0
BCHKK−data
VXH−data
0 .04 .08 .12 .16 .20 .24 .28 .32 .36 .40 .44 .48 .52 .56 .60 .64 .68 .72 .76 .80
perturbation limit (r)
Fig. 5. p-values for perturbation tests
λ = 2
λ = 3
λ = 4
λ = 5
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
k
Fig. 6. F-measure of random test and reference clusterings with cluster sizes drawn from a
Weibull distribution with scale parameter λ ∈ [2, 5] and shape parameter k ∈ [0.2, 0.9], av-
eraged over 10 trials. Error bars show standard deviation. Note that the best-ﬁt (k, λ) value for
the BCHKK-data reference clustering is (0.4488, 4.8175) and for the VXH-data reference clus-
tering is (0.7803, 2.5151).
distance matrix, we applied hierarchical clustering using the same threshold to stop
clustering as reported in [6], resulting in a clustering whose cluster-size distribution has
corresponding estimated Weibull parameters k = 0.4307 and λ = 2.0399. We took this
clustering as the starting point for “Downsized” perturbation test and show the results
(averaged over 5 runs) in Figure 4. And as we can see, “Downsized” BCHKK-data is
still more immune to perturbation than VXH-data.
To further examine the effects of cluster size distributions on precision and recall,
in Figure 6 we plot the average F-measure for reference clusters D and test clusters C
whose cluster sizes are chosen from a Weibull distribution with the shape parameter
On Challenges in Evaluating Malware Clustering
253
k shown on the x-axis. Once the reference and test cluster sizes are chosen (indepen-
dently), the reference and test clusters are then populated independently at random (i.e.,
each point is assigned to a cluster in D and a cluster in C independently). As Figure 6
shows, the F-measure that results simply from different values of k provides further
insight into the bias that cluster size distribution can introduce.
We do not mean to suggest that the complete discrepancy between the results of the
BCHKK-algo clustering technique on the VXH-data and BCHKK-data is due solely to
the cluster size distributions underlying the two datasets. However, we do believe that
this case and our analysis of it offers sufﬁcient evidence to recommend that evaluation
of future clustering techniques be done on datasets with a variety of cluster size distri-
butions. It is also possible that measures of cluster accuracy other than precision and
recall better avoid this source of bias. For example, Perdisci et al [15] employed an
approach based on the compactness of each cluster and the separation among different
clusters, which may be preferable.
6 Conclusion
In this paper we have reported on our investigation of the impact that ground-truth se-
lection might have on the accuracy reported for malware clustering techniques. Our
starting point was investigating the possibility that a common method of determining
ground truth, namely utilizing the concurrence of multiple anti-virus tools in classifying
malware instances, may bias the dataset toward easy-to-cluster instances. Our investi-
gation of this possibility was based on clustering using a different set of tools developed
without attention to the subtleties of malware, namely plagiarism detectors. While our
application of these tools, ﬁrst to a dataset used in the evaluation of a state-of-the-art
malware clustering technique and second to a whole new malware dataset, arguably
leaves our conjecture unresolved, we believe that highlighting this possibility is impor-
tant to facilitate discussion of this issue in the community.
It has also led us to examine an issue that we believe to be important for future
analyses of malware clustering, namely the impact of the ground-truth cluster-size dis-
tribution on the signiﬁcance of results suggesting high accuracy. In particular, we have
shown that the highly accurate results reported for a state-of-the-art malware classiﬁer
(BCHKK-algo) are tempered by a reduced signiﬁcance owing to having tested on a
dataset with a biased cluster-size distribution. We consequently recommend that future
evaluations employ data with a cluster-size distribution that is more even.
We caution the reader from drawing more conclusions from our study than is war-
ranted, however. In particular, despite the similar performance of the BCHKK-algo
algorithm and the plagiarism detectors in clustering on the malware datasets we con-
sidered, it is not justiﬁed to conclude that these algorithms are equally effective for
malware clustering. The design of the BCHKK-algo algorithm should make it more
difﬁcult to evade, not to mention more scalable. It is evident, however, from our results
in Section 3 that either malware today is not designed to exploit differences in the clus-
tering abilities of BCHKK-algo and plagiarism detectors, or else that the ground-truth
selection of the test datasets eliminated malware instances that do so.
We recognize that our paper has perhaps introduced more questions than it has deﬁni-
tively answered. Nevertheless, we believe that in addition to the observations above,
254
P. Li et al.
multiple opportunities for future research can be drawn from our investigation. In par-
ticular, we believe our investigation underlines the importance of further research in
malware clustering, speciﬁcally in better methods for establishing ground truth, in iden-
tifying more reliable features for malware clustering, or in both.
Acknowledgements. We are deeply grateful to Ulrich Bayer, Engin Kirda, Paolo Milani
Comparetti, and Christopher Kruegel for helpful assistance, for providing access to the
BCHKK-data dataset, for applying BCHKK-algo to our VXH-data dataset, for helpful
discussions, and for useful comments on drafts of this paper. This work was supported in
part by NSF award CT-0756998 and by DRTech Singapore under grant POD0814140.
References
1. Threatexpert3, http://www.threatexpert.com/
2. Norman sandbox center (2008),
http://www.norman.com/security_center/security_tools/en
3. VX Heavens (2010), http://vx.netlux.org/
4. Aiken, A.: Moss: a system for detecting software plagiarism,
http://theory.stanford.edu/˜aiken/moss/
5. Bailey, M., Oberheide, J., Andersen, J., Mao, Z.M., Jahanian, F., Nazario, J.: Automated
classiﬁcation and analysis of internet malware. In: Kruegel, C., Lippmann, R., Clark, A.
(eds.) RAID 2007. LNCS, vol. 4637, pp. 178–197. Springer, Heidelberg (2007)
6. Bayer, U., Comparetti, P.M., Hlauschek, C., Kruegel, C., Kirda, E.: Scalable, behavior-based
malware clustering. In: Proceedings of the Network and Distributed System Security Sym-
posium (2009)
7. Bayer, U., Kruegel, C., Kirda, E.: Ttanalyze: A tool for analyzing malware. In: 15th European
Institute for Computer Antivirus Research (EICAR 2006) Annual Conference (2006)
8. Commtouch, Inc. Malware outbreak trend report: Bagle/beagle (March 2007),
http://www.commtouch.com/documents/Bagle-Worm_MOTR.pdf
9. Gheorghescu, M.: An automated virus classiﬁcation system. In: Proceedings of the Virus
Bulletin Conference, VB (1994)
10. Ha, K.: Keylogger.stawin,
http://www.symantec.com/security response/
writeup.jsp?docid=2004-012915-2315-99
11. Hu, X., Chiueh, T., Shin, K.G.: Large-scale malware indexing using function-call graphs. In:
Proceedings of 16th ACM Conference on Computer and Communications Security (2009)
12. Kamiya, T., Kusumoto, S., Inoue, K.: Ccﬁnder: A multi-linguistic token-based code clone
detection system for large scale source code. IEEE Trans. on Software Engineering, 654–
670 (2002)
13. Lee, T., Mody, J.J.: Behavioral classiﬁcation. In: 15th European Institute for Computer An-
tivirus Research (EICAR 2006) Annual Conference (2006)
14. McAfee. W97m/opey.c, http://vil.nai.com/vil/content/v_10290.htm
15. Perdisci, R., Lee, W., Feamster, N.: Behavioral clustering of http-based malware and sig-
nature generation using malicious network traces. In: USENIX Symposium on Networked