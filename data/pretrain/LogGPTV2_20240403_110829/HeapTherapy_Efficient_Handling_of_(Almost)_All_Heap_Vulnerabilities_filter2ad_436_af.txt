### Memory Overhead and Performance
HEAPTHERAPY+ operates with an average memory overhead of 4.3%. The overall performance overhead is only 5.2%, primarily due to the interception of allocation and deallocation calls and the maintenance of metadata. This overhead can be further reduced if our system is integrated into the underlying heap allocator. In real-world service programs, the throughput overhead is very low or negligible.

### Discussion
#### Limitations
One limitation of HEAPTHERAPY+ is that it can only handle overflows caused by continuous writes or reads, which are the primary forms of buffer overflows. Discrete reads or writes leading to overflows cannot be detected by HEAPTHERAPY+. Additionally, if an overflow occurs within an array that is an internal field of a structure, HEAPTHERAPY+ cannot detect it. These limitations are shared by many existing countermeasures against buffer overflows, such as AddressSanitizer [8] and HeapTherapy [19]. A common challenge for heap security tools that work via interception of allocation calls is to make them compatible with custom allocators. Existing works like MemBrush [61] may be leveraged to locate custom memory allocations and address this challenge.

#### Defense Mechanism
The patches generated by HEAPTHERAPY+ are configurable runtime defenses. They do not completely fix a bug (e.g., DoS can still be triggered via overflows). Our goal is not to replace conventional patching but to complement it by providing immediate protection when patches are not available or need more time for testing.

#### Multiple CCIDs
A heap vulnerability can be exploited via multiple Calling Context Identifiers (CCIDs). Attackers may develop different attack inputs to exploit buffers with these CCIDs. However, whenever the attack exploits a buffer allocated in a new calling context, our system treats it as a new vulnerability and starts another defense generation cycle. Based on our evaluation and previous research on context-sensitive defenses [19], [33], [40], [48], such cases are rare.

#### Use-After-Free Attacks
When analyzing use-after-free attacks in programs with large memory profiles, the memory quota for the FIFO queue of freed blocks may be exhausted. In such cases, we can replay attacks across multiple executions. Specifically, we divide the whole space of CCIDs into N subspaces, and each of the N executions defers the deallocation of buffers that have the allocation-time CCIDs in one of the subspaces. This approach ensures that each execution consumes approximately 1/N of the memory.

### Conclusions
We have combined heavyweight offline attack analysis and lightweight online defense generation to build a new heap memory defense system, HEAPTHERAPY+. This system demonstrates how shadow memory, which typically incurs significant slowdowns, can be used to generate defenses with minimal overhead. Key advantages include:
1. Automatic patch generation without manual efforts.
2. Code-less patching.
3. Versatile handling of heap buffer overwrites, overreads, use-after-free, and uninitialized reads.
4. Imposing a very small overhead.
5. No dependency on specific allocators.

Our evaluation shows that HEAPTHERAPY+ is both effective and efficient. The speed overhead is only 5.2% when five patches are installed on SPEC CPU2006 benchmarks, and this overhead can be further reduced if the system is integrated into the underlying allocator.

Additionally, we have proposed targeted calling context encoding, which achieves a sixfold speed boost compared to prior encoding techniques. This innovation may be of interest to researchers applying or building calling context encoding techniques.

### Acknowledgment
This project was supported by NSF CNS-1815144 and NSF CNS-1856380. We thank the anonymous reviewers for their invaluable comments and constructive suggestions.

### References
[References listed here]

---

**Note:** The references section has been left unchanged as it appears to be a comprehensive list of citations. If you need any specific reference details or further refinement, please let me know.