title:SmarPer: Context-Aware and Automatic Runtime-Permissions for Mobile
Devices
author:Katarzyna Olejnik and
Italo Dacosta and
Joana Soares Machado and
K&apos;evin Huguenin and
Mohammad Emtiyaz Khan and
Jean-Pierre Hubaux
2017 IEEE Symposium on Security and Privacy
SmarPer: Context-Aware and Automatic
Runtime-Permissions for Mobile Devices
Katarzyna Olejnik∗,1, Italo Dacosta†, Joana Soares Machado†, K´evin Huguenin‡,1,
Mohammad Emtiyaz Khan§,1, Jean-Pierre Hubaux†
∗Raytheon BBN Technologies, Cambridge, MA, USA
†School of Computer and Communication Sciences (IC), EPFL, Lausanne, Switzerland
‡Faculty of Business and Economics (HEC), UNIL, Lausanne, Switzerland
§Center for Advanced Intelligence Project (AIP), RIKEN, Tokyo, Japan
Abstract—Permission systems are the main defense that mobile
platforms, such as Android and iOS, offer to users to protect
their private data from prying apps. However, due to the
tension between usability and control, such systems have several
limitations that often force users to overshare sensitive data. We
address some of these limitations with SmarPer, an advanced
permission mechanism for Android. To address the rigidity of
current permission systems and their poor matching of users’
privacy preferences, SmarPer relies on contextual information
and machine learning methods to predict permission decisions
at runtime. Note that the goal of SmarPer is to mimic the
users’ decisions, not to make privacy-preserving decisions per se.
Using our SmarPer implementation, we collected 8,521 runtime
permission decisions from 41 participants in real conditions. With
this unique data set, we show that using an efﬁcient Bayesian
linear regression model results in a mean correct classiﬁcation
rate of 80% (±3%). This represents a mean relative reduction
of approximately 50% in the number of incorrect decisions
when compared with a user-deﬁned static permission policy,
i.e., the model used in current permission systems. SmarPer also
focuses on the suboptimal trade-off between privacy and utility;
instead of only “allow” or “deny” type of decisions, SmarPer
also offers an “obfuscate” option where users can still obtain
utility by revealing partial information to apps. We implemented
obfuscation techniques in SmarPer for different data types and
evaluated them during our data collection campaign. Our results
show that 73% of the participants found obfuscation useful and
it accounted for almost a third of the total number of decisions.
In short, we are the ﬁrst to show, using a large dataset of real in
situ permission decisions, that it is possible to learn users’ unique
decision patterns at runtime using contextual information while
supporting data obfuscation; this is an important step towards
automating the management of permissions in smartphones.
I. INTRODUCTION
Smartphones can be considered the most personal comput-
ing devices we have today, due to their popularity and the
increasing amount of personal information they collect. To
control third-party apps’ access to this sensitive information,
mobile platforms such as Android and iOS rely on a permis-
sion system where users can allow or deny apps’ permission
requests. In general, users deﬁne an access control policy that
is enforced by the mobile OS at runtime.
1Parts of this work were carried out while Katarzyna Olejnik and Moham-
mad Emtiyaz Khan were working at EPFL and K´evin Huguenin was working
at LAAS-CNRS.
Unfortunately, due to the trade-off between usability (i.e.,
permission management) and the level of control offered (i.e.,
granularity of permissions), current mobile permission systems
have several limitations. For instance, users’ permission deci-
sions represent a static policy, i.e., once a permission decision
is made, it will not change without user intervention (Android
6+ and iOS). This approach assumes that permission decisions
are not context-dependent and rarely change over time. Yet,
researchers have shown evidence of the contrary [1], [2]. For
example, a user might be willing to grant an app access to
her location if she is using it, but she might be reluctant
to do so if the app is in the background. Our user survey
(Section V) conﬁrms this idea: Only 19% of the participants
stated that context is not important to them. The results of
our study also show that users’ decisions are not static—for
similar permission requests, many participants changed their
decision at least once.
To support context-aware permission policies, a simple
approach is to prompt users at runtime to make a decision.
In this way, users will have more contextual information and
a better understanding of the purpose of the request [2].
Android 6+ and iOS support permission decisions at runtime,
but only the ﬁrst time an app requests a permission. Hence,
the resulting policy only captures a single user’s context.
CyanogenMod [3] and permission tools such as XPrivacy [4]
and LBE Privacy Guard [5] offer users with an “always-ask”
option to indicate what requests should be always prompted
at runtime. This approach enables a better matching of users’
privacy preferences, but it requires a signiﬁcant effort from the
user. For example, a single app can make tens to hundreds of
sensitive requests per day, even if the user is not interacting
with it [2]. As users have on average close to 95 apps [6] and
each app requires around 5 permissions [7], it is clear that
runtime decisions can overwhelm users or cause habituation to
prompts. Hence, to support context-aware permission policies,
advanced mechanisms are needed to help users with the
overhead introduced by runtime permissions.
Another important limitation of current permission systems
is their sub-optimal trade-off between privacy and utility, as
users can only allow (i.e., no privacy) or deny (i.e., no utility)
access to their private information. As a result, to beneﬁt
from apps’ functionalities, users often have no choice but
© 2017, Katarzyna Olejnik. Under license to IEEE.
DOI 10.1109/SP.2017.25
1058
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:19:06 UTC from IEEE Xplore.  Restrictions apply. 
to overshare personal information. A better trade-off can be
achieved by providing users with additional decision types,
where sensitive information is only partially revealed to apps
in exchange for some utility, i.e., data obfuscation. For in-
stance, to check the weather forecast, a user could reveal her
approximated location instead of the precise one. In our user
survey (Section V), 73% of the participants reported ﬁnding
data obfuscation useful.
To address the aforementioned limitations, we propose
“Smart Permissions” (“SmarPer”), an advanced permission
mechanism for Android with three main goals: context-
aware permissions, automatic decision-making at runtime, and
data obfuscation. SmarPer follows a platform-agnostic design
where apps’ sensitive requests are intercepted at runtime and
users are prompted for a decision, i.e., allow, obfuscate, deny.
By observing users’ responses, SmarPer progressively learns
to predict and make decisions on behalf of users. It should be
noted that the goal of SmarPer is to mimic users’ decisions,
not to make privacy-preserving decisions or to ﬁnd a balance
between utility and privacy. In other words, if a user makes
poor privacy decisions, SmarPer will do the same.
SmarPer relies on machine learning to predict users’ per-
mission decisions. Instead of using a multi-class classiﬁer ap-
proach, as prior work in this area2 [8], [9], we model the prob-
lem as a linear regression problem, using a one-dimensional
privacy-preference function that outputs the degree of privacy
of each user for each request (allow<obfuscate<deny). Specif-
ically, by using a set of contextual features, we use a Bayesian
linear regression model (BLR) to ﬁt a linear regression to each
users’ decision data. This model has several advantages: It is
lightweight enough for smartphones, and it is well suited for
limited amounts of training data. Also, by training directly in
the smartphone a model per-user, it preserves users’ privacy.
We use an implementation of SmarPer, based on XPri-
vacy [4], to collect at runtime permission decisions from 41
participants3. Each participant used SmarPer (in fully manual
mode) for a period of at
least 10 days. Unlike previous
studies [2], [10], ours relies on decision data collected in
real conditions, i.e., participants using SmarPer daily on their
own or loaned devices with their own apps. In total, we
collected 8,521 unique permission decisions, along with 32
raw contextual features per decision (e.g., time, location, app
name, etc.). Using this unique data set, our model achieves
a mean absolute error (MAE) of 0.22 (±0.03)4 and a mean
incorrect classiﬁcation rate (ICR) of 0.20 (±0.03),
i.e., a
mean correct classiﬁcation rate (CCR) of 80% (±3%). This
represents a mean relative improvement of 55% for the MAE
and 50% for the ICR over a static policy baseline, where
participants manually deﬁne permission decisions, i.e., the
model used by current permission systems. Our results show
that it is possible to learn the decision patterns of users with
2Note that prior work uses machine learning to predict users’ static per-
mission conﬁgurations instead of runtime permission decisions.
3This user study was approved by our institution’s IRB (ethical committee).
4On a scale from -1 to +1; thus, the maximum value for the MAE is 2.
good accuracy, even when training data is scarce, and that
contextual information is key for such a task.
We also implemented in SmarPer obfuscation techniques
for four data types: location, contacts, storage, and camera.
During our data-collection campaign, we evaluated three of
these techniques with our participants. Our results demonstrate
the importance of obfuscation: Obfuscate accounted for 27%
of the total number of decisions collected and, in our user
survey, 80% of the participants stated that they would like to
obfuscate additional data types. Few users reported compatibil-
ity problems with apps. We believe this is the ﬁrst evaluation
of obfuscation techniques in smartphones on this scale.
It is important to mention that there are two key parts in the
SmarPer project. First, modeling users’ permission-decision
patterns by using contextual information and data obfusca-
tion. This part requires a user study to collect the decision
data required to assess the potential of our machine learning
approach. Second, evaluating our machine learning approach
in practice (including user perception and the use of SmarPer’s
features), through a new ﬁeld experiment and user study. In
this paper, we present the results associated with the ﬁrst part.
We are currently working towards the second part.
Our main contributions are as follows:
• Design and partial implementation of SmarPer. We
present a platform-agnostic design to support context-
aware and automatic decisions at runtime, and data
obfuscation. Our implementation, publicly available as
an open-source project [11], offers runtime collection of
permission decisions and associated contextual features,
and data obfuscation for four data types.
• Unique data set of permission decisions. We collected
8,521 runtime permission decisions and their context
from 41 participants. We believe this is the largest and
most realistic data set of this type. After the approval of
our university’s ethical committee, we made a sanitized
subset of this data set publicly available [11].
• Evaluation of the potential of automatic prediction
techniques for permission decisions. We use an adapted
linear regression model and demonstrate that it achieves
signiﬁcant performance improvements over two carefully
chosen baselines. Our results show that contextual infor-
mation is key to accurately predict permission decisions.
In addition, we show that a per-user model has better
performance than a one-size-ﬁts-all model, as the former
is able to better capture users’ unique privacy preferences.
• Machine learning framework. We provide a framework
for carefully training and comparing different context-
aware models that predict permission decisions. The
framework’s source code is also available online [11].
• Implementation and evaluation of data obfuscation.
We develop obfuscation techniques for four data types
in SmarPer and evaluate them in our data-collection
campaign. This is one of the ﬁrst and largest evaluations
of obfuscation in smartphones with real users.
The remainder of this paper proceeds as follows. Section II
highlights related work in the area of mobile permission
1059
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:19:06 UTC from IEEE Xplore.  Restrictions apply. 
systems. Section III presents SmarPer’s design goals and ar-
chitecture. Section IV describes our SmarPer implementation.
Section V explains our data-collection methodology and the
resulting data set. Section VI describes our machine learning
methodology to predict users’ decisions using contextual
information and presents the results of our performance
evaluation. Section VII further discusses our data set and
machine learning results, and the limitations of our study.
Finally, Section VIII presents our concluding remarks and
future research directions.
II. RELATED WORK
Mobile permission systems have several limitations that
cause users [12], [13] and developers [14] difﬁculty in under-
standing and managing them. Researchers propose different
extensions to current permission models to provide users with
more control and better management [8], [15]–[19]. Yet, most
of these approaches do not support contextual information in
their access control policies (i.e., static policies). The lack
of context-awareness in mobile permission systems has also
been addressed in previous work [1], [2], [20]–[23]. Still, most
of the proposed solutions are not practical for average users,
as they require manually deﬁning context-aware policies for
each (app, permission, inferred context) tuple. In contrast, our
work focuses on the automatic inference of these policies from
users’ decision-making behavior in different contexts. Another
limitation is the lack of decision-granularity i.e., only “allow”
or “deny” decisions. To address this issue, researchers propose
sending fake or obfuscated data to apps [18], [22], [24], [25].
Yet, most of these solutions have not been evaluated with users
in real scenarios. To ﬁll this gap, we implement obfuscation
techniques for different data types in Android and perform one
of the ﬁrst evaluations of obfuscation with real users.
With the increasing number of apps and data types, another
important area of study is helping users to efﬁciently manage
permissions. Machine learning has been used to automate
decision-making in other areas such as location-based services
and social networks [26]–[29]. In the area of mobile devices,
researchers propose crowdsourcing [19] and machine learning
to help users manage permissions [8], [9], [30]. For instance,
Lin et al. and Liu et al. identify a small number of “privacy
proﬁles”, using clustering techniques that could be used to
facilitate static permission conﬁguration for different types of
users [8], [9], [30]. Also, Liu et al. [8] show that a binary
classiﬁer can predict users’ static permission decisions with
high accuracy. These works, however, focus on static permis-
sion policies that do not change over time, i.e., no context-
awareness, and they rely on a one-size-ﬁts-all approach, i.e.,
training a single model with data from all users.
Closer to our work, Wijesekera et al. [2] propose the use of
permission decisions at runtime to provide users with contex-
tual information to make more informed decisions. To reduce a
user’s load, they conclude that a mechanism should infer when
to prompt users or automatically block app requests (note that
this is not exactly the same as predicting users’ decisions).
The authors show how a one-size-ﬁts-all mixed-effects logistic
regression model can be used for this purpose with good
accuracy, using a small data set of users’ decisions collected in
semi-realistic conditions, i.e., 673 decisions from 36 users col-
lected ofﬂine during an exit survey. We extend this line of work
in several ways. First, we demonstrate that it is possible to
predict users’ permission decisions with great accuracy, even
when we consider an additional decision type (i.e., obfuscate),
and that contextual information is key for doing so. Second,
we show that a per-user model is signiﬁcantly more accurate
than a one-size-ﬁts-all model, due to users’ unique privacy
preferences. Third, we provide an experimental framework
and methodology for carefully comparing the performance of
different machine learning algorithms that predict decisions
using contextual information. Fourth, we use a unique and
substantially larger data set of permission decisions per user,
collected in real conditions (i.e., 8,521 decisions from 41 users
collected at runtime in users’ smartphones), and we describe
the many challenges faced when doing so. Fifth, we provide a
design and partial prototype of a mechanism for predicting and
automating permission decisions and propose an approach for
automating permission decisions. Sixth, we design and imple-
ment obfuscation mechanisms in our prototype and evaluated
them with real users.
III. SMARPER
We address two important limitations of the current per-
mission systems: the use of static policies that do not capture
users’ privacy needs in different contexts, and the sub-optimal
trade-off between privacy and utility. We propose SmarPer,
an extension to Android’s permission system that supports
dynamic and automatic decision policies inferred from users’
behavior, and that provides ﬁner-grained decisions, i.e., allow,
obfuscate, and deny. SmarPer provides a feedback loop where
users are initially prompted for permission decisions, and
over time SmarPer learns users’ decisions patterns and makes
decisions on behalf of the users. SmarPer can even adapt to
changes in users’ privacy posture. Note that, though SmarPer
targets Android, its concepts and design are platform-agnostic.
A. Threat Model
We focus on the case of privacy-invasive apps, that access
private data (e.g., location, camera) about users through the
dedicated APIs calls of the mobile OS. We do not address
the cases where the threat comes from the OS itself or from
apps that use native code or security breaches to access private
data. We assume that the considered apps access, in some
cases, more information than they actually need to provide
the features (and the associated quality of service) the users
actually need; this constitutes a privacy threat for the users.
B. Design Goals
SmarPer’s design follows three main goals: Context-aware
permissions,
to support dynamic permission policies that
change according to users’ context; Automatic permission
decisions, to predict and make permission decisions at runtime
on behalf of the user and reduce users’ load; and Data
1060
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:19:06 UTC from IEEE Xplore.  Restrictions apply. 
(cid:14)
(cid:9)(cid:12)(cid:17)(cid:6)(cid:15)(cid:4)(cid:6)(cid:14)(cid:17)(cid:9)(cid:13)(cid:12)
(cid:9)
(cid:13)
(cid:13)(cid:3)(cid:7)(cid:18)(cid:16)(cid:4)(cid:2)(cid:17)(cid:9)(cid:13)(cid:12)
(cid:36)(cid:25)(cid:37)(cid:34)(cid:33)(cid:32)(cid:37)(cid:25)
(cid:10)
(cid:22)(cid:34)(cid:34)(cid:1)(cid:36)(cid:25)(cid:35)(cid:39)(cid:25)(cid:37)(cid:38)
(cid:7)
(cid:2)
(cid:38)(cid:29)(cid:31)(cid:25)
(cid:30)(cid:33)(cid:23)(cid:22)(cid:38)(cid:29)(cid:33)(cid:32)
(cid:34)(cid:28)(cid:33)(cid:32)(cid:25)(cid:1)(cid:37)(cid:38)(cid:22)(cid:38)(cid:39)(cid:37)
(cid:23)(cid:33)(cid:32)(cid:32)(cid:1)(cid:38)(cid:41)(cid:34)(cid:25)