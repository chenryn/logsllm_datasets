# SmarPer: Context-Aware and Automatic Runtime-Permissions for Mobile Devices

## Authors
Katarzyna Olejnik<sup>∗,1</sup>, Italo Dacosta<sup>†</sup>, Joana Soares Machado<sup>†</sup>, Kévin Huguenin<sup>‡,1</sup>, Mohammad Emtiyaz Khan<sup>§,1</sup>, Jean-Pierre Hubaux<sup>†</sup>

- <sup>∗</sup>Raytheon BBN Technologies, Cambridge, MA, USA
- <sup>†</sup>School of Computer and Communication Sciences (IC), EPFL, Lausanne, Switzerland
- <sup>‡</sup>Faculty of Business and Economics (HEC), UNIL, Lausanne, Switzerland
- <sup>§</sup>Center for Advanced Intelligence Project (AIP), RIKEN, Tokyo, Japan

### Abstract
Permission systems are the primary defense mechanism that mobile platforms, such as Android and iOS, offer to users to protect their private data from intrusive applications. However, these systems often suffer from a trade-off between usability and control, leading to several limitations. These limitations frequently result in users oversharing sensitive data. We address some of these limitations with SmarPer, an advanced permission mechanism for Android. SmarPer leverages contextual information and machine learning methods to predict and automate permission decisions at runtime, aiming to mimic users' decisions rather than making privacy-preserving decisions per se.

Using our implementation of SmarPer, we collected 8,521 runtime permission decisions from 41 participants in real-world conditions. Our unique dataset demonstrates that using an efficient Bayesian linear regression model results in a mean correct classification rate of 80% (±3%). This represents a mean relative reduction of approximately 50% in the number of incorrect decisions compared to a user-defined static permission policy, which is the current standard in permission systems.

SmarPer also addresses the suboptimal trade-off between privacy and utility by offering an "obfuscate" option, allowing users to reveal partial information to apps while still obtaining utility. We implemented obfuscation techniques for different data types and evaluated them during our data collection campaign. Our results show that 73% of participants found obfuscation useful, and it accounted for almost a third of the total number of decisions.

In summary, we are the first to demonstrate, using a large dataset of real in-situ permission decisions, that it is possible to learn users' unique decision patterns at runtime using contextual information while supporting data obfuscation. This is a significant step towards automating the management of permissions in smartphones.

## I. Introduction

Smartphones have become the most personal computing devices we use today, thanks to their widespread adoption and the vast amount of personal information they collect. To control third-party apps' access to this sensitive information, mobile platforms like Android and iOS rely on a permission system where users can allow or deny apps' permission requests. Generally, users define an access control policy that the mobile operating system enforces at runtime.

Unfortunately, current mobile permission systems face several limitations due to the trade-off between usability and the level of control offered. For instance, users' permission decisions represent a static policy, meaning once a decision is made, it does not change without user intervention. This approach assumes that permission decisions are not context-dependent and rarely change over time. However, research has shown evidence to the contrary [1], [2]. For example, a user might be willing to grant an app access to her location when actively using the app but may be reluctant to do so if the app is running in the background. Our user survey (Section V) confirms this idea: only 19% of participants stated that context is not important to them. The results of our study also show that users' decisions are not static; for similar permission requests, many participants changed their decision at least once.

To support context-aware permission policies, one simple approach is to prompt users at runtime to make a decision. This way, users have more contextual information and a better understanding of the request's purpose [2]. While Android 6+ and iOS support permission decisions at runtime, they only do so the first time an app requests a permission, capturing only a single context. Tools like CyanogenMod [3] and XPrivacy [4] offer an "always-ask" option, but this requires significant effort from the user. A single app can make tens to hundreds of sensitive requests per day, even if the user is not interacting with it [2]. Given that users typically have around 95 apps [6] and each app requires about 5 permissions [7], runtime decisions can overwhelm users or lead to habituation to prompts. Therefore, advanced mechanisms are needed to support context-aware permission policies and reduce the overhead introduced by runtime permissions.

Another limitation of current permission systems is the suboptimal trade-off between privacy and utility. Users can only allow (no privacy) or deny (no utility) access to their private information. As a result, to benefit from apps' functionalities, users often overshare personal information. A better trade-off can be achieved by providing additional decision types, such as data obfuscation, where sensitive information is partially revealed to apps in exchange for some utility. For example, a user could reveal an approximated location instead of a precise one to check the weather forecast. In our user survey (Section V), 73% of participants reported finding data obfuscation useful.

To address these limitations, we propose "Smart Permissions" (SmarPer), an advanced permission mechanism for Android with three main goals: context-aware permissions, automatic decision-making at runtime, and data obfuscation. SmarPer follows a platform-agnostic design where apps' sensitive requests are intercepted at runtime, and users are prompted for a decision (allow, obfuscate, or deny). By observing users' responses, SmarPer progressively learns to predict and make decisions on behalf of users. It is important to note that SmarPer aims to mimic users' decisions, not to make privacy-preserving decisions or find a balance between utility and privacy. If a user makes poor privacy decisions, SmarPer will do the same.

SmarPer uses machine learning to predict users' permission decisions. Instead of using a multi-class classifier, as in prior work [8], [9], we model the problem as a linear regression problem using a one-dimensional privacy-preference function. This function outputs the degree of privacy for each user for each request (allow < obfuscate < deny). Specifically, we use a set of contextual features and a Bayesian linear regression model (BLR) to fit a linear regression to each user's decision data. This model is lightweight enough for smartphones and well-suited for limited training data. Training a model per-user directly on the smartphone also preserves users' privacy.

We used an implementation of SmarPer, based on XPrivacy [4], to collect runtime permission decisions from 41 participants. Each participant used SmarPer (in fully manual mode) for at least 10 days. Unlike previous studies [2], [10], ours relies on decision data collected in real conditions, i.e., participants using SmarPer daily on their own or loaned devices with their own apps. In total, we collected 8,521 unique permission decisions, along with 32 raw contextual features per decision (e.g., time, location, app name, etc.). Using this unique dataset, our model achieves a mean absolute error (MAE) of 0.22 (±0.03) and a mean incorrect classification rate (ICR) of 0.20 (±0.03), i.e., a mean correct classification rate (CCR) of 80% (±3%). This represents a mean relative improvement of 55% for the MAE and 50% for the ICR over a static policy baseline, where participants manually define permission decisions. Our results show that it is possible to learn users' decision patterns with good accuracy, even with limited training data, and that contextual information is key for this task.

We also implemented obfuscation techniques for four data types: location, contacts, storage, and camera. During our data-collection campaign, we evaluated three of these techniques with our participants. Our results demonstrate the importance of obfuscation: it accounted for 27% of the total number of decisions collected, and in our user survey, 80% of participants stated that they would like to obfuscate additional data types. Few users reported compatibility issues with apps. We believe this is the first evaluation of obfuscation techniques in smartphones on this scale.

There are two key parts to the SmarPer project. First, modeling users' permission-decision patterns using contextual information and data obfuscation. This part requires a user study to collect the decision data needed to assess the potential of our machine learning approach. Second, evaluating our machine learning approach in practice, including user perception and the use of SmarPer's features, through a new field experiment and user study. In this paper, we present the results associated with the first part. We are currently working towards the second part.

Our main contributions are as follows:
- **Design and Partial Implementation of SmarPer:** We present a platform-agnostic design to support context-aware and automatic decisions at runtime, and data obfuscation. Our implementation, publicly available as an open-source project [11], offers runtime collection of permission decisions and associated contextual features, and data obfuscation for four data types.
- **Unique Dataset of Permission Decisions:** We collected 8,521 runtime permission decisions and their context from 41 participants. We believe this is the largest and most realistic dataset of its kind. After approval from our university’s ethical committee, we made a sanitized subset of this dataset publicly available [11].
- **Evaluation of Automatic Prediction Techniques for Permission Decisions:** We use an adapted linear regression model and demonstrate that it achieves significant performance improvements over two carefully chosen baselines. Our results show that contextual information is key to accurately predicting permission decisions. Additionally, we show that a per-user model has better performance than a one-size-fits-all model, as the former can better capture users' unique privacy preferences.
- **Machine Learning Framework:** We provide a framework for carefully training and comparing different context-aware models that predict permission decisions. The framework’s source code is also available online [11].
- **Implementation and Evaluation of Data Obfuscation:** We develop obfuscation techniques for four data types in SmarPer and evaluate them in our data-collection campaign. This is one of the first and largest evaluations of obfuscation in smartphones with real users.

The remainder of this paper is organized as follows. Section II highlights related work in the area of mobile permission systems. Section III presents SmarPer's design goals and architecture. Section IV describes our SmarPer implementation. Section V explains our data-collection methodology and the resulting dataset. Section VI describes our machine learning methodology to predict users' decisions using contextual information and presents the results of our performance evaluation. Section VII further discusses our dataset and machine learning results, and the limitations of our study. Finally, Section VIII presents our concluding remarks and future research directions.

## II. Related Work

Mobile permission systems have several limitations that cause difficulties for both users [12], [13] and developers [14] in understanding and managing them. Researchers propose various extensions to current permission models to provide users with more control and better management [8], [15]–[19]. However, most of these approaches do not incorporate contextual information into their access control policies (i.e., static policies). The lack of context-awareness in mobile permission systems has been addressed in previous work [1], [2], [20]–[23]. Still, most proposed solutions are not practical for average users, as they require manually defining context-aware policies for each (app, permission, inferred context) tuple. In contrast, our work focuses on the automatic inference of these policies from users' decision-making behavior in different contexts.

Another limitation is the lack of decision granularity, i.e., only "allow" or "deny" decisions. To address this issue, researchers propose sending fake or obfuscated data to apps [18], [22], [24], [25]. However, most of these solutions have not been evaluated with users in real scenarios. To fill this gap, we implement obfuscation techniques for different data types in Android and perform one of the first evaluations of obfuscation with real users.

With the increasing number of apps and data types, another important area of study is helping users efficiently manage permissions. Machine learning has been used to automate decision-making in other areas such as location-based services and social networks [26]–[29]. In the area of mobile devices, researchers propose crowdsourcing [19] and machine learning to help users manage permissions [8], [9], [30]. For instance, Lin et al. and Liu et al. identify a small number of "privacy profiles" using clustering techniques that could facilitate static permission configuration for different types of users [8], [9], [30]. Additionally, Liu et al. [8] show that a binary classifier can predict users' static permission decisions with high accuracy. These works, however, focus on static permission policies that do not change over time, i.e., no context-awareness, and they rely on a one-size-fits-all approach, i.e., training a single model with data from all users.

Closer to our work, Wijesekera et al. [2] propose the use of permission decisions at runtime to provide users with contextual information to make more informed decisions. To reduce the user's load, they conclude that a mechanism should infer when to prompt users or automatically block app requests (note that this is not exactly the same as predicting users' decisions). The authors show how a one-size-fits-all mixed-effects logistic regression model can be used for this purpose with good accuracy, using a small dataset of users' decisions collected in semi-realistic conditions, i.e., 673 decisions from 36 users collected offline during an exit survey. We extend this line of work in several ways. First, we demonstrate that it is possible to predict users' permission decisions with great accuracy, even when considering an additional decision type (i.e., obfuscate), and that contextual information is key for doing so. Second, we show that a per-user model is significantly more accurate than a one-size-fits-all model, due to users' unique privacy preferences. Third, we provide an experimental framework and methodology for carefully comparing the performance of different machine learning algorithms that predict decisions using contextual information. Fourth, we use a unique and substantially larger dataset of permission decisions per user, collected in real conditions (i.e., 8,521 decisions from 41 users collected at runtime in users' smartphones), and we describe the many challenges faced when doing so. Fifth, we provide a design and partial prototype of a mechanism for predicting and automating permission decisions and propose an approach for automating permission decisions. Sixth, we design and implement obfuscation mechanisms in our prototype and evaluate them with real users.

## III. SmarPer

We address two important limitations of current permission systems: the use of static policies that do not capture users' privacy needs in different contexts, and the suboptimal trade-off between privacy and utility. We propose SmarPer, an extension to Android's permission system that supports dynamic and automatic decision policies inferred from users' behavior and provides finer-grained decisions (i.e., allow, obfuscate, and deny). SmarPer provides a feedback loop where users are initially prompted for permission decisions, and over time, SmarPer learns users' decision patterns and makes decisions on their behalf. SmarPer can even adapt to changes in users' privacy posture. Note that, although SmarPer targets Android, its concepts and design are platform-agnostic.

### A. Threat Model

We focus on the case of privacy-invasive apps that access private data (e.g., location, camera) about users through the dedicated APIs calls of the mobile OS. We do not address cases where the threat comes from the OS itself or from apps that use native code or security breaches to access private data. We assume that the considered apps sometimes access more information than they need to provide the features and associated quality of service that users actually need, constituting a privacy threat for the users.

### B. Design Goals

SmarPer's design follows three main goals:
1. **Context-Aware Permissions:** To support dynamic permission policies that change according to users' context.
2. **Automatic Permission Decisions:** To predict and make permission decisions at runtime on behalf of the user, reducing the user's load.
3. **Data Obfuscation:** To provide finer-grained decisions, allowing users to reveal partial information to apps while still obtaining utility.

These goals aim to enhance the usability and effectiveness of permission management on mobile devices, ensuring that users' privacy preferences are respected and dynamically adjusted based on context.