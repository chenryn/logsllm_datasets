is inefficient and unnecessary. Table 1 summarizes the computa-
tion and communication costs for the Du-Atallah protocol and the
protocol based on MTs (§2.4). As can be seen, online computation
and communication are improved by factor 2x. Also the offline
communication is improved by factor 3x. Unfortunately, using the
Du-Atallah protocol in this format will reduce the efficiency of
vector dot product computation in Chameleon. Please note that
it is no longer possible to perform a complete dot product of two
vectors by two parties only since the third share (⟨z⟩A2 = a0 × a1)
is shared between two parties (P0 and P1). However, this problem
can be fixed by a modification which we describe next.
Du-Atallah Protocol and Vector Dot Product. We further
modify the optimized Du-Atallah protocol such that the complete
vector dot product is efficiently processed. The idea is that instead
of the STP additively sharing its shares, it first sums its shares
and then sends the additively shared versions to the two parties.
Consider vectors of size n. The STP needs to generate n different
a0 and a1 as a list for a single vector multiplication. We denote the
ith member of the list as [a0]i and [a1]i. Our modification requires
that the STP generates a single l-bit value a2 and sends it to P0.
The STP also computes
n−1(cid:88)
i =0
a3 =
[a0]i × [a1]i − a2
and sends it to P1. We call a2 and a3 the Vector Dot Product Shares
or VDPS. This requires that the STP knows the size of the array
in the offline phase. Since the functionality of the computation is
not secret, we can calculate the size and number of all dot products
6
in the offline phase and ask for the corresponding random shares
from the STP.
Reducing Communication. A straightforward implementa-
tion of the offline phase of the Du-Atallah protocol requires that
the STP sends n random numbers of size l ([a0]i and [a1]i) to P0
and P1 for a single dot product of vectors of size ∼ n. However,
we suggest reducing the communication using a Pseudo Random
Generator (PRG) for generating the random numbers as was pro-
posed in [33]. Instead of sending the complete list of numbers to
each party, the STP can create and send random PRG seeds for
each string to the parties such that each party can create [a0]i and
[a1]i locally using the PRG. For this purpose, we implement the
PRG using Advanced Encryption Standard (AES), a low-cost block
cipher, in counter mode (AES CTR-DRBG). Our implementation
follows the description of the NIST Recommendation for DRBG
[8]. From a 256-bit seed, AES CTR-DRBG can generate 263 indistin-
guishable random bits. If more than 263 bits are needed, the STP
sends more seeds to the parties. The STP uses the same seeds in
order to generate a2 and a3 for each dot product. Therefore, the
communication is reduced from n × l bits to sending a one-time
256-bit seed and an l-bit number per single dot product.
Performance evaluation. For an empirical performance eval-
uation of our optimized VDP protocol, we refer the reader to §6.2:
the evaluated SVM classification mainly consists of a VDP com-
putation together with a negligible subtraction and comparison
operation.
4.3 Supporting Signed Fixed-point Numbers
Chameleon supports Signed Fixed-point Numbers (SFN) in addition
to integer operations. Supporting SFN requires that not only all
three secure computation protocols (GC, GMW, and Additive SS)
should support SFN but the secret translation protocols should
be compatible as well. We note that the current version of the
ABY framework only supports unsigned integer values. We have
added an abstraction layer to the ABY framework such that it
supports signed fixed-point numbers. The TinyGarble framework
can support this type if the corresponding Boolean circuit is created
and fed into the framework.
All additive secret sharing protocols only support unsigned inte-
ger values. However, in this section, we describe how such protocols
can be modified to support signed fixed-point numbers. Modification
for supporting signed integers can be done by representing numbers
in two’s complement format. Consider the ring Z2l which consists
of unsigned integer numbers {0, 1, 2, ..., 2l−1 − 1, 2l−1
, ..., 2l − 1}.
We can perform signed operations only by interpreting these num-
bers differently as the two’s complement format: {0, 1, 2, ..., 2l−1 −
1,−2l−1
, ...,−1}. By doing so, signed operations work seamlessly.
In order to support fixed-point precision, one solution is to inter-
pret signed integers as signed fixed-point numbers. Each number is
represented in two’s complement format with the Most Significant
Bit (MSB) being the sign bit. There are α and β bits for integer and
fraction parts, respectively. Therefore, the total number of bits is
equal to γ = α + β + 1. While this works perfectly for addition and
subtraction, it cannot be used for multiplication. The reason is that
when multiplying two numbers in a ring, the rightmost 2 × β bits
of the result now correspond to the fraction part instead of β bits
and β bits from MSBs are overflown and discarded. Our solution
to this problem is to perform all operations in the ring Z2l where
l = γ + β and after each multiplication, we shift the result β bit to
the right while replicating the sign bit for β MSBs.
In addition to the support of computation engines, share trans-
lation protocols also work correctly. Share translation from GC to
GMW works fine as it operates on bit-level and is transparent to the
number representation format. Share translation from GC/GMW
to additive either happens using a subtraction circuit or OT. In
the first case, the result is valid since subtraction of two signed
fixed-point numbers in two’s complement format is identical to
subtracting two unsigned integers. In the second case, OT is on
bit-level and again transparent to the representation format. Finally,
share translation from additive to GC/GMW is correct because it
uses an addition circuit which is identical for unsigned integers
and signed fixed-point numbers.
Floating Point Operations. The current version of Chameleon
supports floating point operations by performing all computations
in the GC protocol. Since our GC engine is based on TinyGarble,
our performance result is identical to that of TinyGarble, hence, we
do not report the experimental results of floating-point operations.
A future direction of this work can be to break down the primitive
floating point operations, e.g., ADD, MULT, SUB, etc. into smaller
atomic operations based on integer values. Consequently, one can
perform the linear operations in the ring and non-linear opera-
tions in GC/GMW, providing a faster execution for floating-point
operations.
Most methods for secure computation on floating and fixed point
numbers proposed in the literature were realized in Shamir’s secret
sharing scheme, e.g. [2, 26, 55, 73, 85], but some of them also in GC
[73], GMW [32], and HE [63] based schemes. The quality of the
algorithms varies from self-made to properly implemented IEEE
754 algorithms, such as in [32, 73]. The corresponding software
implementations were done either in the frameworks Sharemind
[18] and PICCO [85], or as standalone applications. For fixed-point
arithmetics, Aliasgari et al. [2] proposed algorithms that outperform
even integer arithmetic for certain operations. As a future direction
of this work, we plan to integrate their methodology in Chameleon.
4.4 Generating Multiplication Triples
As we discussed in §2.4, each multiplication on additive secret
shares requires an Arithmetic Multiplication Triple (A-MT) and one
round of communication. Similarly, evaluating each AND gate in the
GMW protocol requires a Boolean Multiplication Triple (B-MT) [33].
In the offline phase, we calculate the number of MTs (NA-MT and
NB-MT). The STP precomputes all MTs needed and sends them
to both parties. More precisely, to generate A-MTs, the STP uses
a PRG to produce five l-bit random numbers corresponding to
a0, b0, c0, a1, and b1. We denote the ith triple with [.]i. Therefore,
the STP completes MTs by computing c1’s as [c1]i = ([a0]i +[a1]i )×
([b0]i + [b1]i ) − [c0]i. Finally, the STP sends [a0]i , [b0]i, and [c0]i
to the first party and [a1]i , [b1]i, and [c1]i to the second party for
i = 1, 2, ..., NA-MT. Computing B-MTs is also very similar with the
only differences that all numbers are 1-bit and [c1]i is calculated as
[c1]i = ([a0]i ⊕ [a1]i ) ∧ ([b0]i ⊕ [b1]i ) ⊕ [c0]i.
7
Reducing Communication. A basic implementation of pre-
computing A-MTs and B-MTs requires communication of 3 × l ×
NA-MT and 3 × NB-MT bits from the STP to each party, respectively.
However, similar to the idea of [33] presented in §4.2, we use a PRG
to generate random strings from seeds locally by each party. To
summarize the steps:
(1) STP generates two random seeds: seed0 for generating
(2) STP computes [c1]i = ([a0]i + [a1]i ) × ([b0]i + [b1]i ) − [c0]i
(3) STP sends seed0 to the first party and seed1 together with
[a0]i , [b0]i, and [c0]i and seed1 for [a1]i and [b1]i.
for i = 1, 2, ..., NA−MT .
the list of [c1]i to the second party.
After receiving the seeds, the parties locally generate their share
of the triples using the same PRG. This method reduces the com-
munication from 3 × l × NA-MT to 256 and 256 + l × NA-MT bits for
the first and second parties, respectively. The STP follows a simi-
lar process with the same two seeds to generate B-MTs. Figure 1
illustrate the seed expansion idea to generate MTs [33].
Figure 1: Seed expansion process to precompute A-MTs/B-
MTs with low communication.
4.5 Fast STP-aided Oblivious Transfer
Utilizing the idea of correlated randomness [47], we present an
efficient and fast protocol for Oblivious Transfer that is aided by
the Semi-honest Third Party (STP). Our protocol comprises a setup
phase (performed by the STP) and an online phase (performed
by the two parties). The protocol is described for one 1-out-of-2
OT. The process repeats for as many OTs as required. In the setup
phase, the STP generates random masks q0, q1 and a random bit
r and sends q0, q1 to the sender and r, qr to the receiver. In the
online phase, the two parties execute the online phase of Beaver’s
OT precomputation protocol [12] described in Figure 2. Please
note that all OTs in Chameleon including OTs used in GC and
secret translation from GC/GMW to Additive are implemented as
described above.
Reducing Communication. Similar to the idea discussed in
§4.4, the STP does not actually need to send the list of (q0, q1) to
the sender and r to the receiver. Instead, it generates two random
seeds and sends them to the two parties. The STP only needs to
send the full list of qr to the receiver.
4.6 Security Justification
The security proof of Chameleon is based on the following propo-
sitions: (i) the GC execution is secure since it is based on [81]. (ii)
The security proof of GMW execution and share type translation
STPP1P0Rseed0seed1Rseed0seed1PRGPRG[c1]i PRGPRG[a0]i , [b0]i , [c0]i[a1]i , [b1]i[c1]i [a0]i , [b0]i , [c0]i[a1]i , [b1]iSender
Has: messages q0, q1
Input: messages m0, m1
Output: -
(q0 ⊕ m0, q1 ⊕ m1) if b′ = 0
(s0, s1) =
(q0 ⊕ m1, q1 ⊕ m0) if b′ = 1
Receiver
Has: message qr and r
Input: choice bit b
Output: mb
b′ = r ⊕ b
b′←−
(s0,s1)−→ mb = sr ⊕ qr
Figure 2: Beaver’s OT precomputation protocol [12].
directly follows the one of [34]. (iii) All operations in A-SS are per-
formed in the ring Z2l which is proven to be secure in [18]. Our
support for SFN only involves the utilization of a bigger ring and
does not change the security guarantees, and finally (iv) our opti-
mizations for reducing the communication between the STP and the
two parties are secure as we use a PRG instantiation recommended
by the NIST standard [8].
5 BENCHMARKS OF ATOMIC OPERATIONS
Evaluation Setup. We benchmark different atomic operations of
Chameleon and compare them with three prior art frameworks:
TinyGarble [81], ABY [34], and Sharemind [18]. The result for ABY
is reported for three different scenarios: GC-only, GMW-only, and
Additive SS-only. We run our experiments for a long term security
parameter (128-bit security) on machines equipped with Intel Core
i7-4790 CPUs @ 3.6 GHz and 16 GB of RAM. The CPUs support
fast AES evaluations due to AES-NI. The STP is instantiated as
a separate compute node running a C/C++ implementation. The
communication between the STP and its clients as well as between
the clients is protected by TLS with client authentication. All parties
run on different machines within the same Gigabit network.4
Atomic Operations. The detailed run-times and communica-
tion for arithmetic and binary operations are shown in Table 2 and
in Table 3, respectively. Table 4 additionally shows the run-times
for conversions between different sharings.5 All reported run-times
are the average of 10 executions with less than 15% variance.
For TinyGarble, ABY, and Chameleon we ran the frameworks
ourselves. Unlike TinyGarble and ABY, Sharemind lacks built-in
atomic benchmarks and is a commercial product that requires con-
tracting even for academic purposes. Thus, we give the results from
the original paper [18] and justify why Chameleon performs better
on equal hardware.
As can be seen, Chameleon outperforms all state-of-the-art
frameworks. Run-times and communication for arithmetic op-
erations in Chameleon are only given in A-SS since from the ABY
results and Table 4 it follows that even for a single addition or
4We do not include WAN benchmarks of atomic operations for the following
reason: Due to higher latency, GC-based circuit evaluation with constant rounds is
preferred instead of GMW for binary operations. However, since the atomic bench-
marks do not measure input sharing (for which GC uses STP-aided OT generation),
no difference is visible to prior art.
5With exception of the B2A conversion, the required communication of Chameleon
for conversion operations equals ABY [34] since STP-aided OT generation, as required
for B2Y and A2Y conversions, does not reduce the amount of communication (cf
Table 5).
multiplication operation it is worthwhile to perform a protocol
conversion. The remaining atomic operations for Chameleon are
given in Boolean sharing where we observe major improvements
over ABY due to our efficient B-MT precomputation.6 Regarding
conversion operations, the B2A performance in Chameleon benefits
from reduced communication of fast STP-aided A-MTs (c.f §4.4).
Likewise, the performance of the B2Y and A2Y conversion benefits
from fast STP-aided OTs (cf. §4.5).
Although, the experimental setup of Sharemind is computation-
ally weaker than ours, we emphasize that Chameleon is more effi-
cient because of the following reasons: (i) To compute each MULT
operation, Sharemind requires 6 instances of the Du-Atallah proto-
col while our framework needs only 2. (ii) In Sharemind, bit-level
operations such as XOR/AND require a bit-extraction protocol
which is computationally expensive. Please note that these costs
are not reported by [18] and hence are not reflected in Table 2. (iii)
Operations such as CMP, EQ, and MUX can most efficiently be
realized using GC/GMW protocols and as a result, Chameleon can
perform these operations faster. The highlighted area for specific
operations using ABY-A means that ABY does not perform those
operations in additive SS. The highlighted area in Table 3 for Share-
mind means that the corresponding information is not reported in
the original paper.
The computation run-times for TinyGarble include base OTs,
online OTs, garbling/evaluating, and data transmission. This is
why the run-time for MULT is not significantly higher than other
operations where they require orders of magnitude fewer gates.
However, in Chameleon, we precompute all OTs which reduces
the computation run-time. Note that the shown run-times and
communication results for Chameleon represent the worst case,
namely for the party that receives additional data from the STP
besides the required seeds for OT and MT generation.7
Communication in the Setup (Offline) Phase. The commu-
nication cost (number of bits) of the setup phase in Chameleon
is compared to the ABY framework [34] in Table 5. To gener-
ate a single B-MT, Chameleon requires only a constant-size data
transmission to one party and 256× less communication to the
other party compared to ABY. When generating a single A-MT, the
required communication to the other party is reduced by factor
273×/289×/321× compared to ABY for a bitlength of 16/32/64, re-
spectively. This is a significant enhancement since in most machine
learning applications, the main bottleneck is the vector/matrix mul-
tiplication which requires a large amount of A-MTs.
6 MACHINE LEARNING APPLICATIONS
Many applications can benefit from our framework. Here, we cover
two important applications in greater detail due to the space con-
straints. In particular, we show how Chameleon can be leveraged
in Deep Learning (§6.1) and classification based on SVMs (§6.2).
6The benchmarking methodology inherited from ABY omits input sharing, which
is why no improvement for GC-based operations is measurable compared to ABY.
7An improved implementation could equally distribute computation and commu-
nication among the two parties by dividing the data sent by the STP evenly, thereby
further reducing the runtimes.
8
Table 2: RUN-TIMES (in milliseconds unless stated otherwise) for different atomic operations and comparison with prior
art. Each experiment is performed for 1,000 operations on 32-bit numbers in parallel. The detailed performance results for
ABY [34] are provided for three different modes of operation: GC, GMW, and Additive. Minimum values marked in bold.
Op
ADD
MULT
XOR
AND
CMP
EQ
MUX
TinyGarble [81]
Online
1.57 s
2.31 s
0.00
1.58 s
1.57 s
1.56 s
1.59 s
ABY-GC [34]
Offline