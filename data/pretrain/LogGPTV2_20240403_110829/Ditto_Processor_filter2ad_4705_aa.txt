title:Ditto Processor
author:Shih-Chang Lai and
Shih-Lien Lu and
Jih-Kwon Peir
Shih-Chang Lai
Dept. of ECE
Oregon State University
Corvallis, OR
Ditto Processor
Shih-Lien Lu
Konrad Lai
Labs.
Hillsboro, OR
Microprocessor Research, Intel
PI:EMAIL
Jih-Kwon Peir
Dept. of Computer Science
University of Florida
Gainesville, FL
Abstract
for current single-chip
Concentration of design effort
Commercial-Off-The-Shelf
(COTS) microprocessors has
been directed towards performance. Reliability has not
been the primary focus. As supply voltage scales to
accommodate technology scaling and to lower power
consumption,
transient errors are more likely to be
introduced. The basic idea behind any error tolerance
scheme involves some type of redundancy. Redundancy
techniques can be categorized in three general categories:
(1) hardware redundancy, (2) information redundancy, and
(3) time redundancy. Existing time redundant techniques
for improving reliability of a superscalar processor utilize
the otherwise unused hardware resources as much as
possible to hide the overhead of program re-execution and
verification. However, our study reveals that re-executing
of long latency operations contributes to performance loss.
We suggest a method to handle short and long latency
instructions in slightly different ways to reduce the
performance degradation. Our goal
is to minimize the
hardware overhead and performance degradation while
maximizing the fault detection coverage. Experimental
studies through microarchitecture simulation are used to
compare performance lost due to the proposed scheme with
tolerant design and different existing time
non-fault
redundant
fault
tolerant schemes. Fourteen integer and
floating-point benchmarks are simulated with 1.8~13.3%
performance loss when compared with non-fault-tolerant
superscalar processor.
1. Introduction
Transient
Transient errors, also called soft errors, can be
introduced by alpha or neutron particles strikes. They can
also be introduced by power supply disturbances or other
environmental variations. As supply voltage scales to
accommodate technology scaling and to lower power
transient errors are more likely to be
consumption,
errors may
introduced
[1-5].
affect
microprocessors
[6-7]. One possible
manifestation of soft errors in the modern processor is
undetected data corruption. Experiments done by injecting
faults into unprotected microprocessors resulted in the
observation of non-negligible risk of data corruption [8].
Soft errors cannot be detected by manufacturing testing nor
by
of
microprocessors in critical financial data processing, it is
desirable to have microprocessors capable of transparent
testing. With widespread
in many ways
periodic
usage
recovery and protection from data corruption in the face of
soft errors.
The basic idea behind any error tolerance schemes
involves some type of redundancy. Redundancy techniques
can be categorized in three general categories [9-10]: (1)
hardware redundancy [11], (2) information redundancy [13-
14] and (3) time redundancy [15-16]. Hardware redundancy
employs physical duplication and achieves redundancy
spatially. Information redundancy with error detection and
correction coding is effective in protecting memory
elements against transient faults. Transient faults that occur
in the logic blocks have no easy way to increase immunity
besides utilizing either hardware redundancy or
time
redundancy. Time redundancy re-executes operations with
the same hardware and obtain redundancy temporally. Time
redundancy can be performed at different levels of the
microprocessor. Work done by Nicolaidis [17] proposed a
way to duplicate in time at the circuit level. This method
introduces a delay element between the combination logic
and the pipeline register allowing the data to be latched
twice at different time. At the microarchitecture level, time
redundancy can be achieved by instruction re-execution or
by check pointing and rollback [18]. At the software level it
can be accomplished by statically duplicating the program
in multiple versions [12]. It assumes that if one version
fails, other versions will produce correct results. In this
paper, we focus on the microarchitecture level of time
redundancy technique.
time
level
Existing microarchitecture
redundancy
mechanisms lose performance due to blindly duplicating
the execution of
instructions at either decode stage
[25][27][32][34] or at commit stage [22-24][33]. Both
schemes verify the result at the point when the original
copy is ready to retire and redundant copy has completed
execution.
1. Duplicating the instructions at decode stage generates
many unnecessary instructions to consume hardware
resource when branch mis-prediction occurs.
2. The second scheme stored the committed instructions
to a buffer in program order. This buffer provides the
information of retired instructions to the fetch units.
The instructions would then be re-fetched, re-decoded,
re-renamed and re-executed.
The main drawback of the first scheme is that it does
not cover faults that may occur at the frond-end of the
pipeline. The second approach is commonly used in
Simultaneous multithreading (SMT) based fault
tolerant
processors. They have better fault coverage compare to the
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:09:01 UTC from IEEE Xplore.  Restrictions apply. 
if
the performance degradation of
they only have limited
first approach. However,
resources,
the second
scheme is worse than the first. The main reason is that the
second scheme reduced the instruction bandwidth available
to the original instruction stream [27]. Since long latency
operations tend to stay in reorder buffer longer than short
latency operation, our study reveals that the long latency
operations are important factor to the performance loss of
both schemes. Here we categorize memory reference micro-
operation, multiply and divide operations as long latency
instructions and the rest, including data effective address
calculation, are short latency operations.
In this paper we proposed a Ditto Processor to
combine the advantages of two previous schemes and still
be able to reduce the performance loss needed for reliable
computing. It achieves the goal by handling short and long
latency instructions in slightly different ways. After the
instructions are decoded, long latency instructions would
speculatively execute twice and the results are compared
before instructions committed. All instructions are cloned
when they are ready to retire. The duplicated instructions
are held in a buffer and send back to the beginning of the
pipeline. Since results of long latency instructions are
checked, the clones of these instructions would not pass
execution stage again after renaming operation are verified.
For
latency operations, once they
completed the re-execution, results are compared with the
results of original instructions. If the results of any types
instructions do not match with their clones, processor
rollbacks to the point prior to the execution of these
instructions.
the clones of short
This approach is unique in several ways:
1. It does not require SMT support and the operation
the duplicated
to be aware of
system needs not
instructions.
2. The entire pipeline except the commit stage is covered
instead of just functional units. Commit stage must be
duplicated in order to have full coverage.
to
paper
result
shows
quantify
attempts
and
time
3. Detecting the transient fault of short and long latency
instructions in different ways and having fewer penalty
cycles for fault recovery help to reduce performance
loss. Our
1.8~13.3%
simulation
performance degradation.
This
compare
performance degradation of various
redundant
schemes using a microarchitecture simulator when faults
are present. It assumes transient faults are few and occur
only as isolated single event. When a fault occurs during
the simulation, it is always detected. Performance lost due
to re-execution and accounting is logged. This paper does
not guarantee schemes used will detect all faults. It is
organized as follows. In the next section we provide
background research in this area. In section 3 we discuss
the details of Ditto Processor operation and additional
hardware overhead required. In section 4 we describe the
simulation experimental setup. In section 5 we present
results of our
simulation study together with some
observations. Finally, we draw some conclusion.
2. Background and Previous Works
Present single-chip Commercial-Off-The-Shelf (COTS)
microprocessors have concentrated the design effort on
performance. Reliability has not been the primary focus.
However, some fault tolerant features have been added into
COTS microprocessors [19][31].
two
connect
Hardware redundancy is one possible approach to cover
logic errors. The Pentium? Pro processor family has built-in
processors
mechanism to
the
into
master/checker duplexing configuration for
functional
redundancy checking. It allows duplicated chips to compare
their outputs and detect errors. However, this technique
required 100% or more logic overhead. Other hardware
redundancy
duplicating
selected logic within the chip and include error-checking
logic in all functional elements. IBM’s G5 processor is a
good example of this approach [19][21]. G5 duplicates its I-
unit and E-unit.
incurs no delay penalty with the
duplication because it is able to hide the compare-and-
detect cycle completely. Therefore G5 achieves improved
checking without any performance penalties. However,
there is a 35% circuit overhead.
approaches
adopted
involve
It
Recently there has been a resurgence of interest
in
utilizing time redundancy at the microarchitecture level to
recover transient faults. We may classify these related
works into two categories. The first category utilizes SMT
mechanism to execute two redundant threads in a processor
with SMT support. The second type focuses on modifying
superscalar processor. We group several existing designs
into these two time-redundant schemes.
A. Utilizing SMT mechanism in a SMT processor:
1. Active-stream/Redundant-stream
Simultaneous
Multithreading (AR-SMT) proposed by Rotenberg [22]
exploits several recent microarchitectural
trends to
protect computation from transient faults and some
restricted permanent faults. In this approach, a SMT
processor executes an instruction stream called active
stream (A-stream) first. Results committed from this
instruction stream are stored in a delay buffer. A
second stream (R-stream) of instructions tails behind
the A-stream with a distance equals to the length of the
delay buffer. Results from the R-stream execution are
compared with results stored in a delay buffer and
committed if they match. Since there are two threads
being executed,
two memory images
maintained.
there are
2. Recently, the same research group has proposed a new
paradigm for increasing both performance and fault
tolerance coverage called “slipstream”.
Instead of
executing two exact instruction streams as in AR-SMT,
slipstream processors’ A-stream is shortened by the
removal of ineffectual instructions. This approach [23]
allows the A-stream to run ahead of the R-stream and
thus provides not only fault-tolerant coverage but also
performance improvement.
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:09:01 UTC from IEEE Xplore.  Restrictions apply. 
and Redundantly Threaded
3. Work done by Reinhardt and Mukerjee on the
Simultaneous
(SRT)
processor [33] also utilizes redundant thread in a SMT
processor
faults. The SRT dynamically
schedules the redundant thread to hardware resources
to have higher performance. Their work introduces the
abstraction called sphere of replication to identify the
fault coverage. .
to detect
4. Rashid et. al. proposed fault tolerant mechanism in the
Multiscalar Architecture [24]. Multiscalar processor
usually has many processing units to exploit
the
instruction level parallelism (ILP). This technique
utilizes a minor part of the processing units for re-
executing the committed instructions. Both permanent
and transient faults in the processor units can be
detected.
B. Modified superscalar processor
1. Work done by Franklin [25] utilizes spare resources in
a superscalar processor to implement time-redundancy.
This approach duplicates all instructions at either the
dispatch or the issue stage. Duplicated instructions
occupy the otherwise under-utilized functional units to
produce checking results for verification.
capacity. After
2. Nickel et. al. [26] extended Franklin’s work and tried
to improve performance of time-redundant processors
by adding spare
an instruction
completes execution but before it
retired, a
is
duplicated copy is placed in a FIFO queue. This
duplicated instruction is re-scheduled and re-executed.
In order to minimize the performance loss, this method
also strategically adds extra functional units to the
pipeline.
3. Ray et. al. [32] proposed a similar scheme to what
Franklin has done. A single instructions stream creates
multiple redundant threads at decode stage and results
from duplicated threads are verified at commit stage.
4. Mendelson et. al. [27] mentioned that if the decoding
logic is not implemented by table lookup (memory
structure) one needs to employ some methods to
protect it from transient errors also. However, their
approach focused on re-executing the operations twice
execution stage and verifying results before
at
instruction commit. This
scheme has minimum
hardware requirement to perform error checking and
has less performance impact due to error detection.
However, compare to previous studies, this scheme has
less
fault coverage in that
it only verified the
correctness of functional units.
5. Austin et. al. [34][35][36] introduced the concept of
using a less complex checker named DIVA to verify
faults. The DIVA checker can verify not only transient
faults
the
performance impact of this extra checking mechanism
is less than 3%.
faults. Moreover,
design
also
but
loss. While works on
In summary, we found works on using SMT to detect
fault have better fault coverage but suffer higher percentage
performance
existing
superscalar processor, they do not cover the fault that may
occur at the frond-end of the pipeline. In this study, our
goal is to provide a fault tolerant processor which has low
cost, low performance degradation and high fault coverage.
We use a microarchitecture simulator
to quantify the
performance loss of several schemes.
using
3. Design of Ditto Processor
those
including
instructions
Ditto Processor differs from previous approaches in that
it splits long latency operations and short latency operations
into different verification path. After the instructions are
decoded,
long latency instructions are identified and
speculatively executed twice. Results of these long latency
instructions are compared but they are not committed. All
non-speculative
non-
speculative long latency instructions are cloned before
retirement. These duplicated instructions are held in a
buffer and send back to the beginning of the pipeline. Since
the result of long latency instructions are executed twice
and checked, the clones of these instructions would not pass
execution stage again after renaming operation are verified.
For the clones of short latency operations, once they
completed the re-execution, results are compared with the
results of original
instructions. Any transient fault can
potentially be discovered when the result of
the re-
execution differs from that of the original execution and
simple recovery scheme is used. If faults occurs at the
decode stage, results will differ also and be detected.
Prior to our main study, we observe, in an average, only
12% of the resources are utilized for integer and floating-
point applications on a baseline 8-issue superscalar
processor. This means that there are plenty of opportunities
to take advantage of these unused resources to hide the
overhead of program re-execution, verification and
transient fault recovery. However execution in a superscalar
tends to be busty at times. Without careful organization,
time-redundancy
its
performance.
degrades
through
cloning
still
In the following sections we will describe in more
details the design of Ditto processor. After reading through
the design details, interested reader may find an example of
pipeline flow for a small piece of sample code in the
appendix.
3.1 What hardware is added to support fault-
tolerant mechanism?
Figure 1 illustrates the basic microarchitecture diagram
of Ditto processor. It has two additional blocks - a “delay
buffer” and a “verify logic”. Several existing blocks in a
superscalar processor also need to be modified. These
include the re-order buffer (ROB), the commit logic, the
fetch unit and the decode unit. We describe the changes
needed for each of these blocks.
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:09:01 UTC from IEEE Xplore.  Restrictions apply. 
L 1 I n s t r u c t i o n C a c h e
B r a n c h
P r e d i c t i o n U n i t
F e t c h U n i t
C l o n e d F e t c h U n i t
D e l a y B u f f e r
R e o r d e r B u f f e r
N o r m a l
I n s t r u c t i o n s
s t r e a m
C l o n e d
I n s t r u c t i o n s
s t r e a m
( L P - R O B )
R e g i s t e r F i l e
D e c o d e r
C l o n e d D e c o d e r
R e n a m e r
L o a d
S t o r e
Q u e u e
S c h e d u l e r
R e a d R e g i s t e r / B y p a s s
l o g i c
L 1 D a t a C a c h e
F u n c t i o n a l E x e c u t i o n U n i t
V e r i f y
l o g i c
W r i t e b a c k
l o g i c
P r o c e s s o r C o r e
C o m m i t L o g i c
Figure 1 Basic Architecture of Ditto Processor
the
code
that
short
suggest
copied from the delay buffer to the result field of LP-
ROB. Error Correction Code (ECC) checking mechanism
protects this copy operation. In order to differentiate long
latency instruction and short latency instruction, extra bit
is added to each ROB entry. We will describe how to