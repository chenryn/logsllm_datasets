the run-time per IP is O(logk). In Step 4, we compare each
pair of preﬁxes in Told,z and Told,z−1, so our run-time for
Step 4 is O(k). In Step 5, we examine potential ∆-change
preﬁx together with its parents, so our run-time is bounded
by O(k log k). For Step 6, we examine each potential ∆-
change preﬁx together with its children subtrees in Tcurr,
and since Tcurr is a k-IPtree, the run-time is bounded by
O(k). Thus, the total run-time of ∆-Change, for an input
sequence of length n, becomes O(n log k + k log k).
We conclude with a note about accuracy: by design, ev-
ery ∆-change preﬁx discovered is guaranteed to reﬂect a
change in the IPs between the sequences sz and sz−1. If
a preﬁx has had high classiﬁcation error in Told,z and low
classiﬁcation error in Told,z−1, then that preﬁx is indeed
originating a different kind of trafﬁc in sz−1 than it did in
sz. Thus, the ∆-Change algorithm will have no false pos-
itives (though it may not ﬁnd all ∆-change preﬁxes, since
the Tcurr and Told are approximate).
3.3 The ∆-Motion Algorithm
In this section, we address the second question posed in
our problem: What regions of the Internet are prone to fre-
quent changes? The answer to this helps us pinpoint struc-
tural properties of the ∆-change preﬁxes.
A straightforward approach might be to use the ∆-
change preﬁxes output by ∆-Change, but as just described
Stream sz:
...
Tz-1
Classify each IP  
with Tz-1
Tz-1
Update with 
TrackIPTree
Stream s’z:
.
…
Tz
Change-IPTree Wz-1
Update with 
TrackIPTree
Change-IPTree Wz
Figure 9. High-level approach of ∆-Motion
/0
/1
/16
/17
No Change
No Change Change
Figure 10. Example Change-IPTree: Partitioning the
IP address space into “change” and “no-change” re-
gions. This is just like the regular IPTree in Figure 1, but
with the leaf labels denoting “change” or “no-change”.
in Section 3.2, this list of ∆-change preﬁxes may be incom-
plete: ∆-Change can only ensure that every identiﬁed preﬁx
is truly a ∆-change preﬁx (i.e., there are no false positives),
but not that every ∆-change preﬁx is discovered (i.e., there
may be false negatives). However, there is additional infor-
mation in the structure of the learned IPtree Told as well as
the input data sequence sz that we can exploit.
To answer our question, we need to partition the IP ad-
dress space into regions that change quickly and regions that
change slowly. We ﬁrst observe that this problem may be
modeled as another instance of the problem of learning an
IPtree – we need simply to learn a decision tree over the IP
address space where the leaf labels denote “change” or “no
change”, rather than “malicious” or “non-malicious”. For
clarity, we deﬁne this IPTree as a change-IPTree; Figure 10
shows an example of such an IPtree. Therefore, if we get
access to IPs labelled with “change” or “no change” (rather
than our usual sequences of IPs labelled with “malicious” or
“non-malicious”), and we directly use TrackIPTree to solve
this problem.
Recall that we denote sz to be the part of the stream that
appears in interval z. ∆-Motion uses the IPtree Tz−1 to an-
notate each IP i in sz. If the label of IP i matches the predic-
tion of Tz−1, it pairs IP i with label ”no change”, and if they
do not match, it pairs the IP with a label ”change”. We thus
have a new stream s′
z derived from sz, where the label of
each IP is ”change” or ”no change”. Next, we apply Track-
IPTree on this new stream, and the resulting change-IPtree
differentiates preﬁxes that change frequently from those do
not change frequently. We use Wz to denote this change-
IPtree built on the stream s′
z of IPs labeled with ”change”
or ”no change”. Even though the IPtree Tz−1 we use to
generate the new labels is approximate, it typically has a
very high accuracy and so the new stream will typically
have only a little noise. We note that the space and run-
time complexity of ∆-Motion is identical to TrackIPTree:
its data structure uses only three IPTrees (a change-IPTree
and two regular IPTrees); each step of ∆-Motion applies a
part of TrackIPTree, and the different parts of TrackIPTree
are applied three times in ∆-Motion.
4 Experimental Results
Data.
Our ﬁrst data set uses spam as our source of ma-
licious activity. Our data is collected from the operational
mailservers of a tier-1 ISP which handle mail for total of
over 8 million subscribers. We collected data in two pe-
riods: from mid-April to mid-August 2010 over 120 days,
and from mid June to late July 2012, over 41 days. Our data
set includes the IP addresses of the senders’ mail servers and
the number of spam and legitimate messages that each mail
server sends in a 5-minute interval; we do not collect any
other information. We use the mailserver’s spam-ﬁltering
system (Brightmail) as labels for IP addresses in our learn-
ing algorithm; a single IP address can thus be labeled mali-
cious at one point in time and non-malicious at a different
point, as it may send legitimate messages at some points and
spam at others. In total, the IP addresses in our data have
sent over 5.3 billion spam and 310 million legitimate mes-
sages. While our data may have some noise in labeling (due
to Brightmail mislabeling spam as legitimate mail and vice-
versa), because the algorithm is adaptive and noise-tolerant,
a small fraction of inaccurate labels in the data will not have
a signiﬁcant long-term impact on the tree.
Our second data set is based on botnet activity from Oc-
tober 2011 to January 2012. For this data set, we ﬁrst ob-
tain a distribution of the active IP addresses across the Inter-
net by collecting daily snapshots of ﬂows sampled from IP
backbone trafﬁc. All together, our monitoring points cover
80% of the trafﬁc carried by the IP backbone. On any given
day, our data includes 24-28 million unique IP addresses.
We use botnet activity to label these IP addresses as ma-
licious or non-malicious for our algorithms. In particular,
we obtain a daily snapshot of IP addresses within a tier-1
ISP that are part of a botnet, as identiﬁed by the ISP’s secu-
rity vendors. These security vendors employ a combination
of monitoring algorithms, sinkholes, spam traps and mal-
ware binary analysis to identify and track bot IP addresses,
and the daily snapshot includes all the bot IPs observed by
the vendors on that particular day – speciﬁcally, a bot IP is
included in the list for a particular day only if it has gen-
erated activity matching a signature on that particular day
6 The botnet feed contains around 30,000-100,000 unique
IP addresses daily (these include drones as well as the re-
sponsible C&C servers), and the feed includes over 2.64
million unique bot IP addresses in total across 94 days of
data. We label an IP address as malicious on day i if it ap-
pears in the botnet feed on day i. As in the spam data set,
any noise in the input data stream will be carried over to our
results; however, if there is a only small amount of noise
in the labeling, the adaptive nature of the algorithm ensures
that there will not be a long-term impact on the tree.
Our results demonstrate that our algorithms are able to
discover many changes in the Internet’s malicious activ-
ity, and do so substantially better than alternate approaches.
The exact ∆-change preﬁxes we detect are, of course, spe-
ciﬁc to our data sets, and for conﬁdentiality reasons, we
anonymize the owning entities of all the preﬁxes in the re-
sults. Our results show two examples of how our algorithm
can be applied on real data sets from operational networks,
and discover changes that operators were unaware of.
Experiment Setup.
Throughout our experiments, we
keep the algorithm parameters ﬁxed. We set ǫ = 0.05,
following [29]. We use IPtrees of size k = 100, 000 for
spam data and k = 50, 000 for the botnet data, as they
make accurate predictions on the input stream, and a fur-
ther increase in k does not substantially increase the tree’s
accuracy. We measure the accuracy of our algorithms on
a per-IP basis (following [29]), and the accuracy of our
constructed IPtrees are similar to [29]. All our change-
detection experiments are performed on day-length inter-
vals, i.e., each of the three trees is built, tested and compared
across different days. We use three states for the preﬁxes,
split by legitimate-ratio thresholds: [0, 0.33), [0.33, 0.75),
and [0.75, 1]. We term these states bad, neutral and good
states respectively, and this means that a preﬁx state is as-
signed as “good” if it sends at least 75% non-malicious traf-
ﬁc, “neutral” if it sends 33% − 75% non-malicious trafﬁc,
and “bad” if it sends less than 33% non-malicious trafﬁc.
With the thresholds of the set of states, we derive γ = 33%.
We set allowable error τ = 5% throughout, and the mini-
mum trafﬁc needed θ = 0.01% and 0.05%. We chose these
values for τ and θ because in our experiments, we are able
to obtain a list of ∆-change preﬁxes that is small enough to
be manually analyzed, and yet large enough for us to dis-
cover interesting trends across our data sets. Our parame-
ters remain stable throughout our data set when we seek to
analyze changes across day-long intervals. As operator re-
sources allow, these parameters can be changed to allow for
the discovery of either more ﬁne-grained changes (say, with
smaller of θ or larger values of k) or more coarse-grained
6While there are bound to be inaccuracies – both false positives and
false negatives – in this dataset due to the difﬁculty of identifying botnets,
our results demonstrate that our algorithms are able to highlight those pre-
ﬁxes where signiﬁcant changes occur as a function of the input data.
changes. Our experiments were run on a on a 2.4GHz
Sparc64-VI core. Our current (unoptimized) implementa-
tion takes 20-22 minutes to process a day’s trace (around
30-35 million IP addresses) and requires less than 2-3 MB
of memory storage.
We note that the ground truth in our data provides labels
for the individual IP addresses, but does not tell us the pre-
ﬁxes that have changed. Thus, our ground truth allows us to
conﬁrm that the learned IPTree has high accuracy, but we
cannot directly measure false positive rate and false nega-
tive rate of the change-detection algorithms. Thus, our ex-
perimental results instead demonstrate that our algorithm
can ﬁnd small changes in preﬁx behaviour very early on real
data, and can do so substantially better than competing ap-
proaches. Our operators were previously unaware of most
of these ∆-change preﬁxes, and as a consequence, our sum-
marization makes it easy for operators to both note changes
in behaviour of speciﬁc entities, as well as observe trends in
malicious activity. 7
4.1 Comparisons with Alternate Approaches
We ﬁrst compare ∆-Change with previous approaches
and direct extensions to previous work. We compare two
different possible alternate approaches with ∆-Change: (1)
using a ﬁxed set of network-based preﬁxes (i.e., network-
aware clusters, see Sec. 2.2) instead of a customized IP-
Tree, (2) directly differencing the IPTrees instead of using
∆-Change. We focus here on only spam data for space rea-
sons.
Network-aware Clusters.
As we described in Sec-
tion 3.2, our change-detection approach has no false pos-
itives – every change we ﬁnd will indeed be a change in
the input data stream. Thus, we only need to demonstrate
that ∆-Change ﬁnds substantially more ∆-changes than
network-aware clusters (i.e., has a lower false negative rate),
and therefore, is superior at summarizing changes in mali-
cious activity to the appropriate preﬁxes for operator atten-
tion.
We follow the methodology of [29] for labeling the
preﬁxes of the network-aware clusters optimally (i.e., we
choose the labeling that minimizes errors), so that we can
test the best possible performance of network-aware clus-
ters against ∆-Change. We do this allowing the network-
aware clusters multiple passes over the IP addresses (even
though ∆-Change is allowed only a single pass), as detailed
in [29]. We then use these clusters in place of the learned
IPTree in our change-detection algorithms.
We ﬁrst compare ∆-change preﬁxes identiﬁed by the
network-aware clustering and ∆-Change. This compari-
son cannot be directly on the preﬁxes output by the two ap-
7As discussed in Section 1, our evaluation focuses exclusively on
changes in preﬁx behaviour, since prior work [28, 29] already ﬁnds per-
sistent malicious behaviour.
s
e
x
i
f
e
r
P
e
g
n
a
h
c
−
∆
f
o
.
o
N
120
100
80
60
40
20
0
∆−Change
Network−aware
15
20
Interval in Days
25
30
35
s
e
x
i
f
e
r
P
e
g
n
a
h
c
−
∆
n
i
s
P
I
106
105
104
103
∆−Change
Network−aware
15
20
Interval in Days
25
30
35
(a) ∆-change Preﬁxes
(b) IPs in ∆-change preﬁxes
Figure 11. Comparing ∆-Change algorithm with
network-aware clusters on the spam data: ∆-Change
always ﬁnds more preﬁxes and covers more IPs
proaches, as slightly different preﬁxes may reﬂect the same
underlying change in the data stream, e.g., network-aware
clusters might identify a /24 while ∆-Change identiﬁes a
/25.
In order to account for such differences, we group
together preﬁxes into distinct subtrees, and match a group
from the network-aware clustering to the appropriate group
from ∆-Change if at least 50% of the volume of changed
IPs in network-aware clustering was accounted for in ∆-
Change. In our results, network-aware clustering identiﬁed
no ∆-change preﬁxes that were not identiﬁed by ∆-Change;
otherwise, we would have do the reverse matching as well.
Furthermore, this is what allows us to compare the num-
ber of ∆-changes that were identiﬁed by both algorithms,
otherwise we would not be able to make this comparison.
Fig. 11(a) shows the results of our comparison for 37
days. Network-aware clustering typically ﬁnds only a small
fraction of the ∆-change preﬁxes discovered by ∆-Change,
ranging from 10% − 50%. On average, ∆-Change ﬁnds
over 2.5 times as many ∆-change preﬁxes as network-aware
clusters. We compare also the number of IPs in ∆-change
preﬁxes identiﬁed by the network-aware clustering and ∆-
Change in Fig. 11(b). The ∆-change preﬁxes discovered
by ∆-Change typically account for a factor of 3-5× IP ad-