### Hypervisor Stacks, vCPU State, and Register Frames

Hypervisor stacks and vCPU register frames are designed to have lifetimes that align with their corresponding vCPUs. Short-lived objects will be managed using ephemeral mappings.

A hypervisor may consider guest memory as long-lived and map it entirely in the domain-private region to simplify `copy_from_guest()` and `copy_to_guest()` operations. However, we have chosen not to permanently map all guest memory in the hypervisor space, including in domain- and vCPU-private regions. This decision is based on lessons learned from ret2dir, where aliasing user memory in the kernel enables gadget injection at lower privilege levels. Therefore, our secret-free design employs ephemeral mappings to access guest memory, even when the hypervisor is entered under the guest's context, for a defense-in-depth approach.

### Isolation of Guest Registers and State

We define guest registers and their copies as secrets, necessitating the isolation of any spills of register state. Upon entry, the hypervisor switches to its stack, and a copy of the vCPU state (including the guest register frame) is spilled onto it. This could potentially leak sensitive data to speculative side channels.

Per-vCPU stacks increase memory consumption. For commercial cloud platforms, the maximum supported number of host pCPUs and total vCPUs are 512 and 2048 for Hyper-V, 768 and 4096 for ESX, and 288 host CPUs (1152 vCPUs assuming an overcommit factor of 4) for XenServer. Assuming 256 host cores with a total of 4096 vCPUs, introducing 4KiB per-pCPU bounce buffers and 16KiB per-vCPU stacks consumes 65MiB of memory. We believe this is not a substantial pressure on the host and represents a pessimistic case for a per-pCPU stack hypervisor.

### Ephemeral Mappings

In a secret-free hypervisor context, only the hypervisor image, the vCPU-private stack, the current vCPU's register state, and internal secret-less bookkeeping structures are visible. The hypervisor must create ephemeral mappings for short-lived objects or other accesses whose mappings are not present in the minimal address space. These include walking and modifying page tables, `copy_from_guest()`, and `copy_to_guest()` during hypercalls, background scrubbing of free heap memory, and more. This contrasts with existing hypervisor and OS kernel designs, as we never switch to the full page table but only grant temporary access necessary for the hypervisor to complete the current operation.

Mapping and unmapping for temporary access in the global map area can be costly due to the IPI and TLB operations, which multiply as the core count increases. For example, XPFO suffers a 27–31% performance degradation from IPIs even on a 4-core desktop after optimizations. Broadcasting is feasible with hardware acceleration, such as AMD Milan and Arm MP Extensions, which allow for TLB invalidation on all CPUs. However, we do not rely on hardware TLB broadcasting because such architectural assistance is not yet ubiquitous across ISAs or CPU generations.

When accessing guest memory during `copy_from_guest()`, another hypervisor context is unlikely to simultaneously copy and mutate data at the same page. Based on this observation, we introduce a per-vCPU ephemeral mapping infrastructure. The hypervisor uses local APIs for temporary access. Ephemeral mappings are created and destroyed in the local ephemeral address range, visible only to the current vCPU, avoiding scalability issues from broadcasting page table maintenance operations. Care must be taken to ensure the private ephemeral window does not outlive the underlying pages. For example, pages ballooned out by a guest may be allocated to other domains. The hypervisor must ensure vCPU ephemeral mappings are flushed during ballooning, or take references to prevent the underlying memory from changing ownership while the mappings are active.

### Self-Mapping Page Tables

Creating ephemeral mappings requires modifying the page table of the current hypervisor context. Without a direct map, we lose the ability to walk page tables conveniently. We use page table self-mapping to overcome this limitation, allowing us to locate and modify the PTEs of ephemeral mappings. This is a common technique in kernel code for PTE modification without manual page table walking. Note that self-mapping can only be used for a virtual address of the current installed page table, meaning it cannot act as a generic page table walker starting from an arbitrary root. A generic walker needs to be implemented on top of the ephemeral mapping infrastructure to map arbitrary physical addresses when the direct map is absent.

### The Map Cache

The cost of manipulating mappings locally is significantly higher than bitwise operations to access the direct map. For example, the x86 `invlpg` instruction for TLB invalidation is a serializing operation that flushes the pipeline. We introduce a map cache to allow for efficient ephemeral memory access. Ephemeral mappings often exhibit spatial and temporal locality: guest buffers passed in a hypercall are likely to be reused, and consecutive mappings are either at adjacent guest physical memory or share the same top levels of page directory pages.

The structure of the map cache is shown in Figure 4. When the hypervisor requests an ephemeral mapping to a Machine Frame Number (e.g., a 4KiB-page at physical address 0x1234000 has an MFN of 0x1234), it computes the hash slot based on the MFN and fetches the cached entry. If the entry already contains a mapping to the same MFN, the cache immediately returns the virtual address. If not, the entry is evicted from the cache, and a new mapping is inserted. Each ephemeral entry has a reference count, ensuring the mapping can be replaced only when all owners have dropped the reference via unmap calls.

We consider several optimizations, such as promoting an entry to become hot when the same mapping has been requested repeatedly, preventing immediate eviction even when all references are dropped. To increase map cache performance, we explore batch invalidation, superpage caches, and set associativity to reduce the cost of local TLB flushes, large region mappings, and collision cache misses, respectively. These caching optimizations must not expose additional side channels. For example, no ephemeral mapping to other domains can be cached or promoted as hot entries under the context of an unprivileged domU. This ensures that cached entries and map cache contention are only caused by the domain itself, preventing an attacker from revealing secrets by probing the timing of ephemeral mappings or speculatively accessing the cached entries.

With an optimal set of parameters, we achieve a hit rate of 80-90% in our implementation, greatly reducing the cost of ephemeral access from the hypervisor. A high-performance map cache demonstrates that the hypervisor address space can be minimized, making it unnecessary to switch to a full address space like KPTI or XPTI with a direct map for efficiency.

### µarch Isolation

We do not propose new defenses against pure microarchitectural sniffing attacks but do not exclude this category from the threat model for the secret-free hypervisor. As the overhead of secret freedom is small, we can compose it well with other known mitigations, including core scheduling and microarchitectural buffer flushing on context switch, to mitigate all categories in the threat model. This is also necessary for attacks that combine coercion and microarchitectural sharing. An attacker may mistrain a sibling vCPU thread from another domain to fill the shared L1 cache with secrets before launching L1TF. Without microarchitectural isolation, secret freedom would be unable to prevent this attack combination.

### Putting It All Together

Figure 5 shows the address space of a vCPU, separating it into multiple tiers of secret levels. At the global non-secret level, only the hypervisor image and non-secret data are visible. The next tier, domain secrets, is shared with all vCPUs of the same domain. Next, the hypervisor stack, register frames, and other vCPU secrets appear at the vCPU-private level. Ephemeral mappings and the map cache reside in the vCPU-private range, hidden from other vCPUs and domains while the hypervisor is temporarily accessing memory. This provides a minimal address space that is secret-free.

There are two major differences with state-of-the-art techniques. First, the minimal address space is maintained at all times. We never expose the full hypervisor space that contains secrets belonging to other domains, unlike PTI techniques. The hypervisor has the same restricted address space as the guest and only creates ephemeral mappings when necessary. Second, we adopt an allow-list approach by identifying and promoting non-secrets. Data is accessed via ephemeral mappings by default. Long-lived objects are added to the vCPU-private level first. We promote memory to be visible within a domain or globally only when it does not violate secret freedom and is performance-critical. Our approach does not identify secrets that need to be hidden; instead, it identifies performance-critical non-secrets that should be shared.

### Secret-Freedom as a Generic Design Principle

The recent epidemic of speculative vulnerabilities motivates the secret-free hypervisor design, aiming to introduce a comprehensive framework for isolating customer secrets in a multi-party cloud environment. The components introduced in this section are not unique to any specific hypervisor and can be easily extrapolated to a variety of implementations. For OS kernels, a secret-free design applies as well because the abstraction of kernel, user space, processes, and threads are analogous to hypervisor, guest domain, VMs, and vCPUs.

To demonstrate the generality of the secret-free principle, we implement and evaluate the design on multiple systems, including Xen (Type-I), Hyper-V (Type-I), bhyve (Type-II), and FreeBSD (UNIX kernel). We apply common secret-free design components to all systems and introduce minor changes to each. In this paper, we elaborate on the Xen hypervisor for detailed evaluation and analysis, demonstrating other implementations for comparison and showing secret-free as a generic mechanism, focusing on necessary adaptations for each type of kernel.

### Implementation: A Secret-Free Xen

We implemented the secret-free hypervisor in Xen 4.14.0 on x86_64 architecture. Several necessary adaptations were made to the Xen codebase in addition to the aforementioned secret-free components:

1. **Early Boot Direct Map**: Xen requires a direct map under 4GiB during early boot. We implemented a lightweight mapping mechanism by reserving 5 fixmap entries (for up to 5-level paging) to bootstrap Xen and set up initial address spaces, which is superseded by the per-vCPU ephemeral mapping infrastructure once bootstrapping is done.
2. **Domain Page Mapping API**: We replaced Xen’s `domain_page()` mapping API with per-vCPU ephemeral mappings and revealed three bugs, which have been fixed and merged upstream.

The amount of code changed is shown in Table I. We have sent the first patch series for new APIs and direct map teardown to Xen upstream for review. At present, 40 out of 54 patches have been merged into the latest main branch. We reported the bugs revealed by Secret-Free to Xen upstream, and our fixes have been merged.

### Evaluation of Secret-Free Xen

#### Experimental Setup

We evaluate our secret-free Xen implementation on an AMD system featuring a 12-core (24-thread) Ryzen 5900X CPU, 32GB of DDR4 3200MT/s RAM running Ubuntu 18.04 as dom0. We approximate a common cloud configuration using a guest with 8 vCPUs and 16GB RAM, matching an Azure A8v2 or AWS c4.2xlarge instance.

We evaluate performance with a range of benchmark suites, including the industry-standard SPEC-CPU2017 suite, micro-benchmarks for hypercall latency, context switch speed, IPI latency, and MMIO performance. We also analyze disk and network I/O to investigate cross-domain communication between domU front-end and dom0 back-end PV drivers. Lastly, we run real-world workloads representative of a wide range of cloud applications, including databases, HTTP servers, decompression, kernel builds, and scientific computing.

We build several Xen configurations with different mitigation options:

- **Baseline**: Xen without any compiled-in speculative mitigation facilities and with boot-time speculative defenses disabled. The baseline is susceptible to all speculative execution attacks that the underlying hardware is vulnerable to.
- **Default**: Xen with compiled-in mitigation support and with default boot-time mitigations by detecting the hardware. On the 5900X CPU, this enables IBPB, `lfence` for indirect branches, conditional branch hardening, and core scheduling.
- **XPTI**: Force enabling Xen Page Table Isolation for Meltdown mitigation in addition to default Xen parameters. PV only.

Figure 6 illustrates a 2-stage page table walk, where 20 ephemeral mappings are avoided by promoting EPT to global non-secrets.