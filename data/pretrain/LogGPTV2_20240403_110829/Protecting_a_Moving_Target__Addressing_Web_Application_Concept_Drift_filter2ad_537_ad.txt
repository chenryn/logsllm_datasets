injections (e.g., CVE-2009-1224), and command execution exploits (e.g., CVE-
2009-0258) that are reﬂected in request parameter values. In particular, we in-
cluded a total of 1000 attacks, comprised of 400 XSS attacks, 400 SQL injections,
and 200 command injections. The XSS attacks are variations on those listed in
[20], the SQL injections were created similarly from [21], and the command exe-
cution exploits were variations of common command injections against the Linux
and Windows platforms.
In both experiments, webanomaly was evaluated on a data set consisting of
HTTP traﬃc drawn from real-world web applications. This data was obtained
from several monitoring points at both commercial and academic sites. For each
application, the full contents of each HTTP connection observed over a period of
several months were recorded. The resulting ﬂows were ﬁltered using signature-
based techniques to remove known attacks, and then partitioned into distinct
training and test sets. In total, the data set contains 823 unique web applications,
36,392 unique resource paths, 16,671 unique parameters, and 58,734,624 HTTP
requests.
4.1 Eﬀects of Concept Drift
In the ﬁrst experiment, we demonstrate that concept drift as observed in real-
world web applications results in a signiﬁcant negative impact on false positive
rates. First, webanomaly was trained on an unmodiﬁed, ﬁltered data set. Then,
the detector analyzed a test data set Q to obtain a baseline ROC curve.
After the baseline curve had been obtained, the test data set was processed to
introduce new behaviors corresponding to the eﬀects of web application changes,
such as upgrades or source code refactoring, obtaining Qdrift. In this manner, the
set of changes in web application behavior was explicitly known. In particular, as
Protecting a Moving Target: Addressing Web Application Concept Drift
35
Table 1. Reduction in the false positive rate due to HTTP response modeling for
various types of changes
Change type Anomalies False Positives Reduction
New session ﬂows
New parameters
Modiﬁed parameters
6,749
6,750
5,785
Total
19,284
0
0
4,821
4,821
100.0%
100.0%
16.6%
75.0%
detailed in Table 1, 6,749 new session ﬂows were created by introducing requests for
new resources and creating request sequences for both new and known resources
that had not previously been observed. Also, new parameter sets were created
by introducing 6,750 new parameters to existing requests. Finally, the behavior
of modeled features of parameter values was changed by introducing 5,785 muta-
tions of observed values in client requests. For example, each sequence of resources
(cid:2)/login, /index, /article(cid:3) might be transformed to (cid:2)/login, /article(cid:3). Sim-
ilarly, each request like /categories found in the traﬃc might be replaced with
/foobar. For new parameters, a set of link or form parameters might be updated
by changing a parameter name and updating requests accordingly.
It must be noted that in all cases, responses generated by the web application
were modiﬁed to reﬂect changes in client behavior. To this end, references to new
resources were inserted in documents generated by the web application, and both
links and forms contained in documents were updated to reﬂect new parameters.
webanomaly – without the HTTP response modeling technique enabled – was
then run over Qdrift to determine the eﬀects of concept drift upon detector
accuracy. The resulting ROC curves are shown in Figure 4a. The consequences
of web application change are clearly reﬂected in the increase in false positive
rate for Qdrift versus that for Q. Each new session ﬂow and parameter manifests
as an alert, since the detector is unable to distinguish between anomalies due to
malicious behavior and those due to legitimate change in the web application.
4.2 Change Detection
The second experiment quantiﬁes the improvement in the detection accuracy
of webanomaly in the presence of web application change. As before, the detec-
tor was trained over an unmodiﬁed ﬁltered data set, and the resulting proﬁles
were evaluated over both Q and Qdrift. In this experiment, however, the HTTP
response modeling technique was enabled.
Figure 4b presents the results of analyzing HTTP responses on detection ac-
curacy. Since many changes in the behavior of the web application and its clients
can be discovered using our response modeling technique, the false positive rate
for Qdrift is greatly reduced over that shown in Figure 4a, and approaches that
of Q, where no changes have been introduced. The small observed increase in
false positive rate can be attributed to the eﬀects of changes in parameter val-
ues. This occurs because a change has been introduced into a parameter value
36
F. Maggi et al.
e
t
a
r
e
v
i
t
i
s
o
p
e
u
r
T
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0
 1
 0.9
 0.8
 0.7
 0.6
e
t
a
r
e
v
i
t
i
s
o
p
e
u
r
T
 0.05
 0.1
False positive rate
Detection accuracy (Q)
Detection accuracy (Qdrift)
 0.15
 0.2
 0.5
 0
 0.05
 0.1
False positive rate
Detection accuracy (Q)
Detection accuracy (Qdrift)
 0.15
 0.2
(a) Response modeling disabled.
(b) Response modeling enabled.
Fig. 4. Detection and false positive rates measured on Q and Qdrift, with HTTP re-
sponse modeling enabled in (b)
submitted by a client to the web application, and no indication of this change
was detected on the preceding document returned to the client (e.g., because no
 were found).
Table 1 displays the individual contributions to the reduction of the false pos-
itive rate due to the response modeling technique. Speciﬁcally, the total number
of anomalies caused by each type of change, the number of anomalies erroneously
reported as alerts, and the corresponding reduction in the false positive rate is
shown. The results displayed were generated from a run using the optimal op-
erating point (0.00144, 0.97263) indicated by the knee of the ROC curve in
Figure 4b. For changes in session ﬂows and parameters sets, the detector was
able to identify an anomaly as being caused by a change in web application be-
havior in all cases. This resulted in a large net decrease in the false positive rate
of the detector with response modeling enabled. The modiﬁcation of parame-
ters is more problematic, though; as discussed in Section 3.3, it is not always
apparent that a change has occurred when that change is limited to the type of
behavior a parameter’s value exhibits.
From the overall improvement in false positive rates, we conclude that HTTP
response modeling is an eﬀective technique for distinguishing between anomalies
due to legitimate changes in web applications and those caused by malicious
behavior. Furthermore, any anomaly detector that does not do so is prone to
generating a large number of false positives when changes do occur in the mod-
eled application. Finally, as it has been shown in Section 2, web applications
exhibit signiﬁcant long-term change in practice, and, therefore, concept drift is
a critical aspect of web application anomaly detection that must be addressed.
5 Related Work
Anomaly-based IDSs have evolved considerably after Denning’s seminal paper
on intrusion detection [22]. Besides network-based detection [23], anomaly-based
Protecting a Moving Target: Addressing Web Application Concept Drift
37
techniques have been also exploited to protect the operating system. In [24],
the normal behavior of applications is captured by modeling system call se-
quences [25,26] along with features of their arguments. In [27], a mixture of
machine learning techniques is exploited to detect anomalous system calls in
the Linux kernel. Ad-hoc distances between system calls are deﬁned to perform
clustering in order to identify natural classes of similar calls. The reduced size
of the clustered input makes the training of Markov chains eﬃcient. The behav-
ior of each host application is modeled as Markov chains on which probabilistic
thresholds are calculated to detect misbehaving sequences.
PAYL [28] is a network-based anomaly detection system. It creates models of
each service’s normal behavior by recording byte frequencies of network streams.
This approach has been further explored in [29], where higher-order n-grams are
used instead of frequencies. Instead, [30] exploits self-organizing maps to classify
the payload of IP frames in order to separate normal packets from malicious
ones.
Anomaly-based detectors of web attacks have been ﬁrst proposed in [5], where
a multi-model approach to characterizing the normal behavior of web application
parameters is proposed.
A tool to protect against code-injection attacks has been recently proposed
in [17]. The approach exploits a mixture of Markov chains to model legitimate
payloads at the HTTP layer. The computational complexity of n-grams with
large n is solved using Markov chain factorization, making the system algorith-
mically eﬃcient.
HTTP responses are exploited in [8]. Besides other features, the DOM is
modeled to enhance the detection capabilities of SQL injection and cross-site
scripting attacks. The fact that it relies on HTTP responses makes this approach
similar to ours. However, we exploit HTTP responses to detect changes and
update other anomaly models accordingly, instead of modeling responses per se.
A complementary tool is proposed in [6], where an approach to improve the
explanatory power of anomaly-based detectors is proposed along with a cluster-
ing and classiﬁcation methodology to reduce their false positive rate. Another
technique to increase detection accuracy is presented in [31], where Bayesian
networks are exploited to combine models and deﬁne inter-model dependencies.
The resulting system shows a signiﬁcant reduction in false alerts.
Reduction of false positives in anomaly detection systems has also been stud-
ied in [13]. Similar behavioral proﬁles for individual hosts are grouped together
using a k-means clustering algorithm. However, the distance metric used was
not explicitly deﬁned. Coarse network statistics such as the average number of
hosts contacted per hour, the average number of packets exchanged per hour,
and the average length of packets exchanged per hour are all examples of metrics
used to generate behavior proﬁles. A voting scheme is used to generate alerts,
in which alert-triggering events are evaluated against proﬁles from other mem-
bers of that cluster. Events that are deemed anomalous by all members generate
alerts.
38
F. Maggi et al.
6 Conclusions
In this work, we have identiﬁed the natural dynamicity of web applications as an
issue that must be addressed by modern anomaly-based web application anomaly
detectors in order to prevent increases in the false positive rate whenever the
monitored web application is changed. We refer to this frequent phenomenon
the web application concept drift.
We propose the use of novel HTTP response modeling techniques to discrim-
inate between legitimate changes and anomalous behaviors in web applications.
More precisely, responses are analyzed to ﬁnd new and previously unmodeled pa-
rameters. This information is extracted from anchors and forms elements, and
then leveraged to update request and session models. We have evaluated the
eﬀectiveness of our approach over an extensive real-world data set of web appli-
cation traﬃc. The results show that the resulting system can detect anomalies
and avoid false alerts in the presence of concept drift.
As future work, we plan to investigate the potential beneﬁts of modeling the
behavior of JavaScript code, which is becoming increasingly prevalent in modern
web applications. Also, additional, richer, and media-dependent response models
must be studied to account for interactive client-side components, such as Adobe
Flash and Microsoft Silverlight applications.
Acknowledgments
The authors wish to thank the anonymous reviewers and our shepherd, Manuel
Costa, for their insightful comments. This work has been supported by the
National Science Foundation, under grants CCR-0238492, CCR-0524853, and
CCR-0716095, and by the European Union though the grant FP7-ICT-216026-
WOMBAT.
References
1. Turner, D., Fossi, M., Johnson, E., Mark, T., Blackbird, J., Entwise, S., Low,
M.K., McKinney, D., Wueest, C.: Symantec Global Internet Security Threat Report
– Trends for July-December 2007. Technical Report XII, Symantec Corporation
(April 2008)
2. Shezaf, O., Grossman, J., Auger, R.: Web Hacking Incidents Database (March
2009), http://whid.xiom.org
3. Open Security Foundation: DLDOS: Data Loss Database – Open Source (March
2009), http://datalossdb.org/
4. Cho, S., Cha, S.: SAD: web session anomaly detection based on parameter estima-
tion. In: Computers & Security, vol. 23, pp. 312–319 (2004)
5. Kruegel, C., Robertson, W., Vigna, G.: A Multi-model Approach to the Detection
of Web-based Attacks. Journal of Computer Networks 48(5), 717–738 (2005)
6. Robertson, W., Vigna, G., Kruegel, C., Kemmerer, R.A.: Using Generalization and
Characterization Techniques in the Anomaly-based Detection of Web Attacks. In:
Proceedings of the Network and Distributed System Security Symposium (NDSS
2006), San Diego, CA, USA (February 2006)
Protecting a Moving Target: Addressing Web Application Concept Drift
39
7. Guangmin, L.: Modeling Unknown Web Attacks in Network Anomaly Detection.
In: Proceedings of the 3rd International Conference on Convergence and Hybrid
Information Technology (ICCIT 2008), Washington, DC, USA, pp. 112–116. IEEE
Computer Society, Los Alamitos (2008)
8. Zanero, S., Criscione, C.: Masibty: A Web Application Firewall based on Anomaly
Detection. In: DeepSec - In-depth security conference (November 2008)
9. Citrix Systems, Inc.: Citrix Application Firewall (January 2009),
http://www.citrix.com/English/PS2/products/product.asp?contentID=25636
10. F5 Networks, Inc.: BIG-IP Application Security Manager (January 2009),
http://www.f5.com/products/big-ip/product-modules/application-
security-manager.html
11. Breach Security, Inc.: Breach WebDefend (January 2009),
http://www.breach.com/products/webdefend.html
12. Axelsson, S.: The Base-Rate Fallacy and its Implications for the Diﬃculty of In-
trusion Detection. In: Proceedings of the ACM Conference on Computer and Com-
munications Security (CCS 1999), pp. 1–7. ACM, New York (1999)
13. Frias-Martinez, V., Stolfo, S.J., Keromytis, A.D.: Behavior-Proﬁle Clustering for
False Alert Reduction in Anomaly Detection Sensors. In: Proceedings of the Annual
Computer Security Applications Conference (ACSAC 2008), Anaheim, CA, USA
(December 2008)
14. Escalante, H.J., Fuentes, O.: Kernel Methods for Anomaly Detection and Noise
Elimination. In: Proceedings of the International Conference on Computing (CORE
2006), Mexico City, Mexico, pp. 69–80 (2006)
15. Kim, S.i., Nwanze, N.: Noise-Resistant Payload Anomaly Detection for Network
Intrusion Detection Systems. In: Proceedings of the Performance, Computing and
Communications Conference (IPCCC 2008), Austin, TX, USA, pp. 517–523. IEEE
Computer Society, Los Alamitos (2008)
16. Cretu, G.F., Stavrou, A., Locasto, M.E., Stolfo, S.J., Keromytis, A.D.: Casting
out Demons: Sanitizing Training Data for Anomaly Sensors. In: Proceedings of the
2008 IEEE Symposium on Security and Privacy (S&P 2008), Oakland, CA, USA,
pp. 81–95. IEEE Computer Society, Los Alamitos (2008)
17. Song, Y., Stolfo, S., Keromytis, A.: Spectrogram: A Mixture-of-Markov-Chains
Model for Anomaly Detection in Web Traﬃc. In: Proc. of the 16th Annual Network
and Distributed System Security Symposium, NDSS (2009)
18. Schlimmer, J., Granger, R.: Beyond incremental processing: Tracking concept drift.
In: Proceedings of the Fifth National Conference on Artiﬁcial Intelligence, vol. 1,
pp. 502–507 (1986)
19. Kolter, J., Maloof, M.: Dynamic weighted majority: An ensemble method for drift-
ing concepts. The Journal of Machine Learning Research 8, 2755–2790 (2007)
20. Hansen, R.: (RSnake): XSS (Cross Site Scripting) Cheat Sheet (June 2009),
http://ha.ckers.org/xss.html
21. Mavituna, F.: SQL Injection Cheat Sheet (June 2009),
http://ferruh.mavituna.com/sql-injection-cheatsheet-oku/
22. Denning, D.E.: An Intrusion-Detection Model. IEEE Transactions on Software
Engineering 13(2), 222–232 (1987)
23. Lee, W., Stolfo, S.J.: A Framework for Constructing Features and Models for In-
trusion Detection Systems. ACM Transactions on Information and System Secu-
rity 3(4), 227–261 (2000)
24. Mutz, D., Valeur, F., Vigna, G., Kruegel, C.: Anomaly system call detection. ACM
Transactions on Information and System Security 9(1), 61–93 (2006)
40
F. Maggi et al.
25. Forrest, S., Hofmeyr, S.A., Somayaji, A., Longstaﬀ, T.A.: A Sense of Self for Unix
Processes. In: Proceedings of the IEEE Symposium on Security and Privacy (S&P
1996), Oakland, CA, USA, pp. 120–128. IEEE Computer Society, Los Alamitos
(1996)
26. Wagner, D., Dean, D.: Intrusion Detection via Static Analysis. In: Proceedings of
the IEEE Symposium on Security and Privacy (S&P 2001), Oakland, CA, USA,
pp. 156–168. IEEE Computer Society, Los Alamitos (2001)
27. Maggi, F., Matteucci, M., Zanero, S.: Detecting intrusions through system call
sequence and argument analysis. IEEE Transactions on Dependable and Secure
Computing 99(1) (5555)
28. Wang, K., Stolfo, S.J.: Anomalous Payload-based Network Intrusion Detection.
In: Jonsson, E., Valdes, A., Almgren, M. (eds.) RAID 2004. LNCS, vol. 3224, pp.
203–222. Springer, Heidelberg (2004)
29. Wang, K., Parekh, J.J., Stolfo, S.J.: Anagram: A Content Anomaly Detector Re-
sistant to Mimicry Attack. In: Zamboni, D., Kr¨ugel, C. (eds.) RAID 2006. LNCS,
vol. 4219, pp. 226–248. Springer, Heidelberg (2006)
30. Zanero, S.: Analyzing TCP traﬃc patterns using self organizing maps. In: Roli, F.,
Vitulano, S. (eds.) ICIAP 2005. LNCS, vol. 3617, pp. 83–90. Springer, Heidelberg
(2005)
31. Kruegel, C., Mutz, D., Robertson, W., Valeur, F.: Bayesian Event Classiﬁcation
for Intrusion Detection. In: Proceedings of the 19th Annual Computer Security
Applications Conference (ACSAC 2003), Las Vegas, NV, USA. IEEE Computer
Society, Los Alamitos (2003)