#backslash_quote = safe_encoding        # on, off, or safe_encoding  
#escape_string_warning = on     
#standard_conforming_strings = on  
#transform_null_equals = off  
```  
## 内存使用评估  
```  
# 1/4 主机内存   
shared_buffers = 24GB   
#temp_buffers = 8MB  
# 可以在会话中设置，如果有大量JOIN，聚合操作，并且期望使用hash agg或hash join。   
# 可以设大一些，但是不建议大于    四分之一内存除以最大连接数  .   
# (一条QUERY中可以使用多倍WORK_MEM，与执行计划中的NODE有关)    
work_mem = 8MB   
# min( 2G, (1/4 主机内存)/autovacuum_max_workers )    
maintenance_work_mem = 2GB     
#autovacuum_work_mem = -1      
# 建议 min( 512MB, shared_buffers/32 )   
wal_buffers = -1   
autovacuum_max_workers = 6   
max_connections = 2000    
总memory使用评估:     
shared buffer   shared_buffers  : 24GB  
vacuum          autovacuum_work_mem * autovacuum_max_workers  或  maintenance_work_mem * autovacuum_max_workers  : 2G*6=12G      
create index    maintenance_work_mem * 同时创建索引的并发  : 2G * 8 = 16G        (假设同时创建索引的进程为6个)        
group by, sort, hash agg, hash join    并发使用这些操作的SQL * work_mem      :   (max_connections/10)*8MB = 1.6GB  (假设十分之一的连接，每条SQL只用一份work_mem, 实际上复杂SQL可能用多份)       
wal buffer      wal_buffers  :         16MB      
connection      :   max_connections * 10MB    = 20GB      (假设每个连接使用10MB，实际上可能更多，relcache, syscache，与访问的对象有关)  
page table      :   页表，与shared_buffers，并发连接，以及连接TOUCH的SHARED BUFFER数，是否使用HUGE PAGE有关  
[《PostgreSQL Huge Page 使用建议 - 大内存主机、实例注意》](201803/20180325_02.md)    
```  
## 模板例子  
### 1、动态参数  
```  
port=xxx  
synchronous_commit = xx            # 异步复制:off,     同步复制: remote_write      
synchronous_standby_names = 'ANY 1 (*)'       # 三节点(1主2从)为例 , 任意一个从的FEEDBACK都可以释放同步事务的等待队列  
max_connections=        # 规格内存(GB)*1000*(1/4)/10   +   superuser_reserved_connections  
shared_buffers=           # IF use hugepage: 规格内存*(1/4)   ELSE: min(32GB, 规格内存*(1/4))    
max_prepared_transactions      # max_prepared_transactions=max_connections   
work_mem     # max(min(规格内存/4096, 64MB), 4MB)   
maintenance_work_mem         # min( 8G, (主机内存*1/32) )            
autovacuum_work_mem          # min( 8G, (规格内存*1/8)/autovacuum_max_workers )     
max_parallel_workers_per_gather      # min( max(2, CPU核数-4) , 24 )     
max_parallel_workers       # min(max(2, CPU核数-4)  , 32)  
max_wal_size           # min(shared_buffers*2,   用户存储空间/10)    
min_wal_size            # min(shared_buffers/2  , 用户存储空间/10)  
max_sync_workers_per_subscription   # min ( 32 , max(2, CPU核数-4) )    
effective_cache_size          # 规格内存 * 0.75  
autovacuum_max_workers      # max(min( 8 , CPU核数/2 ) , 5)    
temp_file_limit= 数据库规格内存大小  
```  
根据实际情况开启归档  
```  
archive_mode = on  
archive_timeout = '5min'  
archive_command='test ! -f /disk1/digoal/arch/%f && cp %p /disk1/digoal/arch/%f'  
#  也可以先设置为如下，规划好归档目录后再设置。  
# archive_command = '/bin/date'  # 开启归档，但是不COPY归档文件，  
```  
根据实际情况，设置预加载的SO库    
```  
shared_preload_libraries='pg_stat_statements,auth_delay,auto_explain'    
```  
根据实际情况，设置SSL链路    
```  
ssl=on    
ssl_cert_file = 'server.crt'    
ssl_key_file = 'server.key'    
```  
### 2、OS环境相关信任参数（固定参数）  
```  
data_sync_retry = off  
full_page_writes = on  
```  
### 3、固定静态参数（社区版参数）  
```  
listen_addresses='*'  
superuser_reserved_connections=100  
tcp_keepalives_idle=45  
tcp_keepalives_interval=10  
tcp_keepalives_count=10  
vacuum_cost_delay=0  
vacuum_cost_limit=10000  
bgwriter_delay=10ms  
bgwriter_lru_maxpages=1000  
bgwriter_lru_multiplier=10.0  
effective_io_concurrency=0  
max_worker_processes=256  
old_snapshot_threshold = -1  
wal_level = replica  
wal_compression = on  
wal_buffers=16MB  
wal_writer_delay=10ms  
checkpoint_timeout = 25min  
checkpoint_completion_target = 0.4  
max_wal_senders = 64  
max_replication_slots = 56  
max_logical_replication_workers = 56  
hot_standby = on  
max_standby_archive_delay = 300s  
max_standby_streaming_delay = 300s  
wal_receiver_status_interval = 1s  
hot_standby_feedback = off  
wal_receiver_timeout = 30s  
random_page_cost=1.1  
logging_collector=on  
log_truncate_on_rotation=on  
log_min_duration_statement=5s  
log_checkpoints=on  
log_error_verbosity=verbose  
log_lock_waits=on  
log_statement='ddl'  
log_temp_files=128MB  
track_io_timing=on  
track_functions=pl  
autovacuum = on  
log_autovacuum_min_duration=0  
autovacuum_analyze_scale_factor = 0.05  
autovacuum_freeze_max_age = 1200000000  
autovacuum_multixact_freeze_max_age = 1400000000  
autovacuum_vacuum_cost_delay=0  
statement_timeout = 0  
lock_timeout = 0  
idle_in_transaction_session_timeout = '1h'  
vacuum_freeze_table_age = 200000000  
vacuum_multixact_freeze_table_age = 200000000  
deadlock_timeout = 1s  
auth_delay.milliseconds=3s  
pg_stat_statements.max=5000  
pg_stat_statements.save=off  
pg_stat_statements.track=top  
pg_stat_statements.track_utility=off  
auto_explain.log_format=text  
auto_explain.log_analyze=off  
auto_explain.log_nested_statements=off  
auto_explain.log_triggers=off  
auto_explain.sample_rate=1  
auto_explain.log_buffers=off  
auto_explain.log_min_duration=-1  
auto_explain.log_timing=on  
auto_explain.log_verbose=off  
track_activity_query_size = 1024  
unix_socket_directories = '.'  
unix_socket_permissions = 0700  
log_timezone='UTC'  
huge_pages=try   
log_error_verbosity=verbose     # 改变后，前缀可能不同，需要注意。  
log_rotation_age=1h     
log_rotation_size = 100MB     
log_filename = 'postgresql-%H.log'   
autovacuum_vacuum_scale_factor = 0.02 # 0.005~ 0.15   
log_destination = 'csvlog'    
```  
### 4、建议只允许用户修改如下配置，默认值以及允许用户修改的范围如下：  
```  
temp_file_limit=规格内存大小                # -1,  16MB ~ 1024000MB      
wal_level=replica                 # replica , logical  
wal_keep_segments=0         #  0 ~ 1024000  
track_commit_timestamp=off        # off, on     
vacuum_defer_cleanup_age=0        #  0 ~ 5000000  
log_min_duration_statement=5s      #  -1 , 1s ~ 600s     
log_connections=off       # on, off  
log_disconnections=off   # on, off  
log_duration=off           # on, off  
log_statement='ddl'         # ddl, mod, all  
log_temp_files=128MB                     # 0, -1, 16MB ~ 1024MB  
default_transaction_deferrable=off          #  on, off     
statement_timeout = 0                           #  0,    3s ~ 3600s     
lock_timeout = 0                                    #  0,    3s ~ 600s     
idle_in_transaction_session_timeout = '1h'          #  0,    3s ~ 36000s     
extra_float_digits = 0              # -15~3, int     
old_snapshot_threshold=-1         # -1, 1min ~ 2880min   
autovacuum_vacuum_cost_delay = 0   # 0~50     
autovacuum_vacuum_cost_limit = 10000  # 5000 ~ 10000    
shared_buffers=min(32GB, 规格内存*(1/4))             # min(32GB, 规格内存*(1/4)) ,规格内存*(1/4)  
autovacuum_vacuum_scale_factor = 0.02    # 0.005~ 0.15  
synchronous_commit = off      # 当高并发写事务遇到了WAL瓶颈时，优先考虑提高磁盘IOPS能力，如果需要立即提升性能可以使用异步提交，或开启分组提交  
如果加了LOG审计的采样插件，再加上对应参数，允许用户修改，以及允许用户可以修改的范围。  
https://www.pgxn.org/dist/pg_sampletolog/    
```  
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")