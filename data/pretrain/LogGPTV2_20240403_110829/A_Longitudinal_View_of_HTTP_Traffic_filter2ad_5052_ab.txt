### Figure 7: Distribution of Requests per Server Hostname

Figure 7 illustrates the distribution of requests per server hostname. As discussed in §5, all requests to a specific server name, such as "www.cnn.com," are grouped together in this plot, regardless of the IP address that handles the request. The data shows that the distribution of requests per hostname remains relatively consistent over the years of our study. Many server hostnames are accessed infrequently, with the median being less than 10 requests per year. However, a small number of server hostnames are highly popular, with the maximum number of requests per hostname exceeding one million per year. We also observe changes in the top hostnames over time. For each year, we identified the top ten hostnames and found that four hostnames remained in the top ten for all four years, one hostname appeared in the top ten for three of the years, two hostnames were in the list for two years, and 17 hostnames appeared only once across the four years.

### Figure 8: Distribution of Requests per Object

Figure 8 presents the distribution of the number of requests per object. The distributions are similar across the years. The plot shows that request popularity closely follows a Zipf-like distribution. Over more than three orders of magnitude, the fall-off in the distribution matches a Pareto distribution with α = 1. Approximately 90% of the objects are accessed only once. Furthermore, only a small number of objects are requested more than 10 times. However, there are some popular objects that are requested thousands of times over the course of a year. It is important to note that we consider the entire URL, including parameters, as a distinct object, as unique sets of parameters at the end of a URL generally yield distinct outputs.

### Figure 9: Unique Objects per Hostname

Figure 9 depicts the distribution of the unique number of objects (determined by URL) per hostname over time. The data shows stability across the years of our study. One-third of the hostnames we encounter serve only a single unique object, and two-thirds serve ten or fewer objects. Similar to other aspects of web traffic, a small number of hostnames serve a large number of web objects. For instance, roughly 5% of the hostnames provide more than 100 objects, with some hostnames serving over one million objects.

### Caching and Conditional GETs

Object popularity has a direct impact on the effectiveness of caching. We use our data to investigate both visible end-host caching and potential savings from a network-based cache, as illustrated in Figure 10. First, we examine the number of bytes saved by end-host caches using conditional GET requests. These requests involve a client re-requesting an object in the browser cache, including the timestamp of the cached object in the GET request. If the object has been updated, the server will resend it; otherwise, it will send a 304 ("not modified") response, indicating that the version the client has is correct. As shown in the figure, the number of bytes fetched would increase by approximately 10% without these conditional GET requests. The use of conditional GETs across the dataset increases in proportion to the overall number of bytes downloaded.

Next, we explore the number of additional bytes that could benefit from caching at the institute level, i.e., with a shared proxy cache at the border shared by all users. We identify unique objects using the URL (including hostname) and object size. Ideally, we would include a stronger notion, such as a hash of the content itself, but our logs do not contain this information. To assess the accuracy of our heuristic, we analyzed 5.75 days of full-payload packet traces from January 2010. We formed tuples of URLs and sizes, (u, s), and computed an MD5 hash of the object for each tuple. We found that 1.4% of the 846K (u, s) pairs in the trace had multiple MD5s, representing 6.7% of the bytes fetched. Therefore, while we assume that if the object size remains the same, the object has not changed, this assumption is incorrect in a small number of cases. Additionally, we calculated the amount of cachable data for each month in isolation, without considering the timing out of objects or imposing limits on the number or size of objects held in the cache. Thus, our results represent an upper bound on how an actual institute-wide cache would perform under real-world constraints. As shown in Figure 10, the percentage of bytes that could be cached by a network-wide proxy is 10–20% across most of our study. In 2009, more than 25% of the GET requests could plausibly be handled by a cache, requiring over 10 GB of storage space, which is modest by modern standards. We note that our caching results may differ if the user population was larger.

### Server Structure and HTTP Transactions

Web traffic consists of a series of HTTP transactions that utilize TCP for reliable data transfer. Early HTTP used a separate TCP connection for each HTTP transaction, but with persistent HTTP connections, multiple transactions can be conducted over a single TCP connection. Figure 11 shows the total number of TCP connections observed for the sampled week of each month in our dataset, as well as the average number of HTTP transactions per TCP connection. The plot indicates a fairly stable number of connections and average transactions per connection, except for a significant drop in the reuse of TCP connections between November and December 2007. This resulted in a dramatic increase in the number of web connections observed, though the overall number of HTTP requests did not change significantly.

We attribute this change in delivery pattern to a software update on the web clients. To verify this, we identified the top 100 servers in each month by the overall number of requests and calculated the average number of transactions per connection for each server. We found 66 servers common across the top 100 lists for the two months. The average number of requests per connection dropped in December for all but one instance, with over 70% of the cases showing a drop of at least 10 requests. This suggests that the use of persistent connections decreased across the board, likely due to a client policy change, possibly caused by a widespread web browser upgrade.

### CDN and Server Hostnames

We next examine how websites are structured to serve content. Figure 12 shows the distribution of the number of hostnames each server IP address takes on over the course of each year in our study. Content Delivery Network (CDN) hosts can accommodate a wide range of logical hostnames using a single IP address. The distributions are similar across the years, with around 80% of the server IP addresses mapping to a single server hostname. Approximately 10% of the server IPs map to two hostnames, and a small percentage (≈5%) of server IPs accommodate three or more hostnames. A few IP addresses serve traffic for a large number of hostnames, with the maximum number of hostnames observed for a single IP address increasing over time.

In addition to using one IP address for multiple server hostnames, CDNs also use multiple IP addresses to serve content from a common server hostname, typically for load balancing and proximity to the requesting client. Figure 13 shows the distribution of the number of IP addresses used for each hostname observed for each year in our dataset. The figure indicates that 80–90% of the hostnames are served by one IP address, another 5–10% by two IP addresses, and approximately 5% by three or more IP addresses. Some hostnames have dozens to hundreds of IP addresses over the course of a year, with the maximum number of IP addresses for a single hostname increasing over time.

### Akamai CDN Traffic

To assess the extent to which content providers rely on CDNs, we focused on the Akamai CDN. A colleague provided us with a list of partial Akamai hostnames manually gathered for another project. These hostnames, derived from downloading known Akamai-based web pages from 300-400 locations worldwide, represent 12K Akamai IP addresses, which is an undercount of Akamai's footprint. We correlated the Akamai hostnames with DNS logs produced by Bro. For each web log, we used the corresponding DNS log to find resolutions for the Akamai names and record the associated IP addresses, allowing us to classify web traffic as Akamai or non-Akamai.

Figure 14 shows the percentage of bytes fetched in response to GET requests that are handled by Akamai servers. Across the time period of our study, we found that 15–30% of the bytes are delivered by Akamai. However, this is a lower bound due to our classification methodology. Over the years, ICSI users accessed Akamai-served content from over 9K distinct Akamai servers, with the number of observed Akamai servers increasing over time.

### Related Work

The literature on empirical evaluations of web traffic is extensive and diverse. Key topics include characterization and modeling, performance analysis, web applications, web technologies, web caching, and studies of the HTTP protocol. Our work adds longitudinal data to the existing body of research, providing a broader and more temporally extended perspective.

### Summary

In this paper, we used a three-and-a-half-year longitudinal dataset to assess various aspects of web operations. Our study provides a reappraisal of previous work and a broader temporal perspective. We found that some aspects of web traffic, such as the distribution of transaction types, have remained relatively static, while others, like the average size of GET and POST transactions, have changed. We also developed insights into the structure of the web, including the behavior of browser caches and the growing prominence of content distribution networks. While there are many more aspects of web operations to explore, we believe our contribution will help ground the community's mental models and experiments in long-term empirical observation.