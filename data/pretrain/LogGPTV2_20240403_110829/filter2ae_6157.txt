## 0X000 前言
这是该 `使用tensorflow自动识别验证码`系列的第三篇文章，  
本系列最后一篇。前面几章的回顾可以看这里。
  * [使用tensorflow自动识别验证码（一）--- CNN基础模型以及示例](https://xianzhi.aliyun.com/forum/topic/1505/)
  * [使用tensorflow自动识别验证码（二）--- 利用CNN模型去识别开源系统验证码](https://xianzhi.aliyun.com/forum/topic/1552/)
## 0x001 文章结构
  * CNN的基础
  * Tensorflow的CNN代码理解
  * 调参和优化的方法介绍
本文不会对数学理论做过多的探讨，也不会深入研究原理，只对CNN基础知识和Tensorflow实现过程做一下简单的梳理。
以及常见的优化流程 毕竟是个人阅读心得，难免会有纰漏，如有错误，请及时指出。
## 0x002 CNN的基础知识
### CNN简介
cnn 全称是 Convolutional Neural Network ,中文叫
卷积神经网络。理解这个词语需要简单来梳理几个名词：人工智能，机器学习，深度学习。
简单的来说，人工智能的实现方式包括了机器学习，而机器学习实现的方式可以通过深度学习来实现。
而CNN，简单的可以理解为是深度学习的一种实现方式（这里并不严谨！但是展开描述会非常困难,这里就不表述了。）
### CNN经典结构
简单了解CNN的概念以后，我们先来看一下 CNN的几种结构。
  * Lenet，1986年
  * Alexnet，2012年
  * GoogleNet，2014年
  * VGG，2014年
  * Deep Residual Learning，2015年
几乎都是来自 Lennt的优化和改良。 Lenet的结构如图所示，
经典的Lennt是由
  * 输入 INPUT（图片转置矩阵）
  * 卷尺层 Convolution（对图片进行过滤器 输出特征图 Feature）
  * 池化层 Pooling（也叫子采样层 图中的 Subsampling ）
  * 全联接层 FullConnection （主要对卷尺池化后的结果进行分类的结果 OUTPUT）
五个基础部分组成
图中所示结果 则是  
**输入- >卷尺->池化->卷尺->池化->全联接->全联接->输出 **
这里简单说一下卷尺和池化，全联接简单的理解就是一个简单的分类函数即可。
### 卷尺 Convolution
#### 卷尺构成
输入 -> 过滤器 = 输出
假设 我们有一个3x3的图像，卷尺核（又叫过滤器）为3x3的矩阵得出的结果如图
卷尺要先把卷尺核调转180度后在去计算。左上 的 -13 的计算过程如下
一个完整的卷尺过程如下
#### 卷尺的计算类型
  * full 
  * same 
  * valid 
这里有三种 我们只需先了解same就行，和意思一样 卷尺后的大小 和 卷尺前一样。
  * 各种卷尺方式 
#### 卷尺作用
概念有点晕 下面举几个例子说明一下卷尺的作用
##### 例子 1
当卷尺如下所示，对一个图像做卷尺时
（1就相当于权重，新像素点包含对应像素点与其周边像素点的综合信息，等于求平均值  
得出来的图片效果 就是 模糊效果 ）
##### 例子 2
当卷尺如下所示，对一个图像做卷尺时
如果像素点周围颜色和该像素点差不多，那么得出来的值接近0 也就是黑色
如果像素点和周围的颜色差别巨大 那么就会得到一个比较大的非0值
这个矩阵的作用是检测物体的边缘值，卷尺后的效果
简单的理解 **卷尺对原图完成了特征抽取的工作**
### 池化 pooling
池化的结果是使得特征减少，参数减少。
#### 池化的类型
常见的两种池化的类型
  * mean-pooling 求邻近平均
  * max-pooling 取邻近最大
例子 ：4*4 矩阵 的通过2x2的 max ooling后 如下
**简单的理解** 池化的作用就是保持一定特征的情况下缩减图片面积
至此 我们就差不多掌握了CNN的所有的基础的概念 。那么接下来就是回顾我们上上篇文章的模型。
### Tensorflow CNN的代码理解
打开 **captcha_model.py** 文件
看 first layer
    #first layer
            w_conv1 = self.weight_variable([5, 5, 1, 32])
            b_conv1 = self.bias_variable([32])
            h_conv1 = tf.nn.relu(tf.nn.bias_add(self.conv2d(x_images, w_conv1), b_conv1))
            h_pool1 = self.max_pool_2x2(h_conv1)
            h_dropout1 = tf.nn.dropout(h_pool1,keep_prob)
            conv_width = math.ceil(self.width/2)
            conv_height = math.ceil(self.height/2)
  * w_conv1 就是 我们所说的过滤器 ，[5, 5, 1, 32] 表示为一个5x5，通道为1（黑白图片 所以通道为1） 深度为32 的过滤器 。
  * b_conv1 一般和过滤器的深度一致
  * 步长为1的卷尺的过程 tf.nn.relu(tf.nn.bias_add(self.conv2d(x_images, w_conv1), b_conv1)) 得出的卷尺结果是 h_conv1 
  * 池化是采用2x2 的max-pooling 方式 结果为 h_pool1 
  * h_dropout1 用tf.nn.dropout 的方式输出了下一层的结果 
  * 此时 因为池化是2x2 所以 长和宽都缩减为原来的1/2 所以要除2 （这也是为什么验证码的长宽均为2的倍数的时候比较好 因为缩减无损不需要额外的开销）
  * max_pool_2x2，conv2d这些自定义函数里面包含了 步长 padding的方式等等
那么 layer(例如 first layer，second layer) 包含了卷尺层和池化层
fully layer 则是 全连接层 ，全连接层没什么特别的地方 主要用于归类和输出结果。
那么我们编写的模型就是  
**输入- >卷尺->池化->卷尺->池化->卷尺->池化->全联接->全联接->输出 **
我们对模型的原理和结构了解了以后 我们可以开始尝试优化了。
## 0x003调参和优化的方法介绍
我们编写的模型  
**输入- >卷尺->池化->卷尺->池化->卷尺->池化->全联接->全联接->输出 **
对比 Lenet的模型  
**输入- >卷尺->池化->卷尺->池化->全联接->全联接->输出 **
可以看到仅仅是比 Lenet的模型 多了一个 卷尺->池化 的过程，
实际上 关于图片分类的CNN结构 我们都可以用一个正则表达式表示：
**输入 - > ( 卷尺+ -> 池化? )+ -> 全联接+ -> 输出 **
![注：池化层可以去掉的原因是因为有论文表明 池化的过程可以通过调整卷尺过滤器的步长来完成]
所以 根据我们所掌握的原理 有以下几种方式去优化我们的模型，大部分是修改过滤器的参数
  * padding 图像大小 使其接近2的倍数 
  * 修改过滤器的大小。我们这里的过滤器是5*5 一般来说就是用 7x7,5x5,3x3等等去试 。过滤器的大小影响特征是否更完整。 
  * 修改过滤器的步长。假设图片中有大片色块相同的区域，可以尝试把步长跳大，更快的提取特征。
  * 修改过滤器的padding方式 。(参考上文的图)
  * 增加或者减少( 卷尺+ -> 池化? )+ 
  * 选择更加优秀的算法 FNN,Attention,迁移算法等
**总的来说，就是多试，多修改模型以便于更好的提升识别率。**
## 0x004 总结
使用tensorflow自动识别验证码 系列的基本写完了。原本还有
  * 使用tensorflow自动识别验证码（四） 自动化批量识别验证码
但是已经和tensorflow 关系不大。无非就是通过队列和web控制台去调用这篇文章的模型去获取API去学习而已。所以暂且告一段落。
今后的重心把对图片识别转移到日志分析和威胁情报类，结合兜哥的书籍对常见的一些日志系统例ELK等等编写分析模型对tensorflow进行更深入的学习。
## 0x005 参考资料
  * 
  * 
  * 
  * 
  * 