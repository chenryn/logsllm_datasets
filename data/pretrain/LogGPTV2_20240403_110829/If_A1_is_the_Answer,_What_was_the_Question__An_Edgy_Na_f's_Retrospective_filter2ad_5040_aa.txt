title:If A1 is the Answer, What was the Question? An Edgy Na?f's Retrospective
on Promulgating the Trusted Computer Systems Evaluation Criteria
author:Marvin Schaefer
If A1 is the Answer, What was the Question? 
An Edgy Naïf’s Retrospective on Promulgating  
Trusted Computer Systems Evaluation Criteria
the
Marvin Schaefer 
Books With a Past, LLC
PI:EMAIL
Abstract 
This  paper  provides  an  introspective  retrospective 
on  the  history  and  development  of  the  United  States 
Department  of  Defense  Trusted  Computer  System 
Evaluation  Criteria  (TCSEC).  Known  to  many  as  the 
Orange  Book,  the  TCSEC  contained  a  distillation  of 
what  many  researchers  considered  to  be  the  soundest 
proven  principles  and  practices  for  achieving  graded 
degrees  of  sensitive 
information  protection  on 
multiuser  computing  systems.  While  its  seven  stated 
evaluation  classes  were  explicitly  directed 
to 
standalone  computer  systems,  many  of  its  authors 
contended  that  its  principles  would  stand  as  adequate 
guidance  for  the  design,  implementation,  assurance, 
evaluation  and  certification  of  other  classes  of 
computing 
database 
management  systems  and  networks.  The  account  is  a 
personal  reminiscence  of  the  author,  and  concludes 
with a subjective assessment of the TCSEC’s validity in 
the face of its successor evaluation criteria. 
applications 
including 
1. Introductory: From the primordial ooze 
In  the  beginning,  there  was  no  computer  security 
problem.1  There  was  no  external  threat.  There  was  no 
intrusion problem.  
You could ask almost anyone who used or operated 
computers in those days of yesteryear. Computers were 
expensive, so they were kept and operated in physically 
protected  rooms.  Only  authorized,  trained  personnel 
1  Earl  Boebert  would  dispute  this,  having  exploited  a  flaw  in 
the  early  1960s  at  Stanford  University  to  read  and  modify  memory 
[now called storage] to plant a Trojan horse. Boebert spoke of this as 
his locked room mystery.
to  mainframes  or 
were  allowed  physical  access 
peripherals.  Users  submitted  jobs  on  punched  card 
decks or on tape, jobs were run successively, and every 
job had a stated duration in which to run or be “kicked 
off” the machine. If one was lucky, an aborted or failed 
job  would 
being 
unceremoniously  dumped.  Common  belief  was  that 
physical  protection  and  personnel  background  checks 
were  adequate  to  protect  data  in  the  government,  at 
banks, and in industry. 
produce 
before 
a 
dump 
This paper is a personal account of my involvement 
in  the  events  leading to the development, writing, trial 
use,  promulgation,  official  use,  and  misuse  of  the 
United  States  Department  of  Defense  Trusted 
Computer  System  Evaluation  Criteria  (TCSEC).  Even 
after  it  became  a  Department  of  Defense  Standard, 
many came to know it by its paper cover as the Orange 
Book. Orange was the final color of an evolving series 
of published drafts that began on 24 May of 1982 with 
powder blue, and progressed through white and a sickly 
shade of olive green, until it reached its distinctive final 
draft shade of orange on 15 August 1983.
1.1. Early education in computer security 
I2  first  left  academia  in  1965  for  an  experimental 
summer  research  and  technology  training  program  in 
Santa Monica at the System Development Corporation 
(SDC), a non-profit spin-off of the RAND Corporation. 
The  atmosphere  provided  to  our  group  of  “special 
trainees”  at  SDC  was  a  radical  departure  from  that  of 
2 Because this is a personal account, I use both the first person 
singular  and  plural  pronouns.  The  latter  are used for most contexts, 
as  important  results  often  came  not  from individuals but as a result 
of  close  collaboration  with  many  colleagues in several research and 
development institutions in academia, industry and government. 
Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC’04) 
1063-9527/04 $ 20.00 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 11:37:23 UTC from IEEE Xplore.  Restrictions apply. 
the UCLA mathematics department. SDC had a staff of 
academic  mathematicians  and  researchers  from  the 
social  and  hard  sciences  in  addition  to  its  computing 
staff. SDC received the majority of its funding from the 
Department of Defense and other government agencies. 
The  company  teemed  with  modern  vacuum  tube  and 
semitransistorized  computers,  consuming  fully  half  of 
the  electric  power  generated  for  the  city  of  Santa 
Monica.  Our 
the 
opportunities  to  which  we  were  exposed  were  so 
exciting that most of us cancelled our future plans and 
stayed  on  afterward  in  the  Research  and  Technology 
Directorate.
training  class  and 
three-month 
The young people in our training class held freshly-
minted  degrees 
in  mathematics,  physics,  music, 
literature, and philosophy. We were assigned to use the 
new  experimental  IBM  A/N-FSQ-32(V)  Time  Sharing 
System3.  In  our  three  months  of  training,  we  received 
lectures  from  pioneering  researchers  in  hardware  and 
operating  system  design,  assemblers,  programming 
language 
interpreters, 
metacompilers,  natural  language  processing,  database 
management,  list  processing  (LISP  1.5),  and  time 
sharing  system  design.  But  the  most  exciting  was  our 
chance  to  use  the  Q-32  for  our  classwork.  The  Q-32 
would support up to 24 interactive users at a time. Our 
class  got 
this  computer  with  SDC’s 
researchers, and we were given individual login IDs so 
that  our  projects  could  be  billed  for  the  time we used. 
These  IDs  were  not  used  for 
identification  or 
authorization.  
compilers, 
design, 
to  share 
Occasionally  we  were  asked  to  get  off  the  machine 
to  allow  a  remote  demonstration  of  the  system  to  run 
smoothly  and  rapidly.  Many  of  these  demonstrations 
were  scheduled  and  conducted  from  overseas  by 
telephone dataphone and teletypewriter. Other than for 
these demonstrations, there were no public or employee 
dialup services on the Q-32. 
There  were  no  access  controls  on  data,  and  files 
were  generally  meant  to  be  shared  with  colleagues. 
Indeed, the concept of protection was soon revealed to 
be  nonexistent  as  a few of us inadvertently discovered 
how  to  subvert  careful  operating  system  policies  and 
mechanisms  on 
the  single  protection  state  Q-32 
architecture. 
1.1.1.  Modifying  an  operating  system.  It  was  here  that 
my  first  experiences  penetrating  computer  system  took 
3 Developed under contract to ARPA as one of two “competing” 
projects.  The  other  contemporaneous  time  sharing  system  was  the 
Compatible  Time  Sharing  System  (CTSS)  at    MIT’s  Project  MAC 
and Bell Labs designed in 1959 and operational from 1961-71. 
in 
the  full  systems 
place.  While  we  could  code 
programming  language  JOVIAL,  this  required  overnight 
batch-mode compilation before we could interact with our 
programs  under  time-sharing.  This  time  delay  could  be 
avoided  by  programming  in  the  fully-interactive  Time 
Shared  Interpreter  (TINT)  for  rapid  prototyping,  a  subset 
time-shared  compiler  JOVIAL  Time  Sharing  Subset  (JTS),
and LISP 1.5. However, Q-32 TSS required that adequate 
space  be  available  in  a  contiguous  block  on  one  of  the 
swap drums in order to load the entire compiler or LISP or
to  do  any  work  with  a  user  program.  This  was  because 
dynamic  paging  had  not  yet  been  invented.  So  I  and  a 
couple  of  colleagues  managed  to  write  a  very  small 
program (appropriately named  CANCER) that would usurp 
the  operating  system,  repack  the  drums  that  contained 
other  user  programs,  modify  the  internal  systems  tables, 
and make room for our own programs to load. All of this 
had  to  be  completed  inside  of  a  single  quantum. 
Sometimes it didn’t. The resulting system crash got other 
users angry. It was also less than amusing to the operating 
systems  staff.  Our  actions  were  dismissed  as  those  of 
college kids having fun, and not those of malicious users. 
Besides,  until  our  program  (CANCER)  was  developed  and 
fully  debugged,  everyone  had  to  waste  time  waiting  for 
adequate space to become available. 
1.1.2.  Cat  and  MOUSE.  Q-32  TSS  scheduling  was 
initially  a  “democratic”  system.  Every  program4  was 
given  a  300  ms  quantum  in  a  strictly  round  robin 
scheme. This proved to interfere with the performance 
of  highly  interactive  programs,  and  it  resulted  in  very 
long  compilation  time.  So  Clark  Weissman  decided  to 
implement  queues  for  different  kinds  of  jobs: initially, 
there  were  two  queues  an  “interactive”  queue  and  a 
“production”  queue.  Membership  in  the  interactive 
queue depended on the program performing an input or 
output  during  every  few  quanta,  and  a  program  that 
failed to do this was moved into the production queue. 
Here,  a  program  would  execute  less  frequently,  but 
once it reached the head of the queue it would alternate 
through  ten  quanta  interleaved  with  members  of  the 
interactive queue prior to being sent to the back of the 
queue. In practice, users needed to get their work done, 
and  they  found  ways  to  avoid  being  placed  in  the 
production  queue.  Soon  most  user-written  programs 
were  soon  laced  with code that would perform useless 
single-character  output  operations  to  the  terminal  to 
avoid  being  moved  out  of  the  interactive  queue.  This 
did  nothing  to  shorten  compilation  time  for  people 
4  Process  was  not  yet  a  developed concept and ‘program’ was 
synonymous  with  the  executing  context  as  well  as  with  the  code 
image. Privilege state was not yet a well-recognized concept either. 
Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC’04) 
1063-9527/04 $ 20.00 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 11:37:23 UTC from IEEE Xplore.  Restrictions apply. 
using  compilers  or  LISP,  so  additional  dodges  were 
found to avoid the production queue.  
techniques.  Ultimately,  a 
On learning of these, Weissman and his staff added 
intermediate  queues  and  introduced  foils  to  the  user’s 
avoidance 
few  users 
collaborated on a set of means to modify the operating 
system’s  scheduling  algorithms,  during  execution  of 
course,  in  their  favor.  As  there  was  no  protected 
memory,  and  there  were  no  privileged  instructions, 
there  was  little  other  than  procedural  controls  that 
could  be  applied  by  the  operating  system  staff  to 
control  usage.  Soon,  passwords  were  associated  with 
user  IDs,  and  audit  logs  were  generated  out  to  tape 
along with the billing information. But, since there was 
no  protection  on  the  machine,  these  proved  to  be 
illusory at best—nothing in the hardware could prevent 
any  program  from  accessing  system  audit  files.  The 
systems  programming  staff 
introduced  monitoring 
programs that would check on the behavior of specific 
users  and  programs,  and  we  found  means  to  use 
programs to abort or replace the monitoring programs. 
And  so,  for  each  protective  or  regulatory  move  made 
by 
found 
themselves forced to launch offensive countermoves in 
order to feel that they could get their work done on the 
system. 
researchers  soon 
the  defenders, 
the 
In  effect,  the  system’s  design  was  still  a  prototype, 
and if future system versions were to evolve, test users 
were needed to provide useful data and feedback. Q-32 
TSS  was  not  designed  with  security  or  protection  in 
mind,  and  because  of  hardware  inadequacies,  no  form 
of  strong  security  could  have  been  provided  in  any 
case.  To 
the  only 
penetrations  or  subversions  of 
the  system  were 
performed in order to get work done more rapidly, and 
no  user  data  was  maliciously  corrupted  or  spied-upon. 
But  such  acts  of  user  anarchy 
in  a 
semideclared  “state  of  war”  between  users  and  the 
operating system staff. 
the  best  of  my  knowledge, 
resulted 
1.1.3.  Concepts  in  absentia  but  not  forgotten.  The 
primitive  understandings  of  protection  mechanisms 
made  early  time  sharing  systems  look  like  the  Wide 
Open  Old  West.  The  following  important  concepts 
were  soon  learnt  to  be  absent  in  contemporaneous 
computers and systems: 
•  Protection policy 
•  Multiple privilege states 
•  Segmented memory 
•  Privileged instructions 
•  The process as subject concept 
•  Access controls on objects 
•  Individual accountability 
•  Protected audit trails 
It  soon  became  obvious  that  if  systems  were  to 
control  users,  such  concepts  would  need 
to  be 
implemented.  But,  of  course,  we  didn’t  know  that 
then….  Many  of  these  lacking  controls  remained 
AWOL  through  the  1970s  and  1980s  on  a majority of 
ARPANet sites, and thence well into the 1990s and early 
21st  century  on  the  Internet.  But,  it must be observed, 
there  was  “no  known  security  problem  that  wasn’t 
caused  by  improper  management  and  that  couldn’t  be 
corrected by proper procedural controls.” 
1.2. The Ware Report 
In  our  research  lab,  as  elsewhere,  there  was  no 
perceived  computer  security  problem.  All  SDC 
employees  had  a  Defense  Department  clearance 
because  there  were  some  classified  projects  in  SDC’s 
buildings. Guests had to sign in with a guard and wear 
a visitor badge while being escorted.  
However,  a  series  of  events  in  the  spring  and 
summer  of  1967  focused  the  Department  of  Defense’s 
attention to the question of security control in resource-
sharing  systems.  In  June  of  that  year,  Bob  Taylor, 
director  of  the  Office  of  Information  Processing 
Techniques at  ARPA was tasked to “form a Task Force 