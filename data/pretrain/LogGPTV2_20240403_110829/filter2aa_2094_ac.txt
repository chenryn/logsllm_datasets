### 文件列表与PDF生成结果分析

#### 文件列表
以下是相关文件的详细信息：
- `2BLSTM_epoch20.h5_diversity1.5.txt` (1802129 bytes, 8月 15 06:04)
- `2BLSTM_epoch20.h5_diversity1.8.txt` (2138562 bytes, 8月 17 04:30)
- `2BLSTM_epoch30.h5_diversity0.2.txt` (693064 bytes, 8月 15 23:23)
- `2BLSTM_epoch30.h5_diversity0.5.txt` (1109692 bytes, 8月 14 16:43)
- `2BLSTM_epoch30.h5_diversity0.8.txt` (1441973 bytes, 8月 16 08:38)
- `2BLSTM_epoch30.h5_diversity1.0.txt` (1484294 bytes, 8月 15 02:13)
- `2BLSTM_epoch30.h5_diversity1.2.txt` (1477235 bytes, 8月 16 16:46)
- `2BLSTM_epoch30.h5_diversity1.5.txt` (1551167 bytes, 8月 15 08:48)

#### PDF生成结果
- **单进程生成**: 10,000个PDF
- **时长**: 约10分钟
- **单个文件大小**: 约380KB
- **总文件大小**: 约3.7GB
- **21个模型，共计210,000个样本**: 总计约77.7GB

#### 示例PDF文件
以下是部分生成的PDF文件及其大小：
- `9476.pdf` (339179 bytes, 8月 13 09:43)
- `9477.pdf` (338730 bytes, 8月 13 09:43)
- `9478.pdf` (338794 bytes, 8月 13 09:43)
- `9479.pdf` (335113 bytes, 8月 13 09:43)
- `9480.pdf` (339384 bytes, 8月 13 09:43)
- ...
- `9501.pdf` (345394 bytes, 8月 13 09:43)

### PDF生成样本示例
- **主机**: 
  - 生成样本1
  - 生成样本2
  - 生成样本3
  - 生成样本4

### 测试
#### 代码覆盖率测试
- **代码覆盖率**是评估样本质量的重要量化指标。
- **计算公式**: 代码覆盖率 = 执行代码量 / 总代码量
- **通过率**仅能反映生成样本是否符合格式规约，而代码覆盖率则直接反映样本是否能探索更多路径或代码，对漏洞挖掘具有指示作用。

#### 漏洞挖掘测试
- **目标软件**: Foxit Reader, Adobe Reader, Mupdf, Chrome, Edge等
- **测试平台**: 集群漏洞分析系统
- **每款软件分配**: 20台虚拟机
- **测试时间**: 1天
- **测试样本数**: 210,000

### 结果分析
#### 代码覆盖率
- **数据集基础覆盖率**: 37.996%
- **PinAFL覆盖率**: 38.077%，提升0.081%
- **Learn&Fuzz覆盖率**: 38.113%，提升0.117%

#### 训练轮次对代码覆盖率的影响
- **模型**: 2BLSTM
- **采样值**: 0.5
- **测试时长**: 69.45小时
- **轮次与覆盖率**:
  - 10轮: 38.064%
  - 20轮: 38.108%
  - 30轮: 38.123%
  - 40轮: 38.130%
  - 50轮: 38.133%
  - 60轮: 38.02%

#### 漏洞挖掘测试
- **测试软件及结果**:
  - Power PDF: 4520个崩溃，去重后28个，涉及多种类型漏洞
  - Corel PDF: 23560个崩溃，去重后78个，涉及多种类型漏洞
  - Cool PDF: 468个崩溃，去重后8个，涉及多种类型漏洞
  - Nitro PDF Reader: 256个崩溃，去重后5个，涉及多种类型漏洞
  - Foxit 9.2: 10265个崩溃，去重后27个，涉及多种类型漏洞
  - Foxit 9.1: 2783个崩溃，去重后18个，涉及多种类型漏洞

### 结论与展望
#### 结论
1. 本方案实现了一种基于AI制导的PDF文件生成技术，支持字符级学习、LSTM、BLSTM、Attention机制网络模型。
2. 经过严格测试，高训练轮次、低采样值生成的样本具有更高的代码覆盖率，其中2BLSTM模型60轮采样值0.2的表现最佳。
3. 该方案可作为新的样本变异策略，单独生成样本用于漏洞挖掘，也可作为AFL等工具的前端，但不能完全取代当前主流Fuzzer。

#### 展望
1. 支持更多结构化样本格式的学习和生成，如XML、XSL、JavaScript、HTML、AS等。
2. 训练二进制格式（PNG、MKV、ZIP等），看是否能生成通用模型。难点在于校验和和二进制规律性不强。
3. 将生成的样本交给AFL进行Fuzzing，看能否增强AFL性能。
4. 单一模型与多模型组合比对。
5. 交互方式训练模型：GAN

### 参考资源
- Adobe Systems Incorporated. PDF Reference, 6th edition, Nov.2006.
- Wang J, Chen B, Wei L, et al. Skyfire: Data-driven seed generation for fuzzing. Security and Privacy (SP), 2017 IEEE Symposium on. IEEE, 2017: 579-594.
- Patrice Godefroid's GitHub: https://patricegodefroid.github.io/
- Godefroid P, Peleg H, Singh R. Learn&fuzz: Machine learning for input fuzzing. Proceedings of the 32nd IEEE/ACM International Conference on Automated Software Engineering. IEEE Press, 2017: 50-59.
- Keras LSTM Text Generation Example: https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py
- Keras Attention Mechanism: https://github.com/philipperemy/keras-attention-mechanism

谢谢！