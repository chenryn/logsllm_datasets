title:Hide &amp; Share: Landmark-Based Similarity for Private KNN Computation
author:Davide Frey and
Rachid Guerraoui and
Anne-Marie Kermarrec and
Antoine Rault and
François Ta&quot;ıani and
Jingjing Wang
2015 45th Annual IEEE/IFIP International Conference on Dependable Systems and Networks
2015 45th Annual IEEE/IFIP International Conference on Dependable Systems and Networks
Hide & Share: Landmark-based Similarity for
Private KNN Computation
§ Davide Frey∗, Rachid Guerraoui†, Anne-Marie Kermarrec∗, Antoine Rault∗, Franc¸ois Ta¨ıani‡ and Jingjing Wang†
∗INRIA Rennes, France
†EPFL, Switzerland
Email: ﬁPI:EMAIL
Email: ﬁrstname.lastname@epﬂ.ch
‡University of Rennes 1, France
Email: PI:EMAIL
Abstract—Computing k-nearest-neighbor graphs constitutes a
fundamental operation in a variety of data-mining applications.
As a prominent example, user-based collaborative-ﬁltering pro-
vides recommendations by identifying the items appreciated by
the closest neighbors of a target user. As this kind of applications
evolve, they will require KNN algorithms to operate on more and
more sensitive data. This has prompted researchers to propose
decentralized peer-to-peer KNN solutions that avoid concentrating
all information in the hands of one central organization. Un-
fortunately, such decentralized solutions remain vulnerable to
malicious peers that attempt to collect and exploit information
on participating users.
In this paper, we seek to overcome this limitation by proposing
H&S (Hide & Share), a novel landmark-based similarity mecha-
nism for decentralized KNN computation. Landmarks allow users
(and the associated peers) to estimate how close they lay to one
another without disclosing their individual proﬁles.
We evaluate H&S in the context of a user-based collaborative-
ﬁltering recommender with publicly available traces from existing
recommendation systems. We show that although landmark-
based similarity does disturb similarity values (to ensure privacy),
the quality of the recommendations is not as signiﬁcantly ham-
pered. We also show that the mere fact of disturbing similarity
values turns out to be an asset because it prevents a malicious
user from performing a proﬁle reconstruction attack against other
users, thus reinforcing users’ privacy. Finally, we provide a formal
privacy guarantee by computing an upper bound on the amount
of information revealed by H&S about a user’s proﬁle.
Keywords—Data privacy, Nearest neighbor searches, Peer-to-
peer computing, Recommender systems
I.
INTRODUCTION
K-Nearest-Neighbor (KNN) algorithms provide a funda-
mental tool to mine and explore large amounts of data. In
particular, they lie at the core of memory-based collaborative
ﬁltering (CF), a common technique for providing recommen-
dation to users [1]. The use of KNN for memory-based CF has
been particularly fruitful and has led to the recent emergence
of peer-to-peer (P2P) recommenders based on highly decen-
tralized KNN algorithms [2], [3].
Peer-to-peer KNN recommenders are particularly scalable,
and have therefore been proposed as a way to address the
§ Antoine Boutet is an author of this paper. His name was mistakenly
forgotten at the time of registering the paper (the submission was double
blinded). At the time of publication, we were prevented from correcting our
mistake.
978-1-4799-8629-3/15 $31.00 © 2015 IEEE
978-1-4799-8629-3/15 $31.00 © 2015 IEEE
DOI 10.1109/DSN.2015.60
DOI 10.1109/DSN.2015.60
263
263
 0.8
 0.6
 0.4
 0.2
l
l
a
c
e
R
noRandomize
randomize10
randomize25
randomize75
fullRandom
 0
 0.8  0.82  0.84  0.86  0.88  0.9  0.92  0.94
Precision
Fig. 1. Recommendation quality with different levels of randomization of user
proﬁles. This quality is not signiﬁcantly hampered by levels of randomization
of up to 75%.
scalability issues that characterize centralized recommenders.
Distributing KNN computation across peers makes it possible
to compute recommendation without requiring huge servers or
data centers.
Peer-to-peer KNN recommenders also avoid the danger of
prominent players acting as “Big Brothers”. Deconcentrating
data across peers makes it more difﬁcult for content providers
to access and possibly reuse the personal data for purposes
other than recommendation. Yet, the peer-to-peer model in-
troduces new privacy threats that do not come from a Big
Brother but from the peers themselves. The decentralized KNN
algorithms at the basis of most peer-to-peer recommenders [2],
[3] require peers to exchange their interest proﬁles with other
peers in order to compute similarity values. In doing so,
they do not simply risk to share sensitive information; they
systematically require users to share personal data with random
other users. This makes it very easy for an attacker to learn
about the interests of a large number of victims.
To address this challenge, we propose Hide & Share
(H&S), a novel similarity mechanism for P2P KNN compu-
tation. H&S makes it possible to compute the KNN graph
without requiring users to share their proﬁle information with
anyone else. H&S relies on a simple observation: user-centric
KNN applications such as recommendations do not require
perfect knowledge. To illustrate this fact, Figure 1 depicts
recommendation quality (quality increases towards the top and
the right) with varying level of randomness injected into user
proﬁles. The plot shows that randomness levels of up to 75%
do not signiﬁcantly hamper recommendation quality.
Based on this observation H&S trades-off precision in
the computation of similarity for privacy. This allows it to
gain signiﬁcant protection in terms of privacy with a minimal
impact on applications like recommendation. This makes H&S
a perfect ﬁt for decentralized CF systems.
H&S’s key contribution lies in a novel landmark-based ap-
proximation technique as well as in a fair landmark-generation
protocol. The landmarks of our solution allow two users to
indirectly measure their similarity by comparing their own pro-
ﬁles with a set of randomly generated proﬁles (the landmarks).
The similarity between a user’s proﬁle and a landmark acts
as a coordinate in a coordinate system. Users then exchange
vectors of coordinates and compute an approximation of their
actual similarity. This preserves user privacy as users do not
exchange their full proﬁles and landmark coordinates only
reveal a limited amount of information about a user.
We present and evaluate H&S using real data traces. We
also demonstrate formally its privacy guarantees by computing
an upper bound on the amount of information leaked by H&S’s
similarity approximation. Our results show that H&S’s KNN
provides a reasonable trade-off between privacy and utility.
H&S disturbs similarity values but it does not signiﬁcantly
hamper the quality of the resulting recommendations. Ap-
proximate similarity values constitute instead an asset towards
privacy preservation as they effectively prevent adversaries
from performing proﬁle reconstruction attacks as we show in
Section IV.
In the remainder of this paper, we ﬁrst describe our
system model in Section II before detailing our contribution in
Section III. Then we evaluate H&S experimentally in terms of
recommendation quality, privacy protection, and overhead in
Section IV, and analyze its privacy guarantees in Section V.
Finally, we discuss related work in Section VI and present our
conclusions in Section VII.
II. SYSTEM MODEL
We present H&S in the context of a user-based peer-to-peer
recommender. To this end, we start by describing the operation
of such a system, and highlighting the corresponding privacy
risks. We then present our adversary model in Section II-C.
A. Decentralized User-based Collaborative-Filtering System
We consider a decentralized collaborative-ﬁltering (CF)
system similar to that of [3]. Each user controls a single peer
which stores her full proﬁle as a list of ratings for the items
she has rated. Ratings may consist either of binary values or of
discrete values within a range (e.g. 1 to 5). In the following,
we consider binary ratings as in most existing decentralized
solutions [3], [4], [5], [6], [7], [2], [8].
The system uses asynchronous rounds that are executed
periodically by each peer. In each round, each peer attempts
to select a better set of similar other nodes (its neighbors)
according to some similarity metric:
for example cosine
similarity [9]. Cosine similarity considers proﬁles as high-
dimensional vectors in which each unique item is a dimension
and values for each dimension correspond to ratings. It then
evaluates the similarity of two proﬁles as the cosine of the
angle between the two corresponding vectors.
Ellie 
E
Carl 
Dave 
Dave 
Ellie 
Bob 
Alice 
Bob 
Alice 
clustering layer 
gossip-based 
similarity clustering 
Carl 
RPS layer providing 
random sampling 
random link 
similarity link 
node 
Fig. 2. Gossip-based distributed clustering
cos(u1, u2) =
u1 · u2
(cid:2)u1(cid:2)(cid:2)u2(cid:2)
(1)
In what follows, we ﬁrst describe how the neighbors of
a peer are identiﬁed in this model (Neighbor identiﬁcation),
before moving on to the actual mechanism used for to recom-
mend new items to users (Recommendation).
1) Neighbor identiﬁcation: Peers use two gossip protocols
to identify their KNN: a random-peer sampling (RPS) and
a clustering protocol. The former maintains a continuously
changing topology, while the latter converges to the KNN
graph, as illustrated in Figure 2. Both protocols follow the
same high-level behavior. In each protocol, each peer maintains
a data structure, called view, consisting of a list of references to
other peers: the peer’s current neighbors in the corresponding
protocol. Periodically, a peer p contacts another peer q from
this list and sends it a subset of its own view—half of its
view in the RPS protocol, and its entire view in the clustering
protocol. Upon receiving such a subset, q merges the received
subset with its own view. In the case of RPS, it keeps e random
entries from the union of the two views. In the case of the
clustering protocol, it keeps the e entries whose proﬁles are
most similar to its own after combining its own clustering view,
its own RPS view and the received clustering view. Then q
replies by sending to p a subset of its view before the update,
and p updates its view analogously. The clustering protocol
provides each peer with a view that converges to its KNN. The
RPS provides resilience to churn and partitions and ensure that
the process cannot get stuck into a local minimum.
Figure 3 exempliﬁes the operation of the clustering proto-
col. Alice and Bob are interested in hearts, though Bob prefers
diamonds. After exchanging their respective list of neighbors,
they keep the users which are closest to their interests. In this
Frank 
Alice 
Ellie 
Carl 
Bob 
Dave 
1 
exchange of 
neighbors lists 
2 
neighborhood 
optimization 
Fig. 3. Clustering mechanism for convergence to an optimal neighborhood.
In this example, after exchanging their proﬁles, Alice and Bob modify their
neighbors in order to be connected with the users who share the most their
interests.
264264
example, Alice replaces Ellie with Carl who likes hearts, and
Bob replaces Alice with Ellie who likes diamonds. After a few
cycles of this protocol, each peer’s neighborhood view contains
the corresponding KNN.
2) Recommendation: Peers use the KNN identiﬁed with the
above protocol to recommend items to their users. In typical
systems, each peer identiﬁes the items that were found most
interesting by its KNN and to which the peer has not yet been
exposed. In the case of binary rating, these consist of the items
that were liked by the largest number of KNN and to which
the peer has not been exposed.
B. Privacy Risks
As suggested, the above protocols requires peers to share
their proﬁles with each other in order to identify their KNN.
This constitutes a major privacy risk: before convergence,
both the RPS and the clustering protocol require peers to
communicate with a large number of other peers, even with
non similar ones. This means that a malicious non-similar
peer can easily copy the proﬁle of a target peer in order to
forcibly enter its clustering view. In the rest of this paper,
we remove this privacy threat by introducing H&S, a novel
similarity mechanism that does not require peers to exchange
their proﬁle information.
Thanks to H&S, peers can identify their KNN without
having to disclose any personal details to other peers. Once
they identiﬁed their KNN, they do share their proﬁle infor-
mation with neighbors that are sufﬁciently stable to compute
recommendations as described in Section II-A2. However, this
does not constitute a signiﬁcant privacy risk because peers
identiﬁed as KNN already know that they have similar proﬁles.
Learning the details of each other’s proﬁles therefore does not
add much to this knowledge. Conversely, a malicious peer that
wanted to become a neighbor of a target node would not be
able to clone the corresponding proﬁle without being already
similar to the target peer.
C. Adversary Model
In the rest of this paper, we consider a curious adversary
model. Our adversary can only take a limited set of active
actions to reach her goal, and can otherwise passively gather
information. The goal of the adversary is to discover the proﬁle
of a chosen user (target) by a proﬁle reconstruction attack,
using information obtained during similarity computation. The
adversary only controls one peer, i.e we assume there is no
collusion between adversaries, and our adversary cannot forge
peer identities (no sybil capacity). She also has no a priori
knowledge regarding her target’s interests. The active actions
the adversary can take are: tap unencrypted communications;
attempt to bias multi-party computations; compute her simi-
larity with her target as many times as she want.
III. THE HIDE & SHARE LANDMARK-BASED SIMILARITY
We address the privacy issues in decentralized KNN compu-
tation by introducing H&S (Hide & Share), a novel mechanism
for similarity computation. H&S relies on a simple observation:
good recommendations do not require perfect neighborhoods.
H&S therefore relaxes the precision of similarity computation,
Alice 
2 
0.5 
4 
0.2 
5 
0.6 
0.5 
0.2 
1 
Bob 
0.6 
3 
0.7 
0.2 
0.4 
0.7 
0.2 
0.4 
6 
cosim 
0.896  
Fig. 4. Overview of the H&S similarity computation mechanism
by exploiting randomly selected intermediate proﬁles (land-
marks) with respect to which each peer positions itself. This
allows peers to compute similarity scores they can exploit
without exchanging clear-text proﬁles.
H&S landmarks take inspiration from reference points in
geo-localization systems. For instance, two-dimensional geo-
graphic locations usually refer to the Equator and the Green-
wich meridian: two landmarks that deﬁne their latitude and