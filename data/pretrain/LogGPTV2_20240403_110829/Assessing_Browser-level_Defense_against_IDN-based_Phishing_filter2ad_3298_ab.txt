ICANN continues to release new TLDs, this approach be-
comes burdensome because Firefox has to constantly update
2Chrome has a hard-coded list of top domain names. According to the
source code of Chromium, there are 5001 top domain names on the list.
the list. After 2012, Firefox added the mixing script rules.
The idea is similar to that of Chrome, but the rules deﬁne dif-
ferent allowed/disallowed script combinations. For example,
Firefox allows “Latin + Han + Hiragana,” “Latin + Han +
Bopomofo,” “Latin + Han + Hangul,” and “Latin + any single
other Recommended/Aspirational scripts except Cyrillic or
Greek.”
Safari.
Based on a security update in 2016 [5], Safari main-
tains a list of allowed scripts. Any IDNs containing scripts
that are not on the allowed will be displayed in Punycode.
This is an aggressive policy since it excludes the entire Uni-
code blocks such as Cherokee, Cyrillic, and Greek that might
contain Latin look-alike characters. The goal is to prevent
homograph IDNs such as “apple.com” (where Cyrillic “a”
(U+0430) is used).
Internet Explorer (IE).
IE only allows ASCII characters
to be mixed with a predeﬁned set of scripts that are unlikely
to have confusable characters [41].
Microsoft Edge.
Edge has two generations. For the legacy
Edge (based on EdgeHTML), we cannot ﬁnd any public doc-
umentations on their IDN policies. The new generation of
Edge is based on Chromium. We assume Edge Chromium
has the same policy as Chrome (as marked in Table 2) and
will run experiments in Section 5 to validate this assumption.
User Conﬁgurations.
Certain browsers allow user conﬁg-
urations. For example, Firefox allows users to disable IDN
altogether and always display Punycode [17]. For IE, user-
conﬁgured “accept language” can affect the IDN display. For
example, if an IDN contains characters that are not part of the
“accept language,” IE will display the Punycode [41].
4.2 Building Testing Cases
Next, we design testing cases to systematically evaluate
browsers’ IDN policies. We focus on two main aspects: 1)
we design cases to test the implementation correctness of
the rules in the claimed policies; 2) we design cases that are
likely to bypass known policies. We seek to test a number of
browsers (of different versions, across different platforms) to
understand how the policy implementations evolve over time.
As shown in Table 3, we develop 10 categories of testing
cases. For each category, we construct about 1,000 testing
IDNs3. After generating the IDNs, we then remove the live
domains to 1) avoid disruptions to these live domains; 2) to
improve the speed and stability of large-scale testing (i.e., live
domains take a much longer time to resolve and display). We
have veriﬁed that all browsers will execute the same policies
3When constructing IDNs for a given category, we try to identify all the
relevant Unicode blocks, and then randomly sample the same number of
characters from each block. Sometimes, we do not get exactly 1,000 IDNs
because 1,000 cannot be divided evenly by the number of related Unicode
blocks or there are not enough qualiﬁed characters.
Category Description
Test-1
Test-2
Test-3
Test-4
Test-5
Test-6
Test-7
Test-8
Test-9
Test-10
Total
Mixing Latin, Cyrillic and Greek characters
Mixing Latin any other Unicode blocks
Whole-script-confusables and TLD
“Dangerous” patterns and Unicode confusables
Skeleton rules (top-ranked domains)
ASCII look-alikes
Extended confusable characters
Skeleton rules (low-ranked domains)
Full-substitution of all characters in a domain name
Mixing extension blocks of Latin, Cyrillic and Greek
Policy
Example IDNs
# Testing IDNs
P1
P2
P5
P4
P3
P6
P4
P3
P1
P1
1,000
1,442
997
1,090
978
166
493
1,600
873
880
9,519
Table 3: Testing cases and their related browser policies (the list of browser policies is in Table 2).
regardless of whether the domain is live or not. We in total
obtain 9,519 IDNs as testing cases.
Testing the Claimed Policies Directly.
As shown in Ta-
ble 3, categories 1–6 are designed to directly test the claimed
policies to examine if they are implemented correctly. Each
testing category is mapped to a policy in Table 2. We do not
plan to test user conﬁgurations since they depend on user pref-
erence. These testing cases are focused on testing the claimed
rules instead of aiming for high-quality impersonations.
• Category 1. Most browsers do not allow the mixing be-
tween Latin, Cyrillic and Greek characters (P1). To test
this rule, we construct IDNs that consist of mixing char-
acters randomly sampled from Latin, Cyrillic, and Greek
Unicode blocks (17 blocks in total). We randomly sample 2
characters from each of the 17 Unicode blocks to generate
the 1,000 mixing-script IDNS (covering 4 types of combi-
nation: Latin + Cyrillic, Latin + Greek, Cyrillic + Greek,
Latin + Cyrillic + Greek).
• Category 2. Chrome and Firefox claim to allow Latin char-
acters to be mixed with Chinese, Japanese and Korean
(CJK) characters (P2). However, it is not clear if other com-
binations are allowed. We construct IDNs that mix Basic
Latin and 172 other non-CJK Unicode blocks. By randomly
sampling 3 characters per block, we mix them to generate
1,442 testing IDNs.
• Category 3. This category is designed for whole-script
confusable domain names, i.e., all the characters are from a
single look-alike script without any mixing (P5). To test this
rule, we construct 997 IDNs using whole-script confusables
from Cyrillic as domain names combined with non-Cyrillic
TLDs (3 ASCII TLDs .com, .net, .org and 2 IDN TLDs
.{fõ(é⌥, .5N ).
• Category 4. Chrome claims that if the IDN matches some
dangerous patterns, it will display Punycode. The danger-
ous patterns include certain Japanese characters that can
be mistaken as slashes, certain Katakana and Hiragana
characters that look like each other. It is also not allowed
to use U+0307 (dot above) after ‘i’, ‘j’, ‘l’ or dotless ‘i’
(U+0131). We construct 1,090 testing cases to cover all the
documented rules.
• Category 5. This category is used to test the skeleton rule
(P3). Chrome checks whether the domain name looks like
one of the top-ranked domains, after mapping each charac-
ter to its spooﬁng skeleton. Chrome uses Unicode ofﬁcial
confusable table [65] and 31 additional confusable pairs to
map a spooﬁng character to its ASCII skeleton. We use the
same confusable pairs to construct 978 homograph IDNs.
• Category 6. Safari claims to only allow scripts that do not
have ASCII look-alikes (P6). For this category, we ran-
domly pick characters from Cyrillic, Greek and Cherokee
Unicode blocks (without any mixing) to form 166 IDNs.
Testing to Bypass the Claimed Policies.
Next, we as-
sume all the claimed policies are correctly implemented. Un-
der this assumption, we construct IDNs that are likely to
bypass existing policies. For these testing cases, we explicitly
construct homograph IDNs that impersonate target domains.
• Category 7. Given the possibility that the Unicode con-
fusable table used by browsers is incomplete, we test to
use a more comprehensive confusable database provided
by researchers [61]. We generate 493 homograph IDNs to
impersonate 200 domains sampled from Alexa top 10K [1].
• Category 8. The skeleton rule is currently applied to 5K
popular domain names. However, many important web-
sites are not necessarily “popular” (e.g., based on trafﬁc
volume). For example, websites of governments, military
agencies, educational institutions, regional hospitals, and
other organizations may have a high phishing value but
are not necessarily ranked to the top. To explore this idea,
we construct homograph IDNs for .gov, .mil, .edu, .org
and .net target domain names4 that are not in the top 5K
domain list.
• Category 9. In this category, we test whole-script confus-
ables beyond Cyrillic. We use extended sets of confusable
4Registering .gov, .mil, and .edu domain names requires additional
veriﬁcation. However, anecdotal evidence shows such veriﬁcation can be
abused or bypassed by attackers to obtain these domain names [32]. Domain
names under .org and .net are open to the public for registrations.
scripts to construct homograph IDNs without mixing. We
randomly sample 200 target domains from Chrome’s top
domain list, and generate up to 5 all-substitution homo-
graph domains for each target domain. We also keep the
original TLDs unchanged.
• Category 10. Most browsers prohibit the mixing between
Latin, Cyrillic and Greek. However, each script has multi-
ple Unicode blocks, and it is not clear we can mix different
blocks under the same script. For example, Latin has at
least 9 blocks including Basic Latin, Latin Extended-A to
E (5 blocks), IPA Extensions, Latin Extended Additional,
and Latin-1 Supplement. We want to understand, for in-
stance, if Latin Extended-A and Latin Extended-B can be
mixed. We construct 880 IDNs using characters within
Latin look-alike Unicode blocks. All the IDNS are homo-
graph domains impersonating 200 domain names randomly
sampled from Alexa top 1 million list [1].
Biases and Limitations.
Our testing cases are designed
to identify the problems with existing IDN policies. Certain
policies are designed at the Unicode block level (P1, P2, P6).
From each related block, we randomly select a few characters
and exhaustively test their combinations. As such, the testing
result is representative because these policies make decisions
at the block level. For policies that are concerning the charac-
ter level (e.g., P3, skeleton rule), we randomly sample popular
target domains and search for confusable characters. This
does not guarantee completeness (we do not cover all target
domain names). Exhaustive testing at the character level is
difﬁcult to ﬁnish within a reasonable amount of time.
Note that for test categories 1–4, and 6, the character re-
placement does not attempt to use look-alike characters since
the policies are about allowable Unicode blocks. Categories
5 and 7–10 use look-alike characters. Due to the space limit,
we make the list of testing IDNs available under this link5.
5 Measurement Methods and Results
With the testing cases, we present our empirical experiments
on major browsers and their historical versions to understand
the effectiveness of IDN policies. We test historical versions
for two reasons. First, it helps us to understand how different
policies and their implementations evolve over time. Sec-
ond, many users and organizations are still using outdated
browsers [6] – their IDN policies are worth investigating.
We design experiments to answer four key questions. First,
how well do browsers enforce known IDN policies? Sec-
ond, how effective are existing policies in detecting homo-
graph IDNs that impersonate target domains? Third, how are
browser defenses changing over time?
5https://github.com/stevetkjan/IDN_Testing/blob/master/
testcases.xlsx
Desktop (Total # of Versions) Version Range
Chrome (21)
Firefox (15)
Safari (4)
Edge Legacy (4)
Edge Chromium (2)
IE (4)
Mobile (Total # of Versions)
Android Chrome (7)
iOS Safari (13)
Table 4: Tested browsers and their versions.
43.0 – 81.0
54.0 – 75.0
10.0 – 13.0
15.0 – 18.0
80.0 – 81.0
8.0 – 11.0
Version Range
5.0 – 9.0
10.2 – 13.2
5.1 Testing Platform and Methods
Browser Versions. We performed the experiments during
April – May in 2020. The browser versions are shown in Ta-
ble 4. We have primarily focused on Chrome, Safari, Firefox
and Microsoft Edge. Note that Microsoft has stopped IE at
its last version at v11.0 in 2016 [42], and continued with the
new Microsoft Edge browser. For completeness (and consid-
ering users may use outdated browsers [6]), we have tested
the legacy versions of IE too. For mobile browsers, we have
tested Android Chrome and iOS Safari across their latest and
historical versions.
Regarding the historical versions, we did not start from a
browser’s ﬁrst version because most browsers did not support
internationalized domain names in the beginning. Without
IDN support, there is no point to test IDN defense policies.
Testing Method.
We run black-box testing on each
browser. By loading the testing cases (i.e., IDNs), we examine
whether the browser displays the Unicode or the Punycode.
We control the browser to load the testing IDNs sequentially,
and record a video to capture the screenshots of the browser.
We choose to record a video (continuously) instead of taking
screenshot images one by one to speed up the testing. An-
other advantage of screen recording is that it works across
browsers and platforms. To help with the post-analysis of the
recorded videos, we choose to load a special delimiter URL
“http://aaaaaa---{index}” into the address bar between
two consecutive testing IDNs. This index ﬁeld is the index
number of the next IDN to be tested. Using this delimiter,
we can accurately split video frames and map them to the
corresponding IDN (based on the index number).
In order to fully automate the tests, a key challenge is
to conﬁgure the right environment for the browsers. For ex-
ample, we need different desktop platforms (e.g., Windows,
Linux) and mobile platforms (e.g., Android, iOS) to run the
tests. In order to test historical versions, we need the right
legacy OS versions to support outdated browsers. To solve
this problem, we used a cloud-based testing framework called
LambdaTest [34]. LambdaTest provides remote Selenium for
desktop browsers and Appium for mobile browsers that can
be controlled by our scripts via APIs. Before each test, we
ﬁrst specify the operating system name and the version via
a conﬁguration ﬁle, and LambdaTest will automatically set
up the testing virtual machine (VM) in the cloud. Our scripts
then remotely control the browser running in the VM to load
the list of IDN URLs one by one while recording the screen.
Video Analysis.
The video analysis aims to determine
whether a given IDN is displayed as Unicode (allowed) or
Punycode (blocked) by the browser. First, we slice the video
frames and map them to the speciﬁc IDN. As mentioned
before, between two consecutive IDNs, we have loaded a
delimiter. For example, delimiter “aaaaaa---b16” means
the next video frames should be mapped to testing case #16
in category 2 (based on “b”). After slicing the video frames,
we remove duplicated images based on perceptual hash (or
phash) [3]. Given an image, we ﬁrst crop the image to focus
on the browser address bar. Then we apply OCR (Optical
Character Recognition) to extract the URL in text format from
the image. We use Google’s Tesseract OCR tool [19] which
is known to have a good performance. If the extracted URL
starts with “xn--”, then we determine it is a Punycode. We
have taken extra steps to improve the accuracy of ORC, e.g.,
by converting images into black and white, and improving
the image resolution. To ensure the reliability of Punycode
identiﬁcation, we randomly sampled 100 images for each
browser for manual validation. Across these browsers, we had
a 0% false negative rate and a false positive rate below 2%.
Our code is available here6.
Extended Testing vs. Simpliﬁed Testing. We divide the
testing into two phases. First, we run an extended test using
all 9,519 testing cases on the latest versions of the browsers.
Our goal is to understand the effectiveness of the current IDN
policies. This test covers Chrome 81.0, Firefox 75.0, Safari
13.0, Edge Chromium 81.0, Android Chrome 9.0, and iOS
Safari 13.2. This test does not cover IE or Edge Legacy since
Microsoft has chosen Edge Chromium over the other two
(we consider IE and Edge Legacy as historical browsers).
Second, for all other historical versions, we run a simpliﬁed
test considering the scalability requirement for covering a
large number of browsers versions on different platforms. We
sample about 10% of the testing cases for each category. For
certain categories, the sampling rates are slightly higher than
10% in order to cover all the relevant Unicode blocks. This
test covers 1,027 IDNs in total.
Additional Validations on IDN Policy Execution.
To
ensure the validity of the testing results, we have performed
further sanity checks on IDN policy executions. First, we
conﬁrm that IDN policies are hard-coded in the client side, i.e.,
the policies are executed without querying any remote servers.
We conﬁrm this by manually reading the Chromium code and
running browsers in a sandbox to analyze the network trafﬁc.
This ensures the testing results do not depend on external
services (e.g., remote blacklists). Second, by monitoring the
6https://github.com/stevetkjan/IDN_Testing
Unicode
Failure Rate
Edge
Chrome
1,963
1,963
20.62% 44.46% 42.91% 20.62%
Firefox
4,233
Safari
4,085
Table 5: Testing results of the latest browsers. In total, 9,519
IDNs are tested per browser. We report the number of IDNS
displayed as Unicode (i.e., IDNs that browsers fail to block).
network trafﬁc, we ﬁnd that IND policies are triggered (e.g.,
displaying Punycode) before the browser queries DNS. This