5
D
02 :41: 24:
ext4
947879
30 903
0
10547
0
02:41:24:
TCP
1231
982
0
I...]
4. Develop a tool to show the ratio of logical file system I/O (via VFS or the file system
interface) vs physical I/O (via block tracepoints).
5. Develop a tool to analyze file descriptor leaks: those that were allocated during tracing
but not fred. One possible solution may be to trace the kernel functions __alloc_fd(
and _close_fd().
6. (Advanced) Develop a tool to show file system I/O broken down by mountpoint.
7. (Advanced, unsolved) Develop a tool to show the time between accesses in the page cache
as a distribution. What are the challenges with this tool?
8.6
6Summary
This chapter summarizes BPF tools for file system analysis, instrumenting: system calls, VFS calls,
file system calls, and file system tracepoints; the operation of write-back and read-ahead; and the
page cache, the dentry cache, the inode cache, and the buffer cache. I included tools that show
histograms of file system operation latency to identify multi-modal distributions and outliers, to
'sanssi aoueuoad uogeogdde asqos dpaus
---
## Page 378
ter
Disk I/O
Disk I/O is a common source of performance issues because I/O latency to a heavily loaded disk
can reach tens of milliseconds or more—orders of magnitude slower than the nanosecond or
microsecond speed of CPU and memory operations. Analysis with BPF tools can help find ways to
tune or eliminate this disk I/O, leading to some of the largest application performance wins.
The term disk I/O refers to any storage I/O type: rotational magnetic media, flash-based storage,
and network storage. These can all be exposed in Linux in the same way, as storage devices, and
analyzed using the same tools.
Between an application and a storage device is usually a file system. File systems employ caching,
read ahead, buffering, and asynchronous I/O to avoid blocking applications on slow disk I/O.
I therefore suggest that you begin your analysis at the file system, covered in Chapter 8.
Tracing tools have already become a staple for disk I/O analysis: I wrote the first popular disk I/O
Ialso developed the BPF versions, called biosnoop(8) and biotop(S), finally adding the long-missing
saso quauagsp um padduqs smou aue qorqm 'sooz u (g)dopos pue pooz ut (g)doousot spooq Bupoen
*b" for block device I/O. These and other disk I/O analysis tools are covered in this chaptet.
Learning Objectives:
■Understand the I/O stack and the role of Linux I/O schedulers
 Learn a strategy for successful analysis of disk I/O performance
 Identify issues of disk I/O latency outliers
Analyze multi-modal disk I/O distributions
 Identify which code paths are issuing disk I/O, and their latency
Analyze I/O scheduler latency
 Use bpftrace one-liners to explore disk I/O in custom ways
This chapter begins with the necessary background for disk I/O analysis, summarizing the I/O
stack. I explore the questions that BPF can answer, and provide an overall strategy to follow. I then
focus on tools, starting with traditional disk tools and then BPF tools, including a list of BPF
one-liners. This chapter ends with optional exercises.
---
## Page 379
342
Chapter 9 Disk I/0
9.1
Background
This section covers disk fundamentals, BPF capabilities, and a suggested strategy for disk analysis.
9.1.1
Disk Fundamentals
Block 1/O Stack
Page
File System
Raw Block-Device IIO
Cache
Block Device Interface
Volume Manager (if used)
T
Device Mapper (if used)
Block Layer
Schedulers
Classic
Multiqueue
Schedulers
Host Bus Adaptor Driver (SCSI)
Disk Devices
Figure 9-1 Linux block I/0 stack
The term block I/O refers to device access in blocks, tradlitionally S12-byte sectors. The block device
interface originated from Unix. Linux has enhanced block I/O with the addition of schedulers
for improving I/O performance, volume managers for grouping multiple devices, and a device
mapper for creating virtual devices.
Internals
Later BPF tools will refer to some kernel types used by the I/O stack. To introduce them here: I/O
is passed through the stack as type struct request (from include/linux/blkdev.h) and, for lower
levels, as struct bio (from include/linux/blk_types.h).
---
## Page 380
9.1Background
343
rwbs
For tracing observability, the kernel provides a way to describe the type of each I/O using a character
string named rwbs. This is defined in the kernel blk_fil_rwbs( function and uses the characters:
 R: Read
· W: Write
 M: Metadata
S: Synchronous
peae-peay :y =
● F: Flush or force unit access
 D: Discard
• E: Erase
• N: None
The characters can be combined. For example, *WM’ is for writes of metadata.
1/0 Schedulers
I/O is queued and scheduled in the block layer, either by classic schedulers (only present in Linux
versions older than 5.0) or by the newer multi-queue schedulers. The classic schedulers are:
 Noop: No scheduling (a no-operation)
· Deadline: Enforce a latency deadline, useful for real-time systems
 CFQ; The completely fair queueing schecduler, which allocates I/O time slices to processes,
similar to CPU scheduling
A problem with the classic schedulers was their use of a single request queue, protected by a single
lock, which became a performance bottleneck at high I/O rates. The multi-queue driver (blk-mq,
added in Linux 3.13) solves this by using separate submission queues for each CPU, and multiple
dispatch queues for the devices. This delivers better performance and lower latency for I/O versus
classic schedulers, as requests can be processed in parallel and on the same CPU as the I/O was
initiated. This was necessary to support flash memory-based and other device types capable of
handling millions of IOPS [90].
Multi-queue schedulers available include:
 None: No queueing
 BFQ: The budget fair queueing scheduler, similar to CFQ, but allocates bandwidth as well
as I/O time
• mq-deadline: A blk-mq version of deadline
 Kyber: A scheduler that adjusts read and write dispatch queue lengths based on
performance, so that target read or write latencies can be met
---
## Page 381
344
Chapter 9 Disk I/0
The classic schedulers and the legacy I/O stack were removed in Linux 5.0. All schedulers are now
multi-queue.
Disk 1/O Performance
Figure 9-2 shows a disk I/O with operating system terminology
Request Time
Service Time
OS Scheduler Queue
Cache
Hits
Cache
&DispatchQueue
Misses
Disk
On-Disk
Cache
VO Queue
Figure 9-2 Disk I/0
From the operating system, wait time is the time spent in the block layer scheduler queues and
device dispatcher queues. Service time is the time from device issue to completion, This may
include time spent waiting on an on-device queue. Request time is the overalltime from when an
I/O was inserted into the OS queues to its completion. The request time matters the most, as that
is the time that applications must wait if I/O is synchronous.
A metric not included in this diagram is disk utilization. It may seem ideal for capacity plan-
ning: when a disk approaches 100% utilization, you may assume there is a performance problem.
However, utilization is calculated by the OS as the time that disk was doirng something, and does
not account for virtual disks that may be backed by multiple devices, or on-disk queues. This can
make the disk utilization metric misleading in some situations, including when a disk at 90%
Clue, and is a readily available metric. However, saturation metrics, such as time spent waiting, are
may be able to accept much more than an extra 10% of workload. Utilization is still useful as a
better measures of disk performance problems.
9.1.2
BPF Capabilities
Traditional Performance tools provide some insight for storage I/O, including IOPS rates, average
latency and queue lengths, and I/O by process. These tradlitional tools are summarized in the next
section.
---
## Page 382
9.1  Background
345
BPF tracing tools can provide additional insight for disk activity, answering:
 What are the disk I/O requests? What type, how many, and what I/O size?
• W'hat were the request times? Queued times?
Were there latency outliers?
• Is the latency distribution multi-modal?
 Were there any disk errors?
•What SCSI commands were sent?
• Were there any timeouts?
To answer these, trace I/O throughout the block I/O stack.
Event Sources
Table 9-1 lists the event sources for instrumenting disk I/O.
Table 9-1 Event Sources for Instrumenting Disk I/0
Event Type
Event Source
Block interface and block layer I/0
block tracepoints, kprobes
I/0 scheduler events
kprobes
SCSI I/0
scsi tracepoints, kprobes
Device driver I/0
kprobes
These provide visibility from the block I/O interface down to the device driver.
As an example event, here are the arguments to block:block_rq_issue, which sends a block I/O to
a device:
: bpftrace -1v tracepoint:block :block_rq_lssve
tracepoint:block:block_ra_issue
dev_t dev;
unsigned int nz_sector,
unsigned int bytes7
chaz rxbs [8]
char corn [16];
_data_loc char[] csd;
Questions such as *what are the I/O sizes for requests?? can be answered via a one-liner using this
tracepoint:
opftrace -e *tracepoint:block:block_rq_issue ( @bytes = hist (args=>bytes): )*
Combinations of tracepoints allow the time between events to be measured.
---
## Page 383
346
Chapter 9 Disk I/0
9.1.3
Strategy
If you are new to disk I/O analysis, here is a suggested overall strategy that you can follow. The next
sections explain these tools in more detail.
1. For application performance issues, begin with file system analysis, covered in Chapter 8.
2. Check basic dlisk metrics: request times, IOPS, and utilization (e.g., iostat(1). Look for high
utilization (which is a clue) and higher-than-normal request times (latency) and IOPS.
a. If you are unfamiliar with what IOPS rates or latencies are normal, use a
microbenchmark tool such as fio(1) on an idle system with some known workloads and
run iostat(1) to examine them.
3. Trace block 1/O latency distributions and check for multi-modal distributions and latency
outliers (e-g., using BCC biolatency(8).
4. Trace individual block I/O and look for patterns such as reads queueing behind writes
(you can use BCC biosnoop(8).
5. Use other tools and one-liners from this chapter.
To explain that first step some more: if you begin with disk I/O tools, you may quickly identify
cases of high latency, but the question then becomes: how much does this matter? I/O may be
asynchronous to the application. If so, that's interesting to analyze, but for different reasons:
understanding contention with other synchronous I/O, and device capacity planning.
9.2
TraditionalTools
This section covers iostat(1) for disk activity summaries, perf(1) for block I/O tracing, blktrace(8),
and the SCSI log.
9.2.1 iostat
iostat(1) summarizes per-disk I/O statistics, providing metrics for IOPS, throughput, I/O request
times, and utilization. It can be executed by any user, and is typically the first command used to
investigate disk I/O issues at the command line. The statistics it sources are maintained by the
kernel by default, so thte overhead of this tool is considered negligible.
iostat(1) provides many options for customizing the output. A useful combination is dxz 1, to
show disk utilization only (a),extended columns (×), skipping devices with zero metrics (2),
and per-second output (1). The output is so wide that I°ll show a left portion and then the right
portion; this is from a production issue I helped debug:
+ iostat -dxz 1
Linux 4,4,01072=avs 1.-)
12/18/2018
_xB6_64_
(16 CPU)
Device:
rrqn/s
B/ub3月
x/ a
v/s
rkB/s
xXB/s 1 ..*
xvda
0.00
0.29
0.21
0.17
6.29
3. 09/
xv@o
0. 00
0.08
44.39
9.98550T.391110.55 1-*.
---
## Page 384
9.2 Traditional Tools
347
Device:
s/ubx.3
B/ub3月
x/ a
v/s
3B/a
xkB/s \ ...
xvdb
0., 00
0.00745,00
0.00 91656.00
0.00 / ..*
xXB/s f .*
...
Device:
rrqn/s
2/uB3A
α/I
2/A
ckB/s
xvdb
0. 00
0.00739.00
0.00 92152.00
0.00 \ ..
These columns summarize the workload applied, and are useful for workload characterization.
The first two provide insight into disk merges: this is where a new I/O is found to be readling or writing
to a disk location adjacent (front or back) to another queued I/O, so they are merged for efficiency
The columns are:
•rrqm/s: Read requests queued and merged per second
■ wrqm/s: Write requests queued and merged per second
•r/s: Read requests completed per second (after merges)
 w/s: Write requests completed per second (after merges)
•rkB/s: Kbytes read from the disk device per second
wkB/s: Kbytes written to the disk device per second
The first group of output (showing both xvda and xvdb devices) is the summary since boot, and
can be used for comparison with the subsequent one-second summaries. This output shows that
xvdb normally has a read throughput of 5,s07 Kbytes/sec, but the current one-second summaries
show over 90,000 read Kbytes/sec. The system has a heavier-than-normal read workload.
Some math can be applied to these columns to figure out the average read and write size. Dividing
the rkB/s column by the r/s column shows the average read size is about 124 Kbytes. A newer version
of iostat(1) includes average sizes as the rareq-sz (read average request size) and wareq-sz columns.
The right columns show:
z2nbb.e zbBAe \..
svsit r_axait v_avsit svctn guti1
- . - /
49.32
0.00
12.74
6.96
19.87
96'
0. 15
243,43
2.28
41.96
41,75
42.88
1,52
8.25
-.- /
-\ avgrq-sz avgqu-5z
svsit c_axait v_avait
TTnq u0A2
·.- /
246.06
25 . 32
33.84
DB'EE
0. 00
1.35 100.40
.. -/ avgrq=sz avgqu=sz
avait r_axalt v_avait svctn huti1
..249.40
24,7533.4933.49
0.001.35 100.00
These show the resulting performance by the device. The columns are:
·avgrq-sz: Average request size in sectors (512 bytes),
aoe pue ananb sanba1 asiup aq u Surrem tqsoq ssanbou jo Iaqunu ae1asy :zs-nb&ae =
on the device.
---
## Page 385
348
8 Chapter 9 Disk I/O
·await: Average I/O request time (aka response time), including time waiting in the driver
request queue and the I/O response time of the device (ms),
*r_await: Same as await, but for reads only (ms).
w_await: Same as await, but for writes only (ms).
● svctm: Average (inferred) I/O response time for the disk device (ms).
 %util: Percentage of time device was busy processing I/O requests (utilization).
The most important metric for delivered performance is await. If the application and file system
use a technique to mitigate write latency (e-g., write through), then w_await may not matter as
much, and you can tocus on r_awatt instead.
 Aquo st # veu puu u daax nq *ueuodur s! [ng Buuued Aapoedeo pue a8esn aornosau 1o
measure of busy-ness (non-idle time), and may mean little for virtual devices backed by multiple
disks. Those devices may be better understood by the load applied: IOPS (z/s + w/s) and through
put (rkB/s + wkB/s).
This example output shows the disk hitting 100% utilization, and an average read I/O time of
33 milliseconds. For the workload applied and the disk device, this turned out to be expected
atto ou pno ag are os auooaq peu peau uaq say at seq sem anss ea at1 aoueoad
be cached in the page cache, and were read from disk instead.
9.2.2perf
perf(1) was introduced in Chapter 6 for PMC analysis and timed stack sampling Its tracing capa
bilities can also be used for disk analysis, especially using the block tracepoints.
For example, tracing the queuing of requests (block_rq_insert), their ssue to a storage device
(block_rq_issue), and their completions (block_rq_complete):
 perf zecord -e block:block_rq_insert,block:block_rq_issue,block:block_rq_conplete -a
^C[ perf record: Noken up 7 tines to vrite data ]
[(setdues pEoz] eaep*gxed eH stb*9 eqoxn pue pexnqdeo ipxooex Ixed 1
 perf script
kvozkez/u16:3 25003 [004] 543348.164811: block:b1ock_rq_Lnsert: 259, 0 RM 4096 ()
2564656 + 8 [kxorker/u16 :3]
2564656 + 8 [kvorker/4:18]
kvozkez/4 :1B