ers, this algorithm is capable of revealing at least 12-bits
from this monitor per day.
6 Protecting Threat Monitors
As mentioned earlier, threat monitors are inherently vul-
nerable to marking activities. Possible approaches to
protect these monitors is discussed in this section, start-
ing with assessment of the Leak. By knowing the how
much information the monitor is leaking, we can infer
the time-to-live for sensors and the monitor, which in
turn can be used to take correct measures.
6.1 Assessing the Leak
The ﬁrst step of the monitor protection is to assess how
much information is leaking per unit time. An important
guideline for the assessment is that we should not to-
tally rely on ﬁgures derived by some explicit procedure
in mind.
A hypothetical example would show this. Assume
that there is a hypothetical monitor that publishes a com-
pletely unpopulated table type port report every hour.
USENIX Association
14th USENIX Security Symposium
221
Date
12/02
12/03
12/04
12/05
12/06
12/07
12/08
mean
T SP
0.965
0.848
0.881
0.838
0.835
0.842
0.851
sthresh
tthresh
nmarker
0.738
0.638
0.654
0.553
0.648
0.660
0.674
0.625
0.533
0.540
0.410
0.554
0.570
0.586
13
14
15
16
16
16
16
Hits
(%)
88.8
94.8
88.2
87.2
95.3
95.0
94.7
FP
(%)
0.1
2.1
0.5
12.3
0.3
0.1
0.4
FN
(%)
11.1
3.1
11.3
0.5
4.4
4.9
4.9
3o4
(%)
93.5
98.6
93.2
92.1
99.3
98.7
98.5
Table 2: Result of Simulated Marking for First Week of Dec. 2004.
Let’s assume that there are 1K sensors in this moni-
tor. A botnet with 20K hosts each shooting address-
encoded-port type markers at 30 marker/sec will pro-
duce a complete list of /16 blocks where sensors are
placed in the very ﬁrst hour. Then during the second
hour, each /16 block is marked with address-encoded-
port markers each using 64 port (6 bits), producing a
complete list of /22 blocks. This process is repeated,
and at the end of 4th hour, complete list of full 32-bit
addresses for all 1K sensors will be produced.
The process may become shorter, depending on num-
ber of blocks produced by each phase.
If 1K sensor
addresses are actually 128 wide aperture sensors each
monitoring a /28 space, then the each phase will produce
maximum of 128 blocks, which means that we can use
512 ports (11-bit worth) for second and third phases, and
the complete list would be available after the 3rd hour.
As shown here, the same marking activity behaves
differently under different conditions. So the procedu-
rally derived assessment results should only be used as a
reference.
6.2 Possible Protections
Provide Less Information
An obvious way to ﬁght against marking activities is to
decrease the amount of information the system is giv-
ing out, prolonging the time-to-live. Manipulating feed-
back properties studied in section 4.2 will provide a good
starting point. For example, longer accumulation win-
dow, longer feedback delay, less sensitivity, and larger
cut-off threshold all works for this purpose. However,
there are several points that we have to be aware of.
• Frequency and level of detail of published reports
usually reﬂect a system’s basic operation policy.
For example, some system expect large-scale dis-
tributed (manual) inspection by report viewers so
that new malicious activities can be captured at its
very early stage. Such system obviously requires
frequent and detailed reports to be published, and
decreasing the amount of information given may in-
terfere with this policy. Therefore, there is a trade
off between the degree of protection by this method
and the fundamental policy of the system.
• Even if we decrease the amount of information, we
still have a leak. So, the amount of information the
system is giving out should be decided with theo-
retical considerations, and should never be decided
by some simplistic thoughts.
Giving out background information that leads to ac-
quisition of vital system parameters or valuable addi-
tional information should be kept minimum. This in-
cludes system overview statements that are open to pub-
lic, such as those in system’s home pages, proceedings
and meeting handouts. Some system is required to dis-
close its internals to some extent by its nature. The in-
formation disclosed should still be examined carefully
even if this is the case.
Throttle the Information
There seem to be some standard remediation tech-
niques that are being used to provide privacy in data
mining that could be applied here. It would be helpful to
study the privacy of database queries and relate it to the
problem presented in this paper.
Introducing Explicit Noise
Because of the stealthiness requirement, most mark-
ing activities would try to exploit small changes in feed-
backs. Adding small noise to captured events would dis-
turb capturing the small changes. The noise can be arti-
ﬁcially generated, but authors believe that this is some-
thing we should not do. One possible way is to intro-
duce explicit variance into level sensitivity into sensors.
For example, sensors can be divided into two groups,
in which one group operates at full sensitivity, and an-
other group operates at a reduced sensitivity, generating
low level noise like events. Theoretically speaking, this
method can be understood as introducing another dimen-
sion that markings have to consider. In this sense, lev-
els of sensitivity should be different across all sensors,
rather than limiting them to only two levels.
The similar effect can be introduced by inter-monitor
collaboration, in which noise is generated from moni-
tor results from other monitor systems, using them as
222
14th USENIX Security Symposium
USENIX Association
sources for legitimate noise.
Disturbing Mark-Examine-Update Cycle
Another obvious way is to disturb the mark-examine-
update cycle in ﬁgure 5 so that list of addresses will not
get reﬁned, or at least slowing down the cycle. One way
to implement this strategy is to incorporate explicit sen-
sor mobility.
Things to consider here are:
• Degree of mobility required to disturb the cycle
must be studied. Assuming that marking activi-
ties do not use address bit scrambling (for stealth-
iness purposes), it is obvious that changing ad-
dresses within a limited small address space does
little harm to the cycle, because the cycle only have
to discard the last part of its activity. Conversely,
moving among much larger blocks would invali-
date the marking result at its early stage, impacting
all results thereafter.
• Current threat monitors that use different set of al-
most identical sensors and almost identical post-
processing provide different reports. Our guess is
that with the number of sensors these systems are
using, location of sensors affects the monitor re-
sult quite a bit. So, degree of how sensor mobil-
ity affects monitor results must be studied, together
with further investigation for reasoning of multiple
threat monitors giving different results. A study
using variations in sensor aperture and placement
[18] gives answers to some of these questions.
Intentionally discarding part of captured events in ran-
dom or other fashion also disturbs the mark-examine-
update cycle. From the view point of consistency of
monitor results, this method is better than explicit mo-
bility. However, it must be noted that discarding events
will deteriorate the effective sensitivity of the monitor.
Marking Detection
Another obvious and powerful, but hard to implement
way is to detect marking activities and discard associated
capture events. This is extremely difﬁcult, because well
designed marking is expected to give least correlations
among markers and thus nearly indistinguishable from
real background activities.
However, there is a fundamental difference between
marking activities and real background activities; events
generated by marking activities are basically local and
transient by nature. It may be possible to design a mark-
ing activity that implicitly covers multiple addresses and
that persist over time, but only at the sacriﬁce of mark-
ing speed. We are now looking at several ways to handle
transient events. Statistical approach may work in some
cases, especially for those activities that introduce strong
statistical anomalies, and we have already gathered some
positive result from the statistical ﬁltering approach.
Correlations among different monitors may be used
to detect marking activities, but again, difference among
feedbacks from different monitors must be studied in
depth ﬁrst. We are also not certain if this method would
be capable of detecting small transient changes. In any
case, we believe that studies on advanced IDS would
provide another good starting point.
Sensor Scale and Placement
Consider an imaginary case in which 216 sensors are
placed uniformly over the /16 blocks (one sensor per /16
block) for example. This arrangement forces address-
encoded-port marking to be applied sequentially until
half of sensors are detected. Although the marking still
derives complete sensor addresses at constant rate during
this period, the arrangement effectively slows down the
most efﬁcient marking method.
Increasing number of
sensors that are carefully placed provide a certain level
of protection, and worth studying its property.
The carefully planned distributed sensor placement
may also beneﬁt the marking detection efforts, by reveal-
ing patterns of the transient events that sweeps across
address blocks.
Small Cautions
In section 4.5, we have pointed out several additional
methods to gather useful information. Most of these
methods can be disabled by paying small attentions.
• Give FQDNs to sensors deployed in intranets to
prevent FQDN-based ﬁltering. Names that re-
sembles common functionality, or names that dis-
solves into other hosts in the same subnet are better
choices.
• For ICMP-echo-responding sensors, consider an-
swering to some other packets they capture, to pre-
vent them from detected as silent host that only an-
swers to ICMP echo request.
• Consider how sensors respond to various ICMP re-
quests to prevent ICMP-based ﬁngerprinting and
topology inferencing.
• For intranet-placed sensors, introduce some facility
(hardware and/or software) such as TTL mangling,
to make sensors look like they are deep inside a in-
tranet to avoid topology inferencing based ﬁltering.
7 Conclusion
Passive Internet threat monitors are an important tool for
obtaining a macroscopic view of malicious activity on
the Internet. In this paper, we showed that they are sub-
ject to detection attacks that can uncover the location of
their sensors. We believe that we have found a new class
of Internet threat, because it does not post a danger to the
host systems themselves, but rather a danger to a meta-
system that is intended to keep the host systems safe.
USENIX Association
14th USENIX Security Symposium
223
[6] About the Internet Storm Center (ISC). http://isc.
sans.org/about.php.
[7] Ruoming Pang, Vinod Yegneswaran, Paul Barford, Vern
Paxson, and Larry Peterson. Characteristics of Internet
Background Radiation.
In Proceedings of the Internet
Measurement Conference (IMC) 2004, October 2004.
[8] Dug Song, Rob Malan, and Robert Stone. A Snapshot of
Global Internet Worm Activity. Technical report, Arbor
Networks Inc., 2001.
[9] SWITCH Internet Background Noise (IBN). http://
www.switch.ch/security/services/IBN/.
[10] @police Internet Activities Monitored. http://www.
cyberpolice.go.jp/english/obs_e.html.
[11] JPCERT/CC Internet Scan Data Acquisition System
(ISDAS). http://www.jpcert.or.jp/isdas/
index-en.html.
[12] Masaki Ishiguro. Internet Threat Detection System Us-
ing Bayesian Estimation. In Proceedings of The 16th An-
nual Computer Security Incident Handling Conference,
June 2004.
[13] Internet Motion Sensor.
http://ims.eecs.
umich.edu/.
[14] Michael Bailey, Eval Cooke, Farnam Jahanian, Jose
Nazario, and David Watson. Internet Motion Sensor: A
Distributed Blackhole Monitoring System. In Proceed-
ings of The 12th Anual Network and Distributed System
Security Symposium. ISOC, February 2005.
[15] PlanetLab. http://www.planet-lab.org/.
[16] The Team Cymru Darknet Project. http://www.
cymru.com/Darknet/.
[17] libnet. http://libnet.sourceforge.net/.
[18] Evan Cooke, Michael Bailey, Zhuoqing Morley Mao,
David Watson, Farnam Jahanian, and Danny McPher-
son. Toward understanding distributed blackhole place-
ment.
In Proceedings of the 2004 ACM workshop on
Rapid malcode, October 2004.
Although we believe that we have not fully deﬁned
the threat, we presented marking algorithms that work
in practice. They were derived more or less empirically,
so it is possible that there may be more efﬁcient marking
algorithms that we did not study. For example, methods
for detecting remote capture devices has been studied in
the context of remote sniffer detection, but none of these
studies have correlated plain sniffers with threat moni-
tors, and there may be techniques that can be applied in
our context. To ﬁnd insights that we may have missed, a
more mathematical approach to the analysis of feedback
properties may be necessary.
We presented some methods to protect against our
markings algorithms, but some of these solutions are
hard to implement, and others still need to be studied
more carefully for their feasibility and effectiveness and
most importantly, for their vulnerabilities. The goal of
this paper is to bring attention of this problem to the re-
search community and leverage people with various ex-
pertise, not limited to system and network security, to
protect of this important technology. Continuing efforts
to better understand and protect passive threat monitors
are essential for the safety of the Internet.
Acknowledgments
We would like to present our sincere gratitude to multi-
ple parties who admitted our marking activities on their
networks and monitor systems during the early stage of
this research. We must confess, that marking against
them sometimes went well beyond the level of the back
ground noise, and sometimes took a form of unexpect-
edly formatted packets. We would also like to acknowl-
edge members of the WIDE Project, members of the
Special Interest Group on Internet threat monitors (SIG-
MON) and the anonymous reviewers for thoughtful dis-
cussions and valuable comments. We must also note
that the ﬁnal version of this paper could not have been
prepared without the sincere help of our paper shepherd
Niels Provos.
References
[1] CAIDA Telescope Analysis.
http:
//www.caida.org/analysis/security/
telescope/.
[2] Distributed intrusion detection system. http://www.
dshield.org/.
[3] David Moore, Geoffrey M. Voelker, and Stefan Savage.
In 10th
Inferring Internet Denial-of-Service Activity.
USENIX Security Symposium, August 2001.
[4] SANS Internet Storm Center (ISC). http://isc.
sans.org/.
[5] The IUCC/IDC Internet Telescope. http://noc.
ilan.net.il/research/telescope/.
224
14th USENIX Security Symposium
USENIX Association