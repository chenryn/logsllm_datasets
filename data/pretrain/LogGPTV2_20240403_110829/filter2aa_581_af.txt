no one can intercept any of those internal channels by enforcing strong network-level 
security. The other option is to use optimized hardware to carry out the encryption/
decryption process in the TLS communication. Doing encryption/decryption process 
at the dedicated hardware level is far more cost-effective than doing the same at the 
application level, in terms of performance.
Even with TLS, the message is only protected while it is in transit. As soon as the 
message leaves the transport channel, it’s in cleartext. In other words, the protection 
provided by TLS is point to point. When you log in to your banking web site from the 
browser, your credentials are only secured from your browser to the web server at your 
bank. If the web server talks to a Lightweight Directory Access Protocol (LDAP) server 
to validate the credentials, once again if this channel is not explicitly protected, then 
the credentials will be passed in cleartext. If anyone logs all the in and out messages to 
and from the bank’s web server, then your credentials will be logged in plaintext. In a 
highly secured environment, this may not be acceptable. Using message-level security 
over transport-level security is the solution. With message-level security, as its name 
implies, the message is protected by itself and does not rely on the underlying transport 
for security. Since this has no dependency on the transport channel, the message will 
be still protected, even after it leaves the transport. This once again comes at a high 
performance cost. Using message-level protection is much costlier than simply using 
TLS. There is no clear-cut definition on making a choice between the security and the 
performance. Always there is a compromise, and the decision has to be taken based on 
the context.
 Weakest Link
A proper security design should care about all the communication links in the system. 
Any system is no stronger than its weakest link. In 2010, it was discovered that since 
2006, a gang of robbers equipped with a powerful vacuum cleaner had stolen more than 
600,000 euros from the Monoprix supermarket chain in France.14 The most interesting 
thing was the way they did it. They found out the weakest link in the system and attacked 
it. To transfer money directly into the store’s cash coffers, cashiers slid tubes filled with 
14 “Vacuum Gang” Sucks Up $800,000 From Safeboxes, https://gizmodo.com/
vacuum-gang-sucks-up-800-000-from-safeboxes-5647047
Chapter 2  Designing seCurity for apis
41
money through pneumatic suction pipes. The robbers realized that it was sufficient to 
drill a hole in the pipe near the trunk and then connect a vacuum cleaner to capture the 
money. They didn’t have to deal with the coffer shield.
Not always, the weakest link in a system is either a communication channel or an 
application. There are many examples which show the humans have turned out to be 
the weakest link. The humans are the most underestimated or the overlooked entity in a 
security design. Most of the social engineering attacks target humans. In the famous Mat 
Honan’s attack, calling to an Amazon helpdesk representative, the attacker was able to 
reset Mat Honan’s Amazon credentials. The October 2015 attack on CIA Director John 
Brennan’s private email account is another prime example of social engineering.15 The 
teen who executed the attack said, he was able to fool a Verizon worker to get Brennan’s 
personal information and duping AOL into resetting his password. The worst side of 
the story is that Brennan has used his private email account to hold officially sensitive 
information—which is again a prime example of a human being the weakest link of the 
CIA defense system. Threat modeling is one of the techniques to identify the weakest 
links in a security design.
 Defense in Depth
A layered approach is preferred for any system being tightened for security. This is 
also known as defense in depth. Most international airports, which are at a high risk of 
terrorist attacks, follow a layered approach in their security design. On November 1, 
2013, a man dressed in black walked into the Los Angeles International Airport, pulled 
a semi-automatic rifle out of his bag, and shot his way through a security checkpoint, 
killing a TSA screener and wounding at least two other officers.16 This was the first 
layer of defense. In case someone got through it, there has to be another to prevent the 
gunman from entering a flight and taking control. If there had been a security layer 
before the TSA, maybe just to scan everyone who entered the airport, it would have 
detected the weapon and probably saved the life of the TSA officer.
NSA (National Security Agency of the United States) identifies defense in depth as 
a practical strategy for achieving information assurance in today’s highly networked 
15 Teen says he hacked CIA director’s AOL account, http://nypost.com/2015/10/18/
stoner-high-school-student-says-he-hacked-the-cia/
16 Gunman kills TSA screener at LAX airport, https://wapo.st/2QBfNoI
Chapter 2  Designing seCurity for apis
42
environments.17 It further explains layered defense under five classes of attack: passive 
monitoring of communication channels, active network attacks, exploitation of insiders, 
close-in attacks, and attacks through various distribution channels. The link and network 
layer encryption and traffic flow security is proposed as the first line of defense for 
passive attacks, and the second line of defense is the security-enabled applications. For 
active attacks, the first line of defense is the enclave boundaries, while the second line 
of defense is the computing environment. The insider attacks are prevented by having 
physical and personnel security as the first line of defense and having authentication, 
authorization, and audits as the second line of defense. The close-in attacks are 
prevented by physical and personnel security as the first layer and having technical 
surveillance countermeasures as the second line of defense. Adhering to trusted 
software development and distribution practices and via runtime integrity controls 
prevents the attacks via multiple distributed channels.
The number of layers and the strength of each layer depend on which assets you 
want to protect and the threat level associated with them. Why would someone hire a 
security officer and also use a burglar alarm system to secure an empty garage?
 Insider Attacks
Insider attacks are less complicated, but highly effective. From the confidential US 
diplomatic cables leaked by WikiLeaks to Edward Snowden’s disclosure about the 
National Security Agency’s secret operations, all are insider attacks. Both Snowden 
and Bradley Manning were insiders who had legitimate access to the information they 
disclosed. Most organizations spend the majority of their security budget to protect 
their systems from external intruders; but approximately 60% to 80% of network misuse 
incidents originate from inside the network, according to the Computer Security 
Institute (CSI) in San Francisco.
There are many prominent insider attacks listed down in the computer security 
literature. One of them was reported in March 2002 against the UBS Wealth Management 
firm in the United States. UBS is a global leader in wealth management having branches 
over 50 countries. Roger Duronio, one of the system administrators at UBS, found guilty 
of computer sabotage and securities fraud for writing, planting, and disseminating 
malicious code that took down up to 2000 servers. The US District Court in Newark,  
17 Defense in Depth, www.nsa.gov/ia/_files/support/defenseindepth.pdf
Chapter 2  Designing seCurity for apis
43
New Jersey, sentenced him for 97 months in jail.18 The Target data breach that we 
discussed at the beginning of the chapter is another prime example for an insider 
attack. In that case, even the attackers were not insiders, they gained access to the 
Target internal system using the credentials of an insider, who is one of the company’s 
refrigeration vendors.
According to an article by Harvard Business Review (HBR),19 at least 80 million 
insider attacks take place in the United States each year. HBR further identifies three 
causes for the growth of insider attacks over the years:
• 
One is the dramatic increase in the size and the complexity of IT. As 
companies grow in size and business, a lot of isolated silos are being 
created inside. One department does not know what the other does. 
In 2005 call center staffers based in Pune, India, defrauded four 
Citibank account holders in New York of nearly $350,000, and later 
it was found those call center staffers are outsourced employees of 
Citibank itself and had legitimate access to customers’ PINs and 
account numbers.
• 
The employees who use their own personal devices for work are 
another cause for the growing insider threats. According to a report 
released by Alcatel-Lucent in 2014, 11.6 million mobile devices 
worldwide are infected at any time.20 An attacker can easily exploit 
an infected device of an insider to carry out an attack against the 
company.
• 
The third cause for the growth of insider threats, according to the 
HBR, is the social media explosion. Social media allow all sorts of 
information to leak from a company and spread worldwide, often 
without the company’s knowledge.
Undoubtedly, insider attacks are one of the hardest problems to solve in a security 
design. These can be prevented to some extent by adopting robust insider policies, 
raising awareness, doing employee background checks at the point of hiring them, 
18 UBS insider attack, www.informationweek.com/ex-ubs-systems-admin-sentenced-to- 
97-months-in-jail/d/d-id/1049873
19 The Danger from Within, https://hbr.org/2014/09/the-danger-from-within
20 Surge in mobile network infections in 2013, http://phys.org/news/2014-01-surge-mobile-
network-infections.html
Chapter 2  Designing seCurity for apis
44
enforcing strict processes and policies on subcontractors, and continuous monitoring of 
employees. In addition to these, SANS Institute also published a set of guidelines in 2009 
to protect organizations from insider attacks.21
Note insider attacks are identified as a growing threat in the military. to address 
this concern, the us Defense advanced research projects agency (Darpa) 
launched a project called Cyber insider threat (CinDer) in 2010. the objective of 
this project was to develop new ways to identify and mitigate insider threats as 
soon as possible.
 Security by Obscurity
Kerckhoffs’ principle22 emphasizes that a system should be secured by its design, not 
because the design is unknown to an adversary. One common example of security by 
obscurity is how we share door keys between family members, when there is only a 
single key. Everyone locks the door and hides the key somewhere, which is known to 
all the other family members. The hiding place is a secret, and it is assumed only family 
members know about it. In case if someone can find the hiding place, the house is no 
more secured.
Another example for security by obscurity is Microsoft’s NTLM (an authentication 
protocol) design. It was kept secret for some time, but at the point (to support 
interoperability between Unix and Windows) Samba engineers reverse-engineered it, 
they discovered security vulnerabilities caused by the protocol design itself. Security by 
obscurity is widely accepted as a bad practice in computer security industry. However, 
one can argue it as another layer of security before someone hits the real security layer. 
This can be further explained by extending our first example. Let’s say instead of just 
hiding the door key somewhere, we put it to a lock box and hide it. Only the family 
members know the place where the lock box is hidden and also the key combination to 
21 Protecting Against Insider Attacks, www.sans.org/reading-room/whitepapers/incident/
protecting-insider-attacks-33168
22 In 1883, Auguste Kerckhoffs published two journal articles on La Cryptographie Militaire in 
which he emphasized six design principles for military ciphers. This resulted in the well-known 
Kerckhoffs’ principle: A cryptosystem should be secured even if everything about the system, 
except the key, is public knowledge.
Chapter 2  Designing seCurity for apis
45
open the lock box. The first layer of defense is the location of the box, and the second 
layer is the key combination to open the lock box. In fact in this case, we do not mind 
anyone finding the lock box, because finding the lock box itself is not sufficient to open 
the door. But, anyone who finds the lock box can break it to get the key out, rather than 
trying out the key combination. In that case, security by obscurity adds some value as a 
layer of protection—but it’s never good by its own.
 Design Principles
Jerome Saltzer and Michael Schroeder produced one of the most widely cited research 
papers in the information security domain.23 According to the paper, irrespective of 
the level of functionality provided, the effectiveness of a set of protection mechanisms 
depends upon the ability of a system to prevent security violations. In most of the 
cases, building a system at any level of functionality that prevents all unauthorized 
actions has proved to be extremely difficult. For an advanced user, it is not hard to find 
at least one way to crash a system, preventing other authorized users accessing the 
system. Penetration tests that involved a large number of different general-purpose 
systems have shown that users can build programs to obtain unauthorized access to 
information stored within. Even in systems designed and implemented with security 
as a top priority, design and implementation flaws could provide ways around the 
intended access restrictions. Even though the design and construction techniques that 
could systematically exclude flaws are the topic of much research activity, according 
to Jerome and Michael, no complete method applicable to the construction of large 
general-purpose systems existed during the early 1970s. In this paper, Jerome Saltzer and 
Michael Schroeder further highlight eight design principles for securing information in 
computer systems, as described in the following sections.
 Least Privilege
The principle of least privilege states that an entity should only have the required set 
of permissions to perform the actions for which they are authorized, and no more. 
Permissions can be added as needed and should be revoked when no longer in use. 
23 The Protection of Information in Computer Systems, http://web.mit.edu/Saltzer/www/
publications/protection/, October 11, 1974.
Chapter 2  Designing seCurity for apis
46
This limits the damage that can result from an accident or error. The need to know 
principle, which follows the least privilege philosophy, is popular in military security. 
This states that even if someone has all the necessary security clearance levels to access 
information, they should not be granted access unless there is a real/proven need.
Unfortunately, this principle didn’t apply in the case of Edward Snowden,24 or he 
was clever enough to work around it. Edward Snowden who worked for NSA (National 
Security Agency of the United States) as a contractor in Hawaii used unsophisticated 
techniques to access and copy an estimated 1.7 million classified NSA files. He was 
an employee of NSA and had legitimate access to all the information he downloaded. 
Snowden used a simple web crawler, similar to Google’s Googlebot (which collects 
documents from the Web to build a searchable index for the Google Search engine), 
to crawl and scrape all the data from NSA’s internal wiki pages. Being a system 
administrator, Snowden’s role was to back up the computer systems and move 
information to local servers; he had no need to know the content of the data.
ISO 27002 (formerly known as ISO 17799) also emphasizes on the least privilege 
principle. ISO 27002 (Information Technology - Code of Practice for Information Security 
Management) standard is a well-known, widely used standard in the information 
security domain. It was originally developed by the British Standards Institution and 
called the BS7799 and subsequently accepted by the International Organization for 
Standardization (ISO) and published under their title in December 2000. According to 
ISO 27002, privileges should be allocated to individuals on a need-to-use basis and on 
an event-by-event basis, that is, the minimum requirement for their functional role only 
when needed. It further identifies the concept of “zero access” to start, which suggests 
that no access or virtually no access is the default, so that all subsequent access and the 
ultimate accumulation can be traced back through an approval process.25
 Fail-Safe Defaults
The fail-safe defaults principle highlights the importance of making a system safe by 
default. A user’s default access level to any resource in the system should be “denied” 
unless they’ve been granted a “permit” explicitly. A fail-safe design will not endanger the 
24 Snowden Used Low-Cost Tool to Best NSA, www.nytimes.com/2014/02/09/us/snowden-used-
low-cost-tool-to-best-nsa.html
25 Implementing Least Privilege at Your Enterprise, www.sans.org/reading-room/whitepapers/
bestprac/implementing-privilege-enterprise-1188
Chapter 2  Designing seCurity for apis
47
system when it fails. The Java Security Manager implementation follows this principle—
once engaged, none of the components in the system can perform any privileged 
operations unless explicitly permitted. Firewall rules are another example. Data packets 
are only allowed through a firewall when it’s explicitly allowed; otherwise everything is 
denied by default.
Any complex system will have failure modes. Failures are unavoidable and should be 
planned for, to make sure that no security risks get immerged as part of a system failure. 
Possibility of failures is an assumption made under the security design philosophy, 
defense in depth. If no failures are expected, there is no point of having multiple layers 
of defense. Let’s go through an example where every one of us is most probably familiar 
with: credit card verification. When you swipe your credit card at a retail store, the credit 
card machine there connects to the corresponding credit card service to verify the card 
details. The credit card verification service will verify the transaction after considering 
the available amount in the card, whether the card is reported as lost or blacklisted, and 
other context-sensitive information like the location where the transaction is initiated 
from, the time of the day, and many other factors. If the credit card machine fails to 
connect to the verification service, what would happen? In such case, the merchants are 
given a machine to get an imprint of your card manually. Getting an imprint of the card 
is not just sufficient, as it does not do any verification. The merchant also has to talk to 
his bank over the phone, authenticate by providing the merchant number, and then get 
the transaction verified. That’s the fail-safe process for credit card verification, as the 
failure of the credit card transaction machine does not lead into any security risks. In 
case the merchant’s phone line is also completely down, then according to the fail-safe 
defaults principle, the merchant should avoid accepting any credit card payments.
The failure to adhere to fail-safe defaults has resulted in many TLS (Transport Layer 
Security)/SSL (Secure Sockets Layer) vulnerabilities. Most of the TLS/SSL vulnerabilities 
are based on the TLS/SSL downgrade attack, where the attacker makes the server to 
use a cryptographically weak cipher suite (we discuss TLS in depth in Appendix C). In 
May 2015, a group from INRIA, Microsoft Research, Johns Hopkins, the University of 
Michigan, and the University of Pennsylvania published a deep analysis26 of the Diffie- 
Hellman algorithm as used in TLS and other protocols. This analysis included a novel 
downgrade attack against the TLS protocol itself called Logjam, which exploits export 
cryptography. Export ciphers are weaker ciphers that were intentionally designed to be 
26 Imperfect Forward Secrecy: How Diffie-Hellman Fails in Practice, https://weakdh.org/
imperfect-forward-secrecy-ccs15.pdf
Chapter 2  Designing seCurity for apis
48
weaker to meet certain legal requirements enforced by the US government, in 1990s. 
Only weaker ciphers were legally possible to export into other countries outside the 
United States. Even though this legal requirement was lifted later on, most of the popular 
application servers still support export ciphers. The Logjam attack exploited the servers 
having support for export ciphers by altering the TLS handshake and forcing the servers 
to use a weaker cipher suite, which can be broken later on. According to the fail-safe 
defaults principle, in this scenario, the server should abort the TLS handshake when they 
see a cryptographically weaker algorithm is suggested by the client, rather than accepting 
and proceeding with it.
 Economy of Mechanism
The economy of mechanism principle highlights the value of simplicity. The design 
should be as simple as possible. All the component interfaces and the interactions 
between them should be simple enough to understand. If the design and the 
implementation were simple, the possibility of bugs would be low, and at the same 
time, the effort on testing would be less. A simple and easy-to-understand design and 
implementation would also make it easy to modify and maintain, without introducing 
bugs exponentially. As discussed earlier in this chapter, Gary McGraw in his book, 
Software Security, highlights complexity in both the code and the system design as one 
attribute that is responsible for the high rate of data breaches.
The keep it simple, stupid (KISS) principle introduced by the US Navy in 1960 is quite 
close to what Jerome Saltzer and Michael Schroeder explained under the economy of 
mechanism principle. It states that most systems work best if they are kept simple rather 
than made complicated.27 In practice, even though we want to adhere to the KISS principle, 
from operating systems to application code, everything is becoming more and more 
complex. Microsoft Windows 3.1 in 1990 started with a codebase slightly over 3 million lines 