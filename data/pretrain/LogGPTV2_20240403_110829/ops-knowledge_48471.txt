User: I have a problem with understanding a strange file locking behavior in Python Debugger.
I have a 2TB image file, which my script reads. Everything works perfect, until I want to read the same file with a different hex editor. If the file is opened in hex editor before I start my script, everything is fine. If I try to open the file during script paused at breakpoint, my system almost hangs and becomes very slow. I normally can kill Pyhon and hex editor from terminal, but it is very slow and takes up to 10 minutes.
The same problem apperares AFTER I stop the script and even extensively kill all Python instances. The disk, where this image is situated is remained locked and it's not possible to unmount it (only with diskutil force command), system hangs if I try to open the file anywhere else.
Also I can't start scripts one after another, next scripts just stops working and hangs my system.
I have to wait up to 10 minutes to be able to work with the file again.
I tried to find the process which locks the file with "sudo lsof +D" command but it doesn't list anything.
Here are some more details:
— My system is Mac Os X 10.9. Python is 3.4. I use Eclipse with Pydev to develop the script.
— I use open('image.dmg', mode='rb') command to open the file in python and close()to close it.
— The file is a 2TB disk image on external ExFat formatted drive. Other files don't have such problems. File is write-protected in Finder settings.
Can anyone direct me in a proper direction to locate the source of this problem?
Assistant: I never worked with Mac OS but I could imagine this:

Maybe Python locks the file on open and the hex-editor is failing if you try to open it afterwards. 
The system hangs and get slow (even after killing all processes) -> I think thats some kind of caching which fill up your memory till your computer starts using the harddisk as memory (and turns really slow)

I think you should try to find out how files get open with python on Mac OS (if there is some kind of lock) and you should take care that this large file never get stored complete in memory (there are different methods how to read large files in chunks). 
Greetings Kuishi
PS: I apologize for my English. It isnt my native language.