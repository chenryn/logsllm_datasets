b3
a1
b2
b4
a3
a2
c3
b1
c2
c4
b3
b2
Step 7:
c3
c2
c1 a4
a3
a2
a1
b4
b3
b2
b1
c4
: Normal Transmission Buffer
: Retransmission Buffer with unsent data
: Inter-router Link
: Retransmission Buffer with sent data
=
⎤
Figure 10. A Deadlock recovery example
⎡
4 / 4
=
4 ( n 1) 12
⎡
6 / 4
=
4 ( n 2 ) 32
2, n
=
1, n
=
⎤
4
3
=
×
×
×
×
=
>
=
>
- Figure 10: 
- Figure 11: 
T
i
∴ =
=
B
4, R
i
B
2
=
3, M 4,   N
i
=
n ( 4
21
×
=
3 )
+
=
T
i
∴ =
6, R
i
=
B B
2
=
3,   M 4,   N
i
=
36
n (6
×
=
3 )
+
=
If the retransmission buffers are not to be used for deadlock 
recovery,  then  this  lower  limit  for  the  total  buffer  size  is  no 
longer  necessary.  Therefore,  if  we  forego  deadlock  recovery 
support, only three retransmission buffers will be needed per 
VC  for  link  error  correction  (see  Section  3.1),  regardless  of 
the regular transmission buffer size. 
3.2.2 Probing for Deadlock Detection and Recovery 
To  detect  possible  deadlocks,  most  of 
the  previous 
approaches adopted a threshold value of blocked cycles, after 
which the router assumed that the blocked flit was involved in 
a deadlock. This approach is guaranteed to detect all possible 
deadlocks  [28].  However,  it  can  also  give  false  positives, 
where  a  node  assumes  a  deadlock  even  though  the  flit  is 
simply  experiencing  long  blocking  delay.  Increasing  the 
triggering  threshold  value  will  decrease  the  number  of  false 
positives,  but  increasing  the  threshold  value  arbitrarily  will 
cause the number of blocked flits in the network to increase. 
In  order  to  predict  the  most  appropriate  threshold  value,  one 
needs  to  consider  a  multitude  of  parameters,  such  as  the 
network  traffic  among  nodes,  the  traffic  load,  the  routing 
algorithm  and  the  deadlock  recovery  scheme.  This  can  be  a 
daunting feat, since the exploration space is huge. 
To overcome this limitation, we aim to formulate a different 
methodology, which will detect only actual deadlocks without 
any false positives; this optimizes network performance, while 
T D
D
H
T
D D H
TD
H
D
D
T
H
D
D
H
T
D
D
H
DH
D
T
D
: Packet partially sent to the
router buffer.
DH
T
: Packet already in the router
buffer but blocked by a partially
sent packet.
DT
DDH
HT
D
D T
Figure 11. A Worst case example 
eliminating the need to precisely identify an optimal threshold 
value. 
We  propose  a  probing  technique,  whereby  a  compact 
probing signal is sent along the suspected deadlock path after 
a  flit  has  experienced  more  than  a  predefined  number  of 
cycles  (Cthres)  of  blocking.  The  probe  will  check  whether  the 
flit is involved in a real deadlock or not. While the selection of 
Cthres  will  also  affect  network  performance  (as  the  threshold 
value described above), its impact is less pronounced because 
the probing technique will ensure that no action is prematurely 
taken.  In  other  words,  the  threshold  itself  does  not  initiate 
deadlock recovery. The probing technique will first assess the 
situation  to  prevent  the  occurrence  of  any  false  positives. 
Therefore, the value of Cthres need not be precisely calculated; 
its effect on overall network performance will be minimal as 
long as the value chosen is not excessively high. 
The  proposed  probing  technique  detects  a  deadlock  based 
on the following two rules: 
Rule  1:  After  a  flit  experiences  more  than  Cthres  cycles  of 
blocking,  the  router  sends  a  probing  signal  to  the  next  node 
specifying the VC buffer of the suspected flit. 
Rule 2: When a node receives a probing signal, it checks the 
status of the buffer specified in the probing  signal. If the VC 
buffer  is  also  blocked  in  the  current  node  or  the  node  is  in 
deadlock recovery mode, it forwards the probing signal to the 
next node, modifying the VC identifier accordingly. Otherwise, 
it discards the probing signal. 
If the probing signal returns to the original sender node, then 
the latter can safely assume that the flit under investigation is 
involved  in  a  deadlock  configuration;  this  is  because  the 
probing signal can return to the sender only if there is a cyclic 
path  dependency  and  all  intermediate  nodes  also  experience 
blocking (by Rule 2). If increased blocking delay due to a hard 
failure  causes  a  node  to  suspect  deadlock,  the  subsequent 
probing signal will be discarded by the router adjacent to the 
faulty  node,  which  will  redirect  blocked  flits  to  another 
direction  using  an  adaptive  routing  scheme,  breaking  the 
deadlock if any. 
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:28:17 UTC from IEEE Xplore.  Restrictions apply. 
After the probe returns, the sender sends an activation signal 
that  triggers  the  nodes  involved  in  the  deadlock  to  switch  to 
the deadlock recovery mode. The sender node switches to the 
deadlock recovery mode after the activation signal returns. To 
handle  the  case  where  multiple  nodes  in  the  same  deadlock 
configuration send probing signals at the same time, we need 
two more rules: 
Rule 3: A node will discard an activation signal unless it has 
received a probing signal from the same sender node before. 
Rule  4:  If  a  node  receives  a  valid  activation  signal  (as  per 
Rule  3),  while  it  is  waiting  for  its  own  probe  to  return,  it 
switches to the deadlock recovery mode and discards its own 
probe  when  it  finally  returns,  since  the  deadlock  recovery 
mode has already been activated by another node involved in 
the same deadlock configuration. 
To  avoid  incurring  any  additional  overhead  in  supporting 
dedicated  probing  lines,  we  propose  using  a  regular  flit 
transmission  for  the  probing  signal,  which  can  use  the 
retransmission  buffers  in  each  suspected  node  to  propagate. 
Note  that  the  retransmission  buffers  are  empty  in  nodes 
experiencing long blocking. This will ensure that the probing 
signal  itself  will  not  be  blocked  in  an  intermediate  router. 
Figure  3  shows  how  an  incoming  link  can  feed  the 
retransmission  buffer  directly.  Since  the  probing  signal  is  a 
regular  flit,  it  will  also  be  protected  by  the  error  correcting 
blanket, thus ensuring its safe traversal through the network.
4. Handling Soft Errors in Intra-Router Logic 
Until recently, soft errors were tackled within the context of 
memory cells or registers. This has led to the widespread use 
of  error  detection  and  correction  circuits  to  protect  memory 
arrays.  Combinational  logic  circuits,  on  the  other  hand,  have 
been  found  to  be  less  susceptible  to  soft  errors  in  equivalent 
device  technologies  due  to  the  naturally  occurring  logical, 
electrical and latching-window masking effects [31]. However, 
decreasing  feature  sizes  and  higher  operating  frequencies  are 
rapidly  thinning  the  protective  effect  of  these  masking 
phenomena.  As  mentioned  before,  research  has  indicated  an 
exponential  increase  in  the  soft  error  rate  (SER)  per  chip  of 
logic  circuits  in  the  future  [14].  Hence,  it  is  crucial  that 
modern  router  designs  account  for  these  events  to  ensure 
reliable  and  uninterrupted  operation  of  the  on-chip  network. 
The  notion  of  logic  errors  resulting  from  soft  error  upsets  is 
directly  related  to  the  number  of  pipeline  stages  within  the 
router.  While  the  proposed  measures  are  the  same  for  all 
implementations,  the  recovery  process  differs  depending  on 
the  number  of  pipeline  stages  present  (and,  thus,  the  amount 
of  speculation  employed  by  the  architecture).  The  following 
sub-sections  discuss  the  effects  of  soft  errors  on  each  router 
component  along  with  proposed  counter-measures.  The 
recovery process for the different pipeline implementations is 
also  analyzed.  The  latency  overhead  in  the  cases  of  2-stage 
and 1-stage routers assumes successful speculative allocation 
in  the  recovery  phase.  Mis-speculation  will  increase  the 
Routing State Info
Valid
Input VC
Output VC(s)
South VCs
N_1
VC Allocator State Info
Input VC Output VC
N_1
S_2
W_3
East VCs
W_3
E_2
Here we assume that Routing 
Function returns all VCs of a 
single PC (R => P)
Switch Allocator State Info
Output PC
Input PC
Winning 
N
E
S
W
PE
VC
2
2
S
E
Allocation Comparator (AC)
(1)
(2)
(3)
Is Out-VC assigned by 
VA in agreement with 
Routing Function?
Invalid Out-VC?
Duplicate VCs?
Invalid Out-PC?
Duplicate PCs?
Error Flag
(Invalidate last allocation)
Figure 12. The Allocation Comparator (AC) unit. 
The AC unit uses state information from the three router units 
  (RT, SA, and VA) to perform three computations in parallel.
overhead, but mis-speculation occurs during normal operation 
as well and is unpredictable. 
4.1. Virtual Channel Allocator Errors 
The VA, like the routing unit, operates only on header flits. 
All new packets request access to any one of the valid output 
VCs,  returned  by  the  routing  function.  The  VA  arbitrates 
between all those packets requesting the same output VC. The 
VA  maintains  states  of  all  successful  allocations  through  a 
pairing between input VCs and allocated output VCs. It is this 
state  that  effectively  opens  up  the  "wormhole"  for  all 
subsequent flits of the same packet. Soft errors within the VA 
may give rise to four different scenarios: 
(1)  One  input  VC  is  assigned  an  invalid  output  VC:  For 
example, suppose a PC has 3 VCs – designated by 00, 01, 
and 10. A soft error might cause the assignment of invalid 
VC 11. Such an assignment will block further traversal of 
the packet through the network. 
(2)  An unreserved output VC is assigned to two different 
input  VCs:  This  will  lead  to  packet  mixing,  and, 
eventually  packet/flit  loss.  Flits  from  both  packets  will 
follow  the  same  wormhole,  since  they  are  seen  as  one 
packet by the routers. As soon as the tail flit of one of the 
two packets releases the wormhole, any subsequent flits of 
the other packet will essentially be stranded in the network. 
For example, incoming packets from the North and West 
both can be assigned the same output VC in the South. 
(3)  A reserved output VC is assigned to a requesting input 
VC: This case is very similar to case (2) above. The new 
packet  will  erroneously  follow  the  existing  wormhole, 
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:28:17 UTC from IEEE Xplore.  Restrictions apply. 
G
following  a  path  to  a  wrong  destination.  The  same 
consequences will result as above. 
(4)  An erroneous, yet unreserved, output VC is assigned to 
a  requesting  input  VC:  In  this  scenario,  there  are  two 
different types of erroneous output VC assignments: 
(a)  The  wrong  output  VC  belongs  to  the  intended  PC.
This  is  a  benign  case,  since  the  packet  will  still  be 
forwarded  to  the  same  physical  direction  as  originally 
intended. 
(b) The wrong output VC belongs to a PC other than the 
intended  one.  This  case  is  similar  to  the  misdirection 
situation  to  be  analyzed  in  Section  4.2.  It  may  lead  to 
deadlock in deterministic routing algorithms. The solution 
described in Section 4.2 will also protect against this type 
of error. 
The proposed safeguard for VA logic errors is the addition 
of a compact hardware unit, called the Allocation Comparator 
(AC). The proposed AC unit is shown in Figure 12. The unit 
employs purely combinational logic, in the form of XOR gates, 
to compare the RT state entries, SA state entries, and the VA 
state entries. The AC unit performs three types of comparisons 
in parallel, within one clock cycle. It first checks to see if the 
output  VCs  assigned  by  the  VA  unit  are  in  accordance  with 
the output of the routing function (i.e. RT unit). For instance, 
if a soft error causes the VA to erroneously assign an output 
VC  in  the  North  PC,  while  the  RT  unit  had  indicated  the 
assignment of a VC in the South PC, the AC unit will trigger 
an  error  flag,  thus  invalidating  the  VA  allocation  of  the 
previous  clock  cycle.  This  comparison  protects  against 
scenario  (4b)  above.  Secondly,  the  AC  unit  checks  the  VA 
state  info  to  detect  both  invalid  and  duplicate  output  VC 
assignments. Should any of these cases appear, an error flag is 
raised.  This  comparison  safeguards  against  scenarios  (1) 
through  (3)  above.  Finally,  the  AC  unit  checks  for  Switch 
Allocation errors as discussed in the following sub-section. 
The  duration  of  the  recovery  phase  is  independent  of  the 
pipeline  architecture.  In  all  cases  except  the  4-stage  router, 
parallelization  implies  that  the  AC  unit  will  operate  in  the 
same  stage  as  the  crossbar  traversal  (i.e.  after  the  VA 
operation concludes in Figure 2). This means that if an error is 
detected  by  the  AC  unit,  a  NACK  should  be  sent  to  all 
neighboring routers to ignore the previous transmission. Then 
the previous VA allocations are repeated in the current router, 
thus  incurring  single-clock  latency  overhead.  In  a  4-stage 
router, the AC unit will detect the error by the end of stage 3 
(i.e.  before  crossbar 
therefore,  no  erroneous 
transmission  will  occur.  The  latency  delay  is  still  one  clock 
cycle. 
traversal); 
While adding additional hardware increases the overall area 
and  power  consumption  of  the  router,  the  proposed  unit  was 
deliberately architected to be as small and efficient as possible. 
First,  the  number  of  state  entries  to  be  compared  is  equal  to 
PV, where P is the number of input/output ports and V is the 
number of VCs per port. For a typical 5-port mesh NoC router 
(North, East, South, West, PE) with 4 VCs per PC, the number 
of entries is 5x4=20. The size of the entries is minimal, since 
the VC IDs are only a few bits long (e.g. 2 bits for 4 VCs per 