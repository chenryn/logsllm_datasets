dissimilarity with the target sites), it needs to be accurately built; in
particular, the indirect calls among functions should not be ignored.
If the above two issues are not well handled, the distance-based
guiding mechanism for DGF will get hindered and fail in such cases.
2.2 Desired Properties of Directed Fuzzing
As observed from the above example, an ideal DGF should possess
the following desired properties.
2.2.1 P1. The DGF should define a robust distance-based mecha-
nism that can guide the directed fuzzing by avoiding the bias to some
traces and considering all traces to the targets. Different from general
GFs, to reach the targets, there may exist several execution traces
towards the targets. More often than not, a target function could
appear several times in the code and be called even from different
entries of the code. Without any static information as guidance,
during the fuzzing process, the fuzzer knows nothing about the
execution traces that can cover the targets before the targets have
been executed; and even if the targets have already been covered,
the fuzzer does not know whether there are other traces that can
lead to these targets. Hence, the guiding mechanism should help
find all the traces that lead to the targets — taking Fig. 2 as an
example, in the AFL fuzzing process, trace ⟨a, b, c, d,T , Z⟩ may not
be ever exercised by the existing inputs due to the existence of a
strong precondition before a. Hence, the guiding mechanism could
provide the knowledge of all possible traces leading to targets and
guide the mutation towards it via gradually reducing the distance.
However, for DGF, awareness of all possible traces towards the
targets is not enough: the distance to the targets for all traces should
be properly calculated so that all traces reachable to the targets
will be assigned more energy compared to other traces. For Fig. 2,
aebTcdfZT is the target and we would like to check the functionality of T 1.
Intuitively, traces ⟨a, e,T , Z⟩ and ⟨a, b, c, d,T , Z⟩ should be treated
without bias as both of them can lead to the target site, while
⟨a, e, f , Z⟩ should be less important as it misses the target site.
2.2.2 P2. The DGF should strike a balance between overheads and
utilities in static analysis. Effective static analysis can benefit the
dynamic fuzzing procedure in two aspects: 1) In real world C/C++
programs, there are indirect function calls (e.g., passing a function
pointer as a parameter in C, or using function objects and pointers
to member functions in C++). In the presence of indirect calls, call
sites cannot be observed directly from the source code or binary
instructions. So the trade-offs between overheads and utilities need
to be made for analyzing them. 2) Not all call relations should be
treated equally. For example, some functions occur multiple times
in its calling functions, implying that they have higher chance to
be called at runtime. From the static analysis perspective, we need
to provide a way to distinguish these scenarios. As to function level
distances between functions that have immediate calling relations, it
is intuitive that callees called in multiple times in different branches
should be “closer” to the caller.
To sum up, taking Fig. 2 as an example, the desired design for
the DGF is: 1) if function a (transitively) calls T in an indirect
way (i.e., one or more calls in the chain a → b → c → d → T
are through function pointers), the static analysis should capture
such indirect calls, otherwise the distance from a to T will be not
available (i.e., treated as unreachable). 2) if the callee appears in
more different branches and occurs more times in its caller, a smaller
distance should be given since it may have more chance of being
called for reaching the target(s). However, modeling the actual
branch conditions in static phrase is impractical due to the inherent
limitations of static analysis. For example, given a nontrivial code
segment, it is hard to predict whether the true branch of a predicate
will be executed more often than its false branch during runtime. On
the other hand, tracking symbolic conditions dynamically would
be too time costly in a grey-box fuzzing setting.
2.2.3 P3. The DGF should select and schedule the seeds to reach
target sites rapidly. AFL determines how many new inputs should
be generated (i.e., “energy”) from a test seed to improve the fuzzing
effectiveness (i.e., increase the coverage); this is termed “power
scheduling” in [6, 7]. In directed fuzzing, the goal of fuzzing is not
to reach the upper-limit of coverage as fast as possible, but reach the
particular targets as fast as possible. Hence, power scheduling in
DGF should determine how many new inputs should be generated
from a test seed in order to get a new mutated input that leads to
the target sites [6]. Similarly, the seed prioritization in DGF is to
determine an optimized fuzzing order of test seeds to reach target
sites as fast as possible. Both of them can be guided by the distance-
based mechanism which measures the affinity between the current
seed to the target sites.
For power scheduling, the desired design is that the seed trace
with a smaller distance to targets should be assigned more energy
for fuzzing, as the trace closer to the target sites gets better chance
1If we know previously that only the traces that involve d and T may cause crashes,
we can set both d and T as the target sites.
to reach there. Therefore, ⟨a, e,T , Z⟩ should be allocated with sim-
ilar energy with ⟨a, b, c, d,T , Z⟩, and ⟨a, e, f , Z⟩ should have less
energy than the previous two. For seed prioritization, seeds that have
smaller distance (“closer”) to the targets should be fuzzed earlier
in subsequent mutations. Therefore, ⟨a, e,T , Z⟩ and ⟨a, b, c, d,T , Z⟩
should be put ahead of ⟨a, e, f , Z⟩.
2.2.4 P4. The DGF should adopt an adaptive mutation strategy
when the seeds cover the different program states. GFs usually ap-
ply different mutations, such as bitwise flip, byte rewrite, chunk
replacement, to generate new test seeds from the existing one. In
general, these mutators can be categorized into two levels: fine-
grained mutations (e.g., bitwise flip) and coarse-grained mutations
(e.g., chunk replacement). Although there is no direct evidence that
fine-grained mutations will likely preserve the execution traces, it
is widely accepted that a coarse-grained random mutation has a
high chance to change the execution trace greatly. Therefore, the
desired design is that when a seed has already reached the target
sites (including target lines, basic blocks or functions), it should be
given less chances for coarse-grained mutations.
For the example in Fig. 2, consider the case where the DGF has
already reached the target function via trace ⟨a, b, c, d,T , Z⟩, but
crash is not triggered yet. Now, the DGF should allocate less chances
for coarse-grained mutations for the input of ⟨a, b, c, d,T , Z⟩. Mean-
while, if DGF has just started up and ⟨a, b, c, d,T , Z⟩ has not been
reached yet, then the DGF should give more chances for coarse-
grained mutations.
2.3 AFLGo’s Solution
In this section, we evaluate the solution of AFLGo against the
four desired properties to demonstrate the significances of these
properties as well as some useful concepts in DGF.
For P1. For Fig. 2, based on the distance formula defined in
AFLGo the trace distances are: ds(abcdT Z) = (2 + 3 + 2 + 1 + 0)/5 =
1.6, ds(aeT Z) = (2 + 1 + 0)/3 = 1 and ds(ae f Z) = (2 + 1)/2 = 1.5 2.
Given these three execution traces, the energy assigned to them will
be ⟨a, e,T , Z⟩ > ⟨a, e, f , Z⟩ > ⟨a, b, c, d,T , Z⟩. This is problematic:
the normal trace ⟨a, e,T , Z⟩ is overemphasized; the crashing trace
⟨a, b, c, d,T , Z⟩ is however considered the least important, even less
important than the trace ⟨a, e, f , Z⟩ that fails to reach the target T .
For P2. AFLGo only considers the explicit call graph information.
As a result, all function pointers are treated as external nodes which
are ignored during distance calculation. This means that, in an
extreme case, if the target function is called via a function pointer,
its distance from the actual caller is undefined. For example, in Fig. 2,
if d and e callT via function pointers, both d and e will be mistakenly
considered unreachable to T ; consequently, all nodes except for T
will be considered unreachable to T . Therefore essentially there is
no directedness in such a case.
Besides, AFLGo counts the same callee in its callers only once,
and it does not differentiate multiple call patterns between the caller
and callee (see §4.2). The function level distance is calculated on
the call graph with the Dijkstra shortest path, assuming the weight
of two adjacent nodes (functions) in the call graph always to be 1,
which will distort the distance calculation.
2In fact, AFLGo calculates the trace distance at the basic block level with harmonic
mean of the accumulative distance; nevertheless, the essential idea is the same.
Figure 3: Approach Overview of Hawkeye
For P3. AFLGo applies a simulated annealing based power
scheduler: it favors those seeds that are closer to the targets by
assigning more energy to them for mutation; the applied cooling
schedule initially assigns smaller weight on the effect of “distance
guidance”, until it reaches the “exploitation” phrase. It solves the
“exploration vs exploitation” problem [8] and mitigates the impre-
cision issue brought by the statically calculated basic block level
distance. In our opinion, this is an effective strategy. The problem
is that there is no prioritization procedure so the newly generated
seeds with smaller distance may wait for a long to be mutated.
For P4. The mutation operators of AFLGo come from AFL’s two
non-deterministic strategies: 1) havoc, which does purely randomly
mutations such as bit flips, chunk replacement, etc; 2) splice, which
generates seeds from some random byte parts of two existing seeds.
Notably, during runtime AFLGo excludes all the deterministic mu-
tation procedures and relies purely on the power scheduling on
havoc/splice strategies. The randomness of these two strategies can
indeed favor those with smaller distances to the targets. However,
it may also destroy the existing seeds that are close to the targets.
In fact, some subtle vulnerabilities can only be reached with some
special preconditions. In reality, an incomplete fix may still leave
some concern cases to be vulnerable; for example, CVE-2017-15939
is caused by an incomplete fix for CVE-2017-15023. Hence, AFLGo
lacks the adaptive mutation strategies, which will mutate arbitrarily
even when the current seeds are close to the targets enough.
Summary. Taking AFLGo as example, we can summarize the
following suggestions to improve DGFs:
(1) For P1, a more accurate distance definition is needed to retain
trace diversity, avoiding the focus on short traces.
(2) For P2, both direct and indirect calls need to be analyzed; vari-
ous call patterns need to be distinguished during static distance
calculation.
(3) For P3, a moderation to the current power scheduling is re-
quired. The distance-guided seed prioritization is also needed.
(4) For P4, the DGF needs an adaptive mutation strategy, which
optimally applies the fine-grained and coarse-grained mutations
when the distance between the seed to the targets is different.
3 APPROACH OVERVIEW
In this section, we briefly introduce the workflow of our proposed
approach, named Hawkeye. An overview of Hawkeye is given in
Fig. 3, which consists of two major components, i.e., static analysis
and fuzzing loop.
3.1 Static Analysis
The inputs of static analysis are the program source code and the tar-
get sites (i.e., the lines of code that the fuzzer is directed to reach). We
derive the basic blocks and functions where the target sites reside in,
and call them target basic blocks and target functions, respectively.
The main output of static analysis is the instrumented program bi-
nary with the information of basic block level distance.
First, we precisely construct the call graph (CG) of the target pro-
gram based on the inclusion-based pointer analysis [3] to include all
possible calls. Besides, for each function, we construct the control
flow graph (CFG) (§4.1).
Second, we compute several utilities that are used to facilitate
the directedness in Hawkeye based on CG and CFG (§4.3).
(1) Function level distance is computed based on CG by aug-
menting adjacent-function distance (§4.2). This distance is uti-
lized to calculate the basic block level distance. It is also used
during the fuzzing loop to calculate the covered function simi-
larity (§4.4).
(2) Basic block level distance is computed based on the function
level distance, together with the CG and the functions’ CFGs.
This distance is statically instrumented for each basic block that
is considered to be able to reach one of the target sites. During
the fuzzing loop, it is also used to calculate the basic block trace
distance (§4.4).
(3) Target function trace closure is computed for each target
site according to the CG to obtain the functions that can reach
the target sites. It is used during the fuzzing loop to calculate
the covered function similarity (§4.4).
Finally, the target program is instrumented to keep track of the
edge transitions (similar to AFL), the accumulated basic block trace
distance (similar to AFLGo), and the covered functions.
3.2 Fuzzing Loop
The inputs of fuzzing loop are the instrumented program binary, the
initial test seeds, the target sites as well as the information of function
level distance and target function trace closure. The outputs of fuzzing
loop are the test seeds that cause abnormal program behaviors such
as crashes or timeouts.
During fuzzing, the fuzzer selects a seed from a priority seed
queue. The fuzzer applies a power scheduling against the seed
with the goal of giving those seeds that are considered to be “closer”
Program Source CodeTarget SitesInstrumented Program BinaryGraph ConstructionControl Flow GraphCall GraphDirectedness Utility ComputationBasic Block Level DistanceFunction Level DistanceCompilation and InstrumentationPower SchedulingAdaptive MutationSeed QueueSeed SelectionSeedEnergyNew SeedsSeed PrioritizationStatic AnalysisFuzzing LoopTarget Function Trace ClosureInitial Seedsto the target sites more mutation chances, i.e., energy (§4.4). Specif-
ically, this is achieved through a power function, which is a combi-
nation of the covered function similarity and the basic block trace
distance. For each newly generated test seed during mutation, after
capturing its execution trace, the fuzzer will calculate the covered
function similarity and the basic block trace distance based on the
utilities (§3.1). For each input execution trace, its basic block trace
distance is calculated as the accumulated basic block level distances
divided by the total number of executed basic blocks; and its cov-
ered function similarity is calculated based on the overlapping of
current executed functions and the target function trace closure, as
well as the function level distance.
After the energy is determined, the fuzzer adaptively allocates
mutation budgets on two different categories of mutations accord-
ing to mutators’ granularities on the seed (§4.5). Afterwards, the
fuzzer evaluates the newly generated seeds to prioritize those that
have more energy or that have reached the target functions (§4.6).
4 METHODOLOGY
In this section, we will elaborate the key components in Fig. 3
featuring the four desired properties.
4.1 Graph Construction
To calculate the accurate distance from a test seed to the oracle seed
executing the target sites, we first build up the CG and CFG, then
combine them to construct the final inter-procedural CFG. Note
that CG is used to compute the function level distance in §4.2 and
§4.3, CFG together with CG (i.e., inter-procedural CFG) is used to
compute the basic block distance in §4.3.
To identify the indirect call in call graph, we propose to apply the
inclusion-based pointer analysis [3] against the function pointers
of the whole program. The core idea of this algorithm is to translate
the input program with statements of the form p := q to constraints
of the form “q’s points-to set is a subset of p’s points-to set”. Es-
sentially, the propagation of the points-to set is applied with four
rules namely address-of, copy, assign, dereference. This analysis is
context-insensitive and flow-insensitive, meaning that it ignores
both the calling context of the analyzed functions and the statement
ordering inside functions, and eventually only computes a single
points-to solution that holds for all the program points. Usually, a
fixed point of the points-to sets will be reached at the end of the
analysis. Among these, points-to sets of the function pointers inside
the whole program are calculated, resulting in a relatively precise
call graph including all the possible direct and indirect calls. The
complexity of this pointer analysis is Θ(n3). The reason that we do
not apply context-sensitive or flow-sensitive analyses lies in the
fact that they are computationally costly and not scalable to large
projects. Despite that, our call graph is still much more precise than
the one generated by LLVM’s builtin APIs, which does not contain
any explicit nodes that represent indirect calls.
The control flow graph of each function is generated based on
LLVM’s IR. The inter-procedure flow graph is constructed by collect-
ing the call sites in all the CFGs and the CG of the whole program.
By applying these static analyses, we achieve P2.
i f
void f a ( int
( i > 0 )
fb ( i ) ;
} else {
fb ( i ∗ 2 ) ;
f c ( ) ;
}
}
{
i )
{
{
i )
{
i f
void f a ( int
( i > 0 )
fb ( i ) ;
fb ( i ∗ 2 ) ;
} else {
f c ( ) ;
}
}
(a)
(b)
Figure 4: An example illustrating different call patterns
4.2 Adjacent-Function Distance Augmentation
To achieve P1, we propose to implement a lightweight static analy-
sis that considers the patterns of the (immediate) call relation based
on the generated call graph. As discussed in §2.2.2, under different
context, the distances from the calling function to the immediately
called function may not be exactly the same. Given functions fa,
fb, fc, there may exist several different call patterns in the call
graph. For example, in Fig. 4a and Fig. 4b, there are calls fa → fb
and fa → fc in both cases. However, in Fig. 4a fa is bound to call
fb (since fb appears in both if and else branches in fa), but not
necessary to call fc; in Fig. 4b, both fb and fc are not necessary
to be called by fa. From a probability perspective, we would think
that in both cases the distance from fa to fb should be smaller than
the distance from fa to fc, and the distance from fa to fb in Fig. 4a
should be smaller than that in Fig. 4b.
Therefore, we propose two metrics to augment the distance that
is defined by immediate calling relation between caller and callee.
(1) Call site occurrences CN of a certain callee for a given caller.
More occurrences of callee could incur more chance that callee
will be dynamically executed with more different (actual) pa-
rameters, and in return the distance between the caller to the