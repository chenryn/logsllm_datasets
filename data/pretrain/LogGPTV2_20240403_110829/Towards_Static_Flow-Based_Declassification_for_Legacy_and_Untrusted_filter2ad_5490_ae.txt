Then, a “safe” node is a node whose both data and control
dependencies are safe, i.e. a node which is both DDS and
CDS.
safe(n, g, d) ≡ dds(n, g, d) ∧ cds(n, g, d)
Finally, we can present the deﬁnition of a “valid” graph,
which holds for a graph if all its outputs are safe.
Deﬁnition 13 (Graph Validity). An expression graph g is
marked as valid with respect to a policy d if the following is
true:
valid (g, d) ≡ ∀(γ, out) ∈ nodes(g) : safe(nγ, g, d)
We say g is d-valid if valid(g,d).
With the matching mechanism deﬁned, we can present its
theorem of soundness. It states that if a node n in the graph
simulates a node nd in the policy graph, then the set of
expressions possibly held by n is a subset of the set held
by nd in the policy. Once again, proof is omitted.
Theorem 14 (Soundness of the matching mechanism). For
a program’s expression graph g and a policy d, the following
relation holds:
(∀(α, nd
) ∈ uni(d), ∀w : nα
n)
∀n ∈ nodes(g), nd
⇒ expg
g,d nd
∈ nodes(d) :
(n) ⊆ expd
(nd
n ∼
)
We use ∼
g,d to denote the largest policy simulation (i.e. the
union of all of them) between information path g and policy
graph d.
Next, we present a few supporting deﬁnitions for validating
a program’s expression graph. First, we deﬁne when a node
n in an information path g is “safe” in terms of data depen-
dencies. This is the case if it matches some ﬁnal node of the
declassiﬁcation policy or all its parents are already safe; here
fnodes(d) returns the sets of ﬁnal vertices on policy graph d.
ddsg
(n, d) ≡ (∃nf
g,d nf
∈ fnodes(d) : n ∼
) ∨
(∀(α, in) ∈ nodes(g), w : α w−→∗
⇒ ∃n(cid:2) ∈ nodes(g) : α w(cid:2)−→
ddsg
(n(cid:2), d))
n
n(cid:2) w(cid:2)(cid:2)−−→
∗
∗
n ∧
Now we deﬁne a data dependency safe node, as a node
in which all maximal information paths that reach it are data
dependency safe. Function dds deﬁnes this relation.
dds(n, g, d) ≡ ∀p ∈ mip(n, g) : ddsp
(n, d)
Similarly, a node is “control dependency safe” (CDS) if
all nodes on which it has control dependencies, directly or
indirectly, are DDS. For this deﬁnition,
the whole graph
102
For the next theorem, we deﬁne the notion of a “public”
expression, in terms of a declassiﬁcation policy. The relation
is deﬁned below.
public(e, d) ≡ (∃nf
∈ fnodes(d) : e ∈ expd
(nf
)) ∨
(e = f (e1, . . . , en
public(e1, d) ∧ · · · ∧ public(en, d))
)∧
With this, we can present the theorem of safety between
process and policy, demonstrating that if the corresponding
graph of a program satisﬁes a policy, then the expressions on
the process will also satisfy it. This theorem is a consequence
of theorems 9 and 14.
Theorem 15 (Safety between process and policy). For a
program C0, environment π0 and t a run in Run(C0, π0),
any conﬁguration (cid:6)C, σ, π(cid:7) ∈ t, the graph g = G(C0), and a
policy d, the following relations hold:
(i )
(ii )
(x) is deﬁned ∧
∀x ∈ Var : Eσ
dds(nx, g, d) ⇒ public(Eσ
∀γ ∈ Out : Oσ
dds(nγ, g, d) ⇒ ∀e ∈ Oσ
(γ) is deﬁned ∧
(x), d)
(γ) : public(e, d)
(iii) ∀ρ ∈ Var + IO : PC σ
(ρ) is deﬁned ∧
cds(nρ, g, d) ⇒ ∀e ∈ PC σ
(ρ) : public(e, d)
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 04:11:48 UTC from IEEE Xplore.  Restrictions apply. 
(i) states that if a variable in the program has its corre-
sponding node in the graph (which is guaranteed to exist by
Theorem 9) being data dependency safe, then the expression
held by that variable in the process is safe (i.e. allowed by the
policy); (ii) states that if an output channel in the program has
its corresponding node in the graph being data dependency
safe, then all expressions sent to it in the process are safe;
ﬁnally, (iii) states that if a variable or I/O channel has a
corresponding node in the graph being control dependency
safe, then all conditional expressions of the variable (or I/O
channel) in the process are safe.
V. SECURITY PROPERTY
In this section we deﬁne our reference security property
called Policy Controlled Release. It is an “end-to-end” property
in the sense that it bounds the knowledge that an attacker can
gain by observing information released on output channels
during any collection of runs. Our property closely follows
the Conditional Gradual Release (CGR) given by Banerjee et
al. [12], though our variant differs from the original deﬁnition
in several important respects, being simpler and independent
of characteristics of the program’s execution. CGR itself is
a variant of the Gradual Release [19] property. To simplify
the discussion, we assume that information obtained from all
the input channels is conﬁdential and can be modiﬁed only
by the target machine (on which the program runs). Reading
from an input channel is not visible to an outsider. On the
other hand, any information placed on the output channels
is regarded as public. Releasing information from the secret
input channels to the public output channels is permitted only
according to declassiﬁcation policies. Recall that we have also
assumed that the input channels are non-interactive in the sense
that reading data from one input channel, has no effect on
the values obtained from other input channels. We discuss the
relaxation of these assumptions in Section VIII.
Two environments are said to be d-Equivalent if the values
of the declassiﬁable expressions are the same in both the
environments. Evaluating the expressions represented by ﬁnal
nodes in a policy (see V in Section III) gives the actual values
that can be declassiﬁed.
Deﬁnition 16 (d-Equivalent Environments (≈
d)). Given a
declassiﬁcation policy d, two environments π1 and π2 are said
to be d-equivalent, π1 ≈
∈ fnodes(d) . ∀e ∈
expd
Lemma 17. Given a declassiﬁcation policy d, two environ-
ments π1 and π2, if π1 ≈
d π2, then for all e ∈ Exp, if
public(e, d), then V (e, π1) = V (e, π2).
) . V (e, π1) = V (e, π2).
(nf
d π2, if ∀nf
By observing the value of declassiﬁable expressions, one
can learn something about the actual environment. In particular
one learns that it must belong to a given class of d-equivalent
environments. The policy d is correctly enforced if no further
information can be learned.
Deﬁnition 18 (Revealed Knowledge (R)). Given a declassi-
ﬁcation policy d and an environment π we deﬁne R(π, d) =
103
{π(cid:2)|π ≈
d π(cid:2)}.
Note that the smaller the set R(π, d) is, the more infor-
mation about π is permitted to be revealed. The revealed
knowledge represents a bound on the amount of information
that may be revealed by a program that complies with policy d.
The next step is to deﬁne the amount of information a program
actually reveals.
The behaviour of a program that an observer can see is
the sequence of outputs it generates. Thus an observer cannot
distinguish two environments if their runs produce the same
sequence of visible output actions.
Deﬁnition 19 (Observed Knowledge (K)). Deﬁne K(π, C)
by K(π, C) = {π(cid:2)|Run(C, π) ≡out Run(C, π(cid:2))}.
Our security property, Policy Controlled Release (PCR),
states that the knowledge obtained from observing the program
is bounded by the information released by the declassiﬁcation
policies.
Deﬁnition 20 (Policy Controlled Release (PCR)). A program
C satisﬁes policy controlled release for policy d if for all
environments π : K(π, C) ⊇ R(π, d).
VI. SOUNDNESS OF THE ANALYSIS
The following theorem shows that if our analysis says that a
program is secure, then the program satisﬁes the PCR property.
Theorem 21. For any terminating program C and a declassiﬁ-
cation policy d, if valid(G(C), d) then the program C satisﬁes
PCR.
Proof: Lemma 24 below implies that the executions of a d-
valid program in two d-equivalent environments can be linked
in a way that guarantees they will result in the same runs.
This implies that for all environments π,π(cid:2) if π(cid:2) ∈ R(π, d)
then also π(cid:2) ∈ K(π, C).
The proof of the theorem relies on a linking between runs,
the existence of which is stated by Lemma 24. First we deﬁne
the properties of this linking and the intuition behind how the
linking works and why it must exist. The linking is inspired by
the proof of soundness in Banerjee et al. [12]. However, our
proof is simpler because we do not need to consider the exact
path taken by the program to reach a particular state – our d-
equivalence property together with our ﬂow-sensitive approach
to check validity ensures that both the runs take the same
branches for paths leading to the output actions. Additionally,
the proof is termination-insensitive. This means that for the
proofs to go through, we assume that the loops, in which the
conditional expression is non-declassiﬁable, terminate.
The core idea behind the linking is that a program can be in
one of two distinct conﬁdentiality levels: a level L (low, pub-
lic) in which it may do output or a level H (high, secret) where
it may behave differently depending on non-declassiﬁable
information. We say that C is a compositional statement if
C is of the form C1; C2, otherwise C is non-compositional.
Note that any program can be written in the form C1; . . . ; Cn
(n ≥ 1) with Ci non-compositional statements. Here we call
Authorized licensed use limited to: Tsinghua University. Downloaded on March 22,2021 at 04:11:48 UTC from IEEE Xplore.  Restrictions apply. 
C1 the active command of C, denoted Λ(C). Given a policy
d, we type all non-compositional statements contained in C
as follows:
other requirements allow us to inductively build the correspon-
dence relation Q between runs of a program in d-equivalent
environments.
1) Γ(skip) = H.
2) If Ci
is a conditional statement
(if or while)
whose condition c is not marked as declassifyable,
i.e. ¬safe((c, var), G(C), d) then Γ(Ci
) = H and also
all statements nested inside Ci, directly or indirectly, are
typed H.
3) If Ci is a conditional statement whose condition is de-
classifyable we repeat the procedure for the statement(s)
in the body in the same way.
4) Each non-compositional statement not typed H accord-
ing to the above rules is typed L.
The type of a compositional statement C is the type of its
active command Λ(C). We deﬁne the low continuation of C =
C1; . . . ; Cn, denoted L-cont(C) as the statement Ci
; . . . ; Cn
where i is the ﬁrst index for which Ci is not typed high.
In the L level the program will behave ‘the same’ in two
d-equivalent environments. The next deﬁnitions capture this
notion of ‘the same’. We ﬁrst consider the states that a program
could reach.
Deﬁnition 22 (Compatible States ((cid:27))). Two states σ1 and
σ2 are said to be compatible for program C and policy d,
denoted σ1 (cid:27)(C,d) σ2, if the following conditions hold:
(α) = Iσ2
1) ∀α ∈ In : cds((α, in), G(C), d) ⇒ (Iσ1
(α) ∧
PC σ1
(α) = PC σ2
(α)).
2) ∀x ∈ Var : cds((x, var), G(C), d) ⇒ (Eσ1
(x) =
Eσ2
(x) ∧ PC σ1
(x) = PC σ2
(x)).
If the control dependencies of a variable or channel are
declassiﬁable then they cannot be altered/read from by the
program in a H level and as L behaviour has to be the same,
they cannot differ between two d-equivalent environments.
Deﬁnition 23 (Correspondence between two runs (Q)). Let
C be a program, π and π(cid:2) be environments, and d be a
policy. Let t be a prerun of Run(C, π) and t(cid:2) be a prerun
of Run(C, π(cid:2)) with (cid:28)t(cid:28) = n and (cid:28)t(cid:2)(cid:28) = m. A correspondence
between t and t(cid:2) is a relation Q ⊆ {1, . . . , n} × {1, . . . , m}
such that 0 Q 0 and for all i, j such that i Q j, letting
j, π(cid:2)(cid:7)(cid:7), the following
ti
conditions hold:
= (cid:6)oi, (cid:6)Ci, σi, π(cid:7)(cid:7) and t(cid:2)
j, (cid:6)C (cid:2)
= (cid:6)o(cid:2)
j, σ(cid:2)
j
Lemma 24. Given a program C and a declassiﬁcation policy
d, satisfying valid(G(C), d), and given two environments π
and π(cid:2) satisfying π ≈
d π(cid:2), such that the program C terminates
under the environments π and π(cid:2). Let ω = (cid:6)C, σinit , π(cid:7), ω(cid:2) =
(cid:6)C, σinit , π(cid:2)(cid:7), and S a (partial) run starting from ω then there
is a partial run T starting from ω(cid:2) that corresponds to ω.