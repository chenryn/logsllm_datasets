try URL.setResourceValue(true, forKey:NSURLIsExcludedFromBackupKey)
success = true
} catch let error as NSError {
success = false
print("Error excluding \(URL.lastPathComponent) from backup \(error)");
}
return success
}
Dynamic Analysis
In order to test the backup, you obviously need to create one first. The most common way to create a backup of an
iOS device is by using iTunes, which is available for Windows, Linux and of course macOS. When creating a backup
via iTunes you can always only backup the whole device and not select just a single app. Make sure that the option
"Encrypt local backup" in iTunes is not set, so that the backup is stored in cleartext on your hard drive.
After the iOS device has been backed up through iTunes you need to retrieve the file path of the backup, which are
different locations on each OS. The official Apple documentation will help you to locate backups of your iPhone, iPad,
and iPod touch.
When you want to navigate to the iTunes backup folder up to High Sierra you can easily do so. Starting with macOS
Mojave you will get the following error (even as root):
$ pwd
/Users/foo/Library/Application Support
$ ls -alh MobileSync
ls: MobileSync: Operation not permitted
This is not a permission issue of the backup folder, but a new feature in macOS Mojave. Solve this problem by
granting full disk access to your terminal application by following the explanation on OSXDaily.
Before you can access the directory you need to select the folder with the UDID of your device. Check the section
"Getting the UDID of an iOS device" in the "iOS Basic Security Testing" chapter on how to retrieve the UDID.
Once you know the UDID you can navigate into this directory and you will find the full backup of the whole device,
which does include pictures, app data and whatever might have been stored on the device.
Review the data that's in the backed up files and folders. The structure of the directories and file names is obfuscated
and will look like this:
$ pwd
/Users/foo/Library/Application Support/MobileSync/Backup/416f01bd160932d2bf2f95f1f142bc29b1c62dcb/00
$ ls | head -n 3
000127b08898088a8a169b4f63b363a3adcf389b
0001fe89d0d03708d414b36bc6f706f567b08d66
000200a644d7d2c56eec5b89c1921dacbec83c3e
Therefore it's not straightforward to navigate through it and you will not find any hints of the app you want to analyze in
the directory or file name. What you can do is use a simple grep to search for sensitive data that you have keyed in
while using the app before you made the backup, for example the username, password, credit card data, PII or any
389
Data Storage on iOS
data that is considered sensitive in the context of the app.
$ ~/Library/Application Support/MobileSync/Backup/
$ grep -iRn "password" .
If you can find such data it should be excluded from the backup as described in the Static Analysis chapter, or
encrypted properly by using the Keychain or not stored on the device in the first place.
In case you need to work with an encrypted backup, the following Python scripts (backup_tool.py and
backup_passwd.py) will be a good starting point. They might not work with the latest iTunes versions and might need
to be tweaked.
Testing Auto-Generated Screenshots for Sensitive Information (MSTG-
STORAGE-9)
Overview
Manufacturers want to provide device users with an aesthetically pleasing effect when an application is started or
exited, so they introduced the concept of saving a screenshot when the application goes into the background. This
feature can pose a security risk because screenshots (which may display sensitive information such as an email or
corporate documents) are written to local storage, where they can be recovered by a rogue application with a sandbox
bypass exploit or someone who steals the device.
Static Analysis
While analyzing the source code, look for the fields or screens that take or display sensitive data. Use UIImageView to
determine whether the application sanitizes the screen before being backgrounded.
The following is a sample remediation method that will set a default screenshot:
@property (UIImageView *)backgroundImage;
- (void)applicationDidEnterBackground:(UIApplication *)application {
UIImageView *myBanner = [[UIImageView alloc] initWithImage:@"overlayImage.png"];
self.backgroundImage = myBanner;
[self.window addSubview:myBanner];
}
This sets the background image to overlayImage.png whenever the application is backgrounded. It prevents sensitive
data leaks because overlayImage.png will always override the current view.
Dynamic Analysis
Navigate to an application screen that displays sensitive information, such as a username, an email address, or
account details. Background the application by hitting the Home button on your iOS device. Connect to the iOS device
and navigate to the following directory (which may be different for iOS versions below 8.0):
/var/mobile/Containers/Data/Application/$APP_ID/Library/Caches/Snapshots/
Screenshot caching vulnerabilities can also be detected with Needle. This is demonstrated in the following Needle
excerpt:
[needle] > use storage/caching/screenshot
[needle][screenshot] > run
[V] Creating timestamp file...
[*] Launching the app...
390
Data Storage on iOS
[*] Background the app by hitting the home button, then press enter:
[*] Checking for new screenshots...
[+] Screenshots found:
[+] /private/var/mobile/Containers/Data/Application/APP_ID/Library/Caches/Snapshots/app_name/B75DD942-76D1-4B
PI:EMAIL
[+] /private/var/mobile/Containers/Data/Application/APP_ID/Library/Caches/Snapshots/app_name/downscaled/12B93
PI:EMAIL
[+] Retrieving screenshots and saving them in: /home/user/.needle/output
If the application caches the sensitive information in a screenshot, the app fails this test.
The application should show a default image as the top view element when the application enters the background, so
that the default image will be cached and not the sensitive information that was displayed.
Testing Memory for Sensitive Data (MSTG-STORAGE-10)
Overview
Analyzing memory can help developers to identify the root causes of problems such as application crashes. However,
it can also be used to access to sensitive data. This section describes how to check process' memory for data
disclosure.
First, identify the sensitive information that's stored in memory. Sensitive assets are very likely to be loaded into
memory at some point. The objective is to make sure that this info is exposed as briefly as possible.
To investigate an application's memory, first create a memory dump. Alternatively, you can analyze the memory in
real time with, for example, a debugger. Regardless of the method you use, this is a very error-prone process
because dumps provide the data left by executed functions and you might miss executing critical steps. In addition,
overlooking data during analysis is quite easy to do unless you know the footprint of the data you're looking for (either
its exact value or its format). For example, if the app encrypts according to a randomly generated symmetric key,
you're very unlikely to spot the key in memory unless you find its value by other means.
Therefore, you're better off starting with static analysis.
Static Analysis
Before looking into the source code, checking the documentation and identifying application components provide an
overview of where data might be exposed. For example, while sensitive data received from a backend exists in the
final model object, multiple copies may also exist in the HTTP client or the XML parser. All these copies should be
removed from memory as soon as possible.
Understanding the application's architecture and its interaction with the OS will help you identify sensitive information
that doesn't have to be exposed in memory at all. For example, assume your app receives data from one server and
transfers it to another without needing any additional processing. That data can be received and handled in encrypted
form, which prevents exposure via memory.
However, if sensitive data does need to be exposed via memory, make sure that your app exposes as few copies of
this data as possible for as little time as possible. In other words, you want centralized handling of sensitive data,
based on primitive and mutable data structures.
Such data structures give developers direct access to memory. Make sure that this access is used to overwrite the
sensitive data with dummy data (which is typically zeroes). Examples of preferable data types include char [] and
int [] , but not NSString or String . Whenever you try to modify an immutable object, such as a String , you
actually create a copy and change the copy.
391
Data Storage on iOS
Avoid Swift data types other than collections regardless of whether they are considered mutable. Many Swift data
types hold their data by value, not by reference. Although this allows modification of the memory allocated to simple
types like char and int , handling a complex type such as String by value involves a hidden layer of objects,
structures, or primitive arrays whose memory can't be directly accessed or modified. Certain types of usage may
seem to create a mutable data object (and even be documented as doing so), but they actually create a mutable
identifier (variable) instead of an immutable identifier (constant). For example, many think that the following results in a
mutable String in Swift, but this is actually an example of a variable whose complex value can be changed
(replaced, not modified in place):
var str1 = "Goodbye" // "Goodbye", base address: 0x0001039e8dd0
str1.append(" ") // "Goodbye ", base address: 0x608000064ae0
str1.append("cruel world!") // "Goodbye cruel world", base address: 0x6080000338a0
str1.removeAll() // "", base address 0x00010bd66180
Notice that the base address of the underlying value changes with each string operation. Here is the problem: To
securely erase the sensitive information from memory, we don't want to simply change the value of the variable; we
want to change the actual content of the memory allocated for the current value. Swift doesn't offer such a function.
Swift collections ( Array , Set , and Dictionary ), on the other hand, may be acceptable if they collect primitive data
types such as char or int and are defined as mutable (i.e., as variables instead of constants), in which case they
are more or less equivalent to a primitive array (such as char [] ). These collections provide memory management,
which can result in unidentified copies of the sensitive data in memory if the collection needs to copy the underlying
buffer to a different location to extend it.
Using mutable Objective-C data types, such as NSMutableString , may also be acceptable, but these types have the
same memory issue as Swift collections. Pay attention when using Objective-C collections; they hold data by
reference, and only Objective-C data types are allowed. Therefore, we are looking, not for a mutable collection, but for
a collection that references mutable objects.
As we've seen so far, using Swift or Objective-C data types requires a deep understanding of the language
implementation. Furthermore, there has been some core re-factoring in between major Swift versions, resulting in
many data types' behavior being incompatible with that of other types. To avoid these issues, we recommend using
primitive data types whenever data needs to be securely erased from memory.
Unfortunately, few libraries and frameworks are designed to allow sensitive data to be overwritten. Not even Apple
considers this issue in the official iOS SDK API. For example, most of the APIs for data transformation (passers,
serializes, etc.) operate on non-primitive data types. Similarly, regardless of whether you flag some UITextField as
Secure Text Entry or not, it always returns data in the form of a String or NSString .
In summary, when performing static analysis for sensitive data exposed via memory, you should
try to identify application components and map where the data is used,
make sure that sensitive data is handled with as few components as possible,
make sure that object references are properly removed once the object containing sensitive data is no longer
needed,
make sure that highly sensitive data is overwritten as soon as it is no longer needed,
not pass such data via immutable data types, such as String and NSString ,
avoid non-primitive data types (because they might leave data behind),
overwrite the value in memory before removing references,
pay attention to third-party components (libraries and frameworks). Having a public API that handles data
according to the recommendations above is a good indicator that developers considered the issues discussed
here.
Dynamic Analysis
392
Data Storage on iOS
Several approaches and tools are available for dumping an iOS app's memory.
On a non-jailbroken device, you can dump the app's process memory with objection and Fridump. To take advantage
of these tools, the iOS app must be repackaged with FridaGadget.dylib and re-signed. A detailed explanation of this
process is in the section "Dynamic Analysis on Non-Jailbroken Devices", in the chapter "Tampering and Reverse
Engineering on iOS".
Objection (No Jailbreak needed)
With objection it is possible to dump all memory of the running process on the device.
(virtual-python3) ➜ objection explore
_ _ _ _
___| |_ |_|___ ___| |_|_|___ ___
| . | . | | | -_| _| _| | . | |
|___|___|_| |___|___|_| |_|___|_|_|
|___|(object)inject(ion) v0.1.0
Runtime Mobile Exploration
by: @leonjza from @sensepost
[tab] for command suggestions
iPhone on (iPhone: 10.3.1) [usb] # memory dump all /Users/foo/memory_iOS/memory
Dumping 768.0 KiB from base: 0x1ad200000 [####################################] 100%
Memory dumped to file: /Users/foo/memory_iOS/memory
After the memory has been dumped, executing the command strings with the dump as argument will extract the
strings.
$ strings memory > strings.txt
Open strings.txt in your favorite editor and dig through it to identify sensitive information.
You can also display the current process' loaded modules.
iPhone on (iPhone: 10.3.1) [usb] # memory list modules
Name Base Size Path
-------------------------------- ----------- ------------------- -------------------------------------------
--------------------------------------
foobar 0x1000d0000 11010048 (10.5 MiB) /var/containers/Bundle/Application/D1FDA1C6
-D161-44D0-BA5D-60F73BB18B75/...
FridaGadget.dylib 0x100ec8000 3883008 (3.7 MiB) /var/containers/Bundle/Application/D1FDA1C6
-D161-44D0-BA5D-60F73BB18B75/...
libsqlite3.dylib 0x187290000 1118208 (1.1 MiB) /usr/lib/libsqlite3.dylib
libSystem.B.dylib 0x18577c000 8192 (8.0 KiB) /usr/lib/libSystem.B.dylib
libcache.dylib 0x185bd2000 20480 (20.0 KiB) /usr/lib/system/libcache.dylib
libsystem_pthread.dylib 0x185e5a000 40960 (40.0 KiB) /usr/lib/system/libsystem_pthread.dylib
libsystem_kernel.dylib 0x185d76000 151552 (148.0 KiB) /usr/lib/system/libsystem_kernel.dylib
libsystem_platform.dylib 0x185e53000 28672 (28.0 KiB) /usr/lib/system/libsystem_platform.dylib
libdyld.dylib 0x185c81000 20480 (20.0 KiB) /usr/lib/system/libdyld.dylib
Fridump (No Jailbreak needed)
To use Fridump you need to have either a jailbroken/rooted device with Frida-server installed, or build the original
application with the Frida library attached instructions on Frida’s site
The original version of Fridump is no longer maintained, and the tool works only with Python 2. The latest Python
version (3.x) should be used for Frida, so Fridump doesn't work out of the box.
393
Data Storage on iOS
If you're getting the following error message despite your iOS device being connected via USB, checkout Fridump with
the fix for Python 3.
➜ fridump_orig git:(master) ✗ python fridump.py -u Gadget
______ _ _
| ___| (_) | |
| |_ _ __ _ __| |_ _ _ __ ___ _ __
| _| '__| |/ _` | | | | '_ ` _ \| '_ \
| | | | | | (_| | |_| | | | | | | |_) |
\_| |_| |_|\__,_|\__,_|_| |_| |_| .__/
| |
|_|
Can't connect to App. Have you connected the device?
Once Fridump is working, you need the name of the app you want to dump, which you can get with frida-ps .
Afterwards, specify the app name in Fridump.
➜ fridump git:(master) ✗ frida-ps -U
PID Name
---- ------
1026 Gadget
➜ fridump git:(master) python3 fridump.py -u Gadget -s
______ _ _
| ___| (_) | |
| |_ _ __ _ __| |_ _ _ __ ___ _ __
| _| '__| |/ _` | | | | '_ ` _ \| '_ \
| | | | | | (_| | |_| | | | | | | |_) |
\_| |_| |_|\__,_|\__,_|_| |_| |_| .__/
| |
|_|
Current Directory: /Users/foo/PentestTools/iOS/fridump
Output directory is set to: /Users/foo/PentestTools/iOS/fridump/dump
Creating directory...
Starting Memory dump...
Progress: [##################################################] 100.0% Complete
Running strings on all files:
Progress: [##################################################] 100.0% Complete
Finished! Press Ctrl+C
When you add the -s flag, all strings are extracted from the dumped raw memory files and added to the file
strings.txt , which is stored in Fridump's dump directory.
References
OWASP Mobile Top 10 2016
M1 - Improper Platform Usage - https://www.owasp.org/index.php/Mobile_Top_10_2016-M1-
Improper_Platform_Usage
M2 - Insecure Data Storage - https://www.owasp.org/index.php/Mobile_Top_10_2016-M2-
Insecure_Data_Storage
OWASP MASVS
394
Data Storage on iOS
MSTG-STORAGE-1: "System credential storage facilities are used appropriately to store sensitive data, such as
user credentials or cryptographic keys."
MSTG-STORAGE-2: "No sensitive data should be stored outside of the app container or system credential
storage facilities."
MSTG-STORAGE-3: "No sensitive data is written to application logs."
MSTG-STORAGE-4: "No sensitive data is shared with third parties unless it is a necessary part of the
architecture."
MSTG-STORAGE-5: "The keyboard cache is disabled on text inputs that process sensitive data."
MSTG-STORAGE-6: "No sensitive data is exposed via IPC mechanisms."
MSTG-STORAGE-7: "No sensitive data, such as passwords or pins, is exposed through the user interface."
MSTG-STORAGE-8: "No sensitive data is included in backups generated by the mobile operating system."
MSTG-STORAGE-9: "The app removes sensitive data from views when moved to the background."
MSTG-STORAGE-10: "The app does not hold sensitive data in memory longer than necessary, and memory is
cleared explicitly after use."
CWE
CWE-117 - Improper Output Neutralization for Logs
CWE-200 - Information Exposure
CWE-311 - Missing Encryption of Sensitive Data
CWE-312 - Cleartext Storage of Sensitive Information
CWE-359 - "Exposure of Private Information ('Privacy Violation')"
CWE-522 - Insufficiently Protected Credentials
CWE-524 - Information Exposure Through Caching
CWE-532 - Information Exposure Through Log Files
CWE-534 - Information Exposure Through Debug Log Files