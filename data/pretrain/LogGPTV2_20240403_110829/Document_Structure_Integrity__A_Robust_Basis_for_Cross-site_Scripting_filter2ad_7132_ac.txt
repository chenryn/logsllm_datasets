4.1 Serialization
• Step 3—Deserialization: Browser-side reconstruction
of static document structure. The web browser parses
the web page into its initial parse tree, coercing the
parse tree to preserve the intended structure. Thus, it
can robustly identify untrusted data in the document
structure at the end of the deserialization step.
• Step 4—Browser-side dynamic PLI. This step is
needed to ensure DSI when web pages are dynamically
updated. In essence, once untrusted data is identiﬁed in
the browser at previous step, we initialize it as quaran-
tined and track quarantined data in the browser dynam-
ically. Language parsers for HTML and other higher-
order languages like JavaScript are modiﬁed to disal-
low quarantined data from being used during parsing
in a way that violates the policy. This step removes the
burden of having the client-side code explicitly check
Web pages are augmented with additional markup at the
server’s end, in such a way that the browser can separate
trusted structural entities from untrusted data in the static
document structure. We call this step serialization, and it is
ideally performed at the output interface of the web server.
Adaptive Attacks. One naive way to perform serializa-
tion is to selectively demarcate or annotate untrusted data
in the web page with special markup. The key concern is
that an adaptive attacker can include additional markup to
evade the isolation. For instance, let us say that we embed
the untrusted data in a contained region with a special tag
that disallows script execution that looks like:
possibly-malicious content
...
3 : 
4 : 
5 : if (J3246 GET[’MainUser’] K3246) {
...
Figure 6: Example of minimal serialization using random-
ized delimiters for lines 3-5 of the example shown in Fig-
ure 2.
This scheme is proposed in BEEP [15]. As the authors
of BEEP pointed out, this naive scheme is weak because
an adaptive attacker can prematurely close the  en-
vironment by including a  in a node splitting at-
tack. The authors of BEEP suggest an alternative mecha-
nism that encodes user data as a JavaScript string, and uses
server-side quoting of string data to prevent it from escaping
the JavaScript string context. They suggest the following
scheme:
We point out that it can be tricky to prevent the mali-
cious content from breaking out of even the simple static
JavaScript string context. It is not sufﬁcient to quote the
JavaScript end-of-string delimiters (") – an attack string
such as ... perpe-
trates a node splitting attack closing the script environment
altogether, without explicitly breaking out the string con-
text. Sanitization of HTML special characters  might
solve this instance of the problem, but a developer may not
employ such a restrictive mechanism if the server’s policy
allows some form of HTML markup in untrusted data (such
as  or  tags in user content).
Our goal is to separate the isolation mechanism from
the policy. The above outlined attack reiterates that con-
tent server-side quoting or validation may vary depending
upon the web application’s policy and is an error-prone pro-
cess; keeping the isolation mechanism independent of input
validation is an important design goal. We propose the fol-
lowing serialization schemes as an alternative.
Minimal Serialization.
In this form of serialization, only
the regions of the static web page that contain untrusted
data are surrounded by special delimiters. Delimiters are
added around inlined untrusted data independent of the con-
text where the data is embedded. For our running example
shown in the Figure 2, the serialization step places these
delimiters around all occurrences of the GET array vari-
ables. If the markup elements used as delimiters are stat-
ically ﬁxed, an adaptive attacker could break out of the con-
ﬁnement region by embedding the ending special delimiter
in its attack string as discussed above. We propose an alter-
native mechanism called markup randomization to defend
against such attacks.
The idea is to generate randomized markup values for
special delimiters each time the web page is served, so that
the attacker can not deterministically guess the conﬁning
context tag it should use to break out. Abstractly, the server
appends a integer sufﬁx c, c ∈ C to a matching pair J K
of delimiters enclosing an occurrence of untrusted data, to
generate Jc Kc while serializing. The set C is randomly gen-
erated for each web page served. C is sent in a conﬁden-
tial, tamper-proof communication to the browser along with
the web page. Clearly, if we use a pseudo-random number
generator with a seed Cs to generate C, it is sufﬁcient to
send {Cs, n}, where n is the number of elements in C ob-
tained by repeated invocations of the pseudo-random num-
ber generator.
In the Figure 6 , we show the special de-
limiters added to the lines 3-5 of our running example in
Figure 2. One instance of a minimal serialization scheme
is the tag matching scheme proposed in the informal jail
tag[7], which is formally analyzed by Louw et. al. [21].
Full Serialization. An alternative to minimal serializa-
tion is to mark all trusted structural entities explicitly, which
we call full serialization. For markup randomization, the
server appends a random sufﬁx c, c ∈ C, to each trusted ele-
ment (including HTML tags, attributes, values of attributes,
strings) and so on.
Though a preferable mechanism from a security stand-
point, we need a scheme that can mark trusted elements
independent of the context of occurrence with a very ﬁne
granularity of speciﬁcation. For instance, we need mech-
anism to selectively mark the id attribute of the div ele-
ment of line 3 in the running example (shown in Figure 2)
as trusted (to be able to detect attribute injection attacks),
without marking the attribute value as trusted. Only then
can we selectively treat the value part as untrusted which
can be essential to detect dynamic code injection attacks,
such as attack 3 in Figure 3.
Independently and concurrent with our work, Gundy et.
al. have described a new randomization based full seri-
alization scheme, called Noncespaces [10] that uses XML
namespaces. However, XML namespaces does not have the
required granularity of speciﬁcation that is described above,
and hence we have not experimented with this scheme. It is
possible, however, to apply the full serialization scheme de-
scribed therein as part of our architecture as well, sacriﬁcing
some of the dynamic integrity protection that is only possi-
ble with a ﬁner-grained speciﬁcation. We do not discuss
full serialization further, and interested readers are referred
to Noncespace [10] for details.
N Kc
V −→ Jc
X −→ Y1Y2
{N.mark = U ntrusted;}
{if (X.mark == U ntrusted)
then (Y1.mark = X.mark;
Y2.mark = X.mark;)
else (Y1.mark = T rusted; }
Y2.mark = T rusted;)
...
3 :
4 :
5 :
...
if (J3246 ..
K2222 ... K3246) {
K5367">
Figure 7: Rules for computing mark attributes in minimal
deserialization.
4.2 Deserialization
When the browser receives the serialized web page, it
ﬁrst parses it into the initial static document structure. The
document parse tree obtained from deserialization can veri-
ﬁably identify the untrusted nodes.
Minimal deserialization . Conceptually, to perform de-
serialization the browser parses as normal, except that it
does special processing for randomized delimiters Jc, Kc. It
ensures that the token corresponding to Jc matches the token
corresponding to Kc, iff their sufﬁxes are the same random
value c and c ∈ C. It also marks the nodes in the parse tree
that are delimited by special delimiters as untrusted.
Algorithm to mark untrusted nodes. Minimal deserial-
ization is a syntax-directed translation scheme, which com-
putes an inherited attribute, mark, associated with each
node in the parse tree, denoting whether the node is
Trusted or Untrusted. For the sake of conceptual ex-
planation, let us assume that we can represent valid web
pages that the browser accepts by a context-free grammar G
5.Let G = {V, Σ, S, P } , where V denotes non-terminals,
Σ denotes terminals including special delimiters, S is the
start symbol, and P is a set of productions. Assuming that
C is the set of valid randomized sufﬁx values, the serialized
web page s obeys the following rules:
(a) All untrusted data is conﬁned to a subtree rooted
at some non-terminal N , such that a production, V −→
JcN Kc, is in P .
(b) Productions of the form V −→ Jc1
N Kc2
, c1 6= c2 are
not allowed in P.
(c) ∀c ∈ C, all productions of the form V −→ JcN Kc
are valid in P.
The rules to compute the inherited attribute mark are
deﬁned in Figure 7, with mark attribute for S initialized to
Trusted.
Fail-Safe. Appending random sufﬁxes does not lead to ro-
bust design by itself. Sending the set C of random values
5practical implementations may not strictly parse context-free gram-
mars
Figure 8: One possible attack on minimal serialization, if
C were not explicitly sent. The attacker provides delimiters
with the sufﬁx 2222 to produce 2 valid parse trees in the
browser.
used in randomizing the additional markups adds robustness
against attacker spooﬁng delimiters.
To see why, suppose C was not explicitly sent in our
design. Consider the scenario where an adaptive attacker
tries to confuse the parser by generating two valid parse
In Figure 8 the attacker embeds delimiter J2222 in
trees.
GET[’FriendId-Status’] and a matching delimiter
K2222 in GET[’MainUser’]. There could be two valid
parse trees—one that matches delimiters with sufﬁx 5367
and 3246, and another that matches the delimiters with suf-
ﬁx 2222. Although, the browser could allow the former to
be selected as valid as delimiter with 5367 is seen ﬁrst ear-
lier in the parsing, this is a fragile design because it relies
on the server’s ability to inject the constraining tag ﬁrst and
requires sequential parsing of the web page. In practice, we
can even expect the delimiter placement may be imperfect
or missing in cases. For instance in Figure 8, if the special
delimiters with sufﬁx 5367 were missing, then even if the
server had sanitized GET[’FriendId-Status’] per-
fectly against string splitting attack (attack 1 in Section 2),
the attacker possesses an avenue to inject a spurious de-
limiter tag J2222. All subsequent tags placed by the server
would be discarded in an attempt to match the attacker pro-
vided delimiter. The attacker’s ability to inject isolation
markup is a weakness in the mechanism which does not ex-
plicitly send C. The informal  proposal may be
susceptible to such attacks as well [7]. Our explicit com-
munication of C alleviates this concern.
4.3 Browser(cid:173)side dynamic PLI
Once data is marked untrusted, we initialize it as quar-
antined. With each character we associate a quarantine bit,
signifying whether it is quarantined or not. We dynamically
track quarantined metadata in the browser. Whenever the
base type of the data is converted from the data type in one
language to a data type in another, we preserve the quaran-
tine bit through the type transformation. For instance, when
the JavaScript code reads a string from the browser DOM
into a JavaScript string, appropriate quarantine bit is pre-
served. Similarly, when a JavaScript string is written back
to a DOM property, the corresponding HTML lexical enti-
ties preserve the dynamic quarantine bit.
Quarantine bits are updated to reﬂect data dependences
between higher-order language variables, i.e. for arithmetic
and data operations (including string manipulation), the
destination variable is marked quarantined, iff any source
operand is marked quarantined. We do not track control
dependence code as we do not consider this a signiﬁcant
avenue of attack in benign application. We do summa-
rize quarantine bit updates for certain functions which result
in data assignment operations but may internally use table
lookups or control dependence in the interpreter implemen-
tation to perform assignments. For instance, the JavaScript
String.fromCharCode function requires special pro-
cessing, since it may use conditional switch statement or a
table-lookup to convert the parameter bytes to a string ele-
ments. In this way, all invocations of the parsers track quar-
antined data and preserve this across data structures repre-
senting various parse trees.
Example. For instance, consider the attack 3 in our ex-
ample. It constructs a parse tree for the eval statement as
shown in Figure 4. The initial string representing the ter-
minal id on line 3 is marked quarantined by the deserial-
ization step. With our dynamic quarantine bit tracking, the
JavaScript internal representation of the div’s id and vari-
ables divname, Name and Status are marked quaran-
tined. According to the terminal conﬁnement policy, during
parsing our mechanism detects that the variable Status
contains a delimiter non-terminal “;”. It coerces the lexeme
“;” to be treated a terminal character rather than interpret-
ing it as a separator non-terminal, thus nullifying the attack.
5 Architecture
In this section, we discuss the details of a client/server ar-
chitecture that embodies our approach. We ﬁrst outline the
goals we aim to achieve in our architecture and then outline
how we realize the different steps proposed in Section 4.
5.1 Architecture Goals
We propose a client-server architecture to realize DSI.
We outline the following goals for web sites employing
DSI enforcement, which are most important to make our
approach amenable for adoption in practice.
1. Render in non-compliant6 browsers, with minimal im-
pact. At least the trusted part of the document should
render as original in non-compliant browsers. Most
user-generated data is benign, so even inlined un-
trusted data should render with minimal impact in non-
compliant browsers.
6Web browsers that are not DSI-compliant are referred to as non-
compliant
2. Low false positives. DSI-compliant browsers should
raise very few or no false positives. A client-server ar-
chitecture, such as ours, reduces the likelihood of false
positives that arise from a purely-client side implemen-
tation of DSI (see Section 7).
3. Require minimal web application developer effort. Au-
tomated tools should be employed to retroﬁt DSI
mechanisms to current web sites, without requiring a
huge developer involvement.
5.2 Client(cid:173)Server Co(cid:173)operation Architecture
Identiﬁcation of Untrusted data. Manual code refac-
toring is possible for several web sites. Several web mashup
components, such as Google Maps, separate the template
code of the web application from the untrusted data already,
but rely on sanitization to prevent DSI attacks. Our explicit
mechanisms would make this distinction easier to specify
and enforce.
Automatic transformation to enhance the markup gener-
ated by the server is also feasible for several commercial
web sites. Several server side dynamic and static taint-
tracking mechanisms [44, 19, 38] have been developed in
the past. Languages such as PHP, that are most popularly
used, have been augmented to dynamically track untrusted
data with moderate performance overheads, both using au-
tomatic source code transformation [44] as well as manual
source code upgrades for PHPTaint [38]. Automatic mech-