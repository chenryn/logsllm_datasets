more chances to collude with each other. Informally, we
should select delegates from different sets of friends to
reduce the possibility of a collusive attack and minimize
the inﬂuence of such a collusion.
• whether i is an attractive target for an adversary:
since an adversary can minimize her attack cost by
compromising nodes holding more keys, i is more
attractive to an adversary if she is a delegate of many
users. Hence, less trust should be put on those candi-
dates i currently keeping more shares.
Given the above observations, the following heuristics can
be used to evaluate the trustworthiness of a user. The key
idea is to explore social relationships among users to prevent
the spreading of infection from malicious nodes already
under adversary control, as well as reducing the chance of
colluding among these malicious nodes. More concretely,
we deﬁne:
ti = (cid:26) 1
1 − δ(bi) − σ(li)
if i ∈ D0
if i ∈ [N ] = Fu \ D0
(4)
where bi =| F ∞
i ∩Fu | and li is the number of shares held by
i. The candidate delegates [N ] = {i, 1 ≤ i ≤ N } are from
the set of friends of the user Fu. In Equation (4), D0 is a set
of m  maxi∈[N ]{bi} (Algorithm 1).
The term 0 ≤ σ(li) ≤ 1 determines the attractiveness of i
to an adversary, e.g., how many keys the adversary gets by
compromising i.
We let 0 ≤ δ(bi) ≤ 1 reach the maximal value of 1 at bi ≥
b∗ = k − m and be at the minimum 0 at bi = 0. Similarly,
σ(li) is deﬁned to achieve the maximal value of 1 − δ(bi) at
li = l∗ = max{li, i ∈ [N ]} and be 0 at li = 0. That means
currently we care more on the impact of δ(bi) than of σ(li).
The testing of different impact weights by δ(bi) and σ(li) is
subject to future work. Depending on user’s prior belief on
the environment vulnerability, the following functions can
be used:
• exponential: e.g., δ(bi) = 1{bi>b∗} +1{bi≤b∗}
2bi −1
2b∗ −1 and
σ(li) = (1 − δ(bi)) 2li −1
2l∗ −1 . These functions4 are appro-
priate for vulnerable environments with potentially a lot
of malicious users. Hence, the possibility that a node
j would be compromised increases exponentially with
the number of shares she keeps li and the number of
common friends bi between i and u.
• logarithmic: e.g., δ(bi) = 1{bi>b∗} + 1{bi≤b∗}
log(bi+1)
log(m+1)
and σ(li) = (1 − δ(bi)) log(li+1)
log(l∗+1) . These functions are
appropriate in more secured environments with fewer
malicious users, thus the possibility j being compro-
mised increases less than linearly with li and bi.
• linear: δ(bi) = 1{bi>b∗} + 1{bi≤b∗}
bi
b∗ and σ(li) = (1 −
l∗ , which are applicable in neutral environments
δ(bi)) li
with a moderate number of malicious users.
B. A trust-based delegate selection algorithm
According to Proposition 1,
the probability T (n, k −
1) = P r(Dc ≤ k − 1) is maximized by choosing D
as n delegates with highest
trustworthiness ti from the
candidates [N ]. We assume that messages to unavailable
delegates can be kept pending and processed later on when
they go online (Section II). Hence the unavailability of
delegates do not affect the computation of the probability
T (n, k − 1)A(n, n − 2k + 1), and we can approximate
T (n, k − 1)A(n, n − 2k + 1) = T (n, k − 1).
With the trust measure in Section III-A, the selection
of delegates to maximize the probability T (n, k − 1) is
given in Algorithm 1. Roughly speaking, we sequentially
pick a user i with the highest trust value ti from remaining
candidate delegates. Thus Algorithm 1 forms a delegate set
D approximately maximizing T (n, k − 1). Since P r(Dat ≥
k) ≥ T (n, k − 1), we expect this algorithm to maximize the
probability that the delegate set achieved the desired security
level ε.
Algorithm 1 stops in two cases: ﬁrst, all available N
candidates are selected to be delegates; second, we achieve
4The function 1{A} evaluates to 1 if A is true and to 0 otherwise.
423
the desired security level 1 − ε. In the ﬁrst case, the actual
security level of the selection is P r(Dat ≥ k) ≥ P r(Dc ≤
k − 1) = T (n, k − 1). This lower bound T (n, k − 1) also
reﬂects the vulnerability of the environment and may be used
by the user to decide whether to share her secret. In our later
experiments, a user backs up her secrets only if the achieved
security level is P r(Dat ≥ k) ≥ τ , where 0 ≤ τ ≤ 1 − ε is
a parameter of our experiments.
Algorithm 1 selectDelegates(candidates [N ], trustworthi-
ness ti for each i ∈ [N ], threshold k, security parameter ε):
selected delegates D, achieved security level T [n, k − 1]
1: n = 0; D = ∅; L = [N ]; /* L is the current candidate list */
2: T [n, 0] = T [n, 1] = 1;
3: while (n ≤ N and T [n, k − 1]  0.9,
and τ does not clearly affect fL. Therefore, we focus on
the performance metric fL in later experiments with a given
value τ = 0.75.
Given the above metrics, the system load model consists
of the following factors:
• inf : whether there is an infection spreading in the
network, i.e., whether a user having lost her secret also
becomes under adversary control.
• pmal : the percentage of initially malicious users, i.e.,
the number of users already under adversary control at
the beginning of the simulation before the adversary
commands them to initiate the coordinated attack. A
higher pmal means a more vulnerable environment.
• adv : the distribution of the initially malicious users in
the network. The distribution can be random or based
on certain criteria, e.g., number of friends of a user.
Beside the load factors and their intensities, the major
factors inﬂuencing the system performance are:
• select :
the
secret sharing protocol, which includes the three
the algorithm to select delegates for
algorithms FRIENDBASED, RANDOMWALK, and
TRUSTBASED as described in Section IV-A.
• 0 ≤ ξ ≤ 1: the threshold k/n of a (k,n)-threshold
secret-sharing scheme being used.
Our goal is to measure the effects of two factors select
and ξ to the system performance fL under various load
intensities inf , pmal , and adv .
We ran each simulation with appropriate parameters and
measured each performance metric when the simulation
reached the stationary regime. The result (not shown) con-
ﬁrms that the distribution of fL is approximately Gaussian
and perfectly iid. Therefore, for later experiments, we only
ran each simulation with N=35 replications (sufﬁciently
large sample size) and summarized the measurements of fL
with its means and conﬁdence intervals at level 95%. As
data is roughly normal iid, this summarization shows both
accuracy and variability of our results.
C. Effects of the threshold values ξ
We ﬁrst measured inﬂuences of
the cryptographical
threshold ξ = k/n to system security under various load
intensities. For this goal ξ was varied from 0.1 to 1.0 for
each of the delegate selection approaches FRIENDBASED,
RANDOMWALK, and TRUSTBASED. The inﬂuence of ξ
on the fraction of secrets lost fL for each selection algorithm
is given in Figure 1, where the Y-axis shows the mean of
fL and 95%-conﬁdence intervals of the mean of fL.
For each given delegation-selection algorithm, we varied
the load intensity as follows. First, pmal was increased
from 0.1% to 50% to simulate environments with different
numbers of malicious users under adversary control. To
reduce the simulation parameter space, we randomized the
distribution of these initially malicious users in the network
(adv =RANDOM). Each experiment was carried out with
both cases (inf = false and inf = true).
We expected fL to be lower with higher values of ξ. In
fact, the results in Figure 1 give us two main observations.
Firstly, for any delegate-selection algorithm and for any case
of infection spreading, the smallest fraction of keys lost fL is
achieved with ξ = 1. This is intuitive: given a secret sharing
scheme with ξ = 1, the adversary must successfully attack
all delegates of a user to be able to steal the victim’s secret.
For values of ξ < 1.0 the differences are not substantial.
Secondly, we observe that the system security with an
infection spreading (left pane of each ﬁgure) is much lower
than without infection spreading (right pane). Figures 1(a,
c, e), left panes, show that the adversary can steal a large
fraction of secrets (from 50% up to 100% of secrets in most
cases) by initially controlling a small number of malicious
users (from 0.2% if ξ < 1 and from 5% if ξ = 1).
The inﬂuence of the infection spreading is minimal
in
two cases: (1) with ξ = 1.0 and the delegate-selection
approach FRIENDBASED as in Figure 1(a, left), and (2):
for the TRUSTBASED delegation selection algorithm, as in
424
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:14:16 UTC from IEEE Xplore.  Restrictions apply. 
Inf= true, select=FRIENDBASED
Inf= false, select=FRIENDBASED
Inf= true, select=FRIENDBASED
Inf= false, select=FRIENDBASED
t
s
o
l
s
t
e
r
c
e
s
f
o
n
o
i
t
c
a
r
F
1
0.8
0.6
0.4
0.2
0
1
t
s
o
l
s
t
e
r
c
e
s
f
o
n
o
i
t
c
a
r
F
0.8
0.6
0.4
0.2
 ξ=0.1 → 0.9
 ξ=1.0
0
0.2
0.4
0.8
% of initially malicious users
0.6
 ξ=0.1 → 0.9
 ξ=0.1 → 0.9
0.04
0.035
0.03
0.025
0.02
0.015
0.01
0.005
t
s
o
l
s
t
e
r
c
e
s
f
o
n
o
i
t
c
a
r
F
 ξ=1.0
0.2
0.4
0.8
% of initially malicious users
0.6
1
0
0.2
0.4
0.8
% of initially malicious users
0.6
 ξ=1.0
1
(a) pmal = 0.1% → 1%
Inf= true, select=RANDOMWALK
−3
Inf= false, select=RANDOMWALK
x 10
t
s
o
l
s
t
e
r
c
e
s
f
o
n
o
i
t
c
a
r
F
9
8
7
6
5
4
3
2
1
0
0.2