completely 
behavior 
extracted 
with the feature 
extracted 
makes the features 
superior 
for easy presentation, 
between a pair of subjects. However, 
holds for other subjects. 
to those extracted 
from holistic 
extracted 
(panel (c» from behavior 
for two different 
subjects, 
are overlapping
. This 
among users' behavior 
when 
patterns, 
subjects 
from behavior 
differentiate 
behavior. 
stability 
from behavior 
discussed 
pattern 
before, 
this 
using 
whereas 
evidently 
from holistic 
behavior. Note that 
we only compare the difference 
observation 
a similar 
and discriminability 
Across Subjects 
3) Statistical 
Further 
to investigate 
of Features 
the stability 
Dispersion 
of 
we 
metric based on 
patterns, 
extracted 
[2]. The measurement 
from frequent behavior 
dispersion 
features 
defined a simple and effective 
Gini's Mean Difference 
of this metric 
is a real number that is zero if all the data are identical 
stable and unique), and increases 
diverse, 
For each feature 
values {x; hXII, (nk is the number of feature 
dispersion 
(or 
as the data become more 
fk used in this study, with a sequence 
with the same scale as the quantity 
of 
samples), the 
metric DM(Jk) can be defined 
as: 
being measured. 
VII. DETECTOR IMPLEMENTATION 
In this section, 
we develop three types of one-class 
detector. 
detectors, 
is specific 
range of detectors. 
that we have diversity 
in the set of 
By ensuring 
we can examine whether or not an observed 
to one type of detector 
true for a 
or more generally 
effect 
A. One-Class 
Detector 
Overview 
is still a challenging 
from the 
classification 
user are available 
task  from  the 
. It is a two class (legitimate 
used both the legitimate 
in advance. Most previous 
user's and impostors' 
since there may be thousands 
User authentication 
viewpoint
problem, but only the patterns 
pattern 
user vs. impostors) 
legitimate 
research 
to train their models. Yet this is not practical 
applications 
impostors' 
a  better 
legitimate 
impostors 
type of problem is known as one-class 
anomaly detection 
attention 
similarity 
user's data samples, 
who are using some sort of similarity 
to one-class 
in terms of their input and output. 
data samples at the risk of fatal intrusion
classification 
[15]. In this study, we constrained 
that behave 
is to build  a  model 
and then use it to detect 
in realistic 
of potential 
. Therefore
anomaly detectors 
only based on the 
[14] or 
our 
measures. This 
solution 
samples 
, 
DM(fk) = 
1  11k  11k 
LL:!x: -xjl 
nk (nk -1) i=1 j=1 
B. Detector 
1: Nearest-Neighbor 
Detector 
A nearest-neighbor 
based detector 
models a user's mouse 
based on the assumption 
that new mouse behavior­
The dispersion 
metric of each feature 
computed over 300 corresponding 
we calculated 
the average dispersion 
over all 28 subjects. 
for every subject 
mouse operations. 
is 
Then 
metric for each feature 
Table VI shows the average dispersion 
metrics 
extracted 
from behavior patterns, 
typical features 
comparison 
addition 
percentage 
decrease 
with those extracted 
from holistic 
to the dispersion 
in parentheses, 
metrics, 
which indicates 
the table includes 
the percent 
a 
in dispersion 
metrics of behavior 
patterns 
over 
for some 
in 
behavior. In 
speeds for 24 types of  mouse 
of maximal speed), 
for average movement acceleration 
'This study extracted  average  movement 
movement (same setting 
position 
3  different 
present 
pixels' distance. 
features. 
movement distances. 
one case of speed features 
the similar 
with  the  diagonal 
direction 
observation 
we only 
and 524 
holds for the other 
speed 
Note that for easy presentation, 
based  on  8 different 
However, 
movement directions  and 
and  relative 
from the user will resemble 
the covariance 
data. During training, 
matrix of the training 
one or 
the 
and saved each mouse behavior-pattern 
feature 
vector. 
vectors 
estimated 
After multiple 
behavior 
pattern 
more of those in the training 
detector 
feature vectors, 
feature 
5 we obtained 
shown in section 
Mahalanobis 
training 
feature-distance 
data. The distance 
from the training 
data), and distance 
the best results 
distances 
tests with k changing 
from 1 to 
with k=3, which will be 
9. During testing, 
the detector 
calculated 
(using the covariance 
was calculated 
matrix of the 
from the new 
in the training 
vector to each of the vectors 
from the new vector to the nearest 
vector 
data was used as the anomaly score. 
C.  Detector 
2: Neural Network Detector 
Neural networks 
have been used successfully 
in many 
applicatio
ns. In this paper, we considered 
single-hidden-layer 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:50:32 UTC from IEEE Xplore.  Restrictions apply. 
B. Calculating 
Detection 
Peiformance 
initialized, 
and 
was trained 
to produce a 1.0 on the output 
In the training phase,  a 
neural networks. 
network was built 
with p input nodes, one output node, and L 2 p / 3 J hidden 
nodes. The network weights were randomly 
then the detector 
node for every training 
epochs using a learning-rate 
testing 
and the output of the network was recorded. 
the output of the network; 
test vector is similar 
to -1.0, it is dissimilar. 
vector. We trained for 500 
of 0.0001. In the 
phase, the test vector was run through  the 
Denote s to be 
intuitively, 
vectors, 
if s is close to 1.0, the 
to the training 
and with s close 
parameter 
feature 
network, 
To convert these sets of detection 
scores of legitimate 
measures 
into aggregate 
of detector 
we compute the false-acceptance 
rate (FAR) 
rate (FRR). The FAR is the measure of 
system will 
users and impostors 
performance, 
and false-re
jection 
the likelihood 
incorrectly 
The FRR is the measure of the likelihood 
security 
an authorized 
accurate 
reject an access attempt 
user. The lower the FRR and FAR, the more 
system will incorrectly 
accept an access attempt 
by an unauthorized 
user. 
that the biometric 
that the biometric 
the approach. 
security 
by 
D. Detector 
3: Support 
Vector Machine (one-class) 
A one-class 
SVM generalizes 
feature 
the idea of mapping the 
space via a kernel 
the origin as the only example from 
vectors. In the testing 
phase, the detector 
was built 
phase, the test vector 
into the same high-dimensional 
space and the 
The 
from the linear separator 
was calculated. 
as this distance, 
with the sign 
from the data. 
scores are separated 
in this study, and the SVM 
and treating 
data into a high dimensional 
function, 
other classes. In the training 
using the training 
was projected 
distance 
anomaly score was calculated 
inverted, 
We used a REF kernel function 
parameter 
and 0.02 respectively. 
calculat
authorized 
rejection 
impostors' 
case occurs. 
case. On the contrary, 
ed. The function 
so that positive 
g and nu (using LibSVM [18]) were set to 0.01 
Then the decision 
would generate 
function 
was 
"+ 1" if the 
it is a false 
user's test set is input, otherwise 
"-1" should be obtained 
if the 
test set is the input; otherwise 
a false acceptance 
a 
We also brought FAR and FRR together 
to generate 
called an ROC curve 
behavior 
generates 
an 
is 
an 
a 
on the anomaly  scores 
indicates 
indicates 
establishes 
on how the threshold 
while a score  under 
user. The choice of threshold 
point of the detector 
of possible 
graphical 
summary of performance 
[17]. Whether or not mouse operating 
alarm  depends 
chosen. An anomaly score over the threshold 
impostor, 
the threshold 
legitimate 
operating 
continuum 
the FARs and FRRs that would be attained 
detector 
increased 
the classifier 
the FRR or FAR, respectively. 
observe  that  setting 
relatively 
paper, we would show results 
in most cases. 
low FAR on average*. Therefore, 
with a threshold 
After multiple 
the threshold  value 
operating 
or decreased 
point.  Moreover, 
towards authentic 
from the default 
thresholds, 
users or impostors, 
we 
lowering 
tests, 
of 0.45 yields a 
throughout 
this 
value of 0.45 
the 
on the curve. Over the 
the ROC curve illustrates 
at each possible 
value of 0.0 to bias 
the threshold 
can be 
IX. RESULTS AND ANALYSIS 
In this section, 
effectiveness 
experiments, 
session 
lengths, 
usability. 
we present 
an objective 
of the proposed  approach  through 
and then investigate 
trying to find a balance 
the performance 
between security 
evaluation 
on the 
a series of 
at varying 
and 
A. Detector 
Peiformance 
authentication 
Table VII shows the average FARs and FRRs of 
for each of three detectors 
samples from 
samples from holistic 
continuous 
subjects, with the input set to be feature 
behavior 
(as mentioned 
the threshold 
efficacy of features 
patterns, 
the ROC curve for each of three detectors. 
8.2, these tests are performed 
with 
analyze the 
Figure 3 shows 
in Section 
of 0.45.). 
Additionally, 
from behavior 
and feature 
to further 
patterns 
over all 
Our first observation 
is that the best performance 
behavior 
level of accuracy 
which is impressive 
for realistic 
FAR of 0.37% and FRR of 1.12%, obtained 
Class SVM detector, 
acceptable 
also competitive  with 
while being subject 
compared with previous 
activities 
that the average error rates for features 
in a longer period of observation. 
to more variability 
the best results 
has a 
by the One­
an 
It is 
and achieves 
application. 
previously 
of mouse dynamics 
reported, 
We also observe 
from the holistic 
work, because they represent 
detectors, 
*Note that for different 
For instance, 
and for the one-class 
mapped all intervals to 
intervals. 
there are different 
threshold 
for the neural network detector 
is [0, 1], 
we 
SVM, it is [-1, 1].  For uniform presentation, 
[0, 1]. 
the threshold 
interval 
VIII. EVALUATION METHODOLOGY 
This section explains 
how we set up the detector 
the detector 
performance. 
training 
and testing, 
and calculates 
A. Training and Testing 
Procedure 
We started 
as follows: 
to recognize 
half of feature 
the legitimate 
by designating 
and tested its ability 
subject. The detector 
as the 
one of our 28 subjects 
We trained 
each 
user 
user, and the rest as impostors. 
legitimate 
detector 
and impostors 
on the 
Step 1: We ran the training phase of the detector 
samples generated 
randomly-selected 
by the 
of that user. 
legitimate 
Step 2: We ran the testing 
on the 
feature samples from the remaining 
half of the data 
generated 
by the legitimate 
scores assigned 
to each feature 
Step 3: We ran the testing 
feature 
recorded 
as impostor 
sample as user scores. 
phase of the detector 
by the impostors. 
We 
to each feature 
sample 
samples from data generated 
the anomaly scores assigned 
phase of the detector 
user. We recorded 
builds a profile 
the anomaly 
scores. 
on the 
This process 
was then repeated, 
designating 
each of other 
user in turn. For choosing 
Since we used a random sampling 
of interest, 
as the legitimate 
subjects 
parameters 
employed. 
data into training 
the effect of this randomness, 
procedure 
selected 
draw from the entire 
and testing 
l O-fold cross validation 
was 
to divide the 
sets, and we want to account 
for 
the above 
we repeated 
ten times, each time with an independently 
data set. 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:50:32 UTC from IEEE Xplore.  Restrictions apply. 
TABLE VII. FARs AND FRRs OF THE THREE DETECTORS (WITH 
TABLE VIII. FARs AND FRRs FOR VARIOUS DATA SESSION LENGTHS 
STANDARD DEVIATION IN PARENTHESES) 
Operation lenj!th FAR 
FRR  FAR 
Detector  FAR 
Behavior Pattern Holistic Behavior 
FRR 
Neighbor 2.73% 3.67% 8.87% 9.63% 
Nearest 
Neural Network 0.89% 2.15% 6.36% 6.95% 
(0.0057)  (0.0065)  (0.0534)  (0.0653) 
0.37% l . l 2%  5.57% 6.73% 
(0.0062) (0.0067) (0.0502) (0.0493) 
(0.0124) (0.0089) (0.0936) (0.0923) 
One-Class 
100 
500 
1000 
2000 
3000 
SVM 
FRR  Authentication 
time 
44.65% 34.78% about 1 minute 
7.78% 
9.45% about 5 minutes 
2.75% 3.39% about 10 minutes 
1.22% 1.69% about 20 minutes 
0.37% l . l 2%  about 30 minutes 
obtained 
that the performance 
observe 
of FAR=2.7%, FRR=3.67%, which may be not encouraging 
comped WIth other two detectors 
that thIS may be due to lacking 
this method. 
in our study. We gauge 
using 
of self-learning 
ability 
by nearest 
neighbor 
is 
and systematically 
approach, 
from the proposed 
evaluate 
we 
Furthermore, 
to statistically 
the performance 
obtained 
conduct a statistical 
(HTER) and confidence 
shows that the proposed 
among three detectors, 
confidence 
test  using 
approach 
interval 
interval 
the half total error rate 
[22]. This statistical  test 
provides 
and with 95% confidence, 
the lowest HTER 
the 
lies in between 0.75%±1.15%. 
B. Effect of Session 
Length 
The session 
length corresponds 
to the number of mouse 
Session 
session. 
to accomplish 
a data collection 
user authentication 
operations 
length may play an important 
continuous 
of opportunities 
nough for an adversary 
InVestIgate 
detector, 
varying session 
security 
we conducted 
lengths, 
and usability. 
role in mouse dynamics 
for 
since it represents 
the window 
and even a few minutes is 
the system. To 
of the 
a test on the same data set with 
trying to find a balance between 
length on the accuracy 
the effect of session 
for an impostor, 
to compromise 
Table VIII shows the FARs and FRRs at varying 
session 
time refers 
SVM detector
a data session, 
using a One-Class 
the authentication 
The FAR and FRR obtained 
the FAR and FRR drop to 2.75% and 3 .39%, with 
to the sum of average 
and the average time needed to 
on the 
. In addition 
to the 
time in 
lengths. The 
to the varying  session 
time needed 
lengths, 
FAR and FRR, the table includes 
minutes corresponding 
authentication 
to collect 
make the decision. 
sesion lengh  of 100 is 44.56% and 34.78% respectively, 
whIch IS akIn to random guessing, 
but the authentication 
time only took about 1 minute. As the session length 
increases, 
we may 
time about 1 0  minutes. Therefore, 
the authentication 
of detectors 
almost 
draw a conclusion 
get improved as the session length increases
. 
certainly 
What's more, the FAR and FRR drop to 0.37% and 1 . 1 2% 
after observing 
a 
practically 
authentication 
applicability 
Thus a tradeoff 
FRR) and user acceptability (authentication 
investigations 
place it in more realistic 
but having a 
time up to 30 minutes. This may limit the 
(FAR and 
time), and more 
to 
must be made between  security 