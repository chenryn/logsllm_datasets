title:Byzantine Fault Tolerance Can Be Fast
author:Miguel Castro and
Barbara Liskov
Byzantine Fault Tolerance Can Be Fast 
Miguel Castro 
Microsoft Research Ltd. 
1 Guildhall St., Cambridge CB2 3NH, UK 
PI:EMAIL 
Barbara Liskov 
MIT Laboratory for Computer Science 
545 Technology Sq., Cambridge, MA 02139, USA 
liskov @Ics.mit.edu 
Abstract 
Byzantine fault tolerance is important because it can be 
used to implement highly-available systems that tolerate ar- 
bitrary behaviorfrom faulty components. This paper presents 
a detailed performance evaluation of BFT, a state-machine 
replication algorithm that tolerates Byzantine faults in asyn- 
chronous systems.  Our results contradict the common belief 
that Byzantine fault tolerance is too slow to be used in prac- 
tice - BFT performs well  so that it can be used to iniple- 
nient  real systems.  We implemented a  replicated  NFS file 
system  using  BFT that performs 2% faster to 24% slower 
than production implementations of the NFS protocol that 
are not fault-tolerant. 
1. Introduction 
We  are increasingly  dependent on services provided  by 
computer systems. We would like these systems to be highly- 
available:  they  should provide correct service without in- 
terruptions.  There is an extensive body of research on repli- 
cation  techniques to achieve  high availability  but  most  as- 
sume that nodes fail by  stopping or by omitting some steps. 
We believe  that these assumptions are not likely to hold  in 
the future. For example, malicious attacks are increasingly 
common and can cause faulty nodes to behave arbitrarily. 
Byzantine fault tolerance  techniques can be used  to im- 
plement highly-available  systems that tolerate arbitrary  be- 
havior from faulty replicas.  The problem is that it is widely 
believed  that  these  techniques  are too  slow to  be  used  in 
practice.  This paper presents  experimental results showing 
that it is possible to implement highly-available systems that 
tolerate Byzantine faults and perform well. 
We developed astute machine replication  [ 141 algorithm, 
BFT, that  tolerates  Byzantine faults.  BFT has been  imple- 
mented as a generic program library with a simple interface 
and  we  used  the  library  to  implement the  first Byzantine- 
fault-tolerant  NFS file system, BFS. The algorithm, the li- 
This research was supported by DARPA under contract F30602-98- 1-0237 
monitored  by  the  Air  Force  Research  Laboratory.  This  paper  describes 
work done while the first author was at the MIT Laboratory  for Computer 
Science. 
brary,  and BFS  were described elsewhere [3, 4, 21.  This 
paper presents a performance evaluation of BET and BFS. 
BFT performs  well  mostly  because  it  uses  symmetric 
cryptography to  authenticate messages.  Public-key  cryp- 
tography, which  was the major bottleneck  in previous  sys- 
tems [12, 91, is used only to exchange the symmetric keys. 
Additionally, BFT incorporates several important optimiza- 
tions that reduce the size and number of messages used  by 
the protocol. 
We present results of several micro-benchmarks that char- 
acterize the  performance of  the  BFT library  in  a  service- 
independent way,  and  evaluate  the  impact of  each  of  the 
performance optimizations.  Additionally,  we present  per- 
formance results  for BFS  on the  modified  Andrew bench- 
mark [ 1 11 and PostMark [8].  These results  show that BFS 
performs 2% faster to 24% slower than  production  imple- 
mentations of the NFS protocol that are not replicated. 
There is little published work on the performance of By- 
zantine fault tolerance. There is an evaluation of the Ram- 
part toolkit  [ 121, and performance studies of three services 
R  [13], e-Vault [7], and COCA [15].  It is hard  to perform 
a direct comparison between  these systems and the BFT li- 
brary  but  it  is  clear that  our library  is  significantly  faster. 
Some performance numbers reported in this paper appeared 
in  [4] but we expand on their analysis. 
The rest  of the paper is organized as follows.  We start 
by describing the properties provided by the algorithm and 
its assumptions. Section 3 presents  a brief overview of the 
algorithm and the performance optimizations.  The perfor- 
mance evaluation is in Sections 4 and 5: they present micro- 
benchmark and file system benchmark results, respectively. 
Section 6 summarizes our results. 
2. Properties and Assumptions 
BFT can replicate  any service that can be modeled  as a 
deterministic  state  machine,  i.e.,  the different replicas  are 
required to produce the same sequence of results when they 
execute the same sequence of operations. Note that replicas 
do not need to run the same code [5]. 
We  make  no  assumptions about  the  network  that  con- 
nects  replicas  and  clients except that  we  assume eventual 
time bounds on message delays for liveness. We use a Byzan- 
tine failure model, i.e., faulty nodes may behave arbitrarily. 
But we assume that an attacker is computationally bound so 
that  (with very high probability) it is unable to subvert the 
cryptographic techniques we use in the algorithm. 
0-7695-1101-5/01 $10.00 0 2001 IEEE 
513 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:06:48 UTC from IEEE Xplore.  Restrictions apply. 
BFT offers strong safety  and liveness properties if  less 
than  1/3  of  the  replicas  are  faulty  and  regardless of  the 
number of  faulty  clients.  BFT provides linearizability  [6] 
without relying  on any synchrony assumption, and it guar- 
antees  that  correct clients receive replies  to their  requests 
if  delays are  bounded  eventually.  In  particular,  BFT can 
guarantee safety in the presence of denial of service attacks 
whereas previous state-machine replication  systems [ 12, 91 
could not. 
BFT can  recover replicas proactively  [4].  This allows 
BFT to offer safety and liveness even if all replicas fail pro- 
vided less  than  1/3 of the replicas become faulty  within  a 
window  of  vulnerability.  To simplify  the presentation, we 
assume that there are 3f + 1 replicas to enable the system 
to tolerate up to .f  faults. 
There is  little  benefit  in  any  form  of  replication  if  the 
replicas are likely to fail at the same time. We discuss tech- 
niques to fight this problem in [5, 21. 
3. Algorithm 
The algorithm is described in detail in [2]. Here, we pro- 
vide  only  a  brief  overview  to help understand the  perfor- 
mance evaluation.  The basic  idea is simple.  Clients send 
requests  to execute operations and  all  non-faulty  replicas 
execute the same operations in the same order.  Since repli- 
cas  are deterministic and  start in  the  same state,  all  non- 
faulty  replicas send replies with  identical  results for each 
operation.  The client chooses the result  that appears in  at 
least f + 1 replies. 
The  hard  problem  is  ensuring non-faulty  replicas exe- 
cute the same requests in the same order.  BFT uses a com- 
bination  of  primary-backup  and  quorum  replication tech- 
niques to order requests.  Replicas move through a succes- 
sion  of  numbered  configurations called  views.  In  a  view, 
one replica  is the primary and the others are backups.  The 
primary picks the execution order by  assigning a sequence 
number to each request.  Since the  primary  may  be faulty, 
the  backups  check the sequence numbers and trigger  view 
changes to select a  new  primary  when  it  appears that  the 
current one has failed. 
Figure 1 shows the operation of the algorithm in the nor- 
mal  case of  no pritnary  faults.  In  the  figure,  p 7 )  
denotes a message m from i to j  with  a message authen- 
tication code (MAC), and a,  is  a message  with  a 
vector  of  MACS with  an  entry  for each replica other than 
i.  The algorithm also uses  a cryptographic hash  function 
D. Currently, we use UMAC32 [ 11 to compute MACS and 
MD5 to compute digests. 
The figure illustrates  an example where a client c sends 
a request  m to (execute an operation o with  a timestamp t 
to the primary  for the current view II (replica 0).  The pri- 
mary  assigns a  sequence number n to m and sends a pre- 
prepare message with the assignment to the backups. Each 
backup i accepls the  assignment if  it  is  in  view  v,  and  it 
has not assigned n to a different request in v.  If i accepts 
the pre-prepare, it multicasts a prepare message to all other 
replicas signalling that it accepted the sequence number as- 
signment. Then, each replica collects messages until it has 
a  pre-prepare and  2f  matching  prepare  messages  for  se- 
quence number n, view U ,  and request m. When the replica 
has these messages, we say that it prepared the request.  The 
protocol  guarantees that it is not possible for correct repli- 
cas to prepare distinct  requests with the same view and se- 
quence number. 
The algorithm uses an additional phase to ensure this or- 
dering  information  is  stored  in  a  quorum  to  survive view 
changes. Each replica multicasts a commit message saying 
that  it has prepared  the request.  Then each replica collects 
messages until  it  has 2f  + 1 commit messages for v and 
n from different replicas (including itself).  We say that the 
request is committed when the replica has these messages. 
Each replica executes operation o when  m is commit- 
ted and the replica has executed all requests with sequence 
numbers less  than  n.  Then, the  replicas send  replies  with 
the operation result  T  to the client.  The reply  message in- 
cludes the current view number so that clients can track the 
current primary. 
3.1. Optimizations 
This section describes several optimizations that improve 
the  performance during  normal  case operation while pre- 
serving the safety and liveness properties. 
With the digest replies optimization, a client request des- 
ignaltes a replica to send the result.  This replica may be cho- 
sen randomly or using  some other load balancing scheme. 
After the designated replica executes the request, it  sends 
back  a reply  containing the result.  The other replicas  send 
back  replies  containing only the digest of  the  result.  The 
client uses the digests to check the correctness of the result. 
If thl:  client does not receive a correct result from the desig- 
nated replica, it retransmits the request (as usual) requesting 
all replicas to send replies with the result. 
The tentative execution optimization reduces the number 
of message delays for an operation invocation  from five to 
four.  Replicas  execute requests tentatively as soon  as:  the 
request is prepared; their  state reflects  the execution of  all 
requests with  lower  sequence number;  and  these  requests 
have: committed.  After executing the  request, the  replicas 
send tentative replies to the client.  Since replies  are tenta- 
tive, the client must wait for 2f  + 1 replies  with the same 
result.  This ensures that the request is prepared by  a quo- 
rum and, therefore, it is guaranteed to commit eventually  at 
non-faulty replicas. 
11; is  possible  to  take  advantage  of  tentative  execution 
to eliminate commit messages  without increasing latency: 
they can be piggybacked in the next pre-prepare or prepare 
message sent by a replica. 
We  also have  a read-only optimization that  reduces  la- 
tency to a single round trip for operations that do not mod- 
ify the service state. A client multicasts a read-only request 
to all replicas.  The replicas execute the request immediately 
after checking that it is properly authenticated, and that the 
request  is  in  fact  read-only.  A  replica sends back  a  reply 
only  after all  requests it executed before the read-only re- 
q u a t  have committed.  The client waits  for 2f + 1 replies 
with  the  same result.  It  may  be  unable to collect these if 
there are concurrent writes to data that affect the result.  In 
5 14 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:06:48 UTC from IEEE Xplore.  Restrictions apply. 
this case,  it retransmits the request as a regular read-write 
request after its retransmission timer expires. The read-only 
optimization  preserves  linearizability  provided clients  ob- 
tain  2f  + 1 matching replies for both read-only  and read- 
write operations. 
Request batching  reduces protocol overhead under load 