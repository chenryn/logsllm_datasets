ments the get and put_fragment methods that character-
ize our technique. We followed two implementation strate-
gies, one using fragments as atomic separate objects, and
the other adopting the DLO support oﬀered by Swift.
Figure 10 compares, for diﬀerent numbers of fragments,
the time required for the execution of get requests assum-
ing to map each fragment to a separate object. The lines
correspond to distinct values for the number f of fragments
(i.e., 1, 4, 16, 64, 256, and 1024). The parameters that drive
the performance are the network bandwidth and the over-
head imposed by the management of each request. For get
requests, the overhead introduced by the management of
one request for each fragment dominates when the resource
is small, whereas the increase in object size makes the net-
work bandwidth the bottleneck. The proﬁle of put requests
uploading the complete resource proved to be identical to
the proﬁle of get requests using a single fragment. The exe-
cution of put_fragment requests grows linearly with the size
of the fragment.
The identiﬁcation of the best number of fragments re-
quires to consider the proﬁle of the scenario. We evaluated
the behavior of a system on a collection of 1000 objects
where, after each put_fragment request, a sequence of 50
get requests were executed on objects in the collection, all
of the same size. Figure 11 reports the results of these ex-
periments. As objects become larger, the beneﬁts of frag-
mentation in the application of policy updates compensate
for the overhead imposed on the retrieval of the objects. It
is to note that the performance of the solution that does not
use our technique corresponds to the line with one fragment.
The throughput of the conﬁgurations using fragments is or-
ders of magnitude higher already for medium-size objects.
The graph also shows that the best number of fragments
depends on the resource size. The identiﬁcation of the value
to use requires to consider the conﬁguration of the system
and the expected workload.
A second set of experiments followed the same approach,
but considering the use of DLOs in Swift. The number of
fragments still has a signiﬁcant impact on the performance
of the get request, because the server has to generate in-
ternally the mapping for the single request originating from
the client and the multiple requests addressed to the stor-
age nodes. The application of the same workload considered
for the experiments in Figure 10, which interleaves get and
put_fragment requests, produces the results presented in
Figure 12. Comparing the cost with and without DLO we
notice a signiﬁcant beneﬁt deriving from the use of DLOs.
5.3 Ad-hoc solution
The use of an ad-hoc protocol is able to provide the full
range of beneﬁts of our approach. The protocol will have to
support the basic primitives to upload (put) and download
(get) a resource. The put primitive, when used to upload
the initial state of the resource, will have to provide a re-
source descriptor that deﬁnes: the identiﬁer of the key k0
used by the owner to encrypt the resource; the size of mini-
blocks and the number of fragments (which determine the
size of the macro-block); an array with an element for every
fragment describing its version. In addition to the put prim-
itive, the server will recognize the put_fragment primitive,
which will allow the owner to update a fragment. Parame-
ters of this primitive, in addition to the resource identiﬁer
and fragment content, will be the identiﬁer of the fragment
and its version number. The put_fragment primitive re-
quires the authentication of the user issuing the request, in
the same way as the put primitive.
The get primitive can return to the user the resource,
one macro-block after the other. The client will be able to
immediately start the decryption of macro-blocks, after a
preliminary decryption with key ki of the mini-blocks be-
longing to the fragments at version i > 0. In this way, the
client does not have to wait for the completion of the down-
load of all the fragments. The answer to the get request
always provides ﬁrst the resource descriptor, with the rep-
resentation of the version of each of the fragments. Among
the parameters of the get primitive we have the option to
retrieve only a speciﬁc portion of the resource.
For this solution, we have to dedicate attention to the
mapping of the logical structure to the physical represen-
tation of data. At the logical level, the resource is divided
into fragments, and the content is represented by a sequence
of macro-blocks. At the physical level, the resource can be
stored as a collection of separate fragments or as a sequence
of macro-blocks. In addition to these two options, there is
a range of intermediate alternatives, with the interleaved
representation of multiple fragments.
226 9
 8
 7
 6
 5
 4
 3
 2
 1
)
s
/
B
M
(
t
u
p
h
g
u
o
r
h
t
 0
64KB
number of fragments
1024
256
64
16
4
1
cost
get
update
)
s
(
e
m
i
t
 1000
 100
 10
 1
 0.1
256KB
1MB
4MB
16MB
64MB
256MB
1GB
1
2
4
8
16
32
64
128
256
512
1024
object size
number of fragment partitions
Figure 12: Throughput for a workload combining
get and put_fragment requests with Swift DLOs
Figure 13: Conﬁgurations for physical blocks
5.3.1 Experiments on the Ad-hoc solution
The advantage of a dedicated server is the ability to use
an eﬃcient protocol. The use of an ad-hoc server makes
the management of fragments more ﬂexible and avoids the
overheads associated with the generation of a number of in-
dependent get requests equal to the number of fragments
that are produced by the Overlay solution. Still, the use of
a potentially large number of fragments can introduce non-
negligible costs. In the extreme case where a large resource
is managed with a single macro-block (i.e., the number of
fragments corresponds to the number of mini-blocks of the
whole resource). The client will have to wait the complete
download to start decryption, and decryption will involve
a high number of rounds. Also, when only a portion of the
resource is needed, our approach requires the client to down-
load the macro-blocks that contain the portion of interest; if
macro-blocks are large, this may lead to a signiﬁcant over-
head. As already discussed, the identiﬁcation of the optimal
number of fragments has to consider several features of the
application domain. In the current technological scenario,
we notice that the use of an ad-hoc server can support a
number of fragments larger than what is adequate for the
Overlay solution, but extreme values cause ineﬃciencies.
As mentioned above, an important aspect that the imple-
mentation of the ad-hoc server has to consider is the map-
ping from the logical structure to its physical representa-
tion. In this analysis, we will consider a traditional scenario
where the server uses the functions of the operating system
to access the storage ability of mass memory devices.
In
the experiments we used the Amazon EC2 instance and its
access to the Elastic Block Storage. The operating system
oﬀers an interface that allows to read and write physical
blocks, typically a few KiB in size. The mapping of the
bidimensional logical structure with macro-blocks and frag-
ments to the concrete physical structure realized by a se-
quence of physical blocks can follow several strategies. To
compare these alternatives, we assume a scenario where we
have 1024 fragments and map the structure to 4KiB physi-
cal blocks. A ﬁrst strategy consists in storing the resource
one macro-block after the other. The dual strategy consists
in storing the resource one fragment after the other. Be-
tween these two extremes, we have strategies that split each
macro-block into a number of parts and store contiguously
into a physical disk block all the macro-block portions that
correspond to the mini-blocks in the same position. The ra-
tionale is that the organization along macro-blocks will be
the most eﬃcient to support get requests, but it will require
to access all the physical disk blocks when a put_fragment
request is received. The representation based on fragments
will instead be the most eﬃcient to support put_fragment
requests, but it will introduce a signiﬁcant overhead when
managing get requests. For small resources these aspects do
not have a large impact, whereas for large resources the per-
formance beneﬁt can be signiﬁcant. Figure 13 illustrates the
results obtained on a container with 1000 ﬁles, each of 1 GiB
in size. The horizontal axis denotes the number of shares of
each macro-block (1 represents the strategy with the macro-
blocks stored in sequence, and 1024 represents the strategy
with fragments stored in sequence). For a workload that in-
terleaves a get request for every put_fragment request, the
total cost is minimized when we use a solution with 256 frag-
ments. Interestingly, the two extremes with this workload
do not represent the best option. In these experiments, we
measured the time required to access the data from storage.
In most systems we expect the network to be the bottleneck
that limits the performance and the choice of physical rep-
resentation will rarely be observed by the clients, but the
performance beneﬁt that is shown by the experiment can
lead to a more eﬃcient implementation of the server.
6. RELATED WORK
The idea of making the extraction of the information
content of an encrypted resource dependent on the avail-
ability of the complete resource has been ﬁrst explored
by Rivest [16], who proposed the all-or-nothing transform
(AONT). The AONT requires that the extraction of a re-
source where n bits of its transformed form are missing
should require to attempt all the possible 2n combinations.
The AONT can be followed by encryption to produce an all-
or-nothing encryption schema. In [16], the author proposes
the package transform, which realizes an AONT by apply-
ing a CTR mode using a random key k. The ciphertext is
then suﬃxed with the used key k xor-ed with a hash of
all the previous encrypted message blocks.
In this way, a
modiﬁcation on the encrypted message limits the ability to
derive the encryption key. This technique works under the
assumption that the user who wants to decrypt the resource
has never accessed the key before, but fails in a scenario
where the user had previously accessed the key and now the
227access must be prevented (i.e., revocation of privileges on
encrypted ﬁles). The user, in fact, could have stored key
k and so she would be able (depending on the encryption
mode used) to partially retrieve the plaintext. Key k can
be seen as a digest:
it is compact and its storage allows a
receiver to access the majority of the ﬁle, even if one of the
blocks was destroyed.
Most approaches for eﬃcient secure deletion [5, 8] rely on
the fact that the key is a digest for a resource and its content
can be securely deleted by deleting the speciﬁc disk location
that stores a piece of information that permits to derive
the key used to encrypt the resource. Such approaches are
already used by commercial storage devices [17] and recent
proposals have considered the integration of such approaches
with ﬂexible policies [5]. All these approaches are not appli-
cable in our scenario, where the encrypted resource is stored
on a server that does not have access to (and hence does
not store) the key and it is the user who has to decrypt the
resource. Making the encryption key unavailable to the user
does not limit her access.
Other approaches for enforcing access control in the cloud
through encryption have been developed along two research
lines: attribute-based encryption (ABE) and selective en-
cryption approaches. ABE approaches (e.g., [11, 13, 15, 18])
provide access control enforcement by ensuring that the key
used to protect a resource can be derived only by the users
that satisfy a given condition on their attributes (e.g., age,
role). The main shortcoming of these solutions is due to
their evaluation costs (they rely on public key encryption),
and to the hardness in the support of revocations [13, 18].
Approaches based on selective encryption (e.g., [6, 7, 12])
assume to encrypt each resource with a key that only au-
thorized users know or can derive. In this scenario, policy
updates are then either managed by the data owner, with
considerable overhead, or delegated to the server through
over-encryption [6, 7]. Although over-encryption guarantees
a prompt enforcement of policy updates and demonstrates
to oﬀer good performance, it requires stronger trust assump-
tions on the server, which must provide dedicated support.
On the contrary, our technique can be used also if the server
is completely unaware of its adoption.
7. CONCLUSIONS
We presented an approach for eﬃciently enforcing ac-
cess revocation on encrypted resources stored at external
providers. Our solution enables data owners to eﬀectively
revoke access by simply overwriting a small portion of the
(potentially large) resource and is resilient against attacks
by users locally maintaining copies of previously-used keys.
Our implementation and experimental evaluation conﬁrm
the eﬃciency and eﬀectiveness of our proposal, which enjoys
orders of magnitude of improvement in throughput with re-
spect to resource re-writing, and conﬁrms its compatibility
with current cloud storage solutions, making it also imme-
diately applicable to many application domains.
9. REFERENCES
[1] E. Andreeva, A. Bogdanov, and B. Mennink. Towards
understanding the known-key security of block
ciphers. In Proc. of FSE, Hong Kong, Nov. 2014.
[2] M. Atallah, K. Frikken, and M. Blanton. Dynamic and
eﬃcient key management for access hierarchies. In
Proc. of CCS, Alexandria, VA, USA, Nov. 2005.
[3] A. Biryukov and D. Khovratovich. PAEQ:
Parallelizable permutation-based authenticated
encryption. In Proc. of ISC, Hong Kong, China, Oct.
2014.
[4] A. Biryukov and D. Khovratovich. PAEQ reference
v1. Technical report, CryptoLUX, University of
Luxembourg, 2014.
[5] C. Cachin, K. Haralambiev, H. Hsiao, and
A. Sorniotti. Policy-based secure deletion. In Proc. of
CCS, Berlin, Germany, Nov. 2013.
[6] S. De Capitani di Vimercati, S. Foresti, S. Jajodia,
S. Paraboschi, and P. Samarati. Over-encryption:
Management of access control evolution on outsourced
data. In Proc. of VLDB, Vienna, Austria, Sept. 2007.
[7] S. De Capitani di Vimercati, S. Foresti, S. Jajodia,
S. Paraboschi, and P. Samarati. Encryption policies
for regulating access to outsourced data. ACM TODS,
35(2):12:1–12:46, April 2010.
[8] S. Diesburg and A. Wang. A survey of conﬁdential
data storage and deletion methods. ACM Computer
Surveys, 43(1), Dec. 2010.
[9] M. Dworkin. Recommendation for block cipher modes
of operation, methods and techniques. Technical
Report NIST Special Publication 800-38A, National
Institute of Standards and Technology, 2001.
[10] K. Fu, S. Kamara, and Y. Kohno. Key regression:
Enabling eﬃcient key distribution for secure
distributed storage. In Proc. of NDSS, San Diego, CA,
USA, Feb. 2006.
[11] V. Goyal, O. Pandey, A. Sahai, and B. Waters.
Attribute-based encryption for ﬁne-grained access
control of encrypted data. In Proc. of CCS,
Alexandria, VA, USA, Oct.-Nov. 2006.
[12] I. Hang, F. Kerschbaum, and E. Damiani. ENKI:
Access control for encrypted query processing. In
Proc. of SIGMOD, Melbourne, Australia, May 2015.
[13] J. Hur and D. Noh. Attribute-based access control
with eﬃcient revocation in data outsourcing systems.
IEEE TPDS, 22(7):1214–1221, July 2011.
[14] M. Luby and C. Rackoﬀ. How to construct
pseudorandom permutations from pseudorandom
functions. SIAM J. Comp., 17(2):373–386, Apr. 1988.
[15] Z. Peterson, R. Burns, J. Herring, A. Stubbleﬁeld, and
A. Rubin. Secure deletion for a versioning ﬁle system.
In Proc. of FAST, San Francisco, CA, USA, Dec. 2005.
[16] R. Rivest. All-or-nothing encryption and the package
transform. In Proc. of FSE, Haifa, Israel, Jan. 1997.
[17] TCG storage security subsystem class: Opal, Aug.
8. ACKNOWLEDGMENTS
2015.
This work was supported by the EC within the H2020 un-
der grant agreement 644579 (ESCUDO-CLOUD) and within
the FP7 under grant agreement 312797 (ABC4EU).
[18] S. Yu, C. Wang, K. Ren, and W. Lou. Attribute based
data sharing with attribute revocation. In Proc. of
ASIACCS, Beijing, China, April 2010.
228