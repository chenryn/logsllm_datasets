Our problem definition is based on the Privilege Error Minimiza-
tion Problem (PEMP) originally defined in [16] for creating least
privilege RBAC policies which consisted of users, operations, and
objects. Like the original PEMP, our problem seeks to minimize the
under- and over-privilege assignment errors in policies and uses
the notions of observation and operation periods for evaluation.
However, users, operations, and resources are only some of the at-
tributes available when creating ABAC policies; therefore, a unique
problem definition in the ABAC privilege space is needed.
The size of an ABAC privilege space is determined by the at-
tributes and values of valid ABAC policies. A is the set of valid at-
tributes which can be used in policies. As in related works [5, 14, 21],
we assume all attributes and values existing in the logs can also
be used in policies. Each individual attribute ai ∈ A has a set
of atomic values Vi which are valid for that attribute. All val-
ues for an attribute are the attribute’s range Ranдe(ai) = Vi. The
Cartesian product of all possible attribute:value combinations is
ξ = V1 × ... × Vn = {(v1, ..., vn)|vi ∈ Vi for every i ∈ {1, ..., n}}.
However, some attribute:value pairs are not valid when present in
combination with other attribute:value pairs because of dependen-
cies between them. For example, some operations are only valid on
certain resource types so combinations such as operation:DeleteUser
and resourceType:File are not valid. The valid privilege universe ξ‘
is the set of all possible attribute:value combinations when con-
sidering the dependency relationships between all attributes and
values.
Any measure of security policy accuracy must also take time into
account because the amount of risk from over-privilege accumu-
lates over time. Over-privilege carries the risk that an unnecessary
privilege will be misused, and this risk increases the longer the over-
privilege exists. To capture risk across a specified time period, we
define the Operation Period (OPP) as the time period during which
security policies are evaluated against user operations. With the
valid privilege universe ξ‘ and the operation period OPP defined, we
now define the ABAC version of the Privilege Error Minimization
Problem PEMPABAC (Definition 1).
Definition 1. PEMPABAC: ABAC Privilege Error Minimization
Problem. Given the universe of all valid attribute:value combinations
ξ ′, find the set of attribute:value constraints that minimizes the over-
privilege and under-privilege errors for a given operation period OPP.
3.2 Evaluation Metrics
We use terminology from statistical hypothesis testing for evaluat-
ing the effectiveness in addressing the PEMPABAC. We first present
our method for scoring individual predictions, and then our method
for splitting up the dataset and evaluating the performance over
multiple time periods.
Scoring Individual Predictions. Policy evaluation for a given
3.2.1
operation period is a two-class classification problem where every
possible event in the ABAC privilege space falls into one of two
possible classes: grant or deny. By applying the policies generated
from the observation period data to the privileges exercised in the
operation period, we can categorize each prediction into one of
four outcomes:
• True Positive (TP): a privilege that was granted in the predicted
• True Negative (TN): a privilege that was denied in the predicted
• False Positive (FP): a privilege that was granted in the predicted
policy and not exercised during the OPP.
policy and exercised during the OPP.
policy but not exercised during the OPP.
• False Negative (FN): a privilege that was denied in the predicted
policy but attempted to be exercised during the OPP.
Using the above outcomes we then calculate True Positive Rate
(TPR) also known as Recall and False Positive Rate (FPR) as shown
in Formulas 1 and 2, respectively:
T PR =
T P
(T P + F N)
(1)
F PR =
F P
(F P + T N)
(2)
RBAC mining in [16] used metrics based on TPR and Precision,
while our ABAC mining has to use TPR and FPR instead. Precision
( T P
T P +F P ) is suitable when considering the users and operations be-
cause the universe of possible grants is roughly on the same order of
magnitude as the number of unique log events. When dealing with
the ABAC universe, the number of possible unique attribute:value
combinations is likely to be many orders of magnitude greater than
the number of events in the operational logs. Precision is not a
suitable metric for use in mining ABAC policies from logs because
it uses one term (TP) which is driven primarily by the number of
entries in the log, and another term (FP) which is driven by the size
of the privilege universe. On the other hand, both terms in the TPR
(TP and FN) are log derived, and both terms in FPR (FP and TN) are
policy derived metrics.
TPR and FPR are the metrics used to evaluate a policy in terms
of under-privilege and over-privilege, respectively. If all privileges
exercised in the OPP were granted, there was no under-privilege
for the policy being evaluated so F N = 0, and T PR = 1. As the
number of erroneously denied privileges (FNs) grows, T PR → 0,
thus TPR represents under-privilege. If all privileges granted by the
policy were exercised during the OPP, there was no over-privilege
for the policy being evaluated so F P = 0 and F PR = 0. As the
number of erroneously granted privileges (FPs) grows, F PR → 1,
thus FPR represents over-privilege.
is a known value for the number of possible resources in the system.
This presents a challenge to any least-privilege scoring approach,
and not just to the ABAC model or our methodology. While every
system has finite limits on the resource identifier length and number
of resources, these can be so numerous that we consider them as
too large to quantify and treat them as being infinite. For example,
consider the number of possible file names in an ext4 file system
with up to 255 bytes for a file name, 28255 possible distinct file
names exist excluding the path [13].
Instead of counting all possible resource identifiers, we use the
resource identifiers existing in the OBP and OPP for our policy
scoring calculations. This approach presents several advantages
over other possible approaches such as using all values in a dataset,
or introspecting an environment for the resource identifiers (which
would be prohibitively time consuming for our work). Only the
recently used resources are counted, giving them greater impor-
tance, and all necessary data is available in the audit logs. This also
implies that the valid privilege space ξ‘ may vary in size between
scoring periods depending on the resource identifiers present.
4 METHODOLOGY
This section presents our rule mining algorithm for addressing the
PEMPABAC problem, policy scoring algorithm for evaluating the
policies across multiple operation periods, and optimization meth-
ods for processing large ABAC privilege spaces. Before going into
the details, we first describe the overall workflow of our approach
for mining least privilege ABAC policies as shown in Figure 1.
Scoring Policies Across Multiple Time Periods. To score poli-
3.2.2
cies across multiple time periods, we use out-of-time validation [10],
a temporal form out-of-sample validation. In out-of-sample valida-
tion, a set of data is used to train an algorithm (training set) and a
separate set of non-overlapping data is used to test the performance
of the trained algorithm (test set). In our evaluation, the training
and test sets are contiguous, and the test time period immediately
follows the training time period. The training set is referred to as
the Observation Period (OBP), while the test set is the Operation
Period (OPP) defined previously in Section 3.1. It is important to
note that this method preserves the temporal interdependencies be-
tween actions. For example, if an employee moves to a new position
within the organization, one would expect the privileges mined for
that employee in the future time periods would be very different
from those mined in the past time periods. Methods such as k-fold
cross validation which randomly partition a dataset (as used in [12]
for evaluating policies) do not account for these temporal interde-
pendencies. When charting metrics for multiple time periods, we
use the average of all individual scores. This gives equal weight to
each operation period score.
Scoring Infinite Possible Resource Identifiers. Quantifying the
3.2.3
number of resources allowed or denied by a policy implies that there
Figure 1: Overall Workflow of our Approach
A system under operation or in testing will continuously gener-
ate audit log events for access requests (either allowed or denied).
The events of any chosen Observation Period (OBP) will be the in-
put to the ABAC Rule Mining Algorithm, which generates an ABAC
policy with a set of rules as the output. This policy is then scored
against a subsequent Operation Period (OPP) of audit log events
to evaluate its performance as if it were put into operation. If this
policy can better balance or minimize under- and over-privilege, it
would be deployed to the system. This is an iterative and continu-
ous process, so that a newly deployed policy can also be adaptive
to user behavior and situation changes over time.
This workflow can be easily bootstrapped as long as the system
generates audit log events. It does not depend on the model (e.g.,
AuditLogABAC Rule Mining Algorithmdeploy, updateABAC Policy with RulesSystem of an Organization (e.g., services deployed in the cloud)Original Access Control Policy to be Replaced(could be from any model with any default policy such as “allow all”)ABAC Policy Scoring AlgorithmABAC Policy Deployment and EnforcementOBPOPPRBAC or ABAC), content, and even the existence of an original
access control policy. For example, an administrator may choose to
begin with a simple “allow all” style of policy based on whatever
model. Our approach will then periodically mine a new ABAC
policy, evaluate its performance (quantitatively regarding the level
of under- and over-privilege if the policy were deployed), and deploy
or update an improved policy to the system either automatically or
with the confirmation from the administrator.
4.1 Rule Mining
Our rule mining algorithm operates similarly to the mining algo-
rithms presented in [12, 21] in that it considers the set of uncovered
log entries and iteratively generates many candidate rules, scores
them, and selects the best scoring rule for the next iteration until
all of the given log events are covered by the set of generated rules.
A critical component of this approach is the metric used to evaluate
candidate rules. Before describing the algorithm design, we will
first detail the metric used for evaluating candidate rules generated
during the mining process. We propose a candidate scoring metric
termed Cscor e using the following definitions.
• c is an ABAC constraint specified as a attribute:value pair, or a
key with a set of values key:{values}. Values must be discrete,
so continuous ones should be binned to be used by the mining
algorithm. r is a rule consisting of one or more constraints. p is a
policy consisting of one or more rules.
• L is the complete set of log entries for the dataset, LOBP is the
set of logs in the observation period OBP; LOBP ⊆ L.
• LOBP(C) is the set of log entries which meet (i.e., are “covered
by”) the constraints in a set C that can be specified by the use of
a rule r or policy p; LOBP(C) ⊆ LOBP .
• ξ ′ is the privilege universe of valid log events as defined previ-
ously in Section 3.1.
The CoverageRate (Formula 3) is the ratio of all logs in the ob-
servation period covered by a candidate rule r but not already
covered by other rules in the policy p (|LOBP(r) \ LOBP(p)|) to the
remaining number of log entries not covered by any rules in the
policy (|LOBP \ LOBP(p)|). A candidate rule that covers more log
entries is considered higher quality than a rule that covers fewer log
entries. The numerator of the OverPrivilegeRate (Formula 4) finds
the number of valid attribute:value combinations in the privilege
universe covered by a rule (ξ‘(r)) minus the set LOBP(r)\ LOBP(p),
resulting the total number of over-assignments for rule r. The total
over-assignments are then normalized upon the total number of
combinations in the valid privilege universe |ξ ′|. A candidate rule
which has fewer over-assignments is considered higher quality
than a rule that has more over-assignments.
CoveraдeRate(r, p, LOBP) =
|LOBP(r) \ LOBP(p)|
|LOBP \ LOBP(p)|
OverPrivileдeRate(r, p, LOBP , ξ
′) =
|ξ ′(r) \ (LOBP(r) \ LOBP(p))|
|ξ ′|
(3)
(4)
The candidate score Cscor e (Formula 5) is then the ω weighted
addition of the CoverageRate and the complement of the OverPrivi-
legeRate. By normalizing the under-assignments using the number
of log entries and the over-assignments using the size of the valid
privilege universe, the effect of varying the weight ω in Cscor e is
more predictable and better performance can be achieved when
compared to the λ−Distance metric which also uses a variable
weighting between over-assignments and under-assignments but
does not normalize these values (see Section 5.2 for the Cscor e vs.
λ−Distance comparison details).
Cscor e(r, p, LOBP , ξ
′
, ω) = CoveraдeRate(r, p, LOBP)+
′))
ω × (1 − OverPrivileдeRate(r, p, LOBP , ξ
(5)
Our algorithm for mining an ABAC policy from the logs of a
given observation period is presented in Algorithm 1. Note that we
use arithmetic operators =, +,− when describing integer operations,
and set operators ←,∪,\, ∈, |...| when describing set operations. As
mentioned previously, the algorithm iteratively generates candidate
rules from the set of uncovered logs. To avoid confusion between
the original set of log entries for the observation period LOBP and
the current set of uncovered log entries which is updated for each
iteration of the algorithm, we copy LOBP to Luncov at line 2. The
FP-growth algorithm [6] is used to mine frequent itemsets from the
set of uncovered observation period log entries (line 4). The itemsets
returned by the FP-growth algorithm are sets of attribute:value
statements, and each of these itemsets is used to create a candidate
rule which is then scored using the Cscor e metric (lines 6-12). After
all candidates are scored, the highest scoring rule is selected and
added to the policy, then all log entries covered by that rule are
removed from the set of uncovered log entries (lines 13-15). This
process continues until all log entries are covered (lines 3-16).
4.2 Policy Scoring
Once the observation period logs have been mined to create a
policy, that policy is scored using the events that took place during
the operation period immediately following the mined observation
period as described in Algorithm 2. Each event during the operation
period is evaluated against the mined policy (lines 3-10). Events
allowed by the policy are TPs, while events denied by the policy
are FNs. A unique combination of attribute:value pair may occur
multiple times within the same time period. The TPs and FNs are
both values based on the number of times an event occurs in the log.
The set of unique events that were exercised in the operation period
and granted by the policy is also maintained (line 6) in order to
calculate the FPs later (line 15). By counting each TP and FN instead
of unique occurrences, the resulting TPR is frequency weighted.
Events that occur more frequently in the operation period have a
greater impact on TPR than those events that occur less frequently.
While the TPs, FNs, and resulting TPR are based on the frequency
weighted count of events present in the log, the FPs, TNs and
resulting FPR cannot be frequency weighted because each unique