### Optimized Text

#### Introduction
Honeynet traffic analysis is a valuable tool for assessing the significance of observed events at a site. The authors highlight the potential benefits of such analysis, which relies heavily on visualization techniques. In this work, we aim to advance this field by developing a comprehensive "toolkit" for analyzing specific features of large-scale honeynet events. Our toolkit will include methods and a general framework to automatically or semi-automatically derive conclusions from honeynet data.

#### Comparison with DShield
DShield is the largest global alert repository on the Internet [27]. However, our approach offers several advantages over DShield:

1. **Data Quality**: DShield data is often noisy, and sensor density is non-uniform. This makes it challenging to draw reliable inferences from the data.
2. **Pollution and Avoidance**: DShield is susceptible to pollution and avoidance [9], which can compromise its reliability for operational security.
3. **Target Scope**: For small target scopes, it is difficult to find other sensors in DShield that share the same behavior, making DShield less effective in such scenarios.

#### State of the Art
While significant progress has been made in building honeynet systems, the analysis of large-scale events captured by these systems is still in its early stages. The Honeynet project has developed tools for host-level honeypot analysis [2]. At the network level, Honeysnap [3] analyzes individual connections, particularly for investigating IRC traffic used for botnet command-and-control. These approaches typically focus on single instances of activity or on the study of specific botnets over time (e.g., [24]). In contrast, our paper aims to understand the significance of single, large-scale events as seen by honeynets. Such activity inherently requires integrated analysis across multiple instances but is also localized in time.

Furthermore, the literature includes several forensic case studies analyzing specific large-scale events, particularly worms [16, 20]. These case studies often benefit from prior knowledge of the underlying mechanisms generating the traffic of interest. Our goal, however, is to infer these mechanisms from a starting point of more limited knowledge.

Gu et al. propose a series of botnet detection techniques based on behavior correlation [12, 13]. In contrast, we focus on inferring botnet properties after detection, rather than the detection itself.

#### Conclusions
In this paper, we present several algorithms that can automatically analyze and determine the features of large-scale events observed at a honeynet. Specifically, we develop techniques for recognizing botnet scanning strategies and inferring the global properties of distributed scans. An evaluation of our tools using extensive honeynet and DShield data demonstrates the potential of our approach to contribute to a site's "situational awareness," including the crucial question of whether a large probing event detected by the site reflects broader, indiscriminate activity or an attacker who has explicitly targeted the site.

#### Acknowledgments
We would like to thank Vinod Yegneswaran and Ruoming Pang for their help in collecting the data and implementing the Bro payload summary scripts. We also thank the operations staff of the Lawrence Berkeley National Laboratory for facilitating the LBNL honeypot setup and anonymous reviewers for their valuable comments. This work was supported by DOE CAREER award DE-FG02-05ER25692//A001, DOD (Air Force of Scientific Research) Young Investigator Award FA9550-07-1-0074, and NSF grants NSF-0433702 and CNS-0627320. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the funding sources.

#### References
[References remain unchanged]

#### Appendix A: Modeling How Bots Scan

**A.1 Bot Source Code Study**
By analyzing the source code of five popular families of bots, we study different dimensions of scan strategies employed by botnets. The popularity of these five bot families is confirmed in [6, 7]. Our findings confirm those in [7], but we focus more on scan pattern study.

| Botnet Name | Global | Local | Hit-list | Independent & Uniform | Sequential | # of Lines | Modularity |
|-------------|--------|-------|----------|-----------------------|------------|------------|------------|
| Agobot      | Yes    | Yes   | Possible | Yes                   | No         | 3093       | Low        |
| Phatbot     | Yes    | Yes   | Possible | Yes                   | No         | 16855      | Medium     |
| Spybot      | Yes    | Yes   | Possible | Yes                   | No         | 21629      | High       |
| SDBot       | Yes    | Yes   | Possible | Yes                   | No         | 7371       | Low        |
| rxBot       | Yes    | Yes   | Possible | Yes                   | Yes        | 19021      | High       |

Table 8 shows the scan strategies and complexity of the bot families. Some of them are modularly well-designed. Currently, these bot families mainly use simple scanning strategies. Each supports both global scanning (a specified address block) and local scanning (relative to each bot’s address). By hit-list scanning, we refer to an event where the attacker appears to have previously acquired a specific list of targets. Such scans may heavily favor the use of "live" addresses (those that respond) over "dark" (non-responsive) addresses. The five bot families we analyzed do not directly automate hit-list scanning, but an attacker can achieve this via two steps: first, scanning to gather a list of live addresses/blocks, and then specifying these at the command line. Additionally, most bot families support uniformly random and sequential scanning of the designated addresses or blocks.

Our dataset analysis aligns with the above capabilities: most scanners we observe use either simple sequential scanning (IP address increments by one between scans) or independent uniform random scanning. We occasionally observe more sophisticated monotonic trends (address incrementing by k), but very infrequently. We also frequently observe botnets using hit-list scanning.

**A.2 Modeling Botnet Global Scanning**
There is a large design space for botmasters when developing scan strategies, but we expect the following features to be generally desired:

- **Coverage**: Fully cover the target scope.
- **Load Distribution**: Distribute the load based on bots’ capabilities.
- **Low Communication Overhead**: Minimize coordination communication.
- **Scan Detection Evasion**: Avoid aggressive scanning of a small address range to evade detection and blocking by IDS/IPS systems.
- **Redundancy**: Ensure multiple bots scan the same addresses to account for potential loss of bots.

A similar analysis is proposed in [19] for worms. Given these desired features, a simple and effective approach is to have each bot independently scan the specified range in a random uniform fashion. This approach can achieve scan detection evasion, low communication overhead, and load distribution while providing good coverage and redundancy. Most of the events in our datasets are close to uniform scanning.

**Advanced Scanning Strategies**
By introducing some simple coordination between bots, one can improve both coverage and redundancy beyond random uniform scanning. An advanced scanning strategy, called "worm scan permutation," was proposed in the context of worm propagation [28]. However, this strategy is optimized for worms and does not consider the usage of C&C channels of botnets. Using the botnet C&C, we propose a better scan strategy called Advanced Botnet Permutation Scan (ABPS). Each bot permutes the whole scanning scope in the same way with a key from the botmaster. Based on bots’ capabilities, the botmaster divides the replicates of the permuted IP scope among all the bots. This can achieve much better coverage and redundancy. We simulate and evaluate this strategy in our evaluation.

#### Appendix B: Proof of Theorem 1
**Proof:**
There are \( d^n \) ways to distribute \( n \) scans into \( d \) addresses. If there are \( X_0 \) ways which have \( z_0 \) addresses receiving zero scans (i.e., \( z_0 \) empty slots), then we know \( P(z_0) = \frac{X_0}{d^n} \). We will show that for a given \( z_0 \), \( X_0 \) is:
\[ X_0 = \binom{d}{z_0} \cdot S(n, d - z_0) \cdot (d - z_0)! \]
where \( S(n, m) \) denotes the Stirling number of the second kind, which represents the number of ways to partition a set of \( n \) elements into \( m \) nonempty sets [29].

In \( d \) addresses, there are \( \binom{d}{z_0} \) configurations to select which \( z_0 \) addresses got zero scans. Each configuration has \( z_0 \) addresses that received zero scans and \( d - z_0 \) addresses that received non-zero scans. After partitioning the \( n \) scans into \( d - z_0 \) sets, there are \( (d - z_0)! \) ways to map the sets to the addresses. Therefore, for each configuration, we have \( S(n, d - z_0) \cdot (d - z_0)! \) ways to distribute the \( n \) scans into \( d - z_0 \) addresses. Hence, we have:
\[ X_0 = \binom{d}{z_0} \cdot S(n, d - z_0) \cdot (d - z_0)! \]

#### Appendix C: Proof of Theorems 2 and 3
**Proof of Theorem 2:**
**Theorem 2:** \( \hat{\theta} \) is an unbiased estimator for \( \theta \).

**Proof:**
\[ E(\hat{\theta}) = E\left( \sum_{i=1}^{m_0} \frac{n_i}{R G_i T_i} \right) = \sum_{i=1}^{m_0} E\left( \frac{n_i}{R G_i T_i} \right) \]

As mentioned, \( n_i \) is the number of scans we see if we sample from \( R G_i T_i \) total scans with probability \( \theta \), which follows a binomial distribution. Hence, we have \( E(n_i) = \theta \cdot R G_i T_i \). Therefore,
\[ E\left( \sum_{i=1}^{m_0} \frac{n_i}{R G_i T_i} \right) = \sum_{i=1}^{m_0} \frac{E(n_i)}{R G_i T_i} = \sum_{i=1}^{m_0} \frac{\theta \cdot R G_i T_i}{R G_i T_i} = \theta \]

**Proof of Theorem 3:**
**Theorem 3:** \( \text{Var}(\hat{\theta}) = \frac{\theta (1 - \theta)}{\sum_{i=1}^{m_0} R G_i T_i} < \text{Var}\left( \frac{n_i}{R G_i T_i} \right) \), i.e., the accuracy of the \( \theta \) estimator when aggregating over all \( m_0 \) senders is higher than that of each and every single sender.

**Proof:**
\[ \text{Var}(\hat{\theta}) = \text{Var}\left( \sum_{i=1}^{m_0} \frac{n_i}{R G_i T_i} \right) = \sum_{i=1}^{m_0} \text{Var}\left( \frac{n_i}{R G_i T_i} \right) \]

Since \( n_i \) follows a binomial distribution, we have \( \text{Var}(n_i) = \theta \cdot (1 - \theta) \cdot R G_i T_i \). Therefore,
\[ \text{Var}\left( \sum_{i=1}^{m_0} \frac{n_i}{R G_i T_i} \right) = \sum_{i=1}^{m_0} \frac{\text{Var}(n_i)}{(R G_i T_i)^2} = \sum_{i=1}^{m_0} \frac{\theta \cdot (1 - \theta) \cdot R G_i T_i}{(R G_i T_i)^2} = \theta \cdot (1 - \theta) \cdot \sum_{i=1}^{m_0} \frac{1}{R G_i T_i} \]

On the other hand,
\[ \text{Var}\left( \frac{n_i}{R G_i T_i} \right) = \frac{\text{Var}(n_i)}{(R G_i T_i)^2} = \frac{\theta \cdot (1 - \theta) \cdot R G_i T_i}{(R G_i T_i)^2} = \frac{\theta \cdot (1 - \theta)}{R G_i T_i} \]

Therefore,
\[ \text{Var}(\hat{\theta}) = \frac{\theta \cdot (1 - \theta)}{\sum_{i=1}^{m_0} R G_i T_i} < \frac{\theta \cdot (1 - \theta)}{R G_i T_i} = \text{Var}\left( \frac{n_i}{R G_i T_i} \right) \]

This completes the proof.