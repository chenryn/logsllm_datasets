o
i
t
a
r
e
p
O
(
t
u
p
h
g
u
o
r
h
T
 16000
 14000
 12000
 10000
 8000
 6000
 4000
 2000
 0
 0
 20
 40
 60
 80
 100
 120
 140
 160
 180
 200
cbase
base
Fig. 4. Overhead of CBASE versus BASE
Number of clients
yielding a CPU overhead of less than 100 µs per re-
quest. CBASE runs with 16 execution threads and BASE
runs with 1 thread. All points in the graph are aver-
ages of 3 runs with variance of less than 15%. The CBASE
parallelizer treats all requests as independent, but lim-
ited hardware resources limit
the beneﬁts gained by
concurrency—requests run on a uniprocessor and re-
turn immediately. Figure 4 shows that the lines representing
CBASE and BASE closely follow each other illustrat-
ing that CBASE introduces little overhead when there is no
scope for concurrent execution of requests.
6.1.2. Scalability of throughput with application paral-
lelism and resources The throughput of a service depends
both on the parallelism present in the application and on
the hardware resources (e.g., processors, disks, bandwidth)
available to the system. In this set of experiments, we eval-
uate the scalability of throughput with varying application
parallelism and hardware resources.
First, we evaluate the ability to scale throughput with re-
sources. We simulate accesses to a varying array of parallel
disks by running the benchmark with the modiﬁcation that
the code to process each request sleeps for 20ms before re-
turning a reply. The CBASE parallelizer assumes inﬁnite
parallelism in the application and considers all requests to
be independent. We simulate varying “disk” resources by
conﬁguring CBASE to run with varying numbers of exe-
cution threads. We note that BASE still runs with a single
thread since it never attempts to issue more than one re-
quest to the execution stage at a time. Figure 5(a) shows
that the throughput of BASE saturates at 50 ops/sec (as ex-
pected with 20ms service time for each operation) which
matches the throughput of CBASE running with 1 thread.
The throughput of CBASE increases with the number of
clients but eventually saturates because increasing the num-
ber of clients improves concurrency only if throughput is
limited by the available hardware resources. As the number
of “disks” (threads) increases, the throughput of CBASE in-
creases nearly linearly—128 “disks” reach a throughput of
"cbase_1thread"
"cbase_2threads"
"cbase_8threads"
"cbase_16threads"
"cbase_64threads"
"cbase_128threads"
"base"
 50
 100
 150
 200
Number of clients
(a)
cbase with parallelism=1
cbase with parallelism=5
cbase with parallelism=10
cbase with parallelism=20
cbase with parallelism=50
cbase with parallelism=100
cbase with parallelism=150
cbase with parallelism=inf
base
 5000
 4500
 4000
 3500
 3000
 2500
 2000
 1500
 1000
 500
 0
 0
 5000
 4500
 4000
 3500
 3000
 2500
 2000
 1500
 1000
 500
)
c
e
s
r
e
p
s
n
o
i
t
a
r
e
p
O
(
t
u
p
h
g
u
o
r
h
T
)
c
e
s
r
e
p
s
n
o
i
t
a
r
e
p
O
(
t
u
p
h
g
u
o
r
h
T
 0
 0
 20
 40
 60
 120
 140
 160
 180
 80
 100
Number of clients
(b)
Fig. 5. Scalability of throughput
4700 requests/second.
Next, we evaluate the scalability of throughput with par-
allelism in the application. We run the same experiment as
above except that we ﬁx the number of resources in this ex-
periment and vary parallelism in the application. We emu-
late 100 resources by ﬁxing the number of CBASE execu-
tion threads to 100. We deﬁne the parallelism factor as the
number of requests that we allow to be executed concur-
rently, and simulate varying application parallelism by vary-
ing this parameter. The parallelizer randomly assigns each
incoming requests to one of parallelism factor buckets and
creates dependencies among all requests to the same bucket,
allowing only a ﬁxed number of requests to be independent
at any point of time. Figure 5(b) shows that the throughput
of BASE saturates at 50 ops/sec and that CBASE matches
this performance when the application parallelism factor is
1. CBASE’s maximum throughput increases almost linearly
with increasing parallelism factor up to 100. The through-
put of CBASE does not improve beyond a parallelism fac-
tor of 100 because it is limited by the 100 simulated hard-
ware resources.
Notice that when application parallelism and hardware
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 10:04:03 UTC from IEEE Xplore.  Restrictions apply. 
BASE-FS
CBASE-FS
NFS
 1e+06
Throughput (bytes/sec)
(a)
 1e+07
BASE-FS
CBASE-FS
NFS
 60
 50
 40
 30
 20
 10
 100000
 500
 450
 400
 350
 300
 250
 200
 150
 100
 50
)
s
m
(
e
m
i
t
e
s
n
o
p
s
e
R
)
s
m
(
e
m
i
t
e
s
n
o
p
s
e
R
 10000
 100000
 1e+06
 1e+07
Throughput (bytes/sec)
(b)
Fig. 6. Throughput versus response time with 4KB
writes
whereas the throughput of NFS saturates around 4MB/sec.
In this experiment, because servers run on a uniproces-
sor system and write asynchronously to the local disk there
is little or no beneﬁt for concurrently executing the re-
quests because the threads write in the ﬁle buffer cache in
memory and rarely block. Hence we show that CBASE-FS
performs as well as BASE-FS and adds little or no over-
head when there is no scope in concurrency. The max-
imum throughput of BASE and CBASE is within a
factor of 2 compared to unreplicated NFS;
the differ-
ence stems from the extra overhead of processing protocol
messages, additional cryptographic computations, and ex-
tra kernel crossings. For similar reasons, NFS also yields
less latency than BASE and CBASE.
Beneﬁts of Pipelining with artiﬁcial delay In this experi-
ment we evaluate the performance when there is scope for
concurrent execution of requests. We simulate this scenario
by making BASE and CBASE servers sleep for 20 ms af-
ter writing to a ﬁle and before sending a reply to the client.
Figure 6(b) shows the response time plotted against the
throughput of BASE, CBASE and NFS. The throughput of
BASE saturates at about 90 KB/sec since it cannot execute
more than 1 request at a time. However, CBASE achieves its
maximum throughput of about 2MB/sec when there is sufﬁ-
cient load on the system to run enough concurrent requests
to achieve this throughput, which is almost 20 times more
than that of the throughput of BASE. We did not modify the
NFS implementation to sleep for 20 ms so its performance
remains the same. This experiment shows that CBASE-FS
does orders of magnitude better than BASE-FS when there
is scope for concurrent execution of requests.
resources are available, CBASE’s throughput can exceed
BASE’s by orders of magnitude.
6.2. NFS Micro-Benchmarks
In this subsection, we evaluate the performance of
CBASE-FS, a replicated NFS that uses CBASE. We com-
pare the performance of CBASE-FS with BASE-FS and
unreplicated NFS.
6.2.1. Local disk In this benchmark, each client writes
4KB of data to a different ﬁle in a directory exported by
the ﬁle system. We vary the number of concurrent clients
and measure the response time and throughput of the sys-
tem. As described in Section 4, requests to different ﬁles