M∗ = argmin
M
subject to: argmax
|EM(д(s + n)) − 0.5|
{sj}
{sj + nj} = argmax
j
j
EM(d(s, s + n)) ≤ ϵ

sj + nj ≥ 0,∀j
sj + nj = 1,
(1)
(2)
(3)
(4)
(5)
j
where the objective function of the optimization problem is to
achieve Goal I and the constraints are to achieve Goal II. Specifically,
j nj = 0 since
is equivalent to
the first constraint means that the added noise does not change
the predicted label of the query data sample; the second constraint
means that the confidence score distortion is bounded by the budget
ϵ; and the last two constraints mean that the noisy confidence score
vector is still a probability distribution. Note that the last constraint
j sj = 1. Moreover, we adopt L1-
norm of the noise vector to measure the confidence score distortion,
i.e., d(s, s + n) = ||n||1.
4 OUR MemGuard
4.1 Overview
Finding the randomized noise addition mechanism is to solve the
optimization problem in Equation 1. We consider two scenarios
depending on whether д(s) is 0.5 or not.
Scenario I: In this scenario, д(s) = 0.5. For such scenario, it is easy
to solve the optimization problem in Equation 1. Specifically, the
mechanism that adds the noise vector 0 with probability 1 is the
optimal randomized noise addition mechanism, with which the
objective function has a value of 0.
Scenario II: In this scenario, д(s) is not 0.5. The major challenge
to solve the optimization problem in this scenario is that the ran-
domized noise addition mechanism is a probability distribution
over the continuous noise space for a given true confidence score
vector. The noise space consists of the noise vectors that satisfy
the four constraints of the optimization problem. As a result, it is
challenging to represent the probability distribution and solve the
optimization problem. To address the challenge, we observe that
the noise space can be divided into two groups depending on the
output of the defense classifier’s decision function д. Specifically,
for noise vectors in one group, if we add any of them to the true
confidence score vector, then the decision function д outputs 0.5
as the probability of being member. For noise vectors in the other
group, if we add any of them to the true confidence score vector,
then the decision function д outputs a probability of being member
that is not 0.5.
Based on this observation, we propose a two-phase framework
to approximately solve the optimization problem. Specifically, in
Phase I, for each noise group, we find the noise vector with min-
imum confidence score distortion (i.e., d(s, s + n) is minimized)
as a representative noise vector for the noise group. We select the
noise vector with minimum confidence score distortion in order
to minimize the confidence score distortion. Since д(s) (cid:44) 0.5, the
selected representative noise vector for the second noise group is 0.
We denote by r the selected representative noise vector for the first
noise group. In Phase II, we assume the randomized noise addition
mechanism is a probability distribution over the two representative
noise vectors instead of the overall noise space. Specifically, the de-
fender adds the representative noise vector r to the true confidence
score vector with a certain probability and does not add any noise
with the remaining probability.
Next, we introduce our Phase I and Phase II.
4.2 Phase I: Finding r
Finding r as solving an optimization problem: Our goal essen-
tially is to find a noise vector r such that 1) the utility loss of the
confidence score vector is minimized and 2) the decision function
д outputs 0.5 as the probability of being member when taking the
noisy confidence score vector as an input. Formally, we find such
noise vector via solving the following optimization problem:
d(s, s + r)
subject to: argmax
min
r
{sj + rj} = argmax
j
j
д(s + r) = 0.5

sj + rj ≥ 0,∀j
rj = 0,
{sj}
(6)
(7)
(8)
(9)
(10)
j
where s is the true confidence score vector, the objective function
means that the confidence score distortion is minimized, the first
constraint means that the noise does not change the predicted la-
bel of the query data sample, the second constraint means that
the defense classifier’s decision function outputs 0.5 (i.e., the de-
fense classifier’s prediction is random guessing), and the last two
constraints mean that the noisy confidence score vector is still a
probability distribution.
Solving the optimization problem in Equation 6 can be viewed
as finding an adversarial example to evade the defense classifier. In
particular, s is a normal example and s + r is an adversarial exam-
ple. The adversarial machine learning community has developed
many algorithms (e.g., [10, 19, 31, 35, 39, 40, 50, 63]) to find adver-
sarial examples. However, these algorithms are insufficient to our
problem because they did not consider the unique challenges of pri-
vacy protection. In particular, they did not consider the utility-loss
constraints, i.e., the constraints in Equation 7, Equation 9, and Equa-
tion 10.
One naive method (we call it Random) to address the challenges
is to generate a random noise vector that satisfies the utility-loss
constraints. In particular, we can generate a random vector r′ whose
entries are non-negative and sum to 1. For instance, we first sample
a number r′
1 from the interval [0,1] uniformly at random as the
first entry. Then, we sample a number r′
2 from the interval [0, 1-r′
1]
uniformly at random as the second entry. We repeat this process
until the last entry is 1 minus the sum of the previous entries. Then,
we exchange the largest entry of r′ to the position j to satisfy the
constraint 7. Finally, we treat r = r′ − s as the noise vector, which
is a solution to the optimization problem in Equation 6. However,
as we will show in experiments, this Random method achieves
suboptimal privacy-utility tradeoffs because the noise vector is
not optimized and it is challenging to satisfy the constraint Equa-
tion 9. We propose to solve the optimization problem via change of
variables and adding the constraints to the objective function.
Eliminating the constraints on probability distribution via
change of variables: Since we consider the target classifier to
be a neural network, whose output layer is a softmax layer, the
true confidence score vector s is a softmax function of some vector
z. The vector z is the output of the neurons in the second-to-last
layer of the neural network and is often called logits of the neural
network. Formally, we have:
s = so f tmax(z).
(11)
s + r = so f tmax(z + e),
Moreover, we model the noisy confidence score vector as follows:
(12)
where e is a new vector variable. For any value of e, the noisy
confidence score vector s + r is a probability distribution, i.e., the
constraints in Equation 9 and Equation 10 are satisfied. Therefore,
in the optimization problem in Equation 6, we change the true
confidence score vector s as so f tmax(z) and change the variable
r as so f tmax(z + e) − so f tmax(z). Then, we obtain the following
optimization problem:
min
e
d(so f tmax(z), so f tmax(z + e))
{zj}
{zj + ej} = argmax
subject to: argmax
(13)
(14)
j
j
д(so f tmax(z + e)) = 0.5.
(15)
After solving e in the above optimization problem, we can obtain
the noise vector r as follows:
r = so f tmax(z + e) − so f tmax(z).
(16)
The optimization problem without the constraints on probability
distribution is still challenging to solve because the remaining two
constraints are highly nonlinear. To address the challenge, we turn
the constraints into the objective function.
Turning the constraint in Equation 15 into the objective func-
tion: We consider the defender’s binary defense classifier is a neu-
ral network whose output layer has a single neuron with sigmoid
activation function. Therefore, we have:
1
д(so f tmax(z + e)) =
1 + exp(−h(so f tmax(z + e))) ,
(17)
where h(so f tmax(z + e)) is the output of the neuron in the second-
to-last layer of the defense classifier when the defense classifier
takes the noisy confidence score vector so f tmax(z + e) as an input.
In other words, h is the logit of the defense classifier. д(so f tmax(z +
e)) = 0.5 implies h(so f tmax(z + e)) = 0. Therefore, we transform
the constraint in Equation 15 to the following loss function:
L1 = |h(so f tmax(z + e))|,
(18)
where L1 is small when h(so f tmax(z + e)) is close to 0.
Turning the constraint in Equation 14 into the objective func-
tion: We denote by l the predicted label for the query data sample,
i.e., l = arдmaxj{sj} = argmaxj{zj}. The constraint in Equation 14
means that zl + el is the largest entry in the vector z + e. Therefore,
we enforce the inequality constraint zl + el ≥ maxj |j(cid:44)l{zj + ej}.
Moreover, we further transform the inequality constraint to the
following loss function:
L2 = ReLU(−zl − el + maxj |j(cid:44)l{zj + ej}),
(19)
where the function ReLU is defined as ReLU(v)=max{0, v}. The
loss function L2 is 0 if the inequality zl + el ≥ maxj |j(cid:44)l{zj + ej}
holds.
Unconstrained optimization problem: After transforming the
constraints into the objective function, we have the following un-
constrained optimization problem:
L = L1 + c2 · L2 + c3 · L3,
min
e
(20)
Algorithm 1 Phase I of MemGuard
Input: z, max_iter, c2, c3, and β (learning rate).
Output: e
1: //Predicted label
2: l = argmaxj{zj}
3: while True do
4:
5:
6:
7:
8: while i  0) do
9:
10:
11:
12:
13:
14:
15:
16:
//Gradient descent with normalized gradient
u = ∂L
∂e
u = u/||u||2
e = e − β · u
i = i + 1
end while
//Return the vector in the previous iteration if the predicted
label changes or the sign of h does not change in the current
iteration
if argmaxj{zj + ej} (cid:44) l or h(so f tmax(z)) · h(so f tmax(z +
e)) > 0 then
return e′
end if
c3 = 10 · c3
17:
18:
19:
20: end while
where L3 = d(so f tmax(z), so f tmax(z + e)), while c2 and c3 balance
between the three terms.
Solving the unconstrained optimization problem: We design
an algorithm based on gradient descent to solve the unconstrained
optimization problem. Algorithm 1 shows our algorithm. Since we
aim to find a noise vector that has a small confidence score dis-
tortion, we iteratively search a large c3. For each given c3, we use
gradient descent to find e that satisfies the constraints in Equa-
tion 14 and Equation 15. The process of searching c3 stops when
we cannot find a vector e that satisfies the two constraints. Specifi-
cally, given c2, c3, and a learning rate β, we iteratively update the
vector variable e (i.e., the inner while loop in Algorithm 1). Since
we transform the constraints in Equation 14 and Equation 15 into
the objective function, there is no guarantee that they are satisfied
during the iterative gradient descent process. Therefore, in each
iteration of gradient descent, we check whether the two constraints
are satisfied (i.e., Line 8 in Algorithm 1). Specifically, we continue
the gradient descent process when the predicted label changes or
the sign of the logit h does not change. In other words, we stop the
gradient descent process when both constraints are satisfied. We
use h(so f tmax(z)) · h(so f tmax(z + e)) ≤ 0 to approximate the con-
straint in Equation 15. In particular, the constraint in Equation 15 is
equivalent to h(so f tmax(z + e)) = 0. Once we find a vector e such
that h(so f tmax(z)) and h(so f tmax(z + e)) have different signs (e.g.,
h(so f tmax(z)) > 0 and h(so f tmax(z + e)) < 0), h(so f tmax(z + e))
just crosses 0 and should be close to 0 since we use a small learn-
ing rate. Note that we could also iteratively search c2, but it is
computationally inefficient to search both c2 and c3.
4.3 Phase II
After Phase I, we have two representative noise vectors. One is 0 and
the other is r. In Phase II, we assume the randomized noise addition
mechanism is a probability distribution over the two representative
noise vectors instead of the entire noise space. Specifically, we as-
sume that the defender picks the representative noise vectors r and
0 with probabilities p and 1− p, respectively; and the defender adds
the picked representative noise vector to the true confidence score
vector. With such simplification, we can simplify the optimization
problem in Equation 1 to the following optimization problem: