Questions to consider when developing red team goals:
● What ability does an adversary have to access common areas?
● What ability does an adversary have to access restricted areas?
● Can an adversary use gained access to enable electronic capabilities?
● What impacts can an adversary have with gained access?
● Can an adversary access key/critical systems?
● What impacts can an adversary have on a key/critical system?
● What ability does an adversary have to move through a network freely?
● How long can an adversary live on target without discovery?
● What actions are required to trigger a detection/response?
These questions shift focus on measuring or understanding the ability a threat has to perform some
action or the ability the defense has on impacting the threat. This leads to the need of an alternate
means of providing risk metrics.
Three-tiered categorization
Chris Crowley[23] has proposed a simple yet highly effective concept for categorization using only
three tiers. While this tiered structure was intended to be applied to security operations, it can be
applied to virtually any concept.
A benefit to this model is the categories focus on the ability to mitigate rather than risk. By nature, this
provides an actionable plan to implement improvements. Let's review and understand this concept by
starting with the tier categories. Each tier is defined based on the relative ease of applying a
mitigation to the observation or finding.
Tiered Matrix
Category Rating
1 The correction is readily available in the
environment but has not been implemented or
applied.
2 The correction or mitigation is readily
available in the environment or public, but
something such as policy, procedure, politics,
contracts, training, etc. prevents
implementation or application.
3 The correction or mitigation is not readily
available in any industry or sector. Research
or additional effort is required to investigate
to determine a correction or mitigation plan.
Example Diagram Summarizing Categories
Example snippet from a report showing how to use category rating
Author’s Thoughts
Very few things should be labeled 3. There’s almost
always an acceptable mitigation/workaround.
Many will likely be labeled 2. This should be cause for
policy or process change and could be used to justify
additional training.
Anything labeled 1 should be of great concern to the
organization, division, or management. Often indicates a
lack of effort.
It is important to note that this method of categorization requires open and effective communication
between the Red Team and the organization. Internal Red Teams may have the organizational
knowledge and experience required to categorize their observations. However, as most Red Teams
(internal or external) are not typically part of the business function being assessed, require a
collaborative review and discussion of each observation.
During Red Team reporting, this method can be used in conjunction with the Pyramid of Pain to
illustrate how a specific correction impacts a threat's ability to perform nefarious actions. This
knowledge can, in turn, be leveraged to create a prioritization of corrections or organizational
modifications.
Pyramid of Pain
Security operations do not need a list of patches or misconfiguration flaws as the highlight of
mitigations or recommendations. Yes, these should be included in the report. However, it is much
more beneficial to provide security operations with a list of actions, processes, procedures, etc. that
would make a threat's ability to operate (move, gather data, and cause impact) much more difficult. A
great way to both describe and illustrate this concept is the Pyramid of Pain.
The Pyramid of Pain[24] was created and described by David Bianco in 2013 and revised later in
2014. The pyramid describes types of indicators that may be used to detect threat activities and how
much pain will be caused (to the threat) if a Blue Team is able to deny a threat the ability to perform
actions that generate those IOCs. What does this mean in terms of a Red Team engagement? Red
Teams generate artifacts during an engagement. A Red Team can use the concept of the Pyramid of
Pain to measure where they fit on this chart during an assessment. In other words, how much pain is
Blue causing Red.
When a Blue Team is measured against the actions of a threat instead of against how well they detect
malware, configure their firewalls, or implements a password policy, they are measured against
threat techniques. This includes known, unknown, and even zero-day attacks. Decomposing threats
into their actions provide defenders a manageable way to understand the effectiveness of their
defensive strategy. Blue Teams can become more effective and better protect against any threat
instead of defending against a single piece of malware.
A Blue Team Perspective
Detection in Depth
Detection Engineering (the process of creating detection
logic for attacker activity) is an often misunderstood
discipline. It is common to see these “detections” labeled
as good or bad, but detection logic isn’t inherently either.
The misunderstanding tends to occur when someone’s
expectations of specific logic don’t align with reality. To
be successful in detection, it is important to build a
detection mesh that combines precise indicators with low
false-positive expectations (signatures) with broad
indicators with low false-negative expectations
(behavioral detections). I refer to this concept as Detection
in Depth. This approach ensures that analysts can rely on
high signal detection of known bad activity, while also
expecting that the mesh will stand up to evasion attempts.
- Jared Atkinson, Microsoft MVP, @jaredcatkinson
Introducing the Funnel of Fidelity -
https://posts.specterops.io/introducing-the-funnel-of-
fidelity-b1bb59b04036
What are some examples of defensible actions that would make a threat’s ability to operate difficult?
Defensive Description
Action
Prevent client-to- Preventing these communications
client limits a threat's ability to move freely
communication throughout the network, reduces the
likelihood of privileged account
discovery, forces an increase in time
and effort (more activities and
artifacts), and ,therefore, can increase
the defender's ability to detect.
Prevent server- Assuming the network has prevented
to-client client-to-client communications, the
communication only option a threat has is to attempt
access to a server, but cannot
communicate server to the client.
Block outbound There are very few instances where a
server server needs to communicate with a
communications system external to the network. These
are exceptions and should be managed
to allow only connections to the
required external asset or IP and
allow only the use of required ports
and protocols.
Clear cached Cached credential discovery is a
administrative common and primary method in which
credentials threats escalate privileges.
Reset the Reset the KRBTGT account twice
KRBTGT within a limited time-frame followed
Account by the changing of all administrative
credentials. These resets limit a
threat's ability to maintain access after
credential changes.
Perform a Perform frequent search and
sensitive items discovery activities for critical items
review stored across organizational assets
(Passwords, Configs, Privacy of
Information Act (PIA) data,
Intellectual Property, etc.)
Block and Both internal and external systems and
Disable non- network devices should disable and
required ports, block PPS that aren't required for the
protocols, and network. Limit PPS to only what is
services (PPS) required for each specific system.
Implement Users should be limited to only what
separation of is required to perform daily tasks.
accounts and Standard users often do not require
privileges elevated privileges on a daily basis.
In rare scenarios where a user needs
elevation often, require the use of a
secondary account with only the
access required and no external
communications ability.
Ensure group This recommendation has multiple
permissions are applications; however, the main focus
appropriately is nested groups and permissions.
identified and
mapped
Implement No two local accounts have the same
Microsoft Local password. A client-side component
Administrator generates a random password, updates
Password the LAPS password on the Active
Solution (LAPS) Directory computer account, and sets
the password locally.
Multi-Factor Additional security control and
Authentication protection that requires more than one
authenticator or authentication factor
for successful authentication.
Application Implement Application Whitelisting
Whitelisting only after all of the prior
recommendations have been
implemented.
This list is comprised of list of preventable controls (Mitigation Strategies Part 1[25] and Part 2[26])
and is a great list of starter techniques a Red Team can use to apply Red Team techniques that directly
measures security operations ability to detect and response to threat techniques.
Attack Narrative
The Attack Narrative section of the report contains the observations made during a Red Team
engagement. It is the written version of the attack diagram. These are typically written in
chronological order and follows the execution flow of an engagement. Key observations that a Red
Team uses to achieve its goals must be documented. This includes all major successful and failed
steps taken while working toward a goal. Threat profiles or other indicators that Blue can use during
post-analysis should be included. The end of a Red Team engagement can be the beginning of post-
forensic analysis or hunt team engagement. Blue teams that take advantage of the IOCs listed in the
report after an engagement through post-analysis can use this to find blind spots or to tune security
tools to better protect against threats by comparing what was discovered against what was not.
Types of Observations that Should Be Documented
Observation to be Description
Documented
Key actions that led Actions that describe how access
from initial access was gained as various phases of the
to the final goal engagement.
Include
● Initial access
● Lateral movement
● Privilege escalation
Command and Overview of C2 design and
Control architecture.
Include
● Network information (IP
addresses, domain name, ports,
protocols, etc.)
● Include agent information
(binaries, scripts, locations, and
Registry changes)
● Include persistence methods
Reconnaissance Steps taken to perform
actions reconnaissance or situational
awareness.
Include
● Techniques used that help
identify potential indicators
● Include key pieces of
information gathered
Interesting Operators often take advantage of
observations that unique situations to support an
assisted the red engagement. This is often non-
team during the technical in nature. Observations
engagement related to people, processes, and
technology should be documented.
Include
● Logic flaws found in the
environment
● Response (or lack of) from
defenders
Interesting Engagement offer a unique view to a
observations that range of systems. Operators often
may be of concern find interesting paths or other
but that are not observations that may or may not
directly related to have been explored. These should
the engagement be documented.
A single observation should Include the following elements (a complete example is available on the
companion website)
● Observation title
● A narrative description
● Technical details
○ Source/destination IP addresses
○ Tools or techniques
○ Results (Including impacts)
● Screenshots
Example Observation
Where to Include Findings and Recommendations
Although a report is focused on the attack diagram and narrative, flaws will be identified and should
be reported in a findings section of the report. Findings should be a list of critical issues that helped
the Red Team with their success in achieving goals. These should include traditional findings, such as
lack of patching, weak passwords, or other common flaws.
Recommendations of mitigations are typically generic at this phase. In order to enhance
recommendations and provide mitigation advice that directly focuses on the target organization, there
must be a collaboration with the Red Team and the target organization to determine the root cause of
the security failures. Unfortunately, this does not always occur. Many Red Teams provide a list of
recommendations, and these are taken as ground truth. Red teams should encourage a proper risk
assessment to be performed regarding the recommended mitigations. Red teams only provide one side
of the risk equation. Organizations that use a report to conduct their own root cause analysis are often
better off and implement more robust improvement to their security operations.
Focus Point
Although Findings and recommendations are not the focus
of a Red Team engagement or always requested, they
should always be included in an appendix.
After observations are analyzed and understood, the Red Team has an understanding of how the
defense fared against the attack, but this understanding is often one-sided. I can be difficult to provide
exact recommendation or remediations. It can be beneficial to provide a relationship instead of a
direct recommendation. A relationship that gives an overall picture of an engagement will help
describe how improvements will increase security.
The details in this example are not important. The mapping of observation to recommendation in
relationship to the pyramid of pain is the focus. The left of the image shows the red team's
observations mapped to the defense's ability to impact the threat actions. This is currently at Easy.
The right of the image describes the issue and provides a recommendation. If the target organization
implements the recommendation, the Red Team estimates the defensive posture and impact to the
threat . In this case, to challenging or annoying.
Reporting does not explicitly need to display this diagram, but the concept should be understood in
the report context. Note, as with the attack diagram, images assist understanding. Including visuals,
along with text, dramatically increases the chances of ingestion and application.
Key Chapter Takeaways
A Red Team engagement report is the final and only piece of evidence of a red team engagement.
These reports can be quite different than other security reports. Reports should focus on the attack
narrative and highlight the key observations made by operators during engagement execution.
Applying a risk rating can be difficult as red team observations are often one-sided. Consider
applying ratings by directly working with a risk team or individuals from the security operations
team. Use these tips to apply a rating in cases where the red team will provide a rating.
● Use an observation section to support the attack narrative
● Use a findings section to track and define technical flaws
● Apply the three-tiered rating technique for observations
● Apply a 5x5 rating techniques for technical findings
Homework
1. Develop a custom report template
2. Create a collection of observations to enable consistent wording when reporting on
repeated observations in the attack narrative.
3. Create a findings section to track technical findings (similar to a penetration test report).