All participants, except for P2 and P5, believe that the
security of any communication tool can be breached by three
types of adversaries: (1) intelligence agencies, (2) application
service providers, and (3) technically-skilled attackers.
Intelligence agencies. 58 out of 60 participants believe gov-
ernment agencies (e.g., NSA, GCHQ) have the resources and
capabilities required to monitor any citizen. They also believe
that governments can coerce or compel service providers to
hand over all the data related to a particular user. 21 par-
ticipants believe governments do this to protect their national
security; e.g., to prevent terrorism. P51 mentioned a “universal
decryption key” that allows governments to decrypt and read
any encrypted communication.
Application service providers. 54 out of 60 participants
think that all messages pass through the service provider
who “knows how the communication tool works” (P10) and,
therefore, is able to access all messages. They also believe
that service providers can access any account stored on their
servers either because passwords are not encrypted, or en-
crypted in a way that can be “reverse-engineered” (P9). Eight
participants mentioned that companies access the content of
messages not for malicious, but commercial reasons (e.g.,
targeted advertisements, removing inappropriate content). P1,
P12, P13, P35 and P42 reported that when they download
an application to their device, the application asks for their
permission to access PII, geo-location data, photo albums, and
contact lists. To them, this means that providers have ways of
circumventing the security properties of communication tools.
they have to accept a
provider’s Terms and Conditions (T&Cs), which they do not
read because they are “too long” and “intentionally vague”,
and contain “a lot of jargon” (like Data Privacy Policies and
End-user Licence Agreements). 15 participants mentioned that
these terms are regularly updated without users being notiﬁed.
Our participants suspected they have agreed, because of a
clause somewhere, that the provider can access their data.
Hence, “having my data anyway” means trying to protect it is
pointless (P47).
55 participants mentioned that
Technically-skilled attackers. All participants (except for
P2 and P5) believe that the use of a secure communication
144
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:20:09 UTC from IEEE Xplore.  Restrictions apply. 
P2, P4 and P5 believe that conﬁdentiality can be breached
through social engineering attacks, exploiting vulnerabilities,
using weak cryptographic schemes, or inserting backdoors.
Only P2, P4, P5 and P6 mentioned the terms “encryption” or
“decryption”, albeit with simplistic mental models. We discuss
participants’ mental models of encrypted communications in
detail later in Section IV-E.
Message integrity. As discussed in Section IV-C,
this
security property was not mentioned by any participant. When
we hinted at it, all participants said that messages should
be protected from modiﬁcation, but many did not think that
messages can be modiﬁed in transit (50 out of 60). P3 believes
her messages have never been modiﬁed because her phone has
never been stolen, and her account “has never been hacked”.
Thus, no one can send modiﬁed messages from her account.
She believes that integrity is assured as long as authentication
takes place. 21 other participants share P3’s belief. Many
believe that their messages cannot be tampered with, which
is in stark contrast to their other belief that conﬁdentiality
cannot be achieved.
P4 does not worry about integrity being breached because
“any message modiﬁcation can be detected even after some
point in time” by the recipient (a belief shared by P11, P25,
P49 and P60). P4 believes that if someone sends a message
encrypted and then it gets modiﬁed in transit by an attacker, the
recipient will receive “nonsense”, and resending the message
will resolve the problem. 30 participants said they have never
thought of the possibility that messages can be tampered with
because, as P11 put it, “the chat history does not change when
sending a message”.
P6, P12 and P18 believe that integrity does not get breached
unless people live under a repressive regime. Hence, govern-
ments can modify or censor communications. 40 participants
believe that service providers can tamper with messages,
however, P12 thinks it is not worth the effort: “this would
require someone to have access to the intermediate server
between me and the recipient, so it could probably only be
done by someone within the company, who has access to the
central server. But, this is unlikely, and I don’t know why
they would do it either, so I think it’s a very small concern”.
P13 reported that message integrity can be violated if the
application software has a “bug”.
None of the participants knows how integrity can be
achieved, except for P2 and P5 who correctly explained
hashing and digital signatures. We discuss participants’ mental
models of digital signatures in Section IV-E.
“No impersonation”. All participants believe that as long
as passwords are hard to guess or steal, authentication is
achieved. Passwords can be stolen by hacking, social engi-
neering, or brute forcing.
tool cannot protect against attackers with technical expertise,
described as hackers, computer science students, or competing
companies (e.g., Apple vs. Google).
Only P2 and P5 said that a secure communication tool is
as secure as the device they install it on, provided that the
security protocols are proved to be secure and implemented
correctly. Reasons for the device not being secure that P2 and
P5 are aware of include software and hardware bugs, malware
(e.g., viruses) and backdoors.
D.II. Violating the Security of Communications
Below, we explain how participants believe the security
properties of secure communication tools (discussed in Section
IV-C) can be violated.
Secrecy of message content. Almost all participants (except
for P2, P4, P5, P6, P9 and P28) believe that information
exchanged via any tool can be accessed and read by (1)
physically accessing the user’s mobile phone or PC, and
reading messages from the chat history, (2) a communication
partner colluding with a third party and sending them the chat
history, (3) accessing the microphone and speaker to listen to
phone calls using some “sophisticated techniques”, (4) using
CCTV cameras to capture exchanged messages on a users’
device screen, or (5) falling for a social engineering attack.
Some participants also believe that conﬁdentiality (i.e.,
secrecy of message content) can be easily breached by the
service provider because when users download an application,
it asks for their permission to access the device’s contact list,
camera, microphone and photo gallery. According to P1, if
the user decides not to agree to such a request, they will not
be able to exchange photos with others. This ﬁnding is in
line with the threat model explained earlier in Section IV-D.I.
P8 also reported that providers access log ﬁles to perform
quality monitoring of the service, hence, they can read the
information exchanged if they want to. She also mentioned that
a law enforcement agency that has a subpoena can “obviously”
access users’ information.
Only P2, P4, P5, P6, P9 and P28 mentioned eavesdrop-
ping, wiretapping or decrypting cipher-texts. No participant
explicitly talked about man-in-the-middle attacks (although we
cannot rule out that these attacks could have been part of the
“sophisticated techniques” mentioned above). P6 believes that
conﬁdentiality can be breached by wiretapping the commu-
nications between one point and another, though he believes
that as long as “basic encryption, which is signing in to an
application” is used, this attack can be avoided. He thinks the
password used to log in to an account is a form of encryption
to protect the data in transit against unsophisticated attackers
(other members of the public).
P9 also mentioned that if many people use a communication
tool (whether secure or not), there will be “billions of messages
being exchanged via the network”. This, he believes, makes
it hard to identify a message sent by a particular person. He
thinks that as long as a tool has a large user base, attackers
cannot associate exchanged messages with speciﬁc parties,
even if messages are sent in cleartext.
According to our participants (41 out of 60), hacking means
(1) stealing the username and password by mounting a social
engineering attack, guessing the password, intercepting the
password when logging into the application, or stealing the
password from the company’s server, (2) logging into the
account on behalf of the legitimate user, and then (3) reading
145
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:20:09 UTC from IEEE Xplore.  Restrictions apply. 
messages from the victim’s chat history and accessing PII.
Many participants (32 out of 60) believe that hacking generally
happens over the “Internet”; the traditional network (3G) is
more secure and, as a result, hacking is impossible.
All participants think social engineering attacks are possible,
and that they need to be aware of these attacks. They believe
security can be increased by not writing passwords down and
by changing them regularly, but doing so is onerous.
43 out of 60 participants mentioned that passwords can
be brute-forced. Furthermore, 21 out of 60 stated that an
attacker can create fake accounts to impersonate others, but
“the company providing the service should be aware of this
and ensure this does not happen” (P4). 25 participants also
believe that providers store passwords encrypted on their
servers: “they [service providers] are immune to brute-forcing
attacks because encryption is used to protect credentials” (P9).
E. Mental Models of (Secure) Communications
During the interview, we asked our participants how a
communication tool works, and who the actors in a commu-
nication system are. We also asked about different security
mechanisms, such as encryption, digital signatures and cryp-
tographic ﬁngerprints. We provided participants with an iPad
and a stylus pen, so they would draw if they wished to explain
a speciﬁc concept (e.g., encryption). This helped us identify
whether our participants know the mechanisms used to achieve
a particular security property, such as associating encryption
with conﬁdentiality, and how this relates to their threat models
in Section IV-D. We also found a misconception about deleting
accounts shared by most participants.
Actors in a communication system. All participants,
except for P1 and P11, believe the actors in a communication
tool are the sender,
the recipient(s) and a single service
provider, referred to as the “company providing the service”.
This architecture is the same,
irrespective of whether the
information exchanged is via telephony, SMS, email or IM.
P12 mentioned that the topology of a 3G network is different
from that of the Internet (or Wi-Fi). She incorrectly believes
there are only the sender and the recipient(s) in a 3G network
without a provider.
P1 has never thought of how a communication tool works.
She said the process is “too complicated” for her to think
about. As long as the message is “sent”, “delivered” and
“read”, she will be satisﬁed. Also, P11 does not know how
communications work.
An important ﬁnding of our study is that unlike experts’
network centric view, our participants’ mental models are
somewhat “ego-centric”: they see themselves as the centre
of their personal communications universe and being able
to choose across different tools, which they see as separate
channels. For example, 18 participants think that segmenting
information and sending different “bits” via different tools
means segments cannot be intercepted by the same attacker.
Participants assume that attackers can hack one tool or listen to
one channel. Participants who have more technical expertise
(P2, P4, P5, P16 and P28) showed the same basic mental
models (i.e., ego-centric models).
Encrypted communications. When we asked our partici-
pants how secrecy of message content can be achieved, P2, P4,
P5 and P6 mentioned the terms “encryption” or “decryption”
(albeit with simplistic mental models). The remaining partic-
ipants did not. Hence, we probed and asked what encryption
is, why it is used, and how it works (including client-server
and E2E encryption, as distinguished by the EFF Scorecard).
Ten participants confused encryption with authentication.
Nine mentioned “multiple encryption”: using a username and
multiple passwords to log in to an account. P12 mentioned
“double encryption” to describe two-factor authentication. In
other words, “encryption would be something like what banks
use. I have a mobile banking app, but they send me a code
in the post, so only I have it, so protection means only I can
access it in a way with the unique code” (P12). P19 stated
that when encryption is used, “it will be harder to get to the
data because of the passcode and password used to log in to
the account”. He believes that encryption is used to protect
the company providing the service from other companies and
“hackers”. P17 also described encryption as using the account
password in a way to protect the data in transit; the more
passwords the account has, the stronger the encryption is.
P1 and P59 conﬂated encryption with data encoding. P1
explained encryption as sending messages in “computer lan-
guage: 01010011110100” (i.e., binary representation) and said
“these messages can only be understood by computer scien-
tists, hackers, service providers and governments. Lay people
cannot”. P59 explicitly described encryption as sending text
in “binary language: 122121122”.
Other participants explained encryption as follows:
1) Turning a message into random text that people cannot
understand (27 out of 60).
2) Using a special language, such that if someone (like a
computer scientist) knows the language, they can decrypt
the message (P26, P27, P32 and P35).
3) Using a special code (P14 and P27).
4) Making conversations “invisible” (P14 and P60).
5) Slowing down the process of understanding the data;
“encryption is (no encryption + adding some time to
send the data packets)” (P23).
6) Using proxies when accessing websites to protect
against attackers (P29).
Seven participants said they have not heard of encryption
and, hence, did not provide any deﬁnition.
All participants, except for P2, P4 and P5, believe that
encryption protects against the unsophisticated attackers “who
do not know how to hack” (P32). They believe that service
providers should not be able to read exchanged messages
in theory, but “this sort of encryption” (P9) is not offered
by existing communication tools. They think that encrypted
communications are futile because the designers who create
the encryption scheme know how to decrypt messages. As
P15 put it, “even the ultimate encryption can be broken, like
the ENIGMA machine in WWII”.
146
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:20:09 UTC from IEEE Xplore.  Restrictions apply. 
Only P2, P4 and P5 distinguished between client-server
encryption and E2E encryption; they provided a good (al-
though simplistic) understanding of both types of encryption
and discussed private-key and public-key cryptography. They
also stated that E2E encryption could protect against all types
of attackers.
The 57 remaining participants either did not know the
difference between both types of encryption or gave wrong
answers. For example, P13 equated client-server encryption
to SSL, and described E2E encryption as a special encryption
program (or software) used to manually encrypt messages. P16
equated keys to passwords, describing client-server encryption
as using one key (one password) for encryption and decryp-
tion, whereas E2E encryption as using two different keys (two
passwords): one for encryption and one for decryption.
Passcodes, digital signatures and ﬁngerprints. Some