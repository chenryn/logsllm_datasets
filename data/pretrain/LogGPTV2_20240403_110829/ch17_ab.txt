设计具有天文数字高的系统相当容易。二十四个九对应于 一兆兆（10的24次方）年的 MTTF。当你的 MTTF 使宇宙的年龄相形见绌时，也许是时候重新审视你的优先级了。
不过，我们应该相信这些数字吗？当然不是，因为秘密的事实是，坚持理论的耐久性估计没有切中要点。它只是告诉你由于常规磁盘故障而丢失数据的可能性有多大，而常规磁盘故障很容易建模和防止。如果由于常规磁盘故障而丢失数据，那可能是做错了什么。
丢失数据的最有可能方式是什么？是在极短的时间内有多个地理区域一组特定的六个磁盘同时损坏？或者是因为维护人员意外运行了删除所有文件的脚本，还是导致一半的存储节点同时发生故障的固件错误，还是软件错误导致 1% 的对象默默损坏？防范这些威胁才是真正的 SRE 职责。  in   
真实世界的耐久性真实世界的耐久性
 在现实世界中，最糟糕的情况往往来自那些你看不到的事件：也就是所谓“未知的无解”。如果你能看到正要发生什么，却没有防止它发生，那么最起码还可以归类为失职！但我们从来不知道卡车何时会撞入数据中心，或者何时有人会让实习生来操作重要基础架构，因此我们需要全力以赴，不仅减少可能发生的坏事的范围，而且能够从各类问题中恢复。坏事总会发生。可靠的公司是能够在用户受到影响之前做出响应和恢复的公司。
那么，当防范未知事物时，我们该从哪里开始呢？我们将在本章的其余部分中专门介绍涵盖耐久性工程四大支柱的耐久性策略：
隔离
保护
验证
自动化
隔离
  强有力的隔离是防止问题扩散的关键。
基于复制的耐久性完全取决于如何限制各个副本独立失败。尽管这似乎相当明显，但系统中单个组件的故障之间通常有很大的相关性。数据中心火灾可能会破坏现场备份；一批不良硬盘可能在短时间内出现故障；软件错误可能会同时损坏所有副本。在这些情况下，你会遭受着缺乏问题隔离的痛苦。物理隔离显然是一个问题，但也许更重要的是对逻辑和操作隔离的投资。
物理隔离
  简单地说，把你的鸡蛋放在不同的篮子里面。
从磁盘到计算机、机架、机列、供电系统、网络群集、数据中心、区域甚至国家/地区，都会面临广泛的物理故障。随着你的技术升级，隔离会有所改善，但往往带来巨大的成本、复杂性或性能损失。跨多个地理区域存储状态通常具有很高的网络和硬件成本，并且通常需要大大增加延迟。在 Dropbox，我们设计数据放置算法时甚至会参考数据中心的配电图，以尽量减少停电对服务的影响。对于许多公司来说，这似乎有点吹毛求疵。
每个公司都需要选择符合其期望的保证和技术可行性的隔离级别，但在选择一个级别后，达成承诺很重要。“如果这个数据中心被烧毁，我们将失去我们所有的数据，并导致公司解散”不一定是不负责任的声明，但若你不确定自己实际上拥有什么级别的隔离承诺，那么被意外故障而折磨就是不可避免的。物理隔离还有其他思路，例如硬件采购来源多样化或采购磁盘和存储设备的多个硬件版本。尽管这不在许多公司的范围之内，但大型基础架构供应商通常会从多个厂家采购硬件资源，以尽量减少产能不足或硬件错误的影响。你可能会惊讶地发现，错误在磁盘驱动程序、路由固件和 RAID 卡等组件中频繁出现。如果新硬件类未通过生产验证测试，明智地采用硬件多样性可以减少灾难性故障的影响，并提供备份选项。
逻辑隔离
  失败往往级联，错误往往会传播。如果一个系统出现故障，它通常会使过程中的其他所有系统都发生拥塞。如果一个坏节点开始将损坏的数据写入另一个节点，则该数据可能会通过系统传播，并进一步损坏存储系统中其他的数据。发生这些故障的原因是分布式系统在组件之间通常具有很强的逻辑依赖关系。
逻辑隔离的关键是构建松散耦合的系统。逻辑隔离的关键是构建松散耦合的系统。
逻辑隔离是很难实现的。数据库副本将无条件更新由主数据库传给给它们的坏数据。连Zookeeper这样的选举协议也无法避免同样的命运。这些系统不仅从耐用性角度紧密耦合，而且从可用性角度紧密耦合：如果负载峰值导致一个组件发生故障，则通常会把更大的负载带给其他组件，然后导致它们也一并失败。
强逻辑隔离通常需要设计到系统的基础体系结构中。
Dropbox 的一个案例是存储系统中的区域隔离。Dropbox 中的文件对象不只在单个地理区域内广泛复制，也可能在地图上很远的完全独立的地理区域中复制。区域内的复制协议相当复杂，并且为高存储效率而设计，但两个区域之间的 API 则非常简单：主要是简单的 put 和 get，如#isolated_multiregion_storage_architecture所示。
隔离的多区域存储体系结构隔离的多区域存储体系结构
区域之间的强隔离是使用模块化来隐藏复杂性的好方法，但在复制开销方面却付出了巨大的代价。那么，为什么公司在存储方面花费超过所需成本呢？
存储区域之间的抽象边界使得级联问题很难跨区域传播。松散的逻辑耦合和简单的 API 使一个区域中的 Bug 或不一致难以影响另一个区域。松散耦合还使得在紧急情况下的整个区域离线，却并不影响我们的最终用户，这种可能性十分宝贵。事实上，作为测试练习，我们每周都会把一个区域离线。从可用性和耐用性的角度来看，这种架构的架构非常可靠，而不会给运行系统的工程师带来沉重的运维负担。
操作隔离
  隔离最重要的维度是操作隔离，但它经常被忽视。虽然你可以构建世界上最复杂的分布式存储系统之一，具有广泛的复制和物理和逻辑隔离，但可能随后让某人运行整个机群范围的固件升级，导致磁盘写入失败，或意外重启所有计算机。这些都不是学术上的例子；我们已经看到这两件事都发生在 Dropbox 的早期。通常，系统最危险的部分是负责系统运维的人员。成熟的 SRE 组织都能体会到这一点，并构建系统来抵御自身。在下一节中，我将详细介绍保护，但一组关键的保护是跨发布过程、工具和访问控制隔离。这意味着实施限制以防止潜在危险的批处理同时跨多个隔离区域运行。
操作隔离在 Dropbox 堆栈的许多层实施，但一个特定示例是存储系统的代码发布过程中的隔离。Dropbox 代码库的某些部分每天都会推送到生产中，在正确性或持久性没有风险的用例中，但对于底层存储系统，我们采用多周发布过程，以确保至少一个完全复制的数据存储在经过全面审查的代码版本上，如#storage_system_code_release_process所示。
存储系统代码发布过程。存储系统代码发布过程。