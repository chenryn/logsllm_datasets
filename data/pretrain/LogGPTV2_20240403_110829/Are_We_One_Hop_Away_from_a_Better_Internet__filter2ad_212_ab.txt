4876 ASes contribute 72% of the query volume in our CDN trace,
with most of the queries coming from preﬁxes that have the shortest
paths for the ASes. The GCE to end-users weighted, shortest path
bars in Figure 1 show how long paths would be if all traﬃc took the
shortest observed path to its destination AS. With this hypothetical
routing, 80% of queries traverse only one hop.
Path lengths vary regionally. Peering connectivity can also vary
by region. For example, overall, 10% of the queries in our CDN log
come from end users in China, 25% from the US, and 20% from
Asia-Paciﬁc excluding China. However, China has longer paths and
less direct peering, so 27% of the 2 hop paths come from China,
and only 15% from the US and 10% from Asia-Paciﬁc.
3.2 Google’s Peers (and Non-Peers)
In our traceroutes from GCE, we observed Google peering with
5083 ASes (after merging siblings).4
5 Since a primary reason to
peer is to reduce transit costs, we ﬁrst investigate the projected
query volume of ASes that do and do not peer with Google. We
form a ﬂow graph by combining the end-user query volumes from
our CDN trace with the AS paths deﬁned by our GCE traceroutes.
So, for example, the total volume for an AS will have both the
queries from that AS’s preﬁxes and from its customer’s preﬁxes if
traceroutes to the customer went via the AS. We group the ASes
into buckets based on this aggregated query volume.
,
Figure 1: Paths lengths from GCE/PlanetLab to iPlane/end-user dest.
Figure 1 shows that only 2% of paths from PlanetLab are one hop
to the destination, and the median path is between two and three AS
hops.3 However, there is likely little traﬃc between the networks
hosting PlanetLab sites (mostly universities) and most preﬁxes in
the iPlane list, so these longer paths may not carry much traﬃc.
Instead, traﬃc is concentrated on a small number of links and
paths from a small number of sources. For example, in 2009, 30%
of traﬃc came from 30 ASes [26]. At a large IXP, 10% of links
contribute more than 70% of traﬃc [38]. In contrast, many paths
and links are relatively unimportant. At the same IXP, 66% of links
combined contributed less than 0.1% of traﬃc [37].
To begin answering what paths look like for one of these popular
source ASes, we use our traceroutes from GCE, Google’s cloud
oﬀering, to the same set of iPlane destinations. We use GCE tracer-
outes as a view of the routing of a major cloud provider for a number
of reasons. First, traceroutes from the cloud give a much broader
view than traceroutes to cloud and content providers, since we can
measure outward to all networks rather than being limited to the rel-
atively small number where we have vantage points. Second, we are
interested in the routing of high-volume services. Google itself has
a number of popular services, ranging from latency-sensitive prop-
erties like Search to high-volume applications like YouTube. GCE
also hosts a number of third-party tenants operating popular ser-
vices which beneﬁt from the interdomain connectivity Google has
established for its own services. For the majority of these services,
most of the traﬃc ﬂows in the outbound direction. Third, Google
is at the forefront of the trends we are interested in understanding,
maintaining open peering policies around the world, a widespread
WAN [20], a cloud oﬀering, and ISP-hosted front end servers [9].
Fourth, some other cloud providers that we tested ﬁlter traceroutes
(§3.4 discusses measurements from Amazon and SoftLayer, which
also do not ﬁlter). Finally, our previous work developed techniques
that allow us to uncover the locations of Google servers and the
client-to-server mapping [9], enabling some of the analysis later in
this paper.
Compared to PlanetLab paths towards iPlane destinations, GCE
paths are much shorter: 87% are at most two hop, and 41% are one
hop, indicating that Google peers directly with the ASes originating
the preﬁxes. Given the popularity of Google services in particular
and cloud-based services in general, these short paths may better
represent today’s Internet experience.
However, even some of these paths may not reﬂect real traﬃc,
as some iPlane preﬁxes may not host Google clients. In the rest of
this section and §3.3, we capture diﬀerences in Google’s and GCE’s
paths toward iPlane destinations and end-users.
3In addition to using PlanetLab, researchers commonly use BGP
route collectors to measure paths. A study of route collector archives
from 2002 to 2010 found similar results to the PlanetLab traceroutes,
with the average number of hops increasing from 2.65 to 2.90 [14].
4For the interested reader, Google publishes its peering policy and
facilities list at http://peering.google.com and in PeeringDB.
5Some of these peers may be using remote peering [10].
0123 and aboveNumber of Hops020406080100Percentage of PathsPL to iPlane dstsGCE to iPlane dstsGCE to end-usersGCE to end-users,  weightedGCE to end-users,  weighted -- shortest path525Table 1: Estimated vs. measured path lengths from Atlas to google.com
Type
all paths
paths to on-nets
paths to oﬀ-nets
paths w/ ≤ 1 hop
Count
1,409
1,120
289
925
no error
81.26%
80.89%
82.70%
86.05%
error ≤ 1 hop
97.16%
98.21%
93.08%
97.62%
Figure 2: How many (and what fraction) of ASes Google peers with by AS
size. AS size is the number of queries that ﬂow through it, given paths from
GCE to end-user preﬁxes and per preﬁx query volumes in our CDN trace.
Volumes are normalized and bucketed by powers of 10.
Figure 2 shows the number of ASes within each bucket that do
/ do not peer with Google in our traceroutes. As expected, Google
peers with a larger fraction of higher volume ASes. And while there
are still high volume ASes that do not peer with Google, most ASes
that do not peer are small in terms of traﬃc volume and, up to the
limitations of public geolocation information, geographic footprint.
We used MaxMind to geolocate the preﬁxes that Google reaches via
a single intermediate transit provider, then grouped those preﬁxes
by origin AS. Of 20,946 such ASes, 74% have all their preﬁxes
located within a 50 mile diameter.6 However, collectively these
ASes account for only 4% of the overall query volume.
Peering is increasing over time. We evaluated how Google’s visi-
ble peering connectivity changed over time by comparing our March
2015 traces with an additional measurement conducted in August
2015. In August, we observed approximately 700 more peerings
than the 5083 we measured in March. While some of these peerings
may have been recently established, others may have been previously
hidden from our vantage point, possibly due to traﬃc engineering.
These results suggest that a longitudinal study of cloud connectivity
may provide new insights.
3.3 Estimating paths to a popular service
The previous results measured the length of paths from Google’s
GCE cloud service towards end-user preﬁxes. However, these paths
may not be the same as the paths from large web properties such as
Google Search and YouTube for at least two reasons. First, Google
and some other providers deploy front-end servers inside some end-
user ASes [9], which we refer to as oﬀ-net servers. As a result, some
client connections terminate at oﬀ-nets hosted in other ASes than
where our GCE traceroutes originate. Second, it is possible that
Google uses diﬀerent paths for its own web services than it uses
for GCE tenants. In this section, we ﬁrst describe how we estimate
the path length from end-users to google.com, considering both
of these factors. We then validate our approach. Finally, we use
our approach to estimate the number of AS hops from end-users to
google.com and show that some of the paths are shorter than our
GCE measurements above.
Estimating AS Hops to Google Search: First, we use EDNS0 client-
subnet queries to resolve google.com for each /24 end-user preﬁx,
as in our previous work [9]. Each query returns a set of server
IP addresses for that end-user preﬁx to use. Next, we translate the
server addresses into ASes as described in §2. We discard any end-
user preﬁx that maps to servers in multiple ASes, leaving a set of
preﬁxes directed to servers in Google’s AS and a set of preﬁxes
directed to servers in other ASes.
6Geolocation errors may distort this result, although databases tend
to be more accurate for end-user preﬁxes like the ones in question.
Figure 3: Paths lengths from Google.com and GCE to end-users
For end-user preﬁxes directed towards Google’s AS, we estimate
the number of AS hops to google.com as equal to the number of
AS hops from GCE to the end-user preﬁx, under the assumption,
which we will later validate, that Google uses similar paths for
its cloud tenants and its own services. For all other traces, we
build a graph of customer/provider connectivity in CAIDA’s AS
relationship dataset [3] and estimate the number of AS hops as the
length of the shortest path between the end-user AS and the oﬀ-net
server’s AS.7 Since oﬀ-net front-ends generally serve only clients
in their customer cone [9] and public views such as CAIDA’s should
include nearly all customer/provider links that deﬁne these customer
cones [34], we expect these paths to usually be accurate.
Validating Estimated AS Hops: To validate our methodology for
estimating the number of AS hops to google.com, we used tracer-
outes from 1409 RIPE Atlas probes8 to google.com and converted
them to AS paths. We also determined the AS hosting the Atlas
probe and estimated the number of AS hops from it to google.com
as described above.9
For the 289 ground-truth traces directed to oﬀ-nets, we calculate
the diﬀerence between the estimated and measured number of AS
hops. For the remaining 1120 traces that were directed to front-ends
within Google’s network, we may have traceroutes from GCE to
multiple preﬁxes in the Atlas probe’s AS. If their lengths diﬀered,
we calculate the diﬀerence between the Atlas-measured AS hops
and the GCE-measured path with the closest number of AS hops.
Table 1 shows the result of our validation: overall, 81% of our
estimates have the same number of AS hops as the measured paths,
and 85% in cases where the number of hops is one (front-end
AS peers with client AS). We conclude that our methodology is
accurate enough to estimate the number of AS hops for all clients
to google.com, especially for the short paths we are interested in.
Oﬀ-net front-ends shorten some paths even more. Applying our
estimation technique to the full set of end-user preﬁxes, we arrive
at the estimated AS hop distribution shown in the Google.com to
end-users, weighted line in Figure 3.
The estimated paths between google.com and end-user preﬁxes
are shorter overall than the traces from GCE, with 73% of queries
coming from ASes that either peer with Google, use oﬀ-nets hosted
in their providers, or themselves host oﬀ-nets. For clients served by
oﬀ-nets, the front-end to back-end portions of their connections also
7If the end-user AS and oﬀ-net AS are the same, the length is zero.
8The rest of the 1600 traceroutes failed.
9We are unable to determine the source IP address for some Atlas
probes and thus make estimations at the AS level.
100101102103104105106107108Aggregated per AS query volume(normalized and bucketed)02000400060008000Number of ASes7%8%8%11%22%43%69%89%100%Non-PeersPeers0123 and aboveNumber of Hops020406080100Percentage of PathsGCE to end-users,  weightedGoogle.com to end-users,  weighted526Figure 4: Paths lengths from diﬀerent cloud platforms to end-users.
Figure 5: Path lengths from RIPE Atlas nodes to content and cloud11
cross domains, starting in the hosting AS and ending in a Google
datacenter. The connection from the client to front-end likely plays
the largest role in client-perceived performance, since Google has
greater control of, and can apply optimizations to, the connection
between the front-end and back-end [17]. Still, we evaluated that
leg of the split connection by issuing traceroutes from GCE to the
full set of Google oﬀ-nets [9]. Our measurements show that Google
has a direct connection to the hosting AS for 62% of oﬀ-nets, and
there was only a single intermediate AS for an additional 34%.
3.4 Paths to Other Popular Content
In this section, we compare measurements of Google and other
providers. First, in Figure 4, we compare the number of AS hops
(weighted by query volume) from GCE to the end-user preﬁxes to
the number of AS hops to the same targets from two other cloud
providers. While SoftLayer and AWS each have a substantial number
of one hop paths, both are under 42%, compared to well over 60%
for GCE. Still, the vast majority of SoftLayer and AWS paths have
two hops or less. Our measurements and related datasets suggest
that these three cloud providers employ diﬀerent strategies from
each other: Google peers widely, with 5083 next hop ASes in our
traceroutes, and only has 5 providers in CAIDA data [3], using
routes through those providers to reach end users responsible for
10% of the queries in our CDN trace; Amazon only has 756 next
hop ASes, but uses 20 providers for routes to 50% of the end user
queries; and SoftLayer is a middle ground, with 1986 next hops and
11 providers it uses to reach end users with 47% of the queries.
We anticipate that some other large content providers are build-
ing networks similar to Google’s to reduce transit costs and im-
prove quality of service for end-users. Since we cannot issue tracer-
outes from within these providers’ networks towards end-users,10
we use traceroutes from RIPE Atlas vantage points towards the
providers. We execute traceroutes from a set of Atlas probes towards
facebook.com and Microsoft’s bing.com. We calibrate these re-
sults with our earlier ones by comparing to traceroutes from the
Atlas probes towards google.com and our GCE instance.
Figure 5 shows the number of AS hops to each destination.11 The
AS hop distribution to bing.com is nearly identical to the AS hop
distribution to GCE. Paths to bing.com are longer than paths to
google.com, likely because Microsoft does not have an extensive
set of oﬀ-net servers like Google’s. Facebook trails the pack, with
just under 40% of paths to facebook.com having 1 AS hop.
Summary. Path lengths for popular services tend to be much
shorter than random Internet paths. For instance, while only 2%
of PlanetLab paths to iPlane destinations are one hop, we estimate
that 73% of queries to google.com go directly from the client AS
to Google.
10Microsoft’s Azure Cloud appears to block outbound traceroutes.
11The percentages are of total Atlas paths, not weighted.
4. CAN SHORT PATHS BE
BETTER PATHS?
Our measurements suggest that much of the Internet’s popular
content ﬂows across at most one interdomain link on its path to
clients. In this section, we argue that these direct connections may
represent an avenue to making progress on long-standing Internet
routing problems. Within the conﬁnes of this short paper, we do
not develop complete solutions. Instead, we sketch where and why
progress may be possible, starting with general arguments about
why short paths may help, and then continuing with particular prob-
lems where short paths may yield deployable solutions. We hope
this paper serves as a spark for future work in this area.
4.1 Short paths sidestep existing hurdles
Paths to popular content will continue to shorten. Competi-
tive pressures and the need to ensure low latency access to popular
content will continue to accelerate this trend. Services are mov-