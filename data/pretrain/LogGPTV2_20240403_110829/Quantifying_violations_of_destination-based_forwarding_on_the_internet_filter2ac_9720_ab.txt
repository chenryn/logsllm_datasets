Analysis methodology: We recorded all experimental datasets
between December 16, 2011 and March 12, 2012. Before we con-
ducted each experiment, we compiled a list of suitable PlanetLab
nodes by selecting at most one active node per AS. For sets PL/PL
and R/PL+S we also removed nodes from the sender set which em-
ploy spooﬁng ﬁlters since these experiments use spoofed source
addresses in some probes. Since set PL/PL only investigates di-
rect routes between PlanetLab nodes, we encountered fewer than
2,000 unique IPs on the paths between these nodes; sets R/PL and
R/PL+S encountered about 25,000 IPs each when targeting arbi-
trary destinations within seven hops distance. Overall, we recorded
more than 260,000 traces using 179 PlanetLab sites, 65 of which
do not ﬁlter source-spoofed packets.
After we recorded the measurements, we compared each test
hop-sequence with its corresponding control hop-sequence. We
analyzed the data at two levels of granularity: IP addresses and
AS numbers. To map an IP address stored in the RR ﬁeld to its cor-
Figure 3: Overview of the coverage of nodes by each of the
experiment sets and the ping packets associated with it. Vio-
lations can only be detected in ﬁlled nodes due to the RR hop
limit.
PlanetLab nodes, we designed two additional sets of experiments.
In Set R/PL (Router-to-PlanetLab) we send an RR ping from a Plan-
etLab node P1 to a node R and use the hops visited by the response
along the reverse path back to P1 as the control hop-sequence.
Then, P1 sends an RR ping to each such hop as the test probe, again
selecting the hops visited by the response as the test hop-sequence.
Since we designed this approach to analyze paths back to the source
of the ping, it has the advantage of not requiring spooﬁng. How-
ever, it has the drawback that R can be at most seven hops away
from the source to leave space for at least two reverse hops in the
RR ﬁeld. We inject the test probe at the ﬁrst reverse hop and use
the second reverse hop to test the fork condition. The Set R/PL part
of Figure 3 illustrates which hops this methodology can test. To
determine which nodes are suitable choices for R for each Plan-
etLab node, we had the node send an RR ping to the .1 address in
each routable /24 preﬁx and retained those that were responsive and
within range.
Our third set, Set R/PL+S (Router-to-PlanetLab with spooﬁng),
uses source spooﬁng to expand the coverage of the second set, as
seen in Figure 3. Each PlanetLab node P1 probes each nearby
router R that it probed in R/PL, but P1 sends multiple RR pings
to R, spooﬁng as each of the other PlanetLab nodes in turn. This
technique measures the (partial) path from R to a PlanetLab node
P2 even if P2 is not near R. We use the hops h1, ..., hm tra-
versed by the response from R to P2 as the control hop-sequence.
We produce the test hop-sequences by sending probes from P1 to
h1, ..., hm directly and extracting the hops visited by the response.
Establishing Fork Causality: In addition to determining viola-
tors, we also want to establish causality for forks. We explore two
causes, load balancing and MPLS tunnels. Attributing violations to
other causes is left for future work.
To characterize a violation as induced by load balancing, we
employ two techniques. First, we measure the paths between our
source-destination pairs with Paris traceroute, a traceroute variant
that measures all load balancing paths to the destination [4]. Since
traceroute and RR may record different IP addresses for a given
router [17], we align the Paris traceroutes with our RR pings us-
ing IP alias data [12].
If a violating node is an alias for a load
balancer seen by Paris traceroute on the same route, we classify
the violation as being caused by load balancing. Since the alias
data is likely incomplete, we use a second technique to attribute
P1P2RP1RP1P2SetPL/PLSetR/PLSetR/PL+SRequestP1 → P2RequestP1 → RResponseR → P1RequestP1 → RResponseR → P2267Traces recorded
Involved PlanetLab nodes
IP addresses targeted
IP addresses violating (IP forks)
IP addresses violating (AS forks)
ASes targeted
ASes w/ viol. IP addr. (IP forks)
ASes w/ viol. IP addr. (AS forks)
262,034
179
39,699
11,487 (28.9%)
505 (1.3%)
3,777
669 (17.7%)
165 (4.4%)
Table 1: Overview of combined results from all experiment sets
(PL/PL, R/PL, R/PL+S)
Type
Without violation
Load balancing
Explicit MPLS tunnel
Default routing
Unclassiﬁed
Freq. (IP)
Freq. (AS)
72.6%
22.3%
0.2%
0.2%
11.8%
89.9%
0.0%
0.0%
0.2%
10.0%
Table 3: Percentages of paths between source-destination pairs
where a violation of particular type (or no violation at all) was
observed in the PL/PL set (only considering ﬁrst nine hops)
Type
Non-violating
Load balancing
Explicit MPLS tunnel
Default routing
Unclassiﬁed
Invalid
Freq. (IP)
Freq. (AS)
74.8%
16.1%
0.4%
0.3%
6.9%
1.5%
97.8%
0.0%
0.0%
0.3%
1.7%
0.0%
Table 2: Node type frequencies in Set PL/PL for IP and AS
forks
responding AS number, we used preﬁx-to-AS mappings provided
by an iPlane dataset [15].
On the IP level, we classiﬁed a targeted node as a violating router
if, for at least one pair of paths to a common destination, the next
hop differed. In this case we observed an IP fork. If the next AS,
different from the AS of the targeted node, differed between the
control and test hop-sequences, we labeled it an AS fork.
Frequency of violations: Table 1 summarizes the experimental
results. Out of nearly 40,000 targeted IP addresses, 28.9% caused
IP forks and 1.3% of the nodes caused an AS fork. The existence of
a non-trivial fraction of AS forks is interesting, and to our knowl-
edge, has not been documented elsewhere. Our results also indicate
that most of these forks occur at edge routers. It is not surprising
that the fraction of nodes causing AS forks is signiﬁcantly smaller
than the number of nodes responsible for IP forks for the follow-
ing reason. We expect the majority of IP forks to be the result of
load balancing, and prior studies have shown that most load bal-
ancers only distribute trafﬁc across multiple paths inside their own
AS boundaries [3]. Thus, forks caused by load balancing usually
converge before leaving the current AS and rarely translate to AS
forks.
Causes of Violations: As discussed earlier, violations can have
different causes, e.g., load balancing, MPLS tunneling, or other
routing policies. In this section we classify forks by cause.
Table 2 provides a classiﬁcation of the targeted nodes in set PL/PL
(classifying violations in sets R/PL and R/PL+S is difﬁcult since
this requires traceroutes from the R router, which we could not
obtain for these sets). The middle column shows statistics for all
forks, whereas the right column only considers forks which also
result in differing AS traversals. Table 3 shows statistics for the vi-
olation types observed on paths between source-destination pairs.
We determined load balancing, Explicit MPLS tunnel2, and de-
fault routing violations as described in Section 2. We classiﬁed a
node as invalid if we suspected routing instabilities or if the conﬁ-
dence of having observed all interfaces was below 99%. Any vio-
2Our traceroute data as well as results from an earlier study [18]
indicate that about 25% of the paths contain an MPLS tunnel, but
in our experiments most of them do not trigger a violation.
Figure 4: Fraction of violating IP addresses in an AS, that are
violators for the most frequently targeted ASes (all experimen-
tal sets)
lation that did not ﬁt in any of these categories is labeled as unclas-
siﬁed.
The distribution suggests that we can attribute the majority of IP
forks to load balancing. However, for more than 6% of the cases
we were unable to determine a violation cause. For many of these
cases, we did not observe the violator on any recorded traceroute,
e.g., due to ICMP error message ﬁltering by some routers or miss-
ing IP address alias mappings. Thus, a fraction of these violations
could still be the result of load balancing. However, we did not ob-
serve any load balancers causing AS-level divergences. All cases
of default routing caused AS forks, as did a signiﬁcant portion of
the unclassiﬁed violations. Additional causes such as routing poli-
cies incorporating source addresses may be responsible for some
path forks. In Section 4 we discuss some speciﬁc instances of the
unclassiﬁed violations in more detail.
These frequencies may be a lower bound on the likelihood of ob-
serving violations on paths, because RR’s nine hop limit restricts
the coverage of our methodology. For example, as we discuss be-
low, traceroutes from PlanetLab nodes to randomly selected des-
tinations revealed that over 70% of the paths include at least one
load-balancing node. However, many of these load balancers were
in core networks that were located more than nine hops from our
sources.
AS Characteristics: Next, we analyzed which ASes exhibited
violations and with what frequency. Table 1 shows that we ob-
served IP-level forks in 17.7% of the visited ASes and AS forks
in 4.4% of the ASes assessed. However, the distribution of violat-
ing IP addresses across ASes is not uniform, with the number of
IP addresses in an AS observed to cause a fork varying from 1%
to over 70%. In Figure 4, we show the violation frequencies for
the ASes in which we probed the most targets. While 55% of the
targeted COGENT nodes are violating routers, less than 5% of the
targeted TWTC addresses are responsible for a path fork. A likely
explanation for these differences across ASes is the variability in
AS engineering practices. For example, Sommers et al. found that
COGENT is one of the top-10 ASes in terms of total MPLS tunnels
268Type
AS Name
COGENT
Large ISP
AR-TAST-LACNIC Large ISP
Large ISP
SWISSCOM
Stub
GNAXNET-AS
GBLX
Tier-1
obs. IPs
viol. IPs
3303
62
600
35
1119
86
18
13
12
12
Table 4: Statistics for ASes with the largest number of violating
IP addresses (viol. IPs) causing AS forks (all experimental sets;
obs. IPs describes the number of observed IPs in that AS in our
measurements)
Diamond type
Single AS
Multiple ASes
µ
2.5
4.9
σ Median
2.0
2.5
2
5
Table 5: Diamond length statistics from traces with violations
from Set PL/PL
per AS, which likely contributes to the high number of violations
in that AS [18].
We obtained similar results when considering only nodes respon-
sible for AS forks. Table 4 shows the statistics for the ASes with the
largest number of violating IP addresses and gives the UCLA In-
ternet Topology Project’s AS-type classiﬁcation for the ASes [19].
As the table shows, AS forks can be found even in large ISPs and
a Tier-1 provider, possibly due to the usage of MPLS and policy-
based routing for trafﬁc engineering.
Diamond lengths:
In this section we analyze how much two
paths deviate from each other once they traverse a violating router,
before reconverging on their path to the common destination. The
deviating path portion is termed a diamond [4]. To do so, we count
the number of hops between the violating router and the ﬁrst inter-
face common to the two paths after the violating router. We refer
to the common interface as the merging router, and we refer to
the number of hops between the violating router and the merging
router as the diamond length.3 Note that due to the nine hop limit