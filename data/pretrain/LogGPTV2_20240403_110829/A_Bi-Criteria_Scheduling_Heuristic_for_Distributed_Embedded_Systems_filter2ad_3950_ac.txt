( n
B cf
θ
ta n ( θ)G
L =
(o1, {p2})
(o1, {p1})
(o1, {p1, p3})
0
0
0.4
0.2
0.8
Relative gain G(n)(o1, Pj )
Figure 6. Selection of the best choice with Bcf .
0.6
1
Figure 6 illustrates the Bcf computation for operation o1.
We ﬁrst compute the set 2P
of all combinations of all pro-
cessors of P. We then compute, for each set Pi ∈ 2P
,
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 05:38:08 UTC from IEEE Xplore.  Restrictions apply. 
the compromise value Bcf (n)(o1, Pi). Graphically, it is the
−−−−−−−−−→
Bcf (n)(o1, Pi) vector, whose end is the orthog-
length of the
onal projection of the point (G(o1, Pi),L(o1, Pi)) onto the
line L = tan(θ)G (with θ = 45◦
here). In the present case,
the best compromise value is reached for Pi = {p1, p3}. As
a consequence, o1 is replicated onto two processors, p1 and
p3. In general, replicating an operation maximizes the sys-
tem reliability [20] and minimizes the schedule length [3].
4.2 Our scheduling algorithm RBSA
The RBSA scheduling algorithm is shown in Figure 7.
of all combinations of processors of P;
Algorithm RBSA:
input: Alg, Arc, Exe, Dis, Rel, Rel obj, Rtobj, and θ;
output: a reliable distributed static schedule of Alg on Arc satis-
fying Rel obj and Rtobj, or a fails message;
begin
Compute the set 2P
/* the user can limit the degree k of processor combinations */
Initialize the lists of candidate and scheduled operations:
n := 0;
:= {o ∈ O | pred(o) = ∅};
O(0)
:= ∅;
O(0)
while O(n)
➀ For each candidate operation ocand, compute Bcf (n) on each
(cid:5)= ∅ do
sched
cand
cand
set Pk of 2P
:
Bcf
(n)(ocand, Pk)
:= cos(θ)L(n)(ocand, Pk) +
sin(θ)G(n)(ocand, Pk)
➁ For each candidate operation ocand, select
the best set
best
P ocand
Bcf
such that:
(n)(ocand, P ocand
best
) := min
k
Bcf
(n)(ocand, Pk)
best
Initially, O(0)
sched is empty and O(0)
cand is the list of opera-
tions without any predecessors. At the n-th step, these lists
are updated according to the data-dependencies of Alg.
At each step n, one operation ocand of the list O(n)
cand is
selected to be scheduled on at least one processor. To se-
lect an operation, we select at the micro-steps ➀ and ➁,
for each candidate operation ocand, the set P ocand
of pro-
best
cessors having the smallest bi-criteria compromise value.
(cid:2), we select at
Then, among those best pairs (cid:1)ocand, P ocand
the micro-step ➂ the one having the biggest Bcf value, i.e.,
the most urgent pair (cid:1)ourgent, P ourgent
The selected operation ourgent is replicated and imple-
mented actively at the micro-step ➃ on each processor of
P ourgent
computed at micro-step ➁, and the communi-
cations implied by these implementations are also imple-
mented actively on communications links. When a com-
munication operation is generated, it is assigned to the set
of communication units bound to the fastest communication
medium connecting the processors executing the source and
destination operations.
Finally, we check at the micro-step ➅ if the two objec-
tives Rel obj and Rtobj are satisﬁed or not. If they are not,
the user can change θ or the objectives and re-execute the
algorithm.
(cid:2).
best
best
4.3 An example
◦
Figure 8 shows the ﬁnal reliable schedule produced by
for the graphs Alg and Arc of Fig-
RBSA with θ = 45
ure 2. The objectives taken for running RBSA were Rt obj
= 16 and Rel obj = 0.999997. The results obtained by
RBSA are Rt f inal = 13 and Rel f inal = 0.9999991.
➂ Select the most urgent candidate operation ourgent between
all oi
Bcf
cand of O(n)
(n)(ourgent, P ourgent
cand such that:
best
) := max
i
Bcf
(n)(oi
cand, P oi
best
cand
)
➃ Schedule actively each replica of ourgent on each proces-
; the implied communications are also im-
sor of P ourgent
plemented actively on the communications links;
➄ Compute the new values Rel sched and Rtsched;
➅ if (Rel sched  Rtobj)
best
then return “fails to satisfy objectives” /* the user can re-
execute the algorithm by changing θ or the objectives */
➆ Update the lists of candidate and scheduled operations:
:= O(n−1)
:= O(n)
cand
O(n)
sched
O(n+1)
{o(cid:2) ∈ succ(ourgent) | pred(o(cid:2)) ⊆ O(n)
cand
∪ {ourgent};
− {ourgent} ∪
sched
sched
};
Figure 8. The ﬁnal reliable schedule produced
by RBSA with θ = 45◦.
➇ n := n + 1;
end while
end
Figure 7. The RBSA scheduling algorithm.
4.4 Run-time behavior
In order to give the same weight to L and G in the Bcf
. If the Rel obj or Rtobj
computation, we ﬁrst take θ = 45◦
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 05:38:08 UTC from IEEE Xplore.  Restrictions apply. 
requirements are not met at the micro-step ➄, then the user
can refer to Table 3 to change θ, Rel obj, or Rtobj, and re-
execute RBSA until both requirements are met.
4. If both criteria are satisﬁed, then the user can generate
executable code from the ﬁnal schedule, for instance
by using the SYNDEX tool [16, 9].
RBSA output
user action
RBSA output
user action
Rel obj and Rtobj
θnew ∈ [θ, 90◦];
re-execute RBSA;
Rel obj and Rtobj
Rel obj,
change
Rtobj, and/or θ;
re-execute RBSA;
Reliability and run-time objectives
Rel obj and Rtobj
θnew ∈ [0◦, θ];
re-execute RBSA;
Rel obj and Rtobj
generate
reliable
distributed code;
Rel obj (resp. Rtobj) means that Rel obj (resp. Rtobj) is not satisﬁed
Table 3. Re-execution strategy for RBSA.
Four cases can arise:
1. If Rel obj is not met, then we re-execute RBSA with a
new θ: here, we take θnew ∈ [θ, 90◦], meaning that L
will have more weight than G in Bcf .
2. If Rtobj is not met, then we re-execute RBSA by
changing θ. We take θnew ∈ [0◦, θ], meaning that L
will have less weight than G in Bcf when we re-execute
RBSA. For instance, in Figure 9, we decrement θ; so
{p3} become the best replication set for operation o1,
instead of {p1, p3} previously; as a consequence, o1 is
not replicated in the new schedule.
L(n)(o1, Pj )
1
0.8
0.6
0.4
0.2
0
0
(o1, {p3})
∗G
ta n θ
L =
G
θ
∗
,
] )
◦
θ n e w
∈
0
[
(oi, {p2})
L
( c
n
a
= t
θ n e w
a s e
(o1, {p1})
(o1, {p1, p3})
G(n)(o1, Pj )
θ
θnew
0.2
0.4
0.6
0.8
1
Figure 9. Changing the bi-criteria compro-
mise parameters.
3. If none of the criteria are satisﬁed, then the user has
to loosen at least one of the two objectives Rel obj or
Rtobj before re-executing RBSA. He/she can also
change θ.
Finally, remember that for complexity reasons, we com-
pute in Bcf only the upper bound of the partial schedule’s
reliability. Hence, once we have obtained the ﬁnal sched-
ule, we compute its exact reliability, which we compare to
Rel obj.
5 RBSA time complexity
We compute the time complexity of RBSA as follows.
Among the micro-steps ➀ to ➇, the dominant one is ➀.
The computational complexity of the combinations of pro-
cessors of P is O(mk+1), where m is the number of pro-
cessors in Arc and k is the degree of maximum processor
combinations. Thus, the time complexity of micro-step ➀
is O(N mk+1), where N is the number of operations in
Alg. Thus, for n iterations the overall time complexity is
O(nN mk+1). Finally, since exactly one operation is repli-
cated and scheduled at each iteration, n = N, and the total
time complexity is therefore O(N 2mk+1).
6 Performance evaluation
6.1 Simulation parameters
To evaluate RBSA, we have compared its performances
with our previous algorithm proposed in [8], called FT-
BAR (Fault-Tolerance Based Active Replication), and with
the algorithm proposed by Hashimoto in [12], called HBP
(Height-Based Partitioning). HPB actively replicates all op-
erations once, therefore producing schedules that tolerate
one processor failure, while FTBAR actively replicates all
operations a ﬁxed number of times, say n, therefore pro-
ducing schedules that tolerate n − 1 processor failures. We
have implemented all three algorithms within the SYNDEX
tool [16, 9]. SYNDEX generates automatically executable
fault-tolerant distributed code, by ﬁrst producing a static
fault-tolerant distributed schedule of a given algorithm on
a given distributed architecture (either with FTBAR, HBP,
or RBSA), and then by generating sthe real-time fault-
tolerant distributed executive implementing this schedule.
The performance comparisons were done in two ways
and with various parameters: ﬁrst RBSA with θ = 0◦
against FTBAR and HBP without any replication of oper-
ation, then RBSA with θ = 45◦
against FTBAR and HBP
with exactly one replication of each operation. At each run,
the Rel obj and Rtobj objectives given to RBSA were com-
puted on the ﬁnal schedule produced by FTBAR.
The random algorithm graphs were generated as follows:
given the number of operations N, we randomly generate a
set of levels with a random number of operations. Then, op-
erations at a given level are randomly connected to opera-
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 05:38:08 UTC from IEEE Xplore.  Restrictions apply. 
tions at a higher level. The WCET of each operation are ran-
domly selected from a uniform distribution with the mean
equal to the chosen average execution time. Similarly, the
WCTT of each data dependency are randomly selected from
a uniform distribution with the mean equal to the chosen av-
erage communication time. For generating the complete set
of algorithm graphs, we have varied two parameters: N=25,
50, 75, 100, and the Communication-to-Computation Ratio
CCR=0.1, 1, and 10, deﬁned as the average communication
time divided by the average computation time.
6.2 Performance of RBSA against HBP and FT-
BAR for θ = 0◦
In this simulation, the architecture graph Arc was a fully
connected network of 4 processors, with the failure rates of
processors and communications links given in Table 2. For
each schedule, we have computed the normalized sched-
ule length (NSL), obtained by dividing the output schedule
length by the sum of the computation costs on the critical-
path of each graph [3]. Thus, we have compared the average
NSL produced by RBSA with those produced by FTBAR
and HBP, averaged over 50 random Alg graphs. To make
the comparison fair, FTBAR and HBP were run without any
replication of operation.
In Figure 10, we have plotted the average NSL as a func-
tion of CCR, for N=100 operations. RBSA was run with
, meaning that only Rtobj was taken into account as
θ = 0◦
objective (i.e., no reliability objective).
l
h
t
g
n
e
L
e
u
d
e
h
c
S
d
e
z
i
l
a
m
r
o
N
e
g
a
r
e
v
A
70
60
50
40
30
20
10
0
0.1
RBSA(0)
FTBAR(0)
HBP(0)
10
Figure 10. Average NSLs for θ = 0◦ and N =
100 operations.
1
CCR