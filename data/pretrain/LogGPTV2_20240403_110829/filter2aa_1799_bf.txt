-
dating a database, or modifying a shared variable, no other thread can be allowed to access the same 
data structure without mutual exclusion.
The issue of mutual exclusion, although important for all operating systems, is especially impor-
tant (and intricate) for a tightly coupled, symmetric multiprocessing (SMP) operating system such as 
Windows, in which the same system code runs simultaneously on more than one processor, sharing 
-
nisms that system code can use to prevent two threads from modifying the same data at the same 
time. The kernel provides mutual-exclusion primitives that it and the rest of the executive use to syn-
chronize their access to global data structures.
Because the scheduler synchronizes access to its data structures at DPC/dispatch level IRQL, the 
kernel and executive cannot rely on synchronization mechanisms that would result in a page fault or 
reschedule operation to synchronize access to data structures when the IRQL is DPC/dispatch level 
or higher (levels known as an elevated or high
kernel and executive use mutual exclusion to protect their global data structures when the IRQL is high 
and what mutual-exclusion and synchronization mechanisms the kernel and executive use when the 
IRQL is low (below DPC/dispatch level).
172 
CHAPTER 8 System mechanisms
High-IRQL synchronization
At various stages during its execution, the kernel must guarantee that one, and only one, processor at 
mutually exclusive manner.
Simple single-processor operating systems sometimes prevent such a scenario by disabling all inter-
rupts each time they access global data, but the Windows kernel has a more sophisticated solution. 
Before using a global resource, the kernel temporarily masks the interrupts whose interrupt handlers 
-
causes the dispatcher, which uses the dispatcher database, to run. Therefore, any other part of the 
kernel that uses the dispatcher database raises the IRQL to DPC/dispatch level, masking DPC/dispatch-
level interrupts before using the dispatcher database.
-
processor. The kernel also needs to guarantee mutually exclusive access across several processors.
Interlocked operations
The simplest form of synchronization mechanisms relies on hardware support for multiprocessor-
safe manipulation of integer values and for performing comparisons. They include functions such as 
InterlockedIncrement, InterlockedDecrement, InterlockedExchange, and InterlockedCompareExchange. 
The InterlockedDecrement function, for example, uses the x86 and x64 lock-
ple, lock xadd) to lock the multiprocessor bus during the addition operation so that another processor 
functions are called intrinsic because the code for them is generated in an inline assembler, directly 
-
rameters onto the stack, calling the function, copying the parameters into registers, and then popping 
the parameters off the stack and returning to the caller would be a more expensive operation than the 
Spinlocks
The mechanism the kernel uses to achieve multiprocessor mutual exclusion is called a spinlock. A 
spinlock is a locking primitive associated with a global data structure, such as the DPC queue shown 
CHAPTER 8 System mechanisms
173
Do
Try to acquire
DPC queue
spinlock
Until SUCCESS
Do
Try to acquire
DPC queue
spinlock
Until SUCCESS
Processor A
•••
Processor B
•••
DPC queue
Begin
Remove DPC from queue
End
Release DPC queue spinlock
Begin
Add DPC from queue
End
Release DPC queue spinlock
Critical section
Spinlock
DPC
DPC
FIGURE 8-38 Using a spinlock.
-
lock until it succeeds. The spinlock gets its name from the fact that the kernel (and thus, the processor) 
waits, “spinning,” until it gets the lock.
Spinlocks, like the data structures they protect, reside in nonpaged memory mapped into the 
system address space. The code to acquire and release a spinlock is written in assembly language for 
speed and to exploit whatever locking mechanism the underlying processor architecture provides. On 
many architectures, spinlocks are implemented with a hardware-supported test-and-set operation, 
which tests the value of a lock variable and acquires the lock in one atomic instruction. Testing and ac-
quiring the lock in one instruction prevents a second thread from grabbing the lock between the time 
such the lock instruction mentioned earlier can also be used on the test-and-set operation, resulting in 
the combined lock bts opcode on x86 and x64 processors, which also locks the multiprocessor bus; oth-
erwise, it would be possible for more than one processor to perform the operation atomically. (Without 
the lock, the operation is guaranteed to be atomic only on the current processor.) Similarly, on ARM 
processors, instructions such as ldrex and strex can be used in a similar fashion.
All kernel-mode spinlocks in Windows have an associated IRQL that is always DPC/dispatch level or 
lower ceases on that processor. Because thread dispatching happens at DPC/dispatch level, a thread 
that holds a spinlock is never preempted because the IRQL masks the dispatching mechanisms. This 
masking allows code executing in a critical section protected by a spinlock to continue executing so 
that it will release the lock quickly. The kernel uses spinlocks with great care, minimizing the number of 
instructions it executes while it holds a spinlock. Any processor that attempts to acquire the spinlock 
and performing no actual work.
174 
CHAPTER 8 System mechanisms
On x86 and x64 processors, a special pause assembly instruction can be inserted in busy wait loops, 
and on ARM processors, yieldhint to the processor 
that the loop instructions it is processing are part of a spinlock (or a similar construct) acquisition loop. 
I 
looping.
I 
On SMT cores, it allows the CPU to realize that the “work” being done by the spinning logical
core is not terribly important and awards more CPU time to the second logical core instead.
I 
Because a busy wait loop results in a storm of read requests coming to the bus from the waiting
thread (which might be generated out of order), the CPU attempts to correct for violations of
memory order as soon as it detects a write (that is, when the owning thread releases the lock).
Thus, as soon as the spinlock is released, the CPU reorders any pending memory read opera-
tions to ensure proper ordering. This reordering results in a large penalty in system perfor-
mance and can be avoided with the pause instruction.
If the kernel detects that it is running under a Hyper-V compatible hypervisor, which sup-
ports the spinlock enlightenment (described in Chapter 9), the spinlock facility can use the
HvlNotifyLongSpinWait library function when it detects that the spinlock is currently owned
by another CPU, instead of contiguously spinning and use the pause instruction. The func-
tion emits a HvCallNotifyLongSpinWait hypercall to indicate to the hypervisor scheduler that
another VP should take over instead of emulating the spin.
The kernel makes spinlocks available to other parts of the executive through a set of kernel func-
tions, including KeAcquireSpinLock and KeReleaseSpinLock. Device drivers, for example, require spin-
locks to guarantee that device registers and other global data structures are accessed by only one part 
of a device driver (and from only one processor) at a time. Spinlocks are not for use by user programs—
user programs should use the objects described in the next section. Device drivers also need to protect 
access to their own data structures from interrupts associated with themselves. Because the spinlock 
KeAcquireInterruptSpinLock and KeReleaseInterruptSpinLock 
system looks inside the interrupt object for the associated DIRQL with the interrupt and raises the IRQL 
to the appropriate level to ensure correct access to structures shared with the ISR. 
Devices can also use the KeSynchronizeExecution API to synchronize an entire function with an ISR 
instead of just a critical section. In all cases, the code protected by an interrupt spinlock must execute 
negative performance effects.
an IRQL of DPC/dispatch level or higher, as explained earlier, code holding a spinlock will crash the 
system if it attempts to make the scheduler perform a dispatch operation or if it causes a page fault.
CHAPTER 8 System mechanisms
175
Queued spinlocks
To increase the scalability of spinlocks, a special type of spinlock, called a queued spinlock, is used in 
many circumstances instead of a standard spinlock, especially when contention is expected, and fair-
ness is required. 
A queued spinlock works like this: When a processor wants to acquire a queued spinlock that is 
the meantime, a processor waiting for a busy spinlock checks the status not of the spinlock itself but of 
-
synchronization, and the memory location of the bit is not in a single NUMA node that then has to be 
snooped through the caches of each logical processor. The second is that instead of a random pro-
queued spinlocks do require additional overhead, including extra interlocked operations, which do add 
decide if a queued spinlock is worth it for them.
globalprocessor 
control region LockArrayKPCR 
data structure.
A global spinlock can be acquired by calling KeAcquireQueuedSpinLock with the index into the array 
at which the pointer to the spinlock is stored. The number of global spinlocks originally grew in each 
KSPIN_LOCK_QUEUE_NUMBER enumeration, but note, however, 
that acquiring one of these queued spinlocks from a device driver is an unsupported and heavily 
176 
CHAPTER 8 System mechanisms
EXPERIMENT: Viewing global queued spinlocks
You can view the state of the global queued spinlocks (the ones pointed to by the queued 
!qlocks kernel debugger command. In the 
following example, note that none of the locks are acquired on any of the processors, which is a 
standard situation on a local system doing live debugging.
lkd> !qlocks 
Key: O = Owner, 1-n = Wait order, blank = not owned/waiting, C = Corrupt 
Processor Number 
    Lock Name
0  1  2  3  4  5  6  7 
KE   - Unused Spare
MM   - Unused Spare
MM   - Unused Spare
MM   - Unused Spare
CC   - Vacb
CC   - Master
EX   - NonPagedPool
IO   - Cancel
CC   - Unused Spare
In-stack queued spinlocks
Device drivers can use dynamically allocated queued spinlocks with the KeAcquireInStackQueued 
SpinLock and KeReleaseInStackQueuedSpinLock functions. Several components—including the cache 
global queued spinlocks. 
KeAcquireInStackQueuedSpinLock takes a pointer to a spinlock data structure and a spinlock queue 
handle. The spinlock queue handle is actually a data structure in which the kernel stores information 
usually a stack variable, guaranteeing locality to the caller thread and is responsible for the InStack part 
of the spinlock and API name.
Reader/writer spin locks
While using queued spinlocks greatly improves latency in highly contended situations, Windows 
contention in many situations to begin with. The multi-reader, single-writer spinlock, also called 
the executive spinlock, is an enhancement on top of regular spinlocks, which is exposed through 
the ExAcquireSpinLockExclusive, ExAcquireSpinLockShared API, and their ExReleaseXxx counterparts. 
Additionally, ExTryAcquireSpinLockSharedAtDpcLevel and ExTryConvertSharedSpinLockToExclusive 
functions exist for more advanced use cases.
EXPERIMENT: Viewing global queued spinlocks
You can view the state of the global queued spinlocks (the ones pointed to by the queued 
!qlocks kernel debugger command. In the 
following example, note that none of the locks are acquired on any of the processors, which is a 
standard situation on a local system doing live debugging.
lkd> !qlocks
Key: O = Owner, 1-n = Wait order, blank = not owned/waiting, C = Corrupt
Processor Number
    Lock Name
0  1  2  3  4  5  6  7
KE   - Unused Spare
MM   - Unused Spare
MM   - Unused Spare
MM   - Unused Spare
CC   - Vacb
CC   - Master
EX   - NonPagedPool
IO   - Cancel
CC   - Unused Spare
CHAPTER 8 System mechanisms
177
As the name suggests, this type of lock allows noncontended shared acquisition of a spinlock if no 
writer is present. When a writer is interested in the lock, readers must eventually release the lock, and 
no further readers will be allowed while the writer is active (nor additional writers). If a driver developer 
items, this type of lock can remove contention in the majority of cases, removing the need for the com-
plexity of a queued spinlock.
Executive interlocked operations
The kernel supplies some simple synchronization functions constructed on spinlocks for more 
advanced operations, such as adding and removing entries from singly and doubly linked lists. 
Examples include ExInterlockedPopEntryList and ExInterlockedPushEntryList for singly linked lists, 
and ExInterlockedInsertHeadList and ExInterlockedRemoveHeadList for doubly linked lists. A few 
other functions, such as ExInterlockedAddUlong and ExInterlockedAddLargeInteger also exist. All 
these functions require a standard spinlock as a parameter and are used throughout the kernel and 
Instead of relying on the standard APIs to acquire and release the spinlock parameter, these func-
tions place the code required inline and also use a different ordering scheme. Whereas the Ke spinlock 
test-and-set operation to make the acquisition, these routines disable interrupts on the processor and 
immediately attempt an atomic test-and-set. If the initial attempt fails, interrupts are enabled again, 
and the standard busy waiting algorithm continues until the test-and-set operation returns 0—in which 
case the whole function is restarted again. Because of these subtle differences, a spinlock used for the 
executive interlocked functions must not be used with the standard kernel APIs discussed previously. 
Naturally, noninterlocked list operations must not be mixed with interlocked operations.
Note Certain executive interlocked operations silently ignore the spinlock when possible. 
ExInterlockedIncrementLong or ExInterlockedCompareExchange APIs use 
the same lock
These functions were useful on older systems (or non-x86 systems) where the lock operation 
inlined in favor of the intrinsic functions.
Low-IRQL synchronization
Executive software outside the kernel also needs to synchronize access to global data structures in a 
which it accesses as a global data structure, and device drivers need to ensure that they can gain exclu-
sive access to their devices. By calling kernel functions, the executive can create a spinlock, acquire it, 
and release it.
178 
CHAPTER 8 System mechanisms
waiting for a spinlock literally stalls a processor, spinlocks can be used only under the following strictly 
limited circumstances:
I 
The protected resource must be accessed quickly and without complicated interactions with
other code.
I 
exceptions.
-
tive needs to perform other types of synchronization in addition to mutual exclusion, and it must also 
provide synchronization mechanisms to user mode.
There are several additional synchronization mechanisms for use when spinlocks are not suitable:
I 
I 
I 
Pushlocks
I 
Executive resources
I 
Run-once initialization (InitOnce)
Additionally, user-mode code, which also executes at low IRQL, must be able to have its own locking 
I 
System calls that refer to kernel dispatcher objects (mutants, semaphores, events, and timers)
I 
Condition variables (CondVars)
I 
Slim Reader-Writer Locks (SRW Locks)
I 
Address-based waiting
I 
Run-once initialization (InitOnce)
I 
Critical sections
We look at the user-mode primitives and their underlying kernel-mode support later; for now, we 
focus on kernel-mode objects. Table 8-26 compares and contrasts the capabilities of these mechanisms 
and their interaction with kernel-mode APC delivery.
CHAPTER 8 System mechanisms
179
TABLE 8-26 
Exposed for 
Use by Device 
Drivers
Disables 
Normal Kernel-
Mode APCs
Disables Special 
Kernel-Mode 
APCs
Supports 
Recursive 
Acquisition
Supports 
Shared and 
Exclusive 
Acquisition
mutexes 
Yes