验的必要前提。
同时，近些年来，用户上传的数据一直在飞速的增长，分布式系统所覆盖的文数
件也从十亿级跃升到了千亿级，单纯垂直方向的Scale-up的存储架构已经难以满足
用户数据的需要，我们更多的开始需要一个能够水平扩展，不断满足千亿乃至更高级
别需求，能够实现Scale-out模式的存储架构。
作为通用的存储平台，Pangu系统一直在力求对更多的业务进行支持。完成多
业务的的并行发展需要令模块分层更加单元化，以适应不同使用者定制化的需求。
Pangu1.0每次发布一个新版本都必须对每种不同业务需求进行综合考量，不仅时间
上难以协调，且随着团队的规模逐渐扩大，这样一个单元和模块化不够细致的架构也
愈发的不适于一个大团队的开发。亟需一个更加高效的架构，以更好的分层和更好的
模块化来满足大团队快速迭代开发的需要。
还有一点，随着近年来专有云，混合云的快速发展，对存储系统独立输出，轻量
化输出的需求也越来越强烈，Pangu1.0的输出不够轻量级，敏捷性也略显不足，这
个过程也同样是需要加速处理的。
Pangu2.0的总体业务架构
接下来，我们来聊聊Pangu2.0的总体业务架构。它的最底层是物理硬件架构与
Datacenter网络，其上则是Pangu的存储系统，里面包括存储节点，分布式系统，
存储系统内部的上层辐射出支持的多个业务方向，例如Block FS，LogFil，DBFS
以及 HDFS ，整个系统的最上层则是目前主要的业务形式，包括存储服务、数据库
服务、和大数据处理等一众分类。
新智能  9年双11：互联网技术超级工程
解决核心诉求 做到用户满意
存储系统的核心诉求无外乎几点，重中之重的稳定性、性能尽可能高、成本尽
可能低，运维难度同样越低越好。在接下来的文段中，我们将针对这些用户永恒的追
求，来详细的介绍Pangu2.0在这四个部分做到的一些成绩。
稳定性：高可用
首先是在稳定性方面的成果。面向线上众多的块存储集群，我们要在日常工作中
频繁的对其进行扩容、缩容、下线、机器维修、集群整体迁移、软件版本发布和变更
等各式各样的操作。在自始至终的整个过程中，我们实现了全年零故障，完全保障了
业务的稳定性格。
现在正在进行的“ 系统盘云化”工作也是一项良好的佐证，未来，我们的服务器物
理机将不再采购系统盘，而是直接通过协议导出做成云盘，这同样充分体现了我们对稳
定性的掌控，一旦突发问题产生，我们的终极目标就是让用户需要意识不到存在稳定性
波动的可能。实现这点需要内部极为复杂的技术手段和管理手段，以及反复进行的尝试。
我们的另一个成果在于使基础设施完全消除了故障依赖，没个数据三副本都分散
在三个rack上，每个rack都是独立的供电和网络单元，发生供电或交换机故障时不
新智能  9年双11：互联网技术超级工程
前文中，我们讲了用于维持稳定性的一些大体技术手段，而面对系统抗压能力
的测试，我们也同样会采用非常严格的手段。从图中可以看到，平均每台机器都在每
秒上百个UPS的条件下各种自杀进程（包括但不限于cs、bs、同时杀两台bm等）
的failover 测试才敢于交付给用户。这一套测试和管控成熟，无论下面的进程如何
failover，上面的UPS始终处于一条直线上，波动极小。
除了自杀进程，rack掉电的模拟往往会显得更加的极端，每个版本发布前我们
都要进行rack掉电的模拟：直接关掉涵盖48台机器的rack集群，并测试其恢复的
过程，实际结果表明，掉电的机器能安全的将负载转移到其它机器上，待掉电的rack
恢复后再将负载转移回来，全部掉电机器的功能都能在一分钟之内恢复。整体过程对
用户使用上的冲击很小。
还有另外有趣的一点，这比较像一道概率题：通常情况下，在一个集群的规模
内，非常小的时间窗口内（例如一台机器重启的时间内）两台机器failover的概率应
该是可以忽略不计的，但随着样本的容量增加，小概率事件长期积累就会必然发生，
很短的时间窗口内两台机器同时failover 的糟糕境况也会时有出现。如果一个客户
端同时写入A、B、C这3台机器，但A和B都出现了failover，就会只剩下C的
一份形成I/O HANG。解除的唯一方法就是进行数据复制，将C中的数据复制到D，
新智能  9年双11：互联网技术超级工程
联，将部分用户和某个存储节点进行链接，成功使机器错误的影响范围缩小至最低，
如果集群规模较大，影响用户的比例就会变得极低。
技术手段的发挥离不开相关标准的制定，硬件和环境上的标准也是稳定性足以实
现的重要部分。线上集群诸多，由于历史原因的影响，各类硬件，网络，内核，和应
用配置等信息的跨度都很发散，造成了隐形的危险：任何一个变化的影响都很难百分
百的提前进行覆盖和评估。对此，我们着力推行环境标准化，标准服务化， 一切内容
都只有先遵循标准才能进行上线，从而真正把环境标准落到实处。
此外，改进稳定性的手段还有不少，比如，我们会组织两个工程师团队形成攻守
同盟，抛开经验，发挥想象，蓝军的任务是在系统不同单元制造failover，例如磁盘，
网络，内核等，红军进行防御，并在接下来评估对错误系统和用户的影响。通过这一
内部竞争显著提升了系统的稳定性。
针对运维操作的响应性，我们制定了一个“双十”标准作为最后的两道防线：任
何时候收到告警，团队都要在十分钟内响应。且一周收到的告警数不得超出10条。
在技术人员的长期坚持和推行下，这两个标准都取得了成功。
新智能  9年双11：互联网技术超级工程
这么好的性能数据从哪儿来
首先，Pangu2.0拥有自己的单机存储引擎Bypass OS kernel，它是一个基于
SPDK的用户态文件系统，区别于使用VFS、Block Layer 和drivers进行传递的
传统文件系统，Bypass OS kernel直接将文件返回NVME盘，使用Polling方式
进行访问来降低延迟，Data + meta直接一次落盘，整个过程中无需进行任何拷贝。
网络上，Pangu2.0不再使用基于内核的TCP，而是利用RMDA网络 Bypass
掉内核，省略系统调用的过程。同样使用Polling方式进行访问，全过程零拷贝。
另外一件很有趣的事情就是在线程模型上的优化，我们将客户端和服务端进行了
一些配合， 客户端的链接由指定线程处理，形成Run-Complete的线程模型，从I/O
请求到业务完成全部在一个线程内转完，没有任何上下文切换，且时间可控、关键路
径无锁、无数据拷贝。
新智能  9年双11：互联网技术超级工程
第二是写长尾快速收敛——这里采用2-3异步的模式进行。对于一个需要写入