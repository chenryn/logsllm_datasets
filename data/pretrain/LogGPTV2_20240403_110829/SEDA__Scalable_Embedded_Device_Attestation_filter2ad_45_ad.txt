versig(pk ; N(cid:107)β(cid:107)τ(cid:107)c, σ) = 1, pk is the public key in cert(pk ), N
is the nonce previously sent by VRF, c is the reference software
conﬁguration in cert(c), and β = τ = s − 1. We distinguish
among two cases: (1) ADV modiﬁes software conﬁguration of
the initiator device D1 interacting with VRF; (2) ADV modiﬁes
software conﬁguration of any other Dj ∈ S. Note that these two
cases and all combinations of them cover all possibilities of ADV
modifying software conﬁguration of at least one device in S.
We start with the case where ADV modiﬁes software conﬁgura-
tion of D1. Since according to the assumption made in Section 2,
ADV cannot tamper with code performing integrity measurements
on D and code of attest, c(cid:48) is different from c in cert(c) and
σ = sign(sk ; N(cid:107)q(cid:107)β(cid:107)τ(cid:107)c(cid:48)). This means that ADV must forge
σ to make VRF accept. Due to selective forgery resistance of the
signature scheme, ADV can forge σ with probability negligible in
(cid:96)sign.
Next, we consider the case of ADV modifying software of any
other Dj. Let Di be the device that veriﬁes software integrity of
Dj, i.e., its parent in the spanning tree. Again, since ADV can-
not tamper with Dj’s code performing software integrity measure-
ments and code of attdev, c(cid:48)j will be different from cj expected
by Di and h1 = mac(kij; Ni(cid:107)q(cid:107)c(cid:48)j). Hence, ADV must either
forge h1 or compensate for the fact that attestation fails for Dj.
Due to selective forgery resilience of MAC, ADV can forge h1
with probability negligible in (cid:96)mac. To compensate for failed attes-
tation of Dj, ADV could increase βj or decrease τj reported to
Di, or ADV could cause another device Dl send multiple attesta-
tion reports. Furthermore, β and τ are computed and authenticated
with h0 = mac(kij; Ni(cid:107)q(cid:107)βj(cid:107)τj) by code of attdev, which can-
not be tampered with by ADV. Now, ADV could forge h0 or the
report (βl, τl) of a neighbor Dl of Dj, which is used as input to
computation of (βj, τj). However, (βl, τl) are authenticated via
mac(kij; Nj(cid:107)q(cid:107)βl(cid:107)τl). Moreover, due to global session identiﬁer
q included in MAC authenticating the accumulated attestation re-
port, ADV cannot cause any device in S to send its attestation
report twice for the same value of q. Hence, in both cases, ADV
succeeds with probability negligible in (cid:96)mac.
This means that the probability of ADV making VRF accept
in the case where ADV modiﬁed software conﬁguration of at least
one device in S is negligible in (cid:96)sign and (cid:96)mac.
8. PROTOCOL EXTENSIONS
In this section we discuss several variants and extensions of
SEDA which go beyond the scope of the adversary model described
in Section 2.2.
Identifying compromised devices. In some applications it may be
necessary to identify compromised devices. SEDA can be easily ex-
tended to report the identiﬁers of devices whose software integrity
could not be veriﬁed. Speciﬁcally, whenever a device Di detects
that one of its neighbors Dj reported a software conﬁguration c(cid:48)j
that is different from expected software conﬁguration cj, Di ap-
pends the identiﬁer of Dj to its report. Eventually, VRF receives
a complete list of identiﬁers of all devices that could not be attested
successfully. However, this approach increases message complex-
ity and is best suited for small swarms or applications where the
number of compromised devices is expected to be low.
Devices with different priorities. In some applications some de-
vices may be more important than others. For instance, in a wireless
sensor network (WSN), software integrity of a cluster head may
be much more important than software integrity of a sensor node.
SEDA can support such scenarios by weighting attestation results.
Speciﬁcally, when attesting a high-priority device, counters β and
τ are not incremented by one but by a weighted factor.
Random sampling. Performance of SEDA in a very large swarm S
can be improved by attesting only a randomly sampled statistically
representative subset S(cid:48) ⊂ S. In this case, the veriﬁer VRF gets
assurance that with probability p all devices in S are authentic and
running certiﬁed software. Speciﬁcally, VRF sends the desired
sample set size z together with nonce N in attest. All devices in
S broadcast z along with a global session identiﬁer q in attdev to
their neighboring devices. A global deterministic function which
takes the device identity as a parameter (along with other parame-
ters like q, z, s) is used to determine if a device Dj ∈ S \ {D} is
to be part of S(cid:48). This way the parent of each Dj knows if Dj needs
to be attested and can detect if Dj does not provide an attestation
report. Finally, only attestation results of devices in S(cid:48) are accu-
mulated and reported to VRF. As a result, VRF is assured that –
with a certain conﬁdence level and conﬁdence interval – attestation
result of S(cid:48) is also valid for S. For example, in swarms with more
than 105 devices only about 9 % of devices need to be attested to
achieve a conﬁdence level of 95 % and a conﬁdence interval of 1 %.
Software updates. SEDA allows updating device software ver-
ifying whether the update has been performed correctly. More
concretely, new software comes with a code certiﬁcate cert(cnew).
After new software has been installed on device Di,
it sends
cert(cnew) authenticated with keys in Ki to all its neighbors, which
then update their reference software conﬁguration for Di to cnew, if
veriﬁcation of cert(cnew) was successful. Otherwise, they keep the
old software conﬁguration. To prove that software update has been
performed successfully, Di can either attest itself to all its neigh-
bors using keys in Ki (similar as in attdev), or to an external veri-
ﬁer using its secret key sk i (similar as in attest). Roll-back attacks,
where an adversary ADV installs old software versions (that may
contain exploitable security vulnerabilities) are detected by VRF
when attesting the swarm.
Highly dynamic swarms. SEDA can be extended to support
highly dynamic swarms that change their topology even while the
attestation protocol is executing.
In this case SEDA generates a
virtual spanning tree, i.e., nodes which are neighbors in the span-
ning tree may not be neighbors in the topology after it has changed.
An appropriate routing mechanism is used to ensure that messages
of child nodes are delivered to parent nodes. However, this basic
approach increases communication overhead of SEDA since mes-
sages must be sent over multiple hops.
Denial of Service (DoS) Attack Mitigation. In general, DoS at-
tacks are hard to mitigate. SEDA is designed to use mostly sym-
metric cryptography, thus making it less appealing for DoS attacks.
However, ADV can still target portions of SEDA that use asym-
metric cryptography, i.e., join and attest. For example, a compro-
mised D can send fake join requests with incorrect certiﬁcates to
its neighbors. This would cause each neighbor to waste resources,
since verifying public key certiﬁcates is computationally expensive.
Mitigating such attacks can be done by: (1) limiting join request fre-
quency, or (2) processing join requests with lower priority. Indeed,
some current embedded security architectures with support for real-
time execution, such as TyTAN [5], can handle certain events (e.g.,
join requests) with low priority. This allows system resources to be
preferentially allocated to more critical tasks, while assuring that
only otherwise idle CPU cycles are dedicated to processing (poten-
tially malicious) join requests.
9. PHYSICAL ATTACKS
In some swarm settings it is reasonable to assume that physical
attacks are either impossible or unlikely, e.g., automotive, avionics,
shipboard, or satellite. In these examples, the swarm is either phys-
ically unreachable and/or has a secure perimeter. However, in other
scenarios, it might be infeasible to assure physical security of all
devices, e.g., drones (or robots) used for military, surveillance, law
enforcement and prospecting purposes, or devices used in factory
or building automation. Since in SEDA aggregation of individual
device attestation results is done within the swarm, if ADV learns
all keys of just one device, it can forge the attestation result for that
device as well as any of its descendants in the spanning tree. Fur-
thermore, an adversary ADV can create clones of the compromised
device and spread them across the swarm. Consequently, we need
to expand our adversary model to include the possibility of a de-
vice being captured and physically attacked to extract keys and/or
modify software. We now sketch out several mitigation techniques.
PUF-based attestation. Physical unclonable functions (PUFs) are
(believed to be) tamper-resistant primitives that can be integrated
into attestation protocols to mitigate physical attacks. PUFs are
based on the variations inherently present in various hardware com-
ponents of a computing device, such as memory. PUFs can be used
for device identiﬁcation and authentication, or as a seed for random
number generation. Uniqueness of components upon which PUFs
are constructed comes from variations in the manufacturing pro-
cesses which are assumed not to be controllable by the adversary,
and thus are not clonable. Therefore, an on-board PUF can thwart
a physical attack that aims to clone a compromised device. Also,
since components used for PUFs, such as on-chip static random-
access memory (SRAM), are anyhow part of the device (regardless
of their use as PUFs) additional costs of PUFs are minimal. Several
approaches to PUF-based attestation have been proposed [26, 49].
However, all PUF-based attestation schemes impose additional re-
quirements on the device. Furthermore, recent work on PUF secu-
rity demonstrated that conjectured security of certain PUF families,
such as Arbiter PUFs, does not hold in practice [33], speciﬁcally,
their unpredictability and unclonability properties.
Double veriﬁcation. The basic idea for double veriﬁcation is
to make attestation and aggregation secure against one physically
compromised device, i.e., whose keys are known to ADV. This can
be achieved by mandating that integrity veriﬁcation of each device
Di be done by both its parent and its grandparent in the spanning
tree. This idea was also used in [22] in order to make hop-by-hop
aggregation secure against the compromise of one node.
In par-
ticular, upon joining the swarm, each Di shares a symmetric key
ki with every one-hop and two-hop neighbor. At attestation time,
(βi, τi, c) are authenticated using keys shared with both the parent
and the grandparent. Thus, one fully-compromised device would
be unable to forge the attestation response of its neighbors. This
extension is secure as long as no two neighboring devices are phys-
ically compromised. However, it involves extra computation and
communication costs.
Absence detection. As in prior literature on WSN security, we as-
sume that, in order to physically attack a device, ADV has to take
it out of the ﬁeld for a certain amount of time [11], e.g., to dis-
assemble its components in order to extract its secrets. Therefore,
absence detection of at least one device can be a sign of a physical
attack. Recall that we earlier assumed that the swarm is always con-
nected. In a static swarm, a device can detect whenever a neighbor
is missing by running a periodic heartbeat check with each neigh-
bor, using a current shared key. If a neighbor disappears, the device
can ﬂood the swarm with the announcement reﬂecting the missing
device. However, the same is hard to achieve in a dynamic swarm
where topology can change unpredictably. We consider two alter-
natives overviewed below. They assume: (1) global knowledge of
some x < X, where X denotes the minimum time ADV needs to
take a victim device out of circulation, for physical attack purposes,
and (2) loosely synchronized clocks among all swarm devices.
Option 1: The easiest option is for a swarm S to periodically
self-check by running SEDA without an explicit veriﬁer request.
This requires almost no extra functionality, except one: we use the
SEDA extension to identify compromised devices, as described in
section 8. However, instead of identifying compromised devices,
we identify all present, uncompromised ones. Suppose that, after
every x-long interval, all devices deterministically select the device
that will serve as the root of the spanning tree – D1, e.g., by taking
the hash of current time modulo s, where s is the total number of
devices. Then, D1 acts as prescribed by SEDA, with the aforemen-
tioned extension. Once it receives all reports from all direct neigh-
bors, D1 identiﬁes nodes from a master list that are missing from
the current list and informs the rest of the swarm of their identities.
An optimization of the ﬁrst approach is to create a special-
purpose version of SEDA that works in much the same way as
described above, except that, instead of full-blown attestation, the
self-checking protocol simply veriﬁes the presence (but not soft-
ware integrity) of each device. In other words, communication re-
mains the same, while computation for each Di becomes negligible;
Di simply replies to its parent with just a list of identities of present
(i.e., alive and responsive) devices in its subtree.
Option 2: Another mitigation technique is via periodic fully dis-
tributed swarm self-checking via link state-like veriﬁcation.
In
brief, after each interval of duration x, every Di broadcasts – over
existing pairwise secure channels – an update to its neighbors. An
update includes at least the device identiﬁer and current time-stamp.
For each update received from Dj, Di re-broadcasts it to its other
neighbors. It is easy to see that this approach generates a lot of ex-
tra trafﬁc since every device’s update message is ﬂooded through-
out the swarm; each device forwards and receives O(s) messages
per protocol instance. At the end of each self-checking, Di collects
a list of all current devices and compares it against its master list.
Any device on the latter that is absent from the former is assumed
to be untrusted from here on, i.e., it is potentially physically com-
promised.
Implications. Both physical attack countermeasures outlined
above have certain consequences for SEDA. Notably, due to dis-
tributed maintenance of a master list, seamless introduction of new
devices into an already deployed swarm is no longer possible. How-
ever, this can be easily remedied by requiring a new device to “an-
nounce” its presence via a public key signature-based authenticated
message that includes appropriate certiﬁcates. Upon receipt of such
a join announcement, each current device can independently au-
thenticate it and add the new device to its master list. Among the
solutions explained above, Absence Detection is most suited to our
protocol. We will include a thorough security and performance
analysis of this technique in the technical report [4].
10. RELATED WORK
Attestation. Numerous remote attestation techniques have been
proposed. Common to all of them is that the prover sends a status
report of its current software conﬁguration to another platform to
demonstrate that it is in a known and thus trustworthy state. Au-
thenticity of this report is typically assured by secure hardware [16,
26, 27, 42, 46, 51] and/or trusted software [2, 24, 27, 29, 47, 48, 52].
Attestation based on secure hardware is often too complex and/or
expensive for low-end embedded systems. Software-based attesta-
tion [24, 29, 47, 48] does not require secure hardware and does not
use cryptographic secrets. However, security properties of software-
based attestation typically rely on strong assumptions, such as the
adversary being passive while the attestation protocol is executed
and optimality of the attestation algorithm and its implementation,
that are hard to achieve in practice [3]. Hence, a secure and practi-
cal attestation scheme requires at least some basic security features
in hardware [16, 17, 25]. SEDA follows this philosophy and uses
only minimal security functionalities in hardware such as read only
memory (ROM) or lightweight memory access control extensions.