title:The Good, the Bad, and the Differences: Better Network Diagnostics
with Differential Provenance
author:Ang Chen and
Yang Wu and
Andreas Haeberlen and
Wenchao Zhou and
Boon Thau Loo
The Good, the Bad, and the Differences:
Better Network Diagnostics with
Differential Provenance
Ang Chen
Yang Wu
University of Pennsylvania
University of Pennsylvania
Andreas Haeberlen
Wenchao Zhou
Boon Thau Loo
University of Pennsylvania
Georgetown University
University of Pennsylvania
ABSTRACT
In this paper, we propose a new approach to diagnosing prob-
lems in distributed systems. Our approach is based on the in-
sight that many of the trickiest problems are anomalies. For
instance, in a network, problems often affect only a small
fraction of the trafﬁc (perhaps a certain subnet), or they only
manifest infrequently. Thus, it is quite common for the op-
erator to have “examples” of both working and non-working
trafﬁc readily available – perhaps a packet that was mis-
routed, and a similar packet that was routed correctly.
In
this case, the cause of the problem is likely to be wherever
the two packets were treated differently by the network.
We present the design of a debugger that can leverage this
information using a novel concept that we call differential
provenance. Differential provenance tracks the causal con-
nections between network states and state changes, just like
classical provenance, but it can additionally perform root-
cause analysis by reasoning about the differences between
two provenance trees. We have built a diagnostic tool that
is based on differential provenance, and we have used our
tool to debug a number of complex, realistic problems in
two scenarios: software-deﬁned networks and MapReduce
jobs. Our results show that differential provenance can de-
liver very concise diagnostic information; in many cases, it
can even identify the precise root cause of the problem.
CCS Concepts
•Networks → Network management; Network experimen-
tation; •Information systems → Data provenance;
Keywords
Network diagnostics, debugging, provenance
Permission to make digital or hard copies of all or part of this work for personal
or classroom use is granted without fee provided that copies are not made or
distributed for proﬁt or commercial advantage and that copies bear this notice
and the full citation on the ﬁrst page. Copyrights for components of this work
owned by others than the author(s) must be honored. Abstracting with credit is
permitted. To copy otherwise, or republish, to post on servers or to redistribute to
lists, requires prior speciﬁc permission and/or a fee. Request permissions from
permissions@acm.org.
SIGCOMM ’16, August 22 - 26, 2016, Florianópolis, Brazil
c(cid:13) 2016 Copyright held by the owner/author(s). Publication rights licensed to
ACM. ISBN 978-1-4503-4193-6/16/08. . . $15.00
DOI: http://dx.doi.org/10.1145/2934872.2934910
INTRODUCTION
1.
Distributed systems are not easy to get right. Despite the fact
that researchers have developed a wide range of diagnostic
tools [16, 30, 31, 19, 27, 29, 10], understanding the intricate
relations between low-level events, which is needed for root-
cause analysis, is still challenging.
Recent work on data provenance [36] has provided a new
approach to understanding the details of distributed execu-
tions.
Intuitively, a provenance system keeps track of the
causal connections between the states and events that a sys-
tem generates at runtime; for instance, when applied to a
software-deﬁned network (SDN), it might associate each ﬂow
entry with the parts of the controller program that were used
to compute it. Then, when the operator asks a diagnostic
question – say, why a certain packet was routed to a par-
ticular host – the system returns a comprehensive explana-
tion that recursively explains each relevant event in terms of
its direct causes. A number of provenance-based diagnostic
tools have been developed recently, including systems like
ExSPAN [36], SNP [34], and Y! [30].
However, while such a comprehensive explanation is use-
ful for diagnosing a problem, it is not the same as ﬁnding the
actual root causes. We illustrate the difference with an ana-
logy from everyday life: suppose Bob wants to know why
his bus arrived at 5:05pm, which is ﬁve minutes late.
If
Bob had a provenance-based debugger, he could submit the
query “Why did my bus arrive at 5:05pm?”, and he would
get a comprehensive explanation, such as “The bus was dis-
patched at the terminal at 4:00pm, and arrived at stop A at
4:13pm; it departed from there at 4:15pm, and arrived at stop
B at 4:21pm; ... Finally, it departed from stop Z at 5:01pm,
and arrived at Bob’s platform at 5:05pm”. This is very dif-
ferent from what Bob really wanted to know: the actual root
cause might be something like “At stop G, the bus had to
wait for ﬁve minutes because of a trafﬁc jam”.
But suppose we allow Bob to instead ask about the dif-
ferences between two events – perhaps “Why did my bus
arrive at 5:05pm today, and not at 5:00pm like yesterday?”.
The debugger can then omit those parts of the explanation
that the two events have in common, and instead focus on
the (hopefully few) parts that caused the different outcomes.
We argue that a similar approach should work for diagnos-
ing distributed systems: reasoning about the differences be-
tween the provenance of a bad event and a good one should
lead to far more concise explanations than the provenance
of the bad event by itself. We call this approach differential
provenance.
Differential provenance requires some kind of “reference
event” that produced the correct behavior but is otherwise
similar to the event that is being investigated. There are sev-
eral situations where such reference events are commonly
available, such as 1) partial failures, where the problem ap-
pears in some instances of a service but not in others (Exam-
ple: DNS servers A and B are returning stale records, but
not C); 2) intermittent failures, where a service is available
only some of the time (Example: a BGP route ﬂaps due to a
“disagree gadget” [12]); and 3) sudden failures, where a net-
work component suddenly stops working (Example: a link
goes down immediately after a network transition). As long
as the faulty service has worked correctly at some point, that
point can potentially serve as the needed reference.
At ﬁrst glance, it may seem that that differential prove-
nance merely requires ﬁnding the differences between two
provenance trees, perhaps with a tree-based edit distance al-
gorithm [5]. However, this naïve approach would not work
well because small changes in the network can cause the
provenance to look wildly different. To see why, suppose
that the operator of an SDN expects two packets P and P ′ to
be forwarded along the same path S1-S2-S3-S4-S5, but that
a broken ﬂow entry on S2 causes P ′ to be forwarded along
S1-S2-S6 instead. Although the root cause (the broken ﬂow
entry) is very simple, the provenance of P and P ′ would
look very different because the two packets traveled on very
different paths. (We elaborate on this scenario in Section 2.)
A good debugger should be able to pinpoint just the broken
ﬂow entry and leave out the irrelevant consequences.
In this paper, we present a concrete algorithm called Diff-
Prov for generating differential provenance, as well as a pro-
totype debugger that leverages such information for root-
cause analysis. We report results from two diagnostic sce-
narios: software-deﬁned networks and Hadoop MapReduce.
Our results show that differential provenance can explain
network events in far simpler terms than existing systems:
while the latter often return elaborate explanations that con-
tain hundreds of events, DiffProv can usually pinpoint one
critical event which, in our experience, represents the “root
cause” that a human operator would be looking for. We also
show that the cost for the higher precision is small: the run-
time overheads are low enough to be practical, and diagnos-
tic queries can usually be answered in less than one minute.
We make the following contributions:
• The concept of differential provenance (Section 3);
• DiffProv, a concrete algorithm for generating differen-
tial provenance (Section 4);
• a DiffProv debugger prototype (Section 5); and
• an experimental evaluation in the context of SDNs and
Hadoop MapReduce (Section 6).
We discuss related work in Section 7, and conclude the paper
in Section 8.
Overly	specific	 rule
S1
S2
S3
S4
S5
Internet
P
S6
P’
Web server	 #1 DPI	device
Figure 1: Example scenario (SDN debugging).
Web server	 #2
2. OVERVIEW
Figure 1 shows a simple example of the problem we are ad-
dressing. The illustrated network consists of six switches,
two HTTP servers, and one DPI device. The operator wants
web server #2 to handle most of the HTTP requests; how-
ever, requests from certain untrusted subnets should be pro-
cessed by web server #1, because it is co-located with the
DPI device that can detect malicious ﬂows based on the mir-
rored trafﬁc from S6. To achieve this, the operator conﬁg-
ures two OpenFlow rules on switch S2: a) a speciﬁc rule
R1 that matches trafﬁc from the untrusted subnets and for-
wards it to S6; and b) a general rule R2 that matches the
rest of the trafﬁc and forwards it to S3. However, the op-
erator made R1 overly speciﬁc by mistake, writing the un-
trusted subnet 4.3.2.0/23 as 4.3.2.0/24. As a result,
only some of the requests from this subnet arrive at server #1
(e.g., those from 4.3.2.1), whereas others arrive at server
#2 instead (e.g., those from 4.3.3.1). The operator would
like to use a network debugger to investigate why requests
from 4.3.3.1 went to the wrong server. One example of
a suitable reference event would be a request that arrived at
the correct server – e.g., one from 4.3.2.1.
2.1 Background: Provenance
Network provenance [36] is a way to describe the causal
relationships between network events. At a high level, the
provenance of an event e is simply a tree of events that has
e at its root, and in which the children of each vertex repre-
sent the direct causes of that vertex. Figure 2(a) sketches the
provenance of the packet P from Figure 1 when it arrives
at web server #1. The direct cause of P ’s arrival is that P
was sent from a port on switch S6 (vertex V1); this, in turn,
was caused by 1) P ’s earlier arrival at S6 via some other port
(V2), in combination with 2) the fact that P matched some
particular ﬂow entry in S6’s ﬂow table (V3), and so on.
To answer provenance queries, systems use the abstrac-
tion of a provenance graph, which is a DAG that has a vertex
for each event and an edge between each cause and its direct
effects. To ﬁnd the provenance of a speciﬁc event e, we can
simply locate e’s vertex in the graph and then project out the
tree that is rooted at that vertex. The leaves of the tree con-
sist of “base events” that cannot be further explained, such
as external inputs or conﬁguration states.
Provenance itself is not a new concept; it has been ex-
plored by the database and networking communities, and
there are techniques that can track it efﬁciently by maintain-
ing some additional metadata [6, 11, 30].
V0#
EXISTENCE(Server #1, 
packet(@Server #1, Sip=4.3.2.1), t1) 
V1#
The packet arrived at web 
server #1 because it was 
forward by the last-hop 
switch.!
EXISTENCE(S6, 
packetForward(@S6, Sip=4.3.2.1), t2) 
The packet arrived at  
the last-hop switch . 
AND 
V3#
When the packet arrived, it 
matched a high priority flow 
entry that forwards untrusted 
packets to web server #1.!
V2#
EXISTENCE(S6, 
packet(@S6, Sip=4.3.2.1), t3) 
.
.
.
#
EXISTENCE(S6, 
flowEntry(@S6, Pri=High, 
Sip=4.3.2.0/24, Act=Output:1), t4) 
…
root
faulty rule
root
(a) Provenance example
(b) Full provenance of P′ at server #2
(c) Full provenance of P at server #1
Figure 2: Simpliﬁed excerpt from a provenance tree (a) and the full provenance trees for P ′ (b) and P (c) from Figure 1. Each
circle in (b) and (c) corresponds to a box in (a), but the details have been omitted for clarity. Although the two full trees have
some common subtrees (green), most of their vertexes are different (red). Also shown is the single vertex in (b) that represents
the root cause of the routing error that affected P ′.
2.2 Why provenance is not enough
Provenance can be helpful for diagnosing a problem, but
ﬁnding the actual root cause can require substantial addi-
tional work. To illustrate this, we queried the provenance of
the packet P ′ in our scenario after it has been (incorrectly)
routed to web server #2. The full provenance tree, shown in
Figure 2(b), consists of no less than 201 vertexes, which is
why we have omitted all the details from the ﬁgure. Since
this is a complete explanation of the arrival of P ′, the oper-
ator can be conﬁdent that the information in the tree is “suf-
ﬁcient” for diagnosis. However, the actual root cause (the
faulty rule; indicated with an arrow) is buried deep within the
tree and is quite far from the root, which corresponds to the
packet P ′ itself. This is by no means unusual: in other sce-
narios that were discussed in the literature, the provenance
often contains tens or even hundreds of vertexes [30]. Hence,
extracting a concise root cause from a complex causal expla-