a result, we see the average classiﬁcation time grow sig-
niﬁcantly, albeit linearly, from about 1.6 ms for 30 fea-
tures to over 7 ms for about 1,300 features. While these
numbers are from our unoptimized implementation, we
believe that ZOZZLE’s static detector has a lot of potential
for fast on-the-ﬂy malware identiﬁcation.
2The ZOZZLE false negative rate listed in Figure 14 is taken on
our cross-validation experiment in Figure 12.
Figure 15: Classiﬁcation time as a function of JavaScript ﬁle size. File size in bytes is shown on the x axis and the classiﬁcation time in ms is
shown on the y axis.
tion. This adaptation takes two forms:
improving its
ability to reason about the malware, and adapting the
feature set used to detect malware as it evolves. To im-
prove ZOZZLE’s detection capability, it needs to incorpo-
rate more semantic information about the JavaScript it
analyzes. For example, as described in Section 3, feature
ﬂow could help ZOZZLE identify attempts to obfuscate
the use of APIs necessary for malware to be success-
ful. Adapting ZOZZLE’s feature set requires continuous
retraining based on collecting malware samples detected
by deploying other detectors such as NOZZLE. With such
adaptation, ZOZZLE would dramatically reduce the effec-
tiveness of the copy-and-pasted attacks that make up the
majority of JavaScript malware today.
In combination
with complementary detection techniques, such as NOZ-
ZLE, an updated feature set can be generated frequently
with no human intervention.
Just as with anti-virus, we believe that ZOZZLE is one
of several measures that can be used as part of a defense-
in-depth strategy. Moreover, our experience suggests that
in many cases attackers are slow to adapt to the changing
landscape. Despite the wide availability of obfuscation
tools, in our NOZZLE detection experiments we still ﬁnd
many sites not using any form of obfuscation at all. We
also see little diversity in the exploits collected. For ex-
ample, the top ﬁve malicious scripts account for 75% of
the malware detected.
Deployment: The most attractive deployment strategy
for ZOZZLE is in-browser deployment. ZOZZLE has been
designed to require only occasional ofﬂine re-training so
that classiﬁer updates can be shipped off to the browser
every several days or weeks. Figure 17 shows a proposed
workﬂow for ZOZZLE in-browser deployment.
The code of the in-browser detector does not need to
change, only the list of features and weights needs to
be sent, similarly to updating signatures in an anti-virus
product. Note that our detector is designed in a way that
can be tightly integrated into the JavaScript parser, mak-
Figure 16: Classiﬁer throughput and accuracy as a function of the
number of features, using 1-level classiﬁcation with .25 of the train-
ing set size.
6 Discussion
Caveats and limitations: All classiﬁer-based malware
detection tools will fail to detect some attacks, such as
exploits that do not contain any of the features present
in the training examples. More importantly, attackers
who have a copy of ZOZZLE as an oracle can devise vari-
ants of malware that are not detected by it. For example,
they might rename variables, obscure strings by encod-
ing them or breaking them into pieces, or substitute dif-
ferent APIs that accomplish the same task.
Evasion is made somewhat more difﬁcult because any
exploit that uses a known CVE must eventually make
the necessary JavaScript runtime calls (e.g., detecting
or loading a plugin) to trigger the exploit.
If ZOZZLE
is able to statically detect such calls, it will detect the
attempted exploit. To avoid such detection, an attacker
might change the context in which these calls appear by
creating local variables that reference the desired run-
time function, an approach already employed by some
exploits we have collected.
In the future, for ZOZZLE to continue to be effective,
it has to be adaptive against attempts to avoid detec-
0246810121416182002,0004,0006,0008,00010,00012,00014,00016,00018,00020,000Classification Time (ms) 97.5%98.0%98.5%99.0%99.5%100.0%0.00.20.40.60.81.01.21.41.61.803006009001,2001,500Classifier Accuracy Throughput (MB/s) Features ThroughputAccuracyProject
ZOZZLE
JSAND
Prophiler
CUJO
Citation
[6]
[4]
[22]
FP rate
3.1E-6
1.3E-5
9.8E-2
2.0E-5
FN rate
9.2E-2
2E-3
7.7E-3
5.6E-2
Static Dynamic
-3
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
Figure 18: Quantitative comparison to closely related work.
code. In its purely static mode, Cujo is also potentially
quite fast, with running times ranging from .01 to 10 ms
per URL, however, our rates are not directly comparable
because URLs and code contexts are not one-to-one.
Canali et al. [4] present Prophiler, a lightweight static
ﬁlter for malware. It combines HTML-, JavaScript-, and
URL-based features into one classiﬁer that quickly ﬁl-
ters non-malicious pages so that malicious pages can be
examined more extensively. While their approach has
elements in common with ZOZZLE, there are also dif-
ferences. First, ZOZZLE focuses on classifying pages
based on unobfuscated JavaScript code by hooking into
the JavaScript engine entry point, whereas Prophiler ex-
tracts its features from the obfuscated code. Second,
ZOZZLE automatically extracts hierarchical features from
the AST, whereas Prophiler relies on a variety of sta-
tistical and lexical hand-picked features present in the
HTML and JavaScript. Third, the emphasis of ZOZZLE
is on very low false positive rates, whereas Prophiler, be-
cause it is intended as a fast ﬁlter, allows higher false
positive rates in order to reduce the false negative rate.
Rieck et al. [22] describe Cujo, an system that com-
bines static and dynamic features in a classiﬁer frame-
work based on support vector machines. They pre-
process the source code into tokens and pass groups of
tokens (Q-grams) to automatically extract Q-grams that
are predictive of malicious intent. Unlike ZOZZLE, Cujo
is proxy-based and uses JavaScript emulation instead of
hooking into the JavaScript runtime in a browser. This
emulation adds runtime overhead, but allows Cujo to use
static as well as dynamic Q-grams in their classiﬁcation.
ZOZZLE differs from Cujo in that it uses the existing Java-
Script runtime engine to unfold JavaScript contexts with-
out requiring emulation reducing the overhead.
Similarly, Cova et al. present a system JSAND that
conducts classiﬁcation based on static and dynamic fea-
tures [6].
In JSAND, potentially malicious JavaScript is
emulated to determine runtime characteristics around de-
obfuscation, environment preparation, and exploitation,
such as the number of bytes allocated through string op-
erations. These features are trained and evaluated with
known good and bad URLs. Like Cujo, JSAND uses em-
ulation to combine a collection of static and dynamic
features in their classiﬁcation, as compared to ZOZZLE,
3The only part of ZOZZLE that requires dynamic intervention is
unfolding.
Figure 17: In-browser ZOZZLE deployment: workﬂow.
ing malware “scoring” part of the overall parsing pro-
cess; the only thing that needs to be maintained as the
parse tree (AST) is being constructed is the set of match-
ing features. This, we believe, will make the incremental
overhead of ZOZZLE processing even lower than it is now.
Another way to deploy ZOZZLE is as a ﬁlter for a more
heavy-weight technique such as NOZZLE or some form
of control- or dataﬂow integrity [1, 5]. As such, the ex-
pected end-user overhead will be very low, because both
the detection rate of ZOZZLE and the rate of false posi-
tives is very low; we assume if an attack is prevented, the
user will not object to additional overhead in that case.
Finally, ZOZZLE is suitable for ofﬂine scanning, ei-
ther in the case of dynamic web crawling using a web
browser, or in the context or purely static scanning that
exposes some part of the JavaScript code to the scanner.
7 Related Work
Several recent papers focusing on static detection tech-
niques for malware, speciﬁcally implemented in Java-
Script. None of the existing techniques propose integrat-
ing malware classiﬁcation with JavaScript execution in
the context of a browser, as ZOZZLE does.
7.1 Closely-related Malware Detection Work
A quantitative comparison with closely related tech-
niques is presented in Figure 18. It shows that ZOZZLE is
heavily optimized for an extremely low rate of false pos-
itives — about one in quarter million — with the closest
second being CUJO [22] with six times as many false
positives.
ZOZZLE is generally faster than other tools, since the
only runtime activity it performs is capturing JavaScript
URL in blacklistScan scripts with ZozzlenoBenign;proceedbenignMalicious; warn useryesmaliciousApply other scannersmaliciousbenignVisit URLwhich extracts only static features automatically. Also,
because ZOZZLE leverages the existing JavaScript en-
gine unfolding process, JSAND performance is signiﬁ-
cantly slower than ZOZZLE.
7.2 Other Projects
Karanth et al.
identify malicious JavaScript using a
classiﬁer based on hand-picked features present in the
code [14]. Like us, they use known malicious and be-
nign JavaScript ﬁles and train a classiﬁer based on fea-
tures present. They show that their technique can detect
malicious JavaScript with high accuracy and they were
able to detect a previously unknown zero-day vulnerabil-
ity. Unlike our work, they do not integrate their classiﬁer
into the JavaScript engine, and so do not see the unfolded
JavaScript as we do.
High-interaction client honeypots have been at the
forefront of research on drive-by-download attacks.
Since they were ﬁrst introduced in 2005, various stud-
ies have been published [15, 20, 25, 30–32]. High-
interaction client honeypots drive a vulnerable browser
to interact with potentially malicious web page and mon-
itor the system for unauthorized state changes, such as
new processes being created. The detection of drive-by-
download attacks can also occur through the analysis of
the content retrieved from the web server. When cap-
tured at the network layer or through a static crawler,
the content of malicious web pages is usually highly
obfuscated opening the door to static feature based
exploit detection [10, 20, 24, 27, 28]. While these ap-
proaches, among others, consider static JavaScript fea-
tures, ZOZZLE is the ﬁrst to utilize hierarchical features
extracted from ASTs.
Besides static features focusing on HTML and Java-
Script, shellcode injection exploits also offer points for
detection. Existing techniques such as Snort [23] use
pattern matching to identify attacks in a database. Poly-
morphic attacks that vary shellcode on each exploit at-
tempt can avoid pattern-based detection unless improb-
able properties of shellcode are used to detect such at-
tacks, as in Polygraph [17]. Like ZOZZLE, Polygraph uti-
lizes a na¨ıve bayes classiﬁer, but only applies it to the
detection of shellcode.
Abstract Payload Execution (APE) by Toth and
Kruegel [29], STRIDE by Akritidis et al. [2, 18], and
NOZZLE by Ratanaworabhan, Livshits and Zorn [21] all
focus on analysis of the shellcode and NOP sled used by
a heap spraying attack. Such techniques can detect heap
sprays with low false positive rates, but incur higher run-
time overhead than is acceptable for always-on deploy-
ment in a browser (10-15% is farily common).
Dynamic features have been the focus of several
groups. Nazario, Buescher, and Song propose systems
that detect attacks on scriptable ActiveX components [3,
16, 26]. They capture JavaScript interactions and use
vulnerability speciﬁc signatures to detect attacks. This
method is effective in detecting attacks due to the rela-
tive homogeneous characteristic of the attack landscape.
However, while they are effective in detecting known ex-
isting attacks on ActiveX components, they fail to iden-
tify attacks that do not involve ActiveX components,
which ZOZZLE is able to detect.
8 Conclusions
This paper presents ZOZZLE, a highly precise, mostly
static detector for malware written in JavaScript. ZOZZLE
is a versatile technology that is suitable for deployment
in a commercial browser, staged with a more costly run-
time detector like NOZZLE. Designing an effective in-
browser malware detector requires overcoming techni-
cal challenges that include achieving high performance,
generating precise results, and overcoming attempts at
obfuscating attacks. Much of the novelty of ZOZZLE
comes from its hooking into the the JavaScript engine
of a browser to get the ﬁnal, expanded version of Java-
Script code to address the issue of deobfuscation. Com-
pared to other classiﬁer-based tools, ZOZZLE uses contex-
tual information available in the program abstract syntax
tree (AST) to perform fast, scalable, yet precise malware
detection.
This paper contains an extensive evaluation of our
techniques. We evaluated ZOZZLE in terms of perfor-
mance and malware detection rates (both false posi-
tives and false negatives) using over 1.2 million pre-
categorized code samples. ZOZZLE has an extremely low
false positive rate of 0.0003%, which is less than one in
a quarter million. Despite this high accuracy, the ZOZZLE
classiﬁer is fast, with a throughput at over one megabyte
of JavaScript code per second.
Acknowledgments
This work would not have been possible without the help
of many people, including Sarmad Fayyaz, David Fel-
stead, Michael Gamon, Darren Gehring, Rick Gutierrez,
Engin Kirda, Jay Stokes, and Ramarathnam Venkatesan.
We especially thank Rick Bhardwaj for working closely
with malware samples to help us understand their prop-
erties in the wild.
References
[1] M. Abadi, M. Budiu,
´Ulfar Erlingsson, and J. Ligatti.
Control-ﬂow integrity. In Proceedings of the Conference
on Computer and Communications Security, 2005.
[2] P. Akritidis, E. P. Markatos, M. Polychronakis, and K. G.
Anagnostakis.
STRIDE: Polymorphic sled detection
through instruction sequence analysis. In Proceedings of
Security and Privacy in the Age of Ubiquitous Comput-
ing, 2005.
[3] A. Buescher, M. Meier, and R. Benzmueller. Monkey-
Wrench - boesartige webseiten in die zange genommen.
In Deutscher IT-Sicherheitskongress, Bonn, 2009.
[4] D. Canali, M. Cova, G. Vigna, and C. Kr¨ugel. Prophiler:
A fast ﬁlter for the large-scale detection of malicious web
In Proceedings of the International World Wide
pages.
Web Conference, Mar. 2011.
[5] M. Castro, M. Costa, and T. Harris. Securing software
In Proceedings of the
by enforcing data-ﬂow integrity.
Symposium on Operating Systems Design and Implemen-
tation, 2006.
[6] M. Cova, C. Kr¨ugel, and G. Vigna. Detection and analy-
sis of drive-by-download attacks and malicious JavaScript
code. In Proceedings of the International World Wide Web
Conference, April 2010.
[7] C. Cowan, C. Pu, D. Maier, H. Hinton, J. Walpole,
P. Bakke, S. Beattie, A. Grier, P. Wagle, and Q. Zhang.
Stackguard: Automatic adaptive detection and prevention
of buffer-overﬂow attacks. In Proceedings of the USENIX
Security Symposium, January 1998.
[8] Y. Ding, T. Wei, T. Wang, Z. Liang, and W. Zou. Heap
Taichi: exploiting memory allocation granularity in heap-
spraying attacks. In Proceedings of Annual Computer Se-
curity Applications Conference, 2010.
[9] M. Egele, P. Wurzinger, C. Kr¨ugel, and E. Kirda. De-
fending browsers against drive-by downloads: Mitigating
heap-spraying code injection attacks. In Proceedings of
the Conference on Detection of Intrusions and Malware,
and Vulnerability Assessment, 2009.
[10] B. Feinstein and D. Peck. Caffeine Monkey: Automated
collection, detection and analysis of malicious JavaScript.
In Proceedings of Black Hat USA, 2007.
[11] F. Howard. Malware with your mocha: Obfuscation
and anti-emulation tricks inmalicious JavaScript. http:
//www.sophos.com/security/technical-papers/
malware_with_your_mocha.pdf, Sept. 2010.
[12] M. Howard.
space layout
Address
tion in Windows Vista.
com/b/michael_howard/archive/2006/05/