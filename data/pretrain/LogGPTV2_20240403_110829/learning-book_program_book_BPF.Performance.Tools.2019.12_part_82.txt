[16, 32)
185 188e88e88
[32, 64)
[64, 128]
88886886886881 000
[128, 256}
2 1
Pus [COM_STMT_EXECUTE] :
[16, 32)
1410 188e889
[32, 64)
1654 18898898
[64, 128]
112 leeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee 
[128, 256}
8899 18e988e88e886 886e88e88986e8e988e88e886 8869
[256, 512)
5000 leeeeeeeeeeeeeeeeeeeeeee
[512, 1K]
1478 1889889
[1K, 2K)
5 1
[2K, 4K)
1504 1869889
[4K, 83]
141 |
[8K, 16K)
71
[16K,32K)
11
This shows that queries took between 8 and 256 microseconds and that statement execution was
bimodal, with modes of different latencies.
This works by instrumenting time (latency) between the USDT probes mysql:command_start
and mysql:command_done, and reading the command type from the start probe. The over-
head should be negligible, as the rate of commands is typically low (less than a thousand
per second).
---
## Page 656
13.2 BPF Tools
619
The source to mysqld_clat(8) is:
#1/usx/local/bin/bpEtrace
BEGIN
printf(*Tracing mysgld cormand latencies, Ctr]C to end.\o*);
// from include/my_commandi.h1
Bcom[0] - *coM_sLEEP*;
LIoa0。 = []uoog
Bcon[2] = *COM_INIT_DB*
xxsoao = [ejuoog
Bcon[4] - *coH_FrELo_LIsT*;
Bcon[5] - *coM_CREATE_DB*;
80“a080400。 - [9]u
Bcon[9] - *COM_STATISTICs*
Bcon[10] - *COM_P9OCESs_INFO*;
Bcon[11] - *coe_coNEcr*;
TIxss3084N00。 = [ztu008
rμ908soaoo。 = [et]uoog
Bcon[14] = *CON_PING*
3KIaa0o。 = [st]uoog
fsHI03xYT30N00。 -[9t]u00g
fudHnacoTNIeNoo。 = [et]uoo8
Bcon[19] - *coe_TABLs_0xMP*;
Bcon[20] = *CON_CONNECT_OUT";
3nxsaxsH0。 - [cjuoog
Bcon[24] - *COM_STKT_SEND_LONG_A7A*;
Bcon[25] = *COe_STMT_CLoSE*;
Bcon[26] = *CON_STXT_RESET*;
Notaossa0 - [c]uoog
Bcon[29] = *COe_DAEMON*
Bcon[ 30] = *CON_BINLOG_DUMP_GTID*≠
---
## Page 657
620
Chapter 13 Applications
usdt: /usr/sbin/mysgld:mysq] :cormand_start
1
↑6xe - [PT|pueuuoo]
Bstart[tid] = nsecs;
usdt:/usr/sbin/mysgld:mysq] rcormand_done
/ [p]xes8/
Sdux = [nseca - fstart[tid]) / 1000;
Bus[gcon[fcormand [tid]]] = hist($dur) 
delete (8conmand [tid]) 
delete (bstart[tid)) :
END
clear (8con) 
This includes a lookup table to convert from a command ID integer to a human-readable string:
the command name. These names are from the MySQL server source in include/my_command.h
and are also documented in the USDT probe reference [155].
If USDT probes are not available, this tool can be rewritten to use uprobes of the dispatch_
command( function. Instead of reproducing the entire tool, here is a diff that highlights the
required changes:
5 diff mysqld_clat.bt mysqld_clat_uprobes.bt
42c42
 upzobe: /usr/sbin/nysqld:*dispatch_command*
44c44
Bcommand[tid] = arg1
==
Bcomnand[t1d] = arg2:
48c48
uretprobe :/usx/sbin/nysqld: *dispatch_connand*
the tool is the same.
The command is fetched from a different argument and uprobes are used instead, but the rest of
---
## Page 658
13.2 BPF Tools
621
13.2.12 signals
signals(8)* traces process signals and shows a summary distribution of the signal and target
process. This is a useful troubleshooting tool for investigating why applications may be terminat-
ing unexpectedlly, which may be because they were sent a signal. Example output:
 signals.bt
Attaching 3 pzobes...
Counting sigoals. Hit Ctrl-C to end.
[SIGNAL,  PID, COMM] - COUNT
[SIGKILL, 3022, sleep]: ]
e[SIGINT, 2997, s1gnals,bt] : 1
[S1GCHLD, 21086, bssb] : 1
e[SIGSYs, 3014, ServiceKorker t]: 4
e[SIGALRM, 2903, npstat] : 6
e[SIGALRM, 18B2, Xorg]: 87
This output showed that a SIGKILL was sent to the sleep process with PID 3022 once (it only
needs to be sent once), while SIGALRM was sent to Xorg PID 1882 a total of 87 times while
tracing.
It works by tracing the signal:signal_generate tracepoint. Since these are infrequent, the overhead
is expected to be negligible.
The source to signals(8) is:
/usr/local/bin/bpftrace
BEGIN
printf(*Counting signals. Hit Ctr]C to end.ln*) 
// from /usr/include/asn-generic/signal .h:
Bsig[0] = *0;
Bsig[1] - *SIGHUP*;
Bsig[2] - *sIGINT;
uLino1s - [c]bteg
Bsig[4] - *SIGILL*;
Bsig[5] - *SIGTRAP";
Bsig[6] - *SIGABRT";
8 Origin: I created this for this book on 16-Feb-2019, plus earlier versions for other tracers. These were inspired by
sig.d from the Dynam/c Tracing Gu/de, Jan 2005 [Sun 05].
---
## Page 659
622
Chapter 1.3Applications
Bsig[7] - *sIGBUS*;
Bsig[B] - *SIGFPE′,
Bsig[9] - *SIGKILL*;
tesnors。 - [ot]6rs8
Ass91s。 - [1t]61sg8
zesn5is。 - [zt]6ts8
aala51s。 - [et]6tsg
T41s。 - [>t]6t58
Bsig[16] - *sIGsrKFLT”;
GTH0oIS。 = [cT]6Tsg
I80201s。 - [8t]6158
d0ss91s。 - [6t]6te8
dts1o1s。 - [0z]61s8
101s, - [1]eg
n0szo1s。 - [zzl6ts8
Bsig[23] = *SIGURG”; 
ndoxors. - [>z]61s8
Bsig[25] = *sIGxrss*
Bsig[26] - *sIGVTALRN*;
Bsig[27] = *sIGPROE* ;
gNIxos。 - [ez]bt8
sig[29] - *s1G10*;
Bsig[30] = *SIGPMR”;
Bsig[31] = *sIGsrs";
 [Bs1g[args=>sig1 , args=>pid, axqs=>conn] = count () ;
END
printf(*.n8 [SIGNAL, PID, COMM] = COOMT*):
clear (8sig)
This uses a lookup table to convert the signal number to a readable code. In the kernel source,
there is no name for signal number zero; howeve, it is used for health checks to determine if the
target PID is still running.
---
## Page 660
13.2 BPF Tools
623
13.2.13 killsnoop
killsnoop(8)? is a BCC and bpftrace tool to trace signals sent via the kil(2) syscall. This can show
who is sending signals but, unlike signals(8), does not trace all signals sent on the system, only
those sent via kill(2). Example output:
+ki11snoop
TIME
PID
CONH
SIGTPID
RESULT
00:28:00 21086 bash
9
3593
[.--]
This output shows the bash shell sent a signal 9 (KILL) to PID 3593.
This works by tracing the syscalls:sys_enter_killand syscalls:sys_exit_kill tracepoints. The
overhead should be negligible.
BCC
Command line usage:
ki1lsnoop [options]
Options include:
• =x: Only show failed kill syscalls
=p PID: Measure this process only
bpftrace
The following is the code for the bpftrace version, which summarizes ts core functionality.
This version does not support options.
+1/usr/local/bin/bpftrace
BEGIN
printf(*7racing kill() signals... Hit Ctel-C to end.^n*);
printf(*=9s =6s 16s 4s =6s s\n*, *TIHE", "PID", "C0MM*, *SIG"”,
*TPID", *RESULT*)
tracepoint:syscalls:sys_enter_ki11
etpld[tld] = args=>p.d;
I also wrote the BCC version on 20-Sep-2015 and the bpftrace version on 7-Sep-2018.
---
## Page 661
624
Chapter 13 Applications
Btsig [tid] - args->sig
tracepoint:syscalls:sys_exit_k111
/8tpid [tid]/
timeI*%B:H:s *)
printf(*4=6d s16s 5=4d 6d sd)n*, p1d, comn, 8tslg[tld], 8tp1d[t1d],
args->ret) 
delete (@tpld[tid])
delete (etsig[tid]}
The program stores the target PID and signal on the entry to the syscall, so they can be referenced and
printed on the exit. This could be enhanced like signals(8) to include a lookup table of signal names.
13.2.14 pmlock and pmheld
The pmlock(8)0 and pmheld(8) bpftrace tools record libpthread mutex lock latency and held
times as histograms, with user-level stacks. pmlock(8) can be used to identify an issue of lock
contention, and then pmheld(8) can show the cause: which code path is responsible. Starting
with pmlock(8) on MySQL server:
+ pmlock.bt $ (pgrep mysqld)
Attaching 4 prsbes...
Tracing libpthresd mutex lock latency, Ctr1-C to end.
°C
[...]
elock_latency_ns[0x7f3728001a50, 
pthzead_nutex_lock+36
THD::Query_plan:1set_query_plan (enun_sql_command, LEx*, boo1l) +121
mysql_execute_connand (T8D*, boo1) +15991
Prepared_statenent::execute (String*, boo1) +1410
 mysg1d] :
[18, 2K]
123|
[2K, 4K)
1203 1889889889
[4K, 8K)
6576 188e88e88e888888e88e88e88e88e88e88e888888e88e88e8ee8e1
[8K, 16K)
988888898808898816107
10 0rigin: I crested these tools for this book on 17-Feb-2019, inspired by the Solaris lockstat(IM) tool, which also
showed various lock times with latency histograms and partial stack traces.
---
## Page 662
13.2 BPF Tools
625
elock_latency_ns [0×x7f37280019f0 ,
pthzead_nutex_lock+36
THD::set_query lst_mysg]_con.st_lex_string consts) +94
Prepared_statenent::execute [String*, bcol) +336
Prepared_statenentirexecute_loop (String*, boo1, unsigned char*, unsigned char*...
mysqld_stat_execute (THD*, unslgned Long, unslgned long, unslgned char*, unsign..
r mysqld] :
[18, 2K]
471
[2K, 4K)
945 188988988
[4K, 8K)
3290 18ee88e88e88e888e8ee8ee8ee8ee88
[8K, 16K)
5702 1889889889888 8889889889899889889889888 8889889889899881
lock_1atency_ns [0×7f37280019f0 ,
pthzead_nutex_1ock+36
THD::set_querylst_nysg]_con.st_lex_string consts) +94
dlspatch_connand (THD*, Cox_DATA const*, enun_sezvez_cormand) +1045
S+(GH>puesuoaop
handle_connectlon+680
 mysq1d] :
[18, 23]
55|
[2K, 4K)
1198 186988988988
[4K, 83]
5283 1eee8ee8ee88e88ee8ee8ee8ee8ee8ee8ee88e88ee8ee8eeeeeee1
[8K, 16K]
3966 1888e88 888888e8ee8e8e88e88
Ssaoss sted apoo tosg osetoszxo ssappe xoof to ouape mots soes og se a
THD:set_query0), and with times usually in the 4 to 16-microsecond range.
Now running pmheld(8):
+ pmheld.bt $ (pgrep mysqld)
Attaching 5 pzobes..
Tracing libpthread mutex held times, Ctrl-C to end.
[..]
eheld_tine_ns [0x7f37280019c0,
pthread_nutex_unlock+0
close_thread_table (THD*, TABLE**) +169
close_thread_tables (THD*) +923
mysql_execute_cormand (THD*, bool) +887
Prepared_statenent::execute [String*, bool) +1410
: [pbsAu
[2K, 43)
3311 leeeeeeeeeeee eeeeeeeeeeeeeeeeeeeeeeeeee
[4K,8K)
4523 868888 8888898898989886 888e88e8898898 1
---
## Page 663
626
 Chapter 13 Applications
eheld_tine_ns [0×x7f37280019f0,
pthread_nutex_unlock+0
THD::set_query lst_mysq]_con.st_lex_string consts) +147
dlspatch_command (THD*, Cox_DATA const*, enun_server_cormand) +1045
S+ (xGH>poesuoop
handle_connectlon+680
mysqld] :
[2K, 4K)
3848 18ee88e88e88e88ee88e8ee8ee8ee88e88e88e88
[4K, 8K)
5038 18 988 88 888 88898898898898 9889889888 888e88e889869801
[B, 16K]
 1
[16K,32K)
10
(x9*x21
11
ehe1d_tine_ns [0x7f37280019c0,
_pthread_nutex_unlock+0
Prepared_statenent::execute (String*, bool) +321
Prepared_statenent:itexecute_loop (String*, bool, unsigned char*, unsigned char* ..-
dispatch_conmand (THD*, Co_pATA const*, enun_server_cormand) +S582
mysqld_stat_execute (THD*, unslgned long, unsigned long. unsigned char*, unsign.. -
 mysq1d] :
[1K,2K)
2204 188e88e88e886 886e8ee86e8
[2K, 4K)
4803 1eee88e88e88e888e8ee8ee8ee8ee88e88e88e88ee8ee8ee8ee8e1
[4K, 8K]
2845 1869889889888 88988988988988988
[BK, 16K]
[16K,32K)
111
This shows paths that were holding the same lock and the duration it was held, as a histogram.
There are various courses of action given all this data: the size of thread pools could be tuned to
redluce lock contention, and a developer could look at the holding code paths to optimize them
to hold the lock for shorter durations.
It is recommended to output these tools to files for later analysis. For example:
 pmlock.bt PID > out-pnlock01.txt
# pmheld.bt PID > out .pnhe1d01 .txt
An optional PID can be provided to only trace that process ID, which is also recommended to
redluce the overhead on the system. Without it, all pthread lock events system-wide are recorded.
These tools work by instrumenting libpthread functions using uprobes and uretprobes:
pthread_mutex_lock( and pthread_mutex_unlock(). The overhead can be significant, as
these lock events can be very extremely frequent. For example, timing them using BCC
funccount for one second:
---
## Page 664
13.2 BPF Tools
627
+funccount -d 1 */1ib/x86_641inux-gnu/1ibpthread.so.0:pthread_mutex_*1ock'
Tracing 4 functlons for
•/1ib/x86_64linux-gnu/1ilbpthreed,so.0pthresd_mutex_*lock*.. Rit Ctel-C to end
FUBC
COUVT
pthread_nutex_trylock
4525
pthread_nutex_lock
44726
pthread_nutex_unlock
49132
At such rates, axdding a tiny amount of overhead to each call will add up.
pmlock
The source to pmlock(8) is:
1/usz/local/bin/bpftrace
BEGIN
printf (*Tracing libpthresd mutex lock latency, Ctel-C to end.n*)
1
uprobe:/1ib/x86_6411nux=gnu/1lbpthzead,so 0:pthzead_mutex_1ock
/$1 == 0 11 pid == $1/
1
8lock_start[tid] - nsecs,
Block_addx[tild] = arg0;
uretprobe:/lib/x86_641inux=gnu/lilbpthread.so,0:pthread_mutex_lock
/ ($1 == 0 11 pld ==$1) ss @lock_staxt [tla] /
lock_1atency_ns[usyn (8lock_addx[t1d]) , ustack (5),。 conn]=