c
c
(
generated 
×+
dO t
|
1
D.  Discussion 
P
×
|
by 
log
algorithm 
. 
|
P
|)
BOVTest 
is 
Recall  that buffer overflow  occurs  when  data  is  written 
beyond the boundary of an array-like structure. Let D be the 
data  to  be  written.  Let  B  be  an  array-like  structure.  As 
discussed earlier, if the size of D is larger than the capacity 
of  B  (either  D  is  unexpectedly  long,  or  B  is  unexpectedly 
small, or both), then D will be written beyond the boundary 
of  B,  i.e.,  B  will  overflow.  There  is  a  more  subtle  case  to 
consider. In languages like C, an array-like structure is often 
accessed  using  a pointer,  and  such  a pointer  can be  moved 
forward  or  backward  using  explicit  arithmetic  operations. 
For example, an array variable in C is in fact a pointer that 
points  to  the  beginning  of  the  array.  It  is  possible  that  the 
pointer  may  be  moved  beyond  the  upper  or  even  lower 
boundary  of  a  buffer  due  to  explicit  pointer  arithmetic 
operations. If data of any size is written at this point, a buffer 
overflow will occur.  
The above scenario suggests that attention should also be 
paid to external parameters whose values may be used as an 
offset  in  a  pointer  arithmetic  operation,  in  addition  to 
external  parameters  of  variable 
length,  and  external 
parameters that indicate the length of other parameters. For 
example, in a record keeping application, the record number 
may be used as an offset to locate a record. If proper checks 
are not performed, a negative value, or an unexpectedly large 
positive  value,  of  the  record  number  could  move  the  base 
pointer beyond the lower or upper boundary of the structure 
that keeps all the records.  
It  is  worth  noting  that  extreme  values  typically  matter 
because of their extreme properties, instead of their specific 
values.  For  example,  what  matters  for  an  extreme  string  is 
typically its length, instead of the specific characters in the 
string.  This  observation  greatly  simplifies  the  selection  of 
extreme values.  
Our approach is most effective if the attack-payload and 
attack-control parameters and values are identified properly. 
If  a  vulnerable  point  can  only  be  reached  when  an  attack-
payload or attack-control parameter takes a particular value, 
and if this value is not identified, then our approach will miss 
this vulnerable point. Note that an attack-payload parameter 
may also be involved in a control-flow decision. In this case, 
some extreme values of this parameter may be able to reach 
a  vulnerable  point,  whereas  other  extreme  values  may  not. 
Nonetheless, our approach ensures t-way coverage for each 
attack-payload  parameter  (with  its  extreme  values)  and  its 
control parameters (with  their  control  values). This  ensures 
that no vulnerable point will be missed because a particular t-
way combination is not tested in our approach. 
Fortunately,  identification of attack-payload  and attack-
control parameters and values does not have to be perfect. In 
practice, we can exploit this flexibility to scale up or down 
our test effort. On the one hand, when adequate resources are 
available,  more  parameters  and  values  can  be  identified  to 
acquire  more  confidence  at  the  cost  of  creating  more  tests. 
For  example,  if  we  are  unsure  about  whether  an  external 
parameter  should  be  considered  to  be  an  attack-control 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:29:42 UTC from IEEE Xplore.  Restrictions apply. 
273parameter or a particular value should be considered to be an 
extreme or control value, it is safe to do so. This will likely 
create more tests, but will also help to detect vulnerabilities 
that  otherwise  would  not  be  detected.  On  the  other  hand, 
when  the  resource  is  constrained,  we  can  focus  our  effort 
only on a subset of parameters and values that we believe are 
the  most  important  ones  to  test.  Doing  so  will  reduce  the 
number  of 
tests,  but  may  miss  some  vulnerabilities. 
Nonetheless,  any  vulnerability  that  is  detected  by  our 
approach is guaranteed to be a real vulnerability. 
III.  TANCE: A PROTOYPE TOOL 
We implemented our approach in a prototype tool called 
Tance.  Fig.  4  shows  the  architecture  of  Tance,  which 
consists of the following major components:  
Controller:  This  is  the  core  component  of  Tance.  It  is 
responsible for driving the entire testing process. In a typical 
scenario, after Controller receives from the user the external 
parameter  model  of  the  subject  application,  it  calls  Test 
Generator to generate combinatorial tests based on the given 
parameter  model.  For  each  test,  Controller  uses  Test 
Transformer to transform it into an executable format, i.e., a 
format  that  is  accepted  by  the  subject  application.  Then, 
Controller  calls  Test  Executor 
test 
automatically.  
to  execute  each 
Test  Generator: This component  is  responsible  for  the 
actual  test  generation.  In  other  words,  this  component 
implements algorithm BOVTest. This component first uses a 
combinatorial  test  generation  tool,  called  ACTS  (formerly 
known as Fireeye) [24] to generate a base combinatorial test 
set,  which  is  used  later  to derive  a  set of complete  tests as 
discussed in Section II.  
Test  Transformer:  This  component  is  responsible  for 
transforming  each  combinatorial  test  into  a  format  that  is 
accepted  by  the  subject  program.  This  step  is  necessary 
because  a  combinatorial  test  only  consists  of  parameter 
values, but programs often require a test to be presented in a 
particular  format.  For  example,  a  web  server  requires  each 
test  to  be  presented  as  an  HTTP  request.  This  component 
needs  to  be  customized  for  different  programs.  Tance 
provides  a  programming  interface  that  allows  the  user  to 
hook a third party component into its testing framework. 
Test  Executor:  This  component  is  responsible  for 
carrying out the actual test execution process. For example, 
this  tool  will  send  test  requests  automatically  to  HTTP 
servers. In addition, Test Executor will restart HTTP servers 
before  running  the  next  test  so  that there  is  no interference 
between  different  tests.  This  component  also  needs  to  be 
customized  for  different  programs.  Tance  also  provides  a 
programming  interface  for  integration  with  an  existing  test 
execution environment. 
Bounds  Checker: This component is used to detect the 
actual occurrence of a buffer overflow. In our experiments, 
we used the bounds checking tool reported in [10]. This tool 
instruments the source code. Source-level information helps 
analysis  of  test  results  for  our  evaluation  purpose.  In 
practice,  our  tool  can  be  used  with  bounds  checkers  that 
work  on  binary  code,  e.g.,  Chaperon,  which  require  no 
source code access. 
IV.  CASE STUDIES 
In Section IV.A, we present the results of our inspection 
on  three  public  vulnerability  databases,  as  an  effort  to 
validate  Hypothesis  H1.  In  Section  IV.B,  we  describe  the 
subject programs as well as the computing environment used 
in  our  case  studies.  In  Section  IV.C,  we  present  the 
vulnerability  detection  results  of  applying  our  approach  to 
five open-source programs. 
A.  Validation of Hypothesis H1 
To  validate  Hypothesis  H1,  we  checked  three  public 
vulnerability  databases:  National  Vulnerability  Database 
(NVD)  [27],  SecurityFocus  [32],  and  SecurityTracker  [33]. 
For each database, we conducted a search using the keyword 
“buffer  overflow”  to  retrieve  reports  on  buffer  overflow 
vulnerabilities. For each of the three databases, we inspected 
the  first  100  reports  returned  by  our  search.  Among  the 
reports  we  inspected,  there  are  15  reports  cross-referenced 
between NVD and SecurityTracker. 
Figure 4.   Tance’s architecture 
into 
Table I shows the results of our inspection. We classify 
the  reports 
three  categories.  The  first  category 
(Explicitly  Stated)  includes  reports  that  contain  an  explicit 
statement confirming the satisfaction of Hypothesis H1. For 
example,  the  report  CVE-2010-0361  in  NVD  contains  the 
following  statement:  “Stack-based  buffer  overflow  …  via  a 
long  URI  in  HTTP  OPTIONS  request.”.  This  statement 
explicitly states that a single parameter URI takes an extreme 
value.  The  second  category  (Reasonably  Inferred)  includes 
reports that are written in a way that reasonably suggests the 
satisfaction of Hypothesis H1, despite the lack of an explicit 
statement. For example, the report CVE-2007-1997 in NVD 
contains the following statement: “… via a crafted CHM file 
that  contains  a  negative  integer  …  leads  to  a  stack-based 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:29:42 UTC from IEEE Xplore.  Restrictions apply. 
274buffer overflow.”. This statement does not explicitly identify 
a  parameter,  but  it  is  reasonable  to  believe  that  one  of  the 
fields  in  a  CHM  file  can  be  modeled  as  an  attack-payload 
parameter taking the negative value. The third category (Not 
Clear)  includes  reports  that  do  not  fall  into  the  first  two 
categories.  For  these  reports,  we  do  not  have  adequate 
information to make a reasonable judgment. We did not find 
any report that explicitly states that two or more parameters 
must  take  an  extreme  value  at  the  same  time  to  trigger  a 
buffer  overflow.  In  other  words,  none  of  the  examined 
reports explicitly disproves Hypothesis H1. 
In  [21],  it  is  reported  that  NIST  examined  more  than 
3000  NVD  reports  for  denial-of-service  vulnerabilities  and 
found  that  93.1  percent  involved  only  a  single  attack-
payload parameter, nearly always an input string that is too 
long. This result is consistent with our findings.  
TABLE I.  
VALIDATION OF HYPOTHESIS H1 
Database 
NVD 
SecurityFocus 
SecurityTracker 
TABLE II.  
Subject 
Ghttpd 
Gzip 
Hypermail 
Nullhttpd 
Pine 
4 
34 
57 
11 
449 
Explicitly 
stated 
49 
61 
62 
Reasonably 
inferred 
25 
9 
29 
Not clear 
26 
30 
9 
STATISTICS OF SUBJECT APPLICATIONS 
Files 
LOC 
Functions 
16 
108 
401 
38 
4883 
609 
5809 
23057 
2245 
154301 
B.  Experimental Setup 
Subject  Programs:  Our  case  studies  use  the  following 
five programs:  
(1)  Ghttpd (version 1.4.4) is a fast and efficient web server 
that supports a reduced set of HTTP requests [12]. 
(version  1.2.4) 
is 
the  widely  used  GNU 
(2)  Gzip 
compression utility tool [17].  
(3)  Hypermail  (version  2.1.3)  is  a  tool  that  facilitates  the 
browsing  of  an  email  archive.  It  compiles  an  email 
archive  in  the  UNIX  mailbox  format  to  a  set of  cross-
referenced HTML documents [19].  
(4)  Nullhttpd  (version  0.5.0)  is  a  web  server  that  handles 
HTTP requests [28]. 
(5)  Pine  (version  3.96)  is  a  widely  used  tool  for  reading, 
sending, and managing emails [29]. 
All five programs are written in C. Ghttpd and Nullhttpd 
have been used in other empirical studies for buffer overflow 
detection methods, e.g., [34]. Table II shows some statistics 
about the size of these five applications.  
Platform  Configuration:  The  five  case  studies  were 
conducted on a 3GHz machine that has 2GB RAM, running 
Red Hat Enterprise Linux WS release 4, gcc-3.4.6 and bgcc-
3.4.6. 
C.  Testing Results and Discussion 
In  our  studies,  we  identified  the  attack-payload  and 
fairly 
attack-control  parameters 
and  values 
in 
a 