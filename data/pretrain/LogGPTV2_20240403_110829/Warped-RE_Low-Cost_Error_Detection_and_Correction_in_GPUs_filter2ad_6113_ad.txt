In this stage, the active mask for each sub-warp is generated
and the threads replications on the idle SIMT lanes are
performed based on the inherent redundancy and warp defor-
mation information generated in the previous stage. Figure 10
shows how this stage ﬁts in the GPU pipeline. The stage is
added between the issue queue and the SP unit pipeline. Every
warp instruction iterates in this stage according to the number
of sub-warps required for the current operational mode. In
every cycle, a new sub-warp active mask is generated using
the deformation datapath unit which corresponds to the current
operational mode. The sub-warp active mask is then used to
control thread replication in order to force redundancy by
exploiting the idle lanes. In the following paragraphs, we
338338
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:52:38 UTC from IEEE Xplore.  Restrictions apply. 
Decode and 
schedule 
Inherent Redundancy 
Sub-warps’ Active Masks 
and  
Issue 
Deformation Analysis 
and  
Thread Replication 
EX1 
EXN 
Write-Back 
T5 
T4 
T3 
T2 
T1 
T0 
Iteration 
Counter 
MUX 
Select Ctrl 
D_T 
3-to-1 
MUX 
3-to-1 
MUX 
4-to-1 
MUX 
4-to-1 
MUX 
3-to-1 
MUX 
3-to-1 
MUX 
L5 
L4 
L3 
L2 
L1 
L0 
Fig. 12: Thread replication hardware support
cluster is issued as part of the 1st sub-warp. Hence, the cluster
will be completely idle during the 2nd sub-warp (i.e. S2 AM
[y+1: y] = 00). The latter is achieved by XOR-ing the original
active mask and the issued active mask for 1st sub-warp to
deactivate all the threads issued as part of the 1st sub-warp.
The 5th row represents the case when warp deformation
is required and there are two threads assigned to the cluster
but they are not inherently redundant. During the 1st iteration,
the active mask of the 1st sub-warp is chosen as ”01” through
the priority encoder and the 4:1 MUX in Figure 11. Similarly,
in the 2nd iteration the active mask of the 2nd sub-warp is
chosen as ”10”. Finally, the 6th row shows the case when warp
deformation is required and two inherently redundant threads
are assigned to the cluster. In this case, the two threads are
assigned to the 1st sub-warp which is achieved through the
upper input of the second rightmost 2:1 MUX in Figure 11.
The XOR-ing deactivates all threads issued with the 1st sub-
warp, which causes the active mask of the 2nd sub-warp to be
”00” as chosen by the priority encoder and the 4:1 MUX.
The design of the TMR deformation datapath unit is very
similar to the DMR deformation datapath unit. The function-
ality is also the same with the exception that the number of
sub-warps during TMR mode can be zero, two, three, or four.
In the interest of space, the exact details are left out.
2) Replicating Active Threads: To leverage idle lanes for
forced redundancy, we need the ability to forward the source
operands of each SIMT lane to other lanes in the same cluster.
We achieve this by adding forwarding multiplexers adopted
and modiﬁed from [4] [6] where the cluster size is ﬁxed to
four lanes. In Warped-RE framework, the cluster size is two
lanes during DMR mode then it dynamically changes to three
lanes when an error is detected and TMR mode is activated.
Figure 12 shows the multiplexers required for the ﬁrst
six SIMT lanes with an SP unit (i.e. L5-L0). In addition to
receiving the source operands of the active thread assigned
to it, L0 should be able to receive source operands from L1
during DMR mode and from L1 and L2 During TMR mode.
Hence, a 3:1 MUX is needed for L0. Similarly, L1 should be
able to receive source operands from the thread assigned to
it or the threads assigned to L0 and L2. So, a 3:1 MUX is
also needed for L1. On the other hand, L2 should be able to
receive source operands from L3 during DMR mode and at
the same time should be able to receive source operands from
L0 and L1 during TMR mode. Hence, a 4:1 MUX is needed
for L2. Following the same criteria, L3, L4 and L5 need 4:1
MUX, 3:1 MUX, and 3:1 MUX, respectively.
The second set of six SIMT lanes within the SP unit (i.e.
L11-L6) have exactly the same multiplexing requirements as
the ﬁrst six lanes. The last four SIMT lanes (i.e. L15-L12)
have different multiplexing requirements because they form
one special TMR cluster. L14, L13 and L12 need 4:1 MUXes
NDMR_sub-warps 
NTMR_sub-warps 
WD
DMR 
DIR Vector 
TIR Vector 
W D T M R  
P
i
p
e
R
e
g
i
s
t
e
r
p
r
a
w
_
b
u
S
k
s
a
M
e
v
i
t
c
A
P
i
p
e
R
e
g
i
s
t
e
r
DMR 
Deformation  
Datapath 
TMR 
Deformation 
Datapath 
Fig. 10: Sub-warps’ active masks and thread replication stage
Active Mask 
11 
4
t
o
1
M
u
x
S1 S0 
I
n
p
u
t
M
a
s
k
R
e
g
AMy 
AMy+1 
00 
10 
01 
Valid 
E
n
c
o
d
e
r
2
-
t
o
-
1
P
r
i
o
r
i
t
y
DIR  
Issued 
Active 
Mask 
2
t
o
1
M
u
x
New Warp 
2
t
o
1
M
u
x
2
t
o
1
M
u
x
WDDMR 
k
s
a
M
p
r
a
w
-
b
u
S
t
n
e
r
r
u
C
≡
t
u
p
t
u
O
Fig. 11: DMR Cluster deformation datapath
discuss the detailed design for the additional logic required
to perform these tasks.
1) Generating Sub-warps Active Masks in DMR: Figure 11
shows the deformation datapath unit for one DMR cluster.
For each SP unit in the Fermi architecture, we need eight
DMR deformation datapath units responsible for generating
the active masks for the eight DMR clusters. The active masks
of the DMR clusters are then concatenated together to form
the active mask of the whole sub-warp. For every new warp
instruction, the logic in Figure 11 is iterated based on number
of sub-warps needed.
Table II lists all possible cases that could happen while
generating the active mask for the sub-warps of a DMR cluster.
The 1st row shows the case where no deformation is required
(i.e. W DDM R = 0). In this case, the original issued active
mask of the cluster (i.e. AM [y+1: y]) is selected to be
the active mask of the ﬁrst sub-warp (i.e. S1 AM [y+1: y])
as shown by the upper input of the rightmost 2:1 MUX in
Figure 11. The ”jk” expression in the 1st row of Table II can
be any of the four possible active masks: ”00”, ”01”, ”10”, and
”11”. As no deformation is required, there will be no second
sub-warp. The 2nd, 3rd and 4th rows show the cases when
warp deformation is required but the cluster under study has
at most one active thread assigned to it. In these cases, inherent
redundancy is not available (i.e. DIR[y/2] = 0) and the priority
encoder ensures that the active thread originally assigned to the
Row#
DIR[y/2]
Input
AM[y+1:y] W DDM R
Output
S1 AM
[y + 1 : y]
S2 AM
[y + 1 : y]
1
2
3
4
5
6
x
0
0
0
0
1
jk
00
01
10
11
11
0
1
1
1
1
1
jk
00
01
10
01
11
N/A
00
00
00
10
00
TABLE II: DMR cluster sub-warps active masks
339339
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:52:38 UTC from IEEE Xplore.  Restrictions apply. 
in order to receive operands from all threads assigned to the
cluster. L15 only needs a 2:1 MUX to receive source operands
from its assigned thread and the thread assigned to L14 during
DMR mode.
C. Error Detection and Correction Stage
After each sub-warp completes its redundant execution, the
outputs of the SIMT lanes are compared against each other in
order to detect and correct errors. During DMR mode, only
error detection is possible. Hence, it is sufﬁcient to compare
the outputs of every two SIMT lanes which belong to the same
DMR cluster using an XOR-based comparator. During TMR
mode, error detection and correction are performed. Hence, the
outputs of every three SIMT lanes which belong to the same
TMR cluster are fed to TMR voter and comparator logic.
VII. EXPERIMENTAL EVALUATION
To evaluate Warped-RE framework we used GPGPU-Sim
v3.02 [9]. The baseline GPU architecture is conﬁgured using
the Nvidia GTX480 (i.e. Fermi) conﬁguration ﬁle included
in the GPGPU-Sim package and Warped-RE framework is
implemented on top of the baseline architecture. The GPU
pipeline is modiﬁed to include the additional pipeline stages
described in section VI. In the evaluation, 22 benchmarks from
GPGPU-Sim [9], Parboil [10], and Rodinia [11] benchmarks
suites are used to cover a wide range of application domains.
In our evaluation, we perform two sets of experiments. The
ﬁrst set of experiments assume that the underlying hardware
is error-free and the GPU continuously runs in DMR mode
to guarantee 100% error detection. This experiment shows the
cost of providing error detection in the error free scenario.
The second set of experiments assumes every TMR cluster is
suffering from a single non-transient error in one of its SIMT
lanes. Hence, the GPU continuously runs in TMR mode during
the second set of experiments. This experiment shows the cost
of providing error correction.
A. DMR Mode Evaluation
Figure 13 shows the execution time of the Warped-RE
framework during the DMR mode relative to the baseline
architecture without error detection and correction support. The
weighted average performance overhead across all benchmarks
is 8.4%. This overhead is much less than the expected overhead
of dual redundant execution which may reach up to 100%. This
huge reduction in performance overhead is attributed to three
main factors. First, low-cost opportunistic DMR execution is
achieved for many warp instructions (i.e. 46% as shown in
Figure 3) by exploiting inherent redundancy and utilizing idle
SIMT lanes. Second, for some benchmarks it is rarely the
case that warp instructions are issued back-to-back to the same
SP unit due to long latency data dependencies or application
instruction mix. This creates empty bubbles in the SP unit
pipeline which helps to hide the performance degradation
caused by dynamic warp deformation. Third, when warp
deformation is activated it prevents consecutive warps from
issuing to the same SP unit. Consequently, the consecutive
warps give higher priority to ready memory instructions. This
helps to reduce the contention in the memory sub-system
especially for memory-intensive benchmarks and in some cases
it may even lead to an anomalous increase in performance. For
some benchmarks, the beneﬁts achieved by the three factors
i
e
m
T
n
o
i
t
u
c
e
x
E
e
v
i
t
a
l
e
R
e
g
a
t
n
e
c
r
e
P
p
r
a
W
1.4 