### 287
**Authorized licensed use limited to: Tsinghua University. Downloaded on March 20, 2021 at 09:56:20 UTC from IEEE Xplore. Restrictions apply.**

Normalized Mutual Information (NMI) is a relatively new measure, and there is little guidance on what value of NMI constitutes an indication of strong correlation. We address this issue by comparing NMI with the well-studied Pearson correlation coefficient, \( r^2 \). The first three properties of NMI also hold for \( r^2 \); however, the fourth property holds only if \( f \) is a linear function.

Our work begins with the observation that any pair of metrics with strong linear correlation must have a strong correlation, but the converse is not necessarily true. Therefore, a suitable NMI threshold for strong correlation must not classify any pair of metrics with high \( r^2 \) as weakly correlated. A reasonable NMI threshold, \( t_{\text{NMI}} \), for strong correlation with respect to the \( r^2 \) threshold, \( t_{r^2} \), for strong linear correlation, is given by:

\[ t_{\text{NMI}} = \min_{r^2_{XY} > t_{r^2}} \text{NMI}(X, Y) \]

We compute both \( r^2 \) and NMI for many metric pairs, thereby obtaining an estimation of \( t_{\text{NMI}} \) with respect to a given \( t_{r^2} \).

### 2.3 System Monitoring
We use a three-step procedure to monitor the health of the target system:
1. **Compute Similarities:** Calculate NMI for every pair of metrics using samples collected from the target system executing error-free. The number of samples must be large enough to correctly estimate a stable value of the entropy. The resulting NMI values are stored in a similarity matrix, \( M \).
2. **Cluster Metrics:** Feed \( M \) and \( t_{\text{NMI}} \) into a clustering algorithm, which produces a set of clusters such that metrics within a cluster are correlated to each other. Since the relationship between metrics may not fit any pre-assumed form, it is very difficult to establish analytical models for metrics in the cluster. Information entropy provides a tool to monitor the state of each cluster.
3. **Monitor Clusters:** Track the in-cluster entropy at every sampling period. A significant and persistent change in the in-cluster entropy indicates a potential fault, as the correlations among metrics are either weakened or strengthened, both of which could be signs of anomalies.

### Figure 1: In-Cluster Entropy Change
In our prior work, we conducted a small case study to see if the idea held any promise. Fault-injection experiments showed that in-cluster entropy changed visibly, as seen in Figure 1, which illustrates sample results when the fault was injected at time-interval 32. However, no formal evaluation was presented because no detection or diagnosis algorithms were developed in that work. The variability in entropy made the development of such algorithms non-obvious.

### 3 Fault Detection
Consider the entropy behavior of the clusters shown in Figure 1. They show selected representative clusters' behavior when some fault occurs at time-sample 32. Human operators can readily identify significant changes in the pattern of the in-cluster entropy and, as a result, suspect errors. However, it is impractical to have these operators continuously track the behavior of all clusters. On the other hand, automatically identifying anomalies in the in-cluster entropy is very difficult because there are no general rules that differentiate between normal and disturbed behavior.

### 3.1 Observations about the In-Cluster Entropy
Before devising a method to automatically identify anomalous behavior, several characteristics of the in-cluster entropy need to be considered:
1. **Non-Comparability:** The empirical entropy estimated for different clusters are not comparable. As a result, no single threshold is suitable for all clusters. Techniques based on setting thresholds do not work. Only relative changes in the entropy within individual clusters provide reliable signals for fault detection.
2. **Volatility:** Within a cluster, the in-cluster entropy can be very volatile. The empirical entropy is only a rough estimate computed from a sample; if the sample size is small (e.g., when a cluster has only a few metrics), changes in in-cluster entropy may not indicate anomalies.
3. **Single Observation Reliability:** Judgment based on a single observation is not reliable. An algorithm must consider several samples before deciding that an error exists; otherwise, many false alarms may be raised.

These observations suggest that a deviation in entropy is a reliable indication of errors only if the deviation is relatively significant and persistent. Therefore, we choose to employ a non-parametric statistical test, namely the Wilcoxon Rank-Sum test, to identify significant shifts in the in-cluster entropy of individual clusters. The Wilcoxon Rank-Sum test suits our needs because:
1. It is non-parametric (i.e., we make no distribution assumptions), and it does not learn a threshold or rely on one to work.
2. It is a statistical test, which allows temporary fluctuations to be accommodated.

### 3.2 Fault Detection by Wilcoxon Rank-Sum Test
For fault detection, let \( E_i \) be the in-cluster entropy of cluster \( E \) at time \( i \). To detect a significant change in \( E_i \) when a fault occurs, we keep two sliding windows of \( E_i \)'s. The test window consists of the most recent \( n \) \( E_i \)'s. The baseline window consists of the \( m \) \( E_i \)'s preceding the test window. We apply the Wilcoxon Rank-Sum test to the two windows. If the test indicates a significant shift between values in the two windows, an alarm is raised.

The Wilcoxon Rank-Sum test is a well-established hypothesis test. In our case, the null hypothesis is that the two sample sets \(\{E_{s+1}, E_{s+2}, \ldots, E_{s+m}\}\) and \(\{E_{s+m+1}, E_{s+m+2}, \ldots, E_{s+m+n}\}\) from the two sample windows \((s+1, s+m)\) and \((s+m+1, s+n)\) are from the same distribution. The Wilcoxon Rank-Sum statistic is given by:

\[ W = \sum_{i=1}^{m} \sum_{j=1}^{n} h_{s+i, s+m+j} + \frac{m(m+1)}{2} \]

where \( h_{ij} = 1 \) if \( X_i \leq X_j \).

### 4 Diagnosis
RatioScore and SigScore, which we discuss later, are two examples of diagnosis algorithms as defined here. In our implementation of the algorithms, we consider clusters as models and software modules (e.g., Java Servlet, JavaBean, Messaging Engine, etc.) as subsystems. Therefore, our diagnosis localizes faults at the software module level by integrating analysis results from all the clusters. However, with the same algorithms, we can change the tuple \((S, M, C, A, B)\) to extend our diagnosis to different models and to different definitions of subsystem. For example, instead of software components, the subsystems may represent different machines.

### Measures of Diagnosis Accuracy
In general, a good algorithm assigns the faulty component a higher anomaly score than other components. We now describe two measures of diagnosis accuracy, the Faulty-Component Rank and Identified-Fault Counts, which we use to evaluate the quality of our diagnosis.

Assume a diagnosis algorithm is applied to \( m \) cases where errors exist and are detected. We use \( i = 1, 2, \ldots, m \) as indices of these cases. Let \( S_f^i \) be the faulty component in case \( i \), and \( r^i \) be the anomaly-score vector given by the diagnosis algorithm in case \( i \). Intuitively, the rank of the faulty component is an indicator of diagnosis quality. The faulty-component rank, \( R_i \), for case \( i \) is given by:

\[ R_i = \sum_{j=1}^{n} 1_{r_f^i \leq r_j^i} \]

where \( 1_Q = 1 \) if \( Q \) is true, and \( 1_Q = 0 \) if \( Q \) is false. The smaller the \( R_i \), the better the diagnosis is for the case \( i \).

While intuitive, the faulty component rank alone is of no practical use. System administrators consider components in order of decreasing anomaly scores. They first check the component with the highest anomaly score; if not faulty, they proceed to the one with the second-highest anomaly score, and so on. For practical reasons (e.g., time availability), administrators may set a candidate set size \( t \) beforehand and check if the faulty component is one of the \( t \) components with the highest anomaly scores. If so, the fault is diagnosed, i.e., it is identified in the top-\( t \) components. For any \( t \), the number of faults that are successfully identified in the top-\( t \) components (i.e., the identified fault count) is given by:

\[ N_t = \sum_{i=1}^{m} 1_{R_i \leq t} \]

Since there are only \( n \) components, \( t \leq n \). \( t \) can be any integer value from 1 to \( n \) chosen by the system administrator.

### 4.2 Algorithm I: RatioScore
Our first diagnosis algorithm is RatioScore. The idea is to count the number of times a component is found in anomalous clusters. The rationale for this algorithm is that a faulty component is likely to cause the clusters which contain the componentâ€™s metrics to show anomalous behavior. As a result, a component has a higher anomaly score than other components if more clusters containing metrics of that component detect anomalies.

Given the model-subsystem association matrix, \( M \), and the observation vector, \( O(t) \), we can use the Jaccard coefficient to assign an anomaly score to each component:

\[ r_j = \frac{\sum_{i=1}^{n} c_i(t) \cap M_{ij}}{\sum_{i=1}^{n} c_i(t) \cup M_{ij}} \]

Using an anomaly score based on the Jaccard coefficient is the best current diagnosis method based on metric correlations. While it has been proposed [10, 17] and evaluated [17] in the context of metric-pair models, in this paper, we have extended it to clusters. However, there are drawbacks to using the Jaccard coefficient as an anomaly score. Components of a system differ in their "popularity"; a popular component has many dependent components. This phenomenon can cause popular components that depend on a faulty component to have higher anomaly scores. This is because a popular component is more likely to have metrics correlated with the metrics of a faulty component. Thus, correlation models of metrics of a popular component are more likely to report anomalies.

### Figure 3: A Sample System of Components
To see the effects of popular components in diagnosis, consider a system of five components, as illustrated in Figure 3. We have identified five clusters of metrics, and a fault occurs in component B. The fault causes some metrics in component B to behave anomalously. Because component B depends on component A, some metrics in component A are affected by the fault. As a result, Cluster 2 and 4 report anomalous changes in the entropy level, while Cluster 1 does not report any significant change. Cluster 1 may not report an anomaly because it is larger, and as such, its cluster entropy can tolerate disturbance to a few of its metrics. This produces the model-subsystem association matrix and the observations shown in Table 1.

RatioScore will result in an anomaly score vector of \([0.5, 0.33, 0, 0.25, 0.25]^T\). The method correctly indicates that Component B is more likely to be the faulty component than components C, D, or E. However, component A is assigned the highest anomaly score because it is popular. If the dependency information shown in Figure 3 is available, we can suspect that the high score of component A is caused by B; therefore, the scores can be adjusted to rank B higher.

### 4.3 Algorithm II: SigScore
We propose the SigScore algorithm to improve the diagnosis produced by the Jaccard-coefficient-based RatioScore algorithm. This algorithm assumes the availability of the dependency information, which can be obtained from the source code, execution traces, or other artifacts. The anomaly score of a component on which many others depend (i.e., the more popular or significant it is) tends to be less reliable. We leverage knowledge of component dependencies to dampen the influence of popular components. To do so, we first calculate the significance (popularity) measure for all system components and then use them to adjust the anomaly scores.

We define the significance measure of a component as the likelihood that it is called in the long run. This is similar to the likelihood that a web page is accessed on the Internet (i.e., the popularity of a web page). As such, computing the significance measures of components given the system dependency graph is similar to PageRank [6]. PageRank ranks web pages by modeling web page browsing as a stochastic process and uses the stationary probability distribution as a measure of popularity. We can derive the relative significance of components from PageRank by mapping components to web pages and page references to component dependencies. We thus model the system as a stochastic process, in which states are components and state transitions are inter-component calls. The significance measure is the resulting stationary probability distribution.

To adapt PageRank to our needs, we make the following assumptions:
1. A system consists of a set of components (subsystems) denoted by \( S = \{S_1, S_2, S_3, \ldots, S_n\} \). All activities in the system can be viewed as a series of transitions from one component to another.
2. Two components are neighbors if there is a dependency relationship between them. We denote \( P_i \) as the set of neighbor components of \( S_i \).
3. (Optional) Every component has a dependency relationship with at least one other component; i.e., \( P_i \) is always non-empty.
4. Execution shifts from one component to another by a progress transition with probability \( \alpha \), or by an exit transition with probability \( 1 - \alpha \).
5. In a progress transition, a user request continues to be processed by a neighboring component. For a component \( S_i \), the probability distribution vector \( u_i^T \) defines what component executes next, where \( u_i(j) > 0 \) if and only if \( S_j \in P_i \).
6. In an exit transition, the processing of the current request stops, and a new request begins to be processed. For a component \( S_i \), the probability distribution vector \( v^T \) defines what component executes next, where \( v(i) > 0 \) for every \( i \).

These six assumptions reasonably approximate a real software system. For example, a function call or return may cause a progress transition. Likewise, a conditional statement such as "if" may lead to a transition from component \( S_i \) to one of its two neighbors, \( S_a \) and \( S_b \). In \( u_i(a) \) of the cases, it transitions to \( S_a \), and in \( u_i(b) \) of the cases, it transitions to \( S_b \), where \( u_i(a) + u_i(b) = 1 \). When a request or task is terminated and a new one is started, there is an exit transition. The system state \( T_k \in S \) is the component processing a request at time \( k \). Let \( p(S) \) be the probability that

### 288
**Authorized licensed use limited to: Tsinghua University. Downloaded on March 20, 2021 at 09:56:20 UTC from IEEE Xplore. Restrictions apply.**

### 290
**Authorized licensed use limited to: Tsinghua University. Downloaded on March 20, 2021 at 09:56:20 UTC from IEEE Xplore. Restrictions apply.**

### 291