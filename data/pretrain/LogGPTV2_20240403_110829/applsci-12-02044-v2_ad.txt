Figure 34. The compression rates of the joint use on the D dataset.
It can be seen that, in the case of datasets with sizes in gigabytes, the joint use produces approximately 1% higher compression rates than the ones achieved by the single use of the general compressor in Section 5.2.3.5.2.6. Experiment 6: Comparing the Speeds of the Joint Use of the New Enhanced Algorithm and General Compressors
	We also evaluated the compression and decompression times of the joint use of our algorithm and general compressors. The results can be seen in Figures 35â€“38.
Compression and decompression speeds on the Small 
dataset
Compression time Decompression time
IPLoM
IPLoM + 
LZMA
IPLoM +IPLoM
IPLoM + 
LZMA
IPLoM + 
	Bzip2
IPLoM + 
Method PPMd 
MoLFI
MoLFI + 
LZMA
MoLFI + 
Bzip2
MoLFI + 
PPMd
0.000 0.200 0.400 0.600 0.800
Elapsed time (s)
Figure 35. The speeds of the joint use on the Small dataset.
The use of a general compressor increases both the compression and decompression; however, this extra time is negligible. In terms of compression, out of all combinations, the joint use of MoLFI and PPMd proved to be the fastest, while the combination of MoLFI and LZMA takes less time to decompress the data. The use of any combination is considered to be fast.Appl. Sci. 2022, 12, 2044 24 of 32
Compression and decompression speeds on the Mid dataset
Compression speed Decompression speed
IPLoM
IPLoM + 
LZMA
IPLoM + 
	Bzip2
IPLoM + 
Method PPMd 
MoLFI
MoLFI + 
LZMA
MoLFI + 
Bzip2
MoLFI + 
PPMd
0.000 0.500 1.000 1.500 2.000
Elapsed time (s)
Figure 36. The speeds of the joint use on the Mid dataset.
Compression and decompression speeds on the Large 
datasetdataset
Compression speed Decompression speed
IPLoM
IPLoM + 
LZMA
IPLoM + 
	Bzip2
IPLoM + 
Method PPMd 
MoLFI
MoLFI + 
LZMA
MoLFI + 
Bzip2
MoLFI + 
PPMd
0.000 1.000 2.000 3.000 4.000 5.000
Elapsed time (s)
Figure 37. The speeds of the joint use on the Large dataset.
Compression and decompression speeds on the Big dataset
Compression speed 	Decompression speed
IPLoM
IPLoM + 
LZMA
IPLoM + 
	Bzip2IPLoM
IPLoM + 
LZMA
IPLoM + 
	Bzip2
IPLoM + 
Method PPMd 
MoLFI
MoLFI + 
LZMA
MoLFI + 
Bzip2
MoLFI + 
PPMd
0.000 2.000 4.000 6.000 8.000 10.000 12.000
Elapsed time (s)
Figure 38. The speeds of the joint use on the Big dataset.
Appl. Sci. 2022, 12, 2044 25 of 32
5.2.7. Experiment 7: Comparing the Speeds and the Storage Sizes Needed to Retrieve All Instances of an Event Type by the New Enhanced Algorithm and General CompressorsIn this experiment, we randomly selected 10 and 100 templates and investigated the time and storage space that were needed to recover all log entries that correspond to a template in the set. For this experiment, the previously introduced A dataset was used. Figures 39 and 40 show the results of the experiment.
Log entry retrieval speeds in case of 10 templates
Decompression 	Lookup
600Decompression 	Lookup
600
Elapsed time (s) 400
200
0
Proposed Bzip2 LZMA PPMd Proposed General
Figure 39. The times needed to recover all instances of the 10 template.
Log entry retrieval speeds in case of 100 templates
Decompression Lookup
8000
| Elapsed time (s) | 6000 |  |  |  |  |  |  |
|---|---|---|---|---|---|---|---|
| Elapsed time (s) |4000 | | | | | | |
| Elapsed time (s) |2000 | | | | | | || Elapsed time (s) |2000 | | | | | | |
| Elapsed time (s) |0 | | | | | | |
| Elapsed time (s) |0 |Proposed |Bzip2 |LZMA |PPMd |Proposed |General |
Figure 40. The times needed to recover all instances of the 100 template.Since we can find the corresponding log entry based on the ID of the template, in the case of our algorithm, only the Huffman decoding step is necessary. This requires more time than decompressing with a general compressor; however, the time needed to look up the entries is considerably less. The reason behind this is that we only need to check the first n characters of the encoded file (where n is the length of the ID), rather than checking all the constant tokens. The storage size needed is much larger in the case of general compressors, since a full decompression of the data is necessary to look for templates, while, in the case of our algorithm, the intermediate compressed file is enough. In the case of dataset A, this means 2 GB for the general compressors, while only 290 MB for our algorithm.We also wanted to measure the time needed to retrieve the entries when our algorithm is used in conjunction with a general compressor. Since, in Section 5.2.5, the joint use of the proposed method and PPMd had the best compression rate, we chose PPMd as the general compressor for this experiment. The compressed file is first decompressed with PPMd, then the compressed file is decoded using the Huffman algorithm. The results can be seen in Figures 41 and 42.Appl. Sci. 2022, 12, 2044 26 of 32
Log entry retrieval speeds in case of joint use and 10 
templates
| 600
400