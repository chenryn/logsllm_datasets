the interaction classiﬁer.
E. Interaction classiﬁer
The classiﬁer takes a feature vector F as input and outputs
an interaction ID, its inference that the sensor data associated
with that feature vector represents that interaction.
To train the classiﬁer, we segment a subject’s wrist
sensor data based on her actual interaction timings, as
described above. We feed the classiﬁer with feature vectors
corresponding to the actual interaction and provide the actual
interaction labels. Later, when evaluating our approach with
a given subject, we use a classiﬁer that was trained with
other subjects’ data, because our intent is for the classiﬁer
to be user agnostic.
The classiﬁer receives a sequence of feature vectors
and it outputs its inference, a sequence of interaction IDs
(i0, i1, . . .). It then sends this sequence to the authenticator.
We explored two classiﬁers: Naive Bayes classiﬁer and
Random Forest classiﬁer. For our dataset, the Random Forest
classiﬁer outperformed the Naive Bayes classiﬁer; the results
reported in Section VI are with the Random Forest classiﬁer.
F. Authenticator
The authenticator matches two sequences: the sequence of
actual interactions and the sequence of interactions inferred
by the classiﬁer based on the user’s wrist movement. If the
713
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:00:04 UTC from IEEE Xplore.  Restrictions apply. 
two sequences match, the authenticator outputs 1 indicating
that the current terminal and the bracelet user are the same.
On the other hand, if the two sequences do not match, it
outputs 0 indicating that the two users are different. If the
users are different, we need to deauthenticate the bracelet
user, who is logged in the terminal.
To match the two sequences, we use four parameters:
window size, overlap fraction, match threshold, and grace
period. The window size, w, is the number of interactions
the authenticator compares at a time. The overlap fraction,
f (0 ≤ f < 1), indicates how much we should overlap the
moving window, 0 being no overlap. For each window the
authenticator computes a matching score (between 0 and 1)
indicating how well the two sequences match in that window;
0 being no match at all, and 1 being a complete match. If
the matching score for a window is greater than the match
threshold, m, we output 1 for that window, indicating that
the terminal user and the bracelet users are the same for that
window. Otherwise, we output 0 for that window.
If we incorrectly output 0 for a window and deauthenticate
the user immediately, it would frustrate the user. To account
for such false negatives, we introduce the grace period
parameter, g. This parameter indicates how many consecutive
window scores of 0 are measured to deauthenticate the user.
For example, if g = 3 then we should get 0 for three
consecutive windows before we deauthenticate the user. We
reset the zero-count when we get a window with output
1. This parameter increases convenience but also increases
security risk; we keep its default value low.
VI. EVALUATION
As mentioned in Section III, we desire ZEBRA to be
continuous, passive, unobtrusive, user-agnostic, quick, and
accurate. We achieve the ﬁrst four properties by design.
ZEBRA requires no explicit input from the user and as long
as the user is in (radio) proximity, i.e., the user’s bracelet
can send data to the terminal, ZEBRA continuously veriﬁes
the presence of the user; thus, ZEBRA does continuous
authentication passively. The bracelet can potentially monitor
a user’s physical activity, which may be sensitive information
for some users. ZEBRA respects users’ privacy, and it does
not monitor the user’s movements when the user (and no one
else) is not using her logged-in terminal. While evaluating
ZEBRA for a user, we did not train the classiﬁer using that
user’s data. Hence, ZEBRA is user-agnostic, i.e., independent
of the user’s behavior when she is using a terminal. We
evaluate accuracy and quickness through a user study and
present the results in this section.
A. User study
We recruited 20 subjects for our user study, using ﬂyers
posted across our college campus and online. Table II shows
demographic data about the subjects. Subjects took about 30
to 40 mins to complete the user study; they received $10 as
Table II: Demographics of user study participants.
Gender
Field
Age
Handedness
Category
Male
Female
Computer Science
Non-CS
18-25
25-30
Right
Left
# of subjects
7
13
8
12
15
5
19
1
compensation. Our research protocol was approved by our
campus IRB.
The user study consisted of three experiments. The
ﬁrst experiment was designed to capture the users’ hand
movements as they interact with a desktop in normal use.
Subjects were instructed to imagine that they were in a public
cafe and were asked to browse the web for 10 min. They
were told that everything they typed would be logged and so
were asked not to enter any sensitive information. Further,
they were asked not to read any long articles or watch videos,
as it would not provide much data for our study.
We designed our second experiment
to collect user
interaction data in a more controlled setting. Users were
asked to ﬁll out a small web form, which required users to
type, scroll, drag the mouse, click, and move the mouse; they
were asked to ﬁll this web form ﬁve times.
Our third experiment was designed to collect data to test
a malicious adversarial case. For this experiment, we asked
each subject to be a malicious adversary whose goal was to
mimic the victim user’s mouse-hand movements to the best
of their abilities. The victim user (one of the researchers)
ﬁlled out the same web form that the subjects used in
Experiment 2; thus, the subjects were already accustomed to
the task. We realize that a real adversary can be motivated
and skilled enough to mimic users very well, compared to
our subjects. So we decided to assist the subjects when they
were performing the role of a malicious adversary. To assist
them in mimicking the victim, we made sure they had a
good view of the screen and the victim’s hand movement,
we increased the cursor size, and the victim user gave verbal
clues before he began an action. For example, the victim
would say ‘typing’ before he began typing. He would say
‘2’ when he was going to ﬁll the question number 2 in the
web form. The victim tried to use the same pace to ﬁll out
the web form for all subjects, but reduced the pace for some
subjects when they were lagging too far behind. It should
be noted that this experiment was intended to be favorable
for the adversary.
Each subject performed, on average, about 192 Scrolling
interactions, 293 Typing interactions, and 146 MKKM
interactions in the three experiments. After these three
experiments, we asked each subject to walk for a few minutes
and to write on a paper, so we could collect data for walking
714
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:00:04 UTC from IEEE Xplore.  Restrictions apply. 
and writing activities, because these are common activities
for a user that steps away from the terminal. We use this
data to evaluate how quickly ZEBRA can deauthenticate a
user when she does one of these tasks while another user
attempts to use her terminal.
B. Data collection
In our user study, we collected two types of data about
subjects’ interaction with the terminal: i) inputs received by
the OS through keyboard and mouse, captured by a script
we wrote; and ii) the subject’s hand movement, captured by
a sensor worn by the subject on her dominant wrist.
We used iMacs for our subject study. Subjects used an
iMac with an Apple keyboard and Apple mouse with a
scroll ball. We wrote a Python script that uses Apple’s
Cocoa APIs for OS X and captures all keyboard and
mouse input events generated by the operating system when
the subject provides input using those input devices. The
captured input events were KeyDown, KeyUp, MouseMove,
ScrollWheel, LeftMouseDown, LeftMouseUp, and
LeftMouseDragged, which are generated when the sub-
ject presses and releases a key, moves the mouse, uses the
scroll-wheel, presses and releases the left mouse button (left
click), and drags the mouse, respectively.1 For each keypress
event the OS reports the time when it is pressed/released,
the key value, whether the subject is holding the key down,
and whether the subject is repeatedly pressing the key. For
mouse-related events, the OS reports the time the event was
generated, absolute coordinates of the mouse pointer on
the screen, pointer displacement (in pixels) since the last
mouse event, and scroll length (i.e., how much the subject
scrolled the wheel). We log all this information, but in the
current implementation of ZEBRA, we use only the time
of event, event type, key value for keypress events, scroll
duration, absolute mouse pointer coordinates, and mouse
pointer displacement.
We used a Shimmer [27] to capture the subjects’ hand
movements, by asking each subject to wear a Shimmer device
on the wrist of the hand they normally use to operate a mouse.
The Shimmer contains an accelerometer sensor, a gyroscope
sensor, and a Bluetooth radio. Once connected to the terminal
over Bluetooth, the Shimmer streams its accelerometer and
gyroscope readings to the terminal at 500 Hz, where they are
logged to a ﬁle. We calibrated all Shimmers’ accelerometers
and gyroscopes prior to their use.
C. Results
In this section we evaluate ZEBRA’s accuracy and how
quickly it deauthenticates users when an adversary starts
using their logged-in terminal.
1Although our implementation is for MacOS X, the same kinds of
information are available in Windows and Linux so our method should be
easily portable to other systems.
1) Accuracy: We use two metrics to evaluate the accuracy
of ZEBRA. The false-positive rate (FPR) is the fraction of
the testing data that is negative but misclassiﬁed as positive;
in ZEBRA the FPR is the fraction of all interactions where
an unauthorized user is authenticated as an authorized user.
Similarly, the false-negative rate (FNR) is the fraction of all
interactions where an authorized user is misclassiﬁed as an
unauthorized user.
A high FNR indicates that
the system classiﬁes an
authorized user incorrectly as an unauthorized user more
often. When this happens, the system takes protective action,
such as logging out the user or locking the terminal; both
actions will annoy the authorized user using the terminal. A
negative result indicates to the system that an unauthorized
individual is using the terminal and the system takes action,
such as logging out the user or locking the terminal. A false
negative is, as one might imagine, annoying to an authorized
user of the terminal. Thus, from the usability point of view
a low FNR is desirable. Figure 4 shows the average false-
negative rate across all subjects for different window sizes
and thresholds.
As described above, ZEBRA classiﬁes the terminal user as
the bracelet user by comparing the actual interaction sequence
and the interaction sequence inferred by the classiﬁer from
bracelet data. The comparison is performed over a given
window size. Thus, we compute an FNR as the fraction of
all windows where ZEBRA misclassiﬁed the authorized user
as an unauthorized user. Then each data point in the Figure 4
is the average of the FNR across all subjects for a given
window size and threshold value.
The threshold parameter indicates the fraction of interac-
tions in a window that should match for ZEBRA to consider
the user as the authorized user. Thus, the threshold value
indicates how strict ZEBRA is when correlating interactions,
and as expected the FNR is smaller for smaller threshold
values and it increases with threshold values. Window size is
the number of interactions matched at a time to authenticate
the user; a larger window size allows more interactions to
be matched, so the FNR drops as the window size increases.
ZEBRA performs best in terms of authenticating a user for
window sizes greater than 20; thus, the more interactions
a user provides while working on the terminal, the better
ZEBRA performs. In terms of threshold values ZEBRA
provides best FNR for 0.5 and 0.55, and reasonably well
for threshold value of 0.6. A low threshold value improves
usability but, as we show below, it reduces security, so we
need to choose the trade-off carefully.
For a given subject and adversary, the FPR is the fraction
of all windows where ZEBRA misclassiﬁed the adversary
as the subject (authorized user). We compute a FPR for
each subject as the average FPR across all adversaries; each
data point in the following FPR graphs is the average of
these FPR across all subjects. A high FPR indicates that we
falsely authenticate an unauthorized user as the logged-in
715
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:00:04 UTC from IEEE Xplore.  Restrictions apply. 
Figure 4: Average false-negative rate vs. window size for
different thresholds (0.5, 0.55, 0.6, 0.65 and 0.7). ZEBRA
performs best in continuously authenticating users for window
sizes larger than 20.
Figure 5: Average false-positive rate when the adversary is
accessing the terminal while the logged-in user is walking
nearby.
user, allowing him to access the logged-in user’s account,
which is undesirable. Thus, a low FPR is good from a security
point of view. Window size is the number of interactions
that ZEBRA is allowed to consider to issue the decision
whether the current user is the same as the logged-in user.
Thus, ideally we want a low FPR for a small window size.
Figures 5 and 6 show the average false-positive rate when
the adversary is using the terminal and the logged-in user is
walking and writing, respectively, near the terminal. (Note the
different y-axis scales.) As expected, the FPR is smaller for
the higher thresholds. The FPR is low and drops quickly with
respect to window size, when the user is walking compared
to when she is writing because the wrist movements while
walking are very different to wrist movements when a user
is using the terminal, whereas the wrist movements during
writing are somewhat similar to terminal use. Figure 5 shows
that the FPR is below 0.02 for thresholds 0.6 and above,
even for short window sizes. The FPR in the user-writing
case drops below 0.03 for threshold 0.6 for windows of size
15 or greater. Thus, ZEBRA performs reasonably well even
if the user is performing an activity that is somewhat similar
to working on a terminal in terms of hand movements.
In our third experiment, we imagine a malicious adversary:
the user is logged-in on a terminal A but steps aside to
work on a nearby terminal B, and the adversary starts using
terminal A while trying to mimic the user’s hand movements
and similar interactions. If the adversary succeeds in mim-
icking the user’s hand movements while providing similar
interactions to terminal A, then ZEBRA will misclassify
the adversary as the user and the adversary can continue
using the terminal. In our experiment we asked the subjects
to be the malicious adversary and try to mimic a user (a
researcher). Both the subject and researcher performed the
same tasks (ﬁlling web forms), and the researcher’s screen
Figure 6: Average false-positive rate when the adversary is
accessing the terminal while the logged-in user is writing
nearby.
and hands were clearly visible to the subject. Figure 7 shows
the false-positive rate for this case. The FPR rate drops below
0.04 for windows of size 15, and threshold 0.6 and above.
Thus, even when the adversary and the user were performing
the same task on nearby terminals, and the adversary was
trying to mimic the user’s actions, ZEBRA performed well
in recognizing the adversary. Thus, ZEBRA should be able
to recognize a change in user even in an environment where
the previous user is working on a nearby terminal when a
new user walks to the unlocked terminal to use it.
In Table III we show the mean and standard-deviation
of FNR and FPR for all subjects for threshold of 0.6 and
four window sizes. The high variability in FNR is because
of Subject 1, whose wrist movement during keyboard and
mouse interaction were very different compared to the other
subjects. To keep ZEBRA user-agnostic, for each subject we
train the classiﬁer using other subjects’ data, but if a subject’s
716
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:00:04 UTC from IEEE Xplore.  Restrictions apply. 
Figure 7: Average false-positive rate when the adversary is
trying to access the user’s logged-in terminal by mimicking
the user who is using a nearby terminal.
Figure 8: Fraction of authorized users that have access to
the terminal at time t, for optimal window size = 21 and
optimal threshold = 0.6.
interaction is very different than other subjects, the classiﬁer
cannot accurately classify that subject’s interactions, which
affects ZEBRA’s accuracy in verifying that subject. This can
be resolved by training the classiﬁer on a larger population
or training the classiﬁer for these speciﬁc subjects. If we
exclude Subject 1, we get low variability and even better
FNR, as shown in the last column (FNR3) in Table III.
From the FPR and FNR results we found the parameters
that give a reasonable tradeoff between usability and security
with ZEBRA are window size of 21 and threshold of 0.6.
For window size of 21, ZEBRA veriﬁes the user after every
21 interactions, which can take at most 21 s if the user is
providing inputs continuously, because each interaction is
at most 1 s long. However, in our experiment subjects took
about 6 s for 21 interactions. We use these optimal parameters
to evaluate quickness of ZEBRA in terms of the time ZEBRA
takes to recognize an unauthorized user.
Table III: Average FNR and FPR for different Window sizes
(W). Mean (and standard-deviation) of all subjects.
W
5
13
21
29
FNR
0.164 (0.155)
0.041 (0.077)
0.037 (0.096)
0.035 (0.094)
FPR1
0.016 (0.012)
0.007 (0.008)
0.001 (0.002)