tation is sufficient. Similarly, approaches to subject access requests
vary and there appears to be little support for improvements as the
main objective is legal compliance instead of fostering understand-
ing at the users’ end. While most participants think there is value
in transparency mechanisms, there still seems to be a mismatch
between user expectations and the understanding of personal data
in the industry that has not considered users’ data personal data for
so long and does not always seem aware of the actual data flows.
6 DISCUSSION AND RECOMMENDATIONS
The companies we surveyed reported that the number of users
asking for access is rather low. One factor for this is probably that
many consumers are not (yet) aware of these new opportunities,
granted by the online tools and new regulation. Still, some compa-
nies make it hard for users to learn who collects their data, so that
even those who know about the new tools or their rights might
have a hard time executing them. When getting access, users prefer
receiving inferred information (e. g., interest segments) rather than
technical data. In our user study, participants strongly expressed
their wish that the provided data should be “less technical” (P-43)
and in a “easy to read visualization” (P-324). But not all companies
can provide such information because it depends on the business
the company is doing. Furthermore, companies should provide both
high-level information that users can easily understand and the
underlying raw data so that users can use a tool to analyze the data
according to their own needs. The problems with privacy policies
have long been known, but still, it seems to be up to research to
develop better tools, as companies do not focus on understanding
but more on legal compliance. As I-5 stated:“I wrote something like
a hundred of privacy policies and all of them, I think, lack of trans-
parency. [...] I think that I can defend myself in front of an authority,
but I think a normal user, like a person that would read a policy, they
will not understand fully what is happening.”.
Over 60 % of the companies that participated in our survey ex-
pressed the wish for more regulatory guidance on the design of ac-
cess request processes. Our research suggests that consumers would
appreciate simplified and unified ways to obtain transparency.
Based on our results, we recommend providing a visual overview
(e. g., a workflow diagram) that describes what happens with the
collected data, where it comes from, and with whom it is shared.
Further research in this area is needed to evaluate designs. These
designs could be used as blueprints for companies when design-
ing/improving their SAR processes or their transparency guidelines
in general. An industry-wide standard would allow users to com-
pare two services regarding their privacy impact. Those that want
to be transparent about their practices should start by educating
users about what they do with personal data before collecting and
presenting it, first on a high level with the option of downloading
raw data. Previous research has underlined this need for informa-
tion literacy [6].
It is the public mistrust in the data sharing industry that fueled
harsher regulations. To counter misconceptions, companies need
to improve public understanding of their practices. It could help to
provide information on what is not done with collected data (e. g., a
company might not collect the users’ location but users might still
wonder why it is not shown). As we found that users struggle to
identify the companies that might collect personal data, it would
be helpful to add “Provided by X” information in every ad banner.
7 LIMITATIONS
In our transparency tool analysis, we analyzed the data provided by
22 ad companies—a subset of all advertisement related companies.
Our study focuses on rather big companies (in terms of presence
on websites), we did not analyze approaches of smaller companies.
Still, we were able to identify different transparency approaches
and our interviews with smaller companies do not hint that we
missed methodological different approaches. The analyzed profiles
do not include all data a company might collect (e. g., not all interest
segments or all demographic information) and hence our classifi-
cation might be false at some points. However, omitting the four
cases in which we were unsure would not fundamentally change
the overall results and findings.
Our user study is based on participants from the US only. We
decided not to recruit EU residents since we would have had to
provide the online questionnaire in various languages to avoid any
bias because users do not take the questionnaire in their native
language. Furthermore, we expect that US residents have similar
needs when it comes to transparency in online advertisements. Our
survey is based on a small subset of companies willing to participate
in our study and telephone interviews. Therefore, the views they
presented might not be fully representative of the industry as a
whole. Still, we identified a diverse set of opinions and hope that
future work can broaden the empirical basis of our results.
8 RELATED WORK
In the following, we discuss work closely related to ours and com-
pare prior work to our approach that was not already mentioned in
Section 3.1. Personal data is often conceptualized as an economic
asset of a company [2]. Business models are created based on the
collection and aggregation of personal data (e. g., [1, 20]) and also
malicious attempts to collect such data have been studied [53].
Subject Access Requests. The SAR process, introduced by the
GDPR, gives users the right to access their data collected by an
online service. Urban et al. measure the SAR process in detail and
show that the process is heterogeneous in terms of obstacles, tim-
ing, and success between different actors in the online advertising
economy and can get quite elaborate [52]. Boniface et al. analyze
the tension between authentication and security when users per-
form a SAR [7] and discuss measures used to identify users and
discuss threats (e. g., denial of access) of too harsh measures. Most
recently, two studies showed how subject access requests can be
misused to get access to personal data companies stored about
other individuals [10, 15]. Both works spoofed their identity and
filed a SAR using the spoofed identity and found that companies
sometime carelessly share data without verifying the users’ identity
carefully. Degeling et al. analyzed the adoption and effect of the
GDPR regarding privacy policies and cookie notices [14].
User Transparency Tools. Leon et al. [33] evaluate the usability of
several tools to limit OBA. The authors conduct a laboratory study
in which participants for example use tools to opt-out of OBA and
712show that all tools at the time had serious usability flaws which
lead to the misuse and misunderstanding of such tools. Andreou
et al. [4] presented an analysis of ad transparency tools provided
by Facebook. In their work, they analyze the messages presented by
the social media platform that explain why users see specific ads.
They find that these messages are often incomplete and misleading.
A web browser extension that gives users a more equitable choice
with regards to ad blocking was presented by Parra-Arnau et al. [40].
The extension gives users fine-grained control over the ads they
see and helps them understand how their browsing data is used. In
a study with 40 participants, the authors evaluate the performance
of their tool and show that re-targeting is the most common ad
strategy.
Melicher et al. investigates the users’ perspective on perceived
benefits and risks of online tracking by conducting 35 user inter-
views [38]. They find that users, on the one hand, want more control
over tracking but on the other hand, are unwilling to put effort into
actually taking control. Schaub et al. evaluate three different tools
that are used to block online tracking (e. g., Ghostery) regarding
their effectiveness to inform users that they are being tracked [44].
One result of their study is that the tools do not manage to in-
form users about tracking and some users believe that the analyzed
tools track them. Bashir et al. analyzed “ad preference managers”,
a special kind of transparency tool, that allows users to see and
edit the segments companies have inferred about them [5]. In a
user study, the authors analyze the correctness and compare the
composition of such tools. They found that only 27 % of partici-
pants state that shown interests are relevant for them. In this study,
Google, Facebook and Twitter provided such tools. Most recently,
Utz et al. analyzed user interactions with cookie banners [55]. They
found that current implementations of such banners often do not
allow for meaningful consent and that only very few users interact
with the banners.
9 CONCLUSION
The ad industry tries to provide more transparency about its prac-
tices and the data collected in different ways. We studied imple-
mentations of new transparency and data access possibilities in the
online advertising industry. By analyzing different transparency
approaches of ad-tech companies, we identified three conceptual
types of data companies provide users, if they ask for access: (1)
tracking data, (2) segment data, and (3) raw technical data. Our
research shows that not all companies disclose the necessary in-
formation and that many do it in a way that is not user-friendly.
The participants in our user study struggled to understand and
interpret the personal data they received after they had asked for
access, especially if confronted with low-level technical data. Most
users rated the provided data to be helpful (> 50 %) while “segment
data” was the most popular category. Furthermore, we found that a
large proportion of users (65 %) do not trust that companies provide
all collected data upon request. When it comes to the identification
of companies that provide an standard ad banner, we found that
only 24 % of users would correctly identify the ad network, while
46 % named the advertised products company as ad provider. We
surveyed data protection officers in different companies active in
the advertisement ecosystem to better understand their perspec-
tives. Participants reported that there were technical hurdles rooted
in the complexity of the ecosystem that make it hard to disclose
exact information. Most companies in the interviews and almost
half in the survey (42 %) stated that they receive less SARs than
expected and 63 % of participating companies expressed their wish
for more guidance when designing SAR processes. We also found
that companies still primarily focus on compliance instead of trans-
parency for users. Regulatory authorities and industry associations
therefore need to develop clear guidelines and consistent consumer
facing portals to improve the situation.
ACKNOWLEDGMENTS
This work was partially supported by the Ministry of Culture and
Science of the State of North Rhine-Westphalia (MKW grants 005-
1703-0021 “MEwM” and Research Training Group NERD.nrw). We
would like to thank the anonymous reviewers for their valuable
feedback, Christine Utz at Ruhr University Bochum for her efforts
proofreading this work, and Yana Koval also at Ruhr University
Bochum for transcribing the interviews. Furthermore, we would
like to thank all participants of our user and company study and
especially thank the interview partners for their valuable insights.
Any findings, conclusions, opinions, or recommendations stated in
this work are those of the authors and do not necessarily reflect the
views of the participants of the conducted interviews/user studies,
or the sponsors.
REFERENCES
[1] Gunes Acar, Christian Eubank, Steven Englehardt, Marc Juarez, Arvind
Narayanan, and Claudia Diaz. 2014. The Web Never Forgets: Persistent tracking
mechanisms in the wild. In Proceedings of the 21st ACM Conference on Computer
and Communications Security (CCS’14). ACM Press, New York, New York, USA,
674–689.
[2] Alessandro Acquisti, Curtis R. Taylor, and Liad Wagman. 2015. The Economics
[3] Amazon. 2018. Amazon’s Mechanical Turk. https://www.mturk.com/ Accessed:
of Privacy. Journal of Economic Literature 52 (2015), 64.
2019-02-05.
[4] Athanasios Andreou, Giridhari Venkatadri, Oana Goga, Krishna P. Gummadi,
Patrick Loiseau, and Alan Mislove. 2018. Investigating ad transparency mecha-
nisms in social media: A case study of Facebook’s explanations. In Proceedings
of the 2018 Symposium on Network and Distributed System Security (NDSS’18).
Internet Society, San Diego, CA, 15.
[5] Muhammad Ahmad Bashir, Umar Farooq, Maryam Shahid, Muhammad Fareed
Zaffar, and Christo Wilson. 2019. Quantity vs. Quality: Evaluating User Interest
Profiles Using Ad Preference Managers. In Proceedings of the 2019 Symposium on
Network and Distributed System Security (NDSS’19). Internet Society, San Diego,
CA, 15.
[6] Bettina Berendt. 2012. Data Mining for Information Literacy. In Data Mining:
Foundations and Intelligent Paradigms, Dawn E. Holmes and Lakhmi C. Jain (Eds.).
Springer-Verlag, Cham, 265–297.
[7] Coline Boniface, Imane Fouad, Nataliia Bielova, Cédric Lauradoux, and Cristiana
Santos. 2019. Security Analysis of Subject Access Request Procedures How to
authenticate data subjects safely when they request for their data. In Annual
Privacy Forum (APF’19). Springer-Verlag, Berlin, Heidelberg, 20.
[8] Virginia Braun and Victoria Clarke. 2012. Thematic analysis. In APA handbook
of research methods in psychology, Vol 2: Research designs: Quantitative, quali-
tative, neuropsychological, and biological. American Psychological Association,
Washington, DC, US, 57–71. https://doi.org/10.1037/13620-004
[9] Randolph E Bucklin and Catarina Sismeiro. 2003. A model of web site browsing
behavior estimated on clickstream data. Journal of marketing research 40, 3 (2003),
249–267.
[10] Matteo Cagnazzo, Thorsten Holz, and Norbert Pohlmann. 2019. GDPiRated–
Stealing Personal Information On- and Offine. In Proceedings of the 2019 European
Symposium on Research in Computer Security (ESORICS’19). Springer-Verlag,
Cham, 21.
[11] S. Chiasson, Y. Abdelaziz, and F. Chanchary. 2018. Privacy Concerns Amidst
OBA and the Need for Alternative Models. IEEE Internet Computing 22, 2 (2018),
71352–61.
[12] CNN Business. 2019. Amazon reportedly employs thousands of people to listen
to your Alexa conversations. https://edition.cnn.com/2019/04/11/tech/amazon-
alexa-listening/index.html Accessed: 2019-02-05.
[13] CONSENT project. 2017. CONSENT Report Summary. https://cordis.europa.eu/
result/rcn/140471_en.html Accessed: 2019-02-05.
[14] Martin Degeling, Christine Utz, Christoper Lentzsch, Henry Hosseini, Florian
Schaub, and Thorsten Holz. 2019. We Value Your Privacy ... Now Take Some
Cookies: Measuring the GDPR’s Impact on Web Privacy. In Proceedings of the
2019 Symposium on Network and Distributed System Security (NDSS’19). Internet
Society, San Diego, California, USA, 20.
[15] Mariano Di Martino, Pieter Robyns, Winnie Weyts, Peter Quax, Wim Lamotte
Lamotte, and Ken Andries. 2019. Personal Information Leakage by Abusing the
GDPR "Right of Access". In Proceedings of the 15th Symposium on Usable Privacy
and Security (SOUPS’19). ACM Press, New York, NY, 16.
https:
//digitaladvertisingalliance.org/principles Accessed: 2019-02-05.
[16] Digital Advertising Alliance. 2018. DAA Self-Regulatory Principles.
[17] Digital Advertising Alliance. 2018. Your Ad Choices. https://optout.aboutads.
info/?c=2&lang=EN Accessed: 2019-02-05.
[18] Claire Dolin, Ben Weinshel, Shawn Shan, Chang Min Hahn, Euirim Choi,
Michelle L. Mazurek, and Blase Ur. 2018. Unpacking Perceptions of Data-Driven
Inferences Underlying Online Targeting and Personalization. In Proceedings of
the 2018 Conference on Human Factors in Computing Systems (CHI’18). ACM Press,
New York, NY, USA, 1–12.
[19] eMarketer. 2017. Ad Blocking in the US: eMarketer’s Updated Estimates and
Forecast for 2014–2018. https://www.emarketer.com/Report/Ad-Blocking-US-
eMarketers-Updated-Estimates-Forecast-20142018/2002044 Accessed: 2019-02-
05.
[20] Steven Englehardt and Arvind Narayanan. 2016. Online tracking: A 1-million-
site measurement and analysis. In Proceedings of the 2016 ACM Conference on
Computer and Communications Security (CCS’16). ACM Press, New York, NY,
USA, 1388–1401.
IAB Europe Transparency & Consent Framework
http://www.iabeurope.eu/tcfdocuments/documents/legal/
[21] IAB Europe. 2018.
Policies.
currenttcfpolicyFINAL.pdf Accessed: 2019-02-05.
[22] European Interactive Digital Advertising Alliance. 2018. Your Online Choices.
http://www.youronlinechoices.com Accessed: 2019-02-05.
[23] Benjamin Fabian, Tatiana Ermakova, and Tino Lentz. 2017. Large-scale Read-
ability Analysis of Privacy Policies. In Proceedings of the 2017 Conference on Web
Intelligence (WI’17). ACM Press, New York, NY, USA, 18–25.
[24] Uwe Flick. 2014. The SAGE handbook of qualitative data analysis. Sage Publications
Ltd., Thousand Oaks, CA, USA.
[25] Samuel Grogan and Aleecia M. McDonald. 2016. Access Denied! Contrasting
Data Access in the United States and Ireland. Proceedings on Privacy Enhancing
Technologies 3, 23 (07 2016), 191–211.
[26] Mireille Hildebrandt. 2012. The Dawn of a Critical Transparency Right for the Pro-
filing Era. Digital Enlightenment Yearbook 1 (2012), 41–56. http://www.medra.org/
servlet/aliasResolver?alias=iospressISBN&isbn=978-1-61499-056-7&spage=41
[27] Inc. 2019. Google Is Absolutely Listening to Your Conversations, and It Confirms
Why People Don’t Trust Big Tech. https://www.inc.com/jason-aten/google-
is-absolutely-listening-to-your-conversations-it-just-confirms-why-people-
dont-trust-big-tech.html Accessed: 2019-02-05.
[28] Interactive Advertising Bureau. 2017.
Internet Advertising Revenue Re-
port. https://www.iab.com/wp-content/uploads/2018/05/IAB-2017-Full-Year-
Internet-Advertising-Revenue-Report.REV2_.pdf Accessed: 2019-08-27.
[29] Interactive Advertising Bureau Europe. 2017. European Digital Advertising mar-
ket has doubled in size in 5 years. https://www.iabeurope.eu/research-thought-
leadership/resources/iab-europe-report-adex-benchmark-2017-report/ Ac-
cessed: 2019-08-27.
[30] Musa J Jafar and Amjad Abdullat. 2009. Exploratory analysis of the readability
of information privacy statement of the primary social networks. Journal of
Business & Economics Research 7, 12 (2009), 123–142.
[31] Carlos Jensen and Colin Potts. 2004. Privacy Policies As Decision-making Tools:
An Evaluation of Online Privacy Notices. In Proceedings of the 2004 Conference on
Human Factors in Computing Systems (CHI’04). ACM Press, New York, NY, USA,
471–478.