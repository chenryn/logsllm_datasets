ﬁed/missing ﬁles.
4.2.2 Characteristics of the ILGs
The characteristics of the three groups are shown in Table
2. All average values shown in the table are “truncated aver-
age” values that exclude the top 20% and bottom 20% of the
results; truncated average [22] was used to accommodate for
the high variances we saw in the results. First, the average
number of ﬁles in the VAs is similar across the three ILGs,
averaging around 52,300. The average number of unveri-
ﬁed/missing ﬁles, on the other hand, is signiﬁcantly higher
in ILG C (1, 915) than in ILGs A (34) and B (172). That
was expected, as the ILGs are classiﬁed based on the per-
centage of unveriﬁed/missing ﬁles and the average number
of ﬁles across the three groups is the same.
Table 3 contains the number of software packages with
each integrity score as well as the proportion of unveri-
ﬁed/missing critical and non critical ﬁles, again showing the
truncated average values for the three ILGs. The table indi-
cates that the VAs in ILG C have a relatively larger number
of software packages with low integrity scores ( 2 and 1 ),
while most of the software packages installed on VAs in ILG
A have an integrity score of 3 . Note, score 2 represents a
partially clean or medium-integrity package and 1 a modi-
ﬁed or low-integrity package (see Section 3.2.2).
The total number of packages averages around 420 in all
three groups. About 99% of the software packages in the
44 VAs in ILG A are high-integrity, and the numbers are
not too diﬀerent for the 59 VAs in ILG B. Both groups
have a small number of low-integrity and medium integrity
packages. There is a big jump, however, as we reach ILG C,
236Table 2: Integrity Level Groups for VAs and their ﬁle characteristics
No. VAs
ILG A
ILG B
ILG C
44
59
48
Avg. % of unveriﬁed/missing ﬁles All ﬁles Unveriﬁed/missing Exe
Avg. # ﬁles
Avg. # unveriﬁed/missing ﬁle types
Img Comp Data
Src/web
0.06%
0.34%
3.67%
53,737
50,292
52,198
29
165
1,871
3
16
291
2
24
635
1
3
28
0
1
6
23
121
911
Table 3: Average number of software packages installed and average number of software packages to which the three
integrity scores have been assigned
Avg. # software
non critical ﬁles
critical ﬁles
Avg. # unveriﬁed/missing
Avg. % of unveriﬁed/missing
non critical ﬁles
critical ﬁles
ILG A
ILG B
ILG C
428
424
415
23
122
917
6
43
954
68%
71%
48%
18%
25%
50%
Avg. # integrity scores
3
426
416
346
2
1
2
20
1
0
1
45
Avg. time
37s
35s
36s
"
$
"
,
-
.
2
5
"
9
8
7
6
"
5
,
4
1
3
2
1
0
"
/
.
"
-
,
+
*
)
(
"
"
%
,
-
.
2
5
"
9
8
7
6
"
5
,
4
1
3
2
1
0
"
/
.
"
-
,
+
*
)
(
’!!"
&#!"
&!!"
%#!"
%!!"
$#!"
$!!"
#!"
!"
%#!"
%!!"
$#!"
$!!"
#!"
!"
!"
#!!"
$!!!"
$#!!"
%!!!"
%#!!"
&!!!"
&#!!"
()*+,-"./"):;,-7/7,"/7>,5"
!"
#!!"
$!!!"
$#!!"
%!!!"
%#!!"
&!!!"
&#!!"
’!!!"
()*+,-"./"):;,-7/7,"/7>,5"
(A)
(B)
Figure 5: (A) # unveriﬁed/missing critical ﬁles vs.
# score 1; (B) # unveriﬁed/missing non critical ﬁles
vs. # score 2
whose VAs have, on average, 45 low-integrity packages and
20 medium-integrity packages. Those are about 11% and
4.8% of the total number of packages, respectively. We note
this as our ﬁrst key ﬁnding.
Finding 1: across the VAs, there is high variance in
the number of unveriﬁed/missing ﬁles and the num-
ber of low-integrity and medium-integrity software
packages.
While the majority of the unveriﬁed/missing ﬁles belong
to what we deemed the non critical ﬁle category (data and
compressed ﬁles) for ILGs A and B (68% and 71%, re-
spectively), this proportion decreases signiﬁcantly in ILG
C (48%). In contrast, the proportion of unveriﬁed/missing
ﬁles that belong to what we deemed the critical ﬁle cate-
gory (executables, source/web ﬁles, image ﬁles) starts small
in ILG A (18%), but increases signiﬁcantly in ILG C (50%).
This can be explained by the huge jump in the number of
unveriﬁed/missing executables and src/web ﬁles from ILG
A to ILG C.
Graphs (A) and (B) in Figure 5 plot the number of un-
veriﬁed/missing critical ﬁles against the number of packages
with score 1 , and the number of unveriﬁed/missing non
critical ﬁles against the number of packages with score 2 ,
respectively.
Interestingly, in most VAs, both the unveri-
ﬁed/missing critical ﬁles and non critical ﬁles are concen-
trated in a small number of packages. The graphs indicate
that there is no strong correlation between the number of
unveriﬁed/missing ﬁles and the number of packages they in-
ﬂuence. Hence, the absolute number of unveriﬁed/missing
ﬁles does not give a good estimation of the number of par-
tially clean or modiﬁed packages. Our second key ﬁnding is
as follows.
Finding 2: The number of unveriﬁed/missing ﬁles
is not a good indicator of the number of medium-
integrity or low-integrity packages installed.
There are some VAs, however, for which the unveriﬁed or
missing ﬁles do spread out across a large number of pack-
ages, and these are the 12 or so outliers that we see in the
two graphs. These outliers seem to show some correlation
between the number of packages and the number of unveri-
ﬁed/missing ﬁles, and so we investigate these further in Sec-
tion 4.3.
4.2.3 Veriﬁcation time
Table 3 shows that the entire veriﬁcation process takes
about 36 seconds on average across all three groups. This is
how long publishers evaluating the conﬁguration of their VA
prior to publishing it will have to wait to see the results. The
performance overhead could be signiﬁcantly amortized by
using the Mirage image library [13], which uses the Mirage
Image Format [26] (see Appendix A).
4.3 VAs with large number of low-integrity pack-
ages
4.3.1 Classiﬁcation method
In this second part of the analysis, we further investi-
gate the outliers identiﬁed in Figure 5, which have notice-
ably larger number of partially clean and modiﬁed packages.
237Figure 6: VA clusters based on the percentage of the
software packages given each of the three integrity
scores; k-means clustering with k = 2 is used.
We do so by forming VA clusters based on the percentages
of packages given integrity scores 1 and 2 . The k-means
clustering method—an unsupervised learning algorithm—is
used to identify the clusters (k = 2). Figure 6 shows the
two distinct VA clusters: Cluster 1 represents VAs with low
percentages of packages given scores 1 and 2 , comprising
137 VAs; Cluster 2 represents VAs with high percentages of
packages given those two scores, consisting of 14 VAs.
4.3.2 Characteristics of the VA clusters
Table 4 summarizes the characteristics of the two VA clus-
ters, showing that the 14 VAs in Cluster 2 have signiﬁcantly
high percentage of packages with scores 1 and 2 ; the ab-
solute numbers are also very high, averaging 171 and 77 for
scores 1 and 2 , respectively. Only 43% of the packages are
cleanly installed (high-integrity). The percentage of the un-
veriﬁed/missing critical ﬁles is high too, averaging 73%. In
contrast, for the VAs in Cluster 1, 99% of the packages are
cleanly installed, and the percentage of unveriﬁed/missing
critical ﬁles averages only 22%. Considering that our sam-
ples are a representative set (see Section 4.1.2), here is our
third key ﬁnding:
Finding 3: About 9% of the VAs have a signiﬁ-
cant portion of low-integrity and medium-integrity
packages installed.
To cross-validate the results, we look at which ILGs the 14
VAs in Cluster 2 belong to: all belong to ILG C (the group
with the highest percentage of unveriﬁed/missing ﬁles), ex-
cept for one that belongs to ILG B. We took a closer look
at the 14 potentially untrusted VAs and the types of un-
veriﬁed ﬁles they contain. Most of the ﬁles are ones that
failed the rpm verify checks. A signiﬁcant portion of the
ﬁles are common system ﬁles like /bin/cut and /bin/grep
which rpm verify ﬂagged as not matching its database of
trusted hashes for the package versions that are supposed to
be installed. Although it is hard to say why those ﬁles ended
up being unveriﬁed (and this is out of the scope), our virus
scan results (see Section 5.2) show that 41 of those ﬁles are
potentially malicious, infecting 7 of the 14 VAs. The VAs
are from diﬀerent publishers, were built to support diﬀerent
functions, and do not share common base images. What is
most worrying about those 14 VAs is that none of them, in
their name or VA description, mention anything about soft-
ware customization or modiﬁcation eﬀorts. Just looking at
Figure 7: Percentage of the VAs used vs. percentage
of the whitelist coverage
the VA descriptions, they all appear to have only the cleanly
installed, standard packages.
Interestingly, we found a correlation between the number
of packages given score 1 and the number of packages given
score 2 (see Figure 8, Appendix B, Pearson’s: 0.65). This
implies that VAs with a high number of medium-integrity
packages, such as the VAs we see in Cluster 2, tend also to
have a high number of low-integrity packages.
4.4 Scalability evaluation: whitelist size
This section analyzes the size of the whitelist that we cre-
ated (including the rpm database used) to verify our sample
of 151 VAs and the 47 base images, showing how the size
changes as the number of VAs grows. Figure 7 plots the
percentage of the VAs used against the percentage of the
whitelist coverage (i.e., how much of the total whitelist was
created). To get the values, we randomly shuﬄed all the
VAs and incrementally generated the whitelist, adding the