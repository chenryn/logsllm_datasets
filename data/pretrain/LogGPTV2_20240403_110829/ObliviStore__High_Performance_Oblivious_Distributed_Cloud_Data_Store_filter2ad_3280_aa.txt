# Title: ObliviStore: High-Performance Oblivious Distributed Cloud Data Store

## Authors:
- Emil Stefanov (UC Berkeley)
- Elaine Shi (University of Maryland, College Park)

## Abstract
Access patterns to encrypted data can leak significant amounts of sensitive information. Oblivious RAM (ORAM) is a cryptographic construction that allows a client to access encrypted data on an untrusted storage server while completely hiding the access patterns. This paper introduces ObliviStore, an efficient ORAM-based cloud data store that secures both data and access patterns against adversaries in the malicious model. To our knowledge, ObliviStore is the fastest ORAM implementation built to date.

## 1. Introduction
It is well established that access patterns to encrypted data can leak a considerable amount of sensitive information [13]. Oblivious RAM (ORAM), originally proposed by Goldreich and Ostrovsky [8], is a cryptographic construction that allows a client to access encrypted data on an untrusted storage server while completely hiding the access patterns. Specifically, the sequence of physical addresses accessed is independent of the actual data being accessed. Existing ORAM constructions achieve this by continuously re-encrypting and reshuffling data blocks on the storage server, thereby concealing the logical access pattern.

In addition to storage outsourcing, ORAM, in combination with trusted hardware in the cloud, has been proposed to protect user privacy in a broad range of online services such as behavioral advertising, location and map services, and web search [4, 15].

While the idea of using trusted hardware and ORAM to enable access privacy in cloud services is promising, practical efficiency remains a key challenge. ORAM was initially studied as a theoretical concept, but recent works have demonstrated its potential for real-world applications [15, 25, 28, 29].

### 1.1 Our Contributions
We design and build ObliviStore, an efficient ORAM-based cloud data store that secures data and access patterns against adversaries in the malicious model. To the best of our knowledge, ObliviStore is the fastest ORAM implementation built to date.

- **Performance Evaluation**: In a single client/server setting with 7 rotational hard disk drives (HDDs), ObliviStore is an order of magnitude faster than the concurrent and independent work, PrivateFS, by Williams et al. [29]. We evaluate the performance of ObliviStore with both HDDs and solid-state drives (SSDs). With 11 trusted nodes (each with a modern CPU), we achieve a throughput of 31.5 MB/s with a block size of 4 KB.
  
- **Asynchronous ORAM Operations**: We propose novel techniques for making the SSS ORAM [25] asynchronous and parallel. We chose the SSS ORAM due to its bandwidth efficiency. Asynchronizing ORAM operations poses unique challenges, as we must prevent information leakage through timing and out-of-order processing of I/O events. We formally define the notion of oblivious scheduling and prove that our construction satisfies this requirement. Our ORAM scheduler relies on carefully placed semaphores, ensuring that operations on semaphores depend only on information observable by an adversary who is not aware of the data request sequence.

- **Distributed ORAM**: Typical cloud service providers use distributed storage backends. We show how to adapt our ORAM construction for a distributed setting. Naive methods of partitioning and distributing an ORAM can violate security. For example, even if each block is assigned to a random partition when written, accessing the same block twice in a row (read after write) can leak sensitive information. Our distributed ORAM construction applies the SSS partitioning framework [25] twice to achieve secure partitioning across multiple servers. We also propose a novel algorithm for securely scaling up a distributed ORAM at runtime without causing service interruption.

## 2. Experimental Results

### 2.1 Results with Rotational Hard Disk Drives
We conducted experiments with a single ORAM node equipped with an i7-930 2.8 GHz CPU and 7 WD1001FALS 1TB 7200 RPM HDDs with 12 ms random I/O latency [1]. To be comparable to PrivateFS, our experiments were performed over a network link simulated to have 50 ms latency, and we used the same block size, 4 KB, as PrivateFS.

- **Throughput and Response Time**: Figure 2 shows the throughput of our ORAM against the ORAM capacity. For a 1 TB ORAM, our throughput is about 364 KB/s. Figure 3 plots the response time for data requests with various ORAM capacities. For a 1 TB ORAM, our response time is about 196 ms. These measurements account for both online data retrieval and offline shuffling overhead under maximum load.

- **Comparison with Other Schemes**: In Figures 2 and 3, we also marked data points for PrivateFS and PD-ORAM for comparison. For a 1 TB ORAM, ObliviStore has about 18 times higher throughput than PrivateFS.

| Scheme | Block Size | ORAM Capacity | Processors | Private RAM Consumed | Response Time | Throughput |
|--------|------------|---------------|------------|-----------------------|---------------|-------------|
| Lorch et al. [15] | 10 KB | 320 TB | 10,000* | 300 GB | 360 ms | 28 KB/s |
| PrivateFS [29] | 4 KB | 100 MB | 1 | 2 GB | 191 ms | 15 KB/s |
| PD-ORAM [29] | 10 KB | 13 GB | 1 | 33 GB | 276 ms | 20 KB/s |
| ObliviStore | 4 KB | 1 TB | 1 | 36 GB | 196 ms | 364 KB/s |

*Note: Based on a combination of experimentation and theoretical projection. Due to the constrained computational power of IBM 4768 secure co-processors, the number of processors is projected.

Figure 1: Comparison with concurrent work.

Throughput means average total throughput measured after warming up the ORAM with O(N) accesses, unless otherwise indicated. The numbers for PrivateFS are based on personal communication with the authors [2, 29].