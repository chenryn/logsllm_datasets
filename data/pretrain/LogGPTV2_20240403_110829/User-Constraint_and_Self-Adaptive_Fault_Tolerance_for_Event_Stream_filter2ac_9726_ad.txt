2
6
8
10
12
14
16
18
20
Fig. 8: Fraction of time spent in each fault tolerance scheme with
varying recovery time thresholds for different cost models.
Passive Replication
Deployed
Passive Standby Cold
Passive Standby Hot
Active Standby
Active Replication
Gap Recovery
Precise Recovery (Exactly Ones)
100
)
%
h
c
a
e
n
i
t
n
e
p
s
e
m
T
i
(
e
m
e
h
c
s
e
c
n
a
r
e
o
l
t
t
l
u
a
f
80
60
40
20
0
Fig. 4: Throughput, state size and fault toler-
ance scheme evolution over time using Twit-
ter workload with a recovery threshold set to
5.5 seconds.
max
mean
min
4
6
2
Network Utilization
8
CPU Utilization
0
0
0
6
0
0
4
0
0
2
0
)
%
(
d
a
e
h
r
e
v
O
e
c
r
u
o
s
e
R
0
0
1
0
8
0
6
0
4
0
2
0
0
2
4
6
8
State Synchronization/Checkpointing Interval (s)
2
4
6
8
10
12
14
16
18
20
4
Recovery time (s)
2
6
8
10
12
14
16
18
20
Fig. 10: Trade-off between saved CPU and addi-
tional network trafﬁc for different state synchro-
nization and checkpoint intervals.
Fig. 9: Fraction of time spent in each fault tolerance scheme with
varying recovery time thresholds for different recovery semantics (gap
and precise recovery).
workload with regards to the evolution of event throughput
and state size. As mentioned previously, there is a correlation
between throughput and state size for time based sliding win-
dows where the state size follows the pattern of the throughput,
as shown in Figure 4. Since the throughput is quite low during
the ﬁrst 100 seconds (around 100 kEvents/s), the amount
of events being kept in the sliding window accumulates to
roughly 20 M B, while with the sudden increase in throughput
the state size quickly rises to 90 M B. In our experiment,
we set the recovery time to 5.5 seconds since application
criticality regards only user experience. However, we chose
precise recovery rather than gap recovery for two reasons: ﬁrst,
precise recovery provides repeatability, a very useful feature
for debugging distributed applications; second, because it is the
safest approach it is typically the one selected. Since the state
is quite small, we set the checkpoint and state synchronization
interval to a rather small value of 3.5 seconds. We did not
specify a cost weight vector, hence the default one is used
where the approach that consumes the least CPU, network,
memory and virtual machine resources is selected.
As shown in the beginning of the bottom plot in Figure 4,
the system starts with active replication, as it is the safe choice.
Once enough measurements have been collected, the controller
quickly switches to the deployed scheme as the state and the
throughput are quite low and, thus, recovery from disk and
replay from upstream nodes can be easily accomplished within
the state and upstream queues grow,
the user’s speciﬁed recovery time threshold. However, as spikes
occur which let
the
controller switches between passive replication and deployed
schemes. The cool down time of ﬁve seconds prevents the
system from oscillating due to sudden load spikes which
are common in workloads originating from live data sources
such as Twitter streams. In summary, the controller chose a
combination of passive replication and deployed during the
ﬁrst half of the experiment, whereas the second half was
dominated by passive hot standby.
C. Resource Overhead and Savings
For the next experiment, we were interested in the evolution
in the resource overhead for fault tolerance with an increasing
recovery time threshold. For this experiment and the following
ones, we used the Twitter workload and 10 nodes of our
infrastructure. We ran the experiment several times, each time
with a different value for the recovery time threshold. Similar
to the previous experiment, we used the default cost weight
vector. The results for the experiment are depicted in Figure 5.
The plot in Figure 5 shows the overhead for CPU, memory,
network (incoming and outgoing) and infrastructure utilization,
where the infrastructure utilization reﬂects the number of
virtual machines used. The resource utilization has been nor-
malized to the the execution of active replication. Hence, when
470470
CPU Utilization
● ● ● ● ● ●
● ● ● ● ●
● ●
● ● ● ● ● ● ●
Memory Utilization
● ● ● ● ● ● ●
● ● ● ●
●
●
● ● ● ● ● ● ●
Network Utilization (In)
●
● ●
● ● ●
● ● ● ● ● ●
●
● ● ● ● ● ●
Network Utilization (Out)
●
● ●
● ● ●
● ● ● ● ● ●
●
● ● ● ● ● ●
Infrastructure Utilization
●
●
● ● ● ● ● ● ● ● ● ● ●
●
● ●
● ●
● ● ● ●
)
%
(
d
a
e
h
r
e
v
O
e
c
r
u
o
s
e
R
100
75
50
25
0
100
75
50
25
0
300
200
100
0
300
200
100
0
100
75
50
25
0
)
%
(
d
a
e
h
r
e
v
O
e
c
r
u
o
s
e
R
100
75
50
25
0
100
75
50
25
0
100
75
50
25
0
100
75
50
25
0
100
75
50
25
0
CPU Utilization
● ● ● ● ● ● ● ● ● ● ●
●
●
● ● ● ● ● ● ●
Memory Utilization
● ● ● ● ● ● ● ● ● ● ●
●
●
● ● ● ● ● ● ●
Network Utilization (In)
● ● ● ● ● ● ● ● ● ● ●
●
●
● ● ● ● ● ● ●
Network Utilization (Out)
● ● ● ● ● ● ● ● ● ● ●
●
●
● ● ● ● ● ● ●
Infrastructure Utilization
● ● ● ● ● ● ● ● ● ● ●
● ●
●
●
● ● ● ● ●
CPU Utilization
●
●
●
Memory Utilization
●
●
●
●
●
●
●
Network Utilization (In)
●
●
●
●
●
Network Utilization (Out)
●
●
●
●
●
●
Infrastructure Utilization
●
●
●
●
20
15
10
5
20
15
10
5
20
15
10
5
20
15
10
5
20
15
10
5
i
)
s
(
s
g
n