ables.
Series from a random normal distribution generated
by a simple rule as
x(t)
i.i.d.∼ U (a, b),
where a, b are randomly determined.
Series from a random Gaussian distribution
i.i.d.∼ N (μ, σ
2
),
x(t)
Fig. 8. Examples of four types of synthetic time series
534534
where the mean μ and variance σ2 are randomly
generated.
Figure 8 illustrates examples of these four types of syn-
thetic time series. We generate 100 datasets for each type. For
every dataset, we simulate a KPI curve, as well as inject status
changes in some time series with respect to the KPI so that
those selected time series are treated as suspicious ones. The
KPI curve y(t) is a binary sequence with the value change at
a randomly generated position T0
y(t) = I(0 < t ≤ T0) − I(T0 < t ≤ T )
where I(·) is an indicator function. That is, the KPI value is
1 before the time T0 and changes to −1 after that.
TABLE II.
NUMBER OF GROUND TRUTHS FOUND BY EACH RANKER
SUMMED OVER 100 TRIALS (MAXIMUM IS 200)
Ranker
Reg. based
Tree based
Nonlinear
Fused
AR
182
173
176
182
Freq
152
134
110
140
Uniform
Gaussian
181
168
180
181
199
190
198
199
Given the KPI in each data set, we randomly select two
time series, xi(t) and xj(t), and manipulate their data to make
them as suspicious series. Suppose the values of those time
series are xi(t) = [xi(1),··· , xi(T0), xi(T0 + 1),··· , xi(T )]
and xj(t) = [xj(1),··· , xj(T0), xj(T0 + 1),··· , xj(T )]. We
exchange their samples after T0 and replace the old series with
new ones
xi(t) = [xi(1),··· , xi(T0), xj(T0 + 1),··· , xj(T )]
xj(t) = [xj(1),··· , xj(T0), xi(T0 + 1),··· , xi(T )]
After the switch, the two time series will encounter behavior
changes at time T0. Our method is expected to pinpoint those
two series to explain the quality changes.
In the experiments, we use features shown in Table I
and three rankers and their fused result introduced in Section
IV. Figure 9 shows examples of the synthetic abnormal time
series with their KPI and most important features found by
TABLE III.
NUMBER OF TIMES A FEATURE IS RANKED IN THE TOP 5
Features
org
mean
std
skew
kurt
qt05
qt95
Fmax
FmxLoc
PinBin0
PinBin1
PinBin2
PinBin3
PinBin4
PinBin5
PinBin6
PinBin7
PinBin8
ARp1
ARp2
ARp3
ARcons
ARaic
corr
AR
8
32
80
19
8
164
108
25
12
226
88
113
141
19
10
9
10
11
259
86
56
9
7
0
LIST
Freq
RUniform
RNormal
3
90
91
49
29
216
99
137
2
21
51
0
1
0
0
0
0
18
45
12
2
13
253
368
4
219
313
20
16
72
471
5
0
15
6
11
1
0
16
1
2
0
33
9
11
21
254
0
56
421
155
3
6
284
268
0
2
5
0
4
22
0
0
16
2
0
13
10
11
16
206
0
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:14:32 UTC from IEEE Xplore.  Restrictions apply. 
Fig. 9. Examples of KPI, original abnormal time series, and its most important feature for each type of synthetic dataset
the proposed method. It indicates that the selected feature
series change almost simultaneously with the KPI changes, and
thus they capture the characteristic dynamics of the sensors.
Moreover, to show more reliable results, we calculate how
many times the ground truths (exchanged time series) are
ranked to the top ﬁve suspicious attributes over 100 trials for
each synthetic type.
Table II summarizes the results. It shows that the fused
ranker and the regularization based ranker achieve good rank-
ing accuracy, and the fused ranker successfully aggregates
these three rankers.
Table III shows how many times a feature is ranked to
the top 5 importance. It shows that different time series have
different appropriate features to explain the KPI changes and
the original time series are no longer useful.
B. Real Dataset
We also examined the efﬁciency of the proposed method
by using data set from a real manufacture system. Due to
the privacy issue of real system data, we only illustrate the
results from seven sensors in the system, which are labeled as
‘I’,‘J’,‘K’,‘L’,‘M’,‘N’ and ‘O’. Each sensor records a system
status every minute. The KPI time series of this data set is
shown in Figure 10.
Each bump represents the execution process for each lot
and the KPI value shows the quality of products or whether
the process is working or not. For example, the products have
some anomalies if the corresponding KPI is 1, the products
are normal if the corresponding KPI is 0 and the process is
not active in the time region where the KPI is −1. We assign
the quality regions according to this KPI, i.e., regions where
KPI = 0 is assigned to good quality regions and vice versa.
Our goal is to ﬁnd sensors which are related to the KPI.
Table IV shows the ﬁnal result of the proposed method and
sensor ‘J’ is found as the most important relevant feature. In
practice, this is the key sensor according to a domain expert of
this plant. However, we cannot tell why this sensor is important
only by this result, so we look into the intermediate feature
ranking results of each rankers.
TABLE IV.
RESULT OF THE SENSOR RANKING
Rank
Sensor
1
2
3
J
L
I
Score
3.1587
1.1897
0.8146
Table V shows the results of the top features from each
ranker. The feature ‘kurt::J’ (kurtosis of sensor ‘J’) is discov-
ered as the most important feature from all rankers, which
has been conﬁrmed by system operators. Unfortunately our
TABLE V.
FEATURE RANKING FOR EACH RANKER
Fig. 10. KPI of a real manufacture plant
1
2
3
4
5
535535
Feature
kurt::J
(a) Regularization based
Score
1.0000
0.9860
0.9586
0.8000
0.3000
PinBin0::J
ARp1::L
qt05::I
PinBin1::K
(b) Tree based
Score
1.0000
0.2279e-1
0.6294e-2
0.2982-2
0.2804-2
Feature
kurt::J
skew::J
std::J
qt05::I
skew::K
(c) Nonlinear
Feature
kurt::J
skew::J
std::L
qt05::L
FmxLoc::L
Score
0.3434e-1
0.2076e-2
0.8785e-3
0.8297e-3
0.7446e-3
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:14:32 UTC from IEEE Xplore.  Restrictions apply. 
customer does not allow us to plot the curve of ‘kurt::J’. That
feature actually changes almost at the same time as the KPI.
Such synchronized changes indicate that the proposed method
can ﬁnd the most important time series and the most important
features that are related to the KPI of the real physical system
such as biochemical plant.
We have built a cloud service platform based on the
proposed quality control engine. Several customers are now
intensively using our service in the cloud. The engine has been
proved to improve the production quality of those customers.
For instance, for one customer, its proprietary revenue indicator
increased from 80% to 87% after changing system conﬁgura-
tions based on the output of our engine. We also received many
valuable feedbacks from customers. For example, in addition to
generating suspicious sensors, we are also asked by customers
to provide solutions to automatically tune to system parameters
to reach the optimum of production quality. Currently we are
working on this topic based on the output of quality control
engine.
VII. CONCLUSIONS
This paper has proposed a general framework to pinpoint
suspicious sensors that explain the output quality change
in physical systems. We have presented three main steps
in the framework, including extracting informative features
from time series, selecting and ranking feature series, and
the ranking score aggregation. Our method has successfully
captured various aspects of system dynamics as well as the
correlation between candidate time series and system output
quality. Experimental results have demonstrated that it can
correctly discover responsible sensors that contribute to the
related quality degradation. The implemented tool has served
as a promising engine for system debugging and quality
control.
REFERENCES
[1] A. Y. Ng, “Feature selection, L1 vs. L2 regularization, and rotational
invariance,” in Proceedings of the 21th international conference on
machine learning (ICML), 2004.
[2] L. Breiman, “Random forests,” Machine Learning, vol. 45, pp. 5–23,
2001.
I. Kononenko, E. ˇSimsec, and M. R.-ˇSikonja, “Overcoming the myopia
of inductive learning algorithms with RELIEFF,” Applied Intelligence,
vol. 7, pp. 39–55, 1997.
[3]
[4] S. Orfanidis, Introduction to Signal Processing. Prentice Hall, 1996.
[5]
J. D. Hamilton, Time series analysis. Princeton University Press, 1994.
[6] H. Akaike, “A new look at the statistical model identiﬁcation,” IEEE
Transactions on Automatic Control, vol. 19, pp. 716–723, 1974.
[7] R. Tibshirani, “Regression shrinkage and selection via the lasso,”
Journal of the Royal Statistical Society. Series B, vol. 58, pp. 267–288,
1996.
J. Liu, J. Chen, and J. Ye, “Large-scale sparse logistic regression,” in
Proceedings of the 15th ACM SIGKDD international conference on
Knowledge discovery and data mining (KDD), 2009, pp. 547–556.
[9] R. E. Schapire, “The strength of weak learnability,” Machine Learning,
[8]
vol. 5, pp. 197–227, 1990.
[10] T. M. Cover and J. A. Thomas, Elements of Information Theory. Wiley-
[11] V. N. Vapnik, The Nature of Statistical Learning Theory.
Interscience, 2006.
1995.
Springer,
536536
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:14:32 UTC from IEEE Xplore.  Restrictions apply.