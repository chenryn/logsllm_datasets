title:Information-flow types for homomorphic encryptions
author:C&apos;edric Fournet and
J&apos;er&apos;emy Planul and
Tamara Rezk
Information-Flow Types for Homomorphic Encryptions
Cédric Fournet
Microsoft Research
PI:EMAIL
Jérémy Planul
MSR–INRIA Joint Centre
PI:EMAIL
Tamara Rezk
INRIA Sophia Antipolis-Méditerranée
PI:EMAIL
ABSTRACT
We develop a ﬂexible information-ﬂow type system for a range of
encryption primitives, precisely reﬂecting their diverse functional
and security features. Our rules enable encryption, blinding, ho-
momorphic computation, and decryption, with selective key re-use
for different types of payloads.
We show that, under standard cryptographic assumptions, any
well-typed probabilistic program using encryptions is secure (that
is, computationally non-interferent) against active adversaries, both
for conﬁdentiality and integrity. We illustrate our approach using
ElGamal and Paillier encryption.
We present two applications of cryptographic veriﬁcation by typ-
ing: (1) private search on data streams; and (2) the bootstrapping
part of Gentry’s fully homomorphic encryption. We provide a pro-
totype typechecker for our system.
Categories and Subject Descriptors
K.6.m [Security and Protection]: Security; D.2.0 [Software En-
gineering]: Protection Mechanisms; F.3.1 [Specifying and Veri-
fying and Reasoning about Programs]: Speciﬁcation techniques.
General Terms
Security, Veriﬁcation, Design, Languages.
Keywords
Secure information ﬂow, cryptography, conﬁdentiality, integrity,
non-interference, type systems.
1.
INTRODUCTION
Information ﬂow security is a well-established, high-level frame-
work for reasoning about conﬁdentiality and integrity, with a clear
separation between security speciﬁcations and mechanisms. At
a lower level, encryption provides essential mechanisms for con-
ﬁdentiality, with a wide range of algorithms reﬂecting different
trade-offs between security, functionality, and efﬁciency. Thus, the
secure usage of adequate algorithms for a particular system is far
from trivial.
Even with plain encryption, the conﬁdentiality and integrity
of keys, plaintexts, and ciphertexts are interdependent: encryp-
tion with untrusted keys is clearly dangerous, and plaintexts should
never be more secret than their decryption keys.
Integrity also
matters: attackers may swap ciphertexts, and thus cause the de-
classiﬁcation of the wrong data after their successful decryption.
Conversely, to protect against chosen-ciphertext attacks, it may be
necessary to authenticate ciphertexts, even when plaintexts are un-
trusted.
Modern encryption schemes offer useful additional features,
such as the ability to blind ciphertexts, thereby hiding dependencies
between encrypted inputs and outputs, and more generally to com-
pute homomorphically on encrypted data, for instance by multiply-
ing ciphertexts instead of adding their plaintexts. These features
are naturally explained in terms of information ﬂows; they enable
computations at a lower level of conﬁdentiality—homomorphic op-
erations can be delegated to an “honest but curious” principal—but
they also exclude CCA2 security and require some care in the pres-
ence of active adversaries.
In this paper, we develop an information-ﬂow type system for
cryptography, with precise typing rules to reﬂect the diverse func-
tional and security features of encryption schemes. Our goal is to
understand them better, and to guide protocol designers and pro-
grammers. We rely on standard cryptographic assumptions, ex-
pressed as probabilistic polynomial-time indistinguishability games
—this level of detail is necessary to reliably capture the informa-
tion ﬂows of the underlying algorithms. Thus, our adversaries
are probabilistic polynomial-time programs, with limited read and
write access to data, that attempt to gain information about higher-
conﬁdentiality data, or to inﬂuence higher-integrity data, by inter-
acting with our programs. Our main theorem states that well typed
probabilistic polynomial programs using any combination of en-
cryptions, blinding, homomorphic functions, and decryptions are
such that our adversaries succeed only with a negligible probabil-
ity. Depending on the relative security levels of keys, plaintexts,
and ciphertexts, we propose different typing rules. Our rules are
sound with regards to standard cryptographic assumptions such as
CPA or CCA2; they enable the selective re-use of keys for protect-
ing different types of payloads, as well as blinding and homomor-
phic properties.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’11, October 17–21, 2011, Chicago, Illinois, USA.
Copyright 2011 ACM 978-1-4503-0948-6/11/10 ...$10.00.
Secure Distributed Computations Our work is part of a research
project on the synthesis and veriﬁcation of distributed cryptogra-
phic implementations of programs from a description of their infor-
mation ﬂow security requirements. Fournet et al. [10] present such
a security compiler that automatically generates code for encryp-
tion and authentication. As illustrated in our programming exam-
ples, an important motivation for a new type system is to justify its
efﬁcient use of cryptography. For instance, we strive to re-use the
same keys for protecting different types of data at different levels
of security, so that we can reduce the overall cost of cryptographic
protection. More generally, we would like to automatically gen-
erate well-typed code for performing blind computations, such as
those supported by the systems of Henecka et al. [14] and Katz and
Malka [15].
Formally, our work is based on the type system of Fournet and
Rezk [9], who introduce the notion of computational non-inter-
ference against active adversaries to express information ﬂow se-
curity in probabilistic polynomial-time cryptographic systems and
present a basic type system for encryption and authentication mech-
anisms. In comparison, their typing rules are much more restrictive,
and only support CCA2 public-key encryptions with a single pay-
load type.
Applications We illustrate our approach using programming ex-
amples based on classic encryption schemes with homomorphic
properties [8, 22]. We also develop two challenging applications of
our approach. Both applications rely on a security lattice with inter-
mediate levels, reﬂecting the structure of their homomorphic oper-
ations, and enabling us to prove conﬁdentiality properties, both for
honest-but-curious servers and for compromised servers controlled
by an active attacker.
• We program and typecheck a practical protocol for private
search on data streams proposed by Ostrovsky and Skeith III
[21], based on a Paillier encryption of the search query. This
illustrates that our types protect against both explicit and im-
plicit information ﬂows; for instance we crucially need to
apply some blinding operations to hide information about se-
cret loop indexes.
• We program and typecheck the bootstrapping part of Gen-
try’s fully homomorphic encryption [11]. Starting from the
properties of the bootstrappable algorithms given by Gentry–
being CPA and homomorphic for its own decryption and for
some basic operations—we obtain an homomorphic encryp-
tion scheme for an arbitrary function. This illustrates three
important features of our type system: the ability to encrypt
decryption keys (which is also important for typing key es-
tablishment protocols); the use of CPA encryption despite
some chosen-ciphertext attacks; and an interesting instance
of homomorphism where the homomorphic function is itself
a decryption.
This paper exclusively treats public-key encryptions. We believe
that their symmetric-key counterparts can be treated similarly. We
also refer to Fournet and Rezk [9] for cryptographic types for au-
thentication primitives, such as public-key signatures. This paper
omits many details and all proofs. The full paper, programming
examples, and a prototype typechecker for our system are available
online at msr-inria.inria.fr/projects/sec/cflow.
2. PROGRAMS, TYPES, AND POLICIES
We use an imperative probabilistic WHILE language with secu-
rity policies. A probabilistic semantics is necessary for modeling
encryption security [13]. Shared memory is sufﬁcient to model a
wide range of interactions between programs and adversaries; for
instance public untrusted variables model an open network.
Language The grammar for expressions and commands is
e
P
::= x | op(e1, . . . , en)
::= x := e | x1, . . . , xm := f (e1, . . . , en) |
P ; P | if e then P else P | while e do P | skip
ASSIGNS
[[e]](µ) = v
(cid:104)x := e, µ(cid:105) ;1 (cid:104)√
√
, µ{x (cid:55)→ v}(cid:105)
SEQS
(cid:104)P, µ(cid:105) ;p (cid:104)P1, µ1(cid:105)
P1 (cid:54)=
(cid:104)P ; P (cid:48), µ(cid:105) ;p (cid:104)P1; P (cid:48), µ1(cid:105)
SKIPS
(cid:104)skip, µ(cid:105) ;1 (cid:104)√
, µ(cid:105)
, µ1(cid:105)
SEQT(cid:104)P, µ(cid:105) ;p (cid:104)√
(cid:104)P ; P (cid:48), µ(cid:105) ;p (cid:104)P (cid:48), µ1(cid:105)
, µ(cid:105) ;1 (cid:104)√
(cid:104)√
STABLE
, µ(cid:105)
CONDTRUE
(cid:104)if e then P else P (cid:48), µ(cid:105) ;1 (cid:104)P, µ(cid:105)
[[e]](µ) (cid:54)= 0
CONDFALSE
(cid:104)if e then P else P (cid:48), µ(cid:105) ;1 (cid:104)P (cid:48), µ(cid:105)
[[e]](µ) = 0
WHILETRUE
(cid:104)while e do P, µ(cid:105) ;1 (cid:104)P ; while e do P, µ(cid:105)
[[e]](µ) (cid:54)= 0
WHILEFALSE
[[e]](µ) = 0
(cid:104)while e do P, µ(cid:105) ;1 (cid:104)√
, µ(cid:105)
FUN
p = [[f ]](µ(y1), . . . , µ(yn))((cid:126)v)
(cid:104)(cid:126)x := f (y1, . . . , yn), µ(cid:105) ;p (cid:104)√
p > 0
, µ{(cid:126)x (cid:55)→ (cid:126)v}(cid:105)
Figure 1: Probabilistic operational semantics
where op and f range over polynomial n-ary deterministic and
probabilistic functions respectively, with arity n ≥ 0.
Expressions e consist of variables and operations on data repre-
sented as bitstrings. We write op for nullary operations op(). We
assume given standard functions for boolean and arithmetic con-
stants (0, 1, . . . ) and operators (||, +, . . . ). We let =0 be compari-
son on booleans, true when both its arguments are either 0 or non-0.
We also have standard functions for pairs and functional arrays: we
use (cid:104)e0, e1(cid:105) and (e)i for constructing and projecting pairs, and use
e[ei] and update(x, e, ei) for reading and updating arrays.
Commands P consist of variable assignments, using determinis-
tic expressions and probabilistic functions (such as encryptions or
key generations) composed into sequences, conditionals, and loops.
We use syntactic sugar for arrays, writing x[ei] := e instead of
x := update(x, e, ei), and for loops, writing for x := e to e(cid:48) do P
instead of x := e; while x ≤ e(cid:48) do {P ; x := x + 1}.
Semantics Conﬁgurations (s) range over pairs of a command and
a memory, written (cid:104)P, µ(cid:105), plus inert conﬁgurations, written (cid:104)√
, µ(cid:105),
that represent termination with ﬁnal memory µ.
Probabilistic reductions between distributions of conﬁgurations
are based on a probabilistic transition relation ;p deﬁned in Fig-
(cid:80)
ure 1. We lift these reduction steps to conﬁguration distributions (d),
and write d ; d(cid:48) when, for all conﬁgurations s(cid:48), we have d(cid:48)(s(cid:48)) =
s;ps(cid:48) p × d(s). We denote by ρ∞((cid:104)P, µ(cid:105)) the ﬁnal distribution
of memories after running program P with initial memory µ. We
write Pr[(cid:104)P, µ(cid:105); ϕ] for the probability that P terminates with a ﬁnal
memory that meets condition ϕ.
Conﬁdentiality and Integrity We annotate variables, types, and
commands with security labels. These labels specify the program-
mer’s security intent, but they do not affect the behavior of pro-
grams. The security labels form a lattice (L,≤) obtained as the
product of two lattices, for conﬁdentiality (LC ,≤C ) and for in-
tegrity (LI ,≤I ). We write ⊥L and (cid:62)L for the smallest and largest
elements of L, and (cid:116) and (cid:117) for the least upper bound and greatest
lower bound of two labels, respectively. We write ⊥C, ⊥I, (cid:62)C,
and (cid:62)I for the smallest and largest elements of LC and LI, respec-
tively.
For a given label (cid:96) = ((cid:96)C , (cid:96)I ) of L, the conﬁdentiality label (cid:96)C
speciﬁes a read level for variables, while the integrity label (cid:96)I spec-
iﬁes a write level; the meaning of (cid:96) ≤ (cid:96)(cid:48) is that (cid:96)(cid:48) is at least as
conﬁdential (can be read by fewer entities) and at most as trusted
(can be written by more entities) than (cid:96) [20]. We let C((cid:96)) = (cid:96)C
and I((cid:96)) = (cid:96)I be the projections that yield the conﬁdentiality
and integrity parts of a label. We overload ≤C and ≤I, writing
(cid:96) ≤C (cid:96)(cid:48) for C((cid:96)) ≤C C((cid:96)(cid:48)) and (cid:96) ≤I (cid:96)(cid:48) for I((cid:96)) ≤I I((cid:96)(cid:48)).
Hence, the partial order on L is deﬁned as (cid:96) ≤ (cid:96)(cid:48) iff (cid:96) ≤C (cid:96)(cid:48) and
(cid:96) ≤I (cid:96)(cid:48). In examples, we often use a four-point lattice deﬁned by
LH < HH < HL and LH < LL < HL, where for instance LH
stands for low conﬁdentiality and high integrity.
Types for Information-Flow Security We use the following
grammar for security types:
τ ::= t((cid:96)) | τ ∗ τ | Array τ
t ::= Data
Security types
Payload Data types
| Enc τ Kq | Ke E K | Kd E K Encryption Data types
where (cid:96) ∈ L is a security label, E is a set of security types, K is
a key label, and q is an encryption index, as explained below. We
have pairs at the level of the security types to keep track of tuples
of values with different labels, e.g. for encrypting tuples.