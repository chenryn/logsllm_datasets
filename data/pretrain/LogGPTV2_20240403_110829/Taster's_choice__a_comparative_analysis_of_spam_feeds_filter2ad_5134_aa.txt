# Taster’s Choice: A Comparative Analysis of Spam Feeds

## Authors
- Andreas Pitsillidis<sup>∗</sup>
- Chris Kanich<sup>†</sup>
- Geoffrey M. Voelker<sup>∗</sup>
- Kirill Levchenko<sup>∗</sup>
- Stefan Savage<sup>∗</sup>

<sup>∗</sup>Department of Computer Science and Engineering, University of California, San Diego  
<sup>†</sup>Department of Computer Science, University of Illinois at Chicago

## Abstract
E-mail spam has been the subject of numerous measurement studies, largely due to the abundance of available data sources. However, there has been limited attention given to the suitability of these data sources for the types of analyses they are used in. Despite the wide range of data available, most studies rely on a single "spam feed," and little is known about how these feeds may differ in content. In this paper, we provide a comparative analysis of ten distinct contemporaneous spam feeds, focusing on the domain names advertised in spam messages. We document significant variations based on how such feeds are collected and show how these variations can lead to different findings.

## Categories and Subject Descriptors
- E.m [Data]: Miscellaneous
- H.3.5 [Information Storage and Retrieval]: On-line Information Services

## General Terms
- Measurement, Security

## Keywords
- Spam e-mail, Measurement, Domain blacklists

## 1. Introduction
In the measurement of Internet-scale phenomena, it is rare to make comprehensive observations. The research community often relies on available data, assuming it is sufficient to draw conclusions. However, some datasets may be too small or biased for certain purposes. This paper explores this issue in the context of e-mail spam.

E-mail spam is abundant, making it deceptively easy to gather. Industry estimates suggest that spammers sent over 100 billion e-mails daily in 2010. Even a corpus of 100,000 messages per day would represent only a tiny fraction of global spam. Therefore, researchers must extrapolate by many orders of magnitude, assuming their samples are unbiased and representative. To date, there has been no systematic examination of these assumptions and their relation to commonly used data sources.

To address these questions, we compare spam data from ten different feeds, both academic and commercial, using a variety of collection methods. We focus on the Internet domain names advertised in spam messages to identify like messages. Using a corpus of over a billion messages over three months, we characterize the relationships between the data sources. We explore four aspects of "feed quality": purity (the proportion of actual spam), coverage (the fraction of spam captured), timing (the ability to determine the start and end of spam campaigns), and proportionality (the accuracy of estimating the relative volume of different campaigns).

Our findings indicate significant differences across spam feeds, which can defy intuition. For example, our lowest-volume data source, with just over 10 million samples, captures more spam-advertised domain names than all other feeds combined, despite the other feeds containing two orders of magnitude more samples. These differences translate into analysis limitations, as not all feeds are suitable for all questions. In the remainder of this paper, we provide context, describe our data sources and analysis, and summarize best practices for future spam measurement studies.

## 2. Background
E-mail spam affects everyone, making it a widely studied phenomenon. Studies have focused on spam filtering, botnets, and the goals of spam, such as phishing, malware distribution, and advertising. These studies use a diverse range of data sources, including personal spam e-mail, static spam corpora, open mail proxies, botnet output, abandoned e-mail domains, and human-identified spam.

These data sources vary significantly in volume, with some collecting millions of spam messages daily while others gather far fewer. Intuitively, larger data feeds might provide better coverage, but this is not always the case. Differences in collection and reporting methods can also impact the type of spam found. For example, spam collected via MX honeypots (accepting all SMTP connections) will likely contain broadly targeted spam, while manually tagged e-mail may self-select for high-quality spam that evades filters.

Additionally, how data is reported can introduce limitations. Some providers include full e-mail contents, while others redact information or provide only spam-advertised URLs. Data can be reported in raw form or aggregated, with some providers de-duplicating domains within a time window.

These differences suggest that different data feeds may be more or less useful for answering specific questions. This paper aims to provide an empirical basis for this hypothesis.

## 3. Data and Methodology
In this study, we compare ten distinct spam data sources, ranging from full e-mail content to only domain names. Comparisons are limited to the lowest common denominator, namely domain names. We treat each feed as a source of spam-advertised domains, regardless of additional information.

By focusing on domain names, we restrict our analysis to spam containing URLs, which is the dominant class of spam today. Specifically, web-oriented advertising spam, such as pharmaceuticals, accounts for over 93% of total spam volume.

### 3.1. Domains
A registered domain, in this paper, is the part of a fully-qualified domain name that its owner registered with the registrar. For common top-level domains like .com, .biz, and .edu, this is the second-level domain (e.g., "ucsd.edu"). Blacklisting generally operates at the level of registered domains because spammers can create multiple subdomains to evade fine-grained blacklisting.

### 3.2. Types of Spam Domain Sources
The spam domain sources in this study fall into five categories: botnet-collected, MX honeypots, seeded honey accounts, human-identified, and blacklists. Each category has unique characteristics, limitations, and trade-offs.

- **Botnet:** Botnet datasets result from capturing and executing bot software in a controlled environment. These datasets are highly pure, with no false positives under normal circumstances. They are also accessible, as researchers can run malware to obtain large amounts of spam. Since a few botnets generate most spam, these datasets should be ideal for spam studies.
- **MX Honeypot:** MX honeypot spam is collected by configuring the MX record for a domain to accept all inbound messages. New domains capture spam from brute-force address lists, while older or abandoned domains may attract a broader set of e-mail.

In the following sections, we will provide a detailed analysis of these data sources and their implications for spam measurement.