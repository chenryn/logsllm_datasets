hmin≤h≤hmax
cov({DJS(Pi(cid:5)Pj) | 1 ≤ i  αR,
we raise an R-type alert (R-type detection); if |H(T )− E(HB)| > αH, we raise
an H-type alert (H-type detection). The rationale behind it is simple: if the
mean observed from the test sequence deviates from the mean observed from
the training trace by a predeﬁned threshold, we deem it as anomalous.
Then, an important question is how to choose thresholds αR and αH. A too
large threshold may miss many anomalous behaviors but a too low threshold
may raise too many false alerts. We do this based on the Chebyshev’s inequality:
P{|R(T ) − E(RB)| > αR} ≤ var(RB)
.
(4)
α2
R
(cid:4)
(cid:4)
Let βR be the upper bound on the expected false alarm rate for R-type alerts. In
var(RB)/βR,
practice, βR is a conﬁgurable input parameter. By having αR =
we ensure that the expected false alarm rate of R-type alerts does not exceed
var(HB)/βH, where βH gives the upper bound
βR. Similarly, choosing αH =
on the expected false alarm rate for H-type alerts, renders the expected false
alarm rate of H-type alerts no greater than βH.
From an implementation point of view, the mean-based anomaly detection
scheme imposes trivial computational overhead. For each SMS user, it only re-
quires only four states for anomaly detection: E(RB), E(HB), αR, and αH. The
parameters can be derived from the training trace in an oﬄine fashion, but their
values can be stored in the memory (instead of on disk), thereby relieving the
online anomaly detection from intensive disk access operations.
Similarity-based anomaly detection. We now explore how to exploit
similarity-based metrics for anomaly detection. A naive implementation can be
the following: we compute a similarity metric (recipient similarity metric or JS-
divergence) between the test sequence T and each block in the history trace
and check whether its mean signiﬁcantly deviates from the mean similarity met-
ric only between the blocks in the history trace. Although straightforward, this
scheme demands knowledge of the whole history trace when performing online
anomaly detection, thereby rendering it hardly practical due to its prohibitive
computational cost.
Due to such performance concern, we propose a light-weight anomaly detec-
tion scheme as follows. First, instead of comparing the test sequence T against
each block in the history trace, we condense information in the history trace into
a set of recipients and a distributional function. Furthermore, we do not consider
the entire set of recipients that have been witnessed in the history trace, but in-
stead focus on the top few recipients that have received the most messages from
the SMS user. Such simpliﬁcation is justiﬁed by the previous results showing
that the similarity metrics bear low variation even if only the top few recipients
are considered within each message block.
Suppose that we only consider the top φ recipients. Let Gφ(X) denote the
set of the top φ recipients that receive the most messages within sequence X,
and Qφ(X) the normalized distribution of the number of short messages sent
SMS-Watchdog: Proﬁling Social Behaviors of SMS Users
217
(cid:4)
(cid:4)
to the top φ recipients within sequence X. The similarity-based anomaly detec-
tion scheme checks how signiﬁcantly S(Gφ(T ),Gφ(V)) and DJS(Qφ(T )(cid:5)Qφ(V))
deviate from the means that have been observed from the history trace.
Recall that {B1,B2, ...,Bl} is the set of blocks after dividing sequence V by
every h∗ messages. To compute the means, we ﬁrst deﬁne V\Bi, where 1 ≤ i ≤ l,
as the sequence after block Bi is removed from V. We then let E(Sφ) and var(Sφ)
be the mean and variance of elements in set {S(Gφ(Bi),Gφ(V \ Bi)) : 1 ≤ i ≤
l}. Similarly, we use E(Dφ) and var(Dφ) to denote the mean and variance of
elements in set {DJS(Qφ(Bi)(cid:5)Qφ(V \ Bi)) : 1 ≤ i ≤ l}. Given V and h∗, we can
easily calculate E(Sφ), var(Sφ), E(Dφ) and var(Dφ).
Similarity-based anomaly detection on test sequence T works as follows: if
|S(Gφ(T ),Gφ(V)) − E(Sφ)| > αS, we raise an S-type alert (S-type detection);
if |DJS(Qφ(T )(cid:5)Qφ(V))− E(Dφ)| > αD, we raise a D-type alert (D-type detec-
tion). Using the Chebyshev’s inequality, we can determine parameters αS and
αD as follows: αS =
var(Dφ)/βD, where βS and βD
are the upper bounds on the expected false alarm rates for S-type and D-type
alerts, respectively. Both βS and βD are input parameters in practice.
var(Sφ)/βS and αD =
From the implementation perspective, the similarity-based anomaly detec-
tion schemes do not impose high computational cost. For each SMS user, we can
compute the four variables E(Sφ), var(Sφ), E(Dφ) and var(Dφ) based on her
history trace V in an oﬄine fashion. We then calculate αS and αD accordingly.
When we perform online anomaly detection, we need to know not only E(Sφ),
E(Dφ), αS and αD, but also Gφ(V) and Qφ(V). Clearly, the sizes of Gφ(V) and
Qφ(V) depend on φ. In total, the S-type detection requires at most φ + 2 states
and the D-type detection requires at most 2φ + 2 states. Since φ is usually
much smaller than the size of the set of unique recipients shown in history trace
V, the computational cost of our proposed scheme improves signiﬁcantly com-
pared to the aforementioned naive similarity-based scheme that demands the full
knowledge of the whole history trace. Our experiments later show that φ = 5 is
suﬃcient to achieve high detection accuracy. In that case, even for the D-type
detection scheme, only 12 states are needed.
6 Experimental Evaluation
Setup. In this section, we shall evaluate the performance of our proposed de-
tection schemes. For this, we use the same data trace discussed in Section 3. As
our detection schemes require some training data to derive a few parameters, we
consider only those SMS users that have sent out at least 200 short messages.
In total, there are 167 such users. Here note that the discarded user data are
not relevant because of the limited SMS traﬃc they produce and are thus not
a concern. We also use 70% of each SMS user’s short messages for training and
the remaining 30% for testing. Suppose that the number of training short mes-
sages is n. We let hmin be 10 and hmax be min{30,(cid:7)n/10(cid:8)} in Equation (4).
We believe that bounding h between 10 and 30 provides a good balance between
detection accuracy and latency. Further, we also bound h from the upper side by
218
G. Yan, S. Eidenbenz, and E. Galli
(cid:7)n/10(cid:8) to ensure that there are at least 10 elements for variance computation; if
we have enough training data, such a constraint can be relieved. We also have:
βR = βH = βS = βD = β, and vary β between 0.05 and 0.1.
False positive rates. The false positive rates of the four detection schemes are
shown in the following table:
Scheme
β = 0.05 β = 0.1
R-type detection 1.0% 2.2%
H-type detection 0.8% 2.7%
S-type detection
0.0% 5.4%
D-type detection 0.0% 4.3%
From the above table, we observe that the false positive rates of all four
detections are very low. The eﬀect of β on the false positive rates is also obvious:
a higher β leads to a higher false positive rate, irrespective of the type of alerts
considered. This is because a higher β lowers threshold αR in Equation (4) (or
αH, αS, and αD in the other three cases).
Detection rates of blending attacks. In our experiments, we consider every
pair of SMS users in which one is the victim and the other is the attacker.
Suppose that SMS user a is the victim and b is the attacker. We ﬁrst identify
the timestamp of the last message in user a’s training dataset; we further get
the list of messages that are sent by user b that are sent after that timestamp
in the trace. For brevity, we call this list an attack list. Since it is possible that
the attack list may not have enough messages, e.g., because user b quit from
system before data collection terminated, we only consider those cases that have
at least 4h∗
a is the detection window size
for user a. Messages on the attack list are then merged with those in user a’s
test dataset, with their timestamp ordering unchanged as in the original trace.
Among all pairs of SMS users considered, we compute the fraction of cases
in which the blending attack is successfully detected by each scheme, and the
average detection delay in the number of detection windows if the attack is
indeed detected. The results are as follows:
a messages on the attack list, where h∗
Scheme
β = 0.1
β = 0.05
Rate Delay Rate Delay
R-type 35.6% 3.9 55.6% 4.2
H-type 40.5% 1.8 62.3% 2.8
S-type 44.1% 1.0 71.6% 1.0
D-type 65.1% 1.0 81.7% 1.0
Three observations can made from the above table. First, similarity-based
schemes can detect blending attacks with higher rates and smaller detection
delays than mean-based schemes. This is because similarity-based schemes en-
code more information in the detection metrics. Second, both H-type detection
SMS-Watchdog: Proﬁling Social Behaviors of SMS Users
219
and D-type detection consider not only the set of unique recipients, but also
the distribution of the number of short messages sent to each recipients. Hence,
they perform better than both the R-type and S-type detection schemes. Third,
a higher β leads to a higher detection threshold, thereby improving both the
detection rate and the detection delay, irrespective of the detection scheme.
Detection rates of broadcast attacks. In the experiments, we intermingle
the test dataset of each SMS user with malicious messages sent to recipients that
are randomly chosen from those observed in the training dataset. For each SMS
user, exactly γ malicious messages are sent out at 12:00PM every day. We call
γ the broadcast threshold, which is varied among 10, 20, 30, and 40.
The detection ratios are depicted in Figure 13. Unsurprisingly, detection ra-
tios when β = 0.1 are higher than those when β = 0.05. We note, however,
that the relative ranks of the four schemes diﬀer signiﬁcantly from the detec-
tion results for blending attacks. Detection based on recipient similarity metric
(i.e., S-type detection) performs the worst but detection simply based on the
number of unique recipients (i.e., R-type detection) performs quite well. Recall
that R-type detection for blending attacks is not as eﬀective as the other three
schemes. Such diﬀerence actually attributes to the type of attacks we are con-
sidering. For broadcasting attacks, as recipients of illegitimate short messages
are actually drawn from those recipients of those legitimate short messages, the
change on the recipient similarity metric under broadcasting attacks is limited.
Broadcast attacks, however, generate a large number of messages with diﬀerent
recipients, thereby exposing themselves to the R-type detection scheme which
simply monitors the change on the number of unique recipients within each de-
tection window. On the other hand, Figure 13 reveals that D-type detection is
still eﬀective against broadcast attacks. This is because although broadcast at-
tacks mimic the set of recipients that have been observed in the training dataset,
the distribution of the number of messages sent to each recipient is still diﬀerent
from that in the training dataset.
o
i
t
a
r
n
o
i
t
c
e
e
D
t
 1.2
 1
 0.8
 0.6
 0.4
 0.2
R-type
H-type
S-type
D-type
 5  10  15  20  25  30  35  40  45
Broadcast threshold
(1) β = 0.05
o
i
t
a
r
n
o
i
t
c
e
e
D
t
 1
 0.8
 0.6
 0.4
 0.2
 0
R-type
H-type
S-type
D-type
 5  10  15  20  25  30  35  40  45
Broadcast threshold
(2) β = 0.1
Fig. 13. Detection ratio of broadcast attacks
220
G. Yan, S. Eidenbenz, and E. Galli
The average detection delay in the number of detection windows are given in
the following table:
β R-type H-type S-type D-type
0.05
0.1
4.0
3.2
3.7
3.0
6.8
5.5
4.1
3.2
Recall that on average similarity-based schemes detect blending attacks within
a single detection window (if the detection is successful). For broadcast attacks,
however, detection delays are higher because illegitimate short messages are sent
at the same time in a day in our experiments and the detector thus has to wait
for that moment to catch these attacks.
Hybrid detection. We now explore the detection solution space further by
combining multiple detection schemes together. Due to space limitation, we con-
sider only two hybrid detection schemes: In the ﬁrst one (R/H/S/D), if any
type of alert is ﬂagged, we treat it as anomalous; otherwise, we treat it as nor-
mal; in the second one (S/D), if an S- or D-type of alert is ﬂagged, we treat
it as anomalous; otherwise, we treat it as normal. The following table provides
the performance of these two schemes (DRblending and DRbroadcast denote the
detection ratio of blending and broadcast attacks, respectively):
R/H/S/D
S/D
DRblending
False alarm rate
β = 0.05 β = 0.1 β = 0.05 β = 0.1
1.3% 8.5%
0.0% 5.0%
85.7% 96.2% 69.1% 83.4%
DRbroadcast (γ = 10) 78.3% 94.0% 65.7% 82.5%
DRbroadcast (γ = 20) 82.5% 92.8% 68.1% 80.7%
DRbroadcast (γ = 30) 83.7% 93.4% 69.3% 81.9%
DRbroadcast (γ = 40) 83.1% 93.4% 69.3% 81.9%
We note that the R/H/S/D scheme with β = 0.1 can catch blending and
broadcast attacks with detection ratios higher than 90% but at the expense of
a relatively high false positive rate, which is about 8.5%; when β = 0.05, the
false alarm rate is only 1.3% but its detection ratios of blending and broad-
cast attacks fall between 78% and 86%. The S/D scheme, although not able to
detect as many attacks as the R/H/S/D scheme with the same β, does not
generate any false alarm when β = 0.05, and still catches about two thirds of
the attacks.
There is a clear tradeoﬀ between high detection rates and low false alarm
rates. In practice, the decision on which parameterized detection scheme to use
can be made based on the user’s preference on this tradeoﬀ, which is also af-
fected by the frequency at which she needs to deal with a false alarm. Here, we
provide simple analysis on the average interval between two false alarms. Sup-
pose that each detection window contains h short messages and the false alarm
rate is p. By modeling false alerts as a Bernoulli process, the average number
of windows before a false alarm is raised is 1/p. Hence, the average number of
SMS-Watchdog: Proﬁling Social Behaviors of SMS Users
221
messages between two false alarms is h/p. Consider the case with h = 20 and
p = 8%. Note that we are considering a relatively high false alarm rate. Then,
about every 250 short messages leads to a false alarm. In our trace, we observe
that a persistent user sends 1.5 messages per day on average, suggesting that a
normal SMS user needs more than 5 months on average to receive a false alarm.
Even if we consider the largest average daily number of short messages sent by
an SMS user in our trace, which is about 25, a false alarm is raised every 10
days.
7 Conclusions and Future Work
The goal of this work is to detect anomalous SMS behaviors. From an SMS trace
that was collected within a ﬁve-month period, we observe that there are window-
based regularities inherent in behaviors of typical SMS users. Accordingly, we
develop SMS-Watchdog, a light-weight detection scheme that relies on normal
social behavior proﬁles built for each SMS user. Experimental results show that
our detection approach can detect more than 92% of SMS-based attacks with
false alarm rate 8.5%, or about two thirds of the attacks without any false alarm.
Admittedly, SMS-Watchdog is not panacea for all SMS-related attacks. For
instance, SMS-Watchdog is not able to detect SMS faking attacks, as such at-
tacks simulate the behavior of SMS switches (i.e., SMSC in Figure 1) and the
illegitimate SMS messages do not go through the SMSC of the originating ter-
minal, where the SMS-Watchdog is deployed. Moreover, with the integration of
the telecommunication network and the Internet, many SMS messages are now
sent from the Internet. SMS accounts can be easily created through the Inter-
net and then used to send spamming or phishing SMS messages. Given the fact
that SMS-Watchdog requires a training process to build a behavioral proﬁle for
each SMS user, it is diﬃcult for SMS-Watchdog to identify those transient SMS
accounts that are used only for spamming or phishing purposes.
Moreover, as SMS-Watchdog detects abnormal SMS activities by monitoring
deviations from behavioral proﬁles trained under normal circumstances, it is
possible that some malware can intelligently evade its detection. For example, a
stealthy malware can learn the behavior of an SMS user from her recent SMS
communication history and then send spamming or phishing SMS messages in a
similar fashion. Also, the design of SMS-Watchdog takes the variation of a typical
SMS user’s regular behavior into consideration to avoid high false positive rates.
Accordingly, a stealthy malware can exploit this to evade its detection by limiting
the number of illegitimate SMS messages sent within each detection window.
With the lesson learned from the increasing sophistication of cyber-attacks
in the Internet, we do not claim that SMS-Watchdog can address all existing
or future SMS-related attacks. While we will continuously improve the eﬀec-
tiveness of SMS-Watchdog against these attacks, we also plan to explore other
complementary approaches to protect this increasingly popular service.
222
G. Yan, S. Eidenbenz, and E. Galli
References
1. Bose, A., Hu, X., Shin, K.G., Park, T.: Behavioral detection of malware on mobile
handsets. In: Proceedings of MobiSys 2008 (2008)
2. Chandola, V., Banerjee, A., Kumar, V.: Anomaly detection: A survey. ACM Com-
puting Survey (September 2009) (to appear)
3. Cover, T., Thomas, J.: Elements of Information Theory. John Wiley, Chichester
(1991)
4. http://www.redherring.com/Home/19081
5. Davis, A.B., Goyal, S.K.: Knowledge-based management of cellular clone fraud. In:
Proceedings of IEEE PIMRC 1992, Boston, MA, USA (1992)
6. Enck, W., Traynor, P., McDaniel, P., Porta, T.L.: Exploiting open functionality in
SMS-capable cellular networks. In: Proceedings of CCS 2005 (2005)
7. Fawcett, T., Provost, F.: Activity monitoring: noticing interesting changes in be-
havior. In: Proceedings of ACM KDD 1999 (1999)
8. Hu, G., Venugopal, D.: A malware signature extraction and detection method
applied to mobile networks. In: Proceedings of IPCCC 2007 (April 2007)
9. Kim, H., Smith, J., Shin, K.G.: Detecting energy-greedy anomalies and mobile
malware variants. In: Proceedings of MobiSys (2008)
10. Lee, L.: Measures of distributional similarity. In: Proceedings of the 37th Annual
Meeting of the ACL (1999)
11. Lee, W., Xiang, D.: Information-theoretic measures for anomaly detection. In: Pro-
ceedings of IEEE S&P (2001)
12. Lin, Y., Chlamtac, I.: Wireless and Mobile Network Architectures. John Wiley &
Sons, Inc., Chichester (2001)
13. Meng, X., Zerfos, P., Samanta, V., Wong, S.H.Y., Lu, S.: Analysis of the reliability
of a nationwide short message service. In: Proceedings of INFOCOM 2007 (2007)
14. Noble, C.C., Cook, D.J.: Graph-based anomaly detection. In: KDD 2003: Proceed-
ings of the ninth ACM SIGKDD international conference on Knowledge discovery
and data mining (2003)
15. http://www.vnunet.com/vnunet/news/2163586/sms-phishing-attack-
seen-wild
16. http://www.kval.com/news/local/17945949.html
17. http://www.mobilemarketer.com/cms/opinion/columns/1610.html
18. http://www.textually.org/textually/archives/2007/12/018482.htm
19. http://www.openmindnetworks.com/SMSSpoofing.asp
20. Stolfo, S.J., Hershkop, S., Hu, C., Li, W., Nimeskern, O., Wang, K.: Behavior-based
modeling and its application to email analysis. ACM Transactions on Internet
Technology 6(2), 187–221 (2006)
21. Sun, B., Yu, F., Wu, K., Xiao, Y., Leung, V.C.M.: Enhancing security using
mobility-based anomaly detection in cellular mobile networks. IEEE Trans. on
Vehicular Technology 55(3) (2006)
22. http://searchcio-midmarket.techtarget.com/tip/0,289483,sid183
gci1310706,00.html
23. Taniguchi, M., Haft, M., Hollmn, J., Tresp, V.: Fraud detection in communications
networks using neural and probabilistic methods. In: Proceedings of the 1998 IEEE
International Conference in Acoustics, Speech and Signal Processing (1998)
24. Traynor, P., Enck, W., McDaniel, P., Porta, T.L.: Mitigating attacks on open
functionality in SMS-capable cellular networks. In: Proceedings of MobiCom 2006
(2006)
SMS-Watchdog: Proﬁling Social Behaviors of SMS Users
223
25. Yan, G., Eidenbenz, S., Sun, B.: Mobi-watchdog: you can steal, but you can’t run!
In: Proceedings of ACM WiSec 2009, Zurich, Switzerland (2009)
26. Yan, G., Xiao, Z., Eidenbenz, S.: Catching instant messaging worms with change-
point detection techniques. In: LEET 2008: Proceedings of the 1st Usenix
Workshop on Large-Scale Exploits and Emergent Threats, Berkeley, CA, USA
(2008)
27. Zerfos, P., Meng, X., Samanta, V., Wong, S.H.Y., Lu, S.: A study of the short
message service of a nationwide cellular carrier. In: Proceedings of IMC 2006
(2006)