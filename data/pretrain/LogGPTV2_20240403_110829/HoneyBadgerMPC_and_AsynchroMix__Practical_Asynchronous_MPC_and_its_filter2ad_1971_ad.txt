reconstruct each Si. Finally, we use a solver for the set of mi using
multiplication would require at least O(log k) rounds of commu-
nication. However, in PowerMix we use a novel way to trade-off
communication for computation, generating all the powers in a
single round of communication by using some precomputed powers
j(cid:75) and publicly
i(cid:75) using Beaver
2(cid:75),. . .,(cid:74)r k(cid:75). As a result, PowerMix only requires
of the form(cid:74)r(cid:75),(cid:74)r
two rounds of communication to finish mixing.
j
5.1 Option I: Switching Network
Our first approach is to use an MPC program to randomly permute
a set of k secret shared values using a switching network.
Switching networks are implemented in layers, where each layer
applies a permutation to the inputs by conditionally swapping each
pair. However, the resulting permutations are biased [1, 68]. For
example, while a random Benes network can express every possi-
ble permutation, some permutations are more likely than others.
Czumaj and Vöcking showed that O(log k) iterations of random but-
terfly networks (each of which consists of O(log k) layers) provide
adequate shuffling [34] in the sense that the combined permutation
is nearly uniform. The round complexity of the switching network
kn)
is O(log2
k), and the overall communication cost is O(k log2
k) layers in total and O(k) multipli-
considering there are O(log2
cations are needed in each layer. Computation cost is O(k log2
kn)
since O(k log2
kn) multiplications are needed in total. (See Figure 6
for a secure switching network instantiation with standard MPC
operations.)
Session 4C: Secure Computing IIICCS ’19, November 11–15, 2019, London, United Kingdom894Table 2: Summary of Online Phase computation and com-
munication cost overhead (per client input) for Iterated But-
terfly and PowerMix MPC programs
Protocol
PowerMix
Switching Network
Rounds
2
log2 k
Comm. complexity
O(n)
O(n log2 k)
Compute
O(n + k2)
O(n log2 k)
.
2(cid:75), . . . ,(cid:74)mk(cid:75) from just(cid:74)m(cid:75).
the k powers of each shared secret,(cid:74)m
5.2 Option II: PowerMix
To contrast with the switching network, we propose a novel proto-
col PowerMix, which results in reduced communication at the cost
of computation. Our approach follows two steps. First, we compute
Surprisingly, we show how to achieve this using only O(1) commu-
nication per shared secret, our protocol for computing powers may
be of independent interest. The second step, inspired by Ruffing et
al. [70], is to to use Newton’s Identities [63] to solve a system of
equations of the form Si = mi1 + ... + mi
The servers can obtain Si by computing locally(cid:74)Si(cid:75) and publicly
k
reconstructing. Then we solve the system of equations to obtain
{m′
i} in canonical ordering. We next describe this approach in more
detail.
secret share(cid:74)m(cid:75) sent by clients, we need to compute(cid:74)m
3(cid:75), . . . ,
Computing powers with constant communication. For each
(cid:74)mk(cid:75). The naïve way is to directly use Beaver triples k − 1 times. If
we cared only round complexity, we could also use the constant-
round unbounded fan-in multiplication [35], though it adds a 3x
factor of additional work. In either case, we’d need to reconstruct
O(k) elements in total.
We instead make use of a preprocessing step to compute all
of(cid:74)m
random element,(cid:74)r(cid:75),(cid:74)r
3(cid:75), . . . ,(cid:74)mk(cid:75) by publicly reconstructing only a single
2(cid:75), ...,(cid:74)r k(cid:75) obtained from the preprocessing
element. Our approach makes use of precomputed powers of a
phase. We start with the standard factoring rule
2(cid:75),(cid:74)m
2(cid:75),(cid:74)m
(cid:33)
(cid:32)k−1
ℓ=0
mk − r k = (m − r)
mk−1−ℓr ℓ
.
Taking C = (m − r), and annotating with secret share brackets, we
of smaller degree,
can obtain an expression for any term(cid:74)mir j(cid:75) as a sum of monomials
(cid:74)mir j(cid:75) =(cid:74)r i +j(cid:75) + C
(cid:33)
(cid:32)i−1
ℓ=0(cid:74)mi−1−ℓr j+ℓ(cid:75)
.
(1)
efficient algorithm to output all the powers(cid:74)m
2(cid:75), ...,(cid:74)mk(cid:75) by mem-
oizing the terms(cid:74)mir j(cid:75). The algorithm requires a total of k
we compute(cid:74)mir j(cid:75), we only need monomials of degree i + j − 1, so
the shuffled values from the power sums. We have Sj =k
Based on Equation (1), in Figure 7, we give pseudocode for an
2/2
2 additions in the field. The memory require-
multiplications and k
ment for the table can be reduced to O(k) by noticing that when
we can forget the terms of lower degree. Table 2 summarizes the as-
ymptotic communication and computation costs of each approach.
Solving Newton’s Identity. We now discuss how to reconstruct
j
i =1 m
i
where mi is the message provided by client Ci. So we require an
algorithm to extract the message mi from Si.
2(cid:75),(cid:74)b
2(cid:75),(cid:74)m
• Procedure:
3(cid:75) . . .(cid:74)bk(cid:75)
3(cid:75) . . .(cid:74)mk(cid:75)
MPC Program compute-powers
Initialize Array[k + 1][k + 1]
for ℓ from 1 to k: // compute all Array[i][j] where ℓ = i + j
sum := 0
for i from 1 to (ℓ − 1), j = ℓ − i:
sum += Array[i − 1][j]
• Input:(cid:74)m(cid:75)
• Output:(cid:74)m
• Precompute: k powers of random b,(cid:74)b(cid:75),(cid:74)b
for i from 1 to k: Array[0][i] :=(cid:74)bi(cid:75)
C := Open((cid:74)m(cid:75) −(cid:74)b(cid:75))
// Invariant: sum =
k <i(cid:74)mi−1−kbj+k(cid:75)
Array[i][j] =(cid:74)bi +j(cid:75) + C · sum
// Invariant: Array[i][j] will store(cid:74)mibj(cid:75) by (1)
for i from 2 to k output(cid:74)mi(cid:75) := Array[i][0]
Figure 7: Algorithm for calculating k powers of input(cid:74)m(cid:75)
ers. Then all servers calculate(cid:74)Sj(cid:75) =k
i =1(cid:74)m
i(cid:75) locally and then
publicly reconstruct each Sj.
Let f (x) = ak xk +ak−1xk−1 +. . .+a1x +a0 be a polynomial such
that f (x) = 0 has roots m1, m2, m3, . . . , mk. And we have ak = 1
given that it is the coefficient of xk resulting from the product of
(x −m1)(x −m2) . . . (x −mk). According to Newton’s identities [70],
we can calculate all coefficients of f (x) by:
Assuming that our goal is to mix k messages m1, m2, m3, . . . , mk,
the servers first run Algorithm 7 to compute the appropriate pow-
using preprocessing in the Powermix online phase
S1 + ak−1 = 0
S2 + ak−1S1 + 2ak−2 = 0
S3 + ak−1S2 + ak−2S1 + 3ak−3 = 0
. . .
Knowing Si we can recover all ai by solving these equations
one by one. Once we know the coefficients of f (x) we can then
2) computation complexity in our
find k roots of f (x) = 0 with O(k
implementation [19]. Then we recover all mi. Our final mixing set
consists of these k messages.
To conclude, Figure 8 shows the overall protocol of Power-
j
mixing.
5.3 AsynchroMix Offline Phase Requirements
The offline phase supporting AsynchroMix needs to be able to
generate the requisite preprocessing elements for both converting
client inputs into secret sharings and for realizing either mixing
program. Of these, handling client inputs is the most straightfor-
ward as it only requires generating a t-shared random value for
each input. For simplicity, we note that the randomness extraction
protocol is just RanDouSha, but with only one matrix operation
performed and with half the number of inputs and outputs. We,
therefore, write randomness extraction as simply half of a call to
RanDouSha.
Session 4C: Secure Computing IIICCS ’19, November 11–15, 2019, London, United Kingdom895j
compute-powers
k beaver triples
MPC Program power-mix
• Procedure:
- (Step 1) for i from 1 to k:
• Input:(cid:74)m1(cid:75),(cid:74)m2(cid:75), . . . ,(cid:74)mk(cid:75),
• Output: a shuffling of (m1, m2, . . . , mk)
• Precompute: k sets of precomputed powers, for k instances of
i(cid:75) for i ∈ [1..k], j ∈ [1..k],
(i.e.,(cid:74)b
Run compute-powers (Algorithm 7) on (cid:74)mi(cid:75) to obtain
i(cid:75)
i(cid:75), . . . ,(cid:74)mk
(cid:74)m
i(cid:75),(cid:74)m
Locally compute(cid:74)Sj(cid:75) :=k
i(cid:75)
i =1(cid:74)m
Si := Open((cid:74)Sj(cid:75))
- (Step 3) Apply Newton’s identities to solve (S1, S2, . . . , Sk), re-
covering a shuffling of (m1, m2, . . . , mk).
cret shared values(cid:74)m1(cid:75), . . . ,(cid:74)mk(cid:75)
Figure 8: Power-mixing protocol for shuffling and open se-
- (Step 2) for j from 1 to k:
2
3
j
Table 3: Offline phase requirements to run AsynchroMix t +1
times
Preprocess Task RanDouSha BatchRecPub Needed for
Client input:
0.5
1
each input
Switch Network:
beaver triple
random(cid:74)r(cid:75)
random bit(cid:74)b(cid:75)
Total:
PowerMix:
2
1.5
1.75k log2
k
1
1
k log2
k
k-powers
Total:
k
2
k
k
2
k
each switch
each switch
each epoch
each input
each epoch
Running our mixing programs requires additional preprocessing
inputs. The Switching-Network program requires the generation
of random selector bits as well as the Beaver triples needed to use
them. Meanwhile, our PowerMix program needs k secret-shared
powers of the same random value. These preprocessing costs are
given in terms of invocations of RanDouSha and BatchRecPub in
Table 3.
5.4 Supporting Larger Messages
We have so far assumed that each client message consists of a
single 32-byte field element, but AsynchroMix can easily be adapted
to support larger (fixed-size) messages of multiple field elements
each. Since the switching network choices depend only on the
preprocessed selection bits, we can simply apply the same selection
bits to each portion of input (i.e., the 1st element of clients’ messages
are permuted in the same way as the 2nd element, and so on). For
PowerMix, we could reserve a portion of each message element
(e.g., κ = 40 bits) to use as a tag which would be used to link parts
of a message together. Since no information about mixing inputs is
leaked until the mix is opened, tags will not collide except for with
2−κ probability.
6 IMPLEMENTATION AND EVALUATION
We have developed a prototype implementation that includes all of
the protocols needed to realize both the offline and online phases
of AsynchroMix. Our prototype is written primarily in Python
3, although with computation modules written in C++ (to use
NTL [72]).5 For batch computations on secret sharings, both the
FFT-based and matrix-based algorithms are implemented in C++
using the NTL library. We carried out a distributed benchmarking
experiment with several aims: to validate our analysis, to demon-
strate the practicality of our approach, and to identify bottlenecks
to guide future improvement. We are mainly concerned with two
performance characteristics: cost and latency. Latency is the user-
facing cost, the time from when the user initiates a message to when
the message is published. Computation and bandwidth costs are
a complementary metric since we can improve latency by adding
more resources, up to the extent that sequential computations and
communication round trips are unavoidable. We are mainly inter-
ested in configurations with varying the mix size k, as well as the
number of servers n (and assuming n ≈ 3t + 1). We evaluated not
only the online phase of the MPC protocols, but also the offline
phase which generates precomputed Beaver triples, powers, and
bits.
6.1 Microbenchmarks for Robust
Reconstruction
Evaluating FFT-based and matrix- based decoding. For the
switching network, the main cost in the online phase is batch recon-
struction. We implemented two variations of the batch reconstruc-
tion operation, one based on matrix multiplication (superlinear)
as in HyperMPC [8] and others, and an alternative based on FFT
(quasilinear time).6 The use of FFT-based methods has been sug-
gested by Damgärd et al. [41], but to our knowledge it has not been
included in any MPC implementation. We give a detailed explana-
tion of the FFT-based algorithms we use in the Appendix. Clearly
for some large enough value of n, FFT-based methods would lead to
a performance improvement, but we want to determine if it could
provide benefits for the network sizes in our experiments.
Figure 9 shows the results of microbenchmarks for a single-core
C++ implementation of the reconstruction algorithms, using a sin-
gle t2.medium node for a series of 144 batch reconstructions of 4096
shares each, corresponding to a run of the switching network pro-
gram for mixing k = 4096 client messages. The primary crossover
point is at around n = 2048. For network sizes of n = 2048 and
larger, FFT-based methods offer a significant (greater than 2x)
improvement. For context, while our distributed experiment only
goes to n = 100, HyperMPC [8] ran with up to n = 1000, hence the
n = 2048 could be considered within a practical range.
We noticed that NTL switches strategies for matrix multiplica-
tion at n = 70. Hence at n = 64 the FFT evaluation performed
5https://github.com/initc3/HoneyBadgerMPC
6A function f (n) is quasilinear if f = O(n logc n) for some constant c.
Session 4C: Secure Computing IIICCS ’19, November 11–15, 2019, London, United Kingdom896Figure 9: Compute costs for switching network application
at k = 4096 (144x batch reconstructions of 4096 shares each)
using FFT vs. Matrix Multiplication algorithms
marginally better (a 23.5% speed up) using the hybrid approach