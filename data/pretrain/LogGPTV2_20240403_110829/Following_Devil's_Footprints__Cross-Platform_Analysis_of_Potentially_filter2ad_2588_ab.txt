versions). To this end, we utilized a recently proposed technique
called Centroid [5] in our research, which extracts a set of
features (e.g., loops, branches, etc.) from an app’s control-ﬂow
graph (CFG), uses such features to convert the program into a
high-dimension object (with each feature as a dimension) and
then maps the whole program into the geometric center (the
centroid) of the object. The centroid, which is a concrete value,
is characterized by a monotonicity property: for two program
components with similar centroids, their CFGs also come close;
for those unrelated to each other, their centroids are also very
different. This approach localizes the global comparison across
the whole market to a small number of “neighbors”, which
allows high scalability and accuracy to be achieved at the same
time [5]. More speciﬁcally, a code component can be easily
compared with millions of other components through a similar
binary search over their centroids.
Adversary model. We consider the adversary who spreads po-
tentially harmful code through repackaging legitimate Android
or iOS libraries, or through distributing dedicated PhaLibs for
PHA authors to build attack payloads. As a ﬁrst step, we only
studied the libraries that have not been obfuscated within the
app code. Also for the cross-platform analysis, we have to
focus on the PhaLibs with both Android and iOS versions. It
is important to note that we did not make any assumption on
what the PHA authors cannot do. Instead, our study is meant
to improve our understanding of the scope and magnitude of
this type of PHA infections and techniques the adversary uses,
by investigating a subset of Android and iOS PhaLibs.
III. METHODOLOGY
A. Overview
Idea and key techniques. As mentioned earlier, a study on
mobile PhaLibs needs to discover hidden libraries integrated
within apps and determine whether they are indeed suspicious,
which is nontrivial on Android and even more so on iOS, due to
the lack of the ground truth (AV detecting systems for validating
whether a library is indeed suspicious). Our solutions are a
suite of techniques enabling a unique analysis procedure that
correlates Android PhaLibs to their iOS counterparts, using
the resources on the Android side to study the suspicious
behavior of iOS apps. This procedure is illustrated in Figure 1
and the key techniques involved are highlighted as follows:
on Android (Section III-B) (1) hidden library discovery, (2)
PhaLib detection, and on iOS (Section III-C) (3) cross-platform
mapping of PhaLibs and (4) suspicious behavior correlation.
Speciﬁcally, the ﬁrst step on the Android side is to cluster
the packages recovered from the code of over a million apps
(including 400,000 from Google Play) to identify “libraries”,
that is, those extensively reused across apps. The libraries are
then extracted and scanned by VirusTotal to detect PhaLibs
from them or their variations. After that, the invariants (e.g.,
constant URL strings) collected from individual PhaLib are
utilized to analyze over 140,000 iOS apps, for the purpose of
ﬁnding related iOS PhaLibs from the apps. Finally, suspicious
behavior (in terms of invariant-API-category sequences) in the
iOS PhaLibs is identiﬁed by correlating each iOS invariant-
API-category sequence to the one within the related Android
PhaLib, so that it can be conﬁrmed by existing AV systems to
be potentially harmful. All these steps are automated. However,
we do need manual effort to build a dictionary for the mappings
between Android and iOS APIs (Section III-C). Note that this
only needs to be done once when the OS for iOS or Android
is updated.
Example. Figure 2 presents an example that describes how
our methodology works. As we can see from Figure 2-A, the
packages found within 13 Android apps share over 65% of
methods and are therefore considered to be the variations of a
library. They are extracted from the hosting apps and scanned
by VirusTotal to detect PhaLibs. A conﬁrmed Android PhaLib
is illustrated in Figure 2-B, whose URL sequence is considered
stable across platforms (see the ﬁgure). Such a stable invariant
can also be found from a related iOS Phalib (Figure 2-C),
even though it is built upon a different programming language.
Further from those PhaLibs, we can identify their corresponding
invariant-API-category sequences. The Android-side sequence
turns out to be part of the signatures some AV scanners use
to detect PHAs, which indicates that the related behavior on
the iOS side is also suspicious. In the measurement study we
performed using the methodology, the correlations between the
PhaLibs on different platforms and their shared behavior were
all automatically detected and then manually validated, which
conﬁrmed that almost all of them were accurate.
B. Finding PhaLibs on Android
Our analysis on mobile PhaLibs starts from the Android end,
since Android apps are easier to study (unencrypted, relatively
small size and availability of the ground truth, i.e., VirusTotal)
than the programs on iOS. What we did ﬁrst is to identify
the libraries from the code of over a million apps and run
VirusTotal to detect those considered to be potentially harmful.
This approach could miss the PhaLibs whose behavior has not
360360
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:16:50 UTC from IEEE Xplore.  Restrictions apply. 
Fig. A
packa
package 1
PhaLib
PhaLib
PhaLib
65%
VirusTotal
package 2
ge 2
package 3 .. 13
pa
Android  PhaLib
“http://apiconfig.adwo.com/adwo/a2”
TelephoneManager.getDeviceId() -- READ DEVICE INFO
iOS PhaLib
“http://apiconfig.adwo.com/adwo/i”
ASIdentifierManager:advertisingIdentifier -- READ DEVICE INFO
Fig. B
Fig. C
Fig. 2: An example showing how our methodology works.
been known (and therefore cannot be found by VirusTotal),
but simply attributing known harmful behavior to libraries
and analyzing their relations already helps us gain a better
understanding about a few important issues never studied before,
for example, what is the role a PhaLib plays in potentially
harmful activities, how the libraries are exploited as an avenue
to propagate harmful code, etc. Following we elaborate our
approach (see Figure 1).
Grouping packages. As introduced earlier, an Android library
is in the form of a Java package, which implements a set
of functionalities and provides services to its hosting app
(Section II). It can be built by any developer, who only needs
to pack her code and make it available for sharing. There are
tens of popular libraries available online [15], which however
are only a tip of the iceberg. Many libraries in the wild are
only circulated within a small group of people. Examples
include those used within an organization and the attack
toolkits available to the hacker community. Even for the popular
libraries, they tend to have multiple versions introduced by
updates and the needs for serving different devices (phone,
tablet, etc.) and different markets (North America, Europe,
Asia, etc.). As a result, ﬁnding these libraries online is highly
difﬁcult, and in some cases, even impossible (e.g., an older
version that has been replaced with the new one).
Given the challenges in collecting libraries online and
tracking their version changes, we have to look at the apps,
the ultimate source of libraries, and recover them from the
app code. The advantage of doing this is that whatever we
found must be the libraries that are still “alive”, being used
by some apps. The security threats discovered from those
apps will have real-world impacts. Speciﬁcally, we leverage an
observation: a library is typically used as a whole piece and also
named and structured in the standard way [16]; also in most
cases, different instances of the same library carry the same
package name preﬁx, at least the top domain and organization’s
domain (e.g., com.android), when they are integrated within
different apps. What we can do here is to automatically analyze
the disassembled code of Android apps, breaking them into
packages and grouping these packages according to their names
as appear within their hosting apps. All the packages in the
same group are further inspected to ﬁnd out whether they share
a lot of code among them. Those indeed are and also used by
the apps from more than 20 different vendors (determined by
looking at the certiﬁcates used to sign apps, as prior research
does [2]) are reported as libraries. This approach helps us
avoid the pair-wise code comparison across a large number
of apps, which is very computation-intensive. Also note that
though grouping packages by their names could miss some
potentially harmful libraries that have been obfuscated, this
treatment is simple and effective at identifying many PhaLib
instances, particulary for the legitimate libraries contaminated
with attack code, since they are integrated by legitimate app
developers who have no intention to hide their package names.
In our research, we performed this analysis over 1.3 million
Android apps collected from the app markets around the world,
including over 400,000 popular apps from the Google Play store
(see Section IV-A for details). We implemented a tool, called
LibFinder, to automatically analyze the disassembled apps,
which discovered 612,437 packages and further organized the
packages into 763 groups according to their names. Particularly
our approach utilizes the Root Zone Database [17] to identify
multi-level domain names for accurately grouping the packages.
Within each group, our approach further clustered all the
packages to identify libraries and their variations (different
versions or those customized by the third party).
Finding Android libraries. The purpose of clustering is to
ﬁnd out all the related packages, those sharing a large portion
of code with others in the same cluster. To this end, we ﬁrst
deﬁne a distance, called package similarity degree (PSD) based
upon Jaccard index, to measure the similarity between two
packages: for two packages p1, p2 from different vendors,
P SD(p1, p2) = n(p1 ∩ p2)/n(p1 ∪ p2), where n(p1 ∩ p2)
is the number of common methods shared between p1 and p2
and n(p1∪ p2) is the number of unique methods in either p1 or
p2. To compare two packages at the method level, LibFinder
utilizes the centroid-based approach [5], which computes the
geometric center (centroid) of a model derived from a method’s
CFG (see Section II) to represent the method: two methods are
considered to match each other if their centroids come very
close (within the boundary set according to the prior work [5]).
The PSD between two packages describes their similarity.
The higher it becomes, the more likely that these packages
are variations of the same library. To determine the threshold
for classifying the packages into a library, we utilized two
training datasets in our research: the ﬁrst one contains 20
randomly-selected libraries (e.g., youmi and unity3d) that
are unrelated to each other and the second one involves 20
libraries together with their different versions (e.g., updates,
patched libraries, etc). Figure 3 shows the distribution of the
PSDs between unrelated libraries and that of those related. As
we can see from the ﬁgure, the unrelated libraries never share
more than 13% of their methods, while for those related, they
have at least 57% of the methods in common and most of pairs
have PSDs above 85%. Given the huge gap between those
related and those not, we set the threshold to 35%, right in
the middle between 13% and 57%, which easily differentiates
these two types of library pairs (see Figure 3).
Using the threshold (35%), LibFinder ﬁrst clusters the
packages within the same group (based upon the shared package
name preﬁx) with algorithm DBSCAN [18], and then checks
361361
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:16:50 UTC from IEEE Xplore.  Restrictions apply. 
o
i
t
a
R
100.00%
80.00%
60.00%
40.00%
20.00%
0.00%
unrelated libraries
libraries with different versions
s
r
e
t
s
u
l
c
f
o
r
e
b
m
u
N
180
160
140
120
100
80
60
40
20
0
0         0.1        0.2       0.3        0.4       0.5        0.6       0.7       0.8        0.9       1.0
0.3
0.4
0.1
0.9
0.2
0.5
0.6
0.7
0.8
1
PSD
1
3
5
7
9 11 13 15 17 19 21 23 25 27 30 32 35 40 45 56
Number of variations
Fig. 3: Distribution of PSDs between unrelated libraries and that of
those related.
Fig. 4: Distribution over the number of variations for each library
discovered.
whether the clusters in different groups can be merged (when
the members in two clusters share over 35% methods). In our
research, we successfully compared over 1.3 million Android
apps in this way and discovered 763 clusters, each considered
to be a library. Figure 4 shows the distribution over the number
of variations for each library discovered in this way.
Detecting PhaLibs. To determine whether a library and its
variations are PhaLibs, we scanned them with VirusTotal
(Figure 1). A package is ﬂagged as suspicious if at least
two scanners report it. A technical challenge here is that we
cannot trivially extract the libraries and directly scan them with
VirusTotal, which only works on apps, not the library packages.
Our solution is to scan the special host app of a library, which
carries nothing but the library. For this purpose, we ﬁrst pick
up an app integrating the library, locate the package within the
app’s DEX bytecode and remove all other code to build the
new host app. More speciﬁcally, our approach automatically
discovers the program location of the package from the header
of the DEX ﬁle, including its code and data, before emptying the
whole app and converting it to a placeholder for the package. In
this way, whatever is discovered by VirusTotal can be attributed
to the library.
To scan such an app, VirusTotal has to work in its scan
model, running all 54 AV systems on the app. This is much
more heavyweight than the caching mode, in which only the
checksum of the app is compared against those already scanned.
In the scan mode, on average 5 minutes need to be taken to
analyze an app. To efﬁciently handle over 763 libraries and
their 4,912 variations discovered in our study (which could take
long time to scan if the libraries are processed sequentially), we
come up with a technique to analyze multiple libraries together.
Speciﬁcally, our approach ﬁrst combines different packages
within the same cluster together on a single placeholder app,
as many as possible, under the constraint of the ﬁle-size limit
put by VirusTotal. If the app is reported to be legitimate, we
can drop all the libraries involved. Otherwise, we upload and
scan each variation one by one. Using this approach, we went
through all 763 libraries and their variations found from the
1.3 million apps within only 1,725 scans, total one day with 6
VirusTotal accounts.
C. Analyzing iOS Libs Cross-Platform
Finding iOS PhaLibs is challenging, since recovering li-
braries from the binary code of iOS apps is hard and no
AV systems are publicly available for the Apple platform to
validate our discoveries. To address this issue, we utilize a
key observation that many iOS libraries actually have Android
counterparts. More speciﬁcally, in our research, we looked into
the top 38 iOS libraries as reported by SourceDNA, an analytics
service that proﬁles the Android and iOS app stores. It turns out
that 36 of them, nearly 95%, have Android versions (Table VI in
Appendix presents the details of these popular libraries). Since
Android is less protected than iOS, there is no reason to believe
that once a legitimate library’s iOS version is contaminated
(e.g., adwo), its Android version will remain intact. Therefore,
we decided to map a conﬁrmed Android PhaLib (by VirusTotal)
to its iOS counterpart (if exists) and utilize the Android-side
ground truth to help validate the potentially harmful code
discovered on the iOS side. This approach will certainly miss
some iOS PhaLibs. Nevertheless, it serves as a ﬁrst step towards
systematic study of iOS PHAs and provides a baseline for a
better understanding of the security risks posed by iOS libraries.
Such a cross-platform mapping, however, is by no means
trivial. Android and iOS are two dramatically different systems
with totally different frameworks and APIs, and the program
languages for developing apps (Java vs. Objective-C). Given
the huge gap between the two platforms, it does not come
with a surprise that oftentimes, the Android and iOS versions
of the same library are actually designed and implemented
independently by different developers. As a result, the program
structures and logic can be very different across the platforms,
even for the same library. For example, a function on one
platform can be implemented into multiple ones on the other;
APIs on different platforms are hard to align, and even
when this can be done, the input arguments of the APIs
can also be signiﬁcantly different (Figure 5). Although prior
research studies the relations between the variations of the
same program (e.g., one obfuscated while the other is not) [19]
or those on different platforms but compiled from the same
source code [20], never before has any effort been made to
correlate two independently developed programs with the same
functionalities across platforms.
With the difﬁculty in correlating Android and iOS libraries,
we believe that there must be some invariant relations between
362362
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:16:50 UTC from IEEE Xplore.  Restrictions apply. 
Android
boolean shouldOverrideUrlLoading(…){
if (“adwoPlayAudio”.equalsIgnoreCase(str2)){
//start media player thread
new aq(str17).start();
}
…}
iOS
__AWAdShow_webView_shouldStartLoadWit
hRequest_navigationType__{
…
objc_msgSend(v10->jsConnector, 
"parseCommand:webview:", v31, v11);
… }
__AWJSConnector_parseCommand_webview_
_{
…
void* play_audio_ptr = [[dict
objectForKey:@”adwoPlayAudio”] 
unsignedLongValue]
play_audio_ptr(…);        … }
Fig. 5: Different ways to use audio in Android and iOS platforms.
The name of the class (i.e., aq) is obfuscated in Android part. In iOS