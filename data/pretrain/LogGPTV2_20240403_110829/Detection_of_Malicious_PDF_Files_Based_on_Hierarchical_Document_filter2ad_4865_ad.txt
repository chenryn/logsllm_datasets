Detection Accuracy
30,130
14
892
27
.9991
.0154
.9986
30,149
12
894
8
.9997
.0132
.9993
21,695
1
905
8,462
.7194
.0011
.7275
Table 3. Aggregated results of the WithJS ex-
periment
5.3.3 The WithJS experiment
Table 3 shows detailed experimental results for both of
our algorithms and PJSCAN. Since PJSCAN performs
anomaly detection; i.e., it learns using only examples of one
class (malicious), the experimental protocol for PJSCAN is
slightly different. Five-fold cross-validation is employed on
the same data subsets as with our method, except that the
benign training ﬁles are left unused for PJSCAN.
Overall, our method performs somewhat worse than
in the Standard experiment, due to the strong class im-
balance in the dataset. However, it signiﬁcantly outper-
forms PJSCAN, a method specialized for detecting mali-
cious JavaScript, even on a dataset carefully chosen for it.
PJSCAN’s high false negative rate in this experiment can be
attributed to its failure to deal with intricate obfuscations.
The reported effectiveness of PJSCAN is comparable to the
results presented earlier with VIRUSTOTAL data [19].
The experimental results presented above represent a sig-
niﬁcant improvement in comparison to previous results on
detection of PDF malware reported in the literature, sum-
marized in Table 4 on the following page. It can be clearly
seen that the detection performance of the proposed method
(referred to as STRPATH) is signiﬁcantly better than in pre-
viously reported results. Its closest competitor, MALWARE
SLAYER [23], attains similar true positive rate but at the
cost of more than 200-fold increase of the false positive
rate. Both of the dynamic analysis methods, MDSCAN [37]
and SHELLOS [34], generate no false positives12 but de-
tect only 80-90% of malware; it should be also noted that
these results have been measured on an order of magnitude
smaller datasets.
12Strangely, no data on false positive rate is reported for SHELLOS al-
though benign data was collected. We presume it to be zero, as there is
no reason to believe that a false detection of injected shellcode would have
been reported on some realistic benign data.
True Positives
False Negatives
10,681
728
10,870
539
True Positive Rate
.9361
.9527
Table 5. Aggregated results of the Novel ex-
periment
5.3.4 The Novel experiment
Table 5 shows the results for the Novel experiment13.
The Novel experiment shows that, even when our learn-
ing algorithms are trained on a 2 to 3 month-old dataset,
they still achieve respectable 93% (decision tree) or 95%
(SVM) true positive rates.
5.3.5 The 10Weeks experiment
Figure 6 shows the comparison of our method to the best
VIRUSTOTAL antivirus14 in the 10Weeks experiment in
terms of true positive rate (TPR). The best AV achieves
an overall TPR of 92.81%, signiﬁcantly better than 87.14%
achieved by our method. However, our method consistently
outperforms the best AV in 7 out of 10 weeks, and there
is a draw in week 8. The performance degradation of our
method in weeks 14 and, most notably, 12 has motivated
a further investigation which uncovered a curious trend in
VIRUSTOTAL submissions.
Our Method
Best Antivirus
Total Positives
6000
5000
4000
3000
2000
1000
0
t
n
u
o
C
e
v
i
t
i
s
o
P
5
6
7
8
10
9
Week
11
12
13
14
R
P
T
1.0
0.8
0.6
0.4
0.2
0.0
Figure 6. Comparison of the true positive rate
of our method to the best antivirus for the
10Weeks experiment
The top half of Figure 6 shows the number of PDF sub-
missions to VIRUSTOTAL detected by at least 5 AVs, i.e.,
13Note that some information, such as the true negative count, is missing
for this experiment because it was only applied to malicious data, since
changes in benign performance were negligible.
14The name of the best AV is not disclosed, as there are several AVs
within a 5% margin of the TPR achieved in this experiment, and their rank-
ings may change from week to week.
STRPATH MDSCAN
PJSCAN
SHELLOS MALWARE SLAYER
Number of malicious samples
Number of benign samples
True positive rate
False positive rate
38,207
90,384
.9988
.0001
197
2,000
.8934
0
30,157
906
.7194
.0011
405
179
.8024
N/A
11,157
9,989
0.9955
0.0251
Table 4. Comparison of the proposed method with previous results
the number of positives per week. In the ﬁrst week of Octo-
ber 2012, week 12, VIRUSTOTAL saw the positive submis-
sion count increase by approx. 150%, from around 2,000 to
around 5,000. This elevated level of submissions has per-
sisted to the end of the experiment. A closer inspection of
the submissions in this week has revealed that there are two
groups of ﬁles, one with 1,842 and the other with 2,595,
which differ byte-wise from each other, but have identi-
cal PDF structure, i.e., every ﬁle in a group corresponds
to the same bag-of-paths. Furthermore, there is a high sim-
ilarity between the structure of the ﬁles in the two groups.
The bag-of-paths of the smaller group consists of 99 struc-
tural paths, all of which are present in the other group as
well. The two only differ by the presence of additional 11
structural paths in the bigger group. Files with the same
bag-of-paths were also submitted later, but not before this
week. This ﬁnding strongly suggests that the submissions
of week 12 and later stem in great part from a single source
and are generated using fuzzing techniques.
The cause for the false negative rate of 37% in week 12
is that all the 1,842 ﬁles in the smaller group were wrongly
labeled as benign by our method. The prediction is the same
for all ﬁles because they all translate into equal bags-of-
paths, i.e., the same data point. A wrong classiﬁcation of
one data point in this case led to a false negative rate of
more than 1/3 because the test data was heavily skewed by
one source producing very similar, fuzzed PDFs. In about
20 cases, these fuzzed PDFs were also missed by all the
AVs.
The data point corresponding to the bag-of-paths of the
smaller group of ﬁles is located on the wrong side of the
SVM decision boundary, although very close to it. The
addition of further 11 structural paths positioned the data
point corresponding to the bag-of-paths of the larger group
signiﬁcantly over the decision boundary into the positive
class. The reason for this lies in the fact that 8 out of 11
added structural paths are strong indicators of malicious-
ness in the learned SVM model15. In the weeks following
week 12, these examples showed up in the learning stage
15A linear SVM was trained for the purpose of this feature interpretation
which exhibits the same misclassiﬁcation problem for the smaller group of
ﬁles. The evaluation was performed analogue to the evasion strategy for
linear SVMs presented in Section 6 by calculating and sorting weights for
all features.
and were correctly classiﬁed.
The performance drop in week 14 comes from a very
high number of submitted ﬁles (over 900) which our parser
could not open. This anomaly was not further investigated
as these are either malformed PDFs which are not danger-
ous to the PDF renderer application but are still scanned by
ignorant AVs or parser bugs, in which case it sufﬁces to up-
date or ﬁx the parser or even employ a completely different
one, as the method is parser-agnostic.
The overall false positive rate of our method in this ex-
periment is 0.0655%, as in laboratory tests. The AVs do not
have false positives by deﬁnition of our experiments, as the
“undecided” ﬁles (the ones between 1 and 4 detections) are
ﬁltered.
5.4 Throughput
High throughput is an important consideration when
dealing with large volumes of PDF data, as is the case with
VIRUSTOTAL, big companies or governments. Our system
was designed to handle such loads and utilize the parallel
processing capabilities of modern computer systems. We
have measured the time it takes to perform feature extrac-
tion, learning and classiﬁcation for datasets D1, D2, D3 and
D4 with both decision trees and SVMs. The measurements
were made on a quad-core CPU with 8 GBs of RAM and
a 7,200 RPM SATA hard disk with the memory caches pre-
viously cleared.
Feature extraction is the most time-consuming operation,
as it requires to load all the PDF ﬁles from the hard drive.
It was performed using 7 parallel processes. In total, 121
minutes and 55 seconds were spent on feature extraction
for the 150 GB of data in the above mentioned datasets, of
which 5 minutes and 13 seconds were spent on malicious
ﬁles and 116 minutes and 42 seconds on benign ﬁles. This
yields a throughput of 168 Mbit/s.
Numbers for learning and classiﬁcation differ for deci-
sion trees and SVMs. They are presented in Table 6.
Since each of the 5 cross-validation runs trains on 80%
of the training data, we divided the total sum of execution
times for all runs by four to obtain an estimate of how long a
single training would take for the entire dataset. The classi-
ﬁcation time is a simple sum of 5 individual classiﬁcations,
Learning
Classiﬁcation
Decision tree
SVM
6m 31s
1m 23s
52s
54s
Table 6. Time required for learning and clas-
siﬁcation for the Standard experiment
as each deals with 20% of the testing data. Note that exe-
cuting the cross-validation runs in parallel increases perfor-
mance linearly with the number of processes. Even though
decision trees are signiﬁcantly slower than the SVM, the
overall running time is dominated by feature extraction.
The total time required for feature extraction, learning
and classiﬁcation using SVMs in the Standard experiment
with the datasets D1 and D4 of 74.4 GB was 1 hour and 2
seconds, which yielded a total throughput of around 169
Mbit/s and a mean processing time of 28 ms per ﬁle. The
high performance numbers are achieved by static detection
and parallel execution. In contrast, dynamic methods such
as MDSCAN (slightly less than 3,000 ms per malicious
ﬁle, 1,500 ms per benign ﬁle on average) and SHELLOS (on
average 5.46 seconds per ﬁle for analysis, plus additional 2
(benign) to 20 (malicious, non-ROP) seconds for buffer ex-
traction) require orders of magnitude more time. The only
other fully static method, PJSCAN, takes 23 ms per ﬁle, be-
cause it only extracts a well-deﬁned, limited subset of the
entire PDF ﬁle.
6 Evasion
An important aspect of every proposed security measure
is how difﬁcult it is to evade. Given the increasing interest to
the application of learning methods for security problems,
some previous work has addressed the methodology for se-
curity analysis of learning algorithms [3, 18, 2]. Following
such methodology, in the following section, we present and
experimentally evaluate a novel type of attacks against our
method which is motivated by the speciﬁc constraints im-
posed by the structural features on the attacker.
The ﬂexibility of the PDF format and the lax enforce-
ment of its rules by the Acrobat Reader gives the attacker
ample opportunity to inﬂuence both the content and the
structure of the ﬁle. The only fundamental constraint on
the attacker is the need to deliver the malicious content and
trigger its execution by means of an appropriate attack vec-
tor. In our evasion model, we assume that the attacker has
crafted a malicious PDF ﬁle that is correctly classiﬁed as
malicious. The attacker’s goal now is to modify the ﬁle
such that it is classiﬁed as benign. We assume that the at-
tacker can not decrease the detection footprint by removing
parts of malicious content and is thus limited to only adding
content that the classiﬁcation model considers benign. Al-
though we cannot verify that this limitation is insurmount-
able for an attacker, intuitively it is much easier to add ar-
bitrary benign content to a PDF document than to change
its syntactic structure of an existing document such that it
is still “correctly” rendered by the viewer and triggers the
exploit.
In our analysis, we assume that the attacker has com-
plete knowledge of the detection mechanism and its classi-
ﬁcation model. Although the latter assumption may seem
too restrictive, nothing prevents the attacker from collect-
ing a surrogate dataset, similar to the one used for training,
train a classiﬁer of his own and thus obtain a good guess
of the classiﬁcation model. Alternatively, if our method
were to be deployed on end-user systems, the ﬁles contain-
ing the learning models would be distributed to end-users,
as with antivirus deﬁnitions. This would make them com-