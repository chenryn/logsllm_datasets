smaller depth trees have much lower accuracy (82% for
depth 4 and 84% for depth 5). In contrast, our classifier
for the Nursery dataset achieves an accuracy of 98.7%.
6.7 Matrix Factorization
We measure the performance of our gradient descent on
the MovieLens dataset. We implemented both the base-
line algorithm and the oblivious algorithm of Section 4.6.
As for k-means, we stream the input data (once) into the
enclave to initialize the data structures, then we operate
on them in-place. We also implemented the oblivious
method of Nikolaenko et al. [48] to compare its overhead
with ours (see Section 7 for the asymptotic comparison).
We did not use garbled circuits, and merely implemented
their algorithm natively on Skylake CPUs.
In each experiment, we set the dimension of user and
vector profiles to d = 10, following previous implemen-
tations in [47, 48]. We experimented with fixed numbers
of iterations T = 1,10,20. With higher number of itera-
tions the prediction rate of the model improves. For ex-
ample, when using 90K instances for training, the mean
squared error of prediction on 10K test dataset drops
from 12.94 after 1 iteration, to 4.04 after 20 iterations,
to 1.06 after 100 iterations (with λ = µ = γ = 0.0001).
Table 1 reports the overheads for the MovieLens-100K
dataset. The oblivious version takes 49s, versus 0.43s
for the baseline, reflecting the cost of multiple oblivious
sorting for each of the T = 20) iterations. With smaller
number of iterations, the running times are 8.2s versus
0.03s for T = 1, and 27s versus 0.21s for T = 10. (As
a sanity check, a naive oblivious algorithm that accesses
5The numbers correspond to a random forest trained on the standard
Covertype dataset from the UCI repository.
630  25th USENIX Security Symposium 
USENIX Association
12
are based on garbled circuits, secret sharing and en-
cryption with homomorphic properties. Lindell and
Pinkas [36] survey these techniques with respect to data
mining tasks including machine learning. It is worth not-
ing that beside mathematical assumptions, some of the
above approaches also rely on (a subset of) computing
parties being honest when running the protocol as well
as non-colluding.
Garbled circuits [71] provide a mechanism for multi-
ple parties to compute any function on their joint inputs
without having to reveal the inputs to each other. So-
lutions based on garbled circuits have been tailored for
several specific machine learning tasks including matrix
factorization [48], and training of a decision tree [6, 35].
GraphSC [47] and ObliVM [38] are two recent program-
ming frameworks for secure computation using garbled
circuits. The former framework offers a paradigm for
parallel computation (e.g., MapReduce) and the latter
uses a combination of ORAM and garbled circuits.
Training of an SVM kernel [34] and construction of a
decision tree [18] have been proposed based on secret-
sharing and oblivious transfer.
Homomorphic encryption lets multiple parties encrypt
their data and request the server to compute a joint func-
tion by performing computations directly on the cipher-
texts. Bost et al. [13] study classification over encrypted
data in the model where the server performs classifica-
tion by operating on semi-homomorphic encrypted data;
whenever the server needs to perform operations not sup-
ported by the encryption, it engages in a protocol with a
party that can decrypt the data and perform the necessary
computation. Solutions based on fully-homomorphic en-
cryption have been proposed for training several ML al-
gorithms [27, 69] and for classifying decision trees [68].
Shokri and Shmatikov [59] describe a method for mul-
tiple parties to compute a deep neural network on joint
inputs. This method does not rely on cryptographic prim-
itives. It assumes that the parties train their own model
and do not share the data with each other, but exchange
intermediate parameters during training. Our model is
different as parties in our solution do not perform any
computation and do not learn anything about the train-
ing process; after the training they can either obtain the
model, if they agreed to, or use it for querying in a black-
box manner.
T
1
10
20
This work
8
27
49
Previous work
14 (1.7x)
67 (2.4x)
123 (2.5x)
Table 2: Comparison of running times (in seconds) of oblivious
matrix factorization methods on the MovieLens dataset: our
work is the method in Section 4.6 and previous work is our im-
plementation of an algorithm in [48] without garbled circuits.
T is the number of algorithm iterations.
all entries in U and V to hide its random accesses runs in
1850s for T = 10.)
Table 2 compares the overheads of our oblivious algo-
rithm and the one of [48]. As expected, our method out-
performs theirs as the number of iterations grows, inas-
much as it sorts smaller data structures.
Comparison with cryptographic evaluations: We
are aware of two prior evaluations of oblivious matrix
factorization [47, 48]. Both solutions are based on gar-
bled circuits, and exploit their parallelism. Both only
perform one iteration (T = 1). Nikolaenko et al.
(in
2013) report a run time of 2.9 hours for 15K ratings
(extracted from 100K MovieLens dataset) using two ma-
chines with 16 cores each. Nayak et al. (in 2015) report
a run time of 2048s for 32K ratings, using 32 processors.
6.8 Security Evaluation
We experimentally confirmed the data-obliviousness of
all enclave code for each of our algorithms, as follows.
We ran each algorithm in a simulated SGX environment6
and used Intel’s Pin framework [42] to collect runtime
traces that record all memory accesses of enclave code,
not only including our core algorithms, but also all stan-
dard libraries and SGX framework code. For each algo-
rithm, we collected traces for a range of different inputs
of the same size and compared code and data accesses at
cache-line granularity, simulating the powerful attacker
from Section 2. While we initially discovered deviations
in the traces due to implementation errors in our oblivi-
ous primitives and algorithmic modifications, we can re-
port that the final versions of all implementations pro-
duce uniform traces that depend only on the input size.
7 Related Work
Secure multi-party machine learning General cryp-
tographic approaches to secure multi-party computation
6For debugging purposes, the Intel SGX SDK allows for the cre-
ation of simulated SGX enclaves. Those simulated enclaves have
largely the same memory layout as regular SGX enclaves, but are not
isolated from the rest of the system. In simulation mode, SGX instruc-
tions are emulated in software inside and outside the enclave with a
high level of abstraction.
Privacy implications of revealing the output of a ma-
chine learning algorithm, i.e., the model, is orthogonal
to the focus of this paper; we refer the reader to Fredrik-
son et al. [21, 22] on this topic. As a remedy, differ-
ential privacy guarantees for the output of several ma-
chine learning algorithms have been studied by Blum et
al. [11].
Data-oblivious
RAM
(ORAM) [25] is a general protection technique against
techniques Oblivious
USENIX Association  
25th USENIX Security Symposium  631
13
Though recent
side-channels on memory accesses.
advances in this space [62] have significantly decreased
the ORAM overhead, there are cases where the default
solution does not always meet system requirements.
First, many ORAM solutions offer a tradeoff between
the size of the private memory and the overhead they
incur.
In current CPUs, registers act as an equivalent
of processor’s private memory, however their number
is limited, e.g., even for the latest x86 generations, less
than 2KB can be stored in all general purpose and SIMD
registers combined. Second, ORAM does not hide the
number of accesses. That is, if this number depends
on a sensitive input (e.g., number of movies rated by
each user) then fake accesses need to be generated to
hide the real number of accesses. Finally, ORAM is
ideal for programs that make few accesses in a large
dataset.
For algorithms that process data multiple
times, customized solutions often perform better (e.g.,
MapReduce [47, 49]). Machine learning algorithms fall
in the latter category as they need all input instances to
train and use the model.
Raccoon [53] and GhostRider [37] propose general
compiler techniques for protecting memory accesses of
a program. Some of the techniques they deploy are
ORAM and execution of both branches of if-else state-
ments. However, general techniques are less effective in
cases where an algorithm accesses data in a structured
way that can be exploited for greater efficiency. For ex-
ample, compiling matrix factorization using these tech-
niques is not trivial as the interleaving of the accesses
between internal data structures has to be also protected.
(The interleaving depends on sensitive information such
as rating counts per user and per movie which have to be
taken into account.)
Asymptotical comparison of individual algorithms
We now compare the asymptotic performance of our
data-oblivious algorithms to prior work. We evaluate the
overhead of obtaining oblivious properties only. That is,
we do not consider the cost of their secure implemen-
tation on SGX (our approach) or using garbled circuits
in [38, 47, 48] (though the latter is known to add large
run time overheads).
ObliVM [38] uses a streaming version of MapReduce
to perform oblivious k-means which is then compiled to
garbled circuits. The algorithm relies on oblivious sort-
ing to update the centroids at each iteration, resulting
in the running time of O(cid:31)T (nkd + dn(logn)2)(cid:30) (ignor-
ing conversion to garbled circuits). Since our algorithm
takes O(T nkd) time, the asymptotical comparison be-
tween the two depends on the relation between values k
and O((logn)2). Moreover, oblivious sorting incurs high
constants and our experiments confirmed that our simple
method was more efficient.
The algorithmic changes required to make SVM and
Neural Networks oblivious can be captured with auto-
mated tools for compiling code into its oblivious coun-
terpart. Instead of an oblivious shuffle or sort between
the iterations, these methods would place input instances
into an ORAM and then sample them by accessing the
ORAM. Since all n instances are accessed at each itera-
tion, the asymptotical cost of the two solutions remains
the same. However, such tools either use a backend that
would require careful adaption for the constrained SGX
environment (for example, GhostRider [37] defines its
own source language and ObliVM [38] translates code
into circuits) or they are not as optimized as our approach
(for example, Raccoon [53] always executes both code
paths of a secret-dependent conditional statement and its
described array scanning technique is less fine-tuned for
the x86 architecture than ours).
Our simple data-oblivious decision tree algorithm is
adequate for ad hoc tree evaluations, and scales up to
reasonably large forests. With larger irregular data struc-
tures, algorithms based instead on oblivious data struc-
tures [38, 66] may be more effective as they store data in
elaborate randomized data structures that avoid stream-
ing over all the tree leaves. Though their asymptoti-
cal performance dominates our approach — O((logn)2)
vs. O(n), assuming height of the tree of O(logn) —
as pointed out in [53] ORAM-based solutions improve
over the plain scanning of arrays only for larger n due
to the involved constants. Moreover, private mem-
ory of size O(logn) is assumed in [66] while as men-
tioned earlier, private memory for SGX is limited to
registers. Oblivious tree can be implemented also via
ORAM with constant private memory size [33], incur-
ring O((logn)3/loglogn) overhead.
Finally, oblivious matrix factorization for garbled cir-
cuits, rather than SGX processors, was considered in [48]
and [47]. Nikolaenko et al. [48] also rely on a data struc-
ture that combines both user and movie profiles: They
maintain a global matrix of size M + n + m with M rows
for the ratings, n rows for the users, and m rows for the
movies. Their updates are performed in several sequen-
tial passes, and synchronized using a sorting network on
the whole data structure. Hence, their algorithm runs
in time O(cid:31)T (M + n + m)(log(M + n + m))2(cid:30), dominated
by the cost of sorting the rows of the matrix at every it-
eration. GraphSC [47] implements matrix factorization
using an oblivious parallel graph processing paradigm.
However, this method also relies on oblivious sorting of
M + n + m profiles, hence, asymptotically it incurs the
same cost.
In comparison, our approach sorts on that
scale only during Setup and, besides, those costly op-
erations only sort user ids and ratings—not the larger
profiles in d. Then, asymptotically, our iterations are
more efficient due to a smaller logarithmic factor as we
632  25th USENIX Security Symposium 
USENIX Association
14
sort fewer tuples at a time: O(cid:31)T (M + ˜n)(log ˜n)2(cid:30) where
˜n = max(n,m). As we showed in the evaluation section
our method also outperforms [48] in practice.
Similar to prior oblivious matrix factorization tech-
niques [47,48], our method is easily parallelizable. First,
an oblivious sort that runs in time O(n(logn)2) sequen-
tially can run in time O((logn)2) with n parallel pro-
cesses. Besides, each row in our data structures U
and V can be processed independently, and aggregated
in time log(M + ˜n), as in the method described in [47].
Even with parallel processing, our method is more effi-
cient, because the depth of the computation stays loga-
rithmic in ˜n for our method and M in theirs [47, 48].
Secure hardware TrustedDB [5], Cipherbase [3], and
Monomi [64] use different forms of trusted hardware to
process database queries with privacy. Haven [8] runs
unmodified Windows applications in SGX enclaves, and
VC3 [57] proposes a cloud data analytics framework
based on SGX. None of these systems provides protec-
tion from side-channel attacks. These systems were eval-
uated using SGX emulators. In contrast, we are the first
to evaluate implementations of machine learning algo-
rithms on real SGX processors.
8 Conclusions
We presented a new practical system for privacy-
preserving multi-party machine learning. We propose
data-oblivious algorithms for support vector machines,
matrix factorization, decision trees, neural networks, and
k-means. Our algorithms provide strong privacy guar-
antees:
they prevent exploitation of side channels in-
duced by memory, disk, and network accesses. Exper-
iments with an efficient implementation based on Intel
SGX Skylake processors show that our system provides
good performance on realistic datasets.
References
[1] AJTAI, M., KOML ´OS, J., AND SZEMER ´EDI, E. An
O(nlogn) sorting network. In ACM Symposium on
Theory of Computing (STOC) (1983).
[2] ANATI, I., GUERON, S., JOHNSON, S., AND
Innovative technology for CPU
SCARLATA, V.
based attestation and sealing.
In Workshop on
Hardware and Architectural Support for Security
and Privacy (HASP) (2013).
[3] ARASU, A., BLANAS, S., EGURO, K., KAUSHIK,
R., KOSSMANN, D., RAMAMURTHY, R., AND
VENKATESAN, R. Orthogonal security with Ci-
pherbase. In Conference on Innovative Data Sys-
tems Research (CIDR) (2013).
[4] ARASU, A., AND KAUSHIK, R.
Oblivious
query processing. In International Conference on
Database Theory (ICDT) (2014).
[5] BAJAJ, S., AND SION, R. TrustedDB: A trusted
hardware-based database with privacy and data
confidentiality.
In IEEE Transactions on Knowl-
edge and Data Engineering (2014).
[6] BARNI, M., FAILLA, P., KOLESNIKOV, V.,
LAZZERETTI, R., SADEGHI, A., AND SCHNEI-
DER, T. Secure evaluation of private linear branch-
ing programs with medical applications. In Euro-
pean Symposium on Research in Computer Security
(ESORICS) (2009).
[7] BATCHER, K. E. Sorting networks and their appli-
cations. In Spring Joint Computer Conf. (1968).
[8] BAUMANN, A., PEINADO, M., AND HUNT, G.
Shielding applications from an untrusted cloud with