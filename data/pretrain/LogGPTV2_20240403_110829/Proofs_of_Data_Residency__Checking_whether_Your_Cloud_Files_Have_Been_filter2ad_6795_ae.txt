### 3.2 Effect of the Late Delivery Threshold (l) on Security in N-ResCheck

In this section, we examine the impact of the late delivery threshold \( l \) on the security of N-ResCheck. The Message Authentication Code (MAC) length is set to 16 bits, and the audit size is \( v = 300 \) challenges.

**Figure 7: Effect of the late delivery threshold \( l \) on the security in N-ResCheck.**
- **(a) \( c = 10\% \)**
- **(b) \( c = 20\% \)**
- **(c) \( c = 40\% \)**

When the late delivery threshold \( l \) increases from 2 to 32, the false rejection rate \( \gamma \) drops exponentially. Specifically, for N-ResCheck, \( \gamma \) decreases by up to 22 orders of magnitude, while for E-ResCheck, it decreases by almost 50 orders of magnitude. This indicates that increasing \( l \) can make the scheme more tolerant to environmental noise.

However, as \( l \) increases, the false acceptance rate \( \psi \) also grows. For both N-ResCheck and E-ResCheck, \( \psi \) increases by 8 to 16 orders of magnitude when \( l \) increases from 2 to 16, depending on the code rate of the error-erasure code in use. Notably, when \( c = 10\% \) and \( l = 32 \), \( \psi \) can reach up to 0.7.

We recommend setting the late delivery threshold \( l \) to 8, which results in a false rejection rate \( \gamma \) as low as \( 5 \times 10^{-10} \), while keeping \( \psi \) below \( 10^{-6} \) even for \( c = 10\% \). Additionally, for the same parameter settings, \( \psi \) decreases exponentially as \( c \) increases. For example, in E-ResCheck, \( \psi \) reduces by up to 30 orders of magnitude when \( c \) increases from 10% to 40%.

### 3.3 Effect of Audit Size (v) on Security

In the final set of experiments, we investigate the effect of the audit size \( v \) on overall security. We fix the MAC length at 16 bits and the late delivery threshold at 8, and examine how \( v \) affects \( \psi \) and \( \gamma \).

**Figure 8: Effect of audit size \( v \) on the security in E-ResCheck.**
- **(a) \( c = 10\% \)**
- **(b) \( c = 20\% \)**
- **(c) \( c = 40\% \)**

**Figure 9: Effect of audit size \( v \) on the security in N-ResCheck.**
- **(a) \( c = 10\% \)**
- **(b) \( c = 20\% \)**
- **(c) \( c = 40\% \)**

For E-ResCheck, \( \psi \) reduces by 8 to 26 orders of magnitude as \( v \) varies from 200 to 400. Similarly, for N-ResCheck, the reduction in \( \psi \) is comparable. This suggests that increasing the audit size (i.e., issuing more challenges) can arbitrarily reduce the false acceptance rate \( \psi \). Although increasing the audit size leads to higher communication costs in N-ResCheck, the actual increase is only in kilobytes, which is reasonable. E-ResCheck, on the other hand, does not require transferring challenges and responses over the network, thus incurring no network communication overhead.

However, as \( v \) increases from 200 to 400, the false rejection rate \( \gamma \) also increases. In E-ResCheck, \( \gamma \) increases from \( 1.3 \times 10^{-11} \) to \( 6.1 \times 10^{-9} \) (almost 450 times), and in N-ResCheck, \( \gamma \) increases from \( 4.6 \times 10^{-4} \) to \( 3.7 \times 10^{-2} \) (by 80 times). While the increase in \( \gamma \) is more pronounced in E-ResCheck, the false rejection rate remains several orders of magnitude lower than in N-ResCheck. This increase is due to greater exposure to environmental noise, with network transmission noise being significantly higher than the noise from housekeeping operations at the OS level in E-ResCheck.

### 3.4 Summary of Experimental Results

Across all experiments, E-ResCheck consistently outperforms N-ResCheck. It offers better false acceptance and rejection rates, incurs no network communication overhead, and is less exposed to environmental noise. These results highlight the superiority of E-ResCheck in terms of security and efficiency.

### 4. Related Work

#### 4.1 Proofs of Retrievability

Proofs of retrievability (PoR) were first proposed by Juels and Kaliski [26] and have since been extended by various works [36, 16, 38]. These works address the problem of auditing a remote and untrusted storage server for data preservation. A closely related technique is Provable Data Possession (PDP), initially discussed by Ateniese et al. [13], which ensures that most (but not necessarily all) of the data are stored. PoR and PDP have been extended to dynamic settings [37, 21]. However, none of these works consider the location of the data. PoDR, on the other hand, provides a proof that the original file \( F \) is retrievable in its entirety from data stored locally at the storage provider's server.

#### 4.2 Timed Challenge-Response Protocols

Timed challenge-response protocols have been studied in various application scenarios. Bowers et al. [17] presented a remote assessment of fault tolerance based on measuring the response latency of read requests for a collection of file blocks. Their model assumes that network latency can be accurately estimated and treated as a constant. In contrast, our model assumes that network latency is probabilistic, with only its distribution known.

Gondree et al. [22] proposed a framework that uses known landmarks to verify the geolocation of stored data. Benson et al. [15] investigated the correlation between network latency and geographical distance, suggesting the use of such techniques to verify data replication across geographically separated data centers. Our construction focuses on verifying the residency of data on the server in question. Unlike previous proposals that advocate minimizing server-side computation for practical and cost-saving reasons, we discuss such requirements from a security perspective and emphasize the impact of block size on protocol security, which has not been studied in previous works.

#### 4.3 Locality of Storage

Recent cryptocurrency proposals [27, 35] have discussed incentives for storing data locally. These proposals require constructing a proof of retrievability during mining, designed to encourage miners to store data locally rather than outsourcing it to a remote storage. While these works share our concern about storage location, they only incentivize local data preservation without enforcing it. PoDR, in contrast, imposes local data preservation and provides an auditing mechanism to detect non-compliance.

#### 4.4 Protected Execution Environment

Various works have relied on trusted computing to provide a protected execution environment for secure services [19, 34, 14]. By assuming the presence of a trusted environment, these works offer security with efficiency and scalability. Our construction leverages trusted computing primitives to co-locate the verifier and prover, enhancing security.

### 5. Conclusion

We have defined the security definition of Proofs of Data Residency (PoDR), which enables the data owner to obtain a proof that the file \( F \) is retrievable in its entirety from the local drives of a storage server. PoDR can be an integral component in auditing contractual assurances, such as affirming the geolocation of data or checking the fault tolerance of a storage system by verifying the residency of files at different storage servers. We have shown potential attacks on insecure constructions and proposed a secure PoDR scheme. The two implementations, N-ResCheck and E-ResCheck, illustrate an interesting use case of trusted computing, where co-locating the verifier and prover enhances security.

This work focuses on a static setting where the data owner does not frequently update \( F \). Future work could extend our construction to support dynamic data updates.

### 6. Acknowledgements

This research is supported by the National Research Foundation, Prime Ministerâ€™s Office, Singapore under its Corporate Laboratory@University Scheme, National University of Singapore, and Singapore Telecommunications Ltd.

### 7. References

[1] Australian privacy act. http://www.austlii.edu.au/au/legis/cth/consol_act/pa1988108/.

[2] Business Insider. Amazon's cloud crash disaster permanently destroyed many customers' data. http://www.businessinsider.com/amazon-lost-data-2011-4?IR=T&r=US&IR=T.

[3] Data protection directive. http://eur-lex.europa.eu/legal-content/EN/TXT/?uri=URISERV%3Al14012.

[4] Google Drive. https://www.google.com/drive/.

[5] IBM 4764 PCI-X Cryptographic Coprocessor. http://www-03.ibm.com/security/cryptocards/pcixcc/overview.shtml.

[6] Intel SGX. https://software.intel.com/en-us/sgx.

[7] Intel SGX Programming Reference. https://software.intel.com/sites/default/files/managed/48/88/329298-002.pdf.

[8] Intel SGX SDK for Linux. https://github.com/01org/linux-sgx.

[9] Intel Skylake processor. http://ark.intel.com/products/codename/37572/Skylake.

[10] PsPing. https://technet.microsoft.com/en-us/sysinternals/psping.aspx.

[11] Traceroute. http://linux.die.net/man/8/traceroute.

[12] I. Anati, S. Gueron, S. Johnson, and V. Scarlata. Innovative technology for CPU-based attestation and sealing. In HASP, 2013.

[13] G. Ateniese, R. Burns, R. Curtmola, J. Herring, L. Kissner, Z. Peterson, and D. Song. Provable data possession at untrusted stores. In CCS, 2007.

[14] A. Baumann, M. Peinado, and G. Hunt. Shielding Applications from an Untrusted Cloud with Haven. In OSDI, 2014.

[15] K. Benson, R. Dowsley, and H. Shacham. Do you know where your cloud files are? In CCSW, 2011.

[16] K. D. Bowers, A. Juels, and A. Oprea. Proofs of retrievability: Theory and implementation. In CCSW, 2009.

[17] K. D. Bowers, M. Van Dijk, A. Juels, A. Oprea, and R. L. Rivest. How to tell if your cloud files are vulnerable to drive crashes. In CCS, 2011.

[18] G. Connolly, A. Sachenko, and G. Markowsky. Distributed traceroute approach to geographically locating IP devices. In IDAACS, 2003.

[19] T. T. A. Dinh, P. Saxena, E.-C. Chang, B. C. Ooi, and C. Zhang. M2R: Enabling stronger privacy in MapReduce computation. In USENIX Security, 2015.

[20] Y. Dodis, S. Vadhan, and D. Wichs. Proofs of retrievability via hardness amplification. In Theory of cryptography. 2009.

[21] C. Erway, A. Kupcu, C. Papamanthou, and R. Tamassia. Dynamic provable data possession. In CCS, 2009.

[22] M. Gondree and Z. N. Peterson. Geolocation of data in the cloud. In CODASPY, 2013.

[23] K. Harrenstien, M. K. Stahl, and E. J. Feinler. NICNAME/WHOIS. RFC-954, 1985.

[24] C. Houri. Method and systems for locating geographical locations of online users, 2003. US Patent 6,665,715.

[25] H. Jiang and C. Dovrolis. Passive estimation of TCP round-trip times. ACM SIGCOMM, 2002.

[26] A. Juels and B. S. Kaliski Jr. PORs: Proofs of retrievability for large files. In CCS, 2007.

[27] A. Miller, A. Juels, E. Shi, B. Parno, and J. Katz. Permacoin: Repurposing Bitcoin work for data preservation. In IEEE S&P, 2014.

[28] M. Naor and G. N. Rothblum. The complexity of online memory checking. In FOCS, 2005.

[29] V. N. Padmanabhan and L. Subramanian. An investigation of geographic mapping techniques for Internet hosts. In SIGCOMM, 2001.

[30] Z. N. Peterson, M. Gondree, and R. Beverly. A position paper on data sovereignty: The importance of geolocating data in the cloud. In HotCloud, 2011.

[31] J. Postel. User datagram protocol. 1980.

[32] J. Postel. Transmission control protocol. 1981.

[33] I. S. Reed and G. Solomon. Polynomial codes over certain finite fields. J. SIAM, 1960.

[34] F. Schuster, M. Costa, C. Fournet, C. Gkantsidis, M. Peinado, G. Mainar-Ruiz, and M. Russinovich. VC3: Trustworthy data analytics in the cloud. In IEEE S&P, 2015.

[35] B. Sengupta, S. Bag, S. Ruj, and K. Sakurai. Retricoin: Bitcoin based on compact proofs of retrievability. In ICDCN, 2016.

[36] H. Shacham and B. Waters. Compact proofs of retrievability. Journal of cryptology, 2013.

[37] E. Shi, E. Stefanov, and C. Papamanthou. Practical dynamic proofs of retrievability. In CCS, 2013.

[38] J. Xu and E.-C. Chang. Towards efficient proofs of retrievability. In ASIACCS, 2012.

[39] I. N. Yezhkova. Worldwide and U.S. enterprise storage systems forecast update, 2015-2019. White Paper. 2015.

[40] F. Zhang, E. Cecchetti, K. Croman, A. Juels, and E. Shi. Town Crier: An authenticated data feed for smart contracts. In CCS, 2016.

### Appendix

#### A. Notation Table

A table of notations used throughout the paper is provided in Table 1.

**Table 1: Summary and descriptions of the notations used throughout the paper.**
- **Group I:** Parameters to be decided in the setup phase.
- **Group II:** Parameters and variables involved in the audit phase.
- **Group III:** Security metrics of our construction.

| Notation | Description |
|----------|-------------|
| \( n \) | Number of blocks in the original file \( F \) |
| \( s_0 \) | Block size of \( F \) |
| \( c \) | Expansion rate due to error-erasure code |
| \( m \) | Number of encoded blocks; \( m = (1 + c) \times n \) |
| \( s \) | Authenticated block size; \( s = s_0 + b \) |
| \( b \) | Bit length of authentication tags (MACs) |
| \( h \) | Total file expansion factor; \( h = \frac{m \times s}{n \times s_0} \) |
| \( v \) | Audit size (i.e., number of challenge-responses) |
| \( d \) | Latency threshold |
| \( l \) | Late delivery threshold |
| \( q_i \) | \( i \)-th challenge |
| \( f_i \) | \( i \)-th response |
| \( t_i \) | Measured latency of \( i \)-th response |
| \( \psi \) | False acceptance rate |
| \( \gamma \) | False rejection rate |

**Group I:**
- \( n \)
- \( s_0 \)
- \( c \)

**Group II:**
- \( m \)
- \( s \)
- \( b \)
- \( h \)
- \( v \)
- \( d \)
- \( l \)
- \( q_i \)
- \( f_i \)
- \( t_i \)

**Group III:**
- \( \psi \)
- \( \gamma \)

#### B. Related Notions

##### B.1 Proofs of Retrievability

Proof of retrievability (PoR) [26] enables the data owner to audit the storage server on data preservation. In PoR protocols, the data owner encodes the original data using a redundant encoding (such as the error-erasure Reed-Solomon code [33]) and authenticates all the blocks of the encoded data before sending them to the storage server. Due to the redundant encoding, the storage provider must discard a considerable portion of the blocks to cause data loss.