32
(a) c = 10%
(b) c = 20%
(c) c = 40%
Figure 7: Eﬀect of the late delivery threshold l on the se-
curity in N-ResCheck. MAC length is set to 16 bits, and
audit size is v = 300 challenges.
to 1.4 × 10−36 in E-ResCheck when c = 40%. The reduc-
tion becomes less evident as b approaches 16 bits. Further
increasing b does not result in better false acceptance rate.
With 16 bits MAC and the block size is set to 64 bytes as
suggested in the previous set of experiments, the expansion
rate due to authentications tags is as small as 3%.
Comparing across ﬁgures, it is evident that larger c leads
to lower false acceptance rate and hence better security.
Moreover, the false acceptance rate of E-ResCheck is con-
sistently smaller than that of N-ResCheck, suggesting
E-ResCheck oﬀers better security guarantee.
We note that the use of short authentication tags (e.g.
16 bits MAC) does not compromise the ability to detect
an adversary who incurs data loss (i.e. keeping less than n
data blocks). For example, with parameter setting of c =
40%, v = 300 and 16 bits MAC, the probability that such
adversary escapes the detection is less than 2−145.
7.4 Effect of late delivery threshold (l)
In the third set of experiments, we ﬁx the MAC length at
16 bits, the audit size at v at 300 challenges, and investigate
the eﬀect of late delivery threshold l on the false acceptance
rate ψ and the false rejection rate γ.
Figure 6 shows the results for E-ResCheck, and Figure 7
for N-ResCheck. As l increases from two to 32, the false
rejection rate γ drops exponentially – by upto 22 orders of
magnitude for N-ResCheck and almost 50 orders of magni-
tude for E-ResCheck. This suggests it is possible to make
the scheme more tolerable to environment noise.
However, increasing l leads to the growth of the false ac-
ceptance rate ψ. For both implementations, ψ grows by
eight to 16 orders of magnitude when l increases from two
to 16, depending on the code rate of the error-erasure code
in use. In particular, when c = 10% and the late delivery
threshold is set to 32, ψ raises upto 0.7.
We suggest the late delivery threshold l to be set to eight,
attaining γ as small as 5×10−10, while still keeping ψ smaller
10−3
10−5
10−7
10−9
10−11
ψ γ
200
250
300
v
350
400
10−7
10−11
10−15
10−19
10−23
200
10−6
10−17
10−28
10−39
10−50
200
ψ γ
250
300
v
350
400
ψ γ
250
300
v
350
400
(a) c = 10%
(b) c = 20%
(c) c = 40%
Figure 8: Eﬀect of audit size v on the security in
E-ResCheck. MAC length is set to 16 bits, and late deliv-
ery threshold is set to eight.
10−2
10−4
10−6
10−8
10−10
200
ψ γ
250
300
v
350
400
10−5
10−11
10−17
10−23
200
ψ γ
250
300
v
350
400
102
10−11
10−24
10−37
10−50
200
ψ γ
250
300
v
350
400
(a) c = 10%
(b) c = 20%
(c) c = 40%
Figure 9: Eﬀect of audit size v on the security in
N-ResCheck. MAC length is set to 16 bits, and late deliv-
ery threshold is set to eight.
than 10−6 even for c = 10%. We note that for the same
parameter setting, ψ drops exponentially when c increases.
For examples, in E-ResCheck, ψ reduces by upto 30 orders
of magnitude when c increases from 10% to 40%.
7.5 Effect of audit size (v)
In the last set of experiments, we study the eﬀect of audit
size v on the overall security. We ﬁx the MAC length at
16 bits, late delivery threshold at eight and examine how v
eﬀects ψ and γ. The results are reported in Figure 8 (for
E-ResCheck) and 9 (for N-ResCheck). For E-ResCheck,
ψ reduces by eight to 26 orders of magnitude when v varies
from 200 to 400. Likewise, the reduction in N-ResCheck is
similar. This suggests that we can make the false acceptance
rate ψ arbitrarily small by increasing the audit size (i.e. is-
suing more challenges). Though expanding the audit size
leads to larger communication costs in N-ResCheck, the
actual increase is only in KBs, which is reasonable. Note
that E-ResCheck does not require transferring the chal-
lenges and responses over the network, thus incurring no
network communication overhead.
Nevertheless, we observe that as v expands from 200 to
400 challenges, γ increases from 1.3 × 10−11 to 6.1 × 10−9
(almost 450×) in E-ResCheck and from 4.6 × 10−4 to
3.7 × 10−2 (by 80×) in N-ResCheck. While the incre-
ment of γ in E-ResCheck is much larger than that in
N-ResCheck, the former witnesses the false rejection rate
of only 6.1× 10−9, several orders of magnitude smaller than
the corresponding value of the latter. The reason for such
increases is because larger audit size leads to greater ex-
posure to the environment noise; and the noise introduced
by network transmission is much greater than that of the
housekeeping operations at OS level in the E-ResCheck.
It is evident across all experiments that E-ResCheck is
superior to N-ResCheck. It oﬀers better false acceptance
and rejection rates, incurs no network communication over-
head, and is less exposed to the environment noise.
8. RELATED WORKS
Proofs of Retrievability. Proofs of retrievability were
ﬁrst proposed by Juels and Kaliski [26], and have been fol-
lowed by various works [36, 16, 38]. While these works ad-
dress similar problems – auditing a remote and untrusted
storage server on data preservation – they diﬀer in their se-
curity models. A closely related technique is PDP, initially
discussed by Ateniese et al. [13], assuring that most (but not
necessarily all) of the data are stored. Later on, the notions
of PoR and PDP are also extended to dynamic settings [37,
21]. While there are various eﬃcient constructions in the lit-
erature [26, 36], none of them has taken the location of data
into consideration. PoDR attains a proof that the original
ﬁle F is retrievable in its entirety from data stored locally
at the storage provider’s server.
Timed Challenge-Response Protocols.
Timed
challenge-response protocols have been studied in various
application scenarios. Bowers et al. [17] presented a remote
assessment of fault tolerance based on measuring the re-
sponse latency of read request for a collection of ﬁle blocks.
In such an assessment, it is assumed that network latency
can be accurately estimated and deemed as a constant. Our
model assumes that the network latency is probabilistic,
only its distribution can be determined.
Gondree et al.[22] proposed a framework that employs a
set of known landmarks to verify the storage geolocation.
Benson et al.
[15] investigated the correlation of network
latency and geographical distance, and suggested the use of
such technique in verifying replications of the data across
geographically separated datacenters. Our construction, on
the other hand, focuses on verifying residency of the data on
the server-in-question. Moreover, while those proposals ad-
vocate minimising server-side computation due to practical
concerns on usability and for cost-saving, we discuss such re-
quirement from security perspective. Further, we stress the
impact of block size on the security of the protocol, which
has not been studied in previous works.
Locality of Storage. Incentives for storing data locally
have also been discussed by recent new cryptocurrency pro-
posals [27, 35]. These proposals require constructing a proof
of retrievability during the mining, which in turn is designed
to encourage miners to store data locally as opposed to out-
sourcing them to a remote storage. While these works share
with ours a concern on storage location, they only incentivise
local preservation of the data instead of enforcing such re-
quirement. PoDR, on the other hand, imposes local preser-
vation of the data and oﬀers an auditing mechanism to de-
tect storage providers who do not follow the stipulation.
Protected Execution Environment. Various works
have relied on trusted computing to provision the protected
execution environment for secure services [19, 34, 14]. By
making a realistic assumption on the presence of the trusted
environment, these works are able to oﬀer security with ef-
ﬁciency and at scale. Besides the trusted execution envi-
ronment, our construction employs a co-location of veriﬁer
and the prover, which is made feasible by trusted computing
primitives, to enhance security.
9. CONCLUSION
We have deﬁned the security deﬁnition of Proofs of Data
Residency. PoDR enables the data owner to obtain a proof
that the ﬁle F is retrievable in its entirety from local drives of
11
a storage server in-question. PoDR can be an integral com-
ponent in auditing contractual assurances. In particular, it
can be combined with host geolocating to aﬃrm geolocation
of the data, or utilised to access fault tolerance of a storage
system, by checking the residency of the ﬁles at diﬀerent
separate storage servers. We show potential attacks on inse-
cure constructions and propose a secure PoDR scheme. The
two implementations of the proposed construction, namely
N-ResCheck and E-ResCheck, illustrate an interesting
use-case of trusted computing, wherein having the veriﬁer
of a cryptographic protocol co-locating with the prover en-
hances the security.
The focus of this work has been on a static setting where
the data owner does not frequently update F .
It would
be an interesting future work to extend our construction to
support dynamic data updates.
Acknowledgements
This research is supported by the National Research Foun-
dation, Prime Minister’s Oﬃce, Singapore under its Corpo-
rate Laboratory@University Scheme, National University of
Singapore, and Singapore Telecommunications Ltd.
10. REFERENCES
[1] Australian privacy act. http://www.austlii.edu.au/au/
[2] Business Insider. Amazon(cid:48)s cloud crash disaster
legis/cth/consol act/pa1988108/.
permanently destroyed many customers data.
http://www.businessinsider.com/
amazon-lost-data-2011-4?IR=T&r=US&IR=T.
[3] Data protection directive. http://eur-lex.europa.eu/
legal-content/EN/TXT/?uri=URISERV%3Al14012.
[4] Google Drive. https://www.google.com/drive/.
[5] Ibm 4764 pci-x cryptographic coprocessor.
http://www-03.ibm.com/security/cryptocards/pcixcc/
overview.shtml.
[6] Intel SGX. https://software.intel.com/en-us/sgx.
[7] Intel SGX programming reference.
https://software.intel.com/sites/default/ﬁles/
managed/48/88/329298-002.pdf.
[8] Intel SGX SDK for Linux.
https://github.com/01org/linux-sgx.
[9] Intel Skylake processor. http:
//ark.intel.com/products/codename/37572/Skylake.
[10] PsPing. https://technet.microsoft.com/en-us/
sysinternals/psping.aspx.
[11] Traceroute. http://linux.die.net/man/8/traceroute.
[12] I. Anati, S. Gueron, S. Johnson, and V. Scarlata.
Innovative technology for cpu based attestation and
sealing. In HASP, 2013.
[13] G. Ateniese, R. Burns, R. Curtmola, J. Herring,
L. Kissner, Z. Peterson, and D. Song. Provable data
possession at untrusted stores. In CCS, 2007.
[14] A. Baumann, M. Peinado, and G. Hunt. Shielding
Applications from an Untrusted Cloud with Haven. In
OSDI, 2014.
[15] K. Benson, R. Dowsley, and H. Shacham. Do you
know where your cloud ﬁles are? In CCSW, 2011.
[16] K. D. Bowers, A. Juels, and A. Oprea. Proofs of
retrievability: Theory and implementation. In CCSW,
2009.
12
[17] K. D. Bowers, M. Van Dijk, A. Juels, A. Oprea, and
R. L. Rivest. How to tell if your cloud ﬁles are
vulnerable to drive crashes. In CCS, 2011.
[18] G. Connolly, A. Sachenko, and G. Markowsky.
Distributed traceroute approach to geographically
locating ip devices. In IDAACS, 2003.
[19] T. T. A. Dinh, P. Saxena, E.-C. Chang, B. C. Ooi,
and C. Zhang. M2R: Enabling stronger privacy in
mapreduce computation. In USENIX Security, 2015.
[20] Y. Dodis, S. Vadhan, and D. Wichs. Proofs of
retrievability via hardness ampliﬁcation. In Theory of
cryptography. 2009.
[21] C. Erway, A. K¨up¸c¨u, C. Papamanthou, and
R. Tamassia. Dynamic provable data possession. In
CCS, 2009.
[22] M. Gondree and Z. N. Peterson. Geolocation of data
in the cloud. In CODASPY, 2013.
[23] K. Harrenstien, M. K. Stahl, and E. J. Feinler.
NICNAME/WHOIS. RFC-954, 1985.
[24] C. Houri. Method and systems for locating
geographical locations of online users, 2003. US Patent
6,665,715.
[25] H. Jiang and C. Dovrolis. Passive estimation of TCP
round-trip times. ACM SIGCOMM, 2002.
[26] A. Juels and B. S. Kaliski Jr. PORs: Proofs of
retrievability for large ﬁles. In CCS, 2007.
[27] A. Miller, A. Juels, E. Shi, B. Parno, and J. Katz.
Permacoin: Repurposing bitcoin work for data
preservation. In IEEE S&P, 2014.
[28] M. Naor and G. N. Rothblum. The complexity of
online memory checking. In FOCS, 2005.
[29] V. N. Padmanabhan and L. Subramanian. An
investigation of geographic mapping techniques for
internet hosts. In SIGCOMM, 2001.
[30] Z. N. Peterson, M. Gondree, and R. Beverly. A
position paper on data sovereignty: The importance of
geolocating data in the cloud. In HotCloud, 2011.
[31] J. Postel. User datagram protocol. 1980.
[32] J. Postel. Transmission control protocol. 1981.
[33] I. S. Reed and G. Solomon. Polynomial codes over
certain ﬁnite ﬁelds. J. SIAM, 1960.
[34] F. Schuster, M. Costa, C. Fournet, C. Gkantsidis,
M. Peinado, G. Mainar-Ruiz, and M. Russinovich.
VC3: Trustworthy data analytics in the cloud. In
IEEE S&P, 2015.
[35] B. Sengupta, S. Bag, S. Ruj, and K. Sakurai.
Retricoin: Bitcoin based on compact proofs of
retrievability. In ICDCN, 2016.
[36] H. Shacham and B. Waters. Compact proofs of
retrievability. Journal of cryptology, 2013.
[37] E. Shi, E. Stefanov, and C. Papamanthou. Practical
dynamic proofs of retrievability. In CCS, 2013.
[38] J. Xu and E.-C. Chang. Towards eﬃcient proofs of
retrievability. In ASIACCS, 2012.
[39] I. N. Yezhkova. Worldwide and U.S. enterprise storage
systems forecast update, 2015-2019. White Paper.
2015.
[40] F. Zhang, E. Cecchetti, K. Croman, A. Juels, and
E. Shi. Town Crier: An authenticated data feed for
smart contracts. In CCS, 2016.
APPENDIX
A. NOTATION TABLE
A table of notations that are used throughout the paper
is shown in Table 1.
Table 1: Summary and descriptions of the notations that
are used throughout the paper. Group I are parameters to
be decided in the setup phase. Group II are parameters
and variables involved in the audit phase. Group III are the
security metrics of our construction.
Notation
Description
n
s0
c
m
s
b
h
v
d
l
qi
fi
ti
ψ
γ
number of blocks in the original ﬁle F
F ’s block size
expansion rate due to error-erasure code
number of encoded blocks; m = (1 + c) × n
authenticated block size; s = s0 + b
bit length of authentication tags (MACs)
total ﬁle expansion factor; h = (m × s)/(n × s0)
audit size (i.e. number of challenge-responses)
latency threshold
late delivery threshold
ith challenge
ith response
measured latency of ith response
false acceptance rate
false rejection rate
I
II
III
B. RELATED NOTIONS
B.1 Proofs of Retrievability
Proof of retrievability [26] enables the data owner to audit
the storage server on the data preservation. In PoR proto-
cols, the data owner encodes the original data using a re-
dundant encoding (such as the error-erasure Reed-Solomon
code [33]), authenticates all the blocks of the encoded data
before sending them to the storage server. Due to the redun-
dant encoding, the storage provider has to discard a consid-
erable portion of the blocks to cause data loss. However, if