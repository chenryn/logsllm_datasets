of code assumes that it is not randomized. It should absolutely
be randomized, but this is presently left for future work.
The probability that an attacker’s payload will be emitted
as expected if it requires k out of n randomized registers to
be correctly mapped is (n − k)!/n!.
B. Constant blinding
Most constant blinding implementations observed in real-
world code only blind a limited subset of instructions or
untrusted constants, presumably under the rationale that some
instructions and constants are harmless and therefore rep-
resent unnecessary overhead if blinded. Our implementa-
tion blinds every untrusted (meaning that it appears in the
JavaScript code) integer and ﬂoating point constant. Un-
trusted constants only appear in Baseline JIT code as val-
ues that are loaded into registers; we protect Baseline JIT
code by blinding those load instructions using the canoni-
cal mov reg, blinded_val; xor reg, secret in-
struction sequence, where secret is an immediate with a
unique7 32-bit random value, and blinded_val is an imme-
diate whose value is secret ⊕ untrusted_constant.
We implement constant blinding for IonMonkey by in-
jecting blinding instructions into the architecture-independent
intermediate representation (IR) called MIR. MIR is compiled
from SpiderMonkey’s interpreter bytecode, optimized, lowered
to an architecture-dependent IR, then ﬁnally compiled to native
code. During construction of the MIR code, we tag constants
found in the bytecode as untrusted so that we avoid blinding
constants generated by the compiler that were not present
in the JavaScript. After the MIR has been optimized, we
7Unlike some constant blinding implementations (e.g., V8) which share the
same secret value among constants within the same compilation unit, ours
generates a fresh secret for each constant.
(a) Unrandomized
(b) Randomized
Fig. 6: Baseline JIT call stacks with and without call frame
randomization. Stacks grow downward.
replace untrusted constants that remain with a sequence of
MIR instructions that implement constant blinding in the same
XOR-based manner as the Baseline JIT’s constant blinding. It
is important to apply constant blinding only after optimizations
have completed to avoid potential constant folding optimiza-
tions, which would undo the blinding.
In order to predict the code sequences that will be generated
for any given untrusted k-bit constant, the attacker must guess
each corresponding secret bit, for which she has a success
probability of 2−k. Since all constants are blinded with unique
secrets, the attacker’s probability of predicting the code for the
n untrusted constants, each k bits long, needed for her JIT
spraying payload is 2−kn.
C. Call frame randomization
SpiderMonkey’s Baseline JIT and IonMonkey JIT use very
different call frame conventions requiring different treatment
to randomize. The Baseline JIT uses a frame pointer relative
to which all call frame elements are accessed and pushes
outgoing function arguments onto the stack as part of its
implementation of a stack-based virtual machine. IonMonkey,
on the other hand, performs frame pointer omission (i.e., call
frame elements are accessed relative to the stack pointer)
and pre-allocates enough stack space during each function
prologue to ﬁt the maximum number of outgoing function
call arguments across all calls within that function. For both
Baseline and IonMonkey call frames, we randomly shift the
frame pointer and stack pointer, respectively, relative to the
call frame elements. Whenever possible, we also permuted
call frame elements of the same type, and when neither of the
above was possible, we performed a process similar to constant
blinding to the load/store instructions accessing the call frame.
1) Baseline JIT: Figure 6a illustrates the layout of an
unrandomized Baseline JIT call frame. All elements shown are
accessed at statically-computed frame pointer-relative offsets.
Baseline JIT code stores three types of local variables on the
stack above the frame pointer, and we randomize their offsets
by permuting their orders within each type and randomly
increasing the size of the bookkeeping data structure pushed
onto the stack before them, shown as the dotted box in
11
Previous Frame InfoSaved FPBookkeepingdataLocal VarsBody-level Lexical-scopedBlock-levelLexical-scopedFramePointerIncomingArgsStackPointer}Previous Frame InfoSaved FPBookkeepingdataLocal VarsRandom PaddingIncomingArgsPermuteBody-level Lexical-scopedPermuteBlock-levelLexical-scopedPermuteFramePointerStackPointerOﬀsetsblinded}OﬀsetsblindedFigure 6b labeled “Random Padding.” The size of this padding
is determined for each function at JIT compile time and is
between 0 and 15, inclusive, units of stack alignment (the
size of which is 8 bytes for ARM32 and MIPS32 and 16
bytes otherwise). Because that does not change the frame
pointer’s relative offset to the incoming function arguments
and “Previous Frame Info,” we modify instructions that access
them in a manner similar to constant blinding. Rather than
accessing those elements at ﬁxed offsets relative to the frame
pointer, each access site populates a scratch register with the
value of the frame pointer minus a unique random multiple of
4 in the range [0, 64)8 and performs the access using a new
offset that corrects for the shifted base register value.
We do not shift the incoming arguments by injecting stack
padding between them and the frame pointer location because
the great complexity of the code that traverses and unwinds the
call stack makes doing so very difﬁcult. Similarly, we do not
permute incoming arguments on the stack because of the com-
plex interactions between their stack positions and SpiderMon-
key’s implementaion of JavaScript features like rest parame-
ters, default parameters, and the arguments object. However,
permuting call frame elements is secondary to shifting their
offsets since permutation without shifting is vulnerable to the
corner case where there is only one element to permute.
1
An attacker is only able to predict the blinding offset of an
incoming argument access site with probabiity 1
16. Therefore,
if an attack relies on reusing n incoming argument access sites,
there is only a
16n chance that she will be able to predict all
necessary access site offsets. The deviation of the frame pointer
offset of a local variable or body/block-level lexically-scoped
variable from its unrandomized value can be interpreted as the
linear combination of independent discrete uniform random
variables. In particular, if there are n variables of a certain
type (local, body-level lexical, or block-level lexical), the offset
shift of the ith (0 ≤ i < n) variable of that type, is given by
Zi = −(Xi + Y ), where Xi is the shift due to permutation
and is distributed as Xi ∼ 8 · (U{0, n − 1} − i); and Y is
the shift due to padding the bookkeeping data structure and is
distributed as Y ∼ a · U{0, m − 1}, where a is the size of a
unit of stack alignment in bytes (which varies by architecture),
and m is the number of possible padding amounts (m = 16
for our implementation).
2) IonMonkey JIT: Figure 7a shows the IonMonkey call
frame layout. Since IonMonkey performs frame pointer omis-
sion, and all call frame elements are below the stack pointer,
we can shift all call frame accesses by pushing a random
amount of padding—whose size is determined once for each
compilation unit at JIT compile time—on top of the call frame.
The size of the padding is between 0 and 15, inclusive, units
of stack alignment (the size of which is 8 bytes for ARM32
and MIPS32 and 16 bytes otherwise). IonMonkey does not
store local values on the stack unless they must be spilled due
to register contention; we permute the order that these spilled
values are allocated to stack slots. Figure 7b illustrates the ap-
plication of these randomizations to an IonMonkey call frame.
Since the stack pointer-relative offset of all non-spill values
is shifted by a common value, an attacker’s probability of
8We use a multiple of 4 because the ARM code generation backend can
compile an optimized instruction sequence for certain cases where the offset
is a multiple of 4.
12
(a) Unrandomized
(b) Randomized
Fig. 7: IonMonkey call stacks with and without call frame
randomization. Stacks grow downward.
Fig. 8: Probability that attacker’s best guess correctly predicts
the number of random NOPs inserted in n instructions.
guessing any number of non-spill value offsets is reduced by a
factor of 16. Spilled values have their values shifted according
to a distribution similar to the one described above for Baseline
JIT locals and lexically-scoped variables. One difference is that
spilled values may have varying sizes that are a multiple of 4
bytes, so the permutation distribution is not uniform.
D. Random NOP insertion
Our implementation of random NOP insertion places a
single NOP instruction before each intended instruction with
8. There is a small handful of exceptions
probability p = 1
where random NOP insertion must be disabled due to assump-
tions in the JIT’s implementation regarding the precise layout
of a section of emitted code.
Random NOP insertion’s security beneﬁt depends on the
attacker’s needs. If the attacker needs to predict the offset
of the nth instruction from the beginning of its unit of code
compilation, she must predict the number of NOPs that will be
inserted before it, given by the random variable X ∼ B(n, 1
8 ).
The attacker’s best guess is the mode of X; the probability
that this best guess will be correct as a function of n is shown
in Figure 8.
Alternately, an attacker might require n consecutive in-
structions with no random NOPs inserted between them (e.g.,
when the payload uses instructions decoded at unintended
instruction boundaries as in [7]), which occurs with probability
(1 − p)n−1 =(cid:0) 7
(cid:1)n−1.
8
Previous FrameInfoSpilled valuesIncomingArgsOutgoingArgsStackPointerPrevious FrameInfoRandom PaddingIncomingArgsOutgoingArgsSpilled valuesPermuteStackPointer100101102103Number of instructions (log)0.00.10.20.30.40.50.60.70.80.9ProbabilityTABLE III: Geometric mean of code size increases incurred
by diversiﬁcation defenses when executing benchmark suites
x86-64
32-bit ARM
Register randomization
Constant blinding
Call frame randomization
Random NOP insertion
Base offset randomization
All
-0.008%
0.433%
2.79%
2.67%
2.39%
8.57%
1.01%
1.56%
1.31%
12.58%
2.52%
18.15%
E. Base offset randomization
Whenever SpiderMonkey needs to ﬁnd space to place a unit
of code compilation, it rounds up the size of the JIT code to
an architecture-speciﬁc alignment granularity G and searches
memory pools of allocated code memory for free space to
accomodate the rounded size. We randomize the base offsets
of each unit of code compilation by randomly increasing the
size of its allocation request by rG where r ∈ {0, 1, 2, ..., 15}
and shifting the code rG bytes further into the allocation. The
attacker’s probability of guessing the base offset shifts for n
consecutive units of code compilation is(cid:0) 1
(cid:1)n.
16
F. Benchmark results
We evaluated the performance overheads of our implemen-
tations on x86-64 and 32-bit ARM using the SunSpider 1.0.1,
Kraken 1.1, and Octane v.2 benchmarks suites. Results for x86-
64 were gathered on a quad-core Intel Core i7-870 2.93GHz
processor with 16GB RAM running Ubuntu 14.04.2 LTS
with kernel version 3.13.0-49-generic. Results for 32-bit ARM
were gathered on an octa-core AppliedMicro APM883208-X1
ARMv8 2.4GHz processor with 16GB RAM running 32-bit
Debian 8.0 in a chroot jail on APM Linux with kernel version
3.12.0-mustang sw 1.12.09-beta.
To evaluate our implementations, we built an unmodiﬁed
version of SpiderMonkey and a separate binary for each
diversiﬁcation mechanism. We also built a binary that de-
ploys all implemented defenses. We executed each benchmark
suite 100 times for each binary and computed the arithmetic
means for each group of 100 benchmark scores. We computed
the overhead imposed on the results of “smaller-is-better”
benchmarks (SunSpider and Kraken) as ¯v/¯u − 1, where ¯v
is the arithmetic mean of the 100 benchmark scores for a
particular modiﬁed binary, and ¯u is the arithmetic mean of the
100 benchmark scores for the unmodiﬁed binary. Octane is a
“bigger-is-better” benchmark whose scores are derived from a
“smaller-is-better” measurement by dividing a constant value
by the measurement, so we compute the overhead on its results
as ¯u/¯v − 1.
The measured overheads of our implementations are shown
in Table II. We used Welch’s unequal variances t-test to test
the mean benchmark score from each variant’s 100 execution
sample against the mean benchmark score from the unmodi-
ﬁed binary’s 100 execution sample and indicate statistically-
signiﬁcant (p <0.05) changes to the mean by printing the cor-
responding overhead with boldface type. Note that overheads
are not independent and cannot necessarily be added.
13
G. Code size increase
To measure the impact of our mitigation implementations
on the memory demands of the JIT, we instrumented Spi-
derMonkey to emit the ﬁle name, line number, and number
of JIT code bytes used each time unit of code compilation
is compiled and executed the three benchmark suites once
on each binary variant. Let ¯vi be the average code size of
the ith ﬁle name-line number pair, as emitted by a binary
variant implementing a one or more diversiﬁcation defenses;
let ¯ui represent the average code size for the ith ﬁle name-
line number pair, as emitted by an unmodiﬁed SpiderMonkey
binary. We compute the increased memory usage for each
i=1( ¯vi/ ¯ui) − 1. Table III shows the code size
increases for each mitigation, broken down by architecture.
variant as n(cid:112)(cid:81)n
H. Concrete security analysis
In order to give concreteness to the security beneﬁts offered
by our diversiﬁcation defense implementations, we report on
our analysis of the estimated relative success probability of
four concrete JIT spraying attacks when launched against
individual diversiﬁcation mitigations. The results are shown
in Table IV. Remember that since some defenses may interact
with one another, these relative probabilities may not neces-
sarily be combined by multiplication.
Our estimates are conservative;
in order to make the
relative probabilities concrete, we have made assumptions in
the attacker’s favor when necessary. For example, random NOP
insertion can disrupt Blazakis’ JIT spray by causing its NOP
sled to resynchronize to the intended instruction stream, but the
probability of at least one NOP interrupting execution depends
on how many uninterrupted instructions the attacker requires,
including the NOP sled. This in turn depends on where in the
NOP sled the attacker’s control ﬂow vulnerability happens to
divert control. Therefore, we conservatively assume that the
attacker’s control ﬂow vulnerability directs execution to the
head of the shellcode and only compute the probability that
a NOP will not be inserted into the sequence of instructions
needed to encode a very short 10-instruction shellcode. We
consider minor adaptations to the existing attacks that allow
them to use the most
likely diversiﬁcation outcome when
possible, but we do not claim to have considered the most
optimized versions of each attack. Lastly, the values shown in
Table IV only reﬂect the relative success of a single instance
of the sprayed function.
Constant blinding, which incurs the greatest runtime over-
head among the surveyed diversiﬁcation defenses, performs
tremendously well to mitigate [7], [17], and the self-sustaining
ARM payload (§III-C), which rely on attacker-chosen con-
stants appearing in JIT code. We also observe that register
randomization and call frame randomization complement con-
stant blinding by diversifying compiler-chosen operands, relied
upon heavily by our V8 attack.
We were surprised to ﬁnd that register randomization
provided little defense against [7]. Blazakis’ attack is able to
fare well against register randomization because the attacker’s
payload is an unintended instruction stream (cf. § II) that skips
over intended instruction opcodes (the XOR opcode, in the
case of Blazakis’ attack) as long as the number of bytes to
be skipped is correctly predicted. The x86 XOR instruction’s
opcode is either 1 byte long when XORing against %eax or
TABLE II: Diversiﬁcation performance overheads. Bold typeface in non-geometric mean columns denotes statistically-signiﬁcant
impact on the mean benchmark score of each 100-execution sample (Welch’s unequal variances t-test, p <0.05); and negative
overheads indicate improved performance. *Register randomization overhead for x86-64 only includes IonMonkey randomization.
x86-64
32-bit ARM
Register randomization*