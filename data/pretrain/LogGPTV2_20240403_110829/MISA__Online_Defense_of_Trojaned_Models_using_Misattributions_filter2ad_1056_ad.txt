2.62
1.6
5.31
0.6
0.0
2.81
Final FPR
Intermediate
Layer
12.08
12.74
13.08
11.27
12.92
13.69
14.43
13.4
21.63
15.37
9.31
14.72
Figure 10: Fashion MNIST: Example of Trojaned models
where the entropy distributions produced by STRIP overlap
significantly.
summarizes our results over different trigger types. We observe
that applying our method to an intermediate layer significantly
improves the detection of large triggers (5x5, 8x8) and triggers in
the center of the image. Additionally, smooth triggers and Instagram
0.51.01.50.00.1Probability (%)GTSRBnormalized entropy(Trigger at the top)without trojanwith trojan010.00.2Probability (%)GTSRBnormalized entropy(Trigger in the center)without trojanwith trojan010.00.1Probability (%)GTSRBnormalized entropy(Trigger at the bottom)without trojanwith trojan010.00.2Probability (%)GTSRBnormalized entropy(Spread-out trigger)without trojanwith trojan0120.00.2Probability (%)GTSRBnormalized entropy(Instagram Filter)without trojanwith trojan0120.00.1Probability (%)GTSRBnormalized entropy(Dynamic)without trojanwith trojan0.51.00.00.1Probability (%)Fashion MNISTnormalized entropy(Trigger on the top)without trojanwith trojan0120.00.1Probability (%)Fashion MNISTnormalized entropy(Trigger in the center)without trojanwith trojan0120.000.050.10Probability (%)Fashion MNISTnormalized entropy(Trigger on the bottom)without trojanwith trojan0.00.20.40.60.81.0False Positive Rate0.00.20.40.60.81.0True Positive RateMNISTROC CurveMISA (AUC:0.97)STRIP (AUC:0.9)0.00.20.40.60.81.0False Positive Rate0.00.20.40.60.81.0True Positive RateGTSRBROC CurveMISA (AUC:0.99)STRIP (AUC:0.87)577MISA: Online Defense of Trojaned Models using Misattributions
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
filters can only be detected using intermediate-layer attributions.
Moreover, our method is first applied at the input layer. If the input-
layer attributions classify the image as clean, we proceed to apply
our method to the next activation layer of the neural network, and
repeat until no layer can identify the input as Trojaned (Alg. 3).
We examine the effect of using different layers to attribute the
decision (Stage 1) and apply our method. For 23 different GTSRB
Trojaned models, we scan all activation layers and investigate the
effectiveness of each of these layers when used to detect the Tro-
janed images. We observe that not all activation layers can reveal
the Trojan trigger. For example, layer 15 can identify the Trojan
trigger across 23 different Trojaned models of different types of trig-
gers. However, layer 20 cannot detect any of these Trojan triggers.
Table 4: Use of different activation layers to detect Trojaned
GTSRB models.
Activation Layer
1
5
8
12
15
20
94.19
94.96
92.13
98.89
90.56
0.18
Final TPR Final FPR
39.14
23.66
37.93
16.02
31.44
0.0
4.4 Ablation Studies
This section examines our approach’s ability to detect Trojans
when we remove (a) Stage 1 & Stage 3, (b) Stage 2 or (c) Stage 3.
Removing Stage 1 & Stage 3 corresponds to removing the use of
attributions. In this case, we train an SVM directly on raw images or
raw intermediate-layer features while there is no attribution map
in order to apply the extract-and-evaluate step. We then observe if
the SVM can separate Trojaned images from clean images based on
raw features. Removing Stage 2 corresponds to removing the SVM
and directly applying the extract-and-evaluate step for every image
we encounter. Finally, removing Stage 3 corresponds to relying on
the SVM only to identify the Trojaned images.
4.4.1 Removing Stage 1 & Stage 3. We present the results of train-
ing an SVM directly on raw images or intermediate-layer features
instead of attributions over a representative set of models. When
we remove Stage 1 we cannot extract the trigger. Therefore, Stage
3 cannot be applied. Therefore, in this step we compare the SVM
TPRs and FPRs against MISA’s SVM. In Table 5, we clearly observe
that the SVM cannot separate clean and Trojaned images based
on input-layer features. Additionally, in Table 6 we train the SVM
on the last activation layer of the neural network. The Activation
Clustering approach [8] proposes to perform clustering on the last
activation-layer features over a set of clean and Trojaned images
to identify whether there is a cluster associated with the backdoor.
In our case, we observe that the last activation-layer clean and
Trojaned features cannot be separated by the SVM, where the TPR
is 70%, and the FPR is as high as 100%. On the contrary, using attri-
butions to train an SVM is much more effective in identifying the
Trojaned images while keeping the FPR close to 70%.
Table 5: Results of removing Stage 1 & Stage 3, that is, use an
SVM trained directly on clean images instead of attributions
to detect the Trojaned images.We compare the SVM TPRs
and FPRs.
No Stage 1 & 3
Input-layer features
MISA
SVM
SVM
Final
MNIST
Fashion
MNIST
CIFAR10
GTSRB
TPR
65.88
43.4
44.3
57.4
FPR
100
100
100
100
TPR
99.5
97.0
100
98.9
FPR TPR FPR
0.9
69.6
0
0.0
2.4
99.6
96.9
96.9
86.1
100
46.9
60.0
Table 6: Results of removing Stage 1 & Stage 3, that is, use an
SVM trained on clean last activation-layer features instead
of attributions to detect the Trojaned images. We compare
the SVM TPRs and FPRs.
Last activation-layer features
No Stage 1 & 3
SVM
MISA
SVM
Final
MNIST
Fashion
MNIST
CIFAR10
GTSRB
TPR
70.0
67.4
63.4
75.8
FPR
70.1
85.0
98.4
100
TPR
99.0
99.0
100
99.2
FPR TPR FPR
0.4
70.5
25.4
71.1
14.6
13.2
90.2
95.0
99.4
96.9
70.3
70.6
4.4.2 Removing Stage 2. The defender has the option to remove
the SVM and apply the extract-and-evaluate approach to every
input that the neural network encounters. This will slow down the
response of the defense in the cases where the clean image would
have been directly classified as clean from the SVM and the extract-
and-evaluate step would not be applied. Additionally, Table 7 shows
that the SVM improves false positives when used before the extract-
and-evaluate step without sacrificing the TPR. Finally, our approach
does not critically depend on the SVM classifier. The SVM classifier
is used to improve FPR at the expense of a small reduction in TPR.
In Fig. 12 we show how different ν values used for training the SVM
Table 7: Results of removing stage 2 applied for 23 different
GTSRB Trojaned models. Removing the anomaly detection
component (1-class SVM) and classifying everything as Tro-
janed in Stage 2 results in a higher False Positive Rate.
No Stage 2
MISA
Final TPR Final FPR Final TPR
97.8 ± 3.9
99.4 ± 1.3
19.1 ± 3.9
Final FPR
12.7 ± 2.9
affect the Final TP and FP rates. We observe that as ν increases, TPR
increases as well. At the same time, the FPR increases significantly
more than the TPR. Additionally, we have observed that increasing
ν for layers such as layer 20 (Table 4) is not going to improve the
578ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Panagiota Kiourti, Wenchao Li, Anirban Roy, Karan Sikka, and Susmit Jha
low TPR. Therefore, the improvement regarding the TPR is not
significant after 0.7, and we suggest using a hyperparameter of
0.7 that facilitates the detection of complicated triggers such as
Instagram filters, and smooth triggers.
Figure 12: Effect of different ν values on the Final TPR, FPR.
4.4.3 Removing Stage 3. In this section, we present the results of
our approach before and after Stage 3 to show the importance of
applying the extract-and-evaluate step. Table 8 shows that the SVM
exhibits a high FPR as discussed in Section 3. After applying Stage
3 we observe a significant drop in the FPR without sacrificing the
TPR.
Table 8: Results of removing Stage 3 averaged over all Tro-
janed models.
No Stage 3
MISA
SVM TPR SVM FPR Final TPR Final FPR
MNIST
Fashion
MNIST
CIFAR10
GTSRB
98.8
99.5
99.16
99.9
71.5
70.9
70.3
71.1
91.2
97.7
98.7
99.4
0.46
27.1
15.0
18.8
4.4.4 Comparison with Grad-CAM-based defenses. In SentiNet [11]
and Februus [12] the authors propose to use saliency maps of the
input in order to identify Trojaned images. However, as we show
earlier in Table 3, input-layer attributions do not provide a good
approximation of the trigger for large (8x8) triggers, triggers in-
jected in the center of the image or spread-out triggers. At the same
time, input-layer attributions cannot contribute to the detection
of Instagram filters, and smooth triggers. Moreover, we observe
that both Februus and SentiNet use saliency maps (Grad-CAM) to
extract attributions. Fig. 13 presents a comparison between Grad-
CAM and DeepSHAP attributions for the same Trojaned image.
Februus suggest to extract the trigger using the saliency features
with values > 0.8. Using this approach we extract clean features
as triggers that don’t include the main part of the Trojan trigger.
Finally, using coarse attributions such as Grad-CAM significantly
drops the TPR, as shown in Table 9.
5 RELATED WORK
Offline Defenses. Offline detection methods analyze the trained
neural network directly to determine whether it is Trojaned. Be-
cause of the absence of any Trojaned image, most of these methods
Figure 13: Comparison between Grad-CAM and DeepSHAP
attribution maps for the same image.
Table 9: Comparison against a method that extracts triggers
using Grad-CAM attributions. We use a GTSRB model that
responds to a square trigger.
No Stage 2 & Grad-CAM
Final TPR
Final FPR
70.7
4.3
MISA
Final TPR Final FPR
100
1.2
make assumptions on the trigger pattern. For example, MESA [37]
utilizes GANs to approximate the unknown distribution of learned