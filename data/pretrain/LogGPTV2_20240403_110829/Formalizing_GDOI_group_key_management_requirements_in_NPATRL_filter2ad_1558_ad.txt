rent. The second describes the intruder learning a key be-
fore another key expires. We call these two cases “backward
inference” and “forward inference.”
BI(K(cid:2)
G, G)
✸learn(P, (), (KG, G), )
∧ ✸( gcks createkey(GCKS , (), (G, KG), )
∧ ✸gcks createkey(GCKS , (), (G, K(cid:2)
G), ))
Note that when a new key is sent, the old key expires.
And, we assume any (non-initial) key is sent in a push-
key message as soon as it is created. Thus BI for K(cid:2)
G
describes an intruder learning a key KG that became
current after a key K(cid:2)
G was current.
FI(KG, G)
G, G), )
✸learn(P, (), (K(cid:2)(cid:2)
∧ ✸( gcks sendpushkey(GCKS , (), (G, KG, K(cid:2)
∧ ✸gcks sendpushkey(GCKS , (), (G, K(cid:2)(cid:2)
FI describes an intruder learning a key K(cid:2)(cid:2)
before a later key KG was generated.
G that expired
G), )
G, K(cid:2)(cid:2)(cid:2)
G ), ))
Backward Inference will be used to specify forward ac-
cess control without backward access control: If an intruder
learns a key KG, then BI(KG, G) will be listed among the
set of possible paths to that event, but not FI(KG, G), that
is, the intruder may have learned KG as a result of learning
a key K(cid:2)
G that expired previously to KG, but not a key K∗
G
that was generated after KG expired. Similarly, Forward
Inference will be used to specify backward access control
without forward access control: if an intruder learns a key
KG, then FI(KG, G) will be listed among the set of of pos-
sible paths to that event, but not BI(KG, G).
We note that there appear to be some major changes from
the original, informal, deﬁnition of forward and backward
access control. The original deﬁnition put the requirement
on the knowledge of any group member, not on the intruder.
Also, the original requirement discussed a member learning a
key as a result of joining the group, while we simply consider
the results of the intruder learning a key without specifying
how it was learned.
Our rationale for changing the focus from member to in-
truder can be expressed in two steps. In the NRL Protocol
Analyzer model, we assume that dishonest group members
can do everything honest group members do and more, since
honest members can only obey the rules of the protocol.
Thus any conditions on a dishonest member’s learning a
key should also hold for an honest member. Secondly, we
assume that all dishonest members share information with
the intruder, so that any conditions on the intruder’s learn-
ing a key would imply the same condition for a dishonest
member learning that information.
2424.5.3
Sample Requirements
In this section, we show how the various “cases” can be
combined into requirements.
Weak Secrecy
The weakest form of secrecy requirement simply requires
that the protocol should protect against key compromise
given the most benign assumptions possible: that is, that
neither pairwise or key encryption keys have been lost, and
no dishonest members have even joined the group. This can
be described in terms of three separate conditions:
learn(P, (), (KG, G), )
→ BC1(K(cid:2)
G, G) ∨ BC2b(K(cid:2)
G, G) ∨ BC3a(K(cid:2)
G, G)
In other words, the intruder should not learn a key KG for G
unless some group key has previously been lost, a dishonest
member joined the group at some time, or a pairwise key
that was used to distribute a group key was stolen, either
before or after being used.
Strong Secrecy
We can also use the base cases to formulate the strongest
type of secrecy possible.
In strong secrecy, the intruder
learns a key KG only if KG is lost, a dishonest member
received KG, either when it joined the group or while it was
a member of the group, or if a pairwise key was stolen and
used to distribute KG. We may or may not wish to require
perfect forward secrecy.
Here, for example, is strong secrecy with perfect forward
secrecy:
→ BC1(KG, G) ∨ BC2a(KG, G) ∨ BC2b(KG, G)
learn(P, (), (KG, G), )
∨ BC3b(KG, G)
Forward Access Control
Forward access control (without backward access control)
can be thought of as strong secrecy together with added
condition of backward inference: An intruder can learn a
key, not only if the key was lost, distributed to a dishonest
member, or distributed using a lost pairwise key, but if the
key became current before the intruder learned a later key,
e.g., because a dishonest member joined the group. We do
not include perfect forward secrecy, since protecting against
old keys being compromised as a result of a stolen pairwise
key makes no sense if the keys could be learned as a result
of a dishonest member joining the group at any point:
→ BC1(KG, G) ∨ BC2a(KG, G) ∨ BC2b(KG, G)
learn(P, (), (KG, G), )
∨ BC3a(KG, G) ∨ BI(KG, G)
Backward Access Control
Backward access control (without forward access control)
can be speciﬁed similarly to forward access control, except
that we replace backward with forward inference. We can
require perfect forward secrecy or not. Here, for example, is
backward access control without forward access control but
with perfect forward secrecy:
→ BC1(KG, G) ∨ BC2a(KG, G) ∨ BC2b(KG, G)
learn(P, (), (KG, G), )
∨ BC3b(KG, G) ∨ FI(KG, G)
If we wanted to omit the perfect forward secrecy requirement
we would substitute BC3a(KG, G) for BC3b(KG, G).
In appendix A we show how to put the requirements for
Forward and Backward Access Control into normal form.
5. CONCLUSIONS
We have presented a set of formal security requirements
for the group protocol GDOI. In developing these require-
ments we learned much, not only about GDOI itself, but
about the nature of requirements for open-ended crypto-
graphic protocols. This has motivated us to develop the
NPATRL requirements language into a full-scale logic that
can be used to reason about and simplify requirements as
well as specify them.
As this paper is being written, we are currently using the
NRL Protocol Analyzer to verify that GDOI satisﬁes these
requirements. This in turn may lead to a revision or im-
provement of the requirements as we discover more by our
analysis. We have also been able to use our formalization of
the requirements to discover and suggest improvements to
GDOI. These suggestions have been incorporated into later
versions of the draft. Thus, we have already found these
requirements to be useful.
6. REFERENCES
[1] M. Baugher, T. Hardjono, H. Harney, and B. Weis.
Group domain of interpretation for ISAKMP.
available at http://search.ietf.org/internet-drafts/
draft-irtf-smug-gdoi-01.txt, January 2001.
[2] R. Canetti, J. Garay, G. Itkis, D. Micciancio,
M. Naor, and B. Pinkas. Multicast security: A
taxonomy and some eﬃcient constructions. In Proc. of
INFOCOM’99, vol. 2, pages 708–716, March 1999.
[3] Brian F. Chellas. Modal Logic: An Introduction.
Cambridge University Press, 1980.
[4] Danny Dolev and Andrew C. Yao. On the security of
public-key protocols. IEEE Transactions on
Information Theory, 2(29):198–208, March 1983.
Preliminary version in Proc. 22nd Annual IEEE Symp.
Foundations of Computer Science, 1981, 350–357.
[5] Naganand Doraswamy and Dan Harkins. IPSEC: The
New Security Standard for the Internet, Intranets, and
Virtual Private Networks. Prentice Hall, 1999.
[6] Robert Goldblatt. Logics of Time and Computation,
2nd edition, volume 7 of CSLI Lecture Notes. CSLI
Publications, Stanford, 1992.
[7] D. Harkins and D. Carrel. The Internet Key Exchange
(IKE). RFC 2409, IETF, November 1998. available at
ftp://ftp.isi.edu/in-notes/rfc2409.txt.
[8] G.E. Hughes and M.J. Creswell. A New Introduction
to Modal Logic. Routledge, 1996.
[9] C. Meadows and P. Syverson. A formal speciﬁcation of
requirements for payment transactions in the SET
protocol. In R. Hirschfeld, editor, Financial
Cryptography, FC’98, pages 122–140. Springer-Verlag,
LNCS 1465, 1998.
[10] Catherine Meadows. A model of computation for the
NRL Protocol Analyzer. In Proceedings of the 7th
Computer Security Foundations Workshop, pages
84–89. IEEE CS Press, June 1994.
[11] Catherine Meadows. The NRL Protocol Analyzer: An
243overview. Journal of Logic Programming,
26(2):113–131, February 1996.
[12] Catherine Meadows. A cost-based framework for
analysis of denial of service in networks. Journal of
Computer Security, 9(1–2):143–164, 2001.
[13] M. Steiner, G. Tsudik, and M. Waidner. Key
agreement in dynamic peer groups. IEEE
Transactions on Parallel and Distributed Systems,
11(8), August 2000.
[14] P. Syverson and C. Meadows. A logical language for
specifying cryptographic protocol requirements. In
Proceedings of the IEEE Computer Society Symposium
on Research in Security and Privacy, pages 165–177.
IEEE CS Press, May 1993.
[15] P. Syverson and C. Meadows. Formal requirements for
key distribution protocols. In A. De Santis, editor,
Advances in Cryptology — EUROCRYPT ’94, pages
32–331. Springer-Verlag, LNCS 950, 1994.
[16] P. Syverson and C. Meadows. A formal language for
cryptographic protocol requirements. Designs, Codes,
and Cryptography, 7(1 and 2):27–59, January 1996.
APPENDIX
A. REMOVING RECURSION
In this appendix we show how we use the NPATRL logic
to remove recursion from the requirements for forward and
backwards access control. Removing recursion is not only
desirable from the point of view of the NRL Protocol Ana-
lyzer, but also because a recursively deﬁned condition may
cause an inﬁnite regression in other model checkers and the-
orem provers.
We present only the proof for backward access control;
that for forward access control is similar.
Lemma 1.
The backward access control condition BAC(KG, G) =
learn(P, (), (KG, G), )
✸BC1(KG, G) ∨ ✸BC2a(KG, G) ∨ ✸BC2b(KG, G)
∨ ✸BC3a(KG, G) ∨ ✸FI(KG, G)
is equivalent to the conditions NRFAC(KG, G) =
learn(P, (), (KG, G), )
✸BC1(KG, G) ∨ ✸BC2a(KG, G) ∨ ✸BC2b(KG, G)
∨ ✸BC3a(KG, G) ∨ ✸NRFI(KG, G),
where NRFI(KG, G) =
G, G) ∨ BC2b(K(cid:2)(cid:2)
G, G) ∨ ✸BC3a(K(cid:2)(cid:2)
(BC1(K(cid:2)(cid:2)
∧ gcks sendpushkey(GCKS , (), (G, KG, K(cid:2)
G), )
∧ ✸gcks sendpushkey(GCKS , (), (G, K(cid:2)(cid:2)
G, K(cid:2)(cid:2)(cid:2)
G ), ).
G, G) ∨ BC2a(K(cid:2)(cid:2)
G, G))
Proof. We make use of the following facts that follow
from the NPATRL axioms. For reasons of space, we leave
the proofs as an exercise to the reader:
1. ✸(A ∧ B) → ✸A ∧ ✸B;
2. ✸✸A → ✸A, and;
3. (A ∧ ✸B) ∧ (C ∧ ✸A) → C ∧ ✸B.
For purposes of of this proof, let BC(K, G) =
✸BC1(K, G) ∨ ✸BC2a(K, G) ∨ ✸BC2b(K, G) ∨ ✸BC3a(K, G).
→
→
We need to show that “learn(P, (), (K, G), ) → BC(K, G) ∨
✸NRFI(K, G)” is logically equivalent to “learn(P, (), (K, G), )
→ BC(K, G) ∨ ✸F I(K, G)”. It is clear that “✸BC(K, G) ∨
✸NRFI(K, G)” implies “✸BC(K, G) ∨ ✸FI(K, G)”, since
“(BC1(K1, G) ∨ BC2a(K1, G) ∨ BC2b(K1, G) ∨ BC3a(K1, G)”
implies “learn(P, (), (K1, G), )”.
We prove the implication in the other direction by induc-
tion on the age of K1. Suppose that K is the ﬁrst key used
by the GCKS for G. Then, since there is no K1 that was
distributed before K, neither “FI(K, G)” nor “NRFI(K, G)”
holds, and so “BC(K, G) ∨ FI(K, G)” is trivially equivalent
to “BC(K, G) ∨ N RF I(K, G)”.
Suppose that now that the result holds for the k’th key
Kn used by the GCKS, for all k < n. Let Kn by the n’th
key. Then
learn(P, (), Kn, G), )
→
∨ (
learn(P, (), (Kk, G), )
✸BC(Kn, G)
∧ gcks sendpushkey(GCKS , (), (G, Kn, K2), )
∧ ✸gcks sendpushkey(GCKS , (), (G, Kk, K3), )),
for some k. Since Kk was used before Kn, we have k < n,
and by the induction hypothesis we get
learn(P, (), (Kn, G), )
→
BC(Kn, G)
∨ ✸( ✸( BC(Ki, G)
∧ gcks sendpushkey(GCKS , (), (G, Kk, K(cid:2)(cid:2)(cid:2)), )
∧ ✸gcks sendpushkey(GCKS , (), (G, Ki, K(cid:2)(cid:2)(cid:2)(cid:2)), )))
∧ gcks sendpushkey(GCKS , (), (G, Kk, K(cid:2)(cid:2)), )))).
∧ ( gcks sendpushkey(GCKS , (), (G, Kn, K(cid:2)), )
Using the facts “✸(A ∧ B) → ✸A ∧ ✸B”, that “✸✸A →
✸A”, and that “(A ∧ ✸B) ∧ (C ∧ ✸A) → C ∧ ✸B”, we
have
learn(P, (), Kn, G), )
→
BC(Kn, G)
∨ ✸( BC(Ki, G)
∧ gcks sendpushkey(GCKS , (), (G, Kn, K(cid:2)(cid:2)(cid:2)), )
∧ ✸gcks sendpushkey(GCKS , (), (G, Ki, K(cid:2)(cid:2)(cid:2)(cid:2)), )),
which is the result we need.
Lemma 2.
The forward access control condition FAC(KG, G) =
learn(P, (), (KG, G), )
✸BC1(KG, G) ∨ ✸BC2a(KG, G) ∨ ✸BC2b(KG, G)
∨ ✸BC3a(KG, G) ∨ ✸BI(KG, G)
is equivalent to the conditions NRBAC(KG, G) =
learn(P, (), (KG, G), )
✸BC1(KG, G) ∨ ✸BC2a(KG, G) ∨ ✸BC2b(KG, G)
∨ ✸BC3a(KG, G) ∨ ✸NRBI(KG, G),
G, G) =
where NRBI(K(cid:2)(cid:2)
(BC1(KG, G) ∨ BC2a(KG, G) ∨ BC2b(KG, G) ∨ ✸BC3a(KG, G))
∧ gcks sendpushkey(GCKS , (), (G, KG, K(cid:2)
∧ ✸gcks sendpushkey(GCKS , (), (G, K(cid:2)(cid:2)
G), )
G, K(cid:2)(cid:2)(cid:2)
G ), ).
Proof. The proof is the same as for backward access
control, except the base induction case is the most recent
key instead of the ﬁrst key, and the induction is on distance
from the most recent key instead of on distance from the
earliest key.
→
→
244