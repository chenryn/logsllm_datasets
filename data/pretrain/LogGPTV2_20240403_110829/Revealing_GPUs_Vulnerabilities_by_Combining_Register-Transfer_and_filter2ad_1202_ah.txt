underestimate the applications reliability of up to 30% for Lava
and 48% for Hotspot, respectively. For other codes (Gaussian
and Quicksort) the two fault models provide very similar
results, as the PVF of the considered instructions is, by itself,
extremely high (close to 1).
For CNNs, if we consider an SDC, as we do in Figure 10
and Table III, a mismatch in the application output (we will
consider misdetection/classiﬁcation next), the single bit-ﬂip
injection underestimates the PVF of 33% for LeNET and 50%
for YoloV3. The higher reliability to transient fault of CNNs
compared to HPC codes should not surprise, as it has already
been observed and studied on GPUs [28], [29].
For LeNET and YoloV3, we also have measured the PVF
when we inject the corrupted t-MxM, as presented earlier in
this section. On LeNET, the SDC PVF when t-MxM fault
model is injected is much higher than the other two fault
models (12x higher), while for YoloV3 it is similar to the
relative error PVF. This different behavior is because LeNET
has a very small number of network parameters per layer
(12,000, on average), and, thus, the corruption of a tile consists
in the corruption of a considerable number of parameters. On
the contrary, YoloV3 layers are very big (100,000 parameters,
on average), and even fully corrupted 8x8 tile represent a small
percentage of the matrix.
We can further analyze the impact of faults in CNNs by
distinguishing between tolerable SDCs and critical SDCs, i.e.
those that corrupt the output sufﬁciently to cause a network
misclassiﬁcation/misdetection. We found that t-MxM injection
produce an unacceptable amount of critical errors. For LeNET,
the number of errors that completely change the classiﬁcation
is 20% and, for YoloV3, it is 15%. It is worth noting that, in
LeNET, none of the injected single bit-ﬂips nor RTL single
thread syndrome produce misclassiﬁcations nor misdetections.
A realistic and accurate fault model, that also considers faults
in GPU critical resources as the scheduler, is then necessary
not to risk to underestimate the effect of transient faults in
CNNs.
By investigating further the RTL fault propagation, we
found that the control structures (inside the scheduler, the
pipeline, and the SFU) are the primary sources of errors that
corrupt multiple threads, affecting a warp or even generating
the geometrical patterns of errors shown in Figure 8. As we
have seen with the software fault injection, despite the limited
size of these structures in a GPU core and the relative low AVF,
these critical modules might produce severe consequences for
an application, especially CNNs. An efﬁcient, and effective,
hardening solution for GPU should deﬁnitely target
these
modules.
Finally, we highlight that injecting at RTL level one single
fault in just one of the applications listed in Figure 10 would
take more than 10 hours, using our 12 CPUs server. As
we inject a total of 48,000 faults, it would take 4.8 × 105
hours to produce all data in Figure 10. That is more than 54
years. Despite the limitations listed in Section II-C and the
introduction of some simpliﬁcations on the input range, our
two-level framework allows an analysis that would otherwise
be impossible.
VII. CONCLUSIONS
In this paper we have applied the concept of multi-level
fault injection to GPUs. Thanks to the combination of RTL
and software fault injection, we reduce by several orders of
magnitude the time required to have a detailed and accurate
analysis of faults propagation from the hardware source to the
application output. The RTL accuracy of our framework identi-
ﬁes the most critical GPU resources, for both SDCs and DUEs,
and identiﬁes a set of possible fault effects (syndromes) in the
instructions output. The efﬁciency of our version of NVBitFI
allows to propagate these effects in real-world applications.
The faults syndrome database we present in this paper is
made publicity available with the intent of providing a more
accurate fault model than the naive single bit-ﬂip, to evaluate
the reliability of applications and to validate hardening solu-
tions. Moreover, the ﬂexibility of our framework grants the
possibility of future updates, both in terms of updated RTL
model or extended instructions evaluation.
In the future we intend to include a beam experiment FIT
rate evaluation of instructions, to provide also an estimation of
the faults occurrence rate together with the fault propagation.
VIII. ACKNOWLEDGMENTS
This project has received funding from the European
Union’s Horizon 2020 research and innovation programme un-
der the Marie Sklodowska-Curie grant agreements No 886202,
No 722325 (RESCUE ETN) and from The Coordenac¸˜ao
de Aperfeic¸oamento de Pessoal de N´ıvel Superior, Brazil
(Finance Code 001). We also thank the funding of CNPq,
Research Productivity Scholarship grant ref. 306475/2019-7.
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 08:56:48 UTC from IEEE Xplore.  Restrictions apply. 
302
REFERENCES
[1] P. Rech, L. Carro, N. Wang, T. Tsai, S. K. S. Hari, and S. W. Keckler,
“Measuring the Radiation Reliability of SRAM Structures in GPUS
Designed for HPC,” in IEEE 10th Workshop on Silicon Errors in Logic
- System Effects (SELSE), 2014.
[2] NVIDIA, “NVIDIA Announces World’s First Functionally Safe AI
”https://nvidianews.nvidia.com/news/nvidia-
Self-Driving
announces-worlds-ﬁrst-functionally-safe-ai-self-driving-platform”,
2018.
Platform.”
[3] NVLABS, “Nvbitﬁ: An architecture-level fault injection tool for GPU
application resilience evaluations.” https://github.com/NVlabs/nvbitﬁ,
2020.
[4] S. K. S. Hari, T. Tsai, M. Stephenson, S. W. Keckler, and J. Emer,
“SASSIFI: An architecture-level fault injection tool for GPU applica-
tion resilience evaluation,” in 2017 IEEE International Symposium on
Performance Analysis of Systems and Software (ISPASS), pp. 249–258,
2017.
[5] J. Wei, A. Thomas, G. Li, and K. Pattabiraman, “Quantifying the Accu-
racy of High-Level Fault Injection Techniques for Hardware Faults,” in
2014 44th Annual IEEE/IFIP International Conference on Dependable
Systems and Networks, pp. 375–382, 2014.
[6] A. Vallero, D. Gizopoulos, and S. Di Carlo, “SIFI: AMD southern
islands GPU microarchitectural level fault injector,” in 2017 IEEE 23rd
International Symposium on On-Line Testing and Robust System Design
(IOLTS), pp. 138–144, 2017.
[7] B. Fang, K. Pattabiraman, M. Ripeanu, and S. Gurumurthi, “GPU-Qin: A
methodology for evaluating the error resilience of GPGPU applications,”
in Performance Analysis of Systems and Software (ISPASS), 2014 IEEE
International Symposium on, pp. 221–230, March 2014.
[8] B. Nie, L. Yang, A. Jog, and E. Smirni, “Fault site pruning for practi-
cal reliability analysis of GPGPU applications,” in 2018 51st Annual
IEEE/ACM International Symposium on Microarchitecture (MICRO),
pp. 749–761, 2018.
[9] P. Rech, L. L. Pilla, P. O. A. Navaux, and L. Carro, “Impact of
GPUs parallelism management on safety-critical and HPC applications
reliability,” in 2014 44th Annual IEEE/IFIP International Conference
on Dependable Systems and Networks, pp. 455–466, 2014.
[10] D. A. G. Goncalves de Oliveira, L. L. Pilla, T. Santini, and P. Rech,
“Evaluation and mitigation of radiation-induced soft errors in graphics
processing units,” IEEE Transactions on Computers, vol. 65, no. 3,
pp. 791–804, 2016.
[11] R. Balasubramanian et al., “Understanding the impact of gate-level phys-
ical reliability effects on whole program execution,” in 2014 IEEE 20th
International Symposium on High Performance Computer Architecture
(HPCA), 2014.
[12] S. Nimara, A. Amaricai, O. Boncalo, and M. Popa, “Multi-level
simulated fault injection for data dependent reliability analysis of rtl
circuit descriptions,” Advances in Electrical and Computer Engineering,
vol. 16, pp. 93–98, 02 2016.
[13] H. Cho, C. Cher, T. Shepherd, and S. Mitra, “Understanding soft
errors in uncore components,” in 2015 52nd ACM/EDAC/IEEE Design
Automation Conference (DAC), pp. 1–6, 2015.
[14] M. A. Kochte, C. G. Zoellin, R. Baranowski, M. E. Imhof, H. Wunder-
lich, N. Hatami, S. D. Carlo, and P. Prinetto, “Efﬁcient simulation of
structural faults for the reliability evaluation at system-level,” in 2010
19th IEEE Asian Test Symposium, pp. 3–8, 2010.
[15] A. Ejlali, S. G. Miremadi, H. Zarandi, G. Asadi, and S. B. Sarmadi,
“A hybrid fault injection approach based on simulation and emulation
co-operation,” in 2003 International Conference on Dependable Systems
and Networks, 2003. Proceedings., pp. 479–488, 2003.
[16] A. L. Sartor, P. H. Becker, and A. C. Beck, “A fast and accurate hybrid
fault injection platform for transient and permanent faults,” Des. Autom.
Embedded Syst., vol. 23, p. 3–19, June 2019.
[17] E. Schneider and H. Wunderlich, “Multi-level timing and fault simula-
tion on GPUs,” Integr., vol. 64, pp. 78–91, 2019.
[18] O. Subasi, C.-K. Chang, M. Erez, and S. Krishnamoorthy, “Characteriz-
ing the impact of soft errors affecting ﬂoating-point alus using rtl-ievel
fault injection,” in Proceedings of the 47th International Conference on
Parallel Processing, ICPP 2018, (New York, NY, USA), Association for
Computing Machinery, 2018.
[19] J. E. R. Condia et al., “FlexGripPlus: An improved GPGPU model to
support reliability analysis,” Microelectronics Reliability, vol. 109, 2020.
[20] Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner, “Gradient-based learning
applied to document recognition,” Proceedings of the IEEE, vol. 86,
no. 11, pp. 2278–2324, 1998.
[21] J. Redmon and A. Farhadi, “Yolov3: An incremental improvement,”
arXiv, 2018.
[22] D. A. G. D. Oliveira, L. L. Pilla, M. Hanzich, V. Fratin, F. Fernandes,
C. Lunardi, J. M. Cela, P. O. A. Navaux, L. Carro, and P. Rech,
“Radiation-induced error criticality in modern hpc parallel accelerators,”
in 2017 IEEE International Symposium on High Performance Computer
Architecture (HPCA), pp. 577–588, 2017.
[23] F. F. dos Santos, J. E. R. Condia, L. Carro, M. S. Reorda, and P. Rech,
“DSN 2021 data repository.” https://github.com/UFRGS-CAROL/dsn
2021 data, June 2021.
[24] R. Baumann, “Soft errors in advanced computer systems,” IEEE Design
Test of Computers, vol. 22, pp. 258–266, May 2005.
[25] N. DeBardeleben, S. Blanchard, L. Monroe, P. Romero, D. Grunau,
C. Idler, and C. Wright, “GPU behavior on a large HPC cluster,” in Euro-
Par 2013: Parallel Processing Workshops (D. an Mey, M. Alexander,
P. Bientinesi, M. Cannataro, C. Clauss, A. Costan, G. Kecskemeti,
C. Morin, L. Ricci, J. Sahuquillo, M. Schulz, V. Scarano, S. L. Scott,
and J. Weidendorfer, eds.), (Berlin, Heidelberg), pp. 680–689, Springer
Berlin Heidelberg, 2014.
[26] D. Tiwari, S. Gupta, J. Rogers, D. Maxwell, P. Rech, S. Vazhkudai,
D. Oliveira, D. Londo, N. DeBardeleben, P. Navaux, L. Carro, and
A. Bland, “Understanding GPU errors on large-scale HPC systems and
the implications for system design and operation,” in 2015 IEEE 21st
International Symposium on High Performance Computer Architecture
(HPCA), pp. 331–342, 2015.
[27] L. B. Gomez, F. Cappello, L. Carro, N. DeBardeleben, B. Fang, S. Gu-
rumurthi, K. Pattabiraman, P. Rech, and M. Sonza Reorda, “GPGPUs:
How to combine high computational power with high reliability,” in
2014 Design, Automation Test in Europe Conference Exhibition (DATE),
pp. 1–9, 2014.
[28] F. F. d. Santos, P. F. Pimenta, C. Lunardi, L. Draghetti, L. Carro,
D. Kaeli, and P. Rech, “Analyzing and increasing the reliability of con-
volutional neural networks on GPUs,” IEEE Transactions on Reliability,
vol. 68, no. 2, pp. 663–677, 2019.
[29] Y. Ibrahim, H. Wang, M. Bai, Z. Liu, J. Wang, Z. Yang, and Z. Chen,
“Soft error resilience of deep residual networks for object recognition,”
IEEE Access, vol. 8, pp. 19490–19503, 2020.
[30] S. Tselonis and D. Gizopoulos, “GUFI: A framework for GPUs reliabil-
ity assessment,” in 2016 IEEE International Symposium on Performance
Analysis of Systems and Software (ISPASS), pp. 90–100, 2016.
[31] A. Chatzidimitriou, P. Bodmann, G. Papadimitriou, D. Gizopoulos, and
P. Rech, “Demystifying soft error assessment strategies on arm cpus:
Microarchitectural fault injection vs. neutron beam experiments,” in
2019 49th Annual IEEE/IFIP International Conference on Dependable
Systems and Networks (DSN), pp. 26–38, 2019.
[32] S. Che, M. Boyer, J. Meng, D. Tarjan, J. W. Sheaffer, S. Lee, and
K. Skadron, “Rodinia: A benchmark suite for heterogeneous computing,”
in 2009 IEEE International Symposium on Workload Characterization
(IISWC), pp. 44–54, 2009.
[33] “Cuda code samples,” Oct 2018.
[34] NVIDIA, “Cuda binary utilities.”
[35] F. G. Previlon, C. Kalra, D. R. Kaeli, and P. Rech, “Evaluating the impact
of execution parameters on program vulnerability in GPU applications,”
in 2018 Design, Automation Test
in Europe Conference Exhibition
(DATE), pp. 809–814, 2018.
[36] S. S. Mukherjee, C. Weaver, J. Emer, S. K. Reinhardt, and T. Austin,
“A Systematic Methodology to Compute the Architectural Vulnerability
Factors for a High-Performance Microprocessor,” in Proceedings of the
36th Annual IEEE/ACM International Symposium on Microarchitecture,
(Washington, DC, USA), pp. 29–, IEEE Computer Society, 2003.
[37] A. Avizienis, J.-C. Laprie, B. Randell, and C. Landwehr, “Basic concepts
and taxonomy of dependable and secure computing,” IEEE Trans.
Dependable Secur. Comput., vol. 1, p. 11–33, Jan. 2004.
[38] V. Sridharan and D. R. Kaeli, “Eliminating microarchitectural depen-
dency from architectural vulnerability,” in 2009 IEEE 15th International
Symposium on High Performance Computer Architecture, pp. 117–128,
2009.
[39] E. Lindholm, J. Nickolls, S. Oberman, and J. Montrym, “Nvidia Tesla:
A uniﬁed graphics and computing architecture,” IEEE Micro, vol. 28,
pp. 39–55, March 2008.
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 08:56:48 UTC from IEEE Xplore.  Restrictions apply. 
303
[40] B. Du, J. E. R. Condia, M. Sonza. Reorda., and L. Sterpone, “On the
evaluation of SEU effects in GPGPUs,” in 2019 IEEE Latin American
Test Symposium (LATS), pp. 1–6, 2019.
[43] A. Clauset, C. R. Shalizi, and M. E. J. Newman, “Power-law distri-
butions in empirical data,” SIAM Review, vol. 51, no. 4, pp. 661–703,
2009.
[41] D. Oliveira, L. Pilla, N. DeBardeleben, S. Blanchard, H. Quinn, I. Koren,
P. Navaux, and P. Rech, “Experimental and analytical study of xeon
phi reliability,” in Proceedings of the International Conference for High
Performance Computing, Networking, Storage and Analysis, SC ’17,
(New York, NY, USA), pp. 28:1–28:12, ACM, 2017.
[42] S. Jha, T. Tsai, S. Hari, M. Sullivan, Z. Kalbarczyk, S. W. Keckler, and
R. K. Iyer, “Kayotee: A fault injection-based system to assess the safety
and reliability of autonomous vehicles to faults and errors,” 2019.
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 08:56:48 UTC from IEEE Xplore.  Restrictions apply. 
304