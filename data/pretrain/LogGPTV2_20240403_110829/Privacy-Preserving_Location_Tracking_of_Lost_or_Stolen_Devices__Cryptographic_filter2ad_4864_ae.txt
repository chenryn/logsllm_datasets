obvious reasons, these remote storage facilities would
want to restrict the parties able to insert data.
If we
use traditional authentication mechanisms, the authen-
tication tag might reveal who is submitting the update.
Thus one might think about using newer cryptographic
primitives such as group or ring signatures [10, 31] that
allow authentication while not revealing what member of
a group is actually communicating the update.
Corporations or other large organizations might opt
to internally host storage facilities, as per Scenario 5 of
Section 2. Again, dedicated storage servers ease design
constraints, meaning Adeona can be simpliﬁed for this
setting. But there is again the issue of access control.
(Though in this setting existing corporate VPN’s, if these
do not reveal the client’s identity, might be used.) On the
other hand, this kind of deployment raises other interest-
ing questions. Particularly, the privacy set is necessarily
restricted to only employees of the corporation, and so an
adversary might be able to aggregate information about
overall employee location habits even if the adversary
cannot track individual employees.
8 Extensions
We describe several extensions for the Adeona system
that highlight its versatility and extensibility. These in-
clude: removing the reliance on synchronized clocks,
tamper-evident FSPRGs for untrusted local storage, a
panic mode of operation that does not rely on state, the
use of anonymous channels, and enabling communica-
tion from an owner back to a lost device.
8.1 Avoiding synchronized time
The Adeona system, as described in Section 4, utilizes a
shared clock between the client and owner to ensure safe
retrieval. This is realized straightforwardly if the client is
loosely synchronized against an external clock (e.g., via
NTP [27]).
In deployment scenarios where the device
cannot be guaranteed to maintain synchronization or the
thief might maliciously modify the system clock, we can
modify the client and retrieval process as follows.
Whenever the client is executed, it reads the current
state (which is now just the current cryptographic seed
for the FSPRG and the cache) and computes the inter-
update time δ associated to the state. It then waits that
amount of time before sending the next update and pro-
gressing the state. For retrieval, the owner can still com-
pute all of the inter-update times, and use these to esti-
mate when a state was used to send an update.
If the
client runs continuously from initialization, then a state
will be used when predicted by the sum of the inter-
update times of earlier states.
If the client is not run
continuously from initialization, then a state might be
used to send an update later (relative to absolute time)
than predicted by the inter-update times. It is therefore
USENIX Association  
17th USENIX Security Symposium 
287
privacy-preserving for the owner to retrieve any states es-
timated to be sent after the time at which the device was
lost. The owner might also query prior states to search
for relevant updates, but being careful not to go too far
back (lest he begin querying for updates sent before the
device was lost).
8.2 Detection of client state tampering
The Adeona system relies on the client’s state remain-
ing unmodiﬁed. Compared to a (hypothetical) stateless
client, this allows a new avenue for disabling the de-
vice. To rectify this disparity between the ideal (in which
an adversary has to disable/modify the client executable)
and Adeona we design a novel cryptographic primitive,
a tamper-evident FSPRG, that allows cryptographic val-
idation of state. By adding this functionality to Adeona
we remove this avenue for disabling tracking functional-
ity. Moreover, we believe that tamper-evident FSPRGs
are likely of independent interest and might ﬁnd use in
further contexts where untrusted storage is in use, e.g.,
when the Adeona core is implemented in hardware but
the state is stored in memory accessible to an adversary.
A straightforward construction would work as follows.
The owner, during initialization, also generates a signing
key and a veriﬁcation key for a digital signature scheme.
Then, the initialization routine generates the core’s val-
ues si, ci,1, Ti for each future state i that could be used by
the client, and signs these values. The veriﬁcation key
and resulting signatures are placed in the client’s stor-
age, along with the normal initial state. The client, to
validate lack of tampering with FSPRG states, can verify
the state’s si, ci,1, Ti values via the digital signature’s ver-
iﬁcation algorithm and the (stored) veriﬁcation key. Un-
fortunately this approach requires a large amount of stor-
age (linear in the number of updates that could be sent).
Moreover, a very sophisticated thief could just mount a
replacement attack: substitute his or her own state, ver-
iﬁcation key, and signatures for the owner’s. Note this
attack does not require modifying or otherwise interfer-
ing with the client executable. We can do better on both
accounts.
To stop replacement attacks, we can use a trusted au-
thority to generate a certiﬁcate for the owner’s veriﬁca-
tion key (which should also tie it to the device). Then the
trusted authority’s veriﬁcation key can be hard-coded in
the client executable and be used to validate the owner’s
(stored) veriﬁcation key. To reduce the storage space
required, we have the owner, during initialization, only
sign the ﬁnal state’s values. To verify, the client can seek
forward with the FSPRG (without yet deleting the cur-
rent state) to the ﬁnal state and then verify the signature.
(A counter can be used to denote how many states the
client needs to progress to reach the ﬁnal one.) Under
reasonable assumptions regarding the FSPRG (in partic-
ular, that it’s difﬁcult to ﬁnd two distinct states that lead
to the same future state) and the assumption that the dig-
ital signature scheme is secure, no adversary will be able
to generate a state that deviates from the normal progres-
sion, yet veriﬁes. A clever thief might try to roll the
FSPRG forward in the normal progression, to cause a
long wait before the next update. This can be defended
against with a straightforward check relative to the cur-
rent time: if the next update is too far away, then assume
adversarial modiﬁcation. We could also store the signa-
tures of some fraction of the intermediate states in or-
der to operate at different points of a space/computation
trade-off.
8.3 Private updates with tampered state
If the client detects tampering with the state, then it can
enter into a “panic” mode which does not rely on the
stored state to send updates. One might have panic mode
just send updates in the clear (because these locations
are presumably not associated with the owner), but there
can be reasons not to do this. For example, conﬁguration
errors by an owner could mistakenly invoke panic mode.
Panic mode can still provide some protection for up-
dates without relying on shared state, as follows. We as-
sume the client and owner have access to an immutable,
unique identiﬁcation string ID. In practice this ID could
be the laptop’s MAC address. We also use a cryp-
tographic hash function H: {0,1}∗ → {0,1}h, such as
SHA-256 for which h = 256 bits. Then pick a param-
eter b ∈ [0 ..h]. For each update, the client generates a
sequence of indexes via I1 = H(1 || T || H(ID)|b), I2 =
H(2 || T || H(ID)|b), etc. Here T is the current date and
H(ID)|b denotes hashing ID and then taking the ﬁrst b
bits of the result.
(Varying the parameter b enables a
simple time-privacy trade off known as “bucketization”.)
Location information can be encrypted using an
anonymous identity-based encryption scheme [8]. Using
a trusted key distribution center, each owner can receive
a secret key associated to their device’s ID. (Note that
the center will be able to decrypt updates, also.) Encryp-
tion to the owner only requires ID. This is useful because
then encryption does not require stored per-device state,
under the presumption that ID is always accessible. The
ciphertext can be submitted under the indices. The owner
can retrieve these panic-mode updates by re-computing
the indices using ID and the appropriate dates and then
using trial decryption.
8.4 Anonymous channels
Systems such as Tor [14] implement anonymous chan-
nels, which can be used to effectively obfuscate from re-
288 
17th USENIX Security Symposium 
USENIX Association
cipients the originating IP address of Internet trafﬁc. The
Adeona design can easily compose with any such sys-
tem by transmitting location updates to the remote stor-
age across the anonymous channel. The combination of
Adeona with an anonymous routing system provides sev-
eral nice beneﬁts. It means that the storage provider and
outsiders do not trivially see the originating IP address,
meaning active ﬁngerprinting attacks are prevented. Ad-
ditionally, it merges the anonymity set of Adeona with
that of the anonymous channel system. For example,
even if there exists only a single user of Adeona, that
user might nevertheless achieve some degree of location
privacy using anonymous channels.
On the other hand, attempting to use anonymous chan-
nels without Adeona does not satisfy our system goals.
The now more complex clients would not necessarily
be suitable for some deployment settings (e.g. hardware
implementations). It would force a reliance on a com-
plex, distributed infrastructure in all deployment settings.
This reliance is particularly bad in the corporate setting.
Routing location updates through nodes not controlled
by the company could actually decrease corporate pri-
vacy: outsiders could potentially learn employee loca-
tions (e.g., see [36]). Moreover, when analyzing how to
utilize anonymous channels and meet our tracking and
privacy goals, it is easy to see that even with the anony-
mous channel one still beneﬁts from Adeona’s mecha-
nisms. Imagine a hypothetical system based on anony-
mous channels. Because the storage provider is poten-
tially adversarial, the system would still need to encrypt
location information and so also provide an index to en-
able efﬁcient search of the remote storage. Because the
source IP is hidden, one might utilize a static, anony-
mous identiﬁer. This would allow the storage provider
to, at the very least, link update times to a single device,
which leaks more information than if the indices are un-
linkable.
8.5 Sending commands to the device
In situations where a device is lost, an owner might wish
to not only retrieve updates from it, but also securely
send commands back to it. For example, such a chan-
nel would allow remotely deleting sensitive data. We
can securely instantiate a full duplex channel using the
remote storage as a bulletin board. An owner could post
encrypted and signed messages to the remote storage un-
der indices of future updates. The client, during an up-
date, would ﬁrst do a retrieve on the indices to be used
for the update, thereby receiving the encrypted and au-
thenticated commands. Standard encryption and authen-
tication tools can be used, including using cryptographic
keys derived from the FSPRG seed in use on the client.
In terms of location privacy, the storage provider would
now additionally learn that two entities are communicat-
ing via the bulletin board, but not which entities.
9 Conclusion
This paper develops mechanisms by which one can build
privacy-preserving device tracking systems. These sys-
tems simultaneously hide a device owner’s legitimately
visited locations from powerful adversaries, while en-
abling tracking of the device after it goes missing. More-
over, we do so while using third party services that are
not trusted in terms of location privacy. Our mecha-
nisms are efﬁcient and practical to deploy. Our client-
side mechanisms are well-suited for hardware implemen-
tations. This illustrates that not only can one circumvent
a trade-off between security and privacy, but one can do
so in practice for real systems.
We implemented Adeona, a full privacy-preserving
tracking system based on OpenDHT that allows for im-
mediate, community-orientated deployment.
Its core
module, the cryptographic engine that renders location
updates anonymous and unlinkable, can be easily used in
further deployment settings. To evaluate Adeona, we ran
a ﬁeld trial to gain experience with a deployment on real
user’s systems. Our conclusion is that our approach is
sound and an immediately viable alternative to tracking
systems that offer less (or no) privacy guarantees. Lastly,
we also presented numerous extensions to Adeona that
address a range of issues: disparate deployment settings,
increased functionality, and improved security. The tech-
niques involved, particularly our tamper-evident FSPRG,
are likely of independent interest.
Notes
1EmailMe is a ﬁctional system, though its functionality is based on
products such as PC Phone Home [9] and Inspice [21].
2A ﬂea market is a type of ad-hoc market where transactions are
typically anonymous and done in cash.
3AllDevRec is a ﬁctional company, though the services it offers are
comparable to those advertised by Absolute Software [1], which has
tracking software pre-installed in the BIOS of some Dell laptops.
4A real example of such insider abuse is found in [20].
5The owner could download the entire database and do trial decryp-
tion, but with many users this would be prohibitively expensive.
6One could also utilize as basic primitive a keyed hash function.
7To be precise, the guarantee is that OpenDHT guarantees not to ex-
pire a key-value pair before its time-to-live passes, barring some catas-
trophic failure of the DHT service [30].
8Systems we built on had version 0.9.7l or later. We used SHA1,
instead of the more secure SHA-256, due to its lack of implementation
in OpenSSL 0.9.7l (the most recent version available for OSX).
9To be precise, the search was for any update potentially sent over
the course of 6 days and 23 hours. The ﬁnal hour was omitted for sim-
plicity since it avoided retrieving updates being expired by OpenDHT.
USENIX Association  
17th USENIX Security Symposium 
289
References
[1] Absolute
Software.
Laptops.
for
solutions-theft-recovery.asp
Computrace
LoJack
http://www.absolute.com/
[2] Akamai website. http://www.akamai.com/
[3] M. Bellare, R. Canetti, and H. Krawczyk. Keying Hash
Functions for Message Authentication. CRYPTO, 1996.
[4] M. Bellare and C. Namprempre.
Authenticated-
Encryption: Relations among notions and analysis of the
generic composition paradigm. ASIACRYPT, 2000.
[5] M. Bellare and B. Yee. Forward-Security in Privatey-Key
Cryptography. CT-RSA, 2003.
[6] M. Blum and S. Micali. How to generate cryptograph-
ically strong sequences of pseudo-random bits. SIAM
Journal on Computing, vol. 13, no. 4, pp. 850–864, 1984.
[7] D. Boneh and X. Boyen. Efﬁcient selective-ID secure
identity based encryption without random oracles. In EU-
ROCRYPT, 2004.
[8] D. Boneh and M. Franklin.
Identity-based encryption
from the Weil pairing. In CRYPTO, 2001.
[9] Brigadoon Software, Inc. PC Phone Home. http://www.
pcphonehome.com/
[10] D. Chaum and E. van Heyst. Group signatures. In EU-
ROCRYPT, 1991.
[11] B. Chun, D. Culler, T. Roscoe, A. Bavier, L. Peterson,
M. Wawrzoniak, and M. Bowman. PlanetLab: An over-
lay testbed for broad-coverage services ACM SIGCOMM,
2003.
[12] F. Dabek, R. Cox, F. Kaashoek, and R. Morris Vivaldi: A
decentralized network coordinate system. In SIGCOMM,
2004.
[13] L. Devroye. Non-Uniform Random Variate Generation.
New York, Springer-Verlag, 1986.
[14] R. Dingledine, N. Mathewson, and P. Syverson. Tor: the
second-generation onion router. USENIX Security Sym-
posium, USENIX, vol. 13, pp. 9–13, 2004.
[15] M. Feldhofer, J. Wolkerstorfer, and V. Rijmen. AES im-
IEE Proc. Inf. Secur.,
plementation on a grain of sand.
vol. 152, no. 1, pp. 13–20, Oct. 2005.
[16] L. Gordon, M. Loeb, W. Lucyshyn, and R. Richard-
son. CSI/FBI Computer Crime and Security Survey 2006.
Computer Security Institute publications, 2006.
[17] M. Gruteser and D. Grunwald. A Methodological As-
sessment of Location Privacy Risks in Wireless Hotspot
Networks Security in Pervasive Computing – SPC, 2003.
[18] B. Gueye, A. Ziviani, M. Crovella, and S. Fdida.
Constraint-based geolocation of Internet hosts. To appear
in ACM Transactions on Networking.
[19] IEEE Standards Association.
IEEE Std 802.11i-2004.
2004.
[20] InformationWeek.
Federal Agent Indicted for Us-
ing Homeland Security Database To Stalk Girl-
friend. http://www.informationweek.com/shared/
printableArticle.jhtml?articleID=201807903
[21] Inspice. Inspice Trace. http://www.inspice.com/
[22] M. Jakobsson and S. Wetzel. Security Weaknesses in
Bluetooth. CT-RSA, 2001.
[23] A. Juels. RFID Security and Privacy: A Research Sur-
vey, IEEE Journal on Selected Areas in Communications,
2006.
[24] T. Kohno, A. Broido, and K.C. Claffy. Remote physical
device ﬁngerprinting. IEEE Symposium on Security and
Privacy, 2005.
[25] B. Lynn.
Stanford Pairings-Based Crypto Library.
http://crypto.stanford.edu/pbc/.
[26] D. McGrew and J. Viega. The security and performance
IN-
of the Galois/Counter Mode (GCM) of operation.
DOCRYPT, 2004.
[27] D. Mills. Improved Algorithms for Synchronizing Com-
IEEE/ACM Trans. Netw., vol. 3
puter Network Clocks.
no. 3, pp. 245–254, 1995.
[28] New York Times. At U.S. Borders, Laptops Have No
Right to Privacy. http://www.nytimes.com/2006/10/
24/business/24road.html . October 24, 2006.
[29] Raytheon Oakley Systems. SureFind.
http://www.
oakleynetworks.com/products/surefind.php
[30] S. Rhea, B. Godfrey, B. Karp, J. Kubiatowicz, S. Rat-
nasamy, S. Shenker, I. Stoica, and H. Yu. OpenDHT: A
Public DHT Service and Its Uses. In SIGCOMM, 2005.
[31] R. Rivest, A. Shamir, and Y. Tauman How to leak a secret.
In ASIACRYPT, 2001.
[32] B. Schneier and J. Kelsey. Secure Audit Logs to Support
Computer Forensics. ACM Transactions on Information
and System Security, vol. 1, no. 3, 1999.
[33] Slashdot. US Courts Consider Legality of Laptop Inspec-
http://yro.slashdot.org/article.pl?sid=
tion.
08/01/08/1641209&tid=158 . January 8, 2008.
[34] Tri-8, Inc. MyLaptopGPS. http://www.mylaptopgps.
com/
[35] Trusted
Computing Group.
http://www.
trustedcomputinggroup.org/specs/TPM/
[36] Wired.
Rogue Nodes Turn Tor Anonymizer
Into
http://www.wired.com/
Eavesdropper’s Paradise.
politics/security/news/2007/09/embassy_
hacks . September 10, 2007.
[37] XTool Mobile Security, Inc. XTool Laptop Tracker.
http://www.xtool.com/xtooltracker.aspx
[38] zTrace Technologies. http://www.ztrace.com/
290 
17th USENIX Security Symposium 
USENIX Association