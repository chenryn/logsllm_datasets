title:Enhancing Collaborative Spam Detection with Bloom Filters
author:Jeff Yan and
Pook Leong Cho
Enhancing Collaborative Spam Detection with Bloom Filters
Newcastle University, School of Computing Science, UK
Jeff Yan
Pook Leong Cho
{jeff.yan, p.l.cho}@ncl.ac.uk
Abstract
Signature-based collaborative spam detection (SCSD)
systems provide a promising solution addressing many
problems facing statistical spam ﬁlters, the most widely
adopted technology for detecting junk emails. In par-
ticular, some SCSD systems can identify previously un-
seen spam messages as such, although intuitively this
would appear to be impossible. However, the SCSD ap-
proach usually relies on huge databases of email signa-
tures, demanding lots of resource in signature lookup,
storage, transmission and merging. In this paper, we re-
port our enhancements to two representative SCSD sys-
tems. In our enhancements, signature lookups can be per-
formed in constant time, independent of the number of sig-
natures in the database. Space-efﬁcient representation
can signiﬁcantly reduce signature database size. A sim-
ple but
fast algorithm for merging different signature
databases is also supported. We use the Bloom ﬁlter tech-
nique and a novel variant of this technique to achieve all
this.
1. Introduction
Spam (junk bulk email) is an ever-increasing problem. It
causes annoyance to individual email users but also imposes
signiﬁcant costs on many organisations. To date, statistical
spam ﬁlters are probably the most heavily studied and the
most widely adopted technology for detecting junk emails.
However, among other disadvantages, these ﬁlters need to
be regularly trained, particularly when the ﬁlters result in
excessive numbers of “false positive” or “false negative” de-
cisions. In particular, such systems fail to detect spam that
cannot be predicted by the machine learning algorithms on
which they are based. Such ﬁlters also cannot identify spam
that is sent as an image attachment to an otherwise unob-
jectionable email message. In addition, as content-based ﬁl-
ters, they are language-dependent (e.g. a ﬁlter trained for
English is useless in detecting spam in Chinese, and vice
versa) and vulnerable to various content-manipulation at-
tacks (e.g. so-called “ﬁlter poisoning”).
Signature-based Collaborative Spam Detection (SCSD)
systems, e.g. Razor [7] and Distributed Checksum Clearing-
house (DCC) [3], are an attractive complement to statistical
spam ﬁlters. As an alternative approach, these systems pro-
vide a promising solution addressing all the above problems
facing statistical ﬁlters. In particular, systems like DCC
can identify previously unseen spam messages as such, al-
though intuitively this would appear to be impossible.
However, SCSD systems usually rely on huge databases
of email signatures, demanding expensive computers and
lots of resource in signature lookup, storage, transmission
(over the Internet) and merging. For example, a busy Ra-
zor or DCC server usually uses a dedicated computer. A
dedicated Razor server typically handles up to 200 million
queries per day. The number of active signatures it main-
tains is about 10 million at any time, and the database size
exceeds 320 MB [8]. A dedicated DCC server typically han-
dles up to 10 million requests per day. Its database is typi-
cally of about 1 GB (up to 5 GB), storing more than 20 mil-
lion signatures [11].
We have performed an analysis of DCC source code and
conﬁrmed that a standard technique of hash table with in-
ternal chaining (dealing with collisions) is used to support
all signature insertion, lookup and deletion operations. A
large collection of message signatures, a hash table used for
organising these signatures, and other information are all
stored, leading to a huge database as well as expensive com-
putation. Techniques used in Razor are not publicly known.
The source code of Razor’s server program is not publicly
available, either. However, the size of its signature database,
together with technical information available on the Inter-
net (e.g. the largest message signature used in Razor is of
20 bytes [7]), suggests that at least signature storage, trans-
mission and merging could be optimised in Razor.
In this paper, we propose some enhancements to both
Razor and DCC. In our enhancements, signature lookups
can be performed in O(1), i.e. constant time, independent
of the number of signatures in the database. Space-efﬁcient
representation can signiﬁcantly reduce signature database
size (e.g. by a factor of 16 or more for the Razor system),
Proceedings of the 22nd Annual Computer Security Applications Conference (ACSAC'06)0-7695-2716-7/06 $20.00  © 2006before any data compression algorithm is applied. This also
implies much less trafﬁc when signature databases are ex-
changed over the Internet. A simple but efﬁcient algorithm
for merging different signature databases is also supported.
We have achieved all this using the Bloom ﬁlter tech-
nique [1] and a novel variant of this technique. Our variant
extends the standard Bloom ﬁlter scheme to support count-
ing, heuristics for reducing counting errors, and an innova-
tion for storage saving. This variant can also be applied to
other distributed applications.
The rest of this paper is organised as follows. Section 2
provides technical backgrounds of this paper by brieﬂy re-
viewing both the signature-based collaborative spam detec-
tion approach and the Bloom ﬁlter technique. Section 3 dis-
cusses enhancing the Razor system with Bloom ﬁlters. Sec-
tion 4 introduces our new Bloom ﬁlter variant, and discusses
enhancements it can introduce to the DCC system. Section
5 reports a simulation study, which shows the performance
improvement the new variant can achieve in reducing count-
ing errors. Section 6 concludes with a summary of the main
contributions of this paper and a brief discussion of ongo-
ing and future work.
2. Technical background
2.1. Signature-based collaborative spam detection
The signature-based collaborative spam detection ap-
proach is based on simple but powerful insights. For ex-
ample, Razor implements the following idea: if a message
has been identiﬁed elsewhere as spam by somebody trust-
worthy, then this human effort shall be shared/reused.
DCC also relies on a simple but insightful observation:
spam by deﬁnition is unsolicited bulk email, so we can de-
tect spam by checking for “bulkiness”. That is, when a mes-
sage that has been seen many times elsewhere on the Inter-
net reaches you, if it is not from any person, organisation or
email list that appears on your so-called “white list”, then
it is safe for the email system to treat it as spam and dis-
card it. This is a clever way of detecting and dealing with
spam email messages (including those unforeseeable new
ones) without checking the message content.
As indicated, both DCC and Razor are signature-based.
In the simplest conceptual form of both systems, one sig-
nature (i.e., digest or checksum) is computed with a crypto-
graphic hash h() to represent each message. Since any slight
change in input to such a hash will dramatically change its
output, msg1 and msg2 are considered the same if and only
if h(msg1) = h(msg2). The use of a crypto hash also ad-
dresses users’ privacy concern, since anybody who receives
a message signature will not be able to reverse engineer it
to get the message text.
In the actual implementations of these two systems, mul-
tiple different signatures are calculated for the same mes-
sage in some scenarios. To simplify our discussion, unless
otherwise indicated, we assume in this paper that an email
message is represented by a single signature. However, our
discussions can be generalised to the actual case easily.
A simple illustration of how DCC works is as follows.
A DCC server collects and accumulates counts of signa-
tures for email messages. To decide whether a new message
is spam, a DCC client queries the server using a signature
of the message. If the count number for the signature re-
turned by the server is larger than a local threshold value set
by the user, then the message is marked as spam.
In Razor, a server maintains a database of signatures for
identiﬁed spam. That is, an end-user identiﬁes a spam mes-
sage and then reports its signature to the server serving her.
Other users will query the server to detect spam in their mail
boxes: if a particular email message already has its signa-
ture appearing in the server database, then it is identiﬁed as
being spam.
Both DCC and Razor are collaborative in nature. Both
systems run a distributed network of (signature) servers,
each serving a particular part of the user population and
collecting signatures from that particular community. Sig-
nature databases are periodically synchronised among all
servers. In this way, each user’s effort can be reused by
many others.
The following issues are critical to the success of SCSD
systems:
• Near-replica identiﬁcation. Near-replicas are simi-
lar messages with minor differences. Spammers often
use them to evade detection. Since any slight change
in an input to a crypto hash function will dramati-
cally change its output, it seems impossible to correlate
near-replica messages by examining their signatures
computed with such a hash. It would be very useful to
create a “fuzzy” hash function that will produce similar
hashed values for similar inputs. This hash should also
be robust against a number of attacks such as random
addition, dictionary substitution and perceptive substi-
tution (e.g. substituting “Viagra” by “V1agr@”).
• Trust. Spammers can cheat so as to defeat any spam
detection system. How would you differentiate trust-
worthy users and spammers in the same community
so that their updates to the servers are treated differ-
ently? A proper reputation system is essential, in par-
ticular for Razor and the like systems.
Solutions adopted by Razor and DCC to address these is-
sues appear to be effective and sophisticated enough to be
deployed on a large scale, as the accuracy and popularity
(see [7, 3]) of both systems suggests. However, much im-
Proceedings of the 22nd Annual Computer Security Applications Conference (ACSAC'06)0-7695-2716-7/06 $20.00  © 2006provement can be done, as suggested by our preliminary
analysis, but they are beyond the scope of this paper.
2.2. Bloom ﬁlters
Conceived by Burton H Bloom in 1970, a Bloom ﬁlter
is a space-efﬁcient data structure supporting fast member-
ship testing [1]. It is a bit vector B of m bits, each set to
zero initially. To insert an element x into B, ﬁrst compute
h1(x), ..., hk(x) with k independent, random hash func-
tions, each mapping x into the range {0, 1, ..., m− 1}; then,
set B[h1(x)] = ... = B[hk(x)] = 1. To query if y is
a member in the ﬁlter, h1(y), ..., hk(y) are computed. If
B[h1(y)] = ... = B[hk(y)] = 1, then answer Yes, else an-
swer No.
A Bloom ﬁlter does not introduce false negatives (an-
swering No when an element is actually in the ﬁlter), but it
can cause small false positives (answering Yes when query-
ing an element that is not in the ﬁlter). A false positive oc-
curs when an element y is not stored in the ﬁlter, but acci-
dentally (by coincidence) B[h1(y)], ..., B[hk(y)] are all set
to 1. The probability that a false positive occurs, or the false
positive rate, for a Bloom ﬁlter can be made as small as de-
sired, and it can be calculated as follows.
The probability that one hash fails to set a given bit is
1−1/m. After n elements are inserted into the Bloom ﬁlter,
the probability that a speciﬁc bit is still 0 is: (1 − 1/m)kn.
The probability of a false positive, f, is the probability that
a speciﬁc set of k bits are 1, and it can be estimated with the
following approximation:
f ≈ (1 − (1 − 1/m)kn)k ≈ (1 − e
−kn/m)k
(1)
Three performance metrics in a Bloom ﬁlter can be
traded off: k (computation time), m (storage size) and f
(false positive). The false positive rate f is minimised when
2)k ≈ (0.6185)m/n. As m
k = ln2 × m/n, and fmin = ( 1
grows in proportion to n, f will decrease.
It is worthwhile to note that the claim by Bloom in
his original analysis [1] that the false-positive rate f =
(1 − (1 − 1/m)kn)k is incorrect. He implicitly assumed
that the event “B[h1(y)] = 1”, the event “B[h2(y)] = 1”,
..., and the event “B[hk(y)] = 1” are independent. How-
ever, this assumption is not necessarily true. For example,
that B[h1(y)] is set to 1 can have an impact on the outcome
of B[hk(y)]. Nonetheless, the false positive rate of Bloom
ﬁlters observed in simulations matched well with its theo-
retical estimation given by Equation (1), as shown in empir-
ical studies such as [9].
Notable applications of Bloom ﬁlters in computer secu-
rity include the following. In early 1990’s, Spafford [12]
proposed to use a Bloom ﬁlter to build a proactive pass-
word checker that could quickly tell whether a password
candidate was in a collection of weak passwords. Recently,
a new Bloom ﬁlter variant was introduced to store portions
of network packets for the purposes of payload attribution
in forensics [10]. A brief survey of application of the Bloom
ﬁlters in other contexts is also included in [10].
3. Enhancing the Razor system with Bloom
ﬁlters
Intuitively, if signature databases are organised with
Bloom ﬁlters in the Razor system, we could achieve
fast signature lookups, signiﬁcantly reduce the database
size, and obtain an efﬁcient algorithm for merging sig-
nature databases. However, the following two problems
have to be addressed before applying the Bloom ﬁlter tech-
nique to Razor.
• Choosing proper hash functions. A popular way of
constructing Bloom ﬁlters is to use MD5 or other cryp-
tographic hash functions, as described in [4]. However,
such a construction and the like do not work well in our
setting, as will be discussed below.
• Signature revocation. Occasionally, a Razor server has
to revoke from its database signatures that are falsely
identiﬁed as spam. However, a Bloom ﬁlter does not
support deletion: to set a bit to zero could delete too
many elements!
Choosing proper hash functions. Fan et al [4] used
MD5, a message digest function that hashes arbitrary length
strings to 128 bits, to implement their Bloom ﬁlter. They
chose k = 4, and the k hash functions were constructed as
follows: for each x to be inserted into the ﬁlter, they ﬁrst
applied the MD5 to get a 128-bit hashed value of x. The
hashed value was then divided into four 32-bit words. Tak-
ing the modulus of each 32-bit word by m, the size of the
bit vector, gave an index in the vector.
It would appear to be straightforward to generalise the
above method to construct the Bloom ﬁlters with arbitrary
k hash functions as follows:
hi(x) = (the i-th chunk of MD5(x)) mod m,
where i = 1, ..., k and k|128 (i.e., 128 is dividable by k).
However, the actual number of bits that can be utilised in
the Bloom ﬁlter will be bounded by min(m, 2128/k). See
Fig.1(a), which shows a scenario where all bits in the ﬁlter
are reachable and thus can be utilised, and Fig.1(b), which
shows a scenario where the number of utilisable bits are
smaller than the ﬁlter size m. Therefore, the above construc-
tion does not leave much room for the choice of k. For ex-
ample, when k = 8, the number of utilisable bits in the ﬁlter
is min(m, 216), which is too small for most applications! It
is also meaningless to trade off other parameters by increas-
ing m in this kind of scenario.
Proceedings of the 22nd Annual Computer Security Applications Conference (ACSAC'06)0-7695-2716-7/06 $20.00  © 2006hi(x), i = 1, …, k
hi(x), i = 1, …, k 
h1(x)                                   