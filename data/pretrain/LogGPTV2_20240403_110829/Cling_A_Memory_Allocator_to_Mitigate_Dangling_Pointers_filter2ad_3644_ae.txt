and tuning as much as possible, Table 2 also includes
columns for CPU and memory overhead using Cling
with a single pool (which implies no unwinding over-
head as well). We observe that in some cases Cling
with a single pool is faster and uses less memory than
the system allocator, hiding the non-zero overheads of
pooling allocations in the full version of Cling. On the
other hand, for some benchmarks with higher overhead,
such as dealII and parser, some of the overhead re-
mains even without using pools. For these cases, both
slow and fast, it makes sense to compare the overhead
against Cling with a single pool. A few programs, how-
ever, like xalancbmk, use more memory or run slower
with a single pool. As mentioned earlier, this benchmark
is quite sensitive to allocator tweaks.
Table 2 also includes columns for CPU and memory
overhead using Cling with many pools but without un-
winding wrappers. We observe that for espresso and
parser, some of the runtime overhead is due to this
unwinding.
Peak memory consumption was also low for most
benchmarks, except
for parser (14%), soplex
(27%), povray (33%), and espresso (13%). Inter-
estingly, for soplex and povray, this overhead is not
because of allocation pooling: these benchmarks incur
similar memory overheads when running with a single
pool.
In the case of soplex, we were able to deter-
mine that the overhead is due to a few large realloc
requests, whose current implementation in Cling is sub-
optimal. The allocation intensive benchmarks parser
and espresso, on the other hand, do appear to incur
memory overhead due to pooling allocations. Disabling
unwinding also affects memory use by reducing the num-
ber of pools.
The last two columns of Table 2 report virtual ad-
dress space usage. We observe that Cling’s address
space usage is well within the capabilities of modern 64-
bit machines, with the worst increase less than 150%.
Although 64-bit architectures can support much larger
address spaces, excessive address space usage would
cost in page table memory.
Interestingly, in all cases,
the address space increase did not prohibit running the
programs on 32-bit machines. Admittedly, however, it
would be pushing up against the limits.
In the ﬁnal set of experiments, we ran Cling with Fire-
fox. Since, due to the size of the program, this is the
most interesting experiment, we provide a detailed plot
of memory usage as a function of time (measured in al-
located Megabytes of memory), and we also compare
against the naive solution of Section 2.2.
The naive solution was implemented by preventing
Cling from reusing memory and changing the memory
block size to 4K, which is optimal in terms of mem-
ory reuse.
(It does increase the system call rate how-
Figure 11: Firefox memory usage over time (measured in
requested memory).
Figure 12: Firefox address space usage over time (mea-
sured in requested memory).
ever.) The naive solution could be further optimized by
not using segregated storage classes, but this would not
affect the memory usage signiﬁcantly, as the overhead
of rounding small allocation requests to size classes in
Cling is at most 25%—and much less in practice.
Figure 11 graphs memory use for Firefox. We ob-
serve that Cling (with pools) uses similar memory to the
system’s default allocator. Using pools does incur some
overhead, however, as we can see by comparing against
Cling using a single pool (which is more memory efﬁ-
cient than the default allocator). Even after considering
this, Cling’s approach of safe address space reuse ap-
pears usable with large, real applications. We observe
that Cling’s memory usage ﬂuctuates more than the de-
fault allocator’s because it aggressively returns memory
to the operating system. These graphs also show that the
naive solution has excessive memory overhead.
Finally, Figure 12 graphs address space usage for Fire-
fox.
It illustrates the importance of returning memory
to the operating system; without doing so, the scheme’s
memory overhead would be equal to its address space
use. We observe that this implied memory usage with
Firefox may not be prohibitively large, but many of the
benchmarks evaluated earlier show that there are cases
where it can be excessive. As for the address space usage
of the naive solution, it quickly goes off the chart because
it is linear with requested memory. The naive solution
was also the only case where the page table overhead
had a signiﬁcant contribution during our evaluation: in
this experiment, the system allocator used 0.99 MiB in
page tables, Cling used 1.48 MiB, and the naive solu-
tion 19.43 MiB.
5 Related Work
Programs written in high-level languages using garbage
collection are safe from use-after-free vulnerabilities, be-
cause the garbage collector never reuses memory while
there is a pointer to it. Garbage collecting unsafe lan-
guages like C and C++ is more challenging. Neverthe-
less, conservative garbage collection [6] is possible, and
can address use-after-free vulnerabilities. Conservative
garbage collection, however, has unpredictable runtime
and memory overheads that may hinder adoption, and is
not entirely transparent to the programmer: some port-
ing may be required to eliminate pointers hidden from
the garbage collector.
DieHard [4] and Archipelago [16] are memory alloca-
tors designed to survive memory errors, including dan-
gling pointer dereferences, with high probability. They
can survive dangling pointer errors by preserving the
contents of freed objects for a random period of time.
Archipelago improves on DieHard by trading address
space to decrease physical memory consumption. These
solutions are similar to the naive solution of Section 2.2,
but address some of its performance problems by even-
tually reusing memory. Security, however, is compro-
mised: while their probabilistic guarantees are suitable
for addressing reliability, they are insufﬁcient against at-
tackers who can adapt their attacks. Moreover, these so-
lutions have considerable runtime overhead for alloca-
tion intensive applications. DieHard (without its replica-
tion feature) has 12% average overhead but up to 48.8%
for perlbmk and 109% for twolf. Archipelago has
6% runtime overhead across a set of server applications
with low allocation rates and few live objects, but the
allocation intensive espresso benchmark runs 7.32
times slower than using the GNU libc allocator. Cling
offers deterministic protection against dangling pointers
 0 50 100 150 200 250 300 0 2000 4000 6000 8000 10000 12000 14000 16000Memory Usage (MiB)Requested Memory (MiB)ClingSystemCling (1 Pool)Naive 0 200 400 600 800 1000 0 2000 4000 6000 8000 10000 12000 14000 16000Address Space Usage (MiB)Requested Memory (MiB)ClingSystemCling (1 Pool)Naive(but not spatial violations), with signiﬁcantly lower over-
head (e.g. 16% runtime overhead for the allocation in-
tensive espresso benchmark) thanks to allowing type-
safe reuse within pools.
Dangling pointer accesses can be detected using
compile-time instrumentation to interpose on every
memory access [3, 24]. This approach guarantees com-
plete temporal safety (sharing most of the cost with spa-
tial safety), but has much higher overhead than Cling.
Region-based memory management (e.g. [14]) is a
language-based solution for safe and efﬁcient memory
management. Object allocations are maintained in a lex-
ical stack, and are freed when the enclosing block goes
out of scope. To prevent dangling pointers, objects can
only refer to other objects in the same region or regions
higher up the stack. It may still have to be combined with
garbage collection to address long-lived regions. Its per-
formance is better than using garbage collection alone,
but it is not transparent to programmers.
A program can be manually modiﬁed to use reference-
counted smart pointers to prevent reusing memory of ob-
jects with remaining references. This, however, requires
major changes to application code. HeapSafe [12], on
the other hand, is a solution that applies reference count-
ing to legacy code automatically. It has reasonable over-
head over a number of CPU bound benchmarks (geomet-
ric mean of 11%), but requires recompilation and some
source code tweaking.
Debugging tools, such as Electric Fence, use a new
virtual page for each allocation of the program and
rely on page protection mechanisms to detect dangling
pointer accesses. The physical memory overheads due
to padding allocations to page boundaries make this ap-
proach impractical for production use. Dhurjati et al. [8]
devised a mechanism to transform memory overhead to
address space overhead by wrapping the memory allo-
cator and returning a pointer to a dedicated new virtual
page for each allocation but mapping it to the physical
page used by the original allocator. The solution’s run-
time overhead for Unix servers is less than 4%, and for
other Unix utilities less than 15%, but incurs up to 11×
slowdown for allocation intensive benchmarks.
Interestingly, type-safe memory reuse (dubbed type-
stable memory management [13]) was ﬁrst used to sim-
plify the implementation of non-blocking synchroniza-
tion algorithms by preventing type errors during specu-
lative execution. In that case, however, it was not applied
indiscriminately, and memory could be safely reused af-
ter some time bound; thus, performance issues addressed
in this work were absent.
Dynamic pool allocation based on allocation site in-
formation retrieved by malloc through the call stack
has been used for dynamic memory optimization [25].
That work aimed to improve performance by laying out
objects allocated from the same allocation site consecu-
tively in memory, in combination with data prefetching
instructions inserted into binary code.
Dhurjati et al. [9] introduced type-homogeneity as a
weaker form of temporal memory safety. Their solution
uses automatic pool allocation at compile-time to seg-
regate objects into pools of the same type, only reusing
memory within pools. Their approach is transparent to
the programmer and preserves address space, but relies
on imprecise, whole-program analysis.
WIT [2] enforces an approximation of memory safety.
It thwarts some dangling pointer attacks by constraining
writes and calls through hijacked pointer ﬁelds in struc-
tures accessed through dangling pointers. It has an aver-
age runtime overhead of 10% for SPEC benchmarks, but
relies on imprecise, whole-program analysis.
Many previous systems only address the spatial di-
mension of memory safety (e.g. bounds checking sys-
tems like [15]). These can be complemented with Cling
to address both spatial and temporal memory safety.
Finally, address space layout randomization (ASLR)
and data execution prevention (DEP) are widely used
mechanisms designed to thwart exploitation of memory
errors in general, including use-after-free vulnerabilities.
These are practical defenses with low overhead, but they
can be evaded. For example, a non-executable heap can
be bypassed with, so called, return-to-libc attacks [20]
diverting control-ﬂow to legitimate executable code in
the process image. ASLR can obscure the locations of
such code, but relies on secret values, which a lucky or
determined attacker might guess. Moreover, buffer over-
reads [23] can be exploited to read parts of the memory
contents of a process running a vulnerable application,
breaking the secrecy assumptions of ASLR.
6 Conclusions
Pragmatic defenses against low-level memory corrup-
tion attacks have gained considerable acceptance within
the software industry. Techniques such as stack ca-
naries, address space layout randomization, and safe ex-
ception handling —thanks to their low overhead and
transparency for the programmer— have been read-
ily employed by software vendors.
In particular, at-
tacks corrupting metadata pointers used by the mem-
ory management mechanisms, such as invalid frees, dou-
ble frees, and heap metadata overwrites, have been ad-
dressed with resilient memory allocator designs, beneﬁt-
ing many programs transparently. Similar in spirit, Cling
is a pragmatic memory allocator modiﬁcation for defend-
ing against use-after-free vulnerabilities that is readily
applicable to real programs and has low overhead.
We found that many of Cling’s design requirements
could be satisﬁed by combining mechanisms from suc-
cessful previous allocator designs, and are not inherently
detrimental for performance. The overhead of mapping
allocation sites to allocation pools was found acceptable
in practice, and could be further addressed in future im-
plementations. Finally, closer integration with the lan-
guage by using compile-time libraries is possible, espe-
cially for C++, and can eliminate the semantic gap be-
tween the language and the memory allocator by for-
warding type information to the allocator, increasing se-
curity and ﬂexibility in memory reuse. Nevertheless, the
current instantiation has the advantage of being readily
applicable to a problem with no practical solutions.
Acknowledgments
We would like to thank Amitabha Roy for his suggestion
of intercepting returning functions to discover potential
allocation routine wrappers, Asia Slowinska for fruitful
early discussions, and the anonymous reviewers for use-
ful, to-the-point comments.
References
[1] AFEK, J., AND SHARABANI, A. Dangling pointer: Smashing
the pointer for fun and proﬁt. In Black Hat USA Brieﬁngs (Aug.
2007).
[2] AKRITIDIS, P., CADAR, C., RAICIU, C., COSTA, M., AND
CASTRO, M.
Preventing memory error exploits with WIT.
In Proceedings of the IEEE Symposium on Security and Pri-
vacy (Los Alamitos, CA, USA, 2008), IEEE Computer Society,
pp. 263–277.
[3] AUSTIN, T. M., BREACH, S. E., AND SOHI, G. S. Efﬁcient
detection of all pointer and array access errors. In Proceedings
of the ACM SIGPLAN Conference on Programming Language
Design and Implementation (PLDI) (New York, NY, USA, 1994),
ACM, pp. 290–301.
[4] BERGER, E. D., AND ZORN, B. G. DieHard: probabilistic mem-
ory safety for unsafe languages. In Proceedings of the ACM SIG-
PLAN Conference on Programming Language Design and Imple-
mentation (PLDI) (New York, NY, USA, 2006), ACM, pp. 158–
168.
[5] BERGER, E. D., ZORN, B. G., AND MCKINLEY, K. S. Re-
considering custom memory allocation. SIGPLAN Not. 37, 11
(2002), 1–12.
[6] BOEHM, H.-J., AND WEISER, M. Garbage collection in an
uncooperative environment. In Software Practice & Experience
(New York, NY, USA, 1988), vol. 18, John Wiley & Sons, Inc.,
pp. 807–820.
[7] CHEN, S., XU, J., SEZER, E. C., GAURIAR, P., AND IYER,
In Pro-
R. K. Non-control-data attacks are realistic threats.
ceedings of the 14th USENIX Security Symposium (Berkeley, CA,
USA, 2005), USENIX Association, pp. 177–192.
[8] DHURJATI, D., AND ADVE, V. Efﬁciently detecting all dan-
gling pointer uses in production servers. In Proceedings of the
International Conference on Dependable Systems and Networks
(DSN) (Washington, DC, USA, 2006), IEEE Computer Society,
pp. 269–280.
[9] DHURJATI, D., KOWSHIK, S., ADVE, V., AND LATTNER, C.
Memory safety without runtime checks or garbage collection.
In Proceedings of the ACM SIGPLAN Conference on Language,
Compiler, and Tool for Embedded Systems (LCTES) (2003),
pp. 69–80.
[10] EVANS, J. A scalable concurrent malloc(3) implementation for
FreeBSD. BSDCan, Apr. 2006.
[11] FENG, Y., AND BERGER, E. D. A locality-improving dynamic
memory allocator. In Proceedings of the Workshop on Memory
System Performance (MSP) (New York, NY, USA, 2005), ACM,
pp. 68–77.
[12] GAY, D., ENNALS, R., AND BREWER, E. Safe manual memory
management. In Proceedings of the 6th International Symposium
on Memory Management (ISMM) (New York, NY, USA, 2007),
ACM, pp. 2–14.
[13] GREENWALD, M., AND CHERITON, D. The synergy between
non-blocking synchronization and operating system structure.
SIGOPS Oper. Syst. Rev. 30, SI (1996), 123–136.
[14] GROSSMAN, D., MORRISETT, G., JIM, T., HICKS, M., WANG,
Y., AND CHENEY, J. Region-based memory management in Cy-
clone. In Proceedings of the ACM SIGPLAN Conference on Pro-
gramming Language Design and Implementation (PLDI) (New
York, NY, USA, 2002), ACM, pp. 282–293.
[15] JONES, R. W. M., AND KELLY, P. H. J. Backwards-compatible
bounds checking for arrays and pointers in C programs. In Pro-
ceedings of the 3rd International Workshop on Automatic Debug-
ging (AADEBUG) (1997), pp. 13–26.
[16] LVIN, V. B., NOVARK, G., BERGER, E. D., AND ZORN, B. G.
trading address space for reliability and security.
Archipelago:
SIGOPS Oper. Syst. Rev. 42, 2 (2008), 115–124.
[17] MITRE CORPORATION. Common vulnerabilities and exposures
(CVE). http://cve.mitre.org.
[18] MITRE CORPORATION. CWE-416: Use After Free. http:
//cwe.mitre.org/data/definitions/416.html.
[19] ROBERTSON, W., KRUEGEL, C., MUTZ, D., AND VALEUR, F.
Run-time detection of heap-based overﬂows. In Proceedings of
the 17th USENIX Conference on System Administration (LISA)
(Berkeley, CA, USA, 2003), USENIX Association, pp. 51–60.
[20] SOLAR DESIGNER. “return-to-libc” attack. Bugtraq, Aug. 1997.
[21] SOTIROV, A. Heap feng shui in JavaScript. In Black Hat Europe
Brieﬁngs (Feb. 2007).
[22] STANDARD PERFORMANCE EVALUATION CORPORATION.
SPEC Benchmarks. http://www.spec.org.
[23] STRACKX, R., YOUNAN, Y., PHILIPPAERTS, P., PIESSENS,
F., LACHMUND, S., AND WALTER, T. Breaking the memory
In Proceedings of the Second European
secrecy assumption.
Workshop on System Security (EUROSEC) (New York, NY, USA,
2009), ACM, pp. 1–8.
[24] XU, W., DUVARNEY, D. C., AND SEKAR, R. An efﬁcient and
backwards-compatible transformation to ensure memory safety
of C programs. In Proceedings of the 12th ACM SIGSOFT In-
ternational Symposium on Foundations of Software Engineering
(SIGSOFT/FSE) (New York, NY, USA, 2004), ACM, pp. 117–
126.
[25] ZHAO, Q., RABBAH, R., AND WONG, W.-F. Dynamic memory
optimization using pool allocation and prefetching. SIGARCH
Comput. Archit. News 33, 5 (2005), 27–32.