pacemaker: active/enabled
node2:0nline
nodel:Online
corosync:
"http://127.0.0.1/server-status"
Online
Online
(ocf::heartbeat:apache):
(ocf::heartbeat:IPaddr2)
active/enabled
topped
topped
---
## Page 277
置较好的服务器上，待其失效后再转移至较低配置的服务器上。这就需要配置优先级
动Apache，然后再启用VIP，这是不正确的。调整如【示例9-9】所示。
现VIP在节点node1上，而Apache运行在node2上的情况。另一个情况则是有可能集群先启
（Pacemaker中称为Location），此配置为可选，如【示例9-10】所示。
native color: Web allocation score on nodel: 20
native_color:
group_color:
group_color:
Allocation scores:
#数值越大表示优先级越高
【示例9-10】
如果 nodel与 node2的硬件配置不同，那么应该调整节点的优先级，让资源运行于硬件配
native_color:
group_color:
Current cluster status
[rootenodel ]# pcs constraint location Web prefers node2=5
[rootenodel ~]# pcs constraint location Web prefers nodel=10
#调整Location
[root@nodel ~]# pcs constraint order start VIP then start Web
#先启动VIP，然后再启动Web
#设置资源的启动停止顺序
#方式二：使用托管约束
[rootenodel ]# pcs resource
#将VIP和Web添加到myweb组中
#方式一：使用组的方式“捆绑”资源
【示例9-9】
Resource Group: myweb
[root@nodel ~]# crm simulate -sL
[root@nodel
[root@nodel ]# pcs resource group add myweb Web
添加资源后还需要对资源进行调整，让VIP和Web这两个资源“捆绑”在一起，以免出
（5）优先级
（4）调整资源
Web
VIP
Web allocation score on node2: 10
ViP allocation score on node2: 0
~1# pcs
(ocf::heartbeat:apache):
(ocf::heartbeat:IPaddr2):
node2
constraint
score on node2:20
a qemAw ppe dnoae
colocation add Web VIP INFINITY
on
nodel:
Started nodel
Started nodel
第9章双机热备
265
---
## Page 278
9.2.4
native color: Web allocation score on node2: -INFINITy
CentOS7系统管理与运维实战
266
过程如【示例9-11】所示。
提示
经过上面的配置，Pacemaker 集群已经配置完成，重新启动集群所有设置可以生效，启动
#验证VIP是否启用
2 Resources configured
2 Nodes configured
#启动所有集群
nodel:Stopping cluster
nodel: stopping cluster (pacemaker)...
#停止所有集群
Version: 1.1.12-a14efad
Stack: corosync
Last updated:Sat Apr 25 23:13:26 2015
Cluster name: mycluster
[root@nodel
#查看集群状态
nodel:
[rootenodel ~]# pcs cluster start
node2: Stopping Cluster
[rootenodel
【示例9-11】
PCSD Status:
Resource Group: myweb
Last
node2: Online
nodel:
Web
VIP
change:
Pacemaker测试
使用虚拟fence设备，
property set stonith-enabled=false 禁用 fence 设备。读者也可以使用在Linux上的虚拟机中
在本例中并没有设置fence设备，集群在启动时可能会提示一些错误，可以使用命令pcs
Online
Sat
~j# pcs status
(ocf::heartbeat:apache):
(ocf::heartbeat:IPaddr2):
Apr 2523:04:272015
关于虚拟fence设备的使用方法可参考相关文档了解。
(corosync)..
(corosync)..
(pacemaker).
--all
Started nodel
Started nodel
---
## Page 279
接管服务，方法是直接重启节点nodel，然后观察备节点是否接管了主机的资源，测试过程如
【示例9-12】所示。
state UP qlen 1000
Last updated: Sat Apr 25 23:23:41 2015
#在节点node1上执行重启操作
【示例9-12】
启动后正常情况下VIP设置在主节点192.168.3.87上。如主节点故障，则节点node2自动
root
#验证Apache是否启动
2: eno16777736:
1: 1o:  mtu 65536 qdisc nogueue state UNKNOWN
Daemon Status:
PCSD Status:
Full list of resources
OFFLINE:
Online:
[root@node2 ~]# pcs status
......
[rootenodel]# ps aux/grep
pacemaker:active/enabled
corosync: active/enabled
node2:
[root@nodel
inet 192.168.3.118/24 brd 192.168.3.255 scope global secondary eno16777736
inet 192.168.3.87/24 brd 192.168.3.255 scope global dynamic eno16777736
link/ether 00:0c:29:a0:3e:e5brd ff:ff:ff:ff:ff:ff
Web
VIP
Online
513000.0
nodel
node2
~]# reboot
(ocf::heartbeat:apache):
(ocf::heartbeat:IPaddr2)
 mtu 15OO qdisc pfifo fast
1.22378966196？
httpd
Started node2
Ss
Started node2
23:13
 0:00 /sbin/httpd
第9章双机热备
267
---
## Page 280
9.3.2
务异常，则keepalived 将把这台服务器从集群中剔除。
服务默认端口一般为3306，如果keepalived检测到3306无法登录或拒绝连接，则认为后端服
CentOS7系统管理与运维实战
268
192.168.3.1和192.168.3.2，keepalived主机为192.168.3.87，备机为192.168.3.88。
是否正常，如果与用户的设定不相符，则keepalived将把服务器从集群中剔除。
地址是否有效作为服务器工作正常与否的标准。
除。常见的场景为某台机器网卡损坏或服务器被非法关机。IP层的工作方式是以服务器的IP
如果发现某台服务的IP地址没有激活，keepalived便报告这台服务器异常，并将其从集群中剔
这些工作全部由keepalived 自动完成，不需要人工干涉，需要人工做的只是修复故障的服务器。
服务的节点恢复并且正常提供服务后keepalived自动将提供TCP服务的节点加入到集群中，
机，或工作出现故障，keepalived及时检测到，并将有故障的节点从系统中剔除，当提供TCP
9.3.1
keepalived为例说明keepalived的使用方法。
恢复且设置了优先给，VIP和Web又会重新被节点node1接管。
源接管程序，上述命令输出中说明VIP 和Web已经被节点 node2 成功接管。如果节点nodel
本节实现的功能为访问192.168.3.118的Web服务时，自动代理到后端的真实服务器
如 keepalived工作在应用层了，此时keepalived 将根据用户的设定检查服务器程序的运行
这种工作模式主要以TCP后台服务的状态来确定后端服务器是否工作正常。如MySQL
keepalived使用IP的方式工作时，会定期向服务器群中的服务器发送一个ICMP的数据包，
keepalived 的作用是检测后端TCP服务的状态，如果有一台提供TCP服务的后端节点死
关于HA 目前有多种解决方案，比如 Heartbeat、keepalived 等，各有优缺点。本节主要以
keepalived可以工作在TCP/IP协议栈的IP层、TCP层及应用层：
以上几种方式可以通过keepalived的配置文件实现。
（3）应用层
（2）TCP层
（1）IP层
keepalived安装与配置
keepalived 概述
双机热备软件keepalived
---
## Page 281
[root@nodel ~]# cat
步骤同主节点。接下来进行配置文件的设置，如【示例9-14】所示。
/etc/
如【示例9-13】所示。
#主节点配置文件
【示例9-14】
[rootenodel
[root@nodel keepalived-1.2.16]#make install
[root@nodel
(root@nodel keepalived-1.2.16]# yum install
#安装依赖软件
[root@nodel -1# cd keepalived-1.2.16
[root@nodel ]#tar xvf keepalived-1.2.16.tar.gz
【示例9-13】
最新的版本可以在http://www.keepalived.org获取，本示例采用的版本为1.2.16，安装过程
24#虚拟IP服务
22
21
15
N
l!Configuration File for keepalived
vrrp instance VI 1
state MASTER
#指定该节点为主节点备用节点上需设置为BACKUP
virtual_ipaddress!
#指定虚拟IP，两个节点需设置一样
authentication I
##设置验证信息，
advert_int 1
##组播信息发送间隔，
priority 50
#主节点的优先级，
virtual router id 51
#VRRP组名，两个节点需设置一样，以指明各个节点属于同一
interface enol677736
#绑定虚拟IP的网络接口
keepalived-1.2.16)# ln -s /usr/local/keepalived/etc/keepalived
keepalived-1.2.161#
192.168.3.118
auth_type PASs
-n /etc/keepalived/keepalived.conf
两个节点需一致
数值在1~254，
两个节点需设置
./configure
注意从节点必须比主节点优先级低
-y
-prefix=/usr/local/keepalived
openssl
 openssl-devel
VRRP组
第9章双机热备
269
---
## Page 282
CentOS7系统管理与运维实战
270
9.3.3
的权重相同，类似轮询的模式。Apache服务的部署可参考其他章节，此处不再赘述。
和192.168.3.2，
192.168.3.87备节点为192.168.3.88。虚拟IP为192.168.3.118后端的真实服务器有192.168.3.1
安装完毕后keepalived可以设置为系统服务启动，也可以直接通过命令行启动，命令行启
1.启动keepalived
经过上面的步骤keepalived已经部署完成，接下来进行keepalived的启动与故障模拟测试。
/etc/keepalived/keepalived.conf为keepalived的主配置文件。以上配置state表示主节点为
[root@node2 ]# cat-n /etc/keepalived/keepalived.conf
【示例9-15】
备节点配置大部分配置同主节点，不同处如【示例9-15】所示。
#其他配置和主节点相同
#不同于主节点，备机state设置为BACKUP
46
L9
N
20
keepalived启动与测试
#优先级低于主节点
当通过192.168.3.118访问Web服务时，自动转到后端的真实节点，后端节点
priority 50
state BACKUP
real server192.168.3.280
#后端实际TCP服务配置
real_server 192.168.3.180
#后端实际TCP服务配置
protocol TCP
#转发协议为TCP
#持久连接设置，会话保持时间
nat_mask 255.255.255.255
#指定LVS模式
lb_algo rr
#指定LVS算法
delay_1oop6
#设定检查实际服务器的间隔
lb kind nat
weight1
weight1
---
## Page 283
Transition to MASTER STATE
重新接管资源正常服务。测试过程如【示例9-18】所示。
问，如【示例9-17】所示。
/etc/keepalived/keepalived.conf
动方式如【示例9-16】所示。
上绑定了192.168.3.118这个VIP，而备节点处于监听的状态。Web服务可以通过VIP直接访
#部分结果省略
#备节点接管服务
故障模拟主要分为主节点重启，服务恢复，此时备节点正常服务，当主节点恢复后主节点
He110192.168.3.2
He110192.168.3.1
分别在主备节点上启动keepalived，然后通过ip 命令查看服务状态，在主节点etho 接口
#备节点启动keepalived
#查看备节点日志
#主节点服务终止
【示例9-18】
2.测试keepalived
[root@nodel conf]# curl http://192.168.3.118
#
【示例9-17】
[root@node2~1#ip addr 1ist
#
#查看服务状态
[root@node2 conf]# tail -f/var/log/messages
[root@nodel conf]# ip addr list
[root@nodel keepalived]#reboot
[root@nodel -]# keepalived -D -f /etc/keepalived/keepalived.conf
[root@nodel ~]# export PATH=/usr/local/keepalived/sbin:SPATH:.
#主节点启动keepalived
【示例9-16】
inet 192.168.3.118/32 scope global eno16777736
inet 192.168.3.88/24 brd 172.16.45.255 scope global dynamic eno16777736
inet 192.168.3.118/32 scope globa1 eno16777736
valid lft forever preferred_lft forever
valid 1ft 40807sec preferred_1ft 40807sec
第9章双机热备
271
---
## Page 284
面并没有实质性的区别，读者可根据实际情况进行选择。
keepalived 是目前使用比较广泛的高可用集群软件。本章分别介绍了Pacemaker 和keepalived