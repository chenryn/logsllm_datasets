viding advice on e.g., app naming and keyword optimization, oth-
ers provide illegal, banned or discouraged services that include
installing an app on many devices and keeping it installed for pro-
longed intervals, a.k.a., retention installs, and writing fake reviews
with high ratings.
We consider the ASO organizations studied in [67], see Figure 2,
that employ combinations of (1) ASO admins who organize and co-
ordinate communities of workers, and act as intermediaries between
developers and workers, (2) professional workers who use multiple
devices and accounts dedicated to ASO work, and (3) organic work-
ers who blend product promotion with personal activities from
their devices and accounts. In the following we informally use the
terms organic device and account, to denote devices and accounts
used by organic workers.
Developers can either directly hire ASO organizations or post
jobs in online boards dedicated to ASO work, see next.
ASO Communication Boards. Communications between devel-
opers, admins and crowdsourced workers often occur through dedi-
cated online boards in e.g., Facebook, WhatsApp, Telegram [67], see
Figure 2. In this paper we recruited participants through Facebook
groups that we identified using Facebook’s search functionality
(using keywords that include reviews, google reviews, app reviews,
app installs, android promotion) to identify relevant groups.
We found 11 public and 5 closed groups that matched our criteria.
We became members of the public groups and sent requests to
closed groups which were all accepted. These groups had 86,718
members (Min = 354, Max = 26896, M = 2840.5, SD = 6787.96) in
total. We detail our recruitment process in § 4.
3 MEASUREMENTS INFRASTRUCTURE
We have built the RacketStore platform to measure and compare the
app and device usage of ASO workers and regular users. RacketStore
641
Figure 3: RacketStore architecture consists of a mobile app installed by participants and a back-end server that collects and
aggregates snapshots reported by deployed apps.
WAKE_LOCK) that are automatically granted when the app is installed.
The RacketStore app was approved as compliant by the Play Store.
Data Buffer Module: Snapshot Processor. The data buffer mod-
ule (see Figure 3) leverages the device storage to process both types
of snapshots. The snapshot data is written to different accumulating
files depending on the snapshot type. When the slow snapshot accu-
mulation file reaches 8KB and the fast snapshot file reaches 100KB,
this module compresses the file and creates a new accumulation
file to store the following snapshots. We selected these threshold
values based on the observed battery and bandwidth consumption,
which we sought to minimize.
The slow snapshot alarm that fires every 2 minutes looks for any
existing compressed files in the mobile app’s directory and sends
them to our server. To enable resilient communications, upon file
reception, the server returns the crypto hash of the received data in
order for the mobile app to validate the transfer with its own hash
calculation. If the hashes are equal, the data buffer module deletes
the file.
Device Compatibility. The RacketStore app was targeted for de-
vices with Android version 9 (compile SDK and target SDK version
are Android Pie, API level 28) and is compatible with devices with
Android version at or above Lollipop (min SDK version = 5, API
level 21). In our deployment study (§ 4), RacketStore was compatible
with 298 unique device models from 28 Android device manufactur-
ers. The top 5 most popular Android manufacturers were Samsung,
Huawei, Oppo, Xiaomi, Vivo).
RacketStore Web App. We have built a web app that supports
RacketStore on the server side, see Figure 3. The Sign-in component
processes registration requests from the client app, interacts with
the Mongo database where the credentials are stored and sends the
response back to the client. The snapshot collector engine receives
the compressed snapshot files from the app, decompresses, and
inserts them into the database. The backend component consists
of two subsystems: (1) a review crawler that scraps reviews from
Google Play given an app name and a device model and (2) a Google
ID crawler that maps Gmail accounts to a unique Google ID (see
§ 5). The internal dashboard allows researchers to monitor the data
collection process, and test and validate the data sent from the app
to the server. Our stack is Linux-based and built on Python, PHP,
JavaScript, MongoDB, and MySQL. The recruitment website is an
informative website where we offer information to participants
about our study, ask for consent, and collect their emails to send
instructions on how to proceed (§ 4).
Security and Privacy Risks of RacketStore. RacketStore uses
TLS to encrypt all collected data while in-transit. We also securely
store all participant data on a server that is accessible from only 4
IP addresses in our campus. Further, RacketStore does not collect
any information if the user has not entered a 6-digit passcode. Each
study participant received a unique, random code. Participants can
deny access to any of the two permissions requested by RacketStore.
RacketStore minimizes collected Personal Identifiable Informa-
tion (PII) by only collecting PII that is needed for the study. Table 3
summarizes the participant PII that RacketStore collected, the rea-
sons for the collection and how long it was stored.
4 DATA COLLECTION
In order to collect app and device usage, we deployed RacketStore
with a group composed of both ASO workers and regular Google
Play users. In this section we detail our recruitment process and
discuss ethical considerations.
Recruitment of ASO Workers. We recruited ASO workers from
Facebook groups that we found to be dedicated to product promo-
tion (see § 2). Specifically, we posted calls to recruit participants
who would be able to install and provide reviews. Many group
members commented on our posts, expressed their interest, and
asked us to communicate with them over the Facebook inbox for
further details. We contacted such members over the Facebook
642
inbox. We shared with them the details of the recruitment instruc-
tions which we include in Appendix B. We asked them to reply if
they were interested and also to answer screening questions, i.e.,
confirm that they have posted paid reviews, specify how many
devices and accounts they have and on how many devices they can
install RacketStore.
We sent to each prospective participant, their participant ID (§ 3)
and a YouTube video that explains how to sign up for RacketStore.
We have received 672 installs from 549 unique worker-controlled
devices.
Recruitment of Regular Users. We have recruited regular An-
droid device users through commercial advertisements on Insta-
gram (see Figure 16 in Appendix B) that point to a landing page
that explains the study (see Figure 17(a) Appendix B). We chose
Instagram in order to minimize the exposure of Facebook groups
of ASO workers to our ads.
We posted the ads intermittently between December 17, 2019 and
April 15, 2020, spending a total of $79.23. Since cultural differences
could affect patterns in mobile device use [17, 82], we targeted reg-
ular users of similar demographic with the recruited ASO workers.
Concretely, we used Facebook’s audience creation functionality to
ensure that our ads were shown only to mobile devices of Insta-
gram users who are from the countries of the above workers, are
between 18 and 40 years old, speak English, and show interests
related to Google Play and Android applications as specified on
their Facebook profiles.
According to the Facebook Ads Manager, our ad was shown a
total of 136,022 times and reached 61,748 users. 2,471 of these users
clicked on the Instagram ad and made it to our landing page. The
landing page introduces our study, explains the payment method
(i.e., Paypal, Bitcoin or Litecoin), presents the consent form, and
allows visitors to either withdraw or sign up. To sign up, a visitor
needs to acknowledge and agree with the terms and conditions that
are included in the consent form explaining in detail the information
that we would collect from their phones (see § 4.1 for more details).
If the visitor consents, the landing page asks them to register in the
study by submitting their email address.
Of the consenting visitors, we have filtered out those who
claimed to have written paid reviews in Google Play (question
1 in the recruitment message, see Appendix B) and who claimed to
be administrators (question 6).
To each of the remaining 614 visitors, we sent an automatic
confirmation email along with the Google Play link to download
the RacketStore app (§ 3) and a six-digit unique participant ID
that the participant would need to type-in to the app. RacketStore
received 233 installs from these participants.
Participant Payments. We paid each participant who installed
RacketStore on a per device basis: $1 to install the app and $0.2
for each day on which the participant kept the app installed. The
process of registering in the study, providing consent and installing
RacketStore takes an average of 3 minutes. Participation does not
require any subsequent user interaction. We paid participants in
our follow-up study $5 for each 15 minutes of their time.
Overall, we recruited a ground truth set of 587 ASO workers
and 233 regular users. The participants used IP addresses from
Pakistan (420), India (210), Bangladesh (148), USA (10) and other
countries from Africa, Asia, South America and Europe (15). The
distribution of Worker (W) and Regular (R) participants for the
most represented countries was as follows: Pakistan (W: 364, R: 56),
India (W: 57, R: 153), Bangladesh (W: 143, R: 5) and USA (W: 8, R: 2).
We note that IP addresses can only provide an approximate measure
of geolocation [56]. The RacketStore app did not collect location
information from participant devices thus we cannot corroborate
this information.
4.1 Ethical Considerations
Some ASO work is considered unethical according to several ethical
frameworks, and many ASO workers belong to low-paid vulnerable
groups. This is why our study took utmost care to follow the best
ethical practices for conducting sensitive research with vulnera-
ble populations [30]. We did not use any deception in our study.
Participation in this study was completely voluntary. We did not
ask any participant to write reviews for any app, including for the
RacketStore app. We included the consent form both in the land-
ing page for our study and in the RacketStore app (see excerpts
in Appendix C). The consent form explicitly mentions the iden-
tity of the researchers, the research objectives, the data that we
wanted to collect, and the potential impacts on participants, in-
cluding risks. Our team members were also available to explain
this to the participants if needed. Each participant needed to ex-
plicitly provide consent. The full study procedure was examined
and approved by the Institutional Review Board of our university
(IRB-19-0392@FIU).
In Appendix D we further discuss the privacy policy and per-
missions requested by the RacketStore app, our data protection
procedure, and participant compensation.
We have then collected a total of 592,045 slow snapshots and
5 DATA
We now detail the data collected by RacketStore from 943 devices
between October 2019 and April 2020.
Snapshot Fingerprinting and Coalescing. We used a combina-
tion of the install ID, participant ID and Android ID collected by
RacketStore, along with its install interval to address repeat installs
and suspected incompatibilities of the RacketStore app, see Appen-
dix A. After this process, we identified 803 unique devices: 580
devices controlled by ASO workers and 223 devices controlled by
regular participants recruited through Instagram ads (§ 4).
57,770,204 fast snapshots (§ 3).
Google Play Review Dataset. The review crawler of the Backend
component of RacketStore’s web app (see Figure 3) collects reviews
posted for apps installed on participant devices every 12 hours.
For each of these apps, we collected the most recent reviews by
querying Google Play for reviews sorted by timestamp. The first
time an app was processed, we collected reviews until hitting a
threshold of 100,000 reviews. In subsequent collection efforts, we
collected the most recent reviews until finding a previously col-
lected review. This procedure allowed us to collect reviews “live” as
soon as our RacketStore mobile application discovered a new app
on a participant’s device.
Further, we collected reviews posted by accounts registered on
participant devices. This process uses the Google ID crawler com-
ponent of the Backend API in RacketStore’s web app (Figure 3),
643
maps e-mail accounts to Google IDs. To achieve this, for each Gmail
account registered on a device, the ID crawler issues requests to
Gmail’s email search functionality. This is because we found that
responses of Gmail’s email search functionality embed the Google
ID. We then list all the apps installed on each device, that are hosted
on the Play Store. Then, for each such app, we search the Google
IDs corresponding to accounts registered on the device, among the
Google IDs collected by the above review crawler from the Play
Store for the app.
We collected 110,511,637 reviews from 12,341 apps installed on
participant devices. Each review includes metadata, e.g., the user’s
Google ID, posting timestamp (1s granularity) and rating.
We also collected 217,041 reviews posted by the 10,310 Gmail
addresses registered on the worker-controlled devices of the par-
ticipants in our studies, with participant consent (§ 4.1). We have
reported to the Google Vulnerability Reward Program (VRP, issue
ID: 156369357) the functionality that we used to collect this data.
More specifically, our finding that responses of Gmail’s email search
functionality embed the user’s Google ID. This allows a third party
with a Gmail address, to obtain the account’s Google ID, then de-
termine if the account has posted a review in the Play Store for any
app of interest. Google responded that this is “intended behavior”
and made the decision “not to track it as a security bug”. We notified
study participants about this data collection (§ 4.1).
6 DEVICE USAGE MEASUREMENTS
We use the data collected from the participant devices (§ 5) to
investigate differences between workers and regular users in terms
of the accounts registered and the apps installed on their devices.
We used the Kolmogorov–Smirnov (KS) test to compare the
distributions of the features, and non-parametric and parametric
ANOVA (Analysis of Variance) to check for significant differences in
the means across groups. The reason for this is that after performing
the Shapiro test, we can not claim normality for any of the features
(p-value< 0.05). Similarly, after performing the Fligner-Killen test,
we found significant differences in the variances for all the features
(p-value< 0.05). Thus, we have also performed non-parametric
ANOVA since normality is not assumed. We report the result of the
three approaches.
6.1 Participant Engagement
Figure 4 shows the scatterplot of the average number of snapshots
per day vs. the number of active days over the participant devices.
Larger dots denote multiple overlapping devices. The average num-
ber of daily snapshots collected from regular devices is 9,430.71 (M
= 3,097.67, SD = 12,789.14, max = 63,452) and from worker devices
is 8,208.10 (M = 3,669, SD = 10,303.42, max = 55,281.38). The maxi-
mum number of snapshots per day is 55,281.38. We observe that
529 devices have reported at least 100 snapshots per day.
6.2 Registered Accounts
To post a review, a user needs to have a Gmail account. For one
app, a single review can be posted from any Gmail account. We
now investigate differences in the number and types of accounts
controlled by workers and regular users. We expect that workers
will have more Gmail accounts registered on their devices than
644
Figure 4: Scatterplot of average number of snapshots col-
lected per day vs active days over regular (green), and worker
(red) devices. Dot size indicates the number of overlapping