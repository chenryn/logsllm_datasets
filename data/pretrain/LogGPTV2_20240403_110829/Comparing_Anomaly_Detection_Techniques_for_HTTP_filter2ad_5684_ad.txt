f
e
v
i
t
i
s
o
p
e
u
r
T
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
 0.02
 0.04
 0.06
 0.08
 0.1
False positive fraction
aya.org
explorenm.com
i-pi.com
cs.unm.edu
Fig. 7. Receiver Operating Characteristic curves showing the accuracy of the 6-gram
algorithm
n-grams eﬀectively model the structure, or grammar, of a request by encoding
sequences of tokens as a directed graph in a manner similar to the DFA and
Markov Model. n-grams minimize false positives by allowing a small number of
mismatches, and it is better able to tell normal requests from nonsense.
4.7 False Positives
A human system administrator would have to inspect false positives to determine
if they represent normal traﬃc or attacks. When comparing the algorithms, a
useful metric is the load that the algorithm would place on this person. Table 1
shows the false positive rate per day, assuming a true positive rate of only 80%
is required. This table presents data using the cs.unm.edu data sets and shows
that only the 6-grams and the DFA have a false positive rate that might be
acceptable for a web site like the UNM CS department.
Most previous research has reported false positives as the fraction of the non-
attack test data misidentiﬁed, which is the value shown in the ROC plots pre-
sented in the earlier sections. This result can be misleading for web sites if a
5 Preliminary tests showed n = 6 to be optimal.
58
K.L. Ingham and H. Inoue
human must evaluate the abnormal requests to determine if if they represent at-
tacks. A 1% false positive rate on a lightly-visited web site may be tolerable; the
same percentage on Amazon.com or Google.com would require a large full-time
staﬀ. A false positive rate of 0.01 corresponds to 917, 50, 8, and 43 false positives
per day for cs.unm.edu, aya.org, i-pi.com, and explorenm.com respectively. In
the 1999 DARPA/MIT Lincoln Laboratories IDS tests, they stated that above
10 false positives per day is a high rate [15].
Table 1. False positive rate per day for the algorithms, trained and tested using the
cs.unm.edu data. Algorithms marked with ∞ did not achieve a threshold 80% true
positive rate. The Markov Model data transform is described in Section 4.4.
Algorithm
Mahalanobis distance
χ2 of ICD
Length
6-grams
DFA
Markov Model (log transform)
Linear combination
FP/day
91,524
∞
∞
13
37
39,824
∞
5 Discussion
The results in Section 4 show that character-based algorithms (Mahalanobis
distance, χ2 of ICD, and Length) are notably less accurate than two of the
token-based algorithms (DFA, n-grams). Tokens represent a higher lexical unit,
and are used by the system to represent meaning; attacks often represent non-
sensical requests. With the need to “ship the product yesterday” and other
deadlines, programmers often focus on making the system work under common
circumstances and spend fewer resources on exceptional cases. Additionally, to
consider all of the ways in which exceptional states may be represented requires
thinking in ways many programmers were not trained. In our attack database,
most, if not all, of the attacks are nonsensical. The ability to represent more of
the meaning of a HTTP request improves the ability of an algorithm to discrim-
inate between normal and abnormal. Presumably the normal requests do not
represent nonsense. Applying these concepts to the algorithms we tested, the
DFA and n-grams learn the higher-level structure of valid HTTP requests, and
so therefore they can use this structure to better tell if a request is normal or
not.
Both token based algorithms share a weakness in their similarity measures in
that they cannot discern between a novel request with a few new tokens and
an attack with a small number of tokens. This was responsible for some of the
missed attacks. Another attack missed by the DFA can be traced to a user typo.
Comparing Anomaly Detection Techniques for HTTP
59
The pair of tokens // appeared in the training data, causing an edge from the
node corresponding to the path separator / back to itself. Unfortunately, the
beck attack [7] used a multitude of /s to cause an out-of-memory condition in
an older version of Apache.
The idea of representing the meaning of the request allows us to make a pre-
diction: Statistics such as character distribution applied to tokens rather than
characters may be more accurate than when the same statistic is applied to the
characters making up the request. However, the relationships between tokens is
important to the semantics. Statistics on tokens are likely to be less accurate
unless the measure can represent these relationships. In eﬀect, by ignoring the
relationships between tokens, measures such as the character distribution algo-
rithms applied to tokens will continue to overgeneralize, and therefore be more
prone to mimicry attacks. Consider as an example all English-language sentences
with a speciﬁc distribution of words versus the sentences that are well-formed
and not nonsense.
6 Conclusion
This paper evaluated and compared seven diﬀerent diﬀerent anomaly intrusion
detection algorithms for HTTP under realistic conditions. This testing is more
rigorous than any HTTP IDS testing reported to date. For this comparison we
implemented an open-source IDS testing framework. In addition, we developed
the most comprehensive open database of HTTP attacks designed for IDS test-
ing.
Most previous IDS approaches for HTTP have represented the request as a
character string. The work we report is one of the ﬁrst to use tokens from parsing
the request, and the ﬁrst to use these tokens with DFA induction and n-grams.
These algorithms detect more attacks than earlier approaches. One reason for
this improved accuracy is that we use the complete HTTP request instead of
just a portion—most previous IDSs ignore portions of the request and obviously
cannot detect attacks in the ignored portions.
Our test results are explained by two factors. The ﬁrst is the data representa-
tion of the HTTP request. We have shown that the token-based methods result
in algorithms with a better ability to discriminate between sense and nonsense,
and as a result, between legitimate requests and attacks. The second factor is
generalization. We included several heuristics for generalization the algorithms
using tokens. A detailed discussion of the eﬀects of generalization is out of scope
for this paper but is provided by Ingham in [20].
This research has shown that all the algorithms have an unacceptable false
positive rate. We need additional algorithms and heuristics to improve perfor-
mance. Furthermore, our work implies that new approaches should be token
based, because they better represent HTTP requests than current algorithms.
We hope that the IDS testing framework described in this paper encourages
further research.
60
K.L. Ingham and H. Inoue
Acknowledgments
We thank the anonymous reviewers for their comments and suggestions. The ﬁrst
author was partially supported by National Science Foundation grant ANIR-
9986555. The second author is supported by the Canadian Government through
MITACS.
References
1. Apple Computer: Tunneling RTSP and RTP over HTTP (2006) (accessed Sep-
tember 13, 2006), http://developer.apple.com/ documentation/QuickTime/
QTSS/Concepts/chapter 2 section 14.html
2. Athanasiades, N., Abler, R., Levine, J., Owen, H., Riley, G.: Intrusion detection
testing and benchmarking methodologies. In: IEEE-IWIA ’03: Proceedings of the
First IEEE International Workshop on Information Assurance (IWIA’03), Wash-
ington, DC, USA, page 63, IEEE Computer Society, Los Alamitos (2003)
3. Booth, D., Haas, H., McCabe, F., Newcomer, E., Champion, M., Ferris, C., Or-
chard, D.: Web services architecture. Technical Report W3C Working Group Note
11 February 2004, World Wide Web Consortium (W3C) (2004)
(accessed 2007-
04-05), online at http://www.w3.org/TR/ws-arch/
4. Cohen, C.F.: CERT advisory CA-2002-17 Apache web server chunk handling vul-
nerability (July 2002) (accessed July 24, 2002),
http://www.cert.org/advisories/CA-2002-17.html
5. Corporation, M.: Common vulnerabilities and exposures (accessed June 16, 2006),
http://cve.mitre.org/
6. Curry, D., Debar, H.: Intrusion detection message exchange format data model and
extensible markup language (XML) document type deﬁnition (December 2002)
(accessed January 1, 2003),
http://www.ietf.org/internet-drafts/draft-ietf-idwg-idmef-xml-09.txt
7. cve.mitre.org: CVE-1999-0107 (July 1999) (accessed September 3, 2006),
http://www.cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-1999-0107
8. cve.mitre.org: CVE-1999-1199 (September 2004) (accessed October 30, 2005),
http://www.cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-1999-1199
9. Damashek, M.: Gauging similarity with n-grams: language-independent categoriza-
tion of text. Science 267(5199), 843–848 (1995)
10. Danyliw, R., Dougherty, C., Householder, A., Rueﬂe, R.: CERT advisory CA-2001-
26 Nimda worm (September 2001),
http://www.cert.org/advisories/CA-2001-26.html
11. Debar, H., Dacier, M., Wespi, A., Lampart, S.: An experimentation workbench for
intrusion detection systems. Technical Report RZ 6519, IBM Research Division,
Zurich Research Laboratory, 8803 R¨uuschlikon, Switzerland (September 1998)
12. Eastlake, D., Khare, R., Miller, J.: Selecting payment mechanisms over HTTP
(2006) (accessed September 13, 2006),
http://www.w3.org/TR/WD-jepi-uppflow-970106
13. Est´evez-Tapiador, J.M., Garc´ıa-Teodoro, P., D´ıaz-Verdejo, J.E.: Measuring nor-
mality in http traﬃc for anomaly-based intrusion detection. Journal of Computer
Networks 45(2), 175–193 (2004)
14. Fielding, R., Gettys, J., Mogul, J., Frystyk, H., Masinter, L., Leach, P., Berners-
Lee, T.: Hypertext transfer protocol—HTTP/1.1. RFC 2616 (June 1999) (accessed
October 2, 2002), ftp://ftp.isi.edu/in-notes/rfc2616.txt
Comparing Anomaly Detection Techniques for HTTP
61
15. Haines, J.W., Lippmann, R.P., Fried, D.J., Tran, E., Boswell, S., Zissman, M.A.:
1999 DARPA intrusion detection system evaluation: Design and procedures. Tech-
nical Report TR-1062, Lincoln Laboratory, Massachusetts Institute of Technology,
Lexington, MA, USA (February 2001)
16. Hancock, J., Wintz, P.: Signal Detection Theory. McGraw-Hill, New York (1966)
17. Heberlein, L.: Network security monitor (NSM)—ﬁnal report. Technical report,
University of California at Davis Computer Security Lab, Lawrence Livermore
National Laboratory project deliverable (1995),
http://seclab.cs.ucdavis.edu/papers/NSM-final.pdf
18. Heberlein, L., Dias, G., Levitt, K., Mukherjee, B., Wood, J., Wolber, D.: A network
security monitor. In: 1990 IEEE Computer Society Symposium on Research in
Security and Privacy, Oakland, CA, USA, May 7–9, 1990, pp. 296–304. IEEE
Computer Society Press, Los Alamitos, CA, USA (1990)
19. Hern´andez, L.O., Pegah, M.: WebDAV: what it is, what it does, why you need it.
In: SIGUCCS ’03: Proceedings of the 31st annual ACM SIGUCCS conference on
User services, New York, NY, USA, pp. 249–254. ACM Press, New York (2003)
20. Ingham, K.L.: Anomaly Detection for HTTP Intrusion Detection: Algorithm Com-
parisons and the Eﬀect of Generalization on Accuracy. PhD thesis, Department of
Computer Science, University of New Mexico, Albuquerque, NM, 87131 (2007)
21. Ingham, K.L., Somayaji, A., Burge, J., Forrest, S.: Learning DFA representations
of HTTP for protecting web applications. Computer Networks 51(5), 1239–1255
(2007)
22. Kruegel, C., Vigna, G.: Anomaly detection of web-based attacks. In: Proceedings of
the 10th ACM conference on Computer and communications security, pp. 251–261.
ACM Press, New York (2003)
23. Kruegel, C., Vigna, G., Robertson, W.: A multi-model approach to the detection
of web-based attacks. Computer Networks 48(5), 717–738 (2005)
24. Lippmann, R., Haines, J., Fried, D., Korba, J., Das, K.: The 1999 DARPA oﬀ-line
intrusion detection evaluation. Computer Networks 34(4), 579–595 (2000)
25. Mahoney, M.V.: Network traﬃc anomaly detection based on packet bytes. In: Pro-
ceedings of the 2003 ACM Symposium on Applied computing, pp. 346–350. ACM
Press, New York (2003)
26. Mahoney, M.V., Chan, P.K.: Learning nonstationary models of normal network
traﬃc for detecting novel attacks. In: Proceedings of the eighth ACM SIGKDD
international conference on Knowledge discovery and data mining, pp. 376–385.
ACM Press, New York (2002)
27. McHugh, J.: The 1998 Lincoln Laboratory IDS evaluation—a critique. In: Debar,
H., M´e, L., Wu, S.F. (eds.) RAID 2000. LNCS, vol. 1907, pp. 145–161. Springer,
Heidelberg (2000)
28. McHugh, J.: Testing intrusion detection systems: a critique of the 1998 and 1999
DARPA intrusion detection system evaluations as performed by Lincoln Labora-
tory. ACM Transactions on Information and Systems Security 3(4), 262–294 (2000)
29. Microsoft Corporation: Exchange server 2003 RPC over HTTP deployment
scenarios (2006) (accessed Sept 13, 2006), http://www.microsoft.com/technet
prodtechnol/exchange/2003/library/ex2k 3rpc.mspx
30. Puketza, N., Chung, M., Olsson, R., Mukherjee, B.: A software platform for testing
intrusion detection systems. IEEE Software 14(5), 43–51 (1997)
31. Puketza, N.J., Zhang, K., Chung, M., Mukherjee, B., Olsson, R.A.: A methodology
for testing intrusion detection systems. IEEE Transactions on Software Engineer-
ing 22(10), 719–729 (1996)
62
K.L. Ingham and H. Inoue
32. Robertson, W., Vigna, G., Kruegel, C., Kemmerer, R.A.: Using generalization and
characterization techniques in the anomaly-based detection of web attacks. In:
Network and Distributed System Security Symposium Conference Proceedings:
2006. Internet Society (2006) (accessed February 12, 2006),
http://www.isoc.org/isoc/conferences/ndss/06/proceedings/html/2006/
papers/anomaly signatures.pdf
33. Stolcke, A., Omohundro, S.: Hidden Markov Model induction by bayesian model
merging. In: Hanson, S.J., Cowan, J.D., Giles, C.L. (eds.) Advances in Neural
Information Processing Systems, vol. 5, pp. 11–18. Morgan Kaufmann, San Mateo,
CA (1993)
34. Stolcke, A., Omohundro, S.M.: Best-ﬁrst model merging for hidden Markov model
induction. Technical Report TR-94-003, International Computer Science Institute,
1947 Center Street, Suite 600, Berkeley, CA, 94704-1198 (1994)
35. Tombini, E., Debar, H., M´e, L., Ducass´e, M.: A serial combination of anomaly
and misuse IDSes applied to HTTP traﬃc. In: 20th Annual Computer Security
Applications Conference (2004)
36. Vargiya, R., Chan, P.: Boundary detection in tokenizing network application pay-
load for anomaly detection. In: Proceedings of the ICDM Workshop on Data Mining
for Computer Security (DMSEC). Workshop held in conjunction with The Third
IEEE International Conference on Data Mining, November 2003, pp. 50–59 (2003)
(accessed April 5, 2006), available at
http://www.cs.fit.edu/~pkc/dmsec03/dmsec03notes.pdf
37. Wan, T., Yang, X.D.: IntruDetector: a software platform for testing network intru-
sion detection algorithms. In: Seventeenth Annual Computer Security Applications
Conference, New Orleans, LA, USA, December 10–14, 2001, IEEE Computer So-
ciety, Los Alamitos, CA, USA (2001)
38. Wang, K., Stolfo, S.J.: Anomalous payload-based network intrusion detection. In:
Jonsson, E., Valdes, A., Almgren, M. (eds.) RAID 2004. LNCS, vol. 3224, pp.
203–222. Springer, Heidelberg (2004)
39. Warrender, C., Forrest, S., Pearlmutter, B.A.: Detecting intrusions using system
calls: Alternative data models. In: IEEE Symposium on Security and Privacy, pp.
133–145. IEEE Computer Society Press, Los Alamitos (1999)
40. Wiers, D.: Tunneling SSH over HTTP(S) (2006) (accessed September 13, 2006),
http://dag.wieers.com/howto/ssh-http-tunneling/