To realize F (cid:63)
Our model consists of a bounty maker denoted M and a set of
parties P1, P2, . . . , PN (denoting parties in the Bitcoin network).
37F (cid:63)
ML with session identiﬁer sid,
running with parties
P1, . . . , Pn and a parameter 1λ, proceeds as follows:
• Lock phase. Wait to receive (lock, sid, ssid, i, Di =
(x, φ1, . . . , φn, τ ), coins(x)) from each Pi and record
(locked, sid, ssid, i, Di). Then if ∀i, j : Di = Dj send
message (locked, sid, ssid) to all parties and proceed to the
Redeem phase. Otherwise, for all i, if the message (locked,
sid, ssid, i, Di) was recorded then delete it and send mes-
sage (abort, sid, ssid, i, coins(x)) to Pi, and terminate.
• Redeem phase.
• Payout phase.
In round τ: upon receiving a message
(redeem, sid, ssid, i, wi) from Pi, if φi(wi) = 1 then
delete (locked, sid, ssid, i, Di), send (redeem, sid, ssid,
coins(x)) to Pi and (redeem, sid, ssid, i, wi) to all parties.
if
(locked, sid, ssid, i, Di) was recorded but not yet deleted,
then delete it and send the message (payout, sid, ssid, i, j,
coins( x
In round τ + 1: For all i ∈ [n]:
n−1 )) to every party Pj (cid:54)= Pi.
Figure 7: The ideal functionality F (cid:63)
ML.
Figure 8: Illustration of the F (cid:63)
ML Functionality.
M holds a relation Φx (deﬁning a NP language L) and wishes
to learn a witness w such that Φx(w) = 1.
In return for the
knowledge of the witness M is willing to pay coins(q) to a party
C ∈ {P1, . . . , PN} that ﬁnds the witness. We stress that at the
time of bounty creation, the identity of the bounty collector is un-
known. Informally, the properties that we want to guarantee from
our bounty collection problem are:
• (Noninteractive.) The bounty maker M publishes a single mes-
• (Race-free soundness.) If there exists at most one party C that
knows the witness, then no party other than C or M can claim
the bounty except with probability negligible in λ.
• (Correctness and privacy.) An honest C holding valid witness
will claim the bounty except with probability negligible in λ. In
this case, only M learns the witness.
sage to the network and remains passive otherwise.
For simplicity we assume that there exists exactly one such bounty
collector C. Furthermore, we assume that the bounty maker is hon-
est (alternatively we can ask M to give a ZK proof that its published
message corresponds to a bounty). We assume that some small
fraction of the Bitcoin miners are malicious. Therefore, if the wit-
ness is made public on the Bitcoin network, this may in turn result
in a scenario where parties “race” to claim the bounty. Afterall
in such a situation, there is nothing that distinguishes C from any
other party. Formally, we deﬁne a noninteractive private bounty
mechanism as a four-tuple of algorithms (Make, Coll, Ver, Ext):
1. (tm, ω) ← Make(1λ, Φx). The bounty maker with input φ uses
private randomness ω and runs Make to generate tm.
2. tc ← Coll(w, tm). The bounty collector with a witness w such
that φ(w) = 1 uses algorithm Coll to generate tc.
3. {0, 1} ← Ver(tm, tc). Upon receiving a claim tc the miners
use Ver to determine whether the claim is valid.
4. w∪⊥ ← Ext(ω, tc). The bounty maker runs the algorithm Ext
using the message tc. The output of the algorithm is either w
such that Φx(w) = 1 or ⊥.
The scheme should satisfy:
Correctness (with guaranteed extraction) For any x, w such
that if x ∈ L (i.e., Φx(w) = 1):
(cid:20) (tm, ω) ← Make(φ, 1λ);
tc ← Coll(w, tm)
Pr
1 = Ver(tm, tc)(cid:86)
w = Ext(ω, tc)
(cid:21)
:
= 1.
Extractability There exists a simulator Sim = (S1, S2) such that
for all PPT adversaries E and all poly q there exists a PPT extractor
E and a poly p, such that for all auxiliary inputs z and for all x ∈
{0, 1}∗ the following holds:
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) Pr
(cid:20) (tm, ω) ← Make(Φx, 1λ);
(cid:20) (tm, st) ← S1(Φx, 1λ);
tc ← Coll(w, tm)
tc ← S2(tm, st)
−Pr
(cid:21)
(cid:21)
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ≥ 1/q(|x|)
: 1 = E(tm, tc)
: 1 = E(tm, tc)
= 1
= 1
=⇒ Pr[E(x, z) = w : Φx(w) = 1] ≥ 1/p(|x|).
The extractability condition above essentially formalizes the
privacy property which in turn helps in satisfying the “race-free
soundness” property. The condition effectively states that an ad-
versary does not learn any information about the witness w even
after obtaining both the bounty maker’s message and the collector’s
message. More precisely, an adversary can distinguish between the
simulated messages (where the simulator does not use the witness
at all) and the actual messages generated by M and C, only if it
already knew the witness. This leads us to a contradiction since
we assumed that only C knows the witness. Our deﬁnitions are
inspired by deﬁnitions of witness encryption, a powerful crypto-
graphic primitive that excellently ﬁts to our scenario.
Deﬁnition 5 (Witness encryption [16, 20]). A witness encryption
scheme for an NP language L (with corresponding witness rela-
tion φ) consists of the following two polynomial-time algorithms:
Encryption. The algorithm Enc(1λ, x, m) takes as input a secu-
rity parameter 1λ, an unbounded-length string x, and a message
m ∈ {0, 1}, and outputs a ciphertext ψ.
Decryption. The algorithm Dec(ψ, w) takes as input a ciphertext
ψ and an unbounded-length string w, and outputs a message m
or the symbol ⊥.
These algorithms satisfy:
• Correctness. For any security parameter λ, for any m ∈ {0, 1},
and for any x ∈ L such that φ(w; x) holds, we have that
Pr[Dec(Enc(1λ, x, m), w) = m] = 1.
♦
Deﬁnition 6 (Extractable security [20]). A witness encryption
scheme for a language L ∈ NP is secure if for all PPT adver-
saries A and all poly q there exists a PPT extractor E and a poly
p, such that for all auxiliary inputs z and for all x ∈ {0, 1}∗ the
following holds:
(cid:20) b ← {0, 1}; ψ ← Enc(1λ, x, b)
(cid:21)
≥ 1/2 + 1/q(|x|)
Pr
: A(x, ψ, z) = b
=⇒ Pr[E(x, z) = w : φ(w; x) = 1] ≥ 1/p(|x|).
B.3xA.3xC.3xD.3xA?3xB?3xC?3xD?3xC.xB.xD.xC.xA.xD.xB.xA.xD.xB.xA.xC.xA.3xD.3xB.3xC.3xtime≥τ+1time≥τ+1revealwArevealwDrevealwBrevealwC138A starting point is to let the bounty maker create a witness en-
cryption ψ of a signing key sk and create a Bitcoin transaction
t that allows a party to claim the bounty only if it possesses sk.
Clearly, a party holding the witness is able to decrypt ψ and us-
ing sk is able to transfer the bounty to a different address addr of
its choice. Note however that the above solution does not allow
the bounty maker to learn the witness! Alternatively, if the bounty
maker modiﬁes t such that the bounty can be claimed only if a party
can produce w such that Φx(w) = 1, then this appears to solve the
problem. Unfortunately, this idea turns out to be naïve since a party
C that claims the transaction reveals the witness which when made
public allows malicious miners to decrypt ψ, recover the signing
(cid:48) of its choice.
key and then claim the bounty to an address addr
In other words, this leads to a network race between the legitimate
collector C and malicious nodes on the Bitcoin network.
What we need is a mechanism that simultaneously allows a le-
gitimate collector to claim the bounty while allowing the bounty
maker to extract a valid witness. We present a novel solution to this
problem via use of garbled circuits. In our construction the bounty
maker broadcasts the following: (1) witness encryption ψ of the
signing key sk, (2) a garbled circuit computing Φx(·), (3) witness
encryption ψ(cid:48) of the input labels U corresponding to GC, (4) the
output label w1 of GC corresponding to the value 1, and (5) a trans-
action that releases the bounty to a party that possesses sk and sup-
plies input labels that evaluates GC to produce the output label w1.
Clearly, a legitimate collector can claim the bounty by decrypting
ψ, ψ(cid:48) and the revealing the input labels w(cid:48) corresponding to wit-
ness w. Further, since the bounty maker knows all input labels, it
can obtain the witness using w(cid:48). On the other hand, the privacy
property of the garbling scheme ensures that a malicious miner that
obtains w(cid:48), GC still does not have any information about the actual
witness w. Although the miners can copy the value w(cid:48) and claim
it as their own, a network race is avoided because they are unable
to forge a signature without knowing the signing key. Our bounty
mechanism is presented in Figure 9. We formally prove:
Theorem 3. Let λ be a computational security parameter. As-
suming the existence of extractable witness encryption, an exis-
tentially unforgeable secure signature scheme (SigKeyGen, Sig,
SigVer), and a secure garbling scheme (Gb, Eval), there exists a
noninteractive private bounty mechanism for NP language L with
relation Φx(·) for x ∈ L whose validation complexity equals the
complexity of Eval(Gb(1λ, Φx),·) plus the complexity of SigVer.
Proof sketch. We rely on the semantic security of the extractable
witness encryption scheme as well as the existential unforgeability
of the signature scheme. Speciﬁcally, we consider a simulator that
upon receiving input Φx for x ∈ L does the following:
• Compute ( ˆGC, ˆr, ˆU, ˆw) ← Fake(1λ, Φx).
• Let ˆw ∈ ˆw. Generate (pk, sk) ← SigKeyGen(1λ).
• Compute ˆψ = Enc(1λ, x, 0λ) and ˆψ(cid:48) = Enc(1λ, x, ˆU).
• Generate ˆσ = Sigsk(r(cid:48)) for random r(cid:48) and ˆw(cid:48) = ˆUˆr.
• Output tm = (Φx, ˆψ, ˆψ(cid:48), pk, ˆGC, ˆh) and tc = (ˆσ(cid:48), ˆw(cid:48)).
We then construct a series of games starting from the real tran-
script and ending up with the simulated transcript. In the ﬁrst set of
games we replace ψ by ˆψ, and then we replace one-by-one the in-
put labels in W with encryptions of 0 in a way that ultimately ends
up in transforming U to have a structure similar to ˆU. In the second
set, we replace the actual garbled circuit GC and the legitimate in-
put labels w(cid:48) by their faked counterparts ˆGC, ˆw(cid:48). By the security
of the garbling scheme we have that the adversary’s advantage in
Let (Enc, Dec) be a witness encryption scheme for L with wit-
ness relation Φx. Let (SigKeyGen, Sig, SigVer) be an existen-
tially unforgeable secure signature scheme. Let (Gb, Eval) be
a secure garbling scheme. The bounty protocol proceeds as
follows:
• M with input Φx executes Make(1λ, Φx, ω) for random ω:
– Generate (pk, sk) ← SigKeyGen(1λ).
– Generate (GC, U, W) ← Gb(1λ, Φx; ω).
– Compute ψ = Enc(1λ, x, sk) and ψ(cid:48) = Enc(1λ, x, U).
– Let (w0, w1) = W. Set tm = (Φx, ψ, ψ(cid:48), pk, GC, w1).
• C holding w such that Φx(w) = 1 executes Coll(w, tm):
– Compute sk ← Dec(ψ, w) and U ← Dec(ψ(cid:48), w).
– Set tc = (σ = Sigsk(addr), w(cid:48) = Uw).
• Miners execute Ver(tm, tc):
– Parse tm = (Φx, ψ, ψ(cid:48), GC, w1) and tc = (˜σ, ˜w(cid:48)).
– Output 1 iff SigVer(pk, ˜σ) = 1(cid:86) Eval(GC, ˜w(cid:48)) = w1.
• M executes Ext(φ, ω, tc):
– Parse tc = (σ(cid:48), w(cid:48)). If SigVer(pk, σ(cid:48)) = 0, output ⊥.
– Output ˆw s.t. U ˆw = w(cid:48). If no such ˆw exists output ⊥.
Figure 9: A noninteractive Bitcoin bounty mechanism.
second set of games is negligible in λ. Therefore, an adversary that
has 1/poly advantage in distinguishing real transcripts from simu-
lated transcripts must have 1/poly advantage in distinguishing be-
tween the real transcript and the last of the ﬁrst set of games. Then
by appealing to the extrability of witness encryption schemes, we
can derive an extractor who succeeds in guessing the witness with
1/poly probability. Finally observe that the privacy of the scheme
and the security of the signature scheme taken together sufﬁce to
show that our mechanism provides race-free soundness.
Remark. Extractable witness encryption is a heavy assump-
tion [15] and is quite inefﬁcient in practice (cf. [13]). We sketch
a heuristic construction to replace use of witness encryption that
works for certain languages. For e.g., assume that x ∈ L iff x is
a RSA modulus. Let Φx(w) = 1 iff w = (p, q) such that both
p and q are prime and x = p · q. Our key observation is that
we can replace the witness encryption scheme simply by any RSA
encryption scheme with RSA modulus x. Note that knowing the
factorization of the RSA modulus x readily allows decryption.
Bounties via time-locked puzzles. We now sketch a noninteractive
nonprivate bounty mechanism that still enjoys race-free soundness.
To do this, we use a time-lock puzzles scheme [32]. Such a scheme
allows the bounty maker M to generate a time-locked encryption
sk(cid:48) = puzz(sk, t), so that it should take approximately time t for
anyone besides M to compute sk from sk(cid:48) (even allowing parallel
computations). The time-lock scheme allows M to generate sk(cid:48) in
time that is orders of magnitude shorter than t, hence M can esti-
mate which t0 implies that the puzzle would take e.g. ≥ 30 minutes
to solve at the year in which computing the witness w is likely to
be feasible, and use ψ = Enc(1λ, x, puzz(sk, t0)) for the witness
encryption scheme. This way, C would have a head start of t0
over other parties, and is therefore likely to win the race because its
transaction will be buried under enough PoW blocks. Depending
on the complexity of Φx(·), this bounty protocol may be realizable
with the current Bitcoin standard scripts.
397. CONCLUSIONS
In this paper we have shown that a variety of cryptographic prim-
itives can be incentivized in order to encourage honest behavior by
participants. We believe that our constructions offer compelling
motivation to change the state-of-affairs. Our work leaves a num-
ber of open questions some of which are mentioned below.
• Veriﬁable computation.
Is it possible to develop a formal
model to incentivize based on the resource usage of the worker
in private veriﬁcation schemes?
• Fair computation. Is it possible to design a protocol that needs
only O(1) rounds and O(n) transactions in the worst case?
• Secure computation with leakage. Is it possible to come up
with a general methodology to design highly efﬁcient secure
computation protocols that guarantee restricted leakage? Can
such protocols be incentivized?
Acknowledgments
This work was supported by funding received from European Com-
munity’s Seventh Framework Programme (FP7/2007-2013) under
grant agreement number 259426 and 240258. The second author
would like to thank Alex Mizrahi for useful discussions and contri-
butions to Section 5.1.
8. REFERENCES
[1] Bitcoin wiki: CVEs. https://en.bitcoin.it/wiki/CVEs#CVE-2010-5141.
[2] G. Andresen. Turing complete language vs non-turing
complete. https://bitcointalk.org/index.php?topic=431513.20#msg4882293.
[3] M. Andrychowicz, S. Dziembowski, D. Malinowski, and L.
Mazurek. Fair two-party computations via the bitcoin