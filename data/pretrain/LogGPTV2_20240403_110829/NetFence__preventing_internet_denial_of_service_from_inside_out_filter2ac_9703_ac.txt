a transport protocol such as TCP to fully utilize its available band-
width.
Figure 4: Once a router Rb encounters congestion between time
[t, t1], it will continuously stamp the L↓ feedback until t1 + 2Ilim.
A packet may cross multiple links in the mon state. The access
router must ensure that the sender’s rate does not exceed its legit-
imate share at any of these links. The second rule above allows
NetFence to achieve this goal, gradually. This is because the ﬁrst
link L1 on a packet’s forwarding path that is both overloaded and in
the mon state can always stamp the L↓
1 feedback, and downstream
links will not overwrite it. When the L↓
1 feedback is presented to
an access router, the router will reduce the sender’s rate limit for
the link L1 until L1 is not overloaded and does not stamp L↓
1. This
would enable the next link (L2) on the path that is both in the mon
state and overloaded to stamp L↓
2 into the packets. Gradually, a
sender’s rate will be limited such that it does not exceed its fair
share on any of the on-path links in the mon state.
4.3.3 Regular Packet Policing at Access Routers
A sender src’s access router polices the sender’s regular packets
based on the congestion policing feedback in its packets. If a packet
carries the nop feedback, indicating no downstream links require
congestion policing, the packet will not be rate-limited. Otherwise,
if it carries L↑ or L↓, it must pass the rate limiter (src, L).
We implement a rate limiter as a queue whose de-queuing rate
is the rate limit, similar to a leaky bucket [44]. We use the queue
to absorb trafﬁc bursts so that bursty protocols such as TCP can
function well with the rate limiter. We do not use a token bucket
because it allows a sender to send short bursts at a speed exceeding
its rate limit. Strategic attackers may synchronize their bursts to
temporarily congest a link, leading to successful on-off attacks.
When an access router forwards a regular packet to the next hop,
it resets the congestion policing feedback. If the old feedback is
nop, the access router refreshes the timestamp of the feedback. If
the old feedback is L↓ or L↑, the access router resets it to L↑. This
design reduces the computational overhead at the link L’s router,
as it does not update a packet’s feedback if L is not overloaded.
For simplicity, NetFence uses at most one rate limiter to police
a regular packet. One potential problem is that a ﬂow may switch
between multiple rate limiters when its bottleneck link changes. We
discuss this issue in § 4.3.5.
4.3.4 Robust Rate Limit Adjustment
The L↑ and L↓ feedback enables an access router to adjust a
rate limiter (src, L)’s rate limit rlim with an AIMD algorithm. A
strawman design would decrease rlim multiplicatively if the link L
is overloaded and stamps the L↓ feedback, or increase it additively
otherwise. However, a malicious sender can manipulate this design
by hiding the L↓ feedback to prevent its rate limit from decreasing.
To address this problem, we periodically adjust a rate limit, use
L↑ as a robust signal to increase the rate limit, and ensure that a
sender cannot obtain valid L↑ feedback for a full control interval if
its trafﬁc congests the link L. Let Ilim denote the control interval
length for rate adjustment on an access router. Suppose a down-
stream bottleneck router Rb has a link L in the mon state. Rb
259We have considered various solutions to address this problem.
One simple solution is to allow a packet to carry all feedback from
all the bottleneck links on its path. An access router can then pass
the packet through all the on-path rate limiters, each receiving its
own feedback and policing the packet independently. This solution
requires a longer and variable-length NetFence header. Another
one is for an access router to infer the on-path bottleneck links of
a packet based on history information and send the packet through
all the inferred rate limiters.
We do not include these solutions in the core design for sim-
plicity. We describe the details of these solutions in [28], and use
simulations to evaluate how NetFence performs against those al-
ternative designs when there are multiple bottlenecks. The results
suggest that NetFence’s performance is acceptable. Thus, we con-
sider it a worthy tradeoff to keep the design simple.
4.4 Securing Congestion Policing Feedback
Congestion policing feedback must be unforgeable. Malicious
end systems should not be able to forge or tamper the feedback,
and malicious routers should not be able to modify or remove the
feedback stamped by other routers. The NetFence design uses efﬁ-
cient symmetric key cryptography to achieve these goals.
Feedback format: A congestion policing feedback consists of
ﬁve key ﬁelds as shown in Figure 5: mode, link, action, ts,
and M AC. When the mode ﬁeld is nop, it represents the nop
feedback. When the mode ﬁeld is mon, the link ﬁeld indicates
the identiﬁer (an IP address) of the corresponding link L, and the
action ﬁeld indicates the detailed feedback: if action is incr (decr),
it is the L↑ (L↓) feedback. The ts ﬁeld records a timestamp, and
the M AC ﬁeld holds a MAC signature that attests the feedback’s
integrity.
In addition to the ﬁve key ﬁelds, a mon feedback also includes a
ﬁeld tokennop. We explain the use of this ﬁeld later in this section.
Stamping nop feedback: When an access router stamps the nop
feedback, it sets mode to nop, link to a null identiﬁer linknull,
action to incr, ts to its local time, and uses a time-varying secret
key Ka known only to itself to compute the M AC:
tokennop = M ACKa (src, dst, ts, linknull, nop)
(1)
The MAC computation covers both the source and destination
addresses to prevent an attacker from re-using valid nop feedback
on a different connection.
Stamping L↑ feedback: When an access router stamps the L↑
feedback, the mode ﬁeld is already mon, and the link ﬁeld already
contains the link identiﬁer L. The router sets action to incr and
ts to its local time, and computes the M AC ﬁeld using the secret
key Ka:
tokenL↑ = M ACKa (src, dst, ts, L, mon, incr)
(2)
The router also inserts a tokennop as computed in Eq (1) into
the tokennop ﬁeld.
Stamping L↓ feedback: When a link L’s router Rb stamps the
L↓ feedback, it sets mode to mon, link to L, action to decr,
and computes a new M AC value using a secret key Kai shared
between its AS and the sender’s AS:
tokenL↓ = M ACKai (src, dst, ts, L, mon, decr, tokennop)
(3)
The shared secret key Kai is established by piggybacking a dis-
tributed Difﬁe-Hellman key exchange in BGP as in [26]. The router
Rb includes tokennop stamped by the sender’s access router in its
MAC computation, and erases it afterwards to prevent malicious
downstream routers from overwriting its feedback.
mode
link
action
ts
MAC
Figure 5: The key congestion policing feedback ﬁelds.
If Rb is an AS internal router that does not speak BGP, it may
not know Kai. In this case, Rb can leave the M AC and tokennop
ﬁelds unmodiﬁed and let an egress border router of the AS update
their values when the packet exits the AS. This design reduces the
management overhead to distribute Kai to an internal router Rb.
Validating feedback: When a source access router receives a reg-
ular packet, it ﬁrst validates the packet’s congestion policing feed-
back.
If the feedback is invalid, the packet will be treated as a
request packet and subject to per-sender request packet policing.
A feedback is considered invalid if its ts ﬁeld is more than w sec-
onds older than the access router’s local time tnow: |tnow − ts| >
w, or if the M AC ﬁeld has an invalid signature. The M AC ﬁeld
is validated using Eq (1) and Eq (2) for the nop and L↑ feedback,
respectively. To validate L↓ feedback, the access router ﬁrst re-
computes the tokennop using Eq (1), and then re-computes the
MAC using Eq (3). The second step requires the access router to
identify the link L’s AS in order to determine the shared secret key
Kai. We can use an IP-to-AS mapping tool [33] for this purpose,
as the feedback includes the link L’s IP address.
4.5 Localizing Damage of Compromised Routers
The NetFence design places enforcement functions that include
feedback validation and trafﬁc policing at the edge of the network
to be scalable. However, if an access router is compromised, attack-
ers in its subnet or itself may misbehave to congest the network.
NetFence addresses this problem by localizing the damage to the
compromised AS. If an AS has a compromised router, we consider
the AS as compromised, and do not aim to provide guaranteed net-
work access for that AS’s legitimate trafﬁc.
A NetFence router can take several approaches to localize the
damage of compromised ASes, if its congestion persists after it
has started a monitoring cycle, a signal of malfunctioning access
routers. One approach is to separate each source AS’s trafﬁc into
different queues. This requires per-AS queuing. We think the over-
head is affordable because the present Internet has only about 35K
ASes [7]. We may replace per-AS queuing with per-AS rate lim-
iting and set the rate limits by periodically computing each AS’s
max-min fair share bandwidth on the congested link as in [30].
Another more scalable approach is to use a heavy-hitter detection
algorithm such as RED-PD [31] to detect and throttle high-rate
source ASes. A heavy-hitter detection algorithm is suitable in this
case because legitimate source ASes will continuously reduce their
senders’ trafﬁc as long as they receive the L↓ feedback. The de-
tected high-rate ASes are likely to be the compromised ASes that
do not slow down their senders.
All these approaches require a router to correctly identify a packet’s
source AS, which can be achieved using an IP-to-AS mapping tool
if the packet’s source IP address is not spoofed. NetFence uses
Passport [26] to prevent source address spooﬁng. A Passport header
is inserted between IP and the NetFence header. Passport pig-
gybacks a distributed Difﬁe-Hellman key exchange in the inter-
domain routing system to enable each pair of ASes to share a se-
cret key. A source AS uses a key it shares with an AS on the
path to a destination to compute a secure MAC and inserts it into
a packet’s Passport header. Each AS on the path can verify that
a packet is originated from the source AS by validating the corre-
sponding MAC. NetFence also uses Passport to establish the shared
secret keys between ASes to secure the congestion policing feed-
back (§ 4.4).
2604.6 Parameter Settings
Figure 3 summarizes the main parameters in the NetFence de-
sign and their values used in our implementation. The level-1 re-
quest packets (l1) are rate limited at one per 1 ms. A request
packet size is estimated as 92 bytes that includes a 40-byte TCP/IP
header, a 28-byte NetFence header (Figure 6) and a 24-byte Pass-
port header [26]. We set the control interval Ilim to 2 seconds, one
order of magnitude larger than a typical RTT (< 200ms) on the
Internet. This allows an end-to-end congestion control mechanism
such as TCP to reach a sender’s rate limit during one control inter-
val. We do not further increase Ilim because a large control interval
would slow down the rate limit convergence.
The rate limit AI parameter ∆ can be neither too small nor too
large: a small ∆ would lead to slow convergence to fairness; a
large ∆ may result in signiﬁcant overshoot. We set ∆ to 12Kbps
because it works well for our targeted fair share rate range: 50Kbps
∼ 400Kbps. A legitimate sender may abort a connection if its send-
ing rate is much lower than 50Kbps, and 400Kbps should provide
reasonable performance for a legitimate sender during DoS ﬂood-
ing attacks. The rate limit MD parameter δ is set to 0.1, a value
much smaller than TCP’s MD parameter 0.5. This is because a
router may stamp the L↓ feedback for two control intervals longer
than the congestion period (§ 4.3.4).
We set the attack detection threshold pth to 2%, since at this
packet loss rate, a TCP ﬂow with 200ms RTT and 1500B packets
can obtain about 500Kbps throughput [34]. We set a link’s maxi-
mum queue length Qlim to 200ms × the link’s capability. We use
a loss-based algorithm RED to detect a link’s congestion status. It
is our future work to implement a load-based algorithm (e.g., [46]).
5. ANALYSIS
In this section, we analyze the scalability and security of Net-
Fence, and discuss the incremental deployment issues.
5.1 Scalability
As a closed-loop design, NetFence can place different functions
at different locations to provide per-sender fairness. It places per-
sender trafﬁc policing at access routers, and lightweight congestion
detection, feedback stamping, and AS-level policing at bottleneck
routers. In contrast, per-host fair queuing, an open-loop solution
used in previous work [48, 27], does not have this ﬂexibility. Every
bottleneck router must keep per-host queues to provide per-sender
(or per-receiver) fairness. There are only 35K ASes on today’s In-
ternet [7], while the number of compromised hosts involved in a
DoS attack could reach millions [17]. Thus, compared to per-host
fair queuing, NetFence can signiﬁcantly reduce the amount of state
kept by a bottleneck router.
However, NetFence access routers need to perform per-(sender,
bottleneck link) rate limiting. Our calculation suggests that with
today’s hardware technology, they can afford to do so and will not
become a new scaling bottleneck. While we do not have accu-
rate data to estimate the number of bottlenecks a sender traverses
during attack times, we think 100 links per legitimate sender is a
reasonable upper bound. An access router can aggregate a sender’s
rate limiters by bottleneck links’ preﬁxes if a sender needs more
than 100 rate limiters. If an access router serves 10K end hosts, it
will have at most one million rate limiters in total. Each rate lim-
iter needs about 24 bytes of memory for state variables (1 bit for
hasIncr, 8 bytes for two timestamps, 4 bytes for the rate limit,
and 12 bytes for a queue object) and another 1500 bytes to queue at
least one packet. The total amount of memory requirement is less
than 2GB, and we can use fast DRAM for this purpose as access
routers’ line speeds are typically slower than those of core routers.
The processing overhead of an access router is also acceptable.
The per-packet processing time on our benchmarking PC is less
than 1.3µs during attack times (§ 6.2). This translates into a through-
put of 770K packets per second, or more than 9 Gbps, assuming
1500-byte packet size and CPU is the throughput bottleneck. Im-
plementing the cryptographic operations in hardware can further
improve an access router’s throughput.
5.2 Security
Next we summarize how NetFence withstands various attacks.
5.2.1 Malicious End Systems
Forgery or Tampering: Malicious end systems may attempt to
forge valid congestion policing feedback. But NetFence protects
congestion policing feedback with MAC signatures. As long as
the underlying MAC is secure, malicious end systems cannot spoof
valid feedback. A malicious sender may selectively present L↑ or
hide L↓ to its access router, but NetFence’s robust AIMD algorithm
(§ 4.3.4) prevents it from gaining a higher rate limit.
Evading attack detection: Malicious end systems may attempt to
prevent a congested router from starting a monitoring cycle. This
attack is ineffective when a well-provisioned router uses high link
utilization to detect attacks. When an under-provisioned router uses