0.7
0.7
AUC
T Prate
FPrate
97
98
98
98
97
99
99
100
99
99
0
0.1
0
0.2
0.1
AUC
99
99
100
99
99
to the best of our knowledge, have no known malware
association.
7.1 DGA Classiﬁer’s Detection Results
In this section, we present the accuracy of the DGA
classiﬁer. We bootstrap the classiﬁer with NXDo-
mains from Bobax, Sinowal, Conﬁcker-A, Conﬁcker-B,
Conﬁcker-C and Murofet. We test the classiﬁer in two
modes. The ﬁrst mode is bootstrapped with a “super”
Conﬁcker class composed of an equal number of samples
from Conﬁcker-A, Conﬁcker-B and Conﬁcker-C classes
and another with each Conﬁcker variant as its own class.
As we mentioned in Section 5.2, the DGA classiﬁer is
based on a multi-class version of the Alternating Deci-
sion Trees (ADT) learning algorithm [9]. We build the
vectors for each class by collecting NXDomains from
one day of Honeypot trafﬁc (in the case of Sinowal and
Bobax) and one day of NXDomains produced by the
DGAs for Conﬁcker-A, Conﬁcker-B, Conﬁcker-C and
Murofet. Finally, the domain names that were used to
represent the benign class were the ﬁrst 10,000 Alexa
domain names with and without the www. child labels.
From the raw domain names in each of the classes,
we randomly selected 3,000 sets of cardinality a . As a
reminder, the values of a
that we used were two, ﬁve,
ten and 30. This was to build different training datasets
in order to empirically decide which value of a would
provide the best separation between the DGA models.
We generated additional testing datasets. The domain
names we used in this case were from each class as in
the case of the training dataset but we used different days.
We do that so we get the minimum possible domain name
overlap between the training and testing datasets. We
evaluate the training datasets using two methods: 10-fold
cross validation on the training dataset and by using the
testing datasets computed from domains collected on dif-
ferent days. Both methods gave us very similar results.
Our system performed the worst in the case of the 10-
fold cross validation, therefore we chose to present this
worst-case scenario.
In Table 1, we can see the detection results using two
values for a , ﬁve and ten. We omit the results for the
other values due to space limitations. The main confu-
sion between the classes was observed in the datasets
that contained separate Conﬁcker classes, speciﬁcally
between the classes of Conﬁcker-A and Conﬁcker-B. To
address this problem, we created a generic Conﬁcker
class that had an equal number of vectors from each Con-
ﬁcker variant. This merging of the Conﬁcker variants
into a single “super” class allowed the DGA classiﬁer
to correctly classify 99.72% (Table 1) of the instances
(7,986 correctly classiﬁed vs 22 incorrectly classiﬁed).
Using the datasets with the ﬁve classes of DGAs, the
weighted average of the T Prates and FPrates were 99.7%
and 0.1%, respectively. As we see in Table 1, a = 5 per-
forms reasonably well, but with a higher rate of FPs.
7.2 NXDomain Clustering Results
In this section, we will discuss results from the DGA
discovery module. In particular, we elaborate on the se-
lection of the thresholds used, the unique clusters identi-
ﬁed and the false alerts the DGA discovery module pro-
duced over the duration of our study.
7.2.1 Correlation Thresholds
In order to set the thresholds q ma j and q s deﬁned
in Section 4.2, we spent the ﬁrst ﬁve days of Novem-
ber 2010 labeling the 213 produced clusters as DGA re-
lated (Positive) or noisy (Negative). For this experiment,
we included all produced clusters without ﬁltering out
those with q m =98% (or higher) “similarity” to an already
known one (see Section 4.2). In Figure 3, we can see in
the Y-axis the percentage values for the dominant (non-
benign) class in every cluster produced during these ﬁve
days.
In the X-axis we can see the variance that each
dominant class had within each cluster. The results show
that the Positive and Negative assignments had a clear
cut, which we can achieve by setting the thresholds as
q ma j = 75% and q s = 0.001. These thresholds gave us
very good results throughout the duration of the experi-
ments. As we will discuss in Section 7.2.3, the DGA dis-
covery module falsely reported only ﬁve benign clusters
over a period of 15 months. All falsely reported clusters
had variance very close to 0.001.
7.2.2 New DGAs
Pleiades began clustering NXDomain trafﬁc on the
ﬁrst day of November 2010. We bootstrapped the DGA
modeler with domain names from already known DGAs
and also a set of Alexa domain names as the benign class.
In Table 2, we present all unique clusters we discovered
throughout the evaluation period. The “Malware Fam-
ily” column simply maps the variant to a known mal-
ware family if possible. We discover the malware family
by checking the NXDomains that overlap with NXDo-
mains we extracted from trafﬁc obtained from a malware
repository. Also, we manually inspected the clusters with
the help of a security company’s threat team. The “First
New-DGA-v1
New-DGA-v2
New-DGA-v3
71f9d3d1.net
a8459681.com
a8459681.info
a8459681.net
1738a9aa.com
1738a9aa.info
1738a9aa.net
84c7e2a3.com
84c7e2a3.info
84c7e2a3.net
clfnoooqfpdc.com
slsleujrrzwx.com
qzycprhfiwfb.com
uvphgewngjiq.com
gxnbtlvvwmyg.com
wdlmurglkuxb.com
zzopaahxctfh.com
bzqbcftfcrqf.com
rjvmrkkycfuh.com
itzbkyunmzfv.com
uwhornfrqsdbrbnbuhjt.com
epmsgxuotsciklvywmck.com
nxmglieidfsdolcakggk.com
ieheckbkkkoibskrqana.com
qabgwxmkqdeixsqavxhr.com
gmjvfbhfcfkfyotdvbtv.com
sajltlsbigtfexpxvsri.com
uxyjfflvoqoephfywjcq.com
kantifyosseefhdgilha.com
lmklwkkrficnnqugqlpj.com
New-DGA-v4
New-DGA-v5
New-DGA-v6
semk1cquvjufayg02orednzdfg.com
invfgg4szr22sbjbmdqm51pdtf.com
0vqbqcuqdv0i1fadodtm5iumye.com
np1r0vnqjr3vbs3c3iqyuwe3vf.com
s3fhkbdu4dmc00ltmxskleeqrf.com
gup1iapsm2xiedyefet21sxete.com
y5rk0hgujfgo0t4sfers2xolte.com
me5oclqrfano4z0mx4qsbpdufc.com
jwhnr2uu3zp0ep40cttq3oyeed.com
ja4baqnv02qoxlsjxqrszdziwb.com
zpdyaislnu.net
vvbmjfxpyi.net
oisbyccilt.net
vgkblzdsde.net
bxrvftzvoc.net
dlftozdnxn.net
gybszkmpse.net
dycsmcfwwa.net
dpwxwmkbxl.net
ttbkuogzum.net
lymylorozig.eu
lyvejujolec.eu
xuxusujenes.eu
gacezobeqon.eu
tufecagemyl.eu
lyvitexemod.eu
mavulymupiv.eu
jenokirifux.eu
fotyriwavix.eu
vojugycavov.eu
Figure 3: Thresholds q ma j and q s
November 2010.
from the ﬁrst ﬁve days of
Figure 4: A sample of ten NXDomain for each DGA cluster that
we could not associate with a known malware family.
Seen” column denotes the ﬁrst time we saw trafﬁc from
each DGA variant. Finally, the “Population on Discov-
ery” column shows the variant population on the discov-
ery day. We can see that we can detect each DGA variant
with an average number of 32 “infected hosts” across the
entire statewide ISP network coverage.
Table 2: DGAs Detected by Pleiades.
Malware Family
First Seen
Population
on Discovery
Shiz/Simda-C [32]
Bamital [11]
BankPatch [5]
Expiro.Z [8]
Boonana [41]
Zeus.v3 [25]
New-DGA-v1
New-DGA-v2
New-DGA-v3
New-DGA-v4
New-DGA-v5
New-DGA-v6
03/20/11
04/01/11
04/01/11
04/30/11
08/03/11
09/15/11
01/11/10
01/18/11
02/01/11
03/05/11
04/21/11
11/20/11
37
175
28
7
24
39
12
10
18
22
5
10
As we see in Table 2, Pleiades reported six vari-
ants that belong to known DGA-enabled malware fami-
lies [5,8,11,25,32,41]. Six more variants of NXDomains
were reported and modeled by Pleiades but for these, to
the best of our knowledge, no known malware can be as-
sociated with them. A sample set of 10 domain names
for each one of these variants can be seen in Figure 4.
In the 15 months of our observations we observed an
average population of 742 Conﬁcker infected hosts in the
ISP network. Murofet had the second largest population
of infected hosts at 92 per day, while the Boonana DGA
comes third with an average population of 84 infected
hosts per day. The fastest growing DGA is Zeus.v3 with
an average population of 50 hosts per day, however, dur-
ing the last four days of the experiments the Zeus.v3
DGA had an average number of 134 infected hosts. It
is worth noting the New-DGA-v1 had an average of 19
hosts per day, the most populous of the newly identiﬁed
DGAs.
7.2.3 False Reports on New DGAs
During our evaluation period we came across ﬁve cat-
egories of clusters falsely reported as new DGAs. In all
of the cases, we modeled these classes in the DGA mod-
eler as variants of the benign class. We now discuss each
case in detail.
The ﬁrst cluster of NXDomains falsely reported by
Pleiades were random domain names generated by
Chrome [16,45]. Each time the Google Chrome browser
starts,
it will query three “random looking” domain
names. These domain names are issued as a DNS check,
so the browser can determine if NXDomain rewriting is
enabled. The “Chrome DGA” was reported as a vari-
ant of Bobax from Pleiades. We trained a class for this
DGA and ﬂagged it as benign. One more case of test-
ing for NXDomain rewriting was identiﬁed in a brand of
wireless access points. Connectify3, offers wireless hot-
spot functionality and one of their conﬁguration option
enables the user to hijack the ISP’s default NXDomain
rewriting service. The device generates a ﬁxed number
of NXDomains to test for rewriting.
Two additional cases of false reports were triggered
by domain names from the .it and .edu TLDs. These
domain names contained minor variations on common
words (i.e. repubblica, gazzetta, computer, etc.). Domain
names that matched these clusters appeared only for two
days in our traces and never again. The very short lived
presence of these two clusters could be explained if the
domain names were part of a spam-campaign that was
remediated by authorities before it became live.
The ﬁfth case of false report originated from domain
names under a US government zone and contained the
3www.connectify.me
Table 3: TPs (%) for C&C detection (1,000 training sequences).
botnet
Zeus.v3
Expiro.Z
Bamital
Shiz
Boonana
BankPatch
0.1
99.9
33.03
100
0
3.8
56.21
0.5
99.9
64.56
100
1.64
10.69
70.77
FPs (%)
1
3
99.9