1.00s
然后修改参数 slave_parallel_workers 为0，切换回单线程模式，延迟开始加大。
0.00s
.00s
.00s
.01s
.00s
.00s
.00s
00s
.00s
00s
.00s
.00s
00s
.00s
.00s
.00s
.00s
.00s
.00s
.00s
0.20s
0.20s
0.00s
0.00s
0.00s
0.00s
0.20s
0.40s
0
0.60
0.80s
0.60
0
0
.
.20s
.20s
.20s
.60s
.20s
.20s
.00s
.00s
.00s
.00s
.00s
S
S
延迟逐渐减低，并回复平稳。
图5-27
2线程-4线程
DATABASE
8线程
---
## Page 231
处理了这么多的主从数据不一致的场景，有没有共性的原因呢，我梳理了下图5-29。
5.2.5
论下数据不一致的问题。
数据完整性了，如果主从数据不一致，这比产生延迟的影响都要大，下一小节我们来讨
的延时还是不够稳定。
幅度的差异改进。
刚刚我们讨论了数据延迟问题，在延迟问题之外，还有一类问题尤其关键，那就是
关于主从数据不一致，作为 DBA不处理几次主从复制异常都不好意思了。那么我们
而在LOGICAL_CLOCK 模式下，8线程的延时几乎是触底的；而相对来说，2线程
在DATABASE 模式下，多线程的测试情况可以看到延时问题依旧存在，这是有一定
主从数据不一致的分析
主从数据不一致的原因
系统层异常
操作规范从库可以写入数据
LOGICAL CLOCK
图5-29
配置问题
图5-28
主从表结构不一致
主从数据库版本不统一
MySQLbug导致
盲目跳过数据复制错误，错上加错
高可用切换时丢失数据
服务器异常宕机
自增列步长设置不同
binlog_format为statement或者mixed模式
主从的参数不兼容，比如表名大小写敏感
复制采用了过滤机制，如ignore/do/rewrite等
第5章MySQL运维管理实践|209
---
## Page 232
210丨MySQL DBA工作笔记：数据库管理、架构优化与运维开发
场景，如果数据库重启，
的改进措施。
Create
test]>show create table t1G 
MySQL 里面有一个问题尤其值得注意，那就是自增列的重复值问题。我们设想一个
可以看到 insert 语句是 MySQL 独有的语法形式。
sock
我们来挖掘一下 binlog 的内容，就会发现 insert 语句很特别。
这个时候会发现AUTO_INCREMENT=4的值不会有任何变化。
QueryOK，
因为存在3行数据，这个时候自增列的值是4。
insert
insert
[test]>
首先复现这个问题。
为了解答这个问题，
案例5-10：经典的自增列问题测试
接下来我们来通过两个案例来对数据不一致的场景做下分析。
上图基本上包含了常见数据不一致的场景，面对这些问题，我们需要整理一些可行
###
###SET
我们删除id 值最大的记录id=3。
[test]>
row in set (0.oo sec)
 ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=latinl
PRIMARY
P
idla
id`
123
 @2=2 /* INT meta=0 nullable=1 is_null=0
int(11)
Table: t1
int(11） NOT NULL AUTO_INCREMENT
intot
select
into
drop table if exists tl;
22
KEY
DEFAULT NULL,
CREATE TABLE
values
values
values
，创建表tl，插入3行数据。
我们来测试一下。
是否对自增列有影响？
(null,2);
(0.02 sec)
id=3；
"t1
1
a int，primarykey(id)）engine=innodb;
*
---
## Page 233
测试，在主库插入一条记录，这样自增列的值就是4。
max(id)+1 的方式来计算的。
myt>shwcreatetablet1G
mysalshow create tablet1G
而从库呢，我们来验证一下，
QueryOK，
mysql> insert into tl values (null,2);
继续插入一条记录，这个时候主库的自增列就会是5。
自增列的值为4，而从库的自增列的值依旧没有任何变化。
Query OK，1 row affected (0.01 sec)
这个时候就会发现重启数据库以后，主从的自增列的值不同了。那么我们来进一步
这个时候我们来关注一下从库，从库的自增列值会变化吗？
CreateTable:CREATE TABLEt1
重启之后就会发现情况发生了变化，
我们重启一下数据库。
delete 也会基于行级变更，定位到具体的记录方式来删除。
#at 2271
PRIMARY
row in set (0.00 sec)
ENGINE=InnoDB
PRIMARY KEY
at2509
id
￥
￥
WHERE
Table:t1
Table:t1
Table: t1
int(11)
int(11)
@1=3
int(11)
/*
DEFAULT NULL,
DEFAULT NULL,
 INT meta=0 nullable=0 is_null=0 */
NOT
NOT
id
AUTO_INCREMENT=3 DEFAULT CHARSET=latin1
NULL
NULI
，发现这个时候从库的自增列又开始生效了。
AUTO_INCREMENT,
AUTO_INCREMENT,
1.row
"t1
row
原来的自增值4 现在变为了3，这个也是基于
第5章MySQL运维管理实践|211
data/s1/s1.cnf&
---
## Page 234
212丨MySQL DBA工作笔记：数据库管理、架构优化与运维开发
worker(s) .
'8fc8d9ac-a62b-
复制。Last Error 的内容为：
据官方的计划会在8.0中修复。
归档的情况下，如果主库重启，很可能会出现数据不一致的情况。
储这个信息，会按照 max(id)+1的方式来得到后续的自增列值，实际上在多环境历史数据
-下。假设此时表中的数据如下：
Last_Error:Coordinator
mysal> show create table t1\G.
mysql> select * from tl;
当然，InnoDB 在处理自增列问题上，有一点还是比较优雅的，
发现一个5.7版本的 MySQL 从库在应用日志的时候报出了错误。从库启用过了并行
案例5-11：主从不一致的修复过程
自增列的问题在 MySQL 很久以前就有，5.7版本依旧存在，什么时候会修复呢，根
Create Table:CREATE TABLE^t1
令人感到欣慰的是，结果是符合预期的。
mysql> insert into t1 values(6,2);
为了方便测试，
5rows in set
可见从库端会自动去同步主库的自增列，而数据库重启后，因为InnoDB 层没有去存
row in set (0.00 sec)
PRIMARY
id
row in set (0.00 sec)
^id int(11） NOT NULL AUTO_INCREMENT,
3
a
int (11)
Table:t1
a
5290535
KEY
222
22
11e6-a3ee-a4badb1b4a00:7649'
我们继续插入一条数据，这一次我指定了id值。
(0.00 sec)
id`
NC
 AUTO_INCREMENT=5 DEFAULT CHARSET=latin1
AUTO
NULL
。
INCREMENT=7 DEFAULT CHARSET=latin1
rror
AUTO_INCREMENT,
stoppedbecause
logand/orperformance
 at master log mysql-bin.000011,
there
were
我们来通过测试说明
error（s)
others, if any
.repli
inthe
---
## Page 235
10.127.%.%
pt-table-sync，当然这两个工具的选项很多，我只做一些基本的操作。
然后根据checksum 的情况来修复数据，这样就涉及两个命令行工具 pt-table-checksum 和
了9条。如此一来，这个从库就是不合格的。
改参数 slave_exec_mode 来完成。
in'sys_
Worker
5290028,
看出是在更修改backend 数据库的表 sys_user_audit 的时候抛出了错误。
此处的 relay log 是 teststd-relay-bin.000013。
一致了。于是我对这个表在主从做了对比，发现数据是不一致的，从库的数据比主库少
创建用户的方式如下，需要主从做checksum对比的数据库为backend。
set global slave_exec_mode=STRICT;
set global slave_exec_mode=IDEMPOTENT;
7649'
2016-11-29T00:03:58.754987+08:00
2016-11-29T00:03:58.754386+08:00 161 [Note] Slave SQL thread for channel
最终决定选择方案 3，在主从库各创建一个临时作为同步的用户，先做 checksum，
（1）重建从库，显然这不是一个很好的方案。
怎么修复数据呢，目前想到的有三种方案：
当然这种方式解决当前问题还是比较合适的，
手工跳过了几次之后，发现总这样也不是事儿，如果这样的问题较多，可以直接修
START SLAVE;
（3）使用 pt工具进行修复。
（2）使用navicator也是一个不错的方案，图形界面点点配配就可。
很快从库的状态就正常了，但是又一个新的问题又来了：主从数据库的数据怎么不
BEGIN; COMMIT;
STOP SLAVE;
然
而修复方式和常规的略有一些差别。
对于这类问题看起来还是比较陌生，
后再次应用
0
@@SESSION.GTID_NEXT = AUTOMATIC;
failed
atmaster
relay
IDENTIFIED BY
audit'
OWS
不过我发现这次碰到的问题比想象的要麻烦一些。
event
1og
mysql-bin.000011,
transaction
uo
table
，我们可以到binlog 里面看到一些明细的信息。
'8fc8d9ac-a62b-11e6-a
162
--no-defaults --base64-output=DEcoDE-
[ERROR]
1og
，跟上了主库的变更，重新设置为原值。
position: 27175
Slave
audit;
ERR KEY
SQL