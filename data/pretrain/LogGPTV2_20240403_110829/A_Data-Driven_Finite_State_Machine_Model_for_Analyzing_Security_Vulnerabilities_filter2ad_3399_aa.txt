title:A Data-Driven Finite State Machine Model for Analyzing Security Vulnerabilities
author:Shuo Chen and
Zbigniew Kalbarczyk and
Jun Xu and
Ravishankar K. Iyer
A Data-Driven Finite State Machine Model for  
Analyzing Security Vulnerabilities 
Shuo Chen, Zbigniew Kalbarczyk, Jun Xu, Ravishankar K. Iyer 
Center for Reliable and High-Performance Computing  
Coordinated Science Laboratory 
University of Illinois at Urbana-Champaign 
1308 W. Main Street, Urbana, IL 61801 
{shuochen, kalbar, junxu, iyer}@crhc.uiuc.edu 
Abstract 
This  paper  combines  an  analysis  of  data  on  security 
vulnerabilities  (published  in  Bugtraq  database)  and  a 
focused source-code examination to develop a finite state 
machine  (FSM)  model  to  depict  and  reason  about 
security  vulnerabilities.  An  in-depth  analysis  of  the 
vulnerability reports and the corresponding source code 
of  the  applications  leads  to  three  observations:  (i) 
exploits must pass through multiple elementary activities, 
(ii) multiple vulnerable operations on several objects are 
involved  in  exploiting  a  vulnerability,  and  (iii)  the 
vulnerability  data  and  corresponding  code  inspections 
allow  us  to  derive  a  predicate  for  each  elementary 
activity.  
Each  predicate  is  represented  as  a  primitive  FSM 
(pFSM). Multiple pFSMs are then combined to create an 
FSM  model  of  vulnerable  operations  and  possible 
exploits.  The  proposed  FSM  methodology  is  exemplified 
by  analyzing  several  types  of  vulnerabilities  reported  in 
the  data:  stack  buffer  overflow,  integer  overflow,  heap 
overflow,  input  validation  vulnerabilities,  and  format 
string vulnerabilities. For the studied vulnerabilities, we 
identify  three  types  of  pFSMs,  which  can  be  used  to 
analyze  operations  involved  in  exploiting  vulnerabilities 
and to identify the security checks to be performed at the 
elementary  activity 
the 
practical usefulness of the FSM modeling approach was 
the  discovery  of  a  new  heap  overflow  vulnerability  now 
published in Bugtraq.  
level.  A  demonstration  of 
Key  words:  security  vulnerabilities,  data  analysis,  finite 
state machine modeling. 
1. 
Introduction 
Analysis  of  security  vulnerabilities  has  typically 
been  approached  in  one  of  two  ways:  (i)  using  real  data 
to  develop  a  classification  and  perform  statistical 
analysis; examples include Landwehr’s study on security 
vulnerabilities  [8]  and  Lindqvist’s  study  on  intrusions 
[11],  and  (ii)  providing  a  degree  of  formalism  by 
modeling  vulnerabilities  and  attack  characteristics; 
representative  work  includes  Ortalo’s  Markov  model  of 
UNIX  vulnerabilities  [17]  and  Sheyner’s  attack  graph 
[18]. 
  This  paper  combines 
constructor
two 
approaches:  real  data  is  analyzed,  in  conjunction  with  a 
focused  source-code  examination,  to  develop  a  finite 
state  machine  (FSM)  model  to  depict  and  reason  about 
security vulnerabilities. 
the 
Using  the  Bugtraq  list  maintained  in  Securityfocus
[13],  the  study  first  identifies  leading  causes  of  security 
vulnerabilities. 1  An  in-depth  analysis  of  the  reported 
vulnerabilities shows: 
•  Exploits  must  pass  through  multiple  elementary 
activities  –  at  any  one  of  which,  one  can  foil  the 
exploit. 
•  Exploiting 
a  vulnerability 
involves  multiple 
vulnerable operations on multiple objects. 
•  Analysis  of  a  given  vulnerability  along  with 
examination of the associated source code allows us 
to  specify  predicates  that  need  to  be  met  to  ensure 
security. 
These  observations  motivate  the  development  of  an 
FSM  modeling  methodology  capable  of  expressing  the 
process  of  exploitation  by  decomposing  it  into  multiple 
operations,  each  of  which 
includes  one  or  more 
elementary  activities.  Since  each  elementary  activity  is 
simple,  it  is  feasible  (using  the  data  and  the  application 
code)  to  develop  a  predicate  and  a  corresponding 
primitive  FSM  (pFSM)  to  represent  the  elementary 
activity.  The  pFSMs  can  then  easily  be  combined  to 
develop  FSM  models  of  vulnerable  operations  and 
possible exploits.  
file 
race  condition,  and 
The  proposed  FSM  methodology  is  exemplified  by 
analyzing  several  types  of  vulnerabilities  reported  in  the 
data:  stack  buffer  overflow,  integer  overflow,  heap 
overflow, 
format  string 
vulnerabilities.  These  vulnerabilities  include  both  those 
that  can  be  exploited  remotely  (e.g.,  those  impacting 
Internet servers) and those that can be exploited by local 
users (e.g., privilege escalation of a regular user to root). 
It  should  be  noted  that  this  family  of  vulnerabilities 
constitutes  22%  of  all  vulnerabilities  in  the  Bugtraq
1 CERT  and  Bugtraq  are  two  of  the  most  comprehensive  databases  in 
which  security  vulnerabilities  are  reported.  We  chose  Bugtraq  for  this 
study  because  its  vulnerability  reports  are  better  organized  and  more 
amenable to automatic processing and statistical study. 
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:06:47 UTC from IEEE Xplore.  Restrictions apply. 
database.  For  the  studied  vulnerabilities,  we  identify 
three  types  of  pFSMs  that  can  be  used  to  analyze 
operations  involved  in  exploiting  vulnerabilities  and  to 
identify  the  security  checks  to  be  performed  at  the 
elementary activity level. 
An additional demonstration of the usefulness of the 
approach  was  the  discovery  of  a  new  heap  overflow 
vulnerability  now  published  in  Bugtraq  crediting  the 
authors  [13].  The  discovery  was  made  when  modeling 
another, known vulnerability.  
2.  Related Work 
There  has  been  significant  research  in  modeling, 
analysis, and classification of security problems, some of 
which is based on real data.  
satisfies  certain 
Security  Models  of  Access  Control.  A  number  of 
studies [1][2][3] have proposed models for access control 
security 
that 
properties.  Bell  and  LaPadula  [1]  proposed  a  multilevel 
model and formally defined a secure system. A summary 
of the state of the art is presented in [4].  
rigorously  defined 
studies 
have 
Several 
Classification  and  statistical  analysis  of  security 
vulnerabilities. 
proposed 
classifications  to  abstract  observed  vulnerabilities  into 
easy-to-understand  classes.  Representative  examples 
include Protection Analysis [10], RISOS [9], Landwehr’s 
taxonomy  [8],  Aslam’s  taxonomy  [7],  and  the  Bugtraq 
classification.  Similarly,  taxonomies  for  intrusions  have 
been  proposed.  Examples  include  Lindqvist’s  intrusion 
classification [11] and the Microsoft STRIDE model [12]. 
In  addition  to  providing  taxonomies,  [8]  and  [11] 
perform  statistical  analysis  of  actual  vulnerability  data, 
based on the proposed taxonomies.  
is  applied 
Modeling  security  vulnerabilities  and  intrusions.
Several studies focus on modeling attacks and intrusions 
with the objective of evaluating various security metrics. 
Michael  and  Ghosh  [19]  employ  an  FSM  model 
constructed  using  system  call  traces.  By  training  the 
model  using  normal  traces,  the  FSM  is  able  to  identify 
abnormal  program  behaviors  and  thus  detect  intrusions. 
In  [18],  a  finite  state  machine  based  technique  to 
automatically  construct  attack  graphs  is  described.  The 
approach 
in  a  networked  environment 
consisting  of  several  users,  various  services,  and  a 
number  of  hosts.  A  symbolic  model  checker  is  used  to 
formally  verify  the  system  security.  Recent  studies  have 
proposed  stochastic  models  to  quantitatively  evaluate 
security  metrics.  Ortalo  et  al.  [17]  develop  a  Markov 
model to describe intruder behavior and evaluate system 
security  in  terms  of  METF  (mean  effort  to  failure). 
Madan  [20] described  a  semi-Markov  model  to  evaluate 
an  intrusion-tolerant  system  subject  to  security  attacks. 
Several  security  and  reliability  metrics  (e.g.,  METF  and 
availability)  are  defined  and  shown  to  be  solvable. 
Clearly,  such  a  model  requires  that  parameters,  e.g., 
probabilities of transitions and sojourn time, be available 
or estimated.  
There  is  little  work  on  modeling  of  discovered 
security  vulnerabilities  to  capture  how  and  why  an 
implementation  fails  to  achieve  the  desired  level  of 
security.  This  paper  uses  actual  vulnerability  data  (e.g., 
reports)  and  code  inspection  to  derive  FSMs  to  describe 
simple  predicates,  which  are  used  to  generate  FSM 
models.  The  developed  FSMs  allow  us  to  reason  about 
the  existing  vulnerabilities  and  also  seem  to  have  the 
potential for discovering new vulnerabilities.  
3.  Analysis of the Bugtraq Database 
3.1  Statistical Analysis  
As  of  November  30,  2002,  the  Bugtraq  database 
included 5925 reports on software-related vulnerabilities 
[13]. Each vulnerability report2 in this database provides 
information  such  as  version  number  of  the  vulnerable 
software, date of discovery, an assigned vulnerability ID, 
cause  of  the  vulnerability,  and  possible  exploits3.  Figure 
1  shows  the  breakdown  of  the  5925  vulnerabilities 
among the 12 defined classes. Observe that the pie-chart 
is  dominated  by  five  categories:  input  validation  errors 
(23%),  boundary  condition  errors  (21%),  design  errors 
(18%),  failure  to  handle  exceptional  conditions  (11%), 
and  access  validation  errors  (10%).  The  primary  reason 
for the domination of these categories is that they include 
the  most  prevalent  vulnerabilities,  such  as  buffer 
overflow (included under boundary-condition errors) and 
format  string  vulnerabilities  (included  under 
input-
validation  errors).  The  remaining  categories,  being  very 
broadly  defined  (e.g.,  access  validation  errors,  design 
errors), are more or less all-encompassing.  
3.2  An In-depth Analysis of Vulnerability Reports 
An  in-depth  analysis  of  the  data  and  information 
reported in Bugtraq together with a close examination of 
the  associated  application  code 
to 
understanding  the  root  causes  of  the  vulnerabilities.  By 
examining  the  vulnerability  reports  and  the  associated 
application source codes, we made three observations: 
is  essential 
 Observation 1: Exploits must pass through multiple 
elementary activities – at any one of which, one can foil 
the exploit. The scenario thus can be described as a serial 
chain  in  which  each  link  (which  we  model  as  an 
elementary  activity)  provides  a  security  checking 
opportunity:  failure  at  any  one  elementary  activity  can 
foil the exploit.  
2 Note that Bugtraq refers to all vulnerabilities as errors, although these 
may not be error in the sense defined in [6]. 
3 Certain vulnerability reports in Bugtraq include exploits. For example, 
an exploit associated with vulnerability #5960 is provided in 
http://online.securityfocus.com/bid/5960/exploit  
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:06:47 UTC from IEEE Xplore.  Restrictions apply. 
Serialization Error
0%
Race Condition 
Error
2%
Origin Validation 
Error
3%
Input Validation 
Error
23%
Failure to 
Handle 
Exceptional 
Conditions
11%
Access 
Unknow n
Validation Error
6%
10%
Atomicity Error
0%
Boundary 
Condition Error
21%
Configuration 
Error
5%
Design Error
18%
Environment Error
1%
•Access Validation Error: an operation on an object outside its 
access domain.
•Atomicity Error: code terminated with data only partially modified 
as part of a defined operation.
•Boundary Condition Error: an overflow of a static-sized data 
structure: a classic buffer overflow condition.
•Configuration Error: a system utility installed with incorrect setup 
parameters.
•Environment Error: an interaction in a specific environment 
between functionally correct modules. 
•Failure to Handle Exceptional Conditions: system failure to handle 
an exceptional condition generated by a functional module, device, 
or user input. 
•Input Validation Error: failure to recognize syntactically incorrect 
input.
•Race Condition Error: an error during a timing window between 
two operations.
•Serialization Error: inadequate or improper serialization of 
operations.
•Design Error and, Origin Validation Error: Not defined.
Figure 1: Breakdown of Vulnerabilities and Definitions of Vulnerability Categories 
We  illustrate  this  observation  using  data  from  three 
signed  integer overflow  vulnerabilities  given  in  Table  1. 
Here  the  analysts  have  used  three  different  activities  as 
reference points to classify the same type of vulnerability 
into three categories, although there is nothing in the data 
to indicate the specific elementary activity corresponding 
to  the  observed  vulnerability.  Thus  #3163  has  been 