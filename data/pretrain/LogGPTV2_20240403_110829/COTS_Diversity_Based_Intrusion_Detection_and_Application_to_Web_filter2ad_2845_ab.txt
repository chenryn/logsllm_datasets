COTS
Service 1
COTS
Service 2
COTS
Service 3
COTS server 1
COTS server 2
COTS server 3
Service Proxy
Service IDS
Fig. 1. General architecture
3.3 An Intrusion Detection Architecture Based on COTS Diversity
The architecture proposed, shown on Figure 1, is clearly inspired by the classical ar-
chitecture of N-version programming. It is composed of three components: a proxy, an
IDS, and a set of servers. We ﬁrst describe each of these elements. Then, we discuss the
pros and cons of the proposed architecture.
Description of the architecture. The role of the proxy is to handle the client requests.
It forwards the request from the client to the COTS servers and then forwards the re-
sponse from the IDS to the client. It ensures that the COTS servers receive the same
requests, in order to synchronise their states. It is the sole part of the architecture acces-
sible directly to the clients but it is simple enough to be considered as secure.
The IDS is in charge of comparing the response from the COTS servers. If it detects
some differences, it raises an alarm and it informs the proxy of the response that has
been elected by a voting algorithm. This algorithm is in charge of choosing which re-
sponse must be sent back to the client. Section 4.1 gives an example in the case of web
servers.
A set of COTS servers constitutes the core of the architecture: they provide the ser-
vice requested by the client. These servers offer the same services but they are diverse
in terms of application software, operating systems and hardware. This aims to reduce
the probability of a common-mode failure as in the N-version programming: in the con-
text of our studies, it aims at ensuring the vulnerabilities are decorrelated between the
servers. Thus, we can make the assumption that an intrusion occurs in only one COTS
server at a time. In this case, because the other COTS servers are not affected by the
vulnerability, the architecture allows to detect the intrusion and to tolerate it. The ref-
erence [16] demonstrates that there are very few common mode failures in a pool of
COTS database servers. Moreover, a study of the vulnerabilities of IIS and Apache [17]
COTS Diversity Based Intrusion Detection and Application to Web Servers
49
proves the same property. This shows that our assumption can be considered as true at
least in these two cases.
The choice of a three COTS servers architecture shown on Figure 1 is dictated by
several requirements: ﬁrst, it allows to tolerate one intrusion on one server without
modifying the security properties of the whole architecture. Secondly, it provides a way
to identify the failed server with a simple comparison algorithm: this would not have
been possible on a two-version architecture without additional mechanisms (e.g., server
diagnostic). Once an intrusion has occurred, this architecture with three COTS servers
cannot tolerate another intrusion before the reconﬁguration of the server that have been
compromised. It is of course possible to use more than three servers in order to tolerate
more intrusions before it is necessary to reconﬁgure the compromised servers. It must be
noted that the reconﬁguration can be made periodically or when an intrusion is detected.
It is certainly better to combine the two techniques, as the IDS can miss the detection
of some kinds of intrusion.
Taxonomy of Detected Differences. The purpose of the N-version programming is to
compare the output of several programs: a difference detection is the consequence of
a design difference. As these programs have the same speciﬁcation, this design differ-
ence can be thus recognized as a consequence of a design fault in the variant whose
output differs from those of the other variants. The discussion about COTS diversity
that has been conducted in Section 3.2 explained that this assumption on the speciﬁca-
tion uniformity must be considered as false in the case of COTS. A COTS speciﬁcation
is composed of both a common part and a speciﬁc part that differs from other variants
speciﬁc parts.
Thus, the output differences that are detected are the results (see Figure 2):
– either of design differences that are due to differences in the speciﬁc parts of the
speciﬁcations. These design differences are not necessarily (but can be) design
faults;
– or, design differences that are due to design faults in the part of the program covered
by the common speciﬁcation.
In our approach we expect to detect intrusions. Thus, we intend to detect differences
that are in fact the consequences of the exploit of vulnerabilities. These vulnerabili-
ties are design faults, and can be part of any of the two classes that have been listed
above. However, the vulnerabilities can be characterized by their consequence on the
system: their activation leads to a violation of the system security policy (i.e., the in-
tegrity, availability or conﬁdentiality properties of the system). This means that the set
of design faults detected by the comparison algorithm is the union of two sets of faults:
the vulnerabilities that permit to violate the security policy on one side, and the classi-
cal design faults that do not break the security policy on another side. Thus, albeit it is
impossible to detect if differences are due to design faults or speciﬁcation differences,
it is possible to know if these differences are due to the exploit of vulnerabilities or not.
However, we must point out here that this cannot be directly achieved automatically
by the comparison algorithm without the help of additional diagnosis (through human
expertise, use of other IDSes, etc.).
50
E. Totel, F. Majorczyk, and L. Mé
COTS 1
Specification
Common
Specification
COTS 2
Specification
COTS 1 Outputs
COTS 2 Outputs
Comparisons
Output differences
Design faults
Design differences
Vulnerabilities
Classical design faults
False Positives
Elimination
Alerts
False Positives
Elimination
Fig. 2. Taxonomy of Detected Differences
The output differences detected that are due to classical design faults or speciﬁca-
tion differences are actually false positives, because they do not lead to violations of the
security policy. These false positives must, of course, be eliminated. Most of the time,
the COTS we have selected have been used for years and can now be considered rea-
sonably fault free in the context of a normal use. (This hypothesis has been conﬁrmed
by the tests we have conducted, see Section 4.2.) Consequently, we do not expect to
detect a lot of classical design faults. Thus, most of the false positives will be due to
design differences that are not the consequence of design faults. As a consequence, we
decided to concentrate on the elimination of these differences. This elimination is per-
formed by masking the legitimate differences. The masking functions are thus applied
by modifying the request before it is processed (pre-request masking: proxy masking
function) or after the request has been performed (post-request masking: rule masking
mechanisms). In both cases, the easy solution we chose was an off-line experimental
identiﬁcation of the speciﬁcation differences (See 4.1 for an application).
Extending majority voting fault masking mechanism to COTS output difference
masking. In order to insert fault tolerance mechanisms in a N-version programming
scheme, it is required to implement fault masking mechanisms. These mechanisms pro-
vide a way to return a correct answer despite the fact that one version delivers a faulty
output. In classical diversity, this output is an error because all the versions are known to
have the same speciﬁcation. In our case, a difference at the output level will be mainly
COTS Diversity Based Intrusion Detection and Application to Web Servers
51
due to a design difference in the COTS: it is thus necessary to extend the notion of
fault masking to COTS difference masking. As an example, we suppose that the fault
masking function is a majority voting algorithm.
Formally, a voting fault masking function in the context of N-version programming
can be described as follows: I be the set of inputs of the service, Idi f f the subset of I
that produces an output difference in one of the versions. Let Oi = {oi
} the
1,oi
2, ...,oi
set of outputs of the versions for a given entry i ∈ Idi f f . The majority voting function M
N
is a masking function M : Oi (cid:4)→ oi
∈ Oi if there is
a majority of j ∈ {1,2, ...N} | oi
k that returns either a correct value oi
k
k, or an error if no majority is found.
j = oi
In the case of COTS diversity, the elements of Oi can differ from each other because
of a design difference between the versions, even if no fault has been activated. These
differences must then be considered as legal, and must thus be masked. In order to mask
these differences, we use a transitive equivalence function: for i ∈ Idi f f , two elements
(oi
j,oi
k) if they are both known correct outputs
of the versions j and k (i.e., no intrusion has occurred). The majority voting function M
∈ Oi if there is
is a masking function M : Oi (cid:4)→ oi
a majority of j ∈ {1,2, ...N} | oi
k that returns either a correct value oi
≡ oi
k
k) ∈ Oi × Oi are equivalent (noted oi
j, or an error if no majority is found.
These deﬁnitions are very closed in term of algorithm complexity, and thus the mask-
ing rule based mechanism described in Section 4.1 does not produce a very higher com-
plexity algorithm than a simple fault masking voting algorithm.
≡ oi
j
k
Intrusion tolerance at the proxy and IDS levels. Intrusion tolerance is not completely
ensured, because both the proxy and the IDS can be considered as a single point of fail-
ure in case of an attack against them succeeds. Nevertheless, notice that the complexity
of the proxy is pretty low (as shown by the output difference masking deﬁnition mech-
anism deﬁned in the previous paragraph), and thus it should be less vulnerable than the
servers. In fact, this architecture is devoted to intrusion detection, not intrusion toler-
ance. To ensure intrusion tolerance, some additional mechanisms must be added, such
as proxy diversity or redundancy (coupled with consensus Byzantine agreement pro-
tocols), or eventually proxy monitoring via model checking. Some of these ideas have
been tackled in [18] as part of the DIT project. We also plan to apply such approaches
to our architecture, which actually is part of the CNRS/ACISI DADDi (Dependable
Anomaly Detection with Diagnosis) project. In that project, the proxy dependability
will be tackled by one of our partner.
4 A COTS-Diversity Based IDS for Web Servers
The approach we have presented in the previous section can be applied to any type
of service (ftp server, mail server, etc.) if the hypothesis of vulnerability decorrela-
tion can be veriﬁed. In this section, we apply it to web servers (as, once again, the
reference [17] shows that the hypothesis is veriﬁed) in order to demonstrate the feasi-
bility of the approach through experimental results.
Web servers constitute the electronic front door of many organisations, if not all.
More and more critical applications are developed on the web in various ﬁelds like
ﬁnance, e-commerce. In the same time, web servers and web-based applications are
52
E. Totel, F. Majorczyk, and L. Mé
popular attack targets. A large number of disclosure of vulnerabilities concerns web
servers or web-applications. For instance, in the time of writing, Snort 2.2 devotes 1064
of its 2510 signatures to detect web-related attacks. Finally, many COTS implementing
web servers are available and widely used. Thus, we decided to apply our approach to
web servers.
In this section, we ﬁrst give the detection algorithm in the case of web servers and
discuss on the choices that have been made. Then, we give some experimental results
that aim at giving evidence on the reliability and on the accuracy of the approach.
4.1 Detection Algorithm
The detection algorithm depends on the application monitored and must be developed
speciﬁcally for each application considered. We give here an algorithm for web servers.
We view the web servers as black boxes and their interactions with the environment
are the only things that can be observed. The only identiﬁed common part of the spec-
iﬁcation is the HTTP protocol. We must then compare the HTTP responses from the
several web servers. The common speciﬁcation part does not a priori deﬁne other out-
puts, such as system calls for example. That is why we restrict the data processed by
the detection algorithm to HTTP responses.
The HTTP protocol is based on a request/response paradigm. A client establishes a
connection with a server and sends a request to the server. A response is then given in
return to the client. This HTTP response is composed of two parts: the header part and
the body. The header part is well deﬁned. For example, the ﬁrst ﬁeld is the status line,
which is principally composed by the version of the HTTP protocol and the status code.
If not empty, the body can be almost everything depending on the request.
A binary comparison of the HTTP headers cannot be performed because the servers
actually uses different headers. Moreover, some headers may be ﬁlled differently by dif-
ferent servers, such as the header “Date” or the header “Server”. The semantic of each
header has to be taken into account in the comparison process. Also, we have to care-
fully analyse which headers to process during the comparison. The status code is ob-
viously an important element. Other headers are interesting: Content-Length, Content-
Type, Last-Modiﬁed. These three headers are almost always sent by web servers. A
difference in these headers can notably be a piece of evidence of a defacement.
The bodies, when they are not empty, are also compared. We have restricted our
experiments to static http contents. In that particular case, a binary comparison of the
bodies is possible. Even in this restricted case, we may have a problem during binary
comparisons; for example the comparison of directory listings, as different servers pro-
vide different bodies when answering to this type of request (this can be clearly identi-
ﬁed as a speciﬁcation difference). For the moment, our web variants are conﬁgured so
that access to directories is not allowed.
The detection algorithm is composed of two phases:
– a watchdog timer provides a way to detect that a server is not able to answer to a
request. All servers that have not replied are considered to be unavailable, and an