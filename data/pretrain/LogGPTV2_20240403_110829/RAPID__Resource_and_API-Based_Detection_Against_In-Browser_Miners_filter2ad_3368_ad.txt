signicant enough to guarantee that all sites have higher indexes
for all comparisons. For example, Instagram’s speed index has a
lower value for 4-grams than for 3-grams, although it exposes an
increasing behavior between the baseline, bag of words, 2- and
3-grams. This can be related to some dynamic features of the sites,
but it could also happen because values for the mean of the speed
index lie within an error margin (related to the standard deviation).
So, we can only know that they are “close" the value shown.
To provide an even more intuitive view on the results from the
Alexa top 100 speed index, Table 4 shows the mean and standard
deviation of the overhead of the dierent instrumentation and
6Remember the non-deterministic bug described in Section 3.1
320
RAPID: Resource and API-Based Detection Against In-Browser Miners
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Figure 6: Speed Index comparison vs Instrumentation Method (top Alexa 20 sites)
XP, while monitoring operations to the registry performed by the
machine. As the program simulating the user was not instructed
to accept to download or install malicious software, activities ob-
served in the registry after the end of the visit agged exploit sites.
Capture-HPC uses several HTTP clients, such as Firefox or Internet
Explorer to orchestrate them and monitor the le system, registry,
or processes a kernel level. As a result, it can ag malicious behavior
whenever an unexpected change takes place [41].
We are following a similar approach as HoneyMonkey and Capture-
HPC in the sense that we also use real browsers to visit sites but at
the same time perform data collection in lower layers, i.e., docker
would be analogue to the OS.
Heidrich et al. created an in-browser solution to detect and miti-
gate malicious Websites called IceShield [19]. IceShield has been
implemented as a JavaScript Internet Explorer or Firefox extension
that redenes browser APIs to monitor JavaScript code, extracts
features and then uses Linear Discriminant Analysis (LDA) to de-
tect malicious Websites. As the most signicant contribution from
IceShield is to provide a safe and lightweight manner to rewrite the
browser APIs, the evaluation of their LDA is not as extensive as
others found in the literature. Our approach uses similar techniques
as IceShield to redene the resource-related APIs and monitor them,
yet we do this by instrumenting the browser through the Chrome
Debugging Protocol API in a research context instead of using
extensions for this.
Cova et al. used HtmlUnit, a headless browser based on the Rhino
JavaScript interpreter, to create JSAND [8]. JSAND collected partic-
ular features related to four phases observed in drive-by downloads:
redirection and cloaking, de-obfuscation, environment preparation,
and exploitation. Also, JSAND was publicly available for some time
as Wepawet, and the authors validated around 140.000 pages by
2010. Song et al. introduced an approach to prevent drive-by down-
loads via inter-module communication monitoring [42]. Song et al.
created a browser module to monitor when COM modules were
created, invoked or freed. Also, to increase the number of malicious
samples that would attack the browser, the implemented an ActiveX
emulator, to simulate several vulnerabilities. Song’s approach is
based on a Deterministic Finite Automaton (DFA) created based on
37 known exploits manually. Thus, whenever the DFA for a website
reached a dangerous state, an exploit alert was generated.
Egele et al. [12] performed heapspray shellcode detection through
the execution of a modied Firefox, with a modied SpiderMonkey
instance monitoring all string concatenation and construction op-
erations and emulating the bytes stored therein through a library
an x86 code emulation library.
Ratanaworabhan et al. proposed NOZZLE [36]: a mechanism
against heapspray attacks by using a Windows binary instrumen-
tation framework to modify Firefox’s routines to validate objects
in the heap during garbage collection. Unlike Egele et al. [12] who
only checked strings, NOZZLE inspects all objects allocated the
heap. NOZZLE disassembles the code creating a control ow graph
and analyzing data ows to nd valid x86 sequences and. Then, it
denes a heap attack surface area based on the previous analysis.
Curtsinger et al. created ZOZZLE [9] to achieve better perfor-
mance than NOZZLE. To this end, ZOZZLE uses the Detours in-
strumentation library to perform JavaScript code deobfuscation
by hooking calls to the eval function on the JavaScript engine of
Internet Explorer. Once the deobfuscated code is available, ZOZZLE
parses the JavaScript and obtains the Abstract Syntax Tree (AST).
Our approach relates to JSAND [8], Egele et al. [12], Song’s
inter-module communication monitoring [42], NOZZLE [36] and
ZOZZLE [9] as they all collect features based on observations for a
particular security problem.
Rieck et al. created Cujo: a Web proxy performing static and dy-
namic analysis of JavaScript code to detect drive-by downloads [38].
Specically, Cujo uses a custom YACC grammar to extract tokens
through lexical analysis. The result of the lexer shows a simpli-
ed representation of the code replacing variable and function
names, string values and their length and numeric values by dif-
ferent tokens, e.g., ID = ID + STR reects an instruction where the
concatenation of a variable and a string is assigned to a variable.
Then, Cujo uses ADSandbox [10], a modication of SpiderMonkey,
to execute the JavaScript code to extract abstract operations. To
relate the static and dynamic analysis with one another, Rieck et al.
create q-grams from the reports generated by the static analysis and
ADSandbox. EarlyBird [40] is an optimization of Cujo. EarlyBird is
321
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
Juan D. Parra Rodriguez and Joachim Posegga
a modied linear SVM with the same features as Cujo, yet giving
higher weights to malicious events occurring in the early stages of
an attack. On the one hand, EarlyBird gives higher weights to events
commonly appearing early in malicious scripts in the training set,
while leaving the weight for events mostly seen in benign sites
constant. Also, according to Schutt et al., the authors of EarlyBird,
this approach would produce a regular linear SVM whenever the
data available for training is not useful to identify which events are
present early in malicious Websites.
Clearly, the closest related work for our approach is Cujo and
EarlyBird because they both use q-grams and a SVM. However,
Rieck et al. focus on more generic features using dynamic and static
analysis, even including variable assignments; on the contrary, we
focus on particular resource-related API calls and do not need to
perform static analysis. The main reason for this is explained in
Section 2: attackers need to sustain the resource abuse to make
mining protable; thus, a pure dynamic analysis suces because
there is no way an attacker can perform mining without repeatedly
executing resource-intensive calls. Also, EarlyBird and Cujo are
deployed on a Proxy server; instead, we have studied, a worst-case
scenario, in which the API-based classier is deployed directly in
the browser. We consider this eort to be valuable because the in-
creasing adoption of TLS (after Cujo was published) makes harder
the deployment of secure proxies. Especially, considering that prox-
ying TLS connections require a man-in-the-middle attack: known
to decrease security and privacy for users [31].
6 CONCLUSIONS AND FUTURE WORK
To the best of our knowledge, this is the rst work proposing
several learning-based approaches to detect in-browser mining and
evaluate them thoroughly. We compare six approaches using two
data sources: system’s resources consumed by the browser, and
APIs used by Websites. To assess the detection performance of each
one of the feature sets extracted from the datasets above, we trained
and evaluated the classiers with 330.500 sites from the Alexa top
ranking.
We conclude that our classiers close the gap between false
negatives introduced by blacklists [6] and false positives resulting
from CPU-based site classication [13]. More to the point, using
our feature sets and our labeling approach, we found very good
classiers.
The best classier we found has 97.84% recall, i.e., detects 97.84%
of all mining sites in an entirely new dataset. Moreover, the best
classier also attains 99.7% precision; that is to say, from 100 sites
predicted to perform mining, there are 99.7 on average who are
indeed abusing the browser. Also, all detection mechanisms pre-
sented by us are resilient to obfuscation techniques because they
only rely on dynamic information. Nonetheless, our API-based de-
tection mechanisms can misclassify sites whose APIs usage pattern
changed, e.g., we have observed dierences in versions of Coinhive
rendering dierent geometrical gures. In such cases, the classier
should be trained again with proper labels to solve the problem.
Also, existing solutions such as Revolver [23] could be used to pre-
vent evasion. The main idea behind it is to detect sites that used to
be classied as malicious and are not classied as such anymore
and then investigate the changes.
322
While every detection approach can be executed oine, accord-
ing to the denition given in Section 2, we explored whether the
API-based approaches, e.g., bag of words, could be deployed di-
rectly on the browser. To this end, we evaluated the impact on
page-loading time induced by a prototypical API monitoring tech-
nique for the Alexa top 100 sites. Although this is just a worst-case
scenario, i.e., a production-level implementation directly in the
browser must be more ecient, results are somewhat encouraging.
Since there are no signicant detection performance dierences
between using 2-, 3- or 4-grams, we concluded that executing the
bag of words or the 2-grams classier would induce only 9.2% or
24.9% overhead on the speed index, respectively.
However, after analyzing the overhead on page-loading time and
performance of each detection approach, we encountered several
technical hurdles when attempting to implement the detection in
browsers. The rst issue we found was that even though Chromium
is the best approach to instrument the resource-related APIs during
the data collection phase, their security model makes the same kind
of instrumentation in production dicult, i.e., through a Chrome
extension. Extensions work on an isolated world, and changes
are propagated through copies of the DOM [5]. Despite this, we
implemented a proof of concept capable of executing the classier
using a WebAssembly port [24] of LibSVM [3]. To do this, we require
an additional program instrumenting Chromium remotely through
the Chrome Debugging Protocol. We must clarify that even though
we did not implement a Chrome extension to apply the classiers
explained in this paper, this may be viable by placing a content script
that modies the browser APIs. Also, looking at OpenWPM [14]
and how it uses a Firefox extension to perform JavaScript API
instrumentation [15] would be a good start. However, even though
this is an interesting engineering task, it does not weaken nor
strengthen our analysis of the classiers’ detection performance
and feasibility.
Also, we performed prediction based on a 35-second visit. This
provided high-quality data and assumed a realistic scenario con-
sidering that visits take approximately 5 minutes on average [7].
However, the question of the minimum time required to achieve
an accurate prediction remains open and can be explored as future
work with the API events collected.
ACKNOWLEDGMENTS
This research has been supported by the EU under the H2020 AGILE
(Adaptive Gateways for dIverse muLtiple Environments), grant
agreement number H2020-688088.
REFERENCES
[1] Bitcoinplus. 2011. Bitcoinplus. https://web.archive.org/web/20170103133312/http:
//www.bitcoinplus.com/miner/embeddable. Accessed: 2018-04-06.
[2] Gavin C. Cawley and Nicola L.C. Talbot. 2010. On Over-tting in Model Selection
and Subsequent Selection Bias in Performance Evaluation. J. Mach. Learn. Res.
11 (Aug. 2010), 2079–2107. http://dl.acm.org/citation.cfm?id=1756006.1859921
[3] Chih-Chung Chang and Chih-Jen Lin. 2011. LIBSVM: A Library for Support
Vector Machines. ACM Trans. Intell. Syst. Technol. 2, 3, Article 27 (May 2011),
27 pages. https://doi.org/10.1145/1961189.1961199
[4] Kevin Zhijie Chen, Guofei Gu, Jianwei Zhuge, Jose Nazario, and Xinhui Han.
2011. WebPatrol: Automated Collection and Replay of Web-based Malware
Scenarios. In Proceedings of the 6th ACM Symposium on Information, Computer
and Communications Security (ASIACCS ’11). ACM, New York, NY, USA, 186–195.
https://doi.org/10.1145/1966913.1966938
RAPID: Resource and API-Based Detection Against In-Browser Miners
ACSAC ’18, December 3–7, 2018, San Juan, PR, USA
[5] Content Scripts-Google Chrome. 2018. Work in Isolated Worlds. https://develope
r.chrome.com/extensions/content_scripts#isolated_world. Accessed: 2018-06-02.
In-Browser Cryptojacking Is Getting Harder to De-
tect. https://www.bleepingcomputer.com/news/security/in-browser-cryptojack
ing-is-getting-harder-to-detect/. Accessed: 2018-06-02.
[6] Catalin Cimpanu. 2018.
[7] Clicktale. 2013. ClickTale’s 2013 Web Analytics Benchmarks Report. https:
//research.clicktale.com/web_analytics_benchmarks.html. Accessed: 2018-04-06.
[8] Marco Cova, Christopher Kruegel, and Giovanni Vigna. 2010. Detection and
Analysis of Drive-by-download Attacks and Malicious JavaScript Code. In Pro-
ceedings of the 19th International Conference on World Wide Web (WWW ’10).
ACM, New York, NY, USA, 281–290. https://doi.org/10.1145/1772690.1772720
[9] Charlie Curtsinger, Benjamin Livshits, Benjamin Zorn, and Christian Seifert. 2011.
ZOZZLE: Fast and Precise In-browser JavaScript Malware Detection. In Proceed-
ings of the 20th USENIX Conference on Security (SEC’11). USENIX Association,
Berkeley, CA, USA, 3–3. http://dl.acm.org/citation.cfm?id=2028067.2028070
[10] Andreas Dewald, Thorsten Holz, and Felix C. Freiling. 2010. ADSandbox: Sand-
boxing JavaScript to Fight Malicious Websites. In Proceedings of the 2010 ACM
Symposium on Applied Computing (SAC ’10). ACM, New York, NY, USA, 1859–
1864. https://doi.org/10.1145/1774088.1774482
[11] WebPagetest Documentation. 2017. WebPagetest Documentation: Speed In-
dex. https://sites.google.com/a/webpagetest.org/docs/using-webpagetest/metric
s/speed-index. Accessed: 2018-06-10.
[12] Manuel Egele, Peter Wurzinger, Christopher Kruegel, and Engin Kirda. 2009.
Defending Browsers against Drive-by Downloads: Mitigating Heap-Spraying
Code Injection Attacks. In Detection of Intrusions and Malware, and Vulnerability
Assessment, Ulrich Flegel and Danilo Bruschi (Eds.). Springer Berlin Heidelberg,
Berlin, Heidelberg, 88–106.
[13] ellenpli@chromium.org. 2018. Please consider intervention for high cpu usage
js. https://bugs.chromium.org/p/chromium/issues/detail?id=766068.
[14] Steven Englehardt and Arvind Narayanan. 2016. Online Tracking: A 1-million-site
Measurement and Analysis. In Proceedings of the 2016 ACM SIGSAC Conference
on Computer and Communications Security (CCS ’16). ACM, New York, NY, USA,
1388–1401. https://doi.org/10.1145/2976749.2978313
[15] Steven Englehardt and Arvind Narayanan. 2018. OpenWPM Firefox extension
Instrumenting JavaScript Code. https://github.com/citp/OpenWPM/blob/f3f
c7884fd93a31c689a2228c21865003749cf27/automation/Extension/firefox/data/
content.js#L480. Accessed: 2018-01-15.
[16] Steven Englehardt, Dillon Reisman, Christian Eubank, Peter Zimmerman,
Jonathan Mayer, Arvind Narayanan, and Edward W. Felten. 2015. Cookies That
Give You Away: The Surveillance Implications of Web Tracking. In Proceedings
of the 24th International Conference on World Wide Web (WWW ’15). Interna-
tional World Wide Web Conferences Steering Committee, Republic and Canton
of Geneva, Switzerland, 289–299. https://doi.org/10.1145/2736277.2741679
[17] Eset. 2018. Wayback Machine: Eset Virus Radar. https://web.archive.org/web/
20180126135759/www.virusradar.com/en/statistics. Accessed: 2018-06-02.
[18] Shayan Eskandari, Andreas Leoutsarakos, Troy Mursch, and Jeremy Clark. 2018.
A rst look at browser-based Cryptojacking. Technical Report. Bad Packets.
[19] Mario Heiderich, Tilman Frosch, and Thorsten Holz. 2011. IceShield: Detection
and Mitigation of Malicious Websites with a Frozen DOM. In Recent Advances in
Intrusion Detection, Robin Sommer, Davide Balzarotti, and Gregor Maier (Eds.).
Springer Berlin Heidelberg, Berlin, Heidelberg, 281–300.
[20] Paul Irish. 2016. Speedline. https://github.com/paulirish/speedline Accessed:
[21] Paul Irish. 2017. Debugging Protocol: Does ‘Page.addScriptToEvaluateOnLoad‘
execute before the "load" event? https://groups.google.com/a/chromium.org/for
um/#!topic/headless-dev/cD0iF2lpHeA. Accessed: 2018-01-15.
[22] Rafael K. 2017. NoCoin: blacklist.txt. https://raw.githubusercontent.com/keraf/
NoCoin/master/src/blacklist.txt. Accessed: 2017-10-15.
[23] Alexandros Kapravelos, Yan Shoshitaishvili, Santa Barbara, Marco Cova, Christo-
pher Kruegel, and Giovanni Vigna. 2013. Revolver: An Automated Approach
to the Detection of Evasive Web-based Malware. In Usenix security. USENIX,
Washington, D.C., 637–652. https://www.usenix.org/conference/usenixsecurity
13/technical-sessions/presentation/kapravelos
[24] Daniel Kostro. 2017. LIBSVM for the browser and nodejs. https://github.com/mlj
s/libsvm. Accessed: 2018-06-02.
[25] Chaoying Liu and Joseph C. Chen. 2018.
Abuses Google’s DoubleClick
https://blog.trendmicro.com/trendlabs-security-intelligence/malvertising
-campaign-abuses-googles-doubleclick-to-deliver-cryptocurrency-miners/
Malvertising Campaign
to Deliver Cryptocurrency Miners.
[26] Mark Maunder. 2018. WordPress Plugin Banned for Crypto Mining. https://ww
w.wordfence.com/blog/2017/11/wordpress-plugin-banned-crypto-mining/. Ac-
cessed: 2018-01-15.
[27] Jose Nazario. 2009. PhoneyC: A Virtual Client Honeypot. In Proceedings of the
2Nd USENIX Conference on Large-scale Exploits and Emergent Threats: Botnets,
Spyware, Worms, and More (LEET’09). USENIX Association, Berkeley, CA, USA,
6–6. http://dl.acm.org/citation.cfm?id=1855676.1855682
[28] Shaun Nichols. 2018. Guys, you’re killing us! LA Times homicide site hacked to
mine crypto-coins on netizens’ PCs. https://www.theregister.co.uk/2018/02/22/la
2018-06-10.
_times_amazon_aws_s3/.
[29] N. Nikiforakis, A. Kapravelos, W. Joosen, C. Kruegel, F. Piessens, and G. Vigna.
2013. Cookieless Monster: Exploring the Ecosystem of Web-Based Device Fin-
gerprinting. In 2013 IEEE Symposium on Security and Privacy. IEEE, Berkley, CA,
USA, 541–555. https://doi.org/10.1109/SP.2013.43
[30] Scipy Lecture Notes. 2018. Coordinate Format (COO). http://www.scipy-lectures
.org/advanced/scipy_sparse/coo_matrix.html. Accessed: 2018-06-02.
[31] Mark O’Neill, Scott Ruoti, Kent Seamons, and Daniel Zappala. 2016. TLS Proxies:
Friend or Foe?. In Proceedings of the 2016 Internet Measurement Conference (IMC
’16). ACM, New York, NY, USA, 551–557. https://doi.org/10.1145/2987443.2987488
[32] Fabian Pedregosa, Gaël Varoquaux, Alexandre Gramfort, Vincent Michel,