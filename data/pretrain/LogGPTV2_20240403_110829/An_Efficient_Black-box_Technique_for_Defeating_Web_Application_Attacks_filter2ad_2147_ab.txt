priately normalized. By relying on ModSecurity to handle
these tasks, which can be complex and error-prune, we have
been able to build a robust implementation of event inter-
ception for HTTP requests and responses.5
5Note that weaknesses in parsing, decoding and normalization HTTP
requests and responses can be exploited by an attacker to mount evasion
attacks to get past our defenses. Such evasion attacks are a signiﬁcant
threat in the context of HTTP requests, which are entirely under the control
of an attacker. By relying on ModSecurity, which has been developed
(and tested over many years) with an eye towards evasive techniques, our
The input event
interceptor extracts various HTTP
header ﬁelds, URL name, parameters, cookies, etc. It then
makes them available to the rest of our system in a stan-
dardized format, namely, a pair of strings (cid:104)name, value(cid:105).
In addition, for complex data that need additional parsing,
it can invoke additional parser plug-ins. Currently, we do
this primarily for extracting parameters from XML RPC re-
quests.
On the output side, we have currently implemented
parsers for SQL, shell-scripts and HTML. Both SQL and
shell are “command languages” and hence have some com-
monality, thus leading us to employ similar approaches for
implementing parsers for the two languages. Our imple-
mentation uses standard parser generator tools Flex and Bi-
son, and required about one week for initial implementation
and testing. Our SQL and shell-scripts parsers are quite ac-
curate in terms of recognizing the lexical structure of these
languages — we chose to do this because (a) the lexical
structure of these languages is signiﬁcantly simpler (and
much less variable across language variants) than the syn-
tactic structure, so accurate lexical analysis is feasible with
modest efforts, and (b) injection attacks typically involve
changes to the lexical structure (due to the introduction of
characters such as quotes, spaces or comment characters),
and hence inaccuracies in lexical analysis can lead to false
positives and false negatives.
As mentioned before, there is a trade-off between com-
pleteness of the parser for a language and other factors such
as implementation effort, generality, robustness and perfor-
mance of the parser. There may be several ways to balance
these conﬂicting concerns. Here, we describe some of the
speciﬁc choices made in our implementation. Our shell-
script parser is capable of parsing nested structures such as
if-then-else, loops, parenthesized expressions, and so on,
but does not know the interpretation of most operators, or
information such as their precedence.
Instead, it treats a
nested structure as a sequence of elements. At the highest
level, the parser assumes that shell commands will consist
of a sequence of statements that are separated by characters
such as semicolons, newlines, ampersands, pipe characters,
etc. The ﬁrst word in a statement is recognized as a com-
mand name, and the others as parameters. The resulting
parser is capable of parsing multiple shell languages, and
has been tested on several bash and C-shell scripts that con-
tain tens of thousands of lines of code.
A similar approach is used in our SQL parser. It recog-
nizes keywords such as select and union, as well as opera-
tors, comments, literals, numbers, etc. It can also recognize
nested structures such as expressions within nested paren-
theses. It does not currently incorporate knowledge about
speciﬁcs of each operator or keyword, such as the number
of required operands or operator precedence. (However, un-
implementation reduces the likelihood of such attacks.
like shell languages, this knowledge could be incorporated
into our SQL parser with modest additional efforts.) The re-
sulting parser has been tested against a large number (many
thousands) of SQL queries generated by several web appli-
cations.
HTML parsing is simpliﬁed by the fact that it does not
use any inﬁx operators. The goal of the parser is to iden-
tify tag names and parameters so that they may be matched
against policies for attack detection; the parser is otherwise
unconcerned with the signiﬁcance of tags. The main com-
plexity in the HTML parser arises from the fact that HTML
frequently contains syntactic errors, e.g., missing closing
tags6. A related complication is that closing tags are op-
tional in some cases. To cope with both complications, our
parser uses a stack to keep track of currently open tags.
When a closing tag does not match the open tag at the stack
top, it can skip the top few tags to ﬁnd a matching tag fur-
ther down. The parser pretends as if these missing close
tags were present, so as to produce a valid parse. But if the
matching open tag is not found among the top few, then the
closing tag is considered an error, and is discarded. When
the end-of-ﬁle is encountered, the parser pretends that clos-
ing tags corresponding to all open tags on the stack have
been seen, thus producing a valid parse tree. The result-
ing parser has been tested on thousands of web pages. Es-
sentially the same parser was used for parsing XML in the
context of XML/RPC.
The output of the parser is an abstract syntax tree (AST).
The AST consists of nodes that are linked to substrings of
the parsed text. Each node is annotated with a tag that
indicates the type of the node, such as a command name,
parameter name, parameter value, command separator, etc.
Additional details about the AST structure are provided in
Section 5.
Our design choice to implement rough parsers led to sig-
niﬁcant reductions in implementation efforts: the actual im-
plementation of all of the above-mentioned parsers took just
over two weeks of a single developer’s time.
4 Taint Inference
Our taint inference algorithm is based on the following
observations about many web applications:
• Web applications perform sanitization operations on
their input parameters. These operations involve dele-
tion (e.g., white-space removal), insertion (e.g., es-
6While errors are possible in SQL and shell-commands, they usually
occur in the context of attacks. This is because syntax errors in web-
application generated SQL and shell commands lead to application fail-
ures, and hence are promptly corrected. In contrast, many HTML errors
go unnoticed because browsers typically employ robust error-handling and
recovery, and can often cope with many syntax errors without visibly al-
tering outputs.
caping special characters or introducing quotes), or
substitution (e.g., replacing lower-case characters with
upper-case and replacing spaces with underscore).
However, a majority of characters are usually left un-
touched by sanitization.
• A web application assembles an outgoing request from
input parameters. Some parts of these requests are
statically speciﬁed in the web application code, while
other parts are derived from inputs.
The ﬁrst observation suggests that taint inference should
be based on approximate string-matching rather than ex-
act string matching. The second observation suggests that
it should be based on ﬁnding substrings rather than com-
plete matches. To illustrate these choices, consider the
SquirrelMail command injection example again. The vul-
nerable URL is /squirrelmail-1.4.0/plugins/gpg/
gpg encrypt.php. In the exploit we studied, there were
about dozen parameters, all of which were parsed and ex-
tracted. The one that is of interest is the “send to” parame-
ter, which had the value
alice, bob; touch /tmp/GotYou
Based on these input values, SquirrelMail generated the fol-
lowing shell-command:
echo ’···’ | /usr/bin/gpg ··· -r
alice@ -r bob;touch /tmp/GotYou@ 2>&1
Some parts of the command that are irrelevant for the at-
tack have been replaced with “···”.
In addition, charac-
ters copied from the send to parameter have been high-
lighted in italics. Note that the input text has gone through
a few changes before use:
in particular, the recipient list
has been separated into its component names, and each of
these names preﬁxed by a “-r” and postﬁxed with an “@”
symbol. As a result, an exact substring matching algorithm
will not identify that the send to parameter appears in the
shell-command, but an approximate substring matching al-
gorithm can detect this with a high degree of conﬁdence.
4.1 Taint Inference and Approximate Substring
Matching
We start by recalling the notion of edit distance on
strings. Edit distance is given by three cost functions D,
I, and S. D(c) denotes the cost of deleting the character
c, I(c) denotes the cost of inserting c, and S(c, d) denotes
the cost of substituting a character c by another character d.
The following conditions apply for all characters c and d:
• I(c) ≥ 0 and D(c) ≥ 0
• S(c, d) ≤ D(c) + I(d)
Let {e1, ..., ek} be a sequence of edit operations (insertion,
deletion or substitution) that yield a string t from another
string s. The cost of this sequence is deﬁned to be the sum
of costs of the individual edit operations. The weighted edit
distance ED(s, t) is deﬁned to be the lowest cost among
all edit sequences that transform s into t. Next, we deﬁne
normalized weighted substring edit distance between s and
t, which, for simplicity, we refer to as taint distance (TD).
Let D(s) denote the cost of deleting all characters in s:
T D(s, t) =
min
u a substring of t
ED(s, u)/D(s)
Note that T D(s, ) = 1.0, where  denotes the empty string.
Deﬁnition 1 (Taint Inference Criteria) Given an input s
and output t and a threshold 0 ≤ d ≤ 1, taint is inferred if
T D(s, t) ≤ d.
The problem of selecting thresholds is discussed in Sec-
tion 7.3.
Edit distance can be computed using a dynamic pro-
gramming technique in O(nm) time [14, 7] and using
O(nm) storage, where n = |s| and m = |t| represent
the lengths of the strings involved in the computation. Be-
low, we review this dynamic programming algorithm. Let
s = s1s2 ··· sn and t = t1t2 ··· tm, where si and tj denote
the ith and jth characters in s and t respectively. Let Mk,l
denote the weighted edit distance between s1s2 ··· sk and
t1t2 ··· tl.
Mi,j = min(Mi−1,j−1 + S(si, tj),
Mi−1,j + D(si),
Mi,j−1 + I(tj))
This same recurrence can be used to handle approximate
matching of whole strings as well as substrings — the dif-
ference arises only in the base case for M. To support ap-
proximate substring matching, M0,j is set to zero, which
captures the fact that a match for s may be tried within t
starting from any position j + 1, i.e., there is no “cost”
for skipping the ﬁrst j characters of t. However, there
is a penalty for skipping characters in s:
it corresponds
to the cost of deleting these characters, so Mi,0 is set to
D(s1s2 ··· si).
(For matching whole strings (rather than
substrings), M0,j will be set to I(t1t2 ··· tj))
Based on the deﬁnition of M above, we can deﬁne T D
as follows:
T D(s, t) = min
0 r, and cq denotes
that a character c is repeated q times (consecutively) in a
string.
Note that t can be obtained from s by inserting r-
occurrences of b into it. Thus, ED(s, t) = I(br) = r. How-
ever, we show that ED(cid:48)(s, ti) is twice that of ED(s, t). To
understand why, note that when q > r, every ti’s will con-
tain r occurrences of b. Moreover, it will contain fewer (or
the same) occurrences of a’s and c’s as compared to s. Thus,
to obtain Ti from S, we need to insert r-occurrences of b
into s, and then delete a total of r occurrences of a’s and
c’s. Thus, ED(cid:48)(ti) = 2r.
The example illustrates that we need an alternative met-
ric in place of ED(cid:48) in order to ensure that all potential ti
are identiﬁed, and the full dynamic programing algorithm
9Often, there is no better way to deﬁne S(c, d) than that of D(c) +
I(d). Exceptions to this occur primarily in the context of upper-case to
lower-case (or one white-space to another white-space) character. These
can be handled by ﬁrst mapping such “equivalent” characters into the same
character, and then applying the coarse-ﬁltering algorithm — this is what
we do in our implementation.
s
t
ED(s, t)
ti
aqcq
aqbrcq
aq−(i−1)brcq−r+(i−1)
r
Figure 4. Example to illustrate ED and ED(cid:48).
r
D(S − Ti)