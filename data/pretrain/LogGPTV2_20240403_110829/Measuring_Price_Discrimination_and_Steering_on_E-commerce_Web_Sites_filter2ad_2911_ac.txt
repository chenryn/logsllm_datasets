ucts for the given query. We can then calculate the DCG
for the AMT user’s results and normalize it using R(cid:48). Ef-
fectively, if nDCG(AM T user) > nDCG(control), then the
AMT user’s search results include more-expensive products
towards the top of the page than the control.
For each site, Figure 2 presents the average Jaccard index,
Kendall’s τ , and nDCG across all queries. The results are
presented comparing the comparison to the control searches
(Control), and the comparison to the AMT user searches
(User). We observe several interesting trends. First, Sears,
Walmart, and Priceline all have a lower Jaccard index for
AMT users relative to the control. This indicates that the
AMT users are receiving diﬀerent products at a higher rate
than the control searches (again, note that we are not com-
paring AMT users’ results to each other; we only compare
each user’s result to the corresponding comparison result).
Other sites like Orbitz show a Jaccard of 0.85 for Control
and User, meaning that the set of results shows inconsisten-
cies, but that AMT users are not seeing a higher level of
inconsistency than the control and comparison searches.
Second, we observe that on Newegg, Sears, Walmart, and
Priceline, Kendall’s τ is at least 0.1 lower for AMT users,
i.e., AMT users are consistently receiving results in a diﬀer-
 0 10 20 30 40 50BestbuyCDWHomeDepotJCPMacysNeweggOfficeDepotSearsStaplesWalmartCheapticketsExpediaHotelsOrbitzPricelineCheapticketsExpediaOrbitzPricelineTravelocity% of Users72%E-commerceHotelsRental CarsAccountPurchase309Figure 2: Average Jaccard index (top), Kendall’s τ (middle), and nDCG (bottom) across all users and searches for each web site.
Figure 3: Percent of products with inconsistent prices (bottom), and the distribution of price diﬀerences for sites with ≥0.5% of
products showing diﬀerences (top), across all users and searches for each web site. The top plot shows the mean (thick line), 25th and
75th percentile (box), and 5th and 95th percentile (whisker).
ent order than the controls. This observation is especially
true for Sears, where the ordering of results for AMT users
is markedly diﬀerent. Third, we observe that Sears alone
appears to be ordering products for AMT users in a price-
biased manner. The nDCG results show that AMT users
tend to have cheaper products near the top of their search
results relative to the controls. Note that the results in
Figure 2 are only useful for uncovering price steering; we
examine whether the target sites are performing price dis-
crimination in § 4.3.
Besides Priceline, the other four travel sites do not show
signiﬁcant diﬀerences between the AMT users and the con-
trols. However, these four sites do exhibit signiﬁcant noise:
Kendall’s τ is ≤0.83 in all four cases. On Cheaptickets and
Orbitz, we manually conﬁrm that this noise is due to ran-
domness in the order of search results. In contrast, on Ex-
pedia and Hotels.com this noise is due to systematic A/B
testing on users (see § 5.2 for details), which explains why
we see equally low Kendall’s τ values on both sites for all
users. Unfortunately, it also means that we cannot draw
any conclusions about personalization on Expedia and Ho-
tels.com from the AMT experiment, since the search results
for the comparison and the control rarely match.
4.3 Price Discrimination
So far, we have only looked at the set of products returned.
We now turn to investigate whether sites are altering the
prices of products for diﬀerent users, i.e., price discrimina-
tion. In the bottom plot of Figure 3, we present the frac-
tion of products that show price inconsistencies between the
user’s and comparison searches (User) and between the com-
parison and control searches (Control). Overall, we observe
that most sites show few inconsistencies (typically 0.5% of the products show inconsistency.
We plot the mean price diﬀerential (thick line), 25th and
 0 0.2 0.4 0.6 0.8BestbuyCDWHomeDepotJCPMacysNeweggOfficeDepotSearsStaplesWalmartCheapticketsExpediaHotelsOrbitzPricelineAvg. nDCGControlUser 0 0.2 0.4 0.6 0.8 1Avg. Kendall’s tau 0 0.2 0.4 0.6 0.8 1Avg. JaccardE-commerceHotels 0 1 2BestbuyCDWHomeDepotJCPMacysNeweggOfficeDepotSearsStaplesWalmartCheapticketsExpediaHotelsOrbitzPricelineCheapticketsExpediaOrbitzPricelineTravelocity% Products w/different prices3.6%Threshold 0.5%ControlUser$1$10$100$1000Distribution ofinconsistenciesE-commerceHotelsRental Cars310Figure 5: AMT users that receive highly personalized search results on general retail, hotels, and car rental sites.
75th percentile (box), and 5th and 95th percentile (whisker).
Note that in our data, AMT users always receive higher
prices than the controls (on average), thus all diﬀerentials
are positive. We observe that the price diﬀerentials on many
sites are quite large (up to hundreds of dollars). As an ex-
ample, in Figure 4, we show a screenshot of a price inconsis-
tency that we observed. Both the control and comparison
searches returned a price of $565 for a hotel, while our AMT
user was returned a price of $633.
4.4 Per-User Personalization
Next, we take a closer look at the subset of AMT users
who experience high levels of personalization on one or more
of the e-commerce sites. Our goal is to investigate whether
these AMT users share any observable features that may il-
luminate why they are receiving personalized search results.
We deﬁne highly personalized users as the set of users who
see products with inconsistent pricing >0.5% of the time.
After ﬁltering we are left with between 2-12% of our AMT
users depending on the site.
First, we map the AMT users’ IP addresses to their ge-
olocations and compare the locations of personalized and
non-personalized users. We ﬁnd no discernible correlation
between location and personalization. However, as men-
tioned above, in this experiment all searches originate from
a proxy in Boston. Thus, it is not surprising that we do not
observe any eﬀects due to location, since the sites did not
observe users’ true IP addresses.
Next, we examine the AMT users’ browser and OS choices.
We are able to infer their platform based on the HTTP head-
Figure 4: Example of price discrimination. The top result was
served to the AMT user, while the bottom result was served to
the comparison and control.
ers sent by their browser through our proxy. Again, we ﬁnd
no correlation between browser/OS choice and high person-
In § 5, we do uncover personalization linked to
alization.
the use of mobile browsers, however none of the AMT users
in our study did the HIT from a mobile device.
Finally, we ask the question: are there AMT users who
receive personalized results on multiple e-commerce sites?
Figure 5 lists the 100 users in our experiments along the
x-axis of each plot; a dot highlights cases were a site person-
alized search results for a particular user. Although some
dots are randomly dispersed, there are many AMT users
that receive personalized results from several e-commerce
sites. We highlight users who see personalized results on
more than one site with vertical bars. More users fall into
this category on travel sites than on general retailers.
The takeaway from Figure 5 is that we observe many AMT
users who receive personalized results across multiple sites.
This suggests that these users share feature(s) that all of
these sites use for personalization. Unfortunately, we are
unable infer the speciﬁc characteristics of these users that
are triggering personalization.
Cookies.
Although we logged the cookies sent by AMT
users to the target e-commerce sites, it is not possible to
use them to determine why some users receive personalized
search results. First, cookies are typically random alphanu-
meric strings; they do not encode useful information about
a user’s history of interactions with a website (e.g., items
clicked on, purchases, etc.). Second, cookies can be set by
content embedded in third-party websites. This means that
a user with a cookie from e-commerce site S may never
have consciously visited S, let alone made purchases from
S. These reasons motivate why we rely on survey results
(see Figure 1) to determine AMT users’ history of interac-
tions with the target e-commerce sites.
4.5 Summary
To summarize our ﬁndings in this section: we ﬁnd ev-
idence for price steering and price discrimination on four
general retailers and ﬁve travel sites. Overall, travel sites
show price inconsistencies in a higher percentage of cases,
relative to the controls, with prices increasing for AMT users
by hundreds of dollars. Finally, we observe that many AMT
users experience personalization across multiple sites.
5. PERSONALIZATION FEATURES
In § 4, we demonstrated that e-commerce sites personalize
results for real users. However, we cannot determine why
results are being personalized based on the data from real-
world users, since there are too many confounding variables
attached to each AMT user (e.g., their location, choice of
browser, purchase history, etc.).
BestbuyCDWHomeDepotJCPMacysNeweggOfficeDepotSearsStaplesWalmartAMT UsersCheapticketsExpediaHotelsOrbitzPricelineAMT UsersCheapticketsExpediaOrbitzPricelineTravelocityAMT Users311Category Feature Tested Values
Account
Cookies No Account, Logged In, No Cookies
User-
Agent
Account
History
OS Win. XP, Win. 7, OS X, Linux
Browser
Click
Purchase
Chrome 33, Android Chrome 34, IE 8,
Firefox 25, Safari 7, iOS Safari 6
Low Prices, High Prices
Low Prices, High Prices
Table 3: User features evaluated for eﬀects on personalization.
In this section, we conduct controlled experiments with
fake accounts created by us to examine the impact of spe-
ciﬁc features on e-commerce personalization. Although we
cannot test all possible features, we examine ﬁve likely can-
didates: browser, OS, account log-in, click history, and pur-
chase history. We chose these features because e-commerce
sites have been observed personalizing results based on these
features in the past [1, 28].
We begin with an overview of the design of our synthetic
user experiments. Next, we highlight examples of person-
alization on hotel sites and general retailers. None of our
experiments triggered personalization on rental car sites, so
we omit these results.
5.1 Experimental Overview
The goal of our synthetic experiments is to determine
whether speciﬁc user features trigger personalization on e-
commerce sites. To assess the impact of feature X that can
take on values x1, x2, . . . , xn, we execute n + 1 PhantomJS
instances, with each value of X assigned to one instance.
The n + 1th instance serves as the control by duplicating
the value of another instance. All PhantomJS instances ex-
ecute 20 queries (see § 3.4) on each e-commerce site per day,
with queries spaced one minute apart to avoid tripping secu-
rity countermeasures. PhantomJS downloads the ﬁrst page
of results for each query. Unless otherwise speciﬁed, Phan-
tomJS persists all cookies between experiments. All of our
experiments are designed to complete in <24 hours.
To mitigate measurements errors due to noise (see § 3.1),
we perform three steps (some borrowed from previous
work [16, 17]): ﬁrst, all searches for a given query are ex-
ecuted at the same time. This eliminates diﬀerences in re-
sults due to temporal eﬀects. This also means that each of
our treatments has exactly the same search history at the
same time. Second, we use static DNS entries to direct all
of our query traﬃc to speciﬁc IP addresses of the retailers.
This eliminates errors arising from diﬀerences between dat-
acenters. Third, although all PhantomJS instances execute
on one machine, we use SSH tunnels to forward the traﬃc
of each treatment to a unique IP address in a /24 subnet.
This process ensures that any eﬀects due to IP geolocation
will aﬀect all results equally.
Static Features.
Table 3 lists the ﬁve features that
we evaluate in our experiments. In the cookie experiment,
the goal is to determine whether e-commerce sites person-
alize results for users who are logged-in to the site. Thus,
two PhantomJS instances query the given e-commerce site
without logging-in, one logs-in before querying, and the ﬁnal
account clears its cookies after every HTTP request.
In two sets of experiments, we vary the User-Agent sent
by PhantomJS to simulate diﬀerent OSes and browsers. The
goal of these tests is to see if e-commerce sites personalize
based on the user’s choice of OS and browser. In the OS
experiment, all instances report using Chrome 33, and Win-
dows 7 serves as the control.
In the browser experiment,
Chrome 33 serves as the control, and all instances report
using Windows 7, except for Safari 7 (which reports OS X
Mavericks), Safari on iOS 6, and Chrome on Android 4.4.2.
Historical Features.
In our historical experiments,
the goal is to examine whether e-commerce sites personal-
ize results based on users’ history of viewed and purchased
items. Unfortunately, we are unable to create purchase his-
tory on general retail sites because this would entail buying
and then returning physical goods. However, it is possi-
ble for us to create purchase history on travel sites. On
Expedia, Hotels.com, Priceline, and Travelocity, some hotel
rooms feature “pay at the hotel” reservations where you pay
at check-in. A valid credit card must still be associated with
“pay at the hotel” reservations. Similarly, all ﬁve travel sites
allow rental cars to be reserved without up-front payment.
These no-payment reservations allow us to book reservations
on travel sites and build up purchase history.
To conduct our historical experiments, we created six ac-
counts on the four hotel sites and all ﬁve rental car sites.
Two accounts on each site serve as controls: they do not
click on search results or make reservations. Every night
for one week, we manually logged-in to the remaining four
accounts on each site and performed speciﬁc actions. Two
accounts searched for a hotel/car and clicked on the high-
est and lowest priced results, respectively. The remaining
two accounts searched for the same hotel/car and booked
the highest and lowest priced results, respectively. Sepa-
rate credit cards were used for high- and low-priced reser-
vations, and neither card had ever been used to book travel
before. Although it is possible to imagine other treatments
for account history (e.g., a person who always travels to
a speciﬁc country), price-constrained (inelastic) and uncon-
strained (elastic) users are a natural starting point for exam-
ining the impact of account history. Furthermore, although
these treatments may not embody realistic user behavior,
they do present unambiguous signals that could be observed
and acted upon by personalization algorithms.
We pre-selected a destination and travel dates for each
night, so the click and purchase accounts all used the same
search parameters. Destinations varied across major US,
European, and Asian cities, and dates ranged over the last
six months of 2014. All trips were for one or two night
stays/rentals. On average, the high- and low-price pur-
chasers reserved rooms for $329 and $108 per night, respec-
tively, while the high- and low-price clickers selected rooms
for $404 and $99 per night. The four rental car accounts
were able to click and reserve the exact same vehicles, with
$184 and $43 being the average high- and low-prices per day.
Each night, after we ﬁnished manually creating account
histories, we used PhantomJS to run our standard list of 20
queries from all six accounts on all nine travel sites. To main-
tain consistency, manual history creation and automated
tests all used the same set of IP addresses and Firefox.
Ethics.
We took several precautions to minimize any
negative impact of our purchase history experiments on
travel retailers, hotels, and rental car agencies. We reserved,
at most, one room from any speciﬁc hotel. All reservations
were made for hotel rooms and cars at least one month into
the future, and all reservations were canceled at the conclu-
sion of our experiments.
312Figure 6: Examining the impact of user accounts and cookies on hotel searches on Cheaptickets.
Analyzing Results.
To analyze the data from our
feature experiments, we leverage the same ﬁve metrics used
in § 4. Figure 6 exempliﬁes the analysis we conduct for each
user feature on each e-commerce site. In this example, we
examine whether Cheaptickets personalizes results for users
that are logged-in. The x-axis of each subplot is time in
days. The plots in the top row use Jaccard Index, Kendall’s
τ , and nDCG to analyze steering, while the plots in the
bottom row use percent of items with inconsistent prices