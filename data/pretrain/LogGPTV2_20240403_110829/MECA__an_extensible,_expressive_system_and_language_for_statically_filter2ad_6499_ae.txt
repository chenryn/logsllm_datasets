is set to be in the kernel. Two are due to wrong pointer
arithmetic propagation, where user base - kernel base +
kernel pointer which computes user base + offset is con-
sidered as a kernel pointer. Two are caused by false paths.
The other two are because our predicate analysis is not so-
phisticated enough.
To measure the eﬀectiveness of suppressing false posi-
tives, we rerun the analysis without the imply annotations
and the ignore annotations. We left the one for struct
kernel symbols unremoved because removing it will cause
too many false positives to inspect. Not surprisingly, 98
more false positives (uniqued by ﬁle name and function name)
were generated in that run.
Figure 16 gives a rare security hole in the base kernel that
was found in fs/quota.c, which is well-tested, well audited
code. Function sys quotactl is a system call. The global
annotator taints all of its parameters, including special.
This tainted pointer is passed into lookup dev, which deref-
erences it. A malicious user can trivially cause the kernel
Arbitrary Write
Arbitrary Read
Fault at Will
Always Fail
Total
False Positives
11
8
19
6
44
8
11
8
17
3
39
Table 6: User-pointer bugs we found in Linux 2.5.63,
broken down by severity and ease of exploit.
/* linux-2.5.63/fs/quota.c */
asmlinkage long sys quotactl(unsigned int cmd,
const char *special, qid t id, caddr t addr) {
bdev = lookup bdev(special);
}
/* linux-2.5.63/fs/block dev.c */
struct block device *lookup bdev(const char *path) {
if (!path || !*path)
return ERR PTR(−EINVAL);
}
Figure 16: A security hole in fs/quota.c. Only rele-
vant code is shown
to crash or read unfortunate device memory addresses by
passing in a value for special of their choosing.
Cross-checking. Cross checking by propagating anno-
tations across function pointers was extremely eﬀective. Se-
curity errors seem to cluster: if a programmer is unaware of
an interface rule (e.g., that a parameter should be tainted)
they stay unaware, blithely violating the rule. For Linux,
all eleven of the write bugs and four of the read bugs were
found by propagating annotations across functions assigned
to the same function pointer. For most of these bugs, there
was not a single check in the functions (or even the ﬁles)
that contain the bugs.
Figure 17 gives a representative example. The function
sg read taints its second argument buf using a call to func-
tion verify area. The function sg read is also statically as-
signed to the ﬁeld read in a structure of type file operations.
This will cause the system to taint the second argument in
all other functions assigned to a structure of this type. In
our example, this happens when the function do read is as-
signed to the variable Divas fops. This taints do reads
second argument; this annotation is then propagated to the
variable ClientLogBuffer, which causes an error when it is
passed to memcpy. Interestingly, even the user pointer itself
has the name pClientLogBuffer and pUserBuffer.
9. RELATED WORK
There have been numerous annotation languages designed
for program checkers. Systems that are most related to
MECA are Splint [9], CQual [12], and ESC/Java [16].
Splint is an annotation based tool for detecting a vari-
ety of programming errors such as null-pointer dereferences
and potential buﬀer overrun vulnerabilities.
It employs a
simple ﬂow-sensitive analysis assisted by user provided an-
notations that is fast and scalable. However, Splint has the
following drawbacks that limits its usefulness in eﬀectively
checking large systems. First, its annotation propagation is
Formal Parameter
Annotation Rank
p-value Rank Utility
tainted
!tainted
unknown
Actual Parameters
copy to user:1
put user:2
get user:2
put user:2
verify area:2
get user:2
copy from user:2
copy to user:1
access ok:2
user walk:1
clear user:1
1
2
3
4
5
6
7
8
9
10
11
2
1
3
8
5
9
18
19
4
80
10
496
422
354
125.9
84
58.9
37.6
33.1
26
11
6.9
931
644
347
33
103
18
8
7
81
3
6
8
1
1
0
0
2
0
0
1
0
0
496
422
354
126
84
59
44
43
26
27
7
Table 5: Annotation ranking using statistical inference and annotation utility.
more limited than MECA (e.g., it lacks true inter-procedural
propagation). Second, except for a small set of pre-deﬁned
operators, Splint only allows unary predicates for expressing
program properties rather than n-ary predicates (§ 3.1.1).
Finally, other than the “ignore” primitive which essentially
turns oﬀ checking for a segment of the target code, Splint
provides few means of systematic suppression of false posi-
tives. MECA, on the other hand, allows extension-speciﬁc
suppression using hints from user-provided annotations (e.g.
the from user ==> tainted example in Section 3).
CQual is a type-based analysis tool for deﬁning, inferring,
and checking ﬂow-sensitive type qualiﬁers in C programs.
It employs an eﬃcient constraint-based type inference al-
gorithm to propagate user provided information to mini-
mize manual annotation. It is more ambitious than MECA
in that it is sound by design. However, because it forces
soundness, it must always use conservative alias analysis,
which can give many false positives. Extra user-provided
alias speciﬁcations are needed in order to suppress a large
portion of those false positives. The large amount of work
required limits the applicability of CQual on large exist-
ing systems [23]. Furthermore, it only supports unary type
qualiﬁers, which limits the properties it can express.
ESC/Java descends from the intellectual tradition of pro-
gram veriﬁcation.
It allows users to write arbitrary ﬁrst-
order logic formulas for annotations, which it checks using
an automatic theorem prover. Its annotation language can
express a signiﬁcantly richer set of concepts than MECA.
However, it appears that in practice MECA can match much
of this power because it lets checkers deﬁne their own builtin
predicates (§ 3.2). ESC/Java lacks extensibility in terms of
deﬁning new checks and it appears that MECA applies much
more easily to large code bases than ESC/Java does. While
ESC/Java has a high annotation burden, recent work on
Houdini [11] has shown how to use annotation templates to
automatically derive ESC annotations. One diﬀerence be-
tween our approach and theirs is that our use of statistical
inference allows us to handle noisier samples when deriving
our annotations.
The GCC attribute extension allows users to annotate
declarations in C programs. The main objective of the GCC
attributes is to provide the GCC compiler with hints for
error reporting (mostly for syntax and type errors detected
in the frontend) and optimization purposes.
Zhang et al [23] modiﬁed GCC and used a Perl script
to annotate all the local variables of certain types to be
“unchecked.” This can be viewed as hardwired program-
matic annotation. Compared with their approach, our sys-
tem allows programmers to easily write such programmatic
annotations in the source without any compiler knowledge.
MOPS [3] is another system that checks for security prop-
erties, which is loosely related to MECA. It uses ﬁnite state
automatons to represent security rules, slices a program
based on the state transitions speciﬁed in these rules, trans-
forms the sliced program into a pushdown automaton and
uses model checking techniques to check for security errors
and verify their absence. Compared with MECA, it pro-
vides no annotation support for programmers to express
general security rules in the source code. The range of
the security rules it can check seems limited since it does
no dataﬂow analysis except simple syntactical matching on
variable names.
The taintedness problem in Section 7 has been explored
in [1, 12, 9]. Capability checking has been explored in [7].
10. CONCLUSION
This paper has described a system and language for ex-
pressing and checking general security rules.
The annotation language is expressive and direct. It gives
programmers novel powers. One is the ability to write pro-
grammatic annotations that automatically annotate a large
bodies of source code. Another is the ability to use computa-
tionally ﬂexible predicates to control whether an annotation
is applied. We used this ability to handle kernel backdoors
and other false-positive inducing constructs.
The system is tailored for getting results on real systems.
It is designed to make it easy to suppress false positives.
Additionally, its propagation abilities mean that a single
manual annotation leads to many derived annotations (e.g.,
hundreds in our experiments) freeing programmers from the
crushing manual eﬀort of most traditional systems.
The system is eﬀective. Our most through case study was
a user-pointer checker that used 75 annotations to check
thousands of declarations in millions of lines of code in the
Linux system.
It found over forty errors, many of which
were serious, while only having eight false positives.
While the system is still a prototype, our initial expe-
riences indicate that it can give signiﬁcant traction when
checking large bodies of real code.
/* linux-2.5.63/drivers/scsi/sg.c */
static ssize t
sg read(struct ﬁle *ﬁlp, char *buf, size t count, loﬀ t * ppos) {
// [META]: taints second argument buf
if ((k = verify area(VERIFY WRITE, buf, count)))
return k;
}
static struct ﬁle operations sg fops = {
/* Assigns: sg read to the read ﬁeld in ﬁle operations. Since
* the second parameter of sg read is tainted (from the code
* above) this will taint the second parameter of all
* functions assigned to this ﬁeld. */
.read = sg read,
.write = sg write,
.poll = sg poll,
.ioctl = sg ioctl,
. . .
};
/* linux-2.5.63/drivers/isdn/eicon/lincfg.c */
struct ﬁle operations Divas fops;
int DivasCardsDiscover(void) {
/* Assign do read to the read ﬁeld in ﬁle operations: causes
* its parameter to be marked as tainted. */
Divas fops.read = do read;
}
/* linux-2.5.63/drivers/isdn/eicon/linchr.c */
ssize t do read(struct ﬁle *pFile, char *pUserBuﬀer,
size t BuﬀerSize, loﬀ t *pOﬀset)
{
/* pUserBuﬀer tainted from function pointer prop. */
klog t *pClientLogBuﬀer = (klog t *) pUserBuﬀer;
if (pHeadItem) {
/* ERROR: dereferencing tainted pointer. */
memcpy(pClientLogBuﬀer, pHeadItem, sizeof (klog t));
}
Figure 17: A security hole found by cross checking
through ﬁle operations.read. Only relevant code is
shown
Acknowledgements
This research was supported in part by DARPA contract
MDA904-98-C-A933 and by a grant from the Stanford Net-
working Research Center. Dawson Engler is partially sup-
ported by an NSF Career Award and Ted Kremenek re-
ceived funding from an NSF Graduate Fellowship. We are
also grateful for helpful comments from Xiaowei Yang, Ken
Ashcraft, and the anonymous reviewers.
11. REFERENCES
[1] K. Ashcraft and D. Engler. Using programmer-written
compiler extensions to catch security holes. In IEEE
Symposium on Security and Privacy, Oakland,
California, May 2002.
[2] M. Bishop and M. Dilger. Checking for race conditions
in ﬁle accesses. Computing systems, pages 131–152,
Spring 1996.
[3] H. Chen and D. Wagner. MOPS: an infrastructure for
examining security properties of software. In
Proceedings of the 9th ACM conference on Computer
and communications security, pages 235 – 244. ACM
Press, 2002.
[4] A. Chou. Static Analysis for Bug Finding in Systems
Software. PhD thesis, Stanford University, 2003.
[5] R. DeLine and M. Fahndrich. Enforcing high-level
protocols in low-level software. In Proceedings of the
ACM SIGPLAN 2001 Conference on Programming
Language Design and Implementation, June 2001.
[6] N. Dor, M. Rodeh, and S. Sagiv. Cleanness checking
of string manipulations in C programs via integer
analysis. In 8th International Symposium on Static
Analysis (SAS), pages 194–212, July 2001.
[7] A. Edwards, T. Jaeger, and X. Zhang. Runtime
veriﬁcation of authorization hook placement for the
linux security modules framework. In Proceedings of
the 9th ACM conference on Computer and
communications security, pages 225–234. ACM Press,
2002.
[8] D. Engler, D. Yu Chen, S. Hallem, A. Chou, and
B. Chelf. Bugs as deviant behavior: A general
approach to inferring errors in systems code. In
Proceedings of the Eighteenth ACM Symposium on
Operating Systems Principles, 2001.
[9] D. Evans and D. Larochelle. Improving security using
extensible lightweight static analysis. IEEE Software,
19(1):42–51, January/February 2002.
[10] C. Flanagan and S. N. Freund. Type-based race
detection for Java. In SIGPLAN Conference on
Programming Language Design and Implementation,
pages 219–232, 2000.
[11] C. Flanagan, K. Rustan, and M. Leino. Houdini, an
annotation assistant for ESC/Java. In Symposium of
Formal Methods Europe, pages 500–517, Mar. 2001.
[12] J. Foster, T. Terauchi, and A. Aiken. Flow-sensitive
type qualiﬁers. In Proceedings of the ACM SIGPLAN
2002 Conference on Programming Language Design
and Implementation, June 2002.
[13] D. Freedman, R. Pisani, and R. Purves. Statistics.
W.W. Norton, third edition edition, 1998.
[14] T. Kremenek and D. Engler. Z-ranking: Using
statistical analysis to counter the impact of static
analysis approximations. In 10th Annual International
Static Analysis Symposium, 2003.
[15] D. Larochelle and D. Evans. Statically detecting likely
buﬀer overﬂow vulnerabilities. In USENIX Security
Symposium, Washington, D. C., Aug. 2001.
[16] K. R. M. Leino, G. Nelson, and J. Saxe. ESC/Java
user’s manual. Technical note 2000-002, Compaq
Systems Research Center, Oct. 2001.
[17] A. Myers and B. Liskov. A decentralized model for
information ﬂow control. In Proceedings of the
Sixteenth ACM Symposium on Operating Systems
Principles, pages 129–142, Oct. 1997.
[18] J. Pincus. Personal communication. Developing a
buﬀer overﬂow checker in PREfast (a version of of
PREﬁx)., Oct. 2001.
[19] S. M. Ross. Probability Models. Academic Press,
London, UK, sixth edition, 1997.
[20] J. Viega, J. Bloch, T. Kohno, and G. McGraw. ITS4:
A static vulnerability scanner for C and C++ code. In
Annual Computer Security Applications Conference,
2000.
[21] D. Wagner and D. Dean. Intrusion detection via static
analysis. In IEEE Symposium on Security and
Privacy, 2001.
[22] D. Wagner, J. Foster, E. Brewer, and A. Aiken. A ﬁrst
step towards automated detection of buﬀer overrun
vulnerabilities. In The 2000 Network and Distributed
Systems Security Conference. San Diego, CA, Feb.
2000.
[23] X. Zhang, A. Edwards, and T. Jaeger. Using CQUAL
for static analysis of authorization hook placement. In
Proceedings of the 11th USENIX Security Symposium,
pages 33–48, Aug. 2002.