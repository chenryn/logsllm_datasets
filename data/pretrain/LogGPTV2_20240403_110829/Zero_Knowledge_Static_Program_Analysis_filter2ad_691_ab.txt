program-specific circuit, then applies a circuit-based ZKP backend.
In Section 6.2, we compare the performance of our scheme with the
circuits automatically generated by the scheme in [66] and show
that our design improves the circuit size by around 35–40×.
2 PRELIMINARIES
We use negl(·) : N → N to denote the negligible function, where
for each positive polynomial 𝑓 (·), negl(𝑘) < 1
𝑓 (𝑘) for sufficiently
large integer 𝑘. Let 𝜆 denote the security parameter.
2.1 Zero-knowledge Arguments
A zero knowledge argument scheme is a protocol between a prover
P and a verifier V, where at the end of the protocol, V is con-
vinced by P that the result of a computation 𝐶 on a public input
𝑥 and prover’s secret witness 𝑤 is 𝑦 = 𝐶(𝑥, 𝑤). A zero knowledge
argument has (1) correctness: V always accepts if the result and the
proof are honestly computed by P; (2) soundness: V rejects with all
but negligible probability if the result is not correctly computed; (3)
zero knowledge: the proof leaks no information about the witness
𝑤 beyond the fact the 𝐶(𝑥, 𝑤) = 𝑦. We give the formal definitions
of zero knowledge arguments in Appendix A.
2.2 Instantiating Abstract Interpretation
Abstract Interpretation Fundamentals. When applying Abstract
Interpretation, one begins with a ground-truth semantics for pro-
grams 𝑝, commonly encoded as a partial function S𝑝 ∈ state ⇀
state where 𝜎 ∈ state is some semantic domain for intermediate
execution states. For example, the program 𝑝 could be encoded
as map from program labels to statements, and the state of the
program could include the current program label to execute, as
well as a map from program variables to their current values. This
𝛾
𝛼
transition function S𝑝 can be iterated from an initial configuration
𝜎0 ∈ state to a final state 𝜎𝑛 ∈ S𝑛
𝑝 (𝜎0) (for some number of steps
𝑛), and where 𝜎𝑛 is called final iff S𝑝(𝜎𝑛) is not defined.
From this “ground truth” semantics, a collecting semantics is
derived C𝑝 ∈ ℘(state) → ℘(state) which re-characterizes the
semantics to transform properties (i.e., sets) of states as opposed
to discrete states. This collecting semantics establishes a ground
truth for asking questions like “when given an initial state where
variable 𝑥 is negative, does the program result in a state where 𝑥 is
positive?” The collecting semantics is a specification and in general
is not computable. A program analysis algorithm then inhabits
A𝑝 ∈ state♯ → state♯ for some abstract semantic domain state♯,
and must be shown sound w.r.t. the collecting semantics C𝑝. The full
analysis is computed (naively) as the smallest solution (i.e., the least
fixpoint) to the equation 𝑋 = 𝑋 ⊔ A𝑝(𝑋) ⊔ 𝛼(𝜎0), which soundly
approximates (by construction) any final state so long as A𝑝 is
sound. Although analysis algorithms A𝑝 are typically designed
in an ad-hoc manner, the abstract interpretation framework can
also be used to systematically derive the analysis algorithm itself,
yielding an analyzer which is correct by-construction; this is often
referred to as the calculational method [28].
The analysis algorithm A must operate over an abstract do-
main—often annotated with a “sharp” (♯)—and must form an order-
theoretic lattice in addition to a Galois connection with sets of con-
crete states. Computability of the analysis—i.e., the least fixpoint of
the equation 𝑋 = 𝑋 ⊔ A𝑝(𝑋) ⊔ 𝛼(𝜎0)—is predicated on either the
abstract domain being finite, or the use of a widening operator ∇
to ensure there are no “infinite ascending chains” while computing
the analysis.
In general, a Galois connection between lattices 𝐴—called the
concrete domain—and 𝐵—called the abstract domain—consist of
two mappings 𝛼 ∈ 𝐴 → 𝐵—called the abstraction function—
and 𝛾 ∈ 𝐵 → 𝐴—called the concretization function—such that
𝑥 ⊑𝐴 𝛾(𝑦) ⇐⇒ 𝛼(𝑥) ⊑𝐵 𝑦; Galois connections are notated
𝐴 −−−→←−−−
𝐵. When the context is unambiguous, we omit subscripts
to abstraction and concretization functions 𝛼 and 𝛾, partial order-
ing ⊑, and lattice operations ⊔. The Galois connection for state♯
is then notated ℘(state) −−−−−−→←−−−−−−
state♯, and the correspondence
becomes 𝑅 ⊆ 𝛾(𝑟 ♯) ⇐⇒ 𝛼(𝑅) ⊑ 𝑟 ♯ where 𝑅 ∈ ℘(state),
𝑟 ♯ ∈ state♯, the lattice over the concrete domain is the power-
set lattice, and ⊑ is a custom-defined partial order for the lattice
associated with the abstract domain state♯. Abstract states state♯ of-
ten include an environment env♯ ≜ var → val♯ mapping program
variables to values, and an abstract domain for values val♯ such that
℘(val) −−−−−→←−−−−−
val♯. A program analysis algorithm A is then sound
when any of the following equivalent (under assumption of Galois
connection laws) statements are true: (1): 𝛼(C𝑝(𝛾(𝑟 ♯))) ⊑ A𝑝(𝑟 ♯);
(2): C𝑝(𝛾(𝑟 ♯))) ⊆ 𝛾(A𝑝(𝑟 ♯)); (3): 𝛼(C𝑝(𝑅)) ⊑ A𝑝(𝛼(𝑅); or (4):
C𝑝(𝑅) ⊆ 𝛾(A𝑝(𝛼(𝑅))).
𝛾state
𝛼state
𝛾val
𝛼val
Forming a Galois connection isn’t strictly necessary for soundness—
it merely shows that the abstract domain is “tight”. Calculational
methods make great use of the Galois connection, and completing
a soundness argument using only the 𝛾 side of the connection (the
Session 11B: Zero Knowledge II CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2953second statement above) is commonly referred to as the “𝛾-only”
framework [58].
Soundness means that the behavior of any concrete run of the
program is guaranteed to be approximated by the analysis results.
Verification is achieved when the analysis result does not contain
any unwanted behavior, i.e., if the analysis result does not include,
say, buffer overflows, then we know it is impossible for a buffer
overflow to occur when running the program. However, false posi-
tives are possible: if the analysis result says the result may contain
a buffer overflow, there is a possibility that the program is free of
buffer overflows, but the analysis is not precise enough to detect it.
Our Instantiation of Abstract Interpretation. In this work, we
implement in zero-knowledge the following instantiation of the ab-
stract interpretation framework: a small imperative language with
conditionals and while loops, as well as an extension to the language
which includes toplevel functions; a worklist-based flow-sensitive
analysis algorithm which relies on control flow information; and
instantiations of the worklist-based algorithm for interval analysis,
taint analysis and control flow analysis.
As noted previously, analysis results are naively computed as
the least fixpoint of the equation 𝑋 = 𝑋 ⊔ A𝑝(𝑋) ⊔ 𝛼(𝜎0), using
the abstract transfer function A𝑝, initial state 𝜎0, and abstraction
function 𝛼. There are two practical matters missing from this sim-
ple characterization of computing analysis results. First, there are
several orthogonal notations of “sensitivity” in program analysis,
such as flow sensitivity, object sensitivity, context sensitivity, etc..
Incorporating each of these vectors typically amounts to appropri-
ately altering the definition of state♯ to include extra information,
yielding more precision at the expense of a more computationally
costly analysis. Second, when implemented directly, this computa-
tion is overly naive, e.g., this approach may re-analyze the entire
program multiple times when its only necessary to re-analyze a few
statements. As for the first practical matter, most analyses adopt at
the very least flow sensitivity, as the precision gained vs efficiency
lost is nearly always desirable. As for the second practical matter,
most analyses are split into two phases: (1) compute a control-flow
graph for statements in the program, and (2) using this control-flow
graph, compute the analysis property of interest.
We therefore adopt a flow-sensitive and control-flow worklist-
based algorithm, displayed as Algorithm 1, and which we have
drawn nearly directly from a standard textbook on program analy-
sis design by abstract interpretation [56]. The algorithm operates
conceptually over an abstract domain of states defined state♯ ≜
℘(loc) × (loc → env♯) where abstract environments are defined
env♯ ≜ var → val♯ and for some abstract domain of values
val♯. That is, at any given state of abstract execution, there is a
set of program locations to execute next, and a global matrix of
abstract values for each pair of program location and program
variable. We adopt a set-based notation for the function space
𝑆 = {𝑠𝑙}𝑛
𝑙=1 ∈ loc → env♯, and its applications 𝑠𝑙 ∈ env♯ for
the abstract environment at location 𝑙.
A common optimization is to split this (hypothetical) transfer
function A𝑝 ∈ state♯ → state♯ in two: CFG𝑝 ∈ loc → ℘(loc) as
a statically determined over-approximation of control flows, and
A𝑝,𝑙 ∈ loc×env♯ → env♯ as an update to the abstract environment
(𝑙, 𝑙′) = 𝑊 .𝑝𝑜𝑝()
if A𝑝,𝑙 (𝑠𝑙) /⊑ 𝑠𝑙′ then
𝑠𝑙′ = 𝑠𝑙′ ⊔ A𝑝,𝑙 (𝑠𝑙)
for all 𝑙′′ follows 𝑙′ do
𝑊 .𝑝𝑢𝑠ℎ(𝑙′, 𝑙′′)
𝑙∈𝐿 CFG𝑝(𝑙). The final analysis result {𝑠𝑙}𝑛
𝑙 =𝑙′|𝑙∈CFG𝑝 (𝑙′) A𝑝,𝑙′(𝑠𝑙′); the algorithm we im-
Algorithm 1 Worklist Algorithm
Input: A program 𝑝, control flow graph CFG𝑝, transfer function
A𝑝,𝑙, and lattice val♯.
Output: Abstract environment at each line {𝑠𝑙}𝑛
𝑙=1.
1: Init 𝑠𝑙 (𝑥) := ⊥val♯ for all 𝑙 and 𝑥.
2: Init queue: 𝑊 := {(𝑙, 𝑙′) | 𝑙′ ∈ CFG𝑝(𝑙)}.
3: while 𝑊 ≠ ∅ do
4:
5:
6:
7:
8:
9: return 𝑆 = {𝑠𝑙}𝑛
𝑙=1
env♯ which (abstractly) interprets the program at location 𝑙; in the
analysis algorithm, A𝑝,𝑙 is always applied to the environment 𝑠𝑙.
Note that CFG𝑝 is easily lifted to sets of locations 𝐿 ∈ ℘(loc) via
𝑙=1 is then recursively
specified as 𝑠fin
plement efficiently computes the smallest solution to the set of
recursive equations generated by 𝑠fin
for each program location 𝑙.
𝑙
Concretely, Algorithm 1 takes as input a control flow graph of the
program CFG𝑝 and initializes a control flow queue 𝑊 ∈ ℘(loc×loc)
as 𝑊 = {(𝑙, 𝑙′) | 𝑙′ ∈ CFG𝑝(𝑙)}, i.e., all control flows. The abstract
environment is initialized as 𝑠𝑙 (𝑥) (cid:66) ⊥ for all program variables
𝑥 and for the bottom element of the abstract value lattice ⊥. For a
straightline program, 𝑊 has a simple definition mapping locations
to their successor: 𝑊 (𝑙) ≜ {𝑙 + 1}. For a program with a while loop,
𝑊 will associate the line before the loop to both the first line of
the loop and the first line after the loop, and associate the last line
of the loop with the first line of the loop and the first line after
the loop. For programs with functions, 𝑊 encodes the control flow
graph of function call and return edges.
The algorithm iterates over all control flows using a queue, up-
dating 𝑠𝑙′ to 𝑠𝑙′ ⊔ A𝑝,𝑙 (𝑠𝑙) (line 6); this updates the analysis results
at location 𝑙′ to include new information, e.g., due to a new anal-
ysis result at location 𝑙. If the update leads to a new value for 𝑠𝑙′,
then we must re-analyze all program points which are influenced
by program point 𝑙′, so we add flows (𝑙′, 𝑙′′) to the worklist for
𝑙′′ ∈ CFG𝑝(𝑙′) (lines 5, 7 and 8). When instantiated to abstract
domains with infinite ascending chains (such as interval analysis),
the join operation ⊔ in Algorithm 1 at line 6 is replaced with a
widening operator ∇ which approximates ⊔ while avoiding infinite
ascending chains. In practice, and for interval analysis, this amounts
to approximating ([1, 2] ⊔ [1, 3]) ⊔ [1, 4] = [1, 3] ⊔ [1, 4] = [1, 4]
as ([1, 2] ∇ [1, 3]) ∇ [1, 4] = [1,∞] ∇ [1, 4] = [1,∞], i.e., it forces
early convergence of the upper bound to ∞.
Unique Properties of Abstract Interpretation for ZK. Many
applications of zero-knowledge are able to exploit structural or alge-
braic properties of algorithms to achieve efficiency gains. In general,
such insights arise from the observation that checking 𝑦 = 𝑓 (𝑥)
need not always compute 𝑓 (𝑥), e.g., one can instead check 𝑓 −1(𝑦) ∋
𝑥. The framework of abstract interpretation prescribes an algorith-
mic approach based on computing least fixpoints of recursively de-
fined equations, such as 𝑠fin
𝑙 =𝑙′|𝑙∈CFG𝑝 (𝑙′) A𝑝,𝑙′(𝑠𝑙′) in the case
Session 11B: Zero Knowledge II CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2954of our particular worklist algorithm, or 𝑋 = 𝑋 ⊔ A𝑝(𝑋) ⊔ 𝛼(𝜎0) in
general. Computing the least solution is computationally expensive,
and encoded as an iterative process, starting from the ⊥ element
of the lattice, and applying the equations successively until the
solution stabilizes on a result.
However, checking that a proposed solution is larger or equal to
the least fixpoint is simple and can be computed in one step without
any iteration. This insight applies to zero-knowledge applications of
abstract interpretation where the prover wants to show the absence
of bugs in a secret program: it suffices to present any solution to
the equation (it need not be the smallest) so long as the solution
demonstrates the absence of bugs. The prover will likely discover
this solution through the iterative least fixpoint algorithm, but they
can do this privately and without the use of cryptography.
On the other hand, if the prover wants to show that a program
analysis flags a secret program as potentially having a bug, the en-
tire least fixpoint computation must be executed in zero-knowledge.
That is, to be convinced that the program has a bug, the verifier
must be convinced that the best possible analysis of the program
(i.e., the least fixpoint) is insufficient to verify the absence of bugs.
Because no better solution exist (a property of the least solution),
the verifier knows the prover did not present an unnecessarily