program-specific circuit, then applies a circuit-based ZKP backend.
In Section 6.2, we compare the performance of our scheme with the
circuits automatically generated by the scheme in [66] and show
that our design improves the circuit size by around 35â€“40Ã—.
2 PRELIMINARIES
We use negl(Â·) : N â†’ N to denote the negligible function, where
for each positive polynomial ğ‘“ (Â·), negl(ğ‘˜) < 1
ğ‘“ (ğ‘˜) for sufficiently
large integer ğ‘˜. Let ğœ† denote the security parameter.
2.1 Zero-knowledge Arguments
A zero knowledge argument scheme is a protocol between a prover
P and a verifier V, where at the end of the protocol, V is con-
vinced by P that the result of a computation ğ¶ on a public input
ğ‘¥ and proverâ€™s secret witness ğ‘¤ is ğ‘¦ = ğ¶(ğ‘¥, ğ‘¤). A zero knowledge
argument has (1) correctness: V always accepts if the result and the
proof are honestly computed by P; (2) soundness: V rejects with all
but negligible probability if the result is not correctly computed; (3)
zero knowledge: the proof leaks no information about the witness
ğ‘¤ beyond the fact the ğ¶(ğ‘¥, ğ‘¤) = ğ‘¦. We give the formal definitions
of zero knowledge arguments in Appendix A.
2.2 Instantiating Abstract Interpretation
Abstract Interpretation Fundamentals. When applying Abstract
Interpretation, one begins with a ground-truth semantics for pro-
grams ğ‘, commonly encoded as a partial function Sğ‘ âˆˆ state â‡€
state where ğœ âˆˆ state is some semantic domain for intermediate
execution states. For example, the program ğ‘ could be encoded
as map from program labels to statements, and the state of the
program could include the current program label to execute, as
well as a map from program variables to their current values. This
ğ›¾
ğ›¼
transition function Sğ‘ can be iterated from an initial configuration
ğœ0 âˆˆ state to a final state ğœğ‘› âˆˆ Sğ‘›
ğ‘ (ğœ0) (for some number of steps
ğ‘›), and where ğœğ‘› is called final iff Sğ‘(ğœğ‘›) is not defined.
From this â€œground truthâ€ semantics, a collecting semantics is
derived Cğ‘ âˆˆ â„˜(state) â†’ â„˜(state) which re-characterizes the
semantics to transform properties (i.e., sets) of states as opposed
to discrete states. This collecting semantics establishes a ground
truth for asking questions like â€œwhen given an initial state where
variable ğ‘¥ is negative, does the program result in a state where ğ‘¥ is
positive?â€ The collecting semantics is a specification and in general
is not computable. A program analysis algorithm then inhabits
Ağ‘ âˆˆ stateâ™¯ â†’ stateâ™¯ for some abstract semantic domain stateâ™¯,
and must be shown sound w.r.t. the collecting semantics Cğ‘. The full
analysis is computed (naively) as the smallest solution (i.e., the least
fixpoint) to the equation ğ‘‹ = ğ‘‹ âŠ” Ağ‘(ğ‘‹) âŠ” ğ›¼(ğœ0), which soundly
approximates (by construction) any final state so long as Ağ‘ is
sound. Although analysis algorithms Ağ‘ are typically designed
in an ad-hoc manner, the abstract interpretation framework can
also be used to systematically derive the analysis algorithm itself,
yielding an analyzer which is correct by-construction; this is often
referred to as the calculational method [28].
The analysis algorithm A must operate over an abstract do-
mainâ€”often annotated with a â€œsharpâ€ (â™¯)â€”and must form an order-
theoretic lattice in addition to a Galois connection with sets of con-
crete states. Computability of the analysisâ€”i.e., the least fixpoint of
the equation ğ‘‹ = ğ‘‹ âŠ” Ağ‘(ğ‘‹) âŠ” ğ›¼(ğœ0)â€”is predicated on either the
abstract domain being finite, or the use of a widening operator âˆ‡
to ensure there are no â€œinfinite ascending chainsâ€ while computing
the analysis.
In general, a Galois connection between lattices ğ´â€”called the
concrete domainâ€”and ğµâ€”called the abstract domainâ€”consist of
two mappings ğ›¼ âˆˆ ğ´ â†’ ğµâ€”called the abstraction functionâ€”
and ğ›¾ âˆˆ ğµ â†’ ğ´â€”called the concretization functionâ€”such that
ğ‘¥ âŠ‘ğ´ ğ›¾(ğ‘¦) â‡â‡’ ğ›¼(ğ‘¥) âŠ‘ğµ ğ‘¦; Galois connections are notated
ğ´ âˆ’âˆ’âˆ’â†’â†âˆ’âˆ’âˆ’
ğµ. When the context is unambiguous, we omit subscripts
to abstraction and concretization functions ğ›¼ and ğ›¾, partial order-
ing âŠ‘, and lattice operations âŠ”. The Galois connection for stateâ™¯
is then notated â„˜(state) âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’â†’â†âˆ’âˆ’âˆ’âˆ’âˆ’âˆ’
stateâ™¯, and the correspondence
becomes ğ‘… âŠ† ğ›¾(ğ‘Ÿ â™¯) â‡â‡’ ğ›¼(ğ‘…) âŠ‘ ğ‘Ÿ â™¯ where ğ‘… âˆˆ â„˜(state),
ğ‘Ÿ â™¯ âˆˆ stateâ™¯, the lattice over the concrete domain is the power-
set lattice, and âŠ‘ is a custom-defined partial order for the lattice
associated with the abstract domain stateâ™¯. Abstract states stateâ™¯ of-
ten include an environment envâ™¯ â‰œ var â†’ valâ™¯ mapping program
variables to values, and an abstract domain for values valâ™¯ such that
â„˜(val) âˆ’âˆ’âˆ’âˆ’âˆ’â†’â†âˆ’âˆ’âˆ’âˆ’âˆ’
valâ™¯. A program analysis algorithm A is then sound
when any of the following equivalent (under assumption of Galois
connection laws) statements are true: (1): ğ›¼(Cğ‘(ğ›¾(ğ‘Ÿ â™¯))) âŠ‘ Ağ‘(ğ‘Ÿ â™¯);
(2): Cğ‘(ğ›¾(ğ‘Ÿ â™¯))) âŠ† ğ›¾(Ağ‘(ğ‘Ÿ â™¯)); (3): ğ›¼(Cğ‘(ğ‘…)) âŠ‘ Ağ‘(ğ›¼(ğ‘…); or (4):
Cğ‘(ğ‘…) âŠ† ğ›¾(Ağ‘(ğ›¼(ğ‘…))).
ğ›¾state
ğ›¼state
ğ›¾val
ğ›¼val
Forming a Galois connection isnâ€™t strictly necessary for soundnessâ€”
it merely shows that the abstract domain is â€œtightâ€. Calculational
methods make great use of the Galois connection, and completing
a soundness argument using only the ğ›¾ side of the connection (the
Session 11B: Zero Knowledge II CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea2953second statement above) is commonly referred to as the â€œğ›¾-onlyâ€
framework [58].
Soundness means that the behavior of any concrete run of the
program is guaranteed to be approximated by the analysis results.
Verification is achieved when the analysis result does not contain
any unwanted behavior, i.e., if the analysis result does not include,
say, buffer overflows, then we know it is impossible for a buffer
overflow to occur when running the program. However, false posi-
tives are possible: if the analysis result says the result may contain
a buffer overflow, there is a possibility that the program is free of
buffer overflows, but the analysis is not precise enough to detect it.
Our Instantiation of Abstract Interpretation. In this work, we
implement in zero-knowledge the following instantiation of the ab-
stract interpretation framework: a small imperative language with
conditionals and while loops, as well as an extension to the language
which includes toplevel functions; a worklist-based flow-sensitive
analysis algorithm which relies on control flow information; and
instantiations of the worklist-based algorithm for interval analysis,
taint analysis and control flow analysis.
As noted previously, analysis results are naively computed as
the least fixpoint of the equation ğ‘‹ = ğ‘‹ âŠ” Ağ‘(ğ‘‹) âŠ” ğ›¼(ğœ0), using
the abstract transfer function Ağ‘, initial state ğœ0, and abstraction
function ğ›¼. There are two practical matters missing from this sim-
ple characterization of computing analysis results. First, there are
several orthogonal notations of â€œsensitivityâ€ in program analysis,
such as flow sensitivity, object sensitivity, context sensitivity, etc..
Incorporating each of these vectors typically amounts to appropri-
ately altering the definition of stateâ™¯ to include extra information,
yielding more precision at the expense of a more computationally
costly analysis. Second, when implemented directly, this computa-
tion is overly naive, e.g., this approach may re-analyze the entire
program multiple times when its only necessary to re-analyze a few
statements. As for the first practical matter, most analyses adopt at
the very least flow sensitivity, as the precision gained vs efficiency
lost is nearly always desirable. As for the second practical matter,
most analyses are split into two phases: (1) compute a control-flow
graph for statements in the program, and (2) using this control-flow
graph, compute the analysis property of interest.
We therefore adopt a flow-sensitive and control-flow worklist-
based algorithm, displayed as Algorithm 1, and which we have
drawn nearly directly from a standard textbook on program analy-
sis design by abstract interpretation [56]. The algorithm operates
conceptually over an abstract domain of states defined stateâ™¯ â‰œ
â„˜(loc) Ã— (loc â†’ envâ™¯) where abstract environments are defined
envâ™¯ â‰œ var â†’ valâ™¯ and for some abstract domain of values
valâ™¯. That is, at any given state of abstract execution, there is a
set of program locations to execute next, and a global matrix of
abstract values for each pair of program location and program
variable. We adopt a set-based notation for the function space
ğ‘† = {ğ‘ ğ‘™}ğ‘›
ğ‘™=1 âˆˆ loc â†’ envâ™¯, and its applications ğ‘ ğ‘™ âˆˆ envâ™¯ for
the abstract environment at location ğ‘™.
A common optimization is to split this (hypothetical) transfer
function Ağ‘ âˆˆ stateâ™¯ â†’ stateâ™¯ in two: CFGğ‘ âˆˆ loc â†’ â„˜(loc) as
a statically determined over-approximation of control flows, and
Ağ‘,ğ‘™ âˆˆ locÃ—envâ™¯ â†’ envâ™¯ as an update to the abstract environment
(ğ‘™, ğ‘™â€²) = ğ‘Š .ğ‘ğ‘œğ‘()
if Ağ‘,ğ‘™ (ğ‘ ğ‘™) /âŠ‘ ğ‘ ğ‘™â€² then
ğ‘ ğ‘™â€² = ğ‘ ğ‘™â€² âŠ” Ağ‘,ğ‘™ (ğ‘ ğ‘™)
for all ğ‘™â€²â€² follows ğ‘™â€² do
ğ‘Š .ğ‘ğ‘¢ğ‘ â„(ğ‘™â€², ğ‘™â€²â€²)
ğ‘™âˆˆğ¿ CFGğ‘(ğ‘™). The final analysis result {ğ‘ ğ‘™}ğ‘›
ğ‘™ =ğ‘™â€²|ğ‘™âˆˆCFGğ‘ (ğ‘™â€²) Ağ‘,ğ‘™â€²(ğ‘ ğ‘™â€²); the algorithm we im-
Algorithm 1 Worklist Algorithm
Input: A program ğ‘, control flow graph CFGğ‘, transfer function
Ağ‘,ğ‘™, and lattice valâ™¯.
Output: Abstract environment at each line {ğ‘ ğ‘™}ğ‘›
ğ‘™=1.
1: Init ğ‘ ğ‘™ (ğ‘¥) := âŠ¥valâ™¯ for all ğ‘™ and ğ‘¥.
2: Init queue: ğ‘Š := {(ğ‘™, ğ‘™â€²) | ğ‘™â€² âˆˆ CFGğ‘(ğ‘™)}.
3: while ğ‘Š â‰  âˆ… do
4:
5:
6:
7:
8:
9: return ğ‘† = {ğ‘ ğ‘™}ğ‘›
ğ‘™=1
envâ™¯ which (abstractly) interprets the program at location ğ‘™; in the
analysis algorithm, Ağ‘,ğ‘™ is always applied to the environment ğ‘ ğ‘™.
Note that CFGğ‘ is easily lifted to sets of locations ğ¿ âˆˆ â„˜(loc) via
ğ‘™=1 is then recursively
specified as ğ‘ fin
plement efficiently computes the smallest solution to the set of
recursive equations generated by ğ‘ fin
for each program location ğ‘™.
ğ‘™
Concretely, Algorithm 1 takes as input a control flow graph of the
program CFGğ‘ and initializes a control flow queue ğ‘Š âˆˆ â„˜(locÃ—loc)
as ğ‘Š = {(ğ‘™, ğ‘™â€²) | ğ‘™â€² âˆˆ CFGğ‘(ğ‘™)}, i.e., all control flows. The abstract
environment is initialized as ğ‘ ğ‘™ (ğ‘¥) (cid:66) âŠ¥ for all program variables
ğ‘¥ and for the bottom element of the abstract value lattice âŠ¥. For a
straightline program, ğ‘Š has a simple definition mapping locations
to their successor: ğ‘Š (ğ‘™) â‰œ {ğ‘™ + 1}. For a program with a while loop,
ğ‘Š will associate the line before the loop to both the first line of
the loop and the first line after the loop, and associate the last line
of the loop with the first line of the loop and the first line after
the loop. For programs with functions, ğ‘Š encodes the control flow
graph of function call and return edges.
The algorithm iterates over all control flows using a queue, up-
dating ğ‘ ğ‘™â€² to ğ‘ ğ‘™â€² âŠ” Ağ‘,ğ‘™ (ğ‘ ğ‘™) (line 6); this updates the analysis results
at location ğ‘™â€² to include new information, e.g., due to a new anal-
ysis result at location ğ‘™. If the update leads to a new value for ğ‘ ğ‘™â€²,
then we must re-analyze all program points which are influenced
by program point ğ‘™â€², so we add flows (ğ‘™â€², ğ‘™â€²â€²) to the worklist for
ğ‘™â€²â€² âˆˆ CFGğ‘(ğ‘™â€²) (lines 5, 7 and 8). When instantiated to abstract
domains with infinite ascending chains (such as interval analysis),
the join operation âŠ” in Algorithm 1 at line 6 is replaced with a
widening operator âˆ‡ which approximates âŠ” while avoiding infinite
ascending chains. In practice, and for interval analysis, this amounts
to approximating ([1, 2] âŠ” [1, 3]) âŠ” [1, 4] = [1, 3] âŠ” [1, 4] = [1, 4]
as ([1, 2] âˆ‡ [1, 3]) âˆ‡ [1, 4] = [1,âˆ] âˆ‡ [1, 4] = [1,âˆ], i.e., it forces
early convergence of the upper bound to âˆ.
Unique Properties of Abstract Interpretation for ZK. Many
applications of zero-knowledge are able to exploit structural or alge-
braic properties of algorithms to achieve efficiency gains. In general,
such insights arise from the observation that checking ğ‘¦ = ğ‘“ (ğ‘¥)
need not always compute ğ‘“ (ğ‘¥), e.g., one can instead check ğ‘“ âˆ’1(ğ‘¦) âˆ‹
ğ‘¥. The framework of abstract interpretation prescribes an algorith-
mic approach based on computing least fixpoints of recursively de-
fined equations, such as ğ‘ fin
ğ‘™ =ğ‘™â€²|ğ‘™âˆˆCFGğ‘ (ğ‘™â€²) Ağ‘,ğ‘™â€²(ğ‘ ğ‘™â€²) in the case
Session 11B: Zero Knowledge II CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea2954of our particular worklist algorithm, or ğ‘‹ = ğ‘‹ âŠ” Ağ‘(ğ‘‹) âŠ” ğ›¼(ğœ0) in
general. Computing the least solution is computationally expensive,
and encoded as an iterative process, starting from the âŠ¥ element
of the lattice, and applying the equations successively until the
solution stabilizes on a result.
However, checking that a proposed solution is larger or equal to
the least fixpoint is simple and can be computed in one step without
any iteration. This insight applies to zero-knowledge applications of
abstract interpretation where the prover wants to show the absence
of bugs in a secret program: it suffices to present any solution to
the equation (it need not be the smallest) so long as the solution
demonstrates the absence of bugs. The prover will likely discover
this solution through the iterative least fixpoint algorithm, but they
can do this privately and without the use of cryptography.
On the other hand, if the prover wants to show that a program
analysis flags a secret program as potentially having a bug, the en-
tire least fixpoint computation must be executed in zero-knowledge.
That is, to be convinced that the program has a bug, the verifier
must be convinced that the best possible analysis of the program
(i.e., the least fixpoint) is insufficient to verify the absence of bugs.
Because no better solution exist (a property of the least solution),
the verifier knows the prover did not present an unnecessarily