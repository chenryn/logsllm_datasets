整个过程中.frm 和.ibd 文件没有任何大小的变化。
Records:0Duplicates:0
Query OK，
Records:0Duplicates:0
这个过程中，DML 依旧是畅通的。
alter table newtest add index (client_ip) ,algorithm=inplace;
（2）inplace 选项
这个过程可以看到效果和启用copy算法是一样的，为什么呢。因为添加字段，删除
而如果此时删除索引，这个过程就如同飞一般的感觉，不到一秒即可完成
相比而言，整个添加过程的持续时间要短很多，大概是3分钟。
insert into newtest(game_type,login_time,login_account,cn_master,
接下来就是添加/删除索引；
values(l,
我们可以看到 DML 操作依然畅通无阻。
Query
-rw-r-
alter table newtest add index (client_ip) ,algorithm=inplace;
OK，
OK，
'2017-02-27
1 row affected (0.04 sec)
 1 mysql mysql
1 mysql mysql
1 mysql mysql
Duplicates:0
1 4018143232 Feb 27 23:06 newtest.ibd
我们添加索引，启用 inplace 算法。
affected
Warnings: 0
3
，'150581500032′，572031626′,183.128.143.113);
min
8840 Feb 27 23:06 #sql-6273_2980ab.frm
8840 Feb 27 22:49 newtest.frm
8840 Feb 27 23:13 newtest.frm
Warnings:
(29
sec)
,algorithm=copy;
0
---
## Page 203
pt_osc -p xxxx -P3306
和print组合来得到执行的一些细节信息。
否则我们使用 pt-osc 时就仅是一个执行者而已，
一些准备和同步工作能够离线进行，而正式的切换是一个最小粒度的 rename 操作。
做 DDL操作真是一种煎熬，我们也基本理解这是一种以空间换时间的策略，尽可能保证
的，Percona-toolkit是一把“瑞士军刀”，功能丰富而且实用，如下图 5-5所示。
5.1.4
，但是这样一个很柔性的操作，其实有一些问题还需要我们更深层次地分析和理解，
CREATE TABLE
Starting a dry run.
Operation, tries, wait:
[root@localhost bin]#
alter table newtest add index idx_newtest_name(name),
比如有一个表 newtest，我们需要给它加上一个索引，可以使用 pt-osc 的 dry-run 选项
我们来分析一下 pt-osc 这个工具的实现原理。想想一个数据量有些大的表，在上面
Percona 的 pt-osc 工具算是 DBA 的一个福利工具，是隶属于 Percona-Tookit 工具集
使用 pt-online-schema-change，命令如下：
DDL语句类似如下这样：
案例5-5：源码分析 pt-osc 的实现原理
swap_tables, 10,
id
analyze
ceate
pt-osc 的原理和实现
int(11)
pt-table-sync
pt-table-checksum
pt-slave
· pt-index-usage
triggers,
复制
性能
10,0.25
NOT
keys,
10，
10,
NULL,
一
10
·pt-stalk
newtest_new`
test`
pt-config-diff
./pt-online-schema-change
系统
配置
一
newtest`will not be altered.
图5-5
：还没有掌握这种思路的核心。
t-mext
实用
监控
-digest
D=test,t=newtest
name（name)
--host=127.0.0.1-u
upgr
shov
第5章MySQL运维管理实践丨181
Specify
---
## Page 204
182丨MySQL DBA工作笔记：数据库管理、架构优化与运维开发
请求进来，就会是一个 replace into 实现的类似 update 的过程。
有 insert 请求进来，那么 replace into 就类似于 insert，如果复制流程已经完成，那么 insert
的 DML 操作不应该被阻塞，我们打开代码逐个来分析一下。
因为新表的数据复制是一个离线的过程，而要实现在线修改，我们的目标是操作过程中
什么瓶颈？带着这个问题我们来逐个分析一下。
的细节来看看触发器的方式是否可行。
是显然上面的信息是很粗略的，而且有些信息是经不起推敲的。我们需要了解更深层次
然后新的DDL变更部署在这个上面，因为这个时候表里还没有数据，所以这个过程很快。
SELECT
newtest_old，同时把_newtest_new修改为 newtest。
_newtest_new select *from newtest 这种形式。
首先创建的三个触发器（delete、insert、update）是怎么把增量数据写入到新表中的。
先来看一下 insertrigger，整个过程的思路就是 replace into，如果在数据复制期间,
如果用触发器的方式可以直接变更，那么我们直接手工触发整个变更是否可行，有
数据复制完成之后，开启rename 模式，这个过程会把表 newtest 改名为一个别名
接下来会在原表上添加三个触发器，然后开始数据的复制，基本原理就是inser into
这个过程我相信做过 pt-osc 的同学，简单看下日志也能够明白这个原理和过程，但
最后清理战场，删除原来的旧表和原来的触发器。
Dry run complete.
2018-06-24T23:30:52 Dropped new table OK.
DROP
2018-06-24T23:30:52 Dropping
DROP TRIGGER
DROP TRIGGER
Not
Not
INSERT
DROP
台
Not
Not creating triggers because
ALTER TABLE
Created new table
my $insert_trigger
ENGINE=InnoDB DEFAULT CHARSET=latinl
十
tered
dropping
swapping
droppir
id`，
TRIGGER
"REPLACE INTO
"FOR EACH ROW
"CREATETRIGGER
test
name
PRIORITY
I tables because this is a dry run.
EXISTS
triggers
test`
EXISTS
EXISTS
EXISTS
FROM
id
newtest
because
O $new_tbl->{name} ($qcols) VALUEs ($new_vals)";
test
because
IGNORE
"${prefix)_ins^ AFTER INSERT ON $orig_tbl->(name) "
test
`test
test
test
test
this
new
newtest
new
this is
newtest
this is a dry run.
`pt_osc_test_newtest_del`
is a dryrun.
ot
pt
this
OSC
OSC
`test
was not altered.
isa
cest
dry
schema-
newtest
 idx_newtest_name (name)
run.
run.
upd
(id
/*pt-online-
"name
---
## Page 205
比如对于外键，或者是表中的约束的信息等。
制中增量 DML 的replace into 处理很巧妙，加上数据的粒度拆分，让这个事情变得可控可用。
后逐个击破。这样一来数据做了切分，粒度小了，阻塞的影响也会大大降低。
显然也不合理，所以这里做到了小步快走的方式，把一个表的数据拆分成多份，也叫chunk，然
这个操作的代价就很高了。如果存在1000万条数据，整个阻塞的过程会把这个时间无限拉长，
的方式，基本能够杜绝潜在的性能问题。
一个 delete 操作能够避免这种尴尬的数据冲突出现。
后表里就会生成两条记录，显然这是不合理的（实际上确实不可行)，所以我们需要保证
需要注意的一点是，复制还没有完成的时候，处理update 请求，我们直接 insert，那么稍
。所以 pt-osc 工具实现了一个切分的思路，这个是原本的触发器不可替代的。整个数据的复
一个 replace into 的 insert 操作；如果复制已经完成，那么就会是一个update 操作。这里
No slaves found. See --recursion-method if host localhost.localdomain has slaves.
当然实际的 pt-osc 工具的逻辑远比上面所讲要复杂，里面考虑了很多额外的因素，
CREATE TABLE
Creating new
Altering
Operation,tries, wait:
[root@localhostbin]#
最后来一个基本完整的变更日志。
如此看来，触发器的过程是由一系列隐式的操作组成，但是实际上在这个表很大的情况下，
my $delete_trigger
然后就是 delete 操作，这个过程相比前面的过程会略微简单一些,使用了 delete ignore
而 update trigger 的作用和上面的类似，如果数据复制还没有完成，那么也会转换为
dorp
Cr
my Supdate_trigger
reate
"CREATE TRIGGER $(prefix)_del` AFTER DELETE ON Sorig_tbl->(name) "
"DELETE IGNORE FROM Snew_tbl->{name) WHERE !(Supd_index_cols) AND
"BEGIN
10,0.25
test`
TRIGGER
10,
_newtest_new`
10，
${prefix}_upd` AFTER UPDATE ON $orig_tbl->{name} "
1
./pt-online-schema-change
1
--host=127.0.0.1
第5章MySQL运维管理实践丨183
e（name）
-execute
-print
-lac
-u
---
## Page 206
184
4MySQL DBA工作笔记：数据库管理、架构优化与运维开发
影响，单说这个需求，
SQL语句：
TO
4424
select count(id) from tgp_db.tgp_track_log
简单验证了下，数据量确实在亿级别。
DROP TABLE IF
test
RENAME TABLE
看自增列的情况，
CREATE TABLE
delete from test_track_log
有一天中午接到一位开发同学的数据操作需求，
Successfully altered^test`
DROP TRIGGER
2018-06-24T23:35:54
INSERT LOW
2018-06-24T23:35:54
带着疑问我看下了表结构，如下：
看需求描述是因为查询统计较差，
Altered
Altering new table..
案例5-6：平滑删除数据的小技巧
copy table*
KEY
PRIMARY KEY (`id`),
`uid`
ROP
PRIMARYKEY(id)
name
"id`int(1l) NOT NULL,
name
TRIGGER
TRIGGER
idx_uid_fsm
int(11)
`newtest
FROM
varchar(30)
PRIORITY
test
table
test track log
EXISTS
test
test
，你会发现这是一个“陨石坑”。
这个表的数据量有近1亿条记录了，暂且不说数据量带来的额外
EXISTS
EXISTS
`newtest`
test.
log`
4 Swapped original
Copied rows
newtest
Copying
Created
DEFAULT NULL,
test`
._newtest_new
"test`
test
INTO