title:Using Reflexive Eye Movements for Fast Challenge-Response Authentication
author:Ivo Sluganovic and
Marc Roeschlin and
Kasper Bonne Rasmussen and
Ivan Martinovic
Using Reﬂexive Eye Movements for Fast
Challenge-Response Authentication
Ivo Sluganovic, Marc Roeschlin, Kasper B. Rasmussen, Ivan Martinovic
Department of Computer Science, University of Oxford
ﬁPI:EMAIL
ABSTRACT
Eye tracking devices have recently become increasingly pop-
ular as an interface between people and consumer-grade elec-
tronic devices. Due to the fact that human eyes are fast, re-
sponsive, and carry information unique to an individual, an-
alyzing person’s gaze is particularly attractive for eﬀortless
biometric authentication. Unfortunately, previous propos-
als for gaze-based authentication systems either suﬀer from
high error rates, or require long authentication times.
We build upon the fact that some eye movements can be
reﬂexively and predictably triggered, and develop an interac-
tive visual stimulus for elicitation of reﬂexive eye movements
that supports the extraction of reliable biometric features in
a matter of seconds, without requiring any memorization or
cognitive eﬀort on the part of the user. As an important ben-
eﬁt, our stimulus can be made unique for every authentica-
tion attempt and thus incorporated in a challenge-response
biometric authentication system. This allows us to prevent
replay attacks, which are possibly the most applicable attack
vectors against biometric authentication.
Using a gaze tracking device, we build a prototype of our
system and perform a series of systematic user experiments
with 30 participants from the general public. We investigate
the performance and security guarantees under several dif-
ferent attack scenarios and show that our system surpasses
existing gaze-based authentication methods both in achieved
equal error rates (6.3%) and signiﬁcantly lower authentica-
tion times (5 seconds).
1.
INTRODUCTION
Eye tracking devices capture precise position and move-
ment of the human cornea on a millisecond scale. This in
turn allows determining tzhe exact location of one’s gaze on
a screen or on surrounding objects. Since analyzing eye be-
havior can give insight into our internal cognitive processes
and even predict conditions such as autism [24], eye track-
ers have been used in neurophysiological research for over
a century, but until recently their use in everyday life was
limited due to prohibitive equipment costs.
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
CCS’16 October 24-28, 2016, Vienna, Austria
c(cid:13) 2016 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-4139-4/16/10.
DOI: http://dx.doi.org/10.1145/2976749.2978311
However, the speed and responsiveness of eye movements
strongly motivate their use as an attractive input channel for
human-computer interaction; as a result, recent years have
brought a sharp reduction in retail prices of eye tracking de-
vices. While dedicated trackers can be purchased for as little
as $100 [1], eye tracking capabilities are also being added to
consumer products such as laptops [23], cars [34], tablets,
and mobile phones [32]. Given the diverse advantages and
applications of eye tracking, its widespread expansion into
our everyday lives is only likely to continue.
As we demonstrate in the following sections, tracking a
user’s gaze is particularly suitable for fast and low-eﬀort
user authentication, especially in scenarios where keyboard
input is not available. Eye movements exhibit traits dis-
tinctive enough that classiﬁcation algorithms (e.g., [13]) can
reliably discern among a large group of individuals. How-
ever, despite the advantages, exploiting eye movements for
user authentication remains a challenging topic. As we sum-
marize in Section 8, previous work on gaze-based authenti-
cation achieves either high error rates (e.g., EER above 15%)
or long authentication times (e.g., above 20 seconds). One
likely explanation for some of these outcomes are overly com-
plex visual stimuli that result in voluntarily triggered eye
movements which are highly dependent on a user’s current
cognitive state.
In this paper, we show how the reﬂexive physiological be-
havior of human eyes can be used to build fast and reli-
able biometric authentication systems. We utilize the fact
that, even though most eye movements are elicited volun-
tarily, speciﬁc reﬂexive movements can be actively triggered
using a simple visual stimulus. Measuring and analyzing
millisecond-scale characteristics of reﬂexive eye movements
provides several important beneﬁts. Users’ eyes naturally
and spontaneously react to the shown stimulus so they do
not need to follow any instructions or memorize additional
information. As a result, elicitation of reﬂexive behavior
requires lower cognitive load and is very fast. This in turn
enables keeping authentication times short while at the same
time extracting large amounts of useful biometric data and
achieving low error rates.
Finally, we show a crucial advantage of exploiting re-
ﬂexive eye movements for authentication: by employing a
challenge-response type of protocol, such systems can pro-
vide security even under a stronger adversary model than
is usually considered for biometrics. One of the obstacles
for widespread use of biometric authentication in our daily
lives is the fact that most biometrics can be captured and
replayed relatively easily. Examples include spooﬁng image
recognition systems with photographs from social media and
spooﬁng ﬁngerprint recognition using copies of ﬁngerprints
left behind on everyday items.
If the visual stimulus can
be made unique for each authentication attempt, then the
elicited responses will accordingly be diﬀerent, but still in-
clude user-speciﬁc characteristics. By always choosing a new
challenge (randomly generated stimulus) and verifying if the
response (measured eye movements) corresponds to it, our
authentication system can assert that the biometric sample
is indeed fresh. Other biometric systems have to make spe-
cial provisions to achieve a level of spooﬁng and replay pro-
tection. For example, sophisticated ﬁngerprint readers mea-
sure additional attributes like temperature and moisture in
order to determine liveness. Our gaze-based authentication
system obtains these guarantees practically for free, without
requiring any other information besides the recording of a
user’s eye movements.
2. BACKGROUND ON EYE MOVEMENTS
We start with a short background of the human visual sys-
tem and necessary eye movements terminology; this allows
us to introduce main concepts that motivate our research
and guide the design of the system in the following sections.
Even when one’s gaze is ﬁrmly ﬁxated on a single stimulus,
human eyes are never completely still. They are constantly
making hundreds of micro movements per second, which are
interlaced with more than 100,000 larger movements dur-
ing the course of one day [2]. During visual tasks, such as
search or scene perception, our eyes alternate between ﬁx-
ations and saccades. Fixations are used to maintain the
visual focus on a single stimulus, while saccades reorient
the eye to focus the gaze on a next desired position. Sac-
cades are rapid eye movements and they are considered to
be the fastest rotational movement of any external part of
our body, reaching angular velocities of up to 900 degrees
per second, and usually lasting between 20 ms and 100 ms.
In Figure 1, ﬁxations can be seen as areas of large numbers
of closely grouped points, while saccades consist of series of
more spread recordings that depict fairly straight paths.
When a salient change happens in our ﬁeld of vision, our
eyes naturally reorient on the target, since this is a neces-
sary ﬁrst step to provide information for further higher-level
cognitive processes [30]. These externally elicited saccades
happen reﬂexively and are considered to be an eﬀortless neu-
ronal response, requiring very low cognitive load from the
user. After the stimulus onset, a corresponding reﬂexive
saccade is initiated rapidly, with usual latencies of less than
250 ms.
In contrast, voluntary saccadic movements have
larger mean latencies (above 300 ms) which are additionally
inﬂuenced by diﬀerent internal and external factors [41].
The analysis of eye movements has been part of medi-
cal research for more than a century since it oﬀers valu-
able information of our cognitive and visual processing [30,
9, 3]. Keeping the goal of reliable biometric authentica-
tion in mind, we are interested in extracting and combining
multiple characteristics of human eye movements for which
there exists supporting research that they oﬀer stable indi-
vidual diﬀerences between users. For example, Castelhano
et al. [8] examine stable individual diﬀerences in characteris-
tics of both saccades and ﬁxations and provides support for
their stable use in biometric authentication. Saccades were
also used in [13] to enable stable authentication and iden-
tiﬁcation. Furthermore, several researchers have analyzed
Figure 1: Eye movements of four diﬀerent users as a response
to the same visual stimulus. Fixations are visible as clus-
tered areas, while saccades consist of series of dots that de-
pict paths. Larger red dots represent the positions at which
the visual stimulus was shown. Despite their distinct char-
acteristics, all four gaze paths closely match the positions of
the stimulus.
eye behavior features of trained shooters [12], professional
baseball players [4] and other speciﬁc groups of individu-
als [15], and reported measurable diﬀerences between their
eye movements characteristics.
Given that reﬂexive reactions are less dependent on mo-
mentary conscious states of an individual than conscious ac-
tions, it is expected that biometrics based on reﬂexive char-
acteristics oﬀer more stable authentication. Furthermore,
taking into account the advantage in faster elicitation times,
the goal of our research is to design a stimulus that supports
the use of reﬂexive saccades for biometric authentication.
For example, prior research has shown that saccade laten-
cies depend on the dominant eye [31, 26] of the individual,
which is a stable characteristic and provides strong motiva-
tion for using saccade latencies for classiﬁcation. Finally, it
was shown that saccade latency varies if anticipation (tem-
poral expectancy) is present [40]. This provides an argument
for randomizing the stimulus that is shown to users.
3. ASSUMPTIONS AND GOALS
We start by deﬁning the system and adversary model used
throughout this paper; we then state the design goals for the
visual stimulus and the authentication system.
System Model. We assume the general settings of a user
authenticating to a workstation in an oﬃce scenario through-
out the course of a normal work day. A simple visualization
of the system model is shown in Figure 2. The user au-
thenticates to a workstation using a gaze tracking device
throughout the course of a workday. The workstation uses
data acquired by the gaze tracker and a user’s biometric
template to make the authentication decision.
A legitimate user is one who is enrolled with the authen-
cherjanelua●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●toni●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●ﬁxationsaccadesingle gazemeasurement1234567123567412345671235674replay attacks is one of the major strengths of our scheme
since simply replaying an acquired sample is arguably the
most accessible attack vector for most biometrics.
We do not consider a targeted adversary who is able to
model and generate arbitrary artiﬁcial samples of a user’s
eye movements in an interactive manner. As we further
discuss in Section 9, such attacks require signiﬁcantly higher
levels of complexity and eﬀort from the adversary; a level of
commitment against which most biometric systems can not
provide security guarantees.
Design Goals.
• Low cognitive load: The system should pose low cogni-
tive load on the users. Ideally, users should not be re-
quired to remember credentials, carry tokens, or learn
new procedures. Moreover, the cooperation required
from the user should be as eﬀortless as possible.
• Fast: The duration of a single authentication attempt
should be as short as possible.
• Resistance against replay: The system should make it