### Simulated Lower Bounds and Their Variance

To gain insights into the variance of the lower bound (LB), we simulate multiple lower bounds instead of a single one. The dashed vertical lines, which are color-coded to match the corresponding cumulative distribution functions (CDFs), indicate the targeted privacy parameters \(\varepsilon_0\). The horizontal, red line represents the prescribed confidence level \(1 - \alpha\), where \(\alpha = 0.05\).

### Empirical CDFs for Correct Algorithms

For the correct algorithms (a) through (f), an important feature of the empirical CDFs is their location. When evaluated at the targeted privacy parameter \(\varepsilon_0 = \varepsilon\), the CDF describes the confidence level \(P(LB \leq \varepsilon)\). According to our theoretical framework, this should be approximately equal to \(1 - \alpha\) (see Theorem 2). Therefore, we expect the empirical CDFs to intersect the horizontal confidence level line and the vertical targeted privacy level line. In most scenarios, the prescribed confidence level is well approximated, although sometimes it is slightly too large, corresponding to smaller values of LB.

This tendency is inherent in the empirical study of differential privacy (DP). To approximate \(\varepsilon\), one must first select the appropriate data pair from \(B\) pairs and then empirically maximize the privacy loss. Poor performance in either step can bias estimates towards smaller values, a trend observed in other empirical studies (e.g., [19], where p-values are consistently higher than the prescribed level).

### Ascent of the CDF Near \(\varepsilon\)

Another performance measure for our correct algorithms is the rate of increase of the CDF near \(\varepsilon\). In most of our simulations (a) through (f), we observe a rapid increase close to \(\varepsilon\), suggesting that LB is a tight and reliable bound for \(\varepsilon\). For SVT2 and SVT4, the ascent is slightly slower in the high privacy regime (\(\varepsilon_0 = 0.2\)), indicating higher variance in LB due to smaller values of the discrete densities.

### Empirical CDFs for Incorrect Algorithms

For the incorrect algorithms (g) and (h), the most conclusive information on the performance of the maximum privacy loss (MPL) is provided by the location of the empirical CDFs. Specifically, if the lower bound LB is to the right of the targeted privacy parameter \(\varepsilon_0\), it exposes a false privacy claim. We observe that LB is usually sampled to the right of \(\varepsilon_0\) (with almost certainty for (g) and in the middle and low privacy regimes for (h)), often with a significant margin. In the high privacy regime for (h), we sometimes observe \(LB \leq \varepsilon_0\) due to increased variance. These experiments confirm the performance of MPL in detecting flawed algorithms.

### Sample Sizes and Runtime

After considering the statistical results, we briefly discuss computational aspects. Our MPL algorithm relies on standard statistical tools available in many programming languages, such as R, making it convenient to implement. We ran our simulations on a standard desktop computer (3.4 GHz Intel Core i5 CPU, 4 cores, 16 GB RAM). Runtimes range from 10 seconds for smaller sample sizes (algorithms (a)-(d)) to less than one minute for larger sample sizes (algorithms (e)-(h)). The precise runtimes are reported in Table II and are shorter than those given in [21], which also analyzes the above algorithms (except for the exponential mechanism) using a much more powerful machine (128 cores at 1.2 GHz and 500 GB RAM).

Our gains in runtime are mainly achieved by reducing sampling efforts. For example, with \(B = 10\) pairs of neighboring databases as input, the total sampling effort for one run of MPL is \(5 \times 10^5\) for smaller samples (algorithms (a)-(d)) and \(3 \times 10^6\) for larger ones (algorithms (e)-(h)). This corresponds to approximately 0.05% and 0.32% of the sample sizes used by the DD-Search algorithm in [21], meaning we rely on only a small fraction of the data used in [21].

### Runtimes for Different Algorithms

| Algorithm | Laplace (a) | Noisy Max (b) | Continuous Noisy Max (c) | Exponential (d) |
|-----------|-------------|---------------|--------------------------|-----------------|
| Runtime   | 10.9 s      | 4.7 s         | 10.5 s                   | 11.3 s          |

| Algorithm | SVT 2 (e) | SVT 4 (f) | SVT 5 (g) | SVT 6 (h) |
|-----------|------------|------------|------------|------------|
| Runtime   | 23.8 s     | 26.6 s     |            |            |

These results demonstrate the efficiency and effectiveness of our MPL algorithm in both statistical accuracy and computational performance.