I recently developed a Python script that utilizes BeautifulSoup to scrape information from a website. The script works perfectly when executed from the command line. However, when I run it as a cron job, the server returns the following error:

```
Traceback (most recent call last):
  File "/home/ws/undwv/mindfactory.py", line 7, in <module>
    from bs4 import BeautifulSoup
ImportError: No module named bs4
```

Since I don't have root access to the server, I installed BeautifulSoup in the user directory: `$HOME/local/lib/python2.7/site-packages`. I suspect that the cron job is not looking for modules in this directory. Do you have any suggestions on how to resolve this issue?

---

**Response:**

When you install packages using `pip install --user`, they are typically placed in `~/.local/lib/pythonX.Y/site-packages` and should be automatically available to the corresponding user. However, if your installation path is different, you can configure the `PYTHONPATH` environment variable in the crontab to include the custom directory.

Hereâ€™s how you can do it:

1. **Edit the Crontab:**
   Open your crontab file for editing:
   ```sh
   crontab -e
   ```

2. **Set the PYTHONPATH:**
   Add the following line at the top of your crontab file to set the `PYTHONPATH`:
   ```sh
   PYTHONPATH=$PYTHONPATH:$HOME/local/lib/python2.7/site-packages
   ```

3. **Add Your Cron Job:**
   Below the `PYTHONPATH` line, add your cron job. For example:
   ```sh
   * * * * * /usr/bin/python /home/ws/undwv/mindfactory.py
   ```

This will ensure that the `PYTHONPATH` includes the directory where BeautifulSoup is installed, allowing the cron job to find and import the module correctly.

**Note:** Avoid modifying `sys.path` directly within your script, as it can lead to unexpected behavior. Setting the `PYTHONPATH` in the crontab is the recommended approach.