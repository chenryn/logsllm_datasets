Remark. Note that validating an F (cid:63)
CR transaction also requires ver-
iﬁcation of the designated sender’s and receiver’s signatures. Our
justiﬁcation for not accounting for this in the F (cid:63)
CR-validation com-
plexity as deﬁned above is that such veriﬁcations are required even
for standard transactions between two parties.
Incentivizing public veriﬁable computation. A natural approach
to minimize the validation complexity would be to use a public
veriﬁable computation scheme pubVC.
Indeed we show how to
compile an arbitrary public veriﬁable computation scheme into an
incentivizable veriﬁable computation scheme. Perhaps the main
difﬁculty in constructing such a compiler is the need to handle ma-
licious clients in our setting. Note in contrast that in the standard
setting of veriﬁable computation, the client is always assumed to
be honest and security is required only against malicious server.
To see why it is important to safeguard against a malicious client
let us take a look at a naïve scheme based on any public veriﬁable
computation scheme pubVC.
Naïve scheme based on pubVC. D runs KeyGen(f, 1λ) to gen-
erate (ekf , vkf ), and then sends ekf , u to W , and then creates
an F (cid:63)
CR transaction that allows W to claim its coins(q) if it re-
veals (y, ψy) such that Verify(vkf , u, (y, ψy)) = 1. (More con-
cretely, φ(w; (vkf , u)) = 1 iff 1 = Verify(vkf , u, w).) W runs
Compute(ekf , u) to obtain (y, ψy) and claims coins(q) by provid-
ing w = (y, ψy) to F (cid:63)
CR.
The main problem with the above solution is that a malicious D
may not generate the veriﬁcation key honestly, and thus an honest
worker that computes y ← f (u) is not guaranteed payment. Note
however that in such a situation we may ask W to reveal y to D
only if w = (y, ψy) is such that φ(w) = 1 for the φ obtained from
F (cid:63)
CR. Still the above solution is undesirable since a honest worker
does perform the required the computation yet does not get paid by
the delegator. This motivates the following condition:
• (Guaranteed pay on honest computation.) W obtains coins(q)
from D if W followed the protocol honestly.
Note that standard secure computation protocol to jointly emu-
late KeyGen algorithm such that both D and W obtain (ekf , vkf )
at the end of the protocol sufﬁces to satisfy the condition above.
Observe that the work performed by D for securely emulating
KeyGen will be amortized over several executions.
exitCR. Recall that F (cid:63)
exitCR offers. Speciﬁcally, F (cid:63)
Although the above modiﬁed scheme does minimize the valida-
tion complexity signiﬁcantly, one may still wonder if further im-
provements are possible. Note that current state-of-the-art pub-
lic veriﬁcation schemes [31], although quite impressive relative to
prior work, still require 288 bytes storage and 9ms to verify. That is,
each miner would be required to spend 9ms to execute the veriﬁca-
tion algorithm in order to validate the F (cid:63)
CR transaction. We observe
that in an optimistic scenario (where we assume both D and W are
interested in reducing the validation complexity), it is possible to
drive the validation complexity to zero. To do this, we ﬁrst let D
and W to interact as described above. Then, in a later phase, we
simply let W reveal (y, ψy) to D. If Verify(vkf , u, (y, ψ)) = 1,
then (honest) D pays W . Note that if D does not pay W , then W
can always claim the F (cid:63)
CR transaction made by D. On the other
hand, if D does pay W , then a malicious W may attempt to get
paid twice by also claiming coins(q) from the original F (cid:63)
CR trans-
action. In order to avoid this double payment, we use a new ideal
transaction functionality F (cid:63)
exitCR. The description of our veriﬁable
computation protocol (in the F (cid:63)
exitCR-hybrid model) appears in the
full version of our paper. We provide more details on the ideal
transaction functionality F (cid:63)
exitCR and a candidate Bitcoin imple-
mentation below.
Ideal functionality F (cid:63)
CR (cf. Figure 1) allows
a sender to conditionally send coins(x) to a receiver. However,
F (cid:63)
CR does not allow parties to mutually agree to discard check-
ing the condition to release payment. It is exactly this ability that
our new ideal functionality F (cid:63)
exitCR
allows parties to mutually agree to revoke the condition φ that re-
leases payment. In addition there is a “time” bound, formalized as
a round number τ2 within which the revision has to occur. As in
F (cid:63)
CR, Pr must act within some round number τ1 in order to claim
coins(x) by revealing a witness for φ if the condition φ was not
revoked.
To realize F (cid:63)
exitCR via Bitcoin, we need to modify the realization
of F (cid:63)
CR (e.g., as in [11, Appendix F]) only slightly. The mechanism
that we rely upon for txrefund is the script in txclaim that speciﬁes
that one of the ways to redeem txclaim is by signing with secret
keys that Ps and Pr hold. This allows txrefund to be created by both
parties signing a transaction that would be considered valid by Bit-
coin nodes only if it is included in a future block (as speciﬁed by a
timelock parameter). Hence, we only require an extra intermediate
step after txclaim was broadcast, in which, upon agreement, both
parties will sign a transaction txexit that redeems txclaim to Pr.
Incentivizing private veriﬁable computation. Perhaps the main
concern about our previous scheme is that D’s input u is made
public on the Bitcoin network. This is because the veriﬁcation
algorithm Verify(vkf , u,·) is part of the Bitcoin script that each
miner needs to verify before validating the transaction. A more
desirable scheme would be one where D’s input is kept private.
However note that a malicious W is given access to D’s input u,
and hence always has the power to make u (or f (u)) public. There-
fore, to make the problem more meaningful we will consider veri-
ﬁable computation schemes which already preserve privacy against
a malicious worker. Then one may ask whether it is possible to in-
centivize a veriﬁable computation that preserves input/output pri-
vacy of D. Indeed in the full version of our paper, we show some-
what surprisingly it is possible to incentivize veriﬁable computation
schemes with designated veriﬁer (i.e., in contrast to public veriﬁ-
34cation). However, this comes at a price. Speciﬁcally we no longer
guarantee pay on honest computation. On the other hand, we show
that it is possible to penalize a malicious worker that tries to exe-
cute the “rejection” attack (typically allowed by private veriﬁcation
schemes based on fully-homomorphic encryption). In such an at-
tack, the malicious worker supplies incorrect proofs of computation
and learns information depending on whether the honest delegator
accepts its proof or not.
At a high level, our constructions use secure computation to em-
ulate all algorithms except the Compute algorithm used by the
worker.
(Observe that the amortized complexity of D depends
only on the input/output length of f and is otherwise independent
of complexity of f.) An important issue is to ensure that parties
(especially the delegator) provide consistent inputs across all these
secure emulations. However, this is easily achieved by use of (one-
time) message authentication codes (since the MAC veriﬁcation
happens inside a secure protocol). While securely emulating the
Verify algorithm to secret share the ﬁnal output of the computation
between D and W if a successful proof was supplied, and then re-
quire D to make a F (cid:63)
CR deposit in order to learn the other secret
share. This is achieved using techniques similar to the ones em-
ployed in [11]. We defer other details of the construction to the full
version due to lack of space.
In summary, we provide two protocols that incentivize veriﬁable
computation schemes (i.e., force D to pay to learn the output while
denying payment for an incorrect output). The ﬁrst scheme com-
piles any public veriﬁcation scheme, guarantees pay on computa-
tion, but does not protect client privacy. The validation complexity
equals the public veriﬁcation complexity in the worst case and is
zero in an optimistic scenario (due to use of F (cid:63)
exitCR). The second
scheme compiles the designated veriﬁer scheme of [17], protects
client privacy and also penalize malicious workers that supply in-
valid proofs, but does not guarantee pay on computation. The val-
idation complexity of this protocol equals a hash invocation (with
hash input equal to the length of output of the computation).
Remark. We note that similar techniques may be extended to al-
low penalizing deviations in publicly veriﬁable covert secure pro-
tocols [8, 6].
4. SECURE COMPUTATION
We focus on the DualEx protocol of Huang et al. [23] (which
in turn is inspired by [29]). The protocol enjoys efﬁciency com-
parable to that of semihonest Yao garbled circuits protocol while
guaranteeing that a malicious party can learn at most one bit of
information about the honest party’s input. Given that secure com-
putation protocols require a high overhead due to use of cut-and-
choose or zero-knowledge, the DualEx protocol offers an attractive
alternative in scenarios where efﬁciency is the bottleneck.
We now provide a quick outline of the DualEx protocol. The
high level idea is to let two parties P1 and P2 run two simultane-
ous instances of a semihonest garbled circuit protocol. In the ﬁrst
instance P1 acts as the circuit constructor and P2 acts as the circuit
evaluator. In the second instance they swap roles. The key observa-
tion made in [29, 23] is that appending a secure equality test to the
above step somewhat surprisingly results in a protocol that leaks at
most a single bit of information about an honest party’s input to a
malicious party. Furthermore, several enhancements to the DualEx
are possible. For instance, it is possible to design a variant that re-
leases output to the parties only if the equality test passes. In such
a scenario, a cheating adversary does so only at the expense of not
learning the actual output.
[23] also experimentally validate the
superior efﬁciency of the DualEx protocol.
F (cid:63)
f,leak with session identiﬁer sid, running with parties P1 and
P2, a parameter 1λ, and an ideal adversary S that corrupts Pi
for i ∈ {1, 2} proceeds as follows. Let j ∈ {1, 2}\{i}. Let d
be a parameter representing the safety deposit, and let q denote
the penalty amount.
• Input phase. Honest Pj sends its input (input, sid,
ssid, xj, coins(d)). S sends input (input, sid, ssid, xi, L,
coins(q)) on behalf of Pi, where x1, x2 ∈ {0, 1}(cid:96), and
L : {0, 1}(cid:96) → {0, 1}.
• Output phase.
– Send (return, sid, ssid, coins(d)) to Pj.
– Compute z ← f (x1, x2) and y ← L(xj).
– If y = 0 send message (abort, sid, ssid) to S and
(penalty, sid, ssid, coins(q)) to Pj, and terminate.
– Else send message (output, sid, ssid, z, y) to S.
– If S returns (continue, sid, ssid) then set z(cid:48) = z and
q(cid:48) = 0, and send (return, sid, ssid, coins(q)) to S. Else
if S returns (abort, sid, ssid) set z(cid:48) = ⊥ and q(cid:48) = q.
– Send (output, sid, ssid, z(cid:48), coins(q(cid:48))) to Pj.
Figure 3: The leaky functionality with penalty F (cid:63)
f,leak.
f,leak.
Ideal functionality F (cid:63)
In the ﬁrst phase, the functionality
F (cid:63)
f,leak receives inputs from both parties. In addition F (cid:63)
f,leak al-
lows the ideal world adversary S to deposit coins(q) and specify a
“leakage function” denoted L. Note that an honest party makes a
ﬁxed deposit coins(d) in the input phase which is returned to it in
the output phase. The functionality ﬁrst computes the output z us-
ing inputs received from both parties, and also computes the output
y of the leakage function on the honest party’s input. If the output
of the leakage function equals 0 (without loss of generality), then
the honest party is compensated by coins(q). On the other hand
if output of the leakage function is 1, then this goes “undetected.”
The ideal functionality F (cid:63)
f,leak also penalizes corrupt parties that
abort on learning the output.
High level overview. As observed in [23], the attacks a malicious
party may use against a DualEx protocol can be grouped into three
main types: selective failure, in which the attacker constructs a
circuit that fails along some execution paths and attempts to learn
about the party’s private inputs from the occurrence of failure, false
function, in which the attacker constructs a circuit that implements
function that is different from f, and inconsistent inputs, in which
the attacker provides different inputs to the two executions. The
DualEx protocol mitigates all of the attacks in a elegant way and
allows a malicious party to learn at most one bit of information.
Our main observation is that attacks due to selective failure or
inconsistent inputs can be prevented using techniques whose efﬁ-
ciency depends only on the input/output length and is otherwise
independent of the circuit size of the function to be evaluated. Mo-
tivated by this observation, we design our protocol to narrow down
the one-bit leakage to be launched via the false function attack. We
then use standard techniques to penalize false function attacks.
Detailed overview. Our starting point is the observation that leak-
age in the DualEx protocol is detected only at the equality test
(“secure validation”) step. More precisely, in the event of de-
tected leakage, the equality test simply fails. We take advantage
of this in the following way: (1) letting P1, P2 exchange hash val-
ues h1 = H(r1), h2 = H(r2) of random strings r1, r2 ahead of the
equality step; (2) letting P1, P2 make F (cid:63)
CR transactions that release
coins(q) to the other party if it reveals the preimage to both hash
35Input from P1: m, x1, ω1.
Input from P2: m, x2, ω2.
Output to both P1 and P2:
• Create U1 ← iGb(1λ, ω1, m) and U2 ← iGb(1λ, ω2, m).
• Compute g(cid:48)
2 = com(ω2; ρ2) where
1 = com(ω1; ρ1) and g(cid:48)
ρ1, ρ2 are picked uniformly at random.
• Output (Ux1(cid:107)x2
2
, g(cid:48)
2, ρ1) to P1 and (Ux1(cid:107)x2
1
, g(cid:48)
1, ρ2) to P2.
Figure 4: Secure key transfer subroutine KT.
Input from P1: (cid:96)1 = (cid:96), w1, ω1, ρ1, r1, h2, g(cid:48)
2.
Input from P2: (cid:96)2 = (cid:96), w2, ω2, ρ2, r2, h1, g(cid:48)
1.
Output to both P1 and P2:
• If (cid:96)1 (cid:54)= (cid:96)2 or H(r1) (cid:54)= h1 or H(r2) (cid:54)= h2 or com(ω1; ρ1) (cid:54)=
1 or com(ω2; ρ2) (cid:54)= g(cid:48)
g(cid:48)
2, output bad and terminate.