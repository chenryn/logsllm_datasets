crawlergo是一个使用 chrome headless 模式进行URL收集的浏览器爬虫。它对整个网页的关键
位置与DOM渲染阶段进行HOOK，自动进行表单填充并提交，配合智能的JS事件触发，尽可能的
收集网站暴露出的入口。内置URL去重模块，过滤掉了大量伪静态URL，对于大型网站仍保持较快
的解析与抓取速度，最后得到高质量的请求结果集合。
crawlergo 目前支持以下特性：
* 原生浏览器环境，协程池调度任务
* 表单智能填充、自动化提交
* 完整DOM事件收集，自动化触发
* 智能URL去重，去掉大部分的重复请求
* 全面分析收集，包括javascript文件内容、页面注释、robots.txt文件和常见路径Fuzz
* 支持Host绑定，自动添加Referer
* 支持请求代理，支持爬虫结果主动推送
Github: https://github.com/Qianlitp/crawlergo
作者开源了源码，我是很兴奋的，以前也有写一个的想法，但是开源的动态爬虫不多，看了其中几个。
调研
1. https://github.com/fcavallarin/htcap
递归dom搜索引擎
发现ajax/fetch/jsonp/websocket请求
支持cookie，代理，ua，http auth
基于文本相似度的页面重复数据删除引擎
根据文本长度 = 32 {
            pathParts[index] = TooLongMark
        } else if 
onlyNumberRegex.MatchString(numSymbolRegex.ReplaceAllString(part, "")) {
            pathParts[index] = NumberMark
        } else if strings.HasSuffix(part, ".html") || strings.HasSuffix(part, 
".htm") || strings.HasSuffix(part, ".shtml") {
            part = htmlReplaceRegex.ReplaceAllString(part, "")
            // 大写、小写、数字混合
            if numberRegex.MatchString(part) && 
alphaUpperRegex.MatchString(part) && alphaLowerRegex.MatchString(part) {
                pathParts[index] = MixAlphaNumMark
                // 纯数字
            } else if b := numSymbolRegex.ReplaceAllString(part, ""); 
onlyNumberRegex.MatchString(b) {
                pathParts[index] = NumberMark
            }
            // 含有特殊符号
        } else if s.hasSpecialSymbol(part) {
            pathParts[index] = MixSymbolMark
        } else if chineseRegex.MatchString(part) {
            pathParts[index] = ChineseMark
基于网页结构去重
作者原帖中的基于网页结构去重写的非常精彩 https://www.anquanke.com/post/id/178339#h2-17
参考的论文下载: https://patents.google.com/patent/CN101694668B/zh
作者的将网页特征向量抽离出来，索引存储，用来判断大量网页的相似度，非常惊艳，未来用到资产收
集系统或者网络空间引擎上也都是非常不错的选择。
URL收集
robots
在爬虫之前，会先请求robots.txt，解析出所有链接，加入到待爬取页面。
源码中使用了一个正则来匹配
看了下robots规范:https://baike.baidu.com/item/robots%E5%8D%8F%E8%AE%AE/2483797 ，应该
还可以再优化一下，来处理一些表达式。
        } else if unicodeRegex.MatchString(part) {
            pathParts[index] = UnicodeMark
        } else if onlyAlphaUpperRegex.MatchString(part) {
            pathParts[index] = UpperMark
            // 均为数字和一些符号组成
        } else if b := numSymbolRegex.ReplaceAllString(part, ""); 
onlyNumberRegex.MatchString(b) {
            pathParts[index] = NumberMark
            // 数字出现的次数超过3，视为伪静态path
        } else if b := OneNumberRegex.ReplaceAllString(part, "0"); 
strings.Count(b, "0") > 3 {
            pathParts[index] = MixNumMark
        }
    }
    newPath := strings.Join(pathParts, "/")
    return newPath
}
var urlFindRegex = regexp.MustCompile(`(?:Disallow|Allow):.*?(/.+)`)
DIR FUZZ
在爬虫之前，如果没有指定dir字典的话，默认会使用内置的字典
根据状态码判断
['11', '123', '2017', '2018', 'message', 'mis', 'model', 'abstract', 'account', 
'act', 'action', 'activity', 'ad', 'address', 'ajax', 'alarm', 'api', 'app', 
'ar', 'attachment', 'auth', 'authority', 'award', 'back', 'backup', 'bak', 
'base', 'bbs', 'bbs1', 'cms', 'bd', 'gallery', 'game', 'gift', 'gold', 'bg', 
'bin', 'blacklist', 'blog', 'bootstrap', 'brand', 'build', 'cache', 'caches', 
'caching', 'cacti', 'cake', 'captcha', 'category', 'cdn', 'ch', 'check', 'city', 
'class', 'classes', 'classic', 'client', 'cluster', 'collection', 'comment', 
'commit', 'common', 'commons', 'components', 'conf', 'config', 'mysite', 
'confs', 'console', 'consumer', 'content', 'control', 'controllers', 'core', 
'crontab', 'crud', 'css', 'daily', 'dashboard', 'data', 'database', 'db', 
'default', 'demo', 'dev', 'doc', 'download', 'duty', 'es', 'eva', 'examples', 
'excel', 'export', 'ext', 'fe', 'feature', 'file', 'files', 'finance', 
'flashchart', 'follow', 'forum', 'frame', 'framework', 'ft', 'group', 'gss', 
'hello', 'helper', 'helpers', 'history', 'home', 'hr', 'htdocs', 'html', 
'hunter', 'image', 'img11', 'import', 'improve', 'inc', 'include', 'includes', 
'index', 'info', 'install', 'interface', 'item', 'jobconsume', 'jobs', 'json', 
'kindeditor', 'l', 'languages', 'lib', 'libraries', 'libs', 'link', 'lite', 
'local', 'log', 'login', 'logs', 'mail', 'main', 'maintenance', 'manage', 
'manager', 'manufacturer', 'menus', 'models', 'modules', 'monitor', 'movie', 
'mysql', 'n', 'nav', 'network', 'news', 'notice', 'nw', 'oauth', 'other', 
'page', 'pages', 'passport', 'pay', 'pcheck', 'people', 'person', 'php', 
'phprpc', 'phptest', 'picture', 'pl', 'platform', 'pm', 'portal', 'post', 
'product', 'project', 'protected', 'proxy', 'ps', 'public', 'qq', 'question', 
'quote', 'redirect', 'redisclient', 'report', 'resource', 'resources', 's', 
'save', 'schedule', 'schema', 'script', 'scripts', 'search', 'security', 
'server', 'service', 'shell', 'show', 'simple', 'site', 'sites', 'skin', 'sms', 
'soap', 'sola', 'sort', 'spider', 'sql', 'stat', 'static', 'statistics', 
'stats', 'submit', 'subways', 'survey', 'sv', 'syslog', 'system', 'tag', 'task', 
'tasks', 'tcpdf', 'template', 'templates', 'test', 'tests', 'ticket', 'tmp', 
'token', 'tool', 'tools', 'top', 'tpl', 'txt', 'upload', 'uploadify', 'uploads', 
'url', 'user', 'util', 'v1', 'v2', 'vendor', 'view', 'views', 'web', 'weixin', 