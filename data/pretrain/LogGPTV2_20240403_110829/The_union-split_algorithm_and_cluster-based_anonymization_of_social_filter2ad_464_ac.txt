ever, because the formulation and analysis of privacy prob-
lems, including attack models and anonymization goals, bear
the same spirit as security and cryptography issues, interest
from researchers in the security and cryptography commu-
nities has grown signiﬁcantly in recent years.
Hay et al.
has recently proposed an anonymization
method by grouping similar nodes into anonymous groups
and then publishing a generalized graph [6]. The generalized
graph describes the inter- and intra-group connectivity, e.g.,
there are 10 edges connecting group A and B, 50 internal
edges in group A, 18 internal edges in group B. A sample
of a generalized graph is then needed if one wants to make
use of the anonymized social networks for data mining. In
order to group nodes in the social network, they use sim-
ulated annealing to do a random exploration of the search
space for a good set of clusters, where the branching factor
may be exponential.
Our anonymization algorithm bears a similar spirit to the
neighborhood anonymization approach [21], but there are
several major diﬀerences. Zhou and Pei’s approach uses
a greedy approach to group and anonymize similar nodes
in one phase. Their method also relies on frequent checks
for isomorphisms between subgraphs, a problem which has
no known polynomial-time solution.
Indeed, their algo-
rithm runs in exponential time in the size of the subgraphs
examined, although they provide optimizations that make
the computation feasible in practice.
In comparison, our
anonymization method is more lightweight. Our approach
happens in two stages: cluster and anonymize. We clus-
ter graph vertices based on simple distance metrics ﬁrst,
and then anonymize to the clusters. Our edge insertion and
deletion are performed strategically to match needy nodes
and avoid unnecessary modiﬁcations.
The t-means algorithm is a data mining technique that
clusters n objects into t groups (t < n) based on a given
distance metric. Bennett, Bradley, and Demiriz proposed a
constrained t-means algorithm that accommodates the con-
straint of minimum cluster size [1]. They reformulate the
clustering problem as a Maximum Network Flow problem,
which is then solved using dynamic programming. Our so-
lution is more natural, and is easier to implement and use.
Our data anonymization problem is related to privacy-
preserving relational data, which has been extensively stud-
ied in the past decade. Most of the literature considers the
attack model as re-identiﬁcation of individuals by joining
the published table with some external tables modeling the
background knowledge of users. To defend against this type
of attacks, the mechanism of k-anonymity was proposed in
[16, 18]. Speciﬁcally, a dataset is said to be k-anonymous
if every group of tuples that are of the same values on the
quasi-identiﬁer attributes (i.e., the minimal set of attributes
in the table that can be joined with external information to
re-identify individual records) consists of at least k tuples.
The larger the value of k, the better the privacy is protected.
To improve on k-anonymity, new notions (e.g., l-diversity [9],
t-closeness [7], (α, k)-Anonymity [19]) have been proposed
to provide stronger privacy. We adapt the concept of k-
anonymity to our problem since it is the most essential and
most applicable privacy model. However, because relational
data and graph data have intrinsically diﬀerent representa-
tions, many techniques for relational data cannot be directly
applied to social networks.
Byun et al. came up with a clustering idea for anonymiz-
ing relational databases [2]. They presented a solution for
database records that are in the form of vectors, where each
dimension is a numerical value or a label in a ﬁxed hierarchy.
Again, their work is for relational databases, and does not
have a direct application to data in the form of a graph.
Cormode et al. developed a safe grouping approach for
anonymizing bipartite graphs [5].
In comparison, we con-
sider general undirected graphs. Compared with social net-
work graphs that we consider, bipartite graphs generated
by recommend systems diﬀer in several aspects. First,
unlike in the social network graphs where every node is
de-identiﬁed, recommendation graphs contain considerable
numbers of nodes whose identiﬁcations are revealed (e.g.,
the names of movies, music, books, etc.).
Second, un-
like social network graphs which are normally dense, most
real-world recommend system datasets are very sparse [12].
Thus, anonymization techniques developed for recommen-
dation data have a diﬀerent focus and emphasis from the
ones for social networks.
7. CONCLUSIONS AND FUTURE WORK
In this paper, we studied the data anonymization prob-
lem in static social networks. In particular, we investigated
whether clustering algorithms can be used for anonymiza-
tion and how eﬀective they are in ﬁnding similar nodes in
social networks. To that end, we developed new constrained
graph clustering methods, namely the bounded t-means and
union-split clustering algorithms, and showed that they are
eﬀective and general approaches to grouping similar nodes
on large social network graphs for anonymization.
Our similarity metrics and anonymization algorithms were
based on the k-anonymity privacy model. We considered
an i-hop degree-based neighborhood adversary model that
can be generalized to capture more complex neighborhood
knowledge of an adversary. We implemented our clustering
and anonymization algorithms in Java and ran experiments
on synthetic social network graphs. Our experimental re-
sults demonstrated that our methods are eﬀective in pre-
serving the statistical graph utilities studied.
For future work, we decide to formally deﬁne and study
the relationships between l-diversity and social relationship
attacks in social networks. In this paper, we consider adver-
saries whose goal is to re-identify a target in the anonymized
social networks. A diﬀerent type of attack is what we call
social relationship attacks, or link disclosures according to
Liu and Terzi [8], where the adversary’s goal is to gain more
information on the target’s social connectivity, for example,
to learn whether or not the target node has an edge with a
socially popular node of high degree. Although the adver-
sary may not be able to identify a target, she may learn that
the target is socially connected with an individual that is
well-connected (e.g., a popular person with Britney Spears’
status). In order to prevent these kinds of social relation-
ship attacks, our privacy model needs to be expanded to
introduce the concept of diversity, similar to the l-diversity
deﬁnition in anonymizing relational data [9].
Intuitively,
the diversity in social networks means that certain sensitive
nodes with distinct properties need to connect to at least l
diverse anonymous groups. We plan to formalize the deﬁ-
nition and investigate how l-diversity aﬀects the utilities of
the anonymized graphs.
8. REFERENCES
[1] P. Bradley, K. Bennett, and A. Demiriz. Constrained
k-means clustering. Technical Report
MSR-TR-2000-65, Microsoft Research, 2000.
[2] J.-W. Byun, A. Kamra, E. Bertino, and N. Li.
Eﬃcient k-anonymization using clustering techniques.
In Proceedings of the 12th International Conference on
Database Systems for Advanced Applications
(DASFAA), volume 4443 of Lecture Notes in
Computer Science, pages 188–200. Springer, 2007.
[3] Cambridge English Dictionary.
http://dictionary.cambridge.org/define.asp?
key=68410&dict=CALD.
[4] D. Chakrabarti, Y. Zhan, and C. Faloutsos. R-MAT:
A recursive model for graph mining. In M. W. Berry,
U. Dayal, C. Kamath, and D. B. Skillicorn, editors,
SDM. SIAM, 2004.
[5] G. Cormode, D. Srivastava, T. Yu, and Q. Zhang.
Anonymizing bipartite graph data using safe
groupings. In Proceedings of the International
Conference on Very Large Data Bases (VLDB), 2008.
[6] M. Hay, G. Miklau, D. Jensen, D. Towsley, and
P. Weis. Resisting structural identiﬁcation in
anonymized social networks. In Conference on Very
Large Databases (VLDB), 2008.
[7] N. Li, T. Li, and S. Venkatasubramanian. t-closeness:
Privacy beyond k-anonymity and l-diversity. In
Proceedings of the 23rd International Conference on
Data Engineering (ICDE), pages 106–115, 2007.
[8] K. Liu and E. Terzi. Towards identity anonymization
on graphs. In J. T.-L. Wang, editor, SIGMOD
Conference, pages 93–106. ACM, 2008.
[9] A. Machanavajjhala, J. Gehrke, D. Kifer, and
M. Venkitasubramaniam. l-diversity: Privacy beyond
k-anonymity. In Proceedings of the International
Conference on Data Engineering (ICDE), 2006.
[10] S. Milgram. The small world problem. Psychology
Today, 1(1):60–67, May 1967.
[11] A. W. Moore and D. Pelleg. X-means: Extending
k-means with eﬃcient estimation of the number of
clusters. In Proceedings of the Seventeenth
International Conference on Machine Learning, pages
727–734. Morgan Kaufmann, 2000.
[12] A. Narayanan and V. Shmatikov. Robust
de-anonymization of large sparse datasets. In IEEE
Symposium on Security and Privacy, pages 111–125.
IEEE Computer Society, 2008.
[13] M. E. Nergiz and C. Clifton. Thoughts on
k-anonymization. Data Knowl. Eng., 63(3):622–645,
2007.
[14] M. E. Nergiz, C. Clifton, and A. E. Nergiz.
Multirelational k-anonymity. In Proceedings of the
23rd International Conference on Data Engineering
(ICDE), pages 1417–1421, 2007.
[15] Netﬂix Prize. http://www.netflixprize.com.
[16] P. Samarati and L. Sweeney. Generalizing data to
provide anonymity when disclosing information
(abstract). In PODS, page 188. ACM Press, 1998.
[17] R. Stein. Social networks’ sway may be
underestimated. Washington Post, May 26, 2008.
[18] L. Sweeney. k-Anonymity, a model for protecting
privacy. International Journal on Uncertainty,
Fuzziness and Knowledge-based Systems, 10(5):557 –
570, 2002.
[19] R. C.-W. Wong, J. Li, A. W.-C. Fu, and K. Wang. (α,
k)-anonymity: an enhanced k-anonymity model for
privacy preserving data publishing. In T. Eliassi-Rad,
L. H. Ungar, M. Craven, and D. Gunopulos, editors,
KDD, pages 754–759. ACM, 2006.
[20] V. N. Zemlyachenko, N. M. Korneenko, and R. I.
Tyshkevich. Graph isomorphism problem. Journal of
Mathematical Sciences, 29(4):1426 ˝U1481, May 1985.
[21] B. Zhou and J. Pei. Preserving privacy in social
networks against neighborhood attacks. In Proceedings
of the 24th International Conference on Data
Engineering (ICDE), pages 506–515, 2008.
we initialize these data structures, which takes O(m2 · αµ
G)
and O(m2) time, respectively, using the linear-time heap-
building algorithm.
Choosing which cluster to union by iterating through the
current clusters and ﬁnding the small cluster with the small-
est value at the top of its heap takes O(m) time. After
unioning those two clusters, which takes O(κ) = O(k) time,
we calculate the new center and then update the tables.
Calculating the new center takes O(βµ
G) time. In the Inter-
Cluster Distance Table, we must nullify the distances for
the rows and columns corresponding to the unioned clus-
ters, and replace it with newly calculated distances from
all clusters to the new unioned cluster. This takes time
O(m · αµ
G). For each modiﬁed entry, we update that value in
the corresponding heap, which takes O(m log m) time total.
Finally, we create a new heap for the new unioned cluster in
time O(m). The total run-time for these operations is thus
O(m log m + m · αµ
G. Finding the two points in the
cluster farthest from each other requires calculating all the
pairwise distances, which takes O(k2 · αµ
G) time. The total
run-time of step 2b is O(m log m + m · αµ
G + k2 · αµ
G + βµ
G.
We bound the number of iterations of the union-split al-
gorithm by keeping track of the number of small clusters.
Initially there are n clusters, and every cluster is small. Dur-
ing every iteration, the number of small clusters decreases
by at least one when the union is performed. Since splitting
only results in clusters of size ≥ k, no new small clusters are
created. Therefore the algorithm terminates in at most n it-
erations. Assuming αµ
G, and k to be application-speciﬁc
constants, we conclude that the total run-time of the union-
split algorithm is O(m2 log m) and thus O(n2 log n).
G + k + βµ
G, βµ
APPENDIX
A. EXAMPLE OF MODE-BASED
CLUSTER CENTER
Vertex Vertex’s Degree
1-Hop Neighbors’ Degrees
v1
v2
v3
v4
v5
v6
v7
v8
2
3
2
3
5
3
3
3
{3,3}
{5,2,2}
{3,3}
{5,3,2}
{3,3,3,3,3}
{5,3,2}
{5,3,3}
{5,3,3}
Table 1: An example cluster with degrees of nodes
and their neighbors.
Table 1 gives an example of our mode-based cluster center
generation algorithm. We ﬁrst compute the cluster center as
having a degree of 3, the rounded average degree of vertices
in the cluster. The three (virtual) neighbors’ degrees are
{5,3,3}.
B. PROOFS OF THEOREMS
Proof of Theorem 3.1: Denote the number of undersized
clusters by X. The union-split algorithm terminates when
there is no undersized clusters, i.e., X = 0. At each iteration,
three cases can happen and X decreases in all three cases.
1. Two undersized clusters are unioned into one under-
sized cluster, then X = X − 1.
2. Two undersized clusters are unioned into one cluster
whose size is ≥ k, then X = X − 2.
3. One undersized cluster is unioned with a cluster whose
size is ≥ k, then X = X − 1.
Therefore, each iteration strictly reduces the number of un-
dersized clusters and the algorithm converges in a ﬁnite num-
ber of iterations.
2
Proof of Theorem 3.2:
Let n = |V (G)|, d = avg − deg(G), k = minimum allow-
able cluster size. Let m denote the number of clusters in
the current partition. Note m ≤ n/k. Let κ(c) denote the
number of points in cluster c. Let κ denote the maximum
number of points in any cluster at any time. In the union-
split algorithm, κ ≤ 3k −2. Let µ denote the distance metric
being used. A cluster is small if it contains < k points. A
cluster is large if it contains ≥ 2k points.
We will denote by αµ
G the maximum time to calculate
the distance between any two points in the graph G using
distance metric µ. We denote by βµ
G the maximum time it
takes to calculate the center of a cluster of ≤ κ points in G
using distance metric µ.
In the union-split algorithm, we maintain two dynamic
data structures. The ﬁrst is the Inter-Cluster Distance Ta-
ble, which records the distance between every pair of clus-
ters, and is thus an m×m matrix. The second is the Nearest
Cluster Heap List, which for each cluster c stores a heap con-
taining all other clusters, prioritized by their distance from
c. We will use this during the union-split algorithm to ﬁnd
the nearest cluster to c. At the beginning of the algorithm