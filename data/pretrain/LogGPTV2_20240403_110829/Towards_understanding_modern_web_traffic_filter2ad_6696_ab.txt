 85
 80
2006
2008
2010
 1
 3
 2
 4
# User Agents Per IP
 5
(c) BR
Figure 2: NAT usage: Most (83-94%) client IPs have only one user agent. The number gets slightly bigger over time due to an
increase in the number of computers per household.
Users and Content Our large-scale data set spanning many years
is much larger than the sets used in previous Web trafﬁc research,
and has broader coverage than much previous work, which has typ-
ically been restricted to users from a particular university or com-
pany [6, 63]. While some self-selection is unavoidable since we
are measuring users of our own system, we have found that our
user population is quite diverse, covering people who want faster
Web access, unﬁltered content, better routing, better privacy, and
other reasons.
As a high-level check on representativeness, we examine the
users of CoDeeN by looking at the User-Agent ﬁeld in the ac-
cess log, and ﬁnd that our global trends and regional variations
in browser and operating system usage are consistent with other
studies [60, 61]. Overall, Firefox and Microsoft Internet Explorer
(MSIE) account for more than 86% of the browsers in use over
the course of ﬁve years in all of the four countries, and more than
83% of the users’ operating systems are Windows. In some coun-
tries, we see a slightly higher share of Firefox than reported in other
studies, which we attribute to the existence of many Firefox Web
proxy addons that can use CoDeeN [23]. In most countries, we also
observe a decreasing share of MSIE due to the increasing share of
other browsers, such as Firefox and Chrome, with the exception of
China, which continues to show higher usage of MSIE and Win-
dows.
In addition, we investigate content that the users of CoDeeN
browse by examining the top sites in terms of the number of re-
quests. The results also correspond to other studies [5]. We observe
that globally-popular Web sites, such as Google, YouTube, Yahoo,
and Facebook, are commonly ranked high in all of the four coun-
tries. Furthermore, locally-popular Web sites also appear high in
the ranking. For example, these sites include craigslist.org,
go.com, and espn.com in the United States, baidu.com, qq.
com, and sina.com.cn in China, lequipe.fr, free.fr,
and over-blog.com in France, and globo.com, uol.com.
br, and orkut.com in Brazil.
3. HIGH-LEVEL CHARACTERISTICS
In this section, we analyze high-level characteristics of our Web
trafﬁc data, looking at the properties of clients, objects, and Web
sites.
Connection Speed We estimate the client bandwidth by observ-
ing the download time for objects – from the time when CoDeeN
proxy node receives the request from a client to the time when the
proxy ﬁnishes sending the object to the client. To minimize the ef-
fect of link latency, we consider only those objects that are larger
than 1 MB. Figure 1 shows CDFs of average client bandwidth per
aggregated /24 IP address, but similar patterns exist when using
the 95th percentile of download time. Overall, we observe that
the client bandwidth is consistently increasing over time, despite
no signiﬁcant change in PlanetLab’s own connectivity in that pe-
riod. Geographically, the speed of the United States and France is
faster than Brazil and China. This scarcity of bandwidth is partic-
ularly apparent in 2006, when we did not see any clients in Brazil
and China with download speeds exceeding 2 Mbps. Interestingly,
there still exist many slow clients with less than 256 Kbps, even in
the developed countries.
NAT Usage We analyze the use of Network Address Translation
(NAT) in Figure 2 where we present CDFs of the number of differ-
ent user agents per client IP address. The result shows that while
most (83-94%) client IPs have just one user agent, the number gets
slightly bigger over time. We attribute this increase to an increase in
the number of computers per household over the years, which im-
plies the scarcity of IPv4 addresses. The maximum number of user
agents per IP we observe is 69 in the United States, 500 in China
and 36 in Brazil. Our estimated number of NATs that have two or
more distinct hosts (6-17%) is lower than the numbers from other
studies that use client-side measurements or IP TTLs [15, 33, 37],
possibly due to methodology differences or from only some of the
hosts behind a NAT using the CoDeeN system.
297s
r
e
s
U
%
 100
 75
 50
 25
 0
2006
2008
2010
 5
 10
 15
 20
 25
 30
Max # Concurrent Connections
(a) US
s
r
e
s
U
%
 100
 75
 50
 25
 0
2006
2008
2010
 5
 10
 15
 20
 25
 30
Max # Concurrent Connections
(b) CN
s
r
e
s
U
%
 100
 75
 50
 25
 0
2006
2008
2010
 5
 10
 15
 20
 25
 30
Max # Concurrent Connections
(c) BR
Figure 3: Maximum number of concurrent connections per user: We observe quite a big increase in 2010 due to the browsers
increasing the number of connections.
html
css
xml
javascript
image
other-video
flv-video
octet
 100
 10
 1
s
e
t
y
B
%
 100
 10
 1
 0.1
s
e
t
y
B
%
 100
 10
 1
s
e
t
y
B
%
 0.1
 0.01
 0.1
 1
 10
 100
 0.01
 0.001  0.01  0.1
 1
 10
 100
 0.1
 0.01
 0.1
 1
 10
 100
% Requests
(a) US
% Requests
(b) FR
% Requests
(c) BR
Figure 4: Content type distribution changes from 2006 to 2010: We observe growth of Flash video, JavaScript, CSS, and XML.
Images are still dominating request trafﬁc.
Maximum Concurrent Connections Figure 3 shows CDFs of
the maximum number of concurrent connections per user agent.
We observe quite a big increase in 2010 – the median number
grows from 4-5 in 2006 and 2008 to 6-7 in 2010. This increase
is mainly because the browsers change the default number of max-
imum simultaneous connections per server from 4 to 6 in starting
in 2008 [4, 51], largely to accommodate Ajax which usually re-
quires many simultaneous connections to reduce latency. In fact,
the default number speciﬁed in HTTP/1.1 is only 2 [22].
Content Type We observe a shift from static image-oriented Web
pages to dynamic rich media Web pages in Figure 4. It presents the
content type distribution changes from 2006 to 2010, connected by
arrows. The X axis is the percentage of requests, and the Y axis is
the percentage of bytes, both in log-scale.
First, we observe a sharp increase of JavaScript, CSS, and XML,
primarily due to the popular use of Ajax. We also ﬁnd a sharp in-
crease of Flash video (FLV) trafﬁc, taking about 25% of total traf-
ﬁc both in the United States and Brazil in 2010, as it eats into the
share of other video formats. In addition, while the byte percent-
age of octet-stream trafﬁc sees a general decrease, its percentage
of requests actually increases. This may be related to the custom
use of HTTP as a transport protocol for exchanging binary data in
many applications. Still, image trafﬁc, including all of its subtypes,
consumes the most bandwidth.
Despite the growth of embedded images in Web pages, we do not
see a corresponding surge in their numbers in the trafﬁc patterns.
We believe that this is due to the improved caching behavior of
many Web sites that separate the cacheable parts of their content
on different servers and use long expiration dates. As a result, most
of these images are served from the browser cache after the initial
visit to the Web site.
Object Size We ﬁnd that the size of JavaScript and CSS to be in-
creasing steadily over time. As an example, Figure 5 (a) presents
CDFs of JavaScript sizes in France, and we show CDFs of CSS
sizes in China in Figure 5 (b), from 2006 to 2010. We omit the
similar results of other countries due to space constraints. The in-
creased code size of JavaScript and advanced CSS is likely related
to the increasing popularity of Ajax. In general, other content types
do not show consistent size changes over time.
While there seems to be no signiﬁcant size changes over time in
video objects, we observe FLV objects are bigger than other video
in general. Figure 5 (c) compares the object size (CDF) of differ-
ent video types in the United States for 2010. Some video objects
(e.g., ASF) are very small in size and they are container objects
that do not contain actual video content. Once users fetch this kind
of container object, they contact media streaming servers that use
non-HTTP protocols such as RTSP [55] or RTP [54] for fetching
the content. The median size of such container objects is typically
less than 1 KB, while that of FLV, WMV, and MPEG is 1743 KB,
265 KB, and 802 KB, respectively.
Finally, while new video streaming technologies that split a large
video ﬁle into multiple smaller ﬁles for cacheability and perfor-
mance started gaining popularity in late 2009 and 2010 [1, 8, 41],
we do not see its wide deployment in our data set yet. With these
new technologies, we expect to observe a decrease in size of video
objects with an increasing number of requests. We plan to analyze
this case with more recent data set in the future.
Trafﬁc Share of Web Sites We examine the trafﬁc share of 1)
video sites 1, and 2) advertising networks and analytics sites 2 in
Figure 6. We consider the top 50 sites that dominate these kinds
of trafﬁc.
In Figure 6 (a), we observe that the advertising net-
work trafﬁc takes 1-12% of the total requests, and it consistently
increases over time as the market grows [31].
In addition, we
ﬁnd the volume of video site trafﬁc is consistently increasing as
1e.g., youtube.com
2e.g., doubleclick.com and google-analytics.com
298 100
 75
 50
 25
s
t
s
e
u
q
e
R
%
 0
102
2006
2008
2010
104
105
103
Object Size (byte)
(a) FR: JavaScript
106
 100
 75
 50
 25
s
t
s
e
u
q
e
R
%
 0
102
 100
 75
 50
 25
s
t
s
e
u
q
e
R
%
2006
2008
2010
104
105
103
Object Size (byte)
106
(b) CN: CSS
 0
102 103 104 105 106 107 108
Object Size (byte)
asf
wmv
mpeg
flv
(c) US, 2010: video
Figure 5: Object size: The object size of JavaScript and CSS becomes larger. Flash video is bigger than other video.
s
t
s
e
u
q
e
R
%
 15
 10
US
CN
FR
BR
 5
 0
 2006
 2008
Year
 2010
s
e
t
y
B
%
 30
 20
 10
 0
US
CN
FR
BR
 2006
 2008
Year
 2010
s
P
I
%
 80
 60
 40
 20
 0
US
CN
FR
BR
 2006
 2008
Year
 2010
(a) Ads network trafﬁc by requests
(b) Video site trafﬁc by bytes
(c) Single top site % IPs
Figure 6: Top sites: Ads/video site trafﬁc is increasing. A single top site tracks up to 65% of the user population.
shown in Figure 6 (b), taking up to 28% in Brazil for 2010. China,
with lower bandwidth, sees more still image trafﬁc than video. Fi-
nally, we see that the single top site reaches a growing fraction
of all users over time in Figure 6 (c). All of the single top sites
by the number of client IPs during a ﬁve-year period are either a
search engine (google.com or baidu.com), or analytics site
(google-analytics.com), reaching as high as 65% in Brazil
for 2010, which may have implications for user tracking and pri-
vacy.
4. PAGE-LEVEL CHARACTERISTICS
In this section, we analyze our data with Web page-level details.
We ﬁrst provide background on page detection algorithms and ex-
plain the problems with previous approaches in Section 4.1. In Sec-
tion 4.2, we present a new page detection algorithm called Stream-
Structure that is better suited for modern Web trafﬁc analysis, and
also demonstrate it is more accurate than previous approaches. Us-
ing this algorithm, Section 4.3 examines the initial page character-
istics, analyzes page loading latency via simulations, and presents
a simple characterization of modern Web pages.
4.1 Previous Page Detection Algorithms
A common approach for empirically modeling Web trafﬁc is to
reconstruct end-user browsing behavior from the access log data,
in which users repeatedly request Web pages. Once Web pages
(or main objects) are identiﬁed, we can derive relevant model pa-
rameters such as the number of embedded objects, total page size,
total page time, and inter-arrival time. Thus, detecting Web page
boundaries is crucial to the model accuracy.
Previous approaches for detecting page boundaries fall into two
categories. The ﬁrst approach (time-based) is to use the idle time
between requests [9, 35, 56]. If the idle time is short enough (less
than a predeﬁned threshold), the request is assumed to be generated
automatically by the browser, and it becomes an embedded object
of the previous Web page. Otherwise, the request is assumed to be
generated manually by the user’s click, and it becomes the main
object of a new Web page. The second approach (type-based) is
to use the content type of the object [17]. This approach simply
regards every HTML object as a main object, and any non-HTML
object as an embedded object of the previous main object.
Unfortunately, the complex and dynamic nature of the current
Web trafﬁc blurs the traditional notion of Web pages, and the pre-
vious approaches do not work well. For example, client-side inter-
actions (e.g., Ajax) that usually have longer idle time would be mis-
classiﬁed as separate Web pages by the time-based approach. On
the other hand, the type-based approach would misclassify frames
in a single Web page as separate independent Web pages. As a re-
sult, these approaches would generate inaccurate trafﬁc models if
applied to modern Web trafﬁc. Worse, they have already been used
in hundreds of studies without validation.
4.2 StreamStructure Algorithm
To overcome the limitations of the previous approaches, we de-
velop a new page detection algorithm called StreamStructure, that
exploits the stream and structure information of Web pages. Our al-
gorithm consists of three steps – grouping streams, detecting main
objects, and identifying initial pages. Figure 7 depicts the deﬁni-
tion of streams, Web pages, initial pages, main/embedded objects,
and client-side interactions in our algorithm.
Step 1. Grouping Streams Instead of treating all the requests in a
ﬂat manner, we ﬁrst group them into multiple independent streams
by exploiting the Referer ﬁeld. The referer of a request reveals
the address of an object from which the request came from – a de-