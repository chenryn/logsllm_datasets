### 6. What Elements Would a Building Code for Software Entail?

If we accept the utility of the architectural metaphor for software systems, can the codes created to control buildings help us identify the necessary elements for a code to control the development and deployment of software with desired security properties? Building codes typically focus on maintaining public safety, health, and welfare. Key areas of concern include:

- **Structural Integrity:** Ensuring that the building's structure can withstand hazards such as high winds, heavy rains, lightning, and earthquakes.
- **Fire Safety:** Prevention, detection, limits on propagation, safe exit, and support for firefighters in larger structures.
- **Physical Safety of Occupants:** Proper dimensions for doors and stairways, handrails, and spacing of balusters.
- **Water Use:** Plumbing regulations, sufficiency of supply, sanitation, and water conservation.
- **Energy Use:** Electrical power, energy conservation, insulation, heating systems, and lighting.

Correlates for a building code for software security might include:

- **Structural Integrity:** Requirements for software and system integrity, tamper resistance, and the ability of system isolation mechanisms to resist attacks.
- **Fire Safety:** Use of "inflammable" materials (e.g., safe coding standards), domain separation to limit the propagation of attacks, intrusion detection, and recovery mechanisms.
- **Physical Safety:** Avoiding the equivalent of sharp corners and unprotected drop-offs in the security architecture; ensuring that security mechanisms are easy to use and understand.
- **Resource Usage:** Information flow control mechanisms, limitations on resource usage for security functions, and protection against the system becoming a source of denial-of-service attacks (exerting excessive resource demands on networks).

Creating an actual building code for software is beyond the scope of this paper. Such a code must inherently be a group activity, gradually building consensus among various stakeholders. Given the effort expended over the past decades on the Orange Book and the Common Criteria, what would be different about such an effort? Would it just yield a relabeling of the voluminous documents we've already created? I don’t think it has to be that way, though it makes sense to leverage activities like BSIMM and the nascent NIST cybersecurity framework as much as possible.

The NRC report on software for dependable systems [29] advocates the development of explicit dependability claims for systems and the development of evidence and arguments based on the evidence to support a dependability case for a system. Although the report observes that “it makes little sense to invest effort in ensuring the dependability of a system while ignoring the possibility of security vulnerabilities” [29, p. 19], it generally excludes security concerns from its scope. However, it makes another observation of particular interest here:

"As is well known to software engineers (but not to the general public), by far the largest class of problems arises from errors made in the eliciting, recording, and analysis of requirements. A second large class of problems arises from poor human factors design… Security vulnerabilities are to some extent an exception; the overwhelming majority of security vulnerabilities reported in software products—and exploited to attack the users of such products—are at the implementation level. The prevalence of code-related problems, however, is a direct consequence of higher-level decisions to use programming languages, design methods, and libraries that admit these problems. In principle, it is relatively easy to prevent implementation-level attacks but hard to retrofit existing programs."

The TCSEC and CC generally approach security from the top down: define the security policy, apply it to the specifications, identify security functions, and provide assurance that the security functions work as intended. This is a logical approach. However, the attacks we suffer from generally do not aim to pick the locks on the doors in our systems; rather, they probe the weak building materials in the walls that were not part of the security argument at all. They submit inputs that, because of low-level implementation errors, entirely change the transition function of the system and then open the doors from the inside.

This observation—that the vast majority of exploitable and exploited vulnerabilities in today’s systems are not the result of requirements or design flaws, but simple implementation oversights—seems to offer a direction for a building code for critical infrastructure software. At least, use development practices that minimize, and where possible, rule out these kinds of flaws. Use programming languages that make buffer overflows infeasible. Use static and dynamic analysis techniques on software for which source code is available to confirm the absence of whole classes of flaws. The software won’t be perfect, but it will be measurably better.

One of the advances in the past decade has been the incorporation of hardware in a wide range of systems to provide a root of trust. Yet, today, that hardware is vastly underused. It would seem to make sense for a building code to require that code for critical infrastructure systems take advantage of built-in mechanisms such as Trusted Platform Modules to help assure at least the initial integrity of software loads.

We need to be wary of creating a code that requires masses of highly trained building inspector equivalents. That’s where we ended up with the TCSEC, and the Common Criteria don’t seem to have helped a great deal in this respect. Our building code should not try to do more than can be done with automated support. It can evolve over time as technology advances in this respect.

We also need to recognize that we may want to use software developed by others, for which source code may not be available. We need to understand what we can assure about such software and how to use it without depending on properties we can’t assure. This may mean certifying the strength of walls we build around it or providing alternative means of computing the same result as a check, for example.

There is much more to be said about what could and should be put into a building code for critical infrastructure software. I don’t pretend to have all the knowledge and wisdom to create such a code myself; moreover, this seems to me inherently a group activity, as already noted.

### 7. Call to Action

We are told there are tens of thousands of jobs awaiting cybersecurity specialists, and we need to act quickly to train individuals for them [41]. I suspect most of these are not jobs creating new and innovative software products, but rather service jobs for people who configure systems, install patches, monitor systems, conduct forensic investigations, and, in some cases, develop attacks on the systems of others. There is nothing dishonorable about these jobs, but they provide graphic evidence of the poor level of software security and system security engineering that we have come to accept in today’s commercial products.

We do not lack the means to build systems that are much less vulnerable to attack, but those means will only be applied when those in a position to apply them have the incentive to do so. It is essential to provide that incentive where the systems being delivered underpin our society. Perhaps Congress will find a legislative means to provide that incentive, but today’s highly polarized political climate and industry’s ingrained resistance make that a difficult path. Perhaps the executive branch can use existing regulatory mechanisms to move in that direction, but its tools are weak, and the commercial world strongly resists them. Perhaps lawsuits can eventually establish some liability through the courts, but lawsuits are only effective after serious damage has occurred, and it would surely be better to avoid disasters than to rely on them to change policy.

The technical community can begin to act on its own by creating a credible building code for critical infrastructure system software that could be adopted by industry and perhaps eventually given legal force through government adoption. Industry can and should participate fully in the development of such a code, which can provide a credible means of self-regulation. The security technical community should collaborate with the software engineering and software quality/dependability/safety communities in this effort, but we should not wait for them to get started. If disasters do occur, this code should be available for adoption.

Another mechanism the technical community could create would be the equivalent of a board for investigating structural failures. When major cybersecurity failures occur, we need a respected group of technologists who can investigate what happened and extract the lessons engineers of future systems need to learn from those failures. Steve Bellovin has already proposed something similar to this [42].

Research has an important role to play in this process. Ideally, there should be a basis in theory or experiment for each requirement put into the building code. In practice, I suspect there will be substantial consensus on requirements for which the research basis is weak or lacking. I wouldn’t omit such agreed-upon practices or architectural features from the code, but they should be recognized as needing empirical or theoretical validation, and the research community should take up the challenge of providing sound evidence to illuminate the issue.

Regulation of any sort is often seen as a brake on technology, an overhead that perhaps must be tolerated but should certainly be minimized. I want to close with some evidence to the contrary from the Wall Street Journal. This conservative bastion recently published a review of a new, fuel-efficient luxury hybrid car with the following paragraphs:

"The specimen in question is a luxury sedan of goodly size and weight, around 3,700 pounds, with 200 hybrid horsepower, generous leather seats, big audio, exceptional soundproofing, and a cabin filled with fine joinery and brushed alloy trim. All in all, a handsome and sophisticated presentation. This car accelerates from zero to 60 miles per hour in around eight seconds and breaks the beam in the quarter-mile in about 16 seconds, certainly quicker than the last Jaguar E-type I drove.

"This quite uncompromised car … averages 40 miles per gallon in mixed driving, according to the EPA."