today. 
6.  WHAT ELEMENTS WOULD A 
BUILDING CODE FOR SOFTWARE 
ENTAIL? 
Suppose  we  accept  the  utility  of  the  architectural  metaphor  for 
software systems.  Can thinking about the codes created to control 
buildings help us identify the elements needed for creating a code 
to  control  the  development  and  deployment  of  software  with 
desired  security  properties?  Building  codes  are 
typically 
concerned  with  maintaining  public  safety,  health,  and  welfare. 
General areas of concern include: 
• 
• 
• 
integrity:  building 
structural 
integrity  must  be 
maintained in the face of hazards of its location, such as 
high winds, heavy rains, lightning, earthquakes 
fire safety: prevention, detection, limits on propagation, 
safe exit, and in larger structures, support for firefighters 
physical  safety  of  the  occupants:  door  and  stairway 
dimensions and handrails, spacing of balusters   
•  water  use:  plumbing  regulations,  sufficiency  of  supply 
sanitation,  water 
sewer/septic, 
effective 
and 
conservation  
energy  use: 
electrical power, energy conservation 
• 
insulation,  heating  systems, 
lighting, 
• 
Correlates for a building code for software security might include: 
Structural  integrity:  requirements  on  software  and 
system  integrity,  tamper  resistance  ability  of  system 
isolation mechanisms to resist attack 
Fire safety: use of  “inflammable” materials (e.g., safe 
coding 
limit 
propagation  of  attacks,  intrusion  detection,  recovery 
mechanisms 
Physical  safety:  avoid  the  equivalent  of  sharp  corners 
and  unprotected  drop-offs  in  the  security  architecture: 
be  sure  security  mechanisms  are  easy  to  use  and 
understand  
standards),  domain 
separation 
to 
• 
• 
•  Water  and  energy  usage:  information  flow  control 
mechanisms, limitations on resource usage for security 
functions, protection against system becoming a source 
of denial-of-service attacks (exerting excessive resource 
demands on networks) 
Constructing  an  actual  building  code  for  building  code  is  far 
beyond  the  scope  of  this  paper.  Moreover,  the  construction  of 
such  a  code  must  inherently  be  a  group  activity,  something  that 
builds consensus gradually among various stakeholders. 
Given the effort that has been expended over the past decades on 
the  Orange  Book  and  the  Common  Criteria,  what  would  be 
different about such an effort? Would it just yield a relabeling of 
the voluminous documents we’ve already created? I don’t think it 
has  to  be  that  way,  though  it  makes  sense  to  leverage  activities 
like  BSIMM  and  the  nascent  NIST  cybersecurity  framework  as 
much as possible. 
The  NRC  report  on  software  for  dependable  systems  [29], 
advocates  the  development  of  explicit  dependability  claims  for 
systems and the development of evidence and arguments based on 
the  evidence,  to  support  a  dependability  case  for  a  system1. 
Although the report observes that “it makes little sense to invest 
effort in ensuring the dependability of a system while ignoring the 
possibility  of  security  vulnerabilities”  [29,  p.  19],  it  in  general 
excludes security concerns from its scope. But it makes one other 
observation of particular interest here:  
“As  is  well  known  to  software  engineers  (but  not  to  the 
general public), by far the largest class of problems arises 
from errors made in the eliciting, recording, and analysis 
of requirements. A second large class of problems arises 
from poor human factors design… 
“Security vulnerabilities are to some extent an exception; 
the  overwhelming  majority  of  security  vulnerabilities 
reported in software products – and exploited to attack the 
users of such products – are at the implementation level. 
The  prevalence  of  code-related  problems,  however,  is  a 
direct  consequence  of  higher-level  decisions  to  use 
programming  languages,  design  methods,  and  libraries 
that admit these problems. In principle, it is relatively easy 
to prevent implementation-level attacks but hard to retrofit 
existing programs.” 
The  TCSEC  and  CC  generally  approach  security  from  the  top 
down:  define  the  security  policy,  apply  it  to  the  specifications, 
identify  security  functions,  provide  assurance  that  the  security 
functions work as intended. It’s a logical approach. But the attacks 
that we suffer from generally don’t aim to pick the locks on the 
doors  in  our  systems;  rather  they  probe  at  the  weak  building 
materials in the walls that weren’t part of the security argument at 
all. They submit inputs that, because of low-level implementation 
errors,  entirely  change  the  transition  function  of  the  system  and 
then open the doors from the inside. 
This  observation  that  the  vast  majority  of  the  exploitable  and 
exploited  vulnerabilities  in  today’s  systems  are  not  the  result  of 
requirements  or  design  flaws,  but  simple 
implementation 
oversights,  seems  to  offer  a  direction  for  a  building  code  for 
critical infrastructure software. At least use development practices 
that minimize, and, where possible, rule out these kinds of flaws. 
Use  programming 
that  make  buffer  overflows 
infeasible. Use static and dynamic analysis techniques on software 
for  which  source  code  is  available  to  confirm  the  absence  of 
whole classes of flaws. The software won’t be perfect but it will 
be measurably better.  
One of the advances in the past decade has been the incorporation 
of hardware in a wide range of systems to provide a root of trust, 
yet  today  that  hardware  is  vastly  underused.  It  would  seem  to 
make  sense  for  a  building  code  to  require  that  code  for  critical 
infrastructure systems take advantage of built-in mechanisms such 
as  Trusted  Platform  Modules  to  help  assure  at  least  the  initial 
integrity of software loads.  
We need to be wary also of creating a code that requires masses of 
highly  trained  building  inspector  equivalents.    That’s  where  we 
ended up with the TCSEC, and the Common Criteria don’t seem 
to  have  helped  a  great  deal  in  this  respect.  Our  building  code 
should  not  try  to  do  a  great  deal  more  than  can  be  done  with 
automated  support.  It  can  evolve  over  time  as  technology 
advances in this respect. 
languages 
1 Similar approaches have been explored with respect to security 
[40] but not widely adopted. 
145
forensic 
for  attacks,  and  conduct 
We also need to recognize that we may want to use software that 
was developed by others and for which source code may not be 
available. We need to understand what we can assure about such 
software  and  how  to  use  it  without  depending  on  properties  we 
can’t assure.  That may mean certifying the strength of walls we 
build around it, or providing alternative means of computing the 
same result as a check, for example. 
There is a great deal more to be said about what could and what 
should  be  put  into  a  building  code  for  critical  infrastructure 
software.  I don’t pretend to have all the knowledge and wisdom 
to  create  such  a  code  myself;  moreover  this  seems  to  me 
inherently a group activity, as already noted.  
7.  CALL TO ACTION 
We  are  told  there  are  tens  of  thousands  of  jobs  awaiting 
cybersecurity  specialists,  and  we  need  to  act  quickly  to  train 
individuals  for  them  [41].  I  suspect  most  of  these  are  not  jobs 
creating new and innovative software products, but rather service 
jobs  for  people  who  configure  systems,  install  patches,  monitor 
systems 
investigations 
afterwards. In some cases they are jobs developing attacks on the 
systems of others. There is nothing dishonorable about these jobs, 
but  they  provide  graphic  evidence  of  the  poor  level  of  software 
security  and  system  security  engineering  that  we  have  come  to 
accept in today’s commercial products.  
We  do  not  lack  the  means  to  build  systems  that  are  much  less 
vulnerable to attack, but those means will only be applied when 
those in a position to apply them have the incentive to do so. It is 
essential  to  provide  that  incentive  where  the  systems  being 
delivered underpin our society.  Perhaps the Congress will find a 
legislative  means  to  provide  that  incentive,  but  today’s  highly 
polarized  political  climate  and  industry’s  ingrained  resistance 
makes that a difficult path. Perhaps the executive branch can use 
existing regulatory mechanisms to move in that direction, but its 
tools  are  weak  and  the  commercial  world  strongly  resists  them. 
Perhaps  lawsuits  can  eventually  establish  some  liability  through 
the courts, but lawsuits are only effective after serious damage has 
occurred and it would surely be better to avoid disasters than to 
rely on them to change policy.  
The technical community can begin to act on its own by creating a 
credible  building  code  for  critical  infrastructure  system  software 
that  could  be  adopted  by  industry  and  perhaps  eventually  given 
legal force through government adoption. Industry can and should 
participate  fully  in  the  development  of  such  a  code,  which  can 
provide a credible means of self-regulation. The security technical 
community should collaborate with the software engineering and 
software  quality/dependability/safety  communities  in  this  effort, 
but  we  should  not  wait  for  them  to  get  started.  If  disasters  do 
occur, this code should be available for adoption.  
Another mechanisms the technical community could create would 
be  the  equivalent  of  a  board  for  investigating  structural  failures.  
When  major  cybersecurity  failures  occur,  we  need  a  respected 
group  of  technologists  who  can  investigate  what  happened  and 
extract the lessons engineers of future systems need to learn from 
those  failures.  Steve  Bellovin  has  already  proposed  something 
similar to this [42] 
Research  has  an  important  role  to  play  in  this  process.  Ideally, 
there  should  be  a  basis  in  theory  or  experiment  for  each 
requirement put into the building code. In practice, I suspect there 
will  be  substantial  consensus  on  requirements  for  which  the 
research  basis  is  weak  or  lacking.  I  wouldn’t  omit  such  agreed-
upon  practices  or  architectural  features  from  the  code  but  they 
should  be  recognized  as  needing  empirical  or 
theoretical 
validation,  and  the  research  community  should  take  up  the 
challenge of providing sound evidence to illuminate the issue. 
Regulation of any sort is often seen as a brake on technology, an 
overhead that perhaps must be tolerated, but should certainly be 
minimized.  I  want  to  close  with  some  evidence  to  the  contrary 
from the Wall Street Journal.  This conservative bastion recently 
published a review of a new, fuel-efficient luxury hybrid car with 
the following paragraphs: 
trim.  All 
“The  specimen  in  question  is  a  luxury  sedan  of  goodly 
size  and  weight,  around  3,700  pounds,  with  200  hybrid 
horsepower, generous leather seats, big audio, exceptional 
soundproofing,  and  a  cabin  filled  with  fine  joinery  and 
brushed  alloy 
in  all,  a  handsome  and 
sophisticated presentation. This car accelerates from zero 
to 60 miles per hour in around eight seconds and breaks 
the beam in the quarter-mile in about 16 seconds, certainly 
quicker than the last Jaguar E-type I drove.  
“This quite uncompromised car … averages 40 miles per 
gallon in mixed driving, according to the EPA. 