title:"You Might Also Like: " Privacy Risks of Collaborative Filtering
author:Joseph A. Calandrino and
Ann Kilzer and
Arvind Narayanan and
Edward W. Felten and
Vitaly Shmatikov
“You Might Also Like:”
Privacy Risks of Collaborative Filtering
Joseph A. Calandrino1, Ann Kilzer2, Arvind Narayanan3, Edward W. Felten1, and Vitaly Shmatikov2
1Dept. of Computer Science, Princeton University {jcalandr,felten}@cs.princeton.edu
2Dept. of Computer Science, The University of Texas at Austin {akilzer,shmat}@cs.utexas.edu
3Dept. of Computer Science, Stanford University PI:EMAIL
Abstract—Many commercial websites use recommender sys-
tems to help customers locate products and content. Modern
recommenders are based on collaborative ﬁltering: they use
patterns learned from users’ behavior to make recommendations,
usually in the form of related-items lists. The scale and complexity
of these systems, along with the fact that their outputs reveal only
relationships between items (as opposed to information about
users), may suggest that they pose no meaningful privacy risk.
In this paper, we develop algorithms which take a moderate
amount of auxiliary information about a customer and infer this
customer’s transactions from temporal changes in the public
outputs of a recommender system. Our inference attacks are
passive and can be carried out by any Internet user. We evaluate
their feasibility using public data from popular websites Hunch,
Last.fm, LibraryThing, and Amazon.
I. INTRODUCTION
Recommender systems are ubiquitous on the Web. When
you buy products from Amazon, rent movies on Netﬂix,
listen to music on Last.fm, or perform myriad other tasks
online, recommender systems make suggestions based on your
behavior. They typically rely on collaborative ﬁltering, or
patterns learned from other users: for example, “customers
who buy item X (as you just did) often buy item Y .”
We investigate the privacy risks of recommender systems
based on collaborative ﬁltering. By design, such systems
do not directly reveal behavior of individual users or any
“personally identiﬁable information.” Their recommendations
are based on aggregated data involving thousands to millions
of users, each with dozens to thousands of transactions. More-
over, modern collaborative ﬁltering leverages relationships
between items rather than relationships between users, creating
an extra level of indirection between public recommendations
and individual transactions. One might therefore assume that it
is infeasible to draw meaningful inferences about transactions
of speciﬁc users from the public outputs of recommender
systems. We show that this assumption is wrong.
Our contributions. We develop a set of practical algorithms
that allow accurate inference of (partial) individual behavior
from the aggregate outputs of a typical recommender system.
We focus on item-to-item collaborative ﬁltering, in which the
system recommends items similar to a given item. Our key
insight is to exploit the dynamics of public recommendations
in order to make the leap from aggregate to individual data.
This paper is the ﬁrst to make and quantitatively evaluate the
observation that temporal changes in aggregate recommenda-
tions enable accurate inference of individual inputs.
Our algorithms require only passive, “black-box” access to
the public outputs of a recommender system, as available to
any Internet user. The attacker need not create fake customers
or enter purchases or ratings into the system. We do not assume
that customers’ transactions are available in either identiﬁable
or anonymized form. Our approach is thus fundamentally
different from the techniques for re-identifying anonymized
transactional records [26]. Re-identiﬁcation assumes that the
attacker has direct access to customers’ records. By contrast,
our attacks rely only on indirect access: the records are fed into
a complex collaborative ﬁltering algorithm and the attacker’s
view is limited to the resulting outputs.
Our algorithms monitor changes in the public outputs of rec-
ommender systems—item similarity lists or cross-item correla-
tions—over a period of time. This dynamic information is then
combined with a moderate amount of auxiliary information
about some of the transactions of a particular “target” user. The
combination is used to infer many of the target user’s unknown
transactions with high accuracy. Auxiliary information can be
obtained by analyzing the user’s publicly revealed behavior;
we discuss this in more detail in Section III.
Overview of results. We evaluate our algorithms on real-world
recommender systems which produce different types of rec-
ommendations. Our goal is not to claim privacy ﬂaws in these
speciﬁc sites—in fact, we often use data voluntarily disclosed
by their users to verify our inferences—but to demonstrate the
general feasibility of inferring individual transactions from the
outputs of collaborative ﬁltering systems.
Some recommender systems make item-to-item correlations
available. An example is Hunch, a popular recommendation
and personalization website. There is a tradeoff between the
number of inferences and their accuracy. When optimized for
accuracy, our algorithm infers a third of the test users’ secret
answers to Hunch questions with no error.
Other recommender systems make only item similarity or
“related items” lists available, with or without numeric similar-
ity scores. Examples include Last.fm, an online music service,
and LibraryThing, an online book cataloging service and
recommendation engine. The results from our LibraryThing
experiment illustrate the yield-accuracy tradeoff, ranging from
58 inferences per user with 50% accuracy to 6 inferences per
user with 90% accuracy. Another example of item similarity
lists is the “Customers who bought this item also bought . . . ”
feature on Amazon. Our ability to evaluate our algorithms on
Amazon’s recommender system is constrained by the lack of
a “ground-truth oracle” for verifying our inferences, but we
conducted a limited experiment to demonstrate the feasibility
of adversarial inference against Amazon’s recommendations.
By necessity, our experiments on real-world systems involve
only a limited sample of users. To demonstrate that our
inference algorithms also work at scale, we implemented an
item-to-item collaborative ﬁltering engine very similar to that
used by Amazon, and ran it on the Netﬂix Prize dataset of
movie-rating histories [28]. This allowed us to simulate a
complete system, producing public recommendations as well
as auxiliary information about users. The underlying dataset
of individual ratings served as the “ground-truth oracle” for
verifying inferences made by our algorithm. Our algorithm
was able to infer 4.5% of transactions of sufﬁciently active
users with an accuracy of 90%.
There is a passing similarity between our inference algo-
rithms and actual collaborative ﬁltering. Both use statistical
methods to reach probabilistic conclusions about unknown
aspects of users’ behavior. Our algorithms, however, are tech-
nically different and pursue a fundamentally different goal: not
to predict future events, but to infer past events. This translates
into several concrete differences, discussed in Section V. For
example, in contrast to prediction algorithms, ours perform
best when a user deviates from normal patterns and if his
transactions involve less popular items. We can also infer an
approximate date when a transaction occurred.
For completeness with respect to different types of recom-
mender systems, we present a simple active attack on user-
based collaborative ﬁltering. In broad terms, the attacker cre-
ates multiple sybil users whose transactional proﬁle is similar
to what he knows about the target user’s proﬁle and infers
the target’s non-public transactions from the recommendations
made by the system to these sybils.
In summary, this work is the ﬁrst to develop a generic
method for inferring information about individual users’ trans-
actions from the aggregate outputs of collaborative ﬁltering.
We show that public outputs of common recommender al-
gorithms may expose non-public details of individual users’
behavior—products they purchase, news stories and books
they read, music they listen to, videos they watch, and other
choices they make—without their knowledge or consent.
II. SURVEY OF RECOMMENDER SYSTEMS
Recommender systems have become a vital tool for attract-
ing and keeping users on commercial websites. Their utility
is supported by research [14] as well as common practice.
The task of a recommender system can be abstractly de-
scribed as follows. Consider a matrix in which rows corre-
spond to users and columns correspond to items. Each value
in this matrix represents a user’s revealed or stated preference
(if any) for an item: for example, whether he purchased a book,
how many times he listened to a song, or what rating he gave
to a movie. Because the item set is typically far larger than a
single user can consume and evaluate, this matrix is “sparse:”
only a small fraction of entries are ﬁlled in. A recommender
system takes this matrix as input, along with any available
metadata about users (such as demographics) and items (such
as item categories). The goal of the system is to extrapolate
users’ “true” preferences over the full item set.
Recommender systems can provide several types of rec-
ommendations. If the system suggests items to an individual
user based on its knowledge of the user’s behavior, it provides
user-to-item recommendations. If the system helps users ﬁnd
similar users, it provides user-to-user recommendations. If,
given an item, the system suggests similar items, it provides
item-to-item recommendations. The system may even list users
who are strongly associated with a given item, thus providing
item-to-user recommendations. The same system may provide
several types of recommendations: for example, Last.fm pro-
vides both item-to-item and user-to-user recommendations.
We focus on item-to-item recommendations, both because
they are supported by essentially all popular online recom-
mender systems and because their output is typically public
and thus the most feasible avenue for an attack.
A thorough technical survey of the literature on recom-
mender systems can be found in [1]. Recommender systems
can be classiﬁed as content-based, collaborative, and hybrid.
Content-based systems identify relationships between items
based on metadata alone and recommend items which are
similar to the user’s past transactions. Purely content-based
recommender systems pose no privacy risks under our attacks,
since the system does not consider other users’ transactions
when making recommendations to a user.
Collaborative ﬁltering is much more robust and domain-
agnostic, and hence far more popular. Collaborative ﬁltering
identiﬁes relationships between items based on the preferences
of all users. Traditional collaborative ﬁltering methods are
user-based. For a given user, the system ﬁnds other users
with a similar transaction history. In the user-to-user case, the
system recommends these similar users; in the user-to-item
case, it recommends items selected by the similar users.
The alternative is item-based collaborative ﬁltering, which
was ﬁrst described by Sarwar et al. [31] and has become the
dominant approach [2, 20, 21]. It generates recommendations
using item similarity scores for pairs of items, which are based
on the likelihood of the pair being purchased by the same
customer. Although some systems make raw similarity scores
public, their main uses are internal: for example, to ﬁnd items
which are similar to a user’s previously purchased items in
order to make user-to-item recommendations.
A. Item-to-item recommendations
It has become standard practice for online recommender
systems to publish item-to-item recommendations, usually in
the form of item similarity lists produced from item similarity
scores. Given an item,
these lists help ﬁnd related items
(see [6] for a survey of algorithms). On Amazon, this is seen as
the “Customers who bought this item also bought . . . ” feature.
Similar features are found on many commercial websites,
including iTunes, Last.fm, Pandora, Netﬂix, YouTube, Hulu,
and Google Reader. Item similarity lists even appear on many
sites that do not have traditional user-to-item recommenda-
tions, such as IMDb, CNN, and the New York Times.1 Item
similarity lists may be limited to top N items or contain an
ordered list of hundreds or thousands of items.
Many systems reveal additional information. Amazon re-
veals not only the relative popularity of items via bestseller
lists and “sales rank,” but also the percentage of users pur-
chasing certain other items after viewing the given item.2 For
every song, Last.fm provides the number of listeners and how
many times it was played by each listener. Given a book,
LibraryThing provides several ordered lists of related books,
including more common and more obscure recommendations;
some lists also contain detailed transaction information, such
as the precise number of users who have both books. Finally,
Hunch gives all users access to the entire item-to-item co-
variance matrix via an API.
B. User-to-item recommendations
User-to-item recommendations may be user-based (ﬁnding
similar users and recommending their items) or item-based
(ﬁnding items related to ones that the user chose in the past).
Amazon provides several personalized lists with up to 1,000
items to logged-in users. LibraryThing, Last.fm, and Netﬂix
also provide recommendation lists to their users.
III. ATTACK MODEL
We view the data that the system uses to make recommenda-
tions as a matrix where rows correspond to users and columns
to items. Each cell represents a transaction (e.g., the user’s
purchase or stated preference for an item). Entries may be
dated; the date may or may not be sensitive from a privacy
perspective. As users interact with the system, the matrix is
continually updated and new recommendations are generated.
Our primary focus is on passive inference attacks. The
attacker has access to the public outputs of the recommender
system, which, depending on the system, may include item
similarity lists, item-to-item covariances, and/or relative pop-
ularity of items (see Section II). The outputs available to the
attacker are available to any user of the system. Crucially, the
attacker observes the system over a certain period and can
thus capture changes in its outputs: an increase in covariance
between certain items, appearance of an item on the similarity
list of another item, an increase in an item’s sales rank, etc.
Note, however, that each update incorporates the effects of
hundreds or thousands of transactions. With the exception
of auxiliary information (described below), inputs into our
inference algorithms are based on aggregate statistics and con-
tain neither personally identiﬁable information nor information
about speciﬁc transactions.
1Even ofﬂine retailers such as supermarkets frequently deploy item-to-item
similarity analysis to optimize store layout [3].
2We do not exploit the latter information for the inference attacks in this
paper. This is an interesting topic for future research.
For completeness, we also brieﬂy consider active attacks,
where the attacker creates fake, “sybil” users and manipulates
their entries in the corresponding rows of the transaction
matrix. Depending on the system, this includes adding new
entries (easy in the case of ratings and stated preferences,
more expensive for purchases), modifying existing entries, or
deleting them (easy in the case of ratings and preferences
and may also be possible for purchases; for example, one
can instruct Amazon to ignore certain purchases when making
recommendations). Observable outputs include items recom-
mended by the system to the sybil users and, in the case of
systems like Last.fm or LibraryThing, also user similarity lists
which explicitly identify users with similar histories.
Auxiliary information. We assume that for some users, a
subset of their transaction history is available to the attacker.
We refer to this as the attacker’s auxiliary information. An
inference attack is successful if it enables the attacker to learn
transactions which are not part of the auxiliary information.
In other words, the attacker’s objective is to “leverage” his
prior knowledge of some of the target user’s transactions to
discover transactions that he did not know about.
There are many sources of auxiliary information. The ﬁrst is
the target system itself. On many websites, users publicly rate
or comment on items, revealing a high likelihood of having
purchased them. The system may even publicly conﬁrm the
purchase, e.g., “veriﬁed purchase” on Amazon. Alternatively,
on sites with granular privacy controls, some of the transac-
tions may be publicly visible, while others remain private.
The second source is users revealing partial information
about themselves via third-party sites. This is increasingly
common: for example, music websites allow embedding of
tracks or playlists on blogs or other sites, while Amazon
Kindle allows “tweeting” a selected block of text; the identity
of the book is automatically shared via the tweet.3
The third source is data from other sites which are not
directly tied to the user’s transactions on the target site,
but leak partial information about them. For example, books
listed in a Facebook user proﬁle reveal partial information
about purchases on Amazon. Linking users across different
sites is a well-studied problem [17, 27]. On blippy.com, “a
website where people obsessively review everything they buy,”
individual purchase histories can be looked up by username,
making linkages to other sites trivial. Note that the third (and
to a lesser extent, the second) source of auxiliary information
is outside the control of the recommender system.
Furthermore,
information about users’ behavior is con-
stantly leaked through public mentions on online fora, real-
world interactions with friends, coworkers, and acquaintances,
etc. Therefore, we do not consider the availability of auxiliary
information to be a signiﬁcant impediment to our attacks.
3The stream of such tweets can be conveniently accessed in real time by
searching Twitter for “amzn.com/k/”.
function : R|A| → R
Algorithm 1: RELATEDITEMSLISTINFERENCE
Input: Set of target items T , set of auxiliary items A, scoring
Output: Subset of items from T which are believed by the
inf erredItems = {}
foreach observation time τ do
attacker to have been added to the user’s record
∆ = observation period beginning at τ
N∆ = delta matrix containing changes in positions of
items from T in lists associated with items from A
foreach target item t in N∆ do
scorest = SCOREFUNCTION(N∆[t])
if scorest ≥ threshold and t /∈ A then
inf erredItems = inf erredItems ∪ {t}
return inf erredItems
IV. GENERIC INFERENCE ATTACKS
A. Inference attack on related-items lists
In this setting of the problem, the recommender system
outputs, for each item, one or more lists of related items.
For example, for each book, LibraryThing publishes a list of
popular related books and a list of obscure related books.