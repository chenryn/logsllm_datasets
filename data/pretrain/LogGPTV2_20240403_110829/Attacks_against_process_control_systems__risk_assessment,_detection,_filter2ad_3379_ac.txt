rate models from ﬁrst principles [51]. However, for the majority of
process control systems, the development of process models from
fundamental physics is difﬁcult.
In many cases such detailed models are difﬁcult to justify eco-
nomically, and even impossible to obtain in reasonable time due to
the complex nature of many systems and processes. (The TE-PCS
system used in our experiments is one of the few cases available in
the literature of a detailed nonlinear model of an industrial control
problem; this is the reason why the TE-PCS system has been used
as a standard testbed in many industrial control papers.)
To facilitate the creation of physical models, most industrial con-
trol vendors provide tools (called identiﬁcation packages) to de-
velop models of physical systems from training data. The most
common models are linear systems. Linear systems can be used to
model dynamics that are linear in state x(k) and control input u(k)
x(k + 1) = Ax(k) + Bu(k)
(1)
where time is represented by k ∈ Z+, x(k) = (x1(k), . . . , xn(k)) ∈
Rn is the state of the system, and u(k) = (u1(k), . . . , um(k)) ∈
Rm is the control input. The matrix A = (aij) ∈ Rn×n models the
physical dependence of state i on state j, and B = (bij) ∈ Rn×m
is the input matrix for state i from control input j.
Assume the system (1) is monitored by a sensor network with
p sensors. We obtain the measurement sequence from the observa-
tion equations
ˆy(k) = Cx(k),
(2)
where ˆy(k) = (ˆy1(k), . . . , ˆyp(k)) ∈ Rp, and ˆyl(k) ∈ R is the
estimated measurement collected by sensor l at time k. Matrix C ∈
Rp×n is called output matrix.
5.2 Detection Methods
The physical-model-based attack detection method presented in
this paper can be viewed as complementary to intrusion detection
methods based on network and computer systems models.
Because we need to detect anomalies in real time, we can use
results from sequential detection theory to give a sound foundation
to our approach. Sequential detection theory considers the problem
where the measurement time is not ﬁxed, but can be chosen online
as and when the measurements are obtained. Such problem formu-
lations are called optimal stopping problems. Two such problem
formulations are: sequential detection (also known as sequential
hypothesis testing), and quickest detection (also known as change
detection). A good survey of these problems is given by Kailath
and Poor [53].
In optimal stopping problems, we are given a time series se-
quence z(1), z(2), . . . , z(N ), and the goal is to determine the min-
imum number of samples, N , the anomaly detection scheme should
observe before making a decision dN between two hypotheses: H0
(normal behavior) and H1 (attack).
The difference between sequential detection and change detec-
tion is that the former assumes the sequence z(i) is generated either
by the normal hypothesis (H0), or by the attack hypothesis (H1).
The goal is to decide which hypothesis is true in minimum time.
On the other hand, change detection assumes the observation z(i)
starts under H0 and then, at a given ks it changes to hypothesis H1.
Here the goal is to detect this change as soon as possible.
Both problem formulations are very popular, but security re-
searchers have used sequential detection more frequently. How-
ever, for our attack detection method, the change detection formu-
lation is more intuitive. To facilitate this intuition, we now brieﬂy
describe the two formulations.
5.2.1
Sequential Detection
Given a ﬁxed probability of false alarm and a ﬁxed probability
of detection, the goal of sequential detection is to minimize the
number of observations required to make a decision between two
360
hypotheses. The solution is the classic sequential probability ra-
tio test (SPRT) of Wald [54] (also referred as the threshold ran-
dom walk (TRW) by some security papers). SPRT has been widely
used in various problems in information security such as detecting
portscans [55], worms [56], proxies used by spammers [57], and
botnets [58].
Assuming that the observations z(k) under Hj are generated
with a probability distribution pj , the SPRT algorithm can be de-
scribed by the following equations:
S(k + 1) = log
p1(z(k))
p0(z(k))
+ S(k)
N = inf
n
{n : S(n) /∈ [L, U ]},
where bi is a small positive constant chosen such that
E0[˜yi(k) − ˆyi(k) − bi]  τi
otherwise.
(7)
(8)
(9)
where τi is the threshold selected based on the false alarm rate for
sensor i.
Following [59], we state the following two important results for
starting with S(0) = 0. The SPRT decision rule dN is deﬁned as:
Eq. (8)-(9):
(3)
- The probability of false alarm decreases exponentially as the
threshold τi increases,
dN =  H1
1−a and U ≈ ln 1−b
H0
if S(N ) ≥ U
if S(N ) ≤ L,
where L ≈ ln b
a , and where a is the desired
probability of false alarm and b is the desired probability of missed
detection (usually chosen as small values).
5.2.2 Change Detection
The goal of the change detection problem is to detect a possible
change, at an unknown change point ks.Cumulative sum (CUSUM)
and Shiryaev-Roberts statistics are the two most commonly used
algorithms for change detection problems. In this paper we use the
CUSUM statistic because it is very similar to the SPRT.
Given a ﬁxed false alarm rate, the CUSUM algorithm attempts to
minimize the time N (where N ≥ ks) for which the test stops and
decides that a change has occurred. Let S(0) = 0. The CUSUM
statistic is updated according to
S(k + 1) = log
p1(z(k))
p0(z(k))
+ S(k)+
(4)
where (a)+ = a if a ≥ 0 and zero otherwise. The stopping time
is:
N = inf
n
{n : S(n) ≥ τ }
(5)
for a given threshold τ selected based on the false alarm constraint.
We can see that the CUSUM algorithm is an SPRT test with L =
0, U = τ , and whenever the statistic reaches the lower threshold
L, it re-starts.
We now describe how to adapt the results of change detection
theory to the particular problem of detecting compromised sensors.
In the following, we use the subscript i to denote the sequence cor-
responding to sensor i.
One problem that we have in our case is that we do not know
the probability distribution for an attack p1. In general, an adaptive
adversary can select any arbitrary (and possibly) non-stationary se-
quence zi(k). Assuming a ﬁxed p1 will thus limit our ability to
detect a wide range of attacks.
To avoid making assumptions about the probability distribution
of an attacker, we use ideas from nonparametric statistics. We do
not assume a parametric distribution for p1 and p0; instead, only
place mild constraints on the observation sequence. One of the
simplest constraints is to assume the expected value of the random
process Zi(k) that generates the sequence zi(k) under H0 is less
than zero (E0[Zi]  0).
To achieve these conditions let us deﬁne
- The time to detect an attack, (Ni − ks,i)+, is inversely pro-
portional to bi.
5.3 Stealthy Attacks
A fundamental problem in intrusion detection is the existence of
adaptive adversaries that will attempt to evade the detection scheme;
therefore, we now consider an adversary that knows about our anomaly
detection scheme. We take a conservative approach in our models
by assuming a very powerful attacker with knowledge of: (1) the
exact linear model that we use (i.e., matrices A,B, and C), the pa-
rameters (τi and bi), and (3) the control command signals. Such
a powerful attacker may be unrealistic in some scenarios, but we
want to test the resiliency of our system to such an attacker to guar-
antee safety for a wide range of attack scenarios.
The goal of the attacker is to raise the pressure in the tank without
being detected (i.e., raise the pressure while keeping the statistic he
controls below the corresponding threshold τi).
We model three types of attacks: surge attacks, bias attacks and
geometric attacks. Surge attacks model attackers that want to achieve
maximum damage as soon as they get access to the system. A bias
attack models attackers that try to modify the system discretely by
adding small perturbations over a large period of time. Finally,
geometric attacks model attackers that try to shift the behavior of
the system very discretely at the beginning of the attack and then
maximize the damage after the system has been moved to a more
vulnerable state.
5.4 Surge Attacks
In a surge attack the adversary tries to maximize the damage as
soon as possible, but when the statistic reaches the threshold, it then
stays at the threshold level: Si(k) = τ for the remaining time of
the attack. To stay at the threshold, the attacker needs to solve the
following quadratic equation:
Si(k) +(ˆyi(k) − ˜yi(k))2 − bi = τi
The resulting attack (for y5 and y4) is:
˜yi(k) =  ymin
i
ˆyi(k) − |τi + bi − Si(k)|
For y7 we use
˜y7(k) =  ymax
7
ˆy7 + |τ7 + b7 − Sy7 (k)|
if Si(k + 1) ≤ τi
if Si(k + 1) > τi
if Sy7 (k) ≤ τ7
if Sy7 (k) > τ7
zi(k) := ˜yi(k) − ˆyi(k) − bi
(6)
5.5 Bias Attacks
361
In a bias attack the attacker adds a small constant ci at each time
step.
˜yi,k = ˆyi,k − ci ∈ Yi
In this case, the nonparametric CUSUM statistic can be written
as:
Si(n) =
n−1
k=0
|ˆyi(k) − ˜yi(k)| − nbi
Assuming the attack starts at time k = 0 and assuming the at-
tacker wants to be undetected for n time steps the attacker needs to
solve the following equation:
n−1
k=0
ci = τi + nbi
Therefore ci = τi/n + b. This attack creates a bias of τi/n + bi
for each attacked signal.
This equation shows the limitations of the attacker. If an attacker
wants to maximize the damage (maximize the bias of a signal), the
attacker needs to select the smallest n it can ﬁnd. Because ˜yi ∈ Yi
this attack reduces to an impulse attack.
If an attacker wants to attack for a long time, then n will be very
large. If n is very large then the bias will be smaller.
5.6 Geometric Attacks
In a geometric attack, the attacker wants to drift the value very
slowly at the beginning and maximize the damage at the end. This
attack combines the slow initial drift of the bias attack with a surge
attack at the end to cause maximum damage.
Let α ∈ (0, 1). The attack is:
˜yi(k) = ˆyi(k) − βiαn−k
i
.
Now we need to ﬁnd α and β such that Si(n) = τi.
Assume the attack starts at time k = 0 and the attacker wants to
be undetected for n time steps. The attacker then needs to solve the
following equation.
n−1
k=0
βiαn−k
i − nbi = τi
model when the operating conditions are reasonably close to the
steady-state.
5.7.2 Nonparametric CUSUM parameters
In order to select bi for each sensor i, we need to estimate the
expected value of the distance |ˆyi(k) − yi(k)| between the linear
model estimate ˆyi(k) and the sensor measurement yi(k) (i.e., the
sensor signal without attacks).
y
4
X: 0.015
Y: 9951
15000
10000
5000
4
x 10
y
7
X: 0.015
Y: 1.911e+004
4
x 10
y
5
X: 1.5
Y: 1.818e+004
2.5
2
1.5
1
0.5
2.5
2
1.5
1
0.5
0
−0.1
0
0.1
0.2
0
−10
0
10
20
30
0
−0.1
0
0.1
0.2
Figure 4: The paramenter of ADM: b. For y4, 9951 bs are
0.015. The mean value of by4 is 0.0642.
We run experiments for ten thousand times (and for 40 hours
each time) without any attacks to gather statistics. Fig 4 shows the
estimated probability distributions (without normalization).
To obtain bi, we compute the empirical expected value for each
distance and then round up to the two most signiﬁcant units. We
obtain by4 = 0.065, by5 = 4.1, by7 = 0.042.
Once we have bi for each sensor, we need to ﬁnd a threshold τi
to balance the tradeoff between false alarms and detection time.
False Alarm Rate.
We run simulations for twenty times without attacks and com-
pute the total number of false alarms for different values of τ (and
for each sensor). Fig 5 shows the results. Taking y4 as an example,
we notice that Sy4 alerts frequently if we set τy4 < 6.
20
15
10
5
0
0
y
4
y
5
20
15
10
5
X: 4900
Y: 1
l
m
r
a
a
e
s
a
f
l
X: 7
Y: 1
20
15
10
5
l
m
r
a
a
e
s
a
f
l
10
20
30
40
50
tau
0
0
2500
7500
10000
5000
tau
0
0
25
y
7
X: 44
Y: 1
50
tau
75
This addition is a geometric progression.
n−1
k=0
βiαn−k
i
= βiαn
i
n−1
(α−1
i
)k = βi
k=0
1 − αn
i
α−1
i − 1
By ﬁxing α the attacker can select the appropriate β to satisfy the
above equation.
5.7 Experiments
We continue our use of the TE-PCS model. In this section we
ﬁrst describe our selection criteria for matrices A, B, and C for
the linear model, and the parameters bi and τi for the CUSUM
statistic. We then describe the tradeoffs between false alarm rates