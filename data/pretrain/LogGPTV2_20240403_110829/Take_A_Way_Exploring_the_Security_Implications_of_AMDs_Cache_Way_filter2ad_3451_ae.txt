178
173
175
179
197
180
174
180
177
177
177
176
172
166
170
177
183
167
180
179
182
196
176
181
185
180
166
172
177
175
182
188
169
183
171
180
182
176
194
178
178
174
167
182
175
182
174
177
174
178
174
184
182
184
177
193
186
180
173
177
176
171
181
182
184
161
172
175
178
174
172
181
196
183
179
182
182
175
176
179
182
172
182
176
181
179
171
178
175
189
164
177
176
172
175
174
164
177
183
175
171
179
172
172
182
173
196
180
174
189
179
182
169
179
175
179
177
170
168
180
174
178
179
189
182
178
186
179
179
179
182
185
185
169
178
165
177
169
167
174
197
171
177
184
174
171
172
176
180
171
169
178
182
178
177
182
183
195
166
172
182
175
178
168
185
179
171
177
173
189
179
190
185
182
195
175
178
186
184
171
177
180
173
179
176
174
180
176
184
169
178
195
179
172
169
178
187
172
164
171
180
178
180
173
174
183
175
181
196
175
174
185
173
179
175
179
182
182
175
178
177
172
170
176
178
185
187
179
180
181
180
174
180
179
175
182
181
172
179
181
170
176
186
s
s
e
r
d
d
A
00 10 20 30 40 50 60 70 80 90 a0 b0 c0 d0 e0 f0
00 10 20 30 40 50 60 70 80 90 a0 b0 c0 d0 e0 f0
Byte value
Byte value
(a) Collide+Probe
(b) Load+Reload
Figure 5: Cache access pattern with Collide+Probe and Load+
Reload on the first key byte.
higher number of cache hits than the other parts of the table. We
repeated every experiment 1000 times. With Collide+Probe, we can
successfully recover with a probability of 100 % (σ ¯x = 0) the upper
4 bits of each ki with 168 867 (σ ¯x = 719) encryptions per byte in
0.07 s (σ ¯x = 0.0003). With Load+Reload, we require 367 731 (σ ¯x =
82388) encryptions and an average runtime of 0.53 s (σ ¯x = 0.11) to
recover 99.0 % (σ ¯x = 0.0058) of the key bits. Using Prime+Probe on
the L1 cache, we can successfully recover 99.7 % (σ ¯x = 0.01) of the
key bits with 450 406 encryptions (σ ¯x = 1129) in 1.23 s (σ ¯x = 0.003).
6 DISCUSSION
While the official documentation of the way prediction feature
does not explain how it interacts with other processor features, we
discuss the interactions with instruction caches, transient execution,
and hypervisors.
Instruction Caches. The patent [23] describes that AMD’s way
predictor can be used for both data and instruction cache. However,
AMD only documents a way predictor for the L1D cache [8] and
not for the L1I cache.
Transient Execution. Speculative execution is a crucial optimiza-
tion in modern processors. When the CPU encounters a branch,
instead of waiting for the branch condition, the CPU guesses the
outcome and continues the execution in a transient state. If the
speculation was correct, the executed instructions are committed.
Otherwise, they are discarded. Similarly, CPUs employ out-of-order
execution to transiently execute instructions ahead of time as soon
as their dependencies are fulfilled. On an exception, the transiently
executed instructions following the exception are simply discarded,
but leave traces in the microarchitectural state [17]. We investi-
gated the possibility that AMD Zen processors use the data from
the predicted way without waiting for the physical tag returned by
the TLB. However, we were not able to produce any such results.
Hypervisor. AMD does not document any interactions of the way
predictor with virtualization. As we have shown in our experiments
(cf. Section 5.2), the way predictor does not distinguish between
virtual machines and hypervisors. The way predictor uses the vir-
tual address without any tagging, regardless whether it is a guest
or host virtual address.
Take A Way: Exploring the Security Implications of AMD’s Cache Way Predictors
ASIA CCS ’20, June 1–5, 2020, Taipei, Taiwan
7 COUNTERMEASURES
In this section, we discuss mitigations to the presented attacks on
AMD’s way predictor. We first discuss hardware-only mitigations,
followed by mitigations requiring hardware and software changes,
as well as a software-only solution.
Temporarily Disable Way Predictor. One solution lies in designing
the processor in a way that allows temporarily disabling the way
predictor temporarily. Alves et al. [4] evaluated the performance
impact penalty of instruction replays caused by mispredictions. By
dynamically disabling way prediction, they observe a higher perfor-
mance than with standard way prediction. Dynamically disabling
way prediction can also be used to prevent attacks by disabling
it if too many mispredictions within a defined time window are
detected. If an adversary tries to exploit the way predictor or if
the current legitimate workload provokes too many conflicts, the
processor deactivates the way predictor and falls back to compar-
ing the tags from all ways. However, it is unknown whether AMD
processors support this in hardware, and there is no documented
operating system interface to it.
Keyed Hash Function. The currently used mapping functions (Sec-
tion 3) rely solely on bits of the virtual address. This allows an
attacker to reverse-engineer the used function once and easily find
colliding virtual addresses resulting in the same µTag. By keying the
mapping function with an additional process- or context-dependent
secret input, a reverse-engineered hash function is only valid for the
attacker process. ScatterCache [77] and CEASAR-S [61] are novel
cache designs preventing cache attacks by introducing a similar
keyed mapping function for skewed-associative caches. Hence, we
expect that such methods are also effective when used for the way
predictor. Moreover, the key can be updated regularly, e.g., when
returning from the kernel, and, thus, not remain the same over the
execution time of the program.
State Flushing. With Collide+Probe, an attacker cannot monitor
memory accesses of a victim running on a sibling thread. However,
µTag collisions can still be observed after context switches or tran-
sitions between kernel and user mode. To mitigate Collide+Probe,
the state of the way predictor can be cleared when switching to
another user-space application or returning from the kernel. Ev-
ery subsequent memory access yields a misprediction and is thus
served from the L2 data cache. This yields the same result as invali-
dating the L1 data cache, which is currently a required mitigation
technique against Foreshadow [74] and MDS attacks [16, 68, 75].
However, we expect it to be more power-efficient than flushing the
L1D. To mitigate Spectre attacks [41, 44, 51], it is already neces-
sary to invalidate branch predictors upon context switches [17]. As
invalidating predictors and the L1D cache on Intel has been imple-
mented through CPU microcode updates, introducing an MSR to
invalidate the way predictor might be possible on AMD as well.
Uniformly-distributed Collisions. While the previously described
countermeasures rely on either microcode updates or hardware
modifications, we also propose an entirely software-based miti-
gation. Our attack on an optimized AES T-table implementation
in Section 5.4 relies on the fact that an attacker can observe the key-
dependent look-ups to the T-tables. We propose to map such secret
data n times, such that the data is accessible via n different virtual
addresses, which all have a different µTag. When accessing the data,
a random address is chosen out of the n possible addresses. The at-
tacker cannot learn which T-table has been accessed by monitoring
the accessed µTags, as a uniform distribution over all possibilities
will be observed. This technique is not restricted to T-table imple-
mentations but can be applied to virtually any secret-dependent
memory access within an application. With dynamic software di-
versity [19], diversified replicas of program parts are generated
automatically to thwart cache-side channel attacks.
8 CONCLUSION
The key takeaway of this paper is that AMD’s cache way predictors
leak secret information. To understand the implementation details,
we reverse engineered AMD’s L1D cache way predictor, leading
to two novel side-channel attack techniques. First, Collide+Probe
allows monitoring memory accesses on the current logical core
without the knowledge of physical addresses or shared memory.
Second, Load+Reload obtains accurate memory-access traces of
applications co-located on the same physical core.
We evaluated our new attack techniques in different scenarios.
We established a high-speed covert channel and utilized it in a
Spectre attack to leak secret data from the kernel. Furthermore,
we reduced the entropy of different ASLR implementations from
native code and sandboxed JavaScript. Finally, we recovered a key
from a vulnerable AES implementation.
Our attacks demonstrate that AMD’s design is vulnerable to side-
channel attacks. However, we propose countermeasures in software
and hardware, allowing to secure existing implementations and
future designs of way predictors.
ACKNOWLEDGMENTS
We thank our anonymous reviewers for their comments and sugges-