A.1 Overview
We follow a standard game-based approach for deﬁning secu-
rity. We describe a game between an adversary and challenger.
The adversary controls the communication medium, and is al-
lowed to schedule the actions of legitimate users. For example,
the adversary can instruct a legitimate user to run GenBeacon
to generate a discovery beacon; or instruct a recipient to receive
the beacon(s) and call Recognize to determine the linkability
of discovered neighbors. The adversary can also instruct a le-
gitimate user to perform handshake with any member of the
compromised coalition. Link identiﬁers generated during such
a handshake (with the adversary) are marked as compromised
(i.e., known to the adversary). In addition, the adversary can ex-
plicitly compromise an encounter between two legitimate users
in which case the secret link identiﬁer and shared key are ex-
posed; or explicitly compromise a user in which case all its
internal states, including previous link identiﬁers, are exposed.
At some point during the game, the adversary will issue a
challenge, either an anonymity challenge or a conﬁdentiality
challenge.
An anonymity challenge intuitively captures the notion that
an adversary cannot break a legitimate user’s anonymity, unless
the legitimate user has authorized linkability to a party within
the adversary’s coalition. Note that this part of the deﬁnition
captures the unlinkability, selective linkability, and revocability
requirements (See Section 3.1) simultaneously.
A conﬁdentiality challenge intuitively captures the notion
that an eavesdropping cannot learn anything about the (online
or post-hoc) communication in between two legitimate users.
This is guaranteed since for any two users that remain uncom-
promised at the end of the security, their shared key established
for some time epoch t is as good as “random” to the adversary
(assuming their encounter in time epoch t also remains uncom-
promised by the end of the security game).
A.2 Formal Security Deﬁnitions
We deﬁne the following security game between and an adver-
sary A and a challenger C . The time epoch t is initialized to 0
at the beginning of the game. The adversary adaptively makes
a sequence of queries as below.
Next time epoch. Increments the current time epoch t.
Expose handshake beacons. The adversary speciﬁes an un-
compromised user Pi, identiﬁers of a subset Si of Pi’s previous
encounters, and asks the challenger to expose Pi’s handshake
beacon in the current time step t using the subset of previous
encounters Si.
Handshake - Uncompromised users. The adversary speci-
ﬁes two uncompromised users Pi and Pj, such that Pj can hear
Pi in the current time epoch t. After receiving Pi’s handshake
beacon, Pj calls the Recognize algorithm, and updates its local
state accordingly. The adversary does not obtain information
from the challenger for this query.
Handshake - Adversary. The adversary sends a handshake
beacon to an uncompromised user Pi. Pi calls the Recognize
algorithm, and updates its local state. The identiﬁer of this en-
counter is marked as compromised. The adversary does not
obtain any information from the challenger for this query.
Compromise - Encounter. The adversary speciﬁes a reference
to an encounter which took place in time t(cid:31) ≤ t between two
uncompromised users Pi and Pj, and the challenger reveals to
the adversary the corresponding link identiﬁer, encounter key,
and any additional information associated with this encounter.
Compromise - User. The adversary speciﬁes an uncompro-
mised user Pi. The adversary learns all Pi’s internal state, in-
cluding the list of all previous link identiﬁers, encounter keys,
received beacons, and any additional information associated
with Pi’s previous encounters3. Pi and all of its link identiﬁers
are marked as compromised.
Challenge. There can only be one challenge query in the entire
game, of one of the following types. In both cases, the adver-
sary outputs a guess b(cid:31) of b selected by the challenger.
• Anonymity. Adversary speciﬁes two users Pi and Pj who
must remain uncompromised at the end of the game. The ad-
versary speciﬁes Si and S j to the challenger, which (respec-
tively) denote a subset of Pi’s and Pj’s previous encounters
that must remain uncompromised at the end of the game. We
require that |Si| = |S j|. Furthermore, at the end of the game,
the adversary must not have issued an “expose handshake
beacon” query in the current time step for Pi (or Pj) involv-
ing any element in the subset Si (or S j).
The challenger ﬂips a random coin b. If b = 0, the challenger
constructs Pi’s handshake beacon for the current time epoch
t for the set Si, and returns it to adversary.
If b = 1, the
challenger constructs Pj’s handshake beacon for the set S j,
and returns it to adversary.
• Conﬁdentiality. The adversary speciﬁes two users Pi and
Pj who must remain uncompromised at the end of the game.
3Speciﬁc to our construction, the internal states also include the
exponents of Pi’s own DH beacons in all previous time epochs.
938  23rd USENIX Security Symposium 
USENIX Association
Furthermore, the encounter between Pi and Pj during time
epoch t must also remain uncompromised at the end of the
game.
The challenger ﬂips a random coin b. If b = 0, challenger
returns the encounter key ski j established between Pi and Pj
in time epoch t. If b = 1, challenger returns a random number
(from an appropriate range).
Deﬁnition 1 (Anonymity, Selective linkability). Suppose that
the adversary A makes a single anonymity challenge in the
above security game. The advantage of such an adversary
A is deﬁned as Advlink(A ) := |Pr[b(cid:30) = b]− 1
2|. We say that
our handshake protocol satisﬁes selective linkability, if the ad-
vantage of any polynomially bounded adversary (making an
anonymity challenge) in the above game is a negligible func-
tion in the security parameter.
Deﬁnition 2 (Conﬁdentiality). Suppose that the adversary A
makes a single conﬁdentiality challenge in the above security
game. The advantage of such an adversary A is deﬁned as
Adv(A )conf := |Pr[b(cid:30) = b]− 1
2|. We say that our handshake
protocol satisﬁes conﬁdentiality, if the advantage of any poly-
nomially bounded adversary (making a conﬁdentiality chal-
lenge) in the above game is a negligible function in the security
parameter.
A.3 Proofs of Security
Theorem 1 (Anonymity, selective linkability). Assume that the
CDH problem is hard. For any polynomial-time algorithm A ,
under the random oracle model,
Advlink(A ) ≤ negl(λ )
where λ is the security parameter.
ε
Proof. If there is an adversary that can break the anonymity
game with probability ε, we can construct a simulator which
breaks CDH assumption with probability
poly(N,T,qo) , where N
denotes the total number of users, T denotes the total number
of epochs, and qo denotes the number of random oracle queries.
Revealing hashes instead of Bloom ﬁlter
In the challenge
stage, the Pi∗’s Bloom ﬁlter will have m elements. Instead of an-
nouncing the Bloom ﬁlter, we assume for the proof that users
simply broadcast the outcomes of the hash functions used to
construct the Bloom ﬁlter. This will only reveal more informa-
tion to the adversary – so as long as we can prove the secu-
rity when these hashes are revealed, we immediately guarantee
security when the Bloom ﬁlter instead of the hash values are
revealed.
Real-or-random version and sequence of hybrid games
Instead of proving the left-or-right version of the game as in
the security deﬁnition, we prove the real-or-random version.
Namely, the adversary speciﬁes one user Pi (instead of two) in
the anonymity challenge (who must remain uncompromised at
the end of the game), as well as a subset of Pi’s previous en-
counters (which must remain uncompromised at the end of the
game). The challenger ﬂips a random coin, and either returns
the faithful hash values to the adversary, or returns a list of ran-
dom values from an appropriate range. The adversary’s job is
to distinguish which case it is.
We use a sequence of hybrid games. In the k-th game, re-
place the k-th hash (out of m hashes) in the challenge stage
with some random value from an appropriate range.
Simulator construction The simulator obtains a CDH in-
stance gα ,gβ . The simulator guesses that the k-th encounter
in the anonymity challenge took place between users Pi∗ and
P(cid:31)i∗ in time step τ. If the guess turns out to be wrong later, the
simulator simply aborts. The simulator answers the following
queries:
Expose handshake beacons. First, the simulator generates the
τ, the simulator generates all other DH beacons normally. For
DH beacons as below: except for users Pi∗ and P(cid:31)i∗ in time step
Pi∗ and P(cid:31)i∗ in time step τ, their DH beacons will incorporate gα
and gβ respectively. Notice that the simulator does not know α,
β , or the dhk := gαβ . Except for gαβ , the simulator can com-
pute all other dhks between two uncompromised users (even
when one of gα or gβ is involved) since the simulator knows
the exponent of at least one DH beacon.
In generating the hashes for the Bloom ﬁlter, each hash can
correspond to an encounter of the following types:
• Case 1: The hash does not involve an encounter in time τ.
The simulator can compute the dhk and link identiﬁer nor-
mally in this case.
• Case 2: The hash corresponds to an encounter in time τ, but
at least one of the parties in the encounter is an uncompro-
mised user (at the time of the challenge query) other than
the dhk = gαβ .
hence the link identiﬁer) in this case, since the simulator
knows the exponent of the DH beacon of the other party.
Pi∗, P(cid:31)i∗. Notice that the simulator can compute the dhk (and
• Case 3: The hash corresponds to an encounter in time τ, and
between Pi∗ and P(cid:31)i∗. In this case, the simulator does not know
• Case 4: The hash corresponds to an encounter in time τ,
and between Pi∗ (or P(cid:31)i∗) and the adversary. Suppose in this
encounter in question, the adversary sent Pi∗ the DH beacon
gγ. (The case for P(cid:31)i∗ is similar and omitted). The simulator
does not know the dhk = gαγ in this case.
Regardless of which type of encounter the hash corresponds
to, as long as the simulator knows the dhk of this encounter, it
can compute the link identiﬁer and Bloom ﬁlters. Below, when
we explain how to answer queries of the types “Handshake -
Uncompromised users” and “Handshake - Adversary”, we will
explain how the simulator generates and records a link identi-
ﬁer for each of these encounters – even when it may not know
the dhk (Cases 3 and 4). In this way, the simulator can answer
queries for Cases 3 and 4 as well.
Handshake - Uncompromised users. Except for the en-
counter between Pi∗ and P(cid:31)i∗ in time epoch τ, for all other en-
counters, the simulator can compute the resulting dhks for both
uncompromised users – even when one of gα or gβ is involved.
Therefore, the simulator computes and saves the dhk, which
may later be used in answering “expose handshake beacon”
queries.
For the encounter between Pi∗ and P(cid:31)i∗ in time τ, since the
simulator does not know dhk := gαβ , it simply chooses a ran-
dom link identiﬁer and saves it internally, which will later be
USENIX Association  
23rd USENIX Security Symposium  939
used in answer “Expose handshake beacon” queries to con-
struct Bloom ﬁlters.
Handshake - Adversary. Except when time step τ and user
be done. Assume the adversary sends Pi∗ handshake beacon gγ
generate and dhk and other secrets that are derived as hashes of
the dhk.
Pi∗ or P(cid:31)i∗ are involved, the simulator can proceed normally, and
For time step τ, and Pi∗ or P(cid:31)i∗, something special needs to
(the case for P(cid:31)i∗ is similar and omitted). The simulator does
not know α or γ, hence it cannot compute the corresponding
dhk := gαγ. Without loss of generality, assume gα < gγ. The
simulator picks a random link identiﬁer L∗ – intended to be the
link identiﬁer for this encounter with the adversary. The simu-
lator saves L∗, which will later be used in answering “Expose
handshake beacon” queries.
The simulator informs the random hash oracle of the tuple
(L∗, gα, gγ). Later, random oracle may receive multiple queries
of the form H0(gα||gγ||Z). Suppose there are at most qo of
these queries. With probability 1
qo+1 , the hash oracle never uses
encK∗ as the answer. With probability 1− 1
qo+1 , the hash or-
acle guesses one of these queries at random, and uses L∗ as
the answer. The simulator guesses correctly with probability at
least
Compromise - Encounter. The adversary speciﬁes a reference
to a previous encounter (i, j,t(cid:28)), where users Pi and Pj are un-
1
qo+1 where qo is the number of hash oracle queries.
simulator answers the query normally.
erwise the simulator would have aborted. If one of i or j is
knowing α or β – since the simulator knows the exponent of
the other player’s DH beacon.
Compromise - User. If the adversary issues this query for user
compromised thus far. If i and j are not i∗ or(cid:31)i∗, or t(cid:28) (cid:27)= τ, the
If t(cid:28) = τ, i and j cannot simultaneously be i∗ and (cid:31)i∗, oth-
i∗ or (cid:31)i∗, the simulator can still answer the query, even without
Pi∗ or P(cid:31)i∗, the simulator simply aborts. For all other uses, the
query can be answered normally.
Random oracle. Above, we mentioned how the random oracle
handles queries of the form H0(gα||gγ||Z), where gγ was a DH
beacon from the adversary in a “Handshake - Adversary” query.
For all other random oracle queries, the simulator picks random
numbers to answer. The simulator records previous random
oracle queries, so in case of a duplicate query, the same answer
is given. Whenever the simulator needs to evaluate the hash
function, it also queries its own random oracle.
Challenge - Anonymity. The Bloom ﬁlter hash values re-
quested in the challenge stage must not have been queried in
an “Expose handshake beacon” query. In the k-th hybrid game,
the simulator outputs random values for the ﬁrst k hashes. For
the rest, the simulator constructs the answers normally – since
these encounters happened before time τ, the simulator can
compute their link identiﬁers and compute these hashes nor-
mally.
Without loss of generality, assume that gα < gβ .
In the
above simulation, the simulator makes all guesses correctly
with probability at least
poly(N,T,qo) . Conditioned on the fact
1
that the simulator made all guesses correctly, unless the ad-
versary queried H0(gα||gβ||gαβ ), the (k − 1)-th and k-th hy-
brid games are information theoretically indistinguishable from
each other to the adversary. Now the adversary cannot have
queried at any point H0(gα||gβ||gαβ ) with more than negligi-
ble probability, since otherwise we can construct a simulator
that outputs gαβ with non-negligible probability, thus breaking
the CDH assumption.
Theorem 2 (Conﬁdentiality). Assume that the CDH problem
is hard. For any PPT algorithm A , under the random oracle
model,
Advconf (A ) ≤ negl(λ )
where λ is the security parameter.
Proof. The simulator guesses that the adversary will issue a
conﬁdentiality between users Pi∗ and P(cid:31)i∗ in time epoch τ. If the
guess turns out to be wrong later, the simulator simply aborts.
Suppose that simulator gets a CDH instance (gα ,gβ ). The
simulator would then answer all queries exactly as in the proof
of Theorem 1, except for the challenge – instead of submitting
a anonymity challenge, the adversary now submits a conﬁden-
tiality challenge:
Challenge - Conﬁdentiality. If i, j, and current time epoch τ
does not agree with what the simulator had guessed, the simu-
lator simply aborts. Otherwise, the simulator would have cho-
sen a random link identiﬁer in a “Handshake - Uncompromised
users” query for (i∗,(cid:31)i∗,τ). The encounter key of this session is
obtained by making a random oracle query on H2(L).
The simulator makes all guesses correctly with probability
at least
poly(N,T,qo) . Conditioned on the fact that all guesses are
correct, the encounter key returned in the challenge stage is in-
formation theoretically indistinguishable from random, unless
the adversary has queried H0(gα||gβ||gαβ ) (assuming gα < gβ
without loss of generality). However, if the adversary makes
such a random oracle query with non-negligible probability, we
can construct a simulation that leverages the adversary to break
the CDH assumption.
1
A.4 Co-Linking
Proposition 1. Any non-interactive handshake protocol must
be subject to a co-linking attack.
Proof. In an non-interactive protocol, a user Alice publishes a
message M in a certain time epoch. Suppose Bob and Charles
have met Alice before (in encounters with link-ids L and L(cid:28)
respectively), and Alice has granted both of them permission
to link her. Bob should be able to derive from his secret state
and the message M, the link identiﬁer L linking this encounter
to the previous encounter L. Similarly, with his secret state and
the message M, Charles should also be able to derive L(cid:28). Now
trivially, if Bob and Charles collude, they can decide that the
message M can be linked to previous encounters L and L(cid:28).
940  23rd USENIX Security Symposium 
USENIX Association