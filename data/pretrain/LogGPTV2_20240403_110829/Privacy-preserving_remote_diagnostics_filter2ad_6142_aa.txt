title:Privacy-preserving remote diagnostics
author:Justin Brickell and
Donald E. Porter and
Vitaly Shmatikov and
Emmett Witchel
Privacy-Preserving Remote Diagnostics
Justin Brickell
Donald E. Porter
Vitaly Shmatikov
Emmett Witchel
The University of Texas at Austin
{jlbrick,porterde,shmat,witchel}@cs.utexas.edu
ABSTRACT
We present an efﬁcient protocol for privacy-preserving evaluation
of diagnostic programs, represented as binary decision trees or
branching programs. The protocol applies a branching diagnos-
tic program with classiﬁcation labels in the leaves to the user’s
attribute vector. The user learns only the label assigned by the
program to his vector; the diagnostic program itself remains secret.
The program’s owner does not learn anything. Our construc-
tion is signiﬁcantly more efﬁcient than those obtained by direct
application of generic secure multi-party computation techniques.
We use our protocol to implement a privacy-preserving version
of the Clarify system for software fault diagnosis, and demonstrate
that its performance is acceptable for many practical scenarios.
Categories and Subject Descriptors
E.3 [Data]: Data Encryption; I.2.1 [Artiﬁcial Intelligence]: Ap-
plications and Expert Systems
General Terms
Algorithms, Security, Performance
Keywords
Privacy, Data Mining, Diagnostics, Branching Programs
1.
INTRODUCTION
Diagnostic programs, typically represented as decision trees or
binary branching programs, are the cornerstone of expert systems
and data analysis tools. Learning and evaluating diagnostic pro-
grams which classify data on the basis of certain features are among
the most fundamental data mining tasks.
Evaluation of a diagnostic program on a remote user’s data of-
ten presents privacy risks to both the user and the program’s owner.
The program’s owner may not want the user to learn the entire con-
tents of the diagnostic program, while the user may not want to
reveal his local data to the program’s owner. For example, con-
sider a medical expert system, where the diagnostic program is the
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’07, October 29–November 2, 2007, Alexandria, Virginia, USA.
Copyright 2007 ACM 978-1-59593-703-2/07/0010...$5.00.
realization of a substantial investment, and the data on which the
program is evaluated contain information about the user’s health.
Another example is remote software fault diagnosis, which is an
increasingly popular support method for complex applications. The
details of remote software diagnostic systems differ (see Section 5),
but there are many commonalities. An application does something
undesirable (crashes, becomes slow or unresponsive, quits with an
obscure error message), and the runtime system gathers some data
about the problem. The software manufacturer uses this informa-
tion to diagnose the problem, usually by reading a small subset of
the data. Users are typically required to ship all fault-related data to
the manufacturer. For example, most users of Microsoft Windows
have encountered the (in)famous “send error report” button.
The data gathered by the runtime system may contain sensitive
information, such as passwords and snippets of the user’s docu-
ments. Many users are not willing to reveal this information to
the software manufacturer. On the other hand, software manufac-
turers often view their proprietary diagnostic programs as valuable
intellectual property. Diagnostic programs may reveal the applica-
tion’s support history, unpatched security vulnerabilities, and other
information about the implementation and internal structure of the
application that the manufacturer may prefer to keep secret.
This paper describes a method for privacy-preserving evaluation
of diagnostic branching programs. This problem is different from
privacy-preserving learning of decision trees, which has been the
subject of much research [1, 4, 22]. We assume that the diagnostic
program already exists, in the form of a binary decision tree or
branching program, and investigate how to apply it to the user’s
data in such a way that the program is not revealed to the user, and
the user’s data are not revealed to the program’s owner.
Our contributions. We present a practical, provably secure inter-
active protocol for privacy-preserving evaluation of branching pro-
grams. The protocol takes place between a Server, in possession
of a binary branching program T , and a User, in possession of an
attribute vector v. The User learns c = T (v), the diagnostic label
that T assigns to v. The Server may or may not learn the label—we
consider both variants.
Our protocol does not reveal any useful information except the
outcome of the computation, which is the diagnostic label in this
case. In particular, the User does not learn how the branching pro-
gram arrived at the diagnosis, nor which of the User’s attributes
it considered, nor the topology of the branching program, nor any
other diagnostic labels that it may contain. The Server, on the other
hand, learns nothing whatsoever about the User’s local data.
We emphasize the strong privacy properties achieved by our pro-
tocol. For example, secrecy of the program being evaluated is
not the standard requirement of secure multi-party computation,
which usually assumes that the program is public, and only the par-
498ties’ respective inputs are secret. In many of our applications, the
user should not learn which of his attributes are considered by the
branching program. If the attribute vector is very large (as is the
case, for example, in software fault diagnostics, where the attribute
vector is a record of the user’s runtime environment), achieving
these security properties efﬁciently is a difﬁcult challenge.
Our branching program evaluation protocol combines in a novel
way several cryptographic techniques such as homomorphic en-
cryption, blinding, and Yao’s “garbled circuits” method. Yao’s
method is used in a somewhat unusual way, not simply as a black-
box realization of secure circuit evaluation. We exploit the details
of circuit representation in Yao’s protocol to implement a condi-
tional oblivious transfer primitive needed by our protocol.
We present a substantial case study, in which we use our method
to implement a privacy-preserving version of Clarify [17], a system
for remote diagnosis of software faults. We apply our protocol to
the decision trees generated by Clarify for several large, real-world
applications such as gcc and latex, and demonstrate that its per-
formance is efﬁcient for many practical scenarios.
While there have been many theoretical results in the ﬁeld of
secure multi-party computation, actual implementations and work-
ing systems are extremely rare. Experimental evaluation of our
prototype implementation demonstrates that our protocol performs
signiﬁcantly better than the generic methods.
The paper is organized as follows. We describe related work
in Section 2, and our cryptographic toolkit in Section 3. In Sec-
tion 4, we present our protocol. In Section 5, we apply it to privacy-
preserving software fault diagnosis, and analyze its performance in
Section 6. Conclusions are in Section 7.
2. RELATED WORK
This paper follows a long tradition of research in the secure
multi-party computation (SMC) paradigm. Informally, security of
a protocol in the SMC paradigm is deﬁned as computational in-
distinguishability from a simulation of some ideal functionality, in
which the trusted third party accepts the parties’ inputs and carries
out the computation. Formal deﬁnitions for various settings can be
found, for example, in [2, 7, 15].
Any probabilistic polynomial-time multi-party computation,
represented as a circuit or a binary decision diagram, can be con-
verted into a “privacy-preserving” one using generic techniques
of Yao [40] and Goldreich et al. [16]. Generic constructions,
however,
tend to be impractical due to their complexity (e.g.,
see the comparison of our techniques with the generic approach
in Section 4.5). Recent research has focused on ﬁnding more
efﬁcient privacy-preserving algorithms for problems such as com-
putation of approximations [10], auctions [31], set matching and
intersection [12], surveys [11], and various data mining problems.
Some SMC research has used branching programs instead of cir-
cuits as function representation [14,29]. It is still the case, however,
that when computing f (x, y) securely, f is assumed to be known
to both parties, while x and y are their private inputs. In our sce-
nario, we are computing g(y), where g is the private input of the
ﬁrst party and y is the private input of the second party. This can
be implemented by making f a generic function evaluator and x a
description of the particular function g. As we show in Section 4.5,
this approach does not scale to the size of branching programs that
arise in real-world applications. Selective private function evalu-
ation [8] considers evaluation of functions on large datasets, but
the functions are much simpler than the branching programs con-
sidered in this paper. To achieve practical efﬁciency, our protocol
fundamentally relies on the structure of branching programs.
Many papers investigated the problem of privacy-preserving de-
cision tree learning, both in cryptographic [22] and statistical [1,4]
settings. Decision tree learning is a machine learning technique for
building a compact classiﬁer that best represents a set of labeled ex-
amples. The problem considered in this paper is privacy-preserving
evaluation of decision trees and branching programs, which is fun-
damentally different (and complementary) to the problem of tree
learning. For example, in our protocol the tree is an input, whereas
in the privacy-preserving learning protocols the tree is the output.
Concurrently and independently of this work, Ishai and Paskin
presented a protocol for evaluating a branching program P on an
encrypted input x in such a way that only P (x) is revealed to the
evaluator [19]. The representation of P must contain only single-
bit decision nodes and output a single bit. This protocol appears im-
practical for scenarios such as remote software diagnostics where
the user’s input contains thousands of 32-bit values.
Crypto-computing [36] considers the problem of a circuit owner
obliviously evaluating the circuit on encrypted inputs. While in our
construction the User evaluates an encrypted branching program, in
the crypto-computing paradigm the Server would perform the com-
putation on the encrypted attribute vector. It is not clear whether the
theoretical techniques of [36] lend themselves to a practical imple-
mentation, and shifting the burden of evaluation to the Server is not
desirable in practical applications.
Several papers considered problems which are superﬁcially sim-
ilar to our remote software diagnostics scenario. The Scrash sys-
tem [5] removes sensitive information from the crash data, thus en-
abling users who are concerned about privacy to assist in building
a software crash diagnostic. Scrash requires re-compilation, and
assumes that users have access to the program’s source code. By
contrast, we focus on privacy-preserving evaluation of “black-box”
fault diagnosis programs. Unlike Scrash, our system can be applied
to commercial software applications, which are compiled without
symbols and distributed without source code.
The Friends Troubleshooting Network system [18, 38] allows
participants in a trust network to collaborate in order to diagnose
software errors. By contrast, we assume that the diagnostic tool is
controlled by a single party (e.g., the software manufacturer). Fur-
thermore, our protocol is cryptographically secure.
3. CRYPTOGRAPHIC TOOLS
3.1 Oblivious transfer
Oblivious transfer (OT) is a fundamental cryptographic primi-
tive [21, 35]. A 1-out-of-2 oblivious transfer, denoted as OT 1
2 , is
a protocol between two parties, the Chooser and the Sender. The
Chooser’s input is the index i ∈ {0, 1}. The Sender’s inputs are
the values x0, x1. As a result of the protocol, the Chooser learns xi
(and only xi), while the Sender learns nothing.
2 [30]. Each instance of OT 1
In our constructions, we use oblivious transfer as a “black-box”
primitive, i.e., our constructions do not depend on a particular OT
In our implementations, we employ the Naor-
implementation.
Pinkas constructions for OT 1
2 re-
quires one online and one ofﬂine modular exponentiation for the
sender, and one online and one ofﬂine modular exponentiation for
the chooser. Amortization techniques of [30] can achieve fewer
than one exponentiation per oblivious transfer, but reducing the
number of exponentiations by more than a constant factor requires
an impractical increase in the communication complexity.
3.2 Homomorphic encryption
A homomorphic encryption scheme is a semantically secure
cryptosystem that permits algebraic manipulations on plaintexts
given their respective ciphertexts. In this paper, we require an en-
cryption scheme with an additively homomorphic property, which
allows E[x1 + x2] to be computed from E[x1] and E[x2].
In our prototype implementation, we use the Paillier cryptosys-
tem [34]. This is sufﬁcient when the participants are semi-honest.
If security against malicious participants is required, the homomor-
phic encryption scheme needs the additional property of veriﬁa-
bility: there should exist efﬁcient zero-knowledge proof systems
which enable a participant to prove certain relationships between
the encrypted plaintexts and previously committed values (see Sec-
tion 4.4). Such efﬁcient proof systems are not known for the Paillier
cryptosystem. In the malicious case, the protocol should be imple-
mented with a homomorphic, veriﬁable cryptosystem, e.g., the ho-
momorphic version of the Camenisch-Shoup cryptosystem [6, 20].
3.3 Garbled circuits
Garbled circuits are a fundamental technique in secure multi-
party computation. Originally proposed by Yao [40], the garbled
circuits method enables secure constant-round computation of any
two-party functionality. We only give a brief overview here; a de-
tailed explanation can be found in [23].
Let C be a boolean circuit which receives two n-bit inputs x =
x 1  . . . xn  and  y  =  y 1  . . . yn ,  a nd  out put s  bi t  C (x, y )  ∈ {0,  1}.  (If
t he  c i r cui t  t a ke s  onl y  one  i nput ,  w e  denot e  t he  ot her  i nput  as  ⊥ .)
Consider Alice and Bob who wish to securely compute C(x, y),
where x is Alice’s input, y is Bob’s input. Yao’s method transforms
any C into a secure garbled circuit C
, which enables computation
of C(x, y) without revealing x to Bob or y to Alice.
(cid:2)
A, w0
B, w1
i and w1
For each wire i of the circuit, Alice generates two random wire
keys w0
i . These wire keys are used as labels encoding,
respectively, 0 and 1 on that wire. Now consider a single gate g
in C, described by some boolean function g : {0, 1} × {0, 1} →
{0, 1}. Let the two input wires to g be labeled A and B, and let
the output wire be labeled C. The corresponding wire keys are
w0
A, w1
B, w0
C, w1
C.
(cid:2)
The garbled gate g
of circuit C
is deﬁned by a random permuta-
tion of the following four ciphertexts, where {x}κ is a symmetric-
key encryption of plaintext x under key κ (see [23] for the proper-
ties that the encryption scheme must satisfy).
c00 = {{wg(0,0)
c10 = {{wg(1,0)
c01 = {{wg(0,1)
c11 = {{wg(1,1)
}
}
}
}
}
}
}
}
w
w
w
(cid:2)
w
w
0
B
1
B
w
w
1
A
1
A
w
C
C
C
C
0
B
1
B
0
A
0
A
Alice garbles all gates of the circuit in this manner, and sends the
entire garbled circuit to Bob.
i
Garbled circuit evaluation proceeds as follows. For each input
wire i associated with Alice, Alice simply sends to Bob the wire
key wbA
encoding Alice’s input bit bA on that wire. This leaks
no information about the value of bA because the wire keys are
random. For each input wire j associated with Bob, Alice and Bob
engage in OT 1
2 protocol. Alice’s inputs as the sender are the two
wire keys w0
j , and Bob’s input as the chooser is his bit bB
on that wire. As a result of the OT protocol, Bob learns the wire
key wbB
j
encoding his input without revealing bB to Alice.
j and w1
Bob evaluates the circuit starting from the gates where he has a
wire key for each input wire. For each such gate, Bob can decrypt
exactly one of the four ciphertexts, and learn the key wC encoding
the value of the gate’s output wire. If the output wire is used as an
input into another gate, Bob continues the process. This evaluation
procedure maintains the invariant that, for each circuit wire i, Bob
learns exactly one wire key wb
i . This wire key is random and thus
leaks no information about the bit b it “represents.”
In the standard Yao’s method, Alice provides a mapping for the
out of each circuit output wire out to 0 and
out and w1
wire keys w0
1, respectively. This allows circuits transformed by Yao’s method
to be used as “black boxes” which have the same functionality as
normal circuits, but hide the parties’ respective inputs.
out and w1
out to 0 and 1; instead, we consider w0
In our constructions, we use Yao’s garbled circuits to implement
secure integer comparison (see Section 3.4). In contrast to the stan-
dard black-box functionality, Alice does not provide a mapping
from w0
out or w1
out
to be Bob’s ﬁnal output from evaluating the circuit. Furthermore,
w0
out can be arbitrary strings of our choosing rather than
random strings. Using Yao’s method in this non-standard way al-
lows us to implement a conditional oblivious transfer, in which
Bob learns exactly one of two values depending on the output of
the function encoded by the circuit.