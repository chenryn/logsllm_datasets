structure
No
Yes
Measure Calculated
expected expected
quality ROI
Stake assets
Monitor Check other
quality and stakeholders'
Main process share results results
END execution
mq auC ia no l in aty cfi tr w om i rt (h s) coR nse ea nc sh us
No
Job Well Done?
Yes
Receive
reward and
retrieve stake
Fig.1.Theprocessofstakingandthedifferentstepsinvolvedinthenecessarydecisions
ofstakers.Themainprocessexecutionisoutsideofthestakerscontrolandistherefore
not shown with a solid line around the box.
DiPenta [2].Weillustratethestakersperspectiveusingthegeneralizedprocess
of a staking process depicted in Fig.1.
Whenselectingaprocesstostakeon,thestakershouldstartbyassessingthe
technicalaspectsofthemainprocessthataffectits(promised)qualityanddecide
how and when these should be measured. These can be either the quality of a
good, such as in Scenario 2, the relevant quality metrics of the process, such as
inScenario1,orboth,suchasinScenario3.Thisdecisionisultimatelybasedon
thestaker’sexpectedReturn-on-Investment(ROI),whichinturndependsonthe
perceived (expected) quality, the perceived risk, and the expected reward that
resultsfromthestakingprocess.Ifthestakerdecidestostake,theylocksomeof
their assets on the blockchain, at which point the main process can commence.
The role of the staker during the main process depends entirely on the nature
of said process; it can be that the staker is not required to do anything, as in
Scenario 2, or that the staker has to monitor and guarantee the quality during
themainprocessand,achieveconsensuswithotherstakers,suchasinScenarios
Staking Assets Management on Blockchains 7
1 and 3. Either way, once the process is over, the staker gets rewarded, usually
in proportion to the usefulness of their contribution and the size of their stake.
A crucial step in the flowchart in Fig.1 is the decision of whether staking is
worthwhile.ThestakerwantstomaximizetheirexpectedROI.Thisrequiresthat
thestakerbalancesthepromisedrewardagainsttheriskofunintendedbehavior
in the process, which can violate the quality that the staker is guaranteeing.
In order to assess this risk, the staker has to have a good understanding of the
processitisstakinginfromtheperspectiveofthemainactor(s),whocontrolthe
process,as well asthestakingand/orconsensusprotocol.Bystaking,thestaker
effectively guarantees the quality of both the main process, which they deem
likely enough to be used, and the (un)likelihood that the process will contain
unintended behavior. We have found a surprising lack of literature, theory, and
tools that address this challenge and propose our own ideas on this in the next
section.
The systems architect should take into account that the staker’s objective
(maximizingROI)doesnotnecessarilyalignwellwiththeobjectivesoftheother
actors in the system. This, in turn, means that the service that the supportive
services mentioned in Sect.2 staker is another problem that arises from the lack
of consideration for the staker’s perspective. We have found that existing liter-
ature on staking in blockchain-based scenarios consistently fails to address this
potential misalignment between the staker and the other actors in the system.
4 Proposed Solution
As a way to address the challenges introduced in Sect.3, we propose the intro-
ductionofastakingframework,whichcanassistbothaspiringstakersaswellas
systemsarchitectsintheprocessofstakingandthedecisionsassociatedwiththis
process. This framework is bound to contain at least the following supportive
elements:
1. A“cookbook”whichwillcontainstandardpatterns,bestpracticesinstaking
scenarios and, how to deal with them;
2. A number of techniques that can be leveraged for assessing the process, the
staking protocol, the alignment between the staker and, the other actors;
3. A tool suite which can be used to streamline the staking process outlined
in Fig.1 by automating (part of the) the required risk assessment and the
connected orchestration machinery;
Weillustrate theusefulnessandexpectedimpact ofour proposedframework
by describing a hypothetical staker who participates in scenario 3 following the
flowchart in Fig.1.
Whendesigningablockchain-based solutionthatinvolves staking, asystems
architectconsiderstheframework’sstandardpatternsandbestpracticestohelp
themselectthebestoptionfortheirsystem.Additionally,theyconsiderwhether
the objectives of the staker and the other actors line up well. Before selecting
a service, the staker uses our proposed framework to identify relevant patterns
8 S. Driessen
andbestpracticesregardingqualitymetrics(e.g.,QoS&non-functionals).They
leverage our assessment techniques to make sure they understand which mea-
surements allow them to monitor these quality metrics effectively. Using this
knowledge and our proposed tool suite, the staker identifies scenarios where
they could fail to achieve consensus (and thus not get rewarded for staking).
Finally, after having confirmed their understanding of both the process they are
stakingin*and* theprocessofstakingitselfcantheyselectprocessesthathave
acceptable expected ROIs.
Once the decision is made, the staker stakes their assets and participates in
the monitoring process and, if consensus is achieved, it gets rewarded by the
smart contract that enforces the SLA. For a more in-depth explanation of this
scenario, we invite the reader to check Uriarte et al. [7].
5 Roadmap and Contributions
This paper has outlined the contours of a methodological framework for effec-
tively supporting stakers, -and the process of staking- in a blockchain environ-
ment.Theresultsofthispaperarecoreresearchresultsinnature.Moreresearch
is required in several main directions.
Firstly we intend to conduct one or more case studies, possibly followed by
a survey. This will help us map more clearly how the proposed challenges are
experienced first-hand by the actors in blockchain-based staking scenarios. It is
likely this will result into a call for research based on the challenges we identify.
Secondly, we intend to apply action research to solve the problems arising
from the challenges identified in this paper. This will provide a proof-of-concept
for future endeavors, both in academics and in business, that aim to solve these
challenges.
Finally, we hope to generalize a framework, supported by theory, that can
be applied to the set of problems described in this paper and addressed in the
previous step. This will both open up the door for further theory development
regardingstakinginblockchainscenarios,aswellasdirectlybenefitbothstakers
and systems architects.
References
1. Butijn, B.J., Tamburri, D.A., Heuvel, W.J.V.D.: Blockchains: a systematic multi-
vocal literature review. arXiv preprint arXiv:1911.11770 (2019)
2. Canfora, G., Di Penta, M.: Service-oriented architectures testing: a survey. In:
De Lucia, A., Ferrucci, F. (eds.) ISSSE 2006-2008. LNCS, vol. 5413, pp. 78–105.
Springer, Heidelberg (2009). https://doi.org/10.1007/978-3-540-95888-8 4
3. Ocean Protocol Foundation and BigChainDB GmbH and Newton Circus: Ocean
protocol: a decentralized substrate for AI data & services technical whitepaper
(2019). https://oceanprotocol.com/tech-whitepaper.pdf
4. Irresberger, F., John, K., Saleh, F.: The public blockchain ecosystem: an empirical
analysis. Available at SSRN (2020)
Staking Assets Management on Blockchains 9
5. Mik, E.: Smart contracts: terminology, technical limitations and real world com-
plexity. Law Innov. Technol. 9(2), 269–300 (2017)
6. Saleh, F.: Blockchain without waste: proof-of-stake. Available at SSRN 3183935
(2020)
7. Uriarte, R.B., Zhou, H., Kritikos, K., Shi, Z., Zhao, Z., De Nicola, R.: Distributed
service-level agreementmanagementwithsmartcontractsandblockchain.Concur-
rency Comput. Pract. Experience 1–17(March) (2020). https://doi.org/10.1002/
cpe.5800
Hybrid Context-Aware Method for Quality
Assessment of Data Streams
B
MostafaMirzaie( )
FerdowsiUniversityofMashhad(FUM),Mashhad,Iran
PI:EMAIL
Abstract. Data quality is one of the most important issues that if not taken
into consideration appropriately, results in the low reliability of the knowledge
extractedthroughbigdataanalytics.Furthermore,thechallengeswithdataquality
managementareevengreaterwithstreamingdata.Mostofthemethodsintroduced
intheliteratureforprocessingstreamingdatadonotusecontextualinformationfor
thepurposeofaddressingdataqualityissues,however,itispossibletoimprovethe
performanceofthesemethodsbyconsideringthecontextualinformation,espe-
cially those obtained from the external resources. Based on this point of view,
ourmainobjectiveinthisthesisistoproposeahybridmultivariatecontext-aware
approachfordataqualityassessmentinstreamingenvironments,suchassmart
cityapplications.
Keywords: Dataqualityassessment·Contextawareness·Streamingdata
1 ProblemStatementandContributions
According to Statista website1 report, the total amount of data created in the world
reaches 175 zettabytes by the year 2025. This data is generated from various sources
includingsensorsinasmartcityplatform[1].However,animportantpointisthatthe
observations of a sensor might be of insufficient quality due to various constraints,
like environmental conditions or hardware malfunctioning [2]. The poor quality data
may result in wrong business decisions being made by organizations [3]. Therefore,
it is important to find data quality issues and clean poor data before using for any
knowledgeextractionordecisionmaking.Someresearchersusecontext-awaremethods
that quality of data is determined not only through analysis of the local application-
specific information, but also using information from a global context, which in turn
enhances the performance of big data quality management [4]. Based on our recent
1https://www.statista.com/statistics/871513/worldwide-data-created/
Supervised by Behshid Behkamal, Samad Paydar (Ferdowsi University of Mashhad (FUM),
Mashhad,Iran)andMohammadAllahbakhsh(UniversityofZabol,Zabol,Iran).
©SpringerNatureSwitzerlandAG2021
H.Hacidetal.(Eds.):ICSOC2020Workshops,LNCS12632,pp.10–16,2021.
https://doi.org/10.1007/978-3-030-76352-7_2
HybridContext-AwareMethodforQualityAssessment 11
systematic literature review on big data quality2, we have observed that although a
numberoftechniqueshavebeenproposedintheliteraturetoimprovedataqualityinthe
bigdatafield,onlyafewconsidercontextualinformationintheprocessofdataquality
assessment.Sincenocontextmodelforbigdataqualityassessmenthasbeenproposed,in
anotherstudy3wereviewedcontext-awarestudiestoprovideacontextmodelforbigdata
quality,accordingtowhichwefoundthatinallstudies,onlyinternalcontexts(available
inthesubjectdataset)areusedandnoneofthemhasconsideredtheexternalcontext
(available fromother data sources).Inaddition, none of thecontext-aware techniques
haveusedthestoreddatatoincreasetheaccuracyofqualityassessment.Inwhatfollows,
someofthechallengesarementioned:
 Variety of arrival rate: Data values arrives at the different rate, so the evaluation
algorithmshouldprovideamechanismforprocessingexistingdatabeforethearrival
ofthenewincomingdata.
 Infinite: In streaming data, data is continuously being received, and the evaluation
processmustbedoneonlineandwithoutinterruptionofthemainretrievalprocess.
 Volatility:Indatastream,volatilityisasignificantchallengethatdataexpiresaftera
whileandlosecredibility,sodataprocessingshouldbedonebeforeitexpires.
 Heterogeneoussources:Datamaybereceivedfromdifferentsources,inwhichcase
itisnecessarytointegrateandextractthecorrelationofthesedatainordertoobtain
theappropriatecontextinformation.
Basedonthediscussionabove,inthisearlystageproposal,weintendtopresenta
novelhybridcontext-awaremethodusingenvironmentalinformationtoassessthequality
ofdatastream.Thenovelcontributionsofourworkcanbesummarizedasfollows:
 Weuseexternalcontext(relatedinformationextractedfromothersources),inorder
toimprovedatastreamqualityassessmentperformance.
 Webenefithistoricaldatathatenablestrackingofdatavaluesovertimewhichgives
keyinsights,inordertoincreasedetectionprecision.
 Weproposeagrid-basedclusteringtodecreaseexecutiontime.
2 StateoftheArt
Inthissection,wediscussandcomparethecontext-awarequalityassessmentstudiesin
streamingdata,basedonoursystematicliteraturereview.Studieshavebeencompared
basedonseveralcriteria,includinglevelofmanagement,typeofcontextualinformation,
processingtype,variablequantity,andtechniqueused.Fromthepointofviewoflevel
ofmanagement,therearetwoapproaches:sensor-level,inwhichallqualitycontrolsare
performedbythesensorswithoutanyinterferencebyusers,anduser-level,inwhichpre-
processingphaseisperformedbytheuserafterreceivingdatafromthesensors.From
anotherpointofview,wehaveclassifiedthesemethodsintotwogroupsbasedonthetype
2StateoftheArtontheQualityofBigData:ASystematicLiteratureReviewandClassification
Framework.
3ContextualizationofBigDataQuality:Aframeworkforcomparison.
12 M.Mirzaie
ofcontextualinformationtheyusefordetectingqualitydeficiencies.Thefirstgrouphas
usedintra-networkinformation,whilethelaterexploitedexternalresourcesinformation.
Intermsofprocessingtype,streamdataqualityassessmentstudiesaredividedintotwo
categoriesofonlinemethods,whichhaveevaluateddatainatimeframei.e.,window,and
hybridmethodsthathaveusedstoreddataforthequalityassessmentofreal-timedata.
Wehavealsocategorizedthestudiesintotwogroupsofunivariateandmultivariatein
termsofthenumberoffeaturesusedforanalysis.Thelastfeatureforcomparingstudies
is the technique used for quality evaluation. Some methods calculated the similarity
or distance between all data values to consider data that is far from the threshold as
poor quality data. These methods are classified as distance based methods. The other
techniquesthatattempttoobtainnormaldistributionthroughtimeanalysisandmodel
building,arecalledmodel-based,andfinally,studiesthatuseclusteringorclassification
techniques, are named as learning based techniques. The advantage of model-based
methods is that they have less computational complexity than other methods and are
moresuitableforonlineprocessing.Distance-basedandlearning-basedmethodsarenot
recommendedforonlineprocessing[5,6].Thesummaryofthisfeaturebasedevaluation
ispresentedinTable1.
Table1. Featurebasedcomparativeevaluation
Ref Year Levelof Contextual Processing Numberof Technique
management information type variables
used
[7] 2012 Sensorlevel Internal Online Univariate Model
based
[8] 2013 Sensorlevel Internal Online Univariate Distance
based
[9] 2013 Sensorlevel Internal Online Univariate Learning
based
[10] 2014 Sensorlevel Internal Online Univariate Distance
based
[11] 2015 Userlevel – Hybrid Univariate Model
based
Internal Online Multivariate Model
based
[12] 2018 Sensorlevel Internal Online Univariate Learning
based
Proposed 2020 Userlevel Internaland Hybrid Multivariate Learning
method external based
AsillustratedinTable1,mostofthemethodscontrolthequalityofdataatthesensor
level.Thismeansthattheuserhasnoroleindatapre-processing.Giventhelimitations
ofprocessingandmemoryinsensors,thiscanaffecttheperformanceofsuchmethod.
HybridContext-AwareMethodforQualityAssessment 13
In terms of contextual information, only one study [11] took the advantage of the
storeddataforqualityassessmentusingtwoalgorithms.Inthefirstalgorithm,thestored
dataareusedtocreatethemodelwithoutincludinganycontextualinformation;while
inthesecondalgorithm,whichbenefittedcontextualdata,onlywindow-baseddataare
considered.Thus,itcanbeconcludedthatnohybridprocessingmethodhasbeenapplied