WordPress
Reports
3 (8.1%)
0 (0.0%)
2 (5.0%)
7 (12.7%)
3 (11.5%)
23 (14.1%)
15 (7.5%)
RESULTS OF MANUAL NOTIFICATION
12
201
Fixed
1
0
1
3
2
7
Channel
Cont.
Postal
Email
Web forms
Social Media
Phone
30
48
29
36
20
Total
163
TABLE IX.
10
be established. Seeing the effort of manual notiﬁcations, they
yield a comparatively low success rate. Using the best available
channels, i.e., postal and phone for Git as well as social media
and phone for WordPress, we managed to reach a slightly
higher fraction of reports compared to our regular notiﬁcation
campaign. However, it remains unclear how to determine the
best alternative channel in beforehand.
At
the same time, we must consider the cost of this
notiﬁcation. Apart from approximately 60 hours of work to
conduct 364 notiﬁcations manually (approx. 40 hours to look
up contacts for all 970 domains, 10 hours for the phone calls,
5 hours for letters and 5 hours for social network and Web
forms), we spent both postage and telephone costs. Moreover,
of the 67 letters we sent, 18 were returned to us because
a non-existing recipient. We thus argue that such a manual
notiﬁcation can by no means be considered cost-efﬁcient when
trying to notify an even larger number of sites.
VI. SURVEY
Following our automated and manual notiﬁcations, we sent
anonymous surveys (see our GitHub repository [1]) to all
notiﬁcation recipients who did not opt-out of our experiments,
as described in Section II-D. Here, we analyze the responses
and distill the insights they provide.
A. Summary of Survey Submissions
We distributed a distinct survey to each notiﬁcation re-
sponse group (which were based on their interactions with our
notiﬁcations and their remediation status). This allowed us to
track the anonymous survey answers per response group. The
sets of questions for each survey were identical, except for
an additional question for response groups that did not ﬁx
the vulnerability, asking for the reasons they did not address
the issue. Note all survey questions were optional, typically
resulting in fewer question answers than submitted surveys.
Across our six response groups, we received a total of
193 submitted surveys, and an additional 232 initiated but not
submitted surveys. However, these submissions were primarily
from two response groups. Notiﬁcation recipients who viewed
our vulnerability report Web site and also ﬁxed a vulner-
ability (a group we label as REPORT FIXED) contributed
162 submissions (and an additional 150 other views). The
high submission rate for this group is unsurprising given they
were most likely to have observed and responded to our prior
notiﬁcation efforts. More unexpected was that the response
group with the second most survey answers was those who
did not appear to view our email and did not address the
issues (which we label as NOREAD NOFIX). They completed
27 surveys (with 59 incomplete ones). This indicates that a
number of these email contacts were active, despite the fact
we could not verify they had read the email.
The remaining response groups provided two or fewer sub-
missions, with 12 or fewer total views. These are surprisingly
low reply rates, as some response groups include those we
observed as having viewed our report Web site or opened the
notiﬁcation message, indicating the email addresses were at
least active. Even though we randomly distributed the order
of the sent out emails and regularly checked for the presence
of our mail server in well-known IP blacklists, our messages
containing a link to the survey page might have been detected
as spam by mail servers. Since we conducted our survey in
an anonymous fashion, it is impossible to determine whether
speciﬁc mail servers were more likely to ﬂag our mail as spam.
However, we assume that the impact of this is similar to what
we had observed for the notiﬁcations in the Tracking group,
i.e., that likely Google’s mail servers might have ﬂagged more
of our messages as spam. Given this distribution of survey
submissions, we cannot assume our ﬁndings generalize to all
contacts, but they can provide insights nonetheless.
B. Respondent Demographics
We asked respondents to self-describe the type of Web
site their organization maintains and the nature of their or-
ganization. The most popular response was that
the Web
site was a corporate or business homepage. Over a third of
contacts (66 out of 162) in the REPORT FIXED group self-
reported this answer, as did 6 out of 27 (22%) of those in
the NOREAD NOFIX group. This indicates that exploitation
of our Web site vulnerabilities may have ﬁnancial implica-
tions, potentially compromising businesses or harming their
customers. Thus, our reported vulnerabilities can have a note-
worthy impact. Other notable Web site categories included
personal or blog pages, e-commerce Web sites, community
forums, online services, and academic institution homepages,
although none of these categories accounted for more than 7%
of respondents.
C. Security Response Manpower
The availability of security personnel to address Web vul-
nerabilities impacts the effectiveness of security notiﬁcations.
For example, Web sites with only one webmaster tasked with
responding to vulnerability reports may struggle to properly
address all issues. We asked respondents to disclose the num-
ber of personnel tasked with responding to security incidents or
security notiﬁcations, as well as the number of people directly
responsible for administrating or maintaining the Web site.
The survey responses indicate a Web site typically has few
administrators who handle security issues, less so than the total
number of webmasters. Out of the 173 answers we received
regarding personnel, 92 Web sites (53%) indicated there was
only one security administrator, 66 (38%) indicated there were
two to ﬁve such webmasters, and 9 (5%) indicate no one was
tasked with handling security incidents. Only 6 responses indi-
cate there were ﬁve or more security personnel. In comparison,
101 Web sites (58%) had two to ﬁve webmasters, 56 (32%)
had a single Web site maintainer, and two responses indicated
no one managed the Web site. 14 (8%) indicated more than
ﬁve people helped run the Web site.
D. Acceptability of Detection and Notiﬁcation
It is vital to understand whether our vulnerability scans and
subsequent notiﬁcations are acceptable to those we contact. A
negative answer would argue against the practice of notiﬁca-
tion. To assess this, we asked respondents to indicate whether
they found it acceptable to detect security issues on their
Web site and whether it was acceptable for us to notify them
about any detected problems. We additionally asked if they
would ﬁnd such notiﬁcations useful in the future. Naturally,
11
this carries a sampling bias, given that recipients who found
our message helpful would be more willing to take our survey.
Our responses were almost universally positive. Over 98%
of respondents (178 out of 181) indicated detection was
allowed, and only 1 out of 185 survey answers (0.5%) indicated
security notiﬁcations were unacceptable. These notiﬁcations
were not only acceptable,
they were deemed helpful, as
99% (181 out of 183) surveys showed they would ﬁnd our
notiﬁcations useful in the future. Our survey responses may
suffer from response bias, such that those who feel strongly
positive or negative are more likely to complete our survey.
However, the nearly universally positive responses suggest that
these notiﬁcations are well-received. In addition, we received
numerous thanks in the survey’s free response comments. This
conclusion is in line with prior security notiﬁcation stud-
ies [13, 19], which have also reported positive interactions with
the vast majority of notiﬁcation recipients (through surveys and
notiﬁcation follow-on communication).
E. Proper Points of Contact
Our notiﬁcation efforts have illuminated the challenges
in even establishing contact with the maintainers of a site.
To gain insight on the proper points of contact, we inquired
as to the best point(s) of contact for each respondent. We
observe a wide range of responses, although the WHOIS
technical email contact and site-listed emails appeared to be
the predominantly preferred contacts. 123 respondents marked
the WHOIS technical contact as appropriate, and 115 did so
for email contacts listed on the site. Other popular options
included the WHOIS abuse contact (59 replies) and Web forms
(55). For the remaining options we listed, including social
media, as well as snail mail addresses and phone numbers
(both in WHOIS records and on the site), between 15 and 25
respondents designated those as reasonable contact points.
This range of responses highlights the difﬁculty in reliably
reaching the appropriate webmaster, as different Web sites may
be best notiﬁed at different points of contact. It also provides
guidance towards future notiﬁcation efforts, such as utilizing
emails scraped from Web sites or automating Web site form
submissions. Also of note is the popularity of the WHOIS
technical email compared to the WHOIS abuse contact. The
difference is drastic, even when considering the possibility that
some respondents may have mistaken (or did not distinguish)
between the two. This counters the intuition used in prior
notiﬁcation studies [6, 13, 19, 25, 26] which have utilized the
abuse contact, considering it more security-relevant.
F. Trust as a Factor
Our remaining survey questions attempted to assess the
qualities and characteristics of our notiﬁcation messages.
While there was a diverse set of feedback, a common theme
emerged of trust in the notiﬁcation. A number of notiﬁcation
recipients did not immediately react or dismissed our message
as initially untrustworthy, and those who eventually did heed
our notiﬁcation indicated it was after some investigation to
conﬁrm its validity. Such negative perception of a vulnerability
report naturally can signiﬁcantly limit its effectiveness.
There were three common characteristics of our notiﬁcation
that were most frequently discussed as impacting its trust-
worthiness. First was the message sender, which 14 survey
submissions explicitly stated was either unfamiliar or lacked
an established trustworthy reputation. One respondent said
“As an American, Saarland University was not a school I
had heard of before.” Others stated that
the notiﬁcations
could be improved if we were to “build up a reputation
to make them seem less dodgy and more trustworthy,” or
“use a trusted brand to rely on.” Several of those that noted
they did not recognize the sender also discussed needing to
investigate to conﬁrm the legitimacy of the notiﬁcation source.
For example, one respondent recalled that they “had to google
you to know it was not phishing” while another suggested
providing “instructions on how to verify the authenticity of the
sender.” These replies indicate that the sender may impact a
notiﬁcation’s effectiveness, a conclusion that conﬂicts with the
study from Cetin et al. [6], which experimented with several
different notiﬁcation senders and found that sender reputation
did not appear to affect remediation rates. Further investigation
into this factor is needed, as our survey responses suggest that
trust in the sender is an important consideration.
The second characteristic of our notiﬁcation that survey
recipients noted was the use of an external link. Email links,
particularly from unknown senders, can appear suspicious as
they can lead to phishing or malware domains. As our notiﬁ-
cation’s report link was hosted at a university’s domain, those
who were unfamiliar with the institution or its domain could be
wary of clicking on it. One survey submission advised “Don’t
try to link me to an external site. This makes me immediately
think it may be a phishing attempt.” Another expressed similar
sentiments: “I wouldn’t have acted if there wasn’t something
veriﬁable inside of the e-mail, or if it required following
anything from the e-mail or accessing any attachments.” These
replies suggest that a notiﬁcation message should encompass
the entire vulnerability report. While perhaps external links to
information pages (or sites that validate the sender) could still
be provided, recipients should not have to visit these to obtain
the necessary information. This corresponds with the ﬁndings
of Li et al. [19], who found that more detailed notiﬁcation
messages resulted in improved remediation behavior.
A ﬁnal quality widely mentioned was the similarity to
phishing or spam emails. In fact, 10 notiﬁcation recipients
indicated they found our notiﬁcation originally in their spam
folders, which likely grossly under-represents the true fraction
as those who never observed our initial notiﬁcation were
unlikely to respond to our survey (or perhaps our survey
message itself was relegated to spam). Numerous comments
touched on their suspicions, such as:
• “At ﬁrst
this email was considered rather suspicious
(spam / phishing / malware). We checked it with extreme
caution.”
• “I ignored ﬁrst one as spam/phishing but reacted to the
• “My initial instinct was your email was spam and/or some
kind of attack itself, but I quickly realized it was real.”
• “Risk to read it as spam due to lots of false security mails
friendly reminder followup.”
from no-trust-senders.”
Also, several replies indicated they had poor past expe-
riences with some less benevolent parties claiming to have
relevant security information. One person recounted “I have
been contacted in the past by bug bounty hunters who hounded
12
me for payment for vulnerabilities they found in another site
I run.” Another explained “Lots and lots of emails I receive
claim to be attempts to alert me about something, and it is
usually a veiled sales pitch for something like SEO services.”
This illuminates a challenge for these administrators in ﬁltering
out legitimate notiﬁcations.
instead of receiving unsolicited notiﬁcations. While effective,
VRPs incur additional costs for domain operators. Thus, it
seems unlikely that a large enough number of domains will
register for already existing VRPs to provide a complete so-
lution. However, future efforts could attempt to run low effort
and cheap services that provide vulnerability information.
From this, it is apparent that the appearance of the no-
tiﬁcation message is also a vital consideration, as it needs
to distinguish itself from spam and phishing messages. One
potential solution was proposed by ﬁve responders, who sug-
gested using more professionally designed or HTML-based
messages. Another might be to switch to a subscription model,
where webmasters subscribe to vulnerability notiﬁcations. This
suggestion was proposed in seven comments, which explained
that such a model would result in increased trust in both
the sender and the received messages. Overall, future work
on notiﬁcations should investigate not
the method of
conducting notiﬁcations, but
the design of the notiﬁcation
message itself, with an emphasis on establishing trust.
just
VII. QUO VADIS, VULNERABILITY NOTIFICATIONS?
While the majority of domains we notiﬁed about remained
unﬁxed, a signiﬁcant fraction did correct the issues, showing
the promise of notiﬁcations. This aligns with the results from
Stock et al. [25] and Li et al. [19]. Moreover, our survey
responses indicated strongly positive reception to our efforts.
The research into large-scale security notiﬁcations is still in
its infancy though. In this section, we outline challenges we
identiﬁed from our study as well as previous work, laying a
roadmap for what future work could focus on.
A. Better Delivery Mediums
In nearly all works related to large-scale notiﬁcations,
the authors faced similar technical hurdles. One of the main
challenges was in identifying an appropriate email address to
contact (in an automated manner). We likewise faced these
issues, resulting in a large number of bounces for generic
aliases. Particularly sobering was the 85% bounce rate for
the security@ alias. Even though we could extract contact
information from the WHOIS entries for some of the affected
domains, these at times pointed to an Internet registrar, hosting