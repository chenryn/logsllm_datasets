HTTP/2
HTTP/2
HTTP/1.1
HTTP/1.1
HTTP/1.1
HTTP/1.1
HTTP/1.1
HTTP/1.1
HTTP/1.1
HTTP/1.1
HTTP/1.1
HTTP/1.1
HTTP/1.1
HTTP/1.1
HTTP/1.1
HTTP/1.1
HTTP/1.1
HTTP/1.1
HTTP/1.1
HTTP/1.1
Experiments have revealed that, as shown in Table I,
CDNs support HTTP/2 in client–CDN connection but use only
HTTP/1.1 in the CDN–origin connection, even when the origin
supports HTTP/2. Consequently, these CDNs have to convert
web requests between HTTP/2 and HTTP/1.1 protocols, which
may introduce new security threats. Even worse, as shown
in Table II,
turn on HTTP/2
client–CDN connection support by default for their customer
websites, directly exposing their customer websites to possible
protocol conversion threats. Furthermore, the resulting severity
increases because three of the CDNs (Cloudﬂare, CDNSun,
and KeyCDN) do not even provide an option to turn off such
HTTP/2 support.
these CDNs, except Fastly,
TABLE II: HTTP/2 support statuses of the CDNs included in
this study. Five of the six CDNs enable HTTP/2 support by
default for their customer websites.
CloudFront
Cloudﬂare
CDNSun
Fastly
KeyCDN
MaxCDN
HTTP/2 Support
Default On
Conﬁgurable
Default On
Default On
Default Off
Conﬁgurable
Default On
Default On
Conﬁgurable
Primer on HTTP/2. The primary goals of HTTP/2 are to
reduce latency and minimize protocol overhead. Primarily, the
HTTP/2 protocol supports multiple concurrent bidirectional
streams within a single HTTP/2 connection, thus reducing
unnecessary TCP handshake processes and supporting full re-
quest and response multiplexing [8]. For example, in a client–
CDN connection, a client makes one HTTP/2 connection with
the CDN, using two streams to request resources through
“path1” and “path2,” as shown in Fig. 3.
In HTTP/1.1, header ﬁelds are not compressed. Because
web pages have grown to require dozens to hundreds of
requests, the redundant header ﬁelds in these requests unnec-
essarily consume bandwidth. Therefore, in HTTP/2, HPACK
header compression is introduced primarily to reduce unnec-
Crafted Legal RequestsCDN-rendered Attacking Connections Origin ServerAttackerCDNFig. 3: HTTP/2-HTTP/1.1 conversion has to decompress and
expand HTTP/2 requests, resulting in bandwidth ampliﬁcation.
essary network trafﬁc caused by the repeated request and
response headers in HTTP/1.1 [49].
According to the HPACK mechanism, within the client–
CDN connection, both the client and CDN (as an HTTP/2
server) maintain an indexed dynamic table of previously
seen header values, and subsequent repeated header ﬁelds
are substituted as an index referencing a value in the table.
Because many header ﬁelds, e.g., :authority, cookie,
and user-agent are repetitive, this mechanism has a very
high table-hitting ratio. Thus, instead of full header ﬁelds, the
substituted indexes are transmitted in the network, reducing
the transferred bytes.
Accordingly, when the client opens a second stream to send
another “path2” request, the repeated header ﬁelds, such as
cookie, are substituted as indexes (and thus these ﬁelds are
not shown in “stream2” of Fig. 3). These mechanisms greatly
reduce the header overhead and improve transfer performance.
Attack Principle. When a CDN forwards these requests
to the origin, all header ﬁelds indexed in HTTP/2 must
be expanded into HTTP/1.1 requests, leading to bandwidth
ampliﬁcation. As shown in Fig. 3, this mechanism results in
two large-sized HTTP/1.1 requests with the same large-sized
cookie, which leads to a bandwidth ampliﬁcation in the
CDN–origin connection, with an ampliﬁcation ratio of almost
2. An unsymmetrical bandwidth-consuming attack that takes
advantage of this mechanism was evaluated by Beckett et al.
on an experimental testbed with proxy software Nginx and
nghttp2 [7], but to our knowledge, no real-world experiments
on this kind of attack have been performed yet.
As we can see, within one HTTP/2 connection, the ampli-
ﬁcation ratio is linear with respect to the number of concurrent
streams. The maximum values for concurrent streams are nego-
tiated when an HTTP/2 connection is established. We measure
the stream limits of the CDNs and list them in Table III. Across
all six CDNs, the maximum allowed concurrent streams are all
bigger than 100 (the recommended value in the RFC [8]).
TABLE III: Limits set by CDNs on HTTP/2 streams.
CloudFront
Cloudﬂare
CDNSun
Fastly
KeyCDN
MaxCDN
Max Concurrent Streams
Dynamic Table Size
Max Entry Size
128
4KB
3072B
256
4KB
3072B
128
4KB
3072B
100
4KB
3072B
128
4KB
3072B
100
4KB
3072B
Therefore, for an attacker to achieve the maximum am-
pliﬁcation ratio in CDN–origin connections, crafted attacking
HTTP/2 requests can all use a header ﬁeld with the same
large-sized value, e.g., cookie with a large-sized value, given
that it is widely used in HTTP requests. Besides the cookie
ﬁeld, the attacker can also use other header ﬁelds deﬁned in
the HTTP/2 protocol, such as user-agent and referer,
which are also forwarded to the origin. The size of the header
ﬁeld value is limited by the size of the indexed dynamic table,
which is also negotiated during the HTTP/2 connection. As
shown in Table III, the maximum table entry size across the
CDNs is 3072 B, and the table size is 4 kB. Thus, crafted
attacking HTTP/2 requests can use two header ﬁelds to ﬁll
the indexed table, resulting in the converted HTTP/1.1 CDN–
origin requests to have the maximum size.
B. Real-World Attack Analysis
Experiment Setup. Based on the previously explained anal-
ysis, we further evaluate the severity of such an ampliﬁcation
attack across the six CDNs. After deploying an Apache server
behind each CDN, we initiate an HTTP/2 connection to each
of the six CDNs to send attacking requests which are crafted
as
:path: /?
:scheme: https
:authority: victim.com
:method: GET
cookie: A=X...X
cookie: B=X...X
(a large-sized string)
(a large-sized string)
(or /)
To achieve the maximum ampliﬁcation ratio, we use two
cookie ﬁelds with large-sized strings to ﬁll the 4 kB HTTP/2
dynamic table. Given that the maximum table entry size is
3072 B, the lengths of two cookie values are calculated
by subtracting additional overhead bytes from the total 4
kB dynamic table size. The additional overhead bytes are
determined by table entry overhead and other header ﬁeld
values, e.g., :authority and user-agent. These two
cookies stay the same in all concurrent streams, thus they will
be transferred in the same way as indexes except for the ﬁrst
stream. Note that we actually use two types of :path header
ﬁeld values to evaluate the ampliﬁcation ratio; the reason for
this will be discussed later in this section.
In our experiments, to explore the impact of concurrent
streams on the ampliﬁcation ratio, we change the number of
concurrent streams within one HTTP/2 connection and use
tcpdump to capture the trafﬁc in both the client–CDN connec-
tion and CDN–origin connection to evaluate the ampliﬁcation
factor.
Experiment Results. According to Fig. 4, when the number
of concurrent streams grows, the bandwidth ampliﬁcation ratio
also grows. As shown in Fig. 5, when the number of concurrent
streams grows, the packet ampliﬁcation ratio also grows. When
the concurrent streams reach the maximum allowed number
for one HTTP/2 connection, the ampliﬁcation ratio reaches
the maximum. When the stream number grows beyond the
maximum allowed number for one HTTP/2 connection, our
HTTP/2 client has to wait for the previous streams to close,
and the packets ratio drops, as shown in Fig. 5. Meanwhile,
the bandwidth ampliﬁcation ratio ﬂuctuates after the maximum
number of allowed concurrent streams is reached.
The bandwidth ampliﬁcation ratios are summarized in
Table IV; we will illustrate the difference between the 2nd
4
Get /path1 HTTP/1.1Host: victim.comCookie: a=large-stringCookie: b=large-stringHTTP/2HTTP/1.1:path: path1:Authority: server.comCookie: a=large-stringCookie: b=large-string---------Stream1----------------Stream2-------:path: path2Get /path2 HTTP/1.1Host: victim.comCookie: a=large-stringCookie: b=large-stringCDNOrigin ServerAttackerOne TCP Connection         2 StreamsTABLE IV: Maximum ampliﬁcation ratios across the CDNs.
CloudFront
Cloudﬂare
CDNSun
Fastly
KeyCDN
MaxCDN
Streams
Bandwidth Ratio
(:path: /?random string)
Bandwidth Ratio
(:path: /)
128
99.6
116.9
256
132.6
166.1
128
99.5
118.7
100
89.0
97.9
128
96.8
105.5
100
82.3
94.7
it
• :path header ﬁeld: In our experiments, we also ﬁnd
that the :path header ﬁeld contributes to the ampliﬁcation
ratio. If we use :path: / directly in all of our attacking
requests, given that
is a predeﬁned index in the static
table1, only 1 B needs to be transmitted in all of the HTTP/2
concurrent streams. However, in the World Wide Web, URLs
can be of varying lengths, and an attacker normally uses
random URLs to bypass CDN caching or WAF rules. There-
fore, we also append different random strings to the :path
header ﬁeld in each HTTP/2 stream, in the form :path:
/?random_string.
TABLE V: Length of the :path header ﬁeld during HTTP/2
and HTTP/1.1 conversion.
HTTP/2 client–CDN Connection
HTTP/1.1 CDN–origin Connection
Header Field
:path: /
:path: /?xxxyy
Transmission Length
1 bytes
8 bytes
URL
/
/?xxxyy
Transmission Length
1 bytes
7 bytes
As shown in Table V, the :path: / header ﬁeld is also
converted into 1 B in each resulting HTTP/1.1 connection.
When we use a random value /?random_string in the
:path header ﬁeld in each HTTP/2 request, the random value
in that ﬁeld is a non-repetitive value and is therefore not present
in the dynamic table. According to the HPACK mechanism,
the value will be encoded in either its raw form or using the
Huffman encoding form (the shorter of the two). In Table V,
we can see that :path: /?xxxyy consumes 8 B in HTTP/2
(1 B for the index of :path ﬁeld, and 7 B for /?xxxyy 2),
and the converted URL in each HTTP/1.1 request will be 7 B.
In our experiments, we send these two types of :path
headers to evaluate the bandwidth ampliﬁcation ratio and
obtain different results, as listed in Table IV. The reason
for these differences is that when the number of concurrent
HTTP/2 streams grows, the length of the :path header ﬁeld
begins to inﬂuence the ampliﬁcation ratio. In our experiments,
when the :path: / form is used, the network trafﬁc of the
attacker–CDN connection front-end trafﬁc (FB) is in the order
of thousands, e.g., 5,000 bytes per second, whereas the network
trafﬁc of the CDN–origin connection back-end trafﬁc (BB) is
in the order of millions, e.g., 600,000 bytes per second. The
ampliﬁcation ratio is BB /FB. On the other hand, when the
:path: /?xxxyy form is used, and we send n (e.g., 100,
128, or 256, i.e., the maximum values in Table III) concurrent
HTTP/2 streams,
the network trafﬁc of the attacker–CDN
connection, compared with for the ‘:path: / form, will be
1According to the HTTP/2 speciﬁcation, the HPACK mechanism uses
an additional static table to predeﬁne common header ﬁelds associated with
frequently occurring values, e.g., :path: / is predeﬁned in the indexed table
as index 4 [49].
2We generate a different random string in each request. Here, we neglect
the chances that the Huffman encoding may compress the random string to
shorter than 7 B.
Fig. 4: Bandwidth ampliﬁcation ratio when the number of con-
current streams increases (:path: /?random_string).
Fig. 5: Packets ampliﬁcation ratios when the number of con-
current streams increases (:path: /?random_string).
and 3rd rows later. We can see that this HTTP/2–HTTP/1.1
conversion threat is realistic; it can break the CDN protection
and cause a severe DoS attack against the origin.
Analysis of Ampliﬁcation Factors. From the given illus-
tration, we can see that the bandwidth ampliﬁcation ratio is
determined primarily by the number of concurrent streams.
From further analysis of the HTTP/2 speciﬁcation, we also
ﬁnd other inﬂuencing factors, such as the Huffman encoding