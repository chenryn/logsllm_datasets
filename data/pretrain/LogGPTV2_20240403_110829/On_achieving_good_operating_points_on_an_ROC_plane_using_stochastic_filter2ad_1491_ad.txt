and, while signiﬁcant accuracy improvements with adap-
tive thresholding were not observed, good ROC operational
points were identiﬁed. Non-adaptive TRW failed to main-
tain its accuracy for the endpoint dataset as it primarily
works on the principle of observing incoming requests which
were not present in this dataset. Adaptive-TRW mitigates
this accuracy loss and provides signiﬁcant improvements in
both detection and false alarm rates.
Fig.
7 shows the ROC-based accuracy comparison of
STIDE, SVM and KL-Divergence detectors with and with-
out adaptive thresholding. It can be observed that STIDE
gives consistently good performance on both the datasets
(i.e., UNM and MIT-LL), thus not providing enough space
for improvement. Nevertheless, Adaptive-STIDE identiﬁes
good accuracy points on the ROC curve without requiring
manual conﬁguration. Similarly, SVM performed compar-
321← Adaptive Max−Entropy
← Adaptive PHAD
← Adaptive TRW
← Max−Entropy
← TRW
← PHAD
100
80
60
40
20
)
%
(
t
e
a
r
n
o
i
t
c
e
e
d
t
e
g
a
r
e
v
A
0
0
20
40
60
80
100
120
140
False Alarms per day
(a) Endpoint Dataset
100
)
%
(
← Adaptive PHAD
↑ Adaptive TRW
Adaptive ↑ Max−Entropy
t
e
a
r
n
o
t
i
t
c
e
e
d
e
g
a
r
e
v
A
80
60
40
20
0
0
← TRW
← PHAD
← Max−Entropy
20
40
60
80
100
120
140
False Alarms per day
(b) LBNL Dataset
Figure 6: Accuracy evaluation of network-based ADSs.
)
%
t
(
e
a
r
n
o
i
t
c
e
t
e
d
e
g
a
r
e
v
A
100
80
← Adaptive−STIDE
← Adaptive−SVM
← SVM
← Adaptive−KL
60
← STIDE
← KL
40
20
0
0
20
40
60
80
100
False Alarms (%)
(a) UNM Dataset
)
%
(
e
t
a
r
n
o
i
t
c
e
t
e
d
e
g
a
r
e
v
A
100
80
60
40
20
0
0
← Adaptive−SVM
← Adaptive−STIDE
← Adaptive−KL
← STIDE
← SVM
↓ KL
20
40
60
80
100
False Alarms (%)
(b) MIT-LL Dataset
Figure 7: Accuracy evaluation of host-based ADSs.
atively better on the UNM dataset but failed to maintain
its performance on the MIT-LL dataset.
In the MIT-LL
dataset case, Adaptive-SVM reduces the false alarms sig-
niﬁcantly and marginal improvements can also be observed
for the UNM dataset. KL-based detector could not perform
well on both the datasets, thereby providing enough room
for improvement for Adaptive-KL on both the datasets; it
can be clearly seen that Adaptive-KL induces a considerable
reduction in false alarms on both datasets.
6.2 Complexity Evaluation
We measured algorithm run-time and memory require-
ments using the hprof tool [9] on a 2.2GHz dual-core Intel
machine. Complexity was measured by running the algo-
rithms on the entire traﬃc set of one endpoint and over the
entire UNM dataset. The total time taken by the adap-
tive thresholding module on the endpoint’s traﬃc data was
approximately 60 milliseconds which was two and ﬁve or-
ders of magnitude less than the time taken for execution
of the Maximum-Entropy and TRW/PHAD anomaly detec-
tion algorithms, respectively. Similarly, the data memory
requirements of adaptive thresholding algorithm were also
negligible (a few hundred KBs) with respect to the mem-
ory consumed by the anomaly detection algorithms; three
orders of magnitude for Maximum-Entropy and two orders
of magnitude for TRW and PHAD. Similar complexity re-
sults (approximately two orders of magnitude in run-time
and an order of magnitude in data memory) were observed
for host-based detectors.
7. LIMITATIONS AND COUNTERMEASURES
Although the proposed adaptive thresholding algorithm
provides accuracy and automation improvements, it has cer-
tain limitations.
In this section, we enumerate these con-
straints and limitations and propose remedial measures.
• Adaptive thresholding is designed speciﬁcally for real-
time anomaly detectors. Other anomaly detectors which
operate on non-real-time measurements (e.g., ﬁle anal-
ysis algorithms, rule-base traﬃc classiﬁcation algorithms,
etc.) cannot use adaptive thresholding.
• Due to its self-learning nature, adaptive thresholding
algorithm would raise fewer and fewer alarms for a
persistent anomaly. We can cater for this limitation
by tuning the adaptability feedback metric by giving a
greater value to β. This measure causes the algorithm
to assign lesser feedback weight to past values, thus
eﬀectively reducing the dependence on behavior too
far back in the past.
322• Some anomalies could potentially go undetected if the
adaptive thresholding algorithm’s predicted score is
well above the observed value; we have not observed
such behavior in our experiments.
• The preceding limitation can also be viewed from a
security perspective. That is, undetected anomalies
can be exploited by a crafty attacker to bypass the
ADS. While all ADSs are inherently susceptible to
such stealth and mimicry attacks, in an adaptive al-
gorithm this limitation can be eﬀectively mitigated by
setting an appropriate bin size in accordance with the
ADS’ observed score deviations. Speciﬁcally, a small
bin size can be used to reduce the score granularity.
An attacker trying to stay below the ﬁner granular
predicted scores would in turn compromise the eﬀec-
tiveness (volume) of the attack.
8. CONCLUSIONS
We showed that ROC-based accuracy evaluation using
ﬁxed thresholds is not necessarily representative of the ac-
tual accuracy that an IDS can potentially achieve. We pro-
posed a generic threshold tuning algorithm that: 1) allows
an IDS to achieve high accuracy points on the ROC plane;
2) can be readily introduced into existing IDSs; 2) reduces
the need for human threshold conﬁguration in an IDS; and
4) has very low run-time complexity and memory require-
ments.
9. REFERENCES
[1] J. M. Agosta, C. D. Wasser, J. Chandrashekar and C.
Livadas. An adaptive anomaly detector for worm
detection, Usenix SysML, 2007.
[2] A. B. Ashfaq, M. Joseph, A. Mumtaz, M. Q. Ali, A.
Sajjad, and S. A. Khayam. A comparative evaluation
of anomaly detectors under portscan attacks, RAID,
2008.
[3] B. E. Boser, I. M. Guyon and V. N. Vapnik. A
training algorithm for optimal margin classiﬁers, ACM
COLT, 1992.
[4] Cisco Anomaly Guard Module Homepage,
www.cisco.com/en/US/products/ps6235/.
[5] Computer Immune Systems, Datasets, http:
//www.cs.unm.edu/~immsec/data/synth-sm.html
[6] S. Forrest, S. A. Hofmeyr, A. Somayaji and T. A.
Longstaﬀ. A sense of self for unix processes, IEEE
Symp S&P, 1996.
[7] Y. Gu, A. McCullum and D. Towsley. Detecting
anomalies in network traﬃc using maximum entropy
estimation, ACM/Usenix IMC, 2005.
[8] G. Hollinger, J. Djugash and S. Singh. Tracking a
moving target in cluttered environments with ranging
radios: extended results, Tech. report
CMU-RI-TR-08-07, Robotics Institute, CMU, 2008.
[9] HPROF: A Heap/CPU Proﬁling Tool in J2SE5.0,
http://java.sun.com/developer/
technicalArticles/Programming/HPROF.html
[10] T. IDE and H. Kashima. Eigenspace-based anomaly
detection in computer systems, ACM SIGKDD, 2004.
[11] K. L. Ingham and H. Inoue. Comparing anomaly
detection techniques for http, RAID, 2007.
[12] J. Jung, V. Paxson, A. W. Berger and H.
Balakrishnan. Fast portscan detection using sequential
hypothesis testing, IEEE Symp S&P, 2004.
[13] D. K. Kang, D. Fuller and V. Honavar. Learning
classiﬁers for misuse and anomaly detection using a
bag of system calls representation, IAW, 2005.
[14] A. Lakhina, M. Crovella and C. Diot. Mining
anomalies using traﬃc feature distributions, ACM
SIGCOMM, 2005.
[15] A. Lakhina, M. Crovella and C. Diot. Diagnosing
network-wide traﬃc anomalies, ACM SIGCOMM,
2004.
[16] A. Lazarevic, L. Ertoz, V. Kumar, A. Ozgur and J.
Srivastava. A comparative study of anomaly detection
schemes in network intrusion detection, SIAM SDM,
2003.
[17] LBNL/ICSI Enterprise Tracing Project, http://www.
icir.org/enterprise-tracing/Overview.html
[18] W. Lee and D. Xiang. Information-theoretic measures
for anomaly detection, IEEE Symp S&P, 2001.
[19] R. P. Lippmann, D. J. Fried, I. Graf, J. W. Haines, K.
R. Kendall, D. McClung, D. Weber, S. E. Webster, D.
Wyschogrod, R. K. Cunningham, and M. A. Zissman.
Evaluating Intrusion Detection Systems: The 1998
DARPA Oﬀ-Line Intrusion Detection Evaluation,
DISCEX, (2):12–26, 2000.
[20] R. P. Lippmann, J. W. Haines, D. J. Fried, J. Korba
and K. Das. The 1999 DARPA oﬀLine intrusion
detection evaluation, Computer Networks,
34(2):579–595, 2000.
[21] M. V. Mahoney and P. K. Chan. PHAD: Packet
header anomaly detection for indentifying hostile
network traﬃc, Florida Tech. technical report
CS-2001-4, 2001.
[22] M. Merhav, M. Gutman, and J. Ziv. On the
estimation of the order of a markov chain and
universal data compression, IEEE Trans. Info Theory,
35(5):1014–1019, 1989.
[23] MIT Lincoln Laboratory, Information Systems
Technology,
http://www.ll.mit.edu/mission/communications/
ist/corpora/ideval/data/index.html
[24] R. Pang, M. Allman, M. Bennett, J. Lee, V. Paxson
and B. Tierney. A ﬁrst look at modern enterprise
traﬃc, ACM/USENIX IMC, 2005.
[25] Arbor Networks’ Peakﬂow Product,
http://www.arbornetworks.com/peakflowsp.
[26] Report on Host-based Intrusion Detection Systems,
http://staff.science.uva.nl/~delaat/
snb-2004-2005/p19/
[27] C. Shannon and D. Moore. The spread of the Witty
worm, IEEE SSP, 2004.
[28] Symantec Security Response,
http://securityresponse.symantec.com/avcenter
[29] H. L. V. Trees. Detection, estimation and modulation
theory: part I, Wiley-Interscience, 1st ed., 2001.
[30] WisNet ADS Comparison Homepage,
http://wisnet.niit.edu.pk/projects/adeval
[31] C. Wong, S. Bielski, A. Studer and C. Wang.
Empirical analysis of rate limiting mechanisms, RAID,
2005.
323