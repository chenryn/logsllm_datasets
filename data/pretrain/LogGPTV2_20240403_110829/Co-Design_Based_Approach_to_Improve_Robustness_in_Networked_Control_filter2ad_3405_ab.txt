larly at road intersections [12]. Hence, the main problem in
the lower level control loop is to follow these trajectories as
closely as possible.
3.3. Design enhancements
We have applied the ideas of Section 2 to enhance the
software architecture of the testbed and improve system ro-
bustness. In this paper, however, we only consider design
y
y
t+1
yt
s
t+1
t+1
t+1
s t
t
t
x t
xt+1
x
Figure 5. State evolution in the car model
enhancements for the lower level control loop in Figure 3.
The key components and connections of the lower level
control loop are reproduced in Figure 4(a). As shown in the
ﬁgure, the controller depends on periodic updates from the
vision data server, since the controller would have to operate
with obsolete data if any updates are lost over the network.
Similarly, the actuator depends on the controller as it can
only transmit the last received control to the car. This design
is not robust, since updates from the vision data server and
the controller have strict deadlines, and component restarts
cannot be tolerated.
These problems are similar to those illustrated in Figure
2. The solutions developed in the previous section are ap-
plied as shown in Figure 4(b). The controller uses a state es-
timator to get periodic estimates and tolerate delays in sen-
sor updates. The state estimator is also used as a predictor
to compute a sequence of future controls that are stored in
the control buffer at the actuator. In particular, the extension
of deadlines for updates from the sensor and the controller
is determined by the accuracy of state prediction. This issue
is analyzed in detail in the next section.
4. Analysis of state prediction
State prediction has been used to improve system robust-
ness in our testbed as described in Section 3.3. However, the
accuracy of prediction decreases with time due to errors in
modeling and calibration. Hence, acceptable horizons of fu-
ture controls, and consequent increases in update deadlines,
depend on how the error in prediction evolves. In this sec-
tion, we consider accuracy of state prediction in the lower
level control loop of our testbed, and analyze how the asso-
ciated error evolves with time.
4.1. Model of a car
In the trafﬁc control testbed, we model a car by consid-
ering its position and orientation on the track. More speciﬁ-
cally, the state of a car xt at time t is given by xt = [xt yt q
t ]T ,
where xt and yt are the coordinates of the center of the car,
and q
t is its orientation. Further, the car has a speed st and
steering a
t at time t.
t+1 = q
t + h (cid:3) a
The evolution of the state of a car in one time step is
shown in Figure 5. The orientation of the car after one
time step is given by q
t + wq t, where h is
the length of a time-step, and wq t is the update error due to
noise. During this interval, the car is moving at speed st.
Further, we assume that h is small enough so that the car
moves at an average orientation of J
t =2) during
the interval. Consequently, the car has a displacement of
h (cid:3) st at an orientation of J
t. These relations are summa-
t = q
t + (a
rized in the following equation.
2
664
xt+1
yt+1
t+1
1
3
775
=
2
664
1
0
0
0
0 0
1 0
0 1
0 0
hst cosJ
hst sinJ
t
ha
1
t
t
3
775
2
664
xt
yt
t
1
3
775
+
wxt
2
wyt
664
wq t
0
3
775
(1)
Equation (1) can be written more compactly using vec-
tors as follows:
xt+1 = Mt xt + wt
(2)
where xt is the state of the car, Mt is the car model, and
wt is the update error, all at time t. Also, the state has been
extended to xt = [xt yt q
t 1]T to account for state evolution.
4.2. Deterministic error bound
During normal operation, the state estimator maintains
ˆxt, an estimate of the state xt, which evolves according to
the equations
ˆx((cid:0))
t+1 =
ˆxt+1 = f (ˆx((cid:0))
Mt ˆxt
t+1;yt+1)
(3)
(4)
where yt+1 is the observation (sensor feedback) at time
t + 1 and is used to correct the estimate using the correction
f in eq (4). This is a common approach to account for the
error term wt in eq (2).
During state prediction, however, there are no observa-
tions, and ˆxt evolves according to
ˆxt+1 = Mt ˆxt
(5)
Since the error term wt in eq (2) cannot be accounted
for in the prediction update of eq (5), the prediction error
˜xt = xt (cid:0) ˆxt grows with time. In particular, if ˜x0 = 0, and the
error term can be bounded as wt (cid:20) wmax, then the prediction
error grows as:
˜xt+1 (cid:20) wmaxt
(6)
This is due to the special structures of Mt (upper triangu-
lar form) and wt (last component is zero) shown in eq (1).
q
a
q
a
q
q
This is equivalent to specifying uncertainty in the prediction
of the car position by a bounding box whose area grows lin-
early with time. Consequently, if the acceptable uncertainty
is ˜xmax, then the prediction is acceptable for all time t with
each term in the above summation reduces to E[wT
j w j].
Further, since the w j were assumed to be i.i.d, we have
E[wT w] = E[wT
j w j] for all j. Consequently, eq (9) sim-
pliﬁes to give
˜xt+1 (cid:20) wmaxt (cid:20) ˜xmax
(7)
Hence, the deterministic (worst case) upper bound on the
prediction error grows linearly with time. Further, since
prediction is equivalent to estimation without observations,
the same analysis applies for computing deadlines for the
sensor as well. In particular, the maximum value of t satis-
fying eq (7) is the hard real-time deadline for observation
updates from the sensor.
4.3. Mean error bound
The deterministic analysis of Section 4.2 can be used to
compute hard-real time deadlines using eq (7). In partic-
ular, this bound uses the maximum error ˜wmax, and hence
the prediction error bound grows linearly with time. How-
ever, if the error ˜wt is “well behaved”, and we can tolerate
occasional failures, then we can obtain signiﬁcantly higher
deadline extensions.
In equation (2), the exact values of wt cannot usually
be determined in practice, and only the probability distri-
butions are known. Hence, xt and wt are modeled as ran-
dom variables in the car model as well as in the updates of
eqs (3), (4), and (5). Further, we may reasonably assume
that the error terms wt are independent and identically dis-
tributed (i.i.d) with mean zero. We can then use eqs (2) and
(5) to compute the mean squared error as follows:
E[˜xT
t+1 ˜xt+1] = E[(˜xT
= E[˜xT
t )(Mt ˜xt + wt)]
t MT
t MT
+E[˜xT
t MT
t + wT
t Mt ˜xt ] + E[wT
t MT
t Mt ˜xt ] + E[wT
t wt ]
t ]E[wt ] + E[wT
t wt ]
= E[˜xT
t ]E[Mt ˜xt ]
(8)
The expectations factor out in the ﬁrst step since ˜xt is
independent of wt, and the last two terms disappear in the
second step as wt has mean zero.
Equation (8) is a recursion in ˜xt. Assuming ˜x0 = 0, we
can solve the above recursion to get ˜xt+1 in terms of the
error terms w j as
E[˜xT
t+1 ˜xt+1] = E[wT
t wt]
t(cid:0)1(cid:229)
+
E[ ˜wT
j (
MT
i )(
t
i= j+1
t(cid:0)( j+1)
i=0
j=1
(9)
Mt(cid:0)i) ˜w j]
(10)
We can now conclude that the mean prediction error e
t+1 ˜xt+1] = E[wT w](cid:3) t
E[˜xT
grows as the square root of time t, i.e.,
e = qE[˜xT
t+1 ˜xt+1] = kpt
(11)
for constant k. In practice, this gives much higher dead-
line extensions than eq (6) as we demonstrate in Section 5.
The key result established in this section is that the upper
bound on the prediction error grows linearly with time, but
the average prediction error grows only as the square root
of time. Hence, for the hard guarantee that a car will stay
within the system tolerance, the deadline is the largest t for
which eq (7) is satisﬁed. However, if occasional failures
(and transitions to the fail-safe state) can be tolerated, then
eq (11) gives a much larger deadline extensions in practice.
5. Experimental validation
This section presents some experiments to validate the
conclusions of Section 4. We begin by covering some im-
plementation details in the testbed, and describe the plat-
form used to implement robustness features such as compo-
nent restarts. We then describe the experiments and analyze
the results obtained.
5.1. Implementation details
The cars are controlled using manually calibrated dis-
crete controls for speed and steering. This discretization
contributes to the error in eq (2) of Section 4. In particu-
lar, the maximum difference between successive calibrated
speeds is 12.7cm/s, which we can assume to be the deter-
ministic error in eq (6) for a small enough interval. Also,
the sensor and controller operate with a period of 100ms.
Thus, under normal operation, the controller receives feed-
back from the sensor every 100ms, and sends controls to the
actuator every 100ms.
In the testbed, the vision processing components run on
Windows NT based desktops, and have a processing time
of about 50ms per frame to determine car positions. All
other components in Figure 3 execute on Linux based lap-
tops with Intel Pentium-III processors. The testbed has been
implemented using Etherware, which is described below.
5.1.1 Etherware
Due to the special structures of Mt (upper triangular
form) and wt (last component is zero) shown in eq (1),
Etherware [3] [4] is a Java based message-oriented com-
ponent middleware that we have developed for networked
(cid:213)
(cid:213)
control systems. In Etherware, components are addressed
by automatically generated globally unique ids, or by reg-
istered user-deﬁned proﬁles. Components interact by ex-
changing messages, and each component has a message
queue in which incoming messages are stored. Etherware
also supports MessageStreams to specify delivery require-
ments for streams of messages such as sensor updates.
For instance, each of the data and control ﬂows between
components of Figure 3 has been implemented as a Mes-
sageStream.
Etherware also provides efﬁcient restart mechanisms
for handling component failures.
To accomplish this,
component state can be check-pointed, and used for re-
initialization during restarts. In particular, MessageStreams
are maintained across component restarts, and their iden-
tiﬁers can be passed on as part of the check-pointed state.
A typical component restart in Etherware takes less than
20ms, which is well within the 100ms hard real-time dead-
line of components in the testbed. However, for the exper-
iments presented in this section, delays are introduced in
component restarts to study their effect on the cars.
5.2. Case study: Motorcade
Through our experiments we intend to answer the fol-
lowing questions:
1. Does the empirical growth in state prediction error cor-
respond to eq (11) in Section 4?
2. What is the deadline extension achieved?
3. Is our new design indeed tolerant to delayed restarts of
sensors and controllers?
To answer these questions we consider a motorcade sce-
nario with two cars, a leader and a follower. The cars
move around in an elliptical trajectory with a major axis of
length 2.8m and a minor axis of length 2m. The cars them-
selves are about 225mm long, travel at an average speed of
371mm/s, and take about 21.7 seconds for one iteration of
the trajectory. An elliptical trajectory was chosen since it
exercises different steering angles at different points.
The main goal is to maintain a separation of about
400mm between the centers of the cars, i.e., about 175mm
between their bumpers. Hence, the deviation of the leader
car from its trajectory is constrained to be less than half the
separation between the cars in order to avoid collision. To
ensure this, we set the maximum allowable deviation for the
leader car to be 50mm.
5.2.1 Error in state prediction
In the ﬁrst experiment, we seek to answer the ﬁrst two ques-
tions posed in Section 5.2 by measuring the growth of error
in state prediction as a function of time. For this, the lead-
ing car is driven along the elliptical trajectory, and a sep-
arate state estimator for the car is executed in parallel. At
a designated point, the feedback to the state estimator is
turned off, after which the estimator essentially operates as
a state predictor. However, the actual car is still operated by
a controller with complete feedback. Hence, the distance
between the actual position of the car and the predictions of
the state estimator is the growth of error in state prediction.
Figure 6 plots the prediction error for six different points
along the elliptical trajectory of the motorcade.
As shown in Figure 6, the prediction error grows as the
square root of time. In fact, the ﬁgure also shows the solid
curve y = kpx, where k = 1:0769 is the value for which
this function has the least mean squared error from the pre-
diction error curves. This co-incides with the average case
analysis of Section 4.3 and validates eq (11). Also, as noted
in Section 5.1, the maximum difference between calibrated
speeds is 127mm/s. Assuming this to be the worst case er-
ror in eq (7) for the duration of two seconds, Figure 6 also
shows the growth of the worse case error bound with time.
To determine the deadline extensions, we observe when
the various error curves cut the tolerable error of 50mm in
Figure 6. The original deadline for the sensor and the con-
troller was 100ms - the operating period of the lower level
control loop. However, using our enhancements, even the
worst case bound extends this deadline to 400ms. Further,
if we can tolerate occasional failures, then the average error
curves extend this deadline to 1300ms. In particular, these
extended deadlines are more than sufﬁcient to tolerate most
delays in the network.
5.2.2 Effect of delayed restarts
The second experiment addresses the third question raised
in Section 5.2. In this experiment, both cars in the motor-
cade have trajectories that make them go along an ellipse
with a separation of about 400mm between their centers.
Faults are then injected into the controller (cf. Figure 3)
of the leader at random points in the trajectory. The sub-
sequent restart of the controller is also delayed for random
intervals to observe the behavior of the car based on future
controls stored in the control buffer at the actuator. Note
that restarting the vision sensor would have a similar effect
on the behavior of the car, since in either case the controls