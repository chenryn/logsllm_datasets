Also presented in Figure 12 is the trend line for the performance
of the cross-validation while the user is just sitting. Clearly, there
is a signiﬁcant decrease in the inference performance as a result of
movement noise. However, what is unclear from this experiment
is how a model would perform if it had a large collection of move-
ment noised examples to train on. Unfortunately, we do not have
sufﬁcient samples to investigate such a proposition, but it is likely
that performance would improve, but would not surpass controlled
and movement-stable collection scenarios.
7.2 PIN/Pattern Sequence Inference
The results above model the ﬁrst attack scenario, where the at-
tacker has a large corpus of labeled data available, and the attacker
can apply logistic regression to differentiate input. In this subsec-
tion, we consider the second attack scenario, where such a corpus
is unavailable, and instead the attacker must infer the larger input
by performing a sequence of smaller inferences. For example, we
consider an attacker who has a set of labeled data that refers not
to the exact PIN/pattern but to examples of single touches of digits
or individual swipes. The goal is to link those predictions together
using a idden Markov Model (HMM) to infer the whole input.
Single Touch/Gesture Inference. The ﬁrst step in this process
requires showing that the features described previously also differ-
entiate single touch or swipe input. To study this, we segmented
the accelerometer data for PINs and patterns based on the recorded
touch logs such that features can be extracted based on a single
event. As noted previously, the process an attacker may use to seg-
ment the data in this manner using just accelerometer data is be-
yond the scope of this work; however, such segmentation is likely
possible, such as described in [34].
We performed experiments for inferring both unigrams and bi-
grams. A unigram consists of a swipe across a contact point in a
pattern, or touching a single digit for a PIN. A bigram consists of a
48
To begin, we investigate prediction performance for training and
testing on the same device for the same user. These results are
presented in Figure 9. As we might expect, devices with higher
accelerometer sample rates (refer to Table 1) tend to perform better;
however, the decrease in performance for lower sample rates is not
as extreme as was seen in [24]. For patterns, there is a small drop
in inference performance between the Nexus S and the Nexus One,
although the Nexus S effective sample rate is double that of the
Nexus One. PINs seem more affected by sample rate issues, there is
at least a 50% drop in performance between the highest sample rate
device and the lowest sample rate one. Yet, all devices perform well
above random guessing, suggesting that the features are reasonably
resilient to sample rate ﬂuctuations, as addressed by the sample-
normalized features (see Section 6).
However, in order to show that the attacker can construct a com-
prehensive dictionary, we must show that training and testing on
different devices and different users is also effective. In Figures 10
and 11, we present the results of experiments to test such a capabil-
ity. First, in Figure 10 we present two trend lines: one where train-
ing and testing occurred on the same device and one where training
and testing occur on different devices. As expected, training and
testing on different devices performed worse than using the same
device. This decline was fairly signiﬁcant for patterns; however,
the decline was relatively small for PINs by comparison.
In Figure 11, we present the results of experiments where we
constructed a model trained on all but one user in the data set, and
tested on the remaining. This experiment most closely resembles
the scenario of an attacker with a large corpus trained on varied
users and devices. Interestingly, although patterns are inferred at a
reasonable rate on average, there is great variance. Inspecting the
gray-scale lines for individual users, some users perform fractions
better than random guessing, while others perform as well or better
than testing and training on the same user (the dash-dotted trend
line). PINs, surprisingly, perform much more consistently when
training and testing across multiple users and devices, and even
perform as well (and sometimes better) than testing and training on
a single user/device. This suggest that dictionaries of accelerometer
data can be collected, but there seems to be wide variance for some
input types that may affect accuracy.
Movement Noise.
Finally, all the results presented previously
considered data collected in a controlled movement setting, i.e.,
while the user was seated at a table. It is important to know how
these models perform if they were predicted from noisy data, e.g.,
collected while the user was walking. Although it is likely that
an attacker would obtain stable accelerometer data, he/she would
also obtain data while the user is in motion. The effects of noisy
samples must also be considered if the attacker were to construct a
representative corpus.
In Figure 12, we present the results of an experiment that in-
Figure 14: Prediction results for PIN pad as factor greater than
random guessing, included (in smaller text) results from taplog-
ger [34].
swipe connecting two contact points in a pattern, or two sequential
digit presses in a PIN. Thus, there are 9 and 10 possible unigram
values for patterns and PINs, respectively, and 72 and 100 possible
bigram values for patterns and PINs, respectively. To test the infer-
ence capabilities of an attacker, we use the collected accelerometer
data and divide it into uni- and bigrams appropriately using the
touch information and perform a ﬁve-fold cross validation for each
user. The average across all users is presented in Figure 13.
Clearly, both uni- and bigram prediction proceeds at a rate well
above random chance, with bigrams performing better overall as
a factor above random chance. This bodes well for sequence pre-
diction using bigrams. However, when we conducted experiments
where we test and train on different users, or when we introduce
movement noise, the models fail, either performing a small fraction
greater than random chance, or worse. As we will discuss below,
when using such models in an HMM, they were unable to infer the
input, even after 1000 guess attempts.
Comparison to Taplogger.
In the case of unigram inference for
PINs, we can compare the results of taplogger [34] to our own since
Xu et al. used a numeric number pad, much like PINs. Recall that
taplogger uses gyroscopic data to infer where on a touchscreen a
tap event occurred, while we use accelerometer data. Figure 14
presents the comparisons for four guesses (described as coverage
in [34]). Although, taplogger performs well, our technique is com-
parable to taplogger’s results, either performing nearly as well, or
slightly better, in all instances.
Hidden Markov Model Inference. With models for individual
touches or swipes, it is now possible to construct a hidden Markov
model (HMM) that selects the most likely (maximum a posteriori)
set of touch or gesture input. For the experiment, we use a transi-
tion matrix trained from a set of 50 PINs and 50 patterns, and use
bigram models. We found that prediction results for unigrams were
very poor.
The results of the experiment are presented in Figure 15. On the
x-axis is the number of guesses (or paths in the HMM attempted)
and the y-axis is the prediction result. The most likely path is
straightforward to obtain. To generate additional reasonable alter-
nate high scoring paths from the HMM, we order the set of labels
at each position by their max-marginal probabilities4 and employ
non-max suppression to get a diverse set of guesses. The details of
the technique can be found in [25].
At 20 guesses, the results for both PINs and patterns are very
good. Patterns can be inferred with an accuracy of 26%, and PINs
with an accuracy of 40%. Note this is a cross-validation for a sin-
in the other positions
4A max-marginal m((cid:2)i) for label (cid:2)i at position i in a se-
quence is obtained by maximizing over
the label possibil-
ities
in the sequence: m((cid:2)i) =
maxj(cid:2)=i p((cid:2)1, . . . , (cid:2)k|o1, . . . , ok). This can be done for all labels
and all positions as efﬁciently as computing the single most likely
assignment [17].
49
Figure 15: Prediction accuracy for bigram HMM over multiple
guesses for patterns (left) and PINs (right), and the 20 guess thresh-
old is indicated with a dashed line. The shaded trend lines are indi-
vidual users. Note that PINs outperform pattern prediction, likely
due to the limited number of transitions and shorter sequences.
gle user on a single device. We ran similar experiments where we
cross train on all users and test on a single user: The results were
greatly depressed, and the actual PIN or pattern is rarely predicted.
Similarly, we applied these techniques to data from when the users
were walking, and, again, we found that the HMM infers input very
poorly, predicting with an accuracy far below 1%.
These results suggest that the capabilities of attackers are mixed
when limited labeled data is available. In one sense, if the attacker
has sufﬁcient training on a single user in a controlled setting, the at-
tacker would likely do very well. However, adverse situations such
as movement noise or limited training greatly affects the models,
and may even render them completely ineffective.
8. SENSORS AND DEVICE SECURITY
Given these results and previous sensor-based side channel re-
sults [6, 7, 22, 24, 34], clearly any effective security mechanisms
for touchscreen devices with movement sensors must deny untrusted
applications access, at a minimum, to the accelerometer when sen-
sitive touchscreen input is being provided to other applications. At
the same time, it may be equally undesirable to restrict access to
the accelerometer (and other sensors) when sensitive input opera-
tions are not being performed. Many legitimate applications are
designed to run in the background at all times (e.g., pedometer ap-
plications), and preventing such applications from gaining access
to the accelerometer at any time, or requiring the user to manually
shut them down before performing any sensitive operation, would
greatly reduce their appeal.
One approach might be to carefully vet applications that use sen-
sors for malicious behavior before allowing them to be installed
or before making them available in application markets. Unfor-
tunately, this approach is logistically impractical at scale. An al-
ternative approach, as exempliﬁed by Google in the Android App
Market, is to label applications that access sensors (or other ser-
vices) using a permission model; however, this is also insufﬁcient
because users may either ignore such labels or do not understand
their implications.
Another approach may be to restrict the sampling rate of the sen-
sors, as suggested in [24]. However, in our experiments, even with
a relatively low sample rate of 20 Hz, prediction accuracy was sur-
prisingly high and on par with devices with sample rates at 50 Hz or
more. Such a technique would likely require a reduction in sample
rate below the functional level required by legitimate applications.
We propose an alternative strategy: Applications installed by the
user that require access to movement sensors, however frivolous
they may seem, should be able to use them and use them at the
highest sample rate allowed. But, the sensors should be disabled (or
untrusted applications denied access to them) whenever a trusted
input function – such as password entry – is being performed.
Unfortunately, the security models implemented by current hand-
held platforms do not allow temporal access control over sensors;
however, context-based security rules proposed in [23] and [9] could
be adopted in this way. Currently, applications declare what access
they need once (typically when they are ﬁrst installed by the user
or ﬁrst run), and, from that point onward, have essentially unre-
stricted, permanent access to everything they asked for at any time
they wish.
Although current mobile platforms do not support temporary re-
vocation of sensor access, it could be implemented in a straightfor-
ward way, e.g., via a system call available to trusted input functions
to obtain and revoke exclusive access to sensors. One approach
would be for this system call to cause any untrusted application
that requests access to a sensitive sensor to block (or fail) until the
sensitive operation has concluded. Alternatively, untrusted appli-
cations could simply be suspended for the duration of the sensitive
input.
9. CONCLUSION
In this paper we demonstrate that the accelerometer sensor can
function as a side channel against secure input, and our results indi-
cate that a surprising amount of information can be inferred, even
when movement noise is introduced. We show that there is con-
sistency across users and devices, despite varied sample rates, and
the construction of a sensor-reading-to-input dictionary is possible;
however, in less controlled settings, such dictionaries may be inef-
fective. Further, we show that sequence predictions, in the form of
a hidden Markov model, can be applied to this problem if insufﬁ-
cient labeled accelerometer readings are available, but such models,
again, seem prone to false predictions caused by movement noise
and cross-user training.
Given these new results, and previous results using the accelerom-
eter sensor [24] and gyroscopic sensor [6, 34], it is now clear that
the security model for on-board sensors on smartphones should be
reconsidered. Both the new and previous results should be consid-
ered conservative estimates of the potential threat: Enhancements
to features and larger data sources will inevitably lead to greater
ﬁdelity side channels, as was the case for the study of keyboard
acoustic side channels from the supervised learning strategies in [1]
to the unsupervised learning strategies in [35]. It is clear that ap-
plications that have access to the accelerometer sensor should not
be able to read from the sensor while the user is providing sensitive
input. Current mobile platform permission schemes are not insufﬁ-
cient to specify this; they provide applications with “all or nothing”
access to every sensor they might ever need to use. The permission
scheme and enforcement mechanism should restrict or allow access
to sensors based on context: untrusted applications that require ac-
cess to a sensor should be granted access only when sensitive input
operations are not occurring.
References
[1] Dmitri Asonov and Rakesh Agrawal. Keyboard accoustic emanations. In Pro-
ceedings of IEEE Syymposium on Security and Privacy, 2004.
[2] Adam J. Aviv, Katherine Gibson, Evan Mossop, Matt Blaze, and Jonathan M.
Smith. Smudge attacks on smartphone touch screens. In Proceedings of the 4th
USENIX Workshop On Offensive Technologies, WOOT’10, 2010.
[3] Ling Bao and Stephen Intille. Activity recognition from user-annotated acceler-
ation data. In Pervasive Computing, volume 3001 of Lecture Notes in Computer
Science, pages 1–17. 2004.
[4] Alastair R. Beresford, Andrew Rice, and Nicholas Skehin. Mockdroid: Trad-
ing privacy for application functionality on smartphones. In 12th Workshop on
Mobile Computing Systems and Applications, HotMobile’11, 2011.
[5] Joseph Bonneau, Sören Preibush, and Ross Anderson. A birthday present ev-
ery eleven wallets? the security of customer-chosen banking pins. In Sixteenth
International Conference on Financial Cryptography and Data Security, FIN-
CRYPTO ’12, 2012.
[6] Liang Cai and Hao Chen. Touchlogger: inferring keystrokes on touch screen
from smartphone motion. In Proceedings of the 6th USENIX conference on Hot
topics in security, HotSec’11, 2011.
50
[17] D. Koller and N. Friedman. Probabilistic Graphical Models: Principles and
ory. The MIT Press, 1994.
Techniques. The MIT Press, 2009.
[18] Jiayang Liu, Lin Zhong, Jehan Wickramasuriya, and Venu Vasudevan. uwave:
Accelerometer-based personalized gesture recognition and its applications. Per-
vasive Mob. Comput., 5:657–675, December 2009.
[19] Jani Mäntyjärvi, Juha Kela, Panu Korpipää, and Sanna Kallio. Enabling fast and
effortless customisation in accelerometer based gesture interaction. In Proceed-
ings of the 3rd international conference on Mobile and ubiquitous multimedia,
MUM ’04, 2004.
[20] Philip Marquardt, Arunabh Verma, Henry Carter, and Patrick Traynor.
(sp)iphone: decoding vibrations from nearby keyboards using mobile phone ac-
celerometers.
In Proceedings of the 18th ACM conference on Computer and
communications security, CCS ’11, 2011.
[21] Uwe Maurer, Anthony Rowe, Asim Smailagic, and Daniel P. Siewiorek. ewatch:
A wearable sensor and notiﬁcation platform. In Proceedings of the International
Workshop on Wearable and Implantable Body Sensor Networks, 2006.
[22] Emiliano Miluzzo, Alexander Varshavsky, Suhrid Balakrishnan, and Romit Roy
Choudhury. Tapprints: your ﬁnger taps have ﬁngerprints.
In Proceedings of
the 10th international conference on Mobile systems, applications, and services,
MobiSys ’12, 2012.
[23] Machigar Ongtang, Stephen McLaughlin, William Enck, and Patrick McDaniel.
Semantically rich application-centric security in android. In Computer Security
Applications Conference, 2009. ACSAC ’09. Annual, ACSAC ’09, 2009.
[24] Emmanuel Owusu, Jun Han, Sauvik Das, Adrian Perrig, and Joy Zhang. Acces-
sory: Keystroke inference using accelerometers on smartphones. In Proceedings
of The Thirteenth Workshop on Mobile Computing Systems and Applications,
HotMobile, 2012.
[25] Dennis Park and Deva Ramanan. N-best maximal decoders for part models. In
IEEE International Conference on Computer Vision, ICCV’11, 2011.
[7] Liang Cai and Hao Chen. On the practicality of motion based keystroke infer-
In Proceedings of the 5th Internaltional Conference on Trust &
ence attack.
Trustworthy Computing, Trust’12, 2012.
[8] Liang Cai, Sridhar Machiraju, and Hao Chen. Defending against sensor-snifﬁng
attacks on mobile phones. In Proceedings of the 1st ACM workshop on Network-
ing, systems, and applications for mobile handhelds, MobiHeld ’09, 2009.
[9] Mauro Conti, Vu Nguyen, and Bruno Crispo. Crepe: Context-related policy
enforcement for android. In Mike Burmester, Gene Tsudik, Spyros Magliveras,
and Ivana Ilic, editors, Information Security, volume 6531 of Lecture Notes in
Computer Science, pages 331–345. Springer Berlin / Heidelberg, 2011.
[10] Google Android Development.
http://developer.android.com/
reference/android/hardware/SensorEvent.html.
[11] Splasho Development. Pattern lock pro. https://market.android.
com/details?id=com.splasho.patternlockpro.
[12] Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen
Lin. Liblinear: A library for large linear classiﬁcation. J. Mach. Learn. Res.,
9:1871–1874, June 2008.
[13] Google Inc. Google wallet. http://www.google.com/wallet/.
[14] THQ Inc. Star wars: Lightsaber duel. http://itunes.apple.com/us/
app/star-wars-lightsaber-duel/id362158521?mt=8.
[15] Rupesh Jain. Pattern encrypt/decrupt upgrad. https://market.android.
com/details?id=PatternEncryptDecryptUpgrade.free.
[16] M.J. Kearns and U.V. Vazirani. An introduction to computational learning the-
[26] Rio Park.
Memorize pattern.
details?id=riopark.pattern.
https://market.android.com/
[27] Kurt Partridge, Saurav Chatterjee, Vibha Sazawal, Gaetano Borriello, and Roy
Want. Tilttype: accelerometer-supported text entry for very small devices. In
Proceedings of the 15th annual ACM symposium on User interface software and
technology, UIST ’02, 2002.
[28] C. Randell and H. Muller. Context awareness by analysing accelerometer data.
In Wearable Computers, The Fourth International Symposium on, pages 175 –
176, 2000.
[29] Nishkam Ravi, Nikhil D, Preetham Mysore, and Michael L. Littman. Activity
recognition from accelerometer data. In Proceedings of the Seventeenth Con-
ference on Innovative Applications of Artiﬁcial Intelligence(IAAI, pages 1541–
1546. AAAI Press, 2005.
[30] Roman Schlegel, Kehuan Zhang, Xiaoyong Zhou, Mehool Intwala, Apu Kapa-
dia, and XiaoFeng Wang. Soundcomber: A stealthy and context-aware sound
trojan for smartphones. In Proceedings of the Network and Distributed System
Security Symposium, NDSS, 2011.
[31] Dawn Xiaodong Song, David Wagner, and Xuqing Tian. Timing analysis of
keystrokes and timing attacks on ssh. In Proceedings of the 10th conference on
USENIX Security Symposium, SSYM’01, 2001.
[32] Bump Technologies. Bump app. bu.mp.
[33] Nan Xu, Fan Zhang, Yisha Luo, Weijia Jia, Dong Xuan, and Jin Teng. Stealthy
video capturer: a new video-based spyware in 3g smartphones. In Proceedings
of the second ACM conference on Wireless network security, WiSec ’09, 2009.
[34] Zhi Xu, Kun Bai, and Sencun Zhu. Taplogger: Inferring user inputs on smart-
phone touchscreens using on-board motion sensors. In Proceedings of the ﬁfth
ACM conference on Wireless network security, 2012.
[35] Li Zhuang, Feng Zhou, and J. D. Tygar. Keyboard acoustic emanations revisited.
ACM Trans. Inf. Syst. Secur., 13, November 2009.