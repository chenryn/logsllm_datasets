# Automated Detection and Fingerprinting of Censorship Block Pages

**Authors:**
- Ben Jones
- Tzu-Wen Lee
- Nick Feamster
- Phillipa Gill

**Affiliations:**
- Georgia Tech
- *Stony Brook University

## Abstract
Web censorship often involves returning a block page to inform users that their attempt to access a webpage has been unsuccessful. Detecting these block pages can provide a more comprehensive understanding of web censorship, but it is challenging due to the dynamic, personalized, and multilingual nature of web content. Previous work has relied on manual detection and identification, which is difficult to reproduce and time-consuming, making continuous, longitudinal studies impractical. This paper introduces an automated method for detecting block pages and fingerprinting the filtering products that generate them. Our approach enables continuous monitoring, achieving a 95% detection rate for block pages and identifying five filtering tools, including one previously unreported in the wild.

**Categories and Subject Descriptors:**
- C.2.0 [Computer-Communication Networks]: Security and protection (e.g., firewalls)
- C.2.3 [Network Operations]: Network Monitoring

**Keywords:**
- Censorship
- Internet Measurement

## 1. Introduction
Internet censorship is widespread, with the OpenNet Initiative's latest measurements detecting censorship in 38 out of 74 countries. Censorship mechanisms vary, from injecting TCP RST packets or altering DNS responses to displaying explicit block pages. While previous work has developed methods to detect TCP RST packets and altered DNS responses, a significant portion of censorship still relies on block pages. To fully understand internet censorship, we need automated methods to detect block pages and identify the filtering tools that create them.

Differentiating between accessible content and block pages is challenging for several reasons:
1. **Dynamic Content:** Websites may update content between requests, and block pages themselves can change.
2. **Personalized Content:** Websites may tailor content for individual users or regions, reducing the similarity between different versions of the same page.
3. **Multilingual Content:** Variations in language across regions make keyword matching difficult.

Currently, measuring block pages requires manually creating regular expressions, which is slow and resource-intensive, making consistent, continuous measurements impractical. This paper presents techniques for automatically detecting block pages and identifying the products that serve them. Our detection method correctly identifies 95% of block pages and 98.6% of accessible pages. Our fingerprinting technique uniquely identifies the filtering tool that generated the block page, allowing us to identify five known filtering tools, including one not previously observed in the wild.

The rest of this paper describes our methods for detecting and fingerprinting block pages, the accuracy of these methods, and an application to five years of block page measurements from 49 countries.

## 2. Background
### 2.1 Censorship and Block Pages
Censors use various mechanisms to return block pages, such as injecting DNS responses, redirecting traffic through transparent proxies, and inserting packets into TCP streams. DNS redirection involves injecting a fake DNS response to redirect users to a server hosting a block page. Transparent proxies inspect HTTP streams for restricted keywords or URLs and can drop requests, returning a block page. Since block pages are overt, censors who use them are generally not trying to hide their actions.

### 2.2 Related Work
OONI is the only other censorship measurement tool that has implemented an automated block page detection method. We compare OONI's DOM similarity measure to other block page detection techniques. Document classification and web page classification are related fields, with term-based classification being particularly relevant. Previous work has focused on identifying other censorship techniques, such as injected TCP RST packets and transparent proxies.

## 3. Data
We used the OpenNet Initiative (ONI) block page corpus, which contains over 500,000 entries collected from 49 countries between 2007 and 2012. Each entry includes an uncensored version of the page collected in Toronto and a test page collected in the censoring country at approximately the same time. The dataset includes a timestamp, a label indicating whether the test page is blocked, the location of the test, and the test network. An anonymized version of the dataset is available online.

The ONI dataset labels each measurement as blocked or accessible. About 28,000 test pages were labeled as blocked, and the remaining 480,000 were labeled as accessible. These labels, created using regular expressions, account for changes in block pages and have been used in previous studies.

## 4. Block Page Detection
Our block page detection methods are based on the insight that block pages are less similar to accessible pages than different versions of accessible pages are to each other. We compare the test page to a known unblocked version of the page using various similarity metrics, including page length, cosine similarity, and DOM similarity.

### 4.1 Metrics
- **Length:** We compare the sizes of the test page and the known unblocked page. Block pages tend to be smaller than accessible pages.
- **Cosine Similarity:** This metric compares pages based on a term frequency vector, representing the number of times each HTML tag appears.
- **DOM Similarity:** This metric compares the HTML structure of pages using an adjacency matrix of transition probabilities between HTML tags.

### 4.2 Results
Our automated detection methods are accurate, with the page length similarity measure performing best. A threshold of a 30% size difference achieves a true positive rate of 95% and a false positive rate of 1.37%. The low standard deviation indicates consistent performance during cross-validation.

## 5. Block Page Fingerprinting
To fingerprint filtering tools, we identify block page templates and match signatures for each template. We use page length and term frequency vectors to cluster block pages and label each cluster with the filtering tool that generated the template.

### 5.1 Approach
We assume that filtering tools generate block pages from unique templates. We use single-link hierarchical clustering to group block pages based on their sizes and term frequency vectors.

### 5.2 Results
We validated the clusters by comparing them to manually labeled block page templates. Our algorithm achieved high precision and recall, confirming the effectiveness of our clustering approach.

In summary, our automated methods for detecting and fingerprinting block pages provide a robust and efficient way to study internet censorship, enabling continuous and consistent measurements.