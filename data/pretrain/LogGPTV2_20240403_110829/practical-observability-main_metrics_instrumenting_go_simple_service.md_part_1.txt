# Instrumenting a Simple HTTP Service
Imagine you have a service in Golang that exposes some HTTP API routes and you're interested in tracking some metrics pertaining to these routes. Later we'll cover instrumenting more complex services and using instrumentation packages for common frameworks like [Gin](https://github.com/gin-gonic/gin) and [Echo](https://github.com/labstack/echo) to add some baseline metrics to existing services without having to manually instrument our handlers.
## Defining an Example Service
```go
package main
import (
	"encoding/json"
	"net/http"
)
// User is a struct representing a user object
type User struct {
	ID   int    `json:"id"`
	Name string `json:"name"`
}
var users []User
func main() {
	http.HandleFunc("/users", handleUsers)
	http.ListenAndServe(":8080", nil)
}
func handleUsers(w http.ResponseWriter, r *http.Request) {
	switch r.Method {
	case "GET":
		// List all users
		json.NewEncoder(w).Encode(users)
	case "POST":
		// Create a new user
		var user User
		json.NewDecoder(r.Body).Decode(&user)
		users = append(users, user)
		json.NewEncoder(w).Encode(user)
	default:
		http.Error(
			w,
			http.StatusText(http.StatusMethodNotAllowed),
			http.StatusMethodNotAllowed,
		)
	}
}
```
This code defines a struct called `User` that represents a user object. It has two fields: `ID` and `Name`.
The `main()` function sets up an HTTP server that listens on port `8080` and registers a handler function for requests to the `/users` endpoint.
The `handleUsers()` function is the handler for requests to the `/users` endpoint. It uses a `switch` statement to handle different HTTP methods (`GET`, `POST`, etc.) differently.
For example, when a `GET` request is received, it simply encodes the list of users as JSON and writes it to the response. When a `POST` request is received, it decodes the request body as a `User` object, appends it to the list of users, and then encodes the `User` object as JSON and writes it to the response.
## Instrumenting the Example Service
Metrics we may be interested in tracking include **which routes** are called in a time period, **how many times** they're called, **how long** they take to handle, and **what status code** they return.
::: info An Aside on Collectors, Gatherers, and Registries
The Prometheus client library initializes one or more Metrics [Registries](https://pkg.go.dev/github.com/prometheus/client_golang/prometheus#Registry) which are then periodically Collected, Gathered, and Exposed generally via an HTTP route like `/metrics` for scraping via library-managed goroutines.
For our purposes, we can generally rely on the implicit Global Registry to register our metrics and use the `promauto` package to initialize our Collectors behind the scenes. If you are a power user that wants to dig deeper into building custom Metrics Registries, Collectors or Gatherers, you can take a deeper dive into the docs [here](https://pkg.go.dev/github.com/prometheus/client_golang/prometheus#hdr-Advanced_Uses_of_the_Registry).
:::
We'll import three packages at the top of our file:
```go
import (
        //...
        "github.com/prometheus/client_golang/prometheus"
        "github.com/prometheus/client_golang/prometheus/promauto"
        "github.com/prometheus/client_golang/prometheus/promhttp"
)
```
The `prometheus` package is our client library, `promauto` handles registries and collectors for us, and `promhttp` will let us export our metrics to a provided HTTP Handler function so that our metrics can be scraped from `/metrics`.
### Registering Metrics and Scraping Handler
Now we can initialize a `CounterVec` to keep track of calls to our API routes and use some labels on the counter to differentiate between the HTTP Method being used (`POST` vs `GET`).
A `CounterVec` is a group of `Counter` metrics that may have different label values, if we just used a `Counter` we'd have to define a different metric for each distinct label value.
When initializing the `CounterVec` we provide the `keys` or names of the labels in advance for registration, while the label `values` can be defined dynamically in our application when recording a metric observation.
Let's initialize our `reqCounter` `CounterVec` above the `main()` function and use the `promhttp` library to expose our metrics on `/metrics`:
```go
//...
var users []User
// Define the CounterVec to keep track of Total Number of Requests
// Also declare the labels names "method" and "path"
var reqCounter = promauto.NewCounterVec(prometheus.CounterOpts{
	Name: "userapi_requests_handled_total",
	Help: "The total number of handled requests",
}, []string{"method", "path"})
func main() {
    // Expose Prometheus Metrics on /metrics
    http.Handle("/metrics", promhttp.Handler())
    // Register API route handlers
	http.HandleFunc("/users", handleUsers)
    // Startup the HTTP server on port 8080
	http.ListenAndServe(":8080", nil)
}
//...
```
### Recording Observations of Custom Metrics
Finally we'll want to update our `handleUsers()` function to increment the `Counter` with the proper labels when we get requests as follows:
```go
//...
func handleUsers(w http.ResponseWriter, r *http.Request) {
	switch r.Method {
	case "GET":
		// Increment the count of /users GETs
		reqCounter.With(prometheus.Labels{"method": "GET", "path": "/users"}).Inc()
		// List all users
		json.NewEncoder(w).Encode(users)
	case "POST":
		// Increment the count of /users POSTs
		reqCounter.With(prometheus.Labels{"method": "POST", "path": "/users"}).Inc()
		// Create a new user
		var user User
		json.NewDecoder(r.Body).Decode(&user)
		users = append(users, user)
		json.NewEncoder(w).Encode(user)
	default:
		http.Error(
			w,
			http.StatusText(http.StatusMethodNotAllowed),
			http.StatusMethodNotAllowed,
		)
	}
}
```
### Testing our Instrumentation
Let's test our results by running the server, hitting the endpoints a few times, then watching the `/metrics` endpoint to see how it changes:
```shell
go run main.go
```
In another tab we can use `curl` to talk to the server at `http://localhost:8080`
```shell
$ # GET our /users route
$ curl http://localhost:8080/users
> null
```
```shell
$ # Check the /metrics endpoint to see if our metric appears
$ curl http://localhost:8080/metrics
> ...
> # HELP userapi_requests_handled_total The total number of handled requests
> # TYPE userapi_requests_handled_total counter
> userapi_requests_handled_total{method="GET",path="/users"} 1
```
Note that we see a single time series under the `userapi_requests_handled_total` heading with the label values specified in our `GET` handler.
```shell
$ # POST a new user and then fetch it
$ curl -X POST -d'{"name":"Eric","id":1}' http://localhost:8080/users
> {"id":1,"name":"Eric"}
$ curl http://localhost:8080/users
> [{"id":1,"name":"Eric"}]
```
We've made two more requests now, a `POST` and an additional `GET`.
```shell
$ # Check the /metrics endpoint again
$ curl http://localhost:8080/metrics
> ...
> # HELP userapi_requests_handled_total The total number of handled requests
> # TYPE userapi_requests_handled_total counter
> userapi_requests_handled_total{method="GET",path="/users"} 2
> userapi_requests_handled_total{method="POST",path="/users"} 1
```
And we can see that the `POST` handler incremented its counter for the first time so now it shows up in the `/metrics` route as well.
### Expanding our Instrumentation
Let's add the additional metrics we discussed, we're still interested in understanding the response time for each endpoint as well as the status code of each request.
We can add an additional label to our existing `CounterVec` to record the status code of responses as follows:
```go
//...
// Define the CounterVec to keep track of Total Number of Requests
// Also declare the labels names "method", "path", and "status"
var reqCounter = promauto.NewCounterVec(prometheus.CounterOpts{
	Name: "userapi_requests_handled_total",
	Help: "The total number of handled requests",
}, []string{"method", "path", "status"})
//...
func handleUsers(w http.ResponseWriter, r *http.Request) {
    // Keep track of response status
	status := http.StatusOK
	switch r.Method {
	case "GET":
		// List all users
		err := json.NewEncoder(w).Encode(users)
		// Return an error if something goes wrong
		if err != nil {
			http.Error(
				w,
				http.StatusText(http.StatusInternalServerError),
				http.StatusInternalServerError,
			)
			status = http.StatusInternalServerError
		}
		// Increment the count of /users GETs
		reqCounter.With(prometheus.Labels{
			"method": "GET",
			"path":   "/users",
			"status": fmt.Sprintf("%d", status),
		}).Inc()
	case "POST":
		// Create a new user
		var user User
		err := json.NewDecoder(r.Body).Decode(&user)
		// Return an error if we fail to decode the body
		if err != nil {
			http.Error(
				w,
				http.StatusText(http.StatusBadRequest),
				http.StatusBadRequest,
			)
			status = http.StatusBadRequest
		} else {
			users = append(users, user)
			err = json.NewEncoder(w).Encode(user)
			// Return an error if can't encode the user for a response
			if err != nil {
				http.Error(
					w,
					http.StatusText(http.StatusInternalServerError),
					http.StatusInternalServerError,
				)
				status = http.StatusInternalServerError
			}
		}
		// Increment the count of /users POSTs
		reqCounter.With(prometheus.Labels{
			"method": "POST",
			"path":   "/users",
			"status": fmt.Sprintf("%d", status),
		}).Inc()
	default:
		http.Error(
			w,
			http.StatusText(http.StatusMethodNotAllowed),
			http.StatusMethodNotAllowed,
		)
	}
}
```
You can see here our code is beginning to look like it needs some refactoring, this is where frameworks like [Gin](https://github.com/gin-gonic/gin) and [Echo](https://github.com/labstack/echo) can be very useful, they provide middleware interfaces that allow you to run handler hooks before and/or after the business logic of a request handler so we could instrument inside a middleware instead.
Running the same series of requests as before through our application now gives us the following response on the `/metrics` endpoint:
```shell
$ # Check the /metrics endpoint
$ curl http://localhost:8080/metrics
> ...
> # HELP userapi_requests_handled_total The total number of handled requests
> # TYPE userapi_requests_handled_total counter
> userapi_requests_handled_total{method="GET",path="/users",status="200"} 2
> userapi_requests_handled_total{method="POST",path="/users",status="200"} 1
```
We can then trigger an error by providing invalid JSON to the `POST` endpoint:
```shell
$ curl -X POST -d'{"name":}' http://localhost:8080/users
> Bad Request
```