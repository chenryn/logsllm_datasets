are some interesting  findings.  As shown in Table 3, factor 
covering designs, on average, performed better than random 
testing  in all cases. For 2-factor covering designs, however, 
the difference is not  clear.  This fact is not consistent with 
previous research  on other types of testing, where it was re- 
ported that 2-way coverage was sufficient to achieve higher 
detectability  than  random testing (e.g., [9]). In contrast, the 
mutation  scores of  3-  and  4-factor covering designs  were 
much superior to random  testing  for all  specifications.  As 
shown in Table 2, the mutation scores of 3- and 4-factor cov- 
ering designs were even comparative to those of test suites 
generated  by BMIS for some specifications.  For example, 
the mutation scores for Specification 7 were 89.5%, 98.9%, 
and 97.6% for  3-factor covering  design, 4-factor covering 
design, and BMIS, respectively. 
4.3  Mutation Analysis by Ranges 
Here we discuss the cost and effectiveness  in more detail 
based on the number of  variables  in the  specifications  and 
fault types. 
Let w denote the  number of  variables.  We divided  the 
specifications  into three groups according to the number of 
variables(5  5 *U  _<  8,9 5 U 5 11,and 12 _<  U 5  14). Table 
4 shows the average percentage of the size of generated test 
suites to the exhaustive  test suite size for each method and 
each group. 
342 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:02:50 UTC from IEEE Xplore.  Restrictions apply. 
Table 11. Mutation scores for expression negation faults (ENF). 
I 
avg 
1  67.5 
I 
5 7.1 
(1  89.6 
1 
78.5 
(1  95.2 
I 
8 7.9 
11  96.5 
1 
87.9 
11 
22.4 
1 
Table 12. Mutation scores for variable reference faults (VRF). 
[ 
avg 
1  26.2 
1 
23.5 
(1  60.8 
I 
46.1 
I(  73.2 
I 
61.8 
I[  87.6 
1 
55.7 
[I 
93.6 
1 
343 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:02:50 UTC from IEEE Xplore.  Restrictions apply. 
Table 13. Mutation scores for operator reference faults (ORF). 
I 1
avg 
I  47.1 
. I  
.3 
4. 
7.7 
16.4 
1
Table 14. Mutation scores for associative shift faults (ASF). 
I 
avg 
I  38.0 
I  35.7 
11  75.3 
I 
62.5 
11  82.4 
I  71.7 
11  86.6 
I 
11 
66.3 
9.0 
1 
344 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:02:50 UTC from IEEE Xplore.  Restrictions apply. 
Table 5 shows the average mutation score for each method 
In  all  cases,  it  is  seen  that  test  suites 
and  each  group. 
generated by BMIS were more effective than factor covering 
designs.  As shown  in Table 4, the  sizes of 3-factor and 4- 
factor covering  designs were approximately equal to those 
of BMIS where 5  5 v 5 8 and 9  5  ‘U  5  11, respectively. 
When 12 5 v 5 14, in all cases, the sizes of factor covering 
designs were smaller than those of BMIS. Thus if available, 
the  specification-based  approach  is  preferable  to  achieve 
high  detectability  at  the  same  cost.  Otherwise  using  3- 
factor covering  designs is preferable  for 5  5  U  5 8, since 
its  average  mutation  score was  higher than  80 %.  When 
U  2 9, using 4-factor covering  designs or larger test suites 
are needed for the same effectiveness. 
Tables 6, 7, 8, and 9 show the  average  mutation  scores 
for  each  mutation  type  and  each  group  by  methods. 
In 
all  entries, the  left  and  right  side  values  show the  average 
mutation  scores for each method and for randomly  selected 
test  suites  of  exactly  the  same  size,  respectively.  These 
tables  summarize the  raw  data  which  are shown  in  Tables 
IO,  11, 12, 13, and  14. 
From  these  four  tables, one can  see that  combinatorial 
testing did not work well  in detecting VRFs.  For example, 
the  average  mutation  scores of  3-factor covering  designs 
where 5  5  U  5 8 were 92.l%, 93.6%, 70.4%, 86.9%, and 
86.9%  for  VNF,  ENF, VRF,  ORE and  ASF,  respectively. 
This finding suggests that to enhance combinatorial testing, 
further research  should be focused o n  detecting VRFs. 
On  the  other hand, BMIS  achieves  more than  85% for 
every  mutation  type.  This  seems counter-intuitive,  since 
BMIS constructs a test suite for a given boolean formula by 
hypothesizing  only VNFs in the disjunctive normal form of 
the formula.  We believe that  this fact can be  explained  as 
follows. 
First, we discuss the relationship  among VNF, ENF, and 
VRF.  Recently,  it  was reported  that  VNF, ENF, and  VRF 
are highly related  [ 181.  More specifically, [ 181 showed that 
when a specification is in a disjunctive form, tests that detect 
VRF will detect VNF, and tests that detect VNF will detect 
ENF. These results not only explain the high mutation score 
for ENF but  also justify  the  above  suggestion to improve 
combinatorial testing.  The hierarchy  of fault models is ex- 
hibited in Tables 6 , 7 ,  8, and 9. Also this can be seen more 
clearly  in  Tables  IO,  1 1,  and  12, which  show the mutation 
score for  each  specification  for  VNF,  ENF,  and  VRF,  re- 
spectively.  As can  be  seen  in  these  tables,  for  almost  all 
specifications, the score for ENF is higher than VNF and the 
score for VNF is higher than VRF. 
High mutation scores for ORF and ASF of BMIS cannot 
be explained by the above reasons.  We think that this reason 
is that many of these faults were easy to detect. Actually, as 
shown  in  Tables  13 and  14, the mutation  scores of 3-factor 
and 4-factor covering designs and BMIS for ORF and ASF 
were close to 100 % for many specifications. 
However,  it should be  noted  that there are some speci- 
fications for which  the mutation  scores were very  low  for 
ASF. For example, #9 and #18 are such specifications.  Ta- 
ble  14 shows that the mutation scores of BMIS for the two 
specifications were only 66.7 5%  and 40.0 %. At present, we 
do not know the cause of this low performance. Not only for 
ASF but also for many other fault types, little research  has 
been  conducted on their properties.  We think  that  studies 
that  investigate  the characteristics of various  faults  will  be 
important for developing efficient test generation  schemes. 
5  Conclusions 
In  this  paper,  we  examined  the  applicability  of  non- 
specification-based approaches to logic testing for software, 
by using a set of 20 specifications taken from the specifica- 
tion for a real aircraft collision avoidance system (TCAS 11). 
As non-specification-based  approaches, we selected combi- 
natorial  testing,  which  uses  factor  covering  designs,  and 
random testing.  We used mutation  analysis for the assess- 
ment of effectiveness.  To our knowledge, this study is the 
first to examine the applicability of the combinatorial test- 
ing  approach  to  logic  testing.  The results of  the  analysis 
showed that combinatorial testing was often comparative to 
specification-based testing and was always much superior to 
random testing.  Also it was found that it is difficult to detect 
VRFs by combinatorial testing.  Therefore we believe that it 
is possible to improve combinatorial testing by focusing on 
detecting VRFs. 
We plan to further develop the research on factor covering 
designs.  For  example, we are planing  an analysis  using  a 
much larger number of formulas. 
Acknowledgements 
The authors wish to thank Dr.  Jean Arlat for his helpful 
suggestions on how to improve the paper. 
References 
[I] B.  Beizer,  Black-Box  Testing, John  Wiley  & Sons, 
1995. 
[2]  K. Burr and W. Young, “Combinatorial test techniques: 
Table-based automation, test generation and code cov- 
erage,” Proc. Software  Testing Analysis & Review  (S- 
TAR’98 West), Oct. 1998. 
[3]  K. Burroughs, A. Jain  and R. L. Erickson, “Improved 
quality  of  protocol  testing  through  techniques  of  ex- 
perimental  design,”  Proc.  International  Conference 
on Communications (ICC’94) New York, pp.745-752, 
1994. 
345 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:02:50 UTC from IEEE Xplore.  Restrictions apply. 
[4]  T. Y.  Chen  and M. F.  Lau,  “Two  test  data  selection 
strategies  towards  testing of  boolean  specifications,” 
Proc. International  Computer Software  and Applica- 
tions Conference (COMPSAC’97), pp.608-611,  1997. 
[SI D. M. Cohen, S. R. Dalal, M. L. Fredman, and G. C. 
Patton,  “The AETG system:  An  approach  to testing 
based on combinatorial design,” IEEE Trans. on Soft- 
ware  Engineering,  Vol.  23, No.  7, pp.437-443,  July 
1997. 
[6]  D. M.  Cohen  and  M.  L. Fredman, “New  techniques 
for  designing  qualitatively  independent  systems,”  J. 
of Combinatorial Designs, Vol. 6, No. 6, pp.4 1 1-4 16, 
1998. 
[7]  S. R. Dalal  and  C. L. Mallows,  “Factor-covering de- 
signs for testing software,” Technometrics, Vol. 40, No. 
3, pp.234-243, Aug. 1998. 
[8]  R. A. DeMillo, R. J. Lipton, and F. G. Sayward, “Hints 
on test data selection:  Help for the practicing program- 
mer,” IEEE Computer Magazine, Vol. 1 1, 1978. 
[9]  I. S. Dunietz, C. L. Mallows, and A. Iannino, “Apply- 
ing design  of experiments to software testing,” Proc. 
the  19th international  Conference of Sofivare  Engi- 
neering (ICSE ’97), pp.205-215,  1997. 
[ 101  J. W. Duran and S. C. Ntafos, “An evaluation of random 
testing,”  IEEE  Truns. Software  Engineering,  Vol. 10, 
NO.4, pp.438-444,  1984. 
[I 11  K. A. Foster, “Sensitive test data for logic expressions,” 
ACM  SIGSOFT  Sofmare  Engineering  Notes,  Vo1.9, 
No.2, pp. 120- 125, 1984. 
[ 121  D. Harel,  “Statecharts:  A  visual  formalism  for com- 
plex  systems,”  Science  of  Computer  Programming, 
VoI.8, pp.231-274,  1987. 
[I31 C.  Heitmeyer,  J.  Kirby,  and  B.  Labaw,  “The  SCR 
method  for  formally  specifying,  verifying  and  vali- 
dating software requirements:  tool support,” Proc. the 
19th International  Conference on Software Engineer- 
ing (ICSE’97), pp.610-61 I ,  May  1997. 
[ 141  K. L. Heninger, “Specifying software requirements for 
complex systems:  new techniques  and  their applica- 
tion,”lEEE Trans. SofnYare  Engineering, Vo1.6, No. 1, 
pp.2-13,  1980. 
[ 151  J. Huller, “Reducing time to market with combinatorial 
design method testing,” Proc. International Council on 
Sys rems Engine e ring (INC 0 SE2000), 2000. 
[ 161  R. B. Hurley, Decision Tables in Software Engineering, 
Van Nostrand Reinhold,  1983. 
[17]  D. C. Ince and S. Hekmatpour, “Empirical evaluation 
of  random  testing,”  The  Computer Journal,  Vo1.29, 
No.4, p.380, 1986 
[ 181  D.  R.  Kuhn,  “Fault  classes  and  error  detection  ca- 
pability  of  specification-based  testing,” ACM  Trans. 
Sofmare Engineering and Methodology, Vo1.8, No.4, 
pp.4 1 1-424, 1999. 
[I91 N.  G. Leveson, M. P.  E. Heimdahl, H. Hildreth,  and 
J. D. Reese, “Requirements specification for process- 
control systems,” IEEE Trans. Sofhvare Engineering, 
V01.20, No.9, pp.684-707, 1994. 
[20]  G. J. Myers, The Art of Software Testing, John  Wiley 
& Sons,  1979. 
[21]  D. J. Richardson  and M. C. Thompson, “An analysis 
of test data selection criteria using the RELAY model 
of fault detection,” IEEE Trans. Software Engineering, 
Vol.19, No.6, pp.533-553,  1993. 
[22]  P.  ThCvenod-Fosse,  H.  Waeselynck, and  Y.  Crouzet, 
“An experimental  study of  software structural testing: 
Deterministic versus random  input generation,” Proc. 
the 21st  International  Symposium  on  Fciult-Tolerant 
Conputing  (FTCS-2 I),  MontrCal,  Canada,  pp.4 10- 
417, 1991. 
[23]  P.  ThCvenod-Fosse,  H.  Waeselynck, and  Y.  Crouzet, 
“Software statistical testing,” in Predictably  Depend- 
able  Computing Systems  (B. Randell, J-C. Laprie, H. 
Kopetz and  B.  Littlewood, Eds),  ESPRIT Basic  Re- 
search Series, pp.253-72, Springer Verlag,  1995. 
[24]  M. Vouk, K. Tai, and A. Paradkar, “Empirical studies 
of  predicate-based  software  testing,”  Proc.  Interna- 
tional Symposium on Software Reliability Engineering 
(ISSRE’94), pp.55-64, 1994. 
[25]  C .  H. West, “Protocol validation - principles and appli- 
cations,“Computer Networks and ISDN  Systems, Vol. 
24, No. 3, pp.219-242, May  1992. 
[26]  E.  Weyuker,  T.  Goradia,  and  A.  Singh,  “Automat- 
ically  generating  test  data  from  a  boolean  specifi- 
cation,”  IEEE  Trans.  Software  Engineering,  V01.20, 
No.5, pp.353-363,  1994. 
271  L.White, “Regression testing of CUI event interaction- 
s”, Proc.  of the International  Conference on Software 
Maintenance  (ICSM’96),  Washington,  DC,  pp.350- 
358,  1996. 
281  A. W. Williams and R. L. Probert, “A practical strategy 
for testing pair-wise coverage of network interfaces,” 
Proc.  of International  Symposium on Software  Relia- 
bility Engineering (ISSRE ’97), pp.246-254,  1997. 
346 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:02:50 UTC from IEEE Xplore.  Restrictions apply.