ε ρψ w.r.t. χ.)
Session 9C: Zero-Knowledge ProofsCCS ’19, November 11–15, 2019, London, United Kingdom2097The definition of a subdistribution is constructed to deal with
adversaries. As a concrete example consider extraction by rewind-
ing: It may happen that the adversary does not correctly answer a
challenge. Thus, the challenges which are answered are a subset, or
more generally a subdistribution. An adversary with success prob-
ability ε must succeed on a subdistribution of weight ε.
Definition 2.9. A testing distribution χm for Fm
p with sound-
ness δsnd(κ) is a distribution over Fm
p with following property: For
all subdistributions ψ of χm with weight ε (cid:21) δsnd B δsnd(χm ), we
have
P(xi   ψ ; X = (x1; : : : ; xm ) : det(X ) = 0) (cid:20) 1
ε δsnd:
We write δsnd(χm ) for some (fixed) soundness error of χm.
∩
Note that det(X ) , 0, is equivalent to all xi being linearly inde-
⊤
i ) = f0g. These interpretations allow
pendent, and to
to generalise in different directions. For more about testing distri-
butions, see the full version [31]. Typically, we want that δsnd(χ )
is very small, e.g. 2
(cid:0)100 in practice.
m
i=1 ker(x
For our examples, we need a minor generalisation of the lemma
of Schwartz–Zippel. For details, see Appendix A.1.
Example 2.10 (Polynomial testing). The distribution induced by
x = (x 0; : : : ; xm(cid:0)1), where x   Fp, is a testing distribution.
This follows from X being a Vandermonde matrix, hence invert-
ible except if the same x was chosen twice. It is easy to see that
δsnd(χ ) (cid:20) m
p .
Example 2.11. For the special case m = 2, and testing distribu-
tion with x = (α; 1) where α   S for some S (cid:18) Fp we write χ (β )
and α   χ (β ). If S (cid:18) F(cid:2)
p , i.e. α , 0, we write χ (β,0).
Example 2.12 (Random testing). The uniform distribution over
Fm
p is a testing distribution. The Lemma of Schwartz–Zippel imme-
diately yields δsnd(χ ) (cid:20) m
p . Drawing from a set S of “small expo-
nents”, e.g. from S = f1; : : : ; ℓg, still has soundness δsnd(χ ) (cid:20) m
ℓ .
Example 2.13 (Pseudo-random testing). The verifier can replace
truly random choices, e.g. x   Fm
p as above, by pseudorandom
choices, e.g. x   PRG(s) for s   f0; 1gκ. This allows the verifier
to compress such challenges to a random seed s.
It is heuristically plausible, that any non-pathological PRG has
distribution with soundness error (negligibly close) to that of the
respective uniform distributions. For more, see the full version [31].
Note that soundness of testing distributions is a combinatorial
property. No pseudorandomness property is required, as illustrated
by Example 2.10. Thus, there may be better options to use “small
exponents” than (pseudo)random testing.
2.3.1 Dual testing distributions. Due to space constraints, dual test-
ing distributions are not explicitly used in the main body, so we
omit their definition. Morally, testing distributions test whether
some z 2 Fm
p is 0. Dual testing distributions enforce z = 0. Dual
testing distributions can be used to derive fresh (Pedersen) com-
mitment keys, and guarantee that no commitment generated prior
can be opened (except to 0).
2.4 Special soundness
In the main body, we only consider special soundness and give ex-
tractors which produce a witness given a suitable tree of accepting
transcripts, see also [10].
Definition 2.14 (µ-special soundness (over Fp)). Let (GenCRS; P; V)
be a public coin argument system for R. Suppose the verifier sends
n challenges and µ = (µ0; : : : ; µn(cid:0)1) 2 Nn. Furthermore, suppose
the challenges are vectors in Fni
p . Then the protocol is µ-special
sound if there exists an extractor Ext such that given any good
µ-tree treeµ of transcripts, Ext(st; treeµ ) returns a witness w with
(st; w) 2 R. A µ-tree of transcripts is a (directed) tree where nodes
of depth i have µi children, with edges labelled with the i-th chal-
lenge, and nodes labelled with the prover’s i-th answer, and every
path along the tree constitutes an accepting transcript. We call a µ-
tree good if for every node, all its challenges (i.e. outgoing edges)
are in general position.¹
Given a TreeFind algorithm, which produces good µ-trees (with
oracle access to a successful prover), and an extractor as above,
one obtains witness extended emulation by plugging the tree into
the extractor. To be able to speak about the security of the resulting
protocol, one needs success and runtime guarantees of TreeFind. We
do not deal with this here as it is a separate issue. See [10, 40] for
TreeFinders and the full version [31] for more details.
Short-circuit extraction. Suppose TreeFind produces the tree’s
2.4.1
nodes and leaves on demand, and Ext queries TreeFind as an oracle,
and traverses the tree in depth-first order. Moreover, suppose Ext ei-
ther extracts a witness for some statement, or a solution to a (sup-
posedly) hard problem, or both. Concretely, we have statements
like “we extract w such that either [д]w = [c] is a valid commit-
ment opening, or [д]w = [0] breaks the hard kernel assumption
′ (cid:20) µ
for [д].” In such a situation, short-circuit extraction with µ
asserts that, extraction either finds the opening w using only the
′-subtree of treeµ, or for one layer i, all µi children are examined,
µ
and the extractor finds a non-trivial w in ker([д]).
′
i
′ (cid:20) µ (i.e. µ
Definition 2.15. Consider the situation in Definition 2.14. Sup-
pose R is OR(R1; R2), i.e.
R = f((st1; st2); (w1; w2)) j (sti ; wi ) 2 Ri for i = 1 or i = 2g:
(cid:20) µi for all i) such that
Suppose there is some µ
extractor Ext has following property. For any good µ-tree treeµ,
Ext(st; treeµ ) we have either:
′-subtree of treeµ and returns
(cid:15) Ext finishes after exploring a µ
a witness for st1. We call this quick-extraction.
′
(cid:15) If in layer ℓ of the tree, Ext must explore more than µ
ℓ chil-
dren of some node, then after exploring all µℓ children, Ext
returns a witness for st2 (and perhaps st1). (That is, Ext short-
circuits in layer ℓ.)
′ (cid:20) µ
We say that such an Ext has short-circuit extraction with µ
for finding a witness to st1 or to st2. (Note that order of the state-
ments matters!)
Our definition is ad-hoc and tailored to our needs. We leave a
solid definition and precise treatment of short-circuit extraction
for future work.
¹ Vectors x1; : : : ; xN 2 Fn
p are in general position if any subset of size n is a basis.
Session 9C: Zero-Knowledge ProofsCCS ’19, November 11–15, 2019, London, United Kingdom2098′
′
0
= (µ
∏
Corollary 2.16.
If Ext as in Definition 2.15 traverses a good tree
∑
treeµ in depth-first order, we have following “runtime” guarantees:
′
n(cid:0)1) (cid:20) (µ0; : : : ; µn(cid:0)1) = µ. In case of quick-
Let µ
n(cid:0)1
′
i leafs are explored. In case of short-circuit
extraction, at most
i=0 µ
n(cid:0)1
i=0(µi (cid:0)
extraction, at most s0 +1 leaves are explored, where s0 =
′
i ).
1)
′
j . In particular, s0 (cid:20) (
n(cid:0)1
i=0 µi )(
n(cid:0)1
j=i+1 µ
n(cid:0)1
i=0 µ
∏
∏
∑
; : : : ; µ
We note that since the tree treeµ is randomised (or Ext might
explore children in random order), the above worst-case analysis
is very conservative.
3 HVZK ARGUMENTS FOR [A]w = [t]
Let ck B [д] = [д0; д]   G1(cid:2)n+1 be a Pedersen commitment key,
where [д0] 2 G and [д] 2 Gn. Define Comд(w; r ) B [д0]r + [д]w
for r 2 Fp, w 2 Fn
p . In the whole section, we work with matrices
[A] 2 Gm(cid:2)n, and vectors w 2 Fn
p and [t] 2 Gm. The dimensions
are as above, unless otherwise specified. Our witness relation R is
st = ([A]; [t]) and w = w such that (st; w) 2 R () [A]w = [t].
3.1 Intuition
In this section, we devise communication efficient public-coin HVZK
arguments for knowledge of a preimage of a linear map, i.e. 9w :
[A]w = [t]. We follow two principles: “Use probabilistic (batch)
verification to check many things at once” and “If messages are
too long, replace them by a shorter proof (of knowledge).” For this,
we use shrinking commitments, to keep the messages small.
Our strategy is as follows: First, we recall the well-known gen-
eral HVZK protocol [16, 36] for proving 9w : [A]w = [t] where
[A] 2 Gm(cid:2)n. Then, we show how to apply batch verification to re-
duce the argument for ([A]; [t]) to another an argument for some
([B]; [u]) with [B] 2 G2(cid:2)n. This makes communication indepen-
dent of the number m of rows of [A]. After this, we revisit the ar-
guments from [10] which recursively batch statement and witness,
i.e. they reduce the number n of columns of [A]. Unlike [10, 13], we
need a zero-knowledge version of these arguments. We provide a
very efficient conversion with constant communication and loga-
rithmic computational overhead. Taken together, we can for any
[A] prove knowledge of w in communication O(log(n)) now.
3.2 Step 0: A standard (cid:6)-protocol for [A]w = [t]
We recall the prototypical (cid:6)-protocol in a group setting [16, 36].
Protocol 3.1 ((cid:6)std). The following is a protocol to prove9w : [t] =
[A]w, using testing distribution χ (β ) for challenges, c.f. Example 2.11.
Common input is ([A]; [t]) 2 Gm(cid:2)n (cid:2) Gn. The prover’s witness is
some w 2 Fn
p .
p and let [a] = [A]r. Send [a] 2 Gm.
(cid:15) P ! V: Pick r   Fn
(cid:15) V ! P: Pick β   χ (β ). Send β 2 Fp.
(cid:15) P ! V: Compute z = βw + r. Sends z 2 Fn
p .
(cid:15) V: Check if [A]z = β[t] + [a]. (Accept/reject if true/false.)
It is straightforward to show that any (x1; x2)   χ2 can be used
instead of χ (β ), as long as x2 , 0, so that x1w + x2r is uniformly
distributed, c.f. Section 1.1.
Lemma 3.2. Protocol (cid:6)std is a HVZK-PoK for 9w : [A]w = [t]. It
is perfectly complete, has perfect HVZK and is 2-special sound.
Proof. Completeness is straightforward. Extraction: We are
′
′; z
) with β(cid:0)
given two accepting transcripts ([a]; β; z), and ([a]; β
′ , 0. Due to the final check of the verifier, we obtain 1
β(cid:0)β′ [A](z(cid:0)
β
′
′
β(cid:0)β′ (z (cid:0) z
) = [t]. Consequently, w B 1
) is a witness.
p . Then [a] B [A]z (cid:0) β[t]
HVZK: Pick β   χ (β ) and z   Fm
is uniquely defined. Since the distribution of β and z is as in an
□
honest execution, this yields a perfect simulation.
z
Now, we improve communication efficiency. We apply the tech-
niques mentioned in the introduction, using shrinking commitments
to keep messages small. Composition of proof systems is implicit
due the following remark.
Remark 3.3. AND-proofs for statements of the form9w : [A]w =
[t] are trivial. Namely, to prove 9w : [A1]w = [t1] ^ [A2]w =
and prove
[t2], it suffices to define [A] =
9w : [A]w = [t]. This AND-compilation technique will be used
without explicit mention. Evidently, many trivial optimisations are
possible, e.g. removing duplicate rows.
and [t] =
A1
A2
[
]
[
]
t1
t2
3.3 Step 1: Batching all equations together
In this step, we devise a HVZK-AoK for 9w : [A]w = [t], where
P’s communication is independent of m, the “number of equa-
tions”. Thus, we have to shrink the message [a] 2 Gm somehow.
We would like to batch all m linear equations (given by [A]) into
a single linear equation, i.e. replace [A] by a random linear combi-
nation of its rows. We do not know whether this is sound or not.
Nevertheless, if P has explicitly committed to the witness w (or
[a]), the statement — excluding the commitment — can be batched,
as P cannot change his mind anymore. Note that the value [t] is in
general not a commitment, since the adversary may supply (parts
of) [A] in the soundness experiment. Thus, he may know dlogs and
generate preimages of [t] freely. By adding a commitment to w,
we get around this problem. Using a shrinking (Pedersen) commit-
ment to w, keeps the communication overhead small. Now, the
verifier can send batching randomness, and a HVZK-AoK for the
batched statement is carried out. Details are in the full version [31]
We thus reduced general [A] to [B] 2 F2(cid:2)n
, where the (say top) row
of [B] is a commitment key.
p
д
A
Remark 3.4 (Commitment extending). When working with ad-
versarial [A] (and [t]), one can not rely on hardness assumptions.
Extending [A] to, for example, [B] =
with commitment key
[д] is one way to circumvent problems. For the sake of referencing,
we call this commitment extending [A].
3.4 Step 2: “Batching” the witness
In this section, we show how to “batch” the witness, i.e. proving
9w : [A]w = [t] for [A] 2 Gm(cid:2)n with communication sublinear in
n. For the introduction, one may assume m = 1, e.g. [A] = [д].
3.4.1 The general idea. We present the technique of [10], but in
our situation and notation. For the motivation, let us ignore zero-
knowledge, and only construct an argument (of knowledge). We
add zero-knowledge later.
In general, one can achieve a size reduction of k 2 N recursive
step. For proof size, k = 2 is optimal, so we restrict ourselves to
[
]
Session 9C: Zero-Knowledge ProofsCCS ’19, November 11–15, 2019, London, United Kingdom2099p
(
that. The full version [31] deals with general k. Assume for simplic-
ity that 2jn, i.e. n/2 2 N. We will reduce the equation [A]w = [t]
, [bt] 2 Gm. To do so,
) 2 (Gn/2)2. We want to prove
to [bA]bw = [bt], where [bA] 2 Gm(cid:2)n/2,bw 2 Fn/2
∑
divide [A] and w into 2 equal blocks,² obtaining vectors/matrices
of vectors/matrices i.e. [A] = [A1jA2] 2 (Gm(cid:2)n/2)1(cid:2)2 with [Ai ] 2
Gm(cid:2)n/2, and likewise w =
i=1[Ai ]wi = [t].
2
Still, the techniques from Section 3.3 are not applicable, because
[t] 2 G (if m = 1). The trick of [10] is to embed our problem into a
different one which can be batch-verified. Namely, we exploit that
the scalar product is the sum of the diagonal entries (i.e. the trace)
of the outer product: