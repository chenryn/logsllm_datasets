title:Facilitating Privacy-preserving Recommendation-as-a-Service with Machine
Learning
author:Jun Wang and
Afonso Arriaga and
Qiang Tang and
Peter Y. A. Ryan
POSTER: Facilitating Privacy-preserving
Recommendation-as-a-Service with Machine Learning
Jun Wang
Peter Y.A. Ryan
Afonso Arriaga
Qiang Tang
University of Luxembourg
PI:EMAIL
University of Luxembourg
PI:EMAIL
LIST
PI:EMAIL
University of Luxembourg
PI:EMAIL
ABSTRACT
Machine-Learning-as-a-Service has become increasingly popular,
with Recommendation-as-a-Service as one of the representative
examples. In such services, providing privacy protection for the
users is an important topic. Reviewing privacy-preserving solutions
which were proposed in the past decade, privacy and machine learn-
ing are often seen as two competing goals at stake. Though improv-
ing cryptographic primitives (e.g., secure multi-party computation
(SMC) or homomorphic encryption (HE)) or devising sophisticated
secure protocols has made a remarkable achievement, but in con-
junction with state-of-the-art recommender systems often yields
far-from-practical solutions.
We tackle this problem from the direction of machine learn-
ing. We aim to design crypto-friendly recommendation algorithms,
thus to obtain efficient solutions by directly using existing cryp-
tographic tools. In particular, we propose an HE-friendly recom-
mender system, referred to as CryptoRec, which (1) decouples user
features from latent feature space, avoiding training the recom-
mendation model on encrypted data; (2) only relies on addition
and multiplication operations, making the model straightforwardly
compatible with HE schemes. The properties turn recommendation-
computations into a simple matrix-multiplication operation. To fur-
ther improve efficiency, we introduce a sparse-quantization-reuse
method which reduces the recommendation-computation time by
9× (compared to using CryptoRec directly), without compromising
the accuracy.
We demonstrate the efficiency and accuracy of CryptoRec on
three real-world datasets. CryptoRec allows a server to estimate
a user’s preferences on thousands of items within a few seconds
on a single PC, with the user’s data homomorphically encrypted,
while its prediction accuracy is still competitive with state-of-the-
art recommender systems computing over clear data. Our solution
enables Recommendation-as-a-Service on large datasets in a nearly
real-time (seconds) level.
KEYWORDS
Privacy-preserving; Recommender System
Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).
CCS ’18, October 15–19, 2018, Toronto, ON, Canada
© 2018 Copyright held by the owner/author(s).
ACM ISBN 978-1-4503-5693-0/18/10.
https://doi.org/10.1145/3243734.3278504
ACM Reference Format:
Jun Wang, Afonso Arriaga, Qiang Tang, and Peter Y.A. Ryan. 2018. POSTER:
Facilitating Privacy-preserving Recommendation-as-a-Service with Ma-
chine Learning. In 2018 ACM SIGSAC Conference on Computer and Commu-
nications Security (CCS ’18), October 15–19, 2018, Toronto, ON, Canada. ACM,
New York, NY, USA, 3 pages. https://doi.org/10.1145/3243734.3278504
1 INTRODUCTION
We consider a common case in the real world: a service provider
(server) like Amazon, wishes to monetize the user data they have
collected, by providing recommendation services, and a client wants
to obtain personalized recommendation services. However, none
of them is willing to reveal their data or the models learned from
the data, due to privacy concerns or commercial constraints.
A natural approach is to deploy a secure framework, which al-
lows a server to compute recommendations over encrypted client
data, sending back the encrypted results that the client can decrypt.
The encryption ensures the data confidentiality since the server
does not have access to the secret keys for decryption. We propose
an HE-friendly recommender system, CryptoRec, which signifi-
cantly improves the efficiency of computing recommendations on
encrypted data without compromising accuracy performance.
2 OUR SOLUTION: CRYPTOREC
State-of-the-art recommendation algorithms, such as matrix factor-
ization [6] and AutoRec [10], require jointly learning individualized
user and item features on all the observed user data. Performing
this training process in a cipher space will lead to an efficiency bot-
tleneck immediately. The key technical innovation of our proposed
model, CryptoRec, is to decouple user features from the feature
space. The model learns only item features on clear data. To con-
struct personalized user features, we exploit the fact that a user
profile is essentially identified by items (e.g., movies, musics) that
the user has rated (ru), to model the personalized user features pu
by aggregating pre-learned item features Q = {qi}m
i =1 as follows,
(1)
therefore we can approximate an observed rating by
qT
i
(2)
pu = ruQ
(cid:124)(cid:123)(cid:122)(cid:125)
rui ≈ ˆrui = (ruQ)
pu
Using only a single item feature space Q to model a large number
of user ratings often leads to an information bottleneck. To address
this issue, we increase the model expressiveness by relaxing the
item features which were used to construct the user features P, and
redefine the Equation (2) as
qT
i
(3)
(cid:124)(cid:123)(cid:122)(cid:125)
rui ≈ (ruA)
pu
Poster PresentationCCS’18, October 15-19, 2018, Toronto, ON, Canada2306Note that A ∈ Rm×d is a new feature space which is independent
from Q. To further improve accuracy, we incorporate linear biases
into the estimation function (i.e., Equation (3)), we have
rui ≈ ˆrui = µ + bu + bi + (ruA)qT
i
(4)
(u,i)∈R rui
n
N
where µ =
is the global rating average, N is the number
of observed ratings. bu ( bu = ¯ru−µ) and bi (bi = ¯ri−µ) approximate
the user bias and item biases, respectively. ¯ru (¯ri) is the mean rating
value of user u (item i).
Obviously, besides decoupling user features from the latent fea-
ture space, CryptoRec only relies on addition and multiplication
operations. The model parameters Θ = {A, Q} are learned by solv-
ing the regularized least squares objective function,
(5)
u=1
L =
||(ˆru − ru) · ϕu||2 + λ · (∥A∥2 + ∥Q∥2)
where ˆrui is defined in Equation (4), ϕu = {ϕui}m
i =1 and (ˆru −
ru) · ϕu denotes {(ˆrui − rui)ϕui}m
i =1. If user u rated item i, then
ϕui = 1, otherwise, we let ϕui = 0 and rui = 0. We use ϕui to
remove the (incorrect) gradients computed on unobserved ratings.
The constant λ is the regularization factor. For more details on
the training process, we refer to the full version of this paper [11,
Section IV.B].
2.1 Secure Prediction Protocol
client (Input: rv , ¯rv)
(cid:74)rv(cid:75) ← HE.Enc(rv , pk)
(cid:74)¯rv(cid:75) ← HE.Enc(¯rv , pk)
ˆrv ← HE.Dec((cid:74)ˆrv(cid:75), sk)
server ( Input: Θ)
(cid:74)rv(cid:75),(cid:74)¯rv(cid:75)
−−−−−−−−→ (cid:74)ˆrv(cid:75) ← P((cid:74)rv(cid:75),(cid:74)¯rv(cid:75), Θ)
(cid:74)ˆrv(cid:75)←−−−−
Figure 1: Predication with pre-trained Θ = {A, Q}
We describe the basic form of securely computing recommen-
dations with pre-trained CryptoRec parameters Θ, in Figure 1. A
client v encrypts (HE.Enc) her data (rv, ¯rv) and sends it ((cid:74)rv(cid:75),(cid:74)¯rv(cid:75))
the result ((cid:74)ˆrv(cid:75)) that only the client can decrypt (HE.Dec).
to the server. With the pre-trained Θ, the server executes the pre-
diction process P (Algorithm 1) over the encrypted data and return
Algorithm 1 shows that the computation is straightforward since
CryptoRec only relies on additions and multiplications. ⊙ presents
a multiplicative operation between a plaintext and a ciphertext. ⊕
denotes an additive operation between two ciphertexts.
The data security and the correctness of algebraic operations
are guaranteed by HE primitives straightforwardly. The client can
(always) generate a new pair of secret/public keys to encrypt its
data when requiring recommendation services. The server trains a
randomly initialized CryptoRec model with a stochastic method,
so the learned model is non-deterministic.
Algorithm 1 CryptoRec prediction process P (server)
Input: ratings(cid:74)rv(cid:75), mean(cid:74)¯rv(cid:75) , Θ = {A, Q, µ, bu , bi}
Output: recommendations(cid:74)ˆrv(cid:75)
1: procedure P((cid:74)rv(cid:75),(cid:74)¯rv(cid:75), Θ)
(cid:74)pv(cid:75) ←(cid:74)rv(cid:75)A
(cid:74)x1(cid:75) ← bi ⊕(cid:74)¯rv(cid:75)
(cid:74)x2(cid:75) ←(cid:74)pv(cid:75)qT
(cid:74)ˆrvi(cid:75) ←(cid:74)x1(cid:75) ⊕(cid:74)x2(cid:75)
(cid:74)ˆrv(cid:75)[i] ←(cid:74)ˆrvi(cid:75)
return(cid:74)ˆrv(cid:75)
for i ← [1, 2,· · · , m] do
2:
3:
4:
5:
6:
7:
8:
i
▷ HE dot-product using ⊙ and ⊕
▷ bv ← ¯rv − µ
3 EXPERIMENT SETUP
We employ state-of-the-art collaborative filtering algorithms as
baseline models, including I-NBM [3], BiasedMF [6], U-AutoRec [10]
and I-AutoRec [10]. We perform tests on three real-world datasets
(Table 1). The testbed is a single PC with an Intel Xeon(R) CPU (8
cores) running at 3.5 GHz, running Ubuntu 16.04. The root mean
square error (rmse) is adopted as the accuracy metric, rmse =
where D is the testing set. The lower the RMSE
value, the higher the accuracy performance is. To measure the
accuracy, we perform a 5-fold cross-validation.
(cid:114)(u,i)∈D(ˆrui−rui)2
|D|
scale
[1,5]
netflix [8]
[1,5]
ml1m [5]
yahoo [12]
[1,5]
Table 1: Datasets used for benchmarking
density
2.17%
4.2%
0.72%
user #
11,000
6,040