pages are created and the original page is copied into both of
them. This effectively creates two copies of the program’s
memory space in physical memory. The pagetable entries
corresponding to the code and data pages are changed to
map to one of those copies of the memory space, leav-
ing the other copy unused for the moment.
In addition,
the pagetable entries for those pages get the supervisor bit
cleared, placing that page in supervisor mode in order to be
sure a page fault will occur when that entry is needed. A
previously unused bit in the pagetable entry is used to sig-
nify that the page is being split. In total, about 90 lines of
code are added to the ELF loader.
In this particular implementation of split memory the
memory usage of an application is effectively doubled,
however this limitation is not one of the technique itself,
but instead of the prototype. A system can be envisioned
based on demand-paging (only allocating a code or data
page when needed) instead of the current method of proac-
tively duplicating every virtual page. We would anticipate
this optimization to not have any noticeable impact on per-
formance.
Modiﬁcations to the Page Fault Handler
Under Linux, the page fault (PF) handler is called in re-
sponse to a hardware generated PF interrupt. The handler is
responsible for determining what caused the fault, correct-
ing the problem, and restarting the faulting instruction.
For our modiﬁcations to the PF handler we simply mod-
ify it to handle a new reason for a PF: There was a permis-
sions problem caused by the supervisor bit in the PTE. We
must be careful here to remember that not every PF on a
split page is necessarily our fault, some PFs (such as ones
involving copy-on-write), despite being on split memory
pages, must be passed on to the rest of the PF handler in-
stead of being serviced in a split memory way. If it is deter-
mined that the fault was caused by a split memory page and
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:52:10 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007Instruction Page 
Data Page 
Instruction Page 
Data Page 
Instruction Page 
Blank
(Zeros)
Return
Address
String Buffer 
0xbf000000
Blank
(Zeros)
0xbf000000
Attack Code 
Blank
(Zeros)
0xbf000000
0xbf000000
Data Page 
0xbf000000
Attack Code 
Processor
(a)
Processor
Data
Access
(b)
Instruction 
Access
Processor
(c)
Figure 3. (a) Before the attacker injects code (b) The injection to the data page (c) The execution
attempt that gets routed to the instruction page
that it does need to be serviced, then the instruction pointer
is compared to the faulting address to decide whether the
instruction-TLB or data-TLB needs to be loaded. (Recall
from algorithm 1 that this is done by simply checking if the
two are the same.)
If the data-TLB needs to be loaded, then the PTE is set
to user mode, a byte on the page is touched, and the PTE
is set back to supervisor mode. This pagetable walk loads
the data-TLB1. In the event the instruction-TLB needs to
be loaded, the PTE is set to user mode (to allow access
to the page) and the trap ﬂag (single-step mode) bit in the
EFLAGS register is set. This will ensure that the debug in-
terrupt handler gets called after the instruction is restarted.
Before the PF handler returns and that interrupt occurs,
however, a little bit of bookkeeping is done by saving the
faulting address into the process’ entry in the OS process
table in order to pass it to the debug interrupt handler.
In total there were about 110 lines of code added to the
PF handler to facilitate splitting memory.
Modiﬁcations to the Debug Interrupt Handler
The debug interrupt handler is used by the kernel to han-
dle interrupts related to debugging. For example, using a
debugger to step through a running program or watch a par-
ticular memory location makes use of this interrupt handler.
For the purposes of split memory, the handler is modiﬁed
to check the process table to see if a faulting address has
been given, indicating that this interrupt was generated be-
cause the PF handler set the trap ﬂag. If this is the case,
then it is safe to assume that the instruction which originally
caused the PF has been restarted and successfully executed
(meaning the instruction-TLB has been ﬁlled) and as such
the PTE is set to supervisor mode once again and the trap
ﬂag is cleared. In total, about 40 lines of code were added to
the debug interrupt handler to accommodate these changes.
1Occasionally the pagetable walk does not successfully load the data-
TLB. In this case, single stepping mode (like the instruction-TLB load)
must be used.
Modiﬁcations to the Memory Management System
There are a number of features related to memory manage-
ment that must be slightly modiﬁed to properly handle our
system. First, on program termination any split pages must
be freed specially to ensure that both physical pages (the
code page and data page) get put back into the kernel’s pool
of free memory pages. This is accomplished by simply
looking for the split memory PTE bit that was set by the
ELF loader above, and if it is found then freeing two pages
instead of just one.
Another feature in the memory system that needs to be
updated is the copy-on-write (COW) mechanism. COW is
used by Linux to make forked processes run more efﬁ-
ciently. That basic idea is that when a process makes a copy
of itself using fork both processes get a copy of the orig-
inal pagetable, but with every entry set read-only. Then, if
either process writes to a given page, the kernel will give
that process its own copy. (This reduces memory usage in
the system because multiple processes can share the same
physical page.) For split memory the COW system must
copy both pages in the event of a write, instead of just one.
A update similar to the COW update is also made to the
demand paging system. Demand paging basically means
that a page is not allocated until it is required by a process.
In this way a process can have a large amount of available
memory space (such as in the BSS or heap) but only have
physical pages allocated for portions it actually uses. The
demand paging system was modiﬁed to allocate two pages
instead of just the one page it normally does.
Overall, about 75 lines of code were added to handle
these various parts related to memory management.
5.2. Eﬀectiveness
The sample implementation was tested for its effective-
ness at preventing code injection attacks using a benchmark
originally put forth by Wilander et al [8]. The benchmark
was modiﬁed slightly in order to allow it to handle hav-
ing the code injected on the data, bss, heap, and stack por-
tions of the program’s address space. In addition, four of
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:52:10 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007Table 1. The number of attacks halted when code is injected onto the data, bss, heap, and stack
segments
Attack Type
Hijack Type
Buffer overﬂow on stack
Buffer overﬂow on heap/bss
Buffer overﬂow of pointers on stack
Buffer overﬂow on heap/bss
Return address
Old base pointer
Function pointer as local variable
Function pointer as parameter
Longjmp buffer as local variable
Longjmp buffer as function parameter
Function pointer
Longjmp buffer
Return address
Old base pointer
Function pointer as local variable
Function pointer as parameter
Longjmp buffer as local variable
Longjmp buffer as function parameter
Return address
Old base pointer
Function pointer as variable
Longjmp buffer as variable
Injection Destination
Data
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
N/A
N/A
(cid:1)
(cid:1)
(cid:1)
(cid:1)
N/A
N/A
(cid:1)
(cid:1)
BSS Heap
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
N/A
N/A
N/A
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
N/A
N/A
N/A
(cid:1)
(cid:1)
(cid:1)
(cid:1)
Stack
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
(cid:1)
N/A
N/A
(cid:1)
(cid:1)
(cid:1)
(cid:1)
N/A
N/A
(cid:1)
(cid:1)
Plain
Protected
 100
d
e
e
p
s
l
l
u
f
f
o
%
 80
 60
 40
 20
 0
the testcases did not successfully execute an attack on our
unprotected system, and so have been labeled “N/A.” Table
1 shows the results of running the benchmark. The check-
marks indicate that the system successfully halted the at-
tack. As can be seen, the system was effective in preventing
all types of code injection attacks present in the benchmark.
The effectiveness of the system is due to the fact that no
matter what method of control-ﬂow hijacking the bench-
mark uses, the processor is simply unable to fetch the in-
jected code.
5.3. Performance
A number of benchmarks, both applications and micro-
benchmarks, were used to test the performance of the sys-
tem. Our testing platform was a modest system, a Pentium
III 600Mhz with 384 MB of RAM and a 100MBit NIC.
When applicable, benchmarks were run 10 times and the
results averaged. Details of the conﬁguration for the tests
are available in table 2. Each result has been normalized
with respect to the speed of the unprotected system.
Four benchmarks that we consider to be a reasonable as-
sessment of the system’s performance can be found in Fig-
ure 4. First, the Apache [25] webserver was run in a thread-
ing mode to serve a 32KB page (roughly the size of Purdue
University’s main index.html). The ApacheBench program
was then run on another machine connected via the NIC to
determine the request throughput of the system as a whole.
The protected system achieved a little over 89% of the un-
protected system’s throughput. Next, gzip was used to com-
press a 256 MB ﬁle, and the operation was timed. The pro-
tected system was found to run at 87% of full speed. Third,