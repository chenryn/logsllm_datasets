title:Differentially Private Nonparametric Hypothesis Testing
author:Simon Couch and
Zeki Kazan and
Kaiyan Shi and
Andrew Bray and
Adam Groce
Differentially Private Nonparametric Hypothesis Testing
Simon Couch
Reed College
Portland, Oregon
PI:EMAIL
Zeki Kazan
Reed College
Portland, Oregon
PI:EMAIL
Kaiyan Shi
Reed College
Portland, Oregon
PI:EMAIL
Andrew Bray
Reed College
Portland, Oregon
PI:EMAIL
Adam Groce
Reed College
Portland, Oregon
PI:EMAIL
ABSTRACT
Hypothesis tests are a crucial statistical tool for data mining and are
the workhorse of scientific research in many fields. Here we study
differentially private tests of independence between a categorical
and a continuous variable. We take as our starting point traditional
nonparametric tests, which require no distributional assumption
(e.g., normality) about the data distribution. We present private
analogues of the Kruskal-Wallis, Mann-Whitney, and Wilcoxon
signed-rank tests, as well as the parametric one-sample t-test. These
tests use novel test statistics developed specifically for the private
setting. We compare our tests to prior work, both on parametric
and nonparametric tests. We find that in all cases our new nonpara-
metric tests achieve large improvements in statistical power, even
when the assumptions of parametric tests are met.
CCS CONCEPTS
• Mathematics of computing → Nonparametric statistics; •
Security and privacy → Data anonymization and sanitiza-
tion.
KEYWORDS
differential privacy; hypothesis test; nonparametric
ACM Reference Format:
Simon Couch, Zeki Kazan, Kaiyan Shi, Andrew Bray, and Adam Groce.
2019. Differentially Private Nonparametric Hypothesis Testing. In 2019
ACM SIGSAC Conference on Computer and Communications Security (CCS
’19), November 11–15, 2019, London, United Kingdom. ACM, New York, NY,
USA, 15 pages. https://doi.org/10.1145/3319535.3339821
1 INTRODUCTION
In 2011, researchers in Switzerland began an investigation into the
link between methylation levels of a given gene and the occurance
of schizophrenia and bipolar disorder[4]. They recruited patients
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
CCS ’19, November 11–15, 2019, London, United Kingdom
© 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-6747-9/19/11...$15.00
https://doi.org/10.1145/3319535.3339821
that suffered from psychosis as well as healthy controls and mea-
sured the level of methylation of the gene in each individual. They
found that levels in the groups suffering from psychosis were higher
than those in the healthy group. In order to rule out the possibility
that this difference was due to sampling variability, they relied upon
a suite of nonparameteric hypothesis tests to establish that this link
likely exists in the general population.
While the results of these tests were published in an academic
journal, the data itself is unavailable to preserve the privacy of
the patients. This is a necessary consideration when working with
sensitive data, but it hampers scientific reproducibility and the
extension of this work by other researchers.
Our goal in this paper is to provide nonparametric hypothesis
tests that satisfy differential privacy. The difficulty of developing a
private test comes not just from the need to privately approximate
a test statistic, but also from the need for an accurate reference
distribution that will produce valid p-values. It is not sufficient to
treat the approximate test statistic as equivalent to its non-private
counterpart.
In this paper, we present several new hypothesis tests. In all cases
we are considering data sets with a categorical explanatory variable
(e.g., membership in the schizophrenic, bipolar, or control group)
and a continuous dependent variable (e.g., methylation level). Our
goal when designing a hypothesis test is to maximize the statistical
power of the test, or equivalently to minimize the amount of data
needed to detect a particular effect.
In the traditional public setting, there are two families of tests for
these scenarios. The more commonly used are parametric tests that
assume that within each group, the continuous variable follows a
particular distribution (usually Gaussian). An alternative to these
tests are nonparametric tests, which make no distributional assump-
tion but, in exchange, have slightly lower power. Nonparametric
tests generally rely upon substituting in, for each data point, the
rank of the continuous variable relative to the rest of the sample.
The test statistic is then a function of these ranks rather than the
original values.
The private hypothesis tests we propose all use rank-based test
statistics. Our overarching argument in this paper, beyond the
individual value of each of the tests we introduce, is that in the
private setting these rank-based test statistics are more powerful
than the traditional parametric alternatives. This is contrary to the
public setting, where the parametric tests (when their assumptions
are met) perform better.
Our second, broader point is that as a research community we
need to support the development of hypothesis tests specifically
tailored to the private setting. Our private test statistics are not
simply approximations of traditional test statistics from the public
setting and as a result, we find that they can require an order
of magnitude less data. Current tests used by statisticians in the
public setting have been refined through decades of incremental
improvement, and the same sort of development needs to happen
in the private setting.
1.1 Our contributions
We introduce several new private hypothesis tests that mirror the
three most commonly used rank-based tests. In one setting, this is
a private analog of the traditional public test statistic, but for the
remaining two settings it is a new statistic developed specifically for
the private setting. The privacy of these statistics generally follows
from non-trivial but reasonably straightforward applications of the
Laplace mechanism. Our main contribution is not the method of
achieving privacy but the construction of novel private hypothesis
tests with high statistical power.
There are two components to the construction of each hypothesis
test. The first is the creation of a test statistic to capture the effect of
interest while remaining provably private. The second is a method
to learn the distribution of the statistic under the null hypothesis in
order to compute p-values, which are the object of primary interest
to researchers.
In particular, we develop tests for the following cases:
Three or more groups. When the categorical variable divides the
sample into three or more groups, the traditional public test is the
one-way analysis of variance (ANOVA) in the parametric case and
Kruskal-Wallace in the nonparametric case. ANOVA has been previ-
ously studied by Campbell et al. [3] and then by Swanberg et al. [28],
who improved the power by an order of magnitude. We give the first
private nonparametric test by modifying the rank-based Kruskal-
Wallace test statistic for the private setting. We provide experimen-
tal evidence that this statistic has dramatically higher power than
a simple privatized version of the public Kruskal-Wallace statistic.
Moreover, we provide evidence that even in the parametric setting
(i.e., when the data is normally distributed) the private rank-based
statistic outperforms the private ANOVA test, in one representative
case requiring only 23% as much data to reach the same power.
Two groups. In the two group setting, the most common public
nonparametric test is the Mann-Whitney test. We provide an algo-
rithm to release an approximation of this statistic under differential
privacy and a second algorithm to conduct the test and release a
valid p-value.
In the public setting, the analogous parametric test is the two
sample t-test which is equivalent to an ANOVA test when there
are two groups. We compare therefore to the private ANOVA test
and show experimental evidence that our Mann-Whitney analog
has significantly higher power.
Paired data. We also consider the case where the two sets of
data are in correspondence with each other (e.g., before-and-after
measurements). The nonparametric test in this case is the Wilcoxon
signed-rank test, and it is the only nonparametric test that has pre-
viously been studied in the private setting[30]. We provide two
improvements to the prior work. First, we change the underlying
statistic to the less well-known Pratt variant, which we find con-
forms more easily to the addition of noise. Second, we show that
our simulation method for computing reference distributions is
more precise than the upper bounds used in the prior work (which
contained an error which we identify and correct). The result is a
significant improvement in the power of the test over the the prior
work.
In parallel with the previous two scenarios, we then compare our
private nonparametric test with a private version of the analogous
parametric test, the paired t-test. A direct private implementation
of this test does not exist in the literature, so we propose one
here.1 In alignment with the previous results, we show experimental
evidence that the rank-based test has superior power.
For all our tests we give not just private test statistics but also precise
methods of computing a reference distribution and a p-value, the
final output practitioners actually need. We also experimentally
verify that the probability of Type 1 errors (incorrectly rejecting the
null hypothesis) is acceptably low. We give careful power analyses
and use these to compare tests to each other. All our tests and
experiments are implemented with publicly available code.2
We find that rank-based statistics are very amenable to the pri-
vate setting. We also repeatedly find that what is optimal in the
public setting is no longer optimal in the private setting. We hope
that this work contributes to the development of a standard set of
powerful hypothesis tests that can be used by scientists to enable
inferential analysis while protecting privacy.
2 BACKGROUND
In this section, we begin by discussing hypothesis testing in general
and outlining the formalities of differential privacy. We then discuss
the difficulties of hypothesis testing within the privacy framework
and the previous work done in this area. Each of our main results
requires a more detailed discussion of prior work on that particular
test or use case; we leave those discussions for Sections 3-5.
2.1 Hypothesis Testing
The key inferential leap that is made in hypothesis testing is the
claim that not only is the sample of data incompatible with a particu-
lar scientific theory, but that the incompatiblility holds in a broader
population. In the study on psychotic disease, the researchers used
this technique to generalize from their 165 subjects to the pop-
ulation of causasian-descended Swiss. The scientific theory that
they refuted, that there is no link between methylation levels and
psychosis, is called the null hypothesis (H0).
To test whether or not the data is consistent with H0, a researcher
computes a test statistic. The choice of a function f to compute the
test statistic largely determines the hypothesis test being used. For
a random database X drawn according to H0, the distribution of the
statistic T = f (X) can be determined either analytically or through
simulation. The researcher then computes a p-value, the probability
1In simultaneous work Gaboardi et al. [13] propose such a test, but our test is still
higher power. See Section 5.5 for more details.
2Our source code is available at: github.com/simonpcouch/non-pm-dpht
that the observed test statistic or more extreme would occur under
H0.
Definition 2.1. For a given test statistic t = f (x) and null hypoth-
esis H0, the p-value is defined as
Pr[T ≥ t | T = f (X) and X ← H0] = p.
If the function f is well-chosen, the underlying distribution of X
will differ more from the distribution under H0 and a low p-value
becomes more likely. Typically a threshold value α is chosen, such
that we reject H0 as a plausible explanation of the data when p < α.
The choice of α determines the type I error rate, the probability of
incorrectly rejecting a true null hypothesis.
We define the critical value t∗ to be the value of the test statistic
t where p = α. We use this to define the statistical power, a measure
of how likely a hypothesis test is to pick up on a given effect (i.e. the
chance of rejecting when the null hypothesis is false). The power
is a function of how much the underlying distribution of X differs
from the distribution under H0 as well as the size of the database.
Definition 2.2. For a given alternate data distribution HA, the
statistical power of a hypothesis test is
Pr[T ≥ t
∗ | T = f (X) and X ← HA].
Statistical power is the accepted metric by which the statistics
community judges the usefulness of a hypothesis test. It provides a
common scale upon which to evaluate different tests for the same
use case.
2.2 Differential Privacy
To persuade people to allow their personal data to be collected,
data owners must protect information about specific individuals.
Historically, ad-hoc database anonymization techniques have been
used (i.e. changing names to numeric IDs, rounding geospatial
coordinates to the nearest block, etc.), but these methods have
repeatedly been shown to be ineffective [14, 19, 29].
Differential privacy, proposed by Dwork et al. in 2006 [9], is a
mathematically robust definition of privacy preservation, which
guarantees that a query does not reveal anything about an indi-
vidual as a consequence of their presence in the database. When
the condition of differential privacy is satisfied, there is not much
difference between the output obtained from the original database,
and that obtained from a database that differs by only one individ-
ual’s data. Here we present (ϵ, δ)-differential privacy [8], which
allows the closeness of output distributions to be measured with
both a multiplicative and an additive factor. However, for most of
our hypothesis tests δ = 0.
Definition 2.3 (Differential Privacy). A randomized algorithm ˜f
on databases is (ϵ, δ)-differentially private if for all S ⊆ Range( ˜f )
and for databases x, x′ that only differ in one row:
Pr[ ˜f (x) ∈ S] ≤ eϵ Pr[ ˜f (x′) ∈ S] + δ .
We call databases x and x′ neighboring if they differ only in that
a single row is altered (but not added or deleted), and we will use
this notation in the following sections.3
3This is one of two roughly equivalent variants of differential privacy. The key differ-
ence is that under this definition the size of the database is public knowledge.
Differential privacy, like any acceptable privacy definition, is
resistant to post processing. That is, if an algorithm is differentially
private, an adversary with no access to the database will be unable
to violate such privacy through further analysis (e.g., attempted
deanonymization) of the query output [9].
Theorem 2.4 (Post Processing). Let ˜f be an (ϵ, δ)-differentially
private randomized algorithm. Let д be an arbitrary randomized
algorithm. Then д ◦ ˜f is (ϵ, δ)- differentially private.
Theorem 2.4 has another useful consequence. It allows us to
develop private algorithms by first computing some private output,
and then carrying out further computation on that output without
accessing the database. The additional computation need not be
analyzed carefully—the final output of the additional analysis is
automatically known to retain privacy.
Differential privacy requires the introduction of some random-
ness to any query output. A frequently used method is the Laplace
mechanism, introduced by Dwork et al. [9]. When given an arbi-
trary algorithm f with real-valued output, this mechanism will add
some noise drawn from the Laplace distribution to the output of
the algorithm and release a noisy output.
Definition 2.5 (Laplace Distribution). The Laplace Distribution
centered at 0 with scale b is the distribution with probability density
function:
exp(cid:16) − |x|
(cid:17)
.
b