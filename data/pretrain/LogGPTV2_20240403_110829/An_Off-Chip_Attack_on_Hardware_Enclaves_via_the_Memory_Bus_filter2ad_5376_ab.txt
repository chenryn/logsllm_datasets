the attacker can alleviate the noise by identifying cache sets
that are critical to the attack. This technique can be applied to
applications that have data-dependent accesses in a small num-
ber of cache sets. CacheZoom [22] also uses PRIME+PROBE
but minimizes the noise by inducing Asynchronous Exits
(AEXs) every few memory accesses in the victim. This incurs
a signiﬁcant overhead on enclaves, and also makes the attack
easily detectable [32].
Flush-based Side Channels. Other techniques such as
FLUSH+RELOAD [45] and FLUSH+FLUSH [46] use a shared
cache block between the attacker and the victim to create
a noiseless and lossless side channel. However, these tech-
niques cannot be directly applied to enclave memory, be-
cause an enclave does not share the memory with other pro-
cesses. However, these techniques can still be used to observe
the page table walk for enclave addresses [23]. Speciﬁcally,
the attacker can monitor the target page tables with a tight
FLUSH+RELOAD loop. As soon as the loop detects page
table activities, the attacker interrupts the victim and infers
page-granularity addresses. Similar to CacheZoom, this attack
incurs a signiﬁcant AEX overhead and thus can be detected
by the victim.
Controlled Channels. Controlled-channel attacks [24] take
advantage of the adversarial memory management of the un-
trusted OS, to capture the access patterns of an SGX-protected
execution. Even though Intel SGX masks the lower 12 bits
of the page fault addresses to the untrusted OS, controlled-
channel attacks use sequences of virtual page numbers to
differentiate memory accesses within the same page. The con-
trolled channel is noiseless and lossless but can be detected
and mitigated as it incurs a page fault for each sequence of
accesses on the same page [28, 31].
2.2.2 Advantages of MEMBUSTER
As shown in Table 1, MEMBUSTER creates a noiseless side
channel by ﬁltering out all of the non-victim memory accesses,
leaving only addresses that are useful for the attack. It can
observe memory accesses with cache line granularity. Also,
MEMBUSTER does not incur interference such as AEX or
page fault to the victim and needs not to incur an order-of-
magnitude overhead.
Several recent mechanisms, such as Varys [28], Hyper-
race [29], Cloak [30], T-SGX [31], or Déjà Vu [32], have
been proposed to prevent the attacker from observing mem-
ory access patterns in the victim. In general, PRIME+PROBE
can be mitigated by partitioning the cache to shield the vic-
tim from on-chip attackers. This does not defeat an off-chip
attacker who directly observes DRAM requests. T-SGX [31]
and Déjà Vu [32] have proposed to use the Intel Transactional
Synchronization Extensions (TSX) to prevent AEX or page
faults from an enclave. These techniques are based on thwart-
ing the interference (e.g., AEX, page faults) that causes the
side channels [22–24]. However, MEMBUSTER does not incur
such interference on enclaves, and thus cannot be thwarted
through similar approaches. To our best knowledge, there
is no reliable way to detect or mitigate MEMBUSTER using
existing on-chip measures.
2.2.3 Related Work
Other On-Chip Attacks. Other on-chip attacks worth men-
tioning are speculative-based execution side channels like
Foreshadow [18] or ZombieLoad [47], branch shadowing
side channels [48], denial-of-service attacks (e.g., Rowham-
mer [49, 50]), or rollback attacks [51, 52].
Other Off-Chip Side-Channel Attack. DRAM row
buffers can be exploited as side-channels between cores or
CPUs, as demonstrated in DRAMA [53]. DRAMA shows that
by observing the latency of reading or writing to DRAM, the
attacker can infer whether the victim has recently accessed the
data stored in the same row. DRAMA shows how a software-
only attacker can use DRAM row buffers as covert channels or
side channels. MEMBUSTER further explores how the attacker
can directly use the address bus as a side channel.
3 MEMBUSTER
In this section, we describe the basic attack model of MEM-
BUSTER. In further sections, we will reﬁne and improve the
attack. At a high level, the attacker ﬁrst sets up an environment
to collect the DRAM signals and waits until the victim exe-
cutes some code containing data-dependent memory accesses.
The attacker translates the collected signals into cache-line
granularity virtual addresses.
3.1 Threat Model
We assume the standard Intel SGX threat model in which noth-
ing but the CPU package and the victim program is trusted.
Everything else, including the OS or other applications, is
untrusted and can be controlled by the attacker. External hard-
ware devices are also untrusted, so the attacker can tap the
address bus to the external DRAM. For the advanced tech-
niques discussed in §5, the attacker may also use the root
privilege to install the modiﬁed SGX driver.
To tap the memory bus, the attacker needs to have physical
access to the machine where the victim is running. Such an as-
sumption eliminates the possibility of remote attacks through
Figure 2: Hardware setup for a memory bus side-channel
attack. DIMM interposer collects the bus signals and sends
them to the signal analyzer. The attacker can use the analyzed
signals to learn the memory access pattern of the victim.
either cloud environments or network connections. The candi-
dates who may perform MEMBUSTER could be two types. On
the server-side, these may include the employees of a cloud
provider, or IT administrators of an institution, who act as
insiders to leak sensitive information. On the client-side, end
users may want to attack the local hardware enclaves, which
protect proprietary data (e.g., licenses, digital properties, etc).
We assume that the attacker has enough budget and knowl-
edge to acquire and install the DIMM interposer for the attack
described in §3.2. This might be an obstacle for the general
public, but we claim that the cost is manageable if the attacker
has a strong motivation for obtaining the data.
Like in the controlled channel and cache side channels,
MEMBUSTER assumes that the adversary has knowledge
of the victim application, by either consulting the source
code or reverse-engineering the application. The adversary is
also aware of the runtime used by the victim application for
platform support, such as the SDK libraries, library OSes,
or shield systems. In our experiments, we use Graphene-
SGX [54] for platform support of the victim applications.
Address Space Layout Randomization (ASLR) in the library
OSes or the runtimes may complicate the extraction of secret
information but generally is insufﬁcient to conceal the access
patterns completely [24]. ASLR offered by the host kernel is
irrelevant because a hostile host kernel can either control or
monitor the addresses where the victim enclaves are loaded.
3.2 Hardware Setup for the Attack
Figure 2 shows a detailed hardware setup for the MEM-
BUSTER attack. The hardware setup may vary on different
CPU models and vendors. The attacker installs an interposer
on the DIMM socket prior to system boot. The interposer
is a custom printed circuit board (PCB) that can be placed
between the DRAM and the socket. The interposer contains
a signal repeater chip which duplicates the command bus
signals and sends them to a signal analyzer. The analyzer
ampliﬁes the signals and then outputs the signals to a storage
server through a PCIe interface.
In the rest of the section, we will highlight the key require-
ments in successfully performing the attack.
Sampling Rate. The sampling rate of the interposer needs to
Signal AnalyzerDDR4DIMMStorageAMPSignal RepeaterPCIe ControllerPCB BoardDATAADDR/CMDInterposerDIMM Socketbe equal or higher than the clock rate of the DIMM in order
to capture all the memory requests. A standard DDR4 clock
rate ranges from 800 to 1600 MHz, while a DIMM typically
supports between 1066 (DDR4-2133) and 1333 (DDR4-2666)
MHz. To match with the sampling rate, the attacker can lower
the DIMM clock rate if it is conﬁgurable in the BIOS.
Recording Bandwidth. The sampling rate also determines
the recording bandwidth. For example, DDR4-2400 (1200
MHz) has a 32-bit address and a 64-bit data bus, thus the
recording bandwidth for the address bus is 1200 Mbps×32
bits = 4.47 GiB/s. For reference, the data bus of a DDR has
a 2× transfer rate, as well as a 2× transfer size. Hence, the
bandwidth for logging all the data on DDR4-2400 will be
17.88 GiB/s.
Acquisition Time Window. The acquisition time window
(i.e., the maximum duration for collecting the memory com-
mands) determines the maximum length of execution that the
attacker can observe. The acquisition time window equals
the acquisition depth (i.e., the analyzer’s maximum capacity
of processing a series of contiguous sample) divided by the
recording bandwidth of the interposer. For example, with 64
GiB acquisition depth, the analyzer can process and log the
commands from DDR4-2400 up to ∼ 14 seconds.
We surveyed several vendors which offer DIMM analyz-
ers [55–57] for purchase or rental. Among them, the maxi-
mum sampling rate can reach 1200-1600 MHz, and the ac-
quisition depth typically ranges between 4-60 GiB. One of
the devices [55] can extend the acquisition time window to
> 1 hour by attaching 16 TB SSD and streaming the com-
pressed log via PCIe at 4.8 GiB/s. Another device [57] does
not disclose the memory depth but speciﬁes that it can cap-
ture up to 1G (109) samples. The cost of the analyzer varies
depending on the sampling rate and the acquisition depth. At
the time of writing, Kibra 480 [56] (1200 MHz, 4 GiB) costs
$6,500 per month, MA4100 [57] (1600 MHz, 1G-samples)
costs $8,000 per month, and JLA320A [55] (1600 MHz, 64
GiB) costs $170,000 for purchase.
3.3
Once the attacker has ﬁnished setting up the environment, she
can collect the DRAM signals at any point in time, and ana-
lyze the trace off-line. As the ﬁrst step, the attacker interprets
the DRAM commands collected from the interposer.
Interpreting DRAM Commands
A modern DRAM contains multiple banks that are sepa-
rated into bank groups. Within each bank, data (often of the
same size as the cache lines) are located by rows and columns.
Each bank has a row buffer (i.e., a sense ampliﬁer) for tem-
porarily holding the data of a speciﬁc row when the CPU
needs to read or write in the row. Because only one row can
be accessed in a bank at a time, the CPU needs to reload the
row buffer when accessing a data block in another row.
consists of the following commands:
The log collected from the DRAM interposer typically
• ACTIVATE(Rank,Bank,BankGroup,Row): Activating a
speciﬁc row in the row buffer for a certain rank, bank,
and bank group.
• PRECHARGE(Rank,Bank,BackGroup): Precharging and
deactivating the row buffer for a certain rank, bank, and
bank group.
• READ(Rank,Bank,BankGroup,Col): Reading a data
• WRITE(Rank,Bank,BankGroup,Col): Writing a data
block at a speciﬁc column in the row buffer.
block at a speciﬁc column in the row buffer.
Other commands such as PDX (Power Down Start), PDE
(Power Down End), and AUTO (Auto-recharge) are irrelevant
to the attack and thus omitted from the logs.
Based on the DRAM commands, we can construct the rank,
bank, row, and column of each trace, by simply tracing the
activated row within each bank. Note that the ﬁnal traces are
also time-stamped by the clock counter of the analyzer. The
result of the translation is a sequence of logs containing the
timestamp, access type (read or write), rank, bank, row, and
column in the DRAM.
3.4 Reverse-engineering DRAM Addressing
A physical address in the CPU does not linearly map to a
DRAM address consisting of rank, bank, row, and column.
Instead, the memory controller translates the address to maxi-
mize DRAM bank utilization and minimize the latency. The
translation logic heavily depends on the CPU and DRAM
models, and Intel does not disclose any information. Thus,
the attacker needs to reverse-engineer the internal translation
rule for the speciﬁc set of hardware. This has been also done
by a previous study [53].
We use the traces collected from the DRAM interposer to
reverse-engineer the addressing algorithm of an Intel CPU.
For attacking the enclaves, we only need a part of the ad-
dressing algorithm that affects the range of the enclave page
cache (EPC). We write a program running inside an enclave,
which probes the DRAM addresses translated from the EPC
addresses. The probing program allocates a heap space larger
than the EPC size (93.5MB). For every cache line in the range,
the program generates cache misses by repeatedly ﬂushing
the cache line and fetching it into the cache. By accessing
each cache line multiple times, we can differentiate the traces
caused by probing from other memory accesses in the back-
ground and minimize the effect of re-ordering by the CPU’s
memory controller. The techniques in §3.5 are also needed for
translating the probed virtual addresses to physical addresses.
Using the DRAM traces generated by probing cache lines
inside the EPC, we can create a direct mapping between the
physical addresses and DRAM addresses (ranks, banks, bank
groups, rows, and columns). We further deduce the addressing
function of the target CPU (i5-8400), by observing the chang-
ing bits in the physical addresses when DRAM addresses
change. We conclude that the addressing function on i5-8400
is as shown in Figure 3. Other CPU models may implement a
different addressing function, and reverse-engineering should
Figure 3: The reverse engineered addressing function of the
i5-8400 CPU. The function translate a physical address (PA)
to the Bank Group (BG), Bank Address (BA), Row (ROW) and
Column (COL) within the DRAM.
be done for each CPU model beforehand.
3.5 Translating PA to VA
In order to extract the actual memory access pattern of
the victim, we need to further translate the physical ad-
dresses into more meaningful virtual addresses. In general, a
root-privileged attacker has multiple ways of obtaining the
physical-to-virtual mappings: either by parsing the proc ﬁle
/proc/[PID]/pagemap (assuming Linux as the OS), or using
a modiﬁed driver. However, paging in an enclave is controlled
by the SGX driver, and the vanilla driver forbids poking the
physical-to-virtual mappings through the proc ﬁle system.
Nevertheless, the attack can still modify the SGX driver to
retrieve the mappings, and this is what we do.
Hence, we print the virtual-to-physical mappings in the
dmesg log and ship the log together with the memory traces.
During our ofﬂine analysis, we use the dmesg log as an input
to the attack script. The dmesg log also contains system tim-
ings of paging, and can be further calibrated to the timestamps
of the collected traces. Because paging in an enclave needs
to copy the whole pages in and out of the EPC a sequential
access pattern of a whole or partial page will appear in the
memory traces. After calibration, we successfully translate
all the physical addresses to virtual addresses.
4 Attack Examples
We show how MEMBUSTER exploits two example applica-
tions: (1) spell checking of a conﬁdential document using
Hunspell, and (2) email indexing cache using Memcached.
4.1 Hunspell
Hunspell is an open-source spell checker library widely
used by LibreOfﬁce, Chrome, Firefox and so on [58]. The
controlled-channel attack [24] has shown that Hunspell is
exploitable by page-granularity access patterns, which moti-
vated us to use it as the ﬁrst target of MEMBUSTER. We make
the same assumptions as described in [24]; the attacker tries
to infer the contents of a conﬁdential document owned by a
victim while Hunspell is spell-checking. The attacker knows
the language of the document, and therefore can also obtain
the same dictionary, which is publicly available.
The side-channel attacks on Hunspell are based on observ-
ing the access patterns for searching words in a hash table
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23