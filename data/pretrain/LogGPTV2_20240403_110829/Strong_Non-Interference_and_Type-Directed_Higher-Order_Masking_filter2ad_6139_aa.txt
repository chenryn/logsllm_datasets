title:Strong Non-Interference and Type-Directed Higher-Order Masking
author:Gilles Barthe and
Sonia Bela&quot;ıd and
François Dupressoir and
Pierre-Alain Fouque and
Benjamin Gr&apos;egoire and
Pierre-Yves Strub and
R&apos;ebecca Zucchini
Strong Non-Interference and Type-Directed
Higher-Order Masking∗
Gilles Barthe1, Sonia Bela¨ıd2, Franc¸ois Dupressoir3†, Pierre-Alain Fouque4, Benjamin
Gr´egoire5, Pierre-Yves Strub6†, and R´ebecca Zucchini5,7
(PI:EMAIL)
1 IMDEA Software Institute
2 Thales Communications & Security
3 University of Surrey
4 Universit´e de Rennes 1
5 Inria Sophia Antipolis – M´editerran´ee
6 ´Ecole Polytechnique
7 ´Ecole Normale Sup´erieure de Cachan
Abstract. Differential power analysis (DPA) is a side-channel attack in which
an adversary retrieves cryptographic material by measuring and analyzing the
power consumption of the device on which the cryptographic algorithm under
attack executes. An effective countermeasure against DPA is to mask secrets by
probabilistically encoding them over a set of shares, and to run masked algorithms
that compute on these encodings. Masked algorithms are often expected to provide,
at least, a certain level of probing security.
Leveraging the deep connections between probabilistic information ﬂow and
probing security, we develop a precise, scalable, and fully automated methodology
to verify the probing security of masked algorithms, and generate them from
unprotected descriptions of the algorithm. Our methodology relies on several
contributions of independent interest, including a stronger notion of probing
security that supports compositional reasoning, and a type system for enforcing
an expressive class of probing policies. Finally, we validate our methodology on
examples that go signiﬁcantly beyond the state-of-the-art.
1
Introduction
Differential power analysis, or DPA [25], is a class of side-channel attacks in which an
adversary extracts secret data from the power consumption of the device on which a pro-
gram manipulating the data executes. One practical countermeasure against DPA, called
masking [11,22], transforms an algorithm that performs computations over a ﬁnite ring
∗ This work appears in the Proceedings of CCS 2016. This is the long version. A preliminary ver-
sion, made public in 2015 under the title “Compositional Veriﬁcation of Higher-Order Masking:
Application to a Verifying Masking Compiler”, can be found as revision 20150527:192221 of
this report.
† The majority of the work presented here was performed while the author was working for the
IMDEA Software Institute.
K into a randomized algorithm that manipulates probabilistic encodings.8At an abstract
level, any masking transformation performs two tasks. First, it replaces every algebraic
operation performed by the original algorithm by a call to a gadget, i.e. a probabilistic
algorithm that simulates the behavior of algebraic operations on probabilistic encodings.
Second, it inserts refreshing gadgets, i.e. gadgets that take a probabilistic encoding of
v and rerandomizes its shares in order to produce another probabilistic encoding w of
v. Inserting refreshing gadgets does not change the functional behavior of the masked
algorithm, and increases the randomness complexity and execution time of the masked
program. However, it is also compulsory for achieving security. Therefore, an important
line of research is to ﬁnd suitable trade-offs that ensure security while minimizing the
performance overhead of masking; see [8] for recent developments in this direction.
The baseline notion of security for masked algorithms is t-probing security. Infor-
mally, an algorithm P is t-probing secure if the values taken by at most t intermediate
variables of P during execution do not leak any information about secrets (held by
its inputs). More formally, an algorithm P achieves t-probing security iff for every
set of at most t intermediate variables, the joint distributions of the values taken by
these intermediate variables coincide for any two executions initiated from initial inputs
that agree on t shares of each input encoding. Stated in this form, probing security is
an instance of probabilistic information ﬂow, universally quantiﬁed over all position
sets that meet a cardinality constraint, and is therefore potentially amenable to formal
analysis using a well-developed body of work on language-based security and program
veriﬁcation. Indeed, the connection between probing security and information ﬂow has
been instrumental in a promising line of research, initiated in [27] and further developed
in [7,20,19,4], which uses type systems, program logics, SMT solvers and other methods
for verifying or synthesizing masked algorithms at small (≤ 5) orders. However, none of
these works addresses the problem of composition, and all fail to scale either to higher
orders or to larger algorithms.
Contributions We develop precise and scalable techniques for synthesizing masked
algorithms that achieve probing security. Our techniques apply to a wide range of
probing policies, including existing policies and new policies deﬁned in this paper, and
deliver masked algorithms that outperform (in terms of randomness complexity and
computational efﬁciency) prior approaches. In more detail, we make the following broad
contributions:
1. Strong non-interference. We introduce a stronger notion of probing security,
which we call strong non-interference, and prove that it is in fact satisﬁed by many (but
not all) gadgets from the literature. Furthermore, we justify that strong non-interference
is the desired property for refreshing gadgets, by reconsidering known negative and
positive results [15] for a simpliﬁed example extracted from Rivain and Prouff’s inversion
algorithm [31]. We ﬁrst observe that the refreshing gadget used in the original, ﬂawed,
algorithm does not enjoy strong non-interference. Second, we note that the refreshing
gadget used in the ﬁxed, secure, algorithm is indeed strongly non-interfering, and we
8 A t-encoding of an element v ∈ K is a (t + 1)-tuple v = (cid:104)v0, . . . , vt(cid:105) such that(cid:74)v(cid:75) (cid:52)
=
v0 ⊕ . . . ⊕ vt = v. Each of the vı ∈ K in an encoding v of v is called a share. Moreover, t is
called the masking order. A probabilistic encoding of v is a distribution over encodings of v.
show that one can prove the probing security of the ﬁxed algorithm, based simply on
the assumption that the refreshing gadget is strongly non-interfering. Generalizing these
observations, we prove that every non-interfering algorithm can be turned into a strongly
non-interfering algorithm, by processing its inputs or its output with a strongly non-
interfering refreshing gadget. We also provide more general results about the composition
of strongly non-interfering gadgets.
2. Formal proofs. We develop and implement an automated method, inspired from [4],
for checking strong non-interference. We apply our automated veriﬁer for strong non-
interference to several gadgets from the literature and some other interesting com-
positions, for orders t ≤ 6. For several more widely-used gadgets, we further use
EasyCrypt [5] to provide machine-checked proofs of t-probing security for all t.
3. Type-based enforcement of probing security. We deﬁne an expressive language for
specifying a large class of non-interference properties with cardinality constraints. Our
language can be seen as a variant of the ﬁrst-order theory of ﬁnite sets with cardinality
constraints [32,3], and can be used to specify baseline probing security and strong non-
interference, among others. Then, we deﬁne a type system that enforces probing policies
and prove its soundness. Furthermore, we show how to model in our language of probing
policies the notion of afﬁne gadget, and we show how it helps improve the precision of
type-checking.
4. Certifying Masking Transformation. As a proof of concept, we implement a
type inference algorithm and a certifying masking transformation that takes as input an
arithmetic expression and returns a masked algorithm typable by our type system.9 Our
transformation improves over prior works by selectively inserting refreshing gadgets
only at points where type-checking would otherwise fail. This strategy leads to improved
efﬁciency while retaining provable soundness.
5. Practical evaluation. We evaluate our type system and masking transformation on
complete algorithms at various orders, often achieving provable t-probing security levels
far beyond the state-of-the-art for algorithms of those sizes, and with better performance
than most known (provably secure) algorithms in terms of time, memory and randomness
complexity.
Related work Section 9 discusses related work in more detail. Here we focus on recent
work on automated tools for the veriﬁcation of synthesis of masked algorithms, starting
with Moss et al. [27], who point out and leverage connections between probing security
and probabilistic information-ﬂow for ﬁrst-order boolean masking schemes. Subsequent
works in this direction accommodate higher-order and arithmetic masking, using type
systems and SMT solvers [7], or model counting and SMT solvers [20,19]. Although
approaches based on model counting are more precise than early approaches based on
type systems and can be extended to higher-order masking schemes, their algorithmic
complexity constrains their applicability. In particular, existing tools based on model
counting can only analyze ﬁrst or second order masked implementations, and can only
deal with round-reduced versions of the algorithms they consider (for instance, only
9 The cryptography literature often refers to such transformations as masking compilers. We
purposely avoid this terminology, since the terms is used in programming languages for
transformations that output executable code
analyzing a single round of Keccak at order 1, and algorithms for ﬁeld operations at
orders 2 and higher). Breaking away from model counting, Barthe et al. [4] develop
efﬁcient algorithms for analyzing the security of masked algorithms in the probing
model. Their approach outperforms previous work and can analyze a full block of AES
at ﬁrst-order, reduced-round (4 rounds) AES at the second-order, and several S-box
computation algorithms masked at the third and fourth orders. However, their work does
not readily scale either to higher orders or to larger algorithms, mainly due to the lack of
composition results.
Our work also bears some connections with language-based security, and in particular
with work on the speciﬁcation and the enforcement of conﬁdentiality policies using
techniques from programming languages. For instance, our work has similarities with the
work of Pettai and Laud [29], who develop techniques for proving security of multi-party
computations in the presence of strong adversaries, and work by Zdancewic et al. [33],
who propose a compiler that partitions programs for secure distributed execution.
Mathematical preliminaries A function µ : B → R≥0 is a (discrete) distribution over
(cid:80)
B if the subset supp(µ) of B with non-zero weight under µ is discrete and moreover
b∈supp(µ) µ(b) = 1. We let D(B) denote the set of discrete distributions over B.
Equality of distributions is deﬁned as pointwise equality of functions. Distributions
can be given a monadic structure with the two operators munit(·) and mlet · = ·. For
every b ∈ B, munit(b) is the unique distribution µ such that µ(b) = 1. Moreover, given
µ : D(B) and M : B → D(C), mlet x = µ inM x is the unique distribution µ(cid:48) over C
such that µ(cid:48)(c) =(cid:80)
We often use the notion of marginals. The ﬁrst and second marginals of a distribution
µ ∈ D(B1 × B2) are the distributions π1(µ) ∈ D(B1) and π2(µ) ∈ D(B2) given by
π1(µ)(b1) =
µ(b1, b2)
π2(µ)(b2) =
µ(b1, b2).
b µ(b) M (b)(c).
(cid:88)
b2∈B2
(cid:88)
b1∈B1
The notion of marginal readily extends to distributions over ﬁnite maps (rather than
pairs).
2 A bird’s eye view of strong non-interference
Before formalizing our deﬁnitions, we give an intuitive description of our language for
gadgets and of our security notions, based on simple examples.
such that(cid:74)a(cid:75) =(cid:74)c(cid:75). The gadget ﬁrst makes local copies of individual input shares aı
Gadgets and Positions Gadget RefreshM2 (Gadget 1) shows the description in our
language of a mask refreshing gadget for t = 2. The gadget takes as input an encoding
variable a ∈ K3, where K is some ﬁnite ring and returns a new encoding c ∈ K3
(for 0 ≤ ı ≤ 2) of a into local variables cı (for 0 ≤ ı ≤ 2). After this ﬁrst step, we
sample uniform random elements from K into a local variable r and perform some ring
operations. Finally, the algorithm returns a vector in K3, constructed from the ﬁnal value
of local variables c0, c1 and c2.
Gadget 1 SNI Mask Refreshing with t = 2
function RefreshM2(a)
c0,0 ← a0; c1,0 ← a1; c2,0 ← a2;
r0
r1
r2
return (cid:104)c0,2, c1,2, c2,2(cid:105)
$← K; c0,1 ← c0,0 ⊕ r0; c1,1 ← c1,0 (cid:9) r0;
$← K; c0,2 ← c0,1 ⊕ r1; c2,1 ← c2,0 (cid:9) r1;
$← K; c1,2 ← c1,1 ⊕ r2; c2,2 ← c2,1 (cid:9) r2;
RefreshM2
Note that the gadget is written in single static assignment (SSA) form, an intermediate
representation in which each variable is deﬁned exactly once. Having gadgets written in
SSA form allows us to easily refer to the value of a particular variable at a particular point
in the program–simply by referring to its name, which corresponds to a unique deﬁnition.
In this paper, we refer to positions in gadgets and algorithms, which correspond exactly
to intermediate variables. We distinguish between three different kinds of positions:
input positions, which correspond to shares of the gadget’s input (here, IRefreshM2 =
{a0, a1, a2}), output positions, which correspond to the variables that appear in the gad-
= {c0,2, c1,2, c2,2}), and internal positions, which
get’s return vector (here, Oint
= {c0,0, c1,0, c2,0, c0,1, c1,1, c2,1, r0, r1, r2}).
refer to all other positions (here, Oext
Intuitively, this separation allows us to distinguish between direct observations made
by the adversary into a gadget (as internal positions), output shares about which the
adversary may have learned some information by probing gadgets that use them as input
(as output positions), and shares of the gadget’s inputs (as input positions) about which
the adversary is now learning information. In the following, we often write “the joint
distribution of a set of positions” to discuss the joint distribution of the variables deﬁned
at these positions in the gadget (in order). For example, referring to RefreshM2, the
joint distribution of the ordered set O = (cid:104)c0,1, c2,2(cid:105) of positions can be described as the
following function of a, where we use $ to denote a fresh uniform random sample in K
(cid:52)
= (cid:104)a0⊕$0, (a2(cid:9)$1)(cid:9)$2(cid:105).
(using indices to denote distinct samples):(cid:74)RefreshM2(cid:75)O(a)
RefreshM2
Probing Security and Non-Interference The RefreshM2 gadget is known to be 2-probing
secure, or 2-non-interfering (2-NI) in our terminology, in the sense that the joint distribu-
tion of any set of at most 2 of its positions, corresponding to adversary probes, depends
on at most 2 shares of the gadget’s inputs. This guarantees, if the input encoding is
uniform, that no information about it leaks through any 2 probes in the circuit.
Considering again the set O = (cid:104)c0,1, c2,2(cid:105) of positions in RefreshM2 and its distri-
bution(cid:74)RefreshM2(cid:75)O, it is easy to see–purely syntactically–that it depends at most on
shares a0 and a2 of the gadget’s input encoding. Similarly considering all possible pairs
of positions, we can prove that each of them has a joint distribution that depends on at
most two shares of a.
Strong Non-Interference Probing security is generally not composable: combining t-
probing secure gadgets does not necessarily yield a t-probing secure algorithm [15].
Our main contribution is a new and stronger notion of security for gadgets, which we
dub strong non-interference (or SNI), which does support some compositional reason-