### Evaluation and Feedback on Control-Alt-Hack

#### 3. Distribution and Presentation
We distributed 300 copies of the game at various NSF-sponsored events, including job fairs and competitions. Additionally, we were invited to present a talk on the game at a large web company’s internal security training conference, where an optional play session was held following the hands-on training.

#### 4. Evaluation Methods
In this paper, we evaluate Control-Alt-Hack using two primary methods:
1. **Educator Feedback Surveys**: Feedback from educators who requested copies of the game.
2. **User Studies**: User studies conducted with participants playing the game.

Both methods were approved by the University of Washington’s Human Subjects Institutional Review Board.

#### 5. Educator Feedback Surveys
We distributed online feedback surveys via email to 150 instructors who received educator copies before May 2013. The survey questions are detailed in Section A.2 of the Appendix. We received 22 responses.

**Coding Process:**
- Two researchers independently analyzed the survey responses to form preliminary categories.
- They then compared their categories and developed a cohesive coding scheme through consensus.
- The primary coder recoded the surveys based on this scheme. (One researcher had no financial interest in RGB Hats, LLC, as per our institution’s conflict management plan.)
- The unit of analysis was the entire survey rather than individual responses. If a response was coded as "Awareness," it did not matter which question elicited the response or how many times it appeared.
- The primary and secondary coders achieved 93% agreement across all surveys and codes. There were 11 cases of disagreement, which are detailed in the Appendix (Section A.3) along with contextual quotes. The primary coder's results, which are reported in the paper, represent the stricter interpretation of the data.

**Classroom vs. Non-Classroom Activities:**
- The primary and secondary coders also classified activities as either classroom-based or non-classroom-based, with 100% agreement.
- Tables 1 and 2 provide details on classroom and non-classroom activities, respectively.

#### 6. User Studies
We recruited participants for the user studies through institutional bulletin boards and local Craigslist listings. We held two sessions:
- Session 1: 7 participants (3 male, 4 female) divided into two groups.
- Session 2: 4 participants (1 male, 3 female) in one group.

Participants ranged in age (mean=31, min=18, max=50, median=29). Five were hobbyist gamers, and six had casual or little gaming experience. Each session lasted approximately 2 hours, and participants were compensated $20. After consent paperwork, they filled out a pre-gameplay survey, watched a 15-minute introductory video, played for 40-60 minutes, and then completed a post-gameplay questionnaire.

**Coding Process:**
- Two researchers independently analyzed the survey responses for themes and categories.
- They discussed and reached a consensus on the data of interest, which is presented as direct quotations.

#### 7. Educator Survey Results
The 22 educators who responded used the game with over 450 students at high school, undergraduate, and graduate levels in computer science, computer security, and game design courses, primarily in the United States. These survey results form the primary evaluation of Control-Alt-Hack in this study.

**Categories of Feedback:**
- **Classroom Activities (N=14)**: Feedback on activities that took place in a classroom.
- **Non-Classroom Activities (N=8)**: Feedback on activities outside the classroom, such as vetting, ACM gatherings, lunch activities, and offering the game for home use.

**Positive Functions:**
- **Social/Engagement (Classroom: 11/14; Non-Classroom: 2/8)**: The game was seen as fun, engaging, and serving a social function, such as an icebreaker or a breather before a test.
  - Example: E7-classroom (56 undergraduates, Cyber-Security and Information Awareness): "It worked as a way to break the ice and get students from diverse majors to know each other and get thinking about the topics of the course."
- **Awareness (Classroom: 11/14; Non-Classroom: 1/8)**: The game increased students' awareness of computer security issues, such as domain terminology, career opportunities, and critical thinking.
  - Example: E9-classroom (60 high school students, Computers and Information Technology): "The game did not necessarily teach security methods, but it did a great job of teaching vocabulary and literacy."

**Tables:**
- Table 3: Positive Functions results from classroom-based educator responses.
- Table 4: Positive Functions results from non-classroom-based educator responses.

**Discussion:**
- **Awareness**: Most educators indicated that the game raised students' awareness of computer security issues, aligning with our design goals.
- **Social/Engagement**: The game served a social and engagement role, which is promising for increasing engagement and encouraging people to play outside the classroom.

#### 8. Critiques
Some educators provided critiques, including:
- Takes a long time to learn and play.
- Not enough educational value.
- Not enough fun.
- Inappropriate content.

**Tables:**
- Table 3: Classroom-based educator survey analysis results.
- Table 4: Non-classroom-based educator survey analysis results.

Overall, the feedback from educators indicates that the game performs multiple positive functions, particularly in raising awareness and serving a social/engagement role in the classroom.