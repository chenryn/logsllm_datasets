vice mediates communication with the IMD, thereby provid-
ing both conﬁdentiality for transmitted data and protection
against unauthenticated communication. One concern with
the use of such devices is their acceptability to the patient,
however. Denning et al. [39] treat this issue in some detail
and study the usability of several possible authentication
methods, including external devices and password tattoos.
Denning et al. [69] propose an external device, called the
cloaker, that proxies authorized communication to the IMD.
If the cloaker is absent, the IMD communicates openly (e.g.,
in case of a medical emergency, the cloaker fails open). A
malicious programmer can exploit this fail-open behavior
by selectively jamming the cloaker or otherwise convincing
the IMD of the cloaker’s absence, so Denning et al. suggest
additional mitigation techniques to prevent such an attacker
from communicating with the IMD.
Gollakota et al. [59] and Xu et al. [62] use friendly
jamming to protect IMD communication, which uses jam-
ming constructively to prevent unauthorized communication.
IMDGuard [62] employs an external wearable device, called
the Guardian,
to enable access control and conﬁdential
data transmissions. The Guardian ﬁrst authenticates the
programmer and then uses an ECG-based key agreement
mechanism to authenticate itself to the IMD. Temporary keys
can then be issued to allow a secure channel between the
programmer and the IMD. In the event that an attacker jams
the messages from the Guardian device to the IMD, the
Guardian initiates an active defense by jamming all IMD
transmissions. However, IMDGuard has the disadvantage of
requiring modiﬁcations to the IMD itself (which is difﬁcult
in practice with respect to already-deployed devices) and the
suggested ECG-based key agreement scheme suffers from
security ﬂaws. Rostami et al. [19] show a simple man-in-
the-middle attack that reduces the effective key length from
129 bits to 86 bits. This attack takes advantage of a protocol
ﬂaw in the second round of reconciliation (in which the
two parties verify they know the same key), which can be
spoofed to reveal one bit per block.
The shield [59] works by listening for and jamming all
IMD transmissions and unauthorized commands. Given the
shield’s proximity and jamming power, the assumption is
that only the shield can cancel out its own jamming signal
and decode IMD transmissions. This design mitigates both
passive and active wireless attacks, but the security of the
system relies on the assumption that an attacker whose
distance from the IMD is greater than the distance between
the IMD and the shield will be unable to recover IMD
transmissions, even if the attacker is equipped with multiple
input and multiple output (MIMO)-systems and directional
antennas. Tippenhauer et al. [50] challenge this assumption,
however, and show that MIMO-based attacks are possible
in the presence of an adversary with two receiving antennas
from distances of up to 3 m.
5) Anomaly Detection: Anomaly detection attempts to
automatically identify resource depletion and malicious
communication, as well as distinguish between safety and
security events [46], [51], [63]. This is generally achieved by
observing patterns over time, such as physiological changes
or IMD access patterns (e.g., programmer commands, date,
or location).
Hei et al. [63] obtain and use normal IMD access patterns
as training data for their supervised learning-based scheme.
The resultant classiﬁcation is used to identify anomalous
IMD access in real time. That is, Hei et al.’s method tries
to detect abnormal access attempts and block such authenti-
cation from proceeding, before any expensive computations
take place. In this way, the IMD is protected against denial
of service attacks that deplete the system’s resources. This
scheme is designed for non-emergency settings, however,
and Hei et al. recommend that either the IMD automatically
detect emergency conditions and fail open, or that hospitals
have access to a master device key. The feasibility and
security provided by these two approaches is not considered.
Another anomaly detection approach makes use of audits;
Henry et al.’s scheme [46] observes correlated physiological
changes when an insulin bolus is administered by tracking
acoustic bowel sounds. These observations are recorded as
an audit log for retroactive veriﬁability of intended system
execution. While useful, a limitation of passive anomaly
detection is that such schemes do not provide medical device
integrity, and so need to be used in conjunction with another
mechanism that protects communications.
531
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:58:38 UTC from IEEE Xplore.  Restrictions apply. 
At
the physical
layer, wireless transmissions from an
attacker are likely to deviate in physical characteristics
from legitimate programmer transmissions. Zhang et al. [51]
propose a medical security monitor, MedMon, which is
an external device that detects anomalous transmissions by
examining physical characteristics of the transmitted signal;
such characteristics include received signal strength, time
of arrival, differential time of arrival, and angle of arrival.
When an anomalous transmission is detected, MedMon can
initiate either a passive defense (e.g., by alerting the patient)
or an active defense (e.g., by blocking the transmissions from
reaching the medical device).
The characteristics of the device used for anomaly de-
tection (and any associated audit logs) have important im-
plications for the overall security of the system. Suggested
anomaly detection implementations make use of dedicated
devices, such as analog sensor systems [46], or extend the
functionality of personal devices, such as smartphones [51],
[63]. Ofﬂoading heavy computation to another device like
a smartphone might improve the IMD’s battery life, but
signiﬁcantly increases the attack surface, as malware on
mobile devices is common [85]. Moreover, regulatory bar-
riers for medical devices may make this approach difﬁcult.
Additional challenges related to the use of mobile devices
and health-related BANs are surveyed by Avancha et al. [41].
B. Software Threats
Software running on medical devices spans a wide range
of complexity. An increasing number of medical devices
are reliant on digital circuits controlled by software, rather
than analog circuits. Faris [86] notes that in 2006, a major
milestone was crossed when over half of deployed medical
devices contained software. So far there has been a lack
of detailed analysis of IMD software. However, there have
been efforts to verify proper functionality by simulating an
artiﬁcial heart to interface with cardiac pacemakers [58],
[87]. Although these testing methods are not directly tailored
to security, the tests reduce software bugs and may therefore
reduce possible software vulnerabilities.
Devices communicating over a BAN, in addition to their
application code, have to include a telemetry interface that
increases both the amount of code and the number of
possible bugs. It is not surprising, then, that software is one
of the main reasons for FDA recalls of computer-related
issues [49]. Sandler et al. [88] report that in 2010, the FDA
issued 23 recalls of defective devices, six of which were
likely caused by software defects. Alemzadeh et al. [49]
report that the percentage of computer-related recalls be-
tween 2006 and 2011 was between 30 % to 40 %. In this
study, software defects are found to be the cause of 33 % of
computer-related class I recalls (reasonable chance of patient
harm), 66 % of class II recalls (temporary or reversible
adverse effects), and 75 % of class III recalls (non-compliant,
but unlikely to cause harm).
532
Bugs in medical devices have been a cause of over 500
recalls recorded between 2009 and 2011 by the FDA [53].
While there exists no method to extrapolate from the re-
ported bugs to those existing in deployed devices, the num-
ber reported is most likely only a lower bound. Fu reports
that failures in medical device software often result from a
failure to apply known system engineering techniques [89],
indicating that the problem is partially solvable today.
Moreover, the presence of a telemetry interface on the
device may expose software bugs to a remote attacker.
Evidence of the brittleness of software implementations is
apparent when investigating security vulnerabilities, includ-
ing those in proprietary ﬁrmware. Hanna et al. [77] perform
the ﬁrst public software security analysis of an automatic
external deﬁbrillator (AED). By reverse engineering the de-
vice, the authors successfully target three software packages
responsible for programming device parameters, collecting
post-cardiac device data, and updating the AED. The authors
locate four vulnerabilities, one of which enables arbitrary
code execution on the device.
The need for secure coding practices for safety-critical
devices is clear. However, closed source for medical de-
vices make it challenging to run a static analyzer on the
source code, let alone obtain the ﬁrmware. With proprietary
protocols and the special MICS band used on the wireless
telemetry interface, traditional fuzzing tools such as Peach
Fuzzer [90] have not developed modules appropriate for
testing medical devices.
A related security vulnerability is the existence of mal-
ware on medical devices. Regardless of whether the intent
of the attacker is to compromise a medical device, malware
can signiﬁcantly impact the performance and reliability of
safety-critical devices such as IMDs [13].
VI. RESEARCH CHALLENGES AND EMERGING THREATS
In this section, we identify and address challenges com-
puter science researchers face in examining the security and
privacy of medical devices and discuss promising areas for
future work. In particular, we discuss common problems,
identifying partial solutions and highlighting areas where
further work is needed. A particularly difﬁcult issue is the
lack of reproducibility of research results in this ﬁeld; given
the safety-critical nature of IMDs and some BANs, it is
critical that proposed attacks and defenses be thoroughly
and independently evaluated in order to accurately assess
risk of the attack and efﬁcacy of the defense. A second area
of concern, which we discussed brieﬂy in Section V-A, is
the use of physiological values to secure IMDs/BANs. The
evaluations in the literature are limited in scope, partially
because of the lack of availability of appropriate data sets
for use by researchers and partially because the focus has
been on protocol design rather than on a rigorous assessment
of the use of biometrics for cryptographic key establishment.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:58:38 UTC from IEEE Xplore.  Restrictions apply. 
We ﬁrst address issues related to reproducibility in Sec-
tion VI-A, before moving to a discussion of the use of
physiological values in Section VI-B.
A. Reproducibility challenges
Lack of access to devices is a common problem; access
to medical devices is either non-existent or limited to older,
end-of-life models that have been received from patients, rel-
atives, or physicians. The ICD that Halperin et al. [12] study,
for example, is a model introduced to the market ﬁve years
earlier. Without access to the devices themselves, researchers
are necessarily limited in their ability to analyze potential
attacks and defenses; often device hardware conﬁgurations
are not public knowledge. Research results from groups that
have managed to acquire and study particular IMDs are not
likely to be validated by others, if only because of lack of
equipment. While there have been some efforts to provide
access to medical devices [91], direct access to devices from
manufacturers by the security research community appears
to be limited at present.
A second issue in computer security and privacy experi-
ments on medical devices is the use of food-grade meat as
a phantom, or human tissue simulator [12], [50], [59]. As
Clark and Fu [21] observe, this method does not lead to
reproducible experiments, possibly due to the introduction
of uncontrolled variables that can affect
the impedance
of the tissue or propagation of signals in the phantom.
Instead, researchers should use a calibrated saline solution
at 1.8 g/L at 21 ◦C [92, Table 10, p. 30] with electrodes to
inject the appropriate simulated physiological signals. The
complete design is described in the ANSI/AAMI PC69:2007
standard [92, Annex G]; this is the accepted standard for
electromagnetic compatibility of medical devices by re-
searchers, device manufacturers, and regulators.
B. Physiological values as an entropy source
As mentioned in Section V-A1, the use of physiological
values as a building block for security and privacy mech-
anisms is widespread in the literature. In particular, much
research relies on the use of ECGs for security and privacy
mechanisms. ECG measurements have been suggested for
use in authentication [45], key establishment [56], [62], [72],
and proximity detection [57] protocols (i.e., determining if
one or more devices are in physical contact with the same
body). Several systems have devices generate a shared secret
key by reading the ECG signal through physical contact with
the same person [23], [47], [56], [60], [62], [68], [75].
Most of these ECG-based mechanisms rely on the re-
ported randomness of the IPI, or the amount of time between
individual heartbeats [45], [62]; Rostami et al. [19], [45]
suggest that sufﬁcient entropy may be extracted from the
least signiﬁcant bits of properly quantized IPIs. There are
some inconsistencies in the literature with respect to the
quality of randomness it is possible to extract [65], [67],
[71], however, and in studying this issue, researchers have
been limited by a lack of sufﬁcient real-world data. In partic-
ular, it is important to understand the impact of confounding
factors such as health and age on the amount of entropy in
IPI, in order to ensure that appropriate protocol parameters
are chosen for entropy extraction.
In addition, Chang et al. [52] draw attention to the fact
that the feasibility of these schemes relies on the ability of
two devices to measure (and agree on) IPI in the presence
of noise. Therefore, realizing such schemes may be more
difﬁcult using real-world data, rather than data collected in
controlled environments (as measured by physicians with
advanced medical equipment). Chang et al.’s results are in-
dicative that measurement noise must be taken into account;
later work by Rostami et al. [45] address this concern by
taking into account and optimizing for these error rates.
Most evaluations have relied on an aggregation of heart
rate databases from the MIT PhysioNet portal [93], which
provides access to a large number of waveforms (collected
by clinicians) ranging from healthy sinus rhythms to irregu-
lar heartbeat rhythms, or arrhythmias. Many suggested pro-
tocols are evaluated using either unspeciﬁed databases [23],
[47], [56], [62], [68], [75] or arrhythmia databases [45],
[60], [76], [94]. To extract random bits for a given record,
the mean and standard deviation of the record are used to
ﬁrst quantize the bits, with a subset of the least signiﬁcant
bits treated as random. For example, Rostami et al. [45]
quantize the IPI data into 8-bit representations and take the
four least signiﬁcant bits as random; the amount of entropy
is estimated empirically using the classical deﬁnition of
Shannon entropy (i.e., average entropy). A statistical battery
of tests is then applied to the extracted bits—typically the
(basic) subset of the NIST test suite [95] appropriate for the
amount of data available.
Following the state of the art [96], [97], the assessment of
a true random number generator (TRNG) for cryptographic
purposes requires a) an assessment of the quality of the
entropy source itself (and a justiﬁcation that the physical
process being measured is random); b) an analysis of the
efﬁciency and robustness of the extraction method (and the
impact of the extraction method on the statistical properties
of the TRNG); and c) cryptanalysis in the suggested use
case (e.g., if an adversary can observe the entropy source
or has an advantage in guessing future bits, this is not good
for cryptographic use).
In particular, statistical analysis of the output of a TRNG,
such as testing the output using the NIST test suites, is not
sufﬁcient to determine suitability for use in key agreement.
The statistical properties of the physical phenomena need
to be well-understood; properly quantizing the data and
extracting bits that are close to uniform requires an accurate
characterization of the distribution. For example, in the case
of IPI, if the suggested methods for bit extraction do not
ensure that the distribution characteristics used at time of
533
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:58:38 UTC from IEEE Xplore.  Restrictions apply. 
authentication are accurate, the resulting bits may exhibit
bias. We discuss the issue of observability of the IPI entropy