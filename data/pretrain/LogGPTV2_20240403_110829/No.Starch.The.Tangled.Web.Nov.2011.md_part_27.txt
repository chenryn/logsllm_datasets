which may be that both lists have numerous glaring omissions and, given the
number of network protocols devised to date, simply have no chance of ever
being exhaustive. For example, no rule would prevent the browser from talk-
ing to Internet Relay Chat (IRC) servers, which use a fault-tolerant, text-based
protocol not entirely unlike SMTP.
The lists are also not regularly updated to reflect the demise of nearly
extinct network protocols or the introduction of new ones. Lastly, they can
unfairly and unexpectedly penalize system administrators for picking non-
standard ports for certain services they want to hide from public view: Doing
so means opting out of this browser-level protection mechanism.
Limitations on Third-Party Cookies
Since their inception, HTTP cookies have been misunderstood as the tool
that enabled online advertisers to violate users’ privacy to an unprecedented
and previously unattainable extent. This sentiment has been echoed by the
mainstream press in the years since. For example, in 2001, the New York Times
published a lengthy exposé on the allegedly unique risks of HTTP cookies and
even quoted Lawrence Lessig, a noted legal expert and a political activist:1
Before cookies, the Web was essentially private. After cookies, the
Web becomes a space capable of extraordinary monitoring.
The high-profile assault on a single HTTP header continued over the
course of a decade, gradually shifting its focus toward third-party cookies in
particular. Third-party cookies are the cookies set by domains other than the
domain of the top-level document, and they are usually associated with the
process of loading images, frames, or applets from third-party sites. The rea-
son they have attracted attention is that operators of advertising networks
have embraced such cookies as a convenient way to tag a user who sees their
ad embedded on fuzzybunnies.com and then recognize that user through a
similar embedded ad served on playboy.com.
Because the clearly undesirable possibility of performing this type of
cross-domain tracking has been erroneously conflated with the existence of
third-party cookies, the pressure on browser vendors has continued to mount.
In one instance, the Wall Street Journal flat out accused Microsoft of being in
bed with advertisers for not eliminating third-party cookies in the company’s
product.2
Naturally, the readers of this book will recognize that the fixation on
HTTP cookies is deeply misguided. There is no doubt that some parties use
the mechanism for vaguely sinister purposes, but nothing makes it uniquely
suited for this task; there are many other equivalent ways to store unique iden-
tifiers on visitors’ computers (such as cache-based tags, previously discussed
in Chapter 3). Besides, it is simply impossible to prevent cooperating sites
192 Chapter 12
from using existing unique fingerprints of every browser (exposed through
the JavaScript object model or plug-ins such as Flash) to correlate and mine
cross-domain browsing patterns at will. The sites that embed advertisements
for profit are quite willing to cooperate with the parties who pay their bills.
In fact, the common reliance on HTTP cookies offers a distinctive
advantage to users: Unlike many of the easily embraced alternatives, this
mechanism is purpose built and coupled with reasonably well-designed and
fine-grained privacy controls. Breaking cookies will not hinder tracking but
will remove any pretense of transparency from the end user. Another noted
privacy and security activist, Ed Felten, once said: “If you’re going to track
me, please use cookies.”3
Unscrupulous online tracking is a significant social issue, and new tech-
nical mechanisms may be needed so that users can communicate their privacy
preferences to well-behaved sites (such as the recently added DNT request
header4 rolled out in Firefox 4). In order to deal with the ill-behaved ones,
aregulatory framework may be required, too. In the absence of such a frame-
work, in Internet Explorer 9, Microsoft is experimenting with a managed
blacklist of known bad sources of tracking cookies—but the odds that this
would discourage sleazy business practices are slim.
In any case, despite having little or no merit, the continued public outcry
against third-party cookies eventually resulted in several browser vendors
shipping half-baked and easily circumvented solutions that let them claim
they had done something.
 In Internet Explorer, setting and reading third-party cookies is blocked
by default, except for session cookies accompanied by a satisfactory P3P
header. P3P (Platform for Privacy Preferences)5 is a method to construct
machine-readable, legally binding summaries of a site’s privacy policy, be
it as an XML file or as a compact policy in an HTTP header. For example,
the keyword TEL in an HTTP header means that the site uses the col-
lected information for telemarketing purposes. (No technical measure
will prevent a site from lying in a P3P header, but the potential legal
consequences are meant to discourage that.)
NOTE The incredibly ambitious, 111-page P3P specification caused the solution
to crumble under its own weight. Large businesses are usually very hesi-
tant to embrace P3P as a solution to technical problems because of the
legal footprint of the spec, while small businesses and individual site
owners copy over P3P header recipes with little or no understanding of
what they are supposed to convey.
 In Safari, the task of setting third-party cookies is blocked by default,
butpreviously issued cookies can be read freely. However, this behavior
can be overridden if the user interacts with the cookie-setting document
first. Such an interaction could be intentional but may very well not be:
The clickjacking-related tricks outlined in Chapter 11 apply to this sce-
nario as well.
Other Security Boundaries 193
 In other browsers, third-party cookies are permitted by default, but a
configuration option is provided to change the behavior. Enabling this
option limits the ability to set third-party cookies, but reading existing
ones is not limited in any way.
For the purpose of these checks, a cookie is considered to be coming from
a third party if it’s loaded from a completely unrelated domain. For example, a
frame pointing to bunnyoutlet.com loaded on fuzzybunnies.com meets this crite-
rion, but www1.fuzzybunnies.com and www2.fuzzybunnies.com are considered to
be in a first-party relationship. The logic used to make this determination is
fragile, and it suffers from the same problems that cookie domain scoping
would. In Internet Explorer 6 and 7, for example, the comparisons in certain
country-level domains are performed incorrectly.
NOTE The crusade against third-party cookies could be seen as a harmless exercise, but it has
had negative consequences, too. Browsers that reject third-party cookies make it very dif-
ficult to build cookie-based authentication for embeddable gadgets and other types of
mashups, and they make it difficult to use “sandbox” domains to isolate untrusted but
private content from the main application to limit the impact of script-injection flaws.
194 Chapter 12
Security Engineering Cheat Sheet
When Building Web Applications on Internal Networks
 Assume that determined attackers will be able to interact with those applications through
a victim’s browser, regardless of any network-level security controls. Ensure that proper
engineering standards are met and require HTTPS with secure cookies for all sensitive
applications in order to minimize the risk of origin infiltration attacks.
When Launching Non-HTTP Services, Particularly on Nonstandard Ports
 Evaluate the impact of browsers unintentionally issuing HTTP requests to the service
andthe impact of having the response interpreted as HTTP/0.9. For vulnerable proto-
cols, consider dropping the connection immediately if the received data begins with
“GET” or “POST” as one possible precaution.
When Using Third-Party Cookies for Gadgets or Sandboxed Content
 If you need to support Internet Explorer, be prepared to use P3P policies (and evaluate
their legal significance). If you need to support Safari, you may have to resort to an alter-
native credential storage mechanism (such as HTML5 localStorage).
Other Security Boundaries 195
C O N T E N T R E C O G N I T I O N
M E C H A N I S M S
So far, we have looked at a fair number of well-
intentioned browser features that, as the technology
matured, proved to be short-sighted and outright dan-
gerous. But now, brace for something special: In the
history of the Web, nothing has proven to be as mis-
guided as content sniffing.
The original premise behind content sniffing was simple: Browser vendors
assumed that in some cases, it would be appropriate—even desirable—to
ignore the normally authoritative metadata received from the server, such as
the Content-Type header. Instead of honoring the developer’s declared intent,
implementations that support content sniffing may attempt to second-guess
the appropriate course of action by applying proprietary heuristics to the
returned payload in order to compensate for possible mistakes. (Recall from
Chapter 1 that during the First Browser Wars, vendors turned fault-tolerance
compatibility into an ill-conceived competitive advantage.)
It didn’t take long for content-sniffing features to emerge as a substantial
and detrimental aspect of the overall browser security landscape. To their
horror and disbelief, web developers soon noticed that they couldn’t safely
host certain nominally harmless document types like text/plain or text/csv on
behalf of their users; any attempt to do so would inevitably create a risk that
such content could be misinterpreted as HTML.
Perhaps partly in response to these concerns, in 1999 the practice of
unsolicited content sniffing was explicitly forbidden in HTTP/1.1:
If and only if the media type is not given by a Content-Type field, the
recipient may attempt to guess the media type via inspection of its
content and/or the name extension(s) of the URI used to identify
the resource.
Alas, this uncharacteristically clear requirement arrived a bit too late. Most
browsers were already violating this rule to some extent, and absent a con-
venient way to gauge the potential consequences, their authors hesitated to
simply ditch the offending code. Although several of the most egregious mis-
takes were cautiously reverted in the past decade, two companies—Microsoft
and Apple—largely resisted the effort. They decided that interoperability with
broken web applications should trump the obvious security problems. To
pacify any detractors, they implemented a couple of imperfect, secondary
security mechanisms intended to mitigate the risk.
Today, the patchwork of content-handling policies and the subsequently
deployed restrictions cast a long shadow on the online world, making it nearly
impossible to build certain types of web services without resorting to contrived
and sometimes expensive tricks. To understand these limitations, let’s begin
by outlining several scenarios where a nominally passive document may be
misidentified as HTML or something like it.
Document Type Detection Logic
The simplest and the least controversial type of document detection heuris-
tics, and the one implemented by all modern browsers, is the logic imple-
mented to handle the absence of the Content-Type header. This situation,
which is encountered very rarely, may be caused by the developer acciden-
tally omitting or mistyping the header name or the document being loaded
over a non-HTTP transport mechanism such as ftp: or file:.
For HTTP specifically, the original RFCs explicitly permit the browser
toexamine the payload for clues when the Content-Type value is not available.
For other protocols, the same approach is usually followed, often as a natural
consequence of the design of the underlying code.
The heuristics employed to determine the type of a document typically
amount to checking for static signatures associated with several dozen known
file formats (such as images and common plug-in-handled files). The response
will also be scanned for known substrings in order to detect signatureless for-
mats such as HTML (in which case, the browser will look for familiar tags—
, , etc). In many browsers, noncontent signals, such as trailing .html
or .swf strings in the path segment of the URL, are taken into account aswell.
198 Chapter 13
The specifics of content-sniffing logic vary wildly from one browser to
another and are not well documented or standardized. To illustrate, consider
the handling of Adobe Flash (SWF) files served without Content-Type: In Opera,
they are recognized unconditionally based on a content signature check; in
Firefox and Safari, an explicit .swf suffix in the URL is required; and Internet
Explorer and Chrome will not autorecognize SWF at all.
Rest assured, the SWF file format is not an exceptional case. For example,
when dealing with HTML files, Chrome and Firefox will autodetect the docu-
ment only if one of several predefined HTML tags appears at the very begin-
ning of the file; while Firefox will be eager to “detect” HTML based solely on
the presence of an .html extension in the URL, even if no recognizable markup
is seen. Internet Explorer, on the other hand, will simply always default to
HTML in the absence of Content-Type, and Opera will scan for known HTML
tags within the first 1000 bytes of the returned payload.
The assumption behind all this madness is that the absence of Content-
Type is an expression of an intentional wish by the publisher of the page—
but that assumption is not always accurate and has caused a fair number of
security bugs. That said, most web servers actively enforce the presence of a
Content-Type header and will insert a default value if one is not explicitly gen-
erated by the server-side scripts that handle user requests. So perhaps there is
no need to worry? Well, unfortunately, this is not where the story of content
sniffing ends.
Malformed MIME Types
The HTTP RFC permits content sniffing only in the absence of Content-Type
data; the browser is openly prohibited from second-guessing the intent of the
webmaster if the header is present in any shape or form. In practice, however,
this advice is not taken seriously. The next small step taken off the cliff was
the decision to engage heuristics if the server-returned MIME type was
deemed invalid in any way.
According to the RFC, the Content-Type header should consist of two
slash-delimited alphanumeric tokens (type/subtype), potentially followed by
other semicolon-delimited parameters. These tokens may contain any non-
whitespace, seven-bit ASCII characters other than a couple of special “sepa-
rators” (a generic set that includes characters such as “@”, “?”, and the slash
itself). Most browsers attempt to enforce this syntax but do so inconsistently;
the absence of a slash is seen almost universally as an invitation to content
sniffing, and so is the inclusion of whitespaces and certain (but not all) con-
trol characters in the first portion of the identifier (the type token). On the
other hand, the technically illegal use of high-bit characters or separators
affects the validity of this field only in Opera.
The reasons for this design are difficult to understand, but to be fair, the
security impact is still fairly limited. As far as web application developers are con-
cerned, care must be exercised not to make typos in Content-Type values and not
to allow users to specify arbitrary, user-controlled MIME types (merely validated
against a blacklist of known bad options). These requirements may be unex-
pected, but usually they do not matter a lot. So, what are we ultimately getting at?
Content Recognition Mechanisms 199
Special Content-Type Values
The first clear signal that content sniffing was becoming truly dangerous was
the handling of a seemingly unremarkable MIME type known as application/
octet-stream. This specific value is not mentioned at all in the HTTP specifica-
tion but is given a special (if vague) role deep in the bowels of RFC 2046:1
The recommended action for an implementation that receives an
application/octet-stream entity is to simply offer to put the data in a
file, with any Content-Transfer-Encoding undone, or perhaps to use it
as input to a user-specified process.
The original intent of this MIME type may not be crystal clear from the
quoted passage alone, but it is commonly interpreted as a way for web servers
to indicate that the returned file has no special meaning to the server and
that it should not have one to the client. Consequently, most web servers
default to application/octet-stream on all types of opaque, nonweb files, such as
downloadable executables or archives, if no better Content-Type match can be
found. However, in rare cases of administrator errors (for example, due to
deletion of the essential AddType directives in Apache configuration files),
web servers may also fall back to this MIME type on documents meant for
in-browser consumption. This configuration error is, of course, very easy to
detect and fix, but Microsoft, Opera, and Apple nevertheless chose to com-
pensate for it. The browsers from these vendors eagerly engage in content
sniffing whenever application/octet-stream is seen.*
This particular design decision has suddenly made it more difficult for
web applications to host binary files on behalf of the user. For example, any
code-hosting platform must exercise caution when returning executables or
source archives as application/octet-stream, because there is a risk they may be
misinterpreted as HTML and displayed inline. That’s a major issue for any
software hosting or webmail system and for many other types of web apps.
(It’s slightly safer for them to use any other generic-sounding MIME type,
such as application/binary, because there is no special case for it in the
browser code.)
In addition to the special treatment given to application/octet-stream, a
second, far more damaging exception exists for text/plain. This decision,
unique to Internet Explorer and Safari, traces back to RFC 2046. In that doc-
ument, text/plain is given a dual function: first, to transmit plaintext docu-
ments (ones that “do not provide for or allow formatting commands, font attribute
specifications, processing instructions, interpretation directives, or content markup”)
and, second, to provide a fallback value for any text-based documents not
otherwise recognized by the sender.
* In Internet Explorer, this implemented logic differs subtly from a scenario where no Content-
Type is present. Instead of always assuming HTML, the browser will scan the first 256 bytes for
popular HTML tags and other predefined content signatures. From the security standpoint,
however, it’s not a very significant difference.
200 Chapter 13
The distinction between application/octet-stream and text/plain fallback
made perfect sense for email messages, a topic that this RFC originally dealt
with, but proved to be much less relevant to the Web. Nevertheless, some
web servers adopted text/plain as the fallback value for certain types of
responses (most notably, the output of CGI scripts).
The text/plain logic subsequently implemented in Internet Explorer and
Safari in order to detect HTML in such a case is really bad news: It robs web
developers of the ability to safely use this MIME type to generate user-specific
plaintext documents and offers no alternatives. This has resulted in a sub-
stantial number of web application vulnerabilities, but to this day, Internet
Explorer developers seem to have no regrets and have not changed the
default behavior of their code.
Safari developers, on the other hand, recognized and tried to mitigate the
risk while keeping the functionality in place—but they failed to appreciate
the complexity of the Web. The solution implemented in their browser is to
rely on a secondary signal in addition to the presence of a plausible-looking
HTML markup in the document body. The presence of an extension such as
.html or .xml at the end of the URL path is interpreted by their implementa-
tion as a sign that content sniffing can be performed safely. After all, the
owner of the site wouldn’t name the file this way otherwise, right?
Alas, the signal they embraced is next to worthless. As it turns out, almost