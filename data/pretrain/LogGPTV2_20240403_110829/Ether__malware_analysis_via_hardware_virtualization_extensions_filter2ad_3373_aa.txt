title:Ether: malware analysis via hardware virtualization extensions
author:Artem Dinaburg and
Paul Royal and
Monirul I. Sharif and
Wenke Lee
Ether: Malware Analysis via
Hardware Virtualization Extensions
Artem Dinaburg∗†, Paul Royal†∗, Monirul Sharif∗†, Wenke Lee†∗
{artem, paul, msharif, wenke}@{gtisc.gatech.edu, damballa.com}
∗Georgia Institute of Technology, Atlanta, GA, USA
†Damballa, Inc., Atlanta, GA, USA
ABSTRACT
Malware has become the centerpiece of most security threats
on the Internet. Malware analysis is an essential technology
that extracts the runtime behavior of malware, and supplies
signatures to detection systems and provides evidence for re-
covery and cleanup. The focal point in the malware analysis
battle is how to detect versus how to hide a malware ana-
lyzer from malware during runtime. State-of-the-art analyz-
ers reside in or emulate part of the guest operating system
and its underlying hardware, making them easy to detect
and evade. In this paper, we propose a transparent and ex-
ternal approach to malware analysis, which is motivated by
the intuition that for a malware analyzer to be transparent,
it must not induce any side-eﬀects that are unconditionally
detectable by malware. Our analyzer, Ether, is based on a
novel application of hardware virtualization extensions such
as Intel VT, and resides completely outside of the target OS
environment. Thus, there are no in-guest software compo-
nents vulnerable to detection, and there are no shortcomings
that arise from incomplete or inaccurate system emulation.
Our experiments are based on our study of obfuscation tech-
niques used to create 25,000 recent malware samples. The
results show that Ether remains transparent and defeats the
obfuscation tools that evade existing approaches.
Categories and Subject Descriptors
D.4.6 [Operating Systems]: Security and Protection—In-
vasive software
General Terms
Security
Keywords
Malware Analysis, Dynamic Analysis, Virtualization, Emu-
lation, Unpacking
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’08, October 27–31, 2008, Alexandria, Virginia, USA.
Copyright 2008 ACM 978-1-59593-810-7/08/10 ...$5.00.
1.
INTRODUCTION
Malware–the increasingly common vehicle by which crim-
inal organizations facilitate online crime–has become an ar-
tifact whose use intersects multiple major security threats
(e.g., botnets) faced by information security practitioners.
Given the ﬁnancially motivated nature of these threats, meth-
ods of recovery now mandate more than just remediation:
knowing what occurred after an asset became compromised
is as valuable as knowing it was compromised. Concisely,
independent of simple detection, there exists a pronounced
need to understand the intentions or runtime behavior of
modern malware.
Recent advances in malware analysis [17, 24, 25, 33] show
promise in understanding modern malware, but before these
and other approaches can be used to determine what a mal-
ware instance does or might do, the runtime behavior of that
instance and/or an unobstructed view of its code must be ob-
tained. However, malware authors are incentivized to com-
plicate attempts at understanding the internal workings of
their creations. Therefore, modern malware contain a myr-
iad of anti-debugging, anti-instrumentation, and anti-VM
techniques to stymie attempts at runtime observation [16,
42]. Similarly, techniques that use a malware instance’s
static code model are challenged by runtime-generated code,
which often requires execution to discover.
In the obfuscation/deobfuscation game played between
attackers and defenders, numerous anti-evasion techniques
have been applied in the creation of robust in-guest API call
tracers and automated deobfuscation tools [34, 38, 43, 47].
More recent frameworks [1, 3, 44] and their discrete com-
ponents [15, 19] attempt to oﬀer or mimic a level of trans-
parency analogous to that of a non-instrumented OS running
on physical hardware. However, given that nearly all of these
approaches reside in or emulate part of the guest OS or its
underlying hardware, little eﬀort is required by a knowledge-
able adversary to detect their existence and evade [26, 39].
In this paper we present a transparent, external approach
to malware analysis. Our approach is motivated by the in-
tuition that for a malware analyzer to be transparent, it
must not induce any side-eﬀects that are unconditionally
detectable by its observation target. In formalizing this in-
tuition, we model the structural properties and execution
semantics of modern programs to derive the requirements
for transparent malware analysis. An analyzer that satis-
ﬁes these transparency requirements can obtain an execution
trace of a program identical to that if it were run in an en-
vironment with no analyzer present. Approaches unable to
fulﬁll these requirements are vulnerable to one or more de-
tection attacks–categorical, formal abstractions of detection
techniques employed by modern malware.
Creating a transparent malware analyzer required us to
diverge from existing approaches that employ in-guest com-
ponents, API virtualization or partial or full system em-
ulation, because none of these implementations satisfy all
the transparency requirements. Based on novel application
of hardware virtualization extensions such as Intel VT [6],
our analyzer–called Ether –resides completely outside of the
target OS environment– there are no in-guest software com-
ponents vulnerable to detection or attack. Additionally, in
contrast to other external approaches, the hardware-assisted
nature of our approach implicitly avoids many shortcomings
that arise from incomplete or inaccurate system emulation.
To demonstrate the eﬃcacy of our approach we tested
Ether with other academic and commercial approaches. Our
testing included the analysis of speciﬁc in-the-wild malware
instances that attempt to detect instrumentation and/or a
virtual environment.
In addition, we also surveyed over
25,000 recent malware samples to identify the distribution of
obfuscation tools used in their creation; this knowledge was
then used to create a synthetic sample set that represents
the majority of the original corpus. The results of testing
(presented in Section 5) show that Ether is able to remain
transparent and defeat a large percentage of the obfuscation
tools that evade existing approaches.
Our work represents the following contributions:
• A formal framework for describing program execution
and analyzing the requirements for transparent mal-
ware analysis.
• Implementation of Ether, an external, transparent mal-
ware analyzer that operates using hardware virtualiza-
tion extensions to oﬀer both ﬁne- (single instruction)
and coarse- (system call) granularity tracing. To mo-
tivate the use of our approach by the information se-
curity community, the GPL’ed source code for Ether is
available for download at http://ether.gtisc.gatech.edu.
• Broad-scale evaluation of current approaches using a
proxy set of samples representing the majority of a
recent, large malware corpus. Copies of discrete sam-
ples referenced in this paper and the 25,000 malware
sample corpus used for our survey are available to any
academic or industry professional at an accredited or-
ganization.
The remainder of this paper is organized as follows. Sec-
tion 2 describes related work. Section 3 presents our model
for programs and their execution, formal requirements for
transparency, and abstract representations of failures in trans-
parency that lead to detection attacks. Section 4 describes
Ether’s design and implementation, including an in-depth
explanation of how hardware virtualization extensions are
leveraged. Section 5 details the experiment selection pro-
cess and how experimentation was performed, and provides
an analysis of the results. Finally, Section 6 brieﬂy describes
future work and provides some concluding remarks.
2. RELATED WORK
Traditionally, anti-virus scanners have used simple emu-
lation and API virtualization in their scanning engines [42].
More recent malware analysis eﬀorts make heavy use of vir-
tualized and emulated environments for their operation. Ex-
amples include systems derived from the BitBlaze project [3]
(e.g., Polyglot [23] and Panorama [48]), Siren [22] and oth-
ers. Honeypot-based projects also employ virtual environ-
ments for trapping and investigating malware [31, 36, 46].
Virtualization- or emulation-based approaches can be used
to construct malware processing systems that provide a level
of isolation between the guest and the host operating sys-
tems.
In these systems, modiﬁcations made to the guest
by an instance of malware can be quickly discarded, en-
suring that each instance runs in the same sterile environ-
ment. Approaches that employ these ideas to obtain scal-
ability include malware analysis services such as Norman
Sandbox [13], CWSandbox [47] and Anubis [1].
Previous frameworks for ﬁne-grained tracing of programs
include VAMPiRE [43], BitBlaze [3] and Cobra [44]. Among
these, VAMPiRE is in-guest, BitBlaze uses whole-system
emulation, while Cobra traces malware at the same privilege
level as itself. None of these frameworks use hardware virtu-
alization extensions for their analysis capabilities or informa-
tion gathering. Automated unpackers–common applications
for ﬁne-grained analysis–include PolyUnpack [40] and Ren-
ovo [32]. Renovo takes an out-of-guest approach, utilizing
whole-system emulation for its unpacking engine. PolyUn-
pack uses an in-guest approach and hence runs at the same
privilege level as the malware it is analyzing.
Frameworks which could be used for system call or Win-
dows API tracing include Detours [29] and DynInst [4]. Sys-
tem call tracing using out-of-guest environments has been
previously implemented in VMScope [30] and TTAnalyze [19],
both of which are based on QEMU [20]. There are many
in-guest approaches used to trace Windows API functions,
which include older tools such as FileMon [5], RegMon [9],
and more recently sandboxing environments such as CWSand-
box and Norman Sandbox. These approaches use a com-
bination of API hooking and/or API virtualization, which
are detectable by malware running at the same privilege
level [27].
3. FORMAL FOUNDATIONS
In this section, we analyze the requirements for building
a dynamic transparent malware analysis system (i.e., one
that cannot be detected and evaded by the malware being
analyzed). These requirements serve as guiding principles
to the design and implementation of Ether (Section 4). We
start with a simple, abstract model for program execution
and present the basic deﬁnition and theorem of transparent
malware analysis. We then extend our model to consider
virtual memory, privilege levels, system calls, exception han-
dling, and execution timing that are part of realistic program
execution environments.
3.1 Abstract Model of Program Execution
We model a program’s execution at the machine instruc-
tion level. Since a low level instruction can access memory
and CPU directly, we consider a system state as the collec-
tion of the contents of memory and CPU registers. Let M
be the set of all possible memory states and C be the set
of all possible CPU states. We use I to denote all possible
instructions. Each instruction can be considered a machine
recognizable combination of opcode and operands stored at
at a particular address in memory. The low-level semantics
of an instruction deﬁnes how it updates the memory and
CPU state.
We model any program P as a tuple (IP , DP ) of code and
data. Here, IP ⊆ I is the set of all instructions belonging to
the program, including any dynamically generated instruc-
tions. DP is the set of static data used by the code where
each element can be considered a value stored in a particular
address. Execution of a program’s instruction may require
access to hardware resources, especially for performing I/O.
Such hardware resources are usually managed by the under-
lying operating system, which executes predeﬁned service
routines on behalf of speciﬁc application level instructions.
We deﬁne the surrounding runtime environment E for the
program P that contains any software or hardware compo-
nents that provide any service necessary for P ’s execution.
In other words, the environment E contains the operating
system, underlying hardware, virtual machine monitors and
external inputs.
We deﬁne a transition function δE : I ×M ×C → I ×M ×C
to formally represent the semantics of executing an instruc-
tion in E, which is a combination of the machine-level exe-
cution semantics and the semantics deﬁned by components
in the environment. This function deﬁnes how an instruc-
tion execution in the environment updates CPU and mem-
ory state and determines the next instruction to be exe-
cuted. Since we only need instructions belonging to IP
in order to obtain an execution trace of P in E, we use
another transition function δE,IP : IP × M × C → IP ×
M × C, which takes from δE a projection of instructions in
IP . The trace of the program P in E is T (P, E), which is
an ordered set deﬁned as T (P, E) = (i0, i1, i2, ..., il), where
δE,IP (ik, mk, ck) = (ik+1, mk+1, ck+1) for 0 ≤ k < l.
3.2 Transparent Malware Analysis
Suppose P is a malware program. Consider a dynamic
malware analyzer PA whose goal is to learn about P ’s ac-
tivities (e.g., its execution traces). In order to analyze P ,
PA or at least some of its components need to reside in the
underlying environment E. The malware program P , on the
other hand, will try to detect the presence of PA and change
or hide its actvities to thwart analysis. Thus, we want PA
to be transparent or undetectable by P .
Since PA and P share at least some resource in the run-
time environment (e.g., the CPU), a covert channel can ex-
ist that leaks information about the presence of PA to the
malware P . To prevent such leakage, the principle of non-
interference [21] dictates that the execution of PA shall not
interfere with the execution of P . Intuitively, if noninter-
ference is achieved, P has the same execution (for the same
given input) regardless of PA.
We model an attempt by P to detect the presence of PA in
E as a boolean function dP (E). P must perform its own dP
instructions (included as part of its code IP , i.e., dP ⊂ Ip)
to get/infer information about PA. For example, dp can
include an instruction to query the debugging ﬂag in E.
The results of this check can be used in the malware to alter
its behavior when the analyzer PA is detected. Before PA is
enabled in E, we have dp(E) = 0. Denote the environment
with PA running as A. The transparency goal is to achieve
dP (A) = dP (E) = 0 for any detection method dP . Thus, we
have the following deﬁnition:
Definition 1. Assume E is a runtime environment, and
A is E with malware analyzer PA running. PA is transpar-
ent if for any malware P containing any detection logic dP ,
dP (A) = dP (E) = 0.
The above deﬁnition provides a starting point for ana-
lyzing the requirements of a transparent malware analyzer.
Since enumerating all possible instruction sequences for the
detection attempt dP is an undecidable problem, we state
the transparency goals in a diﬀerent and more tractable way.
Without loss of generality, we assume that P will alter its
execution path when it detects PA (i.e., if dP (E) = 1) be-
cause the malware author would try to hide the behavior of
the malware from an analyzer. That is, at the point of detec-
tion k, δE,IP (ik, mk, ck) = (i′
k+1) if dP (E) = 1,
i.e., P executes i′
k+1 instead of the instruction ik+1 that
would have executed without the presence of an analyer.
Ultimately, the goal of a transparent malware analyzer is to
extract the same execution traces from malware as if the an-
alyzer is not present. Thus, we have the following malware
analysis theorem, which inherently guarantees the above def-
inition of transparency:
k+1, m′
k+1, c′
Theorem 1. If E is a runtime environment and A is the
same environment with the addition of a malware analyzer
PA, then PA is transparent if and only if T (P, E) = T (P, A)
for any malware program P = (IP , DP ).
Proof. In both environments E and A the same exter-
nal inputs are provided to the program P since they are
modeled as part of the environments. The traces of the pro-
gram P in these two environments are deﬁned as T (P, E) =