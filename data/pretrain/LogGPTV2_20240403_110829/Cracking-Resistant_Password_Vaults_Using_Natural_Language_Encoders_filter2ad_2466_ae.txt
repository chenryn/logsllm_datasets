selected using p1 from the rule set for the start symbol S,
producing the children of S in the tree. A rule from the rule
set for each child is then selected using p2, p3, etc., from
left to right. Recursing in this way produces the full parse
tree; its leaves, read left to right, constitute str.
As shown in the full paper, we can represent a rule-set
probability by an b-bit integer. It follows that a parse tree for
a PCFG, and thus a generated string P , may be completely
speciﬁed by a vector (cid:2)X = (cid:8)X1, . . . , Xk(cid:9) of k integers, where
Xi ∈ {0, 1}b. This vector is not necessarily unique: There
may, of course, be multiple vectors corresponding to str.
We can now build a DTE from any PCFG model. Decod-
ing takes as input a vector (cid:2)X of integers, uses it to determine
a parse tree, and outputs the corresponding password P .
This requires time O(n log s) for n-character passwords and
where s is the size of the largest rule set in the PCFG.
Encoding takes as input a password P and selects uniformly
490490
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:07:53 UTC from IEEE Xplore.  Restrictions apply. 
at random a vector (cid:2)X from the set of all that decode to
P . This inverse sampling can be efﬁciently implemented by
ﬁnding all parse trees (also known as parse forest) of P , and
picking one at random. This is an O(k3) time operation [2],
[16]. Note that (cid:2)X is of a ﬁxed size k; thus encoding pads
out the resulting vector with random bit strings representing
sufﬁciently many extra integers.
Of course, all of the above relies on having a PCFG that
accurately models the password distribution, a research topic
in its own right [27], [30], [35], [37]. Our general approach
has the beneﬁt of allowing us to use any of these prior
PCFG construction approaches. We built our own hand-
tuned PCFG using the RockYou training set, employing a
combination of techniques from Weir et al. [37] and Veras et
al. [35]. In initial evaluations it performs better than the Weir
et al. PCFG (in terms of security; see Section VI). Some
further details on the process for generating it are provided in
the full version of the paper. We refer to the DTE built from
our new PCFG as PCFG. As baselines for decoy generation
quality, we built two additional DTEs, WEIR and WEIR-
UNIF. WEIR uses the grammar proposed by Weir et al. [37].
WEIR-UNIF is the same grammar except it ignores frequency
information and treats all rules inside a rule-set with equal
probability. These grammars are functionally equivalent to
those used by Kamouﬂage+ and Kamouﬂage, respectively,
when restricted to a single password.
From one-password DTEs to vault DTEs. We can eas-
ily extend any single-password DTE to handle multiple
passwords by applying an encoder independently to each
password in the vault. This models a vault distribution in
which passwords are independent of one another. This is
especially useful when we have both computer-generated
passwords in a vault as well as human-chosen; we can
choose appropriate single-password DTEs for each case.
We denote this independent-password DTE by MPW (for
multiple passwords).
Such a DTE may not work well when users repeat or
have related passwords in their vaults, however, motivating
a decode algorithm that generates a vector of passwords (cid:2)P
in which passwords repeat in full or part. We introduce
a technique for embellishing PCFG-based single-password
DTEs to handle vaults in this way, what we refer to as the
sub-grammar approach. The intuition is that if DTE-decode
samples passwords from a smaller domain than the actual
trained PCFG, it will often end up using the same password
components or full passwords.
In more detail, SG (for sub-grammar) is the following
DTE scheme. Encoding ﬁrst parses all the passwords in
(cid:2)P using the trained PCFG. It then generates a new sub-
grammar PCFG that consists of the cumulative set of rules
used in parsing the passwords in (cid:2)P . The rule probabilities
are copied from the original PCFG and then normalized over
the sub-grammar PCFG. (We also copy special rule sets
described in detail in the full paper. For example, T, the
catch-all rule, is always included in the sub-grammar.) This
sub-grammar is encoded as the ﬁrst part of the DTE output,
as detailed below. Finally, the DTE separately encodes each
P ∈ (cid:2)P as in PCFG, but using the sub-grammar PCFG.
Decoding works in the natural way: ﬁrst decode the sub-
grammar PCFG, then decode the encoding of each password
using the resulting sub-grammar PCFG.
Encoding/Decoding of the sub-grammar. Given a canon-
ical representation of the trained PCFG, a sub-grammar
can be speciﬁed by simply encoding for each non-terminal
(except T) the number of corresponding rules used by the
sub-grammar followed by a list of such rules. Each rule in
the list is encoded in the same way as a derivation rule for
a password.
To encode the size of a rule set we proceed as follows.
Using a set of leaked password vaults in Pastebin (see
Section VI), we generate the sub-grammar PCFG for all
the vaults of size ≥ 2. For each non-terminal in the PCFG
(except T), we then create a histogram of the number of the
non-terminal rules used by each sub-grammar. This gives
a per-non-terminal empirical distribution on the number
of rules used, which we use as the distribution for sizes
that should arise when decoding a random string to a sub-
grammar. The DTE encodes this distribution via the inverse
transform sampling mechanism of [23].
We have explained now how SG encodes an input (cid:2)P in
a way that captures structure across passwords, making SG
suitable for encoding of password vaults. One additional step
is required in the full speciﬁcation of encode: SG pads out
all encodings to a constant length with random bits. This is
important because the size of the encoding will otherwise
leak the size of the sub-grammar.
VI. EVALUATING THE ENCODERS
We have shown how to construct functional NLEs that
model real-world password selections by human users of
password vaults. To evaluate the quality of these NLEs, we
now study their resilience to attack using standard machine-
learning techniques.
Recall that in an ofﬂine brute-force attack the adversary
makes repeated guesses at the master password and decrypts
the target vault under each guess. The task of the adversary
is to identify the result of decryption under the true master
password, i.e., to determine the true plaintext for the vault.
Suppose q is the number of such guessing / decryption
attempts. If the true master password is among the adver-
sary’s guesses, the result will be q− 1 random samples from
the NLE, as well as the true plaintext, and thus q plaintext
candidates in total.
We consider an adversary that orders these q plaintexts
in a list from highest to lowest likelihood of being the true
vault (in the adversary’s view). The adversary’s best strategy
491491
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:07:53 UTC from IEEE Xplore.  Restrictions apply. 
in the list
for attacking the vault is then to make online authentication
attempts using one password from each plaintext (decrypted
vault) in order from the list. Thus the position of the
true plaintext vault
indicates the number of
online authentication attempts the adversary must make. We
evaluate such an attack for an adversary that ignores master
password likelihood, and instead uses machine learning
(ML) algorithms on the plaintexts to order the list.
Evaluating single decoy passwords. We start by evaluating
the security of NLEs for single decoy passwords, and leave
full vault analysis to the next subsection. The security goal
for a single-password NLE is to produce a decoy password
that is indistinguishable by an adversary from a true, user-
selected one. We evaluate security in two ways.
First, we look at the accuracy with an binary adversarial
classiﬁer can assign the right label (“true” / “decoy”) to a
password. Second, we evaluate the ability of such a classiﬁer
to assign a high rank to a true password in an ordered list
of plaintexts (single passwords) as described above. For this
second evaluation, we use the conﬁdence measure of the
classiﬁer for a label assignment of “true” as the basis for
ranking passwords in the list.
Methodology. We explored a number of approaches to
attack, and settled on building machine learning (ML) clas-
siﬁers to distinguish between true and decoy passwords.
We treat this as a supervised learning problem. That means
we train a classiﬁer with two sets: labeled true passwords
and labeled decoy passwords. We test by drawing from two
(disjoint) sources of real passwords and decoy passwords.
After experiments with a number of feature and classiﬁer
types, we have chosen to report only on the best-performing
option, random forest classiﬁers [10] with 20 estimators
using the following features:
(1) Bag of characters: This feature captures the frequency
distribution of characters in a password. We represent
this feature as a vector of integers of size equal to the
number of printable characters. We also append the
length of the password to the vector.
(2) n-gram probability: We train two 4-gram models sepa-
rately on each of the two classes of password (true and
decoy) provided for training. For a given password, we
use the probability yielded by each of these two models
as a feature. (These two probabilities / features do not
sum in practice to 100%, as they would for perfectly
complementary models.)
We apply this classiﬁer to the various training set / testing
set pairs explored in our experiments.
We evaluate ﬁve distinct NLEs as sources of decoys:
WEIR-UNIF, WEIR, UNIF, NG, and PCFG. These are all
trained using the RockYou training set RY-tr. To generate a
decoy using any of these NLEs, we decode a fresh, random
bit string of suitable length. As a sixth source of “decoys”
NLEs
WEIR-UNIF
WEIR
UNIF
NG
PCFG
RY-tr
Myspace
¯r
α
24
66
35
63
86
2
22
70
26
70
70
22
Yahoo
¯r
α
13
72
54
36
97 <2
41
68
39
58
64
50
RY-ts
¯r
α
5
82
60
25
97 <2
41
61
39
57
50
50
Figure 4.
For different decoy / true password source pairs, percentage
classiﬁcation accuracy (α) and percentage average rank (¯r) of a real
password in a list of q = 1,000 decoy passwords for ML adversary. Lower
α and higher ¯r signify good decoys.
we sample directly from RY-tr.
As sources of true passwords, we use the RY-ts, Myspace,
and Yahoo data sets. Use of RY-ts creates a case where
the NLE is trained using samples from the same data set
(but not the same data) as the classiﬁer is tested upon. Use
of Myspace and Yahoo data sets creates a case where true
passwords originate from a different distribution, which we
expect to make the task of distinguishing true from decoy
easier for the adversary.
As we have six sources of decoy passwords and three sets
of true passwords, we have a total of eighteen true / decoy
source pairs on which to conduct our experiments.
For each experiment, given a true / decoy password source
pair, we ﬁrst sample t passwords from the true data set
uniformly without replacement to obtain a derived set of
true passwords. We set t = 100, 000 or the size of the true
data set, whichever is smaller. We treat the sampled data
set as a multiset, meaning that the probability of selecting a
password is proportional to the number of times it appears
in the set. We also treat the derived data set as multiset,
meaning that a given true password can be sampled and
thus appear multiple times. We then generate a set of t
decoy passwords using the decoy source, i.e., by using the
appropriate NLE or sampling from the “decoy” set RY-tr.
Using the resulting pair of derived data sets, we do a 10-fold
cross-validation of the random forest classiﬁer with 90% /
10% training / testing splits.
For our experiments in true / decoy password classiﬁca-
tion, we measure α, the average accuracy of the classiﬁer
on testing data. In those experiments involving ranking of q
passwords in order of likelihood of being the true password,
we order passwords according to the conﬁdence of the
classiﬁer in assigning a “true” label. We measure ¯r, the
average rank of the true password in the resulting list. (Thus
¯r is an estimate of the number of online authentication
attempts required for a brute-force attacker that uses the
classiﬁer to identify the true password.)
An effective classiﬁer will achieve a high value of α and
a low value of ¯r. For example, a classiﬁer that performs no
better than random on a given decoy generation algorithm
492492
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:07:53 UTC from IEEE Xplore.  Restrictions apply. 
will on expectation achieve α = 50% and ¯r = (q + 1)/2. A
perfect classiﬁer will achieve α = 100% and ¯r = 1.
Figure 4 reports the average classiﬁcation accuracy (α)
and average rank (¯r) (expressed as a percentage) across
our eighteen true / decoy password source pairs. For ex-
periments, we set q = 1,000. In other words, we drew
one password from the true password set and inserted it in
a randomly selected position among 999 decoys generated
from the decoy source. (We chose q = 1,000 as larger values,
e.g., q = 10,000, yielded similar results in preliminary exper-
iments, but resulted in signiﬁcantly longer times generating
decoys and thus for overall experiment execution.)
It
Several outcomes of our experiments are notable. As
expected, the uniform NLE UNIF does quite poorly, with
the classiﬁer strongly distinguishing it from true passwords.
Also as expected, the adversary performs better in nearly all
cases against Myspace and Yahoo data than RY-tr, that is,
when the adversary trains on the true password source, and
the decoy generator designer does not. (As a sanity check,
given the use of RY-tr as a source of “decoy” passwords, and
RY-ts as a source of true passwords, i.e., a common source
for both, the adversary does no better than random guessing
in distinguishing true from “decoy.”)
is important
to observe that no decoy generator is
consistently superior to others across the board. For example,
WEIR resists attack best for Myspace and Yahoo data sets,
while PCFG is superior in the case of RY-ts. As all decoy
generators are trained on RY-ts, these results suggest that
WEIR generalizes better than PCFG, in the sense that it can
be deployed effectively to protect password sources different
from those on which it has been trained. Strikingly, in the
task of distinguishing decoys from true passwords drawn
from the the Myspace and Yahoo data sets, WEIR generates
decoys that are harder for the adversary than “decoys” (true
passwords) from RY-tr.
Evaluating complete password vaults. Due to space con-
straints we relegate to the full version a description of our
analysis of SG, our NLE for generating full decoy vaults.