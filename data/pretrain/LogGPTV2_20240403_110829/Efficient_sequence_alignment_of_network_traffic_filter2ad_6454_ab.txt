ei−1  I S2
The resulting sequence of S2 indices is an LCS of S1 and S2:
‘GET ’, ‘/’, ‘ HTTP’. To estimate the runtime complexity
of this procedure, observe that the last numbers of the sub-
sequences are sorted in increasing order at all times when
scanning the table left-to-right. We can thus ﬁnd the correct
column for insertion via binary search. Let S1 be the shorter
of the two strings, without loss of generality. Since there can
never be more than s1 sequences in the table and we insert
π elements in total, this algorithm runs in O(π log s1).
3.2
Improving Jacobson-Vo: Targeted LCS
Selection
Note that for our running example, standard Jacobson-Vo
yields an LCS that violates the goals of gap minimisation
and substring maximisation. We now extend the algorithm
to overcome this limitation, borrowing several concepts from
Smith-Waterman: we introduce dynamic programming to
Jacobson-Vo to track incrementally the LCS that yields the
smallest number of gaps and longest-possible substrings, and
collect the optimal LCS via back-pointer traversal. As we
will show, these extensions render Jacobson-Vo gap-mini-
mising and substring-maximising, while retaining the same
algorithmic complexity as the original algorithm.
3.2.1 Path Selection Through Dynamic Programming
The unmodiﬁed Jacobson-Vo algorithm does not consider
possible alternatives in the selection of each subsequence’s
LCS member. The ﬁrst step therefore is to consider the
choices we have whenever an LCS member in S i−1 is selected
after having selected one in S i. Adding the S1 indices of each
element in Π to the subsequence table (in small type), we
obtain the following:
Observe that while the S2 indices are non-increasing in each
subsequence when reading top-down, the S1 indices are non-
decreasing. This follows from the mechanics of the algo-
rithm:
later insertions appear further down in the subse-
quences and are made using elements further to the right in
Π. Those elements have equal or larger S1 indices.
Assume now that we have just chosen an element ei+1 in
S i+1. Since every element in S i has least one element in
S i−1 that can be chosen as its predecessor, we can pick any
element ei in S i as an LCS member subject to the condition
that I S1
ei+1 since only then does ei
appear before ei+1 in both S1 and S2. Given the opposite
growth directions of the indices in each subsequence in the
table, this means that for each ei+1 there exists a window of
possible predecessors in subsequence i, and, by symmetry,
for each ei there exists a window of possible successors in
subsequence i+1. More formally, the sets of elements Wp(ei)
in the predecessor window of ei and Ws(ei) in its successor
window are deﬁned as follows:
ei+1 and I S2
ei  I S1
ei ∧ I S2
D(ei, e) = min
e0∈Ws(ei)
e > I S2
ˆD(ei, e
ei ∧
0
)˜
The neighbour always resides within Ws, since it is a legiti-
mate successor of ei, all of which are by deﬁnition contained
in Ws. As the elements inside ei’s window are considered,
a direct neighbour can be scored in a way ensures extension
of an existing common substring as opposed to introducing
a gap. Figure 2 illustrates sliding windows with neighbour
tracking.
The introduction of alignment scoring adds signiﬁcant ﬂex-
ibility to the algorithm, since many diﬀerent scoring mod-
els become feasible. Below we show the subsequence table
for the running example, with each visited element’s align-
ment score in the top right corner, showing previous point-
ers where set, and using a scoring scheme that quadratically
favours longer common substrings (by adding the length of
the common substring to the score, for each substring char-
acter) while linearly increasing the score for gaps. Elements
in grey font are outside of the corridor and not considered:
3.2.2 Overcoming Greedy Substring Extension
The algorithm is now gap-minimising if a scoring scheme
favouring common substrings over gaps is used, because such
a scoring scheme will never introduce a gap if it can extend a
Figure 2: Parallel subsequence scanning with slid-
ing windows. As the iteration proceeds over the
left sequence’s elements 107, 97, and 88, the window
of possible successor elements slides downward. The
dotted border indicates the previous window. Along
with the window boundaries, the current element’s
neighbour (shown with lighter background) moves
down as well: while 107 can extend the substring
ending at 118, for 97 and 88 the introduction of a gap
is unavoidable. (The string indices shown are hypo-
thetical and not related to the running example.)
common substring. Whichever path has the least amount of
gaps globally will be the one with the largest overall score.
One problem remains: the greediness of common substring
extension means that a common sequence will always be ex-
tended when possible due to its locally higher score, even
when it would be beneﬁcial to stop a substring and begin
a new one. This situation occurs when one common sub-
string’s suﬃx is a later common substring’s preﬁx.
Thankfully the problem is easy to ﬁx: in addition to tracking
with every element ei the globally best score it obtains by
linking with the best element in S i+1, we now also track
the local score the element has when following the common
substring it is part of through to the end. If this common
substring turns out to be longer than the one it overlaps
with, the local score will eventually exceed the global one
and take its stead. What is left to do is to adjust the back-
pointer that cuts oﬀ the tail of the longer substring back
into the substring.
3.3 Complexity Analysis
The extended Jacobson-Vo is identical to the original one
as far as construction of the subsequence table is concerned.
Clearly the extended variant’s runtime complexity cannot
beat the original algorithm’s O(π log s1), since the latter
does less work. The question is how costly the extension
of the algorithm is. The parallel scanning phase considers
every element in the left subsequence at most once, imply-
ing O(π) additional cost. Na¨ıvely, for each element ei in S i,
every element in Ws(ei) must be considered. This implies
a non-constant amount of additional work per Π element
which would certainly aﬀect the overall runtime complexity
negatively. The following observation comes to the rescue:
unless ei’s neighbour in Ws(ei) is direct, all elements in the
window are going to introduce gaps. In this case, and unless
our alignment model scores diﬀerent gaps diﬀerently, there
is no reason to consider each window member. We only
need to know which window member’s score is best, and up-
date that score according to our scoring schema. This trick
renders the amount of work needed per ei element constant,
since we only need to track the best-scoring node in the win-