title:Compiler-Directed Program-Fault Coverage for Highly Available Java
Internet Services
author:Chen Fu and
Richard P. Martin and
Kiran Nagaraja and
Thu D. Nguyen and
Barbara G. Ryder and
David Wonnacott
Compiler-directed Program-fault Coverage
for Highly Available Java Internet Services∗
Chen Fu, Richard P. Martin, Kiran Nagaraja,
Thu D. Nguyen, Barbara G. Ryder
Department of Computer Science
Rutgers University, Piscataway, NJ 08854
‡
†
David Wonnacott
Department of Computer Science
Haverford College
Haverford, PA 19041
Abstract: We present a new approach that uses compiler-
directed fault-injection for coverage testing of recovery
code in Internet services to evaluate their robustness to op-
erating system and I/O hardware faults. We deﬁne a set
of program-fault coverage metrics that enable quantiﬁca-
tion of Java catch blocks exercised during fault-injection
experiments. We use compiler analyses to instrument appli-
cation code in two ways: to direct fault injection to occur
at appropriate points during execution, and to measure the
resulting coverage. As a proof of concept for these ideas,
we have applied our techniques manually to Mufﬁn, a proxy
server; we obtained a high degree of coverage of catch
blocks, with, on average, 85% of the expected faults per
catch being experienced as caught exceptions.
1
Introduction
Many different approaches to fault injection have been
developed and studied [10, 11, 17, 20, 28], but in a software
engineering context all these efforts suffer from a funda-
mental limitation. Speciﬁcally, they have led to a proba-
bilistic analysis that describes the likelihood that a program
or software component can deliver correct service under
speciﬁc fault and work loads [3], treating the application as
a black box which only can be tested in terms of its observ-
able behavior in response to inputs. While this probabilistic
reasoning is necessary to produce dependable software, it
is not sufﬁcient for software designers and testers to under-
stand how programming constructs, such as methods and
statements, are affected by faults, nor does it ensure exercise
of recovery code. For example, a tester may want to know
how many different operations in the code can be affected
by the same fault and if all these operations have been ex-
ercised through testing. When performing a fault-injection
experiment, the system should allow the tester to know if a
fault triggered an error and consequently the execution of
speciﬁc error detection and handling code. In particular, if
∗
This work was supported in part by NSF grants EIA-0103722 and
EIA-9986046
†
PI:EMAIL
‡{chenfu, knagaraj, rmartin, tdnguyen, ryder}@cs.rutgers.edu
the program reads the disk in many different places, how
can the tester identify all of these vulnerable operations and
test them against appropriate disk faults?
In this paper, we argue that compiler analysis of applica-
tion source or bytecode provides a powerful tool that can be
applied to the problem of increasing the availability of In-
ternet services. In particular, we explore a systematic tech-
nique for using compiler analyses to direct fault injection
and measure the resulting coverage of recovery code. Our
technique is designed to help testers identify faults to which
the software is vulnerable1, identify the location of the vul-
nerabilities in the code, and observe how the software han-
dles the faults when they are injected to test vulnerabili-
ties. Our approach is motivated, in part, by the observation
that infrequently executed code exhibits a higher failure rate
than frequently executed code [18].
We focus on analyzing the ability of software to handle
hardware and operating system faults; we leave the test-
ing of functionality vs.
requirements to traditional test-
ing techniques. We concentrate on I/O hardware faults
since they are much more common than CPU or memory
faults [31, 19]. We also focus on resource exhaustion faults
and faults due to corruption of operating system data struc-
tures by bugs in the operating system. Our approach can be
applied to software components as well as entire programs.
We use compiler analyses to identify code blocks that
are vulnerable to faults, inserting instrumentation that di-
rects the fault-injection infrastructure to inject the appro-
priate faults at these vulnerable operations, and tabulating
coverage according to a metric that will be introduced in
Section 2. In essence, we propose the adoption of what the
software engineering community calls a white box testing
approach [8, 23, 25], where we use the compiler to look
inside of software components to help the tester use a fault-
injection infrastructure to maximal effect. This is similar to
a number of software engineering approaches that examine
1Software is vulnerable to a fault if it performs some operation that can
trigger the fault, leading to an error. For example, an application that uses
the network, but does not use the disk, is vulnerable to network faults, but
not disk faults.
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:06:14 UTC from IEEE Xplore.  Restrictions apply. 
the code to measure test coverage in terms of program con-
structs such as branches, statements and deﬁnitions-uses of
variables [26, 8, 23, 25]; these measures try to quantify how
many of these application constructs have been exercised
by the testing process. In our case, we will concentrate on
services (and/or components) developed in Java, and so the
program constructs of interest are try/catch blocks.
We aim our work at Java-based services for many rea-
sons. First, unlike C where programming convention of-
ten overloads the return mechanism to describe errors, Java
contains well-deﬁned program-level constructs, exceptions,
that respond to error conditions [4]. This facilitates both the
construction and analysis of error recovery. Second, a Java
program which may experience fault-induced errors cannot
be written without inclusion of the appropriate code to han-
dle exceptional conditions. Third, Java is used increasingly
in building large-scale servers. Finally, the platform inde-
pendence of Java, its portable program representation, (i.e.,
bytecode), and its deﬁned JDK [30] libraries all facilitate
software reuse via COTS components.
Contributions: In this paper, we deﬁne the problem of test-
ing Java-based Internet services to improve availability, us-
ing a white box technique. We present our advances over
the current state-of-the-art below.
• We explore the connection between fault injection and
coverage of program-recovery code in a layered sys-
tem, deﬁning the problems that must be addressed;
• We deﬁne a white box coverage metric for testing fault-
• We describe compile-time techniques to automatically
recovery code in Java applications;
instrument Java code to
– direct a fault-injection infrastructure to inject
faults at appropriate points in the execution of
the program to exercise speciﬁc pieces of fault-
recovery code, and
– measure the faults and corresponding recovery
code covered by a given test;
This work includes the deﬁnition of an API for com-
munication between the compiler-inserted instrumen-
tation and the Mendosus [21] fault-injection engine;
• We present a feasibility study in which we have man-
ually instrumented a sample benchmark to test for re-
covery from a set of faults. We achieve 100% coverage
of four of the seven catch blocks where faults were
injected, with an on average fraction per catch of ap-
proximately 85% of the expected faults actually being
experienced as caught exceptions.
Overview: In Section 2, we present our white box deﬁni-
tion of fault coverage. In Section 3 we present our analyses
used to instrument Java applications to measure coverage
In Section 4, we give the results
and direct fault injection.
of our initial test of our approach on a single benchmark,
Mufﬁn, a proxy server. Finally, in Sections 5 and 6, we dis-
cuss related work and give our conclusions.
2 Deﬁning Coverage for Fault-recovery Code
Before giving our deﬁnition of coverage for fault-
recovery code of Java programs, we ﬁrst review prior uses
of the term coverage and discuss the relation between op-
erating system/hardware faults, Java exceptions, and excep-
tion handlers in the application. After this background, we
discuss possible coverage metric choices and give our rea-
sons for selecting the one we use in our experiments. We
conclude this section with a discussion of some issues re-
lated to the measurement of coverage.
2.1 Comparing Deﬁnitions of Coverage
Both the dependability and software engineering com-
munities have precise deﬁnitions for the term coverage;
however, they use this term in very different ways. In the
dependability context, coverage is deﬁned as the conditional
probability that the system properly processes a fault, given
that the speciﬁc fault occurs [9]. Later work included the
assumption that the fault was activated in the probabilistic
deﬁnition [3]. A number of modeling and analysis strategies
naturally arise from this deﬁnition. First, coverage can be
mathematically represented as probability density and cu-
mulative density functions (PDF and CDFs). Second, these
functions can be transformed into probability density over
time and cumulative density over time, leading to a range of
analyses using stochastic process models (e.g., [13]). These
models can describe the impact that coverage has on the ex-
pected time to enter a failure state under a given fault load,
and the amount of redundancy necessary to achieve targeted
levels of availability and performance.
By contrast, the software engineering community uses a
fundamentally different deﬁnition of coverage. In this con-
text, coverage is deﬁned as the fraction of the application
that has been exercised by a given test in terms of speciﬁc
programming constructs including statements and branches.
For example, all-branch coverage ensures that every branch
in a program (e.g., exits from an if statement) is traversed
at least once during testing. Similarly, all-statement cov-
erage guarantees that every statement in the program has
been executed at least once during testing. Another set of
constructs, based on dataﬂow, traces values from their def-
inition point to their subsequent usage, that is, def-use cov-
erage [26]. The all-defs coverage metric requires that tests
cover one path between each value-setting operation and a
use of that value [26]; this is to ensure that errors due to
incorrect ﬂow of data values are handled properly. The all-
defs metric is the traditional dataﬂow metric most closely
related to the new metric we deﬁne for fault coverage in
Section 2.3. A hierarchy of def-use coverage metrics has
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:06:14 UTC from IEEE Xplore.  Restrictions apply. 
been deﬁned; these vary in power, in the sense that one has
more conﬁdence in the correctness of a program tested us-
ing a higher coverage metric than a lower one.
For the remainder of this paper, we call the deﬁnitions
based on conditional probability fault coverage and the soft-
ware engineering deﬁnitions, program coverage. One of our
primary goals in this work is to deﬁne a metric for program
coverage as it relates to faults and fault-recovery code. This
will be called a program-fault coverage metric because it
measures the fraction of the program run in response to a
fault load. Some of the program-fault metrics we deﬁne for
complete applications (see Section 2.3) are reminiscent of
the conditional probability deﬁnitions used in the depend-
ability community, but our metrics describe the coverage of
combinations of recovery-code blocks and fault types, not
the fraction of actual faults that were handled.
2.2 Relating Faults to Exceptions
The software engineering program-coverage metrics are
motivated by a desire to know what parts of the applica-
tion have been explored by the testing process. Since we
are measuring the response of a Java application to faults
that are returned by the operating system or I/O hardware
(e.g., disk or network errors), we focus our attention on Java
exception handling code. The challenge is to map lower-
level faults to program-level exceptions and ﬁnd their cor-
responding program-level exception handlers. In the rest of
this paper we use the terms exception and exception handler
to refer to these program-level constructs.
In order to explore the relations between faults, excep-
tions and exception handlers, we present the following sim-
pliﬁed discussion of Java exception handling. For details,
see [4]. In Java, operations and method calls generally in-
dicate the presence of errors by throwing an exception in-
stead of returning a value. Code that can throw an exception
may be enclosed within a try block with one or more as-
sociated catch blocks, each of which identiﬁes the type of
exception it can handle. If an operation in the try block
throws an exception, program control is transferred directly
to a catch block with matching exception type. Java’s sub-
typing rules can be used to write catch blocks that will be
triggered by multiple types of exceptions; a catch (Ex-
ception e) matches any type of thrown exception.
For example, a programmer may enclose a sequence of
operations that read from a ﬁle within a try block that has
an associated catch of IOException (or a more general
catch of Exception) containing code to recover from ﬁle
read errors. If any of the read operations encounters an error
and throws IOException, the program will go directly to
that catch block.
Exception handling code may be located either in the
method performing a vulnerable operation or in some
method that directly (or indirectly) calls this method. When
an exception is thrown, the JVM searches for an appropriate
catch, beginning in the method performing the throw, and,
if necessary, working “backwards” to a caller method con-
taining the handling code. All of the exceptions we discuss
are classiﬁed by Java as checked exceptions, meaning that
methods that contain vulnerable operations that may trigger
these exceptions, need either to handle them or to pass them
explicitly “backwards” to a caller to handle [4]2.
A Java operation may be vulnerable to a variety of faults,
and the exception generated may depend on both the fault
and the operation. For example, reads and writes ex-
posed to faults that produce the operating system error code
NET EAGAIN may cause different exceptions (namely,
IOException and SocketException). In contrast, the
error codes NET EPIPE and NET EFAULT can both re-
sult in SocketException. (See Section 4 for more details
on speciﬁc faults.) So the relation between faults and excep-
tions can be one-to-many or many-to-one. There is gener-
ally a unique Java exception for any speciﬁc fault-operation
pair, but our approach does not rely on this fact.
Our techniques make use of a table mapping fault-
operation pairs to (one or more) exceptions. Unfortunately,
the construction and use of this table are complicated by the
layers of software between the hardware and the application
being tested (such as device drivers, the operating system,
and the Java Virtual Machine (JVM)). These layers can have
a dramatic impact the way in which low-level faults trans-
late into exceptions at the program level.
In the simplest case, a fault can cause an immediate ex-
ception, and thus direct control to the appropriate catch
block for a vulnerable operation that was executed while
the fault was activated.
In some cases, recovery strategies at a lower level of
the system can entirely prevent a higher-level layer from