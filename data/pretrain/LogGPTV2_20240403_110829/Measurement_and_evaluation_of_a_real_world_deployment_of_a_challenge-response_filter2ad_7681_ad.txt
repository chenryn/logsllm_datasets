mic scale in Figure 11, shows that while most of the servers
had no problem at all with blacklisting, some of them were
often blacklisted, even for a few days in a row. However,
there seems to be no relationship between the server black-
listing ratio and the number of challenges it sends.
The main problem with this approach is that the error
messages received when delivering the challenges were not
always very accurate, providing results that may not be
completely reliable. Therefore, we decided to complement
our analysis with a second technique, based on an auto-
mated script that periodically checked for the IP addresses
of the CR servers in a number of services that provide an IP
blacklist for spam ﬁltering. In particular, our tool queried
the blacklists provided by Barracuda [1], SpamCop [10],
SpamHause [11], Cannibal [9], Orbit [4], SORBS [7], CBL [3],
and Surriel [5]. The queries were performed every 4 hours for
a period of 132 days (between September 2010 and January
2011).
The results of this second analysis conﬁrm our previous
ﬁnding. In more than four months, 75% of the servers never
appeared in any blacklists. Few servers were blacklisted for
less than one day, while the remaining four servers experi-
enced some serious problems, appearing in at least one of the
blacklists for many consecutive days (17, 33, 113, and 129
respectively). Again, between the top 3 server (according to
the traﬃc and the number of challenges sent) none appeared
421In the rest of this section we summarize the main ﬁndings
we presented in the previous three sections.
Whitelist Assumptions
All approaches based on white-lists share two main assump-
tions: ﬁrst, that the large majority of the “good” emails
come from senders already in the recipient’s whitelist, and,
second, that these lists eventually reach a steady state where
changes do not occur very often.
Both claims are supported by our experiments. In fact,
over 43 companies, only 2/33 = 6.1% of the incoming emails
delivered to the users’ INBOX require a challenge-response
phase (see Figure 4) and 2% require the user to manually
pick the message from the digest.
The stability of the whitelists was already evaluated by
Erickson et al. [21], showing that the major burden on the
user is concentrated in the ﬁrst three weeks, after which
the number of changes drops on average to one per day.
Our experiments show that, in a real deployment, there are
on average 0.3 new entry per user per day (excluding new
users). Only 6.8% of the users had at least one daily change
in their whitelists.
Delivery Delay
Another common critique of CR systems is due to the fact
that the challenge-response step introduces a delay in the
incoming email delivery. This is obviously an unavoidable
side-eﬀect, but our measurements show that it also has a
limited impact. In fact, according to our study, it concerns
only 4.3% of incoming emails and in half of the cases the
delay is below 30 minutes. Even though the remaining 2.15%
may still be an unacceptable inconvenient for certain users,
we believe that for most of the users it would be a reasonable
price to pay to protect against spam.
Challenge Trafﬁc
Most of the criticisms against CR systems, and most of the
hassles for the system administrators, come from the chal-
lenges that are sent to the wrong recipients. If they corre-
spond to existing email accounts, the misdirected challenges
become a spam for other users. On the other hand, if the
addresses do not exist, the challange may hit a spamtrap.
And on top of that, they constitute useless traﬃc over the
Internet.
Our study shows that, on average, a CR system sends back
one challenge for every 21 emails it receives (see Section 3),
accounting for a traﬃc increase of less than 1%. These ﬁg-
ures depend on the amount of spam received by the server,
and seems to be more or less constant between small and
large servers.
Unfortunately, the large part of the challenges sent are
indeed useless (only about 5% of them are solved). But,
as we already explained in the paper, these challenges are
“required” to justify the system.
In other words, without
useless challenges, it would be the CR system to be useless.
Therefore, this can be considered an intrinsic and unavoid-
able limitation of systems based on a challenge-response ap-
proach.
Our ﬁndings conﬁrm that the backscattered phenomenon
is the main problem of solutions based on challenge-response
technique. Each installation must be carefully conﬁgured
in order to minimize the impact of misdirected challenges
on other real users. The administrator also has to decide
Figure 12: SPF validation test
in any of the blacklists during our experiment. Thus, prov-
ing again that there is no direct link between the number of
times a server gets blacklisted and the server size.
5.2 Combining CR Systems with Other Spam
Filters
Our ﬁnal evaluation focuses on the combination of CR
systems with other antispam solutions. As we already men-
tioned in Section 2, the product we analyzed in our exper-
iments includes three other spam ﬁlters in order to reduce
the number of useless challenges sent in response to spam
messages.
It employs a traditional antivirus to scan the
emails, an IP blacklist provided by SpamHause [11] to ﬁlter
out known spammers, and a reverse DNS lookup to exclude
suspicious origins.
According to Table 1 and Figure 1, the combination of
these ﬁlters was responsible for dropping 77.5% of the mes-
sages in the gray spool. One may argue if this is good
enough, or if a much better result could be obtained by
introducing other antispam techniques. This is a diﬃcult
question to answer, since the main drawback of adding new
ﬁlters is that they also introduce false positives, to avoid
which CR systems were introduced in the ﬁrst place.
However, we decided to experiment with one additional
spam ﬁlter based on the veriﬁcation of the Sender Policy
Frawework [36] (SPF). SPF was introduced to detect source
address spooﬁng, that is one of the main problems of CR
systems. Since SPF checks were not included in the product
we evaluated in this paper, we decided to evaluate the poten-
tial impact of this ﬁlter by using an oﬄine tool to automat-
ically test all the emails in the gray spool. Figure 12 shows
the results of our experiment, grouped by diﬀerent message
categories. For instance, by dropping the emails for which
the SPF test fails, it would be possible to reduce by almost
9% the challenges that cannot be delivered (expired), and
4.10% of the bounced ones. The overall result shows that
SPF can further reduce the number of “bad” challenges by
2.5%, at the cost of loosing 0.25% of the challenges that are
actually solved by the sender.
6. DISCUSSION
Even though the aim of this work is neither to attack nor
to defend challenge-response systems, it may be natural to
ask what conclusions about this class of antispam solutions
could be drawn from our measurements.
422which other additional antispam techniques should be com-
bined with the CR ﬁlter to maximize the beneﬁts and, at
the same time, to reduce the side eﬀects and the risk of
having the servers’ IP blacklisted. However, the backscat-
tered phenomenon is intrinsic in the behavior of a CR system
and cannot be completely eliminated. From a company, the
single most negative argument against the adoption of CR
system is the fact that the challenge server can occasionally
get blacklisted. Even worse, an attacker could intentionally
forge malicious messages with the goal of forcing the server
to send back the challenge to spam trap addresses, thus in-
creasing the likelihood of getting the server IP added to one
or more blacklist.
Other Limitations
This paper does not cover all aspects related to the adoption
of a challenge-response system. We focused on performing
a set of measurements based on real installations that were
not under our direct control. Therefore, we intentionally
excluded from our studies any evaluation of potential attacks
against CR systems (like trying to spoof the sender address
using a likely-whitelisted address).
In addition, in order to protect the users and the compa-
nies’ privacy, we limited our study to the statistical informa-
tion that can be automatically extracted from the headers
of the messages. This ruled out other potentially interesting
experiments that would have required access to the email
bodies.
7. RELATED WORK
Most of the spam blocking techniques proposed by pre-
vious research fall into two categories: content-based and
sender-based ﬁltering. Content-based spam ﬁltering tech-
niques rely on signatures and classiﬁcation algorithms ap-
plied to the emails content [32, 14, 19, 15, 33]. Although
content-based ﬁlters were initially very eﬀective and pro-
vided an acceptable defense against spam [27], with the evo-
lution of the spam sophistication they became less eﬀective
over time.
Sender-based spam ﬁltering techniques aim instead at block-
ing spams by analyzing information about the sender. To
date, a wide range of sender-based ﬁltering solutions has
been proposed, including sender authentication (e.g., SPF [36],
DMIK [18], and Occam [22]), sender IP reputation [11],
network-level feature categorization, sender whitelisting, and
detecting anomalies on the sender’s behavior.
Sender authentication techniques authenticate the sender
either by verifying it’s domain [36, 18] or by providing a pro-
tocol to authenticate the server at each message delivery [22].
These kind of solutions are quite eﬀective to prevent email
spooﬁng, a phenomenon that is very common among spam-
mers.
Approaches based on IP reputation [11, 25] rely on whitelists
or/and blacklists of IP addresses that are known either to
send spam or to be a trusted source. Therefore, these ap-
proaches are eﬀective against static spammers and open-
relay servers used for spam distribution. On the other hand,
they are not able to provide the same degree of protection
against spam sent through botnets, since botnets can change
the sender’s IP address by using a large number of diﬀerent
infected machines to deliver the messages.
Behavior-based solutions, like the ones proposed by Pathak
et al. [30] or Ramachandran et al. [31], and network-level de-
tection techniques, like the one proposed by Hao et al. [24],
tend to react faster to spam campaigns and have a lower
number of false-positive. However, these kind of solutions
block only part of illegitimate emails, and, therefore, they
have to be used in combination with other ﬁlters.
Beside the more common techniques presented so far, a
number of other solutions have been proposed to protect
users against spam. For example, ﬁne-grained approaches
have been proposed based on personal white and blacklists.
The assumption behind such techniques is that users com-
municate mainly with a list of contacts that does not change
much over time [16, 20, 21].
In this case, the main problem is to provide an automated
way to populate and maintain the users whitelist. Garris et.
al. [23] proposed a solution to this problem based on the idea
of sharing the whitelist content with the user’s friends on so-
cial networks. Their cryptographic solution addresses also
the sender spooﬁng problem, and the protection of the pri-
vacy of the users during the friend list sharing process. The
main limitation of their system is the fact that it requires a
large-scale adoption by many social networking users.
One of the most wide-spread approaches for building and
maintaining a list of trusted senders is based on the adoption
of a challenge-response technique [28, 29, 8, 12, 6], already
largely described in the rest of the paper.
Although challenge-response schemes are extremely suc-
cessful in blocking spam, they also have a number of lim-
itations that makes them disadvantageous over other so-
lutions [21]. Additionally, CR solutions received a great
amount of critiques from the anti-spam community [13, 2],
often because of the amount of challenge emails they gener-
ate.
To the best of our knowledge, the only empirical study
that analyzes challenge-response based whitelisting systems
is presented by Erickson et.al. [21]. The authors focus on
the deployment and the usability of such systems. The re-
sults of their evaluation support the usability of CR systems,
but also show their limitations in coping with automatically
generated legitimate emails, such as newsletters and noti-
ﬁcations. On the other hand, the authors concluded that
challenge-response systems are very successful to prevent
spam and have lower false positives and false negatives rates
compared to traditional content ﬁltering techniques like Spa-
mAssassin.
Our work aims instead to present a comprehensive study
of a real-world whitelisting challenge-response antispam sys-
tem, evaluating it’s eﬀectiveness and it’s impact on the end-
users, Internet, and server administration.
8. CONCLUSIONS
In this paper we present the ﬁrst measurement study of
the behavior of a real world deployment of a challenge-
response antispam system. The experiments lasted for a
period of six months, covering 47 diﬀerent companies pro-
tected by a commercial CR solution.
In particular, we measure the amount of challenges gen-
erated by these systems and their impact in terms of traﬃc
pollution and possible backscattered messages delivered to
innocent users. We then measure the amount of emails that
are delayed due to the quarantine phase, and the amount of
spam that is able to pass through the ﬁlter and reach the
users mailboxes. Finally, we focus on a problem that is less
known, i.e., the fact that the invitations sent by these sys-
423ACM SIGCOMM Conference on Internet
measurement, pages 370–375. ACM, 2004.
[26] C. Kanich, C. Kreibich, K. Levchenko, B. Enright,
G. Voelker, V. Paxson, and S. Savage. Spamalytics:
An empirical analysis of spam marketing conversion.
In Proceedings of the 15th ACM conference on
Computer and communications security, pages 3–14.
ACM, 2008.
[27] D. Lowd and C. Meek. Good word attacks on
statistical spam ﬁlters. In Proc. of the second
conference on email and anti-spam (CEAS), pages
125–132, 2005.
[28] R. Mastaler. Tagged message delivery agent.
http://www.tmda.net/.
[29] M. Paganini. ASK: active spam killer. In Proc. 2003
Usenix Annual Technical Conference, 2003.
[30] A. Pathak, Y. Hu, and Z. Mao. Peeking into spammer
behavior from a unique vantage point. In Proc. of the
1st Usenix Workshop on Large-Scale Exploits and
Emergent Threats, pages 1–9. USENIX Association,
2008.
[31] A. Ramachandran, N. Feamster, and S. Vempala.
Filtering spam with behavioral blacklisting. In Proc.
of the 14th ACM conference on computer and
communications security, pages 342–351. ACM, 2007.