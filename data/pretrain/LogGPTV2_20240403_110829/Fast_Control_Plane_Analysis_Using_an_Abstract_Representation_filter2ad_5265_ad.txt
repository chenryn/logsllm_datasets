to generate counter-examples when violations occur. These
help an operator take corrective actions before a buggy con-
trol plane is made “live” on the network.
5.1 Verifying Security/Availability
Invariants I1–I4 in Table 1 can be expressed as graph
characteristics that can be computed on a pathset-equivalent
ETG using polynomial-time graph algorithms.
I1: Always blocked. For security reasons, an operator may
want to ensure that a particular trafﬁc class is always blocked.
For this to be true under arbitrary failure scenarios, there
must not exist a path from src-node to dst-node in the traf-
ﬁc class’s ETG. We can check for the existence of a path by
traversing (e.g., depth-ﬁrst or breadth-ﬁrst) the ETG starting
from src-node. If dst-node remains unvisited, then the prop-
erty holds. Otherwise, assuming the ETG is path-equivalent,
we provide the shortest path as a counterexample.
I2: Always reachable with < k failures. To improve avail-
ability, an operator may want to ensure that a particular desti-
nation d can always be reached from a particular source s as
long as there are fewer than k link failures in the network. To
verify this, we can leverage properties of graph cuts. In par-
ticular, according to Menger’s Theorem, the maximum num-
ber of edge-disjoint paths from s to d in a digraph equals the
minimum number of edges whose removal separates s and
d [3]. Thus, as long as the ETG has at least k edge-disjoint
paths from s to d, d will always be reachable from s.
Finding the number of edge-disjoint paths in an arbitrary
acyclic digraph is NP-Complete [22], but in a unit-weight
graph the problem reduces to computing the max-ﬂow/min-
cut. Because we are only concerned with the presence of
paths, and not which paths are chosen under speciﬁc failures,
we can safely convert the weight of all inter-device edges in
the ETG to 1 and the weight of intra-device edges to ∞. We
set the weight of intra-device edges to ∞, because we are
only concerned with counting physical-link-disjoint paths,
not device-disjoint paths, and a weight of ∞ allows multiple
physical-link-disjoint paths to traverse the same device. We
compute the max-ﬂow/min-cut on the ETG with modiﬁed
weights to identify the number of edge-disjoint paths. When
the max-ﬂow is ≥ k + 1, the invariant is satisﬁed.
When the invariant is violated, we produce a counter-exam-
ple set of edges that form a cut of size ≤ k.
I3: Always isolated. For security or performance reasons,
an operator may want to ensure that two disjoint trafﬁc classes
(s1→d1 and s2→d2; s1 6= s2, d1 6= d2) can never simul-
taneously traverse the same link. Thus, the preferred path
for s1→d1 must never overlap with the preferred path for
s2→d2 under any scenario. Such overlap is possible in some
scenario if the ETG for s1→d1 has an edge in common with
the ETG for s2→d2. An extreme scenario is where all links
have failed except those used in paths that contain the com-
mon edge. The trafﬁc isolation invariant is guaranteed to
hold only if the ETGs for the two trafﬁc classes do not have
any edges in common, a property we can easily check.
ETGs constructed using our algorithm in §4.2 are com-
plete, so they do not contain extra paths. However, the ETGs
may still contain “dead-ends”—i.e., extra edges and vertices
that are never part of any path from SRC to DST. Dead-ends
arise because: (i) we do not add intra-device edges between
vertices associated with different processes unless one pro-
cess has a lower AD than the other or one process redis-
tributes routes into the other, and (ii) we remove edges to
account for ACLs and route ﬁlters (§4.2). When an ETG
contains extra edges, we will inadvertently claim that two
trafﬁc classes are not always isolated, when in reality the ex-
tra edges are not part of any path from SRC to DST and hence
have no bearing on trafﬁc isolation. Thus, prior to checking
this property, we recursively remove all vertices (excluding
SRC and DST) whose in- or out-degree is 0; these vertices
are dead-ends. When removing such vertices, we also re-
move their incident edges.
If the pruned ETGs have any edges in common, we return
the set of common edges as a counter-example.
I4: Always traverse a waypoint. When a network includes
middleboxes, such as ﬁrewalls, an operator may want to en-
sure that trafﬁc always traverses some instance of the mid-
dlebox (i.e., a waypoint) under arbitrary failure scenarios.
To verify this, we augment the ETG to include special ver-
tices that represent waypoints. Then we remove all waypoint
nodes from the ETG and check if there exists a path from
src-node to dst-node. If such a path exists, then there is some
path that may be taken by the trafﬁc that does not traverse a
waypoint; we return this path as a counterexample.
Other invariants. Other important security and availabil-
ity invariants can also be veriﬁed by computing graph-level
attributes on the ARC. For example, we can verify trafﬁc “al-
ways traverses a chain of waypoints” by removing the ver-
tices associated with one type of waypoint at a time, and
checking if there exists a path from a vertex associated with
one of the preceding waypoints in the chain to a vertex asso-
ciated with one of the following waypoints in the chain. We
can verify forwarding of particular trafﬁc class is “always
loop free” by checking that the ETG does not have a cycle
containing a static route vertex and one or more vertices as-
sociated with processes in the same routing instances. We
omit details for brevity.
5.2 Equivalence Testing
Invariant I5, equivalence, differs from the other invari-
ants in three respects: (1) equivalence testing involves mul-
tiple ARCs; (2) it requires path-equivalent ARCs, because
the actual paths taken in the network are the attributes un-
der scrutiny; and (3) it is implemented by comparing ETGs,
rather than computing graph characteristics of ETGs. How-
ever, prior to comparing the ETGs from different ARCs, we
must make two transformations to the ETGs.
Convert process-based ETGs to interface-based ETGs.
Modeling forwarding behavior at the level of routing pro-
cesses (§4.2) prevents us from determining if any two con-
trol planes are equivalent, because the two control planes
may use a different set of routing instances, causing their
ETGs to contain a different set of vertices and edges. To
address this issue, we convert our process-based ETGs into
309
Src:U 
0 
0 
I 
2 
B 
I 
1 
B 
1 
O 
1 
C 
O 
2 
C 
3 
1 
0 
0 
0 
0 
Dst:T 
0 
I 
1 
D 
0 
I 
2 
D 
0  0 
1 
O 
2 
B 
O 
1 
B 
1 
I 
1 
C 
I 
2 
C 
3 
O 
1 
D 
O 
2 
D 
Figure 4: Part of the interface-based ARC for the example
control plane in Figure 2a
interface-based ETGs, which depends only on the physical
network topology, not the routing processes running atop it.
As an example, Figure 4 shows the transformed ETG that
corresponds to the upper-left ETG in Figure 2b. Our conver-
sion process assumes each interface is used by at most one
routing process to send/receive route advertisements; this is
common practice in data center and enterprise networks, in-
cluding those we study (§7.1).
In particular, we take the following steps:
1. Replace each process’s in and out vertices with an in and
out vertex for each physical interface over which the pro-
cess sends/receives route advertisements. We identify in-
terfaces on which a routing process operates based on
overlap between the IP addresses assigned to interfaces
and the networks (for OSPF and RIP) and neighbors (for
eBGP) speciﬁed in the router stanzas in device con-
ﬁgurations. For example, BI and BO in Figure 2b are
replaced with vertices BI
2 in Figure 4.
2. Replace the inter-device edges that used to connect the
out vertex of a process P on one device to the in vertex
of a process P ′ on another device with an edge connect-
ing the out vertex of the interface over which P sends
advertisements to P ′ to the in vertex of the interface over
which P ′ receives advertisements from P . For example,
the edge BO → DI in Figure 2b is replaced with the
edge BO
2, because the second interface on router
B is connected to the second interface on router D.8
2 , and BO
2 → DI
1 , BO
1 , BI
3. Replace the intra-device edge E that used to connect a
routing process’s in and out vertices by a set of edges
that connect the in vertex of each interface associated
with the process to the out vertex of every interface as-
sociated with the process. The edge weight is the same
as the edge weight that was assigned to E. Note that an
edge is not created between the in and out vertices of the
same interface, because a router will never send trafﬁc
out the same interface on which it arrived. For example,
the edge BI → BO in Figure 2b is replaced with the
edges BI
1 in Figure 4.
2 and BI
1 → BO
2 → BO
4. For each intra-device edge that connected the in vertex of
a routing process P to the out vertex of another routing
process P ′, create an intra-device edge from the in ver-
tex associated with each of P ’s interfaces to the out ver-
tices associated with P ′’s interfaces; again, the weight
of these edges is the same as the weight of the original
edge. (No such edges exist in Figure 2b.)
An ARC constructed in this manner represents a network’s
routing behavior with the same ﬁdelity as the ARC described
8We assume interfaces corresponding to the inter-router
links in Figure 2a are numbered clockwise for each router.
310
earlier, because it captures the exact same pathways between
routers (no inter-device edges are added), and models at a
ﬁne granularity the same software pathways within routers.
Convert edge weights to canonical weights. There are in-
ﬁnitely many ARCs that differ only in the scale of their edge
weights. All of these will produce the same data plane un-
der all failure scenarios, and hence are equivalent. To ensure
we can detect such equivalence, we must reduce all edge
weights to canonical weights. In other words, we compute
the lowest possible weight for every edge in every ETG in
the ARC such that the relative order of all possible loop-
free paths between src-node and dst-node in each ETG is the
same as using the original weights. We can perform such a
reduction using a linear program; details are included in our
technical report [11].
After applying the above transformations, we can test the
equivalence of two control planes by checking whether their
ARCs have the same vertices, edges, and edge weights. This
is facilitated by the fact that vertices are always named based
on the device interfaces to which they pertain. Thus, vertices
and their incident edges can be easily matched across ARCs.
6.
IMPLEMENTATION
We implemented the ARC generation process described
in §4 and the veriﬁcation tasks described in §5.1 in Java.
We use Batﬁsh [9] to parse Cisco IOS conﬁgurations. From
these, we extract trafﬁc classes and generate ETGs. We
use JGraphT [2] to apply common graph algorithms (Dijsk-
tra’s shortest path, max-ﬂow/min-cut, etc.) to the generated
ETGs and obtain the information required to verify a partic-
ular property. Our tool outputs the results of the requested
veriﬁcation for all of a network’s ﬂows. Our code is open
source [1], so operators can apply it to their own networks.
7. EVALUATION
We now evaluate ARC along two different dimensions:
(1) How efﬁciently can we represent real network control
planes using ARC? (2) How quickly can we verify key in-
variants using ARC? How does this compare to state-of-the-
art control plane veriﬁcation tools (e.g., Batﬁsh [9])?
We generate ARCs and verify invariants using a machine
with a quad-core Intel Xeon 2.8GHz CPU and 24GB of RAM.
7.1 Network Characteristics
In our evaluation we use conﬁgurations from 314 data
center networks operated by a large OSP. These networks
have between two and a few tens of routers connected using
between one and several tens of physical links (Figure 5a).
Two-thirds of the networks have a single routing process
on each device, while the remaining third have two processes
per device on average (ignoring static routes). Similarly,
two-thirds of the networks have a single routing instance,
while the rest have a handful of instances (Figure 5a). As
shown in Table 3, only two routing protocols are used—
OSPF (37% of networks) and eBGP (all networks)—along
with static routes (27% of networks). Only one network has
OSPF processes that use multiple areas, and only 10 net-
O(10)
●
t
n
u
o
C
0
D evices
Processes
Links
Insta nces
1.0
0.8
F
D
C
0.6
0.4
0.2
0.0
0
5
1
0
0
1
0
5
0
s
e
c
i
t
r
e
V
f
o
r
e
b
m
u
N
●
●
●
●
●
●
●
●
●
●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●
●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●
●●●●●●●●●●
0
0
2
0
0
1
0
5
0
s
e
g
d
E
f
o
r
e
b
m
u
N
●
●
●
●●●●
●
●
●
●●
●
●
●
●
●
●
●
●
●●●●●●●●●●●●●●
●
●
●●
●●
●
●●
●●●●●●●●●●●●●
●●●●
●●●●●●●●●●●●
●
●
●●
●
●
●
●
●●●●●●●●●●
●●●●●●●●●●●●
●●●●●●●●●●●●●●●
●
●
●●
●
●●●●●●●●●
●●●●
●●●●●●●
●
●●●●
●
●
●●●●●
●
●
●●●●
●
●●
●
●
●●
●●
●
●●
●●
●
●●●
●
●
●●
●
●
●●●●●●●●●
●●●●●●●●●●●●●
●
●●
●●
●●
●●
●
●●●●
●●●
●●●
●●●●
●
●
●
●●●●