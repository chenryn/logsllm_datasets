All = caching + gzip (lv 5) + delta + MODP (for all trafﬁc). n and p are MODP parameters.
with no loss. In that ideal case, the CR decreases by about 1% due to the eliminated
retransmission overhead of reference packets, implying that the impact of packet loss
observed in the ﬁve-month dataset on CR is small.
5.3 Combining Multiple Approaches
We now apply multiple RE techniques together by following the order described
in §5.1. The left seven columns in Table 4 indicate that jointly employing caching,
ﬁle compression, and delta encoding is beneﬁcial in that it reduces the CR to as low as
70.1% (for HTTP trafﬁc) and 74.5% (for all trafﬁc). Caching and ﬁle compression are
complementary schemes: the former makes trafﬁc due to multiple requests of the same
ﬁle more efﬁcient, while the latter improves the efﬁciency of a single ﬁle transfer.
Figure 1 plots the CR distribution (for all trafﬁc) across the 20 users, assuming
caching, gzip (lv 5), and delta encoding are jointly used. The CR for each user ranges
from 34% to 89%, implying the heterogeneity of trafﬁc generated by diverse users (§3).
Clearly, the effectiveness of RE techniques depends on trafﬁc content that differs across
users, but the incurred bandwidth savings are unanimously non-trivial (> 10%).
We then take a further step by applying MODP in addition to the three object-based
RE techniques. By further looking at the right four columns in Table 4, we learn the
additional CR reduction due to MODP is non-trivial (ranging from 5.4% to 7.2%)
but is much smaller than the saving brought by using MODP alone (21.0% to 29.8%
as depicted in Table 3). This implies that object-based RE techniques have already
eliminated most redundancies for the HTTP trafﬁc that dominates the trace. In fact,
MODP further reduces the HTTP trafﬁc volume by 6.2% to 7.8%, most of which comes
from cross-ﬁle redundancy of non-cacheable ﬁles. In contrast, MODP results in much
more reduction of CR for non-HTTP trafﬁc, between 16.1% and 21.7%.
5.4 Performance
We measure the performance of each RE technique on a real server and a smartphone
device. Our equipment includes a Dell PowerEdge server with an Intel Xeon E5620
quad-core CPU at 2.4 GHz and a Motorola Atrix 4G smartphone with a Tegra 2 dual-
core CPU at 1 GHz. The server ran Ubuntu 11.04 and the phone used Android 2.2.
Two Macro-benchmarks were employed to evaluate the ﬁle compression and the
packet stream compression technique, respectively. The ﬁle benchmark consisted of
1000 HTTP responses randomly sampled from the dataset. The packet stream bench-
mark was a 2GB packet trace generated by a random user. We produced ﬁve instances
50
F. Qian et al.
Table 5. Throughput (in Mbps) of object-based RE techniques on the File Benchmark
gzip (level 1 – 9) bzip2 (level 1 – 9) 7-zip (level 1 – 9) VCDIFF (δ 10%–90%)
comp decomp comp
Server 80–132 380–392 24–25
Phone 19–37 223–231 5.2–5.6
decomp
479–808
231–392
decomp
57–60
18–21
comp
14–17
4.4–5.4
decomp
20–20
10–10
comp
5.4–5.5
1.9–1.9
Table 6. Throughput (in Mbps) of MODP on the Packet Stream Benchmark
Compress n=128k p=1/16 n=64k p=1/32 Decompress n=128k p=1/16 n=64k p=1/32
Server
Phone
19
4.2
41
8.9
Server
Phone
320
40
348
41
of this benchmark, all yielding very similar performance results. We report the results
for one instance.
We measured the in-memory compression/decompression time (excluding disk I/O)
for the two benchmarks on both the server and the phone, using binaries compiled from
the same source code. Table 5 shows the results for the ﬁle benchmark. Each ﬁle was
compressed (decompressed) separately and the measured throughput is the total ﬁle
size divided by the sum of the processing time of all ﬁles. For VCDIFF, we artiﬁcially
generated a previous version of each ﬁle by randomly changing its content by a ﬁxed
percentage of δ. Table 6 summarizes the packet stream benchmark results. We measured
the processing time of the second-half data of the 2GB packet trace, whose ﬁrst-half
data of 1GB was used to ﬁll the packet cache and the signature table (for compression).
Changing this 1GB to 0.5GB or 1.5GB has negligible impact on the results.
In Table 5 and Table 6, the throughput was estimated in an extreme case where
the data was fed into the compressor/decompressor as fast as possible without any
interruption. We repeated each test 10 times and measured the average running time,
from which we derived the throughput value. The standard deviation of the running
time across 10 runs was always less than 2% of the average.
The benchmark results deliver several observations. (i) As expected, compression
is slower than decompression. But compressed ﬁles can be cached by servers to avoid
having to repeat the compression for each incoming request for the same ﬁle. (ii) gzip
is much faster than the more sophisticated bzip2 and 7-zip (for both compression and
decompression) while its achieved CR is only slightly higher for small ﬁles from which
most beneﬁts of compression come (§5.2). (iii) VCDIFF is more expensive than all three
ﬁle compression techniques, because it involves heavy computation for comparing two
versions of a ﬁle. (iv) For gzip, bzip2, VCDIFF, and MODP, their low decompression
overheads make it possible to keep up with a high data rate (e.g., 15Mbps), incurring
very small impact on page processing/rendering time on a handset. (v) MODP is quite
efﬁcient for small n and p. Exponentially increasing n and p worsens the performance
(not shown in Table 6), and doing so provides little additional trafﬁc savings when
object-based RE is performed beforehand (Table 4). The performance could be further
improved by enhancements of MODP, such as MAXP and SAMPLEBYTE [5].
How to Reduce Smartphone Trafﬁc Volume by 30%?
51
6 Summary and Recommendations
We summarize our main ﬁndings and recommendations as follows.
1. Under-utilization of compression contributes to signiﬁcant redundancy, i.e., 15%
of the overall trafﬁc volume for our trace. It is imperative that the content providers
utilize the compression feature supported by all mainstream Web servers. Handsets
should use the Accept-Encoding header ﬁeld, which appeared in only 40% of HTTP
requests within the dataset, to enable compression.
2. Considering both effectiveness and performance, gzip is the best compression
approach for small ﬁles from which most beneﬁts of compression come (yet the
trafﬁc volume contribution of such small ﬁles is considerable, see §5.2). Applying
delta encoding on non-trivial cases (§5.2) brings limited beneﬁts, because less than
5% of HTTP bytes belong to ﬁles with a different previous version. Except for 7-zip,
decompression performance is generally not an issue on mobile devices, leading to very
small impact on page processing/rendering time.
3. Special emphasis should be put on html, xml, javascript, and css ﬁles. They
account for 15% of the HTTP trafﬁc in the dataset (17% reported in [12] for hand-
held trafﬁc in campus Wi-Fi networks), but are usually (58% to 98% bytewise) not
compressed. More than 70% of their bytes can be saved using compression.
4. Using packet stream compression alone, represented by the MODP algorithm,
effectively reduces the trafﬁc volume by up to 30%. If object-based RE techniques,
which are already part of the HTTP speciﬁcation, are applied beforehand, the beneﬁt of
MODP decreases but is still non-trivial, i.e., a reduction of 5.4% to 7.2% of all trafﬁc.
In that case, the impact of the aggressiveness level on CR is much less signiﬁcant.
We therefore recommend that MODP be deployed in a less aggressive manner, e.g.,
n≤64k packets and p≤1/16 for downlink. This achieves most of the bandwidth savings
possible from MODP while limiting the performance overhead for compression as
well as decompression. Note that packet stream compression provides beneﬁts despite
idiosyncrasies in application implementations.
5. A judicious combination of all RE techniques achieves an overall reduction of
the smartphone trafﬁc studied in this measurement by more than 30% with acceptable
computational overhead. This is even more interesting and somewhat surprising given
that a major fraction of the trafﬁc is video, audio, or image that are already compressed.
In comparison, caching by itself only saves 17% of the overall trafﬁc (§5.2).
Acknowledgements. This work is partly funded by NSF grants CNS-1059372, CNS-
1050157, CNS-1039657 and Navy grant N00014-09-1-0705. We thank Emir Halepovic
and the shepherd Marios Iliofotou for their valuable comments on the paper. We would
also like to thank anonymous reviewers whose comments improved the ﬁnal version.
References
1. Invest in Cell Phone Infrastructure for Growth in 2010 (2010), http://pennysleuth.
com/invest-in-cell-phone-infrastructure-for-growth-in-2010/
2. Packet Data Convergence Protocol (PDCP) speciﬁcation. 3GPP TS 25.323
52
F. Qian et al.
3. SPDY: An experimental protocol for faster web, http:// dev. chromium. org/
spdy
4. Cisco Visual Networking Index (2012),
http:// newsroom. cisco. com/
press-release-content? type=webcontent& articleId=668380
5. Aggarwal, B., Akella, A., Anand, A., Balachandran, A., Chitnis, P., Muthukrishnan, C.,
Ramjee, R., Varghese, G.: EndRE: An End-System Redundancy Elimination Service for
Enterprises. In: NSDI (2010)
6. Anand, A., Gupta, A., Akella, A., Seshan, S., Shenker, S.: Packet Caches on Routers: The
Implications of Universal Redundant Trafﬁc Elimination. In: SIGCOMM (2008)
7. Anand, A., Sekar, V., Akella, A.: SmartRE: An Architecture for Coordinated Network-wide
Redundancy Elimination. In: SIGCOMM (2009)
8. Anand, A., Muthukrishnan, C., Ramjee, R.: Redundancy in Network Trafﬁc: Findings and
Implications. In: SIGMETRICS (2009)
9. Deutsch, P.: DEFLATE Compressed Data Format Speciﬁcation version 1.3. RFC 1951
(1996)
10. Erman, J., Gerber, A., Hajiaghayi, M., Pei, D., Sen, S., Spatscheck, O.: To Cache or not to
Cache: The 3G case. IEEE Internet Computing (2011)
11. Fielding, R., Gettys, J., Mogul, J., Masinter, H.F.L., Leach, P., Berners-Lee, T.: Hypertext
Transfer Protocol - HTTP/1.1. RFC 2616 (1999)
12. Gember, A., Anand, A., Akella, A.: A Comparative Study of Handheld and Non-handheld
Trafﬁc in Campus Wi-Fi Networks. In: Spring, N., Riley, G.F. (eds.) PAM 2011. LNCS,
vol. 6579, pp. 173–183. Springer, Heidelberg (2011)
13. Korn, D., MacDonald, J., Mogul, J., Vo, K.: The VCDIFF Generic Differencing and
Compression Data Format. RFC 3284 (2002)
14. Lumezanu, C., Guo, K., Spring, N., Bhattacharjee, B.: The Effect of Packet Loss on
Redundancy Elimination in Cellular Wireless Networks. In: IMC (2010)
15. Mogul, J., Douglis, F., Feldmann, A., Krishnamurthy, B.: Potential beneﬁts of delta encoding
and data compression for HTTP. In: SIGCOMM (1997)
16. Mogul, J., Krishnamurthy, B., Douglis, F., Feldmann, A., Goland, Y., van Hoff, A.,
Hellerstein, D.: Delta encoding in HTTP. RFC 3229 (2002)
17. Qian, F., Quah, K.S., Huang, J., Erman, J., Gerber, A., Mao, Z.M., Sen, S., Spatscheck, O.:
Web Caching on Smartphones: Ideal vs. Reality. In: Mobisys (2012)
18. Sanadhya, S., Sivakumar, R., Kim, K.H., Congdon, P., Lakshmanan, S., Singh, J.P.:
Asymmetric Caching: Improved Network Deduplication for Mobile Devices. In: Mobicom
(2012)
19. Spring, N.T., Wetherall, D.: A Protocol-Independent Technique for Eliminating Redundant
Network Trafﬁc. In: SIGCOMM (2000)
20. Zohar, E., Cidon, I., Mokryn, O.O.: The Power of Prediction: Cloud Bandwidth and Cost
Reduction. In: SIGCOMM (2011)