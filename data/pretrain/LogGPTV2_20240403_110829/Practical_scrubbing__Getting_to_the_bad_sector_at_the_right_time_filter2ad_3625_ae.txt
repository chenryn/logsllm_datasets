16ms
Oracle
Auto−Regression
Waiting
Lossless Waiting
AR (20th) + Waiting
AR (40th) + Waiting
AR (60th) + Waiting
AR (80th) + Waiting
d
e
z
i
l
i
t
u
e
m
i
t
l
e
d
i
f
o
n
o
i
t
c
a
r
F
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0
256ms
512ms
64ms
64ms
128ms
128ms
256ms
1024ms
2048ms
512ms
32ms
32ms
16ms
16ms
1024ms
2048ms
256ms
512ms
1024ms
2048ms
128ms
64ms
32ms
16ms
0.00
0.01
0.02
0.03
0.07
Collision rate (fraction) −− HPc6t8d0
0.04
0.05
0.06
0.08
0.09
0.10
0.00
0.01
0.02
0.04
0.03
0.07
Collision rate (fraction) −− MSRusr2
0.05
0.06
Oracle
Auto−Regression
Waiting
Lossless Waiting
AR (20th) + Waiting
AR (40th) + Waiting
AR (60th) + Waiting
AR (80th) + Waiting
8ms
0.08
0.09
0.10
Figure 14. Comparison of the Auto-regression and Waiting approaches with the optimal (Oracle), for two disks: HPc6t8d0 (left) and MSRusr2 (right).
For each of these values we plot one line in the graph, which
results from varying the wait time threshold.
Finally, for reference we also plot the best possible results
that could be achieved by a clairvoyant Oracle that can
accurately predict the x% longest idle intervals and only
utilize those, maximizing the amount of idle time one can
utilize for a collision rate of x%. This Oracle provides an
upper bound on the results one can hope to achieve.
The results in Fig. 14 are quite interesting. We ﬁnd that
the simple Waiting approach clearly outperforms AR and the
combined approaches, as it consistently manages to utilize
more idle time for a given collision rate. On the other hand,
the pure AR policy shows by far the worst performance,
which we attribute to its inability to capture enough request
history to make successful decisions. While outperforming
the other policies, the Waiting approach is weaker than the
Oracle. One might wonder whether this is due to the fact
that Waiting fails at predicting all the long idle intervals, or
because it wastes idle time while sitting idle waiting for t
time before ﬁring. To answer this question we also plotted
results for a hypothetical policy, Lossless Waiting, which
utilizes the same intervals as Waiting, while assuming that
we can magically also make use of the time that passes while
waiting. We see that this hypothetical policy performs very
closely to the best possible policy (the Oracle). This means
that the Waiting approach is extremely good at identifying
long idle intervals, and only falls short from achieving
optimal possible performance due to the time spent waiting.
C. Sizing up throughput opportunities
One important remaining parameter is the size of each
scrub request. While larger scrub requests will increase scrub
throughput (recall Fig. 4), they also increase the impact on
foreground workloads, as collisions become more expensive
(increasing delays for the foreground request arriving while
a scrub request is in progress, and often also for the ones
following that). Our goal is to take as input from a system
administrator the average and maximum tolerable slowdown
per foreground application request, and within these limits
ﬁnd the parameters that maximize scrub throughput.
Fig. 15 shows that the throughput a scrubber can achieve
while limiting the slowdown of the foreground application
128ms
204ms
256ms
512ms
256ms
512ms
1024ms
1024ms
2048ms
2048ms
4096ms
4096ms
64Kb fixed
728Kb fixed (Optimal: 0.5ms)
1216Kb fixed (Optimal: 1.5ms)
1280Kb fixed (Optimal: 1ms)
4Mb fixed
Optimal exponential (a=2)
Optimal linear (a=2, b=64Kb)
)
s
/
B
M
(
t
u
p
h
g
u
o
r
h
t
i
g
n
b
b
u
r
c
S
50
45
40
35
30
25
20
15
10
5
0
0
0.5
1
1.5
2
2.5
3
Mean of request slowdown (ms)
Figure 15. Comparison of different Waiting variants. Fixed variant prevails.
to some acceptable threshold, can vary dramatically as a
function of the request size. The ﬁxed lines in Fig. 15 were
obtained by simulating the Waiting policy while keeping
the request size ﬁxed at 64KB, 768KB, 1216KB, 1280KB and
4MB, and varying the wait time threshold. For each threshold
value, we plot the resulting average slowdown on foreground
requests versus the throughput achieved by the scrubber (we
experimented with request sizes ranging from 64KB to 4MB
and a maximum allowed request slowdown of 50ms, but
plot only results for 5 sizes for readability). We observe
that for the two extreme examples of 64KB and 4MB, the
scrubber using 4MB requests has a consistently higher scrub
throughput for the same foreground application slowdown.
This motivated us to try and determine the optimal scrub
request size for a speciﬁc request slowdown, i.e. the request
size that will lead to a slowdown within the prescribed limit,
while maximizing scrub throughput (we focus only on the
Waiting approach, since we showed how it outperforms the
rest). We accomplished this using simulation to ﬁnd the op-
timal request size in the range from 64KB to 4MB (bounded
by the maximum tolerable slowdown), and the wait time
threshold for which it yields the maximum throughput,
satisfying the given average slowdown goal per I/O request.
For each size, the optimal threshold can be found efﬁciently
through binary search, since for a given request size, larger
thresholds will always lead to smaller slowdowns. Using the
threshold we can then estimate the maximum throughput per
request size, and use that as a comparison metric to ﬁnd
the optimal request size. To summarize, our policy chooses
for each slowdown the request size (and corresp. wait time
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:48:41 UTC from IEEE Xplore.  Restrictions apply. 
threshold) that maximizes the scrubber’s throughput. Results
for our policy are shown in Fig. 15, where we ﬁnd, for ex-
ample, that some optimal (slowdown, request size) pairs are:
(0.5ms, 768KB), (1.0ms, 1280KB) and (1.5ms, 1216KB).
We observe that this approach performs signiﬁcantly better
than either the 64KB or the 4MB approach.
In the experiment above, we limit ourselves to picking the
best request size (and wait time) to maximize throughput
for a given acceptable slowdown, and have the scrubber
send back-to-back scrub requests of that ﬁxed size until a
collision occurs. Based on our observations of decreasing
hazard rates in Section V-A, one might think of doing even
better by varying the request size over time, as the scrubber
ﬁres. When the wait time is just over and the scrubber starts
sending requests, the probability of a foreground request
arriving during that scrub request is much higher than later,
when the scrubber has already been ﬁring requests for a
while (due to the decreasing hazard rates, the probability
of collision decreases as the system remains idle – recall
Fig. 11, 12). One could, therefore, start with smaller request
sizes at the beginning of a scrub interval (when chances of a
foreground request arriving are still high) and then gradually
increase the request size over time.
We have experimented with three adaptive approaches, all
of which wait for some time t before ﬁring scrub requests
of a start size s; this size is then increased with time. The
exponential approach multiplies the request size by a factor
a every time a scrub request is completed without a collision
occurring. The linear approach uses the factor a calculated
by the exponential approach and afﬁxes a constant b to each
increase, so each new request is multiplied by a and further
increased by b. Using both, we can ﬁnd the optimal rate
of increase for our request size (we apply the exponential
approach ﬁrst, since it affects that rate more than the linear).
We used simulations to ﬁnd the constants a, b that provide
the best trade-off between slowdown and scrub throughput
for each trace. We have also experimented with a simpler
swapping policy, that considers only two different request
sizes: when the initial wait time t is over it starts ﬁring with
the optimal request size s that achieves the average given
slowdown, and then at some later point t′ it switches over
to the maximum request size, whose service time does not
exceed the maximum allowed slowdown.
The results for our adaptive approaches are given by the
dashed lines in Fig. 15 (omitting swapping, for which we
found t′
opt = ∞). Surprisingly, we notice that none of these
adaptive approaches outperforms the ﬁxed approach where
one optimal request size is picked for a given slowdown goal.
Through detailed statistical analysis, we managed to identify
the reason behind the poor performance of the adaptive
approaches. The technique of increasing the request size
only works in the presence of strongly decreasing hazard
rates, i.e. over time the instantaneous probability of collision
decreases. While we found this to be the case for idle
time distributions in their entirety, we also found that upon
“cutting off” the initial wait time, the resulting truncated
distribution shows a much weaker decrease in hazard rates.
In other words, the long intervals captured by the Waiting
approach, are far longer than the time it takes the slowest
of our adaptive approaches to reach the maximum allowed
request size. Since this size will be larger than the optimal
and will be reached on every captured interval, each collision
will incur more slowdown than it would with the optimal
size. As a result, the extra throughput comes at a cost of extra
slowdown, and vice versa: when the predeﬁned slowdown
goal is considered, the corresponding throughput is lower
than that for the optimal ﬁxed approach5.
D. Putting it all together
In summary, we have made some interesting observations
for optimizing the background scheduling of scrubbing
requests in I/O schedulers. First, we found that a simple
approach based on waiting outperforms more complex ones
based on auto-regression. Second, we found that picking one
ﬁxed request size for the scrubber, rather than adapting it
within an idle interval, is sufﬁcient. This allows for a simple
scrub policy with only two tunable parameters: the scrub
request size and the wait time threshold. We further found
that for a given slowdown target these two parameters can
be determined relatively easily, based on a short I/O trace
capturing the workload’s periodicity, and simulations guided
by binary search. The simulations can be repeated to adapt
the parameter values if the workload changes substantially.
Disk
Avg. Sldn
Throughput
Threshold
Req. Size
HPc6t8d0
(Waiting)
CFQ
HPc6t5d1
(Waiting)
CFQ
MSRsrc11
(Waiting)
CFQ
MSRusr1
(Waiting)
CFQ
1.0 ms
2.0 ms
4.0 ms
938 ms
1.0 ms
2.0 ms
4.0 ms
4.4 ms
1.0 ms
2.0 ms
4.0 ms
7.7 ms
1.0 ms
2.0 ms
4.0 ms
106 ms
38.75 MB/s
50.53 MB/s
61.51 MB/s
6.25 MB/s
68.12 MB/s
72.83 MB/s
73.97 MB/s
13.75 MB/s
73.54 MB/s
75.77 MB/s
76.40 MB/s
13.19 MB/s
62.49 MB/s
71.24 MB/s
71.58 MB/s
13.44 MB/s
Table III
205 ms
88.1 ms
32.4 ms
10 ms
632 ms
340 ms
247 ms
10 ms
22.3 ms
15.3 ms
12.6 ms
10 ms
10.8 ms
39.8 ms
18.5 ms
10 ms
1280KB
1536KB
2048KB
64KB
3072KB
4096KB6
4096KB6
64KB
3072KB
4096KB6
4096KB6
64KB
1472KB
3072KB
4096KB6
64KB
FIXED WAITING APPROACH RESULTS FOR DIFFERENT DISK TRACES
Table III summarizes the throughput a scrubber can ac-
complish for four of our traces and three average slowdown
goals of one, two and four msec, respectively. The table
5This is why the adaptive and 4MB Fixed approaches overlap in Fig.15.
6The maximum slowdown allowed (50.4ms) limits the request size at
4MB. If that restriction is relaxed, this run can achieve higher throughput.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:48:41 UTC from IEEE Xplore.  Restrictions apply. 
also provides the wait time threshold and the request size
that was used to achieve those throughputs. To put these
results into perspective, we also include numbers for CFQ,
albeit for 64KB requests. We ﬁnd that our scrubber achieves
signiﬁcantly less slowdown (up to 3 orders of magnitude
for busier traces) for up to 64x larger requests, yielding
signiﬁcantly more throughput per ms of slowdown. CFQ
comes (somewhat) close to our approach only when its ﬁxed
threshold (10ms) happens to align with the workload.
VI. CONCLUSIONS AND FUTURE WORK
the same time, we limit
With this work, we have taken a broad look at ways to
issue background scrub requests in storage systems, in order
to maximize the rate at which the system is being scrubbed.
At
the impact on foreground
applications running on the system to a predeﬁned threshold.
We have also developed an experimental framework within
the Linux kernel, which can be used to implement scrubbing
algorithms in only tens of LoC and we have made its
source code publicly available1. Using our framework, we
performed the ﬁrst experimental comparison of sequential
and staggered scrubbing. While sequential scrubbing is the
approach that is currently used in production systems, we
ﬁnd that staggered scrubbing implemented with the right
parameters can achieve the same (or better) scrub through-
put as a sequential scrubber, without additional penalty to
foreground applications. In addition, we presented a detailed
statistical analysis of publicly available I/O traces, and used
the results to deﬁne policies for deciding when to issue scrub
requests, while keeping foreground request slowdown at a
user-deﬁned threshold. We ﬁnd that the simplest approach,
based on idle waiting and using a ﬁxed scrub request
size outperforms more complex statistical approaches and
approaches using variable request sizes.
While we have focused on issuing scrub requests, we
believe that our approach and observations can be applied
for other uses of idle time. Examples include: contributing
to power savings in data centers (e.g. by spinning disks
down), guaranteeing availability (e.g. checkpointing, back-
ups), performance (e.g. prefetching), reliability (e.g. lazy
parity updates), or proﬁt in the cloud by encouraging sharing
a disk among more users while retaining QoS.
ACKNOWLEDGMENTS
We thank Sotirios Damouras for his help on matters of
statistics, Ari Juels and Alma Riska for insightful conver-
sations on scrubbing, Vladislav Sekulic for assisting us
patiently as systems administrator of our group, Austin
Donnelly from Microsoft Research for clariﬁcations on the
MSR trace, and Jens Axboe for addressing our questions
on CFQ. We also thank the four anonymous reviewers for
their kind reviews and their suggestions on improving the
presentation of the paper. This work was funded by EMC, an
NSERC Discovery grant and a NetApp Faculty Fellowship.
REFERENCES
[1] M. Hilbert and P. L´opez, “The world’s technological capacity
to store, communicate, compute information,” Science, 2011.
[2] L. N. Bairavasundaram, G. R. Goodson, S. Pasupathy, and
J. Schindler, “An analysis of latent sector errors in disk
drives,” in Proc. of ACM SIGMETRICS, 2007.
[3] S. Hetzler, “System impacts of storage trends: Hard errors
and testability,” USENIX ;login:, vol. 36, June 2011.
[4] A. Oprea and A. Juels, “A clean-slate look at disk scrubbing,”
in Proc. of USENIX FAST, 2010.
[5] E. Thereska, J. Schindler, J. Bucy, B. Salmon, C. R. Lumb,
and G. R. Ganger, “A framework for building unobtrusive disk
maintenance applications,” in Proc.of USENIX FAST, 2004.
[6] M. Wachs, M. Abd-El-Malek, E. Thereska, and G. R. Ganger,
“Argon: performance insulation for shared storage servers,” in
Proc. of USENIX FAST, 2007.
[7] R. Golding, P. Bosch, C. Staelin, T. Sullivan, and J. Wilkes,
“Idleness is not sloth,” in Proc of USENIX ATC, 1995.
[8] N. Mi, A. Riska, X. Li, E. Smirni, and E. Riedel, “Restrained
utilization of idleness for transparent scheduling of back-
ground tasks,” in Proc. ACM SIGMETRICS, 2009.
[9] N. Mi, A. Riska, Q. Zhang, E. Smirni, and E. Riedel,
“Efﬁcient management of idleness in storage systems,” ACM
Trans. Storage, vol. 5, pp. 4:1–4:25, June 2009.
[10] B. Schroeder, S. Damouras, and P. Gill, “Understanding latent
sector errors and how to protect against them,” in Proc. of
USENIX FAST, 2010.
[11] J.-F. Pˆaris, S. Thomas Schwarz, A. Amer, and D. Long, “Im-
proving disk array reliability through expedited scrubbing,”
in Proc. of IEEE NAS, 2010.
[12] T. J. E. Schwarz, Q. Xin, E. L. Miller, D. D. E. Long,
A. Hospodor, and S. Ng, “Disk scrubbing in large archival
storage systems,” in Proc. of IEEE MASCOTS, 2004.
[13] Z. Dimitrijevic, R. Rangaswami, and E. Y. Chang, “Systems
support for preemptive disk scheduling,” IEEE Trans. Com-
put., vol. 54, pp. 1314–1326, October 2005.
[14] C. R. Lumb, J. Schindler, and G. R. Ganger, “Freeblock
scheduling outside of disk ﬁrmware,” in Proc. of FAST, 2002.
[15] E. Bachmat and J. Schindler, “Analysis of methods for
scheduling low priority disk drive tasks,” in Proc. of ACM
SIGMETRICS, 2002.
[16] D. Anderson, J. Dykes, and E. Riedel, “More Than an
Interface—SCSI vs. ATA,” in Proc. of USENIX FAST, 2003.
[17] J. Axboe, “Linux Block IO – present and future,” in Proc. of
the Ottawa Linux Symposium, July 2004.
[18] Storage Networking Industry Association, “I/O traces, tools,
and analysis repository,” http://iotta.snia.org/.
[19] A. Riska and E. Riedel, “Disk drive level workload charac-
terization,” in Proc. of USENIX ATC, 2006.
[20] ——, “Evaluation of disk-level workloads at different time-
scales,” in Proc. of IISWC, 2009.
[21] C. Ruemmler and J. Wilkes, “Unix disk access patterns,” in
Proc. of USENIX Winter Technical Conference, 1993.
[22] Akaike, H., “A new look at the statistical model identiﬁca-
tion,” IEEE Trans. on Automatic Control, vol. 19, no. 6, 1974.
[23] N. Hautsch, Modelling Irregularly Spaced Financial Data:
Theory and Practice of Dynamic Duration Models, ser. Lec-
ture Notes in Econ. and Mathem. Systems. Springer, 2004.
[24] Engle, Robert F. and Russell, Jeffrey R., “Autoregressive
Conditional Duration: A New Model for Irregularly Spaced
Transaction Data,” Econometrica, vol. 66, no. 5, Sept. 1998.
[25] J. Maindonald and J. Braun, Data Analysis and Graphics
Using R, 3rd ed. Cambridge Univ. Press, 2010.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:48:41 UTC from IEEE Xplore.  Restrictions apply.