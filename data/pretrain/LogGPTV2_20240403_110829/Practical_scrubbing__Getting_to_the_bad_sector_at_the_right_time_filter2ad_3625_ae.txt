### Comparison of Auto-Regression and Waiting Approaches

#### Figure 14: Performance Analysis
Figure 14 compares the performance of the Auto-Regression (AR) and Waiting approaches with the optimal Oracle for two disks: HPc6t8d0 (left) and MSRusr2 (right). The Oracle represents the best possible results, where a clairvoyant system can accurately predict the longest idle intervals and maximize the utilization of idle time for a given collision rate. The results are plotted for various wait time thresholds.

**Key Observations:**
- **Waiting Approach:** This simple approach outperforms both AR and combined approaches by consistently utilizing more idle time for a given collision rate.
- **Auto-Regression (AR):** The pure AR policy shows the worst performance, attributed to its inability to capture sufficient request history for making successful decisions.
- **Lossless Waiting:** A hypothetical policy that assumes perfect utilization of waiting time performs very close to the Oracle, indicating that the Waiting approach is highly effective in identifying long idle intervals but falls short due to the time spent waiting.

#### C. Sizing Up Throughput Opportunities
The size of each scrub request is a critical parameter. Larger requests increase scrub throughput but also impact foreground workloads, leading to higher delays. The goal is to find the parameters that maximize scrub throughput while keeping the slowdown within acceptable limits.

**Figure 15: Throughput vs. Slowdown**
Figure 15 illustrates the scrubber's throughput as a function of the request size and the average slowdown on foreground requests. The fixed lines in the figure were obtained by simulating the Waiting policy with different request sizes (64KB, 768KB, 1216KB, 1280KB, and 4MB) and varying wait time thresholds.

**Key Findings:**
- **Fixed Request Size:** The 4MB request size consistently achieves higher scrub throughput for the same foreground application slowdown compared to smaller sizes like 64KB.
- **Optimal Request Size:** For specific slowdowns, the optimal request size and corresponding wait time threshold can be determined through simulation. For example, optimal pairs include (0.5ms, 768KB), (1.0ms, 1280KB), and (1.5ms, 1216KB).
- **Adaptive Approaches:** Experiments with adaptive approaches (exponential, linear, and swapping) show that none outperform the fixed approach. The reason is that the hazard rates do not decrease strongly enough after the initial wait time, leading to suboptimal performance.

#### D. Putting It All Together
In summary, the following observations have been made for optimizing background scheduling of scrubbing requests:
1. **Simple Waiting Outperforms Complex Approaches:** A simple waiting-based approach outperforms more complex auto-regression methods.
2. **Fixed Request Size is Sufficient:** Using a single fixed request size for the scrubber, rather than adapting it, is sufficient and simplifies the policy.
3. **Parameter Determination:** The scrub request size and wait time threshold can be determined based on I/O traces and simulations, allowing for easy adaptation if the workload changes.

**Table III: Summary of Results**
Table III provides the throughput, wait time threshold, and request size for four disk traces and three average slowdown goals (1 ms, 2 ms, and 4 ms). The results show that the proposed scrubber achieves significantly less slowdown and higher throughput compared to CFQ, especially for busier traces.

### Conclusions and Future Work
This work has explored ways to issue background scrub requests in storage systems to maximize scrub throughput while limiting the impact on foreground applications. Key findings include the superiority of the simple waiting approach and the effectiveness of using a fixed request size. The developed experimental framework within the Linux kernel allows for easy implementation and testing of scrubbing algorithms.

Future work could extend these findings to other uses of idle time, such as power savings, availability, performance, reliability, and cloud resource sharing.

### Acknowledgments
We thank Sotirios Damouras, Ari Juels, Alma Riska, Vladislav Sekulic, Austin Donnelly, and Jens Axboe for their contributions and support. This work was funded by EMC, an NSERC Discovery grant, and a NetApp Faculty Fellowship.

### References
[References listed as provided]

---

This revised version aims to make the text more coherent, clear, and professional, with a logical flow and concise presentation of key points.