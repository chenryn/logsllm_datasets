selection-based image reCAPTCHA challenges appear more
often than click-based ones. The success rate and speed of
breaking selection-based challenges are 84.74% and 17.47
seconds, respectively. Figure 5a shows frequency and suc-
cess rate for each object category in the submitted challenges.
As we can see, only 19 object categories have been repeated
across all 701 selection-based reCAPTCHA image challenges.
Further, the top 5 object categories constitute over 78% of the
total challenges. If we consider the ﬁrst 10 categories, this
number goes above 95%.
Note that reCAPTCHA often asks users to solve multiple
image puzzles in a row to pass a single selection-based re-
CAPTCHA test. However, in 80.81% of passed CAPTCHAs,
our system is required to solve only one image test. In 16.84%
of challenges, it is required to solve 2 image puzzles. The
maximum number of puzzles required to pass a test is 5, and
it occurs only twice.
(a) Selection-based CAPTCHA.
(b) Click-based CAPTCHA.
Figure 5: Attack performance. Frequency and success rate
for each object category.
We ﬁnd that in the majority of cases, there are at least 3
potential grids required to be chosen to pass a selection-based
CAPTCHA test. Precisely, in 5.72% of passed CAPTCHAs,
our system is asked to select 2 grids. In 42.59% of solved
CAPTCHAs, it is required to choose 3 grids. In 32.15% of
solved challenges, the system is required to select 4 grids. The
number of selected potential grids in the remaining challenges
ranges from 5 to 14. We also ﬁnd 2 tests where our system
had to choose 18 grids to pass the challenges. It takes 4.01
seconds to select a grid while solving a challenge, on average.
Attack on click-based CAPTCHAs. We come across only
87 click-based CAPTCHAs in the 800 submitted challenges,
and our system passes 62 of them. The success rate and speed
are 71.26% and 43.53 seconds, respectively. Figure 5b pro-
vides the frequency and success rate for different object cat-
egories in click-based reCAPTCHA challenges. As we can
see, in click-based CAPTCHA challenges, there are only ﬁve
object categories.
USENIX Association
23rd International Symposium on Research in Attacks, Intrusions and Defenses    275
Since reCAPTCHA’s click-based CAPTCHAs are rela-
tively new and have not been explored in the previous study,
we experiment to analyze the security of it further. The study
by Sivakorn et al. revealed that the initial implementation of
reCAPTCHA v2 used to provide ﬂexibility in its selection-
based challenges, i.e., it used to accept 1 or 2 wrong grid
selection(s) along with a certain number of correct grid se-
lections while solving a CAPTCHA test [44]. We investigate
whether reCAPTCHA provides such ﬂexibility for click-based
challenges. We submit some CAPTCHAs by clicking on a
different combination of correct and wrong grids. We sub-
mit 50 challenges for each combination. The result of our
experiment is summarized in Table 4. The highest success
rate we achieve is 6% when we click 6 correct grids and 1
wrong grid while submitting the challenges. It suggests that
reCAPTCHA does not usually provide any solution ﬂexibility
for click-based CAPTCHAs.
Table 4: The success rates of different combinations of cor-
rect and wrong grid selection in a click-based CAPTCHA
solution.
# of Correct Grid
# of Wrong Grid
Success Rate
3
4
5
6
6
3 (out of 4)
4 (out of 5)
5 (out of 6)
1
1
1
1
2
0
0
0
0.00%
2.00%
0.00%
6.00%
0.00%
0.00%
0.00%
2.00%
Impact of security preference. reCAPTCHA allows the
website owners to adjust the security level based on their
needs while deploying it to their websites. There are three
levels in the security preference setting from “Easiest for user”
to “Most secure.” By default, reCAPTCHA uses the security
level in the middle, which we call “Medium secure.” To inves-
tigate the impact of these settings on the attackers’ success
rate, we deploy reCAPTCHA on our website and submit 50
challenges for each security setting. We run the experiment
from a network that is isolated from the network hosting our
webserver to avoid any biases. We further follow the same
experimental setting mentioned in 5.1.
The results of our ﬁndings are summarized in Table 5. The
difference in the accuracy of our system across three security
preferences is negligible. We have not noticed any obvious
pattern that can distinguish one security preference from oth-
ers. However, for the “Easiest for user” setting, we ﬁnd that
reCAPTCHA occasionally accepts a solution even when our
bot misses one potential grid containing the target object or
clicks on a wrong grid along with the correct grid selections.
Further, reCAPTCHA often requires the bot to solve multiple
image puzzles in a single selection-based challenge when us-
Table 5: The success rates of different security preferences
in the reCAPTCHA deployment setting.
Security Preference
Success Rate (%)
Speed (s)
Easiest for user
Medium secure
Most secure
82
78
84
16.75
14.31
18.79
ing the “Most secure” security preference on the reCAPTCHA
admin panel for our website.
Impact of browser automation software. To study the im-
pact of different browser automation frameworks on the per-
formance of the bots, we develop a bot using the Selenium
[12]. Selenium is one of the most widely used browser automa-
tion frameworks, which was also used by prior arts. Selenium
provides WebDriver for both Mozilla Firefox and Google
Chrome web browsers. In particular, we use Selenium Python
bindings (version 3.141.0) with Python version 2.7.18 in this
experiment. For web browsers, we select Firefox 65.0 and
Chrome 78.0.3882.0. To keep the experiment consistent with
our main attack, we run the program from the same machine,
and we access reCAPTCHA-enabled websites from the same
IP address. Further, we clear the caches and cookies each time
we launch the program.
First, we use Firefox WebDriver. We submit 100
CAPTCHAs and notice that most of our attempts fail to break
them. Accurately, the system can solve only 32% of the total
submitted challenges. A careful examination of our system
log reveals that reCAPTCHA rejects many of the potentially
correct solutions. Further, 12 out of 100 requests have been
blocked with the message — “We’re sorry, but your computer
or network may be sending automated queries. To protect our
users, we can’t process your request right now.” Note that
at the same time, we also run our original puppeteer-ﬁrefox
based system and verify that it can normally solve the chal-
lenges. Next, we repeat the same experiment with Chrome
WebDriver. We recognize a similar pattern as before: the suc-
cess rate of breaking the CAPTCHAs is below 40%. We also
ﬁnd that reCAPTCHA shows a signiﬁcantly higher percent-
age of click-based CAPTCHAs when we use the Selenium.
Speciﬁcally, more than 25% of the challenges that our system
attempt to solve are click-based ones. Furthermore, we also
encounter many noisy images.
Since reCAPTCHA’s advanced risk analysis engine treats
our Selenium based system as highly suspicious, we try to
obfuscate the presence of Selenium and investigate whether
the obfuscation could improve our attack performance. When
using an automation framework, the browser is supposed to
set navigator.webdriver property to “true” according to
W3C speciﬁcation. However, an adversary may not follow
this speciﬁcation in an attempt to hide the presence of Web-
Driver to dodge detection. To experiment with an attacker’s
perspective, we set this property to “false.” Moreover, we ob-
276    23rd International Symposium on Research in Attacks, Intrusions and Defenses
USENIX Association
fuscate different aspects of the browser environment, such as
the user-agent string, the number of plugins used, the number
of fonts, and screen resolution. We then run a series of ex-
periments with these settings. However, none of our attempts
have resulted in any noticeable difference.
Impact of anti-recognition. We conduct a comprehensive
analysis of the anti-recognition techniques employed by re-
CAPTCHA that have been introduced only recently in an
attempt to undermine AI-based recognition. First, we need
to identify noisy, distorted, or perturbed images. However,
identifying such images is not trivial. A simple approach
could be using Signal to Noise Ratio (SNR) measure to
estimate the noise in an image. However, we cannot sim-
ply use SNR because we do not have access to the orig-
inal ground truth images. In this situation, we ﬁnd scikit-
image’s [48] estimate_sigma function to be particularly
useful. estimate_sigma provides a rough estimation of the
average noise standard deviation (σnoise) across color chan-
nels for an RGB image. We calculate σnoise for all 1,048
images that our solver attempt to solve during our experi-
ment. The σnoise for 928 (over 88%) images are all below
2. For the remaining 120 images, the σnoise ranges from 2 to
14.86. By manually analyzing the images, and doing the visual
inspection, we ﬁnd images with σnoise over 10 appear to be
extremely noisy and distorted, and contains some kinds of per-
turbations. We ﬁnd 52 such images, and we use them for our
comprehensive analysis of reCAPTCHA’s anti-recognition
attempts.
We suspect that reCAPTCHA might be using adversar-
ial examples [15, 46], slightly perturbed images maliciously
crafted to fool pre-trained image classiﬁers. Prior work also
recommended using adversarial examples to limit the impact
DNN image classiﬁer based attacks [44]. We experiment to
validate our assumption. First, we labeled the potential grids
in images with perturbations. We then extract these grids from
the images and submit them to the computer vision services
for recognition.
Table 6 shows the label sets returned by 4 off-the-shelf im-
age recognition services for an actual reCAPTCHA challenge
image. The target object in the challenge is a ﬁre hydrant,
and the potential grids are 1, 3, and 4. Table 7 shows the
result of our experiment. We can see that vision APIs have
misclassiﬁed a signiﬁcant number of potential grids. Clarifai
API has the highest number of misclassiﬁcations, followed by
Microsoft Computer Vision API. Google Cloud Vision API
did not return any labels for 32 potential grids. Note that we
consider a label set to be acceptable (A) if at least one of the
tags in the set describes the image’s content to some extent,
even if the name of the target object is not present in it. For
example, a potential grid for the target object car may also
contain other objects like road, trafﬁc light, and crosswalk.
If an image recognition API returns a label set with the tags
crosswalk, street, and trafﬁc light, we consider it acceptable
even though it does not contain the tag for the main target
object (a “car” in this case). We consider a label set to be
an exact match (EM) if one of the returned labels in the set
matches the name of the target object. A label set is said to be
misclassiﬁed (MC) if none of the returned labels in the label
set has any semantic relation with the grid’s actual content.
For instance, as shown in Table 6, Google Cloud Vision API
misclassiﬁed the potential grid number 3, which is an image of
a ﬁre hydrant, as an Art (or a Plant). A label set is considered
empty (E) if the API does not return any label. In our exper-
iment, we ﬁnd many grids that are misclassiﬁed by image
recognition services with very high (over 90%) probability,
which is a strong indication that those grids are adversarial.
Generally, non-adversarial perturbation does not mislead a
well-trained image classiﬁer; instead, it degrades the target
class’s conﬁdence score. At the same time, vision APIs for
image recognition return correct or acceptable label sets for
some noisy girds (see Table 7). Hence, based on our ﬁndings,
we hypothesize that reCAPTCHA is using a mixture of ad-
versarial perturbations and random noises in some challenge
images. Note that the actual identiﬁcation of adversarial per-
turbations or examples is a non-trivial task, and it is still an
open research problem in the AI domain.
Next, we investigate the impact of adversarial perturbations
or random noises on our object detection models. We run our
pre-trained object detection models on the same 52 images to
determine how many target objects they can correctly identify.
Note that, it is not always necessary to detect and localize all
the target objects in a challenge image, i.e., it is sufﬁcient to
pass a challenge if the bounding box to grid mapping algo-
rithm result can capture all the potential grids regardless of
the number of objects present in the challenge image. Our
base object detection models can recognize less than 60% of
the target objects in the challenge images (see Table 8). We
use the object counts as a metric to assess object detection
models’ performance to simplify the analysis.
Next, we apply different data augmentation techniques to
study whether retraining the object detection system using the
augmented data helps increase the system’s robustness against
reCAPTCHA’s anti-recognition mechanisms. We develop a
data augmentation pipeline employing various augmentation
methods such as additive Gaussian noise injection, blurring,
and changing the brightness and contrast, etc. We utilize the
imgaug [31] library for data augmentation. For adding Gaus-
sian noise, we use the AdditiveGaussianNoise function
with scale=(0, .2∗255). We use the following methods for
blurring: GaussianBlur with sigma=(0.5-5.0), MedianBlur
with k=(5, 17), and AverageBlur with k=(5, 17). Figure 8 in
Appendix B shows some examples of data augmentation meth-
ods applied to a sample reCAPTCHA challenge image. We
randomly select 30% of training images and apply each data
augmentation method from our pipeline to images. Finally,
we retrain our object detection models using the augmented
training samples. We also collect 500 perturbed images (σnoise
> 5) from the reCAPTCHA challenges and ﬁne-tune the mod-
USENIX Association
23rd International Symposium on Research in Attacks, Intrusions and Defenses    277
Table 6: A noisy image from reCAPTCHA challenge and the labels returned by 4 image recognition services. The target object
is a “Fire Hydrant.” PGNs=Potential Grid Numbers (1, 3, 4).
Image
PGNs
Google Cloud Vision
Microsoft Azure
Computer Vision
Amazon
Rekognition
Clarifai
1
3
4
leaf, grass, plant
animal, mammal
art, painting
pattern, art
pink, toy, action ﬁgure
grass, outdoor
hydrant, outdoor
object, ﬁre hydrant
hydrant, ﬁre hydrant
hydrant, ﬁre hydrant
desktop, animal, dog,
desktop
people, nature
nature, abstract,
pattern, art