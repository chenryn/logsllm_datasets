25 End Function
The function getFilterStatement(Q) is used to retrieve these filter statements from the query and to identify the type of Value FiValue. If it is a Literal, the getPredicate(Q) function will look for the connected predicate. Similar to the technique used in triples, we use getLogProperty() to retrieve the regular expression defined in regexPattern (RP). Finally, the collected prefixes and retrieved key-value pairs, both from triples and filters, will be stored in QueryElements (Qe) for further processing. Figure 5 depicts a SPARQL query translation example.Figure 5. SPARQL Query translation example.
Log Extraction This component is part of the Log Parser that extracts the selected raw log lines and splits them into a key-value pair representation by means of predefined regular
Mach. Learn. Knowl. Extr. 2022, 4 381
expression patterns. As outlined in Algorithm 2, Log sources (Ls) are included based on the prefixes that appear in the query.Algorithm 2: Log Extraction and RDF Mapping.
size 
Input: SPARQL Query (Q), TimeFrame (T f), LogSources (Ls) Output: Response (R)
| 1 TimeFrame T f = {startT, endT} ; 
2 LogSources Ls = {Ls1, ..., Lsn}; 
3 LogLines Ln = {Ln1, ..., Lnn} ϵ Ls; 
4 LogSourceOptions LsO = {vocabulary, regexPatterns} ϵ Ls; 5 LogLineOptions LnO = {logTime, logProperties} ϵ Ln ; 6 QueryElements Qe = {pre f ixes, triplesKV, f iltersKV}; 7 Qe ← translateQuery(Q, LsOvocabulary, LsOregexPatterns);8 foreach LogSource Lsi ϵ Ls do
9 	if Qepre f ixes contains LsOivocabulary then
10 	foreach LogLines Lnj ϵ Ln do | 1 TimeFrame T f = {startT, endT} ; 
2 LogSources Ls = {Ls1, ..., Lsn}; 
3 LogLines Ln = {Ln1, ..., Lnn} ϵ Ls; 
4 LogSourceOptions LsO = {vocabulary, regexPatterns} ϵ Ls; 5 LogLineOptions LnO = {logTime, logProperties} ϵ Ln ; 6 QueryElements Qe = {pre f ixes, triplesKV, f iltersKV}; 7 Qe ← translateQuery(Q, LsOvocabulary, LsOregexPatterns);8 foreach LogSource Lsi ϵ Ls do
9 	if Qepre f ixes contains LsOivocabulary then
10 	foreach LogLines Lnj ϵ Ln do |
|---|---|
| 11  12  13 |lt ← LnOjLogTime;  if ltT fstartT && lt<T fendT then  ml ← matchLog(LnOjlogProperties, QetriplesKV, Qe f iltersKV); if ml=True then |
| 18  19 |	parsedLine ← parseLine(Lnj);  end |
| 20 |end || 20 |end |
| 21 |parsedData += parsedLine; |
| 22 |end |
| 23  24  25 |RDFData ← RDFMapping(parsedData); if result=True then result ← compressData(RDFData); |
| 26  27 |end response ← ”Success”; |
| 28 |end |
| 29 |return response; |
30 endFor each log line (Lnj) in a log source, we check whether the log timestamp (LnOlogTime) is within the defined TimeFrame (T f ). We leverage the monotonicity assumption that is common in the log context by stopping the log parsing once the end of the temporal window of interest is reached in a log file (i.e., we assume that log lines do not appear out of order). This can be adapted, if required for a specific log source. If this condition is satisfied, the matchLog() function checks the logline property (LnOlogProperties) against the set of queried triples (QetriplesKV) and filters (Qe f iltersKV). If the log line matches the requirements, the selected log line will be parsed using parseLine() based on predefined regular expression patterns. The resulting parsed queries will be accumulated and cached in a temporary file for subsequent processing.RDF Mapping
This sub-component of the Log Parser maps and parses the extracted log data into RDF. It uses the standard RDF mapping language to map between the log data and the vocabulary. Different log sources use a common core log vocabulary (e.g., SEPSES coreLog [48]) for
Mach. Learn. Knowl. Extr. 2022, 4 382common terms (e.g., host, user, message) and can define extensions for specific terms (e.g., the request term in ApacheLog). The RDF Mapping also maps terms from a log entry to specific background knowledge (e.g., hosts in a log entry are linked to their host type according to the background knowledge). Figure 6 provides an overview of the log graph generation process.
Figure 6. Log graph generation overview.RDF Compression
This sub-component is part of the Log Parser, which transforms the resulting RDF output produced by the RDF Mapper into a compact version of RDF. This compression results in a size reduction by an order of magnitude, which has significant advantages in our VloGraph framework: (i) it enables fast data transfer to the Query Processor component and thereby reduces latency; (ii) it makes the query execution itself more efficient as the compressed RDF version enables query operations without prior decompression directly on the binary representation [49].We discuss the implementation of this component based on existing libraries in Section 6 and evaluate the effect of compression on the query execution performance on virtual log graphs in Section 7.
Query ExecutionOnce the pre-processing on each target host has been completed and the compressed RDF data results have been successfully sent back to the Query Processor, a query engine executes the given queries against the compressed RDF data. If multiple hosts were defined in the query, the query engine will perform query federation over multiple compressed RDF data from those individual hosts and combine the query results into an integrated output.Furthermore, due to semantic query federation, external data sources are automatically linked in the query results in case they were referenced in the query (cf. Section 6 for an example that links IDS messages to the SEPSES-CSKG [50]).
VisualizationVisualization
	Finally, this component presents the query results to the user; depending on the SPARQL query form [51], e.g.,: 	(i) SELECT—returns the variables bound in the query pattern, (ii) CONSTRUCT—returns an RDF graph specified by a graph template, and (iii) ASK—returns a Boolean indicating whether a query pattern matches.
Mach. Learn. Knowl. Extr. 2022, 4 383Mach. Learn. Knowl. Extr. 2022, 4 383
The returned result can be either in JSON or RDF format, and the resulting data can be presented to the user as an HTML table, chart, graph visualization, or it can be downloaded as a file.
6. Implementation & Application Scenarios
	In this section, we discuss the implementation of VloGraph framework Source code available at  and demonstrate its feasibility by means of three application scenarios.6.1. ImplementationThe VloGraph prototype relies on a number of existing open source tools and libraries. Specifically, we implement the  component as a Java-based tool that is installed and run on each monitoring hpports log parsing from multiple different OSs (e.g., Windows, Linux, etc.) and heterogeneous log files (e.g., authlog, apachelog, IISlog, IDSlog). For the Log Extraction component, we integrate , a collection of composeable regular expression patterns that can be reused aces. Furthermore, we use CARML [52] as an RDF Mapping component based on RML mappings [53] to map the extracted log data into RDF. For the RDF Compression component, we leverage the HDT [49] library to efficiently compress the resulting RDF data into a compact, binary format that allows query operations without prior decompression.For the analysis interface, we implemented a  component as a web-application that receives SPARQL queries, sends theget hosts, and presents the resulting graph to the analyst. Figure 7 shows the user interface of the application, which consist of (i) Query Options, including e.g., target hosts, background knowledge, analysis timeframe, as well as predefined queries to select. (ii) SPARQL Query Input to formulate and execute SPARQL queries, and (iii) Query Results to present the output of the executed query.The query execution is implemented on top of the Comunica [54] query engine that supports query federation over multiple linked data interfaces including HDT files and SPARQL endpoints.
Figure 7. SPARQL query editor interface.
6.2. Application Scenarios