在系统的技术框架里，开源软件占绝对多数，对开源软件的性能优化，也就实现对系统的性能优化，保障系统的运行效率。因此通过采集开源软件的性能指标、资源指标如积压数、等待时长、吞吐率、磁盘IO使用率、内存使用率等，并以线性回归算法建立模型作性能的分析，实现开源软件在不同周期的性能分析，可评估出其性能短板、相关优化的建议方案，以及在保障其性能指标的情况下，对一定的资源扩容和回收建议方案，节省开支成本。
2.3.3.3服务调用链性能优化（新）
当前系统向微服务化进行架构演进，如何高效快速的对微服务之间的调用情况进行分析优化成为了迫切需要解决的问题。基于调用链日志数据，引入词向量、余弦相似度、Apriori 挖掘等算法进行调用链分析，分析并发现调用链环节中可能存在的风险和异常，进行频繁服务结构的挖掘，定位性能瓶颈，从而进行性能调优。
2.3.3.4客户端体验评分（新）2.3.3.4客户端体验评分（新）
客户端的设计，尤其是界面的设计是直接影响客户端体验的，好的客户端体验能提升用户的操作效率、正确率，如果很难用，很有可能直接影响订单，进而影响营收。如何评价某个界面、功能是否合理、友好是关键。通过采集浏览器、APP客户端的性能指标、用户操作时长、页面加载时间、解析时间，通过AI模型（auto_arima、xgboost、holt-winter、LinearRegression），分析其交互性能、效率，针对被监控的功能、界面给出具体评分。评分越低，体验越差。通过客户端体现评分，可智能化评估客户端体现效果，及时处理规避客户不良感知。
2.3.3.5 数据库空间优化
随着业务的快速发展，需要通过表空间增长趋势估算数据库存储容量、监控表空间使用情况并及时预警。应用大数据技术对业务调用链日志提取与业务相关的后端数据表，通过 DFA 算法，线性回归算法，基于对应业务量的未来趋势来预测后端数据表所在表空间的需求容量，提前应对调整，提升数据库存储资源的利用率。2.3.3.6 错峰混合部署推荐
业务支撑系统具备明显的潮汐特征，为进一步提升系统资源利用率，通过挖掘监控系统记录的各业务系统机器的性能、CPU 占用、内存占用等数据，结合各个厂商系统部署经验与规则，应用余弦相似度算法分析各个业务系统的资源的使用情况，找到资源占用情况错峰互补的两个业务，推荐混合部署策略
2.3.4容量规划
2.3.4.1容器规格评估（新）
随着现在容器技术的火热，受到越来越多的企业青睐，然而容器并不只是一个独立工程，随着容器的升级、改进，其衍生出很多技术包括容器OS、容器引擎，基础框架的容器网络、存储、安全等，因此容器的管控对资源的合理充沛利用意义重大。对容器规格进行评估就显得越来越重要，可以提高资源利用率，规范管理。通过容器性能数据，结合AI算法（LTSM、prophet），基于应用容器，容量指标（容器CPU总核数、内存总大小），性能指标（CPU使用率、内存使用率），对容器性能进行分析预测。根据预测数据合理动态调整容器的资源配置，提升资源利用率。2.3.4.2网络流量预测（新）
网络规模越来越庞大和复杂，发生各种问题的可能性越来越多，同时给管理、监控运维增加了更大的难度。传统的运维是等告警之后，再响应处理，这时网络已经出现问题，业务已经受到影响。本场景功能规划通过LTSM、Prophet智能算法对网络历史流量数据进行分析，提前发现潜在风险，主动为网络流量优化提供参考。
2.3.4.3开源软件容量预测（新）
开源软件作为消息处理、数据计算、数据存储组件正在被越来越多的系统作为基础组件使用，而由于业务不断增长，系统规模不断扩大，包括开源软件资源在内的各系统资源需求也在不断增长，扩容需求正在成为需要快速相应的工作，而人工的评估方式将越来越力不从心。因此，获取开源软件的内存、CPU、线程数等性能指标历史数据，通过LSTM长短期记忆模型算法及TextCNN卷积神经网络等算法，构建相关性能指标的预测模型，并且输出未来一段时间的性能指标预测数据，根据预测结果，结合计扩缩规则，生成优化报告，优化建议及推荐值，支持不同时间周期的容量预测，需要扩容或调整的设备数量。2.3.4.4 资源池容量预测
挖掘分析运维大数据平台的历史容量数据（CPU 总核数、CPU 已分配量、CPU 剩余可分配量、内存总量、内存已分配量、内存剩余可使用量等容量指标）、业务数据（CRM 系统话费充值业务、启停机业务等等）、资源关联关系、日志数据、应用性能数据等数据，确定影响容量的关键因素创建适合的数据模型，并通过大数据进行机器训练，对数据模型各个参数进行修正，直到容量预测结果与历史结果一致，确定容量预测数据模型。通过容量预测模型、最近的容量数据、性能数据、业务数据进行未来容量预测。
2.3.4.5 容器竖直规格管控
不同应用上云时，需要根据该应用特性分配不同规格容器，以保证资源最大利用率。然而当前，仍使用经验确定应用单实例规格，并且规格的分档不够精确，在生产环境中资源利用率不高。期望实现“千App 千面”规格标准，提高资源利用率。因此，基于在压测过程中收集到的容器资源性能消耗指标，基于 LSTM 算法，实现性能异动指标数据的监测，优化容器规格。2.3.5成本优化（新）
2.3.5.1低效系统识别
随着电信行业环境的不断变化成本管控能力将成为企业核心竞争力的重要组成部分，如何高效准确的进行低效资产的判定成为了较难解决的问题。同时大量的虚拟系统涌现，也面临着资产需要评估的问题。而传统人们往往关注的是实体物理机的评估，而忽略了虚拟系统的评估。面对存在的痛点，基于人工智能的评估显得尤为重要，需要在海量数据当中，挖掘规律，从不同的指标维度，评估资产，根据不同客户的需求、业务目标需求，结合服务数据，整合运维人员经验，建立精准容量规划模型，从而精确预测各个业务的容量，为高效运维运维提供依据。基于虚拟系统的基本信息以及宿主机的基本信息，通过规则匹配筛选出低效资产；基于监控数据的智能判定，对指标数据进行auto_arima分析，对可能的低效资产进行标注，并进行XGBoost模型训练，实现自动低效识别。
2.3.5.2主机资源成本优化2.3.5.2主机资源成本优化
现在系统的经常存在部分主机利用率往往都很低，而这些主机往往没有专门的管理人员去发现统计并利用起来，通过采集主机资源相关数据指标，如CPU、内存、存储等资源数据指标，并以智能算法如Xgboost算法、CART回归树对，从海量指标数据当中，挖掘规律，从不同指标维度，评估预测未来一段时间资源使用情况，从而发现部分可利用的空闲资源，节省成本。
2.3.5.3数据库存储空间成本优化
现有数据库的年度扩容计划计算方式比较粗放简单，没有合理预估现有表空间的合并优化及清理，对表空间的增长预测不合理，导致年度扩容计划不够准确，容易造成磁盘空间成本浪费。采用数据库各个表空间的容量监控数据，通过ARIMA算法对每个表空间年度的扩容预测，并关联表空间所在的磁盘空间数据和表空间每年的优化数据，获取数据库实例的年度扩容计划，通过与现有扩容计划粗放计算方式相比，避免造成资源的浪费，做到按需供给更好的节约成本。2.3.5.4上云资源评估
云平台搭建完成后，应用需逐步往云上迁移，而往云上迁移时，面临的首要问题是该应用上云所需要的资源量评估。引入auto_arima、xgboost、holt-winter、LinearRegression等智能算法，对输入的信息数据做评估，结合规模数据、业务量数据、现网资源配置综合评估上云迁移所需的资源，提供合理规格配置及资源分配，为资源分配提供有理依据，改变依赖人为经验进行资源评估的现状，避免资源评估过多导致资源浪费或者资源评估过少导致二次扩容带来的改造成本两种情况，有效提高企业云资源利用率，大幅降低云上成本。
2.3.5.5微服务架构熵值评估2.3.5.5微服务架构熵值评估
微服务让服务细化到极致，单一而灵活，但同样将运维带到调用链复杂、故障根因难以分析的困境，为避免此种局面，需要有效评估应用微服务化后的熵值，以便作出微服务细化与维护量的平衡值评估，称之为熵值，越大越复杂，最后给出调整建议。引入ridge、ewma、iforest等智能算法，对输入的信息数据（bomc告警、第三方告警、手工输入的指标数据：单个应用接口数、每周上线次数）做评估，结合规模数据、告警规模数据、pod接口服务调用次数、应用包含的接口数、平均每周上线次数做综合评估，最后给出科学的熵值评估和改进建议。对上云后的系统做架构模块拆分做修正，避免可能出现的各种问题。
2.3.5.6资产维护费的智能评估
通过对资产的入网时间、利用率情况、用电费用、维保费情况等进行智能分析，实现对资产维护费分配合理性的准确评估。基于资产相关历史数据，通过PCA-主成分分析算法、多项式回归算法对资产维护费的历史分析预测，判断费用与资源使用情况是否合理，给出评估结果。2.4场景联动类（新）
本期新增场景联动类场景，通过对多个AIOps场景分析能力进行关联结合，从而拓展AIOps运用场景及落地效果，发挥多个AIOps场景之间联动价值。本期主要有8个场景联动类AIOps场景，详情如下：
2.4.1质量保障
2.4.1.1故障处理全流程联动
随着业务系统向云化、平台化、集群化演进，业务越来越复杂，组件越来越多，当出现故障的时候，排查需要大量的人力和时间，且解决起来非常复杂，因此基于故障处理的全流程联动，实现智能化就尤为重要。根据异常检测的结果，对可能出现的故障，结合关联规则(Apriori、FP-growth)、相似度计算(SBD)、xgboost分类算法、孤立森林(iForest)、指数加权移动平均(ewma)、岭回归(ridge)、平均绝对差算法(MAD)基于3倍统计标准差的动态基线等AI智能实时匹配根因分析流程，找到出现故障可能的原因，并针对根因进行故障自愈流程操作，实现故障处理全流程联动。当检测到异常时，快速匹配根因，调用故障自愈流程流程，实现联动。2.4.1.2容器生命周期全流程联动
随着业务不断增长，业务系统规模不断扩大，容器数量也在不断的增多。而针对众多的容器，即使是异常检测、故障自愈、容量预测等智能场景带来的工作量也是巨大的。因此，基于容器的CPU、内存、存储等性能指标和日志的实时及历史数据，通过DBSCAN聚类算法及Apriori关联挖掘等算法，构建相关指标的故障诊断模型，并针对实时的性能数据及日志进行故障诊断，在诊断出异常后调用故障自愈场景进行故障自愈，并在故障频发时引入容器智能扩缩容场景，自动判断是否由于性能瓶颈导致故障频发，并有针对性的进行容器扩缩容，实现容器从故障诊断到故障自愈再到智能扩缩容的全生命周期的智能场景联动，达到减少工作量、IT换人等目的。
2.4.1.3 IT资源池运营全流程联动2.4.1.3 IT资源池运营全流程联动
云资源池整体利用率不高，资源整合难度大，涉及因素多，步骤繁琐。基于IT云基础监控数据，对历史数据、约束条件进行深度分析和综合评估，实现资源趋势智能预测、资源智能整合优化、资源运行异常监测等功能，借助数智化手段达成大规模IT云最大化资源利用率的运营目标。
1.利用LSTM神经网络预测虚拟机资源使用率
2.利用相似度算法实现削峰填谷
3.利用剪枝算法进行虚拟机互斥性评估
4.利用装箱算法进行虚机迁移预演
5.基于无监督分类算法掌控资源池总体利用情况
6.基于AI算法检测资源异常使用情况
2.4.2效率提升
2.4.2.1事件工单处理全流程联动
随着营业一线需求迅猛增长，为了重视内部用户服务感知，打造面向B域内部用户的工单自处理服务，实现工单的自处理流程，确保IT支撑能力可以快速响应目标用户的需求。因此，基于客服工单数据、业务配置数据、资源配置数据、知识库等工单数据，利用大数据技术、NLP自然语言分析算法等，实现时间工单关键字分析，解析事件工单突出的问题，通过匹配业务知识库，对事件工单进行自动处理回复，加快服务效率，提升内部满意度。2.4.2.2知识管理全流程联动
运维知识（比如工单、案例、文档）往往都是很零散，运维对象（主机、容器、中间件、应用等）之间都是有关联的，运维对象和运维操作（诊断、修复等）也是分离的，目前缺乏一张图将彼此进行关联。通过引入知识图谱（运用编辑距离算法进行实体消歧）和自然语言处理技术，对运维零散的知识和对象进行抽取、解析、映射、融合，最终将运维知识和对象图谱化，增强知识与知识、知识与对象、对象与对象之间的关联。用户以自然语言方式（运用朴素贝叶斯分类算法进行意图识别）进行图谱问答，知识和对象以图谱化方式展示，由点到面、由面到点相互串联结合，实现知识管理全流程联动，通过图谱场景化应用开发平台，提供丰富的、基于运营场景的图谱数据，并实现图谱能力开放，提升一线人员故障定位和故障处理时的工作效率。
2.4.2.3智能应答全流程联动2.4.2.3智能应答全流程联动
目前知识查找、运维操作、故障咨询和推荐之间没有直接关联，非常不利于知识的结构化展现和系统化应用。通过将智能机器人、知识图谱、智能投诉分析三个单场景组合起来，形成一个多场景联动场景，以知识图谱为纽带，将知识库、工单库、作业平台、日志平台等运维相关系统关联起来。实现以运维对象为中心，聚合所有与之相关的运维知识、运维案例、运维工单和运维操作等的多场景联动。
2.4.3成本管理
2.4.3.1性能优化全流程联动