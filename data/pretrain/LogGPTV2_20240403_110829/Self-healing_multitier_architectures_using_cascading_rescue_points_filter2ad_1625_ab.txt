(cid:11)(cid:5)(cid:12)(cid:13)(cid:8)(cid:9)
(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)
(cid:4)(cid:21)(cid:14)(cid:21)(cid:5)
(cid:4)(cid:21)(cid:14)(cid:21)(cid:5)(cid:32)
(cid:28)(cid:29)(cid:30)(cid:30)(cid:1)(cid:14)(cid:12)(cid:31)
(cid:4)(cid:21)(cid:14)(cid:21)(cid:5)
(cid:4)(cid:21)(cid:14)(cid:21)(cid:5)
(cid:4)(cid:21)(cid:14)(cid:21)(cid:5)(cid:32)
(cid:25)(cid:26)
(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)
(cid:25)(cid:27)
(cid:28)(cid:22)(cid:29)(cid:5)(cid:11)
(cid:30)(cid:5)(cid:13)(cid:5)(cid:11)(cid:2)
(cid:11)(cid:5)(cid:12)(cid:5)(cid:18)(cid:13)(cid:5)(cid:4)
(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)
(cid:1)(cid:2)(cid:3)(cid:2)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)(cid:10)
(cid:24)(cid:24)(cid:24)(cid:24)
(cid:1)(cid:2)(cid:3)(cid:2)(cid:11)(cid:5)(cid:12)(cid:13)(cid:8)(cid:9)(cid:10)
(cid:24)(cid:24)(cid:24)(cid:24)
(cid:1)(cid:2)(cid:3)(cid:2)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)(cid:10)
(cid:24)(cid:24)(cid:24)(cid:24)
(cid:14)(cid:11)(cid:11)(cid:14)(cid:15)(cid:16)(cid:17)(cid:17)(cid:18)(cid:7)(cid:19)(cid:20)(cid:3)(cid:2)(cid:7)(cid:10)
(cid:24)(cid:24)(cid:24)(cid:24)
(cid:11)(cid:5)(cid:21)(cid:22)(cid:11)(cid:6)(cid:2)(cid:23)(cid:10)
Figure 3: A rescue point deployed on function
bug() of process p1 needs to both send and receive
data to and from p2. When an error triggers a
roll back, p1 can end up in an inconsistent state
with p2. Deploying rescue points in routines that
communicate with other parties over the network
can be problematic because their eﬀects cannot
be reversed.
Figure 4: Adopting a naive approach to address
the issue in Fig. 3 will not work. For exam-
ple, buﬀering the data being send from a rescue
point, and only transmitting them after deter-
mining that an error did not occur, can break
applications. In this case, p2 never receives the
data that will cause it to respond to p1.
error handling code written by the programmer to handle
expected error conditions, and directly or indirectly (e.g.,
through a function call) engulf code containing an unex-
pected fault. ASSURE proposed the use of existing error
handling code to gracefully handle unanticipated faults, vir-
tualizing in this manner error handling, by mapping the
larger set of unknown errors that can occur during execution
(e.g., invalid memory accesses and attacks) to the smaller set
of handled errors (e.g., a system call failing).
2.1.1 Discovering Rescue Points
ASSURE proposed a mechanism for automatically discov-
ering possible RPs and selecting the one that is more likely
to patch an observed error. The goal was to identify program
functions and returned error codes through fault injection.
Consider the function bug() in Fig. 2; bug() may return err1
or err2, if send() or recv() fail respectively. This designates
the function as a potential RP for errors occurring within
the function, or a function that it calls, because it can return
a valid error code to f2(), allowing it to handle an unantic-
ipated error, such as an out of bounds access of array that
could cause the application to crash.
The simplest way to detect unknown errors and initiate
the rescue point analysis is to intercept the signals (or excep-
tions in Windows OSs) that are raised when a serious error
such as an invalid memory reference occurs. In Linux, such
signals include SIGSEGV for memory faults, SIGFPE for
ﬂoating point errors like division by zero, etc. Software self-
healing can be also employed in conjunction with protection
mechanisms already incorporated in the application [10, 2,
22], or retroﬁtted on the binary after it was deployed [27,
15]. For example, ProPolice [10] uses the abort() system
call, which raises signal SIGABRT, when a stack smashing
attack is detected.
The primary goal of ASSURE was to automate the pro-
cess of discovering, selecting and deploying an RP, however
RPs can be also discovered manually. For example, the op-
erating system can be conﬁgured to produce a dump of the
memory image of processes crashing due to a memory viola-
tion error. This core dump can be manually analyzed by a
developer or administrator to determine the location of the
error [1] and look for an appropriate RP. While this process
is time consuming and requires user intervention, produc-
ing and distributing an actual software patch that corrects
the error at its source, frequently requires even more time
and resources. Security related patches can take as much as
two weeks from the date they have been disclosed [3], while
less critical faults that only aﬀect the availability of software
may take even longer [37].
2.1.2 Rescue Point Deployment
ASSURE relies on process-wide checkpoint/rollback based
on Zap [20] to create checkpoints, as well as to rollback to
a checkpoint when an error occurs. Because of Zap, the
overhead is little, but it is not extremely practical as it
requires modiﬁcations to the Linux kernel, and cannot be
dynamically installed and removed. In previous work [28],
we designed and implemented REASSURE a tool that sim-
pliﬁed the deployment of RPs. We built upon Intel’s Pin
dynamic instrumentation framework [18], to create a self-
contained mechanism that can dynamically deploy RPs on
binary-only software, for as as long as it is required. The use
of Pin enables us to attach to an already running application
to deploy a RP on demand, while we can also detach from
the application to apply a patch at runtime [19]. In this pa-
per, we build on our previous work to enable the application
of rescue points on multiparty software systems.
2.2 The Problem: Irreversible Side-effects
within Rescue Points
Previous software self-healing approaches cannot apply
rescue points on functions that have side eﬀects, such as
transmitting data to other entities on the network. Doing
so can result in inconsistent states between the communicat-
ing parties, as shown in Fig. 3, because the eﬀects of process
p1 sending a message to p2 cannot be undone. The problem
with this scenario is that the client’s state has been rolled
back and the client believes that an error, such as being un-
able to communicate with the server, occurred. However,
data has been exchanged with the server, which is oblivi-
ous of the error that occurred in the client. Depending on
the nature of the communicating applications this can lead
381
(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)
(cid:5)(cid:4)(cid:6)(cid:7)(cid:8)(cid:4)(cid:9)(cid:10)(cid:11)(cid:12)(cid:2)(cid:3)
(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)
(cid:7)(cid:2)(cid:8)(cid:9)(cid:5)(cid:6)
(cid:18)(cid:16)(cid:8)(cid:14)(cid:3)
(cid:13)(cid:11)(cid:14)(cid:14)(cid:15)(cid:16)(cid:7)(cid:17)
(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)
(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)
(cid:7)(cid:2)(cid:8)(cid:9)(cid:5)(cid:6)
(cid:13)(cid:11)(cid:14)(cid:14)(cid:15)(cid:16)(cid:7)(cid:17)
(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)
(cid:10)(cid:11)
(cid:10)(cid:12)
(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)
(cid:5)(cid:4)(cid:6)(cid:7)(cid:8)(cid:4)(cid:9)(cid:10)(cid:11)(cid:12)(cid:2)(cid:3)
(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)
(cid:7)(cid:2)(cid:8)(cid:9)(cid:5)(cid:6)
(cid:1)(cid:13)(cid:12)(cid:3)
(cid:5)(cid:4)(cid:6)(cid:7)(cid:8)(cid:4)(cid:9)(cid:10)(cid:11)(cid:12)(cid:2)(cid:3)
(cid:1)(cid:10)(cid:11)(cid:3)(cid:12)(cid:13)
(cid:14)(cid:7)(cid:15)(cid:8)(cid:2)(cid:1)(cid:1)(cid:16)(cid:8)(cid:17)(cid:2)(cid:8)(cid:18)(cid:10)(cid:15)(cid:19)(cid:3)(cid:20)(cid:19)(cid:3)(cid:21)
(cid:22)(cid:15)(cid:7)(cid:23)(cid:24)(cid:25)(cid:16)(cid:23)(cid:2)(cid:1)(cid:1)(cid:24)(cid:21)(cid:2)
(cid:26)(cid:2)(cid:1)(cid:1)(cid:24)(cid:21)(cid:2)(cid:16)(cid:27)(cid:17)(cid:19)(cid:25)(cid:2)(cid:16)(cid:8)(cid:17)(cid:2)(cid:8)(cid:18)(cid:10)(cid:15)(cid:19)(cid:3)(cid:20)(cid:19)(cid:3)(cid:21)
(cid:10)(cid:13)
(cid:13)(cid:11)(cid:14)(cid:14)(cid:15)(cid:16)(cid:7)(cid:17)
(cid:18)(cid:7)(cid:19)(cid:8)(cid:2)(cid:1)(cid:1)(cid:20)(cid:8)(cid:21)(cid:2)(cid:8)(cid:22)(cid:14)(cid:19)(cid:10)(cid:3)(cid:23)(cid:10)(cid:3)(cid:11)
(cid:24)(cid:19)(cid:7)(cid:25)(cid:12)(cid:13)(cid:20)(cid:25)(cid:2)(cid:1)(cid:1)(cid:12)(cid:11)(cid:2)
(cid:26)(cid:2)(cid:1)(cid:1)(cid:12)(cid:11)(cid:2)(cid:20)(cid:27)(cid:21)(cid:10)(cid:13)(cid:2)(cid:20)(cid:8)(cid:21)(cid:2)(cid:8)(cid:22)(cid:14)(cid:19)(cid:10)(cid:3)(cid:23)(cid:10)(cid:3)(cid:11)
(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)
(cid:7)(cid:2)(cid:8)(cid:9)(cid:5)(cid:6)
(cid:1)(cid:10)(cid:11)(cid:3)(cid:12)(cid:13)
(cid:14)(cid:15)
(cid:14)(cid:16)
(cid:14)(cid:17)
(a) Fault occurs. The next transmission from p1 to p2 will
notify the latter to also roll back. p2 will eventually notify
p3.
(b) No fault. When p1 exits the rescue point, it immediately
notiﬁes p2, which also exits checkpointing and notiﬁes p3,
and so forth.
Figure 5: Cascading rescue points overview. When process p2 receives a message from process p1, which
executes within a rescue point, it also begins checkpointing. Other processes, like p3, that receive messages
from a checkpointing process also begin checkpointing. This way the original rescue point cascades to the
communicating processes.
to various problems and can require additional mechanisms,
like transactions employed by database (DB) servers, for
restoring them to a consistent state. By consistent state, we
refer to every party having a correct view of what is the state
of their peer. For example, if p1 tries to issue a command to
and it fails, p1 can still think
p2 to switch it to statestate
that p2 is in statestate.
(cid:3)
Previous designs simply ignore data exchanges and rely
on the protocols implemented by applications to discover
and correct such inconsistencies (e.g., they use transactions).
Moreover, the problem cannot be trivially addressed by sim-
ply delaying the transmission of messages. Fig. 4 depicts an
example where the application expects to receive a response
to a message send from within a RP. Buﬀering the transmit-
ted message would break function bug(), causing it to fail or
wait forever because no data is sent as a response from p2.
3. CASCADING RESCUE POINTS
3.1 Overview
Self-healing using cascading rescue points aims to enable
applications participating in multitier architectures to self-
heal without facing the problems presented in Sec. 2.2. To
achieve this, we introduce a protocol, which is transparently
implemented over the application’s TCP connections. The
protocol encapsulates application data, and serves the sole
purpose of allowing us to convey signals between applica-
tions of the architecture.
Consider process p1 shown in Fig. 5. All of its communi-
cations with other processes in the architecture are modiﬁed
to implement our CRP protocol. When p1 executes within
a RP, it is essentially checkpointing, indicated by the high-
lighted areas in Fig. 5. This means that a fault will cause
all the changes performed within the RP to be undone, and
we will simulate the return of an error code from the RP
routine. When p1 transmits data to another process (while
in a RP), we use our protocol to instruct the remote peer to
also begin checkpointing. Later on, if an errors occurs in p1,
the RP will recover the process. Since we piggyback our pro-
tocol on existing communications, p1 does not immediately
notify p2 that it discarded the state generated in the RP,
and p2 will continue checkpointing until the next message
is received by p1. Figure 5(a) depicts this process, which is
propagating in time to the other processes. If p2 sends any
data to another process (e.g., p3 ), that process also begins
checkpointing, and so forth (see Sec 3.2 for limitations).
If no fault occurs, the process is almost entirely the same,
and it is shown in Fig. 5(b). Like before, the RP of p1 causes
the checkpointing to cascade to p2 and p3. However, in this
case no error occurs and p1 successfully exits the RP. When
this happens, we immediately notify the other processes by
utilizing TCP’s out-of-band (OOB) data [33]. OOB data
are not part of the regular data stream, so we can signal p2
and p3 without corrupting the application data stream and
without requiring data to be read by the processes. Instead,
we can rely on the OS to notify the process when such a
packet is received (e.g., by raising a signal or exception).
TCP does not support multiple OOB signals on a particular
stream (i.e., a second OOB would overwrite the ﬁrst and
would be the only one to raise a signal on the receiver).
For this reason, we can only use it to signal successful exits
from RPs. Our approach is an optimistic one, assuming that
errors will be rare.
We are planning to explore scenarios with more frequent
errors, e.g., when the application is under attack. One ap-
proach we are looking into is to be able to allow our pro-
tocol’s notiﬁcation system to adapt depending on the con-
ditions of the involved applications. For example, for pro-
cesses where errors are too frequent, the CRP protocol could
switch the notiﬁcation methods used for notifying the com-
municating processes for the events of successful or not exit
from an RP. The OOB signal used in the current CRP pro-
tocol as to notify the other processes for a successful exit
from a RP, could be used for the opposite purpose, i.e.,
to signal the rest of the processes to rollback to a previous
state. Consequently, the next transmission of data would
have to piggyback the signal for successful exit from a RP.
This new approach requires exploring other important fac-
tors ﬁrst, such as the necessary conditions under which the
switch of the notiﬁcation methods would make the CRP pro-
tocol more eﬀective.
3.2 Limitations: Overlapping Checkpoints
Our approach enables multiple processes in a multiparty
architecture to checkpoint in a loosely coordinated way. How-
ever, our goal is not to provide another algorithm for coor-
dinated checkpoint/restart for an unstructured distributed
or peer-to-peer system. Our approach is a good ﬁt for archi-
382
(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)
(cid:5)(cid:4)(cid:6)(cid:7)(cid:8)(cid:4)(cid:9)(cid:10)(cid:11)(cid:12)(cid:2)(cid:3)
(cid:18)(cid:16)(cid:8)(cid:14)(cid:3)
(cid:13)(cid:11)(cid:14)(cid:14)(cid:15)(cid:16)(cid:7)(cid:17)