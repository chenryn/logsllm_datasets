title:A Data-Driven Analysis and Tuning of a Live Hybrid CDN/V2V Video
Distribution System
author:Ishani Sarkar and
Soufiane Roubia and
Dino Martin L&apos;opez-Pacheco and
Guillaume Urvoy-Keller
A Data-Driven Analysis and Tuning
of a Live Hybrid CDN/V2V Video
Distribution System
Ishani Sarkar1,2(B), Souﬁane Roubia1, Dino Martin Lopez-Pacheco2,
and Guillaume Urvoy-Keller2
1 Easybroadcast, Nantes, France
PI:EMAIL
2 Universit´e Cˆote d’Azur, CNRS, I3S, Nice, France
Abstract. Video live streaming now represents over 34.97% of the Inter-
net traﬃc. Typical distribution architectures for this type of service heav-
ily rely on CDNs that enable to meet the stringent QoS requirements of
live video applications. As CDN-based solutions are costly to operate, a
number of solutions that complement CDN servers with WebRTC have
emerged. WebRTC enables direct communications between browsers
(viewers). The key idea is to enable viewer to viewer (V2V) video chunks
exchanges as far as possible and revert to the CDN servers only if the
video chunk has not been received before the timeout. In this work, we
present the study we performed on an operational hybrid live video sys-
tem. Relying on the per exchange statistics that the platform collects,
we ﬁrst present an high level overview of the performance of the system
in the wild. A key performance indicator is the fraction of V2V traﬃc of
the system. We demonstrate that the overall performance is driven by
a small fraction of users. By further proﬁling individual clients upload
and download performance, we demonstrate that the clients responsible
for the chunk losses, i.e. chunks that are not fully uploaded before the
deadline, have a poor uplink access. We devised a work-round strategy,
where each client evaluates its uplink capacity and refrains from sending
to other clients if its past performance is too low. We assess the eﬀec-
tiveness of the approach on the Grid5000 testbed and present live results
that conﬁrm the good results achieved in a controlled environment. We
are indeed able to reduce the chunk loss rate by almost a factor of two
with a negligible impact on the amount of V2V traﬃc.
1 Introduction
By 2022, the global video traﬃc in the Internet is expected to grow at a com-
pound annual growth rate of 29%, reaching an 82% share of all IP traﬃc [2].
The video content is usually delivered to the viewers using a content delivery
network (CDN). The huge amount of users puts a high pressure on the CDN
networks to ensure a good Quality of Experience (QoE) to the users. It also leads
to huge cost for the content owner. This is where a hybrid CDN/V2V (viewer-
to-viewer) architecture plays an important role. It allows sharing of the data
between diﬀerent viewers (browsers) while maintaining the QoE for the users.
c(cid:2) Springer Nature Switzerland AG 2021
O. Hohlfeld et al. (Eds.): PAM 2021, LNCS 12671, pp. 128–140, 2021.
https://doi.org/10.1007/978-3-030-72582-2_8
A Data-Driven Analysis and Tuning
129
This paper focuses on a commercial hybrid V2V-CDN system that oﬀers
video live streaming channels, where each channel is encoded in diﬀerent quality
levels. More precisely, we focus on the operations of the library that acts as a
proxy for fetching the video chunks for the video player. The library strives to
fetch the video chunks from other viewers watching the same content and reverts
to the CDN in case the chunk is not received fast enough. This operation is fully
transparent to the player, which is independent from the library and decides
the actual quality level based on the adaptive bitrate algorithm it implements,
according to the network conditions and/or the buﬀer level occupancy.
Our hybrid V2V-CDN architecture uses Web-RTC [3] for direct browser com-
munication and a central manager, see Fig. 1. The library is downloaded when the
user lands on the Web page of the TV channel. It ﬁrst uses the Internet Commu-
nication Exchange (ICE) protocol along with the STUN and TURN protocols
to ﬁnd its public IP address and port. The library then contacts the central
manager using the session description protocol (SDP) to provide its unique ID,
ICE data which includes reﬂexive address (public IP and port), and its playing
quality.
The manager sends to the library a
list of viewers watching the same con-
tent at the same quality level. Those
candidate neighbors, called a swarm,
are chosen in the same Internet Ser-
vice Provider (ISP) and/or in the
same geographic area as far as pos-
sible. The viewer will establish Web-
RTC [3] channels with up to 10 neigh-
bors. This maximum swarm size value
of 10 in our production system oﬀers
a good trade-oﬀ between the diversity of video chunks it oﬀers and the eﬀorts
needed to maintain those channels active.
Fig. 1. Overall hybrid V2V-CDN architec-
ture
When the video player asks for a new video chunk, the library selects the
source from which the chunk will be downloaded, either another viewer or a CDN
server if the chunk is not available in the swarm. We allow viewers to download
data from other viewers within a speciﬁed time period which is generally in the
order of the size of one video chunk. For example, in the channel used in this
paper, the size of one chunk is 6 s for the three diﬀerent encoding rates.
In terms of global synchronization of the live stream, there is no mechanism
to enforce that clients stay synchronized within a given time frame, but a new
video client, upon arrival, always asks for the latest available chunk whose id
is in the so-called manifest ﬁle (list of available chunks, materialized as URLs)
that the viewer downloads from the CDN server. Users have the possibility to
roll back in time. For the channel we proﬁle, the last 5 h of content is available
from the CDN servers. The library maintains a history of the last 30 chunks,
corresponding to about 3 min of content.
130
I. Sarkar et al.
Although hybrid V2V-CDN systems oﬀer a cost eﬀective alternative to a
pure CDN architecture, they need to achieve a trade-oﬀ between maintaining
video quality and a high fraction of video chunks delivered in V2V mode. Those
requirements are somehow contradicting as the V2V content delivery is easier
when the content (video chunks) is smaller in size, i.e. for lower video quality.
The contributions of this paper are as follows:
(i) We present detailed statistics of a 3-day period – with over 34,000 clients
and 6.TB of data exchanged – for a popular channel serviced by our com-
mercial live video distribution. We follow an event-based rather than a
time-based approach to select those days. Indeed, as the audience of a TV
channel varies greatly over time depending on the popularity of the content
that is broadcasted, we choose this 3-day period to oﬀer a variety of events,
in terms of connected viewers.
(ii) We question the eﬃciency of the system using three metrics: V2V Eﬃ-
ciency, which is the fraction of content sent in V2V mode, (application
level) Throughput and Chunk Loss Rate (CLR) which is the number of
chunks not received before the deadline. These metrics allow to evaluate
the eﬃciency of the library operations. They are speciﬁc to the evaluation
of the library and diﬀer from classical metrics used at the video player like
the number of stalled events and quality level ﬂuctuations.
(iii) We demonstrate that the root cause of the high observed CLR rate lies at
the uplink of some clients, rather than the actual network conditions. This
allows us to devise a mitigation strategy that we evaluate in a controlled
environment, to prove its eﬀectiveness and then deploy on the same channel
that we initially analyzed. We demonstrate that we are able to reduce the
observed chunk loss rate by almost 50% with a negligible impact on the
fraction of V2V traﬃc.
2 State of the Art
Several studies have demonstrated that Web-RTC can be successfully used for
live video streaming, e.g. [5,6]. The V2V protocol used in this work relies on
a mesh architecture to connect diﬀerent viewers together [4]. The V2V content
delivery protocol used applies a proactive approach, which means that the infor-
mation is disseminated in the V2V network as soon as a single viewer downloads
the information. The information is sent to other viewers by using the same
Web-RTC channel with a message called downloaded. So even if a viewer has not
yet requested the resource, it still has the information about all the resources
present in its V2V network.
There have been some large scale measurement studies on live video systems
done in the past. One of the most popular studies done on a P2P IPTV system is
[7] dates back to 2008. In this paper, the authors demonstrate that the current
Internet infrastructure was already able to support large P2P networks used
to distribute live video streams. They analysed the downloading and uploading
bitrate of the peers. They show that there is a lot of ﬂuctuation in the upload
A Data-Driven Analysis and Tuning
131
and download bitrate. They also found that the popularity of the content does
aﬀect the number of viewers and how easy or diﬃcult it is to ﬁnd other viewers.
In [8], the authors focused on the problems caused by P2P traﬃc to ISP
networks. This concern is in general addressed in hybrid V2V-CDN architectures
through a central manager that can apply simple strategies like oﬀering to a
viewer neighbors in the same ISP or geographic location.
3 Overall Channel Proﬁling
The TV channel we proﬁle in this study is a popular Moroccan channel serviced
by our hybrid V2V-CDN system, that oﬀers regular programs like TV series
and extraordinary events like football matches. Almost 50% of the clients are in
Morocco. The second most popular country is France which represents 15% of
the viewers. Italy, Spain, Netherlands, Canada, United States, Germany, Belgium
each hosts approximately 4% of the viewers, for a total of about 28% of users.
Watching the channel is free of charge. It is accessible using a Web browser only
(all browsers now support WebRTC), and not through a dedicated application
as can be the case of other channels. On average, 60% of the users use mobile
devices to view this channel, whereas 40% of the users use ﬁxed devices.
3.1 Data Set
Our reference data set aggregates three days (from Oct. 2020) of data. Two
days have no special events thus the distribution and size of the clients through-
out the day remains the same whereas on the third day there is an important
event which changes the distribution and size of the clients throughout the day.
The channel can be watched at three diﬀerent quality levels corresponding to
3.5 Mb/s for the smallest quality, 7 Mb/s for the intermediate quality and around
10 Mb/s for the highest quality. These quality levels are selected by the content
owner, not the library. Over these three days, we collected information on 34,816
client sessions. On a standard day, the total amount of data downloaded (in
CDN or V2V mode) varies between 1.5 and 2 TB whereas in case of big events,
the amount of data downloaded is between 6 and 6.5 TB. Figure 2 reports the
instantaneous aggregate bit rate over all the clients connected to the channel.
The average is at 34 MB/s (372 Mb/s) while for the peak event (a football
match), the aggregate throughput reaches 479 MB/s (3,8 Gb/s).
The V2V library reports to the manager detailed logs for all the resource
exchanges made by each viewer every 10 s. Over the 3 days, 4,615,045 chunks
have been exchanged. The manager later stores those records in a back-end
database. Each exchange is labelled with the mode (V2V or CDN) and in case
of V2V, the id of the remote viewer. We also have precise information about
the time it took to download the chunk or alternatively if a chunk loss event
occurred. In addition to per chunk exchange record, we also collect various player
level information as well like watching time, video quality level, operating system
(OS), browser, city, country, Internet service provider (ISP), etc. We also collect
132
I. Sarkar et al.
Fig. 2. Initial 3-day period
Fig. 3. V2V size bytes distribution
various other viewer information as well like to how many viewers a viewer is
connected to simultaneously (swarm size), how many consecutive uploads to the
other viewer has been done, rebuﬀering time, rebuﬀering count etc.
3.2 Clients Proﬁling and V2V Eﬃciency
The V2V paradigm directly inherits from the P2P paradigm where a signiﬁcant
problem was the selﬁshness of users [1]. We are not in this situation here as on one
side, the V2V library is under our control and second, the choice of a viewer to
request a chunk from, is done at random among the peers possessing this chunk.
Still, we observe a clearly biased distribution of viewers contribution with 1% of
the viewers responsible for over 90% of the bytes exchanged, as can be seen from
Fig. 3. This bias in the contribution is in fact related to the time actually spent
by the user watching the channel. We report session times in Fig. 4. Since most
of the V2V data is sent by only 1% of the viewers, we compare the session time
of all the viewers with these 1% of most active viewers. We can readily observe
in Fig. 4 that the top 1% active viewers feature a bimodal distribution of session
time with around 25% of clients staying less than 1 min and the rest staying in
general between 30 min and a few hours. In contrast, the overall distribution (all
users) is dominated by short session times with 60% of users staying less than
10 min.
Another factor that is likely to heavily aﬀect the viewer ability to perform
eﬀective V2V exchanges is its network access characteristics. As part of the
content is downloaded from the CDN servers which are likely to be close to the
client and feature good network performance, the average throughput achieved
during chunks downloads from the CDN provides a good hint on the network
access capacity of the user. Note that as a chunk is several MB large, the resulting
throughput should be statistically meaningful.
As we see from Fig. 6, there is a signiﬁcant diﬀerence between the CDN
bitrates of the overall viewers and most active 1% viewers, which experience
way higher throughputs. The correlation coeﬃcients between CDN bitrate and
chunk loss rate (CLR) for overall viewers is −0.47 and for most active top 1%
viewers, it is −0.7. Ideally, one expects this value to be indeed negative as the
better the access link of the user is, the less likely it is to miss the deadline when
sending or receiving a chunk. From this perspective, the CLR is highly correlated
A Data-Driven Analysis and Tuning
133
with the CDN throuhgput performance for the top 1% of users, hinting that this
metric is a good estimator of the reception quality.
The actual chunk lost rate (CLR) of the overall viewers and most active
viewers are reported in Fig. 5. We can clearly observe that for the most active
1% of users, the distribution is skewed to the left. Indeed, over 50% of these
users experience less than 20% CLR, while the others experience a CLR roughly
uniformly distributed between 20 and 75%.
To further understand the observed CLR, and how to reduce it, we carry a
detailed study the CLR in the next section.
Fig. 4. Watching time distribution
Fig. 5. Lost chunk rate distribution
Fig. 6. CDN bandwidth distribution
Fig. 7. Viewer’s neighbour set size
4 Detailed Analysis of Chunk Loss Rate (CLR)
We focus in this section on the 1% most active users viewers with more than
1 min session time. We formulated hypotheses to identify the root causes behind
the observed lost data chunks:
– H1: The swarm size aﬀects the lost chunk rate of a viewer, because the bigger
the swarm size, the more control messages you receive, thus more network
traﬃc resulting in a higher CLR.
– H2: The type of client access aﬀects the lost chunk rate. Ideally, we would like
to know the exact type of network access the client is using: Mobile, ADLS,
FTTH. The library is not able (allowed) to collect such information. We can
however classify clients as mobile or ﬁxed lines clients based on the user-agent
HTTP string.
134
I. Sarkar et al.
– H3: The network access link characteristics directly aﬀects the CLR. We
already studied the download rate of the users using the transfers made with
the CDN servers. The download and especially the upload rates achieved
during V2V exchanges can also be used to understand the characteristics of
the client access link.