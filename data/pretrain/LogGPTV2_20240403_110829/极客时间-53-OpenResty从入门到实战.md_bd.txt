## SystemtapSystemtap 有自己的DSL，也就是小语言，可以用来设置探测点。在介绍更多的内容之前，为了不仅仅停留在抽象的概念上，让我们先来安装下Systemtap 吧。这里，用系统的包管理器来安装就可以了：    sudo apt install systemtap我们再来看下，用 Systemtap 写的 hello world 程序是什么样子的：    
# cat hello-world.stpprobe begin{  print("hello world!")  exit()}是不是很简单？不过，你需要使用 sudo 权限才可以运行：    sudo stap hello-world.stp它会打印出我们想要的 `hello world!` 。在大部分场景下，我们都不需要自己写stap 脚本来进行分析，因为 OpenResty 已经有了很多现成的 stap脚本来做常规的分析，下节课我就会为你介绍这些脚本。所以，今天我们只用对stap 脚本有一个简单的认识就行了。操作了几下后，回到我们的概念上来。Systemtap 的工作原理，是将上述 stap脚本转换为 C，运行系统 C 编译器来创建 kernel模块。当模块被加载的时候，它会通过 hook内核的方式，来激活所有的探测事件。比如，刚刚这个示例代码中的 `probe` 就是一个探针。`begin`会在探测的最开始运行，与之对应的是 `end`，所以上面的 `hello world`程序也可以写成下面的这种方式：    probe begin{  print("hello ")  exit()} probe end{print("world!") 这里，我只对 Systemtap 进行了非常粗浅的介绍。其实，Systemtap 的作者Frank Ch. Eigler 写了一本电子书《Systemtap tutorial》，详细地介绍了Systemtap。如果你想进一步地学习和深入了解Systemtap，那么我建议，从这本书开始入手，就是最好的学习路径。
## 其他动态追踪框架当然，对于内核和性能分析工程师来说，只有 Systemtap 还是不够用的。首先，Systemtap并没有默认进入系统内核；其次，它的工作原理决定了它的启动速度比较慢，而且有可能对系统的正常运行造成影响。eBPF（extended BPF）则是最近几年 Linux 内核中新增的特性。相比Systemtap，eBPF有内核直接支持、不会死机、启动速度快等优点；同时，它并没有使用DSL，而是直接使用了 C 语言的语法，所以也大大降低了它的上手难度。除了开源的解决方案外，Intel 出品的 VTune也是神兵利器之一。它直观的界面操作和数据展示，可以让你不写代码也能分析出性能的瓶颈。
## 火焰图最后，让我们再来回忆下前面课程中提到过的火焰图。前面我们也提到过，perf和 Systemtap等工具产生的数据，都可以通过火焰图的方式，来进行更加直观的展示。下面这张图就是火焰图的示例：![](Images/6aa53a7139ecbfbc946feeea026f9c6d.png){savepage-src="https://static001.geekbang.org/resource/image/6e/32/6e72452ac3b97d46a44234d41993c832.png"}在火焰图中，色块的颜色和深浅都是没有意义的，只是为了对不同的色块儿做出简单的区分。火焰图其实是把每次采样的数据进行叠加，所以，真正有意义的是色块的宽度和长度。对于 on CPU 火焰图来说，色块的宽度是函数占用的 CPU时间百分比，色块越宽，则说明性能消耗越大。如果出现一个平顶的山峰，那它就是性能的瓶颈所在。而色块的长度，代表的是函数调用的深度，最顶端的框显示正在运行的函数，在它之下的都是这个函数的调用者。所以，在下面的函数是上面函数的父函数，山峰越高，则说明调用的函数层级越深。为了让你更透彻掌握火焰图这个利器，在后面的视频课中，我会用一个真实的代码案例，给你演示，如何使用火焰图来找出性能的瓶颈并解决它。
## 最后要知道，哪怕是动态跟踪这种无侵入的技术，也并不是完美的。它只能检测某一个单独的进程，而且一般情况下，我们只短暂开启它，以使用这段时间内的采样数据。所以，如果你需要跨越多个服务，或者是进行长时间的检测，还是需要opentracing 这样的分布式追踪技术。不知道你在平时的工作中，都使用到了哪些调试工具和技术呢？欢迎留言和我讨论，也欢迎你把这篇文章分享给你的朋友，我们一起学习和进步。![](Images/12bf8dad402b50769d64b4fa7ee66191.png){savepage-src="https://static001.geekbang.org/resource/image/e5/95/e55bae60140f9cfa5649bb637421d595.jpg"}
# 37 \| systemtap-toolkit和stapxx：如何用数据搞定"疑难杂症"？你好，我是温铭。正如上节课介绍过的，作为服务端开发工程师，我们并不会对动态调试的工具集做深入的学习，大都是停留在使用的这个层面上，最多去编写一些简单的stap 脚本。更底层的，比如 CPU缓存、体系结构、编译器等，那就是性能工程师的领域了。在 OpenResty 中有两个开源项目：`openresty-systemtap-toolkit` 和 `stapxx`。它们是基于 Systemtap 封装好的工具集，用于 Nginx 和 OpenResty的实时分析和诊断。它们可以覆盖 on CPU、offCPU、共享字典、垃圾回收、请求延迟、内存池、连接池、文件访问等常用的功能和调试场景。在今天这节课中，我会带你浏览下这些工具和对应的使用方法，目的是帮你在遇到Nginx 和 OpenResty 的疑难杂症时，可以快速找到定位问题的工具。在OpenResty的世界中，学会使用这些工具是你进阶的必经之路，也是和其他开发者沟通的非常有效的方式------毕竟，工具产生的数据，会比你用文字描述更加准确和详尽。不过，需要特别注意的是，OpenResty 的最新版本 1.15.8 默认开启了 LuaJITGC64 模式，但是 `openresty-systemtap-toolkit` 和 `stapxx`并没有跟着做对应的修改，这就会导致里面的工具都无法正常使用。所以，你最好在OpenResty 旧的 1.13 版本中来使用这些工具。``{=html}开源项目的贡献者大都是兼职身份，他们并没有义务来保证这些工具可以一直正常使用，这也是你在使用开源项目时候需要意识到的一点。
## 以共享字典为例按照惯例，我先用一个你最熟悉的、也是上手最简单的工具`ngx-lua-shdict`，来作为今天开篇的示例。`ngx-lua-shdict` 这个工具，可以分析 Nginx的共享内存字典，并且追踪字典的操作。你可以用 `-f` 选项指定 dict 和key，来获取共享内存字典里面的数据。 `--raw` 选项可以导出指定 key的原始值。下面是一个从共享内存字典中获取数据的命令行示例：    
# 假设 nginx worker pid 是 5050$ ./ngx-lua-shdict -p 5050 -f --dict dogs --key Jim --luajit20Tracing 5050 (/opt/nginx/sbin/nginx)... type: LUA_TBOOLEANvalue: trueexpires: 1372719243270flags: 0xa类似的，你可以用 `-w`选项，来追踪指定 key 的字典写操作：    $./ngx-lua-shdict -p 5050 -w --key Jim --luajit20Tracing 5050 (/opt/nginx/sbin/nginx)... Hit Ctrl-C to end set Jim exptime=4626322717216342016replace Jim exptime=4626322717216342016^C让我们看看这个工具是怎么实现的吧。`ngx-lua-shdict` 是一个 perl的脚本，但具体的实现和 perl 并没有关系，perl 只是被用来生成了 stap脚本并运行起来：    open my $in, "|stap $stap_args -x $pid -" or die "Cannot run stap: $!\n";你完全可以用 Python、PHP、Go 或者你喜欢的任何语言来编写。stap脚本中，比较关键的地方是下面这行代码：    probe process("$nginx_path").function("ngx_http_lua_shdict_set_helper")这就是我们在上节课中提到的探针`probe`，探测的是`ngx_http_lua_shdict_set_helper` 这个函数。而这个函数的调用，都是在`lua-nginx-module` 模块的 `lua-nginx-module/src/ngx_http_lua_shdict.c`文件中：    static intngx_http_lua_shdict_add(lua_State *L){return ngx_http_lua_shdict_set_helper(L, NGX_HTTP_LUA_SHDICT_ADD);} static intngx_http_lua_shdict_safe_add(lua_State *L){return ngx_http_lua_shdict_set_helper(L, NGX_HTTP_LUA_SHDICT_ADD|NGX_HTTP_LUA_SHDICT_SAFE_STORE);} static intngx_http_lua_shdict_replace(lua_State *L){return ngx_http_lua_shdict_set_helper(L, NGX_HTTP_LUA_SHDICT_REPLACE);}这样，我们只要探测这个函数，就可以追踪到共享字典的所有操作了。
## on CPU 和 off CPU在使用 OpenResty的过程中，你最常遇到的应该就是性能问题了把。性能比较差，也就是 QPS很低的表现主要有两类，CPU 占用过高和 CPU占用过低。前者的瓶颈，可能是没有使用我们之前介绍过的性能优化的方法；而后者可能是因为使用了阻塞函数。相对应的，onCPU 和 off CPU 火焰图，可以帮助我们确认最终的根源所在。要生成 C 级别的 on CPU 火焰图，你需要使用 systemtap-toolkit中的`sample-bt`；而 Lua 级别的 on CPU 火焰图，则是由 stapxx 中的`lj-lua-stacks` 来生成的。我们以 `sample-bt` 为例来介绍下如何使用。`sample-bt`这个脚本，可以对你指定的任意用户进程（不仅限于 Nginx 和 OpenResty进程），来进行调用栈的采样。例如，我们可以用下列代码，对一个正在运行的 Nginx worker 进程（PID 是8736）采样 5 秒钟：    $ ./sample-bt -p 8736 -t 5 -u > a.btWARNING: Tracing 8736 (/opt/nginx/sbin/nginx) in user-space only...WARNING: Missing unwind data for module, rerun with 'stap -d stap_df60590ce8827444bfebaf5ea938b5a_11577'WARNING: Time's up. Quitting now...(it may take a while)WARNING: Number of errors: 0, skipped probes: 24它输出的结果文件 a.bt， 可以使用 FlameGraph 工具集来生成火焰图:    stackcollapse-stap.pl a.bt > a.cbtflamegraph.pl a.cbt > a.svg这里的`a.svg`，就是生成的火焰图，你可以用浏览器打开查看。不过要注意，在采样期间，我们需要保持一定的请求压力，否则采样数为0 的话，就没办法生成火焰图了。接着我们再来看下如何采样 off CPU，你需要使用的脚本是 systemtap-toolkit中的 `sample-bt-off-cpu`。它的使用方法和 `sample-bt`类似，我也写在了下面的代码中：    $ ./sample-bt-off-cpu -p 10901 -t 5 > a.btWARNING: Tracing 10901 (/opt/nginx/sbin/nginx)...WARNING: _stp_read_address failed to access memory locationWARNING: Time's up. Quitting now...(it may take a while)WARNING: Number of errors: 0, skipped probes: 23在 stapxx中，分析延迟的工具是`epoll-loop-blocking-distr`，它会对指定的用户进程进行采样，并输出连续的`epoll_wait` 系统调用之间的延迟分布：    $ ./samples/epoll-loop-blocking-distr.sxx -x 19647 --arg time=60Start tracing 19647...Please wait for 60 seconds.Distribution of epoll loop blocking latencies (in milliseconds)max/avg/min: 1097/0/0value |-------------------------------------------------- count    0 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@  18471    1 |@@@@@@@@                                            3273    2 |@                                                    473    4 |                                                     119    8 |                                                      67   16 |                                                      51   32 |                                                      35   64 |                                                      20  128 |                                                      23  256 |                                                       9  512 |                                                       2 1024 |                                                       2 2048 |                                                       0 4096 |                                                       0你可以看到，这个输出结果显示，绝大部分延迟都小于 1 毫秒，但也有少数是在200 毫秒以上的，这些就是需要关注的。
## 上游和阶段跟踪除了 OpenResty 的代码本身可能出现性能问题外，当 OpenResty 通过`cosocket` 或者 `proxy_pass`这样的上游模块，与上游服务进行通信时，如果上游服务自身的延时比较大，也会对整体的性能带来很大的影响。这个时候，你可以使用 `ngx-lua-tcp-recv-time`、`ngx-lua-udp-recv-time` 和`ngx-single-req-latency` 这几个工具来进行分析，这里我以`ngx-single-req-latency` 为例解释下。这个工具和工具集里面的大部分工具并不太一样。其他工具，多是基于大量的采样和统计分析，得出一个数学上的分布结论。而`ngx-single-req-latency` 分析的却是单个的请求，跟踪出单个请求在OpenResty 中各个阶段的耗时，比如 rewrite、access、content阶段以及上游的耗时。我们可以来看一个具体的示例代码：    