title:Predicting the Resource Consumption of Network Intrusion Detection
Systems
author:Holger Dreger and
Anja Feldmann and
Vern Paxson and
Robin Sommer
Predicting the Resource Consumption of
Network Intrusion Detection Systems
Holger Dreger1, Anja Feldmann2, Vern Paxson3,4, and Robin Sommer4,5
1 Siemens AG, Corporate Technology
2 Deutsche Telekom Labs / TU Berlin
3 UC Berkeley
4 International Computer Science Institute
5 Lawrence Berkeley National Laboratory
Abstract. When installing network intrusion detection systems (NIDSs), opera-
tors are faced with a large number of parameters and analysis options for tuning
trade-offs between detection accuracy versus resource requirements. In this work
we set out to assist this process by understanding and predicting the CPU and
memory consumption of such systems. We begin towards this goal by devising a
general NIDS resource model to capture the ways in which CPU and memory us-
age scale with changes in network trafﬁc. We then use this model to predict the re-
source demands of different conﬁgurations in speciﬁc environments. Finally, we
present an approach to derive site-speciﬁc NIDS conﬁgurations that maximize the
depth of analysis given predeﬁned resource constraints. We validate our approach
by applying it to the open-source Bro NIDS, testing the methodology using real
network data, and developing a corresponding tool, nidsconf, that automati-
cally derives a set of conﬁgurations suitable for a given environment based on a
sample of the site’s trafﬁc. While no automatically generated conﬁguration can
ever be optimal, these conﬁgurations provide sound starting points, with promise
to signiﬁcantly reduce the traditional trial-and-error NIDS installation cycle.
1 Introduction
Operators of network intrusion detection systems (NIDSs) face signiﬁcant challenges
in understanding how to best conﬁgure and provision their systems. The difﬁculties
arise from the need to understand the relationship between the wide range of analy-
ses and tuning parameters provided by modern NIDSs, and the resources required by
different combinations of these. In this context, a particular difﬁculty regards how re-
source consumption intimately relates to the speciﬁcs of the network’s trafﬁc—such as
its application mix and its changes over time—as well as the internals of the particular
NIDS in consideration. Consequently, in our experience the operational deployment of
a NIDS is often a trial-and-error process, for which it can take weeks to converge on an
apt, stable conﬁguration.
In this work we set out to assist operators with understanding resource consumption
trade-offs when operating a NIDS that provides a large number of tuning options. We
begin towards our goal by devising a general NIDS resource model to capture the ways
in which CPU and memory usage scale with changes in network trafﬁc. We then use
R. Lippmann, E. Kirda, and A. Trachtenberg (Eds.): RAID 2008, LNCS 5230, pp. 135–154, 2008.
c(cid:2) Springer-Verlag Berlin Heidelberg 2008
136
H. Dreger et al.
this model to predict the resource demands of different conﬁgurations for speciﬁc envi-
ronments. Finally, we present an approach to derive site-speciﬁc NIDS conﬁgurations
that maximize the depth of analysis given predeﬁned resource constraints.
A NIDS must operate in a soft real-time manner, in order to issue timely alerts and
perhaps blocking directives for intrusion prevention. Such operation differs from hard
real-time in that the consequences of the NIDS failing to “keep up” with the rate of
arriving trafﬁc is not catastrophe, but rather degraded performance in terms of some
trafﬁc escaping analysis (“drops”) or experiencing slower throughput (for intrusion pre-
vention systems that forward trafﬁc only after the NIDS has inspected it). Soft real-time
operation has two signiﬁcant implications in terms of predicting the resource consump-
tion of NIDSs. First, because NIDSs do not operate in hard real-time, we seek to avoid
performance evaluation techniques that aim to prove compliance of the system with
rigorous deadlines (e.g., assuring that it spends no more than T microseconds on any
given packet). Given the very wide range of per-packet analysis cost in a modern NIDS
(as we discuss later in this paper), such techniques would severely reduce our estimate
of the performance a NIDS can provide in an operational context. Second, soft real-
time operation means that we also cannot rely upon techniques that predict a system’s
performance solely in terms of aggregate CPU and memory consumption, because we
must also pay attention to instantaneous CPU load, in order to understand the degree
to which in a given environment the system would experience degraded performance
(packet drops or slower forwarding).
When modeling the resource consumption of a NIDS, our main hypothesis concerns
orthogonal decomposition: i.e., the major subcomponents of a NIDS are sufﬁciently
independent that we can analyze them in isolation and then extrapolate aggregate be-
havior as the composition of their individual contributions. In a different dimension, we
explore how the systems’ overall resource requirements correlate to the volume and the
mix of network trafﬁc. If orthogonal decomposition holds, then we can systematically
analyze a NIDS’ resource consumption by capturing the performance of each subcom-
ponent individually, and then estimating the aggregate resource requirements as the sum
of the individual requirements. We partition our analysis along two axes: type of analy-
sis, and proportion of connections within each class of trafﬁc. We ﬁnd that the demands
of many components scale directly with the prevalence of a given class of connections
within the aggregate trafﬁc stream. This observation allows us to accurately estimate
resource consumption by characterizing a site’s trafﬁc “mix.” Since such mixes change
over time, however, it is crucial to consider both short-term and long-term ﬂuctuations.
We stress that, by design, our model does not incorporate a notion of detection qual-
ity, as that cannot reasonably be predicted from past trafﬁc as resource usage can. We
focus on identifying the types of analyses which are feasible under given resource con-
straints. With this information the operator can assess which option promises the largest
gain for the site in terms of operational beneﬁt, considering the site’s security policy and
threat model.
We validate our approach by applying it
to Bro, a well-known, open-source
NIDS [7]. Using this system, we verify the validity of our model using real network
data, and develop a corresponding prototype tool, nidsconf, to derive a set of conﬁg-
urations suitable for a given environment. The NIDS operator can then examine these
Predicting the Resource Consumption of NIDSs
137
conﬁgurations and select one that best ﬁts with the site’s security needs. Given a rela-
tively small sample of a site’s trafﬁc, nidsconf performs systematic measurements on
it, extrapolates a set of possible NIDS conﬁgurations and estimates their performance
and resource implications. In a second stage the tool is also provided with a longer-term
connection-level log ﬁle (such as produced by NetFlow). Given this and the results from
the systematic measurements, the tool can project resource demands of the NIDS’ sub-
components without actually running the NIDS on long periods of trafﬁc. Thus the
tool can be used not only to derive possible NIDS conﬁgurations but also to estimate
when, for a given conﬁguration and a given estimation of trafﬁc growth, the resources
of the machine running the NIDS will no longer sufﬁce. While we do not claim that
nidsconf always produces optimal conﬁgurations, we argue that it provides a sound
starting point for further ﬁne-tuning.
We structure the remainder of this paper as follows. In §2 we use an example to
demonstrate the impact of resource exhaustion. In §3 we introduce our approach, and
validate its underlying premises in §4 by using it to predict the resource usage of the Bro
NIDS. In §5 we present our methodology for predicting the resource consumption of a
NIDS for a speciﬁc target environment, including the automatic derivation of suitable
conﬁgurations. We discuss related work in §6 and conclude in §7.
2 Impact of Resource Exhaustion
We begin with an examination of how resource exhaustion affects the quality of network
security monitoring, since this goes to the heart of the problem of understanding the onset
and signiﬁcance of degraded NIDS performance. We do so in the context of the behavior
of the open-source Bro NIDS [7] when it runs out of available CPU cycles or memory.
CPU Overload. The primary consequence of CPU overload are packet drops, and thus
potentially undetected attacks. As sketched above, a NIDS is a soft real-time system:
it can buffer packets for a certain (small) amount of time, which enables it to tolerate
sporadic processing spikes as long as trafﬁc arriving in the interim ﬁts within the buffer.
On average, however, processing needs to keep up with the input stream to avoid chronic
overload and therefore packets drops. To understand the correlation between packet
drops and CPU load, we run the Bro NIDS live on a high-volume network link (see §4)
using a conﬁguration that deliberately overloads the host CPU in single peaks. We then
correlate the system’s CPU usage with the observed packet drops.
Figure 1 shows the real-time (Y-axis) that elapses while Bro processes each second
of network trafﬁc (X-axis). The vertical lines denote times at which the packet capture
facility (libpcap) reports drops; the corresponding CPU samples are shown with a ﬁlled
circle.
The NIDS can avoid drops as long as the number of processing outliers remains
small—more precisely, as long as they can be compensated by buffering of captured
packets. For example, the 20MB buffer used in our evaluations enabled us to process
an extreme outlier—requiring 2.5 s for one real-time second worth of network trafﬁc—
without packet drops. Accordingly, we ﬁnd that the ﬁrst packet drop occurs only after
a spike in processing real time of more than 4s. Closer inspection shows that the loss
138
H. Dreger et al.
normal sample
sample with packet drops
c
i
f
f
a
r
t
.
c
e
s
r
e
p
d
e
s
p
a
e
l
]
s
[
e
m
i
t
l
a
e
R
4
3
2
1
0
0
200
400
600
800
1000
1200
Network time elapsed [s]
Fig. 1. Relation between elapsed real-time and packet drops
does not occur immediately during processing the “expensive” trafﬁc but rather six
network seconds later. It is only at that point that the buffer is completely full and
the lag (i.e., how far the NIDS is behind in its processing) exceeds 5.5s. Such a large
amount of buffering thus makes it difﬁcult to predict the occurrence of drops and their
likely magnitude: (i) the buffer can generally absorb single outliers, and (ii) the buffer
capacity (in seconds) depends on the trafﬁc volume yet to come. But clearly we desire
to keep the lag small.
Memory Exhaustion. When a stateful NIDS completely consumes the memory avail-
able to it, it can no longer effectively operate, as it cannot store additional state. It can,
however, try to reclaim memory by expiring existing state. The challenges here are
(i) how to recognize that an exhaustion condition is approaching prior to its actual on-
set, (ii) in the face of often complex internal data structures [3], and then (iii) locating
apt state to expire that minimizes the ability for attackers to leverage the expiration for
evading detection.
One simple approach for limiting memory consumption imposes a limit on the size
of each internal data structure. Snort [8], for example, allows the user to specify a
maximum number of concurrent connections for its TCP preprocessor. If this limit is
reached, Snort randomly picks some connections and ﬂushes their state to free up mem-
ory. Similarly, Snort addresses the issue of variable stream reassembly size by providing
an option to limit the total number of bytes in the reassembler. Bro on the other hand
does not provide a mechanism to limit the size of data structures to a ﬁxed size; its state
management instead relies on timeouts, which can be set on a per-data structure basis,
and with respect to when state was ﬁrst created, or last read or updated. However, these
do not provide a guarantee that Bro can avoid memory exhaustion, and thus it can crash
in the worst case. Bro does however include extensive internal memory instrumenta-
tion [3] to understand its consumption, which we leverage for our measurements.
Memory consumption and processing lag can become coupled in two different ways.
First, large data structures can take increasingly longer to search as they grow in size,
increasing the processing burden. Second, in systems that provide more virtual memory
than physical memory, consuming the entire physical memory does not crash the system
but instead degrades its performance due to increased paging activity. In the worst case,
such systems can thrash, which can enormously diminish real-time performance.
Predicting the Resource Consumption of NIDSs
139
3 Modeling NIDS Resource Usage
In this section we consider the high-level components that determine the resource usage
of a NIDS. We ﬁrst discuss the rationale that leads to our framing of the components,
and then sketch our resulting distillation. The next section proceeds to evaluate the
framework against the Bro NIDS.
3.1 The Structure of NIDS Processing
Fundamental to a NIDS’s operation is tracking communication between multiple net-
work endpoints. All major NIDS’s today operate in a stateful fashion, decoding network
communication according to the protocols used, and to a degree mirroring the state
maintained by the communication endpoints. This state naturally grows proportional to
the number of active connections1, and implementations of stateful approaches are nat-
urally aligned with the network protocol stack. To reliably ascertain the semantics of an
application-layer protocol, the system ﬁrst processes the network and transport layers of
the communication. For example, for HTTP the NIDS ﬁrst parses the IP header (to ver-
ify checksums, extract addresses, determine transport protocol, and so on) and the TCP
header (update the TCP state machine, checksum the payload), and then reassembles
the TCP byte stream, before it can ﬁnally parse the HTTP protocol.
A primary characteristic of the network protocol stack is its extensive use of en-
capsulation: individual layers are independent of each other; while their input/output
is connected, there ideally is no exchange of state between layers. Accordingly, for
a NIDS structured along these lines its protocol-analyzing components can likewise
operate independently. In particular, it is plausible to assume that the total resource
consumption, in terms of CPU and memory usage, is the sum of the demands of the
individual components. This observation forms a basis for our estimation methodology.
In operation, a NIDS’s resource usage primarily depends on the characteristics of
the network trafﬁc it analyzes; it spends its CPU cycles almost exclusively on analyzing
input trafﬁc, and requires memory to store results as it proceeds. In general, network
packets provide the only sustained stream of input during operation, and resource usage
therefore should directly reﬂect the volume and content of the analyzed packets.2
We now hypothesize that for each component of a NIDS that analyzes a partic-
ular facet or layer of network activity—which we term an analyzer—the relation-
ship between input trafﬁc and the analyzer’s resource demands is linear. Let t0 be
the time when NIDS operation begins, and Pt the number of input packets seen up
to time t ≥ t0. Furthermore, let Ct be the total number of transport-layer connec-
tions seen up to time t, and ct the number of connections currently active at time t.
Then we argue: Network-layer analyzers operate strictly on a per-packet basis, and so
should require O(Pt) CPU time, and rarely store state. (One exception concerns re-
assembly of IP fragments; however, in our experience the memory required for this is
1 For UDP and ICMP we assume ﬂow-like deﬁnitions, similar to how NetFlow abstracts
packets.
2 In this work, we focus on stand-alone NIDSs that analyze trafﬁc and directly report alerts. In
more complex setups (e.g., with distributed architectures) resource consumption may depend
on other sources of input as well.
140
H. Dreger et al.
negligible even in large networks.) Transport-layer analyzers also operate packet-wise.
Thus, their amortized CPU usage will scale as O(Pt). However, transport-layer analyz-
ers can require signiﬁcant memory, such as tracking TCP sequence numbers, connection
states, and byte streams. These analyzers therefore will employ data structures to store
all currently active connections, requiring O(max(ct)) memory. For stream-based pro-
tocols, the transport-layer performs payload reassembly, which requires memory that
scales with O(max(ct · mt)), where mt represents the largest chunk of unacknowl-
edged data on any active connection at time t (cf. [1]). Finally, application-layer ana-
lyzers examine the payload data as reconstructed by the transport layer. Thus, their CPU
time scales proportional to the number of connections, and depends on how much of the
payload the analyzer examines. (For example, an HTTP analyzer might only extract the
URL in client requests, and skip analysis of the much larger server reply.) The total size
of the connection clearly establishes an upper limit. Accordingly, the state requirements
for application analyzers will depend on the application protocol and will be kept on a
per-connection basis, so will scale proportional to the protocol mix (how prevalent the
application is in the trafﬁc stream) and the number of connections ct.
In addition to protocol analyzers, a NIDS may perform inter-connection correlation.
For example, a scan detector might count connections per source IP address, or an FTP
session analyzer might follow the association between FTP client directives and subse-
quent data-transfer connections. In general, the resource usage of such analyzers can be
harder to predict, as it will depend on speciﬁcs of the analysis (e.g., the scan detector