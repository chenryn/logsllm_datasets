title:Probabilistic Validation of an Intrusion-Tolerant Replication System
author:Sankalp Singh and
Michel Cukier and
William H. Sanders
Probabilistic Validation of an Intrusion-Tolerant Replication System∗
‡
, Michel Cukier
†
Sankalp Singh
†
University of Illinois
Urbana, IL 61801, USA
{sankalps,whs}@crhc.uiuc.edu
, and William H. Sanders
†
‡
University of Maryland
College Park, MD 20742, USA
PI:EMAIL
Abstract
As computer systems become more complex and more
widely distributed, it is becoming increasingly difﬁcult to
remove all vulnerabilities that can potentially be exploited
by intruders. Intrusion tolerance is an emerging approach
that aims to enable systems to continue functioning in spite
of successful intrusions. Before intrusion tolerance is ac-
cepted as an approach to security, there must be quanti-
tative techniques to measure its efﬁcacy. However, there
have been very few attempts at quantitative validation of
intrusion-tolerant systems or, for that matter, of security in
general. In this paper, we show that probabilistic valida-
tion through stochastic modeling is an attractive mecha-
nism for evaluating intrusion tolerance. We demonstrate
our approach by using stochastic activity networks to quan-
titatively validate an intrusion-tolerant replication manage-
ment system. We characterize the intrusion tolerance pro-
vided by the system through several measures deﬁned on the
model, and study variations in these measures in response
to changes in system parameters to evaluate the relative
merits of various design choices.
1. Introduction
The popularity of the Internet, electronic commerce, cor-
porate networks, and distributed computing has caused a
proliferation of critical distributed applications, the conse-
quence of which is a high premium on survivability of these
systems. The availability of valuable information on mod-
ern computer networks and our increasing dependence on
various distributed applications have led to a proportionate
increase in the complexity and variety of intrusions. Intru-
sion tolerance is an emerging approach to security for such
systems that aims to increase the likelihood that an applica-
∗
0172.
This research has been supported by DARPA contract F30602-00-C-
tion will be able to operate correctly in spite of malicious
intrusions.
Before intrusion tolerance can be accepted as an ap-
proach to providing security, it is important to develop tech-
niques to evaluate its efﬁcacy. However, it is quite dif-
ﬁcult to reason about the correctness of security mecha-
nisms. Most traditional approaches to security validation
have not been quantitative (e.g., the Security Evaluation
Criteria [14]). Quantitative methods, when attempted, have
either been based on formal methods [7], and aimed to
prove that certain security properties hold given a speciﬁed
set of assumptions, or been quite informal, and used teams
of experts (often called “red teams,” e.g., [9]) to try to com-
promise a system. Both approaches, while being valuable
in identifying system vulnerabilities, have their limitations.
An alternative approach, which has received much less
attention from the security community, is that of trying to
probabilistically quantify the behavior of an attacker and
his impact on the ability of the system to provide cer-
tain security-related properties. Probabilistic evaluation has
been used extensively in the dependability community, but
very few attempts have been made to use it to assess sys-
tem security. Early work on probabilistic quantiﬁcation of
security was done by Littlewood et al. [8]. That exploratory
work primarily suggested questions that must be answered
in order to make probabilistic security evaluation viable.
Jonsson et al. [6] conducted several experiments and pre-
sented a quantitative model of a security intrusion based
on attacker behavior. Their approach considers only one
source of uncertainty in security validation:
the behavior
of the attacker. Several attempts have been made to build
models that take into account the attacker as well as the sys-
tem being validated. For example, Gong et al. [4] present
a general 9-state model of an intrusion-tolerant system for
describing known and unknown attacks. Jha and Wing [5]
use a state machine model with injected faults and a surviv-
ability property speciﬁed using temporal logic to generate
a scenario graph, which is then used for evaluating overall
system reliability or latency using Bayesian networks. Or-
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:27:53 UTC from IEEE Xplore.  Restrictions apply. 
talo et al. [10] propose modeling known vulnerabilities in
a system combined with simple assumptions concerning an
attacker’s behavior, which can be analyzed using standard
Markov techniques once several parameter values have been
obtained experimentally.
All the approaches described above provide good start-
ing points for the development of a probabilistic approach
to security validation. In particular, they suggest that mea-
sures similar to those used in dependability evaluation can
be deﬁned; that it may be possible to model attackers; and
that the systems can be represented as state-level models
in a way that captures either known or unknown vulnera-
bilities. However, it does not provide a clear road map for
comparing alternative intrusion tolerance approaches quan-
titatively, or for estimating the intrusion tolerance of par-
ticular approaches, particularly during the design phase and
with respect to unknown vulnerabilities.
We believe that probabilistic models for intrusion-
tolerant systems should, either explicitly or logically, in-
the intrusion-tolerance
clude submodels of the attacker,
mechanism being used,
the application, and the re-
source/privilege state of the system. It is also important to
determine the appropriate level of detail/abstraction. For
example, the system submodels should represent the parts
of the system that are important, relative to the types of at-
tacks considered and the expression of a particular avail-
ability measure. Furthermore, depending on the nature of
the attack, the attacker model may either represent details
of the intrusion itself (corresponding to explicit represen-
tation of faults in a dependability model) or represent the
effect of the intrusion (corresponding to the representation
of errors in a dependability model). The type and accu-
racy of input parameter values available will depend on the
stage of development of the system that is being validated.
Even if accurate input parameter values are not available,
a model can still be used to study the trends in a system’s
security and availability for various parameter ranges, and
the trends can be used to guide the system design process.
In this paper, we show that probabilistic modeling us-
ing Stochastic Activity Networks (SANs) [12] addresses the
above challenges. We demonstrate our approach by using
SANs to model and validate an intrusion-tolerant replica-
tion system. The system modeled is a part of the Intru-
sion Tolerance by Unpredictable Adaptation (ITUA) archi-
tecture, which aims to provide a middleware-based intru-
sion tolerance solution. We attempted to build a model in a
modular way, so that it could be easily adapted to a wide va-
riety of intrusion-tolerant systems. We deﬁned several mea-
sures on the model to characterize the intrusion tolerance
provided by the system. We provide insights into the rela-
tive merits of various design choices by studying the vari-
ations in those measures in response to changes in system
parameters.
Security Domain
Groups
Manager Replication
M
R
S
A
Security Domain
M
Manager
S
A
S
A
Host
Sensor−
Actuator
R
Replica
M
S
A
M
R
S
A
Security Domain
M
M
M
S
A
S
A
S
A
Figure 1. ITUA Architecture
The remainder of the paper is organized as follows. First,
Section 2 provides a brief overview of the ITUA replication
system and the assumptions that were made in construct-
ing the model. Section 3 describes the composed stochastic
activity network representation of the model for the system
described in Section 2. Section 4 gives the various results
we obtained from the model, along with our interpretations
and inferences. We conclude in Section 5 with a synopsis
of the major contributions of the paper.
2. Overview of ITUA Replication System and
Model Assumptions
The Intrusion Tolerance by Unpredictable Adaptation
(ITUA) [2] architecture is a middleware-based intrusion
tolerance approach that helps applications survive certain
kinds of attacks. The ITUA architecture uses intrusion-
tolerant group communication to eliminate single points of
failure in processes and objects; integrates a set of COTS
security tools that, together with the information from the
group communication system, detect corrupt processes; and
provides a decentralized replica management facility that
decides what to do (in a possibly unpredictable way) when
intrusions occur. ITUA assumes that as a result of an at-
tack, replicas and management entities can fail in arbitrary
ways. The management algorithms also deal with the fail-
ure of management entities. We now describe the system as
we have modeled it.
The system is divided into multiple security domains,
each consisting of a set of hosts, as shown in Figure 1. Each
domain implements a boundary that the attackers have dif-
ﬁculty crossing.
The decentralized management infrastructure of ITUA
consists of architectural components known as managers.
Each host runs a manager. There can be any number of
applications, and the application objects protected by ITUA
are replicated by the middleware and distributed across the
security domains, subject to the constraint that a security
domain can have only one replica from each application.
We can think of various collections of objects as groups;
the replicas of a replicated object form a replication group,
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:27:53 UTC from IEEE Xplore.  Restrictions apply. 
and the managers of all security domains form a manager
group. An intrusion-tolerant group communication system
is used to multicast among replica groups and the manager
group [11].
The ITUA replication management system has three ma-
jor functions: 1) making decisions about the group structure
of the managers and replicas; 2) propagating information
regarding important state changes among the managers, so
that the managers are aware of the state of the system in
order to make decisions; and 3) convicting corrupt mem-
bers of the system to prevent known corrupt processes from
corrupting the system.
Frequently, the members of a group need to reach a con-
sensus, either to convict a group member in a replica or
manager group, or to help managers decide where to place
a new replica. Since we consider all entities in the system
susceptible to intrusions, there could be any number of en-
tities in a group that are corrupt, but not yet detected. There
is a limit on how many such undetected corruptions can be
tolerated before the group becomes unable to reach consen-
sus. We assume Byzantine fault tolerance [1] using authen-
ticated Byzantine agreement under a timed-asynchronous
environment, and hence assume that less than a third of the
currently active group members can be corrupt and still al-
low the group to reach consensus on various decisions. Note
that group memberships are dynamic: some of the group
members may have been killed upon detection of corrup-
tion, and new ones may have been started to replace them.
Hence, the number of currently active group members may
be less than the number of members the group initially
started with, which would also result in fewer Byzantine
faults being tolerated.
We now describe how the management entities react
when replicas become corrupt. The corruption of a replica
can be discovered in two ways: by the intrusion detection
software on its host, or, when it displays corrupt behavior
during group communication, by other replicas in its repli-
cation group. The intrusion detection software can detect
successful attacks against the host operating system and ser-
vices, the replicas running on the host, or the manager run-
ning on the host. However, it cannot detect all such intru-
sions, and can even generate false alarms when there has
been no actual security breach. On the other hand, we as-
sume that when a corrupt replica behaves incorrectly dur-
ing group communication (that uses Byzantine agreement),
it is always detected and convicted by the correct mem-
bers of the replication group, provided that less than a third
of the currently active group members are corrupted. The
replication group excludes the convicted replica from all fu-
ture communications, and each correct replica in the group
sends a message to the manager running on its host, inform-
ing it about the failure of the recently-convicted replica. If a
manager receiving such a message from a replica on its host
is not itself corrupt, it multicasts the message to the manager
group. If there are enough managers to reach a consensus
(i.e., less than a third of the currently active managers are
corrupt), they randomly pick the domain in which to start
the new replica. As mentioned earlier, the new domain can-
not already have a replica of the application whose replica
is being started. The managers within the chosen domain
then randomly pick a host on which to start the replica, and
the manager on the designated host then starts the replica.
When the intrusion detection software on a host detects an
intrusion into either the host operating system or a replica
running on the host, it informs the local manager. The fur-
ther dissemination of this information and the subsequent
exclusion of the host(s) and restarting of the replica(s) are
similar to the response to detection by replica groups.
Under the current algorithm, the managers also convict
the security domain that had the corrupt replica, by ex-
cluding all the hosts in the domain, including their repli-
cas and management entities. That might result in restart-
ing of some more replicas to replace the ones that were ex-
cluded. The motivation behind this preemptive approach is
that when an entity on a host has been compromised, there
is a good chance that other hosts in the domain have also
been compromised, since the attacker may have been able
to spread the attack to other hosts in the domain, perhaps
by using techniques similar to those of the initial attack or
by using the corrupt hosts for covert purposes. We have
also considered an alternative approach in which only the
host running the corrupt replica is excluded, not the entire
domain. We assume the system is left to itself with mini-
mum human intervention; hence, we do not model manual
repair of excluded domains/hosts, and can run out of do-
mains/hosts to start new replicas to replace the killed ones.
We make several assumptions about attacker behavior.
We have based our attacker model on the experiments con-
ducted by Jonsson et al. [6], which suggest that there are
three distinct classes of attacks: script-based attacks, more
exploratory attacks, and totally innovative attacks. The
script-based attacks are generally the most frequent, and
are usually employed by inexperienced enthusiasts using
scripts downloaded from the Internet. The commercial in-
trusion detection software packages are regularly updated
with information about the latest attack scripts and exploits;
hence, we assume that the intrusion detection software can
detect a fairly high percentage of script-based attacks. The
next category are attacks from slightly more experienced
attackers using intelligent combinations of various scripts.
Those attacks are less frequent, but are also more difﬁcult
to detect. The third category is entirely new and innovative
attacks. They are quite rare, but have an excellent chance
of escaping detection. We also assume that attackers learn
from successful intrusions. Thus, the corruption of a host in
a security domain would increase the vulnerability of other
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:27:53 UTC from IEEE Xplore.  Restrictions apply. 
hosts in the domain, as they probably have similar operat-
ing system versions and service conﬁgurations. We assume
that an attacker can target the host operating system and ser-
vices, application objects, or even the management infras-
tructure. We further assume that a successful intrusion into
the host operating system greatly increases the chances of a
successful intrusion into the application objects running on
that host, as well as the manager on that host.
We assume that a secure mechanism for starting replicas
on a chosen host is in place. To keep the model simple,
we also assume that the middleware starts the same number
of replicas for each application, and also that each security
domain has the same number of hosts.
(a) Composed Model
3. SAN Models
(c) SAN Submodel for
Management Algorithm
(b) SAN Submodel for a Replica
We use Stochastic Activity Networks (SANs) [12] as our
modeling formalism. We built atomic SAN submodels for
a single host, a single replica, and a management algorithm.
A complete model of the system was then composed using
replicate and join operations. We now give a description of
the salient features of the model. A more detailed treatment
can be found in [13].
3.1. Composed Model
Figure 2(a) shows the composed model for ITUA. The
model consists of three atomic SAN submodels: Replica,
Host, and Management. The Replica submodel is repli-
cated num_reps times to form an application (a replica-
tion group) with num_reps replicas. The resultant sub-
model is joined (Join2 in the ﬁgure) with a Management
submodel, which models the management algorithm for
starting new replicas of the application when some are
killed. The resultant submodel is replicated num_apps
times (Rep1 in the ﬁgure) to form num_apps applica-
tions (replication groups). Similarly, the Host submodel
is replicated num_hosts times to form a security do-
main submodel, which is then replicated num_domains
times (Rep2 in the ﬁgure) to model num_domains secu-
rity domains. The models for applications and security do-
mains are joined (Join1 in the ﬁgure) to form the complete
model for ITUA. The global variables num_domains,
num_hosts, num_apps, and num_reps can be conﬁg-
ured to any short integer value.
3.2. SAN Model for an Application Replica
Figure 2(b) shows the SAN representation of the Replica
submodel. This SAN models the behavior of a single
replica, including assignment of an application identiﬁer,
start of application replicas, attacks on the replica, detection
and false alarms of the replica’s corruption by the intrusion
(d) SAN Submodel for a Host
Figure 2. SAN Models
detection software, display of anomalous behavior by cor-
rupt replicas, and the shutting down of the replica when the
host on which it is running is shut down.
We correlate between replicas and the hosts on which
they are running using various shared places that act as bit
vectors; we discern among the replicas of different applica-
tions by associating a unique identiﬁer (a particular bit posi-
tion) with each application. The high-rate activity assign id
ﬁres repeatedly as soon as the model is solved or simulated,
until each application has received a unique identiﬁer of the
form 2n, 0 ≤ n ≤ 14 stored in the place app id, which
is shared by all replicas of an application. Since places
hold short integers, that assignment of identiﬁers limits
the number of applications, to at most 15, but we believe