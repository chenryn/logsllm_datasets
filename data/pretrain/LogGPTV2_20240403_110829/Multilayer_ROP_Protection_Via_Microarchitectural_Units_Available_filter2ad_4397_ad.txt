Second, the executable target constraint only accesses memory
when executing return instructions; and only due to iTLB
misses, to check if the destination of a call is executable.
In our experiments with SPEC CPU2006 benchmarks, the
iTLB miss rate was only 0.005%. In CET, the shadow stack
is implemented in memory to prevent overﬂows. Therefore,
each call and return operation will require a memory
access. Finally, our schema does not require the creation of
mechanisms to protect storage structures, such as the RAS
or the LBR, because they already exist in hardware and are
inaccessible to the programmer. In the case of CET, since the
shadow stack is located in memory, it is necessary to create and
manage a protection ﬂag against unauthorized writing. This
said, we emphasize that our multilayer approach is equally
effective to reduce the overhead imposed on either CET or
XT. This overhead is the subject of the next section.
C. RQ3 – Overhead
Our ﬁrst layer of protection can be implemented at zero-
overhead, because it relies on hardware already in place in
modern computer architectures. Therefore, in this section we
focus on the overhead of Layers 2 and 3. Like in Section IV-B,
we analyze two implementations of Layer 2, based on call-
validation and control-ﬂow enforcement technology.
1) The Overhead of Layer 2 Without Layer 1 - Executable
Target Constraint: Return address validation is performed by
the combination of two constraints, as mentioned in Sec-
tion III-B: the call-preceded and the executable target. In
this section we shall measure the impact of enforcing them.
Measurement Methodology. To estimate the overhead of
the second layer, we will proceed in two steps. First, we
shall approximate the cost of implementing the checks of
Section III-B for every return instruction processed during
the execution of a program. Then, we shall reduce this
cost proportionally to the quantity of such instructions that
slip from the ﬁrst to the second layer of our approach. As
benchmarks, we use SPEC and the LLVM test suite. Our
prototype is implemented in Pin, which already imposes a
heavy overhead on the code that it emulates. Thus, to estimate
the overhead of Layer 2 when running at the hardware level,
we need to discount Pin’s runtime cost. To carry out this
discount, we also run our applications through Pin without the
veriﬁcations used to implement Layer 2. Let ExTime pruned
be our baseline time. This is the runtime of the simpliﬁed
Pintool. Let ExTime complete be the runtime of the Pintool
with the implementation of Layer 2. The estimated overhead
is the difference ExTime complete − ExTime pruned.
(cid:40)(cid:39)(cid:39)(cid:1)
o
t
)
Weighted average = 50.64%
%
n
i
(
d
a
e
h
r
e
v
O
s
l
l
a
c
e
t
a
d
i
l
a
v
(cid:46)(cid:44)(cid:1)
(cid:44)(cid:39)(cid:1)
(cid:41)(cid:44)(cid:1)
(cid:39)(cid:1)
(cid:1)
(cid:24)
(cid:13)
(cid:23)
(cid:1)
(cid:15)
(cid:24)
(cid:12)
(cid:25)
(cid:1)
(cid:8)
(cid:10)
(cid:7)
(cid:7)
(cid:1)
(cid:15)
(cid:42)
(cid:16)
(cid:20)
(cid:23)
(cid:30)
(cid:16)
(cid:23)
(cid:1)
(cid:27)
(cid:24)
(cid:30)
(cid:32)
(cid:16)
(cid:37)
(cid:1)
(cid:8)
(cid:3)
(cid:2)
(cid:30)
(cid:32)
(cid:31)
(cid:14)
(cid:12)
(cid:14)
(cid:20)
(cid:1)
(cid:35)
(cid:25)
(cid:19)
(cid:27)
(cid:30)
(cid:1)
(cid:30)
(cid:14)
(cid:12)
(cid:24)
(cid:26)
(cid:29)
(cid:18)
(cid:1)
(cid:19)
(cid:14)
(cid:25)
(cid:16)
(cid:13)
(cid:23)
(cid:29)
(cid:16)
(cid:27)
(cid:1)
(cid:24)
(cid:32)
(cid:31)
(cid:25)
(cid:12)
(cid:32)
(cid:28)
(cid:13)
(cid:20)
(cid:23)
(cid:1)
(cid:17)
(cid:14)
(cid:24)
(cid:1)
(cid:6)
(cid:6)
(cid:23)
(cid:12)
(cid:16)
(cid:15)
(cid:1)
(cid:26)
(cid:31)
(cid:25)
(cid:26)
(cid:31)
(cid:1)
(cid:14)
(cid:14)
(cid:18)
(cid:23)
(cid:1)
(cid:35)
(cid:16)
(cid:27)
(cid:26)
(cid:30)
(cid:1)
(cid:36)
(cid:12)
(cid:29)
(cid:33)
(cid:26)
(cid:27)
(cid:1)
(cid:22)
(cid:24)
(cid:13)
(cid:26)
(cid:18)
(cid:1)
(cid:30)
(cid:30)
(cid:16)
(cid:24)
(cid:12)
(cid:18)
(cid:1)
(cid:35)
(cid:20)
(cid:23)
(cid:32)
(cid:14)
(cid:23)
(cid:12)
(cid:14)
(cid:1)
(cid:30)
(cid:16)
(cid:33)
(cid:12)
(cid:34)
(cid:13)
(cid:1)
(cid:17)
(cid:16)
(cid:29)
(cid:43)
(cid:45)
(cid:41)
(cid:19)
(cid:1)
(cid:25)
(cid:12)
(cid:12)
(cid:11)
(cid:23)
(cid:1)
(cid:17)
(cid:29)
(cid:34)
(cid:1)
(cid:18)
(cid:25)
(cid:16)
(cid:21)
(cid:30)
(cid:1)
(cid:29)
(cid:12)
(cid:31)
(cid:30)
(cid:12)
(cid:1)
(cid:41)
(cid:27)
(cid:20)
(cid:37)
(cid:13)
(cid:1)
(cid:14)
(cid:23)
(cid:20)
(cid:24)
(cid:1)
(cid:29)
(cid:16)
(cid:24)
(cid:24)
(cid:19)
(cid:1)
(cid:27)
(cid:27)
(cid:31)
(cid:16)
(cid:25)
(cid:24)
(cid:26)
(cid:1)
(cid:3)
(cid:9)
(cid:3)
(cid:4)
(cid:30)
(cid:24)
(cid:16)
(cid:5)
Figure 8. Call-validation overhead.
Analysis of Results. Figure 8 shows the result of this analysis.
The numbers in Figure 8 show a weighted average upper
bound of 50.64% on the overhead that we can expect. We are
emulating in software all the veriﬁcations that, in production,
would be implemented in hardware. For instance, our Pintool
produces sequences with several operations to check if the
instruction that precedes the target of a return is a call.
Even more instructions are issued by the Pintool to verify
if the call targets an executable memory area because our
prototype needs to track, through data-structures provided by
Pin, which memory sections of a process image are executable.
In hardware, these veriﬁcations would happen in parallel with
the instruction pipeline; hence, we speculate that it would be
orders of magnitude lower. Nevertheless, as we shall see in
Section IV-C4, this overhead shall fade away due to Layer 1
– this is the beauty of the multilayer approach.
2) The Overhead of Layer 2 Without Layer 1 - Control-Flow
Enforcement Technology: We also measured the overhead of
Layer 2 considering a CET-like shadow stack in-place. This
new experiment uses the infra-structure seen in Section IV-B3.
Measurement Methodology. Like in Section IV-C1, we also
discount Pin’s runtime cost to measure overhead. To this end,
we created a pruned version of the Pintool. This baseline has
all the code of the ﬁnal prototype: shadow stack manipulation,
counters operation, etc. However,
it does not perform the
comparison between the return address and the address in the
top of the shadow stack. We subtract its execution time from
the value observed for the complete Pintool.
Analysis of Results. Results are presented in Figure 9. Our
shadow stack implementation slowed down the benchmarks in
21.65% on average. We cannot establish a rigid comparison
between the overhead observed in the shadow stack and in our
Executable Target Constraint, because software implementa-
tions in Pin are considerably different than hardware imple-
mentations. However, these values indicate that both strategies
present a comparable cost. When applied to a tiny portion of
returns, as shown in Section IV-B1, both strategies will
cause an insigniﬁcant overhead, as we show in the next section.
3) The Overhead of Layer 2 and Layer 1: The overhead
presented thus far, be it through call validation, be it through
Control-ﬂow Enforcement Technology is high. However, only
323
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:52:59 UTC from IEEE Xplore.  Restrictions apply. 
mispredicted indirect branches need to be veriﬁed at Layer 2.
In this section we estimate this new overhead, to conclude that
Layer 1 brings a fundamental improvement onto any of these
two validation mechanisms.
Measurement Methodology. We use the following formula
to compute the overhead for each application/benchmark:
Overhead L1+L2 = RET mp × RET vo
(cid:43)(cid:1)
(cid:42)(cid:1)
(cid:40)(cid:1)
(cid:39)(cid:1)
)
Weighted average = 0.57%
%
n
i
(
d
a
e
h
r
e
v
O
(cid:1)
(cid:6)
(cid:6)
(cid:23)
(cid:12)
(cid:16)
(cid:15)
(cid:1)
(cid:26)
(cid:31)
(cid:25)
(cid:26)
(cid:31)
(cid:1)
(cid:17)
(cid:16)
(cid:29)
(cid:42)
(cid:43)
(cid:40)
(cid:19)
(cid:1)
(cid:19)
(cid:14)
(cid:25)
(cid:16)
(cid:13)
(cid:23)
(cid:29)
(cid:16)
(cid:27)
(cid:1)
(cid:29)
(cid:12)
(cid:31)
(cid:30)
(cid:12)
(cid:1)
(cid:18)
(cid:25)
(cid:16)
(cid:21)
(cid:30)
(cid:1)