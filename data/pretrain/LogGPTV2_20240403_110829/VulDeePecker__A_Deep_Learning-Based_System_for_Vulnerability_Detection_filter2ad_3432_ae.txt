### Identical to the Vulnerable Functions in Training Programs

VulPecker can only detect vulnerabilities caused by Type I and Type II code clones, as well as some Type III code clones (e.g., deletion, insertion, and rearrangement of statements) [42]. This explains why VulPecker has a lower False Negative Rate (FNR) compared to VUDDY. However, both systems cannot detect vulnerabilities that are not caused by code clones, which results in high FNRs.

In contrast, VulDeePecker achieves a much higher F1-measure (80.8% vs. 9.3% for VUDDY and 18.2% for VulPecker) due to its significantly higher True Positive Rate (TPR) and, consequently, lower FNR. It is important to note that VulDeePecker's False Positive Rate (FPR) is 22.9%, compared to 0% for VUDDY and 1.9% for VulPecker. The high FPR of 22.9% for the BE-SEL-NVD dataset is likely due to the small number of training code gadgets from the National Vulnerability Database (NVD). This is supported by the much lower FPR of 3.4% when using a larger number of training code gadgets from the Software Assurance Reference Dataset (SARD), which is approximately 18 times larger than the NVD dataset. Additionally, the FPR of 5.7% for the entire BE-SEL dataset falls between these two values. The high FNR of 16.9% can be similarly explained.

The high FPR and FNR of VulDeePecker with respect to the BE-SEL-NVD sub-dataset should not be seen as a definitive drawback, as for the BE-SEL-SARD sub-dataset, VulDeePecker achieves an even smaller FPR of 3.4% and an FNR of 5.1%. Notably, VUDDY and VulPecker are not applicable to this sub-dataset. Furthermore, VulDeePecker achieves an FPR of 5.7% and an FNR of 7.0% over the entire BE-SEL dataset, which is a more practical scenario as it includes all available data.

### Table VI: Undetected Vulnerabilities Identified by VulDeePecker

| **Target Product** | **CVE ID** | **Vulnerable Product Published in NVD** | **Vulnerability Publish Time** | **Vulnerable File in Target Product** | **Library/API Function Call** | **1st Patched Version of Target Product** |
|--------------------|------------|----------------------------------------|--------------------------------|--------------------------------------|------------------------------|-----------------------------------------|
| Xen 4.6.0          | CVE-2016-9104 | Qemu                                   | 12/09/2016                      | .../qemu-xen/hw/9pfs/virtio-9p.c      | memcpy                        | Xen 4.9.0                               |
| Seamonkey 2.31     | CVE-2015-4517 | Firefox                                | 09/24/2015                      | .../system/gonk/NetworkUtils.cpp       | snprintf                      | Seamonkey 2.38                          |
| Seamonkey 2.31     | CVE-2015-4513 | Firefox                                | 11/05/2015                      | .../protocol/http/Http2Stream.cpp      | memset                        | Seamonkey 2.39                          |
| Libav 10.2         | CVE-2014-2263 | FFmpeg                                 | 02/28/2014                      | libavformat/mpegtsenc.c               | strchr, strlen                | Libav 10.4                              |

VulDeePecker detected four vulnerabilities in three products (Xen, Seamonkey, and Libav) that were not published in the NVD but had been "silently" patched by the vendors in later releases. These vulnerabilities were entirely missed by other vulnerability detection systems, except for FlawFinder, which detected one vulnerability while missing the other three.

### Limitations

The current design, implementation, and evaluation of VulDeePecker have several limitations, suggesting interesting open problems for future research:

1. **Source Code Availability**: VulDeePecker currently assumes that the source code of programs is available. Detecting vulnerabilities in executables is a different and more challenging problem.
2. **Language Support**: VulDeePecker is currently limited to C/C++ programs. Future work should adapt it to handle other programming languages.
3. **Vulnerability Types**: VulDeePecker currently focuses on vulnerabilities related to library/API function calls. Research is needed to extend its capabilities to detect other types of vulnerabilities.
4. **Control Flow Analysis**: The current design only accommodates data flow analysis and not control flow analysis. Enhancing VulDeePecker to include control flow analysis is an important future task.
5. **Heuristics**: The current design uses heuristics for labeling ground truth, transforming code gadgets into symbolic representations, and converting variable-length vector representations into fixed-length vectors. Further research is needed to understand the impact of these heuristics.
6. **Neural Network Architecture**: The current implementation is limited to the Bidirectional Long Short-Term Memory (BLSTM) neural network. Experiments with other neural network architectures are planned.
7. **Dataset Scope**: The current evaluation is limited to buffer error and resource management error vulnerabilities. Future work will include experiments with all available types of vulnerabilities.

### Related Work

#### A. Prior Work in Vulnerability Detection

- **Pattern-Based Approach**: This approach can be divided into three categories:
  - **Manual Pattern Generation**: Tools like FlawFinder, RATS, and ITS4 often have high false positive or false negative rates.
  - **Semi-Automatic Pattern Generation from Pre-Classified Vulnerabilities**: Methods like those for missing check, taint-style, and information leakage vulnerabilities.
  - **Semi-Automatic Pattern Generation from Type-Agnostic Vulnerabilities**: These methods use machine learning techniques but rely on human experts to define features and cannot pinpoint precise locations of vulnerabilities.
  
  VulDeePecker falls under the pattern-based approach but has the advantages of not requiring human-defined features and using fine-grained program representation to pinpoint vulnerabilities.

- **Code Similarity-Based Approach**: This approach involves dividing a program into code fragments, representing them abstractly, and computing similarity. While it can detect vulnerabilities in Type I and II code clones and some Type III clones, it requires human-defined features for effectiveness and cannot detect vulnerabilities not caused by code clones.

#### B. Prior Work Related to Using Deep Learning for Program Analysis

- **Deep Learning for Vulnerability Detection**: VulDeePecker is the first to use deep learning for this purpose, inspired by its success in image processing, speech recognition, and natural language processing. Programs are represented as vectors, either by mapping tokens or nodes of abstract syntax trees.
- **Related Work**: Other deep learning applications in software defect prediction, software language modeling, code cloning detection, API learning, binary function boundary recognition, and malicious URL, file path, and registry key detection.

### Conclusion

VulDeePecker is the first deep learning-based vulnerability detection system, designed to reduce the need for manual feature definition and minimize false negatives. Systematic experiments show that VulDeePecker outperforms other systems, particularly in detecting vulnerabilities not reported in the NVD. Future research should address the current limitations and further refine the principles for applying deep learning to vulnerability detection.

### Acknowledgment

We thank the anonymous reviewers for their comments and Marcus Pendleton for proofreading the paper. This work is supported by various grants, including the National Basic Research Program of China, the National Science Foundation of China, the Shenzhen Fundamental Research Program, and the Natural Science Foundation of Hebei Province. Shouhuai Xu is also supported by NSF and ARO grants.

### References

[1] C/C++ standard library functions, http://en.cppreference.com/w.  
[2] Checkmarx, https://www.checkmarx.com/.  
[3] Coverity, https://scan.coverity.com/.  
[4] CVE, http://cve.mitre.org/.  
[5] Cyber Grand Challenge, https://www.cybergrandchallenge.com/.  
[6] FlawFinder, http://www.dwheeler.com/flawfinder.  
[7] HP Fortify, https://www.hpfod.com/.  
[8] Keras, https://github.com/fchollet/keras.  
[9] Linux kernel API functions, https://www.kernel.org/doc/htmldocs/kernel-api/.  
[10] NVD, https://nvd.nist.gov/.  
[11] Rough Audit Tool for Security, https://code.google.com/archive/p/rough-auditing-tool-for-security/.  
[12] Software Assurance Reference Dataset, https://samate.nist.gov/SRD/index.php.  
[13] Windows API functions, https://msdn.microsoft.com/en-us/library/windows/desktop/ff818516(v=vs.85).aspx#user interface.  
[14] word2vec, http://radimrehurek.com/gensim/models/word2vec.html.  
[15] M. Backes, B. K¨opf, and A. Rybalchenko, “Automatic discovery and quantification of information leaks,” in Proceedings of the 30th IEEE Symposium on Security and Privacy. IEEE, 2009, pp. 141–153.  
[16] Y. Bengio, “Learning deep architectures for AI,” Foundations and Trends in Machine Learning, vol. 2, no. 1, pp. 1–127, 2009.  
[17] K. Cho, B. Van Merri¨enboer, D. Bahdanau, and Y. Bengio, “On the properties of neural machine translation: Encoder-decoder approaches,” arXiv preprint arXiv:1409.1259, 2014.  
[18] L. V. Davi, “Code-reuse attacks and defenses,” Ph.D. dissertation, Darmstadt University of Technology, Germany, 2015.  
[19] G. Grieco, G. L. Grinblat, L. Uzal, S. Rawat, J. Feist, and L. Mounier, “Toward large-scale vulnerability discovery using machine learning,” in Proceedings of the 6th ACM Conference on Data and Application Security and Privacy.