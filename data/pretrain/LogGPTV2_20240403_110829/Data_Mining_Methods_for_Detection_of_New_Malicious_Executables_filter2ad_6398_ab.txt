To extract resource information from Windows executa- 
bles we used GNU’s Bin-Utils  [SI. GNU’s Bin-Utils  suite 
of tools can analyze PE binaries within  Windows.  In  PE, 
or Comnioti Object File  Format (COFF), program headers 
are composed of  a  COFF header, an  Optional header,  an 
MS-DOS stub, and a file signature. From the PE header we 
used IibBFD, a library within Bin-Utils,  to extract informa- 
tion  in objzct format.  Object format for a PE binary gives 
the file size, the names of DLLs, and the names of function 
calls within those DLLs and Relocation Tables.  From  the 
object format, we extracted a set of features to compose a 
feature vector for each binary. 
To understand how resources affected a binary’s behav- 
ior we performed our experiments using three types of fea- 
tures: 
1.  The list of DLLs used by the binary 
2.  The list of DLL function calls made by  the binary 
3.  The  number  of  different  function  calls  within  each 
DLL 
The first approach to binary  profiling  (shown  in  Figure 
1)  used  the DLLs loaded  by  the  binary  as  features.  The 
feature  vector  comprised  of  30 boolean  values represent- 
ing  whether  or  not  a  binary  used  a  DLL. Typically,  not 
every DLL was  used  in  all  of  the  binaries,  but  a  major- 
ity  of the binaries called the same resource.  For example, 
almost every binary called GDI32.DLL, which is the Win- 
dows NT Graphics Device Interface and is a core compo- 
nent of WinNT. 
~ a d v a p . 3 2  A avicap32 A  ... A w i n m m  A ~ w s o c k 3 2  
Figure  1 :   First  Feature  Vector:  A  conjunction  of  DLL 
names 
The example vector given  in  Figure  1  is  composed of 
at  least  two  unused  resources:  ADVAPI32.DLL,  the  Ad- 
vanced Windows API, and WSOCK32.DLL, the Windows 
Sockets API.  It  also  uses  at  least  two  resources:  AVI- 
CAP32.DLL, the AV1 capture API, and WINNM.DLL, the 
Windows Multimedia API. 
The second approach to binary profiling (seen in Figure 
2) used DLLs and their function calls as features. This ap- 
proach was similar to the first, but with added function call 
information.  The  feature vector  was  composed of  2,229 
boolean values.  Because some of the DLL‘s had  the same 
function names it was important to record which DLL the 
function came from. 
The example  vector given  in  Figure 2  is  composed of 
at least four resources.  Two functions were called  in AD- 
VAPI32.DLL:  AdjustTokenPrivileges()  and  GetFileSecu- 
advapi32.ildjustTokenPrivileges() 
A  advapi32.GetFileSecu~ztyA() A ... 
A  wsock32.~ecv() A wsock32.send() 
Figure 2:  Second Feature Vector:  A conjunction of DLL‘s 
and the functions called inside each DLL 
rityA(), and two functions in WSOCK32.DLL: recv() and 
send(). 
The third approach to binary profiling (seen in Figure 3) 
counted the number of different function calls used within 
each DLL. The feature vector included  30 integer values. 
This profile gives a rough  measure of  how heavily a DLL 
is used within a specific binary.  Intuitively, in the resource 
models we  have been  exploring, this is a macro-resource 
usage model because the number of calls to each resource 
is counted instead of detailing referenced functions. For ex- 
ample, if a program only called the recv() and send() func- 
tions  of WSOCK32.DLL, then  the  count would  be  2.  It 
should be noted that we do not count the number of times 
those functions might have been called. 
advapi32 = 2  A  avzcap32 = 10 A  ... 
A  w i n m m  = 8  A wsock32 = 2 
Figure 3:  Third Feature Vector:  A  conjunction of  DLL‘s 
and a count of the number of functions called inside each 
DLL 
The example vector given in Figure 3 describes an exam- 
ple  that calls two functions in  ADVAPI32.DLL, ten  func- 
tions in AVICAP32.DLL, eight functions in WINNM.DLL 
and two functions from WSOCK32.DLL. 
All  of  the  information  about  the  binary  was  obtained 
from the program header.  In addition, the information was 
obtained without  executing the  unknown program  but  by 
examining the static properties of the binary, using IibBFD. 
Since  we  could  not  analyze  the  entire  dataset  with 
IibBFD we  found another method  for extracting  features 
that works over the entire dataset. We describe that method 
next. 
4.2  GNU Strings 
During  the  analysis  of  our  IibBFD  method  we  noticed 
that  headers in  PE-format were  in  plain  text.  This meant 
that  we  could extract  the same information  from  the  PE- 
executables by just extracting the  plain  text  headers.  We 
also noticed  that non-PE executables also have strings en- 
coded in  them.  We theorized that we could use this infor- 
mation to classify the full 4,266 item data set instead of the 
41 
small IibBFD data set. 
To extract features from the first data set of 4,266 pro- 
grams  we  used  the  GNU srr-ings program.  The  strings 
program extracts consecutive printable characters from any 
file.  Typically  there are many printable strings in  binary 
files.  Some common strings found in our dataset are illus- 
trated in Table  I .  
1 foe Oeba b400 cd09 b82 1 4cO1 2 I cd 6854 
7369 7020 6f72 7267 6d6 1 7220 7 I65 6975 
65722073694d7263736f666f20746957 
646e776f2e73OaOd0024000000000000 
454e3c05026c00090000000003020004 
0400 2800 3924 0001 0000 0004 0004 0006 
OOOc00400060021e0238024402f5 0000 
0001 0004000008020032  13040000030a 
Figure 4: Example Hexdump 
reloc 
createfilea 
regcl osekey 
Table  I :   Common strings extracted  from  binaries  using 
GNU strings 
5  Algorithms 
In this section we  describe all the algorithms presented in 
this paper as  well  as the signature-based method used  for 
comparison.  We  used  three  different  data  mining  algo- 
rithms to generate classifiers with  different features: RIP- 
PER, Naive Bayes, and a Multi-Classifier system. 
We describe the signature-based method first. 
Through testing we found that there were similar strings 
in  malicious  executables  that  distinguished  them  from 
clean  programs,  and  similar  strings  in  benign  programs 
that distinguished them from malicious executables.  Each 
string in the binary was used as a feature. In the data mining 
step, we discuss how a frequency analysis was performed 
over all the byte sequences found in our data set. 
The strings contained in a binary may consist  of reused 
code fragments, author signatures, file  names, system re- 
source information, etc.  This method  of  detecting mali- 
cious executables is already used by the anti-malicious ex- 
ecutable community to create signatures for malicious exe- 
cutables. 
Extracted strings from an executable are not very robust 
as features because they can be changed easily, so we ana- 
lyzed another feature, byte sequences. 
4.3  Byte Sequences Using Hexdump 
Byte sequences are the last set of features that we used over 
the entire 4,266 member data set.  We  used hexdump [ 181, 
a  tool  that  transforms binary  files  into  hexadecimal filcs. 
The byte sequence feature is the most informative because 
it represents the machine code in an executable instead of 
resource information like IibBFD features.  Secondly, ana- 
lyzing the entire binary gives more information for non-PE 
format executables than the strings method. 
After we generated the hexdumps we had features as dis- 
played  in  Figure 4  where each  line  represents  a  short se- 
quence of machine code instructions. 
We again assumed that there were similar instructions in 
malicious executables that differentiated them from benign 
programs,  and  the  class  of  benign  programs had  similar 
byte code that  differentiated them  from the malicious ex- 
ecutables.  Also like the string features, each byte sequence 
in a binary is used as a feature. 
5.1  Signature Methods 
We examine signature-based  methods to compare our re- 
sults to traditional anti-virus methods. Signature-based de- 
tection methods are the most commonly used algorithms in 
industry  [27].  These signatures are picked  to differentiate 
one malicious  executable from  another,  and  from benign 
programs.  These signatures are generated  by  an expert in 
the field  or an automatic method.  Typically, a signature is 
picked to illustrate the distinct properties of a specific ma- 
licious executable. 
We  implemented  a  signature-based  scanner  with  this 
method that follows a simple algorithm for signature gen- 
eration.  First, we calculated the byte-sequences that  were 
only  found in  the malicious executable class.  These byte- 
sequences  were  then  concatenated  together  to  make  a 
unique  signature  for each  malicious executable example. 
Thus, each malicious executable signature contained only 
byte-sequences found in the malicious executable class. To 
make  the  signature unique,  the  byte-sequences found  in 
each example were concatenated together to form one sig- 
nature. This was done because a byte-sequence that is only 
found in one class during training could possibly be found 
in the other class during testing [9], and lead to false posi- 
tives in testing. 
The method described above for the commercial scanner 
was never intended  to detect unknown malicious binaries, 
but the data mining algorithms that follow were built to de- 
tect new malicious executables. 
5.2  RIPPER 
The next  algorithm we  used, RIPPER  [3], is  an  inductive 
rule  learner.  This algorithm generated  a detection model 
composed of resource rules that  was built  to detect future 
42 
examples  of  malicious executables.  This  algorithm used 
IibBFD information as features. 
RIPPER is a rule-based learner that builds  a set of rules 
that  identify  the  classes  while  minimizing  the  amount  of 
error. The error is defined by the number of training exam- 
ples misclassified  by the rules. 
An  inductive  algorithm  learns  what  a  malicious  exe- 
cutable is given a set of  training  examples.  The four fea- 
tures seen in Table 2 are: 
1 .   “Does it have a CUI?” 
2.  “Does it perform a malicious function?” 
3.  “Does it compromise system security?” 
4. “Does it delete files?” 
and finally the class question “Is it malicious?” 
Is it 
malicious? 
Table  2:  Example Inductive Training Set.  Intuitively  all 
malicious executables share the  second  and  third  feature, 
“yes” and “yes” respectively. 
The defining property of any inductive learner is that no a 
priori assumptions have been made regarding the final con- 
cept. The inductive learning algorithm makes as its primary 
assumption that the data trained over is similar in some way 
to the unseen data. 
A  hypothesis generated  by  an  inductive learning algo- 
rithm  for this  learning problem  has  four attributes.  Each 
attribute will have one of these values: 
1.  T, truth, indicating any value is acceptable in this po- 
sition. 
2.  a value, either yes, or no, is needed in this position, or 
3.  a I, falsity, indicating that  no value is acceptable for 
this position 
For  example, the  hypothesis  (T,T,T,T) and  the  hy- 
pothesis (yes, yes, yes, no) would make the first  example 
true.  (T, T, T, T)  would  make  any  feature  set true  and 
(yes, yes, yes, no) is the set of features for example one. 
The algorithm we describe is Find-S [20]. Find-S finds 
the  most  specific  hypothesis  that  is  consistent  with  the 
training examples.  For a positive training example the al- 
gorithm  replaces any attribute in the hypothesis that  is in- 
consistent with  the  training  example with  a more  general 
attribute.  .Of all  the  hypotheses  values  1  is more  general 
than 2 and 2 is more general than  3.  For a negative exam- 
ple the algorithm  does nothing.  Positive examples in  this 
problem  are defined  to  be  the  malicious  executables and 
negative examples are the benign programs. 
The  initial  hypothesis 
that  Find-S  starts  with 
is 
(131-, L,L). This  hypothesis  is  the  most  specific 
because  it  is  true  over  the  fewest  possible  examples, 
none.  Examining  the  first  positive  example in  Table  2, 
(yes, yes, yes, no), the  algorithm  chooses the  next  most 
specific hypothesis  (yes, yes, yes, no). The next positive 
example, (no, no; no, yes), is inconsistent with the hypoth- 
esis in its first and fourth attribute (“Does it have a CUI?” 
and  “Does it delete files?”)  and those attributes in the hy- 
pothesis get replaced  with  the next most general attribute, 
T. 
The resulting  hypothesis after two positive examples is 
(T, yes,yes, T). The algorithm skips the third example, a 
negative example, and finds that this hypothesis is consis- 
tent with the final example in Table 2. The final rule for the 
training data listed in Table 2 is (T, yes, yes, T). The rule 
states that  the attributes of  a malicious  executable, based 
on  training data, are  that  it  has  a  malicious  function and 
compromises system security.  This is consistent  with  the 
definition  of  a malicious executable we  gave in  the intro- 
duction.  It does not  matter in  this example if  a malicious 
executable deletes files, or if  it has a CUI or not. 
Find-S is a relatively  simple algorithm while RIPPER is 
more complex. RIPPER looks at both positive and negative 
examples to generate a set of hypotheses that more closely 
approximate the target concept while Find-S generates one 
hypothesis that approximates the target concept. 
5.3  Naive Bayes 
The next classifier we describe is a Naive Bayes classifier 
[6]. The naive Bayes classifier computes the likelihood that 
a program is malicious given the features that are contained 
in  the program.  This method  used  both  strings and  byte- 
sequence data to compute a probability of a binary’s mali- 
ciousness given its features. 
Nigam et al. [21] performed a similar experiment when 
they  classified  text  documents according to  which  news- 
group  they  originated  from. 
In  this  method  we  treated 
each  executable’s features as  a  text  document and  classi- 
fied based on that. The main assumption in this approach is 
that the binaries contain similar features such as signatures, 
machine instructions, etc. 
Specifically, we  wanted  to  compute the  class of  a  pro- 
gram given  that  the program contains a set of  features F .  
We define C 10  be a random variable over the set of classes: 
benign,  and  nialicioiis  executables.  That  is,  we  want  to 
compute P(CIF), the  probability  that  a  program  is  in  a 
certain class given the program contains the set of features 
F .  We apply Bayes rule and express the probability as: 
43 
To use the naive Bayes rule we assume that the features 
occur  independently  from one another.  If  the  features of 
a  program F  include the features Fl, F2, F3, ..., Fn, then 
equation (1)  becomes: 
Each P(FilC) is the frequency that string F, occurs in a 
program of class C. P ( C )  is the proportion of the class C 
in the entire set of programs. 
The  output  of  the  classifier  is  the  highest  probability 
class for a  given  set of  strings.  Since the denominator of 
(1)  is the same for all classes we take the maximum  class 
over all classes C of the probability of each class computed 
in (2) to get: 
Most Likely Class = max C 
( P ( C )  fi P(F,lC)) 
( 3 )  
i=l 
In (3), we use inazc to denote the function that returns 
the class with  the highest probability.  Most Likely Class 
is the class in C with  the highest probability and hence the 
most likely classification of the example with features F .  
To train  the classifier,  we recorded how many programs 
in each class contained each unique feature.  We  used  this 
information to classify a new  program into an appropriate 
class. We first used feature extraction to determine the fea- 
tures contained in the program. Then we applied equation 
(3) to compute the most likely class for the program. 
We  used  the Naive  Bayes algorithm  and  computed  the 
most likely class for byte sequences and strings. 
\ 