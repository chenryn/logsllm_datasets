83
17
92
4
EXO 14 ST3 4
0
N
Y
S
25
U
H
T
24
100 100
0
O
D
V
60
43
52
BO3 5
56
92
ST3 36 BO3 4 BO3 5
VDO 8
SYN 3
28
72
96
4
96
N
A
B
R
U
A
1
O
B
samples 23 15 40
correct 100 100 95
unknown
0
0
1
E
2
3
O
O
B
B
3 28
0 100
0
5 100
wrong
(b) NTP
I
W
R
O
C
D
27 27
I
X
E
7
100 96 71
4 29
0
O
T
X
S
E
K
61 20
97 100
0
3
1
T
S
R
E
S
W
A
R
O
N
T
3
D
Y
E
T
V
S
N
S
29 82 15 21 19
28 22 61
86 100 100 100 89 100 91 100 95 100
0
4
A
T
T
S
S
27 22
0 11
U
H
T
0
0
0
9
0
5
0
EXO 10
CRI 3
2 unknown 100 100 100 100 100
E
wrong
74 100 100
34 100
NET 26
NET 66
correct 87 73 90
unknown 13 27 10 100
0 96
4
3
E
89 81 43
11 19 57
90 80
10 20
wrong
10 100 100 100 100
EXO 86
CRI 3
69 98 87 86 74
17
2 13 14 26
EXO 10
CRI 3
93 100
93 100 100
SYN 7
ST4 7
93 77
7 23
86 86 97
14 14
3
time. Misclassiﬁcations are even more prevalent in our E2 experiment, where
in some cases the classiﬁer confused over half of the attacks. While the num-
ber of misclassiﬁcations could be reduced by lowering the cutoﬀ threshold, this
would also cause a higher rate of unknown results in the other two experiments.
Finally, in E3 the classiﬁer shows similar performance compared to E1, with
a slight degradation. However, this is expected, since if a booter service has
just rescanned we will have no training samples that match the current set of
ampliﬁers.
For NTP the victim-driven classiﬁer generally performs better than for DNS.
In the 10-fold CV (E1), the classiﬁer correctly attributed 71% or more of the
attacks for every booter, in many cases even more than 85%. As before, BO2
marks an exception due to the small number of attacks that were recorded for this
booter. As already observed in the honeypot-based classiﬁer, attacks from NET
and CRI showed similar behavior. A third booter, EXO, that was only observed in
the victim-based data set exhibits similar traits as well. While we were not able to
verify that these booters are just diﬀerent front ends of a multibranding booter,
they account for almost all of the misattributions not only for NTP but also for
CharGen. In E2 the classiﬁer achieves a perfect result for most booters, with the
exception of the previously mentioned group and two confusions between ST4
and SYN. Again, the results of our real-time classiﬁcation experiment (E3) are as
expected, with attribution rates of over 69% in all cases, except for EXI, whose
Linking Ampliﬁcation DDoS Attacks to Booter Services
443
recall drops from 71% to only 43%, due to the small number of attacks observed
from this booter.
Overall, the victim-driven classiﬁer achieves a macro-averaged precision of
91.65% and recall of 79.03% for DNS, while for NTP it performs better with
94.58% and respectively 91.07%.
7 Discussion
We now discuss potential ways to evade our attribution implementation and
describe general limitations of our approach that we have not discussed so far.
7.1 Evasion
While our attribution methods have proven to work well as of now, they may
be susceptible to evasion attempts by miscreants. A mimicry attacker could try
to be attributed as someone else by following our methodology, i.e., learning the
attack proﬁle of another booter and copying its behavior. For example, she could
use the same set of reﬂectors as the other booter for her own attacks. However,
this involves a signiﬁcant increase in terms of eﬀort in comparison to Internet-
wide scans. In addition, our TTL-based features are much harder to copy, as
they encode the location of the booter service and are subject to changes for
other booter locations. While such mimicry attacks are possible [2], given the
complexity and overhead, we do not believe that attackers trying to trigger a
false attribution constitute an actual risk in practice. For similar arguments,
attackers that share lists of reﬂectors with each other would partially poison our
analysis, but again TTL-based attribution may be safe against this. Our use of
the set of domain names resolved as a feature for our victim-driven DNS classiﬁer
can be evaded by booter services selecting a larger pool of domain names that
result in large replies and cycling through this pool.
An evasive attacker could try to evade our classiﬁcation mechanisms. Attack-
ers have full control over the traﬃc they generate, and thus could add noise. For
example, one could randomize the set of reﬂectors used in the attacks, or spoof
the initial TTL value within a range of possible values. It is unclear if a classiﬁer
could still keep up with such evasion attempts, but it may be possible to add
additional features to enrich the classiﬁcation, such as other characteristics (e.g.,
IP packet IDs, DNS transaction IDs), as those have shown characteristic pat-
terns even if they were randomized [8]. In addition, honeypots that selectively
respond to scan requests may survive such randomization [10]. Even if attackers
randomize the set of reﬂectors, any subset will still be a subset of a unique map-
ping to a scanner. Lastly, randomizing the traﬃc does also incur a performance
overhead to attackers, as they cannot reuse pre-generated packets.
Finally, attackers could try to map out the honey ampliﬁers using probing
messages [3] if the honeypot ampliﬁer data was made public for the DDoS service
to use as an oracle. To avoid this evasion technique, access to the honeypot
ampliﬁer data is restricted to vetted entities, such as researchers and LEAs.
444
J. Krupp et al.
7.2 Limitations
Our in-the-wild experiments faced some limitations, as discussed in the following:
Honeypot Coverage: Regardless of our attempts to maximize the coverage of
the honeypots, they missed signiﬁcant fractions of the self-attacks, especially for
SSDP and CharGen. This can be addressed by framing larger emulated responses
to make the honeypots more attractive to attackers. The coverage for two of the
main protocols, DNS and NTP, was signiﬁcant, though, covering about 57% of
the self-attacks. We therefore argue that our results are representative at least
for these two protocols. In addition, there is no limitation of our methodology
that would restrict its applicability to the two well-tested protocols.
Multi-source Attribution: We assumed that attacks are caused by single
sources (booters). If botnets launched ampliﬁcation attacks, our features (e.g.,
TTL) would be unstable. To give an upper bound of attacks launched by botnets,
we searched for attacks with several TTL values, as this—among other reasons—
might be caused by distributed traﬃc sources. Less than 9.5% of attacks at the
honeypots show more than 2 TTL values at a honeypot.
Other Attacks: Other types of DDoS attacks, such as SYN ﬂooding or HTTP-
based attacks, do not use reﬂectors and are thus not traceable with our pro-
posed methods. Note that ampliﬁcation attacks constitute the most common
bandwidth exhaustion attack. This is also demonstrated by the fact that all
booters advertise ampliﬁcation attacks, while support for other attack types
(e.g., HTTP-based attacks) is far less popular. To put things into perspective:
we observed more than 8,900 ampliﬁcation attacks per day.
8 Related Work
The general risk of ampliﬁcation attacks was ﬁrst illustrated in Paxon’s sem-
inal paper on reﬂection attacks [15] and then by Rossow’s recent overview of
ampliﬁcation vulnerabilities in 14 UDP-based network protocols [18]. A wealth
of further work analyzed ampliﬁcation attacks, such as attempts to monitor
and reduce the number of reﬂectors [1,4,11], analyses on detailed ampliﬁca-
tion vectors in speciﬁc protocols [4,12,24–26], studies on the impact of DDoS
attacks [29], and proposals to detect and defend against ampliﬁcation DDoS
attacks [5,9,18,28].
Orthogonal to these studies, we investigated ways to perform attribution
for ampliﬁcation DDoS attacks. While concepts for closing the root cause of
ampliﬁcation attacks (IP spooﬁng) are well-known [14], little success has been
made in identifying the spooﬁng sources. Our work thus constitutes an important
element for law enforcement to identify and act upon information of booter
services that are responsible for the majority of attacks. We follow a similar goal
to IP traceback mechanisms [16,21–23,30], i.e., to ﬁnd the source of “bad” (such
as spoofed) traﬃc. While we also aim to reveal the source of the bad traﬃc, we
focus on attack services rather than locating the networks that cause the traﬃc.
Linking Ampliﬁcation DDoS Attacks to Booter Services
445
In addition, the working principles behind the methods are inherently diﬀerent.
Most IP traceback methods are deterministic and can be guaranteed to ﬁnd the
correct source of traﬃc. However, at the same time, they impose requirements
that are often not met in practice, such as that providers have to mark IP
packets or collaborate to ﬁnd traﬃc paths. In contrast, our proposed mechanism
advances the ﬁeld in that we do not require such a collaborative eﬀort. In fact,
despite being known for decades, automated traceback mechanisms have not
been deployed by many providers. To tackle this problem, our approach merely
requires a set of honeypots that anybody can set up, enabling a single party
to perform attribution. On the other hand, our approach is limited to mapping
ampliﬁcation attacks to booter services, whereas traceback mechanisms could
trace back any type of DoS traﬃc—down to the network that caused it.
Closely related to our work is AmpPot, as proposed by Kr¨amer et al. [8]. This
honeypot technology has enabled us to monitor thousands of DDoS attacks per
day. We combine such data with observations of attack traﬃc emitted by booters,
introducing the new concept of attributing ampliﬁcation attacks to booters.
Our work was motivated by various research papers that shed light onto
booter services using forensic analyses. Karami and McCoy were the ﬁrst to mon-
itor such booter services, studying the adversarial DDoS-As-a-Service concept [6]
and observing that booters are a source for ampliﬁcation attacks. Similarly,
Santanna et al. analyze leaked databases and payment methods of 15 boot-
ers [19]. Related to our idea to ﬁngerprint booters, Santanna et al. performed
self-attacks of 14 booter services and also observed that the set of reﬂectors
chosen by booters may have overlap across attacks [20]. We build upon this
observation, ﬁnd further correlations for attacks of booter services, and propose
to use theses for attack attribution. Karami et al. [7] provide a detailed view
on the subscribers and victims of three booters. They provide early attempts to
map the infrastructures of booters, but do not perform any kind of attribution
between attacks and booters or infrastructures.
Wang et al. [27] have studied the dynamics of attack sources of DDoS botnets,
showing distinct patterns per botnet. While the authors provide ﬁrst results that
might enable them to predict future attack sources, they do not further investi-
gate this matter. Our work is diﬀerent in motivation and techniques in multiple
respects. First, booters follow a completely diﬀerent methodology than DDoS
botnets, which rarely use IP spooﬁng. Second, we can leverage the observation
that attackers scan for “attack sources” (ampliﬁers). Third, we perform attack
attribution rather than prediction.
Recently, Krupp et al. [10] showed how to uncover the scan infrastructures
behind ampliﬁcation DDoS attacks, which in some cases could also be identiﬁed