performing local CFI enforcement because remote veriﬁers
can only rely on limited after-fact measurements to make
the determination whereas local enforcers simply use the
readily available unlimited runtime information. Furthermore,
remote veriﬁers cannot always determine whether a hash-
based control-ﬂow measurement is legitimate or not because
the veriﬁability is limited to those hashes pre-computed from
known/traversed code paths.
Second, checking the integrity of dynamic data is known
for its high overhead. Existing checkers [13], [3], [11], mostly
address-based, instrument every memory-accessing instruction
in a program, and during runtime, check if an instrumented
instruction should be allowed to access the referenced address,
5
src.csrc.cControl FlowInstrumentationCritical VariableDiscovery & Instrumentation... ...CVI CheckTrampolineLibrary signedblobMeasurementEngineRuntimeCompiler Compile-time TEE OSApplicationCFI CheckNormal World Secure World Veriﬁcation Engine Veriﬁcationattestation blob (i.e., measurements) is sent to the remote
veriﬁcation engine (e.g., IoT backend) along with the output
from the attested operation. We discuss OAT design details in
§IV and §V.
D. Threat Model
We trust code running inside the Secure World (e.g., the
measurement engine) and assume that attackers cannot break
the TrustZone protection. We also trust our compiler and the
trampoline code. We assume that attackers cannot inject code
in the Normal World or tamper with the instrumented code
or the trampoline library. This can be enforced using code
integrity protection methods for embedded devices [16], [37],
which are orthogonal to the focus of this paper, namely OEI
attestation. Due to the absence of a standalone OS on bare-
metal embedded devices, all code in the Normal World runs at
the same privilege level (i.e., no higher privileged code exists
or needs to be trusted).
On the other hand, we anticipate the following attacks in
the Normal World, which previous attestation methods cannot
detect. First, attackers may exploit vulnerabilities to launch
ROP (return-oriented programming) and DOP (data-oriented
programming) attacks. As a result, the control ﬂow and the
critical data of an embedded program can be compromised.
Second, attackers may abuse unprotected interfaces of an
embedded program and force the device to perform unintended
or unauthorized operations. Our system is designed to detect
these attacks by means of attestation. We present a security
analysis on our system in §VIII-D.
IV. OPERATION-SCOPED CONTROL-FLOW ATTESTATION
Inspired by the operation-oriented nature of embedded
programs, we attest CFI at the operation level, which avoids
always-on measurement collection and whole-program instru-
mentation. It is lightweight and suitable for embedded devices.
Moreover, our attestation provides deterministic veriﬁabil-
ity. It avoids the problem of unveriﬁable control-ﬂow hashes,
caused by code path explosions, as purely hash-based attesta-
tion faces [2]. The deterministic veriﬁability is achieved via a
new hybrid measurement scheme, which uses a compact trace
for recording forward edges and a hash for backward edges.
This scheme resembles the hardware tracing-based CFI [24],
[59]. But it has two major distinctions.
First, previous tracing-based CFI requires hardware com-
ponents that are not available on deployed IoT or embedded
devices1. Our control ﬂow traces are generated purely using
the software. Second, our trace is much shorter and more
compact partly because it only records forward edges (i.e.,
backward edges or returns happen very frequently and thus
would lead to overly long traces that embedded devices cannot
store). By hashing the backward edges, rather than recording
them in the trace, our scheme reduces the trace size by
97% (§VIII-B). Furthermore, combining trace and hash makes
1Although recent MCUs support tracing, this optional feature is meant for
debugging and usually unavailable on for-release devices due to additional
hardware cost.
veriﬁcation deterministic and free of path explosions. Veriﬁers
no longer need to pre-compute or search for all possible code
paths; they simply follow the forward-edge trace to reconstruct
the actual execution path, and in the end, check the resulting
backward-edge hash (more details later).
Instrumented Control Flow Events: OAT compiler instru-
ments the code in each attestation-enabled operation to collect
runtime measurements. We limit
this instrumentation to a
minimum set of the control ﬂow transfers that need to be
recorded/encoded in the measurement for deterministic ver-
iﬁcation. This minimum set, Smin, is constructed as follows.
three types of transfers possible on a CFG:
Consider all
direct call/jump, conditional branch, and indirect
transfers
(indirect call/jump and return). Only the last two types need
to be measured and are included in Smin. This is because
knowing where each branch and indirect transfer went during
a code execution is both sufﬁcient and necessary for statically
ﬁnding the exact operation execution path on the CFG. Direct
calls and jumps are not included in Smin (i.e., no need for
instrumentation) because their destinations are unique and
statically determinate.
The instrumentation code simply calls the trampoline func-
tion corresponding to the type of the instrumented control-ﬂow
transfer, reporting the destination of the transfer. For a branch,
its destination is one bit: taken (1) or non-taken (0). For an
indirect transfer, its destination is the memory address. The
trampoline functions are thin wrappers of the world-switching
routine. When called, they initiate the switch to the Secure
World and pass the destination information to the measurement
engine.
it adds the taken/non-taken bit
Measurement Scheme: The measurement engine maintains
two types of measurements for control-ﬂow attestation: a
trace and a hash. The trace is used for recording forward-
edge control ﬂow transfers (branches and indirect calls/jumps).
The hash is for encoding backward-edge transfers (returns).
The measurement engine updates the measurement trace or
hash respectively, as shown in the upper half of Fig. 2. For
each branch,
to the trace.
For each indirect call/jump, it adds the destination address
to the trace. Note that code addresses do not change across
different ﬁrmware runs (including veriﬁcation runs) because
embedded ﬁrmware is always loaded at the pre-speciﬁed base
address in memory. When dynamic loading or ASLR becomes
available in embedded ﬁrmware, the measurement engine will
need to record the ﬁrmware base address in the attestation
blob, in order for the veriﬁer to construct the same code
layout in memory and check the trace. For each return, the
measurement engine encodes the return address to the hash:
H = Hash(H ⊕ RetAddr). Here we use the symbol ⊕
to represent a binary operation. In our implementation, we
use concatenation2. The trace and the hash together form the
2See our formal deﬁnition and proof of the veriﬁcation scheme in Appendix
§B
6
Fig. 2: Operation-scoped control-ﬂow attestation. By measuring the control-ﬂow of an executing operation, the measurement engine produces
a control-ﬂow proof that consists of a trace (proving forward edges including branches and indirect transfers) and a hash (proving backward
edges or returns). This measurement scheme allows a remote veriﬁer to statically and deterministically reconstruct the code path of the
operation execution and perform full CFI veriﬁcation.
attestation blob, which serves as the proof of the control ﬂow
of an executed operation.
In our design, we chose the cryptographic hash function
BLAKE-2s3 as the Hash function for its high speed, security,
and simplicity. BLAKE-2s has a block size of 64 Bytes and
an output size of 32 Bytes. We present the collision analysis
as part of the security analysis in § VIII-D.
The reason why we use two forms of measurements, namely
trace and hash, is two-fold. First, a forward-edge trace allows
for reconstruction and easy veriﬁcation of recorded control-
ﬂow transfers. Second, a hash has ﬁxed length and does not
grow whereas a trace grows as the execution proceeds. How-
ever, control-ﬂow hashes by themselves are not always veri-
ﬁable due to the impossibility of pre-computing all possible
code paths for a program and their hashes. Our measurement
scheme uses the trace and hash in tandem to combine their
strengths while avoiding their individual weaknesses, in terms
of the ease of veriﬁcation and space efﬁciency.
Recording the forward-edge trace is necessary for code path
reconstruction. These events are either very compact (1 bit
for each branch) or infrequent (indirect calls/jumps are less
common than direct calls/jumps). Therefore, they do not bloat
the trace. On the other hand, we encode return addresses
in the hash because they are not needed during the path
reconstruction phase (i.e., only needed for checking backward-
edge CFI after a path has been constructed). Plus, returns
happen fairly frequently and, if recorded in the trace, would
consume too much space.
A possible (yet to implement) optimization would be to
record the event
type information in a separate sequence
and then use this information to enable early detection of
control ﬂow divergences during veriﬁcation (i.e., when a type
mismatch is detected, the veriﬁer can conclude that the current
stream is invalid and terminate the veriﬁcation early). For three
types of events (i.e., conditional branch, indirect branch and
return), two bits would be enough for identifying and recording
3https://blake2.net/
each type. This optimization can speed up the veriﬁcation
process at the cost of using extra storage. However, given the
fact that RAM and ﬂash storage on embedded devices are
fairly limited and the veriﬁcation process does not affect the
runtime performance, we decided not to implement the early
termination optimization for the current prototype.
The measurements are stored in a buffer allocated in the
Secure World. Although rare, this buffer can run out if an op-
eration execution is very long and yields a measurement trace
longer than the buffer. When this happens, the measurement
engine signs the current measurements, temporarily stores it
in the ﬂash storage, and frees up the buffer for subsequent
measurements. At the end of the operation, the measurement
engine sends all measurements to the remote veriﬁer.
Measurement Veriﬁcation: Given a control-ﬂow proof for
an operation execution (i.e., a trace and a hash), generated
and signed by the measurement engine, the veriﬁcation engine
statically reconstructs the code path on the CFG of the
operation, as shown in the lower half of Fig. 2. Starting
from the root basic block, or the entry point, the veriﬁer
abstractly executes the operation on the CFG by following the
forward-edge trace. During the abstract execution, the veriﬁer
maintains a simulated call stack to keep track of the return
addresses and computes/updates the hash in the same way as
the measurement engine does during runtime.
Speciﬁcally, when the abstract execution encounters a
control-ﬂow diverging point (i.e., more than one edge on the
CFG can be followed) the veriﬁer takes the next available
element out of the trace and consults it for direction: either a
taken/non-taken bit for a branch or an address for an indirect
call/jump. The veriﬁer also performs a CFI check in case of
1(cid:13) the
an address. A control ﬂow violation is found when:
CFI check fails; 2(cid:13) a mismatch is observed between a basic
block and the corresponding trace element (e.g., the current
basic block ends with an indirect call but the next available
element indicates a branch); or 3(cid:13) after the abstract execution,
the veriﬁer-computed hash does not match the reported hash.
7
...11..001011101010...    1|    2... =   ℎ( ⊕       )   ℎStreamconditionalbranchesindirectjump/callsret1...2	if	(read_command(&cmd))	{3			get_input(&peripheral_input);4			if	(status_OK(peripheral_input))	{5					op_func	=	get_op_func(cmd->op);6					(*op_func)(cmd->p_size,	...);7			}8	}9	...	(part	of	an	operation)L2L3L4L9L5L8L61010icalladdr1ret2ret3ret4ret5...Hash'AttestationBlobMeasurement-guided Path Reconstruction & VeriﬁcationEach transfer meets CFG?Hash' = Hash?Normal WorldSecure WorldProver-sideVeriﬁer-sideAll indirect call/jump violating CFI trigger 1(cid:13). 2(cid:13) can hap-
pen because when ROP happened during the actual execution,
the trace did not return to the call site whereas the abstract
execution always returns correctly (cued by the simulated call
stack). This mismatch leads to early detection of ROP (i.e.,
no need to wait till 3(cid:13)). 3(cid:13) signals that one or more return
addresses (or backward control ﬂow transfers) were corrupted
during runtime. Note that not all ROP trigger 2(cid:13) but all ROP
trigger 3(cid:13).
V. CRITICAL VARIABLE INTEGRITY
Data-only attacks,
including data-oriented programming,
are capable of manipulating program behavior and internal
logic without injecting code or violating CFI [15], [33]. For
example, as shown in Listing 1, a simple buffer overﬂow can
make the robotic arm perform attacker-speciﬁed operations
without breaking CFI. Unfortunately, existing attestation meth-
ods cannot detect data-only attacks.
We formulate Critical Variable Integrity (CVI) as a sub-
property of OEI to detect data-only attacks on embedded
devices. CVI is selective and concerns only data that attacks
target: (i) control-dependent data, such as conditional vari-
ables, whose value directly determines the code path of a
particular program execution; (ii) semantically critical data,
whose value, though not directly affecting code execution
paths, inﬂuences the outcome of an operation, such as cmd
in Listing 1. CVI is not scoped by attested operations due to
external data dependencies.
CVI is different from previous works on data integrity
check [13], [3], [11], which require heavy instrumentation and
is unsuitable for embedded devices. For example, DFI [13]
uses a whitelist to record which instruction is allowed to
access which memory address. It instruments all memory-
accessing instructions to perform the check during runtime.
DataShield [11] reserves a special memory region for critical
variables to facilitate checks. Even though it concerns only
selected data, DataShield still needs to instrument all memory-
write instructions to prevent illegal access to the reserved
memory region. In general, previous works on program data
integrity share the same fundamental approach, which we call
address-based checking. They need to check every memory-
write instruction and determines if it should be allowed to
write to the referenced address.
In contrast, CVI takes a new approach to data integrity
checking, called Value-based Deﬁne-Use Check. It checks
if the value of a critical variable at an instrumented load
instruction (i.e., use) remains the same as the value recorded
at the previous instrumented store instruction (i.e., deﬁne).
At an instrumented store instruction, CVI makes a copy of
the value in a secure region guarded by TrustZone. At an
instrumented load instruction, CVI compares the value read
from memory with the copy recorded in TrustZone. Any
data corruption causes a value mismatch and therefore a
CVI breach. CVI only needs to instrument the instructions
that are supposed to read/write the critical variables whereas
address-based checkers have to instrument all memory-write
TABLE I: Comparison between Different Data Integrity Mechanisms
(R:Read, W:Write)
Instrumentation
Name
All memory R&W
DFI [13]
WIT [3]
All memory W
DataShield [11] All memory W
CVI
Whitelist
Yes
Yes
No
Critical variable R&W No
Check
Addr.
Addr.
Addr.
Value
instructions even if only selected data needs checking. Table I
shows the comparison between CVI and the previous data
integrity checking techniques.
Critical Variable Identiﬁcation & Expansion: OAT compiler
automatically identiﬁes control-dependent variables, including
branch/loop condition variables. Note that we do not include
code pointers as critical variables. This is because all control-
ﬂow violations, including those resulted from corrupted code