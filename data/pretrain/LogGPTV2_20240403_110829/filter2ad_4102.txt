# Title: Effect of Security Controls on Patching Window: A Causal Inference-based Approach
# Authors: Aditya Kuppa, Lamine M. Aouad, and Nhien-An Le-Khac
# Conference: Annual Computer Security Applications Conference (ACSAC) 2020

## Motivation
- Can security controls help in addressing residual risk?
- How do defenders use security controls to manage their residual risk?
- Do the characteristics of security controls influence the patching time windows?

### How This Study Can Help Defenders
- Re-calibrate and manage residual risk for a given threat or class of threats, given that a control is already installed.
- Prioritize patching of a specific Common Vulnerabilities and Exposures (CVE) based on the effectiveness of the security control.
- Allocate security investments into people, processes, and controls depending on the organization's risk appetite.
- Convey risk decisions in a data-driven manner to stakeholders and decision-makers.
- Improve and manage the controls that are already in place.

## Impact

### Classifier-Centric View
- The features collected capture the underlying data distribution and are not conditional on external influences or biases.
- It assumes that the patch window is dependent on CVE-specific features.
- Inference of \( y \) via a classifier treats features (\( X \)) as independently observed inputs.

### Causal-Centric View
- The features collected capture the underlying data distribution and are conditional on external influences or biases (\( Z \)).
- Assumes there are unknown variables that influence the features, outputs, and data generation process.
- Inference of \( y \) is dependent on features (\( X \)) and hidden confounders (\( Z \)).

## Causal Inference
- The concept of causality can be understood in terms of units, treatment, and outcomes.
- **Units**: Physical objects (assets) of interest at a particular point in time.
- **Treatment (\( T \))**: Exposure to a security control.
- **Pre-Treatment Variables**: Background noise and confounders.
- **Post-Treatment Variables**: Affected by the treatment.
- **Treatment Effect**: Measured at the population (Average Treatment Effect, ATE), treated group (Conditional Average Treatment Effect, CATE), subgroup, and individual levels (Individual Treatment Effect, ITE).
- **Outcomes**: Patching of CVE.
- **Potential Outcomes**: For each unit-treatment pair, the outcome if that treatment were applied.
- **Observed Outcomes**: The actual outcome of the treatment that was applied.
- **Counterfactual Outcomes**: The outcome if the unit had taken another treatment.

### Example
- An asset \( a \) is exposed to a CVE, and there are two security controls, \( SC_a \) and \( SC_b \), with mitigation rates of 70% and 90%, respectively.
- Observational data includes a group of assets/organizations (units) who installed/configured different security controls (treatment), their corresponding outcomes (mitigation and patch timelines), but without direct access to the reason/mechanism why/how they use specific controls.
- With causal inference, we can observe the delay in the application of a patch for the CVE in the presence or absence of \( SC_a \) or \( SC_b \).

## Problem

### Question 1: Does the Presence of Security Controls on Assets Influence the Patch Management Policy?
- **\( X \)**: Covariate vector (includes CVE features).
- **\( T \)**: Binary treatment variable (presence of security control on the asset).
- **\( Y \)**: Outcome of interest (delay in patching, measured as the time difference from the patch release date to the patch applied date on the asset).
- **Average Treatment Effects (ATE) of \( T \) on \( Y \)**:
  \[
  \tau = E[Y(1) - Y(0)]
  \]
- We are interested in estimating the ATE.

### Question 2: Do the Characteristics of Security Controls Influence the Patching Time Windows?
- **\( X \)**: Feature vector containing pre-treatment covariates of CVE.
- **\( T_f \)**: Treatment random variable (security control), a pair of values \( T_f = (W_f, D_f) \), where \( W_f \in W \) corresponds to the type of treatment being administered (e.g., \( SC_1, SC_2 \)).
- **\( D_f \)**: Corresponds to the dosage of the treatment (e.g., parameters derived from a continuous function which, for a given treatment \( w \), lies in the corresponding treatment’s dosage space \( D_w \) (e.g., the interval [0, 1]).
- **Individual Treatment Effects (ITE) of \( T \) on \( Y_i \)**:
  \[
  \tau_i = E[Y_i(1) - Y_i(0)]
  \]
- We are interested in estimating the ITE.

### Scoring Function
- The capability of a security control can be measured based on multiple criteria:
  - Effectiveness (\( Eff \))
  - Coverage (\( Cov \))
  - Assurance (\( Assu \))
  - Cost (\( Co \))
  - Impact (\( Im \))
  - Mitigation Time (\( Mt \))

#### Process
- Selection of datasets to use.
- Setting security controls criterion’s weightings.
- Conducting effectiveness scoring.
- Computing relative trade-off scores.

### Scoring Function Example
- To weight the Impact (\( Im \)) criteria based on prevention, detection, and response (P/D/R), security managers can set \( w_p = 0.5 \), \( w_d = 0.25 \), and \( w_r = 0.25 \) respectively.
- For example, if the CVSS Score is 7, then \( (r, t) = (0.7, 0.3) \).
- The truncated distributions method can be used to generate order weights \( W = [0.5, 0.25, 0.25] \) and [0.67, 0.04, 0.29].

## Datasets

### Patch Status Data Set
- Nessus vulnerability scanner output from 2000 enterprises.
- \( patch\_delay \) is calculated as the difference between the patch applied date (FIXED) and the date on which the CVE was first found on the asset (OPEN) in the scan output.
- Only assets that are regularly scanned over a 90-day period are considered to ensure short-lived assets are not included.
- Organizations have a centralized patching policy.
- Only CVEs/assets that have been patched on at least one asset in the organization are considered.

### CVE Features
- 269 features for each CVE, including:
  - Age of CVE, CVSS Vector, CPE, CWE, CAPEC, MITRE techniques mapped to CVE, exploit availability and sources, and software types.
  - Textual features: topics extracted from media sources, web forums, paste sites, blogs, descriptions of CVE on NVD and vendor notes, and mitigation steps of CVE.
- For textual features, a Word2Vec model is trained with text data, outputting 100 covariates. Numerical and textual features are concatenated to form a feature vector of size 269.

### File-Based Mitigation Dataset
- 508,521 file hashes of current attacks in the past three months from a threat intelligence vendor, covering around 3,000 CVEs.

### Attack Emulation Dataset
- MITRE ATT&CK attack simulations of ATP29, APT3, and FIN7 APT groups on cybersecurity products using an open methodology.
- For a particular attack, 134 substeps are recorded.
- The detection/protection capability of the product is assessed.

## Experiments – Metrics
- **Evaluation Metrics**:
  - Rooted Precision in Estimation of Heterogeneous Effect
  - Mean Absolute Error on ATE

### Experiments – Question 1
- We estimate the Average Treatment Effect (ATE) with the Doubly Robust Estimator (DRE).
- First, fit the treatment and response with one classifier.
- Use a linear model to predict the response residuals from the treatment residuals.
- Models used: Logistic Regression (LR), Random Forest (RF), Multi-Layer Perceptron (MLP), and Gradient Boosting (GB) in terms of propensity score and outcome (both treated and control) estimations.
- Data is randomly split into training (63%), validation (27%), and test sets (10%) for all models to report the scores, and grid search is employed to tune the parameters of the models.

### Experiments – Question 2
- Ground truth data for ITE estimation is very hard to obtain.
- Create a semi-synthetic dataset from real-world observations by leveraging the continuous scoring function to derive counterfactuals from risk curves.
- Ideal potential outcomes are modeled using truncated Gaussian distributions \( \tilde{y} \sim N(\mu_{dose}, \sigma) + \epsilon \) with \( \epsilon \sim N(0,1) \), where \( \mu_{dose} = (p\_score, d\_score, r\_score, f\_m\_score) \) is derived from the weights from the scoring function for each treatment.
- State-of-the-art methods for learning ITEs from observational data are used:
  - Counterfactual Regression (CFR)
  - Causal Effect Variational Autoencoder (CEVAE)
  - Bayesian Additive Regression Trees (BART)
  - Dose Response Network (DRNet)

## Results
- The presence of security controls influences the patching policy of the defender, with an average delay window of 9.45 days.
- The capability of security controls directly impacts the patching priority in organizations. CVEs with higher CVSS scores are left unpatched for an average of 5-6 days in the presence and absence of controls, while CVEs with low scores are delayed by 10-12 days.
- Organizations with response-oriented controls tend to delay patching more than those with protection and detection.
- Defenders invest in controls that align well with the security goals of the organization. For example, if the organization has invested in incident response personnel, they may prefer controls that help in detection rather than the response process.
- Overall, the results highlight the importance of security controls in the defender's risk management process.

## Related Work
- Our work combines several research areas:
  - **Security Control Scoring**: Most surveyed work either runs operations research (OR) simulations or relies on SME surveys to score security controls. We provide tunable parameters for stakeholders to choose from a set of controls, fitting well within the causal inference framework.
  - **Risk Management**: State-of-the-art frameworks define factors and metrics for risk, threat, and risk estimation. The main weaknesses are the predominantly manual process or lack of formal modeling. We present a mathematical formalism and significantly improve the level of automation in cybersecurity risk assessment.
  - **Causal Inference**: Applying causal inference in the context of a security dataset is rare. To the best of our knowledge, this is one of the first attempts to study security policy problems through the lens of causal inference.

## Future Work
- Our work opens up multiple research directions:
  - There are many scenarios in cybersecurity where labeled data is scarce, and decisions must be made based on observational data.
  - Applying causal inference to other areas of cybersecurity and adapting the proposed method to areas of security risk assessment and processes in organizations.
  - Causal learning helps build robust, reproducible, and easier-to-explain models in the cybersecurity domain and needs further exploration.