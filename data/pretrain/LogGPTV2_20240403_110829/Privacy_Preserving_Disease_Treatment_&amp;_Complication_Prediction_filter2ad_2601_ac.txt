structed.
hash function, and use L-bit Bloom ﬁlters to handle typos.
1. Operations performed by the TA:
(i) In the initialization phase, a secret key SK = {KO, KB,
KA} is produced by the trust authority where (a) KO is a
symmetric key for OP E operation; (b)KB is the generation
key for the Bloom ﬁlter generation; (c) KA is the key used
for computing key hash values of category keywords.
(ii) Then, TA generates a set of key hash values of category
keywords, Enc(CW ) = {Enc(cw1), Enc(cw2), ···} which
will form the 1st level nodes.
(iii) For every category i, TA also produces a set: (cid:102)Wi
= {ai1, ai2, ··· , ai|(cid:103)Wi|}, where aij is a disease keyword
belonging to category i. Next, for each keyword aij, the TA
generates a fuzzy keyword set: {aij1 , aij2 , ···}, where aijz is
fuzzy keyword sets into a L-bit Bloom ﬁlter, bf ((cid:102)Wi), using
a single-typo keyword of aij. The TA inserts the keyed hash
values of all relevant disease keywords and their associated
nodes, |Ci| for each category node i and forms the set (cid:101)S =
{|C1|,|C2|,··· ,|C|(cid:101)S||}. Then, for each child node (e.g., the
(iv) In addition, TA determines the number of children
the secret key KB.
jth child node of the ith category), it stores a keyword set
Dij, which contains k disease keywords. Next, TA generates
a Bloom ﬁlter bf (Dij), which contains those k keywords as
well as their associated fuzzy keywords. Our solution inserts
the same disease into k diﬀerent 2nd level nodes so that
the cloud server can go through k diﬀerent nodes (based on
query identiﬁers) to ﬁnd a matched leaf node even with the
same keyword search request. Thus, both the search and
path patterns can be hidden from the cloud server.
cluding {Enc(CW ),(cid:101)S,{BF D((cid:102)W1),··· ,BF D((cid:93)W|S|)}}, where
BF D((cid:102)Wi)={Icwi ,bf ((cid:102)Wi),{bf (Di1),bf (Di2),··· ,bf (Di|Ci|)}}
(v) Finally, TA delivers all the generated ciphertexts in-
and Icwi is a category index, to the cloud server.
(vi) It also sends both encrypted category keywords, Enc(CW )
and the secret key SK to every hospital. The secret key SK
is also sent to all authorized clients.
2. Operations performed by hospitals:
(i) Every hospital Hm contains a category set (cid:94)CWm=
{kw1,kw2,··· ,kw| (cid:94)CWm|} and a disease keyword set {Gm(kw1),
Gm(kw2), ··· , Gm(kw| (cid:94)CWm|)}, where Gm(kwi) = {bi1, bi2,
··· , bi|Gm(kwi)|} and bij is a disease keyword.
(ii) Then, hospital Hm generates Enc(CWm) which con-
sists of all key hash values of category keywords in CWm.
(iii) For each illness bij which Hm has relevant patients’
information, it also generates bf (bij) using the secret key
KB.
(iv) Next, Hm uses a classiﬁcation method to extract the
training feature set for that illness bij, denoted as (cid:101)sv(bij).
the KO key to produce(cid:103)SV (bij)=OP EKO ((cid:101)sv(bij))+rij, where
Later, it encrypts this training feature set using OPE and
rij are some random value sets. The random values are
added to ensure the participating hospitals cannot uncover
the true values of these feature vectors each hospital sends
even if some hospitals collude with the cloud server.
(v) Finally, hospital Hm sends {Enc((cid:94)CWm),{BSV (Gm(kw1)),
{bf (bi1), (cid:103)SV (bi1)}, ··· , {bf (bi|Gm(kwi)|), (cid:103)SV (bi|Gm(kwi)|)}}
··· , BSV (Gm(kw| (cid:94)CWm|))}}, where BSV (Gm(kwi)) = {Ikwi ,
and Ikwi is the category index for category keyword kwi, to
the cloud server.
3. GenIndex: (i) The cloud server ﬁrst builds the 1st level
846Figure 6: PDTCPS Index Tree Structure
nodes, where the ith category node stores the encrypted key-
word Enc(cwi) and the corresponding Bloom ﬁlter bf ((cid:102)Wi).
(ii) Then, the public cloud uses the received information
to build the 2nd level, where the jth second level node of
the ith ﬁrst level node stores the corresponding Bloom ﬁlter
bf (Dij).
(iii) For each 2nd level node, the cloud server constructs
three children nodes, one for each query type, i.e., “diag-
nose”, “complication” and “treatment”. An integer value can
be used to represent each query type.
(iv) For each received set of information from a hospital,
the cloud server ﬁrst uses the received Enc(kwi) to ﬁnd the
matched 1st level category node. Then, it computes the
inner product values between each of the received bf (bij)
and the Bloom ﬁlters stored in the |Ci| child nodes under
the ith category node to ﬁnd the k matched 2nd level nodes.
Next, the cloud server traverses into their leaf nodes to ﬁnd
the right training model.
(v) If no training model exists, the newly received training
model will be stored. If a training model already exists, the
public cloud generates a new model by combining previously
stored feature vectors for that disease with the most recently
received feature vectors to generate a new training model.
With the procedures outline above, the cloud server ﬁnally
constructs the encrypted index tree, which is shown in Fig 6.
Query Generation
ferent search request even for the same keyword query.
To provide query unlinkability, we need to generate a dif-
(i) Given a query Q={cwq, (F1, ··· , Fi, ··· ), xq, tq},
where cwq is the category keyword, Fi is either a personal
attribute of a client or his lab test result i, xq is the disease
keyword and tq is the query type.
(ii) An authorized client ﬁrst generates a random query
id IDq and a keyed hash value of the category keyword as
Enc(cwq).
(iii) Each Fi will be encrypted as OP EKO (Fi) + Ri using
the received encryption key KO and a random value Ri. This
step ensures that the same Fi results in diﬀerent encrypted
value and hence provides query unlinkability.
(iv) The client also generates a fuzzy keyword set: {xq1 ,
··· , xqi , ···}, where xqi
is a single-typo keyword of xq.
Then, the client generates bf (xq) using the secret key KB.
(v) Finally, the encrypted search request EncSK (Q)={IDq,
(OP EKO (F1) + R1, ··· , OP EKO (Fi) + Ri, ··· ), Enc(cwq),
bf (xq), hash(tq)}, is submitted to the cloud server.
Search Process
(i) Upon receiving the search request EncSK (Q), the server
ﬁrst checks if Enc(cwq) can be matched with the stored
encrypted keywords Enc(CW ) in the 1st level nodes.
(ii) If it is not found, then the cloud server computes the
Figure 7: Inner Product Computation
inner products of Bloom ﬁlter bf (xq) in the query with |(cid:101)S|
Bloom ﬁlters stored in the 1st level nodes. The one with the
best match will be the selected 1st level node. (Fig 7)
(iii) Next, the cloud server searches through the child
nodes of this selected 1st level category node by perform-
ing the following operations:
• Compute the inner product values between the bf (xq)
and the stored |Ci| Bloom ﬁlters in the 2nd level nodes.
• Find the top k nodes among those |Ci| nodes in the
• Next, select one of k matched 2nd level nodes, node j,
using j = IDq mod (k) and travels into its sub-tree nodes
based on the query type.
second level.
(iv) After ﬁnding the matched leaf node, the cloud server
can ﬁnd the appropriate training model to diagnose disease,
predict potential complications or determine the best treat-
ment options for a client based on his query type, tq.
5. SECURITY ANALYSIS
In this section, we analyze the privacy characteristic of
P DT CP S against possible attacks by various entities in-
volved in our system. Adversaries in our system could be
participating hospitals, network eavesdroppers, or even the
cloud server. For instance, hospitals and the cloud server in
our system are assumed to be semi-trusted, implying that
they follow the protocol execution, but may attempt to learn
additional information. A network eavesdropper could have
the resources to monitor all messages in the network or the
messages sent by a particular hospital or a client.
5.1 Network Eavesdroppers
For network eavesdroppers, P DT CP S achieves privacy
preserving mainly via encrypted communication. Our de-
signed scheme guarantees that attackers cannot uncover any
knowledge of any content within the ciphertext as long as
eavesdroppers cannot obtain the cryptographic keys. In ad-
dition, by adding randomness in each encrypted query, the
adversaries cannot conduct frequency analysis to gain ad-
ditional information about submitted queries and hence no
sensitive information is revealed.
5.2 Semi-honest Hospitals
In the presence of semi-honest hospitals, our scheme achieves
information-theoretic security. Speciﬁcally, our design adds
some randomness to the encrypted training features gener-
ated by each hospital before they are being sent to the cloud
server. Thus, participating hospitals cannot gain additional
information on the ciphertext sent by other hospitals even
if they know the secret key.
8475.3 Semi-honest Cloud Server
several search privacy requirements:
In this subsection, we will show how P DT CP S satisﬁes
• Index and Query conﬁdentiality under both the known
ciphertext model and the known background model. More
details are provided in subsequent subsections.
• Query unlinkability: Our P DT CP S generates diﬀerent
search requests even with the same query keyword and hence
provides query unlinkability to a certain extent.
• Hiding access pattern: Our design ensures that the cloud
server traverses diﬀerent nodes to ﬁnd a match even with the
same keyword search request and hence the access patterns
are hidden from the server.
5.3.1 Security Analysis of PDTCPS Under the
Known Ciphertext Model
Here, we adapt the simulation-based security model in [27]
to prove that our scheme can be secure under the known
ciphertext attack. Before proving, we ﬁrst introduce some
notations that will be used in the proving process.
• History: It is an index set I and a query set Q = {Q1,
Q2, ···}, denoted as H = (I, Q).
• View: The cloud server can only see the encrypted
form of a H, denoted as V I(H), including the secure in-
dexes Enc(I) and the encrypted search requests Enc(Q) =
{Enc(Q1), Enc(Q2), ···}.
• Trace: A trace is a set of queries, denoted as T r(H) =
{T r(Q1), T r(Q2), ...}. T r(Qi) captures the information for
each query Qi including the search pattern P AQi , and the
outcome of the search REQi which is available to the cloud
server to gain additional information.
As in [27], our proof is based on the following argument:
given two histories that produce the same trace, if the cloud
server cannot distinguish which history is produced by the
simulator, then the cloud server cannot learn additional knowl-
edge beyond the information that the system is willing to
leak.
We adopt a simulator that can simulate a view V I(H)(cid:48)
indistinguishable from cloud server’s view V I(H). The sim-
ulator works as follows:
erates Enc(Q1)(cid:48) as follows:
where si ∈ {0, 1}U , and then sets ID(cid:48)
s2 and hash(t(cid:48)
value, ID(cid:48)
keyword in that query and t(cid:48)
1. For the encrypted query Enc(Q1), the simulator gen-
(i) The simulator ﬁrst selects random strings {s1, s2, s3},
Q1 ) =
Q1 ) = s3 separately. U is the length of hash-
Q1 is the category
(ii) The simulator also generates a L(cid:48)-bit vector v ∈ {0, 1}L(cid:48)
Q1 mimics the disease keyword
and sets bf (x(cid:48)
in the query.
(iii) Next, the simulator builds a vector which represents
Q1 ) = {G1,
encrypted attributes used in the query, Enc(F (cid:48)
G2, ···}, where Gi is a random string chosen from {0, 1}U .
(iv) After the above steps, the following encrypted query,
Enc(Q1)(cid:48)={ID(cid:48)
Q1 ),hash(t(cid:48)
is simulated.
generate the Enc(I)(cid:48) as follows:
2. Based on the search pattern P AQ1 , the simulator can
Q1 is the query identiﬁer, and cw(cid:48)
Q1 = s1, hash(cw(cid:48)
Q1 ) = v where x(cid:48)
Q1 is its query type.
Q1 ),hash(cw(cid:48)
Q1 ,Enc(F (cid:48)
Q1 ),bf (x(cid:48)
Q1 )},
(i) Let us assume P AQ1 goes through category node ca(1),
intermediate node im(1) and leaf node ln(1) of the index
tree.
(ii) The simulator ﬁrst sets the Enc(ca(1))(cid:48) = hash(cw(cid:48)
(iii) Then, the simulator adds bf (x(cid:48)
Q1 ) to bf (ca(1))(cid:48).
Q1 ).
(iv) The simulator also sets bf ((cid:102)D(cid:48)
Q1 ), where |(cid:102)D(cid:48)
Q1| = k and (cid:102)D(cid:48)
Q1 )(cid:48) = bf ((cid:102)D(cid:48)
Q1 )(cid:48) +
Q1 )mode(k)] =
Q1 [(ID(cid:48)
bf (x(cid:48)
im(1).
3. For subsequent queries such as Qj with search pattern
P AQj which goes through category node ca(j), intermediate
node im(j) and leaf node ln(j) of the index tree where 2 ≤
i ≤ j ≤ |Q|, the simulator does the following:
(i) If ca(j), im(j), ln(j) are not same as ca(i), im(i), ln(i),
then the simulator repeats the same process as simulating
Enc(Q1)(cid:48) and Enc(I)(cid:48).
(ii) If ca(j) is the same as ca(i) but im(j) (cid:54)= im(i), then
the simulator repeats the same process as simulating Enc(Q1)(cid:48)
Qj )=hash(cw(cid:48)
and Enc(I)(cid:48) with the condition that hash(cw(cid:48)
Qi ).
(iii)If im(j) is the same as im(i) but ln(j) (cid:54)= ln(i), then
Qi ) and also generates
the simulator sets hash(t(cid:48)
all the other necessary information.
Qj ) (cid:54)= hash(t(cid:48)
Qi ).
Qj ) = hash(t(cid:48)
Qi ) and does the following:
(iv) If the search pattern P AQj ends at the same leaf
node ln(i) as the previous query Qi, then the simulator sets
hash(t(cid:48)
• If the search result REQj for the query Qj, is not the
same as REQi , then the simulator repeats the same process
as simulating Enc(Q1)(cid:48) and Enc(I)(cid:48) with the condition that
the Enc(F (cid:48)
• If the search result is the same, then the simulator sets
bf (x(cid:48)
Qj ), which is
similar to the Enc(F (cid:48)
Qi ).
Qi ) and generates the Enc(F (cid:48)
Qj ) is diﬀerent from the Enc(F (cid:48)
Qj ) = bf (x(cid:48)
Qi ) to the training feature set (cid:101)sv(x(cid:48)
4. After all the queries have been simulated, the simulator
• It converts each bf (ca(i))(cid:48) and bf (im(i))(cid:48) into L(cid:48)-bit
vectors by replacing the elements bigger than 1 with
does the following:
{0, 1}L(cid:48)
1. • It adds Enc(F (cid:48)
Qi )
Note that the training feature set (cid:101)sv(x(cid:48)
to make sure that the query result is the same as REQi .
Qi ) is attached to the
5. The simulator outputs the view V I(H)(cid:48)=(Enc(I)(cid:48),
In summary, the Enc(I)(cid:48) and Enc(Q)(cid:48) can generate the
same trace as the one that the cloud server has. Thus, we
claim that no probabilistic polynomial-time (P.P.T) adver-
sary can distinguish between the view V I(H)(cid:48) and V I(H).
5.3.2 Security Analysis of PDTCPS Under the
appropriate simulated leaf node.
Enc(Q)(cid:48)).
Known Background Model
In this subsection, we analyze the security of P DT CP S
under the known background attack model. For each query
Qi we generate the encrypted search request as follows:
Enc(Qi)={IDQi ,Enc(FQi ),hash(cwQi ),bf (xQi ),hash(tQi )}.
Since a random value set is introduced during the query gen-