safety lifecycle, phases heavily depend on each other: the
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:30:50 UTC from IEEE Xplore.  Restrictions apply. 
input from one phase serves as output to subsequent phases.
If one phase is completely missing, and is not replaced or
compensated for by an alternative technique2 then this can-
not be compensated for by any other phase. Thus if one
EVj is 0, the EV of the parent phase and ﬁnally the overall
EV should be 0 as well.
The above selected aggregation functions are sugges-
tions. Others are possible, such as
EVP = min
j=1,...,n
(EVj)αj .
A possible way to model aggregation functions is by formu-
lating a set of beliefs or axioms on how missing evidence
inﬂuences the overall EV. Possible axioms that have been
formulated on aggregation functions, for example in [6] are
given below. Let EVj be the evidential volume for phase
Pj. Let EVP be the evidential volume of a parent phase,
(this includes the overall EV of the product under assess-
ment).
i) The calculation of EVP is uniquely determined.
ii) EVP shall be not larger than the largest value EVj and
not smaller than the smallest value EVj.
iii) Small improvements in EVj, j ∈ {1, ..., n} do not
make EVP smaller.
iv) EVP shall take on its highest possible value (i.e. 1)
only when all EVj take on the highest possible value.
va) EVP shall take on the smallest possible value (i.e. 0)
only if all EVj take on the smallest possible value.
OR
vb) EVP shall take on the smallest possible value if at least
one EVj takes on the smallest possible value.
One can see how the functions in (2) and (3) ﬁt into this
context. Both equations (2) and (3) fulﬁl i) - iv). (2) ful-
ﬁls va), whereas (3) fulﬁlls vb). Axiom vb) represents a
“Knock Out” (K.O.) criterion: if evidence for one phase is
completely missing, then the resulting EVj will be 0. This
ﬁlters down to the parent-phase, EVj = 0 cannot be com-
pensated for by another phase having been performed ex-
ceptionally well, the resulting EVP and ﬁnally the overall
EV will be 0.
A future step of our work will be to carry out a sensitivity
study to examine the effect of several choices of aggregation
functions on the results obtained with EVA.
2Hereby, replacement of a technique with an alternative method should
be performed according to the principles acceptable in the context of the
standard.
3.3 Tool-support
We have taken the above considerations in sections 3.1.
and 3.2. as the basis of specifying a tool that implements
EVA for IT 10−4. We have started the implementation
of this tool using an Excel Workbook in which all require-
ments pertaining to IT 10−4 and their rankings (I, V, L) are
contained. For each requirement there are columns headed
“requirement met”, “not met”, “not applicable”. These
columns take binary inputs (1 for yes, 0 for no). Further
columns list the evidence required to demonstrate that the
requirement is met, again the entries in this list can be
“ticked” by entering 0 or 1. A set of alternative evidence
routes is offered, which can replace the direct evidence. We
currently develop an interface which presents the user with
the list of phases, by clicking one phase, a new interface
pops up that shows the list of requirements, for which the
user then has to enter one of the choices above. If “require-
ment met” is ticked, then the list of required evidence or
alternative evidence will be shown. If not all evidence is
“ticked off”, but still “requirement met” is chosen, a warn-
ing will be issued. Based on the set of rankings r(Rij) of all
applicable requirements, the set of ﬁnal weights wij is cal-
culated by the Workbook as described in 3.1. The weights
for all phases are assumed to be equal. Based on the weights
and the user input, the EV for the currently chosen phase
can be calculated using (2) and displayed. This can be done
for each phase and ﬁnally, the overall EV will be calculated
using equation (3) and displayed to the user. Since this is
an ongoing project, the further development of this tool will
be part of future work. A feature that we aim at including
is to indicate how many V-requirements are missing in to-
tal. This refers to some feedback from our collaborators in
which a Knock Out (K.O.) criterium was suggested, such
as: “More than x V-rated requirements missing should lead
to rejection of the product”. At this stage of our work, the
aim of developing a simple tool is to support the discus-
sion on the approach. The tool will be disseminated to a
group of people involved in the project so that the way in
which the approach currently works can be easily seen and
tested by them. This, we believe, will again produce valu-
able feedback. An option for the implementation of EVA
in the long-term would be to put the calculation of the EV
“on top of” an existing tool. This could be for example
a tool used to display the evidence structure in the certiﬁ-
cation process graphically. This would allow to show all
the evidence and backing evidence required for each clause
of a standard in a structured way and simultaneously dis-
play the achieved level of compliance at each stage. A tool
that we explored in this context is the Adelard ASCE tool
for safety-case generation [7]. ASCE gives the possibility
to display the evidence structure of a standard such as e.g.
IEC 61508 or the PES Guidelines in a convenient and visu-
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:30:50 UTC from IEEE Xplore.  Restrictions apply. 
ally accessible way. If the calculation of an EV was added
to this tool, then for example the calculated EVP s for each
phase and the overall EV could be displayed as an additional
decision-aid.
4 Use of the Evidential Volume in decision-
making
Once the weights and aggregation functions are speci-
ﬁed, the outcome of an assessment as measured by the evi-
dential volume is repeatable and can be compared to the
outcome of other assessment scenarios. For all products for
which the same EV is achieved, the same decision outcome
should be made: accept or reject.
n(cid:1)
Potentially, the evidential volume can be used to formu-
late a prior belief on the reliability of the product under as-
sessment, which could form the basis of deciding whether
or not to perform further more quantitative assessment such
as statistical testing. Such a prior belief could be for exam-
ple expressed in the form of a probability of success or a
conﬁdence in having achieved the required integrity target.
A possible approach to link the EV to a success probabili-
ty, is based on the success likelihood index model (SLIM)
[8].
In SLIM, a success likelihood index S is calculated
I[P SFi] · wi. Hereby, P SFi are performance
via S =
shaping factors contributing to the task at hand. wi de-
scribe the relative importance of P SFi for the task, hereby
n(cid:1)
wi = 1. I[P SFi] rate the quality of P SFi in the cur-
i=1
rent context. The EV is a similar compilation of weights
and ratings for a set of factors, all inﬂuencing the quality of
the ﬁnal (human) task of producing a system of suitable re-
liability. Thus, we interpret the EV as a success likelihood
index. The use of SLIM in the context of reliability estima-
tion is also mentioned in [9]. Using SLIM, the following
relation can be established between EV and a probability
of success P success [8].
i=1
Log(P success) = a · EV + b.
(4)
P success can be deﬁned as the probability of having suc-
cessfully met the claimed integrity target, i.e. P success :=
P r(pf d < Integrity Target). The parameters a and b in (4)
are determined through the boundary conditions
EV = 0 : P success = PLower, Log(PLower) = b,
EV = 1 : P success = PU pper, Log(PU pper) = a + b.
(5)
SLIM is originally used to model human error probabili-
ties. The task of developing a software product from a given
speciﬁcation to a certain level of reliability is a human task,
thus use of this model seems suitable. It has to be noted that
even though SLIM is based on experimental data and theo-
retical considerations, [8], it is to be seen as a modelcompi-
ling expert judgement and thus prior belief rather than being
derived from statistical inference. Thus it is important to
check the message the model conveys against expert beliefs
for example for a series of example scenarios.
In (5), for two extreme cases such as EV=0 or 1, one
formulates a prior belief about P success. This could take
on the following form. We consider the example of aiming
at a SIL 2 system, i.e. pf d < 0.001, see (1). In the case
of EV=1, we have encountered the “ideal” assessment sce-
nario where all evidence is demonstrably met. In this case,
because the standard comprises the consensus on what is
considered to be sound development practice, and because
compliance with the standard is associated with complying
with the claimed integrity level, one could model PU pper as
for example 0.99. This would be the same level of conﬁ-
dence that one often aims at with statistical testing. Other
values for PU pper are possible, the importance is on check-
ing it with expert belief. The value PLower can be modelled
as follows.
In the absence of all evidence, we could as-
sume that we do not know anything about the system’s pfd.
This can be modelled through a uniform prior distribution
over the pfd, which results in P r(pf d < 0.001) = 10−3.
Thus a possible choice is PLower = 10−3. The assump-
tion PLower = 0 is not suitable due to the Log(PLower) in
equation (5).
Using (4) and (5), one can then calculate P success for EV
∈]0, 1[. In the following, we shall perform some example
calculations. We deﬁne boundary conditions as described
above, and calculate success probabilities for different EVs.
4.1 Example
A. Calculating P success.
We deﬁne P success := P r(pf d < T ). Hereby T is the pfd
target under the given SIL or IT, which in the case of IEC
61508 can be interpreted as the lower bound of the pfd inter-
val in (1). For the PES Guidelines the pfd target coincides
with the integrity level. We assume the following boundary
conditions:
1) SIL 1/IT 10−2. P success := P r(pf d < 0.01).
PLower = 0.01, PU pper = 0.99.
2) SIL 2/IT 10−3. P success := P r(pf d < 0.001).
PLower = 0.001, PU pper = 0.99.
3) SIL 3/IT 10−4. P success := P r(pf d < 0.0001).
PLower = 0.0001, PU pper = 0.99.
Table 1 contains the results on calculating P success for dif-
ferent values of EV. Using SLIM with the above boundary
conditions yields for SILs 2 and 3 a relatively small esti-
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:30:50 UTC from IEEE Xplore.  Restrictions apply. 
Table 1. Results from calculation of P success.
SIL 1
EV P success
0.99
0.95
0.9
0.8
0.5
SIL 2
0.95
0.787
0.625
0.39
0.099
EV P success
0.942
0.99
0.95
0.7
0.497
0.9
0.249
0.8
SIL 3
EV P success
0.99
0.95
0.9
0.8
0.9
0.624
0.394
0.15
mated success probability already when 5 − 10% of the to-
tal evidential volume is missing. This may be considered as
too pessimistic by experts, in which case the model needs
to be revised to capture these beliefs. However, 5% of the
total evidential volume missing may be considered as a case
where a considerable decrease in conﬁdence in the product
from assessment data alone is justiﬁed.
In this case, one
can investigate whether a higher level of conﬁdence can be
achieved by adding evidence such as statistical testing.
We will next perform some example calculations of
evidential volumes on a constructed example.
B. Calculating EVs
Assume a standard/guideline consisting of 8 phases. For
this constructed example we also assume that each phase
consists of no sub-phases but simply of a list of 7 require-
ments. Each phase is given the same weight αj = 1
8 . The
rankings given to the requirements are as follows:
P1: (10,10,10,10,10,10,10), P2: (100,100,10,10,10,10,10),
P3: (100,100,10,10,10,10,10), P4: (100,100,10,10,10,10,10),
P5: (100,100,10,10,10,10,10), P6: (100,100,10,10,10,10,10),
P7: (100,10,10,10,10,10,10), P8: (10,10,10,10,10,10,10).