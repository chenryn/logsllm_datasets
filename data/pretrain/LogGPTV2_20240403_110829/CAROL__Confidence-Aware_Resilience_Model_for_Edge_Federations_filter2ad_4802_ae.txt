• Without
the GON model, and using a traditional feed-
forward model, the decision time is reduced again, but at
the cost of higher ﬁne-tuning overheads.
We observe that the conﬁdence-aware model ﬁne-tuning and
using the GON network have the maximum impact on perfor-
mance values, accounting to nearly 70% of the total impact.
E. Sensitivity Analysis
Figure 6 provides a sensitivity analysis of the performance
i.e., γ in (1),
of the CAROL model with learning rate,
memory consumption and size of the tabu list. This sensitivity
analysis highlights the trade-off between the QoS scores and
scheduling time as we increase either of these parameters. The
variation of performance metrics with the learning rate is more
straightforward. The scheduling time of CAROL decreases as
we increase the learning rate. This is due to larger jumps in
the optimization steps. However, for a high learning rate of
γ ≥ 10−2, the model is unable to converge to the optima
and hence we see the increase in the MSE scores, energy
consumption and SLO violation rates for these values. The
QoS scores are best for the learning rate of γ = 10−3 and
hence have been used in our experiments.
As the number of layers in the GON model increases, so
does the memory footprint. This increases the scheduling time
11
as it takes longer to generate samples by running optimization
in the input space. However, a higher layer count improves the
prediction performance by giving lower MSE scores, leading
to lower energy consumption and SLO violation rates due to
the more accurate QoS prediction. However, we see marginal
improvement in energy consumption and SLO violation rates
for memory consumption >1GB, but large increase in the
scheduling time of the model. Thus, we use the model with
1GB of memory footprint (3 layers) in our experiments.
Finally,
increases the
scheduling time and gives better energy and SLO scores. We
use a 100 size tabu list in our experiments.
increasing the size of the tabu list
VI. CONCLUSIONS AND FUTURE WORK
We have developed a novel method for resilient computing in
edge federations. Our method uses a lightweight generative
network as a surrogate model
to efﬁciently and precisely
map performance metrics like energy consumption and SLO
violation rates for a given graph topology and scheduling
decision. In the event of a broker failure, CAROL reactively
optimizes the graph topology to accommodate the orphaned
worker nodes. The topology is chosen by running a tabu
search to optimize the QoS scores predicted by the surrogate
model. CAROL uses the discriminator output as a conﬁdence
score that allows us to run model ﬁne-tuning steps only
when conﬁdence scores drop below running thresholds. This
parsimonious ﬁne-tuning gives rise to 35.6% lower overheads
compared to the current state-of-the-art. Performance evalua-
tion of a real edge test-bed with AI and IoT based benchmark
applications show that
the low overheads in CAROL can
improve energy consumption and SLO violation rates by
16.5% and 17.0% compared to the state-of-the-art.
The current approach is able to achieve optimal performance
due to its lower ﬁne-tuning overheads compared to prior
work. Our methods are best suited to highly dynamic systems.
For stationary settings, we propose to extend the current
reactive model to a proactive scheme that is able to prevent
node failures. However, proactive optimization may entail
higher computation for improved predictive performance. Such
challenges would be addressed in the future.
SOFTWARE AVAILABILITY
The code and relevant result reproduction scripts are available
at https://github.com/imperial-qore/CAROL.
10−510−410−310−210−1LearningRate0.040.060.080.10MSE05Sched.Time(seconds)20406080Energy(KW·hr)0.10.2SLOViolation0.250.5125MemoryConsumption(GB)0.030.040.050.06MSE01020Sched.Time(seconds)12.012.513.0Energy(KW·hr)0.050.060.07SLOViolation51050100500TabuListSize0.04100.04120.0414MSE0510Sched.Time(seconds)12141618Energy(KW·hr)0.0500.0750.1000.125SLOViolationREFERENCES
[1] P. K. R. Maddikunta, Q.-V. Pham, B. Prabadevi, N. Deepa, K. Dev,
T. R. Gadekallu, R. Ruby, and M. Liyanage, “Industry 5.0: a survey on
enabling technologies and potential applications,” Journal of Industrial
Information Integration, p. 100257, 2021.
[2] A. Zanella, N. Bui, A. Castellani, L. Vangelista, and M. Zorzi, “Internet
of things for smart cities,” IEEE Internet of Things journal, vol. 1, no. 1,
pp. 22–32, 2014.
[3] B. Rochwerger, D. Breitgand, E. Levy, A. Galis, K. Nagin, I. M.
Llorente, R. Montero, Y. Wolfsthal, E. Elmroth, J. Caceres et al., “The
reservoir model and architecture for open federated cloud computing,”
IBM Journal of Research and Development, vol. 53, no. 4, pp. 4–1,
2009.
[4] S. Tuli, R. Mahmud, S. Tuli, and R. Buyya, “Fogbus: A blockchain-
based lightweight framework for edge and fog computing,” Journal of
Systems and Software, 2019.
[5] T. Hao, Y. Huang, X. Wen, W. Gao, F. Zhang, C. Zheng, L. Wang, H. Ye,
K. Hwang, Z. Ren et al., “Edge AIBench: towards comprehensive end-
to-end edge computing benchmarking,” in International Symposium on
Benchmarking, Measuring and Optimization. Springer, 2018, pp. 23–
30.
[6] J. Shao and J. Zhang, “Communication-computation trade-off
in
resource-constrained edge inference,” IEEE Communications Magazine,
vol. 58, no. 12, pp. 20–26, 2020.
[7] K. Bilal, E. Baccour, A. Erbad, A. Mohamed, and M. Guizani, “Collab-
orative joint caching and transcoding in mobile edge networks,” Journal
of Network and Computer Applications, vol. 136, pp. 86–99, 2019.
[8] S. Tuli, G. Casale, and N. Jennings, “GOSH: Task scheduling using deep
surrogate models in fog computing environments,” IEEE Transactions
on Parallel and Distributed Systems, 2021.
[9] H. P. Sajjad, K. Danniswara, A. Al-Shishtawy, and V. Vlassov,
“Spanedge: Towards unifying stream processing over central and near-
the-edge data centers,” in 2016 IEEE/ACM Symposium on Edge Com-
puting (SEC).
IEEE, 2016, pp. 168–178.
[10] S. Li and T. Lan, “Hotdedup: Managing hot data storage at network
edge through optimal distributed deduplication,” in IEEE INFOCOM
2020-IEEE Conference on Computer Communications.
IEEE, 2020,
pp. 247–256.
[11] S. P. Ahuja, S. Mani, and J. Zambrano, “A survey of the state of cloud
computing in healthcare,” Network and Communication Technologies,
vol. 1, no. 2, p. 12, 2012.
[12] S. Ristov, T. Fahringer, D. Peer, T.-P. Pham, M. Gusev, and C. Mas-
Machuca, “Resilient techniques against disruptions of volatile cloud
resources,” in Guide to Disaster-Resilient Communication Networks.
Springer, 2020, pp. 379–400.
[13] N. Wang, M. Matthaiou, D. S. Nikolopoulos, and B. Varghese, “DY-
VERSE: dynamic vertical scaling in multi-tenant edge environments,”
Future Generation Computer Systems, 2020.
[14] D. Rathod and G. Chowdhary, “Scalability of m/m/c queue based cloud-
fog distributed internet of things middleware,” International Journal of
Advanced Networking and Applications, vol. 11, no. 1, pp. 4162–4170,
2019.
[15] H. A. Khattak, H. Arshad, S. ul Islam, G. Ahmed, S. Jabbar, A. M.
Sharif, and S. Khalid, “Utilization and load balancing in fog servers
for health applications,” EURASIP Journal on Wireless Communications
and Networking, vol. 2019, no. 1, p. 91, 2019.
[16] T. Gouasmi, W. Louati, and A. H. Kacem, “Exact and heuristic
mapreduce scheduling algorithms for cloud federation,” Computers &
Electrical Engineering, vol. 69, pp. 274–286, 2018.
[17] A. Sharif, M. Nickray, and A. Shahidinejad, “Fault-tolerant with load
balancing scheduling in a fog-based iot application,” IET Communica-
tions, vol. 14, no. 16, pp. 2646–2657, 2020.
[18] F. M. Talaat, M. S. Saraya, A. I. Saleh, H. A. Ali, and S. H. Ali, “A load
balancing and optimization strategy (lbos) using reinforcement learning
in fog computing environment,” Journal of Ambient Intelligence and
Humanized Computing, pp. 1–16, 2020.
[19] F. M. Talaat, S. H. Ali, A. I. Saleh, and H. A. Ali, “Effective load
balancing strategy (ELBS) for real-time fog computing environment
using fuzzy and probabilistic neural networks,” Journal of Network and
Systems Management, vol. 27, no. 4, pp. 883–929, 2019.
[20] M. Etemadi, M. Ghobaei-Arani, and A. Shahidinejad, “A cost-efﬁcient
auto-scaling mechanism for IoT applications in fog computing environ-
12
ment: a deep learning-based approach,” Cluster Computing, pp. 1–16,
2021.
[21] Z. He, P. Chen, X. Li, Y. Wang, G. Yu, C. Chen, X. Li, and Z. Zheng,
“A spatiotemporal deep learning approach for unsupervised anomaly
detection in cloud systems,” IEEE Transactions on Neural Networks
and Learning Systems, 2020.
[22] Y. Feng, Z. Liu, J. Chen, H. Lv, J. Wang, and J. Yuan, “Make the rocket
intelligent at iot edge: Stepwise gan for anomaly detection of lre with
multi-source fusion,” IEEE Internet of Things Journal, 2021.
[23] M. Roopaei, P. Rad, and M. Jamshidi, “Deep learning control for
complex and large scale cloud systems,” Intelligent Automation & Soft
Computing, vol. 23, no. 3, pp. 389–391, 2017.
[24] W. Luping, W. Wei, and L. Bo, “CMFL: Mitigating communication
overhead for federated learning,” in 2019 IEEE 39th International
Conference on Distributed Computing Systems (ICDCS).
IEEE, 2019,
pp. 954–964.
[25] S. Tuli, S. Tuli, G. Casale, and N. R. Jennings, “Generative optimization
networks for memory efﬁcient data generation,” Advances in Neural
Information Processing Systems, Workshop on ML for Systems, 2021.
[26] M. Ashman, J. So, W. Tebbutt, V. Fortuin, M. Pearce, and R. E. Turner,
“Sparse gaussian process variational autoencoders,” arXiv preprint
arXiv:2010.10177, 2020.
[27] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley,
S. Ozair, A. Courville, and Y. Bengio, “Generative adversarial nets,” in
Advances in neural information processing systems, 2014, pp. 2672–
2680.
[28] D. P. Kingma and M. Welling, “Auto-encoding variational bayes,” in
International Conference on Learning Representations (ICLR), 2014.
[29] “Under submission,” Details omitted for double-blind reviewing and
communicated to the program chairs.
[30] J. McChesney, N. Wang, A. Tanwer, E. de Lara, and B. Varghese,
“DeFog: fog computing benchmarks,” in The 4th ACM/IEEE Symposium
on Edge Computing, 2019, pp. 47–58.
[31] C. Luo, F. Zhang, C. Huang, X. Xiong, J. Chen, L. Wang, W. Gao, H. Ye,
T. Wu, R. Zhou et al., “AIoT bench: towards comprehensive bench-
marking mobile and embedded device intelligence,” in International
Symposium on Benchmarking, Measuring and Optimization. Springer,
2018, pp. 31–35.
[32] Z. Nezami, K. Zamanifar, K. Djemame, and E. Pournaras, “Decentral-
ized edge-to-cloud load balancing: Service placement for the internet of
things,” IEEE Access, vol. 9, pp. 64 983–65 000, 2021.
[33] S. Tuli, S. R. Poojara, S. N. Srirama, G. Casale, and N. R. Jennings,
“COSCO: Container Orchestration Using Co-Simulation and Gradient
Based Optimization for Fog Computing Environments,” IEEE Transac-
tions on Parallel and Distributed Systems, vol. 33, no. 1, pp. 101–116,
2022.
[34] L. Girish and S. K. Rao, “Anomaly detection in cloud environment using
artiﬁcial intelligence techniques,” Computing, pp. 1–14, 2021.
[35] S. Tuli, S. Tuli, R. Verma, and R. Tuli, “Modelling for prediction of the
spread and severity of COVID-19 and its association with socioeconomic
factors and virus types,” MedRxiv, 2020.
[36] Y. Gan, S. Dev, D. Lo, and C. Delimitrou, “Sage: Leveraging ml to
diagnose unpredictable performance in cloud microservices,” ML for
Computer Architecture and Systems, 2020.
[37] S. Chouliaras and S. Sotiriadis, “Detecting performance degradation in
cloud systems using lstm autoencoders,” in International Conference on
Advanced Information Networking and Applications.
Springer, 2021,
pp. 472–481.
[38] A. Siffer, P.-A. Fouque, A. Termier, and C. Largouet, “Anomaly detec-
tion in streams with extreme value theory,” in Proceedings of the 23rd
ACM SIGKDD International Conference on Knowledge Discovery and
Data Mining, 2017, pp. 1067–1075.
[39] E. Martin and A. Morris, “Non-parametric conﬁdence bounds for process
performance monitoring charts,” Journal of process control, vol. 6, no. 6,
pp. 349–358, 1996.
[40] J. B. Weissman and A. S. Grimshaw, “A federated model for scheduling
in wide-area systems,” in Proceedings of 5th IEEE International Sym-
posium on High Performance Distributed Computing.
IEEE, 1996, pp.
542–550.
[41] K. Ye, Y. Liu, G. Xu, and C.-Z. Xu, “Fault injection and detection
intelligence applications in container-based clouds,” in
Springer, 2018, pp.
for artiﬁcial
International Conference on Cloud Computing.
112–127.
[42] V. Sivagami and K. Easwarakumar, “An improved dynamic fault tolerant
management algorithm during VM migration in cloud data center,”
Future Generation Computer Systems, vol. 98, pp. 35–43, 2019.
[43] K. Driscoll, B. Hall, H. Sivencrona, and P. Zumsteg, “Byzantine fault
tolerance, from theory to reality,” in International Conference on Com-
puter Safety, Reliability, and Security. Springer, 2003, pp. 235–248.
[44] X. Vasilakos, W. Featherstone, N. Uniyal, A. Bravalheri, A. S. Muqad-
das, N. Solhjoo, D. Warren, S. Moazzeni, R. Nejabati, and D. Sime-
onidou, “Towards Zero Downtime Edge Application Mobility for Ultra-
Low Latency 5G Streaming,” in 2020 IEEE Cloud Summit.
IEEE,
2020, pp. 25–32.
[45] N. Samarji and M. Salamah, “A fault tolerance metaheuristic-based
scheme for controller placement problem in wireless software-deﬁned
networks,” International Journal of Communication Systems, vol. 34,
no. 4, p. e4624, 2021.
[46] M. J. Kochenderfer and T. A. Wheeler, Algorithms for optimization.
Mit Press, 2019.
[47] S. Tuli, S. Ilager, K. Ramamohanarao, and R. Buyya, “Dynamic schedul-
ing for stochastic edge-cloud computing environments using a3c learning
and residual recurrent neural networks,” IEEE Transactions on Mobile
Computing, 2020.
[48] J. Moon, J. Kim, Y. Shin, and S. Hwang, “Conﬁdence-aware learning
for deep neural networks,” in International Conference on Machine
Learning. PMLR, 2020, pp. 7034–7044.
[49] A. M. Connor and K. Shea, “A comparison of semi-deterministic and
stochastic search techniques,” in Evolutionary Design and Manufacture.
Springer, 2000, pp. 287–298.
[50] P. Veliˇckovi´c, G. Cucurull, A. Casanova, A. Romero, P. Li`o, and
Y. Bengio, “Graph Attention Networks,” International Conference on
Learning Representations, 2018.
[51] K. Gilly, S. Alcaraz, N. Aknin, S. Filiposka, and A. Mishev, “Modelling
edge computing in urban mobility simulation scenarios,” in 2020 IFIP
Networking Conference (Networking).
IEEE, 2020, pp. 539–543.
[52] V. Looga, Z. Ou, Y. Deng, and A. Yl¨a-J¨a¨aski, “Mammoth: A massive-
scale emulation platform for internet of things,” in 2012 IEEE 2nd
International Conference on Cloud Computing and Intelligence Systems,
vol. 3.
IEEE, 2012, pp. 1235–1239.
[53] A. Haeberlen, P. Kouznetsov, and P. Druschel, “The case for byzantine
fault detection.” in HotDep, 2006.
[54] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan,
T. Killeen, Z. Lin, N. Gimelshein, L. Antiga et al., “Pytorch: An
imperative style, high-performance deep learning library,” Advances in
Neural Information Processing Systems, vol. 32, pp. 8026–8037, 2019.
[55] S. Tuli, “Splitplace: Intelligent placement of split neural nets in mo-
bile edge environments,” ACM SIGMETRICS Performance Evaluation
Review, vol. 49, no. 2, pp. 63–65, 2022.
[56] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan,
P. Doll´ar, and C. L. Zitnick, “Microsoft COCO: Common objects in
context,” in European conference on computer vision. Springer, 2014,
pp. 740–755.
[57] Y. Mao, J. Zhang, and K. B. Letaief, “Dynamic computation ofﬂoading
for mobile-edge computing with energy harvesting devices,” IEEE
Journal on Selected Areas in Communications, vol. 34, no. 12, pp. 3590–
3605, 2016.
13