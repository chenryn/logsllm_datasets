title:Evaluating the Error Resilience of Parallel Programs
author:Bo Fang and
Karthik Pattabiraman and
Matei Ripeanu and
Sudhanva Gurumurthi
2014 44th Annual IEEE/IFIP International Conference on Dependable Systems and Networks
Evaluating the Error Resilience of Parallel Programs
Bo Fang∗, Karthik Pattabiraman∗, Matei Ripeanu∗, Sudhanva Gurumurthi†
∗Department of Electrical and Computer Engineering
University of British Columbia
Email: {bof, karthikp, matei}@ece.ubc.ca
†AMD Research, Advanced Micro Devices, Inc.
Email: PI:EMAIL
Abstract—As a consequence of increasing hardware fault rates,
HPC systems face signiﬁcant challenges in terms of reliability.
Evaluating the error resilience of HPC applications is an essential
step for building efﬁcient fault-tolerant mechanisms for these
applications. In this paper, we propose a methodology to char-
acterize the resilience of OpenMP programs using fault-injection
experiments. We ﬁnd that
the error resilience of OpenMP
applications depends on the program structure and thread model;
hence, these need to be taken into account while characterizing
error resilience. We also report preliminary results about the
correlation between the application’s error resilience and the
algorithm(s) used in the application.
I. INTRODUCTION
Prior studies [1]–[3] showed that fault rates experienced
by processors and memory likely will increase as chips get
denser. High-performance computing (HPC) systems usually
have high reliability, availability and serviceability (RAS)
requirements; thus, understanding the resilience characteristics
of HPC applications is important for hardware and system/ap-
plication designers to make sound decisions about how to
design and provision them for desired RAS levels.
Our previous work [4] on studying the error resilience of
GPGPU applications suggests that the resilience of an applica-
tion correlates with its algorithmic characteristics. Among the
twelve CUDA benchmarks we studied, we observed correla-
tions between the algorithmic characteristic and the resilience
of the applications. If our hypothesis that error resilience and
algorithmic properties are correlated is true, then an analogous
trend also should be observable when using programming
models other than CUDA. This motivates us to continue to
explore this space by investigating parallel applications that
run on CPUs.
Several parallel-programming paradigms are used widely in
HPC applications on CPUs. POSIX thread (pthread) and Open
Multi-Processing (OpenMP) typically are used for shared-
memory systems, while Message Passing Interface (MPI)
typically is used for distributed-memory systems. Among these
programming models, OpenMP is particularly interesting due
to its strong emphasis on structured parallel programming [5].
Because OpenMP has gained a lot of attention in the HPC
community, our study focuses on evaluating the error resilience
of OpenMP parallel applications.
However, characterizing the error resilience of OpenMP
applications is challenging due to two challenges:
1) Any error resilience characterization needs to consider
the underlying thread model of the application. Because
OpenMP programs contain two types of threads (master
and slave threads) that accomplish different types of
work, each thread’s error resilience properties needs to
be characterized separately in addition to its overall
impact on application resilience;
2) Resilience
characterization (e.g.,
fault-
injection study) usually works at the assembly/machine-
code instruction level, but we need source-code level
information to understand the program structure and
address the ﬁrst challenge above.
through a
To overcome these challenges, we perform static analysis
of OpenMP programs using a modiﬁed version of the LLVM
compiler [6]. We collect the necessary dynamic information
from a program at runtime to obtain the execution proﬁle
of each of its OpenMP threads, thus addressing challenge 1.
Based on this information, we map information from source-
code level to the instruction level using LLVM, and conduct
fault-injection experiments on speciﬁc program regions, thus
addressing challenge 2.
This paper makes the following contributions:
1) Proposes a methodology to evaluate the resilience of
OpenMP applications using fault-injection experiments,
2) Extends an existing fault-injection tool, LLFI [7] to
support multi-threading programs (i.e. OpenMP),
3) Characterizes the error resilience of eight OpenMP par-
allel applications drawn from the Rodinia benchmark
suite [8],
4) Explores the hypothesis that
the error resilience of
OpenMP programs correlate with their algorithmic char-
acteristics
Our study’s main ﬁndings are:
1) We ﬁnd that
the error resilience characterization of
OpenMP programs needs to take into account the thread
model and the program structure. Otherwise, the re-
silience characteristics could be biased (as shown in
Figure 4 and Figure 6). This is important as different
threads and structures of OpenMP programs show dif-
ferent level of resilience, which opens the opportunity to
use differentiated fault-detection and impact-mitigation
mechanisms to reduce the error detection overhead and
improve resilience. Our characterization mechanisms are
978-1-4799-2233-8/14 $31.00 © 2014 IEEE
DOI 10.1109/DSN.2014.73
720
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:23:14 UTC from IEEE Xplore.  Restrictions apply. 
insightful for studying the fault tolerance of parallel
programs, and instructive to design future hardware fault
detection techniques.
2) We ﬁnd preliminary support for our hypothesis that error
resilience properties do correlate with the algorithmic
characteristics of parallel applications. If this hypothesis
is indeed true,
then this opens an avenue to under-
stand application resilience at much lower cost with-
out conducting exhaustive and complex fault-injection
experiments. This can also provide useful information
on designing algorithmic speciﬁc error detection and
recovery mechanisms.
II. RELATED WORK
This section provides an overview of related work in the
areas of error resilience studies of parallel programs and
explains how our work differs.
Fault injection has been well-explored on CPUs using run-
time debuggers. Examples are GOOFI [9] and NFTAPE [10].
However, they do not consider multi-threaded programs, nor
do they concern themselves with choosing different parts of
a program for injection. Other work [11] attempted to inject
faults in scientiﬁc applications using the PIN tool from Intel, a
dynamic binary instrumentation framework, but multi-threaded
fault injection was not their focus at that time.
Lu et al. [12] proposed a way to assess fault sensitivity in
MPI applications by injecting faults into registers, application
memory regions and messages at run-time. They showed that
registers and MPI messages are particularly vulnerable to
single-bit-ﬂip faults and urge the MPI standard to redesign and
enhance the error-handling APIs in the context of hardware
faults. While their goals were similar to our study, their study
did not consider shared-memory parallel programs, which are
very different from MPI programs.
Wei et al.
[13] focused on leveraging similarities between
threads in parallel programs to protect faults in program’s
control data. They used LLVM compiler infrastructure to
instrument a parallel program with fault-detecting code and the
PIN tool to conduct fault injections to evaluate its detectors.
Their methodology integrated software level instrumentation
and assembly-level evaluation. However, their study was based
on pthread programs, which differ from OpenMP in terms of
programming models and code structures. In addition, their
evaluation was about only the control data and did not study
end-to-end program vulnerability.
Sloan et al. proposed algorithmic approaches [14] to locate
errors during the execution and partially recompute the result
on parallel systems. They improved the performance of the
Conjugate Gradient solver in high-error scenarios by 3x-4x
and increased the probability that it completes successfully by
up to 60%. Their results showed that the application-speciﬁc
techniques help improve the fault tolerance of applications.
However, their techniques were based on mathematical meth-
ods, which can be applied only to linear algebra problems such
as matrix-vector multiplication. Our goal in contrast is to ﬁnd
techniques for general-purpose parallel applications.
To the best of our knowledge, it is the ﬁrst to study experi-
mentally the error resilience of OpenMP programs, and discuss
the possibility of correlating the resilience of applications with
their algorithm characteristics.
III. METHODOLOGY
This section introduces our methodology. As we have dis-
cussed in Section I, two factors may have unequal impacts on
the resilience of OpenMP programs; faults in different types of
threads and faults in different parts of the program. Therefore,
it becomes important to study these factors separately.
Figure 1 shows the thread model of OpenMP programs.
An OpenMP application starts as a single thread, which is
the master thread. As the program executes, it may encounter
one or more parallel regions, at which point slave threads are
created by the master thread and run in parallel (including
the master thread). Therefore, the master thread and slave
threads differ from each other in terms of their behaviors
and amounts of work performed. Our methodology takes into
account the thread model of OpenMP programs. In addition
to the thread model, we need to identify the program structure
of the master thread. As shown in Figure 2, we partition the
entire execution of the master thread into ﬁve segments. Each
segment represents a task that the master thread does within
that part of the code. For example, pre-algorithm and post-
algorithm are segments that respectively contain the pre- and
post- processing of the input and output data for the parallel
region.
To make the preceding description more concrete, Figure 3
shows a code-snippet from the srad application, a diffusion
method for ultrasonic and radar- imaging applications based
on partial differential equations. The code snippet presents
the main stages of srad, namely (1) image reading, (2) pre-
processing (resizing, setting up and scaling down), (3) com-
putation, (4) scaling up, and (5) output. The ﬁgure also shows
how the stages correspond to the segments identiﬁed in the
preceding paragraph. We believe that understanding the impact
of each segment on the resilience of the program is important
for understanding its overall error resilience.
Start
Master 
thread 
Master thread
Slave threads 
Master 
thread
End
Fig. 1: An example of the thread model of OpenMP programs
721
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:23:14 UTC from IEEE Xplore.  Restrictions apply. 
Input 
processing
Pre-
algorithm
Parallel 
region
Post-
algorithm
Output
processing
OpenMP master thread
Fig. 2: Program segments of the master thread
Begin:
    //read image
    read_graphics(image_orig);
   //resize the image
   resize(image_orig);
    //setup
   image = image_setup(image_orig);
    //image scale down
    for (i=0; i<Ne; i++){
      image[i] = exp(image[i]/255);
    }
    //computation
    #pragma omp parallel for shared(var_list1) 
private(var_list2)
Input 
processing
Pre- 
algorithm
   for (j=0; j<Nc; j++){
   //directional derivatives,ICOV,diffusion coefficient
    }
    #pragma omp parallel for shared(var_list1) 
private(var_list2)
Parallel 
region
   for (j=0; j<Nc; j++){
     //divergence & image update
   }
   //image scale up
   for (i=0; i<Ne; i++){
     image[i] = log(image[i])*255;
    }
    //write image out
    write_graphics(image);
    free_memory()
End
Post-
algorithm
Output 
processing
Fig. 3: An example of the partition of an OpenMP program
A. Fault model
Hardware faults can be classiﬁed broadly as transient or
permanent. Transient faults usually are ”one-off” events and
occur non-deterministically, while permanent faults persist at a
given location. Further, transient faults are caused by external
events such as cosmic rays and over-heated components, while
permanent hardware faults usually are caused by manufactur-
ing or design faults. We consider only transient faults in this
study. We use the single-bit-ﬂip model in this study because
it is the de-facto fault model adopted in studies of transient
faults [13], [15], [16]. However, our fault injector can support
both single- and multiple-bit ﬂips. We will consider multiple-
bit errors in future work.
We consider faults in the CPU’s computational elements.
We inject faults into the destination register of the program’s
instructions to simulate an error in the processor’s compu-
tational units. For memory instructions, we inject faults into
address-calculation parts in load/store instructions. We assume
that the memory is error-correction-code (ECC)-protected, as
is typically the case in HPC systems, and so do not inject
faults into memory values.
An application may have four outcomes after a fault is
injected:
1) Throws an exception (crash)
2) Times out by going into an inﬁnite loop (hang)
3) Completes with incorrect output (silent data dorruption
(SDC)) 1
4) Completes with correct output (benign).
These four outcomes are mutually exclusive and exhaustive.
Among the four outcomes, SDC is the most serious one
because there is no indication that the result is incorrect.
Therefore, we focus on SDC in our evaluation of a program’s
error resilience in this study.
B. Fault-injection tool
We extend the fault-injection tool called LLFI to inject faults
into OpenMP applications [7]. LLFI performs fault injection at
the LLVM compiler’s intermediate code level. It instruments
the original intermediate representation (IR) of an application
with fault-injection code, which performs the actual injection
at run-time. LLFI allows users to specify the kinds of faults
and locations (i.e., instructions, operands) to inject. Although
LLFI is a convenient tool for fault injection, it did not support
multi-threaded programs. We extended LLFI and redesign the
interface between its components to support multi-threading.
The operation of LLFI consists of three main phases, all of
which we modify for multi-threaded programs as follows:
1) Instrumentation phase adds callback functions after each
IR instruction. The instructions to be instrumented are
determined based on the conﬁgurations speciﬁed by
users. We add new conﬁgurations in this phase to allow
the user to specify individual regions and threads as
targets for instrumentation.
2) Proﬁling phase uses the callback functions added in the
ﬁrst phase for counting and generating statistics, such as
the total number of dynamic instructions of the program.
We modify these functions to keep the statistics on a per-
thread basis. The statistics are used in the next phase to
choose a random instruction into which to inject .
3) Injection phase uses the callback functions added in the
ﬁrst phase, and the statistics added in the second phase
to inject faults. To inject a fault, a random instruction
is chosen from the set of all dynamically executed
instructions in the program and a single bit is ﬂipped
in its address operand (for memory instructions ) or
destination register (otherwise). Our modiﬁcation to this
phase consists of performing the injections on a per-
thread basis using the per-thread statistics in the second
phase, and into speciﬁc program regions as described in
the ﬁrst phase.
IV. ERROR RESILIENCE CHARACTERISTICS
We run our experiments on an Intel Xeon CPU X5650
multi-core processor running at 2.67GHz with 24 hardware
cores. The standard distribution of Clang, which is a compiler
frontend in the LLVM tool-chain, does not support OpenMP
directives, so we use an implementation of the OpenMP
1We deﬁne an SDC as an outcome that differs from the fault-free run.
722
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:23:14 UTC from IEEE Xplore.  Restrictions apply. 
C/C++ language extensions in Clang from [17]. We use eight
OpenMP programs from the Rodinia benchmark suite [8] in
our evaluation. We conﬁgure the OpenMP programs with 24
threads, which is equal to the number of cores. For each
benchmark, we conduct more than 10,000 fault-injection runs.
In each run, we inject a single random fault using our extended
version of LLFI.
A. Thread-level Differences on Error Resilience
We evaluate the effects of different kinds of threads on
the error resilience of the program. We perform two separate
experiments for injecting faults into the master and slave
threads respectively. In the ﬁrst experiment, the master thread
(threadID = 0) is chosen and the locations to inject are
distributed over the entire execution of the program. In the
second experiment, a random slave thread is chosen and the
locations to inject are conﬁned to the parallel segment of the
OpenMP program.
This set-up is based on the following hypothesis: threads
within the parallel segment resemble each other in OpenMP
programs, and so choosing a random thread into which to
inject is sufﬁcient. We test our hypothesis by counting the
number of dynamic instructions in each thread as a way to
represent the behaviors of threads. Other possible solutions
to determine the similarity of threads are still under-explored.
We report the mean value and the standard deviation of the
number of instructions in all threads of each benchmark in
Table I. Our results indicate that most of the benchmarks show
similar behaviors across threads within the parallel segment,
as demonstrated by the relatively low standard deviation. The
one exception is the nn (k-nearest neighbours) benchmark,
which exhibits high standard deviation (SD). This is because
the 24 threads of nn are clustered into two groups (one with
10 threads and the other with 14) according to the number
of instructions they execute. The probability of choosing a
thread from the second group is higher by roughly 8% (1/12).
We disregard this difference for simplicity.
Figure 4 presents the SDC rates for two sets of experiments.
In most of the benchmarks, the master thread has a higher SDC
rate than slave threads except for lud. This is lud’s master
thread spends most of its time in the parallel segment, and
hence it makes no difference whether we inject into the master
thread or into slave threads. The average deviation of the SDC
rate between threads is 7.8%, with the biggest deviation of
16% in pathﬁnder. This suggests that performing a naive fault
injection without taking thread-level differences into account
can grossly misestimate the error resilience of applications.
To add to this point, we proﬁle an OpenMP version of
matrix multiplication (mm), which is not included in Rodinia
benchmark suite. Of a total of 24 threads, only ﬁve of them
(on average, executing 89476 dynamic instructions) perform
signiﬁcant amount of work, while the other 19 ﬁnish rather
quickly (after executing 22 instructions). A random thread