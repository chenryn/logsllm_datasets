[5], [11], [24], or hardware-assisted mechanisms [11], [4],
[12]. All coverage-guided fuzzers are based on one of three
metrics of code coverage: basic blocks, basic block edges, or
basic block paths. Basic blocks (Figure 3) refer to straight-
lined sequences of code terminating in a control-ﬂow transfer
instruction (e.g., jumps or returns); they form the nodes of a
program’s control-ﬂow graph.
A basic block edge represents the actual control-ﬂow
transfer. It is possible to represent edge coverage as a set
of (src , dest) tuples, where src and dest are basic
blocks. Representing edge coverage this way (i.e., solely of
basic blocks) allows edge coverage to be inferred from block
coverage. The caveat is that this requires prior elimination of
all critical edges, i.e., edges whose starting/ending basic blocks
1Seeds refers to test cases used as the basis for mutation. In the ﬁrst iteration,
the seeds are generally several small inputs accepted by the target binary.
(cid:24)(cid:25)(cid:26)
Source 
Code
IF (x==1) 
  foo();
IF (y==2) 
  bar();
return;
Basic 
Blocks 
IF(x==1)
x=1
foo();
x≠1
IF(y==2)
y=2
y≠2
bar();
return; 
Fig. 3. An example of basic blocks in C code.
have multiple outgoing/incoming edges, respectively (details in
Section VIII-B). honggFuzz [4], libFuzzer [6], and AFL [5] are
fuzzers that track coverage at edge granularity. honggFuzz and
libFuzzer track edge coverage indirectly using block coverage,
while AFL tracks edge coverage directly (although it stores the
information approximately in a 64KB hash table [34]).
To date, no fuzzers that we are aware of track coverage at
path granularity, however, we can imagine future approaches
leveraging Intel Processor Trace’s [35] ability to make tracking
path coverage tractable. Thus, coverage-guided tracing com-
plements coverage-guided fuzzers that trace block or edge
coverage at block granularity.
C. Coverage Tracing Performance
of
[6],
fuzzing
white-box
Coverage-guided
[4], allowing for
(source-
available) binaries typically uses instrumentation inserted
at compile/assembly-time [5],
fast
identiﬁcation and modiﬁcation of basic blocks from source.
AFL accomplishes this through custom GCC and Clang
wrappers. honggfuzz and libFuzzer also provide their own
Clang wrappers. Fuzzing black-box (source-unavailable)
binaries is far more challenging, as having no access to
source code requires costly reconstruction of binary control-
ﬂow. VUzzer
to dynamically (during
run-time)
instrument black-box binaries. AFL’s QEMU
user-mode emulation also instruments dynamically, but as
our experiments show (Section VI), it incurs overheads as
high as 1000% compared to native execution. To address
the weakness of dynamic rewriting having to translate basic
blocks in real-time—potentially multiple times—Cisco-Talos
provides a static binary rewriter AFL-Dyninst [10]. While
previous work shows AFL-Dyninst signiﬁcantly outperforms
AFL-QEMU on select binaries [37], results in Section VI
suggest that the performance gap is much narrower.
[7] uses PIN [36]
D. Focus of this Paper
A characteristic of coverage-guided fuzzing is the coverage
tracing of all generated test cases. Though “smarter” fuzzing
efforts generate coverage-increasing test cases with higher fre-
quency, results in Section III show that only a small percentage
of all test cases are coverage-increasing. We draw inspiration
from Amdahl’s Law [38], realizing that the common case—
the tracing of non-coverage-increasing test cases—presents
an opportunity to substantially improve the performance of
coverage-guided fuzzing. Thus we present coverage-guided
tracing, which restricts tracing to only coverage-increasing test
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:42:59 UTC from IEEE Xplore.  Restrictions apply. 
bsdtar
cert-basic
cjson
djpeg
pdftohtml
readelf
sfconvert
tcpdump
AFL-Clang
AFL-QEMU
89.4
95.7
91.9
98.9
86.0
95.7
94.7
97.8
98.4
99.5
86.9
96.5
99.2
98.6
88.3
95.8
CADET_1
CADET_3
CROMU_1
CROMU_2
CROMU_3
CROMU_4
CROMU_5
CROMU_6
Driller-AFL
97.6
97.1
96.0
94.9
96.0
93.1
97.5
94.9
avg.
91.8
97.3
avg.
95.9
TABLE I.
PER-BENCHMARK PERCENTAGES OF TOTAL FUZZING RUNTIME SPENT ON TEST CASE EXECUTION AND COVERAGE TRACING BY AFL-CLANG
AND AFL-QEMU (“BLIND” FUZZING), AND DRILLER-AFL (“SMART” FUZZING). WE RUN EACH FUZZER FOR ONE HOUR PER BENCHMARK.
AFL-Clang
AFL-QEMU
bsdtar
1.63E−5
3.34E−5
cert-basic
4.47E−5
4.20E−4
cjson
2.78E−6
1.41E−5
djpeg
4.30E−5
1.09E−4
pdftohtml
1.42E−4
6.74E−4
Driller-AFL
CADET_1
2.70E−5
CADET_3
4.00E−4
CROMU_1
2.06E−5
CROMU_2
2.67E−5
CROMU_3
2.33E−5
readelf
7.43E−5
2.28E−4
CROMU_4
8.65E−7
sfconvert
8.77E−5
4.25E−4
CROMU_5
1.61E−5
tcpdump
8.55E−5
1.55E−4
CROMU_6
8.45E−6
avg.
6.20E−5
2.57E−4
avg.
6.53E−5
TABLE II.
PER-BENCHMARK RATES OF COVERAGE-INCREASING TEST CASES OUT OF ALL TEST CASES GENERATED IN ONE HOUR BY AFL-CLANG
AND AFL-QEMU (“BLIND” FUZZING), AND DRILLER-AFL (“SMART” FUZZING).
cases. Our implementation, UnTracer, is a coverage-guided
tracing framework for coverage-guided fuzzers.
III.
IMPACT OF DISCARDED TEST CASES
Traditional coverage-guided fuzzers (e.g., AFL [5], lib-
Fuzzer [6], and honggfuzz [4]) rely on “blind” (random
mutation-based) test case generation; coverage-increasing test
cases are preserved and prioritized for future mutation, while
the overwhelming majority are non-coverage-increasing and
discarded along with their coverage information. To reduce
rates of non-coverage-increasing test cases, several white-box
and grey-box fuzzers employ “smart” test case generation.
Smart mutation leverages source analysis (e.g., symbolic ex-
ecution [18], program state [9], and taint tracking [39], [7])
to generate a higher proportion of coverage-increasing test
cases. However, it is unclear if such fuzzers spend signiﬁ-
cantly more time on test case generation than on test case
execution/coverage tracing or how effective smart mutation is
at increasing the rate of coverage-increasing test cases.
In this section, we investigate the performance impact of
executing/tracing non-coverage-increasing test cases in two
popular state-of-the-art fuzzers—AFL (blind test case gen-
eration) [5] and Driller (smart
test case generation) [18].
We measure the runtime spent by both AFL and Driller on
executing/tracing test cases across eight binaries, for one hour
each, and their corresponding rates of coverage-increasing test
cases. Below, we highlight the most relevant implementation
details of both fuzzers regarding test case generation and
coverage tracing, and our experimental setup.
AFL: AFL [5] is a “blind” fuzzer as it relies on random
mutation to produce coverage-increasing (coverage-increasing)
test cases, which are then used during mutation.2 AFL traces
test case coverage using either QEMU-based dynamic instru-
mentation for black-box binaries or assembly/compile-time
instrumentation for white-box binaries. We cover both options
by evaluating AFL-QEMU and AFL-Clang.
Driller: Driller [18] achieves “smart” test case genera-
tion by augmenting blind mutation with selective concolic
execution—solving path constraints symbolically (instead of
by brute-force). Intuitively, Driller aims to outperform blind
fuzzers by producing fewer non-coverage-increasing test cases;
2A second, less-relevant factor inﬂuencing AFL’s test case mutation priority
is test case size. For two test cases exhibiting identical code coverage, AFL
will prioritize the test case with smaller ﬁlesize [5].
(cid:24)(cid:26)(cid:17)
its concolic execution enables penetration of path constraints
where blind fuzzers normally stall. We evaluate Driller-AFL
(aka ShellPhuzz [40]). Like AFL, Driller-AFL also utilizes
QEMU for black-box binary coverage tracing.
A. Experimental Setup
For AFL-Clang and AFL-QEMU we use the eight bench-
marks from our evaluation in Section VI. As Driller currently
only supports benchmarks from the DARPA Cyber Grand
Challenge (CGC) [41], we evaluate Driller-AFL on eight pre-
compiled [42] CGC binaries. We run all experiments on the
same setup as our performance evaluation (Section VI).
To measure each fuzzer’s execution/tracing time, we in-
timing code in AFL’s test case execution function
sert
(run_target()). As timing occurs per-execution, this al-
lows us to also log the total number of test cases generated.
We count each fuzzer’s coverage-increasing test cases by
examining its AFL queue directory and counting all saved test
cases AFL appends with tag +cov—its indicator that the test
case increases code coverage.
B. Results
As shown in Table I, both AFL and Driller spend the
majority of their runtimes on test case execution/coverage
tracing across all benchmarks: AFL-Clang and AFL-QEMU
average 91.8% and 97.3% of each hour, respectively, while
Driller-AFL averages 95.9% of each hour. Table II shows each
fuzzer’s rate of coverage-increasing test cases across all one-
hour trials. On average, AFL-Clang and AFL-QEMU have
.0062% and .0257% coverage-increasing test cases out of all
test cases generated in one hour, respectively. Driller-AFL
averages .00653% coverage-increasing test cases out of all test
cases in each one hour trial. These results show that coverage-
guided fuzzers AFL (blind) and Driller (smart)—despite adopt-
ing different test case generation methodologies—both spend
the majority of their time executing and tracing the coverage
of non-coverage-increasing test cases.
IV. COVERAGE-GUIDED TRACING
Current coverage-guided fuzzers trace all generated test
cases to compare their individual code coverage to some
accumulated global coverage. Test cases with new coverage are
retained for mutation and test cases without new coverage are
discarded along with their coverage information. In Section III,
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:42:59 UTC from IEEE Xplore.  Restrictions apply. 
	
	
	

	


	
		


		


"	
#		
	


$


		




		




		





	
	
	



	





