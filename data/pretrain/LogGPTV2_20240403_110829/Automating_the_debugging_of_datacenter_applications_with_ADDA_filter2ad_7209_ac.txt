one can obtain a globally unique id for any given
TCP message using a  tuple. The
stream ID need only be communicated once, when the
TCP connection is established, while the local ID can
be computed during replay, based on the ordering of
messages received on the stream.
C. Distributed Replay and Analysis
1) Serial Replay: The current ADDA prototype pro-
vides the illusion of serial replay by replaying nodes
serially: only one thread at any given node is allowed to
execute at a time. Though simple to implement and ver-
ify, the undesirable consequence of this implementation
decision is that replay overhead will increase linearly
with the number of nodes being replayed. That is, 1000
nodes will take approximately 1000x as long to replay,
even if replay is distributed over 1000 nodes. We are
currently working on parallel replay. This can be done
by allowing nodes to proceed in parallel during replay
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:58:57 UTC from IEEE Xplore.  Restrictions apply. 
and enforce the relative order given by the Lamport
clocks that ADDA already records.
2) Fine-Grained Analyses: ADDA plugins have ac-
cess to a variety of ﬁne-grained analysis primitives,
such as data-ﬂow tracking and instruction tracing. Under
the hood, ADDA implements these primitives by binary
translating the replay execution. The binary translation
is done by LibVEX, an open-source binary translator
that offers an easy-to-use RISC-style intermediate rep-
resentation for performing instruction-level analyses.
A key challenge in replaying in binary translated
mode is that LibVEX does not simulate operations
on hardware performance counters, which are used by
ADDA to deliver asynchronous events during replay.
ADDA addresses this problem by adding branch counting
emulation support to LibVEX (in the form of a module
that counts branches in software).
V. EVALUATION
In this section we aim to answer the following
questions: a) Is ADDA effective in debugging real-world
problems occurring in real-world datacenter applica-
tions? (§V-A) b) Is ADDA’s recording overhead toler-
able, and how does it scale with cluster size and input
data volume? (§V-B) c) Is ADDA efﬁcient in replaying
failed executions for debugging? (§V-C).
A. Experience
In this section we describe how we used ADDA
to succesfully reproduce and debug bugs in Hy-
pertable [21]. Hypertable [21]
is an open source,
high performance data store designed for large-scale
data-intensive tasks and is modeled after Google’s
Bigtable [22]. Hypertable is deployed at Baidu,
the
leading search services in China, and the Rediff online
news provider.
1) Hypertable Hang Under Memory Pressure: We
found a new bug in Hypertable while recording various
workloads with ADDA. We noticed that occasionally Hy-
pertable clients timed-out, and the system became un-
responsive. This failure was hard to reproduce without
ADDA. It turned out that the error would manifest when
the machine where the Hypertable master server was
running experienced memory pressure and a memory
allocation failed, which in turn hung the master. ADDA’s
deterministic replay and the visualization plugin helped
to quickly identify that nodes were trying to connect
to the master, which was not making any progress. We
identiﬁed the failed memory allocation, which explained
the random Hypertable hangs that we were experienc-
ing. On subsequent analysis, we discovered that the
particular cluster machine was accidentally conﬁgured
without a swap partition, making memory allocations
more likely to fail.
2) Data Loss in Hypertable: We used ADDA to
debug a previously solved Hypertable defect [23] that
causes updates to a database table to be lost when
multiple Hypertable clients concurrently load rows into
the same table. According to Hypertable’s bug tracker,
this bug took 6 days to ﬁx. The bug is hard to reproduce,
and its root cause spans multiple nodes. The load
operation appears to be a success—neither clients nor
slaves receiving the updates produce error messages.
However, subsequent dumps of the table do not return
all rows—several thousand are missing. The data loss
results from rows being committed to slave nodes that
are not responsible for hosting them (the slave nodes are
called Hypertable range servers and they are responsible
for holding a piece of the entire data). The slaves honor
subsequent requests for table dumps, but do not include
the mistakenly committed rows in the dumped data.
The committed rows are merely ignored. The erroneous
commits stem from a race condition in which row
ranges migrate to other slave nodes at the same time
that a recently received row within the migrated range
is being committed to the current slave node.
Reproducing this failure required 8 concurrent
clients that insert 500MB of data into the same table,
after which they check the consistency of the table.
We recorded several executions with ADDA until the
failure was reproduced—the recording overhead was
40%. Afterwards, we replayed the failure with ADDA in
a single-machine setup. We inserted breakpoints during
row range migration, where we suspected the root cause
to be located, and we observed the data race occurring
deterministically. ADDA’s ability to reliably replay the
failure, combined with the bird’s eye view of the entire
system, made debugging substantially easier and faster.
B. Recording Efﬁciency
We ran all experiments in a cluster with 14 machines
with two Intel Xeon 3.06GHz processors, 2GB of
RAM, two 7200RPM drives in RAID 0, running 32-
bit Linux 2.6.29. The machines were in a single rack,
had 1Gbps NICs, and were interconnected by a single
1Gbps switch.
The size of the cluster may not be representative of
the size of current datacenters, however, we used the
largest cluster that was available to us and in which we
had access to the bare-metal hardware. We could not
use a virtualized environment such as EC2, because we
needed access to the hardware branch counter in order
to replay asynchronous events (§IV-B2). This limitation
may be removed by on-going work on virtualizing
performance counters [24].
We measure ADDA’s recording overhead versus the
overhead of the naive approach that records all inputs,
in order to show the beneﬁts of DPS. To simulate the
naive approach, we conﬁgured ADDA to log all inputs.
We ﬁrst evaluate the single processor case (§V-B1), then
the logging overhead (§V-B2) and then the multiple
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:58:57 UTC from IEEE Xplore.  Restrictions apply. 
CPU case (§V-B3). We did not compare against mature
record-replay solutions, such as VMWare Workstation,
since it does not work for multiple CPUs and has been
deprecated since version 7.
1) Runtime Overhead: We ﬁrst evaluate the single
processor case, therefore the CREW protocol was not
used. To use a single CPU, we pinned the recorded
process to a single CPU for both the native and the
recorded systems.
We evaluate on two systems: Memcached and Hy-
pertable.
Memcached [16] is a high-performance, distributed
memory object caching system,
typically used for
speeding up dynamic web applications by alleviating
database load. Memcached is used by online services
providers such as Youtube, Wikipedia, and Flickr.
To evaluate the efﬁciency of recording a Memcached
deployment, we simulated a photography blog Web
application in which Memcached is used by user-facing
Web application servers to cache the ﬁles containing
the photos. This setup resembles the Facebook photo
storage [25], in which Memcached is used to reduce
latency. We assume that the photos are stored in persis-
tent storage (i.e., HDFS) and the clients (i.e., the user-
facing Web applications, which are also running in the
same datacenter) copy them from persistent storage to
the Memcached servers. We used various setups with
a varying number of Memcached servers, number of
clients, and total input sizes. Each server and client runs
on a separate machine. Each client randomly selects
one of the Memcached servers to either read or write
a photo—reads are selected with 90% probability and
writes with 10% probability, since reads are predomi-
nant in Facebook’s daily photo trafﬁc [25].
For this experiment we used a setup consisting of
4 Memcached servers and 7 clients, each client having
4 threads. Overhead is measured in terms of reduction
in client throughput. In the baseline execution, clients
achieve a maximum throughput of 68MB/s, correspond-
ing to 68 Memcached operations per second. The photos
were conﬁgured to have a ﬁxed size of 1MB, they were
randomly generated and previously stored in the clients’
local disks before starting the experiment.
ADDA’s recording overhead with varying size of the
input from persistent storage (Fig. 2) is between 18%
and 23%. On the other hand, the naive approach imposes
a high overhead: between 100% and 125%. This shows
the beneﬁts of DPS: logging all inputs causes the naive
approach to have up to 5 times higher runtime overhead
than ADDA.
Fig. 3 shows ADDA’s scalability with the number of
nodes in the system. We varied the number of recorded
nodes by increasing the number of Memcached clients.
Each client connects to a shared pool of 4 Memcached
Recording overhead vs. input size for Memcached
ADDA
Naive approach
]
%
[
d
a
e
h
r
e
v
O
 150
 125
 100
 75
 50
 25
 500
 1000
 1500
 2000
 2500
 3000
 3500
Total input size [MB]
Fig. 2: Recording overhead compared to the native
execution in Memcached while varying the total size
of the input from persistent storage.
servers. The overhead is measured in terms of reduction
in client throughput relative to the native execution.
This experiment shows that ADDA’s overhead is
between 20% and 65%, and scales well with the number
of nodes in the system (Fig. 3). Moreover, ADDA
scales well when the servers operate under heavy load.
The naive approach has high overhead (up to 250%).
However, as the Memcached servers become saturated,
clients become less loaded. Since in the naive approach
clients have to record all their inputs, the clients become
slower, so the impact of heavy recording for the naive
approach decreases.
]
%
[
e
v
i
t
a
n
o
t
d
e
r
a
p
m
o
c
d
a
e
h
r
e
v
O
 300
 250
 200
 150
 100
 50
 0
Recording overhead vs. # clients for Memcached
ADDA
Naive approach
 2
 4
 6
 8
 10
# Clients
Fig. 3: Recording overhead for Memcached with vary-
ing number of clients.
Hypertable The Hypertable workload consists of
several clients inserting a log of Web search queries
and click streams into a Hypertable table. A query is
several hundred bytes long and contains the timestamp,
user id, the query keywords, and the links clicked by
the user. The clients generate a workload that would be
performed by a user-facing component of the datacenter,
such as a Web application server.
The range servers store the content of the database
tables in memory and also dump this content
to a
distributed ﬁle system such as HDFS. Because ADDA
currently requires that
the target application use a
VFS-like interface to communicate with the ﬁle sys-
tem (§III-C2) we used a dedicated machine in our
cluster as a dedicated shared ﬁle system for the range
servers. In future work we intend to use the HDFS Fuse
support and ﬁx a bug in Hypertable that prevented us
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:58:57 UTC from IEEE Xplore.  Restrictions apply. 
from experimenting with this setup.
Fig. 4 shows that, for Hypertable, the recording
overhead scales well with the size of the input from
persistent storage. The overhead, measured as reduction
in transaction throughput, is between 10% and 50%. On
the other hand, the naive approach has higher overhead,
which increases up to 90% for the largest total input
size. In this experiment, Hypertable was conﬁgured with
one master, one lock server, 3 range servers, and 7
clients that placed a heavy load on the system. Each
client used an input ﬁle ranging from 30MB to 150MB.
Clients read the input ﬁle from persistent storage.
Recording overhead vs. input size for Hypertable
ADDA
Naive approach
]
%
[
d
a
e
h
r
e
v
O
 120
 100
 80
 60
 40
 20
 0
 300
 600
 900
 1200
 1500
Total input size [MB]
Fig. 4: Recording overhead for Hypertable with varying
size of the input from persistent storage.
Fig. 5 shows that ADDA scales well with the number
of traced nodes and the overhead is in between 40% and
50%. Due to higher logging rates, the naive approach
has higher overhead. In this experiment, Hypertable was
conﬁgured with one master, one lock server, 2 range
servers, and a number of clients ranging from 3 to 9.
Each component was run on a separate machine. The
overhead is measured in terms of throughput loss.
]
%
[
e
v
i
t
a
n
o
t
d
e
r
a
p
m
o
c
d
a
e
h
r
e
v
O
 120
 100
 80
 60
 40
 20
Recording overhead vs. # clients for Hypertable
ADDA