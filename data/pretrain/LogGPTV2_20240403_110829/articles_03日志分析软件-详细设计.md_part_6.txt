其中
\\S表示匹配非空格字符，\\S+表示匹配连续的非空格字符，(?\value) 表示提取名字为key的字段，其值为value，会解析出如下字段：
1 timestamp：2014-05-14 23:24:47
2 pid：15752
3 loglevel：Note
4 message：InnoDB: 128 rollback segment(s) are active
除了正常的正则表达式，我们还提供了一些常用的正则表达式，可以通过%{XXX}的方式来引用。比如可以使用%{NOTSPACE}来代替\\S+，这样的正则表达式为：
(?\%{NOTSPACE} %{NOTSPACE}) %{NOTSPACE:pid}
\\\[%{NOTSPACE:loglevel}\\\] %{GREEDYDATA:message}
默认的字段值是string类型的，如果用户想将其转换为number类型，可以在引用中加入type类型，目前仅支持int和float类型，例如：
%{XXX:int} 或者 %{XXX:float}
**常用的正则表达式**
1 基本：
%{NUMBER} (?:%{BASE10NUM})
%{POSINT} \\b(?:\[1-9\]\[0-9\]\*)\\b
%{NONNEGINT} \\b(?:\[0-9\]+)\\b
%{WORD} \\b\\w+\\b
%{NOTSPACE} \\S+
%{SPACE} \\s\*
%{MORESPACE} \\s+
%{DATA} .\*?
%{GREEDYDATA} .\*
%{IP} 略
%{PORT} 略
2 Apache/Nginx：
%{ApcClientIP}
%{ApcIdent}
%{ApcUser}
%{ApcTimestamp｝
%{ApcStatus}
%{ApcRespLen}
%{ApcReferer}
%{ApcUa}
%{ApcXForward}
%{ApcRequest}
例如原始日志:
192.168.1.139 - - \[24/Jan/2015:17:03:49 +0800\] \"GET
/api/v0/search/fields/?field=tag&filters=&order=desc&page=1&query=\*&size=50&sourcegroup=all&sourcegroupCn=%E6%89%80%E6%9C%89%E6%97%A5%E5%BF%97&time_range=-2d,now&type=fields
HTTP/1.1\" 200 363
\"http://alltest.rizhiyi.com/search/?query=\*&time_range=-2d%2Cnow&order=desc&size=20&page=1&sourcegroup=all&type=timeline&\_t=1422088066859&title=%E9%BB%98%E8%AE%A4&index=0\"
\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.10; rv:35.0) Gecko/20100101
Firefox/35.0\"
可以采用如下配置：
%{ApcClientIP} %{ApcIdent} %{ApcUser} %{ApcTimestamp} %{ApcRequest}
%{ApcStatus} %{ApcRespLen} %{ApcReferer} %{ApcUa}
抽取出如下字段：
**注意事项**
正则库使用的是完全匹配模式，即正则表达式需要消耗掉整条日志才可以匹配：
%{IP:ip}:%{PORT:port} 不会匹配2014-10-20
192.168.1.1:8080和 192.168.1.1:8080 2014-10-20，只会匹配192.168.1.1:8080
一个正则表达式中字段分组命名的字段不能重复，如果命名的字段有.
\@或空格，它们都会被替换成下划线\_，因此不要使用这些符号。
以下解析规则需要配置source（哪个字段），指定这个配置对哪个字段有效，如果没有指定source则默认指定的是原始日志。
**KeyValue分解**
KV主要用来解析明显的KV字符串，例如上面的例子中正则表达式解析后，request_query字段为：
field=tag&filters=&order=desc&page=1&query=\*&size=50&sourcegroup=all&sourcegroupCn=%E6%89%80%E6%9C%89%E6%97%A5%E5%BF%97&time_range=-2d,now&type=fields
这是一个按照\"&\"和\"＝\"来分割的KV字段。添加解析规则：KeyValue分解，source字段选择request_query，定义字段间分隔符为&，定义k-v分隔符为=，点击解析，如图可看到解析结果：
**数值型字段转换**
默认提取出来的字段都是字符串类型的。如果用户希望将这个值转换成数值类型，以方便再后面做统计，则需要通过这个功能来做转换。转换时需要用户配置数值的类型：int/float
例如： 用户的日志经过解析得出如下字段：
k1: \"123\",
k2: \"123.0\"
经过转换可以转变为：
k1: 123,
k2: 123.0
如针对正则表达式的解析结果，选择resp_len字段，点击解析：
**url解码**
将编码过的url进行解码，这个操作只能针对已经解析出来的字段。
如针对正则表达式的解析结果，选择字段request_query.sourcegroupCn，点击解析：
**User Agent解析**
分析HTTP日志中User
Agent的用户操作系统和浏览器信息。如针对正则表达式解析后的结果，选择ua字段，点击解析：
**时间戳识别**
使用者通常关心日志发生的时间，比如检索最近几天的日志，需要转换日志中的timestamp字段的内容，日志分析软件系统就可以识别这条日志的时间戳。这就需要用户在之前抽取字段时就提取出timestamp字段。例如：
timestamp: \"150120 16:00:30\"
需要配置解析类型为：
yyMMdd HH:mm:ss
具体的配置格式参考：
  ------------------------------------------------------------------------
  符号   含义           格式          举例
  ------ -------------- ------------- ------------------------------------
  e      星期           数字          星期二：\
                                      e2\
                                      ee：02
  E      星期           文本          星期二：\
                                      E：Tue\
                                      EEEE：Tuesday
  M      月份           月            七月：\
                                      M:7\
                                      MM:07\
                                      MMM:Jul\
                                      MMMM:July
  d      一月的第几天   数字          第9天\
                                      d:9\
                                      dd:09
  H      0-23小时       数字          8点\
                                      H:8\
                                      HH: 08
  m      0-59分钟       数字          8分\
                                      m:8\
                                      mm:08
  s      0-59毫秒       数字          8秒\
                                      s:8\
                                      ss:08
  S      0-999毫秒      数字          888毫秒\
                                      SSS:888
  z      时区           文本          zzz:PST\
                                      zzzz:Pacific Standard Time;
  Z      时区           时区          Z: +0800;\
                                      ZZ: +08:00;\
                                      ZZZZ: America/Los_Angeles
  ------------------------------------------------------------------------
如果符合ISO8601标准可以直接配置成\"ISO8601\"，例如：Fri Jul 05 21:28:24
2013 ISO8601，
如果是UNIX格式可以直接配置成\"UNIX\"，例如：1412899200.000，
如果解析失败或者没有配置，默认使用进入系统的时间作为这条日志发生的时间。
对上面例子中的日志时间戳进行配置，source字段选择timestamp，填入"dd/MMM/yyyy:HH:mm:ss
Z"，点击解析，弹出配置成功窗口如下图：
**JSON解析**
JSON解析用来解析JSON格式的日志, 例如原始日志为：
{\"Name\": \"John Smith \", \"Age\": 23, \"Employed\": true,
\"Address\": {\"Street\": \"324 Chrome St\", \"City\": \"Portland, New
York,Los Angeles \", \"Country\": \"United States\"}}
JSON解析后如下图所示：
**字段值拆分**
将字符串切分，例如：
key：\"1.2.3.4, 2.4.5.6\"
可以根据"，"来对其进行切分成两个value:
key：\[\"1.2.3.4\", \"2.4.5.6\"\]
在上面的JSON解析结果中，Address.City字段内容为 \"Portland, New York,Los
Angeles
\"，将其作为source字段，将分隔符设定为","，点击解析，即得到解析结果如图所示:
**（3）字典管理**
原始日志中往往包含了大量具有特殊意义的代码字符，即使是专业人员也无法迅速理解日志内容，造成日志分析工作难以进行，利用字典功能可以对日志内容进行自定义的对应转换，使日志更易读，分析更容易。
## API
日志分析软件RESTful
API提供对日志分析软件系统的调用接口，便于用户以灵活的方式集成日志分析软件系统。
访问日志分析软件RESTful API服务器需要进行签名验证。签名验证的目的是：
1.  验证用户身份：只有拥有表明用户身份的key，用户才能够访问API服务。
2.  保护网络传输过程中用户请求不被篡改：API会验证用户使用key为每次请求计算出的签名，以防止在网络传输过程中用户的请求被篡改。
3.  防止重复请求攻击(Replay
    attack)：当API使用者的HTTP请求记录被窃取（如：访问API的日志文件泄露），导致窃取者可以重复发送此的请求，从API服务器窃取对应的查询结果。
通过给用户分发access_key、secure_key，API服务提供了基于MD5的签名验证机制。其中针对重复请求攻击，API服务承诺会接受当前时间一分钟之内的请求，对于签名时间到被API服务端接收之间时延超过一分钟的请求则直接拒绝。
**获取签名需要的key**
请从API服务提供者处获取一对access_key和secure_key。key的形式为长度为32的字符串。举例如下：
-   access_key：e31429454b845ae95ece2cbeae06a3a6
-   secure_key：535479d978359bf4975acf7e7f3f0147
**使用签名**
签名计算过程：
1.  将原始请求构造成Hash形式origin_params，hash的key与value均为字符串。
2.  将origin_params的key按照字母顺序排序后，key与value之间用=进行字符串链接，每对key之间用&进行字符串链接，构造一个用来生成签名的字符串sorted_query_str
3.  将以毫秒计的当前Unix时间戳query_time和从API提供者处获得的secure_key跟sorted_query_str进行字符串链接获得字符串进行MD5计算，其结果截取前32个字符即为本次请求的sign
在原始请求之上，添加 { \'qt\': query_time, \'ak\'=access_key, \'sign\':
sign } 作为额外参数即可使用签名访问API服务。
**接口手册**
API服务使用HTTP GET方式，返回数据格式为json格式。当前支持如下查询：
-   搜索(search)
**返回码**
  ---------------------------------------------------------------------------------------------------------------------------
  状态码   含义                     详述
  -------- ------------------------ -----------------------------------------------------------------------------------------
  200      成功                     请求成功执行。
  400      用户请求内容错误         可能请求的参数缺少qt,ak,sign；可能使用了错误的ak；可能请求URL没有encode。
  403      用户没有权限访问该资源   可能是计算错了签名sign；可能这是一次重复的请求被认为是replay attack。
  404      找不到请求的资源         可能是传入了不支持的参数或者参数给定了非法的值，比如传入了order=\'\'但值不为desc和asc。
  408      用户请求过期             可能是qt参数标明的时间戳为服务器时间的一分钟之前，考虑需要同步客户端与服务端时间。
  500      服务端错误               API服务没有处理到的服务端异常；如果出现感谢用户能反馈给日志分析软件。
  ---------------------------------------------------------------------------------------------------------------------------
**搜索接口**
日志分析软件产品的搜索功能可从搜索章节了解。API搜索接口提供通过搜索语句和字段过滤,搜索结果有如下三个查询接口：
-   events:
    输出搜索和过滤后的event具体内容，包括event的原始内容、appname、tag、logtype和分析后的fields。
-   timeline: 输出搜索和过滤后的event按照时间段的统计计数。
-   fields:
    输出搜索和过滤后的events所含有的fields的名字和指定filed的值的统计计数。
**timeline**
路径 /search/timeline/
参数
+-------------+----+------------------------------------------+-------+
| 参数        | 含 | 合法值                                   | 默    |
|             | 义 |                                          | 认值  |
+=============+====+==========================================+=======+
| s           | 日 | all和其他日志分组                        | all   |
| ource_group | 志 |                                          |       |
|             | 分 |                                          |       |
|             | 组 |                                          |       |
+-------------+----+------------------------------------------+-------+
| time_range  | 搜 | -   以逗号分隔的两个以毫秒计的unix时间戳 | -3    |