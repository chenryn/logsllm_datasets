### Classification of Bottlenecks

We classify the bottlenecks in our study using two primary methods. The first classification is based on the AS (Autonomous System) tiers, which are determined using the WHOIS servers from RADB [27] and RIPE [28] routing registries. We further categorize these ASes into tiers using the results from [33].

The second classification is based on the latency of the bottleneck links. We categorize bottlenecks into three levels of latency: low latency (≤ 5ms), medium latency (5-15ms), and high latency (> 15ms). Within each latency level, we distinguish between bottlenecks that occur within ISPs and those that occur between carrier ISPs.

For paths leading to Network Access Points (NAPs), we classify them into three categories:
1. Paths without a bottleneck (as reported by BFind).
2. Paths with a bottleneck at the NAP.
3. Paths with a bottleneck elsewhere.

In all cases, we focus on non-access bottlenecks. For each category, we present a cumulative distribution function (CDF) of the available capacity of the bottlenecks.

### Subjective Critique

Here, we discuss some potential limitations of our approach. To approximate the measurement of "typical" paths, we selected what we believe to be a representative set of network paths. While this set is not exhaustive, it is diverse in terms of location and network connectivity. However, since most of our measurements are sourced from PlanetLab's academic hosts, there may be hidden biases in their connectivity. For instance, they may predominantly have Internet2 connections, which are uncommon in other networks. This bias does not affect our measurements, as our destinations are not academic sites and thus do not use Internet2. Nonetheless, our test nodes are primarily USA-centric (only 3 international sources and 7 destinations), which may limit our ability to accurately measure international network connectivity.

Routing can also significantly impact our measurements. If routes change frequently, it becomes challenging for the BFind tool to saturate a path and detect a bottleneck. Similarly, if an AS uses multipath routing, BFind’s UDP probe traffic and traceroutes may take different paths through the network, leading to undetected bottlenecks. However, during our continuous sampling with traceroute, we did not observe these routing issues frequently. This aligns with recent findings that most Internet paths tend to be stable, even over hours [37].

The processing time taken by routers to generate traceroute ICMP responses can also affect our measurement of queuing delays and, consequently, the detection of bottlenecks. Many researchers have noted that ICMP error processing, typically done in the router's "slow" processing path, takes longer than packet forwarding. Some routers pace their ICMP processing to avoid being overwhelmed, which could artificially inflate the delays reported by traceroute. However, recent work [9] has shown that slow path/fast path differences should not significantly impact traffic measurement tools, as the typical ICMP processing delays are on the order of 1-2 ms, well within the timescales needed for accurate bottleneck detection.

Address allocation can also skew our results. We rely on the addresses reported by routers in their response to traceroute probes to determine ownership. In some peering arrangements, a router owned by an ISP may be allocated an address from the peer ISP's address space for configuration convenience. This can lead to misidentification of the peering link. However, the common use of point-to-point links in private peering and separate address allocations in public exchanges reduces this issue significantly.

Finally, our results represent an empirical snapshot of non-access Internet bottlenecks. We focus on collecting observations from a large number of paths rather than taking repeated measurements over an extended period. While this approach provides a broad view of bottleneck characteristics and locations, it does not allow us to assess the stability or persistence of these locations. A long-term characterization of bottlenecks is a natural extension of our work.

### Results

Over a period of 5 weekdays, we ran our BFind tool between our chosen source and destination sites, conducting tests between 9am and 5pm EST. These tests identified 889 non-access bottleneck links along 2028 paths. As described in Section 2, our post-processing tools categorize these network links and bottlenecks in various ways. In this section, we describe the properties of these paths and bottlenecks in these different categories.

#### Path Properties

Our results are based on observations made on paths between PlanetLab sites and ISPs at different tiers in the Internet hierarchy. Before describing the results on bottleneck links, it is useful to consider some overall characteristics of these paths.

Figures 3(b) and 4(b) summarize the overall features of paths from PlanetLab sites, classified by paths to ISPs of a particular tier. On the y-axis, we plot the normalized number of links, i.e., the total number of links encountered of each type divided by the total number of paths in each class. Each path class has a pair of bars. The left bars show the overall average properties of the paths, while the right bars show the average number of unique links. The number of unique links is significantly less, by a factor of 2 or 3, than the actual link counts because links near the sources and destinations are probed by many paths and are counted repeatedly. Such links can bias our measurements, so we also present information about unique links.

Figure 3 shows intra-ISP links, while Figure 4 shows peering links. By examining both figures, we can understand the characteristics of the entire paths. For example, Figure 3(b) shows that the average path between a PlanetLab site and a tier-2 destination traversed about 4.5 links inside tier-1 ISPs, 2.0 tier-2 ISP links, and 0.5 tier-3 links. Figure 4(b) shows that these same paths also traversed about 0.25 tier-1 to tier-1 peering links, 0.75 tier-1 to tier-2 links, 0.2 tier-1 to tier-3 links, 0.2 tier-2 to tier-2 links, and a small number of other peering links. The total average path length to tier-2 ISPs is the sum of these two bars, i.e., 7 + 1.4 = 8.4 hops. Similar bars for tier-1, tier-3, and tier-4 destinations show the breakdown for those paths. A clear trend is that the total path length for lower-tier destinations is longer. The tier-1 average length is 7.8 hops, tier-2 is 8.3, tier-3 is 8.3, and tier-4 is 8.8. Another important feature is the diversity of link types in typical paths to each class. As expected, paths to lower-tier destinations contain a significant proportion of all types of peering and intra-ISP links.

#### Locations of Bottlenecks

Figures 3(a) and 4(a) describe the different types of bottleneck links found on paths to different tier destinations. Recall that BFind identifies either one or zero bottleneck links on each path. The left bars in the graphs show the overall average properties of the paths, while the right bars show the average number of unique links.