==== Docker容器日志采集
日志易从1.10.0.26版本开始，提供DockerInput插件，支持采集单一Docker容器，以及Docker Swarm、Kubernetes等容器编排环境下的容器集群内的系统及应用日志。
其工作原理如下图所示：
image::images/docker-input.png[]
以Docker Swarm平台为例：
1.	在宿主机上部署一个Heka Container，通过配置-v参数，将宿主机的/及/var/run/docker.sock挂载到Heka Container内部。
2.	Heka Container里的hekad通过配置DockerInput，监控宿主机的Container变化，并根据Container的LABEL采集对应容器的stdout和文件目录。
3.	其他应用的容器启动时，需要配置LABEL来告知是否期望采集stdout以及期望哪个文件目录被采集。
4.	在发现Container配置变化时，在进程内动态创建对应的LogstreamerInput，采集相关文件。
5.	不同于传统企业版的heka，Docker环境的Heka采用固定配置，且不和auth、yottaweb 等模块通信。
6.	hekad除了采集对应文件内容外，还会将文件所属容器的hostname, ip, source等信息自动填入上传。
7.	支持不同文件配置不同多行合并规则和编码。
比如，阿里云容器日志采集配置方法如下:
[source,]
###Other
[DockerInput]
# 宿主机的/目录对应在Heka容器内的路径
base_dir = "/host"
# 容器LABELS前缀,LABELS规则稍后会详细描述
prefix = "aliyun.logs."
# docker endpoint
endpoint =  "unix:///var/run/docker.sock"
数据格式：
* docker.container_id：容器 ID
* docker.container_name：容器名称
* docker.image_id：容器镜像 ID
* docker.ip_of_host：容器 IP 地址
* docker.name_of_host: 容器主机名
kubernetes平台不支持将LABELS 信息传递给POD中的容器。使用kubernetes平台的用户，需要借助envs来达到类似效果。
比如，在envs中配置如下一行键值对：
 aliyun_logs_catalina=stdout
这行配置表示，日志易要采集对应容器实例的stdout，并将采集到的数据的appname设为catalina。
[NOTE]
====
日志易会自动将envs键名称中的“_”全部替换为“.”后当作LABLES处理。本节后续内容将继续使用LABLES概念进行讲述，并不影响kubernetes平台上的envs逻辑。
====
===== 容器LABLES规则说明
可被日志易感知的容器LABLES为如下格式:
[source,]
###Other
# 必填项，${prefix}后的一项为appname，对应LABEL的值为待采集文件的白名单（支持正则，但不支持通配符）
# 如果非阿里云环境，对应容器需要正确配置VOLUME(如: -v /usr/local/logs/)，使待采集目录可在宿主机访问
# 如果要采集容器的stdout，则该LABEL的值配置为stdout
${prefix}appname=/usr/local/logs/test\\.log
# 日志的tag，非必须, 默认使用appname作为tag
${prefix}appname.tag=xxx
# 日志的编码，非必须，默认使用utf-8
${prefix}appname.charset=gbk
# 多行合并规则，非必须，默认使用\\n(\\S)
${prefix}appname.splitter_regex=\\n
如果LABLES中的目录不存在，或者正则不合法，则对应容器文件不被采集，且在heka标准出错中可看到相关日志。
===== 部署流程示例
在容器环境下，日志易采集端的部署流程示例如下：
1. 首先需要将对应hekad镜像上传到对应Docker环境。不同云方式不同，且镜像中的配置文件需要根据不同环境进行配置，因此请联系日志易技术支持人员获取对应的Heka镜像。
2. 启动hekad容器，开始监听采集Docker容器日志：
 docker run --rm -it -v /var/run/docker.sock:/var/run/docker.sock  -v /:/host -v /var/cache/hekad:/var/cache/hekad hekad
3. 启动容器，并适当配置LABLES告知需要采集特定文件日志：
 docker run -it --rm -p 10080:8080 -v /usr/local/tomcat/logs --label aliyun.logs.catalina=stdout --label aliyun.logs.access=/usr/local/tomcat/logs/localhost_access_log\.txt tomcat
如果通过envs来配置，则可以使用如下命令达到类似效果 （kubernetes中可以在YAML文件中配置应用容器的envs）：
 docker run -it --rm -p 10080:8080 -v /usr/local/tomcat/logs -e "aliyun_logs_catalina=stdout" -e "aliyun_logs_access=/usr/local/tomcat/logs/localhost_access_log\.txt" tomcat
可以看到，tomcat容器配置了LABELS如下：
 # 采集该容器的stdout，appname为catalina
 aliyun.logs.catalina=stdout
 # 采集/usr/local/tomcat/logs/localhost_access_log.txt文件，appname为access
 aliyun.logs.access=/usr/local/tomcat/logs/localhost_access_log\.txt
1.	上述LABLES配置使用了默认的tag、字符集和多行合并规则；
2.	文件路径使用的是正则，而非通配符，因此.需要用\.转义，而*需要写成.*。
3.	hekad是流式采集，能自动发现日志滚动，因此推荐只采集最新的一个日志文件，而不要采集滚动后的文件，否则会造成文件滚动后重复采集。
例如：日志滚动方式为a.log,a.log.1,a.log.2，只需要配置采集xxx/a\.log即可。
===== 通过环境变量指定collector地址以及token
考虑到用户Docker环境存在需要动态指定Collector地址及Token的可能，对应镜像支持通过环境变量配置collector地址及token，具体操作方式如下:
 docker run --rm -it -v /var/run/docker.sock:/var/run/docker.sock  -v /:/host -v /var/cache/hekad:/var/cache/hekad -e RIZHIYI_ADDRESS=192.168.1.54:5180;192.168.1.55:5180 -e RIZHIYI_TOKEN=xxxxx hekad
RIZHIYI_ADDRESS：日志易collector地址，多个地址间用;分割
RIZHIYI_TOKEN：对应token
===== 采集Docker指标信息
版本要求：heka-linux-amd64 v3.1.0.15以上 (包括v3.1.0.15)
配置
build镜像配置
1. 浏览器访问 http://heka.rizhiyi.com:8084/build
+
image::images/docker1.png[]
2. 根据集群实际情况，填入Token，Collector地址(多个地址用";"分隔), Label前缀
3. 如果需要统计指标，就勾选EnableMetricInput，并填入统计间隔
4. 点击build
5. 如果build成功，将出现下载界面，点击Download即可下载对应的heka.tar文件，如果失败，将提示失败原因
如果不在docker中运行，则在高级配置的other下增加：
[source,]
----
[DockerMetricInput]
  type = "DockerMetricInput"
  # 单次统计所有容器的超时时间
  timeout = "60s"
  # 统计间隔
  ticker_interval = 60
  # appname
  appname = "docker_metric"
  # tag
  tag = "docker_metric"
  # 是否立刻采集
  immediate_start = true
  # socket地址
  endpoint = "unix:///var/run/docker.sock"
  # 需要采集的指标，cpu和percpu(统计每个核心)一般只取一个
  metricsets = ["cpu", "diskio", "memory", "network", "percpu"]
----
数据格式
* appname：docker_metric
* tag：docker_metric_具体指标，如docker_metric_percpu,docker_metric_network,docker_metric_memory,docker_metric_diskio，docker_metric_cpu
* type：DockerMetricInput
* ip：docker的ip
* hostname：docker的hostname
* source：docker的id
各指标类型的payload数据如下：
network：
* in/out：收发速度，bytes为字节数，其余为包数
* interface：网络接口名称
* inbound/outbound：分别为接收/发送的总量，bytes为字节数，其余为包数
[source,]
----
{
  "in": {
    "bytes": 0,
    "dropped": 0,
    "errors": 0,
    "packets": 0
  },
  "inbound": {
    "bytes": 1640,
    "dropped": 0,
    "errors": 0,
    "packets": 22
  },
  "interface": "eth0",
  "out": {
    "bytes": 0,
    "dropped": 0,
    "errors": 0,
    "packets": 0
  },
  "outbound": {
    "bytes": 0,
    "dropped": 0,
    "errors": 0,
    "packets": 0
  }
}
----
memory：凡是带pct的单位均为1，尚未百分化，如rss.pct为0.0197%
* fail：故障计数器
* limit：内存限制
* stats:docker api返回的原始数据
* rss：长驻内存，即分配的内存
* usage.max：最大内存使用量
* usage.pct：内存使用率
* usage.total:总内存使用量
[source,]
----
{
  "fail": {
    "count": 0
  },
  "limit": 2096263168,
  "rss": {
    "pct": 0.00019734926716987472,
    "total": 413696
  },
  "stats": {
    "pgpgout": 686,
    "rss": 413696,
    "pgpgin": 787,
    "total_rss": 413696,
    "total_inactive_anon": 258048,
    "hierarchical_memory_limit": 9223372036854771712,
    "total_pgfault": 1325,
    "active_anon": 155648,
    "total_active_anon": 155648,
    "total_pgpgout": 686,
    "inactive_anon": 258048,
    "pgfault": 1325,
    "total_pgpgin": 787,
    "hierarchical_memsw_limit": 9223372036854771712
  },
  "usage": {
    "max": 2498560,
    "pct": 0.00033412598699058,
    "total": 700416
  }
}
----
diskio 
* read.bytes:容器使用寿命内读取的字节数
* read.ops:容器使用寿命内的读取次数，
* read.rate:每秒读取的次数（同标黑的reads)
* write下的类似
* reads：每秒读取次数
* summary.bytes:读写字节数
* summary.ops:容器使用寿命内的读写次数
* summary.rate:每秒io次数（同标黑的total)
* total:每秒读写次数
* writes ：每秒写入次数
[source,]
----
{
  "read": {
    "bytes": 51175424,
    "ops": 2188,
    "rate": 0.17233693558430005
  },
  "reads": 0.17233693558430005,
  "summary": {
    "bytes": 51175424,
    "ops": 2188,
    "rate": 0.17233693558430005
  },
  "total": 0.17233693558430005,
  "write": {
    "bytes": 0,
    "ops": 0,
    "rate": 0
  },
  "writes": 0
}
----
cpu
凡是带pct的单位均为1，尚未百分化，如system.pct为200%
* core：下属为每个核心的情况
* norm.pct：通过cpu核心数标准化(平均计算每个cpu)后的占用率,如本例中，核数为2，所以system.norm.pct*2=system.pct，所以system.norm.pct为1时，system.pct为2
* pct: cpu使用率
* ticks: 各空间占用的时钟周期
* kernel：内核空间
* system：系统空间
* total：总量
* user：用户空间
[source,]
----
{
  "core": {
    "0": {
      "norm": {
        "pct": 0
      },
      "pct": 0,
      "ticks": 14049122
    },
    "1": {
      "norm": {
        "pct": 0
      },
      "pct": 0,
      "ticks": 36816301
    }
  },
  "kernel": {
    "norm": {
      "pct": 0
    },
    "pct": 0,
    "ticks": 20000000
  },
  "system": {
    "norm": {
      "pct": 1
    },
    "pct": 2,
    "ticks": 276826040000000
  },
  "total": {
    "norm": {
      "pct": 0
    },
    "pct": 0
  },
  "user": {
    "norm": {
      "pct": 0
    },
    "pct": 0,
    "ticks": 20000000
  }
}
----
cpu：
core下没有记录，其余同percpu。
[source,]
----
{
  "core": null,
  "kernel": {
    "norm": {
      "pct": 0
    },
    "pct": 0,
    "ticks": 20000000
  },
  "system": {
    "norm": {
      "pct": 1
    },
    "pct": 2,
    "ticks": 278453690000000
  },
  "total": {
    "norm": {
      "pct": 0
    },
    "pct": 0
  },
  "user": {
    "norm": {
      "pct": 0
    },
    "pct": 0,
    "ticks": 20000000
  }
}
----