of these default values to conduct a sensitivity analysis.
Table 2 lists the application codes used in our experi-
mental evaluation. Our applications are divided into two
groups. The ﬁrst group contains the C benchmarks from the
SPECFP2000 suite [25] plus two FORTRAN benchmarks,
of which we were able to generate the C versions by hand,
whereas the second group consist of representative appli-
cations from the domain of embedded computing. We col-
lected the applications in the second group from the differ-
ent sources. For the SPEC benchmarks, we fast-forwarded
the ﬁrst 1 billion instructions and then simulated the next
400 million instructions. The embedded applications are
ran to completion. For each group of benchmarks in Ta-
ble 2, the second column gives a brief description, and the
third column shows the input ﬁle/data size used.
4.2 Results
Our ﬁrst group of results are given in Figure 13 and cap-
tures the increase in the memory space requirements as a
result of data duplication. We evaluated the three differ-
ent schemes presented in Section 3: FULL, NRWD, and
CDDR. Recall that CDDR is the memory space conscious
approach we proposed in this paper. We need to men-
tion that, although not presented here in detail, the FULL
scheme increased the original memory space (i.e., the one
Figure 14. Increase in execution cycles due to dif-
ferent schemes.
Figure 15. Relative contributions of intra-nest and
inter-nest optimizations.
with no duplication) by nearly 45% on the average. Since
the data memory requirements of the different applications
are in different orders, the results in Figure 13 are normal-
ized with respect to those obtained with the FULL scheme.
One can see from these results that our compiler-directed
approach (CDDR) saves, on an average, about 31.2% mem-
ory space with respect to the FULL scheme and 19.7%
memory space with respect to the NRWD scheme.
In
fact, our approach generates signiﬁcant savings over the
NRWD scheme for all application codes tested. These re-
sults clearly emphasize the importance of using compiler
analysis to reduce the extra memory space demand due to
data duplications.
In our next set of experiments, we evaluate the impact
of our approach on execution cycles. Figure 14 presents the
execution cycles, normalized with respect to the total execu-
tion cycles when no duplication is used. It can be seen that,
while all three duplication-based schemes lead to some in-
crease in execution cycles (as a result of both the extra syn-
chronization needed among processors and the degradation
caused in cache behavior by extra data elements), there is
a signiﬁcant difference between the CDDR scheme and the
other two. Speciﬁcally, the increase in execution cycles due
to the FULL, NRWD and CDDR schemes are 13.9%, 9.2%,
and 3.9%, respectively. These results indicate that minimiz-
ing the extra memory space requirements through compiler
analysis can also be beneﬁcial from the performance angle,
though its main objective is to minimize the extra memory
requirements arising from data duplication.
Recall from the discussion in Section 3.3 that our ap-
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:27:26 UTC from IEEE Xplore.  Restrictions apply. 
To make the difference between this and our default paral-
lelization strategy clear, let us consider a scenario where we
have three loops, whose indices are i1, i2 and i3, in a nest
and i1 can not be parallelized but i2 can be parallelized. In
this case, our default strategy would parallelize i2, whereas
the new strategy would not parallelize any loop, in an at-
tempt to reduce the number of times a parallel thread is
spawned and the number of times the threads are synchro-
nized. As compared to the results given earlier in Figure 13,
we see that the memory space savings achieved by our ap-
proach under this new scheme (Figure 17) are higher with
this new scheme. The main reason for this is that the new
scheme is more conservative in parallelization and this in
turn increases the opportunities for duplication. Therefore,
as compared to the FULL scheme, our approach ﬁnds more
opportunities for reducing the extra memory space require-
ments.
5 Related Work
We discuss the related work in three categories, namely,
reliability efforts on CMP architectures, memory reuse op-
timizations, and efforts targeting at minimizing the impact
of transient and permanent errors.
There exist various prior efforts [6, 13, 14, 19, 20, 28, 32]
on chip multiprocessors, and they improve the behavior
of a chip multiprocessor from different aspects, for exam-
ple, memory performance, communication, reliability, etc.
While chip multiprocessors post a new challenge for com-
piler researchers, they also provide new opportunities as
compared to traditional parallel architectures. Most of the
prior reliability oriented work on CMPs have been done in
the architecture domain [6, 13, 28], whereas our work is
compiler oriented.
Array contraction was proposed by Wolfe [31] for opti-
mizing programs in a vector architecture. Memory reuse
optimization for loop-based codes has been studied in
[12, 24, 26, 27]. Wilde and Rajopadhye [29] proposed us-
ing a polyhedral model for studying memory reuse. All
these prior studies and our approach exploit variable life-
time information extracted by the compiler. The main dif-
ference between these efforts and our approach is that we
use the compiler-extracted lifetime information for reduc-
ing the additional memory space demand due to enhanced
reliability against transient errors, rather than reducing the
original memory demand of the application. Speciﬁcally,
our objective is to reduce the memory space requirement
for duplicates.
Software techniques for fault detection and recovery
have been studied by prior research [7, 10, 21, 16, 22].
Rebaudengo et al [17] and Nicolescu et al [15] proposed
systematic approaches for introducing redundancy into pro-
grams to detect errors in both data and code. Their approach
demonstrated good error detection capabilities, but it also
introduced considerable memory overheads due to full du-
plication for all variables. Our approach, in contrast, tries
to minimize the memory overhead and retains the same de-
gree of reliability that would be provided by full duplica-
tion. Audet et al [2] presented an approach for reducing a
Figure 16. Extra memory requirements of FULL
and NRWD over CDDR. Each bar represents the
average value across all benchmarks.
Figure 17. Extra memory requirements with differ-
ent schemes.
proach can reuse memory locations from the arrays ref-
erenced in the current nest (intra-nest optimization) and
the previous nest (inter-nest optimization). The bar-chart
in Figure 15 shows the individual contributions of intra-
nest and inter-nest optimizations to the memory reductions
achieved by our approach (CDDR) over the FULL scheme.
We see from these results that, while the intra-nest opti-
mization is more effective than the inter-nest optimization
on the average (57.3% versus 42.7%), both these optimiza-
tions are necessary for achieving the best results.
We next modify the default values of two of our simula-
tion parameters and perform a sensitivity analysis. We mod-
ify the value of a single simulation parameter at a time, in
order to be able to interpret the variations in results without
much difﬁculty. The ﬁrst parameter we modify is the num-
ber of processors. Recall from Table 1 that the default num-
ber of processors used so far was 8. We now report aver-
age results across all twelve benchmark codes we have with
different number of processors. The results shown in Fig-
ure 16 indicate that the relative improvements achieved by
our compiler approach over the FULL and NRWD schemes
are consistent across the different processor counts. The
next parameter we change is the parallelization scheme.
The default parallelization strategy used so far in our ex-
periments was the outer-most loop parallelism, where in
each loop nest the outermost loop that can run parallel is
parallelized. Figure 17 shows the results when the under-
lying parallelization strategy does not parallelize any loop
in a nest where the outermost loop cannot be run parallel.
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:27:26 UTC from IEEE Xplore.  Restrictions apply. 
program’s sensitivity to transient errors by modifying the
program structure, without introducing redundancy into the
program. Although this approach introduces almost no ex-
tra memory overhead, it cannot provide the same degree of
reliability that would be provided by full duplication. Benso
et al [3] presented a similar work that improves the reliabil-
ity of a C code by code reordering. Reis et al [18] presented
a compiler-assisted fault tolerant approach for VLIW archi-
tecture. These approaches focus on performance issues, and
do not consider memory consumption. In [5], a compiler
based strategy has been proposed to reuse the memory space
requirements due to data duplication. However, this strategy
targets at single processor machines, whereas the approach
proposed in this paper targets at CMP based architectures.
6 Conclusions
An important problem in embedded chip multiproces-
sors is the tradeoff between memory space requirements
and reliability. While code duplication for improving re-
liability also requires data duplication, there has been lit-
tle work done so far to reduce these memory space over-
heads. This work is a step in this direction and proposes a
compiler-directed memory-conscious computation duplica-
tion scheme in the context of chip multiprocessors. The pro-
posed approach uses dead memory locations to store the ex-
tra data elements required for duplicating computations. In
this way, the extra memory space requirements due to dupli-
cation are kept at minimum. Our experiments results show
that the proposed approach improves over a straightforward
data duplication scheme signiﬁcantly (31.2% on the aver-
age). In addition, it cuts the performance overhead incurred
by the straightforward data duplication scheme.
Acknowledgments
This work is supported in part by NSF Career Award
#0093082, and grants from GSRC and SRC.
References
[1] R. Allen and K. Kennedy. Optimizing compilers for modern archi-
tectures: a dependence-based approach. Morgan Kaufmann Pub-
lishers Inc., San Francisco, CA, 2001.
[2] D. Audet, S. Masson, and Y. Savaria. Reducing fault sensitivity of
microprocessor-based systems by modifying workload structure. In
Proc. IEEE International Symposium in Defect and Fault Tolerant
in VLSI Systems, 1998.
[3] A. Benso, S. Chiusano, P. Prinetto, and L. Tagliaferri. A C/C++
source-to-source compiler for dependable applications. In Proc. In-
ternational Conference on Dependable Systems and Networks, pp.
71-78, June 2000.
[4] F. Catthoor, K. Danckaert, C. Kulkarni, E. Brockmeyer, P. G.
Kjeldsberg, T. V. Achteren, and T. Omnes. Data Access and Stor-
age Management for Embedded Programmable Processors. Kluwer
Academic Publishers, 2002.
[5] G. Chen, M. Kandemir, and M. Karakoy. Memory space conscious
loop iteration duplication for reliable execution. In Proc. the 12th
International Static Analysis Symposium, September 2005.
[6] M. Gomaa, C. Scarbrough, T. N. Vijaykumar, and I. Pomeranz.
Transient-fault recovery for chip multiprocessors. In Proc. Interna-
tional Symposium on Computer Architecture, 2003.
[7] C. Gong, R. Melhem, and R. Gupta. Loop transformations for
fault detection in regular loops on massively parallel systems. IEEE
Transaction on Parallel and Distributed Systems, 7(12):1238-1249,
December 1996.
[8] M. Gschwind, P. Hofstee, B. Flachs, M. Hopkins, Y. Watanabe, and
T. Yamazaki. A novel SIMD architecture for the Cell heterogeneous
chip-multiprocessor. Hot Chips 17, August 2005.
[9] R. Hetheringtonh. The UltraSPARC T1 Processor - Power Efﬁcient
Throughput Computing. Sun White Paper, December 2005.
[10] K. H. Huang and J. A. Abraham. Algorithm-based fault tolerance
for matrix operations. IEEE Transactions on Computers, vol. C-33,
pp. 518-528, June 1984.
[11] I. Kadayif, M. Kandemir, and M. Karakoy. An energy saving strat-
egy based on adaptive loop parallelization. In Proceedings of Design
Automation Conference, June 2002.
[12] V. Lefebvre and P. Feautrier. Automatic storage management for
parallel programs. Research Report PRiSM 97/8, France, 1997.
[13] S. S. Mukherjee, M. Kontz, and S. K. Reinhardt. Detailed design
and evaluation of redundant multi-threading alternatives. In Pro-
ceedings of International Symposium on Microarchitecture, 2002.
[14] B. A. Nayfeh and K. Olukotun. Exploring the design space for a
shared-cache multiprocessor. In Proc. International Symposium on
Computer Architecture, 1994.
[15] B. Nicolescu and Raoul Velazco. Detecting soft errors by a purely
software approach: method, tools and experimental results. In Proc.
Design, Automation and Test in Europe Conference and Exhibition,
March 2003.
[16] N. Oh and E. J. McCluskey. Error detection by selective procedure
call duplication for low energy consumption. IEEE Transactions on
Reliability, 51(4):392-402, December 2002.
[17] M. Rebaudengo, M. Sonza Reorda, M. Violante, P. Cheynet, B.
Nicolescu, and R. Velazco. System safety through automatic high-
level code transformations: an experimental evaluation. In Proc.
IEEE Design Automation and Testing in Europe, Munich, Germany,
March 13-16, 2001.
[18] G. A. Reis, J. Chang, N. Vachharajani, R. Rangan, and D. I. Au-
gust. SWIFT: Software implemented fault tolerance. In Proc. Inter-
national Symposium on Code Generation and Optimization, 2005.
[19] J. Renau, K. Strauss, L. Ceze, W. Liu, S. Sarangi, J. Tuck, and J.
Torrellas. Energy-efﬁcient thread-level speculation on a CMP. IEEE
Micro Special Issue: Micro’s Top Picks from Computer Architecture
Conferences, January-February 2006.
[20] S. Richardson. MPOC: A chip multiprocessor for embedded sys-
tems. Technical Report HPL-2002-186, HP Labs, 2002.
[21] Amber Roy-Chowdhury. Manual and compiler assisted methods for
generating error detecting parallel programs. Ph.D thesis, Depart-
ment of Electrical and Computer Engineering, University of Illinois
at Urbana-Champaign, 1996.
[22] P. P. Shirvani, N. Saxena, and E. J. McCluskey. Software-
implemented EDAC protection against SEUs. IEEE Transaction on
Reliability, 49(3):273-284, September 2000.
[23] Simics. http://www.simics.com/.
[24] Y. Song, R. Xu, C. Wang, and Z. Li. Data locality enhancement by
memory reduction. In Proc. the 15th ACM International Conference
on Supercomputing, June 2001.
[25] http://www.spec.org/osg/cpu2000/CFP2000/.
[26] M. Strout, L. Carter, J. Ferrante, and B. Simon. Schedule-
independent storage mapping in loops. In Proc. ACM International
Conference on Architectural Support for Programming Languages
and Operating Systems, October 1998.
[27] P. Unnikrishnan, G. Chen, M. Kandemir, M. Karakoy, and I.
Kolcu. Loop transformations for reducing data space requirements
of resource-constrained applications. In Proc. International Static
Analysis Symposium, June 11-13, 2003.
[28] C. Weaver and T. Austin. A fault tolerant approach to microproces-
sor design. In Proc. IEEE International Conference on Dependable
Systems and Networks, June 2001.
[29] D. Wilde and S. Rajopadhye. Memory reuse analysis in the polyhe-
dral model. Parallel Processing Letters, 1997.
[30] R. Wilson et al. SUIF: An infrastructure for research on paralleliz-
ing and optimizing compilers. SIGPLAN Notices, 29(12):31-37, De-
cember 1994.
[31] M. J. Wolfe. High Performance Compilers for Parallel Computing,
Addison-Wesley Publishing Company, 1996.
[32] W. Wolf. The future of multiprocessor systems-on-chips. In Proc.
Design Automation Conference, 2004.
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:27:26 UTC from IEEE Xplore.  Restrictions apply.