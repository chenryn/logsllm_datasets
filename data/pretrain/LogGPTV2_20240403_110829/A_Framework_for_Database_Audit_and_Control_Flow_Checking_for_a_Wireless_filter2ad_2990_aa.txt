title:A Framework for Database Audit and Control Flow Checking for a Wireless
Telephone Network Controller
author:Saurabh Bagchi and
Y. Liu and
Keith Whisnant and
Zbigniew Kalbarczyk and
Ravishankar K. Iyer and
Ytzhak H. Levendel and
Lawrence G. Votta
A Framework for Database Audit and Control Flow Checking 
for a Wireless Telephone Network Controller 
S. Bagchi, Y. Liu, K. Whisnant, Z. Kalbarczyk, R. Iyer 
Center for Reliable and High-Performance  Computing 
University of Illinois at Urbana-Champaign 
1308 W. Main St.,  Urbana, IL 61801 
E-mail: [bagchi, yliu, kwhisnan, kalbar, iyer] @crhc.uiuc.edu 
Y. Levendel, L. Votta 
Motorola Inc. 
1303 East Algonquin Rd., Schaumburg, IL 60196 
E-mail: LLevendel @motorola.com, 
lvottal @email.mot.com 
Abstract.  The paper presents  the design  and  iniplementa- 
tion of a dependability franiework for a call-processing en- 
vironment  in a digital  mobile telephone network  controller. 
The franiework contains a data audit subsystem to maintain 
the structural  and senlatitic  integrity  of  the database arid  a 
preemptive  control  flow  checking  technique,  PECOS,  to 
protect  call-processing  clients.  Evaluation  of  the  depend- 
ability-enhanced  system  is  perfornied  (using  NFTAPE,  a 
software-implemented  error  injection  environnient).  The 
evaluation  shows  that for control flow errors in  the client, 
the combination of  PECOS  and  data  audit eliminates fail- 
silence  violations',  reduces  the incidence of  client crashes, 
and  eliminates  client  hangs.  For database  injections, data 
audit detects 8.5%  of  the errors and  reduces the incidence 
of  escaped  errors. Evaluation of  conibiried  use of data and 
control  checking  (with error  injection  targeting  the  data- 
base and  the  client) shows coverage  increase from 3.5% to 
80% and indicates data jlow errors as a key reason for er- 
ror escapes. 
1 
Application availability  can be compromised  because of er- 
rors that affect the execution flow or because of corrupt data 
used  during the execution. In this paper,  we present  the de- 
sign and  implementation  of a dependable framework for the 
call-processing  environment  of  a digital  wireless telephone 
network  controller  whose  availability  is dependent  on  both 
control  and  data  integrity.  The call-processing environment 
includes  a database  subsystem containing configuration  pa- 
rameters  and  resource  usage  status and  call-processing  cli- 
ents for  setting  up, managing,  and  tearing  down individual 
calls.  Both  subsystems  are  vulnerable  to  errors, which  can 
manifest  as system  outages  affecting  many  customers.  The 
main  contributions  of  the  paper  can  be  summarized  as fol- 
lows: 
Introduction 
Design  and  implementation  of  a  generic,  extendable 
framework  for  providing  data  audits  and  preemptive 
control  flow checking  (using PECOS) to applications'. 
'  A  fail-silent application process either works correctly or stops function- 
ing  (i.e., becomes  silent) if  an  internal  failure occurs  131.  A  violation  of 
[his premise  is termed  a  fail-silence  violation.  In  distributed  applications, 
fail-silence  violations can  have  potentially catastrophic  effects by  causing 
fault propagation. 
Confro1 flow errors have been  demonstrated  to account for between  33% 
I IS, 21 and 77% (171 of all errors depending upon application characteris- 
tics and the error model. 
In  this  framework,  new  detection  and  recovery  tech- 
niques  can  be  integrated  into  the  system  with  minimal 
or no changes to the application. 
An  experimental  evaluation  of the  implemented  frame- 
work.  The  software-based,  error-injection  evaluation 
(using NFTAPE, a software implemented faultlerror in- 
jection  environment  [ 181) quantifies  (1) the  combined 
coverage  provided  by  data  audit  and  control  flow 
checking  in  protecting  the  call-processing  environment 
and  (2)  the  chances  of  error  propagation  between  the 
database and the client. 
The  evaluation  of  the  environment  with  both  control  and 
data  protection  shows the  following:  ( I )   for corruptions  to 
the database  subsystem (a) data audit detects 85% of the er- 
rors and (b) the incidence of escaped errors is reduced  from 
63%  to  13%; (2)  for  errors injected  to  the call-processing 
clients  (a) in  the absence  of any detection  in  the client, 8% 
of  injected  errors propagate  to the database,  (b) use of PE- 
COS completely eliminates fail-silence violations and client 
hangs, and  (c)  the incidence  of  client process  crash  are re- 
duced from 52% to  19%. 
2  Related Work 
Data  Audits.  In  the  telecommunications  industry,  the  term 
data  audit typically  refers  to a  broad  range  of  custom and 
ad  hoc,  application-level  techniques  for  detecting  and  re- 
covering  from  errors  in  a  switching  environment.  Data- 
specific  techniques  deeply  embedded in  the  application  are 
generally  believed  to  provide  significant  improvement  in 
availability, although  little or no actual  assessment of  these 
techniques has been available until the present publication. 
Application-layer  self-checking  maintenance  software  was 
successfully  deployed  to  achieve  high  availability  in  sys- 
tems  such  as  the  Lucent  Technologies 5ESS8 switch  [6]. 
The techniques  employed  include  in-line defensive  checks, 
data audits, process activity and resource checks, and modu- 
lar, hierarchical  error recovery. 
A  related  approach  to data  audit  is  robust  data  structures, 
which aims at detecting  and correcting  errors  in  stored data 
structures  that  contain carefully deployed  redundancy.  Tay- 
lor  [ 19, 201  presents  examples  of  robust  storage  structures 
and their practical  implementation. 
Commercial  off-the-shelf  database  systems  from  Oracle 
[26],  Sybase 
in-memory  database  from 
TimesTen  [25], include  utilities  to  perform  consistency 
[24],  and  the 
0-7695-1101-5/01 $10.00 0 2001 IEEE 
225 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:59:52 UTC from IEEE Xplore.  Restrictions apply. 
checks of  database  integrity. For example,  in relational  da- 
tabases  such as Oracle  the  core  database  engine supports  a 
set  of  rules  for  identifying  relations/dependencies  between 
tables  or  records  in  the  database.  These  rules  can  be  used 
for detecting  structural  and  semantic  errors  in the database 
by  performing  referential  integrity  checking  or  structural 
checking  [4].  However,  the  lack  of  a  fault-tolerant  infra- 
structure that ties the database error  detection  and recovery 
elements  together  is  a  major  limitation  in  the  existing  sys- 
tems,  especially  when  continuous  availability  and  integrity 
of  the  database  are  required.  Sabaratnam  et  al.  [16]  per- 
formed  a  fault-injection-based  assessment  of  a  replicated 
database management  system, ClustRa,  used  to  support ap- 
plications  with  soft  real-time  requirements,  e.g.,  telecom- 
munication applications. 
In  our  work  we  leverage  the  existing  experience,  and  con- 
tribute by: 
Providing  a  unified,  flexible  framework  for  creating 
and invoking new audit techniques  with little impact on 
the  database  structure  and  minimum  interference  with 
database clients. 
Combining the error detection  and the following recov- 
ery  actions  so the  two  are  transparent  to  the  database 
clients. 
Improving  the  efficiency  of  the  proposed  detection 
techniques by  ( I )   using new triggering for initiating au- 
dit, e.g., prioritized  audit and (2) adding redundancy  to 
facilitate better error diagnosis. 
Controlflow monitoring. The field of control-flow checking 
has evolved over a period  of about 20 years. The first paper, 
by  Yau  and  Chen  [22], outlined  the  general  control  flow 
checking  scheme  using  the  program  specification  language 
PDL.  Mahmood  [ 1 I] presents  a survey of the  various tech- 
niques  in  hardware  for detecting  control  flow errors. Many 
schemes  for  checking  control  flow  in  hardware  have  been 
proposed,  more recent  are [lo, 12, 14, 21, 231. Representa- 
tive  software-based  control  flow  monitoring  schemes  are 
Block  Signature Self Checking  [ 131, and Enhanced  Control 
Checking with Assertions (ECCA) [ 11. 
The key  problems with existing hardware and software con- 
trol  flow checking techniques are: ( I )   None  of  the schemes 
is  preemptive  in  nature  and  typically  detects  an  erroneous 
control  flow  after executing  instructions  from  the  incorrect 
path (although it seems to us that  [21] has the potential to be 
made  preemptive).  Consequently  the  system  often  crashes 
before  any  checking  is  triggered.  (2) The existing schemes 
cannot handle control  flow structure determined  at runtime, 
libraries  or  accessing  functions 
e.g.,  calls  to  dynamic 
through  virtual  function  tables.  These  identified  problems 
served as a reference point in designing PECOS. 
3 
Overview of the Target System Software and 
Data base Architecture 
The target system is a small-scale digital wireless telephone 
network  controller  that  integrates  many  functions  in  stan- 
dard wireless telephone  network components  (including call 
switching, packet routing, and mobility management). 
3.1  Software Components 
The key  components of application  software running  on  the 
controller are the call processing  (sets and terminates clients 
calls),  the  database  (supports  information  about  system  re- 
sources), and support environment. 
3.1.1  Call-Processing Client 
Call  processing  is  the  key  component  that  provides  cus- 
tomer-visible  functionality.  This  process  dynamically  cre- 
ates  a call-processing  thread  to  handle  activities  associated 
with  a voice/data  connection.  Specifically, the thread  is  re- 
sponsible  for  subscriber  authentication,  hardware  resource 
allocation  and deallocation,  mobility management,  and  sup- 
porting  basic  and  supplementary  telephony  features.  The 
failure of  call-processing  alone  could  render  the entire sys- 
tem  unavailable  from  a  user’s  point  of  view.  Since  call 
processing  requires  database  access,  we  refer  to  this appli- 
cation as a database or call-processing client. 
3.1.2  Database Subsystem 
The  database  subsystem  contains  data  (static  system  con- 
figuration data and runtime data that indicate resource usage 
and  process  activities)  necessary  to  support  call  processing 
application. 
Organization. To satisfy the real  time constraints, the entire 
database  is  loaded  from  disk  into  memory  at  startup  time 
and resides  completely  in memory during system operation. 
The memory region  that contains the database is contiguous 
and  is shared  among all  processes  that  require database  ac- 
cess. To remove  the possibility  of memory  leak and  ensure 
continuous  system  operation,  the  space  for all  tables  in  the 
database  is  pre-allocated,  and  no  dynamic  memory  alloca- 
tion is used in the database. 
Although the entire space is statically allocated, some tables 
are dynamic  in nature  while  others are  static.  Static data  in 
tables  usually  refer  to  system  configuration  (e.g., the  num- 
ber  of  CPUs in  the  system) and  stay constant during opera- 
tion,  whereas  dynamic  data  is  often  updated,  e.g.,  on  every 
incoming  call.  Note that each  table  usually contains a mix- 
ture of static and dynamic data. 
The database subsystem  exports an  API  for other processes 
to access the database. Some API functions along with brief 
explanations are shown in Table  I .  
Table 1: Examples of Database API 
3.2  Errors in Database 
The  database  is  subject  to  corruption  from  a  number  of 
sources:  human  operator  error, software  bugs or faults, and 
hardware  faults.  The  effects  from  these  errors  appear  in 
226 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:59:52 UTC from IEEE Xplore.  Restrictions apply. 
several ways. The most serious consequence occurs if errors 
are  introduced  into  the  system  catalog  (metadata),  which 
contains  information  used  by  the  database  API  to  access 
records  and  consists  of  several  database  tables  that  are 
referenced  on each database  operation. Errors in the system 
catalog  can  cause  all  database  operations  to  fail,  thus 
bringing down the whole controller. 
Resource  leak  is  another effect  of  a data error.  If  any  data 
indicating  resource  status  is  corrupted,  the  particular  re- 
source in question could falsely appear to be busy to the rest 
of  the  controller  leading  to  a  reduced  system  capacity.  If 
this type of error is allowed to accumulate, system availabil- 
ity is reduced. Other errors may have a local effect only. For 
example, a damaged call  record  related  to a particular  con- 
nection  will  likely bring  down that  connection  prematurely 
without affecting other active connections. 
While exact figures are not  publicly available, data from the 
telecommunication  industry  has  repeatedly  shown  that  not 
performing  database  audits  can  significantly  reduce  tele- 
phone switching system availability [8]. 
4  Audit Subsystem Architecture 
The overall design  of the database audit process  and  its in- 
teraction  with  other  system components is shown  in  Figure 
1. The right  half  of  the  figure  shows the  database,  a client 
process, and the database API (DB API) that is used  by  cli- 
ent  processes to access database.  An  inter-process commu- 
nication channel  (the IPC message queue) is added between 
the  database  API  and  the  audit  process  to  transmit  events 
from client activities. The audit  process  consists of  a dedi- 
cated  thread  (the  main  thread)  acting  as  the  interface  to 
other  components.  The  function  of  the  main  thread  is  to 
translate  information  from  external  entities  (e.g.,  the  data- 
base  client)  into  audit  messages  via  the  audit framework 
API.  The  proposed  audit  framework provides  audit  func- 
tionality  and consists of  the top-layer  shell  (the audit  inter- 
face) and  the  individual  elements  that  implement  specific 
audit triggering, error detection and recovery techniques. 
To reduce  contention  with  database  clients,  the  audit  ele- 
ments access the database directly instead of through the da- 
tabase  API.  Bypassing  the  locking  and  access  control 
mechanisms managed by  the API reduces performance pen- 
alty, but  it  requires  the  audit process  to detect database  ac- 
cess conflicts between  clients and  itself to ensure the  valid- 
ity of audit results. 
The manager performs administrative tasks such as starting, 
stopping, monitoring, and recovering  the audit process; it is 
also responsible  for overseeing the overall state of the envi- 
ronment.  The manager starts the audit process and monitors 
it  by  heartbeats  as shown  in  Figure  1.  If  the  audit  process 
fails, the manager restarts it on the same or another node. 
The  proposed  framework  provides  high  modularity  and 
transparency  allowing  for  easy  extensibility  of  the  audit 
subsystem.  New  error  detection  and  recovery  techniques 
can  be  implemented,  encapsulated  in  new  elements,  and 
added  to the system. A  new element to be incorporated  into 
the  system  needs  to  define  and  communicate  to  the  audit 
main thread  a set of messages that the element is capable of 
processing.  The different  audit  elements  can  be  quite  inde- 
pendent  of  each other,  which  allows for easy customizabil- 
ity of the audit subsystem. 
Audit Process 
lDbserver + audit) 
Ipc (message queue) 
f 
I 
Figure  1:  Target  System  with  Embedded  Audit  and 
Control Flow  Checking. The  heartbeat  (HB), progress  indicator 
(frog. Ind.), audit  (Audit  Ekni.) which  encapsulates  a set  of  error detec- 
tion  and  recovery  techniques:  periodic  audit  (fer. arrdir) and  event  trig- 
gered  audit  (EvTrig audit) which  support periodic and event triggered  in- 