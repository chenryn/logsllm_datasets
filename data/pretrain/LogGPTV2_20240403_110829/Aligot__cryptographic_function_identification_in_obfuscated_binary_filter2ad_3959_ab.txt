2. Address-centric loops Another approach, especially
built for dynamic analysis is that of [28]. A loop is
identiﬁed by a speciﬁc memory address, named target
address, where a set of backward branch instructions
jump.
In other words, several back-edges can corre-
spond to the same loop, which is then identiﬁed by
the target address. Nevertheless, this deﬁnition would
also consider Fig. 1(a) as a loop, but not Fig. 1(b).
3. Instruction-centric loops Kobayashi deﬁnes loops
on execution traces as the repetition of a machine in-
struction sequence [14]. For example, let T be a six in-
struction execution trace such that T/Ins = I1; I2; I3;
I1; I2; I3, then T is a loop iterating two times with
I1; I2; I3 as body. With this simple deﬁnition, Fig.
1(a) would not be considered as a loop, whereas Fig.
1(b) would be.
case 18:  ...c = 24  ...switch(c)case 24:  ...c = 6  ...case 6:  ...c = 180x00 inc eax0x01 inc ebx0x02 mov [ebx], eax0x03 inc eax0x04 inc ebx0x05 mov [ebx], eax0x06 inc eax0x07 inc ebx0x08 mov [ebx], eax1715.2 Simple Loop Deﬁnition
We focus on loops because cryptographic code usually use
them to apply a same treatment on I/O parameters. Follow-
ing this idea, Fig. 1(a) should not be considered as a loop
—as a diﬀerent logic is executed at each “iteration”— and
on the contrary Fig. 1(b) should be. Therefore, we choose
the Kobayashi approach as our starting point: we identify a
loop by a repeated machine instruction sequence, called its
body. Thus, the body of the Fig. 1(b) loop is made of the
three instructions inc eax, inc ebx and mov [ebx],eax.
A same loop can be run several times during an execu-
tion, each time with a diﬀerent number of body repetitions.
We call a particular run an instance of the loop. We also
consider that the last iteration might be incomplete: a loop
instance does not necessarily terminate at the exact end of
its body.
We deﬁne this loop instance notion with formal language
theory on the machine instruction alphabet X 86. For a word
α ∈ X 86∗ (i.e. α corresponds to a sequence of x86 instruc-
tions), we denote the set of preﬁxes of α by P ref (α), that is
β ∈ P ref (α) if ∃γ ∈ X 86∗, α = βγ. We denote as α ∈ X 86+
when α ∈ X 86∗ and |α| ≥ 1.
Definition 1. The language SLOOP of simple loop in-
stances is deﬁned as all traces L ∈ T RACE such that:
L/Ins ∈ {αn.β|α ∈ X 86+, n ≥ 2, β ∈ P ref (α)}
Thus, a simple loop instance is deﬁned by at least two rep-
etitions of a machine instruction sequence, called its body
and represented by α. This deﬁnition is actually more gen-
eral than Kobayashi’s, who limited a loop body to contain
the same machine instruction only once.
In other words,
there is no instruction (cid:96) ∈ X 86 such that α = u(cid:96)u(cid:48)(cid:96)u(cid:48)(cid:48) in
Kobayashi’s work.
5.3 Nested Loop Deﬁnition
For our purposes, we also need to consider nested loops.
Fig. 2(a) presents a common situation. Block B constitutes
the body of an inner loop that does not iterate the same
number of times for each outer loop iteration (cf. Fig. 2(b)).
Consequently, if we directly apply Deﬁnition 1 on the execu-
tion trace, the outer loop would not be recognized as a loop.
Nevertheless, it is still consistent with our loop principle: a
same treatment applied repeatedly.
We introduce a set LID of loop identiﬁers, and we will use
the letter X as a loop identiﬁer in the rest of the paper. For
example the execution trace in Fig. 2(b) can be rewritten as
AXCAXC with X ∈ LID the loop identiﬁer for the inner
loop B. The next application of Deﬁnition 1 will then be
able to detect the outer loop with AXC as body.
We denote as T RACELID the set of execution traces
where loop identiﬁers can replace dynamic instructions.
Definition 2. The language LOOP of loop instances is
deﬁned as all traces L ∈ T RACELID such that:
L/Ins ∈ {αn.β|α ∈ (X 86 ∪ LID)+, n ≥ 2, β ∈ P ref (α)}
Let L ∈ LOOP, we denote BODY [L] ∈ (X 86∪LID)+ the
body of the loop instance L, i.e. α in Deﬁnition 2.
5.4 Loop Instance Detection Algorithm
The loop detection algorithm is based on the recogni-
tion of the language {αn.β|α ∈ (X 86 ∪ LID)+, n ≥ 2, β ∈
P ref (α)}, which is context-sensitive and in particular not
context-free [13]. We built a single pass algorithm for loop
instance detection, working in O(m2) operations, with m
the execution trace size. We present the complete algorithm
pseudo-code in Appendix B and, for the sake of brevity, we
give here only an overview of how it works with an example.
The LOOP recognition algorithm processes machine in-
structions from the execution trace one after the other, and
stores them at the end of a list-like structure, named history.
A common situation is then the one describes in Fig. 3(a):
instructions I1, I2, I1, I3 have been recorded into the his-
tory and the currently processed machine instruction is I1.
Therefore this instruction appears twice in the history.
L1
L2
(a) Algorithm state
(b) Loop instances after I1
processing
Figure 3: Loop detection example: step one
Each occurrence of I1 in the history corresponds to a pos-
sible loop instance beginning.
In the ﬁrst case, the body
would be α = I1; I2; I1; I3, whereas in the second one it
would be α = I1; I3. Thus, the algorithm creates two loop
instances, named respectively L1 and L2, each of them with
a cursor on the next instruction expected, I2 for L1 and I3
for L2 (cf. Fig. 3(b)).
(a) CFG
(b) Execution trace
Figure 2: Simpliﬁed nested loop example
(a) Algorithm state
L2
(b) Loop instances
after I3 processing
It actually suﬃces to abstract each loop instance and ap-
ply Deﬁnition 1 recursively to solve this problem. Each time
a loop instance is detected, we replace its code by a loop
identiﬁer in the execution trace. This identiﬁer represents
the loop associated with the instance. In other words, we re-
place each instance of a same loop with the same identiﬁer.
Figure 4: Loop detection example: step two
I1 is then appended to the history. Now assume I3 is the
next machine instruction in the trace, the current situation
is described in Fig. 4(a). L1 is then discarded, as it was not
ABCA B B B C A B B CB loop instance 1B loop instance 2I1I2I1I3...    I1     ...GrowthHistoryTraceI1I2I1I3I1I3I1I2I1I3I1...    I3   ...HistoryTraceI1I3172expecting this instruction. On the other hand, the L2 cursor
is incremented and returns on the ﬁrst instruction:
it just
made a turn (cf. Fig. 4(b)). At this point we have seen ex-
actly two iterations for L2, that is I1; I3; I1; I3, and therefore
we consider it as a conﬁrmed loop instance. Thus, we re-
place its code in the history by its associated loop identiﬁer
X ∈ LID, as described in Fig. 5.
Figure 5: Loop detection example: step three
Suppose the next machine instruction is I4. Then L2,
which was waiting for I1, is removed from running loop in-
stances and registered. The replacement of its code with its
loop identiﬁer X will allow the detection of an outer loop, in-
dependently of the number of iterations of L2 for each outer
loop iteration, as explained in §5.3.
6. LOOP INPUT-OUTPUT PARAMETERS
Loops allow possible cryptographic code extraction from
execution traces, but our ﬁnal objective is to collect cryp-
tographic parameters. We present in this section a loop in-
stance parameter notion and an algorithm to extract these
parameters from execution traces. Then we will exhibit a
simple example in order to make the understanding easier.
6.1 Deﬁnition
Loop instance parameters are low-level counterparts of
high-level implementation parameters (called high-level pa-
rameters in the rest of the paper). Bytes read or written in
the execution trace constitute our starting point and, for a
loop instance L, we deﬁne its parameters by combining the
three following necessary conditions:
1. Bytes belonging to the same parameter of L are either
adjacent in memory, or in the same register at the same
time. This condition alone would tend to group multi-
ple high-level parameters in the same parameter of L.
Indeed diﬀerent high-level parameters can be adjacent
in memory, as it is often the case in the stack. Such
over-approximation would strongly complicate the ﬁ-
nal comparison phase; this is the reason we introduce
the following condition.
2. Bytes belonging to the same parameter of L are ma-
nipulated in the same manner (read or written) by the
same instruction in BODY [L]. Indeed a particular in-
struction in BODY [L] can manipulate diﬀerent bytes
at each iteration but these data tend to have the same
role (in particular because of our strict loop deﬁnition).
3. Finally, bytes belonging to an input parameter of L
have been read without having been previously written
by code within L, whereas bytes belonging to an output
parameter of L have been written by code in L.
In order to gather these parameters, we deﬁne concrete
variables as simple byte arrays starting at a particular mem-
ory address.
If a concrete variable starts at the address
Figure 6: Assembly program implementing one-time
pad cipher. KEY, ENCRYPTEDTEXT and SIZETODECRYPT are
constants resolved by the assembler, the ﬁrst two
are memory addresses pointing to parameter values,
whereas the last one contains their size.
0x400000 and contains four bytes, we denote it as 0x400000:4.
Moreover, we also consider registers as concrete variables,
whose addresses are register names, like eax:4 or bx:2. The
value contained in a concrete variable can change during the
execution. A parameter is then deﬁned as a concrete vari-
able with a ﬁxed value. For the sake of brevity, we now give
only an overview of the parameter gathering algorithm.
6.2 Algorithm Overview
The algorithm groups bytes into concrete variables by us-
ing the ﬁrst two necessary conditions. Then, we divide con-
crete variables into two groups, input and output param-
eters, by applying the third condition (the same concrete
variable can be in both groups).
In a second step, the algorithm associates a ﬁxed value to
each previously deﬁned concrete variables. As explained in
§4, our tracer engine collects values for each data access. We
use the two following rules to set parameter values: (1) the
ﬁrst time an input parameter is read provides its value, and
(2) the last time an output parameter is written provides its
value.
Finally, for each loop instance L, the algorithm returns:
INM (L) and INR(L) containing input parameters in mem-
ory and registers respectively, and OU TM (L) and OU TR(L)
containing output parameters. The need for this distinction
between memory and registers will become apparent in §7.
The algorithm takes O(m) steps, with m the execution trace
size.
6.3 Example
In order to facilitate understanding of the previous deﬁ-
nitions, we present here a simple artiﬁcial example. Fig. 6
presents an assembly language implementation of the one-
time pad cipher [25], that is the application of a bitwise
XOR operation between an input text and a key of the same
length. We assembled this code into a program P that
uses it with an 8-byte key 0xDEADBEEFDEADBEEF, in order
to decrypt the 8-byte text 0xCAFEBABECAFEBABE. To iden-
tify the cryptographic function in P with the approach pre-
sented in this paper, we would need to collect the two in-
put values along with the associated output result, namely
I1I2X...    I4     ...HistoryTrace; Prologue LEA EAX,[KEY]            LEA EBX,[ENCRYPTEDTEXT]  PUSH SIZETODECRYPT       MOV ECX, 0               ; counter; Core treatmentLOOP:     MOV EDX,[EAX+ECX]   ; read 4 bytes from the key     XOR [EBX+ECX], EDX  ; apply XOR operation     ADD ECX,4           ; increment counter     CMP ECX,[ESP]       ; is it finished ?     JNZ LOOP; EpilogueADD ESP,4                ; rewind the stackRETN1730x1453045114530451. Therefore we gathered the execution
trace of P with our tracer engine and applied the previous
deﬁnitions on it. One loop instance was detected, whose in-
structions are presented in Table 1. Loop parameters were
extracted by the previously described algorithm and we rep-
resent them in a parameter graph shown in Fig. 7.
Figure 7: Parameter graph for P. Orange nodes are
input-parameters, whereas blue ones are output pa-
rameters. Their values are noted under the line.
Cryptographic parameters have been successfully retrieved:
402000:8 and 402008:8 as inputs, and 402000:8 as output.
On the other hand, we also collected parameters with values
linked to this particular implementation: (i) eax:4, ebx:4,
esp:4 containing memory addresses, (ii) ecx:4, containing a
counter value, (iii) 12FFC0:4, corresponding to a local vari-
able initialized before the loop (SIZETODECRYPT), and (iv)
edx:4, an intermediate storage. This will be taken into con-
sideration in §8 for the comparison phase.
7. LOOP DATA FLOW
Until now we considered that each possible cryptographic
implementation contains a single loop. Nevertheless, crypto-
graphic functions can actually be composed of several non-
nested loops, such as RC4 [34]. Consequently, the loop ab-
straction alone is not enough to capture them completely.
In order to tackle this, we used data ﬂow to group loop in-
stances participating in the same cryptographic implemen-
tation. In this section we will describe the data ﬂow con-
struction algorithm leading to our ﬁnal model and then we
will deﬁne the associated parameters.
7.1 Loop Data Flow Construction
We deﬁne the data ﬂow between loop instances in a simi-
lar way to def-use chains [3]: two loop instances L1 and L2
are connected if L1 produces an output parameter used by
L2 as an input parameter. For the sake of simplicity, we con-
sider only memory parameters, because register parameters
would require a precise taint tracking inside sequential code
between loop instances. Indeed, our assumption is that all
treatments on inputs and outputs in memory are processed
through loops.
Suppose that {L1, . . . ,Ln} is the set of loop instances
extracted from T ∈ T RACE. We deﬁne a binary rela-
tion  between loop instances such that ∀(i, j) ∈ [1, n]2,
Li Lj if (i) Li started before Lj in T , and (ii) OU TM (Li)∩
INM (Lj) (cid:54)= ∅. Next, we deﬁne the loop data ﬂow graph G
as ({L1, . . . ,Ln}, ). G is an acyclic graph, which may have
several connected components G1, . . . ,Gm, each of them with
possibly several roots and leafs. For a connected component
Gk we denote, respectively, by ROOT [Gk] and LEAF [Gk]
the sets of root and leaf loop instances.
Each of these connected components represents an ab-
straction that is akin to functions in common binary pro-
grams. Thus, each Gk is a candidate cryptographic function
implementation that will then be tested against known im-
plementations. A standard graph algorithm is used to re-
construct the loop data ﬂow graph, by testing the binary
relation  for each pair of detected loops Li and Lj, and to
detect its connected components. In the remainder of this
paper, the connected components of a loop data ﬂow graph
will simply be called loop data ﬂows.
In the case of composition between diﬀerent cryptographic
functions, that is, a function output used as input for an-
other function, they will be grouped into the same loop data
ﬂow. A solution to this is to consider every possible sub-
graph in the loop data ﬂow graph. For example, suppose
that G is the loop data ﬂow graph ({L1,L2,L3}, ), such
that L1  L2 and L2  L3, then we test during the compar-
ison phase not only the connected component {L1,L2,L3},
but also {L1,L2}, {L2,L3}, and ﬁnally each loop instance
alone. Thus, we will be able to identify cryptographic func-
tions used in combination with others.
7.2 Loop Data Flow Input-Output Parameters
Loop data ﬂows constitute our model for cryptographic
implementations and our ﬁnal objective is the extraction of
cryptographic parameters. We deﬁne loop data ﬂow param-
eters as memory loop instance parameters not used in the
internal data ﬂow, i.e. in loop instance grouping. Regarding
register parameters, we take input registers of the root loop
instances and output registers of the leaf ones, for the sake
of simplicity.
Definition 3. Let Gk = ({L1, . . . ,Ln}, ) be a loop data
ﬂow. Its input parameters INGk are deﬁned as
OU TM (Lj)
INR(Lr)
1≤i≤n
(cid:91)
(cid:91)
(cid:16)
INM (Li) − (cid:91)
(cid:16)
OU TM (Li) − (cid:91)
Lj Li
(cid:17)
(cid:91)
(cid:17) (cid:91)
Lr∈ROOT [Gk]
and its output parameters OU TGk are deﬁned as
1≤i≤n
LiLj
Ll∈LEAF [Gk]
INM (Lj)
OU TR(Ll)
The values of these parameters have been collected dur-
ing loop instance parameter extraction. Thus, we now have
a model to extract possible cryptographic implementations
from execution traces and collect their parameters. We can
now identify cryptographic functions.
8. COMPARISON PHASE
The ﬁnal step for our identiﬁcation technique is the com-
parison of loop data ﬂows with cryptographic reference im-
plementations. We consider two diﬀerent kinds of inputs: