Of particular interest here is that Anagram is shown to be robust against existing 
mimicry attack approaches. We demonstrate Anagram’s ability to counter the simple 
mimicry attacks  levied against PAYL. Furthermore,  Anagram is designed to defeat 
training and  mimicry attacks  by using randomized  n-gram  modeling. The approach 
presented raises the bar against the enemy, making it far more difficult to design an n-
gram attack against Anagram. By randomizing the portion of packets that Anagram 
extracts  and  models,  mimicry  attackers  cannot  easily  guess  how  and  where  to  pad 
malicious  content  to  avoid  detection.  We  also  describe  the  use  of  a  feedback  loop 
between  the  Anagram  sensor  and  host-based  detectors,  thereby  updating  Anagram 
models over time and improving its detection performance. Thus, the combination of 
model randomization and a feedback loop makes it more difficult to evade detection 
by training and mimicry attacks. The contributions of this paper include: 
•  A  new  statistical,  language-independent,  efficient  content-based  anomaly 
detector  based  upon  semi-supervised  training  of  higher-order  n-gram 
analysis that is shown to be resistant against existing mimicry attacks. The 
sensor does not rely upon a specification or semantic analysis of the target 
applications; 
•  Robustness  against  future  mimicry  attacks  by  the  use  of  a  novel,  low-
overhead randomized testing strategy, making it difficult for the attacker to 
guess where or how to pad content; 
•  Development of a run-time measure of the “stability” of a network’s content 
flow,  providing  a  reasonable  estimate  of  when  the  sensor  has  been  well 
enough trained and is ready for deployment.  
•  A robust means of representing content-based alerts for cross-site alert shar-
ing  and  robust  signature  generation  using  a  Bloom  Filter  representation  of 
anomalous byte sequences2;  
•  A  new  defensive  strategy  showing  how  a  symbiotic  relationship  between 
host-based  sensors  and  a  content-based  sensor  can  adapt  over  time  to  im-
prove accuracy of modeling a site’s content flow. 
2  The representation also permits patch generation systems to share anomalous data for local 
patch generation across an “application community” [13, 14]. 
                                                                     Anagram: A Content Anomaly Detector         229 
The rest of the paper is organized as follows.  Section 2 details the Anagram sen-
sor and its relevant algorithms. Performance, detection rate, and false positive char-
acteristics are presented testing Anagram against real network traffic traces infected 
with a collection of worms and viruses. Section 3 describes Anagram’s robustness 
against  the  cleverly  crafted  blended  polymorphic  worm  reported  in  [1],  previews 
the possibility of new customized mimicry attacks being crafted against Anagram, 
and describes randomization techniques for defeating such attacks. In section 4 we 
present the concept of coupling a “shadow server” with Anagram and discuss how 
the  combination  can  effectively  support  the  techniques  presented  in  section  3,  as 
well  as  support  robust  signature  generation  and  patch  generation.  Section  5  dis-
cusses related work, while section 6 concludes the paper with a call for collabora-
tion among researchers at distributed sites. 
2   Anagram – Modeling a Mixture of N-Grams  
Anagram’s  approach  to  network  payload  anomaly  detection  uses  a  mixture  of 
higher  order  n-grams  (n>1)  to  model  and  test  network  traffic  content.  N-gram 
analysis  is  a  well-known  technique  has  been  used  in  a  variety  of  tasks,  such  as 
system call monitoring [15-17]. In Anagram, the n-grams are generated by sliding 
windows  of  arbitrary  lengths  over  a  stream  of  bytes,  which  can  be  per  network 
packet, per request session, or other type of data unit.  
In our previous work on network payload anomaly detection, PAYL [10, 11], we 
modeled the length-conditioned 1-gram frequency distribution of packet payloads, 
and tested new packets by computing the Mahalanobis distance of the test packet 
against the  model. This approach is effective at capturing attacks that display ab-
normal byte distributions, but it is likely to miss well-crafted attacks that focus on 
simple CPU instructions and that are crafted to resemble normal byte distributions. 
For instance, although a standard CodeRed II’s buffer overflow exploit uses a large 
number of “N” or “X” characters and so appears as a peak in the frequency distri-
bution, [18] shows that the buffer can instead be padded with  nearly any random 
byte sequence without affecting the attack vector. Another example is the following 
simple phpBB forum attack:  
GET /modules/Forums/admin/admin_styles.php?phpbb_root_path=h
ttp://81.174.26.111/cmd.gif?&cmd=cd%20/tmp;wget%20216.15.209
.4/criman;chmod%20744%20criman;./criman;echo%20YYY;echo|..HT
TP/1.1.Host:.128.59.16.26.User-Agent:.Mozilla/4.0.(compatibl
e;.MSIE.6.0;.Windows.NT.5.1;).. 
In such situations, the abnormal byte distribution model is insufficient by itself 
to identify these attack vectors as abnormal data. However, invariants remain in the 
packet payloads: the exploit code, the sequence of commands, or the special URL 
that should not appear in the normal content flow to the target application [19, 20]. 
By modeling higher order n-grams, Anagram captures the order dependence of byte 
sequences in the network payload, enabling it to capture more subtle attacks. The 
core hypothesis is that any new, zero-day exploit will contain a portion of data that 
has  never  before  been  delivered  to  the  application.  These  subsequences  of  new, 
230 
K. Wang, J.J. Parekh, and S.J. Stolfo 
distinct byte values will manifest as anomalous” n-grams that Anagram is designed 
to efficiently and rapidly detect.3  
In the following sections we will give a detailed description of Anagram, which 
outperforms PAYL in the following respects: 
•  Accuracy in detecting anomalous payloads, even carefully crafted ‘mimicry 
attacks’ with a demonstrably lower false positive rate; 
•  Computational  efficiency  in  detection  by  the  use  of  fast  (and  incremental, 
linear-time) hashing in its Bloom filter implementation; 
•  Model  space  efficiency  since  PAYL's  multiple-centroid  modeling  is  no 
• 
• 
longer necessary, and Bloom filters are compact; 
Fast correlation of multiple alerts while preserving privacy as collaborating 
sites exchange Bloom filter representations of common anomalous payloads; 
The generation of robust signatures via cross-site correlation for early warn-
ing and detection of new zero day attacks. 
In the following sections, we will describe the mechanisms in detail and present 
experimental  results  of  testing  Anagram  against  network  traces  sniffed  from  our 
local LAN.  
2.1   High Order N-Gram Payload Model 
While higher order n-grams contain more information about payloads, the feature 
space grows exponentially as n increases. Comparing an n-gram frequency distribu-
tion against a  model is infeasible since the training data is simply too sparse; the 
length of a packet is too small compared to the total feature space size of a higher-
order n-gram. One TCP packet may contain only a thousand or so n-grams, while 
the feature space size is 256n. Clearly, with increasing n, generating sufficient fre-
quency statistics to estimate the true empirical distribution accurately is simply not 
possible in a reasonable amount of time. 
In  Anagram,  we  therefore  do  not  model  the  frequency  distribution  of  each  n-
gram. Rather, we observe each distinct n-gram seen in the training data and record 
each  in  a  space  efficient  Bloom  filter.  Once  the  training  phase  terminates,  each 
packet is scored by measuring the number of n-grams it did not observe in the train-
ing  phase.  Hence,  a  packet  is  scored by  the  following  formula,  where  Nnew  is  the 
number of new n-grams not seen before and T is the total number of n-grams in the 
packet: Score = Nnew / T ∈ [0,1]. 
At  first  glance,  the  frequency-based  n-gram  distribution  may  contain  more  in-
formation about packet content; one might suspect it would model data more accu-
rately and perform better at detecting anomalous data, but since the training data is 
sparse, this alternative “binary-based model” performs significantly better than the 
frequency-based approach given the same amount of training data.  
3  Note  that  some  attacks  may  not  include  byte  sequences  that  are  “code-like”,  and  hence 
testing content for such code-like data subsequences is not guaranteed to cover all attack 
cases.  The  language  independence  of  anomalous  n-grams  may  be  broadly  applicable  to 
these and other attacks. 
                                                                     Anagram: A Content Anomaly Detector         231 
We  analyzed  the  network  traffic  for  the  Columbia  Computer  Science  website 
and, as expected, a small portion of the n-grams appear frequently while there is a 
long “tail” of n-grams that appear very infrequently. This can be seen in Table 1, 
which  displays  the  percentage  of  the  n-grams  by  their  frequency  counts  for  90 
hours of  CS  web traffic. Since a significant  number of  n-grams  have a small  fre-
quency count, and the number of n-grams in a packet is very small relative to the 
whole  feature  space,  the  frequency-distribution  model  incurs  relatively  high  false 
positives. Thus, the binary-based model (simply recording the distinct n-grams seen 
during training) provides a reasonable estimate of how “normal” a packet may be. 
This is a rather surprising observation; as we will demonstrate, it works very well in 
practice.  The conjecture is that true attacks will be delivered in packets that contain 
many  more  n-grams  not  observed  in  training  than  “normal”  packets  used  to  train 
the model. After all, a true zero-day attack must deliver data to a server application 
that has never been processed by that application before. Hence, the data exercising 
the vulnerability is very likely to be an n-gram of some size never before observed. 
By  modeling a  mixture of n-grams,  we increase the likelihood of observing these 
anomalous grams.  
To validate this conjecture, we compare the ROC curves of the frequency-based 
approach and the binary-based approach for the same datasets (representing equiva-
lent training times) as displayed in figure 1. We collected the web traffic of two CS 
departmental web servers, www and www1; the former serves the department web-
page,  while  the  latter  serves  personal  web  pages.  Traffic  was  collected  for  two 
different  time  periods:  a  period  of  sniffed  traffic  from  the  year  2004  and  another 
dataset  sniffed  in  2006.  The  2004  datasets4 (www-04  and  www1-04)  contain  160 
hours of traffic; the 2006 datasets (www-06 and www1-06) contain about 560 hours. 
We tested for the detection of several real worms and viruses: CodeRed, CodeRed II, 
WebDAV, Mirela, a php forum attack, and a worm that exploits the IIS Windows media 
service, the nsiislog.dll buffer overflow vulnerability (MS03-022). These worm samples 
were collected from real traffic as they appeared in the wild, from both our own dataset 
and from a third-party. 
For the first experiment, we used 90 hours of www1-06 for training and 72 hours 
for testing. (Similar experiments on the other datasets display similar results, and 
we skip them here for brevity.) To make it easier for the reader to see the plots, the 
curves  are  plotted  for  the  cases  where  the  false  positive  rate  is  less  than  0.03%. 
Both the detection rate and false positive rate are calculated based on packets with 
payloads;  non-payload (e.g., control) packets  were ignored. Notice that the detec-
tion rate in figure 1 is based on per packet, instead of per attack. Some attacks have 
multiple packets; while fragmentation can result in a few packets appearing normal, 
we  can  still  guarantee  reliable  attack  detection  over  the  entire  set  of  packets.  For 
example,  for  the  IIS5  WebDAV  attack,  5-grams  detect  24  out  of  25  packets  as 
being  anomalous.  The  only  missed  packet  is  the  first  packet,  which  contains  the 
buffer overflow string “SEARCH /AAA……AA”; this is not the key exploit part of 
the attack. For further comparison, we list minimum false positive rates when de-
tecting all attack attempts (where an attack is detected if at least 80% of the packets 
are classified as anomalous) for both binary-based and frequency-based models in 
table 2. 
4  The 2004 dataset was used to train and test PAYL as reported in [11], and is used here 
for comparative evaluation.  
232 
K. Wang, J.J. Parekh, and S.J. Stolfo 
Table  1.  The  percentage  of  the  observed 
unique n-grams for different frequencies of 
occurrence for 90 hours of training traffic 
freq 
count 
>=5 
3-grams  5-grams  7-grams 
58.05% 
2 to 4   22.17% 
19.78% 
1 
39.13% 
28.22% 
32.65% 
32.53% 
28.48% 
38.99% 
100
95
90
85
80
s
t
e
k
c
a
p
l
l
a
f
o
)
%
(
e
t
a
R
n
o
i
t
c
e
t
e
D
75
70
0    
Freq-based, 5-gram
Binary-based, 5-gram
Freq-based, 3-gram
Binary-based, 3-gram
0.01 
0.02 
False Positive Rate (%)
0.03 
Fig. 1. ROC curves comparing the frequency-
based and binary-based n-gram approach 
Table  2.  The  false  positive  rate  (%)  of  the  two  approaches  using  different  n-grams  when 
achieving 100% detection rate, www1-06 train/test dataset 
8-gram 
0.41477 
0.00914 
4-gram 
0.18559 
0.01406 
7-gram 
0.30792 
0.00914 
6-gram 
0.13427 
0.00703 
5-gram 
0.08858 
0.00634 
3-gram 
30.40205 
0.02109 
Freq-based 
Binary-based 
The binary-based approach yields significantly better results than the frequency-
based approach. When a 100% detection rate is achieved for the packet traces ana-
lyzed, the false positive rate of the binary-based approach is at least one order of 
magnitude less than the frequency-based approach. The relatively high false posi-
tive rate of the frequency-based approach suggests much more training is needed to 
capture accurate statistical information to be competitive. In addition, the extremely 
high false positive rate of the 3-gram frequency-based approach is due to the fact 
that the 3-grams of the php attack all appear frequently enough to make it hard to 
distinguish them from normal content packets. On the other hand, the binary-based 
approach used in Anagram results in far better performance. The 0.01% false posi-
tives average to about 1 alert per hour for www1 and about 0.6 alerts per hour for 
www.  The  result  also  shows  that  5-grams  and  6-grams  give  the  best  result,  and 
we’ve found this to be true for others as well.  
As previously stated, Anagram may easily model a mixture of different n-grams 
simply by storing these in the same Bloom filter. However, for larger n-grams addi-
tional  training  may  be  required;  as  we  shall  describe  shortly,  our  modeling  ap-
proach allows us to estimate when the sensor has been sufficiently trained.  
2.2   Model Size and Bloom Filters 
As  previously  stated,  one  significant  issue  when  modeling  with  higher  order  n-
grams is memory overhead. By leveraging the binary-based approach, we can use 
more memory-efficient set-based data structures to represent the set of observed n-
grams. In particular, the Bloom filter (BF) [21] is a convenient tool to represent the 
binary model. Instead of using n bytes to represent the n-gram, or even 4 bytes for a 
                                                                     Anagram: A Content Anomaly Detector         233 
32-bit hash of the n-gram, the Bloom filter can represent a set entry with just a few 
bits, reducing memory requirements by an order of magnitude or more. 
A Bloom filter is essentially a bit array of m bits, where any individual bit i is set if 
the hash of an input value, mod m, is i. As with a hash table, a Bloom filter acts as a 
convenient one-way data structure that can contain many items, but generally is or-
ders-of-magnitude smaller. Operations on a Bloom filter are O(1), keeping computa-
tional overhead low. A Bloom filter contains no false negatives, but may contain false 
positives if collisions occur; the false positive rate can be optimized by changing the 
size of the bit array and by using multiple hash functions (and requiring all of them to 
be set for an item to be verified as present in the Bloom filter; in the rare case where 
one hash function collides between two elements, it’s highly unlikely a second or a 
third would also simultaneously collide). By using universal hash functions [22], we 
can minimize the probability of multiple collisions for n-grams in one packet (assum-
ing each n-gram is statistically independent); the Bloom filter is therefore safe to use 
and does not negatively affect detection accuracy.  
2.2.1   Memory Overhead 