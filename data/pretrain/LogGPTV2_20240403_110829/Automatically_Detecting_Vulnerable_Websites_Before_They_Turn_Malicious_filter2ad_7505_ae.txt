this transient period, the system fails to use features that
would be useful in classiﬁcation and so performance suf-
fers. This problem may be partially addressed by shrink-
ing the input block size from the data streams well as the
window for computing the static value to a smaller value
to reduce the transient. However such a strategy will still
be outperformed by the strategy which remembers past
features.
 0.8
 0.75
 0.7
 0.65
 0.6
 0.55
e
v
r
u
C
C
O
R
r
e
d
n
U
a
e
r
A
 0.5
 0
 5
 10
 15
 20
 25
 30
 35
 40
Block Number
Figure 14: AUC plot for the system over time us-
ing current and past dynamic features. The system
was run using both current and past top dynamic fea-
tures. ROC curves were generated for each block of ex-
amples that was processed and the corresponding AUC
value was computed.
For each input block in the experiments using past fea-
tures, we recorded the true positive and false positive
rates and used them to generate an ROC curve. We then
used the ROC curve to approximate the area under the
curve (AUC) which is a value that gives some intuitive
understanding of how well the classiﬁer performed on
that block. Figure 14 shows the AUC values for each
block in the experiment. The system performed rela-
tively poorly until a sufﬁcient number of blocks had been
processed at which point the performance increased to a
threshold value. We believe that the difﬁculty in achiev-
USENIX Association  
23rd USENIX Security Symposium  637
13
6 Limitations
The limits on the classiﬁcation performance of the sys-
tem can be attributed to the following few difﬁculties in
predicting if a site will become malicious.
Our system assumes the factors responsible for
whether or not a site will become compromised can be
summarized by its content and its trafﬁc statistics. This
assumption is sometimes violated, since for example
sites may be compromised and become malicious due
to weak administrator passwords being guessed or being
retrieved via social engineering. Other examples may in-
clude adversaries who host their own sites with malicious
intent. While it is often the case that such actors use sim-
ilar page templates due to their participation in afﬁliate
networks or out of convenience, such sites may introduce
examples where the factors for the site being malicious
are independent of its content.
In such situations, the
system will fail to perform well since the factors for site
becoming malicious are outside its domain of inputs.
The nature of adversaries who compromise sites may
also be perceived as a limitation on what our system
can do.
It has been observed that attack campaigns
are launched where adversaries appear to enumerate
and compromise sites containing a similar vulnerability.
While adversaries do attack many sites which contain a
particular vulnerability, it is generally not a reasonable
assumption that they will systematically attack all sites
containing this vulnerability both at the time of the cam-
paign and in the future. The impact of this behavior on
the system is that sites which contain similar content to
those which were compromised in the campaign will be
classiﬁed as becoming malicious in the future, when they
actually may not since attackers have chosen to ignore
them. While this does deteriorate the performance of the
system, we argue that this does not take away its useful-
ness since these misclassiﬁcations represent sites which
are still at considerable security risk and need attention.
The dynamic feature extraction system also presents
at least two main limitations. The ﬁrst is a correlation
of features that are selected as top features at any given
point in time. Tags often rise to the top of the list because
they are part of some page template which has come up
frequently. There may be multiple tags associated with a
particular page template which all rise at the same time,
and so a few of the top tags are redundant since they are
identifying the same thing. It would be desirable to mea-
sure the correlation of the top features in order to select
a more diverse and useful set however no attempt to do
this was made in our experiments.
ing better performance is due to the nature of the prob-
lem, speciﬁcally it is not always the case that the content
of a site and its trafﬁc statistics are a factor in whether or
not it will become compromised. We discuss this issue
in more details in the limitations section.
Finally, we observed that when classiﬁcation yielded
a prediction that a site would become compromised, the
reasoning can be read as the conjunction of conditions
from the decision tree.
For example the classiﬁca-
tion of www.bisoft.org which appeared in the
search redirection data set was described as (Global
Site Rank = 8) ∧ ( =
type=”text/javascript” src=”/static/js/analytics.js”> =
1). The classiﬁcation of benign examples was generally
less obvious.
∧
1)
The conditions resulting in incorrect classiﬁcation
tended to follow a few main types. The ﬁrst type are
instances where a website would in the future become
malicious, but very few examples like it exist at classi-
ﬁcation time. These sites contained content that would
eventually yield prominent features for identifying sites
that would become malicious but were not classiﬁed cor-
rectly due to latency in the dynamic feature extraction.
As an example, consider in Figure 12 the samples that
occurred just before the ﬁrst signiﬁcant spike.
The second type of instance that was incorrectly clas-
siﬁed were examples that did not become malicious, but
were classiﬁed as becoming so based on some strong
positive content features that they contained. It is likely
that after an initial attack campaign, vulnerable CMSs
are less targeted due to the incremental number of com-
promises that could be yielded from them.
The third type of instance that was incorrectly clas-
siﬁed were examples that would be become malicious
for seemingly no apparent reason. These examples
that would become malicious did not follow the general
trend of large spikes corresponding to attack campaigns
against a CMS, and have been observed with positive fea-
tures both before and after its initial spike as well as with
strong negative features. It is believed that these exam-
ples are cases where a site is becoming malicious for rea-
sons completely independent of its content or trafﬁc pro-
ﬁle. It could be the case that an attack is launched where
default login credentials for many CMSs are being at-
tempted resulting in a few seemingly random breaks. It
could also be the case that the domain in question was
sold or rebuilt after observing it causing the system to er-
roneously predict its future malicious status from its old
content.
Another limitation of the dynamic features is that for
system conﬁgurations which use past features in addition
to the current top features, the size of the feature set is
monotonically increasing. Thus, it will take longer over
time train the classiﬁers and run the system. It would be
638  23rd USENIX Security Symposium 
USENIX Association
14
useful to further investigate the trade-offs between clas-
siﬁcation performance and limited feature lists.
Last, dynamic features introduce a unique opportunity
for adversarial machine learning approach to poison the
performance of the system. Adversaries which control
a website may attempt to remove, change, or insert tags
into their pages in order to damage the effectiveness of
feature generation. For example, adversaries that host or
control sites that have distinguishing tags may either try
to remove them or rewrite them in semantically equiv-
alent ways to prevent the system from using them for
classiﬁcation. Since the sites examined by the system are
typically not under adversarial control at the time of eval-
uation, we believe that the impact of such attacks should
be minimal; but it deserves further analysis.
7 Conclusions
We discussed a general approach for predicting a web-
sites propensity to become malicious in the future. We
described a set of desirable properties for any solution
to this problem which are interpretability, efﬁciency, ro-
bustness to missing data, training errors, and class im-
balance, as well as the ability to adapt to time chang-
ing concepts. We then introduced and adapted a num-
ber of techniques from the data mining and machine
learning communities to help solve this problem, and
demonstrated our solution using an implementation of
these techniques. Our implementation illustrates that
even with a modest dataset, decent performance can be
achieved since we are able to operate with 66% true pos-
itives and only 17% false positives at a one-year horizon.
We are currently working on making our software pub-
licly available.
Acknowledgments
We thank our anonymous reviewers for feedback on an
earlier revision of this manuscript, Brewster Kahle and
the Internet Archive for their support and encourage-
ment, and Jonathan Spring at CERT/SEI for providing us
with historical blacklist data. This research was partially
supported by the National Science Foundation under ITR
award CCF-0424422 (TRUST) and SaTC award CNS-
1223762; and by the Department of Homeland Security
Science and Technology Directorate, Cyber Security Di-
vision (DHS S&T/CSD), the Government of Australia
and SPAWAR Systems Center Paciﬁc via contract num-
ber N66001-13-C-0131. This paper represents the po-
sition of the authors and not that of the aforementioned
agencies.
References
[1] Alexa Web Information Service. http://aws.
amazon.com/awis/.
[2] DNS-BH: Malware domain blocklist. http://
www.malwaredomains.com/.
[3] Norton safe web. http://safeweb.norton.
com.
[4] Scrapy: An open source web scraping framework
for Python. http://scrapy.org.
[5] Stop badware: A nonproﬁt organization that makes
the Web safer through the prevention, remediation
and mitigation of badware websites. https://
www.stopbadware.org/.
[6] M. Bailey, J. Oberheide, J. Andersen, Z. Mao,
F. Jahanian, and J. Nazario. Automated classiﬁ-
cation and analysis of internet malware.
In Proc.
RAID’07, pages 178–197, Gold Coast, Australia,
2007.
[7] U. Bayer, P. Comparetti, C. Hlauschek, C. Kruegel,
and E. Kirda. Scalable, behavior-based malware
clustering.
In Proc. NDSS’09, San Diego, CA,
February 2009.
[8] K. Borgolte, C. Kruegel, and G. Vigna. Delta: au-
tomatic identiﬁcation of unknown web-based infec-
tion campaigns. In Proc. ACM CCS’13, pages 109–
120, Berlin, Germany, November 2013.
[9] L. Breslau, P. Cao, L. Fan, G. Philips, and
S. Shenker. Web caching and Zipf-like distribu-
tions: Evidence and implications.
In Proc. IEEE
INFOCOM’99, pages 126–134, New York, NY,
March 1999.
[10] D. Chakrabarti, R. Kumar, and K. Punera. Page-
level template detection via isotonic smoothing. In
Proc. WWW’07, pages 61–70, Banff, Canada, May
2007.
[11] S. Debnath, P. Mitra, N. Pal, and C.L. Giles. Auto-
matic identiﬁcation of informative sections of web
pages. IEEE Transactions on Knowledge and Data
Engineering, 17(9):1233–1246, 2005.
[12] G. Forman. An extensive empirical study of feature
selection metrics for text classiﬁcation. The Journal
of machine learning research, 3:1289–1305, 2003.
[13] J. Gao, W. Fan, J. Han, and P. Yu. A general frame-
work for mining concept-drifting data streams with
skewed distributions.
In Proc. SIAM SDM’07,
pages 3–14, Mineapolis, MN, April 2007.
[14] Google.
Google
Safe Browsing API.
https://code.google.com/apis/
safebrowsing/.
USENIX Association  
23rd USENIX Security Symposium  639
15
[15] L.
Invernizzi, P. Comparetti, S. Benvenuti,
C. Kruegel, M. Cova, and G. Vigna. Evilseed: A
guided approach to ﬁnding malicious web pages.
In Proc. 2012 IEEE Symp. Sec. & Privacy, pages
428–442, San Francisco, CA, May 2012.
[16] J. Jang, D. Brumley, and S. Venkataraman. Bit-
shred: Feature hashing malware for scalable triage
and semantic analysis.
In Proc. ACM CCS’11,
Chicago, IL, October 2011.
[17] J. John, F. Yu, Y. Xie, M. Abadi, and A. Krishna-
murthy. deSEO: Combating search-result poison-
ing. In Proc. USENIX Security’11, San Francisco,
CA, August 2011.
[18] L. Lancor and R. Workman. Using Google hack-
ing to enhance defense strategies. ACM SIGCSE
Bulletin, 39(1):491–495, 2007.
[19] N. Leontiadis, T. Moore, and N. Christin. A nearly
four-year longitudinal study of search-engine poi-
soning. Tech. Rep. CyLab-14-008, Carnegie Mel-
lon University. July 2014.
[20] N. Leontiadis, T. Moore, and N. Christin. Mea-
suring and analyzing search-redirection attacks in
the illicit online prescription drug trade.
In Proc.
USENIX Security’11, San Francisco, CA, August
2011.
[21] K. Levchenko, N. Chachra, B. Enright, M. Fel-
egyhazi, C. Grier, T. Halvorson, C. Kanich,
C. Kreibich, H. Liu, D. McCoy, A. Pitsillidis,
N. Weaver, V. Paxson, G. Voelker, and S. Savage.
Click trajectories: End-to-end analysis of the spam
value chain. In Proc. 2011 IEEE Symp. Sec. & Pri-
vacy, Oakland, CA, May 2011.
paradigms - NSPW ’00, pages 15–21, New York,
New York, USA, 2000.
[27] J. Mirkovic, S. Dietrich, D. Dittrich, and P. Rei-
her. Internet Denial of Service: Attack and Defense
Mechanisms. Prentice Hall PTR, 2004.
[28] PhishTank.
com/.
https://www.phishtank.
[29] N. Provos, P. Mavrommatis, M. Rajab, and F. Mon-
rose. All your iFrames point to us.
In Proc.
USENIX Security’08, San Jose, CA, August 2008.
[30] Foster Provost and Tom Fawcett. Robust classiﬁca-
tion for imprecise environments. Machine Learn-
ing, 42(3):203–231, 2001.
[31] J. R. Quinlan. C4. 5: programs for machine learn-
ing, volume 1. Morgan Kaufmann, 1993.
[32] Ruihua Song, Haifeng Liu, Ji-Rong Wen, and Wei-
Ying Ma. Learning block importance models for
web pages.
In Proc. WWW’04, pages 203–211,
New York, NY, May 2004.
[33] Sophos.
Security
threat
2013,
http://www.sophos.com/
report
2013.
en-us/medialibrary/PDFs/other/
sophossecuritythreatreport2013.
pdf.
[34] The Internet Archive. Wayback machine. https:
//archive.org/web/.
[35] M. Vasek and T. Moore.
Identifying Risk Fac-
In Proc. Finan-
tors for Webserver Compromise.
cial Crypto.’14, Accra Beach, Barbados, February
2014.
[22] L. Lu, R. Perdisci, and W. Lee. SURF: Detect-
ing and measuring search poisoning. In Proc. ACM
CCS 2011, Chicago, IL, October 2011.
[36] D. Wang, G. Voelker, and S. Savage.
longitudinal study of an SEO botnet.
NDSS’13, San Diego, CA, February 2013.
Juice: A
In Proc.
[23] MalwareBytes. hphosts online. http://www.
hosts-file.net/.
[24] McAfee.
Site Advisor.
siteadvisor.com/.
http://www.
[25] D. McCoy, A. Pitsillidis, G. Jordan, N. Weaver,
C. Kreibich, B. Krebs, G. Voelker, S. Savage,
and K. Levchenko. Pharmaleaks: Understanding
the business of online pharmaceutical afﬁliate pro-
grams.
In Proc. USENIX Security’12, Bellevue,
WA, August 2012.
[26] J. P. McDermott. Attack net penetration testing. In
Proceedings of the 2000 workshop on New security
[37] G. Widmer and M. Kubat. Learning in the pres-
ence of concept drift and hidden contexts. Machine
learning, 01:69–101, 1996.
[38] L. Yi, B. Liu, and X. Li. Eliminating noisy infor-
mation in web pages for data mining. In Proc. ACM
KDD’03, pages 296–305, Washington, DC, August
2003.
[39] Y. Zhai and B. Liu. Web data extraction based on
In Proc. WWW’05, pages
partial tree alignment.
76–85, Chiba, Japan, May 2005.
640  23rd USENIX Security Symposium 
USENIX Association
16