### Transient Period and System Performance

During the transient period, the system fails to utilize features that would be beneficial for classification, leading to a decline in performance. This issue can be partially mitigated by reducing the input block size from the data streams and the window for computing the static value. However, such a strategy is still outperformed by one that retains past features.

### AUC Plot Analysis

**Figure 14: AUC Plot for the System Over Time Using Current and Past Dynamic Features**

- **Description**: The system was run using both current and past top dynamic features. For each block of examples processed, ROC curves were generated, and the corresponding AUC values were computed.
- **Methodology**: For each input block, we recorded the true positive and false positive rates to generate an ROC curve. The AUC value, which provides an intuitive understanding of the classifier's performance, was then approximated from the ROC curve.
- **Observations**: The system initially performed poorly until a sufficient number of blocks had been processed. After this point, performance increased to a threshold value. We attribute the initial difficulty to the nature of the problem, where content and traffic statistics are not always indicative of whether a site will become compromised.

### Limitations

The limitations on the classification performance of the system can be attributed to several factors:

1. **Assumption Violation**:
   - The system assumes that the factors responsible for a site becoming compromised can be summarized by its content and traffic statistics. This assumption is sometimes violated, as sites may be compromised due to weak administrator passwords or social engineering.
   - Adversaries may also host their own malicious sites, which may not follow the same content and traffic patterns.

2. **Adversary Behavior**:
   - Attack campaigns often target sites with similar vulnerabilities, but it is not reasonable to assume that all sites with a particular vulnerability will be systematically attacked. This leads to misclassifications where sites with similar content to those compromised in a campaign are incorrectly predicted to become malicious.

3. **Feature Correlation**:
   - The dynamic feature extraction system often selects top features that are correlated, such as tags from frequently used page templates. This results in redundant features, and a more diverse and useful set of features could improve performance.

4. **System Latency**:
   - The dynamic feature extraction process has latency, leading to incorrect classifications for sites that will become malicious but have few similar examples at the time of classification.
   - Sites that do not become malicious may be incorrectly classified as becoming so based on strong positive content features.
   - Some sites may become malicious for reasons independent of their content or traffic profile, such as default login credentials being guessed.

5. **Increasing Feature Set Size**:
   - For configurations that use past features in addition to current top features, the feature set size increases over time, leading to longer training and runtime. Further investigation into the trade-offs between classification performance and limited feature lists is needed.

6. **Adversarial Machine Learning**:
   - Adversaries may attempt to poison the system by removing, changing, or inserting tags to damage the effectiveness of feature generation. While the impact of such attacks is believed to be minimal, further analysis is required.

### Conclusions

We presented a general approach for predicting a website's propensity to become malicious in the future. Our solution, which includes techniques from data mining and machine learning, demonstrates decent performance with 66% true positives and only 17% false positives at a one-year horizon. Future work will focus on making our software publicly available and addressing the identified limitations.

### Acknowledgments

We thank our anonymous reviewers, Brewster Kahle and the Internet Archive, Jonathan Spring at CERT/SEI, and the National Science Foundation for their support and contributions.

### References

[References listed here, formatted as per the original document]

---

This revised version aims to provide a clearer, more coherent, and professional presentation of the information.