(cid:2)
Lemma 5. After GST, there exists a bounded time period T
such that if all correct replicas remain in view v during T and
the leader for view v is correct, then a valid pre-prepareQC
can be formed.
Proof. In view change, the leader lv collects n − f VIEW-
CHANGE messages and calculates its highQCv to propose a
new block. By Lemma 4, one of the three cases must apply.
Suppose among all correct replicas, the lockedQC with the
(cid:2) denote the parent
highest rank is a prepareQC qc for b. Let b
block of b, vb denote b.view. We distinguish two cases:
1) If b
(cid:2) for b. Thus, Mv contains at
.view  vb or
(qch.view = vb and type(qch) = PREPARE). Either way, by
Lemma 1, rank(qch) ≥ rank(qc). Then the block(s) proposed
by lv in view v will be voted by all correct replicas for
pre-prepareQC, because Case R1 is satisﬁed.
(cid:2) for
(cid:2)
2) If b
(cid:2). At least f + 1 correct replicas have set their highQC to
b
(cid:2). Thus, Mv contains at least one VIEW-CHANGE message
qc
from these replicas. The rank of QC(s) in highQCv is no
(cid:2)
). If the rank of QC(s) in highQCv is equal
less than rank(qc
(cid:2). In this
to rank(qc
case, lv proposes two blocks, one normal block b1 with height
(cid:2)
.height + 2.
b
At least b2 can be voted by all correct replicas to form a
pre-prepareQC qcv, since Case R1 or R2 is satisﬁed. If the
(cid:2) is received by lv, lv updates its highQC
prepareQC vc for b
to (qcv, vc) and qcv is a valid pre-prepareQC. Otherwise a
valid pre-prepareQC for b1 can be formed.
.height + 1 and a virtual block b2 with height b
), then due to Lemma 2, highQCv is qc
(cid:2)
(cid:2)
If the rank of QC(s) in highQCv is higher than rank(qc
),
we know the rank of QC(s) in highQCv is no less than
rank(qc). The block(s) proposed by lv will be voted by all
correct replicas for pre-prepareQC, as Case R1 is satisﬁed.(cid:3)
Theorem 2. (Liveness) After GST, there exists a bounded time
period Tf such that if all correct replicas remain in view v
during Tf and the leader for view v is correct, then an decision
can be reached.
Proof. By Lemma 5, a valid pre-prepareQC qc can be formed
in the new view if the leader is correct. Then the block of qc
can be accepted by all correct replicas in the prepare phase
since the rank of qc is higher than the lockedQC for any
(cid:2)
correct replicas. Replicas can then resume the normal case
(cid:4)
operation and a decision can be reached.
VI. IMPLEMENTATION AND EVALUATION
Overview. We implement Marlin and HotStuff in Go using
around 7,000 LOC, including 1,500 LOC for evaluation. We
implement the chaining (pipelining) mode for both Marlin
and HotStuff. We deploy the protocols in a cluster with 40
servers. Each server has a 16-core 2.3GHz CPU, 128 GB
RAM, 1000 MB NIC. We use f to represent the network size,
where we use 3f +1 replicas in each experiment. The network
bandwidth is 200 Mbps. We injected 40ms network latency for
all experiments carried. Except for the experiment for no-op
requests (containing digital signatures but no operations), all
transactions and reply messages are of size 150 bytes. We
use LevelDB as the underlying database. The frequency of
garbage collection (checkpointing) is set to every 5000 blocks.
We use ECDSA as the underlying signature. Our main ﬁnding
is unlike other HotStuff variants that are at least sometimes
less efﬁcient than HotStuff (as reported in [30, 31]), Marlin
consistently outperforms HotStuff.
Throughput vs. latency. We ﬁrst assess the throughput vs.
latency of the in failure-free scenarios for both Marlin and
HotStuff. We report throughput vs. latency for f = 1 to
f = 30 in Figure 10a-10f. As shown in the ﬁgures, by
reducing the number of phases of HotStuff from three to two,
the throughput of Marlin is 4.47%-34.4% higher than that of
HotStuff. In particular, when f = 1, Marlin achieves peak
throughput of 101 ktx/sec, 27.2% higher than that of HotStuff.
Note that our implementation appears to have lower perfor-
mance than those in prior works [2, 30, 31, 52]. This reason
is that our implementation writes data into the database rather
than into memory and we run checkpointing in the backend.
Thus, our experiments are more realistic than prior ones.
Scalability. We report the peak throughput of Marlin and
HotStuff for f = 1 to f = 10 in Figure 10g. The peak
throughput of Marlin is 11.56%-34.4% higher than that of
HotStuff. When f grows, the throughput of Marlin degrades
in a way much like HotStuff. In our case, when f is greater
than 5, the performance downgrades signiﬁcantly. However,
even when f = 10, the throughput of Marlin can still be as
large as 23.82 ktx/s.
We also conduct the same experiments for no-op requests.
Due to space limitation, we only report the performance for
f = 1, f = 2, and f = 5 in Figure 10h. The performance
of these no-op experiments for both Marlin and HotStuff is
consistently higher than the one for experiments with larger
requests and replies (150 bytes). For instance, when f = 1, the
peak throughput for no-op requests is 16.7% higher than that
with the large request size. When f increases, the performance
does not downgrade as much as that for large request sizes. For
instance, when f = 5, the peak throughput of Marlin is still
101 ktx/s, almost twice higher than the experiment using 150-
byte requests. In other words, the protocols are more scalable
for smaller requests and replies.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:24:47 UTC from IEEE Xplore.  Restrictions apply. 
63
HotStuff
Marlin
1,000
800
600
400
200
)
s
m
(
y
c
n
e
t
a
L
)
s
m
(
y
c
n
e
t
a
L
1,000
800
600
400
200
0
0
100
HotStuff
Marlin
20
40
60
80
)
s
m
(
y
c
n
e
t
a
L
1,000
800
600
400
200
0
0
HotStuff
Marlin
10
20
30
0
0
20
60
40
80
Throughput (ktx/sec)
(a) Throughput vs. Latency (f = 1).
1,000
)
s
m
(
y
c
n
e
t
a
L
800
600
400
200
0
0
HotStuff
Marlin
5
10
15
20
25
Throughput (ktx/sec)
(b) Throughput vs. Latency (f = 2).
1,000
HotStuff
Marlin
Throughput (ktx/sec)
(c) Throughput vs. Latency (f = 5).
1,000
HotStuff
Marlin
)
s
m
(
y
c
n
e
t
a
L
800
600
400
200
0
0
5
10
15
20
)
s
m
(
y
c
n
e
t
a
L
800
600
400
200
0
0
5
10
15
20
(d) Throughput vs. Latency (f = 10).
Throughput (ktx/sec)
(e) Throughput vs. Latency (f = 20).
Throughput (ktx/sec)
(f) Throughput vs. Latency (f = 30).
Throughput (ktx/sec)
101.27
100
89.82
79.58
78.49
66.83
62.61
59.91
Marlin
HotStuff
45.6
44.36
39.16
36.83
30.29
33.82
28.78
28.83
25.35
26.25
23.84
23.15
20.3
)
c
e
s
/
x
t
k
(
t
u
p
h
g
u
o
r
h
t
k
a