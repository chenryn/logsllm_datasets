whose faces will become known in the future.
A. Related Work in Face Recognition
Different aspects of face recognition have been addressed
in numerous papers. Here we focus on the robustness of the
representation, and on protection of the biometric data.
Robust Face Representations: An ideal face represen-
tation should be robust to illumination changes, occlusions,
and other variations of the image. In particular, illumination
variations are known to greatly inﬂuence the appearance
of human faces. Adini et al. [9] have shown that images
of different faces under similar illumination vary less than
the same face under different illumination. This is a great
obstacle to any face identiﬁcation system that must work in
real-life conditions.
Most existing systems for robust face cognition use Real-
valued representations of faces, and therefore cannot be
used as is in secure computation. Straightforward attempts
to quantize the values of the representations result in poor
recognition results. A previous design of a privacy preserv-
ing face identiﬁcation system was based on the Eigenfaces
algorithm (see discussion in Section I-B). The Eigenfaces
241
algorithm is a well known basic face recognition algo-
rithm [10]. However, its recognition performance is poor
if the training and suspect images were taken in different
conditions (see our experiments in Section VI).
Protection of Biometric Data: It is known that different
readings of the same biometric data of the same person are
usually similar, but not necessarily identical. Therefore the
biometric representations used in recognition are designed
to produce the same results for similar inputs. An easy
way to do that is to store a copy of the original biometric
data and compare it to the reading of the user’s data. This,
however, enables attackers to steal this data. A more secure
approach would be to store a one-way hash of the biometric
data, as is used with password based authentication. In the
case of biometric data this approach requires the usage of
noise resistant one-way hash functions, referred to as fuzzy
hashing (or fuzzy commitments), or as secure sketches. Such
functions were described in [6], [7], [8].
Recent attempts in integrating these schemes in face
recognition [3] focus on the simpler, one-to-one, veriﬁcation
task. These methods are limited to controlled environments,
and use a large number of images of the subject for
registration. In SCiFI the biometric data is stored at the
server, which is assumed to be much more secure than users’
machines, and therefore we do not use these methods to
protect it.
Another approach for securing biometric data uses revo-
cable biometrics, see e.g. [11], [12]. It involves transforming
the biometric data using a one-way hash function such that
it is impossible to restore the original data from the result.
Different persons use different transformation functions and
therefore their images cannot be compared. If the stored
data is compromised, the person can simply re-enroll using
another transformation function.
Computer vision and privacy research: Recent work on
“blind vision” [13] investigates a setting which is different
than ours. In that setting one party wishes to detect faces in
a collection of sensitive images it owns, and the other party
has a conﬁdential face detection algorithm. The work shows
how to use cryptographic secure computation to privately
perform the recognition task.
There has also been a series of results on obscuring private
information in digital surveillance videos [14], [15], [16],
[17], [18]. The setting is one where the persons watching
the surveillance videos can detect suspected behavior with-
out being able to examine the faces of the subjects. The
challenge is to identify the private information and obscure
it in real-time, while being able to recover it if needed.
B. Related Work on Secure computation
The problem we discuss is that of secure computation
(or Secure Function Evaluation – SFE). It involves several
parties with private inputs that wish to compute a function
of their joint inputs, without revealing to an adversarial party
(or a coalition of such parties) any information that cannot
be computed using the input of the adversary and the output
of the function.
There exist well known solutions for secure computation
of any function (see e.g. [19] for the two party case,
or [20] for a detailed discussion of the subject). The general
method employed by most of these solutions is to construct
a binary circuit that computes the required function, and
run a distributed protocol that securely evaluates the circuit
gate by gate. The communication overhead of these generic
protocols is linear in the size of the circuit, and the com-
putation involves an oblivious transfer for each input bit. It
seems hard to apply these methods to compute continuous
functions or represent Real numbers, since the methods
inherently work over ﬁnite ﬁelds.
Secure computation of Eigenfaces: Secure computation
of a face recognition algorithm was previously applied to the
Eigenfaces algorithm. A secure protocol for computing this
algorithm was presented in [21], and a considerable improve-
ment in efﬁciency was shown in [22]. The secure protocol in
that work computes a quantized version of Eigenfaces. The
quantization did not affect the recognition performance so
much, but as we show in Section VI, the original Eigenfaces
algorithm is not very good in recognizing images taken in
unseen conditions.
The Eigenfaces algorithm is based on computing the
Euclidean distance, whose secure computation is more com-
plicated than that of the Hamming distance. It was unknown
before our work, how to translate the face recognition
problem to a computation of the Hamming distance, which
lends itself more efﬁciently to secure computation.
To exemplify the efﬁciency of SCiFI, we note that the
secure computation of Eigenfaces must send a homomorphic
encryption of every pixel of the image. The experiments
conducted in [21], [22] use images of 92 × 112 = 10304
pixels. (It is hard to imagine that smaller images could be
used for meaningful recognition.) This image size translates
to more than 10, 000 homomorphic encryptions, and any
increase in the image size (which is needed in order to
improve the quality of recognition) will result in an increase
in this number. In SCiFI, on the other hand, a face is always
represented by a vector of 900 bits, independently of the size
of the image. The system sends a homomorphic encryption
per each of these 900 bits. Moreover, this communication
can be done in a preprocessing phase, while the online
communication requires sending only a single 900 bit rep-
resentation of the face.
The papers discussing secure computation of Eigenfaces
provide timing results for the implementation of the secure
computation part alone (as well as an analysis of the
number of bytes that must be communicated). We report
on experiments which time also the communication layer,
including socket opening, etc.
242
II. SYSTEM ARCHITECTURE
The SCiFI system is composed of a server and a client.
The operation of the system can be separated into an ofﬂine
(or preprocessing) part, and an online part.
The structure of the SCiFI system is described in Table I.
The ofﬂine part prepares the face recognition database, by
computing representations of the faces that are in the server’s
list. This stage is also used to execute some initializations
and preprocessing of the cryptographic algorithms.
The online part is executed after the client obtains an
image. This part decides whether the image is of a person
who appears in the list, and can be separated into two distinct
stages. In the ﬁrst stage the client prepares a representation
of the face that it acquired. In the second stage the two
parties execute a cryptographic algorithm which compares
the client’s representation with those in the server’s list, and
decides whether there is a match between them (without
revealing any other information).
ofﬂine
online
server
prepare representations
of faces in server’s list
client
initialize cryptographic algorithms
- acquire face
- generate representation
s of the acquired face
run a secure protocol, checking if
there is a match between s and list
Table I: The operation of the system.
This modular structure of the system enables us to sepa-
rate the description of the system into a description of the
face recognition part, in Section III, and a description of the
cryptographic parties, in Section IV.
III. THE FACE RECOGNITION ALGORITHM
We assume that facial features have a number of typical
appearances and almost every face can be generated by
combining such components. Let X denote a set of people
enrolled in the recognition system. Assume that we have a
(possibly public) database Y of faces unrelated to X. While
this database is public, we want to protect the data in X. We
divide a face into p parts and build vocabularies of typical
appearances (that we call words) per part using Y . Let
V = {V1, . . . , Vp} denote the part vocabularies (where, for
example, in a simpliﬁed way, V1 might include 20 options
for the nose, V2 includes 20 options for the mouth, etc.).
Let I be an image of a person from X. We represent
I as a vector of indices, denoted s, of words from the
part vocabularies which are most similar to the parts in I.
Our goal is to produce almost identical vectors of indices
from different images of the same person. Different face
representation vectors can now be compared by computing
their set difference (the set difference of two sets A and B
is deﬁned as the difference between the size of their union
243
and the size of their intersection; if A = B then their set
difference is 0).
Previous research shows that locations of facial features
in a face have good discriminative power. Thus our rep-
resentation takes these locations into account as well, and
includes quantized distances from each part of the face to the
center of the face. (An exact description of the representation
appears in Section III-C.)
The proposed representation has a number of advantages:
(1) The model is tailored for computing the set difference
and the Hamming distance, which are discrete metrics that
can be used in secure computation. (2) The vocabularies
of parts are constructed from a set Y of people unrelated
to the set X of enrolled people, and therefore there is no
need to store the original data of the persons enrolled in
the system. (3) The representation also makes it possible to
use only a single image per person for recognition, which
is an important feature for practical systems (where, say,
only a single photo of a suspect
is available). (4) The
vocabularies are constructed from Y , and therefore they
stay ﬁxed whether X changes or not, and thus no retraining
is needed when a new subject is added to the system. (5)
The proposed model is more ﬂexible than the existing part-
based face representations, because each part in our model is
represented by an unordered set of appearances. The use of
set difference for comparison allows for partial similarity
between the representations of the same individual. This
contributes to the robustness against occlusions, shadows,
highlights, and other local changes in appearance. (6) The
proposed representation uses facial components which are
small patches, which allows to assume their planarity and
use illumination insensitive local descriptor of patches (e.g.,
SIFT [23]) in order to cope with varying illumination. To
summarize, the proposed representation is very robust to
environmental changes and is designed to be incorporated
with privacy preserving mechanisms. These features make
it an excellent choice for security applications.
Section organization: The following sections describe in
detail the construction of face representations. Readers who
are only interested in the security applications can jump to
Section III-C which describes the representation which is
used by the secure computation.
A. Preprocessing
Deﬁnition of Parts: We deﬁne a regular grid, corre-
sponding to the centers of the parts, over facial area with
higher variance, namely eyes, eyebrows, nose and mouth.
Patch sizes were chosen to be relatively small (20% of face
width) in order to have many patches with minimum overlap.
Part Vocabularies: The construction of part vocabu-
laries consists of three steps: (1) Normalization of images
of subjects in Y to a canonical size. (2) Extracting patches
from images of subjects in Y . Prior to extraction, patches
are localized, by searching a corresponding template from
an average face in images from Y . (3) Selection of words for
part vocabularies. In this step, patches corresponding to the
same part are clustered and only a single patch per cluster
is chosen to be a word in the part vocabulary. This aims to
remove similar words from the vocabularies.
At the end of the process p vocabularies of parts are
formed, one for every face part. Each vocabulary containing
N words, which are given unique indices in the range
[0, N − 1] to be used in the face representation.
Distance Vocabularies: The spatial information is mod-
elled by the distance from the center of a part to the center
of the face. During the preprocessing stage, we estimate the
distance distributions of the parts and quantize them into
a number of bins. Each bin is given a unique index. The
estimation is done on the subjects from the public set Y .
B. Input to the system
We assume that the input to the system is an image of
a face in which the the positions of the eyes and mouth
are known. The positions of the eyes and mouth can be
marked manually by an operator of the client’s module or
determined using automatic methods for detection of facial
features [24], [25]. These positions are used for alignment
purposes.
C. Face Representation
The representation of a face has the following form. We
denote by N the number of words in each part vocabulary,
and by p the number of parts in the face representation. A
full face representation is in the format s = (sa, ss) and
contains the following components:
1, . . . , sa
• Appearance component: sa is the appearance compo-
nent and is composed of p sets sa
p, one set per
facial part, where each set contains the indices of n
out of N words of the part vocabulary. To select a
set sa
i for the part i we deﬁne a window centered at
the corresponding grid point in the input image. Every
word from the part vocabulary is matched against the
deﬁned window. The indices of the n words that have
the most resemblance with the part i are selected for
the set sa
i .
• Spatial component: ss is the spatial component of the
representation. Since we want to use discrete values, the
representation uses quantized distances. The spatial part
is therefore composed of p sets ss
p, where each
set contains z indices of bins of quantized distance from
the center of the face (namely, the set ss
i is a quantized
representation of the distance of the ith part from the
center of the face). Denote the total number of these
bins by Q. The ith part of the input face is localized by
matching the same part from the average face against
the local window centered at the grid point.