title:Anomaly detection of web-based attacks
author:Christopher Kr&quot;ugel and
Giovanni Vigna
Anomaly Detection of Web-based Attacks
Christopher Kruegel
PI:EMAIL
Giovanni Vigna
PI:EMAIL
Reliable Software Group
University of California, Santa Barbara
Santa Barbara, CA 93106
ABSTRACT
Web-based vulnerabilities represent a substantial portion of
the security exposures of computer networks. In order to de-
tect known web-based attacks, misuse detection systems are
equipped with a large number of signatures. Unfortunately, it
is diﬃcult to keep up with the daily disclosure of web-related
vulnerabilities, and, in addition, vulnerabilities may be intro-
duced by installation-speciﬁc web-based applications. There-
fore, misuse detection systems should be complemented with
anomaly detection systems. This paper presents an intrusion
detection system that uses a number of diﬀerent anomaly de-
tection techniques to detect attacks against web servers and
web-based applications. The system correlates the server-
side programs referenced by client queries with the parameters
contained in these queries. The application-speciﬁc charac-
teristics of the parameters allow the system to perform fo-
cused analysis and produce a reduced number of false posi-
tives. The system derives automatically the parameter pro-
ﬁles associated with web applications (e.g., length and struc-
ture of parameters) from the analyzed data. Therefore, it
can be deployed in very diﬀerent application environments
without having to perform time-consuming tuning and con-
ﬁguration.
Categories and Subject Descriptors
D.4.6 [Operating Systems]: Security and Protection
General Terms
Security
Keywords
Anomaly Detection, World-Wide Web, Network Security
1.
INTRODUCTION
Web servers and web-based applications are popular at-
tack targets. Web servers are usually accessible through cor-
porate ﬁrewalls, and web-based applications are often devel-
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’03, October 27–31, 2003, Washington, DC, USA.
Copyright 2003 ACM 1-58113-738-9/03/0010 ...$5.00.
oped without following a sound security methodology. At-
tacks that exploit web servers or server extensions (e.g., pro-
grams invoked through the Common Gateway Interface [7]
and Active Server Pages [22]) represent a substantial por-
tion of the total number of vulnerabilities. For example, in
the period between April 2001 and March 2002, web-related
vulnerabilities accounted for 23% of the total number of vul-
nerabilities disclosed [34]. In addition, the large installation
base makes both web applications and servers a privileged
target for worm programs that exploit web-related vulnera-
bilities to spread across networks [5].
To detect web-based attacks, intrusion detection systems
(IDSs) are conﬁgured with a number of signatures that sup-
port the detection of known attacks. For example, at the time
of writing, Snort 2.0 [28] devotes 868 of its 1931 signatures
to detect web-related attacks. Unfortunately, it is hard to
keep intrusion detection signature sets updated with respect
to the large numbers of vulnerabilities discovered daily. In
addition, vulnerabilities may be introduced by custom web-
based applications developed in-house. Developing ad hoc
signatures to detect attacks against these applications is a
time-intensive and error-prone activity that requires substan-
tial security expertise.
To overcome these issues, misuse detection systems should
be composed with anomaly detection systems, which sup-
port the detection of new attacks.
In addition, anomaly
detection systems can be trained to detect attacks against
custom-developed web-based applications. Unfortunately, to
the best of our knowledge, there are no available anomaly de-
tection systems tailored to detect attacks against web servers
and web-based applications.
This paper presents an anomaly detection system that de-
tects web-based attacks using a number of diﬀerent tech-
niques. The anomaly detection system takes as input the
web server log ﬁles which conform to the Common Log For-
mat and produces an anomaly score for each web request.
More precisely, the analysis techniques used by the tool take
advantage of the particular structure of HTTP queries [11]
that contain parameters. The parameters of the queries are
compared with established proﬁles that are speciﬁc to the
program or active document being referenced. This approach
supports a more focused analysis with respect to generic
anomaly detection techniques that do not take into account
the speciﬁc program being invoked.
This paper is structured as follows. Section 2 presents re-
lated work on detection of web-based attacks and anomaly
detection in general. Section 3 describes an abstract model
for the data analyzed by our intrusion detection system. Sec-
tion 4 presents the anomaly detection techniques used. Sec-
tion 5 contains the experimental evaluation of the system
with respect to real-world data and discusses the results ob-
tained so far and the limitations of the approach. Finally,
Section 6 draws conclusions and outlines future work.
2. RELATED WORK
Anomaly detection relies on models of the intended behav-
ior of users and applications and interprets deviations from
this ‘normal’ behavior as evidence of malicious activity [10,
17, 13, 19]. This approach is complementary with respect
to misuse detection, where a number of attack descriptions
(usually in the form of signatures) are matched against the
stream of audited events, looking for evidence that one of the
modeled attacks is occurring [14, 25, 23].
A basic assumption underlying anomaly detection is that
attack patterns diﬀer from normal behavior.
In addition,
anomaly detection assumes that this ‘diﬀerence’ can be ex-
pressed quantitatively. Under these assumptions, many tech-
niques have been proposed to analyze diﬀerent data streams,
such as data mining for network traﬃc [21], statistical analy-
sis for audit records [16], and sequence analysis for operating
system calls [12].
Of particular relevance to the work described here are tech-
niques that learn the detection parameters from the ana-
lyzed data. For instance, the framework developed by Lee et
al. [20] provides guidelines to extract features that are useful
for building intrusion classiﬁcation models. The approach
uses labeled data to derive which is the best set of features
to be used in intrusion detection.
The approach described in this paper is similar to Lee’s
because it relies on a set of selected features to perform both
classiﬁcation and link analysis on the data. On the other
hand, the approach is diﬀerent because it does not rely on
the labeling of attacks in the training data in order to derive
either the features or the threshold values used for detection.
The learning process is purely based on past data, as, for
example, in [18].
3. DATA MODEL
Our anomaly detection approach analyzes HTTP requests
as logged by most common web servers (for example, Apache
[2]). More speciﬁcally, the analysis focuses on GET requests
that use parameters to pass values to server-side programs or
active documents. Neither header data of GET requests nor
POST/HEAD requests are taken into account. Note, however,
that it is straightforward to include the parameters of these
requests. This is planned for future work.
More formally, the input to the detection process consists
of an ordered set U = {u1, u2, ..., um} of URIs extracted from
successful GET requests, that is, requests whose return code
is greater or equal to 200 and less than 300.
A URI ui can be expressed as the composition of the path
to the desired resource (pathi), an optional path information
component (pinfoi), and an optional query string (q). The
query string is used to pass parameters to the referenced
resource and it is identiﬁed by a leading ‘?’ character. A
query string consists of an ordered list of n pairs of param-
eters (or attributes) with their corresponding values. That
is, q = (a1, v1), (a2, v2), . . . , (an, vn) where ai ∈ A, the set of
all attributes, and vi is a string. The set Sq is deﬁned as the
subset {aj, . . . , ak} of attributes of query q. Figure 1 shows
an example of an entry from a web server log and the cor-
responding elements that are used in the analysis. For this
example query q, Sq = {a1, a2}.
The analysis process focuses on the association between
programs, parameters, and their values. URIs that do not
contain a query string are irrelevant, and, therefore, they are
removed from U . In addition, the set of URIs U is partitioned
into subsets Ur according to the resource path. Therefore,
each referred program r is assigned a set of corresponding
queries Ur. The anomaly detection algorithms are run on
each set of queries Ur, independently. This means that the
modeling and the detection process are performed separately
for each program r.
In the following text, the term ‘request’ refers only to re-
quests with queries. Also, the terms ‘parameter’ and ‘at-
tribute’ of a query are used interchangeably.
4. DETECTION MODELS
The anomaly detection process uses a number of diﬀerent
models to identify anomalous entries within a set of input
requests Ur associated with a program r. A model is a set
of procedures used to evaluate a certain feature of a query
attribute (e.g., the string length of an attribute value) or a
certain feature of the query as a whole (e.g., the presence and
absence of a particular attribute). Each model is associated
with an attribute (or a set of attributes) of a program by
means of a proﬁle. Consider, for example, the string length
model for the username attribute of a login program.
In
this case, the proﬁle for the string length model captures the
‘normal’ string length of the user name attribute of the login
program.
The task of a model is to assign a probability value to
either a query or one of the query’s attributes. This proba-
bility value reﬂects the probability of the occurrence of the
given feature value with regards to an established proﬁle.
The assumption is that feature values with a suﬃciently low
probability (i.e., abnormal values) indicate a potential at-
tack.
Based on the model outputs (i.e., the probability values of
the query and its individual attributes), a decision is made –
that is, the query is either reported as a potential attack or as
normal. This decision is reached by calculating an anomaly
score individually for each query attribute and for the query
as a whole. When one or more anomaly scores (either for
the query or for one of its attributes) exceed the detection
threshold determined during the training phase (see below),
the whole query is marked as anomalous. This is necessary
to prevent attackers from hiding a single malicious attribute
in a query with many ‘normal’ attributes.
The anomaly scores for a query and its attributes are de-
rived from the probability values returned by the correspond-
ing models that are associated with the query or one of the
attributes. The anomaly score value is calculated using a
weighted sum as shown in Equation 1. In this equation, wm
represents the weight associated with model m, while pm is
its returned probability value. The probability pm is sub-
tracted from 1 because a value close to zero indicates an
anomalous event that should yield a high anomaly score.
Anomaly Score = (cid:0)
m∈Models
wm ∗ (1 − pm)
(1)
A model can operate in one of two modes, training or de-
tection. The training phase is required to determine the char-
acteristics of normal events (that is, the proﬁle of a feature
according to a speciﬁc model) and to establish anomaly score
thresholds to distinguish between regular and anomalous in-
169.229.60.105 − johndoe [6/Nov/2002:23:59:59 −0800 "GET /scripts/access.pl?user=johndoe&cred=admin" 200 2122
path
a = v
1
1
a = v
2
2
q
Figure 1: Sample Web Server Access Log Entry
puts. This phase is divided into two steps. During the ﬁrst
step, the system creates proﬁles for each server-side program
and its attributes. During the second step, suitable thresh-
olds are established. This is done by evaluating queries and
their attributes using the proﬁles created during the previ-
ous step. For each program and its attributes, the highest
anomaly score is stored and then, the threshold is set to a
value that is a certain, adjustable percentage higher than this
maximum. The default setting for this percentage (also used
for our experiments) is 10%. By modifying this value, the
user can adjust the sensitivity of the system and perform a
trade-oﬀ between the number of false positives and the ex-
pected detection accuracy. The length of the training phase
(i.e., the number of queries and attributes that are utilized
to establish the proﬁles and the thresholds) is determined by
an adjustable parameter.
Once the proﬁles have been created – that is, the models
have learned the characteristics of normal events and suit-
able thresholds have been derived – the system switches to
detection mode. In this mode, anomaly scores are calculated
and anomalous queries are reported.
The following sections describe the algorithms that ana-
lyze the features that are considered relevant for detecting
malicious activity. For each algorithm, an explanation of the
model creation process (i.e., the learning phase) is included.
In addition, the mechanism to derive a probability value p for
a new input element (i.e., the detection phase) is discussed.
4.1 Attribute Length
In many cases, the length of a query attribute can be used
to detect anomalous requests. Usually, parameters are either
ﬁxed-size tokens (such as session identiﬁers) or short strings
derived from human input (such as ﬁelds in an HTML form).
Therefore, the length of the parameter values does not vary
much between requests associated with a certain program.
The situation may look diﬀerent when malicious input is
passed to the program. For example, to overﬂow a buﬀer
in a target application, it is necessary to ship the shell code
and additional padding, depending on the length of the tar-
get buﬀer. As a consequence, the attribute contains up to
several hundred bytes.
The goal of this model is to approximate the actual but
unknown distribution of the parameter lengths and detect
instances that signiﬁcantly deviate from the observed normal
behavior. Clearly, we cannot expect that the probability
density function of the underlying real distribution will follow
a smooth curve. We also have to assume that the distribution
has a large variance. Nevertheless, the model should be able
to identify signiﬁcant deviations.
4.1.1 Learning
We approximate the mean ˙µ and the variance ˙σ2 of the real
attribute length distribution by calculating the sample mean
µ and the sample variance σ2 for the lengths l1, l2, . . . , ln of
the parameters processed during the learning phase (assum-
ing that n queries with this attribute were processed).
4.1.2 Detection
Given the estimated query attribute length distribution
with parameters µ and σ2 as determined by the previous
learning phase, it is the task of the detection phase to assess
the regularity of a parameter with length l.
The probability of l can be calculated using the Chebyshev
inequality shown below.
p(|x − µ| > t)  |l − µ|) < p(l) =
σ2
(l − µ)2
(3)
This is the value returned by the model when operating in
detection mode. The Chebyshev inequality is independent
of the underlying distribution and its computed bound is, in
general, very weak. Applied to our model, this weak bound
results in a high degree of tolerance to deviations of attribute
lengths given an empirical mean and variance. Although
such a property is undesirable in many situations, by using
this technique only obvious outliers are ﬂagged as suspicious,
leading to a reduced number of false alarms.
4.2 Attribute Character Distribution
The attribute character distribution model captures the
concept of a ‘normal’ or ‘regular’ query parameter by look-
ing at its character distribution. The approach is based
on the observation that attributes have a regular structure,
are mostly human-readable, and almost always contain only
printable characters.
A large percentage of characters in such attributes are
drawn from a small subset of the 256 possible 8-bit values
(mainly from letters, numbers, and a few special charac-
ters). As in English text, the characters are not uniformly
distributed, but occur with diﬀerent frequencies. Obviously,
it cannot be expected that the frequency distribution is iden-
tical to a standard English text. Even the frequency of a cer-
tain character (e.g., the frequency of the letter ‘e’) varies con-
siderably between diﬀerent attributes. Nevertheless, there
are similarities between the character frequencies of query