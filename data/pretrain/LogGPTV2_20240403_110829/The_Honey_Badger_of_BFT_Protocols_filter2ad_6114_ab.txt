batching, while using threshold encryption to preserve censorship
resilience (see Section 4.4). We also obtain better efﬁciency by
cherry-picking from the literature improved instantiations of sub-
components. In particular, we sidestep the expensive MVBA primi-
tive by using an alternative ACS [9] along with an efﬁcient RBC [18]
as explained in Section 4.4.
Table 1 summarizes the asymptotic performance of HoneyBad-
gerBFT with several other atomic broadcast protocols. Here “Comm.
compl.” denotes the expected communication complexity (i.e., total
bytes transferred) per committed transaction. Since PBFT relies
on weak synchrony assumptions, it may therefore fail to make
progress at all in an asynchronous network. Protocols KS02 [34]
and RC05 [47] are optimistic, falling back to an expensive recovery
mode based on MVBA. As mentioned the protocol of Cachin et
al. (CKPS01) [15] can be improved using a more efﬁcient ACS
Table 1: Asymptotic communication complexity (bits per trans-
action, expected) for atomic broadcast protocols
PBFT no
KS02 [34] yes
RC05 [47] yes
CKPS01 [15] yes
CKPS01 [15]+ [9, 18] yes
HoneyBadgerBFT (this work) yes
Async? Comm. compl.
Optim. Worst
O(N) ∞
O(N2) O(N3)
O(N) O(N3)
O(N3) O(N3)
O(N2) O(N2)
O(N) O(N)
construction [9, 18]. We also obtain another O(N) improvement
through our novel reduction.
Finally, King and Saia [30,31] have recently developed agreement
protocols with less-than-quadratic number of messages by routing
communications over a sparse graph. However, extending these
results to the asynchronous setting remains an open problem.
3. THE GAP BETWEEN ASYNCHRONOUS
AND WEAKLY SYNCHRONOUS NET-
WORK MODELS
Almost all modern BFT protocols rely on timing assumptions
(such as partial or weak synchrony) to guarantee liveness. Purely
asynchronous BFT protocols have received considerably less atten-
tion in recent years. Consider the following argument, which, if it
held, would justify this narrowed focus:
[X] Weak synchrony assumptions are unavoidable, since in any
network that violates these assumptions, even asynchronous
protocols would provide unacceptable performance.
In this section, we present make two counterarguments that refute
the premise above. First, we illustrate the theoretical separation
between the asynchronous and weakly synchronous network models.
Speciﬁcally we construct an adversarial network scheduler that
violates PBFT’s weak synchrony assumption (and indeed causes it
to fail) but under which any purely asynchronous protocol (such
as HoneyBadgerBFT) makes good progress. Second, we make a
practical observation: even when their assumptions are met, weakly
synchronous protocols are slow to recover from a network partition
once it heals, whereas asynchronous protocols make progress as
soon as messages are delivered.
3.1 Many Forms of Timing Assumptions
Before proceeding we review the various standard forms of tim-
ing assumptions. In an asynchronous network, the adversary can
deliver messages in any order and at any time, but nonetheless must
eventually deliver every message sent between correct nodes. Nodes
in an asynchronous network effectively have no use for “real time”
clocks, and can only take actions based on the ordering of messages
they receive.
The well-known FLP [27] result rules out the possibility of de-
terministic asynchronous protocols for atomic broadcast and many
other tasks. A deterministic protocol must therefore make some
stronger timing assumptions. A convenient (but very strong) net-
work assumption is synchrony: a ∆-synchronous network guarantees
that every message sent is delivered after at most a delay of ∆ (where
∆ is a measure of real time).
Weaker timing assumptions come in several forms. In the un-
known-∆ model, the protocol is unable to use the delay bound as
a parameter. Alternatively, in the eventually synchronous model,
the message delay bound ∆ is only guaranteed to hold after some
(unknown) instant, called the “Global Stabilization Time.” Collec-
tively, these two models are referred to as partial synchrony [26].
33Yet another variation is weak synchrony [26], in which the delay
bound is time varying, but eventually does not grow faster than a
polynomial function of time [20].
In terms of feasibility, the above are equivalent — a protocol that
succeeds in one setting can be systematically adapted for another.
In terms of concrete performance, however, adjusting for weak syn-
chrony means gradually increasing the timeout parameter over time
(e.g., by an “exponential back-off” policy). As we show later, this
results in delays when recovering from transient network partitions.
Protocols typically manifest these assumptions in the form of
a timeout event. For example, if parties detect that no progress
has been made within a certain interval, then they take a corrective
action such as electing a new leader. Asynchronous protocols do not
rely on timers, and make progress whenever messages are delivered,
regardless of actual clock time.
Counting rounds in asynchronous networks. Although the guar-
antee of eventual delivery is decoupled from notions of “real time,” it
is nonetheless desirable to characterize the running time of asynch-
ronous protocols. The standard approach (e.g., as explained by
Canetti and Rabin [19]) is for the adversary to assign each mes-
sage a virtual round number, subject to the condition that every
(r − 1)-message between correct nodes must be delivered before
any (r + 1)-message is sent.
3.2 When Weak Synchrony Fails
We now proceed to describe why weakly synchronous BFT proto-
cols can fail (or suffer from performance degradation) when network
conditions are adversarial (or unpredictable). This motivates why
such protocols are unsuited for the cryptocurrency-oriented applica-
tion scenarios described in Section 1.
A network scheduler that thwarts PBFT. We use Practical Byzan-
tine Fault Tolerance (PBFT) [20], the classic leader-based BFT
protocol, a representative example to describe how an adversarial
network scheduler can cause a class of leader-based BFT proto-
cols [4, 6, 10, 22, 33, 50] to grind to a halt.
At any given time, the designated leader is responsible for propos-
ing the next batch of transactions. If progress isn’t made, either
because the leader is faulty or because the network has stalled, then
the nodes attempt to elect a new leader. The PBFT protocol critically
relies on a weakly synchronous network for liveness. We construct
an adversarial scheduler that violates this assumption, and indeed
prevents PBFT from making any progress at all, but for which Hon-
eyBadgerBFT (and, in fact, any asynchronous protocol) performs
well. It is unsurprising that a protocol based on timing assumptions
fails when those assumptions are violated; however, demonstrating
an explicit attack helps motivate our asynchronous construction.
The intuition behind our scheduler is simple. First, we assume
that a single node has crashed. Then, the network delays messages
whenever a correct node is the leader, preventing progress and
causing the next node in round-robin order to become the new
leader. When the crashed node is the next up to become the leader,
the scheduler immediately heals the network partition and delivers
messages very rapidly among the honest nodes; however, since the
leader has crashed, no progress is made here either.
This attack violates the weak synchrony assumption because it
must delay messages for longer and longer each cycle, since PBFT
widens its timeout interval after each failed leader election. On the
other hand, it provides larger and larger periods of synchrony as well.
However, since these periods of synchrony occur at inconvenient
times, PBFT is unable to make use of them. Looking ahead, Honey-
BadgerBFT, and indeed any asynchronous protocol, would be able
to make progress during these opportunistic periods of synchrony.
To conﬁrm our analysis, we implemented this malicious scheduler
as a proxy that intercepted and delayed all view change messages
to the new leader, and tested it against a 1200 line Python imple-
mentation of PBFT. The results and message logs we observed were
consistent with the above analysis; our replicas became stuck in
a loop requesting view changes that never succeeded. In the on-
line full version [42] we give a complete description of PBFT and
explain how it behaves under this attack.
Slow recovery from network partitions. Even if the weak syn-
chrony assumption is eventually satisﬁed, protocols that rely on
it may also be slow to recover from transient network partitions.
Consider the following scenario, which is simply a ﬁnite preﬁx of
the attack described above: one node is crashed, and the network is
temporarily partitioned for a duration of 2D∆. Our scheduler heals
the network partition precisely when it is the crashed node’s turn to
become leader. Since the timeout interval at this point is now 2D+1∆,
the protocol must wait for another 2D+1∆ interval before beginning
to elect a new leader, despite that the network is synchronous during
this interval.
The tradeoff between robustness and responsiveness. Such be-
haviors we observe above are not speciﬁc to PBFT, but rather are
fundamentally inherent to protocols that rely on timeouts to cope
with crashes. Regardless of the protocol variant, a practitioner
must tune their timeout policy according to some tradeoff. At one
extreme (eventual synchrony), the practitioner makes a speciﬁc esti-
mate about the network delay ∆. If the estimate is too low, then the
system may make no progress at all; too high, and it does not utilize
the available bandwidth. At the other extreme (weak synchrony), the
practitioner avoids specifying any absolute delay, but nonetheless
must choose a “gain” that affects how quickly the system tracks
varying conditions. An asynchronous protocol avoids the need to
tune such parameters.
4. THE HoneyBadgerBFT PROTOCOL
In this section we present HoneyBadgerBFT, the ﬁrst asynch-
ronous atomic broadcast protocol to achieve optimal asymptotic
efﬁciency.
4.1 Problem Deﬁnition: Atomic Broadcast
We ﬁrst deﬁne our network model and the atomic broadcast prob-
lem. Our setting involves a network of N designated nodes, with
distinct well-known identities (P0 through PN−1). The nodes re-
ceive transactions as input, and their goal is to reach common agree-
ment on an ordering of these transactions. Our model particularly
matches the deployment scenario of a “permissioned blockchain”
where transactions can be submitted by arbitrary clients, but the
nodes responsible for carrying out the protocol are ﬁxed.
The atomic broadcast primitive allows us to abstract away any
application-speciﬁc details, such as how transactions are to be inter-
preted (to prevent replay attacks, for example, an application might
deﬁne a transaction to include signatures and sequence numbers).
For our purposes, transactions are simply unique strings. In prac-
tice, clients would generate transactions and send them to all of
the nodes, and consider them committed after collecting signatures
from a majority of nodes. To simplify our presentation, we do not
explicitly model clients, but rather assume that transactions are cho-
sen by the adversary and provided as input to the nodes. Likewise,
a transaction is considered committed once it is output by a node.
• (Purely asynchronous network) We assume each pair of nodes
is connected by a reliable authenticated point-to-point channel
Our system model makes the following assumptions:
34that does not drop messages.2 The delivery schedule is entirely
determined by the adversary, but every message sent between
correct nodes must eventually be delivered. We will be inter-
ested in characterizing the running time of protocols based on the
number of asynchronous rounds (as described in Section 2). As
the network may queue messages with arbitrary delay, we also
assume nodes have unbounded buffers and are able to process all
the messages they receive.
• (Static Byzantine faults) The adversary is given complete control
of up to f faulty nodes, where f is a protocol parameter. Note
that 3 f + 1 ≤ N (which our protocol achieves) is the lower bound
for broadcast protocols in this setting.
• (Trusted setup) For ease of presentation, we assume that nodes
may interact with a trusted dealer during an initial protocol-
speciﬁc setup phase, which we will use to establish public keys
and secret shares. Note that in a real deployment, if an actual
trusted party is unavailable, then a distributed key generation
protocol could be used instead (c.f., Boldyreva [11]). All the
distributed key generation protocols we know of rely on timing
assumptions; fortunately these assumptions need only to hold
during setup.
DEFINITION 1. An atomic broadcast protocol must satisfy the
following properties, all of which should hold with high probabil-
ity (as a function 1 − negl(λ ) of a security parameter, λ ) in an
asynchronous network and in spite of an arbitrary adversary:
• (Agreement) If any correct node outputs a transaction tx, then
• (Total Order) If one correct node has output the sequence of trans-
every correct node outputs tx.
output
actions
0, tx(cid:48)
(cid:104)tx(cid:48)
1, ...tx(cid:48)
(cid:104)tx0, tx1, ...tx j(cid:105)
and
has
i for i ≤ min( j, j(cid:48)).
j(cid:48)(cid:105), then txi = tx(cid:48)
another
• (Censorship Resilience) If a transaction tx is input to N− f correct
nodes, then it is eventually output by every correct node.
The censorship resilience property is a liveness property that
prevents an adversary from blocking even a single transaction from
being committed. This property has been referred to by other names,
for example “fairness” by Cachin et al. [15], but we prefer this more
descriptive phrase.
Performance metrics. We will primarily be interested in analyzing
the efﬁciency and transaction delay of our atomic broadcast protocol.
• (Efﬁciency) Assume that the input buffers of each honest node are
sufﬁciently full Ω(poly(N,λ )). Then efﬁciency is the expected
communication cost for each node amortized over all committed
transactions.
Since each node must output each transaction, O(1) efﬁciency
(which our protocol achieves) is asymptotically optimal. The above
deﬁnition of efﬁciency assumes the network is under load, reﬂecting
our primary goal: to sustain high throughput while fully utilizing
the network’s available bandwidth. Since we achieve good through-
put by batching, our system uses more bandwidth per committed
transaction during periods of low demand when transactions ar-
rive infrequently. A stronger deﬁnition without this qualiﬁcation
would be appropriate if our goal was to minimize costs (e.g., for
usage-based billing).
In practice, network links have limited capacity, and if more
transactions are submitted than the network can handle, a guarantee
on conﬁrmation time cannot hold in general. Therefore we deﬁne
transaction delay below relative to the number of transactions that
2Reliable channels can be emulated on top of unreliable channels
by resending transmissions, at the expense of some efﬁciency.
have been input ahead of the transaction in question. A ﬁnite
transaction delay implies censorship resilience.
• (Transaction delay) Suppose an adversary passes a transaction tx
as input to N − f correct nodes. Let T be the “backlog”, i.e. the
difference between the total number of transactions previously
input to any correct node and the number of transactions that have
been committed. Then transaction delay is the expected number
of asynchronous rounds before tx is output by every correct node
as a function of T .
4.2 Overview and Intuition
In HoneyBadgerBFT, nodes receive transactions as input and