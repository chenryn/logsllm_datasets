title:MoCFI: A Framework to Mitigate Control-Flow Attacks on Smartphones
author:Lucas Davi and
Alexandra Dmitrienko and
Manuel Egele and
Thomas Fischer and
Thorsten Holz and
Ralf Hund and
Stefan N&quot;urnberger and
Ahmad-Reza Sadeghi
MoCFI: A Framework to Mitigate Control-Flow Attacks on Smartphones
Lucas Davi1, Alexandra Dmitrienko2, Manuel Egele3, Thomas Fischer4,
Thorsten Holz4, Ralf Hund4, Stefan N¨urnberger1, Ahmad-Reza Sadeghi1,2
1CASED/Technische Universit¨at Darmstadt, Germany
{lucas.davi,stefan.nuernberger,ahmad.sadeghi}@trust.cased.de
3University of California, Santa Barbara, USA
PI:EMAIL
2Fraunhofer SIT, Darmstadt, Germany
{alexandra.dmitrienko,ahmad.sadeghi}@sit.fraunhofer.de
4Ruhr-Universit¨at Bochum, Germany
{thomas.ﬁscher,thorsten.holz,ralf.hund}@rub.de
Abstract
Runtime and control-ﬂow attacks (such as code injec-
tion or return-oriented programming) constitute one of the
most severe threats to software programs. These attacks
are prevalent and have been recently applied to smartphone
applications as well, of which hundreds of thousands are
downloaded by users every day. While a framework for
control-ﬂow integrity (CFI) enforcement, an approach to
prohibit this kind of attacks, exists for the Intel x86 plat-
form, there is no such a solution for smartphones.
In this paper, we present a novel framework, MoCFI
(Mobile CFI),
that provides a general countermeasure
against control-ﬂow attacks on smartphone platforms by en-
forcing CFI. We show that CFI on typical smartphone plat-
forms powered by an ARM processor is technically involved
due to architectural differences between ARM and Intel x86,
as well as the speciﬁcs of smartphone OSes. Our framework
performs CFI on-the-ﬂy during runtime without requiring
the application’s source code. For our reference implemen-
tation we chose Apple’s iOS, because it has been an attrac-
tive target for control-ﬂow attacks. Nevertheless, our frame-
work is also applicable to other ARM-based devices such
as Google’s Android. Our performance evaluation demon-
strates that MoCFI is efﬁcient and does not induce notable
overhead when applied to popular iOS applications.
1. Introduction
Although control-ﬂow (or runtime) attacks on software
are known for about two decades, they are still one of
the major threats to software today. Such attacks com-
promise the control-ﬂow of a vulnerable application during
runtime based on diverse techniques (e.g., stack- or heap-
based buffer overﬂows [4, 5], uncontrolled format strings
vulnerabilities [23], or integer overﬂows [9]). Many current
systems offer a large attack surface, because they still use
software programs implemented in unsafe languages such
as C or C++. In particular, modern smartphone platforms
like Apple’s iPhone and Google’s Android have recently
become appealing attack targets (e.g., [25, 33, 26, 27, 43])
and increasingly leak sensitive information to remote adver-
saries (e.g., the SMS database [26]).
A general approach to mitigate control-ﬂow attacks is the
enforcement of control-ﬂow integrity (CFI) [1]. This tech-
nique asserts the basic safety property that the control-ﬂow
of a program follows only the legitimate paths determined
in advance. If an adversary hijacks the control-ﬂow, CFI en-
forcement can detect this divagation and prevent the attack.
In contrast to a variety of ad-hoc solutions, CFI provides a
general solution against control-ﬂow attacks. For instance,
to detect conventional return-oriented programming attacks
one can check every return instruction the program is ex-
ecuting [12, 21, 16], but recent results show that return-
oriented programming without returns is feasible on both
x86 and ARM [11]. Moreover, CFI provides stronger pro-
tection than recent ASLR (address space layout randomiza-
tion) mainly due to the fact that existing randomization re-
alizations are often vulnerable to brute-forcing [38] or leak
sensitive information about the memory layout [40]. Sur-
prisingly, and to the best of our knowledge, there exist no
CFI framework for smartphone platforms.
In this paper, we present the design and implementa-
tion of MoCFI (Mobile CFI), a CFI enforcement frame-
work for smartphone platforms. Speciﬁcally, we focus on
the ARM architecture since it is the standard platform for
smartphones, and there is currently no smartphone avail-
able deploying an x86-based processor [28]. The imple-
mentation of CFI on ARM is often more involved than on
desktop PCs due to several subtle architectural differences
that highly inﬂuence and often signiﬁcantly complicate a
CFI solution: (1) the program counter is a general-purpose
register, (2) the processor may switch the instruction set at
runtime, (3) there are no dedicated return instructions, and
(4) control-ﬂow instructions may load several registers as a
side-effect.
Although our solution can be deployed to any ARM
based smartphone, we chose Apple’s iPhone for our refer-
ence implementation because of three challenging issues:
First, the iPhone platform is a popular target of control-ﬂow
attacks due to its use of the Objective-C programming lan-
guage. In contrast, Android is not as prone to control-ﬂow
attacks because applications are mainly written in the type-
safe Java programming language. Second, iOS is closed-
source meaning that we can neither change the operating
system nor can we access the application’s source code.
Third, applications are encrypted and signed by default.
Contribution. To the best of our knowledge, MoCFI is
the ﬁrst general CFI enforcement framework for smart-
phone platforms. Solutions like NativeClient (NaCl) for
ARM [36] only provide a compiler-generated sandbox and
are unsuitable for smartphones. NaCl needs access to
source code and currently does not support 16-Bit THUMB
code which is typically used in modern smartphone apps.
In contrast, our solution operates on binaries and can be
transparently enabled for individual applications. MoCFI
allows us to retroﬁt CFI onto smartphone applications with
commonly unavailable source code. Note that a compile-
time solution would be speciﬁc to a single compiler, and
Apple currently supports two compilers (LLVM and GCC).
Hence, compiler-solutions are typically not suitable in prac-
tice, since neither the end-user nor the App store maintainer
can recompile the application.
To this end, we ﬁrst implemented a system to recover the
control-ﬂow graph (CFG) of a given iOS application in bi-
nary format. In particular, we extend PiOS [19] (a data-ﬂow
analysis framework) to generate the CFG. Based on this in-
formation, we perform control-ﬂow validation routines that
are used during runtime to check if instructions that change
the control-ﬂow are valid. Our prototype is based on library
injection and in-memory patching of code which is com-
patible to memory randomization, static code signing, and
encryption. Finally, our approach only requires a jailbreak
for setting a single environment variable, installing a shared
library, and allowing our library to rewrite the application
code during load-time.
For performance evaluation, we measured the overhead
MoCFI introduces as well the average overhead for typi-
cal applications and worst-case scenarios. The evaluation
shows that our implementation is efﬁcient. Moreover, we
proved the effectiveness by constructing a control-ﬂow at-
tack that uses return-oriented programming [37, 10, 20, 24,
30, 11] and techniques similar to GOT (Global Offset Ta-
ble) dereferencing [45, 22], which our tool can successfully
prohibit.
Outline. The remainder of this paper is organized as fol-
lows: after brieﬂy recalling the ARM architecture and the
iOS smartphone operating system in Section 2, we present
the problem of modern control-ﬂow attacks, the original
concept of CFI, and technical challenges when applying
CFI to smartphones in Section 3. Afterwards, we present
the design and implementation of MoCFI in Section 4
and 5. In Section 6 we discuss the security of MoCFI and
current limitations. We present performance measurements
in Section 7, summarize related work in Section 8, and con-
clude the paper in Section 9.
2. Background
In this section, we present a brief overview of the rele-
vant aspects of the ARM processor architecture and the iOS
operating system that are closely related to our work.
2.1. ARM Architecture
ARM features a 32 bit processor and sixteen general-
purpose registers r0 to r15, where r13 is used as stack
pointer (sp) and r15 as program counter (pc). Further-
more, ARM maintains the so-called current program status
register (cpsr) to reﬂect the current state of the system
(e.g., condition ﬂags, interrupt ﬂags, etc.). In contrast to In-
tel x86, machine instructions are allowed to directly operate
on the program counter pc (EIP on x86).
In general, ARM follows the Reduced Instruction Set
Computer (RISC) design philosophy, e.g., it features ded-
icated load and store instructions, enforces aligned memory
access, and offers instructions with a ﬁxed length of 32 bits.
However, since the introduction of the ARM7TDMI mi-
croprocessor, ARM provides a second instruction set called
THUMB which usually has 16 bit instructions, and hence, is
suitable for embedded systems with limited memory space.
The ARM architecture procedure call standard (AAPCS)
document speciﬁes the ARM calling convention for func-
tion calls [8].
In general, a function can be called by a
BL (Branch with Link) or BLX (Branch with Link and
eXchange) instruction. BLX additionally allows indirect
calls (i.e., the branch target is stored in a register), and
the exchange (“interworking”) from ARM to THUMB code
and vice versa. Both instructions have in common that they
store the return address (which is simply the instruction suc-
ceeding the BLX/BL) in the link register lr (r14). In order
to allow nested function calls, the value of lr is usually
pushed on the stack when the called function is entered.
Function returns are simply accomplished by loading the
return address to pc. Any instruction capable of loading
values from the stack or moving lr to pc can be used as
return instruction. In particular, ARM compilers often use
“load multiple” instructions as returns meaning that the in-
struction does not only enforce the return, but also loads
several registers, e.g., POP {R4-R7,PC} loads R4 to R7
and the program counter with new values from the stack.
2.2. Selected Security Features of Apple iOS
Apple iOS is a closed and proprietary operating system
designed for mobile Apple devices such as iPhone, iPad,
and iPod Touch. A remarkable security feature of iOS is
that only binaries and libraries signed by Apple are allowed
to execute, which reduces the attack surface for malicious
software. Furthermore, Apple only signs applications after
inspecting the code. However, Apple provides no informa-
tion how code inspection is enforced. Further, Apple only
has access to the application binary (and not to the actual
source code).
Since iOS v2.0, Apple enables the W ⊕ X (Writable
xor eXecutable) security model, which basically marks a
memory page either writable or executable. W ⊕ X pre-
vents an adversary from launching a code injection attack,
e.g., the conventional stack buffer overﬂow attack [4]. Fur-
thermore, iOS deploys dynamic code signing enforcement
(CSE) at runtime [48] to prevent the injection of new (mali-
cious) code. In contrast to systems that only enable W ⊕ X
(e.g., Windows or Linux), CSE on iOS prevents an appli-
cation from allocating new memory (e.g., via mprotect)
marked as executable. On the other hand, CSE at runtime in
conjunction with W ⊕ X has practical drawbacks because
it does not support self-modifying code and code generated
by just-in-time (JIT) compilers. Therefore, iOS provides the
so-called dynamic-codesigning entitlement that allows ap-
plications to generate code at runtime. At the time of writ-
ing, only the Mobile Safari Browser and full-screen web ap-
plications are granted the dynamic-codesigning entitlement.
However, a very recent attack demonstrates that the current
CSE implementation is vulnerable allowing an adversary to
apply the dynamic-codesigning to arbitrary market applica-
tions [35]. Moreover, neither CSE at runtime nor W ⊕ X
can prevent return-oriented programming attacks that only
leverage existing and signed code pieces.
To detect stack-based buffer overﬂow attacks, iOS de-
ploys the Stack-Smashing Protector (SSP). Basically, SSP
uses canaries, i.e., guard values that are placed between lo-
cal variables and control-ﬂow information to detect simple
stack smashing attacks. Moreover, SSP features bounds-
checking for selected critical functions (like memcpy and
strcpy) to ensure that their arguments will not lead to
stack overﬂows. However, bounds-checking is only per-
formed for a limited set of functions and SSP cannot de-
tect heap overﬂows or any other control-ﬂow attack beyond
stack smashing.
A very recent feature of iOS (since iOS v4.3) is address
space layout randomization (ASLR). Basically, ASLR ran-
domizes the base addresses of libraries and dynamic areas
(such as stack and heap) thereby preventing an adversary
from guessing the location of injected code (or useful li-
brary sequences). However, it has been shown that exist-
ing randomization realizations are vulnerable to various at-
tacks [38, 40, 13]. In addition, we present an own developed
iOS exploit (see Appendix B) that successfully circumvents
ASLR on iOS.
3. Problem Description
In the following, we discuss the problem of modern
control-ﬂow (runtime) attacks, present the basic idea of
control-ﬂow integrity (CFI), and ﬁnally elaborate on the
technical obstacles to overcome when designing CFI en-
forcement for smartphone platforms.
3.1. Control-Flow Attacks
Figure 1 depicts a sample control-ﬂow graph (CFG) of
an application. Basically, the CFG represents valid execu-
tion paths the program may follow while it is executing.
It consists of basic blocks (BBLs), instruction sequences
with a single entry, and exit instruction (e.g., return, call,
or jump), where the exit instruction enables the transition
from one BBL to another. Any attempt of the adversary to
subvert the valid execution path can be represented as a de-
viation from the CFG, which results in a so-called control-
ﬂow or runtime attack.
In particular, Figure 1 illustrates two typical control-ﬂow
attacks at BBL3: (i) a code injection attack (transition 2a),
and (ii) a code reuse attack (transition 2b). Both attacks
have in common that the control-ﬂow is not transferred to
BBL 5, but instead to a piece of code not originally covered
by the CFG. A conventional control-ﬂow attack is based on
the injection of malicious code into the program’s memory
space. For instance, the adversary may overﬂow a buffer
on the stack by ﬁrst injecting his own malicious code and
then overwriting a function’s return address with the start
address of the injected code [4]. However, modern oper-
ating systems (such as iOS) enforce the W ⊕ X security
model that prevents an adversary from executing injected
code. On the other hand, code-reuse attacks such as return-
into-libc [34, 39] and modern return-oriented programming
(ROP) [37, 10, 20, 24, 30, 11] bypass W ⊕ X by redirecting
execution to code already residing in the program’s mem-
ory space. In particular, ROP allows an adversary to induce
Figure 1. Schematic overview of control-ﬂow attacks