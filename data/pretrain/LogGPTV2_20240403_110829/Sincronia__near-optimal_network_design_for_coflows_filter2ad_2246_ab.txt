d
(cid:40) 
c
p
c
i d
j d
pi
jp
c
=
weight of coflow c (default = 1)
data sent by coflow c
between ingress port i & egress port j
Total data sent by coflow c at port p
if p is an ingress port
if p is an egress port
individual completion times of all coflows
weighted average CCT is defined as (
The source, the destination and the size for each flow in the
coflow is known at time ac. The total amount of data sent by
coflow c between ingress port i and egress port j is denoted
c (see Table 1 for notation).
by dij
The completion time of a coflow (CCTc) is the difference
between the time when the last of its flows finishes and its
arrival time ac. The average CCT for C is the average of
c CCTc/n. The
c wc×CCTc)/n. Given
this formulation, prior work has established that (detailed
discussion of related work in §6):
NP-Hardness [10]. Even when all coflows arrive at time 0
and their sizes are known in advance, the problem of minimiz-
ing average CCT is NP-hard (via reduction from concurrent
open-shop scheduling problem [23]). Thus, the best we can
hope for is an approximation algorithm.
Lower Bounds [5, 24]. Even under the big switch model,
the only known lower bound is a natural generalization of
the lower bound for flows — under a complexity-theoretic
assumption somewhat stronger than P(cid:44)NP, it is impossible
to minimize (weighted) average CCT within a factor of 2 − ε.
Necessity for Coordination [8]. There exists an instance
of coflow scheduling problem, where a scheduling algorithm
that does not use any coordination will achieve average CCT
Ω(√
n) of the optimal. Thus, at least some coordination is
necessary to achieve any meaningful approximation.
3 SINCRONIA DESIGN
In this section, we present the core of Sincronia design — an
offline algorithm for scheduling coflows for the case when all
coflows arrive at time 0; next section describes how Sincro-
nia incorporates this algorithm into an end-to-end network
design that achieves near-optimal performance while sched-
uling coflows in an online and work conserving manner.
Our offline algorithm has two components. The first com-
ponent is a combinatorial primal-dual greedy algorithm,
Bottleneck-Select-Scale-Iterate, for ordering coflows (§3.1);
the second component shows that any per-flow rate alloca-
tion mechanism that is work conserving, preemptive and
schedules flows in order of corresponding coflow ordering
achieves average CCT within 4× of the optimal (§3.2).
SIGCOMM ’18, August 20–25, 2018, Budapest, Hungary
S. Agarwal et al.
t = 2
t = 1
t = 4
average CCT = (2 + 4 × 4)/5 = 3.6
t = 3
(a) Varys
t = 1
t = 2
t = 3
t = 4
average CCT = (3 × 2 + 3 + 4)/5 = 2.6
(b) Sincronia
t = 2
t = 4
t = 1
average CCT = (4 × 2 + 4))/5 = 2.4
t = 3
(c) Optimal
Figure 2: Comparison of Sincronia against Varys and Optimal for the example of Figure 1; corresponding average CCTs are
shown for ε = 0. Each figure shows a “matching” between ports at each time slot; a link indicates data being sent between ports in that time
slot, with multiple links at a port indicating port bandwidth being equally allocated to each of the links in that time slot. For instance, (a)
shows that Varys sends data from first ingress port to the first two egress ports in first two time steps (with each outgoing link getting equal
rate allocation), and from first ingress port to first egress port in third and fourth time steps (with the outgoing link getting full rate). The
orderings produced by Varys and Sincronia are {C1, C2, C3, C4, C5} and {C2, C3, C4, C1, C5}, respectively; the optimal schedule
requires ordering {C2, C3, C4, C5, C1} (modulo permutations within coflows C2, C3, C4 and C5).
Algorithm 1 Bottleneck-Select-Scale-Iterate Algorithm
C = [n]
procedure Order-coflows(J)
▷ Initial set of unscheduled coflows
for k = n to 1 do ▷ Note ordering is from last to first
b ← arg maxp 
c∈C d
p
c
▷ Find the most bottlenecked port
▷ Select weighted largest job to schedule last
σ(k) ← arg minc∈C(wc/db
c )
▷ Scale the weights
wc ← wc − wσ(k) × db
c
db
σ(k)
▷ Iterate on updated set of unscheduled jobs
C ← C\{σ(k)}
∀c ∈ C \ {σ(k)}
return σ
▷ Output the coflow ordering
3.1 Coflow Ordering
Sincronia uses a primal-dual based greedy algorithm —
Bottleneck-Select-Scale-Iterate (BSSI) — for ordering coflows
(Algorithm 1). BSSI generalizes a near-optimal flow schedul-
ing mechanism, “Shortest Remaining Processing Time” first
(SRPT-first) [4], to the case of coflows. The main challenge in
achieving such a generalization is to capture how scheduling
a coflow impacts the completion time of other coflows in
the network. BSSI achieves this using a novel weight scaling
step that is derived based on the primal-dual framework.
BSSI operates in four steps — bottleneck, select, scale, iter-
ate. In its first two steps, BSSI generalizes SRPT-first policy
for flows to the case of coflows. Intuitively, it does so using
an alternative view of SRPT — Largest Remaining Processing
Time last (LRPT-last). In particular, the first step finds the
most bottlenecked ingress or egress port, say b, defined as the
port that sends or receives the most amount of data across all
Table 2: Execution of Algorithm 1 on Figure 1 example. In
this example, we break ties in favor of ingress port with the
largest index. The final ordering produced by the algorithm is
{C2,C3,C4,C1,C5}.
σ(k)
−
C5
{w1, w2, w3, w4, w5}
{1, 1, 1, 1, 1}
C
{ε/(2 + ε), 1, 1, 1, 0}
{0, 1, 1, 1 − ε/2, 0}
k
b
− −
4
5
4
3
3
3
2
2
1
1
C1
C4
C3
C2
{1, 2, 3, 4, 5}
{1, 2, 3, 4}
{2, 3, 4}
{2, 3}
{2}
∅
{0, 1, 1, 0, 0}
{0, 1, 0, 0, 0}
{0, 0, 0, 0, 0}
unordered coflows; the second step then implements LRPT-
last: it chooses the coflow with largest remaining weighted
processing time at port b and places this coflow the last
among all unordered coflows. The third step in BSSI scales
the weights of all unordered coflows to capture how ordering
the coflow chosen in the second step impacts the completion
time of all remaining coflows. The final step is to simply
iterate on the set of unordered flows until all coflows are
ordered.
An Example. Table 2 shows execution of Algorithm 1 on
example of Figure 1. In first iteration (k = 5), the algorithm
chooses bottleneck port b=4 and LRPT coflow σ(5) = C5. The
algorithm then scales the weights — in this example, it ends
up reducing the weight of coflow C1 while keeping other
weights unchanged. This reduction in weight allows C1 to be
selected as the LRPT coflow in next iteration (k = 4). Figure 2
compares the performance of Sincronia against Varys [10]
and optimal for this example. It is not very hard to show that
that the average CCT of Varys can be made arbitrarily worse
compared to Sincronia (and optimal) by adding more ports
and corresponding coflows in the above example [2].
Sincronia: Near-Optimal Network Design for Coflows
SIGCOMM ’18, August 20–25, 2018, Budapest, Hungary
t = 1, 2 t = 3, 4
average CCT = 3.6
(a) Varys + MADD
t = 2 t = 3, 4
t = 1
average CCT = 3.6
(b) Varys + Greedy
t = 1, 2 t = 3, 4
average CCT = 2.4
(c) Optimal + MADD
t = 1, 2 t = 3
t = 4
average CCT = 2.4
(d) Optimal + Greedy
Figure 3: Intuition behind our results in §3.2 using the example of Figure 1. We use two per-flow rate allocation mechanisms in this
example. The first one is weighted fair sharing proposed in Varys [10] (in this example, it simply allocates equal rates to all flows at any
ingress or egress port). The second one is a greedy rate allocation mechanism that simply chooses one flow from the currently highest
ordered coflow at each port, and assigns it the full rate (see Algorithm 2 in §4). The example shows that irrespective of the per-flow rate
allocation mechanism used, both Varys and optimal achieve the same average CCT. We do not show Sincronia in this example because
MADD ends up allocating non-equal rates to flows in the first coflow and it is hard to depict it pictorially.
3.2 Per-Flow Rate Allocation is Irrelevant
As discussed earlier, prior network designs for coflows re-
quire a centralized coordinator to perform complex per-flow
rate allocation, where rate allocated to a flow is dependent
on rates allocated to other flows in the network; for instance,
Varys [10] allocates rates to flows in proportion to their
sizes. Such centralized inter-dependent per-flow rate alloca-
tions make it hard to realize these designs in practice since
changes in location of congestion in the network, transient
failures, and arrival or departure of even one coflow may
result in reallocation of rate for each and every flow in the
network. Such reallocations are impractical in large datacen-
ters where thousands of coflows may arrive each second. We
discuss how Sincronia completely offloads the rate alloca-
tion to and scheduling of individual flows to the underlying
priority-enabled transport layer. We start with an intuitive
discussion, followed by a more formal statement of the result.
High-level idea. Given a coflow ordering produced by our
BSSI algorithm, we show that it is sufficient for Sincronia to
schedule flows in an order-preserving manner; that is, at any
time, a flow from coflow C is blocked if and only if either its
ingress port or its egress port is busy serving a flow from a
different coflow C’ that is ordered before C. The reason this
is sufficient is that once a strict ordering between coflows
has been established, the proof simply requires finishing
each coflow as soon as possible while following the ordering.
The main insight is that if there are multiple flows within a
coflow starting at an ingress port or ending at an egress port,
sharing the link bandwidth does not improve the completion
time of this coflow. For instance, in example of Figure 2(a),
if we would have given full rate to one flow at each ingress
port in the first time step and to the other flow in the other
time step, the completion time of coflow C1 would not have
changed (and so, the same is true for the overall average
CCT). Figure 3 demonstrates the irrelevance of per-flow rate
allocation for both Varys and the optimal.
Formal statement of results. We now formally state the
result regarding the irrelevance of per-flow rate allocation.
The detailed proofs for these results are in the technical
report [2]; we give a high-level idea of the proofs in §7.
Definition 1. Let σ : [n] (cid:55)→ [n] be an ordering of coflows.
A flow scheduling mechanism M is said to be σ-order-
preserving if M blocks a flow f from coflow σ(k) if and only
if either its ingress port or its egress port is busy serving a flow
from a coflow σ(i), i < k (preemption is allowed).
Theorem 1. Consider a set of coflows C, all of which arrive
at time 0. Let O be the ordering of coflows produced by the
Bottleneck-Select-Scale-Iterate algorithm for C and consider
any work-conserving, pre-emptive and O-order-preserving
flow rate allocation scheme used to schedule C in Sincronia.
Then, under the big switch model, Sincronia achieves aver-
age coflow completion time within 4× of the optimal average
coflow completion time for C.
It turns out that if work conservation is desired, preemption
is necessary to achieve bounded average CCT:
Claim 1. There exists a set of coflows C for which the aver-
age coflow completion time using any work-conserving, non-
preemptive flow rate allocation scheme can be arbitrarily worse
than the optimal average coflow completion time for C.
Definition 2. Let σ be an ordering of coflows. For any coflow