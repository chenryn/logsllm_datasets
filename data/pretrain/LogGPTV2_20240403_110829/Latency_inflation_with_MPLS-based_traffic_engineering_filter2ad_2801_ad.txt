### LSP Split and Bandwidth Considerations

When an LSP (Label Switched Path) is split into two smaller ones, only the increased traffic traverses a longer path. The minimum and maximum bandwidth parameters specify the bounds of the LSP's bandwidth. A low minimum bandwidth value can make an LSP unstable, leading to frequent path changes even with minimal latency differences. This is because a small increase in bandwidth (a few hundred kilobits per second) can trigger the bandwidth threshold. In such cases, LSPs may change paths even if the current path has sufficient available bandwidth, due to autobandwidth tie-breaking algorithms (e.g., random, least filled, most filled) that force them to migrate to another equal-cost path. Conversely, a high minimum bandwidth value can waste reservable bandwidth in the network.

A lower maximum bandwidth limits the LSP's bandwidth reservation, making the fate of additional traffic on the LSP uncertain and necessitating the setup of more LSPs between data center pairs to accommodate the entire traffic. Each LSP incurs additional overhead in terms of computation and storage on the ingress router and the network. A large maximum bandwidth value makes the LSP less mobile, as it becomes difficult to find a path with free, large reservable bandwidth during high load conditions. The 'all-or-nothing' policy further complicates this, as it either fully reserves the required bandwidth or does not reserve any at all.

### Bandwidth Threshold and Subscription Factor

The bandwidth threshold determines when the autobandwidth algorithm should be triggered. A small threshold value can make the LSP unstable, while a large threshold value makes the LSP less responsive and requires more headroom on the link to absorb additional bandwidth. The subscription factor, which specifies the fraction of link capacity that must be reserved, also plays a crucial role. A small subscription factor wastes network capacity, while a large subscription factor reduces the headroom for LSPs to grow, triggering the autobandwidth mechanism.

### Future Work

In future work, we will explore how to automatically adjust the autobandwidth parameters. So far, we have assumed that all LSPs and traffic are equally important. However, in an OSP (Online Service Provider) network, different application traffic often has distinct latency requirements. For example, web application traffic is typically latency-sensitive, while backup and replication traffic is not. A "smart" Traffic Engineering (TE) strategy would optimize latency for latency-sensitive traffic and provision sufficient bandwidth for delay-tolerant traffic. This could be achieved by classifying application traffic into delay-sensitive and delay-tolerant LSPs and assigning higher priority to the former. We will study the effectiveness of such classification in our future work.

### Conclusion

In this paper, we presented the first study of the effectiveness of MPLS-TE (Multiprotocol Label Switching - Traffic Engineering) in a multi-continent production network connecting tens of data centers. Using detailed LSP traces collected over a 2-month period, we showed that a substantial number of LSPs experience severe latency inflation. We further demonstrated that 80% of latency inflation occurs due to LSP path changes concentrated on 9% of the links, 30% of the routers, and 3% of the active DC-pairs. Our analysis confirmed that traffic load changes exceeding the capacity of a subset of links along the shortest paths of LSPs are the primary root cause of latency inflation. Additionally, we uncovered poor configuration of MPLS-TE's autobandwidth algorithms in the studied network as a source of inefficiency. As future work, we are developing guidelines and automatic schemes to adjust autobandwidth configurations to changing traffic loads.

### Acknowledgments

We thank the program committee and reviewers for their helpful comments, and especially our shepherd, K. Papagiannaki, whose detailed feedback significantly improved the paper and its presentation.

### References

1. D. Applegate and E. Cohen. Making intra-domain routing robust to changing and uncertain traffic demands: Understanding fundamental tradeoffs. In Proc. of SIGCOMM. ACM, 2003.
2. D. Awduche, L. Berger, D. Gan, T. Li, V. Srinivasan, and G. Swallow. RFC 3209: RSVP-TE: Extensions to RSVP for LSP tunnels. 2001.
3. D. Bertsekas and R. Gallager. Data networks. Prentice-hall New York, 1992.
4. P. Gill, N. Jain, and N. Nagappan. Understanding network failures in data centers: Measurement, analysis, and implications. In Proc. of SIGCOMM. ACM, 2011.
5. S. Kandula, D. Katabi, B. Davie, and A. Charny. Walking the tightrope: Responsive yet stable traffic engineering. In Proc. of SIGCOMM. ACM, 2005.
6. K. Kompella and G. Swallow. RFC 4379: Detecting multi-protocol label switched (MPLS) data plane failures. 2006.
7. H. Wang, H. Xie, L. Qiu, Y. Yang, Y. Zhang, and A. Greenberg. COPE: Traffic engineering in dynamic networks. In Proc. of SIGCOMM. ACM, 2006.
8. Y. Wang, H. Wang, A. Mahimkar, R. Alimi, Y. Zhang, L. Qiu, and Y. Yang. R3: Resilient routing reconfiguration. In Proc. of SIGCOMM. ACM, 2010.
9. LSP Ping: MPLS LSP ping/traceroute for LDP/TE, and LSP ping for VCCV. http://www.cisco.com/en/US/docs/ios/12_4t/12_4t11/ht_lspng.html
10. MPLS for dummies, 2010. http://www.nanog.org/meetings/nanog49/presentations/Sunday/mpls-nanog49.pdf

### Summary Review Documentation for "Latency Inflation with MPLS-based Traffic Engineering"

**Authors:** A. Pathak, M. Zhang, Y. Hu, R. Mahajan, D. Maltz

#### Reviewer #1

**Strengths:**
- MPLS traffic engineering mechanisms are likely in wide use.
- Understanding how these mechanisms work in practice and their pitfalls is valuable to the measurement community.
- Measurements are from a well-known online service provider (MSN).

**Weaknesses:**
- It is unclear if MPLS TE deployments using autobandwidth experience the same problems identified in the paper.

**Comments to Authors:**
- The study is useful and likely to spur additional research.
- There is an apparent mismatch in the caption of Figure 3 and the text describing it.
- Mention that some ISPs are already doing manual splitting of LSPs.
- Address writing and presentation issues, including citations to relevant IETF RFCs.
- Correct redundant phrases and anthropomorphizing language.
- Consider renaming Section 5 to "Discussion."

#### Reviewer #2

**Strengths:**
- Latency between data centers and MPLS TE are critically important topics.
- Results confirm expectations and are important for operators.

**Weaknesses:**
- Experimental methodology uses geographic information to approximate latency instead of active probing.

**Comments to Authors:**
- Good short paper; follow through on future plans to find a solution.
- Use active probing data to validate latency approximation.
- Discuss feedback from operators regarding heavily loaded or under-provisioned nodes.
- Investigate the impact of decreasing the 5-minute timer for autobandwidth recalculations.

#### Reviewer #3

**Strengths:**
- First look into MPLS-TE in practice.
- Nice dataset.
- Shows problems with current TE implementations, leading to further research.

**Weaknesses:**
- Latency measurements are not direct.
- Some analysis could be deeper.

**Comments to Authors:**
- Provide acceptable latency ranges for OSP operations.
- Give an idea of the geographical spread of the network.
- Explain how you verify latency estimation.
- Use consistent terminology (e.g., "latency" instead of "OWD").
- Use statistical correlation metrics in Section 4.2.

#### Reviewer #4

**Strengths:**
- First paper demonstrating the impact of MPLS TE on latency across a network.
- Good understanding of how MPLS TE works and possible reasons behind latency increases.

**Weaknesses:**
- Does not prove that the reason for latency increase is the autobandwidth mechanism.
- Correlation with utilization is weak.

**Comments to Authors:**
- Formulate and test a hypothesis regarding the impact of autobandwidth on latency.
- Define and test the causes of path changes.
- Clarify the optimization problem used for comparison.
- Provide a precise definition of byte-weighted latency.

#### Reviewer #5

**Strengths:**
- First paper on measured performance of MPLS networks.
- Results are interesting to network operators.

**Weaknesses:**
- The paper only scratches the surface of the problem.
- Lack of deep analysis of the causes of sub-optimal paths.

**Comments to Authors:**
- Go deeper into the causes of sub-optimal paths.
- Explain why MPLS picks sub-optimal paths from time to time.

### Response from the Authors

**1. Autobandwidth as the Root Cause of Latency Spikes:**
- MSN comprises tens of DCs interconnected with a dedicated network, all managed by the autobandwidth algorithm.
- Most inter-DC links have three 9's availability.
- About 82.8% of LSPs with severe spikes have cumulative spike durations more than 1.2 hours, suggesting that these spikes are caused by autobandwidth rather than failures.
- Confirmed similar LSP spikes in MPLS simulations.

**2. Use of Geographical Distances to Estimate Latency:**
- Currently, direct LSP latency measurement data is not available.
- Difficult to associate end-to-end ping data with individual LSPs due to load-balancing.
- Latency estimate based on great-circle distance and speed-of-light is the best approximation.

These details have been included in the paper.