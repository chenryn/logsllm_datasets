CPR
FPR
24.6%
0%
47
24
48.9%
0.03%
178
125
72.6%
0.07%
349
301
CP
FP
89.5%
0.22%
901
802
80th
90th
99.7%
0.81%
3.0k
3.1k
99.7%
13.9%
78.1k
50k
99.9%
1.8%
4.3k
5.0k
99.9%
74.9%
193k
402k
98.5%
0.50%
2.1k
2.2k
98.1%
5.42%
53.2k
19.8k
Burst size greater than 15k
80.4%
CPR
0.04%
FPR
11.0k
110
39.3%
0%
5.7k
6
5.6%
0%
1.7k
0
CP
FP
93.0%
0.60%
19.6k
2.4k
Table 2: Inference algorithm with history model: perfor-
mance of the prediction of future withdrawals.
the inference at the end of the burst, SWIFT identified the failed link
for 91% of the bursts (1991), a superset for 9% bursts (188), a set of
links adjacent to the failed one for 1 burst and did a wrong inference
for 3 bursts. When we triggered the inference after 200 withdrawals,
SWIFT still selected backup paths that bypass the actual failed link
for all the bursts but one. SWIFT identified a superset of the failed
link for 12% of the bursts, while for the remaining 88%, it returned
a set of links adjacent to the failed one.
6.3 Withdrawals prediction accuracy
In the previous section (§6.2), we showed that SWIFT inference
algorithm is indeed able to identify the failed link, even with limited
information. In this section, we evaluate the ability of SWIFT to pre-
dict withdrawals, we also give the absolute number of prefixes fast
rerouted upon such inference, enabling us to quantify the benefit
of SWIFT, as well as the possible under/overshooting induced.
Differently from the previous section, in order to evaluate specif-
ically the prediction, we consider as “positives” only the prefixes
withdrawn after the inference was made. This change affects the
definition of TP (and TPR) but leaves FP (FPR) unaltered. Since we
already used TPR in §6.2, we denote with CPR (for Correctly Pre-
dicted Rate) the true positive rate of the prediction. We also denote
with CP and FP, the total numbers of prefixes correctly predicted
or not, respectively.
6.3.1 Validation on real BGP data.
Table 2 shows results obtained by running the SWIFT inference
algorithm with the history model. Results for small (≤15k) and
large (>15k) bursts are shown separately.
SWIFT correctly fast-reroutes a large number of affected pre-
fixes. For half (resp. 80%) of the small bursts, SWIFT correctly pre-
dicts at least 89.5% (resp. 48.9%) of the future prefix withdrawals.
For half (resp. 80%) of the large bursts, SWIFT correctly predicts at
least 93% (resp. 39.3%) of the future prefix withdrawals. In terms
of absolute numbers, we see that SWIFT correctly fast-reroutes a
Technical Report, 2017,
significant amount of prefixes, especially for larger (>15k) bursts,
where the number of prefixes predicted is in the order of tens of
thousands for 60% of the bursts and in the order of hundreds of
thousands for more than 10%.
SWIFT only reroutes a small number of non-affected pre-
fixes. Both for small and large bursts, the fraction of fast-rerouted
prefixes that were not affected by the failure is small in most of the
cases. In few cases (e.g., 90-th percentile of the large bursts) however,
the algorithm significantly overestimates the number of prefixes
to be rerouted (FP). This is because we deliberately designed and
tuned the algorithm to not minimize incorrectly rerouted prefixes in
order to avoid missing prefixes that should be rerouted. Incorrectly
rerouted prefixes are indeed forwarded to a backup path which
is sub-optimal but not disrupted, just for the few minutes needed
for BGP to reconverge. Consistently, we note that less aggressive
weights do reduce the FPR (see Appendix C).
6.3.2 Validation through simulation.
We now evaluate the accuracy of the prefixes prediction on the
bursts generated by C-BGP.
SWIFT accurately predicts prefix withdrawals, even when
considering noise. When inferring the affected prefixes after only
200 withdrawals, the FPR is equal to 0% for 98% of the bursts. The
highest FPR observed is only 13%. In the median case (resp. 25th
percentile), the CPR is equal to 88% (resp. 84%). The lowest CPR
observed is 37%.
To consider the impact of BGP noise on these numbers, we added,
to each burst, 1,000 withdrawals unrelated to the failure (as in §6.2.2).
We found that, for 53% of the bursts, the FPR is still 0%. The FPR
is greater than 9% for only 1% of the bursts. In the median case
(resp. 25th percentile), the CPR is 53% (resp. 50%). The CPR is far
from 100% because the withdrawals unrelated to the failure count
as positives. In practice, we observe that the CPR is less affected by
BGP noise, as the level of noise is usually much lower (see §2.2).
6.4 Encoding effectiveness
We now experimentally evaluate SWIFT encoding scheme (§5) by
quantifying how many prefixes can effectively be rerouted in the
data-plane by matching on the pre-provisioned tags. For each burst,
we define the encoding performance, as the fraction of predicted
prefixes that can be rerouted by the encoding scheme. The perfor-
mance depends on the number of bits allocated to the AS path part
of the tag (see §5). For this part of the evaluation, we rely on the
inference algorithm with the history model and consider the bursts
obtained from the real BGP data.
Allocating 18 bits to the AS-path part of the tag enables to
reroute 98.7% of the predicted prefixes. Fig. 7 shows the encod-
ing performance (over all bursts) as a function of the number of
bits reserved for the AS-path part of the tag. Each box shows the
inter-quartile range of the encoding performance: the line in the
box depicts the median value; the dot depicts the mean; and the
whiskers show the 5th and 95th percentiles. As the number of bits
allocated to the AS paths encoded increases, so does the encoding
performance. We see that 18 bits are already sufficient to reroute
98.7% of the predicted prefixes in the median case (73.9% in average).
Technical Report, 2017,
T. Holterbach et al.
Figure 7: With only 18 bits available for the AS paths encod-
ing, SWIFT can reroute more than 98.7% of the predicted pre-
fixes in the median case.
Figure 8: SWIFT quickly learns about remote outages. In 2
(resp. 9) seconds, SWIFT learns more than 50% (resp. 75%) of
the withdrawals, BGP needs 13 seconds (resp. 32 seconds).
These results illustrate that the compression done by the encoding
algorithm is efficient and manages to encode the vast majority of
the relevant AS links. In addition, Fig. 7 shows that for the large
bursts of at least 10k withdrawals, the encoding performance is bet-
ter (84.0% on average with 18 bits). This is explained by the design
of our encoding algorithm, which encodes with highest priority the
AS links with the largest number of prefixes traversing them (and
which may cause large bursts in case of a failure).
Assuming a tag of 48 bits (e.g., using the destination MAC), the
remaining 30 bits can be used to encode the backup next-hops. If
SWIFT encodes up to depth 4 (i.e., position 5 in the AS path), 64
different next-hops can therefore be used. This suggests that SWIFT
encoding can work well even if the SWIFTED device is connected to
a large number of external neighbors, like in IXPs [46]. The number
of backup next-hops can even be increased by reducing the number
of AS hops encoded (e.g., up to depth 3 instead of 4).
6.5 Rerouting speed
In this section, we show that the combination of the SWIFT infer-
ence algorithm and the encoding scheme enables fast convergence
in practice (within 2 s) by quantifying: (i) the learning time required
for a prediction; and (ii) the number of rules updates to perform in
the data plane. Our results are computed on the bursts in the real
BGP data.
SWIFT learns enough information to converge within 2 sec-
onds (median). Compared to vanilla BGP, SWIFT converges much
faster than a BGP router working at the per-prefix level. Fig. 8
shows the CDF of the time elapsed between the beginning of the
burst and the actual time at which every withdrawal in the burst is
learned. For BGP, the learning time corresponds to the withdrawal
timestamp. For SWIFT, it corresponds to the prediction time if the
withdrawal is predicted, otherwise the withdrawal timestamp. The
plot highlights that, in the median case, SWIFT learns a withdrawal
within 2 s, while BGP needs 13 s. We can observe a shift at 41 s in
the SWIFT curve. After investigation, we found that this is due to
a very large burst of 570k withdrawals which took a total of 105 s
to arrive. The first 20k withdrawals (needed for SWIFT to launch
the prediction) took 41 s to arrive. Observe that, even in such a
case, SWIFT was still able to shave off more than 1 min of potential
downtime.
SWIFT requires few data-plane updates to reroute all the
predicted prefixes. The number of data-plane updates required to
reroute all the predicted prefixes depends on the number of failed
AS links reported by the inference algorithm. When executing the
inference algorithm after 2.5k withdrawals, in 29% of the cases, the
number of links predicted is 1 and the median number (resp. 90th
percentile) is 4 (resp. 29). For each reported link, one data-plane
update is required for each backup next-hop (§5). As a result, in
the median case (resp. 90-th percentile) and with 16 backup next-
hops, 64 (resp. 464) data-plane updates are required. Considering
a median update time per-prefix between 128 and 282 µs [24, 63],
SWIFT can update all the forwarding entries within 130 ms.
7 CASE STUDY
In this section, we showcase the benefits of SWIFT by boosting the
convergence time of a recent Cisco router. As mentioned in §3.2,
SWIFT can be implemented directly on existing routers via a simple
software update, since the only hardware requirement, a two-stage
forwarding table, is readily available in recent platforms [3] (we
confirmed this implementation through discussion with a major
router vendor). Yet, to evaluate SWIFT without waiting for vendors
to implement it, we developed an alternative deployment scheme.
How to SWIFT any existing router. In our alternative deploy-
ment scheme, we interpose a SWIFT controller and an SDN switch
between the SWIFTED router and its peers, respectively at the
control- and data-plane level (as in Fig. 9(b)). The setup is akin to
the SDX platform [30, 31]. It enables to deploy SWIFT on any router
that supports BGP and ARP, that is, virtually any router.
Upon reception of the BGP updates coming from the peers of
the SWIFTED router, the controller assigns 48-bit tags according to
the SWIFT encoding scheme (see §5). The controller programs the
SWIFTED router to embed the data-plane tags in the destination
MAC field in the header of incoming packets, using the same tech-
nique as in a SDX [31] (i.e., with BGP and ARP). It also programs the
SDN switch to route the traffic based on the tags, and rewrite the
destination MAC address with the one of the actual next-hop. The
two-stage forwarding table used by SWIFT then spans two devices:
the SWIFTED router (first stage) and the SDN switch (second stage).
13182328Number of bits available020406080100Encoding performance (%)all burstsmin burst size = 10000020406080100120140Learning time (s)020406080100CDF (%)SWIFTBGPTechnical Report, 2017,
maintenance or internal link failures. For example, LOUP [32] im-
proved internal BGP convergence by ordering external route up-
dates to avoid transient loops. SWIFT complements and generalizes
these approaches by speeding-up local rerouting upon remote fail-
ures. SWIFT goals are similar to R-BGP [43] which enables faster
failover in inter-domain routing by pre-computing and propagating
few disjoint failover paths. Unlike SWIFT though, R-BGP is not
compatible with existing routers: it may also require many paths
to be propagated Internet-wide and stored in routers.