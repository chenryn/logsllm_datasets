contrast to SAD THUG, Stegdetect causes a large num-
ber of false positives, 5.26% on average.
7 Limitations
While our evaluation in section 6 shows that our ap-
proach is very effective with regard to detecting embed-
ded messages that change the structure of JPEG or PNG
ﬁles, it is not designed to detect embeddings in the en-
coded image data. Thus if an attacker chooses to embed
messages in the image data stored in a ﬁle, this fact can-
not be detected using our approach. A large number of
approaches exist that do attempt to detect such embed-
dings (cf. section 8). With respect to detecting structural
embeddings, SAD THUG signiﬁcantly outperforms the
only previous method attempting to solve this problem.
USENIX Association
27th USENIX Security Symposium    1159
(a) JPEG
(b) PNG
Figure 8: The classiﬁcation performance of SAD THUG and two Stegdetect methods for JPEG ﬁles and SAD THUG’s
performance for the PNG format.
Similarly, our prototype could be evaded by using a
ﬁle type that it currently does not support. However,
there are several points that mitigate this limitation. First,
our approach is agnostic with respect to ﬁle types and
the prototype parser could simply be extended to parse
the structure of another ﬁle type. Second, an ALG may
expect to observe ﬁles of one type much less often than
others. As we pointed out in section 2, a web application
ﬁrewall (WAF) typically observes far more images than
HTML documents, since each HTML document usually
references dozens of image ﬁles. While PDF, DOC or
XLS ﬁles are often provided as downloads, they gener-
ally make up a much smaller fraction of a website’s con-
tent than HTML documents. Therefore, WAFs may refer
to more computationally expensive methods, like on-the-
ﬂy conversion into image ﬁles, or even require user inter-
action before letting such ﬁles pass through them.
Like all
supervised machine learning-based ap-
proaches, our approach’s effectiveness depends on the
training data set. A training data set that is not repre-
sentative for the benign data observed in the classiﬁca-
tion phase may increase our approach’s false positive ra-
tio. For instance, some programs, e.g.
image optimiz-
ers, write ﬁles with an unusual structure. If for a given
program of that kind no ﬁles were present in the train-
ing data, SAD THUG is likely – and rightfully so – to
classify their ﬁles as anomalies. However, due to SAD
THUG’s generalization properties, this can usually be re-
mediated by adding a small number of curated ﬁles from
that software to the training data.
Like all
supervised machine learning-based ap-
proaches, SAD THUG is to some degree vulnerable to
poisoning attacks.
If an attacker manages to inject a
large number of ﬁles into its target’s training data set, this
will have a predictable effect on the resulting automaton.
Thus, it could try to create transitions in the automaton
that would accept the structural anomalies created by its
approach. In section 9.2, we discuss several avenues for
future work that may mitigate this threat.
Finally, short of manipulating the target’s automaton,
an attacker could make informed guesses about it as well
as about the target’s parameterization to devise a strategy
to bypass SAD THUG. Generally, such a strategy would
allow an attacker to add a few bytes to each variable
length segment in a ﬁle, possibly at the cost of the ﬁle’s
compatibility with common decoders. i.e. even when an
attacker successfully implements a method that bypasses
SAD THUG, it will only be able to transfer a small num-
ber of bytes per ﬁle – compared against an arbitrary num-
ber of bytes with structural embedding in general.
8 Related Work
In this section, we provide a brief overview of related
work. We focus on three areas. First, we take a quick
look at legitimate use of steganography for censorship
circumvention. Second, we provide an overview of other
approaches for detecting malware or its communications
in settings similar to that sketched in section 2. Finally,
1160    27th USENIX Security Symposium
USENIX Association
0.940.960.981.00True Classification Ratio0.000.020.040.06True Classification RatioNo EmbeddingCerberDuQuHammertossMicrocinSyncCryptTropic TrooperZeusVMZeusVM/Zberp*APP0APP1: CommentSAD THUGStegdetect: True Classification RatioStegdetect: ErrorSAD THUG0.880.900.920.940.960.981.00True Classification RatioNo EmbeddingaaAaBrazilianCryLockerDNSChangerpHYswe discuss other methods for detecting steganographic
message exchanges and their utility with respect to struc-
tural embedding methods. Other approaches that apply
similar machine learning methods for solving informa-
tion security challenges – Sivakorn’s HVLearn [54] or
Görnitz et al.’s work [24] just to name two – provide a
valuable background for this work. However, space con-
straints do not allow us to discuss them in due detail here.
Several systems have been proposed for bypassing
censorship systems that may act like an application level
gateway in our threat model. While SAD THUG was de-
signed to prevent unwanted communications from mal-
ware, the problems are obviously related. Approaches
designed to circumvent censorship could be employed
to bypass legitimate restrictions according to our threat
model while approaches like SAD THUG could be used
to detect attempts to circumvent censorship. Systems
like Burnett et al.’s Collage [18], Invernizzi et al.’s MIAB
[32] or Feamster et al.’s Infranet [22] use stegosystems
like Outguess [47] or HUGO [45] to hide messages in
JPEG image data. Thus, by their choice of cover me-
dia, they are not affected by SAD THUG. Mohajeri et
al.’s SkypeMorph [40] and Weinberg et al.’s StegoTorus
[57] replicate or hide data in voice-over-IP trafﬁc – which
could not traverse a reasonably conﬁgured ALG in our
threat model. However, StegoTorus can also hide data
in HTTP headers and JavaScript, PDF or SWF ﬁles.
Since our prototype currently only supports JPEG and
PNG ﬁles, these methods are unaffected by SAD THUG.
However by adding appropriate parsers, it may be able to
detect StegoTorus’s data hiding methods. Finally, Wus-
trow et al.’s TapDance [58] requires that the attacker’s
system in the protected network is able to engage in a
TLS connection with a system outside that network. This
method is not applicable if the ALG conducts man-in-
the-middle attacks against TLS connections. If it does
not, SAD THUG would not be able to inspect the data
transfered and obfuscation on the payload level would
not be necessary anyway.
Switching to the position of the ALG in our threat
model, we ﬁrst take a look at Bartos et al.’ approach
[13] which analyzes an HTTP proxy’s log ﬁles. While
the approach is very lightweight, in this domain, data in-
or exﬁltration attacks using image ﬁles are practically in-
distinguishable from legitimate transfers and thus their
method cannot provide the utility of SAD THUG.
Similarly, Rahbarinia et al.’s Mastino approach [50],
Stringhini et al.’s Shady Paths method [56] and Kwon et
al.’s approach [35] use the observation that exploit kits
often send browsers through a chain of redirects before
delivering the actual exploit. However, this limits these
approach’s utility to the infection phase and even there
the redirects are not a technical necessity. More so, when
exploit code is extracted from an image ﬁle by an other-
wise inconspicuous JavaScript, a technique used by sev-
eral exploit kits, e.g. Angler [44], Astrum [4] or Sun-
down [36], the approaches are unlikely to detect the at-
tack. Finally, they cannot detect C&C interactions using
hidden messages in image ﬁles. The same holds for In-
vernizzi et al.’s Nazca approach [33] but simply for the
reason that they explicitly ignore media ﬁles like images.
SpyProxy, proposed by Moshchuk et al. [42], is lim-
ited to detecting successful exploitation attempts but not
impeded by the use of steganography in the process. To
the users in the network, it serves as a proxy but before
delivering unknown content to a client, it redirects the
respective URL to a farm of sandboxes and only if its
rendering does not trigger a sandbox violation, it is re-
layed to the user. Taylor et al. use a similar approach
but use honeyclients to impersonate the client request-
ing a conspicuous resource. Like all sandbox-based ap-
proaches, they are resource-intensive and also subject to
evasion techniques like busy-waits or ﬁngerprinting. Gu
et al.’s BotMiner [26] is one of the few approaches that
may detect C&C communications after infection. How-
ever, not only does it heavily rely on other sensors but
also on observing communications with external hosts
that do not occur in our threat model. Similarly, Yu et
al.’s PSI approach [60] does not implement a detection
method of its own but provides a framework integrating
existing network-based detection methods, like the Bro
and Snort IDS or the Squid HTTP proxy. Thus, while
it cannot detect the attacks SAD THUG is designed to
detect, it could integrate our approach to provide com-
prehensive protection against them.
Finally, we want to take a brief look at approaches
for detecting network-based steganography using JPEG
ﬁles. Provos, partly in conjunction with Honeyman, pub-
lished a small series of papers on hiding messages in
JPEG ﬁles and detecting such embeddings [48, 47, 49].
Like the other methods discussed below, their methods
are concerned with the embedding in or detection of em-
beddings in the image data of these ﬁles. The Stegde-
tect tool described in [48] uses a small set of special-
ized χ2 tests on the DCT coefﬁcient distribution of the
ﬁle in question to detect one of three embedding algo-
rithms. Additionally, as we pointed out in section 6, the
Stegdetect tool contains methods for detecting structural
embeddings like the ones we detect with SAD THUG.
While these methods were not covered by the respective
paper, we included them in our evaluation to determine
their effectiveness and provide a comparison for our own
method. Our evaluation in section 6 shows that Stegde-
tect performs well for embedding methods based on the
append paradigm but effectively fails to detect embed-
dings using other methods. Also, for JPEG ﬁles SAD
THUG scores a mean false positive ratio that is one or-
der of magnitude below that of Stegdetect.
USENIX Association
27th USENIX Security Symposium    1161
In another statistical approach to detecting informa-
tion hiding in DCT coefﬁcients, Andriotis et al. [11] use
Benford’s law on the distribution of the DCT coefﬁcients
to determine whether they carry a hidden message. Bar-
bier, Filiol and Mayoura’s method [12] on the other hand
uses a training set to derive the probability density for in-
dividual bits of the encoded coefﬁcients. If a suspicious
ﬁle does not match these ratios, is is considered mali-
cious. The work by Cogranne, Denemark and Fridrich
[21] uses a roughly similar approach but employs ad-
vanced techniques to derive their empirical model and
test suspicious images against it. Despite their indis-
putable merit, these approaches do not solve the problem
at hand. Their methods are designed to detect anomalies
in the image data – which is disregarded by our approach
– and do not consider information hidden in the struc-
ture of image ﬁles. SAD THUG on the other hand has
demonstrated its ability to very reliably detect this kind
of embedding in the evaluation presented in section 6.
9 Conclusions and Future Work
9.1 Conclusions
In this paper, we presented SAD THUG, an approach for
detecting structural anomalies in image ﬁles caused by
hiding messages in them. It derives an abstract model
for the legitimate structure of container ﬁles from a train-
ing set and veriﬁes whether newly observed ﬁles corre-
spond to that model to classify them as either benign or
malicious. SAD THUG achieved perfect classiﬁcation
across all cross-validation data sets for eight methods and
scored well or very well for the remaining sets. Its mean
false positive ratio was just 0.68% for JPEG ﬁles and
1.12% for PNG ﬁles. Hence, in this paper we presented
a very effective solution to a problem faced by computer
users and administrators around the world today.
9.2 Future Work
Currently, our approach is limited to the most common
embedding methods that change the structure but not the
image data in JPEG and PNG ﬁles. Nevertheless, future
malware could rely on DCT coefﬁcient-based steganog-
raphy in JPEG ﬁles and some malware has been ob-
served abusing PNG image data to hide its communica-
tion. Also, malware could use a combination of struc-
tural and coefﬁcient-based embedding to minimize the
observable effect in each domain. Thus, our approach
should be integrated with an approach or approaches that
can detect embeddings in image data to provide compre-
hensive detection.
In section 6.5, we pointed out that a surprisingly large
fraction of image ﬁles referenced by popular websites
contain additional bytes behind their image data. This
had some effect on SAD THUG’s ability to detect em-
bedding methods with a similar effect on the cover ﬁle’s
structure. As highlighted by this observation – like for all
machine learning-based approaches – attackers could try
to inﬂuence our method’s ability to detect their attacks
by poisoning its training set.
There are several avenues that should be explored to
mitigate this threat. First and foremost, we could simply
remove residual data in the training data set as well as
in ﬁles delivered to systems. This would effectively pre-
vent the establishment of a covert channel using a large
fraction of the methods discussed in this paper. For the
remaining methods, SAD THUG scored perfectly. We
abstained from simulating this approach for our evalua-
tion because that would have completely voided Stegde-
tect’s detection.
Additionally, the training data could be hardened by
not including ﬁles from sites that allow users to up-
load images. Thus, attackers would have to compro-
mise each website they want upload data to. The ef-
fect of this approach could be even increased by using
a cross-validation approach. Here, a given website’s im-
ages would be veriﬁed against an automaton trained only
on other page’s ﬁles, i.e. an attacker would have to com-
promise even more websites based on the construction
of the training data set. Finally, instead of using abso-
lute counts to determine whether a transition has been
observed sufﬁciently often to include it in our model, we
could use weights that depend on the input data. These
weights could for instance be scaled to limit the inﬂu-
ence that either individual ﬁles or sources have on SAD
THUG’s automaton. While SAD THUG is already sur-
prisingly robust against a skewed training set, we believe
that these methods would not only improve its reliability
with respect to classiﬁcation in general but also render
it close to impossible to attack by poisoning its training
set.
10 Acknowledgments
The authors would like to express their gratitude towards
the many people that supported the efforts leading up
to this work. In particular, Daniel Plohmann of Fraun-
hofer FKIE, who does not only preserve the most pro-
found knowledge on reverse engineering and malware of
all kinds and creeds but is also always willing to share
his knowledge and insights. Matthew Smith of the Uni-
versity of Bonn identiﬁed key factors that allowed us
to signiﬁcantly improve our evaluation. Among others,
Elmar Padilla of Fraunhofer FKIE provided some com-
ments and feedback on an earlier version of this paper.
Finally, we would like to thank the anonymous review-
ers for their helpful comments and remarks!
1162    27th USENIX Security Symposium
USENIX Association
References
[1] W32.duqu: The precursor to the next stuxnet version 1.4. Tech.
rep., Symantec, 2011.
[2] Zberp banking trojan: A hybrid of carberp and zeus.
https://blog.emsisoft.com/2014/05/27/zberp-banking-trojan-
a-hybrid-of-carberp-and-zeus/, 2014. EmsiSoft.
devices.
[3] Home routers under attack via malvertising on windows,
https://www.proofpoint.com/us/threat-