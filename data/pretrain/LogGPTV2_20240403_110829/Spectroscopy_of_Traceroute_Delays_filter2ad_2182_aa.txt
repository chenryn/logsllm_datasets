title:Spectroscopy of Traceroute Delays
author:Andre Broido and
Young Hyun and
Kimberly C. Claffy
Spectroscopy of Traceroute Delays
Andre Broido, Young Hyun, and kc claffy
Cooperative Association for Internet Data Analysis,
SDSC, University of California, San Diego
{broido, youngh, kc}@caida.org
Abstract. We analyze delays of traceroute probes, i.e. packets that elicit ICMP
TimeExceeded messages, for a full range of probe sizes up to 9000 bytes as ob-
served on unloaded high-end routers. Our ultimate motivation is to use traceroute
RTTs for Internet mapping of router and PoP (ISP point-of-presence) level nodes,
including potentially gleaning information on equipment models, link technolo-
gies, capacities, latencies, and spatial positions. To our knowledge it is the ﬁrst
study to examine in a reliable testbed setting the detailed statistics of ICMP re-
sponse generation.
We ﬁnd that two fundamental assumptions about ICMP often do not hold in
modern routers, namely that ICMP delays are a linear function of packet size and
that ICMP generation rate is equal to the capacity of the inteface on which probes
are received. The primary causes of these violations appear to be optimizations
that suppress size dependence, e.g. buffer carving, and rate-limiting of internal
ICMP packet and bit rates. Our results suggest that the linear model of packet
delay as a function of packet size merits revisiting for many situations, especially
for packets over 1500 bytes. Our ﬁndings also suggest possibilities of developing
new techniques for bandwidth estimation and router ﬁngerprinting.
1
Introduction
Remote network mapping is usually done via active measurement. Generally a measure-
ment host sends packets that trigger ICMP replies from routers, and the reply information
is integrated into a map. ICMP time exceeded, echo reply and port unreachable responses
are commonly elicited for this purpose.
An ICMP reply carries binary (“host is alive”), discrete (“9 hops away”) and temporal
(“replied in 15 ms”) data. The last of these, per-hop delay (in the form of round trip
time or RTT), is potentially the richest source of information about a router. However,
extracting the useful components from a delay value is difﬁcult, since not only are the
delay summands unavailable but even their statistics and their dependence on other
factors are unknown.
In the common linear model, packet delay is split into three summands, with one
being proportional to packet size. Speciﬁcally, the delay, d, is modeled as follows:
d = ax + b + ξ
(∗)
where a and b are positive real constants, x is the size of the packet or frame, and ξ
is a positive random variable (“residual delay”) that can be arbitrarily close to 0. This
C. Dovrolis (Ed.): PAM 2005, LNCS 3431, pp. 278–291, 2005.
c(cid:1) Springer-Verlag Berlin Heidelberg 2005
Spectroscopy of Traceroute Delays
279
representation implies that d = ax + b is a tight lower bound for all observed delays.
Most network spectroscopy and bandwidth estimation experts assume that delay is a
linear function of packet size, [1] [2] [3].
Our main goal in this study is to test the validity of this linear model, at least with
respect to delays seen in ICMP responses (we do not cover forwarding delay in this
study). Our underlying motivation is to ﬁnd ways of using traceroute RTTs to:
– construct router and PoP-level Internet maps [4] [5]
– obtain metric maps with link latencies and capacities
– enable user-level path diagnosis [6]
– improve the integrity of variable-size bitrate estimation tools [7]; and
– ﬁngerprint routers.
For example, one approach to identifying a PoP would be to look at traceroute paths
that branch between backbone and access routers. Given that the routing to external
destinations is common among all routers within a PoP, return paths to the monitor will
be the same. One could thus use the topological closeness of forward paths together with
the numeric closeness of RTTs to identify interfaces that belong to the same PoP. We
recognize that this aggregation technique requires precise knowledge of typical latencies
across a PoP, as well as how often and for how long ICMP TimeExceeded generation
can be delayed.
A typical traceroute covers 14–20 hops [8], and during a traceroute all but the last
hop responds with an ICMP TimeExceeded packet. The last hop responds with an ICMP
EchoReply or ICMP PortUnreachable. We will discuss properties of delays obtained
from TimeExceeded packets in detail. We hope to report on destination-based (EchoRe-
ply, PortUnreachable) ICMP delays in the future.
The rest of the paper is organized as follows. We review previous work in Sec.2. The
description of our testbed and experiment design is in Sec.3. In Sec.4 we present our
results, and Sec.5 contains discussion and conclusions.
2
Previous Work
Although the need for precise and detailed measurement of packet delays is recognized
by the networking community, equipment constraints render it challenging, and the
literature on this topic is scant. In particular, few researchers have access to high-precision
(sub-microsecond precision) capture cards or to high performance routers representative
of those deployed in Tier-1 ISP backbones.
Further, most previous work does not focus on ICMP delays, per se, but rather on
separating forwarding (that is, router transit) delays from queueing delays [9] or delays
caused by network distance [10]. Bovy, et al., estimated the forwarding delay of three
ofﬁce-class routers to be 224 µs per 100-byte packet per hop [10]. A wide variety of
work in bandwidth estimation, much of it surveyed in [11] and [12], also assumes that
delays are amenable to linear modeling.
280
A. Broido, Y. Hyun, and k. claffy
Researchers from Sprint’s Advanced Technology Laboratory (ATL) did several stud-
ies of instrumented operational routers in a setup close to ours [13], [14], [9], and support
the claim that queueing delay in a well-provisioned network is small enough to effec-
tively allow VOIP deployment [15].
A Light Reading test of Cisco, Juniper and Foundry measured forwarding delays at
line rate (100% load) [16].
Govindan and Paxson [17] and Anagnostakis et al.[18] also study ICMP generation
times, concluding that ICMP-based RTTs do not tend to include excessive (slow path)
delays. Timing jitter in the network around routers complicates the attribution of these
delays, but their value (0.1–0.3 ms) is comparable to those in [10] and to ours.
The goal of [18] is to infer link latencies and queueing from ICMP timestamp differ-
ences at both ends of a link (see also [6])1. The authors found routers (5 in 20 studied)
with 95th percentiles of ICMP Timestamp delay around 10 ms; 2 had 95th percentiles at
80 ms. Remote link estimation is quite daunting in the face of such high uncertainty. For
comparison, more than 99.6% of our TimeExceeded delays up to 9000 bytes are under 1
ms, except a few (0.4%) that are rate-limited by Juniper routers to incur approximately
10 ms delays.
Donnelly [20] and Mochalski et al.[21] demonstrate a piecewise linear size depen-
dence for router/switch transit times, which shows a noticeable rate change at 512 bytes.
This phenomenon is similar to our ICMP delay rate discontinuities occurring around
1500 bytes.
To the best of our knowledge, precision timestamping matching modern router speeds
is available only with Dag cards from the Waikato group [22] and Endace [23]. The
latest models (4.xx) can reach sub-microsecond accuracy when synchronized to GPS or
CDMA [20] [24].
Some of the available studies use the now older model (3.xx) of Dag cards, with 5–6
µs precision [13] and 53-byte uncertainty with respect to the portion of the packet that
is timestamped. Despite these limitations, the results obtained in [9], [13], and [14] have
served as inspiration for this work.
3 Data Collection
We collected our measurements in CAIDA’s high-speed testbed [25] [12] which includes
(Fig.1): two IBM eServers (running FreeBSD 4.8); a Dell Gigabit Ethernet switch;
Juniper, Cisco and Foundry routers; an OC48 link between the Juniper and Cisco; and
Gigabit Ethernet links between all other devices. The testbed’s path MTU is 9000 bytes.
We tap both links at the Cisco router (OC48 and gigE) using NetOptics splitters, and
capture packets with Dag cards. The Foundry router doubles as a 16-port switch that
connects all equipment in the lab to the Internet and to CAIDA’s production network via
100 M Ethernet.
We perform traceroutes on herald or post, and use CoralReef [26] utilities to
capture, process, and extract delays from packets. A command line on herald of:
traceroute -q 4 -M 2 -m 3 -w 2 -P udp -t 64 post 214
1 [19] suggests using traceroute delays for both purposes.
Spectroscopy of Traceroute Delays
281
oc48
cisco
foundry
post
juniper
highdell
herald
Fig. 1. Lab diagram. Equipment (clockwise): IBM eServer herald, Dell PowerConnect 5212
switch, Juniper M20 router, Cisco 12008 router, Foundry BigIron 8000 router/switch, IBM eServer
post, Links: oc48 (Juniper to Cisco); GigabitEthernet (all other links). For details, see [12] (this
volume)
speciﬁes series of 4 probes (q) to hops 2 (M) through 3 (m), using a timeout of 2 sec
(w), UDP2 (P), TOS of 64 (t) and packet size 214 bytes. Its output looks like (numbers
from real data):
2 cisco-oc48 0.221 ms 0.154 ms 0.254 ms 0.168 ms
3 foundry
0.217 ms 0.226 ms 0.230 ms 0.227 ms
Our experiments combine UDP and ICMP traceroutes with 9 TOS values (0, 1, 2, 4,
8, 16, 32, 64, 128), and sizes 64-9000 bytes, for a total of 160866 (2*9*8937) traceroutes,
each probing 2 hops with 4 packets at each hop. The router conﬁguration guarantees that
the return path for an ICMP packet is symmetric with the forward path.
Traceroute dynamics determine the intervals between probes in our experiments
(Fig.2). We call a time lag between two successive packets targeting the same interface
an interprobe gap (IPG). When traceroute probes one hop, it sends the next packet
immediately after receiving an ICMP TimeExceeded for the previous packet. These
probes succeed each other within a few hundred microseconds (under 1 ms). The next
traceroute command will probe the same hop after an OS scheduling quantum (10 ms)
and after probing a subsequent hop (several milliseconds); in that case, the probes are
separated by 10-20 ms. When a TimeExceeded is not generated or is lost before the
source host receives it (the loss is in fact very rare in our experiments) the traceroute
script waits for a 2-second timeout. This gap can affect the delay of the packet that
follows, e.g. through route cache latency if the address has been ﬂushed from the cache.
Parameter Scan. We walk the experiment design space (NS packet sizes, NP proto-
cols, ND destinations, NT TOSes, etc.) using a pseudo-random scan. Scanning of other
parameters (hop number, packets/hop) is a part of typical traceroute operation. We take
the product of dimensions m = NSNP NDNT . . . and ﬁnd a prime p > m. Then we
ﬁnd a primitive root r mod p near
p, and try all combinations of parameter values as
follows. For experiment k, 1 ≤ k ≤ m, we use ak = rk mod p in mixed-radix notation
to get indices S (index for size), P (index for protocol), D (index for destination):
√
2 Recall that traceroute sends UDP or ICMP packets, but always gets back ICMP. Our data
contains half UDP and half ICMP probes. The analysis presented here does not distinguish
between UDP and ICMP probes, or between TOS values.
282
A. Broido, Y. Hyun, and k. claffy
Fig. 2. Clustering of interprobe gaps for the Cisco router (OC48 and gigE): microsecond range,
10–20 ms, 2 sec. The higher fraction of 2-sec gaps on the Cisco gigE (upper curve) is caused by
the Juniper not generating some ICMP messages
S = akmodNS, P = [ak/NS]modNP , D = [ak/(NSNP )]modND, etc. (ak ≤ m)
Example. For two packet sizes (NS = 2) and two protocols (NP = 2), m = NSNP = 4
and p = 5; r = 3 is a possible choice of a primitive root. Combinations of packet size
(e.g. (40, 1500) indexed by (0,1)) and protocol ((UDP, ICMP) indexed by (0,1)) follow
each other in sequence3 (31, 32, 33, 34)mod5 = (3, 4, 2, 1) = (11, 00, 10, 01)2, where
11 corresponds to (ICMP, 1500), and so on.
This approach, inspired by turbo codes [27] and Monte-Carlo integration techniques,
is robust against outages, whether at the beginning (Dag cards warming up) or at the
end (too small capture interval, disk space). All parameter values appear close to the
start of experiment (as opposed to with a lexicographic scan), which allows us to debug
problems with each dimension or value, e.g. too high chance of a timeout.
Table 1 presents a description of the data in terms of destinations, experiment dura-
tion, number of traceroutes and number of probes (packets). The second half of the table
is a breakdown of the probes by interprobe gap (IPG). The longer duration of the second
(PCJ) experiment is due to a higher level of ICMP non-generation on Juniper (12140 or
2% of all probes) which results in more occurrences of the 2-sec timeouts. This extra
10K (12140-2310) of timeouts increases the experiment duration by about 5.5 hours. In
addition, Juniper’s generation bitrate of TimeExceeded (at 8 ns/bit) is the slowest of all
three routers (Table 2). ICMP bitrate limiting causes many packets in the 7000–9000
byte range (73K or 11%) to arrive more than 1 ms later than the previous probe. This lag
applies to packets 2–4. Packet 1 is always delayed by an OS scheduling quantum of 10
ms, which explains the large number of packets (about 25% of the total) in the 10-100
3 In this special case, one can read parameters from the two rightmost bits of rkmodp.
Spectroscopy of Traceroute Delays
283
Table 1. Experimental data and intereprobe gaps
Destination
Date
Code Source
HCF herald Cisco, Foundry 2004-09-10 00:00 02:00
PCJ post
Cisco, Juniper 2004-09-12 00:30 08:00
Start End Traceroutes Packets sent
1287 K
1287 K
160866
160866
i/face IPG1s
Code Source Dest.
HCF herald Cisco OC48
HCF herald Foundry gigE
Cisco
PCJ post
gigE
Juniper OC48
PCJ post
482546
20
477557
539
482570
19
389211 72793
158587
160747
148733
157178
0
0
1
1
Total
2310 643463
2310 641153
12140 643463
12140 631323
ms bin. The drop rate (non-generation) for the Foundry is under 0.4%, and the Cisco
returns all 643464 probes, i.e. has 0% drop rate.
4 Results
Table 2 provides a lower bound for size dependence parameters from equation d =
ax + b: a (slope) and b (intercept) of TimeExceeded delay. We apply the O(N) linear
programming (LP) algorithm of [28] to delays observed at the Cisco and Juniper OC48
interfaces for all packet sizes, and to those at the Cisco and Foundry gigE interfaces
separately for ranges ≤ 1500 and > 1500. This latter choice is based on the fact that