the novel concept of directional noise, which can be used to reduce
the impact of the noise on the utility of the query answer. Finally,
we evaluate our approach experimentally for three matrix-valued
query functions on three privacy-sensitive datasets, and the results
show that our approach can provide the utility improvement over
existing methods in all of the experiments.
ACKNOWLEDGEMENT
The authors would like to thank the reviewers for their valuable
feedback that helped improve the paper. This work was supported
in part by the National Science Foundation (NSF) under Grants
CNS-1553437, CCF-1617286, and CNS-1702808; an Army Research
Office YIP Award; and faculty research awards from Google, Cisco,
Intel, and IBM.
REFERENCES
[1] Herve Abdi. 2007. Singular value decomposition (SVD) and generalized singular
value decomposition. Encyclopedia of Measurement and Statistics. Thousand
Oaks (CA): Sage (2007), 907–912.
[2] Gergely Acs, Claude Castelluccia, and Rui Chen. 2012. Differentially private
histogram publishing through lossy compression. In ICDM. IEEE.
[3] P. I. Alatalo, H. M. Koivisto, J. P. Hietala, K. S. Puukka, R. Bloigu, and O. J. Niemela.
2008. Effect of moderate alcohol consumption on liver enzymes increases with
increasing body mass index. AJCN 88, 4 (Oct 2008), 1097–1103.
[4] Davide Bacciu, Paolo Barsocchi, Stefano Chessa, Claudio Gallicchio, and Alessio
Micheli. 2014. An experimental characterization of reservoir computing in
ambient assisted living applications. Neural Computing and Applications 24, 6
(2014), 1451–1464.
[5] Robert M. Bell, Yehuda Koren, and Chris Volinsky. 2008. The bellkor 2008
solution to the netflix prize. Statistics Research Department at AT&T Research
(2008).
[6] Christopher M. Bishop. 2006. Pattern recognition. Machine Learning 128 (2006).
[7] Jeremiah Blocki, Avrim Blum, Anupam Datta, and Or Sheffet. 2012. The johnson-
lindenstrauss transform itself preserves differential privacy. In FOCS. IEEE.
privacy: the SuLQ framework. In PODS. ACM.
to noninteractive database privacy. JACM 60, 2 (2013), 12.
[10] Avrim Blum and Aaron Roth. 2013. Fast private data release algorithms for sparse
queries. Springer, 395–410.
[11] Thee Chanyaswad, Alex Dytso, H Vincent Poor, and Prateek Mittal. 2018. A
Differential Privacy Mechanism Design Under Matrix-Valued Query. arXiv
preprint arXiv:1802.10077 (2018).
[12] Thee Chanyaswad, Changchang Liu, and Prateek Mittal. 2017. Coupling Random
Orthonormal Projection with Gaussian Generative Model for Non-Interactive
Private Data Release. arXiv:1709.00054 (2017).
differentially private principal components. In NIPS.
procedure for differentially private machine learning. In NIPS.
Yu. 2012. Differentially private spatial decompositions. In ICDE. IEEE.
[15] Graham Cormode, Cecilia Procopiuc, Divesh Srivastava, Entong Shen, and Ting
[13] Kamalika Chaudhuri, Anand Sarwate, and Kaushik Sinha. 2012. Near-optimal
[14] Kamalika Chaudhuri and Staal A. Vinterbo. 2013. A stability-based validation
[8] Avrim Blum, Cynthia Dwork, Frank McSherry, and Kobbi Nissim. 2005. Practical
[9] Avrim Blum, Katrina Ligett, and Aaron Roth. 2013. A learning theory approach
Springer.
[16] A. Philip Dawid. 1981. Some matrix-variate distribution theory: notational
[17] Wei-Yen Day and Ninghui Li. 2015. Differentially private publishing of high-
considerations and a Bayesian application. Biometrika 68, 1 (1981), 265–274.
dimensional data using sensitivity control. In CCS. ACM.
[18] Diogo Ayres de Campos, Joao Bernardes, Antonio Garrido, Joaquim Marques de
Sa, and Luis Pereira-Leite. 2000. SisPorto 2.0: a program for automated analysis
of cardiotocograms. Journal of Maternal-Fetal Medicine 9, 5 (2000), 311–318.
and statistical minimax rates. In FOCS. IEEE.
Journal of statistical computation and simulation 64, 2 (1999), 105–123.
[19] John C. Duchi, Michael I. Jordan, and Martin J. Wainwright. 2013. Local privacy
[20] Pierre Dutilleul. 1999. The MLE algorithm for the matrix normal distribution.
[24] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. 2006. Cali-
[25] Cynthia Dwork and Aaron Roth. 2014. The algorithmic foundations of differen-
[26] Cynthia Dwork, Guy N. Rothblum, and Salil Vadhan. 2010. Boosting and differ-
[21] Cynthia Dwork. 2006. Differential privacy. Springer, 1–12.
[22] Cynthia Dwork. 2008. Differential privacy: A survey of results. In TAMC.
[23] Cynthia Dwork, Krishnaram Kenthapadi, Frank McSherry, Ilya Mironov, and
Moni Naor. 2006. Our data, ourselves: Privacy via distributed noise generation.
In EUROCRYPT. Springer.
brating noise to sensitivity in private data analysis. In TCC. Springer.
tial privacy. FnT-TCS 9, 3-4 (2014), 211–407.
ential privacy. In FOCS. IEEE.
[27] Cynthia Dwork, Kunal Talwar, Abhradeep Thakurta, and Li Zhang. 2014. Ana-
lyze gauss: optimal bounds for privacy-preserving principal component analysis.
In STOC. ACM.
[28] Stephen E. Fienberg, Alessandro Rinaldo, and Xiaolin Yang. 2010. Differential
privacy and the risk-utility tradeoff for multi-dimensional contingency tables.
In PSD. Springer.
[29] Daniel Foreman-Mackey, David W Hogg, Dustin Lang, and Jonathan Goodman.
2013. emcee: the MCMC hammer. Publications of the Astronomical Society of the
Pacific 125, 925 (2013), 306.
[30] Richard Forsyth and Roy Rada. 1986. Machine learning: applications in expert
systems and information retrieval. Halsted Press.
[31] Matthew Fredrikson, Eric Lantz, Somesh Jha, Simon Lin, David Page, and
Thomas Ristenpart. 2014. Privacy in Pharmacogenetics: An End-to-End Case
Study of Personalized Warfarin Dosing.. In USENIX Security.
statistical learning. Vol. 1. Springer series in statistics New York.
Monte Carlo in practice. CRC press.
Springer Science & Business Media.
[32] Jerome Friedman, Trevor Hastie, and Robert Tibshirani. 2001. The elements of
[33] Walter R. Gilks, Sylvia Richardson, and David Spiegelhalter. 1995. Markov chain
[34] Chris Godsil and Gordon F. Royle. 2013. Algebraic graph theory. Vol. 207.
[35] Gene H. Golub and Charles F. Van Loan. 1996. Matrix computations. Johns
[36] AK Gupta and T. Varga. 1992. Characterization of matrix variate normal distri-
Hopkins University, Press, Baltimore, MD, USA (1996), 374–426.
butions. Journal of Multivariate Analysis 41, 1 (1992), 80–88.
algorithm for differentially private data release. In NIPS.
[38] Moritz Hardt and Aaron Roth. 2012. Beating randomized response on incoherent
matrices. In Proceedings of the forty-fourth annual ACM symposium on Theory of
computing. ACM, 1255–1268.
[39] Moritz Hardt and Aaron Roth. 2013. Beyond worst-case analysis in private
singular vector computation. In STOC. ACM.
[40] Moritz Hardt and Aaron Roth. 2013. Beyond worst-case analysis in private singu-
lar vector computation. In Proceedings of the forty-fifth annual ACM symposium
on Theory of computing. ACM, 331–340.
[41] Moritz Hardt and Guy N. Rothblum. 2010. A multiplicative weights mechanism
for privacy-preserving data analysis. In FOCS. IEEE.
[42] Moritz Hardt and Kunal Talwar. 2010. On the geometry of differential privacy.
In Proceedings of the forty-second ACM symposium on Theory of computing. ACM,
705–714.
[43] Michael Hay, Ashwin Machanavajjhala, Gerome Miklau, Yan Chen, and Dan
Zhang. 2016. Principled evaluation of differentially private algorithms using
DPBench. In SIGMOD/PODS. ACM.
[44] Michael Hay, Vibhor Rastogi, Gerome Miklau, and Dan Suciu. 2010. Boosting
the accuracy of differentially private histograms through consistency. PVLDB 3,
1-2 (2010), 1021–1032.
[45] Roger A. Horn and Charles R. Johnson. 1991. Topics in matrix analysis, 1991.
[37] Moritz Hardt, Katrina Ligett, and Frank McSherry. 2012. A simple and practical
Cambridge University Press 37 (1991), 39.
university press.
[46] Roger A. Horn and Charles R. Johnson. 2012. Matrix analysis. Cambridge
[47] John F. Hughes, Andries Van Dam, James D. Foley, and Steven K. Feiner. 2014.
Computer graphics: principles and practice. Pearson Education.
[48] Anis Iranmanesh, M. Arashi, and SMM Tabatabaey. 2010. On conditional appli-
cations of matrix variate normal distribution. Iranian Journal of Mathematical
Sciences and Informatics 5, 2 (2010), 33–43.
[49] X. Jiang, Z. Ji, S. Wang, N. Mohammed, S. Cheng, and L. Ohno-Machado. 2013.
Differential-Private Data Publishing Through Component Analysis. Trans. on
Data Privacy 6, 1 (Apr 2013), 19–34.
[50] Noah Johnson, Joseph P. Near, and Dawn Song. 2017. Practical Differential
Privacy for SQL Queries Using Elastic Sensitivity. arXiv:1706.09479 (2017).
115–128.
[51] Ian T. Jolliffe. 1986. Principal Component Analysis and Factor Analysis. Springer,
[52] Eric Jones, Travis Oliphant, Pearu Peterson, et al. 2001–. SciPy: Open source
scientific tools for Python. http://www.scipy.org/
[53] Michael Kapralov and Kunal Talwar. 2013. On differentially private low rank
approximation. In SODA. SIAM.
[54] Krishnaram Kenthapadi, Aleksandra Korolova, Ilya Mironov, and Nina Mishra.
2012. Privacy via the johnson-lindenstrauss transform. arXiv:1204.2606 (2012).
[55] S. Y. Kung. 2014. Kernel Methods and Machine Learning. Cambridge University
Press.
[56] Beatrice Laurent and Pascal Massart. 2000. Adaptive estimation of a quadratic
functional by model selection. Annals of Statistics (2000), 1302–1338.
[57] Chao Li, Michael Hay, Gerome Miklau, and Yue Wang. 2014. A data-and
workload-aware algorithm for range queries under differential privacy. PVLDB
7, 5 (2014), 341–352.
[58] Chao Li, Michael Hay, Vibhor Rastogi, Gerome Miklau, and Andrew McGregor.
2010. Optimizing linear counting queries under differential privacy. In PODS.
ACM.
[59] Chao Li and Gerome Miklau. 2012. An adaptive mechanism for accurate query
answering under differential privacy. PVLDB 5, 6 (2012), 514–525.
[60] Yang D. Li, Zhenjie Zhang, Marianne Winslett, and Yin Yang. 2011. Compressive
mechanism: Utilizing sparse representation in differential privacy. In WPES.
ACM.
[61] M. Lichman. 2013. UCI Machine Learning Repository. http://archive.ics.uci.edu/
[62] Fang Liu. 2016. Generalized gaussian mechanism for differential privacy.
arXiv:1602.06028 (2016).
(2016).
[63] Fang Liu. 2016. Model-based differential private data synthesis. arXiv:1606.08052
[64] Min Lyu, Dong Su, and Ninghui Li. 2016. Understanding the sparse vector
[66] Frank McSherry and Ilya Mironov. 2009. Differentially private recommender
[65] James McDermott and Richard S. Forsyth. 2016. Diagnosing a disorder in a
technique for differential privacy. arXiv:1603.01699 (2016).
classification benchmark. Pattern Recognition Letters 73 (2016), 41–43.
systems: building privacy into the net. In KDD. ACM.
privacy. In FOCS. IEEE.
for singular values using traces. Linear Algebra Appl. 210 (1994), 227–254.
[67] Frank McSherry and Kunal Talwar. 2007. Mechanism design via differential
[68] Jorma Kaarlo Merikoski, Humberto Sarria, and Pablo Tarazaga. 1994. Bounds
[69] Carl D. Meyer. 2000. Matrix analysis and applied linear algebra. Vol. 2. Siam.
[70] Kevin P. Murphy. 2012. Machine Learning: A Probabilistic Perspective. The MIT
[71] Arvind Narayanan and Vitaly Shmatikov. 2008. Robust de-anonymization of
Press.
ml.
[72] Netflix. 2009. Netflix Prize. http://www.netflixprize.com/. Accessed on:
large sparse datasets. In S&P. IEEE.
08/10/2017.
[73] Truc T. Nguyen. 1997. A note on matrix variate normal distribution. Journal of
Multivariate Analysis 60, 1 (1997), 148–153.
[74] Aleksandar Nikolov. 2015. An improved private mechanism for small databases.
In International Colloquium on Automata, Languages, and Programming. Springer,
1010–1021.
[75] Aleksandar Nikolov, Kunal Talwar, and Li Zhang. 2013. The geometry of
[76] Kobbi Nissim, Sofya Raskhodnikova, and Adam Smith. 2007. Smooth sensitivity
differential privacy: the sparse and approximate cases. In STOC. ACM.
and sampling in private data analysis. In STOC. ACM.
[77] Travis E Oliphant. 2006. A guide to NumPy. Vol. 1. Trelgol Publishing USA.
[78] Fabian Pedregosa, GaÃńl Varoquaux, Alexandre Gramfort, Vincent Michel,
Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss,
and Vincent Dubourg. 2011. Scikit-learn: Machine learning in Python. JMLR
12, Oct (2011), 2825–2830.
[79] Davide Proserpio, Sharon Goldberg, and Frank McSherry. 2014. Calibrating
data to sensitivity in private data analysis: a platform for differentially-private
analysis of weighted datasets. PVLDB 7, 8 (2014), 637–648.
grids for geospatial data. In ICDE. IEEE.
[81] Wahbeh Qardaji, Weining Yang, and Ninghui Li. 2013. Understanding hier-
archical methods for differentially private histograms. PVLDB 6, 14 (2013),
1954–1965.
[82] C. Radhakrishna Rao. 1964. The use and interpretation of principal component
analysis in applied research. Sankhya: The Indian Journal of Statistics, Series A
(1964), 329–358.
[80] Wahbeh Qardaji, Weining Yang, and Ninghui Li. 2013. Differentially private
[83] C. Costa Santos, JoÃčo Bernardes, Paul MB VitÃąnyi, and Luis Antunes. 2006.
[84] Jonathan Sondow and Eric W. Weisstein. 2017. Harmonic Number. http://
Clustering fetal heart rate tracings by compression. In CBMS. IEEE.
mathworld.wolfram.com/HarmonicNumber.html.
[85] William Carlisle Thacker. 1989. The role of the Hessian matrix in fitting models
to measurements. JGR: Oceans 94, C5 (1989), 6177–6196.
(2014), 47.
[86] Jalaj Upadhyay. 2014. Circulant matrices and differential privacy. analysis 16
[87] Jalaj Upadhyay. 2014.
Randomness Efficient Fast-Johnson-Lindenstrauss
Transform with Applications in Differential Privacy and Compressed Sensing.
arXiv:1410.2470 (2014).
& business media.
[88] Vladimir Vapnik. 2013. The nature of statistical learning theory. Springer science
[89] J. von Neumann. 1937. Some matrix inequalities and metrization of metric space.
[90] DJ De Waal. 2006. Matrix-Valued Distributions. Encyclopedia of statistical
[91] Steven R. White. 1992. Density matrix formulation for quantum renormalization
[92] Wikipedia. 2017. Matrix (mathematics). https://en.wikipedia.org/wiki/Matrix_
Tomsk Univ.Rev 1 (1937), 286–296.
sciences (2006).
groups. PRL 69, 19 (1992), 2863.
(mathematics).
[93] Xiaokui Xiao, Gabriel Bender, Michael Hay, and Johannes Gehrke. 2011. iReduct:
Differential privacy with reduced relative errors. In Proceedings of the 2011 ACM
SIGMOD International Conference on Management of data. ACM, 229–240.
[94] Xiaokui Xiao, Guozhang Wang, and Johannes Gehrke. 2011. Differential privacy
via wavelet transforms. IEEE TKDE 23, 8 (2011), 1200–1214.
[95] Yonghui Xiao, Li Xiong, Liyue Fan, and Slawomir Goryczka. 2012. DPCube:
differentially private histogram release through multidimensional partitioning.
arXiv:1202.5358 (2012).
[96] Chugui Xu, Ju Ren, Yaoxue Zhang, Zhan Qin, and Kui Ren. 2017. DPPro:
Differentially Private High-Dimensional Data Release via Random Projection.
IEEE TIFS (2017).
[97] Jia Xu, Zhenjie Zhang, Xiaokui Xiao, Yin Yang, Ge Yu, and Marianne Winslett.
2013. Differentially private histogram publication. The VLDB Journal 22, 6
(2013), 797–822.
[98] Ganzhao Yuan, Yin Yang, Zhenjie Zhang, and Zhifeng Hao. 2016. Convex
optimization for linear query processing under approximate differential privacy.
In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining. ACM, 2005–2014.
[99] Ganzhao Yuan, Zhenjie Zhang, Marianne Winslett, Xiaokui Xiao, Yin Yang,
and Zhifeng Hao. 2012. Low-rank mechanism: optimizing batch queries under
differential privacy. PVLDB 5, 11 (2012), 1352–1363.
[100] Ganzhao Yuan, Zhenjie Zhang, Marianne Winslett, Xiaokui Xiao, Yin Yang, and
Zhifeng Hao. 2015. Optimizing batch linear queries under exact and approximate
differential privacy. ACM Transactions on Database Systems (TODS) 40, 2 (2015),
11.
[101] Xiaojian Zhang, Rui Chen, Jianliang Xu, Xiaofeng Meng, and Yingtao Xie. 2014.
Towards accurate histogram publication under differential privacy. In SDM.
SIAM.
[102] Shuheng Zhou, Katrina Ligett, and Larry Wasserman. 2009. Differential privacy
with compression. In ISIT. IEEE.
A FULL PROOF OF (ϵ, δ)-DIFFERENTIAL
PRIVACY
We present the full proof of the sufficient condition for the MVG
mechanism to guarantee (ϵ, δ)-differential privacy presented in
Theorem 3 here.
Proof. The MVG mechanism guarantees differential privacy if
for every pair of neighboring datasets {X1, X2} and all possible
measurable sets S ⊆ Rm×n,
Pr[f (X1) + Z ∈ S] ≤ exp(ϵ) Pr[f (X2) + Z ∈ S] .
The proof now follows by observing that (Lemma 4),
Z = WΣΛ1/2
and defining the following events:
Σ NΛ1/2
Ψ WT
Ψ,
R1 = {N : ∥N∥2
F ≤ ζ(δ)2}, R2 = {N : ∥N∥2
F > ζ(δ)2},
where ζ(δ) is defined in Theorem 2. Next, observe that
Pr[f (X1) + Z ∈ S]
= Pr[({ f (X1) + Z ∈ S} ∩ R1) ∪ ({ f (X1) + Z ∈ S} ∩ R2)]
≤ Pr[{ f (X1) + Z ∈ S} ∩ R1] + Pr[{ f (X1) + Z ∈ S} ∩ R2] ,
where the last inequality follows from the union bound. By Theorem
2 and the definition of the set R2, we have,
Pr[{ f (X1) + Z ∈ S} ∩ R2] ≤ Pr[R2] = 1 − Pr[R1] ≤ δ .
In the rest of the proof, we find sufficient conditions for the
following inequality to hold:
Pr[f (X1) + Z ∈ (S ∩ R1)] ≤ exp(ϵ) Pr[f (X2) + Z ∈ S] .
this would complete the proof of differential privacy guarantee.
Using the definition of MVGm,n(0, Σ, Ψ) (Definition 2), this is
satisfied if we have,
{− 1
2 tr[Ψ−1(Y−f (X1))T Σ−1(Y−f (X1))]}
dY ≤
e
{− 1
2 tr[Ψ−1(Y−f (X2))T Σ−1(Y−f (X2))]}
dY.
S∩R1
e
2 tr[Ψ−1(Y−f (X2))T Σ−1(Y−f (X2))]}
By inserting exp{− 1
2 tr[Ψ−1(Y−f (X2))T Σ−1(Y−f (X2))]} inside the inte-
exp{− 1
gral on the left side, it is sufficient to show that
2tr[Ψ−1(Y − f (X1))T Σ−1(Y − f (X1))]}
2tr[Ψ−1(Y − f (X2))T Σ−1(Y − f (X2))]} ≤ exp(ϵ),
exp{− 1
exp{− 1
for all Y ∈ S∩ R1. With some algebraic manipulations, the left hand
side of this condition can be expressed as,
∫
∫
S∩R1
eϵ
2tr[Ψ−1YT Σ−1(f (X2) − f (X1))