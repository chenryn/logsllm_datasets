35
DFDs show how data moves logically through the system and allows the identification data entering or leav-
ing the system along with the storage of data and the flow of control through these components. Trust bound-
aries show any location where the level of trust changes. Process components show where data is processed, 
such as web servers, application servers, and database servers. Entry points show where data enters the sys-
tem (i.e. input fields, methods) and exit points are where it leaves the system (i.e. dynamic output, methods), 
respectively. Entry and exit points define a trust boundary.
6.9.2 Step 2: Determine and rank threats
Critical to the identification of threats is using a threat categorization methodology. A threat categorization 
such as STRIDE can be used, or the Application Security Frame (ASF) that defines threat categories such as Au-
diting & Logging, Authentication, Authorization, Configuration Management, Data Protection in Storage and 
Transit, Data Validation and Exception Management. 
The goal of the threat categorization is to help identify threats both from the attacker (STRIDE) and the defen-
sive perspective (ASF). DFDs produced in step 1 help to identify the potential threat targets from the attacker’s 
perspective, such as data sources, processes, data flows, and interactions with users. These threats can be 
identified further as the roots for threat trees; there is one tree for each threat goal. 
From the defensive perspective, ASF categorization helps to identify the threats as weaknesses of security 
controls for such threats. Common threat-lists with examples can help in the identification of such threats. Use 
and abuse cases can illustrate how existing protective measures could be bypassed, or where a lack of such 
protection exists. 
The determination of the security risk for each threat can be determined using a value-based risk model such 
as DREAD or a less subjective qualitative risk model based upon general risk factors (e.g. likelihood and im-
pact).
The first step in the determination of threats is adopting a threat categorization. A threat categorization pro-
Methodology
The multiple process shape is used to present a collection of 
subprocesses. The multiple process can be broken down into 
its subprocesses in another DFD.
MULTIPLE PROCESS
The data flow shape represents data movement within the 
application. The direction of the data movement is represent-
ed by the arrow.
DATA FLOW
The privilege boundary shape is used to represent the 
change of privilege levels as the data flows through the 
application.
PRIVILEGE BOUNDARY
The data store shape is used to represent locations where 
data is stored. Data stores do not modify the data, they only 
store data.
DATA STORE
36
vides a set of threat categories with corresponding examples so that threats can be systematically identified 
in the application in a structured and repeatable manner.
STRIDE
Threat lists based on the STRIDE model are useful in the identification of threats with regards to the attacker 
goals. For example, if the threat scenario is attacking the login, would the attacker brute force the password to 
break the authentication? If the threat scenario is to try to elevate privileges to gain another user’s privileges, 
would the attacker try to perform forceful browsing?
A threat categorization such as STRIDE is useful in the identification of threats by classifying attacker goals 
such as shown in table 8.
It is vital that all possible attack vectors should be evaluated from the attacker’s point of view. For example, the login 
page allows sending authentication credentials, and the input data accepted by an entry point has to validate for 
potential malicious input to exploit vulnerabilities such as SQL injection, cross site scripting, and buffer overflows. 
Additionally, the data flow passing through that point has to be used to determine the threats to the entry points 
to the next components along the flow. If the following components can be regarded critical (e.g. the hold sensitive 
data), that entry point can be regarded more critical as well. In an end to end data flow the input data (i.e. username 
and password) from a login page, passed on without validation, could be exploited for a SQL injection attack to ma-
nipulate a query for breaking the authentication or to modify a table in the database.
Exit points might serve as attack points to the client (e.g. XSS vulnerabilities) as well for the realization of information 
disclosure vulnerabilities. In the case of exit points from components handling confidential data (e.g. data access 
components), any exit points lacking security controls to protect the confidentiality and integrity can lead to disclo-
sure of such confidential information to an unauthorized user.
In many cases threats enabled by exit points are related to the threats of the corresponding entry point. In the login 
example, error messages returned to the user via the exit point might allow for entry point attacks, such as account 
Methodology
STRIDE
Explanation
Spoofing
“Identity spoofing” is a key risk for applications that have many users but provide a single execution context at the ap-
plication and database level. In particular, users should not be able to become any other user or assume the attributes 
of another user.
Tampering
Users can potentially change data delivered to them, return it, and thereby potentially manipulate client-side valida-
tion, GET and POST results, cookies, HTTP headers, and so forth. The application should also carefully check data re-
ceived from the user and validate that it is sane and applicable before storing or using it.
Repudiation
Users may dispute transactions if there is insufficient auditing or recordkeeping of their activity. For example, if a user 
says they did not make a financial transfer, and the functionality cannot track his/her activities through the application, 
then it is extremely likely that the transaction will have to be written off as a loss.
Information Disclosure
Denial of Service
Elevation of Privilege
Users are rightfully wary of submitting private details to a system. Is possible for an attacker to publicly reveal user data 
at large, whether anonymously or as an authorized user?
Application designers should be aware that their applications may be subject to a denial of service attack. The use of 
expensive resources such as large files, complex calculations, heavy-duty searches, or long queries should be reserved 
for authenticated and authorized users, and not available to anonymous users.
If an application provides distinct user and administrative roles, then it is vital to ensure that the user cannot elevate 
his/her role to a higher privilege one.
Table 8: Explanation Of The Stride Attributes
37
Methodology
harvesting (e.g. username not found), or SQL injection (e.g. SQL exception errors). From the defensive perspective, 
the identification of threats driven by security control categorization such as ASF allows a threat analyst to focus on 
specific issues related to weaknesses (e.g. vulnerabilities) in security controls. Typically the process of threat identi-
fication involves going through iterative cycles where initially all the possible threats in the threat list that apply to 
each component are evaluated. At the next iteration, threats are further analyzed by exploring the attack paths, the 
root causes (e.g. vulnerabilities) for the threat to be exploited, and the necessary mitigation controls (e.g. counter-
measures). 
Once common threats, vulnerabilities, and attacks are assessed, a more focused threat analysis should take in con-
sideration use and abuse cases. By thoroughly analyzing the use scenarios, weaknesses can be identified that could 
lead to the realization of a threat. Abuse cases should be identified as part of the security requirement engineering 
activity. These abuse cases can illustrate how existing protective measures could be bypassed, or where a lack of such 
protection exists.  Finally, it is possible to bring all of this together by determining the types of threat to each compo-
nent of the decomposed system. This can be done by repeating the techniques already discussed on a lower level 
threat model, again using a threat categorization such as STRIDE or ASF, the use of threat trees to determine how the 
threat can be exposed by vulnerability, and use and misuse cases to further validate the lack of a countermeasure to 
mitigate the threat.
Microsoft DREAD threat-risk ranking model 
In the Microsoft DREAD threat-risk ranking model, the technical risk factors for impact are Damage and Affected Us-
ers, while the ease of exploitation factors are Reproducibility, Exploitability and Discoverability. This risk factorization 
allows the assignment of values to the different influencing factors of a threat. 
To determine the ranking of a threat, the threat analyst has to answer basic questions for each factor of risk, for ex-
ample:
The impact mainly depends on the damage potential and the extent of the impact, such as the number of 
components that are affected by a threat.
Damage
How big would the damage be if the attack succeeded?
Can an attacker completely take over and manipulate the system?
Can an attacker crash the system?
Reproducibility
How easy is it to reproduce an attack to work?
Can the exploit be automated?
Exploitability
How much time, effort, and expertise is needed to exploit the threat? 
Does the attacker need to be authenticated? 
Affected Users
Discoverability
If a threat were exploited, what percentage of users would be affected?
Can an attacker gain administrative access to the system?
How easy is it for an attacker to discover this threat?
DREAD
Questions
Table 9: Explanation Of The Dread Attributes
38
These questions help in the calculation of the overall risk values by assigning qualitative values such as High, 
Medium and Low to Likelihood and Impact factors. In this case, using qualitative values, rather than numeric 
ones like in the case of the DREAD model, help avoid the ranking becoming overly subjective.
6.9.3 Step 3: Determine countermeasures and mitigation. 
A lack of protection against a threat might indicate a vulnerability whose risk exposure could be mitigated 
with the implementation of a countermeasure. Such countermeasures can be identified using threat-counter-
measure mapping lists. Once a risk ranking is assigned to the threats, it is possible to sort threats from the high-
est to the lowest risk, and prioritize the mitigation effort, such as by responding to such threats by applying the 
identified countermeasures. 
The risk mitigation strategy might involve evaluating these threats from the business impact that they pose 
and establishing countermeasures (or design changes) to reduce the risk. 
Other options might include accepting the risk, assuming the business impact is acceptable because of com-
pensating controls, informing the user of the threat, removing the risk posed by the threat completely, or the 
least preferable option, that is, to do nothing.  If the risk identified is extreme, the functionality or product 
could be discontinued, as the risk of something going wrong is greater than the benefit.
The purpose of the countermeasure identification is to determine if there is some kind of protective measure 
(e.g. security control, policy measures) in place that can prevent each threat previously identified via threat 
analysis from being realized. Vulnerabilities are then those threats that have no countermeasures. 
Since each of these threats has been categorized either with STRIDE or ASF, it can be possible to find appropri-
ate countermeasures in the application within the given category. Each of the above steps is documented as 
they are carried out. The resulting set of documents is the threat model for the application. Detailed examples 
of how to carry out threat modeling is given in Appendix B. 
Threat Profile
Once threats and corresponding countermeasures are identified it is possible to derive a threat profile with the 
following criteria:
A more generic risk model takes into consideration the Likelihood (e.g. probability of an attack) and the Impact 
(e.g. damage potential):
Risk = Likelihood x Impact
Note that this is a conceptual formula and is not expected to use actual values for likelihood and impact.  The 
likelihood or probability is defined by the ease of exploitation, which mainly depends on the type of threat and 
the system characteristics, and by the possibility to realize a threat, which is determined by the existence of an 
appropriate countermeasure.
Likelihood
Methodology
39
6.10 Metrics and Code Review
Metrics measure the size and complexity of a piece of code.  There is a long list of quality and security char-
acteristics that can be considered when reviewing code (such as, but not limited to, correctness, efficiency, 
portability, maintainability, reliability and securability). No two-code review sessions will be the same so some 
judgment will be needed to decide the best path. Metrics can help decide the scale of a code review.
Metrics can also be recorded relating to the performance of the code reviewers and the accuracy of the review 
process, the performance of the code review function, and the efficiency and effectiveness of the code review 
function.
The figure 5 describes the use of metrics throughout the code review process. 
Some of the options for calculating the size of a review task include:
Lines of Code (LOC): 
A count of the executable lines of code (commented-out code or blank lines are not counted). This gives a 
rough estimate but is not particularly scientific. 
Function Point: 
The estimation of software size by measuring functionality. The combination of a number of statements which 
perform a specific task, independent of programming language used or development methodology.  In an 
object orientated language a class could be a functional point.
Defect Density: 
The average occurrence of programming faults per Lines of Code (LOC). This gives a high level view of the code 
quality but not much more. Fault density on its own does not give rise to a pragmatic metric. Defect density 
would cover minor issues as well as major security flaws in the code; all are treated the same way. Security of 
code cannot be judged accurately using defect density alone.
Risk Density: 
Similar to defect density, but discovered issues are rated by risk (high, medium & low). In doing this we can 
give insight into the quality of the code being developed via a [X Risk / LoC] or [Y Risk / Function Point] value 
(X&Y being high, medium or low risks) as defined by internal application development policies and standards.
For example:
4 High Risk Defects per 1000 (Lines of Code)
2 Medium Risk Defects per 3 Function Points
Threat Type
Description
Non-mitigated threats
Threats which have no countermeasures and represent vulnerabilities that can be fully exploited and cause an impact.
Partially mitigated 
threats
Threats partially mitigated by one or more countermeasures, which represent vulnerabilities that can only partially be 
exploited and cause a limited impact.
Fully mitigated threats
These threats have appropriate countermeasures in place and do not expose vulnerability and cause impact.
Table 10: Types Of Mitigated Threats
Methodology
40
Methodology
PERSIST METRICS
PERFORM 
REVIEW
CODE 
SUBMITED 
FOR SCR
CODE 
RESUBMITED 
FOR 
RE-REVIEW
HAS CONTEXT 
OF CODE BEEN 
DEFINED
RECOMENDED 
CODE TRIAGE 
MEETING
DEFINE CRITERIA 
PROJECT OR 
VULNERABILITY 
BASED
CODE REVIEW 
DATABASE
TREND 
ANALYSIS
RECORD 
FINDINGS
DEVELOP 
METRICS
PREVIOUS 
FINDINGS
STANDARDS
GUIDELINES
POLICIES
NO
YES
COMMUNICATE
RESULTS TO TEAM
The Use of Metrics 
Throughout The 
Code Review 
Process
Figure 5: Example process diagram for identifying input paths
41
Cyclomatic complexity (CC):  
A static analysis metric used to assist in the establishment of risk and stability estimations on an item of code, 
such as a class, method, or even a complete system. It was defined by Thomas McCabe in the 70’s and it is easy 
to calculate and apply, hence its usefulness.
The McCabe cyclomatic complexity metric is designed to indicate a program’s testability, understandability 
and maintainability. This is accomplished by measuring the control flow structure, in order to predict the diffi-
culty of understanding, testing, maintaining, etc. Once the control flow structure is understood one can gain a 
realization of the extent to which the program is likely to contain defects. The cyclomatic complexity metric is 
intended to be independent of language and language format that measures the number of linearly indepen-
dent paths through a program module. It is also the minimum number of paths that should be tested.
By knowing the cyclomatic complexity of the product, one can focus on the module with the highest com-
plexity. This will most likely be one of the paths data will take, thus able to guide one to a potentially high risk 
location for vulnerabilities. The higher the complexity the greater potential for more bugs. The more bugs the 
higher the probability for more security flaws.
Does cyclomatic complexity reveal security risk? One will not know until after a review of the security posture 
of the module. The cyclomatic complexity metric provides a risk-based approach on where to begin to review 
and analyze the code. Securing an application is a complex task and in many ways complexity an enemy of 
security as software complexity can make software bugs hard to detect. Complexity of software increases over 
time as the product is updated or maintained.
Cyclomatic complexity can be calculated as:
CC = Number of decisions +1
… where a decision would be considered as commands where execution is branched with if/else, switch, case, 
catch, while, do, templated class calls, etc.,
As the decision count increases, so do the complexity and the number of paths. Complex code leads to less 
stability and maintainability.
The more complex the code, the higher risk of defects. A company can establish thresholds for cyclomatic 
complexity for a module:
0-10: Stable code, acceptable complexity
11-15: Medium Risk, more complex
16-20: High Risk code, too many decisions for a unit of code.
Modules with a very high cyclomatic complexity are extremely complex and could be refactored into smaller 
methods. 
Bad Fix Probability: 
This is the probability of an error accidentally inserted into a program while trying to fix a previous error, 
known in some companies as a regression.
Cyclomatic Complexity: 1 – 10 == Bad Fix Probability: 5%
Cyclomatic Complexity: 20 –30 == Bad Fix Probability: 20%
Cyclomatic Complexity: > 50 == Bad Fix Probability: 40%
Cyclomatic Complexity: Approaching 100 == Bad Fix Probability: 60%
As the complexity of software increase so does the probability to introduce new errors.
Methodology
42
Inspection Rate: 
This metric can be used to get a rough idea of the required duration to perform a code review. The inspection 
rate is the rate of coverage a code reviewer can cover per unit of time. For example, a rate of 250 lines per hour 
could be a baseline. This rate should not be used as part of a measure of review quality, but simply to deter-
mine duration of the task.
Defect Detection Rate: 
This metric measure the defects found per unit of time. Again, can be used to measure performance of the 
code review team, but not to be used as a quality measure. Defect detection rate would normally increase as 
the inspection rate (above) decreases.
Re-inspection Defect Rate: 
The rate at which upon re-inspection of the code more defects exist, some defects still exist, or other defects 
manifest through an attempt to address previously discovered defects (regressions).
6.11 Crawling Code
Crawling code is the practice of scanning a code base of the review target and interface entry points, looking 
for key code pointers wherein possible security vulnerability might reside. Certain APIs are related to inter-
facing to the external world or file IO or user management, which are key areas for an attacker to focus on. In 
crawling code we look for APIs relating to these areas. We also need to look for business logic areas which may 
cause security issues, but generally these are bespoke methods which have bespoke names and cannot be de-
tected directly, even though we may touch on certain methods due to their relationship with a certain key API.
We also need to look for common issues relating to a specific language; issues that may not be security related 
but which may affect the stability/availability of the application in the case of extraordinary circumstances. 
Other issues when performing a code review are areas such a simple copyright notice in order to protect one’s 
intellectual property. Generally these issues should be part of a companies Coding Guidelines (or Standard), 
and should be enforceable during a code review.  For example a reviewer can reject a code review because 
the code violates something in the Coding Guidelines, regardless of whether or not the code would work in 
its current state.