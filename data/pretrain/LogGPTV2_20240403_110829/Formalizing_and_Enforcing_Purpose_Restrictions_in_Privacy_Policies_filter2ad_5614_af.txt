### Minimal Disclosure in Workflows and Databases
Barth, Mitchell, Datta, and Sundaram explore the concept of minimal disclosure within the context of workflows [34]. They model a workflow as meeting a utility goal if it satisfies a temporal logic formula. Minimizing the amount of information disclosed can be likened to an agent maximizing their reward by avoiding actions that incur costs without benefits. However, our work considers several additional factors, such as quantitative purposes that are satisfied to varying degrees and probabilistic behavior, which may result in actions being for a purpose even if the purpose is not fully achieved. These considerations are essential for capturing the semantics of purpose restrictions (Section VI).

### Expressing Privacy Policies with Purpose
Research on understanding the components of privacy policies has shown that purpose is a common element in privacy rules (e.g., [35]). Some languages for specifying privacy policies allow the purpose of an action to partially determine whether access is granted (e.g., [36], [37]). However, these languages do not provide a formal semantics for purposes, relying instead on the system using the policy to determine if an action aligns with a given purpose.

The use of the term "purpose" in privacy policies is also related to philosophical concepts of desire, motivation, and intention. The most relevant work in this area is Bratman's Belief-Desire-Intention (BDI) model [38], where an intention is an action an agent plans to take, with the plan formed to maximize the satisfaction of the agent's desires. Bratman's desires correspond to our purposes. Roy formalized Bratman's work using logics and game theory [39], but these works focus on the rationality of actions rather than determining the purposes behind them.

### Non-Redundancy and Causality
We adopt the concept of non-redundancy from Mackie's work on formalizing causality using counterfactual reasoning [20]. Mackie defines a cause as a non-redundant part of a sufficient explanation of an effect. In our context, we replace causes with actions and the effect with a purpose.

### Plan Recognition
Plan recognition involves inferring the plan an agent is following while performing an action [40]. This can help predict future actions, allowing systems to anticipate them. However, our auditing algorithm checks whether a sequence of actions is consistent with a given purpose, rather than predicting the most likely purpose motivating the actions.

The most closely related work is that of Baker, Saxe, and Tenenbaum [41], [42], who use a Markov Decision Process (MDP) model similar to ours to predict the most likely explanation for a sequence of actions. Ramírez and Geffner extended this work to partially observable MDPs to model agents that cannot directly observe their state [43]. Instead of a reward function, their models aim to reduce the costs of reaching a goal state. For each possible goal state, their algorithms assign a probability based on how well the agent's actions minimize the costs of reaching that state. Our reward functions are akin to the negation of their cost functions, but their work predicts the goal state being pursued rather than the cost function used. They do not consider non-redundancy.

Our auditing algorithm is similar to theirs but accounts for the error in approximate MDP solving to maintain soundness. Additionally, their algorithms may assign a non-zero probability to a goal state even if the agent's actions are inconsistent with pursuing that goal under our strict definition.

Mao and Gratch's work [44] also differs in that rewards track the agent's desire to achieve the goal rather than the degree of satisfaction of the goal.

### Philosophical Foundations
Taylor provides a detailed explanation of the importance of planning to the meaning of purpose but does not offer a formalism [18]. Our work is also related to adversarial plan recognition, which models potentially misleading agents [45]. Works using plan recognition for intrusion detection [46], [47] do not consider quantitative purposes or probabilistic transitions.

### Summary and Future Work
We use planning to create the first formal semantics for determining when a sequence of actions is for a purpose. Our formalism uses models similar to MDPs for planning, enabling automated auditing for both exclusivity and prohibitive purpose restrictions. We have provided an auditing algorithm and implementation based on our formalism, and we have illustrated its use in creating operating procedures.

We validate our method through intuitive examples (Sections III-C, IV-B, IV-C, and V-C) and an empirical study of how people understand the word "purpose" in the context of privacy policy enforcement. Our formalism explains and compares previous methods of policy enforcement, highlighting that an action can be for a purpose even if the purpose is never achieved, a point present in philosophical work but unexplored in policy enforcement. Our work underscores the difficulties in enforcement due to issues like the tenable deniability of ulterior motives (Sections IV-B and IV-C).

However, we recognize the limitations of our formalism. While MDPs are useful for automated planning, they are not specialized for modeling human planning. This concern does not apply to creating operating procedures but holds human auditees to unrealistically high standards, leading to the need for models reflecting the bounded abilities of humans to plan. Future work will instantiate our semantic framework with more complete models of human planning and make our formalism easier to use. Methods for finding policy violations without requiring a full model, such as Experience-Based Access Management, may improve environment models using our semantics.

### Acknowledgments
We thank Lorrie Faith Cranor, Joseph Y. Halpern, Dilsun Kaynar, Divya Sharma, Manuela M. Veloso, and the anonymous reviewers for their valuable comments. This research was supported by the U.S. Army Research Office grants W911NF0910273 and DAAD-190210389, the National Science Foundation (NSF) grants CNS083142 and CNS105224, and the HHS grant HHS 90TR0003/01. The views and conclusions in this document are those of the authors and should not be interpreted as representing the official policies of any sponsoring institution, the U.S. government, or any other entity.

### References
[1]–[49] (References remain unchanged and are listed as provided in the original text.)

---

This revised version aims to enhance clarity, coherence, and professionalism while maintaining the essential content and structure of the original text.