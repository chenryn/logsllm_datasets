PostMark, which generates many small ﬁle operations to
simulate an email server. With the same conﬁguration as
above, Figure 11 showed the performance (operations per
second) of the decomposed components of PostMark. Com-
pared with the client-side solution, the middle-box solution
improved the performance of each component, ranging from
23% to 34%. Upon deeper investigation, we found that this
was because outsourcing encryption to a middle-box short-
ens blocking time for application threads. Dm-crypt may
hold application threads on spinlocks (wasting CPU cycles)
while encrypting/ﬂushing writes blocks to disk. However,
the middle-box makes this application-side process much
faster: once data is acknowledged by the active-relay, the
application threads continue.
3) Case 3: Data Reliability: We have implemented a
tenant-deﬁned replica dispatch service in a storage middle-
box. Data storage replication provides data redundancy that
can be used for improved performance and fault tolerance
(if the main storage backup system fails). Our data replica
dispatch middle-box service can also be highly customized.
For example, tenants can selectively replicate important ﬁles
rather than the whole array with customizable replication
levels (e.g.,
tenants
can leverage multiple replicas to achieve enhanced read
throughput.
two or three replicas). In addition,
For write I/O operations, in addition to forwarding the
data to the original volume, our replication service copies ex-
actly the same I/O data in advance to other backup volumes
82
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:39:28 UTC from IEEE Xplore.  Restrictions apply. 
C1 VM
C2 VM
C3 VM
C4 VM
Requests
MySQL VM
vol1
Storage 
Traĸc
Replica
MB
vol1
Data zone1
vol2
Data zone2
vol3
Data zone3
Figure 12: The replication test conﬁguration.
MySQL Perf. With 3-replicas
MySQL Perf. With 1-replica
One replica fails
Timeline
s
d
n
o
c
e
S
r
e
p
s
n
o
i
t
c
a
s
n
a
r
T
500
400
300
200
100
0
1 6
1
1
6
1
1
2
6
2
1
3
6
3
1
4
6
4
1
5
6
5
1
6
6
6
1
7
6
7
1
8
6
8
1
9
6
9
1
0
1
6
0
1
1
1
1
6
1
1
Figure 13: The running status of MySQL before and after a
replica fails.
that are attached to the middle-box. Importantly, to keep the
state consistent across all replicas, we strictly ensure that
a same sequence ordering of write I/O operations on all
volumes. On the other hand, for read I/O operations, the
replication service alternatively chooses one of the available
replicas for reading data. As a result, the read throughput
aggregates from all available replicas. Once a replica is not
responsive for some reason, it will be eliminated from future
operations. The unﬁnished reads of that failed replica are
served from one of the other active replicas.
To evaluate the tenant-deﬁned replication service, we set
up a realistic environment, shown in Figure 12, with one
VM hosting a database server and four tenant VMs sharing
the server (all belonging to the same tenant). We ran MySQL
on the server VM associated with a 20 GB volume attached
as the database disk. Each tenant VM ran Sysbench — an
OLTP benchmark accessing the MySQL database with six
requesting threads in complex mode (both read and write).
We set the replication factor to three, where the replication
middle-box was attached to two replicas (20 GB each). At
runtime, we injected an error (at the 60th second) to one
of the replicas to make it unavailable (by closing the iSCSI
connection). Figure 13 shows the running status of MySQL
before and after that replica fails. We observed that once
the replica failed the replication service removed the failed
replica and ensured the database server continuously worked
properly using the two other available replicas. The average
performance of MySQL after the failure dropped a little due
to lower read parallelism with less replicas, but compared to
the non-replication case using only one store, we observed
80% performance improvement using three replicas because
of aggregated read throughput.
Our case studies demonstrated that many storage security
and reliability services can be offered via middle-boxes to
cloud tenants. Moreover, StorM is capable of providing the
development and deployment platform for these middle-
boxes.
VI. RELATED WORK
Offering security and system services via middle-boxes
has been around for almost a decade. However, the arrival
of software-deﬁned networking (SDN) and the possibility
of deploying middle-boxes dynamically, instead of a static
chain, has renewed researchers’ interest in middle-boxes. In
recent works [14], [15], researchers have identiﬁed chal-
lenges in deploying middle-boxes in a SDN-enabled network
and shown why straightforward deployment of middle-boxes
in SDN networks would be problematic. Our work on de-
signing and implementing StorM is along the same direction:
we investigated the possibility of offering tenant-deﬁned
services in the cloud storage network via middle-boxes and
discovered that existing cloud systems lack mechanisms to
support them.
Previous research has proposed various security mecha-
nisms as cloud services to protect VMs, applications, and
security groups. SSC [16] did allow the deployment of
tenant-speciﬁc storage security services, but their approach
required these protections to be installed inside of tenant
VMs running on a modiﬁed cloud platform. In contrast, we
proposed the ﬁrst storage security platform that allows the
deployment of tenant-speciﬁc storage services via virtualized
middle-boxes in the cloud.
Cryptographic solutions [17] have been proposed to pro-
tect the data in clouds. One common cloud data encryption
solution involves service providers encrypting customers’
data [17], [18] — the approach that major cloud service
providers, like Microsoft, Google, and Yahoo have adopted.
EMC provides its Encryption-as-a-Service (EaaS) cloud ser-
vice [19], which enables client-side encryption. To comple-
ment these existing solutions, our StorM provides a ﬂexible
platform, where various encryption techniques (among other
storage services) can be built upon. This allows tenants
to ﬂexibly choose the cryptographic algorithms that they
want to implement inside a middle-box, depending on their
security/storage needs.
In addition to cryptographic solutions, previous research
has also looked into disk monitoring and logging solutions,
such as the host-based IDS solutions Tripwire [20] and
FWRAP [21]. Host-based disk IDS solutions required a
trusted OS, but advanced kernel rootkits can break that
assumption. To overcome this problem, Virtual Machine
Introspection (VMI) based techniques were proposed such
as XenAccess [22] and other systems [23], [24]. These intro-
duced a set of monitoring libraries running in the privileged
domain (dom0 or the VMM itself) and tracked guest-level
activities such as virtual disk accesses. In contrast to these
services that required access to the privileged domain or
changes inside the tenant VM, StorM’s monitoring service
requires no support from the tenant VM and instead executes
monitoring code in a separate, isolated VM (the middle-
box).
To ensure storage reliability at the block level, existing
vendor-speciﬁc solutions depend on hardware adapters (e.g.,
EMC’s SRDF, and NetApp’s SnapMirror) to replicate en-
tire storage arrays. Further, network-based replication (e.g.,
83
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:39:28 UTC from IEEE Xplore.  Restrictions apply. 
EMC’s RecoverPoint), using an appliance that sits at the
edge of the network,
takes multiple arrays and servers
into account. CYRUS [25] and CDStore [26] provide user-
controlled ﬁle-level data reliability by dispersing users’
backup data across multiple clouds. However, each of
these solutions requires client-side software, and in contrast,
StorM requires no software inside the tenant VM, and allow
tenants to ﬂexibly choose the data replication services on
demand in a transparent and seamless manner.
VII. CONCLUSIONS
In this paper, we have presented StorM, a storage se-
curity/reliability service platform for the multi-tenant cloud
systems. StorM allows each tenant to deploy tenant-deﬁned
storage security/reliability services in the form of virtu-
alized middle-boxes that transparently reside between the
tenant VMs and storage servers. To enable this storage
service platform, we addressed three main challenges —
network splicing, platform efﬁciency, and semantic gap. We
implemented a prototype of StorM on top of the popular
OpenStack cloud system. We also built three middle-box
services to demonstrate the efﬁcacy of StorM— storage
access monitor, data encryption, and data replication. Our
evaluation results demonstrate that StorM provides tenants
with customized, value-added storage services with low
performance overhead.
VIII. ACKNOWLEDGMENTS
We thank the anonymous reviewers for their insightful
comments and suggestions. This work was supported in part
by NSF under Award 1219004.
REFERENCES
[1] R. Sharma and R. K. Trivedi, “A case of multilevel secu-
rity application for ensuring data integrity (prevention and
detection) in cloud environment,” International Journal of
Computer Applications, 2014.
[2] K. Ren, C. Wang, and Q. Wang, “Security challenges for the
public cloud,” IEEE Internet Computing, 2012.
[3] “Virtualization
Protection
http://www.dabcc.com/documentlibrary/ﬁle/
virtualization-data-protection-report-smb-2013.pdf.
Data
Report,”
[4] P. Gill, N. Jain, and N. Nagappan, “Understanding net-
work failures in data centers: measurement, analysis, and
implications,” in ACM SIGCOMM Computer Communication
Review, 2011.
[5] D. A. Joseph, A. Tavakoli, and I. Stoica, “A policy-aware
switching layer for data centers,” in Proceedings of the ACM
SIGCOMM 2008 Conference on Data Communication, 2008.
[6] V. Sekar, S. Ratnasamy, M. K. Reiter, N. Egi, and G. Shi,
“The middlebox manifesto: enabling innovation in middlebox
deployment,” in Proceedings of the 10th ACM Workshop on
Hot Topics in Networks, 2011.
[7] Z. Wang, Z. Qian, Q. Xu, Z. Mao, and M. Zhang, “An
untold story of middleboxes in cellular networks,” in ACM
SIGCOMM Computer Communication Review, 2011.
[8] B. Pfaff, J. Pettit, T. Koponen, E. Jackson, A. Zhou, J. Raja-
halme, J. Gross, A. Wang, J. Stringer, P. Shelar, K. Amidon,
and M. Casado, “The design and implementation of open
vswitch,” in 12th USENIX Symposium on Networked Systems
Design and Implementation (NSDI 15), 2015.
[9] N. Santos, K. P. Gummadi, and R. Rodrigues, “Towards
trusted cloud computing,” in Proceedings of the 2009 Con-
ference on Hot Topics in Cloud Computing, 2009.
[10] “Open-iscsi,” http://www.open-iscsi.org/.
[11] “Fio,” http://linux.die.net/man/1/ﬁo.
[12] T. Harter, D. Borthakur, S. Dong, A. Aiyer, L. Tang, A. C.
Arpaci-Dusseau, and R. H. Arpaci-Dusseau, “Analysis of hdfs
under hbase: a facebook messages case study,” in Proceed-
ings of the 12th USENIX conference on File and Storage
Technologies, 2014.
[13] “Kaspersky:
HEUR:Backdoor.Linux.Ganiw.a,”
MD5:ef5d928cab15a54d33209510818f5c72http:
//malwaredb.malekal.com/.
[14] Z. Qazi, C. C. tu, L. Chiang, R. Miao, V. Sekar, and M. Yu,
“Simple-fying middlebox policy enforcement using sdn,” in
SIGCOMM, 2013.
[15] S. Fayazbakhsh, V. Sekar, M. Yu, and J. Mogul, “Flowtags:
Enforcing network-wide policies in the presence of dynamic
middlebox actions,” in HotSDN, 2013.
[16] S. Butt, H. A. Lagar-Cavilla, A. Srivastava, and V. Ganapathy,
“Self-service cloud computing,” in Proceedings of the 2012
ACM Conference on Computer and Communications Security,
2012.
[17] S. Kamara and K. Lauter, “Cryptographic cloud storage,” in
Financial Cryptography and Data Security, 2010.
[18] S. Kamara, P. Mohassel, and B. Riva, “Salus: a system for
server-aided secure function evaluation,” in Proceedings of
the 2012 ACM conference on Computer and communications
security, 2012.
[19] “Encryption as a service,” http://www.cloudlinktech.com/
wp-content/plugins/download-monitor/download.php?id=
133.
[20] G. H. Kim and E. H. Spafford, “The design and imple-
mentation of tripwire: A ﬁle system integrity checker,” in
Proceedings of the 2nd ACM Conference on Computer and
Communications Security, 1994.
[21] B. Y. M. Cheng, J. G. Carbonell, and J. Klein-Seetharaman,
“A machine text-inspired machine learning approach for iden-
tiﬁcation of transmembrane helix boundaries,” in Foundations
of Intelligent Systems, 2005.
[22] B. D. Payne, M. De Carbone, and W. Lee, “Secure and ﬂex-
ible monitoring of virtual machines,” in Computer Security
Applications Conference, 2007. ACSAC 2007. Twenty-Third
Annual, 2007.
[23] Y. Zhang, Y. Gu, H. Wang, and D. Wang, “Virtual-machine-
based intrusion detection on ﬁle-aware block level storage,”
in Computer Architecture and High Performance Computing,
2006. SBAC-PAD’06. 18TH International Symposium on,
2006.
[24] F. Tsifountidis, “Virtualization security: Virtual machine mon-
itoring and introspection,” Signature, 2010.
[25] J. Y. Chung, C. Joe-Wong, S. Ha, J. W.-K. Hong, and
M. Chiang, “Cyrus: Towards client-deﬁned cloud storage,” in
Proceedings of the Tenth European Conference on Computer
Systems, 2015.
[26] M. Li, C. Qin, and P. P. Lee, “Cdstore: Toward reliable,
secure, and cost-efﬁcient cloud storage via convergent dis-
persal,” arXiv preprint arXiv:1502.05110, 2015.
84
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:39:28 UTC from IEEE Xplore.  Restrictions apply.