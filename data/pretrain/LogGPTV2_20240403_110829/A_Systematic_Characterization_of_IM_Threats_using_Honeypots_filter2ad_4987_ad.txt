improbable to assume that all of them were “cleaned
up”. Therefore, this might indicate a cautious behaviour
on behalf of the attackers. With 55% of the compro-
mised accounts sending up to 4 URLs and 75% sending
less than 20, it is evident that one strategy that attack-
ers follow is to avoid aggressive spamming behaviours
so as not to raise suspicions among the compromised
accounts’ contacts. Such aggressive behaviours could
alert the user and lead to the dis-infection of the ac-
count/machine. However, this cautious behaviour could
also be attributed to technical reasons. If the attack is
propagated through a worm that infects the client, then
a low rate of worm propagation would be used so as not
to trigger antivirus or intrusion detection systems.
Furthermore, approximately 12% of the attackers
sent at least 100 URLs to our decoy accounts. This
aggressive strategy of massively dispatching spam mes-
sages, indicates a category of attackers that don’t try to
remain beneath a certain threshold. This can also be at-
tributed to technical reasons. Speciﬁcally, amongst the
top ten compromised accounts that sent us the largest
number of URLs, we found all the victim accounts
whose credentials we had entered in phishing sites.
Therefore, the attackers use tools to send messages from
these compromised accounts without relying on worms
that infect the IM client software. Thus, we can recog-
nize a second more aggressive strategy, where it is not
necessary for attackers to adopt a stealthy propagation
rate. Finally, it is interesting to note that attackers send
URLs from all the categories, as well as malware, and
do not focus on one speciﬁc type.
8 Real-case Evaluation
We were interested in investigating the potential ef-
fectiveness of an IM attack campaign. To do so, we de-
cided to launch our own benign campaign targeting the
contacts of one of our honeypots. There were two factors
to be taken into consideration. The ﬁrst one was local-
ization. Several users would get suspecious if we sent
them messages that were not in their native language.
We queried the proﬁle pages of most of the contacts we
had at our disposal but unfortunately we could not re-
trieve country information for most of them, so we de-
cided not to localize the messages sent. The second one
was whether a conversation would take place before ac-
tually sending the URL. A message containing a URL
without any prior conversation might get ﬂagged as sus-
picious immediately.
Nonetheless, we decided to launch a simple spam
imitated the ones caught by Honey-
campaign that
Buddy,
that would not provide biased results. We
logged in one of our honeypot accounts and sent
the following message to the online contacts: “Hey!
Check this out: http://mygallery.webhop.
net/gallery1/photo1.jpg”. The URL pointed
to a web server controlled by us and redirected the user
to a web page that asked the user to download a (benign)
executable. The executable was a harmless program that
just requested another URL, again from our own web
server. That way, we were able to track if and when
a user actually executed the ﬁle she downloaded. We
contacted each online contact only once for the whole
duration of the experiment.
s
u
a
t
t
s
k
c
a
t
t
A
4
3
2
1
0
7PM
May18
9PM
11PM
Time
1AM
May19
Message sent
File downloaded
File executed
Figure 14. Time series of events that oc(cid:173)
curred during our benign campaign.
The results of the campaign are summarized in Fig-
ure 14. The bottom series plots the timestamps when
the message was sent to an online user. The middle se-
ries plots the timestamps when a contact visited the URL
contained in the sent message and downloaded the exe-
cutable. The top series displays the timestamps when a
contact actually ran the downloaded executable. During
our campaign we sent 231 messages. 27 unique users
(11.6%) visited the URL and downloaded the ﬁle, while
9 of them (4%) executed the downloaded ﬁle. We re-
peated the same experiment with two other accounts and
the results were almost the same.
9 MyIMhoneypot, a detection service
In this section we present an overview of existing de-
fense measures, and propose a service for the early de-
tection of attacks targeting instant messaging networks.
The existing defense mechanisms deployed by instant
messaging service providers and other vendors, are in-
sufﬁcient for protecting users from the threats presented
in Section 3. Anti-virus products that scan ﬁles received
from instant messaging ﬁle-transfers fail to identify all
malware used by IM attackers, as shown by our ﬁnd-
ings. Anti-virus vendors could provide more up-to-date
signatures for IM malware by deploying HoneyBuddy
for the early collection of such malware. Furthermore,
as shown in Section 5.5, anti-virus products designed to
protect users from phishing attacks fail to detect 87% of
the malicious URLs collected by our infrastructure. Pop
up messages from IM client software that alert users of
phishing, that are triggered by all messages that con-
tain a URL even if it is benign, are ineffective since
users tend to ignore warnings that are presented even for
well-known benign URLs. We propose that IM clients
should correlate received URLs with blacklists and alert
users only when they belong to malicious domains. We
present our client-side mechanism that is orthogonal to
existing defense mechanisms; myIMhoneypot, an early
detection service that can inform users if their accounts
or IM clients have been compromised. IM attacks try
to spread through the victim’s contact list by sending ei-
ther URLs or ﬁles to the victim’s friends. Any user that
wants to check if her account is compromised registers
with the myIMhoneypot service. Upon registration, the
service creates a unique IM honeypot account (for ex-
ample, a new MSN account that will be used as a decoy
account) and informs the user to add that honeypot ac-
count to her contact list. As the user will never start a
conversation with the honeypot account but an IM at-
tacker will (with great probability), the user can check
if something is wrong by visiting the website of the ser-
vice and checking the conversation logs with her unique
honeypot account. If there are entries in the conversa-
tion log of her decoy account like the example in Figure
15, then there is a strong indication that her IM client or
credentials have been compromised.
The reason that a unique IM account must be created
per user is twofold. First, if the service has only one or
a few honeypot accounts then they can be easily black-
listed (recall that anyone can subscribe to the service,
including attackers). The attacker should not be able
to distinguish whether a contact is a decoy account or
not. The service creates accounts with human-like nick-
www.honeyathome.org/imhoneypot .
We also provide a service that does not require user
registration. Users can submit URLs they receive in in-
stant messages to correlate them with our database. As
mentioned before, suspicious URLs usually contain the
target’s username and, thus, searching for an identical
URL in our database would rarely result in a match.
Therefore, the service searches our database for any
URL that has the same top level domain with that of the
submitted URL, which is an indication that they might
belong to the same campaign. If a match is found the
user is presented with a small report containing the date
the URL was ﬁrst caught by HoneyBuddy and the cat-
egory it was assigned by our classiﬁer. Based on our
ﬁndings in Section 5 concerning the uptime of each of
collected TLDs, we assign the submitted URLs with a
value of how likely they are to still pose a threat to users
depending on the time window between being collected
by HoneyBuddy and being submitted by the user.
10 Conclusions
In this paper we propose HoneyBuddy, an active hon-
eypot infrastructure designed to detect malicious activ-
ities in instant messaging services. HoneyBuddy auto-
matically ﬁnds user accounts that belong to a supported
IM service and adds them to its contact list. Our system
monitors decoy accounts for incoming messages and ﬁle
transfers, and extracts suspicious executables and URLs.
The suspicious data gathered by HoneyBuddy is cor-
related with existing blacklists, and malware collection
center databases. Despite the simplicity of our system,
deployment for the MSN service showed that 93% of
the identiﬁed phishing domains were not listed by popu-
lar blacklist mechanisms and 87% of all malicious URLs
were incorrectly ﬂaged as safe by a commercial “web-
safety” product. Furthermore, 21% of collected malware
samples were also not listed by other infrastructures.
These ﬁndings conﬁrm that existing security measures
of instant messaging services are insufﬁcient, and also
indicate the effectiveness of our system as a comple-
mentary detection infrastructure. We further inspected
the top level domains that host the phishing URLs and
found that they translate to a very small number of IP
addresses suggesting the existence of a large network
of collaborating attackers. On the other hand, domains
that distribute malware do not follow the same tactics
and translate to a different set of IP addresses. We lo-
cated domains that belong to fast ﬂux-networks in both
cases, however they are more common in the case of the
phishing domains, which have a higher probability of
Figure 15. A screenshot of the log pre(cid:173)
sented to a user whose IM account has
been compromised.
names. Second, the attacker can try to hack into the ser-
vice’s accounts once she knows the user is a subscriber.
Using a unique honeypot per user makes the attacker’s
life a lot harder. The attacker cannot correlate common
friends across accounts and has to try to compromise all
the accounts in the user’s contact list. Even if she does
that, most IM services (at least MSN and AIM) do not
keep conversation logs at the server side so she cannot
ﬁnd her spam messages in the logs of decoy accounts.
The attacker could guess the decoy accounts by
checking the locally stored conversation logs. Normally,
a user will have conversations with all members of her
contact list except the honeypot account. Therefore, the
attacker could avoid sending messages to accounts for
which no conversation logs were found. This attack can
be easily circumvented by planting a fake conversation
log on the user’s side.
The myIMhoneypot service has a limitation. For
each registered user, a new IM account must be cre-
ated in order to be used as a decoy. This process in-
volves the solution of CAPTCHAs [5] which prevents
us from making it completely automatic. Although we
could claim that MyIMhoneypot is a legal case for laun-
dering CAPTCHAs, we did not implement it for obvi-
ous reasons. For the time being, we have to manually
create decoy accounts. However, we propose that this
service should be implemented by each IM provider as
a means of protection for its users. We implemented
a prototype of myIMhoneypot for the MSN platform.
We call it myMSNhoneypot and it can be found at
being blacklisted. Based on the results from the analy-
sis of the IM attacks we caught, we provided a proﬁle
of the attackers and their spamming strategies. An inter-
esting aspect of IM attacks that could not be measured
by our infrastructure was how successful an MSN phish-
ing campaign can be. To get an estimation, we deployed
our own benign campaign and found that almost 12% of
the users followed the URL and 4% ran the executable it
redirected to.
We also deployed myMSNhoneypot, a prototype im-
plementation of a service that is open to the public and
creates dedicated IM honeypots for users. This service
provides an early alerting mechanism for users whose
IM accounts or clients are compromised. It provides de-
coy accounts for users that register with the service to
add to their contact list. A message from the user to a
decoy account is an indication that the user’s credentials
or IM client are compromised, as the user would never
initiate a conversation with the decoy contact. We pro-
pose this type of service to be adopted and deployed by
instant messaging vendors. Finally, we offer a service
where users can submit a URL and receive a report in-
dicating if the top level domain has been classiﬁed as
dangerous.
Acknowledgments
This work was supported in part by the project Cyber-
Scope, funded by the Greek Secretariat for Research and
Technology under contract number PENED 03ED440.
We thank the anonymous reviewers for their valuable
comments. Iasonas Polakis, Thanasis Petsas and Evan-
gelos P. Markatos are also with the University of Crete.
References
[1] Anubis: Analyzing unknown binaries.
http://
anubis.iseclab.org/.
[2] AQABA Search Engine Demographics.
http:
//http://www.aqaba-sem.com/search_ed.
htm/.
[3] AutoIt.
http://www.autoitscript.com/
autoit3/index.shtml/.
[4] BuddyFetch. http://buddyfetch.com/.
[5] CAPTCHA: Telling Humans and Computers Apart Au-
tomatically. https://captcha.net/.
[6] Crowbar.
http://simile.mit.edu/wiki/
Crowbar.
[7] Europe
surpasses north america
in instant mes-
http:
comscore study reveals.
senger users,
//www.comscore.com/press/release.asp?
press=800.
[8] Google safe browsing api. http://code.google.
com/apis/safebrowsing/.
[9] H1N1 Shortcut Malware. http://www.f-secure.
com/weblog/archives/00001738.html.
[10] MessengerFinder, Find people online.
http://
messengerfinder.com/.
[11] Msn messenger. http://messenger.live.com/.
[12] MSN Polygamy. http://www.softpedia.com/
get/Internet/Chat/Instant-Messaging/
MSN-Messenger-7-8-Polygamy.shtml/.
[13] Norton safe web from symantec. http://safeweb.
norton.com/.
[14] nslookup.
http://en.wikipedia.org/wiki/
Nslookup.
[15] Pidgin,
the universal chat client.
http://www.
pidgin.im/.
[16] Planetlab, an open platform for developing, deploying
and accessing planetary-scale services. http://www.
planet-lab.org.
facebook
[17] Scraping
addresses.
http:
email
//kudanai.blogspot.com/2008/10/
scraping-facebook-email-addresses.
html.
[18] Skype Fast Facts, Q4 2008.
http://ebayinkblog.com/
wp-content/uploads/2009/01/
skype-fast-facts-q4-08.pdf.
[19] Spam Archive. http://untroubled.org/spam/.
[20] The state of spam a monthly report
august 2007.
http://www.symantec.com/avcenter/
reference/Symantec_Spam_Report_-_
August_2007.pdf.
Blog
China
:
[21] StopBadware
Hosts Ma-
http://
of
Badware
jority
blog.stopbadware.org/2008/06/24/
china-hosts-majority-of-badware-sites.
Sites.
[22] Surbl. http://www.surbl.org.
[23] Symantec. http://www.symantec.com/index.
jsp.
[24] Urlblacklist.com.
http://www.urlblacklist.
com/.
[25] Virustotal, online virus and malware scan. http://
www.virustotal.com/.
[26] Vulnerability in PNG Processing Could Allow Remote
Code Execution. http://www.microsoft.com/
technet/security/bulletin/MS05-009.
mspx.
[27] W32.Bropia.
http://www.symantec.com/
security_response/writeup.jsp?docid=
2005-012013-2855-99&tabid=2.
[28] N. Hindocha. Threats to instant messaging. Symantec
Security Response, 2003.
[29] J. Leskovec and E. Horvitz. Planetary-Scale Views on
In Proceedings of
a Large Instant-Messaging Network.
WWW 2008, April 2008.
[30] Z. Liu and D. Lee. Coping with instant messaging worms
- statistical modeling and analysis. pages 194–199, June
2007.
[31] Z. Liu, W. Lin, N. Li, and D. Lee. Detecting and ﬁlter-
ing instant messaging spam - a global and personalized
approach. pages 19–24, Nov. 2005.
[32] Z. Liu, G. Shu, N. Li, and D. Lee. Defending against
In In Proceedings of IEEE
instant messaging worms.
GLOBECOM 2006, pages 1–6, 2006.
[33] M. Mannan and P. Van Oorschot. Secure public instant
messaging: A survey.
In Proceedings of the 2nd An-
nual Conference on Privacy, Security and Trust (PST04),
pages 69–77.
[34] G. Portokalidis, A. Slowinska, and H. Bos. Argos: an
Emulator for Fingerprinting Zero-Day Attacks. In Pro-
ceedings of ACM SIGOPS Eurosys 2006, April 2006.
[35] H. Project. Know your enemy: Learning about Security
Threats. Pearson Education, Inc., 2004.
[36] N. Provos, P. Mavrommatis, M. A. Rajab, and F. Mon-
rose. All your iframes point to us. In SS’08: Proceedings
of the 17th conference on Security symposium, pages 1–
15, Berkeley, CA, USA, 2008. USENIX Association.
[37] A. Trivedi, P. Judge, and S. Krasser. Analyzing network
and content characteristics of spim using honeypots. In
Proceedings of the 3rd USENIX SRUTI, 2007.
[38] M. Williamson, A. Parry, and A. Byde. Virus throt-
tling for instant messaging. In Virus Bulletin Conference,
pages 38–4, 2004.
[39] M. Xie, Z. Wu, and H. Wang. HoneyIM: Fast detec-
tion and suppression of instant messaging malware in
enterprise-like networks. In Proceedings of the 2007 An-
nual Computer Security Applications Conference (AC-
SAC07).