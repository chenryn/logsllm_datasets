Gaussian distributions of the given variance ς 2; the closeness of these approximations is speciﬁed
by the given Rényi divergence and its order.
3.3 Error distributions
The key exchange protocol in Figure I is described in terms of an unspeciﬁed error distribution χ
over a set S. We now describe the concrete choice of error distribution used in our implementation,
which is an instantiation of inversion sampling that uses a precomputed table corresponding to a
discrete cumulative density function (CDF) over a small interval. The four distributions we use are
deﬁned by the discrete probability density functions (PDFs) in Table 1. We use the ﬁrst distribution,
D1, as an example to illustrate how the sampling routine works. Modifying the corresponding PDF
into a CDF gives the table T = [43, 104, 124, 127]. We then sample 8 bits uniformly at random;
the ﬁrst 7 bits correspond to a uniform random integer y ∈ [0, 127] which is used to return the
smallest index ˜x ∈ [0, 3] such that y ≤ T [˜x], and the last (eighth) bit is used to determine the sign
s ∈ {−1, 1} of the sampled value x = s · ˜x.
For each distribution in Table 1, performing inversion sampling can be done eﬃciently using
at most seven precomputed values of at most 16 bits each; thus, the precomputed look-up tables
required for sampling any of the above distributions are at most 14 bytes each. Obtaining a single
sample amounts to accessing an element from one of these small look-up tables; this can be done in
a memory and timing sidechannel-resistant manner by always scanning all elements and performing
comparisons with branchless arithmetic operations.
The four distributions D1, D2, D3, D4, are the result of an exhaustive search for combinations
of discrete probabilities that closely approximate the rounded continuous Gaussians of the variances
speciﬁed in Table 1. Here the measure of “closeness” is the Rényi divergence of the orders speciﬁed
in Table 1. We refer to [10] for more details on the Rényi divergence, but for our purposes it suﬃces
to say that the nearer the divergence is to 1, the tighter the security reduction is (when replacing
the rounded Gaussian distribution with our discrete approximation to it), which gives rise to either
higher (provable) security, or better parameters.
4 Security assessment and parameter selection
In this section, we explain our methodology to provide conservative security estimates against both
classical and quantum attacks, and subsequently, we propose parameters for the protocol in the pre-
vious section. The methodology is similar to the one proposed in [6], with slight modiﬁcations that
take into account the fact that some quasi-linear accelerations [60, 15] over sieving algorithms [12, 43]
are not available without the ring structure. We restate this analysis for self-containment.
We remark that our methodology is signiﬁcantly more conservative than what is usually used in
10
the literature [5]. Our goal is not just to demonstrate feasibility, but to provide long-term and real-
world security. To that end, we acknowledge that lattice cryptanalysis is far less mature than the
cryptanalysis against schemes based on the hardness of factoring and computing discrete logarithms,
for which the best-known attack can safely be considered as a best-possible attack.
4.1 Methodology: the core-SVP hardness
Due to the (very) limited number m of LWE samples available to an attacker (m = n + m or
m = n+n), we are not concerned with BKW-like attacks [41], nor are we concerned with linearization
attacks [8]. This essentially leaves us with two BKZ-style [21] attacks, which are usually referred to
as primal and dual attacks; we review both below.
The BKZ algorithm with block-size b requires up to polynomially many calls to an SVP oracle
in dimension b. However, using some heuristics essentially allows the number of oracle calls to be
decreased to a linear number [20]. To account for further improvement, we only count the cost of
one such call to the SVP oracle, i.e., the core-SVP hardness. Such precaution seems reasonable,
especially in the case of the dual attack that involves running BKZ several times, in which case it
is plausible that most of the lattice reduction cost may be amortized.
Even the concrete cost of a single SVP computation in dimension b is problematic to evaluate.
This is due to the fact that the numerically optimized pruned enumeration strategy does not yield a
closed formula [32, 21]. Even with pruning, enumeration is asymptotically super-exponential, while
sieving algorithms have exponential complexity 2cb+o(b) (where the constant c in the exponent is
well-understood). A sound and simple strategy is therefore to determine a lower bound for the cost
of an attack by 2cb vector operations (i.e., about b2cb CPU cycles1), and to make sure that the
block-size b lies in a range where enumeration is more expensive than 2cb. From the estimate of [21],
it is argued in [6] that this is the case (both classically and quantumly) when b ≥ 200.
(cid:112)3/2 ≈ 0.292, which is provided by the
(cid:112)13/9 ≈ 0.265 (see §14.2.10 in [43]). Since all variants of the sieving algorithm require a list of
(cid:112)4/3
sieve algorithm of [12]; and, in the context of quantum attacks, the best known constant is cQ =
log2
= 20.2075b vectors to be built, it also seems plausible that cP = 0.2075 can serve as a worst-
case lower bound. (Here the subscripts C, Q and P diﬀerentiate between the sieving constants used
to obtain “classical”, “quantum” and “paranoid” estimates on the concrete bit-security given by a
particular set of parameters.)
Classically, the best known constant is cC = log2
b
4.2 Primal attack
The primal attack constructs a unique-SVP instance from the LWE problem and solves it using
BKZ. We examine how large the block dimension b is required to be for BKZ to ﬁnd the unique
solution. Given the matrix LWE instance (A, b = As + e) ∈ Zm×n
, one builds the lattice
Λ = {x ∈ Zm+n+1 : (A | Im | −b)x = 0 mod q} of dimension d = m + n + 1 and volume qm. The
√
vector v = (s, e, 1) ∈ Λ is a unique-SVP solution of norm λ ≈ ς
n + m, where ς is the standard
deviation of the error distribution used to sample e. In our case, the number of samples used, m,
may be chosen between 0 and n + m (or n + n), and we numerically optimize this choice.
× Zm×1
q
q
Using the typical models of BKZ (under the geometric series assumption and the Gaussian
1Due to the presence of the ring-structure, [6] chose to ignore this factor b in order to aﬀord the ad-
versary the advantage of assuming that the techniques in [60, 15] can be adapted to more advanced sieve
algorithms [6]. However, for plain-LWE, we include this factor.
11
heuristic [20, 5]), one concludes that the primal attack is successful if and only if
b ≤ δ2b−d−1 · qm/d,
√
ς
δ = ((πb)1/b · b/2πe)1/2(b−1).
where
4.3 Dual attack
In the dual attack, one searches for a short vector (v, w) in the dual lattice ˆΛ = {(x, y) ∈ Zm ×Zn :
Atx = y mod q}, with the aim of using it as a distinguisher for the decision-LWE problem. The
BKZ algorithm with block-size b will output such a vector of length (cid:96) = δd−1qn/d.
Having found (x, y) ∈ ˆΛ of length (cid:96), an attacker computes z = vt · b = vtAs + vte = wts +
vte mod q. If (A, b) is indeed an LWE sample, then z is distributed as a Gaussian, centered around 0
and of standard deviation (cid:96)ς, otherwise z is distributed uniformly modulo q. The maximal variation
distance between these two distributions is bounded by  ≈ 4 exp(−2π2τ 2), where τ = (cid:96)ς/q: thus,
given such a vector of length (cid:96), the attacker may distinguish LWE samples from random with
advantage at most .
It is important to note that a small distinguishing advantage  does not provide appreciable help
to an adversary that is attacking a key exchange protocol: since the agreed key is to be used to derive
a symmetric cipher key, any advantage below 1/2 does not signiﬁcantly decrease the search space
in a brute force search for the symmetric cipher key. (Recall that the reconciled key is processed
with a random oracle before it is used for any other purposes.)
We therefore require an attacker to amplify his success probability by ﬁnding approximately 1/2
such short vectors. Since the sieve algorithms provide 20.2075b vectors, the attack must be repeated
at least R = max(1, 1/(20.2075b2)) times. We again stress that we are erring on the conservative
side, since the other vectors that are output by the sieving algorithm are typically a little larger
than the shortest one.
4.4 Proposed parameters
Our proposed parameters are summarized in Table 2, and their security detailed in Table 3.
Challenge parameters. We provide a set of challenge parameters as a target that should be
reasonably accessible within the current cryptanalytic state-of-the-art. Attacking these parameters
may even be feasible without subtle optimizations such as pruned enumeration. We do not provide
hardness claims for those parameters because the required BKZ block-size for breaking them is far
below 200, and since our analysis only considers sieving algorithms, it is not valid in that range.
Classical parameters. We also propose a classical parameter set that provides 128-bits of security
against classical attacks. We do not recommend these parameters in practice since they fail to
achieve a high enough protection against quantum attacks, but provide them to ease the comparison
with other proposals from the literature.
Recommended parameters. The last two parameter sets are the ones we recommend if a scheme
like the one described in this paper is to be deployed in the real-world. The ﬁrst (Recommended)
set conservatively oﬀers 128 bits of security against the best known quantum attack. The second
(Paranoid) set would resist an algorithm reaching the complexity lower bound for sieving algorithms
we mentioned in § 4.1, and could even remain quantum-secure if signiﬁcant improvements towards
solving SVP are achieved.
Failure rate estimation. Recall from Claim 3.2 that Alice and Bob’s reconciliation of B bits
(per approximate agreement in Zq) will work with probability 1 if the distance between their two
12
Scheme
Challenge
Classical
Recommended
Paranoid
n
352
592
752
864
dist. B · m2 = B · n2
q
211 D1
212 D2
215 D3
215 D4
1 · 82 = 64
2 · 82 = 128
4 · 82 = 256
4 · 82 = 256
failure bandwidth
2−41.8
7.75 KB
2−36.2
14.22 KB
2−38.9
22.57 KB
2−33.8
25.93 KB
Table 2: Proposed parameter sets with dimension n, modulus q, and noise distribution (which is an
approximation to the rounded Gaussian – see Table 1), showing the size of the shared key in bits
as the product of the number B of bits agreed upon per coeﬃcient and the number of coeﬃcients
m · n, the failure rate and the total size of key exchange messages.
Zq elements is less than q/2B+2. On the other hand, if this distance is greater than 3q/2B+2, the
reconciliation will work with probability 0, and the success probability decreases linearly from 1 to
0 in the range between these two extremes. To determine the overall failure rate of our protocol, we
combine this relationship with the probability distribution of the distance. In the continuous case,
it is easy to check that the distribution of this distance has variance σ2 = 2nς 4 + ς 2, where ς 2 is the
variance of the continuous Gaussian distribution. However, using more computationally-intensive
but tighter analysis, we can compute the distribution of the distance corresponding to our discrete
approximation directly. The union bound gives an upper bound on the total failure probability,
which is summarized for our chosen parameter sets in Table 2.
Numbers of samples and bits per coeﬃcient. We opted to choose m = n, i.e., an equal
division of bandwidth to Alice and Bob. The new reconciliation mechanism from §3.2 drives down
both bandwidth and computation costs by extracting more random bits from a single ring element.
Compared to the previous reconciliation mechanism of Peikert [54] that extracts a single bit per
element, we extract 4 bits per element (when using our Recommended parameter set), which reduces
the total amount of communication and computation by approximately a factor of 2.
5 Proof of Security
The security of our key exchange protocol can be reduced to the learning with errors problem. Our
proof uses a variant with short secrets and matrices (instead of vectors) that is equivalent to the
original LWE problem.
5.1 The LWE problem and variants
Deﬁnition 5.1 (Decision LWE problem). Let n and q be positive integers. Let χ be a distribution
over Z. Let s $← U(Zn
• Oχ,s: a $← U(Zn
• U: a $← U(Zn
q ). Deﬁne the following two oracles:
q ), e $← χ(Zq); return (a, as + e).
q ), u $← U(Zq); return (a, u).
The decision LWE problem for (n, q, χ) is to distinguish Oχ,s from U. In particular, for algorithm
A, deﬁne the advantage
Advdlwe
n,q,χ(A) =
q : AOχ,s() = 1) − Pr(AU () = 1)
(cid:12)(cid:12)(cid:12) .
(cid:12)(cid:12)(cid:12)Pr(s $← Zn
13
Rounded Gaussian
Scheme
Attack
Classical
Challenge
Primal
Dual
Primal
Dual
Recommended Primal
Dual
Primal
Dual
Paranoid
m
338
331
549
544
716
737
793
833
b
266
263
442
438
489
485
581
576
C
–
–
138
136
151
150
179
177
Q
–