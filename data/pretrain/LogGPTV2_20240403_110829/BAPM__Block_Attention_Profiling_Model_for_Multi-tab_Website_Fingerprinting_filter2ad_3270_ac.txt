According to previous multi-tab WF attack results, the second page
is usually harder to distinguish than the first page. [6] illustrates
the reason why the second page classification is more challenging
is that the beginning part of a packet trace plays a more important
role in the classification. However, except for the first page, all
beginning parts of following pages are covered by the overlapping
area, mixed with its previous page. Consistent with this finding,
results on the second page inevitably show a decline, especially
for PSP-WF which removes the overlapping area. Besides, PSP-
WF needs to pinpoint the splitting point firstly but the prediction
accuracy drops about 30% for the second splitting point. Thus the
second page is more likely to be wrongly split and influence the
next website classification result.
6.2 Ablation Analysis
As mentioned above, the block division and attention-based profil-
ing are two key components in BAPM to deal with multi-tab packet
traces. We conduct two ablation analysis experiments for them
separately to demonstrate their effectiveness. Three comparison
models are full BAPM, BAPM without block division and BAPM
without multi-head attention. Figure 5(a), Figure 5(b) and Figure 5(c)
display three evaluation metrics, and solid lines depict results on
the first page while dotted lines represent the second page.
Compare the results between BAPM with and without the block
division module, we can find that the block division help to improve
254ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Guan, et al.
Table 3: Comparison experiment results on two-tab packet traces under five overlapping proportions
Overlapping proportion
Metrics
1st Page
2nd Page
BAPM
PSP-WF
PSE-WF
Multi-DF
BAPM
PSP-WF
PSE-WF
Multi-DF
10%
Pre
86.1
81.8
57.5
50.0
78.7
41.0
47.2
42.6
Acc
85.1
81.1
36.7
51.1
77.9
27.0
30.7
40.8
Rec
85.0
80.4
36.2
50.6
77.9
25.5
29.8
39.0
Acc
86.2
71.9
35.0
50.9
78.9
22.1
30.1
41.9
20%
Pre
86.8
74.5
52.3
49.7
79.3
35.0
46.8
42.6
Rec
85.9
70.6
34.6
50.9
78.8
20.2
29.0
40.2
Acc
84.7
64.4
38.4
50.5
78.0
19.2
31.9
39.1
30%
Pre
85.1
68.6
56.4
50.2
78.4
29.0
49.2
41.2
Rec
84.5
63.0
37.4
52.0
77.2
18.5
30.6
38.7
Acc
86.4
54.4
36.4
51.9
75.0
15.7
30.6
41.5
40%
Pre
86.8
60.9
54.2
51.4
74.6
24.5
48.0
40.9
Rec
86.4
52.0
35.7
52.7
74.4
15.0
29.5
40.3
Acc
83.2
42.5
37.6
48.7
71.9
15.4
29.3
36.0
50%
Pre
84.0
51.0
56.6
48.4
72.5
23.4
48.1
37.2
Rec
82.9
40.5
36.5
49.5
71.3
14.9
28.0
37.8
(a) Attention distribution of the first page tab
(a) Overall accuracy
(b) Average precision
(b) Attention distribution of the second page tab
Figure 6: Attention distribution on blocks of two page tabs
masking the original representation with corresponding attention
scores). We only take the vectors of correctly predicted samples into
account for the reliability. Since there are two attention heads in our
experiments, we get two averaged vectors finally as two tab-aware
representation varieties on A.com and B.com. As we expect, the first
head in Fig. 6(a) mainly focuses on the former part of A.com area,
while the second head in Fig. 6(b) pays more attention on the latter
part belonging to B.com. We notice that attention scores of the
second head are mainly allocated on No.6 ∼ No.9 blocks within the
overlapping area. This proves the importance of overlapping area
acting as the beginning part of the second and also other following
page tabs, same as previous findings. Note that No.1 and No.2 blocks
get higher scores on both two heads and we guess it is possibly
because similar anonymity circuits establishment generates similar
characteristics on packet traces.
6.3 Sensitivity Analysis
Considering that the black-box nature of deep learning based meth-
ods is hard to intuitively display, we try to explain how dose BAPM
contribute to its performance by tuning critical parameters and
observing results in this section. In BAPM, the tab-aware feature
representation is divided into several blocks to preserve local di-
rection patterns of specific page tab. The block number N decides
the granularity of attention mechanism when highlighting block
relations. To find the best value of block number, we repeat the
experiment in section 6.1 and the block number ranges from 1
to 512. The overlapping proportion is set to be 50% since a large
(c) Average recall rate
(d) Improvement on overall accuracy
Figure 5: Results of ablation analysis on BAPM
classification results especially for the second page (a more obvious
improvement about 10%). This is mainly because block division
is the cornerstone of effectively exploiting the overlapping area,
and this area plays a important role on the second page classifica-
tion. In addition, Figure 5(d) displays the accuracy improvements
on two pages, results of the first page (black bars) have almost
no improvement under 10% proportion, but increase by 3% under
50% proportion, which means block division’s effect will be more
obvious on a larger overlapping area.
Towards the comparison between BAPM with and without multi-
head attention, results show that the attention mechanism doubles
all metrics for the first page, and the improvement is even more
obvious for the second page. Theoretically, BAPM would degenerate
into a simple multi-label classifier like Multi-DF without attention,
and block division attached to it would also become meaningless.
We display the attention distribution by visualizing the averaged
vector over all vectors output by the attention layer (i.e., results of
255BAPM: Block Attention Profiling Model for Multi-tab Website Fingerprinting Attacks on Tor
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
mixed with two tabs thus having the largest overlapping area. We
notice that the accuracy of PSP-WF evidently declines compared
with two-tab conditions, a possible reason is that three-tab traces
have four overlapping points and traces will be wrongly split once
PSP-WF wrongly predicts any one of points.
Table 4: Results on three-tab packet traces
1st page
2nd page
3rd page
BAPM
PSP-WF
PSE-WF
Multi-DF
Acc
Pre
Rec
Acc
Pre
Rec
Acc
Pre
Rec
Acc
Pre
Rec
91.3
91.2
91.1
30.9
36.2
31.6
23.0
45.8
22.0
35.1
36.6
36.7
63.5
66.8
63.3
30.6
34.4
31.5
15.6
34.4
15.1
32.8
32.7
28.7
74.7
77.3
74.6
4.0
3.7
3.9
18.9
39.5
17.6
24.4
25.0
50.0
Note that three page tabs are the maximum tab number which
has been explored in practice among all multi-tab WF attacks. In
reality, four-tab or more-tab traces may appear, but they are essen-
tially same with three-tab traces in terms of the trace structure. As
shown in Fig. 8, traces with more than two tabs all have three and
only three types of tabs: the first tab with latter part overlapped, the
last tab with front part overlapped, and the middle tab(s) with both
front and latter part overlapped. Each page tab is mixed with two
other tabs at most and no new case occurs when the tab number
grows, thus the complexity does not increase. For our model, it’s the
tab type matters more instead of the tab number, and multi-tab fin-
gerprints won’t break as long as we adjust the BAPM architecture
to make sure that one tab corresponds to one attention head. The
only difference is that we need process longer packet traces during
training and testing, at the expense of more model parameters and
higher time consumption.
Figure 8: Three page tab types under more-tab scenarios
6.5 Results on Open World Packet Traces
We now evaluate the model performance under the open world
setting. 2000, 4000 and 6000 open world websites are randomly
selected from dataset of [27] as non-monitored websites, and the
class number ratios of non-monitored websites to monitored ones
(a) Accuracy versus block numbers
(b) Precision versus block numbers
(c) Recall rate versus block numbers
(d) Model size versus block numbers
Figure 7: Results of sensitivity analysis on block number
overlapping area reflects block division’s effectiveness more obvi-
ously. Accuracy, precision and recall rate are displayed in Fig. 7(a),
Fig. 7(b) and Fig. 7(c), and there are two points in according with
above theoretical analysis:
(1) All three evaluation metrics get better and then worse with
block number increasing, indicating that too small or large block
number both have negative effect. As discussed above, small number
lets each block contain more mixed parts of different pages, and
model has no idea which page tab this block has stronger connection
with. On the contrary, reducing the block size would “purify” one
block’s content, but it’s also harder to group blocks together through
only a few features of small blocks. Besides, block division with
proper block number improves results on two pages especially for
the second one. Here the block number of 1 is equal to BAPM
without block division in section 6.2, and we detail the conclusion
that effective block number ranges from 4 to 128, with the value of
16 maximizing the effectiveness.
(2) The model size of BAPM shows a same trend as three eval-
uation metrics. Fig. 7(d) gives the model size in MB which firstly
decreases and then rises again with the block number increasing.
The tuning point of model size is in the almost same position as
highest classification accuracy. Therefore, BAPM becomes most
cost-effective when block number is around 16 with strong classifi-
cation ability and low computational complexity.
6.4 Results on Three-tab Packet Traces
Three-tab classification results are shown as Table 4 with a uni-
form 10% overlapping proportion between two adjacent page tabs.
BAPM achieves the best results on all three tabs, showing a bet-
ter robustness when the tab number increases: results on the first
tab are best since the beginning part is not destroyed, following
two tabs are harder to classify especially the middle tab which is
256ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Guan, et al.
are 40:1, 80:1 and 120:1, respectively. Packet traces of non-monitored
websites appear on both training and testing sets which means that
attackers can also take non-monitored traces to train their models.
This assumption is called "the standard model under open world" in
[19]. For each trace to classify, we firstly predict whether it belongs
to a monitored website or not, and further predict the specific class
if it is indeed a monitored trace.
Results under three scales of non-monitored websites are dis-