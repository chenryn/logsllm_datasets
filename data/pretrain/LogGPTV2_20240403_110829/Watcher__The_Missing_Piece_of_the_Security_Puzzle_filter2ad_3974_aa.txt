title:Watcher: The Missing Piece of the Security Puzzle
author:John C. Munson and
Scott Wimer
Watcher: The Missing Piece of the Security Puzzle 
John C. Munson 
Computer Science Department 
University of Idaho 
Moscow, ID 
PI:EMAIL 
Abstract 
  Modern  intrusion  detection  systems  are  comprised 
of  three  basically  different  approaches,  host  based, 
network  based,  and  a  third  relatively  recent  addition 
called  procedural  based  detection.    The  first  two  have 
been extremely popular in the commercial market for a 
number of years now because they are relatively simple 
to  use,  understand  and  maintain.    However,  they  fall 
prey  to  a  number  of  shortcomings  such  as  scaling  with 
increased traffic requirements, use of complex and false 
positive prone signature databases, and their inability to 
detect  novel  intrusive  attempts.    The  procedural  based 
intrusion  detection  systems  represent  a  great  leap 
forward over current security technologies by addressing 
these  and  other  concerns.    This  paper  presents  an 
overview  of  our  work  in  creating  a  true  procedural 
Disallowed Operational Anomaly (DOA) system.   
1. Introduction 
All  modern  software  design  methodologies  have 
their  origin  in  the  very  primitive  standalone  computer 
environments.      These  computer  systems  were  not 
hooked  up  to  the  Internet  nor  even  simple  local 
networks.    Typically  one  job  ran  on  the  computer  at  a 
time and jobs were batched and run sequentially.   In this 
environment,  the  only  threat  to  a  program's  integrity 
while it was executing was provided by the ineptitude of 
the computer operator.   Life was simple enough that the 
execution  of  the  program  could  be  monitored  as  it  ran 
through light displays on the operator's console.   Control 
of the program  was provided by the computer operator.  
Over  time,  control  of  program  execution  gradually 
shifted  from  the  operator  to  the  operating  system.    A 
human  being  simply  could  not  respond  in  a  timely 
fashion  to  the  demands  of  a  program  running  at 
electronic speeds. 
From  a  computer  security  standpoint,  the  computer 
hardware, the operating system, user applications and the 
Scott Wimer 
Software Systems International, LLC 
121 Sweet Avenue 
Moscow, ID 83844 
PI:EMAIL 
The 
of 
the 
original 
evolution 
computer  operator  were  all  well  contained  within  the 
confines  of  a  room  whose  perimeter  could  be  secured 
with  existing  security  technology.    In  this  limited 
environment,  there  was  little  need  to  consider  invasive 
forces from outside.  That only came when the complete 
secure environment was compromised by attaching it to 
a  completely  unregulated  and  potentially  hostile 
information ether.   
computing 
environment  was  almost  exactly  duplicated  by  the 
evolution  of  the  personal  computer.    Originally  these 
systems were self contained computers.  They were used 
for  entertainment  and,  to  a  limited  extent,  for  business.  
Then  everything  changed  (except  for  the  underlying 
security premise).  People attached modems to their PC's 
and  connected  to  the  Internet.    The  software  that  they 
were  running  was  designed  to  run  in  a  contained  and 
completely encapsulated environment. 
The Internet was not a major factor in the design of 
early  Windows  O/S's. 
  It  was  certainly  not  even 
considered  when  the  architectural  framework  for  UNIX 
was laid down.  It still isn't a design consideration in the 
evolution  of  legacy  code  for  managing  a  personnel 
system.  We have a security problem today because the 
same naive premise about the operating environment of 
most our software is still in effect.   That is, the software 
will operate in a closely confined hardware facility and if 
it is to be exposed to a more hostile world, a big brother 
security system will protect it.   
The  literature  and  media  abound  with  reports  of 
successful  violations  of  computer  system  security  by 
both  external  attackers  and  internal  users  [7].    These 
breaches  occur 
social 
engineering attacks, and attacks on the system software. 
It is this later category of attack that is the focus of this 
paper. During an attack, the intruder subverts or bypasses 
the  security  mechanisms  of  the  system  in  order  to  gain 
unauthorized  access  to  the  system  or  to  increase  their 
current  access  privileges.  These  attacks  are  successful 
when the attacker is able to exploit a vulnerability in the 
software  to  cause  it  to  execute  in  a  manner  that  is 
through  physical  attacks, 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:06:32 UTC from IEEE Xplore.  Restrictions apply. 
typically inconsistent with the software specification and 
thus lead to a breach in security [1].  Intrusion detection 
systems monitor traces of user activity to determine if an 
intrusion  has  occurred.    The  traces  of  activity  can  be 
collated  from  audit  trails  or  logs  [11,17],  network 
monitoring  [9,15]  or  a  combination  of  both.    Once  the 
data  regarding  a  relevant  aspect  of  the  behavior  of  the 
system is collected, the classification stage starts.   
Although  taxonomies  that  are  more  complex  exist 
[3,9], intrusion detection classification techniques can be 
broadly  catalogued  in  the  two  main  groups:  misuse 
intrusion  detection  [12,13]  and  anomaly 
intrusion 
detection [10].  The first type of classification technique 
searches  for  occurrences  of  known  attacks  with  a 
particular  "signature"  and  the  second  type  searches  for 
departures from normality.  Some of the newest intrusion 
detection tools incorporate both approaches [2,16]. 
  Most current intrusion detection techniques examine 
the input to software or the output from software.  NIDS 
(Network-based  Intrusion  Detection  Systems)  tools  fit 
directly into this category.  Log scanning tools also fall 
into  this  category.      Other  tools  examine  the  input  and 
output of the system calls made by programs.  These I/O 
driven  intrusion  detection  techniques  have  built  in 
limitations.    These  limitations  are  discussed  below 
because they represent the primary challenges successful 
new intrusion detection techniques need to overcome. 
As  we  will  see  in  the  behavioral  software  model, 
program  modules  are  distinctly  associated  with  certain 
functionalities and operations that the program is capable 
of performing.   As each operation is executed, a subset 
of  software  modules  is  executed  which  creates  a 
particular  and  distinct  signature  of  module  executions 
[15].    An  alternative  approach  examines  sequences  of 
system  calls  as  indicators  of  system  behavior  [cf.  18].  
What is missing in these approaches is an understanding 
that  a  program  is  being  driven,  ultimately  by  a  human 
being whose activity set constitutes behavior.  Thus, we 
can  say  that  this  user  behavior  induces  characteristic 
behavior  on  the  part  of  the  program.      Further,  when 
users  are  behaving  perfectly  normally,  this  normal  user 
behavior induces normal or nominal behavior on the part 
of the program.  As we come to understand the nominal 
behavior  of  a  system  as  it  is  executing  its  customary 
activities  we  can  profile  this  nominal  system  behavior 
quite  accurately.    Departures  from  the  nominal  system 
profile  represent  potential  malicious  activity  on  the 
system.    
Some  unwanted  activity  may  be  understood  from 
previous  assaults  on  the  system.    We  can  store  profiles 
and  recognize  these  activities  from  our  historical  data.  
What  historical  data  cannot  do  is  to  permit  us  to 
recognize new assaults.  An effective security tool would 
be designed to recognize assaults as they occur through 
the  understanding  and  comparison  of 
the  current 
the 
  This  holds 
behavior  against  nominal  system  activity.        This  can 
only be accomplished if the program is instrumented and 
its  activity  is  closely  watched. 
  Monitoring  and 
controlling  program  execution  at  run  time  through 
behavioral  control  is  the  missing  piece  in  the  security 
puzzle. 
2. Current state of the art 
In the current state of the art of intrusion and misuse 
detection, the software system is regarded as a black box.  
The misuse determination is made either on the basis of 
data inputs to the system or data outputs from the system.  
For any given program, the set of all possible input data 
is  enormous. 
true  for  all  software:  
applications,  servers,  compilers,  and  operating  systems.  
The set of all valid input is usually substantially smaller 
than  the  total  input  set.    A  useful  example  would  be  a 
web server that only knows how to parse input that is in 
accordance  with  the  HTTP  specification.    A  string  of 
3000  'a's  would  not  constitute  valid  input  for  that  web 
server.      The  web  server  will  behave  differently  when 
handling  GET  request  than  when  it  is  passed  the  huge 
string  of  'a's.    The  set  of  invalid  input  consists  of  all 
members  of  the  total  input  set  that  are  not  members  of 
the valid input set.   
Each  program  has  a  set  of  potentially  destructive, 
intrusive and  malicious input. Rule and signature based 
intrusion  detection  techniques  exploit  this  set  to  spot 
attacks. 
input  data  for 
occurrences of items from the known  malicious set and 
raise an alarm when a match is found.  The discovery of 
new elements for the malicious set is a difficult and time 
consuming task.  Research has established that variations 
on known malicious input slip past many signature based 
IDS tools [8,17]. Therefore each of these variations must 
then be added to the set of known malicious input.  This 
growth  challenges 
the  ability  of  signature  based 
techniques to scale. 
A  second  drawback  to  examining  the  input  for 
instances of malicious data is the "post attack" nature of 
the discovery process.  The set of malicious input is not 
known a priori for each program.  Rather, elements are 
added to the set as new attacks are observed, studied and 
de-constructed.    Attacks  that  security  professionals  do 
not  get  to  study  may  never  result  in  additions  to  the 
known  malicious  input  set.      Therefore,  the  discovery 
process is dependent on successful attacks, and thorough 
forensic  work  following  these  attacks.    This  leads  to  a 
race between the attackers and the security community.  
Intrusion detection tools can monitor the output data 
for  matches  against  the  known  malicious  output  set.  
These tools raise an alarm if a match is found. By adding 
fingerprint  type  patterns  to  data  that  should  be  kept 
private, these tools can also function as a simple access 
  These  systems  scan 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:06:32 UTC from IEEE Xplore.  Restrictions apply. 
in  execution  behavior 
control list, raising the alarm when the sensitive data are 
leaked.    Tools  that  function  this  way  have  the  same 
primary limitations as tools that look at the input data to 
programs.    The  information  provided  is  useful  but  not 
timely if the goal is to prevent attacks from succeeding.  
Knowing  that  an  attack  has  succeeded  may  better  than 
not knowing at all, but the information is not available in 
time to take action. 
From  our  perspective,  the  input  to  a  program 
determines  the  execution  behavior  of  the  program.    In 
fact,  a  specific  change 
to 
compromise the system in some way is the goal of many 
attacks  and  exploits.    The  ability  to  identify  these 
behavioral  changes  would  be  valuable.    Even  more 
valuable  would  be  the  ability  to  stop  these  behavioral 
changes.    Preventing  these  changes  would  thwart  many 
types of attacks. 
3. The software behavioral model 
In  order  to  understand  running  software  it  will  be 
necessary  to  build  a  metaphor  that  describes  what  the 
software is doing in relation to the user who is causing it 
to  perform  useful  work. 
  Software  systems  are 
constructed  to  perform  a  set  of  operations  for  their 
customers, the users.  An example of such an operation 
might be the activity of adding a new user to a computer 
system [1].  At the software level, these operations must 
be  reduced  to  a  well-defined  set  of  functions.    These 
functions represent the decomposition of operations into 
sub-problems  that  may  be  implemented  on  computer 
systems.    The  operation  of  adding  a  new  user  to  the 
system  might 
the  functional  activities  of 
changing to current directory to a password file, updating 
the  password  file,  establishing  user  authorizations,  and 
creating a new file for the new user.  During the software 
design process, the basic functions are mapped by system 
designers to specific software program modules.  These 
modules will implement the functionality.   
From  the  standpoint  of  computer  security,  not  all 
operations  are  equal.    Some  user  operations  may  have 
little  or  no  impact  on  computer  security  considerations.  
Other operations, such as, system maintenance activities, 
have  a  much  greater  impact  on  security.    System 
maintenance  activities  being  performed  by  systems 
administrators  would  be  considered  nominal  system 
behavior. 
  System  maintenance  activities  being 
performed by dial-up users, on the other hand, would not 
be  considered  nominal  system  behavior.    In  order  to 