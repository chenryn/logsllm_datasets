title:Measuring Information Leakage in Website Fingerprinting Attacks and
Defenses
author:Shuai Li and
Huajun Guo and
Nicholas Hopper
Measuring Information Leakage in Website Fingerprinting
A(cid:29)acks and Defenses
Shuai Li
University of Minnesota
Minneapolis, MN
PI:EMAIL
Huajun Guo
University of Minnesota
Minneapolis, MN
PI:EMAIL
Nicholas Hopper
University of Minnesota
Minneapolis, MN
PI:EMAIL
9
1
0
2
n
u
J
5
]
R
C
.
s
c
[
2
v
0
8
0
6
0
.
0
1
7
1
:
v
i
X
r
a
ABSTRACT
Tor provides low-latency anonymous and uncensored network ac-
cess against a local or network adversary. Due to the design choice
to minimize traﬃc overhead (and increase the pool of potential
users) Tor allows some information about the client’s connections
to leak. Attacks using (features extracted from) this information
to infer the website a user visits are called Website Fingerprinting
(WF) attacks. We develop a methodology and tools to measure the
amount of leaked information about a website. We apply this tool
to a comprehensive set of features extracted from a large set of
websites and WF defense mechanisms, allowing us to make more
ﬁne-grained observations about WF attacks and defenses.
CCS CONCEPTS
• Security and privacy → Web protocol security;
KEYWORDS
Website Fingerprinting; Tor; Anonymity
ACM Reference Format:
Shuai Li, Huajun Guo, and Nicholas Hopper. 2018. Measuring Information
Leakage in Website Fingerprinting Attacks and Defenses. In 2018 ACM
SIGSAC Conference on Computer and Communications Security (CCS ’18),
October 15–19, 2018, Toronto, ON, Canada. ACM, New York, NY, USA, 17 pages.
https://doi.org/10.1145/3243734.3243832
1 INTRODUCTION
The Tor anonymity network uses layered encryption and traﬃc
relays to provide private, uncensored network access to millions
of users per day. This use of encryption hides the exact contents
of messages sent over Tor, and the use of sequences of three relays
prevents any single relay from knowing the network identity of
both the client and the server. In combination, these mechanisms
provide eﬀective resistance to basic traﬃc analysis.
However, because Tor provides low-latency, low-overhead com-
munication, it does not hide traﬃc features such as the volume,
timing, and direction of communications. Recent works [22, 34, 46]
have shown that these features leak information about which web-
site has been visited to the extent that a passive adversary that
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS ’18, October 15–19, 2018, Toronto, ON, Canada
© 2018 Association for Computing Machinery.
ACM ISBN 978-1-4503-5693-0/18/10. . . $15.00
https://doi.org/10.1145/3243734.3243832
records this information is able to train a classiﬁer to recognize
the website with more than 90% accuracy in a closed-world sce-
nario with 100 websites. This attack is often referred to as a Web-
site Fingerprinting (WF) attack. In response, many works [5, 6, 9,
11, 33, 35, 37, 46, 48, 49] have proposed defenses that attempt to
hide this information, by padding connections with extra traﬃc or
rearranging the sequence in which ﬁles are requested.
Defense Evaluation. To evaluate a defense, the popular practice
is to train classiﬁers based on altered traﬃc characteristics and
evaluate the eﬀect of the defense by classiﬁcation accuracy. If the
accuracy of the classiﬁer is low enough, the defense is believed
to be secure with minimal information leakage; one defense is be-
lieved to be better than another if it results in lower accuracy.
Accuracy vs. Information Leakage. We raise a question: does low
accuracy always mean low information leakage from WF defenses?
Our answer is no. The ﬁrst reason is that accuracy is classiﬁer-
dependent. It is possible that the information leakage of a WF de-
fense is high, but the classiﬁer is ineﬀective, so that its accuracy is
low. More importantly, accuracy is all-or-nothing: classiﬁers out-
put a single guess and if it is wrong, this is judged to mean the
defense has been successful. But it ignores cases where a classiﬁer
may confuse some pages with a small set of others. In such situa-
tions, an attacker may well be able to signiﬁcantly reduce the set
of likely pages represented by a ﬁngerprint, even if they cannot
reliably choose the correct page from among this set. We can see
that the ﬁngerprint can contain a great deal of information about
the web page even if the classiﬁer cannot accurately identify the
correct page. Accuracy is prone to underestimate the information
7
6
5
4
3
2
1
)
t
i
B
(
e
g
a
k
a
e
L
n
o
i
t
a
m
o
f
n
I
Generic Maximum
Upper Bound
Lower Bound
0
0
0.1
0.2
0.3
0.4
0.5
Accuracy a
0.6
0.7
0.8
0.9
Figure 1: Accuracy vs. Information Leakage. This ﬁgure shows
the range of potential information leakage for a given classiﬁcation
accuracy (in the closed-world setting with 100 websites)
leakage in WF defenses, or in other words, low accuracy doesn’t
necessarily mean low information leakage.
We further prove the above observation by the information-theoretic
quantiﬁcation upon a given accuracy. We ﬁnd that in a closed-
world setting with n websites, a feature set yielding a classiﬁer
with accuracy α could leak information through the classiﬁer with
the uncertain range (1 − α) log2(n − 1) (the diﬀerence between the
maximum and minimum). The proof also shows that such uncer-
tainty increases with lower accuracy. Figure 1 shows that when
n = 100 and α = 0.95, the uncertain range is only 0.33 bit; but
when α = 0.05, the possible leakage could be as high as 6.36 bits
and as low as 0.06 bits! This uncertainty reveals the potential dis-
crepancy between information leakage and accuracy in evaluating
WF defenses, though its impact on WF attacks is limited. Low in-
formation leakage implies low classiﬁcation accuracy, but the con-
verse is not necessarily true, thus we argue that validating WF
defenses by accuracy alone is ﬂawed.
Feature Evaluation. Diﬀerent features may carry diﬀerent amounts
of information. WF defense designers can evaluate features to ﬁnd
more informative ones to hide [6]; attackers can do so to discover
highly informative features and optimize their feature set [22]. Ex-
isting works [6, 22] designed comparative methods to rank the fea-
tures by their information leakage, but these methodologies do not
give a straightforward way to quantify the relationships between
features. How much information do features A and B share? If fea-
ture A is more informative than features B or C alone, are features
B and C together more informative than A? These methodologies
are unable to answer these questions.
We argue that these coarse-grained evaluations of features and
defenses are overly simplistic. The analysis of new WF attack fea-
tures and defenses should start with the question: how much infor-
mation is leaked? To answer this question, two challenges should
be addressed. The ﬁrst challenge is ﬁnding a way to model the be-
havior of WF features and the interaction between them; these fea-
tures can have highly complex relationships and behavior, exhibit-
ing distributions that could be discrete, continuous, or even partly
discrete and partly continuous. The second challenge is the curse
of dimensionality when estimating the total information leakage,
as the state-of-art feature sets are usually high-dimensional. Un-
fortunately, existing works [10, 32] limited their experimental mea-
surement to features’ individual information leakage, and they can-
not overcome these challenges.
Information Leakage Measurement Framework. In this paper,
we develop WeFDE (for Website Fingerprint Density Estimation),
a methodology for modelling the likelihood functions of website
ﬁngerprints, and a set of tools for measuring the ﬁngerprints’ infor-
mation leakage. To address the ﬁrst challenge, WeFDE uses adap-
tive kernel density estimation [44] to model the probability den-
sity function of a feature or a category of features. By allowing
kernels to determine their bandwidth separately, we adaptively
model both continuous and discrete density functions; by estimat-
ing multi-dimensional kernels over sets of features, we model the
interactions between features. We address the second challenge by
introducing a set of dimension reduction approaches. Firstly, we
measure features’ pairwise mutual information to exclude redun-
dant features. Secondly, we use Kononenko’s Algorithm [8, 27] and
DBSCAN [13] to separate features into sub-groups, which have
pairwise mutual information higher than a threshold ϵ within each
group, and lower than ϵ among diﬀerent groups. Then we apply
adaptive kernels for each sub-group with reduced dimensionality.
Finally, our experiment shows that by including enough highly in-
formative features we are able to approximate the overall informa-
tion leakage. This enables us to further reduce the dimensionality
of our measurement.
Measurement Results. We apply WeFDE to a comprehensive list
of 3043 features (including, to the best of our knowledge, all fea-
tures in the Tor WF literature [7, 11, 22, 34, 36, 40, 46, 47]) extracted
from a 211219 Tor web browsing visits for about 2200 websites.
Among the features of WF attacks, we ﬁnd that: (a) 45.36% of 183
most informative features are redundant; (b) an individual feature
leaks no more than 3.45 bits information in the closed-world set-
ting with 100 websites, which is the maximum leakage we observe
in our experiment from the feature of rounded outgoing packet
count; (c) download stream, though having more packets than up-
load stream, leaks less information; (d) a larger world size has lit-
tle impact on a WF feature’s individual information leakage. We
also include WF defenses such as Tamaraw [6], BuFLO [11], Su-
persequence [46], WTF-PAD [25], and CS-BuFLO [5] to study the
discrepancy between accuracy and information leakage. Our ex-
perimental results conﬁrm this discrepancy and demonstrate that
accuracy alone is not reliable to validate a WF defense or compare
multiple ones. We also ﬁnd that the information leakage of WTF-
PAD [25] is unusually high. Interestingly, recent work [42] con-
ﬁrms our result by achieving 90% classiﬁcation accuracy against
WTF-PAD.
Contributions. We provide our contributions as follows. First, this
paper identiﬁes that validating WF defenses by accuracy alone is
ﬂawed. By information-theoretic quantiﬁcation, we ﬁnd that when
accuracy is low, its corresponding information leakage is far from
certain. Second, we propose WeFDE which makes it possible to
measure the joint information leakage from a large set of features.
In contrast, existing works only limited their experimental mea-
surement to features’ individual information leakage, and they can-
not cope with features of complex property. WeFDE overcomes
these two limitations. We also release the source code of WeFDE
in the GitHub repository1. Third, we use WeFDE to perform infor-
mation leakage measurement for all 3043 features proposed in the
Tor website ﬁngerprinting literature, based on a large dataset hav-
ing 211219 Tor web browsing visits to about 2200 websites. As far
as we know, our work is the ﬁrst large-scale information leakage
measurement in the literature. Fourth, our measurement results
provide the new information-theoretic insights upon WF features,
and these results give the empirical conﬁrmation that accuracy is
not reliable to validate a WF defense or compare multiple ones.
The paper is organized as follows: Section 2 and Section 3 give
background and related works on WF attacks and defenses, with
Section 4 introducing the features. Section 5 introduces the system
design of WeFDE. Section 6, Section 7, Section 8, and Section 9 give
1https://github.com/s0irrlor7m/InfoLeakWebsiteFingerprint
information leakage measurement results, and Section 10 provides
discussions. Finally, we conclude in Section 11.
2 WF ATTACK MODELS
A WF attacker aims at learning which website a user has visited.
The attacker can be an Internet Service Provider (ISP) or a mali-
cious Tor entry guard. It is supposed to be passive (no packet ma-
nipulation), but it can eavesdrop the traﬃc originated from or des-
tinated to the user. Without turning to traﬃc contents or its IP
addresses (both can be encrypted or obfuscated), the attacker in-
spects the traﬃc ﬁngerprints for detection. These ﬁngerprints can
be packet length or the transmission time. Neither Cryptographic
algorithms nor the anonymous services such as Tor can cover such
ﬁngerprints. State of art attacks [22, 34, 46] demonstrate that the
ﬁngerprints carry suﬃcient information that the attacker can pin-
point the visited website by more than 90% accuracy (with assump-
tions). In the following, we introduce two attack models of the web-
site ﬁngerprinting attack.
Closed-World Attack Model. An attacker in the closed-world
knows a set of websites C = {c1 , c2 , · · · , cn } the user may visit.
We adopt an equal-prior model, in which the user visits a website
with probability 1/n. The attacker’s goal is to decide which oneis
visited.
Open-World Attack Model. The attacker in this attack model
has a set of websites for monitoring; its goal is to decide whether
the user visited a monitored website or not, and if yes, which moni-
tored website. Though the user may visit any website, a non-monitored
set of websites are introduced to approximate the user visiting the
non-monitored websites. We consider a popularity-prior model, in
which we give prior probabilities to websites by their popularity,
without considering whether the websites are monitored or not.
3 RELATED WORK
Website Fingerprinting Attacks. The ﬁrst category of WF at-
tacks targeted encrypted protocols with no packet length hiding [30].
More recent website ﬁngerprinting attacks focus on Tor anony-
mous service, in which the unique packet length is hidden by ﬁxed-
size Tor cells. Cai et al. [7] used edit distance to compare Tor packet
sequences, and achieved 86% accuracy in the closed-world scenario
with 100 websites. Wang and Goldberg [47] further improve the ac-
curacy to 91% by using Tor cells instead of TCP/IP packets, delet-
ing SENDMEs, and applying new metrics such as fast Levenshtein.
Their later work [46] increases the accuracy by using a KNN clas-
siﬁer. Panchenko et al. [34] introduces a new method to extract the
packet number information, which increases the accuracy by 2%.
Recently, Hayes and Danezis [22] use random forests to construct
the current state-of-art website ﬁngerprinting attack.
Website Fingerprinting Defenses. Several defenses have been
proposed to defeat WF attacks. One category of defenses try to ran-
domize the traﬃc ﬁngerprints by traﬃc morphing [49], loading a
background page [35], or randomized pipelining [37]. These are
demonstrated ineﬀective by several works [7, 46].
Another category of defenses try to hide traﬃc features by de-
terministic approaches. By holding the packets or creating dummy
packets, BuFLO [11] requires the packets sent in ﬁxed size and
ﬁxed time interval. The packets are padded until reaching a trans-
mission time threshold τ if their original transmission time is shorter.
Otherwise, BuFLO lets the traﬃc ﬁnish. CS-BuFLO [5] is proposed
to extend BuFLO to include congestion sensitivity and some rate
adaptation. Tamaraw [6] improves the eﬃciency of BuFLO by two
methods. First, it allows diﬀerent transmission rate for outbound
and inbound traﬃc. Second, it pads to make the packet count a
multiple of parameter L: if the packet number in one direction is
more than nL and less than (n + 1)L, it sends padding packets un-
til the count is (n + 1)L. Supersequence [46] utilizes clustering al-
gorithms to group websites. For each group of websites, Superse-
quence computes a super trace to be the manner of transmitting
the instances of the websites under this group. WTF-PAD [25] uses
adaptive padding to be eﬃcient. Our paper includes these defenses
for information leakage evaluation. We leave recently proposed de-
fenses [9, 48] in our future work.
Website Fingerprinting Evaluation. Juarez et al. [24] eval-
uates the eﬀectiveness of WF attacks in practical scenarios, enu-
merating several assumptions about user settings, adversary capa-
bilities, and the nature of the web that do not always hold. With-
out these assumptions, the accuracy of the attacks are signiﬁcantly
decreased. Cai et al. [6] use a comparative method to analyze de-
fenses. They apply generators to transform a website class C into
C ′, making C and C ′ diﬀer only by one (category of) feature. Then
they evaluate whether a speciﬁc defense is successful in hiding the
feature. Though they claim this method can shed light on which
features convey more information, the information leakage com-
parison between features is unclear and not quantiﬁed.
Cherubin [18] provides the lower bound estimate for an attacker’s
error. The error of the Nearest Neighbor classiﬁer is used to esti-
mate the lower bound of the Bayes error, which is further used to
be the lower bound for the error of any classiﬁer. Based on such
lower bound, a new privacy metric called (ξ ,
Φ)–privacy is pro-
posed. Though this privacy metric is not dependent on any spe-