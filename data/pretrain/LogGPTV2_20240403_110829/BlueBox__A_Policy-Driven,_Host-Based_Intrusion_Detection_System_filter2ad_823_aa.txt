title:BlueBox: A Policy-Driven, Host-Based Intrusion Detection System
author:Suresh Chari and
Pau-Chen Cheng
BlueBoX: A Policy–driven, Host–Based Intrusion Detection system
Suresh N. Chari
Pau–Chen Cheng
IBM Thomas J. Watson Research Center
Yorktown Heights, NY 10598, U.S.A.
schari,pau @watson.ibm.com
Abstract
In this paper we describe our experiences with build-
ing BlueBox, a host based intrusion detection system. Our
approach can be viewed as creating an infrastructure for
deﬁning and enforcing very ﬁne grained process capabili-
ties in the kernel. These capabilities are speciﬁed as a set
of rules (policies) for regulating access to system resources
on a per executable basis. The language for expressing the
rules is intuitive and sufﬁciently expressive to effectively
capture security boundaries.
We have prototyped our approachon Linux 2.2.14kernel,
and have built rule templates for popular daemons such
as Apache 2.0 and wu-ftpd. We are validating our design
by testing against a comprehensive database of known at-
tacks. Our system has been designed to minimize the kernel
changes and performance impact and thus can be ported
easily to new kernels. We will discuss the motivation and
rationale behind BlueBox, its design, implementation on
Linux, and related work.
1 Introduction
The two mechanisms predominantly used to secure ap-
plication servers today are ﬁrewalls and network intru-
sion detection systems. One of the attractive features of
these mechanisms is that they are independent of the server
and thus, easily deployed. Firewalls controls the ﬂow of
through communication and network IDSs detect possible
attacks by monitoring the communication. While ﬁrewalls,
when properly conﬁgured, serve their intended purpose,
current network IDSs suffer from a number of limitations.
Network IDSs typically analyze trafﬁc on the network and
either scan for patterns containing known attacks or detect
statistically abnormal patterns. With the advent of traf-
ﬁc encryption protocols such as SSL [FKK96, DA97] and
IPSEC [Atk95], a signiﬁcant portion of trafﬁc on the Inter-
net is encrypted and therefore is unavailable for examina-
tion. Also, there are well–known ways to evade network
IDSs [PN98]. Thus, increasingly, intrusion detection must
move to the host server where the content is visible in the
clear and these evasion techniques do not work. Our sys-
tem, BlueBox, is such a host based real–time intrusion de-
tection system and it can also be conﬁgured for blocking
intrusions.
To contrast our approach we ﬁrst look at mechanisms
used in currently deployed host based IDSs. They are pri-
marily based on one of the following [DDW99, Jac99]:
Anomaly detection : Deﬁned by a statistical pro-
ﬁle of “normal” behavior [JV94, ALJ 93, FHSL96,
DDNW98]. A pattern that deviates signiﬁcantly from
the normal proﬁle is considered an attack.
Misuse detection: Deﬁned by collections of signatures
of known attacks [Jac99, Pax98, RLS 97, CDE 96].
Activities matching such patterns are considered at-
tacks.
Conceptually, misuse detection is based on knowledge
of bad behaviors (attacks) and anomaly detection is based
on knowledge of good (normal) behaviors. If both tech-
niques were perfect, then each would exactly complement
the other:
i.e. what is not bad is good and vice versa.
In reality, neither technique is perfect. Misuse detection
can never know all possible attacks and it usually classi-
ﬁes some good behaviors as attacks. Likewise, anomaly
detection can not cover all good behaviors and will mis-
take some attacks for good behaviors. Also, an entity’s be-
havior proﬁle will change as its usage pattern changes. So
anomaly detection has to adapt its proﬁle to these changes.
This opens the possibility for an attacker to gradually in-
crease its level of malicious activities until these activities
are considered normal.
Our policy–driven technique, like the concept of sand-
boxing, tries to deﬁne the boundary between the good and
the bad as a set of rules. These rules specify what an ex-
ecutable program or script is allowed to do and attempts
to violate them are considered intrusions. The rules gov-
erning a process deﬁne precisely which system resources
a process can access and in what way. Section 3 gives an
overview of what the scope of the rules are. The rules are
deﬁned through precise understanding of the expected be-
havior of the program. They can be deﬁned using existing
templates, audit trails, conﬁguration and, if necessary, pro-
gram semantics. The rules are speciﬁed off–line, compiled
into a machine readable binary which is associated with
the program and loaded into the kernel when the program
is executed. Rule enforcement happens when the program
is executed in the context of a process: the behavior of the
process is checked and constrained according to the rules.
The enforcement is done in the kernel during invocations
of system calls. The concept of sandboxing has appeared
in numerous contexts including IDS and we discuss this in
Section 2.
We believe that the policy–based approach of Blue-
Box and like systems offers a number of advantages over
the traditional attack–signature–based or proﬁle–based ap-
proaches. They include:
The security boundaryis much more precisely deﬁned
in terms of the intended use of the sensitive system
resources. Rules are based on understanding a pro-
gram’s behavior and not on attack signatures or time–
variant, incomplete statistical proﬁles of “normal” be-
havior. This has two advantages: (1) unknown attacks
can be detected, (2) previously unseen but legitimate
behaviors would not be mistaken for attacks. There-
fore the false positive and (hopefully) the false nega-
tive rates will be lower.
Another potential win is the manageability of the IDS
especially as compared to statistical proﬁling based
techniques. There is no need to constantly maintain
and update attack–signature database or statistic pro-
ﬁles. Since the rules are precisely deﬁned in terms of
system resources and not by attacks, there will be very
few updates, if any, of rules for an application running
on a particular platform.
Perhaps the most important advantage of BlueBox’s
policy–based approach is that detection is done in
real–time.
therefore there is the option to block an
unauthorized access or act.
On the other hand, since the rules are deﬁned on access
to system resources there are disadvantages as compared to
other IDSs. Some of them are:
Version Migration: Since different versions of appli-
cations may access different resources every version
will require modiﬁed sets of rules. However, in our
experience with the Apache http server, minor version
changes impact the rules very minimally. Even with
major version changes, large chunks of the rule sets
can be reused.
In Memory attacks: Since the checks on process be-
havior are made only when the process makes a sys-
tem call, attacks which are ’in memory’ can not be
detected.
The rest of the paper is organized as follows: Section 2
surveys related work and compares them with our system.
Section 3 gives an overview of the speciﬁcation and gen-
eration of rules. Section 4 presents the technical details of
our design and implementation, the precise scope of rules
and the system architecture. Section 5 presents a few ex-
amples of how BlueBox thwarts several well knownattacks
and also details experiences on specifying rules. Section 6
discusses the performance impact of the IDS and we con-
clude in Section 7.
2 Related Work
Restricting program behavior based on externally spec-
iﬁed rules has a very long history dating back to the ref-
erence monitors of operating systems several decades ago.
In this section, we highlight more recent mechanisms and
compare them with our work. Some of the systems are very
different from BlueBox while others are very similar.
2.1 Language Based mechanisms
There are a large number of language based mechanisms
to restrict program behavior based on policy. They range
from the theoretical program correctness methodology of
using asserts, to the popular type based mechanisms en-
forced by the loader such as the famed Java Virtual Ma-
chine [JVM01]. While the security guarantees promised by
these mechanisms are stronger than ours, they make very
strong and in some cases, unrealistic, assumptions about
the trusted computing base (TCB). Some classes of such
systems include the following:
2.1.1 Program Correctness Based Mechanisms
This method has been the subject of extensive research
spanning decades. Recently, these mechanisms have been
proposed as effective mechanisms to mitigate exposures
[UES00]. While theoretically elegant, they are largely re-
stricted to checks in the user space. Hence, the TCB needed
for these mechanisms to be effective is unrealistic since all
the checks inserted in to the user space program must be
executed. This is rarely realized in commercial operating
systems: An attacker mounting a buffer overﬂow attack is
in no way restricted by any of the checks inserted in the
original program.
2.1.2 Type based mechanisms
The celebrated Java Virtual Machine is a classic example
of a system which enforces strong checks on interpreted
byte code. For this mechanism to work one has to extend
the TCB to include the interpreter and loader. In several
controlled environments this is possible, however it is not
realistic, for reasons of performance, to have daemons such
as the http server run in this environment.
2.2 System call pattern based systems
These systems identify intrusions by an initial training
phase where exhaustive testing is used to identify the ac-
cepted set of patterns in system call sequences, and then
ﬂagging an intrusion if there are erroneous patterns in sys-
tem calls made by daemons in an actual run. Some ex-
amples are discussed in [FHSL96, DDNW98]. The main
advantage of these systems is the minimized impact on the
kernel i.e. one needs to make few changes to the kernel to
implement them. However, they can not offer strong se-
curity guarantees: Firstly, their efﬁcacy requires exhaus-
tive training to identify normal patterns and if not done
correctly, can result in a large number of false positives.
Secondly they are very sensitive to the exact version of
the monitored software: small changes in source code can
yield very different system call patterns. For example, the
Apache http daemon can be conﬁgured to run using pro-
cesses or threads, and the system call patterns are consider-
ably different. Since BlueBox tries to capture the resources
the daemon uses, there are very few changes between the
two versions.
2.3 Kernel Based reference monitors
In the last few years there has been a renewed interest
in sandboxing by intercepting system calls made by pro-
cesses. We describe some systems and highlight the simi-
larities and differences.
2.3.1 LIDS
The Linux IntrusionDetection system (LIDS) [XB01] aims
to extend the concept of capabilities present in the basic
Linux system by deﬁning ﬁne grained ﬁle access capabil-
ities for each process. BlueBox’s rules for ﬁle system ob-
jects is very similar to this. The complete rule set of Blue-
Box is a strict superset of the LIDS system. Among the
several additional features of BlueBox is the state informa-
tion which is useful in thwarting some attacks as described
in Section 5.
2.3.2 A Program as a Finite State Machine
Sekar et al [SU99] present a system which combines lan-
guage based systems with system call intercept based sys-
tems. Their approach is to model processes with a state di-
agram describing its functionality and then enforcing this
state diagram in the kernel during system call invocation.
They achieve strong security guarantees since the state di-
agram captures exact process semantics. The main draw-
back of this system is the difﬁculty in generating the re-
quired state diagrams for a new process. Also, we conjec-
ture based on our experience in incorporating state, that the
performance penalty in enforcing the rules could be some-
what high.
2.3.3 Generic software wrappers
Generic software wrappers[KFBK00, FBF99] are a mecha-
nism to enforce various access control and intrusion detec-
tion checks triggered by events during process execution.
The infrastructure will register various scripts to be run
based on events, monitor process executionfor these events
to occur, and execute registered scripts when the events oc-
cur. This is a powerful infrastructure which can integrate
numerous approaches to system security under one unify-
ing framework. The main drawbacks of this approach is
the complexity of writing scripts and the performance im-
pact in such a complex framework. We believe that our ap-
proach is much more intuitive and has substantially better
performance.
2.3.4 Other Sandboxing Systems
The system that comes closest to our system is the work
of Bernaschi et al [BGM00]. Their system architecture is
very similar to ours and the main differences are in the syn-
tax and semantics of the rules themselves. The placements
of different parts of the system within the kernel are also
very different. Our placement aims to minimize impact on
the kernel code by placing a wrapper around kernel system
call handlers while their placement tries to minimize per-
formance impact. Our system is extensible to newer ver-
sions of the kernel since by and large the same wrapper
should work for newer kernels.
The Domain–and–Type–Enforcement (DTE) based sys-
tem by Walker et al [WSB 96] groups ﬁle system objects
into sets called types and puts a subject (an executable)
into a domain which has speciﬁc access rights to types.
It does not provide protection on non–ﬁle–system–object
resources and seems to incur more complexity when pro-
viding ﬁne–granularity control than BlueBox.
2.4 User space system call introspection
A valid criticism of systems such as BlueBox is the mod-
iﬁcations to the kernel required to install the infrastructure
to install and enforce process behavior rules. To circum-
vent this, one approach is to use existing monitoring infras-
tructure in kernels such as ptrace to have monitors which
reside in user–space [Wag99, JS00]. The monitor sits in a
separate process and intercepts system calls made by the
monitored process using ptrace; the monitor process can
then enforce the rules by examining the intercepted system
calls and their parameters and possibly modifying the pa-
rameters or terminating the calls. As pointed out by the
authors[JS00], this approach has a few drawbacks. Firstly,
since rules are enforced in the context of the monitor pro-
cess, there is some overhead due to context switching and
copying data from one process’s context to the other’s.
Also, there are cases when the monitored process is not
entirely under the control of the monitor due to the imple-
mentations of ptrace.
3 BlueBox Policy Speciﬁcation and Genera-
tion
Since an attack on a system must access sensitive system
resources in unintended ways to be successful, a BlueBox
policy deﬁnes and enforces rules controlling a process’s ac-
cess to system resources, thus thwarting unintended access.
We categorize system resources and the types of access to
them in Table 1.
Features of our current rule speciﬁcation includes:
Access permissions to ﬁle system objects.
Access to the ﬁle system, e.g., mount, unmount.
Permitted uid and gid transitions.
signals which can be sent, received, blocked, ignored
& handled.
Process characteristics such as scheduling priorities
which can be modiﬁed.
Elementary controls for other system resources such
as IPC objects, sockets and ioctl calls. This is an area
requires more study for more comprehensive rules.
To make the policy speciﬁcation expressive, we provide
an allowed system calls list as a coarser level of control
that is effective in thwarting a number of attacks. Since
system resources must be accessed through system calls,
disallowing invocations of a system call disallows access to
resources. For instance, most server processes don’t need
to mount or unmount ﬁle systems, so mount and unmount
are not in their allowed lists and an invocation of either will
be considered an intrusion regardless of the invocation’s
parameters. We have identiﬁed 72 harmless system calls;
each of which either has no security implications or is not
supported by the Linux 2.2.14 kernel. These calls are listed
in Appendix A.
The policy for a program can also be marked inheritable:
this is useful for a script where each program executed by
the script can share the script’s policy.
Based on our experience, for a given program there are
several mechanisms and tools one could use to build and
specify the rules.
Intended Semantics: The most comprehensive way to
generate the correct rules for a program is by looking
through the intended semantics of the program. While
this can be daunting for big servers such as Apache,
we have found that for several cgi–bin scripts, this is
the easiest way to capture rules since these scripts typ-
ically access few resources.
Conﬁguration: For servers such as Apache which can
be conﬁgured to run in different ways, conﬁguration
ﬁles need to be used (either manually or automated)
to create rules.
Audit Trails: A very straightforward mechanism to
generate large chunks of the rules is to inspect system
call audit trails. For a number of servers and scripts
we have found this to be the simplest method.
Existing Templates: For large and popular servers
such as the Apache httpd, we envision existing rule
templates which can automatically be customized to
new installations. Our reference server is the Apache
httpd for which we have developed a template. We
are currentlyinvestigatingrule templates for larger ap-
plication servers and hope to include rule templates
for the most common conﬁgurations of application
servers such as the IBM WebSphere[WEB01].
While these mechanisms sound daunting for nontrivial
programs, as we discuss in section 5, we believe that the
amount of extra work is manageable. For our prototypical
application of web servers, most of the rules need to be
done once, with little customization for new servers.
4 Technical details
In this section we will ﬁrst discuss the BlueBox system
architecture to show how a policy is deﬁned and enforced,
then we discuss policy speciﬁcation in details and conclude
with a discussion of BlueBox’s impact on the kernel.
4.1 System Architecture
The BlueBox system architecture is shown in Figure 1.
The architecture includes two parts :
Policy Speciﬁcation and Parsing A BlueBox policy for
an executable program is speciﬁed in a human–
readable form using a text editor and then parsed into
a binary ﬁle by a parser program. This part is done
off–line and before the program is executed. Details
are in Section 4.2.
resources
File system objects
File systems
Identities
)
Processes (address spaces, signals,
CPU cycles, process scheduling priority
System clock
System/kernel memory
IPC objects : pipes, semaphores,
message queues, shared memory,
Devices, network
Privileges
types of access
create, open, read, write, execute, removal,
link–to, change of access permissions,
change of ownership
mount, unmount, types of mount
acquire, release, inherit
read, write, deliver
raise
set, read
read, write
create, open (attach), read, write
create/attach, open, read, write, io–control,
removal, link–to, change of access permissions,
change of ownership
acquire, release, raise, lower
Table 1. types of resources and access
Policy Loading and Enforcement Since BlueBox poli-
cies are meant to control access to system resources
which can only be accessed through system calls, the
natural place for rule enforcement is at the kernel sys-
tem call entry point. Our prototype on Linux 2.2.14
places an enforcer module at the kernel system call
entry point to enforce rules. The enforcer has built–in
knowledge of what categories of resources each call
may access so it can check the parameters of the in-
voked system call against the rules.
Since it is impractical to write policies for all pro-
cesses on a system, we added a new system call to
mark a process as being monitored ; this status will
be passed on to its children and cannot be unmarked.
As a tool, we have a simple wrapper program which
marks itself as monitored and then execves the real
program to pass on the monitored status to the new