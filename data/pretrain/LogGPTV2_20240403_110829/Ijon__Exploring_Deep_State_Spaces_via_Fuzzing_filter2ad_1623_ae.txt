on libpng and WavPack demonstrate that this previously
unexplored space contains critical bugs that would be much
harder to ﬁnd otherwise.
// callback used to iterate the hash map
void ijon_hash_feedback(bfd_hash_entry* ent, char* data){
IJON_SET(IJON_STRDIST(ent->string, data));
}
//shortened version of a hashmap lookup from binutils
entry* bfd_get_section_by_name(table *tbl, char *str) {
//perform a string feedback for each entry in the hashmap.
bfd_hash_traverse(tab, ijon_hash_feedback, str);
//....
}
rest of the function as shown earlier.
Listing 11: Annotated version of the hash map example.
E. Binutils Hash map - Missing Intermediate States
In this ﬁnal experiment, we extracted the relevant code
from the hash map example introduced earlier (Listing 3).
To provide an IJON annotation, we use an available iteration
function on the hash map. For each entry in the hash map, we
perform an IJON string compare. The resulting modiﬁcation
can be seen in Listing 11. In this case, the annotation is
somewhat more tricky than the previous annotations. We
encode the domain knowledge that the hash map lookup is
an efﬁcient version of a one-to-many string comparison. We
create an explicit loop of string compare operations in the
lookup function. Then we try to maximize the maximum
number of matching bytes amongst all compares.
Similar to the maze example, we performed experiments
with various fuzzers with and without IJON custom annota-
tions. Since we extracted the hard code from the application,
we observed that no new inputs were found after as few as
10 to 20 minutes. As a result, we choose to evaluate each
conﬁguration with three experiments of one hour each. The
results are displayed in Table V and Table VI. Note that
ANGORA is excluded from this experiment as we were unable
to compile libbfd with ANGORA’s taint tracking.
a) Initial Run: During the initial runs, none of the
fuzzers in the experiment were able to solve the constraints in
the unmodiﬁed form.
b) IJON: We extended the target with a small annotation
(three lines, as explained above). After applying this annota-
tion, all fuzzers are able to solve the constraint in a matter of
a few minutes, only AFLFAST failed in two out of three runs.
However, in its only successful run it managed to solve the
constraint in 6 minutes.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:17:13 UTC from IEEE Xplore.  Restrictions apply. 
1607
TABLE V: Different approaches ex-
ploring the hash example. Using
IJON, all fuzzers were able to solve
the hash at least once. Without IJON,
none of the fuzzers could solve this
example.
TABLE VI: Different approaches
solving the hash example (average
time in minutes ± standard devia-
tion). Note that we only report the
numbers for
IJON, since the base
fuzzers never found a solution.
Tool
AFL
AFLFAST
LAF-INTEL
QSYM
Plain
IJON




1
3
Tool
AFL
AFLFAST
LAF-INTEL
QSYM
IJON
8.1 ± 6.4
6.2 ± 0.0
26.1 ± 14.8
15.5 ± 2.4
F. Cyber Grand Challenge
To further substantiate that a manual interaction with the
fuzzing target is helpful in uncovering security issues, we
performed an experiment on the well-known Linux port [2]
of the DARPA CGC [3] data set. This also allowed us to
differentiate our approach from HACRS [52], another human-
in-the-loop approach. We ignored all challenges that could
already be solved by AFL, LAF-INTEL [1], REDQUEEN [7],
QSYM [60], T-FUZZ [43], or VUZZER [45], as there would be
no need for manual analysis when an existing fully automated
tool is able to produce a crash. In total, 62 challenges remained
undefeated. We picked a random subset of 30 CGC targets. For
eight of these targets, even the provided Proof of Vulnerability
(PoV) did not cause a crash. This is most
likely due to
the fact that we used the TRAIL OF BITS x86 Linux port
of the challenges [2]. We use this port since our tooling
does not support DECREE targets. We inspected each of
the 22 remaining challenge manually and performed fuzzing
experiments using AFL and IJON. We managed to produce
crashes in 10 targets as demonstrated in Table VII. More
technical details are available in the appendix.
trigger these crashes, we doubt
We were unable to crash the remaining 12 targets due to a
variety of reasons: Three targets contained only information
leak vulnerabilities that do not cause a crash. Consequently,
they are outside of the scope of this work. Two of the targets
contained crashes that were too complex to uncover (requiring
to trigger a series of different bugs to cause an observable
crash). While it would be possible to design IJON annotations
that
that one could do it
without prior knowledge of the bug. Consequently, we count
these two targets as failures. Of the remaining 7 targets, two
misbehaved in our coverage tracer (crashing on nearly all
inputs), three required very large inputs that AFL is not able
to generate efﬁciently, and two were running very slowly or
causing timeouts on all but very few inputs. Due to the fact
that—unlike HACRS—IJON is aimed at experts, we could
only perform this experiment with a single human analyst.
G. Real-World Software
Beside the memory corruptions we found in the state log
experiment in Section V-D and the novel crashes found in
the CGC dataset, we also performed experiments on other
software to further demonstrate that IJON is useful for ﬁnding
security bugs. In particular, we picked dmg2img, a tool that
TABLE VII: Comparing IJON with HACRS, another Human-in-the-loop
approach, on CGC targets. Note that none of the following CGC targets were
solved by state-of-the-art fuzzers. Note that NRFIN 00012 contains a broken
random number generation that made the challenge impossible to solve. After
ﬁxing the random number generator, we were able to solve the challenge.
Target
Type
Coverage (#Lines)
AFL
IJON
CROMU 00011
NRFIN 00030
NRFIN 00004
NRFIN 00076
NRFIN 00041
CROMU 00020
NRFIN 00005
NRFIN 00012
NRFIN 00038
NRFIN 00049
txt
bin
txt
bin
txt
bin
txt
bin
txt
txt
70%
84%
21%
24%
21%
61%
18%
87%
5%
20%
82%
84%
98%
48%
27%
75%
73%
73%
81%
61%
Crash found
HACRS
IJON









(
)
was very recently fuzzed by the authors of WEIZZ [18]. We
applied patches for the vulnerabilities found, and continued
fuzzing using IJON. In total, we uncovered three additional
memory corruption vulnerabilities in dmg2img. Two were
variants of the bugs found by WEIZZ, where additional
constraints needed to be satisﬁed to reach other unsafe usages
of dangerous string manipulation functions. The third bug is an
integer overﬂow that causes an allocation of size zero. Later
on, the byte at offset minus one is set to zero, corrupting
malloc metadata as illustrated in Listing 12.
IJON_MAX(kolyblk.XMLLength);
plist = (char *)malloc(kolyblk.XMLLength + 1);
if (!plist)
mem_overflow();
//....
plist[kolyblk.XMLLength] = '\0';
Listing 12: Bug #3 in dmg2img
VI. RELATED WORK
After AFL was published about ﬁve years ago, its inner
workings were analyzed in detail and multiple improvements
were proposed. Different scheduling algorithms were proposed
to improve fuzzing in various scenarios [10], [11], [13], [46],
[56]. The second component of AFL is the input muta-
tion strategy. Again, various improvements were proposed to
increase the probability of generating interesting inputs by
means of using more information on the target
[6], [7],
[9], [27], [40], [44] or taint tracking to limit the amount of
input data that needs to be mutated [14], [45]. Lastly, AFL
observes the programs behavior for each test case and receives
feedback on its behavior. Different fully automated techniques
were proposed that help improving the performance of this
feedback generation [19], [50] or to extend the feedback [1],
[29], [32]. To overcome various roadblocks, such as magic
bytes, techniques based on concolic execution [20]–[22], [26],
[37], [53], [55], [60], [63] and—less commonly—on symbolic
execution [16], [38] were proposed. Since fuzzing is very
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:17:13 UTC from IEEE Xplore.  Restrictions apply. 
1608
performance-critical, various aspects of it were optimized by
other projects. For example, Xu et al. improved the perfor-
mance of spawning subprocesses [58]. Various fuzzers used
Intel-PT to increase the performance of coverage tracing on
binary targets [5], [50]. Lastly, to make fuzzing more applica-
ble it was adopted to targets ranging from ﬁrmware [16], [64]
over hypervisors [28] and operating systems [4], [50], [54] to
neural networks [42], [57]
A. Human-in-the-Loop Approaches in Fuzzing
Recently, human-in-the-loop fuzzing gained the attention of
the research community. Current approaches commonly pro-
vide an interactive environment where the humans interactions
are used as seeds by the fuzzer. In some scenarios this is
very helpful, while in other common fuzzing scenarios, it is
very hard to apply. For example, Shoshitaishvili et al. [52]
introduced HACRS, a system that allows humans to interact
with the target application via an emulated terminal. To help
the human, HACRS analyzes the target and provides a list of
strings that might be relevant to the application’s behavior. If
the target provides a text-based interface, a human is often
able to ﬁgure out how to interact with the target application.
However, HACRS does not work when the target application
does not consume data in a format easily understood by
humans, e.g., binary formats, or the program output does
not contain helpful information on the expected input format.
Consequently, the authors excluded any program containing
binary characters in the provided example scenarios from
their evaluation. Similarly, DYNODROID [36] traces a human’s
interaction with Android applications. In contrast to HACRS,
this includes a more diverse set of input interfaces such as
system events and swipe gestures. However, the fundamental
principle remains the same. In contrast, our approach is based
on annotating the code of the target application and does not
require to understand the input format.
Our approach requires little understanding of software se-
curity or program analysis. Even complex games can typically
be won by untrained users. On the other hand, when fuzzing
binary ﬁle formats or network protocols, even an expert user
will have a hard time to come up with novel inputs based on
observing only the program output. IJON allows to guide the
fuzzer’s intrinsic ability to generate inputs to overcome fuzzing
roadblocks and to explore a more diverse part of the state
space. This approach requires no knowledge or understanding
of the input format at all. In fact, we also typically had very
limited understanding of the target application, as our annota-
tions allow to provide guidance without deep understanding of
the program context. For example, consider the bug shown in
Listing 12. The annotation was added without any context or
understanding of how kolyblk.XMLLength is calculated
from the input. Still, IJON was able to trigger the integer
overﬂow after a few minutes of analysis time.
VII. DISCUSSION AND FUTURE WORK
In this paper we describe an interactive approach to fuzzing.
While this offers new ways to steer the fuzzing process, it
requires manual inspection of the test coverage, acquiring
an understanding of why a constraint is hard to solve, and
manually creating a well-suited annotation. This manual effort
comes with a certain cost to the analyst, but our evaluation
demonstrates that this approach can overcome several obsta-
cles for current fuzzers. For example, it is clear that neither
a grammar nor a dictionary will help a fuzzer to solve Super
Mario levels. Additionally, it is not straightforward to ﬁnd
good seed inputs. While in such a case, a record and replay
mechanism such as a version of HACRS or DYNODROID
applicable to this target might be helpful, in many other cases
such as binary formats, it would likely not.
The annotations used in IJON are currently added manually.
It would be interesting to design methods that automatically
infer annotations only for difﬁcult individual constraints. Some
existing fuzzing approaches use a subset of the annotations
described by us. For example, LAF-INTEL can be represented
by annotating the number of equal bytes in a comparison. Sim-
ilarly, ANGORA already implements call stack based virtual
state for all coverage. However, all those tools use additional
feedback indiscriminately. Therefore, they are limited to low
information gain feedback mechanisms. Using more precise
feedback in a similar manner would result in a much larger
queue and decreased performance. Automated techniques to
identify IJON annotations could make use of much more
powerful annotations than LAF-INTEL and ANGORA, as they
are applied sparsely. Finally, right now, the annotations require
source access. In principle, there is no reason why similar
annotations cannot be implemented for binary-only targets. In-
tegrating IJON with a binary-only fuzzer would be interesting.
VIII. CONCLUSION
In this paper, we have shown that a large number of hard
problems for fuzzers can be solved by manually inspecting
the code coverage during fuzzing and using only a few
lines of annotations to guide the fuzzing process. Previously,
practitioners in the industry often used to manually pick seed
ﬁles that solve the coverage or to design custom mutators that
solve constraints (for example, by providing dictionaries or
grammars). Similarly, it is well documented that practitioners
try to remove hard constraints such as checksum manually.
We extended this toolkit with another manual but very ﬂexible
method: annotations that an analyst can use to guide the fuzzer.
By using less than four lines of code, we demonstrated how a
large set of problems could be solved that no other automated
fuzzing approach is currently able to handle.
ACKNOWLEDGMENTS
This work was supported by the Deutsche Forschungsge-
meinschaft (DFG, German Research Foundation) under Ger-
many’s Excellence Strategy – EXC 2092 CASA – 39078197.
In addition, this work was supported by the European Union’s
Horizon 2020 Research and Innovation Programme (ERC
Starting Grant No. 640110 (BASTION) and 786669 (REACT))
and the German Federal Ministry of Education and Research
(BMBF, project HWSec – 16KIS0592K). The content of
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:17:13 UTC from IEEE Xplore.  Restrictions apply. 
1609
this document reﬂects the views only of their authors. The
European Commission/Research Executive Agency are not
responsible for any use that may be made of the information
it contains.
APPENDIX