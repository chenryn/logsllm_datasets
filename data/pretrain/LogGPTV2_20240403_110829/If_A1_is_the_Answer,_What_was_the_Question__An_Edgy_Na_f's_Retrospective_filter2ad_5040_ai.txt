closing  high-bandwidth  covert  channel  discovered  in 
analysis  on  the  one  hand  and  the  lack  of  explicit 
requirements  to  build  in  protections  against  deadlocks 
and  other  denials  of  service.17    This  is  not  to  suggest 
that  the  services  and  agencies  concerns  were  trivial; 
many  were  very  sophisticated  and  few  were  frivolous. 
Many  comments  came  from  a  lack  of  knowledge  or 
understanding  of  the  vocabulary  of  computer  security 
technology,  understandable  since  this  was  largely  an 
arcane field in the 1980s.  
More  than  one  agency  actively  wanted  to  make  the 
TCSEC  optional  since 
there  was  “no  validated 
computer security threat” and it made no sense to build 
in  costly  defenses  where  there  was  no  validated 
requirement.  But  the  discussions  were  very  time-
consuming  and  important  to  all  parties,  and  policy 
coördination is an intricate prolonged process. 
Finally, and as a tribute to Sheila Brand’s skills and 
dedication,  Assistant  Secretary  of  Defense  (C3I)
Donald  Latham  signed  off  on  the  TCSEC  as  DoD 
5200.28-STD on 26 December 1985. 
3.3. Becoming a DoD standard 
4. TCSEC reconsidered 
Shortly  after  the  TCSEC’s  August  publication,  a 
movement  was  initiated  within  the  Computer  Security 
Center  to  promulgate  it  as  a  DoD  Standard.  Doing  so 
was  necessary  in  order  to  legitimize  the  Evaluated 
Products List as part of the certification, accreditation, 
and procurement processes. 
This  turned  into  a  monumental  effort.  In  order  to 
achieve  this  goal, the TCSEC needed to be acceptable 
to the DoD’s many departments, services and agencies. 
As  discussed  above,  products  and  systems  were 
under  evaluation  while  the  TCSEC  was  going  through 
its  drafts  and  coördination  reviews.  Many  problems 
were  discovered.  Some  were  fixed  prior  to  the  15 
August 
These 
publication. 
Standard’s 
1983 
17 In addition to robustness largely being a research area, there 
that  popular  reliability  algorithms 
also  were  demonstrations 
generally introduce exploitable covert channels. 
Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC’04) 
1063-9527/04 $ 20.00 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 11:37:23 UTC from IEEE Xplore.  Restrictions apply. 
and  other 
modifications  required  consensus  among  the  Center’s 
management,  senior  staff,  researchers  and  evaluators 
(including  contractual  support  staff  from  MITRE  and 
Aerospace  Corporation 
consultants). 
However,  no  changes  were  made  unilaterally  (i.e.,
based  only  on  our  own  learning  experiences)  after  15 
August  1983.  This  is  because  of  the  Center’s  top 
management’s  decision  that  we  needed  to  solidify 
agreement among the services and agencies on existing 
wording rather than for us to re-open issues that could 
delay 
the  TCSEC  becoming  a  DoD  Standard. 
Defending criteria we knew to be flawed was a painful 
and bitter pill many of us had to learn to swallow. 
4.1. The education challenge 
We had no way of knowing then that not enough of 
what  we  thought  was  reduced  to  practice  was  reduced 
to practice. It took publishing the TCSEC and trying to 
perform  evaluations  for  us  to  learn  this.  Simple  terms 
like  module  had  very  different  meanings  in  different 
communities  and  among  professionals  who  learned 
their  trade  in  different  decades.  Those  of  us  who  had 
extensive  decadeant 
(sic)  experience  penetrating 
systems  had  a  very  different  appreciation  for  the 
importance  of  certain  structuring  approaches  than  did 
staff  (or  developers)  who  had  never  defeated  a 
protection mechanism or written a real-time I/O driver. 
There  weren’t  many  professionals  in  the  United 
States  who  had  acquired  years  of  experience  working 
in computer security technology. Many were employed 
as  researchers  in  universities,  in  a  small  number  of 
industrial 
research 
organizations. A few were consultants. This meant that 
the  NCSC  needed  to  institute  an  intense  training 
program  for  its  evaluators  and  for  developers  in 
industry.  
government 
or 
defense 
We  had  intended  that  our  evaluation  teams  would 
to  solving  or 
show  vendors  creative  approaches 
working  around  architectural  problems  uncovered 
during  an  developmental  evaluation.  For  two  reasons, 
this  happened  rarely.  One  reason  related  to  the  legal 
context of a representative of the Government advising 
vs  giving  contractual  direction  to  a  contractor—even 
though 
the  vendors  under  evaluation  were  not 
contractors.  
A second problem of advice-giving was more complex. 
Because 
its  evaluation  support 
contractors  hired  young  graduate  computing  science 
graduates,  we  periodically  received  complaints  from 
vendors  that  our  evaluators  had  less  experience  and 
expertise  than  the  developers  whose  efforts  we  were 
evaluating.  They  viewed  our  evaluators  as  being  too 
“Ivory Tower” and “wet behind the ears” to give them 
the  NCSC  and 
any useful pragmatic advice. So, yet another challenge 
for  our  technical  senior  staff  arose,  this  time  requiring 
diplomatic crisis management skills. We needed to find 
an  acceptable  means  of  guiding  the  vendor  and 
evaluator  toward  a  viable  solution  without  making 
either more defensive than they often were. This was a 
skill I have never been accused of! 
4.2. Send in the lawyers 
Early  on,  Dan  Edwards  and  Mario  Tinto  decided 
that  the  evaluators  would  need  to  produce  extensive 
documentation of technical decisions they made during 
the  evaluation  process.  These  decisions  would  be 
likened to judicial case law.
For  a  while,  various  authors  of  the  TCSEC  were 
asked  what  a  given  wording  or  term  meant.  It  was 
quickly discovered that we were individually not often 
in  close  agreement  on  these  concepts,  even though we 
did not think there was a question on the meaning when 
we were writing the criteria. So evaluators soon learned 
that  something  more  than  the  memories  of  the  authors 
was  needed  if  evaluations  were  to  be  performed 
consistently. 
Because  of 
the  TCSEC’s  widely  distributed 
ambiguities  and  the  unanticipatedly  creative  nature  of 
developers, 
the  Center’s  evaluators  were  almost 
immediately faced with the need to make reasoned and 
defensible  decisions  on  how  TCSEC  requirements 
would  be  applied  to  a given situation. This introduced 
an  intricate  and  time-consuming  process  known  as 
Criteria Interpretation. 
It  made  good  sense  for  interpretations  to  be 
considered  carefully  prior  to  telling  a  vendor  of  a 
decision.  But  the  process  that  became  part  of  NCSC-
lore  made  slow  look  fast  in  comparison.  The  average 
interpretation  process  went  through  a  number  of 
proposal,  review,  comment,  revision,  review  and 
publication  phases  that  together  took  weeks  to  months 
to  years.  The  effect  of  this  process  on  product 
developers  was  devastating.  Often,  a  product 
development  hinged  on  making  a  critical  decision  to 
steer  the  architecture  in  one  direction  on  another.  A 
wrong  decision  would  be  extremely  costly  to  correct 
later. But evaluation teams could furnish no advice (or 
at least no advice that might not later be refuted) until 
the interpretation process terminated. 
There  was  one  other  unanticipated  consequence  of 
interpretations  being  treated  as  case  law.  This  became 
known  as  criteria  creep.  It  seemed  that  interpretations 
always  added  new  requirements  rather  than  simply 
clarifying  existing  ones.  This  practice  effectively 
extended  the  criteria  that  had  to  be  satisfied  by  on-
Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC’04) 
1063-9527/04 $ 20.00 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 11:37:23 UTC from IEEE Xplore.  Restrictions apply. 
going evaluations, and it added significantly to the cost 
and time required to complete the evaluation process. 
color).  Many  volumes  in  the  Rainbow  series  were 
scholarly and are still valuable. 
The  result  was  very  painful.  I,  and  other  seniors  in 
the  Center,  received  angry  communications  from 
vendors  demanding  a  speedy  decision.  Evaluators 
resented  any  intervention  on  our  part,  since  we  lacked 
the context from which the evaluators were working—
and they did not want to have their authority undercut.  
In  at  least  two  cases,  those  of  an  A1  and  a  B2 
product  evaluation,  I  took  it  upon  myself  to  coerce 
NCSC  senior  management  to  break  a  stalemate  and to 
accelerate  the  decision  to  grant  or  deny  awarding  an 
evaluation rating to the product. The problem here was 
that  the  evaluators  had  less  guidance  to  work  from  to 
decide that they had indeed performed all of the needed 
validations  and  need  not  perform  any  more;  and  the 
vendor  needed  to  see  some  revenue  from  their  trusted 
product  or  to  disband  their  development  team.  There 
were also some occasions where the evaluation process 
was  so  slow  and  mired  down  in  interpretations  that  a 
vendor  killed  a  project  because  the  hardware  had 
become obsolete. 
As  use  of  the  TCSEC  became  more  common, 
additional  questions  provoked  writing  additional 
volumes.  The  Rainbow  series  became  something  of  a 
self-perpetuating  institution.  Two  definitive  entries  in 
the Rainbow series, the Trusted Network Interpretation
(TNI)  and  the  Trusted  Database  Interpretation  (TDI) 
were  published  to  controversy  over  an  intense  writing 
period. Each addressed portions of the problem of how 
to apply the TCSEC to the construction of a multilevel 
network  or  a  multilevel  database  management  system 
vice  versa).  Sometimes  divisive  controversy 
(or
surrounded  publication  of  each  of  these.  Several  of  us 
argued against publication of either on the grounds that 
the state of knowledge for building multilevel networks 
and  database  management  systems  was  far 
less 
developed  than  the  theory  and  techniques  behind 
building monolithic trusted operating systems. 
A  somewhat  disguised  worked  example  of  a 
counterexample  to  an  A1-compliant  TNI  architecture 
was published by Schaefer, et al. in [23]. 
4.3. Send in the lawyers 
4.5. A1 is the answer; what was the question? 
Another  consequence  of  lengthy  evaluations  was 
that  the  evaluated  product  was  several  maintenance 
releases  behind  the  commercially  available  product. 
The  NCSC  needed  to  find  a  means  of  evaluating 
incremental  product  evolutions  without  performing  a 
complete  re-evaluation  of  the  product.  Ultimately,  the 
Ratings  Maintenance  Program  (RAMP)  came  out  of 
this  process  for  products  in  the  lower  evaluation 
classes. Consensus was not reached during my tenure in 
the Center on how RAMP could be applied to products 
evaluated at or above the B2 level. 
4.4. Rainbows 
As  interpretations  came  out,  so  also  arose  requests 
for  guidance  on  numerous 
topics  ranging  from 
password  selection  to  the  algebra  of  DAC.  So  Sheila 
Brand  instituted  a  process  of  publishing  booklets  on  a 
range of evaluation-related topics. Even as the TCSEC 
was  being  written,  the  late  George  Jelen  raised  the 
question of how one could determine which evaluation 
class was required for a given processing environment. 
His  scholarly  dissertation 
[14]  provoked  many 
animated  discussions  inside  the  Center.  It  resulted  in 
Roger  Schell’s  introduction  of  the  risk  range  concept 
and  an  algorithm  for  addressing  Jelen’s  question.  This 
was  published  as  one  of  Brand’s  Rainbow  Series  (so-
called  because  each  volume’s  cover  had  a  unique 
One  unanticipated  problem  showed  up  as  the 
TCSEC  was  becoming  accepted  by  the  Military 
departments  and  agencies.  These  came  from  the 
procurement  officers  for  whom  we  had insisted on the 
simple  seven-class  structure.  Simply  put,  once  there 
was  a  B2  product  on  the  Evaluated  Products  List 
(commercial  Multics),  a  procurement  officer  balked  at 
the  Air  Force  specifying  a  requirement  for  a  B2  or 
equivalent  operating  system.  The  procurement  officer, 
on  learning  that  there  was  essentially  no  way  for  any 
product  other 
the 
solicitation and its time limit, declared the requirement 
to be anticompetitive. He refused to allow it. 
to  comply  with 
than  Multics 
The other unanticipated problem was likely intrinsic 
to human nature. A large number of procurements and 
development  contracts  came  out  specifying  use  of  an 
A1  product.  At  least  one  demanded  an  A2  product  so 
that  it  would  not  become  obsolete!  In  many  cases,  the 
systems would be operating in a closed environment at 
system-high,  so  all  users  were  assumed  to  be  cleared 
for  almost  all  information  on  the  machine.  A  B1 
product  would  suffice  for  the  application.  But  the 
customers  for  these  products  wanted  the  very  best 
system money could buy, and not some inferior system 
that  failed  to  meet  the  highest  military  standards.  We 
found ourselves having to advocate the use of products 
from lower levels of the EPL (particularly necessary at 
the time, as there was not yet an entry above B2!). 
Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC’04) 
1063-9527/04 $ 20.00 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 11:37:23 UTC from IEEE Xplore.  Restrictions apply. 
Finally, 
there  was  customer 
resistance—often 
intense resistance. Trusted systems were not known for 
having user friendly interfaces. Consequences of the *-
property  and  simple  security  condition  proved  to  be 
confusing  and  frustrating  to  new users. This proved to 
be  embarrassing.  We  found  it  impossible  to  influence 
the Center’s Director or most of its office chiefs to use 
any  commercial  product  that  was  listed  on  the  EPL—
including  the  Center’s flagship B2 Dockmaster system 
(Multics-AIM) or even the C2 Windows-NT during the 
Center’s “C2 by 92” drive. 
5. Reflections and lessons learned 
trusted  systems  unless 
Publication  of  the  TCSEC  was,  in  retrospect,  an 
important step in promoting research and development 
of  trusted  operating  systems.  Vendors  would  resist 