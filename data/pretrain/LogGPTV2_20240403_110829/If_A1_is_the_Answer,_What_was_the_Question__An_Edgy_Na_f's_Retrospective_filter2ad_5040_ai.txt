### Closing High-Bandwidth Covert Channels and Security Requirements

The discovery of a high-bandwidth covert channel, coupled with the absence of explicit requirements to prevent deadlocks and other denial-of-service attacks, highlighted several challenges. This is not to say that the concerns of various services and agencies were trivial; many were highly sophisticated, and few were frivolous. Many of these concerns stemmed from a lack of knowledge or understanding of computer security terminology, which was understandable given that this was a largely esoteric field in the 1980s.

Several agencies argued for making the Trusted Computer System Evaluation Criteria (TCSEC) optional, citing the absence of a "validated computer security threat" and the cost of implementing defenses without a clear need. However, the discussions were time-consuming and crucial for all parties involved, and policy coordination is an intricate and prolonged process.

### TCSEC Becomes a DoD Standard

Assistant Secretary of Defense (C3I) Donald Latham signed off on the TCSEC as DoD 5200.28-STD on December 26, 1985, thanks to Sheila Brand's dedication and skills.

### Promulgation as a DoD Standard

Shortly after the TCSEC's August publication, efforts began within the Computer Security Center to promulgate it as a DoD standard. This was necessary to legitimize the Evaluated Products List (EPL) as part of the certification, accreditation, and procurement processes.

This effort was monumental. The TCSEC needed to be acceptable to the DoD's many departments, services, and agencies. As products and systems were under evaluation, numerous problems were discovered. Some issues were addressed before the August 15, 1983, publication. In addition to robustness being a research area, popular reliability algorithms often introduced exploitable covert channels.

### Consensus and Modifications

Modifications required consensus among the Center's management, senior staff, researchers, and evaluators, including contractual support staff from MITRE and Aerospace Corporation. No unilateral changes were made after August 15, 1983, to avoid delaying the TCSEC's adoption as a DoD standard. Defending flawed criteria was a painful but necessary task.

### The Education Challenge

We realized that much of what we thought was practical had not been fully implemented. Simple terms like "module" had different meanings across communities and professionals from different eras. Those with extensive experience in system penetration had a different appreciation for certain structuring approaches compared to those who had never defeated a protection mechanism or written a real-time I/O driver.

There were few professionals in the U.S. with years of experience in computer security technology. Many worked in university research or a small number of industrial research organizations. This necessitated an intense training program for evaluators and industry developers.

### Evaluations and Advice

We intended for our evaluation teams to show vendors creative approaches to solving or working around architectural problems. However, this rarely happened due to legal constraints and the perception that our evaluators, often young graduate students, lacked the experience and expertise of the developers they were evaluating. This created a diplomatic challenge, requiring us to find an acceptable means of guiding both the vendor and evaluator toward a viable solution.

### Legal and Interpretative Challenges

Dan Edwards and Mario Tinto decided that evaluators needed to produce extensive documentation of technical decisions, akin to judicial case law. We quickly discovered that individual interpretations of the TCSEC's wording varied, even among its authors. This led to a time-consuming process known as Criteria Interpretation, which often added new requirements rather than clarifying existing ones, leading to "criteria creep."

### Vendor and Procurement Issues

Lengthy evaluations meant that evaluated products were several maintenance releases behind commercially available versions. The NCSC developed the Ratings Maintenance Program (RAMP) to address this, but consensus was not reached on how to apply RAMP to higher-level evaluations.

### The Rainbow Series

As interpretations emerged, so did requests for guidance on various topics. Sheila Brand initiated a process of publishing booklets on a range of evaluation-related subjects. George Jelen's dissertation on determining the appropriate evaluation class for a given environment led to Roger Schell's introduction of the risk range concept.

### Unanticipated Problems

One unanticipated problem arose when procurement officers balked at specifying a B2 or equivalent operating system requirement, deeming it anticompetitive if only one product (Multics) could meet it. Another issue was the tendency to specify A1 or even A2 products, even when a B1 product would suffice, driven by a desire for the best system available.

### Customer Resistance

Trusted systems were not known for user-friendly interfaces. The *-property and simple security condition were confusing and frustrating for new users, leading to resistance from customers, including the Center's Director and office chiefs.

### Reflections and Lessons Learned

In retrospect, the publication of the TCSEC was an important step in promoting the research and development of trusted operating systems. Vendors resisted the TCSEC, but it ultimately played a crucial role in advancing the field.