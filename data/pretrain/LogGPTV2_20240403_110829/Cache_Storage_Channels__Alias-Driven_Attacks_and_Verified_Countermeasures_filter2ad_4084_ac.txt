This is used to iteratively shrink the sets T j,v
by removing the pairs that do not satisfy the equation. The
attacker repeats this process until for a byte value v the set
T j,v
contains a single value; then the byte j of key is recovered
using Kn[j] = v ⊕ tj,v
4
4 . Notice that the complete process can
be repeated for every byte without gathering further logs and
that the attacker does not need to know the plain-texts used
to produce the cipher-texts.
4
We implemented the attack on a Raspberry Pi 2 [42],
because this platform is equipped with a widely used CPU
(ARM Cortex A7) and allows to use the TrustZone extensions.
The system starts in TrustZone and executes the bootloader of
our minimal TrustZone operating system. This installs a secure
service that allows an untrusted kernel to encrypt blocks (e.g.
to deliver packets over a VPN) using a secret key. This key
is intended to be conﬁdential and should not be leaked to the
untrusted software. The trusted service is implemented using
an existing AES library for embedded devices [53], that is
relatively easy to deploy in the resource constrained environ-
ment of TrustZone. However, several other implementations
(including OpenSSL [35]) expose the same weakness due to
the use of precomputed SBoxes. The boot code terminates
by exiting TrustZone and activating the untrusted kernel. This
operating system is not able to directly access the TrustZone
memory but can invoke the secure service by executing Secure
Monitor Calls (SMC).
In this setting, the attacker (the untrusted kernel), which is
executed as privileged software outside TrustZone, is free to
manipulate its own page tables (which are different from the
ones used by the TrustZone service). Moreover, the attacker
can invalidate and clean cache lines, but may not use debug-
ging instructions to directly inspect the state of the caches.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:13:33 UTC from IEEE Xplore.  Restrictions apply. 
The attacker uses the algorithm presented in Figure 2,
however several considerations must be taken into account to
make the attack practical. The attacker repeats the ﬁlling and
probing phases for each possible line index (128) and way (4)
of the data-cache. In practice, since the cache eviction strategy
is pseudo random, the ﬁlling phase is also repeated several
times, until the L1 cache is completely ﬁlled with the probing
data (i.e. for every pair of virtual addresses used, accessing to
the two addresses yield different values).
On Raspberry Pi 2, the presence of a uniﬁed L2 cache can
obstruct the probing phase: even if a cache line is evicted from
the L1 cache by the victim, the system can temporarily store
the line into the L2 cache, thus making the probing phase
yield false negatives. It is in general possible to extend the
attack to deal with L2 caches (by repeating the ﬁlling and
probing phases for every line index and way of the L2 cache
subsystem), however, in Raspberry Pi 2 the L2 cache is shared
between the CPU and the GPU, introducing a considerable
amount of noise in the measurements. For this reason we
always ﬂushes the L2 cache between the step A5 and A6
of the attack. We stress that this operation can be done by the
privileged software outside TrustZone without requiring any
support by TrustZone itself.
To make the demonstrator realistic, we allow the TrustZone
service to cache its own stack, heap, and static data. This
pollutes the data extracted by the probing phase of the attack:
it can now yield false positives due to access of the victim
to such memory areas. The key extraction algorithm can
handle such false positives, but we decide to ﬁlter them out
to speed up the analysis phase. For this reason, the attacker
ﬁrst
identiﬁes the cache lines that are frequently evicted
independently of the resulting cipher-text (e.g. lines where the
victim stack is probably allocated) and removes them from
the sets Ej,v. As common, the AES implementation deﬁnes
the SBox tables as consecutive arrays. Since they all consists
of 1 KB of data, the cache lines where different SBoxes are
allocated are non-overlapping, helping the attacker in the task
of reducing the sets Ej,v to contain a single line belonging to
the table T4 and of ﬁltering out all evictions that are due the
previous rounds of AES.
For practical reasons we implemented the ﬁlling and prob-
ing phase online, while we implemented the key extraction
algorithm as a ofﬂine Python program that analyses the logs
saved by the online phase. The complete online phase (includ-
ing the set-up of the page tables) consists of 552 lines of C,
while the Python programs consists of 152 lines of code. The
online attacker generates a stream of random 128 bits plain-
texts and requests to the TrustZone service their encryption.
Thus, the frequency of the attacker’s measurements isolates
one AES encryption of one block per measurement. Moreover,
even if the attacker knows the input plain-texts, they are not
used in the ofﬂine phase. We repeated the attack for several
randomly generated keys and in the worst case, the ofﬂine
phase recovered the complete 128-bit key after 850 encryption
in less than one second.
B. Violating Spatial Isolation in a Hypervisor
A hypervisor is a low-level execution platform controlling
accesses to system resources and is used to provide isolated
partitions on a shared hardware. The partitions are used to
execute software with unknown degree of trustworthiness.
Each partition has access to its own resources and cannot
encroach on protected parts of the system, like the memory
used by the hypervisor or the other partitions. Here we
demonstrate that a malicious operating system (guest) running
on a hypervisor can gain illicit access to protected resources
using the mechanism described in Section III-B.
As basis for our study we use a hypervisor [33] that has
been formally veriﬁed previously with respect to a cache-
less model. The hypervisor runs on an ARMv7 Cortex-A8
processor [16], where both L1 and L2 caches are enabled. On
ARMv7 the address translation depends on the page tables
stored in the memory. Entries of the page tables encode a
virtual-to-physical mapping for a memory page as well as
access permissions and cacheability setting. On Cortex-A8
the MMU consults the data cache before accessing the main
memory whenever a page table descriptor must be fetched.
The architecture is paravirtualized by the hypervisor for
several guests. Only the hypervisor is executing in privileged
mode, while the guests are executed in non-privileged mode
and need to invoke hypervisor functionality to alter the critical
resources of the system, like page tables.
A peculiarity of the hypervisor (and others [7]) that makes
it particularly relevant for our purpose is the use of so-called
direct paging [33]. Direct paging enables a guest to manage its
own memory space with assistance of the hypervisor. Direct
paging allows the guest to allocate the page tables inside
its own memory and to directly manipulate them while the
tables are not in active use by the MMU. Then, the guest
uses dedicated hypervisor calls to effectuate and monitor the
transition of page tables between passive and active state. The
hypervisor provides a number of system calls that support the
allocation, deallocation, linking, and activation of guest page
tables. These calls need to read the content of page tables
that are located in guest memory and ensure that the proposed
MMU setup does not introduce any illicit access grant. Thus
the hypervisor acts as a reference monitor of the page tables.
As described in Section III-B, on a Cortex-A8 processor
sequential consistency is not guaranteed if the same mem-
ory location is accessed by virtual aliases with mismatched
cacheability attributes. This opens up for vulnerabilities. The
hypervisor may check a page table by fetching its content
from the cache. However, if the content of the page table in
the cache is clean and different from what has been placed by
the attacker in the main memory and the page table is later
evicted from the cache, the MMU will use a conﬁguration that
is different from what has been validated by the hypervisor.
Figure 5 illustrates how a guest can use the aliasing of the
physical memory to bypass the validation needed to create a
new page table. Hereafter we assume that the guest and the
hypervisor use two different virtual addresses to point to the
4444
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:13:33 UTC from IEEE Xplore.  Restrictions apply. 
same memory location. Initially, the hypervisor (1) is induced
to load a valid page table in the cache. This can be done
by writing a valid page table, requesting the hypervisor to
verify and allocate it and then requesting the hypervisor to
deallocate the table. Then, the guest (2) stores an invalid page
table in the same memory location. If the guest uses a non-
cacheable virtual alias, the guest write (3) is directly applied
to the memory bypassing the cache. The guest (4) requests
the hypervisor to validate and allocate this memory area, so
that it can later be used as page table for the MMU. At this
point, the hypervisor is in charge of verifying that the memory
area contains a valid page table and of revoking any direct
access of the guest to this memory. In this way, a validated
page table can be later used securely by the MMU. Since the
hypervisor (4) accesses the same physical location through
the cache, it can potentially validate stale data, for example
the ones fetched during the step (1). At a later point in time,
the validated data is evicted from the cache. This data is not
written back to the memory since the hypervisor has only
checked the page table content and thus the corresponding
cache lines are clean. Finally, the MMU (5) uses the invalid
page table and its settings become untrusted.
Note that
this attack is different from existing “double
mapping” attacks. In double-mapping attacks the same phys-
ical memory is mapped “simultaneously” to multiple virtual
memory addresses used by different agents; the attack occurs
when the untrusted agent owns the writable alias, thus being
able to directly modify the memory accessed by the trusted
one. Here, the attacker exploits the fact that the same physical
memory is ﬁrst allocated to the untrusted agent and then
re-allocated to the trusted one. After that the ownership is
transferred (after step A1), the untrusted agent has no mapping
to this memory area. However, if the cache contains stale
data the trusted agent may be compromised. Moreover, the
attack does not depend on misconﬁguration of the TLBs;
the hypervisor is programmed to completely clean the TLBs
whenever the MMU is reconﬁgured.
We implemented a malicious guest that managed to bypass
the hypervisor validation using the above mechanism. The
untrusted data, that is used as conﬁguration of the MMU, is
used to obtain writable access to the master page table of the
hypervisor. This enables the attacker to reconﬁgure its own
access rights to all memory pages and thus to completely take
over the system.
Not all hypervisors are subject to this kind of vulnerability.
For example, if a hypervisor uses shadow paging, then guest
pages are copied into the hypervisor’s own memory where
they are transformed into so-called shadow page tables. The
guest has no access to this memory area and the hypervisor
always copies cached data (if present), so the attack described
above cannot be replicated. On the other hand, the adversary
can still attack secure services hosted by the hypervisor, for
example a virtual machine introspector. In [12] the hypervisor
is used to implement a run-time monitor to protect an untrusted
guest from its internal threats. The monitor is deployed in
a separate partition to isolate it from the untrusted guest.
Fig. 5.
Compromising integrity of a direct paging mechanism using
incoherent memory. The MMU is conﬁgured to use a page table that was
not validated by the hypervisor.
y := 1
for i = m down to 1
y = Square(y)
y = ModReduce(y, N)
if e_i == 1
y = Mult(y,x)
y = ModReduce(y, N)
Fig. 6. Square and multiply algorithm
The policy enforced by the monitor is executable space
protection: each page in the memory can be either writable
or executable but not both at the same time. The monitor, via
the hypervisor, intercepts all changes to the executable codes.
This allows to use standard signature checking to prevent
code injection. Each time the guest operating system tries to
execute an application, the monitor checks if the binary of
the application has a valid signature. In case the signature is
valid, the monitor requests the hypervisor to make executable
the physical pages that contain the binary code. The security
of this system depends on the fact that the adversary cannot
directly modify a validated executable due to executable space
protection. However, if a memory block of the application code
is accessed using virtual aliases with mismatched cacheability
attributes, the untrusted guest can easily mislead the monitor
to validate wrong data and execute unsigned code.
C. Extraction of exponent
from a modular exponentiation
procedure
The square and multiply algorithm of Figure 6 is often
used to compute the modular exponentiation xe mod N, where
em . . . e1 are the bits of the binary representation of e. This
algorithm has been exploited in access-driven attacks, since the
sequence of function calls directly leaks e, which corresponds
to the private key in several decryption algorithms. Here
we demonstrate that an attacker that is interleaved with a
victim can infer e using the storage channel described in
Section III-C.
The attack was implemented on Raspberry Pi 2. We build a
setting where a malicious process (e.g. a just in time compiler)
can self-modify its own code. Moreover, we implement a
scheduler that allows the attacker to be scheduled after every
4545
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:13:33 UTC from IEEE Xplore.  Restrictions apply. 
loop of the victim.1
The attacker uses the vector presented in Figure 4, repeating
the ﬁlling and probing phases for every way of the instruction
cache and for every line index where the code of the functions
Mult and ModReduce can be mapped. Due to the separate
instruction and data L1 caches, the presence of the L2 cache
does not interfere with the probing phase. However, we must
ensure that the instruction overwritten in the step (A2) does not
sit in the L1 data-cache when the step (A4) is executed. Since
user processes cannot directly invalidate or clean cache lines,
we satisfy this requirement by adding a further step (A3.b).
This step writes several addresses whose line indices in the L1
data-cache are the same of the address &A8, thus forcing the
eviction from the L1 data-cache of the line that has contains
the instruction stored at &A8.
We repeated the attack for several randomly generated
values of e and in each case the attacker correctly identiﬁed
the execution path of the victim. This accuracy is due to the
simple environment (no other process is scheduled except the
victim and the attacker) and the lack of noise that is typical
in attacks that use time channels.
V. COUNTERMEASURES
Literature on access-based timing channel attacks suggests
a number of well-known countermeasures. Speciﬁcally, for
attacks on the conﬁdentiality of AES encryption, a rather
comprehensive list of protective means is provided in [51].
Some of the approaches are speciﬁc to AES, e.g., using
registers instead of memory or dedicated hardware instructions
for the SBox table look-up. Others are speciﬁc to the timing
attack vector, e.g., reducing the accuracy of timing information
available to the attacker. Still, there are well-known solutions
addressing the presence of caches in general, thus they are
suitable to defend against attacks built on the cache storage
channel described in this paper.
In what follows we identify such known general counter-
measures (Sections V-A and V-C.1-5) and propose new ones
that are speciﬁc to the attack vector using uncacheable aliases
(Sections V-B, V-C.6, and V-D). In addition it is examined
which countermeasures are suitable to protect against
the
integrity threat posed by incoherent aliases in the memory
system and propose a ﬁx for the hypervisor example.
Different countermeasures are evaluated by implementing
them for the AES and hypervisor scenarios introduced in
the previous section and analysing their performance. The
corresponding benchmark results are shown in Tables I and II.
Since our main focus is on verifying systems in the presence of
caches, for each group of countermeasures we also sketch how
a correctness proof would be conducted. Naturally, such proofs
require a suitable model of the memory system including
instruction and data caches.
It should be emphasised that the veriﬁcation of the coun-
termeasures is meant to be performed separately from the
1Forcing the scheduler of a general purpose OS to grant such high frequency
of measurements is out of the scope of this paper. The interested reader can
refer to [34], [55].
4646
veriﬁcation of the overall system which is usually assuming
a much simpler memory model for feasibility. The goal is to
show that the countermeasures neutralise the cache storage
channels and re-establish a coherent memory model. The nec-
essary program veriﬁcation conditions from such a proof can
then be incorporated into the overall veriﬁcation methodology,
supporting its soundness.
A. Disabling Cacheability
The simplest way to eliminate the cache side channel is
to block an attacker from using the caches altogether. In a
virtualization platform, like an operating system or a hypervi-
sor, this can be achieved by enforcing the memory allocated
to untrusted guest partitions to be uncacheable. Consequently,
cache-driven attacks on conﬁdentiality and integrity of a sys-
tem are no longer possible. Unfortunately, this countermeasure
comes at great performance costs, potentially slowing down a
system by several orders of magnitude. On the other hand, a