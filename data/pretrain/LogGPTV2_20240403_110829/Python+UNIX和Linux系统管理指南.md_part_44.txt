print "Done"
#queue.join()
#By commenting out the join, the main program exits before threads have a chance
When the count of unfinished tasks drops to zero, join() unblocks.
Queue.py
to indicate the item was retrieved and all work on it is complete.
The count of unfinished tasks goes up whenever an item is added to the
run
/System/Library/Frameworks/Python.framework/Versions/2.5/lib/python2.5/
Queue.Queue.task_done(self)
www.TopSage.com
进程与并发丨307
回
---
## Page 322
非常像一个故事的开始，发展以及结束：
从这个docstring我们看到在q·get()和q.task_done()以及q.join()之间有一定联系。这
程序中执行到这一点，我们有了一个缓冲池，其中有三个线程等待执行绑定操作。它们
功能：
守护标志的情况下，程序会无限挂起。你应该自行进行检测，因为这会破坏进程的一些
需要将worker.start()这-行注释掉即可看到结果。为了截断追踪，在没有为线程设置
函数中，使用了无限循环。由于线程永远不会死亡，将其声明为守护线程是必然的。仅
setDaemon(True)。在start方法被调用之前如果没有进行设置，程序会不定期挂起。
在我们的程序中潜藏着一个微妙的惊喜，可以确保让你逃脱追踪。这需要使用
理。需要注意的是，线程池会阻塞或等待，直到队列中有事件发生。
接着看下面的示例，其中使用了一个简单的循环作为控制器，对线程池的创建进行管
308
原因非常简单，
for i in range(num_threads):
Raises a ValueError if called more times than there were items
If a join() is currently blocking, it will resume when all items
onthe taskiscomplete.
Indicate that a formerly enqueued task is complete.
while True:
第10章
worker.start()
worker
q.task_done()
if ret =z 0:
else:
print
，因为如果守护线程正在运行，程序仅能退出。或许你已经注意到在ping
print "%s: is alive" % ip 
Thread(target=pinger, args=(i, queue))
Thread %s: Pinging %s" % (i, ip)
(meaning that
stdout=open('/dev/nu1l',
www.TopSage.com
a task_done() call was received
"(.M.
---
## Page 323
#!/usr/bin/env python
例10-20：多队列与多线程池
址，如果能找到Mac地址也将返回Mac地址。这是如何执行的，参见例10-20。
接下来，第二个线程池会从第一个队列中取得IP地址，然后执行一个arp命令，返回IP地
示例中，我们会让第一个线程池放置有效的IP地址（该地址是响应ping的地址）到第二
第一个示例中，我们ping一个IP地址列表，该列表由线程池从队列中获得。在接下来的
为了真正理解线程和队列，需要进一步介绍示例，创建另一个线程池和另一个队列。在
其特别的美味。
么线程和队列就像巧克力和花生酱一样，两者的味道都是非常不错的，合起来会成为尤
的，在一个队列上调用join将导致程序的主线程等待，直到队列为空为止。这也是为什
夹在两行输出语句之间的最为关键的一行代码，最终具有程序的控制权。正如之前讨论
的操作，在这个示例中，执行的操作是ping一个IP地址：
仅需要将每一元素放到它们的队列中。这会向线程发出获取元素的信号，并且执行要求
ips =["10.0.1.1",
num_arp_threads=
num_ping_threads =
from Queue import Queue
fromthreadingimportThread
#This requires
个队列中。
mportre
while True:
print "Main Thread Waiting"
for ip in ips:.
queue.join()
if ret == 0:
queue.put(ip)
Python2.5or greater
3
stdout=open('/dev/null',
www.TopSage.com
'(.M,
进程与并发1309
---
## Page 324
for i in range(num_ping_threads):
def arping(i, oq):
310
这里我们运行这段代码，以下是代码的输出结果：
print "Done"
out_queue.join()
in_queue.join()
#spawn pool of arping threads
#spawn pool.of ping threads
in_queue.put(ip)
Thread 0: Pinging 10.0.1.51
worker.start()
worker = Thread(target=arping, args=(i, out_queue))
worker.start()
worker = Thread(target=pinger, args=(i, in_queue, out_queue)
Thread 2:Pinging 10.0.1.11
Thread 0:Pinging 10.0.1.1
worker.setDaemon(True)
worker.setDaemon(True)
whileTrue:
grabs
pattern = re.compile(":")
out = p.stdout.read()
p = subprocess.Popen("arping -C 1 %s" % ip,
#match and extract mac address from stdout
iq.task_done()
第10章
result=out.split()
else:
ips:
item in result:
oq.put(ip)
'a valid IP address from a queue and gets macaddr"""
macaddr
=item
stdout=subprocess.PIPE)
shell=True,
www.TopSage.com
---
## Page 325
继续运行：
如果执行这段代码，可以看到一个为函数定时的延迟被触发，而主线程，或是程序，仍
t.start()
call_time = copy.copy(delay) #we copy the delay to use later
#we spawn our time delayed thread here
for
def
#our function that we willrun
import copy
importsys
from threading import Timer
例10-21：线程计时器
计的线程计时器示例。
threading.Timer，在一个线程中运行被定时执行的函数变得非常简单。例10-21是专门设
Python中的线程还有另一个功能，可以为系统管理员完成任务提供一些便利。通过使用
使用threading.Timer的线程延迟
程更方便且更安全。该技术甚至可以毫无疑问地称为必备技术。
功能。这是一个重要的技术，可以放入到你自己的工具包中，因为使用队列模块使得线
为了实现这一解决方案，我们通过添加另一个线程和队列池，略微扩展了第一个示例的
[ngift@Macintosh-6][H:10468][J:0]# python thread timer.py 5
time.sleep(1)
delay =int(delay)-1
print“
hello():
Done
IP Address: 10.0.1.1| Mac Address:[00:00:00:00:00:01]
sys.exit(1
"Hello, I just got called after a %s sec delay" % call_time
10.0.1.3 |Mac Address:[00:00:00:07:E4:03]
=1
2:
www.TopSage.com
进程与并发丨311
X
PDG
---
## Page 326
def _init_(self, poll=10,
peaxul pakeraa e ut pouaw e sumeds zeul sero doon suaas u
#!/usr/bin/env python
例10-22：线程化的目录同步工具
--delete”进行处理。
段代码可以保持两个目录同步，如果它们不同步，在后台延迟线程会使用“rsync，-av
这个模块可以非常容易地抽象为更一般的工具，
发，一个动作方法会在一个延迟线程中被调用。
示例简单性的思想，我们查看一下这个事件循环如何查询注册的事件。事件一旦被触
的事件循环。我们可能已经变得非常有经验，可以检验文件的修改时间，但是出于保持
def action(self):
from subprocess import call
示例中，我们采用延迟线程技术，并且混合了一个对两个目录中文件名的差异进行查询
因为这是一本关于系统管理的书，让我们使用之前的技术来看一个实际的应用。在这个
线程化的事件处理
312
class EventLoopDelaySpawn(object):
importos
importcopy
if self.verbose:
Main program is still running for 1 more sec
Main program is still running for 2 more sec
Main program is still running for 4 more sec
if self.verbose:
self.wait = int(wait)
self.poll = int(poll)
time.sleep(self.poll)
self.dir2=dir2
self.dir1 =dir1
self.verbose=verbose
print "polling at %s sec interval" % self.poll
丨第10章
dir2="/tmp/dir2"):
dir1="/tmp/dir1",
verbose=True,
wait=1,
www.TopSage.com
，但是现在例10-22还是一个硬代码。该
---
## Page 327
以扩展到多处理器，这与Python中的线程不一样。因为GIL（全局解释器锁）的原因，
在Python中线程不是处理并发的唯一方法。事实上，进程相比线程也有一些优势，其可
进程
可以创建根据条件可以取消的将来的操作。
的主目录被意外删除），你可以告诉线程进行取消。线程延迟是一个非常不错的机制，
好处。如果你添加一个延迟，例如5秒，这期间你发现另一个事件发生（例如，如果你
读者可能会认为延迟不是严格需要的，这确实是事实。然而，延迟可以创建一些额外的
E = EventLoopDelaySpawn()
用fork进程。
与线程一起工作。例如，当前Python的Net-SNMP库是同步的，因此写并发代码需要使
如果一个问题需要使用多处理器，那么进程会是一个不错的选择。另外，有许多库不能
的
利用CPU，线程已不是一个好的选择。在这样的情况下，使用独立的进程是非常适合
在某一时刻只有单一线程可以运行，并且这被限制到单处理器。为了让Python可以充分
E.run()
#if two directories contain same file names
finally:.
except Exception, err:
try:.
else:
ret=call("rsync -av --delete %s/ %s"
sys.exit(o)
while True:
if self.verbose:
print "waiting %s seconds to run Action" % self.wait
t.start()
print os.listdir(self.dir1)
+
 = Timer((self.wait), self.action)
print "No Event Registered"
print “"Event Registered"
self.poller()
self.eventHandler()
www.TopSage.com
%(self.dir1, self.dir2), shell=True)
进程与并发丨313
---
## Page 328
def f(q):
#1/usr/bin/env python
例10-23：processing模块
现在，我们已经具有了一些关于processing模块的背景知识，接下来看一下例10-23。
org/pypilprocessing，可以找到有关processing模块的更多信息。
没必要为了创建进程（而不是线程）学习一个新的API。访问网址：http://pypi.python.
程。关于processing模块最重要的内容之一是它或多或少可以映射到线程API。这表示你
processing是一个Python语言的软件包，支持使用标准库中threading模块的API创建进
那么，我们提到的processing模块又是什么呢？在这本书出版时，其描述是这样的：
Processing模块
到一个示例，该示例中我们创建一个可以创建多个dd进程的工具。
在许多情况下，并行执行代码是非常不错且非常简便的选择。如果阅读第13章，可以看
在之前的说明中，我们提及一个可选的使用subprocess.Popen来创建多个进程的方法。
节。这里有一些讨论，涉及整合进程库到Python的标准库中，这对于理解非常有帮助。
通过管道与进程进行通信难度比较小。有一个进程库我们将在这里进一步介绍其中的细
线程共享全局状态，进程则是完全独立的，与进程进行通信需要一些技术。幸运的是，
314
print “main process joins on queue"
for i in range(10):
q = Queue()
import time
注意：
q.put(i)
x= q.get()
i.start()
：正如之前谈论的，处理并发没有什么简单的方法。这个示例也可以认为是低效的，因
= Process(target=f, args=[q])
pep-03241。
Subprocess当前缺少像processing模块一样管理大量进程的能力。这种对Subprocess的需求
个与之前线程示例的合理的对比。有一些将processing模块合并到Subprocess的讨论，因为
call。然而，在一些大的应用背景环境下，使用队列类型API有许多好处，还可以作为一
为仅使用了subprocess.Popen，而不是processing模块的fork，并且运行了subprocess。
第10章
www.TopSage.com
---
## Page 329
#1/usr/bin/env python
例10-24：基于进程的ping扫描
在线程一节中，我们写了一个简单的线程化的子网发现脚本。因为进程API与线程API十
现在已经有了等同的Hello World程序，我们可以做一些更有意义的事情。或许你还记得
这是一个非常简洁的API。
程序所做的所有工作是告诉每一个进程休眠与其进程号相同的时间。正如你所看到的,
q = Queue()
如果查看输出，会看到下面的内容：
import·sys
import subprocess
分相似，
while True:
f(i,q):
Main Program finished
Process number 9 finished
Process number 8