title:Exploring EDNS-client-subnet adopters in your free time
author:Florian Streibelt and
Jan B&quot;ottger and
Nikolaos Chatzis and
Georgios Smaragdakis and
Anja Feldmann
Exploring EDNS-Client-Subnet Adopters in your Free Time*
Florian Streibelt
TU Berlin
ﬂPI:EMAIL
Jan Böttger
TU Berlin
PI:EMAIL
Nikolaos Chatzis
TU Berlin
PI:EMAIL
Georgios Smaragdakis
T-Labs/TU Berlin
PI:EMAIL
ABSTRACT
The recently proposed DNS extension, EDNS-Client-Subnet (ECS),
has been quickly adopted by major Internet companies such as
Google to better assign user requests to their servers and improve
end-user experience. In this paper, we show that the adoption of
ECS also offers unique, but likely unintended, opportunities to un-
cover details about these companies’ operational practices at almost
no cost. A key observation is that ECS allows to resolve domain
names of ECS adopters on behalf of any arbitrary IP/preﬁx in the
Internet. In fact, by utilizing only a single residential vantage point
and relying solely on publicly available information, we are able
to (i) uncover the global footprint of ECS adopters with very little
effort, (ii) infer the DNS response cacheability and end-user clus-
tering of ECS adopters for an arbitrary network in the Internet, and
(iii) capture snapshots of user to server mappings as practiced by
major ECS adopters. While pointing out such new measurement
opportunities, our work is also intended to make current and future
ECS adopters aware of which operational information gets exposed
when utilizing this recent DNS extension.
General Terms
Measurement.
Keywords
Content Delivery; DNS; CDN.
1.
INTRODUCTION
In the current Internet, hostnames are typically resolved using
the local resolvers provided by the respective Internet Service Pro-
vider (ISP). Unless the answer is cached, the ISP’s domain name
server performs a recursive lookup to receive an authoritative an-
swer which it can then cache. Large Content Delivery Networks
(CDNs) and Content Providers (CPs) use the domain name system
(DNS) to map users to possible locations and consequently to ap-
propriate servers [27, 38].
(cid:63) This work would not have been possible without the help,
engagement, and commitment of Walter Willinger.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
IMC’13, October 23–25, 2013, Barcelona, Spain.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-1953-9/13/10 ...$15.00.
http://dx.doi.org/10.1145/2504730.2504767.
Anja Feldmann
TU Berlin
PI:EMAIL
Unfortunately for the CDNs and CPs, the DNS query is not di-
rectly issued by the end-user but only by the local resolver (see [37]
for details). Thus, the assumption underlying this solution is that
the end-user is close to the local resolver or that a resolver serves
clients that are close to each other. However, several studies [11,
26] have shown that these assumptions do not always hold which,
in turn, can lead to degraded end-user experience. In particular, the
introduction of third party resolvers like Google Public DNS [4] or
OpenDNS [7] has exaggerated this trend as end-users, taking ad-
vantage of these as resolvers, may experience poor performance[11,
28, 32]. This empirical evidence is mainly due to the fact that these
popular third-party resolvers are typically not located within the
end-users’ ISP and are therefore often not close to the end-user.
The solution, as proposed by Google and others to the IETF [17],
is the EDNS-Client-Subnet DNS extension (ECS). While tradition-
al DNS queries do not include the IP address of the query issuer
(except via the socket information), ECS includes IP address infor-
mation of the original query issuer in the query to the authoritative
name server. The IP address information can then be used by the
CDN or CP to improve the mapping of end-users to servers. Thus,
it is not surprising that major Internet companies (e.g., Google,
Edgecast, and OpenDNS) have already adopted ECS and have es-
tablished the consortium “a faster Internet” [1]. The fact that ECS
can indeed help improve end-user performance is highlighted by
extensive active measurement studies [28, 32].
For the Internet measurement community, the adoption of ECS
by some of the major Internet players turns out to offer unique but
clearly unintended opportunities. To illustrate, we show in this pa-
per how ECS can be used to uncover details of the operational prac-
tices of ECS adopters with almost no effort. Our key observation is
that ECS allows anyone to issue queries on behalf of any “end-user”
IP address for domains with ECS support. Thus, ECS queries can
help uncovering the sophisticated techniques that CDNs and CPs
use for mapping users to servers (e.g, see [24, 23, 26]). Indeed,
this currently hard-to-extract information can now be collected us-
ing only a single vantage point and relying on publicly available
information. In the past, to obtain similar information, network re-
searchers had to ﬁnd and use open or mis-conﬁgured resolvers [10,
22, 35], have access to a multitude of vantage points in edge net-
works [28, 32], rely on volunteers [11, 12], analyze proprietary
data [25, 30], or resort to searching the Web [34].
In summary, the three contributions of this paper to the area of
Internet measurement are:
• We show that a single vantage point combined with publicly
available information is sufﬁcient to uncover the global foot-
print of ECS adopters and track their expansions.
• We demonstrate how to infer the DNS cacheability and end-
user clustering strategies of ECS adopters.
• We illustrate how to capture snapshots of the assignment of
users to server locations performed by major ECS adopters.
At the same time, this work is also intended to increase the
awareness of current and future ECS adopters about which oper-
ational information gets exposed when enabling this recent DNS
extension. Despite the fact that experts in the operational commu-
nity may be aware of some of the shortcomings and consequences
of the ECS adoption, a systematic study is still missing. Our soft-
ware and measurements are publicly available1.
2. ECS BACKGROUND
The EDNS-Client-Subnet DNS extension [17] was introduced
to tackle the problem of mis-locating the end-system which orig-
inates the DNS request. The problem is that the end-system’s IP
information is typically hidden from the authoritative name server.
With ECS, client IP information is forwarded by all ECS-enabled
resolvers to the authoritative name server in the form of network
preﬁxes.
2.1 Protocol Speciﬁcation
ECS is an EDNS0 DNS extension [36] proposed by the IETF
DNS Extensions Working Group. EDNS0, which is also needed
for DNSSEC, uses an ADDITIONAL section in DNS messages
to transfer optional data between name servers. Since all sections
from a DNS query are present in the DNS response, bidirectional
data transfer is enabled as the responder can modify this section.
Name servers that do not support EDNS0 either strip the EDNS0
OPTRR in the ADDITIONAL section or forward it unmodiﬁed.
An example ECS-enabled query and response is shown in Fig-
ure 1. The ADDITIONAL section includes an OPTRR resource-
record containing the ECS header and data. The ECS payload con-
sists of the address family used, i.e., IPv4 or IPv6, preﬁx length,
scope and client preﬁx. To protect a client’s privacy, [17] recom-
mends to use preﬁxes less speciﬁc than 32. In each query the scope
ﬁeld must be zero and is a placeholder for the returned scope.
The response from an ECS-enabled DNS server differs in one
byte, namely the scope, which is needed for DNS caching. The
answer can be cached and used for any query with a client preﬁx
that is a more speciﬁc or equal to the preﬁx as speciﬁed by the
scope. We note that the response may contain a different scope
than the query network mask, and we have indeed observed larger
as well as shorter scopes than preﬁx length in our measurements. In
the example, the query preﬁx length is 16 while the returned scope
is 24. The scope is the essential element that allows us to infer
operational practices of ECS adopters.
2.2 Challenges in Enabling ECS
While ECS is transparent to the end-user, it requires signiﬁcant
efforts by the DNS server operators, mainly because all involved
DNS servers have to at least forward the ECS information. Among
the major obstacles are: (i) ECS-support in server software is not
widely available2, (ii) all involved DNS servers need to be up-
graded3, and (iii) third-party resolvers are not necessarily sending
ECS queries by default. To change the latter, an engineer of, say,
1http://projects.inet.tu-berlin.de/projects/
ecs-adopters
2We ﬁnd that only PowerDNS supports ECS as authoritative name-
server but not as resolver. Moreover, only for some clients e.g., dig
and dnspython patches are available.
3CDNs may internally use multiple resolution levels, e.g., Aka-
mai [27].
Figure 1: Example of ECS query and response.
Google Public DNS or OpenDNS, has to manually check the au-
thoritative name servers and white-list them as ECS compliant.
Moreover, appropriate cache support has to be added to the DNS
resolvers. Here, ECS with its notion of scope introduces another
problem. For each query, the resolver has to check if the IP ad-
dress of the client lies within the scope of any cached result. If not,
the query has to be relayed with the appropriate preﬁx information.
Just imagine the extreme scenario—scope of 32. Then, the resolver
should keep a separate entry per client making caching largely in-
effective.
Overall, handling ECS is quite complicated as the draft requires
DNS forwarders to forward the ECS information sent by the client.
It may modify the preﬁx mask to a less speciﬁc. If no ECS infor-
mation is present in the DNS request, the forwarder may add an
OPTRR record based on information from the socket. This is the
rule followed e.g., by Google’s public DNS servers. Note, that until
Google enabled EDNS0 for DNSSEC support, it stripped the ECS
records. Now, this information seems to be forwarded unmodiﬁed.
3. DATASETS
The following two different kinds of datasets are used in this
paper: (i) preﬁxes to be used as pretended “client location” for the
ECS queries, and (ii) popular ECS adopters.
3.1 Network Preﬁxes
In principle, one list of preﬁxes may be considered sufﬁcient.
However, because we want to uncover the operational practices of
certain CDNs and CPs with regards to client localization and clus-
tering, we explore different preﬁx sets of varying scopes and mag-
nitudes. To that end, we use both private and public sets of network
preﬁxes.
Academic Network (UNI). This network includes a very diverse
set of clients, ranging from ofﬁce working spaces to student dorms
and research facilities which complicates usage proﬁling. This net-
work uses two /16 blocks, does not have an AS, and is localized to
a single city in Europe.
Large ISP (ISP). The dataset includes more than 400 preﬁxes,
ranging from /10 to /24, announced by a European tier-1 ISP. This
ISP offers services to residential users as well as enterprise net-
works and also hosts CDN servers.
Large ISP, de-aggregated preﬁxes (ISP24). We also use the de-
aggregated announced preﬁxes of our large ISP at the granularity
of /24 blocks to investigate if the ﬁner granularity lets us uncover
additional operational details.
Popular Resolvers (PRES). This proprietary dataset consists of
the 280K most popular resolver IPs that contacted a large commer-
10100006000600010001Option Length (6)ECS Query     : ECS Response:Address Family (1=IPv4)DNS messageEDNS Client−IPOption CodeEDNS0 OPTRR# dig www.google.com +client=130.149.0.0/16 @ns1.google.com00080008Prefix Length (16)HeaderQueryAnswerAuthoritativeAdditional SectionECSScope0082 95...82 95...Client−IP/Prefix 18cial CDN. These resolvers are distributed across 21K ASes, 74K
preﬁxes, and 230 countries.
RIPE. RIPE RIS [8] makes full BGP routing tables from a multi-
tude of BGP peering sessions publicly available. This data includes
500K preﬁxes from 43K ASes.
Routeviews (RV). This is another public BGP routing table source
offered by the University of Oregon [9].
3.2 Content Provider Datasets
For our experiments, we need to identify ECS adopters and the
corresponding hostnames. For this purpose, we utilize Alexa [2]
(April 20, 2013), a publicly available database of the top 1 Mil-
lion second-level domains, as was done by Otto et al.[28]. Since
the ECS extension does not allow us to directly ﬁnd out if a name
server is ECS enabled or not, we use the following heuristic. We
re-send the same ECS query with three different preﬁx lengths. If
the scope is non-zero for one of the replies, we annotate the server
and hostname as ECS-enabled.
We obtain two disjoint groups of (domain names, name-servers)
pairs. The ﬁrst group fully supports ECS and accounts for 3% of
the second-level domain names. The second group, about 10%, is
ECS-enabled according to the IETF draft [17] but does not appear
to use the additional section information for the tested domains
(it may well just return a copy of the additional section). Thus,
roughly 13% of the top 1 million domains may be ECS-enabled.
This number is only slightly larger than what was reported in a 2012
study [28]. However, some of the big players are among the ECS
adopters, including Google (and YouTube), Edgecast, CacheFly,
HiCloud, and applications hosted in the cloud such as MySqueeze-
box.
To estimate the potential trafﬁc affected by ECS, we use a 24
hour anonymized packet-level trace from a large European ISP.
The trace is from a residential network with more than 10K ac-
tive end-users and was gathered using Endace cards and analyzed
with Bro [29]. It contains 20.3 million DNS requests for more than
450K unique hostnames and 83 million connections. While Alexa
only includes the second-level domain names, this dataset allows
us to identify full hostnames, which we use in a similar manner as
above. In total, we ﬁnd that roughly 30% of the trafﬁc involves ECS
adopters. This highlights that while the number of ECS adopters is
relatively small (less than 3% of the authoritative name servers), it
includes some of the relevant players responsible for a signiﬁcant
fraction of trafﬁc.
From the set of identiﬁed ECS adopters, we select a large CDN,
two smaller CDNs, and an application deployed in the cloud to ex-
plore their operational practices. In the rest of the paper we mainly
focus on:
Google is a founding member of the consortium “a faster Internet”
and one of the main supporters of ECS. It has adopted ECS in all
their resolvers and name servers. Moreover, Google uses a sophis-
ticated backend with many data centers, edge-servers, and Google
Global Cache (GGC) servers located inside ISPs [3, 13, 19]. It is
known that there can be anywhere between tens to thousands of
Google servers behind a single Google IP [33].
Edgecast is a large CDN that also offers streaming solutions. It is
also one of the participants in the “a faster Internet” consortium.
CacheFly is another CDN that has adopted ECS.
MySqueezebox is a Logitech product that runs on top of Amazon’s
Web cloud Service EC2.
4. METHOD
For our experiments, we take advantage of the ECS extension of
the python DNS libraries provided by OpenDNS [7]. Based on this
library, we have developed a framework which utilizes the above
API to send ECS DNS queries with arbitrary ECS client subnet
information to authoritative name servers. By embedding this li-
brary into our test framework, we can handle failures and retries
efﬁciently which would have been more complicated with a stand-
alone utility like the patched dig tool [17].
We emphasize that a single vantage point is sufﬁcient for per-
forming our experiments, as with ECS the answers exclusively de-
pend on the client preﬁx sent. This is conﬁrmed by synchronized
measurements from two research networks (US, Germany) and a