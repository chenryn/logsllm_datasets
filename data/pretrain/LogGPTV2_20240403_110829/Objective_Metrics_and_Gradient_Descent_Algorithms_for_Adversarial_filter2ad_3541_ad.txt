### 4.3 Comparative Analysis of Adversarial Perturbations

NewtonFool and DeepFool produce very close results, achieving smaller perturbation values compared to the other two algorithms. Conversely, the performance of FGSM and JSMA is relatively worse. Notably, JSMA significantly alters the high-frequency components, suggesting that it corrupts more feature details than the other algorithms. NewtonFool consistently outperforms all other algorithms in our Fourier transform metric across all experiments.

### 4.4 Efficiency

In the final part of our experimental study, we evaluate the efficiency of different algorithms by measuring the end-to-end time required to generate adversarial examples. Our findings indicate that NewtonFool is substantially faster than DeepFool (up to 49 times) and JSMA (up to 800 times), while being only moderately slower than FGSM. This efficiency is not surprising given that NewtonFool does not need to examine first-order information for all classes in a complex classification network. However, it is noteworthy that NewtonFool, which leverages an aggressive assumption about the vulnerability of CNNs, achieves better efficiency while producing competitive and often superior adversarial examples. Detailed results are provided in Appendix B due to space limitations.

### Tables and Results

#### Table 2: MNIST - Canny Edge Detection
| Original Image | FGSM | JSMA | DeepFool | NewtonFool |
|----------------|------|------|----------|------------|
| 1.71 (0.49)    | 1.62 (0.54) | 2.34 (0.84) | 1.60 (0.53) | 1.62 (0.54) |
| 1.07 (0.35)    | 1.07 (0.34) | 2.39 (1.30) | 1.06 (0.31) | 1.07 (0.34) |
| 1.36 (0.59)    | 1.37 (0.66) | 2.00 (1.01) | 1.34 (0.61) | 1.34 (0.61) |
| 1.17 (0.52)    | 1.20 (0.55) | 1.69 (0.96) | 1.17 (0.53) | 1.19 (0.55) |
| 1.22 (0.53)    | 1.25 (0.57) | 1.67 (0.82) | 1.26 (0.60) | 1.25 (0.59) |

FGSM, DeepFool, and NewtonFool produce similar results, with NewtonFool being especially close to DeepFool. JSMA, on the other hand, produces significantly larger statistics with respect to the Canny edge detection metric.

#### Table 3: GTSRB - Canny Edge Detection
| Original Image | FGSM | JSMA | DeepFool | NewtonFool |
|----------------|------|------|----------|------------|
| 13.73 (6.65)   | 18.88 (7.71) | 15.04 (6.62) | 14.84 (6.61) | 14.68 (6.88) |
| 17.85 (6.84)   | 22.63 (7.76) | 18.54 (6.69) | 18.82 (7.34) | 18.34 (7.11) |
| 11.69 (6.00)   | 19.11 (7.56) | 12.95 (5.86) | 12.96 (5.67) | 12.81 (5.73) |
| 18.14 (7.41)   | 20.97 (8.01) | 19.18 (7.83) | 18.40 (7.03) | 18.37 (7.25) |
| 10.37 (5.42)   | 17.89 (7.92) | 11.20 (5.53) | 11.16 (5.30) | 10.62 (5.20) |
| 13.66 (6.28)   | 20.45 (9.46) | 14.71 (6.24) | 15.06 (7.13) | 15.02 (7.08) |

JSMA, DeepFool, and NewtonFool give close results, while FGSM produces significantly worse results. NewtonFool provides the best results across all tests, except for the last sign.

#### Table 4: MNIST - Fast Fourier Transform
| Original Image | FGSM | JSMA | DeepFool | NewtonFool |
|----------------|------|------|----------|------------|
| 12.57 (6.70)   | 42.37 (9.04) | 6.39 (3.11) | 5.95 (2.96) | 15.33 (6.07) |
| 48.67 (9.42)   | 8.54 (3.17) | 7.83 (3.01) | 15.79 (7.95) | 45.07 (8.69) |
| 7.37 (3.09)    | 6.60 (2.91) | 11.99 (6.52) | 49.44 (11.69) | 7.42 (3.82) |
| 6.76 (3.62)    | 10.43 (5.11) | 44.41 (9.35) | 6.70 (3.01) | 5.96 (2.80) |

DeepFool and NewtonFool produce similar results, while FGSM and JSMA yield worse results, with JSMA being particularly poor. NewtonFool achieves the best results for all labels.

#### Table 5: GTSRB - Fast Fourier Transform
| Original Image | FGSM | JSMA | DeepFool | NewtonFool |
|----------------|------|------|----------|------------|
| 46.86 (36.94)  | 54.95 (28.17) | 9.67 (7.18) | 9.02 (7.66) | 37.50 (15.97) |
| 66.81 (18.04)  | 7.33 (2.70) | 6.16 (2.54) | 44.34 (27.72) | 79.87 (23.89) |
| 8.07 (3.96)    | 6.84 (3.84) | 37.81 (27.04) | 72.62 (29.64) | 7.88 (6.43) |
| 6.93 (6.12)    | 15.12 (10.47) | 56.14 (15.56) | 4.38 (1.21) | 3.49 (0.86) |
| 50.84 (22.82)  | 78.91 (24.02) | 8.78 (4.41) | 7.95 (4.34) |  |

DeepFool and NewtonFool again produce similar results, while FGSM and JSMA perform worse. Across all tests, NewtonFool consistently achieves the best results.

### 5. Limitations and Future Work

We have not yet implemented the enhancements to our algorithm described in the appendix. In future work, we will implement these enhancements and compare their performance to our basic algorithm. The computer vision literature includes several algorithms for image analysis, such as segmentation, edge detection, and deblurring. In our evaluation, we use one algorithm (edge detection) as a metric. Incorporating other computer vision algorithms into a metric is a promising avenue for future research. For example, let \(\mu_1, \mu_2, \ldots, \mu_k\) be \(k\) metrics (e.g., based on number of pixels, edges, and segments). We could consider a weighted metric, such as \(\sum_{i=1}^k w_i \mu_i(x_1, x_2)\). The question remains: how to choose the weights? Mechanical Turk studies could be used to train appropriate weights. Additionally, this weighted metric could be incorporated into algorithms for constructing adversarial examples. These directions are important avenues for future work.

### 6. Conclusion

This paper presents a gradient-descent-based algorithm for finding adversarial examples and uses edge detectors to evaluate the quality of adversarial examples generated by different algorithms. While the area of crafting adversarial examples is well-studied, metrics for evaluating their quality are less so. We believe that incorporating computer vision algorithms into these metrics is a worthwhile goal and worthy of further research. A diverse set of algorithms for generating adversarial examples is crucial for a thorough evaluation of proposed defenses.

### Acknowledgments

We are grateful to the ACSAC reviewers for their valuable comments and suggestions. We also thank Adam Hahn for his patience during the submission process. This work was supported by the Army Research Office (ARO) under contract number W911NF-17-1-0405. Any opinions, findings, conclusions, and recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the funding agencies.

### References

[1] DeepFace: Closing the Gap to Human-Level Performance in Face Verification. In Conference on Computer Vision and Pattern Recognition (CVPR).

[2] Babak Alipanahi, Andrew Delong, Matthew T Weirauch, and Brendan J Frey. 2015. Predicting the sequence specificities of DNA- and RNA-binding proteins by deep learning. Nature Biotechnology (2015).

[3] M. Bojarski, D. Del Testa, D. Dworakowski, B. Firner, B. Flepp, P. Goyal, L. Jackel, M. Monfort, U. Muller, J. Zhang, X. Zhang, J. Zhao, and K. Zieba. 2016. End to End Learning for Self-Driving Cars. Technical Report.

[4] Mariusz Bojarski, Davide Del Testa, Daniel Dworakowski, Bernhard Firner, Beat Flepp, Prasoon Goyal, Lawrence D. Jackel, Mathew Monfort, Urs Muller, Jiakai Zhang, Xin Zhang, Jake Zhao, and Karol Zieba. 2016. End to End Learning for Self-Driving Cars. CoRR abs/1604.07316 (2016). http://arxiv.org/abs/1604.07316.

[5] J Canny. 1986. A Computational Approach to Edge Detection. IEEE Trans. Pattern Anal. Mach. Intell. 8, 6 (June 1986), 679–698. https://doi.org/10.1109/TPAMI.1986.4767851

[6] Nicholas Carlini and David Wagner. 2017. Towards Evaluating the Robustness of Neural Networks. In IEEE Symposium on Security and Privacy.

[7] Chih-Lin Chi, W. Nick Street, Jennifer G. Robinson, and Matthew A. Crawford. 2012. Individualized Patient-centered Lifestyle Recommendations: An Expert System for Communicating Patient-Specific Cardiovascular Risk Information and Prioritizing Lifestyle Options. Journal of Biomedical Informatics 45, 6 (Dec. 2012), 1164–1174.

[8] George E Dahl, Jack W Stokes, Li Deng, and Dong Yu. 2013. Large-scale malware classification using random projections and neural networks. In Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP). IEEE, 3422–3426.

[9] Navneet Dalal and Bill Triggs. 2005. Histograms of Oriented Gradients for Human Detection. In Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) - Volume 1 - Volume 01 (CVPR '05). IEEE Computer Society, Washington, DC, USA, 886–893. https://doi.org/10.1109/CVPR.2005.177

[10] Nathan Eddy. 2016. AI, Machine Learning Drive Autonomous Vehicle Development. InformationWeek. http://www.informationweek.com/big-data/big-data-analytics/ai-machine-learning-drive-autonomous-vehicle-development/d/d-id/1325906

[11] Leslie Hogben (Editor). 2013. Handbook of Linear Algebra. Chapman and Hall/CRC.

[12] Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. 2014. Explaining and Harnessing Adversarial Examples. CoRR (2014).

[13] Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. 2015. Explaining and Harnessing Adversarial Examples. In Proceedings of the 2015 International Conference on Learning Representations. Computational and Biological Learning Society.

[14] Geoffrey Hinton, Li Deng, Dong Yu, George E. Dahl, Abdel-rahman Mohamed, Navdeep Jaitly, Andrew Senior, Vincent Vanhoucke, Patrick Nguyen, Tara N. Sainath, et al. 2012. Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups. IEEE Signal Processing Magazine 29, 6 (2012), 82–97.

[15] Ling Huang, Anthony D. Joseph, Blaine Nelson, Benjamin I.P. Rubinstein, and J.D. Tygar. 2011. Adversarial machine learning. In Proceedings of the 4th ACM Workshop on Security and Artificial Intelligence. ACM, 43–58.

[16] X. Huang, M. Kwiatkowska, S. Wang, and M. Wu. 2017. Safety Verification of Deep Neural Networks.

[17] International Warfarin Pharmacogenetic Consortium. 2009. Estimation of the Warfarin Dose with Clinical and Pharmacogenetic Data. New England Journal of Medicine 360, 8 (2009), 753–764.

[18] K. Julian, J. Lopez, J. Brush, M. Owen, and M. Kochenderfer. 2016. Policy Compression for Aircraft Collision Avoidance Systems. In Proc. 35th Digital Avionics Systems Conf. (DASC).

[19] Guy Katz, Clark Barrett, David Dill, Kyle Julian, and Mykel Kochenderfer. 2017. An Efficient SMT Solver for Verifying Deep Neural Networks.

[20] Eric Knorr. 2015. How PayPal Beats the Bad Guys with Machine Learning. InfoWorld. http://www.infoworld.com/article/2907877/machine-learning/how-paypal-reduces-fraud-with-machine-learning.html

[21] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. 2012. Imagenet Classification with Deep Convolutional Neural Networks. In Advances in Neural Information Processing Systems. 1097–1105.

[22] A. Kurakin, I. J. Goodfellow, and S. Bengio. 2016. Adversarial Examples in the Physical World. (2016).

[23] Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal Frossard. 2015. DeepFool: A Simple and Accurate Method to Fool Deep Neural Networks. CoRR (2015).

[24] Seyed Mohsen Moosavi Dezfooli, Alhussein Fawzi, Omar Fawzi, and Pascal Frossard. 2017. Universal Adversarial Perturbations. In Proceedings of 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR).

[25] Jorge Nocedal and Stephen Wright. 2006. Numerical Optimization. Springer.

[26] NVIDIA. 2015. NVIDIA Tegra Drive PX: Self-Driving Car Computer. (2015). http://www.nvidia.com/object/drive-px.html

[27] Nicolas Papernot, Ian Goodfellow, Ryan Sheatsley, Reuben Feinman, and Patrick McDaniel. 2016. cleverhans v1.0.0: An Adversarial Machine Learning Library. arXiv preprint arXiv:1610.00768 (2016).

[28] Nicolas Papernot, Patrick McDaniel, Somesh Jha, Matt Fredrikson, Z. Berkay Celik, and Ananthram Swami. 2016. The Limitations of Deep Learning in Adversarial Settings. In Proceedings of the 1st IEEE European Symposium on Security and Privacy. arXiv preprint arXiv:1511.07528.

[29] Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. Proceedings of the Empirical Methods in Natural Language Processing (EMNLP 2014) 12 (2014), 1532–1543.

[30] Alfio Quarteroni, Riccardo Sacco, and Fausto Saleri. 2000. Numerical Mathematics. p. 307.

[31] Eui Chul Richard Shin, Dawn Song, and Reza Moazzezi. 2015. Recognizing Functions in Binaries with Neural Networks. In 24th USENIX Security Symposium (USENIX Security 15). 611–626.

[32] J. Stallkamp, M. Schlipsing, J. Salmen, and C. Igel. 2012. Man vs. Computer: Benchmarking Machine Learning Algorithms for Traffic Sign Recognition. Neural Networks 0 (2012), –. https://doi.org/10.1016/j.neunet.2012.02.016

[33] Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian J. Goodfellow, and Rob Fergus. 2013. Intriguing Properties of Neural Networks. CoRR abs/1312.6199 (2013).

### A. Extension

#### A.1 Problem Formulation

In general, given a point \(x_0\), we can consider two disjoint sets of labels \(L^+\) and \(L^-\) as follows:

- \(L^+ = \{l_1^+, \ldots, l_m^+\}\) is the set of \(m\) labels achieving high confidences \(F^{l_1^+}(x_0), \ldots, F^{l_m^+}(x_0)\) of the classifier.
- \(L^- = \{l_1^-, \ldots, l_n^-\}\) is the set of \(n\) labels achieving low confidences \(F^{l_1^-}(x_0), \ldots, F^{l_n^-}(x_0)\) of the classifier.