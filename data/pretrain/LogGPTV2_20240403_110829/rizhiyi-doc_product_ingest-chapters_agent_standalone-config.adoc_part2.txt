==== 数据库
数据库数据采集需要日志易1.8.0之后版本提供，agent需要1.7.30.0以上版本才支持。
1.	点击添加数据页面的数据库数据标签，进入添加数据库数据源流程：
2.	在选择数据库连接页面，可以选择一个已有的连接来进行数据库采集，也可以新建一个数据库连接采集：
+
image::images/agent-database-input.png[]
3.	如果是新建连接，那么需要按提示填入对应配置，点击保存后会自动验证，建议起一个方便管理的连接名称。
+
image::images/agent-database-connection-config.png[]
+
系统会自动将填入的用户名、密码、主机、端口、库名称等参数，按照所选的数据库类型，拼接成 ODBC 支持的 DSN(data source name，一种用来记录数据库连接信息的特定语法) 字符串。如果有需要，你也可以自定义 DSN 的写法。比如：
** 采集 Hive 数据库时，由于页面暂不支持，您需要手动填写 hive 端口为 10000，并修改 DSN 字符串为：`user id=;password=;server=;port=`。
** 采集达梦数据库，DSN配置为：`Driver=DM;Server=;uid=;pwd=;tcp_port=`。
** 采集中兴 GoldenDB 数据库，DSN 配置为：`:@tcp(:)/?ignorePingErr=true`。
** 采集 sybase 16 SP03 及以上版本，DSN 配置为：`database= host= port= user= pass=`。
** 采集 sqlite 文件，则在"数据库名"内填写 sqlite 文件的本地路径，DSN 配置为：``。
+
选中连接后，点击下一步，进入相关参数输入和SQL预览页面, 左侧配置该数据源的appname，tag信息，以及配置采集频率；右侧在输入框输入采集使用的SQL语句，点击预览，下方表格将会展示若干行数据供预览：
+
image::images/agent-database-preview.png[]
4.	如果您需要采集的数据在远端数据库中也是只增方式记录，可以通过增量采集来减少数据读取的压力和避免重复记录。请点击切换成增量采集方式，配置对应库中的增量字段名称、增量操作符、轮询频率等相关配置项。如果数据库中不存在增量字段的，在确定是增量需求的前提下，可以通过数据库的 `ROWNUM` 机制来模拟增量采集效果(性能有限，慎用)：
+
image::images/agent-database-incre-config.png[]
+
不同的数据库类型，需要采用不同的对应模拟增量语句。语句举例如下：
+
* Oracle采集SERVICEEXCEPTION表: `SELECT * FROM (SELECT A.*, ROWNUM RN FROM (SELECT * FROM SERVICEEXCEPTION) A) WHERE RN >= 0`
* MySQL采集Report表: `SELECT * from (SELECT @rownum := @rownum + 1 AS RN, A.* FROM Report A, (SELECT @rownum := 0) R ) T`
* DB2采集DB2ADMIN.test表: `SELECT * from (SELECT ROW_NUMBER() OVER() AS RN, T.* from DB2ADMIN.TEST T)`
* ProgreSQL采集t_test表: `SELECT * FROM (SELECT row_number() over() AS RN, * FROM t_test) T`
* SQLServer: 不支持
5.	配置完毕后点击下一步，进行最后检查
+
image::images/agent-database-step3.png[]
6.	检查无误后，点击下一步，完成数据库数据源的添加。
==== Beats
从1.8.20.0开始，日志易支持beats的Lumberjack协议数据的采集.
一条典型的beats Lumberjack日志内容如下：
[source,javascript]
{"@metadata":{"beat":"filebeat","type":"log"},"beat":{"hostname":"tyrion-macbook","name":"tyrion-macbook","version":"5.3.2"},"fields":{"appname":"app1"},"input_type":"log","message":"acd","offset":44,"source":"/tmp/test.log","tags":["service-X","web-tier"],"@timestamp":"2017-05-02T09:37:36.849Z","type":"log"}
其中：
* 日志原文中的source将作为日志易的source发送
* 日志原文中的hostname将作为日志易的hostname发送
* 日志原文中的["fields"]["appname"]将作为日志易的appname发送 ,需要额外配置yml中的fields配置项，如:
[source,yaml]
fields:
    appname: app1
* 日志原文中的["tags"]将用,连结后，作为日志易的tag发送 ,需额外配置yml中的tags,如:
tags: ["service-X", "web-tier"]
* 日志原文中的@timestamp将被替换为timestamp发送
[NOTE]
====
beats从1.0.1版本开始用的就是Lumberjack v2，因此目前只支持Lumberjack v2协议)
====
1.	点击添加页面的Beats标签，进入添加Beats数据源流程，输入想要监听的地址，并配置该监听地址的appname与tag两个基本信息。
+
image::images/agent-beats-input.png[]
2.	配置好三项参数后，在均不为空且监听地址符合格式要求（注意，端口前的标示冒号需为英文格式下输入的）的条件下，点击“下一步”，即可成功进入最后检查页面：若不符合格式要求并有未填项，则会跳出提醒直到输入内容符合格式要求才可进入下一步。
+
image::images/agent-beats-step2.png[]
3.	检查各个配置项无误后，点击下一步，完成该Beats监听数据源的添加配置操作。
==== Packetbeat
考虑到Packetbeat的主要功能为网络嗅探抓包和协议分析，区别于标准beats的接入方案，Packetbeat属于一种特殊的数据分析场景，因此将其作为单独的一类数据分析agent。
1.	点击添加数据页面的Packetbeat标签，进入添加数据源流程
2.	配置对应的appname，tag以及过滤规则
3.	“嗅探网口”在linux下默认为any，表示采集所有网口，若是windows下则必须详细指定某网口；
4.	“嗅探类型”提供默认的pcap，linux下还有两个选择：af_packet和pf_ring
5.	若有关注的协议需要采集，则在下面根据提示配置对应的端口
+
image::images/agent-packetbeat-input.png[]
6.	确定无误后，点击下一步，进入最后检查页面
7.	检查各个配置项无误后，点击下一步，完成该数据源的添加配置操作
[NOTE]
====
* 该功能从heka 1.8.22.0版本后提供
* linux-386版本不支持该功能（因为packetbeat本身不兼容较旧版本的linux)
* windows版本需要用户在windows上下载安装WinPcap
* 由于前台升级只会升级hekad和hekad-daemon，如果是从1.8.22.0之前版本升级想要使用该功能，需要额外上传安装包bin目录下的packetbeat到对应服务器的heka安装目录的bin子目录下，并确保 Packetbeat所依赖的的libcap库已安装好。
====
==== S3协议的云存储数据采集
Heka提供S3Input采集各种兼容S3协议且支持 key 和 secret_key 认证方式的云存储文件。目前已知的兼容云产品有：华为私有云、腾讯云、minIO 等。
配置流程如下：
1.	进入Agent添加数据界面，选择S3数据源：
2.	填写S3对象相关信息，点击下一步预览匹配上的S3对象。
+
image::images/agent-s3-config.png[]
+
配置项解释如下：
+
* 访问秘钥ID(Access Key ID)和秘密访问秘钥(Secret Access Key)：访问S3/OBS/minIO等的必要配置，请按实际填写；
* AWS区域：请按实际选择或填写，如果是华为私有云、minio 则留空；
* Endpoint：请按实际填写，上图为腾讯云示例，minio 示例为：`http://192.168.1.141:9005/`。
* 桶：仅填写bucket，不要错误将key或bucket_prefix填入；
* 对象路径白名单：填写bucket前缀，例如： "web/AWSLogs/308669983068/elasticloadbalancing/cn-north-1/"，支持正则。
+
3.	选择某个匹配上的S3对象
+
image::images/agent-s3-step2.png[]
+
4.	在分行预览页面可以配置多行合并规则，以及预览分行结果
+
image::images/agent-s3-step3.png[]
5.	点击下一步完成S3数据源的配置。
采集的日志将以S3上完整路径作为source上报，如:
 cgtn-elb-log/web/AWSLogs/308669983068/elasticloadbalancing/cn-north-1/2017/05/01/308669983068_elasticloadbalancing_cn-north-1_app.cctvnews-prod-web.267e1d0de3ddc214_20170501T0030Z_52.80.0.156_2nuhlv3y.log.gz
==== NTP
1. 选择数据来源类型NTP。
+
image::images/agent-config-ntp-1.png[]
2. 填写appname和tag，NTP服务器IP和端口，同步间隔（默认60s），hostname，启用此配置（默认禁用）。
+
image::images/agent-config-ntp-2.png[]
3. 检查配置无误后，点击"完成"。
=== 单一数据源采集配置的批量下发
在某台主机的Agent上完成单一数据源采集配置流程后，如果同类型主机还有多台，并不需要重复数据源配置流程。日志易提供了单一配置的批量下发功能。
在第一次配置添加流程后立即进行批量下发的操作流程如下：
1.	当添加完成时，可点击"批量配置该数据源"，将该数据源配置添加到其他Agent：
+
image::images/agent-config-single-at-end.png[]
2.	在弹出框中，勾选待配置的其他 Agent:
+
image::images/agent-config-single-send.png[]
3.	点击"确认分发"，将看到各个Agent的下发结果。如果下发失败，会返回具体的失败原因：
+
image::images/agent-config-single-error.png[]
历史上已经存在的采集配置，则可以通过配置列表页上的操作入口进行分发:
image::images/agent-config-dist.png[]
分发弹层上，可以通过多选标签来快速过滤不同标签下的 agent 列表。