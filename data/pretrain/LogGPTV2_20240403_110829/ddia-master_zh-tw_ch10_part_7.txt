参与连线的较大输入的每个档案块各有一个 Mapper（在 [图 10-2](../img/fig10-2.png) 的例子中活动事件是较大的输入）。每个 Mapper 都会将较小输入整个载入到记忆体中。
这种简单有效的演算法被称为 **广播杂凑连线（broadcast hash join）**：**广播** 一词反映了这样一个事实，每个连线较大输入端分割槽的 Mapper 都会将较小输入端资料集整个读入记忆体中（所以较小输入实际上 “广播” 到较大资料的所有分割槽上），**杂凑** 一词反映了它使用一个散列表。Pig（名为 “**复制连结（replicated join）**”），Hive（“**MapJoin**”），Cascading 和 Crunch 支援这种连线。它也被诸如 Impala 的资料仓库查询引擎使用【41】。
除了将较小的连线输入载入到记忆体散列表中，另一种方法是将较小输入储存在本地磁碟上的只读索引中【42】。索引中经常使用的部分将保留在作业系统的页面快取中，因而这种方法可以提供与记忆体散列表几乎一样快的随机查询效能，但实际上并不需要资料集能放入记忆体中。
#### 分割槽杂凑连线
如果 Map 侧连线的输入以相同的方式进行分割槽，则杂凑连线方法可以独立应用于每个分割槽。在 [图 10-2](../img/fig10-2.png) 的情况中，你可以根据使用者 ID 的最后一位十进位制数字来对活动事件和使用者资料库进行分割槽（因此连线两侧各有 10 个分割槽）。例如，Mapper3 首先将所有具有以 3 结尾的 ID 的使用者载入到散列表中，然后扫描 ID 为 3 的每个使用者的所有活动事件。
如果分割槽正确无误，可以确定的是，所有你可能需要连线的记录都落在同一个编号的分割槽中。因此每个 Mapper 只需要从输入两端各读取一个分割槽就足够了。好处是每个 Mapper 都可以在记忆体散列表中少放点资料。
这种方法只有当连线两端输入有相同的分割槽数，且两侧的记录都是使用相同的键与相同的杂凑函式做分割槽时才适用。如果输入是由之前执行过这种分组的 MapReduce 作业生成的，那么这可能是一个合理的假设。
分割槽杂凑连线在 Hive 中称为 **Map 侧桶连线（bucketed map joins）【37】**。
#### Map侧合并连线
如果输入资料集不仅以相同的方式进行分割槽，而且还基于相同的键进行 **排序**，则可适用另一种 Map 侧连线的变体。在这种情况下，输入是否小到能放入记忆体并不重要，因为这时候 Mapper 同样可以执行归并操作（通常由 Reducer 执行）的归并操作：按键递增的顺序依次读取两个输入档案，将具有相同键的记录配对。
如果能进行 Map 侧合并连线，这通常意味著前一个 MapReduce 作业可能一开始就已经把输入资料做了分割槽并进行了排序。原则上这个连线就可以在前一个作业的 Reduce 阶段进行。但使用独立的仅 Map 作业有时也是合适的，例如，分好区且排好序的中间资料集可能还会用于其他目的。
#### MapReduce工作流与Map侧连线
当下游作业使用 MapReduce 连线的输出时，选择 Map 侧连线或 Reduce 侧连线会影响输出的结构。Reduce 侧连线的输出是按照 **连线键** 进行分割槽和排序的，而 Map 端连线的输出则按照与较大输入相同的方式进行分割槽和排序（因为无论是使用分割槽连线还是广播连线，连线较大输入端的每个档案块都会启动一个 Map 任务）。
如前所述，Map 侧连线也对输入资料集的大小，有序性和分割槽方式做出了更多假设。在最佳化连线策略时，了解分散式档案系统中资料集的物理布局变得非常重要：仅仅知道编码格式和资料储存目录的名称是不够的；你还必须知道资料是按哪些键做的分割槽和排序，以及分割槽的数量。
在 Hadoop 生态系统中，这种关于资料集分割槽的元资料通常在 HCatalog 和 Hive Metastore 中维护【37】。
### 批处理工作流的输出
我们已经说了很多用于实现 MapReduce 工作流的演算法，但却忽略了一个重要的问题：这些处理完成之后的最终结果是什么？我们最开始为什么要跑这些作业？
在资料库查询的场景中，我们将事务处理（OLTP）与分析两种目的区分开来（请参阅 “[事务处理还是分析？](ch3.md#事务处理还是分析？)”）。我们看到，OLTP 查询通常根据键查询少量记录，使用索引，并将其呈现给使用者（比如在网页上）。另一方面，分析查询通常会扫描大量记录，执行分组与聚合，输出通常有著报告的形式：显示某个指标随时间变化的图表，或按照某种排位取前 10 项，或将一些数字细化为子类。这种报告的消费者通常是需要做出商业决策的分析师或经理。
批处理放哪里合适？它不属于事务处理，也不是分析。它和分析比较接近，因为批处理通常会扫过输入资料集的绝大部分。然而 MapReduce 作业工作流与用于分析目的的 SQL 查询是不同的（请参阅 “[Hadoop 与分散式资料库的对比](#Hadoop与分散式资料库的对比)”）。批处理过程的输出通常不是报表，而是一些其他型别的结构。
#### 建立搜寻索引
Google 最初使用 MapReduce 是为其搜寻引擎建立索引，其实现为由 5 到 10 个 MapReduce 作业组成的工作流【1】。虽然 Google 后来也不仅仅是为这个目的而使用 MapReduce 【43】，但如果从构建搜寻索引的角度来看，更能帮助理解 MapReduce。（直至今日，Hadoop MapReduce 仍然是为 Lucene/Solr 构建索引的好方法【44】）
我们在 “[全文搜寻和模糊索引](ch3.md#全文搜寻和模糊索引)” 中简要地了解了 Lucene 这样的全文搜寻索引是如何工作的：它是一个档案（关键词字典），你可以在其中高效地查询特定关键字，并找到包含该关键字的所有文件 ID 列表（文章列表）。这是一种非常简化的看法 —— 实际上，搜寻索引需要各种额外资料，以便根据相关性对搜寻结果进行排名、纠正拼写错误、解析同义词等等 —— 但这个原则是成立的。
如果需要对一组固定文件执行全文搜寻，则批处理是一种构建索引的高效方法：Mapper 根据需要对文件集合进行分割槽，每个 Reducer 构建该分割槽的索引，并将索引档案写入分散式档案系统。构建这样的文件分割槽索引（请参阅 “[分割槽与次级索引](ch6.md#分割槽与次级索引)”）并行处理效果拔群。
由于按关键字查询搜寻索引是只读操作，因而这些索引档案一旦建立就是不可变的。
如果索引的文件集合发生更改，一种选择是定期重跑整个索引工作流，并在完成后用新的索引档案批次替换以前的索引档案。如果只有少量的文件发生了变化，这种方法的计算成本可能会很高。但它的优点是索引过程很容易理解：文件进，索引出。
另一个选择是，可以增量建立索引。如 [第三章](ch3.md) 中讨论的，如果要在索引中新增，删除或更新文件，Lucene 会写新的段档案，并在后台非同步合并压缩段档案。我们将在 [第十一章](ch11.md) 中看到更多这种增量处理。
#### 键值储存作为批处理输出
搜寻索引只是批处理工作流可能输出的一个例子。批处理的另一个常见用途是构建机器学习系统，例如分类器（比如垃圾邮件过滤器，异常检测，影象识别）与推荐系统（例如，你可能认识的人，你可能感兴趣的产品或相关的搜寻【29】）。
这些批处理作业的输出通常是某种资料库：例如，可以透过给定使用者 ID 查询该使用者推荐好友的资料库，或者可以透过产品 ID 查询相关产品的资料库【45】。
这些资料库需要被处理使用者请求的 Web 应用所查询，而它们通常是独立于 Hadoop 基础设施的。那么批处理过程的输出如何回到 Web 应用可以查询的资料库中呢？