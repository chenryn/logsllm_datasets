title:Cryptographic strength of ssl/tls servers: current and recent practices
author:Homin K. Lee and
Tal Malkin and
Erich M. Nahum
Cryptographic Strength of SSL/TLS Servers:
Current and Recent Practices
Homin K. Lee
Department of Computer
Science
Columbia University
New York, NY
Tal Malkin ∗
Department of Computer
Science
Columbia University
New York, NY
Erich Nahum
Network Server System
Software Dept.
IBM T.J. Watson Research Ctr.
Hawthorne, NY
PI:EMAIL
PI:EMAIL
PI:EMAIL
ABSTRACT
The Secure Socket Layer (SSL) and its variant, Transport
Layer Security (TLS), are used toward ensuring server se-
curity.
In this paper, we characterize the cryptographic
strength of public servers running SSL/TLS. We present a
tool developed for this purpose, the Probing SSL Security
Tool (PSST), and evaluate over 19,000 servers. We expose
the great diversity in the levels of cryptographic strength
that is supported on the Internet. Some of our discourag-
ing results show that most sites still support the insecure
SSL 2.0, weak export-level grades of encryption ciphers, or
weak RSA key strengths. We also observe encouraging be-
havior such as sensible default choices by servers when pre-
sented with multiple options, the quick adoption of AES
(more than half the servers support strong key AES as their
default choice), and the use of strong RSA key sizes of 1024
bits and above. Comparing results of running our tool over
the last two years points to a positive trend that is moving
in the right direction, though perhaps not as quickly as it
should.
Categories and Subject Descriptors
C.2.0 [Computer-Communication Networks]: General—
Security and protection; C.2.2 [Computer-Communication
Networks]: Network Protocols
General Terms
Measurement, Security
Keywords
SSL, Network Security, Servers
∗
This research was supported in part by the New York Soft-
ware Industry Association under grant NYS-CU0232901.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
IMC’07, October 24-26, 2007, San Diego, California, USA.
Copyright 2007 ACM 978-1-59593-908-1/07/0010 ...$5.00.
1.
INTRODUCTION
Cryptography is an essential component of modern elec-
tronic commerce. With the explosion of transactions being
conducted over the Internet, ensuring the security of data
transfer is critically important. Considerable amounts of
money are being exchanged over the network, either through
e-commerce sites (e.g., Amazon, Buy.com), auction sites
(e.g., eBay), on-line banking (e.g., Citibank, Chase), stock
trading (e.g., Schwab), and even government (e.g., irs.gov).
Communication with these sites is secured by the Secure
Sockets Layer (SSL) or its variant, Transport Layer Security
(TLS), which are used to provide authentication, privacy,
and integrity. A key component of the security of SSL/TLS
is the cryptographic strength of the underlying algorithms
used by the protocol. It is crucial to ensure that servers using
the SSL protocol have employed it properly. For example, it
should be determined whether site administrators are using
the best practices, are aware of their sites’ vulnerabilities if
they haven’t already been addressed, and are promptly re-
acting to CERT advisories. Poor use of cryptography may
be an indicator of poorly-administered security. Experience
in related areas of patch management and virus/worm prop-
agation is not encouraging. The recent interest in SSL-based
VPNs only increases the need to study SSL.
One key feature of SSL/TLS is that it allows negotiation
between two peers. Diﬀerent implementations will not nec-
essarily support the same cryptographic algorithms. Thus
SSL allows two peers to determine a subset of common cryp-
tographic routines. This allows for the interoperability and
extensibility of the protocol. For example, SSL allows dif-
ferent algorithms to be used for authentication (e.g., RSA,
DSS), key exchange (RSA, EDH), encryption (RC2, RC4,
DES, 3-DES, AES), and integrity (MD5, SHA-1). This ﬂex-
ibility allows for new, stronger algorithms to be added over
time (such as AES) and reduces dependence on any one al-
gorithm, in case that algorithm is broken or succumbs to
brute-force exhaustive search techniques (as with DES).
While this ﬂexibility improves interoperability, it may also
compromise security. For example, server administrators
may wish to support as wide a range of protocols as possible
in order to maximize the number of clients that can access
a site. However, they may be lax in removing features that
have compromises in security. For example, if a site sup-
ports a weak form of encryption, a client may choose to use
that algorithm for performance or power consumption rea-
sons (e.g., on a wireless PDA), without recognizing the dan-
gers. This could lead to a session being broken, a customer’s
password being cracked, and an empty bank account. While
this could be considered simply a case of clients suﬀering the
consequences of their actions, there are reasons to prevent
this from happening. This type of experience could alien-
ate a customer, damage the reputation of a business, and
perhaps even lead to legal action. More importantly, ex-
perience shows that clients do not understand security, and
thus steps should be taken to minimize opportunities for
clients to make the wrong decision. For these reasons, we
believe the bulk of the burden for ensuring security falls on
the provider, or server in this case. This then raises the ques-
tion: do servers deployed in the Internet adhere to current
best practices by employing strong cryptography?
This paper characterizes the cryptographic strength of
public servers in the Internet running SSL/TLS. We eval-
uate over 19,000 servers, and present a tool developed for
this purpose, the Probing SSL Security Tool (PSST). We
use PSST to evaluate which protocols and cryptographic
options are supported by the servers, and which are chosen
by the servers as a default when presented with several op-
tions. We show that a great variety of behavior can be found
in the network, with both encouraging and discouraging re-
sults. Examples include:
• 85 percent of SSL sites support the SSL 2.0 protocol,
even though it has signiﬁcant security problems. More-
over, a small number of sites support only the SSL2
protocol.
• 93 percent of servers support (single) DES, despite the
fact that DES is considered susceptible to exhaustive
search.
• Many servers support the old export-grade encryption
levels, even though US law has changed and these al-
gorithms are considered susceptible to brute-force at-
tacks.
• 765 (almost 4 percent) of the sites use RSA-based au-
thentication with only 512-bit keys, even though RSA
has announced that this level of security is insuﬃcient.
On the other hand, over 1200 sites use 2048 bits or
greater.
• AES is already supported in over 57 percent of sites we
probed. Out of these, about 94 percent default to AES
when presented with all options (and the vast majority
of them use a strong 256 bit key).
We have also run our tool periodically over the last two
years, in order to study the evolution of SSL use (and mis-
use) over time. The overall trend we discovered is a steady,
though a little slow, improvement in cryptographic strength
of SSL/TLS servers. For example, within the past two years:
• Support of the weak SSL2 protocol has been reduced
by over 9 percentage points.
• Support of AES has grown by nearly 16 percentage
points.
• Support of weak public key sizes has gone down by
nearly 2 percentage points.
• Support of very strong public key sizes has gone up by
nearly 2 percentage points.
Thus, our results show that most servers (though not all)
support both weak cryptography and strong cryptography,
while making the correct choice by default, if given the op-
tion. This is in sharp contrast to the situation several years
ago, where 20-30 percent of the servers used only weak cryp-
tography (see [27] and our discussion in Section 5). As a
concrete example, in 2000 25 percent of servers probed by
Murray [27] supported a very weak server key size of at most
512 bits, compared to about 4 percent today.
Our results are also useful in highlighting the most preva-
lent supported choices among the available options, thereby
allowing future eﬀorts on improving performance and en-
hancing security to focus on the most relevant set of cryp-
tographic algorithms.
Finally, our tool can be useful for regular security com-
pliance testing, especially by large organizations that own
multiple servers.
Organization.
The remainder of this paper is organized as follows.
In
Section 2, we provide some background on the design and
history of SSL/TLS. In Section 3 we describe the design
of our PSST tool and our probing methodology. Section 4
presents our results in detail, and Section 5 discusses rele-
vant related work. Finally, we conclude and describe some
possibilities for future work in Section 6.
2. SSL AND TLS
In this section we provide a brief overview of the mecha-
nisms and history of SSL/TLS.
SSL is designed to facilitate a communication channel be-
tween two peers, providing mechanisms for secure key ex-
change, authentication, encryption, and integrity.
It aims
to be resilient to man-in-the-middle attacks, eavesdropping,
replay attacks, and statistical attacks. While SSL can au-
thenticate two sides of the conversation, in practice it is typ-
ically only the server that authenticates itself. The goals for
SSL/TLS not only include security, but also interoperability,
extensibility, and relative eﬃciency.
SSL/TLS is composed of two layers: the record layer and
the handshake layer. The record layer takes data provided
by a higher-layer application, fragments the data into man-
ageable blocks, and performs compression, symmetric-key
encryption, and MAC digest generation. The handshake
layer performs session establishment and option negotiation,
determining the per-session symmetric keys which are used
in bulk by the record layer.
SSL/TLS runs “above” the Transmission Control Proto-
col/Internet Protocol (TCP/IP), which governs the trans-
port and routing of data over the Internet, and “below”
higher-level protocols such as the Hypertext Transport Pro-
tocol (HTTP), which use TCP/IP to support typical appli-
cation tasks such as downloading Web pages. SSL lets an
SSL-enabled server to authenticate itself to an SSL-enabled
client and vice-versa, and allows both machines to establish
an encrypted connection. All the while, SSL uses TCP/IP
on behalf of the higher-level protocols.
SSL version 2.0 [22] was introduced by Netscape in 1994
for transmitting private data through the Internet (the ﬁrst
version of SSL was never deployed). SSL version 2.0 quickly
became the de facto standard for the cryptographic pro-
tection of Web traﬃc. Unfortunately, SSL 2.0 was quickly
shown to have several ﬂaws [44]:
• SSL 2.0 is vulnerable to “man-in-the-middle” attacks
in which an active attacker can force both the client
and the server to use 40-bit encryption.
• SSL 2.0 exclusively uses the MD5 hash function (the
insecurity of which will be discussed in Section 4.4).
• SSL 2.0 uses a weak message authentication code (MAC).
• SSL 2.0 feeds padding bytes into the MAC in block
cipher modes while leaving the padding-length ﬁeld
unauthenticated. This could allow active attackers to
delete bytes from the end of messages.
• SSL 2.0 uses the same key for authentication and en-
cryption, which could lead to problems for certain ci-
phers.
SSL version 3.0 [20] was introduced in 1996, to improve
both the security and the functionality of SSL 2.0. SSL
3.0 not only ﬁxes the security ﬂaws mentioned above, but
also reduces the number of network round-trips, lets the
server choose the ciphers, supports more complete key ex-
change and cipher algorithms, and uses separate authentica-
tion and encryption keys. Around the same time, Microsoft
introduced its own version of SSL, Privacy Communication
Technology (PCT), but this never gained as much popular-
ity as SSL 3.0.
The Internet Engineering Task Force (IETF) established
the Transport Layer Security (TLS) Working Group in 1996
to come up with a standardized version of SSL and PCT.
The standardized protocol [14], imaginatively named TLS
version 1.0, is very similar to SSL 3.0. So much so that TLS
1.0 is sometimes referred to as SSL 3.1. The most impor-
tant diﬀerence between the two is that TLS uses the keyed-
Hashing for Message Authentication Code (HMAC) algo-
rithm [8] instead of the SSL Message Authentication Code
(MAC) algorithm; HMAC produces more secure hashes than
MAC. There are other minor diﬀerences such as the exclu-
sion of the Fortezza algorithms (which are not open for pub-
lic review), and the allowance of certiﬁcates to go back to an
intermediary certiﬁcate authority (CA) instead of going all
the way back to the root CA. Because of these improve-
ments, the TLS and SSL 3.0 protocols don’t fully inter-
operate, but TLS 1.0 has a mode to fall back to SSL 3.0.
Many Web sites now use SSL to obtain conﬁdential user
information, such as credit card numbers and social secu-
rity numbers. All major Web browsers (Mozilla Firefox,
Netscape Navigator, Internet Explorer, Safari, and Opera)
support SSL. SSL 3.0 and TLS are believed to be reason-
ably secure if used properly. SSL 2.0 has fundamental design
problems and should not be used for sensitive information.
3. METHODOLOGY
PSST is based on httperf [26], a tool for measuring Web
server performance, and utilizes the OpenSSL library [4] for
SSL support. httperf normally establishes an SSL con-
nection advertising the entire available suite of protocols
from the SSL library, allowing the server to choose which
suite to use. We modiﬁed httperf’s core HTTP engine to
make an SSL connection with the target server advertising
only one cipher suite. If the server supports that suite, the
SSL handshake is completed successfully; otherwise, an er-
ror code is returned. By connecting to the server multiple
times and iterating through the set of available suites, we
can determine which suites are supported and which ones
are not. Each connection is aborted immediately after the
initial SSL handshake, reducing overhead on the network,
the SSL server probed, and the PSST client machine itself.
We also included an option where all possible protocols and
cipher suites were presented so that what choice the server
defaults to could be observed.
To maximize our statistical conﬁdence, we clearly wished
to probe as many SSL servers as possible. In gathering our
list of SSL/TLS servers, we aimed to gather as many ad-
dresses as possible while making sure that the largest and
most popular sites were included as well. Since a few Web
sites attract a signiﬁcant portion of all the Web traﬃc, we
used the rating sites Alexa [1] and Web100 [5] to gather a
list of leading SSL/TLS servers. For breadth we used the
list of target Web servers in Padhye and Floyd’s study of
TCP behavior [34], which in turn came from IRCache, the