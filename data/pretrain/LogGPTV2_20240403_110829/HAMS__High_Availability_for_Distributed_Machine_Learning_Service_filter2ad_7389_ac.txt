buffering is a major source of overhead to primary-backup
systems, and the overhead will increase with the replicated
application’s memory footprint.
NSPB enables a stateful model’s primary to release outputs
without waiting for its states to be durable. However, NSPB
must maintain global consistency. A strawman approach is to
buffer each reply to its client only before the reply leaves the
service graph, until all states affected by this reply are durable.
This approach works for deterministic services [36], but will
cause inconsistency in the presence of non-determinism.
Figure 6 shows an example of the inconsistency caused
by the strawman approach: model A (Ma) and model B
(Mb) are two stateful models, and models between A and
B are stateless. The inconsistency can be triggered with ﬁve
steps. First, Ma’s primary processes request rn
a , generates
its output on
a. Second, Ma releases its output
to downstream models and asynchronously sends sn
a to its
a and state sn
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:27:08 UTC from IEEE Xplore.  Restrictions apply. 
188
Fig. 6: Inconsistency caused by the strawman approach.
a
backup. Due to network anomaly, the delivery of sn
a is delayed.
Third, on
a is processed by stateless models between Ma and
Mb and is transformed as rn
b that is processed by Mb. Forth,
Mb ﬁnishes processing rn
b and successfully delivers the state
sn
b to its backup. Fifth, Ma’s primary fails and its backup
takes over as a new primary. As Ma’s new primary still
holds state sn−1
, the new primary needs to re-execute rn
a
(for now, assume HAMS already replicates input requests).
However, as the re-computation is non-deterministic, Ma’s
backup may enter a different state sn(cid:2)
a and generate a different
on(cid:2)
a , causing inconsistency (with the same consequence as
Figure 2). Existing stream processing systems tackle this
problem with a globally coordinated rollback [18], where
all stateful models invoke rollbacks to the latest globally
checkpointed state. However, such an approach causes a long
recovery time [85] due to the expensive globally coordinated
rollback, and a high normal case overhead because a reply can
only be released to a client after a global checkpoint ﬁnishes.
To address this problem, we observe that the inconsistency
is
causal
dependencies of sn
a, and global consistency can
be maintained if HAMS can ensure the following statement:
sn
b always becomes durable after all states that sn
b depends
on (i.e., sn
a) are durable. This can be achieved if we hold the
state of sn
b on Mb’s backup until sn
the
b on sn
a is durable.
triggered
because
failover
breaks
If the primary of Ma fails, HAMS promotes both Ma’s
and Mb’s backups as their new primaries, and now the new
primary of Ma is in state sn−1
and the new primary of Mb is
in state sn−1
, with all their causal dependencies maintained.
HAMS simply lets predecessor models of Ma resend its nth
output and lets the new primary of Ma and Mb re-process their
nth request. In a sense, HAMS regards each stateful model’s
execution as speculation before its state is durable, and HAMS
can safely discard the speculative states on a failover.
the
a
b
b
b
One concern of
this approach is how HAMS handles
correlated failures if Ma’s primary and Mb’s backup fail
simultaneously. HAMS handles this issue by letting Mb’s
primary free its buffer for the state sn−1
only after Mb’s
backup applies sn
(i.e., sn
becomes
b
b
outdated). Therefore, if such a correlated failure happens, Mb’s
primary can rollback to sn−1
by loading this state from its
(CPU) memory buffer to GPU.
is durable and sn−1
Note that HAMS retrieves a stateful model’s complete state
(e.g., all parameters for an online learned model or all cell
states for an RNN) rather than state updates like Remus, so a
rollback can be achieved as a simple state overwriting. If Mb’s
backup does not fail, however, HAMS ﬁrst tries to promote
Mb’s backup as the new primary instead of to rollback its
primary for fast failover, as rolling back the primary is slow
b
State #n-1
State #n
State being updated
Output release
Execution finish
Execution timeline
stateful model A’s primary
Computation
for req #n ((cid:2200)(cid:2183)(cid:2196)) Update
(cid:2201)(cid:2183)(cid:2196)(cid:2879)(cid:2778)
for req #n 
1
stateful model A’s backup
stateful model B’s primary
stateful model B’s backup
4
2
Slow
Computation
for req #n+1 ((cid:2200)(cid:2183)(cid:2196)(cid:2878)(cid:2778))
(cid:2201)(cid:2183)(cid:2196)
Output for req #n ((cid:2197)(cid:2183)(cid:2196))
for req #n ((cid:2200)(cid:2184)(cid:2196))
(cid:2201)(cid:2184)(cid:2196)(cid:2879)(cid:2778)
Update
for req #n 
Computation
3
5
notify
Update
for req #n+1 
(cid:2201)(cid:2183)(cid:2196)
for req #n+1 ((cid:2200)(cid:2184)(cid:2196)(cid:2878)(cid:2778))
(cid:2201)(cid:2184)(cid:2196)
(cid:2201)(cid:2184)(cid:2196)
Output for req #n ((cid:2197)(cid:2184)(cid:2196))
Computation 
buffered
4
6
apply
Update
for req #n+1 
Fig. 7: HAMS’s NSPB protocol in the simpliﬁed setting.
Algorithm 1: Each proxy records requests’ lineage
1 my_seq ← counter of request sequence for the model
2 upon receiving req from pred_model with pred_seq
3
req.lineage.append
(cid:3)pred_model, pred_seq, my_model, ++my_seq(cid:4)
batch.atomic append(req)
4
5 upon receiving outputs for reqs from the model
6
7
for i in range(reqs.size()) do
outputs[i].lineage = reqs[i].lineage
because it involves stopping its current GPU computation and
copying the sn−1
from CPU memory to GPU, while the
backup already has sn−1
loaded on GPU and can takeover
immediately in HAMS (§VI-D).
b
b
a to downstream; (2) Ma’s primary sends sn
Figure 7 illustrates NSPB in this simpliﬁed setting in six
steps: (1) Ma’s primary ﬁnishes processing rn
a and sends
output on
a to
its backup, which may be slow; (3) Mb’s primary ﬁnishes
executing request rn
b and releases output; (4) Mb’s primary
sends sn
b to its backup, and the backup put this state into a
memory buffer; (5) Ma’s backup notiﬁes Mb’s backup that sn
a
is durable; (6) Mb’s backup applies state sn
b .
D. NSPB for Complete Service Graphs with Batching
In HAMS, a stateful model’s state is denoted as a three-tuple
(cid:3)reqs, tensors, outputs(cid:4) and HAMS replicates the state
after the model processes each batch of requests. reqs
contains the requests’ lineage information (explained in next
paragraph) in this batch. tensors are the internal state
of the stateful model, such as the value of the memory
cells in a LSTM or parameter values for an online-learning
model (§II-B). Outputs are the outputs from the model
after processing this batch of requests. As a stateful model
cannot re-execute its computation, HAMS saves this output
in the memory to handle a downstream model failure. A
saved output can be garbage-collected asynchronously when
the client request of this output leaves the service graph.
For a general DAG with batching, we need to make two
additional adaptations from the simpliﬁed protocol described
in the previous subsection. First, to track causal dependencies
for states in a general DAG, HAMS proxies need to maintain
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:27:08 UTC from IEEE Xplore.  Restrictions apply. 
189
Algorithm 2: A HAMS backup’s algorithm
1 PFM[] ← Previous stateFul Models (see §IV-A)
2 NFM[] ← Next stateFul Models (see §IV-A)
3 durable_seqs ← a map for durable seq of each PFM
4 upon receiving(cid:3)reqs,tensors,outputs(cid:4) from primary
for r in reqs do
if r.lineage has m in PFM then
m_seq = r.lineage.get(m)
wait(durable_seqs[m] ≤ m_seq)
5
6
7
8
9
10
12
for nm in NFM do
send (nm, (cid:3)notify, my_id, reqs.last.out_seq(cid:4))
11 upon receiving(cid:3)notify, prev_model, seq(cid:4)
set (durable_seqs[prev_model] =seq)
succ, it records the mapping between oi
lineage information of each client request in the DAG, as
shown in Algorithm 1. Speciﬁcally, when a successor mode
Msucc receives a predecessor Mpred’s ith output oi
pred as
Msucc’s jth input rj
pred
and rj
succ (Line 4). This mapping was trivial in a chain as i
always equals to j, but the mapping is essential in a general
DAG with sequence interleaving (e.g., Figure 1). When Msucc
releases an output for a processed request,
it also carries
the request’s lineage information with the output (Line 7).
In essence, for a request in the service graph that has been
processed by a series of models, the request’s lineage records
the requests sequence number at each model processing it.
Second, in the simpliﬁed chain, a stateful model only has
one Previous statFul Model (PFM, see §IV-A for deﬁnition); in
a general DAG, however, a stateful model has multiple PFMs.
Therefore, when the backup of this stateful model wants to
apply the state generated for a batch of requests, it needs
to ensure that, all states generated by these requests in all
its PFMs are durable (Line 4-8 in Algorithm 2). After the
backup applies this state, it notiﬁes all its next stateful models.
Although this mechanism needs a downstream model to wait
multiple upstream models’ states being durable, it does not
introduce overhead in the normal case, as the of upstream
models’s state propagation are in parallel with downstreams’
computation. This waiting is to ensure correctness and is
only triggered during network anomalies: an upstream’s state
propagation is so slow that
it cannot ﬁnish even after a
downstream model ﬁnishes both execution and propagation.
To ensure global consistency to a client, HAMS’s frontend
needs to buffer an output to the client until all stateful models’
states generated by this request are durable. Effectively, the
frontend can be regarded as a special model, whose state
durable action is sending service outputs to clients.
E. Recovery Protocol for General Service Graphs
If an upstream proxy incurs an RPC timeout when trying to
send its output to a downstream proxy, the upstream proxy
suspects the downstream proxy to have failed and reports
the suspected failure to HAMS’s manager (§III-A). We ﬁrst
explain HAMS’s recovery protocol for single-host failures.
If a stateless model (say Ml) is suspected to fail by its
predecessors, HAMS takes a hot standby (§V) of the model
(M(cid:2)
l ) and reconstructs its dataﬂow. HAMS ﬁrst contacts all
190
Ml’s successors’ proxies to collect the lineage information of
requests received from Ml. From this information, HAMS can
achieve two important information: the max sequence number
(max_out) of the original Ml’s output, and the max sequence
Ml processed for each predecessor model. Then, HAMS sets
the output sequence number of the newly launched M(cid:2)
to
max_out, and lets each predecessor model resend outputs to
M(cid:2)
l
l from their max sequence.
(Mf )
If a stateful model
is suspected to fail by its
predecessors, HAMS ﬁrst contacts its backup to get the max
output sequence (max_seq). Then, HAMS checks the primary
of all downstream models in parallel to get a list of stateful
models that have processed requests whose lineage shows a
larger sequence than max_seq from Mf (§IV-C). For Mf and
models in the list, HAMS promote their backup and lets the
predecessors start to resend requests according to the lineage
information. Note that HAMS retrieves the full internal state of
a stateful model (§IV-B) but not state updates. Therefore, when
a backup is promoted as the new primary, the old primary can