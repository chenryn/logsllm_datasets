0.96 ± 0.01
0.95 ± 0.02
0.98 ± 0
TABLE VIII.
FARE VS. BASELINES IN TWO UNION CLASSES SETTING.
Dataset
Metric
FARE
MixMatch+
Ladder+
DNN+
AMI
MALWARE (N = 6)
K
0.74 ± 0
6 ± 0
0.48 ± 0.05
4 ± 0
0.64 ± 0.08
4 ± 0
4 ± 0
0.45 ± 0.06
K
AMI
Network Intrusion (N = 9)
7 ± 0.82
0.95 ± 0.01
0.56 ± 0.30
5.33 ± 0.47
0.55 ± 0.28
6.33 ± 0.47
0.59 ± 0.42
4 ± 0
TABLE IX.
DECISION MATRIX FOR LABEL ALIGNMENT.
Prediction Matching Score
Class1 Class2
0.1
Cluster1
0.6
Cluster2
0.95
Cluster3
Cluster4
0.9
0.9
0.4
0.05
0.1
Conf.
0.9
0.6
0.95
0.9
Assignment
(Conf.≥ 0.9)
Class1
New Class
Class2
Class2
APPENDIX-C. AMI VS. ACCURACY.
We use a concrete example to explain the AMI metric
and show its advantage over the accuracy metric. Given a
highly imbalanced dataset of 1000 samples of three classes,
class-1 has 980 samples, class-2 has 18 samples, and class-
3 has 2 samples. Suppose a clustering method (denoted as
Method A.) categorized the samples into 2 clusters with the
contingency table shown in Table VI. Method A. wrongly
categorized all the samples from class 2 and 3 into cluster-1,
and mistakenly assigned 20 samples from class 1 into cluster-
2. Given this contingency table, we can compute the AMI by
using the function API in scikit-learn [11], i.e., −0.003.
The mathematical details about AMI can be found in [74]. We
can also compute the accuracy as 960/1000 = 0.96. Despite
making serious mistakes, Method A still has an extremely high
accuracy. In contrast, AMI is not biased towards the large
class and provides a more reasonable score (i.e., a negative
score). This is because AMI not only considers the clustering
correctness of samples in each class, but more importantly
adjusts the score based on the cluster size.
Next, we use real experiment results to discuss the dif-
ference between AMI and Accuracy. Table VII shows the
accuracy of different algorithms under missing-classes and
coarse-grained labels. We have two observations. First, FARE
is still better than (or at least comparable with) the three
baselines under the accuracy metrics. Second, the accuracy
metric looks high for all the algorithms, especially for the
network intrusion dataset. The reason is that
the network
intrusion dataset has a dominating benign class, and the highly
imbalanced classes lead to misleading accuracy results. For this
reason, we used AMI as the primary metric in the paper.
APPENDIX-D. TIME COMPLEXITY OF FARE.
The computational cost of FARE comes from three aspects.
The ﬁrst part comes from the bases clustering methods. The
base clustering algorithms are independent and thus can be
run in parallel. As such, the computation bottleneck is the
slowest algorithm among DEC (O(IdBd|θd|K) [78], k-means
(O(IkKN p)) [28], and DBSCAN (O(pN 2)) [20]. That is,
max{O(IdBd|θd|K), O(IkKN p), O(pN 2)}, where Id and Bd
represents the number of training iterations, and the batch
size. |θd| is the number of parameters in the DEC model.
IK and K are the number of training iterations and the
number of clusters k-means. N is the total number of sam-
ples, and p is the dimension of the input space. Given that
(a) Malware categorization.
(b) Intrusion detection.
Fig. 6.
setting (i.e., nc = (cid:98)n/2(cid:99)) with different ratios of available labels.
The performance of FARE and baselines under the missing class
IKK << N in most cases, this complexity can be represented
as O(max{IdBd|θd|K, pN 2}). The second part comes from
computing the neighborhood relationship and training the
transformation network. In each iteration, FARE derives the
neighborhood relationship for each base method with a cost
of O((Bi)2), and updates the network parameters with the
cost of O(|θi|). As such, the time complexity of this part is
O(IiM (Bi)2|θi|), where Ii and Bi is the number of training
iteration and batch size, |θi| is the number of parameters of
the transformation network. The third part is introduced by
the ﬁnal k-means clustering. In total, FARE’s computational
complexity is O(max{IdBd|θd|K, pN 2, IiM B2
i |θi|}).
APPENDIX-E. ADDITIONAL EXPERIMENTS.
Multiple Union Classes. We compared FARE with the
amended baselines in a coarse-label setting with two union
classes. Speciﬁcally, we randomly selected 6 classes from the
malware and intrusion dataset and relabeled them into two
union classes. Together with the remain original classes, the
training set has in total n − 4 classes. We still only used
1% of the labels for each class. We ran each method 10
times with different random seeds. As shown in Table VIII,
FARE achieves signiﬁcantly higher AMIs and lower standard
deviations than all the amended baselines on both datasets. In
addition, FARE could identify the true number of classes on
the malware dataset and has lowest estimation errors on the
intrusion dataset. This result demonstrates that FARE could
generalize its effectiveness in multiple union class settings.
Setup w/ both Missing Classes and Coarse-grained Labels.
We tested FARE under a setting with both missing classes
and coarse-grained labels. Speciﬁcally, we randomly selected
4 classes from both datasets, relabeled 2 of them as a union
class, and eliminated the labels of the rest. In this way, we
constructed a training set with n − 3 classes. Similarly, we
preserved 1% labels in each class and ran FARE 10 times.
The results AMI and K are: (0.76 ± 0, 6 ± 0) on the malware
dataset, and (0.92± 0.06, 5.67± 2.36) on the intrusion dataset.
APPENDIX-F. CLASS-CLUSTER ALIGNMENT.
We use an example to explain the strategy of post-
clustering analysis introduced in Section §VI. Suppose we
17
1102560% of Label per Class0.20.30.40.50.60.70.8AMIFAREMixMatch+Ladder+DNN+1102550% of Label per Class0.20.40.60.81.0AMIFAREMixMatch+Ladder+DNN+TABLE X.
MEAN AMIS AND STANDARD DEVIATIONS OBTAINED BY VARYING THE α AND q IN FARE.
Label Condition
# q and α
Malware
Intrusion
8
0.76 ± 0.05
0.89 ± 0.05
nc = (cid:98)n/2(cid:99), 1% labels
32 (Our choice)
16
0.75 ± 0
0.89 ± 0.05
0.78 ± 0.02
0.86 ± 0.02
ng = (cid:98)n/2(cid:99), 1% labels
32 (Our choice)
16
0.74 ± 0
0.90 ± 0.05
0.75 ± 0
0.87 ± 0
64
0.74 ± 0
0.85 ± 0.04
64
0.74 ± 0.06
0.89 ± 0.06
8
0.74 ± 0
0.87 ± 0
Noisty Label Percentage x
25
Dataset
Malware
Network Intrusion
TABLE XI.
AMI
0
0.87 ± 0.01
0.98 ± 0
THE PERFORMANCE OF FARE UNDER DIFFERENT PERCENTAGES OF CORRUPTED LABELS.
10
Accuracy
0.97 ± 0
1 ± 0
AMI
0.83 ± 0.01
0.94 ± 0.03
Accuracy
0.96 ± 0.01
0.99 ± 0
AMI
0.81 ± 0.01
0.84 ± 0.05
Accuracy
0.96 ± 0.01
0.99 ± 0
AMI
0.79 ± 0.03
0.75 ± 0.02
50
Accuracy
0.82 ± 0.05
0.98 ± 0
AMI
75
0.73 ± 0.01
0.75 ± 0.01
Accuracy
0.74 ± 0
0.98 ± 0
(a) Malware categorization.
(b) Intrusion detection.
(a) Missing class.
(b) Coarse-grained label.
Fig. 7.
label setting (i.e., ng = (cid:98)n/2(cid:99)) with different ratios of available labels.
The performance of FARE and baselines under the coarse-grained
Fig. 8. Performance comparison of FARE and baselines under missing class
and coarse-grained label settings on the GTSRB dataset.
have the clustering result of a dataset, we ﬁrst compute the
matching score of between every cluster-class pair, constructed
a decision matrix in Table IX. Then, we obtain the conﬁdence
score for each cluster (i.e., the maximum matching score
among all known classes). Finally, we set the threshold as 0.9
and assigned the clusters to the known classes, accordingly. As
we can observe from the assignment (column 5 in Table IX),
we set cluster 2 as an unknown (possibly new) class, because
its conﬁdence is below the threshold. In addition, both cluster
3 and 4 are assigned to class 2. This indicates that class 2
represents a coarse-grained label.
APPENDIX-G. HYPER-PARAMETER SENSITIVITY
Sensitivity to Ratio of Available Labels. We evaluate the
impact of the ratio of available labels: For the missing class
settings, we ﬁxed nc = (cid:98)n/2(cid:99) for each dataset, and then varied
the ratio of labeled samples in the training data as 1%, 10%,
25%, and 50% to construct 4 groups of training sets. We ran
each method by sampling the missing classes 10 times and
reported testing AMIs. For the coarse-grained label settings,
we ﬁxed ng = (cid:98)n/2(cid:99) for each dataset and followed the same
procedure. In both experiments, we set the number of clusters
K to the corresponding ground-truth number.
Figure 6 and Figure 7 show the results. The performances
of all the methods are quite consistent with respect to different
ratios of available labels. This result indicates that FARE is
not sensitive to the raito of labeled samples. Also, the results
show that 1% labeled data is enough for FARE to achieve a
high AMI — the extra information provided by the clustering
ensemble has helped to boost the performance.
Sensitivity to the Latent Dimensionality. We also tested the
sensitivity of FARE to the output dimension of the transfor-
mation network q, and the distance radius α. As mentioned in
Section §III-D, α = q, and thus we changed them together. We
used the above setups (i.e., nc = (cid:98)n/2(cid:99) and ng = (cid:98)n/2(cid:99)) with
1% labels and 151 neighborhood models. We set the α (and
q) as 8, 16, 32, and 64, and ran FARE 10 times per setting. As
shown in Table X, subtly varying α and q in a certain range
does not affect the performance of FARE.
APPENDIX-H. FARE ON DATASET WITH MORE CLASSES.
In Section §IV, we demonstrated the effectiveness of FARE
on two security datasets with 6 and 9 classes, respectively.
Here, we further tested it on an image dataset with more
classes. we used a trafﬁc sign recognition dataset called
GTSRB [66] which has 39,209 training samples and 12,630
testing samples. The dataset has 43 classes, each of which
represents a type of trafﬁc sign (e.g., stop sign, speed limit).
We followed the same missing-class and coarse-grained label
setups as other experiments. For each labeled class, we ran-
domly selected 10% training samples as labeled data, and set
nc and ng as 0, 10, 20, and 30. For each setup, we ran FARE
and the baselines (DNN+, MixMatch+, and Ladders+) 10 times
and reported the testing AMIs. In Figure 8, we observe similar
results as those on the malware and intrusion dataset. FARE
is comparable with the baselines on the original dataset, and
outperforms the baselines when handling low-quality labels.
This result conﬁrms the advantage of FARE over other methods
under a large number true classes.
APPENDIX-I. FARE UNDER CORRUPTED LABELS.
We tested FARE under corrupted labels (which can be
caused by either random labeling errors or poisoning attacks).
Speciﬁcally, we considered a setup without missing classes
and coarse-grained labels. By following the setup in [35], we
randomly sampled x% of the labeled samples and relabeled
each sample with a wrong class randomly selected from the
known classes. Here, we set x =10, 25, 50, 75. For each x, we
ran FARE on the corrupted training data 10 times and reported
the testing AMIs. As shown in Table XI, the performance of
FARE is still reasonably good, even when x = 75. This is
again because the clustering ensemble mitigates the negative
inﬂuence of incorrect labels. However, compared to the clean
label setting (Table I), the performance drops as more labels
are corrupted. The corrupted labels indeed impose a negative
inﬂuence upon FARE. In Section §VI, we have discussed the
potential solutions to alleviate the negative impact.
18
1102560% of Label per Class0.20.30.40.50.60.70.8AMIFAREMixMatch+Ladder+DNN+1102550% of Label per Class0.20.40.60.81.0AMIFAREMixMatch+Ladder+DNN+0102030nc0.10.20.30.40.50.60.70.8AMIFAREMixMatch+Ladder+DNN+0102030ng0.30.40.50.60.70.8AMIFAREMixMatch+Ladder+DNN+