I have index with parent "model" and child "sell" documents at one index with
millions of documents and heavy concurrent indexing.
All nodes works with Oracle Hotspot 8 with 30gb heap, ElasticSearch 1.3.5.
I'm execute delete by query like this:
    curl -XDELETE 'http://127.0.0.1:9200/sells/sell/_query' -d '{"query":{"filtered":{"query":{"match_all":{}},"filter":{"and":{"filters":[{"term":{"client_id":123}}]}}}}}]}'
and our index is corrupted with this error message and exception stack trace
in logs:
    [2014-11-18 12:49:33,650][DEBUG][action.deletebyquery     ] [elastic1] [sells][3], node[hv2718pkQm-5SZq7agcY9g], [P], s[STARTED]: Failed to execute [delete_by_query {[sells][sell], query [{"query":{"filtered":{"query":{"match_all":{}},"filter":{"and":{"filters":[{"term":{"client_id":123}}]}}}}}]}] 
    org.elasticsearch.index.engine.RefreshFailedEngineException: [sells][3] Refresh failed 
            at org.elasticsearch.index.engine.internal.InternalEngine.refresh(InternalEngine.java:789) 
            at org.elasticsearch.index.engine.internal.InternalEngine.delete(InternalEngine.java:686) 
            at org.elasticsearch.index.shard.service.InternalIndexShard.deleteByQuery(InternalIndexShard.java:465) 
            at org.elasticsearch.action.deletebyquery.TransportShardDeleteByQueryAction.shardOperationOnPrimary(TransportShardDeleteByQueryAction.java:123) 
            at org.elasticsearch.action.support.replication.TransportShardReplicationOperationAction$AsyncShardOperationAction.performOnPrimary(TransportShardReplicationOperationAction.java:535) 
            at org.elasticsearch.action.support.replication.TransportShardReplicationOperationAction$AsyncShardOperationAction$1.run(TransportShardReplicationOperationAction.java:434) 
            at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) 
            at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) 
            at java.lang.Thread.run(Thread.java:745) 
    Caused by: java.lang.IllegalStateException: parentFilter must return FixedBitSet; got org.apache.lucene.search.BitsFilteredDocIdSet@74ebc73d 
            at org.elasticsearch.index.search.nested.IncludeNestedDocsQuery$IncludeNestedDocsWeight.scorer(IncludeNestedDocsQuery.java:123) 
            at org.apache.lucene.search.QueryWrapperFilter$1.iterator(QueryWrapperFilter.java:59) 
            at org.apache.lucene.index.BufferedUpdatesStream.applyQueryDeletes(BufferedUpdatesStream.java:554) 
            at org.apache.lucene.index.BufferedUpdatesStream.applyDeletesAndUpdates(BufferedUpdatesStream.java:287) 
            at org.apache.lucene.index.IndexWriter.applyAllDeletesAndUpdates(IndexWriter.java:3322) 
            at org.apache.lucene.index.IndexWriter.maybeApplyDeletes(IndexWriter.java:3313) 
            at org.apache.lucene.index.IndexWriter.getReader(IndexWriter.java:425) 
            at org.apache.lucene.index.StandardDirectoryReader.doOpenFromWriter(StandardDirectoryReader.java:292) 
            at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:267) 
            at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:257) 
            at org.apache.lucene.index.DirectoryReader.openIfChanged(DirectoryReader.java:171) 
            at org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:118) 
            at org.apache.lucene.search.SearcherManager.refreshIfNeeded(SearcherManager.java:58) 
            at org.apache.lucene.search.ReferenceManager.doMaybeRefresh(ReferenceManager.java:176) 
            at org.apache.lucene.search.ReferenceManager.maybeRefresh(ReferenceManager.java:225) 
            at org.elasticsearch.index.engine.internal.InternalEngine.refresh(InternalEngine.java:779) 
            ... 8 more
I cannot reproduce this error on our test stand cluster, sorry. It's seems
like a concurrent access error.
What's a kind of problem? Does it just bug?