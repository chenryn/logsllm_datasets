title:User-Centered Security: Stepping Up to the Grand Challenge
author:Mary Ellen Zurko
User-Centered Security: 
Stepping Up to the Grand Challenge 
Mary Ellen Zurko 
IBM Software Group 
PI:EMAIL 
The  mode  of  interaction  with  security  mechanisms 
was  users  applying  them  consciously  and  directly  as 
standalone  tools  in  a  context  they  understood.  The 
challenge was to make the security model of the tools 
consistent with the user’s mental model of security, so 
that undesirable errors would be minimized.  
By  1996,  humans’  relationships  to  computers  had 
changed dramatically. The World Wide Web, invented 
in  1989,  was  popularized  with  a  GUI  in  1992,  and 
began  its  steady  rise  to  ubiquity.  The  more  diverse, 
distributed, and popular uses of the web, the network, 
and  computers  became,  the  more  obvious  it  became 
that  problems  with  the  usability  of  existing  security 
mechanisms  would  compromise  their  effectiveness. 
Simon  and  I  [58]  defined  the  term  user-centered 
security  to  refer  to  “security  models,  mechanisms, 
systems, and software that have usability as a primary 
motivation  or  goal.”  We  foresaw  the  following  three 
categories  of  solutions:  (1)  applying  human-computer 
interaction  (HCI)  design  and  testing  techniques  to 
secure systems, (2) providing security mechanisms and 
models  for  human  collaboration  software,  and  (3) 
designing security features directly desired by users for 
their immediate and obvious  assurances (for example, 
signatures).  Security  researchers  pursued  the  usability 
in  some  of  the  most  important  and  intractable  areas, 
including  trust  models,  encryption  and  signing,  and 
authentication.  HCI  researchers  began  to  attack  the 
same  problems.  Sometimes  these  even  talked  to  each 
other.  
Two  years  ago,  in  November  2003,  Computing 
Research  Association  held  a  conference  on  “Grand 
Challenges in Information Security & Assurance” [10]. 
One of the four resulting grand challenges was:  
“Give  end-users  security  controls  they  can 
understand  and  privacy  they  can  control  for  the 
dynamic,  pervasive  computing  environments  of 
the future.” 
In the 28 years since psychological acceptability was 
defined, the problem has increased in urgency.  
While  there  has  been  substantial  work  in  usable 
security  in  the  last  nine  years,  the  CRA’s  grand 
challenge  indicates  that  the  problem  is  not  only 
Abstract 
is  on 
User-centered  security  has  been  identified  as  a 
grand challenge in information security and assurance. 
It 
the  brink  of  becoming  an  established 
subdomain  of  both  security  and  human/computer 
interface  (HCI)  research,  and  an  influence  on  the 
product  development  lifecycle.  Both  security  and  HCI 
rely  on  the  reality  of  interactions  with  users  to  prove 
the utility and validity of their work. 
As practitioners and researchers in those areas, we 
still  face  major  issues  when  applying  even  the  most 
foundational tools used in either of these fields across 
both  of  them.  This  essay  discusses  the  systemic 
roadblocks  at  the  social,  technical,  and  pragmatic 
levels  that  user-centered  security  must  overcome  to 
make substantial breakthroughs. Expert evaluation and 
user  testing  are  producing  effective  usable  security 
today.  Principles  such  as  safe  staging,  enumerating 
usability failure risks,  integrated security, transparent 
security  and  reliance  on  trustworthy  authorities  can 
also form the basis of improved systems.  
1. The Problem of User-Centered Security  
The  importance  and  challenge  of  the  relationship 
between  human  users  and  security  mechanisms  has 
been recognized since the dawn of time in the systems 
security  field.  Saltzer  and  Schroeder  [43]  defined  the 
principle of psychological acceptability in their seminal 
1975  paper  on  the  protection  of  information  in 
computer systems.  
“It  is  essential  that  the  human  interface  be 
designed for ease of use, so that users routinely and 
automatically  apply 
the  protection  mechanisms 
correctly.  Also,  to  the  extent  that  the  user’s  mental 
image  of  his  protection  goals  matches 
the 
mechanisms  he  must  use,  mistakes  will  be 
minimized.  If  he  must  translate  his  image  of  his 
protection  needs 
radically  different 
specification language, he will make errors.”  
into 
a 
Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005) 
1063-9527/05 $20.00 © 2005 IEEE 
unsolved, but has become more pressing. Our personal 
and  social  processes  and  interactions  rely  more  and 
more  heavily  on  computers,  communications,  and 
applications. The world and the information that feeds 
it  are  getting  more  connected,  more  available,  and 
more  accessible,  and  all  at  an  increasingly  rapid  rate. 
These  changes  provide  the  value  to  people  and  to 
society,  and  cause  the  difficulties  with  securing  that 
value.  
security  challenges  behind 
This  essay  provides  an  overview  of  the  user-
centered 
the  grand 
challenge and a discussion of the tools and approaches 
that  have  progressed  the  furthest  and  hold  the  most 
promise for near term results. It attempts to answer the 
following question: why have we lost ground in usable 
security  since  1975?  Throughout  this  essay  I  also 
highlight areas where further research is needed.  
2. Opportunities in User-Centered Security 
There  is  no  such  thing  as  problems,  there  are 
only opportunities 
My  boss  at  Prime  Computer,  circa  1986
The  largest  roadblocks  to  providing  user-centered 
security  break  down  into  three  categories;  (1)  human 
and social relationships to usable security, (2) technical 
challenges best attacked with research, and (3) further 
difficulties with implementation and deployment.  
2.1. Human and Social Relationship to Security  
There 
is  much  about 
the  human  and  social 
relationship  to  computer  security  that  we  still  do  not 
sufficiently  understand. What is the best  we can  hope 
for when we ask humans to understand a quality of the 
system so complex that it cannot be understood by any 
single  architect,  developer,  or  administrator?  Since 
humans are part of the system and the system’s security, 
how  much  responsibility  should  be  assigned  to  them? 
Since  usable  security  is  so  obviously  a  universally 
desirable attribute, why aren’t we applying resources to 
it commensurate with its desirability?  
2.1.1. Understanding vs. Effectively Using Security 
Controls.    
If  we  go  on  explaining,  we  shall  cease  to 
understand one another. 
Talleyrand   
What are people’s relationship to computer security, 
as individuals, as a group, as an organization, and as a 
society? Technology thinkers who understand technical 
complexity  see  usable  security  being  enabled  by 
security mechanisms that end users can understand. As 
computer systems  get  more complex, it is unfortunate 
that the security of those systems has also been getting 
more  complex.  For  example,  interpreters  that  enable 
active content attacks exist in simple print and display 
programs. They are at the core of the web technology 
that forms the basis of most people’s interactions with 
computers  today.  How  can  users  ever  understand 
anything that complex?  
Emphasizing  understanding  can  produce  profound 
changes 
the  creation  and  design  of  security 
mechanisms,  when  making  them  understandable  is  a 
primary  design  goal.  This  idea  is  at  the  heart  of  the 
reference  monitor  concept.  Security  mechanisms  that 
cannot  be  understood  cannot  be  effective.  Making 
security features explicable to an imagined, presumed, 
or  tested  representative  user  extends  this  traditional 
security design goal.  
in 
Attempting  to  explain  what  the  security  expert, 
architect,  designer,  or  developer  understands  about  a 
mechanism  can  be  useful.  Transparency  of  security 
mechanism  and  their  guarantees  is  at  the  heart  of 
evaluation  and  accreditation  efforts  such  as  Common 
Criteria [9]. Evaluation by external experts provides a 
bridge between the expert understanding and the needs 
of  users.  Evaluations  enable  informed  comparisons  in 
those  cases  where  the  description  language  is  both 
consistent and coherent.  
Clearly  explaining  and  documenting 
security 
mechanisms  and  their  use  can  produce  more  usable 
security,  both  by  communicating  what  is  known,  and 
by  providing  critical  feedback  on  the  degree  of 
explicability of the mechanisms. Security mechanisms 
that  are  explicit  but 
incomprehensible  and  not 
integrated  with  the  task  do  not  help  [61,  20],  and  the 
act of documenting them can highlight this problem.  
Graphical user interfaces are often meant to be self-
documenting.  Visualizing  security  is  one  method  for 
helping  users  understand  security.  Making  security 
information visually available in the context of the task 
enables users to make the right call, though it does not 
necessarily  give  them  guidance  on  determining  the 
right call [12, 13, 14]. Privacy awareness [7] is another 
form of this approach. In Privacy Bird [11], users liked 
having  the  ability  to  get  high  level  privacy  related 
information at a glance.  
Given  the  richness  and  complexity  of  the  security 
currently needed by our systems, it may be that we will 
never  have  enough  space  to  explain  or  visualize  (or 
audio-ize)  everything  about  the  security  mechanisms 
that users should understand. For example, the Johnny2 
CoPilot  study  [16]  was  built  around  an  interface  and 
mechanism  specifically  designed 
to  make  mail 
encryption and signing understandable. The researchers 
found  that  users  did  not  know  that  digital  signatures 
prevented  content  modification.  While  this  aspect  of 
the technology could be explained or visualized as well 
Proceedings of the 21st Annual Computer Security Applications Conference (ACSAC 2005) 
1063-9527/05 $20.00 © 2005 IEEE 
(for example with some sort of border or other graphic), 
the  mechanisms,  their  benefits,  and  their  limitations, 
pile  up  fast  in  even  a  simple  scenario.  If  the  mail 
message could include active content (for example Java 
or  Javascript)  which  is  also  a  security  concern,  the 
complexity  of  what  should  be  understood  has  at  that 
point  probably  exceeded  the  bounds  or  interests  of 
most users. The majority of users are unlikely to desire 
a  better  understanding  of  security  mechanisms  than 
they  currently  have.  From  a  panel  at  Network 
Distributed  System  Security  Symposium  1999  on 
“Security and the  User” [50] to discussions  with  very 
security  knowledgeable  customers,  what  I  hear  from 
users is “Why can’t security just work?”  
People  do  understand  something  about  security 
controls  in  the  physical  world.  The  understanding 
usually centers on the threats that are repelled by them. 
Locks  on  the  house  and  the  car  keep  burglars  out. 
Strongboxes inside banks and houses make it harder to 
get  to  the  most  valuable  objects,  and  slow  down  the 
intruder  even  more.  Hackers  and  viruses  are  in  the 
news;  they  disrupt  systems  and  corrupt  data  and  steal 
identity information for financial fraud. The intrusions, 
attacks, hacks, and other incidents are how most users 
think  about  security  mechanisms.  Will  it  keep  my 
identity  safe?  Will  it  keep  viruses  off  my  computer? 
This  approach  is  in  direct  opposition  to  how  security 
mechanisms  are  designed.  Security  mechanisms  are 
designed to withstand both current and potential future 
unknown attacks. It is the immediate use and utility of 
the security mechanism that makes sense to users, not 
their inner workings.  
[15]  lists  the  risk  management  questions  that  users 
ask: 
•  What could go wrong? 
•  How  likely  is  it,  and  what  damage  would  it 
cause to me or to others if it did? 
•  How would I know if something went wrong? 
•  What reason do I have to believe that it won’t? 
•  Who is responsible to ensure that it doesn’t, and 
what recourse do I have if it does?  
Humans know that the likelihood and sophistication 
of  an  attack  may  depend  on  the  (perceived)  abilities 
and protections of the person under attack (particularly 
if  social  engineering  or  scamming  is  involved),  the 
abilities  of  the  attacker  (and  their  tools),  and  the 
(perceived)  value  of  the  item  under  attack.  They  will 
trade off the short term and long term benefits applying 
security (or not). A UK news outlet traded candy bars 
for (ostensible) passwords with commuters [42]. A toy 
lock box for ages 6 and up has keys and a combination 
[31]. It shows that people can understand how to use a 
security  control  at  an  early  age.  Greenwald  [21] 