title:Connection-Oriented DNS to Improve Privacy and Security
author:Liang Zhu and
Zi Hu and
John S. Heidemann and
Duane Wessels and
Allison Mankin and
Nikita Somaiya
2015 IEEE Symposium on Security and Privacy
2015 IEEE Symposium on Security and Privacy
Connection-Oriented DNS
to Improve Privacy and Security
Liang Zhu∗, Zi Hu∗, John Heidemann∗, Duane Wessels†, Allison Mankin†, Nikita Somaiya∗
∗USC/Information Sciences Institute
†Verisign Labs
Abstract—The Domain Name System (DNS) seems ideal for
connectionless UDP, yet this choice results in challenges of
eavesdropping that compromises privacy, source-address spooﬁng
that simpliﬁes denial-of-service (DoS) attacks on the server and
third parties, injection attacks that exploit fragmentation, and
reply-size limits that constrain key sizes and policy choices.
We propose T-DNS to address these problems. It uses TCP
to smoothly support large payloads and to mitigate spooﬁng
and ampliﬁcation for DoS. T-DNS uses transport-layer security
(TLS) to provide privacy from users to their DNS resolvers and
optionally to authoritative servers. TCP and TLS are hardly
novel, and expectations about DNS suggest connections will
balloon client latency and overwhelm server with state. Our
contribution is to show that T-DNS signiﬁcantly improves security
and privacy: TCP prevents denial-of-service (DoS) ampliﬁcation
against others, reduces the effects of DoS on the server, and
simpliﬁes policy choices about key size. TLS protects against
eavesdroppers to the recursive resolver. Our second contribution
is to show that with careful
these
beneﬁts come at only modest cost: end-to-end latency from
TLS to the recursive resolver is only about 9% slower when
UDP is used to the authoritative server, and 22% slower with
TCP to the authoritative. With diverse traces we show that
connection reuse can be frequent (60–95% for stub and recursive
resolvers, although half that for authoritative servers), and after
connection establishment, experiments show that TCP and TLS
latency is equivalent to UDP. With conservative timeouts (20 s
at authoritative servers and 60 s elsewhere) and estimated per-
connection memory, we show that server memory requirements
match current hardware: a large recursive resolver may have 24k
active connections requiring about 3.6 GB additional RAM. Good
performance requires key design and implementation decisions
we identify: query pipelining, out-of-order responses, TCP fast-
open and TLS connection resumption, and plausible timeouts.
implementation choices,
I. INTRODUCTION
The Domain Name System (DNS) is the canonical example
of a simple request-response protocol. DNS resolves domain
names like www.iana.org into the IP addresses; rendering a
single web page may require resolving several domain names,
so it is desirable to minimize the latency of each query [12].
Requests and responses are typically small (originally required
to be less than 512 B, and today under 1500 B as a practical
matter), so a single-packet request is usually answered with a
single-packet reply over UDP. Simplicity and efﬁciency has
prompted DNS use in broader applications [78].
DNS standards have always required support for TCP, but
it has been seen as a poor relative—necessary for large
exchanges between servers, but otherwise discouraged. TCP is
more expensive than UDP, since connection setup adds latency
with additional packet exchanges, and tracking connections
requires memory and computation at the server. Why create a
connection if a two-packet exchange is sufﬁcient?
This paper makes two contributions. First, we demonstrate
that DNS’s connectionless protocol is the cause of a range of
fundamental weaknesses in security and privacy that can be
addressed by connection-oriented DNS. Connections have a
well understood role in longer-lived protocols such as ssh and
HTTP, but DNS’s simple, single-packet exchange has been
seen as a virtue. We show that it results in weak privacy,
denial-of-service (DoS) vulnerabilities, and policy constraints,
and that these problems increase as DNS is used in new
applications, and concerns about Internet safety and privacy
grow. While prior problems have been discussed in isolation
(for example, [9], [66]) and individual problems can often be
worked around, taken together they prompt revisiting assump-
tions. We then propose T-DNS, where DNS requests should
use TCP by default (not as last resort), and DNS requests from
end-users should use Transport-Layer Security (TLS [21]).
TCP prevents denial-of-service (DoS) ampliﬁcation against
others, reduces the effects of DoS on the server, and simpliﬁes
policy choices about DNSSEC key size, and that TLS protects
queries from eavesdroppers to the recursive resolver.
Our second contribution is to show that the beneﬁts of
connection-oriented DNS in T-DNS come at only modest
cost: For clients, end-to-end latency of T-DNS (time from
a stub’s request to an answer, considering all queries and
caches) is only moderately more than connectionless DNS.
Our models show latency increases by only 9% for TLS vs
UDP-only where TLS is used just from stub to recursive-
resolver, and it increases by 22% when we add TCP from
recursive to authoritative. Connection reuse results in latencies
almost the same as UDP once the connection is established.
With moderate timeouts (20 s at authoritative servers and 60 s
elsewhere), connection reuse is high for servers (85–98%),
amortizing setup costs for client and server. Connection reuse
for clients is lower (60–80% at the edge, but 20–40% at
the root), but still results in amortized costs and lowered
latencies. For servers, connection rates are viable for modest
server-class hardware today. With conservative timeouts (20 s
at authoritative servers and 60 s elsewhere) and overestimates
of per-connection memory, a large recursive resolver may
have 24k active connections using about 3.6 GB of RAM;
authoritative servers double those needs.
TCP and TLS are well established protocols, and many
DNS variations have been proposed, with TCP in the original
speciﬁcation, and prior proposals to use TLS, DTLS, SCTP,
© 2015, Liang Zhu. Under license to IEEE.
© 2015, Liang Zhu. Under license to IEEE.
DOI 10.1109/SP.2015.18
DOI 10.1109/SP.2015.18
171
171
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:02:44 UTC from IEEE Xplore.  Restrictions apply. 
and HTTP with XML or JSON. Our contribution is not
protocol novelty, but a careful evaluation of what is neces-
sary to add established protocols to an existing ecosystem:
evaluation that shows the performance costs are modest and
experiments that show the security and privacy beneﬁts are
real. With wide belief that connectionless DNS is mandatory
for adequate performance,
this study addresses a primary
impediment to improving DNS privacy. While we evaluate our
speciﬁc design, we suggest that our performance evaluation
generalizes to most connection-like approaches to DNS, nearly
all of which require some state at both ends. In addition, we
identify the speciﬁc implementation choices needed to get
good performance with TCP and TLS; alternative protocols
for DNS encryption will require similar optimizations, and
we suggest they will see similar performance.
Why: Connection-based communication is important
to
improve security in three ways. First, it improves DNS privacy
through the use of encryption. We discuss alternatives in
§ VII-D: although some employ UDP, all effectively build
connections at the application-layer to keep session keys and
manage setup. DNS trafﬁc is important to protect because
hostnames are richer than already visible IP addresses and
DNS queries expose application information (§ II-B3). DNS
queries are increasingly vulnerable, with wireless networks,
growth of third-party DNS (OpenDNS since 2006 [59] and
Google Public DNS since 2009 [63]), meaning that end-
user requests often cross several networks and are at risk
of eavesdropping. Prior work has suggested from-scratch ap-
proaches [57], [20], [80]; we instead utilize existing standards
to provide conﬁdentiality for DNS, and demonstrate only
moderate performance costs. As a side-effect, T-DNS also
protects DNS queries from tampering over parts of their path.
Second, TCP reduces the impact of denial-of-service (DoS)
attacks in several ways. Its connection establishment forces
both sides of the conversation to prove their existence, and
it has well-established methods to tolerate DoS attacks [26].
Lack of these methods has allowed UDP-based DNS to be
exploited by attackers with ampliﬁcation attacks; an anony-
mous attacker who spoofs addresses through a DNS server
can achieve a 20× increase in trafﬁc to its victim, a critical
component of recent multi-Gb/s DoS attacks [3]. We examine
performance under attack in § V.
applications will be preempted if DNS remains limited to short
replies.
How: On the surface, connection-oriented DNS seems un-
tenable, since TCP setup requires an extra round-trip and state
on servers. TCP is seen as bad for DNS, and so TLS’ heavier
weight handshake is impossible.
Fortunately, we show that connection persistence, reusing
the same connection for multiple requests, amortizes connec-
tion setup. We identify the key design and implementation
decisions needed to minimize overhead—query pipelining,
out-of-order responses, TCP fast open and TLS connection
resumption, shifting state to clients when possible. Combined
with persistent connections with conservative timeouts, these
optimizations balance end-to-end latency and server load.
Our key results are to show that T-DNS is feasible and that
it provides a clean solution to a broad range of DNS problems
across privacy, security, and operations. We support
these
claims with end-to-end models driven by analysis of day-long
traces from three different types of servers and experimental
evaluation of prototypes
II. PROBLEM STATEMENT
We next brieﬂy review today’s DNS architecture, the spe-
ciﬁc problems we aim to solve, and our threat model.
II-A Background
DNS is a protocol for resolving domain names to different
resource records in a globally distributed database. A client
makes a query to a server that provides a response of a
few dozen speciﬁc types. Domain names are hierarchical with
multiple components. The database has a common root and
millions of independent servers.
Originally DNS was designed to map domain names to
IP addresses. Its success as a lightweight, well understood
key-to-value mapping protocol caused its role to quickly
grow to other Internet-related applications [78], including host
integrity identiﬁcation for anti-spam measures and replica
selection in content-delivery networks [13]. Recently DNS’s
trust framework (DNSSEC) has been used to complement and
extend traditional PKI/Certiﬁcate Authorities for e-mail [29]
and TLS [33].
Protocols: DNS has always run over both connectionless
UDP and connection-oriented TCP transport protocols. UDP
has always been preferred, with TCP used primarily for zone
transfers to replicate portions of the database, kilobytes or
more in size, across different servers. Responses larger than
advertised limits are truncated, prompting clients to retry with
TCP [76]. UDP can support large packets with IP fragmenta-
tion, at the cost of new problems discussed below.
The integrity of DNS data is protected by DNSSEC [4].
DNSSEC provides cryptographic integrity checking of positive
and negative DNS replies, but not privacy. Since July 2010 the
root zone has been signed, providing a root of trust through
signed sub-domains.
As a Distributed System: DNS resolvers have both client
and server components. Resolvers typically take three roles:
Finally, UDP limits on reply sizes constrains key sizes and
DNS applications. EDNS0 [18] often makes 4096 B replies
possible, extending the original 512 B limit [53]. However,
due to IP fragmentation [18], 1500 B is seen as an opera-
tional constraint and this limit has repeatedly affected policy
choices in DNS security and applications. IP fragmentation
presents several dangers: fragments require a resend-all loss
recovery [42], about 8% of middleboxes (ﬁrewalls) block all
fragments [79], and fragmentation is one component in a class
of recently discovered attacks [32]. Of course current DNS
replies strive to ﬁt within current limits [77], but DNSSEC
keys approaching 2048-bits lead to fragmentation, particularly
during key rollover (§ II-B1). Finally, DNSSEC’s guarantees
make it attractive for new protocols with large replies, but new
172172
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:02:44 UTC from IEEE Xplore.  Restrictions apply. 
stub, recursive, authoritative. Stub resolvers are clients that
talk only to recursive resolvers, which handle name resolution.
Stubs typically send to one or a few recursive resolvers, with
conﬁguration automated through DHCP [23] or by hand.
Recursive resolvers operate both as servers for stubs and
clients to authoritative servers. Recursive resolvers work on
behalf of stubs to iterate through each of the several com-
ponents in a typical domain name, contacting one or more
authoritative servers as necessary to provide a ﬁnal answer to
the stub. Much of the tree is stable and some is frequently
used, so recursive resolvers cache results, reusing them over
their time-to-live.
Authoritative servers provide answers for speciﬁc parts of
the namespace (a zone). Replication between authoritative
peers is supported through zone transfers with notiﬁcations
and periodic serial number inquiries.
This three-level description of DNS is sufﬁcient to discuss
protocol performance for this paper. We omit both design and
implementation details that are not relevant to our discussion.
The complexity of implementations varies greatly [68]; we
describe some aspects of one operator’s implementation in
§ IV-A.
II-B The Limitations of Single-Packet Exchange
Our goal is to remove the limitations caused by optimizing
DNS around a single-packet exchange as summarized in
Table I. We consider transition in § III-D.
II-B1 Avoiding Arbitrary Limits to Response Size: Limita-
tion in payload size is an increasing problem as DNS evolves
to improve security. Without EDNS [18], UDP DNS messages
are limited to 512 B. With EDNS, clients and servers may
increase this limit (4096 B is typical), although this can lead
to fragmentation which raises its own problems [42]. Due to
problematic middleboxes, clients must be prepared to fall back
to 512 B, or resend the query by TCP. Evidence suggests that
5% [79] or 2.6% [35] of users ﬁnd TCP impeded. Such work-
arounds are often fragile and the complexities of incomplete
replies can be a source of bugs and security problems [32].
Evolution of DNS and deployment of DNSSEC have pushed
reply sizes larger. We studied Alexa top-1000 websites, ﬁnding
that 75% have replies that are at least 738 B (data is in [86]
due to space).
With increasingly larger DNS replies (for example, from
longer DNSSEC keys), IP-level fragmentation becomes a risk
in many or all replies. To quantify this problem, Figure 1
examines a 10-minute trace with 13.5M DNSSEC enabled
responses of one server for .com. Over this real-world trace we
model the effects of different key sizes by replacing current
1024-bit RSA signatures with longer ones. We model regular
operation for several key sizes, showing CDFs for the size
of all responses, and dots for negative responses (medians
for NXD; quartiles are within 1% and so are omitted) using
NSEC3 [45], and DNSKEY replies for several sizes of KSK
(each row) and ZSK (different shapes, exact values).
Figure 1 shows that with a 2048-bit ZSK, 5% of DNSSEC
responses and almost all NXDomain responses, and some
>1500: IP fragmentation likely
4k KSK
3k KSK
2k KSK
median
DNSKEY
NXD
1
)
s
e
s
n
o
p
s
e
r
l
l
a
(
F
D
C
0.8
0.6
0.4
0.2
0
normal
case
KSK
rollover
ZSK size
(bits)
1024
2048
3072
4096
 0
 500
 1000
 1500
 2000
 2500
 3000
 3500
Estimated DNSSEC Response size (Bytes)
Fig. 1: Estimated response sizes with different length DNSSEC
keys. Dots show sizes for DNSKEY and median for NXDo-
main replies. (Data: trace and modeling)
DNSKEYs during rollover will suffer IP fragmentation (shown
in the shaded region above 1500 B).
This evaluation supports our claim that connectionless trans-
port distorts current operational and security policies. Worries
about fragmentation have contributed to delay and concern
about key rollover and use of 2048-bit keys. More importantly,
other designs have been dismissed because of reply sizes, such
as proposals to decentralize signing authority for the DNS root
which might lead to requiring TCP for root resolution [72].
For some, this requirement for TCP is seen as a signiﬁcant
technical barrier forcing use of shorter keys or limitations of
algorithms.
Finally, size can also preempt
future DNS applications.
Recent work has explored the use of DNS for managing
trust relationships (for example [60]), so one might ask how
DNS would be used if these constraints to response size
were removed. We examine the PGP web of trust [62] as a
trust ecosystem that is unconstrained by packet sizes. Rather
than a hierarchy, key authentication PGP builds a mesh of
signatures, so 20% of keys show 10 or more signatures, and
well connected keys are essential to connecting the graph. PGP
public keys with 4 signatures exceeds 4kB, and about 40% of
keys have 4 signatures or more [62]. If DNS either grows to
consider non-hierarchical trust, or if it is simply used to store
such information [82], larger replies will be important.
T-DNS’s use of TCP replaces IP-level fragmentation with
TCP’s robust methods for retry and bytestream.
II-B2 Need for Sender Validation: Uncertainty about the
source address of senders is a problem that affects both DNS
servers and others on the Internet. Today source IP addresses
are easy to spoof, allowing botnets to mount denial-of-service
(DoS) attacks on DNS servers directly [36], [69], and to
leverage DNS servers as part of an attack on a third party
through a DNS Ampliﬁcation attack [74], [48].
Work-arounds to DNS’s role in DoS attacks exist. Many
anti-spooﬁng mechanisms have been proposed, and DNS
servers are able to rate-limit replies. T-DNS would greatly
reduce the vulnerability of DNS to DoS and as DoS lever-
173173
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:02:44 UTC from IEEE Xplore.  Restrictions apply. 
problem
packet size limitations
source spooﬁng
privacy (stub-to-recursive)
(recursive-to-authoritative)
current DNS
guarantee: 512 B, typical: 1500 B
spoof-detection depends on source ISP most cost pushed back to spoofer (SYN cookies in TCP)
vulnerable to eavesdropping
aggregation at recursive
privacy (from TLS encryption)
aggregation, or optional TLS
with T-DNS (why)
64 kB
Table I: Beneﬁts of T-DNS.
age against others. Well established techniques protect DNS