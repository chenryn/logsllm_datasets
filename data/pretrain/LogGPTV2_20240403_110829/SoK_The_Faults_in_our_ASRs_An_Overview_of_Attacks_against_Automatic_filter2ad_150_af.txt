framework to evaluate existing works in the adversarial space
against VPSes. We identify the unique contributions, open
problems and future research directions.
The space of attacks against VPSes is different and more
complex than that of their image counterparts. This is because
742
[6] N. Carlini and D. Wagner, “Audio adversarial examples: Targeted at-
tacks on speech-to-text,” in 2018 IEEE Security and Privacy Workshops
(SPW).
IEEE, 2018, pp. 1–7.
[7] H. Abdullah, W. Garcia, C. Peeters, P. Traynor, K. Butler, and
J. Wilson, “Practical Hidden Voice Attacks against Speech and Speaker
Recognition Systems,” Proceedings of the 2019 Network and Dis-
tributed System Security Symposium (NDSS), 2019.
[8] Y. Lin and W. H. Abdulla, “Principles of Psychoacoustics,” in Audio
Watermark. Springer, 2015, pp. 15–49.
[9] “Cloud Speech-to-Text,” Last accessed in 2019, available at https://
cloud.google.com/speech-to-text/.
[10] “Amazon Lex,” Last accessed in 2019, available at https://aws.amazon.
[11] “Apple’s Siri,” Last accessed in 2019, available at https://www.apple.
com/?nc2=h lg.
com/siri/.
[12] “The
Computers
are
available
Listening,
at
Accessed
https://theintercept.com/2015/06/
Part
2,”
[13] “The
2018,
in
nsa-transcription-american-phone-calls/.
Listening,
at
are
available
in
nsa-speech-recognition-snowden-searchable-text/.
Computers
2018,
Part
Accessed
https://theintercept.com/2015/05/
1,”
10
Years,
Searchable
[14] “For
Calls
[Online].
for-10-years-nsa-software-has-made-phone-calls-searchable-by-keyword/
”
Phone
2018.
”https://www.truthdig.com/articl/
Has Made
Accessed
in
NSA
by
Keyword,”
Available:
Software
[15] “The
Computers
2018,
in
nsa-transcription-american-phone-calls/.
[16] “Report: NSA Can
Record,
are
available
Listening,
at
Accessed
https://theintercept.com/2015/06/
Part
1,”
Countries,” Accessed
of Whole
https://www.npr.org/sections/thetwo-way/2014/03/18/2911652/
report-nsa-can-record-store-phone-conversations-of-whole-countries.
Store
in
Phone
2018,
Conversations
available
at
[17] “Otter.ai,” Last accessed in 2019, available at https://otter.ai/login.
[18] J. Sohn, N. S. Kim, and W. Sung, “A statistical model-based voice
activity detection,” IEEE signal processing letters, vol. 6, no. 1, pp.
1–3, 1999.
[19] S. Sigurdsson, K. B. Petersen, and T. Lehn-Schiøler, “Mel Frequency
Cepstral Coefﬁcients: An Evaluation of Robustness of MP3 Encoded
Music.” in ISMIR, 2006, pp. 286–289.
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:09:49 UTC from IEEE Xplore.  Restrictions apply. 
[20] L. R. Rabiner and R. W. Schafer, Digital processing of speech signals.
Prentice Hall, 1978.
[21] N. Ahmed, T. Natarajan, and K. R. Rao, “Discrete cosine transform,”
IEEE transactions on Computers, vol. 100, no. 1, pp. 90–93, 1974.
[22] D. Gunning, “Explainable artiﬁcial intelligence (xai),” Defense Ad-
vanced Research Projects Agency (DARPA), nd Web, 2017.
[23] A. Hannun, “Sequence modeling with ctc,” Distill, vol. 2, no. 11, p. e8,
2017.
[24] P. Koehn, “Pharaoh: a beam search decoder for phrase-based statistical
machine translation models,” in Conference of the Association for
Machine Translation in the Americas. Springer, 2004, pp. 115–124.
[25] “Kaldi ASpIRE Chain Model,” Last accessed in 2019, available at
http://kaldi-asr.org/models.html.
[26] S. Naren, “Speech Recognition using DeepSpeech-2,” Last accessed in
2019, available at https://github.com/SeanNaren/deepspeech.pytorch.
[27] D. Povey, A. Ghoshal, G. Boulianne, L. Burget, O. Glembek, N. Goel,
M. Hannemann, P. Motlicek, Y. Qian, P. Schwarz, J. Silovsky, G. Stem-
mer, and K. Vesely, “The Kaldi Speech Recognition Toolkit,” in IEEE
2011 Workshop on Automatic Speech Recognition and Understanding.
IEEE Signal Processing Society, 2011, iEEE Catalog No.: CFP11SRW-
USB.
[28] P. Lamere, P. Kwok, W. Walker, E. Gouvea, R. Singh, B. Raj, and
P. Wolf, “Design of the CMU Sphinx-4 decoder,” in Eighth European
Conference on Speech Communication and Technology, 2003.
[29] H. Abdullah, M. S. Rahman, W. Garcia, L. Blue, K. Warren, A. S. Ya-
dav, T. Shrimpton, and P. Traynor, “Hear “No Evil”, See “Kenansville”:
Efﬁcient and Transferable Black-Box Attacks on Automatic Speech
Recognition Systems,” In Submission, 2019.
[30] L. Huang, A. D. Joseph, B. Nelson, B. I. Rubinstein, and J. D.
Tygar, “Adversarial Machine Learning,” in Proceedings of the 4th
ACM Workshop on Security and Artiﬁcial Intelligence, ser. AISec ’11.
New York, NY, USA: ACM, 2011, pp. 43–58. [Online]. Available:
http://doi.acm.org/10.1145/2046684.2046692
[31] N. Papernot, P. McDaniel, A. Sinha, and M. Wellman, “Towards the
science of security and privacy in machine learning,” arXiv preprint
arXiv:1611.03814, 2016.
[32] B. I. Rubinstein, B. Nelson, L. Huang, A. D. Joseph, S.-h. Lau, S. Rao,
N. Taft, and J. D. Tygar, “ANTIDOTE: Understanding and Defending
against Poisoning of Anomaly Detectors,” in Proceedings of the 9th
ACM SIGCOMM conference on Internet measurement. ACM, 2009,
pp. 1–14.
[33] B. Biggio, I. Corona, D. Maiorca, B. Nelson, N. ˇSrndi´c, P. Laskov,
G. Giacinto, and F. Roli, “Evasion attacks against machine learning
at test time,” in Joint European conference on machine learning and
knowledge discovery in databases. Springer, 2013, pp. 387–402.
[34] O. Ohrimenko, F. Schuster, C. Fournet, A. Mehta, S. Nowozin,
K. Vaswani, and M. Costa, “Oblivious Multi-Party Machine Learn-
ing on Trusted Processors,” in 25th {USENIX} Security Symposium
({USENIX} Security 16), 2016, pp. 619–636.
[35] C. Dwork, F. McSherry, K. Nissim, and A. Smith, “Calibrating Noise
to Sensitivity in Private Data Analysis,” in Theory of cryptography
conference. Springer, 2006, pp. 265–284.
[36] L. Song, R. Shokri, and P. Mittal, “Privacy Risks of Securing Ma-
chine Learning Models against Adversarial Examples,” arXiv preprint
arXiv:1905.10291, 2019.
[37] M. Nasr, R. Shokri, and A. Houmansadr, “Comprehensive Privacy
Analysis of Deep Learning: Passive and Active White-box Inference
Attacks against Centralized and Federated Learning,” in 2019 IEEE
Symposium on Security and Privacy (SP).
IEEE, 2019, pp. 739–753.
[38] F. Tram`er, F. Zhang, A. Juels, M. K. Reiter, and T. Ristenpart, “Stealing
Machine Learning Models via Prediction APIs,” in 25th {USENIX}
Security Symposium ({USENIX} Security 16), 2016, pp. 601–618.
[39] B. Wang and N. Z. Gong, “Stealing Hyperparameters in Machine
Learning,” in 2018 IEEE Symposium on Security and Privacy (SP).
IEEE, 2018, pp. 36–52.
[40] C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfel-
low, and R. Fergus, “Intriguing properties of neural networks,” arXiv
preprint arXiv:1312.6199, 2013.
[41] X. Yuan, Y. Chen, Y. Zhao, Y. Long, X. Liu, K. Chen, S. Zhang,
H. Huang, X. Wang, and C. A. Gunter, “CommanderSong: A Sys-
tematic Approach for Practical Adversarial Voice Recognition,” in
Proceedings of the USENIX Security Symposium, 2018.
[42] G. Zhang, C. Yan, X. Ji, T. Zhang, T. Zhang, and W. Xu, “Dol-
phinAttack: Inaudible voice commands,” in Proceedings of the 2017
ACM SIGSAC Conference on Computer and Communications Security.
ACM, 2017, pp. 103–117.
[43] P.-Y. Chen, H. Zhang, Y. Sharma, J. Yi, and C.-J. Hsieh, “Zoo: Zeroth
order optimization based black-box attacks to deep neural networks
without training substitute models,” in Proceedings of the 10th ACM
Workshop on Artiﬁcial Intelligence and Security. ACM, 2017, pp.
15–26.
[44] N. Papernot, P. McDaniel, S. Jha, M. Fredrikson, Z. B. Celik, and
A. Swami, “The limitations of deep learning in adversarial settings,”
in Security and Privacy (EuroS&P), 2016 IEEE European Symposium
on.
IEEE, 2016, pp. 372–387.
[45] N. Carlini and D. Wagner, “Towards evaluating the robustness of neural
networks,” in Security and Privacy (SP), 2017 IEEE Symposium on.
IEEE, 2017, pp. 39–57.
[46] N. Papernot, P. McDaniel, and I. Goodfellow, “Transferability in
Machine Learning: from Phenomena to Black-Box Attacks using
Adversarial Samples,” arXiv preprint arXiv:1605.07277, 2016.
[47] F. Tram`er, N. Papernot, I. Goodfellow, D. Boneh, and P. McDaniel,
“The Space of Transferable Adversarial Examples,” arXiv preprint
arXiv:1704.03453, 2017.
[48] A. Demontis, M. Melis, M. Pintor, M. Jagielski, B. Biggio, A. Oprea,
C. Nita-Rotaru, and F. Roli, “Why Do Adversarial Attacks Transfer?
Explaining Transferability of Evasion and Poisoning Attacks,” in 28th
{USENIX} Security Symposium ({USENIX} Security 19), 2019, pp.
321–338.
[49] M. Jagielski, N. Carlini, D. Berthelot, A. Kurakin, and N. Papernot,
“High-Fidelity Extraction of Neural Network Models,” arXiv preprint
arXiv:1909.01838, 2019.
[50] L. Wu, Z. Zhu, C. Tai et al., “Understanding and Enhancing the Trans-
ferability of Adversarial Examples,” arXiv preprint arXiv:1802.09707,
2018.
[51] Y. Liu, X. Chen, C. Liu, and D. Song, “Delving into Transfer-
able Adversarial Examples and Black-box Attacks,” arXiv preprint
arXiv:1611.02770, 2016.
[52] R. Pascanu, T. Mikolov, and Y. Bengio, “On the difﬁculty of training
Recurrent Neural Networks,” in International conference on machine
learning, 2013, pp. 1310–1318.
[53] T. Mikolov, K. Chen, G. Corrado, and J. Dean, “Efﬁcient Esti-
mation of Word Rrepresentations in Vector Space,” arXiv preprint
arXiv:1301.3781, 2013.
[54] N. Papernot, P. McDaniel, I. Goodfellow, S. Jha, Z. B. Celik, and
A. Swami, “Practical Black-box Attacks Against Machine Learning,”
in Proceedings of the 2017 ACM on Asia Conference on Computer and
Communications Security. ACM, 2017, pp. 506–519.
[55] A. Athalye, N. Carlini, and D. Wagner, “Obfuscated Gradients Give
a False Sense of Security: Circumventing Defenses to Adversarial
Examples,” arXiv preprint arXiv:1802.00420, 2018.
[56] J. Lau, B. Zimmerman, and F. Schaub, “Alexa, are you listening?
privacy perceptions, concerns and privacy-seeking behaviors with smart
speakers,” Proceedings of the ACM on Human-Computer Interaction,
vol. 2, no. CSCW, pp. 1–31, 2018.
[57] W. Diao, X. Liu, Z. Zhou, and K. Zhang, “Your voice assistant is mine:
How to abuse speakers to steal information and control your phone,”
in Proceedings of the 4th ACM Workshop on Security and Privacy in
Smartphones & Mobile Devices, 2014, pp. 63–74.
[58] P. J. Young, J. H. Jin, S. Woo, and D. H. Lee, “Badvoice: Soundless
voice-control replay attack on modern smartphones,” in 2016 Eighth In-
ternational Conference on Ubiquitous and Future Networks (ICUFN).
IEEE, 2016, pp. 882–887.
[59] D. Kumar, R. Paccagnella, P. Murley, E. Hennenfent, J. Mason,
A. Bates, and M. Bailey, “Skill Squatting Attacks on Amazon Alexa,”
in 27th USENIX Security Symposium (USENIX Security 18). USENIX
Association, 2018.
[60] N. Zhang, X. Mi, X. Feng, X. Wang, Y. Tian, and F. Qian, “Dan-
gerous skills: Understanding and mitigating security risks of voice-
controlled third-party functions on virtual personal assistant systems,”
in Dangerous Skills: Understanding and Mitigating Security Risks of
Voice-Controlled Third-Party Functions on Virtual Personal Assistant
Systems.
IEEE, 2019, p. 0.
[61] “Azure Speaker Veriﬁcation API,” Last accessed in 2019, available
https://azure.microsoft.com/en-us/services/cognitive-servic/
at
speaker-recognition/.
[62] S. O. Sadjadi, M. Slaney, and L. Heck, “MSR identity toolbox v1.
0: A MATLAB toolbox for speaker-recognition research,” Speech and
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:09:49 UTC from IEEE Xplore.  Restrictions apply. 
743
Language Processing Technical Committee Newsletter, vol. 1, no. 4,
pp. 1–32, 2013.
[63] “Google Cloud Speech-to-Text API,” Last accessed in 2019, available
at https://cloud.google.com/speech-to-text/.
[64] L. Blue, L. Vargas, and P. Traynor, “Hello, is it me you’re looking
for? differentiating between human and electronic speakers for voice
interface security,” in Proceedings of the 11th ACM Conference on
Security & Privacy in Wireless and Mobile Networks, 2018, pp. 123–
133.
[65] F. G. Bordonaro, K. Zhang, and S. R. Raparla, “Method and apparatus
for measuring network data packet delay, jitter and loss,” 15 2005, uS
Patent 6,868,094.
[66] S. Keshav and S. Kesahv, An engineering approach to computer
networking: ATM networks, the Internet, and the telephone network.
Addison-Wesley Reading, 1997, vol. 1.
[67] A. W. Rix, J. G. Beerends, M. P. Hollier, and A. P. Hekstra, “Per-
ceptual evaluation of speech quality (pesq)-a new method for speech
quality assessment of telephone networks and codecs,” in 2001 IEEE
International Conference on Acoustics, Speech, and Signal Processing.
Proceedings (Cat. No. 01CH37221), vol. 2.
IEEE, 2001, pp. 749–752.
[68] M. Pesola, T. Saarnimo, V.-M. Valimaa, and A. Leman, “Electromag-
netic interference shielding construction in a radio telephone,” Dec. 14
1993, uS Patent 5,271,056.
[69] J.-C. Bolot and A. Vega-Garcia, “Control mechanisms for packet audio
in the internet,” in Proceedings of IEEE INFOCOM’96. Conference on
Computer Communications, vol. 1.
IEEE, 1996, pp. 232–239.
[70] B. Reaves, L. Blue, and P. Traynor, “Authloop: End-to-end crypto-
graphic authentication for telephony over voice channels,” in 25th
USENIX Security Symposium USENIX Security 16, 2016, pp. 963–978.
[71] R. Taori, A. Kamsetty, B. Chu, and N. Vemuri, “Targeted Ad-
versarial Examples for Black Box Audio Systems,” arXiv preprint
arXiv:1805.07820, 2018.
[72] M. Ciss´e, Y. Adi, N. Neverova, and J. Keshet, “Houdini: Fooling Deep
Structured Visual and Speech Recognition Models with Adversarial
Examples,” in Advances in Neural Information Processing Systems 30:
Annual Conference on Neural Information Processing Systems 2017,
4-9 December 2017, Long Beach, CA, USA, 2017, pp. 6980–6990.
[73] F. Kreuk, Y. Adi, M. Cisse, and J. Keshet, “Fooling End-to-
end Speaker Veriﬁcation by Adversarial Examples,” arXiv preprint
arXiv:1801.03339, 2018.
[74] Y. Qin, N. Carlini, I. Goodfellow, G. Cottrell, and C. Raffel, “Imper-
ceptible, Robust, and Targeted Adversarial Examples for Automatic
Speech Recognition,” arXiv preprint arXiv:1903.10346, 2019.
[75] L. Sch¨onherr, K. Kohls, S. Zeiler, T. Holz, and D. Kolossa,
“Adversarial Attacks Against Automatic Speech Recognition Systems
via Psychoacoustic Hiding.” The Internet Society, 2019. [Online].
Available: https://www.ndss-symposium.org/ndss2019/
[76] S. Abdoli, L. G. Hafemann, J. Rony, I. B. Ayed, P. Cardinal, and A. L.
Koerich, “Universal Adversarial Audio Perturbations,” arXiv preprint
arXiv:1908.03173, 2019.
[77] H. Yakura and J. Sakuma, “Robust Audio Adversarial Example for a
Physical Attack,” arXiv preprint arXiv:1810.11793, 2018.
[78] Y. Chen, X. Yuan, J. Zhang, Y. Zhao, S. Zhang, K. Chen, and X. Wang,
“Devil’s whisper: A general approach for physical adversarial attacks
against commercial black-box speech recognition devices,” in 29th
USENIX Security Symposium (USENIX Security 20), 2020.
[79] M. Alzantot, B. Balaji, and M. B. Srivastava, “Did you hear that?
Adversarial Examples Against Automatic Speech Recognition,”
in Neural Information Processing Systems Workshop on Machine
Deception 2017, vol. abs/1801.00554. Neural Information Processing
Systems, 2017. [Online]. Available: http://arxiv.org/abs/1801.00554
[80] T. Sugawara, B. Cyr, S. Rampazzi, D. Genkin, and K. Fu, “Light
commands: laser-based audio injection attacks on voice-controllable
systems,” arXiv preprint arXiv:2006.11946, 2020.
[81] T. Vaidya, Y. Zhang, M. Sherr, and C. Shields, “Cocaine Noodles:
Exploiting the Gap between Human and Machine Speech Recognition,”
WOOT, vol. 15, pp. 10–11, 2015.
[82] N. Carlini, P. Mishra, T. Vaidya, Y. Zhang, M. Sherr, C. Shields,
D. Wagner, and W. Zhou, “Hidden Voice Commands.” in USENIX
Security Symposium, 2016, pp. 513–530.
[83] “DeepSpeech,” Last accessed in 2019, available at https://github.com/
mozilla/DeepSpeech.
[84] Y. Wang, W. Cai, T. Gu, W. Shao, Y. Li, and Y. Yu, “Secure your
voice: An oral airﬂow-based continuous liveness detection for voice
assistants,” Proceedings of the ACM on Interactive, Mobile, Wearable
and Ubiquitous Technologies, vol. 3, no. 4, pp. 1–28, 2019.
[85] Q. Wang, X. Lin, M. Zhou, Y. Chen, C. Wang, Q. Li, and X. Luo,
“Voicepop: A pop noise based anti-spooﬁng system for voice authen-
tication on smartphones,” in IEEE INFOCOM 2019-IEEE Conference
on Computer Communications.
IEEE, 2019, pp. 2062–2070.
[86] C. Wang, S. A. Anand, J. Liu, P. Walker, Y. Chen, and N. Saxena,
“Defeating hidden audio channel attacks on voice assistants via audio-
induced surface vibrations,” in Proceedings of the 35th Annual Com-
puter Security Applications Conference, 2019, pp. 42–56.
[87] Z. Yang, B. Li, P.-Y. Chen, and D. Song, “Characterizing Audio
Adversarial Examples Using Temporal Dependency,” arXiv preprint
arXiv:1809.10875, 2018.
[88] “Apple HomePod
build
accessed
apple-homepod-build-cost-hints-at-thin-margins-14519606/.
2020,
in
cost
available
hints
at
at
thin margins,” Last
https://www.slashgear.com/
[89] “Average Bedroom Size and Dimensions,” Last accessed in 2019, avail-
able at https://www.doorwaysmagazine.com/average-bedroom-size/.
[90] A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu, “To-
wards Deep Learning Models Resistant to Adversarial Attacks,” arXiv
preprint arXiv:1706.06083, 2017.
[91] A. Kurakin, I. Goodfellow, and S. Bengio, “Adversarial examples in
the physical world,” arXiv preprint arXiv:1607.02533, 2016.
[92] M. Todisco, X. Wang, V. Vestman, M. Sahidullah, H. Delgado,
A. Nautsch, J. Yamagishi, N. Evans, T. Kinnunen, and K. A. Lee,
“Asvspoof 2019: Future horizons in spoofed and fake audio detection,”
arXiv preprint arXiv:1904.05441, 2019.
[93] H. Jooybar, W. W. Fung, M. O’Connor, J. Devietti, and T. M.
Aamodt, “GPUDet: a deterministic GPU architecture,” ACM SIGARCH
Computer Architecture News, vol. 41, no. 1, pp. 1–12, 2013.
[94] “The USTC-iFlytek System For CHiME-4 Challenge,” Last accessed
in 2019, available at http://spandh.dcs.shef.ac.uk/chime workshop/
chime2016/presentations/CHiME 2016 Du oral.pdf.
[95] “Deep Speech 0.4.1,” Last accessed in 2019, available at https://github.
com/mozilla/DeepSpeech/releases/tag/v0.4.1.
[96] G. F. Cretu, A. Stavrou, M. E. Locasto, S. J. Stolfo, and A. D.
Keromytis, “Casting Out Demons: Sanitizing Training Data for
Anomaly Sensors,” in 2008 IEEE Symposium on Security and Privacy
(sp 2008).