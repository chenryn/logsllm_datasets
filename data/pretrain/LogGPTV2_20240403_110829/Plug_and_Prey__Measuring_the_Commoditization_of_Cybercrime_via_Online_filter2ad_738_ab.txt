Fraud
Mining
Carding
Accounts
Financial malware
Cryptocurrency mining
Credit card reselling
Reselling credentials
Figure 2: Conceptual model of value chains, showing
a representation of the ﬁnancial malware value chain
apps, b) distribution, c) take-over, i.e. the logging of in-
formation, and d) reselling and cashing-out [23, 42].
Last, the resale of non-ﬁnancial accounts leans on the
exact same resources as carding [23, 42].
Looking at these value chains, we can see that some
components are common among them. All models relate
to at least four main resources: development, distribu-
tion, take-over and cash-out. We merge these into a sin-
gle component that belongs to two or more value chains.
We can synthesize all value chains in a overall set of 13
components. Some components, e.g., malware, can be
used for more than one main resource. Figure 2 summa-
rizes our conceptual model and the overall demand for
B2B services in cybercrime.
4 Measurement methodology
Our measurement methodology consists of 1) collect-
ing and parsing data on listings, prices and buyer feed-
back from eight prominent online anonymous markets,
2) implementing and applying a classiﬁer to the listings
to map them to cybercrime components from our con-
ceptual model of value chains (Figure 2) as well as to
additional categories of B2C cybercrime, and 3) using
Latent Dirichlet Allocation (LDA, [10]) to identify the
best-selling clusters of listings and compare their offer-
Source
Levchenko et al. [34], Thomas et al. [42]
Kharraz et al. [30], Thomas et al. [42]
Kshetri et al. [32], Thomas et al. [42]
Miramirkhani et al. [35], Christin et al. [16], Thomas et al. [42]
Thomas et al. [42], Van Wegberg et al. [44]
Huang et al. [27], Thomas et al. [42]
Holt [23], Thomas et al. [42]
Holt [23], Thomas et al. [42]
ings to the capabilities, resources and services needed for
each component of the conceptual model.
4.1 Data collection
We ﬁrst leveraged the parsed and analyzed dataset of
Soska and Christin [40] to obtain information about item
listings and reviews on several prominent online anony-
mous marketplaces. For each of the over 230,000 item
listings,
the data include (but are not limited to) ti-
tles, descriptions, advertised prices, item-vendor map-
ping, category classiﬁcation, shipping restrictions and
various timestamps. Additionally, each item listing con-
tains feedback that has been proven to be a reasonable
proxy for sales [15,40]. Each piece of feedback contains
a message, a numerical score, and a timestamp.
We then extended this data with an additional 16 com-
plete snapshots of AlphaBay that we collected from May
30, 2016 to May 26, 2017, just two months before its
closure in July 2017 [4]. Table 2 summarizes the dataset.
We merged the new AlphaBay scrapes with the existing
dataset by ﬁrst parsing out the same supported ﬁelds and
then running a compatible analysis using the categori-
cal classiﬁer from Soska and Christin [40].2 AlphaBay
is important since, according to the FBI [4], by the time
of its closure, it had featured over 100,000 listings for
stolen and fraudulent documents, counterfeits, and mal-
ware in particular. The US Department of Justice (DoJ)
also claims that AlphaBay was the largest single online
anonymous marketplace ever taken down [3].
As an important data processing note, some vendors
set “holding prices” to their listings when the product or
service they are selling is out of stock. Instead of remov-
ing the listing, these vendors increase the price (astro-
nomically) to prevent buyers trying to buy their product.
Soska and Christin [40] developed a heuristic that cor-
rects these holding prices, which we applied in the pre-
processing of the parsed and labeled dataset. This limits
2Soska and Christin’s dataset included 17 snapshots of AlphaBay,
dating back to December 2014, that they did not use in their published
analysis [40].
1012    27th USENIX Security Symposium
USENIX Association
Table 2: Markets crawled
Market
Agora
Alphabay
Black Market Reloaded
Evolution
Hydra
Pandora
Silk Road 1
Silk Road 2
First seen
2013-12-24
2014-12-31
2012-11-21
2014-01-13
2014-04-14
2013-11-02
2011-06-21
2013-11-27
Last seen
2015-02-11
2017-05-26
2013-12-04
2015-02-18
2014-10-26
2014-10-13
2013-08-19
2014-10-29
# Snapshots
161
33
25
43
29
140
133
195
the potential for errors stemming from falsely assuming
a certain holding price was associated with a buy.
4.2 Classifying cybercrime listings
Most listings on these marketplaces are related to drugs
and other non-cybercrime activities [15, 40]. Our aim is
to classify each item listing into one of the 10 categories
of cybercrime components from the conceptual frame-
work (Figure 2). Unfortunately, the labels provided by
Soska and Christin are not expressive enough to capture
these nuanced categories, so we begin by using their la-
bels as a pre-ﬁlter and retain only item listings that were
identiﬁed as being either “Digital goods” or “Miscella-
neous” (19% of all listings).
Next, we implemented a Linear Support Vector Ma-
chine (SVM) classiﬁer. Manual inspection conﬁrmed our
suspicion that the markets also contain retail (B2C) cy-
bercrime offerings, next to wholesale cybercrime offer-
ings. For this reason, we added six product categories to
distinguish supply in that part of the market: accounts,
custom requests, fake documents, guides and tutorials,
pirated goods, and vouchers. A ﬁnal category, namely,
“other”, captures the listings that did not ﬁt anywhere
else (e.g., scanned legal documents). The classiﬁer is
initially trained and evaluated on a sample of listings
(n = 1,500) from all the markets, where ground truth is
created via manual labeling.
Table 3: “Digital Goods” & “Miscellaneous” Listings
Market
Agora
Alphabay
Black Market Reloaded
Evolution
Hydra
Pandora
Silk Road 1
Silk Road 2
# Listings
3,240
21,350
2,069
9.551
377
1,204
4,053
2,734
# Vendors
526
3,055
386
1.002
28
169
645
441
Total revenue
$ 1,818,991
$ 13,471,406
$
685,108
$ 6,125,136
242,230
$
$
394,306
$ 2,239,436
$ 4,455,339
4.3 Ground truth
For labeling the ground truth, we randomly selected
1,500 items from all listings classiﬁed as either “Digi-
tal Goods” or “Miscellaneous” (n = 44,060), or approxi-
mately 3.5% of the data. Only around 30% of the listings
in the random sample belonged to one of the ten B2B cy-
bercrime components. Around 45% belonged to one of
the B2C categories and the remaining 25% were labeled
as “other.” Those were comprised of drug listings that
were misclassiﬁed as “miscellaneous,” as well as luxury
items and other physical goods. We also found some in-
comprehensible listings, which might be test entries by
vendors. Labeling the ground truth yielded four more
observations. First, we identiﬁed listings that contain
more than one cybercrime component, e.g., offering both
a piece of malware and (access to) a botnet. Second, we
identiﬁed package listings, such as complete cryptocur-
rency mining schemes. Third, we observed that some
vendors add unrelated keywords to their listings, pre-
sumably in a marketing effort similar to search engine
optimization. Fourth and last, we observed custom list-
ings, i.e., listings that are speciﬁcally created to be sold
only once to one speciﬁc buyer. Custom listings con-
tain bespoke products or services ranging from custom
quantities to a completely custom-made product such as
pre-booked plane tickets.
After labeling our random sample of listings, we can
assess whether each category meets our criteria for ac-
curately classifying listings to categories of cybercrime
components. To avoid overﬁtting to a speciﬁc compo-
nent, we ensure the training set for our classiﬁer holds
at least 20 listings per category of cybercrime compo-
nents. Because of the highly skewed distribution of list-
ings in our random sample, we were forced to increase
our ground truth by manually adding listings to the fol-
lowing categories: app, botnet, e-mail, exploit, hosting,
malware, phone, RAT and website. To that end, we oper-
ated a manual search in the ﬁltered portion of data using
up to three keywords on those cybercrime components.
We manually veriﬁed whether the listings with the key-
word in the title or description advertise the actual prod-
uct or was a false positive – e.g., a vendor using the word
“malware” in a listing of lottery tickets.
4.4 Training and evaluation
Before training the classiﬁer, we excluded three cate-
gories of cybercrime components from the classiﬁcation:
JavaScript malware, webinjects, and customer support.
For these, we found no listings in our random sample.
The classiﬁcation phase itself consists of three steps:
(i) data cleaning, (ii) tokenizing, (iii) training and evalu-
ation of the ground-truth samples which are the concate-
nation of the title and description of the item listings. In
USENIX Association
27th USENIX Security Symposium    1013
data cleaning, we removed all English stop words, punc-
tuations, numbers, URLs and accents of all unicode char-
acters. We then lemmatized the words in order to group
together the inﬂected forms of a word so they can be an-
alyzed as a single item, identiﬁed by the word’s lemma,
or dictionary form before being trained and tested. We
tokenized each item (assuming all items are in English)
and computed a tf-idf (term frequency inverse document
frequency) value for each of the resulting 9,629 unique
tokens or words. To calculate the tf-idf, we used a max-df
(maximum document frequency) equal to 0.7 – this dis-
cards words appearing in more than 70% of the listings.
In the classiﬁcation phase we then used these values as an
input for an L2-Penalized SVM under L2-Loss. We im-
plemented this classiﬁer using Python and scikit-learn.
The reported imbalance in the distribution of listings
among categories causes an imbalance in the labeled cat-
egories of our ground truth. On the one hand, we have
nearly 25% of listings labeled as “other” and around 45%
labeled as one of B2C products or services. On the other
hand, we have a large portion of the rest of our ground
truth listings (30%) that are labeled as “cash-out” list-
ings (25%). We mitigate the negative impact of this im-
balance on our classiﬁcation results by re-sampling our
ground truth listings by the SMOTE (Synthetic Minor-
ity Over-sampling Technique) method, thereby increas-
ing the cardinality of each category to match the size of
the largest labels; this is a standard technique towards
improving algorithmic fairness. Due to the implicit op-
timization of our classiﬁer, this over-sampling method
allows the model to carve broader decision regions, lead-
ing to greater coverage of the minority class [14].
Because of the nature of listings that cover multiple
categories, e.g. bundled goods, we anticipate some clas-
siﬁcation errors. It is however important to distinguish
between errors where the item listing is classiﬁed as
“other” (false negative) from acceptable approximations,
e.g., a listing that includes access to a botnet bundled
with malware and is classiﬁed as a botnet. The ﬁrst ex-
ample denotes a classiﬁcation error, while the second is a
listing that truly is a combination of multiple cybercrime
components. Our main goal is therefore to prevent cy-
bercrime component listings, like malware, from ending
up in “other” and vice versa.
We evaluate the performance of our classiﬁer in Fig-
ure 3. In this normalized confusion matrix, each row rep-
resents the instances in an actual category while each col-
umn represents the instances in a predicted category. All
correct predictions are in the diagonal of the table (num-
bers denote recall). The average precision is 0.78 and
the average recall is 0.76, denoting some confusion be-
tween cybercrime components categories. However, the
classiﬁer meets our goal of avoiding confusion between
cybercrime components and “other” listings.
Figure 3: Classiﬁer normalized confusion matrix
4.5 Post-processing
The heuristic for dealing with holding prices [40] used
in pre-processing does not correct situations where all
instances of a listing among our snapshots were either
only seen with a holding price, or in some cases do not
exceed a set maximum of $10,000. To get an idea of
how frequently this happens, we looked into items priced
above $5,000. We manually identiﬁed 12 listings which
received a total of 118 pieces of feedback at holding
prices. In one case we found the correct price from a cus-
tomer commenting “good product for $10”. The remain-
ing 11 listings seemed clear instances of holding prices,
and were removed, as we had no information about the
true sales price.
After examining holding prices, we found some in-
stances of misclassiﬁed drug listings in categories of cy-
bercrime components (false positives). To correct this,
we ﬁrst removed 12 Xanax listings that we encountered
when inspecting the holding prices. To ﬁnd additional
misclassiﬁed drug listings, we leveraged the distinctive
features of drug listings, namely the unique terminology
used to list the quantity of drugs offered, e.g., “grams,”