decryption private-key xu to be the same in the underlying
Elgamal proxy encryption [21] for all subscribers. That is,
for all subscribers u, xu + su = K. This property allows
individual subscribers to decrypt messages with their own
decryption private keys for messages encrypted with the
list’s public key. Moreover, SELS splits the encryption step
of Elgamal proxy encryption into two operations, which
we denote as E and T respectively, as explained below.
Figure 1 illustrates how SELS works under our termi-
nology. The sender Elgamal-encrypts (E) a message m un-
der encryption public-key y, where y = gx for some group
generator g and secret key x, and sends the resulting ci-
phertext c = (A, B) = (gr, myr) to the list server, where
r is the randomness used. The list server transforms (T )
c into another ciphertext c0 = (A0, B0) = (A, BAs) using
its transformation secret-key s, where s = K − x. Note
that c0 is equivalent to the Elgamal encryption of m un-
der another encryption public key ˜y, where ˜y = ygs =
gx+s = gK. The list server re-encrypts (R) ciphertext
c0 using its re-encryption secret-keys s1 and s2 for sub-
1 and c00
scribers Alice and Bob into c00
2 respectively, where
c00
i ) = (A0, B0/A0si). The server then sends
i = (A00
1 and c00
the resulting re-encrypted ciphertexts c00
2 to the cor-
responding users. Finally each of them decrypts (D) using
his or her decryption private-key (x1 for Alice and x2 for
Bob) to recover message m as B00
xi. As mentioned
earlier, the two steps R and D amount to the Elgamal de-
cryption under private key K.
i /A00
i , B00
i
To subscribe users to a list, SELS describes a protocol
where the list manager interacts with the list server in such
a way that K is not known to any single party. Therefore,
if the list manager or a subscribed user do not collude mali-
ciously with the list server, the list server is unable to obtain
K and thereby decrypt messages sent to the list. Further-
more, the list server cannot subscribe users to the list with-
out interacting with the list manager, which is responsible
for managing list membership.
Theorem 1 in [23] states that if Elgamal is secure
against chosen-plaintext attacks by any probabilistic poly-
time (PPT) adversary, then so is SELS. As we will see,
SELS can be adapted to construct PEAPOD for policies
that contain only a single attribute. It is not immediately
clear, however, how SELS can be used to support com-
plex policies based on boolean combinations of attributes,
and how to support policy privacy. To achieve its goals,
PEAPOD therefore also makes use of other tools such as
homomorphic encryption.
Homomorphic encryption An encryption scheme (K, E,
D)5 is homomorphic if there exists an operation ⊗ on ci-
phertexts such that for any key pair (x, y) generated by K
and any messages m1, m2 in the message space M, we
have that Dx(Ey(m1) ⊗ Ey(m2)) = m1 ⊕ m2, where ⊕
is an operation on messages. In other words, ciphertexts
for m1 and m2 can be combined to obtain a ciphertext
for m1 ⊕ m2 without access to m1 and m2. More gen-
erally, the homomorphic property allows meaningful ma-
nipulation of ciphertexts without the knowledge of the un-
derlying plaintexts. Applications of homomorphic encryp-
tion include electronic voting [19, 18, 2], electronic auc-
tions [1, 34, 25, 11], Mix-nets [12, 16], and veriﬁable en-
cryption [28].
Elgamal encryption is one example of homomorphic
encryption. Consider ci = Ey(mi) = (gri, miyri) =
Deﬁne ⊗ as (A1, B1) ⊗
(Ai, Bi) for i = 1, 2.
(A2, B2) 7→ (A1 · A2, B1 · B2). Then Dx(c1 ⊗ c2) =
Dx(gr1+r2, m1m2yr1+r2) = m1 · m2. Paillier’s cryptosys-
tem [27] is another example.
Policies and attributes
In PEAPOD, policies are non-
monotonic boolean formulae in disjunctive normal form
5K, E, D are the key generation, encryption, and decryption algorithms
respectively
ETDDmmmcSenderList ServerSubscriberssyRRAliceBobc!c!!1c!!2s1s2x1x2encryption public-keytransformation secret-keyre-encryption secret-keysdecryption private-keys(DNF), i.e. disjunctions (“ORs”) of one or more clauses,
which are in turn conjunctions (“ANDs”) of one or more
literals, where a literal is either an attribute or its negation.
We argue that most policies are naturally DNF in form as
senders usually have a few classes of intended recipients in
mind (a disjunction of clauses), where each class is deﬁned
by a set of attributes (a clause).
To simplify the description of our system, we repre-
sent a clause within a policy using the symbols X, ×
and ∗, which denote respectively attributes in the system
that are “required” (the X-attributes), “forbidden” (the ×-
attributes) and “irrelevant” (the ∗-attributes). For exam-
ple, if we reconsider the matchmaking example mentioned
earlier and imagine the scenario in which there are alto-
gether ﬁve attributes in the system: {male, college
graduate, age in 30’s, smoker, pet lover},
then the clause “male ∧ age in 30’s ∧ ¬smoker”
is represented by hX,∗, X,×,∗i. Any clause in a non-
monotonic boolean expression can be represented by such
a tuple, which indicates the nature of each attribute in
the clause (required, forbidden, or irrelevant). Recall that
policies are a disjunction of multiple clauses. For ex-
ample, the policy “(male ∧ age in 30’s) ∨ (male
∧ ¬smoker)” would be represented by a set of the two
clauses: {hX,∗, X,∗,∗i,hX,∗,∗,×,∗i}.
We say that an attribute set A satisﬁes a policy P =
{C1, C2, . . . , Cn}, if there exists a clause Ci ∈ P for which
A contains all the X-attributes and does not contain any of
the ×-attributes in Ci. When we say a user Bob satisﬁes a
policy, we mean the attribute set possessed by Bob satisﬁes
the policy.
2.2. Security Notions
As hinted in Section 1, designing a system for publishing
data with both policy privacy and credential privacy faces a
number of security challenges. To rigorously reason about
the security of PEAPOD, we need to formalize various se-
curity notions. Deﬁnitions 1 and 3 provide ideal security
models for conﬁdentiality and policy privacy under which
PEAPOD is immune to adaptive chosen ciphertext attacks
and user coalition attacks (where users collude by “pooling
in” their credentials). Our construction is based on Elgamal
encryption, and therefore is not immune to adaptive cho-
sen ciphertext attacks. Moreover, our scheme provides se-
curity against only restricted versions of coalition attacks.
Deﬁnitions 2 and 5 describe the models under which our
construction of PEAPOD is secure.
Conﬁdentiality Ideally, when given a ciphertext de-
posited at or retrieved from the server, individual entities
(including the Server) other than the intended recipients
speciﬁed by the associated policy should not be able to
learn anything about the underlying plaintext message (ex-
cept perhaps its size). Such a guarantee should hold even
if users who are not intended recipients collude arbitrarily.
Moreover, when attempting to break the conﬁdentiality, an
adversary should be given the chance to study the decryp-
tion of arbitrary retrieved ciphertexts. Formally speaking,
we deﬁne the conﬁdentiality of PEAPOD as follows.
Deﬁnition 1 (C-IND-CCA2-UCA) A PEAPOD system
has Ciphertext Indistinguishability against Adaptive Cho-
sen Ciphertext Attack and User Coalition Attack (C-IND-
CCA2-UCA) if no PPT adversary A can win the follow-
ing game against the challenger C with probability non-
negligibly greater than 1/2.
1. (Setup Phase.) C sets up the PEAPOD system and
makes all public parameters such as the attributes in
the system available to A.
2. (Probing Phase I.) A may corrupt the Server if no user
has been corrupted, thereby learning its secrets and
acting on behalf of it. If the Server has not been cor-
rupted, then A has the ability to arbitrarily and adap-
tively: (a) register a new honest user into the system,6
(b) corrupt an honest user, thereby learning his or her
secrets and acting on behalf of him or her, (c) make de-
posit and retrieval requests to the Server, and (d) ask
honest users for decrypting any retrieved ciphertexts.
3. (Challenge Phase.) At some point, A outputs two
messages M0, M1 of equal length and a policy P ∗ of
his choice under the following restriction:
Restriction 1: None of the corrupted users satisﬁes
the policy P ∗ throughout the game.
Then C ﬂips a fair coin b ∈R {0, 1} and encrypts mes-
sage Mb under policy P ∗ according to the sender’s
encryption algorithm. The resulting ciphertext C∗ is
returned to A.
4. (Probing Phase II.) A may do whatever he is allowed
to in Probing Phase I, except that (a) Restriction 1 ap-
plies, and (b) A may not ask any honest user for de-
crypting C∗.
5. (End-Game Phase.) Eventually A outputs his guess
˜b ∈ {0, 1} on b. A wins if and only if ˜b = b.
(cid:3)
The above deﬁnition of conﬁdentiality is based on the
well-known IND-CCA2 security model for conventional
encryption schemes.
It captures coalition resistance be-
cause the adversary is allowed to corrupt an arbitrary set of
users as long as none of them satisﬁes the challenge policy.
6A also gets to decides the set of attributes possessed by the user being
registered. For simplicity, we assume a user immediately acquires all the
credentials for his or her attributes upon registration.
This models the real-world attack scenario when a coalition
of users who individually do not satisfy the policy tries to
“pool in” their credentials and gain knowledge about the
message.
The PEAPOD system we propose has a weaker form of
coalition-resistance, since some coalitions of users can pool
in their credentials and decrypt the message. We say that a
coalition of users “collectively satisﬁes policy P ” if there
exists a subset of users in the coalition such that the union
A of their attributes satisﬁes the policy. In our construction,
a coalition of users can decrypt a message with policy P
only if they collectively satisfy the policy P . The following
deﬁnition captures the conﬁdentiality our system provides,
which is secure against chosen plaintext attack and the re-
stricted form of coalition attack just mentioned.
Deﬁnition 2 (C-IND-CPA-RUCA) PEAPOD has Ci-
phertext
Indistinguishability against Chosen Plaintext
Attack and Restricted User Coalition Attack (C-IND-CPA-
RUCA) if no PPT adversary A can win the following game
against the challenger C with probability non-negligibly
greater than 1/2.
The game is the same as that in Deﬁnition 1, except that
(1) Ability 2(d) is removed, i.e., A may not ask any honest
users for decrypting any retrieved ciphertext, and (2) Re-
striction 1 is modiﬁed as:
Restriction 10: None of the coalitions of corrupted users
collectively satisﬁes the policy P ∗ throughout the game.
(cid:3)
Policy-privacy Policy privacy hides the policies under
which messages are encrypted from both the server and the
recipients. Ideally, the server or any recipient Bob (intended
or not) should not be able to gain any knowledge of the
policy except that Bob knows whether he satisﬁes the pol-
icy. As with conﬁdentiality, ideally no coalition of users
(who individually do not satisfy the policy) should be able
to gain any knowledge about the policy (except perhaps its
maximum size). This notion of policy privacy is captured
formally by the following deﬁnition.
Deﬁnition 3 (P-IND-CCA2-UCA) A PEAPOD system
has Policy Indistinguishability against Adaptive Chosen Ci-
phertext Attack and User Coalition Attack (P-IND-CCA2-
UCA) if no PPT adversary can win the following game
against the challenger C with probability non-negligibly
greater than 1/2.
1. (Game Setup.) Same as that in Deﬁnition 1.
2. (Probing Phase I.) Same as that in Deﬁnition 1.
3. (Challenge Phase.) At some point, A sends to C
a message M∗ and two valid policies P0, P1 of his
choice under the following restriction:
Restriction 2: Either all corrupted users satisfy none
of the policies P0 and P1 or they all satisfy both poli-
cies throughout the game.
Then C ﬂips a fair coin b ∈R {0, 1} and encrypts the
message M∗ under policy Pb according to the sender’s
encryption algorithm. The resulting ciphertext C∗ is
returned to A.
4. (Probing Phase II.) A may do whatever he is allowed
to in Probing Phase I, except that (a) the Restriction
2 applies, and (b) A may not ask any honest user for
decrypting C∗.
5. (End Game.) Same as that in Deﬁnition 1.
(cid:3)
We now introduce a weaker form of policy privacy,
which we call clausal policy privacy. We believe that other
constructions of PEAPOD, may be able to provide clausal
policy privacy at best, and therefore emphasize this weaker
intermediate model before we describe the security model
for our construction in Deﬁnition 5. It is weaker because
an intended recipient is able to infer information more than
merely whether he or she satisﬁes the policy. Precisely, that
piece of extra information is the number of clauses a re-
cipient satisﬁes. This makes two policies with a different
number of satisfying clauses distinguishable by an intended
recipient. Hence policy indistinguishability is only among
those policies with the same number of satisfying clauses.
The following is a formal deﬁnition of this notion.
Deﬁnition 4 (C-P-IND-CCA2-UCA) A PEAPOD system
has Clausal Policy Indistinguishability against Adaptive
Chosen Ciphertext Attack and User Coalition Attack (C-
P-IND-CCA2-UCA) if no PPT adversary can win the fol-
lowing game against the challenger C with probability non-
negligibly greater than 1/2.
The game is the same as that in Deﬁnition 3, except that
Restriction 2 is modiﬁed as:
Restriction 20: All corrupted users satisfy the same number
of clauses in both policies P0 and P1 throughout the game.
(cid:3)
In our construction, an individual recipient of a message
cannot gain any knowledge about the policy other than the
number of clauses that he or she satisﬁes and whatever can
be inferred from that fact. Therefore our construction pro-
vides clausal policy privacy if the users do not collude. We
do not, however, provide coalition resistance for policy pri-
vacy. This is because we try to provide policy privacy even
when the message can be decrypted. Recall that in some
cases coalitions of users can pool in their credentials to de-
crypt ciphertexts. In that case, the coalition will be able to
gain knowledge about the policy. Our construction, there-
fore, is secure under the following (non-CCA2 and non-
coalition-resistant) model.
Deﬁnition 5 (C-P-IND-CPA) A PEAPOD system has
Clausal Policy Indistinguishability against Chosen Plain-
text Attack (C-P-IND-CPA) if no PPT adversary can win
the following game against the challenger C with probabil-
ity non-negligibly greater than 1/2.
The game is the same as that in Deﬁnition 4, except that
the adversary A (1) may not ask any honest users for de-
crypting any retrieved ciphertext, and (2) may corrupt at
(cid:3)
most 1 honest user.
We discuss the implications of coalition and inference
attacks on conﬁdentiality and policy privacy in Section 4.
Credential privacy Credential privacy protects the pri-
vacy of the recipient from the sender. Speciﬁcally, creden-
tial privacy hides from the sender the credentials that the
recipient possesses and thus uses when attempting to de-