title:Shunting: a hardware/software architecture for flexible, high-performance
network intrusion prevention
author:Jos&apos;e M. Gonz&apos;alez and
Vern Paxson and
Nicholas Weaver
Shunting: A Hardware/Software Architecture for
Flexible, High-Performance Network Intrusion Prevention
Jose M Gonzalez
International Computer
Science Institute
1947 Center Street #600
Berkeley, CA, 94720
Vern Paxson
International Computer
Science Institute
1947 Center Street #600
Berkeley, CA, 94704
Nicholas Weaver
International Computer
Science Institute
1947 Center Street #600
Berkeley, CA, 94704
PI:EMAIL
PI:EMAIL
nweaver@ic s i . ber keley. edu
ABSTRACT
Stateful, in-depth, inline trafﬁc analysis for intrusion detection and
prevention is growing increasingly more difﬁcult as the data rates of
modern networks rise. Yet it remains the case that in many environ-
ments, much of the trafﬁc comprising a high-volume stream can,
after some initial analysis, be qualiﬁed as of “likely uninteresting.”
We present a combined hardware/software architecture, Shunting,
that provides a lightweight mechanism for an intrusion prevention
system (IPS) to take advantage of the “heavy-tailed” nature of net-
work trafﬁc to ofﬂoad work from software to hardware.
The primary innovation of Shunting is the introduction of a sim-
ple in-line hardware element that caches rules for IP addresses and
connection 5-tuples, as well as ﬁxed rules for IP/TCP ﬂags. The
caches, using a highest-priority match, yield a per-packet decision:
forward the packet; drop it; or divert it through the IPS. By manip-
ulating cache entries, the IPS can specify what trafﬁc it no longer
wishes to examine, including directly blocking malicious sources
or cutting through portions of a single ﬂow once the it has had an
opportunity to “vet” them, all on a ﬁne-grained basis.
We have implemented a prototype Shunt hardware design using
the NetFPGA 2 platform, capable of Gigabit Ethernet operation.
In addition, we have adapted the Bro intrusion detection system to
utilize the Shunt framework to ofﬂoad less-interesting trafﬁc. We
evaluate the effectiveness of the resulting system using traces from
three sites, ﬁnding that the IDS can use this mechanism to ofﬂoad
55%–90% of the trafﬁc, as well as gaining intrusion prevention
functionality.
Categories and Subject Descriptors
C.2.0 [General]: Security and protection
General Terms
Security
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’07, October 29–November 2, 2007, Alexandria, Virginia, USA.
Copyright  2007  ACM  978-1-59593-703-2/07/0010  ...$5.00.
Keywords
Intrusion Detection, Intrusion Prevention, Hardware Acceleration,
FPGA, NIDS, NIPS
1.
INTRODUCTION
Stateful, in-depth, inline trafﬁc analysis for intrusion detection
and prevention is growing increasingly more difﬁcult as the data
rates of modern networks rise. One point in the design space for
high-performance network analysis—pursued by a number of com-
mercial products—is the use of sophisticated custom hardware. For
very high-speed processing, such systems often cast the entire anal-
ysis process in ASICs.
In this work we pursue a different architectural approach, Shunt-
ing, which marries a conceptually quite simple hardware device
with an Intrusion Prevention System (IPS) running on commodity
PC hardware. Our goal is to keep the hardware both cheap and
readily scalable to future higher speeds; and also to retain the un-
paralleled ﬂexibility that running the main IPS analysis in a full
general-computing environment provides.
The Shunting architecture uses a simple in-line hardware ele-
ment that maintains several large state tables indexed by packet
header ﬁelds, including IP/TCP ﬂags, source and destination IP
addresses, and connection tuples. The tables yield decision val-
ues the element makes on a packet-by-packet basis: forward the
packet, drop it, or divert (“shunt”) it through the IPS (the default).
By manipulating table entries, the IPS can, on a ﬁne-grained basis:
(i) specify the trafﬁc it wishes to examine, (ii) directly block ma-
licious trafﬁc, and (iii) “cut through” portions or complete trafﬁc
streams once it has had an opportunity to “vet” them.
For the Shunting architecture to yield beneﬁts, it needs to oper-
ate in an environment for which the monitored network trafﬁc has
the property that—after proper vetting—much of it can be safely
skipped. This property does not universally hold. For example, if
a bank needs to examine all Web trafﬁc involving its servers for
regulatory compliance, then a monitor in front of one of the bank’s
server farms cannot safely omit a subset of the trafﬁc from analysis.
In this environment, Shunting cannot realize its main performance
beneﬁts, and the monitoring task likely calls for using custom hard-
ware instead.
However, in many other environments we expect Shunting to po-
tentially deliver major performance gains. Our basis for this con-
jecture rests in the widely documented “heavy tail” nature of most
forms of network trafﬁc [19, 21, 8, 29, 28, 7], which we might ex-
press as “a few of the connections carry just about all the bytes.”
The key additional insight is “... and very often for these few large
139connections, the very beginning of the connection contains nearly
all the information of interest from a security analysis perspective.”
We argue that this second claim holds because it is at the begin-
ning of connections that authentication exchanges occur, data or
ﬁle names and types are speciﬁed, request and reply status codes
conveyed, and encryption is negotiated. Once these occur, we have
seen most of the interesting facets of the dialog. Certainly the re-
mainder of the connection might also yield some grist for analysis,
but this is generally less likely, and thus if we want to lower anal-
ysis load at as small a loss as possible of information relevant to
security analysis, we might best do so by skipping the bulk of large
connections. In a different context, the “Time Machine” work by
Kornexl and colleagues likewise shows that in some environments
we can realize major reductions in the volume of network trafﬁc
processed, by limiting the processing to the ﬁrst 10–20 KB of each
connection [14].
As a concrete example, consider an IPS that monitors SSH traf-
ﬁc. When a new SSH connection arrives and the Shunt fails to ﬁnd
an entry for it in either of its per-address and per-connection tables,
it executes the default action of diverting the connection through the
IPS. The IPS analyzes the beginning of the connection in this fash-
ion. As long as it is satisﬁed with the dialog, it reinjects the packets
forwarded to it so that the connection can continue.
If the con-
nection successfully negotiates encryption, the IPS can no longer
proﬁtably analyze it, so it downloads a per-connection table entry
to the Shunt specifying that the action for the connection in the
future is “forward.”
For heavy-tailed connections, this means a very large majority
of the connection’s packets will now pass through the Shunt device
without burdening the IPS with any further analysis load. On the
other hand, if the IPS is dissatisﬁed with some element of the ini-
tial dialog, or with one of the hosts involved, it downloads a “drop”
entry to terminate the connection. Note that by providing for rein-
jection, we can promote an intrusion detection system into an intru-
sion prevention system, one that does not merely detect attacks but
can block them before they complete. Reinjection also allows the
IPS to normalize trafﬁc [11] to remove ambiguities that attackers
can leverage to evade the IPS [22]. Finally, if the IPS is unable to
resolve whether the connection can progress without further analy-
sis, it simply leaves the Shunt’s tables unmodiﬁed and continues to
receive the connection’s packets due to the Shunt’s default action.
Put more simply, we can frame Shunting as providing a form
of ﬁltering that is particularly well suited to preserving as much
security-relevant information as possible given the need to discard
large volumes of trafﬁc. In this paper we present evidence to back
up this assertion, and discuss numerous subtle points that arise
when realizing Shunting in practice. We present the Shunting ar-
chitecture, based on ﬁxed-size table lookups and a shared-memory
interface to the IPS that greatly simpliﬁes the hardware implemen-
tation because it allows the hardware to make imperfect decisions.
Since the Shunt requires only ﬁxed table lookups on header ﬁelds,
we can implement it readily in a small amount of custom hardware.
We modiﬁed the Bro intrusion detection system [20] to take ad-
vantage of the Shunt, giving it more direct IPS capabilities than
it has had in the past (which involved enabling it to update router
ACL entries by logging into the router), and implemented sample
modiﬁcations to its analysis scripts. Testing this system using full
packet traces from a Gbps-connected site with 1000s of hosts shows
that Bro can leverage a modest Shunt conﬁguration to ofﬂoad 55%–
90% of the trafﬁc. This in turn suggests that the Shunt architecture
should enable Bro to process a Gbps stream with ease when using
a Shunting device coupled with a general-purpose, commodity PC
platform.
We have implemented the Shunt in hardware on the NF2 [17]
FPGA system. While our board does not yet support all of the
architecture’s features, we can use it to evaluate the main mecha-
nisms, and it includes sufﬁcient functionality to ensure the feasi-
bility of processing data—including using a general purpose, com-
modity PC for rich IPS analysis—at Gbps rates for trafﬁc streams
with realistic packet sizes.
We begin in Section 2 with a survey of related work. Section 3
gives an overview of the Shunting architecture and how it lends
itself to fast operation in hardware. We then describe in Section 4
a prototype hardware implementation that realizes this promise. In
Section 5 we discuss general issues with integrating Bro, and in 6
the decisions we made regarding how to enhance Bro’s analysis to
leverage the Shunt. We evaluate the effectiveness of Shunting, as
well as sensitivities to implementation parameters, in Section 7. In
Section 8 we discuss ongoing work, and we conclude in Section 9.
2. RELATED WORK
Intrusion detection systems (IDSs) monitor host or network ac-
tivity to spot attempted or successful misuse of computers. Such
misuses might constitute attacks or simply violations of policy re-
strictions. While there is a vast literature on IDSs, we touch on it
here only in a limited fashion because our Shunting architecture for
the most part is indifferent to the particular mechanisms of the IDS
it supports. Indeed, we aim for Shunting to provide cheap hardware
assistance for a wide range of network-based IDSs.
That said, part of our discussion concerns implementing Shunt-
ing in conjunction with a particular IDS, the open-source Bro sys-
tem [20]. Bro provides an event-oriented framework that couples
generic (non-security-speciﬁc) analysis of network trafﬁc at layers
3, 4 and 7, with an interpreted, domain-speciﬁc “policy script” lan-
guage used to express higher level analysis triggered by the occur-
rence of particular events. The ability to script this latter analysis
makes it particularly easy to extend Bro to work in conjunction with
a shunting device.
When an IDS is capable of not only detecting an attack but also
blocking it to prevent it from succeeding, it is termed an intrusion
prevention system (IPS). Since Shunting directly enables IPS func-
tionality by diverting packets through an intrusion analyzer rather
than simply giving it a passive copy of the trafﬁc stream, in this
paper we will generally use the term IPS to describe the system
with which the Shunt interacts, and only use the term IDS when
the distinction between detection and prevention is signiﬁcant.
The prior work most directly related to ours concerns other
approaches for using hardware to augment
IPS capabilities.
Kruegel and colleagues developed an architecture for accelerating
signature-based systems using a 4-step process that provides mul-
tiple, parallel IPS analyzers each with a subset of the total trafﬁc
that conforms to a small superset of the trafﬁc it needs to detect
particular attacks [15]. Input trafﬁc ﬂows into a simple hardware
device (the “scatterer”) that divides the trafﬁc in a round-robin fash-
ion among a group of classiﬁers (the “slicers”). Each slicer checks
every packet to see whether it might match one or more signatures.
If so, it forwards the packet to the appropriate “reassembler,” which
reassembles the packet stream before forwarding the streams to the
appropriate IPS engine(s).
Another
technique
for
proposed
commonly
high-speed
processing—generally oriented towards IDS rather
than IPS
functionality—is “pushing processing into the NIC”: using a
network interface to ofﬂoad much of the processing required for
passive packet capture and analysis.
Shunting resembles this
concept, although our processing model is very different and
involves explicit inline/diversion decisions. Deri [9] proposes
using a router (Juniper M-series, which allows for trafﬁc ﬁltering
based on header ﬁelds [16]) as a smart Network Interface Card
(NIC), performing generic trafﬁc accounting and simple packet
ﬁltering and sampling, and sending the ﬁltered/sampled stream to a
Linux host. The Intel IXP family of “network processors” provides
a framework to perform in-NIC packet-processing [13]. The IXP
series is composed of multiple miniature processors that operate in
parallel, along with a StrongARM control processor [16]. The IXP
has been proposed as a means to accelerate Snort signature match-
ing [2] by implementing portions of the signature matching and
other pieces on the Snort stack. Indeed, there is a large literature
on implementing signature-matching in custom hardware, but this
work is not applicable to accelerating IPSs in general, other than
for ofﬂoading the signature matching they perform.
Using Endace’s DAG 4 cards [3], Iannaconne and colleagues
present a network adapter that permits passive monitoring of OC-
192 links (10 Gbps) [12]. The authors use the DAG card’s FPGA
to compress packet headers into ﬂow traces, and send only those
ﬂow traces to the PC host. The authors use a hashed, limited-size
connection table to store the ﬂow traces, arguing that, with the help
of fast PCI buses (64 bits, 66 MHz), it is possible to monitor IP,
TCP, and UDP headers on 10 Gbps links, enabling header-only IDS
analysis. However, clearly such analysis cannot extend to inspec-
tion of application-level semantics, since the available information
does not include transport payloads.
The SCAMPI project also proposes using a smart network
adapter to limit the amount of trafﬁc that reaches the host in
packet capture scenarios [4, 5]. SCAMPI runs on several differ-
ent architectures, including Intel IXP family of network proces-
sors, Endace’s DAG cards, and their own network adapter, called
“COMBO.” COMBO adapters perform systematic (deterministic)
and probabilistic 1-in-N sampling, address- and port-based sam-
pling, payload string searching, generic ﬂow-state accounting and
reporting, and packet ﬁltering using FPL-2 (an extended, BPF-like
language).
In contrast to previous approaches, Shunting is based on cou-
pling an IPS running in a general-purpose computing environment
with a separate hardware device, allowing the IPS to control the
processing load it sees at the granularity of individual streams. In
addition, Shunting achieves this with minimal assumptions about
the IPSs overall operation, allowing the specialized hardware to re-
main (i) broadly applicable, and (ii) simple and cheap.
3. THE SHUNT ARCHITECTURE
In this section we present the shunting architecture. We begin
with an overview of the general architecture and the motivation be-
hind it (§3.1), and then discuss in detail the structure of the Shunt
device’s tables (§3.2), which act as a cache for the IPS. We ﬁnish
in §3.4 with an important reﬁnement to the architecture, forward-N.
3.1 Overview
Inline trafﬁc processing is a particularly demanding activity, be-
cause the speed of the processing directly limits overall network
performance.
If the inline element cannot keep up with the rate
at which new trafﬁc arrives, it eventually will exhaust its buffering
capacity and drop some of the trafﬁc, affecting the quality of un-
reliable connections and imposing a major impairment to reliable
trafﬁc due to the transport protocol’s congestion response.
At high speeds (Gbps), using a commodity PC for inline packet
processing becomes very difﬁcult. Simply monitoring the trafﬁc
stream requires 1 Gbps of bandwidth across the I/O bus and 1 Gbps
bandwidth to memory. In addition, if the monitor operates at user
level, unless we can exploit memory mapping we need an addi-
tional 1 Gbps of internal memory bandwidth. If we not only mon-
itor but also forward, then PC inline for a bidirectional Gbps link
requires 4 Gbps of I/O bandwidth and 4 Gbps of memory band-
width (with perhaps another 4 Gbps memory bandwidth if perform-
ing user-level analysis), leaving little additional resources for pro-
cessing. Furthermore, 10 Gbps Ethernet in early deployment, the
problem is growing worse.
Figure 1 shows the Shunting architecture we propose for en-
abling use of inexpensive, highly ﬂexible commodity PCs for inline
packet processing. A Shunt-based system consists of two elements,
a software packet processor (the Analysis Engine) and a hardware
forwarding element (the Shunt itself).
The Analysis Engine, such as an IPS, views the Shunt as a nor-
mal Ethernet device, except that the Shunt has a series of tables
that act as a cache for rules. The Shunt device treats these tables
as read-only; it is the responsibility of the Analysis Engine to both
manage the cache and to resolve cache misses by maintaining more
comprehensive state.
When a packet arrives, the device chooses from one of three pos-
sibilities: (a) forward the packet to the opposite interface (thick,
solid line), (b) drop it (thin, dashed line), or (c) divert (shunt) it
to the analyzer (thin, dotted line) by examining the packet header
and selecting the highest priority action. For packets diverted to the
Analysis Engine, the analyzer makes another decision regarding the
packet’s fate: (c.1) inject the packet back to the network interface,
or (c.2) drop it. It may optionally at this point also update the Shunt
device’s tables to ofﬂoad similar decisions in the future.
In particular, the Analysis Engine must understand that the Shunt
hardware is a cache: if a connection is ofﬂoaded to the Shunt, the
Analysis Engine must still maintain state for the connection, since
it may be necessary to ﬂush the cache entry and return to diverting
the connection’s trafﬁc through the Analysis Engine.