For the example of circular linked lists, the decoder allocates a
node for each node in the original linked list and at the same time
adjusts pointer values according to the buffer map M.
Other issues and LLVM implementation. The previous algo-
rithm shows how to marshall/unmarshall one argument, but our
implementation marshalls and unmarshalls all arguments at the
same time. This is important, not just for efficiency, but for correct-
ness in the case when multiple pointer arguments alias the same
buffer; the buffer should be encoded just once so that the receiver
can recreate aliasing. Essentially, this approach treats multiple ar-
guments as a value of a tuple type.
When a pointer is passed from a caller to a callee partition,
PtrSplit performs deep copying of pointer data. Since the callee may
modify such data, it is necessary to copy back the entire pointer
data from the callee and caller at the end of the RPC call. This
implements the copy-in and copy-out semantics for pointer data,
which is compatible with single-threaded code.
After marshalling, arguments of a function call are encoded as
a byte array, which is sent to the receiver via the help of an RPC
library. We use the popular TI-RPC library [27] for sending and
receiving byte arrays.
In our system, deep copying of pointer data applies to only user-
space data pointers. Our implementation maintains a whitelist of
other kinds of pointers that are not deep copied, including pointers
to OS-kernel data structures and pointers to code. It is not possible
to deep copy these pointers; therefore we adopt the opaque-pointer
approach for them. For instance, when one partition creates a file
pointer through the OS, our marshalling wraps the file pointer as
an opaque object without performing deep copying. The receiver is
transformed to send the file pointer back to the sender for operating
on the underlying file. For a code pointer that crosses the boundary,
our system also wraps it as an opaque pointer with a runtime tag;
an indirect call via a code pointer is instrumented to decide whether
the code pointer is local or remote before performing a local or an
RPC call.
7 EVALUATION
The latest versions of LLVM do not support DSA, the alias analysis
that PtrSplit uses. Therefore, we implemented PtrSplit in LLVM 3.5,
an older version of LLVM. SoftBound’s public release only supports
222(,8)ppp111(,8)ppp1n2n111(,8)ppp2p1p18p28pSession K3:  Program AnalysisCCS’17, October 30-November 3, 2017, Dallas, TX, USA2367(n, int, l2)
(struct {id1 = v1, . . . , idn = vn}, t, ln+1)
(v, tn, l2)
((b′ + p − b)(b′,e′), t1∗, l3)
((b′ + p − b)(b′,e′), t1∗, l2)
if dec_typ(l) = (int, l1) and dec_int(l1) = (n, l2)
if dec_typ(l) = (t, l1) and t = struct {id1 : t1, . . . , idn : tn}
and decodeM(li) = (vi , ti , li +1) for i ∈ [1..n]
if dec_typ(l) = (tn, l1) and decodeM(l1) = (v, TM(tn), l2)
if dec_typ(l) = (t1∗, l1) and dec_ptr(l1) = (p(b,e), l2)
and (b, e) (cid:60) dom(M) and b′ = alloc(e − b) and
e′ = b′ + e − b and l3 = dec_bufM∪{(b,e)(cid:55)→(b′,e′)}(b′, e′, t1, l2)
if dec_typ(l) = (t1∗, l1) and dec_ptr(l1) = (p(b,e), l2)
and (b, e) ∈ dom(M) and (b′, e′) = M(b, e)
decodeM(l) =
 l2
l
dec_bufM(b, e, t, l) =
if b + size(t) ≤ e and decodeM(l) = (v, t, l1)
and write_mem(b, v) and dec_bufM(b + size(t), e, t, l1) = l2
otherwise
Figure 9: Type-based unmarshalling. Function dec_typ(l) is for decoding a type in the first bytes of l; dec_int(l) for decoding an
integer; dec_ptr(l) for decoding a pointer; alloc(n) for allocating a buffer of size n; write_mem(b, v) for writing v at address b in
memory.
LLVM 3.4; so we had to upgrade its code base to support LLVM 3.5.
Several LLVM passes were added to implement the components
of PtrSplit. We evaluated PtrSplit using a set of benchmarks on a
system running x86-64 Ubuntu 14.04 with the Linux kernel ver-
sion 3.19.0, an Intel Core i5-4590 at 3.3GHz, and 16GB of physical
memory.
The evaluation aims to answer several questions: (1) whether Ptr-
Split can automatically partition realistic C applications and scale
to relatively large C applications, (2) whether the performance over-
head of a partitioned application is acceptable, given the overhead
of performing SPBT and deep copying of RPC data, (3) whether
SPBT significantly reduces the overhead, when compared with a
solution that enforces full spatial memory safety.
We first evaluated with a set of microbenchmarks to validate the
major functionalities of PtrSplit. The programs include the running
example in Fig. 2 and programs that send data structures (including
trees, linked lists, and circular linked lists) over RPC calls.
We then evaluated PtrSplit with a set of security-sensitive pro-
grams and programs from SPECCPU 2006. For each program, we
ran its partitioned version and checked that the partitioned ver-
sion functioned well using the reference data set attached with the
program. During the process, we also measured the performance
overhead of the partitioned version. These experiments are detailed
next.
Security-sensitive programs. We evaluated PtrSplit on four security-
sensitive programs. Considering that all of these programs are
networking programs, which are greatly affected by the network
latency, we used another machine that was in the same LAN as a
remote server. The remote server machine has the same hardware
and OS configuration as the local machine. For each program, we
analyzed its functionality and marked some sensitive data that need
isolation; recall that sensitive data means data of either high secrecy
or low integrity. Then PtrSplit is used to partition these programs
to isolate sensitive code and data into a separate partition. Results
for these programs are presented in Table 1. We next discuss in
detail how experiments were performed for each program.
ssh is a networking utility included in OpenSSH (version: 7.4p1),
which is a suite of utilities based on the SSH protocol. The ssh utility
10
implements the client-side of the SSH protocol. We annotated the
buffer that receives the RSA private key as the sensitive data. We
also declassified the return results of functions sshkey_load_file
and sshkey_load_private; although these functions compute on
sensitive data, their return results are status/error codes, which are
not correlated to sensitive data. (The reason for declassification in
wget and telnet is the same and we will not repeat it when we
discuss those programs.) In total, twelve functions were put into a
sensitive partition. For measuring performance overhead, we used
our partitioned ssh to log in to the server one hundred times.
wget (version: 1.18) is a command-line program for retrieving
files from a remote HTTP or FTP server. We annotated the buffer
for receiving the downloaded file from an FTP server as the sen-
sitive data because the file may contain malicious content. We
also declassified the return results of functions fd_read_body and
skip_short_body. For measuring performance overhead, we down-
loaded a 1KB file from the FTP server one hundred times.
thttpd (version: 2.27) is an open-source http server program. We
chose its authentication file as the sensitive data, and annotated the
corresponding buffer that reads contents from the authentication
file in the source code; a single declassification annotation was
also added to declassify the result of function auth_check. After
separation, five functions that access the authentication-file buffer
were put into a sensitive partition. To measure the average overhead,
we set up a server on the remote machine with our partitioned
thttpd and downloaded a 1KB file on that server multiple times
through a local client.
telnet (version: inetutils-1.9.4) is a networking client utility
based on the telnet protocol. We consider the threat of a remote
entity that pretends to be a server and the client somehow connects
to the fake server (in a phishing attack, e.g.) and the fake server
tries to use a vulnerability to attack the client. To counter the threat,
we annotated the buffer that receives packets from the server as the
sensitive data because the received packets may contain malicious
content. We also declassified the return results of functions telrcv,
ttyflush and process_rings. In total, eleven functions were put
into a sensitive partition. We measured the average performance
overhead of using our partitioned telnet to log in to a remote server
one hundred times.
Session K3:  Program AnalysisCCS’17, October 30-November 3, 2017, Dallas, TX, USA2368Benchmark
SLOC
Sensitive Data
Total/BR pointers
ssh
wget
thttpd
telnet
64,671
61,216
21,925
11,118
private key file
downloaded file
authentication file
received data from server
# of functions/
sensitive functions
1235/12
666/8
145/5
180/11
21020/591
14939/466
3068/189
2068/233
PBT
overhead
45.0%
52.5%
56.3%
74.1%
SPBT
overhead
2.6%
3.4%
3.6%
5.1%
Total
overhead
7.4%
6.5%
8.8%
9.6%
Table 1: Partitioning results of security-sensitive programs. (Abbreviations: "Total pointers": total pointer variables in LLVM-IR; "BR
pointers": bounds-required pointer variables; "PBT": pointer bounds tracking; "SPBT": selective pointer bounds tracking.)
Overall, our experiments showed promising results, shown in
Table 1. For each program, the table lists its lines of source code, the
sensitive data, the total number of functions in the program versus
the number of functions in the sensitive partition computed by
the partitioning algorithm, the total number of pointers (i.e., static
counts of pointer variables) versus the number of Bounds-Required
(BR) pointers computed by SPBT, the performance overhead (com-
pared to the vanilla, uninstrumented program) when full pointer
bounds tracking is applied, the performance overhead when only
SPBT is applied, and the total performance overhead for the parti-
tioned application.
As shown in the table, SPBT is effective at reducing the overhead
of pointer bounds tracking and the overall performance overhead of
the security-sensitive applications is acceptable. They demonstrated
that PtrSplit can be used for partitioning realistic security-sensitive
applications to improve security, with a modest amount of perfor-
mance overhead.
SPECCPU 2006 benchmarks. We then evaluated PtrSplit using
the SPECCPU 2006 C benchmarks. These programs are compute-
intensive benchmarks and are not security-sensitive benchmarks.
However, we felt it is important to evaluate PtrSplit using compute-
intensive benchmarks as they stress test the instrumentation mech-
anism of PtrSplit; furthermore, we would like to compare the perfor-
mance overhead of SPBT with the overhead of full pointer bounds
tracking (PBT) on SPEC benchmarks. For each of the benchmarks,
we randomly selected a global variable, marked it sensitive, and fed
it to PtrSplit; in this experiment, only explicit flows are taken into
account and no declassification is used during partitioning since it
is not for evaluating security but for evaluating the instrumentation
mechanism.
Table 2 presents the experimental results. We note that three
programs (perlbench, gcc, and gobmk) were excluded because Soft-
Bound’s memory-safety instrumentation produces runtime crashes
due to SoftBound’s implementation bugs and PtrSplit’s SPBT im-
plementation is on top of SoftBound. The original SoftBound paper
also did not report results on perlbench and gcc; further, a recent
paper [6] reported the difficulty of instrumenting SPEC benchmarks
using SoftBound. We also excluded mcf because it is a small pro-
gram with 24 functions and any global variable marked as sensitive
would lead to all functions being in one partition (adding declassifi-
cation annotations would produce a separation, but we refrained
from doing so since it is unclear where to declassify based on a
randomly selected global variable).
For SPBT, we can see from the table the total number of point-
ers that require bounds is typically a small percentage of the total
number of pointers in a program (we counted the number of point-
ers statically, based on their types). As a result, the average SPBT
runtime overhead for the benchmarks is 7.2%, which is much lower
than the average overhead of 136.2% for full pointer bounds track-
ing (PBT). This shows the effectiveness of SPBT. Note that milc
has no BR pointers because no pointer data are passed between the
created partitions.
The runtime overhead of PtrSplit comes from two sources: pointer
bounds tracking and data marshalling/unmarshalling for RPC calls.
Table 2 also shows the total runtime overhead. libquantum’s over-
head is rather large; we found that RPC call overhead is positively
correlated to the RPC call frequency. For libquantum, the randomly
selected variable leads to a partitioning with a high RPC call fre-
quency (94 Hz); the RPC call frequency of other benchmarks is
below 3Hz. Choosing a different global variable of libquantum
would lead to a similar result.
To further validate the robustness of our partitioning framework,
for each SPEC benchmark, we built a script that randomly splits
the benchmark’s set of functions into two disjoint sets of functions
and creates a partitioning based on the split. The script was run
multiple times and for each run we checked that the partitioned ap-
plication worked as intended (using the reference data set included
in SPECCPU 2006). Some of these random partitionings created
complex interfaces that required exchange of complex data (structs,
pointers, etc.) and provided good stress tests of PtrSplit’s RPC mech-
anism. Table 3 presents the results. For each benchmark, the table
includes the BR-pointer ratio (the number of BR pointers divided
by the number of total pointers), the SPBT overhead, and the total
overhead, averaged over multiple runs of performing random par-
titioning. The total overhead is on the high side, which indicates
random partitioning would not lead to efficient partitionings.
8 LIMITATIONS AND FUTURE WORK
In this section, we discuss current limitations of PtrSplit and how it
can be extended to address them. PtrSplit’s PDG-based partitioning
algorithm can be extended to produce multiple partitions instead
of just two. Programmers can use attributes for different kinds
of sensitive data (e.g., one for networking data and one for data
retrieved from a database) and then the same reachability-based
algorithm can be used to produce multiple partitions, one for pro-
cessing one kind of sensitive data. It is possible that a function
can access multiple categories of sensitive data, in which case the
function can be duplicated in multiple partitions. Another design
would be to employ a security lattice; all functions that access the
same categories of sensitive data are assigned the same label and
put into their own partition.
11
Session K3:  Program AnalysisCCS’17, October 30-November 3, 2017, Dallas, TX, USA2369Benchmark
SLOC
Total
overhead
24.3%
179.2%
5.3%
10.2%
2.2%
7.1%
26.7%
15.5 %
33.8%