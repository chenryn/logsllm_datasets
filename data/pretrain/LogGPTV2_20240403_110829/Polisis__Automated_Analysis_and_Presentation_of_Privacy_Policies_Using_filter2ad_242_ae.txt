utility of the automatically generated answers. This as-
sessment was done for each of the four different con-
ditions (Retrieval, SemVec, PriBot and Random). We
evaluated the top-3 responses of each QA approach to
each question. Thus, we assess the utility of 360 answers
to 120 questions per approach.
Study Design: We used a between-subject design by
constructing four surveys, each corresponding to a differ-
ent evaluation condition. We display a series of 17 QA
pairs (each on a different page). Of these, 15 are a ran-
dom subset of the pool of 360 QA pairs (of the evaluated
condition) such that a participant does not receive two
QA pairs with the same question. The other two ques-
tions are randomly positioned anchor questions serving
as attention checkers. Additionally, we enforce a mini-
mum duration of 15 seconds for the respondent to eval-
uate each QA pair, with no maximum duration enforced.
We include an open-ended Cloze reading comprehension
Fig. 11: An example of a QA pair displayed to the respon-
dents.
test [55]; we used the test to weed out the responses with
a low score, indicating a poor reading skill.
Participant Recruitment: After obtaining an IRB ap-
proval, we recruited 700 Amazon MTurk workers with
previous success rate >95%, to complete our survey.
With this number of users, each QA pair received eval-
uations from at least 7 different individuals. We com-
pensated each respondent with $2. With an average
completion time of 14 minutes, this makes the average
pay around $8.6 per hour (US Federal minimum wage
is $7.25). While not fully representative of the general
population, our set of participants exhibited high intra-
group diversity, but little difference across the respon-
dent groups. Across all respondents, the average age is
34 years (std=10.5), 62% are males, 38% are females,
more than 82% are from North America, more than 87%
have some level of college education, and more than 88%
reported being employed.
QA Pair Evaluation: To evaluate the relevance for a
QA pair, we display the question and the candidate an-
swer as shown in Fig. 11. We asked the respondents to
rate whether the candidate response provides an answer
to the question on a 5-point Likert scale (1=Deﬁnitely Yes
to 5=Deﬁnitely No), as evident in Fig. 11. We denote a
respondent’s evaluation of a single candidate answer cor-
responding to a QA pair as relevant (irrelevant) if s/he
chooses either Deﬁnitely Yes (Deﬁnitely No) or Partially
Yes (Partially No). We consolidate the evaluations of
multiple users per answer by following the methodology
outlined in similar studies [10], which consider the an-
swer as relevant if labeled as relevant by a certain frac-
tion of users. We took this fraction as 50% to ensure a
majority agreement. Generally, we observed the respon-
dents to agree on the relevance of the answers. Highly
mixed responses, where 45–55% of the workers tagged
the answer as relevant, constituted less than 16% of the
cases.
User Study Results: As in the previous section, we com-
pute the top-k score for relevance (i.e., the portion of
questions having at least one user-relevant answer in the
top k returned answers). Table 4 shows this score for
USENIX Association
27th USENIX Security Symposium    543
Table 4: top-k relevance score by evaluation group.
Group
N
top-k Relevance Score
k = 1
k = 2
k = 3
Random
Retrieval
SemVec
PriBot
180
184
153
183
0.37
0.46
0.48
0.70
0.59
0.71
0.71
0.78
0.76
0.79
0.85
0.89
the four QA approaches with k ∈{ 1, 2, 3}, where PriBot
clearly outperforms the three baseline approaches. The
respondents regarded at least one of the top-3 answers as
relevant for 89% of the questions, with the ﬁrst answer
being relevant in 70% of the cases. In comparison, for
k = 1, the scores were 46% and 48% for the Retrieval
and the SemVec models respectively (p-value <= 0.05
according to pairwise Fishers exact test, corrected with
Holm-Bonferroni method for multiple comparisons). An
avid reader might notice some differences between the
predictive models’ accuracy (Section 8.3) and the users’
perceived quality. This is actually consistent with the ob-
servations from research in recommender systems where
the prediction accuracy does not always match user’s sat-
isfaction [44]. For example, the top-k score metric for
accuracy differs by 2%, -3%, and 6% with respect to the
perceived relevance in the PriBot model. Another ex-
ample is that the SemVec model and the Retrieval have
smaller differences in this study than Sec. 8.3. We con-
jecture that the score shift with SemVec model is due
to some users accepting answers which match the ques-
tion’s topic even when the actual details of the answer
are irrelevant.
9 Discussion
Limitations Polisis might be limited by the employed
privacy taxonomy. Although the OPP-115 taxonomy
covers a wide variety of privacy practices [11], there are
certain types of applications that it does not fully cap-
ture. One mitigation is to use Polisis as an initial step
in order to ﬁlter the relevant data at a high level before
applying additional, application-speciﬁc text processing.
Another mitigation is to leverage Polisis’ modularity by
amending it with new categories/attributes and training
these new classes on the relevant annotated dataset.
Moreover, Polisis, like any automated approach, ex-
hibits instances of misclassiﬁcation that should be ac-
counted for in any application building on it. One way to
mitigate this problem is using conﬁdence scores, similar
to that of Eq. (3) to convey the (un)certainty of a reported
result, whether it is an answer, an icon, or another form of
short notice. Last but not least, Polisis is not guaranteed
to be robust in handling an adversarially constructed pri-
vacy policy. An adversary could include valid and mean-
ingful statements in the privacy policy, carefully crafted
to mislead Polisis’ automated classiﬁers. For example,
an adversary can replace words, in the policy, with syn-
onyms that are far in our embeddings space. While the
modiﬁed policy has the same meaning, Polisis might mis-
classify the modiﬁed segments.
Deployment: We provide three prototype web applica-
tions for end-users. The ﬁrst is an application that visual-
izes the different aspects in the privacy policy, powered
by the annotations from Polisis (available as a web ap-
plication and a browser extension for Chrome and Fire-
fox). The second is a chatbot implementation of Pri-
Bot for answering questions about privacy policies in
a conversational interface. The third is an application
for extracting the privacy labels from several policies,
given their links. These applications are available at
https://pribot.org.
Legal Aspects We also want to stress the fact that Polisis
is not intended to replace the legally-binding privacy pol-
icy. Rather, it offers a complementary interface for pri-
vacy stakeholders to easily inquire the contents of a pri-
vacy policy. Following the trend of automation in legal
advice [56], insurance claim resolution [57], and privacy
policy presentation [58, 16], third parties, such as auto-
mated legal services ﬁrms or regulators, can deploy Poli-
sis as a solution for their users. As is the standard in such
situations, these parties should amend Polisis with a dis-
claimer specifying that it is based on automatic analysis
and does not represent the actual service provider [59].
Companies and service providers can internally de-
ploy an application similar to PriBot as an assistance
tool for their customer support agents to handle privacy-
related inquiries. Putting the human in the loop allows
for a favorable trade-off between the utility of Polisis
and its legal implications. For a wider discussion on
the issues surrounding automated legal analysis, we re-
fer the interested reader to the works of McGinnis and
Pearce [60] and Pasquale [61].
Privacy-Speciﬁcity of the Approach: Finally, our ap-
proach is uniquely tailored to the privacy domain both
from the data perspective and from the model-hierarchy
perspective. However, we envision that applications with
similar needs would beneﬁt from extensions of our ap-
proach, both on the classiﬁcation level and the QA level.
10 Related Work
Privacy Policy Analysis: There have been numerous at-
tempts to create easy-to-navigate and alternative presen-
tations of privacy policies. Kelley et al. [32] studied us-
ing nutrition labels as a paradigm for displaying privacy
notices. Icons representing the privacy policies have also
been proposed [31, 62]. Others have proposed standards
to push service providers to encode privacy policies in
a machine-readable format, such as P3P [13], but they
544    27th USENIX Security Symposium
USENIX Association
have not been adopted by browser developers and ser-
vice providers. Polisis has the potential to automate the
generation of a lot of these notices, without relying on
the respective parties to do it themselves.
Recently, several researchers have explored the poten-
tial of automated analysis of privacy policies. For ex-
ample, Liu et al. [58] have used deep learning to model
the vagueness of words in privacy policies. Zimmeck
et al. [63] have been able to show signiﬁcant incon-
sistencies between app practices and their privacy poli-
cies via automated analysis. These studies, among oth-
ers [64, 65], have been largely enabled by the release of
the OPP-115 dataset by Wilson et al. [11], containing
115 privacy policies extensively annotated by law stu-
dents. Our work is the ﬁrst to provide a generic sys-
tem for the automated analysis of privacy policies.
In
terms of the comprehensiveness and the accuracy of the
approach, Polisis makes a major improvement over the
state of the art. It allows transitioning from labeling of
policies with a few practices (e.g., the works by Zim-
meck and Bellovin [16] and Sathyendra et al. [17]) to a
much more ﬁne-grained annotation (up to 10 high-level
and 122 ﬁne-grained classes), thus enabling a richer set
of applications.
Evaluating the Compliance Industry: Regulators and
researchers are continuously scrutinizing the practices of
the privacy compliance industry [21, 38, 39]. Miyazaki
and Krishnamurthy [21] found no support that partici-
pating in a seal program is an indicator of following pri-
vacy practice standards. The FTC has found discrepan-
cies between the practical behaviors of the companies, as
reported in their privacy policies, and the privacy seals
they have been granted [39]. Polisis can be used by these
researchers and regulators to automatically, and contin-
uously perform such checks at scale. It can provide the
initial evidence that could be processed by skilled experts
afterward, thus reducing the analysis time and the cost.
Automated Question Answering: Our QA system, Pri-
Bot, is focused on non-factoid questions, which are usu-
ally complex and open-ended. Over the past few years,
deep learning has yielded superior results to traditional
retrieval techniques in this domain [51, 52, 66]. Our
main contribution is that we build a QA system, with-
out a dataset that includes questions and answers, while
achieving results on par with the state of the art on other
domains. We envision that our approach could be trans-
planted to other problems that face similar issues.
11 Conclusion
We proposed Polisis, the ﬁrst generic framework that
enables detailed automatic analysis of privacy policies.
It can assist users, researchers, and regulators in process-
ing and understanding the content of privacy policies at
scale. To build Polisis, we developed a new hierarchy
of neural networks that extracts both high-level privacy
practices as well as ﬁne-grained information from pri-
vacy policies. Using this extracted information, Polisis
enables several applications. In this paper, we demon-
strated two applications: structured and free-form query-
ing. In the ﬁrst example, we use Polisis’ output to ex-
tract short notices from the privacy policy in the form
of privacy icons and to audit TRUSTe’s policy analysis
approach. In the second example, we build PriBot that
answers users’ free-form questions in real time and with
high accuracy. Our evaluation of both applications re-
veals that Polisis matches the accuracy of expert analysis
of privacy policies. Besides these applications, Polisis
opens opportunities for further innovative privacy policy
presentation mechanisms, including summarizing poli-
cies into simpler language. It can also enable compar-
ative shopping applications that advise the consumer by
comparing the privacy aspects of multiple applications
they want to choose from.
Acknowledgements
This research was partially funded by the Wisconsin
Alumni Research Foundation and the US National Sci-
ence Foundation under grant agreements CNS-1330596
and CNS-1646130.
References
[1] F. H. Cate, “The limits of notice and choice,” IEEE Security Pri-
vacy, vol. 8, no. 2, pp. 59–62, March 2010.
[2] Federal Trade Commission, “Protecting Consumer Privacy in an
Era of Rapid Change,” March 2012.
[3] J. Gluck, F. Schaub, A. Friedman, H. Habib, N. Sadeh, L. F.
Cranor, and Y. Agarwal, “How short is too short? implications
of length and framing on the effectiveness of privacy notices,”
in Twelfth Symposium on Usable Privacy and Security (SOUPS
2016). Denver, CO: USENIX Association, 2016, pp. 321–340.
[4] A. M. McDonald and L. F. Cranor, “The cost of reading privacy
policies,” ISJLP, vol. 4, p. 543, 2008.
[5] President’s Concil of Advisors on Science and Technology, “Big
data and privacy: A technological perspective. Report to the Pres-
ident, Executive Ofﬁce of the President,” May 2014.
[6] F. Schaub, R. Balebako, and L. F. Cranor, “Designing effective
privacy notices and controls,” IEEE Internet Computing, vol. 21,
no. 3, pp. 70–77, 2017.
[7] Federal Trade Commission, “Internet of Things, Privacy & Secu-
rity in a Connected World,” Jan. 2015.
[8] F. Schaub, R. Balebako, A. L. Durity, and L. F. Cranor, “A design
space for effective privacy notices,” in Eleventh Symposium On
Usable Privacy and Security (SOUPS 2015). Ottawa: USENIX
Association, 2015, pp. 1–17.
[9] A. Rao, F. Schaub, N. Sadeh, A. Acquisti, and R. Kang, “Ex-
pecting the unexpected: Understanding mismatched privacy ex-
pectations online,” in Twelfth Symposium on Usable Privacy and
Security (SOUPS 2016). Denver, CO: USENIX Association,
2016, pp. 77–96.
USENIX Association
27th USENIX Security Symposium    545
[10] S. Wilson, F. Schaub, R. Ramanath, N. Sadeh, F. Liu, N. A.
Smith, and F. Liu, “Crowdsourcing annotations for websites’ pri-
vacy policies: Can it really work?” in Proceedings of the 25th In-
ternational Conference on World Wide Web, ser. WWW ’16. Re-
public and Canton of Geneva, Switzerland: International World
Wide Web Conferences Steering Committee, 2016, pp. 133–143.
[11] S. Wilson, F. Schaub, A. A. Dara, F. Liu, S. Cherivirala, P. G.
Leon, M. S. Andersen, S. Zimmeck, K. M. Sathyendra, N. C.
Russell, T. B. Norton, E. H. Hovy, J. R. Reidenberg, and N. M.
Sadeh, “The creation and analysis of a website privacy policy
corpus,” in Proceedings of the 54th Annual Meeting of the Asso-
ciation for Computational Linguistics, ACL 2016, August 7-12,
2016, Berlin, Germany, Volume 1: Long Papers, 2016.
[12] U.S. Department of Commerce,
“Privacy shield program
overview,” https://www.privacyshield.gov/Program- Overview,
2017, accessed: 10-01-2017.
[13] L. Cranor, Web privacy with P3P. ” O’Reilly Media, Inc.”, 2002.
[14] P. G. Kelley, J. Bresee, L. F. Cranor, and R. W. Reeder, “A ”nutri-
tion label” for privacy,” in Proceedings of the 5th Symposium on
Usable Privacy and Security, ser. SOUPS ’09. New York, NY,
USA: ACM, 2009, pp. 4:1–4:12.
[15] “Regulation (EU) 2016/679 of the European Parliament and of
the Council of 27 April 2016 on the protection of natural persons
with regard to the processing of personal data and on the free
movement of such data, and repealing Directive 95/46/EC (Gen-
eral Data Protection Regulation),” Ofﬁcial Journal of the Euro-
pean Union, vol. L119, pp. 1–88, May 2016.
[16] S. Zimmeck and S. M. Bellovin, “Privee: An architecture for au-
tomatically analyzing web privacy policies.” in USENIX Security,
vol. 14, 2014.
[17] K. M. Sathyendra, S. Wilson, F. Schaub, S. Zimmeck, and
N. Sadeh, “Identifying the provision of choices in privacy pol-
icy text,” in Proceedings of the 2017 Conference on Empirical
Methods in Natural Language Processing, 2017, pp. 2764–2769.
[18] Disconnect, “Privacy Icons,” https : / / web.archive.org / web /
20170709022651/disconnect.me/icons, accessed: 07-01-2017.
[19] B. Edelman, “Adverse selection in online ”trust” certiﬁcations,”
in Proceedings of the 11th International Conference on Elec-
tronic Commerce, ser. ICEC ’09. New York, NY, USA: ACM,
2009, pp. 205–212.
[20] T. Foremski, “TRUSTe responds to Facebook privacy prob-
lems...” http : / / www.zdnet.com / article / truste - responds - to -
facebook-privacy-problems/, 2017, accessed: 2017-10-01.
[21] A. D. Miyazaki and S. Krishnamurthy, “Internet seals of ap-
proval: Effects on online privacy policies and consumer percep-
tions,” Journal of Consumer Affairs, vol. 36, no. 1, pp. 28–49,
2002.
[22] G. Glavaˇs, F. Nanni, and S. P. Ponzetto, “Unsupervised text seg-
mentation using semantic relatedness graphs,” in *SEM 2016:
The Fifth Joint Conference on Lexical and Computational Seman-
tics : proceedings of the conference ; August 11-12 2016, Berlin,
Germany. Stroudsburg, Pa.: Association for Computational Lin-
guistics, 2016, pp. 125–130.
[23] Y. Kim, “Convolutional neural networks for sentence classiﬁca-
tion,” in Proceedings of the 2014 Conference on Empirical Meth-
ods in Natural Language Processing, EMNLP 2014, October 25-
29, 2014, Doha, Qatar, A meeting of SIGDAT, a Special Interest
Group of the ACL, 2014, pp. 1746–1751.
[24] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean,
“Distributed representations of words and phrases and their com-
positionality,” in Advances in neural information processing sys-
tems, 2013, pp. 3111–3119.
[25] J. Pennington, R. Socher, and C. D. Manning, “Glove: Global
vectors for word representation,” in Empirical Methods in Natu-
ral Language Processing (EMNLP), 2014, pp. 1532–1543.
[26] D. Tang, F. Wei, N. Yang, M. Zhou, T. Liu, and B. Qin, “Learning
sentiment-speciﬁc word embedding for twitter sentiment classiﬁ-
cation.” in ACL (1), 2014, pp. 1555–1565.
[27] N. Viennot, E. Garcia, and J. Nieh, “A measurement study of
google play,” in ACM SIGMETRICS Performance Evaluation Re-
view, vol. 42, no. 1. ACM, 2014, pp. 221–233.
[28] P. Bojanowski, E. Grave, A. Joulin, and T. Mikolov, “Enrich-
ing word vectors with subword information,” arXiv preprint
arXiv:1607.04606, 2016.
[29] S. Bird and E. Loper, “Nltk: the natural language toolkit,” in Pro-
ceedings of the ACL 2004 on Interactive poster and demonstra-
tion sessions. Association for Computational Linguistics, 2004,
p. 31.
[30] D. Britz,
“Understanding convolutional neural networks
for NLP,” http : / / www.wildml.com / 2015 / 11 / understanding -
convolutional - neural - networks - for - nlp/,
accessed:
01-01-2017.
2015,
[31] L. F. Cranor, P. Guduru, and M. Arjula, “User interfaces for pri-
vacy agents,” ACM Transactions on Computer-Human Interac-
tion (TOCHI), vol. 13, no. 2, pp. 135–178, 2006.
[32] P. G. Kelley, J. Bresee, L. F. Cranor, and R. W. Reeder, “A nutri-
tion label for privacy,” in Proceedings of the 5th Symposium on