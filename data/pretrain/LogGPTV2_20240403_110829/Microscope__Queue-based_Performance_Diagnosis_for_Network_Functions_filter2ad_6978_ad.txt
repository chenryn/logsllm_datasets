553553DownstreamUpstream 1Upstream 2SIGCOMM ’20, August 10–14, 2020, Virtual Event, NY, USA
Gong, et al.
victim packets as those that encountered latency above a threshold,
throughput below a threshold, or got lost. For these victim packets,
Microscope performs the steps outlined in Figure 4 and outputs a
list of causal relation patterns.
ber of upstream NFs for each NF f (i.e.,
For each victim packet, we need to recursively diagnose the
first packet in the queuing period at each NF (see § 4.3). In the-
ory, the maximum number of recursions is the sum over the num-
f N _upstreamf , where
N _upstreamf is the number of upstream NFs for an NF f ). In prac-
tice, for our 16-NF evaluation topology (§ 6), we need a maximum
of five recursions. This is because only a small number of culprit
NFs are causally related to a victim.
6 EVALUATION
In this section, we evaluate the accuracy and performance of Micro-
scope. Our evaluation shows that Microscope can correctly capture
89.7% of all performance problems of various types (traffic bursts,
interrupts, NF bugs, etc.), up to 2.5 times more than the state-of-
the-art tools. We also demonstrate that this can be achieved with a
very small overhead during runtime information collection.
6.1 Setting
Network function chain. As shown in Figure 10, we run an NF
chain consisting of four types of NFs: NATs, Firewalls, Monitors,
and VPNs. This chain is a small-scale replica of commonly used NF
chains in practice [4, 8, 48]. Incoming traffic is load balanced at flow
level based on the hash of packet header fields. If a flow matches
a rule at the Firewall, it is forwarded to the Monitor, otherwise it
directly traverses to the VPN.
Figure 10: Network function chain used in evaluation
In our evaluation, all NFs are based on DPDK 18.08 [3]. We use
NATs, Firewalls and VPNs provided by Click-DPDK [40] while we
implemented the Monitor ourselves using the DPDK library. We
run the NFs on Linux servers, and each NF instance is a single
process bound to a specific physical core, in order to provide the
best performance. Each NF uses SR-IOV for network I/O.
Network traffic trace. We use CAIDA [2] traces as traffic in
our evaluation; traces are replayed using MoonGen [24] traffic
generator. Since the software NF performance is mostly determined
by the packet rate, not the byte rate, we set packet-size to 64 bytes
to subject our system to high packet rates.
Aggregate threshold. We use 1% as the threshold in the aggrega-
tion algorithm, with which we think Microscope reports a reason-
able number of causal relation patterns in our evaluation results.
Alternative approach. We compare Microscope with NetMedic.
Since NetMedic is a diagnostic tool on general networked systems,
397
Figure 11: Overall diagnostic accuracy of Microscope and
NetMedic. The x-axis represents the cumulative percentage
of victim packets, and the corresponding y-axis represents
the rank of the correct cause. For example, if the curve goes
through point (x, y), it means for x% of victim packets, the
rank of the real cause is no larger than y.
we modify NetMedic to adapt it to our NFV system. NetMedic
uses a template of graphs to model system components and causal
relationships between them. In our context, the nodes are NFs,
and the edges exist between NFs that directly exchange traffic
(the DAG in Figure 10). NetMedic captures various resource usage
and performance metrics for each component in the graph. In our
case, we monitor all variables related to NF performance, including
CPU usage, memory usage and traffic rates for each NF. NetMedic
correlates abnormal behavior occurring in the same time window.
In NFV systems, the packet delay is usually very small, so we set
the time window to 10 ms, which we find to be the best window
size in our evaluation scenarios. We not only compare accuracy
between Microscope and NetMedic, but also evaluate accuracy
when NetMedic is configured with different window sizes.
Evaluation platform. We run our evaluation on two hosts. Host 1
runs the MoonGen traffic generator, while the entire NF chain
(consisting of a total of 16 NFs) runs on host 2. Host 1 is a Dell
R730 server, having 10 cores, 32 GB memory, and a two-port 40
Gbps Mellanox ConnextX-3 Pro NIC. Host 2 is a Dell T640 server,
having two CPU sockets, each consisting of 10 cores. It has 128 GB
memory, and a two-port 40 Gbps Mellanox ConnextX-3 Pro NIC.
Both servers run Ubuntu 18.04 Linux OS. As a traffic generator,
MoonGen dynamically allocates CPU cores to keep up with the
traffic rate in the traffic trace. Each NF instance, on the other hand,
is bound to a dedicated core.
6.2 Diagnostic Accuracy
Methodology. We compare the accuracy of Microscope and NetMedic.
Ideally, we would like to run evaluation on real problems, but un-
fortunately ground truth is often hard to come by in such scenarios.
So we evaluate the accuracy by injecting problems ourselves. To
make sure the ground truth is clear, we generate the CAIDA traffic
at a moderate rate (1.2Mpps) so that other problems (i.e., the ones
that are not injected) are much less significant and frequent than
the injected ones.
Specifically, We inject three kinds of problems: (1) Traffic bursts:
We randomly select 5 five-tuple flows and inject traffic bursts at the
source with a burst size randomly chosen from 500 to 2500 packets.
Firewall 1NAT 1NAT 2NAT 3NAT 4Firewall 2Firewall 3Firewall 4Firewall 5MonitorVPN 1VPN 2VPN 3VPN 4VPN 5VPN 6Input Traffic 0 2 4 6 8 10 12 0 10 20 30 40 50 60 70 80 90 100Rank of correct causeCumulative % of victim packetsMicroscopeNetMedicMicroscope: Queue-based Performance Diagnosis for Network Functions
SIGCOMM ’20, August 10–14, 2020, Virtual Event, NY, USA
(a) Traffic bursts
(b) Interrupts
(c) NF bugs
Figure 12: Diagnostic accuracy of Microscope and NetMedic for each injected culprit.
(2) Interrupts: We randomly select an NF instance and inject an
interrupt with a duration randomly chosen between 500 and 1000
µs. (3) NF code bugs. We inject a bug at a random firewall instance
that processes specific incoming flows at a low rate (0.05 Mpps). We
inject flows that trigger this bug. The flow size is randomly chosen
between 50 and 150 packets. Our goal is to identify the culprit
flows (with traffic bursts), culprit NF (where we inject interrupts),
or culprit NF-flow pairs (in the firewall case). We make sure the
injected problems are separate enough in time so we unambiguously
know the ground truth. We run our traffic for 5 seconds and collect
around 12.5 MB data in the run-time for each evaluation.
Accuracy metric. NetMedic reports a ranked list of possible cul-
prits. For comparison, we also rank different culprits by their scores,
and get the rank of the real culprits. Note that lower rank is better
here. In fact, the ideal diagnostic result would be the one where the
injected problem is flagged as the top culprit.
Overall accuracy. Figure 11 shows that Microscope outperforms
NetMedic. The two curves connect the rank of each victim packet
for the two algorithms, and they are independently sorted based
on the rank. Microscope reports rank of one for 89.7% of cases.
For the other 10% or so cases, there are always other culprits that
happen concurrently with the injected one. For example, when
we inject traffic bursts, sometimes interrupts occur at the same
time, and these two culprits both contribute to the performance
problem. For such scenarios, Microscope identifies other problems
as the top reason rather than the injected ones. On the other hand,
NetMedic reports rank of one for only 36% cases, and rank≤5 for
only 66% cases. Next let us delve deeper into the three types of
injected culprits.
Diagnosing injected traffic bursts. Figure 12a shows the result
for victim packets affected by traffic bursts. For 99.8% of victim
packets, Microscope names the traffic burst as the most likely cause.
In contrast, NetMedic’s diagnosis is much less accurate. In fact,
only for 3.7% of victim packets NetMedic ranks the traffic burst as
the top one. For 39.9% of victim packets NetMedic ranks the traffic
burst the second-most likely culprit.
To understand why sometimes Microscope and NetMedic fail to
report burst as the most likely cause, we analyzed many such cases
manually. For Microscope, in most of these cases, there are other
culprits such as interrupts happening concurrently with the injected
traffic burst which also affect the packet performance significantly.
Microscope ranks some of these natural culprits before the injected
bursts, which is not totally incorrect. However, NetMedic almost
always misdiagnoses the problem, because it is often misled by
the local processing rate. When a burst arrives at an NF, the local
processing rate is always much higher than the normal time, so
NetMedic ends up ranking the local problem as the top cause.
Diagnosing injected interrupts. Figure 12b shows the result for
victim packets affected by interrupts. For 85.0% of victim packets,
Microscope reports rank one for the interrupt. In contrast, NetMedic
only reports rank one for 52.8% of victim packets.
For cases where Microscope is not able to pinpoint injected inter-
rupts as the top reason, it is due to other events such as traffic bursts
or other interrupts that affect the outcome. In contrast, NetMedic
misdiagnoses a lot of cases. For example, due to the delay of impact
propagation (similar to the second example in § 2), NetMedic is
unable to correlate the victim with the interrupt (NetMedic still
gives it a rank because it gives every possible culprit a rank).
Diagnosing injected NF bugs. Figure 12c shows the result for
victim packets affected by the NF bug at Firewall 2. The bug is
ranked first for 73.0% cases by Microscope, and has rank no larger
than two for 95.5% cases. However, the bug is ranked first for only
63.3% cases by NetMedic, and all other cases have a rank larger
than 3. For those cases where Microscope assigns second rank
to the bug, Microscope ranks traffic bursts from the source first,
because in this experiment, we manually injected some traffic to
trigger bugs in the Firewall which increased the traffic rate. On the
other hand, NetMedic assigns fourth to sixth place to the real cause
for a large fraction of cases. In most of these cases, the problem
happens in VPNs which are propagated from the bug in the Firewall,
but NetMedic cannot correlate the bug triggering with the victim
packets because there is a time gap between the bug and the final
problem. Thus, it places the correct culprits lower that the other
possible culprits (such as the Monitor and the other four Firewalls).
Runtime overhead. We also test the overhead of our runtime
information collector by determining the degradation of the peak
throughput at NFs which we find to be between 0.88% and 2.33%
for different NFs. Note that this is the worst case overhead (under
peak throughput); in reality the overhead is lower since NFs do not
constantly run at the peak throughput.
NetMedic accuracy with different time window sizes. Fig-
ure 13 shows how the accuracy (the percentages of results that
rank the correct answer first) of NetMedic varies with different
time window sizes. For all window sizes, NetMedic achieves much
lower correct rate than Microscope (see Figure 11). Since NetMedic
398
 0 2 4 6 8 10 12 0 10 20 30 40 50 60 70 80 90 100Rank of correct causeCumulative % of victim packetsMicroscopeNetMedic 0 2 4 6 8 10 12 0 10 20 30 40 50 60 70 80 90 100Rank of correct causeCumulative % of victim packetsMicroscopeNetMedic 0 2 4 6 8 10 12 0 10 20 30 40 50 60 70 80 90 100Rank of correct causeCumulative % of victim packetsMicroscopeNetMedicSIGCOMM ’20, August 10–14, 2020, Virtual Event, NY, USA
Gong, et al.
Figure 13: The correct rate of diagnosis when NetMedic is config-
ured with different time window sizes.
achieves the best correct rate when the window size is 10ms, we
use 10ms as the NetMedic window size in other experiments.
6.3 Detailed Evaluation
Impact of burst sizes: We first inject traffic bursts from the source
with different burst sizes, from 200 packets to 5000 packets. We
found that when the burst size is 5000 packets, Microscope names
the traffic burst as the most likely cause for all victim packets. As
the burst size decreases, the accuracy also decreases. The reason for
the accuracy decrease is that, when the burst size is small, it will
contribute less to the queue relative to other concurrently occurring
culprits.
Impact of interrupt lengths: We inject interrupts with different
lengths, from 300µs to 1500µs. We found that when the interrupt
length is 1500µs, Microscope names the interrupt as the most likely
cause for almost all victim packets. However, as the interrupt length
decreases, the accuracy also decreases. It is because when the in-
terrupt length decreases, fewer packets are buffered due to the
interrupt, and so the contribution of the interrupt is smaller com-
pared to other concurrent culprits.
Impact of propagation hops: We inject different types of prob-
lems, and classify victim packets based on how many hops it takes
for the effect to propagate to the ultimate victim. We found that
as the number of hops increases, the accuracy of Microscope de-
creases. The reason is that, when problems propagate across hops,
concurrent culprits can also propagate to the same victim, and thus
the impact of the problem we inject is smaller.
6.4 Effectiveness of Pattern Aggregation
To demonstrate the effectiveness of pattern aggregation, we run
CAIDA traffic at 1.2 Mpps, and inject flows that trigger the bug at
Firewall 2. The bug-triggering flows are TCP flows from 100.0.0.1/32
to 32.0.0.1/32, with source TCP port number in [2000, 2008] and
the destination TCP port numbers in [6000, 6008]. The experiment
resembles the example in § 1. Note that Microscope has no explicit
information about the bug. Neither does it know about the flows
that trigger the bug.
Pattern aggregation presents concise results. There are a total
of 84K causal relations, and pattern aggregation aggregates them
to 80 different patterns. The run-time of the aggregation is around
three minutes. The number of patterns could be reduced by further
optimizations. For example, currently each port in [2000, 2008]
Figure 14: A snippet of pattern aggregation result. Each row is
one pattern:   => 
and [6000, 6008] is in separate patterns, because the raw hierar-
chical heavy hitter algorithm we use [25] only considers either
the static port range (1024-65536) or single port numbers. If we
provide adaptive port ranges, we expect to report fewer rules (e.g., a
single pattern with source port range of 2000–2008 and destination
port range of 6000–6008). Furthermore, operators can also tune the
threshold in the aggregation algorithm to adjust how many details
the report contains.
Pattern aggregation helps us identify the bug-triggering flows.
Figure 14 shows a snippet of the aggregation results. Four of the pat-
terns contain the bug-triggering flows as culprits. Such information
can be very helpful in diagnosing the bug.