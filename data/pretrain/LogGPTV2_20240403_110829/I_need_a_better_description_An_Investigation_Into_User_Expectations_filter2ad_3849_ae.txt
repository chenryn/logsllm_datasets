### Summary of Findings

Our surveys indicate that (RQ1) users are concerned about the types of information disclosures that Differential Privacy (DP) can protect against, and (RQ2) users' willingness to share information is significantly related to the perceived risk of these disclosures. However, the risk associated with two specific information flows—disclosures through graphs or to a data analyst, which might seem most relevant to users in the context of a salary transparency initiative and a medical research initiative—did not significantly influence their willingness to share.

### Visualization and Framework

Figure 3 visualizes our framework for understanding how DP descriptions impact users' willingness to share information. Colored dots under user representations indicate the information flows they care about, while colored dots under description labels show the information flows for which the description raises expectations. Our results suggest that a user's willingness to share information is not solely a function of how a DP description raises their expectations but also depends on their prior concerns. Specifically, if a description raises expectations for information disclosures that the user was not initially concerned about, it may not increase their willingness to share.

### Noteworthy Observations

This finding is significant because ensuring privacy in graphs and informational charts is a common motivating example of DP. It is the only type of information disclosure protected by both local and central DP, and at least one current deployment of DP focuses on protecting user information from data analysts [50].

### Impact of DP Descriptions

We also found that real-world descriptions of DP have a substantial impact on user privacy expectations (RQ3), but not on their willingness to share (RQ4). Different themes in DP descriptions raise privacy expectations for various information flows, but this can be a double-edged sword. Raising expectations can also mislead users about the privacy properties of a system.

### Novel Framework for Reasoning

At first glance, there appears to be a contradiction in our results: respondents care about information disclosures relevant to DP and are more willing to share when assured that these disclosures will not occur. However, offering DP did not increase their willingness to share, regardless of the description. The results in Table 4 show that respondents had higher privacy expectations when presented with certain descriptions, but these higher expectations did not translate into increased willingness to share. This discrepancy can be explained by the misalignment between the disclosures that matter to a given respondent and those influenced by the DP description they were shown.

### Key Takeaways

These results suggest a framework for understanding how DP descriptions influence a user’s willingness to share information. When users encounter a differentially private system, they already have privacy preferences and concerns. A DP description may raise their expectations about certain information flows. If these raised expectations align with their concerns, they may be more likely to share. A clear and concise description of DP may not be enough; it must directly address and tailor to users' concerns.

### Need for New Descriptions

Our results highlight that current DP descriptions in the wild are insufficient for helping users make informed decisions. There is no consistency or standardization in the language used by organizations. The six descriptive themes we identified haphazardly raise users' expectations, which is concerning given the differences between local and central DP. Figure 2 shows that existing descriptions do little to correctly set expectations, regardless of the deployment model.

While the simple descriptions we used in our surveys are not entirely ineffective, they do not increase participation. Two main alternatives for improving DP descriptions are:
1. **Careful Construction and Training**: As proposed by Xiong et al. [69], carefully constructing descriptions and training users to understand them. However, this approach is challenging as many users still struggle with comprehension.
2. **Explicit Risk Communication**: Informing users about the specific risks posed to their information, similar to the privacy nutrition labels proposed by Kelley et al. [41]. This approach allows users to make informed decisions without requiring a comprehensive understanding of DP techniques.

### Conclusion

In this work, we studied DP from the user's perspective, focusing on how users' privacy expectations relate to DP as they are likely to encounter it in the wild. We showed that while DP can address users' privacy concerns, the varied ways in which DP is described set user expectations in a haphazard and often inaccurate manner. Our results indicate that the interaction between users' intrinsic privacy concerns and the ways in which DP descriptions set expectations influences their willingness to share information. Our work posits a novel framework for understanding this interplay and suggests concrete directions for developing better DP descriptions that directly and accurately address user privacy concerns.

### Acknowledgments

The first author was supported in part by The Defense Advanced Research Projects Agency (grant number W911NF-21-1-0371), NSF grants CNS-1850187 and CNS-1942772 (CAREER), a Mozilla Research Grant, and a JPMorgan Chase Faculty Research Award. Part of this work was completed while the first author was at Georgia Institute of Technology. The second author is supported by the National Science Foundation under Grant #2030859 to the Computing Research Association for the CIFellows Project and The Defense Advanced Research Projects Agency under Agreement No. HR00112020021. Part of this work was completed while the second author was at Johns Hopkins University. Part of this work was completed while the third author was at Microsoft Research. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the United States Government or DARPA.

### References

[References listed here as in the original text]

---

This revised version aims to provide a clearer, more coherent, and professional presentation of your findings and framework.