### Optimized Text

The first statement declares an object with both a property `p` and its corresponding getter. The second statement defines a function, while the third statement defines a property named `"0"` for the object `s0`. After defining the property, the JavaScript (JS) engine traverses an internal dictionary that maps property names to property objects and creates a new object containing both properties `0` and `p`. At this point, the engine incorrectly identifies the type of property `p` as a 'getter' function, even though it is an integer value. This incorrect type casting leads to a type confusion vulnerability. When the function `s1` is called, it attempts to access the property `p` of `s0`. Due to the type confusion, this access tries to dereference an invalid getter function pointer, resulting in a segmentation fault.

Generating such a code snippet is not trivial, as each statement is deeply interrelated. The variable `s0` is used in both the function call statement and the `defineProperty` method. The function `s1` must be defined before being invoked with `s0` as its parameter. CodeAlchemist uses four code bricks, annotated in Figure 10, to generate the test case: a code brick for the variable declaration statement (Var1), a code brick for the function declaration statement (Func2), and two code bricks for the expression statements (Expr3, Expr4). These have the following assembly constraints:

1. `{}` → Var1 → `{s0: Object}`
2. `{}` → Func2 → `{s1: Function}`
3. `{s0: Object}` → Expr3 → `{s0: Object}`
4. `{s0: Object, s1: Function}` → Expr4 → `{s0: Object, s1: Function}`

CodeAlchemist successfully assembles these code bricks based on their assembly constraints to generate the test case that triggers the vulnerability.

### VII. DISCUSSION

#### Seed Selection
Semantics-aware assembly is essentially a seed-based fuzzing approach. Therefore, collecting and selecting good seeds can significantly impact the performance of fuzzing, as it does not create object types that are never seen in seeds. In our experiments, we obtained a set of seeds from existing JS test suites. However, we believe CodeAlchemist can benefit from adopting state-of-the-art seed selection strategies [23], [25]. Additionally, automated seed generation techniques like Skyfire [35] may help expand our seed pool.

#### Code Brick Selection
Currently, CodeAlchemist randomly selects code bricks for each iteration. We believe that devising an intelligent code brick selection strategy could improve the fuzzing effectiveness. Although our current design follows a complete black-box approach similar to LangFuzz [17], a grey-box approach where code brick selection is guided by code coverage or similar metrics could be more effective. Selecting the next code brick using probabilistic language models, as in Skyfire [35] and TreeFuzz [24], could also enhance bug finding. This is an interesting area for future work.

#### Supporting Other Targets
It is straightforward to apply semantics-aware assembly to test other language interpreters or compilers, as the core idea of assembling code bricks is language-agnostic. Furthermore, this approach can be particularly effective for statically-typed languages like C and C++, where variable types can be easily inferred without instrumenting the code. Extending our algorithm to test compilers of other programming languages and applying our technique to find bugs in JS bindings [5], which allow input containing JS code snippets (e.g., Node.js and PDF readers), is left as future work.

### VIII. RELATED WORK

#### A. Fuzzing
Fuzzing is a software testing technique used to find security vulnerabilities. It has been widely adopted by security practitioners and researchers due to its significant practical impact. Fuzzing is typically divided into two major categories: mutation-based and generation-based fuzzing. Mutation-based fuzzers, such as AFL [40], take a set of seeds and output test cases by mutating them. There has been considerable interest in improving the effectiveness of mutation-based fuzzers [6], [25], [36]. On the other hand, generation-based fuzzers produce test cases based on a model, such as a grammar [17], [38]. IMF [14], for example, automatically infers a model between system calls and uses it to generate a sequence of system calls to fuzz kernel code. CodeAlchemist falls into the category of generation-based fuzzing.

Several previous generation-based fuzzers have been developed for testing interpreters and compilers. Most focus on generating syntactically valid programs based on a model to traverse deep execution paths. Since interpreters (and compilers) first check for syntactic validity, generating syntactically valid programs helps in exploring deeper paths.

There are several existing JS engine fuzzers that generate test cases based on predefined rules rather than a complete language grammar. For instance, domato [11] generates HTML, CSS, and JS code to test DOM renderers in web browsers, and esfuzz [10] generates tests for ECMAScript parsers. jsfunfuzz [27], a state-of-the-art JS engine fuzzer maintained by Mozilla, contains a large number of manually built generation rules.

However, such fuzzers cannot create context-sensitive test cases by design. As discussed in §III, jsfunfuzz focuses on syntactic, but not semantic, validity. It heuristically mitigates runtime errors through variable renaming, but still suffers from a high error rate. Consequently, finding new security vulnerabilities with jsfunfuzz is becoming increasingly difficult, as our experimental results show.

Dewey et al. [8] address the problem of reducing runtime errors by proposing a generation-based fuzzing algorithm that leverages constraint logic programming. Their approach aims to drive test case generation towards specific language features with user-provided constraints. However, this requires an analyst to manually provide such constraints before fuzzing.

Several JS engine fuzzers generate test cases based on a set of given seeds. They fragmentize the seeds and reassemble the fragments to generate test cases. LangFuzz [17], the most successful JS engine fuzzer in this category, generates fragments by parsing down a given set of seeds into code fragments and then mutates the seeds by replacing AST subtrees with the generated fragments. GramFuzz [13] and BlendFuzz [37] use the same intuition but focus on other languages like HTML, CSS, and JS. IFuzzer [33] improves upon LangFuzz by employing genetic programming to generate unseen JS test cases. TreeFuzz [24] and Skyfire [35] construct probabilistic language models from a given set of seeds to generate valid JS code snippets. None of these seed-based JS engine fuzzers handle runtime errors during test case generation.

#### B. JavaScript Analysis
JavaScript has become one of the most popular programming languages due to its flexibility, which allows programmers to write simple code quickly. However, this flexibility makes traditional program analysis challenging, as discussed in §II-A. For example, the dynamic type system and the use of `eval` complicate JS analysis. Thus, there has been extensive research on JS program analysis.

Dynamic instrumentation forms the basis for dynamic analyses, and several approaches use dynamic instrumentation on JS code. Yu et al. [39] rewrite and instrument JS code to detect security policy violations. Sen et al. [28] present a dynamic analysis framework for JS, providing a general-purpose dynamic JS code instrumentation mechanism. CodeAlchemist also employs similar techniques to obtain variable types in code bricks.

Many researchers have developed static type systems for JS, starting with seminal works by Anderson et al. [2] and Thiemann et al. [32]. Their approaches support only limited language features. Guha et al. [12] present λJS, a core language that embodies essential JS features, including prototypes and first-class functions. Lerner et al. [18] propose a general framework for building JS type systems based on λJS. Chandra et al. [7] handle a rich subset of JS, capable of computing types for uninvoked functions. Our approach can benefit from these by making assembly constraints more precise. For a detailed overview, see recent survey papers [3], [29].

### IX. CONCLUSION
We have presented CodeAlchemist, the first fuzzing system that generates semantically valid test cases for JS engines. CodeAlchemist learns language semantics from a corpus of JS seed files and generates a pool of code bricks that can be assembled to construct semantically valid JS code snippets. We leverage both static and dynamic analysis techniques to infer variable types in each code brick and use this information to build assembly constraints. This approach significantly reduces runtime errors while producing highly-constructed test cases. CodeAlchemist found 19 bugs in four major JS engines, and all findings have been reported to the vendors.

### ACKNOWLEDGEMENT
We thank our shepherd, Deian Stefan, and the anonymous reviewers for their helpful feedback. We also thank Jaeseung Choi for fruitful discussions. This work was supported by the Institute for Information & Communications Technology Promotion (IITP) grant funded by the Korea government (MSIT) (No. B0717-16-0109, Building a Platform for Automated Reverse Engineering and Vulnerability Detection with Binary Code Analysis).

### REFERENCES
[References remain unchanged]