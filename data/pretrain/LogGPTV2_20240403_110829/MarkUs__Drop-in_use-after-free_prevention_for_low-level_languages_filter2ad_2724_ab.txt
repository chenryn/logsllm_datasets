while previously failed frees may be successful in the next
round of a marking procedure, as the dangling pointer may
disappear, they are disregarded as part of the trigger condition
for mark culling to prevent constant ineffective marking when
large numbers of failed frees exist. Still, under the assumption
that accessible data on the quarantine list is rare, we can
control overheads based on system parameters.
E. Allocator Details
Because it provides data structures to set mark bits for the
marking procedure, we use the allocator from the Boehm-
Demers-Weiser garbage collector [11]. This splits objects into
two sizes: those larger than a page are allocated as monolithic
objects with their own headers, at page-sized granularities. For
MarkUs, this means the entire object can be unmapped from
the virtual address space once it is freed from quarantine, as no
other objects will share pages with the freed object. However,
for objects smaller than a page, the allocator uses a pool
strategy: a single header is used for an entire page of objects,
which are all the same size and initialised simultaneously, to
reduce metadata and allocation overheads. Mark bits are stored
in these headers rather than the objects themselves.
Objects are initialised to zero upon allocation, to reduce the
probability of old false pointers appearing when these objects
are later walked by the marking procedure. These pointers
would reduce the proportion of objects we could securely
free. Zeroing also has the helpful side-effect of mitigating
information leakage via heap initialisation bugs [20], another
class of temporal safety violations.
Other allocators could use MarkUs’s strategy to eliminate
use-after-free vulnerabilities—the allocator’s implementation
choices typically neither help nor hinder MarkUs, and instead
add orthogonal overheads and performance beneﬁts. However,
since these allocators would then need separate support added
for mark bits, to limit engineering work we only evaluate on
the Boehm-Demers-Weiser allocator with existing support.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:38:23 UTC from IEEE Xplore.  Restrictions apply. 
581
F. Page Unmapping
For large allocations, we can provide a form of use-after-free
detection, as well as prevention, by unmapping pages upon
a user’s deallocation, as long as an object’s allocated region
entirely covers each unmapped page. Subsequent access to an
unmapped page will result in a segmentation fault, correctly
ﬂagging the use of a dangling pointer.
There are also performance and memory-consumption bene-
ﬁts to this approach. Because we unmap these physical pages,
they can be reused in a subsequent mmap call for another
allocation without any need for a marking procedure. As
virtual addresses are typically an ample resource, particularly
on 64-bit architectures, this can signiﬁcantly cut down the per-
formance overhead of MarkUs in the face of large allocations,
as marking frequency for a given memory overhead can be
signiﬁcantly reduced. For large objects, this can potentially
be the only practical way of recovering physical memory. As
a single allocation grows in size, in a conservative marker
the likelihood of unrelated data coincidentally pointing to an
address within that allocation’s range increases. This means
a marking procedure may be unable to free and reallocate
such an allocation. For a true garbage collector, this can cause
memory leaks without allowing unsafe manual deallocation,
but for MarkUs,
is reduced to a problem of potential
virtual-address leakage rather than physical-memory leakage.
Unmapping the physical pages therefore eliminates the prob-
lem. In addition, unmapped pages need not be examined for
pointers, as they are inaccessible, reducing marking costs. This
is implemented using a bit in the allocator’s per-page metadata.
On reallocation, if the allocator wishes to reuse space with
the unmapped bit set, it calls mmap with the address of the
page or region as its argument. Otherwise, mmap is called
with the address at the end of the current heap, installing new
metadata. This prevents the allocator from accidentally reusing
the unmapped space of pointed-to addresses for new objects
if its heap is exhausted. If the programmer uses mmap calls
elsewhere, then these can be wrapped to prevent reuse, though
as with previous work [7] we have not found the need to do this
in practice because munmapped space is typically not reused
in an mmap unless deliberately requested.
it
For large objects, this makes our allocation and deallocation
strategy similar to use-after-free-prevention techniques that
use a separate virtual page for every allocation [6], [7]. The
differences are in how we treat small allocations. First, we
store multiple small objects in the same virtual page to avoid
TLB pressure, and use marking procedures to reclaim the
memory. Second, virtual addresses are eventually reclaimed
by marking procedures. Third, aliasing of physical pages is
unnecessary because MarkUs only needs to map one physical
page to one virtual page at any point, rather than using multiple
mappings to have concurrently-live small objects allocated in
the same page but accessible by different virtual addresses.
G. Small-Object Block Sweeping
The Boehm-Demers-Weiser pool allocator ensures all objects
within a page-sized block are of the same size. Once freed,
(a) Quarantine list elements from entirely-unmarked blocks are found
and sent to a small-object list for further analysis, in an attempt to
free the entire page for use by differently-sized objects.
(b) The free lists of the appropriate sizes are checked, to ﬁnd any
objects within blocks we are trying to entirely free, and placed on
the small-object list if from an unmarked block.
(c) Any block for which every object is on the small-object list is
entirely freed. Objects within partially-freed blocks with no marks
are instead placed on the relevant free lists of the pool allocator.
Fig. 4: An example of walking the quarantine, free and small-
object lists when using small-object block sweeping.
these small objects go to separate free lists per object size,
and by default are only reused for new objects of that size.
MarkUs deliberately trades off marking-procedure fre-
quency for memory overhead. This means that, even for a
small working set of memory objects, many pages can be
allocated between each marking procedure, which, by default,
can only be used for memory objects of the same size from
that point on. This can result in signiﬁcant memory overhead,
because if the proportion of object sizes changes over time,
this allocation space effectively becomes unusable.
To ﬁx this, we deallocate blocks that consist of entirely-
freed memory objects, allowing them to be reused more
generally. One way of ﬁnding this information out
is by
looking at the marks within a block: if the block is entirely
unmarked, we can reallocate it by deleting every element from
the appropriate free list. However, in C and C++, where the
marks of a collector cannot necessarily be trusted, this results
in a safety violation, as we may free objects that the user is
still accessing. Instead, we use that information as a guide
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:38:23 UTC from IEEE Xplore.  Restrictions apply. 
582
to trigger a more complicated analysis. If there are no marks
within the block of an object on the quarantine list, we do not
free that object immediately. Instead, we add such objects to
a small-object list. We then sweep the free list, moving any
objects that share a block with a quarantined object we think
is in an entirely free block back to the small-object list. We
then check to see if any blocks are entirely within this new
small-object list. If they are, we delete the entire block and
allow its reuse for differently-sized objects. If not, we add
them to their original free list, from which they may have just
been removed. An example is given in ﬁgure 4.
This means that, as well as freeing small objects in partially-
free blocks so that they can be reused, we also safely free
entire blocks so that they can be reused for data of other sizes,
preventing memory leaks even for programs with many distinct
memory-allocation phases throughout their execution.
H. Concurrency and Parallelism
The marking procedure is parallel; it can be run on multiple
threads at once by splitting up the current frontier of objects
to be searched for pointers. This has the effect of making the
marking procedure faster and more efﬁcient on multicores, and
decreases single-core slowdown at the expense of spreading
CPU utilisation across many cores. If too high, this can impact
other applications running on the system. However, MarkUs
typically spends little time running marking procedures, and
parallel execution is typically more energy efﬁcient.
MarkUs’s marking procedures are performed concurrently
with application execution, which continues while the stack
and heap are searched. Since data may be modiﬁed during the
marking procedure, to preserve correctness we use page-table
dirty bits [16], set when pages are modiﬁed while a marking
procedure is being concurrently performed, to track this new
data. These dirty pages are then checked once again at the end
of the marking procedure, to check for the presence of any new
accessible regions. The marking procedure need only stop-the-
world brieﬂy at the start of the marking procedure, through
sending suspend signals to each thread, (to collect registers
as root sets to ﬁnd pointers) and at the end (to preserve
correctness under concurrent modiﬁcation). Since these require
little work, stop-times are unnoticeable, and thus MarkUs
works for applications with user interaction, such as browsers.
Walking the quarantine list is performed under the allo-
cator’s lock, and is thus single-threaded. While this could
be parallelised, its overhead is negligible compared with the
marking procedure, and thus optimisation is unwarranted.
I. Coverage Limitations and Hidden Pointers
Since low-level languages, like C and C++, allow pointer
hiding, for example by XORing them with other data, we
are not able to see all of them. That doesn’t stop our sys-
tem from being semantically safe, however, since we only
ever delete objects that
the programmer freed themselves,
so we cannot introduce undeﬁned behavior. However, it also
means that MarkUs could fail to detect complex use-after-
free vulnerabilities involving hidden pointers, as is a limitation
with any technique that involves identifying pointers. Still, a
garbage collector works for most parts of most C and C++
programs [21] The vast majority of pointers are not hidden,
as we examine in section V-I. Further, most hidden pointers
are already carefully implemented, and so are unlikely to
contain use-after-free errors. This means the defence is practi-
cal, and other techniques that rely on, for example, zeroing
old pointers [1], [4], [23], or tracking them [16], are also
vulnerable. MarkUs can further successfully protect programs
even in the presence of integer-casted or union pointer types
that the compiler cannot disambiguate, but MarkUs can treat
as potentially containing pointers.
An attacker can deliberately create pointers to objects just
through write access to integer arrays, as MarkUs cannot by
default distinguish between pointers and data. This prevents
deallocation of such space, causing larger memory utilisation.
This gives an attacker with full allocation abilities no more
power unless they are limited to a given area of sandbox space,
at which point they can have more system-level impact than
they could otherwise, potentially exhausting the application
of memory instead of just the sandbox. Still, there are two
alternative mechanisms that can be used to prevent this speciﬁc
case, if necessary for a given application. The ﬁrst is that a
sandbox’s memory can be limited to prevent its quarantine,
as well as its allocated data, from exceeding a given size.
The second is that, in high-level languages, we can tag allo-
cation space as integer-only, to avoid its marking and prevent
any conservative pointer behaviour. The Boehm allocator we
use [16] already supports the latter, but as it is a very speciﬁc
use-case, and requires application targeting rather than being
entirely drop-in, we do not utilise this in our implementation.
The allocator’s headers (section III-E) are isolated from
data, and so cannot be targeted by use-after-free in quarantine.
However, our current
implementation inherits small-object
links that are stored within old objects. An attacker can
potentially rewrite these links in two ways if they ﬁnd a use-
after-free. First, they can add false elements to the list, though
unless these elements are hidden pointers they cannot be
deleted, and unless they can be written to by the attacker, the
marking procedure will not reach the end of its list, preventing
application progress and the presence of a useful attack. Sec-
ond, they can possibly remove elements or cause loops through
an existing double-free. While neither causes useful privilege
escalation, as they either prevent program progress or only
affect memory utilisation, a full implementation could isolate
metadata at negligible overhead. Fast allocators,
including
jemalloc already utilise such isolation [10], and we only avoid
it for implementation complexity.
J. Summary
This section has presented the design of MarkUs, a use-after-
free-preventing memory allocator for low-level
languages,
is manually freed by the
based on quarantining data that
programmer and verifying it using a marking procedure of
the stack, heap, registers, and data segments. Through this,
MarkUs achieves both safety with respect to low-level pointer
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:38:23 UTC from IEEE Xplore.  Restrictions apply. 
583
handling, and protection against use-after-free attacks. To
minimise the costs of the technique, we optimise this strategy
by directly limiting the number of marking procedures based
on the amount of data the programmer has tried to free,
eagerly unmapping virtual pages of large allocations so that
the physical pages can be reused immediately following the
programmer’s deallocation, and using the marking procedure’s
overestimation of entirely-free regions of memory as a guide to
perform more complex checks to reallocate regions to objects
of different sizes. The next section describes our experimental
system before we move on to demonstrate how MarkUs
performs on real workloads.
IV. EXPERIMENTAL SETUP
We evaluate MarkUs using a prototype built by extending the
Boehm-Demers-Weiser Garbage Collector [11], [16]. This is
implemented as a shared library that overrides malloc, free,
calloc, realloc, new, and delete, which can be utilised by
deﬁning LD PRELOAD before execution of a dynamically-
linked application, meaning source code access is unnecessary.
By default, we use a growth bound (section III-D) of 4, to
represent a quarantine list of 33% of the size of the rest of
allocated memory.
We evaluate on an Intel system, featuring a quad-core
Haswell Core i5-4570, 16GB of DDR3 RAM, and running
Ubuntu 16.04. For proﬁling, we used PSRecord [26]. We
evaluate using SPEC CPU2006 [24] (using reference inputs)
and Olden [27] (default inputs), to demonstrate on benchmarks
with a wide range of memory behaviors and to directly
evaluate against other work in the literature. We show C
and C++ benchmarks from SPEC CPU2006 to give direct
comparison with prior work; Fortran benchmarks behave sim-
ilarly. In addition, we use Firefox with BBench [28] to show
applicability to modern, particularly vulnerable workloads.
SPEC CPU2006 and Olden ran with no modiﬁcations, as do
most applications in practice, as the allocator is functionally
compatible with glibc malloc. MarkUs has also been tested
on a variety of real-world applications such as OpenOfﬁce,
Okular, Evince, Texstudio, Vim and Emacs, where no notice-
able impact on the application was observed. For Firefox, we
compiled with --disable-jemalloc to directly hook malloc
and free instead of the custom allocator Firefox normally
uses, to reduce implementation effort. We also compiled with
--enable-valgrind and --disable-sandbox because the
sandboxing of Firefox is unaware that MarkUs’ marking pro-
cedure accessing all memory is intended behavior. This does
not enable valgrind during execution, but prevents warnings
from Firefox’s monitoring mechanism [29]. In production
environments, applications using custom intra-process sand-
boxing would be altered to be aware of MarkUs, or separate
instances of MarkUs would be used for each sandbox. We
execute all workloads three times, unless the benchmark suite
already makes another higher choice for us, for example, in
BBench. Bars show the mean from each of these, with error
bars showing the maximum and minimum values observed.
For comparison, we evaluate against results taken from
Oscar [7], Dhurjati and Adve [6], Dangsan [4], CRCount [25]
and pSweeper [23], on the benchmarks they use. In the latter
case, we compare against the pSweeper-1s technique, as this
compares most closely to MarkUs in terms of additional CPU
costs: overheads for pSweeper-1s on other cores are limited to
approximately 30%, rather than the 100% overhead that occurs
from the consistent use of a single extra core when pSweeper
runs continuously. By comparison, while MarkUs is allowed
to use the resources of other CPUs, the additional utilisation
is typically negligible. In addition, MarkUs also compares
favorably in terms of memory and performance against the
higher-overhead techniques presented in the paper [23].
V. EVALUATION
We ﬁrst look at the overheads of MarkUs in terms of memory
and performance, contrasting them with other state-of-the-art
use-after-free protections [4], [6], [7], [23]. We then take an in-
depth look at how we can trade off overheads within MarkUs,
and the improvements rendered by the optimisations described
in section III. In particular, MarkUs results in performance and
memory overheads of 10% and 16% respectively on SPEC
CPU2006 [24], which are both improvements on all other
techniques for use-after-free prevention in C and C++.
A. SPEC Overheads
Figure 5 shows the performance impact on the C and C++
benchmarks from SPEC CPU2006 [24], compared with the
reported results from other state-of-the-art
techniques. We
see that MarkUs has the lowest average performance impact
of any technique: 10%, versus 40% for Oscar [7], 36% for
DangSan [4], 15% (along with the additional overhead of an
extra computation thread) for pSweeper [23], and 22% for
CRCount [25]. While Oscar shows overheads of up to 4.5×
for pointer-intensive workloads due to TLB pressure, Dangsan
experiences up to 7× due to its expensive logging of all pointer
references, and CRCount pays over 2× even on workloads
such as povray that aren’t allocation intensive but often create
pointers, since MarkUs only increases the malloc and free
costs, it never incurs over 2× overhead.
Memory overhead shows a similar pattern in ﬁgure 6, where
MarkUs incurs an average 16% overhead, compared with
60% for Oscar, 140% for Dangsan, 130% for pSweeper, and
17% for CRCount. Dangsan and pSweeper, in particular, can
face crippling penalties due to the requirement of logging
all pointer locations in the program, and Oscar likely suffers
in extreme cases due to the number of page-table entries
required. The metadata for MarkUs behaves predictably, never
exceeding 2×, partly because it
the
additional resources used before a marking procedure cleans
up the extra resources. Indeed, the variance that exists in
MarkUs is primarily due to the allocation strategy inher-
ited from the Boehm-Demers-Weiser garbage collector [16],
which, compared with the standard GNU malloc, can increase
or reduce memory usage signiﬁcantly, even ignoring the pres-
ence of delayed collection of freed data (see section V-G).
is designed to limit
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:38:23 UTC from IEEE Xplore.  Restrictions apply. 
584
 5
 4
 3
 2
 1
 0
 7
 6
 5
 4
 3
 2
 1
 0
n
w
o
d
w
o
S
l