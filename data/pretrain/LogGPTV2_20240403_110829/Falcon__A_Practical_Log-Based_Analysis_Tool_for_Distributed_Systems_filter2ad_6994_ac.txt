LOG
LOG
LOG
LOG
4
4
SND
SND
SND
SND
SND
SND
SND
SND
SND
SND
1
1
1
1
184
1
1
1
1
184
SND
SND
1
1
6
1
SND
SND
1
184
SND
LOG
LOG
1
1
1
1
184
RCV
RCV
RCV
RCV
RCV
LOG
LOG
LOG
LOG
END
1
LOG
CONNECT
LOG
SND
SND
SND
SND
SND
SND
8
8
1
1
1
1
SND
14
LOG
LOG
LOG
1 QuorumCnxManager:365
Opening channel to server 1
2 FastLeaderElection:888
New election. My id =  1
3 QuorumCnxManager:644
Address of remote peer: 2
4 "zxid":0, "leader":1,
"election_epoch":1,
"epoch":1,"state":LOOKING
5 "zxid":0, "leader":2,
"election_epoch":1,
"epoch":1,"state":LOOKING
6 "zxid":0, "leader":2,
"election_epoch":1,
"epoch":1,"state":LOOKING
SND
SND
1
1
SND
5
1
SND
1
SND
184
RCV
RCV
RCV
RCV
RCV
1
1
1
1
184
RCV
RCV
RCV
RCV
RCV
RCV
RCV
RCV
RCV
1
1
1
1
184
1
1
1
1
RCV
184
Fig. 5. Space-time diagram of two Zookeeper servers connecting to each
other and performing a leader election. Vertical lines are thread timelines
and circles denote the executed events on each thread timeline. The dashed
and solid rectangles represent different protocol steps, namely the connection
establishment between the peers and the leader election.
539
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:47:53 UTC from IEEE Xplore.  Restrictions apply. 
The LOG events correspond to the timestamped entries
logged by log4j, while the remaining events were collected by
the syscall tracer. To ease the understanding of the diagram,
we highlight certain events with a circled number and display
their message content (for LOG events) or payload (for SND
and RCV events).
Figure 5 shows that, after booting, the server joining the
quorum starts by connecting to the existing peer. In particular,
the LOG events identiﬁed by 1 and 3 reveal that the process
5598 is the node with the server identiﬁer (sid) 1 while process
5670 has sid = 2. Note that the events also reveal the lines
of code at which the messages were logged, namely lines 365
and 644 of the QuorumCnxManager class.
The most interesting part of the diagram is arguably the
leader election procedure though, since it is one of the major
applications of fault-tolerant consensus protocols. When the
two quorum peers are connected, server 1 triggers a new leader
election (see event 2 ). In Zookeeper, each server can be in one
of the following states: LOOKING, FOLLOWING, LEADING
and OBSERVING. At
the beginning of the execution, all
servers are in the LOOKING state and vote in themselves
to be the leader by sending notiﬁcations to the other servers
with the leader ﬁeld set to their sid (see messages 4 ,
5
and 6 ). If a server receives a notiﬁcation with a sid higher
than its own, then it updates its vote proposal to the higher
sid and broadcasts the new vote proposal to the rest of the
quorum. Note that, since there are no client requests during
this execution, the last seen transaction identiﬁer zxid remains
unchanged for both servers. Otherwise the servers would vote
for the peer with higher zxid.
In a nutshell, the diagram of Figure 5 reveals the following
leader election protocol in Zookeeper:
• Server 1 sends the vote message
{“leader” : 1} to server 2;
{“leader” : 2} to server 1;
• Server 2 sends the vote message
4 with payload
5 with payload
• Server 1 receives the vote message sent by server 2,
updates its vote proposal for the latter because it has
higher sid, and sends back the updated vote – message
6 with new payload {“leader” : 2} – to server 2;
• Server 1 and server 2 update their state from LOOKING
to FOLLOWING 5 and LEADING 6, respectively, as indi-
cated by the log messages.
A further analysis of this space-time diagram also allows
drawing some conclusions regarding the Zookeeper’s behavior:
is sent twice
due to a timeout that occurs when a server does not receive
enough notiﬁcations within a given time frame.
a) Notiﬁcation timeout: The message 4
b) Message partitioning: The sending of a message is
actually partitioned into several SND events, i.e., to write
syscall executions. Inspecting the Zookeeper’s source code7,
we noticed that the messages sent during the leader election
5FastLeaderElection:636 - leader=2, ..., my id=1, my state=FOLLOWING
6FastLeaderElection:636 - leader=2, ..., my id=2, my state=LEADING
7See class QuorumCnxManager at line 698.
540
)
s
m
(
n
o
i
t
a
r
u
D
20
15
10
5
0
15.76
9.11
normal
strace
Fig. 6. Performance impact on Zookeeper execution caused by tracing with
strace.
protocol are composed by an integer and a buffer. The integer
is sent by executing the write syscall four times, while sending
the buffer requires a single write invocation.
c) Causality: The diagram shows that messages 4 and
5 are not causally related, because the sender and receiver
threads execute concurrently. In contrast, there is a causal
relationship between messages 5 and 6 based on an state
change. Upon reception, message 5 is added to a queue by
the receiver thread. Afterwards, the sender thread dequeues
the message, processes it (i.e., updates the vote proposal of
server 1), and sends message 6 to server 2. Therefore, 5 →
receiver thread enqueues message → sender thread dequeues
message → change of vote proposal → 6 .
B. Performance Impact of Syscall-level Tracing
We developed a micro-benchmark to evaluate the perfor-
mance overhead imposed on Zookeeper due to tracing syscalls
with strace. The micro-benchmark consists of a client issuing
requests to two Zookeeper servers. Concretely,
the client
performs 10K iterations of four operations: i) check whether a
znode exists, ii) create a new znode, iii) check again whether
the znode exists, and iv) delete the created znode.
Figure 6 compares the average duration of an iteration (in
milliseconds) between a vanilla execution of Zookeeper and an
execution with strace. As expected, enabling the tracing affects
negatively the runtime performance, causing Zookeeper to be
1.7× slower comparing to the baseline.
C. Scalability of Constraint Solving
Depending on the debugging level, message logs may
contain hundreds or thousands of entries. In order to better
understand how the constraint solving time varies with an in-
creasing amount of log entries, we ran the same conﬁguration
of Zookeeper for INFO and DEBUG logging levels. To further
increase the log size, we duplicated the number of entries on
both cases log. The resulting logs contained 568 events for the
DEBUG level and 342 events for the INFO level.
The time required by Z3 to solve the constraint models
for both log ﬁles is depicted in Figure 7. The results show
that adding the DEBUG-level log events to the model caused
the solver to take 3.18× more time to ﬁnd a solution than
with an INFO-level log. Although a trade-off must be made
between the duration of the constraint solving and the amount
of information logged, we believe that Falcon is useful in
practice and much more scalable than manual log analysis.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:47:53 UTC from IEEE Xplore.  Restrictions apply. 
456
)
s
m
(
n
o
i
t
a
r
u
D
600
400
200
0
143
INFO
DEBUG
Fig. 7. Time spent on solving the generated models for both levels of
debugging: INFO and DEBUG. Solving the model that contains DEBUG-
level logs signiﬁcantly increases the duration of model solving.
VI. RELATED WORK
Similarly to Falcon, prior work has also focused on tracing
distributed systems executions for performance and correct-
ness analysis.
Sherlog [2] is a tool that analyses source code and runtime
logs in order to isolate the cause of errors occurred at produc-
tion. However, it assumes that the log is generated on single
machine, hence not being suitable for distributed systems.
DTrace [13] and Fay [14] are two dynamic instrumentation
systems able to help diagnosing performance degradation
issues. Unlike Falcon though, they are not capable of estab-
lishing causality relationships between events.
X-Trace [8] is a tracing framework that provides a com-
prehensive view of distributed systems, using execution trees
constructed from propagated metadata within each network
protocol. Dapper
[7] is a tracing infrastructure developed
by Google to trace end-to-end requests in Google services.
These traces are generated through RPC instrumentation, with
support for annotations. Magpie [6] is an online modeling
system that correlates interactions, or events, between compo-
nents in order to generate a performance model of the system.
Pinpoint [15] and Pivot Tracing [5] are similar to Magpie but
allow the execution of distributed queries during the analysis
process. Canopy [4] is an end-to-end performance tracing tool,
developed by Facebook, that records causally-related perfor-
mance data from an end-to-end execution path. Although these
tools and frameworks are designed for diagnosing performance
issues,
their
traces could be part of the Falcon’s pipeline. Moreover, as
these systems do not provide data visualization features, an
integration with Falcon would further improve their usefulness
for in-house log analysis and debugging.
they could be combined with Falcon in that
VII. CONCLUSION
In this paper we introduce Falcon, an extensible tool
pipeline for combining and visualizing log data from several
data sources. The key contribution of this tool is the ability to
merge log data from multiple sources and establish happens-
before relationships between events, providing a coherent
diagram for a visual analysis.
The tool is applied to Zookeeper and demonstrated with a
syscall trace and log4j log ﬁles. The resulting diagram helps in
understanding how remote threads interact among themselves
and what messages were exchanged to execute a given task.
Clearly, the combination of hundreds of events that is ordered
by the SMT solver to produce a trace would clearly be
unfeasible manually. Additionally, we assess the performance
impact on syscall-level tracing in Zookeeper, showing that the
impact is tolerable, in line with what is expected from a more
detailed log level conﬁguration in log4j.
ACKNOWLEDGMENT
The authors would like to thank the anonymous reviewers
for their valuable feedback. This work is ﬁnanced by the
ERDF – European Regional Development Fund through the
Operational Programme for Competitiveness and Internation-
alisation - COMPETE 2020 Programme within project POCI-
01-0145-FEDER-006961, and by National Funds through the
Portuguese funding agency, FCT - Fundac¸˜ao para a Ciˆencia
e a Tecnologia as part of project UID/EEA/50014/2013. The
research leading to these results has received funding from
the European Union’s Horizon 2020 - The EU Framework
Programme for Research and Innovation 2014-2020, under
grant agreement No. 732051.
REFERENCES
[1] X. Zhao, K. Rodrigues, Y. Luo, M. Stumm, D. Yuan, and Y. Zhou,
“Log20: Fully automated optimal placement of log printing statements
under speciﬁed overhead threshold,” in SOSP ’17. New York, NY,
USA: ACM, 2017.
[2] D. Yuan, H. Mai, W. Xiong, L. Tan, Y. Zhou, and S. Pasupathy,
“Sherlog: error diagnosis by connecting clues from run-time logs,” in
ACM SIGARCH Comp. Arch. news, vol. 38, no. 1. ACM, 2010.
[3] L. Lamport, “Time, clocks, and the ordering of events in a distributed
system,” Communications of the ACM, vol. 21, no. 7, 1978.
[4] J. Kaldor, J. Mace, M. Bejda, E. Gao, W. Kuropatwa, J. O’Neill, K. W.
Ong, B. Schaller, P. Shan, B. Viscomi, V. Venkataraman, K. Veeraragha-
van, and Y. J. Song, “Canopy: An end-to-end performance tracing and
analysis system,” in SOSP ’17. New York, NY, USA: ACM, 2017.
[5] J. Mace, R. Roelke, and R. Fonseca, “Pivot tracing: Dynamic causal
monitoring for distributed systems,” in SOSP ’15. ACM, 2015.
[6] P. Barham, R. Isaacs, R. Mortier, and D. Narayanan, “Magpie: Online
modelling and performance-aware systems.” in HotOS ’03, 2003.
[7] B. H. Sigelman, L. A. Barroso, M. Burrows, P. Stephenson, M. Plakal,
D. Beaver, S. Jaspan, and C. Shanbhag, “Dapper, a large-scale distributed
systems tracing infrastructure,” Tech. Rep.
[8] R. Fonseca, G. Porter, R. H. Katz, S. Shenker, and I. Stoica, “X-trace:
USENIX
A pervasive network tracing framework,” in NSDI ’07.
Association, 2007.
[9] F. Mattern, “Virtual time and global states of distributed systems,” in
Parallel and Distributed Algorithms. North-Holland, 1988, pp. 215–
226.
[10] I. Beschastnikh, P. Wang, Y. Brun, and M. D. Ernst, “Debugging dis-
tributed systems: Challenges and options for validation and debugging,”
Communications of the ACM, vol. 59, no. 8, pp. 32–37, Aug. 2016.
[11] L. De Moura and N. Bjørner, “Z3: An efﬁcient SMT solver,” in TACAS
’08/ETAPS ’08. Springer-Verlag, 2008.
[14]
coordination for internet-scale systems.”
[12] P. Hunt, M. Konar, F. P. Junqueira, and B. Reed, “Zookeeper: Wait-free
[13] J. Mauro, DTrace: Dynamic Tracing in Oracle R(cid:2) Solaris, Mac OS X,
and FreeBSD. Prentice Hall, 2011.
´U. Erlingsson, M. Peinado, S. Peter, M. Budiu, and G. Mainar-Ruiz,
“Fay: extensible distributed tracing from kernels to clusters,” ACM
Transactions on Computer Systems (TOCS), vol. 30, no. 4, 2012.
[15] M. Y. Chen, E. Kiciman, E. Fratkin, A. Fox, and E. Brewer, “Pinpoint:
Problem determination in large, dynamic internet services,” in DSN ’02.
IEEE, 2002.
541
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:47:53 UTC from IEEE Xplore.  Restrictions apply.