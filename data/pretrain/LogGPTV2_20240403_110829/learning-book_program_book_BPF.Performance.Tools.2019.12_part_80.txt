(6oot peubtsun.| .etep"n
srv_vorker_thread
start_thread
nysq]d (9908)
1. 6
---
## Page 636
13.2 BPF Tools
669
_rax_spin_unlock_irqrestore
_rax_spin_unlock_lrqrestore
uouunxex
exous-dnexen
sock_def_readable
Dsupoes"ueexas"xtun
Bgapuasxoos
SYSC_sendito
SyS_sendto
do_sysca11_64
entry_SYsCALL_64_after_hmframe
_send
v1o_vrite
net_vrite_packet
net_flush
net_send_ok(THD*, unsigned int, unsigned int, unsigned long long, unsigned lon...
Protocol_classlci:send_ok (unslgned Lnt, unsigned Int, unslgned long long, unsi.. *
THD::send_statement_status ()
d1spatch_connand (THD*, Cox_DATA const*, enun_sezvez_cormand)
(xGH.)pceuuoo"op
handle_connectlon
pfs_spaxn_thread
start_thread
nysq1d (9908)
17
The output was hundreds of stack traces and their frequency counts. Only three have 
been included here. The first stack shows MySQL. statement becoming a join and finally a
my_hash_sort_simple( on CPU. The last stack shows a socket send in the kernel: this stack
has a delimiter between the kernel and user stacks (°"), which was included due to the profile(8)
d option.
Since the output was hundreds of stack traces, it can be helpful to visualize it as a flame graph.
profile(8) can generate folded format output (r) for input by the flame graph software. For
example, with a 30-second profile:
xa TooTTgoxd-no  out.proflle01.svg
Figure 13-2 shows the same workload as a flame graph.
---
## Page 637
600 Chapter 13 Applications
CPU Flame Graph
Figure 13-2 MySQL server CPU flame graph
The flame graph shows where the bulk of the CPU time is spent by the widest frames: in the
middle, dispatch_command0 was present in 69% of samples, and JOIN:exec() was present in
19%. These numbers are shown with a mouse-over of each frame, and frames can be clicked to
zoom in on more details.
Apart from explaining CPU consumption, CPU flame graphs also show which functions are
executing, which can become possible targets for BPF tracing, This flame graph showed functions
such as do_command(), mysqld_stmt_execute(), JOIN:exec(), and JOIN:optimize(): these can all
be instrumented directly using uprobes, and their arguments and latency studied.
This is only working because ’'m profiling a MySQL server that has been compiled with frame
pointers, with libc and libpthread versions that also have frame pointers. Without this, BPF would
be unable to walk the stacks properly. This is discussed in Section 13.2.9.
See Chapter 6 for more about profile(8) and CPU flame graphs.
---
## Page 638
13.2 BPF Tools
601
13.2.4 threaded
threaded(8)? samples on-CPU threads for a given process and shows how often they were on-CPU,
for verifying how well they are multi-threaded. For example, for MySQL server:
thzeaded.bt $(pgrep aysqld)
Attach.ing 3 probes...
Sanpllng PID 22T4 thxeads at 99 Hertz. Ctr1-C to end.
23 :47: 13
[nysq1d, 2317]: 1
e[nysq]d, 2319] : 2
[nysq1d, 231B] : 3
e[nysq]d, 2316] : 4
e[nysq1d, 2534] : 55
23 :47: 14
e[nysq]d, 2319] : 2
e[nyaq]d, 2316]: 4
[nysq1d, 2317]: 5
e[nysq]d, 2534] : 51
[. --]
This tool prints per-second output, and for this MySQL server workload, it shows that only one
thread (thread ID 2534) was significantly on CPU.
This is intended to characterize how well multi-threaded applications are spreading work across
their threads. Since it uses timed sampling, it may miss short wakeups by threads that occur
between the samples.
Some applications change the thread names. For example, using threaded(8) on the freecol Java
application from the previous chapter:
1thzeaded.bt $(pgrep java)
Attaching 3 probes...
Sanpling PID 32584 threads at 99 Heztz. Ctx1-C to end.
23 :52 : 12
[GC Thread#0, 32591] : 1
e[VM Thread, 32611]: 1
e[FreeCo1C1lent:b, 32657]: 6
[aMTEventQueue-, 32629| : 6
?[FreeCo1Sexvex:-, 974] : B
threaded.d to show how other threads were unsble to run with the issue. I also developed this version for this book
---
## Page 639
602
Chapter 13 Applications
[FreeColServer:A, 977] : 11
e[FreeCo1Sexvex:A, 975]: 26
[C1 CompilerThre, 32618] : 29
?[C2 Comp11erThre, 32617| : 44
[C2 CompilerThre, 32616] : 44
?[C2 Comp11erThre, 32615| : 48
[..-]
This makes it clear that the CPU time consumed by this application is mostly spent in the
compiler threads.
threaded(8) works by using timed sampling. The overhead should be negligible at this low
frequency.
The source to threaded(8) is:
#1/usx/local/bin/bpEtrace
BEGIX
1
1f ($1 == 0) (
printf (*usAGE: threaded.bt F10',n*) =
ex1t (1
printf(*Sanpling PID ld threads at 99 Bertz. Ctxl-C to end.\n*, $11
profile:hz:99
/p1d == $1/
[conm, tid] = count[);
interval:s11
t.ime () 
print (81:
clear (81
This tool requires a PID as an argument, and exits if none was provided (S1 defaults to zero).
---
## Page 640
13.2 BPF Tools
603
13.2.5offcputime
offcputime(8), introduced in Chapter 6, is a BCC tool that traces when threads block and leave
the CPUs, and records the duration they were off-CPU with the stack trace. Example output for
MySQL server:
+ offcputime =d -p $(pgrep mysqld)
Tracing off-CPU tine (us] of PID 9908 by user + kernel stack... Hit Ctxl-C to end.
[ . - - ]
finish_task_svltch
schedule
jbd2_1og_xalt_cormit
jbd2_conplete_transaction
ext4_sync_f11e
vfs_fsync_range
do_fsync
sys_fsync
do_aysca11_64
entry_SYscALL_64_after_hvframe
fsync
f11_flush (unslgned long)
log_vrite_up_to (unsigned long, beol) [clone part.56]
txx_comml t_conplete_foz_nysql (txx_c*)
innobase_conmit (handlerton*,THD*, boo1)
ha_conml t_1ou (THD*, boo1, boo1)
TC_LOG_0OMr:rcormit (THD*, boo1)
ha_conmlt_trans (THD*, bool, boo1)
mysq]_execute_connand (THD*, boo1)
Prepared_statenent1iexecute (String*, bool)
Prepared_statenent::execute_1oop (Stxing*, boo1, unslgned chax*, unslgned chax*)
mysqld_stmt_execute (THD*, unsigned long, unsigned long, unsigoed char*, unsign..-
dlspatch_conmand (THD*, Cox_DATA const*, enun_server_cormand)
do_conmand (THD*)
handle_connectlon
pfs_spawm_thread
start_thread
nysq]d (9962)
2458362
---
## Page 641
604
Chapter 13 Applications
[...]
finish_task_switch
schedule
futex_xai t_queve_ne
futex_xa1t
do_futex
SyS_futex
9"Tes.a"op
entzy_SYscALl_64_after_hvfxase
pthread_cond_tinedvaltBeGLIBC_2.3.2
pth.read_cond_tinedvsit
os_event::tined_va.it (tinespec const*)
os_event_xait_t.ine_lov (os_event*, unsigoed long,long)
1ock_valt_tLneout_thread
start_thread
_clone
nyrqld (2311)
10000904
finish_task_svltch
schedule
do_nanosleep
hrtiner_nanosleep
sys_anosleep
9"Tes.a"op
entzy_SYscALL_64_after_hufxame
_nanos1eep
os_th.read_sleep (unsigned long)
peexaxelseu"sxs
start_thread
clone
nysqld (2315)
10001003
The output was hundreds of stacks; only a few have been selected for this example. The first
shows a MySQL statement becoming a commit, a log write, and then an fsync(). Then the code
path crosses into the kernel (°-*) with ext4 handling the fsync, and the thread finally blocks on
a jbd2_log_wait_commit() function. The duration mysqld was blocked in this stack while tracing
was 2458362 microseconds (2.45 seconds): this is the total across all threads.
---
## Page 642
13.2BPF Tools
605
The last two stacks show a lock_wait_timeout_thread() waiting for events via pthread_cond_timewait(),
and the srv_master_thread() sleeping. The output of offcputime(8) can often be dominated by
such waiting and sleeping threads, which are usually normal behavior and not a performance
issue. Your task is to find the stacks that are blocking during application requests, which are the
issue.
Off-CPU Time Flame Graph
Creating an off-CPU time flame graph provides a way to quickly focus on the blocked stacks of
interest. The following commands capture 10 seconds of off-CPU stacks and then use my flame
graph software to generate the flame graph:
qx3 *Toeurandoggono  out .offcputime01. svg
This produced the flame graph shown in Figure 13-3, where I have used the search feature to high-
light frames containing *do_command° in magenta: these are the code paths for MySQL requests
and are what the clients are blocking on.
Off-CPU Time Flame Graph
Reet Searth
P
Figure 13-3 Off-CPU time flame graph for MySQL server, highlighting do_command
---
## Page 643
909
6Chapter 13 Applications
Most of the flame graph in Figure 13-3 is dominated by thread pools waiting for work. The time
blocked in server commands is shown by the narrow tower that includes the do_command()
frame, highlighted in magenta Fortunately, flame graphs are interactive, and this tower can be
clicked for zoom. This is shown in Figure 13-4.
Off-CPU Time Flame Graph
Figure 1.3-4 Off-CPU time flame graph zoomed to show server commands
The mouse pointer is over ext4_sync_file() to show the time spent in this path at the bottom:
3.95 seconds in total. This is the bulk of the blocking time in do_commandO, and shows the
target to optimize to improve server performance.
bpftrace
I wrote a bpftrace version of offcputime(8); see the next section on offcpuhist(8) for the source code.
Final Notes
This off-CPU analysis capability is the companion to CPU analysis by profile(8), and between
them, these tools can shed light on a wide range of performance issues.
The performance overhead of offcputime(8) can be significant, exceeding 5%, depending on
the rate of context switches. This is at least manageable: it could be run for short periods in
---
## Page 644
13.2 BPF Tools
607
production as needed. Prior to BPF, performing off-CPU analysis involved dumping all stacks to
user-space for post processing, and the overhead was usually prohibitive for procdluction use.
As with profile(8), this is only producing full stacks for all code because I've recompiled MySQL
server and system libraries with frame pointers. See Section 13.2.9 for more about this.
See Chapter 6 for more about offcputime(8). Chapter 14 covers additional tools for off-CPU
analysis: wakeuptime(8) and offwaketime(8).
13.2.6 offcpuhist
offcpuhist(8) is similar to offcputime(8). It traces scheduler events to record off-CPU time with
stack traces, but it shows the time as histograms instead of sums. Some example output from
MySQL server:
offcpuhist.bt S (pgrep nysqld)
Attaching 3 probes...
Tracing nanosecond tine In off-CPU stacks. Ctx1-C to end.
[..-]
finish_task_switch+1
schedule+44
futex_xait_queve_ne+196
futex_xa1t+266
do_futex+805
SyS_futex+315
do_sysca11_64+115
entzy_SYscALL_64_after_hvframe+61
pthread_cond_valt+432
pthread_cond_xait89G11Bc_2.3.2+36
os_event_xal t_1ow (os_event* , 1ong] +64
srv_vorker_thread+503
80z+peexus1xe1s
_clone+63
 mysq1d] :
[2K, 4K)
134 18898898
[4K, 83]
293 e ee
[8K, 16K)
886 186988 889886 886986986986986988 889886 886986986986986 1
(x2x9
493 1e8e88e88e88e888e88e88e8ee88e
[TT Baug] xooq eoeujQ TT0Z eg wouy 0os pmdogon Au fq peadsul *6toZ-qay-9T uo ycoq s4a ioy ≥ pejeauo I :ugu0 @
that displayed user off-CPU stack traces with histograms. This is the frst ff-CPU analysis tool written for bpfrace.
---
## Page 645
608
Chapter 13 Applications
[32K, 64K]
447 188988988988688698698898698
[64%, 128K]
263 1eeeeeeeeee8e
[128K, 256K]
8518898
[256K, 512K)
71
[512K,1)
0 1
[1M, 2H)
 1
[2M, 4M)
01
[4M, 8M)
306 1eeeeeeeeeeeeeeeee
[8M, 168)
747 1889889889886 8868888986986988889886 886988
finish_task_swltch+1
schedule+ 44
schedule_hxt.ineout_range_clock+185
schedule_hrt.ineout_range+19
po11_schedule_tineout+69
096+T[od"s.s°op
sys_po11+15s
do_sysca11_64+115
entzy_sSYscALL_64_afte_hvfrase+61
_GI_po11+110
vio_io_vait+141
vlo_socket_lo_ualt+24
vio_resd+226
net_read_packet [at_net*, un.signed long* +14]
my_net_read+412
Protocol_classlc::get_con
do_command (THD*) +192
and*) +60
handle_connect.Lon+680
pfs_spas_thread+337
80z+peexua"1xe1s
_clone+63
， nysqld] :
[2K, 4K)
7531889889
[4K, 8K)
2081 1eeeeeeeeee8ee8ee8e
[8K, 16K]
5759 1eee88e88e88e 88ee8ee8ee8ee8ee88e88e88 88ee8ee8ee8ee8e1
[16K, 32K)
3595 188e88e88e888888e88e88e88e8ee88e8
[32K, 64K]
4045 1869889889886 886986986986986988988988
[64%, 128K]
383 eeeeeeeeeeeeeeeeeeee8ee
[128K, 256K)
751 1869889
[256K, 512K)
4B1
---
## Page 646
13.2 BPF Tools
609
[512K,14)
161
[1H, 2H)
[2M,4M)
71
The output has been truncated to show just the last two stack traces. The first shows a bi-modal
latency distribution as the srv_worker_thread() threads wait for work: the output ranges are
in nanoseconds, and show one mode around 16 microseconds and another between 8 and
16 milliseconds (labeled * [8M, 16M)°). The second stack shows many shorter waits in a
net_read_packet() code path, usually taking less than 128 microseconds.
This works by tracing scheduler events using kprobes. The overhead, like with offcputime(8), can
be significant, and it is only intended to be run for short durations.
The source to offcpuhist(8) is:
#1/usx/local/bin/bpEtrace
#1nclude 
BEGIX
printf (*Txacing nanosecond tine In off-CP0 stacks. Ctx1-C to end.\n*) 