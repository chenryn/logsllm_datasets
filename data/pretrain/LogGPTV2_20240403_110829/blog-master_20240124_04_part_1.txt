## 开源PolarDB|PostgreSQL 应用开发者&DBA 公开课 - 5.3 PolarDB开源版本必学特性 - PolarDB 安装部署               
### 作者                            
digoal                            
### 日期                            
2024-01-24                            
### 标签                            
PostgreSQL , PolarDB , 应用开发者 , DBA , 公开课                  
----                            
## 背景           
## PolarDB 安装部署           
### 1、安装部署 PolarDB 单机版 
PS:   
- 前置条件, 请在本机先安装docker desktop.    
- 注意将文中命令内出现的`${your_data_dir}`替换为你实际的目录全路径.   
在单机文件系统（如 ext4）上部署 PolarDB-PG，适用于所有PolarDB计算节点都可以访问相同本地磁盘存储的场景。     
单机版通常用于快速搭建PolarDB学习或开发环境.      
1\.1、拉取镜像    
我们在 DockerHub 上提供了 PolarDB-PG 的 [本地实例镜像](https://hub.docker.com/r/polardb/polardb_pg_local_instance/tags)，里面已包含启动 PolarDB-PG 本地存储实例的入口脚本。镜像目前支持 `linux/amd64` 和 `linux/arm64` 两种 CPU 架构。    
```    
docker pull polardb/polardb_pg_local_instance    
```    
1\.2、初始化数据库    
在本机新建一个空白目录 `${your_data_dir}` 作为 PolarDB-PG 实例的数据目录。启动容器时，将该目录作为 `VOLUME` 挂载到容器内，对数据目录进行初始化。在初始化的过程中，可以传入环境变量覆盖默认值：    
- `POLARDB_PORT`：PolarDB-PG 运行所需要使用的端口号，默认值为 `5432`；镜像将会使用三个连续的端口号（默认 `5432-5434`）    
- `POLARDB_USER`：初始化数据库时创建默认的 superuser（默认 `postgres`）    
- `POLARDB_PASSWORD`：默认 superuser 的密码    
使用如下命令初始化数据库(`--rm`表示执行后自动删除容器, 但是`VOLUME`目录中的数据被保留, 实现初始化数据库实例目的.)：    
```    
docker run -it --rm \
    --env POLARDB_PORT=5432 \
    --env POLARDB_USER=u1 \
    --env POLARDB_PASSWORD=your_password \
    -v ${your_data_dir}:/var/polardb \
    polardb/polardb_pg_local_instance \
    echo 'done'    
```
例如:
```
mkdir /Users/digoal/polardb_data
docker run -it --rm \
    --env POLARDB_PORT=5432 \
    --env POLARDB_USER=postgres \
    --env POLARDB_PASSWORD=hellopwd123 \
    -v /Users/digoal/polardb_data:/var/polardb \
    polardb/polardb_pg_local_instance \
    echo 'done'     
```
1\.3、启动 PolarDB-PG 服务    
数据库初始化完毕后，使用 `-d` 参数以后台模式创建容器，启动 PolarDB-PG 服务。通常 PolarDB-PG 的端口需要暴露给外界使用，使用 `-p` 参数将容器内的端口范围暴露到容器外。比如，初始化数据库时使用的是 `5432-5434` 端口，如下命令将会把这三个端口映射到容器外的 `54320-54322` 端口：    
```  
docker run -it -d \
    --cap-add=SYS_PTRACE \
    --cap-add SYS_ADMIN \
    --privileged=true \
    --name polardb_pg \
    --shm-size=1g \
    -p 54320-54322:5432-5434 \
    -v ${your_data_dir}:/var/polardb \
    polardb/polardb_pg_local_instance  
```  
或者也可以直接让容器与宿主机共享网络：    
```  
docker run -it -P -d \
    --cap-add=SYS_PTRACE \
    --cap-add SYS_ADMIN \
    --privileged=true \
    --name polardb_pg \
    --shm-size=1g \
    --network=host \
    -v ${your_data_dir}:/var/polardb \
    polardb/polardb_pg_local_instance  
```
例如:
```
docker run -it -P -d \
    --cap-add=SYS_PTRACE \
    --cap-add SYS_ADMIN \
    --privileged=true \
    --name polardb_pg \
    --shm-size=1g \
    --network=host \
    -v /Users/digoal/polardb_data:/var/polardb \
    polardb/polardb_pg_local_instance    
```
### 2、安装部署 PolarDB 集群版(on ECS + ESSD)   
PS: 前置条件   
- ECS 的系统选择Linux, 例如Debian 11, CentOS 8    
- 需要在ECS系统中安装docker server/desktop, 以便运行打包好的 pfs/PolarDB 容器   
[阿里云 ESSD（Enhanced SSD）云盘](https://help.aliyun.com/document_detail/122389.html) 结合 25 GE 网络和 RDMA 技术，能够提供单盘高达 100 万的随机读写能力和单路低时延性能。阿里云 ESSD 云盘支持 NVMe 协议，且可以同时挂载到多台支持 NVMe 协议的 ECS（Elastic Compute Service）实例上，从而实现多个 ECS 实例并发读写访问，具备高可靠、高并发、高性能等特点。更新信息请参考阿里云 ECS 文档：  
- [支持 NVMe 协议的云盘概述](https://help.aliyun.com/document_detail/256487.html)  
- [开启多重挂载功能](https://help.aliyun.com/document_detail/262105.html)  
接下来指导您完成以下过程：  
- 1、部署两台阿里云 ECS 作为计算节点  
- 2、将一块 ESSD 云盘多重挂载到两台 ECS 上，作为共享存储  
- 3、在 ESSD 共享存储上格式化分布式文件系统 PFS  
- 4、基于 PFS，在两台 ECS 上共同搭建一个存算分离、读写分离的 PolarDB 集群  
![pic](20240124_04_pic_001.png)    
2\.1、部署阿里云 ECS  
首先需要准备两台或以上的 [阿里云 ECS](https://www.aliyun.com/product/ecs)。目前，ECS 对支持 ESSD 多重挂载的规格有较多限制，详情请参考 [使用限制](https://help.aliyun.com/document_detail/256487.htm?spm=a2c4g.11186623.0.0.61397e72QGaXV0#section-4w6-dyy-otg)。仅 部分可用区、部分规格（`ecs.g7se、ecs.c7se、ecs.r7se`）的 ECS 实例可以支持 ESSD 的多重挂载。如图，请务必选择支持多重挂载的 ECS 规格：  
![pic](20240124_04_pic_002.png)    
对 ECS 存储配置的选择，系统盘可以选用任意的存储类型，数据盘和共享盘暂不选择。后续再单独创建一个 ESSD 云盘作为共享盘：  
![pic](20240124_04_pic_003.png)    
如图所示，在 同一可用区 中建好两台 ECS：  
![pic](20240124_04_pic_004.png)    
2\.2、准备 ESSD 云盘  
在阿里云 ECS 的管理控制台中，选择 存储与快照 下的 云盘，点击 创建云盘。在与已经建好的 ECS 所在的相同可用区内，选择建立一个 ESSD 云盘，并勾选 多实例挂载。如果您的 ECS 不符合多实例挂载的限制条件，则该选框不会出现。  
![pic](20240124_04_pic_005.png)    
ESSD 云盘创建完毕后，控制台显示云盘支持多重挂载，状态为 待挂载：  
![pic](20240124_04_pic_006.png)    
接下来，把这个云盘分别挂载到两台 ECS 上：  
![pic](20240124_04_pic_007.png)    
挂载完毕后，查看该云盘，将会显示该云盘已经挂载的两台 ECS 实例：  
![pic](20240124_04_pic_008.png)    
2\.3、检查云盘  
通过 ssh 分别连接到两台 ECS 上，运行 `lsblk` 命令可以看到：  
- `nvme0n1` 是 40GB 的 ECS 系统盘，为 ECS 私有  
- `nvme1n1` 是 100GB 的 ESSD 云盘，两台 ECS 同时可见  
```  
$ lsblk  
NAME        MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT  
nvme0n1     259:0    0   40G  0 disk  
└─nvme0n1p1 259:1    0   40G  0 part /etc/hosts  
nvme1n1     259:2    0  100G  0 disk  
```  
2\.4、准备分布式文件系统(PFS)  
2\.4\.1、PFS 编译安装  
接下来，将在两台 ECS 上分别部署 PolarDB 的主节点和只读节点。作为前提，需要在 ECS 共享的 ESSD 块设备上 格式化并挂载 PFS。  
请先在ECS主机上安装Docker desktop/server. 具体步骤请参考docker官网文档( https://www.docker.com/ ), 书中略过.    
拉取polardb_pg_binary镜像, 将在所有PolarDB计算节点(ECS)使用这个镜像的容器来运行pfs和数据库.    
```  
docker pull polardb/polardb_pg_binary  
```  
在所有PolarDB计算节点(ECS) 启动容器  
```  
docker run -d -it --network=host \
    --cap-add=SYS_PTRACE --cap-add SYS_ADMIN \
    --privileged=true \
    --name polardb_pg \
    --shm-size=1g \
    polardb/polardb_pg_binary \
    /bin/bash   
```  
在PolarDB计算节点(ECS) 进入容器的方法:  
```  
docker exec -ti polardb_pg bash   
```  
2\.4\.2、块设备重命名(如果命名已符合pfs需求, 可略过. 例如on ECS+ESSD 可略过该步骤.)  
PFS 仅支持访问 以特定字符开头的块设备（详情可见 [PolarDB File System](https://github.com/ApsaraDB/PolarDB-FileSystem) 源代码的 [src/pfs_core/pfs_api.h](https://github.com/ApsaraDB/PolarDB-FileSystem/blob/master/src/pfs_core/pfs_api.h) 文件）：  
```  
#define PFS_PATH_ISVALID(path)                                  \
    (path != NULL &&                                            \
     ((path[0] == '/' && isdigit((path)[1])) || path[0] == '.'  \
      || strncmp(path, "/pangu-", 7) == 0                       \
      || strncmp(path, "/sd", 3) == 0                           \
      || strncmp(path, "/sf", 3) == 0                           \
      || strncmp(path, "/vd", 3) == 0                           \
      || strncmp(path, "/nvme", 5) == 0                         \
      || strncmp(path, "/loop", 5) == 0                         \
      || strncmp(path, "/mapper_", 8) ==0))  
```  
因此，为了保证能够顺畅完成后续流程，建议在所有访问块设备的节点上使用相同的软链接访问共享块设备。例如，在 NBD 服务端主机上，使用新的块设备名 `/dev/nvme1n1` 软链接到共享存储块设备的原有名称 `/dev/vdb` 上：  
```  
sudo ln -s /dev/vdb /dev/nvme1n1  
```  
在 NBD 客户端主机(PolarDB计算节点)上，使用同样的块设备名 `/dev/nvme1n1` 软链到共享存储块设备的原有名称 `/dev/nbd0` 上：  
```  
sudo ln -s /dev/nbd0 /dev/nvme1n1  
```  
这样便可以在服务端和客户端两台主机上使用相同的块设备名 `/dev/nvme1n1` 访问同一个块设备。  
2\.4\.3、块设备格式化  
使用 任意一台主机的容器，在共享存储块设备上格式化 PFS 分布式文件系统：  
```  
sudo pfs -C disk mkfs nvme1n1  
```  
PS: 格式化 PFS 分布式文件系统仅需在集群中任意一个计算节点执行一次即可.    
2\.4\.4、PFS 文件系统挂载  
在能够访问共享存储的 所有主机节点的容器中 上分别启动 PFS 守护进程，挂载 PFS 文件系统：  
```  
sudo /usr/local/polarstore/pfsd/bin/start_pfsd.sh -p nvme1n1 -w 2  
```  
2\.5、PolarDB 读写节点部署  
在作为PolarDB RW节点的主机的容器中进行部署.  