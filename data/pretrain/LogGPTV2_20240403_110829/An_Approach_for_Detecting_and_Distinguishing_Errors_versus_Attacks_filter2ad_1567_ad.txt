Correct
9.1
9.2
9.3
9.4
9.5
Time [day]
9.6
9.7
9.8
9.9
10
]
%
[
y
t
i
i
d
m
u
H
110
100
90
80
70
60
50
40
30
20
10
0
9
Faulty
Observed
Correct
9.1
9.2
9.3
9.4
9.5
Time [day]
9.6
9.7
9.8
9.9
10
(a) Attack on the temperature read-
ings.
(b) Attack on the humidity read-
ings.
Figure 10. Dynamic Deletion attack.
i ↓, j → (29,56)
(29,56)
0.001
(20,71)
(13,78)
(0,95)
(12,94)
(0,0)
0
0
0
0
0
(20,71)
0.999
1
0
0
0
0
(13,78)
(0,95)
(12,94)
(0,0)
0
0
0.999
0
0
0
0
0
0
1
0
0
0
0
0
0
1
0
0
0
0.001
0
0
1
Table 6. BCO matrix for malicious sensor 7 (Dy-
namic Deletion attack).
the observable environment state to remain (20,71).
A similar injection experiment can be done for Dynamic
Creation attacks. In the considered example, malicious nodes
inject high temperature values and low humidity values into
the system to force a change in the overall, observed state
of the environment, whereas the correct environmental tem-
perature and humidity remain approximately constant (see
Fig. 11). Table 7 reports observation probability matrix BCO
obtained by the proposed methodology for a malicious sensor
2. It can be seen that the column probabilities are not orthog-
onal (see column (12,95) and column (25,69)). This indicates
that an adversary has created an additional state (state (25,69)
in the example).
4.3 Alarm Generation
Figure 12 shows the raw alarms generated for a non-faulty
node and for a faulty node at the output of the Alarm Gener-
ation module of Fig. 1. We can see that although the gener-
i
]
s
u
s
e
c
[
l
e
r
u
t
a
r
e
p
m
e
T
Faulty
Observed
Correct
70
60
50
40
30
20
10
0
8
8.2
8.4
8.6
8.8
9
Time [day]
9.2
9.4
9.6
9.8
10
]
%
[
y
t
i
i
d
m
u
H
110
100
90
80
70
60
50
40
30
20
10
0
8
Faulty
Observed
Correct
8.2
8.4
8.6
8.8
9
Time [day]
9.2
9.4
9.6
9.8
10
(a) Attack on the temperature read-
ings.
(b) Attack on the humidity read-
ings.
Figure 11. Dynamic Creation Attack.
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:29:25 UTC from IEEE Xplore.  Restrictions apply. 
i ↓, j → (17,86)
(17,86)
(31,56)
(18,78)
(12,95)
1
0
0
0
(31,56)
(18,78)
(12,95)
(25,69)
0
1
0
0
0
0
1
0
0
0
0
0
0
0
0.3546
0.6454
Table 7. BCO matrix for malicious sensor 2 (Dy-
namic Creation attack).
2
1.5
1
0.5
0
0
2
1.5
1
0.5
0
0
r
o
s
n
e
S
y
t
l
u
a
f
−
n
o
N
a
r
o
f
m
r
a
A
l
r
o
s
n
e
S
y
t
l
u
a
F
a
r
o
f
m
r
a
A
l
5
10
15
Time [day]
20
25
30
5
10
15
Time [day]
20
25
30
Figure 12. Raw alarms generated for a faulty
and a non-faulty node.
ated alarms clearly indicate the absence and the presence of an
anomaly, the raw alarm data are quite noisy (e.g., 1.5% false
alarm rate for the non-faulty sensor) and appropriate ﬁltering
is required to smoothen them.
5 Related Work
Markov models have been widely used in anomaly detec-
tion systems [5, 6, 11–14]. In [11], a Markov chain is esti-
mated using a training suite and then used to classify nor-
mal versus anomalous behavior by computing different met-
rics, such as miss probability, miss rate, and local entropy.
In [13], a Markov model is used to detect attacks against
web-servers and web-based applications. Nong Ye et al. [14]
analyze the robustness of a Markov chain-based approach to
anomaly detection and conclude that Markov chains perform
well only under low noise levels in the data. Hidden Markov
Models (HMM) provide a more powerful mathematical tool
than standard Markov models and have also been explored in
the domain of anomaly detection [5, 6]. In [5], HMMs are
used to model an application’s behavior by monitoring sys-
tem call invocations. Similarly to the other anomaly detection
approaches cited above, the technique presented in [5] is not
designed for distributed systems and does not deal with ana-
lyzing and classifying the nature of the detected anomalies.
6. Conclusions
This paper proposes an on-the-ﬂy statistical technique to
detect and distinguish faulty data from malicious data in a dis-
tributed sensor network. The technique can learn the correct
system behavior dynamically with no separate training phase
by exploiting the natural redundancy present in sensor net-
works; furthermore, it can classify faults versus attacks based
on structural relations between two types of Hidden Markov
Models learned. Whereas the focus of the current study is in
sensor networks, the proposed mathematical framework can
be generalized for different types of distributed computing en-
vironments. For instance, as a future extension of this work
we are considering the application of the proposed method-
ology to monitor intrusions and failures in a large cluster of
machines dedicated to running an e-commerce application.
Acknowledgments
This work is
supported in part by MURI grant
N00014-01-1-0576, the Gigascale Systems Research Center
(GSRC/MARCO), and the Motorola Corporation as part of
Motorola Center.
References
[1] R. Szewczyk, J. Polastre, A. Mainwaring, and D. Culler.
In Proc. of Eu-
Lessons from a sensor network expedition.
ropean Workshop on Wireless Sensor Networks, 2004.
[2] A. D. Wood and J. A. Stankovic. Denial of service in sensor
networks. IEEE Computer, 35(10):54–62, Oct. 2002.
[3] C. Karlof and D. Wagner. Secure routing in wireless sensor
networks: Attacks and countermeasures. In First IEEE Inter-
national Workshop on Sensor Network Protocols and Applica-
tions, pages 113–127, May 2003.
[4] B. Przydatek, D. Song, and A. Perrig. Sia: Secure information
aggregation in sensor networks. In Proc. of SenSys, 2003.
[5] C. Warrender, S. Forrest, and B. A. Pearlmutter. Detecting in-
trusions using system calls: Alternative data models. In IEEE
Symposium on Security and Privacy, pages 133–145, 1999.
[6] S.-J. Cho and S.-J. Han. Two sophisticated techniques to
LNCS,
improve HMM-based intrusion detection systems.
2820:207–219, 2003.
[7] A. Mainwaring, J. Polastre, R. Szewczyk, D. Culler, and J. An-
derson. Wireless Sensor Networks for Habitat Monitoring. In
Proceedings of the 1st ACM International Workshop on Wire-
less Sensor Networks and Applications, pages 88–97, 2002.
[8] L. R. Rabiner. A Tutorial on Hidden Markov Models and Se-
IEEE Proceed-
lected Applications in Speech Recognition.
ings, 77(2):257–286, 1989.
[9] M. Basseville and I. Nikiforov. Detection of abrupt changes:
theory and application. Information and system science series.
Prentice Hall, Englewood Cliffs, NJ, 1993.
[10] J. Stiller and G. Radons. Online estimation of hidden Markov
models. IEEE Signal Processing Letters, 6(8):213–215, 1999.
[11] S. Jha, K. Tan, and R. A. Maxion. Markov Chains, Classi-
ﬁers, and Intrusion Detection. In Proceedings of the 14th IEEE
Workshop on Computer Security Foundations, page 206, 2001.
[12] M. Nassehi. Anomaly Detection for Markov Models. Techni-
cal Report RZ 3011 (93057), IBM Research Division, Zurich
Research Laboratory, 1998.
[13] C. Kruegel and G. Vigna. Anomaly Detection of Web-based
Attacks. In Proceedings of the 10th ACM Conference on Com-
puter and Communications Security, pages 251–261, 2003.
[14] N. Ye, Y. Zhang, and C. M. Boror. Robustness of the Markov
Chain Model for Cyber-Attack Detection. IEEE Transactions
on Reliability, 53(1), March 2004.
Proceedings of the 2006 International Conference on Dependable Systems and Networks (DSN’06) 
0-7695-2607-1/06 $20.00 © 2006 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:29:25 UTC from IEEE Xplore.  Restrictions apply.