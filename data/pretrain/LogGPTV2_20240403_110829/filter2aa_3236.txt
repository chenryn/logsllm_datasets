Hadoop: 
Apache’s Open Source 
Implementation of Google’s 
MapReduce Framework
Hacked Existence Team
Joey Calca & Ryan Anguiano
http://hackedexistence.com
Cloud Computing
• Clouds are big piles of other people’s 
machines, plus virtualization
• Remote
• Scalable
• Virtual
• High Level API
• Course Grain data processed in parallel
Courtesy Stanzione, Sannier, and Santanam, Arizona State University
How much data?
• Wayback Machine has 2 PB + 20 TB/month (2006)
• Google processes 20 PB a day (2008)
• “all words ever spoken by human being” ~ 5 EB
• NOAA has ~ 1PB climate data (2007)
• CERN’s :HC will generate 15 PB a year (2008)
Stats from The iSchool University of Maryland
Saguaro Cluster
Research Group
High Performance Computing Initiative
Department
Fulton School
Primary Application
Various
# of Processor Cores
4560
Processor Architechture
Intel Xeon
Interconnect
InﬁniBand
Memory
10240 GB (Total)
Storage
215 TB
OS
CentOS 5.3
Sys Admin Contact
Douglas Fuller
Google’s Map/Reduce
•Google 2004 at The Sixth Symposium on 
Operating System Design and Implementation
•Processing and Generating large data sets
•Many real world tasks are expressible in this 
model
•Automatically parallelized for a large cluster of 
commodity machines
Google’s Map/Reduce
•Input -> Mapper -> Intermediate  
Pairs -> Reducer -> Output
•Easy to utilize resources of large distributed 
system without any experience
•Highly scalable: typically processes many 
terabytes of data in parallel
•Upwards of 1,000 MapReduce jobs are 
executed on Googles clusters daily
• Apache Project’s Open Source 
Implementation of MapReduce
• JAVA Based
• Hadoop has been demonstrated on 
clusters with 2000 nodes. The current 
design target is 10,000 node clusters.
• http://hadoop.apache.org
Mapper
• Map is a special function that applies the 
function f to each element in the list
• Map[f,(1,2,3,4,5)] -> {f[1],f[2],f[3],f[4],f[5]}
1
2
3
4
5
sq
1
2
3
4
5
sq
sq
sq
sq
1
sq
4
9
16
25
sq
sq
sq
sq
Mapper
• Input:
• The Entire Data Set
• Maps all the input 
values to a key
• map() is called once 
for each line of input
• Output
• Collects  
pairs
• Passes to reducer as
hashmap
Reducer
• Reduce[f,x,list]
• Sets an accumulator
• Initial value is x
• Applies f to each element of the list plus the 
accumulator
• Result is the ﬁnal value of the accumulator
• Reduce[f,x,{a,b,c}] => f[f[f[x,a],b],c]
Reducer
Reducer
• Input
• The output  
hashmap from the 
mapper
• f(x) is performed on 
every x with a 
common key
• Output
• A  list of the 
output of reduce()
Map/Reduce 
Framework
• Map is implicitly parallel
• Order of application of function does not matter
• Reduce is executed in serial on a single node
• The results of map() are copied and sorted then 
sent to the reduce()
Map/Reduce 
Framework
Data Store
Initial kv pairs
Initial kv pairs
Initial kv pairs
Initial kv pairs
map
map
map
map
k1, values…
k  values
k1, values…
k  values
k1, values…
k  values
k1, values…
k  values
k2, values…
k3, values…
k2, values…
k3, values…
k2, values…
k3, values…
k2, values…
k3, values…
Barrier: aggregate values by keys
reduce
k1, values…
reduce
k2, values…
reduce
k3, values…
reduce
final k1 values
reduce
final k2 values
reduce
final k3 values
Map/Reduce 
Framework
•
Programmer does not have to handle:
•
Work distribution
•
Scheduling
•
Networking 
•
Synchronization 
•
Fault recovery (if a map or reduce node fails) 
•
Moving data between nodes
Master Node
• Assigns tasks and data to each node
• Hosts an http JobTracker on port 50030
• Queries each node
• Kills any task that does not respond
• Re-Batches killed tasks out to next available 
node
Streaming
• Ability to port mappers and reducers 
to any language that is executable on 
each node
• Input is read from stdin()
• def read_input(ﬁle):
for line in ﬁle:
 yield line.rstrip()
Streaming
• Output is a hashmap, which is a 
string in the form:
• Output is written to stdout() 
• print “%s\t%s” % (key, value)
Streaming
• The utility packages all executables  
into a single JAR
• JAR is sent to all nodes
• Distributed Cache ﬁles are 
symlinked to the current working 
directory
Streaming
Streaming
• -mapper and -reducer can be set to a java 
class or any ﬁle that can be executed locally 
• Files and/or Archives can be distributed to 
each node or to distributed cache
Reporting
• Stdin/Stdout used for data, Stderr used for 
communication to Master Node
• Counter must be reported after every output line 
to track job progress
report:counter:pyNetﬂix1,mapper,1
• Status messages can be used to track errors in log 
ﬁles
report:status:Movie not found
• Hadoop Distributed File System (HDFS) - 
Google uses GoogleFileSystem (GFS)
• High fault-tolerant, low cost hardware
• High throughput, streaming access to data
• Data is split on 64 meg blocks and 
replicated in storage
HDFS
• HBase is equivalent to Google’s BigTable
• NON-RELATIONAL DATABASE
• Is not built for real-time querying
• Moving away from per-user actions
• Towards per-action data sets
• Distributed
• Multi-dimensional
• De-Normalized Data
• HBase is not an SQL Database
HBase Tables
• Table Schema deﬁnes Column Families
• Column Family contains multiple Columns
• Each Column has Versions (Z-axis)
• Everything except table name stored as 
byte[]
*Taken from HBase Documentation
Amazon's Elastic 
Compute Cloud (EC2)
• Web service that provides resizable compute 
capacity in Amazon’s Cloud.
• Hadoop is packaged as a public EC2 image (an 
AMI) so it is easy for us to get up and running with 
a cluster.
• ec2-describe-images -a | grep hadoop-ec2-images
• Extremely simple to setup an elastic hadoop cloud
• http://aws.amazon.com/ec2/
Amazon's Pricing
EC2
S3 (Amazon’s Simple Storage Service)
 2 GB dataset of movie/user/ratings
 Training_set1.txt...Training_set17770.txt: 
• MovieIDs range from 1 to 17770 sequentially. 
• CustomerIDs range from 1 to 2649429, with gaps. There are 480189 users. 
• Ratings are on a five star scale from 1 to 5. 
• Dates have the format YYYY-MM-DD. 
1: [Movie 1 of 17770] 
[CustomerID,Rating,Date]
1116, 3, 2006-04-17 
2, 5, 2007-07-07 
• Default input dataset creates one mapper per ﬁle
• Inefﬁcient when dealing with 17,770 ﬁles
• Need to optimize # of ﬁles to the number of 
mappers available
• Awk script used to reorganize input dataset into 
104 ﬁles to be used on 100 procs
• Insures that all mappers are being utilized while 
optimizing ﬁle I/O
netﬂixReorg.awk:
# tokenize on “:”
BEGIN { FS = ":" }
# if it is the ﬁrst line, movieID = ﬁrst token
{if( FNR == 1) movieID = $1
# if it is not the ﬁrst line, 
output movieID  “,” ﬁrst token
if ( FNR != 1 ) print movieID "," $1}
• Efﬁciency gained by reorganizing input dataset
• Netﬂix1 - 43:27
• Netﬂix1Reorg  -  9:55
• pyNetﬂix1 -  13:02
• awkNetﬂix1 -  9:04
Netﬂix1 Program
• Produce statistical information about each 
movie in the dataset  
• It took the entire Netﬂix dataset as input 
• Produced the ﬁrst date rated, last date 
rated, total rating count and average rating 
for each movie as the output
Netﬂix1 Mapper
• Input: Netﬂix Prize Training Set
• output: 
• one  pair for each movieID in the 
input data set
Netﬂix1 Mapper Code
• Netﬂix1/MyMapper.java
pyNetﬂix1 Mapper Code
• pyNetﬂix1/pyMapper.py
awkNetﬂix1 Mapper Code
• awkNetﬂix1/awkMapper.awk
Mapper Comparison
Netﬂix1
Java
Python
Awk
Map Task
Best: 8 sec
Avg: 12 sec
Best: 27 sec
Avg: 1 min 5 sec
Best: 9 sec
Avg: 15 sec
Netﬂix2 Reducer
• The Netﬂix2 program calculates statistics 
based on the users in the dataset
• Netﬂix2 Mapper output
• 
• Netﬂix2 Reducer output
• 
Netﬂix2 Reducer Code
• Netﬂix2/MyReducer.java
pyNetﬂix2 Reducer Code
• pyNetﬂix2/pyReducer.py
Reducer Comparison
Netﬂix 2
Java
Python
Reduce Task
2 min 58 sec
8 min 45 sec
Shoutouts
• Dr. Adrian Sannier - University Technology 
Ofﬁcer
• Dr. Dan Stanzione Jr. - Director of High 
Performance Computing Initiative
• Dr. Raghu Santanam - Associate Professor
• Nathan Kerr and Jeff Conner
Thank you
Joey Calca
r3dﬁsh@
hackedexistence.com
Ryan Anguiano
bl4ckbird@
hackedexistence.com
http://hackedexistence.com
Questions?