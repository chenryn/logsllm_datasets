Figure 6 presents the results for both the PRE-
TRAINED and FROMSCRATCH models over the test set
and trigger set, after applying these four different ﬁne-
tuning techniques.
The results suggest that while both models reach al-
most the same accuracy on the test set,
the FROM-
SCRATCH models are superior or equal to the PRE-
TRAINED models overall ﬁne-tuning methods. FROM-
SCRATCH reaches roughly the same accuracy on the trig-
1624    27th USENIX Security Symposium
USENIX Association
by the adversary to claim ownership of the model). No-
tice that the FROMSCRATCH models were trained using
a different trigger set, denoted as TS-ORIG. Then, we
ﬁne-tuned the models using RTLL and RTAL methods.
In order to have a fair comparison between the robust-
ness of the trigger sets after ﬁne-tuning, we use the same
amount of epochs to embed the new trigger set as we
used for the original one.
Figure 7 summarizes the results on the test set, TS-
NEW and TS-ORIG. We report results for both the FTAL
and RTAL methods together with the baseline results of
no ﬁne tuning at all (we did not report here the results
of FTLL and RTLL since those can be considered as the
easy cases in our setting). The red bars refer to the model
with no ﬁne tuning, the yellow bars refer to the FTAL
method and the blue bars refer to RTAL.
The results suggest that the original trigger set, TS-
ORIG, is still embedded in the model (as is demonstrated
in the right columns) and that the accuracy of classify-
ing it even improves after ﬁne-tuning. This may im-
ply that the model embeds the trigger set in a way that
is close to the training data distribution. However, in
the new trigger set, TS-NEW, we see a signiﬁcant drop
in the accuracy. Notice, we can consider embedding
TS-NEW as embedding a watermark using the PRE-
TRAINED approach. Hence, this accuracy drop of TS-
NEW is not surprising and goes in hand with the results
we observed in Figure 6.
Figure 7: Classiﬁcation accuracy on CIFAR-10 (top) and
CIFAR-100 (bottom) datasets after embedding two trig-
ger sets, TS-ORIG and TS-NEW. We present results for
no tuning (red), FTAL (yellow) and TRAL (blue).
Figure 6: Classiﬁcation accuracy on the test set and
trigger set for CIFAR-10 (top) and CIFAR-100 (bot-
tom) using different ﬁne-tuning techniques. For exam-
ple, in the bottom right bars we can see that the PRE-
TRAINED model (green) suffers a dramatic decrease in
the results comparing the baseline (bottom left) using the
RTAL technique.
ger set when each of the four types of ﬁne-tuning ap-
proaches is applied.
Notice that this observation holds for both the CIFAR-
10 and CIFAR-100 datasets, where for CIFAR-100 it ap-
pears to be easier to remove the trigger set using the PRE-
TRAINED models. Concerning the above-mentioned re-
sults, we now investigate what will happen if an adver-
sary wants to embed a watermark in a model which has
already been watermarked. This can be seen as a black-
box attack on the already existing watermark. Accord-
ing to the ﬁne-tuning experiments, removing this new
trigger set using the above ﬁne-tuning approaches will
not hurt the original trigger set and will dramatically de-
crease the results on the new trigger set. In the next para-
graph, we explore and analyze this setting. Due to the
fact that FROMSCRATCH models are more robust than
PRETRAINED, for the rest of the paper, we report the
results for those models only.
5.5 Ownership Piracy
As we mentioned in Section 3, in this set of experiments
we explore the scenario where an adversary wishes to
claim ownership of a model which has already been wa-
termarked.
For that purpose, we collected a new trigger set of dif-
ferent 100 images, denoted as TS-NEW, and embedded
it to the FROMSCRATCH model (this new set will be used
USENIX Association
27th USENIX Security Symposium    1625
020406080100CIFAR-10 AccuracyFrom Scratch(Test set)Pre Trained(Test set)From Scratch(Trigger set)Pre Trained(Trigger set)No Fine-TuningFTLLFTALRTLLRTAL020406080100CIFAR-100 Accuracy020406080100CIFAR-10 AccuracyNo-TuningFTALRTALTestTS-NewTS-Orig020406080100CIFAR-100 AccuracyTransfer Learning.
In transfer learning we would like
to use knowledge gained while solving one problem and
apply it to a different problem. For example, we use a
trained model on one dataset (source dataset) and ﬁne-
tune it on a new dataset (target dataset). For that pur-
pose, we ﬁne-tuned the FROMSCRATCH model (which
was trained on either CIFAR-10 or CIFAR-100), for an-
other 20 epochs using the labeled part of the STL-10
dataset [12].
Recall that our watermarking scheme is based on the
outputs of the model. As a result, when ﬁne-tuning a
model on a different dataset it is very likely that we
change the number of classes, and then our method will
probably break. Therefore, in order to still be able to
verify the watermark we save the original output layer,
so that on veriﬁcation time we use the model’s original
output layer instead of the new one.
Following this approach makes both FTLL and RTLL
useless due to the fact that these methods update the
parameters of the output layer only. Regarding FTAL,
this approach makes sense in speciﬁc settings where the
classes of the source dataset are related to the target
dataset. This property holds for CIFAR-10 but not for
CIFAR-100. Therefore we report the results only for
RTAL method.
Table 2 summarizes the classiﬁcation accuracy on the
test set of STL-10 and the trigger set after transferring
from CIFAR-10 and CIFAR-100.
els, with and without watermark, achieve roughly the
same accuracy in terms of Prec@1 and Prec@5, while
the model without the watermark attains 0% on the trig-
ger set and the watermarked model attain 100% on the
same set.
Prec@1
Prec@5
Test Set
NO-WM
FROMSCRATCH
NO-WM
FROMSCRATCH
66.64
66.51
Trigger Set
0.0
100.0
87.11
87.21
0.0
100.0
Table 3: ImageNet results, Prec@1 and Prec@5, for a
ResNet18 model with and without a watermark.
Notice that the results we report for ResNet18 on Im-
ageNet are slightly below what is reported in the litera-
ture. The reason beyond that is due to training for fewer
epochs (training a model on ImageNet is computation-
ally expensive, so we train our models for fewer epochs
than what is reported).
In Table 4 we report the results of transfer learning
from ImageNet to ImageNet, those can be considered as
FTAL, and from ImageNet to CIFAR-10, can be consid-
ered as RTAL or transfer learning.
Prec@1
Prec@5
CIFAR10 → STL10
CIFAR100 → STL10
Test set acc. Trigger set acc.
81.87
77.3
72.0
62.0
Test Set
ImageNet → ImageNet
ImageNet → CIFAR-10
66.62
90.53
Table 2: Classiﬁcation accuracy on STL-10 dataset and
the trigger set, after transferring from either CIFAR-10
or CIFAR-100 models.
Although the trigger set accuracy is smaller after trans-
ferring the model to a different dataset, results suggest
that the trigger set still has a lot of presence in the net-
work even after ﬁne-tuning on a new dataset.
5.6
ImageNet - Large Scale Visual Recog-
nition Dataset
For the last set of experiments, we would like to ex-
plore the robustness of our watermarking method on a
large scale dataset. For that purpose, we use ImageNet
dataset [37] which contains about 1.3 million training
images with over 1000 categories.
Table 3 summarizes the results for the functionality-
preserving tests. We can see from Table 3 that both mod-
Trigger Set
ImageNet → ImageNet
ImageNet → CIFAR-10
100.0
24.0
87.22
99.77
100.0
52.0
Table 4: ImageNet results, Prec@1 and Prec@5, for ﬁne
tuning using ImageNet and CIFAR-10 datasets.
Notice that after ﬁne tuning on ImageNet, trigger set
results are still very high, meaning that the trigger set
has a very strong presence in the model also after ﬁne-
tuning. When transferring to CIFAR-10, we see a drop in
the Prec@1 and Prec@5. However, considering the fact
that ImageNet contains 1000 target classes, these results
are still signiﬁcant.
5.7 Technical Details
We implemented all models using the PyTorch pack-
age [33].
In all the experiments we used a ResNet-18
model, which is a convolutional based neural network
1626    27th USENIX Security Symposium
USENIX Association
model with 18 layers [20, 21]. We optimized each of the
models using Stochastic Gradient Descent (SGD), using
a learning rate of 0.1. For CIFAR-10 and CIFAR-100 we
trained the models for 60 epochs while halving the learn-
ing rate by ten every 20 epochs. For ImageNet we trained
the models for 30 epochs while halving the learning rate
by ten every ten epochs. The batch size was set to 100 for
the CIFAR10 and CIFAR100, and to 256 for ImageNet.
For the ﬁne-tuning tasks, we used the last learning rate
that was used during training.
6 Conclusion and Future Work
In this work we proposed a practical analysis of the abil-
ity to watermark a neural network using random training
instances and random labels. We presented possible at-
tacks that are both black-box and grey-box in the model,
and showed how robust our watermarking approach is to
them. At the same time, we outlined a theoretical con-
nection to the previous work on backdooring such mod-
els.
For future work we would like to deﬁne a theoreti-
cal boundary for how much change must a party apply
to a model before he can claim ownership of the model.
We also leave as an open problem the construction of a
practically efﬁcient zero-knowledge proof for our pub-
licly veriﬁable watermarking construction.
Acknowledgments
This work was supported by the BIU Center for Research
in Applied Cryptography and Cyber Security in conjunc-
tion with the Israel National Cyber Directorate in the
Prime Minister’s Ofﬁce.
References
[1] ABADI, M., BARHAM, P., CHEN, J., CHEN, Z., DAVIS, A.,
DEAN, J., DEVIN, M., GHEMAWAT, S., IRVING, G., ISARD,
M., KUDLUR, M., LEVENBERG, J., MONGA, R., MOORE, S.,
MURRAY, D. G., STEINER, B., TUCKER, P., VASUDEVAN, V.,
WARDEN, P., WICKE, M., YU, Y., AND ZHENG, X. Tensor-
In Proceed-
ﬂow: A system for large-scale machine learning.
ings of the 12th USENIX Conference on Operating Systems De-
sign and Implementation (Berkeley, CA, USA, 2016), OSDI’16,
USENIX Association, pp. 265–283.
[2] ADI, Y., AND KESHET, J. Structed: risk minimization in struc-
tured prediction. The Journal of Machine Learning Research 17,
1 (2016), 2282–2286.
[3] ADI, Y., KESHET, J., CIBELLI, E., AND GOLDRICK, M. Se-
quence segmentation using joint rnn and structured prediction
models. In Acoustics, Speech and Signal Processing (ICASSP),
2017 IEEE International Conference on (2017), IEEE, pp. 2422–
2426.
[4] ADI, Y., KESHET, J., CIBELLI, E., GUSTAFSON, E., CLOPPER,
C., AND GOLDRICK, M. Automatic measurement of vowel du-
ration via structured prediction. The Journal of the Acoustical
Society of America 140, 6 (2016), 4517–4527.
[5] AMODEI, D., ANUBHAI, R., BATTENBERG, E., CASE, C.,
CASPER, J., CATANZARO, B., CHEN, J., CHRZANOWSKI, M.,
COATES, A., DIAMOS, G., ET AL. Deep speech 2: End-to-
end speech recognition in english and mandarin. In International
Conference on Machine Learning (2016), pp. 173–182.
[6] BAHDANAU, D., CHO, K., AND BENGIO, Y. Neural ma-
chine translation by jointly learning to align and translate. arXiv
preprint arXiv:1409.0473 (2014).
[7] BARAK, B., GOLDREICH, O., IMPAGLIAZZO, R., RUDICH, S.,
SAHAI, A., VADHAN, S., AND YANG, K. On the (im) possibil-
ity of obfuscating programs. Journal of the ACM (JACM) 59, 2
(2012), 6.
[8] BONEH, D., AND SHAW, J. Collusion-secure ﬁngerprinting for
digital data. In Advances in Cryptology — CRYPT0’ 95 (1995),
D. Coppersmith, Ed., Springer, pp. 452–465.
[9] BRASSARD, G., CHAUM, D., AND CR ´EPEAU, C. Minimum dis-
closure proofs of knowledge. J. Comput. Syst. Sci. 37, 2 (1988),
156–189.
[10] CHEN, H., ROHANI, B. D., AND KOUSHANFAR, F. Deep-
marks: A digital ﬁngerprinting framework for deep neural net-
works, 2018.
[11] CISSE, M. M., ADI, Y., NEVEROVA, N., AND KESHET, J. Hou-
dini: Fooling deep structured visual and speech recognition mod-
els with adversarial examples. In Advances in Neural Information
Processing Systems (2017), pp. 6980–6990.
[12] COATES, A., NG, A., AND LEE, H. An analysis of single-layer
networks in unsupervised feature learning. In Proceedings of the
fourteenth international conference on artiﬁcial intelligence and
statistics (2011), pp. 215–223.
[13] FIAT, A., AND SHAMIR, A. How to prove yourself: Practical so-
lutions to identiﬁcation and signature problems. In Conference on
the Theory and Application of Cryptographic Techniques (1986),
Springer, pp. 186–194.
[14] GOLDREICH, O. The Foundations of Cryptography - Volume 1,
Basic Techniques. Cambridge University Press, 2001.
[15] GOLDWASSER, S., MICALI, S., AND RACKOFF, C. The knowl-
edge complexity of interactive proof-systems (extended abstract).
In Proceedings of the 17th Annual ACM Symposium on Theory
of Computing, May 6-8, 1985, Providence, Rhode Island, USA
(1985), pp. 291–304.
[16] GOODFELLOW, I. J., SHLENS, J., AND SZEGEDY, C. Ex-
plaining and harnessing adversarial examples. arXiv preprint
arXiv:1412.6572 (2014).
[17] GRAVES, A., FERN ´ANDEZ, S., GOMEZ, F., AND SCHMIDHU-
BER, J. Connectionist temporal classiﬁcation: labelling unseg-
In Pro-
mented sequence data with recurrent neural networks.
ceedings of the 23rd international conference on Machine learn-
ing (2006), ACM, pp. 369–376.
[18] GU, T., DOLAN-GAVITT, B., AND GARG, S. Badnets: Identi-
fying vulnerabilities in the machine learning model supply chain.
CoRR abs/1708.06733 (2017).
[19] HE, K., GKIOXARI, G., DOLL ´AR, P., AND GIRSHICK, R. Mask
r-cnn. In Computer Vision (ICCV), 2017 IEEE International Con-
ference on (2017), IEEE, pp. 2980–2988.
USENIX Association
27th USENIX Security Symposium    1627
[38] SIMONYAN, K., AND ZISSERMAN, A. Very deep convolu-
tional networks for large-scale image recognition. arXiv preprint
arXiv:1409.1556 (2014).
[39] SMART, N. P. Cryptography Made Simple. Information Security
and Cryptography. Springer, 2016.
[40] STOCK, P., AND CISSE, M. Convnets and imagenet beyond ac-
curacy: Explanations, bias detection, adversarial examples and
model criticism. arXiv preprint arXiv:1711.11443 (2017).
[41] TOSHEV, A., AND SZEGEDY, C. Deeppose: Human pose es-
timation via deep neural networks. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition (2014),
pp. 1653–1660.
[42] UCHIDA, Y., NAGAI, Y., SAKAZAWA, S., AND SATOH, S. Em-
bedding watermarks into deep neural networks. In Proceedings
of the 2017 ACM on International Conference on Multimedia Re-
trieval (2017), ACM, pp. 269–277.
[43] VENUGOPAL, A., USZKOREIT, J., TALBOT, D., OCH, F. J.,
AND GANITKEVITCH, J. Watermarking the outputs of structured
prediction with an application in statistical machine translation.
In Proceedings of the Conference on Empirical Methods in Natu-
ral Language Processing (2011), Association for Computational
Linguistics, pp. 1363–1372.
[44] WATTENBERG, M., VI ´EGAS, F., AND HARDT, M. Attacking
discrimination with smarter machine learning. Google Research
17 (2016).
[45] YOSINSKI, J., CLUNE, J., BENGIO, Y., AND LIPSON, H. How
transferable are features in deep neural networks? In Advances
in neural information processing systems (2014), pp. 3320–3328.
[46] ZHANG, C., BENGIO, S., HARDT, M., RECHT, B., AND
VINYALS, O. Understanding deep learning requires rethinking
generalization. arXiv preprint arXiv:1611.03530 (2016).
[20] HE, K., ZHANG, X., REN, S., AND SUN, J. Deep resid-
ual learning for image recognition. In Proceedings of the IEEE