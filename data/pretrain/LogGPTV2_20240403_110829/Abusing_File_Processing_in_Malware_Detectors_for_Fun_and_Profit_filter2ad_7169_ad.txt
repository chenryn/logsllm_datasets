20
29
35
8
20
12
CVE
2012-1463
2012-1458
2012-1456
2012-1457
2012-1459
2012-1460
2012-1461
2012-1462
HEADER-PARSING ERRORS (ALL RESULT IN WEREWOLF ATTACKS).
Table XII
Format type
Format
Header ﬁelds
non-archive
ELF
PE
archive
CAB
padding
identsize
class
abiversion
abi
encoding
e version
ei version
e minalloc + 13 others
e ip and e res
cbCabinet
vMajor
reserved3
reserved2
reserved1
coffFiles
vMinor
No.
of
vuln. AVs
4
5
11
4
4
14
4
6
2
1
5
2
3
2
3
14
2
CVE
2012-1439
2012-1440
2012-1442
2012-1444
2012-1445
2012-1446
2012-1447
2012-1454
2012-1441
2012-1441
2012-1448
2012-1449
2012-1450
2012-1451
2012-1452
2012-1453
2012-1455
A. Sample werewolf attacks on archive ﬁles
Wrong checksum. In a POSIX TAR archive, each member
ﬁle has a 512-byte header protected by a simple checksum.
All headers also contain a ﬁle length ﬁeld, which is used by
the extractor to locate the next header in the archive. Most
scanners do not use the checksum ﬁeld when parsing an
archive. This is reasonable because a virus may lurk even
in an archive whose checksum is wrong, but in this case the
scanners are too smart for their own good.
87
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:47:44 UTC from IEEE Xplore.  Restrictions apply. 
Our sample attack uses a TAR archive with two ﬁles: the
ﬁrst one is clean, while the second is infected with the test
EICAR virus. The length ﬁeld in the header of the ﬁrst,
clean ﬁle has been modiﬁed to point into the middle of the
header of the second, infected ﬁle (see Figure 2). Scanners
that do not verify the checksum ﬁeld are unable to ﬁnd the
beginning of the second header. 35 of the 36 tested scanners
fail to detect the infection in the modiﬁed archive (the only
exception is eSafe 7.0.17.0).
In contrast, tar on Linux discovers that the checksum
is invalid, prints out a warning, skips the ﬁrst header, ﬁnds
the second, infected ﬁle by searching for the magic string
“ustar,” and proceeds to extract it correctly.
header 1
header 2
length
chksum
file 1
length
chksum
file 2
regular TAR archive
header 1
header 2
Random garbage at
the end of a valid GZIP archive
does not affect the gzip program, which simply ignores it
when extracting the contents. Yet, given an EICAR-infected
.tar.gz ﬁle with 6 random bytes appended, 8 out of 36
scanners fail to detect the infection.
Ambiguous ﬁles conforming to multiple formats. Flex-
ibility of many ﬁle formats enables an attacker to create
werewolf ﬁles that can be correctly parsed according to more
than one format and produce different results. Given that
zip correctly parses ZIP archives with garbage prepended,
while tar correctly parses TAR archives with garbage
appended, we created a werewolf ﬁle consisting of a TAR
archive followed by a virus-infected ZIP archive. This ﬁle
can be processed either by tar, or by zip and different
contents will be extracted depending on which program is
used. 20 out of 36 scanners fail to detect the infection.
Other werewolf ﬁles that can be parsed according to
multiple formats are CAB-TAR, ELF-ZIP, and PE-CAB.
Some of these pairs include non-archive formats!
length
chksum
(corrupt)
file 1
(benign)
length
chksum
file 2
(infected)
B. Sample werewolf attacks on non-archive ﬁles
crafted TAR archive
Figure 2. A crafted TAR archive with the modiﬁed length ﬁeld in the ﬁrst
header.
Misleading length. If the length ﬁeld in the header of a ﬁle
included into a TAR archive is greater than the archive’s total
length (1, 000, 000+original length in our experiments), 29
out of 36 scanners fail to detect the infection.
One of the vulnerable scanners is McAfee, which has the
default upper limit of 1 MB on memory for loading a ﬁle.
Since the size speciﬁed in the header is greater than 1 MB,
McAfee declares the ﬁle clean. GNU tar prints a warning
but extracts the infected contents correctly.
Multiple streams. GZIP ﬁles can contain multiple com-
pressed streams, which are assembled when the contents are
extracted. This feature can be used to craft a .tar.gz ﬁle
with the EICAR test virus broken into two parts. 20 out of
36 scanners fail to detect the infection. When the contents
are extracted, the infected ﬁle is correctly reassembled.
For example, McAfee simply ignores all bytes after the
ﬁrst stream of compressed data. Even if another infected ﬁle
is appended to a GZIP ﬁle containing multiple compressed
streams, McAfee fails to detect the infection.
Random garbage. If a ZIP archive has garbage bytes in the
beginning, the unzip program skips these bytes and still
extracts the contents correctly (we used Zip 3.0 and UnZip
6.00 in Ubuntu 10.04 for this test). 12 out of 36 scanners
fail to detect the infection in a ﬁle consisting of 1024 bytes
of random garbage followed by an EICAR-infected ZIP ﬁle.
Note that the ﬁle still has the proper .zip extension.
Werewolf attacks are also effective against executables,
Ofﬁce documents, and CHM ﬁles. Many modern ﬁle formats
are similar to archives because they can can contain em-
bedded objects of different types. This makes parsing much
harder and opens the door to werewolf attacks.
Fake endianness. In most ELF ﬁles, the 5th byte of the
header indicates endianness: 01 for little-endian, 02 for big-
endian. Linux kernel, however, does not check this ﬁeld
before loading an ELF ﬁle. If the 5th byte of a Bliss-infected,
little-endian ELF ﬁle is changed to 02, 12 out of 36 scanners
fail to detect the infection.
Empty VBA project names. MS Word ﬁles may contain
embedded objects such as executable macros, images, etc.
Because viruses can exploit the auto-execution feature, de-
tectors try to recognize and scan macros in the document.
In this example, we focus on how ClamAV does this.
In MS documents, macros are generally stored inside
VBA (Visual Basic for Application) projects. A group of
VBA projects is identiﬁed by a two-byte signature, “cc61”;
each project in a group has an unique unicode name. Cla-
mAV ﬁrst iterates through the VBA project names treating
the data as little-endian and checks if the resulting names
are valid (have positive length and begin with “*\g”, “*\h”,
“*\”, or “*\d”). If an invalid name is found, ClamAV stops.
ClamAV stores the number of valid project names it found in
the ﬁrst pass and repeats the same process, but now assuming
that the data are big-endian. Finally, ClamAV compares the
number of strings found during the two passes. If the ﬁrst
number is greater than the second, ClamAV treats the ﬁle as
little-endian, otherwise, as big-endian.
We created an ABC-infected Word ﬁle in which the ﬁrst
VBA project name is empty but the other names are intact.
88
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:47:44 UTC from IEEE Xplore.  Restrictions apply. 
When parsing project names, ClamAV calculated the valid
name count to be 0 in both little-endian and big-endian
cases and failed to detect the infection. On the other hand,
destination applications (MS Ofﬁce 2007 and OpenOfﬁce)
open the document correctly and execute the infected macros
even though the ﬁrst project name is empty.
Incorrect compression reset interval. A Windows Com-
piled HTML Help (CHM) ﬁle is a set of HTML ﬁles, scripts,
and images compressed using the LZX algorithm. For faster
random accesses, the algorithm is reset at intervals instead
of compressing the entire ﬁle as a single stream. The length
of each interval is speciﬁed in the LZXC header.
If the header is modiﬁed so that the reset interval is lower
than in the original ﬁle, the target application (in this case,
Windows CHM viewer hh.exe) correctly decompresses
the content located before the tampered header. On the
other hand, several detectors (including ClamAV) attempt
to decompress the entire CHM ﬁle before scanning it for
malware. When they fail to decompress the contents located
after the tampered header, they declare the ﬁle to be clean.
Bypassing
signatures. ClamAV uses
section-speciﬁc hash signatures when scanning Windows
executables. They contain the offset and the length of a
section of the ﬁle and the value of its MD5 hash. 85% of
signatures in ClamAV’s current database are of this type.
If ClamAV’s parser mistakenly believes that the executable
is corrupt or contains some unsupported features, ClamAV
skips the section-speciﬁc hash signatures, enabling evasion.
section-speciﬁc
VII. DEFENSES AGAINST CHAMELEON ATTACKS
Simplistic solutions such as changing the order in which
magic strings are matched may address the speciﬁc vul-
nerabilities we found but will undoubtedly introduce new
ones. One generic defense against all chameleon attacks is
to recognize ﬁles that match multiple types and process
them for all matching types. This may open the door to
denial of service if the attacker ﬂoods the detector with
ﬁles containing a large number of magic strings. To prevent
this, the detector should reject ﬁles with an abnormally high
number of possible types, but this only works for ﬁxed-offset
magic strings. Checking whether the ﬁle matches more than
a certain number of regular expressions can still impose an
unacceptable overhead on the detector.
Another approach is normalization: the detector can mod-
ify the ﬁle to ensure that the endhost’s interpretation of
its type matches the detector’s. In Windows, ﬁle extension
determines by default which program is used to open it.
In Linux, desktop managers such as KDE and GNOME use
extensions as the ﬁrst heuristic and fall back on magic strings
if the ﬁle has an unknown extension or no extension at all.
Unfortunately, rewriting the extension is not a failproof
defense against chameleon attacks because it does not guar-
antee that the endhost’s behavior matches the detector’s
expectations. First, users may override the default settings
in both Windows and Linux and choose any program to
open any ﬁle. Second, for endhosts running Linux,
the
detector must be aware of the list of known extensions: if the
normalized extension is not on the list, chameleon attacks
may still succeed even with the default settings.
VIII. NETWORK-BASED DEFENSES AGAINST
WEREWOLF ATTACKS
No matter what technique a network-based detector is
using—scanning for virus signatures, emulated execution,
behavioral analysis, etc.—it must ﬁrst recognize the type
of the ﬁle and parse it correctly. Even behavioral detection
does not help if the detector is unable to ﬁnd executable
code in a maliciously crafted ﬁle and thus cannot execute it.
Because network-based detectors do not observe the actual
processing and/or execution of the ﬁle on the endhost, they
must guess how the endhost may process the ﬁle. If a
network-based detector is protecting multiple endhosts, it
must guess correctly for all of them. In the rest of this
section, we argue that this is extremely error-prone.
A. “Write a better parser”
The obvious defense against werewolf attacks is to ensure
that the malware detector parses each ﬁle exactly the same
way as the ﬁle’s destination application or OS, thus elim-
inating the “semantic gap.” Note, however, that detectors
deployed on mail servers, network gateways, as a cloud-
based service, etc. aim to beneﬁt from economies of scale
and typically protect many hosts with a diverse set of
applications installed on them.
To prevent werewolf attacks, the malware detector must
parse each ﬁle in multiple ways, one for every possible
destination application and OS. The detector must (1) know
all applications that may possibly be used on any of the
endhosts to access the ﬁle, (2) know every application’s
parsing logic, (3) precisely replicate this logic within the
detector for all possible inputs, including damaged and non-
compliant ﬁles, (4) replicate every known and unknown bug
in every application’s parsing algorithm, and (5) be promptly
updated with a new algorithm whenever an application is
installed or updated on any endhost.
Format-compliant parsing is not enough. Format speciﬁ-
cations prescribe how to parse correctly formatted ﬁles. In
practice, however, many ﬁles do not fully conform to the
speciﬁcation, thus (1) applications are designed to handle
even non-compliant ﬁles, and (2) blocking “malformed” ﬁles
is likely to render the detector unusable because of false pos-
itives. Many formats do not deﬁne what it means for a ﬁle to
be “well-formed,” causing ﬁles created by legitimate appli-
cations to appear malformed. For example, up to 68% of PE
executable images in the wild have structural anomalies and
do not conform to the PE format speciﬁcation [29]. Formats
like PDF have no universally recognized notion of validity
89
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:47:44 UTC from IEEE Xplore.  Restrictions apply. 
and even conformance benchmarks accept malformed and
corrupt ﬁles [14]. Furthermore, every application parses non-
compliant ﬁles in its own idiosyncratic way, resulting in
different outputs for the same input (see Fig. 3).
format−compliant inputs  
A3
A1

         

         

         

         

         

         

         

         

         

         

         

         

         

         

         
A2
Ai: inputs from which
i−th application
produces valid output
Figure 3. Parsing discrepancies.
Let I be the set of all possible ﬁle inputs, O the set of
possible outputs, and Sf : IS → OS the speciﬁcation for
format f , where IS ⊂ I and OS ⊂ O. An ideal program
Pideal would only produce an output for compliant inputs:
(cid:2)
Pideal(x) =
Sf (x)
Error
if x ∈ IS
if x ∈ I − IS
In practice, however, applications have to deal with non-
compliant inputs that lie in I − IS. Any real program Preal
has its idiosyncratic way Sd of parsing non-compliant ﬁles:
⎧⎨
⎩ Sf (x)
Sd(x)
Error
Preal(x) =
if x ∈ IS
if x ∈ Id where Sd : Id → OS