日志易出品
作者：日志易专业服务部 数据工厂研究小组
后期整理：日志学院
数据工厂专题教材
1.  # 数据工厂基本概念
    1.  ## 背景
由于业务的不断发展，企业往往会采用众多不同种类的组件来解决不同的业务需求。这些来自不同厂商的组件数据结构不同，彼此之间交互困难，对其进行统一管理的难度较大。
异构数据交互难题主要体现在以下方面：
1.  不同的数据来源提供不同的读取方式，需要采用不同的客户端或编写特定的程序脚本；
2.  不同的数据目的提供不同的写入方式，也需要采用不同的客户端或编写特定的程序脚本；
3.  不同数据来源和目的仓库之间，数据结构设计不同，还需要采用不同的转换软件或程序。
![ppt优化-04](media/image1.jpeg){width="5.763888888888889in"
height="3.558333333333333in"}
为解决上述问题，数据工厂应运而生。数据工厂可以通过拖拽式的可视化操作轻松实现异构数据之间的高效流通调度。
快刀斩乱麻的数据工厂，提供了以下功能：
1.  不失灵活性的提供种类繁多的对接和清洗功能；
2.  除了数据以外，其他所有自定义的客户端、程序、脚本、软件等，汇聚成统一平台进行管理。
3.  内置监控，可以对各阶段数据流进行监控统计。
![ppt优化-05](media/image2.jpeg){width="5.763888888888889in"
height="3.4722222222222223in"}
## 产品介绍
日志易数据工厂（DataFlow
Manager）以Flink开源大数据计算引擎为底层框架，自研Fornaxee组件提供任务进行数据处理，在大规模数据量场景下展示了卓越的生命力。
Fornaxee功能与开源的数据流处理款产品StreamSets类似。虽然Fornaxee还不是一款成熟的产品，功能也远未有StreamSets强大。但Fornaxee的开发是需求驱动，在不断的项目积累过程中，Fornaxee已支持14个组件（2个origins，10个processors，2个Destinations）。
数据工厂的核心功能是数据融合引擎，其轻量级的设计和执行引擎，大幅简化异构数据来源和目的的对接过程，通过最简单的拖拽完成数据的采集、流转、清洗、发布。
![](media/image3.png){width="5.179861111111111in" height="3.1625in"}
数据工厂的核心功能主要体现在以下几个方面：
1.  异构数据融合：数据来源和目的相融合。支持可视化配置读写方式、频率，用于实现数据库、文件、网络、消息队列等异构数据间的数据互通；
2.  自助数据清洗：通过可视化的组件实现数据清洗及流控（Flow
    Control），包括解编码、字段解析、转换处理、数据扩充、求值运算、流控、表结构定义、表结构转换；
3.  可视化监控：提供了数据看板、速度信息、错误处理、审计告警、报表统计等功能，数据采集、转换清洗、数据发布等各个阶段均可以进行数据预览、测试、统计和监控；每个数据处理实例均可以进行管理与权限控制；
4.  任务流调度：批流一体。通过事件触发，形成多任务间的上下游关系，通过任务编排实现复杂流程自动化。
    1.  ## 使用说明
数据工厂用于处理数据流中的数据。数据处理需要定义数据源，确定数据处理规则，并定义目的对象。
![](media/image4.png){width="5.763888888888889in"
height="1.9027777777777777in"}
数据工厂中通过管道（pipline）来描述数据处理的流程。管道描述了从源系统到目标系统的数据流，并定义如何沿途转换数据。
管道由数据源、目的对象以及要执行的任何其他处理组成，包括有以下四类：
-   数据源（originis）
-   处理器（processors）：定义数据的处理规则
-   目的对象（destinations）：数据处理之后的目的地
-   执行器（executors）：又称触发器，用于接收到特定事件后触发执行一个动作，例如发邮件、执行JDBC查询、执行shell等。
设计完管道后，点击"开始"，数据工厂就会开始工作。数据工厂在数据到达原点时处理数据，在不需要时安静等待。可以在数据工厂内查看有关数据的实时统计信息，在数据通过管道时查验数据，或查看数据的快照。
以从目录中读取XML文件，删除换行符后导入HDFS系统为例，其数据管道的设置过程如下：
1.  **选定数据源：**从一个目录原点开始，将其配置为源文件目录；
2.  **删除换行符：**将目录连接到表达式计算器处理器，将其配置为从记录的最后一个字段中删除换行符；
3.  **将处理后的数据导出到HDFS：**将表达式计算器连接到Hadoop
    FS目标阶段。根据需要，可以配置将数据作为JSON对象或其他数据格式写入；
4.  **预览数据：**预览数据以查看源数据如何在管道中移动，可能注意到有些字段缺少数据，此时可以添加一个字段替换器来替换这些字段中的空白值。
5.  **错误状况监控：**现在数据流已配置完成，可以将管道错误记录配置为将错误记录写入文件，然后创建一个Data
    Drift警报以告知字段名何时更改，创建邮件告警以告知管道何时生成100多个错误记录。
6.  启动管道，数据工厂开始工作。
7.  **数据处理流程监控：**数据收集器进入监视模式，并立即显示摘要和错误统计信息。为了更深入地了解活动，可以获取管道的快照，以便检查一组数据是如何通过管道传递的。在管道中可能看到一些意外的数据，因此可以为两个阶段之间的链接创建一个数据规则，以收集有关类似数据的信息，并设置一个警报，以便在数据量过高时通知您。
8.  **错误处理：**被写入文件的错误记录与错误详细信息一起保存，因此可以创建一个错误管道来重新处理该数据。
数据工厂是数据流中跃点之间的关键连接。在企业数据拓扑结构中，有很多数据流需要移动、收集和处理。要解决企业需求，可以使用单个数据工厂来运行一个或多个管道，或者安装一系列数据工厂来跨企业数据拓扑传输数据。
目前，日志易数据工厂主要作为弥补日志易缺陷的日志辅助产品使用。
以使用日志易采集日志，从Kafka组件中取日志，进行处理后输出到其他外部组件为例。使用方案如下：
![ppt优化-06](media/image5.jpeg){width="4.527001312335958in"
height="2.7401990376202976in"}
Part 1:
1、沿用日志易流程，采集/解析/入库。
2、配置数据路由，解析后的数据输入到日志易kafka的独立topic
Part 2:
1、数据工厂的数据源组件，对接日志易的kafka
2、任意转换处理，配置转换规则
Part 3:
1、数据工厂的目的组件对接外部，kafka/hive/\...
2、验证数据接收正常
数据工厂时效性强，能够准实时分发数据，且对接面广，支持多种异构数据的处理及交互。日志易与数据工厂结合使用，能够帮企业轻松搭建起强大且健壮的数据生态管理平台。
## 产品架构
日志易数据工厂由Flink开源大数据计算引擎、自研Fornaxee组件组成。
Flink是结合Spark(高吞吐)、Storm(低延迟)优点的分布式、高性能、低延迟的开源流处理框架，可对有限数据流和无限数据流进行有状态或无状态的计算，能够部署在各种集群环境，对各种规模大小的数据进行快速计算。
要使用数据工厂，首先要搭建一套Flink集群。基于Flink集群，搭建一套Fornaxee后，数据工厂即可使用。但为了高可用，还需要使用zookeeper作为Flink作业管理器的高可用方案。
作为对照，同时我们也会介绍开源StreamSets的搭建方案。
使用数据工厂需要设置管道，对各类管道及表达式我们也应有一定认识。
与此相对应的是（expression
language）EL语言。Fornaxee沿用StreamSets的EL语言。EL语言在JSP
2.0表达式语言的基础上发展而来，通过EL语言可用来创建或修改用于数据处理的表达式，如实现时间格式转换等。可以使用EL表示数值或字符串值的任何阶段或管道属性，也可以使用EL中的字段路径表达式来选择要在某些处理器中使用的字段。
管道建立后，还需要对管道进行管理，并对数据处理过程进行监控，后续还有性能调优等内容。
本材料根据以上内容按以下顺序进行组织：
1.  数据工厂基本概念介绍
2.  Flink原理及架构
3.  数据工厂安装部署方案
4.  数据工厂组件介绍
5.  数据工厂EL语言详解
6.  数据工厂管理功能
7.  监控及性能调优
# Flink原理及架构
Apache
Flink是一个面向分布式数据流处理和批量数据处理的开源计算平台，提供支持流处理和批处理两种类型应用的功能。
## 产品介绍
Flink是结合Spark(高吞吐)、Storm(低延迟)优点的分布式、高性能、低延迟的流处理框架，能够部署在各种集群环境，对各种规模大小的数据进行快速计算。
Flink是新的流计算引擎，用java实现，既可以处理流（Streams）数据也可以处理批数据。
Streams分为有限数据流与无限数据流，unbounded stream
是有始无终的数据流，即无限数据流；而bounded stream
是限定大小的有始有终的数据集合，即有限数据流。二者的区别在于无限数据流的数据会随时间的推演而持续增加，计算持续进行且不存在结束的状态，相对的有限数据流数据大小固定，计算最终会完成并处于结束的状态。
Flink可以同时兼顾Spark以及Spark
streaming的功能，与Spark不同的是，Flink本质上只有stream的概念，批处理被认为是special
stream。
Flink的基本构建模块是流（Streams）与转换（transformations）。每一个数据流起始于一个或多个source，并终止于一个或多个sink。
一个由Flink程序映射为Streaming Dataflow的示意图如下：
![](media/image6.png){width="5.763888888888889in"
height="4.048611111111111in"}
并行数据流示意图如下：
![](media/image7.png){width="5.708333333333333in"
height="3.736111111111111in"}
### Flink组件栈
基于处理的事务不同，Flink组件栈结构可分Deploy、Core、APIs &
Libraries层。
![](media/image8.png){width="5.763888888888889in"
height="3.453472222222222in"}
Deploy部署层涉及了Flink的部署模式，Flink支持多种模式的部署，如本地、集群（Standalone/YARN）、云（GCE/EC2）等。
Runtime层提供了支持Flink计算的全部核心实现，比如：支持分布式Stream处理、JobGraph到ExecutionGraph的映射、调度等等，为上层API层提供基础服务。
API层主要实现了面向无界Stream的流处理和面向Batch的批处理API，其中面向流处理对应DataStream
API，面向批处理对应DataSet API。
Libaries层在API层之上构建的满足特定应用的实现计算框架，也分别对应于面向流处理和面向批处理两类：
-   面向流处理支持：CEP（复杂事件处理）、基于SQL-like的操作（基于Table的关系操作）
-   面向批处理支持：FlinkML（机器学习库）、Gelly（图处理）
    1.  ### Flink架构
Flink在运行中主要由三个组件组成：JobClient、JobManager 和
TaskManager。Flink是基于Master-Slave风格的架构，Flink集群启动时，会启动一个JobManager进程、至少一个TaskManager进程。其主要工作原理如下图。
![https://img-blog.csdn.net/20180629211243960?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3N4aWFvYmVp/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70](media/image9.png){width="5.763038057742782in"
height="2.0638298337707788in"}
Client：
-   用户提交一个Flink程序时，会首先创建一个Client，该Client首先会对用户提交的Flink程序进行预处理，并提交到Flink集群
-   Client会将用户提交的Flink程序组装一个JobGraph，
    并且是以JobGraph的形式提交的
JobManager
-   Flink系统的协调者，它负责接收Flink Job，调度组成Job的多个Task的执行
-   收集Job的状态信息，并管理Flink集群中从节点TaskManager
TaskManager
-   实际负责执行计算的Worker，在其上执行Flink Job的一组Task
-   TaskManager负责管理其所在节点上的资源信息，如内存、磁盘、网络，在启动的时候将资源的状态向JobManager汇报
用户首先提交Flink程序到JobClient，经过JobClient的处理、解析、优化提交到JobManager，JobManager
再调度任务到各个 TaskManager 去执行，然后 TaskManager
将心跳和统计信息汇报给 JobManager。TaskManager
之间以流的形式进行数据的传输。
![IMG_256](media/image10.png){width="5.763888888888889in"
height="3.9742836832895887in"}
### Flink特点
Flink的架构特点可概括为四条：
![1_16_001_jpeg](media/image11.jpeg){width="5.763888888888889in"
height="3.2444444444444445in"}
第一， Flink 具备统一的框架处理有界和无界两种数据流的能力。
第二， 部署灵活，Flink 底层支持多种资源调度器，包括 Yarn、Kubernetes
等。Flink 自身带的 Standalone 的调度器，在部署上也十分灵活。
第三，
极高的可伸缩性，可伸缩性对于分布式系统十分重要，阿里巴巴双11大屏采用
Flink 处理海量数据，使用过程中测得 Flink 峰值可达 17 亿/秒。
第四， 极致的流式处理性能。Flink 相对于 Storm
最大的特点是将状态语义完全抽象到框架中，支持本地状态读取，避免了大量网络
IO，可以极大提升状态存取的性能。
### Flink优势
#### **数据处理上的优势**
Flink在数据处理上的优势主要体现在以下方面：
-   支持高吞吐、低延迟、高性能的流处理
-   支持高度灵活的窗口（Windows）操作
-   支持有状态计算的Exactly-once语义
1、同时支持高吞吐、低延迟、高性能
Flink
是目前开源社区中唯一一套集高吞吐、低延迟、高性能三者于一身的分布式流式数据处理框架。像
Apache Spark 也只能兼顾高吞吐和高性能特性，主要因为在 Spark Streaming
流式计算中无法做到低延迟保障；而流式计算框架 Apache Storm
只能支持低延迟和高性能特性，但是无法满足高吞吐的要求。而满足高吞吐、低延迟、高性能这三个目标对分布式流式计算框架来说是非常重要的。
2、支持高度灵活的窗口（windows）操作
在流处理应用中，数据是连续不断的，需要通过窗口的方式对流数据进行一定范围的聚合计算，例如统计在过去的
1
分钟内有多少用户点击某一网页，在这种情况下，我们必须定义一个窗口，用来收集最近一分钟内的数据，并对这个窗口内的数据进行再计算。Flink
将窗口划分为基于 Time、Count、Session，以及 Data-driven
等类型的窗口操作，窗口可以用灵活的触发条件定制化来达到对复杂的流传输模式的支持，用户可以定义不同的窗口触发机制来满足不同的需求。
3、支持有状态计算
所谓状态就是在流式计算过程中将算子的中间结果数据保存在内存或者文件系统中，等下一个事件进入算子后可以从之前的状态中获取中间结果中计算当前的结果，从而无须每次都基于全部的原始数据来统计结果，这种方式极大地提升了系统的性能，并降低了数据计算过程的资源消耗。对于数据量大且运算逻辑非常复杂的流式计算场景，有状态计算发挥了非常重要的作用。
#### **管理上的优势**
> Flink在管理上的优势主要体现在以下方面：
-   支持事件时间（Event Time）概念
-   基于轻量级分布式快照（Snapshot）实现的容错
-   基于JVM实现独立的内存管理
-   Save Points
1、支持事件时间（Event Time）概念
在Flink中，窗口可以将无限流切分成有限流，是处理有限流的核心组件，现在
Flink 中 Window 可以是时间驱动的（Time
Window），也可以是数据驱动的（Count Window）。
在流式计算领域中，窗口计算的地位举足轻重，但目前大多数框架窗口计算采用的都是系统时间（Process
Time），也是事件传输到计算框架处理时，系统主机的当前时间。Flink
能够支持基于事件时间（Event
Time）语义进行窗口计算，也就是使用事件产生的时间，这种基于事件驱动的机制使得事件即使乱序到达，流系统也能够计算出精确的结果，保持了事件原本产生时的时序性，尽可能避免网络传输或硬件系统的影响。