16
8
1
0
1
0
4
5
1
0
0
0
26 (72.2%)
10 (27.8%)
15
9
2
15
8
10
5
3
7
2
0
6
5
2
1
1
Total
10 (27.8%)
13 (36.1%)
2 (5.6%)
0 (0.0%)
1 (2.8%)
0 (0.0%)
36
22
11
2
21
13
12
6
4
Table 5: Demographic, phone usage, and unlock authentication types of participants. For the video study,
the subset of comparable data that includes participants in both the “in-person” and “online” settings that
had screen resolution greater than 1800px and observed patterns on the Nexus 5 phone.
observing PAT/NPAT, we ensured that there was an even ratio between the order of the trials. A guide was
also followed to ensure that the researchers followed the same steps in the protocol (see Appendix A.4).
3.4 Recruitment
Participants were recruited from university student mailing lists, and paid $5 (USD). In total, we recruited 36
participants, including 10 females. The cohort was predominately aged between 18 to 24 years old. Almost
two-thirds of participants used iOS mobile devices. 21 used a ﬁngerprint reader to unlock their phones, and
6 used patterns (we did not ask if feedback lines were turned oﬀ). The demographic breakdown, as well as
their choice in mobile device and authentication are presented in Table 5.
Additionally presented in Table 5 are the demographics of a comparable set of participants from the prior
video study; these participants observed authentication on the Nexus 5 phone in the “in-person” lab setup
or the on-line MTurk setup with a screen resolution of at least 1800px in the y-axis, the most realistic setting
of the prior work. The breakdown of these two groups are similar, slightly younger overall with about 70/30
gender breakdown.
4 Realism and Limitations
As described in the previous section, we attempted, as best as possible, to recreate the settings of the prior
video study in live simulation. Due to the complexities of performing such a process, the study described in
this paper had its own set of limitations.
Viewing angles While we use a similar lab environment for the live simulation to that used in the video
study, the participants could not stand in exactly the same position as the cameras due to height diﬀerences
and the relatively close proximity of the near and far angles from a given side. We thus reduced the
observations to simply left and right and relied on the fact that our participants naturally vary in height to
compensate for the near and far setting of camera height placement in the prior study.
Victim entry speed Another recreation challenge is that our victim (a proctor) must enter the authen-
tication sequence many times over at a consistent speed. Clearly, a video ensures consistency here, and so
9
we trained the victim-proctor on the original videos to maintain consistent timings of authentication entry.
While there is no guarantee that every participant viewed the authentication at the same rate, we believe
this training, and the total number of entries performed by the victim, ensures consistency. Further, the
same victim-proctor was used in all data collection.
Subset of conditions As summarized in Section 3, a subset of the original conditions were used in the live
simulation. We kept factors that were shown to be signiﬁcant in the video study, but also had to remove some
that posed usability challenges for the proctor acting as the victim. While the selection process was done
carefully to address conditions likely to be important, it was also done for a practical nature of conducting a
study with live participants as compared to online. To ensure that we made a fair comparison, we selected a
similar subset of the data from the prior study. In particular, we used results from the previous study from
participants who had viewing screens of at least 1800px across, who viewed authentication attempts via the
Nexus 5 phone with thumb input from the left or right side.
Pen-and-paper attacker recordings As participants were using pen-and-paper to record their observa-
tions during the shoulder surﬁng attack, some participants were able to use this as an added aid to support
recall of the passcodes. For example, some participants were viewed by the proctor mimicking the movements
made by the victim-proctor between multiple-view conditions prior to writing down their ﬁnal observation.
While we directed participants to not do this during training, it was diﬃcult to stop due to the nature of the
task. In the video study, participants were also directed not to use additional aids, such as writing down ob-
servations while observing the passcodes, and were required to attest to this. However, it is possible that the
attestations were not fully truthful, nor could the researchers verify this as the study was conducted online.
As such, as neither study could fully control for this we believe that this provides for a fair comparison.
Ecological validity Low levels of ecological validity are known to be commonplace among lab-based stud-
ies for mobile interactions [16]. Although the method and setting selected for our study cannot approximate
the conditions by which shoulder surﬁng may take place in-the-wild, we designed the study to provide a
sense of realism even in a lab-based environment (e.g. victim in seated position similar to attacks taking
place while seated on public transport, while seated in a classroom, etc.). However, due to time constraints,
conditions such as providing multiple attempts to observe and/or recreate entry, could not be examined.
Further study would be needed to widen the range of factors examined, and to identify the applicability of
these ﬁndings to other types of tasks (e.g. authenticating while ambulatory) or other types of settings (e.g.
ﬁeld-based).
5 Results
As the live simulation used a subset of the variables in the video study (see prior section), we in turn
performed comparisons on an appropriate subset of the video study data. We used video data that met the
following criteria: one-handed/thumb-input on the Nexus 5 (red) phone, viewed from the left or right angle,
and a single recreation attempt. Additionally, we only included video data that was collected with a screen
resolution > 1800 pixels, which was identiﬁed as the most ideal viewing condition in the prior study [4].
With these reductions, we compared 720 shoulder surﬁng attempts for the live simulation to a comparable
1,171 attempts in the video study.
5.1 Comparing Attack Rates Across Video and Live Studies
Statistical Procedures As the results of the experiments for both the live and video study are propor-
tional, either the participant succeeded in recreating the passcode or did not, we compare the results using
a proportionality test for equality of proportions, which follows a χ2 distribution. That is, we compare the
attacker success rate for the video study to that of the live study using the same conditions, reporting the χ2
statistic, the two-tailed p value, and the 95% conﬁdence interval (δ95) for the diﬀerence between proportions.
10
Auth. Length
Live
Video
Live
Video
Live
Video
One-View
Two-Same
Two-Diﬀerent
62/68=91.2%
78/84=92.9%
PAT
NPAT
PIN
4-len
6-len
4-len
6-len
4-len
6-len
18/19=94.7%
15/17=88.2%
24/27=88.9%
χ2 = 0.00, p = 1.00, δ95[−0.21, 0.19]
23/24=95.8%
χ2 = 0.00, p = 1.00, δ95[−0.15, 0.13]
17/20=85.0%
χ2 = 0.22, p = 0.64, δ95[−0.14, 0.33]
50/53=94.3%
106/111=95.5%
χ2 = 0.00, p = 1.00, δ95[−0.10, 0.07]
45/55=81.8%
74/95=77.9%
χ2 = 0.13, p = 0.72, δ95[−0.11, 0.19]
48/55=87.3% 74/104=71.2% 18/19=94.7%
χ2 = 4.37, p = 0.04∗, δ95[0.02, 0.30]
35/53=66.0%
χ2 = 1.95, p = 0.16, δ95[−0.01, 0.38]
χ2 = 0.75, p = 0.39, δ95[−0.09, 0.26]
89/111=80.2% 48/94=51.1% 32/33=97.0% 12/21=57.1% 34/36=94.4% 37/65=56.9%
χ2 = 18.17, p = 0.00∗, δ95[0.16, 0.43]
χ2 = 10.98, p = 0.00∗, δ95[0.14, 0.66] χ2 = 13.88, p = 0.00∗, δ95[0.21, 0.54]
46/105=43.8% 17/109=15.6% 25/39=64.1% 4/17=23.5% 31/36=86.1% 19/68=27.9%
χ2 = 19.16, p = 0.00∗, δ95[0.16, 0.41]
χ2 = 29.62, p = 0.00∗, δ95[0.41, 0.76]
19/20=95.0%
χ2 = 0.01, p = 0.93, δ95[−0.11, 0.19]
14/16=87.5%
χ2 = 0.05, p = 0.82, δ95[−0.26, 0.15]
49/61=80.3%
16/16=100.0%
χ2 = 2.38, p = 0.12, δ95[0.06, 0.34]
56/78=71.8%
58/101=57.4% 17/17=100.0% 15/24=62.5% 18/20=90.0%
χ2 = 6.27, p = 0.01∗, δ95[0.11, 0.70]
χ2 = 6.13, p = 0.01∗, δ95[0.13, 0.62]
Table 6: Attacker accuracy results for the live experiment and the video experiment. The view type indicates
if the participant provides a single (or one) view or multiple views (two), either from the same angle or
diﬀerent angles of observation. For the video study, only data where screen base resolution > 1800 with
left or right views (no top) was considered. A 2-sample test for equality of proportions with continuity
correction was used, and the χ2 statistic, p-value, and 95% conﬁdence interval (δ95) of the diﬀerence between
the proportions (live - video) are reported.
In the cases where p ≤ 0.05, we can conclude that the live study was not well modeled by the video study
because the proportions of attacker success are signiﬁcantly diﬀerent. Similarly if p > 0.05 we cannot reject
the null hypothesis that the two proportions are the same and thus must conclude that the proportions are
more likely measuring the same eﬀect. The conﬁdence interval reports the most likely range of diﬀerence
between the attacker success rate for the video and live results, but is only relevant when a signiﬁcant
diﬀerence is found.
When comparing data across factors with greater than two conditions, we used a χ2 test for goodness of
ﬁt to determine signiﬁcant diﬀerences in attack success rates. Post-hoc analysis is conducted using pairwise
comparisons with a Bonferonni correction.
Across tests, while the data is overlapping for some of the factors being examined, we do not normal-
ize/correct p values as we are not attempting to control for type-1 errors across all tests. Instead, we are
performing exploratory analysis and interested in determining if signiﬁcant diﬀerences may exist and from
where they may arise. In post-hoc analysis, as described above, we do correct p values as appropriate as this
occurs within a single test with directly overlapping hypothesis.
Authentication Types (H1-r/H1-p)
In the prior study, a key ﬁnding was that a statistical diﬀerence was
identiﬁed in attacker performance across authentication type. We can perform the same tests by comparing
vulnerability to shoulder surﬁng for the single view conditions; see the ﬁrst column of Table 6.
We ﬁrst compare each of the authentications between the video and the live study, irrespective of the
authentication length. For patterns with feedback lines (termed: PAT) (χ2 = 0.0, p = 1), there is strong
statistical similarity. However, for patterns without lines (termed: NPAT) (χ2 = 4.54, p = 0.03) we do see
a signiﬁcant diﬀerence between the live and video study, and an even more prominent diﬀerence for PINs
(χ2 = 37.76, p = 0.00). Statistical diﬀerences for NPAT can be accounted for by an increase in the 4-length
performance for attackers in the live setting (see Table 6), and for PINs, we consistently see performance
increases for the live setting compared to the video setting. In this case, the success rate for PINs in the video
setting is 65/208=32.0% compared to 135/216=62.5% for the live setting, an increase of 1.95x; however, the
video study does provide a baseline.
We can also compare authentication types within collection method, as related to H1-p. Using a three-
way χ2 tests with pairwise comparisons, there are statistically signiﬁcant diﬀerences between each of the
success rates for each of the authentications for both the live (χ2 = 24.8, p = 0.00) and video (χ2 =
133.4, p = 0.00) settings. The residuals suggest the leading cause of this diﬀerence is the increased diﬃculty
of shoulder surﬁng PINs, for both the video and live setting, but post-hoc, pairwise-analysis (with Bonferroni
11
Auth. Length
Live
Video
Live
Video
Left
Right
PAT
NPAT
PIN
4-len
6-len
4-len
6-len
4-len
6-len
47/49=95.9%
36/48=75.0%
59/62=95.2%
23/25=92.0%
27/28=96.4%
χ2 = 0.00, p = 0.95, δ95[−0.18, 0.12]
χ2 = 0.00, p = 1.00, δ95[−0.09, 0.10]
23/29=79.3%
22/26=84.6%
χ2 = 0.00, p = 1.00, δ95[−0.22, 0.19]
χ2 = 0.44, p = 0.51, δ95[−0.12, 0.31]
25/26=96.2% 40/58=69.0%
23/29=79.3%
χ2 = 6.11, p = 0.01∗, δ95[0.10, 0.44]
χ2 = 0.07, p = 0.80, δ95[−0.17, 0.28]
20/28=71.4%
15/25=60.0%
χ2 = 0.69, p = 0.41, δ95[−0.12, 0.37]
χ2 = 0.01, p = 0.92, δ95[−0.22, 0.31]
44/54=81.5% 22/45=48.9% 45/57=78.9% 26/49=53.1%
χ2 = 6.86, p = 0.01∗, δ95[0.06, 0.45]
χ2 = 10.31, p = 0.00∗, δ95[0.13, 0.53]
21/51=41.2% 11/64=17.2%
25/54=46.3%
χ2 = 10.91, p = 0.00∗, δ95[0.14, 0.52]
χ2 = 6.98, p = 0.01∗, δ95[0.06, 0.42]
6/45=13.3%
34/46=73.9%
29/52=55.8%
38/47=80.9%
29/49=59.2%
Table 7: Eﬀects on angle on attacker accuracy. The angle is either an observation from the left or right with
a single view (no repeat viewings). For video-based results, no top views were considered. The prior “far”
type angles for each side are reduced to simply, left or right, and only data where screen base resolution
> 1800 was considered. A 2-sample test for equality of proportions with continuity correction was used, and
the χ2 statistic, p-value, and 95% conﬁdence interval (δ95) of the diﬀerence between the proportions (live -
video) are reported.
correction) suggest the beneﬁts of removing feedback lines in NPAT is not consistent across studies. While
there are statistical diﬀerences between PAT and NPAT in the video study, this eﬀect disappears in the live
study with p = .147 (under the correction). This provides further evidence that removing traceback lines
from pattern entry provides limited protection, and perhaps less than what was previously considered [25].
Despite seeing a reduced beneﬁt from NPAT as compared to PAT, we can conﬁrm H1-p in the live
setting. The authentication type has an impact on shoulder surﬁng performance as evident in the diﬀerences
in attacker success rate for diﬀerent authentication types, particularly for PINs.
Repeated Viewings (H1-r/H2-p) An important result of the video study was the ﬁnding that repeated
viewings have signiﬁcant impact on attacker performance (H2-p). By expanding our view of Table 6 to the
Two-Same and Two-Diﬀerent column, we can test for similar eﬀects resulting from repeated viewings. As
before, we observe the most consistency in the PAT and NPAT settings for the live and video study, and
strong diﬀerences in the PIN setting. However, where we do see signiﬁcant diﬀerence the conﬁdence interval
suggest that the video study does provide a baseline to the live setting.
We can further directly measure the impact of multiple viewings by performing within collection method
χ2 tests across viewing methods. For PAT, no eﬀect could be identiﬁed for multiple views in both the video
and live settings. There is an eﬀect for NPAT in the live (χ2 = 12.0, p < 0.01) but not in the video setting
(χ2 = 5.1, p = 0.08). Post-hoc analysis revealed that, for NPAT in the live setting, having the same viewing
angles twice compared to a single viewing angle or two diﬀerence angles drives this diﬀerence (p = 0.03,
corrected), suggesting that two-diﬀerent viewing conditions for NPAT is most advantageous to an attacker.
The case is similar for PINs. In the live setting, a statistically signiﬁcant diﬀerence occurs for conditions of
repeated views (χ2 = 23.1, p = 0.00). However, this was not the case for the video setting (χ2 = 4.1, p = 0.14).
Post-hoc analysis suggests that gaining any repeated viewing, the same angle twice or two diﬀerent, beneﬁts
the attacker signiﬁcantly in the live setting. The lack of signiﬁcance for the video setting may be due to
using this particular subset of video data, but we conjecture that it more likely reﬂects the high diﬃculty
of shoulder surﬁng PINs, generally, which was further exacerbated by the video observation setting without
stereo vision.
Overall, we can conﬁrm H2-p in the live setting, that repeated viewings have an impact on performance.
Where there were previous signiﬁcant diﬀerences in the video study, these persisted in the live setting, except
for NPAT. While there is consistency in viewing the same angle twice, observing the entry from multiple
12
angles seems to play a larger role in the live setting compared to the video setting. However, the larger
hypothesis that repeated views impacts performance of shoulder surﬁng is conﬁrmed.
Observation Angle (H1-r/H4-p) To assess the impact of observation angle, we use only single-view
conditions so as not to conﬂate the results with the impact of multiple observations. These results are
presented in Table 7 with pairwise comparisons between the live and video study for diﬀerent passcode
lengths.
While we continue to see signiﬁcant diﬀerences for PIN and a lack thereof for PAT, we see signiﬁcant
improvements in the live setting for NPAT viewed from the right angle. We conjecture that this improved
attacker performance relates to being able to stereoscopically determine touch locations that are more chal-
lenging to see from the same angle via video simulation. However, depth of touch events continue to be more
challenging when viewed from the left angle. The diﬀerence between the observations angles here may also