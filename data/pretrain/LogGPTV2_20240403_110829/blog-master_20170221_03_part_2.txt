VACUUM  
Time: 1797.681 ms  
```  
现在，使用索引又很快了  
```  
postgres=# select min(id),max(id) from tbl1;  
   min    |   max      
----------+----------  
 10000000 | 10000000  
(1 row)  
Time: 0.542 ms  
postgres=# explain select min(id),max(id) from tbl1;  
                                    QUERY PLAN                                       
-----------------------------------------------------------------------------------  
 Aggregate  (cost=1.44..1.45 rows=1 width=8)  
   ->  Index Only Scan using idx_tbl1_id on tbl1  (cost=0.12..1.44 rows=1 width=4)  
(2 rows)  
Time: 0.467 ms  
```  
那么现在merge join执行计划的耗时恢复正常了吗？  
恢复了  
```  
postgres=# explain select * from tbl1,tbl2 where tbl1.id=tbl2.id;  
                              QUERY PLAN                                
----------------------------------------------------------------------  
 Nested Loop  (cost=0.00..313495.67 rows=1 width=72)  
   Join Filter: (tbl1.id = tbl2.id)  
   ->  Seq Scan on tbl1  (cost=0.00..44248.01 rows=1 width=36)  
   ->  Seq Scan on tbl2  (cost=0.00..144247.85 rows=9999985 width=36)  
(4 rows)  
Time: 0.488 ms  
postgres=# set enable_nestloop=off;  
SET  
Time: 0.210 ms  
postgres=# explain select * from tbl1,tbl2 where tbl1.id=tbl2.id;  
                                    QUERY PLAN                                       
-----------------------------------------------------------------------------------  
 Merge Join  (cost=1642863.46..1737103.01 rows=1 width=72)  
   Merge Cond: (tbl1.id = tbl2.id)  
   ->  Index Scan using idx_tbl1_id on tbl1  (cost=0.12..44249.74 rows=1 width=36)  
   ->  Sort  (cost=1642858.33..1667858.29 rows=9999985 width=36)  
         Sort Key: tbl2.id  
         ->  Seq Scan on tbl2  (cost=0.00..144247.85 rows=9999985 width=36)  
(6 rows)  
Time: 0.505 ms  
```  
虽然现在索引大小没有变化，但是实际上没有引用的index page都置为empty page了  
```  
postgres=# \di+ idx_tbl1_id   
                           List of relations  
 Schema |    Name     | Type  |  Owner   | Table |  Size  | Description   
--------+-------------+-------+----------+-------+--------+-------------  
 public | idx_tbl1_id | index | postgres | tbl1  | 214 MB |   
(1 row)  
```  
具体详见btree的readme  
src/backend/access/nbtree/README  
```  
Page Deletion  
-------------  
We consider deleting an entire page from the btree only when it's become  
completely empty of items.  (Merging partly-full pages would allow better  
space reuse, but it seems impractical to move existing data items left or  
right to make this happen --- a scan moving in the opposite direction  
might miss the items if so.)  Also, we *never* delete the rightmost page  
on a tree level (this restriction simplifies the traversal algorithms, as  
explained below).  Page deletion always begins from an empty leaf page.  An  
internal page can only be deleted as part of a branch leading to a leaf  
page, where each internal page has only one child and that child is also to  
be deleted.  
```  
观察vacuum后索引页的变化  
首先获取metapage的信息，得到root page id，注意索引的层次并没有变化，依旧是2层，也就是说有第一层是branch节点，第二层是leaf节点。  
```  
postgres=# select * from bt_metap('idx_tbl1_id');  
 magic  | version | root | level | fastroot | fastlevel   
--------+---------+------+-------+----------+-----------  
 340322 |       2 |  290 |     2 |    27421 |         0  
(1 row)  
```  
读取root page的信息，显然现在root page只有一个条目，即一级branch的某个page  
```  
postgres=# select * from bt_page_stats('idx_tbl1_id',290);  
 blkno | type | live_items | dead_items | avg_item_size | page_size | free_size | btpo_prev | btpo_next | btpo | btpo_flags   
-------+------+------------+------------+---------------+-----------+-----------+-----------+-----------+------+------------  
   290 | r    |          1 |          0 |             8 |      8192 |      8136 |         0 |         0 |    2 |          2  
(1 row)  
postgres=# select * from bt_page_items('idx_tbl1_id',290);  
 itemoffset |   ctid    | itemlen | nulls | vars | data   
------------+-----------+---------+-------+------+------  
          1 | (27365,1) |       8 | f     | f    |   
(1 row)  
```  
查看第一级，branch的信息，找到第二级，leaf节点。  
```  
postgres=# select * from bt_page_stats('idx_tbl1_id',27365);  
 blkno | type | live_items | dead_items | avg_item_size | page_size | free_size | btpo_prev | btpo_next | btpo | btpo_flags   
-------+------+------------+------------+---------------+-----------+-----------+-----------+-----------+------+------------  
 27365 | i    |          1 |          0 |             8 |      8192 |      8136 |         0 |         0 |    1 |          0  
(1 row)  
postgres=# select * from bt_page_items('idx_tbl1_id',27365);  
 itemoffset |   ctid    | itemlen | nulls | vars | data   
------------+-----------+---------+-------+------+------  
          1 | (27421,1) |       8 | f     | f    |   
(1 row)  
```  
查看第二级，leaf节点的信息  
```  
postgres=# select * from bt_page_stats('idx_tbl1_id', 27421);  
 blkno | type | live_items | dead_items | avg_item_size | page_size | free_size | btpo_prev | btpo_next | btpo | btpo_flags   
-------+------+------------+------------+---------------+-----------+-----------+-----------+-----------+------+------------  
 27421 | l    |          1 |          0 |            16 |      8192 |      8128 |         0 |         0 |    0 |          1  
(1 row)  
postgres=# select * from bt_page_items('idx_tbl1_id',27421);  
 itemoffset |    ctid     | itemlen | nulls | vars |          data             
------------+-------------+---------+-------+------+-------------------------  
          1 | (44247,178) |      16 | f     | f    | 80 96 98 00 00 00 00 00  
(1 row)  
```  
leaf节点，对应的是heap table的行号，所以通过行号，可以直接访问数据  
```  
postgres=# select * from tbl1 where ctid='(44247,178)';  
    id    | info   
----------+------  
 10000000 |   
(1 row)  
```  
从以上分析可以得到一个结论  
在数据库中执行多表JOIN时，如果没有设置enable_mergejoin=off，那么数据库可能会选择merge join，或者说数据库需要评估merge join的成本。  
当JOIN列有索引存在，为了算出更精确的COST值，评估merge join的成本会用到该列的min, max值（通过扫描JOIN列的索引得到）。  
不管任何原因，扫描索引得到min,max 比较慢的话，执行计划的时间都会被拉长。  
## 一个实际的CASE  
某个业务，每天会从几千万数据中清除几十万，然后就发现某些JOIN的SQL执行计划时间变得好长（虽然最后选择的是nest loop join，但是评估过程依旧需要评估merge join的成本）。  
如何发现的？  
1\. 使用perf  
```  
连接会话, pg_backend_pid()得到PID  
收集该会话统计信息  
perf record -avg -p $PID  
在该会话执行explain QUERY;  
分析该会话的代码时间占比  
perf report --tui  
```  
2\. 使用gdb, 或者打印进程的 pstack       
某个场景得到的bt  
```  
while true do; pstack $PID sleep 0.01; done
    0x00000000004a8238 in _bt_checkkeys ()  
#1  0x00000000004a6126 in _bt_readpage ()  
#2  0x00000000004a67a9 in _bt_steppage ()  
#3  0x00000000004a68a8 in _bt_next ()  
#4  0x00000000004a53c8 in btgettuple ()  
#5  0x00000000007da563 in FunctionCall2Coll ()  
#6  0x000000000049e53e in index_getnext_tid ()  
#7  0x000000000049e5fa in index_getnext ()  
#8  0x0000000000782820 in get_actual_variable_range ()  
#9  0x0000000000786092 in ineq_histogram_selectivity ()  
#10 0x0000000000786a87 in scalarineqsel ()  
#11 0x0000000000787062 in mergejoinscansel ()  
#12 0x000000000061896e in initial_cost_mergejoin ()  
#13 0x0000000000624113 in try_mergejoin_path ()  
#14 0x0000000000624c2f in add_paths_to_joinrel ()  
#15 0x0000000000626678 in make_join_rel ()  
#16 0x0000000000626bd8 in join_search_one_level ()  
#17 0x00000000006147e3 in standard_join_search ()  
#18 0x00000000006337c1 in query_planner ()  
#19 0x000000000063521c in grouping_planner ()  
#20 0x0000000000637a80 in standard_planner ()  
#21 0x00000000006cd396 in pg_plan_query ()  
#22 0x000000000056c623 in ExplainOneQuery ()  
#23 0x000000000056c9c5 in ExplainQuery ()  
#24 0x00000000006d1fae in standard_ProcessUtility ()  
#25 0x00007f9c19f8d261 in pgss_ProcessUtility ()   
#26 0x00000000006cf1c7 in PortalRunUtility ()  
#27 0x00000000006d003d in FillPortalStore ()  
#28 0x00000000006d0340 in PortalRun ()  
#29 0x00000000006cd7bb in exec_simple_query ()  
#30 0x00000000006ce9e5 in PostgresMain ()  
#31 0x00000000006682e1 in PostmasterMain ()  
#32 0x00000000005f179c in main ()  
```  
## 如何避免问题  
当系统关闭了autovacuum后，如果批量删除或更新数据，可能会导致索引出现大量引用dead tuple的页面，从而评估与这些列有关的JOIN可能时间会变长（指merge join）  
1\. 当使用了绑定变量时，可能能解决以上问题，但是也可能无法解决以上问题，因为PostgreSQL绑定变量有一个避免执行计划倾斜的算法，会记录custom plan的次数和平均成本，根据plan cache和传入的参数，调用choose custom plan，评估generic plan的成本，和custem plan平均成本进行比较，以此判断是否需要custom plan.  
如果需要custom plan，那么会重新评估各种执行计划的成本。生成一次custom plan。  
原理详见本文末尾的几篇参考文档。  
2\. autovacuum设置的阈值太大（autovacuum_vacuum_scale_factor=0.2），默认是20%，也就是说只有数据发送了20%变化后，才会自动清理。  
如何避免呢？  
1\. 不要关闭表的autovacuum。  
2\. 对于大表，可以设置表级autovacuum 阈值，比如1%，或者更小一点。  
create table 或者 alter table都可以，语法详见PostgreSQL手册。  
3\. 开启系统级autovacuum, 并设置合理的autovacuum_vacuum_scale_factor，不要太大。  
4\. 在大量删除数据或者更新数据后，人为的对这些表执行vacuum analyze table;, 避免以上问题。    
## 小结  
当JOIN列有索引存在，并且优化器允许merge join时，评估merge join的成本时需要用到该列的min,max值，min,max值通过索引获得。  
当JOIN列都没有索引存在时，评估merge join的成本，不需要min,max值。因此评估merge join的执行计划很快。  
从索引获取min,max值，直接影响了产生执行计划的耗时。  
当数据被批量删除后，如果没有触发vacuum垃圾回收，评估merge join的成本就可能比较耗时，也就是本文提到的CASE。  
执行vacuum后，index的垃圾也会被清理，优化器评估merge join成本时用到的min,max值可以很快获得。  
## 参考  
[《为什么用 PostgreSQL 绑定变量 没有 Oracle pin S 等待问题》](../201606/20160617_02.md)  
[《PostgreSQL plan cache 源码浅析 - 如何确保不会计划倾斜》](../201606/20160617_01.md)   
[《执行计划选择算法 与 绑定变量 - PostgreSQL prepared statement: SPI_prepare, prepare|execute COMMAND, PL/pgsql STYLE: custom & generic plan cache》](../201212/20121224_01.md)  
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")