eter and the successor list size. Finally, reducing bl would
further limit the impact of Sybil identities, at the cost of
increased false positives.
Churn Analysis: Next, we evaluate the performance of
X-Vine under churn. We are interested in the static re-
silience of X-Vine, i.e., the probability of lookup success af-
ter a fraction of the nodes in the system fail simultaneously.
To account for churn, we modiﬁed the lookup algorithm to
backtrack whenever it cannot make forward progress in the
overlay namespace. Figure 7 depicts the mean probability
of lookup success as a function of the fraction of nodes that
fail simultaneously, averaged over 100 000 lookups. Sim-
ilar to the analysis of lookup security, we can see that an
increase in either the redundancy parameter or the succes-
sor list size result in improved resilience against churn. We
can also see that as the fraction of failed nodes increases, the
probability of lookup success decreases, but is still greater
than 0.95 for all scenarios using r = 4 and succ = 20.
PlanetLab Implementation: To validate our design and
evaluate lookup latency in real-world environments, we im-
plemented the X-Vine lookup protocol in C++ as a single-
threaded program using 3 000 LOC. We used libasync [5, 6]
and Tame [32] to implement non-blocking socket func-
Table 2. Mean Lookup Path Length
# Succ
New Orleans interaction graph
New Orleans friendship graph
Anonymous interaction graph
r = 1
r = 5
r = 10
1
5
10
20
97.9
30.0
20.2
15.4
57.7
18.2
13.0
10.3
51.7
16.8
12.16
9.6
r = 1
103.6
34.8
23.1
17.0
r = 5
r = 10
57.5
19.3
13.7
10.7
48.1
16.7
12.1
9.45
r = 1
166.7
48.9
29.9
21.0
r = 5
r = 10
96.3
25.5
16.9
12.8
81.0
21.7
14.8
11.3
 1
 0.98
 0.96
 0.94
 0.92
 0.9
 0.88
 0.86
p
u
k
o
o
L
e
r
u
c
e
S
f
o
y
t
i
l
i
b
a
b
o
r
P
r=2, succ=10
r=5, succ=10
r=2, succ=20
r=5, succ=20
 1
 0.98
 0.96
 0.94
 0.92
 0.9
 0.88
 0.86
p
u
k
o
o
L
e
r
u
c
e
S
f
o
y
t
i
l
i
b
a
b
o
r
P
r=2, succ=10
r=5, succ=10
r=2, succ=20
r=5, succ=20
 1
 0.98
 0.96
 0.94
 0.92
 0.9
 0.88
 0.86
p
u
k
o
o
L
e
r
u
c
e
S
f
o
y
t
i
l
i
b
a
b
o
r
P
r=2, succ=10
r=5, succ=10
r=2, succ=20
r=5, succ=20
 0
 500
 1000
 1500
 2000
 0
 1000
 2000
 3000
 4000
 5000
 0
 2000
 4000
 6000
 8000  10000
Attack Edges
(a)
Attack Edges
(b)
Attack Edges
(c)
Figure 6. Probability of secure lookup as a function of number of attack edges for (a) New Orleans
interaction graph, (b) New Orleans friendship graph, and (c) Anonymous Interaction graph.
X-Vine
Chord
our analysis is conservative; accounting for locality of so-
cial network contacts would likely improve the lookup per-
formance.
F
D
C
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0
 100
 1000
Latency (ms)
 10000
Figure 8. Lookup latency
tionality (UDP) in an event-based fashion. We ran our
implementation over 100 randomly selected nodes in the
PlanetLab network. We used a synthetic scale free graph
as the social network topology. The duration of the experi-
ment was set to 1 hour, and nodes performed lookups every
1 second. Figure 8 depicts the CDF of observed one-way
lookup latencies. We can see that the median lookup la-
tency was only 400 ms (as compared to 200 ms in Chord),
for the mean lookup path length of 5 hops (not shown in the
Figure). Using these values, we can estimate the median
lookup latency for mean lookup path lengths of 10 hops
and 15 hops (that were observed in our experiments over
real world social network topologies in Table 2) to be about
800 ms and 1200 ms respectively. We see some outliers in
Figure 8 due to the presence of a few slow/unresponsive
nodes in PlanetLab. For this experiment, we mapped ver-
tices in the social network topology to random PlanetLab
nodes (possibly in different geographic locations). Thus,
Facebook Application:
To bootstrap a X-Vine node,
its user needs to input the IP addresses of his/her friends.
Since this can be a cumbersome for a user, we imple-
mented a Facebook application (available at http://
apps.facebook.com/x--vine) that automates this
process and improves the usability of our design. The work
ﬂow of the application is as follows: (i) When a user visits
the Facebook application URL, Facebook checks the cre-
dentials of the user, the user authorizes the application, and
then the request gets redirected to the application hosting
server. (ii) The application server authenticates itself, and
is then able to query Facebook for user information. The
application server records the user information along with
the user IP address. (iii) The application server then queries
Facebook for a list of user’s friends, and returns their previ-
ously recorded IP addresses (if available) to the user.
This list of IP addresses could then be used by the DHT
software to bootstrap its operations. Our implementation
demonstrates that a user’s social contacts can be integrated
into the DHT protocol using only a few hundred lines of
glue code. Keeping in spirit with our fully decentralized
design goal, in future, our application could be implemented
on a decentralized platform like Diaspora [1] such that the
app server is not a central point of trust or failure.
p
u
k
o
o
l
l
u
f
s
s
e
c
c
u
s
f
o
y
t
i
l
i
b
a
b
o
r
P
 1
 0.98
 0.96
 0.94
 0.92
 0.9
 0.88
 0.86
succ=10, r=1
succ=10, r=4
succ=20, r=1
succ=20, r=4
p
u
k
o
o
l
l
u
f
s
s
e
c
c
u
s
f
o
y
t
i
l
i
b
a
b
o
r
P
 1
 0.98
 0.96
 0.94
 0.92
 0.9
 0.88
 0.86
succ=10, r=1
succ=10, r=4
succ=20, r=1
succ=20, r=4
p