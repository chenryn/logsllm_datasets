Energy
Labeling Rule”),”
Policy
2018.
(“Energy
products
under
[48] International Organization for Standardization, “ISO/IEC 29147:2014
– Information technology – Security techniques – Vulnerability disclo-
sure,” February 2014.
[49] ——, “ISO/IEC 30111:2013 – Information technology – Security
techniques – Vulnerability handling processes,” November 2013.
[50] European Parliament and the Council of the European Union, “Regu-
lation (EU) 2016/679,” April 2016.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:03:38 UTC from IEEE Xplore.  Restrictions apply. 
442
[51] K. Vaniea, E. J. Rader, and R. Wash, “Betrayed by updates: How
negative experiences affect future security,” in CHI Conference on
Human Factors in Computing Systems, CHI’14, 2014, pp. 2671–2674.
[52] K. Vaniea and Y. Rashidi, “Tales of software updates: The process of
updating software,” in Proceedings of the 2016 CHI Conference on
Human Factors in Computing Systems, 2016, pp. 3215–3226.
[53] A. Forget, S. Pearman, J. Thomas, A. Acquisti, N. Christin, L. F.
Cranor, S. Egelman, M. Harbach, and R. Telang, “Do or do not, there
is no try: User engagement may not improve security outcomes,” in
12th Symposium on Usable Privacy and Security, SOUPS, 2016.
[54] A. Mathur and M. Chetty, “Impact of user characteristics on attitudes
towards automatic mobile application updates,” in 13th Symposium on
Usable Privacy and Security, SOUPS, 2017, pp. 175–193.
[55] M. V. Pauly, “The economics of moral hazard: Comment,” The Amer-
ican Economic Review, vol. 58, no. 3, pp. 531–537, 1968.
[56] World Bank, “Households and NPISHs ﬁnal consumption expenditure,”
[Online]. Available: https://data.worldbank.org/indicator/NE.
2016.
CON.PRVT.CD
[57] E. M. Redmiles, S. Kross, and M. L. Mazurek, “How well do my
results generalize? Comparing security and privacy survey results from
MTurk, web, and telephone samples,” in 2019 IEEE Symposium on
Security and Privacy (SP), 2019, pp. 227–244.
[58] Clickworker, “Data management services: AI
text
creation, web researches,” 2018. [Online]. Available: https://www.
clickworker.com/
training data,
[59] T. Dinev and P. Hart, “An extended privacy calculus model for e-
commerce transactions,” Information Systems Research, vol. 17, no. 1,
pp. 61–80, 2006.
[60] Y. Sawaya, M. Sharif, N. Christin, A. Kubota, A. Nakarai, and
A. Yamada, “Self-conﬁdence trumps knowledge: A cross-cultural study
of security behavior,” in Proceedings of the 2017 CHI Conference on
Human Factors in Computing Systems, 2017, pp. 2202–2214.
[61] V. Venkatesh, J. Y. L. Thong, and X. Xu, “Consumer acceptance
and use of information technology: Extending the uniﬁed theory of
acceptance and use of technology,” MIS Quarterly, vol. 36, no. 1, pp.
157–178, 2012.
[62] J. Cohen, Statistical power analysis for the behavioral sciences.
Lawrence Erlbaum Associates, 1988.
[63] A. Field, Discovering statistics using IBM SPSS statistics.
Sage
Publications, 2013.
[64] I. M. Martin, D. W. Stewart, and S. Matta, “Branding strategies, mar-
keting communication, and perceived brand meaning: The transfer of
purposive, goal–oriented brand meaning to brand extensions,” Journal
of the Academy of Marketing Science, vol. 33, no. 3, pp. 275–294,
2005.
[65] C. Mathwick and E. Rigdon, “Play, ﬂow, and the online search
experience,” Journal of Consumer Research, vol. 31, no. 2, pp. 324–
332, 2004.
[66] K. L. Wakeﬁeld and J. Inman, “Situational price sensitivity: The
role of consumption occasion, social context and income,” Journal of
Retailing, vol. 79, no. 4, pp. 199–212, 2003.
[67] J. Lei, N. Dawar, and Z. G¨urhan-Canli, “Base-rate information in
consumer attributions of product-harm crises,” Journal of Marketing
Research, vol. 49, no. 3, pp. 336–348, 2012.
[68] S. B. MacKenzie, R. J. Lutz, and G. E. Belch, “The role of attitude
toward the ad as a mediator of advertising effectiveness: A test of
competing explanations,” Journal of Marketing Research, vol. 23, no. 2,
pp. 130–143, 1986.
[69] M. Featherman and P. A. Pavlou, “Predicting e-services adoption: A
perceived risk facets perspective,” Int. J. Hum.-Comput. Stud., vol. 59,
no. 4, pp. 451–474, 2003.
[70] X. Luo, H. Li, J. Zhang, and J. Shim, “Examining multi-dimensional
trust and multi-faceted risk in initial acceptance of emerging technolo-
gies: An empirical study of mobile banking services,” Decision Support
Systems, vol. 49, no. 2, pp. 222–234, 2010.
[71] F. D. Davis, “Perceived usefulness, perceived ease of use, and user
acceptance of information technology,” MIS Quarterly, vol. 13, no. 3,
pp. 319–340, 1989.
[72] T. Kushwaha and V. Shankar, “Are multichannel customers really more
valuable? The moderating role of product category characteristics,”
Journal of Marketing, vol. 77, no. 4, pp. 67–85, 2013.
[73] J. Jacoby and L. B. Kaplan, “The components of perceived risk,” ACR
Special Volumes, 1972.
[74] M. P. Conchar, G. M. Zinkhan, C. Peters, and S. Olavarrieta, “An in-
tegrated framework for the conceptualization of consumers’ perceived-
risk processing,” Journal of the Academy of Marketing Science, vol. 32,
no. 4, pp. 418–436, September 2004.
[75] F. Faul, E. Erdfelder, A.-G. Lang, and A. Buchner, “G*Power 3: A
ﬂexible statistical power analysis program for the social, behavioral,
and biomedical sciences,” Behavior Research Methods, vol. 39, no. 2,
pp. 175–191, May 2007.
[76] LimeSurvey, “LimeSurvey: The online survey tool - open source
surveys,” 2018. [Online]. Available: https://www.limesurvey.org/
[77] P. E. Green and V. Srinivasan, “Conjoint analysis in consumer research:
Issues and outlook,” Journal of Consumer Research, vol. 5, no. 2, pp.
103–123, 1978.
[78] F. Eggers and H. Sattler, “Hybrid individualized two-level choice-based
conjoint (HIT-CBC): A new method for measuring preference struc-
tures with many attribute levels,” International Journal of Research in
Marketing, vol. 26, no. 2, pp. 108–118, 2009.
[79] J. J. Louviere, T. N. Flynn, and R. T. Carson, “Discrete choice
experiments are not conjoint analysis,” Journal of Choice Modelling,
vol. 3, no. 3, pp. 57–72, 2010.
[80] M. I. Alpert, “Identiﬁcation of determinant attributes: A comparison of
methods,” Journal of Marketing Research, vol. 8, no. 2, pp. 184–191,
1971.
[81] F. V¨olckner, “The dual role of price: decomposing consumers’ reactions
to price,” Journal of the Academy of Marketing Science, vol. 36, no. 3,
pp. 359–377, September 2008.
[82] S. Barge and H. Gehlbach, “Using the theory of satisﬁcing to evaluate
the quality of survey data,” Research in Higher Education, vol. 53,
no. 2, pp. 182–200, March 2012.
[83] M. B. Holbrook and W. L. Moore, “Conjoint analysis on objects with
environmentally correlated attributes: The questionable importance of
representative design,” Journal of Consumer Research, vol. 16, no. 4,
pp. 490–497, March 1990.
[84] A. Scholl, L. Manthey, R. Helm, and M. Steiner, “Solving multiattribute
design problems with analytic hierarchy process and conjoint analysis:
An empirical comparison,” European Journal of Operational Research,
vol. 164, no. 3, pp. 760–777, 2005.
[85] M. Thomas and V. Morwitz, “Penny wise and Pound foolish: The left-
digit effect in price cognition,” Journal of Consumer Research, vol. 32,
no. 1, pp. 54–64, June 2005.
[86] B. Baumgartner and W. J. Steiner, “Are consumers heterogeneous in
their preferences for odd and even prices? Findings from a choice-
based conjoint study,” International Journal of Research in Marketing,
vol. 24, no. 4, pp. 312–323, 2007.
[87] Sawtooth Software, Inc., “The CBC system for choice-based conjoint
analysis – Version 9,” Sawtooth Software Technical Paper Series, 2017.
[88] J. Pinnell, “Comment on Huber: Practical suggestions for CBC studies,”
Sawtooth Software Research Paper, 2005.
[89] M. Natter and M. Feurstein, “Real world performance of choice-based
conjoint models,” European Journal of Operational Research, vol. 137,
no. 2, pp. 448–458, 2002, graphs and Scheduling.
[90] K. M. Miller, R. Hofstetter, H. Krohmer, and Z. J. Zhang, “How should
consumers’ willingness to pay be measured? an empirical comparison
of state-of-the-art approaches,” Journal of Marketing Research, vol. 48,
no. 1, pp. 172–184, 2011.
[91] J. Huber, D. R. Wittink, J. A. Fiedler, and R. Miller, “The effectiveness
of alternative preference elicitation procedures in predicting choice,”
Journal of Marketing Research, vol. 30, no. 1, pp. 105–114, 1993.
[92] J.-B. E. Steenkamp and D. R. Wittink, “The metric quality of full-
proﬁle judgments and the number-of-attribute-levels effect in conjoint
analysis,” International Journal of Research in Marketing, vol. 11,
no. 3, pp. 275–286, 1994.
[93] M. Steiner, N. Wiegand, A. Eggert, and K. Backhaus, “Platform
adoption in system markets: The roles of preference heterogeneity
and consumer expectations,” International Journal of Research in
Marketing, vol. 33, no. 2, pp. 276–296, 2016.
[94] B. Orme, “Sample size issues for conjoint analysis studies,” Getting
Started with Conjoint Analysis: Strategies for Product Design and
Pricing Research, 2010.
[95] Federal Statistical Ofﬁce (Germany), “Germany Census 2011,” 2011.
[Online]. Available: https://www.zensus2011.de/EN
[96] ——, “Germany Mikrozensus 2014,” 2014.
[Online]. Available:
https://www.gesis.org/en/missy/metadata/MZ/2014/
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:03:38 UTC from IEEE Xplore.  Restrictions apply. 
443
[97] Statista, “Smart home report 2019 – Statista digital market outlook -–
Market report,” December 2018.
[98] B. Orme, “Interpreting conjoint analysis data,” Sawtooth Software
Research Paper, 2002.
[99] A. Lengerer, J. Schroedter, M. Boehle, T. Hubert, and C. Wolf,
“Datenhandbuch GESIS-Mikrozensus-Trendﬁle: Harmonisierung der
Mikrozensen 1962 bis 2006 (in German),” 2010.
[100] Sawtooth Software, Inc., “The CBC latent class technical paper –
Version 3,” Sawtooth Software Technical Paper Series, 2017.
[101] H. Bozdogan, “Model selection and Akaike’s Information Criterion
(AIC): The general theory and its analytical extensions,” Psychome-
trika, vol. 52, no. 3, pp. 345–370, September 1987.
[102] D. Kahneman, J. L. Knetsch, and R. H. Thaler, “Fairness and the
assumptions of economics,” The Journal of Business, vol. 59, no. 4,
pp. 285–300, 1986.
[103] L. E. Bolton, L. Warlop, and J. W. Alba, “Consumer Perceptions of
Price (Un)Fairness,” Journal of Consumer Research, vol. 29, no. 4, pp.
474–491, 03 2003.
[104] N. Koschate-Fischer, I. V. Huber, and W. D. Hoyer, “When will price
increases associated with company donations to charity be perceived
as fair?” Journal of the Academy of Marketing Science, vol. 44, no. 5,
pp. 608–626, Sep 2016.
[105] E. M. Redmiles, M. L. Mazurek, and J. P. Dickerson, “Dancing
pigs or externalities? Measuring the rationality of security decisions,”
in Proceedings of
the 2018 ACM Conference on Economics and
Computation, Ithaca, NY, USA, 2018, pp. 215–232.
[106] I. T. Jolliffe, “Discarding variables in a principal component analysis.
I: Artiﬁcial data,” Journal of the Royal Statistical Society. Series C
(Applied Statistics), vol. 21, no. 2, pp. 160–173, 1972.
[107] R. T. Rust, K. N. Lemon, and V. A. Zeithaml, “Return on market-
ing: Using customer equity to focus marketing strategy,” Journal of
Marketing, vol. 68, no. 1, pp. 109–127, 2004.
[108] J. F. Hair, W. C. Black, B. J. Babin, and R. E. Anderson, Multivariate
Data Analysis (7th edition). Englewood Cliffs: Pearson Prentice Hall,
2010.
A. Marketing Research Scales of Prestudy 1
APPENDIX
The scales below were used in Prestudy 1 to compare the
perception of product categories.
• Attitude towards a product category adapted from Martin
et al. [64]
– How favorable are [product]s?
(1 = ‘not at all favorable’ to 7 = ‘very favorable’)
– How likable are [product]s?
(1 = ‘not at all likable’ to 7 = ‘very likable’)
– How pleasing are [product]s?
(1 = ‘not at all pleasing’ to 7 = ‘very pleasing’)
• Involvement with a product category, Mathwick and Rig-
don [65].
‘[Product]s...’
– 1 = ‘Mean nothing to me’ to 7 = ‘mean a lot to me’
‘I ﬁnd [product]s...’
– 1 = ‘worthless’ to 7 = ‘valuable’
– 1 = ‘boring’ to 7 = ‘interesting’
– 1 = ‘exciting’ to 7 = ‘unexciting’
– 1 = ‘fascinating’ to 7 = ‘mundane’
– 1 = ‘involving’ to 7 = ‘uninvolving’
• Consumption motives, Wakeﬁeld and Inman [66]
‘[Product]s are used for ...’
– 1 = ‘Practical purposes’ to 7 = ‘Just for Fun’
– 1 = ‘Purely functional’ to 7 = ‘Pure enjoyment’
– 1 = ‘For a routine need’ to 7 = ‘For pleasure’
• Desirability to possess a product adapted from Lei et al. [67]
– [Product]s are. . . (1 = ‘not at all desirable’ to 7 = ‘very
desirable’)
• Purchase intention adapted from MacKenzie et al. [68] (1
= ‘very low’ to 7 = ‘very high’)
– If I were going to buy a [product], the probability of
buying this model is...
– The probability that I would consider buying this [prod-
uct] is...
– The likelihood that I would purchase this [product] is...
B. Quality Analysis of Perceived Security Risk Scale
We assessed the quality criteria of the perceived security risk
scale based on the results of the conjoint questionnaire, where
the group of 731 respondents (denoted as PC1) evaluated a
product category with a high perceived security risk, and the
group of 735 respondents (denoted as PC2) evaluated a product
category with a low perceived security risk.
First, we evaluated the convergent validity of the perceived
security risk scale using a principal component analysis (PCA)
with Varimax rotation, in order to prove the dimensionality.
For the PCA, the Bartlett test indicated signiﬁcant correlations,
the Kaiser-Meyer-Olkin (KMO) measure veriﬁed the sampling
adequacy with KMO = .898 for PC1 and KMO = .917 for
PC2, and all measures of sampling adequacy (MSA) values
for individual items were greater or equal than .803 for PC1
and .840 for PC2. Thus, KMO and MSA exceed the acceptable
limit of .500 as proposed by Field [63]. Field also suggests
an eigenvalue cutoff, if the sample size exceeds 250 and the
average communality is greater than .6. As both conditions
apply to our case, we used an eigenvalue cutoff of .7, as
proposed by Jolliffe [106]. This procedure is similar to Rust
et al. [107], and helps to provide the best trade-off between
parsimony and interpretability concerning the scale.
The factors of PC1 and PC2 are shown in Table XI. For PC1,
the PCA with Varimax rotation for the 13 perceived security
items revealed four factors for perceived security (variance
explained = 77.94%). For PC2, the PCA with Varimax rotation
revealed three factors (variance explained = 77.14%). Factor
loadings of PC1 and PC2 were greater or equal to .464 (should
be >.400) [108]. For PC1, all items loaded the highest on the
factor (i.e., ‘general’, ‘privacy’, ‘physical’, or ‘ﬁnancial risk’)
on which they were supposed to load, making all factors easy
to interpret. Thus, the four factors aligned closely with the four
perceived security dimensions that we derived from previous
research. For PC2, the ﬁrst seven items formed a composite
factor (‘general/privacy risk’), while items 8 to 10 loads on
‘physical risk’, and items 11 to 13 loaded on ‘ﬁnancial risk’.
The reasons for the loading of the general and privacy risks to
a single factor are not clear, such that the scale may require
further reﬁnement in the future.
Second, we evaluated the perceived security risk scale in
terms of the Cronbach’s alpha, a measure that deﬁnes the inner
consistency of a scale, and the item-to-total correlation for
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:03:38 UTC from IEEE Xplore.  Restrictions apply. 
444
TABLE VIII: Considered product attributes (n = 29) and their
dual-questioning scores (higher score values indicate a higher
perceived importance for this attribute)
Rank Product Attribute
Smart Home Camera
How many days of local weather forecast
Price
Solar panel for energy generation
Battery lifetime
Precision level of measurements
Rain and wind measurements
Expandability for multiple rooms
1.
2.
3.
4.
5.
6.
7. Max. wireless range
8. Warning feature (e.g., storm)
9.
10. Measurement rate
11. Brand/ manufacturer
12. Alarm upon preset threshold exceedance
13.
14.
15. Material of casing
16. Color of product
17. Alexa compatible
18. Accessibility label (ﬁctive)
Seal of technical approval
Environmental label
Rank Product Attribute
Smart Weather Station
Price
Video resolution
Field of view
Video frame rate
Zoom function
Energy consumption
Face recognition
Night vision mode
Timing function for recordings
Type of power supply
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11. Brand/ manufacturer
12.
13. Material of encasement
14.
15.
16. Color of product
17. Accessibility label (ﬁctive)
18. Alexa compatible
Environmental label
SD card slot
Seal of technical approval
µ
σ
31.76 12.83
26.66 12.01
26.31 11.33
23.72 10.98
23.69 10.99
23.48 13.06
23.34 10.17
22.66 10.59
22.14
8.80
19.14 10.15
18.28 10.12
18.03 10.69
17.76 10.14