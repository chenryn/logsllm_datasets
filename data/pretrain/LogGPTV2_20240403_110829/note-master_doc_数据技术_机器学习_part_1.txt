---
tags: ['人工智能', '机器学习', '数据技术']
---
# 机器学习
![](/assets/2024118193311.webp)
频率视角下的机器学习：认为模型待估计的参数是固定不变的常量，用来估计参数的数据是随机的变量，需要我们通过某种手段（比如极大似然法）利用数据找到最优参数，损失函数（loss function）直接定义了模型性能的度量方式，其数学期望被称为风险（risk），风险最小化就是参数估计的依据和准则，用训练数据的经验分布替换掉原始表达式中数据的真实分布，借此找到最优参数
贝叶斯视角下的机器学习：将待估计的参数视为随机变量，用来估计的数据反过来是确定的常数，结合参数自身的分布特性，找到最可能产生观测数据的那个参数的过程，贝叶斯学习的输出是关于参数的概率分布
可被机器学习解决的问题：
1. 解决的问题会包含某些显式或者隐式的模式
2. 无法通过数值计算解决
3. 要有大量的可用数据
监督学习适用于预测任务，无监督学习适用于描述任务
- 批量学习：一口气对整个数据集进行建模与学习，并得到最佳假设
- 在线学习：算法根据数据的不断馈入而动态地更新
- 主动学习：有选择地询问无标签数据的标签来实现迭代式的学习
计算学习理论：关于通过”计算“来进行学习的理论，即关于机器学习的理论基础
目的：分析学习任务的困难本质，为学习算法提供理论保证，指导算法设计
## 集成学习
使用多个个体学习器来获得比每个单独学习器更好的预测性能
每个组中的个体学习器如果属于同一类型（比如都是线性回归或者都是决策树），形成的就是同质集成；相应地，由不同类型学习器得到的集成则称为异质集成
- 个体学习器间存在强依赖关系因而必须串行生成的序列化方法：提升（Boosting），对所有训练数据进行多次重复应用，每次应用前需要对样本的概率分布做出调整，以达到不同的训练效果
- 个体学习器之间不存在强依赖关系因而可以同时生成的并行化方法：打包（Bagging），将原始的训练数据集拆分成若干互不交叠的子集，再根据每个子集独立地训练出不同的个体学习器，模型在不同的数据子集上波动越大，打包法的效果就越好
- 堆叠法（stacking）：用自助采样生成不同的数据子集，用数据子集训练第一层中不同的基学习器。第一层基学习器的输出再被送到第二层的元分类器（meta classifier）中作为输入，用来训练元分类器的参数
### AdaBoost
通过训练多个弱分类器，将它们组合成一个强分类器
假设弱分类器为 Gi​(x)，它在强分类器中的权重 αi​，那么就可以得出强分类器 f(x)：
$$
f(x)=\sum_{i=1}^n\alpha_iG_i(x)
$$
如果弱分类器的分类效果好，那么权重应该比较大，如果弱分类器的分类效果一般，权重应该降低
## 模型
- 参数模型：待求解的概率分布或者数量关系可以用一组有限且固定数目的参数完全刻画，最典型的是线性回归
- 非参数模型：认为存在一个未知的映射 f()˙​，输入通过这个映射转为输出，学习的对象也是这个映射
参数模型与非参数下模型的区别体现的是可解释性和精确性的区别
1. 模型拟合（model fitting）：利用训练数据集（training set）对模型的普通参数进行拟合
2. 模型选择（model selection）：利用验证数据集（validation set）对模型的超参数进行调整，筛选出性能最好的模型
3. 模型评价（model assessment）：利用测试数据集（test set）来估计筛选出的模型在未知数据上的真实性能
## 实验
实验设计的任务是观察一个或多个因子对实验结果的影响，因此包括算法类型、超参数、数据集等
- 一次一因子（控制变量法）：为所有因子都设定一个基线值，再在其他因子保持在基线水平的前提下令单个因子波动，观察它对学习性能的影响
- 全因子实验（full factorial experiment）：每个因子都有有限个离散的取值，实验则覆盖了所有因子所有取值的所有可能组合
- 连续实验（sequential experimentation）：首先执行全因子实验，但只给每个因子赋予较少的可能取值，确定哪些是对学习结果影响较大的活跃因子并保留下来，剩下的不活跃的因子就会被放弃
- 响应面方法（response surface methodology）：通过二次曲面的拟合寻找可变因子的最佳取值
## [特征工程](/数据技术/数据处理.md#特征工程)
异常点会导致数据的有偏分布，如果异常点是由于采集出错，需要剔除这些异常点。如果异常点本身没有问题，除了剔除异常点之外，除了可以对所有特征值采取对数变化降低数值外，还能使用空间标识把异常点拉成正常
对于缺失的特征值，可以用 k 近邻方法和线性回归对特征的缺失值进行人为赋值
如果某个特征在绝大多数数据中的取值都是相同的，那这个特征就没有存在的意义，因为它体现不出对于不同分类结果的区分度，可以把这个特征去掉
- 特征选择：从现有特征集合中提取一部分作为特征，特征选择的思路大多都是去除对结果预测帮助不大的一些特征
- 特征提取：对现有特征进行变化，组合得到新的特征，主成分分析将原始的共线性特征转化为新的正交特征，从而实现特征提取
## 向量化运算
可以充分利用GPU进行大规模并行
```py
x = np.array([1,2,3])
y = np.array([3,2,1])
np.dot(x,y) # = for i in n: x[i] * y[i]
```
## 优化
- 随机优化：对拥有大量题解的一个问题，选取一个可优化的题解进行优化
### 成本函数(代价函数)
用一个值代表方案的好坏程度 值越大代表方案越差，对于一个问题，会有多种变量，则需要对这些变量进行归一化计算，从而确定哪些变量更重要
若果可能，让最优解的成本函数为0，这样子当找到最优解后就可以停止后续的查找
### 梯度下降
梯度下降适用所有代价函数
梯度下降背后的思想是：开始时我们随机选择一个参数的组合，计算代价函数，然后我们寻找下一个能让代价函数值下降最多的参数组合。我们持续这么做直到到到一个局部最小值（local minimum），因为我们并没有尝试完所有的参数组合，所以不能确定我们得到的局部最小值是否便是全局最小值（global minimum），选择不同的初始参数组合，可能会找到不同的局部最小值，但线性回归的代价函数只会有一个最小值
![20231021212810](/assets/20231021212810.jpeg)
梯度下降算法：
$$
tempw = w - \alpha\frac{\partial}{\partial{w}}J(w,b) 
= w - \frac{1}{m}\sum_{i=1}^{m}(f(x^{(i)}) - y^{(i)})x_j^{(i)}
$$
$$
tempb = b - \alpha\frac{\partial}{\partial{b}}J(w,b)
$$
```python
w = tempw
b = tempb
```
对于多变量的线性回归模型，需要额外对所有的参数进行梯度下降：
$$
w_1 = w_1 - \alpha\frac{\partial}{\partial{w}}J(\vec{w},b)
$$
$$
w_2 = w_2 - \alpha\frac{\partial}{\partial{w}}J(\vec{w},b)
$$
$$
w_3 = w_3 - \alpha\frac{\partial}{\partial{w}}J(\vec{w},b)
$$
$$
[w_1,w_2,w_3,...] = \vec{w}
$$
$\alpha$是学习率（learning rate），决定了沿着能让代价函数下降程度最大的方向向下迈出的步子有多大，学习率如果大小了，需要很多步才能到达全局最低点，学习率太大了，可能会越过最低点，甚至可能无法收敛
$\alpha$后面对代价函数的偏导数表示了代价函数在当前取值处的斜率，如果是正斜率，就能得出一个正数，如果是负斜率，就得出负数，这可以使得w，b参数值会向代价函数的最小值的参数值逼近
一个运行良好的梯度下降算法代价函数值应该会随着迭代次数的增加不断收敛到接近局部最小值
![20231022135050](/assets/20231022135050.png)
当计算的参数值不再变化时，就代表找到了局部最小值
#### 软更新
在梯度下降中，为了防止参数更新发生较大变化，我们每次只取一部分新的参数跟大部分老的参数，即
$$
w = 0.01w_{new} + 0.99w\\
b = 0.01b_{new} + 0.99b
$$
#### 特征缩放
在面对多维特征问题的时候，要保证这些特征都具有相近的尺度，如所有特征的取值都在0-1之间，这将帮助梯度下降算法更快地收敛
#### 小批量梯度下降
如果训练集数据很多，按照正常的梯度下降，每轮都会把所有训练数据丢到代价函数计算一遍，小批量梯度下降的思想是，每轮梯度下降只取训练数据的一部分，这样可以有效减少计算量。
但这也会导致梯度下降收敛的速度比正常的慢。
### 过拟合
解决过拟合：
1. 加入更多的训练数据
2. 进行特征选择
3. 正则化
#### 正则化
- 基于训练数据（data）的正则化：在训练数据集上施加变换，从而产生新的训练数据集。通过生成更多的数据来训练以对抗过拟合。如数据增强及dropout
- 基于网络架构（network architecture）的正则化：简化关于从输入到输出的映射的假设，再让网络架构逐步逼近简化后的映射。如参数共享（weight sharing）以及对传递函数的正则化（activation regularization）
- 基于误差函数（error function）的正则化
- 基于正则化项（the regularization term）的正则化：会把正则化项添加到模型的损失函数中，正则化项的作用是惩罚模型的复杂度，鼓励模型选择简单的参数设置
- 基于最优化过程（optimization）的正则化