### The Attack and Its Impact on Performance Metrics

The attack has concluded. However, due to the mobility of nodes, the attack is not uniformly received by all nodes, leading to gaps where alarms are triggered and counted as false positives. Continuous attacks, which last longer, exhibit more of these gaps. This highlights the complexity of performance evaluation using traditional metrics such as detection rate (DR) and false positive rate (FPR).

### Table 1: Detection Performance for Continuous Attacks

| # Adversaries per Partition | Draining Attack | Grey Hole Attack |
|-----------------------------|-----------------|------------------|
| 2                           | Best: 94% DR, 6% FPR<br>Worst: 90% DR, 5% FPR<br>Average: 58% DR, 5% FPR | Best: 95% DR, 6% FPR<br>Worst: 97% DR, 3% FPR<br>Average: 93% DR, 4% FPR |
| 1                           | Best: 93% DR, 8% FPR<br>Worst: 85% DR, 7% FPR<br>Average: 45% DR, 8% FPR | Best: 63% DR, 8% FPR<br>Worst: 44% DR, 4% FPR<br>Average: 29% DR, 6% FPR |
| 0                           | Best: 70% DR, 5% FPR<br>Worst: 55% DR, 2% FPR<br>Average: 66% DR, 3% FPR | Best: 60% DR, 10% FPR<br>Worst: 40% DR, 7% FPR<br>Average: 11% DR, 9% FPR |

### Conclusions

In this article, we present a comprehensive approach to anomaly detection and mitigation for dissemination protocols in intermittently connected networks, specifically within a disaster area scenario. We have integrated and evaluated this approach within the Random Walk Gossip dissemination protocol.

To address the resource constraints of devices, particularly in terms of CPU power, we adopted a statistical-based detector algorithm. The threat model we validated focuses on making a significant impact on fair nodes with minimal energy investment by the adversary. The adversary's behavior closely mimics normal behavior, making it challenging to detect attacks through conventional means such as constraints, signatures, or rules.

Given this threat model, we added a mitigation mode to the basic protocol operation. In this mode, small modifications to the protocol allow nodes to change their behavior when an attack is suspected. This differs from previous approaches that focus on identifying and isolating the attacker. The integrated protocol can also be run in its original no-mitigation mode when no attacks are expected, providing no protection.

Our approach assumes the adversary has full knowledge of the protocol and even the anomaly detection scheme. Despite this, the adversary cannot easily adapt to avoid detection due to the unpredictability of the learning process in the normality model. This simplicity and robustness are key strengths of our scheme.

The evaluation demonstrated the effectiveness of our approach by showing resistance to attacks using network performance metrics. In both transient and continuous attack modes, mitigation brought the network back to performance levels close to pre-attack scenarios. The analysis also highlighted the complexity of using classic metrics like detection rate and false positive rate in highly partitioned networks, indicating that these metrics may not be suitable for measuring global detection performance in such environments.

### Future Work

Future work includes exploring the applicability of our methods to different attack types, including intermittent versions of current attacks, and adding new threat models. We are also interested in integrating parts of this resilience into the dissemination algorithm. Current work includes adding two new components to the detection-mitigation loop: a diagnosis element that runs in parallel with general (early) mitigation, and an adaptive component that decides when and how to end a given mitigation phase and return to a less cautious mode.

Another area for further research is the study of the impact of mitigation actions. When a node enables mitigation, it may change the system's behavior, potentially creating a recursive chain of alarms among the nodes. This is a complex problem because the system's behavior can be affected by the mitigation actions applied by all nodes.

### Acknowledgements

This work was supported by a grant from the Swedish Civil Contingencies Agency (MSB) and the national Graduate School in Computer Science (CUGS).

### References

1. Denning, P.J.: Hastily formed networks. Communications of the ACM 49(4), 15–20 (2006)
2. Steckler, B., Bradford, B.L., Urrea, S.: Hastily formed networks for complex humanitarian disasters after action report and lessons learned from the Naval Postgraduate School’s response to Hurricane Katrina. Technical Report, Naval Postgraduate School (2005)
3. Asplund, M., Nadjm-Tehrani, S.: A partition-tolerant manycast algorithm for disaster area networks. In: IEEE Symposium on Reliable Distributed Systems, pp. 156–165 (2009)
4. Aschenbruck, N., Gerhards-Padilla, E., Gerharz, M., Frank, M., Martini, P.: Modelling mobility in disaster area scenarios. In: MSWiM 2007: Proceedings of the 10th ACM Symposium on Modeling, Analysis, and Simulation of Wireless and Mobile Systems, pp. 4–12. ACM, New York (2007)
5. Ye, N., Chen, Q.: An anomaly detection technique based on a chi-square statistic for detecting intrusions into information systems. Quality and Reliability Engineering International 17(2), 105–112 (2001)
6. Yang, H., Luo, H., Ye, F., Lu, S., Zhang, L.: Security in mobile ad hoc networks: challenges and solutions. IEEE Wireless Communications 11(1), 38–47 (2004)
7. Prasithsangaree, P., Krishnamurthy, P.: On a framework for energy-efficient security protocols in wireless networks. Computer Communications 27(17), 1716–1729 (2004)
8. Farrell, S., Cahill, V.: Security considerations in space and delay tolerant networks. In: Second IEEE International Conference on Space Mission Challenges for Information Technology, Washington, DC, USA, pp. 29–38. IEEE, Los Alamitos (2006)

### Community Epidemic Detection Using Time-Correlated Anomalies

#### Abstract
An epidemic is defined as malicious code running on a subset of a community, which is a homogeneous set of instances of an application. Syzygy is an epidemic detection framework that identifies time-correlated anomalies, i.e., deviations from a model of dynamic behavior. We show mathematically and experimentally that, by leveraging the statistical properties of a large community, Syzygy can detect epidemics even under adverse conditions, such as when an exploit employs both mimicry and polymorphism. This work provides a mathematical basis for Syzygy, describes our implementation, and tests the approach with various exploits and on commodity server and desktop applications to demonstrate its effectiveness.

#### Introduction
Consider a set of instances of an application, which we call a community. Examples include all mail servers in an organization or all browsers on a cluster of workstations. Assume some subset of these instances, or clients, are compromised and are running malicious code. The initial breach went undetected, and the existence of the exploit is unknown, allowing the malicious code to continue running indefinitely, perhaps stealing computing resources, spoofing content, or denying service. We present a method for detecting such situations by using the aggregate behavior of the community to reliably identify when a subset of the community is not behaving properly.

A client is either healthy and exhibits correct behavior or infected and exhibits incorrect behavior. Our method detects epidemics, meaning when a subset of the community is infected. The user specifies what constitutes correct operation for individual clients by providing a model, which may be incomplete or unsound. For example, a community of web servers may be modeled by the typical distribution of response times each provides. The class of attacks we want to detect causes undesirable deviation from normal behavior, regardless of the attack vector.

#### Related Work
Syzygy detects malicious software running on clients in a community even under typical real-world constraints: the client model is incomplete, information about communication is unavailable, and measurements are noisy. It may be impossible, given social engineering and insider attacks, to prevent all security breaches. A strength of Syzygy is that it can detect the bad behavior that follows a breach.

Anomaly-based intrusion detection has a long history. A commonly held view is that anomaly detection is limited by the mediocre quality of the models that can be obtained in practice and must necessarily generate excessive false positives in realistic settings. We agree with this argument for single clients but show that an appropriate use of a community can make strong guarantees even with noisy models.

#### Syzygy
Consider a community of \( n \) clients in which we wish to detect epidemics. During training, Syzygy observes the normal operation of the clients and builds a model. While subsequently in monitoring mode, Syzygy periodically collects the most recent value of the anomaly signal (the anomaly score) from each client and checks whether the community’s average anomaly score exceeds a threshold \( V \). If so, Syzygy reports an epidemic. The properties of the anomaly signal are such that, given a large community, Syzygy can compute the threshold automatically at runtime and is insensitive to minor variations in this parameter.