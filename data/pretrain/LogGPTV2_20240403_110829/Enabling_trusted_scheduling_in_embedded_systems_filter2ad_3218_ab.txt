saves the current state of the system and transfers control to
the new application. Before the actual execution of the ap-
plication itself, the trusted domain conﬁgures and activates
the desired CPU time-slice monitor (e.g., a timer interrupt)
and the atomicity monitor that transfer control back to it
from the application. The CPU time-slice monitor and the
atomicity monitor together guarantee that the trusted do-
main can regain (with minimal latency) control of the CPU
when needed. The scheduler is isolated from the applica-
tions and other system components; it acts directly on the
CPU and thus can always stop and start the execution of
the applications.
In order to ensure application isolation,
each application running on the system is allocated its own
dedicated memory partition and application boundaries are
enforced using an application-aware memory protection unit
(MPU). Finally, to ensure that bus access to the peripherals
is securely mediated, we introduce a peripheral bus man-
ager. This peripheral bus manager controls access to the
peripheral bus from the various peripherals and prevents
misbehaving peripherals from denying the CPU (the run-
ning applications) and other benign peripherals access to
the bus. It also ensures that each application can only ac-
cess the set of peripherals to which it has been granted access
by the trusted domain.
Every application starts executing at its ﬁrst instruction
and continues until it terminates, violates a security policy
or is preempted. A security exception is raised if an appli-
cation tries to access or modify code or data that does not
belong to it. A security exception is also raised if an appli-
cation tries to execute an atomic section that is larger than
the preset limit or if its allocated CPU time-slice expires.
Additionally, the peripheral bus manager also raises a secu-
63
Run A1
A2 resumes
A1 executes
A2 executes
A3 executes
Trusted domain executes
Time
Run A2
Run A3
A3 starts
Figure 4: The trusted domain must save and restore
state during a context switch to prevent applications
from accessing and/or modifying each others state.
rity exception if any application tries to access a resource
to which it has not been granted access or if the length of
any bus transaction exceeds a pre-determined upper bound.
Alternatively, the upper bound on the length of bus transac-
tions can also be enforced by the atomicity monitor. When
an application is preempted or forcibly terminated due to a
security exception, control is transferred back to the trusted
domain (via the hardware scheduler) which resumes execu-
tion of pending applications.
In terms of the system initialization, we assume that a
trusted administrator supplies system initialization values
to the trusted domain. When the system is powered-on,
the trusted domain executes ﬁrst and performs system ini-
tialization based on the inputs provided by the administra-
tor. These inputs may include (but are not limited to) the
number of applications, the peripherals they use, their mem-
ory layout, execution schedule, preemption policies (like the
maximum CPU time-slice for each application, etc.). The
trusted domain conﬁgures the scheduler for periodic and/or
event-driven execution of applications. Furthermore, it also
conﬁgures the resource allocator’s CPU preemption policies
and the application-aware MPU to create dedicated program
and data partitions for each application. Finally, the trusted
domain initializes the program memory of individual appli-
cations and conﬁgures the peripheral bus manager with in-
formation regarding the peripheral access requirements of
the applications.
3.2 System Components
We now describe selected hardware and software compo-
nents of the trusted computing base (TCB) in more detail.
Trusted Domain
The trusted domain is the only software component of the
TCB and resides in ROM. The trusted domain is responsi-
ble for initializing the hardware scheduler, components that
allocate system resources (described below), handling con-
text switches between applications and the actual transfer
of control from the scheduler to the individual applications
(Figure 4). We chose this approach in order to prevent ma-
licious applications from accessing or modifying the state of
their predecessors which could result in a violation of trusted
scheduling. The trusted domain uses a dedicated data parti-
tion in RAM that is not accessible by any other application
or system component.
Scheduler
Our architecture includes a hardware-scheduler that uses in-
formation about external events and internal logic to decide
the order in which applications execute. Although using a
hardware scheduler limits ﬂexibility (adding, removing ap-
plications, changing algorithms, etc.), we believe that this is
an acceptable trade-oﬀ for security in real-time systems, as
they are mostly single-purpose and run applications that do
not change frequently (e.g., due to safety compliance issues).
The scheduler transfers control to the trusted domain that
in turn transfers control to the actual application.
Our scheduler implements preemptive scheduling. Althoug-
h co-operative scheduling, where applications are allowed to
execute to completion or co-operatively release the CPU,
may be simpler and more eﬃcient than preemptive schedul-
ing, relying upon applications to release the CPU punctually
can be dangerous in adversarial settings. This is because
malicious applications may hold onto the CPU and hence
delay (or in the worst case prevent) the execution of other
applications. Hence, in order to achieve trusted scheduling,
one must use preemptive scheduling schemes where the ex-
ecution of any application can be interrupted at any point
of execution except for those that the application explicitly
labels as atomic.
Resource Allocation Components
The resource allocator must ensure that applications have
access to at least three system resources while executing:
CPU, memory and the bus(es).
CPU Availability
Atomic sections are required to ensure the correctness of cer-
tain operations (e.g., updating the stack pointer (SP )). The
sequence of instructions in an atomic section ((i) decrement-
ing the existing SP value and (ii) re-storing the new value
in SP ) should be executed without interruption. Otherwise,
a corrupt system state (SP ) may result. Hence, if an appli-
cation is executing an atomic operation, the scheduler would
have to wait until it completes the operation before suspend-
ing it. Although it is recommended that atomic operations
should be as short as possible, a malicious application could
declare large portions of code as atomic and hence delay, or
in the worst case prevent the execution of another applica-
tion. In order to prevent such attacks, the system must be
able to bound the maximum duration (in time) of atomic
operations.
Our architecture (Figure 3) includes an atomicity monitor
that tracks the length of atomic code sections. The atomic-
ity monitor terminates an erring application which exceeds
a pre-deﬁned execution upper bound. This requires that all
applications are designed to respect this bound; otherwise
they will fail to execute correctly. We note that this bound
does not apply to the trusted domain. The atomicity moni-
tor must also prevent nesting of atomic sections to increase
their eﬀective length. Furthermore, the trusted domain con-
ﬁgures an additional CPU time-slice monitor (e.g., a timer)
just before it transfers control to the individual application.
Memory Availability
Applications typically need two types of memory: program
memory for their code and data memory for their stack and
heap.
64
The use of shared stacks and heaps allows compromised
applications to launch iDoS attacks by potentially exhaust-
ing stack or heap space. Recovery from such stack and heap
overﬂow attacks requires invalidating current stack frames
(e.g., by unwinding) and heap data. Although solutions that
guarantee such secure stack sharing exist [24, 20], recovering
from security violations can be complicated and expensive.
This is because identifying and invalidating data memory
regions that caused the violation can be both costly and
time-consuming. For example, upon a security exception,
one may have to unwind multiple stack frames which is time
consuming compared to simply swapping the stack pointer.
Enforcing access control policies in systems with shared data
memory can also be complicated because it requires main-
taining ownership information on individual stack frames
and heap blocks as described in [20]. Therefore, we use
dedicated data partitions for each application and depend
upon the application-aware MPU (described below) to pre-
vent iDoS attacks on data memory. A similar approach is
used to ensure availability of program memory. Although
such partitioned memory architectures limit ﬂexibility, we
believe they are still suitable for use in trusted scheduling
architectures for such specialized systems whose memory re-
quirements are typically known in advance.
In practice, most embedded systems use a memory pro-
tection unit (MPU) or a memory management unit (MMU)
for protecting each application’s state against unauthorized
access or modiﬁcation. Typically, such a unit only enforces
access control policies (read, write, execute) at run-time on
segments or pages of memory, and the operating system is
responsible for separating memory regions of diﬀerent ap-
plications. Our trusted scheduling architecture relies on a
specialized MPU that combines these two functions, i.e., an
application-aware MPU that not only checks for the type
of access to memory but also whether the entity initiating
such an access has the appropriate privileges. For specialized
embedded devices with relatively long lifetimes, enhanced
MPUs and MMUs that are application-aware (e.g., ARM [1],
NIOS II [7]) present a reasonable trade-oﬀ between ﬂexibil-
ity and better security.
In our system, the trusted domain conﬁgures the applicati-
on-aware MPU with information regarding the boundaries of
diﬀerent applications. Every memory access (both program
and data memory) is then mediated by this MPU.
Mediation of the Bus Access
If an application cannot gain access to the memory or to
the peripherals that it needs for its correct execution, it
will fail to execute. A compromised system component with
access to a bus can cause such failures by holding on to the
bus — preventing any communication among other system
components that are connected to the same bus. We call
this attack an iDoS attack on the bus.
In our system, we do not consider DMA-capable periph-
erals and assume that all peripherals access memory only
through the CPU. We assume that the atomicity monitor
enforces the upper bound on the length of bus transactions.
This in turn prevents iDoS attacks on the system bus. We
discuss this further in the security analysis (Section 3.3).
In addition to components connected to the system bus,
components on the peripheral bus are also often crucial for
the operation of the system or of individual applications,
e.g., EEPROMs containing system conﬁguration data may
need to be accessed in a timely manner, an alarm applica-
tion needs to have access to the radio peripheral to transmit
alarm messages. In order to ensure the availability of the
peripheral bus, we propose a secure hardware bus manager
that mediates bus access requests.
In our system, we consider a multi-master (multi-)slave
bus (e.g., I2C ). In most multi-master bus architectures, a
typical data exchange consists of three phases: bus-arbitrati-
on, data-exchange and bus-release. Bus-arbitration is used
to establish a bus-owner when there are several contenders
(or masters). Arbitration is followed by data exchange and
by an explicit bus-release phase in which other bus masters
are informed about the availability of the bus. These three
phases constitute a bus transaction and it is always executed
atomically.
The shared nature of the multi-master bus allows a mis-
behaving peripheral to aﬀect (by delaying or denying bus
access) the execution of the applications that do not directly
depend upon it. A misbehaving peripheral could deny bus
access in the following ways:
(i) A misbehaving master peripheral may not respect the
rules of bus arbitration and may continue its trans-
mission beyond what it is allowed, thereby indirectly
disrupting or modifying data on the bus.
(ii) A misbehaving master peripheral could gain access to
the bus by sending carefully crafted data to win bus-
arbitration every time and then sending data continu-
ously without releasing the bus.
(iii) A misbehaving slave could delay its master node for
arbitrary lengths of time.
In our system, we prevent these attacks by introducing a
secure peripheral bus manager. This manager is conﬁgured
by the trusted domain at start-up with information regard-
ing the list of peripherals that must be accessed by each
application. The manager uses this information at run-time
to ensure that only peripherals that are needed by the exe-
cuting application have access to the bus.
The manager further allows an application to selectively
enable and disable peripherals at run-time. Such ﬁne-grained
control allows an application to only enable the peripheral
that it is currently using. As a result, a misbehaving periph-
eral cannot inﬂuence any execution sequence during which
it is not enabled and an application’s interaction with any
other peripheral that is not concurrently active. Together,
these two features enable graceful degradation in the func-
tionality of the application while maintaining tight security
guarantees. However, little can be done if the misbehaving
peripheral is critical for the application’s correct execution.
Finally, the manager ensures that if an application termi-
nates as a result of a security violation, then all the devices
(peripherals) to which it had access are reset before they
are re-used. We present a realization of a peripheral bus
manager for the I2C bus in Section 4.
3.3 Security Analysis
In this section, we analyze the security of our system. As
described in Section 2, our attacker does not have physical
access to the system, but can only remotely compromise
selected applications and system components.
We assume that our trusted scheduling extensions (sched-
uler, trusted domain, application-aware MPU, peripheral
65
(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)
(cid:9)(cid:10)(cid:11)(cid:8)(cid:7)
(cid:12)(cid:9)(cid:10)(cid:11)(cid:8)(cid:13)(cid:14)(cid:15)(cid:10)(cid:16)(cid:8)
(cid:4)(cid:17)(cid:6)(cid:18)(cid:10)(cid:19)(cid:6)(cid:7)(cid:20)
(cid:5)(cid:26)(cid:27)(cid:28)(cid:4)(cid:27)(cid:18)(cid:29)(cid:19)(cid:7)(cid:30)
(cid:12)(cid:1)(cid:19)(cid:6)(cid:11)(cid:10)(cid:16)(cid:10)(cid:19)(cid:31)(cid:4)
(cid:17)(cid:6)(cid:18)(cid:10)(cid:19)(cid:6)(cid:7)(cid:20)
(cid:1)(cid:21)(cid:21)(cid:15)(cid:10)(cid:16)(cid:22)(cid:19)(cid:10)(cid:6)(cid:18)(cid:4)
(cid:1)(cid:23)(cid:22)(cid:7)(cid:8)(cid:4)
(cid:17)(cid:24)(cid:25)
(cid:1)(cid:21)(cid:21)(cid:15)(cid:10)(cid:16)(cid:22)(cid:19)(cid:10)(cid:6)(cid:18)(cid:4)
(cid:9)(cid:7)(cid:22)(cid:16)(cid:32)(cid:8)(cid:7)