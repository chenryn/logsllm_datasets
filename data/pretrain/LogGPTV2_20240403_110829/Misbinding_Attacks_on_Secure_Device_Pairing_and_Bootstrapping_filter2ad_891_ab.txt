Bluetooth-paired devices. A more general lesson that we can draw
from the paper is that it is important to pay attention to malicious
insiders, such as untrusted apps, residing in the endpoint devices,
which may be able to interfere with the communication without
fully compromising the device.
The pairing protocols critically depend on user actions, such
as comparing or delivering codes. Ellison [20] introduced the con-
cept of security ceremonies where the users are participants to the
protocol and their actions are specified, modelled and analyzed
just like those of the communicating endpoints. Carlos et al. [13]
use Bluetooth as an example for reasoning about basic security
properties of a security ceremony.
2.4 Trusted computing and cuckoo attack
The published work closest to ours comes from the trusted-comput-
ing community. In trusted computing, a computer or a mobile device
incorporates a secure hardware component that is certified by the
manufacturer and acts as a trusted entity inside the device. The
most common secure hardware component is a trusted platform
module (TPM) [1], which supervises the boot process of the device
and either enforces secure boot or measures (as a cumulative hash
value) the loaded software. The latter case is also called dynamic
root of trust for measurement (DRTM). The latest microprocessors
have more advanced trusted execution environments (TEE), such
as ARM TrustZone1 and Intel SGX2, which allow trusted software
to be isolated and launched after the device has booted. A common
feature in these technologies is that, in addition to enforcing some
security policies inside the computer, they can attest the integrity
of the device and its software configuration to an external verifier.
This could allow, for example, the user to cryptographically verify
the integrity of a cryptocurrency wallet before storing high-value
secrets to it. The attestation naturally needs to be cryptographically
linked to a secure communication channel [23] with the verifier.
Parno et al. [40] first pointed out the problem that, while users
may be able to cryptographically verify that they are communicat-
ing with a trusted hardware module and measured software, it is
difficult to be certain that they are physically accessing the very
device where that module is embedded. In the cuckoo attack, the
device in the verifier’s physical proximity is not actually trusted
but tricks the verifier into believing so. The cuckoo device achieves
this by forwarding the communication to another device which has
the correct configuration and a DRTM for attesting it.
Fink at al. [21] suggest measuring the round trip times of re-
quests to the trusted device to detect if it is in the proximity of the
verifier. Zhang et al. [46] also investigate the problem of a human
user distinguishing genuine secure hardware from adversarial de-
vices. They divide the presence attestation into two phases: first,
existence checking, which uses the standard remote attestation
protocols, and second, residence checking, which provides assur-
ance that the attesting hardware module is, in fact, in the specific
physical device. We will return to the suggested mechanisms for
residence checking in Section 5. Ding et al. [18] further argue that
presence attestation with DRTM differs significantly from device
pairing where both devices are trusted. The current paper sets out
to investigate whether this is always the case.
2.5 Formal modelling
Formal modelling and model checking are standard methodology in
the development and analysis of key-exchange protocols [7, 10, 17].
Various protocol flaws have been found with these methods but,
perhaps more significantly, formal models are a way to lift the
security-protocol design to a higher abstraction level than message
1https://developer.arm.com/technologies/trustzone
2https://software.intel.com/en-us/sgx
Session 6A: IoT SecurityAsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand455formats and state machines, and to define precisely the security
properties that the protocol is expected to have.
The model checkers for security protocols are special compared
to other formal modelling tools in that, in addition to taking the
system design as input, they typically have a built-in model of the
Dolev-Yao type powerful attacker, which the researcher does not
need to explicitly define. Instead, the researcher has to specify the
desired security properties. The model checker then determines
whether the attacker is able to play a game against the honest parties
and trick them into violating these properties. There is, however
one type of attack that the researchers need to explicitly consider:
corrupt insiders. The corruption of an insider is often modelled as
a previously honest party handing out its secrets and capabilities
to the attacker, after which it is subsumed into the attacker.
Jia and Hsu [29] develop a formal model of the Bluetooth SSP
for the Murphi model checker [17]. They discuss two potential
vulnerabilities in the numeric-comparison authentication mode.
First, an impersonator device can pretend to be a good one and trick
the user into pairing an honest initiator device with it. The example
given in the paper is one where the entertainment system in a
rental car has been replaced with one that is under the adversary’s
control. Once the unsuspecting user has paired her phone with
it, the system can steal confidential data. Second, a proxy MitM
device can forward the unmodified connection to another device
(similar to [35]). While these threats might be considered obvious
and unavoidable, the formal analysis focuses our attention to them
and enables systematic consideration of the threats.
The most interesting idea of Jia and Hsu for us is the notion of
intention preservation. It means that the initiating device is paired
with the device with which the user originally intended to pair it,
even if the non-initiating device belongs to an intruder. They show
that Bluetooth pairing with numeric comparison has this property.
We develop further the idea of modelling user intention, which
we state as a correspondence assertion. Because of subtly differ-
ent security definitions, we end with a different result regarding
Bluetooth pairing.
3 MISBINDING IN DEVICE PAIRING
We will now look at identity misbinding attacks against wireless
device pairing where user authenticates the key exchange between
two physical devices. Figure 2(a) shows a common structure for
many such pairing protocols. The unauthenticated key exchange
takes place over an insecure in-band channel, and the user with
physical access to the devices authenticates it over a secure out-of-
band channel. The two phases may not always be distinguishable
by time, but they are distinguishable by the channel.
The authentication in user-assisted pairing protocols is typically
based on physical access to the device. That is, the user must see or
touch the devices directly. The devices could have serial numbers,
public keys, or other unique identifiers, but it is the physical access
that defines which devices need to be paired.
We consider a scenario where one of the devices selected by the
user for the pairing is compromised. (Recall that identity misbinding
is an insider attack where one of the intended communication
endpoints is corrupt.) The device has to be compromised at least to
the extent that the user can control the device’s inputs and outputs
Figure 2: Identity misbinding against device pairing
on the OOB channel. In Figure 2(b), the user wants to pair devices A
and B. However, device B is malicious and relays the authentication
messages to another device C. Devices A and C end up paired,
which does not correspond to the user’s intention. Device C does
not need to collude with B and may be entirely honest, except that
the attacker can put it into the pairing mode and interact with it.
Let’s try to understand why this attack is not easy to prevent. If
we take guide from other authenticated key-exchange protocols,
such as STS and SIGMA, we might try to prevent the attack by
binding the endpoint identifiers A and B cryptographically to the
key exchange and the created session. This will ensure that the
endpoints of the created session agree on the identities. Sadly, that
does not help in device pairing. The attack by B will cause A and
C to be paired, but if the user is not aware of the identifiers com-
municated in band, the user still thinks A is paired with B. As the
next step towards a solution, we would need to check that the de-
vice identifiers A and B correspond to the user’s expectations. For
example, if device A shows the peer identifier to the user, the user
sees that it is C and not B as intended. However, the typical user
in device pairing does not have any expectations about the device
identifiers: the user just sees two physical devices and wants them
to be paired.
Many pairing protocols are like this: the user’s physical access
to the device defines its identity. Since the physical device identity
cannot be communicated in bits and bytes, it cannot be included into
the messages sent over the in-band or out-of-band channel, and it
cannot be used as input to a cryptographic function. Cryptographic
protocol vulnerabilities of the early days could often be fixed by
adding a missing identifier to the right message, but that is not
the case with device pairing where the endpoints either have no
identifiers or, if identifiers exist, user intentions are not expressed
in terms of them.
So far, our discussion of misbinding may appear as rehashing of
the relay attack in the context of device pairing. This perception
is partly true, but the misbinding attack is actually far easier to
implement. As hinted in Figure 2(b), if all three devices are within
unauthenticatedkey exchangephysicalOOB channelBAwirelessin-bandchannelphysicalOOB channelsACauthenticationauthenticationrelayedauthenticationBunauthenticated key exchange(a)(b)wirelessin-bandchannelSession 6A: IoT SecurityAsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand456device C, accessible by the attacker Mallory, is within radio
range.
(2) Alice starts a search for new Bluetooth devices on device A.
She makes device B discoverable, if it is not yet so. Mallory
makes device C discoverable. Device A then presents Alice
with a list of the names of discoverable devices in its vicinity.
Alice chooses the one she thinks is B. At this point, Mallory
needs to arrange things so that Alice mistakenly chooses
C from the list. To achieve this, Mallory should ensure that
the compromised device B remains non-discoverable, even
though Alice thinks otherwise, and ensure that the name
of device C matches the name that Alice expects to see for
device B. (We will discuss the naming in more detail below.)
(3) During the pairing, devices A and C show six-digit codes
and expect the user to compare them. Mallory reads the six-
digit code from the screen of device C and forwards it to the
compromised device B, which displays it to Alice.
(4) Seeing the same six-digit verification code on the screens of
devices A and B, Alice confirms the pairing on both devices.
The action on the compromised device B has no real effect;
instead, Mallory confirms the pairing on device C. This al-
lows the pairing of A and C to complete. Alice now believes
A and B have successfully paired when, in fact, device A is
paired with C.
To understand why the Bluetooth SSP protocol does not prevent
the attack above, we need to look at the protocol in more detail. The
hardest practical obstacle for the attacker is, in fact, not the actual
SSP protocol but the device naming and selection that takes place
before the actual pairing. Bluetooth core specification [43] defines
Inquiry and Paging procedures for discovering nearby devices and
subsequently connecting to one of them. The user typically selects
the name of the non-initiating device from a list of nearby devices
on the initiating device. The device names are strings that aid
the user in identifying the correct peer device. Each device has a
default name that often indicates its make and model, for example
“TomTom Go 510”. Depending on the device, the name may be
user configurable. In the attack, Mallory needs to trick Alice into
choosing device C from the list by its name. Thus, Mallory should
rename C to have the same name as B.
The rare tricky case for Mallory is if she wants to use a device C
that does not have a configurable name, or if Mallory does not have
the permission to change the device name. In that case, Mallory
may be able to choose a device C that has the same make and
model as device B and thus the same default name. If Mallory
absolutely needs to use a device C with a Bluetooth name that is
not configurable and does not match device B, there is still a way
forward. The Inquiry and Paging procedure is not authenticated,
and the attacker can manipulate the device names on the in-band
wireless channel. While that requires more skill than changing the
name of device C on its user interface, message modification on a
wireless channel is within the expected capabilities of a Dolev-Yao
attacker.
Once Alice has been fooled into choosing the wrong device,
the SSP security protocol starts between devices A and C. We will
review the protocol to be certain that it does not present obstacles
to the attack. The numeric-comparison mode of SSP, shown in
Figure 3: Misbinding attack against Bluetooth SSP numeric
comparison
the wireless range from each other, B does not actually need to
relay the wireless in-band traffic. It can let A and C communicate
directly over the wireless channel and focus on relaying the au-
thentication messages between the two OOB channels. B can then
pull out after the authentication is complete, which leaves A and C
communicating directly.
Comparing with the cuckoo attack against trusted computing
hardware, there are also similarities. The problem there was the lack
of secure binding between the physical device and the long-term
public key of the DRTM inside it. Our problem is the lack of secure
binding between the physical devices and the ephemeral session
key. The similarity extends to the lack of definite solutions by the
means of traditional security protocol design. However, there are
ways of mitigating the threats, as we will see in Section 5.
Next, we will look at some examples of the attack in actual pair-
ing protocols. That will help us assess the impact of the vulnerability
in a more concrete way.
3.1 Bluetooth case study
We use the widely-studied Bluetooth SSP as a case study of mis-
binding in pairing protocols. The attack is shown in Figure 3. The
human user Alice is unaware of the fact that the device B, to which
she is trying to pair her phone A, is compromised and under the
control of an attacker Mallory. The attacker also has a third device
C, which she keeps hidden from the user. The attacker’s goal in the
misbinding attack is to pair Alice’s device A with the third device C
while Alice believes A is paired with B. For a successful misbinding
attack, A and C must be within Bluetooth radio range from each
other. For example, Mallory and device C could be in the next room
from where Alice performs the pairing process.
From the user’s and the attacker’s points of view, the following
steps occur in the misbinding attack of Figure 3:
(1) Alice wants to pair devices A and B with the goal of estab-
lishing a secure association between them. Alice is unaware
of the fact that device B is compromised and that a third