### Number of Threads and Processes
- **Number of Threads:** 8, 16, 32
- **Swapping Item Between Queues:**
  - No kill
  - 1 kill every 100ms

### Performance Analysis
- **Figure 12: Persistent Queues (left) and Impact of Failures (right)**
  - The hash set shown in Figure 11 indicates that the number of traversed nodes is rarely above 2. This brings OneFile closer to the Romulus implementations and surpasses PMDK by an order of magnitude in most scenarios.
  - For an update ratio of 100%, OneFile-PTM performs 30% less than RomulusLog but provides lock-free progress.

### Persistent Queues
- **Left Plot of Figure 12:**
  - Multiple persistent queues, all based on singly-linked lists.
  - The FHMP queue, designed by Friedman, Herlihy, Marathe, and Petrank [63], is a hand-made lock-free design.
  - All other queues are sequential implementations wrapped in a PTM.
  - The original FHMP queue uses the system allocator, which is blocking for allocation, has no embedded memory reclamation, and does not work on NVM.
  - Adding an NVM allocator and reclamation scheme to FHMP would decrease its performance.
  - Queues made with OneFile PTMs have performance close to the hand-made lock-free queue FHMP and surpass it in single-thread workloads, while providing failure-resilient memory allocation/de-allocation and reclamation.

### Advantages of Lock-Free PTMs
- **Lock-Free PTMs vs. Hand-Made Lock-Free Data Structures:**
  - Operations over multiple instances benefit from lock-free PTMs.
  - Example: Dequeue an item x from q1 and enqueue it in q2 atomically and with lock-free progress.
  - If a failure occurs between the dequeue and enqueue, the item x will be lost in hand-made structures.
  - With OneFile-PTM, a transaction can encompass both operations, preventing the loss of the item and ensuring no memory leakage or allocator metadata corruption.

### Test Scenario
- **Multiple Processes and Transactions:**
  - Test: N processes, each with a single thread, continually execute a transaction that moves an item between two shared queues.
  - Enqueuing allocates one node, and dequeuing de-allocates another node per transaction.
  - The test runs for 100 seconds with N being 2, 4, 8, 16, or 32 processes.
  - Results (no kill and 1 kill every 100ms) are shown in the right plot of Figure 12.
  - Conclusions:
    - OneFile provides fast recovery time with no measurable performance impact for 1,000 failures during 100 seconds.
    - No memory leaks or allocator metadata corruption observed.
    - Non-failed processes continue executing normally.

### Performance Factors
- **Summary Table:**
  - **PMDK:**
    - pwb: 2.25 * Nw
    - pfence CAS or DCAS: 2 + 2 * Nw
  - **RomulusLog:**
    - pwb: 3 + 2 * Nw
    - pfence CAS or DCAS: 4 or less
  - **OneFile (Lock-Free):**
    - pwb: 1 + 1.25 * Nw
    - pfence CAS or DCAS: 0
  - **OneFile (Wait-Free):**
    - pwb: 2 + 1.25 * Nw
    - pfence CAS or DCAS: 0

### Conclusion
- **STMs and Large Transactions:**
  - STMs have a bad reputation for mishandling large transactions and high contention.
  - Wait-free OneFile is immune to starvation and has predictable latency, regardless of contention or transaction size.
  - Transactions in OneFile-PTM require two persistence fences, are durable linearizable, and have bounded wait-free progress including memory allocation, de-allocation, and reclamation.
  - OneFile-PTM uses an optimistic approach for memory reclamation, allowing safe access to memory locations without announcing to concurrent threads.
  - Reusing memory blocks for de-allocation and allocation of objects of the same size reduces pwbs and improves cache locality.
  - OneFile-PTM provides a generic approach with integrated memory reclamation, enabling the implementation of various data structures like wait-free queues, linked list sets, resizable hash maps, and balanced trees.

### References
- [References listed as provided]

This optimized text is more structured, clear, and professional, making it easier to understand and follow.