for Π(i) = Π(2), . . . , Π(n), ΠIDLE do
// Candidate list
if CandidacyTest(Π(i), t) == F alse then
// No need to test for Π(i+1), · · ·
Break
end
LC ← LC ∪ {Π(i)}
end
Step 2 – Random Selection
Πx ← Select one from LC
return Πx
Algorithm 2: CandidacyTest(Π(i), t)
for Πh ∈ hp(Π(i)) − hp(Π(i−1)) do
if SchedulabilityTest(Πh, t) == F alse then
return F alse
end
end
return T rue
// All hp(Π(i)) are schedulable
allowed to take the CPU, and (ii) random selection, which
selects one randomly from the list.
1) Step 1 – Candidate search: Algorithms 1 and 2 sum-
marize the candidate search process. Suppose we are to make a
scheduling decision at time t. Let Lt = (Π(1), Π(2), . . . , Π(n))
be the list of active partitions, sorted in decreasing order of
priority. Then, for each Π(i), starting from the highest priority,
TIMEDICE tests if it can be a candidate. It passes the candidacy
test if its execution at time t would still allow to meet deadlines
for all of the higher-priority partitions, hp(Π(i)),
including
partitions that are not active at present. If any of them would
miss its deadline, Π(i) cannot be added to the candidate list,
and the search process stops for time t. This is because if a
higher-priority partition Πh would miss its deadline due to the
execution of Π(i), Πh would miss the deadline due to Π(i+1)
anyway. Note that the highest-priority active partition, Π(1), is
always a candidate because no priority inversion occurs due
to its execution. Meanwhile, if all of the active partitions pass
the candidacy test, an additional test is performed to check if
the CPU can be idled. This can be implemented by adding an
‘imaginary’ idle partition, ΠIDLE, and treating it as if it is
another active partition, as shown in Algorithm 1. If passed, it
is added to the candidate list.
a) Detailed process of candidate search: Suppose we
are testing if Π(i) can be a candidate for time t. In order to
check for this, the schedulability test (Algorithm 3) is performed
against each Πh ∈ hp(Π(i)). Πh is schedulable if and only if
its worst-case busy interval does not end past its deadline. The
busy interval begins with a priority inversion by Π(i) at time t:
Deﬁnition 2. The level-Πh busy interval with base time t and
initial window of size w, denoted by Wh,t(w) (shown in Fig. 7),
is a time window [t, t + q) that is comprised of the following:
(a) a priority inversion of size w by Π(i) during [t, t + w),
(b) all remaining execution budgets of hp(Πh) as of time t,
(c) all the future executions of hp(Πh) that will arrive on or
Algorithm 3: SchedulabilityTest(Πh, t)
w ← MIN INV SIZE
(cid:2)
W 0 ← w + Bh(t) +
deadline ← rh,t + Th
// length of priority-inversion
Πj∈hp(Πh) Bj (t)
// Eq. (2)
// rh,t + 2Th if Πh is inactive
while W k+1! = W k do
(cid:2)
W k+1 ← W 0 +
if Πh is inactive then
Πj∈hp(Πh)(cid:5)(W k(w) − oj,t)/Tj(cid:6)0 · Bj
W k+1 ← W k+1 + (cid:5)(W k(w) − oh,t)/Th(cid:6)0 · Bh
end
if W k+1 > deadline then
return False
end
end
return True
(cid:3)(cid:4)(cid:9)(cid:1)(cid:3)(cid:10)
(cid:1)(cid:3)
(cid:1)(cid:7)(cid:4)(cid:8)(cid:1)
(cid:6)
(cid:5)(cid:1)(cid:6)
(cid:7)
// Potential deadline miss
// Πh is schedulable
Offset
Replenishment Period
(cid:5)(cid:3)(cid:6)
(cid:5)(cid:2)(cid:6)
Offset
(cid:5)(cid:3)(cid:6)
Replenishment Period
(cid:5)(cid:2)(cid:6)
(cid:5)(cid:4)(cid:6)
(cid:5)(cid:3)(cid:6)
(cid:2)(cid:5)(cid:2)(cid:6)(cid:9)(cid:7)(cid:10)
(cid:5)(cid:4)(cid:6)
(cid:5)(cid:4)(cid:6)
(cid:6)(cid:8)(cid:5)
(cid:5)(cid:4)(cid:6)
Time
Priority inversion
Fig. 7: Busy interval Wh,t(w) is extended as long as Πh is
delayed by hp(Πh). Wh,t(w) = (a) + (b) + (c) + (d).
after t and are used up by the end of the busy interval,
(d) the remaining execution budget of Πh itself.
Wh,t(w) = q = (a) + (b) + (c) + (d) is the length of the busy
interval, and the end of the interval, i.e., t + q, is the ﬁrst time
instant when Πh itself and all of hp(Πh) that arrive during
[t, t + q) use up their budgets if [t, t + w) is taken by a low-
priority partition Π(i).
Informally speaking, the level-Πh busy interval represents
how long it would take, in the worst-case, for Πh to use up its
remaining budget if it allows for a priority inversion of length
w from time t to t + w. Finding Wh,t(w) can be viewed as a
simulation of the worst-case schedule from time t with a priority
inversion of size w.
Wh,t(w) for given t and w is computed iteratively as shown
in Algorithm 3. Note that at time t, the amount of remaining
budgets of all partitions (i.e., (b) and (d) in Fig. 7) are known.
The worst-case busy interval is when all the future executions
of hp(Πh) (i.e., (c) in Fig. 7) arrive as frequently as possible.
This happens if they use up their budgets as soon as they
become available. Since the last replenishment time of each
Πj ∈ hp(Πh) before t, denoted by rj,t, is already known at
time t, the relative offsets of their next replenishment time from
t are known and calculated by oj,t = rj,t+Tj−t. Then, Wh,t(w)
is computed by the following iterative equation (similar to the
approach to ﬁnding response time [30]):
h,t(w) − oj,t
W k
(cid:2)
(cid:4)
(cid:3)
W k+1
h,t (w) = W 0
h,t(w) +
Bj,
(1)
Tj
0
Πj∈hp(Πh)
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:27:56 UTC from IEEE Xplore.  Restrictions apply. 
457
(cid:4)(cid:5)(cid:10)(cid:1)(cid:3)(cid:11)
(cid:1)(cid:3)
(cid:1)(cid:7)(cid:4)(cid:8)(cid:1)
(cid:7)
Indirect
Interference
(cid:6)(cid:5)(cid:2)(cid:6)(cid:9)(cid:3)(cid:5)
Arrive
Arrive
Deadline miss
(cid:6)(cid:5)(cid:2)(cid:6)(cid:9)(cid:2)(cid:3)(cid:5)
Time
Priority inversion
(cid:8)
Fig. 8: A priority inversion by Π(i) at t can indirectly interfere
with partition Πh that will arrive in the future (at rh,t + Th).
where (cid:4)x(cid:5)0 = max((cid:4)x(cid:5), 0). Here, the summand represents
the interference from the higher-priority partitions (i.e., (c) in
Fig. 7). W 0
h,t(w), i.e., the initial busy interval, is comprised of
(a), (b), and (d) in Fig. 7:
W 0
h,t(w) = w + Bh(t) +
Bj(t).
(2)
(cid:2)
Πj∈hp(Πh)
(cid:5)
Using the iterative procedure, Wh,t(w) is computed as follows:
Wh,t(w) =
h,t (w) = W k
h,t(w)
W k+1
∞
if converging for some k
if not converging
.
It is the worst-case (i.e., longest possible) level-Πh busy interval
that starts with an execution of size w at t by a lower-
priority partition. The scheduler tests if Πh would still meet its
deadline with the priority inversion in addition to the maximum
interference from hp(Πh) by checking if the worst-case busy
interval ends by its deadline, i.e., the next replenishment time:
t + Wh,t(w) ≤ rh,t + Th.
(3)
Note that the busy-interval analysis presented above assumes no
synchronization between partitions (e.g., for overt inter-partition
communication as explained in Sec. II).
b) Indirect interference on inactive Πh: The analysis
above assumes that Πh is active at time t. One may overlook the
case when Πh is inactive, concluding that a priority inversion
at present would not affect the future execution of Πh; thus,
no schedulability test for the inactive Πh is needed. However,
the scheduler also needs to test if the upcoming execution of
Πh, shown in Fig. 8, who is not active at present but would
arrive at the next replenishment time rh,t + Th at the earliest,
would meet its upcoming deadline rh,t + 2Th. The reason is
that a priority inversion at time t by a lower-priority partition
can indirectly interfere with the future execution of Πh: higher-
priority partition(s), i.e., hp(Πh), are delayed by the priority
inversion from t to t + w, which creates a cascading delay
that interferes with the execution of Πh that will arrive in
the future. Hence, the schedulability test should be performed
against inactive partitions as well. For such a case, Eq. (1) can
be simply extended, as shown in Algorithm 3, to include the
upcoming execution of Πh as another higher-priority partition
(i.e., part of (c) in Fig. 7). If the busy interval ends before Πh’s
upcoming arrival at rh,t + Th, the new term would be zero.
c) Search complexity: The schedulability test needs to
be performed at most once for each partition in the system.
Thus the search complexity is O(|Π|). This can be explained
better with an example shown in Fig. 9. Suppose there are 9
(cid:17)(cid:2)
(cid:17)(cid:3)
(cid:23)(cid:1)(cid:22)(cid:1)(cid:1)
(cid:17)(cid:4) (cid:17)(cid:5) (cid:17)(cid:6) (cid:17)(cid:7) (cid:17)(cid:8) (cid:17)(cid:9) (cid:17)(cid:10)
(cid:17)(cid:12)(cid:2)(cid:13)
(cid:17)(cid:12)(cid:5)(cid:13)
(cid:17)(cid:12)(cid:3)(cid:13)(cid:17)(cid:12)(cid:4)(cid:13)
(cid:18)(cid:19)(cid:21)(cid:20)
(cid:16)(cid:1)(cid:5)(cid:8)(cid:7)(cid:6)(cid:13)(cid:10)(cid:3)(cid:4)(cid:9)(cid:10)(cid:9)(cid:12)(cid:14)(cid:2)(cid:7)(cid:11)(cid:12)(cid:24)(cid:17)(cid:11)(cid:15)(cid:12)(cid:25)
Fig. 9: For Π(i)’s candidacy test, we only need to check those
Πh ∈ hp(Π(i)) that have not been examined when testing
Π(i−1).
partitions in the system, and Lt = (Π3, Π5, Π6, Π9) are active
at present. First, Π(1) = Π3, and hence no schedulability test
is performed because, as explained earlier, its execution does
not make a priority inversion. Now, for Π(2) = Π5, we need
to check if its execution for a length of w could make Π(1) =
Π3 potentially unschedulable. We also need to check for Π4,
which is inactive, due to a possibility of the indirect interference
explained above. For Π(3) = Π6, we do not need to test for Π3
and Π4 again because if they are schedulable in the presence
of Π(2)’s priority inversion, they are still schedulable when it
is made by Π(3). That is, from their point of view, it does not
matter who is creating a priority inversion, which is why the
analyses in Eq. (1) and Eq. (2) depend only on the size of a
priority inversion, w, not on who causes the priority inversion.
Hence, for each Π(i) we only need to consider those Πh ∈
hp(Π(i)) that have not been examined when testing Π(i−1).
2) Step 2 – Weighted random selection of partition: Once
a list of candidate partitions is found, the scheduler picks one
randomly as shown in Algorithm 1. One may pick a partition
1|LC|.
uniform randomly: each candidate has an equal chance of
Counter-intuitively, this can make a schedule less randomized.
Consider an example in Fig. 10 in which a selection is being
made between two partitions, LC = {Π1, Π2}, at
time t.
Ignoring the idling option, the probability of Π1 being selected
for t is 1/2. If another selection is made at t + 1, the probability
is again 1/2. Hence, the probability that Π1 would use up its
budget during [t, t + 2) is 1/4, which is high considering the
time until the deadline. Hence, it would likely ﬁnish too early.
In order to alleviate such biases, we propose a weighted
selection process that considers the remaining budget and time
until the deadline. Suppose a selection is made at time t. For
each candidate Πi ∈ LC, the scheduler computes the remaining
utilization:
ui,t = Bi(t)/(di,t − t),
where di,t is the deadline of Πi as of time t (i.e., the next replen-
ishment time), di,t = ri,t + Ti, as in Eq. (3). Then, each candi-
date is assigned a normalized weight ωi,t = ui,t
ux,t.
If the CPU can be idled, the option is assigned a weight of
ux,t. Then, the scheduler performs a weighted
1 − (cid:7)
Πx∈LC
Πx∈LC
(cid:6)(cid:7)
(cid:7)(cid:2)(cid:1)(cid:4)(cid:7)(cid:3)(cid:1)(cid:4)
(cid:7)(cid:2)(cid:1)(cid:4)(cid:9)(cid:8)(cid:10)(cid:2)(cid:3)
(cid:6)(cid:2)(cid:8) (cid:10)(cid:3)(cid:6)(cid:3)(cid:8) (cid:10)(cid:5)
(cid:7)(cid:3)(cid:1)(cid:4)(cid:9)(cid:8)(cid:10)(cid:2)(cid:4)
Next replenishment
Time
(cid:1)(cid:2)
(cid:1)(cid:3)
(cid:8)
Fig. 10: With uniform random selection, Π1 is likely to use up
its budget too early. Hence, it should be given a smaller weight
to decrease the chance of temporal locality.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:27:56 UTC from IEEE Xplore.  Restrictions apply. 
458
random selection based on the ωi,t values. This process can
be viewed as a type of lottery scheduling [31] with the ticket
allocation proportional to the remaining utilization.
Note that the weight reﬂects how urgent a partition is. That is,
the weight is higher if the remaining budget is larger and/or the
deadline is closer. The following theorem shows why assigning
weights inversely proportional to the remaining utilization can
actually increase the degree of temporal locality:
Theorem 1. Giving a higher weight to a partition with a lower
remaining utilization increases the degree of temporal locality.
Proof: Let us consider a 2-candidate situation, LC =
{Πj, Πk}, for time t and assume that uj,t > uk,t. Suppose Πk,
who has a smaller remaining utilization, is selected and runs
until t + 1. Hence, Bk(t + 1) = Bk(t)− 1. Then, the difference
in the remaining utilization between the two grows:
Bj(t)
dj,t − t = uj,t,
Bk(t)
dk,t − t = uk,t.
Bj(t + 1)
dj,t − t − 1
Bk(t + 1)
dk,t − t − 1
dj,t − t − 1
Bk(t) − 1
dk,t − t − 1
Because uj,t+1−uk,t+1 > uj,t−uk,t, the chance that Πk would
be selected again for time t + 1 becomes larger.
uk,t+1 =
uj,t+1 =
=
=
>
<
Bj(t)
Hence, higher weights should be given to those partitions
with larger remaining utilization. This is because the weight of
a partition decreases (resp. increases) if it is selected (resp. not
selected), which steers the weights of candidate partitions in
the direction towards being leveled as time proceeds. There-
fore, one’s budget consumption is likely to spread across a
wide range, and accordingly, the chance of premature budget
exhaustion, thus temporal locality, is reduced. As will be shown
in Sec. V, the weighted random selection further increases the
level of randomness in a partition schedule. The effect is more
profound especially when the system is lightly loaded, which
is when an adversary can achieve a higher communication
accuracy, as discussed in Sec. III.
B. Schedulability Analysis
The schedulability of real-time tasks is tightly dependent on
a particular choice of partition-local scheduling policy as well
as budget replenishment policy. Hence, we base our analysis
on the ﬁxed-priority preemptive local task scheduling [32] on
which our implementation is based. Let us ﬁrst consider the
case without TIMEDICE. The worst-case response time of each
task can be computed by the analysis in [33]. In a nutshell,
the worst-case situation for task τi,j of partition Πi happens
when (a) it arrives, with all the higher-priority tasks in the
same partition, when Πi’s budget has been depleted as soon as
possible; (b) their subsequent invocations arrive as frequently as
possible; and (c) Πi’s budget supply is delayed as maximally
as possible by higher-priority partitions. That is, the analysis