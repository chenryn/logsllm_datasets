ric: an approximate graph edit distance.
4.1 Graph Edit Distance
The edit distance between two graphs measures their similarity
in terms of the number of edit operations required to transform one
graph to the other. For the purpose of identifying malware vari-
ants, the graph-edit distance effectively captures the amount of ef-
fort needed to convert one program to another at the function-call
graph level, and thus forms an intuitively appealing metric. Given
any two graphs, we deﬁne the following two elementary operations
to transform one graph to another. Vertex-edit operations includ-
ing: σR, relabel a vertex; σIV , insert an isolated vertex; and σRV ,
remove an isolated vertex. Edge-edit operations including: σIE,
insert an edge and σRE, remove an edge.
An edit path Pg,h between graphs g and h is deﬁned as a se-
quence (σ1, σ2, . . . , σn) of elementary operations such that h =
σn(σn−1(. . . σ1(g) . . . )). To quantify this similarity, a cost is as-
signed to each edit operation: c : σR, σIV , σRV , σIE, σRE → R.
Then, the cost of an edit path is the sum of the costs of all the
constituent edit operations, i.e., P = (σ1, σ2, . . . , σn) as c(P ) =
Σn
i=1c(σi). The edit distance between two graphs is deﬁned as
the minimum cost of all edit paths between them, i.e., ed(g, h) =
min c(Pg,h). In SMIT, we assign a unit cost to each edit operation.
4.2 Approximating Graph-Edit Distance Us-
ing Graph Matching
The main drawback of graph-edit distance is its computational
complexity, which is exponential in the number of nodes of the
graphs. Thus, application of graph-edit distance is feasible only for
relatively small graphs, say those with fewer than 50 nodes. Be-
cause the number of nodes in malware graphs is signiﬁcantly larger,
we develop heuristic algorithms that can closely approximate the
ideal graph-edit distance using graph matching techniques.
S
g and V
= Vh
∗
h
S
∗
g = Vg
To match two unequal-size graphs g and h, we extend the vertex
set of each graph as: V
h, where g
and h are sets of dummy nodes created to account for insertions
and deletions. In other words, a match from u ∈ Vg to a dummy
node implies the deletion of u from graph g and vice versa. We
set |g| = |Vh| and |h| = |Vg| so that the extended graph has
the same number of nodes. We denote the extended graph for g as
g , Eg,Lg, Lg ∪ {g}) and deﬁne the graph matching as:
∗ = (V
∗
g
Deﬁnition (Graph Matching) A matching between two graphs g
g →
∗
and h is a bijective function φ() between two vertex sets, φ : V
g such that ∀v ∈ V
∗
h
Given a graph matching φ between two graphs g and h, the dis-
tance (edit cost) between them can be computed by considering
mismatched nodes and edges with the following algorithm.
g , φ(v) ∈ V
∗
∗
h .
1. Let CE represent the number of edges that are mapped from
one graph to the other. Speciﬁcally, for any edge (i, j) ∈ Eg,
if (φ(i), φ(j)) ∈ Eh, then the matching preserves the edge
(i, j) and the counter CE is incremented by 1.
2. EdgeCost = (|Eg| − CE) × c(σRE) + (|Eh| − CE) ×
c(σIE). Since we assign unit cost to each edit operation,
EdgeCost = |Eg| + |Eh| − 2 × CE.
3. For any node in graph g that is matched to a dummy node in
h, we add c(σRV ) to the N odeCost to penalize for deleting
613the node. Similarly, when a node in graph h is matched with
a dummy node in g, we add c(σIV ) to the N odeCost.
4. For any two matched nodes, we add c(σR) to the N odeCost
if they have different labels, i.e., the relabeling cost.
5. Edit distance under φ is: edφ(g, h) = N odeCost+EdgeCost.
Because graph-edit distance is deﬁned as the minimum edit cost
between two graphs, the above algorithm casts the problem of com-
puting graph-edit distance into ﬁnding a function φ that minimizes
the total matching cost, i.e., a minimum-cost bipartite matching
problem, where each of the two sides of the bipartite graph cor-
responds to nodes from one of the two input graphs. An opti-
mal (minimum-cost) bipartite matching can be found in polynomial
time (O(n3)) by using the well-known Hungarian algorithm [21].
To further reduce the performance overhead of the Hungarian algo-
rithm, SMIT employs various optimizations that exploit properties
of the malware programs underlying their function-call graphs.
4.3 Optimizations
4.3.1 Exploiting Instruction-Level Information
Since the complexity of the Hungarian algorithm depends on
the number of nodes in the input graphs, the ﬁrst optimization
aims to reduce the number of nodes in the two input graphs that
need to be matched by removing those nodes that can be matched
through other cheaper means. Speciﬁcally, SMIT uses each func-
tion’s mnemonic sequence, CRC value of its mnemonic sequence
and symbolic name to quickly determine if a function in one input
graph matches another function in the other input graph, and com-
pute a common function set C = {v : v ∈ Vg
Vh} containing:
• Static library functions or dynamically-imported functions
and that share the same symbolic names in two input graphs;
• Functions that have the same mnemonic sequence and thus
• Functions that have similar mnemonic sequences. We com-
pute the edit distance between the mnemonic sequences of
two functions, and consider them a match when the distance
is below 15% of the length of the shorter mnemonic sequence
of the two, where the threshold 15% is chosen empirically.
the same CRC value of their mnemonic sequence; and
T
h
T
g = Vg−C and V r
Vh} atomic functions and let V r
To further decrease the number of nodes to which the Hungar-
ian algorithm needs to be applied, we apply a neighborhood-driven
algorithm [8] that exploits the matched neighbor information as-
sociated with functions. Let’s call the functions in C = {v : v ∈
= Vh−C
Vg
denote the sets of the remaining functions in g and h that are not yet
matched. A call-sequence signature for each remaining function is
a sequence of calls to atomic functions in this function. If the call-
sequence signatures of two functions f1 ∈ V r
h are
identical, we generate a match between f1 and f2 because they are
likely very similar or the same. Whenever a new match between
two local functions is found, we move them from V r
h to the
common function set C, and repeat the algorithm until it yields no
additional matches. At the end of the process we apply the Hungar-
ian algorithm to the remaining V r
h . For malware variants
from the same family, this optimization can match over 90% of
functions. On the other hand, the number of matched functions for
malware from different families is often below 20, most of which
are shared library functions.
g and f2 ∈ V r
g and V r
g and V r
4.3.2 Bipartite Graph Matching
The problem of ﬁnding a min-cost bipartite graph matching can
be solved in polynomial-time using the Hungarian algorithm [21].
Once the lowest-cost match is found, it can be used to create an
edit path and compute an estimate of the true edit distance (Section
4.2). Note that, although the Hungarian algorithm is optimal, the
edit-distance result returned by the match function φ that the algo-
rithm ﬁnds is only suboptimal [21], because the cost matrix used to
search for the optimal node assignment is computed without global
knowledge (to be elaborated). To mitigate this problem, we develop
an optimized Hungarian algorithm that biases the matching process
towards the neighboring functions of already-matched functions.
S
S
| and |h| = |V r
The algorithm ﬁrst constructs a complete bipartite graph with
vertex classes X = V r
g and Y = V r
h, where g and h
are sets of dummy nodes with |g| = |V r
g |. In
g
h
h
this bipartite graph, each edge is assigned a weight corresponding
to an estimate of the cost of mapping a vertex x ∈ X to a vertex
y ∈ Y . The choice of weights for the edges of the bipartite graph is
a vital component of the algorithm, as well-assigned weights that
are closer to the real cost will result in a near-optimal edit path,
and thus, the Hungarian estimate will more closely approximate
the true edit distance. Assume the ﬁrst graph gr has size n, and
the second graph hr has size m, we form an (m + n) × (m + n)
cost matrix. In the top left we have an n × m sub-matrix giving
the costs of matching a real node in g to a real node in h. In the
bottom right is an m × n zero sub-matrix, representing the costs
of associating a dummy node with another dummy node. Finally,
the off-diagonal square sub-matrices give the cost of pairing a real
node from a graph to a dummy node from the other graph (thereby
deleting it). On the diagonal, these matrices store the cost of delet-
ing a node and all its incident edges (both In and Out). We set
all non-diagonal components of these matrices to ∞ to ensure that
each real node is associated with a unique dummy node.
In [28], the cost of matching any two real nodes was taken simply
as the relabeling cost. To ﬁnd a better estimate of the true edit
cost, we improve the algorithm by considering the edges as well.
Speciﬁcally, the cost estimate, Ci,j, of matching node i to node j,
is the sum of the Relabeling Cost and the Neighborhood Cost,
where the latter is calculated from the difference between i and j’s
adjacent nodes. This introduces structural information by giving a
lower-bound for the edit cost of matching the neighbors of i and j.
1. Relabeling Cost: If the label of node i is not the same as the
label of node j, we set Ci,j to be the relabeling cost (σR).
2. Outgoing Neighborhood Cost: For any graph g and node i ∈
(i) ≡ {Lg(k)|(i, k)} ∈ Eg. Then, the outgoing
Vg, N g
neighborhood cost of matching node i to node j ∈ Vh is
|N g
(j)| to Ci,j.
3. Incoming Neighborhood Cost is similarly deﬁned with the
(j)| − 2 × |N g
(i)| + |N h
(i) ∩ N h
Out
Out
Out
Out
Out
incoming edges.
The cost computed from the above algorithm is a lower-bound of
the true edit cost for the following reasons. As mentioned in Sec-
tion 3, due to lack of symbolic information for all local functions
written by malware writers, we assign the same label to those func-
tions. As a result, when computing the estimated matching cost
between i and j, any local functions in i’s and j’s neighborhood
are conservatively considered matched (i.e., incurring no matching
cost). However, in the ﬁnal matching function φ (found by apply-
ing the Hungarian algorithm on the cost matrix), these two neighbor
nodes can be unrelated, in which case, the true edit cost between i
and j is higher than the estimate. In other words, because the cost
matrix is predetermined, the algorithm will only be able to consider
the local structure of the nodes without any information about the
matching. This lack of global knowledge when computing the cost
matrix leads to the sub-optimality of the resulting edit distance as
calculated by the algorithm in Section 4.2, even though the Hun-
garian algorithm by itself is optimal in the sense that it ﬁnds the
min-cost matching according to the pre-determined cost matrix. To
614alleviate this problem, in the next subsection, we present our im-
proved Hungarian algorithm that actively exploits the structural in-
formation of already-matched nodes as the algorithm progresses.
4.3.3 Neighbor-Biased Hungarian Algorithm
One drawback of the standard bipartite matching approach to
computing the graph-edit distance is that it assumes a ﬁxed cost of
matching two function nodes. However, as observed in [14], when
two nodes are matched, their neighbors are also likely matched,
because if more neighbors of a node are matched with those of an-
other node, the edge-edit cost of matching these two nodes will de-
crease (thus reducing the real edit cost). Based on this intuition, we
develop a modiﬁed Hungarian algorithm that adaptively biases the
order of matching towards those pairs of nodes whose neighboring
nodes have already been matched.
Given two malware call graphs g and h, we ﬁrst ﬁnd the initial
set of matched functions (Section 4.3.1). For each matched func-
tion f, we decrease the cost (in the cost matrix) of matching all the
unmatched neighbors of function f in g with their counterparts in
h by a predeﬁned percentage. Then, the Hungarian algorithm is
applied to the remaining graphs gr and hr with the updated cost
matrix. In each iteration of the algorithm, whenever two functions,
for instance (u, v), are chosen to be matched, the costs of matching
their unmatched neighbors in the cost matrix are similarly lowered,
thus increasing their chances of being matched later by the algo-
rithm. The procedure repeats itself until a complete match is found
in the bipartite graph. As an additional optimization, whenever
(u, v) is selected to be matched, the amount of cost reduction for
their unmatched neighboring functions is positively proportional to
the matching quality of (u, v), deﬁned as the percentage difference
between the mnemonic sequences of (u, v). Intuitively, the extent
to which the Hungarian algorithm is biased toward the neighbors
of a matched node pair is proportional to the degree to which they
are considered matched. Due to space limitation, we refer inter-
ested readers to our extended technical report [16] for the detailed
pseudocode of the algorithm.
The above algorithm generates the cost-minimizing matching
between function nodes φ : Vg ∪ g → Vh ∪ h, from which the
edit-path cost (denoted as edφ(g, h) under φ) can be calculated,
which is a close approximation to the true edit distance. Note that
edφ(g, h) gives the cost of a particular edit path from g to h. The
minimality of edit distance across all edit paths ensures that the dis-
tance from the Hungarian method is an upper bound on the edit dis-
tance. That is, for any two graphs g and h, ed(g, h) ≤ edφ(g, h).
5. MULTI-RESOLUTION INDEXING
5.1 Overview
For the purpose of identifying malware variants, it is not neces-
sary to pinpoint the exact nearest neighbor for a new malware ﬁle.
As long as one can identify a neighbor that is close enough to the
new ﬁle, one can “convict” it. For scalability to a large database,
SMIT exploits this latitude and incorporates a multi-resolution in-
dexing technique that makes a good balance between pruning efﬁ-
ciency and search effectiveness.
Conventional indexing methods decompose a database into parti-
tions and organize them hierarchically, so that a search can focus on
a subset of these partitions at each level of the hierarchy, thus reduc-
ing the total number of database items that it needs to touch. These
indexing methods are inadequate for SMIT for two reasons. First,
SMIT requires an indexing scheme that supports nearest-neighbor
search, rather than exact search that conventional methods are de-
signed for. Second, since computation of graph similarity is ex-
pensive, SMIT must minimize the number of such computations.
Figure 1: Multi-resolution indexing structure.
For instance, our evaluation shows that a modern desktop PC can
perform an average of 20 graph-similarity computations per second
for our malware set. At this performance level, even if an indexing
scheme could reduce the number of graphs that a search needs to
touch, to less than 10% of the database, it will still take hours to
answer a single query for a database of 1,000,000 malware graphs.
To address the ﬁrst problem, SMIT organizes the input malware
graph database using the optimistic Vantage Point Tree (VPT), which
is designed for nearest-neighbor search and can exploit the fact that
sufﬁciently near neighbors are usually good enough. To solve the
second problem, SMIT uses a two-level indexing scheme, where
the ﬁrst level is a standard B+-tree index based on coarse-grained
malware features that can be computed inexpensively and that can
effectively prune irrelevant parts of the malware database. Graphs
associated within each leaf node of the B+-tree index are organized
with a second-level index, i.e., the VPT Tree, which uses a more ac-
curate but computationally more expensive graph-similarity func-
tion to pinpoint the most similar neighbors. The two-level index-
ing (Figure 1) in SMIT is an instance of multi-resolution indexing
because similarity functions with different accuracy and computa-