title:PGPatch: Policy-Guided Logic Bug Patching for Robotic Vehicles
author:Hyungsub Kim and
Muslum Ozgur Ozmen and
Z. Berkay Celik and
Antonio Bianchi and
Dongyan Xu
7
6
5
3
3
8
9
.
2
2
0
2
.
4
1
2
6
4
P
S
/
9
0
1
1
.
0
1
:
I
O
D
|
E
E
E
I
2
2
0
2
©
0
0
.
1
3
$
/
2
2
/
9
-
6
1
3
1
-
4
5
6
6
-
1
-
8
7
9
|
)
P
S
(
y
c
a
v
i
r
P
d
n
a
y
t
i
r
u
c
e
S
n
o
m
u
i
s
o
p
m
y
S
E
E
E
I
2
2
0
2
2022 IEEE Symposium on Security and Privacy (SP)
PGPATCH: Policy-Guided Logic Bug Patching
for Robotic Vehicles
Hyungsub Kim, Muslum Ozgur Ozmen, Z. Berkay Celik, Antonio Bianchi, and Dongyan Xu
Purdue University
{kim2956, mozmen, zcelik, antoniob, dxu}@purdue.edu
Abstract—Automated program repair (APR) methods aim to
identify patches for a given bug and apply them with minimal
human intervention. To date, existing APR approaches focus on
repairing software bugs, such as memory safety bugs. However,
our analysis of popular robotic vehicle (RV) control software
shows that most of their bugs are not memory bugs but rather
logic bugs. These bugs, while not causing software crashes, can
cause an RV to reach an undesired physical state (e.g., hitting
the ground).
To ﬁx these logic bugs, we introduce PGPATCH, a policy-
guided program repair framework for RV control programs,
which identiﬁes the correct patch for a given logic bug and
applies it without human intervention. PGPATCH takes, as input,
existing or new logic formulas used to discover logic bugs. It
then leverages the formulas using a dedicated dynamic analysis
to classify the previously known logic bugs into a patch type. It
next uses a customized algorithm, based on the identiﬁed patch
type and violated formula, to produce a source code patch as
output. Lastly, it creates repeatable tests to verify the patch’s
completeness, ensuring that the patch is correct and does not
degrade the RV’s performance. We evaluate PGPATCH on selected
bug cases from three popular RV control software and ﬁnd that it
correctly ﬁxes 258 out of 297 logic bugs (86.9%). We additionally
recruit 18 experienced RV developers and users and conduct a
user study that demonstrates how using PGPATCH makes ﬁxing
bugs in RV software signiﬁcantly quicker and less error-prone.
I. INTRODUCTION
Patching security vulnerabilities in a timely manner is crucial
to prevent attackers from compromising software. Yet, recent
works have shown that creating patches on time is challenging
due to the required manual effort [33], [75]. For this reason,
there has been an increasing interest in automated program
repair (APR) to create patches without human intervention.
There are two broad types of APR approaches. First, test
suite-based methods generate patches for bugs that cause
outputs to deviate from developers’ expectations [20], [27],
[40], [49], [54], [56], [79], [80]. Their patch localization
and generation algorithms require users to input passing and
failing test cases that deﬁne the program’s expected outputs
corresponding to certain inputs (i.e., test suites) [39], [46].
Second, speciﬁcation-based APR approaches ﬁx bugs through
speciﬁcations that deﬁne functional requirements in the form
of natural language documents or formal logic formulas [5],
[15], [34], [37], [38], [48], [82].
In this paper, we consider logic bugs in robotic vehicle (RV)
control software, which are bugs that cause deviations in the
RV’s physical behavior from the developer’s expectations but
do not cause the program to stop execution [32]. The reason is
that our analysis of 1,257 existing bugs (from 2014 to 2021) in
two popular RV control programs (ArduPilot [8] and PX4 [64])
indicates 98.2% of them are logic bugs, showing the prevalence
of logic bugs in RV software. Logic bugs in RVs mainly stem
from misimplementations and design ﬂaws. For example, PX4’s
documentation states that “fail-safe mode must be triggered
when GPS loss is detected” [28]. However, PX4 fails to trigger
the fail-safe mode under the following three conditions: (1)
the COM_POS_FS_DELAY conﬁguration parameter has a negative
value, (2) the RV is in the CIRCLE ﬂight mode, and (3) the RV
passes through an area where the GPS signal is not available.
This logic bug leads to unsafe states, which causes the RV to
ﬂoat unpredictably, potentially crashing into an obstacle.
Promptly ﬁxing bugs in RVs is critical because an attacker
can stealthily exploit such logic bugs to cause undesired
behaviors and physical damage [17], [41]–[43]. Yet, patching
logic bugs in RVs is more challenging than ﬁxing bugs in
traditional software for two main reasons. First, the “correct
behavior” of RVs depends not only on the “cyber space”
(i.e., how RVs behave according to inputs given to control
software) but also on the “physical space” (i.e., the physical
environment in which they operate). For example, consider
that a user gives an RV input to make the RV move forward.
From a traditional software point of view, the RV’s correct
behavior is to move forward because the software must show
consistent behaviors according to program inputs. Yet, the RV
may show different correct behaviors based on the current
physical environment: (i) moving backward if the RV is near
an obstacle, (ii) landing on the ground if the RV loses GPS
signals, and (iii) staying in a stable position if a strong wind
blows. Second, the “input space” and “output space” of RV
software are much larger than those of traditional software,
given the amount of data that an RV receives and processes
at any given point in time. This data encompasses periodic
measurements from multiple sensors as well as commands
given by a ground control station (GCS).
Unfortunately, existing APR approaches do not address
these challenges. In fact, test suite-based methods fail to ﬁx
logic bugs in RV control programs because the correctness of
patches depends on the test suite’s completeness. Achieving
completeness is challenging due to the RV software’s large
input and output space, as shown by previous work [45], [52],
[71]. Further, speciﬁcation-based approaches cannot ﬁx logic
bugs since they mainly focus on memory bugs [34], [48], or
they do not create code-level patches from speciﬁcations that
deﬁne the software’s correct behavior [5], [15], [37], [38], [82].
To address these limitations, in this paper, we introduce
© 2022, Hyungsub Kim. Under license to IEEE.
DOI 10.1109/SP46214.2022.00109
1826
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:39:29 UTC from IEEE Xplore.  Restrictions apply. 
PGPATCH, a policy-guided program repair framework for RV
control programs, which generates patches for a given logic
bug and applies them without human intervention. PGPATCH is
composed of four interconnected components: (1) Preprocessor,
(2) Patch Type Analyzer, (3) Patch Generator, and (4) Patch
Veriﬁer. First, the Preprocessor takes an input that triggers the
bug and a formula written in the PGPATCH policy language
(PPL) which deﬁnes RVs’ expected operations. This component
checks the validity of the formula given by users. We note that
PGPATCH requires only a single test case triggering the bug
(i.e., one failing test case) while test suite-based APR methods
require a complete set of test cases, including both failing and
passing cases. Second, to handle diverse types of logic bugs in
RVs, the Patch Type Analyzer ﬁnds the most appropriate patch
type to ﬁx the speciﬁc logic bug. Third, the Patch Generator
component ﬁnds the proper patch location for the targeted bug
and creates a patch. PGPATCH ﬁrst identiﬁes a patch location
through the PPL formula and pattern matching. It then creates
a patch based on the formula, identiﬁed patch type, and patch
location. Lastly, the Patch Veriﬁer inserts the created patch into
the target source code and compiles the patched code. It then
tests if the patch ﬁxes the bug and conﬁrms that the patch does
not break the RV’s functionality or degrade its performance.
We evaluate PGPATCH on ArduPilot [8], PX4 [64], and
Paparazzi [59], the three most popular ﬂight control software
used in many commodity RVs. PGPATCH correctly ﬁxes 258
out of 297 logic bugs (86.9%) requiring, on average, 12.5
minutes to create one patch. Further, we conduct a user study
to compare the effort required by RV software developers and
users to build PPL formulas with their effort to create manual
code-level patches. Our user study shows that building PPL
formulas is easier and less error-prone compared to manually
patching logic bugs. We make the following contributions:
• Behavior-aware Patch Generation. We introduce
PGPATCH, a policy-guided APR framework for RV
control programs, which leverages existing or new logic
formulas for patch localization and generation via a com-
bination of static and dynamic analysis. PGPATCH also
creates repeatable tests to validate the patch’s correctness.
• Evaluation with Real-world RV Software. We applied
PGPATCH to the three most popular RV control software
packages. PGPATCH generated correct patches for 258 of
the 297 previously known bug cases (86.9%).
• User Study. We recruited experienced RV developers and
users and conducted a user study that demonstrates the
usefulness of PGPATCH for patching bugs compared to
manual patching.
To foster research on this topic, we make PGPATCH publicly
available (https://github.com/purseclab/PGPatch).
Ethical Considerations and Responsible Disclosure. We
responsibly disclosed any previously unknown bug discovered
in this paper to the affected RV software developers. In our
user study, we avoid collecting any personally identiﬁable
information (PII). Our study was reviewed by our institution’s
IRB and considered IRB exempt.
: : =    | 
 |
|
i f f  ,
: : = S | P | E | V | F
: : = ` i s '
` i s
` i s g r e a t e r
` i s
| ` i s not '
than '
l e s s
l e s s
|
: : = S | P | V | F |
| ` f a l s e '
i f  ,
t h e n 
t h e n 
| ` i s more than '
|
t h a n o r e q u a l
to '
t h a n o r e q u a l
to '
|
` t r u e '
` d i s a b l e d '
` o f f '
 : : = `and '
| ` e r r o r '
| ` e n a b l e d '
| `on '
|
|
|  | 
| `or '
Listing 1: PGPATCH policy language (PPL) syntax in BNF.
II. PRELIMINARIES
Logic Bugs and Adversarial Exploitation in RVs. In this
paper, we use the term “logic bugs” to refer to bugs that
cause a program to operate incorrectly, leading to undesired
physical behavior, without causing a program crash or memory
corruption. Starting from this deﬁnition, we consider buffer
overﬂows, null pointer dereferences, and divisions by zero
as non-logic bugs [41], [43]. Logic bugs are caused by
developers incorrectly designing or implementing software
components. The developers’ mistakes might occur for various
reasons, including but not limited to unexpected environmental
conditions (e.g., strong wind and signiﬁcant sensor noise) and
copying-and-pasting a buggy code snippet [16], [19], [72].
We assume that an adversary can exploit a logic bug to
stealthily disrupt an RV’s normal behaviors. Particularly, the
RV’s three types of inputs (conﬁguration parameters, user com-
mands, and environmental factors) can be leveraged to trigger
a logic bug. The adversary can (1) override the conﬁguration
parameter values, (2) replay or spoof user commands, and (3)
change environmental conditions or wait for suitable conditions
before conducting attacks. The adversary can conduct input
manipulation by exploiting known vulnerabilities in the RV’s
communication protocol and sensors [44], [73], [81].
PGPATCH Policy Language (PPL). A recent work on
logic bug-ﬁnding (PGFuzz [41]) has created linear temporal
logic (LTL) formulas for discovering logic bugs. Particularly,
users identify the RVs’ correct behaviors through ofﬁcial
documentations [11], [59], [68] and formally represent them
with LTL templates [41], [82]. However, deﬁning LTL formulas
requires users to learn about syntax and rules of temporal logic.
To reduce the difﬁculty of LTL formulas, we introduce PPL
in BNF notation, as shown in Listing 1. In PPL formulas,
the “term” can be formed over an RV’s physical state (S),
conﬁguration parameter (P), environmental factor (E), the name
of a variable (V), and the name of a function (F).
Additionally, we design two PPL templates: (i) T1: “[term]
[verb] [value] (conjunction)” and (ii) T2: “if / iff [term] [verb]
[value] (conjunction), then [term] [verb] [value] (conjunction)”.
Users can use these formula templates to easily and quickly
build new formulas. For example, given a policy in natural
language stating that “the engine must be turned on”, users
can express the policy with T1 template: “engine is on”. Here,
“engine”, “is”, and “on” are matched with “term”, “verb”, and
“value” keywords. These three types of keywords compose
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:39:29 UTC from IEEE Xplore.  Restrictions apply. 
21827
1
2
3
4
5
// Get a time delay to trigger position fail-safe
param_get(param_find("COM_POS_FS_DELAY"), &val);
// Force the valid range of the parameter
posctl_nav_loss_delay = math::constrain(val * sec_to_usec,
POSVEL_PROBATION_MIN, POSVEL_PROBATION_MAX);
Listing 2: GPS Fail-Safe Bug [41].
if (rover.g2.sailboat.sail_enabled()
&& !rover.g2.windvane.enabled()) {
1 bool AP_Arming_Rover::pre_arm_checks() {
2
3
4
5
printf("Sailing enabled with no WindVane");
return false;
Listing 3: Sailboat Pre-Arming Bug [1].
a proposition that
is mandatory to build a PPL formula.