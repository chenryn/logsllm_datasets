under the given levels of the factors, and (ii) the observations
obtained with the same value of SIZE but SNR=0 (again,
the baseline chunks). We used a threshold-based classiﬁer
and measured precision (P) and recall (R), accordingly. TA-
BLE V reports the results of the analysis when SNR=LOW
and VERB=MEDIUM, which corresponds to the middle row
of the box plots in Fig. 16. Similar ﬁndings have been
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:58:24 UTC from IEEE Xplore.  Restrictions apply. 
TABLE V: Precision (P), Recall (R) and threshold (Thd) for each classiﬁcation experiment (SNR=LOW, VERB=MEDIUM).
FP1LNR
SIZE
MEDIUM
P
LOW
R Thd
DICT
P
R Thd
(%)
0.75 0.75 3.47 0.94 0.93 4.66 0.97 0.97 5.81 0.90 0.87 2.75 0.95 0.95 3.46 0.97 0.97 3.94 0.82 0.82 4.01 0.92 0.92 5.45 0.92 0.92 6.31
25
0.89 0.88 3.47 0.98 0.98 4.99 0.97 0.97 5.81 0.96 0.95 3.26 0.97 0.97 3.80 0.98 0.98 4.40 0.97 0.97 4.14 0.98 0.98 5.79 0.95 0.95 6.72
50
0.94 0.93 3.74 0.98 0.98 4.99 0.97 0.97 5.81 0.98 0.98 3.36 0.97 0.97 3.80 0.98 0.98 4.40 0.97 0.97 4.45 0.98 0.98 5.79 0.98 0.98 7.21
75
100 0.96 0.95 3.85 0.98 0.98 4.99 0.97 0.97 5.81 0.98 0.98 3.36 0.97 0.97 3.80 0.98 0.98 4.40 0.97 0.97 4.45 0.98 0.98 5.79 0.98 0.98 7.21
LOW
R Thd
LOW
R Thd
R Thd
R Thd
R Thd
R Thd
R Thd
MEDIUM
HIGH
HIGH
P
HIGH
P
P
P
MN1PAN
SIZE
P
P
D02PAN
SIZE
MEDIUM
P
noted for the other levels of VERB (not reported here due
to space limitations). For example, when DICT=25% and
SIZE=LOW, P and R are 0.75 in FP1LNR and the threshold
Th is 3.47; in other words, assuming interesting the chunks
with log.entropy ≥3.47 allows catching the 75% of true
interesting chunks. Classiﬁcation improves signiﬁcantly when
DICT=50%, SNR=LOW and SIZE=LOW in FP1LNR, where
P=0.89 and R=0.88. When SIZE=MEDIUM the interesting
chunks are retained with P≥0.92 and R≥0.92 in all the log
sources even when DICT=25% (i.e., only one-quarter of the
terms in the entry is unknown).
TABLE V allows making several
inferences. For ex-
ample, P and R are signiﬁcantly high regardless the level
of DICT when SIZE≥MEDIUM (e.g.,
the worst case is
P=R=0.92, which is noted in D02PAN with SIZE=MEDIUM
and DICT=25%). When SIZE=LOW, DICT should be around
50% in order to achieve values of P and R close (i.e., FP1LNR)
or bigger than (i.e., MN1PAN, D02PAN) 0.9. An increase of
DICT from 25% to 50% makes P and R to improve by about
0.15 when SIZE=LOW. Overall the above-discussed ﬁndings
have been obtained with SNR=LOW, which means exactly one
interesting entry out of an entire chunk when SIZE=LOW,
i.e., the worst case. Analysis shows that the entropy-based
method is able to accurately retain even those chunks that
contain one interesting entry, which is half-similar to a baseline
entry. In this respect, our method may be a viable solution to
supplement the analysis of textual logs within current SIEMs.
VIII. THREATS TO VALIDITY
As in any empirical analysis,
there might be concerns
regarding the threats to reproducibility, validity and general-
ization of the results. These concerns are further exacerbated
when the data sources consist of unstructured textual events,
such as the datasets addressed in this work. The ﬁndings
discussed by our paper might be subject to threats to validity,
which are described and mitigated as follows.
Validation has been done by generating synthetic data
under controlled conditions, rather than real incidents. There
are several challenges in obtaining labeled incident data from
production settings, such as costs, the strong dynamic nature
of the incidents, lack of instances for many incident categories,
and the time it takes to collect naturally-occurring incidents.
This is further exacerbated in critical industrial systems. Our
work makes the implicit assumption that interesting activity is
much more infrequent than behavioral baseline data. This is
commonly done in any unsupervised problem [37].
Our analysis is based on real-world datasets. Please note
that many past studies on ﬁltering have adopted DARPA 98/99,
such as [12], [13], [14]. On the contrary, we used logs from a
critical information system and face all the inherent challenges
in dealing with production unstructured data. The data have
been generated by emulating real workload conditions, which
have been supplied by the industry provider. The analysis
involved direct communication with the ATC operations team
to understand and to gain feedbacks on the system dynamics.
In this paper we adopted consolidated and well-documented
data analysis techniques; experiments have been repeated sev-
eral times with the aim of obtaining statistically-signiﬁcant
conclusions.
We are aware that the ﬁndings of our analysis have been
inferred from one system; however, this is the case of many
other studies in the security area, such as [6], [16], [38]. The re-
sults presented by this paper are contextualized to our datasets.
Nevertheless, our ﬁndings, which are strongly supported by
data, contribute to establish new knowledge in an area, which
is still an open research ﬁeld. We strongly believe that, due
to the lack of empirical analysis and validation on production
datasets and real-world critical information systems, our results
are relevant to practitioners.
IX. CONCLUSION
This paper proposed a method to automatically measure
the occurrence of interesting activity within textual and het-
erogeneous runtime log streams. The method leverages the
log.entropy term weighting scheme, which makes no assump-
tions on the structure of the logs, allowing to deal with un-
structured text with no prior knowledge of interesting patterns.
The method has been implemented on the top of cutting-
edge stream data analytics technologies, i.e., Apache Storm
and Cassandra, and has been applied to a real-world Air
Trafﬁc Control information system. Measurements have been
done using the runtime logs generated by the system nodes.
Off-line experiments have been conducted to characterize the
system behavioral baseline, beforehand. Regular operations
and misuse conditions have been then emulated on the system.
The results show that the log.entropy measurements exhibited a
deviation from the system behavioral baseline upon the occur-
rence of interesting activity. More important, misuse affected
different logs, leading deviations of the log.entropy across the
nodes. Finally, we investigated the extent to what measure-
ments are impacted by the characteristics of the interesting
activity. Results indicate that interesting activity consisting of
only one log entry, can be discriminated at high precision and
recall even when it is half-similar to a baseline entry.
Future work will be devoted to explore the potential
of log.entropy-based measurements. We aim to evaluate the
proposed method on different systems as well as on different
security datasets, in order to understand limits and boundaries
of the method under different security scenarios. Moreover,
future effort will be also devoted to the integration of the
proposal into SIEM technologies, enabling them to deal with
unstructured data sources.
389
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:58:24 UTC from IEEE Xplore.  Restrictions apply. 
ACKNOWLEDGMENT
This work has been partially supported by CINI Cyber-
security National Laboratory within the project FilieraSicura:
Securing the Supply Chain of Domestic Critical Infrastructures
from Cyber Attacks (www.ﬁlierasicura.it) funded by CISCO
Systems Inc. and Leonardo SpA, and by the Italian Ministry
of Education, University and Research under the NAPOLI
FUTURA Start-up Project (PAC02L1_00161). The authors
would like to thank Marco Delle Curti for the valuable support
with the experimental testbed.
REFERENCES
[1] T. Mahmood and U. Afzal. Security analytics: Big data analytics for
cybersecurity: A review of trends, techniques and tools. In Information
Assurance (NCIA), 2013 2nd National Conference on, pages 129–134,
Dec 2013.
[2] A. A. Cardenas, P. K. Manadhata, and S. P. Rajan. Big data analytics
for security. IEEE Security & Privacy, 11(6):74–76, 2013.
[3] M. Cinque, D. Cotroneo, R. Della Corte, and A. Pecchia. Characterizing
direct monitoring techniques in software systems. IEEE Transactions
on Reliability, 65(4):1665–1681, Dec 2016.
[4] K. M. Kavanagh, O. Rochford, and T. Bussa. Magic quadrant for
security information and event management. Technical report, Gartner
Reasearch, 2016.
[5] A. A. Cardenas, P. K. Manadhata, and S. P. Rajan. Big data analytics
for security intelligence. Technical report, Cloud Security Alliance -
Big Data Working Group, 2013.
[6] A. Sharma, Z. Kalbarczyk, J. Barlow, and R. Iyer. Analysis of security
data from a large computing organization.
In The 41nd IEEE/IFIP
International Conference on Dependable Systems and Networks (DSN
2011), pages 506–517, 2011.
J. Cao, B. Yu, F. Dong, X. Zhu, and S. Xu. Entropy-based denial-
of-service attack detection in cloud data center. Concurrency and
Computation: Practice and Experience, 27(18):5623–5639, 2015.
[7]
[8] S. Yu, W. Zhou, R. Doss, and W. Jia. Traceback of ddos attacks
using entropy variations. IEEE Transactions on Parallel and Distributed
Systems, 22(3):412–425, March 2011.
[9] K. F. Hong, C. C. Chen, Y. T. Chiu, and K. S. Chou. Scalable
command and control detection in log data through uf-icf analysis. In
Security Technology (ICCST), 2015 International Carnahan Conference
on, pages 293–298, Sept 2015.
[10] Y. Liao and V. R. Vemuri. Using text categorization techniques for
the 11th USENIX Security
In Proceedings of
intrusion detection.
Symposium, 2002.
[11] A. D’Amico and K. Whitley. The real work of computer network
defense analysts. In VizSEC 2007, pages 19–37. Springer, 2008.
[12] G. P. Spathoulas and S. K. Katsikas. Reducing false positives in
intrusion detection systems. Computers & Security, 29(1):35–44, 2010.
[13] N. A. Bakar, B. Belaton, and A. Samsudin. False positives reduction
via intrusion alert quality framework.
In Networks, 2005. Jointly
held with the 2005 IEEE 7th Malaysia International Conference on
Communication, volume 1, pages 6–pp. IEEE, 2005.
[14] R. Alshammari, S. Sonamthiang, M. Teimouri, and D. Riordan. Using
neuro-fuzzy approach to reduce false positive alerts. In CNSR, pages
345–349. IEEE Computer Society, 2007.
[15] T. Pietraszek. Using adaptive alert classiﬁcation to reduce false positives
in intrusion detection. In Erland Jonsson, Alfonso Valdes, and Magnus
Almgren, editors, RAID, volume 3224 of Lecture Notes in Computer
Science, pages 102–124. Springer, 2004.
[16] X. Fu, J. Shi, and L. Xie. A novel data mining-based method for alert
reduction and analysis. Journal of Networks, 5(1), 2010.
[17] F. Valeur, G. Vigna, C. Kruegel, and R. A. Kemmerer. Comprehensive
approach to intrusion detection alert correlation. Dependable and Secure
Computing, IEEE Transactions on, 1(3):146–169, 2004.
[18] D. Cotroneo, A. Paudice, and A. Pecchia. Automated root cause
identiﬁcation of security alerts: Evaluation in a saas cloud. Future
Generation Computer Systems, 56:375 – 387, 2016.
[19] K. Julisch and M. Dacier. Mining intrusion detection alarms for
actionable knowledge.
In Proceedings of the Eighth ACM SIGKDD
International Conference on Knowledge Discovery and Data Mining,
KDD ’02, pages 366–375, New York, NY, USA, 2002. ACM.
[20] P. Giura and W. Wang. Using large scale distributed computing to unveil
advanced persistent threats. Science J, 1(3):93–105, 2012.
[21] X. Shu, J. Smiy, D. Daphne Yao, and H. Lin. Massive distributed and
parallel log analysis for organizational security. In 2013 IEEE Globecom
Workshops (GC Wkshps), pages 194–199, Dec 2013.
[22] D. Gonçalves, J. Bota, and M. Correia. Big data analytics for detecting
In Trustcom/BigDataSE/ISPA, 2015
host misbehavior in large logs.
IEEE, volume 1, pages 238–245, Aug 2015.
[23] T.-F. Yen, A. Oprea, K. Onarlioglu, T. Leetham, W. Robertson, A. Juels,
and E. Kirda. Beehive: Large-scale log analysis for detecting suspicious
activity in enterprise networks.
In Proceedings of the 29th Annual
Computer Security Applications Conference, ACSAC ’13, pages 199–
208, New York, NY, USA, 2013. ACM.
[24] C. W. Ten, G. Manimaran, and C. C. Liu. Cybersecurity for critical
infrastructures: Attack and defense modeling.
IEEE Transactions
on Systems, Man, and Cybernetics - Part A: Systems and Humans,
40(4):853–865, July 2010.
[25] D. Hadiosmanovic, D. Bolzoni, P. Hartel, and S. Etalle. Melissa:
Towards automated detection of undesirable user actions in critical
infrastructures. In Computer Network Defense (EC2ND), 2011 Seventh
European Conference on, pages 41–48, Sept 2011.
J. Timonen, L. Lääperi, L. Rummukainen, S. Puuska, and J. Vankka.
Situational awareness and information collection from critical infras-
tructure.
In Cyber Conﬂict (CyCon 2014), 2014 6th International
Conference On, pages 157–173, June 2014.
[26]
[27] A. J. Oliner, A. Aiken, and J. Stearley. Alert detection in system logs.
[28]
In IEEE International Conference on Data Mining, 2008.
J. Stearley and A. J. Oliner. Bad words: Finding faults in spiritís syslogs.
In IEEE International Symposium on Cluster Computing and the Grid,
pages 765–770, 2008.
[29] C. Lim, N. Singh, and S. Yajnik. A Log Mining Approach to Failure
In Proc. Intl. Conf. on
Analysis of Enterprise Telephony Systems.
Dependable Systems and Networks, June 2008.
[30] M. F. Porter. An algorithm for sufﬁx stripping. In K. Sparck Jones and
P. Willett, editors, Readings in Information Retrieval, pages 313–316,
San Francisco, CA, USA, 1997. Morgan Kaufmann Publishers Inc.
[31] R. Vaarandi. Mining event logs with slct and loghound. In NOMS 2008
- 2008 IEEE Network Operations and Management Symposium, pages
1071–1074, April 2008.
[32] M. W. Berry, Z. Drmac, and E. R. Jessup. Matrices, vector spaces, and
information retrieval. volume 41, pages 335–362. Society for Industrial
and Applied Mathematics, June 1999.
[33] A. Pecchia, D. Cotroneo, R. Ganesan, and S. Sarkar. Filtering security
alerts for the analysis of a production saas cloud.
In Proceedings of
the 2014 IEEE/ACM 7th International Conference on Utility and Cloud
Computing, UCC ’14. IEEE Computer Society, 2014.
[34] A. Toshniwal et al. Storm@twitter. In Proceedings of the 2014 ACM
SIGMOD International Conference on Management of Data, SIGMOD
’14, pages 147–156, New York, NY, USA, 2014. ACM.
[35] R. Jain. The Art of Computer Systems Performance Analysis.
Wiley & Sons New York, 1991.
John
[36] D. Ruiu. Cautionary tales: stealth coordinated attack how to, 1999.
[37] V. Chandola, A. Banerjee, and V. Kumar. Anomaly detection: A survey.
ACM Comput. Surv., 41(3):15:1–15:58, July 2009.
[38] X. Qin and W. Lee. Statistical causality analysis of infosec alert data. In
In Proceedings of The 6th International Symposium on Recent Advances
in Intrusion Detection (RAID 2003, pages 73–93, 2003.
390
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:58:24 UTC from IEEE Xplore.  Restrictions apply.