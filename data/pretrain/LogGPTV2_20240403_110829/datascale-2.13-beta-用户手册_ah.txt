datascale.toml  extension       instance_info   template datatype        group           metastore       vector
• 配置 DataScale 服务
参照文档 Backend 配置，在配置文件 ./config/datascale.toml 中配置目标炎凰数据
平台的接入方式。
• 创建 group 和 dataflow
◦ 参照文档 配置 Group，在 ./config/group/ 目录下创建名称为 another_group的 group。
◦ 参照文档 配置 Dataflow，在 ./config/group/default/dataflow/ 目录和 	./config/group/another_group/dataflow/目录下创建 dataflow（作为示 	例， dataflow 配置参见 创建 dataflow）。
配置 Ansible host inventory
修改 inventory 文件 ./hosts ，内容如下：
# Variables for all hosts 
[all:vars] 
enable_cluster=True 
ds_groups=default 
manager_ip=172.16.0.1 
manager_port=7881
关于 inventory 文件 ./hosts 内容的说明：
• 设置 enable_cluster=True 时才会以集群的方式部署 DataScale。• 默认定义了两个主机组， manager 和 worker 。但为了方便管理，可以将 worker 组进一 	步按照每个 DataScale worker 所属的 group 分组：
worker1属于linux_workersgroup，使用默认的ds_groups=default作为其在
DataScale 中的 group。
worker2属于windows_workersgroup，使用指定的 
ds_groups=group_for_windows作为其在 DataScale 中的 group。
• 如需要将 manager 和 worker 部署同一服务器时，需要修改 ./hosts 中 worker 	vars中的service_name以及各服务的port配置，避免冲突：
[linux_workers:vars] 
service_name=datascale-workerservice_name=datascale-worker 
ds_service_port=9881 
ds_web_port=9880 
ds_vector_api_port=9883 
ds_vector_prometheus_exporter_port=9882
信息
为了便于管理以及回溯配置修改历史，推荐使用版本管理工具（比如 Git）管理解压后的
DataScale Ansible 工具包以及 DataScale 配置。
部署集群
• 安装 DataScale 服务
执行 Ansible playbook ./playbook/install.yaml 安装全部的 DataScale manager 和 worker， source 参数需要指定为 ./playbook/files/ 目录下的 DataScale 安装包
的文件名：的文件名：
$ ansible-playbook -i hosts playbook/install.yaml --extra-vars
"win_source=datascale-X.Y.Z-x86_64-windows.zip
linux_source=datascale-X.Y.Z-x86_64-linux.tar.gz"
• 启动 DataScale 服务
执行 Ansible playbook ./playbook/start.yaml 启动全部的 DataScale manager 和
worker：
$ ansible-playbook -i hosts playbook/start.yaml
查看集群部署状态
与手动部署 DataScale 集群时一样，在 DataScale 集群启动后，可以通过 Web UI 或炎凰数据平 台 DataScale Monitoring 仪表板查看每个服务节点的运行状态，以及通过查询 dataflow 中配置 的数据集得到 DataScale worker 采集到的 event。更多 Ansible playbook 操作
除了上面提到过的安装和启动操作之外，DataScale Ansible 工具包中还提供了更多的 playbook，你可以：
• 停止所有 DataScale 服务
$ ansible-playbook -i hosts playbook/stop.yaml
• 将当前 ./config/ 目录下的配置更新到所有 DataScale 服务
$ ansible-playbook -i hosts playbook/update.yaml
• 卸载所有 DataScale 服务
$ ansible-playbook -i hosts playbook/uninstall.yaml
在执行 Ansible playbook 时，不但可以应用于 host inventory 中的全部主机，还可以限制应用范围
为部分主机，例如：为部分主机，例如：
• 停止所有的 DataScale worker
$ ansible-playbook -i hosts playbook/stop.yaml --limit
linux_workers
• 卸载主机 worker1 上的 DataScale 服务
$ ansible-playbook -i hosts playbook/uninstall.yaml --limit
worker1
版本：2.13.0-beta
管理 DataScale Worker 的群 组
DataScale worker 的群组管理有两种方式：
• 由 worker 指定自己所属的群组
• 为群组设置 worker 的匹配规则后，根据匹配规则确定 worker 所属的群组
两种方式不会同时起效，当为群组设置了 worker 的匹配规则后，worker 自己指定所属的群组将被
忽略。忽略。
Worker 指定自己所属的群组
当由 worker 指定自己所属的群组时，群组信息配置在 worker 的配置文件 config/
datascale.toml中的service配置部分，例如：
[service] 
mode = "worker" 
[service.worker] 
manager_address = "http://master1:7881" groups = "default"
如果 worker 同属与多个群组，群组名称之间使用逗号分隔，例如：
[service] 
mode = "worker" 
[service.worker]
为群组设 组设置 Worker 的匹配规则
当使用集群模式部署 DataScale 时，可以为群组设置 worker 的匹配规则（当群组设置了 worker
的匹配规则后，原由 worker 指定的所属群组将被忽略）：的匹配规则后，原由 worker 指定的所属群组将被忽略）：
可以使用在匹配规则中的字段包括： instance_id 、 hostname 、 os 、 arch ，匹配规则样例如
下：
| • |  |
|---|---|
| • |  |
| • |  |
信息
关于更多匹配规则的说明及样例，参见 。
	版本：2.13.0-beta 
自定义 义采集器
DataScale collector（自定义采集器）的基础介绍和开发指南。
📄 Collector 介绍
| 基础介绍 |
|---|
| 📄开发 发 Collector |
本文以一个最简单的用于演示的 collector 为例，介绍如何开发 DataScale collector。
|  |
|---|
| Collector 介绍 基础 础介绍 ||  |
|---|
| Collector 介绍 基础 础介绍 |
DataScale 中内置了多种 source 组件用于对接各种常用的数据源，但是这些 source 可能仍然无法 满足你的数据采集场景：
	• 你需要的数据采集功能具有非普遍甚至较复杂的逻辑，例如当数据源为某个服务的 Restful 	API 时：
	◦ 该数据源要求实现某种认证方式
	◦ 或者需要调用多个关联的 Restful API 后再经过计算才能得到最终采集的数据
	• 你已经有了一个数据采集的工具，但是希望将其整合到 DataScale 的 dataflow 中：
	◦ 为采集到的数据加入更多的数据处理逻辑
	◦ 将采集到的数据发送到指定的 sink◦ 将采集到的数据发送到指定的 sink 
对于这些情况，DataScale 提供了 collector 机制，用于实现任何定制化的数据采集需求。DataScale 提供了 collector 的安装和部署功能，当你将自己开发的 collector 安装到 DataScale 后，该 collector 就可以作为 source 组件在 dataflow 中使用：
	信息 
在 dataflow 中使用 collector 时，collector 程序会在主机上以运行 DataScale 的同一个账号 被运行。因此，需要注意以下几点：
	• Collector 程序可能会因为受限于其被赋予的账号权限而无法完成指定的任务
	• Collector 程序可能会因为被赋予的账号权限过高而存在导致安全问题的风险 
为了避免上述的问题，你可能可以采取的措施有：为了避免上述的问题，你可能可以采取的措施有：
	• 使用专门的账号运行 DataScale 服务，并且仅赋予该账号一些必须的权限
	• 对于自研的 collector，审查代码实现，避免存在故意或者非故意的危险操作
管理 Collector 
DataScale 提供了 Web UI 管理 collector 的安装、更新和删除：
安装/更新 Collector 
在安装或更新 collector 时，DataScale 会检查安装包文件的命名和内容，只有通过检查的安装包 才能够被安装或更新：
	• 安装包文件名需要符合命名规范（关于 collector 安装包命名规范，参见 Collector 安装包）	• 安装包中的配置文件 meta.json 也需要符合规范（关于 collector 配置文件的介绍，参见 	Collector 配置文件）在集群部署的模式下，DataScale manager 安装或更新 collector 后，会自动将当前版本的 collector 同步至所有的 worker 节点。
不论是在 standalone 或集群部署模式下，一旦 collector 被更新，所有正在使用该 collector 的 dataflow 都会自动加载最新版本的 collector。
删除 Collector 
你可以删除一个不再需要的 collector。但是当一个 collector 正在被 dataflow 使用时，不允许被删 除。因此，在删除一个 collector 之前，请将使用该 collector 的 source 组件从相关 dataflow 中 删除。
使用 Collector 
安装 collector 后，该 collector 就会出现在 source 组件的选择列表中。选择该 collector source 组件后，你可以在配置表单中调整运行 collector 组件的参数、配置和模式等：版本：2.13.0-beta 
开发 发 Collector
本文以一个最简单的用于演示的 collector 为例，介绍如何开发 DataScale collector。
Collector 安装包
目录结构
一个最简单的 collector 安装包中只需要包含下列内容：
% unzip ./example_collector-1.0.0-x86_64-linux.zip % tree ./ 
./
├── exec
│   └── dummy_log_printer.sh
└── meta.json
1 directory, 2 files
• 配置文件 ./meta.json
配置文件中设置了 collector 安装包的基本信息、以及 collector 的运行配置。
•	./exec/目录下的可执行文件（executable）•	./exec/目录下的可执行文件（executable）
Executable 是会在 dataflow 中被运行的程序，可以是编译生成的 binary 文件，也可以是由解 释器执行的脚本程序。
信息
DataScale 不会限制安装包中包含其他文件或者目录结构，所以可以将运行 collector 所需要 的任何依赖放入安装包，如可执行文件所依赖的 lib 文件、配置文件等。
命名规 规范
由于 DataScale 支持在多种 CPU 架构和操作系统中运行，同一个 collector 也可能存在多个版本的 安装包。因此，collector 安装包文件名中需要体现版本信息，安装包的命名规范为：
---.zip
例如：
• example_collector-1.0.0-x86_64-darwin.zip• snmp-1.0.1-arm64-linux.zip
• windows_event_log-1.0.0-x86_64-windows.zip
Collector 配置文件
Collector 配置文件的为安装包根目录下的 ./meta.json 文件，其格式为：
{ 
	"info": { 
	"version": "1.0.0", 
	"name": "Example Collector", 
	"description": "Example collector is a DataScale collector for demo or learning purpose." 
	}, 
	"executables": [
• 
Collector 的基本信息
• 
Collector 中 executable 的配置。如果 collector 中存在多个 executable 时，可以在创建 collector source 组件时，选择使用其中的一个 executable。◦ 
Executable 的运行方式。如果该 executable 可以在目标主机上直接运行， type 值可以 为空，否则需要提供 executable 的运行方式，如 sh 或者 python 等。
◦ 
Executable 的名字，对应安装包 ./exec/ 目录下的的可执行文件名。
◦ 
运行该 executable 时默认使用的命令行参数，可以在 collector source 组件的配置中被 修改。
◦ 
运行该 executable 时需要设置的环境变量的键值对，可以在 collector source 组件的配 置中被修改。
◦ 
应用在该 executable 采集到的 event 的 transform 逻辑（关于 transform 方法及配置，参见 Pipeline 组件）。
•• 
运行 collector 中的任何 executable 时，都需要设置的环境变量，会在运行 executable 时与 executable 中配置的 env 合并（优先级低于 executable 中的配置）。
• 
应用在 collector 中的任何 executable 采集到的 event 的 transform 逻辑，会与 executable 中配置的 transform 合并（执行顺序排在 executable 中的配置之后）。
开发 发 Collector Executable 程序
Collector 的 executable 是一个可以独立运行的可执行文件或脚本，执行数据采集的逻辑，并输出
采集到的 event。
例如，这样一个最简单的输出一行日志文本的 Shell 脚本就可以作为 collector 的 executable：
#!/bin/sh#!/bin/sh
echo `date +%Y-%m-%dT%H:%M:%S%z` This is dummy log from
dummy_log_printer.sh as a DataScale collector
STDOUT/STDERR 输 输出
Executable 程序输出到 STDOUT 的内容会作为采集到的 event 输出到 dataflow 中后续的 pipeline 和 sink 组件，每一行内容做为一条 event。输出到 STDERR 的内容则作为错误日志，用于表现 executable 的执行处于非健康状态（该状态会体现在 dataflow 的运行状态中）。
信息
不论 executable 程序的 exit code 是何值，都不会体现在 dataflow 的运行状态中。
运行参数和环 环境变 变量运行参数和环 环境变 变量
如果需要能够从外部控制 executable 程序的运行逻辑，可以使 executable 程序支持一些命令行参 数或者环境变量的配置。 Collector 的配置文件和 collector source 组件的配置表单中都可以为 executable 设置运行时的命令行参数和环境变量。
运行模式
Collector source 组件可以被配置为周期性执行的模式（scheduled 模式），或者持续运行的模式
（streaming 模式）。
选择何种运行模式取决于 executable 程序的运行方式：
• 在 scheduled 模式下运行的 executable 程序每次启动后都应该能够在预期的时间内完成
event 的采集和输出
• 在 streaming 模式下运行的 executable 程序一但启动后，应该能够持续运行，持续产生
event，直至被要求停止运行event，直至被要求停止运行
信息
如果 collector source 组件配置的运行模式和 executable 程序的运行方式不相匹配，DataScale 在执行 collector executable 时会认为出现了程序运行超时，或者程序异常退出
等不符合预期的行为。