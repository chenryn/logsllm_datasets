1
0
0
L2
L1
L0
L2
L1
L0
L2
L1
L0
L2
L1
L0
L2
L1
L0
L2
L1
L0
L2
L1
L0
Sub-warp1
Sub-warp2
Sub-warp1
Sub-warp2
Sub-warp1
Sub-warp2
Sub-warp3
(a)
(b)
Fig. 7: Warp deformation in TMR mode
(c)
architecture used in our implementation, the number of SIMT
lanes in each SP unit is 16 which is not divisible by three. As
a result, the last four lanes (i.e. L15, L14,L13, and L12) are
handled as a special TMR cluster with four lanes.
For the TMR clusters there are four scenarios where the
opportunistic TMR execution is sufﬁcient to cover all active
threads within the cluster: ﬁrst, if all the threads within the
cluster are active and they are inherently redundant. Second,
if there is only one active thread within the cluster then it can
be replicated twice on two idle lanes. Third, if there are only
two active threads within the cluster and they are inherently
redundant then the threads’ computation is replicated on the
idle lane to achieve TMR execution. Fourth, if all the lanes
are idle then nothing needs to be done. For all other scenarios,
warp deformation is activated to achieve full TMR execution.
C. TMR Execution using Dynamic Warp Deformation
Opportunistic TMR execution covers 47% of the warps
instructions during TMR mode. To cover the remaining warps
instructions we rely on dynamic warp deformation to create
more idle SIMT lanes and allow the threads which are not
covered by the opportunistic TMR execution to be replicated
twice for error detection and correction. During TMR mode,
warp deformation is required when there is more than one
active thread assigned to a speciﬁc cluster and at least one of
these active threads is not inherently redundant.
Figure 7 shows the three possible scenarios where warp
deformation is required during TMR mode. For simplicity, we
assume that a warp consists of a single regular TMR cluster
(i.e. three SIMT lanes). Figure 7a shows the 1st scenario with
two non-inherently redundant threads assigned to L2 and L1.
In this case, the warp needs to be deformed into two sub-warps.
One active thread is assigned to each sub-warp and this active
thread is replicated on the two idle lanes that are created by
warp deformation, as indicated by the curved arrows.
Figure 7b shows the 2nd scenario with three active threads
assigned to the cluster and two of them being inherently
redundant. Again here the warp needs to be deformed into two
sub-warps; the two inherently redundant threads are assigned
to sub-warp1 and their computation is replicated on the third
idle lane so that they become TMR-ed. The non-inherently
redundant thread is assigned to sub-warp2 and its computation
is replicated on the two idle lanes available in the cluster.
Figure 7c shows the 3rd scenario with three non-inherently
redundant active threads. In this case, the warp needs to be split
into three sub-warps issued in three consecutive cycles to allow
each of the active threads to be TMR-ed. Warp deformation
for the special TMR cluster is handled the same way as for
the regular TMR clusters. The only special case is when there
are four active threads assigned to the large cluster and no
inherent redundancy is available. In this case, the warp needs
to be split into four sub-warps with one active thread per sub-
warp to achieve TMR execution.
V. WARP REPLAY
After an error is detected in DMR mode, the faulty warp
is re-executed in TMR mode in order to correct the error and
identify the error type. The procedure for re-executing a faulty
warp is described in this section. Current GPUs do not seem
to support precise exceptions and branch prediction; hence,
they lack traditional
instruction rollback mechanisms used
for handling precise exceptions and branch mis-predictions
in CPUs. These mechanisms would have made the TMR re-
execution of the faulty warp instruction straightforward; once
DMR detects an error then we can simply rollback and re-
execute the faulty warp in TMR mode.
To support warp re-execution in Warped-RE framework, a
replay buffer is added to store the source operands and opcodes
of the warps currently executing in the SP unit. The buffer
is indexed using the warp-id and the warp program counter.
Every time a warp instruction gets issued during DMR mode,
the source operands of all the threads within the warp and
the instruction opcode are stored in the replay buffer. After all
the threads within the warp complete their DMR execution,
the outputs of every DMR cluster are compared to detect the
errors. If no error is detected in any DMR cluster, execution
resumes normally using a combination of opportunistic DMR
and warp deformation modes.
On the other hand, when an error is detected in any
DMR cluster the faulty warp instruction is converted to a no-
operation (NOP) by deactivating its write-back control signal
in order to prevent register ﬁle contamination. In addition,
the warp issue logic is directed to re-issue the faulty warp
instruction by reading its source operands and opcode control
data from the replay buffer. When the faulty warp instruction is
re-issued, execution mode is changed to TMR mode for error
correction. Note that during re-execution the input operands
are read from the buffer. That way even if the register ﬁle is
updated after the last read by a prior non-faulty instruction
in the pipeline we still re-execute the faulty instruction with
correct operands.
As multiple warps concurrently exist in an SP unit pipeline,
SIMT lanes that are experiencing non-transient errors might
affect the computation of multiple warps. Hence, it is important
to buffer the source operands and opcodes for all the warps
that are in the SP unit pipeline. Typically the number of
336336
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:52:38 UTC from IEEE Xplore.  Restrictions apply. 
concurrent warps depends on the depth of the pipeline. We
measured the maximum SP unit occupancy (i.e. the maximum
number of warps concurrently running in an SP unit) for
a Fermi-like architecture. For 22 benchmarks, at most eight
warps concurrently exist in an SP unit pipeline. Hence, in
the Warped-RE framework we augment every SP unit with
8-entry replay buffer to allow the re-execution of faulty warp
instructions. In case the replay buffer is full and a new warp
instruction is ready to be issued to the SP unit, the issue logic
is suspended until an entry is freed from the buffer.
Based on the output of the re-executed instruction there
are two possible scenarios: ﬁrst, when the same error does
not occur during TMR mode, the initial error occurrence is
considered transient and execution resumes in DMR mode.
Second, when the same error is detected during TMR mode,
the error is corrected by the TMR voter and execution resumes
in TMR mode to guarantee correction from then on. When
the latter is the case, there is no need to store instructions
in the replay buffer from this point forward because error
detection and correction are provided during TMR mode. To
better understand how warp replay affects warps execution,
let us consider the case where there are two warps (e.g. Wx
and Wy) operating in DMR mode concurrently in an error-
free SP unit. Assuming that Wy ﬁnishes DMR execution ﬁrst
and an error is detected in one of its DMR clusters, Wy is
converted to NOP and replayed in TMR mode. Notice that
Wx is still running in DMR mode. In case Wx ends up
executing correctly, either because Wx does not use the faulty
execution lane (inactive SIMT lane) or because the original
error is transient, Wx commits its results and no re-execution
is necessary for it. On the other hand, if an error is triggered
for Wx then it will be replayed in TMR mode.
Before the TMR version of Wy ﬁnishes execution, new
warp instructions such as Wz might be ready to be issued to
the SP unit. Since it is not clear yet whether the detected error
is transient or not, one can choose to execute Wz optimistically
in DMR mode or conservatively in TMR mode. In the Warped-
RE framework, we choose to conservatively execute new warps
in TMR mode until the detected error type is identiﬁed. When
the replayed version of Wy completes TMR execution, the
error is corrected and error type is identiﬁed. If the error is
non-transient all new warps from then on are executed in TMR
mode. Otherwise, the error is considered transient and new
warps from then on will execute in DMR mode.
VI. MICROARCHITECTURAL SUPPORT
In this section we describe the hardware support required
to implement the Warped-RE framework on a Fermi-like GPU
architecture [8]. Three additional pipeline stages are added to
the GPU pipeline as will be described next.
A. Inherent Redundancy and Deformation Analysis Stage
This stage is responsible for detecting the inherent redun-
dancy between the issued threads by comparing their source
operands. Based on the inherent redundancy opportunities, a
deformation control logic is used to decide if warp deformation
is required and how many sub-warps are needed in DMR and
TMR modes. Figure 8 shows how the new stage ﬁts in the
GPU pipeline. The details are described next.
Decode and 
schedule 
Inherent Redundancy 
Deformation analysis 
and  
Issue 
EX1 
EXN 
Write-Back 
P
i
p
e
R
e
g
i
s
t
e
r
(cid:1)
(cid:2)
(cid:1)
(cid:2)
(cid:1)
(cid:2)
(cid:1)
(cid:2)
(cid:1)
(cid:2)
DIR Vector 
TIR Vector 
Active Mask 
DMR 
Deformation 
Ctrl 
TMR 
Deformation 
Ctrl 
WDDMR 
NDMR_sub-warps 
WDTMR 
NTMR_sub-warps 
P
i
p
e
R
e
g
i
s
t
e
r
Fig. 8: Inherent redundancy detection and deformation analysis
stage
TIR
=
=
=
=
=
=
=
L5
L4
L3
L2
L1
L0
Fig. 9: Inherent redundancy detection logic
DIR
1) Detecting Inherent Redundancy: To detect inherent re-
dundancy opportunities, XOR-based comparators are used to
detect value similarity between the threads’ source operands.
GPU instructions generally have up to three source operands.
Hence, three comparators between every two threads within the
same cluster are added. Figure 9 shows a simple case with six
SIMT lanes logically divided into three clusters during DMR
mode and two clusters during TMR mode. The comparator
box between every two lanes contains three comparators (i.e.
one for each source operand). For DMR execution, the only
comparators that are relevant are the ones highlighted with
a striped pattern. The three striped comparator boxes are
responsible for comparing the source operands of the active
threads assigned to (L1,L0), (L3,L2) and (L5,L4). When all
source operands match,
the threads within the cluster are
inherently redundant.
For TMR execution, all comparator boxes are relevant
the one that compares the threads assigned to L3
except
and L2. Each TMR cluster needs three comparator boxes to
compare every pair of active threads together. This approach
helps to capture cases where only two out of three threads are
inherently redundant which mitigates the performance over-
head caused by the potential dynamic warp deformation. For
example, the TMR cluster to the right of Figure 9 uses three
comparator boxes to compare threads assigned to (L1,L0),
(L2,L0) and (L2,L1).
During the DMR mode the SIMT lanes are evenly divided
into eight clusters. Each DMR cluster requires one comparator
box. So, a total of eight comparator boxes are needed (i.e. 24
comparators). During TMR mode, the 16 lanes are divided into
ﬁve TMR clusters. The ﬁrst four TMR clusters are of size three
and they account for 12 lanes (i.e. L11-L0). Each one of these
clusters requires three comparator boxes (i.e. 9 comparators).
The ﬁfth TMR cluster is of size four lanes (i.e. L15-L12).
In order to compare the threads assigned to every two lanes
337337
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:52:38 UTC from IEEE Xplore.  Restrictions apply. 
in the special cluster together, six comparator boxes (i.e. 18
comparators) are needed. As described in Figure 9, there is an
overlap between DMR and TMR comparators. Hence, to detect
cluster level inherent redundancy opportunities for DMR and
TMR modes in Fermi-like architecture, 60 comparators are
needed for each SP unit to correct and detect errors across all
threads with a warp.
The comparators outputs are used to create two vectors for
each warp: DMR inherent redundancy (DIR) vector and TMR
inherent redundancy (TIR) vector. The vectors indicate the
active threads which are inherently redundant assuming DMR
and TMR modes, respectively. Figure 9 shows that each DMR
cluster is associated with a single bit in the DIR vector. The bit
is driven by the comparator box responsible for comparing the
source operands of the two threads within the cluster. When
the output of the comparator box is one, it indicates that the
two active threads within the cluster are inherently redundant.
On the other hand, when only one active thread is assigned to
the cluster or two active threads are assigned but their source
operands are not matching, the output of the comparator box
is set to zero. For the TIR vector, every bit in the TIR vector
is associated with one SIMT lane. The TIR bit of every lane
is driven by the OR-ing of the outputs of the two comparator
boxes responsible for comparing the corresponding lane with
the other two lanes in the same TMR cluster. This lane-level
TIR bit is necessary to capture cases where two out of three
threads are inherently redundant.
2) Analyzing Dynamic Warp Deformation: The implemen-
tation of warp deformation in Warped-RE framework is dif-
ferent from the implementation used in [6] for two reasons:
ﬁrst, the deformation control logic has to deal with cluster
size of two in DMR mode and cluster size of three in TMR
mode. Second, the deformation control logic must take into
consideration the inherent redundancy information provided
by the DIR and TIR vectors to avoid unnecessary splits when
inherent redundancy can already provide error detection and
correction capabilities. Deformation analysis is ﬁrst done for
each cluster independently and then a uniﬁed decision is made
for the entire warp. The decision states whether deformation
is required and determines the number of sub-warps according
to the cluster which requires maximum number of sub-warps.
We ﬁrst explain how warp deformation control is imple-
mented for the DMR mode and then expand the description to
show how deformation control is implemented for the TMR
mode. For the DMR mode we consider the 1st DMR cluster in
the SP unit (i.e. L1 and L0). The control logic has three-bit in-
put represented by the active mask bits of L1 and L0 (referred
to as AM [1:0] bits) and the DIR vector bit of the cluster (DIR
[0]). At the output side, the control logic has a one-bit output
to indicate if warp deformation is required or not according to
this cluster (i.e. W DDM R0) and a two-bit output to indicate
the number of sub-warps needed (i.e. NDM R0−sub−warps).
The only case where deformation is required is when there
are two active threads (i.e. AM [1:0] = ”11”) and they are
NOT inherently redundant (i.e. DIR[0] = ”0”). To achieve
DMR execution in this case, two sub-warps are needed. In
the Fermi architecture, there are eight DMR clusters per SP
unit and each cluster has its own deformation control logic.
For a speciﬁc warp instruction, if at least one cluster requires
deformation then the warp is deformed to guarantee 100%
Row#
1
2
3
4
5
6
Input
Output
TIR[2:0]
AM[2:0] W DT M R NT M R0−sub−warps
2
2
3
2
2
2
000
000
000
011
101
110
101
110
111
111
111
111
1
1
1
1
1
1
TABLE I: Warp deformation control per TMR cluster
DMR. Hence, the outputs of the deformation control logic
of all DMR clusters (i.e. W DDM Ri) are OR-ed together to
generate a single bit ﬂag (i.e. W DDM R) to indicate whether
the current warp instruction needs deformation or not. If warp
deformation is required during DMR mode (i.e. W DDM R =1),
the number of sub-warps is two (i.e. NDM R−sub−warps = 2)
or zero otherwise.
The information necessary to make warp deformation de-
cisions for (L2,L1,L0) TMR cluster is shown in Table I. Here,
there is six-bit input vector represented by the active mask
bits AM [2:0] combined with the three TIR vector bits of
the three lanes (i.e. TIR[2:0]). The outputs are the same as
in the DMR deformation control. Table I shows all possible
cases where deformation is required and the number of sub-
warps needed in each case. The TMR deformation control
logic design can be easily derived from this truth table. The
same deformation control logic described in Table I is used
for (L5,L4,L3), (L8,L7,L6), and (L11,L10,L9) TMR clusters.
The deformation control for the four-lane TMR cluster (i.e.
L15-L12) is handled the same as long as the number of active
threads assigned to the cluster is less than four. On the other
hand, when the number of active threads assigned to the large
cluster is four then the number of sub-warps is as follows: the
worst case occurs when each of the four threads has unique
source operands because four sub-warps are needed. When
two out of four threads are inherently redundant, three sub-
warps are needed. Finally, when three out of four threads are
inherently redundant, only two sub-warps are needed.
The deformation output ﬂags (i.e. W DT M Ri) of the regular
TMR clusters and the special 4-lane cluster are OR-ed together
to generate a single bit deformation ﬂag (i.e. W DT M R) for
the whole warp. Further, the numbers of sub-warps required
by each cluster (i.e. NT M Ri−sub−warps) are compared and the
maximum is chosen as the number of sub-warps required for
the whole warp (i.e. NT M R−sub−warps).
B. Sub-warps Active Masks Generation and Thread Replica-
tion Stage