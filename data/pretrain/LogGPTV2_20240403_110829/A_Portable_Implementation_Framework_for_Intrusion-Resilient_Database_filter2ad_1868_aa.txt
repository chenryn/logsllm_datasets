title:A Portable Implementation Framework for Intrusion-Resilient Database
Management Systems
author:Alexey Smirnov and
Tzi-cker Chiueh
A Portable Implementation Framework for Intrusion-Resilient Database
Management Systems
Alexey Smirnov
Department of Computer Science
SUNY at Stony Brook
Stony Brook, NY 11794-4400
PI:EMAIL
Tzi-cker Chiueh
Department of Computer Science
SUNY at Stony Brook
Stony Brook, NY 11794-4400
PI:EMAIL
Abstract
An intrusion-resilient database management system is
the one that is capable of restoring its consistency after be-
ing compromised by a malicious attack or a human error.
More speciﬁcally, an intrusion-resilient mechanism helps to
quickly repair a database by nullifying the damage caused
by malicious or erroneous transactions, while preserving
the effects of unaffected legitimate transactions that take
place between intrusions/errors and their detection. The
goal of this project is to develop a portable implementa-
tion framework that can augment a commercial database
management system with intrusion resilience without re-
quiring any modiﬁcations to its internals. The intrusion re-
silience mechanism described in this paper signiﬁcantly im-
proves the availability of modern DBMSs by facilitating
and sometimes even automating the post-intrusion dam-
age repair process. In addition, it can be embodied in a
reusable implementation framework, whose portability is
demonstrated by its successful application to three differ-
ent DBMSs: PostgreSQL, Oracle, and Sybase. Performance
measurements on the fully operational prototypes under the
TPC-C benchmark show that the run-time overhead of the
intrusion-resilience mechanism is between 6% and 13%.
1. Introduction
Consistency of an information system can be compro-
mised due to a hardware failure, a malicious attack, or a
human mistake. Standard recovery mechanisms in modern
database management systems are designed to recover from
hardware failures, which can be detected as soon as they
occur. For malicious attacks and human mistakes, where
there is typically a time gap between occurrence and de-
tection, these recovery mechanisms are inadequate because
they can neither roll back committed transactions nor keep
track of inter-transaction dependencies. As a result, to clean
up a compromised database using existing tools takes time-
consuming human efforts and typically results in a long
mean time to repair (MTTR) and thus database down time.
We call an information system intrusion-resilient if it can
quickly repair the damage caused by a malicious attack or
human error and maximize the overall system availability.
A wide variety of information systems can be made
instance, Zhu and Chiueh [2]
intrusion-resilient. For
described a general
implementa-
intrusion-resilience
tion framework for network ﬁle servers. The system,
called RFS (Repairable File Service), aims at facilitat-
ing the post-intrusion repair process for network ﬁle
servers. RFS is not a ﬁle server on its own. Instead, it is
a special ﬁle server that acts as a proxy between a pro-
tected network ﬁle server and its clients and logs all the ﬁle
updates. The resulting log is used at recovery time to deter-
mine the extent of the damage and to undo any detrimental
side effects.
Because there is a time gap between when an attack/error
occurs and when it is detected, legitimate transactions that
are not related to the attack/error could be committed to the
compromised database during this period. The key problem
that an intrusion-resilient DBMS needs to address is how to
completely undo the damage caused by an attack or an er-
ror while preserving the effects of these good transactions
as much as possible. More speciﬁcally, an intrusion-resilient
DBMS should be able to:
• Determine the exact extent of database damage from
an initial set of attack/error transactions identiﬁed by
the database administrator, including transactions that
are benign in nature but are polluted by attack/error
transactions.
• Perform a selective rollback of those transactions that
are considered corruptive to undo the database damage
caused by the attack or the error.
Because standard recovery mechanisms in modern DBMSs
performs neither of the above functions, today’s database
administrators (DBA) have to perform these two tasks man-
ually to repair a compromised DBMS. A typical post-
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:30:32 UTC from IEEE Xplore.  Restrictions apply. 
intrusion repair procedure involves restoring the compro-
mised database to a state before the attack/error, analyzing
the transaction log in detail to identify the corrupting trans-
actions, and redoing only those transactions that are legiti-
mate and unaffected by the attack/error. In most cases, this
is a time-consuming, error-prone and labor-intensive pro-
cess.
In this paper, we develop a fast database damage repair
mechanism that can quickly repair a database compromised
by an intrusion or an error and thus greatly improve the
database availability. This mechanism keeps track of inter-
transaction dependencies at run time in order to determine
the exact extent of the database damage at repair time, and
performs a selective rollback of those and only those cor-
rupting transactions. Moreover, this fast database damage
repair mechanism does not require any modiﬁcation to the
DBMS internals, and thus could be embodied in a reusable
implementation framework that can be easily ported to dif-
ferent DBMSs with no or minor customization.
2. Related Work
The previous research on survivable and intrusion-
resilient systems has evolved in both hardware and soft-
ware ﬁelds and has addressed such areas as ﬁle systems,
storage systems, and database systems.
Wylie et al. [3, 4] describes a survivable storage system
S4, which is a network-attached object store with an access
interface based on storage of objects. The Repairable File
System (RFS) project [2] aims at improving the speed and
precision of post-intrusion damage repair for NFS servers.
Traditionally, ﬁle system recovery uses signatures generated
by systems such as Tripwire [5] to determine the corrupted
system ﬁles or complete point in time restoration from back-
ups. Instead, RFS maintains ﬁle system operation logs and
carries out dependency analysis to provide fast and accu-
rate repair of damage caused by NFS operations issued by
attackers.
Traditional database recovery methods have been dis-
cussed in many database textbooks [9, 10]. Combined
with data replication, WAL presents an efﬁcient way for a
database to recover after media failures.
The problem of database post-intrusion recovery has
been addressed from both theoretical [6, 7] and practical
[1, 8] points of view. Liu [7], develops a family of archi-
tectures for intrusion-tolerant database systems. Subsequent
architectures enhance the ﬁrst basic architecture by address-
ing various problems such as attack isolation, damage con-
ﬁnement, and quality of information assurance provision.
Ammann et al. [6] proposes various algorithms for re-
covery from malicious transactions. The authors address
two problems:
the problem of inter-transaction depen-
dency tracking and the problem of database repair.
Inter-transaction dependency tracking requires know-
ing the data read and written by each transaction. The
latter problem is relatively simple since this informa-
tion is logged by modern DBMSs. However, the former
problem is much more difﬁcult. Two solutions are pro-
posed in this paper — comprehensive logging of transaction
reads and extracting the read information from transac-
tion proﬁles. The authors admit that modern database sys-
tems do not support read logging and, therefore, the ﬁrst
approach requires changing the source code of exist-
ing DBMS. The second solution has also some limita-
tions, because it is possible to come up with a transac-
tion whose read set proﬁle will not provide a complete
information on the data read by this transaction. How-
ever, the authors claim that this solution will work in many
cases by providing the read set templates for TPC-C trans-
actions. Two versions of repair algorithms are provided
for each of the tracking approaches — static and dy-
namic. The static algorithm brings the whole database
ofﬂine during the repair time, whereas the dynamic al-
gorithms performs on-the-ﬂy repair. There is a trade-off
between the two algorithms: the dynamic algorithm pro-
vides better service availability, but it can initially mark
some benign transactions as malicious (to prevent the dam-
age from being spread over the database) thus preventing
the user from accessing the data modiﬁed by these trans-
actions. Based on this work, an intrusion tolerant database
system [8] was implemented as an enhancement to Ora-
cle database server.
Pilania et al. [1] describes an intrusion resilience mech-
anism for PostgreSQL. The problem of transaction depen-
dency tracking is solved by modifying the internals of Post-
greSQL to allow the transaction read information to be cap-
tured. Although the system has a relatively small overhead,
its main drawback is that the technique used in it cannot be
directly applied to other DBMSs.
3. Intrusion-Resilient DBMS System Archi-
tecture
3.1. Inter-Transaction Dependency
Let us call the set of rows that an SQL statement retrieves
from the database for further processing the read set of the
statement. The read set of a SELECT, UPDATE or DELETE
statement is the set of rows satisfying its WHERE clause. An
INSERT statement has an empty read set. An SQL state-
ment S2 depends on another SQL statement S1 if the read
set of S2 was modiﬁed by S1. Transaction T1 depends on
transaction T2 if there exists one statement S1 in T1 and an-
other statement S2 in T2 such that S1depends on S2.
This deﬁnition of transaction dependency could lead to
both false positives and false negatives. For example, a false
positive occurs if two transactions, T1 and T2, update differ-
ent attributes of a row. Even though they do not share any
data, one is still considered dependent on the other. This
problem can be solved by tracking inter-transaction depen-
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:30:32 UTC from IEEE Xplore.  Restrictions apply. 
dencies on a column by column basis, which incurs a much
higher overhead. A false negative occurs if a transaction T1
updated the balance of an account from $50 to $500, and
later T2 charged a service fee from all accounts whose bal-
ance is less than $100. Each account is represented by a ta-
ble row. In this case, T2 does not depend on T1, because
the read set of T2 does not include the row that T1 updates.
However, were T1 not to update the row, the read set of T2
would have included that row. Therefore, if T1 is a mali-
cious transaction, the right repair operation is to roll back
both T1 and T2, even though dependency analysis suggests
only T1 needs to be undone.
There are also scenarios in which implicit
inter-
transaction dependencies will not be caught, for instance,
dependencies that arise as a result of internal applica-
tion logic or inter-application interactions. In general,
transaction dependencies cannot be tracked only by just an-
alyzing SQL statements issued to a DBMS. Because of
all these issues, it is still advisable for the DBA to be in-
timately involved in the determination of the ﬁnal set
of corrupting transactions, using the transaction set de-
rived from the dependency analysis as the starting point.
3.2. Transaction Dependency Tracking
An intrusion-resilient DBMS needs to keep track of
inter-transaction dependencies constantly so that it can use
this information to determine the damage perimeter at repair
time. To record inter-transaction dependencies in a way in-
dependent of the underlying DBMS, we propose a transac-
tion dependency tracking mechanism that is based on inter-
cepting and rewriting SQL statements sent from a database
client to its database server. One way to transparently inter-
cept SQL statements from DBMS client to DBMS server
is to put a proxy program between them. Another alterna-
tive to transaction dependency tracking is to use database
triggers, but this approach is not feasible because modern
DBMSs do not support read triggers (therefore, it is not pos-
sible to intercept SELECT statements).
If a DBMS client uses an open database connectivity
protocol such as JDBC to connect to the DBMS server,
a proxy JDBC driver sitting on the client side can per-
form query interception and rewriting, as shown in Fig-
ure 1. Putting the intercepting proxy on the server side is
infeasible because data transmitted over the network is in
a DBMS-speciﬁc and typically proprietary format. Putting
the proxy on the client side makes the database vulnera-
ble to an attack in which an attacker uses a standard JDBC
driver bypassing the proxy. In this case, the malicious trans-
actions executed by the attacker will not be tracked, and,
therefore, it will not be possible to identify them and roll
them back. This problem can be solved by using two prox-
ies as shown in Figure 2. One of these proxies resides on the
client side, the other resides on the server side. The goal of
the client-side proxy is to transmit the data to the server-side
proxy in some format known to both proxies. The transac-
tion dependency tracking is performed by the server-side
proxy. The server-side proxy establishes a local connection
to the database through a standard JDBC driver.
Transaction dependencies are stored as regular database
tables and are committed to the database together with the
transactions that these dependencies relate. The following
changes are made to a database when it is created:
• The
• The
table
trans dep(tr id INTEGER,
dep tr ids VARCHAR) is added to the database.
For each transaction ID, it stores the set of IDs of the
transactions it depends on as a string with IDs sepa-
rated by spaces.
table
annot(tr id INTEGER, descr
VARCHAR) is added to the database. It contains a
symbolic name for each transaction, which is used
in the visualization of the inter-transaction depen-
dency graph, as shown in Figure 3.
• A new ﬁeld trid:INTEGER is added to each database
table transparently. The ﬁeld of each row stores the ID
of the last transaction that modiﬁed the row.
By rewriting incoming SQL statements in a transac-
tion in the way shown in Table 1, the intercepting proxy
can track and record inter-transaction dependencies. For
a SELECT statement, the proxy additionally retrieves the
trid attribute from each table involved in the statement.
These attributes contain the IDs of the transactions that up-
date the rows being read most recently. When the DBMS
server returns a set of rows, the proxy reads these rows’
trid ﬁeld and store them in a local array. For an UPDATE
statement, the intercepting proxy updates the trid attribute
of all the rows the statement modiﬁes with the current trans-
action ID. Because an UPDATE statement implicitly involves
a SELECT operation, the transaction containing the UPDATE
statement thus depends on the transactions whose IDs are
stored in the trid attribute of the rows being updated. In
theory, these transaction IDs can be retrieved by executing a
SELECT statement before the UPDATE statement. However,
we decide to skip this step to reduce the run-time perfor-
mance overhead. This does not affect correctness as DBMS
logs UPDATE operations and these dependencies can be re-
constructed at repair time from the transaction log. For the
same reason the proxy does not record the associated inter-
transaction dependencies associated with a DELETE state-
ment.
For a COMMIT statement, the proxy issues an INSERT op-
eration that records the current transaction ID and the IDs of
all transactions it depends on in the trans dep table. Hav-
ing done so, the proxy commits the current transaction by
sending the COMMIT operation to the DBMS server.
Because inter-transaction dependency tracking involves
only SQL query rewriting, it is highly portable across dif-
ferent DBMSs as long as they support standard SQL inter-
face. In addition, most DBMSs also support open database
Proceedings of the 2004 International Conference on Dependable Systems and Networks (DSN’04) 
0-7695-2052-9/04 $ 20.00 © 2004 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 12:30:32 UTC from IEEE Xplore.  Restrictions apply. 
Client Machine
SQL statements
in text format
JDBC
proxy
driver
Real
JDBC
driver
SQL statements
in text format
Client
program
Server Machine
proprietary protocol
DBMS
Server
Client
Client
Figure 1. Client-side single-proxy architecture for inter-transaction dependency tracking, where
shaded boxes represent new elements to be added to a standard client-server DBMS system.
Client Machine
Client
program
Client
JDBC
proxy
SQL statements
in text format
proxy protocol
Server Machine
SQL statements
in text format
Server
JDBC
proxy
Real
JDBC
driver
proprietary
protocol
Client
Connection
pooling
process
DBMS
Server
Client
Server
JDBC
proxy
Real
JDBC
driver
Real
JDBC
driver
Server
JDBC
proxy
Figure 2. Dual-proxy architecture for inter-transaction dependency tracking, where shaded boxes
represent new elements to be added to a standard client-server DBMS system.
connectivity protocol such as JDBC. Therefore, our inter-
transaction dependency tracking module is fully reusable
across Oracle, Sybase, and PostgreSQL.
3.3. Selective Undo of Committed Transactions
Modern DBMSs perform transaction logging on a per-
row basis, and create a separate log entry for each row be-
ing modiﬁed. As a result, multiple log entries could be cre-
ated from a single SQL statement that affects multiple rows.
Each log entry contains the operation type, e.g., INSERT,
DELETE and UPDATE, internal transaction ID, the ID of the
table that the row belongs to, and the database data affected
by this operation. For an INSERT and DELETE operation,
the entire row is saved into the log. The amount of data
saved into the log in the case of an UPDATE operation varies
from DBMS to DBMS. It can be either complete pre-update
and post-update image of an updated row or only those at-
tributes that were actually modiﬁed. Each log record also
contains a reference to the position in the database to which
the change it describes is applied. For the three DBMSs that
we have studied, this position is a physical location within
the disk ﬁle containing the database, and is described by a
logical page number and an offset within this page. This ad-