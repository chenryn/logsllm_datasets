tures per MDN, feature selection yielded 538 total individual
strings from the 53 MDNs.
An example of some of these strings is shown in Table II.
As detailed in Section III-E, we submitted these candidate
features to a 10% sub-sample of the daily crawl results from
the static crawler. This produced over 2.9M URLs, which
might be considered suspicious. We prune the list by discarding
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:59:16 UTC from IEEE Xplore.  Restrictions apply. 
s
e
g
a
P
g
n
d
n
a
L
i
f
o
r
e
b
m
u
N
6
10
5
10
4
10
3
10
2
10
1
10
0
10
0
5
15
10
Unique MDN
20
25
Fig. 3: Number of landing pages predicted to belong to each
individual MDN as determined by the rule-based system after
false positive pruning. The MDN landing page count varies by
several orders of magnitude with the largest MDN having over
100,000 pages.
features that return less than 60% of detections on pages
marked malicious by the dynamic crawler. This reduces the
candidate feature list
to a ﬁnal set of 128 high-precision
features. This feature list was then submitted to the static
crawler to determine all web pages scanned on January 20,
2012 containing at least one of these features. This ﬁnal step
produced a list of 289,087 URLs which we suspect to be
landing pages belonging to 24 MDNs. The number of landing
pages per MDN is provided in Figure 3.
3) Validation: The last step is to validate the effectiveness
of the system. To do so, we compare our method to three
systems:
the production dynamic crawler, the Nozzle [11]
system, and the Zozzle [12] system. We ﬁrst submitted a
subset of the discovered URLs to the production dynamic
crawler. The validation results for the rule-based system for
the August 25, 2011 and January 2, 2012 datasets are given
in Table IV. Forced to be parsimonious in our use of the
production dynamic crawler (which is a heavily used resource)
we were able to submit only a portion of our newly detected
URLs. We submitted only 48,189 pages randomly selected
from the August dataset and 88,503 from the January dataset.
The dynamic crawler detected 57.2% of the webpages
as malicious for August 25, 2011. Likewise, 58.1% of the
88,503 evaluated by the dynamic crawler for January 2,
2012 dataset were determined to be malicious. This indicates
that the proposed system has very high precision, given that
malicious webpages on the internet constitute a very small
fraction of the whole and random sampling is not viable.
In fact, in a production environment, a automated detection
system is regarded as actionable if 1% of the pages that are
predicted to be malicious are conﬁrmed. Unfortunately we
cannot analyze the system’s recall since it is impossible to
know how many false negatives there are. Using the dynamic
crawler to scan this web-scale dataset is prohibitive for us
due to the computational costs. While 58.1% were veriﬁed
malicious only 42.6% had not previously been discovered. At
this rate, the expected number of new landing pages for these
MDNs is 289, 087 × 0.426 = 123, 071. Thus, since we started
with 719, 089 landing pages we have expanded the veriﬁed
footprint of the MDNs by 100 × 123/719 ≈ 17.1%. It’s also
worth noting that the detection rates remained consistent over
a period of ﬁve months.
In addition, we also evaluated these same webpages using
the Nozzle and Zozzle systems. Nozzle detects heap sprays in
the malicious code in runtime, while Zozzle is a classiﬁcation
system to detect malicious javascript. Table IV shows that
Nozzle did not ﬁnd any of the webpages identiﬁed by our
method while Zozzle detected four for the ﬁrst dataset and
350 for the second. We make several observations from these
results. First, the rule-based detection system does a very good
job of identifying malicious webpages; our system provided
webpages that were almost 60% malicious. Furthermore, the
detection system is essentially orthogonal to the Nozzle and
Zozzle systems. That is, our system is complementary to their
method of discovery.
IV. CLASSIFIER-BASED MDN DETECTION
The rule-based method for detecting MDN landing pages
exhibited high precision as indicated in Table IV: over 57% of
pages the system deemed suspicious turned out to be hosting a
drive-by download attack. We now explore a second, classiﬁer-
based landing page detection method and examine whether it
can produce a better result.
A. Classiﬁer Features and Regular Expression Generation
The classiﬁer borrows much from the rule-based system,
including the preprocessing step (identifying the MDNs from
DCTraces, described in Section III-F1) and the string cluster
features (Section III-C). A departure from the rule-based
method is that we also investigate two additional types of
features: individual string features in isolation, and regular
expression features.
The regular expression generator is based on the algorithm
proposed in [13] which demonstrated considerable efﬁcacy in
accurately capturing spam URLs. With a set of strings as input,
it generates one or more regular expressions that match the
strings in the set. This may be able to capture more generic
forms of features than the string cluster features. The three
types of features are labeled as STRING MATCH, STRING
CLUSTER and REGEX CLUSTER in the evaluation ﬁgures.
B. Classiﬁer Training
We use the 60-day DCTraces ending on August 25, 2011 to
train the classiﬁers and understand the performance of different
feature sets. After the MDN labeling and feature selection
steps, we next construct labeled, sparse binary datasets for
each of the three feature sets. Rows represent webpages and
columns represent features. Each dataset consists of 64,000
rows half of which are constructed from pages belonging to
our benign webpage collection and the other half from landing
pages of known MDNs. An element in the dataset is set to true
if the webpage associated with the row contains the feature
associated with the column (i.e., contains the string, an element
of the string cluster, or matches the regular expression).
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:59:16 UTC from IEEE Xplore.  Restrictions apply. 
TABLE IV: Dynamic Crawler Evaluation.
DC Trace Data
End Date
Total URLs
Scanned
Proposed
Method
Pages Detected By Malicious Webpage Nozzle
Proposed Method
Detection Rate (%)
Zozzle
Aug 25, 2011
Jan 2, 2012
Jan 2, 2012
48,189
88,503
110,982
Jan 2, 2012
102,919
Rule-Based
Rule-Based
Classiﬁer-Based
Highest Probability
Classiﬁer-Based
Random Sampling
27,563
51,567
1,363
1,617
57.2
58.3
1.2
1.6
0
0
0
0
4
350
0
2
100
80
60
40
20
0
0
Regex Cluster
String Cluster
String Match
)
%
(
e
t
a
R
e
v
i
t
a
g
e
N
e
s
a
F
l
20
40
60
80
100
False Positive Rate (%)
100
80
60
40
20
0
0
Regex Cluster
String Cluster
String Match
0.2
0.4
0.6
0.8
1
False Positive Rate (%)
)
%
(
e
t
a
R
e
v
i
t
a
g
e
N
e
s
a
F
l
Fig. 4: Detection error tradeoff curves for the three proposed
feature sets for dynamic trace data over 60 days ending August
25, 2011.
Fig. 5: A zoomed-in view of the detection error tradeoff curves
in Figure 4 for a maximum false positive rate of 1% .
We train separate classiﬁers for each feature set using
multi-class logistic regression [14]. Each MDN is considered
one class, and all of the benign pages are considered as
belonging to a single class. Once training is complete, an
unknown webpage is evaluated by calculating its feature vector
and predicting which class (i.e., particular MDN or the benign
set) it is most likely to belong.
C. Classiﬁer Performance Evaluation
Figure 4 provides the 5-fold cross validation, Detection Er-
ror Trade-Off (DET) curves for the STRING MATCH, STRING
CLUSTER and REGEX CLUSTER classiﬁers. The low false
positive region of these curves is highlighted in Figure 5. These
curves demonstrate that the three algorithms are comparable,
with STRING MATCH algorithm offering a minor improve-
ment.
The shape of the DET curves requires further investigation.
Figure 6 provides the histogram of the STRING CLUSTER
classiﬁer’s score, s(xi), which is the log odds that landing
page i is malicious. The log odds is computed as s(xi) =
log(P (yi = M alicious|xi)/P (yi = Benign|xi)) where yi
and xi are the label and the feature vector determined by the set
of strings extracted from the i-th webpage, respectively. Bars in
dark color in Figure 6 represent samples from benign webpages
while malicious pages are indicated by the white bars. We
ﬁrst observe a nice separation between the distributions of the
malicious and benign pages. We also note ﬁve false positives in
this particular fold of the classiﬁer training. The false positive
rate increases in the DET curves as we sweep a threshold from
right to left in the log odds histogram.
The distribution of the STRING CLUSTER classiﬁer prob-
abilities for a random sample of one million URLs is shown
in Figure 7. Noting the log scale, this ﬁgure indicates many
distinct, and potentially large, sets of URLs which include one
or more of the string cluster features. This distribution indicates
that in many cases, the classiﬁer will either identify a large
number of truly malicious webpages, or an extremely large
number of false positives.
D. Classiﬁer Validation
We also evaluate the results of the STRING CLUSTER
classiﬁcation system. To be parsimonious in our use of the pro-
duction dynamic crawler we submit only the URLs produced
by the STRING CLUSTER system, since there is little difference
between STRING CLUSTER and the STRING MATCH approach,
and both outperform REGEX CLUSTER.
The validation results for the classiﬁer-based system for
the January 2012 dataset are given in Table IV. We evaluated
this method in two ways, namely Highest Probability and
Random Sampling. For the Highest Probability experiment,
we selected URLs which were predicted to be malicious by
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:59:16 UTC from IEEE Xplore.  Restrictions apply. 
Malicious
Benign
104
103
t
n
u
o
C
102
101
100
-2
0
2
4
6
8
10
Log Odds
Fig. 6: String cluster classiﬁer score (i.e. log odds) for the for
dynamic crawler trace data over 60 days ending August 25,
2011. The malicious and benign classes separate nicely, but
we do note ﬁve false positives in the ﬁgure.
6
10
5
10
4
10
3
10
2
10
1