  1. What version of Go are you using (`go version`)? go1.6
  2. What operating system and processor architecture are you using (`go env`)? linux/amd64
  3. What did you do? http://play.golang.org/p/1MigDGnopS (unfortunately this cannot execute because of cgo)
  4. What did you expect to see? One line printed to standard output containing text "test" (edit: as is output by this very similar, working example http://play.golang.org/p/eX1pSIjmo4)
  5. What did you see instead?
    panic: runtime error: cgo argument has Go pointer to Go pointer
    goroutine 1 [running]:
    panic(0x474d20, 0xc82000a210)
        /usr/lib/go/src/runtime/panic.go:464 +0x3e6
    main._cgoCheckPointer0(0x4697e0, 0xc820054094, 0x0, 0x0, 0x0, 0x0)
        github.com/bmatsuo/lmdb-go/tmp/_obj/_cgo_gotypes.go:42 +0x4d
    main.main()
        /home/b/src/github.com/bmatsuo/lmdb-go/tmp/cgopanic.go:24 +0x153
I'm creating this issue to track a problem I brought up in #14210 (comment)
but for which the cause/fix was different. I took some time before filing the
issue to collect more information about the problem and the fix for my own
understanding. My apologies for the delay. But it didn't look like a duplicate
has been filed since.
I was also told to replace my code that looked like the above example with
code which takes the address of a `[]byte` at the actual cgo call site to help
the tool figure out which memory region I was referring to. I have done so,
and it works, but I have found the result to be significantly slower that
before I made this change (both benchmarks takes from a stock go1.6 build --
no flags).
The changes I made to work around the above panic in my actual project can be
found here: bmatsuo/lmdb-go@`40ebaca`
And the performance comparison against master can be seen in my pull request:
bmatsuo/lmdb-go#57 (comment)
My benchmarks, unfortunately, have more noise than I would like but there is a
definite pattern that shows this change having a real impact on call times
(especially for some functions which should execute be extremely quickly). The
relevant benchmarks show a 7-43% performance penalty from this change (100ns+
per affected C call).