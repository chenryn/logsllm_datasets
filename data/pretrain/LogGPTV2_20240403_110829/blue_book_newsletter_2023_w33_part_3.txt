    ```bash
    zfs rename tank/home/cindys@083006 tank/home/cindys@today
    ```
    In addition, the following shortcut syntax is equivalent to the preceding syntax:
    ```bash
    zfs rename tank/home/cindys@083006 today
    ```
    The following snapshot rename operation is not supported because the target pool and file system name are different from the pool and file system where the snapshot was created:
    ```bash
    $: zfs rename tank/home/cindys@today pool/home/cindys@saturday
    cannot rename to 'pool/home/cindys@today': snapshots must be part of same
    dataset
    ```
    You can recursively rename snapshots by using the `zfs rename -r` command. For example:
    ```bash
    $: zfs list
    NAME                         USED  AVAIL  REFER  MOUNTPOINT
    users                        270K  16.5G    22K  /users
    users/home                    76K  16.5G    22K  /users/home
    users/home@yesterday            0      -    22K  -
    users/home/markm              18K  16.5G    18K  /users/home/markm
    users/home/markm@yesterday      0      -    18K  -
    users/home/marks              18K  16.5G    18K  /users/home/marks
    users/home/marks@yesterday      0      -    18K  -
    users/home/neil               18K  16.5G    18K  /users/home/neil
    users/home/neil@yesterday       0      -    18K  -
    $: zfs rename -r users/home@yesterday @2daysago
    $: zfs list -r users/home
    NAME                        USED  AVAIL  REFER  MOUNTPOINT
    users/home                   76K  16.5G    22K  /users/home
    users/home@2daysago            0      -    22K  -
    users/home/markm             18K  16.5G    18K  /users/home/markm
    users/home/markm@2daysago      0      -    18K  -
    users/home/marks             18K  16.5G    18K  /users/home/marks
    users/home/marks@2daysago      0      -    18K  -
    users/home/neil              18K  16.5G    18K  /users/home/neil
    users/home/neil@2daysago       0      -    18K  -
    ```
* New: [See the differences between two backups.](zfs.md#see-the-differences-between-two-backups)
    To identify the differences between two snapshots, use syntax similar to the following:
    ```bash
    $ zfs diff tank/home/tim@snap1 tank/home/tim@snap2
    M       /tank/home/tim/
    +       /tank/home/tim/fileB
    ```
    The following table summarizes the file or directory changes that are identified by the `zfs diff` command.
    | File or Directory Change | Identifier |
    | --- | --- |
    | File or directory has been modified or file or directory link has changed | M |
    | File or directory is present in the older snapshot but not in the more recent snapshot | — |
    | File or directory is present in the more recent snapshot but not in the older snapshot | + |
    | File or directory has been renamed | R |
* New: [Create a cold backup of a series of datasets.](zfs.md#create-a-cold-backup-of-a-series-of-datasets)
    If you've used the `-o keyformat=raw -o keylocation=file:///etc/zfs/keys/home.key` arguments to encrypt your datasets you can't use a `keyformat=passphase` encryption on the cold storage device. You need to copy those keys on the disk. One way of doing it is to:
    - Create a 100M LUKS partition protected with a passphrase where you store the keys.
    - The rest of the space is left for a partition for the zpool.
* New: [Clear a permanent ZFS error in a healthy pool.](zfs.md#clear-a-permanent-zfs-error-in-a-healthy-pool)
    Sometimes when you do a `zpool status` you may see that the pool is healthy but that there are "Permanent errors" that may point to files themselves or directly to memory locations.
    You can read [this long discussion](https://github.com/openzfs/zfs/discussions/9705) on what does these permanent errors mean, but what solved the issue for me was to run a new scrub
    `zpool scrub my_pool`
    It takes a long time to run, so be patient.
* New: [ZFS pool is in suspended mode.](zfs.md#zfs-pool-is-in-suspended-mode)
    Probably because you've unplugged a device without unmounting it.
    If you want to remount the device [you can follow these steps](https://github.com/openzfsonosx/zfs/issues/104#issuecomment-30344347) to symlink the new devfs entries to where zfs thinks the vdev is. That way you can regain access to the pool without a reboot.
    So if zpool status says the vdev is /dev/disk2s1, but the reattached drive is at disk4, then do the following:
    ```bash
    cd /dev
    sudo rm -f disk2s1
    sudo ln -s disk4s1 disk2s1
    sudo zpool clear -F WD_1TB
    sudo zpool export WD_1TB
    sudo rm disk2s1
    sudo zpool import WD_1TB
    ```
    If you don't care about the zpool anymore, sadly your only solution is to [reboot the server](https://github.com/openzfs/zfs/issues/5242). Real ugly, so be careful when you umount zpools.
* New: [Prune snapshots.](sanoid.md#prune-snapshots)
    If you want to manually prune the snapshots after you tweaked `sanoid.conf` you can run:
    ```bash
    sanoid --prune-snapshots
    ```
* New: [Send encrypted backups to a encrypted dataset.](sanoid.md#send-encrypted-backups-to-a-encrypted-dataset)
    `syncoid`'s default behaviour is to create the destination dataset without encryption so the snapshots are transferred and can be read without encryption. You can check this with the `zfs get encryption,keylocation,keyformat` command both on source and destination.
    To prevent this from happening you have to [pass the `--sendoptions='w'](https://github.com/jimsalterjrs/sanoid/issues/548) to `syncoid` so that it tells zfs to send a raw stream. If you do so, you also need to [transfer the key file](https://github.com/jimsalterjrs/sanoid/issues/648) to the destination server so that it can do a `zfs loadkey` and then mount the dataset. For example:
    ```bash
    server-host:$ sudo zfs list -t filesystem
    NAME                    USED  AVAIL     REFER  MOUNTPOINT
    server_data             232M  38.1G      230M  /var/server_data
    server_data/log         111K  38.1G      111K  /var/server_data/log
    server_data/mail        111K  38.1G      111K  /var/server_data/mail
    server_data/nextcloud   111K  38.1G      111K  /var/server_data/nextcloud
    server_data/postgres    111K  38.1G      111K  /var/server_data/postgres
    server-host:$ sudo zfs get keylocation server_data/nextcloud
    NAME                   PROPERTY     VALUE                                    SOURCE
    server_data/nextcloud  keylocation  file:///root/zfs_dataset_nextcloud_pass  local
    server-host:$ sudo syncoid --recursive --skip-parent --sendoptions=w server_data PI:EMAIL:backup_pool
    INFO: Sending oldest full snapshot server_data/log@autosnap_2021-06-18_18:33:42_yearly (~ 49 KB) to new target filesystem:
    17.0KiB 0:00:00 [1.79MiB/s] [=================================================>                                                                                                  ] 34%
    INFO: Updating new target filesystem with incremental server_data/log@autosnap_2021-06-18_18:33:42_yearly ... syncoid_caedrium.com_2021-06-22:10:12:55 (~ 15 KB):
    41.2KiB 0:00:00 [78.4KiB/s] [===================================================================================================================================================] 270%
    INFO: Sending oldest full snapshot server_data/mail@autosnap_2021-06-18_18:33:42_yearly (~ 49 KB) to new target filesystem:
    17.0KiB 0:00:00 [ 921KiB/s] [=================================================>                                                                                                  ] 34%
    INFO: Updating new target filesystem with incremental server_data/mail@autosnap_2021-06-18_18:33:42_yearly ... syncoid_caedrium.com_2021-06-22:10:13:14 (~ 15 KB):
    41.2KiB 0:00:00 [49.4KiB/s] [===================================================================================================================================================] 270%
    INFO: Sending oldest full snapshot server_data/nextcloud@autosnap_2021-06-18_18:33:42_yearly (~ 49 KB) to new target filesystem:
    17.0KiB 0:00:00 [ 870KiB/s] [=================================================>                                                                                                  ] 34%
    INFO: Updating new target filesystem with incremental server_data/nextcloud@autosnap_2021-06-18_18:33:42_yearly ... syncoid_caedrium.com_2021-06-22:10:13:42 (~ 15 KB):
    41.2KiB 0:00:00 [50.4KiB/s] [===================================================================================================================================================] 270%
    INFO: Sending oldest full snapshot server_data/postgres@autosnap_2021-06-18_18:33:42_yearly (~ 50 KB) to new target filesystem:
    17.0KiB 0:00:00 [1.36MiB/s] [===============================================>                                                                                                    ] 33%
    INFO: Updating new target filesystem with incremental server_data/postgres@autosnap_2021-06-18_18:33:42_yearly ... syncoid_caedrium.com_2021-06-22:10:14:11 (~ 15 KB):
    41.2KiB 0:00:00 [48.9KiB/s] [===================================================================================================================================================] 270%
    server-host:$ sudo scp /root/zfs_dataset_nextcloud_pass 192.168.122.94:
    ```
    ```bash
    backup-host:$ sudo zfs set keylocation=file:///root/zfs_dataset_nextcloud_pass  backup_pool/nextcloud
    backup-host:$ sudo zfs load-key backup_pool/nextcloud
    backup-host:$ sudo zfs mount backup_pool/nextcloud
    ```
    If you also want to keep the `encryptionroot` you need to [let zfs take care of the recursion instead of syncoid](https://github.com/jimsalterjrs/sanoid/issues/614). In this case you can't use syncoid's stuff like `--exclude` from the manpage of zfs:
    ```
    -R, --replicate
       Generate a replication stream package, which will replicate the specified file system, and all descendent file systems, up to the named snapshot.  When received, all properties, snap‐
       shots, descendent file systems, and clones are preserved.
       If the -i or -I flags are used in conjunction with the -R flag, an incremental replication stream is generated.  The current values of properties, and current snapshot and file system
       names are set when the stream is received.  If the -F flag is specified when this stream is received, snapshots and file systems that do not exist on the sending side are destroyed.
       If the -R flag is used to send encrypted datasets, then -w must also be specified.
    ```
    In this case this should work:
    ```bash
    /sbin/syncoid --recursive --force-delete --sendoptions="Rw" zpool/backups PI:EMAIL:zpool/backups
    ```
### [ZFS Prometheus exporter](zfs_exporter.md)
* Correction: Update the alerts to the more curated version.
* New: [Useful inhibits.](zfs_exporter.md#useful-inhibits)
    Some you may want to inhibit some of these rules for some of your datasets. These subsections should be added to the `alertmanager.yml` file under the `inhibit_rules` field.
    Ignore snapshots on some datasets: Sometimes you don't want to do snapshots on a dataset
    ```yaml
    - target_matchers:
        - alertname = ZfsDatasetWithNoSnapshotsError
        - hostname = my_server_1
        - filesystem = tmp
    ```
    Ignore snapshots growth: Sometimes you don't mind if the size of the data saved in the filesystems doesn't change too much between snapshots doesn't change much specially in the most frequent backups because you prefer to keep the backup cadence. It's interesting to have the alert though so that you can get notified of the datasets that don't change that much so you can tweak your backup policy (even if zfs snapshots are almost free).
    ```yaml
      - target_matchers:
        - alertname =~ "ZfsSnapshotType(Frequently|Hourly)SizeError"
        - filesystem =~ "(media/(docs|music))"
    ```
## Authentication
### [Authentik](authentik.md)
* New: [Disregard monitorization.](authentik.md#monitorization)
    I've skimmed through the prometheus metrics exposed at `:9300/metrics` in the core and they aren't that useful :(
# Operating Systems
## Linux
### [Linux Snippets](qbittorrent.md)
* New: [Get the current git branch.](linux_snippets.md#get-the-current-git-branch)
    ```bash
    git branch --show-current
    ```
* New: [Install latest version of package from backports.](linux_snippets.md#install-latest-version-of-package-from-backports)
    Add the backports repository:
    ```bash
    vi /etc/apt/sources.list.d/bullseye-backports.list
    ```
    ```
    deb http://deb.debian.org/debian bullseye-backports main contrib
    deb-src http://deb.debian.org/debian bullseye-backports main contrib
    ```
    Configure the package to be pulled from backports
    ```bash
    vi /etc/apt/preferences.d/90_zfs
    ```
    ```
    Package: src:zfs-linux
    Pin: release n=bullseye-backports
    Pin-Priority: 990
    ```
* New: [Rename multiple files matching a pattern.](linux_snippets.md#rename-multiple-files-matching-a-pattern)
    There is `rename` that looks nice, but you need to install it. Using only `find` you can do:
    ```bash
    find . -name '*yml' -exec bash -c 'echo mv $0 ${0/yml/yaml}' {} \;
    ```
    If it shows what you expect, remove the `echo`.
* New: [Force ssh to use password authentication.](linux_snippets.md#force-ssh-to-use-password-authentication)
    ```bash
    ssh -o PreferredAuthentications=password -o PubkeyAuthentication=no PI:EMAIL
    ```
    feat(linux_snippets#Do a tail -f with grep): Do a tail -f with grep
    ```bash
    tail -f file | grep --line-buffered my_pattern
    ```
* New: [Check if a program exists in the user's PATH.](linux_snippets.md#check-if-a-program-exists-in-the-user's-path)
    ```bash
    command -v 
    ```
    Example use:
    ```bash
    if ! command -v  &> /dev/null
    then
        echo " could not be found"
        exit
    fi
    ```
* New: [Add interesting tools to explore.](qbittorrent.md#tools)
    - [qbittools](https://github.com/buroa/qbittools): a feature rich CLI for the management of torrents in qBittorrent.
    - [qbit_manage](https://github.com/StuffAnThings/qbit_manage): tool will help manage tedious tasks in qBittorrent and automate them.
### [Diffview](diffview.md)
* New: Introduce DiffView.
    [Diffview](https://github.com/sindrets/diffview.nvim) is a single tabpage interface for easily cycling through diffs for all modified files for any git rev.
    Installation:
    If you're using it with NeoGit and Packer use:
    ```lua
      use {
        'NeogitOrg/neogit',
        requires = {
          'nvim-lua/plenary.nvim',
          'sindrets/diffview.nvim',
          'nvim-tree/nvim-web-devicons'
        }
      }
    ```
    Usage:
    Calling `:DiffviewOpen` with no args opens a new `Diffview` that compares against the current index. You can also provide any valid git rev to view only changes for that rev.
    Examples: