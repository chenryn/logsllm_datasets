title:TimeDice: Schedulability-Preserving Priority Inversion for Mitigating
Covert Timing Channels Between Real-time Partitions
author:Man-Ki Yoon and
Jung-Eun Kim and
Richard M. Bradford and
Zhong Shao
2
5
0
0
0
.
2
2
0
2
.
5
0
4
3
5
N
S
D
/
9
0
1
1
.
0
1
:
I
O
D
|
E
E
E
I
2
2
0
2
©
0
0
.
1
3
$
/
2
2
/
1
-
3
9
6
1
-
4
5
6
6
-
1
-
8
7
9
|
)
N
S
D
(
s
k
r
o
w
t
e
N
d
n
a
s
m
e
t
s
y
S
e
l
b
a
d
n
e
p
e
D
n
o
e
c
n
e
r
e
f
n
o
C
l
a
n
o
i
t
a
n
r
e
t
n
I
P
I
F
I
/
E
E
E
I
l
a
u
n
n
A
d
n
2
5
2
2
0
2
2022 52nd Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN)
TimeDice: Schedulability-Preserving Priority Inversion for
Mitigating Covert Timing Channels Between Real-time Partitions
Man-Ki Yoon
Yale University, USA
Jung-Eun Kim
Syracuse University, USA
Richard Bradford
Collins Aerospace, USA
Zhong Shao
Yale University, USA
Abstract—Timing predictability is a precondition for successful
communication over a covert timing channel. Real-time systems are
particularly vulnerable to timing channels because real-time appli-
cations can easily have temporal locality due to limited uncertainty
in schedules. In this paper, we show that real-time applications can
create hidden information ﬂow even when the temporal isolation
among the time partitions is strictly enforced. We then introduce
an online algorithm that randomizes time-partition schedules to
reduce the temporal locality, while guaranteeing the schedulability
of, and thus the temporal isolation among, time partitions. We
also present an analysis of the cost of the randomization on the
responsiveness of real-time tasks. From an implementation on a
Linux-based real-time operating system, we validate the analysis
and evaluate the scheduling overhead as well as the impact on an
experimental real-time system.
Keywords-covert channel; timing channel; real-time systems;
I. INTRODUCTION
Time is a crucial resource for enabling safety-critical applica-
tions to operate, monitor, and recover correctly. Especially when
a system is integrated from applications with different levels of
criticality, temporal isolation among them must be enforced to
prevent faulty or malicious applications from misusing the CPU
time resource. Hierarchical scheduling [1], [2] has been the key
mechanism in high-assurance systems as a general approach to
partitioning CPU time among real-time applications. It enforces
time constraints on each application, which can use its share
freely to run its local tasks. Hence, it can abstract away the
details of how others use the assigned time resource, enabling
modular reasoning about individuals’ temporal behavior. Thus
it has been successfully employed especially in avionics sys-
tems [3], [4] and is also increasingly adopted in other time-
critical systems such as automotive systems [5], [6].
However, time is a powerful medium of hidden communi-
cation, especially in real-time systems because of their timing-
predictable nature in operation [7]–[9]. In particular, sharing
time among real-time components makes it possible for them
to communicate indirectly by altering the way they consume
time. In this paper, we demonstrate such an algorithmic timing
channel [10], [11] between real-time partitions that are under
strong budget constraints on CPU time and thus completely iso-
lated from each other by a hierarchical scheduler. The technique
builds a probabilistic model of the receiver’s responsiveness;
the sender modulates how it consumes its own budget, which
inﬂuences the receiver’s timing of CPU usage. A Bayesian
inference enables the receiver to proﬁle and predict the sender’s
signals even in the presence of noises due to other non-colluding
time partitions. We also present a learning-based approach that
ﬁnds patterns in the execution timings. We discuss conditions
under which a system becomes more vulnerable to the threats.
We then introduce a partition-schedule randomization proto-
col, TIMEDICE, which is the main contribution of this paper.
It reduces the temporal locality in partition schedules under a
priority-based hierarchical scheduling by taking a rather radi-
cal approach: randomly inverting the priority relations among
partitions. This adds noise to the execution timing, not to the
time source [12], [13]. Hence, it is effective for systems in
which it is difﬁcult to completely remove every precise time
source including external sources such as network services.
Furthermore,
the local
scheduling level (i.e., within partition) [11].
it does not require modiﬁcations at
The critical challenge in the partition-schedule randomiza-
tion is that unprincipled randomization may lead partitions to
miss deadlines – i.e., not being able to fully utilize the CPU
budget assigned to it. Hence, at each scheduling decision point,
TIMEDICE determines, on the ﬂy, which partitions are allowed
to take the CPU while not leading other partitions to under-use
their budgets. Therefore, by construction, TIMEDICE guarantees
a set of partitions to be schedulable if they were so before
any randomization. We also show that a slight bias in the
random selection in fact further reduces the level of temporal
locality, thus making the covert timing channel more inaccurate.
We analyze the impact of our partition-level randomization on
the responsiveness of real-time tasks. From an implementation
on a Linux-based real-time operating system, we evaluate the
solution’s impact on the scheduling overhead and task respon-
siveness as well as its effectiveness against the covert channel.
II. SYSTEM MODEL
We consider N real-time partitions Π = {Π1, . . . , ΠN}
that share the CPU time. The partitions are scheduled in a
hierarchical manner as shown in Fig. 1; when a scheduling
decision is to be made, a partition is selected ﬁrst by the
global scheduler. Then, the selected partition schedules its tasks
according to its local scheduling policy. This paper considers
a priority-based global scheduling, which is known to achieve
improved responsiveness and CPU utilization compared to
static-partitioning schemes [11], [14]. In this scheme, each
partition is associated with a unique priority Pri(Πi) and the
global scheduler selects the highest-priority partition. Real-time
server algorithms, such as periodic server [15] and sporadic
server [16], can instantiate a priority-based partition. Due to the
enhanced CPU utilization, commercial RTOSes and real-time
hypervisors [2], [6], [17] as well as open-source ones [18], [19]
are increasingly supporting priority-based partition scheduling.
Explicit inter-partition communications through overt chan-
nels are handled by an OS-layer service (e.g., message-passing)
which does not require synchronization between partitions. We
2158-3927/22/$31.00 ©2022 IEEE
DOI 10.1109/DSN53405.2022.00052
453
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:27:56 UTC from IEEE Xplore.  Restrictions apply. 
Replenishment Period (cid:1)(cid:1)
Budget consumption
(cid:1)(cid:7)(cid:3)(cid:5)(cid:2)(cid:3)(cid:6)
Higher-priority 
partition(s)
(cid:1)(cid:1)
(cid:1)(cid:1)’s local 
tasks
Budget is depleted
Replenished
Time
Fig. 2: Covert timing channel over hierarchical scheduling.
Active
Partition-level Preemption
Inactive  (=no budget)
Fig. 1: Hierarchical scheduling. The local tasks of partition Πi
can run only when it has a budget.
do not consider shared-resource-based inter-partition commu-
nication that may require a synchronization protocol such as
Priority Inheritance/Ceiling Protocols [20].
a) Real-time partition and task models: Each partition
is associated with a maximum budget Bi and a replenishment
period Ti; the partition can serve up to Bi (e.g., 10 ms) to
its tasks during each period Ti (e.g., 100 ms) as shown in
Fig. 1. We denote the remaining budget for time t by Bi(t)
and 0 ≤ Bi(t) ≤ Bi. When a task of partition Πi executes,
Bi(t) is depleted for the amount of task execution. No task of
Πi can execute when Bi(t) = 0 unless there is a higher-priority
partition that has an unused budget but no task to run; the budget
may be used by Πi to (i) prevent additional interference by the
deferred executions [21], [22] and (ii) to improve responsiveness
because the CPU would otherwise be idled anyway. Hence, the
lower-priority partition may end up using more than its budget.
Nevertheless, this does not change the worst-case behavior of
the higher-priority partition.
Each partition Πi
is comprised of a set of tasks Πi =
{τi,1, τi,2, . . . , τi,|Πi|}. Each task is characterized by τi,j
:=
(pi,j, ei,j), where pi,j is the minimum inter-arrival time (also
called as period) and ei,j is the worst-case execution time
(WCET). That is, for each arrival it may execute for an arbitrary
amount of time upper-bounded by ei,j.
b) Terminology: Although it is a task that arrives and
executes on CPU, we will use these terms to describe a
partition’s state for ease of explanation. A partition is said to (i)
arrive if its budget is being replenished and (ii) execute when
it has taken the CPU and one of its tasks runs. Also, it is said
to be active if its remaining budget is non-zero. Otherwise, it is
said to be inactive. Lastly, to guarantee the temporal isolation
among partitions, each needs to be schedulable:
Deﬁnition 1 (Schedulable partition). Partition Πi is said to be
schedulable if it is guaranteed to serve its tasks for its maximum
budget Bi over every replenishment period Ti.
III. COVERT TIMING CHANNEL BETWEEN PARTITIONS
In high-assurance systems, information ﬂows must be explicit
(e.g., ‘authorized channels’ in Multiple Independent Levels of
Security (MILS) systems [23], [24]). That is, any communica-
tion between partitions must be known and conﬁgured a priori.
However, as applications are increasingly developed/supplied
by third-party vendors in various forms and updated frequently,
it is challenging to trust or verify them thoroughly. A hidden
information ﬂow, i.e., covert channel, can thus be used to leak
Other partitions
Noise
Hierarchical scheduling
Covert Timing Channel
“…10100…”
(cid:1)(cid:6)(cid:3)(cid:1)(cid:3)(cid:4)(cid:8)(cid:3)(cid:6)
Observation Y
(cid:2)(cid:3)(cid:1)(cid:2)(cid:1) signal: 0
(cid:2)(cid:3)(cid:1)(cid:2)(cid:1) monitoring window
Time
Input X
(cid:2)(cid:2)(cid:1) signal: 1
(cid:2)(cid:2)(cid:1) monitoring window
Sender
Receiver
(cid:2)(cid:4)(cid:11)(cid:7)(cid:4)(cid:9)(cid:6)(cid:13)(cid:5)(cid:8)(cid:4)(cid:9)(cid:14)(cid:1)(cid:11)(cid:4)(cid:12)(cid:6)(cid:10)(cid:3)
Fig. 3: The receiver observes how its execution timing changes