polled 10000 times.
Physical address CBo 0 CBo 1 CBo 2 CBo 3 Slice
0x3a0071010
11620 1468
1458
10702 696
0x3a0071050
0x3a0071090
0x3a00710d0
···
626
498
517
···
143
678
0
1
2
567
565
···
10559 571
573
···
10590 3
···
···
This is performed using Algorithm 1. First, monitoring of the LLC LOOKUP
event is set up by writing to control registers (MSR). Then, one memory address
is repeatedly accessed (Listing 1.1) to generate activity on the corresponding
slice. The counter performance registers are then read for each slice (each CBo).
Next, the virtual address is translated to a physical address by reading the
ﬁle /proc/pid/pagemap. Finally, the physical address is associated to the slice
that has the most lookups. Such monitoring sessions are iterated with diﬀerent
addresses to obtain a set of pairs (physical address, slice) that, eventually, forms
a table.
The number of times the address needs to be polled is determined experi-
mentally to diﬀerentiate the lookup of this particular address in a slice from the
noise of other LLC accesses. We empirically found that polling an address 10 000
times is enough to distinguish the correct slice from noise without ambiguity,
and to reproduce the experiment on diﬀerent conﬁgurations. The polling itself
is carefully designed to avoid access to memory locations other than the tested
address (see Listing 1.1). To this end, most of the variables are put in registers,
1 For the Xeon range (servers): processors of the micro-architecture Sandy Bridge
in [9], Ivy Bridge in [11], and Haswell in [12]. For the Core range (mobiles and
workstations), in [10] for the three aforementioned micro-architectures.
for each slice do
write MSRs to set up monitoring LLC LOOKUP event
// see Listing 1.1
54
C. Maurice et al.
Algorithm 1. Constructing the address to slice mapping table.
1: mapping ← new table
2: for each addr do
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13: end for
read MSRs to access LLC LOOKUP event counter
end for
paddr ← translate address(addr)
ﬁnd slice i that has the most lookups
insert (paddr, i) in mapping
end for
polling(addr)
for each slice do
and the only access to main memory is performed by the clflush instruction
that ﬂushes the line (in all cache hierarchies). The clflush instruction causes a
lookup in the LLC even when the line is not present.
Listing 1.1 Memory polling function.
1: void polling ( uintptr_t addr ){
2:
register int i asm ( " eax " );
3:
r e g i s t e r u i n t p t r _ t ptr asm ( " ebx " ) = addr ;
4:
for ( i =0; i < NB_LOOP ; i ++){
5:
6:
7: }
clflush (( void *) ptr );
}
Table 2 shows the characteristics of the CPUs we tested. Scanning an address
per cache line, i.e., an address every 64 B, takes time, but it is linear with the
memory size. Scanning 1 GB of memory takes a bit less than 45 min. We now
estimate the storage cost of the mapping table. The lowest 6 bits of the address
are used to compute the oﬀset in a line, hence we do not need to store them.
In practice, it is also not possible to address all the higher bits because we are
limited by the memory available in the machine. For a processor with c slices, the
slice is represented with (cid:2)log2(c)(cid:3) bits. A conﬁguration of e.g., 256 GB (= 238) of
memory and 8 cores can be represented as a table with an index of 32 (= 38− 6)
bits; each entry of the table contains 3 bits identifying the slice and an additional
bit indicating whether the address has been probed or not. The size of the table
is thus 232 × 4 bits = 2 GB.
Note that the attacker does not necessarily need the entire table to perform
an attack. Only the subset of addresses used in an attack is relevant. This subset
can be predeﬁned by the attacker, e.g., by ﬁxing the bits determining the set.
Alternatively, the subset can be determined dynamically during the attack, and
the attacker can query an external server to get the corresponding slice numbers.
Reverse Engineering Intel Last-Level Cache Complex Addressing
55
Table 2. Characteristics of the Intel CPUs used in our experimentations (mobile and
server range).
Name Model
µ-arch
Cores Mem
conﬁg 1 Xeon E5-2609 v2 Ivy Bridge
4
conﬁg 2 Xeon E5-2660
Sandy Bridge 8
conﬁg 3 Xeon E5-2650
Sandy Bridge 8
conﬁg 4 Xeon E5-2630 v3 Haswell
8
conﬁg 5 Core i3-2350M Sandy Bridge 2
conﬁg 6 Core i5-2520M Sandy Bridge 2
conﬁg 7 Core i5-3340M Ivy Bridge
conﬁg 8 Core i7-4810MQ Haswell
2
4
16 GB
64 GB
256 GB
128 GB
4 GB
4 GB
8 GB
8 GB
conﬁg 9 Xeon E5-2640
Sandy Bridge 6
64 GB
4 Building a Compact Addressing Function
4.1 Problem Statement
We aim at ﬁnding a function, as a compact form of the table. The function takes
n bits of a physical address as input parameters. In the remainder, we note bi
the bit i of the address. The function has an output of (cid:2)log2(c)(cid:3) bits for c slices.
To simplify the expression and the reasoning, we express the function as several
Boolean functions, one per bit of output. We note oi(b63, . . . , b0) the function
that determines the bit i of the output.
Our problem is an instance of Boolean function minimization: our mapping
can be seen as a truth table, that can consequently be converted to a formula in
Disjunctive Normal Form (DNF). However, the minimization problem is known
as NP-hard, and is thus computationally diﬃcult [4].
Existing work on Boolean function minimization does not seem suitable to
reconstruct the function from this table. Exact minimization algorithms like Kar-
naugh mapping or Quine-McCluskey have an exponential complexity in number
of input bits. In practice those are limited to 8 bits of input, which is not enough
to compute a complete function. The standard tool for dealing with a larger
number of inputs is Espresso, which relies on non-optimal heuristics. However,
it does not seem suited to handle truth tables of hundreds of millions of lines in
a reasonable time.2 It also gives results in DNF, which won’t express the func-
tion compactly if it contains logical gates other than AND or OR. Indeed, we
provided lines for a subset of the address space to Espresso, but the functions
obtained were complex and we did not succeed to generalize them manually.
They were generated from a subset, thus they are only true for that subset and
do not apply to the whole address space.
2 At the time of camera ready, Espresso has been running without providing any
results for more than 2000 h on a table of more than 100.000.000 lines, which only
represents the sixth of the 64 GB of memory of the machine.
56
C. Maurice et al.
We thus need hints on the expression of the function to build a compact
addressing function. We did this by a ﬁrst manual reconstruction, then followed
by a generalization. We have done this work for processors with 2n cores, which
we consider in the remainder of the section.
4.2 Manually Reconstructing the Function for Xeon E5-2609 v2
We now explain how one can manually reverse engineer a complex address-
ing function: this is indeed how we started for a Xeon E5-2609 v2 (conﬁg 1 in
Table 2). In Sect. 4.3, we will explain how this can be automated and generalized
to any processor model with 2n cores. The following generalization removes the
need to perform the manual reconstruction for each setup.
We manually examined the table to search patterns and see if we can deduce
relations between the bits and the slices. We performed regular accesses to
addresses which were calculated to ﬁx every bit but the ones we want to observe,
e.g., regular accesses every 26 bytes to observe address bits b11 . . . b6. For bits
b11 . . . b6, we can observe addresses in 4kB pages. For the higher bits (b12 and
above) we need contiguous physical addresses in a bigger range to ﬁx more bits.
This can be done using a custom driver [8], but for implementation convenience
we used 1 GB pages. Across the table, we observed patterns in the slice number,
such as the sequences (0,1,2,3), (1,0,3,2), (2,3,0,1), and (3,2,1,0). These patterns
are associated with the XOR operation of the input bits, this made the manual
reconstruction of the function easier.
We obtained these two binary functions:
o0(b63, . . . , b0) = b6 ⊕ b10 ⊕ b12 ⊕ b14 ⊕ b16 ⊕ b17 ⊕ b18 ⊕ b20 ⊕ b22 ⊕ b24 ⊕ b25
⊕b26 ⊕ b27 ⊕ b28 ⊕ b30 ⊕ b32 ⊕ b33.
o1(b63, . . . , b0) = b7 ⊕ b11 ⊕ b13 ⊕ b15 ⊕ b17 ⊕ b19 ⊕ b20 ⊕ b21 ⊕ b22 ⊕ b23 ⊕ b24
⊕b26 ⊕ b28 ⊕ b29 ⊕ b31 ⊕ b33 ⊕ b34.
We conﬁrmed the correctness of the obtained functions by comparing the
output of the slice calculated with the function against the entire mapping table
obtained with the MSRs.
4.3 Reconstructing the Function Automatically
Our manual reconstruction shows that each output bit oi(b63, . . . , b0) can be
expressed as a series of XORs of the bits of the physical address. Hund et al.
[8]
manually reconstructed a mapping function of the same form, albeit a diﬀerent
one. In the remainder, we thus hypothesize, and subsequently validate the hypoth-
esis, that the function has the same form for all processors that have 2n cores.
The fact that the function only relies on XORs makes its reconstruction a
very constrained problem. For each Boolean function oi(b63, . . . , b0), we can ana-
lyze the implication of the address bits independently from each other, in order
Reverse Engineering Intel Last-Level Cache Complex Addressing
57
to access only a handful of physical addresses. Our algorithm ﬁnds two addresses
that only diﬀer by one bit, ﬁnds their respective slices using performance coun-
ters, and compares the output. If the output is the same, it means that the bit
is not part of the function. Conversely, if the output diﬀers, it means that the
bit is part of the function. Note that this only works for a XOR function. This
algorithm is linear in number of bits.
To implement the algorithm, we use huge pages of 1 GB on Xeon processors
(resp. 2 MB on Core processors), which is contiguous physical memory naturally
aligned on the huge page size. The oﬀset in a huge page is 30-bit (resp. 21-bit)
long, therefore the lowest 30 bits (resp. 21 bits) in virtual memory will be the
same as in physical memory. We thus calculate oﬀsets in the page that will result
in physical addresses diﬀering by a bit, without converting virtual addresses to
physical addresses. To discover the remaining bits, we allocate several huge pages,
and convert their base virtual address to physical address to ﬁnd those that diﬀer
by one bit. In order to do this, we allocate as many huge pages as possible.
Table 3. Functions obtained for the Xeon and Core processors with 2, 4 and 8 cores.
Gray cells indicate that a machine with more memory would be needed to determine
the remaining bits.
Address Bit
3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 0 0 0 0
7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6 5 4 3 2 1 0 9 8 7 6
⊕
⊕
⊕ ⊕ ⊕ ⊕ ⊕
⊕ ⊕ ⊕ ⊕ ⊕
⊕ ⊕ ⊕
⊕ ⊕ ⊕
⊕
⊕ ⊕
⊕
⊕
⊕
⊕
⊕