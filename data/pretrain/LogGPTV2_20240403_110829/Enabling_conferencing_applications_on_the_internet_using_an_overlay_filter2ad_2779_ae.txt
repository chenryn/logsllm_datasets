u
m
u
C
0
0
recovery time
detection time
reaction time
repair time
5
10
15
25
30
20
Time (seconds)
35
40
45
50
Figure 12: An example demonstrating adaptation to
network congestion in one controlled experiment.
Figure 13: Cumulative distribution of recovery time
and its components for the victim hosts
All experiments are conducted using the hosts in the Pri-
mary Set. The source, located at UCSB, sends CBR traﬃc
at 1.2 Mbps. Ten minutes into the experiment, we randomly
choose a victim from among the receivers, and simulate a
state of congestion on the link between the victim and its
parent in the rest of the experiment. We simulate conges-
tion by randomly dropping 10% of the packets at the parent.
We do not model increased latencies that are typical dur-
ing network congestion. Given that each link in the overlay
tree is congestion-controlled using TFRC, a high loss rate
results in a substantial decrease in the bandwidth perfor-
mance of that link. As a result, the bandwidth received by
the victim drops sharply. Moreover, if the victim is not a
leaf in the overlay tree, all the descendants of the victim
will suﬀer the same performance degradation in bandwidth.
Given that we are not modeling latency eﬀects of conges-
tion, our experiments evaluate our techniques in adapting
to bandwidth changes alone.
To explain the issues involved in the adaptation process,
we present the behavior of the victim in a particular ex-
periment. Figure 12 plots the bandwidth the victim gets
as a function of time. Each vertical line indicates an event
of interest. In this experiment, a machine at U. Delaware
(UDEL) is the victim. Before congestion is introduced,
UDEL receives data directly from the source UCSB. At time
600, we introduce congestion on the link between UCSB
and UDEL, and UDEL observes a substantial drop in band-
width. After switching parents twice, UDEL starts observ-
ing good performance 43 seconds later. Formally, we con-
sider a receiver to have recovered from congestion when it
continuously receives more than 90% of the stable bandwidth
for 15 seconds. We determine the stable bandwidth of a host
based on the bandwidth it receives right before congestion
is introduced. We deﬁne recovery time as the time it takes
for a host to recover, since the onset of congestion.
To gain further insight in the adaptation process of the
protocol, we divide the recovery time into three components
as follows:
• Detection time: This is the duration of time for which
congestion must persist before a victim recognizes this as an
event it should adapt to. In our scheme, we consider conges-
tion to have been recognized when the advertised bandwidth
of a link moves down by one discretized level (Section 4.1).
In this experiment, the detection time is 30 seconds.
• Reaction time: This is the amount of time the protocol
takes to make the ﬁrst parent change after congestion is
detected.
In this experiment, UDEL switches to the host
UMASS in 6 seconds.
• Repair time: This is the additional amount of time the
protocol takes to fully recover since the ﬁrst parent change.
In this experiment, UDEL switches to the host UNC 7 sec-
onds after switching to UMASS.
The detection time captures the time scale at which an
overlay has been designed to adapt to congestion. The re-
action and repair times however measure how quickly our
schemes react given that a decision to adapt has been made.
We now present summary statistics from 60 controlled
experiments. The victims have no descendants in 24 ex-
periments, and an average of 3.1 descendants in the other
experiments.
First we analyze the behavior of the victim hosts alone.
Figure 13 shows the cumulative distribution of each metric
we consider. For most of the cases, recovery time is be-
tween 20 and 45 seconds. Further, the largest contributory
factor is detection time, which is usually between 20 and
35 seconds. In contrast, reaction time and repair time are
relatively short. Narada is a mesh-based protocol running
a distance vector algorithm on the mesh, and two diﬀerent
mechanisms can contribute to reaction time in Narada. In
most of the cases, the victim chooses another neighbor in
the mesh as its new parent. Thus the reaction time in these
cases depends on the frequency of route exchanges between
neighbors, which currently occur once every ten seconds. In
a few cases however, none of the mesh neighbors may oﬀer a
better path to the source, perhaps because all other neigh-
bors are children of the victim.
In such cases the victim
must add a new mesh link to improve performance, and this
process can take longer. Finally, we observe that the repair
time is zero for more than 90% of the cases. This indicates
that typically only a single parent change is involved in the
adaptation process.
Next we analyze the recovery time of the descendant hosts,
1
0.8
0.6
0.4
0.2
)
%
(
e
g
a
t
n
e
c
r
e
P
e
v
i
t
l
a
u
m
u
C
0
-10
0
10
victims
descendants
difference
20
Recovery Time (seconds)
30
40
50
60
Figure 14: Cumulative recovery time of victims and
their descendants
considering only runs where victims have descendants. We
deﬁne diﬀerence as the diﬀerence in recovery time between
the descendant and its respective victim in the same ex-
periment. A positive diﬀerence implies that the descendant
recovers slower than its victim. Figure 14 shows the cumu-
lative distribution of the recovery time of the descendants
and the victims, as well as the diﬀerence. We observe that
the recovery time distribution for victims and descendants
exhibit similar trends. Moreover, more than 80% of descen-
dants recover at the same time as their respective victims,
as shown by the diﬀerence curve. Further analysis indicates
that about 75% of the descendants recover without a change
of parent. In general, it is desirable to minimize the number
of overlay changes when adapting to network congestion, as
it increase the stability of the overlay structure.
Our results indicate that the detection time is a signiﬁ-
cant fraction of the recovery time. Further, the detection
times are around 20 to 35 seconds. Our design choice has
been motivated by two conﬂicting concerns. If the overlay
adapts very quickly to congestion that is usually short in
duration, the beneﬁt of adaptation is small and the overlay
could potentially become unstable. However, if the overlay
adapts too slowly, the applications would suﬀer a perfor-
mance penalty during the transient period. Although we
have found our choice of detection time to work reasonably
well in practice, we believe further studies are needed to de-
termine the proper time scale of adaptation, grounded on a
more rigorous understanding of the characteristics of Inter-
net congestion.
8. DISCUSSION
Our results indicate that End System Multicast can meet
the stringent bandwidth and latency demands of conferenc-
ing applications in heterogeneous and dynamic Internet en-
vironments. Further, to achieve good performance, it is im-
portant that overlays dynamically adapt to both bandwidth
and latency.
This paper exposes three issues that we hope to explore
in the future. First, to construct overlays optimized for con-
ferencing, we employ active end-to-end measurements to es-
timate path bandwidths. While active measurements can
be costly, simple techniques employed in this paper help to
restrict the overhead to about 10–15% for groups as large as
twenty members. However, it is unclear whether the over-
head results scale to larger group sizes. Second, in the ab-
sence of initial network information, self-organizing proto-
cols must take some time to discover network characteris-
tics and converge to eﬃcient overlays. Currently the con-
vergence time is about 4 minutes. While this may be ac-
ceptable in conferencing applications which typically have
a long duration, it may become an issue in other real-time
applications. Finally, our current protocol is designed to
adapt to network congestion on the time scale of tens of
seconds. This design choice is motivated by the inherent
tradeoﬀ between the time scale of adaptation and the sta-
bility of overlay topology. While adaptation at such time
scales may be acceptable when operating in less dynamic
environments, transient degradation of application perfor-
mance may become an important issue in highly dynamic
environments.
As mentioned in Section 2, End System Multicast occurs
in two distinct architectural ﬂavors: peer-to-peer architec-
tures, and proxy based architectures. The discussion in this
paper has centered on End System Multicast in general,
rather than the speciﬁc architectural instantiation. How-
ever, we believe that there are opportunities to address these
new issues in an architecture-speciﬁc way.
Proxy based architectures can have several advantages.
First, multiple multicast groups may share the same proxy
service, which enables sharing of network performance infor-
mation across groups. Second, proxies are persistent beyond
the lifetime of individual groups. This allows proxies to ex-
ploit past history of network performance. Sharing of net-
work information, and leveraging past history help to reduce
the number of active measurements needed in constructing
overlays. Further, eﬃcient overlays may be quickly created
when new groups are instantiated. A third advantage of
proxy architectures is that they are better provisioned. We
expect that proxy environments have more stable network
performance and can leverage the QoS infrastructure on the
network more easily. Finally, proxies are the natural co-
ordination points for managing (network) resources among
multiple groups that use the proxy service. Thus, when con-
gestion occurs, proxies can allocate more resources to groups
with more stringent performance requirements.
While proxy based architectures can have several advan-
tages, peer-to-peer architectures have the attractive prop-
erty that they are completely distributed and can scale to
support millions of groups. This is because each end host
keeps state only for the small number of groups in which
it actually participates. We are currently investigating a
multi-path data delivery framework targeted at these archi-
tectures, where each recipient gets (potentially redundant)
data from the source along multiple paths, with a fraction
of the data ﬂowing along any given path. This multi-path
framework has the potential to address the new issues raised
in this paper. First, because data is received along multiple
paths, degradation in performance along any individual path
does not radically aﬀect the overall performance seen by the
recipient. This enables robust application level performance
even over shorter time scales. Further, data delivery can be
made even more robust with the use of redundancy and er-
ror correction. Second, the multi-path framework enables a
recipient to monitor the performance of several overlay links
concurrently, including (potentially poor) links for which no
previous bandwidth estimate is available. This in turn mini-
mizes the need for active bandwidth measurements, and can
lead to improved performance during the time it takes the
overlay to converge to a good structure.
9. RELATED WORK
Several studies [2, 3, 9, 11] present detailed simulation
results to argue that the performance penalties associated
with an overlay based approach may be low. To our knowl-
edge, this is the ﬁrst detailed evaluation of self-organizing
overlay protocols in a dynamic and heterogeneous Internet
environment.
Several self-organizing protocols have been proposed re-
cently in an overlay setting. Gossamer [2], Narada [3], Yoid
[6] and most recently, Bayeux [13], have only considered
delay based metrics. Further, they have not addressed im-
portant issues pertaining to the dynamic nature of these
metrics. Overcast [9] is targeted at broadcasting and reli-
able data-delivery applications where delay is not a concern.
Thus, it constructs overlay trees optimized for bandwidth
alone. However, as our results suggest, considering both
bandwidth and delay based metrics could potentially enable
more eﬃcient use of network resources without sacriﬁcing
application performance.
ALMI [11] has advocated a centralized approach to over-
lay multicast where algorithms for group management and
overlay optimization are coordinated at a central point. ALMI
currently optimizes the overlay for network resource usage
by constructing minimum spanning trees. However, while
minimum spanning trees are eﬃcient from the network per-
spective, it is not clear that they can perform well from the
application perspective.
10. SUMMARY
Our results indicate that End System Multicast is a vi-
able architecture for enabling performance demanding audio
and video conferencing applications in dynamic and hetero-
geneous Internet settings. In experiments with our Primary
Set, at source rates of both 1.2 and 2.4 Mbps, most hosts
are able to sustain over 95% of the source rate on average,
and yet achieve latencies of less than 100 ms. In extremely
heterogeneous settings such as the Extended Set, the mean
performance attained by each receiver is comparable to the
performance of the unicast path from the source to that
receiver.
Our results indicate that to achieve good performance
for conferencing applications, it is critical to consider both
bandwidth and latency while constructing overlays. For ex-
ample, in experiments with the Extended Set, Bandwidth-
Latency can provide 50% higher throughput than Latency-
Only, and 30–40% lower latencies than Bandwidth-Only for
several ranks. Protocols that do not consider any network
metrics like Random, or those that consider only static net-
work metrics like Prop-Delay-Only perform much worse.
Our techniques introduce a network overhead of 10–15%
for groups with 20 members. Further, they are designed
to adapt at the time scale of 20–35 seconds. Adaptation
at this time scale may be suﬃcient in less dynamic envi-
ronments, and in applications which are willing to tolerate
occasional glitches in performance. Indeed, our techniques
worked reasonably well in the realistic Internet environments
we consider. Our future work includes exploring mecha-
nisms for achieving shorter time scale adaptation targeted
at extremely dynamic environments, and mechanisms for
lowering network costs for larger sized groups
ACKNOWLEDGEMENTS
We are deeply grateful to our contacts at over twenty insti-
tutions who gave us guest accounts and tolerated our exper-
iments. Tung Fai Chan and Annie Cheng developed a cool
visualization tool that helped us develop and debug Narada.
We thank Jason Flinn, Jun Gao, Jorjeta Jetcheva and the
anonymous referees for comments that helped improve the
presentation of the paper.
11. REFERENCES
[1] Deepak Bansal and Hari Balakrishnan. Binomial
Congestion Control Algorithms. In Proc. IEEE
INFOCOM, April 2001.
[2] Y. Chawathe. Scattercast: An Architecture for
Internet Broadcast Distribution as an Infrastructure
Service. Fall 2000. Ph.D. thesis.
[3] Y. Chu, S. Rao, and H. Zhang. A Case for End
System Multicast. In Proceedings of ACM Sigmetrics,
June 2000.
[4] S. Deering. Multicast Routing in Internetworks and
Extended Lans. In Proceedings of ACM SIGCOMM,
August 1988.
[5] S. Floyd, M. Handley, J. Padhye, and J. Widmer.
Equation-Based Congestion Control for Unicast
Applications. In Proceedings of ACM SIGCOMM,
August 2000.
[6] P. Francis. Yoid: Your Own Internet Distribution,
http://www.aciri.org/yoid/. April 2000.
[7] V. Hardman, A. Sasse, M. Handley, and A. Watson.
Reliable audio for use over the Internet. In Proceedings
of INET, June 1995.
[8] V. Jacobson and S. McCanne. Visual audio tool (vat).
http://www-nrg.ee.lbl.gov/vat/
[9] J. Jannotti, D. Giﬀord, K. L. Johnson, M. F.
Kaashoek, and J. W. O’Toole Jr. Overcast: Reliable
multicasting with an overlay network. In Proceedings
of the Fourth Symposium on Operating System Design
and Implementation (OSDI), October 2000.
[10] S. McCanne and V. Jacobson. vic: A ﬂexible
framework for packet video. In ACM Multimedia,
November 1995.
[11] D. Pendarakis, S. Shi, D. Verma, and M. Waldvogel.
ALMI: An Application Level Multicast Infrastructure.
In Proceedings of the 3rd Usenix Symposium on
Internet Technologies & Systems (USITS), March
2001.
[12] S. Savage, A. Collins, E. Hoﬀman, J.Snell, and
T. Anderson. The end-to-end eﬀects of Internet path
selection. In Proceedings of ACM Sigcomm, August
1999.
[13] S.Q.Zhuang, B.Y.Zhao, A.D.Joseph, R.H.Katz, and
J.D.Kubiatowicz. Bayeux: An architecture for scalable
and fault-tolerant wide-area data dissemination. In
Proceedings of NOSSDAV, 2001.
[14] W. Tan and A. Zakhor. Real-time Internet video using
error resilient scalable compression and tcp-friendly
transport protocol. In IEEE Trans. Multimedia, Vol.
1, No. 2, June 1999.
[15] Z. Wang and J. Crowcroft. Bandwidth-delay based
routing algorithms. In IEEE GlobeCom, November
1995.