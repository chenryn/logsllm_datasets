hardware is inherently trustworthy, or at worst buggy
but non-malicious. As a consequence, neither USB nor
mainstream OSes are designed to be robust in the face of
malicious devices. One manifestation of this is the lack of
authentication or confidentiality guarantees at any layer
of the USB standard. As examples, devices self-report
their identity and capabilities without authentication; the
communication primitives at all layers of the protocol
stack (§2) are cleartext; and, prior to USB 3, host-to-
device messages are broadcast across the entire bus [124].
A related issue is that the USB protocol and common
driver stacks emphasize convenience above correctness
and security. For example, hotplugged devices are often
activated without user confirmation. Coupled with the lack
of device authentication, this means that the OS cannot
determine what device the user intended to connect, or
even that a hotplug event was generated by the user rather
than a malicious device [24, 75]. Moreover, malicious
device makers can rely on the near universal availability
of generic class drivers (e.g., for keyboards), since users
expect these devices to “just work.”
USENIX Association  
25th USENIX Security Symposium  399
3
The range and sophistication of USB-based threats
has escalated substantially in recent years. Whereas hard-
ware design costs were once a barrier to entry, creat-
ing custom USB devices is now cheap, both in dollars
and development time [43, 52, 61, 98, 100]; in fact, to-
day’s commodity USB devices are essentially software
defined [43, 75, 98].
The press plays a role too: demonstrating USB attacks
has become fashionable (e.g., recent media hype [6–8, 39,
53, 118] surrounding USB devices with reprogrammable
firmware [43, 84, 125]). A third factor is ease of trans-
mission: malicious USB devices can easily find their way
into the hands of victims [148]. This is partly due to vul-
nerabilities in the supply chain [38, 74, 101, 141], such
as adversarial manufacturers [102]. Intelligence agencies
have also been known to use their resources to intercept
and “enhance” shipments [27, 97], including conference
giveaways [20, 21].
3.2 Threat model
We assume that devices can deviate from the USB specifi-
cation arbitrarily. They may also violate the user’s expec-
tations, for example by masquerading as other devices or
passively intercepting bus traffic. Alternatively, devices
can present a higher-level threat; for example, a storage
device can contain an invalid filesystem that triggers a
bug in a filesystem driver. However, devices that cause
physical damage to the host, with high voltage [86] for
example, are out of scope.
We assume that the host’s OS and drivers can be buggy
but not malicious. We assume the same for the host’s
hardware besides the USB controller and USB devices.
3.3 A taxonomy of USB attacks
Attacks on USB drivers. USB drivers present an at-
tack surface to devices. For example, a driver with an
unchecked buffer access might allow a malicious device
to overwrite kernel memory via an overflow. The space
of possible misbehavior here is vast. For instance, de-
vices might try to deliver more data to the driver than
indicated by the device’s configuration [31]; claim impos-
sible configurations [28, 30]; exceed limits prescribed by
USB class specifications [4, 32, 42]; or produce otherwise
invalid or nonsensical reports [75, 87–89, 92, 137].
The prevalence of these attacks reflects a difficult soft-
ware engineering situation. Since a driver writer needs to
be prepared for an enormous range of undocumented be-
havior, drivers need lots of error checking code; such code
is often ill-exercised and creates complexity, leading to
more vulnerabilities. Indeed, more than half of the vulner-
abilities related to USB drivers in the CVE database [14]
are the result of improper handling of noncompliant USB
transfers; many more such vulnerabilities likely remain
undisclosed [87, 137].
Other attacks on the host via USB. USB can also ex-
pose the rest of the host system’s kernel or user software
to attacks by malicious devices. Recall that USB class
drivers provide an interface between devices and other
kernel subsystems (§2). Leveraging this interface, a USB
flash drive might be used to attack the kernel’s storage
or filesystem drivers [19, 44, 63, 64]. Or the drive might
carry a virus [94] or covertly steal data [140].
Of particular concern is the possibility of attacks in
which the USB host controller uses DMA (direct memory
access) to bypass the CPU and read or write arbitrarily
to RAM [26, 116, 139, 142]. A successful DMA attack
neutralizes essentially all software security measures, al-
lowing the attacker to steal sensitive data, modify running
software (including the kernel itself), and execute arbi-
trary code [128]. And the host controller does not need to
be malicious: misconfigured DMA-capable hardware is a
proven vector for such attacks [153, 154].
Privacy and authentication threats.
Device masquerading. When a device is plugged in, the
host asks the device for information about its capabilities.
The device can respond, disguised as another device or
even another class [29, 41, 43, 65, 85, 120, 125, 150]. For
example, Psychson [43] enables rewriting the firmware
on a cheap USB storage device so that it will act like
a keyboard; similarly, the commercially available “USB
Rubber Ducky” [61] is a programmable keystroke injector
in the guise of a flash drive. Likewise, a malicious hub
can masquerade as other devices [25]. These examples
are more than idle threats: penetration testers regularly
use such tools to breach security systems [3, 24].
Bus eavesdropping. In USB 2 and earlier versions, hubs
broadcast traffic from their upstream port to all down-
stream ports (§2), so any device on the bus can eavesdrop
on traffic from the host to any other device [124]. In all
protocol versions, malicious hubs can eavesdrop on up-
stream and downstream traffic [17, 72]. Furthermore, a
hub need not be malicious: if its firmware is buggy, it can
be exploited by a malicious device [25].
4 Architecture and rationale
The top-level goal of Cinch is to enforce security policies
that enable safe interactions between devices and the host
machine. This enforcement must be done in a way that
respects the requirements outlined in Section 1. In particu-
lar, we must answer two questions in the context of USB:
(1) Where and how can one create a logical separation
between the bus and the host, while arranging for an ex-
plicit communication channel that a policy enforcement
mechanism can interpose on? (2) How can one instantiate
this separation and channel with no modifications to bus
standards, OSes, or driver stacks?
400  25th USENIX Security Symposium 
USENIX Association
4
Blue machine
HID
Storage
USB Core
Printer
Red machine
Gateway
Tunnel
HCI
Hypervisor
IOMMU
Host controller
Root hub
Hub
Trusted components
FIGURE 2—The architecture of Cinch. The trusted components
are surrounded by the dashed line. I/O virtualization separates
the USB host controller from the blue machine’s HCI, redirect-
ing DMA and interrupts to the red machine. The red machine
encapsulates and sends USB transfers through the Tunnel to the
Gateway. Once the Gateway has applied all security policies, it
redirects those transfers to the blue machine’s HCI.
We begin with the logical separation, which Cinch
enforces at the boundary between the host controller and
its driver (HCI), depicted in Figure 1. We choose this
separation point for two reasons: first, it results in a narrow
choke point where software can interpose. Second, the
host controller is “dangerous”—it issues interrupts and
accesses memory via DMA (§2, §3.3)—so there should be
a barrier between it and the rest of the system, including
the modules that administer policy decisions.
The architecture is depicted in Figure 2. After logically
separating the host controller, Cinch attaches it to a new
module, the red machine. The red machine is an endpoint
to a communication channel, the Tunnel. The other end-
point, the Gateway, is positioned at the entrance to the
host that Cinch protects, the blue machine. (These names
are inspired by Lampson’s red/green machine partition-
ing [111].) The Gateway mediates all transfers through
the Tunnel and enforces security policies (for example,
dropping or rewriting USB traffic, as described in §5) be-
fore those transfers reach the blue machine’s USB stack.
To connect the host controller to the red machine, Cinch
uses I/O virtualization hardware, which is widely avail-
able in modern CPUs [70, 71]. Specifically, an IOMMU
provides address translation and protection, which re-
stricts a physical device’s DMA transfers to a designated
memory region (in this case, that of the red machine); and
interrupt remapping provides analogous translation and
protection for interrupts.
the lowest
Instantiation
implementation,
4.1
In our current
layer of
software—the one that manages the hardware resources
and configures the I/O virtualization hardware—is a com-
bination of hypervisor and OS, and is trusted. The red
machine runs on top of this hypervisor and is a full-
fledged virtual machine, with a normal OS that has a
stripped-down USB stack (§6.1). The blue machine is
also a full-fledged virtual machine atop the hypervisor,
and the Gateway is a separate process.
4.2 Discussion
With the instantiation described immediately above,
Cinch meets the requirements described in Section 1. It
isolates devices in the red machine, and its Gateway is
a narrow choke point. It limits overhead to reasonable
factors (§7.5), in part by leveraging hardware-assisted
processor and memory virtualization [68, 123] (as dis-
tinct from I/O virtualization). It works with existing USB
stacks; the main component needed is a driver in the hy-
pervisor, to receive transfers from the Gateway. It works
with a range of OSes because the blue machine runs un-
modified. For the remaining requirements, flexibility is
demonstrated in the next section (§5), and extensibility
arises from Cinch’s software structure (§6.2).
But a disadvantage is the size of the trusted computing
base (TCB) and attack surfaces. Specifically, the TCB
includes a full-featured hypervisor. The attack surface
includes the red machine, which is running a full OS
and which, if compromised, can attack the hypervisor
and the blue machine via the virtualization interface (by
attempting VM escapes, side channel inference, etc.).
There are a number of alternatives that, by tailoring the
hypervisor and red machine, reduce the TCB at the cost
of portability and additional development effort. As an
extreme example, the blue machine could run directly on
the host’s hardware (“bare metal”), with the red machine
running in an untrusted user-level process; the Gateway
would also run in user space. In this setup, there would be
no separate hypervisor; the blue machine would perform
the few required hypervisor-like functions, such as config-
uring the I/O virtualization hardware to connect the host
controller to the red machine process (see [77, 78, 126]).
Compared to Cinch’s instantiation, this one has a smaller
TCB; it also has lower overhead, owing to the absence
of virtual machines. However, it is less portable: each
new blue machine OS needs corresponding “hypervisor”
module and red machine implementations.
One can go further: the Gateway could entirely by-
pass the blue machine’s USB stack, sending device traffic
directly to the corresponding kernel subsystem (for exam-
ple, sending USB keyboard events to the input subsystem).
This would further reduce the TCB, at the cost of even
more development work and less portability.
USENIX Association  
25th USENIX Security Symposium  401
5
Another design point is a hardware-only solution: the
red machine and Gateway would run on a device placed
between USB devices and the blue machine, which would
run as a normal, unmodified host. Compared to Cinch,
this solution is potentially more portable, in that no soft-
ware modifications or reconfiguration are needed. Further,
this solution does not rely on I/O virtualization (which
is widespread but not universal), and it leaves the host’s
virtualization hardware available for other uses. The dis-
advantages are that a hardware solution is likely to be less
flexible, and that building hardware may be substantially
more effort than building Cinch.
A non-solution, in our view, is to implement the Gate-
way in the host’s USB stack, without a separate red ma-
chine. This setup does not have the separation discussed
earlier; it would leave the host and Gateway vulnerable to
DMA attacks by a compromised host controller.
5 Building defenses with Cinch
This section describes some of the defenses (which we
call Policies) that Cinch supports, and the threats (§3)
against which they defend. These Policies are not new;
we discuss previous implementations in Section 8. The
novelty is in providing a platform that makes a range of
Policies straightforward to develop and deploy.
5.1 Detecting attacks by signature
The first strategy is signature matching: dropping mes-
sages that match a known pattern. Defenses in this class
protect against attacks on drivers and user software (§3.3).
The same strategy is used in network security (intrusion
detection [47]) and desktop security (antivirus [11]) and
has been effective in practice, as a first-line defense. The
advantages and disadvantages hold in our context; we
review them briefly.
To begin with, signature generation is flexible and can
be done by victimized companies, individual users, and
designated experts, based on observations of past attacks
and reverse engineering of malicious devices. Further,
shared databases of observed attack signatures can im-
munize others. This strategy also enables rapid responses
to emerging threats: a signature of an attack is typically
available long before the vulnerability is patched.
The principal disadvantage, of course, is that signatures
generally provide protection only against previously ob-
served attacks. Furthermore, they suffer from both false
positives and false negatives: signatures that are too gen-
eral may disable benign devices, while signatures that are
too specialized can fail to catch all variants of an attack.
Cinch’s signature Policy. We implement a signature
matching module in Cinch that compares all USB traffic
from the red machine to a database of malicious payload
signatures. When a match occurs, Cinch disallows further
traffic between the offending device and the blue machine.
5.2 Sanitizing inputs
Another class of defensive strategies detects when devices
deviate from their specification; this is useful for defend-
ing against attacks on USB drivers (§3.3). Given a speci-
fication (say, provided by the manufacturer or converted
from a standards document), Cinch checks that messages
are properly formatted and that devices respond correctly
to commands. While drivers can (and in some cases, do)