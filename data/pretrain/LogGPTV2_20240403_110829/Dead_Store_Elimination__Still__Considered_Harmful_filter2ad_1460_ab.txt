it is equivalent to memset. Unfortunately, this technique
is not reliable when link-time optimization (LTO) is en-
abled, which can merge all the compilation units into
one, giving the compiler a global view of the whole pro-
gram. The compiler can then recognize that the scrub-
bing function is effectively a memset, and remove dead
calls to it. Thus, to ensure this technique works, the de-
veloper needs to make sure that she has the control over
how the program is compiled.
3.3.2 Weak Linkage
GCC and some compilers that mimic GCC allow
developers to deﬁne weak deﬁnitions. A weak deﬁni-
tion of a symbol, indicated by the compiler attribute
__attribute__((weak)),
is a tentative deﬁnition
that may be replaced by another deﬁnition at
link
time. In fact, the OpenBSD explicit_bzero function
(Section 3.1.2) uses this technique also:
__attribute__((weak)) void
__explicit_bzero_hook(void *buf, size_t len) { }
void explicit_bzero(void *buf, size_t len) {
memset(buf, 0, len);
__explicit_bzero_hook(buf, len);
}
because
an
compiler
can
not
the
call
deﬁnition
eliminate
overriding
The
to
of
memset
__explicit_bzero_hook may access buf. This
way, even if explicit_bzero is used in the same com-
pilation unit where it is deﬁned, the compiler will not
eliminate the scrubbing operation. Unfortunately, this
technique is also vulnerable to link-time optimization.
With link-time optimization enabled, the compiler-linker
can resolve the ﬁnal deﬁnition of the weak symbol,
determine that it does nothing, and then eliminate the
dead store.
Used in: Libsodium’s sodium_memzero,
explicit_bzero [14].
libressl’s
1028    26th USENIX Security Symposium
USENIX Association
Availability: Available on GCC and Clang.
Effectiveness: Flawed (defeated by LTO).
3.3.3 Volatile Function Pointer
Another popular
technique for hiding a scrubbing
operation from the compiler
the mem-
ory scrubbing function via a volatile function pointer.
OPENSSL_cleanse of OpenSSL 1.0.2, shown below, is
one implementation that uses this technique:
is to call
typedef void *(*memset_t)(void *,int,size_t);
static volatile memset_t memset_func = &memset;
void OPENSSL_cleanse(void *ptr, size_t len) {
memset_func(ptr, 0, len);
}
The C11 standard deﬁnes an object of volatile-qualiﬁed
type as follows:
An object that has volatile-qualiﬁed type may be
modiﬁed in ways unknown to the implementation
or have other unknown side effects. Therefore any
expression referring to such an object shall be eval-
uated strictly according to the rules of the abstract
machine, as described in 5.1.2.3. Furthermore, at ev-
ery sequence point the value last stored in the ob-
ject shall agree with that prescribed by the abstract
machine, except as modiﬁed by the unknown fac-
tors mentioned previously. What constitutes an ac-
cess to an object that has volatile-qualiﬁed type is
implementation-deﬁned.
The effect of declaring memset_func as volatile means
that the compiler must read its value from memory each
time its used because the value may have changed. The
reasoning goes that because the compiler does not know
the value of memset_func at compile time, it can’t rec-
ognize the call to memset and eliminate it.
We have conﬁrmed that this technique works on GCC,
Clang and Microsoft Visual C, and we deem it to be
effective. It is worth noting, however, that while the
standard requires the compiler to read the value of
memset_func from memory, it does not require it to call
memset if it can compute the same result by other means.
Therefore, a compiler would be in compliance if it in-
lined each call to OPENSSL_cleanse as:
memset_t tmp_fptr = memset_func;
if (tmp_fptr == &memset)
memset(ptr, 0, len);
else
tmp_fptr(ptr, 0, len);
If the memory pointed to by ptr is not read again, then
the direct call to memset, the semantics of which are
known, could be eliminated, removing the scrubbing op-
eration. We know of no compiler that does this and con-
sider such an optimization unlikely.
Used in: OpenSSL 1.0.2’s OPENSSL_cleanse (also
used in Tor and Bitcoin); OpenSSH’s explicit_bzero,
quarkslab’s memset_s [4].
Availability: Universally available.
Effectiveness: Effective in practice.
3.3.4 Assembly Implementation
Because optimizations often take place at compiler’s in-
termediate representation level, it is possible to hide the
semantics of a memory scrubbing operation by imple-
menting it in assembly language. In some cases, this may
also be done as a way to improve performance, how-
ever, our results indicate that the compiler’s built-in in-
trinsic memset performs as well as the assembly imple-
mentation we examined. So long as the compiler does
not perform assembly-level link-time optimization, this
technique is effective at ensuring scrubbing stores are
preserved.
Used in: OpenSSL’s OPENSSL_cleanse (also used by
Tor and Bitcoin); Crypto++’s SecureWipeBuffer.
Availability: Target-speciﬁc.
Effectiveness: Effective.
3.4 Forcing Memory Writes
The fourth set of techniques we found attempts to force
the compiler to include the store operation without hiding
its nature.
3.4.1 Complicated Computation
Several related techniques attempt to force the compiler
to overwrite sensitive data in memory by forcing the
compiler to carry out a computation. OPENSSL_cleanse
from OpenSSL prior to version 1.0.2 is one example:
unsigned char cleanse_ctr = 0;
void OPENSSL_cleanse(void *ptr, size_t len) {
unsigned char *p = ptr;
size_t loop = len, ctr = cleanse_ctr;
if (ptr == NULL) return;
while (loop--) {
*(p++) = (unsigned char)ctr;
ctr += (17 + ((size_t)p & 0xF));
}
p = memchr(ptr, (unsigned char)ctr, len);
if (p) ctr += (63 + (size_t)p);
cleanse_ctr = (unsigned char)ctr;
}
This function reads and writes the global variable
cleanse_ctr, which provides varying garbage data to
ﬁll the memory to be cleared. Because accesses to the
global variable have a global impact on the program,
the compiler cannot determine that this function is use-
less without extensive interprocedural analysis. Since
such interprocedural analysis is expensive, the compiler
most likely does not perform it, thus it cannot ﬁgure
USENIX Association
26th USENIX Security Symposium    1029
out that OPENSSL_cleanse is actually a scrubbing func-
tion. However, this particular implementation is notori-
ously slow (see the performance numbers in Section 4).
OpenSSL gave up this technique in favor of the volatile
function pointer technique (Section 3.3.3) starting with
version 1.0.2.
Another way to scrub sensitive data is to simply rerun
the computation that accesses sensitive data again. This
is used in the musl libc [17] implementation of bcrypt,
which is a popular password hashing algorithm. musl’s
bcrypt implementation __crypt_blowfish calls the
hashing function BF_crypt twice: the ﬁrst time it passes
the actual password to get the hash, the second time
it passes a test password. The second run serves two
purposes. First, it is a self-test of the hashing code.
__crypt_blowfish compares the result of the second
run with the hardcoded hash value in the function. If they
do not match, there is something wrong in the hashing
code. (In fact, the developers of musl libc found a bug
in GCC that manifested in their hashing code [11].) Sec-
ond, the second run of BF_crypt can also clear sensitive
data left on the stack or in registers by the ﬁrst run. Since
the same function is called twice, the same registers will
be used, thus the sensitive data left in registers will be
cleared. Since the two calls to BF_crypt are in the same
scope and the stack pointer points to the same position
of the stack before the two calls, the sensitive data left
on the stack by the ﬁrst run should be cleared by the sec-
ond run. The advantage of this solution is that it clears
sensitive data not only on the stack but also in registers.
While the complicated computation technique appears
effective in practice, there is no guarantee that a com-
piler will not someday see through the deception. This
technique, especially re-running the computation, has a
particularly negative performance impact.
Used in: OPENSSL_cleanse from OpenSSL 1.0.1 (also
used in Tor and Bitcoin), crypt_blowfish from musl
libc [17].
Availability: Universal.
Effectiveness: Effective in practice.
3.4.2 Volatile Data Pointer
Another way to force the compiler to perform a store
is to access a volatile-qualiﬁed type. As noted in Sec-
tion 3.3.3, the standard requires accesses to objects that
have volatile-qualiﬁed types to be performed explicitly.
If the memory to be scrubbed is a volatile object, the
compiler will be forced to preserve stores that would
otherwise be considered dead. Cryptography Coding
Standard’s Burn [9] is one of the implementations based
on this idea:
void burn( void *v, size_t n ) {
volatile unsigned char *p =
( volatile unsigned char * )v;
while( n-- ) *p++ = 0;
}
In the function above, the memory to be scrubbed is writ-
ten via a pointer-to-volatile p in the while loop. We have
found that this technique is effective on GCC, Clang,
and Microsoft Visual C. Unfortunately, this behavior is
not guaranteed by the C11 standard: “What constitutes
an access to an object that has volatile-qualiﬁed type is
implementation-deﬁned.” This means that, while access-
ing an object declared volatile is clearly an “access to an
object that has volatile-qualiﬁed type” (as in the case of
the function pointer that is a volatile object), accessing
a non-volatile object via pointer-to-volatile may or may
not be considered such an access.
Used in: sodium_memzero from Libsodium, in-
secure_memzero from Tarsnap, wipememory from
Libgcrypt, SecureWipeBuffer from the Crypto++
library, burn from Cryptography Coding Stan-
dard [9], David Wheeler’s guaranteed_memset [39],
ForceZero from wolfSSL [27], sudo_memset_s from
sudo [23], and CERT’s C99-compliant solution [37].
Availability: Universal.
Effectiveness: Effective in practice.
3.4.3 Memory Barrier
Both GCC and Clang support a memory barrier ex-
pressed using an inline assembly statement. The clobber
argument "memory" tells the compiler that the inline
assembly statement may read or write memory that
is not speciﬁed in the input or output arguments [1].
This indicates to the compiler that the inline assembly
statement may access and modify memory, forcing it
to keep stores that might otherwise be considered dead.
GCC’s documentation indicates that the following inline
assembly should work as a memory barrier [1]:
__asm__ __volatile__("":::"memory")
Our testing shows the above barrier works with GCC,
and since Clang also supports the same syntax, one
would expect that the barrier above would also work
with Clang. In fact, it may remove a memset call before
such a barrier [6]. We found that Kerberos (more in
Section 5.2) uses this barrier to implement its scrubbing
function, which may be unreliable with Clang. A more
reliable way to deﬁne memory barrier is illustrated by
Linux’s memzero_explicit below:
1030    26th USENIX Security Symposium
USENIX Association
#define barrier_data(ptr) \
__asm__ __volatile__("": :"r"(ptr) :"memory")
void memzero_explicit(void *s, size_t count) {
memset(s, 0, count);
barrier_data(s);
}
The difference is the "r"(ptr) argument, which
makes the pointer to the scrubbed memory visible to the
assembly code and prevents the scrubbing store from be-
ing eliminated.
Used in: zap from Kerberos, memzero_explicit from
Linux [16].
Availability: Clang and GCC.
Effectiveness: Effective in practice.
3.5 Discussion
Our survey of existing techniques indicates that there is
no single best technique for scrubbing sensitive data.
The most effective techniques are those where the in-
tegrity of scrubbing operation is guaranteed by the plat-
form. Unfortunately, this means that creating a scrubbing
function requires relying on platform-speciﬁc functions
rather than a standard C library or POSIX function.
Of the remaining techniques, we found that the volatile
data pointer, volatile function pointer, and compiler
memory barrier techniques are effective in practice with
the compilers we tested. The ﬁrst two of these, relying
on the volatile storage type, can be used with any com-
piler but are not guaranteed by the standard. The memory
barrier technique is speciﬁc to GCC and Clang and its
effectiveness may change without notice as it has done
already.
4 Performance
When it comes to security-sensitive operations like data
scrubbing, performance is a secondary concern. Never-
theless, given two equally good choices, one would pre-
fer one that is more efﬁcient. In this section, we present
our results of benchmarking the scrubbing techniques we
described above under Clang 3.9 and GCC 6.2. Our base-
line is the performance of ordinary memset, both the C li-
brary implementation and the built-in intrinsics in Clang
and GCC. The performance of the C library implementa-
tion represents the expected performance of non-inlined
platform-provided solutions (Section 3.1) and the sepa-
rate compilation (Section 3.3.1) and weak linkage (Sec-
tion 3.3.2) techniques without link-time optimization.
The performance of GCC and Clang intrinsics represents
the expected performance of inlined platform-provided
solutions (Section 3.1) as well as the memory barrier
technique (Section 3.4.3), assuming the scrubbing func-
tion is inlined. We also measured the performance of the
volatile function pointer technique (Section 3.3.3), the
volatile data pointer technique (Section 3.4.2), the cus-
tom assembly implementation of OpenSSL 1.1.0b (Sec-
tion 3.3.4), and the complicated computation technique
of OpenSSL prior to version 1.0.2 (Section 3.4.1).
4.1 Methodology
We compiled a unique executable for each technique and
block size on GCC 6.2 and Clang 3.9 with the -O2 op-
tion targeting the x86_64 platform. A scrubbing routine’s
performance is the median runtime over 16 program exe-
cutions, where each execution gives the median runtime
over 256 trials, and each trial gives the mean runtime of
256 scrubbing calls. Program executions for a given test
case were spaced out in order to eliminate any affects
caused by the OS scheduler interrupting a particular pro-
gram execution. We left the testing framework code un-
optimized. Scrubbing calls were followed by inline as-
sembly barriers to ensure that optimizations to scrubbing
routines did not affect benchmarking code. The bench-
marking code calls a generic scrub function, which then
calls the speciﬁc scrubbing routine to be tested; this code
is allowed to be optimized, so as a result the scrubbing
routine is typically inlined within the generic scrub func-
tion. The scrubbing function and scrubbed buffer size
are deﬁned at compile time, so optimizations can be ex-
haustive. The time to iterate through a loop 256 times
containing a call to a no-op function and memory bar-
rier was subtracted from each trial in order to eliminate
time spent executing benchmarking code and the generic
scrub function call. The runtime for a scrubbing routine
was calculated with the rdtsc and rdtscp instructions
which read the time stamp counter, with the help of the
cpuid instruction which serializes the CPU and thus en-
sures that no other code is benchmarked [34]. Instruction
and data caches were warmed up by executing the bench-
marking code 4 times before results were recorded. Pro-
gram executions were tied to the same CPU core to en-
sure that consistent hardware was used across tests.
The tests were done on an Intel Xeon E5-2430 v2 pro-
cessor with x86_64 architecture and a 32KB L1d cache,
32KB L1i cache, and 256K L2 cache running Ubuntu
14.04 with Linux kernel 3.13.0-100-generic.
4.2 Results
Figures 1 shows the results of our benchmarks. The left
plot (Figure 1a) shows the result of compiling each tech-
nique using Clang 3.9, the right plot (Figure 1b) shows
the result of compiling each technique using GCC 6.2.
In each plot, the x-axis shows the block size being ze-
roed and the y-axis the bytes written per cycle, computed
by dividing the number of cycles taken by the block
size. The heavy solid grey line shows the performance
of plain memset when it is not removed by the optimizer.
The ﬁne solid black line is performance of plain memset
USENIX Association
26th USENIX Security Symposium    1031
(a) Compiled with Clang 3.9.
(b) Compiled with GCC 6.2.
Figure 1: Performance of various scrubbing implementations compiled at optimization level -O2. The x-axis shows the
block size being zeroed and the y-axis the bytes written per cycle, computed by dividing the number of cycles taken
by the block size.
when compiled with the -fno-builtin-memset op-
tion, which instructs the compiler not to use its own built-
in intrinsic memset instead of calling the C standard li-
brary implementation. The remaining dashed lines show
the performance of the volatile function pointer tech-
nique (red line), the custom assembly implementation
from OpenSSL (orange line), the volatile data pointer
technique (blue line), and the complicated computation
technique from OpenSSL (green line).
Large block sizes. At large block sizes, performance
is dominated by the efﬁciently of each implementation.
The largest determining factor of an implementation’s
efﬁciency is the size of its move instructions: “plain
memset” and “volatile function pointer” both jump to
libc’s memset, which performs a loop of movdqa instruc-
tions (24 bytes/instruction); “custom assembly” performs
a loop of movq instructions (23 bytes/instruction); and
“volatile data pointer” performs a loop of movb instruc-
tions (20 byte/instruction). Further, “complicated com-