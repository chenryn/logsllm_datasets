title:CoverUp: Privacy Through "Forced" Participation in Anonymous Communication
Networks
author:David M. Sommer and
Aritra Dhar and
Luka Malisa and
Esfandiar Mohammadi and
Daniel Ronzani and
Srdjan Capkun
CoverUp: Privacy Through “Forced” Participation
in Anonymous Communication Networks
David Sommer
ETH Zurich
Luka Malisa
ETH Zurich
Esfandiar Mohammadi
ETH Zurich
Aritra Dhar
ETH Zurich
Daniel Ronzani
Ronzani Schlauri Attorneys
Srdjan Capkun
ETH Zurich
Abstract
The privacy guarantees of anonymous communication
networks (ACNs) are bounded by the number of par-
ticipants.As a consequence, an ACN can only achieve
strong privacy guarantees if it succeeds in attracting a
large number of active users. Vice versa, weak privacy
guarantees renders an ACN unattractive, leading to a
low number of users.
In this work, we show how to
break this vicious circle. We develop CoverUp, a sys-
tem that “forces” visitors of highly accessed websites
to become involuntary participants of an ACN. CoverUp
leverages basic browser functionality to execute server-
served JavaScript code and to open remote connections
to connect all website visitors to an ACN (which we in-
stantiate by a mix server). We build two applications on
top of CoverUp: an anonymous feed and a chat. We
show that both achieve practical performance and strong
privacy guarantees. Towards a network-level attacker,
CoverUp makes voluntary and involuntary participants
indistinguishable, thereby providing an anonymity set
that includes all voluntary and involuntary participants
(i.e., all website visitors). Given this, CoverUp provides
even more than mere anonymity: the voluntary partici-
pants can hide the very intention to use the ACN. As the
concept of forced participation raises ethical and legal
concerns, we discuss these concerns and describe how
these can be addressed.
1
Introduction
Many privacy-enhancing technologies,
in particular
anonymous communication networks (ACNs) as a key
building block, suffer from a lack of a sufﬁcient num-
ber of participants. Without high user participation,
and therefore without signiﬁcant cover trafﬁc, anonymity
networks become vulnerable to trafﬁc analysis attacks or
suffer from performance loss in terms of their through-
put and latency. The only ACN with a high number of
participants (around 1.5 million users [52]) is Tor [35].
Yet, Tor is known to be prone to trafﬁc analysis attacks,
as illustrated by a wide variety of passive [40, 58, 51]
and active [59, 46, 55] trafﬁc pattern attacks. While
other ACNs [32] have been proposed that are even secure
against global attackers, they suffer from a low number
of participants, since even a perfect ACN can at most
hide a user among all participating users. These ACNs
are in a vicious circle: the lack of participants leads to
low degree of anonymity, and a low degree of anonymity
makes these ACNs unattractive for users. Even if the
number of users produces a large anonymity set, the mere
use of a system can already raise suspicion, which can
serve as a powerful deterrent for a wide range of users.
In this work, we show how these issues can be ad-
dressed through “forced” user participation. The act of
“forcing” users to participate in an ACN enables us to
not only achieve strong anonymity properties via a large
anonymity set, thus helping in bootstrapping an ACN,
but to even hide the intention of those that voluntarily
participate in the ACN.
We design a system, called CoverUp that triggers
users to participate in a centralized, constant-rate mix1
by leveraging the basic functionality of their browsers
to execute (JavaScript) code served by the websites that
they visit. CoverUp is intended to be used on university
or news sites that act as entry servers and serve CoverUp
code to the end-users’ browsers (via an iframe-request
to a CoverUp server) and therefore make them partici-
pate in the ACN. Visitors of these entry servers’ websites
therefore become (involuntary) participants of an ACN
and create cover trafﬁc in which the voluntary partici-
pants can hide their trafﬁc. In addition to the JavaScript
code that is served to the visitors of entry servers’ web-
sites, CoverUp includes a browser extension that is used
by the voluntary participants of the anonymity network.
1While we implement a centralized mix in our case study, our ap-
proach can conceptually be extended to a set of distributed mixes or to
practically any ACN.
1
We use CoverUp in two representative applications: a
feed (e.g., a Wikileaks newsfeed) Wikileaks documents),
and a chat. We evaluate the performance and the pri-
vacy guarantees in all three applications. We show that
they can be practical, provide a high degree of user
anonymity, and enable a user to plausibly deny that it
actively uses CoverUp. In particular, we show through
our prototypical implementations that a strong adversary
cannot distinguish voluntary participants (who addition-
ally installed the CoverUp extension2) from involuntary
participants, which only run the CoverUp code in their
browsers. We assume a strong attacker that can fully ob-
serve the network trafﬁc and can control the entry server.
The feed can tolerate a malicious CoverUp server (which
serves the CoverUp JavaScript code), while the chat re-
quires a trusted CoverUp server.
In the prototype CoverUp the mix servers are im-
plemented as a JAVA servlet API on a Apache Tom-
cat web server. The CoverUp external application and
the browser extension is implemented using Java and
Mozilla Firefox web extension API, respectively. After
a randomized delay of the ﬁrst message to hide leakage,
the CoverUp downlink and uplink rate of our prototype
is 20 Kbit/s and the latency is 36.55 seconds within one
site. We evaluate the privacy guarantees provided by
CoverUp by analyzing differences in the network delays
between voluntary and involuntary users. We show that
the attacker can distinguish voluntary and involuntary
users with an accuracy of 56.3% with an year’s worth
of observations, for a realistic usage pattern.3
Ethical and legal concerns.
“Forcing” participation
might appear intrusive, but it can be implemented with
commonly-used browser functionality and such that the
users are informed about their participation and/or asked
for explicit consent (see Appendix 8 for more). Invol-
untary allocation of resources is nothing unexpected for
a visitor of a webpage; it is already done by advertise-
ments or QoS scripts, such as Google Analytics. In par-
ticular, webpages that incorporate CoverUp would not
cause unexpected behavior on a visitor’s browser. The
computational overhead of CoverUp is negligible but the
trafﬁc overhead for a visitor would be around 7.5MB per
day, which is negligible compared to the data load of
video streaming services. Our work received a formal
approval of our institute’s ethics commission. We ﬁnally
discuss the legal implications for involuntary participants
and for the websites that act as a entry server. We elab-
orate on the liability of the entry server across different
2We assume that voluntary users obtain and install the extension in
an out-of-band fashion or in another way not observed by the adversary.
3As the usage pattern has to be adjusted to the involuntary users, we
assume that a usage pattern of 4 times each working day for 10 minutes
each time (see Section 6.2).
jurisdictions. We also discuss that our system is easy to
deploy for proxies and that there could even be incentives
for participation for both proxies and users. We even
argue that, with an increasing demand for privacy pro-
tection [21, 22], websites could increase their reputation
by supporting a privacy service from their pages, and in
turn privacy-supporting visitors would visit those pages.
We analyzed to the best possible extent the legal impli-
cations of our solutions, but as for similar technologies
(e.g., cookies) ﬁnal judgements are made by the courts
in the different jurisdictions.
In summary, we make the following contributions.
• We introduce a novel concept of privacy by “forced”
participation where we argue that popular services
can help in increasing user participation in privacy
projects and more speciﬁcally in creating cover traf-
ﬁc for anonymous communication. As a result, the
anonymity set includes all visitors of a collaborating
popular service, thereby achieving strong anonymity.
• We design CoverUp, a web-based system that helps
in creating cover trafﬁc for anonymity networks (see
Figure 1).
• We instantiate CoverUp in the context of a feed and
chat application and show that it offers practical per-
formance (see Table 1) and strong privacy guarantees
(see Theorem 1).
• We evaluate the privacy of CoverUp and experimen-
tally evaluate the timing leakage of CoverUp on Win-
dows for, both, voluntary and involuntary participants
(see Figure 6 and Figure 7).
• We discuss the legal for the service that acts as a entry
server and for the involuntary participants. We elabo-
rate on the liability of the entry server and discuss why
the involuntary participants in our view should not ex-
perience any legal issues.
Outline of the paper. Section 2 describes the problem.
Section 3 provides detailed system design and attacker
model of CoverUp. Section 4.1 elaborates on implemen-
tation details. Section 4.2 discusses the overhead that
CoverUp causes and presents the latency and bandwidth
of CoverUp. Section 5 deﬁnes a privacy notion that cap-
tures involuntary being indistinguishable from voluntary
participants and the connections to anonymity notions
from the literature. Section 6 analyzes the privacy of
CoverUp and shows that the direct privacy leakage of
CoverUp solely depends on its timing leakage. Section 7
experimentally evaluates this timing leakage and inter-
prets the privacy results. Section 8, 9, and 10 discuss the
2
ethical and legal aspects of CoverUp, and the deploy-
ment of CoverUp, respectively. Section 11 discusses re-
lated research, and Section 12 concludes the paper and
outlines future work.
2 Problem description
For many privacy-enhancing systems, anonymous com-
munication is a key building block. The anonymity that
an anonymous communication network (ACN) can pro-
vide is limited by the number of participants.
In this
work, we deﬁne and study the following main problem:
Can an anonymous communication network be
strengthened by “forced” participation? What
privacy guarantees and performance can such
an ACN provide?
It is clear that increased participation in an ACN in-
creases privacy. However, increasing privacy in an ACN
through forced participation involves some challenges.
The ﬁrst challenge is to ensure that involuntary partici-
pants can become a part of the ACN without any damage
to their system. Therefore, here, under “forced” partici-
pation we don’t mean that users’ systems are compelled
into participation by infection and malware. Instead, we
assume, and show through our solution, that users can
be made to participate in an ACN through the legitimate
use of existing software and interactions (in our solution,
through their browsers). The second challenge is that
the involuntary participants should not be distinguish-
able from voluntary participants. If an attacker can tell
involuntary participants apart from the voluntary partic-
ipants, increased involuntary participation will not have
an effect on the privacy properties of the ACN. If, how-
ever, the involuntary participants appear just like volun-
tary participants for an attacker, the resulting system will
not only have in a larger anonymity sets but will also
provide plausible deniability for voluntary participants.
Namely, the voluntary participant can always claim that
it was made to participate in the ACN and is not its active
user (i.e., that it is an involuntary user).
The requirement that involuntary participants have to
look the same as voluntary participants makes this prob-
lem particularly challenging. We have to be able to run
code on the machine of an involuntary participant, with-
out damaging her system. At the same time, we have to
develop a toolchain that enables voluntary participants to
use the ACN, while carefully ensuring that they produce
the same observable communication patterns. Since such
a toolchain might introduce additional computations, it
can be prone to producing an observable delay.
To highlight why this is a new type of problem, we
contrast it to anonymous communication systems based
on covert channels. Covert channels use a piggyback ap-
proach to transport data, they depend on existing data
streams, resulting in a dependency of the piggybacked
system for latency, throughput and privacy. An ACN
based on forced participation can create its own cover
trafﬁc and therefore control (i.e. tune) the achieved pri-
vacy, latency and throughput. All other things equal,
such an ACN will also result in higher throughput and
lower latency. However, the privacy properties that a
forced participation systems achieve differ from those of
covert channels. While some covert channels can hide
whether communication took place, and thus achieve
full deniability, forced participation systems make vol-
untary and involuntary participants indistinguishable and
therefor provide plausible deniability. Section 11 thor-
oughly discusses the relationship to covert channels such
as [50, 45, 38, 60].
3 CoverUp
We address the challenges involved in forcing participa-
tion by developing a prototype system, which we name
CoverUp. Section 3.1 presents the uni-directional chan-
nel and how it is used to implement a feed. Section 3.2
shows how this design can be extended to implement a
bi-directional channel.
Our system leverages common and widely-used
JavaScript-functionality of browsers to cause visitors
of a cooperating web site to produce cover trafﬁc for
CoverUp users. We call this website the entry server and
it could be a university, a knowledge site, or a news site.
As depicted in Figure 1a (Step 1), this entry server in-
cludes in its webpage a request to a dedicated server (the
CoverUp server). The CoverUp server responds with
a JavaScript code snippet (Step 2), which triggers the
browsers of the visitors (Step 3) to produce constant rate
cover trafﬁc to a dedicated server (the mix server). The
mix server responds to all parties with the feed (Step 4).
The voluntary participants of CoverUp extract the con-
tent, e.g., from the feed, via an external application (Step
5). We assume that this external application is retrieved
out of band. Involuntary participants do not have an ex-
ternal application installed and will therefore not retrieve
the feed; instead, they only generate cover trafﬁc via the
JS code served by the CoverUp server.
The privacy provided by CoverUp is tied to the brows-
ing behavior of the involuntary participants. Section 6.2
discusses the resulting limitations and their implications.
3.1 Uni-directional channel (feed)
This set-up constitutes a uni-directional channel, over
which the mix server can send information to voluntary
participants. The browser stores the data received by the
3
(a) Uni-directional channel: feed.
(b) Bi-directional channel: chat.
Figure 1: Main components of CoverUp. (a) CoverUp uni-directional channel enables participants to anonymously download
feeds, while assuming no trust in any of the servers that they connect to. (b) CoverUp bi-directional channel supports anonymous
chat with minimal trust assumptions on the CoverUp and the mix server. The mix server only makes sure that the participant’s
communication is properly mixed and therefore cannot be subject to trafﬁc correlation attacks.
mix server into a database (the localStorage), out of
which the external application retrieves the content. With
this uni-directional channel, we implement a continuous