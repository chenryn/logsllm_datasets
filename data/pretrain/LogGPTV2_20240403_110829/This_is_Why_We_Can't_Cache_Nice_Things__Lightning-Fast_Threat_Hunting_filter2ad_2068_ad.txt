with Equation 1.
SI S (P ) = 1 − l(cid:89)
I N (SRCi ) × M (εi ) × OU T (DSTi ) × α
(1)
i =1
The details about the above-mentioned equation can be found
in [41]. At a high-level, I N and OUT are two vectors that quantify
the likelihood that the vertex is a source or destination of informa-
tion flow, respectively. M is the transition probability from SRCi
vertex to DSTi vertex. α is a normalization factor. I N , OUT , M,
and α are parameterized based on observations of historic benign
data from the enterprise deployment. This equation satisfies all
three properties mentioned in Section 4.2. Cumulativity is satisfied
because this equation calculates score of each event by taking the
product of all previous events’ aggregate score and the new event’s
score. Temporality is preserved because the product is taken over
a causal path, which is sorted temporally by definition. If a new
event is added to two paths, the subtraction of their SIS (P ) will be
multiplied by the same factors, which will not change their orders.
Therefore, monotonicity is satisfied.
8.2 Experiment Setup
We collected system events and threat alerts at NEC Labs America.
In total, we monitored 191 hosts (51 Linux and 140 Windows OS)
for 10 days. We deployed Swift on a server with Intel® Xeon(R)
CPU E5-2660 @ 2.20GHz and 64 GB memory running Ubuntu 16.04
OS. We connected Swift to ASI [13], a commercial anomaly-based
TDS, to generate alerts. During the engagement, we injected 10
APT attacks over a period of 10 days. These APT attacks were
designed by expert analysts employed at NEC Labs America. A
short description of these attacks is shown in Table 1. On each day
we injected one attack, except for 3 attacks (Datatheft, ShellShock,
and Netcat backdoor) which were ran on the same day.
We collected more than 1 TB worth of audit logs with around 1
billion system events from 191 hosts over period of 10 days. The
APT attack traces constitute less than 0.0005% of the total audit logs
collected from the enterprise. Meanwhile, we also monitored these
logs with a commercial TDS [13]. This underlying TDS generated
140 threat alerts over a period of 10 days. Out of these 140 alerts,
12 were true alerts generated by our simulated APT attacks, while
the rest were false alerts.
To evaluate Swift against a baseline approach, we re-implement
NoDoze based on its description in [41]. We chose this as a base-
line because it is one of the most recent offline approach that can
perform: 1) suspicious score assignment, 2) automated alert triage
and 3) causality graph generation. Further, our decision to imple-
ment Swift using NoDoze’s suspicious influence scoring algorithm
permits an apples-to-apples comparison when evaluating Swift’s
HSM. We used 20 consumer threads to consume audit logs from
Kafka producers and then we performed forensic analysis in real-
time. Note that 20 threads is also the maximum number of threads
supported by the machine we use in our evaluation.
Parameters. We set ∆Tpromote = 800 seconds, GL size K = 3000,
PAT Habnormal size m = K/3, and ∆Tevict = 1600 seconds in all
experiments unless we explicitly note otherwise. We chose these
values because they generate the optimal throughput and can hold
all the suspicious data in our enterprise. However, we also discov-
ered that it is flexible to choose the parameters for Swift since
the throughput is not heavily affected by the value of the parame-
ters. A detailed discussion of how we derived these values for this
enterprise environment is included in Appendix A.1.
RQ1: Effectiveness in Alert Investigation
To answer this question, we used Swift to generate the most suspi-
cious causal graph for all 140 threat alerts, measuring the response
time for answering each causal graph query. We issued each query
at the end of the day, not immediately following the attack, which
ensured: 1) all attack related events had been evicted from the track-
ing cache, and were thus either in the suspicious cache or on disk; 2)
a steady state for the HSM where all promotion and eviction cycles
were completed for that day. We manually verified the fidelity of
Swift’s causal graph for each alert against the graphs generated
by the baseline approach, checking that Swift returned all of the
critical events necessary to explain the attack.
The results for Swift are shown in Figure 6; Swift was able
to respond in less than one second for 80% of the alerts because
of our novel suspicion-based HSM. In total, Swift took less than
two minutes to generate the concise causal graphs for all alerts. We
compare these results to the baseline approach in Figure 7, noting
that the scale on the x-axis has changed from seconds to minutes.
It took more than 1 hour for the baseline approach to process the
same set of alerts. Moreover, the baseline approach took more than
three minutes for 40% of the alerts and more than 20 minutes for
25% of the alerts, in the worst case taking more than an hour to finish.
Such a slow response time is problematic, especially considering
realistic scenarios in which the processing latency for one alert
adds to the queuing latency of hundreds of other alerts in the stack
(discussed more in RQ3).
A breakdown of performance results for each attack are shown
in Table 2. The rightmost columns show the response time for the
baseline method, Swift, and observed speedup. In all cases, Swift
generated the causal graph for the attack in less than 3 milliseconds,
whereas the baseline required nearly 5 minutes in the worst case.
Comparing the two techniques, we observe a speed up of up to 1.3
million times (Shellshock). In spite of the performance increase,
it may at first glance seem that the performance of the baseline
approach is acceptable. One reason for this is that the underlying
TDS used in our experiments itself maintained a 15GB event cache
that was able to store part of the attack provenance for the baseline
(compare this to the 300MB cache required by Swift, which we
will show in Section 8.2). More importantly, a limitation of our
evaluation is that it does not capture longitudinal attack patterns
that are commonly observed in-the-wild, e.g., the 4.5 month attack
window of the Equifax breach [29]. In such circumstances, the TDS
8
Table 1: APT attack scenarios used in our evaluation with short their descriptions.
Attacks
VPNFilter [10]
Redis-Server
wget-gcc [74]
WannaCry [9]
Data Theft [57]
ShellShock [7]
Netcat Backdoor [8]
Short Description
An attacker used known vulnerabilities [7] to penetrate into an IoT device and overwrite system files for persistence. It then
connected to outside to connect to C2 host and download attack modules.
Example case study in Section 8.2
Malicious source files were downloaded and then compiled.
An attacker exploits EternalBlue [20] vulnerability in enterprise to gain access to machines and then attacker encrypts data
on those machines.
An attacker downloaded a malicious bash script on the data server and used it to exfiltrate all the confidential documents on
the server.
An attacker utilized an Apache server to trigger the Shellshock vulnerability in Bash multiple times.
An attack downloaded the netcat utility and used it to open a Backdoor, from which a Persistent Netcat port scanner was
then downloaded and executed using PowerShell
Cheating Student [61] A student downloaded midterm scores from Apache and uploaded a modified version.
passwd-gzip-scp [74]
An attack stole user account information from passwd file, compressed it using gzip and transferred the data to a remote
machine
An attack remotely exploits in-car information system and gains control over physical components (e.g., wheels, breaks,
engines) by sending out commands via CANBUS.
Jeep-Cherokee [64]
were related to attacks in the main memory even if the size of the
cache was small compared to the size of total events. Particular, on
average, by maintaining about 0.04% of total events of a day, Swift
can maintain on average 90% of attack-related events in its cache. In
other words, Swift was able to significantly reduce disk IOs while
generating causal graphs for attacks. This result also validates our
Hypothesis H2. Reasons for why Swift cannot maintain 100% of
the attack-related events in its cache will be discussed in RQ2.
RQ2: Insights into Cached vs Spilled Events
To further study how causal events are handled in the Swift HSM
(i.e. which events are cached, as opposed to being spilled to disk),
we select a ransomware attack as a case study from the 10 attacks
in Table 2. In this attack, a misconfigured Redis server [25] allows
an attacker to log into the server via the ssh service as root [23].
The attacker first connects directly to a misconfigured Redis server
over its default port, executes the Flushall command to erase the
whole database, uploads their ssh key to the database, then obtains
root access to the server by using CONFIG to copy the database to the
root’s .ssh directory and renaming it to authorized_keys. Once in
the enterprise network, the attacker moves laterally in their search
for valuable data while simultaneously encrypting data by running
an encryptor that was downloaded from their remote server. Time
is crucial in this scenario – the earlier we investigate and respond to
the attack, the more valuable data we can save.
This attack generated two alerts which are marked in red dashed
arrows in Figure 8. However, these true alerts are among a deluge
of unrelated false alerts being generated by TDS, making it criti-
cal to quickly identify the true alerts and take actions to prevent
damages. Fortunately, Swift assigns suspicious influence scores in
real-time; when Alert 1 arrives, Swift automatically remembers
its suspiciousness score and propagates this score to its successors.
When Alert 2 fires, Swift combines the suspiciousness influence
scores from Alert 1 in O(1) time. This means that as soon as Alert
2 is fired by TDS, Swift can instantaneously generates the most
suspicious causal graph and correlate the alerts.
Figure 8 shows the simplified causal graph of this attack. In
this graph, we use diamonds to represent sockets, oval nodes to
Figure 6: Response times in seconds to return concise causal graphs
of threat alerts using Swift.
Figure 7: Response times in minutes to return concise causal graphs
of threat alerts using Swift as compared to NoDoze (baseline). Note
that the Swift CDF is the same as in Figure 6 on a different scale.
cache would be useless and the baseline may take hours or days to
process individual alerts.
To further investi-
Reasons for Milli-second Level Response Time.
gate the reason for the time reduction, we also studied what was
maintained in the memory for these attacks. In Table 2, the col-
umn “All Events” represents all enterprise-wide system events col-
lected while “Critical Events” represents only attack-related events.
“%Cached” shows the percentage of events cached in the memory
end of the day. Our experiment shows that Swift had a much lower
response time because it effectively cached most of the events that
9
 0.4 0.6 0.8 1 0 10 20 30 40 50 60 70 80CDFResponse Time [sec] 0.4 0.6 0.8 1 0 10 20 30 40 50 60 70CDFResponse Time [min]NoDozeSwiftTable 2: Comparison of Swift’s effectiveness against baseline. “#Alerts” shows how many alerts are associated with the particular attack.
Attacks
Reference
#Alerts
VPNFilter
Redis-Server
wget
WannaCry
Data Theft
ShellShock
Netcat Backdoor
Cheating Student
passwd-gzip-scp
Jeep-Cherokee
NoDoze [41]
Case Study Sec. 8.2
Xu et al. [74]
NoDoze [41]
PrioTracker [57]
CVE-2014-6271
Backdoor [8]
ProTracer [61]
Xu et al. [74]
Exploit Vehicle [64]
1
2
1
2
1
1
1
1
1
1
All Events
Critical Events
Response Time
Total
150M
100M
160M
139M
366M
366M
366M
336M
335M
129M
%Cached Total
0.06%
0.07%
0.03%
0.05%
0.04%
0.04%
0.04%
0.03%
0.02%
0.06%
15
29
15
21
13
25
14
37