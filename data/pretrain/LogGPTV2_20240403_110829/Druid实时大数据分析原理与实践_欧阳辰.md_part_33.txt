276
"metricsspec":[
"parser"
"parseSpec"
"type":
"fieldName"”:“visit_qidianid"
"name"
"type"
'name"
'timestampSpec":
"dimensionsSpec"
"format":"json"
"format":"auto",
"dimensionExclusions"：[]
"dimensions":[
"ad_content"
"ad_term",
"ad_campaign"
'ad_media",
"ad_source"
'is_sem"
"is_ad",
"is_new"
"device_type",
"host",
"corpuin",
"tid",
"hadoopyString",
"hyperUnique"
"visit_count"
"count"
"count"
"timestamp"
Druid实时大数据分析原理与实践
---
## Page 301
第10章
"filter":
"dimensions": ["ad_source", "ad media", "ad_campaign", "ad term"],
"granularity":"all",
"dataSource":"visitor_stat_funnel",
"queryType":"groupBy",
查询语句如下：
'tuningConfig":[
"jobProperties":{...}
"cleanupOnFailure":false,
"maxRowsInMemory":100000,
"partitionsSpec":
"type" : "hadoop",
"type":"and",
"targetPartitionSize": 5000000
"type" : "hashed",
实践和应用
"fieldName":"after_talk_indb_qidianid"
"type" : "hyperUnique",
"name":"after_talk_indb_count"
"fieldName" : "before_click_indb_qidianid"
"name":"before_click_indb_count"
"fieldName":"click_wpa_qidianid"
"name"
"click_wpa_count"
---
## Page 302
聚合器。
占用3.83MB；HyperUnique占用500KB。因此，需要结合业务的使用情况和存储空间来选择
始数据集的情况下，人库一天的数据存储占用情况为：原始数据集占用1.2GB；ThetaSketch
个筛选条件的交集做去重统计，但是ThetaSketch需要耗费更多的存储空间。在具有相同原
和ThetaSketch两种聚合器。在去重统计基数方面，ThetaSketch 相比HyperUnique可以支持多
278
'event":
"timestamp"
'version"
聚合器对比：在上例的优化过程中，由于涉及基数统计，故可以考虑使用HyperUnique
"after_talk_indb_count":66.05385244590596
"before_click_indb_count":75.37001710790979,
"click_wpa_count":77.44604364148258,
"count": 6996,
"visit_count":3833.9509193395515,
查询结果如下：
"intervals":["2016-08-28T00:00:00+08:00/2016-08-29T00:00:00+08:00"]
'aggregations":[
{"type":"hyperUnique”,“name"”:"after_talk_indb_count","fieldName”:
{"type":"hyperUnique"，“name":"before_click_indb_count",
{"type":"hyperUnique",
{"type":"hyperUnique",
{"type":“longSu",，"name":"count"，"fieldName":"count”},
"fields":[
after_talk_indb_count"}
before_click_indb_count"},
{"type":"selector", "dimension":"host", "value":"wap.qidian.qq.com"}
"√1"
"2016-08-27T16:00:00.000Z"
"name":"click_wpa_count","fieldName":"click_wpa_count
"name":"visit_count","fieldName":"visit_count"},
Druid实时大数据分析原理与实践
"fieldName"：
---
## Page 303
合存放到Druid集群中以供后端分析应用查询使用。
Topic，然后Druid集群就会通过其KafkaFirehose来拉取并消费数据，最终将指标数据都聚
处理数据，在完成数据处理后会立刻将数据打回到Kafka集群中的另外一个供Druid消费的
紧接着，多个对数据进行逻辑处理的数据消费者（DataConsumer）会根据既定逻辑拉取并
数据的数据包进行解压缩，接下来立刻将解压缩后的数据存放到作为中转缓存的Kafka集群。
端集群通过Nginx来接收这些指标数据，然后通过多个数据收集器（DataCollector）对指标
监控对象的指标数据，然后通过网络将包含指标数据的数据包发送到后端集群进行处理。后
据的实时处理。目前，OneAPM主要有三个产品线在同时使用Druid。
并且在其核心的指标数据（MetricData）处理模块中利用Druid成功地完成了对海量时序数
技术解决方案的部分数据（主要是指标数据）来源及其处理要求具有如下几个主要特征。
性能、可用性及质量进行分析，最终实现对IT基础架构的性能进行管理。不难看出，OneAPM
据包捕获等技术，获取软件与系统在运行时产生的各种性能数据或指标，从而对应用程序的
地位。从技术上讲，OneAPM的产品主要是通过字节码工具（ByteCodeInstrument，BCI）或数
管理（InformationTechnologyOperation Management,ITOM）领域，目前在国内处于行业领先
注于企业应用性能管理（ApplicationPerformanceManagement，APM）与企业级信息系统运维
10.4
第10章
鉴于上述数据特点，OneAPM的数据解决方案中包含了适合其应用场景的Druid项目，
创立于2008年的蓝海讯通科技股份有限公司（OneAPM）是一家科技型的创业公司，
目前，上述三个产品使用Druid的大致架构体系相同：通过自己产品的探针来实时采取
·Browser Insight（Bi）：基于真实用户的Web前端性能监控平台，主要用于统计分析
·数据处理要求能及时、准确完成，否则难以对其所监控的系统进行有效管理。
·数据有很明显的时序特征。
ApplicationInsight（Ai）:
·数据主要由机器或软件系统产生，且频率较高，是典型的大数据。
页面。
网站流量，定位网站性能瓶颈，并且支持浏览器、微信、APP 浏览HTML和HTML5
性能管理平台级解决方案，主要应用在服务器端应用性能监控与管理上。
应用性能测试。
蓝海讯通
实践和应用
一个贯穿应用系统全生命周期的真实用户体验管理和应用
专
279
---
## Page 304
且重要的特点。下面举个简单的例子，假如我们想执行聚合粒度为10分钟的查询，如：
后数据的最小精度便固定了，而低于该精度的细节也都已经丢失了。这是Druid的一个基本
但不支持执行小于其查询粒度的聚合查询—也就是说，Druid在聚合消费数据并存入集群
因为Druid支持在DataSource上执行大于或等于其查询粒度即queryGranularity的聚合查询，
Druid集群中只创建一个能满足最小查询粒度的DataSource（如1分钟的DataSource）即可
为了满足不同聚合粒度的查询（比如上述的1分钟、10分钟和1小时等），其实完全可以在
却大致相同仅聚合粒度不同的DataSource？其实大家的疑惑是有道理的，毕竞如果仅仅是
名为：
聚合粒度分别是1分钟、10分钟和1小时。为了方便介绍，我们为这三个DataSource分别取
的 Schema也基本相同，仅仅是数据的聚合粒度不同——通过queryGranularity进行设置，其
它用三个不同的DruidDataSource来消费同一个KafkaTopic，并且这三个DruidDataSource
案（本文中均简称为“金字塔方案”）。
的Druid使用细节了，仅仅描述其中一个重要的使用特点一金字塔式的DataSource存储方
DataSourceSchema的定义与使用Query的种类等。由于篇幅有限，这里就不再详细描述所有
不同的数据消费方式。
280
在OneAPM公司基于Druid的解决方案中，主要是Ai这个产品使用到了金字塔方案：
虽然这三个产品使用Druid的大致架构体系相同，但是它们各自的Druid集群却采取了
"granularity":{
"dataSource":"{DATASOURCE_NAME}",
"queryType":“groupBy"，
有读者看到这里估计会感到奇怪：为什么要对同一个KafkaTopic创建三个独立但Schema
·druid_metric_lhour，聚合粒度是1小时。
·druid_metric_10minute，聚合粒度是10分钟。
·druid_metric，聚合粒度是1分钟。
除了使用不同的数据消费方式外，每个产品对Druid的各个使用细节也不尽相同，比如
·Druid索引服务：Mi
·Druid实时节点：Ai，Bi
"origin":"2015-11-09T02:00:00"
"type":"duration"
"duration":60000,
Druid实时大数据分析原理与实践
---
## Page 305
结果（均仅取查询结果返回集的最后一个结果做展示）：
如果将该查询作用到聚合粒度为1分钟的DataSourcedruid_metric，
第10章
?
"version":“v1",
在上述的查询语句中，我们通过granularity设置了查询粒度为60000毫秒（即10分钟）。
"intervals":[
"filter":
"aggregations":
"dimensions":[
"2015-11-09T02:00:00/2015111-09T04:00:00
"fields":[
"type":"and",
"metricId"
"applicationId",
实践和应用
"fieldName":"num1”
"type":"LongSum"
"value":“444187722"
"dimension":"metricId",
"type":“selector",
"value":“1007323"
"dimension":"applicationId",
"type":"selector",
都可以得到如下相同的
281
---
## Page 306
行所花费的时间）。
聚合粒度的查询。以下是其中的一组对比结果（为排除缓存的作用，仅记录了查询被首次执
比试验：分别在最低聚合粒度为1分钟、10分钟和1小时的DataSource上做不同时间跨度与
的结果。但是，可能有读者又会好奇：这类查询的性能又如何呢？我们在实际数据上做过对
为1分钟的聚合查询，还完全能够满足大于其最低粒度的10分钟的聚合查询并能返回正确
282
简单的 groupBy查询
DataSource
聚合粒度
简单的 groupBy查询
DataSource
聚合粒度
简单的 groupBy查询
DataSource
聚合粒度
按24小时聚合的对比数据如下表所示。
按1小时聚合的对比数据如下表所示。
按10分钟聚合的对比数据如下表所示。
这就证明了，聚合粒度为1分钟的DataSourcedruid_metric在功能上不仅能够满足粒度
"event":{
"timestamp":"2015-11-09T03:50:00.000Z",
"num1":212
"applicationId":"1007323"
"metricId":"444187722",
0m0.298s
druid_metric
按1小时聚合
0m0.389s
druid_metric
按10分钟聚合
0m16.017s
druid_metric_lhour
按24小时聚合
0m0.296s
druid_metric_lhour
按1小时聚合
0m0.194s
druid_metric_10minute
按10分钟聚合
Druid实时大数据分析原理与实践
0m0.577s
druid_metric
按24小时聚合
---
## Page 307
因此Druid已经成为了OneAPM技术栈中重要的一环。
数据的实时消费与查询，也在其企业级产品中同样通过Druid处理了日益增长的企业数据，
此基础上提供很高的存储性价比，因此很自然地被接纳而作为了数据存储的指导方案。
因，金字塔方案不仅能够满足OneAPM产品对不同时间范围内的查询粒度需求，还能够在
就只会提供小时或更高粒度级别的查询了——这其实符合客户实际的查询需求。由于这个原
它能够提供10分钟级别粒度的查询；而对于更久远的时间范围，比如15天甚至几个月，它
据查询接口来说，对于最近几个小时，它能够提供1分钟级别粒度的查询；对于最近几天，
粒度越高，因为此时往往只需要查一个趋势而非细节。就拿OneAPM产品所提供的指标数
时间范围内的查询所需要的聚合粒度越低，而对于越久远的时间范围内的查询所需要的聚合
所需的存储空间越大。与此同时，对于大多数时序数据库的使用场景来说，一般对于越近的
Replication:1)。
更好地理解这个优势点，我们先看一个根据自己的数据所做的对比表格（单位：GB，Segment
储空间方面获得更高性价比的存储效率，其实这是影响我们做出选择的一个更大因素。为了
能获得更佳的查询效率。
优势：提供不同聚合粒度的DataSource，让查询作用在更接近其粒度的DataSource上，从而
放大，从而使得差距变得很明显。正是因为这个原因，我们看到了金字塔方案带来的第一个
快。这个规律在聚合的数据量变大的情况下，比如按24小时聚合时，这种性能的差距会被
基本符合一个规律：DataSource本身的聚合粒度越接近聚合查询指定的粒度，查询的速度越
10分钟聚合，虽然在不同的DataSource上查询执行时间的绝对时间相差也不大，但是依然
第10章
druid_metric_lhour
druid_metric_10minute
druid_metric
DataSource
目前，OneAPM不仅在其SaaS平台上通过使用Druid技术成功地完成了对其海量指标
我们可以通过图10-9对Druid金字塔存储方案的特点做一个总结。
根据上表我们可以很轻松地得出一个符合推理的试验结论：聚合粒度越低时，单位时间
然而，查询性能的优势并不是我们选择金字塔方案的唯一原因，它有时能够让我们在存
从上面的表中可以看出，在聚合查询的时间跨度即聚合的数据量不大的情况下，比如按
实践和应用
0.18
0.52
1.30
小时存储成本
4.32
12.48
31.20
天存储成本
133.92
386.88
967.20
月存储成本（31天）
283
---
## Page 308
应用场景，从而为Druid技术的更广泛应用贡献自己的力量。
可以早日掌握Druid这项技术，让它为自己产生效益，并且还能够创新出其他的使用技巧与
在实践中碰到的问题驱动自己对Druid技术的学习和理解。通过实践的方式，相信大家不仅
后应该尽快上手练习，并且争取早日将其应用到自己的实际工作中，在战斗中学习战斗，让
学习其他技术一样，掌握Druid最好的方法就是实践，因此大家在对Druid有了一定的认识
自己公司解决方案或应用系统中的思路或方案。“纸上得来终觉浅，绝知此事要躬行”，如同
对Druid有了更加全面和深入的了解，甚至可能已经产生了一些比较具体的将Druid应用到
10.5小结
284
通过对上述不同企业技术团队对Druid的实践案例与经验的介绍，相信读者朋友们已经
可查询时间范围
图10-9Druid金字塔数据存储方案
DataSource
按10分钟聚合
Druid实时大数据分析原理与实践
可查询时间粒度
---
## Page 309
图中提及的一些主要组件做简单的说明。
者了解学习和使用这类开源组件的基本思路和方法。本章只会对“Druid数据分析生态系统"
点介绍Imply.io公司推出的几款组件（Plywood、PlyQL和Pivot）以及其他几个项目，以供读
开发人员。
Druid生态软件，其中包括 Implyio公司及其产品，它的核心创始人都来自于Druid的核心
着生态系统的完善。
括多个以Druid为核心的数据分析平台。另外，Druid在互联网公司的广泛应用也不断推动
重要原因就是Druid的生态系统日渐完整，包括数据管理能力、数据接口访问能力，甚至包
11.1.
并未停止进化升级，其生态正在逐步发展壮大一
常需要仰仗其周边生态体系的繁荣与成熟。作为一款越来越受关注的软件产品，Druid本身
由于Druid相关的开源项目比较多，很难在本章中对它们都进行详细的介绍，因此仅重
如图11-1所示，从数据源、数据管理、数据接口、可视化等方面列举了一些相关的
最近几年数据分析软件层出不穷，Druid在竞争激烈的行业中持续保持高速发展，其中
在当今软件行业中，一款软件的成功不仅需要依赖于自身生生不息的进化与完善，还常
Druid生态系统
一这一切都彰显了Druid旺盛的生命力。
Druid生态与展望
第
章