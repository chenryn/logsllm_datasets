system to issue a warning if, e.g., the user is about to fall
victim to a phishing attack.
Hardware Keyloggers. Resistance to physical attacks is
not an explicit goal of Bumpy; however, the issue warrants
discussion. Bumpy’s resilience to hardware keyloggers de-
pends on the model used for associating new input devices
with the user’s computer. If a simple plug-and-play archi-
tecture is allowed, then a hardware keylogger inserted be-
tween the input device and the user’s computer can appear
as a new input device to the computer, and a new computer
to the input device. One alternative is for input devices
to require manufacturer certiﬁcation before the user’s com-
puter will associate with them. However, this may prove to
be impractical, as users may perceive all certiﬁcation errors
as indicative of a broken device. The core research chal-
lenge here is the problem of key establishment between de-
vices with no prior context [3, 20, 33].
11 Conclusion and Future Work
We have described Bumpy, a system that protects users’
sensitive input from keyloggers and screen scrapers by ex-
cluding the legacy OS and software stack from the TCB for
input. Bumpy allows users to dictate which input is consid-
ered sensitive, thus introducing the possibility of protecting
much more than just passwords. Bumpy allows webservers
to deﬁne how input that their users deem sensitive is han-
dled, and further allows users’ systems to generate attesta-
tions that input protections are in place. With a separate
local device, Bumpy can provide the user with a positive
indicator that her input is protected. We have implemented
Bumpy and show that it is efﬁcient and compatible with ex-
isting legacy software.
We intend to continue the pursuit of a usable solution for
protecting more sizeable input, e.g., composing a sensitive
letter. We also plan to evaluate the current Bumpy architec-
ture with a formal user study.
12 Acknowledgments
The authors would like to thank Karthik S. Lakshmanan
and Anthony Rowe for their advice regarding embedded
Linux systems and USB. Bryan Parno and Ahren Studer
provided feedback and suggestions for the design, imple-
mentation, and writing. We are grateful for observations by
the CyLab Student Seminar audience on October 17, 2008,
and the Security Group Lunch audience at UNC on Novem-
ber 12, 2008. Unrestrained comments from our anonymous
reviewers also proved helpful.
References
[1] Advanced Micro Devices. AMD64 architecture program-
mer’s manual: Volume 2: System programming. AMD Pub-
lication no. 24593 rev. 3.14, Sept. 2007.
[2] D. Balfanz and E. W. Felten. Hand-held computers can be
better smart cards. In Proccedings of the USENIX Security
Symposium, Aug. 1999.
[3] D. Balfanz, D. Smetters, P. Stewart, and H. C. Wong. Talk-
ing to strangers: Authentication in ad-hoc wireless net-
works. In Proceedings of the Symposium on Network and
Distributed Systems Security (NDSS), Feb. 2002.
[4] BeagleBoard.org. BeagleBoard revision B6 system refer-
ence manual revision 0.1. BeagleBoard.org, Nov. 2008.
[5] K. Borders and A. Prakash. Securing network input via a
trusted input proxy. In Proceedings of the USENIX Work-
shop on Hot Topics in Security (HotSec), Aug. 2007.
[6] E. Brickell, J. Camenisch, and L. Chen. Direct anonymous
attestation. In Proceedings of the ACM Conference on Com-
puter and Communications Security (CCS), Oct. 2004.
[7] S. Chiasson, P. C. van Oorschot, and R. Biddle. A usability
study and critique of two password managers. In Proceed-
ings of the USENIX Security Symposium, Aug. 2006.
[8] P. England, B. Lampson, J. Manferdelli, M. Peinado, and
IEEE Computer,
B. Willman. A trusted open platform.
36(7):55–62, July 2003.
[9] N. Feske and C. Helmuth. A nitpicker’s guide to a minimal-
complexity secure GUI. In Proceedings of the Annual Com-
puter Security Applications Conference (ACSAC), 2005.
[10] E. Gabber, P. Gibbons, Y. Matias, and A. Mayer. How
to make personalized web browsing simple, secure, and
anonymous.
In Proceedings of Financial Cryptography,
1997.
[11] E. Gabber, P. B. Gibbons, D. M. Kristol, Y. Matias,
and A. Mayer. On secure and pseudonymous client-
relationships with multiple servers. ACM Trans. Inf. Syst.
Secur., 2(4):390–415, 1999.
[12] IBM Zurich Research Lab. Security on a stick. Press re-
lease, Oct. 2008.
[13] Intel Corporation. Trusted execution technology – prelimi-
nary architecture speciﬁcation and enabling considerations.
Document number 31516803, Nov. 2006.
[14] M. Jakobsson and S. Myers. Phishing and Countermea-
sures: Understanding the Increasing Problem of Electronic
Identity Theft. Wiley, Dec. 2006.
[15] J. Jonsson and B. Kaliski. PKCS #1: RSA cryptography
speciﬁcations version 2.1. RFC 3447, Feb. 2003.
[16] B. Kauer. OSLO: Improving the security of Trusted Com-
puting. In Proceedings of the USENIX Security Symposium,
Aug. 2007.
[17] K. Kursawe, D. Schellekens, and B. Preneel. Analyz-
ing trusted platform communication.
In Proceedings of
the Cryptographic Advances in Secure Hardware Workshop
(CRASH), Sept. 2005.
[18] J. M. McCune, B. Parno, A. Perrig, M. K. Reiter, and
H. Isozaki. Flicker: An execution infrastructure for TCB
minimization. In Proceedings of the ACM European Con-
ference in Computer Systems (EuroSys), Apr. 2008.
[19] J. M. McCune, B. Parno, A. Perrig, M. K. Reiter, and A. Se-
shadri. Minimal TCB code execution (extended abstract).
In Proceedings of the IEEE Symposium on Security and Pri-
vacy, May 2007.
[20] J. M. McCune, A. Perrig, and M. K. Reiter. Seeing-is-
believing: Using camera phones for human-veriﬁable au-
thentication. In Proceedings of the IEEE Symposium on Se-
curity and Privacy, May 2005.
[21] J. M. McCune, A. Perrig, and M. K. Reiter. Bump in the
ether: A framework for securing sensitive user input.
In
Proceedings of the USENIX Annual Technical Conference,
June 2006.
[22] B. Parno. Bootstrapping trust in a “trusted” platform.
In
Proceedings of the USENIX Workshop on Hot Topics in Se-
curity (HotSec), July 2008.
[23] M. Peinado, Y. Chen, P. England, and J. Manferdelli.
NGSCB: A trusted open system. In Proceedings of the Aus-
tralasian Conference on Information Security and Privacy
(ACISP), July 2004.
[24] Proliﬁc Technology Inc. PL-25A1 hi-speed USB host to
host bridge controller. PL-25A1 Product Brochure, Oct.
2006.
[25] B. Ross, C. Jackson, N. Miyake, D. Boneh, and J. C.
Mitchell. Stronger password authentication using browser
extensions. In Proceedings of the USENIX Security Sympo-
sium, Aug. 2005.
[26] A.-R. Sadeghi, M. Selhorst, C. St¨uble, C. Wachsmann, and
M. Winandy. TCG inside? - A note on TPM speciﬁcation
compliance. In Proceedings of the ACM Workshop on Scal-
able Trusted Computing (STC), Nov. 2006.
[27] R. Sailer, X. Zhang, T. Jaeger, and L. van Doorn. Design
and implementation of a TCG-based integrity measurement
architecture. In Proceedings of the USENIX Security Sym-
posium, Aug. 2004.
[28] J. H. Saltzer and M. D. Schroeder. The protection of in-
formation in computer systems. Proceedings of the IEEE,
63(9):1278–1308, Sept. 1975.
[29] R. Sharp, A. Madhavapeddy, R. Want, and T. Pering. En-
hancing web browsing security on public terminals using
mobile composition.
In Proceeding of the Conference on
Mobile Systems, Applications, and Services (MobiSys), June
2008.
[30] R. Sharp, A. Madhavapeddy, R. Want, T. Pering, and
J. Light. Fighting crimeware: An architecture for split-trust
web applications. Technical Report IRC-TR-06-053, Intel
Research Center, Apr. 2006.
[31] R. Sharp, J. Scott, and A. Beresford. Secure mobile comput-
ing via public terminals. In Proceedings of the International
Conference on Pervasive Computing, May 2006.
[32] D. X. Song, D. Wagner, and X. Tian. Timing analysis of
In Proceedings of
keystrokes and timing attacks on SSH.
the USENIX Security Symposium, Aug. 2001.
[33] F. Stajano and R. Anderson. The resurrecting duckling: Se-
curity issues for ad-hoc wireless networks. In Proceedings
of the Security Protocols Workshop, 1999.
[34] Trusted Computing Group. Trusted platform module main
speciﬁcation, Part 1: Design principles, Part 2: TPM struc-
tures, Part 3: Commands. Version 1.2, Revision 103, July
2007.
[35] D. Wendlandt, D. G. Andersen, and A. Perrig. Perspec-
tives: Improving SSH-style host authentication with multi-
path probing. In Proceedings of the USENIX Annual Tech-
nical Conference, June 2008.
[36] D. A. Wheeler.
It’s worth
more! Available at: http://www.dwheeler.com/
essays/linux-kernel-cost.html, Oct. 2004.
Linux kernel 2.6:
A TCG-Style Attestation and Sealed Storage
The v1.2 Trusted Platform Module (TPM) chip contains
an array of 24 or more Platform Conﬁguration Registers
(PCRs), each capable of storing a 160-bit hash. These PCRs
can be Extended with a Measurement (cryptographic hash)
of data, such as a program binary. Given a measurement m
← SHA1(data), the extend process works as follows:
PCRnew ← SHA1(PCRold ||m).
TPMs include two kinds of PCRs: static and dynamic.
Static PCRs reset to 0160 when the TPM itself resets (gen-
erally during a full platform reset or power-cycle, although
physical TPM-reset attacks have been demonstrated [16,17,
26]), and can only have their value updated via an Extend
operation. These PCRs can be used to keep a record of mea-
surements for all software loaded since the last reboot, as in
IBM’s Integrity Measurement Architecture [27].
Dynamic PCRs are present in v1.2 TPMs, and are rel-
evant when the platform supports Dynamic Root of Trust,
e.g., Intel TXT [13] or AMD SVM [1]. Dynamic PCRs re-
set to 1160 during full platform reset, and can additionally
be reset to 0160 via a Late Launch, thereby establishing a
Dynamic Root of Trust. In addition to resetting the dynamic
PCRs, Late Launch resets the CPU to a known trusted state
without rebooting the rest of the system. This includes con-
ﬁguring the system’s memory controller to prevent access
to the launching code from DMA-capable devices. One of
the newly reset dynamic PCRs is then automatically ex-
tended with a measurement of the software that will get
control following the Late Launch [1]. This enables soft-
ware to bootstrap without including the BIOS or any system
peripherals in the TCB. The Open Secure LOader (OSLO)
performs a Late Launch on AMD systems to remove the
BIOS from the TCB of a Linux system [16]. Trusted Boot6
6http://sourceforge.net/projects/tboot
from Intel performs similarly for Intel hardware, though it
adds the ability to enforce a Launch Control Policy. The
Flicker system uses Late Launch to brieﬂy interrupt the ex-
ecution of a legacy OS and execute a special-purpose code
module in isolation from all other software and devices on
the platform, before returning control to the legacy OS [18].
Once measurements have accumulated in the PCRs, they
can be attested to a remote party to demonstrate what soft-
ware has been loaded on the platform. They can also be
used to seal data to a particular platform conﬁguration. We
discuss each of these in turn.
Attestation. The attestation process involves a challenge-
response protocol, where the challenger sends a crypto-
graphic nonce (for replay protection) and a list of PCR
indexes, and requests a TPM Quote over the listed PCRs.
A Quote is a digital signature computed over an aggregate
of the listed PCRs using an Attestation Identity Key (AIK).
An AIK is an asymmetric signing keypair generated on the
TPM. We discuss certiﬁcation of AIKs shortly. The mes-
sages exchanged between a challenger C and an untrusted
system U to perform an attestation are:
C → U : nonce, PCRindexes
U → C: PCRvals, {PCRvals, nonce}AIK−1
Once the challenger receives the attestation response,
it must (1) verify its nonce is part of the reply, (2) check
the signature with the public AIK obtained via an authen-
tic channel, (3) verify that the list of PCR values received
corresponds to those in the digital signature, and (4) ver-
ify that the PCR values themselves represent an acceptable
set of loaded software. Note that since the sensitive opera-
tions for a TPM Quote take place entirely within the TPM
chip, the TPM Quote operation can safely be invoked from
untrusted software. The only attack available to malicious
software is denial-of-service. In the context of the Flicker
system, this removes the code that causes the TPM Quote
to be generated from the system’s TCB.
Certifying Platform Identity. The Attestation Identity
Keypair (AIK) used to perform the TPM Quote effectively
represents the identity of the attesting host. We discuss op-
tions for certifying this keypair (i.e., obtaining an authentic
copy of the public AIK for a particular physical host).
Multiple credentials are provided by TPM and host man-
ufacturers that are intended to convince a remote party that
they are communicating with a valid TPM installed in a host
in conformance with the relevant speciﬁcations [34]. These
are the TPM’s Endorsement Key (EK) Credential, Platform
Credential, and Conformance Credential. One option is to
use these credentials directly as the host’s identity, but the
user’s privacy may be violated. Motivated by privacy con-
cerns, the Trusted Computing Group (TCG) has speciﬁed
Privacy Certiﬁcate Authorities (Privacy CAs). Privacy CAs
are responsible for certifying that an AIK generated by a
TPM comes from a TPM and host with valid Endorsement
Key, Platform, and Conformance Credentials.
To the best of our knowledge, there are no commercial
Privacy CAs in operation today. Thus, we must either pro-
vide all of the credentials corresponding to the untrusted
host to the challenger (compromising privacy), or the chal-
lenger must blindly accept the AIK without performing any
veriﬁcation (compromising host identity, and adopting the
trust-on-ﬁrst-use model). Trust-on-ﬁrst-use models have
been deployed successfully, e.g., for the Secure Shell (SSH)
protocol. Thus, we believe the choice of which host identity
mechanism to use is application-dependent. For communi-
cation with a bank or established online merchant, where
an honest user almost always provides her true identity, it is
not clear that there is any loss of privacy by providing the
full set of TPM and host credentials.
Direct Anonymous Attestation (DAA) has also been pro-
posed as an alternative to Privacy CAs for protecting plat-
form identity [6]. To the best of our knowledge, no systems
are available today that include TPMs supporting DAA.
Sealed Storage. TPM-protected sealed storage is a mech-
anism by which an asymmetric encryption keypair can be
bound to certain PCR values. Data encrypted under this
keypair then becomes unavailable unless the PCR values
match those speciﬁed when the data was sealed. This is a
relatively slow process since the asymmetric cryptographic
operations are performed by the low-cost CPU inside the
TPM. An alternative is to use the TPM’s Non-Volatile RAM
(NV-RAM) facility. NV-RAM can be conﬁgured with simi-
lar properties to sealed storage, in that a region of NV-RAM
can be made inaccessible unless the PCR values match
those speciﬁed when the region was deﬁned. NV-RAM has
a limited number of write cycles during the TPM’s lifetime,
but the use of a symmetric master key that is only read from
NV-RAM in the common case can greatly extend its life.
Flicker can use TPM sealed storage or NV-RAM to protect
long-term state that is manipulated during Flicker sessions.