title:An Approach for Detecting Self-propagating Email Using Anomaly Detection
author:Ajay Gupta and
R. Sekar
An Approach for Detecting Self-propagating Email
Using Anomaly Detection(cid:1)
Ajay Gupta and R. Sekar
Department of Computer Science
Stony Brook University, Stony Brook, NY 11794
{ajay,sekar}@cs.sunysb.edu
Abstract. This paper develops a new approach for detecting self-propagating
email viruses based on statistical anomaly detection. Our approach assumes that
a key objective of an email virus attack is to eventually overwhelm mail servers
and clients with a large volume of email trafﬁc. Based on this assumption, the
approach is designed to detect increases in trafﬁc volume over what was observed
during the training period. This paper describes our approach and the results of
our simulation-based experiments in assessing the effectiveness of the approach
in an intranet setting. Within the simulation setting, our results establish that the
approach is effective in detecting attacks all of the time, with very few false alarms.
In addition, attacks could be detected sufﬁciently early so that clean up efforts need
to target only a fraction of the email clients in an intranet.
Introduction
1
Email viruses have become one of the major Internet security threats today. An email
virus is a malicious program which hides in an email attachment, and becomes active
when the attachment is opened. A principal goal of email virus attacks such as Melissa
[1] is that of generating a large volume of email trafﬁc over time, so that email servers
and clients are eventually overwhelmed with this trafﬁc, thus effectively disrupting the
use of the email service. Future viruses may be more damaging, taking actions such as
creating hidden back-doors on the infected machines that can be used to commandeer
these machines in a subsequent coordinated attack.
Current approaches for dealing with email viruses rely on the use of anti-virus soft-
ware at the desktops, network servers, mail exchange servers and at the gateways. Detec-
tion of email viruses is usually based on a signature-based approach, where the signature
captures distinguishing features of a virus, such as a unique subject line or a unique se-
quence of bytes in its code. This approach is effective against known email viruses, but is
ineffective against unknown (i.e., newly released) viruses. To overcome this drawback,
techniques have been recently developed that focus on virus behavior rather than its
representation. Such “behavior-blocking” approaches detect viruses by using signatures
of behavior, such as fast generation of emails or self-replication.
Although behavior-blocking is more effective against unknown viruses, it can still
be fooled by carefully designed viruses that propagate slowly, or replicate after a period.
For instance, if system is set to block the behavior that an email attachment should
not cause generation of more than k other email messages, a virus that generates only
(cid:1) This research was supported in part by NSF under grant CCR-0098154 and the Defense Ad-
vanced Research Agency (DARPA) under contract number N66001-00-C-8022.
G. Vigna, E. Jonsson, and C. Kruegel (Eds.): RAID 2003, LNCS 2820, pp. 55–72, 2003.
c(cid:1) Springer-Verlag Berlin Heidelberg 2003
A. Gupta and R. Sekar
56
k−1 copies will go undetected. Similarly, an email attachment that causes time-delayed
propagation may also go undetected. More generally, a virus can employ a combination
of low propagation factor, high incubation period, and randomization to evade behavior-
blocking approaches.
An alternative approach for detection is one that focuses on the ultimate effect of
self-propagating email viruses: increase in email trafﬁc. Simple adaptations on the part of
the virus, such as reducing the propagation factor below a certain threshold, introducing
time delays or other randomizations do not alter this ultimate effect. For this reason, our
approach is based on detecting email viruses based on increases in the volume of email
trafﬁc generated.
Given the variations in email trafﬁc from one site to another, and from one time to
another, it is difﬁcult for manual development of characterizations of excessive email
trafﬁc. An alternative approach is to use machine learning — the system is trained to
learn characteristics of normal email trafﬁc, and then detect signiﬁcant increases. In the
context of intrusion detection, such anomaly detection approaches have been associated
with relatively high false-alarm rates, as well as a moderate rate of false negatives (i.e.,
missed attacks). In this paper, we develop and study an approach that appears to be
capable of detecting attacks with very low false alarm rate, while still being able to
detect attacks reasonably early.
This paper ﬁrst presents our approach for anomaly-based detection of the self-
propagating email viruses. It begins with an overview of our approach in Section 2.
We have studied the performance of this approach using two complementary experi-
ments, both based on simulation. The ﬁrst experiment focuses on creating stealthy virus
behaviors, but uses a simplistic user model. The second experiment strives for more
realistic user models, as well as more accurate reproduction of the behaviors of different
software components of the email system, but the virus models are not as stealthy or
variable as the ﬁrst experiment.
Section 3 describes our ﬁrst experiment. Our experimental results show that viruses
similar to the ones that are prevalent currently, can be detected early. This is because
such viruses are very “noisy.” For stealthier viruses that use a small replication factor,
detection is still achieved fairly early in our simulation, when a minority of email clients
are infected. For the most stealthy viruses that use a combination of low replication
factor and delayed propagation, a majority of the network is infected by the time of
detection. In all cases, detection is achieved before the time the email server experiences
a high overload. Since our technique promises to provide low false alarm rates, there is a
potential to launch automated responses at detection time so as to quarantine emails with
attachments on the mail server1. At this point, a more careful investigation of the virus
can be performed, followed by a cleanup phase (on the email clients) if a virus is indeed
present. Note that early detection of the virus reduces the cleanup costs signiﬁcantly, as
only a fraction of the computers in an organization need to be cleaned up.
The second experiment, described in Section 4, used a more elaborate user model.
Moreover, an actual email system was used so as to make the simulation results more
realistic. The goal of the experiment, conducted as part of a DARPA-sponsored research
1 Such a quarantine will be effective in arresting further spread of the virus, assuming that viruses
can spread only through attachments.
An Approach for Detecting Self-propagating Email Using Anomaly Detection
57
program, was to study the effectiveness of automated response to check the spread of such
viruses. A number of signature and behavior based detectors were used in combination
with our anomaly detector. The signature and behavior based detectors were tuned for
early detection, but this meant that the more stealthy viruses would not be caught by
them. The anomaly detector was therefore tuned for delayed but certain detection. The
detection delay was artiﬁcially increased so that the anomaly detector will not raise an
alarm until it is certain that any responses based on other detectors have failed. For this
reason, our primary effectiveness criteria in this experiment was detection, rather than
early detection. Of the hundreds of experiments conducted in this set up, there were 7
cases where the virus was not checked by other detectors, and in each of these cases,
our anomaly detector was able to detect the attack. These experimental results show
that our approach is effective, subject to the accuracy of the simulation models used in
the experiment. They also indicate that our approach can complement other “behavior-
blocking” approaches, which are typically tuned for early detection but may be fooled
by stealthy viruses.
Some of the key beneﬁts of our approach are:
– Accurate detection. In our simulation-based experiments, our approach demonstrated
near-zero false alarm rates with zero false negatives (i.e, 100% detection). The latter
is possible because of the nature of self-propagating email, wherein the email trafﬁc
keeps increasing until it is detected.
– Robust against polymorphic and stealthy viruses. Our technique is unaffected by
polymorphic viruses. It promises to reliably detect stealthy viruses that pose chal-
lenges to previously developed detection techniques, although the detection may be
delayed.
A practical beneﬁt of our approach is that it has a low runtime overhead. Moreover, its
learning phase is robust enough to operate without expert supervision.
While the above results are promising, they are tempered by the fact that they are
based exclusively on simulated behaviors of email users. The ﬁrst experiment used
a particularly simple model for user behaviors: each user was modeled as a Poisson
process. The second experiment used a non-uniform model taking into account such
factors as address books. User behavior was simulated using a 3-state (“reading email,”
“composing email,” and “idle”) Markov process that makes random transitions between
states that is governed by a set of transition probabilities. Thus the user model was
much more realistic in this experiment. Nevertheless, it is well known in the context of
anomaly detection that real system behavior tends to exhibit more variability than what
can be observed in a simulation. Thus, the results obtained using simulation experiments
cannot be directly extrapolated to real operating environments. Our ongoing work aims
to address this weakness by using simulation only for the purpose of modeling viruses;
normal email trafﬁc will be taken from actual mail server logs.
2 Overview of Approach
Our approach is based on speciﬁcation-based anomaly detection [36], a technique that
combines state-machine speciﬁcations of network protocols with statistical machine-
learning. In this case, the protocol models the interaction between email clients in an
organization with the email server of the same organization. These interactions are called
58
A. Gupta and R. Sekar
|
deliver(from, msgID, to)
(msgID == id)&&(sender==from)
>
INIT
send(from, msgID, to1,...,toN)
sender = from, id = msgID
RCVD
timeout()
DONE
Fig. 1. A State Machine Modeling Email Server Operation
events. The state machine (implicitly) classiﬁes events into different categories based
on the transition taken by them in the state machine. Machine learning techniques are
then used to learn statistics associated with each of these classes. Several choices exist
for such statistics, including: average number of attachments to an email, size of a
message, etc. Our focus, however, was on characteristics that are necessarily associated
with increased email trafﬁc, and hence we chose statistics relating to frequency of taking
different transitions. The fact that this simple measure was effective supports the claim
of [36] that the use of protocol state machines simpliﬁes feature selection, i.e., even a
naive choice of features produces good results.
The ﬁrst step in our approach is to develop a state machine modeling the behavior
of an email service, as observed at a mail server. For the rest of this paper, we concern
ourselves mainly with email service within an intranet. We assume that all email clients
transfer each of their outgoing messages to the intranet mail server, which in turn forwards
the messages to each of the recipients2. Since we are only concerned with emails within
the intranet, the email server simply queues each message received from any client on
the mail queues associated with the respective recipients.
Figure 1 shows the simpliﬁed model of email server behavior described in the preced-
ing paragraph. The state machine has three states that are identiﬁed as IN IT , RCV D
and DON E. The reception of an email from a client f rom at the server is modeled using
the event send that takes several parameters: the ﬁrst parameter identiﬁes the sender,
the second is a unique identiﬁer for the message, and the rest of the parameters denote
the recipients of the message. The contents of the message are not modeled in this state
machine. When the server receives this message, it forwards the message to each of the
email recipients. This forwarding operation is modeled using the deliver event, which
takes the sender name, the message identiﬁer and the recipient names as parameters.
This event may occur zero or more times, depending on the number and email ids of the
recipients. Note that there is no easy way to relate the number of recipients in the send
message with the number of recipients to which the message is forwarded by the server.
The number of actual recipients of a message may be more (e.g., when a recipient name
corresponds to a mailing list), or less (e.g., when a recipient name is in error, or due to
duplicates or mail aliases within the recipient list). For this reason, the state machine
indicates that there may be zero or more instances of the deliver event corresponding to
each send event. The correspondence between the send and deliver events is identiﬁed
in the state machine by storing the message identiﬁer and sender in two state variables id
and sender, and then comparing these state variables with the arguments of the deliver
event.
2 This assumption holds for most popular email clients such as Microsoft Outlook and Netscape
Messenger.
An Approach for Detecting Self-propagating Email Using Anomaly Detection
59
The DON E state in the state machine signiﬁes the completion of the processing of
a particular email from a client. Due to the difﬁculty outlined above in recognizing when
such processing is completed, we use a time-out to model completion. The assumption
being made here is that once an email is received by the server, it will be processed and
the message sent to all recipients within a short period of time. The time-out value is set
well above the expected time for such processing of email.
Formally, we use extended ﬁnite state automata (EFSA) to capture the state machine
model shown in Figure 1. An EFSA is similar to a ﬁnite-state automaton in that it is
characterized by a set of states, some times called control states of the automata, and a
set of transitions between these states. EFSA differ from FSA in that (a) EFSA make
transitions on events that may have arguments, and (b) EFSA can use a ﬁnite set of state
variables in which values can be stored. The EFSA in Figure 1 consists of three control
states IN IT (the start state), RCV D, and DON E (the ﬁnal state); three events send,
deliver and timeout; and two state variables sender and id.
To understand how such EFSA speciﬁcations can be used for monitoring email
trafﬁc, consider the state machine diagram again. When an email is accepted by the
mail server for delivery, a new instance of the state machine is created, and this instance
makes a transition from IN IT to RCV D state. The sender and message identiﬁer are
stored in the state variables associated with this instance. As copies of this message are
delivered to the recipients, the deliver transition is taken. Finally, after a timeout period,
a transition to the DON E state is taken. This being a ﬁnal state, the state machine
instance is no longer needed, and is cleaned up, i.e., all resources allocated for this state
machine instance are released. Note that in general, there will be multiple instances of
the state machine active at any time. The number of such active instances is determined
by how many email messages are sent by clients over the duration of the timeout period.
Now, we superimpose statistical machine learning over this state-machine speciﬁca-
tion of email server behavior. An obvious statistical property of interest is the frequency
with which various transitions in the state machine are taken. A self-propagating email
virus will cause an increase in many of these frequencies. We may also be interested in
statistical properties across a subset of instances, rather than all instances. The instances
of interest can be speciﬁed on the basis of state variable values. For instance, we may
be interested in the number of emails sent to any recipient by a particular user C on the
network. We will do this by selecting instances that have sender equal to C in their
RCVD state, and identifying the number of times the transition on the deliver event was
taken in these instances.
2.1 Statistics of Interest and Their Representation
In the state machine in Figure 1, there are two signiﬁcant transitions, taking place on
the send and deliver events respectively. We therefore choose frequencies of these two
transitions as statistical information of interest, and maintain the following statistics:
– frequency with which the send transition is taken, across all clients
– frequency with which the deliver transition is taken, across all clients
– for each client C, the frequency with which emails from C take the send transition
– for each client C, the frequency with which emails from C take the deliver transition
60
A. Gupta and R. Sekar
Each of these statistics were maintained at multiple (of the order of ten) time scales,
ranging from about a second to about an hour.
We could maintain average frequency information, but since most phenomena re-
lated to email can be bursty, we choose to maintain frequency distributions rather than
averages. In particular, we deﬁne a time window w over which we count the number of
times a transition is taken. Let nT1, ..., nTk denote the counts associated with a transition
over k successive time periods T1, ..., Tk that are w units long. Then a histogram of the
values nT1, ..., nTk is used to represent the frequency distribution over a time window
w, as observed during a training period of duration w ∗ k units.
Since we do not know in advance the range of the values nT−1, it is more con-