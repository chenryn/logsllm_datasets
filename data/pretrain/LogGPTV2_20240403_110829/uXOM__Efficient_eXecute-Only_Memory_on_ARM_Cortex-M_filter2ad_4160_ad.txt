that scans the binary executable for exploitable unintended
instructions and records the position of each instruction in-
side the function. With that information, the program is then
recompiled and the exploitable unintended instructions are
replaced into alternative instruction sequences. Sometimes,
new exploitable unintended instructions are revealed after this
process, as code and object layouts are changed and offsets
and addresses embedded in the code are changed accordingly.
Thus, the interaction between the compiler and the veriﬁer is
repeated until there are no exploitable unintended instructions
in the binary.
Figure 6 demonstrates a few examples showing how the
transformation is applied to remove exploitable unintended
instructions. Figure 6.(a) shows the case where an exploitable
unintended instruction (STR) is generated from the immediate
value of 32-bit instruction (MOVW). To remove the exploitable
instruction, we divide the original immediate value into two
3This capability is available in the linker for some architectures like RISC-
V which implements aggressive linker relaxation. For those architectures, the
pc-relative offset resolution is deferred until the linking time to enable linker
optimizations that reduce instructions and thus may change the pc-relative
offsets in the code.
USENIX Association
28th USENIX Security Symposium    239
Instr. #1Instr. #2(1)Unintended Instr. 16-bit32-bitInstr. #2Unintended Instr. 32-bitUnintended Instr. (2)(3)Instr. #132-bitInstr. #132-bitLDR r2, [PC, #0x20]....word 0xf0006008//0x6008 : STR r0, [r1]0xFFC:0x1000:0x1020:MOVT r2, #0xf000MOVW r2, #0x6008...0xFFC:0x1000:MOVW r0, #0x2d18 // HEX encoding : 0xf6425018 // 0x5018 : STR r0, [r3, r0]0x1000:MOVW r0, #0x2918ADDW r0, r0, #0x4000x1000:0x1004:(a) Unintended instruction originating from a 32-bit MOVW instruction(c) Unintended instruction originating from an immediate value in the code regionLDR r8, [sp], 4// HEX encoding : 0xf85d8b04 // 0x8b04 : LDRH r4, [r0, 0x18]0x1000:LDR  r9, [sp], 4MOV  r8, r90x1000:0x1004:(b) Unintended instruction originating from a 32-bit LDR instructionTBB [PC, r5].word 0x50274b39//0x6027 : STR r7, [r4]......0xFFC:0x1000:0x10A0:TBB [PC, r5].word 0x02284c3aB 0x10A2......0xFFC:0x1000:0x1004:0x10A2:(d) Unintended instruction originating from a jump tablenumbers A and B. Then we replace the original 32-bit in-
struction to use A and add an extra instruction (e.g., ADDW)
to add B to the register written by the original instruction.
Note that for 32-bit instructions whose immediate value is
only determined at link time, we only add the extra instruction
at compile time and make sure that the linker puts value A
and B instead of the original immediate value. Figure 6.(b)
shows another example that the destination register of the
32-bit instruction (LDR) generates the exploitable unintended
instruction (LDRH). We solve this case by putting the value
loaded from memory into the other register and then use an
extra MOV instruction to copy the value into the original des-
tination register. We have also implemented an optimization
in the register allocation pass to prefer invulnerable registers
over the others for the destination of these 32-bit instructions
so that exploitable unintended instructions can be avoided as
much as possible. This saves the use of extra instructions and
reduces the performance and code size overhead. Figure 6.(c)
shows an unintended instruction that exists in a constant em-
bedded in a code region to be loaded by a pc-relative load.
To sanitize it, we remove the constant value and replace the
associated pc-relative load with two move instructions. If the
resulting MOVT or MOVW instruction creates new exploitable
unintended instructions, it is further transformed similarly to
the example in Figure 6.(a). Finally, Figure 6.(d) shows the
case where the offsets in a jump table embedded in the code
create an exploitable unintended instruction. In the example,
the value 0xA0 (0x50 * 2) is added to pc and the control is
transferred to 0x10A0. To remove the unintended instruction
in this case, we add a trampoline code right after the jump
table for the targets with the problematic offsets.
5.3 Optimizations
According to our experiments (see § 6.1), unprivileged mem-
ory instructions consume the same CPU cycles as ordinary
memory instructions. However, unprivileged instructions are
32-bits in size while many ordinary memory instructions have
a 16-bit form. Also, extra instructions that are added as de-
scribed in § 5.1.1 can increase both the code size and the per-
formance overhead. Since code size is another critical factor
in an embedded application due to its scarce memory, it can
be beneﬁcial to leave the memory instructions in their original
form if we can ensure that this does not harm the security guar-
antees of uXOM. In fact, a large number of the instructions
do not need to be converted either because they are safe by
nature or because they can be made safe through some addi-
tional effort. For example, ARM supports pc-relative memory
instructions which access a memory location that is a ﬁxed
distance away from the current pc—i.e., the address of the cur-
rent instruction. As these instructions can only access certain
data embedded in the code region, attackers cannot exploit
them to access other memory locations. Therefore, we do not
need to convert these instructions, so we leave them as long as
it is not exploitable as unintended instructions (§ 5.2.3). We
also do not convert stack-based ordinary memory instructions.
Numerous instructions use the sp as the base address. Almost
all of them are 16-bits in size since Cortex-M provides special
16-bit encoding for stack-based memory instructions. Con-
verting all of these as the unprivileged will signiﬁcantly add to
the code size of the ﬁnal binary. Most of the LDM/STM instruc-
tions, including all the PUSH/POP instructions, are also based
on sp. Converting them would require multiple unprivileged
instructions which would further increase the code size and
even the performance overhead. Luckily, recall that uXOM al-
ready enforces the invariant properties noted in § 5.2.2 on the
sp. Therefore, attackers cannot exploit the ordinary memory
instructions based on sp, and we can safely leave sp based
memory instructions in their original forms.
5.4 Security Analysis
uXOM builds on the premise that there remains no abus-
able instructions in a ﬁrmware binary. uXOM satisﬁes this
through its compiler-based static analysis (§ 5.1.1 and § 5.2.3)
that (1) identiﬁes all abusable instructions, such as ordinary
memory instructions and unintended instructions, and (2) con-
verts them into safe alternative instructions. This conservative
analysis does not make false negative conversions, so uXOM
is fail-safe in terms of security. In the following, we show that
attackers we assumed in the threat model (§ 3) will not be
able to compromise uXOM.
5.4.1 At Boot-up
As noted in § 3, we trust the integrity and conﬁdentiality of
the ﬁrmware image. The ﬁrmware image will be distributed
and installed with the uXOM-related code instrumentation
applied. As soon as the system is powered up, the reset excep-
tion handler starts to run and the code snippet that uXOM in-
serted at the start of the handler is executed to enforce uXOM-
speciﬁc memory access permissions. Note that the ﬁrmware
has started its execution from a known good state and the
attackers have not yet injected any malicious payloads. There-
fore, we can guarantee that uXOM will safely enable XOM
without being disturbed by the attackers.
5.4.2 At Runtime
Once uXOM enables XOM, the attackers are completely pre-
vented from accessing the code. They cannot use unprivileged
loads/stores to bypass uXOM, so they have to resort to the
unconverted loads/stores. Through the instruction conversions
and optimizations of uXOM, only three types of unconverted
loads/stores remain in the binary: stack-based loads/stores,
exclusive loads/stores and ordinary loads/stores for the PPB
access.
Stack-based loads/stores. uXOM’s optimization excludes
sp based loads/stores from the conversion candidates. The
attackers may be able to execute these loads/stores, but they
cannot access the PPB region or code regions. This is be-
cause the sp is forced to point to the stack regions due to the
invariant property (Invariant 2 in § 5.2.2) enforced on the
240    28th USENIX Security Symposium
USENIX Association
sp.
Exclusive loads/stores and ordinary loads/stores for the
PPB access. These unconverted loads/stores are protected
by the atomic veriﬁcation technique. Veriﬁcation routines
are inserted just before each unconverted load/store and the
atomic execution of the inserted routine and the corresponding
unconverted load/store is guaranteed. Of course, the attacker
may jump into the middle of the atomic instruction sequence
to directly execute the unconverted load/store without a proper
veriﬁcation. However, as the unconverted loads/stores use the
sp as their base register, the attackers still cannot access the
code and the PPB regions.
6 Evaluation
uXOM transformations are implemented in LLVM 5.0, and
uXOM ’s binary veriﬁer is implemented using the Radare2
binary analysis framework [32]. We used the RIOT-OS [5]
version 2018.10 as the embedded operating system. As the
whole binary, including the OS, runs in a single physical
address space at the same privilege level, uXOM compiler
transformations are applied to the OS code as well as the
application code to enable complete protection. We also ap-
plied our transformations to the C library (newlib) included
in arm-none-eabi toolchain, which had to be patched in a few
places to compile and run correctly with LLVM.
To better show the merits of our approach, we also imple-
mented and evaluated SFI-based XOM to compare against
uXOM. Originally, SFI is developed to sandbox an untrusted
module in the same address space. It restricts the store and
indirect branch instructions (i.e., by masking or checking the
store/branch address) in the untrusted module so that the un-
trusted module cannot corrupt or jump into the trusted module.
It also bundles the checks with the store/branch instructions
and prevents jumps into the bundle so that the restrictions ap-
plied to the store or branch address cannot be skipped. Capital-
izing on the SFI’s access control scheme, some studies [7,31]
have implemented the SFI-based XOM that instruments every
load instructions with masking instructions to prevent them
from reading the code region. However, as these studies fo-
cus on high-end devices like smartphones and desktop PCs,
we adapted the SFI-based XOM to work on Cortex-M based
devices. As our target device do not use virtual memory, code
and data must reside in a speciﬁc memory region. This pre-
vents us from using simple masking to restrict load addresses
and forces us to use a compare instruction to validate the ad-
dress. Furthermore, the instruction set of Cortex-M requires
us to insert additional IT (If-Then) instruction to make load
instruction execute conditionally on the comparison result.
Next, we place the compare and load inside a 16-byte aligned
bundle and make sure that they do not cross the bundle bound-
ary. We insert NOPs in the resulting gaps. Lower bits of indirect
branch targets are masked (cleared) to prevent control ﬂows
into the bundle. We also make sure that all possible targets of
an indirect branch (i.e., functions and call-sites) are aligned.
Figure 7: Execution time of bitcount according to the dif-
ferent alignments of the code region.
POP instructions used for function returns are converted to
masking and return sequence as described in the previous
work on SFI [33]. Following the optimization done in the
paper [39], the memory load instructions based on the sp are
not checked and the sp is regulated in the same way as in
uXOM.
To evaluate uXOM and the SFI-based XOM, we used the
publicly available BEEBs benchmark suite (version 2.1) [29].
We selected 33 benchmarks that are claimed to have relatively
long execution time [12]4. We ran each benchmark on an
Arduino Due [1] board which ships with an Atmel SAM3X8E
microcontroller based on the Cortex-M3 processor. During
the experiment, we found that the program runs give very
inconsistent timing results depending on how the code is
aligned, even though there are no caches in the processor.
After some investigation, we found that the reason is due to
the ﬂash memory. The Arduino Due core runs at 84MHz in
the default setting, which makes it necessary to wait for 4
cycles (called ﬂash wait state) to get stable results from the
ﬂash memory. SAM3X3E chips are equipped with a ﬂash
read buffer to accelerate sequential reads [3], which gave us
variable results depending on where the branches are located.
As a preliminary experiment, we measured the execution time
while changing the displacement of the entire code region for
bitcount benchmark. As shown in Figure 7, the changes in
execution time show a pattern that is repeated every 16-byte,
which corresponds to the size of the ﬂash read buffer. Because
of this result, to get a consistent result, we decreased the core
frequency to 18.5MHz in all our experiments.
6.1 Runtime Overhead
Figure 8 shows the runtime overhead of uXOM and SFI-
based XOM. The geomean overhead of all benchmarks is
7.3% for uXOM and 22.7% for SFI-based XOM. The worst
case overhead for uXOM is 22.3% for huffbench benchmark
and that for SFI-based XOM is 75.1% for edn benchmark.
Note that the performance overhead of SFI reported in the
previous work [33] for a high-end ARM device (Cortex-A9)
is 5%. In the paper, they mention that overhead induced by
additional instructions for SFI can be hidden by cache misses
and out-of-order execution. Based on this, we presume that the
large overhead of SFI-based XOM for Cortex-M3 observed
in our experiment is due to the low-power and cache-less
4Some of the benchmarks have been dropped in the newest version due
to the license problem.
USENIX Association
28th USENIX Security Symposium    241
0.9511.051.11.151.2024681012141618202224262830323436384042Execution Time (s)Alignment (bytes)Figure 8: Runtime overhead on BEEBs benchmark suite.
Figure 9: Performance overhead breakdown for the different
components of uXOM-UI transformation.
processor implementation. This strongly shows the need for
an efﬁcient low-end device oriented XOM implementation
like uXOM.
To inspect the sources of overhead, we built and ran multi-
ple partially instrumented versions of binaries with different
kinds of transformations applied. First, to examine the per-
formance impact of removing exploitable unintended instruc-
tions, we measured the runtime overhead for uXOM-UI—a
variation of uXOM that does not handle unintended instruc-
tions. As a result, we measured that the geomean overhead
for uXOM-UI is 5.2%, which shows that removing unin-
tended instructions incurs 2.1% of overhead in uXOM. We
then gathered the statistics on the number of conversions
and check codes inserted in uXOM-UI (Table 3). We also
measured the overhead ratio in terms of code size and exe-
cution time according to the type of conversions and checks
(Figure 9). In Table 3 and Figure 9, no extra instr. de-
notes the case where a memory instruction is converted to
an unprivileged one without an additional instruction. imm.
offset denotes the case where an additional instruction is
required because the immediate offset is too large or is nega-
tive. pre/post idx. represents the pre/post-indexed address-
ing mode and reg. offset represents the register-register
addressing mode. double/multiple mem. ops. represents
LDRD/STRD/LDM/STM instructions. For the sp check part,
non-const sp mod. is the case where the sp is modiﬁed
by the non-constant (and the check is required). const sp
mod. (checked) is the case where the sp is modiﬁed by the
constant and requires checking since no load/store based on
the sp is found afterwards. const sp mod. (no check) is
the case where the sp is modiﬁed by the constant but does
not need to be checked. Finally, LDR/STR checks denotes
the instructions inserted for the atomic veriﬁcation technique.
The statistics shown in Table 3 are gathered while compil-
ing the C standard library, RIOT-OS, and each of the bench-
Cases