title:Securing Augmented Reality Output
author:Kiron Lebeck and
Kimberly Ruth and
Tadayoshi Kohno and
Franziska Roesner
2017 IEEE Symposium on Security and Privacy
Securing Augmented Reality Output
Kiron Lebeck, Kimberly Ruth, Tadayoshi Kohno, Franziska Roesner
Paul G. Allen School of Computer Science & Engineering
University of Washington
{kklebeck, kcr32, yoshi, franzi}@cs.washington.edu
https://ar-sec.cs.washington.edu
Abstract—Augmented reality (AR) technologies, such as Mi-
crosoft’s HoloLens head-mounted display and AR-enabled car
windshields, are rapidly emerging. AR applications provide users
with immersive virtual experiences by capturing input from a
user’s surroundings and overlaying virtual output on the user’s
perception of the real world. These applications enable users to
interact with and perceive virtual content in fundamentally new
ways. However, the immersive nature of AR applications raises
serious security and privacy concerns. Prior work has focused
primarily on input privacy risks stemming from applications with
unrestricted access to sensor data. However, the risks associated
with malicious or buggy AR output remain largely unexplored.
For example, an AR windshield application could intentionally or
accidentally obscure oncoming vehicles or safety-critical output of
other AR applications. In this work, we address the fundamental
challenge of securing AR output in the face of malicious or buggy
applications. We design, prototype, and evaluate Arya, an AR
platform that controls application output according to policies
speciﬁed in a constrained yet expressive policy framework. In
doing so, we identify and overcome numerous challenges in
securing AR output.
I.
INTRODUCTION
Augmented reality (AR) technologies enable users to in-
teract with virtual content in fundamentally new ways. AR
applications capture input from a user’s surroundings, such as
video, depth sensor data, or audio, and they overlay output
(e.g., visual, audio, or haptic feedback) directly on the user’s
perception of the real world, through devices like smartphones,
head-mounted displays (HMDs), or automotive windshields.
While commercial AR efforts are relatively young, they
are beginning to capture the attentions of users worldwide.
For example, the wildly popular mobile AR app “Pok´emon
Go” [35] brought
in over $600 million in revenue in its
ﬁrst three months after release, making it the most successful
mobile game in history [44]. However, the potential of AR lies
far beyond simple smartphone games, and we are beginning to
see rapid growth in new AR technologies. For example, Mi-
crosoft’s HoloLens HMD is now available to developers [20],
Meta’s second-generation HMD is available for pre-order [27],
and Google has invested over $500 million in the HMD
startup Magic Leap [28]. Additionally, many groups within the
automotive industry are developing AR-enabled windshields
to aid drivers [15, 26, 46]. Overall, interest in employing AR
technologies across diverse industry sectors is increasing, with
AR as a whole projected to grow into a $100 billion industry
by the year 2020 [1].
Challenge: AR Output Security. Though AR technologies
have the potential to deliver tremendous beneﬁts, they also
raise new privacy and security risks. A growing body of
literature focuses on mitigating privacy risks that stem from
applications’ needs to gather input from the numerous sensors
on AR devices, such as cameras [8, 18, 37, 39, 40, 45]. In this
work, we focus instead on a complementary issue: the security
risks of AR output, or the risks that arise from AR applications’
abilities to modify a user’s view of the world. Addressing these
risks is particularly critical for fully immersive AR systems,
such as HMDs and car windshields, where users cannot easily
disengage from their devices if output security issues arise.
To illustrate potential security risks related to AR output,
imagine driving a car with an AR-enabled windshield. The
intended beneﬁts of this technology include the ability to vis-
ibly highlight lane markers to prevent accidental lane drift, to
display turn-by-turn driving directions visually overlaid on the
road, and to visibly warn the driver of impending collisions —
examples already showcased by industry, e.g., [17] (see also
Figure 1). These tasks might run as multiple components
of a single application, or as multiple, distinct applications.
Without appropriate safeguards, however, the beneﬁts of these
applications can be overshadowed by risks. A malicious or
buggy AR application could potentially obscure real-world
pedestrians, overlay misleading information on real-world road
signs, or occlude the virtual content of other AR applications,
such as collision warnings or other important safety alerts.
Similar issues could arise with HMDs for a user on foot.
Consider, for example, an HMD application that accidentally
or intentionally blocks the user’s view of a tripping hazard or
an oncoming car. The ability of AR content to obscure real-
world objects is not hypothetical, as Figure 2 shows.
To our knowledge, no existing industry or research AR
platforms are designed to mitigate the above types of output
security risks. Today, it is the responsibility of the applications
themselves to safely generate output and to adhere to guide-
lines such as those suggested for HoloLens developers [29].
For instance, these guidelines suggest that applications should
not create AR content that covers too much of the user’s
view of the world, but HoloLens itself does not enforce this.
Placing this responsibility on application developers, who may
generate buggy, vulnerable, or malicious code, is problematic.
© 2017, Kiron Lebeck. Under license to IEEE.
DOI 10.1109/SP.2017.13
320
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:24:47 UTC from IEEE Xplore.  Restrictions apply. 
Fig. 1: Example AR Scenario. This screenshot
from Hyundai’s
CES demo [17] shows an AR warning overlaid on a car and the
car’s current speed. In future AR platforms, we expect that multiple
applications will simultaneously produce output.
Furthermore, the fact that today’s AR platforms cannot exert
any control over the output of individual applications means
they also cannot handle conﬂicts between the output of multi-
ple applications. Indeed, HoloLens sidesteps this problem by
not supporting multiple full-screen immersive AR applications
running at once.
Our Work: Designing for Secure AR Output. We seek to
change the above situation. Speciﬁcally, we design, implement,
and evaluate a prototype AR platform with output security as
an explicit, ﬁrst-class goal. We refer to our design as Arya.
In our threat model, Arya is trusted, but the AR applications
running on Arya are untrusted. With Arya’s security mecha-
nisms enabled, applications still have signiﬁcant ﬂexibility to
create immersive AR experiences, but their visual content is
constrained by the platform based on policies, such as ensuring
that windshield applications cannot obscure real-world road
signs or pedestrians while the car is moving. This work
both identiﬁes and overcomes numerous challenges towards
designing AR systems to mitigate output security risks.
Our core design builds upon the designs of prior AR systems
and includes sensors, such as cameras and microphones; rec-
ognizers [18] to detect objects, such as cars and people, from
the sensed input; and an input policy module [40] to determine
which of the sensed objects should be passed to applications,
possibly with modiﬁcation. The central difference in Arya is
the inclusion of an output policy module that sits between
applications and the AR system’s output drivers, and that
enforces policy-based constraints on application outputs. While
the potential utility of an output policy module was suggested
in a position paper [21], we are the ﬁrst to concretely explore
the feasibility of an output policy module in practice. We
ﬁnd that designing an output policy module is fundamentally
challenging, and requires identifying and answering key design
questions, such as how to express desired output policies, how
to enforce those policies, and how to handle policy conﬂicts.
We identify and overcome these challenges through the
iterative design, implementation, and evaluation of Arya and
our Arya prototype. To drive our design, we develop a set
of case study output policies based on existing policies drawn
Fig. 2: Real-World Occlusion. This photo was taken by a smartphone
camera through a HoloLens display (resulting in some reﬂective
camera artifacts). It shows that virtual content displayed by HoloLens
(here, a cat) can visually obscure real-world objects (also a cat).
from several sources, including the HoloLens developer guide-
lines [29] and guidelines for the visibility of road signs [6]. For
example, we use a guideline that real-world trees should not
block road signs to inspire a policy that virtual objects should
not block real-world road signs. To support such policies, we
design an AR output policy speciﬁcation framework that allows
policy writers to specify both (1) a condition under which
the policy is violated (e.g., when a virtual object blocks a
real-world person) and (2) an action to take (e.g., make the
offending virtual object partially transparent). We carefully
constrain this policy framework to support composable policies
and to limit the potential performance or other impacts of
buggy or malicious policies. We do not specify where policies
come from in this work — they may come from the device
manufacturer itself or other sources.
We develop our prototype atop the Unity game engine [47],
an environment for creating interactive 3D content. To evaluate
the output management portion of Arya through controlled
experiments that simulate different real-world contexts, we
develop virtual Unity scenes rather than using real-world sen-
sor input. Our scenes represent HMD and car windshield AR
scenarios, and we develop a set of case study applications that
run within these scenarios. We demonstrate that our prototype
can support the policies we identify and prevent corresponding
undesirable situations in our case studies. We conduct a
performance evaluation consisting of both microbenchmarks
and a full system evaluation, and we ﬁnd that the performance
impact of policy enforcement in even our unoptimized pro-
totype is acceptable. Our prototype played a central role in
iteratively driving the design of Arya, and our design choices
and evaluation ﬁndings provide lessons for future AR system
designers.
Contributions. In summary, we contribute the following:
1) AR Output Security: We address, for the ﬁrst time, the
fundamental challenge of securing AR output in the
face of malicious or buggy applications. We design
321
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:24:47 UTC from IEEE Xplore.  Restrictions apply. 
Arya, an AR platform that can control visual application
output according to output policies. Our design prevents
single applications from modifying the user’s view of
the world in undesirable ways, and it securely supports
multiple applications simultaneously augmenting the
user’s view of the world — unlike existing AR platforms
such as HoloLens, which do neither.
2) AR Output Policies: We develop a policy speciﬁca-
tion framework for deﬁning output policies that
is
designed to provide desirable properties (e.g., to limit
performance impact and support composable policies).
Through our design process, we uncover and overcome
fundamental challenges in realizing the above vision,
including how to specify and enforce policies, and how
to handle conﬂicting policies. Despite its restrictions,
we demonstrate that our framework can support real
policies from multiple sources, such as the HoloLens
developer guidelines and U.S. Department of Trans-
portation guidelines for in-vehicle electronic devices.
3) Prototype, Evaluation, Lessons: We prototype Arya on
top of the Unity game engine and develop case study
applications and policies for both HMD and automotive
AR scenarios. We conduct benchmark and full system
evaluations, ﬁnding the performance of policy enforce-
ment acceptable. From our experiences, we surface
lessons and recommendations for future AR systems.
We stand today at a pivotal juncture with AR technologies,
just as we did in the early 2000s with smartphones — there
are clear indicators that these emerging technologies are on
the horizon, yet it is still very early in their life cycles. Thus,
now is the time to consider security for AR. It is critical
that we identify and address AR security challenges while
the technologies are still young and designs are not yet set
in stone. Our work lays a technical foundation to support
future AR security efforts, and to enable immersive single-
and multi-application AR platforms whose potential beneﬁts
are not overshadowed by risks due to buggy, malicious, or
compromised AR application output.
II. CONTEXT
We begin by providing additional context on the capabil-
ities of AR and its rising commercial presence. Emerging
commercial AR platforms support fundamentally new types
of applications that can respond contextually to input from a
user’s ever-changing environment, and that can directly alter
the user’s perception of his or her world with visual, auditory,
or haptic output. Since today’s AR devices primarily rely on
immersive visual feedback, we focus most of our concrete
discussions on visual output, though we note that similar issues
may apply to other output modalities (e.g., audio or haptic).
Many industries are beginning to leverage emerging AR
technologies for diverse purposes. For example, Microsoft’s
HoloLens is being used by NASA’s Jet Propulsion Laboratory
to guide astronauts through complex tasks [2], and by the
Israeli military to manipulate terrain models and monitor
troop positions [3]. Along with Microsoft, companies such
as Meta [27] and Magic Leap [25] are also developing so-
phisticated AR headsets. Additionally, the U.S. military has
shown increasing interest in AR [23, 32, 41], and researchers
and companies within the automotive industry are exploring
AR-enabled windshields and dedicated HMDs to aid drivers.
Haeuslschmid et al. [15] describe a broad taxonomy of AR
windshield applications grounded in existing literature, ranging
from safety-oriented apps (e.g., highlighting lane markers to
warn a driver of accidental
lane drift) to navigation apps
(e.g., path ﬁnding with 3D navigation arrows). Recent demos
from Hyundai [17] (shown in Figure 1) and Continental [7]
demonstrate the capabilities of early-stage AR windshields,
and organizations such as BMW [4] and Honda Research [46]
continue to push the boundaries of automotive AR.
Though emerging AR platforms and applications hold great
promise,
these technologies are still young and under ac-
tive development. For example, HoloLens has only released
its developer edition to date, and it is limited by the fact
that only one immersive AR application can run at a time.
However, we expect that future AR users will wish to allow
multiple applications to simultaneously augment their view of
the physical world, e.g., one application that translates and
superimposes text in real time, one that shows calendar and
email alerts, and one that runs a game (such as Pok´emon
Go). Similarly, in future versions of the automotive example
in Figure 1, we envision that the collision warning capability
and the speedometer capability might be different applications
written by different development teams within the automotive
company, or even by third-party app providers.
III. MOTIVATION AND THREAT MODEL
In addition to their novel opportunities, AR applications
have a unique ability to impact users’ perceptions of the real
world in undesirable or harmful ways. To understand these
risks, consider the popular mobile AR app Pok´emon Go.
While this game is a relatively simple smartphone app today,
it provides a taste of how emerging platforms like HoloLens
will be able to capture the attention of users [42]. In contrast
to smartphones, HMDs provide continuous, fully immersive
experiences by enveloping a user’s entire ﬁeld of view. With
these emerging HMD platforms, we envision that a user may
wish to multitask while playing a game like Pok´emon Go —
for example, by using an app that overlays walking directions
to nearby restaurants, or by using a labelling app to recognize
and point out nearby social media contacts. To reap the full
beneﬁts of these apps, the user will need to use them while
actively moving about and interacting with the real world.
The interaction of multiple AR apps with each other and
with the user’s view of the real world raises risks. If one of the
apps were malicious or buggy, it could (a) annoy or distract
the user with spurious content (e.g., poorly-placed ads), (b)
endanger the user by occluding critical information in the real
world (e.g., by obscuring oncoming vehicles), or (c) perform
a denial of service attack on another application by occluding
that application’s output (e.g., a Pok´emon creature that pre-
vents the user from seeing navigation directions). Indeed, a
recent concept video sketches out a possible future in which
AR technologies fail to address these types of threats, as shown
in Figure 3. While we describe these risks in terms of an HMD
322
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:24:47 UTC from IEEE Xplore.  Restrictions apply. 
blocking important real-world information, such as people,
with AR content. Arya handles policies that can constrain
when and where applications display content;
it does not
support policies that constrain what content is displayed (e.g.,
a 3D animal versus a 3D rock).
We assume that Arya’s operating system, drivers, and
platform hardware are trusted. However, applications are not
trusted by the system. Speciﬁcally, we assume that applications
may be intentionally malicious, unintentionally buggy, or com-
promised, potentially leading to undesirable AR output. For
example, an adversary might attempt to sneak an intentionally
malicious application onto an open platform’s app store (like
the HoloLens app store), or different
trusted development
teams within a closed AR platform (e.g., a closed automotive
AR platform) might produce applications that interact with