Internet. Thus, the links between mixes have more variable delays and are less
reliable on average in a peer-based setting.
The simulation selected a drop rate for each link using an exponential distri-
bution around an average value. We modeled the drop rate on the link between
the initiator and ﬁrst mix diﬀerently than those on the links between mixes.
The link between the initiator and the ﬁrst mix exhibits a drop rate, called the
early drop rate (edr), with average either 1% or 5%. In the server scenario, the
average inter-mix drop rate (imdr) is either 0%, meaning that there are no drops
on the link, or 1%. For the imdr in the peer-based scenario, we use either 1% or
5% percent as the average drop rate. The lower imdr in the server case reﬂects
good network conditions as can usually be seen on the Internet Traﬃc Report
(http://www.internettraﬃcreport.com). For many test points on the Internet,
there is typically a drop rate of 0%, with occasional jumps to about 1%. Some
test points see much worse network performance, with maximal drop rates ap-
proaching 25%. Since these high rates are rare, we allow them only as unusually
high selections from the exponential distribution using a lower average drop rate.
For the peer-based scenario, the average delay on a link is selected using a
distribution from a study of Gnutella peers [17]. The median delay from this
distribution is about 112ms, but the 98th percentile is close to 3.1 seconds,
so there is substantial delay variation. For the server scenario, we select a less
variable average delay, using a uniform distribution between 0ms and 1ms (“low”
delay) or between 0ms and 100ms (“high” delay). Given an average delay for a
link, the actual per-packet delays are selected using an exponential distribution
with that delay as the mean. This is consistent with results from Bolot [5].
In addition to edr, imdr, and delays, the simulation also accounts for the
length of the initiator’s path and the initiator’s communication rates. The path
length can either be 5 or 8 or selected from a uniform distribution between these
Timing Attacks in Low-Latency Mix Systems
7
values. Larger path lengths are more diﬃcult to use, since packets must have a
ﬁxed length [6].
Generating initiator traﬃc requires a model of initiator behavior. For this
purpose, we employ one of four models for initiator behavior:
– HomeIP: The Berkeley HomeIP traﬃc study [11] has yielded a collection
of traces of 18 days worth of HTTP traﬃc from users connecting to the Web
through a Berkeley modem pool in 1996. From this study, we determined the
distribution of times between each user request. To generate times between
initiator requests during our simulation, we generate uniformly random num-
bers and use those to select from the one million points in the distribution.
– Random: We found that the HomeIP-based traﬃc model generated rather
sparse traﬃc patterns. Although this is representative of many users’ brows-
ing behavior due to think times, we also wanted to consider a more active
initiator model. To this end, we ran tests with traﬃc generated using an ex-
ponentially distributed delay between packets, with a 100ms average. This
models an active initiator without any long lags between packets.
– Constant: For other tests, we model initiators with that employ constant
rate path cover traﬃc. This traﬃc generator is straightforward: the initiator
emits messages along the path at a constant rate of ﬁve packets per second,
corresponding to sending dummy messages when it does not have a real
message to send. (Equivalently, the Random traﬃc model may be thought
of as a method of generating somewhat random cover traﬃc along the path.)
– Defensive Dropping: Defensive Dropping is similar to Constant, as the
initiator sends a constant rate of cover traﬃc. The diﬀerence is that packets
are randomly selected to be dropped. The rate of packets from the initiator
remains at ﬁve packets per second, with a chosen drop rate of 50 percent.
Given a set of values for all the diﬀerent parameters, we simulate the initia-
tor’s traﬃc along the length of her path and have the attacker save the timings
of packets received at the ﬁrst and last mixes. We generate 10,000 such simula-
tions. We then simulate the timing analysis by running a cross correlation test
on the timing data taken from the two mixes. We test mixes on the same path
as well as mixes from diﬀerent paths.
The statistical correlation test we chose works by taking adjacent windows of
duration W. Each mix counts the number of packets Xk it receives per path in
the k-th window. We then cross-correlate the sequence {xk} of values observed
for a path at one mix, with the sequence {x′
k} observed for a path at a diﬀerent
mix. Speciﬁcally, the cross correlation at delay d is deﬁned to be
r(d) =
i
(xi − µ)
x′
i+d − µ′
i (xi − µ)2
i
x′
i+d − µ′2
where µ is the mean of {xk} and µ′ is the mean of {x′
k}. We performed tests
with W = 10 seconds and d = 0; as we will show, these yielded useful results for
the workloads we explored.
8
Levine, Reiter, Wang, and Wright
imdr
0%
1%
5%
traﬃc
delay
low
high
low
high gnutella gnutella
pattern
edr
HomeIP
1%
0.0000 0.0003 0.0007 0.0008
0.0026
0.0061
5%
0.0001 0.0005 0.0008 0.0010
0.0039
0.0070
Random
1%
0.0000 0.0000 0.0000 0.0000
0.0002
0.0003
5%
0.0000 0.0000 0.0000 0.0000
0.0004
0.0005
Constant
1%
0.0011 0.0346 0.0350 0.0814
0.1372
0.2141
5%
0.0002 0.0079 0.0108 0.0336
0.0557
0.1014
Defensive Dropping 1%
0.1925 0.2424 0.2022 0.2506
0.2875
0.3117
5%
0.0930 0.1233 0.1004 0.1289
0.1550
0.1830
Table 1. Equal error rates for simulations with path lengths between 5 and 8, inclusive.
The rows represent the initiator traﬃc model and drop rate before reaching the ﬁrst
mix (edr). The columns represent the delay characteristics and drop rates (imdr) on
each link between the ﬁrst mix and the last mix. See Section 5 for details.
We say that we calculated r(0; I, J) if we used values {xk} from packets on
P I as seen by M I
1 and used values {x′
k} from packets on P J as seen by M J
h .
We infer that the values {xk} and {x′
k} indicate the same path (the attackers
believe that I = J) if |r(0; I, J)| > t for some threshold, t. For any chosen t, we
calculate the rate of false positives: the fraction of pairs (I, J) such that I ̸= J
but |r(0; I, J)| > t. We also compute the false negatives: the fraction of initiators
I for which |r(0; I, I)| ≤ t.
6
Evaluation Results
Decreasing the threshold, t, raises the false positive rate and decreases the false
negative rate. Therefore, an indication of the quality of a timing attack is the
equal error rate, obtained as the false positive and negative rates once t is ad-
justed to make them equal. The lower the equal error rate, the more accurate
the test is.
Representative equal error rate results are shown in Table 1. For all of these
data points, the initiator’s path length is selected at random between 5 and 8,
inclusive. Not represented are data for ﬁxed path lengths of 5 and 8; lower path
lengths led to lower equal error rates overall.
Results presented in Table 1 show that the timing analysis tests are very
eﬀective over a wide range of network parameters when there is not constant rate
cover traﬃc. With the HomeIP traﬃc, the equal error rate never rises to 1%.
Such strong results for attackers could be expected, since initiators often have
long gaps between messages. These gaps will seldom match from one initiator
to another.
Perhaps more surprising is the very low error rates for the attack for the
Random traﬃc ﬂows (exponentially distributed interpacket delays with average
delay of 100ms). One might expect that the lack of signiﬁcant gaps in the data
Timing Attacks in Low-Latency Mix Systems
9
would make the analysis more diﬃcult for the attacker. In general, however,
the gaps still dominate variation in the delay. This makes correlation between
unrelated streams unlikely, while maintaining much of the correlation along the
same path.
When constant rate cover traﬃc is used, the eﬀectiveness of timing analysis
depends on the network parameters. When the network has few drops and low
latency variation between the mixes, the attacker continues to do well. When
imdr = 0% and the inter-mix delay is less than 1ms, meaning that the variation
in the delay is also low, the timing analysis had an equal error rates of 0.0011 and
0.0002, for edr = 1% and edr = 5%, respectively. Larger delays and higher drop
rates lead to higher error rates for the attacker. For example, with imdr = 1%
drop rate and delays between 0ms and 100ms between mixes, the error rates
become 0.0814 for edr = 1% and 0.0336 for imdr = 5%.
6.1
Eﬀects of Network Parameters
To better compare how eﬀective timing analysis tests are with diﬀerent network
parameters, we can use the rates of false negatives and false positives to get a
Receiver Operator Characteristic (ROC) curve (see http://www.cmh.edu/stats/
ask/roc.asp). Let fp denote the false positive rate and fn denote the false negative
rate. Then fp is the x-axis of a ROC curve and 1 − fn is the y-axis. A useful
measure of the quality of a particular test is the area under the curve (AUC).
A good test will have an AUC close to 1, while poor tests will have an AUC as
low as 0.5. We do not present AUC values. The relative value of each test will
be apparent from viewing their curves on the same graph; curves that are closer
to the upper left-hand corner are better. We only give ROC curves for constant
rate cover traﬃc, with and without defensive dropping, as the other cases are
generally too close to the axes to see.
We can see from the ROC curves in Figure 2 how the correlation tests perform
with varying network conditions. The bottommost lines in Figures 2(a–b) show
that the test is least accurate with imdr = 5% and the relatively large delays
taken from the Gnutella traﬃc study. imdr appears to be the most signiﬁcant
parameter, and as the imdr lowers to 1% and then 0% on average, the ROC
curve gets much closer to the upper left hand corner. Delay also impacts the
error rates, but to a lesser extent. Low delays result in fewer errors by the test
and a ROC curve closer to the upper-left-hand corner.
In Figure 2(c), we see how the correlation tests are aﬀected by edr. edr’s
eﬀect varies inversely to that of imdr. With edr = 5%, the area under the ROC
curve is relatively close to one. Note that the axes only go down on the y-axis
to 0.75 and right on the x-axis to 0.25. For the same imdr, correlation tests with
edr = 1% have signiﬁcantly higher error.
Figure 2(d) graphs the relationship between path length an success of the
attackers. Not surprisingly, longer paths decrease the attackers success as there
is more chance for the network to introduce variability in streams of packets.
We can compare the use of defensive dropping with constant rate cover traﬃc
in Figures 2(e–f). It is clear that in both models, the defensive dropping ROC
10
Levine, Reiter, Wang, and Wright
0.5
0.55
0.6
0.65
0.7
0.75
0.8
0.85
0.9
0.95
1
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
1 - (False Negative Rate)
False Positive Rate
imdr = 0%, low delay
imdr = 0%, high delay
imdr = 1%, low delay
imdr = 1%, high delay
imdr = 1%, p2p delay
imdr = 5%, p2p delay
0.5
0.55
0.6
0.65
0.7
0.75
0.8
0.85
0.9
0.95
1
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
1 - (False Negative Rate)
False Positive Rate
imdr = 0%, low delay
imdr = 0%, high delay
imdr = 1%, low delay
imdr = 1%, high delay
imdr = 1%, p2p delay
imdr = 5%, p2p delay
(a) edr = 1%
(b) edr = 5%
0.75
0.8
0.85
0.9
0.95
1
0
0.05
0.1
0.15
0.2
0.25
1 - (False Negative Rate)
False Positive Rate
edr = 5%, imdr = 0%
edr = 5%, imdr = 1%
edr = 1%, imdr = 0%
edr = 1%, imdr = 1%
0.95
0.96
0.97
0.98
0.99
1
0
0.005
0.01
0.015