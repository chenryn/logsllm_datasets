Data
D: Random Extras
TABLE I
FUZZ INTENT CAMPAIGNS
Characteristics of Intents Generated
Valid Action and valid Data URI are generated
separately, but
the combination of them may be
invalid.
Either Action OR Data URI is speciﬁed for each
Intent, but not both. All other ﬁelds are left blank.
Action or the Data URI is valid, and the other is
set randomly.
For each Action deﬁned, we create a valid pair
{Action, Data} with a set of 1-5 Extra ﬁelds
with random values.
# Intents Generated
|Action| × |TypeOf(Data)|
1M aprox. Intents overall
|Action| + |TypeOf(Data)|
100K aprox. Intents overall
|Action| + |TypeOf(Data)|
300K aprox. Intents overall
|Action|
250K aprox. Intents overall
Intent Example
{act=ACTION_DIAL,
data=http://foo.com/,
cmp=some.component.name}
{data=tel:123,
cmp=some.component.name}
{act=ACTION_DIAL,
cmp=some.component.name}
{act=ACTION_DIAL,
data=tel:123,
cmp=some.component.name
(has extras)}
TABLE II
APPLICATION STATS
Category
Health/Fitness
Health/Fitness
Not Health/Fitness
Not Health/Fitness
Total
Classiﬁcation
Built-in
Third Party
Built-in
Third Party
#
2
11
9
24
46
# Activities
81
80
168
185
514
# Services
34
59
188
117
398
System reboot. The Operating System reaches an unrecov-
erable state and the device reboots. The reboot can also be
conﬁrmed in the log ﬁles collected from the target device. This
is a serious manifestation because it can be used to launch a
Denial-of-Service against the entire device.
Crash. The application crashes due its inability to handle
malformed intents. This behavior is identiﬁed in the log ﬁles
as a “FATAL EXCEPTION: main” entry.
Hang or unresponsive. The application experiences temporary
unresponsiveness or freezes permanently, and does not respond
to any action. Eventually a correct state is achieved,
in
some cases with human intervention. This manifestation is
distinguish by an ANR (Application Not Responding) error
in the log ﬁles.
No effect. There is no effect or failure manifestation due to
the malformed intent. The application and the OS behave as
expected. We can verify this behavior from the log ﬁles by the
absence of exceptions or errors, or a SecurityException
triggered by the OS after receiving the malformed intent.
D. Experiment Setup
The FIC experiments were conducted using a phone (LG
Nexus 4) paired via bluetooth to a wearable device (Moto
360, running Android Wear 2.0 released in Feb 2017). QGJ
was installed on both devices. The phone was used to choose
the required input and start the FICs intended to fuzz the
applications installed on the smartwatch. No injections were
performed on the phone. Prior to the experiments, we tested
all the applications on the wearable device to check for basic
device-app compatibility. Moreover, we performed any initial
setup required by the apps, to ensure that all the functionalities
are available during the experiments. One important point
of departure in our app components is the relatively high
frequency of Services compared to Activities. Previous studies
had targeted Activities at a higher rate since they are more
numerous in regular Android applications. Since the user
interaction with wearable apps is usually shorter as compared
to mobile apps, most of each application’s workload is done
by Services, which are background running components that
do the work triggered by some user action.
During the experiments, over a million and half intents
were sent to over 900 components (between Activities and
Services). The mechanism to run the experiments is as follows.
First, we choose a particular wearable application using QGJ
UI, from the mobile phone, and begin the experiments. The
fuzzer starts injecting malformed intents according to the
particular FIC. All 4 campaigns are executed one after another.
Once the execution of the experiments is done, we collected
all of the log ﬁles (over 2GB) from the wearable using
logcat, through the adb interface. Then, we analyzed the
logs to gather information, and for each component classiﬁed
the behavior of the application according to the expected
scenarios described in Section III-C. For any failure or error
encountered, we manually analyzed further the logs ﬁles to
ﬁnd their possible root cause. The QGJ fuzzing model is based
on injection of random intents into the wearable app, following
a pattern deﬁned for each experiment. To keep the load due
to intents realistic, we insert two delays: (a) 100 ms between
successive intents similar to JJB; and (b) 250 ms after every
100 intents. It was empirically determined by checking the
logs that these delays were required to ensure the device is
not overloaded.
Since previous works targeted earlier version of Android,
we decided to run similar experiments on a mobile phone to
have a more accurate comparison between the Android and
AW ecosystem. The experiments included all four campaigns,
targeting a Nexus 6 running Android 7.1.1. We focus our
attention on common applications pre-loaded on the phone
(e.g. Google Chrome, Google Play Store), which are often use
by third party application for implementing common function-
alities. After ﬁltering the apps by the preﬁx com.android,
we found 63 apps (595 Activities and 218 Services).
E. QGJ-UI Design
While QGJ-Master evaluates the robustness of AW applica-
tions by sending explicit intent messages, it does not test how
apps handle user interactions. In most cases, sending an intent
via QGJ-Master has the effect of launching an activity or a
service. However, after launching an application, users often
interact with the application (or the device underneath) either
via touchscreen or via hardware keys. Evaluating application
robustness against such interactions would require emulating
user interface (UI) events. For this purpose, we developed
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:25:53 UTC from IEEE Xplore.  Restrictions apply. 
413
4
QGJ-UI based on the Android stress testing tool Monkey [7],
which mutates intents or user events resulting from UI actions.
Figure 1b depicts QGJ-UI workﬂow. First, monkey is run
on the target device to generate a speciﬁc number of UI events
( 5 ). For event generation, we specify equal percentages for
different types of events (e.g. touch, trackball, app switch,
permission etc.). These UI events may trigger monkey to
generate some intents. Next, the monkey logs are parsed to ﬁnd
the UI events and intents sent to the wearable ( 6 ). Similar to
QGJ-Master, QGJ-UI generates two types of mutated events
– semi-valid and random. In semi-valid, the arguments for
an event are randomly replaced by another valid value for
that argument that had been observed during the experiment.
Similarly, for random events, the arguments are replaced with a
random ASCII string or a ﬂoat value (depending on type). An
example random event would be: input tap -8803.85
4668.17 (note the invalid X, Y coordinates). These mutated
events or mutated intents are then sent to the target device
using adb shell utilities.
For this experiment, we used an Android Watch emulator
(Android 7.1.1, API level 25) and paired it with a Nexus
6 phone (Android 7.1.1). The choice of the Watch emulator
instead of the actual watch from the QGJ-Master experiment
was so that we could study the core functionality in isolation
(which is incorporated into the emulator) rather than together
with the vendor-speciﬁc extensions (as would be present in the
actual watch). Moreover, since different watches have varying
screen sizes and shapes, the same UI event may execute widely
different actions across devices. Using an emulator helps us
avoid that and run repeatable experiments. Similar to the apps
listed in Table II, we installed on the emulator all the built-
in apps and the top 20 of the most popular third-party apps.
Although we do not target the phone for this study, several
Wear apps caused UI components to pop-up on the phone.
Logs from the emulator were collected using logcat and
later analyzed to generate the results, which we present in
Section IV-D.
IV. EXPERIMENTAL RESULTS
We discuss our results based on the following perspectives:
(i) distribution of the error manifestations in the apps in
response to fuzzed intents; (ii) distribution of exceptions and
their ultimate error manifestations.
Fig. 2. Distribution of type for uncaught exceptions (without considering
Security Exception) grouped by component type.
A. Distribution of Exception Types
To understand how well Android Wear responds to mal-
formed intents, we measure the distribution of uncaught
exceptions over all FICs. Here each exception is counted
once per component, even if it was raised several
times.
Fig. 2 shows the distribution without considering security
exceptions, which represent 81.3% of all exceptions. Some
intents are reserved for privileged OS processes and when
sent by QGJ raises the security exception. For example, when
QGJ sends an intent {act=ACTION_BATTERY_LOW}, a
SecurityException is thrown and the intent is ignored
by AW. This is the speciﬁed and secure behavior. After
SecurityException, the second largest share belongs to
IllegalArgumentException. This type of exception is
raised because of the mismatch on the data contained in an
injected intent and what is expected by the component.
We next consider the proportion of application components
that are affected by the mutated intents and classify the
components according to the 4 manifestations. This is shown
in Figure 3a. If a component has different manifestations to
multiple injected intents, we take the most severe manifes-
tation. We ﬁnd that almost 90% of the components are not
affected at all. The most dominant error class is crash, which
is more than 8X the next error class, unresponsive. The most
severe error class, device reboot, affects 4 of the components.
Next, for each error manifestation, we study what exceptions
are the ultimate cause of that manifestation. This is shown in
Figure 3. The exception to which an error is ascribed is the
one that we determine through a simpliﬁed and semi-automatic
root cause analysis. With many cases a simple temporal chain
is used to determine the root cause automatically—thus the
ﬁrst exception in a chain of exceptions is assigned the guilt
(e.g. in the case of RuntimeExceptions). In some cases,
a tight-knit pattern among the exceptions is deduced and
one cannot be inferred to causally precede the others. In
such cases, we assign the blame for that error manifestation
equally among the exception classes. The ﬁrst observation
we make is that the NullPointerException still dom-
inates the crash cases, as in all prior studies on Android
reliability [5], [8], [10]. However, the relative proportion is
less and the decrease has been taken up by an increase
in the proportion of IllegalArgumentException and
IllegalStateException. For the no effect case,
in
about 90% of the cases, there is no exception thrown upon re-
ceipt of the injected intent. In the remaining 10% of the cases,
an exception is thrown but that is handled by the app grace-
fully. For the pathological case of device reboot, three excep-
tion classes are equally culpable. For the unresponsiveness er-
ror category, IllegalStateException dominates, while
the presence of android.os.DeadObjectException
hints that garbage collection can have the undesirable effect.
Furthermore, a crash due to ArithmeticException
is worth highlighting. First, the ArithmeticException
was reported by a Health & Fitness application because a
”divide by zero” operation was reported on an AW class
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:25:53 UTC from IEEE Xplore.  Restrictions apply. 
414
5
(b) Distribution of exceptions by manifestation
(a) Distribution of error manifestations
Fig. 3.
(a) Distribution of error manifestation among all the app components targeted by QGJ. The legend corresponds to each of the states: (1) No Effect,
(2) Unresponsive, (3) Crash, (4) Reboot. (b) Distribution of the most frequent exceptions for each error manifestation. The percentage of each exception is
with respect to the total exceptions per manifestation. The number at the base indicates the absolute number of components showing such manifestation and
the percentage is with respect to the total number of injected components.
GridViewPager. This Layout Manager class, which allows
navigation in both axes, was deprecated in AW 2.0 in favor
of other classes since horizontal paging is not encouraged
anymore
[11], [12]. This ﬁnding indicates the presence of
errors in Android Wear ecosystem due to the lack of migration
to the AW 2.0 speciﬁcation of some applications.
the
attention
our
to
turn
Next, we
numerous
IllegalArgumentExceptions. This exception should
be thrown to indicate that an argument is either illegal or
inappropriate. It is not surprising to ﬁnd this exception in the
logs; however, this exception should not cause the application
to crash. A crashing behavior would indicate that
input
validation in the activity has been implemented only partially.
For instance, Google Fit, a core AW component, reported
a crash because an intent {act=ACTION_ALL_APP} was
sent without the expected message (Complication Provider).
B. Distribution of Error Manifestations
Fig. 4. Distribution of exceptions that originated crashes grouped by app
classiﬁcation.
tion depends on the transient state of device and happens
with error propagation across components and due to soft-
ware aging through repeated fuzzing campaigns. We give
the detailed post-mortem of these two cases considering
the severity of this error manifestation. First, a sequence
of malformed intents to a health app, which interacts with
heart rate sensor using SensorManager class (rather than
the more common Google Fit) provoked a system restart.
There were no exceptions raised before the crash, which
means the malformed intents were not rejected by the app.
During the sequence of injections,
the application experi-
enced unresponsiveness (ANR) which explains the SIGABRT
sent by the system to shutdown the SensorService process
/system/lib/libsensorservice.so. Since this is
the core process which handles Sensor access on AW, the
system was left in an unstable state and the device rebooted.
The second device reboot was due to the inability of the system
to start an Activity because of missing data in the malformed
intent injected in a built-in app. The application crashed several
times due to the inability to start the activity that prevented
it from binding to the Ambient Service, a core AW service
to control low-power ambient mode. Then, the system sent
a SIGSEGV, which caused segmentation fault of the system
process, that eventually ended up rebooting the device.
C. Distribution of Crashes on Android Phone
In Table IV, we show the results after targeting the mo-
bile phone (running Android 7.1.1) with the four FICs in
QGJ. Similar to previous studies [5], [8], [10],
the pri-
Table III presents the distribution of behaviors for all
applications over the four fuzzing campaigns, grouped by ap-
plication type (as Health/Fitness or Not Health/Fitness). Here
we classify the effect of the injection on an entire application
according to the four error manifestations. Since different
components within an app can have different manifestations,
we use the most severe manifestation for this result. We
conclude that there is no clear indication that Health/Fitness
apps, due to implicit complexity because of dependence on
other components (e.g., Google Fit API), are less robust than
others apps. Both categories have no effect due to the injection
at roughly the same rate, 69.2% for health apps versus 74.5%