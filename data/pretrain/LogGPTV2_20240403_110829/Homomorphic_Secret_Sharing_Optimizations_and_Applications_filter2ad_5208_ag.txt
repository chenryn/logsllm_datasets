/226.5 seconds; for example, for 128-bit inputs (i.e., n = 27)
this is roughly 135kB communication and 22ms computation time.
3
Consider the following alternative Beaver triple approaches.
• Paillier based. Beaver triples can be generated using an en-
cryption scheme that supports homomorphic addition and
multiplication by scalars, such as the Paillier cryptosystem.3
This approach requires notably less communication than
the HSS-based approach, as only 2 ciphertexts are required
as opposed to one ciphertext per input bit (where Paillier
ciphertexts with 80 bits of security are comparable size to
ours), and computationally requires a small constant number
of group operations.
However, this approach does not fully subsume HSS tech-
niques (and may be less preferred in some applications), as
it yields a qualitatively different protocol structure. In this
approach, the parties must exchange information, perform a
heavy “public key” computation (homomorphic evaluation),
exchange information once again, and then perform another
heavy computation (ciphertexts to be locally decrypted). In
particular, the computation and second exchange must be
performed if there is a chance the parties will wish to engage
in secure computation in the future.
In contrast, using HSS, the parties need only exchange infor-
mation once; this means a party can exchange HSS shares
with many others, and only later decide which from among
these he wishes to expend the computation to “expand” the
shares into correlated randomness. The expansion of shares
only involves local computation without communication,
which can be useful for mitigating traffic analysis attacks.
Another advantage of the HSS-based approach is that it can
use the same setup for generating correlations over different
rings. This can be useful, for instance, for secure computa-
tion over the integers where the bit-length of the inputs is
not known in advance.
• Coding based. Assuming coding-based intractability assump-
tions such as the pseudo-randomness of noisy Reed-Solomon
codes, there are protocols for generating Beaver triples of
n-bit field elements at an amortized cost of O (n) bits per
triple [2, 28, 35, 40]. These constructions rely on relatively
nonstandard assumptions whose choice of parameters may
require further scrutiny. Moreover, amortization only kicks
in when the number of instances is large (at least a few hun-
dreds). In contrast, the HSS-based approach can apply to a
small number of instances and, as noted before, can use the
same setup for generating correlations over different fields.
• OT based. Perhaps the best comparison approach for generat-
ing Beaver triples of n-bit ring elements (without requiring
2Note we cannot take advantage of the ×2 speedup for even/odd failure recovery since
this requires shares in a field of characteristic 2 whereas here shares are over Zq.
3For example, a Beaver triple can be generated from 2 executions of oblivious linear
evaluation (OLE), each of which achieved as: Party A generates a key pair (pk, sk) ←
GenEnc (1λ ) and sends an encryption Enc(x ) of x ∈ R to Party B, who replies with
the homomorphic evaluation Enc(ax + b ) for his a, b ∈ R, back to Party A who can
decrypt and learn ax + b.
amortization across a very large number of instances) is
achieved by evaluating n 1-out-of-2 OTs of n-bit strings [29,
36]. While this computation can be heavily optimized for
large n using OT extension, it requires communication of
2n(λ + ℓ) bits per such OT, for λ = 80 and ℓ = n. For
n ≥ 4096 = 212 this is greater communication than our
approach (and we expect this crossover to drop substantially
with future optimizations); note in our current implementa-
tion (on a single core of a standard laptop), a 212-bit Beaver
triple correlation can be generated via HSS in ∼ 12.1 minutes.
We remark that the crossover point is lower when instan-
tiating the HSS using ElGamal over elliptic-curve groups.
As discussed in Section 6.2, homomorphic evaluation over
an elliptic-curve group presently runs slower than over a
conversion-friendly group by roughly a factor of 5 × 103
(approx 106 conversions per second as opposed to 5 × 109),
but the corresponding ciphertext size is approximately 8
times smaller. In this setting, the HSS-based solution requires
1504n bits of communication (in the place of 3712n), yielding
a crossover of n = 672 ≈ 29.4. The current implementation of
HSS over elliptic curves would run notably longer at this size
(∼ 4.5 hours), but discovery of “conversion-friendly” elliptic
curve techniques may make this approach more competitive.
Universal bilinear forms. An appealing property of the HSS-based
generation procedure that sets it apart from competing techniques
is its universality: The same fixed communication and computation
can be used to speed up online evaluation of any collection of bilinear
maps on a set of inputs, and the identity of the maps need not be
known during the preprocessing phase.
For example, suppose parties hold respective inputs x, y ∈ {0, 1}n,
and wish to securely evaluate xT Ay for a collection of many dif-
ferent matrices A ∈ {0, 1}n×n, possibly not known at setup time.
For instance, each A may be an adjacency matrix representing
possible connectivity structures between n locations, so that the
above product computes correlation information along the graph
between the resource distribution of the two parties (encoded by x
and y). Given an instance of the bilinear form correlation (shares
of r x , ry ∈ {0, 1}n and each r x
j ∈ {0, 1}), then for each desired
i r
A = (aij ) the parties can take the appropriate linear combination
of their r x
shares (with coefficients aij) to yield a corresponding
i r
“bilinear Beaver triple.” This can be done even if the identity of
matrices A is not determined until runtime.
To the best of our knowledge, in this regime of universality, the
2
best competition is generic Yao/GMW for securely evaluating all n
products. Even utilizing optimized OT extension techniques [37],
2 bits of communication, indicating
this will require more than 100n
that an HSS-based approach wins in communication already for n ≥
84. The computation required for a 84-bit Beaver triple correlation
can be generated via HSS in ∼ 6.3ms.
y
j
y
5.3.2 Truth Table Correlations. Given access to a preprocessed
“one-time truth-table” correlation, one can securely evaluate any
function with polynomial-size domain by a single memory lookup
and short message exchange [21, 33], or provide speedups by run-
ning on sub-computations of a larger secure computation [21]. In
the full version, we describe a means for generating one-time truth-
table correlations via HSS techniques.
Session J1:  OutsourcingCCS’17, October 30-November 3, 2017, Dallas, TX, USA21195.4 Cryptographic Capsules
As a direction of future research, we propose HSS as a promising
approach for generating many (pseudo-)independent instances of
useful correlations given a short, one-time communication. The
idea is for parties to exchange a single short “capsule”4 of HSS-
encoded randomness, then locally apply HSS evaluation of the
computation that first expands the seed into a long sequence of
pseudo-random bits and then uses the resulting bits within the
sampling algorithm for the desired correlation. Combined with high-
stretch local PRGs [1, 3, 34], this may yield compression schemes
for many useful types of correlations. A natural application of
cryptographic capsules is to execute the preprocessing phase of a
multiparty computation protocol, using short communication (of
1/k ) for generating the material for evaluating a circuit
size O (C
of size C, where k is the locality parameter of the high-stretch
local PRG; all known protocols for generating such preprocessing
material have communication O (C)).
Additional challenges arise in this setting when dealing with
HSS error, as the number of homomorphic multiplications is much
greater than the size of the HSS-encoded seed. We introduce two
new techniques for addressing the effects of leakage. The first is
a method of “bootstrapping” leakage pads (as in Section 4.4.1),
enabling the parties to homomorphically generate fresh pseudo-
random pads from a small starting set via homomorphic evalua-
tion. The second is a more sophisticated variant of punctured OT
from [13], making use of prefix-punctured PRFs. Combined, we are
able to drop the cost of expanding an n-bit seed to m bits of corre-
√
lation (for m ≫ n) from O (m/n) per output using [13] to O (
m/n)
using our new techniques. We devote a section to the study of such
cryptographic capsules in the full version.
6 CONCRETE EFFICIENCY
In this section we discuss the concrete performance of our HSS
implementation, providing both analytical predictions and empiri-
cal data. Our implementation builds on the optimized conversion
algorithm from [13], but incorporates additional optimizations that
significantly improve the system’s performance. The optimizations
include the algorithmic improvements discussed in Section 4 and
some additional machine-level optimizations we describe in this
section.
We assume RMS multiplications are performed in the context of
an application which specifies a target error probability ε for each
multiplication. The performance of an RMS multiplication given ε
is determined by the performance of its two main components, ex-
ponentiations in the underlying group G (we will use multiplicative
notation for the group operation) and multiplicative-to-additive
share conversions in this group.
p for
a prime p that is pseudo-Mersenne, safe and ±1 mod 8. That is,
p = 2n − γ for a small γ and p = 2q + 1 for a prime q. If p is such a
prime then 2 is a generator of a group of size q in which the DDH
problem is assumed to be hard. One specific prime of this type on
which we ran our measurements is 21536 − 11510609.
Similarly to [13], we take G to be a large sub-group of Z∗
4Our notion of cryptographic capsules is unrelated to the previous notion of crypto-
graphic capsules from [7].
The optimized implementation from [13] viewed any element
with d leading zeros, i.e. an integer in the range 0, . . . , 2n−d −1, as a
distinguished point. The problem of locating a distinguished point
in the sequence h, 2h, . . . , 2w−1
h, where w is the word size of the
underlying computer architecture, is reduced to searching for the
pattern 0d in the first word of the representation of h. Computing
h2w from h requires with high probability only one multiplication
and one addition, if γ < 2w .
As discussed in Section 4.1, we improve on the approach of [13]
for conversion in several ways. First a distinguished point be-
gins with the pattern 10d, i.e. all integers in the range 2n−1
, . . . ,
2n−12n−d − 1. By Lemma 4.1 the probability of error is z · 2−d−1
for a payload z while the expected running time is 2d +1. Based on
this lemma and on Corollary 4.3 the average probability of error in
a single conversion on bit inputs is (B − 1)/16. This is a factor 16
improvement over the worst-case analysis of [13]. In fact, replacing
the pattern 0d by 10d is necessary for this improvement. Finally,
some machine level optimizations, described in Section 6.1, reduce
the running time by another factor of two. Altogether, we improve
the running time of the conversion procedure for a given failure
probability by a factor of 30 or more over the conversion procedure
of [13].
Three optimizations that were introduced in [11, 13] and which
we use are short-keys, time-memory trade-off for fixed-base expo-
nentiation and large-basis for key representation. The secret key
c which we used for ElGamal encryption is short, 160 bits in our
implementation, which is sufficiently secure given known cryptana-
lytic attacks. Trading memory for time in fixed base exponentiation
for base h, and maximum exponent length e is possible for a param-
2Ri +j for i = 0, . . . , ⌈e/R⌉ − 1, j = 0, . . . , R − 1.
eter R by storing h
Exponentiation can be computed by roughly ⌈e/R⌉ − 1 modular
multiplications of stored elements. The secret key c can be rep-
resented in base B instead of in binary, reducing the number of
ElGamal ciphertexts encrypting integers of the form xc (i ) from 160
per input bit to 160/ log B. This optimization reduces the storage
and the number of exponentiations at the expense of increasing the
number of conversion steps required for the same error probability
δ by a factor of B.
Table 2 sums up the parameters of a single RMS multiplication.
6.1 Low Level Optimizations
We were able to obtain substantial - more than double - improve-
ments in the implementation of the conversion algorithm compared
to the method described in [13]. Boyle et al. [13] look for the dis-
tinguishing pattern by considering “windows” of size w = 32 bits
in the binary representation of the group element. Each window,
once fixed, is divided into strips of length d/2. The implementation
looks first for a zero-strip of length d/2, and then incrementally
counts zeros on the left and on the right.
One improvement over the reported implementation of [13] is
to extend the window size to w = 64, and use the 64-bit arithmetic
operations offered by the CPU. Furthermore, with the aid of a partial
match lookup table, we were able to avoid counting zeros on the
left and on the right.
For an integer i, let l (i) be the number of trailing zeros in the
binary representation of i. Consider a table T of 2d /2 elements such
Session J1:  OutsourcingCCS’17, October 30-November 3, 2017, Dallas, TX, USA2120Parameter
Failure probability
Group operations
Expected conv. steps
Public key size (DEHE)
Share size per input (HSS)
Ciphertext size per input (DEHE)
Preprocessing memory
Analytic expression
(1 + s (B − 1)/2)/2d +3
(s + 1) ℓ+2d
R
(s + 1)2d +1
s + 3⌈√
s⌉ + 2
s + 2
s + 2⌈√
s⌉ + 1
(s + 1)(ℓ + 2d )(2R − 1)/R
Table 2: Parameters of a single RMS multiplication of binary
values as a function of B (basis size for representing secret
key), s = ⌈160/ log B⌉ (for 160-bit ElGamal secret key), R (mod-
ular exponentiation preprocessing parameter), and d (zero-
sequence length for the conversion algorithm). All sizes are
measured in group elements.
that T (i) = 2l (i ) − 1 for all 0 ≤ i < 2d /2. If the j-th strip is 0d /2, the
value of the preceding strip is i and the value of the subsequent
strip is k then a strip of d zero occurs if and only if k < T (i), as
the binary representation k of the next strip has at least d/2 − l (i)
leading zeros. The above optimization can be implemented to use
only 1 CPU cycle (8 uOPs). Globally, using the above optimization
and an extended window of w = 64 bits, we were able to process
each window with 129 uOPs (approx. 30 cycles), when the code was
compiled for d = 16. (We recall that since d is known at compile
time, the compiler will unroll iterations over half strips and the
final program will perform less micro-operations for increasing
ds.) All remaining arithmetic operations were based on the GNU
Multiple Precision library.5
Basic HSS operations, such as conversions and fixed-base group
operations, add up to less than 150 lines of code and run on a single
thread, meaning that all the following results can be easily scaled
linearly with the number of available processors.
1,000
600
200
100
60
20
10
6
2