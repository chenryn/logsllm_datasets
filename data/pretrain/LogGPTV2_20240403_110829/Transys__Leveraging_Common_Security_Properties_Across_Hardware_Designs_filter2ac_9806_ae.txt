(2) For AES designs with trojans, Transys successfully translates all assertions to the 20 trojan-injected AES designs. For instance, as illustrated in Figure 7, Transys translates four Information Flow Tracking (IFT) assertions from the trojan-free AES-04 design to the 20 AES designs, each with a different trojan. The trojans include leaking the secret key through AM radio, leakage current, spread spectrum communications, and draining the battery to cause a denial-of-service [25], [26]. In this context, the translated assertions can potentially be used to detect the injected trojans.

(3) For processor designs, we translate assertions from the OR1200 to five processor designs across two different architectures. We found that assertions A19 and A26 do not exist in the two RISC-V cores, as they pertain to the `l.mtspr` instruction and custom instructions, which are not implemented in these cores.

We first evaluate the remaining 46 out of the 50 total translations, achieving an 85% translation success rate. Among the seven failed cases, three fail in the Transformation Pass, and four fail in the Refinement Pass—Transys cannot find valid preconditions to make the consequent true. All the failed cases occur when translating assertions from OR1K designs to RISC-V designs: two to the OpenV core and five to the Picorv32 core.

We separately evaluate the four translations where the assertion does not exist in the target design. Transys successfully translates three of them. These three new assertions are valid but capture different policies than the original assertions. The false positive rate here is 75%.

(4) For RSA designs, we translate one assertion mined from the specification and five IFT assertions. All of these are successfully translated to the new designs.

(5) We also test Transys by translating the assertions back to the original designs. Transys successfully translates all assertions back to the original designs, indicating that the variable mapping pass can map variables to themselves, and the second and third passes preserve the structure of the assertions.

**Designs**
| Design Type | Total Translations | Total Success | Fail in VM Pass | Fail in T Pass | Fail in R Pass | Total Translation Rate |
|-------------|--------------------|---------------|-----------------|----------------|----------------|------------------------|
| AES         | 360                | 336           | 0               | 8              | 16             | 93%                    |
| AES w/ Trojan | 400                | 400           | 0               | 0              | 0              | 100%                   |
| CPU         | 46                 | 39            | 0               | 3              | 4              | 85%                    |
| RSA         | 18                 | 18            | 0               | 0              | 0              | 100%                   |
| **Total**   | **824**            | **793**       | **0**           | **11**         | **20**         | **96%**                |

**Figures:**
- **Figure 6:** AES01—AES18 translation results: total translation number and success rate.
- **Figure 7:** AES-T100—AES-T2100 translation results: total translation number and success rate.
- **Figure 8:** RSA01—RSA03 translation results: total translation number and success rate.
- **Figure 9:** CPU translation results: total translation number and success rate.

### C. Quality

To evaluate the quality of the translated assertions, we first check their validity for the target design using the model checking tool Cadence IFV. We then manually review the assertions alongside the design specifications to determine whether the translated assertions are semantically equivalent to the original assertions.

1. **Validity:**
   - We check the validity of the translated assertions by adding them to the target designs and running Cadence IFV. Figures 6, 7, 8, and 9 show the results.
   - For the nine IFT assertions, we do not have the tool to check their validity (167 in total), so their validity results are not available.
   - All other 626 translated assertions pass verification by Cadence IFV, indicating that the assertions generated by Transys are valid.

2. **Equivalence:**
   - Figures 10, 11, 12, and 13 show the results of the equivalence checking. Type equivalence refers to the case where the translated assertion and the original assertion belong to the same type or module of security properties, as given in Tables I, II, III, and IV. Semantic equivalence refers to the case where the translated assertion and the original assertion are semantically the same.
   - The translation of assertions to trojan-injected AES designs achieves a 100% semantic equivalence rate.
   - For other designs, the translation of 23 (64%) assertions has a type and semantic equivalence rate above 60% (between 60% and 100%). The translations of the remaining 13 (36%) assertions have a type and semantic equivalence rate between 20% and 50%. The low rates mainly occur in two cases: the translation of IFT assertions and the translation from OpenRISC cores to RISC-V cores.
   - The main reason for the translated assertions failing to capture the meaning of the original assertion is that the variable mapping pass fails to map to an accurate variable or even fails to map to the correct module in the target design. In all our experiments, we empirically choose the parameters in the Variable Mapping Phase to be α : β : γ = 3 : 2 : 1. This combination works well in most cases but not all.

### D. Case Studies

In this section, we present three examples:
1. **Translation from one AES design to another AES design.**
2. **Translation from one processor design to two different processor designs from two architectures (OR1K architecture and RISC-V architecture).**
3. **Translation of an IFT assertion from a trojan-free AES design to a trojan-injected design.**

**Figures:**
- **Figure 10:** Type and semantic equivalence for AES01—AES18 designs.
- **Figure 11:** Type and semantic equivalence for AES-T100—AES-T2100 designs.
- **Figure 12:** Type and semantic equivalence for RSA01—RSA03 designs.
- **Figure 13:** Type and semantic equivalence for CPU designs.

**Example 1:**
- We detail the translation of assertion A28-01 from AES09 to all AES designs. Table XI shows the resulting assertions.
- For the assertions in AES02, AES03, and AES12, we classify them as being of the same type as the original assertion but not semantically equivalent.
- For the assertions in AES16 and AES17, they pertain to the calculation of round keys and are neither type equivalent nor semantically equivalent to the original assertion.

**Table XII:**
- Detailed results of translating A28-01 from AES09 to AES03. After the Variable Mapping Pass, `keysched.next_key_reg` and `keysched.last_key_i` are both mapped to `key_exp.key_in`. The generated assertion is not yet valid.
- After the Transformation Pass, Transys outputs five assertions, generated from the part of the PDG that contains the variable `key_exp.key_in`. Only the fifth assertion is valid.
- From the Refinement Pass, all four assertions are refined and become valid. It is worth noting that the antecedents generated from the Refinement Pass are neither close to the part of the code of the consequent nor similar to the original code, making it difficult for a human to figure them out manually.

**Example 2:**
- Table XIII shows the translation results for translating assertion A04 to five processor designs. The translation fails in the Refinement Pass when translating the assertion to the OpenV design.
- For the other designs, Transys successfully generates valid assertions. The translated assertions for the OR1200, Espresso, and Cappuccino processors are semantically equivalent. These three designs are all implementations of the OR1K architecture, making it easier to translate assertions among them.
- The assertion for the Picorv32 does not capture the same semantic meaning but still belongs to the type of security properties relevant to memory.

**Example 3:**
- In this example, ...