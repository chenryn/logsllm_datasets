graph and then performs community detection on the graph.
To distinguish between malicious communities and benign com-
munities, EvilCohort discusses many ways to post-process com-
munity properties. Here, we assume the best case in which the
maliciousness of each community can be exactly determined
by the post process. We use the account labels to calculate the
percentage of malicious accounts in each community.
The above competitors are state-of-the-art malicious account
detection methods, some of which have been deployed in produc-
tion (e.g., SynchroTrap is deployed by Facebook). Besides, they rely
on comparable methods as Muses (e.g., constructing account-to-
account graphs built upon similar features). Thus, for fair perfor-
mance comparison, we select these prior arts. Via fair comparisons,
we conclude that Muses significantly outperforms these approaches.
304On Detecting Growing-Up Behaviors of Malicious Accounts in Privacy-Centric Mobile Social Networks
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Table 1: Notations of key design parameters and default values used in our experiment.
Parameter
Default
fip
k
α
maxLevel
maxIteration
tolerance
100
4
0.5
10
10
0.0001
The threshold used in dynamic segmentation method to group the IP addresses.
Description
The number of iteration of RWR.
The restart probability of RWR.
The maximum number of levels in which the graph is clustered and then condensed.
The maximum number of iterations that the modularity optimization will run for each level.
The minimum change in modularity between iterations.
Figure 6: Precision and recall of Muses under different set-
tings of final malicious score thresholds.
Figure 7: Precision recall curve of comparing Muses with
three baseline methods.
5.2 Evaluating Effectiveness
Overall performance. We first evaluate the effectiveness of Muses
and measure the precision and recall of Muses under different thresh-
old settings of malicious score in Figure 6. We observe that precision
increases while recall decreases as the threshold increases from 0.5
to 1.0. The results are reasonable because the predicted growing-up
accounts are more likely to be malicious with the increase in the
threshold, resulting in higher precision. On the other hand, as the
threshold increases, growing-up accounts with malicious scores
less than the threshold will be missed by Muses, which leads to
lower recall. Moreover, we demonstrate the effectiveness of Muses,
i.e., Muses can detect 82% of growing-up accounts with a precision
of 90% and an AUC of 0.95 when the threshold is 0.63. In particular,
the effectiveness of Muses is ensured because of the following two
reasons. First, Muses inspects accounts from multiple perspectives
by using multiple behaviors. Thus, it can detect more growing-up
accounts since it is expensive for them to diversify all the behaviors.
Second, as we mentioned before, accounts exhibiting suspicious
behaviors in one dimension will be ruled out of the malicious list if
they are innocent in other dimensions.
We note that Muses failed to detect the remaining 18% of growing-
up accounts. The key reason is that these accounts do not show
obvious malicious behaviors during the first week after registration.
Specifically, we find that most of them belong to the following three
types of malicious accounts: (1) compromised accounts; (2) inde-
pendent malicious accounts; and (3) crowdsourcing accounts. They
were labeled as malicious accounts by the WeChat security team
as their later behaviors violate the community regulations. Com-
pared with the detected growing-up accounts, they have a more
limited number of actions or use fewer IP addresses shared with
each other, thus having relatively lower malicious scores. Neverthe-
less, the impact of their malicious behaviors is limited. Detecting
these accounts will be an interesting topic for future work.
Table 2: AUC and R@P comparison between Muses and
three baseline methods.
Methods
AUC Recall under different precision
SynchroTrap
0.29
ClickStream 0.56
EvilCohort
0.88
0.95
0.80
0.342
0.571
0.398
0.919
0.90
0.067
0.086
0.398
0.818
Muses
0.99
0.026
-
0.398
0.320
Muses vs. SynchroTrap. SynchroTrap is effective in detecting
highly collaborative malicious campaigns by setting high similarity
thresholds. However, according to Figure 7 and Table 2, we observe
that SynchroTrap only detects a small portion(∼6%) of growing-up
accounts when the precision reaches 90%.
Muses vs. Clickstream. Clickstream has trouble detecting growing-
up accounts. The reason is that most of the growing-up accounts
only have a few action records just like the benign accounts during
the first week of activities, which makes this method low in preci-
sion. We reproduce Clickstream graph construction and graph par-
tition steps. Then we use account labels to calculate the growing-up
account proportion of each community. Figure 7 shows the per-
formance of Muses in comparison with the baseline methods. We
can see that the precision of Clickstream drops below 80% when
covering only 60% of growing-up accounts.
Muses vs. EvilCohort. Here we use the account labels to calculate
the percentage of growing-up accounts in each community. Using
this percentage as a threshold, we evaluate the performance of
EvilCohort on our dataset. Table 2 shows that EvilCohort can detect
around 40% growing-up accounts with a high precision of 90%,
while it fails to cover the remaining 60% growing-up accounts.
0.50.60.70.80.91.0Threshold of malicious score0.00.20.40.60.81.0PercentagePrecisionRecall0.00.20.40.60.81.0Recall0.00.20.40.60.81.0PrecisionSynchroTrapClickStreamEvilCohortMuses305ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Zijie Yang1, Binghui Wang2, Haoran Li1, Dong Yuan1, Zhuotao Liu1, Neil Zhenqiang Gong3
Chang Liu4, Qi Li1, Xiao Liang5, Shaofeng Hu5
(a) ACT
(b) IP
(c) VER
(d) ACT+VER
(e) IP+VER
(f) ACT+IP
Table 3: Performance under different behavior combina-
tions. VER means client version and ACT means action
count.
Figure 8: Evaluating the generalizability of Muses with different feature combinations. Figure (a), (b), (c) show the Precision-
Recall curve of Muses when only using action count, IP address, client version, respectively. Figure (d), (e), (f) show the PR
curve under the pairwise combinations.
5.3 Evaluating Generalizability
The above performance evaluation and analysis are all based on
WeChat datasets. Therefore, it is important to validate whether
Muses can be applied as a general scheme with other OSN datasets.
However, the growing-up account datasets of other OSN platforms
are not publicly available, making it difficult to demonstrate the
effectiveness of Muses using other platforms’ datasets. We note
that the features we used (i.e., IP address, client version, and action
count) are not specific to WeChat or based on a particular version. In
fact, many previous methods already used these common platform
features, which are generally available on other OSN platforms
like Instagram and Facebook. Therefore, our framework can be
easily applied to other platforms. As an alternative method for
evaluating the generalizability, we change the features used in the
experiment. Specifically, we test 6 other combinations of the three
behaviors, i.e., separately and pairwisely. We have the following
two key observations.
AUC Recall under different precision
0.90
0.89
0.82
0.91
0.88
0.95
0.95
Overall, the results show that Muses achieves promising results
using a small set of common features adopted by most OSN plat-
forms, which demonstrates the generalizability of Muses.
0.99
0.181
0.470
0.000
0.188
0.481
0.293
0.320
Behaviors
ACT
IP
VER
ACT+VER
IP+VER
ACT+IP
ACT+IP+VER
0.80
0.793
0.627
0.701
0.839
0.661
0.916
0.919
0.90
0.466
0.540
0.000
0.614
0.576
0.813
0.818
First, we observe from Figure 8 that using only one behavior
can already achieve comparable performance with the best of the
three baseline methods (EvilCohort, see Figure 7 and Table 2). This
is mainly because Muses can effectively capture the subtle differ-
ences between growing-up and benign accounts by design. When
considering two of the three behaviors, the performance is further
improved. Second, using only one behavior is not enough in detect-
ing growing-up accounts as shown in Table 3. For example, using
the client version only achieves an AUC of 0.82. The reason is that
there are only a small number of popular version numbers, which
means that growing-up and benign accounts share a lot of version
numbers. We also test the performances when we only use two of
these three behaviors. The results show that using only IP address
and action count achieves an AUC of 0.95, and adding the client
version can further improve 2.7% recall when precision is 99%.
5.4 Evaluating Robustness
As malicious accounts are evolving, their behavior patterns are
dynamic. We measure the impact of possible evasion strategies on
Muses and confirm the robustness of Muses against these evasion
attacks. The detailed results can be found in Appendix A.
6 DISCUSSION
6.1 High Scalability of Muses
Recall that Muses introduces a metric to evaluate the maliciousness
of account communities. Thus, Muses enables one to assess accounts
in a finer grain compared with previous methods which simply
divide communities into malicious ones and benign ones[6, 29].
More importantly, this metric is derived from the statistical result
of each account attribute, so it makes Muses fully unsupervised.
Different platforms can adopt their own set of attributes based on
the content of their data. There is no need for them to select the
0.00.20.40.60.81.0Recall0.40.50.60.70.80.91.0PrecisionAUC=  0.900.00.20.40.60.81.0Recall0.40.50.60.70.80.91.0PrecisionAUC=  0.890.00.20.40.60.81.0Recall0.40.50.60.70.80.91.0PrecisionAUC=  0.820.00.20.40.60.81.0Recall0.40.50.60.70.80.91.0PrecisionAUC=  0.910.00.20.40.60.81.0Recall0.40.50.60.70.80.91.0PrecisionAUC=  0.880.00.20.40.60.81.0Recall0.40.50.60.70.80.91.0PrecisionAUC=  0.95306On Detecting Growing-Up Behaviors of Malicious Accounts in Privacy-Centric Mobile Social Networks
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
most effective attributes, since our experimental results show that
all attributes contribute to the overall detection performance.
Besides, the basic workflow of Muses shown in Figure 5 is platform-
independent. In this work, we abstract four main modules, while
other operators can customize these modules to achieve their own
specific goals. The most naive usage requires little domain knowl-
edge since operators only need to extract the links between accounts
and their attribute values to construct the bigraph for each attribute.
In addition, we propose two methods to segment attribute value
space to aggregate unpopular ones. This process helps to reshape
the bigraph in a more balanced form. Operators can also implement
their own segmentation methods based on the observations of the
attribute distribution in their dataset. Furthermore, Muses uses a
standard deviation-based metric to evaluate the maliciousness of
communities and works well. We note that it is also possible for
operators to adopt other metrics based on the real-world deploy-
ment results. For combining results of different attributes, Muses
uses the normalized length of the high-dimension vector, which
is demonstrated to be effective. It is also possible for operators to
assign different weights to different attributes, which we leave for
future work.
6.2 High Robustness of Muses
Essentially, Muses leverages the intrinsic limitation of growing-up
accounts, i.e., the contradiction between the limited resources they
have and the large number of accounts the criminal campaigns
require. This reflects in two aspects: frequently shared physical
devices and highly homogeneous behavioral logic. Muses uses com-
munity scoring and high dimensional projecting methods to fully
inspect accounts from various aspects. It does not rely on the cer-
tain strategy that criminals use, since criminals always need to
manipulate a large number of accounts to make enough profits,
which however is limited by physical or human resources.
We note that it is possible for attackers to obtain a great number
of resources to evade detection, e.g., purchasing a great number
of servers to proxy their activities or designing complex scripts
to control accounts. However, these evasion strategies are likely
to induce significant costs, which could even outweigh the prof-
its before criminals attain sufficient resources to mingle into the
normal communities. Furthermore, Muses is able to evaluate the
maliciousness of each account based on different attribute behav-
iors and combine them into a final score. This makes criminals even
harder to evade detection since they have to invest much more cost
to obfuscate all kinds of attributes.
7 RELATED WORK
Malicious account detection has been extensively studied [1, 3–
9, 11–16, 19–22, 24, 29, 30, 34], which can be classified into the
following three categories.
Feature-based methods. Feature-based methods [8, 11, 15, 19, 20,
22, 24, 30, 34] formalize malicious account detection as a binary
classification problem. Specifically, they first extract features from
profiles, signatures, and other account statistics, and then train
supervised classifiers using the extracted features and a labeled
training set. Finally, they use the trained classifiers to detect mali-
cious accounts. For instance, Realguard [30] utilizes Deep Neural
Networks (DNNs) to extract features and trains a Random Forest
classifier to detect malicious accounts. However, to detect evolving