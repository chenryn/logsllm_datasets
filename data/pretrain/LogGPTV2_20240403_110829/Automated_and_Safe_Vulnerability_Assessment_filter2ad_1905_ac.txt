Replacing the constructor area of the binary with the secure library loader (secure_libs_loader)
ensures that GOT can be changed before the main () function calls the weak function. The role of the
loader is to ultimately load libsecu.so, which is a safe library in the same memory space as binary.
The loader ﬁnds the address of the ﬁrst dlopen () function as shown in Figure 3, and loads libsecu.so in
the memory. After libsecu.so is loaded, the loader calls a function that performs a PLT/GOT patch
within the library.
Figure 3. Secure_libs_loader operation process.
All processes occur before the main () function is executed. Therefore, the patch process accesses
the GOT via the PLT of the vulnerability function to which the actual address is not yet bound. Since it
has never been called, the patch is executed by overwriting the GOT of the vulnerable function with
the address for the binding (usually PLT + 6 location) with the address of the safe function.
This technique is aimed at minimizing binary modiﬁcation and indirectly replacing vulnerable
functions with safe functions. In other words, it is necessary to modify the constructor in order to load
the library of the binary circle, but there is no need to worry about the side-effects, such as destroying
the original program without touching other code parts. In addition, since the loaded library is in the
form of a shared library, it can be maintained and repaired independently. IoT devices such as smart
phones and smart TVs based on Linux are more likely to be applied as targets, therefore ﬂexibility and
scalability can be expected.
4. Experimental Results
4.1. CFG Recovery Analysis
CFG recovery analysis is often used for the static analysis of vulnerabilities. Among the CFG
recovery techniques, backward slicing is useful for root cause analysis because it extracts the only
path information in which the binary is executed. We have a plan to utilize this analysis method to
analyze the root cause of vulnerability. For benchmarking, we compared CFG recovery speed with the
following tools, shown in Table 6, targeting 131 species of CGC challenge binaries [26]. We compared
these tools on a server with a 3.60 GHz Intel Core i7-4960X 2 CPU and 4 GB of RAM. The backward
slicing tool was slowest because of resource consumption, and the fastest tool was BAP with 1.63 s.
Table 6. CFG Recovery speed comparison.
Tool
CFG Size (kb) Min. Binary (s) Max. Binary (s)
Average Speed (s)
Angr (Backward Slicing)
Angr (CFG Fast)
IDA
BARF
BAP
14,641
105,007
104,779
7,367,244
323,891
10.39
0.87
0.18
1.60
0.56
93.74
12.037
2.33
192.23
36.50
79.46
5.12
1.82
63.08
1.63
Sustainability 2018, 10, x FOR PEER REVIEW  9 of 12 Replacing the constructor area of the binary with the secure library loader (secure_libs_loader) ensures that GOT can be changed before the main () function calls the weak function. The role of the loader is to ultimately load libsecu.so, which is a safe library in the same memory space as binary. The loader finds the address of the first dlopen () function as shown in Figure 3, and loads libsecu.so in the memory. After libsecu.so is loaded, the loader calls a function that performs a PLT/GOT patch within the library.  Figure 3. Secure_libs_loader operation process. All processes occur before the main () function is executed. Therefore, the patch process accesses the GOT via the PLT of the vulnerability function to which the actual address is not yet bound. Since it has never been called, the patch is executed by overwriting the GOT of the vulnerable function with the address for the binding (usually PLT + 6 location) with the address of the safe function. This technique is aimed at minimizing binary modification and indirectly replacing vulnerable functions with safe functions. In other words, it is necessary to modify the constructor in order to load the library of the binary circle, but there is no need to worry about the side-effects, such as destroying the original program without touching other code parts. In addition, since the loaded library is in the form of a shared library, it can be maintained and repaired independently. IoT devices such as smart phones and smart TVs based on Linux are more likely to be applied as targets, therefore flexibility and scalability can be expected. 4. Experimental Results 4.1. CFG Recovery Analysis CFG recovery analysis is often used for the static analysis of vulnerabilities. Among the CFG recovery techniques, backward slicing is useful for root cause analysis because it extracts the only path information in which the binary is executed. We have a plan to utilize this analysis method to analyze the root cause of vulnerability. For benchmarking, we compared CFG recovery speed with the following tools, shown in Table 6, targeting 131 species of CGC challenge binaries [26]. We compared these tools on a server with a 3.60 GHz Intel Core i7-4960X 2 CPU and 4 GB of RAM. The backward slicing tool was slowest because of resource consumption, and the fastest tool was BAP with 1.63 s. Table 6. CFG Recovery speed comparison. Tool CFG Size (kb) Min. Binary (s) Max. Binary (s) Average Speed (s) Angr (Backward Slicing) 14,641 10.39 93.74 79.46 Angr (CFG Fast) 105,007 0.87 12.037 5.12 IDA 104,779 0.18 2.33 1.82 BARF 7,367,244 1.60 192.23 63.08 BAP 323,891 0.56 36.50 1.63 Sustainability 2018, 10, 1652
4.2. Binary Patch Result
10 of 12
We used a Peach Fuzzer to trigger crashes of the open source software and compared the number
of crashes before and after applying the patches in order to evaluate how many crashes we can
eliminate through the automatic patch method. We chose eight open sources that were selected in
descending order of the number of published vulnerability reports. We evaluated our method on
a server with a 2.30 GHz Intel (R) Xeon E5-2650v3 CPU and 64 GB of RAM. The vulnerable functions
shown in Table 7 were converted to safe functions by safe library loading. Let B be the number of
crashes before the patch, and A be the number of crashes after the patch. The method of measuring
the crash removal rate was evaluated as R as shown in the following equation.
R(%) = (B − A)/B × 100
(1)
As a result, the average vulnerability removal rate was 59%, and the vulnerabilities of 25% binaries
were completely removed by automatic patch.
Table 7. Comparison before and after patch.
Test Cases
Crash (Before Patch)
Crash (After Patch)
Removal Rate
300
420
300
400
500
300
400
300
13
39
18
223
18
0
119
38
0
6
0
30
15
0
113
31
100%
85%
100%
87%
17%
-
6%
19%
Binary
Lighthttpd
Libhttpd
Abyss
Wsmp3d (low)
Shttpd
Pserv
Wsmp3d (high)
kritton
5. Conclusions
The number of vulnerabilities is increasing rapidly due to the development of new hacking
techniques. However, time-consuming software analysis depending on a vulnerability analyst make
it difﬁcult to respond to attacks immediately. We proposed a method of Hybrid Fuzzing based on
a binary complexity analysis. We also introduced an automated patch technique that modiﬁes the
PLT/GOT table to translate vulnerable functions into safe functions. The proposed model removed
an average of 59% of crashes in eight open-source binaries, and 100% in two binaries. Because a 100%
removal rate of crashes means that they are not exploitable, the result is signiﬁcant, which means that
a hacker cannot attack any more. With these results, we can respond more quickly to hacker attacks
without the help of experts.
As a subject of future study, we will study automatic exploit generation to verify the patched
binary and root cause analysis of vulnerability to patch vulnerable parts directly. We will also research
the automatic classiﬁcation of vulnerabilities by modeling various data mining techniques [27,28] and
machine learning techniques [29,30].
Author Contributions: J.J. designed the system and performed the experiments; T.K. contributed to study design;
H.K. help revise paper.
Acknowledgments: This work was supported by Institute for Information & communications Technology
Promotion (IITP) grant funded by the Korea government (MSIT) (No. 2017-0-00184, Self-Learning Cyber Immune
Technology Development).
Conﬂicts of Interest: The authors declare no conﬂict of interest.
References
1.
U.S. National Vulnerability Database. Available online: http://cve.mitre.org/cve/ (accessed on 4 April 2018).
Sustainability 2018, 10, 1652
11 of 12
2.
3.
Kang, W.M.; Moon, S.Y.; Park, J.H. An enhanced security framework for home appliances in smart home.
Hum.-Centric Comput. Inf. Sci. 2017, 7, 6. [CrossRef]
Keegan, N.; Ji, S.Y.; Chaudhary, A.; Concolato, C.; Yu, B.; Jeong, D.H. A survey of cloud-based network
intrusion detection analysis. Hum.-Centric Comput. Inf. Sci. 2016, 6, 19. [CrossRef]
4. Miller, B.P.; Fredriksen, L.; So, B. An empirical study of the reliability of UNIX utilities. Commun. ACM 1990,
5.
6.
7.
8.
9.
33, 32–44. [CrossRef]
Zzuf—Caca Labs. Available online: http://caca.zoy.org/wiki/zzuf (accessed on 4 April 2018).
Peach Fuzzer. Available online: https://www.peach.tech/ (accessed on 4 April 2018).
Sulley. Available online: https://github.com/OpenRCE/sulley (accessed on 4 April 2018).
Aitel, D. An introduction to SPIKE, the fuzzer creation kit. In Proceedings of the BlackHat USA Conference,
Las Vegas, NV, USA, 29 July–1 August 2002.
Bekrar, S.; Bekrar, C.; Groz, R.; Mounier, L. A taint based approach for smart fuzzing. In Proceedings of the
IEEE Fifth International Conference on Software Testing, Veriﬁcation and Validation, Montreal, QC, Canada,
17–21 April 2012; pp. 818–825.
10. American Fuzzy Lop. Available online: http://lcamtuf.coredump.cx/aﬂ/ (accessed on 4 April 2018).
11. Honggfuzz. Available online: https://github.com/google/honggfuzz (accessed on 4 April 2018).
12. King, J.C. Symbolic execution and program testing. Commun. ACM 1976, 19, 385–394. [CrossRef]
13. Godefroid, P.; Levin, M.Y.; Molnar, D.A. Automated whitebox fuzz testing. NDSS 2008, 8, 151–166.
14. Cadar, C.; Dunbar, D.; Engler, D.R. KLEE: Unassisted and Automatic Generation of High-Coverage Tests for
Complex Systems Programs. OSDI 2008, 8, 209–224.
15. Ciortea, L.; Zamﬁr, C.; Bucur, S.; Chipounov, V.; Candea, G. Cloud9: A software testing service. ACM SIGOPS
Oper. Syst. Rev. 2010, 43, 5–10. [CrossRef]
16. Cha, S.K.; Avgerinos, T.; Rebert, A.; Brumley, D. Unleashing mayhem on binary code. In Proceedings of the
17.
18.
IEEE Symposium on Security and Privacy, San Francisco, CA, USA, 20–23 May 2012; pp. 380–394.
Stephens, N.; Grosen, J.; Salls, C.; Dutcher, A.; Wang, R.; Corbetta, J.; Shoshitaishvili, Y.; Kruegel, C.; Vigna, G.
Driller: Augmenting Fuzzing through Selective Symbolic Execution. NDSS 2016, 16, 1–16.
Shoshitaishvili, Y.; Wang, R.; Salls, C.; Stephens, N.; Polino, M.; Dutcher, A.; Grosen, J.; Feng, S.; Hauser, C.;
Kruegel, C. Sok: (State of) the art of war: Offensive techniques in binary analysis. In Proceedings of the IEEE
Symposium on Security and Privacy, San Jose, CA, USA, 22–26 May 2016; pp. 138–157.
19. Chipounov, V.; Kuznetsov, V.; Candea, G. S2E: A Platform for In-Vivo Multi-Path Analysis of Software
Systems. In Proceedings of the Architectural Support for Programming Langugaes and Operating Systems,
Newport Beach, CA, USA, 5–11 March 2011; pp. 265–278.
Stephanie, F.; Thanh, V.N.; Westley, W.; Claire, L.G. A Genetic Programming Approach to, Automated
Software Repair. In Proceedings of the 11th Annual Conference on Genetic and Evolutionary Computationm,
Montreal, QC, Canada, 8–12 July 2009; pp. 947–954.
20.
21. Liu, C.; Yang, J.; Tan, L.; Haﬁz, M. R2Fix: Automatically generating bug ﬁxes from bug reports. In Proceedings
of the International Conference on Software Testing, Veriﬁcation and Validation, Luxembourg, 18–22 March
2013; pp. 282–291.
22. Kim, D.; Nam, J.; Song, J.; Kim, S. Automatic patch generation learned from human-written patches.
In Proceedings of the International Conference on Software Engineering, San Francisco, CA, USA, 18–26
May 2013; pp. 802–811.
23. QEMU. Available online: https://www.qemu.org/ (accessed on 4 April 2018).
24. Halstead, M.H. Elements of Software Science; Elsevier North-Holland: New York, NY, USA, 1977; p. 128.
25. DARPA Cyber Grand Challenge. Available online: http://archive.darpa.mil/cybergrandchallenge/
26.
(accessed on 4 April 2018).
Shudrak, M.O.; Zolotarev, V.V. Improving fuzzing using software complexity metrics. In Proceedings of
the International Conference on Information Security and Cryptology, Seoul, Korea, 25–27 November 2015;
pp. 246–261.
27. Mohamed, B.; Smaine, M. A Chi-Square-Based Decision for Real-Time Malware Detection Using PE-File
Features. J. Inf. Process. Syst. 2016, 12, 644–660.
28. Choi, J.H.; Shin, H.S.; Nasridinov, A. A Comparative Study on Data Mining Classiﬁcation Techniques for
Military Applications. J. Converg. 2016, 7, 1–7.
Sustainability 2018, 10, 1652
12 of 12
29. Yamaguchi, F.; Lindner, F.; Rieck, K. Vulnerability extrapolation: Assisted discovery of vulnerabilities using
machine learning. In Proceedings of the 5th USENIX conference on Offensive Technologies, San Francisco,
CA, USA, 8 August 2011.
30. Gustavo, G.; Guilermo, L.G.; Lucas, U.; Sanjay, R.; Josselin, F.; Laurent, M. Toward Large-Scale Vulnerability
Discovery using Machine Learning. In Proceedings of the Sixth ACM conference on Data and Application
Security and Privacy, New Orleans, LA, USA, 9–11 March 2016; pp. 85–96.
© 2018 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access
article distributed under the terms and conditions of the Creative Commons Attribution
(CC BY) license (http://creativecommons.org/licenses/by/4.0/).