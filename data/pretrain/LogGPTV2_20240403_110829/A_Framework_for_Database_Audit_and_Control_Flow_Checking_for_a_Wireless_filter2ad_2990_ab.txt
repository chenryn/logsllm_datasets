vocation of different  audit techniques  (provided by the audit element). 
4.1 
Periodically, the manager process sends a heartbeat message 
to  the  heartbeat  element  in  the  audit  process  and  the  data- 
base client  waits  for a reply.  If  the entire  audit process  has 
crashed  or  hung,  or  if  there  is  scheduling  anomaly  on  the 
controller  system  that  prevents  the  audit  process  from  run- 
ning, the manager times out and restarts the audit process. 
The Heartbeat Element 
The Progress Indicator Element 
4.2 
The progress  indicator element is used  to detect deadlock in 
the  controller  database to  ensure uninterrupted  system  op- 
eration.  If  a  client  process  terminates  prematurely  without 
fully committing  its transaction, the locks left behind  by this 
process would prevent other client processes from accessing 
the database (or portions of it). 
Detection.  A standard  POSIX IPC message queue is added 
between  the  database API and  the  audit process.  The data- 
base API is modified  to send a message to the audit process 
whenever  any API function is called. The message  contains 
the client process  ID information  and  the database location 
being accessed. If  the audit process receives no message  for 
an  extended  period  of  time,  the  progress  indicator  element 
will time out and trigger recovery. 
Recoveiy.  The progress  indicator element, via the  manager, 
can  terminate  a  client  process,  which  has  been  holding  a 
lock  for  greater  than  a  predetermined  threshold  duration, 
thereby  releasing  the  lock. While the  threshold  for a client 
to  hold  a  lock  is  typically  small  (e.g.,  100 milliseconds  in 
the  current  implementation),  the  progress  indicator  timeout 
value  is  much  larger  (e.g.,  100 seconds  in  the  current  im- 
plementation)  in order to reduce runtime overhead. 
227 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:59:52 UTC from IEEE Xplore.  Restrictions apply. 
Static and Dynamic Data Check 
4.3  The Audit Elements 
Specific audit techniques  are implemented  as separate audit 
elements  in  the  audit  process.  The  invocation  of  the  audit 
elements  can be either by  a periodic trigger, or by  an  event 
trigger. The periodic trigger is based  on a fixed time period. 
The event trigger is provided  by  some specific database op- 
erations, e.g., database write  in the current  implementation. 
The  periodic  audit  element  uses  as  its  basis  the  periodic 
heartbeat  query  discussed  earlier  as  trigger  to  perform  the 
following  audits:  static  data  integrity  check,  dynamic  data 
range  check, structural  audit, and referential  integrity audit. 
The auditing has fine enough granularity that if an  interven- 
ing update happens after an audit process  has read a record, 
the  results  are  not  invalidated.  However, in  the case of  the 
referential audit if  there is an intervening update to a record 
being  accessed  by  the  audit  element  while  the  audit  is  in 
progress, the result of this audit run is invalidated. Note also 
that  the  active  audit  thread  shares  the  processor  time  with 
the  client  accessing  the  database.  This  introduces  a  small 
overhead in processing  the client request. 
4.3.1 
Detection  and  recover)?  The audit  element  detects corrup- 
tion  in  static data  region  by  computing a golden  checksum 
of  all  static data at startup and comparing it with  a periodi- 
cally  computed  checksum  (32-bit  Cyclic  Redundancy 
Code). The standard recovery  for static data corruption  is to 
reload the affected portion  from permanent storage. 
To make audit  on dynamic data possible  in  the target data- 
base,  the  range  of  allowable  values  for  database  fields are 
stored  in  the  database  system  catalog.  This  information  al- 
lows the audit program  to do a range  check on  the dynamic 
fields in the database. If  the audit detects an error, the field 
is  reset  to  its  default  value,  which  is  also  specified  in  the 
system catalog. In addition,  if  the table  where the error oc- 
curred  is  dynamic,  the  record  is  freed  as  a  preemptive 
measure to stop error propagation. 
4.3.2  Structural Check 
The structure of  the database  in  the controller  system is es- 
tablished  by  header  fields  that  precede  the  data  portion  in 
every  record  of  each  table.  These header  fields contain  re- 
cord identifiers and indexes of logically adjacent records. 
Detection.  The structural audit element calculates the offset 
of  each  record  header  from  the  beginning  of  the  database 
based  on  record  sizes  stored  in  system  tables  (all  record 
sizes are  fixed and  known).  The database structure (in  par- 
ticular, the alignment of each record and table within the da- 
tabase)  is  checked  by  comparing all  header  fields  at  com- 
puted offsets with expected values. 
Recovey.  A  single error  in  record  identifier is correctable 
because  the correct record  ID can be  inferred  from the off- 
set within the database. However, multiple consecutive cor- 
ruptions  in header  fields is considered  to be a strong indica- 
tion  that  tables  or records  within  the  database may  be  mis- 
aligned,  and  the  entire  database  is  then  reloaded  from  the 
disk to recover from the structural damage. 
4 . 3 . 3   Semantic Referential Integrity Check 
Detection.  Referential integrity checking traces logical rela- 
tionships  among  records  in  different  tables  to  verify  the 
consistency of  the logical loops formed  by  the record.  This 
allows  us to detect  invalid data  impossible to  find when  re- 
cords  are  examined  independent  of  each  other.  Corruption 
of  key  attributes  in  a database  leads  to  “lost  records,”  i.e., 
records  participating  in  semantic  relationships  “disappear” 
without  being  properly  updated.  We refer  to this phenome- 
non  as  resource  leak. Commercial  databases  provide  some 
support for referential integrity checking. However, since no 
timestamps or process IDS for the last access of a record  are 
maintained,  automatic  recovery  action  cannot  be  taken. 
Also, since the recovery  action requires  specific knowledge 
of the application, such a support is not  offered  in a generic 
database package. 
As  an example, consider the data structure established when 
servicing a voice  connection. A thread  must be spawned  to 
manage  the connection; the process  needs  to allocate  hard- 
ware  resources  and  record  information  related  to  the  call 
(e.g.,  the IDS of the parties involved)  into the connection ta- 
ble. Thus, a new record  needs to be written into each of the 
following three tables: 
Process Table (Process ID, Name, Connection ID, Status. . . . ), 
Connection Table (Connection ID, Channel ID, Caller ID, . . .), 
Resource Table (Channel ID, Process ID, Status ... ) 
The  three  new  records  form  a  semantic  loop  because  the 
process record  refers to the connection  record  via the “Con- 
nection  ID” attribute, the connection  record  refers to the re- 
source  record  via  the  “Channel ID” field, and  the resource 
table closes the loop by  pointing back  to the process record 
via  “Process ID.” Thus, the audit program can  follow  these 
dependency loops for each active record  in each of the three 
tables and detect violations of semantic constraints. 
Recovery.  The  recovery  actions  include freeing  “zombie ” 
records and preemptively terminating  the clients that are us- 
ing  these  records.  Preemptive  process  termination  is  desir- 
able  because  it  keeps  system  resources  available  even 
though  an active connection  may  be dropped.  The termina- 
tion  is  made  possible  by  modifying  the  database  API  to 
maintain, along with each database record, the ID of the cli- 
ent process that last accessed the record. The redundant  data 
structure  (added  without  modifying  the  original  database) 
includes also the time of  last access and counters that main- 
tain database access frequencies. 
4.4  Optimization Using Runtime Statistics 
The audit  techniques  presented  in  the previous  section  use 
rules  determined  off-line  to  perform  data  checks.  While 
these  static rules allow the  audit process  to detect  many er- 
rors,  they  do  not  take  the  actual  runtime  system  behavior 
into account  and  therefore  are not  adaptive. Below  we  pre- 
sent  two  audit  optimization  strategies  that  utilize  statistics 
collected during system operation:  (a) prioritized  audit tris- 
gering  and  (b)  selective  monitoring  of  attributes.  Detailed 
assessment of these audit strategies can be found in [9]. 
228 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:59:52 UTC from IEEE Xplore.  Restrictions apply. 
4.4.1  Prioritized Audit Triggering 
The prioritize audit is based on the assumption that database 
objects  have different  importance  and  that  their importance 
varies during  system operation.  We use  the following crite- 
ria to determine the importance of database objects: 
The  access frequency  of  database  tables.  The  tables  that 
contain  data  that  arc more  frequently  updated  arc more  li- 
able  to  be  corrupted  due  to  software  misbehavior  and  are 
more likely to cause error propagation  to processes  that use 
the data. Hence, the tables with higher &cess frequency are 
checked more often. 
The nature  of  the database object. This criterion  takes  into 
account criticality  of database  objects. For example, the da- 
tabase  system  catalog  is  a  crucial  component  because  it  is 
referenced  on  every  database  access  and  consequently  it 
should be checked more often. 
The tiurii6er of  errors detected  in each table. This criterion 
is based  on  the  assumption  of  temporal  locality  of data er- 
rors; i.e., the area  where  more errors occurred  in  the  recent 
past  is likely to  contain  more errors in  the near future. The 
audit  process  can  make  better  utilization  of  system  re- 
sources  by  focusing  on  the  trouble  spots  to achieve  higher 
error detection coverage and lower detection latency. 
To  support  prioritized  audits,  information  on  access  fre- 
quency  and  error  history  are  collected  at  runtime  by  the 
modified  database  read/write  API.  In  addition,  the  audit 
process  maintains  an  error  log  for  each  table,  which  con- 
tains  the  number  of  errors  detected  in  the  last  audit  cycle. 
These  pieces  of  information  are  combined  to  derive  a 
weighted measure of importance that is used  to rank the da- 
tabase tables and to direct the audit to critical sections of the 
database. 
4.4.2  Selective Monitoring of Attributes 
The selective  monitoring  of  certain  table  attributes  (fields) 
is  motivated  by  the  lack  of  good  static  audit rules  in  some 
cases.  For example,  although  the database  catalog provides 
the facility to record the lower and upper bounds of each ta- 
ble  attribute,  not  all ranges are specified. This is due to the 
difficulty  in  characterizing  certain  attributes  whose  values 
cannot  be  predicted  with  relative  certainty  in  advance.  By 
monitoring the values of  such attributes at runtime, adaptive 
rules can  be  generated for use  by  the audit process to detect 
data errors. 
A  related  research  area  is using dynamic techniques to dis- 
cover  program  invariants  [ 5 ] .  The idea  is to  infer  invariant 
variables  in the program during test runs and  compare them 
against  values  captured  at  runtime.  Example  invariants  in- 
clude  range  limits  over a single numeric  variable,  linear  re- 
lationship among two or three  numeric  variables,  and  func- 
tions among multiple variables. 
In  the  selective monitoring  of database attributes, a slightly 
different  approach is taken.  Instead  of trying to verify  a set 
of predetermined  hypotheses, the data trace collected  at run- 
time  is  used  to derive  possible  invariants  to be  used  by  the 
Evaluation of  the Audit Subsystem 
audit  process for error  detection.  Any abnormality  detected 
with these derived  invariants needs to be further checked  by 
other means. 
To derive the set of correct  values  of an attribute  in the da- 
tabase,  the  audit  program  periodically  examines the  values 
of  that  attribute  in  all  active  records of  the  relevant  table. 
An  average number  of  occurrences  is computed  across all 
attribute  values.  A  threshold  value  for  number  of  occur- 
rences is then calculated  using a certain fraction of the aver- 
age.  Any  value  that  has  appeared  less  frequently  than  the 
threshold  is marked  as suspect, and  further  actions,  such as 
semantic audit, are triggered  to make a final decision. 
5 
To assess  the  performance  overhead  and  effectiveness  of 
different  audit  techniques,  the  following  experiments  are 
conducted. 
Audit  Effectiveness  with  Emulated  Call-Processing  Client. 
This experiment  uses  an  emulated  call-processing  client  as 
the workload and measures the effectiveness  of the audits in 
preventing database errors from corrupting the client. 
Overhead  in  Database API. This experiment measures  the 
performance  overhead  introduced  into  the  database  API 
functions that were modified  to communicate  with  the audit 
process and to maintain the support data structure. 
5.1  Audit Effectiveness 
To demonstrate  the  usefulness  of  the  audit  process in  pro- 
tecting  database  clients  from  errors  in  database,  a  simple 
call-processing  client  was  used. The client  provides the ba- 
sic call-processing  service of setting up and tearing  down a 
call  without  additional  features such  as call  waiting  or call 
forwarding.  The program  uses  multiple  threads  to  concur- 
rently  handle  incoming  calls.  The  steps  followed  in  each 
call-processing  thread  include authentication,  resource  allo- 
cation, and other phases  in  a typical  call  setup,  as shown in 
Figure 2. 
I 
I 
Figure 2: Client Program, Call-Processing States 
A run  of  the experiment  lasted 2000 seconds, during which 
the  multi-threaded  client  program  depicted  in  Figure  2 
processed  approximately  1000 calls. The error model  used 
in  the  experiments  was  the  insertion  of  random  bit  errors 
into the database  at various rates and the experiments  were 
carried  out  using  NFTAPE  [ 181. The injected  errors corre- 
spond  to  the  effect  of  transients  causing  data  corruption. 
The number of errors that escaped from the audits as well as 
the  average call  setup time  were  recorded.  The goal  of  the 
experiment was  to determine the reduction  in the number of 
escaped  errors  (i.e.,  errors  that  impact  the  database  client 
program)  when  audits are used,  as well  as the  performance 
overhead seen by  the client program. Table 2 shows the pa- 
rameters used  in the experiments. 
229 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 03:59:52 UTC from IEEE Xplore.  Restrictions apply. 
Table 3 shows the results of running the call-processing  cli- 
ent program with and without database audit at a fixed error 
rate  of  one error every  20 seconds, using data  from 30 runs 
of the experiment. The used  error rate mimics burst  of tran- 
sient errors affecting the database. 
Without  database  audits,  1884 out  of  the  3000 injected  er- 
rors (63%) affected  the application  process,  compared with 
only  402 ( 1  3%) when  audits  were  running.  The number  of 
errors having  no immediate  effect, i.e.,  latent errors,  is also 
greatly reduced  (from 37% to 2%) when audits are running, 
because  the  entire  database  is  checked  for  errors periodi- 
cally. The  timing  of  audit  invocation  with  respect  to  error 
occurrence and  the accuracy  of constraints  (e.g., range  lim- 
its) were the two major factors in determining the number of 
escaped errors.  Because the audits  are invoked  periodically 
in  the experiment, every  piece  of data that is corrupted  and 
then used  by the client application between two consecutive 
audit invocations leads to an escaped  error.  In  addition,  the 
audit does not always have enforceable rules to detect all er- 
rors.  Due to the processing  time  required  by the  audits,  the 
average  call  setup time  in  the  client  process  changes from 
160 milliseconds  to 270 milliseconds,  i.e., a 69% increase, 
as measured on a Sun UltraSPARC-2  system. 
To further  investigate  the  relationships  among audit  cover- 
age,  audit  invocation  frequency,  and  error  rate,  the  inter- 
arrival time of random errors is varied  from 2 seconds to 20 
seconds. All  other  parameters  remain  the same as shown  in 
Table 2. Figure  3  shows that  the  number  of escaped errors 
increases  as the  fault/error  inter-arrival  time decreases (i.e., 
error  rate  increases).  More  importantly,  as  the  fault  inter- 
arrival  time drops below  10 seconds (the audit  period  used 
in  the  experiments),  the  increase  in  the  number  of  escaped 
errors speeds up as the audits start to become overwhelmed 
by  the  burst  of  errors.  The percentage  of  escaped  errors in 
all  injected  errors  remains  relatively  constant  and  ranges 