other users to download. This has been highlighted in the design
document of ROS2 Robotic Systems Threat Model [18]: “third-party
components releasing process create additional security threats (third-
party component may be compromised during their distribution)”.
We also confirm the feasibility and practicality of this threat with
an end-to-end attack demonstrated in § 7. Second, the quality of
third-party function code is not guaranteed. A lot of functions in
the ROS platform are in a lack of coding standards or specifica-
tions. They may also contain software bugs that can be exploited
by an adversary to compromise the nodes at runtime [50, 65]. By in-
specting the latest commit logs in the Robot Vulnerability Database
[16], 17 robot vulnerabilities and 834 bugs (e.g., no authentication,
uninitialized variables, buffer overflow) were discovered in the re-
pos of 51 robot components, 37 robots and 34 vendors in the ROS
platform. Most of them are still not addressed yet. Third, the high
interactions among nodes in a robot app can amplify the attack
damage. If an adversary controls one node, it is possible that he can
affect other nodes directly or indirectly, and then the entire app.
The existence of untrusted nodes can cause data races or deadlocks
when the synchronization is not well handled. Finally, this threat
model is widely adopted in prior works regarding ROS security
[38, 51, 56, 85].
3
1. mqtt_bridge2. rqt_image_view3. rtt_exploration4. wge100_driver5. jsk_recognition(cid:258)(cid:258)The ROS PlatformRepoNamePackage 1Package 2Package 3Package 4ReadME(cid:258)(cid:258)One Repolink to the hosting siteRelated Documentsrcpackage.xml(cid:258)(cid:258)Package 1Manifest FileFunction 1Function 2ImplementImplementMultipleReposROS ApplicationFunction 4Function 1Function 2Function 3UserRobotEnvironmentDeveloperROS PlatformROS Core LibDownloadIntegrationDeploy Robot AppsOperationDevelopment123546Launch MissionMissionExecutionFeedbackPhoneCloudAPP3rd-party functionscustomized functionsTopicsServicesRAID ’21, October 6–8, 2021, San Sebastian, Spain
Yuan Xu, Tianwei Zhang and Yungang Bao
requires the robot to recognize real-time environment conditions
(e.g. obstacle avoidance, traffic light) and react to them promptly.
The robot’s maximal velocity is determined by its reaction time,
which further depends on two factors [37, 62]. The first factor is
the processing time for collision avoidance, which is the end-to-end
latency from obstacle detection to velocity control. The second
factor is the frame rate of the Image Recognition function. The
faster the robot is, the larger frame rate this function requires to
respond to the rapid changes of the environment. In this paper,
we only focus on the second factor as the processing latency is
the safety issue of the internal function node (i.e. Path Tracking)
rather than the interaction between two nodes.
Figure 4c shows the mechanism of RSR. There are two types
of high-risk function nodes: (1) the image-related node is used to
understand the current detected conditions through image recogni-
tion. (2) The max_vel-related node outputs the maximal velocity
value to the corresponding topic based on the current condition.
These two nodes affect each other via an indirect interaction (dotted
line). The maximal velocity and image frame rate should satisfy
certain conditions to guarantee the robot can function correctly. If
either node is malicious and produces anomalous output (too large
maximal velocity or too small frame rate), the requirement can be
compromised, bringing catastrophic effects in some tasks.
3.3 Mission-Specific Risk (MSR)
MSR refers to the violation of users’ expectations regarding the
safe and secure behaviors of a robot system. It exists in the indirect
interaction between an event-related node and action-related node
(Figure 4d), when there are conflicts between them, regulated by
some scenario-specific rules. Although some GRs and RSRs may
also lead to the violation of these rules, the causes and mitigation
strategies are totally different. So it is necessary to discuss MSR
separately. There are two types of high-risk nodes in MSR: (1) the
event-related ones include all the nodes in the Perception domain
except Preprocessing. The robot uses those nodes to understand
the conditions of the physical environment. (2) The action-related
ones include all the nodes in the Control domain which can directly
interact with the actuator drivers. They are used to actively change
the actual states of both the robot and environment. If either of
these nodes are malicious, the robot and task can be compromised
with unexpected consequences.
The rules to prevent MSR are determined by the missions and
usage scenarios, which are usually specified by users. Table 1 lists
some examples of MSRs and the corresponding rules in four scenar-
ios. (1) In a domestic context, robots are designed to manage various
human-centric tasks, e.g., house cleaning, baby-sitting. They are
required not to disturb human’s normal life. (2) In a warehouse con-
text, industrial robots are introduced to achieve high automation
and improve the productivity, such as manipulator and autonomous
ground vehicle (AGV). These robots are required to complete each
subtask correctly, efficiently and safely. (3) In a city context, au-
tonomous vehicles and delivery robots move at high speeds in the
transportation system, and handle complex events from outdoor
dynamic environment. Thus, they need to obey the transportation
rules and ensure the safety of passengers and public assets. (4)
Robots are also deployed in many specialized scenarios to conduct
Figure 4: Three types of interaction risk.
Given this threat model, our goal is to design a methodology and
system, which can identify and mitigate the safety risks caused by
the malicious nodes inside robot apps. For instance, an adversary
can flood the path planning node to block other nodes publishing
goals or increase the speed so that the robot would be too fast to
miss the target searching objects or obstacles in the surroundings.
We focus on the protection of node interactions (both direct and
indirect) instead of the operation of individual nodes. We further
assume the underlying OS and ROS core libraries are trusted: the
operational flow and data transmission are well protected, and the
isolation scheme is correctly implemented so the malicious nodes
are not able to hijack the honest ones or the privileged systems.
How to enhance the security of the ROS core libraries [50, 52, 54, 80]
and mitigate vulnerabilities from networks [36, 44, 64, 71], sensors
[40, 47, 47, 68, 72, 74, 75, 77, 79, 81, 82, 84, 87], actuators [46, 55]
and controllers [69] are orthogonal to our work.
3 RISK ANALYSIS
We analyze safety risks caused by malicious function nodes and
interactions. We classify these risks into three categories (Figure
4 and Table 2). We describe how each risk can incur unexpected
behaviors to threaten the robot safety.
3.1 General Risk (GR)
GR is caused by a direct interaction. It occurs when multiple func-
tion nodes share the same robot states. If one node is malicious, it
can intentionally change the robot states to wrong values to affect
the robot operation. Based on the interaction graph, there are two
conditions to trigger the GR. First, two or more function nodes are
connected to the same successor node, and at least one of them is
untrusted. Second, the transmitted message types among the above
function nodes need to be the same. This guarantees that all these
nodes share the same robot state through the direct interaction.
According to the number of topics, GR can be further divided
into two types. (1) General Risk with Single Topic (GR-ST): multi-
ple high-risk nodes publish to one same topic, subscribed by the
successor node (Figure 4a). (2) General Risk with Multiple Topics
(GR-MT): both the indegree and outdegree of the topic are equal
to 1. There can be multiple parallel topics with the same message
type subscribed by the successor function (Figure 4b).
3.2 Robot-Specific Risk (RSR)
RSR happens in an indirect interaction, due to the conflict behaviors
related to the robotic mobility characteristic. This mobility feature
4
!"#$%&’&()*$+,-.$/$01!2#$+3"34/56&2,72$+,-.!"#$%&’()*+,-!".&/&+&)+&/$)(0/*1(0*!".&23&’"+&/$0(/&!"#4%&’23&’"+&/$0(/&!8#$0,--,3’/56&2,72$+,-.)(0+3(’$")1(05+"+&6&3)&61(0$&%&0+&%&0+23&’"+&/$0(/&")1(023&’"+&/$0(/&9999!)#$%&’&()*$+,-.$/$51Direct Interaction RiskIndirect Interaction RiskAnalysis and Mitigation of Function Interaction Risks
in Robot Apps
Table 1: Examples of Mission-Specific Risks and Rules.
Scenario
Description
The companion robot must send an alert when a user is in danger.
The robotic vacuum must be turned off when a user is sleeping.
Domestic
Warehouse The manipulator must not grasp objects that exceed its limited weight.
The AGV must recharge when the battery level is below a threshold.
The mobile vehicle must follow the traffic rule.
The mobile vehicle must maintain a safe distance with passengers.
City
Specialized The firefighter robot must send an alert when detecting the wounded.
The precision of the surgery robot must be above a specified threshold.
professional missions. For example, rescue robots are used to search
for survivors or extinguish fires. Medical robots are used in hospi-
tals to diagnose and treat patients. Military robots are designed in
battlefields to destroy enemies or constructions. These robots need
to follow the rules related to their specific missions.
3.4 Summary of Risks from Each Domain
An arbitrary malicious node in the robot app can incur the above
risks. We discuss the potential risks and consequences caused by
malicious functions in each domain.
Perception. If a node in the Perception domain is untrusted, the
robot states will be estimated as wrong values. Following the direct
interactions, the robot will take anomalous actions, which violate
the rules of MSR. Moreover, since the Recognition function typ-
ically adopts sensor fusion to reduce uncertainty caused by the
physical limit of different sensors, such threat can cause GR as well.
For instance, an autonomous vehicle is navigating in a highway.
A malicious Preprocessing function intentionally sends wrong
sensory data to the Object Recognition function to cause optical
illusions, e.g., recognizing a turn right sign as a stop sign. This will
violate the traffic rule: “vehicles cannot stop in a highway”.
Planning. A malicious node in the Planning domain can interrupt
the current task, or reset the robot states to wrong values. In a com-
mon robot app, there can be multiple Global Planner functions
for different goals based on various events from the Recognition
functions. This gives the malicious node chances to win the com-
petition against other goals and compromise the robot states (GR).
Besides, the malicious node can also directly modify the goal to
make the robot take anomalous actions in a specific event (MSR).
For instance, a robot vacuum is executing the cleaning task in
a living room. The Global Planner function is compromised and
controlled by an adversary to set a new destination goal as the
master bedroom for stealing privacy. This can violate a possible
MSR rule: “the robot vacuum cannot enter the bedroom”. If the
robot does not have enough power to clean the master bedroom,
this will violate the MSR rule: “the AGV must recharge when the
battery level is below a specified threshold.” (Table 1).
Control. If a function in the Control domain is malicious, the ad-
versary can launch attacks in three ways. First, the function can
interrupt or suspend other actions from different interactions (GR).
Second, it can increase the velocity to cause failures of image-related
recognition functions through the indirect interaction (RSR). Third,
it can directly control the robot to take unexpected actions in a
specific scenario (MSR).
For instance, in a task of searching dangerous goods or wounded
persons, the robot device receives images through the equipped
camera at a certain frame rate. If the max_vel node is malicious and
5
RAID ’21, October 6–8, 2021, San Sebastian, Spain
intentionally increases the maximal velocity, there will be no or
less correlation between adjacent frames. The Image Recognition
function may fail to process each frame promptly, and frames con-
taining safety-related information (e.g. drug, thief) can be missed.
4 MITIGATION METHODOLOGY
We present a novel methodology to mitigate the malicious function
interactions. The core of our solution is a set of coordination nodes
(§ 4.1) and security policies (§ 4.2), as summarized in Table 2.
4.1 Coordination Node
The coordination nodes are deployed inside the robot apps to regu-
late the interactions and enforce the desired security policies. They
are designed to be general for different types of robots, function
nodes and risks. Developers can deploy them into apps without
modifying the internal function code. Users can adjust configura-
tions based on their demands. We design three types of coordination
nodes, to mitigate three types of risks respectively (Figure 5).
General Risk Coordination Node (GRCN). This node is inserted
between the high-risk nodes and their successor node (Figure 5a).
The published topics of each high-risk node need to be remapped to
the subscribed topic of this GRCN to create new data flows, and the
published topic of the GRCN need to be mapped to the subscribed
topic of the successor node. Thus, the GRCN can control each data
flow from the high-risk nodes based on various policies.
Robot-Specific Risk Coordination Node (RSRCN). This node
needs to coordinate the conflict between the image-related node and
max_vel-related node (Figure 5b). We use the same method to insert
the RSRCN between the max_vel-related node and its successor
node. To collect the frame rate from the image-related node, we
insert a fps_monitor node to subscribe to the detected condition
topic published by the image-related node. This fps_monitor node
measures the frequency of the triggered event and publishes the
frame rate to the fps topic. The RSRCN subscribes to this fps topic
and uses it as reference for max velocity adjustment.
Mission-Specific Risk Coordination Node (MSRCN). This node
needs to allow/block the actions taken under wrong conditions (Fig-
ure 5c). Thus, it is deployed between each action-related node and
its successor, and subscribes to all perception event topics of event-
related nodes. In this way, the MSRCN can collect all perception
events in the app and obtain the control of each action. It is worth
noting that there can be multiple GRCNs for each interaction, but
the numbers of both RSRCN and MSRCN are always one.
4.2 Security Policies
To mitigate the malicious interactions in an app, each type of coor-
dination nodes implements a set of policies. Table 2 lists the policies
we have built along with the descriptions and parameters for GRCN,
RSRCN and MSRCN. Each policy needs to be configured by either
the developer or end user, as shown in the “Executor” column.
GRCN Policies. GRCN aims to coordinate data flows from dif-
ferent high-risk nodes. We use four types of policies to adapt to
different scenarios. Specifically, the block policy is used when the
user wants to stop the current action immediately in case of emer-
gency. When multiple high-risk nodes publish control commands,
RAID ’21, October 6–8, 2021, San Sebastian, Spain
Yuan Xu, Tianwei Zhang and Yungang Bao
Table 2: Summary of risks, threats and mitigation for function interactions.
Risk Domain Threat Coordination Node
GR
Perception,
Planning, Control
RSR
MSR
Control
Perception,
Planning, Control
GRCN
RSRCN
MSRCN
Executor Policy
Block
FIFO_Queue
Priority_Queue Timeout, Priority
Preemption
Parameter
Block Bit
Timeout
Developer
Developer Block
Safe
Constrain
End User
End User
Block
Description
Allow/block the action of chosen flow.
Choose the action based on fifo order with time limit.
Choose the action based on priority order with time limit.
Choose the action based on priority order.
Allow/block the velocity control action of chosen flow.
Priority
Block Bit