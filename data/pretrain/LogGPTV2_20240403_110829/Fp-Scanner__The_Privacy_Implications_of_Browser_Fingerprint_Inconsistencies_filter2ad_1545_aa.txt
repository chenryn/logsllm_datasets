title:Fp-Scanner: The Privacy Implications of Browser Fingerprint Inconsistencies
author:Antoine Vastel and
Pierre Laperdrix and
Walter Rudametkin and
Romain Rouvoy
Fp-Scanner: The Privacy Implications of 
Browser Fingerprint Inconsistencies
Antoine Vastel, Univ. Lille / Inria / Inria; Pierre Laperdrix, Stony Brook University;  
Walter Rudametkin, Univ. Lille / Inria / Inria; Romain Rouvoy, Univ. Lille / Inria / IUF
https://www.usenix.org/conference/usenixsecurity18/presentation/vastel
This paper is included in the Proceedings of the 
27th USENIX Security Symposium.
August 15–17, 2018 • Baltimore, MD, USA
ISBN 978-1-939133-04-5
Open access to the Proceedings of the 27th USENIX Security Symposium is sponsored by USENIX.The Privacy Implications of Browser Fingerprint Inconsistencies
FP-Scanner:
Antoine Vastel
Univ. Lille / Inria
Pierre Laperdrix
Stony Brook University
PI:EMAIL
PI:EMAIL
Walter Rudametkin
Univ. Lille / Inria
Romain Rouvoy
Univ. Lille / Inria / IUF
PI:EMAIL
PI:EMAIL
Abstract
By exploiting the diversity of device and browser con-
ﬁgurations, browser ﬁngerprinting established itself as a
viable technique to enable stateless user tracking in pro-
duction. Companies and academic communities have re-
sponded with a wide range of countermeasures. How-
ever, the way these countermeasures are evaluated does
not properly assess their impact on user privacy, in par-
ticular regarding the quantity of information they may
indirectly leak by revealing their presence.
In this paper, we investigate the current state of the
art of browser ﬁngerprinting countermeasures to study
the inconsistencies they may introduce in altered ﬁnger-
prints, and how this may impact user privacy. To do so,
we introduce FP-SCANNER as a new test suite that ex-
plores browser ﬁngerprint inconsistencies to detect po-
tential alterations, and we show that we are capable of
detecting countermeasures from the inconsistencies they
introduce. Beyond spotting altered browser ﬁngerprints,
we demonstrate that FP-SCANNER can also reveal the
original value of altered ﬁngerprint attributes, such as the
browser or the operating system. We believe that this re-
sult can be exploited by ﬁngerprinters to more accurately
target browsers with countermeasures.
1
Introduction
Recent studies have shown that user tracking keeps in-
creasing among popular websites [2, 4, 23], with mo-
tivations ranging from targeted advertising to content
personalization or security improvements. State-of-the-
art tracking techniques assign a Unique User IDentiﬁer
(UUID), which is stored locally—either as a cookie or
some other storage mechanism (e.g., local storage, E-
tags). Nonetheless, to protect users, private browsing
modes and extensions automatically delete cookies and
clear storages at the end of a session, decreasing the efﬁ-
ciency of the standard tracking techniques.
In 2010, Eckerlsey [3] revealed a stateless track-
ing technique that can complement traditional stateful
tracking: browser ﬁngerprinting. This technique com-
bines several non-Personally Identiﬁable Information
(PII) made available as browser attributes and reveal the
nature of the user device. These attributes are disclosed
by querying a rich diversity of JavaScript APIs, and by
analyzing HTTP headers sent by the browser. By col-
lecting browser ﬁngerprints composed of 8 attributes, he
demonstrated that 83.6% of the visitors of the PANOP-
TICLICK website could be uniquely identiﬁed.
Since browser ﬁngerprinting is stateless, it is difﬁcult
for end-users to opt-out or block, and raises several pri-
vacy concerns, in particular when it comes to undesired
advertising and proﬁling. In response to these concerns,
researchers have developed countermeasures to protect
against browser ﬁngerprinting [10, 11, 15, 20]. Most of
the countermeasures rely on modifying the ﬁngerprint’s
attributes to hide their true identity. Nonetheless, this
strategy tends to generate inconsistent combinations of
attributes called inconsistencies, which are used by com-
mercial ﬁngerprinters, like AUGUR1, or open source li-
braries, such as FINGERPRINTJS2 [21], to detect coun-
termeasures.
In this paper, we extend the work of Niki-
forakis et al. [16], which focused on revealing inconsis-
tencies to detect user agent spoofers, to consider a much
wider range of browser ﬁngerprinting countermeasures.
To do so, we introduce FP-SCANNER, a ﬁngerprint scan-
ner that explores ﬁngerprint attribute inconsistencies in-
troduced by state-of-the-art countermeasures in order to
detect if a given ﬁngerprint is genuine or not. In partic-
ular, we show that none of the existing countermeasures
succeed in lying consistently without being detected and
that it is even possible to recover the ground value of key
attributes, such as the OS or the browser. Then, we dis-
cuss how using detectable countermeasures may impact
user privacy, in particular how ﬁngerprinters can leverage
this information to improve their tracking algorithms.
USENIX Association
27th USENIX Security Symposium    135
In summary, this paper reports on 5 contributions to
better evaluate the privacy impact of browser ﬁngerprint-
ing countermeasures: 1) we review the state-of-the-art
browser ﬁngerprinting countermeasures, 2) we propose
an approach that leverages the notion of consistency to
detect if a ﬁngerprint has been altered, 3) we implement
a ﬁngerprinting script and an inconsistency scanner ca-
pable of detecting altered ﬁngerprints at runtime, 4) we
run extensive experiments to detect how ﬁngerprinting
countermeasures can be detected using our inconsistency
scanner, and 5) we discuss the impact of our ﬁndings on
user privacy.
The remainder of this paper is organized as follows.
Section 2 overviews the state of the art in the domain of
browser ﬁngerprinting before exploring existing browser
ﬁngerprinting countermeasures. Then, Section 3 intro-
duces a new test suite to detect altered browser ﬁnger-
prints. Section 4 reports on an empirical evaluation of
our contribution and Section 5 discusses the impact on
user privacy, as well as the threats to validity. Finally, we
conclude and present some perspectives in Section 6.
2 Background & Motivations
Before addressing the consistency properties of ﬁnger-
print attributes (cf. Section 2.3), we introduce the princi-
ples of browser ﬁngerprint (cf. Section 2.1) and existing
countermeasures in this domain (cf. Section 2.2).
2.1 Browser Fingerprinting in a Nutshell
Browser ﬁngerprinting provides the ability to identify
a browser instance without requiring a stateful iden-
tiﬁer. This means that contrary to classical tracking
techniques—such as cookies—it does not store anything
on the user device, making it both harder to detect and to
protect against. When a user visits a website, the ﬁnger-
printer provides a script that the browser executes, which
automatically collects and reports a set of attributes re-
lated to the browser and system conﬁguration known as
a browser ﬁngerprint. Most of the attributes composing a
ﬁngerprint come from either JavaScript browser APIs—
particularly the navigator object—or HTTP headers.
When considered individually, these attributes do not re-
veal a lot of information, but their combination has been
demonstrated as being mostly unique [3, 12].
Browser Fingerprints Uniqueness and Linkability.
Past studies have covered the efﬁciency of browser ﬁn-
gerprinting as a way to uniquely identify a browser. In
2010, Eckersley [3] collected around half a million ﬁn-
gerprints to study their diversity. He showed that among
the ﬁngerprints collected, 83.6% were unique when only
considering JavaScript-related attributes. With the ap-
pearance of new JavaScript APIs, Mowery et al. [14]
showed how the HTML 5 canvas API could be used to
generate a 2D image whose exact rendering depends on
In 2016, Laperdrix et al. [12] studied the
the device.
diversity of ﬁngerprint attributes, both on desktop and
mobile devices, and showed that even if attributes, like
the list of plugins or the list of fonts obtained through
Flash, exhibit high entropy, new attributes like canvas
are also highly discriminating. They also discovered
that, even though many mobile devices, such as iPhones,
are standardized, other devices disclose a lot of informa-
tion about their nature through their user agent. More
recently, G´omez-Boix et al. [8] analyzed the impact of
browser ﬁngerprinting at a large scale. Their ﬁndings
raise some new questions on the effectiveness of ﬁnger-
printing as a tracking and identiﬁcation technique as only
33.6% of more than two million ﬁngerprints they ana-
lyzed were unique.
Besides ﬁngerprint uniqueness, which is critical for
tracking, stability is also required, as browser ﬁnger-
prints continuously evolve with browser and system up-
dates. Eckersley [3] was the ﬁrst to propose a sim-
ple heuristic to link evolutions of ﬁngerprints over time.
More recently, Vastel et al. [22] showed that, using a set
of rules combined with machine learning, it was possible
to keep track of ﬁngerprint evolutions over long periods
of time.
Browser Fingerprinting Adoption. Several studies
using Alexa top-ranked websites have shown a steady
growth in the adoption of browser ﬁngerprinting tech-
niques [1, 2, 5, 16]. The most recent, conducted by En-
glehardt et al. [5], observed that more than 5% of the
Top 1000 Global Sites listed by Alexa were using canvas
ﬁngerprinting techniques.
2.2 Browser Fingerprinting Countermea-
sures
In response to the privacy issues triggered by browser ﬁn-
gerprint tracking, several countermeasures have been de-
veloped. Among these, we distinguish 5 different strate-
gies of browser ﬁngerprinting countermeasures: script
blocking, attribute blocking, attribute switching with pre-
existing values, attribute blurring with the introduction
of noise, and reconﬁguration through virtualization.
While script blocking extensions are not speciﬁcally
designed to counter browser ﬁngerprinting, they may in-
clude rules that block some ﬁngerprinting scripts. Tools
belonging to this category include GHOSTERY,2 NO-
SCRIPT,3 ADBLOCK,4 and PRIVACY BADGER.5
A strategy speciﬁcally designed against browser ﬁn-
gerprinting is to decrease the entropy of a ﬁngerprint
136    27th USENIX Security Symposium
USENIX Association
by blocking access to speciﬁc attributes. CANVAS
BLOCKER6 is a FIREFOX extension that blocks access
to the HTML 5 canvas API. Besides blocking, it also
provides another mode, similar to CANVAS DEFENDER,7
that randomizes the value of a canvas every time it is
retrieved. Thus, it can also be classiﬁed in the cate-
gory of countermeasures that act by adding noise to at-
tributes. BRAVE8 is a CHROMIUM-based browser ori-
ented towards privacy that proposes speciﬁc countermea-
sures against browser ﬁngerprinting, such as blocking
audio, canvas, and WebGL ﬁngerprinting.
Another strategy consists in switching the value of
different attributes to break the linkability and stability
properties required to track ﬁngerprints over time. ULTI-
MATE USER AGENT9 is a CHROME extension that spoofs
the browser’s user agent. It changes the user agent en-
closed in the HTTP requests as the original purpose of
this extension is to access websites that demand a spe-
ciﬁc browser. FP-BLOCK [20] is a browser extension
that ensures that any embedded party will see a differ-
ent ﬁngerprint for each site it is embedded in. Thus, the
browser ﬁngerprint can no longer be linked to different
websites. Contrary to naive techniques that mostly ran-
domize the value of attributes, FP-BLOCK tries to ensure
ﬁngerprint consistency. RANDOM AGENT SPOOFER10 is
a FIREFOX extension that protects against ﬁngerprinting
by switching between different device proﬁles composed
of several attributes, such as the user agent, the platform,
and the screen resolution. Since proﬁles are extracted
from real browsers conﬁgurations, all of the attributes of
a proﬁle are consistent with each other. Besides spooﬁng
attributes, it also enables blocking advanced ﬁngerprint-
ing techniques, such as canvas, WebGL or WebRTC ﬁn-
gerprinting. Since 2018, FIREFOX integrates an option to
protect against ﬁngerprinting. Like TOR, it standardizes
and switches values of attributes, such as the user agent,
to increase the anonymity set of its users, and also blocks
certain APIs, such as the geolocation or the gamepads
API, to decrease the entropy of the ﬁngerprints.
Another way to break linkability is to add noise to
attributes. This approach is quite similar to attribute
switching, but targeted at attributes that are the result of a
rendering process, like canvas or audio ﬁngerprints, dur-
ing which noise can be added. FPGUARD [6] is a combi-
nation of a CHROMIUM browser and a browser extension
that aims at both detecting and preventing ﬁngerprinting.
They combine blocking, switching and noise techniques.
For example, they block access to fonts by limiting the
number of fonts that can be enumerated in JavaScript.
They switch attribute values for the navigator and screen
objects, and also add noise to rendered canvas images.
FPRANDOM [10] is a modiﬁed version of FIREFOX that
adds randomness in the computation of the canvas ﬁn-
gerprint, as well as the audio ﬁngerprint. They focus on
Table 1: Overview of ﬁngerprinting countermeasures
K
N
I
L
B
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
X
O
F
E
R
I
F
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
E
V
A
R
B
(cid:88)
(cid:88)
(cid:88)
(cid:88)
s
r
e
f
o
o
p
s
A
U
(cid:88)
K
C
O
L
B
-
P
F
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
S
A
R
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
D
R
A
U
G
P
F
(cid:88)
(cid:88)
(cid:88)
(cid:88)
M
O
D
N
A
R
P
F
(cid:88)
(cid:88)
(cid:88)
User Agent
HTTP
Headers
Navigator
object
Canvas
Fonts
WebRTC
Audio
WebGL
R
E
D
N
E
F
E
D
S
A
V
N
A
C
(cid:88)
these attributes because canvas ﬁngerprinting is a strong
source of entropy [12], and these two attributes rely on
multimedia functions that can be slightly altered with-
out being noticed by the user. FPRANDOM includes two
modes, one in which noise is different at every call and
a second mode where noise remains constant over a ses-
sion. The goal of the second mode is to protect against
replay attacks, that is, if a ﬁngerprinter runs the same
script twice, the result will be the same and the browser
will not be found to be exposing an artiﬁcial ﬁngerprint.
reconﬁguration
through virtual machines or containers
to clone
real ﬁngerprints—i.e., in contrary to countermeasures
that lie on their identity by simply altering the values of
the attributes collected—BLINK generates virtual envi-
ronments containing different fonts, plugins, browsers
in order to break the stability of ﬁngerprints, without
introducing inconsistencies.
exploits
Finally,
BLINK
[11]
Table 1 summarizes the ﬁngerprint’s attributes com-
monly collected by ﬁngerprinters [13], and altered by
the countermeasures we introduced in this section. For
more complex countermeasures that alter a wider range
of attributes, we give more details in Table 2. In both ta-
bles, the presence of a checkmark indicates that the given
countermeasure either blocks or manipulates the value of
the attribute.
2.3 Browser Fingerprint Consistency
As described above, most of the browser ﬁngerprinting
countermeasures alter the value of several attributes,
either by blocking access to their values, by adding
noise or by faking them. However, by altering the