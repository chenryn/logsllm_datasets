title:ClusterFA: a memory-efficient DFA structure for network intrusion
detection
author:Lei Jiang and
Jianlong Tan and
Yanbing Liu
ClusterFA: A Memory-efﬁcient DFA Structure for Network
Intrusion Detection
Lei Jiang
Institute of Computing
Technology
Beijing, P.R. China
PI:EMAIL
Jianlong Tan
Institute of Computing
Technology
Yanbing Liu
Institute of Computing
Technology
Chinese Academy of Sciences
Chinese Academy of Sciences
Chinese Academy of Sciences
Beijing, P.R. China
PI:EMAIL
Beijing, P.R. China
PI:EMAIL
ABSTRACT
Regular expressions are widely used in modern network in-
trusion detection systems (NIDS) to represent attack signa-
tures for the high expressive power. NIDS typically accom-
plish regular expression matching using deterministic ﬁnite
automata (DFA), which provides fast and steady matching
speed. But the DFA of complex rule sets usually consume
large memory resources because of the state blowup prob-
lem. Many techniques have been proposed to resolve this
issue. In this paper, we present a new DFA structure - Clus-
terFA, which considerably reduces the transition edges and
memory consumption by more than 95%. Observing the D-
FA’s transition table, almost every state has multiple similar
states, with only little (< 1%) diﬀerent transitions. To take
full advantage of these similarities, we cluster the similar
states together using clustering algorithms and calculate a
common state for each cluster.
In this way, we eﬃciently
improve the compression ratio. Experimental results show
that on real-life rule sets, our algorithm reduces the memory
consumption by more than 2 times comparing with previous
DFA compressing algorithms while preserving fast matching
speed. Furthermore, by introducing encoding technique, we
further improve the memory compression ratio to more than
99%, which is better than any known algorithms.
Categories and Subject Descriptors
C.2.0 [COMPUTER-COMMUNICATION NETWORK-
S]: General - Security and protection
General Terms
Pattern, Security
Keywords
NIDS, regular expression, clustering, DFA
1.
INTRODUCTION
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ASIACCS ’12, May 2–4, 2012, Seoul, Korea.
Copyright 2012 ACM 978-1-4503-1303-2/12/05 ...$10.00.
Network intrusion detection systems (NIDS) plays an in-
creasing important role in the ﬁeld of network security. Cur-
rent NIDS, such as Bro [31] and Snort [32], mainly use sig-
natures to represent and detect networking attacks. Tradi-
tionally the signatures are depicted by exact string patterns.
However, new worms and viruses emerge endlessly in recent
years. As a result, the scale of signatures increases sharply.
According to the statistics [12] to the Snort rule sets, the
number of signature patterns has increased eight-fold from
2003 to 2008. Compared with exact strings, regular expres-
sions have more powerful expressiveness, and are replacing
exact strings gradually in state-of-the-art NIDS. For exam-
ple, the Snort has more than 500 regular expression rules in
2008.
Regular expressions matching algorithm is usually imple-
mented via ﬁnite automata (FA) [18]. Lots of theories and
algorithms [2][29][35] on regular expressions have been pro-
posed since 1960s. Typically the FAs are classiﬁed by deter-
ministic ﬁnite automata (DFA) and nondeterministic ﬁnite
automata (NFA). DFA activates only one state transition
for each input character, whereas NFA activates multiple
transitions per charactor. Therefore the DFA algorithm’s
searching complexity is O(1), and provides a fast and stable
matching speed. For this reason, mainstream NIDS (snort,
bro etc.) prefer DFA to perform regular expression match-
ing. But as the rule sets are becoming increasingly complex
and large, DFAs are possible to suﬀer from the state blowup
problem. For example, the L7-ﬁlter’s [22] regular expression
rule set consumes more than 16GB memory space [25] when
compiled by normal DFA algorithm. Obviously, it is crucial
to ruduce the memory consumption of DFA to satisfy the
complex and high-speed networking environments. Many
algorithms have been proposed for this target, by exploiting
the redundancies of DFA transitions.
This paper focuses on the memory compression of DFA.
We introduce a novel DFA structure, named ClusterFA,
which considerably reduces the transition edges and stor-
age space. Observing the DFA’s transition table, we notice
that almost every state has multiple similar states, with lit-
tle (< 1%) diﬀerent transitions between them. It is appeal-
ing to eliminate the redundancies by putting these similar
states together, and use a ”merge-like-terms” approach to
delete the same transitions. In ClusterFA we apply cluster-
ing algorithms to classify all DFA states to K groups. In
each group, we extract a common state, and the transitions
diﬀerent from this common state is stored in a sparse matrix
which is easy to compress.
Two classical clustering algorithms are considered in this
paper, namely K-Means [27] and CLINK [10]. Besides, a
state-of-the-art spectral clustering algorithm, pspectralclus-
tering [7],
is also evaluated in our work. The K-Means
clustering algorithm is a partition based algorithm [20], the
CLINK algorithm is a connectivity based based algorithm
[11], and the pspectralclustering algorithm is a, as mentioned
before, spectral algorithm [16]. Every clustering algorithm
employed in our work is an unsupervised learning mechanis-
m, which means the data don’t have to be tagged in advance.
To the best of our knowledge, cluster analysis has never been
previously applied to the compression of DFA.
We evaluate ClusterFA with real-life rule sets from Bro,
Snort and L7-ﬁlter. Experiment results show that our al-
gorithm considerably reduces the memory consumption by
more than 95% while preserving fast matching speed.
In
addition, an encoding scheme is introduced to our work to
further improve the compression ratio. In the best case, the
improved algorithm saved more than 99% memory space.
In summary, the main contributions of our work are as
follows:
1. A novel compression algorithm is developed using the
similarities of states from a ”global” perspective;
2. We are the ﬁrst to apply clustering technique into the
DFA compression problem, and evaluate three cluster-
ing algorithms, with considerable compression results;
3. Encoding scheme is introduced to further improve the
compression ratio;
4. A great deal of experiments based on signatures of Bro,
Snort and L7-ﬁlter are presented to evaluate the per-
formance of ClusterFA.
The rest of the paper is organized as follows. Section II sum-
marizes the related work in literature. Section III describes
the basic idea of ClusterFA and demonstrates the detailed
algorithm framework. Section IV introduces details of clus-
tering algorithms. Section V presented experiment results.
Finally, Section VI concludes this paper.
2. RELATED WORKS
Early NIDS mainly use exact strings to depict attack sig-
natures and process the packets. Many string-based pat-
tern matching algorithms have been proposed, such as Aho-
Corasick [1] and Wu-Manber [28]. Nowadays state-of-the-art
NIDS prefer regular expressions for their powerful expres-
siveness. Traditionally, DFA and NFA are used to imple-
ment regular expressions matching. The space complexity
of NFA is O(n) and its searching complexity is O(n2), while
DFA’s storage complexity is O(2n) in the worst case and its
searching searching complexity is O(1), where n is the length
of regular expression. So NFA consumes little memory, but
require longer time to process one input character. Due to
the nature of NFA, NFA-based approaches are usually im-
plemented based on hardware, such as ASIC, FPGA and T-
CAMs. In contrast, DFA-based approaches usually consume
memories and provide high-speed matching. For software-
based NIDS, DFA is more appealing because of their deter-
ministic behavior and high throughput.
Floyd and Ullman showed that an NFA regular expression
circuit can be implemented eﬃciently using programmable
logic array architecture [15]. Sidhu et al.
[33] and Clark
et al. [8][9] showed that NFA is an eﬃcient method in ter-
m of processing speed and area eﬃciency for implementing
regular expressions on FPGAs. In recent years, many new
NFA algorithms are proposed, and increase the throughput
to more than 10Gbps on FPGAs [30][36]. But these NFA-
based implementations are diﬃcult to update the rule sets
due to the requirement of reconﬁguring FPGA. In addition,
the implementation of NFA require circuit resources, and
are limited by the scale and cost of hardware.
Fang Yu et al.
[37] study and try to resolve the state
blowup problem of DFAs. They ﬁnd that memory require-
ments using traditional methods are prohibitively high for
typical patterns used in real-world packet payload scanning
applications. Then they propose regular expression rewrite
techniques to reduce memory usage and a group scheme to
regular expression rule sets to several groups. However, their
rule rewriting depends on the rule sets. It is possible that
new attack signatures lead DFAs to become invalid come
out. In this case, new signature structures have to be stud-
ied.
Kumar et al. [21] observed that two states (S1, S2) have
many similar next state transitions (T) for an input charac-
ters subset. According to this observation their proposed a
new algorithm called D2FA to compress the transition table.
D2FA eliminate S1’s transitions (T) by introducing a default
transition from S1 to S2. The experimental results show that
a D2FA reduces transitions by more than 95% compared to
original DFA. However D2FA’s transition mechanism is pos-
sible look up memory multiple times per input character,
which lead to requirement for higher memory band.
Based on the observation that most adjacent states share
a large part of identical transitions, Ficara et al.
[14][13]
present a new representation for deterministic ﬁnite automa-
ta, called Delta Finite Automata (δFA). They record the
transition set of current state int a local memory, and only
store the diﬀerences between current state and next hop s-
tate. In this way, δFA achieves very good compression eﬀect.
In addition, this algorithm requires only a state transition
per character (keeping the characteristic of standard DFAs),
thus allows a fast string matching.
Smith et al.
[34] present a formal characterization of
state-space explosion and presented XFAs to eliminate it.
XFA extends standard DFAs with auxiliary variables and
instructions (e.g., counters of characters and other instruc-
tions attached to edges and states). for manipulating them.
Experiments based on signature sets from Snort and Cisco
Systems show that XFAs achieve state-space reductions of
over four orders of magnitude and space complexity similar
to or better than NFAs.
Based on the observation that DFAs are infeasible with
large sets of regular expressions (especially for those which
present wildcards) and that, as an alternative, NFAs allevi-
ate the memory storage problem but lead to a potentially
large memory bandwidth requirement. Becchi et al.
[4]
propose a hybrid DFA-NFA ﬁnite automaton (Hybrid-FA),
which brings together the strengths of both DFAs and N-
FAs. When constructing a hybrid-FA, any nodes that would
contribute to state explosion retain an NFA encoding, while
the rest are transformed into DFA nodes. Experiment result
show that this data structure presents a size nearly that of
an NFA, but with the predictable and small memory band-
width requirements of a DFA.
Figure 1: FAs built from regular expressions (a+), (b + c) and (c ∗ d+). (a) DFA. (b) D2FA. (c) δFA. (d)
ClusterFA
According to statistics for real-ﬁle rule sets, Lin W et al.
[23] observed that the summation of transitions from each
state to its top three most popular next states took about
90% of all the transitions. Therefore, the author proposed a
hardware-based compact DFA called CPDFA. The CPDFA
employed an indirect index table to represent transitions to
top three most popular next states. The remaining transi-
tions which took about 10% of all the transitions were stored
in a direct transition table or K parallel SRAMs according to
whether or not the remaining transitions of the same state
was more than K. Experimental results showed that CPDFA
could save about 90% of memory storage compared to the
original DFA.
T. Liu et al .[25] introduce a new compression algorithm
which can reduce memory usage of DFA stably without sig-
niﬁcant impact on matching speed. They observe the char-
acteristic of transition distribution inside each state, and
ﬁnd that above 90% of transitions in DFAs transfer to the
initial state or its near neighbors which are called magic s-
tates by Becci in [5]. By this observation, they divide all the
transitions and store them into three diﬀerent matrixes and
compress these matrixes. Experiment results show that this
algorithm save memory space by 95% with only 40% loss of
matching speed comparing with original DFA.
Y. Liu et al .[26] have presented a new DFA matrix com-
pressing algorithm named CRD (Column-Row Decomposi-
tion). This algorithm is to decompose the DFA transition
table into a column, a row vector a sparse matrix to reduce
the storage space as much as possible. Experiments on typ-
ical rule sets show that the proposed method signiﬁcantly
reduces the memory usage and still runs at fast searching
speed.
3. CLUSTERFA ALGORITHM DESIGN
Many algorithms have been proposed to reduce memory
consumption of DFAs by exploiting the redundancies exist-
ing in the transition table. In all these works, D2FA [21] and
δFA [14] are most important. However, Both of them only
focus eliminating the redundancy between adjacent states,
so can be regarded as a kind of ”local” algorithm. In this sec-
tion, we introduce a novel DFA structure named ClusterFA
to eliminate the redundancies from a ”global” perspective.
3.1 Motivating Example
D2FA ,δFA and ClusterFA are all transition eliminating
compressing algorithms. To clarify the relations and diﬀer-
ences of these three algorithms, we analyze an example of
processing a DFA on the alphabet {a, b, c, d} which recog-
nizes the regular expressions (a+), (b + c) and (c∗ d+). The
original DFA is presented as Fig. 1(a). In this graph, state 1
is the initial state, and states 2, 5 and 4 are match states for
the three patterns (a+), (b + c) and (c ∗ d+), respectively.
Fig. 1(b) shows the structure corresponding to D2FA. When
matching an input string, a default transition, presented by
bold unlabeled lines in the graph, is used to determine the
next state, if the current state does not have an outgoing
edge labeled with the current input character. After coming
back to the default transition, the current input character
is used to determine the next state. Consider the opera-
tion of the FAs in Fig. 1(a) and Fig. 1(b), with the input
string aabdbc. For this input, the sequence of states visited
by the original DFA is 1223435, where the underlined states
are the match states that determine the output value for
this input string. The automaton in Fig. 1(b) visits states
1212314135. Note that in Fig. 1(a), the DFA has 20 edges,
while in Fig. 1(b),the D2FA only has 9 edges by introducing
default transitions, thus having a remarkable compression.
Fig. 1(c) shows the structure corresponding to δFA. Ob-