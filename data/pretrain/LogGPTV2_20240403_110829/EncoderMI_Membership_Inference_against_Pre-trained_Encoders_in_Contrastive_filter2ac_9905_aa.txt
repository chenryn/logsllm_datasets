title:EncoderMI: Membership Inference against Pre-trained Encoders in Contrastive
Learning
author:Hongbin Liu and
Jinyuan Jia and
Wenjie Qu and
Neil Zhenqiang Gong
EncoderMI: Membership Inference against Pre-trained
Encoders in Contrastive Learning
Hongbin Liu∗
Duke University
PI:EMAIL
Wenjie Qu†
Huazhong University of Science and Technology
PI:EMAIL
Jinyuan Jia∗
Duke University
PI:EMAIL
Neil Zhenqiang Gong
Duke University
PI:EMAIL
ABSTRACT
Given a set of unlabeled images or (image, text) pairs, contrastive
learning aims to pre-train an image encoder that can be used as a fea-
ture extractor for many downstream tasks. In this work, we propose
EncoderMI, the first membership inference method against image
encoders pre-trained by contrastive learning. In particular, given an
input and a black-box access to an image encoder, EncoderMI aims
to infer whether the input is in the training dataset of the image
encoder. EncoderMI can be used 1) by a data owner to audit whether
its (public) data was used to pre-train an image encoder without
its authorization or 2) by an attacker to compromise privacy of the
training data when it is private/sensitive. Our EncoderMI exploits
the overfitting of the image encoder towards its training data. In
particular, an overfitted image encoder is more likely to output
more (or less) similar feature vectors for two augmented versions of
an input in (or not in) its training dataset. We evaluate EncoderMI
on image encoders pre-trained on multiple datasets by ourselves as
well as the Contrastive Language-Image Pre-training (CLIP) image
encoder, which is pre-trained on 400 million (image, text) pairs col-
lected from the Internet and released by OpenAI. Our results show
that EncoderMI can achieve high accuracy, precision, and recall. We
also explore a countermeasure against EncoderMI via preventing
overfitting through early stopping. Our results show that it achieves
trade-offs between accuracy of EncoderMI and utility of the image
encoder, i.e., it can reduce the accuracy of EncoderMI, but it also
incurs classification accuracy loss of the downstream classifiers
built based on the image encoder.
CCS CONCEPTS
• Security and privacy; • Computing methodologies → Ma-
chine learning;
∗The first two authors made equal contributions.
†Wenjie Qu performed this research when he was a remote intern in Gong’s group.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea.
© 2021 Association for Computing Machinery.
ACM ISBN 978-1-4503-8454-4/21/11...$15.00
https://doi.org/10.1145/3460120.3484749
KEYWORDS
Membership inference; contrastive learning; privacy-preserving
machine learning
ACM Reference Format:
Hongbin Liu∗, Jinyuan Jia∗, Wenjie Qu†, and Neil Zhenqiang Gong. 2021.
EncoderMI: Membership Inference against Pre-trained Encoders in Con-
trastive Learning. In Proceedings of the 2021 ACM SIGSAC Conference on
Computer and Communications Security (CCS ’21), November 15–19, 2021,
Virtual Event, Republic of Korea. ACM, New York, NY, USA, 15 pages. https:
//doi.org/10.1145/3460120.3484749
1 INTRODUCTION
Contrastive learning [10, 17, 20, 37, 38] is a promising approach for
general-purpose AI. In particular, given an unlabeled dataset (called
pre-training dataset) of images or (image, text) pairs, contrastive
learning pre-trains an image encoder that can be used as a feature
extractor for many downstream tasks. Given the image encoder,
the downstream tasks require only a small amount of or no labeled
training data. The pre-training of encoders, however, usually con-
sumes a lot of data and computation resources. Therefore, typically,
a powerful encoder provider (e.g., OpenAI, Google) pre-trains en-
coders and then provides service to downstream customers (e.g.,
less resourceful organizations, end users).
Existing studies [10, 20, 38] on contrastive learning mainly focus
on how to train a better image encoder such that it can achieve
better performance on the downstream tasks. The security and
privacy of contrastive learning, however, is largely unexplored. In
this work, we perform the first systematic study on membership
inference against image encoders pre-trained by contrastive learn-
ing. In particular, we aim to infer whether an input image is in
the pre-training dataset of an image encoder. An input is called a
member (or non-member) of an image encoder if it is in (or not in)
the pre-training dataset of the image encoder.
Membership inference in contrastive learning has two important
applications. Suppose data owners make their images public on the
Internet, e.g., on Twitter. An AI company (e.g., OpenAI) collects and
uses the public data to pre-train and monetize image encoders with-
out the data owners’ authorization. Such practices may violate the
data owners’ data security. For instance, Twitter asked Clearview
to stop taking public images from its website for model training [1];
and FTC requires Ever to delete models trained on unauthorized
user data [3]. The first application of membership inference is that
a data owner can use a membership inference method to audit
whether his/her (public) data was used to pre-train image encoders
Session 7A: Privacy Attacks and Defenses for ML CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2081without his/her authorization, though the membership inference
result may not have formal guarantees. The second application of
membership inference is that an attacker can use it to compromise
privacy of the pre-training data when it is private/sensitive. For
instance, hospitals may collaboratively use contrastive learning to
pre-train image encoders that can be shared across hospitals to
solve various downstream healthcare tasks, e.g., lung CT image
based COVID-19 testing [16] and skin disease prediction. In such
cases, the pre-training data may include sensitive medical images
and one hospital may infer other hospitals’ sensitive members of
the image encoder.
Existing membership inference methods [29, 34, 35, 42, 44, 48] are
mainly designed for classifiers. For example, given the confidence
score vector outputted by a classifier for an input, they aim to infer
whether the input is in the training dataset of the classifier. The
idea of existing membership inference methods [42, 44] is to exploit
the overfitting of the classifier. For instance, the confidence score
vectors of members and non-members of a classifier are statistically
distinguishable. Therefore, the confidence score vector outputted
by the classifier for an input can capture whether the input is a
member of the classifier. However, given an input, an image encoder
outputs a feature vector for it. The feature vector itself does not
capture the overfitting of the image encoder on the input. As shown
by our experimental results in Section 5.2, existing membership
inference methods for classifiers are close to random guessing when
generalized to infer the members of an image encoder.
Our work: In this work, we propose EncoderMI, the first member-
ship inference method against contrastive learning.
Threat model. We call an entity (e.g., a data owner, an attacker)
who performs membership inference an inferrer. We assume an in-
ferrer has a black-box access to a pre-trained image encoder (called
target encoder), which is the most difficult and general scenario.
The inferrer aims to infer whether an input is in the pre-training
dataset of the target encoder. The pre-training of an image encoder
relies on three key dimensions: pre-training data distribution, en-
coder architecture, and training algorithm. In other words, we have
three dimensions of background knowledge. The inferrer may or
may not know each of them. Therefore, we have eight different
types of background knowledge for the inferrer in total. In our
methods, we assume the inferrer has a shadow dataset. In partic-
ular, the shadow dataset could have the same distribution as the
pre-training data distribution if the inferrer knows it. Otherwise,
we assume the shadow dataset has a different distribution from
the pre-training dataset. Moreover, if the inferrer does not know
the encoder architecture (or training algorithm), we consider the
inferrer can assume one and perform membership inference based
on the assumed one.
Our EncoderMI. An important module in contrastive learning
is data augmentation. Roughly speaking, given an input, the data
augmentation module creates another random input (called aug-
mented input) via applying a sequence of random operations (e.g.,
random grayscale, random resized crop) to the input. We observe
that contrastive learning essentially aims to pre-train an image en-
coder such that it outputs similar feature vectors for two augmented
inputs created from the same input. EncoderMI is based on this
observation. Specifically, when an image encoder is overfitted to its
pre-training dataset, it may output more (or less) similar feature
vectors for augmented inputs that are created from an input in (or
not in) the pre-training dataset. In EncoderMI, an inferrer builds a
binary classifier (called inference classifier) to predict whether an
input is a member of the target encoder. Roughly speaking, our
inference classifier predicts an input to be a member of the target
encoder if the target encoder produces similar feature vectors for
the augmented inputs created from the input. Next, we discuss how
to build inference classifiers.
Given a shadow dataset, we first split it into two subsets, namely,
shadow member dataset and shadow non-member dataset. Then,
we pre-train an encoder (called shadow encoder) using the shadow
member dataset based on the background knowledge of the inferrer
(e.g., the inferrer can adopt the same encoder architecture and
training algorithm used to pre-train the target encoder if he/she
knows them). Given the shadow encoder and the shadow dataset,
we extract membership features for each input in the shadow dataset.
In particular, given an input in the shadow dataset, we first create 𝑛
augmented inputs via the data augmentation module of the training
algorithm used to train the shadow encoder, then use the shadow
encoder to produce a feature vector for each augmented input,
and finally compute the set of 𝑛 · (𝑛 − 1)/2 pairwise similarity
scores between the 𝑛 feature vectors using a similarity metric as
the membership features for the input. Given these membership
features, we construct an inference training dataset via labeling
the membership features as “member” ( or “non-member”) if they
are created from an input that is in the shadow member (or non-
member) dataset. Given the inference training dataset, we build
an inference classifier to infer the members of the target encoder.
We consider three types of classifiers: vector-based classifier, set-
based classifier, and threshold-based classifier. Given an input and a
black-box access to the target encoder, we first extract membership
features for the input and then use an inference classifier to predict
whether the input is a member of the target encoder.
Evaluation. To evaluate EncoderMI, we first conduct experiments
on CIFAR10, STL10, and Tiny-ImageNet datasets via pre-training
image encoders by ourselves. Our experimental results show that
EncoderMI can achieve high accuracy, precision, and recall under
all the eight different types of background knowledge. For instance,
our vector-based inference classifier can achieve 88.7% – 96.5%
accuracy on Tiny-ImageNet under the eight types of background
knowledge. Moreover, EncoderMI can achieve higher accuracy as
the inferrer has access to more background knowledge. We also
apply EncoderMI to infer members of the CLIP’s image encoder
released by OpenAI [38]. In particular, we collect some potential
members and ground truth non-members of the CLIP’s image en-
coder from Google image search and Flickr. Our results show that
EncoderMI is effective even if the inferrer does not know the pre-
training data distribution, the encoder architecture, and the training
algorithm of the CLIP’s image encoder.
Countermeasure. When a data owner uses EncoderMI to audit
data misuse, an encoder provider may adopt a countermeasure
against EncoderMI to evade auditing. When an attacker uses Enco-
derMI to compromise pre-training data privacy, a countermeasure
can be adopted to enhance privacy. As EncoderMI exploits the over-
fitting of the target encoder on its training data, we can leverage
Session 7A: Privacy Attacks and Defenses for ML CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2082countermeasures that prevent overfitting. In particular, we gener-
alize early stopping [47], a state-of-the-art overfitting-prevention-
based countermeasure against membership inference to classifiers,
to mitigate membership inference to pre-trained encoders. Roughly
speaking, the idea of early stopping is to train the target encoder
with less number of epochs to prevent overfitting. Our results show
that it achieves trade-offs between the accuracy of EncoderMI and
the utility of the target encoder. More specifically, it can reduce the
accuracy of our EncoderMI, but it also incurs classification accuracy
loss of the downstream classifiers built based on the target encoder.
In summary, we make the following contributions in this work:
• We propose EncoderMI, the first membership inference method
• We conduct extensive experiments to evaluate our EncoderMI
on CIFAR10, STL10, and Tiny-ImageNet datasets. Moreover,
we apply EncoderMI to CLIP’s image encoder.
against contrastive learning.
• We evaluate an early stopping based countermeasure against
EncoderMI. Our results show that it achieves trade-offs be-
tween accuracy of EncoderMI and utility of the encoder.
2 BACKGROUND ON CONTRASTIVE
LEARNING
Given a large amount of unlabeled images or (image, text) pairs
(called pre-training dataset), contrastive learning aims to pre-train a
neural network (called image encoder) that can be used as a feature
extractor for many downstream tasks (e.g., image classification).
Given an input image, the pre-trained image encoder outputs a
feature vector for it.
2.1 Pre-training an Encoder
An essential module in contrastive learning is data augmentation.
Given an input image, the data augmentation module can create
another random input (called augmented input) by a sequence of
random operations such as random grayscale, random resized crop,
etc.. An augmented input and the original input have the same size.
Moreover, we can create multiple augmented inputs for each input
using the data augmentation module. Roughly speaking, the idea
of contrastive learning is to pre-train an image encoder such that it
outputs similar (or dissimilar) feature vectors for two augmented
inputs created from the same (or different) input(s). Contrastive
learning formulates such similarity as a contrastive loss, which an
image encoder is trained to minimize. Next, we introduce three pop-
ular contrastive learning algorithms, i.e., MoCo [20], SimCLR [10],
and CLIP [38], to further illustrate the idea of contrastive learning.
MoCo [20]: MoCo pre-trains an image encoder on unlabeled im-
ages. There are three major modules in MoCo: an image encoder
(denoted as ℎ), a momentum encoder (denoted as ℎ𝑚), and a dictio-
nary (denoted as Γ). The image encoder outputs a feature vector
for an input or an augmented input. The momentum encoder has
the same architecture with the image encoder, but is updated much
more slowly compared with the image encoder. Given an input or
an augmented input, the momentum encoder also outputs a vec-
tor for it. To distinguish with feature vector, we call it key vector.
The dictionary module maintains a queue of key vectors outputted