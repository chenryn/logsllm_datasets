title:Who is tweeting on Twitter: human, bot, or cyborg?
author:Zi Chu and
Steven Gianvecchio and
Haining Wang and
Sushil Jajodia
Who is Tweeting on Twitter: Human, Bot, or Cyborg?
Zi Chu, Steven Gianvecchio and Haining Wang
Department of Computer Science
The College of William and Mary
Williamsburg, VA 23187, USA
{zichu, srgian, hnw}@cs.wm.edu
Sushil Jajodia
Center for Secure Information Systems
George Mason University
Fairfax, VA 22030, USA
PI:EMAIL
ABSTRACT
Twitter is a new web application playing dual roles of online so-
cial networking and micro-blogging. Users communicate with each
other by publishing text-based posts. The popularity and open
structure of Twitter have attracted a large number of automated pro-
grams, known as bots, which appear to be a double-edged sword to
Twitter. Legitimate bots generate a large amount of benign tweets
delivering news and updating feeds, while malicious bots spread
spam or malicious contents. More interestingly, in the middle be-
tween human and bot, there has emerged cyborg referred to either
bot-assisted human or human-assisted bot. To assist human users in
identifying who they are interacting with, this paper focuses on the
classiﬁcation of human, bot and cyborg accounts on Twitter. We
ﬁrst conduct a set of large-scale measurements with a collection of
over 500,000 accounts. We observe the difference among human,
bot and cyborg in terms of tweeting behavior, tweet content, and
account properties. Based on the measurement results, we propose
a classiﬁcation system that includes the following four parts: (1)
an entropy-based component, (2) a machine-learning-based com-
ponent, (3) an account properties component, and (4) a decision
maker. It uses the combination of features extracted from an un-
known user to determine the likelihood of being a human, bot or
cyborg. Our experimental evaluation demonstrates the efﬁcacy of
the proposed classiﬁcation system.
Categories and Subject Descriptors
C.2.0 [Computer-Communication Networks]: General—Secu-
rity and Protection
General Terms
Security
Keywords
Automatic Identiﬁcation, Bot, Cyborg, Twitter
INTRODUCTION
1.
Twitter is a popular online social networking and micro-blogging
tool, which was released in 2006. Remarkable simplicity is its dis-
tinctive feature. Its community interacts via publishing text-based
posts, known as tweets. The tweet size is limited to 140 charac-
ters. Hashtag, namely words or phrases preﬁxed with a # symbol,
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ACSAC ’10 Dec. 6-10, 2010, Austin, Texas USA
Copyright 2010 ACM 978-1-4503-0133-6/10/12 ...$10.00.
can group tweets by topic. For example, #Haiti and #Super Bowl
are the two trending hashtags on Twitter in January 2010. Symbol
@ followed by a username in a tweet enables the direct delivery
of the tweet to that user. Unlike most online social networking
sites (i.e., Facebook and MySpace), Twitter’s user relationship is
directed and consists of two ends, friend and follower. In the case
where the user A adds B as a friend, A is a follower of B while B
is a friend of A. In Twitter terms, A follows B. B can also add A as
his friend (namely, following back or returning the follow), but is
not required. From the standpoint of information ﬂow, tweets ﬂow
from the source (author) to subscribers (followers). More speciﬁ-
cally, when a user posts tweets, these tweets are displayed on both
the author’s homepage and those of his followers.
Since 2009, Twitter has gained increasing popularity. As re-
ported in June 2010, Twitter is attracting 190 million visitors per
month and generating 65 million Tweets per day [30]. It ranks the
12th on the top 500 site list according to Alexa [5]. In November
2009, Twitter emphasized its value as a news and information net-
work by changing the question above the tweet input dialog box
from “What are you doing” to “What’s happening”. To some ex-
tent, Twitter is in the transition from a personal micro-blogging
site to an information publish venue. Many traditional industries
have used Twitter as a new media channel. We have witnessed suc-
cessful Twitter applications in business promotion [1], customer
service [3], political campaigning [2], and emergency communica-
tion [21, 35].
The growing user population and open nature of Twitter have
made itself an ideal target of exploitation from automated programs,
known as bots. Like existing bots in other web applications (i.e., In-
ternet chat [14], blogs [34] and online games [13]), bots have been
common on Twitter. Twitter does not inspect strictly on automa-
tion. It only requires the recognition of a CAPTCHA image during
registration. After gaining the login information, a bot can perform
most human tasks by calling Twitter APIs. More interestingly, in
the middle between humans and bots have emerged cyborgs, which
refer to either bot-assisted humans or human-assisted bots. Cy-
borgs have become common on Twitter. After a human registers
an account, he may set automated programs (i.e., RSS feed/blog
widgets) to post tweets during his absence. From time to time, he
participates to tweet and interact with friends. Cyborgs interweave
characteristics of both humans and bots.
Automation is a double-edged sword to Twitter. On one hand,
legitimate bots generate a large volume of benign tweets, like news
and blog updates. This complies with the Twitter’s goal of becom-
ing a news and information network. On the other hand, malicious
bots have been greatly exploited by spammers to spread spam or
malicious contents. These bots randomly add users as their friends,
expecting a few users to follow back1. In this way, spam tweets
posted by bots display on users’ homepages. Enticed by the appeal-
ing text content, some users may click on links and get redirected
to spam or malicious sites2. If human users are surrounded by ma-
1Some advanced bots target potential users by keyword search.
2Due to the tweet size limit, it is very common to use link short-
ening service on Twitter, which converts an original link to a short
one (i.e., http://bit.ly/dtUm5Q). The link illegibility favors bots to
21
licious bots and spam tweets, their twittering experience deterio-
rates, and eventually the whole Twitter community will be hurt.
The objective of this paper is to characterize the automation feature
of Twitter accounts, and to classify them into three categories, hu-
man, bot, and cyborg, accordingly. This will help Twitter manage
the community better and help human users recognize who they are
tweeting with.
In the paper, we ﬁrst conduct a series of measurements to char-
acterize the differences among human, bot, and cyborg in terms
of tweeting behavior, tweet content, and account properties. By
crawling Twitter, we collect over 500,000 users and more than 40
million tweets posted by them. Then we perform a detailed data
analysis, and ﬁnd a set of useful features to classify users into the
three classes. Based on the measurement results, we propose an
automated classiﬁcation system that consists of four major compo-
nents: (1) the entropy component uses tweeting interval as a mea-
sure of behavior complexity, and detects the periodic and regular
timing that is an indicator of automation; (2) the machine-learning
component uses tweet content to check whether text patterns con-
tain spam or not3; (3) the account properties component employs
useful account properties, such as tweeting device makeup, URL
ration, to detect deviations from normal; (4) the decision maker is
based on Linear Discriminant Analysis (LDA), and it uses the linear
combination of the features generated by the above three compo-
nents to categorize an unknown user as human, bot or cyborg. We
validate the efﬁcacy of the classiﬁcation system through our test
dataset. We further apply the system to classify the entire dataset
of over 500,000 users collected, and speculate the current compo-
sition of Twitter user population based on our classiﬁcation results.
The remainder of this paper is organized as follows. Section 2
covers related work on Twitter and online social networks. Section
3 details our measurements on Twitter. Section 4 describes our
automatic classiﬁcation system on Twitter. Section 5 presents our
experimental results on classiﬁcation of humans, bots, and cyborgs
on Twitter. Finally, Section 6 concludes the paper.
2. RELATED WORK
Twitter has been widely used since 2006, and there are some
related literature in twittering [24, 25, 43]. To better understand
micro-blogging usage and communities, Java et al. [24] studied
over 70,000 Twitter users and categorized their posts into four main
groups—daily chatter (e.g., “going out for dinner"), conversations,
sharing information or URLs, and reporting news—and further clas-
siﬁed their roles by link structure into three main groups—information
source, friends, and information seeker. Their work also studied
(1) the growth of Twitter, showing a linear growth rate; (2) its net-
work properties, showing the evidence that the network is scale-
free like other social networks [27]; and (3) the geographical dis-
tribution of its users, showing that most Twitter users are from the
US, Europe, and Japan. Krishnamurthy et al. [25] studied a group
of over 100,000 Twitter users and classiﬁed their roles by follower-
to-following ratios into three groups: (1) broadcasters, which have
a large number of followers; (2) acquaintances, which have about
the same number on either followers or following; and (3) miscre-
ants and evangelists (e.g., spammers), which follow a large number
of other users but have few followers. Their work also examined
the growth of Twitter, revealing a greater than linear growth rate. In
a more recent work, Yardi et al. [43] investigated spam on Twitter.
According to their observations, spammers send more messages
than legitimate users, and are more likely to follow other spammers
than legitimate users. Thus, a high follower-to-following ratio is a
sign of spamming behavior. Kim et al. [10] analyzed Twitter lists
as a potential source for discovering latent characters and interests
of users. A Twitter list consists of multiple users and their tweets.
Their research indicated that words extracted from each list are rep-
resentative of all the members in the list even if the words are not
used by the members. It is useful for targeting users with speciﬁc
interests.
Compared to previous measurement studies on Twitter, our work
allure users.
3Spam is a good indicator of automation. Most spam messages are
generated by bots, and very few are manually posted by humans.
22
covers a much larger group of Twitter users (more than 500,000)
and differs in how we link the measurements to automation, i.e.,
whether posts are from humans, bots, or cyborgs. While some sim-
ilar metrics are used in our work, such as follower-to-following
ratio, we also introduce some metrics, including entropy of tweet
intervals, which are not employed in previous research. In addition
to network-related studies, several previous works focus on socio-
technological aspects of Twitter [21, 23, 32, 35, 45], such as its use
in the workplace or during major disaster events.
Twitter is a social networking service, so our work is also related
to recent studies on social networks, such as Flickr, LiveJournal,
Facebook, MySpace, and YouTube [6, 7, 27]. In [27], with over 11
million users of Flickr, YouTube, LiveJournal, and Orkut, Mislove
et al. analyzed link structure and uncovered the evidence of power-
law, small-world, and scale-free properties. In [7], Cha et al. exam-
ined the propagation of information through the social network of
Flickr. Their work shows that most pictures are propagated through
the social links (i.e., links received from friends rather than through
searches or external links to Flickr content) and the propagation is
very slow at each hop. As a result of this slow propagation, a pic-
ture’s popularity is often localized in one network and grows slowly
over a period of months or even years. In [6], Cha et al. analyzed
video popularity life-cycles, content aliasing, and the amount of il-
legal content on YouTube, a popular video sharing service. While
YouTube is designed to share large content, i.e., videos, Twitter is
designed to share small content, i.e., text messages. Unlike other
social networking services, like Facebook or YouTube, Twitter is a
micro-content social network, with messages being limited to 140
characters.
As Twitter is a text-based message system, it is natural to com-
pare it with other text-based message systems, such as instant mes-
saging or chat services. Twitter has similar message length (140
characters) to instant messaging and chat services. However, Twit-
ter lacks “presence” (users show up as online/ofﬂine for instant
messaging services or in speciﬁc rooms for chat) but offers (1)
more access methods (web, SMS, and various APIs) for reading
or posting and (2) more persistent content. Similar to Twitter, in-
stant messaging and chat services also have problems with bots and
spam [14,40]. To detect bots in online chat, Gianvecchio et al. [14]
analyzed humans and bots in Yahoo! chat and developed a clas-
siﬁcation system to detect bots using entropy-based and machine-
learning-based classiﬁers, both of which are used in our classiﬁ-
cation system as well. In addition, as Twitter is text-based, email
spam ﬁltering techniques are also relevant [17, 41, 44]. However,
Twitter posts are much shorter than emails and spaced out over
longer periods of time than for instant messages, e.g., hours rather
than minutes or seconds.
Twitter also differs from most other network services in that au-
tomation, e.g., message feeds, is a major feature of legitimate Twit-
ter usage, blurring the lines between bot and human. Twitter users
can be grouped into four categories: humans, bots, bot-assisted hu-
mans, and human-assisted bots. The latter two, bot-assisted hu-
mans and human-assisted bots, can be described as cyborgs, a mix
between bots and humans [42].
3. MEASUREMENT
In this section, we ﬁrst describe the data collection of over 500,000
Twitter users. Then, we detail our observation of user behaviors and
account properties, which are pivotal to automatic classiﬁcation.
3.1 Data Collection
Here we present the methodology used to crawl the Twitter net-
work and collect detailed user information. Twitter has released
a set of API functions [39] that support user information collec-
tion. Thanks to Twitter’s courtesy of including our test account to
its white list, we can make API calls up to 20,000 per hour. This
eases our data collection. To diversify our data sampling, we em-
ploy two methods to collect the dataset covering more than 500,000
users. The ﬁrst method is Depth-First Search (DFS) based crawl-
ing. The reason we choose DFS is that it is a fast and uniformed
algorithm for traversing a network. Besides, DFS traversal implic-
itly includes the information about network locality and clustering.
Inspired by [15, 18], we randomly select ﬁve users as seeds. For
F
D
C
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
 0
Bot
Human
Cyborg
 0
 5000
 10000
 15000
 20000
Tweet Count
Figure 1: CDF of Tweet Count
each reached user, we record its follower list. Taking the follow-
ing direction, the crawler continues with the depth constraint set
as three. We customize our crawler with a core module of PHP
cURL. Ten crawler processes work simultaneously for each seed.
After a seed is ﬁnished, they move to the next. The crawl duration
lasts four weeks from October 20th to November 21st, 2009, and
429,423 users are logged.
Similar to the work in [25] and [43], we also use the public time-
line API to collect the information of active users, increasing the
diversity of the user pool. Twitter constantly posts the twenty most
recent tweets in the global scope. The crawler calls the timeline
API to collect the authors of the tweets included in the timeline.
Since the Twitter timeline frequently updates, the crawler can re-
peatedly call the timeline API. During the same time window of
the DFS crawl, this method contributes 82,984 users to the dataset.
We totally collect 512,407 users on Twitter combining both meth-
ods.
3.2 Ground Truth Creation
To develop an automatic classiﬁcation system, we need a training
data set that contains known samples of human, bot, and cyborg.
Among collected data, we randomly choose different samples and
classify them by manually checking their user logs and homepages.
The training set includes one thousand users per class of human,
bot and cyborg, and thus in total there are three thousand classi-
ﬁed samples. A test set of three thousand samples is created in a
similar way. Both sets serve as the ground truth dataset, containing
8,350,095 tweets posted by the sampled users in their account life-
time4, from which we can extract useful features for classiﬁcation,
such as tweeting behaviors and text patterns.
Our log-based classiﬁcation follows the principle of the Turing