ing type in our dataset (after keywords), with 8,792 distinct
targeted values. A majority of these values (4,126) were as-
sociated with a single participant (e.g., one participant was
targeted as a follower look-alike of @FDAOncology while
26 users were targeted as follower lookalikes of @Speaker-
Pelosi). However, a few well-known handles were frequently
the focus of lookalikes: @netﬂix (used in targeting 5,199 ads),
@espn (3,608), and @nytimes (3,440).
Behavior targeting, one speciﬁc targeting type oﬀered by
Twitter within the full range of psychographic targeting types,
is based on inferences drawn from proprietary algorithms. Our
most commonly observed instances were related to income or
lifestyles (e.g., “US - Household income: $30,000 - $39,999,”
“US - Executive/C-suite,” “US - Presence in household: yes ,”
“US - Fit moms”). Some were surprisingly speciﬁc: “Home in-
surance expiration month: 10 October,” “US - Likely to switch
cell phone providers,” “Country Club Climbers - Suburban
Empty Nesters: K59,” and “US - Animal charity donors.”
Finally, Twitter oﬀers four retargeting types, based on pre-
vious user engagement with ads. There were 15,814 uses
(1,812 unique instances) of retargeting campaign targeting,
which targets users who responded to an advertiser’s prior
campaign. The ambiguous naming of these instances (“Retar-
geting campaign engager: ########”) makes them hard to
interpret in detail. Retargeting user engager, used 707 times,
is similarly vague. Retargeting custom audience lookalike
targeting, which combines retargeting with Twitter’s looka-
like algorithms, was very rarely used in our data.
4.3.3 Advertiser Targeting Types
The ﬁnal category of targeting types use advertiser-provided
information. Instead of providing any targeting data, Twitter
only facilitates matching to Twitter users via Twitter user-
names, email addresses, or other identiﬁers. Notably, adver-
USENIX Association
29th USENIX Security Symposium    153
tiser targeting types are also the most covert from a user’s
perspective: while Twitter-provided data could potentially
be deduced from the standard user interface (e.g., interests
based on likes or Retweets), targeting types using advertiser-
provided data are completely unrelated to Twitter activity.
Tailored audience (lists) match Twitter users to lists up-
loaded by advertisers. We found 113,952 instances of list
targeting across 2,338 unique lists; companies using list
targeting the most were Anker (22,426 instances), Post-
mates (11,986), Rockstar Games (8,494), and Twitter Sur-
veys (3,131). Tailored lists often used words like ‘Negative’,
‘Holdout’, and ‘Blacklist’, which we hypothesize reference
consumers who previously opted out of receiving targeted
ads or content via other mediums. Advertisers may also use
list targeting for targeting oﬄine purchasers, as list names
included the words ‘Purchase’ and ‘Buyers.’ Many lists use
naming schemes that make it diﬃcult or impossible to dis-
cern the contents of the lists (e.g. “#####_#_########”,
“###_MM_YY_*******_#####”).
We identiﬁed several
lists with names that sug-
gest
targeting on attributes prohibited by Twit-
ter’s policies (see Table 2), including ﬁnancial status
(“YYYY account status: balance due”), race (“***_Nis-
san_AfricanAmericans_YYYYMM”), religion (“Christian
Audience to Exclude”), or sex life (“LGBT Suppression
List”) [66]. Tailored audience (web) also consists of
advertiser-collected lists of website visitors, e.g., “Started
New Credit Card Application” or “Registered but not
Activated User on Cloud.” This targeting type therefore
connects users’ potentially sensitive browsing activity to their
Twitter accounts in ways that may violate Twitter’s health
advertising policies [64].
Tailored audience CRM lookalike targeting combines
advertiser lists with the lookalike algorithm to ﬁnd Twit-
ter users who may be similar to known current or poten-
tial customers. We observed this mechanism being used
in incredibly speciﬁc ways, such as to ﬁnd users similar
to “QSR Ice Cream Frozen Yogurt Frequent Spender” or
“Frozen_Snacks_Not_Frozen_Yogurt_Or_Ice_Cream
_Used_in_last_6_months_Principal_Shoppers_Primary
_Fla_Vor_Ice_###,” both used by advertiser Dairy Queen.
Twitter also oﬀers targeting types that enable cross-
platform tracking. Mobile audience targets Twitter users who
also use an advertiser-owned mobile app (i.e., “people who
have taken a speciﬁc action in your app, such as installs or
sign-ups” [68]). Instances reﬂect the user’s status with the
app, app name, and mobile platform, e.g., “Install Gemini:
Buy Bitcoin Instantly ANDROID All” and “Install Lumen -
Over 50 Dating IOS All”. Mobile audience lookalike target-
ing, which combines the prior mechanism with the lookalike
algorithm, was rarely used. Flexible audience targeting al-
lows advertisers to combine tailored audiences (lists, web, or
mobile) using AND, OR, and NOT operations. We observed
seven ads using this type, all from one advertiser.
Policy
Advertiser(s)
Targeting Value
Keywords
ostomy
unemployment
Gay
mexican american
#AfricanAmerican
#native
hispanics
latinas
mexican
-Racist
Conversation Topics
Liberal Democrats (UK)
ConvaTec Stoma UK
Health
Financial Giant Eagle Jobs
Sex Life
Race
H&M United Kingdom
Just Mercy, Doctor Sleep,
The Kitchen Movie
sephora
sephora
sephora
sephora
sephora
xbox
Race
Race
Race
Race
Race
Religion
Politics
Channel 5, Irina von
Wiese MEP
Race
Big Lots
Big Lots
Financial Anker
Religion
Sex Life
Race
Tailored Audience (List)
YYYY account status: balance due
(translated from Mandarin Chinese)
segment_Control | Rising Hispanics | Email
Openers_########
segment_Control | Rising Hispanics |
Race
Non-Opener_########
∗∗∗_Nissan_AfricanAmericans_YYYYMM Race
Christian Audience to Exclude
LGBT Suppression List
ASL Marketing > Hispanic Millennials -
##########
Tailored Audience (Web)
Website Retargeting - Tagrisso.com (a site
about lung cancer therapy)
Table 2: Examples of targeted ads that could be seen as vi-
olating Twitter’s keyword targeting policy (see Appendix F,
Figure 7 [1]) or Twitter’s privacy policy: “. . . our ads policies
prohibit advertisers from targeting ads based on categories
that we consider sensitive or are prohibited by law, such as
race, religion, politics, sex life, or health” [69].
Nissan
nycHealthy
nycHealthy
Verizon
Health
Test Lung Cancer
Finally, for the curiously-named targeting type unknown,
25 participants were associated with a single instance (“Un-
known: ####"), all related to the advertiser “Twitter Surveys."
4.4 Participant Reactions to Targeting Types
One key beneﬁt of our study design is that we could ask par-
ticipants questions about advertising criteria actually used
in ads they saw. Participants answered questions about up
to four randomly selected targeting types, ﬁltered by those
present in their uploaded data. Advertisers used certain target-
ing types more often than others, meaning diﬀerent numbers
of participants saw each type (see Appendix G, Table 4 [1]).
4.4.1 Fairness, Comfort, Desirability, and Accuracy
Participants perceived language, age, and interest target-
ing to be the most fair, with 86.3%, 72.0%, and 69.0% agree-
ing respectively (Figure 4). Overall, few participants thought
any given targeting type was unfair to use: no type had more
than 50% of participants disagree that its use would be fair
(Figure 4, General: Fair). Tailored audience (list), which was
perceived as least fair overall, was still roughly evenly split
154    29th USENIX Security Symposium
USENIX Association
Figure 4: Participants’ level of agreement to questions about targeting types in general and speciﬁc instances.
between participants agreeing and disagreeing. Compared to
the regression baseline (interest), participants were signiﬁ-
cantly more likely to ﬁnd language targeting fair (OR = 4.48,
p < 0.001). Retargeting campaign, age, and platform target-
ing were not statistically diﬀerent from interest (α = 0.05).
Participants found all other targeting types signiﬁcantly less
fair than interest (OR = 0.0607− 0.401, all p < 0.05).
To dig deeper into perceptions of fairness, we asked par-
ticipants to elaborate on their Likert-scale answers in a free-
response question, gathering a total of 898 responses. Partic-
ipants had varying conceptions of the meaning of fairness.
Some equated fairness with utility, some equated fairness
with comfort, and some equated fairness with accuracy of
the information. Across all targeting types, the most common
rationale used to judge fairness were that targeting is useful
to the user in some way (24.8%). For instance, participants
mentioned that they preferred to see relevant rather than ran-
dom ads if they had to see ads at all, and that advertising
allows them to access Twitter for free. 14.6% said that tar-
geting was fair because the advertiser beneﬁted in some way,
namely by increased eﬀectiveness of advertising. These two
rationales centered on deriving beneﬁts, either for advertisers
or users, but failed to consider the privacy or data autonomy
of the participant. Others considered that Twitter is a public
platform. “Twitter is pretty much a public arena, if I were
shouting about various topics in a town square, people would
infer my interests from that, and potentially attempt to proﬁt
from them” (P191). Participants’ rationales seemed to as-
sume that personalized targeting types like these must be used
for advertising. Only a few suggested proﬁting oﬀ of users’
private information was fundamentally unfair.
Perceptions of comfort largely aligned with percep-
tions of fairness, with small exceptions. For example, par-
ticipants rated gender and keyword targeting as more fair
than location targeting, but were curiously more comfortable
with location than gender and keyword (Figure 4, General:
Comfortable). Some participants’ comments suggested dis-
comfort may relate to whether participants understood how
data about them was obtained. P184 commented, “I’m not
sure how they would know my income level. Disturbing.”
We were also curious about participants’ desire for ad-
vertising that used each targeting type and found general
aﬃrmation, with some strong opposition to speciﬁc in-
stances. We told participants to assume the number of ads
they would see would stay the same and asked them to con-
sider how much they would want to see ads targeted with a
given type, for both a speciﬁc instance of that type and for
type generally. As an example, 53.8% of participants who
saw an instance of event targeting disagreed that it described
them accurately and 65.0% disagreed that they would want to
see advertising based on that speciﬁc example. However, only
25.0% disagreed that they would want to see ads utilizing
event targeting in general.
In the general case, participants were signiﬁcantly more
likely to want ads that used language targeting than the
regression-baseline interest (OR = 3.3, p = 0.004). All other
targeting types were signiﬁcantly less wanted than interest
(OR = 0.1− 0.4, all p < 0.05).
Participants found speciﬁc instances of some demo-
graphic targeting types to be very accurate, but other psy-
chographic types to be very inaccurate. More than half of
participants strongly agreed that a speciﬁc instances of lan-
guage, age, platform, gender, location targeting was accurate
for them, while more than half strongly disagreed that re-
targeting, tailored web, and mobile targeting was accurate
(Figure 4, Speciﬁc: Accurate). Participants were more likely
to agree that speciﬁc instances of platform, language, gender,
and age targeting described them accurately compared to a
speciﬁc instance of interest (OR = 2.9− 9.7, all p < 0.01).
Speciﬁc instances of movies and TV shows, location, and be-
havior targeting were not signiﬁcantly diﬀerent from interest
in agreed accuracy (α = 0.05), while all remaining signiﬁ-
cant targeting types were less likely to be rated as accurate
(OR = 0.1−0.5, all p < 0.05). As we found in their initial free-
USENIX Association
29th USENIX Security Symposium    155
Tailored listsMobileTailored webBehaviorEventLookalikesRetargetingMovie/TVLocationGenderKeywordConversationPlatformInterestAgeLanguage0%25%50%75%100%General: Fair0%25%50%75%100%General: Comfortable0%25%50%75%100%General: Want0%25%50%75%100%Specific: Want0%25%50%75%100%Specific: AccurateStronglyagreeAgreeNeitherDisagreeStronglydisagreeResponse
General: Fair
General: Comfortable
General: Want
Speciﬁc: Comfortable
Speciﬁc: Want
ρ
0.332
0.366
0.341
0.614
0.732
p
<.001
<.001
<.001
<.001
<.001
Table 3: Spearman’s ρ correlation between participants’ agree-
ment with Speciﬁc: Accurate (“Speciﬁc instance describes
me accurately”) and their other Likert-scale responses.
response reactions to uses of a particular targeting type in their
data, if participants perceived an instance of targeting to be
accurate, it was generally well-received. Participants seemed
to enjoy seeing information being accurately reﬂected about
themselves, as P189 described about conversation targeting:
“I am okay with this. It’s cool how accurate it is.”
As shown in Table 3, the accuracy of a speciﬁc instance
of a targeting type was signiﬁcantly correlated with all of
our other measurements of participants’ perceptions. That
is, when participants disagreed that a speciﬁc instance of
a targeting type described them accurately, they were also
signiﬁcantly less likely to be comfortable with that instance
being used (ρ = 0.614, p < 0.001) and to want to see more ads
based on that instance (ρ = 0.732, p < 0.001). We found simi-
lar correlations for perceptions of the use of a targeting type
generally. It is possible that inaccuracy leads to perceptions
of discomfort and unwantedness; it is also possible that when
people see ads they ﬁnd undesirable, they are less likely to
believe the associated targeting is accurate.
Even if a majority of people are comfortable with certain
targeting in the abstract, it is important to understand, and
potentially design for, those who feel less comfortable. To
explore this, we looked for participants who consistently dis-
agreed with questions about fairness, comfort, and desirability.