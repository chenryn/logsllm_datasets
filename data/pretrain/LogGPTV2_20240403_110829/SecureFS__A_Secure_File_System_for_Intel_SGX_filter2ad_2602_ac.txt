Page Fault based Attack. As far as the in-memory filesystem
is concerned, enclave memory space is pre-allocated to store
data from various files that need to be accessed. Depending
on the underlying development environment, it is possible that
the location of this memory region might be randomized (i.e.,
using ASLR [41]) Even in scenarios where it is randomized,
the host OS still can deduce the location of the memory buffer
because the location is always fixed after initializing an enclave
and the attacker would be able to leverage the repeated memory
access patterns at runtime.
5
(a) In-memory FS
(b) OBLIVIATE
Fig. 4: Page fault traces observed through the Linux SGX driver for both an in-memory FS and OBLIVIATE. As expected, the in-memory FS
exhibits the same page faults across runs whereas OBLIVIATE shows a data independent access pattern accross runs which is indistinguishable.
OBLIVIATE offers protection on two fronts here: (1) it protects the confidentiality by normalizing the query to a pre-set parameter agreed on by
the application by adding dummy ORAM accesses and (2) it protects the offset that is accessed by the application.
Figure 4-(a) shows the access pattern observed in case of
an in-memory filesystem. The first two page fault(s) for each
query (labeled as (a,b) and (d,e)) are observed since the
database first reads the metadata from the database file. Thus,
the attacker knows that (a) and (d) indicate the starting of the
in-memory file buffer. Using this starting point as a reference,
the next page faults (labeled as (b), (c), (e), (f) and (g))
show the offset within the file that was accessed. Based on
the size of each row and position of metadata in the database,
the attacker can find out which row was accessed. Also, the
attacker can tell which column (i.e., the column with heart
disease or without heart disease) was accessed. In the first
query, shown by (a,b,c), the victim attempted to reference the
fourth row and first column, i.e., heart disease. In the next run,
in the next run, shown by (d,e,f,g), the victim attempted to
access the fifth row and second column, i.e., no heart disease.
Therefore, using page faults, the attacker can tell (a) whether
the same query was run or another query was run, (b) which
row in the table was accessed and (c) which column within the
row was accessed. It is also worth mentioning that the attacker
can find out about the size of a column and row (provided they
are greater than 4KB) using page fault based attack.
Cache Based Attacks. In the case of the in-memory filesystem,
the enclave application is also susceptible to cache based side-
channel attacks. For example, consider the Last-Level Cache
(LLC), which is a unified cache that holds both code and data
from the running applications. The data from the in-memory
file will also be cached in the LLC and will be accessed from
within the LLC. Once the application tries to access the same
rows, an attacker monitoring the cache can trace the cache-
sets that were disturbed using the Prime+Probe attack. Since
subsequent accesses will affect the same cache-sets, he/she can
build similar inferences as for the page fault based attack and
compromise the security of the application.
V. THREAT MODEL
This paper assumes that a target application is running
within an SGX enclave. We further assume that high-privileged
system components, including the kernel, hypervisor, and
BIOS, have been compromised or are adversarial. During the
execution, the target enclave application accesses file resources
located in the storage medium (i.e., Hard Disk Drive, Solid
State Drive, USB, etc.) with the help of privileged system
Fig. 5: A design overview of OBLIVIATE.
components, as the enclave itself does not have privilege to
access such resources. In this setting, an adversarial component
attempts to infer which data in a file has been accessed by
the enclave application through launching side-channel attacks,
namely syscall snooping attack, page fault based attacks, and/or
cache attacks. This paper does not consider other types of
sophisticated side-channel attacks, such as power monitoring
attacks, electromagnetic attacks, and hardware bus snooping
based side-channels, as most of these require direct physical
accesses to the underlying SGX machine and/or are costly to
launch.
VI. DESIGN
Now we present the design of OBLIVIATE, a data oblivious
filesystem for Intel SGX. The key idea behind OBLIVIATE is to
employ ORAM-based access protocols in order to ensure that
6
TimeMemory Address(a)(b)(c)query1run 1run 2TimeMemory Address(d)(e)(f)(g)query2TimeMemory Addressquery1TimeMemory Addressquery2ApplicationEnclaveApplicationTrusted ProxyFS Calls (§VII-C)Non-EnclaveUntrusted ProxyMessage Queue (§VII-A)EnclaveTrusted ServiceObliviateNon-EnclaveUntrusted ServiceEncryptedORAM Server (§VII-B)Asynchronous ORAMUpdate(§VII-B)FS MetadataEncrypted Connection(§VII-A)filef4T1T2f3f2Data Block (filled)Data Block (dummy)Position MapStashORAM Block (filled)File Descriptoropen()read(), write()ORAMClient (§VII-B)filesystem-related operations performed by an SGX application
remain confidential.
Design Overview. OBLIVIATE is a library filesystem, which
runs within a separate SGX enclave, alongside the application
enclave. More specifically, a filesystem enclave runs in the
other process, while the application enclave relays all filesystem
related operations to the isolated filesystem enclave through
encrypted inter-process communication channels. While we
made this design decision to minimize TCB, OBLIVIATE can
be easily extended to support in-enclave filesystem (i.e., running
the filesystem service and the target application in the same
enclave) if needed.
Following this design principle, the overall design sketch of
OBLIVIATE is depicted in Figure 5. OBLIVIATE is consisted
of four components: the trusted and untrusted service, and the
trusted and untrusted proxy Trusted service is running within
an enclave, which performs key oblivious filesystem operations
of OBLIVIATE; Untrusted service is running outside an enclave,
which delegates syscall invoking operations for trusted service.
These two services run in the same process, sharing the virtual
address space for non-EPC memory regions. Moreover, Trusted
proxy is a library linked together to an enclave application,
which forwards all filesystem related system calls to the trusted
service. Untrusted proxy is similar to untrusted service—it runs
outside an enclave and delegates system calls for trusted proxy.
Looking at the design of OBLIVIATE from the perspective
of its key component, the trusted service, it serves three
major operational roles and each role is described in following
subsections: (1) Connecting an enclave application with the
library to receive filesystem operation requests (i.e., open, read,
write, etc.) (§VI-A); (2) Orchestrating ORAM client and server
to hide access patterns onto files (§VI-B); and (3) Managing a
file descriptor and other metadata to keep the compatibility of
filesystem operations (§VI-C).
A. Communication Channel for Filesystem Service
OBLIVIATE establishes a secure communication channel
between an enclave application and OBLIVIATE’s trusted
service in order to transmit data for filesystem services. The
dataflow of this communication starts from the trusted proxy,
flowing through the untrusted proxy and untrusted service
and finally reaching trusted service (or vice-versa). Since this
communication involves untrusted components, OBLIVIATE
performs end-to-end encryption to assure confidentiality of
interactions. Before starting an enclave application, trusted
proxy contacts trusted service to perform the initial handshaking,
allowing them to share a secret key for the communication.
Then all the following communication is encrypted using this
secret key. OBLIVIATE uses a Diffie-Hellman [36] secret key
exchange scheme, which is also used in Intel’s Linux SGX
SDK [5]. To prevent potential side-channel attacks on the
communication layer, OBLIVIATE normalizes features related
to data messages [18], i.e., all messages have a fixed size
with fixed time gaps between the transmission. In addition, the
application developer can predefine some parameters to ensure
that each query to the trusted service accesses the ORAM
server storage a fixed number of time or can oblige the trusted
service to perform dummy ORAM accesses in order to mislead
the attacker.
In this communication channel, there are two main types
of communication: (1) communication between trusted and un-
trusted components (i.e., intra-process communication between
enclave and non-enclave); and (2) communication between un-
trusted proxy and untrusted service (i.e., inter-process commu-
nication). First, to facilitate an efficient communication between
trusted and untrusted components, OBLIVIATE employs exitless
message queues similar to [7, 32]. A naive solution, that is also
practiced by Intel SGX SDK, would be to rely on ocalls, but it
would result in a context switch, incurring costly latency due to
TLB flushes and LLC pollution [32]. To this end, OBLIVIATE
implements exitless message queues that are established
using non-EPC memory region shared between the trusted
and untrusted components of both the application enclave and
the filesystem enclave. Both components run its own separate
thread, which keeps polling the status of the message queue.
In §VIII-B, we quantify the performance improvement achieved
through an exitless design over a naive design.
In addition, OBLIVIATE creates a communication channel
between untrusted proxy and untrusted service. The untrusted
service initializes a shared memory region which is acquired
by the application enclave, i.e., untrusted proxy upon initial-
ization. This shared memory is essentially a combination of
two lock-free single-producer, single-consumer queues. After
initialization, the untrusted service simply polls the request
queue and waits for a request. As the untrusted proxy obtains
a message from the trusted proxy, it simply enqueues the
message into the request queue. The untrusted service receives
the message from the request queue and passes it along to
the trusted service. When a response is made available by
the trusted service, the same path is followed in the reverse
direction but now using the response queue.
B. Orchestrating ORAM Client and Server
1) ORAM Client: The client storage in ORAM comprises
of two data structures, a position map and stash. ORAM
assumes that these data structures are always stored within a
trusted memory region, because the security critical mapping
information is stored in the position map and the decrypted
blocks are stored in the stash. Toward this end, OBLIVIATE
stores the position map and stash within an enclave, leveraging
its confidentiality guarantee (shown in Figure 5).
Position Map. The position map in ORAM helps to locate real
blocks in an ORAM tree. It contains mapping information from
each real block to the corresponding tree path as determined by
the leaf node. Since the position map only holds the mapping
information, it requires a fairly small amount of space. To
be more precise, if N is the height of the tree, we require
2(N−1) × log(N ) bytes of memory to hold the position map.
Stash. The stash is another security critical data structure
stored in the ORAM client. Recall that the stash stores all
the blocks that OBLIVIATE reads from a specific tree path
in the ORAM. Unlike the position map, which is simply a
mapping array, the stash is a large memory region which holds
multiple blocks filled with both real and dummy data extracted
from the oram tree. To be more precise, after each access, the
stash is filled with at least B × log(N ) × D bytes of memory
where B corresponds to blocks-per-node, N denotes the height
of the tree, and D denotes the data size of a single block in
7
bytes. OBLIVIATE employs a fixed size stash configured during
initialization.
Securely Accessing Position Map and Stash. While the
security guarantee of an SGX enclave ensures that a potential
adversary cannot directly access the position map and stash, the
adversary can still launch side-channel attacks. Therefore, the
adversary can observe access patterns onto these data structures,
thereby inferring the hidden ORAM structures and breaking
the ORAM’s security model. For example, using the page
fault side-channel attack, the adversarial kernel can learn page
granularity (i.e., 4 KB) access patterns onto position map or
stash regions. On the other hand, the cache attack can allow
the attacker to gain cache-line (i.e., 64B) granularity onto these
regions. This is especially harmful for the position map, as the
attacker can know which index (upto 64B granularity) in the
position map was accessed and consequently leak information
about the corresponding block which was accessed.
To mitigate these risks, OBLIVIATE employs data oblivious
algorithms [34] to access the position map and stash. In a
data-oblivious algorithm, instead of accessing a specific data
entity, an algorithmic operation accesses all relevant data
entities (i.e., all corresponding memory pages and cache lines
from OBLIVIATE’s perspective). As a result, the adversary
learns nothing about the operational semantics onto these data
structures, since it cannot pinpoint which data entity is linked
to a certain algorithmic operation. OBLIVIATE leverages the
conditional move instruction (i.e., cmov) in the x86 architecture
as a security primitive of data obliviousness. cmov uses a flag to
distinguish between actual and dummy writes while ensuring
the attacker observes the same access patterns as a regular mov
instruction. Hence, both the position map and the stash are
completely accessed irrespective of the position of the required
index in the position map or the required block within the
stash.
In the case of the position map, OBLIVIATE ensures
that each cache-line (and consequently memory page) that
corresponds to memory regions within the position maps
are accessed ensuring complete privacy of access (illustrated
in Figure 6). Also, OBLIVIATE has to maintain multiple position
maps (in the case of multiple files) and uses the same technique
to ensure that these accesses are secure. Similar to the position
map, OBLIVIATE reads all candidate data blocks in the stash.
If the stash is unprotected, the attacker can find out which
block is real from within the path that was extracted, and
consequently break the security of ORAM. For example, as
illustrated in Figure 7 for the stash, the condition flag is set true
only if OBLIVIATE copies the corresponding real block, and
the flag is set false otherwise. From the attacker’s perspective,
each block or index was accessed and therefore, he/she cannot
correlate the current access to a specific block. As a result, the
ORAM protocol operates as if it was running in a completely
isolated environment without any sort of memory leakages.
2) ORAM Server: The ORAM server stores the ORAM
tree, which is updated by the ORAM client. In the following,
we first describe the data structure of the ORAM server. Then
we describe where the ORAM server is located and how it
is accessed by the ORAM client. Lastly, we introduce an
optimization technique, asynchronous ORAM server updates,
which leverages a semantic gap between ORAM protocols and
filesystem operations.
Fig. 6: Data oblivious algorithms in accessing position map. A solid
line denotes using cmov() instruction with a true flag (i.e., actually
copy the data). A dashed line denotes using it with a false flag (i.e.,
only impose access patterns but no copy).
Fig. 7: Data oblivious algorithms in accessing stash.
ORAM Server Structure. As a filesystem, OBLIVIATE has to
provide access to multiple files for an enclave application and
it is therefore important that OBLIVIATE not only prevents the
attacker from obtaining knowledge about the accessed offset
within an individual file but also restricts the attacker from
knowing which file was accessed. This is a common scenario,
e.g., consider simple webservers such as Apache [1], Nginx [35]
etc. which cater to multiple security-sensitive files. A webserver
running within an SGX enclave should not leak information
about what file was just accessed by the client. To provide this
security, OBLIVIATE uses a simple hierarchical oram structure
to load various files into its protective sphere during enclave
initialization.
The hierarchical ORAM structure is a two-tiered ORAM
tree. OBLIVIATE lays out all files to be used for an application
into the first tier of the hierarchical tree structure. For instance,
T1 in Figure 5 depicts the first tier of OBLIVIATE’s tree
structure, where T1 contains four different files from f1 to
f4. Each filled node in T1 corresponds to a file, and an
empty node represents dummy blocks in ORAM. Moreover,
OBLIVIATE maintains a filename table, which maps a filename
to a file-block in T1. As we will describe more on open
syscall handling in §VI-C, OBLIVIATE employs data oblivious