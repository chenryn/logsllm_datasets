### Coverage Recording and Crash Analysis

Fuzzilli records coverage differently from the method used in this thesis experiment. In the thesis, only stable coverage was counted, resulting in a lower overall coverage statistic. All crashes listed in Table 2 were due to generated recursive functions, which caused range errors because the recursion depth exceeded the limit. These crashes are not considered security-related bugs.

### Corpus Files from Public Sources

The following public sources were utilized for corpus generation:

- **Regression tests from JavaScript engines:**
  - ChakraCore: [GitHub](https://github.com/microsoft/ChakraCore/tree/master/test)
  - SpiderMonkey: [Mercurial](https://hg.mozilla.org/mozilla-central/file/tip/js/src/)
  - V8: [GitHub](https://github.com/v8/v8/tree/master/test)
  - WebKit: [GitHub](https://github.com/WebKit/webkit/tree/master/JSTests) (includes the test262 test suite: [GitHub](https://github.com/tc39/test262))

- **Mozilla Developer JavaScript page:** [MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference)

- **Mozilla Developer interactive JavaScript examples page:** [GitHub](https://github.com/mdn/interactive-examples/tree/master/live-examples/js-examples)

- **JS-Vuln-DB:** [GitHub](https://github.com/tunz/js-vuln-db)

- **Sputniktests:** [GitHub](https://github.com/kangax/sputniktests-webrunner/tree/master/src/tests)

- **W3 Resources and exercises:**
  - [W3 Resource](https://www.w3resource.com/javascript/javascript.php)
  - [W3 Exercises](https://www.w3resource.com/javascript-exercises)

- **JavaScript code collections from eight different GitHub sources**

In total, 609,864 JavaScript code snippets were downloaded from these sources using a web crawler. After removing duplicates, the number of unique samples was reduced to 105,892. To ensure efficient fuzzing, only test cases smaller than 200 KB and with a maximum runtime of 800 milliseconds were considered. Code samples that import code from other files were ignored due to implementation-specific limitations.

### Test Case Preprocessing

To prepare the test cases for fuzzing, the following operations were applied:

- **Removal of comments.**
- **Adding newlines before and after brace symbols** to allow the fuzzer to insert code at all possible locations.
- **Removal of empty lines.**
- **Renaming variables, functions, and classes** to follow the fuzzer's naming convention, ensuring the fuzzer is aware of all available tokens.

The initial processing of the 105,892 code samples resulted in 674 timeouts, 9 crashes, and 3,985 successful executions, triggering 124,619 out of 596,937 possible edges, or 20.88% coverage. The 9 crashes were v8 test cases that triggered new, unfixed bugs. Several test cases resulted in exceptions due to missing references to specific engine functionality. These test cases were reprocessed with the problematic function calls removed.

### Function Call Modifications

The following modifications were made to all test cases:

- **Replaced calls to 70 different functions** with other function calls:
  - `writeLine` patched to `console.log`
  - `WScript.SetTimeout` patched to `setTimeout`
  - `assertUnreachable()` patched to an empty line
  - `assertStmt` patched to `eval`
  - `optimizeNextInvocation` patched to `%OptimizeFunctionOnNextCall`
  - `platformSupportsSamplingProfiler()` patched to `true`

- **Removed import or load statements** at the start of test cases, as importing other files is not supported.

- **Removed calls to 78 different functions:**
  - Examples: `WScript.Attach()`, `assert.fail()`, `description()`, `assertUnoptimized()`, `verifyProperty()`, `generateBinaryTests()`, `assertThrowsInstanceOf()`, `testFailed()`, `assert_throws()`, `assert.throws()`, `shouldThrow()`, `assertThrowsValue()`, `enableGeckoProfiling()`, `assertThrownErrorContains()`

- **Rewrote calls to 27 function calls** to comparisons:
  - Examples: `assert.sameValue` patched to `a == b`, `reportCompare` patched to `a == b`, `assert.strictEqual` patched to `a === b`, `assertEq` patched to `a == b`, `verifyEqualTo` patched to `a == b`

- **Replaced calls to 23 assert functions** with their arguments:
  - Examples: `assert.isTrue`, `assert.isFalse`, `assert.assertFalse`, `assertFalse`, `assert_true`, `%TurbofanStaticAssert`, `assert.shouldBeTrue`, `assertNotNull`

Additionally, function calls that easily lead to crashes, such as `quit()` and v8-specific functions like `%ProfileCreateSnapshotDataBlob`, `%LiveEditPatchScript`, `%IsWasmCode`, etc., were removed.

### Data Augmentation

To increase coverage, a data augmentation technique was applied. Test cases were wrapped inside a function, and JIT compilation was forced by invoking the following methods on the function:

- `%PrepareFunctionForOptimization()`
- `%OptimizeFunctionOnNextCall()`

This resulted in the processing of 164,530 unique test cases. By interpreting the code, 8,990 unique test cases were identified, achieving 24.01% coverage in v8. Including the test cases with enforced JIT compilation increased the total coverage to 24.82%, triggering 148,155 out of 596,937 possible edges.

### Comparison with Park et al.

Park et al. published a similar experiment, but they used fewer sources, including only regression tests from JavaScript engines (ChakraCore, JavaScriptCore, v8, and SpiderMonkey) and JS-Vuln-DB. They implemented wrapper functions instead of removing engine-specific functions, which simplified parsing but increased test case size, reducing fuzzer performance. Their corpus contained 14,708 unique JavaScript files, but the exact coverage was not reported. Unlike this thesis, Park et al. included test cases that result in exceptions, and it is unclear which JavaScript engine they used.

### Self-Created Corpus

A Python script was developed to generate JavaScript code samples deterministically. Using edge coverage feedback, samples with new behavior were detected and saved in a separate corpus. The script generated various code constructs, but only achieved 10.83% coverage in v8. Combining the self-created corpus with the browser regression and unit tests increased the coverage to 25.06%, corresponding to 149,570 triggered edges. The final corpus contained 9,162 unique test cases.

### Deterministic Preprocessing Phase 1

The deterministic preprocessing phase, modeled after AFLâ€™s deterministic fuzzing phase, involves adding code lines at all possible locations in each test case to identify similar code samples that trigger edge cases. Examples of inserted code lines include:

- `gc();` to trigger garbage collection.
- `gc();gc();` to move data into the old space memory region.
- `%OptimizeFunctionOnNextCall()` to optimize a function.
- `%DeoptimizeNow();` to deoptimize a function.
- `Array(2**30);` to test large array allocations.
- `try { } finally { }` to test exception handling.
- `this.__proto__ = 0;` to test prototype manipulation.
- `parseInt();` to test parsing integers.

These code lines were inserted in every possible line, as function arguments, and as assignments in loops and conditionals.

By combining these techniques, the coverage and effectiveness of the fuzzing process were significantly improved.