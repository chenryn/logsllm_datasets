fuzzilli records coverage differently than implemented in this thesis experiment. In this thesis 
only stable coverage was counted which results in a lower coverage statistic. 
All found crashes from Table 2 were due to generated recursive functions which resulted in 
a range error because the recursion depth was too deep. The found crashes are therefore 
not considered to be security related bugs. 
Corpus files from public sources: 
The following public sources were further used for corpus generation: 
• 
Regression tests from JavaScript engines 
o ChakraCore 208 
o SpiderMonkey 209 
o V8 210 
o Webkit 211 (already contains the test262 test suite 212) 
• 
Mozilla Developer JavaScript page 213 
208 https://github.com/microsoft/ChakraCore/tree/master/test 
209 https://hg.mozilla.org/mozilla-central/file/tip/js/src/ 
210 https://github.com/v8/v8/tree/master/test 
211 https://github.com/WebKit/webkit/tree/master/JSTests 
212 https://github.com/tc39/test262 
213 https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference 
 113 
• 
Mozilla Developer interactive JavaScript examples page 214 
• 
JS-Vuln-DB 215 
• 
Sputniktests 216 
• 
W3 Resources 217 and exercises 218 
• 
JavaScript code collections from eight different GitHub sources 
In total, 609,864 JavaScript code snippets were downloaded from the mentioned sources 
with a developed web crawler. Since some sources use similar test cases, the total number 
of unique samples can be reduced to 105,892. By extracting edge coverage, samples with 
unique behavior can be identified. For the experiment only test cases smaller than 200 KB 
were considered because big input files slow down fuzzing. Moreover, a maximum runtime 
of 800 milliseconds was configured. Code samples, which import code from other files, were 
ignored since the filenames were changed during corpus generation, which is currently an 
implementation specific limitation. 
Moreover, the following operations were applied on the test cases to prepare them for 
fuzzing: 
• 
Removal of comments. 
• 
Adding newlines before and after brace symbols. This is important because in a later 
phase the fuzzer adds code between two code lines and adding newlines is therefore 
important to ensure that the fuzzer can insert code at all possible locations. 
• 
Removal of empty lines. 
• 
Renaming all variables, functions and classes to follow the naming convention from 
the fuzzer. This is important to ensure that the fuzzer is aware of all available tokens. 
The initial processing of the 105,892 code samples resulted in 674 timeouts, 9 crashes and 
3,985 successful executions which triggered unique behavior. These inputs triggered 
together 124,619 of 596,937 possible edges which means they utilized a coverage of 20.88 
percent. The 9 crashes were v8 test cases which trigger new bugs which were not fixed yet. 
Several test cases resulted in an exception because of missing references to functionality 
used by test suites or which were specific to an engine. The test cases were therefore 
processed again and references to these functions were removed before execution. 
214 https://github.com/mdn/interactive-examples/tree/master/live-examples/js-examples 
215 https://github.com/tunz/js-vuln-db 
216 https://github.com/kangax/sputniktests-webrunner/tree/master/src/tests 
217 https://www.w3resource.com/javascript/javascript.php 
218 https://www.w3resource.com/javascript-exercises 
 114 
The following modifications were performed on all test cases: 
• 
Calls to 70 different functions were replaced by other function calls 
o Examples: 
▪ 
writeLine was patched to console.log 
▪ 
WScript.SetTimeout was patched to setTimeout 
▪ 
assertUnreachable() was patched to an empty line 
▪ 
assertStmt was patched to eval 
▪ 
optimizeNextInvocation was patched to 
%OptimizeFunctionOnNextCall 
▪ 
platformSupportsSamplingProfiler() was patched to true 
• 
Import or load statements at the start of test cases were removed. This is required 
because importing other files is currently not supported. 
• 
Calls to 78 different functions were removed. 
o Examples: 
▪ 
WScript.Attach() 
▪ 
assert.fail() 
▪ 
description() 
▪ 
assertUnoptimized() 
▪ 
verifyProperty() 
▪ 
generateBinaryTests() 
▪ 
assertThrowsInstanceOf() 
▪ 
testFailed() 
▪ 
assert_throws() 
▪ 
assert.throws() 
▪ 
shouldThrow() 
▪ 
assertThrowsValue() 
▪ 
enableGeckoProfiling() 
▪ 
assertThrownErrorContains() 
• 
Calls to 27 function calls were rewritten to a comparison. 
o Examples: 
▪ 
assert.sameValue was patched to a == comparison 
▪ 
reportCompare was patched to a == comparison 
▪ 
assert.strictEqual was patched to a === comparison 
▪ 
assertEq was patched to a == comparison 
▪ 
verifyEqualTo was patched to a == comparison 
• 
Calls to 23 assert functions were replaced by the argument passed to the function. 
o Examples: 
▪ 
assert.isTrue 
▪ 
assert.isFalse 
▪ 
assert.assertFalse 
▪ 
assertFalse 
 115 
▪ 
assert_true 
▪ 
%TurbofanStaticAssert 
▪ 
assert.shouldBeTrue 
▪ 
assertNotNull 
Moreover, some function calls were removed because they easily lead to a state which is 
observed as a crash by the fuzzer. This includes calls to quit() as well as v8 specific functions 
such as: 
• 
%ProfileCreateSnapshotDataBlob 
• 
%LiveEditPatchScript 
• 
%IsWasmCode 
• 
%IsAsmWasmCode 
• 
%ConstructConsString 
• 
%HaveSameMap 
• 
%IsJSReceiver 
• 
%HasSmiElements 
• 
%HasObjectElements 
• 
%HasDoubleElements 
• 
%HasDictionaryElements 
• 
%HasHoleyElements 
• 
%HasSloppyArgumentsElements 
• 
%HaveSameMap 
• 
%HasFastProperties 
• 
%HasPackedElements 
These function calls can easily result in a crash, for example, during test case minimization 
because code lines are removed which changes the logic of the code. 
To further increase the coverage a data augmentation technique was applied. In addition to 
the normal execution of all test cases, the test cases were also wrapped inside a function 
and JIT compilation was forced by invocation of the following two methods on the function: 
• 
%PrepareFunctionForOptimization() 
• 
%OptimizeFunctionOnNextCall() 
This resulted in the processing of 164,530 unique test cases from the mentioned sources. 
By just interpreting the code, 8,990 unique test cases were identified based on coverage 
feedback. These samples triggered a coverage of 24.01 percent in v8. By including the test 
cases were JIT compilation was enforced, the total coverage was increased to 148,155 
triggered edges of 596,937 possible edges which corresponds to a 24.82 percent coverage. 
Applying the above-mentioned modifications is a non-trivial task because it requires the 
correct parsing of JavaScript code in several edge cases including test cases which use 
 116 
Unicode. It also requires the correct parsing of strings, template strings, escaped symbols, 
regex strings and object structures. 
Park et al. published [10] a similar experiment before this thesis was finished. At the time of 
publication of the work of Park et al., the above-mentioned corpus was already created. Park 
et al. used similar but fewer sources to create a corpus. Only regression tests from 
JavaScript engines (ChakraCore, JavaScriptCore, v8 and SpiderMonkey) were used 
together with JS-Vuln-DB. Park et al. used a different technique to handle engine specific 
functions. Instead of patching the test cases by removing the functions, wrapper functions 
were implemented and added to the code. The advantage of this technique is that complex 
JavaScript parsing is not required, however, the disadvantage is that test cases become 
bigger which decreases fuzzer performance. Park et al. reported that their input corpus 
contained 14,708 unique JavaScript files, however, the exact coverage was not mentioned. 
Moreover, Park included test cases to the corpus, which result in an exception. It is also not 
obvious which JavaScript engine was used to create the corpus. Comparing the number of 
files in the corpus is therefore not meaningful. 
In this thesis test cases which trigger an exception are not included in the corpus. This design 
decision was made to reduce the number of exceptions which occur during fuzzing which 
significantly increases the fuzzer speed. 
Self-created corpus: 
A Python script was developed which deterministically generates JavaScript code samples 
by using a brute-force like approach. Using the edge coverage feedback, samples with new 
behavior could be detected and saved in a separated corpus. The script first extracts all 
available global variables, instantiates possible objects and then iterates through all methods 
and calls them with different arguments. State modifying operations like the re-assignment 
of properties are also performed on these objects. The script generates different code 
constructs using loops, if-conditions, functions, generators, classes, labels, exception 
handling, keywords and so on. Moreover, mathematical calculations are created in a variety 
of possible combinations. Although a lot of time was spent on developing and implementing 
edge cases, only a coverage of 10.83 percent of code in v8 was achieved. This clearly 
indicates that test cases from browsers are a better initial source because they already 
achieve more than twice of this coverage. Time should therefore not be spent on creating 
initial test cases. Instead, regression and unit tests from browsers can just be used. 
However, by combining the self-created corpus with the corpus created from the browser 
regression and unit tests, the coverage could be increased from 24.82 percent to 25.06 
percent which corresponds to 149,570 triggered edges of 596,937 possible edges. This final 
corpus contained 9,162 unique test cases. 
 117 
Deterministic preprocessing phase 1: 
The deterministic preprocessing can be viewed as another data augmentation technique. It 
was modeled based on AFL’s deterministic fuzzing phase. Every time a new test case is 
added to the corpus, the preprocessing is performed on the test case to identify similar code 
samples which trigger edge cases. To achieve this, code lines are added at all possible 
locations in the test case. Examples of inserted code lines are: 
• 
gc(); 
o This triggers garbage collection at every possible location. 
• 
gc();gc(); 
o Triggering garbage collection twice can be important because it moves data 
into the old space memory region. Further details are mentioned in chapter 
4.2.2 in the Chromium bug 789393 description. 
• 
%OptimizeFunctionOnNextCall() 
o This function call leads to the optimization of a function. If the test case is just 
interpreted, this mutation ensures that the code from the compiler gets also 
tested. 
• 
%DeoptimizeNow(); 
o This function call leads to the deoptimization of a function at the defined 
location. It tests the correct deoptimization in different scenarios.  
• 
Array(2**30); 
o Details to this code can be found in chapter 4.5.1 in the CVE-2019-5825 
vulnerability analysis. 
• 
try { } finally { } 
o Details to this code can be found in chapter 4.5.1 in the CVE-2017-5070 
vulnerability analysis. 
• 
this.__proto__ = 0; 
o Details to this code can be found in chapter 4.2.3 in the Chromium issue 
992914 vulnerability analysis. 
• 
parseInt(); 
o Details to this code can be found in chapters 4.5.1 and 4.5.2 in the CVE-2016-
5198 and CVE-2017-2547 vulnerability analysis. 
These code lines are not only inserted in every possible line, but also as function arguments 
and as assignments in for-loops or if-condition statements. The code lines are also passed 