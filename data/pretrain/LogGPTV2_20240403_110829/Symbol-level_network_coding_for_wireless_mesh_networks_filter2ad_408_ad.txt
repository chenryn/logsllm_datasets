original correct data. If not, it simply waits to receive more coded
symbols until it can decode. The code guarantees that if m erro-
neous symbols incorrectly classiﬁed as clean seeped through, then
the destination can decode as soon as it receives B + 2m coded
symbols.
• MIXIT’s rateless code provides ﬂexible reliability semantics. Since
the code works on groups of B symbols, there is no fate sharing
across groups. Its likely that when the destination receives a few
packets, it will be able to decode most of the groups of B symbols,
but not some since they had more errors. Depending on the appli-
cation, the destination could wait to receive more coded symbols
until it can decode, or ignore the undecoded symbols and ask the
source to proceed to the next batch by sending a batch-ack to the
source.
10
Implementation
10.1 Packet Format
9 Error Correction
Until now we have ignored the difference between clean and correct
symbols and focused on delivering clean symbols to the destination.
But clean symbols can be incorrect. Moreover, an erroneous symbol
that was incorrectly classiﬁed clean may end up corrupting other
correct clean symbols due to network coding. Thus, the destination,
could get all symbols corrupted due to a single clean but erroneous
symbol. Fortunately, MIXIT comes with error correction capability
MIXIT inserts a variable length header in each packet, as shown in
Fig. 9. The header is also repeated as a trailer at the end of the packet
to improve delivery in the face of collisions [8]. The header contains
the source and destination addresses, the ﬂow identiﬁer, and the the
batch identiﬁer. These ﬁelds are followed by a variable length Code
Vector Block, which describes how the symbols in this packet have
been created. It has the format (Code Vector, Run Start, Run End);
the values of these ﬁelds are obtained using the algorithm in §6.2.
Following that is the variable length Forwarder Block that lists all
Experiment
MIXIT in a lightly loaded network
Impact of concurrency
Impact of symbol level diversity
Impact of mistake rate threshold
Section Result
11.2.1
11.2.2
11.2.2
11.2.3
Impact of batch size
MIXIT in a congested network
Impact of forwarding algorithm
11.2.4
11.3.1
11.3.2
MIXIT improves median throughput by 2.1× over MORE and 2.9× over SPR
MIXIT exploits loose packet delivery constraints to increase concurrency.
MIXIT with plain carrier sense still outperforms MORE by 1.5×.
MIXIT’s error correcting code allows us to be ﬂexible with the mistake rate. This reduces
the fraction of correct symbols incorrectly labeled dirty and increases throughput.
MIXIT is insensitive to batch size, providing large gains for sizes as small as 8.
MIXIT improves median throughput by 2.8× over MORE and 3.9× over SPR.
MIXIT’s congestion-aware forwarding prevents hotspots and keeps network capacity
from dropping during congestion.
Table 1: A summary of the major experimental contributions of this paper.
SRC_IP
DST_IP
FLOW_ID
BATCH_NO
NUM_RUNS
START
END
CODE VECTOR
CODE VECTOR
BLOCK
when it has decoded the required fraction (determined by the applica-
tion’s reliability requirements) of original symbols. The batch-ack is
sent periodically until packets from the next batch start arriving.
NUM_FORWARDERS
FORWARDER ID FRD_CREDIT
FORWARDER 
BLOCK
11 Evaluation
MAC HEADER
MIXIT HEADER
Encoded Data
MIXIT TRAILER
MAC TRAILER
Figure 9: MIXIT’s packet format.
the neighbors of this node ordered according to their C-ETS metrics.
For each neighbor, the header also contains its credit assignment as
described in §7. The Code Vector Block and the Forwarder Block
are computed and updated by the forwarders. The other ﬁelds are
initialized by the source and simply copied by each forwarder.
10.2 Node State
Each MIXIT node maintains per-ﬂow state, which is initialized when
the ﬁrst packet from a ﬂow that contains the node ID in the Neighbor
Block arrives . The per-ﬂow state includes:
• The batch buffer, which stores the received clean symbols for each
batch. This buffer is at most K × S, where K is the batch size and S
the packet size.
• The credit counter, which stores the number of credits assigned to
the node by the upstream neighbors for the batch. Upon the arrival
of a packet from a node with a higher C-ETS, the node increments
the credit by the corresponding credit assignment as indicated in
the packet header.
• The transmit counter, which is incremented by the credit assign-
ment algorithm in §7. After a packet transmission, it decrements
by one.
10.3 Control Flow
MIXIT’s control ﬂow responds to packet receptions. On the receiv-
ing side, whenever a packet arrives, the node checks whether it’s
ID is present in the Forwarder Block. If it is, then it updates the
credit counter for the corresponding batch of that ﬂow by the credit
assigned to it in the Forwarder Block. Next, the node picks out clean
symbols from the received packet using the SoftPHY hints and adds
them to the batch buffer. If the credit is greater than one, it runs the
credit assignment algorithm from §7. It then creates transmit counter
coded packets using the technique in §6.2 and enqueues them. The
MAC layer transmits these packets using the rule discussed in §8.1.
When the destination node receives a packet, it checks the symbol
positions for which it has received at least B coded symbols and
decodes whichever of them it can. It sends a batch-ack to the source
We compare MIXIT with two routing protocols for wireless mesh
networks: MORE, a state-of-the-art packet-level opportunistic routing
protocol, and SPR, single path routing using the commonly used ETX
metric. Our experimental results are summarized in Table 1.
11.1 Testbed
We use a 25-node indoor testbed deployed in a lab. Each node is a
Zigbee software radio. The hardware portion of the node is a Univer-
sal Software Radio Peripheral [6] with a 2.4 GHz daughterboard, the
remainder of the node’s functions (demodulation, channel decoding,
network coding etc) are implemented in software. The peak data rate
on the link is 250 Kbits/s when there are no other transmissions in
progress. Paths between nodes are between one and ﬁve hops long,
and the SNR of the links varies from 5 dB to 30 dB. The average
packet loss rate on links in our network is 23% for 1500 byte packets.
11.2 Single Flow
11.2.1 Throughput Comparison
Method: We run SPR, MORE, and MIXIT in sequence between 120
randomly picked source-destination pairs in our testbed. Each run
transfers a 5 MByte ﬁle. The batch size of MIXIT is 12, but the
error-correction preprocessing stage described in §9 converts it into
16 packets. To make a fair comparison, MORE uses a batch of 16
packets. We use the same batch sizes for MIXIT and MORE for all
other experiments unless speciﬁcally noted otherwise. The packet
size for all three protocols is 1500B. The mistake rate γ for MIXIT is
ﬁxed at 5% and the symbol size for MIXIT is 6 bytes unless otherwise
noted. Before running an experiment, we collect measurements to
compute pairwise packet delivery probabilities, which are then fed to
SPR and MORE to be used in their route computations. The same
measurement packets are used by MIXIT to compute the network’s
SNR proﬁle as described in §8. We repeat the experiment for each
source-destination pair ﬁve times and report the average throughput
for each scheme.
Results: Fig. 10 plots the CDF of the throughput taken over 120
source-destination pairs in our testbed. MIXIT provides a median
throughput gain of 2.1× over MORE and 2.9× over SPR.
We note that MIXIT improves performance across the entire
throughput range. Packet-based opportunistic routing protocols, like
MORE, provide large throughput gains for dead spots, i.e., scenar-
ios where all paths between the source and destination are of poor
quality. The gains for high quality paths were relatively minor [1, 2].
Both MORE and ExOR exploit diversity at the packet level to build
better quality links out of many bad links. But for source-destination
pairs that are connected via good links, diversity does not help. Nat-
urally, this makes one wonder whether MIXIT’s gains over packet
based opportunistic routing protocols arise from its ability to exploit
concurrency, a question that we address in the next section.
ability to exploit clean symbols, i.e., is symbol-level diversity the
dominant contributor to MIXIT’s overall throughput gain?
Method: To answer the above question, we prevent MIXIT from
aggressively exploiting concurrent transmissions and use plain carrier
sense. The intent is to limit its gains over MORE to be from being
able to perform opportunistic routing over clean symbols. We call the
resulting version MIXIT-CS.
s
w
o
F
l
i
f
o
n
o
i
t
u
b
i
r
t
s
D
e
v
i
t
a
u
m
u
C
l
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
MIXIT
MORE
SPR
 20
 40
 60
 80
 100
Flow Throughput (Kbits/s)
s
w
o
F
l
i
f
o
n
o
i
t
u
b
i
r
t
s
D
e
v
i
t
a
u
m
u
C
l
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
MIXIT
MIXIT-CS
MORE
 20
 40
 60
 80
 100
Flow Throughput (Kbits/s)
Figure 10: Throughput comparison: The ﬁgure shows that MIXIT
has a median throughput gain of 2.1× over MORE, the state-of-the-art
packet level opportunistic routing protocol, and 2.9× over SPR, a single
path routing protocol based on the ETX metric.
11.2.2 Where do MIXIT’s Throughput Gains Come From?
MIXIT exploits both wireless diversity and concurrent transmissions.
We would like to measure how much each of these components
contributes to MIXIT’s throughput gains.
Method: We ﬁrst compare MIXIT with a modiﬁed version of
MORE that takes advantage of concurrency at the packet level, which
we call MORE-C. Like MORE, MORE-C performs packet based
opportunistic routing. But MORE-C also allows nodes to transmit
concurrently. To check whether two transmissions should be transmit-
ted concurrently, MORE-C uses the same algorithm used by MIXIT
and described in §8, but after it replaces symbol delivery probabilities
with packet delivery probabilities.
s
w
o
F
l
f
o
n
o
i
t
i
u
b
i
r
t
s
D
e
v
i
t
l
a
u
m
u
C
 1
 0.8
 0.6
 0.4
 0.2
 0
 0
MIXIT
MORE-C
MORE
 20
 40
 60
 80
 100
Flow Throughput (Kbits/s)
Figure 11: Impact of concurrency: The ﬁgure shows the throughput
of MIXIT, MORE, and a concurrency-enabled version of MORE which
we term MORE-C. Clearly concurrency helps but it is not sufﬁcient to
achieve the same throughput as MIXIT.
Results: Fig. 11 plots the CDF of the throughputs of MIXIT,
MORE, and MORE-C taken over the same source-destination pairs
as before. MIXIT provides a median throughput gain of 1.7× over
MORE-C. The main result is that even when compared against a
protocol that exploits both diversity and concurrency like MORE-C,
MIXIT still does signiﬁcantly better. The only extra property that
MIXIT has beyond MORE-C is its ability to work at the symbol level.
Is the median gain of 1.7× over MORE-C due mainly to MIXIT’s
Figure 12: Throughputs for MIXIT with CS: The ﬁgure shows the
throughput of MIXIT, MORE, and MIXIT-CS, a version of MIXIT
which uses plain carrier sense and can only take advantage of symbol-
level diversity. MIXIT-CS still performs better than MORE due to its
ability to exploit long opportunistic receptions but with a few errors in
them.
Results: Fig. 12 plots the CDF of the throughputs of MIXIT,
MIXIT-CS and MORE. MIXIT-CS provides a median through-
put gain of 1.5× over MORE, i.e., signiﬁcantly less gain than
MIXIT. Thus, symbol-level diversity is not the dominant contrib-
utor to MIXIT’s throughput gains. Indeed, comparing Fig. 12 with
Fig. 11 shows that the overall gain of MIXIT over MORE is roughly
Gain of MIXIT-CS over MORE×Gain of MORE-C over MORE, i.e.
1.5 × 1.4 = 2.1. The multiplicative effect is due to the symbiotic inter-
action between concurrency and symbol-level opportunistic routing;
concurrency tries to run the medium at high utilization and hence
increases symbol error rate. But when the symbol error rate becomes
high, almost every packet will have some symbols in error causing
the whole packet to be dropped. Consequently, trying to exploit con-
currency with a packet level protocol is limited by nature. Only a
protocol that ﬁlters out incorrect symbols can push concurrency to its
limits.
11.2.3
Impact of Letting More Errors Through
MIXIT
MORE
SPR
)
s
/
s
t
i
b
K
(
t
u
p
h
g
u
o
r
h
T
.
g
v
A