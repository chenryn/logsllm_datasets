### Correct Data and Decoding Process

If the received data is not correct, the system simply waits to receive additional coded symbols until it can successfully decode. The code ensures that if \( m \) erroneous symbols, incorrectly classified as clean, pass through, the destination can decode as soon as it receives \( B + 2m \) coded symbols.

### MIXIT’s Rateless Code and Reliability Semantics

MIXIT’s rateless code provides flexible reliability semantics. Since the code operates on groups of \( B \) symbols, there is no fate sharing across groups. It is likely that when the destination receives a few packets, it will be able to decode most of the groups of \( B \) symbols, but not all, due to higher error rates in some groups. Depending on the application, the destination can either wait to receive more coded symbols until it can decode or ignore the undecoded symbols and request the source to proceed to the next batch by sending a batch-ack to the source.

### Implementation

#### Packet Format

Until now, we have ignored the distinction between clean and correct symbols, focusing on delivering clean symbols to the destination. However, clean symbols can still be incorrect. An erroneous symbol, incorrectly classified as clean, may corrupt other correct clean symbols due to network coding. Thus, the destination could end up with all symbols corrupted due to a single clean but erroneous symbol. Fortunately, MIXIT includes error correction capabilities.

MIXIT inserts a variable-length header in each packet, as shown in Figure 9. The header is also repeated as a trailer at the end of the packet to improve delivery in the face of collisions. The header contains the source and destination addresses, the flow identifier, and the batch identifier. These fields are followed by a variable-length Code Vector Block, which describes how the symbols in this packet were created. The format of the Code Vector Block is (Code Vector, Run Start, Run End), with the values of these fields obtained using the algorithm in §6.2. Following that is the variable-length Forwarder Block, which lists all forwarders and their credits.

#### Node State

Each MIXIT node maintains per-flow state, which is initialized when the first packet from a flow containing the node ID in the Neighbor Block arrives. The per-flow state includes:

- **Batch Buffer**: Stores the received clean symbols for each batch. This buffer is at most \( K \times S \), where \( K \) is the batch size and \( S \) is the packet size.
- **Credit Counter**: Stores the number of credits assigned to the node by upstream neighbors for the batch. Upon receiving a packet from a node with a higher C-ETS, the node increments the credit by the corresponding credit assignment indicated in the packet header.
- **Transmit Counter**: Incremented by the credit assignment algorithm in §7 and decremented by one after a packet transmission.

#### Control Flow

MIXIT’s control flow responds to packet receptions. When a packet arrives, the node checks whether its ID is present in the Forwarder Block. If it is, the node updates the credit counter for the corresponding batch of that flow by the credit assigned in the Forwarder Block. Next, the node extracts clean symbols from the received packet using SoftPHY hints and adds them to the batch buffer. If the credit is greater than one, it runs the credit assignment algorithm from §7. It then creates transmit counter-coded packets using the technique in §6.2 and enqueues them. The MAC layer transmits these packets using the rule discussed in §8.1.

When the destination node receives a packet, it checks the symbol positions for which it has received at least \( B \) coded symbols and decodes whichever of them it can. It sends a batch-ack to the source when it has decoded the required fraction (determined by the application’s reliability requirements) of original symbols. The batch-ack is sent periodically until packets from the next batch start arriving.

### Evaluation

#### Testbed

We use a 24-node indoor testbed deployed in a lab. Each node is a Zigbee software radio. The hardware portion of the node is a Universal Software Radio Peripheral [6] with a 2.4 GHz daughterboard, and the remainder of the node’s functions (demodulation, channel decoding, network coding, etc.) are implemented in software. The peak data rate on the link is 250 Kbits/s when there are no other transmissions in progress. Paths between nodes range from one to five hops, and the SNR of the links varies from 5 dB to 30 dB. The average packet loss rate on links in our network is 23% for 1500 byte packets.

#### Single Flow

##### Throughput Comparison

**Method**: We run SPR, MORE, and MIXIT in sequence between 120 randomly picked source-destination pairs in our testbed. Each run transfers a 5 MByte file. The batch size of MIXIT is 12, but the error-correction preprocessing stage described in §9 converts it into 16 packets. To make a fair comparison, MORE uses a batch of 16 packets. We use the same batch sizes for MIXIT and MORE for all other experiments unless specifically noted otherwise. The packet size for all three protocols is 1500B. The mistake rate \( \gamma \) for MIXIT is fixed at 5%, and the symbol size for MIXIT is 6 bytes unless otherwise noted. Before running an experiment, we collect measurements to compute pairwise packet delivery probabilities, which are then fed to SPR and MORE for route computations. The same measurement packets are used by MIXIT to compute the network’s SNR profile as described in §8. We repeat the experiment for each source-destination pair five times and report the average throughput for each scheme.

**Results**: Figure 10 plots the CDF of the throughput taken over 120 source-destination pairs in our testbed. MIXIT provides a median throughput gain of 2.1× over MORE and 2.9× over SPR. MIXIT improves performance across the entire throughput range. Packet-based opportunistic routing protocols, like MORE, provide large throughput gains for dead spots, i.e., scenarios where all paths between the source and destination are of poor quality. The gains for high-quality paths were relatively minor [1, 2]. Both MORE and ExOR exploit diversity at the packet level to build better quality links out of many bad links. For source-destination pairs connected via good links, diversity does not help. This raises the question of whether MIXIT’s gains over packet-based opportunistic routing protocols arise from its ability to exploit concurrency, which we address in the next section.

##### Impact of Concurrency

**Method**: To measure the impact of concurrency, we compare MIXIT with a modified version of MORE that takes advantage of concurrency at the packet level, which we call MORE-C. Like MORE, MORE-C performs packet-based opportunistic routing but also allows nodes to transmit concurrently. To check whether two transmissions should be transmitted concurrently, MORE-C uses the same algorithm used by MIXIT, described in §8, but replaces symbol delivery probabilities with packet delivery probabilities.

**Results**: Figure 11 plots the CDF of the throughputs of MIXIT, MORE, and MORE-C taken over the same source-destination pairs as before. MIXIT provides a median throughput gain of 1.7× over MORE-C. Even when compared against a protocol that exploits both diversity and concurrency like MORE-C, MIXIT still performs significantly better. The only extra property that MIXIT has beyond MORE-C is its ability to work at the symbol level.

##### Impact of Symbol-Level Diversity

**Method**: To determine the impact of symbol-level diversity, we prevent MIXIT from aggressively exploiting concurrent transmissions and use plain carrier sense. The intent is to limit its gains over MORE to being able to perform opportunistic routing over clean symbols. We call the resulting version MIXIT-CS.

**Results**: Figure 12 plots the CDF of the throughputs of MIXIT, MIXIT-CS, and MORE. MIXIT-CS provides a median throughput gain of 1.5× over MORE, significantly less gain than MIXIT. Thus, symbol-level diversity is not the dominant contributor to MIXIT’s throughput gains. Comparing Figure 12 with Figure 11 shows that the overall gain of MIXIT over MORE is roughly the product of the gain of MIXIT-CS over MORE and the gain of MORE-C over MORE, i.e., 1.5 × 1.4 = 2.1. The multiplicative effect is due to the symbiotic interaction between concurrency and symbol-level opportunistic routing; concurrency tries to run the medium at high utilization, increasing the symbol error rate. But when the symbol error rate becomes high, almost every packet will have some symbols in error, causing the whole packet to be dropped. Consequently, trying to exploit concurrency with a packet-level protocol is limited by nature. Only a protocol that filters out incorrect symbols can push concurrency to its limits.

##### Impact of Letting More Errors Through

**Method**: To measure the impact of letting more errors through, we vary the mistake rate threshold and observe the throughput.

**Results**: Figure 13 plots the CDF of the throughputs of MIXIT, MORE, and SPR under different mistake rate thresholds. MIXIT’s error-correcting code allows us to be flexible with the mistake rate, reducing the fraction of correct symbols incorrectly labeled dirty and increasing throughput.

### Summary of Experimental Contributions

Table 1 summarizes the major experimental contributions of this paper, including the improvements in median throughput, the exploitation of loose packet delivery constraints to increase concurrency, and the robustness of MIXIT in congested networks.