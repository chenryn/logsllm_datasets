### References

[34] Intel, "Speculative Execution Side Channel Mitigations," January 2018. [Online]. Available: https://software.intel.com/sites/default/files/managed/c5/63/336996-Speculative-Execution-Side-Channel-Mitigations.pdf

[35] Intel, "Intel 64 and IA-32 Architectures Optimization Reference Manual," June 2016.

[38] G. Irazoqui Apecechea, T. Eisenbarth, and B. Sunar, "S$A: A Shared Cache Attack That Works across Cores and Defies VM Sandboxing - and Its Application to AES," in S&P, 2015.

[39] Y. Kim, R. Daly, J. Kim, C. Fallin, J. H. Lee, D. Lee, C. Wilkerson, K. Lai, and O. Mutlu, "Flipping bits in memory without accessing them: An experimental study of DRAM disturbance errors," in ISCA, 2014.

[40] P. Kocher, "Spectre Mitigations in Microsoft's C/C++ Compiler," [Online]. Available: https://www.paulkocher.com/doc/MicrosoftCompilerSpectreMitigation.html, 2018.

[41] P. Kocher, J. Jaffe, and B. Jun, "Differential Power Analysis," in CRYPTO, 1999.

[36] Intel, "Intel Analysis of Speculative Execution Side Channels," January 2018. [Online]. Available: https://newsroom.intel.com/wp-content/uploads/sites/11/2018/01/Intel-Analysis-of-Speculative-Execution-Side-Channels.pdf

[37] G. Irazoqui, T. Eisenbarth, and B. Sunar, "Cross-processor cache attacks," in AsiaCCS, 2016.

[42] P. Kocher, J. Jaffe, B. Jun, and P. Rohatgi, "Introduction to differential power analysis," Journal of Cryptographic Engineering, vol. 1, no. 1, pp. 5–27, 2011.

[43] P. C. Kocher, "Timing Attacks on Implementations of Diffie-Hellman, RSA, DSS, and Other Systems," in CRYPTO, 1996.

[44] S. Lee, M. Shih, P. Gera, T. Kim, H. Kim, and M. Peinado, "Inferring Fine-grained Control Flow Inside SGX Enclaves with Branch Shadowing," in USENIX Security Symposium, 2017.

[45] M. Lipp, D. Gruss, R. Spreitzer, C. Maurice, and S. Mangard, "ARMageddon: Cache Attacks on Mobile Devices," in USENIX Security Symposium, 2016.

[46] M. Lipp, D. Gruss, M. Schwarz, D. Bidner, C. Maurice, and S. Mangard, "Practical Keystroke Timing Attacks in Sandboxed JavaScript," in ESORICS (2), 2017.

[47] M. Lipp, M. Schwarz, D. Gruss, T. Prescher, W. Haas, A. Fogh, J. Horn, S. Mangard, P. Kocher, D. Genkin, Y. Yarom, and M. Hamburg, "Meltdown: Reading Kernel Memory from User Space," in USENIX Security Symposium (to appear), 2018.

[48] F. Liu, Y. Yarom, Q. Ge, G. Heiser, and R. B. Lee, "Last-Level Cache Side-Channel Attacks are Practical," in S&P, 2015.

[49] S. McCanne and V. Jacobson, "The BSD Packet Filter: A New Architecture for User-level Packet Capture," in USENIX Winter, 1993.

[50] Microsoft Edge Team, "Mitigating speculative execution side-channel attacks in Microsoft Edge and Internet Explorer," [Online]. Available: https://blogs.windows.com/msedgedev/2018/01/03/speculative-execution-mitigations-microsoft-edge-internet-explorer/

[51] Y. Oren, V. P. Kemerlis, S. Sethumadhavan, and A. D. Keromytis, "The Spy in the Sandbox: Practical Cache Attacks in JavaScript and their Implications," in CCS, 2015.

[52] D. A. Osvik, A. Shamir, and E. Tromer, "Cache Attacks and Countermeasures: The Case of AES," in CT-RSA, 2006.

[53] M. S. Papamarcos and J. H. Patel, "A Low-overhead Coherence Solution for Multiprocessors with Private Cache Memories," in ISCA, 1984.

[54] A. Pardoe, "Spectre Mitigations in MSVC," January 2018. [Online]. Available: https://blogs.msdn.microsoft.com/vcblog/2018/01/15/spectre-mitigations-in-msvc/

[55] C. Percival, "Cache Missing for Fun and Profit," in Proceedings of BSDCan, 2005. [Online]. Available: https://www.daemonology.net/papers/htt.pdf

[56] P. Pessl, D. Gruss, C. Maurice, M. Schwarz, and S. Mangard, "DRAMA: Exploiting DRAM Addressing for Cross-CPU Attacks," in USENIX Security Symposium, 2016.

[57] F. Pizlo, "What Spectre and Meltdown Mean for WebKit," January 2018. [Online]. Available: https://webkit.org/blog/8048/what-spectre-and-meltdown-mean-for-webkit/

[58] J.-J. Quisquater and D. Samyde, "ElectroMagnetic Analysis (EMA): Measures and Counter-Measures for Smart Cards," in E-smart 2001, 2001.

[59] T. Ristenpart, E. Tromer, H. Shacham, and S. Savage, "Hey, you, get off of my cloud: exploring information leakage in third-party compute clouds," in CCS, 2009.

[60] M. Schwarz, C. Maurice, D. Gruss, and S. Mangard, "Fantastic Timers and Where to Find Them: High-Resolution Microarchitectural Attacks in JavaScript," in Financial Cryptography, 2017.

[61] M. Schwarz, S. Weiser, D. Gruss, C. Maurice, and S. Mangard, "Malware Guard Extension: Using SGX to Conceal Cache Attacks," in DIMVA, 2017.

[62] M. Seaborn, "Security: Chrome provides high-resolution timers which allow cache side-channel attacks." [Online]. Available: https://bugs.chromium.org/p/chromium/issues/detail?id=508166

[63] H. Shacham, "The Geometry of Innocent Flesh on the Bone: Return-into-LIBC Without Function Calls (on the x86)," in CCS, 2007.

[64] O. Sibert, P. A. Porras, and R. Lindell, "The Intel 80x86 Processor Architecture: Pitfalls for Secure Systems," in S&P, 1995.

[65] A. Tang, S. Stolfo, and S. Sethumadhavan, "CLKSCREW: Exposing the Perils of Security-Oblivious Energy Management," in USENIX Security Symposium, 2017.

[66] The Chromium Project, "Actions Required to Mitigate Speculative Side-Channel Attack Techniques." [Online]. Available: https://www.chromium.org/Home/chromium-security/ssca

[67] The Chromium Projects, "Site Isolation." [Online]. Available: http://www.chromium.org/Home/chromium-security/site-isolation

[68] M. Thomadakis, "The Architecture of the Nehalem Processor and Nehalem-EP SMP Platforms," Texas A&M University, Technical Report, March 2011.

[69] Y. Tsunoo, T. Saito, T. Suzaki, M. Shigeri, and H. Miyauchi, "Cryptanalysis of DES Implemented on Computers with Cache," in CHES, 2003.

[70] P. Turner, "Retpoline: A Software Construct for Preventing Branch-Target Injection." [Online]. Available: https://support.google.com/faqs/answer/7625886

[71] L. Wagner, "Mitigations Landing for a New Class of Timing Attack," January 2018. [Online]. Available: https://blog.mozilla.org/security/2018/01/03/mitigations-landing-new-class-timing-attack/

[72] F. Wilhelm, "PoC for Breaking Hypervisor ASLR Using Branch Target Buffer Collisions," 2016. [Online]. Available: https://github.com/felixwilhelm/mario-baslr

[73] H. Wong, "Store-to-Load Forwarding and Memory Disambiguation in x86 Processors," 2014. [Online]. Available: http://blog.stuffedcow.net/2014/01/x86-memory-disambiguation/

[74] Y. Yarom and K. Falkner, "Flush+Reload: A High Resolution, Low Noise, L3 Cache Side-Channel Attack," in USENIX Security Symposium, 2014.

[75] Y. Zhang, A. Juels, M. K. Reiter, and T. Ristenpart, "Cross-VM Side Channels and Their Use to Extract Private Keys," in CCS, 2012.

[76] ——, "Cross-Tenant Side-Channel Attacks in PaaS Clouds," in CCS, 2014.

### Appendix A: Reverse-Engineered Intel Haswell Branch Prediction Internals

This section describes reverse-engineered parts of the branch prediction mechanism of an Intel Xeon Haswell E5-1650 v3. The primary mechanism for indirect call prediction relies on a simple rolling hash of partial source and destination addresses, combined with part of the source address of the call instruction whose target should be predicted, as a lookup key. The rolling hash is updated as shown in Listing 4 when a normal branch is taken. The Branch Target Buffer (BTB) used by the primary mechanism stores targets as absolute addresses.

The secondary mechanism for indirect call prediction ("predicted as having a monotonic target") uses the partial source address, with some bits folded together using XOR, as a lookup key. The destination address is stored as a combination of 32 bits containing the absolute lower half and one bit specifying whether the jump crosses a 4 GB boundary.

```c
void bhb_update(uint64_t *bhb_state, unsigned long src, unsigned long dst) {
    *bhb_state >>= 6;
    *bhb_state ^= (src & 0xc00) >> (10 - 2);
    *bhb_state ^= (src & 0xc000) >> (14 - 4);
    *bhb_state ^= (src & 0x30) >> (12 - 10);
    *bhb_state ^= (src & 0x30000) >> (16 - 12);
    *bhb_state ^= (src & 0xc0000) >> (18 - 14);
}
```

### Appendix B: Indirect Branch Poisoning Proof-of-Concept on Windows

As a proof-of-concept for the indirect branch poisoning attack, we developed an attack on a simple program that keeps a secret key. The program first generates a random key, then repeatedly calls `Sleep(0)`, loads the first bytes of a file (e.g., as a header), calls Windows crypto functions to compute the SHA-1 hash of (key || header), and prints the hash whenever the header changes. When this program is compiled with optimization, the call to `Sleep()` is done with file data in registers `ebx` and `edi`. No special effort was taken to cause this; function calls with adversary-chosen values in registers are common, although the specifics (such as what values appear in which registers) are often determined by compiler optimizations and therefore difficult to predict from source code. The test program did not include any memory flushing operations or other adaptations to help the attacker.

The first step was to identify a gadget that, when speculatively executed with adversary-controlled values for `ebx` and `edi`, would reveal attacker-chosen memory from the victim process. This gadget must be in an executable page within the working set of the victim process. Note that on Windows, some pages in DLLs are mapped in the address space but require a soft page fault before becoming part of the working set. We wrote a simple program that saved its own working set pages, which are largely representative of the working set contents common to all applications. We then searched this output for potential gadgets, yielding multiple usable options for `ebx` and `edi` (as well as for other pairs of registers). Of these, we arbitrarily chose the following byte sequence which appears in `ntdll.dll` in both Windows 8 and Windows 10:

```
13 BC 13 BD 13 BE 13 12 17
```

When executed, this corresponds to the following instructions:

```assembly
adc edi, dword ptr [ebx+edx+13BE13BDh]
adc dl, byte ptr [edi]
```

Speculative execution of this gadget with attacker-controlled `ebx` and `edi` allows an adversary to read the victim’s memory. If the adversary chooses `ebx = m − 0x13BE13BD − edx`, where `edx = 3` for the sample program (as determined by running in a debugger), the first instruction reads the 32-bit value from address `m` and adds this onto `edi`. In the victim, the carry flag happens to be clear, so no additional carry is added. Since `edi` is also controlled by the attacker, speculative execution of the second instruction will read (and bring into the cache) the memory whose address is the sum of the 32-bit value loaded from address `m` and the attacker-chosen `edi`. Thus, the attacker can map the 2^32 possible memory values onto smaller regions, which can then be analyzed via Flush+Reload to solve for memory bytes. For example, if the bytes at `m + 2` and `m + 3` are known, the value in `edi` can cancel out their contribution and map the second read to a 1 MB region which can be probed easily via Flush+Reload.

For branch mistraining, we targeted the first instruction of the `Sleep()` function, which is a jump of the form `jmp dword ptr ds:[76AE0078h]` (where both the location of the jump destination and the destination itself change per reboot due to ASLR). We chose this jump instruction because it appeared that the attack process could `clflush` the destination address, although (as noted later) this did not work. In addition, unlike a return instruction, there were no specific constraints on the target address.