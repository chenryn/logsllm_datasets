Corp.,
“Avoiding
False
[Online]. Avail-
https://software.intel.com/en-us/articles/avoiding-
Sharing Among Threads,” 2011.
able:
and-identifying-false-sharing-among-threads
Identifying
and
[34] ——, “Speculative Execution Side Channel Mitigations,”
Jan. 2018. [Online]. Available: https://software.intel.com/
sites/default/ﬁles/managed/c5/63/336996-Speculative-
Execution-Side-Channel-Mitigations.pdf
[35] ——, “Intel 64 and IA-32 Architectures Optimization
Reference Manual,” Jun. 2016.
(cid:18)(cid:21)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:46:03 UTC from IEEE Xplore.  Restrictions apply. 
[38] G. Irazoqui Apecechea, T. Eisenbarth, and B. Sunar,
“S$A: A Shared Cache Attack That Works across Cores
and Deﬁes VM Sandboxing - and Its Application to
AES,” in S&P, 2015.
[39] Y. Kim, R. Daly, J. Kim, C. Fallin, J. H. Lee, D. Lee,
C. Wilkerson, K. Lai, and O. Mutlu, “Flipping bits in
memory without accessing them: An experimental study
of DRAM disturbance errors,” in ISCA, 2014.
[40] P.
Kocher,
“Spectre
crosoft’s
line].
MicrosoftCompilerSpectreMitigation.html
C/C++
Available:
Compiler,”
Mitigations
Mi-
[On-
https://www.paulkocher.com/doc/
2018.
in
[41] P. Kocher, J. Jaffe, and B. Jun, “Differential Power
Analysis,” in CRYPTO, 1999.
[36] ——,
Side
“Intel
Analysis
Speculative
Channels,”
2018.
https://newsroom.intel.com/wp-
Execution
[Online]. Available:
content/uploads/sites/11/2018/01/Intel-Analysis-of-
Speculative-Execution-Side-Channels.pdf
Jan.
of
[37] G. Irazoqui, T. Eisenbarth, and B. Sunar, “Cross proces-
sor cache attacks,” in AsiaCCS, 2016.
[42] P. Kocher, J. Jaffe, B. Jun, and P. Rohatgi, “Introduction
to differential power analysis,” J. Cryptographic Engi-
neering, vol. 1, no. 1, pp. 5–27, 2011.
[43] P. C. Kocher, “Timing Attacks on Implementations of
Difﬁe-Hellman, RSA, DSS, and Other Systems,” in
CRYPTO, 1996.
[44] S. Lee, M. Shih, P. Gera, T. Kim, H. Kim, and
M. Peinado, “Inferring Fine-grained Control Flow Inside
SGX Enclaves with Branch Shadowing,” in USENIX
Security Symposium, 2017.
[45] M. Lipp, D. Gruss, R. Spreitzer, C. Maurice, and S. Man-
gard, “ARMageddon: Cache Attacks on Mobile Devices,”
in USENIX Security Symposium, 2016.
[46] M. Lipp, D. Gruss, M. Schwarz, D. Bidner, C. Maurice,
and S. Mangard, “Practical Keystroke Timing Attacks in
Sandboxed JavaScript,” in ESORICS (2), 2017.
[47] M. Lipp, M. Schwarz, D. Gruss, T. Prescher, W. Haas,
A. Fogh, J. Horn, S. Mangard, P. Kocher, D. Genkin,
Y. Yarom, and M. Hamburg, “Meltdown: Reading Kernel
Memory from User Space,” in USENIX Security Sympo-
sium (to appear), 2018.
[48] F. Liu, Y. Yarom, Q. Ge, G. Heiser, and R. B. Lee,
“Last-Level Cache Side-Channel Attacks are Practical,”
in S&P, 2015.
[49] S. McCanne and V. Jacobson, “The BSD Packet Filter:
A New Architecture for User-level Packet Capture,” in
USENIX Winter, 1993.
Jan. 2018.
[50] Microsoft Edge Team, “Mitigating speculative execution
side-channel attacks in Microsoft Edge and Internet
Explorer,”
[Online]. Available: https://
blogs.windows.com/msedgedev/2018/01/03/speculative-
execution-mitigations-microsoft-edge-internet-explorer/
[51] Y. Oren, V. P. Kemerlis, S. Sethumadhavan, and A. D.
Keromytis, “The Spy in the Sandbox: Practical Cache
Attacks in JavaScript and their Implications,” in CCS,
2015.
[52] D. A. Osvik, A. Shamir, and E. Tromer, “Cache Attacks
and Countermeasures: The Case of AES,” in CT-RSA,
2006.
[53] M. S. Papamarcos and J. H. Patel, “A Low-overhead Co-
herence Solution for Multiprocessors with Private Cache
Memories,” in ISCA, 1984.
[54] A. Pardoe, “Spectre mitigations in MSVC,” Jan. 2018.
[Online]. Available: https://blogs.msdn.microsoft.com/
vcblog/2018/01/15/spectre-mitigations-in-msvc/
[55] C. Percival, “Cache missing for fun and proﬁt,” in
[Online]. Available:
Proceedings of BSDCan, 2005.
https://www.daemonology.net/papers/htt.pdf
[56] P. Pessl, D. Gruss, C. Maurice, M. Schwarz, and
S. Mangard, “DRAMA: Exploiting DRAM Addressing
for Cross-CPU Attacks,” in USENIX Security Sympo-
sium, 2016.
Pizlo,
[57] F.
“What
and Meltdown
2018.
[Online].
https://webkit.org/blog/8048/what-spectre-
Spectre
Jan.
for WebKit,”
mean
Available:
and-meltdown-mean-for-webkit/
[58] J.-J. Quisquater and D. Samyde, “ElectroMagnetic Anal-
ysis (EMA): Measures and Counter-Measures for Smart
Cards,” in E-smart 2001, 2001.
[59] T. Ristenpart, E. Tromer, H. Shacham, and S. Savage,
“Hey, you, get off of my cloud: exploring information
leakage in third-party compute clouds,” in CCS, 2009.
[60] M. Schwarz, C. Maurice, D. Gruss, and S. Mangard,
“Fantastic Timers and Where to Find Them: High-
Resolution Microarchitectural Attacks in JavaScript,” in
Financial Cryptography, 2017.
[61] M. Schwarz, S. Weiser, D. Gruss, C. Maurice, and
S. Mangard, “Malware Guard Extension: Using SGX to
Conceal Cache Attacks,” in DIMVA, 2017.
[62] M. Seaborn,
timers which
“Security: Chrome
allow cache
high-
res
channel
attacks.” [Online]. Available: https://bugs.chromium.org/
p/chromium/issues/detail?id=508166
provides
side
[63] H. Shacham, “The geometry of innocent ﬂesh on the
bone: return-into-libc without function calls (on the
x86),” in CCS, 2007.
[65] A.
[64] O. Sibert, P. A. Porras, and R. Lindell, “The Intel 80x86
processor architecture: pitfalls for secure systems,” in
S&P, 1995.
Tang,
Stolfo,
“CLKSCREW: Exposing
of Security-
Oblivious Energy Management,” in USENIX Security
Symposium, 2017.
and
the Perils
Sethumadhavan,
S.
S.
[66] The Chromium Project, “Actions required to mitigate
Speculative Side-Channel Attack techniques.” [Online].
Available: https://www.chromium.org/Home/chromium-
security/ssca
[67] The Chromium Projects, “Site Isolation.” [Online].
Available: http://www.chromium.org/Home/chromium-
security/site-isolation
(cid:18)(cid:22)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:46:03 UTC from IEEE Xplore.  Restrictions apply. 
[68] M. Thomadakis, “The Architecture of the Nehalem Pro-
cessor and Nehalem-EP SMP Platforms,” Texas A&M
University, Tech. Rep., Mar. 2011.
[69] Y. Tsunoo, T. Saito, T. Suzaki, M. Shigeri, and
H. Miyauchi, “Cryptanalysis of DES Implemented on
Computers with Cache,” in CHES, 2003.
[70] P. Turner, “Retpoline: a software construct for preventing
[Online]. Available: https://
branch-target-injection.”
support.google.com/faqs/answer/7625886
landing
new
class
[Online].
Available: https://blog.mozilla.org/security/2018/01/03/
mitigations-landing-new-class-timing-attack/
“Mitigations
attack,”
[71] L. Wagner,
timing
2018.
Jan.
for
of
[72] F. Wilhelm, “PoC for breaking hypervisor ASLR
using branch target buffer collisions,” 2016. [Online].
Available: https://github.com/felixwilhelm/mario baslr
[73] H. Wong, “Store-to-Load Forwarding and Memory
Disambiguation
[On-
line]. Available: http://blog.stuffedcow.net/2014/01/x86-
memory-disambiguation/
x86 Processors,”
2014.
in
[74] Y. Yarom and K. Falkner, “Flush+Reload: A High Res-
olution, Low Noise, L3 Cache Side-Channel Attack,” in
USENIX Security Symposium, 2014.
[75] Y. Zhang, A. Juels, M. K. Reiter, and T. Ristenpart,
“Cross-VM side channels and their use to extract private
keys,” in CCS, 2012.
[76] ——, “Cross-Tenant Side-Channel Attacks in PaaS
Clouds,” in CCS, 2014.
APPENDIX A
REVERSE-ENGINEERED INTEL HASWELL BRANCH
PREDICTION INTERNALS
This section describes reverse-engineered parts of
the
branch prediction mechanism of an Intel Xeon Haswell E5-
1650 v3. The primary mechanism for indirect call prediction
relies on a simple rolling hash of partial source and destination
addresses, combined with part of the source address of the call
instruction whose target should be predicted, as lookup key.
The rolling hash seems to be updated as shown in Listing 4,
when a normal branch is taken. The Branch Target Buffer used
by the primary mechanism seems to store targets as absolute
addresses.
The secondary mechanism for indirect call prediction (“pre-
dicted as having a monotonic target”) seems to use the partial
source address, with some bits folded together using XOR, as
lookup key. The destination address seems to be stored as a
combination of 32 bits containing the absolute lower half and
one bit specifying whether the jump crosses a 4 GB boundary.
INDIRECT BRANCH POISONING PROOF-OF-CONCEPT ON
APPENDIX B
WINDOWS
As a proof-of-concept for the indirect branch poisoning
attack, we developed an attack on a simple program keeping
a secret key. The simple program ﬁrst generates a random
key, then repeatedly calls Sleep(0), loads the ﬁrst bytes
(cid:18)(cid:23)
unsigned long src,
unsigned long dst) {
1 /* ‘bhb_state‘ points to the branch history
2 * buffer to be updated
3 * ‘src‘ is the virtual address of the last
4 * byte of the source instruction
5 * ‘dst‘ is the virtual destination address
6 */
7 void bhb_update(uint58_t *bhb_state,
8
9
10 *bhb_state > 6;
13 *bhb_state ˆ= (src & 0xc00) >> (10 - 2);
14 *bhb_state ˆ= (src & 0xc000) >> (14 - 4);
15 *bhb_state ˆ= (src & 0x30) > (12 - 10);
18 *bhb_state ˆ= (src & 0x30000) >> (16 - 12);
19 *bhb_state ˆ= (src & 0xc0000) >> (18 - 14);
20 }
Listing 4: Pseudocode for updating the branch history buffer
state when a branch is encountered.
of a ﬁle (e.g., as a header), calls Windows crypto functions
to compute the SHA-1 hash of (key || header), and prints
the hash whenever the header changes. When this program
is compiled with optimization, the call to Sleep() is done
with ﬁle data in registers ebx and edi. No special effort
was taken to cause this; function calls with adversary-chosen
values in registers are common, although the speciﬁcs (such as
what values appear in which registers) are often determined by
compiler optimizations and therefore difﬁcult to predict from
source code. The test program did not include any memory
ﬂushing operations or other adaptations to help the attacker.
The ﬁrst step was to identify a gadget which, when specula-
tively executed with adversary-controlled values for ebx and
edi, would reveal attacker-chosen memory from the victim
process. This gadget must be in an executable page within
the working set of the victim process. Note that on Windows,
some pages in DLLs are mapped in the address space but
require a soft page fault before becoming part of the working
set. We wrote a simple program that saved its own working
set pages, which are largely representative of the working set
contents common to all applications. We then searched this
output for potential gadgets, yielding multiple usable options
for ebx and edi (as well as for other pairs of registers). Of
these, we arbitrarily chose the following byte sequence which
appears in ntdll.dll in both Windows 8 and Windows 10
13 BC 13 BD 13 BE 13
12 17
which, when executed, corresponds to the following instruc-
tions:
adc edi, dword ptr [ebx+edx+13BE13BDh]
adc dl, byte ptr [edi]
Speculative execution of this gadget with attacker-controlled
ebx and edi allows an adversary to read the victim’s mem-
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:46:03 UTC from IEEE Xplore.  Restrictions apply. 
ory. If the adversary chooses ebx = m − 0x13BE13BD −
edx, where edx = 3 for the sample program (as determined
by running in a debugger), the ﬁrst instruction reads the 32-bit
value from address m and adds this onto edi. In the victim,
the carry ﬂag happens to be clear, so no additional carry is
added. Since edi is also controlled by the attacker, speculative
execution of the second instruction will read (and bring into
the cache) the memory whose address is the sum of the
32-bit value loaded from address m and the attacker-chosen
edi. Thus, the attacker can map the 232 possible memory
values onto smaller regions, which can then be analyzed via
Flush+Reload to solve for memory bytes. For example, if the
bytes at m + 2 and m + 3 are known, the value in edi can
cancel out their contribution and map the second read to a
1 MB region which can be probed easily via Flush+Reload.
For branch mistraining we targeted the ﬁrst instruction of
the Sleep() function, which is a jump of the form “jmp
dword ptr ds:[76AE0078h]” (where both the location
of the jump destination and the destination itself change
per reboot due to ASLR). We chose this jump instruction
because it appeared that the attack process could clflush
the destination address, although (as noted later) this did not
work. In addition, unlike a return instruction, there were no