routers with low connectivity in the topology. Thus, one way to
reduce their storage, if necessary, is forwarding entry aggregation
or virtual address mapping. The average is much lower, under 5%
in most cases. Next, we show the FIB memory overhead as routers
are removed one-by-one in the shadow conﬁguration. There is no
case in which the router with the worst FIB overhead has its FIB
storage increased by 35%. The average overhead is much lower
than the worst case.
FIB Update Overhead: Since we also extend the FIB insertion
and deletion routines to handle shadow conﬁguration, we also eval-
uate the performance when the FIB is being frequently updated. We
use the same setup as the prior experiment on FIB data forwarding
processing overhead, but we also randomly add and delete between
1 and 100 routes in the real conﬁguration in 10.0.0.0/8 each second
at the intermediate router as it is forwarding trafﬁc.
Figure 9 shows the results. Again, there is no noticeable differ-
ence between supporting shadow conﬁguration or not. Note that
when running this experiment without the FIB updates, the CPU
utilization for both our shadow kernel and the standard kernel ﬂuc-
tuates much less, but both remain nearly identical for the duration
of the experiment.
8.3 Usage of Shadow Conﬁgurations
We now demonstrate the effectiveness of shadow conﬁguration
in three usage scenarios.
Equipment Maintenance: A usage scenario of shadow conﬁgura-
tion is equipment maintenance. We use this scenario to demonstrate
the performance of our commitment protocol.
In this experiment, we use the Abilene topology and conﬁgura-
tions, and generate transit trafﬁc according to the CAIDA traces
from peering routers conﬁgured at New York, Seattle, and Atlanta.
Emulab’s delay nodes are used to model propagation delays.
In this scenario, we bring the Kansas router down for mainte-
nance and return it to service when ﬁnished. The real conﬁguration
is initially cloned to the shadow conﬁguration. Next, we disable
OSPF in the shadow conﬁguration on the Kansas router, wait 10
seconds, then commit at time 48. The network operator may then
safely perform upgrades, and restart it when ﬁnished. Once the
shadow conﬁguration with Kansas enabled converges, the conﬁgu-
rations are again swapped, causing the Kansas router to again for-
ward transit trafﬁc.
)
s
m
(
T
T
R
 110
 105
 100
 95
 90
 85
 80
 75
Short transient
    period
Commit
before
shutdown
 0
 20
 40
Swap back
after restart
 80
 100
 60
Time (s)
Figure 11: RTT between peers at New York and Seattle during
commitment and rollback.
Figure 11 shows the round-trip time between the peering routers
at New York and Seattle. Note that there are three modes of op-
eration at 82 ms, 92 ms, and 102 ms due to the Abilene routers
asynchronously executing the swap in phase 3 of the commitment
protocol. This arises because the ICMP echo request follows a dif-
ferent path than the reply, due to tagging at the ingress routers. The
intermediate transition phase lasts for a short time, but the packet
forwarding behavior during this transition phase is clean and con-
trolled. Importantly, there are no packet losses.
Our commitment protocol is executed over serial consoles to
each router. We are currently developing a protocol to access the
routers’ conﬁguration terminals using both the shadow and real
conﬁgurations such that the protocol is resistant to misconﬁgura-
tion in one of the two conﬁgurations.
Parameter Tuning: The next usage scenario for shadow conﬁgu-
rations we evaluate is parameter tuning. We update a set of OSPF
link weights simultaneously. The real conﬁguration uses Abilene’s
normal link weights, and we then change all of the link weights in
the network to be the inverse of the bandwidth (i.e., all equal in the
Abilene case) using two methods: (1) manual conﬁguration and (2)
shadow conﬁgurations.
To perform the manual conﬁguration, we update the link weights
using parallel Telnet sessions, which takes about 4 seconds. With
shadow conﬁgurations, we update the link weights in the shadow
conﬁguration, wait 20 seconds for convergence, and then execute
the commitment protocol.
Manual Configuration
Shadow Commitment
)
s
m
(
T
T
R
 140
 130
 120
 110
 100
 90
 80
 70
 0  5  10  15  20  25  30  35
 0  5  10  15  20  25  30  35
Time (s)
Time (s)
Figure 12: RTT between peers at New York and Seattle during
OSPF link weight change.
We immediately notice in Figure 12 that using the shadow con-
ﬁguration avoids the reconvergence process. Under manual conﬁg-
uration, the round-trip time between the peer routers at Seattle and
New York ﬂuctuate between 83 ms and 135 ms before settling on
the converged value of 80 ms. Using shadow conﬁgurations pro-
vides a quick and smooth transition since convergence takes place
in the shadow conﬁguration prior to commitment.
New Service Testing: The last usage scenario we evaluate is test-
ing of new services. We use this scenario to demonstrate our packet
cancellation technique and show that (1) there is little effect on tran-
sit trafﬁc and (2) performance measurements on shadow trafﬁc are
indicative of its true performance.
Real
Conﬁg Abilene conﬁguration
Trafﬁc
Transit trafﬁc generated
from CAIDA traces with
30% utilization on bot-
tleneck link
Shadow
Abiliene conﬁguration with 4 link
weights adjusted for load balanc-
ing
Duplicated real trafﬁc and UDP
streaming video with 6 servers
and 12 clients
Table 3: New service testing experiment setup.
Setup:
In this scenario, a network operator is testing a streaming
video application under a new set of OSPF link weights. Our setup
is shown in Table 3.
UDP packet traces are constructed using a high-deﬁnition movie
trailer and the VideoLAN [48] VLC software. The movie trailer
alternates between complex scenes (using up to 22 Mbps) and a
black background with text (using 450 Kbps).
With this setup, there exist time intervals when the combined
(raw) real and shadow trafﬁc intensity exceeds link capacity on
some links, meaning bandwidth partitioning is not effective for ob-
taining accurate performance results.
Delay nodes are removed from the Emulab experiment since we
want to observe small-scale variations over multihop ﬂows. We
also use 100 Mbps links to more easily observe delay variation
given the resolution of our measurement tools.
Safety for Transit Trafﬁc: Our experiments show that the shadow
trafﬁc has little effect on the real trafﬁc when packet cancellation is
enabled. We show the measured performance for two paths. Fig-
ure 13 shows the delay variation for trafﬁc from Seattle to Chicago.
The real trafﬁc performance with packet cancellation enabled over-
laps the performance when only real transit trafﬁc is present, while
the delay variation rises sharply up to about 15 ms without packet
cancellation. Similar behavior is observed between Salt Lake City
and Atlanta (Figure 14), where the round-trip time increases from
under 1 ms up to 20 ms without packet cancellation. Round-trip
time is largely unaffected with packet cancellation enabled.
Shadow Performance Accuracy: We next show that packet can-
cellation provides accurate performance measurements despite the
presence of real transit trafﬁc. In our experiment, there are multiple
streaming sessions that have incorrect measurements when packet
cancellation is not enabled. For example, the throughput measure-
ment for the video stream from Houston to Chicago (Figure 16)
shows the correct value of 22 Mbps. Without packet cancellation,
the measurements incorrectly show that only 18 Mbps is supported.
Multiple video streams in our experiments also show that loss
rates with packet cancellation are indicative of the true value. Fig-
ure 15 shows the loss rate of streams served by Salt Lake City.
Without packet cancellation, it is erroneously reported to be up to
14%, while packet cancellation correctly has no losses.
Fine-grained Accuracy: Finally, we show in more detail how real
trafﬁc is protected and performance characteristics of shadow traf-
ﬁc are preserved under packet cancellation. We use a simple il-
lustrative topology shown in Figure 5 and the CAIDA traces. Fig-
ure 17 shows CDFs of delay variation for both real and shadow traf-
ﬁc. The observed performance for real trafﬁc is largely unchanged
as we increase shadow trafﬁc until raw total trafﬁc intensity reaches
link capacity (100%). Similarly, delay variations for shadow trafﬁc
closely approximate its actual behavior.
9. RELATED WORK
The importance of conﬁguration management has motivated many
recent studies and proposals on this topic (e.g., [3, 7, 14, 36]). Due
to space limitation, we review only the most directly related work.
Static Analysis and Simulation Tools: These studies are very
useful for conﬁguration validation in many settings (e.g., [15, 17,
22, 37, 53]). Shadow conﬁgurations provide a complementary tool
and have several advantages such as scalability. A particular ad-
vantage is that it does not depend on an abstract model of the real
network and therefore will not miss conﬁguration errors caused by
the inconsistency between the real network and the model.
• Since static analysis and simulation tools often depend on an ab-
stract model of the real network, they may miss conﬁguration
errors caused by the inconsistency between the real network and
the model (e.g., forgotten network equipment or network con-
nectivity).
• The ﬁnal conﬁguration depends on the whole network process-
ing environment: the hardware, ﬁrmware, and software features
(including the bugs!) of the routers. Typical networks are hetero-
geneous networks consisting of equipment from multiple ven-
dors with distinct hardware, ﬁrmware and software features. As
an example of the complexity, a survey [36] of 31 production
networks found that over 200 different software versions were
running on multiple hardware platforms. As another example,
some routers may also offer special non-standard features (e.g.,
Cisco-speciﬁc BGP decision steps in addition to the conven-
tional BGP decision process [53]). As yet another example, the
Cisco document [10] reports a common OSPF routing problem
related with forwarding addresses. The reachability issue was
caused by a bug in Cisco IOS before Release 12.1(3).
• The interactions of multiple services can be a source of conﬁg-
uration errors. Today’s networks are complex and certain be-
haviors may only arise when two features interact. As a simple
example, the routing protocol can compute a backup path but all
packets rerouted to the backup path can be dropped by a packet
)
s
m
(
n
o
i
t
a
i
r
a
V
y
a
l
e
D
 35
 30
 25
 20
 15
 10
 5
 0
-5
Real Only
Cancellation Enabled
Cancellation Disabled
 30
 25
 20
 15
 10
 5
)
s
m
(
T
T
R
Real Only
Cancellation Enabled
Cancellation Disabled
)
%
(
e
t
a
R
s
s
o
L
 16
 14
 12
 10
 8
 6
 4
 2
 0
 0
 30
 10
 20
 60
Figure 13: Delay variation for real tran-
sit trafﬁc (Seattle→Chicago).
Time (s)
 40
 50
 0
 0
 30
 20