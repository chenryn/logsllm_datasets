attacks, are impossible assuming a correct implementation of
the compiler and runtime system.
Overall, the code is rather unevenly commented. While most
ﬁles have a description of their overall function, the meanings
of individual functions, their arguments, and the algorithms
within are more often than not undocumented. An example
of a complex and completely undocumented function is the
CBallotRelSet::Open function from TSElection/
TSElectionSet.cpp as shown in Figure 2. This block
of code contains two nested loops, four complex conditionals,
and ﬁve debugging assertions, but no comments that explain its
purpose. Ascertaining the meaning of even a small part of this
code is a huge undertaking. For example, what does it mean
for vgroup->KeyId() == -1? That
the ID is simply
undeﬁned? Or perhaps that the group should be ignored? Such
poorly documented code impairs the ability of both internal
developers and external security evaluator to assess whether
the code is functioning properly or might lead to a security
issue.
C. Coding process
An important point to consider is how code is added to
the system. From the project’s CVS logs, we can see that
most recent code updates are in response to speciﬁc bugs
that needed to be ﬁxed. There are, however, no references to
tracking numbers from a bug database or any other indication
that such ﬁxes have been vetted through any change-control
process. Indeed, each of the programmers7 seem to have
completely autonomous authority to commit to any module
in the project. The only evidence that we have found that
the code undergoes any sort of review comes from a single
6Here we mean language safety in the technical sense: no primitive
operation in any program ever misinterprets data.
7Through web searches, we have matched each programmer’s CVS user
names with their likely identities and so can conclude that they are not group
accounts.
void CBallotRelSet::Open(const CDistrict* district, const CBaseunit* baseunit,
const CVGroup* vgroup1, const CVGroup* vgroup2)
{
ASSERT(m_pDB != NULL);
ASSERT(m_pDB->IsOpen());
ASSERT(GetSize() == 0);
ASSERT(district != NULL);
ASSERT(baseunit != NULL);
if (district->KeyId() == -1) {
Open(baseunit, vgroup1);
} else {
const CDistrictItem* pDistrictItem = m_pDB->Find(*district);
if (pDistrictItem != NULL) {
const CBaseunitKeyTable& baseunitTable = pDistrictItem->m_BaseunitKeyTable;
int count = baseunitTable.GetSize();
for (int i = 0; i KeyId() == -1 || *baseunit == curBaseunit) {
const CBallotRelationshipItem* pBalRelItem = NULL;
while ((pBalRelItem = m_pDB->FindNextBalRel(curBaseunit, pBalRelItem))){
if (!vgroup1 || vgroup1->KeyId() == -1 ||
(*vgroup1 == pBalRelItem->m_VGroup1 && !vgroup2) ||
(vgroup2 && *vgroup2 == pBalRelItem->m_VGroup2 &&
*vgroup1 == pBalRelItem->m_VGroup1))
Add(pBalRelItem);
}
}
}
m_CurIndex = 0;
m_Open = TRUE;
}
}
}
The
Fig. 2.
function CBallotRelSet::Open function from
TSElection/TSElectionSet.cpp. This complex function is com-
pletely undocumented.
log comment: “Modify code to avoid multiple exit points to
meet Wyle requirements.” This refers to Wyle Labs, one of
the independent testing authorities charged with certifying that
voting machines have met FEC guidelines.
Virtually any serious software engineering endeavor will
have extensive design documents that specify how the system
functions, with detailed descriptions of all aspects of the sys-
tem, ranging from the user interfaces through the algorithms
and software architecture used at a low level. We found no
such documents in the CVS archive, and we also found no
references to any such documents in the source code, despite
references to algorithms textbooks and other external sources.
There are also pieces of the voting system that come from
third parties. Most obviously, a ﬂaw in the operating system,
Windows CE, could expose the system to attack since the
OS controls memory management and all of the device’s I/O
needs. In addition, an audio library called fmod is used.8 While
the source to fmod is available with commercial licenses,
unless this code is fully audited it might contain a backdoor or
an exploitable buffer overﬂow. Since both the operating system
and fmod can access the memory of the voting program, both
must be considered part of the trusted computing base (TCB)
as a security vulnerability in either could compromise the
security of the voting program itself. The voting terminal’s
hardware boot instructions should likewise be considered part
of the TCB.
Due to the lack of comments, the legacy nature of the code,
and the use of third-party code and operating systems, we
believe that any sort of comprehensive, top-to-bottom code
review would be nearly impossible. Not only does this increase
the chances that bugs exist in the code, but it also implies that
any of the coders could insert a malicious backdoor into the
system without necessarily being caught. The current design
deﬁciencies provide enough other attack vectors, however,
that such an explicit backdoor is not required to successfully
attack the system. Regardless, even if the design problems are
eventually rectiﬁed, the problems with the coding process may
well remain intact.
Since the initial version of this paper was made available on
the Internet, Diebold has apparently “developed, documented,
and implemented a change control process” [27]. The details
of this revised process have not been made available to the
public, so we are unable to comment on their effectiveness.
D. Code completeness and correctness
While the code we studied implements a full system,
the implementors have included extensive comments on the
changes that would be necessary before the system should be
considered complete. It is unclear whether the programmers
actually intended to go back and remedy all of these issues
as many of the comments existed, unchanged, for months,
while other modiﬁcations took place around them. Of course,
while the AVTSCE code we examined appears to have been
the current codebase in April 2002, we know nothing about
subsequent changes to the code. (Modiﬁcation dates and loca-
tions are easily visible from the CVS logs.) These comments
come in a number of varieties. For illustrative purposes, we
have chosen to show a few such comments from the subsystem
that plays audio prompts to visually-impaired voters.
• Notes on code reorganization:
/* Okay, I don’t like this one bit. Its really
tough to tell where m AudioPlayer
should live. [...] A reorganization might be in
order here. */
• Notes on parts of code that need cleaning up:
/* This is a bit of a hack for now. [...]
Calling from the timer message appears
to work. Solution is to always do a 1ms wait
between audio clips. */
• Notes on bugs that need ﬁxing:
/* need to work on exception *caused by audio*.
I think they will currently result
in double-fault. */
There are, however, no comments that would suggest that
the design will radically change from a security perspective.
None of the security issues that have been discussed in this
paper are pointed out or marked for correction. In fact, the
only evidence at all that a redesign might at one point have
been considered comes from outside the code: the Crypto++
library9 is included in another CVS archive in cvs.tar.
However, the library was added in September 2000, before
the start of the AVTSCE AccuVote-TS version 4 tree, and
appears to have never been used. (The subsequent SAIC [27]
and RABA [24] analyses report that many of the problems we
identify are still applicable to recent versions of the AccuVote-
TS system, implying that, at least up to the version that SAIC
8http://www.fmod.org/
9http://www.eskimo.com/˜weidai/cryptlib.html
Proceedings of the 2004 IEEE Symposium on Security and Privacy (S&P’04)  
1081-6011/04 $ 20.00 © 2004 IEEE 
and RABA analyzed, there has not been any radical change
to the AccuVote-TS system.)
VI. CONCLUSIONS
Using publicly available source code, we performed an
analysis of the April 2002 snapshot of Diebold’s AccuVote-TS
4.3.1 electronic voting system. We found signiﬁcant security
ﬂaws: voters can trivially cast multiple ballots with no built-
in traceability, administrative functions can be performed by
regular voters, and the threats posed by insiders such as poll
workers, software developers, and janitors is even greater.
Based on our analysis of the development environment, includ-
ing change logs and comments, we believe that an appropriate
level of programming discipline for a project such as this was
not maintained. In fact, there appears to have been little quality
control in the process.
For quite some time, voting equipment vendors have main-
tained that their systems are secure, and that the closed-source
nature makes them even more secure. Our glimpse into the
code of such a system reveals that there is little difference
in the way code is developed for voting machines relative to
other commercial endeavors. In fact, we believe that an open
process would result in more careful development, as more
scientists, software engineers, political activists, and others
who value their democracy would be paying attention to the
quality of the software that is used for their elections. (Of
course, open source would not solve all of the problems with
electronic elections. It is still important to verify somehow that
the binary program images running in the machine correspond
to the source code and that the compilers used on the source
code are non-malicious. However, open source is a good start.)
Such open design processes have proven successful in projects
ranging from very focused efforts, such as specifying the
Advanced Encryption Standard (AES) [23], through very large
and complex systems such as maintaining the Linux operating
system. Australia is currently using an open source voting
system10.
Alternatively, security models such as the voter-veriﬁed
audit trail allow for electronic voting systems that produce a
paper trail that can be seen and veriﬁed by a voter. In such a
system, the correctness burden on the voting terminal’s code
is signiﬁcantly less as voters can see and verify a physical
object that describes their vote. Even if, for whatever reason,
the machines cannot name the winner of an election, then
the paper ballots can be recounted, either mechanically or
manually, to gain progressively more accurate election results.
Voter-veriﬁable audit trails are required in some U.S. states,
and major DRE vendors have made public statements that they
would support such features if their customers required it. The
EVM project11 is an ambitious attempt to create an open-
source voting system with a voter-veriﬁable audit trail — a
laudable goal.
The model where individual vendors write proprietary code
to run our elections appears to be unreliable, and if we do
10http://www.elections.act.gov.au/EVACS.html
11http://evm2003.sourceforge.net
not change the process of designing our voting systems, we
will have no conﬁdence that our election results will reﬂect the
will of the electorate. We owe it to ourselves and to our future
to have robust, well-designed election systems to preserve the
bedrock of our democracy.
ACKNOWLEDGMENTS
We thank Cindy Cohn, David Dill, Badri Natarajan, Jason
Schultz, Tracy Volz, David Wagner, and Richard Wiebe for
their suggestions and advice. We also thank the state of
Maryland for hiring SAIC and RABA and the state of Ohio
for hiring Compuware to independently validate our ﬁndings.
Most of this work was performed while T. Kohno was visiting
the Johns Hopkins University Information Security Institute.
T. Kohno is supported by a National Defense Science and
Engineering Graduate Fellowship.
REFERENCES
[1] M. Bellare, R. Canetti, and H. Krawczyk. Keying hash functions for
message authentication. In N. Koblitz, editor, Advances in Cryptology
– CRYPTO ’96, volume 1109 of Lecture Notes in Computer Science,
pages 1–15. Springer-Verlag, Berlin Germany, Aug. 1996.
[2] M. Bellare, A. Desai, E. Jokipii, and P. Rogaway. A concrete security
treatment of symmetric encryption. In Proceedings of the 38th Annual
Symposium on Foundations of Computer Science, pages 394–403. IEEE
Computer Society Press, 1997.
[3] M. Bellare and C. Namprempre. Authenticated encryption: Relations
among notions and analysis of the generic composition paradigm.
In
T. Okamoto, editor, Advances in Cryptology – ASIACRYPT 2000,
volume 1976 of Lecture Notes in Computer Science, pages 531–545.
Springer-Verlag, Berlin Germany, Dec. 2000.
[4] California Internet Voting Task Force. A Report on the Feasibility of In-
ternet Voting, Jan. 2000. http://www.ss.ca.gov/executive/
ivote/.
[5] Voting: What Is; What Could Be, July 2001. http://www.vote.
caltech.edu/Reports/.
[6] D. Chaum. Secret-ballot receipts: True voter-veriﬁable elections. IEEE
Security and Privacy, 2(1):38–47, 2004.
[7] Compuware Corporation. Direct Recording Electronic (DRE) Technical
Security Assessment Report, Nov. 2003. http://www.sos.state.
oh.us/sos/hava/files/compuware.pdf.
[8] J. Daemen and V. Rijmen. The Design of Rijndael: AES–The Advanced
Encryption Standard. Springer-Verlag, Berlin Germany, 2002.
[9] Diebold Election Systems. AVTSCE source tree, 2003.
users.actrix.co.nz/dolly/Vol2/cvs.tar.12
http://
[10] D. L. Dill, R. Mercuri, P. G. Neumann, and D. S. Wallach. Frequently
Asked Questions about DRE Voting Systems, Feb. 2003. http://www.
verifiedvoting.org/drefaq.asp.
[11] Federal Election Commission. Voting System Standards, 2001. http:
//fecweb1.fec.gov/pages/vss/vss.html.
[12] J. Gilmore, editor. Cracking DES: Secrets of Encryption Research,
Wiretap Politics & Chip Design. O’Reilly, July 1998.
[13] D. Gritzalis, editor. Secure Electronic Voting. Springer-Verlag, Berlin
Germany, 2003.
[14] B. Harris. Black Box Voting: Vote Tampering in the 21st Century. Elon
House/Plan Nine, July 2003.
[15] T. Jim, G. Morrisett, D. Grossman, M. Hicks, J. Cheney, and Y. Wang.
Cyclone: A safe dialect of C. In USENIX Annual Technical Conference,
June 2002.
[16] D. W. Jones. Problems with Voting Systems and the Applicable Stan-
dards, May 2001. Testimony before the U.S. House of Representatives’
Committee on Science, http://www.cs.uiowa.edu/˜jones/
voting/congress.html.
[17] D. W. Jones. The Case of the Diebold FTP Site, July 2003. http:
//www.cs.uiowa.edu/˜jones/voting/dieboldftp.html.
12The cvs.tar ﬁle has been removed from this website.
Proceedings of the 2004 IEEE Symposium on Security and Privacy (S&P’04)  
1081-6011/04 $ 20.00 © 2004 IEEE 
[18] A. Kerckhoffs. La Cryptographie Militaire. Libraire Militaire de L.
Baudoin & Cie, Paris, 1883.
[19] H. Krawczyk. The order of encryption and authentication for protecting
communications (or: How secure is SSL?). In J. Kilian, editor, Advances
in Cryptology – CRYPTO 2001, volume 2139 of Lecture Notes in
Computer Science, pages 310–331. Springer-Verlag, Berlin Germany,
2001.
[20] R. Mercuri. Electronic Vote Tabulation Checks and Balances. PhD
thesis, University of Pennsylvania, Philadelphia, PA, Oct. 2000.
[21] National Science Foundation. Report on the National Workshop on Inter-
net Voting: Issues and Research Agenda, Mar. 2001. http://news.
findlaw.com/cnn/docs/voting/nsfe-voterprt.pdf.
[22] NBS. Data encryption standard, January 1977. Federal Information
Processing Standards Publication 46.
[23] J. Nechvatal, E. Barker, L. Bassham, W. Burr, M. Dworkin, J. Foti, and
E. Roback. Report on the Development of the Advanced Encryption
Standard (AES), Oct. 2000.
[24] RABA Innovative Solution Cell.
Trusted Agent Report: Diebold
AccuVote-TS Voting System, Jan. 2004. http://www.raba.com/
press/TA_Report_AccuVote.pdf.
[25] A. D. Rubin. Security considerations for remote electronic voting.
Communications of the ACM, 45(12):39–44, Dec. 2002. http://
avirubin.com/e-voting.security.html.
[26] B. Schneier. Applied Cryptography: Protocols, Algorithms, and Source
Code in C. John Wiley & Sons, New York, second edition, 1996.
[27] Science Applications International Corporation. Risk Assessment Report:
Diebold AccuVote-TS Voting System and Processes, Sept. 2003. http:
//www.dbm.maryland.gov/SBE.
Proceedings of the 2004 IEEE Symposium on Security and Privacy (S&P’04)  
1081-6011/04 $ 20.00 © 2004 IEEE