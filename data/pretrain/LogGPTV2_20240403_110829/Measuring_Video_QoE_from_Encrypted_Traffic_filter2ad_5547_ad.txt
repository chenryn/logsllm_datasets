times of the segments are reduced signiﬁcantly until a
certain threshold in the playout buﬀer has been reached
and the video download returns to the steady phase.
In the video session in Figure 3, we can see there is a
steady state in terms of size and inter-arrival times for
the ﬁrst quality. When the representation switch occurs
however, the chunk time delta and size delta are grad-
ually increasing until a steady state is reached again.
Therefore, for the purpose of more accurately captur-
ing the representation changes we use the two features
that were used in section 4.2, the segment size delta
∆size and segment time delta ∆t.
The most suitable approach to detect representation
changes, is to perform a time-series analysis. This method
allows the identiﬁcation of abrupt changes in the values
of diﬀerent metrics in the dimension of time that are
correlated with the switches of representations.
In more detail, our analysis of video sessions with
quality switches showed that whenever a change in res-
olution takes place, a new start-up phase is initiated
in order to ﬁll the buﬀer with data from the new rep-
resentation as fast as possible. This phase is charac-
terized by video segments with small sizes and small
inter-arrival times which will increase gradually until
the steady state is reached once again.
We ﬁnd that the metric which better captures the
changes in both the size and the inter-arrival of the
video segments, is the product ∆size× ∆t. Speciﬁcally,
the multiplication of the two parameters will combine
but at the same time emphasize the eﬀects of each one.
Therefore, for each video session in the dataset, we cal-
culate a new time series where each point corresponds
to the aforementioned product.
While there are many tools and algorithms for de-
tecting abrupt changes in a time series, we ﬁnd that
the most suitable for the purposes of this work is the
Cumulative Sum Control Chart (CUSUM) which was
developed by E.S. Page [17].
CUSUM is a change detection monitoring technique
which allows the detection of shifts from the mean of a
given sample of points in a time series. When a point
exceeds an upper or lower threshold then a change is
found.
In our case, instead of thresholds we use the
standard deviation of the output of the change detec-
tion algorithm. The standard deviation is capable of
capturing the magnitude of the changes that occurred
and is an indicator of high variance.
Figure 4, shows the distributions of the standard de-
viation of the change detection output for sessions with
and without variance. We observe that there is sig-
niﬁcant separation between the two distributions and
by deﬁning a threshold at value 500 on the horizontal
axis, we are capable of correctly identifying 78% of the
sessions without variance and 76% of those that have
representation variations.
Apart from the time-series analysis, ML was also con-
sidered to develop a model for the detection of represen-
tation switches. However, it did not perform as well as
the proposed methodology did and for this reason that
approach was not considered.
5. EVALUATION WITH
ENCRYPTED TRAFFIC
In this section we present and discuss the ﬁndings
from the evaluation of the models that were developed
in Section 4 with encrypted data. This step is impor-
tant for verifying that the proposed methodology can
521application then ‘hooks’ each invocation of this method
and extracts its result, which in this case is the full
URL of the HTTP request. The URL is then parsed to
extract the required ground truth.
Finally, our app will periodically aggregate and send
the collected information from the videos to a remote
server. The local copy of this information is then deleted
from the device to free up space.
5.2 Dataset
Next, the app was installed on a Samsung Galaxy S2
device with a SIM card with an unlimited 3G data plan.
The instrumented phone was given to a user who was
instructed to carry it at all times for a period of 25 days.
The user was motivated to launch the application when
moving to increase the probability of QoE issues.
As a result, we generated a dataset for the ground
truth and a dataset from the encrypted traﬃc corre-
sponding to 722 video sessions. Each entry in the ground
truth dataset corresponds to a unique segment and the
video session ID which the segment belongs to, the
timestamp that marks the beginning of the chunk down-
load, a ﬁeld to indicate if it is an audio or video segment,
the total number and duration of the stalls observed in
the session and ﬁnally its quality representation.
The encrypted traﬃc data is collected again from the
proxy in the form of weblogs. However, since the ﬂows
are encrypted, information such as the session ID, the
stall characteristics and the quality level of each chunk
are not available. Therefore, we only extract the times-
tamp of the HTTP request, the server IP address and
port, the size of the requested object and the TCP
statistics which were described in detail in Section 3.1.
Although the session ID is available in the ground
truth dataset and it is used to group the video segment
statistics in unique sessions, this parameter is missing
from the encrypted data. Even so, we ﬁnd that it is
possible to identify the encrypted segments that belong
to the same session and group them together.
To achieve this we go through the following steps:
• Identify the traﬃc that corresponds to a single
subscriber and remove all requests that do not be-
long to YouTube by ﬁltering out those that have
domain names not related to the service.
• Next, we look for the unique HTTP traﬃc patterns
that take place at the beginning of a new video
session but also after the completion of the play-
back. These include requests to m.youtube.com
and i.ytimg.com which are responsible for down-
loading multiple web objects such as HTML, scripts
and images to construct the video’s web page.
• Longer periods without traﬃc that correspond to
the time between consecutive sessions are identi-
ﬁed in order to clearly deﬁne the beginning and
ending of each session.
Figure 4: CDF of change detection output for
videos with and without resolution changes.
perform with similar accuracy when dealing with en-
crypted traﬃc.
5.1 Ground Truth
For the collection of the encrypted traﬃc, we devel-
oped an Android application which is responsible for
automatically launching YouTube videos which are ran-
domly selected from the list of the 100 most popular
videos on the website [18]. All videos are played using
the latest version of the stock YouTube app for Android,
where encryption is enabled by default.
Apart from handling the playback of videos, the app
has also the capability to extract performance measure-
ments related to the video that is being played.
In
more detail, by accessing the device’s log, it can iden-
tify and log the playback status of a video, i.e.
if the
playback has started, paused, stopped or if a stall has
occurred. Therefore, we do not only detect if the video
was watched throughout its full length or abandoned
earlier, but also identify any stalling events and their
duration. This information is used as the ground truth
for labeling the data and evaluating the accuracy of the
stall detection model.
In order to capture the ground truth related to the
representation quality switches we need access to the
metadata in the HTTP requests that are responsible for
the download of the individual video chunks. However,
these requests are encrypted by default by the YouTube
application and the required information cannot be cap-
tured by means of traﬃc monitoring.
Although solutions such as Man-in-the-middle (MITM)
proxies are common in such use cases for decrypting the
traﬃc generated by the device, we believe that they are
not practical since they alter the path between the client
and the server, but also change the encryption scheme
by establishing two separate TLS connections instead
of one.
To make sure that the ground truth for the quality
switches is obtained without tampering with the en-
cryption scheme or the traﬃc between the player and
the content server, we reverse engineer the YouTube ap-
plication and pinpoint the method which is responsible
for constructing and performing HTTP requests. Our
522This methodology has high accuracy as it successfully
identiﬁed the vast majority of the sessions that were
launched during the entire period of the measurements.
However, it can be limited in scenarios were the same
subscriber launches multiple videos in parallel and not
sequentially. Although such cases are quite rare, it can
be challenging to identify the segments that belong to
the same video session.
Then the two datasets can be easily joined by match-
ing the respective timestamps and the chunk count per
session. As a result, the ﬁnal dataset contains the same
metrics that were described in the left column of Table
1. Having the exact same set of features in both datasets
is necessary to allow the evaluation of the trained mod-
els that were created in the previous section with the
new data from the encrypted traﬃc.
5.3 Dataset Comparison
In this section we characterize the two datasets and
make a comparison of the key features. This will help
verify that the encrypted YouTube service behaves sim-
ilarly to the unecrypted and the model built for plain
traﬃc works for encrypted traﬃc as well.
More speciﬁcally, in Figure 5 we present the distribu-
tions of the segment size (left) for encrypted and clear-
text. The right ﬁgure shows the comparison between
the two distributions for the segment inter-arrival times.
In the case of the segment size, there is a signiﬁcant
overlap between the two distributions. This indicates
that there is a common pattern with respect to the
downloaded chunk sizes of the videos in both datasets
which can be translated to videos streamed with similar
qualities. Only 10% of the segments were larger than
1MB which can be found in HD videos, while the ma-
jority of the segment sizes are consentrated at or below
500KB which corresponds to SD video quality.
The distributions for the segment inter-arrival times
also have very common characteristics. However, 60%
of the encrypted chunks have slightly lower values in
comparison with the respective unencrypted data. The
shorter times between chunks are indicative of lower
bandwidth availability that results in faster depletion of
the playout buﬀer and a more frequent request of new
segments. This observation is expected since a large
part of the encrypted videos was downloaded while the
user was commuting where network conditions can sig-
niﬁcantly deteriorate.
5.4 Stall Detection
Before evaluating the model for detecting stalls, we
repeat the feature construction process described in Sec-
tion 4.1. However, an automated feature selection like
the one employed in the previous section is no longer
necessary since we already know the important features
that are required to make predictions and the rest are
safely removed. Next, the trained model from Section
4.1 is directly tested with encrypted traﬃc.
Figure 5: CDF of the segment size (left) and
segment inter-arrival time (right) for encrypted
and unencrypted traﬃc.
The resulting accuracy is 91.8% which corresponds to
only 1.7% lower performance than the evaluation with
unencrypted data. Nevertheless, this is still an excellent
result which demonstrates that the training set that we
used created a very accurate model that can be applied
to encrypted traﬃc with equal success.
Table 8 shows the evaluation results in terms of Preci-
sion and Recall and Table 9 the corresponding confusion
matrix. Here we can see that the performance has im-
proved for the videos without stalls, it remained roughly
the same for sessions aﬀected by mild stalling but has
decreased for the case of videos with severe stalls.
Class
TP Rate FP Rate Precision Recall
no stalls
mild stalls
severe stalls
weighted avg.
0.97
0.75
0.64
0.92
0.19
0.04
0.02
0.16
0.96
0.79
0.6
0.92
0.97
0.75
0.54
0.92
Table 8: Classiﬁer’s output for the stall detec-
tion evaluation
original label
predicted label
no stalls mild stalls
severe stalls
no stalls
mild stalls
severe stalls
97.2%
18.6%
2%
2.5%
75.2%
32.4%
0.3%
6.2%
65.6%
Table 9: Stall detection confusion matrix
The detection of non-problematic videos is done with
higher accuracy than the one observed in Section 4 be-
cause there is smaller diversity in the network conditions
where the healthy sessions occur. This is attributed to
the fact that the majority of these sessions are generated
when the user is static either at the oﬃce or at home,
where the network conditions have a constant perfor-
mance and as a result, the classiﬁer can more easily
identify that these sessions did not have any issues.
The main source of the overall accuracy loss in this
evaluation however, is the class of videos with sever
stalls. From the confusion matrix it is apparent that
523this is a result of the increased number of videos with
severe stalls that were falsely detected as mild stalls.
This is a problem that was also observed to a lesser
extent in the training and evaluation with the unen-
crypted dataset (Section 4.1).
Although the low performance for the severe stalls
class is attributed to the same reasons that were de-
scribed in the previous section, the further decrease
in accuracy originates from the fact that in the new
dataset most of the sessions with severe stalls have a
Rebuﬀering Ratio slightly higher than 0.1. Remember
that 0.1 is the borderline that was deﬁned to separate
sessions with mild and severe stalls. Therefore, it be-
comes more diﬃcult for the classiﬁer to distinguish to
which class these videos belong to.
5.5 Average Representation Detection
The evaluation of the second model for the detection
of the average representation is done following the same
process as previously. The extended set of features is
generated by means of feature construction, followed
by the manual removal of the features which do not
contribute to the model. This results in the same 15
parameters that were presented in Table 5.
The evaluation is performed with the same approach
as previously, where the encrypted dataset is used as a
test set for the trained model. The process returns an
overall accuracy equal to 81.9% which is approximately
2.5% less than the respective result we got when using
the unencrypted dataset in Section 4.2. Again, this is
an overall good indicator that the model can perform