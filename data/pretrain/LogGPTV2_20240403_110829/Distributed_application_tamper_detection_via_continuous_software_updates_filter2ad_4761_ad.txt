# Attack Tree and Defense Mechanisms

## 1.2.1 Analyze Block Ai
- **1.2.2 Determine if Ai is an Asset Block**
  - **3.1 Analyze A to Determine if They are Orphan Blocks**
  - **3.2 Prevent Server from Replacing A with New Blocks**
    - **3.2.1 Report A ⊆ Active Set**
      - **3.2.1.1 Analyze Blocks & Build Call Graph**
      - **3.2.1.2 Report Valid Active Set Containing A**
  - **3.3 Prevent Server from Making Meaningful Updates to A**
    - **3.3.1 Report an Active Set that Has RPCs/Variables A Uses**
      - **3.3.1.1 Analyze Blocks & Build Call Graph**
      - **3.3.1.2 Find RPCs/Variables A Uses**
      - **3.3.1.3 Report Valid Active Set Containing Blocks with RPCs/Variables A Uses**
    - **3.3.2 Ignore Updates to A**
  - **3.4 Reverse Engineer Updates**
    - **3.4.1 Find Ancestor Nk−1 of New Block Nk**
      - **3.4.1.1 Compare Callgraphs**
      - **3.4.1.2 Compare Nk Against All Other Blocks**
    - **3.4.2 Extract New Variable/RPC Encodings & Call Signatures from N0, ..., Nk**
    - **3.4.3 Patch A with New Encodings**

**Figure 5: Attack Tree [26]**. OR-edges are dashed, AND-edges are solid.

### Defense Mechanisms
To counter the attacks in nodes 3.2 and 3.3, we can use the opaque primitive by inserting calls to non-existing functions. If the adversary reports an active set containing such a function, it indicates cheating.

## 4.3 Empirical Tests
We implemented three attacks and evaluated our system’s ability to detect them. The same target C program, a simple Tetris game with some functionality moved server-side, was used in all cases.

- **Unsophisticated Attacker (Node 3.3.2 in Figure 5)**: An unsophisticated attacker might ignore block updates and continue executing the tampered program. We simulated this attack by turning off client updates. Since RPCs are frequent in our test program, the server reliably detected malicious behavior shortly after the first RPC_encode update.
  
- **Building Program Snapshot (Nodes 1.1.2, 3.2.1.1, and 3.3.1.1)**: A malicious client may attempt to build a snapshot of the entire program to analyze it offline. We simulated this by engineering a client that disassembles its blocks, looks for referenced but not yet held blocks, and requests them from the server. This client quickly requested non-existent blocks protected by opaque predicates. By adding bogus calls in 50% of the blocks, we identified the malicious client after they had successfully requested and received 16 of the 24 real blocks. When we added a call to a bogus function into every block, the malicious client received only 6 of 24 real blocks (25%) before the attack was detected.

- **Reporting Entire Block Bag (Nodes 3.2.1 and 3.3.1)**: To prevent the server from updating blocks, a client can report the entire contents of the block bag as their active set. We implemented such a client, and the server was able to use the program call graph to reliably identify the malicious behavior after the first update cycle.

## 4.4 Diversity of Primitive Transformations
The most sophisticated attack in the attack tree is rooted at node 3.4, where the attacker tries to identify the history of a new block Nk (i.e., all its ancestors N0, ..., Nk−1) to reverse-engineer the transformations used to generate Nk. This could allow the attacker to intelligently update previously tampered blocks without re-analyzing them from scratch.

- **Determining Ancestor Nk−1**: This can be done by comparing the call graphs before and after the update (3.4.1.1) or by comparing Nk against all blocks in the block bag (3.4.1.2). Our primitives generate high entropy in both the call graph and the content of the blocks, making ancestry recognition very difficult.

### Demonstration of Call Graph Diversity
We repeatedly applied merge and split obfuscations to functions from the gzip SPEC benchmark and compared call-graph similarity using the algorithm from Shang et al. [28]. The data series in Figure 6(b) shows the similarity scores after each iteration of the transformations. For comparison, the horizontal lines in the graph show similarity scores of gzip to other unrelated SPEC programs, demonstrating that the call graph of the modified program is often less similar to its ancestor than to that of unrelated code.

- **Block Diversity**: To demonstrate block diversity, we measured n-gram similarity [25] of obfuscated blocks to their ancestors (Nk to Nk−1 pairings) and compared these scores with the n-gram similarity of unrelated code (Nk to Nj pairings). The gray bars in Figure 6(a) show the distribution of n-gram similarities of randomly-chosen unrelated blocks, while the black bars show the distribution of n-gram similarities of obfuscated blocks to their unobfuscated ancestors. The average n-gram similarity of unrelated blocks was 0.57, and the average similarity of a block to its ancestor was 0.66. Although some obfuscated functions show high similarity to their ancestors, many block-to-ancestor pairings show low similarity, making them impractical to find via n-gram analysis.

## 5. Performance Evaluation
We evaluate the overhead of our infrastructure, the overhead added by individual primitives, and the delay experienced by the client during an update. 

- **Client Measurements**: Conducted on a laptop with 4 GB of memory and an Intel 2.9 GHz Core i5 processor running Ubuntu Linux.
- **Server Measurements**: Conducted on an Amazon EC2 m1.small instance providing 1.7 GB of memory and one EC2 compute unit.

Our infrastructure has multiple potential sources of overhead, including breaking the client code into multiple files, impeding inter-procedural optimization, and adding a level of indirection to all function calls. We found the cost to be typically near a 5-10% runtime increase, though crafty was closer to a 20% increase.

- **Update Latency**: The sum of network delay, time to transform blocks, compilation, and linking. Transformation of blocks is usually on the order of a tenth of a second, even with complex primitives. Compilation currently takes roughly a second per function, and transfer across the network takes roughly half a second per function. Compilation time dominates the cost, but this can be improved by concurrent compilation on separate computation units or using a system like LLVM that does not require a final compilation stage.

## 6. Future Work
The latency of updates in our system is acceptable for some applications but not for those with real-time constraints, such as multiplayer online games. We are investigating ways to reduce delays caused by network overhead and code transformations.

- **Background Generation of Working Sets**: We are working on supporting background generation of working sets. The idea is to determine common active sets through profiling or static analysis and generate compatible block working sets in the background. During an update cycle, serve the client with a pre-generated working set if it matches the current active set; otherwise, generate one on the fly.

Previous work on diversification-for-security has often ignored correctness issues or assumed extensive test suites. Our situation is more challenging since we generate code continuously at runtime under time constraints, making comprehensive testing infeasible. However, we track the history of each generated block through our diversity graph and hope to integrate project unit tests into the system.

## 7. Conclusions
We have described a system for detecting tampering of clients running on untrusted nodes in a distributed system. Our system continuously updates client code, keeping it in a state of constant flux, giving the adversary a limited time window for analysis and tampering. We employ protocol-preserving code transformations to provide diversity and slow down the adversary's analysis, and transformations that are not protocol-preserving to make it harder for the adversary to tamper with the code without modifying its expected behavior, thereby making it easier for the trusted server to detect the tampering.

The security provided by the system depends on the frequency of code updates and the complexity and variability generated by individual code transformations, which in turn is related to the computational overhead a particular program can afford. Our diversity scheduler allows detailed control over which parts of the program to transform, which transformations to apply, and uses a rollback technique to avoid compounding too many transformations.

We have shown that our infrastructure causes a performance overhead ranging from 4% to 23% and that, for several easy-to-implement attacks, the server reliably and quickly detects the malicious behavior.

## References
[1] B. Anckaert, M. Jakubowski, R. Venkatesan, and K. D. Bosschere. Run-time randomization to mitigate tampering. In Proceedings of the second International Workshop on Security, number 4752, pages 153–168, Berlin, Oct. 2007.
...
[31] J. Xu, Z. Kalbarczyk, and R. K. Iyer. Transparent runtime randomization for security. IEEE Symposium on Reliable Distributed Systems, 0:260, 2003.