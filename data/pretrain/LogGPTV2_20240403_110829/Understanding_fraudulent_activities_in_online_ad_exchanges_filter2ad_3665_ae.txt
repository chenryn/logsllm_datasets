tect each ad network’s private ad serving data, but it also makes
it very difﬁcult for an ad network to verify the legitimacy of ad
requests from partner ad networks, leaving their advertisers open
to fraud. In particular, the suppression of the last octet of each IP
address is very limiting when trying to ﬁnd machines exhibiting
a particular kind of behavioral pattern.
In addition, all brokered
auction trafﬁc does not have a referrer or section ID ﬁeld, and con-
versions are not reported on the brokered trafﬁc, even if it was sold
to a locally-owned advertiser. The suppression of these ﬁelds al-
lows a fraudster to register with a malicious or naive network and
perpetrate fraud across many networks that may be more vigilant.
6.2 Consistency vs. Flexibility
As we discussed earlier, RightMedia does not verify or enforce
the basic premise that the referrer must match the publisher’s reg-
istered site’s domain and assigned sections. The primary reason
for this appears to be that RightMedia wants their service to be
user-friendly, and it would be inconvenient if a publisher had to re-
register and get new section IDs if they change their domain. We
were able to identify one instance of a benign MIA site, where the
publisher chose to relocate his site to a new domain and keep his old
section IDs. Our analysis tools ﬂagged them as suspicious because
their original site benign-golf-site1.com (obfuscated) gave us a 404
error, but there were a large number of impressions coming from
the referrer benign-golf-site2.com (obfuscated). Manual inspection
veriﬁed that the site had legitimate content, and the change of do-
main most likely came from the owner wanting a more lucrative
domain. Finally, we suspect RightMedia does not verify whether
the referrer matches the section ID. This might be because Right-
Media considers the ad networks to be responsible for monitoring
the validity of their trafﬁc and to ﬁlter any potentially fraudulent
instances.
6.3 Hiding Fraud in the Exchange
The distributed nature of an ad exchange makes it a platform to
commit fraud. Except for Yahoo! and the exchange itself, no en-
tity has a full picture of what is going on, and fraudsters use this
to appear far less malicious than they are in reality. For example,
in Section 5.1, we showed a case where a malicious cookie was
generating 300 times more revenue in NETWORKX’s auction traf-
ﬁc than in their local trafﬁc alone. However, NETWORKX only
sees a small portion of all auctioned trafﬁc in the exchange, thus
knowing how much total fraudulent trafﬁc involving this cookie is
impossible with our limited view. Moreover, every fraudulent site
that we identiﬁed, whether it was a fake site (as discussed in Sec-
tion 2.9) or one of our manually-identiﬁed bad publishers (from
Section 3.2), had a large number of ads from many ad networks and
ad exchanges. So, the total cost of the fraud gets distributed among
many independent and often competing entities (DoubleClick and
RightMedia, for example), which makes the fraud harder to iden-
tify.
6.4 What RightMedia Does Right
RightMedia does not ignore the problem of fraud. Their user in-
terface provides many tools for ad network administrators to iden-
tify the most blatant cases of fraud and shut down any malicious
accounts or suspicious partnerships. In addition, especially in our
experience with NETWORKX, it seems that the general attitude of
ad networks is to stay actively involved in their ad serving process
to ensure that their advertisers are protected from the worst cases
of fraud. RightMedia’s built-in malicious behavior detection sys-
tem is called SCOUR, and it was able to identify the severe case of
fraud outlined in Section 5.4 and take steps to limit (but not stop)
the fraud. According to the RightMedia online user guide, SCOUR
“searches for patterns exhibited by desktop software and ﬂags sec-
tions that exhibit what, in our opinion, may be malicious trafﬁc
patterns” [4]. Based on the description, it appears that the system
focuses on ﬁnding bot signatures and ﬂagging publishers who have
large amounts of trafﬁc coming from machines with these bot sig-
natures. With a full view of the exchange, a modiﬁed version of
this system should be able to detect some of the more sophisticated
types of fraud outlined in the paper.
7. RELATED WORK
Previous work focused on various aspects of detecting click-
fraud. Majumdar et al. proposed a content delivery system to verify
broker honesty under standard security assumptions [18]. Efﬁcient
algorithms for detecting duplicate clicks were proposed by Met-
wally et al.
in [26]. Studies also have
shown how malware can exploit ad networks [7, 10].
in [19] and Zhang et al.
Juels et al. proposed a cryptographic approach for replacing the
pay-per-click model with one where pay-per-action can attract pre-
mium rates and unsuccessful clicks are discarded [14]. Immorlica
et al. studied fraudulent clicks and presented a click-fraud resistant
method for learning the click through rate of advertisements [13].
In contrast, Kintana et al. created a system designed to penetrate
click-fraud ﬁlters to discover detection vulnerabilities [16].
Recent work has examined botnets and researchers have inﬁl-
trated or seized control of parts of the botnet infrastructure to gain
more insight into their inner-workings [15, 22, 24, 25]. Note that
these botnets were targeted at sending spam email and engaging in
acts of ﬁnancial theft.
In contrast to previous work, our analysis is the ﬁrst that uses
near real-time data to investigate the problem of ad fraud from in-
side an ad exchange and from the vantage point of a botnet con-
troller. This offers us a unique opportunity to study the ad exchange
structure in depth and to discover its weaknesses. Unfortunately,
many ad networks are still reluctant to provide researchers with ac-
cess to their data streams. As a result, the effectiveness of the pro-
posed method in preventing fraud and even determining the amount
of fraud that occurs in actual ad exchanges is not clear.
8. CONCLUSIONS
In this paper, we described how online ad exchanges work and
focused in particular on Yahoo!’s RightMedia. We found that the
complexity of the ad exchange provides criminals with an opportu-
nity to generate revenue by developing malware that impersonates
legitimate user activities. Regrettably, there is a trade-off between
the security of the exchange and the ﬂexibility offered to publishers
and ad networks to maximize their proﬁts.
289Acknowledgements
This work was supported by the Ofﬁce of Naval Research (ONR)
under Grant N000140911042, by the U.S. Army Research Lab-
oratory and the U.S. Army Research Ofﬁce under MURI grant
No. W911NF-09-1-0553, and by the National Science Foundation
(NSF) under grants CNS-0845559 and CNS-0905537.
9. REFERENCES
[1] SeleniumHQ. Web Application Testing System.
http://seleniumhq.org/.
[2] Secure Accounting and Auditing on the Web. volume 30,
pages 541 – 550, 1998.
[3] IAB Interactive Advertising Glossary. http://www.iab.
net/wiki/index.php/Category:Glossary, 2011.
[4] RightMedia Exchange Knowledge Base.
https://kb.yieldmanager.com/, 2011.
[5] C. Borgs, J. Chayes, O. Etesami, N. Immorlica, K. Jain, and
M. Mahdian. Dynamics of Bid Optimization in Online
Advertisement Auctions. In Proceedings of the International
Conference on World Wide Web, 2007.
[6] N. Daswani, C. Mysen, V. Rao, S. Weis, and S. G.
K. Gharachorloo. Online Advertising Fraud. In Proceedings
of Crimeware, 2008.
[7] N. Daswani and M. Stoppelman. The Anatomy of
Clickbot.A. In Proceedings of the USENIX Workshop on Hot
Topics in Understanding Botnet, 2007.
[8] B. Edelman. Securing Online Advertising: Rustlers and
Sheriffs in the New Wild West. In Harvard Business School
NOM Working Paper No. 09-039, 2008.
[9] M. Gandhi, M. Jakobsson, and J. Ratkiewicz.
Badvertisements: Stealthy Click-Fraud with Unwitting
Accessories. In Journal of Digital Forensic Practice, 2011.
[10] F. Hacquebor. Making a Million: Criminal Gangs, the Rogue
Trafﬁc Broker, and Stolen Clicks.
http://blog.trendmicro.com/making-a-
million%E2%80%94criminal-gangs-the-
rogue-traffic-broker-and-stolen-clicks/,
2010.
[11] H. Haddadi. Fighting Online Click-fraud Using Bluff Ads.
volume 40, April 2010.
[12] Y. Hu. Performance-based pricing models in online
advertising. Number March, 2004.
[13] N. Immorlica, K. Jain, M. Mahdian, and K. Talwar. Click
Fraud Resistant Methods for Learning Click-Through Rates.
Internet and Network Economics, pages 34–45, 2005.
[14] A. Juels, S. Stamm, and M. Jakobsson. Combatting Click
Fraud via Premium Clicks. In Proceedings of the USENIX
Security Symposium, 2007.
[15] C. Kanich, C. Kreibich, K. Levchenko, B. Enright,
G. Voelker, V. Paxson, and S. Savage. Spamalytics: An
Empirical Analysis of Spam Marketing Conversion. In
Proceedings of the ACM Conference on Computer and
Communications Security, 2008.
[16] C. Kintana, D. Turner, J. Pan, A. Metwally, N. Daswani,
E. Chin, and A. Bortz. The goals and challenges of click
fraud penetration testing systems. In In Proceedings of the
International Symposium on Software Reliability
Engineering, 2009.
[17] N. Kshetri. The Economics of Click Fraud. volume 8, pages
45 –53, May-June 2010.
[18] S. Majumdar, D. Kulkarni, and C. Ravishankar. Addressing
Click Fraud in Content Delivery Systems. In Proceedings of
the IEEE Conference on Computer Communications, 2007.
[19] A. Metwally, D. Agrawal, and A. Abbadi. Duplicate
Detection in Click Streams. In Proceedings of the
International Conference on World Wide Web, 2005.
[20] A. Metwally, D. Agrawal, and A. E. Abbadi. DETECTIVES:
DETEcting Coalition hiT Inïˇn ´Cation attacks in adVertising
nEtworks Streams. In Proceedings of the International
Conference on World Wide Web, 2007.
[21] L. Rodriguez.
http://www.washingtonpost.com/wp-srv/
technology/documents/yahoo_may2006.pdf,
2006.
[22] B. Stock, J. Gobel, M. Engelberth, F. Freiling, and T. Holz.
Walowdac â ˘A¸S Analysis of a Peer-to-Peer Botnet. In
Proceedings of European Conference on Computer Network
Defense, 2009.
[23] B. Stone-Gross, R. Abman, R. Kemmerer, C. Kruegel,
D. Steigerwald, and G. Vigna. The Underground Economy of
Fake Antivirus Software. In Proceedings of the Workshop on
Economics of Information Security, 2011.
[24] B. Stone-Gross, M. Cova, L. Cavallaro, B. Gilbert,
M. Szydlowski, R. Kemmerer, C. Kruegel, and G. Vigna.
Your Botnet is My Botnet: Analysis of a Botnet Takeover. In
Proceedings of the ACM Conference on Computer and
Communications Security, 2009.
[25] B. Stone-Gross, T. Holz, G. Stringhini, and G. Vigna. The
Underground Economy of Spam: A Botmaster’s Perspective
of Coordinating Large-Scale Spam Campaigns. In
Proceedings of the USENIX Workshop on Large-Scale
Exploits and Emergent Threats, 2011.
[26] L. Zhang and Y. Guan. Detecting Click Fraud in
Pay-Per-Click Streams of Online Advertising Networks. In
Proceedings of the IEEE Conference on Distributed
Computing Systems, 2008.
290Summary Review Documentation for 
“Understanding Fraudulent Activities in Online Ad 
Exchanges” 
Authors: B. Stone-Gross, R. Stevens, A. Zarras, C. Kruegel, R. Kemmerer, G. Vigna 
Reviewer #1 
Strengths:  The  paper  takes  a  fascinating  look  at  an  area  of 
Internet  activity  that  is  usually  hidden.  I  am  not  aware  of  other 
quantitative, trace-based analysis of online ad fraud, and if that is 
correct (is it?) then it makes a good case for accepting this paper.  
Weaknesses:  The  paper  feels  very  anecdotal.  It  is  a  mix  of 
different  tidbits  and  there  is no ground truth on which to assess 
how well the fraud detection classifiers work. (I do not doubt that 
they  turn  up  fraud  in  the  worst  cases,  but  have  little  sense  for 
whether they tag legitimate activity or miss lots of fraud.) Being a 
bit more systematic in the analysis would help, including precise 
descriptions  of  the  trace  and  graphs/stats  for  the  range  of 
presumed normal ad-serving behavior. 
Comments to Authors:  I enjoyed reading your paper, as much 
for  finding  out  how  ad  exchanges  work  as  for  learning  about 
fraud, and I have relatively few comments. 
Can you put fraud in perspective? For example, do you have an 
estimate (perhaps from your classifier) as to what percentage of 
the revenue is lost to fraud? Maybe this is small, but it could be 
compared to other systems such as credit cards. 
Explaining the mechanisms as a figure with a numbered sequence 
of steps would be helpful. The free-form prose is difficult to put 
into an overall picture.  
Say somewhere that CPM is the cost per 1000 impressions.  
Generally,  your  descriptions  are  often  unsatisfying  where  they 
could  be  more  informative!  For example, you say the data is in 
RighMedia’s custom format and you use the following 10 fields. 
Well, I’d like to know basic information about the overall trace. 
How big is it, in MB and records? XML or something else? How 
many records are there of what type? Are the fields you look at 
most of a record, or are there many more fields? etc. Maybe all of 
this information isn’t necessary, but it would help me grasp what 
you are working with. 
Say somewhere that classifier warnings are what you interpret as 
fraud  and  they  occur  when  the  thresholds  you  gave  earlier  are 
exceeded. Seems obvious, but you never come out and say it. 
I did not understand the cookie fraud. The cookie is set by the ad 
system.  Why  can’t  the  host  simply  clear  ad  system  cookies and 
appear to be a fresh, new client? 
Reviewer #2 
Strengths: The paper presents a real and challenging problem. It 
would  be  useful  to  publish,  both  because  it  explains  complex 
types of fraud that are not well/widely understood by the network 
community,  and  because  it  provides  evidence  based  on  real 
measurements that such fraud occurs in practice. 
Weaknesses:  The  methodology  used  by  the  authors  to  estimate 
the  number  of  fraud  incidents  is  not  convincing  (it  relies  on 
thresholds that are not justified, hence seem arbitrary). The types 
of fraud that are described have already been identified by prior 
work. 
Comments  to  Authors:    One  weakness  of  the paper is that the 
types  of  fraud  that  it  describes  have  already  been  identified  by 
prior  work.  To  me,  the  paper  was  fascinating,  because  I  do  not 
know  the  area  and  I  found  it  extremely  useful  to  read  such  a 
detailed  overview  of  how  online  ad  exchanges  work  and  what 
opportunities for abuse they offer. However, I think that the paper 
would be less useful to an expert.  
My  main  complaint  has  to  do  with  the  methodology  used  to 
estimate the number of fraud incidents. As the paper describes it, 
it seems to consist of setting a bunch of thresholds and counting 
how  many  times  they  were  violated.  For  example,  the  click-
through-rate (CTR) threshold for a single IP subnet is set to 0.2%, 
while the CTR threshold for a single cookie is set to 0.3%. Why 
the  difference?  I  am  sure  that  the  authors  had  good  reasons  for 
picking these thresholds, but they should explain them. 
A less important complaint has to do with presentation. The paper 
targets  a  general  networking  audience,  not  just  the  experts 
(otherwise it would not be describing how online add exchanges 
work  nor  explaining  attacks  that  were  the  topic  of  prior  work). 
Yet it does not clearly explain the most confusing aspects of the 
story. For example: 
- In Section 4.1, I recommend that the authors clearly state how 
an ad network sets and uses cookies, and what the attacker does 
with  them  (I  presume  that  the  attacker  obtains  one  valid  cookie 
and sends it to multiple bots).  
-  The  whole  story  about  spoofing  the  referrer’s  site:  It  is 
mentioned  in  2.8  and  3.4  without  being  explained,  then  sort-of-
explained in 4.2. I got it in the end, but only after going back and 
forth several times.  
- In Section 4.3, the paragraph on “Spoofing Section IDs”: At first 
it talks about fraudsters spoofing the referrer but using their own 
section  IDs.  Then  it  talks  about  obfuscating  fraud  by  mixing 
benign  with  fraudulent  section  IDs  (which,  if  I  understand 
correctly,  is  different  --  the  fraudster  sometimes  points  the 
291to  do  with 
browser to a good site, as opposed to one of her own fraudulent 
sites). I recommend separating these two scenarios. 
Another  minor  complaint  has 