### Adaptive Throttling Algorithm

To manage network traffic, we first sort the connections from quietest to loudest. We then select and throttle the loudest fraction \( T \) of connections, where \( T \) is a configurable threshold. For instance, setting \( T \) to 0.1 means that the loudest 10% of client connections will be throttled. The selection is adaptive because the Exponentially Weighted Moving Average (EWMA) changes over time based on each connection's bandwidth usage.

Once the connections to be throttled are adaptively selected, we need to determine the throttle rate. To do this, each connection must track its throughput over time. We choose the average throughput rate of the connection with the minimum EWMA from the set of connections being throttled. For example, if \( T = 0.1 \) and there are 100 client connections sorted from loudest to quietest, the chosen throttle rate is the average throughput of the tenth connection. Each of the first ten connections is then throttled at this rate. In our prototype, we approximate the throughput rate as the average number of bytes transferred over the last \( R \) seconds, where \( R \) is a configurable parameter. \( R \) represents the period between which the algorithm re-selects the throttled connections, adjusts the throttle rates, and resets each connection’s throughput counters.

#### Caveat
In our experiments, we observed that occasionally the throttle rate chosen by the threshold algorithm was zero. This occurred if the mean throughput of the threshold connection did not send data over the last \( R \) seconds. To prevent a throttle rate of zero, we added a parameter to statically configure a throttle rate floor \( F \), ensuring no connection would ever be throttled below \( F \). Algorithm 3 details the threshold adaptive throttling process.

### Experiments

In this section, we explore the performance benefits of each throttling algorithm specified in Section 3. We use Shadow [2, 31], an accurate and efficient discrete event simulator that runs real Tor code over a simulated network. Shadow allows us to run an entire Tor network on a single machine and configure characteristics such as network latency, bandwidth, and topology. Since Shadow runs real Tor, it accurately characterizes application behavior, allowing us to focus on the experimental comparison of our algorithms. A direct comparison between Tor and Shadow-Tor performance is presented in [31].

#### Experimental Setup
Using Shadow, we configured a private Tor network with 200 HTTP servers, 950 Tor web clients, 50 Tor bulk clients, and 50 Tor relays. The distribution of clients in our experiments approximates that found by McCoy et al. [38]. All nodes run inside the Shadow simulation environment.

Each client node runs Tor in client-only mode and an HTTP client application configured to download over Tor’s SOCKS proxy available on the local interface. Each web client downloads a 320 KiB file from a randomly selected HTTP server and pauses for a length of time drawn from the UNC "think time" dataset [27] before downloading the next file. Each bulk client repeatedly downloads a 5 MiB file from a randomly selected HTTP server without pausing. Clients track the time to the first and the last byte of the download as indicators of network responsiveness and overall performance.

Tor relays are configured with bandwidth parameters according to a Tor network consensus document. We configure our network topology and latency between nodes according to the geographical distribution of relays and pairwise PlanetLab node ping times. Our simulated network mirrors a previously published Tor network model [31] that has been compared to and shown to closely approximate the load of the live Tor network [3].

We focus on the time to the first data byte for web clients as a measure of network responsiveness and the time to the last data byte—the download time—for both web and bulk clients as a measure of overall performance. In our results, "vanilla" represents unmodified Tor using a round-robin circuit scheduler and no throttling—the default settings in the Tor software—and can be used to compare relative performance between experiments. Each experiment uses network-wide deployments of each configuration. To further reduce random variances, we ran all configurations five times each. Therefore, every curve on every CDF shows the cumulative results of five experiments.

#### Results
Our results focus on the algorithmic configurations that we found to maximize web client performance [33] while showing how the algorithms perform under varying network loads: light (25 bulk clients), medium (50 bulk clients), and heavy (100 bulk clients). The experimental setup is otherwise unmodified from the model described above. Running the algorithms under various loads highlights the unique and novel features each provides.

Figure 3 shows client performance for our algorithms. The time to the first byte indicates network responsiveness for web clients, while the download time indicates overall client performance for both web and bulk clients. Client performance is shown for the lightly loaded network in Figures 3a–3c, the normally loaded network in Figures 3d–3f, and the heavily loaded network in Figures 3g–3i.

Overall, static throttling results in the least amount of bulk traffic throttling while providing the lowest benefit to web clients. For the bit-splitting algorithm, we see improvements over static throttling for web clients in both time to the first byte and overall download times, while download times for bulk clients are also slightly increased. Flagging and threshold throttling perform more aggressive throttling of bulk traffic and therefore provide the greatest improvements in web client performance.

We find that each algorithm is effective at throttling bulk clients independent of network load, as evident in Figures 3c, 3f, and 3i. However, performance benefits for web clients vary slightly as the network load changes. When the number of bulk clients is halved, throughput in Figure 3b is fairly similar across algorithms. When the number of bulk clients is doubled, responsiveness in Figure 3g and throughput in Figure 3h for both the static throttling and the adaptive bit-splitting algorithm lag behind the performance of the flagging and threshold algorithms. Static throttling would likely require a reconfiguration of throttling parameters, while bit-splitting adjusts the throttle rate less effectively than our flagging and threshold algorithms.

As seen in Figures 3a, 3d, and 3g, as the load changes, the strengths of each algorithm become apparent. The flagging and threshold algorithms stand out as the best approaches for both web client responsiveness and throughput, and Figures 3c, 3f, and 3i show that they are also the most aggressive at throttling bulk clients. The flagging algorithm appears very effective at accurately classifying bulk connections regardless of network load. The threshold algorithm maximizes web client performance in our simulations among all loads and all algorithms tested, as it effectively throttles the worst bulk clients while utilizing extra bandwidth when possible. Both the threshold and flagging algorithms perform well over all network loads tested, and their usage in Tor would require little-to-no maintenance while providing significant performance improvements for web clients.

Aggregate download statistics are shown in Table 1. The results indicate that we are approximating the load distribution measured by McCoy et al. [38] reasonably well. The data also indicates that as the number of bulk clients in our simulation increases, so does the total amount of data downloaded and the bulk fraction of the total, as expected. The data also shows that all throttling algorithms reduce the total network load. Static throttling reduces load the least, while our adaptive flagging algorithm is the best at reducing both overall load and the bulk percentage of network traffic. Each of our adaptive algorithms is better at reducing load than static throttling due to their ability to adapt to network dynamics. The relative difference between each algorithm’s effectiveness at reducing load roughly corresponds to the relative difference in web client performance in our experiments, as discussed above.

### Discussion

The best algorithm for Tor depends on multiple factors. Although not maximizing web client performance, bit-splitting is the simplest, most efficient, and most network-neutral approach (every connection is allowed the same portion of a guard’s capacity). This subtle or delicate approach to throttling may be favorable if supporting multiple client behaviors is desirable. Conversely, the flagging algorithm may be used to identify a specific class of traffic and throttle it aggressively, creating the potential for the largest increase in performance for unthrottled traffic. We are currently exploring improvements to our statistical classification techniques to reduce false positives and improve control over traffic of various types. For these reasons, we feel the bit-splitting and flagging algorithms will be the most useful in various situations. We suggest that bit-splitting is the most appropriate throttling algorithm to use initially, even if something more aggressive is desirable in the long term.

While requiring little maintenance, our algorithms were designed to use only local relay information. Therefore, they are incrementally deployable while relay operators may choose the desired throttling algorithm independently. Our algorithms are already implemented in Tor, and software patches are available [5].

### Analysis and Discussion

Having shown the performance benefits of throttling bulk clients in Section 4, we now analyze the security of throttling against adversarial attacks on anonymity. We discuss the direct impact of throttling on anonymity: what an adversary can learn when guards throttle clients and how the information leaked affects the anonymity of the system. We also discuss potential strategies clients may use to elude the throttles.

Before exploring practical attacks, we introduce two techniques an adversary may use to gather information about the network given that a generic throttling algorithm is enabled at all guards. Similar techniques used for throughput-based traffic analysis outside the context of throttling are discussed in detail by Mittal et al. [39]. Discussion about the security of our throttling algorithms in the context of practical attacks will follow.

#### Gathering Information
Our analysis uses the following terminology. At time \( t \), the throughput of a connection between a client and a guard is \( \lambda_t \), the rate at which the client will be throttled is \( \alpha_t \), and the allowed data burst is \( \beta \). Note that, as consistent with our algorithms, the throttle rate may vary over time, but the burst is a static system-wide parameter.

**Probing Guards:** Using the above terminology, a connection is throttled if, over the last \( s \) seconds, its throughput exceeds the allowed initial burst and the long-term throttle rate:
\[
\sum_{k=t-s}^{t} (\lambda_k) \geq \beta + \sum_{k=t-s}^{t} (\alpha_k)
\]
A client may perform a simple technique to probe a specific guard node and determine the rate at which it gets throttled. The client may open a single circuit through the guard, selecting other high-bandwidth relays to ensure that the circuit does not contain a bottleneck. Then, the client can send a burst of data and observe the throttle rate applied by the guard.