### 4. Stored Observation Results Investigation

In Step 2, Stargazer performs various monitoring activities, such as sending a Ping, checking for the presence of `robots.txt`, performing an HTTP GET request, retrieving the A record for the domain, and taking a screenshot of the web page. To mimic the requests that attackers might receive, Stargazer sets the User-Agent, port number, and other parameters. If `robots.txt` prohibits web crawling, Stargazer refrains from conducting HTTP-related monitoring to adhere to ethical standards.

In Step 4, Stargazer conducts two types of investigations: change detection and difference detection. In change detection, Stargazer compares the current monitoring results with previous ones. If discrepancies are found, it is flagged as a potential early indication of a cyberattack. In difference detection, Stargazer compares the monitoring results across different sensors. If differences exist, it is detected as a potential region-targeted cyberattack.

### 3. MEASUREMENTS

#### 3.1 Experimental Setup

To evaluate the effectiveness of Stargazer, we conducted preliminary monitoring. We selected 1,050 malicious hosts from public URL deny lists, most of which were associated with threat actors.

To understand the impact of geographic location on the responses from these hosts, we deployed sensors in seven regions: Japan, US (West), US (East), Singapore, Germany, England, and Brazil. All sensors were hosted on Amazon Web Service (AWS) instances, as shown in Table 1.

#### 3.2 Results

During the monitoring period from December 2018 to March 2020, we collected 10,929,418 measurements. Our analysis revealed three characteristic cases, described below.

**Case Study 1: Revived Hosts**

A total of 87 hosts, inactive in 2018, were revived in 2019. Figure 2 illustrates the status code transition of one of these hosts from December 2018 to March 2020. Green blocks indicate a response with a 2xx status code, while gray blocks indicate no response. This figure shows that the host was inactive in 2018 and reactivated around December 2019. The host had been reported as malicious before 2018 and was deactivated once. These results suggest that long-used hosts should be monitored even after deactivation, and that the transition characteristics of the status code can help identify attacker attribution. However, some revived hosts may be sink-holed, which can be detected manually by the A record (e.g., 127.0.0.1) or content indicating they are sink-holed. More fine-grained reactivation detection is necessary in the future.

**Case Study 2: Region-Specific Response**

Two hosts responded only to accesses from specific regions: Singapore, US (West), and Japan. Figure 3 shows the status transition of one of these hosts from February 2020 to March 2020. This sample is an Emotet C2 known for targeting Japan and other regions. This suggests that multiregional monitoring can reveal attacks that vary based on the origin of access.

**Case Study 3: Attack Preparation Behavior**

Three hosts were reactivated as web servers with default pages and then started providing malicious content for a short period. Figure 4 depicts the status code and content transition of one of these hosts. The host was revived, served a default Apache page, and later provided potential malicious content before being deactivated. This indicates multiple phases: intervals, preparations, and attacks. It also implies that these hosts are used for short-term attacks and that a simple page can be an early indicator of an attack launch.

In summary, these case studies demonstrate that Stargazer’s continuous and multiregional monitoring is effective in achieving our research goals. Specifically, Stargazer can avoid several monitoring evasions, such as reactivation, region-limited response, and short-term activation. We also obtained the state transition of an attacker’s infrastructure, supporting the achievement of research goal 1. Additionally, we identified potentially significant malicious hosts, such as revived hosts and those responding to specific regions, thereby accomplishing research goal 2. Furthermore, the possibility of using host reactivation and attack phase transition as early indicators supports research goal 3.

### 4. Discussion

We discuss the limitations of our current work and ethical issues.

**Limitations**

Attackers often use cloaking techniques to evade analysis by researchers, displaying malicious sites only to victims and harmless sites to others, including researchers. One method is to return malicious content only to specific target countries. Stargazer can effectively handle this because it has sensors in multiple countries. However, another cloaking method involves deny-listing IP addresses of researchers and returning harmless content for listed IPs. If a sensor’s IP address is added to a deny list, monitoring can be evaded. Since our sensors were deployed on AWS, and Amazon publishes its IP ranges, deny-listing of AWS sensors is possible. Another evasion method involves returning malicious content only to the IP address of a malware-infected device. In future work, we will enhance Stargazer to be more robust against these evasion strategies, such as by regularly changing IP addresses and deploying sensors beyond AWS.

**Ethical Issues**

During monitoring, we made normal communication requests, such as HTTP GET and Ping, to hosts open to the Internet, and no malicious communication was performed. We also checked `robots.txt` and refrained from monitoring if web crawling was prohibited.

### 5. RELATED WORK

Many studies have focused on monitoring suspicious hosts. CyberProbe [4] uses active scanning to detect C2 servers and Listen status bots. Soska et al. [5] proposed a method for predicting site falsification using monitoring data. Invernizzi et al. [6] proposed a cloaking detection method. Although these methods do not involve continuous monitoring, they are highly effective. TARDIS [7] detects CMS-targeting attacks using snapshot content, similar to Stargazer. Barron et al. [8] analyzed attacks from the perspective of honeypot location. Augur [9] captures the onset or termination of censorship with continuous and multiregional monitoring. ICLab [10] is a censorship measurement platform with multiregional sensors. While the focus of these systems differs from Stargazer, they all use continuous and multiregional sensors.

### 6. CONCLUSIONS AND FUTURE WORK

In this paper, we introduced Stargazer, a platform for monitoring malicious hosts. Stargazer continuously monitors malicious sites with multiregional sensors.

We conducted monitoring of 1,050 URLs, obtaining 10,929,418 measurements. Our analysis showed that Stargazer can overcome attackers’ evasion strategies and reveal cyberattack activities. However, our analysis was limited. In future work, we will extend our analysis, exhaustively evaluate Stargazer, increase the number of sensors, and collaborate with more organizations to expand observation coverage. We also plan to monitor malicious hosts for longer periods and improve monitoring methods, such as simulating malware communication. Finally, we aim to create datasets from the results and provide them to the research community.

### ACKNOWLEDGMENTS

This work was supported by the National Institute of Information and Communications Technology. We express our gratitude to all who provided valuable advice and assistance during this study.

### REFERENCES

[1] Kyle Zeeuwen, Matei Ripeanu, and Konstantin Beznosov. 2011. Improving Malicious URL Re-evaluation Scheduling through an Empirical Study of Malware Download Centers. In Proceedings of the 2011 Joint WICOW/AIRWeb Workshop on Web Quality (WebQuality 2011), 42–49.

[2] Amazon. 2020. AWS IP Address Ranges. 2020. http://docs.aws.amazon.com/general/latest/gr/aws-ip-ranges.html

[3] Masood Mansoori, Ian Welch, Kim-Kwang Raymond Choo, Roy A. Maxion, and Seyed Ebrahim Hashemi. 2017. Real-World IP and Network Tracking Measurement Study of Malicious Websites with HAZOP. International Journal of Computers and Applications, 39, 106–121.

[4] Antonio Nappa, Zhaoyan Xu, M. Zubair Rafique, Juan Caballero, and Guofei Gu. 2014. CyberProbe: Towards Internet-Scale Active Detection of Malicious Servers. In Proceedings of the 2014 Network and Distributed System Security Symposium (NDSS 2014), 1–15.

[5] Kyle Soska and Nicolas Christin. 2014. Automatically Detecting Vulnerable Websites Before They Turn Malicious. In Proceedings of the 23rd USENIX Conference on Security Symposium (SEC 2014), 625–640.

[6] Luca Invernizzi, Kurt Thomas, Alexandros Kapravelos, Oxana Comanescu, Jean-Michel Picod, and Elie Bursztein. 2016. Cloak of Visibility: Detecting When Machines Browse a Different Web. 2016 IEEE Symposium on Security and Privacy (S&P 2016), 743–758.

[7] Ranjita Pai Kasturi, Yiting Sun, Ruian Duan, Omar Alrawi, Ehsan Asdar, Victor Zhu, Yonghwi Kwon, and Brendan Saltaformaggio. 2020. TARDIS: Rolling Back the Clock On CMS-Targeting Cyber Attacks. 2020 IEEE Symposium on Security and Privacy (S&P 2020), 1156–1171.

[8] Timothy Barron and Nick Nikiforakis. 2017. Picky Attackers: Quantifying the Role of System Properties on Intruder Behavior. In Proceedings of the 33rd Annual Computer Security Applications Conference (ACSAC 2017), 387–398.

[9] Paul Pearce, Roya Ensafi, Frank Li, Nick Feamster, and Vern Paxson. 2017. Augur: Internet-Wide Detection of Connectivity Disruptions. 2017 IEEE Symposium on Security and Privacy (S&P 2017), 427–443.

[10] Arian Akhavan Niaki, Shinyoung Cho, Zachary Weinberg, Nguyen Phong Hoang, Abbas Razaghpanah, Nicolas Christin, and Phillipa Gill. 2020. ICLab: A Global, Longitudinal Internet Censorship Measurement Platform. 2020 IEEE Symposium on Security and Privacy (S&P 2020), 135–151.