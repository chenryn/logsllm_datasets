title:A Lustrum of Malware Network Communication: Evolution and Insights
author:Chaz Lever and
Platon Kotzias and
Davide Balzarotti and
Juan Caballero and
Manos Antonakakis
2017 IEEE Symposium on Security and Privacy
A Lustrum of Malware Network Communication:
Evolution and Insights
Chaz Lever†, Platon Kotzias∗, Davide Balzarotti∓, Juan Caballero∗, Manos Antonakakis‡
{chazlever,manos}@gatech.edu, PI:EMAIL,
{platon.kotzias,juan.caballero}@imdea.org
† Georgia Institute of Technology, School of Computer Science,
‡ Georgia Institute of Technology, School of Electrical and Computer Engineering,
∗ IMDEA Software Institute, ∓ EURECOM
Abstract—Both the operational and academic security commu-
nities have used dynamic analysis sandboxes to execute malware
samples for roughly a decade. Network information derived
from dynamic analysis is frequently used for threat detection,
network policy, and incident response. Despite these common
and important use cases, the efﬁcacy of the network detection
signal derived from such analysis has yet to be studied in depth.
This paper seeks to address this gap by analyzing the network
communications of 26.8 million samples that were collected over
a period of ﬁve years.
Using several malware and network datasets, our large scale
study makes three core contributions. (1) We show that dynamic
analysis traces should be carefully curated and provide a rigorous
methodology that analysts can use to remove potential noise from
such traces. (2) We show that Internet miscreants are increasingly
using potentially unwanted programs (PUPs) that rely on a
surprisingly stable DNS and IP infrastructure. This indicates
that the security community is in need of better protections
against such threats, and network policies may provide a solid
foundation for such protections. (3) Finally, we see that, for the
vast majority of malware samples, network trafﬁc provides the
earliest indicator of infection—several weeks and often months
before the malware sample is discovered. Therefore, network
defenders should rely on automated malware analysis to extract
indicators of compromise and not to build early detection systems.
I.
INTRODUCTION
Malware analysis is at the forefront of the ﬁght against
Internet threats. Over the last decade, numerous systems have
been proposed to statically and dynamically analyze malicious
software and produce detailed behavioral reports [52], [78].
The vast amounts of data collected by such systems can be
used to provide important reputation information about both
IP and domain name system (DNS) infrastructure, which play
an important role in the state-of-the-art detection engines used
by the security industry.
Despite the fact that an increasing number of companies
and researchers now have access to large malware databases—
often containing millions of samples—little is known about
how the infrastructure and methods used by Internet miscreants
has evolved over time. Previous studies [28], [54], [55], [71],
[80], [81] often used small datasets and performed very speciﬁc
analysis—focusing on topics like the role of cloud providers,
the infrastructure behind drive-by downloads, or the domains
used by few malware families.
To shed light on this important problem, we report the
results of a ﬁve year, longitudinal study of dynamic analy-
sis traces collected from multiple (i.e., two commercial and
one academic) malware feeds. These feeds contain network
information extracted from the execution of more than 26.8
million unique malware samples. We complement this dataset
with over ﬁve billion DNS queries collected from a large North
American internet service provider (ISP). The combination of
these two sources provides a unique view into the network
infrastructure that malware samples have contacted over the
past ﬁve years.
Conducting this long term analysis required us to devise
a comprehensive ﬁltering process to remove benign domains
from our datasets. This process, described in detail in Sec-
tion III, emphasizes the challenges of reducing the inevitable
noise present in any large dataset, and it provides a compre-
hensive list of steps that an analyst can follow to curate the
domains obtained from malware dynamic analysis traces.
Our study also required us to perform the largest malware
classiﬁcation effort to date in order to classify malware samples
into families, differentiate malware from Potentially Unwanted
Programs (PUP), and correlate domains with their most likely
malware families. Our results show that the largest families,
by number of samples, are largely dominated by PUP, but
traditional malware is responsible for the largest volume of
domain resolutions. Our classiﬁcation enables us to perform
the ﬁrst study comparing the network properties of PUP and
malware domains.
After performing rigorous ﬁltering and classiﬁcation, we
proceed with a multi-phase analysis of the dataset. In the ﬁrst
phase, we look at the type, variability, and lifetime of malware
domains. Our results suggest
the security community
should be cautious in how it uses the results from dynamic
malware analysis. For instance, we observed that malware is
potentially ineffective as an early-detection trigger as we often
observe network activity, in the form of valid resolutions of
malware domains, months before the corresponding malware
samples are discovered and dynamically analyzed. Speciﬁcally,
that
© 2017, Chaz Lever. Under license to IEEE.
DOI 10.1109/SP.2017.59
788
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:25:08 UTC from IEEE Xplore.  Restrictions apply. 
two weeks,
we discovered that 302,953 malware domains were active at
least
in some cases many months, before the
corresponding malware samples were analyzed. Thus, orga-
nizations that base their network defenses on DNS blacklists
and dynamic malware analysis may be unaware of potential
threats for signiﬁcant periods of time.
In the second phase of our analysis, we study the evolution
of the IP infrastructure resolved by malware and PUP domains
over time, and we identify three interesting categories of “hot
spots” in the IP space. These categories correspond to (1) IPs
associated with large families that use the same network for
extended periods of time, suggesting signiﬁcant deﬁciencies in
current network and system level defenses; (2) IPs associated
with sinkhole operations run by security organizations; and
(3) IPs associated with hosting providers that are more willing
to tolerate malicious infrastructures, resulting in frequent use
by several families. We also analyze the roles of dynamic
DNS (DDNS) and content delivery network (CDN) services,
as they are both frequently used by malware, and show that
approximately 32% of all malware samples in our dataset
queried at least one dynamic DNS domain. Finally, we measure
the prevalence of domains created by domain generation
algorithms (DGAs) in network communication from malware
samples, and we ﬁnd that at least 44% of the domains from
dynamic malware traces are generated by 42 DGA families
In summary, our study makes the following core contribu-
tions.
First, while dynamic analysis traces can be used as ground
truth and forensic evidence of an infection, they should be
very carefully curated. We provide (Section III) a detailed and
extensive set of rules that network defenders should follow
when they wish to remove potentially benign domain names
from their dynamic analysis traces.
Second, we observe that PUPs are not only on the rise
(Section IV) but also that
they surprisingly utilize a very
stable network IP infrastructure. Our analysis shows that PUP
families host
their infrastructure on popular cloud hosting
providers and CDNs for up to several years. This may indicate
that popular hosting providers do not have the same abuse
policies towards banning PUPs that they use to ﬁght malware.
Third, dynamic malware analysis traces are far from the
ideal source of information for building early warning systems
or detecting new emerging threats. In our analysis, we see
that domain names used in malware communications are active
weeks, sometimes even months, before malware gets discov-
ered and analyzed by the security community (Section V-B2).
This observation has a direct implication on malware domain
name blacklists (Section V-A1). While they are certainly useful
for detecting current and past malware families, they are not
necessarily an efﬁcient method of combating future malware
threats. In fact, our long term study shows (Figure 6) that
malicious domains were added to major blacklists several days
after the malware appeared in one of our feeds and months
after the potentially malicious communication was seen in
passive DNS.
Beyond these contributions, there are three main differ-
entiators between this work and all the previous work that
we build upon. First, we analyze several orders of magnitude
more data than any prior research efforts, and we do so over a
Dataset
Data
Malware Executions
VirusTotal
Passive DNS
Public Blacklists
Alexa
Expired Domains
DGArchive [12]
Samples with DNS
FQDNs
e2LDs
IPs
Reports
Resource Records
FQDNs
e2LDs
IPs
Distinct Blacklists
e2LDs
e2LDs
e2LDs
DGA FQDNs
Count
26.8 M
11.5 M
6.8 M
1.4 M
23.9 M
5.2 B
4.6 B
2.9 M
178.7 M
8
320 K
8 M
179 M
50 M
TABLE I: Summary of datasets used. All datasets correspond
to January 2011–August 2015.
Target
Malware, C&C.
Malware.
Blacklist
Abuse.ch
Malware DL
Blackhole DNS Malware, Spyware.
sagadc
hphosts
SANS
itmate
driveby
Malware, Fraud, SPAM.
Malware, Fraud, Ad tracking.
Aggregate list.
Malicious Webpages.
Drive-by downloads.
Source
[4]
[11]
[5]
[9]
[7]
[10]
[8]
[6]
TABLE II: Summary of the public blacklists used in this study.
much longer observation period—almost ﬁve full years. This
affords us unique insights into how tens of millions of malware
samples have evolved over time. Next, we link network level
communications (e.g., domains and IPs) with system oriented
information (e.g., malware families, PUP). Most existing work
does not attempt to perform both these types of analysis in
concert—let alone at this scale. Finally, we provide temporal
analysis of malware communication over time. This gives
us interesting insight into the relationship between the ﬁrst
observable network communication and discovery of malware
by the community.
It is only fair to acknowledge that our work was possible
because of the many prior efforts in the ﬁelds of malware
and network analysis—the most notable of which we cite.
The fact that our ﬁndings conﬁrm the results of many past
studies lends further weight to their results and serves to make
them more generalizable. We believe the community needs a
combination of both large-scale longitudinal studies and more
focused small-scale studies. The former better captures global
phenomena and general trends while the latter enables more
detailed investigations by allowing for manual analysis and
deeper inspection of trafﬁc.
789
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:25:08 UTC from IEEE Xplore.  Restrictions apply. 
II. DATASETS
Table I summarizes the datasets used in this work. All
data corresponds to the time period from January 1st 2011
to August 31st 2015 unless otherwise noted. We use three
malware executions datasets to obtain the domains resolved
by malware and the IP addresses they resolved to; a passive
DNS dataset to map domains to IP addresses and obtain an
estimation of their query volume; VirusTotal (VT) reports to
obtain additional metadata for the executed malware; public
blacklists to identify dates when malicious domains were
blocked; the historical Alexa top 1M for whitelisting benign
domains; domain expiration dates to mark end of ownership
events; and the DGArchive [12] to identify DGA domains.
Each of these datasets is described in more detail below.
In this paper, we focus on effective second level domains
(e2LDs) rather than fully qualiﬁed domains names (FQDNs)
because e2LDs better capture domain ownership. For example,
the FQDN www.google.com has e2LD google.com,
while www.amazon.co.uk has e2LD amazon.co.uk,
since the second level domain co.uk does not correspond
to the domain owner. Thus, unless otherwise noted, when we
talk about domains we refer to e2LDs and only use FQDNs
for better differentiation when needed.
Malware Executions. We collected all the domain names
resolved by malware samples from three different datasets—
each containing the MD5 of the malware, date of execution in
the sandbox, domain names resolved during the execution, and
IP addresses that domains resolved to. Each malware sample
ran for no more than ﬁve minutes in each of the different
datasets.
We brieﬂy describe the three datasets but will only refer to
their union, after removing duplicate samples, throughout the
rest of the paper .
• U N IV ERSIT Y . This dataset comes from a university-
operated malware execution environment. Collected from
January 2011 to August 2015.
• V EN DOR. This dataset comes from the malware exe-
cution environment of a large security vendor that tracks
spam and e-mail abuse. Collected from September 2014
to August 2015.
• AN U BIS. This dataset comes from the Anubis Web
service [42], where users can upload suspicious samples
for dynamic analysis. Anubis has operated since 2007,
but we focus on executions between January 2011 and
June 2014.
In total, we collected the network behavior of 26.8M
unique malware samples. It
this
number excludes samples without any valid or successful DNS
resolutions.
to note that
is important
VirusTotal Reports (V T ). VirusTotal [17] is an online service
that analyzes ﬁles and URLs submitted by users. Submitted
executables are scanned with multiple AV engines. VT offers
an API to query meta-data on malware samples using a
sample’s hash, and we queried VT using the 26.8M hashes.
For each sample, we collected the time it was ﬁrst observed
by V T , AV analysis date, and AV detection labels. Of the
790
26.8M samples, 89% were known to VT at the time of our
submission (i.e., during the period 2015-16).
Passive DNS (pDN S). Due to agreements with the provider
of this data, we cannot publicly disclose the exact source,
but we can state that this dataset contains passive DNS data
collected from a large ISP in the United States. It contains
the domain names resolved by clients of the ISP and the IP
addresses those domains resolved to. This data was collected
above the recursive DNS server, and therefore, it does not
contain information about the clients making requests—rather
it aggregates resolutions from all clients. In particular, the
dataset contains resource records (i.e.,
timestamp, queried
domain name, and associated RDATA [48], [49]), as well
as domain lookup volumes aggregated on a daily basis. It
comprises 2.9M e2LDs resolving to 178.7M IP addresses.
Public Blacklists (P BL). This dataset contains 320K mali-
cious e2LD entries extracted and aggregated from the eight
public domain blacklists, detailed in Table II, which we
regularly collected and updated for the entire duration of the
project. Due to this aggregation, the dataset includes multiple
types of abusive domains such as drive-by downloads, phish-
ing, and botnet C&C. These domains are curated by members
of the security community and, thus, represent cases of human
veriﬁed abuse. For each domain, the data also provides the
exact date when the domain was included in the blacklist.
Alexa. This dataset contains rankings of the Alexa top million
domains collected daily [2]. It contains approximately 8M
unique e2LDs across our entire analysis period.
Expired Domains. This dataset includes the expiration dates
of 179M (benign and malicious) e2LDs for the past seven
years. These expirations were veriﬁed by recording removals