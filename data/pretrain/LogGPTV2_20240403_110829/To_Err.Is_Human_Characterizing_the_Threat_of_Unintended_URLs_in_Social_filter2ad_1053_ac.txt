0, negative).
The resulting classiﬁer achieves 94% accuracy, 94.3%
precision, 90.6% recall and 92.2% f1 score on our ground
truth dataset. Using this classiﬁer, we can now process the 1%
tweet stream and record the tweets that the classiﬁer predicts to
be including unintended URLs. To make sure that our features
do not overﬁt on our ground truth set, we perform a validation
on independent data in Section IV-A, showing that our model
achieves similar performance on an unseen dataset. After run-
ning our model, we use the identiﬁed URLs both to understand
whether attackers are already abusing them but also, when
possible, to register them so that we can quantify the number of
Twitter users that attackers can victimize. Note that the overall
goal for this classiﬁer is to achieve reasonably high accuracy
while keeping the features interpretable. We, therefore, do not
experiment with neural-network-based classiﬁers that require
signiﬁcantly more ground truth and are difﬁcult to interpret.
B. Unintended URL Crawling
Since unintended URLs in tweets can drive unsuspecting
visitors to potentially malicious websites, we seek to determine
the kind of content that they serve, as well as the extent of
malicious activity that leverages this trafﬁc source. Thus, we
implement an automated URL crawling infrastructure that col-
lects data on all unintended URLs uncovered by our classiﬁer.
Our crawling infrastructure visits each website with an in-
strumented Chrome browser using Selenium [11], and records
the following information: (1) webpage HTML, (2) screenshot,
(3) TLS certiﬁcate, (4) redirect URL and IP address, (5) IP
address information, (6) URL blacklist information, and (7)
Alexa rank.
To reduce the ability of websites to ﬁngerprint our crawler
and cloak malicious content, we take measures to mask our use
of browser instrumentation. This involves changing the HTTP
User-Agent to appear as though the browser is Google Chrome
on a Windows 10 desktop, as well as injecting JavaScript into
each rendered page that modiﬁes global JavaScript variables
(such as navigator.webdriver) to hide signs of browser
automation.
type and amount of trafﬁc that attackers can get when they
weaponize unintended URLs.
Using the data gathered by our crawling infrastructure,
we cluster webpages based on the perceptual hashes of their
screenshots [54]. We then manually label these clusters based
on the content that was recorded by our crawlers.
C. Unintended URL Registration
To determine the trafﬁc directed towards unintended URLs
present in tweets, we register a subset of available domains
(i.e., unintended domain names that are part of tweets and
are also available for registration) and forward trafﬁc to web
servers under our control. There, we record information about
each request
including the client’s IP address and request
headers.
To decide which unintended domains to register, we man-
ually analyze all the unintended URLs from each previous day
and focus on the ones that we reason will reach the most users.
Speciﬁcally, we determine the reach of a tweet by observing
the follower count of the tweet’s author as well as the number
of the tweet’s likes and retweets.
In parallel to the tweets that our classiﬁer discovers as part
of the 1% of global tweets that Twitter offers via its API,
we also deploy an infrastructure that speciﬁcally monitors the
tweets of the most popular Twitter users, searching for tweets
that include domains which are available for registration. In
total, we monitor the tweets of 20,000 users with follower
counts ranging from 11 thousand to 118 million. Whenever
we encounter an unregistered domain tweeted by these top
accounts, the infrastructure — in real-time — automatically
registers that domain and forwards trafﬁc to our webservers.
This allows us to observe trafﬁc from tweets as soon as they
are posted, even in the cases where users later discover their
error and delete the unintended-URL-including tweets.
D. Ethical Considerations
Analyzing social media activity has important ethical im-
plications. In this work, we only analyze data that is publicly
posted on Twitter. For our registered unintended domains, we
do not interact in any way with the users who click on those
links and visit the web pages that we set up. We merely
count the number of visits that a page receives. Additionally,
we argue that by registering these domains we are reducing
potential harm, since we prevent attackers from leveraging
them for malicious purposes. Since all the data that we use
is public and we do not interact with users in any way, this
research is not considered as human subjects research by our
institution’s IRB.
IV. EVALUATION
In the following, we ﬁrst present an experiment to vali-
date our classiﬁer’s accuracy on unseen data. Then, we run
our model on the entire dataset and analyze the detected
unintended URLs in detail, together with the characteristics
of the accounts that posted them. We also report on our
experiment involving the registration of 45 domains that appear
as unintended URLs in our dataset and were available for
registration. This experiment allowed us to characterize the
A. Validation of the Classiﬁer
In Section III-A0c we performed a 10-fold cross validation
on our ground truth set and obtained the following average
performance scores: 94% accuracy, 94.3% precision, 90.6%
recall and 92.2% f1 score. To be that our classiﬁer can gener-
alize to unseen data and rule out overﬁtting concerns, however,
we want to test our classiﬁer on a different dataset than the
one the features were developed on. To this end, we collect
a week of unseen tweets, extract the URLs and apply our
preﬁltering mechanism on this new set. After preﬁltering, we
manually label the resulting URLs as intentional/unintentional
following the same process used to determine our ground truth.
This set consists of 1302 unintended and 1829 intended URLs.
We then train our classiﬁer on the ground truth set, and test
it on this new dataset to get predictions. By comparing the
model’s predictions and the manual labels of this set we obtain
93.3% accuracy, 94.5% precision, 89.1% recall and 91.7%
f1 scores. Since we obtained similar performance scores on
our ground truth set and a completely unseen dataset, we
conclude that our feature set does not overﬁt on the training
set, and can therefore be run in the wild. We also observe that
around 40% of false positive URLs originate from spam tweets
belonging to betting, cryptocurrency, and gaming websites
such as “IQ.Cash,” “GG.bet,” and “iBlocks.Games.”
Particularly, we observe the same spam URL appearing among
the false positives more than once because the spam Twitter
accounts post almost exact tweet containing the URL many
times throughout the day. Our analysis shows that 25% of false
negatives contain either “.so” or “.in” as TLD. These two
words are commonly used to start sentences in spoken English
and having “.so” as TLD is among our features, however, that
was not enough by itself to classify these URLs correctly.
B. Common Properties of Unintended URLs
We ran our daily pipeline for 7 months, between January
2020 and July 2020, recording a total of 26,596 unintended
URLS. Figure 4 shows the daily number of unintended URLs
on Twitter identiﬁed by our analysis pipeline. Overall, 19,195
(72% of the total) domains resulting from unintended URLs
are non existent (NXDOMAINs), while 7,401 (28% of the
total) domains are existing (XDOMAINs). On average, 75% of
the unintended URLs posted every day are non-existing. This
result is expected since an unintentionally posted link would
only be an existing domain name due to pure coincidence.
Our results highlight the threat of adversaries opportunistically
registering these unintended domains and populating them with
arbitrary malicious content.
a) Unintended URL placement: We next look at the
placement of unintended URLs in tweets. We ﬁnd that 23,813
unintended URLs are in the middle of the tweet (89.5%), 2,388
(9%) are at the beginning and 395 (1.5%) reside at the end
of the text. As we said previously, one of the reasons why
unintended URLs tend to appear in the middle of tweets is that
users forget to put a space between two sentences, creating an
unintended URL that combines the last word of the previous
sentence and ﬁrst word of the next sentence. This mistake may
also cause unintended URLs at the beginning or at the end of
7
existing and existing domain names with the highest occur-
rence throughout our experiments.
Four of the existing domains shown in Figure 5 are false
positives: “Iq.cash,” “Bonus.express,” “Of.today”
and “Every.black.” The domain “Bonus.express”
is promoted through spam and all 67 tweets are posted
by the same account. Similarly, all 47 tweets containing
“Of.today” are posted by the same account promoting
a website with many subdomains. Moreover,
tweets with
“Every.black” domain are posted by 11 different accounts
that all appear to belong to the owners of this domain in an
attempt to advertise the website. The tweets containing the
domain “Iq.cash” can also be considered spam since they
all aim to promote a speciﬁc crypto currency. These domains,
especially “Of.today” and “Every.black” carry many
of the unintended URL properties that we identiﬁed in our
preliminary analysis, and could be true positives in other
scenarios.
Among the domains in the top 20, 6 of them are abbre-
viations, which are commonly typed by users and result in
unintended URLs: “B.tech,” “W.va,” “B.sc,” “Prod.by,”
“M.sc” and “Co.ltd.”
Unexpectedly, our analysis also revealed an additional
cause for unintended URLs which we had not considered
when we started this work. Instagram allows users to have
a dot
inside their proﬁle names, while Twitter does not.
This semantic difference makes it so that any time a Twitter
user posts an Instagram proﬁle name in their tweets, this
may result in an unintentional URL if the ﬁnal part of the
proﬁle name happens to be a valid TLD. “D.va,” “J.you,”
“H.one,” “Jaybnow.hr” and “J.one” are examples of
these incorrectly expanded Instagram handles. Again, since
users do not intend to include a link when typing these proﬁle
names, we consider them as unintended URLs which can be
weaponized by attackers by merely registering them.
Among the top 20 domain in Figure 5, four are commonly
appearing in tweets as a consequence of users making typos
(e.g., using a dot instead of space to separate between two
words): “Ac.it,” “You.you,” “I.am” and “Oh.my.” In
total, we record 375 tweets for these URLs. To determine
if they actually are unintended URLs or false positives, we
check a random sample of 10 tweets including each domain
(40 in total). We ﬁnd that all the sampled tweets that include
“Ac.it,” “You.you” and “Oh.my” contain links due to ty-
pographical errors. Hence, we conclude that these three domain
names are unintended URLs. For “I.am” we observe three
different causes. This domain name is expanded when users
mention “will.i.am” to refer to the name or the website
of a famous American rapper. This domain can also be used
inside an Instagram handle or may occur due to a typo. Among
the recorded 124 tweets containing the domain “I.am,” we
observe that 73 of them are referring to the American rapper
“will.i.am” (and are therefore false positives), 20 of them
are typos, 3 are Instagram handles and 28 of those tweets are
unavailable due to the author making their account private or
deleting the tweet, possibly after realizing their mistake.
c) Common TLDs: During our initial assessment of
the issue of unintended URLs in social media, we identiﬁed
several TLDs (e.g., “it,” “my,” “no,” “so,” “you” and “to”)
Fig. 4: Number of unintended URLs per day as detected by of
our model over the whole duration of the experiment. Unregistered
domains (NXDOMAINs) dominate the set of unintended URLs posted
on Twitter.
Fig. 5: Number of tweets vs. Domain Names: The total number of
tweets posted containing the unintended domain name throughout
our experiments. The graph shows the top 10 NX (non-existing) and
X (existing) domains with the highest count.
a sentence if the ﬁrst or last sentence only contains one word.
However, the likelihood of this happening is low since single-
word sentences are uncommon. We observe that if a user wants
to intentionally post a link, one of the common ways to do that
is to ﬁrst write about the website and then place the link at the
end of the sentence usually following a punctuation character
(e.g., “:”). Hence, our results are in line with this observation.
b) Common Domain Names: We next focus on the
domain names that are frequently rendered by Twitter when
expanding unintended URLs. Our goal
is to observe the
most common mistakes and discover any active malicious
campaigns abusing them. Figure 5 shows the top 10 non-
8
Unintended URL
Original Author
Follower Count
NX
X
SEE.YOU
Kobe.Osaka
c.bank
im.mo
kuba.black
raminta.art
PERMANENTLY.MORTGAGE
sign.Hair
shake.You
unexpected.Love
thing.It
moment.In
people.It
tongue.Today
pregnant.My
street.It
Rt.live
movie.Best
airbnb.To
violence.In
Harry Styles
Harry Styles
Reuters
9GAG
9GAG
9GAG
iamcardib
iamcardib
iamcardib
iamcardib
Oprah
deepikapadukone
iamcardib
iamcardib
iamcardib
JKCorden
TechCrunch
dhanushkraja
anandmahindra
marcorubio
34M
34M
22M
16M
16M
16M
13M
13M
13M
13M
42M
27M
13M
13M
13M
11M
10M
8.9M
7.8M
4.2M
Fig. 6: Number of tweets vs. TLDs: The total number of tweets posted
containing the TLD name throughout our experiments. Red patch of
a bar shows the contribution from NX (non-existing) domains and the
green patch shows the contribution from X (existing) domains.
that commonly occur in unintended URLs and we used them
as features in our machine learning model (Section III-A).
Figure 6 shows the top 15 TLDs that are used in unintended
URLs in our dataset.
Our ﬁndings are aligned with our initial assessment since
the resulting top 15 TLDs contain the 6 TLDs that we used
as features. Most of the TLDs plotted in Figure 6 are English
dictionary words that are commonly used at the beginning of a
sentence. For example, “you,” “it,” “no,” “my,” “so,” “in,”
“how,” “now,” “one,” “to,” “love” and “be” are usually
used at the beginning of a regular sentence whereas “am” and
“is” are used at the beginning of questions. Only “sc” is
not used as such but, as mentioned earlier, we can straightfor-
wardly conclude that the high occurrence count is due to the
following abbreviations: “B.sc” and “M.sc.” From Figure 6
we notice that unintended URLs with TLDs that happen to be
dictionary words tend to point to non-existing domains (e.g.,
“.you,” “.how”). TLDs that are dictionary words but also
correspond to a country code (e.g., “.it,” “.no”) point to a
mixture of existing and non-existing domains.
The “.you” TLD is an interesting case because, while