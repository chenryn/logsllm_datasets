performance. Δ-encoded programs must be protected from
TABLE II: Quicksort’s slowdown: comparison of approaches.
DI
1.6
Δ-stripped Δ-parallel Δ-full
2.1
2.4
4.4
ANBD
16.0
all error types: transient, intermittent and permanent, single-
bit and multiple-bit, single faults and multiple faults. Our
experiments show that Δ-encoding (namely the Δ-full variant)
achieves an average fault coverage of 99.997%.
We consider performance slowdowns of 3-4 times accept-
able for our use cases. First of all, safety-critical computa-
tions are usually limited in size and not resource-demanding.
Second, a software-only encoded processing approach is inher-
ently slow, and a slowdown of several times is a signiﬁcant im-
provement compared to the previous works on AN-encoding.
2222
TABLE III: Performance characteristics.
Characteristic
Instructions/cycle
Program
Bubblesort
HardCore
Industrial
Branch misses, % Bubblesort
HardCore
Industrial
native Δ-full Δ-parallel Δ-stripped
2.26
2.70
2.82
6.00
0.00
0.77
1.25
1.78
1.46
9.31
0.00
3.08
2.27
2.73
2.70
4.82
0.00
1.02
2.34
2.61
2.75
6.14
0.00
0.92
Unfortunately, we could not obtain the implementations of
AN-encoding [11] or duplicated instructions [15]. However, we
can perform an indirect comparison on the mutual quicksort
benchmark to put Δ-encoding into perspective (see Table II).
The duplicated instructions approach (DI in the table) reveals
a slowdown of 1.6x in the best case [15]; the ANBD-variant of
AN-encoding has a slowdown of 16x [11]. Δ-encoding shows
performance numbers closer to duplicated instructions, with
the slowdowns of 2–4x. This indicates that Δ-encoding out-
performs previous AN-encoding techniques, adding only a
moderate overhead on top of duplicate execution.
For performance, our approach relies on deep instruction
pipelining, out-of-order execution and sophisticated branch
these techniques enable
prediction in modern CPUs. All
effective scheduling of
instructions. Programs usually do
not utilize instruction pipeline and branch prediction fully.
Δ-encoding takes advantage of an underutilized pipeline and
branch predictor, such that the two copies of data can be
processed in parallel. Table III shows that
the number of
instructions per cycle roughly doubles in Δ-encoded programs,
while the number of branch misses drops drastically11. These
numbers prove that Δ-encoding beneﬁts from heavily utilized
pipeline and branch predictor.
VII. RELATED WORK
Local error detection research has a long history. It began in
1960s with pure hardware approaches used in highly available
servers and space industry; starting from late 1990s, research
focus shifted to software-only approaches, commonly known
as software-implemented hardware fault tolerance (SIHFT).
A. Hardware-based approaches
Hardware-implemented error detection is exempliﬁed by
the evolution of two mainframe systems: IBM S/360 (now
called IBM System z) and Tandem NonStop (now HP
NonStop) [8]. These systems provide massive redundancy
to achieve high availability: lockstepped proprietary CPUs,
redundant CPU logic, ECC-protected memory and caches, and
redundant hardware components and paths. The two systems
guarantee very high fault coverage, but hardware implementa-
tion implies very high economic costs. Δ-encoding can be seen
as a much cheaper alternative to harden only a small subset of
software stack run on commodity hardware.
A cost-effective hardware approach is to use simple check-
ers which observe activities of commodity hardware units and
raise exceptions in case of errors. For example, the DIVA
checker [27] commits CPU outputs only after it veriﬁed their
11In case of HardCore, branch predictor shows perfect results, and there are
0% of branch misses even in native execution.
correctness. Argus [28] implements four independent checkers
to validate four CPU/memory tasks: control ﬂow, data ﬂow,
computation, and memory accesses. Nostradamus [29] is yet
another checker that compares an instruction’s expected impact
on the CPU state to the actual impact on the state. Though the
approaches incur low performance overhead (5-10%), they re-
quire signiﬁcant changes in hardware, whereas Δ-encoding is
purely software-based and provides the same error detection
guarantees.
Symptom-based detection (e.g., ReStore [30]) analyzes
anomalous behavior of hardware such as memory access
exceptions, mispredicted branches and cache misses. However,
the approach cannot offer adequate fault coverage required
in safety-critical systems, detecting only about a half of
propagated faults.
B. Software-based approaches
Redundant Multithreading (RMT) [31] protects from tran-
sient faults by executing two copies of the program on two
cores, periodically comparing their outputs. However,
the
technique assumes existence of a spare core, therefore typical
embedded systems with single-core CPUs cannot beneﬁt from
RMT. In contrast, Δ-encoding requires only one core for
computations.
In duplicated instructions approach, program ﬂow executes
twice on the same core. The approach was ﬁrst proposed
in EDDI [15] and later reﬁned in SWIFT [16]. Both solu-
tions concentrate on transient errors and favor performance
over fault coverage; moreover, SWIFT has an assumption of
ECC-protected memory which does not hold for commodity
and embedded hardware. Interestingly, EDDI’s offshoot called
ED4I [32] is similar to Δ-encoding: it combines data diversity
and duplicated instructions, protecting from permanent faults.
Unfortunately, ED4I was a theoretical attempt and was not
even evaluated for performance, whereas Δ-encoding is a
complete and practical solution.
Encoded processing uses AN codes theory and was ﬁrst
used as a pure hardware approach; an example is a STAR com-
puter designed for spacecrafts [33]. Forin [12] laid the foun-
dations of software-implemented encoded processing, which
was later extensively researched by Schiffel [11]. However,
AN-encoding and variants thereof, which were used in these
works, reveal imbalance in fault coverage versus performance:
pure AN encoding has low fault coverage, ANB- and ANBD-
variants have low performance. Our proposed Δ-encoding pro-
vides balance between the two metrics.
VIII. CONCLUSION AND FUTURE WORK
We presented Δ-encoding, a fault detection mechanism that
covers not only commonly assumed Single Event Upsets, but
also multiple-bit, intermittent and permanent faults. To achieve
high fault coverage, Δ-encoding combines two approaches:
AN codes and duplicated instructions. As our evaluation
shows, Δ-encoding achieves fault coverage of 99.997% at the
cost of an average slowdown of 2-4 times.
Our ﬁrst prototype is a source-to-source transformer. In
our future work, we would like to implement Δ-encoding as
a compiler plug-in. In this way, we will be able to perform
2323
sophisticated data ﬂow analysis to remove redundant accumu-
lations and make the compiler Δ-encoding-aware.
Another direction of future work is a software-hardware
Δ-encoding approach. Accumulations and checks can be
moved out of the critical path and encapsulated in a separate
hardware module. Δ-encoding could also beneﬁt from addi-
tional instructions in Instruction Set Architecture (ISA).
Another interesting implication of Δ-encoding is the re-
covery ability. If a fault affected only one copy of data, it is
detected via AN codes. The second copy of data can be used
to recover the ﬁrst copy, masking the fault, and the execution
can continue. Such recovery schemes are in our future plans.
We envisage security-related applications of Δ-encoding.
Data diversity and the ability to use different pairs of As for
different parts of a program could enable protection against
malicious attacks. We will investigate a combined approach
offering both fault tolerance and security in our future work.
ACKNOWLEDGMENT
The authors thank Oleksii Oleksenko for help with eval-
uation and Andreas Dixius for insightful suggestions. This
work is partly supported by the German Research Foundation
(DFG) within the Cluster of Excellence “Center for Advancing
Electronics Dresden”.
REFERENCES
[1] S. Borkar, “Designing reliable systems from unreliable components:
the challenges of transistor variability and degradation,” Micro, IEEE,
vol. 25, no. 6, pp. 10–16, Nov 2005.
[2] B. Schroeder, E. Pinheiro, and W.-D. Weber, “DRAM errors in the wild:
A large-scale ﬁeld study,” in Proceedings of the Eleventh International
Joint Conference on Measurement and Modeling of Computer Systems,
ser. SIGMETRICS ’09. New York, NY, USA: ACM, 2009, pp. 193–
204.
[3] Y. Kim, R. Daly, J. Kim, C. Fallin, J. H. Lee, D. Lee, C. Wilkerson,
K. Lai, and O. Mutlu, “Flipping bits in memory without accessing them:
An experimental study of DRAM disturbance errors,” in Computer
Architecture (ISCA), 2014 ACM/IEEE 41st International Symposium,
June 2014, pp. 361–372.
[4] E. B. Nightingale, J. R. Douceur, and V. Orgovan, “Cycles, cells
and platters: An empirical analysis of hardware failures on a million
consumer PCs,” Proceedings of EuroSys 2011, April 2011.
[5] M.-L. Li, P. Ramachandran, S. K. Sahoo, S. V. Adve, V. S. Adve, and
Y. Zhou, “Understanding the propagation of hard errors to software and
implications for resilient system design,” SIGOPS Operating Systems
Review, vol. 42, no. 2, pp. 265–276, Mar. 2008.
(2008) Amazon S3 availability event.
//status.aws.amazon.com/s3-20080720.html
(2011) 2009-11 Toyota vehicle recalls.
//en.wikipedia.org/wiki/2009-11 Toyota vehicle recalls
[Online]. Available: http:
[Online]. Available: http:
[6]
[7]
[8] W. Bartlett and L. Spainhower, “Commercial fault tolerance: a tale of
two systems,” Dependable and Secure Computing, IEEE Transactions
on, vol. 1, no. 1, pp. 87–96, Jan 2004.
(2014)
self-driving
com/content/dam/www/public/us/en/documents/white-papers/
automotive-autonomous-driving-vision-paper.pdf
for
http://www.intel.
requirements
Technology
computing
Available:
[9]
cars.
and
[Online].
[10] O. Goloubeva, M. Rebaudengo, M. Sonza Reorda, and M. Violante,
Software-Implemented Hardware Fault Tolerance. Springer, 2006.
[11] U. Schiffel, “Hardware error detection using AN-codes,” Ph.D. disser-
tation, Technische Universit¨at Dresden, 2011.
[12] P. Forin, “Vital coded microprocessor principles and application for
various transit systems,” IFAC/IFIP/IFORS Symposium, 1989.
2424
[13] D. T. Brown, “Error detecting and correcting binary codes for arithmetic
operations,” Electronic Computers, IRE Transactions, vol. EC-9, no. 3,
pp. 333–337, Sept 1960.
[14] U. Schiffel, A. Schmitt, M. S¨ußkraut, and C. Fetzer, “ANB- and
ANBDmem-encoding: Detecting hardware errors in software,” in Com-
puter Safety, Reliability, and Security, ser. Lecture Notes in Computer
Science, E. Schoitsch, Ed., vol. 6351.
Springer Berlin / Heidelberg,
2010, pp. 169–182.
[15] N. Oh, P. Shirvani, and E. McCluskey, “Error detection by duplicated
instructions in super-scalar processors,” IEEE Transactions on Reliabil-
ity, vol. 51, no. 1, pp. 63–75, Mar 2002.
[16] G. Reis, J. Chang, N. Vachharajani, R. Rangan, and D. August,
“SWIFT: software implemented fault tolerance,” in International Sym-
posium on Code Generation and Optimization (CGO), March 2005, pp.
243–254.
[17] G. Saggese, N. Wang, Z. Kalbarczyk, S. Patel, and R. Iyer, “An
experimental study of soft errors in microprocessors,” Micro, IEEE,
vol. 25, no. 6, pp. 30–39, Nov 2005.
[18] S. K. Reinhardt and S. S. Mukherjee, “Transient fault detection via
simultaneous multithreading,” in Proceedings of the 27th Annual Inter-
national Symposium on Computer Architecture, ser. ISCA ’00. New
York, NY, USA: ACM, 2000, pp. 25–36.
[19] P. E. Ammann and J. C. Knight, “Data diversity: An approach to
software fault tolerance,” IEEE Transactions on Computers, vol. 37,
no. 4, pp. 418–425, Apr. 1988.
Intel Corporation, Intel® 64 and IA-32 Architectures Optimization
Reference Manual, September 2014, no. 248966-030.
[20]
[21] M. Rebaudengo, M. Reorda, M. Violante, and M. Torchiano, “A source-
to-source compiler for generating dependable software,” in First IEEE
International Workshop on Source Code Analysis and Manipulation,
2001, pp. 33–42.
[22] AMD Corporation, AMD64 Architecture Programmer’s Manual,
September 2012, vol. System Programming, no. 248966-030.
[23] D. Brumley, T. Chiueh, R. Johnson, H. Lin, and D. Song, “RICH:
Automatically protecting against integer-based vulnerabilities,” in Sym-
posium on Network and Distributed Systems Security, 2007.
[24] EGAS Workgroup, Standardized E-Gas Monitoring Concept for Gaso-
line and Diesel Engine Control Units, Version 5.5 ed., July 2013.
[25] D. Behrens, D. Kuvaiskii, and C. Fetzer, “HardPaxos: Replication
hardened against hardware errors,” in Proceedings of the 33rd IEEE
Symposium on Reliable Distributed Systems (SRDS’14). IEEE, October
2014.
[26] M. R. Guthaus, J. S. Ringenberg, D. Ernst, T. M. Austin, T. Mudge, and
R. B. Brown, “MiBench: A free, commercially representative embedded
benchmark suite,” in Proceedings of the Workload Characterization,
2001. WWC-4. 2001 IEEE International Workshop, ser. WWC ’01.
Washington, DC, USA: IEEE Computer Society, 2001, pp. 3–14.
[27] T. Austin, “DIVA: A dynamic approach to microprocessor veriﬁcation,”
Journal of Instruction-Level Parallelism, vol. 2, 2000.
[28] A. Meixner, M. Bauer, and D. Sorin, “Argus: Low-cost, comprehensive
error detection in simple cores,” in 40th Annual IEEE/ACM Interna-
tional Symposium on Microarchitecture, 2007, Dec 2007, pp. 210–222.
[29] R. Nathan and D. Sorin, “Nostradamus: Low-cost hardware-only error
detection for processor cores,” in Design, Automation and Test in Europe
Conference and Exhibition (DATE), March 2014, pp. 1–6.
[30] N. Wang and S. Patel, “ReStore: symptom based soft error detection in
microprocessors,” in International Conference on Dependable Systems
and Networks (DSN), June 2005, pp. 30–39.
[31] S. S. Mukherjee, M. Kontz, and S. K. Reinhardt, “Detailed design
and evaluation of redundant multithreading alternatives,” SIGARCH
Computer Architecture News, vol. 30, no. 2, pp. 99–110, May 2002.
[32] N. Oh, S. Mitra, and E. McCluskey, “ED4I: error detection by diverse
data and duplicated instructions,” IEEE Transactions on Computers,
vol. 51, no. 2, pp. 180–199, Feb 2002.
[33] A. Avizienis, G. C. Gilley, F. P. Mathur, D. A. Rennels, J. A. Rohr,
and D. K. Rubin, “The STAR (Self-Testing And Repairing) computer:
An investigation of the theory and practice of fault-tolerant computer
design,” IEEE Transactions on Computers, vol. 20, no. 11, pp. 1312–
1321, Nov. 1971.