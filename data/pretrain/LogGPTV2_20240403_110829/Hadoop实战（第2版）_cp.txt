＜description＞HDFS to dump to＜/description＞
＜/property＞
writer. hdfs.filesystem中的hdfs：//master：9000/是Hadoop分布式文件系统的地址，Chukwa将利用它来存储数据，可以根据实际地址对其进行修改。
下面的属性设置用于指定sink data地址（见代码内容），/chukwa/logs/就是它在HDFS中的地址。在默认情况下，Collector监听8080端口（代码如下所示），不过这是可以修改的，各个Agent将会向该端口发消息。
＜property＞
＜name＞chukwaCollector.outputDir＜/name＞
＜value＞/chukwa/logs/＜/value＞
＜description＞Chukwa data sink directory＜/description＞
＜/property＞
＜property＞
＜name＞chukwaCollector.http.port＜/name＞
＜value＞8080＜/value＞
＜description＞The HTTP port number the collector will listen on＜/description＞
＜/property＞
4.Agent的配置
Agent由$CHUKWA_CONF_DIR/agents文件进行配置，该配置文件的格式与$CHUKWA_CONF_DIR/collectors相似，每行代表一台运行Agent的机器。如下所示为我们运行Agent的设置：
master
slave1
slave2
另外，CHUKWA_CONF_DIR/chukwa-Agent-conf.xml文件维护了代理的基本配置信息，其中最重要的属性是集群名，用于表示被监控的节点，这个值被存储在每一个被收集到的块中，以区分不同的集群，如设置cluster名称：cluster="chukwa"。
＜property＞
＜name＞chukwaAgent.tags＜/name＞
＜value＞cluster="chukwa"＜/value＞
＜description＞The cluster's name for this Agent＜/description＞
＜/property＞
另一个可选的节点是chukwaAgent.checkpoint.dir，这个目录是Chukwa运行Adaptor的定期检查点，它是不可共享的目录，并且只能是本地目录，不能是网络文件系统目录。
5.使用Pig进行数据分析
我们可以使用Pig进行数据分析，因此需要额外设置环境变量。要让Pig能够读取Chukwa收集到的数据，即与HBase和Hadoop进行连接，首先需要确保Pig已经正确安装，然后在Pig的classpath中引入Hadoop和HBase的配置文件目录，如下所示：
export PIG_CLASSPATH=$HADOOP_CONF_DIR：$HBASE_CONF_DIR
接下来创建HBASE_CONF_DIR的JAR文件：
jar cf$CHUKWA_HOME/hbase-env.jar$HBASE_CONF_DIR
创建周期性运行的分析脚本作业：
pig-Dpig.additional.jars=${HBASE_HOME}/hbase-0.90.4.jar：${ZOOKEEPER_HOME}/
zookeeper-3.3.2.jar：${PIG_HOME}/pig-0.10.0.jar：${CHUKWA_HOME}/hbase-env.jar
${CHUKWA_HOME}/share/chukwa/script/pig/ClusterSummary.pig
其中hbase-env.jar为上一步刚刚生成的HBASE_CONF_DIR的JAR文件。
17.4.3 Chukwa的运行
在启动Chukwa之前需要启动Hadoop和HBase，之后需要分别启动Collector进程和Agent进程。
1.Collector进程的启动
在单个节点上运行Collector进程可以使用bin/chukwa collector命令，如下所示：
chukwa collector
hadoop@master：～/hadoop-1.0.1/chukwa-incubating-0.5.0$
OK writer.hdfs.filesystem[URI]=hdfs：//master：9000
No checker rules for：chukwaCollector.outputDir
started Chukwa http collector on port 8080
在启动成功后将读出一些系统配置信息，如上所示，Collector进程将监视8080端口。另外，Collector可以作为守护进程运行，其脚本命令是sbin/start-collectors.sh，它将远程登录（SSH）到在conf/collectors配置中列出的Collector地址，并且启动一个Collector进程在后台运行。
脚本命令sbin/stop-collectors.sh则用来关闭Collector进程。另外还可以通过bin/chukwa collector sotp命令来关闭Collector进程。
可以在浏览器中输入http：//collectorhost：collectorport/chukwa?ping=true，其中，collectorhost是Collector的节点，collectorport是相应的端口，如果Collector运行正常，一些统计数据将在页面中显示，例如：
Date：1337780783926
Now：1337780798066
numberHTTPConnection in time window：0
numberchunks in time window：0
lifetimechunks：0
2.Agent进程的启动
在单个节点上启动Agent进程可以使用bin/chukwa agent命令。另外也可以通过sbin/start-agents.sh来启动Agent进程。start-agents.sh脚本将会读取CHUKWA_CONF_DIR/agents文件，并且启动该配置文件中所列出的所有机器的Agent进程。
3.HICC进程的启动
开始运行HICC，输入命令$CHUKWA_HOME/bin/chukwa hicc，如下所示：
hadoop@master：chukwa hicc
hadoop@master：～/hadoop-1.0.1/chukwa-incubating-0.5.0$May 23，2012 6：51：41 AM com.
sun.jersey.api.core.PackagesResourceConfig init
INFO：Scanning for root resource and provider classes in the packages：
org.apache.hadoop.chukwa.rest.resource
org.apache.hadoop.chukwa.hicc.rest
May 23，2012 6：51：42 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO：Root resource classes found：
class org.apache.hadoop.chukwa.hicc.rest.MetricsController
class org.apache.hadoop.chukwa.rest.resource.ViewResource
class org.apache.hadoop.chukwa.rest.resource.UserResource
class org.apache.hadoop.chukwa.rest.resource.WidgetResource
class org.apache.hadoop.chukwa.rest.resource.ClientTrace
May 23，2012 6：51：42 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO：Provider classes found：
class org.apache.hadoop.chukwa.rest.resource.WidgetContextResolver
class org.apache.hadoop.chukwa.rest.resource.ViewContextResolver
May 23，2012 6：51：42 AM com.sun.jersey.server.impl.application.WebApplicationImpl
_initiate
INFO：Initiating Jersey application, version'Jersey：1.10 11/02/2011 04：41 PM'
在Agent进程启动成功后，在Web地址栏输入http：//＜Server＞：＜port＞/hicc即可看到Chukwa的可视化界面。其中，Server是主机名，＜port＞是jetty端口，默认为4080，可以根据需要对$CHUKWA/webapps/hicc.war文件中/WEB-INF/目录下的jetty.xml文件进行修改，如下所示：
＜Call name="addConnector"＞
＜Arg＞
＜New class="org.mortbay.jetty.nio.SelectChannelConnector"＞
＜Set name="host"＞＜SystemProperty name="jetty.host"/＞＜/Set＞
＜Set name="port"＞＜SystemProperty name="jetty.port"default="4080"/＞＜/Set＞
＜Set name="maxIdleTime"＞30000＜/Set＞
＜Set name="Acceptors"＞2＜/Set＞
＜Set name="statsOn"＞false＜/Set＞
＜Set name="confidentialPort"＞8443＜/Set＞
＜Set name="lowResourcesConnections"＞5000＜/Set＞
＜Set name="lowResourcesMaxIdleTime"＞5000＜/Set＞
＜/New＞
＜/Arg＞
＜/Call＞
Chukwa HICC界面如图17-4所示。
图 17-4 HICC界面
在Cluster Status表单中可以看到监控集群的运行情况，如图17-5所示。
图 17-5 HICC监控的集群运行
在DFS Status表单中可以看到分布式文件系统的状态，如图17-6所示。
图 17-6 HICC监控的分布式文件系统运行
也可以单击菜单栏中Options选项的Add Widget（窗件），向网页中添加需要监控的窗件，如图17-7所示。
图 17-7 向HICC添加信息窗
单击信息窗右上角的齿轮，可以打开并选择需要显示的度量指标，如图17-8所示。
图 17-8 在HICC的窗件中选择需要显示的度量指标
4.启动Chukwa的过程
我们可以按照如下顺序启动Chukwa。
1）启动Hadoop和HBase；
2）启动Chukwa：$CHUKWA_HOME/sbin/start-chukwa.sh；
17.5 Chukwa数据流的处理
原始日志收集和聚集的流程是基于Chukwa分布式文件系统（DFS）的。Chukwa文件在HDFS中的存储结构如图17-9所示。
图 17-9 Chukwa分布式文件系统（DFS）的结构
下面介绍Chukwa文件在HDFS中的存储流程。
1）Collector将块写到logs/目录下的*.chukwa文件中，直到达到块的大小（64MB）或超时了，Collector关闭块，并且将logs/*.chukwa改为logs/*.done后缀的文件。
2）DemuxManager每20秒检查一次*.done文件。
如果这些文件存在，那么移动它们到demuxProcessing/mrInput中，之后Demux将在demuxProcessing/mrInput目录下执行MapReduce作业。
如果Demux在三次之内成功整理完成MapReduce文件，那么将demuxProcessing/mrOutput中的文件移动到dataSinkArchives/[yyyyMMdd]/*/*.done中，否则移动执行完MapReduce的文件demuxProcessing/mrOutputdataSinkArchives/InError/[yyyyMMdd]/*/*.done。
3）每隔几分钟PostProcessManager将执行聚集、排序和去除重复文件作业，并且将postProcess/demuxOutputDir_*/[clusterName]/[dataType]/[dataType]_[yyyyMMdd]_[HH].Re移动到repos/[clusterName]/[dataType]/[yyyyMMdd]/[HH]/[mm]/[dataType]_[yyyyMMdd]_[HH]_[N].[N].evt。
4）HourlyChukwaRecordRolling将会每个小时运行一次MapReduce作业，然后将每小时的日志数据划分为以5分钟为日期单位的日志，并且移动Repos/[clusterName]/[dataType]/[yyyyMMdd]/[HH]/[mm]/[dataType]_[yyyyMMdd]_[mm].[N].evt文件到temp/hourlyRolling/[clusterName]/[dataType]/[yyyyMMdd]和repos/[clusterName]/[dataType]/[yyyyMMdd]/[HH]/[dataType]_HourlyDone_[yyyyMMdd]_[HH].[N].evt中，同时将文件保留到Repos/[clusterName]/[dataType]/[yyyyMMdd]/[HH]/rotateDone/路径下。
5）DailyChukwaRecordRolling在凌晨1：30运行MapReduce作业，将以小时为单位的日志归类到以日为单位的日志中，同时保留在repos/[clusterName]/[dataType]/[yyyyMMdd]/rotateDone/路径下。
6）ChukwaArchiveManager大约每半个小时使用MapReduce作业聚集和移除dataSinkArchives中的数据，移动dataSinkArchives/[yyyyMMdd]/*/*.done到archivesProcessing/mrInput和archivesProcessing/mrOutput，以及finalArchives/[yyyyMMdd]/*/chukwaArchive-part-*中。
7）以下目录下的文件将随时间的增长而增加，因此需要定期清理。
finalArchives/[yyyyMMdd]/*
repos/[clusterName]/[dataType]/[yyyyMMdd]/*. evt
17.6 Chukwa与其他监控系统比较
在了解了Chukwa的特点和如何使用之后，大家或许会问Chukwa监控系统与其他监控系统相比有什么特点，下面我们将通过介绍其他监控系统特点来帮助大家了解Chukwa所具有的特点。
Splunk[3-6]
 是一个日志收集和索引分析的商业化系统，它依赖于集中的存储和收集架构，不考虑传输日志的可靠性，然而在高级日志分析领域又有这样的需求：为了满足需求，许多大型互联网公司都已经建了大集群监控和分析高级工具。
存在一些专门的日志收集系统，在这些系统当中，Scribe[7]
 是一个开源的监控系统，它的元数据模型比Chukwa简单，消息是key-value对，其优点是灵活，但是缺点是要求用户设计自己的元数据标准，这使得用户之间很难分享源代码。Scribe的部署由多个服务器组成，它们被安排在有向非循环图中，其中的每一个节点对是否提交和存储接收信息都是有具体规定的。相比Chukwa而言，Scribe没有被设计成兼容传统的应用，被监控的系统必须通过Thrift RPC服务发送消息给Scribe。这样的优点在于避免在通常情况下的本地写开销，使消息可以无误地传输；缺点是在对不适用于Scribe的数据源进行收集时需要额外的处理。相对而言，Chukwa处理这样的问题就平滑得多。Scribe在传送上的可靠性也弱于Chukwa。一旦数据被提交到Scribe服务器，服务器将负责处理该数据，而这个服务器为了后续传送会长时间地缓存数据。这就意味着Scribe服务器故障可能造成数据丢失，同时也没有一个端到端的传输保证，这是因为原始发送者没有保留一个副本。客户端在向多个服务器发送消息时，如果在发送失败之前没有找到一个正常工作的Scribe Server，那么数据将会丢失。
另一个相关的系统是Artemis，它是由Microsoft研究设计的，用来调试大规模Dryad集群。Artemis是为针对上下文而专门设计的：它只在本地处理日志，使用DryadLINQ[9]
 作为处理引擎。该架构的优点是避免了网络中多个副本的冗余，也使系统资源可以重复利用正在分析和已经分析的结果；缺点是如果一个节点坏掉或暂时不能用，查询会给出错误的结果。Artemis没有被设计成使用长期可靠的存储，因为那需要除本地以外的副本；另外，在本地分析对于监控商业服务来说也是不理想的，因为其分析数据功能可能会干扰正在被监控的系统。
还有一些其他监控系统工具，像Astrolabe、Pier和Ganglia[10-12]
 被设计成能帮助用户查询分布式系统监控信息的系统。在所有的情况下，每个被监控机器上的客户端都存储了一定量的数据用于答复查询。因为客户端不收集和存储大数据集的结构化数据，所以它们不适合一般目的的编程模型。它们通过在系统中应用一个特殊的数据聚集策略来实现可扩展性，但是这会耗费较大的系统性能。相比而言，因为Chukwa从收集过程中剥离了分析过程，所以每一个部分部署都可以独立地扩展。
Ganglia擅长实时故障侦测，相对而言，Chukwa会有分钟级的延迟，但考虑到系统能在分钟级处理海量数据，并且能够敏锐侦测到运行变化，同时会对故障诊断有所帮助，而工程师一般不能对秒级别的事件有所反应，所以分钟级的延时是被允许的。
17.7 本章小结
Chukwa作为Hadoop的子项目，既能帮助Hadoop处理其日志，也能利用MapReduce对日志进行分析处理。在Chukwa的帮助下，Hadoop用户能够清晰了解系统运行的状态，分析作业运行的状态及HDFS的文件存储状态，从而对整个分布式系统状态有形象直观的了解。
和Hadoop一样，Chukwa也是一个分布式系统，它虽然构建于Hadoop之上，但是本身也有自己的特点。它利用分布在各个节点上Agent进程中的Adaptor收集各个节点被监控的信息，然后以块的形式通过HTTP Post汇集到Collector，再由它处理后转储到HDFS中。之后这些数据由Archiving处理（去除重复数据和合并数据）提纯，再由Demux利用MapReduce将这些数据转换成结构化记录，并存储到数据库中，HICC通过调用数据库中的数据向用户展示可视化后的系统状态。
要想利用好Chukwa这个工具，就必须对Hadoop的各个配置项都有清晰的认识。同时Chukwa这个项目自身也在不断完善中，感兴趣的读者可以持续跟进。以下是其官网地址：http：//incubator.apache.org/chukwa/。
本章参考资料
[1]J. Tan, X.Pan, S.Kavulya, R.Gandhi, and P.Narasimhan.SALSA：Analyzing Logs as StAte Machines.In First USENIX Workshop on Analysis of System Logs（WASL'08），San Diego, CA, December 2008.
[2]J. Tan, X.Pan, S.Kavulya, R.Gandhi, and P.Narasimhan.Mochi：Visual Log-Analysis BasedTools for Debugging Hadoop.In Workshop on Hot Topics in Cloud Computing（HotCloud'09），San Diego, CA, June 2009.
[3]http：//management. silicon.com/itpro/0，39024675，39157789，00.html.
[4]Burns, Bryan；Killion, Dave；Beauchesne, Nicolas；Moret, Eric；Sobrier, Julien；Lynn, Michael；Markham, Eric；Iezzoni, Chris；Biondi, Philippe；Granick, Jennifer；W. Manzuik, Steve；Guersch, Paul.Security Power Tools.O'Reilly Media, Inc..ISBN 0-596-00963-1.
[5]Schubert, Max；Bennett, Derrick；Gines, Jonathan；Hay, Andrew；Strand, John. Nagios 3 Enterprise Network Monitoring：Including Plug-Ins and Hardware Devices.Syngress.ISBN 1-59749-267-1.
[6]Splunk Inc. IT Search for Log Management, Operations, Security and Compliance.http：//www.splunk.com/，2009.
[7]https：//github. com/facebook/scribe.