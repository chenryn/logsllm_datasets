    ::: para
    `cgconfig.conf`{.systemitem}(5) ------ cgroup 在
    `cgconfig.conf`{.filename} 文件中被定义。
    :::
-   ::: para
    `cgconfigparser`{.systemitem}(8) ------ `cgconfigparser`{.command}
    指令用于解析 `cgconfig.conf`{.filename} 文件并且挂载层级。
    :::
-   ::: para
    `cgcreate`{.systemitem}(1) ------ `cgcreate`{.command}
    指令用于在层级中创建新的 cgroup。
    :::
-   ::: para
    `cgdelete`{.systemitem}(1) ------ `cgdelete`{.command}
    指令用于移除指定的 cgroup。
    :::
-   ::: para
    `cgexec`{.systemitem}(1) ------ `cgexec`{.command} 指令用于在指定的
    cgroup 中运行任务。
    :::
-   ::: para
    `cgget`{.systemitem}(1) ------ `cgget`{.command} 指令用于显示 cgroup
    参数。
    :::
-   ::: para
    `cgsnapshot`{.systemitem}(1) ------ `cgsnapshot`{.command}
    指令用于从现存的子系统中生成配置文件。
    :::
-   ::: para
    `cgred.conf`{.systemitem}(5) ------ `cgred.conf`{.filename} 是
    `cgred`{.systemitem} 服务的配置文件。
    :::
-   ::: para
    `cgrules.conf`{.systemitem}(5) ------ `cgrules.conf`{.filename}
    包含可以确定任务何时归属于某一 cgroup 的规则。
    :::
-   ::: para
    `cgrulesengd`{.systemitem}(8) ------ `cgrulesengd`{.systemitem}
    服务用于将任务分配到 cgroup。
    :::
-   ::: para
    `cgset`{.systemitem}(1) ------ `cgset`{.command} 指令用于为 cgroup
    设定参数。
    :::
-   ::: para
    `lscgroup`{.systemitem}(1) ------ `lscgroup`{.command}
    指令用于将层级中的 cgroups 列表。
    :::
-   ::: para
    `lssubsys`{.systemitem}(1) --- `lssubsys`{.command}
    指令将包含特定子系统的层级列表。
    :::
:::
:::
:::
[]{#chap-Control_Group_Application_Examples.html}
::: chapter
::: titlepage
# [⁠]{#chap-Control_Group_Application_Examples.html#chap-Control_Group_Application_Examples}第 4 章 控制群组应用示例 {.title}
:::
::: para
本章将针对如何使用 cgroup 给出应用示例。
:::
::: section
::: titlepage
# [⁠]{#chap-Control_Group_Application_Examples.html#sec-databases-use_case}4.1. 定义数据库 I/O 的优先级 {.title}
:::
::: para
在数据库服务器专用的虚拟机内部运行数据库服务器实例，让您可以根据数据库的优先级来为其分配资源。请参考下列示例：系统在两个
KVM
虚拟机内部运行两个数据库服务器。一个数据库的优先级较高，另一个较低。当两个数据库服务器同时运行，I/O
吞吐量会降低来均等地容纳两个数据库的请求；如[图 4.1
"不根据优先级分配资源时的 I/O
吞吐量"](#chap-Control_Group_Application_Examples.html#fig-graph_IO_1){.xref}
所示：一旦优先级低的数据库启动（约在时间轴的 45 处），分配给两个服务器的
I/O 吞吐量是相同的。
:::
::: figure
[⁠]{#chap-Control_Group_Application_Examples.html#fig-graph_IO_1}
::: figure-contents
::: mediaobject
![不根据优先级分配资源时的 I/O 吞吐量](images/graph_IO_1.png)
:::
:::
**图 4.1. 不根据优先级分配资源时的 I/O 吞吐量**
:::
::: para
为能优先处理来自优先级高的数据库服务器请求，可将此服务器分配给一个 I/O
操作预留量高的 cgroup，而优先级低的数据库服务器可以分配给一个 I/O
操作预留量少的 cgroup。可按照以下步骤[过程 4.1, "I/O
吞吐量优先化"](#chap-Control_Group_Application_Examples.html#proc-IO_Throughput_Prioritization){.xref}来完成此操作，这些步骤将全部在主机系统上执行。
:::
::: {.procedure xmlns:d="http://docbook.org/ns/docbook"}
[⁠]{#chap-Control_Group_Application_Examples.html#proc-IO_Throughput_Prioritization}
**过程 4.1. I/O 吞吐量优先化**
1.  ::: para
    请确保两项服务的所用资源统计功能，处于开启状态：
    :::
    ``` screen
    ~]# systemctl set-property db1.service BlockIOAccounting=true
    ~]# systemctl set-property db2.service BlockIOAccounting=true
    ```
2.  ::: para
    如果将高优先级和低优先级服务的比率设定为 10：1
    ，那么在这些服务单位中运行的进程将只能使用可用资源：
    :::
    ``` screen
    ~]# systemctl set-property db1.service BlockIOWeight=1000
    ~]# systemctl set-property db2.service BlockIOWeight=100
    ```
:::
::: para
[图 4.2 "根据优先级分配资源时的 I/O
吞吐量"](#chap-Control_Group_Application_Examples.html#fig-graph_IO_2){.xref}
显示了优先处理优先级高的数据库请求，而限制优先级低的数据库的情况。一旦数据库服务器移至恰当的
cgroup（约在时间轴的 75 处），I/O 吞吐量就会在两个服务器间按照 10：1
的比率分配。
:::
::: figure
[⁠]{#chap-Control_Group_Application_Examples.html#fig-graph_IO_2}
::: figure-contents
::: mediaobject
![根据优先级分配资源时的 I/O 吞吐量](images/graph_IO_2.png)
:::
:::
**图 4.2. 根据优先级分配资源时的 I/O 吞吐量**
:::
::: para
或者，块设备 I/O
流量调节功能，可对优先级低的数据库限定其读写操作量。更多信息，请参阅
〈[kernel
管控器专项介绍](#chap-Introduction_to_Control_Groups.html#itemlist-Controller-Specific_Kernel_Documentation){.xref}〉对
`blkio`{.systemitem} 管控器的介绍。
:::
:::
::: section
::: titlepage
# [⁠]{#chap-Control_Group_Application_Examples.html#sec-prioritizing_network_traffic}4.2. 定义网络流量的优先级 {.title}
:::
::: para
在单一服务器系统中运行多项与网络相关的服务时，定义这些服务的网络优先级是很重要的。定义优先级可以保证源自特定服务的数据包比源自其它服务的数据包享有更高优先级。例如，当一台服务器系统同时起到
NFS 服务器和 Samba 服务器的作用时，优先级就显得尤为重要。NFS
必须享有高优先权，因为用户会预期较高吞吐量。Samba
的优先级可以较低，以确保 NFS 服务器有更佳表现。
:::
::: para
`net_prio`{.systemitem} 管控器可以用来为 cgroup
中的进程设定网络优先级。之后，优先级会被转译为 Type Of
Service（TOS，服务类型）比特，并嵌入每一个数据包中。请参照[过程 4.2,
"为共享服务的文件设定网络优先级"](#chap-Control_Group_Application_Examples.html#proc-NFS_prioritization){.xref}
中的步骤给两份文件共享的服务（NFS 和 Samba）配置优先级。
:::
::: {.procedure xmlns:d="http://docbook.org/ns/docbook"}
[⁠]{#chap-Control_Group_Application_Examples.html#proc-NFS_prioritization}
**过程 4.2. 为共享服务的文件设定网络优先级**
1.  ::: para
    `net_prio`{.systemitem} 管控器并未编译进
    kernel，它是一个必须手动装载的模块。如需装载，请输入：
    :::
    ``` screen
    ~]# modprobe netprio_cgroup
    ```
2.  ::: para
    请将 `net_prio`{.systemitem} 子系统附加到
    `/cgroup/net_prio`{.filename} cgroup 中：
    :::
    ``` screen
    ~]# mkdir sys/fs/cgroup/net_prio
    ~]# mount -t cgroup -o net_prio none sys/fs/cgroup/net_prio
    ```
3.  ::: para
    请为各项服务创建其 cgroup：
    :::
    ``` screen
    ~]# mkdir sys/fs/cgroup/net_prio/nfs_high
    ~]# mkdir sys/fs/cgroup/net_prio/samba_low
    ```
4.  ::: para
    如希望 `nfs`{.systemitem} 服务被自动移至 `nfs_high`{.filename}
    cgroup，请将下列行添至 `/etc/sysconfig/nfs`{.filename} 文件:
    :::
    ``` screen
    CGROUP_DAEMON="net_prio:nfs_high"
    ```
    ::: para
    此配置可确保 `nfs`{.systemitem} 服务启动或重启时，`nfs`{.systemitem}
    服务进程已被移至 `nfs_high`{.filename} cgroup。
    :::
5.  ::: para
    `smbd`{.systemitem} 后台驻留程序在 `/etc/sysconfig`{.filename}
    目录中没有配置文件。为实现将 `smbd`{.systemitem}
    后台驻留程序自动移至 `samba_low`{.filename} cgroup，请添加下列行至
    `/etc/cgrules.conf`{.filename} 文件：
    :::
    ``` screen
    *:smbd                net_prio                samba_low
    ```
    ::: para
    请注意：此规则会将每一个 `smbd`{.systemitem} 后台驻留程序（不仅仅是
    `/usr/sbin/smbd`{.filename}）移至 `samba_low`{.filename} cgroup 。
    :::
    ::: para
    您可以用相似的方式为 `nmbd`{.systemitem} 和 `winbindd`{.systemitem}
    后台驻留程序定义规则，将它们移至 `samba_low`{.filename} cgroup。
    :::
6.  ::: para
    请启动 `cgred`{.systemitem} 服务，以载入之前步骤的配置：
    :::
    ``` screen
    ~]# systemctl start cgred
    Starting CGroup Rules Engine Daemon:                       [  OK  ]
    ```
7.  ::: para
    至于此示例的目的，让我们假设两项服务都使用 `eth1`{.systemitem}
    网络接口；给每一个 cgroup 定义优先级：`1`{.literal}
    表示优先级低，`10`{.literal} 表示优先级高：
    :::
    ``` screen
    ~]# echo "eth1 1" > /sys/fs/cgroup/net_prio/samba_low/net_prio.ifpriomap
    ~]# echo "eth1 10" > /sys/fs/cgroup/net_prio/nfs_high/net_prio.ifpriomap
    ```
8.  ::: para
    请启动 `nfs`{.systemitem} 和 `smb`{.systemitem}
    服务以检查各自的进程是否已被移至正确的 cgroup：
    :::
    ``` screen
    ~]# systemctl start smb
    Starting SMB services:                                     [  OK  ]
    ~]# cat /sys/fs/cgroup/net_prio/samba_low/tasks
    16122
    16124
    ~]# systemctl start nfs
    Starting NFS services:                                     [  OK  ]
    Starting NFS quotas:                                       [  OK  ]
    Starting NFS mountd:                                       [  OK  ]
    Stopping RPC idmapd:                                       [  OK  ]
    Starting RPC idmapd:                                       [  OK  ]
    Starting NFS daemon:                                       [  OK  ]
    ~]# cat sys/fs/cgroup/net_prio/nfs_high/tasks
    16321
    16325
    16376
    ```
    ::: para
    现在，源自于 NFS 的网络信息传输比源自于 Samba
    的信息传输有更高的优先级。
    :::
:::
::: para
与[过程 4.2,
"为共享服务的文件设定网络优先级"](#chap-Control_Group_Application_Examples.html#proc-NFS_prioritization){.xref}
相似，`net_prio`{.systemitem}
子系统可以用来为客户应用程序（如火狐）设定网络优先级。
:::
:::
:::
[]{#ch-Subsystems_and_Tunable_Parameters.html}
::: appendix
::: titlepage
# [⁠]{#ch-Subsystems_and_Tunable_Parameters.html#ch-Subsystems_and_Tunable_Parameters}附录 A. 子系统和可调参数 {.title}
:::
::: para
*"子系统"* 是识别 cgroup 的 kernel
模块。通常，它们被看做资源管控器，为不同 cgroup
分配不同级别的系统资源。但是当不同的进程组需要被区别对待时，可以改写子系统与
kernel 间的互动。用于开发新子系统的 *"应用程序编程界面"*（API）记载于
kernel 文档的 `cgroups.txt`{.filename} 中，该文件安装在您系统的
`/usr/share/doc/kernel-doc-kernel-version/Documentation/cgroups/`{.filename}
中（由 [kernel-doc]{.package} 软件包提供）。cgroup 文档的最新版本可在
中找到。请注意：最新文档所述功能可能不与您系统中已安装的 kernel
功能匹配。
:::
::: para
包含 cgroup 子系统参数的*"状态对象"*在 cgroup 的虚拟文件系统中，被描述为
*"伪文件"*。这些伪文件可由 shell
命令或者与其对等的系统呼叫来操作。例如：`cpuset.cpus`{.filename}
是一份指定 cgroup可以存取哪个 CPU 的伪文件。如果
`/cgroup/cpuset/webserver`{.systemitem} 是系统中运行的网页服务器的
cgroup，那么以下命令会被执行：
:::
``` screen
~]# echo 0,2 > /cgroup/cpuset/webserver/cpuset.cpus
```
::: para
因为 `cpuset.cpus`{.filename} 伪文件中写入了 `0,2`{.literal}
值，所以任何任务的 PID 一旦被列入
`/cgroup/cpuset/webserver/tasks/`{.filename}，那么此任务将仅能在系统中使用
CPU 0 和 CPU 2。
:::
::: section
::: titlepage