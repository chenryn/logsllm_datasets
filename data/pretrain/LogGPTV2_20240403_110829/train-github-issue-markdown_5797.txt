# Checklist
  * I have verified that the issue exists against the `master` branch of Celery.
  * This has already been asked to the discussion group first.
  * I have read the relevant section in the  
contribution guide  
on reporting bugs.
  * I have checked the issues list  
for similar or identical bug reports.
  * I have checked the pull requests list  
for existing proposed fixes.
  * I have checked the commit log  
to find out if the bug was already fixed in the master branch.
  * I have included all related issues and possible duplicate issues  
in this issue (If there are none, check this box anyway).
## Mandatory Debugging Information
4.4.0
  * I have included the output of `celery -A proj report` in the issue.  
(if you are not able to do this, then at least specify the Celery  
version affected).
  * I have verified that the issue exists against the `master` branch of Celery.
  * I have included the contents of `pip freeze` in the issue.
  * I have included all the versions of all the external dependencies required  
to reproduce this bug.
## Optional Debugging Information
  * I have tried reproducing the issue on more than one Python version  
and/or implementation.
  * I have tried reproducing the issue on more than one message broker and/or  
result backend.
  * I have tried reproducing the issue on more than one version of the message  
broker and/or result backend.
  * I have tried reproducing the issue on more than one operating system.
  * I have tried reproducing the issue on more than one workers pool.
  * I have tried reproducing the issue with autoscaling, retries,  
ETA/Countdown & rate limits disabled.
  * I have tried reproducing the issue after downgrading  
and/or upgrading Celery and its dependencies.
## Related Issues and Possible Duplicates
#### Related Issues
  * None
#### Possible Duplicates
  * None
## Environment & Settings
**Celery version** :
**`celery report` Output: Started app.
software -> celery:4.4.0 (cliffs) kombu:4.6.7 py:3.7.6  
billiard:3.6.2.0 py-amqp:2.5.2  
platform -> system:Linux arch:64bit, ELF  
kernel version:5.3.0-7625-generic imp:CPython  
loader -> celery.loaders.app.AppLoader  
settings -> transport:amqp results:redis://localhost:6379/0
**
**broker_url: 'amqp://guest: **@localhost:5672//'  
result_backend: 'redis://localhost:6379/0'  
task_routes: {  
'task.add': {'queue': 'add', 'routing_key': '**'},  
'task.log': {'queue': 'log', 'routing_key': ' **'},  
'task.receipt': {'queue': 'receipt', 'routing_key': '**'}}  
task_annotations: {  
'task.log': {'rate_limit': '1/s'}}  
**
# Steps to Reproduce
## Required Dependencies
  * **Minimal Python Version** : N/A or Unknown
  * **Minimal Celery Version** : N/A or Unknown
  * **Minimal Kombu Version** : N/A or Unknown
  * **Minimal Broker Version** : N/A or Unknown
  * **Minimal Result Backend Version** : N/A or Unknown
  * **Minimal OS and/or Kernel Version** : N/A or Unknown
  * **Minimal Broker Client Version** : N/A or Unknown
  * **Minimal Result Backend Client Version** : N/A or Unknown
### Python Packages
**`pip freeze` Output:**
### Other Dependencies
N/A
## Minimally Reproducible Test Case
The below example creates a simple task and 3 queues to receive callbacks when
task is completed. The app is configured to use redis backend, yet when the
callbacks are invoked within celery, it generates new queues in AMQP rather
than using the configured results backend.
    workers
    $ celery -A task worker -n log -Q log --loglevel=info -c 1
    $ celery -A task worker -n receipt -Q receipt --loglevel=info -c 1
    $ celery -A task worker -n "worker" -Q add --loglevel=info
    task.py
    ===================
    from celery import Celery
    CELERY_IGNORE_RESULT = True 
    CELERY_STORE_ERRORS_EVEN_IF_IGNORED = False
    app = Celery('task', backend='redis://localhost:6379/0', broker='amqp://guest@localhost//')
    app.conf.task_routes = {
        'task.add': {
            'queue': 'add',
            'routing_key': 'task.add',
        },
        'task.receipt': {
            'queue': 'receipt',
            'routing_key': 'task.receipt',
        'task.log': {
            'queue': 'log',
            'routing_key': 'task.log'
        }
    }
    app.conf.update(
      task_annotations={
        'task.log': {'rate_limit': '1/s'}
     }
    )
    print("Started app.")
    @app.task
    def add(x, y):
        return x + y
    @app.task
    def receipt(result,id):
       print("Got Result: ",result)
       print("Add Receipt: ",id)
    @app.task
    def log(result,id):
       print("LOG Got Result: ",result)
       print("LOG Add Receipt: ",id)
    run.py
    ======================
    from celery import Celery
    from task import add
    from task import receipt
    from task import log
    for i in range(0,10):
       if i % 2:
          r = add.apply((i,i+10),queue="add",link=log.s(str(i)+","+str(i+10)).set(queue="log"))
       else:
          r = add.apply((i,i+10),queue="add",link=receipt.s(str(i)+","+str(i+10)).set(queue="receipt"))
       print(i,i+10,r.get()) 
       r.forget()
    print("Done")
# Expected Behavior
Callbacks provided in link= arguments in task signatures should respect the
configured backend in the app.
# Actual Behavior
Link callbacks are storing their results in amqp queues instead of the
configured backend.