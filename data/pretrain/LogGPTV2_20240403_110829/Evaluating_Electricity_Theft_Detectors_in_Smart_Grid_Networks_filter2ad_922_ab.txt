theorem.
Theorem 1. Among all changes that lower the mean of an ARMA stochastic
processes, the optimal classiﬁcation algorithm in the Neyman-Pearson sense is
to raise an alarm if ¯2 is greater than a threshold τ : where ¯ = 1
i=1 i, k is
n
the innovation process
(cid:2)n
Yk − E0[Yk|Y1, . . . , Yk−1] where E0 is the expectation under probability p0, (9)
and where we assume ¯ is smaller than zero. (If ¯ ≥ 0 then we decide that there
is no attack.)
Proof. An optimal classiﬁcation algorithm in the Neyman-Pearson sense refers
to a classiﬁer that given a ﬁxed false alarm rate, will maximize the probability of
detection. Given two probability distributions p0 and pγ deﬁning the distribution
of Yi under each class, the optimal classiﬁer in the Neyman-Pearson sense is a
likelihood ratio test:
ln
pγ(Y1, . . . , Yn)
p0(Y1, . . . , Yn)
= − γ
σ
n(cid:3)
i=1
(i +
γ
2
)
(10)
However, we do not know the value of γ as an attacker can choose any arbitrary
value. Therefore we need to use the Generalized Likelihood Ratio (GLR) test to
ﬁnd the maximum likelihood estimate of γ given the test observations Y1, . . . , Yn.
ln
supγ>0 pγ(Y1, . . . , Yn)
p0(Y1, . . . , Yn)
= max
γ>0
n(cid:3)
i=1
(− iγ
σ
− γ2
2σ
)
(11)
218
D. Mashima and A.A. C´ardenas
To ﬁnd the maximum (assuming the constraint γ > 0 is not active):
∂f
∂γ
=
n(cid:3)
i=1
(− i
σ
− γ
σ
) = 0 which implies γ = − n(cid:3)
i=1
= −¯
i
n
(12)
as long as γ > 0 (i.e., the optimization constraint is not active).
Therefore, the ﬁnal GLR test (if ¯  τ , send ˆYi =
Evaluating Electricity Theft Detectors in Smart Grid Networks
219
τ−(1−λ)EW MAi−1
λ
). When EW M Ai−1 = τ , send ˆYi = τ . The idea here
M AX(0,
is that, before the EWMA statistic hits the threshold, an attacker attempts to
reduce the meter-reading value as much as possible, and once it reaches τ , the
attacker sends τ .
On the other hand, the Non-parametric CUSUM statistic for detecting a
change in the mean of a random process is deﬁned by Si = M AX(0, Si−1 +
(μ − Yi − b)) (i = 1, . . . , N ), where μ is the expected value of the time-series,
and b is a “slack” constant deﬁned so that E[|μ − Yi| − b]  τ . Our attack against this CUSUM-based
and send ˆYi = μ − M . Note that
detector is as follows: Calculate M = τ +N b
this attack can take advantage of the total margin calculated as τ + N b.
N
3.4 Unsupervised Learning
One of the most successful algorithms for anomaly detection is the Local Outlier
Factor (LOF) [7]. In our experiments we used RapidMiner [3] to calculate LOF
scores. A LOF detector is implemented as follows:
1. Create a vector containing all measurements of a day to be tested in order,
Vtest = {Y1, . . . , YN} where N is the number of measurements per day.
{Xi1, . . . XiN} (i = 1, . . . , T ).
2. For all days in a training dataset, create vectors in the same way, Vi =
3. Create a set containing Vtest and all Vis, and apply LOF to this set.
4. If LOFtest < τ where LOFtest is a score corresponding to Vtest, conclude
Vtest is normal and exit.
i=1 Yi) < 1
N T
5. If ¯Y (= 1
N
(cid:2)N
(cid:2)T
i=1
(cid:2)N
j=1 Xij , raise an alarm.
Because a high LOF score just implies that the corresponding data point is
considered an outlier, we can not immediately conclude that high LOF score
is a potential energy theft. In order to focus on detecting energy theft we only
consider outliers with lower than average energy consumption.
While we are not able to prove that the following attack against our LOF
detector is optimal because of the complexity of LOF, in the experimental section
we show how our undetected attack patterns for LOF were better than the
optimal attacks against other algorithms.
1. Among daily records in the training dataset whose LOF scores are less than
τ , pick the one with the minimum daily sum, which we denote {Y
2. Find the maximum constant B such that { ˆY1, . . . , ˆYN}, where ˆYi = Y
N}.
∗
i − B,
∗
∗
1 , . . . , Y
does not raise an alarm.
3. Send ˆYi.
4 Experimental Results
We use real (anonymized) meter-reading data measured by an electric utility
company during six months. The meter readings consisted of 108 customers
220
D. Mashima and A.A. C´ardenas
with a mix of residential and commercial consumers. The meter readings were
recorded every 15 minutes. Because our dataset contains measurements that
were sent immediately after installation, we assume the meter readings during
this period are legitimate.
4.1 Adversarial Evaluation: Cost of Undetected Attacks
To complete the evaluation proposed in Section 2, we now deﬁne the cost function
C as follows:
C(Y, ˆY ) = M AX(
N(cid:3)
Yi − ˆYi, 0)
i=1
where Y = {Y1, . . . , YN} is the actual electricity usage and ˆY = { ˆY1, . . . , ˆYN} is
(cid:2)N
i=1 Yi − ˆYi can become
Note that, if the actual usage is very small, the term
the fake meter reading crafted by an attacker.
negative, which means that an attacker will pay more money. We assume that a
sophisticated attacker can turn the attack oﬀ and let real readings go unmodiﬁed
when the actual electricity consumption is expected to be lower than the crafted
meter readings. Under this strategy, the cost is always positive or equal to 0.
There are a number of ways to conﬁgure an electricity-theft detector. Ideally
we would like to train anomaly detections with seasonal information, but given
that our data only covers half a year, experiments in this section focus on a
setting where electricity theft detectors are re-trained daily based on the last
T -days data.
The experiments are conducted as follows. For each customer,
1. Set i = 0
2. Pick records for 4 weeks starting at the ith day as a training dataset (i.e.
T = 28).
3. By using this training data set, compute parameters, including τ .
4. Pick a record of a day just after the training dataset as testing data.
5. Test the data under the detection model trained to evaluate false positive
rate. If the result is negative (i.e. normal), attacks are mounted and the cost
of the undetected attack is calculated.
6. Increment i and go back to Step 2.
Given the limited set of data we had, ﬁnding the optimal training length is
outside the scope of this work. We chose a 4-week sliding window because we
saw on preliminary results that it gave us a good trade-oﬀ between average
loss and false alarms. As we obtain more data, we plan to consider in future
work year-long datasets so we can ﬁt seasonal models into our experiments and
analyze in-depth the optimal training length.
Evaluating Electricity Theft Detectors in Smart Grid Networks
221
ARMA−GLR
Average
CUSUM
EWMA
LOF
0
0
0
0
2
0
0
0
5
1
0
0
0
0
1
]
h
W
[
k
c
a
t
t
A
r
e
p
s
s
o
L
e
g
a
r
e
v
A
0.00
0.05
0.10
False Positive Rate
0.15
0.20
0.25
Fig. 1. Trade-oﬀ between false positive rate (the probability of false alarm) and average
cost per attack
For each detector, we conducted 2,808 tests using the dataset of 108 customers,
and for the cases that were claimed negative, we mounted attacks. The results
are summarized in the trade-oﬀ curves in Fig. 1. The average cost per attack is
calculated by dividing the total cost by the number of attacks performed.
As can be seen from the ﬁgure, the ARMA-GLR detector worked well. The
average detector also is eﬀective, but when the false positive rate is around
5%, its cost is higher than ARMA-GLR by approximately 1 KWh. It was some-
what surprising that the average detector outperformed the two online detectors:
CUSUM and EWMA. One of the problems of these detectors is that they are
designed to detect changes in a random process as quick as possible, and while
this might have advantages for quick detection, it forced us to set very high
thresholds τ to prevent false alarms in the 4-week-long training dataset. Detec-
tors like ARMA-GLR and the average detectors on the other hand, smooth out
sudden changes and are not susceptible to short-term changes of the random
process. The cost of the LOF detector is the largest for all false positive rates
evaluated.
Monetary Loss Caused by Undetected Electricity Theft. While assign-
ing monetary losses to computer attacks is a diﬃcult problem, one of the ad-
vantages of the dataset we have is that our data is directly related to the source
of revenue of the utility company, and thus, it is easier to quantify the costs of
potential attacks.
Using the electricity consumption rate charged by the utility company during
the period of time we have available (while the utility company oﬀers time-of-use
prices, the tested customers belong to the ﬂat rate program) we calculated that
the (lower-bound) average revenue per-customer per-day is  1.256 dollars.
222
D. Mashima and A.A. C´ardenas
]
$
[
s
s
o
L
l
a
u
n
n
A
d
e
t
a
m
i
t
s
E
8
0
+
e
1
6
0
+
e
1
4
0
+
e
1
2
0
+
e
1
No Detector
ARMA−GLR Detector
LOF Detector
1e+00
1e+02
1e+04
# of Compromised Meters
1e+06
]
$
[
s
s
o
L
l
a
u
n
n
A
d
e
t
a