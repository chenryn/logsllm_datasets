a small memory footprint, where the program and the used
portion of their bitmap ﬁt within faster cache levels. In
this section, we evaluate how scaling fares when a large
bitmap (i.e., 2MB) is used. For this experiment, we ran
4, 8, and 12 concurrent instances in the master-secondary
conﬁguration. In this conﬁguration, a single master instance
performs the deterministic fuzzing steps before proceeding
to random fuzzing. The rest are secondary instances that
skip the deterministic step. The output corpus is periodically
synchronized between these instances. This conﬁguration is
standard for all real-world parallel fuzzing sessions.
Figure 9(a) shows the resultant throughput. Each bench-
mark’s throughput is normalized to the corresponding single-
run version to visualize the scaling effect better. The black
line is added as a theoretical reference for 1:1 scaling,
where k instances gain k times the throughput. The bold
red line is the average execution rate across all benchmarks.
It is evident that both BigMap and AFL cannot maintain
1:1 scaling with large maps. The reason is, with multiple
instances and large maps, the working set is much more
likely to exceed the last-level cache capacity. Note that the
last-level cache is shared across all the fuzzing instances.
BigMap performs relatively well since it does not access
the full map, therefore having a smaller effective memory
footprint. AFL scales poorly. The throughput of AFL has
a negative slope above four instances, meaning the total
number of executions actually went down as the number
of instances was increased. The per benchmark speedup
attained by BigMap is given in Figure 9(b). This speedup
is measured by taking the ratio of total test cases generated
by BigMap and AFL with equal number of instances. As
AFL scales poorly with the number of instances compared
to BigMap (demonstrated in Figure 9(a)), it is expected for
the speedup to show a super-linear behavior. On average,
t
u
p
h
g
u
o
r
h
t
d
e
z
i
l
a
m
r
o
N
p
a
m
g
B
h
t
i
i
w
p
u
d
e
e
p
S
BigMap
AFL
1:1
AVG
10 11 12
6
5
4
9
# of fuzzing instances
7
8
10 11 12
1
2
3
(a)
6
5
4
9
# of fuzzing instances
7
8
# of fuzzing instances
12
1
4
8
1
2
3
12
11
10
9
8
7
6
5
4
3
2
1
60
50
40
30
20
10
0
(b)
Figure 9: (a) Throughput (normalized to the single instance)
vs. the number of fuzzing instances. Dotted lines represent
the individual benchmarks from (b), and the solid red line
is their average. The solid black line shows 1:1 scaling as a
reference. (b) Speedup attained by BigMap over AFL. The
coverage map is ﬁxed to 2MB for both (a) and (b).
# of instances: 1 – 4 - 8 - 12
Figure 10: Unique crashes found with a varying number of
fuzzing instances. The coverage map is ﬁxed to 2MB.
BigMap achieved a speedup of 4.9x, 9.2x, and 13.8x for the
4, 8, and 12 concurrent runs, respectively.
Figure 10 depicts a similar trend in the number of unique
crashes found. AFL suffers due to the drop in execution
throughput. For 4, 8, and 12 instances, BigMap found 20%,
36%, and 49% more unique crashes on average. If we
compare the best conﬁgurations available on our hardware
(e.g., 12 instances for BigMap and 4/8 instances for AFL),
BigMap shows an average speedup of 9.2x and uncovers
37% more crashes.
VI. RELATED WORK
Fuzzing as an evolutionary process was ﬁrst introduced
by Sidewinder in 2006 [24]. Since then, most successful
fuzzers have followed this path [6]–[8], [16], [17], [23],
[25]–[28]. A critical component in this evolutionary process
is the ﬁtness function that determines what inputs will be
used as seeds for future fuzzing rounds. AFL and AFL
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 09:23:42 UTC from IEEE Xplore.  Restrictions apply. 
540
based fuzzers [8], [16], [23] use coarse edge hit counts as
the ﬁtness function. Any test vector that exercises a yet-
unseen edge or a seen edge with a different hit count is
considered an interesting input. On the other hand, libFuzzer
based fuzzers [6], [7], [25] leverage compiler support such
as SanitizerCoverage [18] to utilize basic block coverage
as the ﬁtness function. Angora [17] combines function
calling context with edge coverage to differentiate between
interesting test cases covering the same sets of edges but
have unique execution paths. PerfFuzz [29] considers both
execution count and code coverage. Ankou [28] queries
behavioral similarity between a new test case and the current
seeds in the seed pool to determine if it should be considered
as interesting. All of these approaches use some form of
code coverage as the ﬁtness function. BigMap is orthogonal
to these approaches and can be adopted to improve their
ﬁtness functions’ accuracy by reducing collision.
In addition to seed selection, fuzzers can leverage cov-
erage information for scheduling seeds from the seed pool.
AFL schedules ”favored” entries more frequently, and these
entries are determined based on the edge coverage. AFLFast
[16] selects seeds that cover the least frequently traveled
paths. VUzzer [25] uses control-ﬂow graphs to model the
execution path and prioritizes inputs that visit deeper blocks.
Cerebro [30] employs a multi-objective algorithm that takes
code coverage, complexity, and execution time into account
during scheduling the seed. FairFuzz [31] prioritizes seeds
based on rare branch coverage. The intuition being that rare
branches are more likely to hide hard to trigger bugs. Neu-
Fuzz [32] trains a deep neural network model to differentiate
between a vulnerable path from a clean path and prioritizes
the vulnerable one. AFLGo [33] measures branch distance
to select seeds that are closer to predetermined targets. Since
these approaches use coverage feedback in their scheduling
mechanism, hash collisions can obscure the seeds’ priority.
The expressiveness of the coverage metric is another
factor that inﬂuences the collision rate. Angora’s context-
sensitive coverage puts up to eight times more pressure
on the bitmap [17]. Coverage metrics such as N-gram
(hash of last N branches), memory-access-aware branch
coverage, and memory-write-aware branch coverage also
exhibits higher map pressure than simple edge coverage
[12]. Control-ﬂow transformations such as laf-intel [11]
or CmpCov [34] can increase the map pressure as well,
necessitating collision mitigation.
Fuzzers do not need to ﬁxate to a particular coverage
metric or scheduling algorithm. An ensemble of different
fuzzing mechanisms is proven to be an effective strategy
[12], [35]. Ensemble fuzzers run multiple fuzzing instances
with different metrics and periodically cross-pollinate the
inputs. However, unlike BigMap, they do not stack the cov-
erage metrics together, which is still subjected to increased
hash collisions. Comparing BigMap with ensemble fuzzing
is not covered in this work and can be an interesting avenue
for future research.
CollAFL [9] is the state-of-the-art technique for mitigat-
ing hash collisions in coverage bitmap. It leverages static
analysis to distribute edge IDs with a link-time compiler
pass. Blocks with a single incoming edge are assigned
IDs statically. For other blocks,
injected instrumentation
generates the IDs at runtime. It adapts to indirect edges
by considering all blocks with no incoming edges as the
potential branching target. One shortcoming of CollAFL
is that it cannot be extended for coverage metrics other
than the block or edge coverage (e.g., N-gram, Angora).
In addition, it expands the bitmap to ﬁt all the statically
assigned IDs. Our experimental ﬁndings (presented in Table
II) indicate that only a fraction of the static edges are visited
during a fuzzing campaign, making the increase in map
size a source of unnecessary runtime overhead. While both
BigMap and CollAFL aim to solve the hash collision issue,
they are orthogonal mitigation techniques. BigMap can be
used independently of CollAFL to reduce hash collisions. It
can also be used in combination with CollAFL to completely
eliminate collisions while providing more efﬁcient access
to the map. Furthermore, BigMap supports any form of
coverage metric as long as it is recorded in a coverage
bitmap, making it applicable to a wide variety of fuzzers.
VII. CONCLUSION
We investigated the common belief that enlarging bitmaps
to mitigate hash collisions necessarily results in the deterio-
ration of both throughput and quality in fuzzing campaigns.
Our key observation is that the primary source of overhead
stems from frequent map operations performed on the full
bitmap, although only a fraction of the map is under active
use. We proposed BigMap, a two-level bitmap that adds an
extra level of indirection to limit the map operations on the
map’s active regions. Our evaluation results showed 0.98x-
33.1x throughput gain over AFL as we increased the map
size from 64kB to 8MB. BigMap also demonstrated better
scalability with the number of concurrent fuzzing instances.
Furthermore, BigMap’s compatibility with most coverage
metrics, along with its efﬁciency on large maps, enabled
exploring aggressive compositions of coverage metrics and
fuzzing algorithms, uncovering 33% more unique crashes.
By making the use of large maps practical and open-sourcing
BigMap, we hope to enable and spur further research into
the design space of coverage metrics.
ACKNOWLEDGEMENT
This work was supported in part by CRISP, one of the
six centers of JUMP, a Semiconductor Research Corpora-
tion program sponsored by DARPA. This work was also
supported in part by DARPA under contract no. W911NF-
18-C-0019 and FA8750-20-C-0507. The authors also wish to
thank the anonymous reviewers for their time and valuable
feedback.
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 09:23:42 UTC from IEEE Xplore.  Restrictions apply. 
541
REFERENCES
[1] C. Cadar et al., “Klee: unassisted and automatic generation of
high-coverage tests for complex systems programs.” in OSDI,
2008, pp. 209–224.
[2] A. Ahmed and P. Mishra, “QUEBS: Qualifying event based
search in concolic testing for validation of RTL models,” in
ICCD, 2017, pp. 185–192.
[3] Y. Lyu, A. Ahmed, and P. Mishra, “Automated activation
of multiple targets in rtl models using concolic testing,” in
DATE, 2019, pp. 354–359.
[4] A. Ahmed, F. Farahmandi, and P. Mishra, “Directed test
generation using concolic testing on rtl models,” in DATE,
2018, pp. 1538–1543.
[19] J. Naus, “Probabilities for a generalized birthday problem,”
Journal of the American Statistical Association, pp. 810–815,
1974.
[20] “opt
-
llvm
optimizer,”
in
https://llvm.org/docs/CommandGuide/opt.html, 2020.
URL:
[21] B. Nagy, “Crashwalk: Bucket and triage on-disk crashes,” in
URL: https://github.com/bnagy/crashwalk, 2020.
[22] “Fuzzbench
report,”
in
URL:
https://www.fuzzbench.com/reports/2020-08-23/index.html,
2020.
[23] M. Heuse et al., “American fuzzy lop plus plus (aﬂ++),” in
URL: https://github.com/AFLplusplus/AFLplusplus, 2020.
[5] K.
Serebryany,
“Oss-fuzz-google’s
fuzzing service
https://github.com/google/oss-fuzz/, 2020.
for open source
software,”
continuous
in URL:
[24] S. Embleton, S. Sparks, and R. Cunningham, “Sidewinder: An
evolutionary guidance system for malicious input crafting,”
Black Hat, August, 2006.
[6] ——, “Continuous fuzzing with libfuzzer and addresssani-
tizer,” in Cybersecurity Development, 2016, pp. 157–157.
[7] R. Swiecki, “Honggfuzz: A general-purpose, easy-to-use
fuzzer with interesting analysis options,” URL: https://github.
com/google/honggfuzz, 2020.
[25] S. Rawat et al., “Vuzzer: Application-aware evolutionary
fuzzing.” in NDSS, 2017, pp. 1–14.
[26] I. Yun et al., “{QSYM}: A practical concolic execution
engine tailored for hybrid fuzzing,” in USENIX, 2018, pp.
745–761.
[8] M. Zalewski, “American fuzzy lop, v2.52b,” in URL:
https://lcamtuf.coredump.cx/aﬂ/, 2020.
[27] D. She et al., “Neuzz: Efﬁcient fuzzing with neural program
smoothing,” in Security and Privacy, 2019, pp. 803–817.
[9] S. Gan et al., “CollAFL: Path sensitive fuzzing,” in Security
and Privacy, 2018, pp. 679–696.
[28] V. J. Man`es, S. Kim, and S. K. Cha, “Ankou: Guiding grey-
box fuzzing towards combinatorial difference.”
[10] “Fuzzbench: Fuzzer benchmarking as a service,” in URL:
https://github.com/google/fuzzbench, 2020.
[29] C. Lemieux et al., “Perffuzz: Automatically generating patho-
logical inputs,” in SIGSOFT, 2018, pp. 254–265.
[11] “laf-intel:
Circumventing
fuzzing
with
https://clang.llvm.org/docs/SanitizerCoverage.html, 2020.
transformations.”
compiler
roadblocks
URL:
in
[30] Y. Li et al., “Cerebro: context-aware adaptive fuzzing for
effective vulnerability detection,” in ESEC/FSE, 2019, pp.
533–544.
[12] J. Wang et al., “Be sensitive and collaborative: Analyzing
impact of coverage metrics in greybox fuzzing,” in RAID,
2019, pp. 1–15.
[31] C. Lemieux and K. Sen, “Fairfuzz: A targeted mutation
strategy for increasing greybox fuzz testing coverage,” in ASE,
2018, pp. 475–485.
[13] M. Zalewski, “Technical whitepaper for aﬂ-fuzz,” in URL:
https://github.com/google/AFL/blob/master/docs/technical details.txt,
2019.
[14] S. Nagy and M. Hicks, “Full-speed fuzzing: Reducing fuzzing
overhead through coverage-guided tracing,” in Security and
Privacy, 2019.
[15] “Ankou
benchmark
sources,”
in
URL:
https://github.com/SoftSec-KAIST/Ankou-Benchmark, 2019.
[32] Y. Wang et al., “Neufuzz: Efﬁcient fuzzing with deep neural
network,” IEEE Access, pp. 36 340–36 352, 2019.
[33] M. B¨ohme et al., “Directed greybox fuzzing,” in CCS, 2017,
pp. 2329–2344.
[34] M.
Jurczyk,
“Comparecoverage,”
in
URL:
https://github.com/googleprojectzero/CompareCoverage,
2020.
[16] M. B¨ohme, V.-T. Pham, and A. Roychoudhury, “Coverage-
based greybox fuzzing as markov chain,” IEEE Transactions
on Software Engineering, pp. 489–506, 2017.
[17] P. Chen and H. Chen, “Angora: Efﬁcient fuzzing by principled
search,” in Security and Privacy, 2018, pp. 711–725.
[35] C. Salls et al., “Exploring abstraction functions in fuzzing,”
in CNS, 2020, pp. 1–9.
[18] “Clang
sanitizer
coverage,”
in
URL:
https://clang.llvm.org/docs/SanitizerCoverage.html, 2020.
Authorized licensed use limited to: Tsinghua University. Downloaded on October 11,2021 at 09:23:42 UTC from IEEE Xplore.  Restrictions apply. 
542