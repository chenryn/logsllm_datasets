ets (known as trajectory sampling [10]). However, tech-
niques to achieve such consistent sampling will not
work in this adversarial environment since an attacker
can easily generate packets that evade being sampled.
We explored along this direction and found that it is ex-
tremely challenging to design noncryptographic6 tech-
niques to achieve consistent sampling in this adversar-
ial environment. Our scheme, on the other hand, is ro-
bust against the tampering by the attackers, without
resorting to cryptographic techniques.
(ORMS). Independent
3.1.2. One-bit Random Marking and Sam-
pling
random sampling
method does not work well since the correlation fac-
tor between the packets sampled by neighboring
routers is only p, the sampling rate. In this sec-
tion, we present our sampling scheme that signi(cid:12)-
cantly improves this correlation factor. The key idea
of our scheme is that, besides sampling the pack-
ets, a router also marks the sampled packets so that
the next router on the path, seeing the mark, can co-
ordinate its sampling with the previous router to im-
prove the correlation factor. We use a marking (cid:12)eld of
only one bit for this coordination. This bit can be eas-
ily (cid:12)t into many possible locations in the IP header
(e.g., IP fragmentation (cid:12)eld 7 ).
5 Note that O( 1
when p is small.
p2 ) can be orders of magnitude larger than O( 1
p )
6 This is possible with cryptographic techniques. However, it
may involve key distribution and management on hundreds
of thousands of Internet routers.
Our ORMS scheme is presented in Figure 1. This al-
gorithm is executed at every interface of the participat-
ing routers. If an arriving packet has the bit marked,
the bit will be unmarked and the packet will be stored
in Bloom (cid:12)lter digest form. However, if the percent-
age of packets (denoted as r) that are marked among
the arriving packets is over p
2 , it must have been tam-
pered by an attacker (explained next). Our scheme will
only sample and store the marked packets with prob-
ability p
2r . This is the meaning of \subject to a cap of
p
2 " in line 4 of Figure 1. If an arriving packet is not
marked, it will be stored and marked with probabil-
p
ity p
2(cid:0)p comes from will become clear after
next paragraph). A router will also measure the per-
centage of packets coming from itself that is marked. If
this percentage is larger or smaller than p
2 , the router
will adjust it to p
2 by marking and unmarking some bits
(lines 9 & 10 in Figure 1). This can be achieved using
traditional rate-control techniques in networking such
as leaky bucket [32].
2(cid:0)p (where
Consider the path from a remote host to the vic-
tim. We will show that the following two invariants
hold in the approximate sense, when only the (cid:12)rst
hop (a router) from the host have other hosts at-
tached to it and all later hops (routers) are neighbor-
ing with other participating routers only. The (cid:12)rst in-
variant is that approximately p
2 of the packets from
a router will be marked. Note that a router on the
(cid:12)rst hop from the attacker will mark p
2 of the pack-
ets (lines 9 & 10 in Figure 1). This argument certainly
works for every router, but we would like to show that
once the system is \jump-started" to \stationarity",
these two lines almost (subject to a small error (cid:15)) do
not need to be executed at later routers. To see this,
note that at later routers, approximately (1 (cid:0) p
2 ) of
the arriving packets are not marked, and among those
2(cid:0)p (1 (cid:0) p
2 will be marked. Therefore,
once the system is jump-started to stationarity (with
p
2 marked), it remains stationary. The second invari-
ant is that each router, except for the (cid:12)rst hop (which
may sample less than p), will sample approximately
p of the packets. This is because a router will sam-
ple all the packets marked by the upstream neighbors
( p
2 ), and sample another p
2 of packets that are marked
by itself. Finally, it is not hard to verify that, no mat-
ter how an attacker manipulates the marking (cid:12)eld, the
(cid:12)rst router on the attacker’s path will sample at least
p
2 and at most p of the packets coming from the at-
tacker.
2(cid:0)p (cid:1) 2(cid:0)p
2 ) = p
2 = p
p
7 The IP fragmentation (cid:12)eld has been reused in the PPM-based
IP traceback schemes. The \backward compatibility" issues
has been discussed in [28].
if (w.mark = 1) then
write 0 into w.mark;
store the digest of w, subject to a cap of p
2 ;
for each packet w
Sampling procedure at router R
(given sampling rate p):
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
store the digest of w;
write 1 into w.mark;
if (marking percentage is not p
with probability p
2(cid:0)p
else
tune it to p
2 ;
/* make the process \stationary" */
2 ) then
Figure 1: One-bit random marking and sampling
(ORMS) scheme
1
Now we quantitatively analyze the bene(cid:12)t of our
one-bit marking technique. We claim that the expected
correlation factor between two neighboring routers R1
(downstream) and R2 (upstream) is
2(cid:0)p , when R2 is
not on the (cid:12)rst hop from the attacker. This is because
R1 has sampled all p
2 percentage of packets R2 has
marked, and among another p
2 percentage of packets
that R2 has sampled but unmarked, R1 samples
2(cid:0)p
p
of them. The total is p
2(cid:0)p . The cor-
p
2(cid:0)p (sampled by both) divided by p
relation factor is
2(cid:0)p is larger
(sampled by R2), which is
than 50% because 0 > 5; 000, more than one
false positive will occur with high probability. This will
result in almost all Internet routers being convicted.
Since jLRj is much smaller than jLvj, the number of
false positives caused by LR is also much smaller.
3.2. Traceback processing
4. An information-theoretic framework
When the victim detects a DDoS attack, it will trig-
ger a traceback procedure. The victim will (cid:12)rst collect
a decent number of attack packets, which is not di(cid:14)-
cult during a DDoS attack. Then it will use these pack-
ets to track down the attackers. We denote the set of
packets that is used for traceback as Lv, described in
Section 1.2. The size of Lv is typically between 1MB
and 10MB depending on the number of attackers and
the traceback accuracy desired.
The traceback procedure starts with the victim
checking all its immediate neighbors. For any router
S which is one hop away from the victim, the victim
will (cid:12)rst query the corresponding (right date and time)
Bloom (cid:12)lter at S with the whole set Lv. The router S is
added to the attack tree if at least one match is found.
If S is convicted, the set of packets in Lv that match
the Bloom (cid:12)lter of S will be assembled into a set LS.
Each neighbor R of S will then be queried by LS (not
Lv!), if R has not yet been convicted. Again, if at least
one match is found, S convicts R and sends Lv to R;
Otherwise, nothing needs to be done to R by S. If R is
convicted, R will assemble LR, which is the set of pack-
ets in Lv that match the Bloom (cid:12)lter at R. The set LR
will then be used by R to query its neighbors. This pro-
cess is repeated recursively until it cannot proceed.
We now discuss the subtleties involved in our trace-
back processing. In the above algorithm, a router is
convicted if the Bloom (cid:12)lter returns \yes" for at least
one packet. It is important to use \1" as the detec-
tion threshold. Otherwise, an attacker can send identi-
cal packets to avoid detection. This loophole exists be-
In this section we present our information-theoretic
framework that serves as the theoretical foundation of
our traceback scheme. We (cid:12)rst present the problems
that are answered by this framework in Section 4.1.
After brie(cid:13)y introducing the relevant information the-
ory concepts and theorems in Section 4.2, we show how
they are applied to our context in Section 4.3.
4.1. Why do we need a theoretical founda-
tion?
Our information-theoretic framework answers the
following two questions concerning parameter tuning
and the minimum number of attack packets needed for
accurate traceback, respectively.
4.1.1. Parameter tuning. We have discussed in
Section 2.2 that given a resource constraint, the num-
ber of hash functions in each Bloom (cid:12)lter is inversely
proportional to the sampling probability. Clearly there
is an optimal trade-o(cid:11) between these two parameters.
Information theory will help us (cid:12)nd the \sweet spot".
4.1.2. Tradeo(cid:11) between traceback overhead
and accuracy. The
frame-
work also allows us to answer the following question:
information-theoretic
8 One can also use counting Bloom (cid:12)lter [11] or Spectrum Bloom
(cid:12)lter [6] to record the number of occurrences of a packet. De-
tection rules based on multiple packets can be designed ac-
cordingly. However, these schemes are much more complicated.
Also the game-theoretic analysis associated with using the
higher threshold is extremely complex.
\What is the minimum number of attack pack-
ets that the victim has to gather in order to achieve
a traceback error rate of no more than (cid:15)?". This in-
formation is important because it exhibits the funda-
mental trade-o(cid:11) between the number of attack packets
the victim needs to use for traceback, and the ac-
curacy to be achieved. Our solution to this question
also answers a related question: \ How does this num-
ber (of attack packets) scale with respect to certain
system parameters such as the number of attack-
ers?" For example, if the number of attackers grows
from 1,000 to 2,000, how many more attack pack-
ets does the victim have to use to achieve the same
accuracy?
4.2. Information theory background
In this section, we summarize the information theory
concepts and theorems that will be used in our later ex-
ploration. We (cid:12)rst review the concepts of entropy and
conditional entropy. Then we introduce Fano’s inequal-
ity [7], which will be used to answer the question raised
in Section 4.1.2.
4.2.1. Entropy and conditional entropy.
De(cid:12)nition 4.1 The entropy of a discrete random vari-
able X is de(cid:12)ned as
H(X)
def
= (cid:0) Xx2X
Pr[X = x] log2 Pr[X = x]
(1)
where X is the set of values that X can take. The en-
tropy of a random variable X measures the uncertainty
of X, in the unit of bits.
De(cid:12)nition 4.2 The conditional entropy of a random
variable X conditioned on another random variable Y
is de(cid:12)ned as
H(XjY )
def
= (cid:0) Xx2X Xy2Y
(cid:1) log2 Pr[X = xjY = y])
(2)
where Y is the set of values that Y can take. The con-
cept of conditional entropy arises when we are inter-
ested in estimating the value of X, which cannot be ob-
served directly, using the observation of a related ran-
dom variable Y . The conditional entropy H(XjY ) mea-
sures how much uncertainty remains for X given our
observation of Y .
4.2.2. Fano’s inequality. In our analysis, we would
like to estimate the value of X based on the observa-
tion of Y . The conditional entropy H(XjY ) measures
how much uncertainty remains for X given our obser-
vation of Y . Intuitively, the smaller this conditional en-
tropy value is, the more accurate the estimation that
can be made is. This intuition is captured by Fano’s in-
equality [7].
Suppose, given an observation of Y , our estimation
of X is ^X. We denote pe as the probability that this
estimation is incorrect, i.e., pe = Pr[ ^X 6= X]. Fano’s
inequality states the following.
H(pe) + pe log2(jX j (cid:0) 1) (cid:21) H(XjY )
(3)
Here, H(pe) is \overloaded" to stand for the entropy
of the indicator random variable 1f ^X6=Xg. By (1),
H(pe) = (cid:0)pe log2 pe (cid:0) (1 (cid:0) pe) log2(1 (cid:0) pe). In (3), jX j
is the number of di(cid:11)erent values that X can take. If we
are estimating a random variable that will only take
2 possible values (i.e., jX j = 2), Fano’s inequality be-
comes the following simpli(cid:12)ed form:
H(pe) (cid:21) H(XjY )
(4)
Note that, without loss of generality, we can assume
that pe is no more than 0.5 (if a binary estimation pro-
cedure A produces wrong result more than half of the
time, we can simply use A). So Fano’s inequality and
the fact that H is strictly increasing from 0 to 0.5, im-
plies that if we would like the estimation of X (binary-