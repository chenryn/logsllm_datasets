2019. Letters were sent on the Friday of the previous week
to ensure they arrived in the same week as the emails, which
were spread over ﬁve days to avoid triggering rate-based spam
ﬁltering. In total, 48 out of 1337 emails (3.5 %) and 153 out of
2660 letters (5.8 %) could not be delivered and were returned
to the sender. The number for emails must be considered a
lower bound, as many spam ﬁlters discard messages silently.
Survival Analysis To avoid skewed data due to the stag-
gered sending of notiﬁcations, survival times are calculated
from the date the message is expected to be received, i. e.
the day it was sent for emails and July 1st for letters. The
given survival rates and signiﬁcance values are computed for
the last day before the reminders were sent (26–35 days af-
ter the initial notiﬁcations). The results of the signiﬁcance
tests are shown in detail in Appendix A1. The given p-values
are already corrected for multiple comparisons using Holm-
Bonferroni [24] and thus considered signiﬁcant at p ≤ 0.05.
In our survival analysis, all notiﬁcation groups show an
improvement over CONTROL. Figure 2a shows the survival
rates (lower is better) for the different varied factors and
the conﬁdence interval given by Kaplan-Meier. For the con-
tact medium, LETTER had the lowest survival (survival rate
55.6± 1.9%), signiﬁcantly lower than the 66.3± 2.6% for
EMAIL (p < 0.0001). For the different senders, the UNI-LAW
group led to the most remediations, achieving a survival
of 55.0 ± 2.8%. The CITIZEN group came in second with
59.9 ± 2.7% survival, followed by the UNI-CS group with
61.4± 2.7%. However, only the difference between UNI-CS
and UNI-LAW is statistically signiﬁcant at p < 0.05. Finally,
for the different framings, the GDPR+FINE framing had the
lowest survival (50.1± 2.8%), compared to 56.6± 2.8% for
GDPR and 69.6± 2.6% for PRIVACY (all differences were
statistically signiﬁcant).
Comparing the overall highest and lowest survivals of all
18 groups shows the true range of results: while the worst
group (UNI-CS – EMAIL – PRIVACY) resulted in a ﬁve-week
survival of 82.0± 7.5%, the best group (UNI-LAW – LETTER
– GDPR+FINE) signiﬁcantly reduced it to 39.4± 5.6% (see
Table 4 in the Appendix), i. e., more than 60 % of owners
remediated the misconﬁguration. This indicates that the con-
sidered factors can make a signiﬁcant difference, although
even the worst-performing notiﬁcation group is still an im-
provement over sending no notiﬁcation at all, which shows a
survival of 93± 2.4% in the same timeframe. In all cases, the
survival curves drop sharply at the beginning. Most websites
are remediated within 7–10 days.
Websites Going Ofﬂine Some owners took their websites
ofﬂine instead of remediating the GA installation. In total, 59
non-CONTROL websites (1.4 %) were ofﬂine at the end of the
ﬁve-week period. Some owners told us that the websites were
outdated and no longer needed. In the same timeframe, six
websites (1 %) in CONTROL went ofﬂine.
5.1.2 Reminders
We sent a reminder to all owners that received our initial mes-
sage (i. e., it did not bounce) but had not become compliant by
USENIX Association
30th USENIX Security Symposium    2495
Figure 2: Survival rates after initial notiﬁcation and reminders
the 25th of July 2019. Owners that had contacted us to give
updates or ask questions received a hand-crafted reminder, if
appropriate. Email reminders were sent on the 1st and 2nd of
August. For organizational reasons, letters were only sent on
the 6th of August. Even though we did not attempt to contact
owners where the delivery of the initial message had failed,
ﬁve out of 809 reminder emails (0.6%) and 27 out of 1351
reminder letters (2%) were returned as undeliverable.
As mentioned before, due to human error, we sent the
GDPR+FINE framing to all three LETTER – UNI-LAW groups,
contaminating the results. However, we present a brief evalu-
ation of the effects of this mistake.
Survival Analysis For the post-reminder survival analysis,
we only consider owners that received a reminder (i. e., we
exclude those that had already made their site compliant or
where the initial message could not be delivered). For CON-
TROL, we include sites that were still non-compliant as of the
2nd of August, 2019. In Figure 2b, we show the post-reminder
survival for the different groups, considering only the EMAIL
and CONTROL due to the unknown inﬂuence of the incorrect
reminders. It thus cannot be directly compared with Figure 2a.
Results for all groups are shown in Table 4 in the Appendix.
UNI-LAW – LETTER – GDPR+FINE achieved a survival of
54.7± 10% after 24 days. Interestingly, the group with the
highest survival was also a UNI-LAW group (UNI-LAW –
EMAIL – PRIVACY), achieving only 88.1 ± 9.1% survival,
which is still an improvement over CONTROL (97.6± 1.7%).
The overall trends remain similar to the initial message, al-
though with smaller differences between the groups.
Table 1: Survival S in percent and sample size N of UNI-LAW
– LETTER groups after initial notiﬁcation (i) and reminder (r),
survival differences to GDPR+FINE in gray. Results marked
with † erroneously received the GDPR+FINE framing.
Group
R GDPR+FINE
E
T
T
E
L
GDPR
PRIVACY
Si
39.4
55.6 +16.2
62.5 +23.1
Ni
304
294
293
Sr
54.7
68.5 +13.8 †
70.4 +15.7 †
Nr
117
148
169
Accidental Experiment: Increasing the Pressure The er-
roneously sent reminders provide us with the opportunity to
study the effects of starting with a regular notiﬁcation and
then increasing the pressure with a later letter that explicitly
mentions potential ﬁnes. As this experiment was unplanned,
we do not have a control group to compare against and thus
can only describe the observed values without a baseline for
comparison. However, we can compare it with data from the
initial notiﬁcation. We thus take a closer look at the results
from the UNI-LAW – LETTER group, shown in Table 1.
Surprisingly, the survival rate for GDPR was 13.8 percent-
age points higher than that for GDPR+FINE, with PRIVACY
showing an even higher survival. This seems counterintuitive,
as one might expect the groups that had previously received
a less severe message to be “shocked into action” and thus
have at least as many remediations as the GDPR+FINE group.
We have no deﬁnitive explanation for this behavior. How-
ever, when sending out the survey invitations at the end of the
2496    30th USENIX Security Symposium
USENIX Association
a) Survival rates after initial notifications in different groupsb) Survival rates after reminder (email groups only due to error described in Sect. 5.1.2)SenderDayDayDayDayDayDayContactMediumSenderFramingContactMediumFramingTable 2: Survival rate S and CheckGA usage of all (Ua), re-
mediated (Ur), and unremediated (Uu) owners after initial
notiﬁcation and at the end of the study.
Group
Pre-reminder
End of study
CONTROL (end of study)
S [%]
58.8
43.4
90.8
Ua
33.9
46.9
3.1
Ur
65.1
67.6
14.8
Uu
12.5
19.8
1.9
study, we found that some recipients had started recognizing
our messages and stopped reading them in detail, with some
asking us why we were notifying them again about an issue
they had remediated, not realizing that the message contained
an invitation to a survey. Thus, some recipients may have sim-
ply recognized the letterhead, remembered the old message,
and acted according to that.
Websites Going Ofﬂine After the reminder, 31 additional
websites (including two in CONTROL) were ofﬂine.
5.2 CheckGA Usage
We now evaluate our web-based tool CheckGA, which site
owners used to verify their IP Anonymization. CheckGA
performed 38 485 scans for 14 023 sites in total. 12 047 of the
sites are not contained in our dataset. As we did not advertise
the tool, one may assume that those sites that are in our dataset
were predominantly scanned by their respective owners. This
assumption is corroborated by the small fraction of scanned
sites from CONTROL (3.1 %). Under this assumption, half of
the notiﬁed owners (46.9 %) have used the tool at least once
for their site(s). Table 2 shows the assumed fraction of owners
who used the tool and compares owners who remediated the
issue (Ur) with those who did not (Uu).
Scans Over Time Figure 3 shows the number of scans per
day during our observation phase of 9 weeks. First notiﬁca-
tions were sent on Friday of Week 0 (cf. Section 5.1). A scan
is considered a scan of a website in the dataset if either the
domain for the user-provided URL is in the dataset itself or
redirects to a domain that is in the dataset. Related scans are
those in which likely site owners of our study scan other sites
not contained in the dataset. We deﬁne a scan to be related if it
targets a site that is not in the dataset, but there is another scan
targeting a site in the dataset, and both scans are performed by
the same user, identiﬁed by the same TLS session or truncated
IP address on the same day. All other scans are considered
unrelated to the dataset.
Achieving Compliance We also evaluate the number of
CheckGA scans performed until a site in our dataset becomes
Figure 3: User-initiated CheckGA scans per day
compliant. For that, we count the scans until all user-initiated
subsequent scans ﬁnd the site to be compliant. In between,
a site might appear compliant because the owner rendered
GA non-functional while trying to enable IP Anonymization.
Users perform a median of two scans before a site is either
remediated or stays non-compliant without further scans, with-
out major differences in mean (4.5 vs. 4.16). Thus, users either
get IP Anonymization right quickly or give up early.
It took sites a median of 2.22 hours from the ﬁrst scan to re-
mediation, with a considerably larger mean of 5.05 days. The
fastest 25 % of remediating sites became compliant within 3.3
minutes; however, it took over 28 hours to reach 75 % com-
pliance, indicating that there are no outliers, but a signiﬁcant
amount of site owners who need an extended time to remedi-
ate. Considering the lower number of scans, site owners who
need an extended time possibly reach out for help or pass the
issue within their organization.
5.3 Support and Complaints
During the study, we were in contact with many owners who
asked questions about our notiﬁcation, requested help, or ques-
tioned the veracity and authenticity of our message. In total,
we received 946 emails (not counting auto-replies), 41 letters,
and 56 phone calls from 764 recipients. We sent 374 emails,
one letter, and issued twelve phone calls in reply.
Authenticating the Message
In total, 32 recipients (4.2 %
of those in contact with us) contacted us to verify that the
message was authentic. They often chose a different contact
address by searching for the sender online and contacting
them via their personal addresses listed on the university
homepage, or calling phone numbers they found online or in
the letter. Two contacted the sender via Twitter. The tone of
the messages was often friendly and curious, but sometimes
USENIX Association
30th USENIX Security Symposium    2497
hostile, alleging bad intentions or complaining that the mes-
sage was hard to understand. Most could be placated with a
cover story without mentioning that they were part of a study.
Requesting Help 204 recipients (26.7 %) asked questions
about how to remediate the misconﬁguration, requested ver-
iﬁcation of their remediation, or sometimes even offered us
login information for the webserver—so we can ﬁx the prob-
lem for them, “if it is that important to you”. We provided
instructions on addressing the misconﬁguration but did not
take any actions to remediate the websites directly.
Complaints 19 recipients (2.5 %) complained about our
messages. While some were simply unhappy with the un-
solicited message or expressed that the tone of the message
had been stressful for them, others went further and threat-
ened legal action, tried to bill us for the time they spent on
our notiﬁcation, or even contacted the chancellor of one in-
volved university to complain directly. We placated these
recipients and removed them from future messages upon re-
quest. The assistance of our legal collaborators proved in-
valuable in many cases. No legal action was ﬁled against the
involved researchers or universities.
Thanks Finally, we also received messages of gratitude
from 260 recipients (34 %), ranging from simple messages to
offers of payment, discounts, or gifts. Some recipients sent
unsolicited packages with gifts, ranging from free magazines
and mugs to a donation to one involved university. Whenever
possible, we turned down any offered gifts or payments.
5.4 Repair vs. Removal
So far, we have treated GA being anonymized and completely
removed from a website as equivalent (cf. Section 4.7). How-
ever, for site owners, this difference is important, as it changes
the insight they get into the behavior of their users. Surpris-
ingly, we found that of the notiﬁed owners that became com-
pliant, 36% did so by completely removing GA from their site.
This behavior was largely consistent across all experimental
groups, indicating that it was not related to any speciﬁcs of
the notiﬁcation. To investigate the correctness of this result,
we visited 50 of these pages and manually conﬁrmed that
they had removed Google Analytics (and not simply hidden
it behind a cookie consent banner), ﬁnding no false negatives.
5.5 Long-Term Effects
Our analysis so far only considered whether the problem was
solved, but not if it stayed solved. To answer this question,
we crawled all 4754 websites in the study again at the begin-
ning of April 2020 (7 months after the end of the study) to
evaluate how many of the previously-compliant websites had
become non-compliant again. Out of 2224 websites that had
become compliant at the end of the study period, 78 (3.5%)
were non-compliant in April (6 of the 78 in CONTROL). An-
other 38 (1.7%) were unreachable. We thus see a long-term
effectiveness of approximately 95%.
Conversely, of the 2371 sites (550 of which in CONTROL)
that remained non-compliant at the end of the study period,
438 non-control (24.1 %) and 82 from the control group
(14.9 %) were compliant by the beginning of April (not check-
ing consent banners). Another 63 were unreachable. Thus,
the base rate of remediations is low (14.9 % over 7 months),
and the notiﬁcations seem to have caused a slight increase in
the remediation rate even after the study.
6 Survey
To understand their perspective, we invited the website owners
to participate in a survey in the debrieﬁng message. The sur-
vey is shown in the supplementary material [33]. Responses
from 477 owners are included in the following analysis. The
value of participants N varies because the survey did not in-
clude any obligatory questions and some items were follow-up
questions or only shown for certain groups.
6.1 Problem Awareness
371 out of 461 (80.5 %) website owners knew that they were
using GA on their website before being notiﬁed. 272 out
of 462 (58.9 %) had heard of the IP Anonymization feature
before being notiﬁed. 58 out of 458 (12.7 %) were aware
of the missing IP Anonymization before being notiﬁed. We
asked those website owners whose IP Anonymization had not