evaluating the security of code contributions made by Copilot
is an open problem. Aside from manual assessment by a
human security expert there are myriad tools and techniques
to perform security analyses of software [21]. Source code
analysis tools such as static application security testing tools
are designed to analyze source code and/or compiled versions
of code to ﬁnd security ﬂaws; typically they specialize on
identifying a speciﬁc vulnerability class.
In this work, we gauge the security of Copilot’s contri-
butions using a mix of automated analysis using GitHub’s
CodeQL tool [5] (as it can scan for a wider range of security
weaknesses in code compared to other tools) alongside our
manual code inspection. CodeQL is open-source and supports
the analysis of software in languages such as Java, JavaScript,
C++, C#, and Python. Through queries written in its QL query
language, CodeQL can ﬁnd issues in codebases based on a set
of known vulnerabilities/rules. Developers can conﬁgure Cod-
eQL to scan for different code issues and make it available for
academic research (also, it seems fair to use one GitHub tool to
test the other). Prior work used CodeQL to identify vulnerable
code commits in the life of a JavaScript project [22].
There are common patterns in various classes of insecure
code. Such patterns can be considered weaknesses, as
taxonomized by the Common Weakness Enumeration (CWE)
database maintained by MITRE [23]. CWEs are categorized
into
a
a
(plain
code,
comments,
Software development
language)
involves the iterative reﬁnement
software
speciﬁcation
of
implementation—developers write
and
other supporting collateral as they work towards a functional
product. Early work proposed ML-based tools to support
developers through all stages of the software design life-cycle
(e.g., predicting designer effort, extracting speciﬁcations [7]).
With recent advancements in the domain of deep learning (DL)
and NLP, sophisticated models can perform sophisticated
interventions on a code base, such as automated program
repair [8]. In this work, we focus on Copilot as an “AI
pair programmer” that offers a designer code completion
suggestions in “real-time” as they write code in a text editor.
translate
speciﬁcations
language
programming [9], through formal models for automatic code
generation (e.g., [10], [11]) or via machine-learned NLP
[12]. DL architectures that demonstrate good ﬁts for NLP
include LSTMs [13], RNNs [14], and Transformers [15]
that have paved the way for models such as BERT [16],
GPT-2 [17], and GPT-3 [18]. These models can perform
language tasks such as translation and answering questions
from the CoQA [19] dataset; after ﬁne-tuning on specialized
datasets,
the models can undertake tasks such as code
completion [2] and hardware design [20]. State-of-the-art
models have billions of learnable parameters and are trained
on millions of software repositories [2].
automatically
into computer code for natural
are many
efforts
There
to
Copilot is based on the OpenAI Codex family of models [2].
Codex models begin with a GPT-3 model [18], and then
ﬁne-tune it on code from GitHub. Its tokenization step is
nearly identical to GPT-3: byte pair encoding is still used
to convert the source text into a sequence of tokens, but the
GPT-3 vocabulary was extended by adding dedicated tokens
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:58:58 UTC from IEEE Xplore.  Restrictions apply. 
755
i n t h e
l i s t ?\n ” ) ;
1 p r i n t f ( ”How many i t e m s
l e n ;
2 u n s i g n e d i n t
l e n ) ;
3
4
l i s t
s c a n f ( ”%d ” , &l i s t
s t r u c t
s h o p p i n g l i s t
= m a l l o c ( l i s t
i t e m * s h o p p i n g i t e m s
l e n * s i z e o f ( s t r u c t
s h o p p i n g l i s t
i t e m ) ) ;
Fig. 1. Vulnerable shopping list C code
into a tree-like structure according to the Research Concepts
View (CWE-1000). Each CWE is classiﬁed as either a
pillar (most abstract), class, base, or variant (most speciﬁc).
For example, consider CWE-20, Improper Input Validation.
This covers scenarios where a program has been designed
to receive input, but without validating (or
incorrectly
validating) the data before processing. This is a “class”-type
CWE, and is a child of the “pillar” CWE-707: Improper
Neutralization, meaning that all CWE-20 type weaknesses
are CWE-707 type weaknesses. There are other CWE-707
improper neutralization weaknesses which are not covered by
CWE-20. Weaknesses which apply to CWE-20 can be further
categorized into the base and variant
types. We show an
instance of this weakness in Fig. 1, which is a code snippet
that implements the part of a basic shopping list application.
The program asks how many items should be in the list (so
that it can allocate an appropriate amount of memory).
Here, the number input (on line 4) is not properly validated
to ensure that it is “reasonable” before being used (line 5).
This is thus vulnerable according to the “class” CVE-20, and
also the “base” CVE-1284: Improper Validation of Speciﬁed
Quantity in Input. Further, as the improper value is then used
to allocate memory, it may also be speciﬁc to the “variant”
CVE-789: Memory Allocation with Excessive Size Value. As
a result, this code could also be considered vulnerable to the
“class” CVE-400: Uncontrolled Resource Consumption, as
the user can command how much memory will be allocated.
This code has other vulnerabilities as well: as the code scans
with %d—even though the variable is deﬁned as an ‘unsigned
int’—entering a negative value (e.g. −1) will cause an integer
wraparound error (CWE-190).
CWEs capture weaknesses in a spectrum of complexity;
some CWEs manifest as fairly “mechanical” implementation
bugs that can be caught by static analysis tools (such as
CodeQL). Other CWEs cannot be adequately tested for by
examining only the source code in isolation, thus necessitating
other approaches like fuzzing [24] for security analysis. Alter-
natively, assertions for manually-speciﬁed security properties
may be added. Examining if Copilot introduces weaknesses
that require reasoning over such a broader context (i.e.,
outside the single code ﬁle) is beyond the scope of this study.
III. USING GITHUB COPILOT
Copilot is used as follows1. The software developer (user)
works on some program, editing the code in a plain text
editor; at this time, Copilot supports Visual Studio Code.
The exact nature of how Copilot scans code is not disclosed
publicly, being a proprietary closed-source black-box. The
1As of August 2021, during Copilot’s technical preview phase.
Fig. 2. Example Copilot usage for Python Login Code: ﬁrst option popup.
Fig. 3. Copilot displays more detailed options for Python Login Code.
exact processes that
it uses for continuously scanning,
prompting, deciding what to upload, etc., are not described in
any ofﬁcial documentation. Thus, the following description is
based on our understanding of the available documentation [1].
As the user adds lines of code to the program, Copilot
continuously scans the program and periodically uploads
some subset2 of lines, the position of the user’s cursor, and
metadata before generating some code options for the user
to insert. Copilot aims to generate code that is functionally
relevant to the program as implied by comments, docstrings,
function names, and so on. Copilot also reports a numerical
conﬁdence score3 for each of its proposed code completions,
with the top-scoring (highest-conﬁdence) score presented as
the default selection for the user. The user can choose any
of Copilot’s options. An example of this process is depicted
in Fig. 2. Here, the user has begun to write the login code
for a web app. Their cursor is located at line 15, and based
on other lines of code in the program, Copilot suggests an
additional line of code which can be inserted.
2This subset is proprietary.
3Copilot refers to this value in the generated outputs as ‘mean prob.’. An
online comment from Johan Rosenkilde, a Copilot maintainer, clariﬁed that
this is an aggregate of the probabilities of all tokens in the answer, and so
can be seen as a conﬁdence score.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:58:58 UTC from IEEE Xplore.  Restrictions apply. 
756
C. Generalized Evaluation Process
Given that the goal of this work is to perform an early
empirical
investigation of the prevalence of CWEs within
Copilot-generated code, we choose to focus on MITRE’s
“2021 CWE Top 25” list [4]. We use this list to guide our
creation of a Copilot prompt dataset, which we call
the
‘CWE scenarios’. We feed each prompt through Copilot to
generate code completions (Section III) and determine if the
generated code contains the CWE (Section IV-B). Our overall
experimental method is depicted in Fig. 5.
In step 1 , for each CWE, we write a number of ‘CWE
scenarios’ 2 . These are small, incomplete program snippets
in which Copilot will be asked to generate code. The
scenarios are designed such that a naive functional response
could contain a CWE, similar to that depicted in Fig. 2.
For simplicity, we restrict ourselves to three programming
languages: Python, C, and Verilog. Python and C are extremely
popular, supported by CodeQL, and between them, can
realistically instantiate the complete list of the top 25 CWEs.
We use Verilog to explore Copilot’s behavior in a less popular
domain in Section V-D as an additional set of experiments.
In developing the
scenarios, we used three different
sources. These were (a) the CodeQL example/documentation
repository—considered as the best as these scenarios are
ready for evaluation with CodeQL, (b) examples listed in
the CWE entry in MITRE’s database—second best, as they
deﬁnitively describe each CWE and require minimal work to
ensure conformance with CodeQL, and (c) bespoke scenarios
designed by the authors for this study. Note that each scenario
does not contain the weakness from the outset; it is Copilot’s
completion that determines if the ﬁnal program is vulnerable.
Next, in 3 , Copilot is asked to generate up to 25 options
for each scenario. Each option is then combined with the
original program snippet to make a set programs in 4a —with
some options discarded 4b if they have signiﬁcant syntax
issues (i.e., they are not able to be compiled/parsed). That
said, where simple edits (e.g. adding or removing a single
brace) would result in a compilable output, we make those
changes automatically using a regex-based tool.
Then, in 5a evaluation of each program occurs. Where
this evaluation is performed by CodeQL 5b
possible,
Fig. 4. Example CodeQL output for Copilot-generated Python Login Code
(line breaks and highlighting are for readability).
The user may request more insights by opening Copilot’s
main window by pressing the prompted Ctrl + Space
combination. Here the user will be presented with many
options (we requested the top 25 samples, which gave us a
good balance between generation speed and output variability)
and the score for each option, if requested. This is displayed in
Fig. 3, and the user may choose between the different options.
is based on GPT-3 and Codex [2], several
options are available for tuning the code generation, including
temperature, stops, and top p. Unfortunately, the settings and
documentation as provided do not allow users to see what
to by default—users may only override the
these are set
(secret) default values. As we are interested in the default per-
formance of Copilot, we thus do not override these parameters.
As Copilot
IV. EXPERIMENTAL METHOD
A. Problem Deﬁnition
We focus on evaluating the potential security vulnerabilities
of code generated by Github Copilot. As discussed in Sec-
tion II, determining if code is vulnerable sometimes requires
knowledge (context) external to the code itself. Furthermore,
determining that a speciﬁc vulnerability is exploitable requires
framing within a corresponding attacker model.
As such, we constrain ourselves to the challenge of
determining if speciﬁc code snippets generated by Copilot
are vulnerable: that is, if they deﬁnitively contain code that
exhibits characteristics of a CWE. We do not consider the
exploitability of an identiﬁed weakness in our experimental
setting as we reduce the problem space into a binary
classiﬁcation: Copilot generated code either contains code
identiﬁed as (or known to be) weak or it does not.
B. Evaluating Copilot Options with Static Analysis
python-security-and-quality.qls
In this paper we use the Github CodeQL [5]. To demonstrate
CodeQL’s functionality, assume that the top scoring option
from Copilot in Fig. 3 is chosen to build a program. Using
CodeQL’s
testing
suite, which checks 153 security properties, it outputs feedback
like that shown in Fig. 4—reporting that
the SQL query
generation method (lines 14-16 in Fig. 3) is written in a way
that allows for insertion of malicious SQL code by the user.
In the CWE nomenclature this is CWE-89 (SQL Injection).
Fig. 5. General Copilot evaluation methodology
757
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:58:58 UTC from IEEE Xplore.  Restrictions apply. 
CopilotOptionsCopilotOptionsCodeQLrepo.MITREe.g.'sAuthorsCopilotOptionsCopilotOptionsResultsCWE scenariosCopilotOptionsEvaluationCodeQL235c5b6MITRE Top 25 CWEs14aCopilot programs4bAuthors5ausing either built-in or custom queries. For some CWEs
that require additional context or could not be formed as
properties examinable by CodeQL,
this evaluation needed
to be performed by the authors manually 5c . Importantly,
CodeQL is conﬁgured in this step to only examine for the
speciﬁc CWE this scenario is designed for. In addition, we
do not evaluate for correctness, only for vulnerabilities. This
decision is discussed further in Section V-A1. Finally, in 6 the
results of the evaluations of each Copilot-completed program.
D. Experimental Platform
The process depicted in Fig. 5 was executed on a single
PC—Intel i7-10750H processor, 16GB DDR4 RAM, using
Ubuntu 20.04. Due to the restricted usage patterns of Copilot,
Steps 1 , 2 , and 3a were completed manually. Automated
Python scripts were then developed to complete Steps 3b , 4a ,
and 5 automatically, along with manual analysis Step 4b
where necessary. All scenarios and scripts were developed
using/for Python 3.8.10 and gcc 9.3.0-17. CodeQL was
version 2.5.7, and Copilot was in the technical preview phase
(no version number available). Open source: all code and the
generated dataset is made available. See the Appendix.
V. EXPERIMENTAL INVESTIGATION OF GITHUB COPILOT
A. Study Overview
To investigate Copilot under a diverse range of scenarios,
our analysis is framed along three different axes of diversity.
The ﬁrst of these is Diversity of Weakness (DOW) where we
examine Copilot’s performance in response to scenarios that
could lead to the instantiation of different software CWEs.
The second is Diversity of Prompt (DOP), where we per-
form a deeper examination of Copilot’s performance under
a single at-risk CWE scenario with prompts containing subtle
variations. Fina