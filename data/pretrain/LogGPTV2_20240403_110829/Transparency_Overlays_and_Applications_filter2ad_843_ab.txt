a DLC should be (1) binding, which means that a commitment cannot represent two diﬀerent lists, (2) sound,
which means that it should be hard to produce a valid proof of inclusion for an element that is not in the
list, and (3) append-only, which means that it should be hard to produce a proof that a list has only been
appended to if other operations (e.g., deletions) have taken place. Formally, these properties can be deﬁned
as follows:
Deﬁnition 3.2 (Basic). Deﬁne Advs
are deﬁned as follows:
dlc,A(λ) = Pr[GA
s (λ)] for s ∈ {bind, sound, append}, where these games
main GbindA (λ)
(c, list1, list2) r←− A(1λ)
return (CheckCom(c, list1) ∧ CheckCom(c, list2) ∧ (list1 (cid:54)= list2))
(λ)
main GsoundA
(c, list, elmt, π) r←− A(1λ)
return (CheckCom(c, list) ∧ CheckIncl(c, elmt, π) ∧ (elmt /∈ list))
A
(λ)
main Gappend
(c1, c2, list2, π) r←− A(1λ)
return (CheckCom(c2, list2) ∧ CheckAppend(c1, c2, π) ∧ ((cid:54) ∃j : CheckCom(c1, list2[1 : j])))
Then the DLC is binding if for all PT adversaries A there exists a negligible function ν(·) such that Advbind
ν(λ), sound if for all PT adversaries A there exists a negligible function ν(·) such that Advsound
and append-only if for all PT adversaries A there exists a negligible function ν(·) such that Advappend
ν(λ).
dlc,A (λ) < ν(λ),
dlc,A (λ) <
dlc,A(λ) <
3.2.2 An augmented formalization for ordered lists.
It will also be useful for us to consider a special type of DLC, in which the elements in the list have some kind
of order imposed on them. In particular, this allows us to more eﬃciently perform two additional operations:
demonstrate that two DLCs are inconsistent (i.e., that they are commitments to strictly distinct or forking
lists), and demonstrate that a given element is not in the list represented by a given commitment. As we
will see in our applications later on, these operations are crucial for providing evidence that certain types of
misbehavior have taken place.
In addition to the algorithms required for a basic DLC, we now require a notion of timing (which may not
be the actual time, but rather any representation that allows us to impose an ordering): for every element
elmt in a list, we assume there exists a function time(·) that returns a value t, and that a global ordering
exists for this function, so that we can also deﬁne a Boolean function 0/1 ← isOrdered(list). Using this, we
deﬁne a notion of consistency for DLCs as follows:
Deﬁnition 3.3 (Consistency). A tuple (c, t, list) is consistent if c is a commitment to the state of list at time
t. Formally, we consider a function isConsistent such that isConsistent(c, t, list) = 1 if and only if there exists
a j, 1 ≤ j ≤ len(list), such that (1) CheckCom(c, list[1 : j]) = 1, (2) time(list[j]) ≤ t, (3) j = len(list) or
time(list[j + 1]) ≥ t), and (4) isOrdered(list).
5
We can now deﬁne four additional algorithms as follows:
• π ← DemoInconsistent(list, c(cid:48), t(cid:48)) proves that list is inconsistent with c(cid:48) at time t(cid:48) and
• 0/1 ← CheckInconsistent(c(cid:48), t(cid:48), c, π) checks this proof;
• π ← DemoNotIncl(list, elmt) proves that elmt is not in the ordered list list; and
• 0/1 ← CheckNotIncl(c, elmt, π) checks this proof.
The security properties in the augmented setting are relatively intuitive: an adversary should not be
able to (1) produce an inconsistent tuple (c, t, list) such that one cannot demonstrate their inconsistency, (2)
produce an ordered list and element such that one cannot demonstrate the non-inclusion of the element in
the list, (3) demonstrate an inconsistency that does not exist, or (4) prove non-inclusion of an element that
is in fact in an ordered list. We deﬁne these formally as follows:1
Deﬁnition 3.4 (Augmented). Deﬁne Advs
where these games are deﬁned as follows:
dlc,A(λ) = Pr[GA
s (λ)] for s ∈ {p-cons, p-incl, uf -cons, uf -incl},
A
(λ)
main Gp-cons
(c, t, list) r←− A(1λ)
b ← CheckInconsistent(c, t, Com(list), DemoInconsistent(list, c, t))
return ((b = 0) ∧ (isConsistent(c, t, list) = 0) ∧ isOrdered(list))
(λ)
main Gp-inclA
(list, elmt) r←− A(1λ)
b ← CheckNotIncl(Com(list), elmt, DemoNotIncl(list, elmt))
return ((b = 0) ∧ (elmt /∈ list) ∧ isOrdered(list))
A
(λ)
main Guf-cons
(c1, t, c2, list2, π) r←− A(1λ)
return (CheckCom(c2, list2) ∧ isConsistent(c1, t, list2) ∧ CheckInconsistent(c1, t, c2, π))
A
(λ)
main Guf-incl
(c, list, elmt, π) r←− A(1λ)
return (CheckCom(c, list) ∧ (elmt ∈ list) ∧ CheckNotIncl(c, elmt, π) ∧ isOrdered(list))
Then the DLC satisﬁes provable inconsistency if for all PT adversaries A Advp-cons
inclusion if for all PT adversary A Advp-incl
there exists a negligible function ν(·) such that Advuf-cons
PT adversaries A there exists a negligible function ν(·) such that Advuf-incl
dlc,A (λ) = 0, provable non-
dlc,A (λ) = 0, unforgeable inconsistency if for all PT adversaries A
dlc,A (λ) < ν(λ), and unforgeable non-inclusion if for all
dlc,A (λ) < ν(λ).
3.2.3 Two instantiations of augmented DLCs.
To demonstrate that dynamic list commitments exist, we provide two instantiations; both can be found
in Appendix B and derive their security from the collision resistance of a hash function. Brieﬂy, our ﬁrst
instantiation is essentially a rolling hash chain: new elements appended to the list are folded into the hash (i.e.,
cnew ← H(cold(cid:107)elmtnew)), and proofs about (in)consistency and (non-)inclusion reveal selective parts of the list.
This ﬁrst instantiation thus demonstrates the feasibility of dynamic list commitments (and is conceptually
quite simple), but the proofs are linear in the size of the list, which is not particularly eﬃcient. Thus, our
second instantiation is essentially a Merkle tree, which allows us to achieve proofs that are logarithmic in the
size of the list.
4 Transparency Overlays
In this section, we present our main contributions. First, in Sections 4.1 and 4.2, we introduce both basic
and augmented formal models for reasoning about transparency. Then, in Sections 4.3 and 4.4 we present
a generic transparency overlay and prove its security. To instantiate this securely (as we do in Sections 5
and 6), one then need only provide a simple interface between the underlying system and the overlay.
1In our games below, we require as a winning condition that the list is ordered. This is because our constructions make this
assumption in order to achieve better eﬃciency, but one could also present constructions for which this extra winning condition
would not be needed.
6
4.1 Basic overlays
In order for a system to be made transparent, we must provide an eﬃcient mechanism for checking that the
system is running correctly. Our setting overlays three additional parties on top of an existing system Sys: a
log server LS, an auditor Auditor, and a monitor Monitor. The role of the log server is to take certain events
in the system’s operation and enter them into a publicly available log. The role of the auditor is to check —
crucially, without having to keep the entire contents of the log — that speciﬁc events are in the log. Finally,
the role of the monitor is to ﬂag any problematic entries within the log. Collectively then, the auditor and
monitor act to hold actors within the system responsible for the creation of (potentially conﬂicting) events.
We assume that each of these parties is stateful: the log server maintains the log as state, so stateLS =
log; the auditor maintains a snapshot (i.e., some succinct representation of the current log) as state, so
stateAu = snap; and the monitor maintains a snapshot, a list of bad events, and a list of all events, so
stateMo = (snap, eventsbad, events).
A transparency overlay then requires ﬁve interactive protocols; these are deﬁned abstractly as follows:2
GenEventSet is an interaction between the actor(s) in the system that produces the events to be logged. The
protocol is such that eventset r←− Run(1λ, GenEventSet, Sys, aux).
Log is an interaction between one or more of the actors in the system and LS that is used to enter events
into the log. The protocol is such that (b, ε) r←− Run(1λ, Log, (Sys, LS), (eventset, ε)), where b indicates
whether or not the system actor(s) believes the log server behaved honestly.
CheckEntry is an interaction between one or more of the actors in the system, Auditor, and LS that is used to
check whether or not an event is in the log. The protocol is such that (b, b(cid:48), ε) r←− Run(1λ, CheckEntry, (Sys,
Auditor, LS), (event, ε, ε)), where b indicates whether or not the system actor(s) believes the event to be in
the log and b(cid:48) indicates whether or not the auditor believes the log server behaved honestly in the interaction.
Inspect is an interaction between Monitor and LS that is used to allow the monitor to inspect the contents of
the log and ﬂag any suspicious entries. The protocol is such that (b, ε) r←− Run(1λ, Inspect, (LS, Monitor),
(ε, ε)), where b indicates whether or not the monitor believes the log server behaved honestly in the inter-
action.
Gossip is an interaction between Auditor and Monitor that is used to compare versions of the log and detect any
inconsistencies. If any misbehavior on behalf of the log server is found, then both parties are able to output
evidence that this has taken place. The protocol is such that (evidence, evidence) r←− Run(1λ, Gossip,
(Auditor, Monitor), (ε, ε)).
We also require the following (non-interactive) algorithms:
(pkLS, sk LS) r←− GenLogID(1λ) is used to generate a public and secret identiﬁer for the log server; and
0/1 ← CheckEvidence(pkLS, evidence) is used to check if the evidence against the log server identiﬁed by
pkLS is valid.
From a functionality standpoint, we would like the protocols to be correct, meaning all parties should be
satisﬁed by honest interactions, and compactly auditable, meaning the size of a snapshot is much smaller than
the size of the log.
We deﬁne security for a basic transparency overlay in terms of two properties: consistency, which says
that a potentially dishonest log server cannot get away with presenting inconsistent versions of the log to the
auditor and monitor, and non-frameability, which says that potentially dishonest auditors and monitors (and
even actors in the original system) cannot blame the log server for misbehavior if it has behaved honestly.
Participants can thus be satisﬁed that they are seeing the same view of the log as all other participants, and
that the interactions they have really are with the log server.
To formalize consistency, we consider a game in which the adversary takes on the role of the log server
and is allowed to interact (via the MsgAu and MsgMo oracles, respectively) with the auditor and monitor.
The adversary wins if there is an event that is not in the list maintained by the monitor but that the auditor
nevertheless perceives as being in the log (the third winning condition of Deﬁnition 4.1), yet the auditor and
monitor are unable to produce valid evidence of this inconsistency (the ﬁrst two winning conditions). For ease
of formal exposition, we (1) assume that in the CheckEntry protocol the ﬁrst message sent to the auditor is
the event to be checked and the last message sent by the auditor is a bit indicating whether the event is in
the log, and (2) require that the monitor must have a newer snapshot than the auditor, but can naturally
extend our deﬁnition to cover other conﬁgurations as well.
2In each protocol, we also allow the participants to output fail, which indicates that they believe they were given improperly
formatted inputs.
7
Deﬁnition 4.1 (Consistency). Deﬁne Advcons
trans,A(λ) = Pr[GconsA (λ)], where GconsA (λ) is deﬁned as follows:
main GconsA (λ)
events ← ∅; eventspass ← ∅
r←− AMsgAu,MsgMo(1λ)
pkLS
evidence r←− Run(1λ, Gossip, (Auditor, Monitor), (ε, ε))
return ((CheckEvidence(pkLS, evidence) = 0) ∧
(time(stateMo[snap]) ≥ time(stateAu[snap])) ∧
(eventspass \ stateMo[events] (cid:54)= ∅))
MsgAu(i, j, m)
(stateAu, m(cid:48), p, out) r←− CheckEntry[Auditor, i, j](1λ, stateAu, m)
if (i = 1) events[j] ← m
if (out (cid:54)= ⊥) ∧ (m(cid:48) = 1) eventspass ← eventspass ∪ {events[j]}
return m(cid:48)
MsgMo(i, j, m)
(stateMo, m(cid:48), p, out) r←− Inspect[Monitor, i, j](1λ, stateMo, m)
return m(cid:48)
Then the transparency overlay satisﬁes consistency if for all PT adversaries A there exists a negligible function
ν(·) such that Advcons
trans,A(λ) < ν(λ).
Next, to formalize non-frameability, we consider an adversary that wants to frame an honest log server;
i.e., to produce evidence of its “misbehavior.” In this case, we consider a game in which the adversary takes
on the role of the auditor, monitor, and any actors in the system, and is allowed to interact (via the Msg
oracle) with the honest log server. The adversary wins if it is able to produce evidence that passes veriﬁcation.
Deﬁnition 4.2. Deﬁne Advframe
trans,A(λ) = Pr[GframeA
(λ)], where GframeA
(λ) is deﬁned as follows:
(λ)
main GframeA
(pkLS, sk LS) r←− GenLogID(1λ)
evidence r←− AMsg(1λ, pkLS)
return CheckEvidence(pkLS, evidence)
Msg(Prot, i, j, m)
if (Prot /∈ {Log, CheckEntry, Inspect}) return ⊥
(stateLS, m(cid:48), p, out) r←− Prot[LS, i, j](1λ, stateLS, m)
return m(cid:48)
Then the transparency overlay satisﬁes non-frameability if for all PT adversaries A there exists a negligible
function ν(·) such that Advframe
trans,A(λ) < ν(λ).
We then say that a basic transparency overlay is secure if it satisﬁes consistency and non-frameability.
Comparison with concurrent work With respect to the security model of Dowling et al. [15], their
model requires only that the monitor and auditor produce evidence of misbehavior in the case where the log
server fails to include an event for which it has issued a receipt (which we consider in the next section). Our
model, on the other hand, also produces evidence in the case where the log has given inconsistent views to
the two parties; this type of evidence seems particularly valuable since this type of misbehavior is detected
only after the fact. This diﬀerence allows them to present a simpler deﬁnition of non-frameability, as they do
not have to worry about malicious monitors and auditors forging this type of evidence.
4.2 Pledged overlays
In the basic setting described, log servers can be held responsible if they attempt to present diﬀerent views
of the log to the auditor and monitor. If log servers simply fail to include events in the log in the ﬁrst place,
however, then there is currently no way to capture this type of misbehavior. While in certain settings the log
server could plausibly claim that it never received an event rather than ignoring it, if the log server issues
8
promises or receipts to include events in the log then we can in fact enforce inclusion, or at least blame the
log server if it fails to do so.
Formally, we capture this as an additional security property, accountability, which says that evidence can
also be used to implicate log servers that promised to include events but then did not.
In the game, the