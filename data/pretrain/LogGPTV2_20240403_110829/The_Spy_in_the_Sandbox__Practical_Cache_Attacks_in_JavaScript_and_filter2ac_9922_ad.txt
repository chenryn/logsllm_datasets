.2
-
-
-
-
-
1
-
-
-
-
-
-
-
-
1
-
-
.4
-
-
.5
-
-
.8
-
-
-
-
-
-
-
-
1
-
.2
-
-
-
-
-
-
.6
Table 2: Confusion matrix for FFT-based classiﬁer
(Safari Private Browsing).
The longer network round-trip times introduced by the
Tor network did not diminish the performance of our classi-
ﬁer, nor did the added load of background activities, which
unavoidably occurred during the 50 seconds of each mea-
surement. The classiﬁer was the least successful in telling
apart the Facebook and Wikipedia memorygrams. We the-
orize that this is due to the fact that both websites load a
minimal website with a blinking cursor that generates the
distinct 2 Hz pulse shown in Figure 6. The accuracy of the
detector can certainly be improved with more advanced clas-
siﬁcation heuristics (e.g., timing the keystrokes of the URL
as it is entered, characterizing and ﬁltering out frequencies
with switching noise).
Our evaluation was limited to a closed-world model of the
Internet, in which only a small set of websites was consid-
ered, and where template creation was performed based on
traces from the victim’s own machine. It is possible to justify
this model for our speciﬁc attacker, who can easily carry out
proﬁling on the victim’s machine by instructing it to load
known pages via JavaScript while recording memorygrams.
Nevertheless, it would still be interesting to scale up the
evaluation to an open-world model, where many thousands
of websites are considered, and where the templates are cre-
ated in a diﬀerent time and place than the victim’s current
browsing session [11].
1414Classiﬁer
Output→,
Ground
Truth↓
Amazon (1)
Baidu (2)
Facebook (3)
Google (4)
Twitter (5)
Wikipedia (6)
Yahoo (7)
Youtube (8)
(1)
(2)
(3)
(4)
(5)
(6)
(7)
(8)
1
-
-
-
-
-
-
-
-
1
.2
-
-
-
-
-
-
-
.8
-
-
.33
-
-
-
-
-
1
.17
-
-
-
-
-
-
-
.83
.17
-
.4
-
-
-
-
-
.5
-
-
-
-
-
-
-
-
1
-
-
-
-
-
-
-
-
1
Table 3: Confusion matrix for FFT-based classiﬁer
(Tor Browser).
Brand
Hi-Res.
Time
Support
Typed
Arrays
Support
Internet Explorer
Safari
Chrome
Firefox
Opera
Total
v10
v8
v20
v15
v15
–
v11
v6
v7
v4
v12.1
–
Worldwide
Preva-
lence
11.77%
1.86%
50.53%
17.67%
1.2%
83.03%
Table 4: Aﬀected desktop browsers: minimal ver-
sion and prevalence [26].
6. DISCUSSION
6.1 Prevalence of Affected Systems
Our attack requires a personal computer powered by an
Intel CPU based on the Sandy Bridge, Ivy Bridge, Haswell
or Broadwell micro-architecture. According to data from
IDC, more than 80% of all PCs sold after 2011 satisfy this
requirement. We furthermore assume that the user is using
a web browser that supports the HTML5 High Resolution
Time API and the Typed Arrays speciﬁcation. Table 4 notes
the earliest version at which these APIs are supported for
each common browser, as well as the proportion of global
Internet traﬃc coming from such browser versions, accord-
ing to StatCounter measurements (January 2015) [26]. As
the table shows, more than 83% of desktop browsers in use
today are aﬀected by the attack we describe.
The eﬀectiveness of our attack depends on being able to
perform precise measurements using the JavaScript High
Resolution Time API. While the W3C recommendation of
this API [16] speciﬁes that the a high-resolution timestamp
should be “a number of milliseconds accurate to a thou-
sandth of a millisecond”, the maximum resolution of this
value is not speciﬁed, and indeed varies between browser
versions and OSes. During our tests, we discovered that the
actual resolution of this timestamp for Safari on Mac OS X
was on the order of nanoseconds, while IE for Windows had
a 0.8µs resolution. Chrome, on the other hand, oﬀered a
uniform resolution of 1µs on all OSes we tested.
Since the timing diﬀerence between a single cache hit and
a cache miss is on the order of 50ns (see Figure 3), the proﬁl-
ing and measurement algorithms need to be slightly modiﬁed
to support systems with coarser-grained timing resolution.
Figure 7: L3 cache hit times show a 3-level gradua-
tion (Haswell i7-4960HQ).
In the proﬁling stage, instead of measuring a single cache
miss, we repeat the memory access cycle multiple times to
amplify the time diﬀerence. We have used this observation
to successfully perform cache proﬁling on versions of the
Chrome browser whose timing resolution was limited5. For
the measurement stage, we cannot amplify a single cache
miss, but we can take advantage of the fact that code ac-
cesses typically invalidate multiple consecutive cache sets
from the same page frame. As long as at least 20 out of the
64 cache sets, in a single page frame, register a cache miss,
our attack is successful even with µs time resolution.
The attack we propose can also be applied to mobile de-
vices, such as smartphones and tablets. It should be noted
that the Android Browser supports High Resolution Time
and Typed Arrays starting from version 4.4, but at the time
of writing the most recent version of iOS Safari (8.1) did not
support the High Resolution Time API.
6.2 Micro-architecture Insights
Despite the fact that our attack was implemented in a
restricted, high-level language, it provides a glimpse into
extremely low-level elements of the victim’s machine. As a
consequence, it is aﬀected by the minute design choices made
by Intel CPU architects. As stated by Acii¸cmez [1], two
concepts can aﬀect the functional behavior of a cache: the
mapping strategy and the replacement policy. The former
determines which memory locations are mapped to each set
in the cache, while the latter determines how the cache set
will be modiﬁed after a cache miss.
We noticed diﬀerent behaviour in the mapping strategy of
the systems we surveyed, especially in the choice of the slice
index of each memory address. In the processors we tested,
the sets of the LLC are divided into slices, with each cache
slice located in hardware with close proximity to one of the
CPU’s cores. All of the slices are interconnected via a ring
buﬀer, allowing all cores to access cache entries in all slices.
5It should be noted that Chrome has an additional feature
called Portable Native Client (PNaCl), which oﬀers direct
access to the native clock_gettime() API.
200250300350400450500550160170180190200210220230240CacheSet(non-canonical)Cachehitlatency(ns)1415Cache sets are thus indexed ﬁrst using the slice index, and
next with the set index within the respective slice.
While the work of Hund et al. [10] showed that on Sandy
Bridge CPUs the slice index is only a function of high-
order bits of the physical address, Liu et al. [14] suggested
that lower-order bits are also considered by newer micro-
architectures. We conﬁrmed this by measuring the cache hit
of each of the cache sets we were able to proﬁle on a quad-
core Haswell processor.
In such a system there are three
possible times for an L3 cache hit. L3 cache entries located
in a slice associated with the current core are the fastest to
access. Hits on cache entries located in the two slices which
are a single core’s distance from the current core should be
slightly slower, since the entry has to travel across a single
hop on the ring buﬀer. Finally, hits on cache entries lo-
cated in the slice which is two cores away from the current
core should be the slowest to access, since the entries travel
across two hops on the ring buﬀer. If lower-order address
bits are used in the selection of the cache slice, we would
expect to see a variation in the cache hit times for addresses
within the same physical memory page. Figure 7 shows that
this behaviour was indeed observed on a Haswell-generation
CPU, conﬁrming the suggestion of Liu et al.
The timing diﬀerence between the worst-case cache hit
(which has to travel across two hops on the ring buﬀer) and
a cache miss is still enough for Algorithm 1 to operate with-
out modiﬁcations. However, an attacker can use this insight
concerning LLC slices to his operative advantage. For ex-
ample, two processes running on the same system can use
this measurement to discover whether they are running on
the same core or not, by comparing cache hit timings for
the same cache sets. This can allow an attacker to option-
ally transition from LLC cache attacks to L1 cache attacks,
which are considered to be more sensitive and simpler to
carry out. More importantly, once the mapping of physi-
cal addresses to cache sets is reverse engineered on newer
systems, this behaviour will allow low-privilege processes to
infer information about the physical addresses of their own
variables, reducing the entropy of several types of attacks
such as ASLR derandomization [10].
When investigating the cache replacement policy, we no-
ticed that the CPUs we surveyed transitioned between two
distinct replacement policies. Modern Intel CPUs usually
employ a least-recently-used (LRU) replacement policy [23],
where a new entry added to the cache is marked as the
most recently used, and is thus the last to be replaced in
the case of future cache misses. In certain cases, however,
these CPUs can transition to the bimodal insertion policy
(BIP) policy, where the new entry added to the cache is
marked most of the times as the least recently used, and
is thus the ﬁrst to be replaced in the case of future cache