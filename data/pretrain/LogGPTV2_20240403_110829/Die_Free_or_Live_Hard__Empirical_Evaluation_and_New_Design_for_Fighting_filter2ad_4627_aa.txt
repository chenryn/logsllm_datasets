title:Die Free or Live Hard? Empirical Evaluation and New Design for Fighting
Evolving Twitter Spammers
author:Chao Yang and
Robert Chandler Harkreader and
Guofei Gu
Die Free or Live Hard?
Empirical Evaluation and New Design for
Fighting Evolving Twitter Spammers
Chao Yang, Robert Chandler Harkreader, Guofei Gu
SUCCESS Lab, Texas A&M University
{yangchao, bharkreader, guofei}@cse.tamu.edu
Abstract. Due to the signiﬁcance and indispensability of detecting and
suspending Twitter spammers, many researchers along with the engi-
neers in Twitter Corporation have devoted themselves to keeping Twitter
as spam-free online communities. Meanwhile, Twitter spammers are also
evolving to evade existing detection techniques. In this paper, we make
an empirical analysis of the evasion tactics utilized by Twitter spam-
mers, and then design several new and robust features to detect Twitter
spammers. Finally, we formalize the robustness of 24 detection features
that are commonly utilized in the literature as well as our proposed ones.
Through our experiments, we show that our new designed features are
eﬀective to detect Twitter spammers, achieving a much higher detection
rate than three state-of-the-art approaches [35, 32, 34] while keeping an
even lower false positive rate.
1
Introduction
Spammers have utilized Twitter as the new platform to achieve their malicious
goals such as sending spam [2], spreading malware [12], hosting botnet command
and control (C&C) channels [5], and performing other illicit activities [29]. All
these malicious behaviors may cause signiﬁcant economic loss to our society
and even threaten national security. In August of 2009, nearly 11 percent of all
Twitter posts were spam [1]. In May of 2009, many innocent users’ accounts on
Twitter were hacked to spread advertisements [2]. In February of 2010, thou-
sands of Twitter users, such as the Press Complaints Commission, the BBC
correspondent Nick Higham and the Guardian’s head of audio Matt Wells, have
seen their accounts hijacked after a viral phishing attack [19].
Many researchers along with engineers from Twitter Corporation have de-
voted themselves to keep Twitter as a spam-free online community. Their eﬀorts
have attempted to protect legitimate users from useless advertisements, porno-
graphic messages or links to phishing or malicious websites. For example, Twitter
has published their deﬁnitions of spam accounts and The Twitter Rules [14] to
protect its users from spam and abuse. Any account engaging in the abnor-
mal activities is subject to temporary or even permanent suspension by Twitter.
Meanwhile, many existing research studies, such as [25, 32, 22, 35, 34], also utilize
machine learning techniques to detect Twitter spammers.
2
“While the priest climbs a post, the devil climbs ten.” This proverb illustrates
the struggle between security researchers and their adversaries – spammers in
this case. The arms race nature between the attackers and defenders leads Twit-
ter spammers to evolve or utilize tools to evade existing detection features [11].
For example, Twitter spammers can evade some existing detection features by
purchasing followers [6] or using tools to automatically post tweets with the same
meaning but diﬀerent words [15].
In this paper, we plan to design more robust features to detect more Twitter
spammers through an in-depth analysis of the evasion tactics utilized by cur-
rent Twitter spammers. To achieve our research goals, we collect and analyze
around 500,000 Twitter accounts and more than 14 million tweets using Twitter
API [18], and identify around 2,000 Twitter spammers by using blacklist and
honeypot techniques. Then, we describe and validate current evasion tactics by
both showing some case studies and examining three existing state-of-the-art
approaches [35, 32, 34] on our collected data set. Based on the in-depth analy-
sis of those evasion tactics, we design ten new features including graph-based
features, neighbor-based features, timing-based features, and automation-based
features to detect Twitter spammers. Through our evaluation experiments, we
show that our newly designed features can be eﬀectively used to detect Twitter
spammers. In addition, we also formalize the robustness of 24 detection features
that are utilized in the existing work as well as our proposed ones.
In summary, the contributions of this paper are as follows:
– We present the ﬁrst in-depth empirical analysis of evasion tactics utilized
by current Twitter spammers based on a large dataset containing around
500,000 Twitter accounts and more than 14 million tweets.
– We evaluate the detection rates of three state-of-the-art solutions on our
collected dataset. Even the best detector still misses detecting around 27% of
Twitter spammers and the worst detector misses about half of the spammers.
– Based on our empirical analysis of the evasion tactics and the Twitter spam-
mers’ desire to achieve malicious goals, we propose and test our newly de-
signed detection features. To the best of our knowledge, it is the ﬁrst work
to propose neighbor-based detection features to detect Twitter spammers.
According to our evaluation, while keeping an even lower false positive rate,
the detection rate by using our new feature set signiﬁcantly increases to
85%, compared with a detection rate of 51% and 73% for the worst existing
detector and the best existing detector, respectively.
– We provide a new framework to formalize the robustness of 24 detection
features that are utilized by the existing work and our work, and categorize
them into 16 low-robust features, 4 medium-robust features and 4 high-
robust features.
2 Related Work
Due to the rising popularity of Twitter, many studies have been conducted with
an aim at studying the topological characteristics of Twitter. Kwa et al. [31]
3
have shown a comprehensive and quantitative study of Twitter accounts’ behav-
ior, such as the distribution of the number of followers and followings, and the
reciprocity of following relationships. Cha et al. [25] design diverse metrics to
measure Twitter accounts.
In addition, since spam and attacks are so rampant in online social network-
ing sites, Koutrika et al. [30] propose techniques to detect tag spam in tagging
systems. Benevenuto et al. [24, 23] utilize machine learning techniques to iden-
tify video spammers in video social networks. Gao et al. [27] present a study
on detecting and characterizing social spam campaigns in Facebook. In terms of
Twitter, most existing detection work can be classiﬁed into two categories. The
ﬁrst category of work, such as [32, 22, 35, 34], mainly utilizes machine learning
techniques to classify legitimate accounts and spam accounts according to their
collected training data and their selections of classiﬁcation features. The second
category of work, e.g. [28], detects spam accounts by examining whether the
URLs or web domains posted in the tweets are tagged as malicious by the public
blacklists. Especially, to collect training data, both [32] and [34] utilize social
honey accounts to identify Twitter spammers.
Diﬀerent from existing studies, our work focuses more on analyzing evasion
tactics utilized by current Twitter spammers and we further design new machine
learning features to more eﬀectively detect Twitter spammers. In addition, we
formalize the robustness of 24 detection features. Our work is a valuable supple-
ment to existing Twitter spammers detection research.
3 Data Collection
In this section, we describe our data collection strategies and results including
crawling Twitter proﬁles and identifying Twitter spammers.
To crawl Twitter proﬁles, we develop a Twitter crawler that taps into Twit-
ter’s Streaming API [18]. In order to decrease the eﬀect of the sampling bias [33],
we utilize a new crawling strategy rather than simply using the Breath First
Search (BFS) sampling technique. Speciﬁcally, we ﬁrst collect 20 seed Twitter
accounts from the public timeline [20]. For each of these 20 accounts, we also
crawl their followers and followings. We then repeat this process by collecting a
new set of 20 seed Twitter accounts from the public timeline. For each account
that we crawl, we collect its 40 most recent Tweets as well as any other infor-
mation that Twitter allows us to collect. Due to the large amount of redirection
URLs used in Twitter, we also follow the URL redirection chain to obtain the
ﬁnal destination URL. This resulted in the collection of nearly 500,000 Twitter
accounts which posted over 14 million tweets containing almost 6 million URLs.
Details about the crawling information can be seen in Table 1.
Then, we need to identify Twitter spammers from our crawled dataset. In our
work, we focus on those Twitter spammers that post harmful links to phishing
or malware sites, since this type of spammers is more deleterious than other
types of spammers. Speciﬁcally, we ﬁrst utilize Google Safe Browsing [9] and
Capture-HPC [7] to detect malicious or phishing URLs in the tweets. We deﬁne
4
Table 1. Twitter accounts crawling information
Name
Value
Number of Twitter accounts
485,721
Number of Followings
791,648,649
Number of Followers
855,772,191
Number of tweets
14,401,157
Number of URLs Extracted 5,805,351
a Tweet that contains at least one malicious or phishing URL as a Spam Tweet.
For each account, we deﬁne its spam ratio as the ratio of the number of its spam
tweets that we detect to the total number of its tweets that we collect. Then, we
extract 2,933 Twitter accounts whose spam ratios are higher than 10%. Then,
in order to decrease false positives, our group members spend several days on
manually verifying all 2,933 accounts and ﬁnally identify 2,060 spam accounts.
We acknowledge that our collected data set may still contain some bias and
the number of spammers in our examination data set is a lower bound of the
real number. (Detailed discussions can be seen in Section 8). However, even for
a subset of spammers, we can still use them to analyze the evasion tactics and
test the performance of existing work on detecting these spammers.
4 Analyzing Evasion Tactics
This section will describe the evasive tactics that spammers are using to evade
existing machine learning detection schemes. Then, we validate these tactics by
both showing some case studies and examining three existing state-of-the-art
approaches on our collected data set.
4.1 Description of Evasion Tactics
The main evasion tactics, utilized by the spammers to evade existing detection
approaches, can be categorized into the following two types: proﬁle-based feature
evasion tactics and content-based feature evasion tactics.
Proﬁle-based Feature Evasion Tactics: A common intuition for discover-
ing Twitter spam accounts can originate from accounts’ basic proﬁle information
such as number of followers and number of tweets, since these indicators usu-
ally reﬂect Twitter accounts’ reputation. To evade such proﬁle-based detection
features, spammers mainly utilize tactics including gaining more followers and
posting more tweets.
Gaining More Followers: In general, the number of a Twitter account’s
followers reﬂects its popularity and credibility. A higher number of follow-
ers of an account commonly implies that more users trust this account and
would like to receive the information from it. Thus, many proﬁle-based detec-
tion features such as number of followers, fofo ratio1 [32, 34] and reputation
1 It is the ratio of the number of an account’s following to its followers.
5
score [35] are built based on this number. To evade these features or break-
through Twitter’s 2,000 Following Limit Policy2 [13], spammers can mainly
adopt the following strategies to gain more followers. The ﬁrst strategy is to
purchase followers from websites. These websites charge a fee and then use an
arsenal of Twitter accounts to follow their customers. The speciﬁc methods
of providing these accounts may diﬀer from site to site. The second strategy
is to exchange followers with other users. This method is usually assisted by
a third party website. These sites use existing customers’ accounts to follow
new customers’ accounts. Since this method does only require Twitter ac-
counts to follow several other accounts to gain more followers without any
payment, Twitter spammers can get around the referral clause by creating
more fraudulent accounts. In addition, Twitter spammers can gain followers
for their accounts by using their own created fake accounts. In this way,
spammers can create a bunch of fake accounts, and then follow their spam
accounts with these fake accounts.
Posting More Tweets: Similar to the number of an account’s followers,
an account’s tweet number usually reﬂects how much this account has con-
tributed to the whole Twitter platform. A higher tweet number of an account
usually implies that this account is more active and willing to share infor-
mation with others. Thus, this feature is also widely used in the existing
Twitter spammers detection approaches, e.g.,
[34]. To evade this feature,
spammers can post more Tweets to behave more like legitimate accounts,
especially recurring to utilizing some public tweeting tools or software [3].
Content-based Feature Evasion Tactics: Another common indicator of
disclosing spam accounts is the content of a suspect account’s Tweets. As dis-
cussed in Section 1, a majority of spam accounts make proﬁts by alluring legiti-
mate users to click the malicious URLs posted in the spam tweets. Those mali-
cious URLs can direct users to websites that may cause harm to their computers
or scam them out of their money. Thus, the percentage of Tweets containing
URLs is an eﬀective indicator of spam accounts, which is utilized in work such
as [32, 34, 35]. In addition, since many spammers repeat posting the same or sim-
ilar malicious tweets in order to increase the probability of successfully alluring
legitimate users’ visits, especially with the utilization of the public automation
tweeting tools, their published tweets shows strong homogeneous characteris-
tics. In this way, many existing approaches design content-based features such as
tweet similarity [32, 34] and duplicate tweet count [35] to detect spam accounts.
To evade such content-based detection features, spammers mainly utilize the
tactics including mixing normal tweets and posting heterogeneous tweets.
Mixing Normal Tweets: Spammers can utilize this tactic to evade content-
based features such as URL ratio, unique URL ratio, hashtag ratio [32, 35].
These normal tweets without malicious URLs may be hand-crafted or ob-
tained from arbitrary users’ tweets or consisted of meaningless characters.
2 According to this policy, if the number of following of an account is exceeding 2,000,
this number is limited by the number of the account’s followers.
6
By using this tactic, spammers are able to dilute their spam tweets and make
it more diﬃcult to be distinguished from legitimated accounts.
Posting Heterogeneous Tweets: Spammers can post heterogeneous tweets
to evade content-based features such as tweet similarity and duplicate tweet
count. Speciﬁcally, in this tactic, spammers can post tweets with the same
semantic meaning using diﬀerent terms. In this way, not only can spammers
maintain the same semantic meanings to allure victims, but also they can
make their tweets diversed enough to not be caught by detectors that rely
on those content-based features. Particularly, spammers can utilize public
tools to spin a few diﬀerent spam tweets into hundreds of variable tweets
with the same semantic meaning using diﬀerent words [15].
4.2 Validation of Evasion Tactics
In this section, we aim to validate the four evasion tactics described in the pre-
vious section by showing real case studies and public services/tools that can be
utilized by the spammers. We also implement existing detection schemes [32, 34,
35] and evaluate them on our collected examination data set. By analyzing the
spammers missed (false negatives) by these works, we can show that many spam-
mers are evolving to behave like legitimate accounts to evade existing detection
features.
Gaining More Followers: As described in Section 4.1, spammers can gain
more followers by purchasing them, exchanging them and creating fake accounts.
In fact, several public websites allow for the direct purchase of followers. The
rates per follower for each website vary. Table 2 shows that followers can be pur-
chased for small amounts of money on several diﬀerent websites, even including
the online bidding website – Ebay, which can be seen in Fig. 1(a).
Table 2. Price of Online Follower Trading
Website
Price Per Follower
BuyTwitterFriends.com
TweetSourcer.com
UnlimitedTwitterFollowers.com
Twitter1k.com
SocialKik.com
USocial.net
Tweetcha.com
PurchaseTwitterFollowers.com
$0.0049
$0.0060
$0.0074
$0.0209
$0.0150
$0.0440
$0.0470
$0.0490
Also, Fig. 1(b) shows a real online website from which users can directly
buy followers. From this ﬁgure, we can ﬁnd that, spammers can buy followers
at a very cheap price. The website also claims that the user can buy targeted
followers with speciﬁc keywords in their tweets.
After showing these online services, through which spammers can obtain more
followers, we examine the detection features of number of followers and fofo ratio
from three existing approaches on our collected dataset. Particularly, we draw
7
(a) Bidding followers from Ebay (b) Purchasing followers from website
Fig. 1. Online Twitter Follower Trading Website
the distribution of both metrics of three account sets: missed spammers (false
negatives) in each of three existing approaches [32, 34, 35], all accounts (around
500,000 collected accounts), and all spammers (2,060 identiﬁed spammers). (We
label the results from [35] as A,
[32] as B and [34] as C). From Fig. 2(a) and
2(b), we can see that the distributions of these two indicators of those missed
spammers by existing approaches are more similar to that of all accounts than
that of all spammers. This observation implies that spammers are evolving to
pretend to be more legitimate by gaining more followers.
Posting More Tweets: Besides using the web to post tweets, spammers
can utilize some softwares such as AutoTwitter [3] and Twitter API [18] to
automatically post more tweets on their proﬁles. Fig. 2(c) shows the distribu-
tion of the numbers of tweets of the missed spammers in each of three existing
approaches, all spammers and all accounts. From this ﬁgure, we can ﬁnd that
missed spammers (false negatives) post much more tweets than all spammers,
even though the tweet numbers of all spammers are much lower than that of all
accounts. This observation also implies that spammers are trying to post more
tweets to not to be recognized as spammers.
F
D
C
l
a
c
i