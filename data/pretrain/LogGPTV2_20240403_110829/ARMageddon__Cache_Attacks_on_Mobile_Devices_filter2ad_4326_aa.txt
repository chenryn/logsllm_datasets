title:ARMageddon: Cache Attacks on Mobile Devices
author:Moritz Lipp and
Daniel Gruss and
Raphael Spreitzer and
Cl&apos;ementine Maurice and
Stefan Mangard
ARMageddon: Cache Attacks on Mobile Devices
Moritz Lipp, Daniel Gruss, Raphael Spreitzer, Clémentine Maurice, and Stefan Mangard, 
Graz University of Technology
 https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/lipp
This paper is included in the Proceedings of the 25th USENIX Security SymposiumAugust 10–12, 2016 • Austin, TXISBN 978-1-931971-32-4Open access to the Proceedings of the 25th USENIX Security Symposium is sponsored by USENIX ARMageddon: Cache Attacks on Mobile Devices
Moritz Lipp, Daniel Gruss, Raphael Spreitzer, Cl´ementine Maurice, and Stefan Mangard
Graz University of Technology, Austria
Abstract
In the last 10 years, cache attacks on Intel x86 CPUs have
gained increasing attention among the scientific com-
munity and powerful techniques to exploit cache side
channels have been developed. However, modern smart-
phones use one or more multi-core ARM CPUs that have
a different cache organization and instruction set than
Intel x86 CPUs. So far, no cross-core cache attacks have
been demonstrated on non-rooted Android smartphones.
In this work, we demonstrate how to solve key chal-
lenges to perform the most powerful cross-core cache at-
tacks Prime+Probe, Flush+Reload, Evict+Reload, and
Flush+Flush on non-rooted ARM-based devices without
any privileges. Based on our techniques, we demonstrate
covert channels that outperform state-of-the-art covert
channels on Android by several orders of magnitude.
Moreover, we present attacks to monitor tap and swipe
events as well as keystrokes, and even derive the lengths
of words entered on the touchscreen. Eventually, we are
the first to attack cryptographic primitives implemented
in Java. Our attacks work across CPUs and can even
monitor cache activity in the ARM TrustZone from the
normal world. The techniques we present can be used to
attack hundreds of millions of Android devices.
1
Introduction
Cache attacks represent a powerful means of exploit-
ing the different access times within the memory hi-
erarchy of modern system architectures. Until re-
cently,
these attacks explicitly targeted cryptographic
implementations, for instance, by means of cache tim-
ing attacks [9] or the well-known Evict+Time and
Prime+Probe techniques [43].
The seminal paper
by Yarom and Falkner [60] introduced the so-called
Flush+Reload attack, which allows an attacker to infer
which specific parts of a binary are accessed by a vic-
tim program with an unprecedented accuracy and prob-
ing frequency. Recently, Gruss et al. [19] demonstrated
the possibility to use Flush+Reload to automatically ex-
ploit cache-based side channels via cache template at-
tacks on Intel platforms. Flush+Reload does not only al-
low for efficient attacks against cryptographic implemen-
tations [8,26,56], but also to infer keystroke information
and even to build keyloggers on Intel platforms [19]. In
contrast to attacks on cryptographic algorithms, which
are typically triggered multiple times, these attacks re-
quire a significantly higher accuracy as an attacker has
only one single chance to observe a user input event.
Although a few publications about cache attacks on
AES T-table implementations on mobile devices ex-
ist [10, 50–52, 57], the more efficient cross-core attack
techniques Prime+Probe, Flush+Reload, Evict+Reload,
and Flush+Flush [18] have not been applied on smart-
phones. In fact, there was reasonable doubt [60] whether
these cross-core attacks can be mounted on ARM-based
devices at all. In this work, we demonstrate that these
attack techniques are applicable on ARM-based devices
by solving the following key challenges systematically:
1. Last-level caches are not inclusive on ARM and thus
cross-core attacks cannot rely on this property. In-
deed, existing cross-core attacks exploit the inclu-
siveness of shared last-level caches [18, 19, 22, 24,
35, 37, 38, 42, 60] and, thus, no cross-core attacks
have been demonstrated on ARM so far. We present
an approach that exploits coherence protocols and
L1-to-L2 transfers to make these attacks applicable
on mobile devices with non-inclusive shared last-
level caches, irrespective of the cache organization.1
2. Most modern smartphones have multiple CPUs that
do not share a cache. However, cache coherence
protocols allow CPUs to fetch cache lines from re-
mote cores faster than from the main memory. We
utilize this property to mount both cross-core and
cross-CPU attacks.
1Simultaneously to our work on ARM, Irazoqui et al. [25] devel-
oped a technique to exploit cache coherence protocols on AMD x86
CPUs and mounted the first cross-CPU cache attack.
USENIX Association  
25th USENIX Security Symposium  549
1
3. Except ARMv8-A CPUs, ARM processors do not
support a flush instruction.
In these cases, a fast
eviction strategy must be applied for high-frequency
measurements. As existing eviction strategies are
too slow, we analyze more than 4 200 eviction
strategies for our test devices, based on Rowham-
mer attack techniques [17].
4. ARM CPUs use a pseudo-random replacement pol-
icy to decide which cache line to replace within a
cache set. This introduces additional noise even for
robust time-driven cache attacks [50, 52]. For the
same reason, Prime+Probe has been an open chal-
lenge [51] on ARM, as an attacker needs to predict
which cache line will be replaced first and wrong
predictions destroy measurements. We design re-
access loops that interlock with a cache eviction
strategy to reduce the effect of wrong predictions.
5. Cycle-accurate timings require root access on
ARM [3] and alternatives have not been evaluated so
far. We evaluate different timing sources and show
that cache attacks can be mounted in any case.
Based on these building blocks, we demonstrate prac-
tical and highly efficient cache attacks on ARM.2 We
do not restrict our investigations to cryptographic im-
plementations but also consider cache attacks as a
means to infer other sensitive information—such as
inter-keystroke timings or the length of a swipe action—
requiring a significantly higher measurement accuracy.
Besides these generic attacks, we also demonstrate that
cache attacks can be used to monitor cache activity
caused within the ARM TrustZone from the normal
world. Nevertheless, we do not aim to exhaustively list
possible exploits or find new attack vectors on crypto-
graphic algorithms. Instead, we aim to demonstrate the
immense attack potential of the presented cross-core and
cross-CPU attacks on ARM-based mobile devices based
on well-studied attack vectors. Our work allows to ap-
ply existing attacks to millions of off-the-shelf Android
devices without any privileges. Furthermore, our investi-
gations show that Android still employs vulnerable AES
T-table implementations.
Contributions. The contributions of this work are:
• We demonstrate the applicability of highly efficient
cache attacks like Prime+Probe, Flush+Reload,
Evict+Reload, and Flush+Flush on ARM.
• Our attacks work irrespective of the actual cache or-
ganization and, thus, are the first last-level cache
attacks that can be applied cross-core and also
cross-CPU on off-the-shelf ARM-based devices.
More specifically, our attacks work against last-
2Source code for ARMageddon attack examples can be found at
https://github.com/IAIK/armageddon.
level caches that are instruction-inclusive and data-
non-inclusive as well as caches that are instruction-
non-inclusive and data-inclusive.
• Our cache-based covert channel outperforms all ex-
isting covert channels on Android by several orders
of magnitude.
• We demonstrate the power of
these attacks
by attacking cryptographic implementations and
by inferring more fine-grained information like
keystrokes and swipe actions on the touchscreen.
Outline. The remainder of this paper is structured as
follows. In Section 2, we provide information on back-
ground and related work. Section 3 describes the tech-
niques that are the building blocks for our attacks.
In
Section 4, we demonstrate and evaluate fast cross-core
and cross-CPU covert channels on Android.
In Sec-
tion 5, we demonstrate cache template attacks on user
input events. In Section 6, we present attacks on crypto-
graphic implementations used in practice as well the pos-
sibility to observe cache activity of cryptographic com-
putations within the TrustZone. We discuss countermea-
sures in Section 7 and conclude this work in Section 8.
2 Background and Related Work
In this section, we provide the required preliminaries and
discuss related work in the context of cache attacks.
2.1 CPU Caches
Today’s CPU performance is influenced not only by the
clock frequency but also by the latency of instructions,
operand fetches, and other interactions with internal and
external devices.
In order to overcome the latency of
system memory accesses, CPUs employ caches to buffer
frequently used data in small and fast internal memories.
Modern caches organize cache lines in multiple sets,
which is also known as set-associative caches. Each
memory address maps to one of these cache sets and ad-
dresses that map to the same cache set are considered
congruent. Congruent addresses compete for cache lines
within the same set and a predefined replacement policy
determines which cache line is replaced. For instance,
the last generations of Intel CPUs employ an undocu-
mented variant of least-recently used (LRU) replacement
policy [17]. ARM processors use a pseudo-LRU replace-
ment policy for the L1 cache and they support two dif-
ferent cache replacement policies for L2 caches, namely
round-robin and pseudo-random replacement policy. In
practice, however, only the pseudo-random replacement
policy is used due to performance reasons. Switching
the cache replacement policy is only possible in privi-
550  25th USENIX Security Symposium 
USENIX Association
2
leged mode. The implementation details for the pseudo-
random policy are not documented.
CPU caches can either be virtually indexed or phys-
ically indexed, which determines whether the index is
derived from the virtual or physical address. A so-called
tag uniquely identifies the address that is cached within
a specific cache line. Although this tag can also be based
on the virtual or physical address, most modern caches
use physical tags because they can be computed simul-
taneously while locating the cache set. ARM typically
uses physically indexed, physically tagged L2 caches.
CPUs have multiple cache levels, with the lower lev-
els being faster and smaller than the higher levels. ARM
processors typically have two levels of cache. If all cache
lines from lower levels are also stored in a higher-level
cache, the higher-level cache is called inclusive.
If a
cache line can only reside in one of the cache levels at
any point in time, the caches are called exclusive. If the
cache is neither inclusive nor exclusive, it is called non-
inclusive. The last-level cache is often shared among
all cores to enhance the performance upon transitioning
threads between cores and to simplify cross-core cache
lookups. However, with shared last-level caches, one
core can (intentionally) influence the cache content of all
other cores. This represents the basis for cache attacks
like Flush+Reload [60].
In order to keep caches of multiple CPU cores or CPUs
in a coherent state, so-called coherence protocols are em-
ployed. However, coherence protocols also introduce
exploitable timing effects, which has recently been ex-
ploited by Irazoqui et al. [25] on x86 CPUs.
In this paper, we demonstrate attacks on three smart-
phones as listed in Table 1. The Krait 400 is an ARMv7-
A CPU, the other two processors are ARMv8-A CPUs.
However, the stock Android of the Alcatel One Touch
Pop 2 is compiled for an ARMv7-A instruction set and
thus ARMv8-A instructions are not used. We generically
refer to ARMv7-A and ARMv8-A as “ARM architec-
ture” throughout this paper. All devices have a shared L2
cache. On the Samsung Galaxy S6, the flush instruction
is unlocked by default, which means that it is available
in userspace. Furthermore, all devices employ a cache
coherence protocol between cores and on the Samsung
Galaxy S6 even between the two CPUs [6].
2.2 Shared Memory
Read-only shared memory can be used as a means of
memory usage optimization. In case of shared libraries it
reduces the memory footprint and enhances the speed by
lowering cache contention. The operating system imple-
ments this behavior by mapping the same physical mem-
ory into the address space of each process. As this mem-
ory sharing mechanism is independent of how a file was
opened or accessed, an attacker can map a binary to have
read-only shared memory with a victim program. A sim-
ilar effect is caused by content-based page deduplication
where physical pages with identical content are merged.
Android applications are usually written in Java and,
thus, contain self-modifying code or just-in-time com-
piled code. This code would typically not be shared.
Since Android version 4.4 the Dalvik VM was gradu-
ally replaced by the Android Runtime (ART). With ART,
Java byte code is compiled to native code binaries [1] and
thus can be shared too.
2.3 Cache Attacks
Initially, cache timing attacks were performed on cryp-
tographic algorithms [9, 30, 31, 40, 41, 44, 55]. For ex-
ample, Bernstein [9] exploited the total execution time
of AES T-table implementations. More fine-grained
exploitations of memory accesses to the CPU cache
have been proposed by Percival [45] and Osvik et al.
[43]. More specifically, Osvik et al. formalized two con-
cepts, namely Evict+Time and Prime+Probe, to deter-
mine which specific cache sets were accessed by a victim
program. Both approaches consist of three basic steps.
Evict+Time:
1. Measure execution time of victim program.
2. Evict a specific cache set.
3. Measure execution time of victim program again.
Prime+Probe:
1. Occupy specific cache sets.
2. Victim program is scheduled.
3. Determine which cache sets are still occupied.
Both approaches allow an adversary to determine
which cache sets are used during the victim’s compu-
tations and have been exploited to attack cryptographic
implementations [24, 35, 43, 54] and to build cross-VM
covert channels [37]. Yarom and Falkner [60] proposed
Flush+Reload, a significantly more fine-grained attack
that exploits three fundamental concepts of modern sys-
tem architectures. First, the availability of shared mem-
ory between the victim process and the adversary. Sec-
ond, last-level caches are typically shared among all
cores. Third, Intel platforms use inclusive last-level
caches, meaning that the eviction of information from the
last-level cache leads to the eviction of this data from all
lower-level caches of other cores, which allows any pro-
gram to evict data from other programs on other cores.
While the basic idea of this attack has been proposed by
Gullasch et al. [21], Yarom and Falkner extended this
idea to shared last-level caches, allowing cross-core at-
tacks. Flush+Reload works as follows.
Flush+Reload:
1. Map binary (e.g., shared object) into address space.
2. Flush a cache line (code or data) from the cache.
USENIX Association  
25th USENIX Security Symposium  551
3
Device
OnePlus
One
Alcatel One
Touch Pop 2
SoC
Qualcomm
Snapdragon 801
Qualcomm
Snapdragon 410
Samsung
Galaxy S6
Samsung Exynos
7 Octa 7420
Table 1: Test devices used in this paper.
CPU (cores)
Krait 400 (2)
2.5 GHz
Cortex-A53 (4)
1.2 GHz
Cortex-A53 (4)
1.5 GHz
Cortex-A57 (4)
2.1 GHz
L1 caches
2× 16 KB,
4-way, 64 sets
4× 32 KB,
4-way, 128 sets
4× 32 KB,
4-way, 128 sets
4× 32 KB,
2-way, 256 sets
L2 cache
2 048 KB,
8-way, 2 048 sets
512 KB,
16-way, 512 sets
256 KB,
16-way, 256 sets
2 048 KB,
16-way, 2 048 sets
Inclusiveness
non-inclusive
instruction-inclusive,
data-non-inclusive
instruction-inclusive,
data-non-inclusive
instruction-non-inclusive,
data-inclusive
3. Schedule the victim program.
4. Check if the corresponding line from step 2 has
been loaded by the victim program.
Thereby, Flush+Reload allows an attacker to deter-
mine which specific instructions are executed and also
which specific data is accessed by the victim program.
Thus, rather fine-grained attacks are possible and have
already been demonstrated against cryptographic im-
plementations [22, 27, 28]. Furthermore, Gruss et al.
[19] demonstrated the possibility to automatically ex-
ploit cache-based side-channel
information based on
the Flush+Reload approach. Besides attacking crypto-
graphic implementations like AES T-table implementa-
tions, they showed how to infer keystroke information
and even how to build a keylogger by exploiting the
cache side channel. Similarly, Oren et al. [42] demon-
strated the possibility to exploit cache attacks on Intel
platforms from JavaScript and showed how to infer vis-
ited websites and how to track the user’s mouse activity.
Gruss et al. [19] proposed the Evict+Reload technique
that replaces the flush instruction in Flush+Reload by
eviction. While it has no practical application on x86
CPUs, we show that it can be used on ARM CPUs. Re-
cently, Flush+Flush [18] has been proposed. Unlike
other techniques, it does not perform any memory ac-
cess but relies on the timing of the flush instruction to
determine whether a line has been loaded by a victim.
We show that the execution time of the ARMv8-A flush
instruction also depends on whether or not data is cached
and, thus, can be used to implement this attack.
While the attacks discussed above have been proposed
and investigated for Intel processors, the same attacks
were considered not applicable to modern smartphones
due to differences in the instruction set, the cache or-
ganization [60], and in the multi-core and multi-CPU
architecture. Thus, only same-core cache attacks have
been demonstrated on smartphones so far. For instance,
Weiß et al. [57] investigated Bernstein’s cache-timing at-
tack [9] on a Beagleboard employing an ARM Cortex-
A8 processor. Later on, Weiß et al. [58] investigated this
timing attack in a multi-core setting on a development
board. As Weiß et al. [57] claimed that noise makes
the attack difficult, Spreitzer and Plos [52] investigated
the applicability of Bernstein’s cache-timing attack on
different ARM Cortex-A8 and ARM Cortex-A9 smart-
phones running Android. Both investigations [52, 57]
confirmed that timing information is leaking, but the at-
tack takes several hours due to the high number of mea-
surement samples that are required, i.e., about 230 AES
encryptions. Later on, Spreitzer and G´erard [50] im-
proved upon these results and managed to reduce the key
space to a complexity which is practically relevant.
Besides Bernstein’s attack, another attack against AES
T-table implementations has been proposed by Bog-
danov et al. [10], who exploited so-called wide collisions
on an ARM9 microprocessor. In addition, power analysis
attacks [13] and electromagnetic emanations [14] have
been used to visualize cache accesses during AES com-
putations on ARM microprocessors. Furthermore, Spre-
itzer and Plos [51] implemented Evict+Time [43] in or-
der to attack an AES T-table implementation on Android-
based smartphones. However, so far only cache attacks
against AES T-table implementations have been consid-
ered on smartphone platforms and none of the recent ad-
vances have been demonstrated on mobile devices.
3 ARMageddon Attack Techniques
We consider a scenario where an adversary attacks a
smartphone user by means of a malicious application.
This application does not require any permission and,
most importantly,
it can be executed in unprivileged
userspace and does not require a rooted device. As our
attack techniques do not exploit specific vulnerabilities
of Android versions, they work on stock Android ROMs
as well as customized ROMs in use today.
3.1 Defeating the Cache Organization
In this section, we tackle the aforementioned challenges
1 and 2, i.e., the last-level cache is not inclusive and mul-
tiple processors do not necessarily share a cache level.
552  25th USENIX Security Symposium 
USENIX Association
4
Core 0
Core 1
L1I
L1D
L1I
L1D
s
t