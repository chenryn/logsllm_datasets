title:Evaluating the Impact of Automated Intrusion Response Mechanisms
author:Thomas Toth and
Christopher Kr&quot;ugel
Evaluating the Impact of
Automated Intrusion Response Mechanisms
Thomas Toth and Christopher Kruegel
Technical University Vienna, Austria
Institute for Information Systems
Argentinierstrasse 8, A-1040 Vienna, Austria
fttoth, PI:EMAIL
Abstract
Intrusion detection systems (IDSs) have reached a high
level of sophistication and are able to detect intrusions with
a variety of methods. Unfortunately, system administrators
neither can keep up with the pace that an IDS is deliver-
ing alerts, nor can they react upon these within adequate
time limits. Automatic response systems have to take over
that task. In case of an identiﬁed intrusion, these compo-
nents have to initiate appropriate actions to counter emerg-
ing threats. Most current intrusion response systems (IRSs)
utilize static mappings to determine adequate response ac-
tions in reaction to detected intrusions. The problem with
this approach is its inherent inﬂexibility. Countermeasures
(such as changes of ﬁrewall rules) often do not only defend
against the detected attack but may also have negative ef-
fects on legitimate users of the network and its services. To
prevent a situation where a response action causes more
damage that the actual attack, a mechanism is needed that
compares the severity of an attack to the effects of a possible
response mechanism. In this paper, we present a network
model and an algorithm to evaluate the impact of response
actions on the entities of a network. This allows the IRS to
select the response among several alternatives which fulﬁlls
the security requirements and has a minimal negative effect
on legitimate users.
1. Introduction
The constant increase of attacks against networks and
their resources causes the necessity to protect these valuable
assets. Although well-conﬁgured ﬁrewalls provide good
protection against many attacks, some services (like HTTP
or DNS) have to be publicly available. In such cases, a ﬁre-
wall has to allow incoming trafﬁc from the Internet to these
services without restrictions. As a matter of fact, the pro-
grams implementing these services are often complex and
old pieces of software. This inevitably leads to the existence
of programming bugs which can be exploited by skilled in-
truders.
Intrusion detection systems (IDSs) are security tools that
are used to detect traces of malicious activities which are
targeted against networks and their resources. IDSs are tra-
ditionally classiﬁed as anomaly or signature based. Signa-
ture based systems like Snort [10], STAT [12] or NetSTAT
[13, 14] act similar to virus scanners and look for known,
suspicious patterns in their input data. Anomaly based sys-
tems watch for deviations of actual from expected behavior
and classify all ‘abnormal’ activities as malicious.
As signature based designs compare their input
to
known, hostile scenarios they have the advantage of rais-
ing virtually no false alarms (i.e. classifying an action as
malicious when in fact it is not). For the same reason, they
have the signiﬁcant drawback of failing to detect variations
of known attacks or entirely new intrusions.
Because of the ability to detect previously unknown in-
trusions a number of different anomaly based systems have
been proposed. Depending on their source of input data,
they are divided into host based and network based designs.
Host based anomaly detection systems can focus on user
or program behavior. User proﬁles are built from login
times and accessed resources (e.g. ﬁles, programs) or from
timing analysis of keystrokes [4, 1]. Unfortunately, user be-
havior is hard to predict and can change frequently. Addi-
tionally, such systems cannot react properly when network
services get compromised as no single user proﬁle can be
associated to a daemon program.
As a consequence, the focus was shifted from user to
program behavior. The execution of a program is modeled
as a set of system call sequences [6, 5] which occur during
‘normal’ program execution. When the observed sequences
deviate from the expected behavior the program is assumed
to perform something unintended, possibly because of a
Proceedings of the 18th Annual Computer Security Applications Conference (ACSAC(cid:146)02) 
1063-9527/02 $17.00 ' 2002 IEEE 
successful attack (e.g. buffer overﬂow).
Most network based anomaly detection systems [8, 9]
only model the ﬂow of packets. The source and destination
IP addresses and ports are used to determine parameters like
the number of total connection arrivals in a certain period
of time, the inter-arrival time between packets or the num-
ber of packets to/from a certain machine. These parameters
can be used to reliably detect port scans or denial-of-service
(DOS) attempts. In [7], an anomaly based method has been
introduced that analyzes the packet payload to identify ma-
licious content used in exploits.
Intrusion response systems (IRSs) take over after signs
of an intrusion are identiﬁed and either record the attack or
attempt to actively counter it. Although IRSs are tightly
coupled with the ID systems themselves and are as impor-
tant as these in defending against threats, not much research
effort has been put into their study. Therefore, intrusion re-
sponse, in most cases, remains a manual process which has
to be performed by the system administrator [2].
Current intrusion response systems can be divided into
notiﬁcation, manual response and automatic response sys-
tems.
The majority of IRSs operate as notiﬁcation systems,
which means that they simply display or forward output de-
livered by the IDS (e.g. incident data) to the system admin-
istrator. Usually, urgent notiﬁcation is realized via e-mail or
text message services over a mobile phone.
Manual IRS allows the administrator to manually launch
countermeasures against a detected intrusion by choosing
from a predetermined set of response mechanisms. This
might allow the administrator to harden the ﬁrewall or to
change router conﬁgurations to disallow malicious trafﬁc.
Manual response can help to cut off denial-of-service at-
tacks [11] but is also beneﬁcial in the case that the sys-
tem detects a hacker who has just obtained access to a cer-
tain host. Such systems support an administrator by offer-
ing ready-to-apply reconﬁguration mechanisms in order to
quickly secure the system. Nevertheless, a person has to
determine which methods are appropriate.
The two categories listed above are not proactive in
countering an intrusion. Even when signs of an intrusion
have been detected, countermeasures are not triggered au-
tomatically and defending the network remains a task for
the system administrator. This opens a time window of vul-
nerability between the point when the intrusion has been
detected and the point when the ﬁrst countermeasure is
launched. The size of this time window can range from
seconds to hours (e.g. during night times or weekends).
According to [3], the success rate of an intruder rises
with the time he can work undisturbed. This interesting
study reports that a skilled attacker can perform an intru-
sion with a 80% success rate if he is given 10 hours time
before any response is launched.
In contrast to the two approaches shown above, au-
tomatic response systems attempt to choose appropriate
countermeasures without human intervention. This allows
to dramatically reduce the size of the vulnerability win-
dow. Most current systems implementing automatic re-
sponse mechanisms use simple decision tables to determine
how to react in the case of identiﬁed attacks. More sophisti-
cated variants such as Cooperating Security Managers [15]
and Emerald [9] apply expert systems to perform that task.
Decision tables are an inherently inﬂexible mechanism
because they allow only a static mapping between intrusions
and the corresponding response actions and do not take pos-
sible negative side effects of countermeasures into account.
In order to provide optimal responses, all possible situa-
tions would have to be encoded in that static table. As this
is clearly infeasible (often situations are not known to the
person creating that table), one has to fall back to default
mechanisms when encountering new situations.
Additionally, it is only feasible to build the static map-
ping table for small networks. In such cases, an operator
can perform the analysis of (all) threat scenarios and deter-
mine the table entries manually. If the network is large and
the network services become more and more intertwined,
hidden dependencies cause the generation of the mapping
table to be more and more cumbersome and error prone.
Another severe problem are false positives (i.e. the IDS
raises an unjustiﬁed alarm). When the corresponding coun-
termeasure in case of an incorrect alert is executed by the
IRS, legitimate users may be negatively effected. Consider
a ﬁrewall reconﬁguration which prohibits incoming connec-
tions to a certain service which is needed by users outside
the network (a nightmare for e-commerce sites).
Emerald and CSM mitigate the drawbacks of a static
mapping table in case of a false alarm by including sever-
ity and conﬁdence metrics into their response process. The
conﬁdence metrics describes the belief of the system that
detected evidence is the indication of a real intrusion. The
severity metrics rates all response mechanism according
to their (potential) negative side effects on legitimate net-
work operations. Measurements with a high severity level
are only allowed when the conﬁdence in an attack is high
enough. A quite similar idea is described in [2] where the
determination of an appropriate response function is done
with the consideration of the expected false positive rate of
the underlying IDS. If the IDS is expected to have a low
false positive rate, the IRS is more likely to invoke severe
response actions.
Such metrics work well when the response action does
not interfere with many other services or when the response
does not last longer than a reasonable small amount of time.
Unfortunately, responses with long-term effects may se-
riously hamper regular users from performing their tasks.
Current response systems do not take normal operation into
Proceedings of the 18th Annual Computer Security Applications Conference (ACSAC(cid:146)02) 
1063-9527/02 $17.00 ' 2002 IEEE 
account and have no notion of dependencies of services be-
tween each other. Large networks contain many hosts, each
running several services which might require other services,
making a thorough manual analysis very difﬁcult. The de-
pendencies among the services are usually very complex,
involving a number of different protocols. While some ser-
vices are critical for remote services or users, others may be
unavailable for some time without causing problems.
The proposed severity and conﬁdence metrics are a ﬁrst
step into the right direction, as they attempt to estimate the
negative side effects of response mechanism. Nevertheless,
they do not include the analysis of the actual network topol-
ogy or services. In addition, these mechanisms are not ﬂex-
ible in assigning priorities to certain services according to
their importance for regular tasks. While the webserver of
an e-commerce site has to remain operational at all times,
this might not be necessary for normal companies. The cost
of having a service off-line due to a response action might
be higher than the threat of the attack. Current models do
not allow to model such requirements.
In this paper, we present a network model to evaluate the
effect of intrusion response mechanisms to the operation of
network services, thus enabling the IRS to choose the best
alternative from a set of possible alternatives. Our model
takes into account the network topology and the dependen-
cies between different entities to capture the consequences
of responses more accurately. Based on this model, an eval-
uation function can estimate the impact of various responses
and select the one with the expected minimal negative con-
sequences.
We deﬁne a modeling language to specify the resources
with their dependencies as well as response actions and their
impact on the availability of resources. By including user
requirements into our network model, different sites can tai-
lor the responses according to their needs.
The next two chapters discuss our requirements and the
network model itself. Section 4 describes the evaluation
function to calculate the effects of responses, while Sec-
tion 5 presents details about the implementation. Then we
provide some measurements obtained from our prototype.
Finally, we outline further research and conclude.
2. Model Requirements
This section elaborates on the requirements that we have
identiﬁed for our network model to be able to accurately
calculate the effects of responses. In the following sections,
we focus on responses that can reconﬁgure the ﬁrewall, en-
able or disable user accounts and modify the status of pro-
cesses running on a host (i.e. restarting network services,
terminating malicious programs).
(cid:15) Flexibility The model has to be able to cope with dif-
ferent network topologies and must be able to express
the dependencies among resources themselves and be-
tween services and users. As there should be no ar-
tiﬁcial restrictions, our model should not have to rely
on simple mapping tables for calculating response ef-
fects. Instead, the actual situation of the network needs
to be reﬂected in the model to be able to determine the
effects of response actions accurately.
Not all resources or users have the same relevance for
the operation of the network – this fact has to be ex-
pressible in our model. A resource that is only utilized
by low priority entities is obviously less important than
one used by a mission critical entity. The importance
of a resource can vary dynamically - even by the time
of day.
(cid:15) Dynamic Model The model has to be dynamic to be
able to track changes in the environment (caused by
response actions). A reconﬁguration of the ﬁrewall has
to be reﬂected in the model, as well as changes in the
availability of services due to their (de)activation by a
response.
(cid:15) Efﬁciency In order to be useful, the evaluation func-
tion needs to be evaluated quickly. IRSs have to re-
spond fast in order to keep the time window of vulner-
ability small. The model should make the design of an
efﬁcient evaluation function possible.
(cid:15) Ease of Use In a large network, there are many depen-
dencies between different entities.
In order to make
administration of our proposed system easy, not all of
them should have to be entered explicitly by an admin-
istrator. The majority of dependencies can be deter-
mined automatically by the analysis of transitive rela-
tions and the network topology. Only basic relation-
ships at a high level (e.g. this host needs access to a
DNS server) should have to be speciﬁed.
The model should be intuitive and comprehensive in
the sense that it resembles the facts of the real world.
A smooth integration of entities and their dependencies
is necessary to achieve this goal.
(cid:15) Minimization of Negative Impact The model should
be able to help the IRS determine which response ac-
tion to use. In the case that more than one response
action is available, the one which has the least nega-
tive effects on the whole system should be chosen.
3. Network Model
The following section introduces our network model that
is used to calculate the effects of response actions. First, the
elements, which are included in our model, are identiﬁed.
The basic elements, as explained in more detail below, are
Proceedings of the 18th Annual Computer Security Applications Conference (ACSAC(cid:146)02) 
1063-9527/02 $17.00 ' 2002 IEEE 
services provided by hosts, users of the network, the under-
lying communication infrastructure and ﬁrewall rules that
are currently in effect.
Then, we specify how direct and indirect dependencies
between entities are represented. After that the algorithm
that operates on this model to determine the effects of re-
sponses is explained.
3.1. Modeled Elements
Networks are complex structures that include many el-
ements which are heavily related and dependent on each
other. For our model, the following elements are relevant
(in the following explanation, system users and resources
are together referred to as entities).
(cid:15) Resources Resources describe network services of-
fered by hosts. They build the basic building blocks of
our network model and can depend on other resources
to various degrees. A resource is a network service
which is provided by a process on a host. Examples of
resources/services are DNS, NFS, NIS, HTTP or FTP.
A process provides resources to others by listening on
a predeﬁned port to which other processes or users can
submit requests. Requests are processed and a reply is
sent back to the originator of the query. In our model,
only resources that are used by other entities have to be
included, and processes running at a host without pro-
viding services to external entities are not considered
to be resources.
(cid:15) System Users Users have to perform their tasks by uti-
lizing the provided resources, therefore they have to be
part of the model as well. Users can assign different
levels of importance to resources.
(cid:15) Network Topology The network topology has an im-
portant role for the evaluation process because it deter-
mines the communication framework utilized between
different resources.
(cid:15) Firewall Rules The installed ﬁrewall rules effect the
availability of resources/services of the protected net-
work. Dependencies between two resources located in
the same subnet are not affected by response effects
that modify ﬁrewall rules. In the case that the com-
munication path from one resource to another leads
through a ﬁrewall, its rules obviously inﬂuence the
availability of that resource.
3.2. Entity Dependencies
This section explains the different types of dependencies
between entities.
Deﬁnition: An entity, which needs a service that is pro-
vided by another entity to be fully operational, is called de-
pendent on that entity. The relation between these two en-
tities is called a dependency. Among the different entities
which are distributed over the hosts of a network, there are
many dependency relationships. While some entities do not