title:The Cookie Hunter: Automated Black-box Auditing for Web Authentication
and Authorization Flaws
author:Kostas Drakonakis and
Sotiris Ioannidis and
Jason Polakis
The Cookie Hunter: Automated Black-box Auditing for Web
Authentication and Authorization Flaws
Kostas Drakonakis∗
FORTH ICS, Greece
PI:EMAIL
Technical University of Crete, Greece
University of Illinois at Chicago, USA
Jason Polakis
PI:EMAIL
Sotiris Ioannidis†
PI:EMAIL
ABSTRACT
In this paper, we focus on authentication and authorization flaws
in web apps that enable partial or full access to user accounts.
Specifically, we develop a novel fully automated black-box auditing
framework that analyzes web apps by exploring their susceptibil-
ity to various cookie-hijacking attacks while also assessing their
deployment of pertinent security mechanisms (e.g., HSTS). Our
modular framework is driven by a custom browser automation tool
developed to transparently offer fault-tolerance during extended
interactions with web apps. We use our framework to conduct
the first automated large-scale study of cookie-based account hi-
jacking in the wild. As our framework handles every step of the
auditing process in a completely automated manner, including the
challenging process of account creation, we are able to fully au-
dit 25K domains. Our framework detects more than 10K domains
that expose authentication cookies over unencrypted connections,
and over 5K domains that do not protect authentication cookies
from JavaScript access while also embedding third party scripts
that execute in the first party’s origin. Our system also automat-
ically identifies the privacy loss caused by exposed cookies and
detects 9,324 domains where sensitive user data can be accessed
by attackers (e.g., address, phone number, password). Overall, our
study demonstrates that cookie-hijacking is a severe and prevalent
threat, as deployment of even basic countermeasures (e.g., cookie
security flags) is absent or incomplete, while developers struggle to
correctly deploy more demanding mechanisms.
CCS CONCEPTS
• Security and privacy → Web application security.
KEYWORDS
Black-box Testing; Cookie Hijacking; Authentication; Authoriza-
tion; Large-Scale Measurement
∗Part of this work was completed while at the University of Illinois at Chicago.
†Sotiris Ioannidis is also with FORTH ICS.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
CCS ’20, November 9–13, 2020, Virtual Event, USA
© 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-7089-9/20/11...$15.00
https://doi.org/10.1145/3372297.3417869
ACM Reference Format:
Kostas Drakonakis, Sotiris Ioannidis, and Jason Polakis. 2020. The Cookie
Hunter: Automated Black-box Auditing for Web Authentication and Au-
thorization Flaws. In Proceedings of the 2020 ACM SIGSAC Conference on
Computer and Communications Security (CCS ’20), November 9–13, 2020,
Virtual Event, USA. ACM, New York, NY, USA, 18 pages. https://doi.org/10.
1145/3372297.3417869
1 INTRODUCTION
Web services have become treasure troves of sensitive data, ren-
dering user accounts high-value targets for attackers. Recently, au-
thentication flaws in popular web applications (or “apps”) exposed
sensitive data and allowed access to critical functionality of millions
of accounts [4, 5]. Reports have even implicated nation-state adver-
saries in attacks that ultimately aimed to steal user credentials [6, 7].
As such, authentication and authorization flaws in web apps are of
great importance [89, 98] as they pose a significant threat. However,
detecting such flaws is challenging.
As new technologies and features continue to emerge, web apps
are becoming increasingly complicated. This complexity is exacer-
bated by their rapid evolution and the addition of new functionality
and modules [35, 39]. This can result in the introduction of semantic
bugs whose composite nature [81] renders detection a challeng-
ing task [39, 70]. Moreover, the massive codebase that comprises
modern web apps is often developed by separate teams, which can
have a negative impact [72] and result in fragmented auditing pro-
cedures that do not fully capture the side effects that arise from
the interoperability of different components. Web apps can also
include legacy code, which is often a significant source of new vul-
nerabilities [33], further complicating internal auditing procedures.
To make matters worse, applicable security mechanisms are often
deployed in an incomplete or incorrect manner [32, 47, 52, 76, 92].
As a result, external auditing initiatives from researchers can sig-
nificantly contribute to the overall hygiene of the web ecosystem
by discovering vulnerabilities. However, the sheer scale of this is-
sue and the prevalence of obfuscation [78] mandate an automated,
black-box dynamic analysis.
In this paper we adopt such an approach and focus on flaws
that lead to the exposure of authentication cookies that allow ad-
versaries to access sensitive data or account functionality. While
recent studies have demonstrated that such flaws exist even in the
most popular websites [30, 44, 77], these studies relied on signifi-
cant manual effort and were, thus, inherently small-scale covering
a very limited number of domains. With surveys reporting that
Internet users in the US now have ∼150 password-protected ac-
counts [2], and tens of thousands of websites streamlining account
creation through Single Sign-On [44], it is apparent that manual
efforts are not sufficient. To that end, we develop a completely
Session 6D: Web Security CCS '20, November 9–13, 2020, Virtual Event, USA1953automated black-box auditing framework that detects authenti-
cation and authorization flaws in web apps and identifies what
sensitive/personal user information can be harvested by attack-
ers. Our system is designed to handle every step of the process,
including account creation and user-level interactions. Specifically,
our framework analyzes the characteristics and infers the access
privileges granted to cookies, while also evaluating the deployment
of security mechanisms that can prevent cookie-hijacking attacks.
The main design goal of our framework is to automatically audit
web apps in a black-box manner, without any prior knowledge of
the underlying app’s structure or code. The framework is driven
by XDriver, our custom browser-automation tool built on top of
Selenium, designed for robustness and fault-tolerance during pro-
longed interactions with web apps. As XDriver is geared towards
security-related tasks, we have implemented modules for evalu-
ating security mechanisms that are pertinent to our study (e.g.,
HSTS). The black-box auditing process is handled by a series of
components dedicated to specific phases of our workflow, including
components that employ differential analysis and a series of oracles
for inferring the account’s “state” reached by requests depending
on the cookies submitted and the level of account access granted
to those cookies. This requires identifying which cookies are used
for authentication and exploring the conditions for different attack
vectors under which they can be hijacked. Finally, our framework
includes a novel module that analyzes web apps and detects per-
sonal user data (e.g., name, email, phone number) that is accessible
using hijacked cookies. This is achieved through an in-depth in-
vestigation that analyzes the app’s client-side source, storage, and
URL parameters to detect the exposure of sensitive data.
Using our framework we conduct the first fully automated, com-
prehensive, large-scale analysis of cookie hijacking in the wild.
First, we crawl 1.5 million domains, and identify over 200 thou-
sand domains that support account creation. Subsequently, our
framework manages to fully audit almost 25 thousand (∼12%) of
the domains, requiring 8.5 minutes per domain on average. Our ex-
periments reveal that 50.3% of those domains expose their cookies
under different scenarios and, thus, suffer from authentication or
authorization flaws. To make matters worse, we find that security
mechanisms that could prevent these attacks are not widely adopted
(only 11.8% of vulnerable domains do so) or are often deployed in an
erroneous manner. In more detail, we find that 10,921 domains ex-
pose authentication cookies over unencrypted connections, which
can be hijacked by passive eavesdroppers and used to access users’
accounts. Moreover, 5,099 domains do not protect their authenti-
cation cookies from JavaScript-based access while simultaneously
including embedded, non-isolated, third party scripts that run in
the first party’s origin. With these scripts being fetched from 2,463
unique third party domains, users currently face a considerable
risk of malicious, compromised, or honest-but-curious third parties
reading their authentication cookies.
Due to the severity of the flaws detected by our system, it is
crucial that our findings are made available to developers so they
can patch their systems. While we have notified several vulnera-
ble domains, finding an appropriate contact point for such a vast
number of domains is infeasible; thus, we will set up a notification
service that allows developers to access the auditing results. In
summary, our main research contributions are:
• We develop a custom browser automation tool that transparently
offers robustness during prolonged interaction with web apps.
Our tool is tailored for security-oriented tasks and includes mod-
ules for assessing relevant security mechanisms. As our system
can streamline a wide range of research projects, our code will
be made open source.
• We develop a novel framework for the automated black-box
detection of flaws in web apps. Our framework incorporates a
series of modules and oracles that employ differential analysis
for automatically evaluating the feasibility of cookie hijacking
attacks under different threat models, and detecting the exposure
of personal user data across multiple dimensions. To facilitate
further research, we will share our code with vetted researchers
upon publication.
• We conduct the largest study of cookie-based authentication and
authorization flaws by auditing ∼25K domains. Our comprehen-
sive evaluation reveals a plethora of security malpractices and
misconfigurations, as 50.3% of the domains are vulnerable to at
least one attack.
2 BACKGROUND AND THREAT MODEL
Our framework focuses on detecting authentication and authoriza-
tion flaws that stem from the incorrect handling or protection of
cookies. While cookie hijacking is not a new attack vector, it can still
affect even the most popular websites (e.g., Google, Facebook) and
expose users to significant threats [77] including complete account
takeover [44]. We consider the following types of attackers.
Passive network attacker. This attacker, referred to as an
eavesdropper, has the ability to intercept and inspect unencrypted
HTTP traffic (but does not attempt to modify it). We assume this at-
tacker cannot intercept HTTPS traffic, and do not explore more elab-
orate, active attacks (e.g., SSL-stripping [60], cookie-overwriting [94]).
This means that any cookies that are not protected with the secure
flag can be intercepted by this attacker when appended to an HTTP
request. This can, e.g., occur naturally while a user browses a web-
site (since many websites serve certain resources over HTTP). An
important detail that amplifies the practicality of this attack is that
even when a domain supports HTTPS, browsers will by default
attempt to access the domain over HTTP before being redirected
by the web server to HTTPS [77]. While this can be prevented with
mechanisms like HSTS, they are still not widely adopted and are
often deployed incorrectly [52, 76].
Web attacker. This attacker can execute some JavaScript code
within the origin of the web app, e.g., through a cross-site scripting
(XSS) attack [45]. Another attack vector is introduced if the web
app includes a script from a third party domain without “isolating”
it in an iframe, effectively allowing it to execute in the first party’s
origin [65]; malicious scripts (e.g., malvertising [59]) or compro-
mised script providers can then read first party cookies [18]. We
define as third-party any scripts that are loaded from a different
domain [73, 82, 83], where the term domain will be used to refer to
the eTLD+1 domain throughout the paper. Consequently, cookies
that are not protected with the httpOnly flag will be readable by
client-side code and can be obtained by the attacker. We refer to
these two attack vectors as JS cookie stealing.
Session 6D: Web Security CCS '20, November 9–13, 2020, Virtual Event, USA1954For each visited page, we extract any forms that resemble a
login or signup process, and a series of heuristics are employed for
detecting such forms within a page’s code. Specifically, for each
form we first count the number of text, email, password, checkbox
and radio type input fields. We also check which of those are visible
following the custom heuristics proposed by SSOScan [96]. If there
are no password fields we skip the form since it probably is not a
login or signup form (e.g., contact forms are common). If it contains
more than one password field we label it as a signup form since
such forms usually require the user to retype the password for
verification. If there is a single password field and a single text field
we label it as a login form, as this is the typical structure of such
forms. If there are more than one text fields or checkbox/radio fields
(accounting for the "remember me" option in login forms) the form is
labeled as a signup form. If the form has a more irregular structure
and has not been identified with these heuristics, our system resorts
to using two sets of regular expressions (one for login and one for
signup) for analyzing the HTML code and detecting elements that
allow us to label the form accordingly.
Automated sign up. Automating the account creation process
in an application-agnostic way is a challenging task. This is due to
the fact that websites have different requirements and constraints
regarding the type and format of information for the fields needed
for completing the registration. These vary and pertain to the num-
ber and type of fields (e.g., email, password, username etc.), as well
as to the different restrictions in what is considered a valid input.
For instance, a website might consider “+1 012 345 6789” a valid US
number while another might require a different format.
The Signup module iterates over the discovered signup pages
and attempts to fill each candidate form appropriately. We use a
manually-curated set of regular expressions that try to detect what
type of information each input element is expecting (e.g., email,
postal address, date). We first carefully assign labels to each of the
input elements by checking the for attribute of label elements, since
we expect them to be the most descriptive. If there is no match, we
move on to the element’s HTML code (i.e., its attributes), which
can reveal useful information about its type (e.g., an element of
type email or with a descriptive id like last_name). If our mod-
ule has yet to identify what type of information is expected, we
consider the text content preceding the element. While this is the
most common convention for labeling elements, developers are
not constrained and can structure their forms differently. We, thus,
follow a conservative strategy and consider these assigned labels
as possible labels, since we cannot be certain of the form structure
– in some cases the input element’s accompanying text might be
after the element. This is also why we prioritize any previously
identified labels, and consider the “possible” labels as a last resort.
If there is still no match, we use Google Translate to translate any
labels assigned to the element in English and repeat the aforemen-
tioned process. This is needed since our analysis is not limited to
English websites and foreign content is common. We refrain from
using Google Translate initially, since the previous steps might
reveal the type of field, allowing us to avoid the unnecessary API
calls. Finally, we resort to either a random string for text inputs or
a random selection for select and radio elements. To generate valid
inputs after having detected the element’s type, we use Python’s
Faker package. We also infer the input’s expected size by inspecting
Figure 1: Major phases in our auditing workflow.
It is important to stress that our framework does not search for
XSS bugs or malicious third party scripts; our system focuses on au-
tomatically inferring the feasibility of stealing authentication cook-
ies through JavaScript due to insufficient protection, and exploring
the subsequent privacy implications for users. As such, the numbers
reported on JavaScript-based cookie stealing are an upper bound
that is contingent on the presence of XSS vulnerabilities or mali-
cious third party scripts. Nonetheless, XSS vulnerabilities remain
one of the most common attacks against web applications [1] and a
plethora of detection systems have been proposed (e.g., [20, 82, 85]).
Similarly, recent work has highlighted the prevalence of (suspicious)
third party scripts [49, 55].
3 SYSTEM DESIGN AND IMPLEMENTATION
Here we present our framework and the methodology of the core
components of our black-box auditing process. Figure 1 depicts a
high-level view of the workflow for clarity, and to facilitate presen-
tation. In the following subsections we highlight each component
in our pipeline and provide design and implementation details.
3.1 Automated Account Setup
The first phase in our workflow is to automatically create accounts.
URL Discovery. This module follows a straightforward process
of crawling domains and terminating when both a login and a
signup form have been located. As a first step it explores the URLs
included in the public dataset by Ghasemisharif et al. [44]. If it
does not locate both types of forms, next it will crawl the target
web application. The crawl starts at the landing page and goes to a
depth of 2 – we opt for a more shallow crawl to reduce the crawl’s
duration and enable our large-scale study. Our framework collects
all links included in each page that point to the same domain, and
subsequently visits and inspects them. This step prioritizes links
that contain an account-related keyword (e.g., signin, register etc.)
and follows a breadth-first search (BFS) approach. If both types of