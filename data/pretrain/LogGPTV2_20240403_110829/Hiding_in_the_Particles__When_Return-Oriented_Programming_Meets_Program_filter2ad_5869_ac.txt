Another relevant detail is to preserve the status register if the
program may read it later. While most instructions alter CPU
ﬂags, our liveness analysis points out the sole statements that
may concur to a later read: whenever in between we introduce
gadgets that pollute the ﬂags2, we spill and later restore them.
3) Materialization: At the end of the crafting stage a chain
is almost readily executable. As its branching labels are still
symbolic, we may optionally rearrange basic blocks:
then
once we ﬁx the layout
the labels become concrete RSP-
relative displacements. We then embed the chain in the binary,
allocating space for it in a data section and replacing the
original function code with a pivoting sequence to the ROP
chain. The sequence extends the stack-switching array and
saves the native RSP value, then the chain upon termination
executes a symmetric unpivoting scheme (details in §§A).
C. Discussion
Our design makes limited assumptions on the input code:
it hinges on off-the-shelf binary analyses to identify intra-
procedural branch targets, and obliviously translates stack
accesses and dereferences to preserve execution correctness
when interacting with the surrounding software stack.
Our implementation could rewrite a large deal of real-world
programs (§VII-C1), even when we supplied it code already
protected by the control-ﬂow ﬂattening and/or (nested) VM
obfuscations of the Tigress framework [55]. We experimentally
observed (§VII-C1) that the analyses of Ghidra are remarkably
effective in recovering intra-procedural indirect branch targets,
Fig. 4: Call to a native function from ROP code.
which in several high-level languages derive from optimized
switch constructs. Whenever those may fail, one could couple
the rewriter with a dynamic tracer for recovering the intended
targets by running the original program using expected inputs.
Transfers to other functions via indirect calls or tail jumps are
instead straightforward, as the chain transfers control to the
prologue of the callee as it happens with direct calls.
A limitation of the design, shared with static rewriting and
instrumentation schemes [45], [56], is lastly the inability to
handle self-modifying and dynamically generated code.
As for register conﬂicts, the high number of x64 registers
give us wiggle room to perform register renaming within
blocks with modest spilling. An area larger than the 1-word
one we use may help with code with very high register
pressure cases (§VII-C) or 32-bit implementations; instruction
reordering and function-wide register renaming may also help.
The implementation incurs two main limitations that one
can address with moderate effort. The spilling slots and the
ss array area are not thread-private, but we may recur to
thread-local storage primitives. Rewritten binaries are com-
patible with address space layout randomization for libraries,
while the body of the program is currently loaded at ﬁxed
addresses. To ship position-independent executables we may
add relocation information to headers so to have the loader
patch gadget addresses in the chains, or use the online patching
for chains from [5] to have the program itself do the update.
In terms of compatibility with ROP defenses of modern op-
erating systems, our context is different to an exploitation one
where the program stack gets altered and the choice of gadgets
is limited. On Windows, for instance, our stack switching upon
API calls would already comply with the RSP range checks
of StackPivot [57]; our liberty to synthesize gadgets would be
decisive against CallerCheck, which checks if the instruction
preceding an API’s return address is a call [57]. We refer
to prior work [5] for details. A potential issue, which may
require the user to whitelist the program, could be instead
coarse-grained defenses that monitor branches [58] or micro-
architectural effects [59]. However, those are yet to become
mainstream as they face robustness and accuracy issues.
2This happens mainly when an intervening instruction involves RSP and
we emit gadgets to do pointer arithmetic for stack pointer reference roplets.
6
C after              sssizess + sizeother_rsprsprsprspinitially  after A after ABfunc-ret gadgetC after rsp after Cvar1ret addressCABROP chainnative stackrecover native rsp  from other_rsp  push addr of  func-ret gadget swap (rsp, other_rsp)& jump to native funcB initially Bcaller frame(ROP func.)Finally, our readers may question if the use of ROP in-
troduces obvious security risks. An attacker needs a write
primitive pointing to a chain in order to alter it. In our
protected programs, ROP-encoded parts use write operations
only for spilling slots, and those cannot go out of bounds. Non-
ROP parts never reference chains in write (or read) operations:
an attacker would thus have to search for an arbitrary memory
write primitive in such parts. Its presence, however, would be
an important source of concern even for the original program.
Our implementation also supports the generation of read-only
chains, which use a slightly longer spilling machinery.
V. STRENGTHENING ROP PROGRAMS
In the furrow of prior works (e.g., [7]–[9]) that highlighted
the hindrances from the ROP paradigm to reverse engineering
attempts, one could anticipate that the design of §IV may chal-
lenge manual deobfuscation and code understanding attempts.
The common thread of their observations is that the exoticism
of the representation—ROP deﬁnes a weird machine [60]—
disturbs humans when compared to native code. The rewriter
makes use of all motivating factors for ROP that we outlined
in §I, such as destructured control ﬂow and diversity and reuse
of gadgets (including gadget confusion that we describe next).
Quantifying the effectiveness of an obfuscation is however
a difﬁcult task, as it depends not only on the available tools,
but also on the knowledge of the human operating them [38].
A well-established practice in the deobfuscation literature is to
measure the resilience to automated deobfuscation techniques,
which in most attack scenarios are the fulcrum of reverse engi-
neering attempts and ease subsequent manual inspections [16].
ROP encoding alone is not sufﬁcient for obfuscation. We
ﬁnd control transfers between basic blocks to be its weak link.
instances, an
attacker aware of the design may follow the ROPMEMU
approach (§III-B) to spot in an execution trace what gadgets
add variable quantities to RSP (thus exposing basic blocks),
untangle ret instructions from the original control ﬂow of the
program, and assemble a dynamic CFG from multiple traces.
Protecting control transfers is equally critical in the face of
the most effective general-purpose semantics-aware techniques
like SE, DSE and TDS, which try to reason on the parts es-
sential for program functionality while sifting out the irrelevant
obfuscation constructs and instructions [7], [38], such as side
effects and dynamically dead portions from gadgets.
Even when diversifying the used gadget
One way to hinder the automated approaches of §III-B
would be to target weaknesses of each technique individually.
For instance, researchers proposed hard-to-solve predicates for
SE (e.g. MBA expressions [61], cryptographic functions [62]),
and code transformations that impact concolic variants like
DSE too [22]. But an experienced attacker can symbiotically
combine methods to defeat this approach, for instance using
TDS or similar techniques (e.g., program synthesis for MBA
predicates [61]) to feed DSE with tractable traces as in [7].
In this section instead we present three rewrite predicates,
naturally meshed with RSP update actions, that bring protec-
tion against generic, increasingly powerful automated attacks
that cover the principled classes A1-2-3 from §III-A. We then
introduce gadget confusion and share some general reﬂections.
A. Predicate P1: Anti-ROP-Disassembly
Our ﬁrst predicate uses an array of opaque values [63] to
hide branch targets (A1). The array contains seemingly random
values generated such that a periodic invariant holds, and backs
the extraction of a quantity a that we use to compute the
displacement in the chain for one of the n branches in the
code. Suppose we need to extract a for branch b∈{0..n− 1}:
starting with cell b, in every p-th cell of the array we store a
random number q such that q ≡ a mod m, with m > n and p
chosen at obfuscation time.
10
19
34
45
54
62
66
33
6
59
61
20
Above we encoded information for n=3 branches using p=4
repetitions and m=7. For the branch with ordinal 1 we wanted
to memorize a = 5: every cell colored in dark gray thus
contains a value v such that v mod 7 equals 5.
During obfuscation we use a period of size s > n, with a
fraction of the cells containing garbage. We also share a valid
cell among multiple branches, so to avoid encoding unique
offsets that may aid reversing. To this end we divide an RSP
branch offset δ in a ﬁxed part a encoded in the array and a
branch-speciﬁc part δ − a computed by the chain, then we
compose them upon branching.
This implies that for static disassembly an attacker should
recover the array representation and mimic the computations
made in every chain segment to extract a and compute the
branch-speciﬁc part. While this is possible for a semantically
rich static technique like SE, periodicity comes to the rescue
as it brings aliasing: every p-th cell is suitable for extracting
a. Our array dereferencing scheme takes the form of:
a = A[f (x) ∗ s + n] mod m
where f (x) depends on the program state and returns a value
between 0 and p − 1. Its implementation opaquely combines
the contents of up to 4 registers that hold input-derived
values. SE will thus explore alternative input conﬁgurations
that ultimately lead to the same rsp += δ update; reducing
their number by constraining the input would lead instead to
missing later portions of program state.
Whenever an attacker may attempt a points-to analysis [64]
over rsp += δ, we believe a different index expression based
on user-supplied or statically extracted facts on input value
ranges would sufﬁce to complicate such analysis signiﬁcantly.
B. Predicate P2: Preventing Brute-Force Search
Our second predicate introduces artiﬁcial data dependen-
cies on the control ﬂow, hindering dynamic approaches for
brute-force path exploration (A2) that ﬂip branches from an
execution trace. While these techniques do not help in secret
ﬁnding (G1) as they neglect data constraints (§III-A), they may
be effective when the focus is code coverage (G2).
P1 is not sufﬁcient against A2: an attacker can record a trace
that takes a conditional branch shielded by P1, analyze it to
7
locate the ﬂags set by the instruction that steered the program
along the branch, ﬂip them, and reveal the other path [10].
Without loss of generality, let us assume that a cmp a, b
instruction determines whether the original program should
jump to location L when a == b and fall through otherwise.
We introduce a data dependency that breaks the control ﬂow
when brute-force attempts leave its operands untouched. As
we translate the branch in ROP, in the block starting at L we
manipulate RSP with, e.g., rsp += x ∗ (a − b), so that when
brute-forcing it without changing the operands, (a − b) != 0
and RSP ﬂows into unintended code by some offset multiple
of x. Similarly, on the fall-through path we manipulate RSP
with, e.g., rsp += x ∗ (1 − notZero(a − b)), where notZero is
a ﬂag-independent computation3 so the attacker cannot ﬂip it.
Different formulations of opaque updates are possible.
Whenever an attacker may attempt to learn and override up-
dates locally, we ﬁgured a future, more covert P2 variant that
encodes offsets for branches using opaque expressions based
on value invariants (obtainable via value set analysis [65]) for
some variable that is deﬁned in an unrelated CFG block.
C. Predicate P3: State Space Widening
Our third predicate brings a path-oriented protection that
artiﬁcially extends the program space to explore and is coupled
with data (and optionally control) ﬂows of the program, so that
techniques like TDS (A3) cannot remove it without knowledge
of the obfuscation-time choices. P3 comes in two variants.
The ﬁrst variant
is an adaptation of the FOR predicate
from [14]. The idea is to introduce state forking points
using loops, indexed by input bytes, that opaquely recompute
available values that the program may use later. In its simplest
formulation, FOR replaces occurrences of an input value char
c with uses of a new char fc instantiated by for (i=0;
i<c; ++i) fc++. Such loop introduces 28 artiﬁcial states
to explore due to the uncertainty on the value of c.
The work explains that targeting 1-byte input portions brings
only a slight performance overhead, and choosing independent
variables for multiple FOR instances optimizes composition for
state explosion. It also argues how to make FOR sequences
resilient to pattern attacks, and presents a theorem for robust-
ness against taint analysis and backward slicing, considered for
forward and backward code simpliﬁcation attacks, respectively
(the TDS technique we use has provisions for both [7]).
While we refer to it for the formal analysis, for our goals
sufﬁce it to say that when the obfuscated variable is input-
dependent (for tainting) and is related to the output (for slic-
ing), such analyses cannot simplify away the transformation.
During the rewriting we use a data-ﬂow analysis to iden-
tify which live registers contain input-derived data (symbolic
registers) and may later concur to program outputs4. We then
introduce value-preserving opaque computations like in the
examples below (the right one is adapted from [14]):
// clear last byte
dead_reg &= 0xAB00;
for (i=0; i<(char)sym; ++i)
dead_reg++;
sym |= (char)dead_reg;
dead_reg = 0;
for (i=0; i<(char)sym; ++i)
if (i%2) dead_reg--;
else dead_reg+=3;
if (i%2) dead_reg-=2;
sym = (sym&0xF..F00)+dead_reg;
8
These patterns signiﬁcantly slow down SE and DSE en-
gines, but also challenge approaches that feed tractable sim-
pliﬁed traces to DSE. While one may think of detecting and
propagating constant values in the trace, the TDS paper [7]
explains that doing it indiscriminately may oversimplify the
program: in our scenario it may remove FOR but also pieces
of the logic of the original program elsewhere. To avoid over-
simpliﬁcation the TDS authors restrict constant propagation
across input-tainted conditional jumps, which is exactly the
case with dead_reg and sym in the examples above.
The authors suggest, as a general way to hamper semantics-
based deobfuscation approaches like TDS, to deeply entwine
the obfuscation code with the original input-to-output com-
putations. They also state that at the time obfuscation tools
had not explored this avenue, possibly for the difﬁculties in
preserving observable program behavior [7].
Our second P3 variant is new and moves in this direc-
tion. Instead of recomputing input-derived variables, we use
them to perform opaque updates to the array used by P1.
Updates include adding/subtracting quantities multiple of m,
swapping the contents of two related cells from different
periods, or combining the contents of two cells i and j
where a≡ A[i] mod m and b≡ A[j] mod m to update a cell l
where (a + b)≡ A[l] mod m. For DSE-alike path exploration
approaches the effect is tantamount to the FOR transformation
described above. For trace simpliﬁcation it introduces implicit
ﬂows, with fake control dependencies between program inputs
and branch decisions taken later in the code: TDS cannot
simplify them without explicit knowledge of the invariants.
D. Gadget Confusion
ROP encoding brings several advantages when implement-
ing P1-2-3. Firstly, it offers signiﬁcant leeway for diversifying
the gadget instances we use to instantiate them. We combine
this diversity with dynamically dead instructions: we can use
gadgets whose each instruction either concurs to implementing
a predicate or has no effect depending on the surrounding
chain portion. This helps in instantiating many variants of a
pattern, challenging syntactic attacks aware of the design.
However, a unique advantage of ROP, as we observed in §I,
is the level of indirection that it brings: this complicates pattern
attacks that look for speciﬁc instruction bytes, since code is
not in plain sight, and attackers need to extract the instruction
sequences as if executing the program. What they see are bytes