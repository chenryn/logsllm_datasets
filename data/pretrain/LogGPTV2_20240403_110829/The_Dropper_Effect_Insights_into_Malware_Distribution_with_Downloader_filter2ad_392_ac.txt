105
Table 2: Top benign downloaders dropping malware.
fact that download graphs may include a mix of benign and mali-
cious software and emphasizes the importance of focusing on the
inﬂuence graph rooted in each downloader in our analysis.
Benign Programs Dropping Malware. In addition to browsers,
we observe a number of benign programs that drop malicious exe-
cutables (see Table 2). These include three Windows process,
EXPLORER.EXE, CSRSS.EXE and SVCHOST.EXE. In the case of
CSRSS.EXE, the 10 most frequently downloaded executables are
adware programs (detected by several AV products); 8 out of 10
are from Mindspark Interactive Network. For EXPLORER.EXE, the
10 most frequently downloaded executables are adware programs
from Conduit, Mindspark, Funweb, and Somoto.
In the case of
SVCHOST.EXE most of top 10 payloads are generic trojan dro-
ppers. Executables downloaded from JAVA.EXE are speciﬁc tro-
jans (Zlob, Genome, Qbot, Zbot, Mufanom, Cycbot, Gbot and Fa-
keAV), and a hack tool (passview). DAP.EXE and IDMAN.EXE are
downloader managers, and the top 5 executables they drop are pro-
ducts signed by Mindspark. For JAVAW.EXE, Bitcoin mining exe-
cutables made the top of the list. Another Java related process,
MODELMANAGERSTANDALONE.EXE, is also used for dropping tro-
jans.
In many of these cases it is difﬁcult to pinpoint the exact
program that is responsible for delivering malware; for example,
SVCHOST.EXE is a process that can contain a variety of Windows
services, while JAVA.EXE is an interpreter that runs Java programs.
However, this illustrates the fact that malware programs, spanning
a broad functionality range, often try to remain undetected by inﬁl-
trating benign software ecosystems.
Signed Malicious Downloaders. Surprisingly, among the 67,609
malicious downloaders, 22.4% (15,115 downloaders) have a va-
lid digital signature. Moreover, the droppers may be uploaded to
VirusTotal after the expiration of their signing certiﬁcate; if we co-
unt the invalid signatures, 55.5% of malicious downloaders are sig-
ned. These signed malicious downloaders form 128,436 inﬂuence
graphs, accounting for 46.9% of all the malicious inﬂuence gra-
phs. The top-5 downloaders with valid signatures are from Softo-
nic International, Amonetize Ltd, InstallX, Mindspark Interactive
Network, SecureInstall. All of these downloaders are known to de-
liver third-party software. Among these, Amonetize is known to be
a pay-per-install provider5. These software publishers release 1.70,
1.55, 1.98, 0.35, and 1.79 new droppers per day, respectively. This
practice likely stems from a desire to evade detection, as benign
software is usually signed. However, this also illustrates that the
organizations responsible for almost half of the malware download
activity identify themselves voluntarily by signing their droppers.
5
http://www.amonetize.com/about-us/
4.3 Properties of Malicious Inﬂuence Graphs
We now turn our attention to the question: How do malicious in-
ﬂuence graphs differ from benign inﬂuence graphs? We compared
multiple features and feature combinations; for brevity, we report
only the strongest indicators of malicious activity.
Large diameter IGs are mostly malicious. The diameter of inﬂu-
ence graphs (the maximum length of the shortest path between two
nodes) ranges between 2–5. Figure 4(a) shows the distribution. A
graph with diameter 2 (a single downloader with multiple payloads)
is equally likely to be benign or malicious. However, when the dia-
meter is 3 and above a high percentage (84% in our case) of graphs
are malicious. More importantly, almost 12% of the malicious in-
ﬂuence graphs have diameter of 3 and larger. These ﬁndings are
consistent with prior observations of pricing arbitrage in the under-
ground economy [3], where PPI providers distribute their droppers
through competing PPI infrastructures.
IGs with slow growth rates are mostly malicious. Figure 4(b)
shows the distribution of the average inter-download time (AIT) of
the inﬂuence graphs. We deﬁne AIT to be the average amount of
time taken to grow by one node. Almost 88% of the inﬂuence gra-
phs that grow slowly (AIT > 1.5 days/node) are malicious. The ra-
tio of malicious graphs further increases with slower growth rates.
We also observe that over 65% of the malicious inﬂuence graphs
have AIT > 1.5 days/node. This suggests that successful malware
campaigns, which are able to evade detection for a long time, tend
to deliver their payloads slowly.
URL access patterns vary across subclasses of malicious/benign
downloaders. Figure 4(c) shows the distribution of the average
number of distinct downloaders accessing an Internet domain. We
compute this number by determining the set of source domains for
the nodes in an inﬂuence graph and by taking the average of the
number of downloaders accessing them, across all the hosts. Even
though the distribution does not clearly separates malicious and be-
nign behavior, we found some interesting patterns. The large nu-
mber of IGs with between 1,100–1,200 downloaders per domain,
towards the right side of the plot, is mostly caused by adware. In
fact, three adware programs, LUCKYLEAP.EXE, LINKSWIFT.EXE,
and BATBROWSER.EXE comprise 26% of the IGs in that distribu-
tion bucket. This suggests that the organizations behind these pro-
grams have resilient server-side infrastructures (and the domains
used to host the adware do not have to change very often) and
that they frequently re-pack their droppers (in order to evade de-
tection on the client side). Figure 4(d) zooms in on the left side
of the same distribution. Most of the benign IGs have up to 10
downloaders per domain. However, we also identiﬁed several ma-
licious IGs in this bucket; the top-3 are fake antivirus programs
(EASYVACCINESETUP.EXE, LITEVACCINESETUP.EXE, and BOAN-
DEFENDERSETUP.EXE), which access Korean domains and seem to
be part of the same campaign. Windows Update IGs have between
60–70 downloaders per domain in our data set.
Malware tend to download fewer ﬁles per domain. Figure 4(e)
shows the distribution of the average number ﬁles downloaded
from the domains accessed from an inﬂuence graph. The ﬁgure
also illustrates the diversity in malicious behavior. Most of the
malicious droppers that download large number of ﬁles per do-
main correspond to adware. For example, 40% of the IGs in
the 4000–5000 ﬁles-per-domain histogram bucket (the tallest mali-
cious bar) correspond to three adware programs (LUCKYLEAP.EXE,
LINKSWIFT.EXE, and BATBROWSER.EXE). Apart from the adware,
most of the other malicious droppers (around 40% of all malware)
download 1–5 ﬁles per domain, as they have to move to new do-
mains after the old ones are blacklisted. Another interesting obser-
1123Figure 4: (a) Distribution of inﬂuence graph diameter (b) Growth rate of inﬂuence graphs (expressed as the average inter-download
time) (c) Distribution of the average number distinct portals accessing the domains of an inﬂuence graph (d) Zoomed in version of
the previous plot (e) Distribution of the number of executables downloaded from the source domains of an inﬂuence graph.
vation is that benign downloaders also exhibit diverse behaviors.
For example, the inﬂuence graphs of Apple Software Update are
also in the 4000–5000 histogram bucket, while DivXInstaller’s in-
ﬂuence graphs download around 10000 ﬁles per domain.
5. MALWARE CLASSIFICATION
While in the previous section we identify several features that
indicate malicious download activity, none of these features, ta-
ken individually, are sufﬁcient for detecting most of the malware in
our data set. We therefore build a malware detection system that
employs supervised machine learning techniques for automatically
selecting the best combination of features to separate the malicious
and benign inﬂuence graphs. Speciﬁcally, we train a random-forest
classiﬁer using inﬂuence graphs labeled as described in Section 3.4;
unlike in Section 4, we employ malicious graphs that correspond to
both known and unknown droppers, as this data set is more repre-
sentative of the state of malicious downloaders in the wild. We test
our classiﬁer using both internal (cross-fold validation and early
detection) and external (VirusTotal results for some of the unlabe-
led samples predicted to be malicious) performance metrics.
5.1 Handling Data Skew
The ground data consists of 274,126 malicious and 14,918,097
benign inﬂuence graphs. Training a classiﬁer on such a skewed data
set may bias the model toward the abundant class (the benign IGs)
and may focus on tuning the unimportant features, i.e., the ones
that do not contribute to the classiﬁcation but rather model noise in
the dataset. We address this problem through stratiﬁed sampling:
we sample the abundant and rare classes separately to select appro-
ximately equal numbers of IGs for the training set. In practice, we
do not need to exclude any examples from the rare class, and some
examples from the abundant class can be identiﬁed easily and ﬁlte-
red to reduce the variability within that class. We therefore ﬁlter out
all the Web browsers (identiﬁed as described in Section 4.2) from
the benign set of IGs, as the set of ﬁles they download is not predic-
table and includes both benign and malicious executables. We then
keep all the malicious graphs and we downsample the remaining
set of benign graphs (sampling uniformly at random). We manu-
ally examined the properties of several random samples created in
this manner and observed that they closely match the properties of
the abundant class. Our balanced training set consists of 43,668
malicious and 44,546 benign inﬂuence graphs.
5.2 Feature Engineering
Table 3 provides the features that we compute based on the pro-
perties of the inﬂuence graphs. We organize the features into ﬁve
semantic categories:
internal dynamics, life cycle, properties of
downloaders, properties of domains, and globally aggregated be-
havior. For each feature, we also provide the high level intuition
for why we expect it would separate malicious and benign graphs.
Depending on how we compute the features, we distinguish two
feature types. Local features (LF) use information contained in the
inﬂuence graph. Global features (GF) are also computed for each
inﬂuence graph; however, they use properties aggregated across all
the hosts. An example of a GF is the Average Distinct File Afﬁnity,
illustrated in Figure 4(e), which reﬂects the tendency of an inﬂuence
graph to download ﬁles from domains that are known to serve a
large number of distinct ﬁles.
We quantify the worth of each feature in terms from distingu-
ishing benign and malicious inﬂuence graphs using the gain ratio6
with 10-fold cross validation. We select this metric because it is
known to be more robust than alternative metrics, such as the infor-
mation gain or the Gini index, when the features differ greatly with
respect to their range [21]. Table 4 shows a summary of the top-10
features in descending order of their gain ratio. The most useful fe-
atures are the average ﬁle prevalence and the features illustrated in
Figures 4(c)–(e). We emphasize that, because the features are com-
puted per inﬂuence graph, the power of these global features helps
classify all the downloaders in the graph. For example, a dropper
that normally evades detection because it is present on many hosts,
but that always downloads unique ﬁles, will likely be classiﬁed as
malicious because of the low average prevalence of the ﬁles in its
inﬂuence graph.
5.3 Choosing the Classiﬁer
Our data set presents several challenges for supervised machine
learning. Some classiﬁcation algorithms work best on data sets
6
http://www.csee.wvu.edu/~timm/cs591o/old/Lecture6.html
BenignMalicious% of Inﬂuence Graphs0.011.00100.00Diameter2345% of Inﬂuence graph Histogram bucket size = 16000 minutesMaliciousBenign0.011.00100.00Rate of Inﬂuence Graph growth (minutes/nodes)01234×105% of Inﬂuence GraphsBenignMaliciousMostly AdwareHistogram Bucket width = 10002040Average #distinct portals accessing an URL050010001500MaliciousBenign% of Inﬂuence GraphsWindows UpdateHistogram Bucket width = 10Fake AVs and more02040Average #distinct portals accessing an URL - Zoomed In050100150200250% of Inﬂuence GraphsMaliciousBenignHistogram Bucket width = 500DivXInstaller.exeApple software updateMostly AdwareGabpath Adware3+ Adware02040Average #Files per URL for Inﬂeunce Graphs05000100001124Categories
Name
f1. Diameter
Type
LF
Internal
Dynamics
(FI)
Domain
Properties
(FU)
Downloader
(FD)
Score
Properties
Life
Cycle
(FL)
Gloablly
Aggregated
Behavior
(FA)
f2. Clustering Coefﬁ-
cient
f3. Density
f4. Total Download
f5. Number of Uni-
que Domains
f6. Domain Name Si-
milarity
f7. Alexa top-1M
f8. Average Score
f9. Standard Devia-
tion of the Score
f10. Inﬂuence Graph
Life Span
f11. Growth Rate
Average File
f12. Children Spread
f13.
Intra-children
Time Spread
f14.
Prevalence
f15. Average Distinct
File Afﬁnity
f16. Average Distinct
Dropper Afﬁnity
LF
LF
LF
LF
LF
LF
LF
LF
LF
LF
LF
LF
GF
GF
GF
Explanation
Diameter capture a chain of download relations (e.g., A → B, B → C, and so on). High diameter
could imply malicious behavior such as droppers or Pay-per-install ecosystem where there is an afﬁliate.
Clustering coefﬁcient is a measure of the degree to which nodes in a graph tend to cluster together, i.e.,
create triangles (e.g., (A → B, A → C, B → C ) or (A → B, B → C, C → A)). Intuitively, we would
expect the benign software to show low clustering as compared to malware.
A graph with high density means that the binaries are downloading each other actively, and there are
binaries that are downloaded by multiple downloaders.
Total number of downloads made by the inﬂuence graph.
Some malware droppers may access more domains, e.g. if they employ domain generation algorithms to
bypass blacklists.
We compute the similarity between all pairs of domains accessed from the graph:
similarity = 1 −
EditDistance(D1, D2)
min(length(D1), length(D2))
Percentage of domains in the inﬂuence graph that appear in Alexa top 1 Million list
Average score (based on signatures—see Section 3.4) of all the downloaders in an inﬂuence graph. In-
tuitively, even if the root has high score (signed malware) it might download low score downloaders,
indicating that the root might be malicious.
A malicious inﬂuence graph can achieve high average score by downloading known high score downloa-
ders. Standard deviation of downloader score in the IG might be relatively robust in that regard.
The life span of an inﬂuence graph is deﬁned as the time interval between the newest and oldest node. The
life span of malicious IGs tends to be shorter, as A/V programs eventually start detecting the droppers.
Average inter-download time for the nodes in an inﬂuence graph (= IGlif espan
#N odes ). Malicious IG trying
to remain stealthy tend to grow slowly, as shown in Figure 4(b).
Average time difference between the root and the children of an inﬂuence graph.
Average difference in download timestamp among the children of the root. Intuitively, we would expect
this value to be smaller for malware, as they tend to be more aggressive as downloaders.
Average FP (see Section 3.4) of the executables that appear in an inﬂuence graph. Benign binaries are
expected to show high prevalence.
Intuitively, this depicts whether an inﬂuence graph tends to prefer/avoid domains that download less/more
distinct binaries. This feature is illustrated in Figure 4(e).
Intuitively, this depicts the bias of a dropper toward a speciﬁc set of domains in order download new
binaries. This feature is illustrated in Figures 4(c)–(d).
Table 3: Feature categories and the high-level intuition behind some of the important features
Features
f14. Avg. File Prevalence
f15. Avg. Distinct File Afﬁnity
f16. Avg. Distinct Dropper Afﬁnity
f10. IG Life Span
f7. Alexa Top-1M
f11. Growth Rate
f13. Children Spread
f1. Diameter
f12. Intra-children Time Spread
Gain Ratio
.16 ± 0