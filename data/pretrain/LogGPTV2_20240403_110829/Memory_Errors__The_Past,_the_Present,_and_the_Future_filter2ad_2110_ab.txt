through direct buﬀer overﬂows. Unfortunately, indirect writes may allow one to
corrupt a function return address while guaranteeing the integrity of the canary.
StackShield [96], released later in 1999, tried to address this issue by focusing
on the return address itself, by copying it to a “secure” location. Upon function
termination, the copy is checked against the actual return address. A mismatch
would result in program termination.
StackShield clearly showed that in-band signaling should be avoided. Unfor-
tunately, as we will see in the next sections, mixing up user data and program
control information is not conﬁned to the stack: heap overﬂows (e.g., dynamic
memory allocator metadata corruption) and format bug vulnerabilities intermix
(in-band) user and program control data in very similar ways.
Both StackGuard and StackShield, and their Windows counterparts, have been
subject to a slew of evasions, showing how such defenses are of limited eﬀect
against skilled attackers [21,81]. On Windows, David Litchﬁeld introduced a novel
approach to bypass canary-based protections by corrupting speciﬁc exception
handling callback pointers, i.e., structured exception handing (SEH), used during
program cleanup, when a return address corruption is detected [61].
Matt Miller subsequently proposed a protection against SEH exploitation [71]
that was adopted by Microsoft (Windows Server 2008 and Windows Vista SP1). It
organizes exception handlers in a linked list with a special and well-known termi-
nator that is checked for validity when exceptions are raised. As SEH corruptions
generally make the terminator unreachable, they are often easy to detect. Un-
like alternative solutions introduced by Microsoft [17], Miller’s countermeasure
is backward compatible with legacy applications. Besides, if used in conjunction
with ASLR, it hampers the attackers’ ability to successfully exploit SEH.
Despite their initial weaknesses, canary-based protection spun oﬀ more coun-
termeasures. ProPolice, known also as Stack Smashing Protection (SSP), built on
the initial concept of StackGuard but addressed its shortcomings [40]; stack vari-
ables are rearranged such that pointers corruptions due to buﬀer overﬂows are
no longer possible. SSP was successfully implemented as a low-overhead patch
for the GNU C compiler and was included in mainstream from version 4.1.
2.3 Protecting the Heap
While defense mechanisms against stack-based buﬀer overﬂow exploitations were
deployed, heap-based memory errors were not taken into consideration yet.
The ﬁrst heap-based buﬀer overﬂow can be traced to January 1998 [36],
and the ﬁrst paper published by the underground research community on heap-
based vulnerabilities appeared a year later [27]. While more advanced heap-based
exploitation techniques were yet to be disclosed, it nonetheless pointed out that
memory errors were not conﬁned to the stack.
The ﬁrst description of more advanced heap-based memory error exploits was
reported by Solar Designer in July 2000 [35]. The exploit shows that in-band
control information (heap management metadata) is still the issue, a bad prac-
tice, and should always be avoided, unless robust integrity checking mechanisms
are in place. Detailed public disclosures of heap-based exploitations appeared
in [7,65]. Such papers dug into the intricacies of the System V and GNU C li-
brary implementations, providing the readers with all the information required
to write reliable heap-based memory error exploits.
Windows OSes were not immune from heap exploitation either. BlackHat 2002
hosted a presentation by Halvar Flake on the subject [45], while more advanced
Unix-based heap exploitation techniques where published in August 2003 [55],
describing how to obtain a write-anything-anywhere primitive that, along with
information leaks, allow for successful exploits even when ASLR is in use.
More about Windows-based heap exploitations followed in 2004 [62]. The in-
troduction of Windows XP SP2, later that year, came with a non-executable heap.
In addition, SP2 introduced heap cookies and safe heap management metadata
unlink operations. Not long had to be waited for before seeing the ﬁrst working
exploits against Microsoft latest updates [26,6,67]. With the release of Windows
Vista in January 2007, Microsoft further hardened the heap against exploita-
tion [64]. However, as with the Unix counterpart, there were situations in which
application-speciﬁc attacks against the heap could still be executed [51,107].
In 2009 and 2010 a report appeared where proof of concept implementations
of almost every scenario described in [78] were shown in detail [12,13].
2.4 Avoiding Format String Vulnerabilities
Similarly to the second generation of heap attacks, but unlike classic buﬀer over-
ﬂows, format string vulnerabilities (also known as format bugs) are easily ex-
ploited as a write-anything-anywhere primitive, potentially corrupting the whole
address space of a victim process. Besides, format bugs also allow to perform
arbitrary reads of the whole process address space. Disclosing conﬁdential data
(e.g., cryptographic material and secrets [29,98]), executing arbitrary code, and
exploring the whole address space of a victim process are all viable possibilities.
Format string vulnerabilities were ﬁrst discovered in 1999 while auditing
ProFTPD [101], but it was in the next couple of years that they gained popularity.
A format string vulnerability against WU-FTPD was disclosed on Bugtraq in
June 2000 [20], while Tim Newsham was the ﬁrst to dissect the intricacies of the
attack, describing the fundamental concepts along with various implications of
having such a vulnerability in your code.
One of the most extensive articles on format string vulnerabilities was pub-
lished by Scut of the TESO Team [87]. Along with detailing conventional format
string exploits, he also presented novel hacks to exploit this vulnerability.
Protection against format string attacks was proposed by FormatGuard in [28].
It uses static analysis to compare the number of arguments supplied to printf-
like functions with those actually speciﬁed by the function’s format string. Any
mismatch would then be considered as an attack and the process terminated.
Unfortunately, the eﬀectiveness of FormatGuard is bound to the limits of static
analysis, which leaves exploitable loopholes.
Luckily, format string vulnerabilities are generally quite easy to spot and
the ﬁx is often trivial. Moreover, since 2010, the Windows CRT disables %n-
like directives by default. Similarly, the GNU C library FORTIFY_SOURCE patches
provide protection mechanisms, which make format string exploitations hard.
Even so, and although the low hanging fruit had been harvested long ago, the
challenge of breaking protection schemes remains exciting [79].
2.5 Address Space Layout Randomization
Memory error exploitations typically require an intimate knowledge of the ad-
dress space layout of a process to succeed. Therefore, any attempt to randomize
that layout would increase the resiliency against such attacks.
The PaX Team proposed the ﬁrst form of address space layout randomization
(ASLR) in 2001 [99]. ASLR can be summarized succinctly as the introduction of
randomness in the address space layout of userspace processes. Such randomness
would make a class of exploits fail with a quantiﬁable probability.
PaX-designed ASLR underwent many improvements over time. The ﬁrst
ASLR implementation provided support for mmap base randomization (July 2001).
When randomized mmap base is enabled, dynamically-linked code is mapped
starting at a diﬀerent, randomly selected base address each time a program
starts, making return-into-libc attacks diﬃcult. Stack-based randomization fol-
lowed quickly in August 2001. Position-independent executable (PIE) random-
ization was proposed in the same month. A PIE binary is similar in spirit to
dynamic shared objects as it can be loaded at arbitrary addresses. This reduces
the risk of performing successful return-into-plt [73] or more generic return-
oriented programming attacks [83] (see next). The PaX Team proposed a kernel
stack randomization in October 2002 and, to ﬁnish their work, a ﬁnal patch was
released to randomize the heap of processes.
Over time, OSes deployed mostly coarse-grained—often kernel-enforced—
forms of ASLR, without enabling PIE binaries. Such randomization techniques
are generally able to randomize the base address of speciﬁc regions of a process
address space (e.g., stack, heap, mmap area). That is, only starting base addresses
are randomized, while relative oﬀsets (e.g., the location of any two objects in
the process address space) are ﬁxed. Thus, an attacker’s task is to retrieve the
absolute address of a generic object of, say, a dynamically-linked library of in-
terest: any other object (e.g., library functions used in return-into-libc attacks)
can be reached as an oﬀset from it.
One of the ﬁrst attacks against ASLR was presented by Nergal in 2001 [73].
Although the paper mainly focuses on bypassing non-executable data protec-
tions, the second part addresses PaX randomization. Nergal describes a novel
technique, dubbed return-into-plt, that enables a direct call to the dynamic
linker’s symbol resolution procedure, which is used to obtain the address of the
symbol of interest. Such an attack was however defeated when PaX released PIE.
In 2002, Tyler Durden showed that certain buﬀer overﬂow vulnerabilities
could be converted into format string bugs, which could then be used to leak
information about the address space of the vulnerable process [38]. Such infor-
mation leaks would become the de-facto standard for attacks on ASLR.
In 2004, Shacham et al. showed that ASLR implementations on 32-bit plat-
forms were of limited eﬀectiveness. Due to architectural constraints and kernel
design decisions, the available entropy is generally limited and leaves brute forc-
ing attacks a viable alternative to exploit ASLR-protected systems [90].
Finally, Fresi-Roglia et al. [47] detail a return-oriented programming [83]
attack able to bypass WˆX and ASLR. This attack chains code snippets of the
original executable and, by copying data from the global oﬀset table, is then
able to compute the base addresses of dynamically linked shared libraries. Such
addresses are later used to build classic return-into-libc attacks. The attack
proposed is estimated to be feasible on 95.6% binaries for Intel x86 architectures
(61.8% for x86-64 architectures). This high success rate is caused by the fact
that modern OSes do not adopt or lack PIE.
A diﬀerent class of attacks against ASLR protection, called heap spraying,
was described ﬁrst in October 2004 when SkyLined published a number of heap
spraying attacks against Internet Explorer [91,92,93]. By populating the heap with
a large number of objects containing attacker-provided code, he made it possible
to increase the likelihood of success in referencing (and executing) it.
Heap spraying is mostly used to exploit cross-platform browser vulnerabili-
ties. Since scripting languages like JavaScript and ActionScript are executed on
the client’s machine (typically in web browser clients), heap spraying has become
the main infection vector of end-user hosts.
Dion Blazakis went far beyond heap spraying by describing pointer inference
and JIT spraying techniques [14]. Wei et al. proposed dynamic code genera-
tion (DCG) spraying, a generalized and improved JIT spraying technique [108].
(Un)luckily DCG suﬀers from the fact that memory pages, which are about to
contain dynamically-generated code, have to be marked as being writable and
executable. Wei et al. found that all DCG implementations (i.e., Java, JavaScript,
Flash, .Net, Silverlight) are vulnerable against DCG spraying attacks. A new de-
fense mechanism to withstand such attacks was eventually proposed [108].
Finally, return-oriented programming, introduced in Section 2.1, may also be
used to bypass non-PIE ASLR-protected binaries (as shown by [47]). In fact, for
large binaries, the likelihood of ﬁnding enough useful code snippets to build a
practical attack is fairly high. Recent work on protecting against these attacks
involves instruction location randomization, in-place code randomization and
ﬁne-grained address space randomization [48,52,77].
3 Data Analysis
We have analyzed statistics as well as real-life evidence about vulnerability and
exploit reports to draw a ﬁnal answer about memory errors. To this end, we
tracked vulnerabilities and exploits over the past 15 years by examining the
Common Vulnerabilities and Exposures (CVE) and ExploitDB databases.
Figure 2a shows that memory error vulnerabilities have grown almost linearly
between 1998 and 2007 and that they started to attract attackers in 2003, where
we witness a linear growth in the number of memory error exploits as well.
Conversely, the downward trend in discovered vulnerabilities that started in 2007
is remarkable. Instead of a linear growth, it seems that the number of reported
vulnerabilities is now reversed. It is worth noting that such a drop mirrors a
similar trend in the total number of reported vulnerabilities. Figure 2b shows
the same results as percentages.
The spike in the number of vulnerabilities that started in 2003 may well
have been caused by the explosive growth of web vulnerabilities in that period
(as supported by [24]).
Figure 2a shows that web vulnerabilities ﬁrst appeared in 2003 and rapidly
outgrew the number of buﬀer overﬂow vulnerabilities. Probably due to their
simplicity, the number of working web exploits also exceeded the number of
buﬀer overﬂow exploits in 2005. It is therefore plausible that the extreme growth
in vulnerability reports that started in 2003 had a strong and remarkable web-
related component. This seems to be reasonable as well: shortly after the dot-
com bubble in 2001, when the Web 2.0 started to kick in, novel web developing
technique were often not adequately tested against exploitation techniques. This
was probably due to the high rate at which new features were constantly asked
by end customers: applications had to be deployed quickly to keep up with
competitors. This race left little time to carefully perform code security audits.
As mentioned earlier, Figure 2a also shows a downward trend in the total
number of vulnerabilities over the years 2006–2010, as reported independently
(a) Absolute
(b) As % of totals
Fig. 2: Vulnerabilities and Exploits.
in [68]. Memory errors were also aﬀected by that trend and started to diminish in
early 2007. Despite such negative ﬂuctuations, generic and memory error-speciﬁc
exploits kept growing linearly each month. The reasons for the downward trend
of reported vulnerabilities could be manifold; it could be that fewer bugs were
found in source code, fewer bugs were reported, or a combination thereof.
Assuming that the software industry is still growing and that, hence, the
number of lines of code (LoC) written each month still increases, it is hard to
back up the ﬁrst hypothesis. More LoC results in more bugs: software reliability
studies have shown that executable code may contain up to 75 bugs per 1000
LoC [9,76]. CVEs look at vulnerabilities and do not generally make a diﬀerence
between plain vulnerabilities and vulnerabilities that could be exploited. Mem-
ory error mitigation techniques are unlikely to have contributed to the drop in
reported vulnerabilities. Most defense mechanisms that we have discussed earlier
do not result in safer LoC (for which static analysis can instead help [103]); they
only prevent exploitation of vulnerable—usually poorly written—code.
However, if we look carefully at the data provided by analyzing CVE entries,
as depicted in Figure 2a, we see that the number of web vulnerabilities follows
the same trend as that of the total number of vulnerabilities. It seems that both
the exponential growth (2003–2007) and drop (2007–2010) in vulnerabilities is
related to fundamental changes in web development. It is reasonable to assume
that companies, and especially web developers, started to take web programming
more seriously in 2007. For instance, developers may well have become more