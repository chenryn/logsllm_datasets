the  penetrator) 
in 
proportion  to its scarcity, hence revenue cannot be scaled 
up  by  expanding  the  supply  of  goods  for  sale  as that 
would  defeat the  scarcity  on  which  pricing  is  based. In 
that sense the question of  “How  much penetration testing 
is  enough?”  cannot  be  answered  without 
first  picking 
either  the  client  or  the  tester point  of  view:  The  client 
wants enough testing for the result to be advertising-ready 
but  not  so much  testing  that  the  tester  fails  to  fail.  By 
contrast, the tester wants enough testing to fail  to fail  and 
thereby  preserve  their  reputation  as  an  entity  whose 
failure  is worth  paying  a premium  for,  but if  the client  is 
lame not so much testing as for the effort  to get boring or 
failing  to fail  look too easy.  No wonder optimization  is a 
remote possibility. 
there  is  wisdom 
that  ancient  English 
aphorism  that  “It  is  the  poor  carpenter what  curses his 
tools,”  in  penetration  testing  the  best  carpenters make 
their own tools. These tools are part labor productivity  for 
the penetration tester - and advancing labor productivity  is 
ever the core supply-side defense of  profit  margins - and 
part  complexity  rigging.  These  bespoke  tools  are,  if 
anything, the intellectual  content of the penetration testing 
field  and  the  flux  of  these tools  into  the  marketplace 
measures 
commodotized  market 
development. Password crackers are a fine example - who 
would  write  one today  now  that  first  rate  crackers  are 
available for  so little  money that all you  are really  paying 
for  is a user interface? Network  service inventory  takers 
are just  as fine an example - who would  write  one of these 
stage  of 
While 
in 
the 
when the Internet is so full  of them that over  loo/o of total 
Internet traffic  is the sort of low  level scans these tools are 
built  to  do? In  some sense, the point  at which  an artist’s 
intuition  moves  beyond  mere  suspicion  and  s/he writes 
down  (codes) what  s/he knows  in  the  form  of  a tool  the 
state of the art is advanced -  not everywhere and at once, 
but  in  the  sense that  the  future  is  already  here,  just 
unevenly  distributed.  It  is the tools of  the artist class that 
define  the  state of  their  art,  even if  they  will  not  show 
them to you. 
inside 
further 
The future  is simple: The target of  penetrations will  be 
ever 
the  enterprise  as  the  corporate 
perimeter dissolves and inside versus outside has ever less 
practical difference,  i.e., for there to be a penetration there 
has  to  be  something  to  penetrate  and  the  corporate 
network  perimeter  is  as  interesting  to  penetrate  as  a 
month-old  whale  carcass. Penetration testing  in  the main 
will  look  more and more like  quality  assurance in  that  it 
will  look  more  and more  like  falsifying  hypotheses that 
such  and  such  a  flaw 
is  present  (by  attempting  to 
demonstrate that it is present and failing  to do so) and less 
and less like  a voyage  of  discovery  about what  hitherto 
unknown  flaws  might  be  present, excepting  for  the  top 
end artists. There is always room at the top, but probably 
not much place else. The artists who can reliably  estimate 
the level of effort  to accomplish a penetration are the ones 
who  will  add value  because they  can chart the steepness 
of  the  curve  of  tradeoff  costs as one moves ones worry 
from  idle  sociopaths to  committed  opponents to  as-yet- 
trusted turncoats. The ones who  are just  taking  inventory 
can be replaced with  a button. The ones who can quantify 
in  a way  that  makes risk  management advance are the 
ones who will  survive. 
Part II:  A Portrait  of the Artist  as a 
Penetration  Tester 
The  Five  W’s  of  Application 
4 
Penetration  Testing 
is 
the 
testing 
As  Application  penetration 
least 
commoditized  of the major penetration test specialities, its 
future  is the least distributed,  and a closer examination of 
the current incarnation of its future is therefore warranted. 
Papers  extrapolating  specific  exploits  against  specific 
applications  abound on the web  and elsewhere. There is 
little  wisdom  to  be gained by  rehashing such ephemeral 
morsels here. Instead, we will  focus on the less immutable 
aspects of  application penetration testing, and will  expand 
on  the  justification 
for  pentestirtg,  as  it  is  called,  its 
methodology,  its  major  players,  its  current  and  future 
placement  in  the  development  lifecycle  and  its  area of 
prioritization  and  focus.  In  short,  we  will  examine  the 
Proceedings of the 18th Annual Computer Security Applications Conference (ACSAC(cid:146)02) 
1063-9527/02 $17.00 ' 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:30:14 UTC from IEEE Xplore.  Restrictions apply. 
WhY,  what,  who,  when  and  where  of  application 
penetration  testing.  Without  attempting  to  dissect  and 
categorize the many  species of  application  here, we will 
focus  largely  on  web  applications,  though  most  of  the 
principles  discussed here apply,  at least in  part, to  other 
types of applications as well. 
41 . 
WhY 
So  we  stop  to  ask  ourselves,  “Why  should  I  pay 
someone to  break into  my  own  applications?”  Especially 
if,  as described in the first  part of  this  article,  penetration 
testing  is at best a science of  insecurity,  pitting  the skill 
and hopes of  a security professional  against the skill  and 
hopes of  the  developer.  Application  penetration  testing 
continues  to  yield  a  tremendous  Return  On  Security 
Investment  (ROSI)  precisely  because  the 
future  of 
application  security  is  still  so unevenly  distributed.  The 
focus of  security consciousness has only  recently  shifted 
to applications, owing  to the assumption that applications 
are the slaves of  infrastructure  and that it  is the networks 
and hosts that  define  the boundaries of  the  corporation’s 
digital  assets. Indeed, we continue to refer to the corporate 
homeland as the  “corporate  network”,  not the  “corporate 
application  mass” (and not just  because it  is phonetically 
more  pleasant).  In  any  case,  it  is  the  application  that 
reaches  out  across  the  Internet  into  every  connected 
human’s living  room. So while  we may think  of firewalls, 
network  ACLs  and host defenses as our  corporate walls 
and  ceilings,  the  applications  represent  our  doors  and 
windows  and are therefore  becoming  both  the  target  of 
attackers and the focus of security professionals. 
the 
information 
is  to  buckle  up  before  putting 
A  quick  glance  at  the  lamentably  few  statistics  on 
digital  (in)security  provide  a  sobering  reminder  of  just 
how  critical 
the 
super  highway. 
corporation  onto 
According  to the CSI/FBI  survey on computer crime and 
(http:i’/www.gocsi.com/press/20020407.htm1) 
security 
which,  while  not  without  limitations 
is  more  likely  to 
understate the extent of  criminality  than otherwise, ninety 
percent of  respondents (primarily  large corporations  and 
government  agencies)  detected  computer 
security 
breaches within  the  last  twelve  months.  Eighty  percent 
acknowledge  financial  losses due to  computer  breaches. 
Thirty-eight  percent  suffered  unauthorized  access  or 
misuse on their  Web  sites within  the last twelve  months, 
with  twenty-one  percent admitting  that they  really  didn’t 
know  whether there had been any unauthorized access or 
misuse, because they either weren’t monitoring  their  sites 
for  abuse or weren’t sufficiently  confident  that they were 
monitoring  those sites successfully. 
While  these  survey  based numbers  are  chilling, 
they  are becoming  mundane through  repetition  and  are 
fairly 
frequently  shrugged  off  as  qualitative  and/or 
personally  irrelevant  since they  are based on a voluntary 
it 
visit 
their 
should 
project, 
survey. The more quantifiable  statistics from  the honeynet 
project  provide  more prescient commentary  on the world 
the 
of  digital  abuse.  Those  who  are  unfamiliar  with 
site 
at 
honeynet 
htty:jl~~ww.honeynet.or~  - 
it  is  as  interesting  as  it  is 
enlightening.  As  a quick  synopsis, the  organizers  of  the 
honeynet  project 
implemented  a  clever  scheme  for 
tracking  and monitoring  black  hat  activity  passively . As 
their  site ind icates, a honeynet is a network  “similar  to  a 
fishbowl,  where  you  can  see  everything  that  happens 
inside it,”  a highly  monitored network  that is connected to 
the Internet  but  is not  advertised actively  in  any way;  in 
fact,  it  consists of  nothing  but  a  few  IP  addresses. All 
activity 
in  the  network  therefore  represents either  the 
collision  of  curiosity  and  coincidence  or  an  attempted 
attack. The  captured activity  illustrates  the tools,  tactics, 
and motives  of  the  blackhat  community.  Some statistics 
taken directly  from the honeynet project’s web site: 
the 
days 
three 
Between  April  and  December  2000,  seven 
installations  of  Red  Hat  6.2  servers 
default 
were 
attacked  within 
of 
connecting  to the  Internet.  Based  on  this,  we 
estimate 
life  expectancy  of  a  default 
installation  of  Red  Hat  6.2  server  to  be  less 
then  72  hours.  The  last time  we  attempted  to 
confirm 
this,  the  system  was  compromised 
in  less  than  eight  hours.  The  fastest 
time 
ever  for  a  system  to  be  compromised  was 
15  minutes.  This  means 
the  system  was 
scanned,  probed,  and  exploited  within  15 
to 
minutes 
Internet. 
Coincidentally, 
the  first  honeypot 
we  ever  setup,  in March  of  1999. 
of  connecting 
this  was 
the 
l 
found 
A  default  Windows98  desktop  was  installed 
on  October  31,  2000,  with  sharing  enabled, 
the  same  configuration 
in  many 
homes  and  organizations. 
The  honeypot 
in  less  than  twenty  four 
was  compromised 
hours. 
it  was 
successfully 
four 
times.  This  makes  a  total  of  five  successful 
attacks  in less than  four  days. 
three  days 
another 
In  the  following 
compromised 
The  lack  of  production  applications  in  the  honeynet 
precludes revelations  about the  shift  of  attack activity  to 
the application  space, but the statistics clearly  underscore 
the  existence  and  tenacity  of  the  black  hat.  Unrelated 
empirical  evidence  clearly 
in  attack 
methodology  from  passively  exploiting  exposed network 
functionality,  i.e. mounting  an exposed share, to  actively 
abusing  networking  applications,  such as writing  buffer 
overflows  to  subvert web  servers or  application  servers. 
Also,  it  is  important  to  note that  the  honeynet  statistics 
underestimate  the  real  danger  to  corporate  applications 
indicates  a  shift 
Proceedings of the 18th Annual Computer Security Applications Conference (ACSAC(cid:146)02) 
1063-9527/02 $17.00 ' 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:30:14 UTC from IEEE Xplore.  Restrictions apply. 
that 
since they capture only  opportunistic  activity,  not targeted 
activity. 
find  any  errors 
Many  developers 
remain  nonplussed  by  attack 
statistics,  arguing 
their  corporate  development 
process is  highly  optimized  or  that  their  applications  do 
not  expose  critical 
functionality  or  that  the  corporate 
firewalls  and  Intrusion  Detection  System  (IDS)  will 
protect the applications  from  any real  danger or  that the 
Quality  Assurance  process  will 
in 
implementation. Penetration testing is the key to resolving 
this debate and is critical  for  determining  how  and where 
to  integrate defensive tactics  in  application  development 
and  deployment.  First  of  all,  while 
the  application 
development process has been highly  optimized  over the 