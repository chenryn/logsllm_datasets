0.036
0
arrests
0.049
0.050
0.619
0.611
0.265
0.253
0.298
0.301
0.135
0
adult
0.046
0.044
0.500
0.501
0.220
0.218
0.377
0.312
0.044
0
arrests
0.047
0.053
0.612
0.615
0.247
0.260
0.033
0.096
0.149
0
adult
0.043
0.042
0.501
0.500
0.213
0.215
0.302
0.377
0.023
0
arrests
0.054
0.051
0.614
0.614
0.262
0.257
0.335
0.228
0.116
0
adult
0.044
0.043
0.501
0.501
0.218
0.215
0.315
0.302
0.012
0
arrests
0.053
0.052
0.620
0.617
0.262
0.259
0.223
0.129
0.109
0
A
B
A
B
A
B
A
B
A
B
MI
MI
Jaccard
Jaccard
corr
corr
disp
disp
QII
QII
TABLE II: Comparison of QII with associative measures. For 4 different classiﬁers, we compute metrics such as Mutual
Information (MI), Jaccard Index (JI), Pearson Correlation (corr), Group Disparity (disp) and Average QII between Gender and
the outcome of the learned classiﬁer. Each metric is computed in two situations: (A) when Gender is provided as an input to
the classiﬁer, and (B) when Gender is not provided as an input to the classiﬁer.
to his negative classiﬁcation were Marital Status, Relationship
and Education.
Mr. Y: The second example, to whom we refer as Mr. Y
(Figure 5), has even higher capital gains than Mr. X. Mr. Y is
a 27 year old, with only Preschool education, and is engaged
in ﬁshing. Examination of the transparency report reveals that
the most inﬂuential factor for negative classiﬁcation for Mr.
Y is his Occupation. Interestingly, his low level of education
is not considered very important by this classiﬁer.
Mr. Z: The third example, who we refer to as Mr. Z
(Figure 6) is from the arrests dataset. History of drug use
and smoking are both strong indicators of arrests. However,
Mr. X received positive classiﬁcation by this classiﬁer even
without any history of drug use or smoking. On examining
his classiﬁer, it appears that race, age and gender were most
inﬂuential in determining his outcome. In other words, the
classiﬁer that we train for this dataset (a decision forest) has
picked up on the correlations between race (Black), and age
(born in 1984) to infer that this individual is likely to engage in
criminal activity. Indeed, our interventional approach indicates
that this is not a mere correlation effect: race is actively being
used by this classiﬁer to determine outcomes. Of course, in
this instance, we have explicitly offered the race parameter
to our classiﬁer as a viable feature. However, our inﬂuence
measure is able to pick up on this fact, and alert us of
the problematic behavior of the underlying classiﬁer. More
generally, this example illustrates a concern with the black
box use of machine learning which can lead to unfavorable
outcomes for individuals.
D. Differential Privacy
Most QII measures considered in this paper have very low
sensitivity, and therefore can be made differentially private
with negligible loss in utility. However, recall that the sensi-
tivity of inﬂuence measure on group disparity ιY
disp depends on
(cid:14)
the size of the protected group in the dataset D as follows:
(cid:13)
ιY
disp = 2 max
1|D \ Y| ,
1
|D ∩ Y|
For sufﬁciently small minority groups, a large amount of
noise might be required to ensure differential privacy, leading
609609
to a loss in utility of the QII measure. To estimate the loss
in utility, we set a noise of 0.005 as the threshold of noise
at which the measure is no longer useful, and then compute
fraction of times noise crosses that threshold when Laplacian
noise is added at  = 1. The results of this experiment are as
follows:Y
Loss in Utility
2.97 × 10
−14
5.41 × 10
−14
6.14 × 10
−05
0.08
0.13
3.3 × 10
3.3 × 10
Race: White
Race: Black
Race: Asian-Pac-Islander
Race: Amer-Indian-Eskimo
Race: Other
Gender: Male
Gender: Female
We note that for most reasonably sized groups, the loss in
utility is negligible. However, the Asian-Pac-Islander, and the
Amer-Indian-Eskimo racial groups are underrepresented in this
dataset. For these groups, the QII on Group Disparity estimate
needs to be very noisy to protect privacy.
Count
27816
3124
1039
311
271
21790
10771
−47
−47
E. Performance
We report runtimes of our prototype for generating trans-
parency reports on the adult dataset. Recall from Section VI
that we approximate QII measures by computing sums over
samples of the dataset. According to the Hoeffding bound to
derive an (, δ) estimate of a QII measure, at  = 0.01, and
n = 37000 samples, δ = 2 exp(−n2) < 0.05 is an upper
bound on the probability of the output being off by . Table III
shows the runtimes of four different QII computations, for
37000 samples each. The runtimes of all algorithms except
for kernel SVM are fast enough to allow real-time feedback
for machine learning application developers. Evaluating QII
metrics for Kernel SVMs is much slower than the other metrics
because each call to the SVM classiﬁer is very computationally
intensive due to a large number of distance computations that
it entails. We expect that these runtimes can be optimized
signiﬁcantly. We present them as proof of tractability.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:16:24 UTC from IEEE Xplore.  Restrictions apply. 
0.16
0.14
0.12
0.10
0.08
0.06
0.04
0.02
s
e
m
o
c
t
u
O
n
o
I
I
Q
0.00
R elatio n s hip
O cc u p atio n
M arital Statu s
C a pital G ain
E d u c atio n
E d u c atio n-N u m
s
e
m
o
c
t
u
O
n
o
I
I
Q
0.18
0.16
0.14
0.12
0.10
0.08
0.06
0.04
0.02
0.00
S e x
W ork cla ss
C a pital L o ss
C o u ntry
R a c e
History
D ru g
History
S e x
S m o kin g
R a c e
Y e ar
Birth
R e gio n
C e n s u s
Feature
w e e k
A g e
p er
H o urs
Feature
(a) QII of inputs on Outcomes for the adult dataset
(b) QII of inputs on Outcomes for the arrests dataset
0.28
0.23
0.18
0.13
Original Discrimination
-0.02 -0.02 -0.02 -0.02 -0.02
-0.00 -0.00 -0.00 -0.00 -0.00
0.09
0.18
y
t
i
r
a
p
s
i
D
p
u
o
r
G
n
o
I
I
Q
0.13
0.08
0.03
0.08
0.05
Original Discrimination
-0.01
-0.01
-0.00
-0.00
y
t
i
r
a
p
s
i
D
p
u
o
r
G
n
o
I
I
Q
-0.07
-0.09
0.08
0.03
M arital Statu s