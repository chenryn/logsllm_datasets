### Table II: Comparison of QII with Associative Measures

For four different classifiers, we compute metrics such as Mutual Information (MI), Jaccard Index (JI), Pearson Correlation (corr), Group Disparity (disp), and Average QII between Gender and the outcome of the learned classifier. Each metric is computed in two situations: (A) when Gender is provided as an input to the classifier, and (B) when Gender is not provided as an input to the classifier.

| Metric | A | B | Metric | A | B | Metric | A | B | Metric | A | B | Metric | A | B |
|--------|---|---|---------|---|---|---------|---|---|---------|---|---|---------|---|---|
| MI     | 0.036 | 0.049 | Jaccard | 0.619 | 0.611 | corr    | 0.265 | 0.253 | disp    | 0.298 | 0.301 | QII     | 0.135 | 0.000 |
|        | 0.046 | 0.044 |         | 0.500 | 0.501 |         | 0.220 | 0.218 |         | 0.377 | 0.312 |         | 0.044 | 0.000 |
|        | 0.047 | 0.053 |         | 0.612 | 0.615 |         | 0.247 | 0.260 |         | 0.033 | 0.096 |         | 0.149 | 0.000 |
|        | 0.043 | 0.042 |         | 0.501 | 0.500 |         | 0.213 | 0.215 |         | 0.302 | 0.377 |         | 0.023 | 0.000 |
|        | 0.054 | 0.051 |         | 0.614 | 0.614 |         | 0.262 | 0.257 |         | 0.335 | 0.228 |         | 0.116 | 0.000 |
|        | 0.044 | 0.043 |         | 0.501 | 0.501 |         | 0.218 | 0.215 |         | 0.315 | 0.302 |         | 0.012 | 0.000 |
|        | 0.053 | 0.052 |         | 0.620 | 0.617 |         | 0.262 | 0.259 |         | 0.223 | 0.129 |         | 0.109 | 0.000 |

### Case Studies

#### Mr. X
The most influential factors contributing to his negative classification were Marital Status, Relationship, and Education.

#### Mr. Y
Mr. Y, a 27-year-old with only preschool education, is engaged in fishing. The transparency report reveals that the most influential factor for his negative classification is his Occupation. Interestingly, his low level of education is not considered very important by this classifier.

#### Mr. Z
Mr. Z is from the arrests dataset. History of drug use and smoking are strong indicators of arrests. However, Mr. Z received a positive classification even without any history of drug use or smoking. Examination of the classifier shows that race, age, and gender were the most influential in determining his outcome. Specifically, the classifier (a decision forest) has picked up on correlations between race (Black) and age (born in 1984) to infer criminal activity. Our interventional approach indicates that race is actively being used by the classifier to determine outcomes. This example highlights a concern with the black-box use of machine learning, which can lead to unfavorable outcomes for individuals.

### Differential Privacy

Most QII measures considered in this paper have very low sensitivity and can be made differentially private with negligible loss in utility. However, the sensitivity of the influence measure on group disparity (\(\iota_{\text{disp}}\)) depends on the size of the protected group in the dataset \(D\) as follows:

\[
\iota_{\text{disp}} = 2 \max \left( \frac{1}{|D \setminus Y|}, \frac{1}{|D \cap Y|} \right)
\]

For sufficiently small minority groups, a large amount of noise might be required to ensure differential privacy, leading to a loss in utility of the QII measure. To estimate the loss in utility, we set a noise threshold of 0.005 and compute the fraction of times the noise crosses that threshold when Laplacian noise is added at \(\epsilon = 1\). The results are as follows:

- **Race: White** - Loss in Utility: \(2.97 \times 10^{-14}\)
- **Race: Black** - Loss in Utility: \(5.41 \times 10^{-14}\)
- **Race: Asian-Pac-Islander** - Loss in Utility: \(6.14 \times 10^{-5}\)
- **Race: Amer-Indian-Eskimo** - Loss in Utility: \(0.08\)
- **Race: Other** - Loss in Utility: \(0.13\)
- **Gender: Male** - Loss in Utility: \(3.3 \times 10^{-47}\)
- **Gender: Female** - Loss in Utility: \(3.3 \times 10^{-47}\)

For most reasonably sized groups, the loss in utility is negligible. However, the Asian-Pac-Islander and Amer-Indian-Eskimo racial groups are underrepresented in this dataset, requiring very noisy QII estimates on Group Disparity to protect privacy.

### Performance

We report runtimes of our prototype for generating transparency reports on the adult dataset. Recall from Section VI that we approximate QII measures by computing sums over samples of the dataset. According to the Hoeffding bound, to derive an \((\epsilon, \delta)\) estimate of a QII measure, at \(\epsilon = 0.01\) and \(n = 37000\) samples, \(\delta = 2 \exp(-n \epsilon^2) < 0.05\) is an upper bound on the probability of the output being off by \(\epsilon\). Table III shows the runtimes of four different QII computations, each for 37000 samples. The runtimes of all algorithms except for kernel SVM are fast enough to allow real-time feedback for machine learning application developers. Evaluating QII metrics for Kernel SVMs is much slower due to the computational intensity of each call to the SVM classifier. We expect that these runtimes can be optimized significantly. We present them as proof of tractability.

### Figures

#### Figure 5: QII of Inputs on Outcomes for the Adult Dataset
- **Features**: Relationship, Occupation, Marital Status, Capital Gain, Education, Education-Num
- **QII Values**: 0.18, 0.16, 0.14, 0.12, 0.10, 0.08, 0.06, 0.04, 0.02, 0.00

#### Figure 6: QII of Inputs on Outcomes for the Arrests Dataset
- **Features**: Sex, Workclass, Capital Loss, Country, Race, Drug History, Smoking History, Race, Year of Birth, Region, Census, Age per Week, Hours
- **QII Values**: 0.28, 0.23, 0.18, 0.13, 0.09, 0.18, 0.13, 0.08, 0.05, 0.08, 0.03, 0.08, 0.05

#### Figure 7: Group Disparity and QII
- **Original Discrimination**: -0.02, -0.02, -0.02, -0.02, -0.02, -0.00, -0.00, -0.00, -0.00, -0.00, 0.09, 0.18, 0.13, 0.08, 0.03, 0.08, 0.05, -0.01, -0.01, -0.00, -0.00, -0.07, -0.09, 0.08, 0.03, Marital Status