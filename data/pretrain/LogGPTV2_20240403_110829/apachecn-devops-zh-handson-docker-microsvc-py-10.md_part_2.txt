我们通过部署来控制吊舱。您可以在[https://github . com/packt publishing/hand-On-Docker-for-micro-service-with-Python/blob/master/chapter 10/kubernetes/logs/deployment . YAML](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/kubernetes/logs/deployment.yaml)查看部署配置文件。让我们在下面的小节中看看它最有趣的部分。
# 对数体积
`log-volume`创建两个容器共享的空目录:
```
  volumes:
  - emptyDir: {}
    name: log-volume
```
这允许容器在文件中存储信息的同时进行通信。`syslog`容器将向其写入，而前轨将从中读取。
# 系统日志容器
`syslog`容器开始一个`rsyslogd`过程:
```
spec:
  containers:
  - name: syslog
    command:
      - rsyslogd
      - -n
      - -f
      - /etc/rsyslog.d/rsyslog.conf
    image: rsyslog:latest
    imagePullPolicy: Never
    ports:
      - containerPort: 5140
        protocol: UDP
    volumeMounts:
      - mountPath: /var/log
        name: log-volume
```
`rsyslogd -n -f /etc/rsyslog.d/rsyslog.conf`命令用我们前面描述的配置文件启动服务器。`-n`参数将进程保持在前台，从而保持容器运行。
指定了 UDP 端口`5140`，这是定义的接收日志的端口，`log-volume`安装到`/var/log`。稍后在文件中，将定义`log-volume`。
# 前轨容器
前轨容器从官方容器映像开始:
```
  - name: frontrail
    args:
    - --ui-highlight
    - /var/log/syslog
    - -n
    - "1000"
    image: mthenw/frontail:4.6.0
    imagePullPolicy: Always
    ports:
    - containerPort: 9001
      protocol: TCP
    resources: {}
    volumeMounts:
    - mountPath: /var/log
      name: log-volume
```
我们用`frontrail /var/log/syslog`命令启动它，指定端口`9001`(这是我们用来访问`frontrail`的端口)，并挂载`/var/log`，就像我们用`syslog`容器一样，来共享日志文件。
# 允许外部访问
正如我们对其他微服务所做的那样，我们将创建一个服务和一个入口。该服务将被其他微服务使用，因此它们可以发送日志。入口将用于访问网络界面，以便我们可以在日志到达时看到它们。
YAML 的文件分别在`service.yaml`和`ingress.yaml`文件中的 GitHub([https://GitHub . com/packt publishing/hand-Docker-for-micro-service-with-Python/tree/master/chapter 10/kubernetes/logs](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/tree/master/Chapter10/kubernetes/logs))上。
服务非常简单；唯一的特点是它有两个端口——一个 TCP 端口和一个 UDP 端口——并且每个端口都连接到不同的容器:
```
spec:
  ports:
  - name: fronttail
    port: 9001
    protocol: TCP
    targetPort: 9001
  - name: syslog
    port: 5140
    protocol: UDP
    targetPort: 5140
```
入口仅暴露前轨端口，这意味着我们可以通过浏览器访问它。请记住，需要将域名系统添加到您的`/etc/host`文件中，如本章开头所述:
```
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: syslog-ingress
  namespace: example
spec:
  rules:
  - host: syslog.example.local
    http:
      paths:
      - backend:
          serviceName: syslog
          servicePort: 9001
        path: /
```
在浏览器中进入`http://syslog.example.local`可以进入前轨界面:
![](img/f6ccd237-8812-48f4-90a1-b5c971772d3a.png)
您可以使用右上角的框过滤日志。
Remember that, most of the time, logs reflect the readiness and liveness probes, as shown in the preceding screenshot. The more health checks you have in your system, the more noise you'll get.
You can filter them out at the `syslog` level by configuring the `rsyslog.conf` file, but be careful not to leave out any relevant information.
现在，我们需要看看其他微服务如何配置并在这里发送它们的日志。
# 发送日志
我们需要在 uWSGI 中配置微服务，这样我们就可以将日志转发给日志服务。我们将以思想后端为例，即使可以在`Chapter10/microservices`目录下找到的前端和用户后端也启用了该配置。
打开`uwsgi.ini`配置文件([https://github . com/PacktPublishing/hand-On-Docker-for-micro-service-with-Python/blob/master/chapter 10/micro-service/thinks _ 后端/docker/app/uwsgi.ini](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/docker/app/uwsgi.ini) )。您将看到下面一行:
```
# Log to the logger container
logger = rsyslog:syslog:5140,thoughts_backend
```
这将把日志以`rsyslog`格式发送到`5140`港的`syslog`服务。我们还增加了*设施*，这是原木的来源。这会将字符串添加到来自该服务的所有日志中，这有助于排序和过滤。每个`uwsgi.ini`文件应该有自己的工具来帮助过滤。
In old systems that support the `syslog` protocol, the facility needs to fit predetermined values such as `KERN`, `LOCAL_7`, and more. But in most modern systems, this is an arbitrary string that can take any value.
uWSGI 的自动日志很有趣，但是我们也需要设置自己的日志来进行自定义跟踪。让我们看看如何。
# 生成应用日志
Flask 自动为应用配置记录器。我们需要通过以下方式添加一个日志，如`api_namespace.py`文件([https://github . com/packt publishing/hand-On-Docker-for-microservice-with-Python/blob/master/chapter 10/microservice/thinks _ back/thinks _ back end/API _ namespace . py # L102](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend/api_namespace.py#L102))所示:
```
from flask import current_app as app
...
if search_param:
    param = f'%{search_param}%'
    app.logger.info(f'Searching with params {param}')
    query = (query.filter(ThoughtModel.text.ilike(param)))
```
`app.logger`可以调用`.debug`、`.info`、`.warning`或`.error`生成日志。注意`app`可以通过导入`current_app`进行检索。
记录器遵循 Python 中的标准`logging`模块。它可以通过不同的方式进行配置。看一下`app.py`文件([https://github . com/packt publishing/动手-Docker-for-micro-service-with-Python/blob/master/chapter 10/micro-service/thinks _ back end/thinks _ back end/app . py](https://github.com/PacktPublishing/Hands-On-Docker-for-Microservices-with-Python/blob/master/Chapter10/microservices/thoughts_backend/ThoughtsBackend/thoughts_backend/app.py))查看我们将在以下小节中介绍的不同配置。
# 字典配置
第一级记录通过默认的`dictConfig`变量。这个变量由 Flask 自动定义，允许我们按照 Python 文档([https://docs.python.org/3.7/library/logging.config.html](https://docs.python.org/3.7/library/logging.config.html))中定义的方式配置日志。您可以在`app.py`文件中查看登录的定义:
```
from logging.config import dictConfig
dictConfig({
    'version': 1,
    'formatters': {
        'default': {
            'format': '[%(asctime)s] %(levelname)s in 
                        %(module)s: %(message)s',
        }
    },
    'handlers': {
        'wsgi': {
            'class': 'logging.StreamHandler',
            'stream': 'ext://flask.logging.wsgi_errors_stream',
            'formatter': 'default'
        }
    },
    'root': {
        'level': 'INFO',
        'handlers': ['wsgi']
    }
})
```
`dictConfig`词典有三个主要层次:
*   `formatters`:检查日志的格式。要定义格式，可以使用 Python 文档中提供的自动值。这将收集每个日志的信息。
*   `handlers`:这将检查日志的去向。您可以为记录器分配一个或多个。我们定义了一个名为`wsgi`的处理程序，并对其进行了配置，使其向上，朝向 uWSGI。
*   `root`:这是日志的最高级别，所以之前没有记录的东西都会引用这个级别。我们在这里配置`INFO`日志级别。
这将设置默认配置，这样我们就不会错过任何日志。然而，我们可以创建更复杂的日志处理程序。
# 记录请求标识
分析大量日志时的一个问题是关联它们。我们需要看看哪些是相互关联的。一种可能性是通过生成日志的 pod 过滤日志，日志存储在日志的开始处(例如，`10-1-0-27.frontend-service.example.svc.cluster.local`)。这类似于生成日志的主机。然而，这个过程很麻烦，在某些情况下，一个容器可以同时处理两个请求。我们需要每个请求的唯一标识符，该标识符被添加到单个请求的所有日志中。
为此，我们将使用`flask-request-id-header`包([https://pypi.org/project/flask-request-id-header/](https://pypi.org/project/flask-request-id-header/))。这增加了一个`X-Request-ID`头(如果不存在的话)，我们可以用它来记录每个单独的请求。
Why do we set up a header instead of storing a randomly generated value in memory for the request? This is a common pattern that allows us to inject the request ID into the backend. The request ID allows us to carry over the same request identifier through the life cycle of a request for different microservices. For example, we can generate it on the Frontend and pass it over to the Thoughts Backend so that we can trace several internal requests that have the same origin.
Although we won't be including this in our example for simplicity, as a microservices system grows, this becomes crucial for determining flows and origins. Generating a module so that we can automatically pass it over internal calls is a good investment.
下图显示了一个**前端**和两个服务之间的流程。请注意，`X-Request-ID`头在到达时没有为**前端**服务设置，它需要被转发到任何呼叫:
![](img/158370df-bab7-416c-ab69-63d258408159.png)
我们还需要将日志直接发送到`syslog`服务，这样我们就可以创建一个处理程序来完成这项工作。
当从脚本中执行代码时，与在 web 服务器中运行代码相比，我们不使用这个处理程序。当直接运行脚本时，我们希望我们的日志转到我们之前定义的默认记录器。在`create_app`中，我们将设置一个参数来区分它们。
The Python logging module has a lot of interesting features. Check out the Python documentation for more information ([https://docs.python.org/3/library/logging.html](https://docs.python.org/3/library/logging.html)).
Setting logs properly is trickier than it looks. Don't be discouraged and keep tweaking them until they work.