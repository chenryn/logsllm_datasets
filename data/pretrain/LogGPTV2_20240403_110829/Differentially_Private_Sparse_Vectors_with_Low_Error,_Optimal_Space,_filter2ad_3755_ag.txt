0.9 the error is at most
6 log(cid:16)
log(cid:16) 25
5
0.12√
19.24
(cid:17)
(cid:17) ≈ 75.33 .
𝜋
|𝑥𝑖 − ˜𝑥𝑖| < 3 +
The error of the observed 90th percentile is 15.78, which is shown
in Figure 3(c) using vertical lines. Again, this shows that the upper
bounds are pessimistic.
For comparison, the plots include the Laplace distribution with
scale parameters 1 and 4.5. Note that the Laplace distribution with
parameter 1 is optimal for the privacy budget. The standard devia-
tion of the distribution with scale 4.5 is 6.36 and as such the mean
absolute error is similar to the ALP mechanism.
The distribution is slightly off-center, and the mean error is 2.33.
This is expected due to hash collisions. The effect of hash collisions
is also apparent for the largest observed errors. The lowest observed
error was −114, while the highest was 274. There is a clear trade-off
between space usage and per-entry error. We reran the experiment
with hash collision probability 0.01 using the same value for 𝛼.
The error improved for all the metrics mentioned above. The mean
absolute error is 4.8, the standard deviation is 7.8, the mean error
is 0.18, the 90th percentile is 11.5, and the largest observed error is
147.
7 SUGGESTIONS TO PRACTITIONERS
The ALP mechanism introduced in this paper combines the best
of three worlds: It has low error similar to the Laplace mechanism,
produces compact representations using asymptotically optimal
space, and has an access time that scales only with 𝑂(log 𝑑).
In an application that wants to make use of differentially private
histograms/vectors, one first has to get an overview of the assumed
properties of the data before making a choice on which approach
to use. If 𝑑 is small or the data is assumed to be dense, the Laplace
mechanism will offer the best performance. If the data is sparse
and the dimension 𝑑 is large, the analyst must know which error
guarantee she wishes to achieve, and which access time is feasible
in the setting where the application is deployed. If a larger error is
acceptable for “small” entries or access time is crucial, just applying
the thresholding technique [5, 13] is the better choice. Otherwise, if
12
Session 4D: Differential Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1234(a) Upper bound on expected per-entry error
(b) Observed mean per-entry error
(c) Error distribution 𝛼 = 3 and collisions = 0.1.
Figure 3: Theoretical expected per-entry error and experiment results.
Note that the y-axes for the plots use different scales.
REFERENCES
[1] Sven Erick Alm. 2002. Simple random walk. Unpublished manuscript (2002).
[2] Victor Balcer and Salil P. Vadhan. 2019. Differential Privacy on Finite Computers.
http://www2.math.uu.se/~sea/kurser/stokprocmn1/slumpvandring_eng.pdf
[3] Mark Bun, Kobbi Nissim, and Uri Stemmer. 2019. Simultaneous Private Learning
[4] Larry Carter and Mark N. Wegman. 1979. Universal Classes of Hash Functions.
J. Priv. Confidentiality 9, 2 (2019).
of Multiple Concepts. J. Mach. Learn. Res. 20 (2019), 94:1–94:34.
J. Comput. Syst. Sci. 18, 2 (1979), 143–154.
[5] Graham Cormode, Cecilia M. Procopiuc, Divesh Srivastava, and Thanh T. L. Tran.
2012. Differentially private summaries for sparse data. In ICDT. ACM, 299–311.
[6] Martin Dietzfelbinger, Torben Hagerup, Jyrki Katajainen, and Martti Pentto-
nen. 1997. A Reliable Randomized Algorithm for the Closest-Pair Problem. J.
Algorithms 25, 1 (1997), 19–51.
[7] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam D. Smith. 2016. Cali-
brating Noise to Sensitivity in Private Data Analysis. J. Priv. Confidentiality 7, 3
(2016), 17–51.
[8] Cynthia Dwork and Aaron Roth. 2014. The Algorithmic Foundations of Differen-
[9] Noam D. Elkies. 2013.
tial Privacy. Found. Trends Theor. Comput. Sci. 9, 3-4 (2014), 211–407.
Upper limit on the central binomial coeffi-
cient. https://mathoverflow.net/questions/133732/upper-limit-on-the-central-
binomial-coefficient. [Online; accessed 15-September-2021].
[10] Ronald L. Graham, Donald E. Knuth, and Oren Patashnik. 1994. Concrete Mathe-
[11] Torben Hagerup. 1998. Sorting and Searching on the Word RAM. In STACS
[12] Moritz Hardt and Kunal Talwar. 2010. On the geometry of differential privacy.
matics: A Foundation for Computer Science, 2nd Ed. Addison-Wesley.
(Lecture Notes in Computer Science, Vol. 1373). Springer, 366–398.
In STOC. ACM, 705–714.
[13] Aleksandra Korolova, Krishnaram Kenthapadi, Nina Mishra, and Alexandros
Ntoulas. 2009. Releasing search queries and clicks privately. In WWW. ACM,
171–180.
[14] Fragkiskos Koufogiannis, Shuo Han, and George J. Pappas. 2015. Optimality of
[15] Stanley L Warner. 1965. Randomized response: A survey technique for eliminating
the Laplace Mechanism in Differential Privacy. CoRR abs/1504.00065 (2015).
evasive answer bias. J. Amer. Statist. Assoc. 60, 309 (1965), 63–69.
small error is paramount or an access time of 𝑂(log 𝑑) is sufficient,
the ALP mechanism will provide the best solution.
Variants. We assume in this paper that 𝑘 is a known bound on the
sparsity of the input data. However, in some applications the value
of 𝑘 itself is private. Here we briefly discuss approaches in such
settings. We use the value of 𝑘 to select the size of the embedding,
such that the probability of hash collisions is sufficiently small.
When 𝑘 is not known we can still bound the probability of hash
collisions.
If the input is a histogram the sparsity differs by at most 1 for
neighboring datasets. As such we can use a fraction of the pri-
vacy budget to estimate the sparsity. Note that this is not possible
for vectors, as the difference in sparsity can be as large as 𝑑 for
neighboring datasets.
If ∥𝑥∥1 = 𝑛 is known then we have ∥ ˆ𝑥∥1 = 𝑛𝜀 for the scaled input.
We can bound the probability of hash collisions by a constant when
the size of the embedding is 𝑂(𝑛𝜀) bits. If ∥𝑥∥1 is unknown we
can estimate it using a fraction of the privacy budget. Note that
the space differs from the 𝑘-sparse setting, and remains 𝑂(𝑛𝜀) bits
when applying the thresholding techniques.
An implementation of a variant of the ALP mechanism is avail-
able as part of the open source project OpenDP (https://opendp.org/)
in the repository https://github.com/opendp/opendp.
8 OPEN PROBLEMS
The main open problem that we leave is if it is possible to achieve
similar space and error with constant time access. We know of a
way (based on the count-min sketch) to achieve optimal expected
error with constant time access and space within a logarithmic
factor of optimal. However, this method does not have strong tail
bounds on the error.
ACKNOWLEDGMENTS
We thank the anonymous reviewers for their detailed suggestions
that helped improve the paper. Christian Janos Lebeda and Rasmus
Pagh are affiliated with Basic Algorithms Research Copenhagen
(BARC), supported by the VILLUM Foundation grant 16582.
13
Session 4D: Differential Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1235A CLOSED-FORM PROOF OF LEMMA 4.6
Here we provide a closed-form expression used in the proof of
Lemma 4.6.
In the proof, we will make use of general binomial coefficient([10,
Equation 5.1]):(cid:18)𝑟
(cid:19)
𝑟(𝑟 − 1) . . . (𝑟 − 𝑘 + 2)(𝑟 − 𝑘 + 1)
𝑘!
=
,
𝑘
Finally, let 𝑝 < 𝑞 and let 𝑧 = 𝑝𝑞. This gives us the closed-form
expression:
(cid:18)2𝑘
(cid:19)
𝑘
𝑘
∞∑︁
𝑘=0
(𝑝𝑞)𝑘 =
=
=
2𝑝𝑞
(1 − 4𝑝𝑞)3/2
2𝑝𝑞
((𝑞 − 𝑝)2)3/2
2𝑝𝑞
(𝑞 − 𝑝)3 .
and the binomial theorem ([10, Equation 5.12]):
(cid:18)𝑟
(cid:19)
∞∑︁
𝑘
𝑘=0
(1 + 𝑧)𝑟 =
(𝑧)𝑘 .
Starting from an infinite series with 𝑧 < 1/4, we simplify as
(−4𝑧)𝑘−1
14
follows:
(cid:18)2𝑘
(cid:19)
𝑘
𝑘
∞∑︁
𝑘=0
𝑘=1
∞∑︁
∞∑︁
∞∑︁
𝑘=1
𝑘=1
4𝑧
2
(𝑧)𝑘 =
=
=
=
= 2𝑧
= 2𝑧
= 2𝑧
(2𝑘)!
𝑘!𝑘! 𝑧𝑘
𝑘(𝑘 − 1
𝑘
𝑘
2
2
𝑘!𝑘!
2)(𝑘 − 1) . . .(cid:16) 3
(cid:17)
(cid:17)1(cid:16) 1
2) . . .(cid:16) 5
(cid:17)(cid:16) 1
(cid:17)(cid:16) 3
(cid:17)
(cid:17)
(cid:17)(cid:16) 3
2) . . .(cid:16) 5
(cid:17) . . . (−𝑘 + 3
(𝑘 − 1)!
2)(𝑘 − 3
(𝑘 − 1)!
2
2
2
2
2
(𝑘 − 1)!
(𝑘 − 1
2)(𝑘 − 3
𝑘=1
∞∑︁
∞∑︁
∞∑︁
∞∑︁
𝑘=1
𝑘=1
2
2
(𝑘 − 1
(cid:16)− 3
(cid:17)(cid:16)− 5
(cid:18) − 3
(cid:19)
(cid:18)− 3
(cid:19)
2
𝑘 − 1
2
𝑘
(−4𝑧)𝑘−1
(−4𝑧)𝑘
𝑘=0
2𝑧
(1 − 4𝑧)3/2 .
=
22𝑘𝑧𝑘
(4𝑧)𝑘
(4𝑧)𝑘−1
2)(−𝑘 + 1
2)
Let 𝑝 = 𝑎
𝑎+𝑏 and 𝑞 = 𝑏
1 − 4𝑝𝑞 =
𝑎+𝑏 . Then we have:
(𝑎 + 𝑏)2
(𝑎 + 𝑏)2 − 4𝑎𝑏
(𝑎 + 𝑏)2
𝑎2 + 𝑏2 − 2𝑎𝑏
(𝑎 + 𝑏)2
=
(𝑏 − 𝑎)2
=
(𝑎 + 𝑏)2
= (𝑞 − 𝑝)2 .
Session 4D: Differential Privacy CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea1236