(colored cell). Items y1, y2, y3 are checked for belonging. The
103103
item y3 /∈ S is found to be present in the ﬁlter and hence is a
false positive. Item y1 however does not belong to S.
The previous equations on the false positive rate of Bloom
ﬁlter are well-established. They are valid as long as the digests
of the inputs are uniformly distributed. We now see how these
parameters behave under adversarial settings.
IV. ADVERSARY MODELS
As a general principle, developers while designing applica-
tions built on a Bloom ﬁlter decide on the maximum number
of elements to be inserted, the desired false positive probability
and a hash function. Once these parameters are chosen, they
can compute the ﬁlter size and the optimal number of hash
functions using (2) and (3).
In this work, we assume that the Bloom ﬁlters are always
deployed and maintained by trusted parties. This assumption is
necessary, otherwise any bit of the ﬁlter can be tampered by the
adversary. The scenario where Bloom ﬁlters are maintained by
possibly untrusted parties is hence meaningless and has indeed
led to big failures such as List Of All Friends (LOAF). LOAF
(now discontinued) was designed to allow a user to send email
messages along with his address book compressed in the form
of a Bloom ﬁlter. The motivation behind sending address books
was that the friends of my friends are trusted. Therefore, the
Bloom ﬁlters of a user’s friends can be used as a whitelist
spam ﬁlter. When an email is received, the source address is
checked against the Bloom ﬁlter. If it is present, the email is
not marked as spam. Otherwise, it is suspicious and must be
analyzed using a more complex spam ﬁlter. The trivial attack
here is to send a fake Bloom ﬁlter (for instance, (cid:3)z where all
the bits are set to 1) allowing a malicious user to whitelist any
email address in the world.
We also assume that the implementation of the Bloom ﬁlter
is public and known to the adversary. Moreover, we assume
that the operations on the ﬁlter are always predictable. These
hypotheses are usually veriﬁed in open source software.
Before describing our adversary models, we deﬁne Pre-
image and Second pre-image attacks on Bloom ﬁlters. These
attacks can be perceived as natural extensions of their hash
function counterparts. Nevertheless, these notions require ex-
plicit treatment due to the subtleties introduced by the data
structure.
Deﬁnition 4.1: Pre-image for a Bloom ﬁlter. Given a
Bloom ﬁlter, (cid:3)z, with only one item inserted into it, an as-
sociated pre-image for the ﬁlter is a string y ∈ {0, 1}∗ with
Iy = {h1(y), . . . , hk(y)} such that Iy ⊆ supp((cid:3)z).
Deﬁnition 4.2: Second pre-image for a Bloom ﬁlter.
Given a Bloom ﬁlter, (cid:3)z, with only one item x ∈ {0, 1}∗
with Ix = {h1(x), . . . , hk(x)} inserted into it, an associated
second pre-image for the ﬁlter is another string y (cid:2)= x
with Iy = {h1(y), . . . , hk(y)} such that Iy ⊆ supp((cid:3)z). The
difference with respect to pre-image is that the item x is now
given to the adversary.
Remark 4.1: Thinking along the lines of (second) pre-
image attacks on hash functions, the complexity of ﬁnding
a pre-image or a second pre-image for a Bloom ﬁlter should
mk , for each hash function hi is uniform over
intuitively be 1
(cid:6)
[0, m − 1]. However, since in case of Bloom ﬁlters, the order
of hashes in the set Iy is not
the probability
of ﬁnding a (second) pre-image in case of Bloom ﬁlters
is wH ((cid:4)z)
that
the total number of (second) pre-images is wH (z)k, i.e., all
permutations of supp((cid:3)z) with repetitions.
. This holds due to the fact
important,
(cid:7)k
wH (z)
=
k
mk
m
In the following, we deﬁne three adversaries for Bloom
ﬁlters: chosen-insertion adversary, query-only adversary and
deletion adversary.
A. Chosen-insertion Adversary
The ﬁrst adversary can choose the items to be inserted in
the Bloom ﬁlter. She can either add the items to the ﬁlter
by herself or can arrange to make the trusted party do it for
her. We consider two cases: in the ﬁrst scenario the adversary
controls all
the items to be inserted in the ﬁlter and the
second in which the ﬁlter is non-empty at the time of the
attack and hence contains some already inserted items. The
goal of this adversary in both the cases is to obtain a false
positive probability which is higher than the one expected by
the developer. This is achieved by increasing the number of
set bits in the ﬁlter, which we refer to as a pollution attack. In
the worst case and in case of certain types of Bloom ﬁlters,
the adversary can set all the bits of the ﬁlter to one: this is
referred to as a saturation attack.
By carefully choosing the items, it becomes possible to
exceed the expected false positive probability, which eventually
forces the application to deviate from its expected behavior. To
be precise, a polluting item x should maximize the number of
bits set to 1:
∀i (cid:2)= j ∈ [1, k], hi(x) (cid:2)= hj(x) ,
∀i ∈ [1, k], hi(x) /∈ supp((cid:3)z) .
(6)
In the above equation, (cid:3)z denotes the ﬁlter after each insertion.
After n such insertions into the ﬁlter, the number of set bits
attains the value kn. An illustrative example is presented
in Fig. 2. Items x1, x2, x3, x4 are so chosen such that all
hj(xi) are distinct, for j ∈ [1, 2] and i ∈ [1, 4]. The colored
cells are the bits set to 1 by the adversary after crafting the
corresponding items.
x1
x2
1
1
2
2
x3
1
2
x4
1
2
0 0 0 1 0 1 1 1 1 1 1 1
Fig. 2: Chosen-insertion adversary (k = 2).
Hence, with carefully selected items, the number of set
bits in the ﬁlter can be made larger than the expected value.
In fact, as previously mentioned (see (5)), with the optimal
parameters: m, n, and kopt, the expected number of set bits in
the ﬁlter is (refer to (2)):
m
nkopt
2 ln 2
=
2
≈ 0.72nkopt .
Comparing it to nkopt bits set to 1 by the adversary, she
increases the number of 1s in the ﬁlter by 38%. For a chosen
k, the adversary sets nk bits of the m-bit ﬁlter to 1, hence the
false positive probability achieved in the attack is:
(cid:3)
(cid:4)k
nk
m
f ADV =
.
(7)
m
√
Fig. 3 shows how the false positive probability behaves
under a chosen-insertion attack. We choose a Bloom ﬁlter of
size m = 3200 with a capacity of 600 items. Equation 2
for optimal parameters gives kopt ≈ 4, and fopt = 0.077.
When the number of inserted items is low, f ADV and f are
superimposed until (cid:9)√
k (cid:10) items have been added. This is
m items’ indexes
due to the Birthday paradox: the ﬁrst
are likely to be all different. It implies that the adversary
does not need to compute pre-images for the ﬁrst (cid:9)√
k (cid:10)
m
items she wants to insert. Let us now consider the threshold
probability of fopt = 0.077. This threshold is reached after
600 insertions if the indexes are uniformly distributed. An
adversary however can attain this value after only 422 well-
chosen insertions. After 600 chosen insertions, she obtains a
false positive probability of 0.314 ≈ 4fopt. In certain scenarios,
an adversary may not be able to control all the insertions into
the ﬁlter. To this end, let us consider the case of 400 normal
insertions followed by insertions chosen by the adversary. The
threshold of 0.077 is then reached after 510 insertions. At the
end of 600 insertions, she obtains a false positive probability
of 0.17 ≈ 2fopt.
False positive probability
f
Partial
f ADV
0.35
0.28
0.21
0.14
0.07
0
0
100
200
Number of inserted items
300
400
500
fopt
600
Fig. 3: False positive probability as a function of inserted items
(m = 3200, k = 4 and fopt = 0.077).
Now, we consider saturation attacks. The expected number
(cid:13). This directly fol-
of items to fully saturate a ﬁlter is: (cid:12) m log m
lows from the Coupon collector’s problem: given m coupons,
ﬁnd the expected number of draws with replacement before
having drawn each coupon at least once. In the case of Bloom
ﬁlter, k coupons are drawn in each draw. In contrast to this
k (cid:13) items, since each item sets
result, our attack only requires (cid:12) m
k
104104
k bits to 1. This allows the adversary to gain a factor of log m
to achieve saturation.
An important question is to estimate the feasibility of
forging a polluting item, i.e., an item which satisﬁes (6). To this
end, let us consider a ﬁlter (cid:3)z of Hamming weight wH ((cid:3)z) = W ,
for an integer W > 0. We want to insert a polluting item x
to (cid:3)z. There are
ways to choose such an item. The
probability to ﬁnd such an item is then:
m−W
(cid:10)
(cid:9)
k
(cid:9)
(cid:10)
m−W
k
mk
.
(cid:9)
(cid:10)
k
m−(n−1)k
If we wish to insert n polluting items in an empty ﬁlter, there
ways to choose the n-th item. If m is large
are
compared to k, ﬁnding polluting elements is much simpler than
ﬁnding pre-image or second pre-image for Bloom ﬁlter. We
illustrate in Section V, the practical cost of forging polluting
items.
B. Query-only Adversary
The second adversary cannot insert items into the ﬁlter.
However, she knows the current state of the ﬁlter or a part
of it. Similar to a chosen-insertion adversary, she can either
generate queries by herself or force the trusted party to query
on her behalf. The query-only adversary can have two distinct
objectives. She can either craft
items that generate false-
positives hence force the application to err, or that her items’
digests are well-distributed in the ﬁlter leading to latency.
There could be several motivations for an adversary to
make the ﬁlter generate false positives. A typical scenario
would be to attack applications incorporating Bloom ﬁlters, but
which do not tolerate false positives at all. In such applications,
Bloom ﬁlters conjointly work with a remote mechanism (for
example a database storing the items) to get rid of false
positives. In general, when the item is found to be present
in the ﬁlter, the remote mechanism provides a conﬁrmation of
a true positive. This ensures that the application does not err.
Generation of large number of false positives would lead to
false positive ﬂooding enabling an adversary to hit the second
mechanism and attempt to mount a DoS.
For a given Bloom ﬁlter (cid:3)z, a query-only adversary wants
to generate an item y such that:
∀i ∈ [1, k], hi(y) ∈ supp((cid:3)z) .
(8)
Fig. 4 shows different examples of false positives: Items
y1, y2, y3 are detected as being present in the ﬁlter while these
items were never inserted in the ﬁlter. Items y1 and y3 are
particularly interesting. While y1 veriﬁes h1(y1) = h2(y1), y3
satisﬁes h1(y3) = h2(x1) and h2(y3) = h1(x1).
.
(cid:9)
(cid:10)k
Knowing the positions of the 1s, the adversary has W k =
(wH ((cid:3)z))k choices to forge a false positive. There are 25
choices in Fig. 4. The probability to forge a false positive
y is:
It
W
m
is also possible to consider a query-only adversary
making dummy queries. The adversary queries for items which
are not in the ﬁlter. Let y be an item chosen by the adversary,
then it must satisfy:
∀i (cid:2)= j ∈ [1, k], hi(y) (cid:2)= hj(y) ,
∀i ∈ [1, k − 1] , hi(y) ∈ supp((cid:3)z) and hk(y) /∈ supp((cid:3)z) .
x1
x2
x3
1
2 1
2
1
2
0 0 0 0 1 1 0 1 1 0 1 0
2
1
y1
2
1
y2
2
1
y3
Fig. 4: Crafted false positives: wH ((cid:3)z) = 5.
The probability of ﬁnding such an item is:
(m − W ) ·(cid:9)
mk
(cid:10)
W
k−1
.
The idea of this attack is to make the query as expensive as
possible. It targets applications with very large Bloom ﬁlters
and forces the party running the Bloom ﬁlter to make more
memory accesses and more computations than expected. The
goal of the adversary is to reach the worst case execution time
for each query.
C. Deletion Adversary
Bloom ﬁlters basically support
insertions and queries.
However, certain variants of Bloom ﬁlters also allow deletion,
a typical example is Counting Bloom ﬁlter [11], where instead
of being a bit vector, the ﬁlter is an array of counters, which
are incremented/decremented when items are inserted/deleted
to/from the ﬁlter. False negatives are the drawbacks of these
variants [17]. Hence, an adversary who does not control the
insertions into the ﬁlter can nevertheless forge an item and
make it delete from the ﬁlter.
We assume that the ﬁlter is fully or at least partially known
to the deletion adversary. The goal of the adversary is then
to create false negatives: she wants to make an item x with
Ix = {h1(x), . . . , hk(x)} disappear from the ﬁlter. To this end,
the adversary needs to ﬁnd item(s) x(cid:2) in the ﬁlter with Ix(cid:2) =