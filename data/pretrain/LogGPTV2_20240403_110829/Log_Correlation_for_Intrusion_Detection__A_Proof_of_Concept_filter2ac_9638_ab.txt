2. System is attacked with a ‘noop’ attack. This can be
seen in the TCP dump by looking at TCP packets with
many noops, which usually indicate a buffer overﬂow
attack.
3. Users are created to gain root access. The telnet log
reveals that after obtaining root access of the system,
the attacker creates two users with the same password,
twin and hantu; the second with superuser access.
Proceedings of the 19th Annual Computer Security Applications Conference (ACSAC 2003) 
1063-9527/03 $17.00 © 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:38:23 UTC from IEEE Xplore.  Restrictions apply. 
4. Intruder gains superuser access and now controls the
system. Syslog shows sessions opened for the newly
created users.
5. Attacker tries to use the compromised system for ma-
licious purposes. The IDS running on the system
(Snort [25]) logs the actions of the attacker:
(a) Telnets to system using as “twin”, then gains su-
peruser access as “hantu”.
(b) Downloads (ftp) attack toolkit from another sys-
tem.
(c) Installs backdoor which allows unauthorized ac-
cess to anyone with the TERM set to vt9111.
(d) Covers moves by deleting affected logs.
(e) Days later comes back and logs in using the back-
door.
(f) Downloads and installs Trinoo [7] client.
(g) Several attempts are made to use the system as a
Trinoo DDoS attack against other systems.
Finally, the sysadmin disconnects the system so the attacker
cannot use it for malicious purposes.
7. Bottom-up approach: A case of anomaly de-
tection
As mentioned in Section 3, a bottom-up approach to
ﬁnding attacks through correlation of data between logs
requires an actual logging infrastructure in an attempt to
identify attack. The problem with this approach is that
each log may have millions of entries in it, and analyzing
them is a computation-intensive task that may be intractable
for even relatively small computer networks. Data min-
ing techniques can be used to ﬁlter out the important data
from different logs and to enable the identiﬁcation of dif-
ferent attacks that may have occurred. In this section we
use the bottom-up approach with a data mining tool (RIP-
PER [3]) to detect anomalies (in particular, the presence of
the Yaha [22] virus).
We used the “predict the next system call” method com-
bined with log correlation to improve virus detection. This
method was brieﬂy mentioned in the work of Lee and
Stolfo [14, 15] but not explored.
There are currently several e-mail born viruses circulat-
ing around the Internet that have been difﬁcult to eradicate,
e.g., Yaha [22] the e-mail virus analyzed in our work. Yaha
is ﬁrst delivered to a user’s mailbox; once the user opens the
infected message, the virus searches the machine for e-mail
addresses and sends off approximately 115 infected mes-
sages to the e-mail addresses that it ﬁnds. This intrusion
takes place in the background and is unknown to the user,
and the 115 messages do not show up in the users Sent items
box.
Looking at the system call sequence, abnormal behavior
may be observed which is not deemed statistically signiﬁ-
cant to signify an intrusion in a tuned IDS. However, if we
examine the corresponding network trafﬁc the traces show
an unusual amount of network trafﬁc corresponding to the
system call sequence where the user opens the e-mail. Com-
bining this information from the system call sequence and
the network trafﬁc, it is possible to identify intrusions that
would normally not be identiﬁed using just one log.
Previous work in literature (Wenke Lee and Sal
Stolfo [14, 15]) mine system calls or network data but do
not correlate information between the two sets of data.
Lee et al. [14, 15] discuss two data mining classiﬁcation
models for anomaly detection. We use RIPPER [3] as the
data mining tool for rule learning in two approaches:
1. The ﬁrst approach is to feed training data to RIPPER
with both “normal” and “abnormal” (system call or
network) sequences. From that, RIPPER outputs rules
which can be applied to predict whether a (system call
or network) sequence is “normal” or “abnormal”.
2. The second approach is to train RIPPER with “normal”
traces only. Each output rule of RIPPER must have
some conﬁdence information: the number of matched
examples and the number of unmatched examples in
the training data. These rules are used to analyze new
sequences.
The ﬁrst step for both approaches is to train RIPPER with
normal traces of both network trafﬁc and system calls. For
this we generated hours of normal e-mails/requests from the
e-mail server. We captured the system calls along with the
network trafﬁc on a machine running Windows XP. The ex-
periments were conducted on two interconnected worksta-
tions in a laboratory isolated from the Internet. The Win-
dows XP machine had an e-mail client and logging tools
installed and the Linux box served as an e-mail server. We
used APISpy32 [10], with some modiﬁcation, to intercept
system calls. The logged system calls and network trafﬁc
on the client machine were then mined to determine if an
intrusion had taken place.
Then second approach uses a system call sequence to
predict the next system call. After processing the training
data, RIPPER generates a series of rules. One such rule
may be: if system call 1 is Open, then system call 7 should
be Closed (with a conﬁdence level of 0.38).
After RIPPER generates the rules, the conﬁdence level
of each rule is calculated as the number of matched exam-
ples divided by the sum of matched and unmatched exam-
ples. When mining the actual experimental data from both
the network trafﬁc log and system call log, the conﬁdence
Proceedings of the 19th Annual Computer Security Applications Conference (ACSAC 2003) 
1063-9527/03 $17.00 © 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:38:23 UTC from IEEE Xplore.  Restrictions apply. 
level of the violated rule is adjusted similar to Lee et al. [14].
The averaged score (by the total number of sequences) of
the trace is used to decide whether there is an intrusion.
The main goal of our experiments was to test if this
method may improve intrusion detection systems when the
results from multiple logs are correlated (speciﬁcally traf-
ﬁc logs and system call logs). For example, if there is a
slight anomaly in network trafﬁc the conﬁdence levels may
change when mining the system calls. Unusual behavior
found in a network trafﬁc log may be an indication of an in-
trusion so the conﬁdence level of certain rules for the system
call log may be increased. Thus, we are able to identify in-
trusions with higher conﬁdence levels that would normally
not be identiﬁed by using a single log (trafﬁc or system log).
8. Design and implementation
This section describes the different stages of design and
implementation in detail. More speciﬁcally, we present the
architecture and mining process, and how we correlate sys-
tem calls with network data.
8.1. Architecture
Our setup consisted of 2 Dell Workstations with 2.56
GHz Pentium 4 processors and 512 MB RAM. Our ar-
chitecture consists of logging utilities that monitor sys-
tem activity from different vantage points. For example,
APISpy32 [10] monitors the system from the kernel level
by recording the system calls executed by the system. Win-
Dump monitors the system from the network level. The rest
of our architecture consists of several Perl scripts used in
the correlation process.
8.2. Training
The training data (1.9 million data points) was generated
by ﬁve users. Each spent approximately 4 hours recording
“normal” and “abnormal” data. In order to capture “nor-
mal” behavior, users followed a written script which con-
sisted of sending and receiving several e-mail messages.
This included performing operations that each user nor-
mally does when using e-mail. We call each execution of
the script a “trace”. In order to capture “abnormal” behav-
ior, the same script was used with the addition of an e-mail
message infected with the Yaha32 [22] virus.
8.3. Formatting data
The next step was to format the data for RIPPER [3].
RIPPER expects a list of system calls followed by the value
that it will predict. For example, if we decide that we are
going to use ﬁve system calls to predict the sixth, then RIP-
PER expects the ﬁve system calls followed by the sixth that
it will try to predict.
A sliding window was used to scan the normal traces and
create a list of unique sequences of system calls. The size
of the sliding window was determined by empirical experi-
ments.
We tested several different sequence sizes (odd number
sizes from 5-19). These sequences are constructed from a
sliding window. For example, the ﬁrst sequence would be
system calls 1-5, while the second sequence would consist
of system calls 2-6.
8.4. Generating rules
RIPPER processes the formatted sequences to generate
a list of rules. Since there were almost two million data
points, it took a long time to generate rules. The smaller
sequence sizes took less time (size 5 took 15 hours). The
larger ones took signiﬁcantly longer (size 19 took ﬁve days).
Taking an idea from Lee and Stolfo’s work [15], in or-
der to get meaningful results for network trafﬁc it is neces-
sary to introduce some type of temporal information into the
equation. Therefore, we decided to introduce the number of
connections within the past 10 seconds as a data item. The
rationale behind this decision is that a sudden spike in net-
work trafﬁc could be a good sign of an intrusion. In short,
RIPPER used the characteristics from the network trafﬁc
connections in order to predict how many network connec-
tions have occurred in the past 10 seconds.
8.5. Applying rules
Approximately 20% of the captured data was saved to
use for testing only; i.e., it was not used in training. The
generated rules were applied to the testing data to deter-
mine how abnormal the traces were. RIPPER returned a
list that consists of each predicted result (predicted based
upon the rules) along with the actual value. It also gives the
conﬁdence level for the particular rule that was used in the
prediction.
8.6. Post processing of system calls
A sliding window of size 13 was passed over the list of
predicted values and actual values returned by RIPPER.2 If
the predicted value differs from the actual value, the penalty
value is set to the conﬁdence level of the rule that was
broken. Then the penalty values are summed from the 13
spaces of the sliding window and if the value is greater than
half (6.5), this “region” is considered as abnormal, other-
wise it is considered as normal.
2Size 13 was selected for the post processing window based on testing.
Proceedings of the 19th Annual Computer Security Applications Conference (ACSAC 2003) 
1063-9527/03 $17.00 © 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:38:23 UTC from IEEE Xplore.  Restrictions apply. 
(a) Threshold = 3.5
(b) Threshold = 2.5
Figure 1. Sliding window in the correlation process
The reason we chose to use the conﬁdence level as a
penalty value is to avoid rules having equal weight. For ex-
ample, a rule that has a conﬁdence level of 50% should not
have the same penalty cost as a rule with conﬁdence level of
99%. This differs from the work from Lee et al. [15]; they
do not use the conﬁdence level when calculating the penalty
values when post processing.
Finally, the number of abnormal regions is added up and
divided by the total number of regions. This value repre-
sents how abnormal a particular trace is.
8.7. Post processing of network trafﬁc
The network trafﬁc was processed in the same way as
the system calls. The rules generated from the training data
were used to predict the number of connections in the past
10 seconds.
The rules generated by RIPPER determine that the num-
ber of connections in the past 10 seconds should be 10.
Next, we determined that if the value is actually between
0-20, we can still consider that normal. If there are 20-40
connections we say that the penalty is 1, and from 40-100
the penalty is 3. If there are 100 or above then we say that
the penalty is 5.
Consider a trace that consists of values from 1pm to 2pm.
If we see 50 connections in the past 10 seconds from 1pm to
1:10pm then we say that the penalty from 1pm to 1:10pm is
3, and so forth. These values were used in post processing.
8.8. Correlating system calls and network trafﬁc
Figure 1 illustrates the correlation process. Figure 1(a)
shows how the sliding window is used to detect if a region
is abnormal. In Figure 1(a) the region is normal, since there
are only 3 abnormals and the threshold is 3.5. In Figure 1(b)
we lower the threshold by 1. Notice that the same region is
now considered abnormal. Lowering the threshold is equiv-
alent to increasing suspicion.
The results from the previous step were used in process-
ing the system calls again, by following the same steps in
Section 8.6 except that the time sequences that were deter-
mined were used along with their penalty values in corre-
lating the data. The penalty value was used to adjust the
threshold to determine if a region is “abnormal”.
Then the system calls were processed. When there was
a sequence with a time value between 1pm and 1:10pm the
threshold was lowered by the penalty value (3). This has the
effect of increasing the suspicion level based on the data in
a different log. After the correlation, it only took a 3.5 value
to declare a region as abnormal as opposed to the original
6.5 value.
We also decided to increase the threshold during normal
time periods. We expect this to help to eliminate false pos-
itives. For example, if network trafﬁc is normal between
1:10pm and 1:30pm we can increase the threshold to detect
an abnormal region by 1. So, it would take 7.5 to label a
region as abnormal during that time period.
9. Results
The results obtained from the experiments are summa-
rized in Tables 2 and 3. Table 2 shows the normal behav-
ior traces and Table 3 shows the abnormal behavior traces.
Traces t3, t7, t10, t14, t45, t23, t24, t51, t53, t33, t35, t40
are all normal behavior traces. While traces t100-t104 are
all abnormal behavior traces. “Sequence size” is the num-
ber of system calls that we used to predict the next one. “No
Corr.” is the percentage of abnormality when no correlation
was done. “With Corr.” is the percentage of abnormality af-
ter the data from the two logs was correlated. “Diff.” is the
change in abnormality after we introduce the correlation.
Our experiments produced interesting results. As is ob-
servable from the tables, the results show that correlation in-
creases the accuracy of the intrusion detection system. Af-
ter correlation, normal traces become more normal while
abnormal traces become more abnormal (See Figure 2). We
Proceedings of the 19th Annual Computer Security Applications Conference (ACSAC 2003) 
1063-9527/03 $17.00 © 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:38:23 UTC from IEEE Xplore.  Restrictions apply. 
 




 




 




 




 




 




 




 




 




 



















 




 




 






























































































