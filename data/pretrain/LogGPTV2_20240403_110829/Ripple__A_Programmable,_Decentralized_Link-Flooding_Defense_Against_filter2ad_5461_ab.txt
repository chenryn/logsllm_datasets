trafﬁc composition, trajectory through the network, and how
they evolve over time. Under the hood, the defense policy is
compiled to a distributed set of P4 programs by the Ripple
compiler. Users of Ripple only need to program against the
panoramic view, without having to directly reason about P4-
level switch programs.
Ripple takes inspiration from recent work on network
telemetry [30, 48] that customizes Spark-style functional op-
erators [60] for trafﬁc measurements and monitoring. Table 1
shows the key primitives in Ripple, which are customized to
support detection, classiﬁcation, and mitigation algorithms
for link-ﬂooding defense. The input to a Ripple policy is (log-
ically) every single packet in the network and its trajectory
over time. The Ripple operators record and transform the
packet headers at every switch locally, ﬁltering out attack-
unrelated signals. Link-ﬂooding attack signals, on the other
hand, are promoted from a switch-local view to be globally
visible. They are materialized as a set of panoramic variables
by a distributed runtime protocol. From Ripple’s perspective,
a packet has physical headers such as TCP/IP, but it has ad-
ditional “virtual” headers such as timestamps, link locations,
or any attack signals as deﬁned by the policy. A parameter
w speciﬁes the frequency at which the panoramic snapshot
should be taken. Each snapshot is captured by executing the
policy body, which consists of a series of functional operators.
In the following subsections, we showcase the expressive-
ness of Ripple by ﬁrst emulating a range of SDN-based de-
fenses in recent work and then developing new defenses.
3.2 The Crossﬁre defense
We start by describing how Ripple supports the Crossﬁre
defense using the panoramic view.
Detection. The detection policy looks for signiﬁcant con-
gestion (>80% link utilization) anywhere in the network, and
it populates the panoramic variable ‘victimLks’ every 100 ms:
Primitive
panorama(w)
Description
The panorama abstraction (w: time window)
map(key, vh, f)
Apply f to key, and emit virtual header vh
reduce(key, vh, agg)
Aggregate by key and emit virtual header vh
filter(p)
distinct(key)
when(pred, f)
Apply predicate p to the packet
Emit unique headers as deﬁned by key
If pred is true, apply f
zip(key, l1, l2)
Join two lists l1 and l2 by key
Table 1: The key language constructs in Ripple.
1
2
3
victimLks = panorama (100 ms )
.map( link , ld , f_load)
.filter( ld > 80)
Line 2 maps the virtual header ﬁeld ‘link’, which indicates
the location of the packet, into its current link load ‘ld’. By de-
fault, header ﬁelds that are not referred to by the policy, such
as TCP/IP headers in this policy, are left untouched. Here,
the link load computation uses an intrinsic function ‘f_load’,
which will be expanded by the compiler; internally, it com-
putes an Exponentially Weighted Moving Average (EWMA)
of the trafﬁc rate at ‘link’. Line 3 checks the newly generated
virtual header ‘ld’ against a threshold. A packet’s headers
(virtual and physical) are kept strictly local unless ‘ld’ passes
the ﬁlter, in which case they are populated as panoramic vari-
ables and can be accessed by all switches via the ‘victimLks’
variable. In fact, the Ripple compiler later will see that only
the size of ‘victimLks’ is needed, so it only propagates data
needed for computing the set size; all other header ﬁelds are
abstracted away from the panorama.
Classiﬁcation. The Crossﬁre ﬂows [40] are low-rate HTTP
requests. One could identify such ﬂows for special treatment
(e.g., rerouting these ﬂows), as long as we are aware that
Crossﬁre classiﬁers may result in false positives/negatives:
1
2
3
4
5
6
7
8
suspicious = panorama (100 ms )
.filter( victimLks . sz > 3)
.reduce([ sip , dip , sport , dport ] , flowsz , f_sum( sz ))
.filter( flowsz  1000)
At a high level, line 2 speciﬁes that classiﬁcation will be
triggered if there is signiﬁcant congestion (more than three
congested links). Further, lines 3-4 select low-rate ﬂows; lines
5-7 counts the number of distinct ﬂows for each source and
destination IP address pair. Line 8 selects IP address pairs
with more than 1000 such ﬂows, and populates the selected
headers to a panoramic variable ‘suspicious’. Notice that,
‘victimLks’ in line 2 is deﬁned in the detection policy, but it
is panoramic thus accessible by any switch in the network.
Lines 3 and 7 use ‘reduce’ to aggregate packet headers per-
ﬂow and per-IP pair, respectively; the aggregation function
‘f_sum’ aggregates packet sizes into ﬂow sizes at line 3, and it
counts the number of distinct ﬂows at line 7 after the ‘distinct’
operator. The ‘map’ operator at line 6 invokes ‘f_id’, which
3868    30th USENIX Security Symposium
USENIX Association
•Crossfire flows•4Kbps per flow•1000 flows / secPanorama:produces a virtual header that always evaluates to 1, a constant.
The compiler will later recognize that only ‘sip’ and ‘dip’ are
needed for ‘suspicious’.
Mitigation. Since Crossﬁre ﬂows are indistinguishable
from ﬂash crowds, simply blocking the trafﬁc will result in col-
lateral damage. Existing work has proposed to reroute ﬂows to
less congested regions of the network for mitigation [43, 51]:
1
2
mitigation = panorama (100 ms )
.when([ sip , dip ] in suspicious , fwd =f_reroute)
As before, ‘f_reroute’ is an intrinsic function. It forwards
packets to a switch’s least-utilized ports by setting the virtual
header ‘fwd’ to the outgoing port. The compiler will recognize
that ‘mitigation’ is never accessed by another policy, so it is
ﬁltered from the panoramic view.
Summary. The mitigation policy can be easily modiﬁed to
invoke ‘f_drop’ as a more aggressive defense, if so desired.
The detection policy can also be parameterized to use differ-
ent thresholds, as can the classiﬁcation policy for different
numbers of congested links or different types of attack ﬂows.
Users operate at a higher level of abstraction, and our com-
piler automatically ensures that the panoramic view will be
implemented in the switch programs.
3.3 The Coremelt defense
Next, we show how one can implement a defense against vol-
umetric Coremelt attack ﬂows. Assuming the same detection
policy as before, we can classify volumetric ﬂows and drop
them.
Classiﬁcation. Line 2 remains the same as before.
Line 3 aggregates the trafﬁc volume for each source IP,
and line 4 selects the ones with high trafﬁc volume:
1
2
3
4
suspicious = panorama (100 ms )
.filter( victimLks . sz > 3)
.reduce([ sip ] , flowsz , f_sum( sz ))
.filter( flowsz > 100 MB )
The mitigation policy will use the panoramic variable ‘suspi-
cious’, which is keyed on ‘sip’.
Mitigation. The operator could specify a more aggressive
defense against volumetric ﬂows by dropping such packets:
mitigation = panorama (100 ms )
1
2. when([ sip ] in suspicious , fwd =f_drop)
The mitigation policy highly resembles that in Crossﬁre, ex-
cept that suspicious trafﬁc will be dropped.
3.4 The SPIFFY defense
throughput for a source IP address increases or not. Nor-
mal TCP ﬂows typically will ramp up, because they were
originally bottlenecked at the network link. In contrast, attack
ﬂows will have stable rates as each bot has already been uti-
lized to the full. SPIFFY identiﬁes IP addresses with stable
rates after rerouting, and drops their trafﬁc. We can spec-
ify this rerouting based classiﬁcation in Ripple as follows.
‘ﬂowsz1’ and ‘ﬂowsz2’ policies compute the trafﬁc rate of
each source IP address before and after rerouting, respec-
tively. The ‘rerouteip’ policy reroutes trafﬁc once the attack is
detected, and records the source IP addresses that have experi-
enced rerouting. The ‘suspicious’ policy implements the rate
change test for classiﬁcation. The ‘drop’ policy implements
the defense.
1
2
3
4
5
6
7
8
9
flowsz1 = panorama (100 ms )
.when( rerouteip . isempty )
.reduce([ sip ] , flowsz1 , f_sum( sz ))
flowsz2 = panorama (100 ms )
.when(! rerouteip . isempty )
.reduce([ sip ] , flowsz2 , f_sum( sz ))
rerouteip = panorama (100 ms )
.when( victimLks . sz >3 , fwd =f_reroute)
.distinct([ sip ])
10
11
12
13
suspicious = panorama (100 ms )
.filter(! rerouteip . isempty )
.zip([ sip ] , flowsz1 , flowsz2 )
.filter( flowsz2 - flowsz1 < 100 KB )
drop = panorama (100 ms )
14
15 .when([ sip ] in suspicious , fwd =f_drop)
The functional operator ‘zip’ performs a join between two sets
of tuples. A zip join between (ka , a) and (kb , b) will produce
(k, a, b) if ka = kb = k; otherwise, the result is empty. Line
12 above performs a join between ‘ﬂowsz1’ with ‘ﬂowsz2’.
Ripple also supports self-joins that join a panoramic variable
with its previous snapshot in the last time window: ‘zip([sip],
ﬂowsz)’ would join the ﬂow sizes in two consecutive time
windows. Similarly, this can also be extended to support joins
across multiple windows, using a similar syntax: ‘.zip([sip],
ﬂowsz, t)’ would zip join the ﬂow sizes in t adjacent windows.
Line 13 takes in the list of (sip, f lowsz1, f lowsz2) tuples, and
selects those with negligible rate differences.
3.5 New defense policies
So far, we have shown how Ripple can support several
state-of-the-art defenses that are developed in the context of
OpenFlow-based SDN. Next, we present a few new policies
that can be supported in Ripple.
SPIFFY [39] proposes a more advanced classiﬁcation algo-
rithm to identify cost-sensitive attackers—i.e., adversaries
that generate protocol-conforming trafﬁc from their bots at
their highest possible rates. The key mechanism of SPIFFY
classiﬁcation is a rate change test, which reroutes trafﬁc to
less congested regions and checks whether the aggregate
P1: Blocking pulsewaves. The following policy identi-
ﬁes ﬂows that generate high-rate, short-lived pulsewaves
to the victim. It relies on detecting signiﬁcant rate dif-
ferences across time windows, and uses 10ms for cap-
turing the panorama. It can be further extended to mon-
itor t consecutive windows at line 3, and by counting
USENIX Association
30th USENIX Security Symposium    3869
the number of pulses across these windows after line 4.
4 Decentralized Panorama Construction
1
2
3
4
pulsewaves = panorama (10 ms )
.reduce([ sip , dip ] , flowsz , f_sum( sz ))
.zip([ sip , dip ] , flowsz , flowsz )
.filter( flowsz1 / flowsz2 < 1/16)
P2: Victim detection. The next policy distinguishes normal
congestion from link-ﬂooding attacks by examining whether
congestion affects all IP ranges roughly evenly, or if there
are victim IPs that experience signiﬁcantly higher packet loss.
Trafﬁc to victim IP ranges will be rerouted to least congested
links for special protection:
1
2
3
4
5
6
7
8
9
inflowsz = panorama (100 ms )
.filter( link ==0 || link ==1)
.reduce([ dip ] , inflowsz , f_sum( sz ))
egflowsz = panorama (100 ms )
.filter( link ==2 || link ==3)
.reduce([ dip ] , egflowsz , f_sum( sz ))
victim = panorama (100 ms )
.zip([ dip ] , inflowsz , egflowsz )
.filter( egflowsz / inflowsz < 0.5)
10 mitigation = panorama (100 ms )
11 .when([ dip ] in victim , fwd =f_reroute)
Assuming links 0-1 are the network ingress and links 2-3
are the egress, the ‘inﬂowsz’ and ‘egﬂowsz’ policies mea-
sure the incoming and outgoing trafﬁc volume for each IP
address, respectively. The ‘victim’ policy performs a zip join
on ‘inﬂowsz’ and ‘egﬂowsz’, and identiﬁes IP addresses that
experience 50%+ loss rate. The ‘mitigation’ policy reroutes
such trafﬁc.
P3: Protecting key networks. The operator could further
customize the ‘victim’ policy above to speciﬁcally protect
key customers as a value-add service:
keyflows = panorama (100 ms )
.zip([ dip ] , inflowsz , egflowsz )
.filter( egflowsz / inflowsz < 0.5)
7
8
9
10 .filter([ dip ] in 1.2.0.0/16)
P4: Multi-vectored attacks. Multiple defense policies can
co-exist in Ripple:
1
2
3
4
5
coremelt_sip = panorama (100 ms )
.. // omitted for brevity
xfire_flow = panorama (100 ms )
.. // omitted for brevity
mitigation = panorama (100 ms )
.when([ sip ] in coremelt_sip , fwd =f_drop)
.when([ sip , dip ] in xfire_flow , fwd =f_reroute)
Summary. Users of Ripple can easily customize the
panoramic view needed for defense, without having to reason
about how the view will be captured locally at each switch
or reconstructed globally. Rather, the Ripple compiler au-
tomatically infers the required header ﬁelds for populating
panoramic variables. At runtime, the protocol only synchro-
nizes the data required by the defense across the network.