of semi-honest adversarial behavior, which is often not suf-
ﬁcient.
Indeed, highly-eﬃcient protocols that are proven
secure in the presence of malicious adversaries and using
the simulation-based approach are few and far between; one
notable exception being the work of [1] for securely com-
puting the median. Therefore, researchers have considered
other directions. One possibility is to consider privacy only;
see for example [9, 21, 6]. A diﬀerent direction considered
recently has been to look at an alternative adversary model
that guarantees that if an adversary cheats then it will be
caught with some probability [2, 16]. We stress that our
protocols are more eﬃcient than all of the above and also
reach a higher level of security than most. (Of course, we
have the additional requirement of a smartcard and thus a
comparison of our protocols is not really in place; rather we
view this as a comparison of models.)
2. STANDARD SMARTCARD FUNCTION-
ALITY AND SECURITY
In this section we describe what functionality is provided
by standard smartcards, and the security guarantees pro-
vided by them. Our description of standard smartcard func-
tionality does not include an exhaustive list of all available
functions. Rather we describe the most basic functionality
and some additional speciﬁc properties that we use:
1. On-board cryptographic operations: Smartcards can store
cryptographic keys for private and public-key opera-
tions. Private keys that are stored (for decryption
or signing/MACing) can only be used according to
their speciﬁed operation and cannot be exported. We
note that symmetric keys are always generated outside
of the smartcard and then imported, whereas asym-
metric keys can either be imported or generated on-
board (in which case, no one can ever know the private
key). Two important operations that smartcards can
carry out are basic block cipher operations and CBC-
MAC computation. These operations may be viewed
as pseudorandom function computations, and we will
use them as such. The symmetric algorithms typically
supported by smartcards use 3DES and/or AES, and
the asymmetric algorithms use RSA (with some also
supporting Elliptic curve operations).
2. Authenticated operations: It is possible to “protect” a
cryptographic operation by a logical test. In order to
pass such a test, the user must either present a pass-
word or pass a challenge/response test (in the latter
case, the smartcard outputs a random challenge and
the user must reply with a response based on some
cryptographic operation using a password or key ap-
plied to the random challenge).
3. Access conditions: It is possible to deﬁne what opera-
tions on a key are allowed and what are not allowed.
There is great granularity here. For all operations
(e.g., use key, delete key, change key and so on), it is
possible to deﬁne that no one is ever allowed, anyone is
allowed, or only a party passing some test is allowed.
We stress that for diﬀerent operations (like use and
delete) a diﬀerent test (e.g., a diﬀerent password) can
also be deﬁned.
4. Special access conditions: There are a number of spe-
cial operations; we mention two here. The ﬁrst is a
usage counter ; such a counter is deﬁned when a key
is either generated or imported and it says how many
times the key can be used before it “expires”. Once
the key has expired it can only be deleted. The sec-
ond is an access-granted counter and is the same as a
usage counter except that it deﬁnes how many times
a key can be used after passing a test, before the test
must be passed again. For example, setting the access-
granted counter to 1 means that the test (e.g., passing
a challenge/response) must be passed every time the
key is used.
5. Secure messaging: Operations can be protected by
“secure messaging” which means that all data is en-
crypted and/or authenticated by a private (symmet-
ric) key that was previously imported to the smart-
card. An important property of secure messaging is
that it is possible to receive a “receipt” testifying to
the fact that the operation was carried out; when se-
cure messaging with message authentication is used,
this receipt cannot be tampered with by a man-in-the-
middle adversary. Thus, it is possible for one party
to initialize a smartcard and send it to another party,
with the property that the ﬁrst party can still carry
out secure operations with the smartcard without the
second party being able to learn anything or tamper
with the communication in an undetected way. One
example where this may be useful is that the ﬁrst party
can import a secret key to the smartcard without the
second party who physically holds the card learning
the key. We remark that it is typically possible to de-
ﬁne a diﬀerent key for secure messaging that is applied
to messages being sent to the smartcard and to mes-
sages that are received from the smartcard (and thus
it is possible to have unidirectional secure messaging
only).
6. Store ﬁles: A smartcard can also be used to store ﬁles.
Such ﬁles can either be public (meaning anyone can
read them) or private (meaning that some test must
be passed in order to read the ﬁle). We stress that
private keys are not ﬁles because such a key can never
be read out of a smartcard. In contrast a public key is
essentially a ﬁle.
not, but are not familiar with all smartcard vendors. We
do know that the smartcards of Siemens (and others) have
these two counters. In the full version of this paper, we will
present a formal deﬁnition of the smartcard functionality.
Smartcard Security. We conclude this section by remark-
ing that smartcards provide a high level of physical security.
They are not just a regular microcontroller with deﬁned
functionality. Rather, great progress has been made over
the years to make it very hard to access the internal mem-
ory of a smartcard. Typical countermeasures against phys-
ical attacks on a smartcard include: shrinking the size of
transistors and wires to 200nm (making them too small for
analysis by optical microscopes and too small for probes to
be placed on the wires), multiple layering (enabling sensitive
areas to be buried beneath other layers of the controller),
protective layering (a grid is placed around the smartcard
and if this is cut, then the chip automatically erases all of
its memory), sensors (if the light, temperature etc. are not
as expected then again all internal memory is immediately
destroyed), bus scrambling (obfuscating the communication
over the data bus between diﬀerent components to make it
hard to interpret without full reverse engineering), and glue
logic (mixing up components of the controller in random
ways to make it hard to know what components hold what
functionality). For more information, we refer the reader
to [22]. Having said the above, there is no perfect security
mechanism and this includes smartcards. Nevertheless, we
strongly believe that it is a reasonable assumption to trust
the security of high-end smartcards (for example, smart-
cards that have FIPS 140-2, level 3 or 4 certiﬁcation). Our
belief is also supported by the computer-security industry:
smartcards are widely used today as an authentication mech-
anism to protect security-critical applications.
3. DEFINITIONS AND TOOLS
We use the standard deﬁnition of two-party computation
for the case of no honest majority, where no fairness is guar-
anteed. In particular, this means that the adversary always
receives output ﬁrst, and can then decide if the honest party
also receives output; this is called “security with abort” be-
cause a corrupted party can abort after receiving output and
prevent the honest party from also receiving output. We re-
fer the reader to [13, Section 7] for full deﬁnitions of security
for secure two-party computation, and present a very brief
description here only.
Preliminaries. A function μ(·) is negligible in n, or just
negligible, if for every positive polynomial p(·) and all suf-
ﬁciently large n’s, μ(n) < 1/p(n). A probability ensemble
X = {X(a, n)}a∈{0,1}∗;n∈N is an inﬁnite sequence of ran-
dom variables indexed by a and n ∈ N.
(The value a
will represent the parties’ inputs and n the security pa-
rameter.) Two distribution ensembles X = {X(a, n)}n∈N
and Y = {Y (a, n)}n∈N are said to be computationally in-
c≡ Y , if for every non-uniform
distinguishable, denoted X
polynomial-time algorithm D there exists a negligible func-
tion μ(·) such that for every a ∈ {0, 1}∗
,
|Pr[D(X(a, n)) = 1] − Pr[D(Y (a, n)) = 1]| ≤ μ(n)
We stress that all reasonable smartcards have all of the
above properties, with the possible exception of the spe-
cial access conditions mentioned above in item 4. We do
not have personal knowledge of any smartcard that does
All parties run in time that is polynomial in the security
parameter. (Formally, each party has a security parameter
tape upon which the value 1n is written. Then the party is
polynomial in the input on this tape.)
Communication model. In this paper we consider a set-
ting where parties can interact with each other and with
a physical smartcard. We model these interactions in the
usual way. Speciﬁcally, each party has two outgoing com-
munication tapes and two incoming communication tapes;
one for interacting with the other party and one for interact-
ing with a smartcard. Of course, only the party physically
holding the smartcard can interact with it via its communi-
cation tapes (if the other party wishes to send a message to
the smartcard it can only do so by sending it via the party
holding the smartcard). This model accurately reﬂects the
real-world scenario of interactive computation with smart-
cards.
Secure two-party computation. A two-party protocol
problem is cast by specifying a random process that maps
sets of inputs to sets of outputs (one for each party). This
process is called a functionality and is denoted f : {0, 1}∗ ×
{0, 1}∗ → {0, 1}∗ × {0, 1}∗
, where party P1 is supposed to
receive the ﬁrst output and party P2 the second output. We
consider the case of malicious adversaries (who may arbi-
trarily deviate from the protocol speciﬁcation) and static
corruptions (meaning that the party controlled by the ad-
versary is ﬁxed before the execution begins).
Security is formalized by comparing a real protocol execu-
tion to an ideal model setting where a trusted party is used
to carry out the computation. In this ideal model, the par-
ties send their inputs to the trusted party who ﬁrst sends the
output to the adversary. (The adversary controls one of the
parties and can instruct it to behave arbitrarily). After the
adversary receives the output it either sends continue to the
trusted party instructing it to also send the output to the
honest party, or halt in which case the trusted party sends
⊥ to the honest party. The honest party outputs whatever
it received from the trusted party and the adversary out-
puts whatever it wishes. We stress that the communication
between the parties and the trusted party is ideally secure.
The pair of outputs of the honest party and an adversary A
in an ideal execution where the trusted party computes f is
denoted idealf,A(z)(x1, x2, n), where x1, x2 are the respec-
tive inputs of P1 and P2, z is an auxiliary input received by
A (representing any prior knowledge A may have about the
honest party’s input), and n is the security parameter.
In contrast, in the real model, a real protocol π is run
between the parties without any trusted help. Once again,
an adversary A controls one of the parties and can instruct
it to behave arbitrarily. At the end of the execution, the
honest party outputs the output speciﬁed by the protocol π
and the adversary outputs whatever it wishes. The pair of
outputs of the honest party and an adversary A in an real
execution of a protocol π is denoted realπ,A(z)(x1, x2, n),
where x1, x2, z and n are as above.
Given the above, we can now deﬁne the security of a pro-
tocol π.
Definition 1. Let π be a probabilistic polynomial-time
protocol and let f be a probabilistic polynomial-time two-
party functionality. We say that π securely computes f with
abort if for every non-uniform probabilistic polynomial-time
adversary A attacking π there exists a non-uniform proba-
bilistic polynomial-time adversary S for the ideal model so
that for every x1, x2, z ∈ {0, 1}∗
idealf,S(z)(x1, x2, n)n∈N
c≡ realπ,A(z)(x1, x2, n)n∈N
,
Reactive functionalities. In some cases, the computation
carried out by the trusted party is not a simple function
mapping a pair of inputs to a pair of outputs. Rather, it can
be a more complex computation that consists of a number
of phases where inputs are received and outputs are sent
(e.g., think of secure poker; parties receive cards, chooses
which cards to throw, and then receive more cards). Such a
computation is called a reactive functionality.
Message authentication codes. Informally speaking, a
message authentication code (MAC) is the symmetric ana-
logue of digital signatures. Speciﬁcally, given the shared
secret key it is possible to generate a MAC tag whose legiti-
macy can be veriﬁed by anyone else knowing the secret key.
A MAC is said to be secure if without knowledge of the key,
no polynomial-time adversary can generate a tag that will
be accepted, except with negligible probability; see [13] for
a formal deﬁnition.
Pseudorandom permutations and smartcards.
In-
formally speaking, a pseudorandom permutation is an eﬃ-
ciently computable bijective function that looks like a truly
random bijective function to any polynomial-time observer;
see [12] for a formal deﬁnition. We remark that pseudo-
random permutations have short secret keys and they look
like random functions to any observer that does not know
the key. Modern block ciphers like 3DES and AES are as-
sumed to be pseudorandom permutations (and indeed one
of the criteria in the choice of AES was that it should be
indistinguishable from a random permutation).
One of the basic cryptographic operations of any smart-
card is the computation of a block cipher using a secret
key that was imported into the smartcard (and is never ex-
ported from it later). We use pseudorandom permutations
in our protocols and will assume that the block cipher in the
smartcard behaves like a pseudorandom permutation. This
is widely accepted for modern block ciphers, and in partic-
ular for 3DES and AES. We remark that this assumes that
the size of inputs to the pseudorandom permutation are of
the appropriate size (e.g., 128 bits for AES).
4. SECURE SET INTERSECTION
In this section we show how to securely compute the se-
cure set intersection problem deﬁned by F∩(X, Y ) = X ∩ Y ,
where X = {x1, . . . , xn1} and Y = {y1, . . . , yn2}, and one
party receives output (while the other learns nothing). We
note that the problem of securely computing the function
feq, deﬁned as feq(x, y) = 1 if and only if x = y, is a special
case of set intersection. Thus, our protocol can also be used
to compute feq with extremely high eﬃciency.
The basic idea behind our protocol is as follows. The
ﬁrst party P1, with input set X = {x1, . . . , xn} initial-
izes a smartcard with a secret key k for a pseudorandom
permutation F (i.e., F is a block cipher). Then, it com-
putes XF = {Fk(x1), . . . , Fk(xn)} and sends XF and the
smartcard to the second party. The second party P2, with
input Y = {y1, . . . , ym} then uses the smartcard to com-
pute Fk(yi) for every i, and it outputs every yi for which
Fk(yi) ∈ XF . It is clear that P1 learns nothing because it
does not receive anything in the protocol. Regarding P2, if
it uses the smartcard to compute Fk(y) for some y ∈ X ∩ Y ,
then it learns that y ∈ X, but this is the information that is
supposed to be revealed! In contrast, for every x ∈ X that
for which P2 does not use the smartcard to compute Fk(x),
it learns nothing about x from XF (because Fk(x) just looks
like a random value).
Despite the above intuitive security argument, there are
a number of subtleties that arise. First, nothing can stop
P2 from asking the smartcard to compute Fk(y) for a huge
number of y’s (taking this to an extreme, if X and Y are
social security numbers, then P2 can use the smartcard to
compute the permutation on all possible social security num-
bers). We prevent this by having P1 initialize the key k on
the smartcard with a usage counter set to n2. Recall that
this means that the key k can be used at most n2 times,
after which the key can only be deleted. In addition to the
above, in order to achieve simulation-based security we need
to have party P2 compute Fk(y) for all y ∈ Y before P1 sends
it XF (this is a technicality that comes out of the proof).
In order to achieve this, we have P1 initialize k with secure