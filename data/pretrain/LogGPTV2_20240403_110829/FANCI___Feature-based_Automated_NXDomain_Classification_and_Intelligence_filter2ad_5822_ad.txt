Table 8: Results for classifying mAGDs of arbitrary
mixed DGAs and bNXD from Siemens applying 5 rep-
etitions of 5-fold CV for 20 sets each of size 100,000
using RFs.
this section, ﬁrst, we show that FANCI performs with
the same quality when trained and deployed in a different
network. Second, we demonstrate that it is even possible
to perform training with data recorded in one network
and use the resulting classiﬁcation model in another net-
work. This means that FANCI generalizes well to new
environments.
Mixed DGAs; Training and Prediction Siemens. To
illustrate FANCI’s detection capabilities are independent
of a certain network, we repeated the mixed DGA exper-
iment from Section 5.2.2 but with sets generated with
bNXDs from the Siemens data set. This experiment
yields ACC values comparable to those obtained in the
same setting for RWTH data. The mean ACC is 0.99699
with a small standard deviation of 0.00015, where the
minimum is 0.99681 and the maximum is 0.99730. Ta-
ble 8 illustrates the detailed detection performance when
using data from the Siemens network.
Next, we carry out two experiments proving that our
trained classiﬁers generalize well to unknown networks,
that is, we examine the scenario of training a classiﬁer
using data from a certain network but use this classiﬁer
somewhere else. To evaluate our loss in ACC when us-
ing a classiﬁer trained in a foreign network we compare
the ACC to scenarios, in which we trained and predicted
using bNXDs from the same network.
Table 9: Classiﬁcation accuracy for training on RWTH
Aachen data and prediction on Siemens data using RFs.
ACC
TPR
TNR
FNR
FPR
0.99785
0.00009
0.99771
0.99784
0.99800
0.99946
0.00006
0.99936
0.99946
0.99952
0.99624
0.00019
0.99591
0.99622
0.99651
0.00054
0.00006
0.00048
0.00054
0.00064
0.00376
0.00019
0.00349
0.00378
0.00409
x
σ
xmin
˜x
xmax
Table 10: Classiﬁcation accuracy for training on Siemens
data and prediction on RWTH Aachen data using RFs.
ing bNXDs from RWTH Aachen for training and sets
containing bNXDs from Siemens for prediction. The
mean ACC is 0.99534, with a small standard deviation of
0.00018. In comparison to performing training and pre-
diction on sets containing bNXDs from Siemens (see Ta-
ble 8), the mean ACC is only marginally smaller, namely
0.00165 percentage points. This is explained by an in-
crease of FPs. However, the false negatives (FNs) even
decrease.
Mixed DGAs, Training Siemens, Prediction RWTH
Table 10 shows results for considering sets containing
bNXDs from Siemens for training and bNXD data from
RWTH Aachen for prediction.
In this experiment the
mean ACC is 0.99785, which is in comparison to the
RWTH-only (see Table 6) experiment even marginally
larger, namely by 0.00026 percentage points. Although
the FNs decrease.
the FPs increase slightly,
This
conﬁrms the trend from the previous experiment.
Mixed DGAs, Training RWTH, Prediction Siemens
The ﬁrst experiment considers training using bNXD
from RWTH Aachen and performs prediction on sets
composed with bNXDs from Siemens. The second ex-
periment is performed vice versa. These experiments are
based on the fact that mAGDs do not differ from network
to network, but only bNXDs may be different. For both
benign data sources we consider 20 data sets each gener-
ated as in the previous experiments. Each data set is used
for training once, where prediction is performed for each
of the 20 sets of the other bNXD source. This results in
20· 20 = 400 passes for each of the two experiments.
Table 9 presents results for considering sets contain-
Again, we performed all experiments with SVMs and
RFs and RFs perform consistently better than SVMs. Re-
sults for SVMs can be found in Appendix A. In summary,
the previous experiments show that FANCI is in general
independent of a certain network, generalizes well to un-
known environments, and even allows for outsourcing of
the actual classiﬁcation.
5.2.4 Additional False Positive Reduction
As highlighted in Section 4.3, FANCI performs a ﬁlter-
ing in the intelligence module to reduce FPs. To evaluate
the efﬁciency of our ﬁltering approach we consider sets
1174    27th USENIX Security Symposium
USENIX Association
Initial
Alexa
top X
RWTH
6,522
Siemens
11,431
102
104
106
102
104
106
Alexa
Alexa + Local
red. by %
0.08
71.79
86.49
0.31
7.52
74.18
rem.
6,517
1,840
881
11,395
10,571
2,952
red. by %
75.53
77.69
89.88
47.85
53.12
77.74
rem.
1,596
1,455
660
5,961
5,359
2,544
Table 11: False positive reduction applied with and with-
out local speciﬁc whitelist, where the reduction is pre-
sented in percent (red. by %) and the remaining amount
of FPs (rem.) is additionally stated as absolute value.
of all unique FP bNXDs occurred during experiments
presented in the previous sections. As we use a local
speciﬁc whitelist in the second ﬁltering step, we con-
sider two data sets, one for RWTH Aachen FP bNXDs
(6,522) and one for Siemens FP bNXDs (11,431). We
evaluated the global ﬁltering step using the Alexa top
100,
top 10,000, or top 1,000,000. The local spe-
ciﬁc ﬁltering is performed with appropriate whitelists
for each of the networks.
For the RWTH Aachen
University network, this list for example includes do-
mains, such as, rwth-aachen.de, sophosxl.net, and
fh-aachen.de. For the Siemens network, this list for
example contains: siemens.net, trendmicro.com,
mcafee.com, and bayer.com. These local speciﬁc
whitelists assume that there is no C2 server present in the
campus networks. Additionally, we assume that certain
companies, such as, Sophos, McAfee, and TrendMicro
do not host a C2 server.
Table 11 presents the results of applying both ﬁlter-
ing steps subsequently on these two sets of unique FP
bNXDs. It states the reduction of FPs in percent and the
amount of remaining FPs. For data from RWTH Aachen
we are able to reduce the FPs by 75.53 up to 89.88 per-
cent, which results in 1,596 or 660 remaining FPs respec-
tively. Considering the Siemens network, we reduce the
FPs at least by 47.85 percent resulting in 5,961 domains
and in the best case we reduce the FPs by 77.74 percent
yielding 2,544 domains left.
The results clearly show the efﬁciency of our subse-
quent FP ﬁltering. Although FANCI’s classiﬁcation ac-
curacy is already outstanding, we are able to at least
halve the amount of FPs even when only considering the
Alexa top 100 as whitelist. In the best case we are even
able to reduce FPs to a tenth of the initial amount.
Now, that we have seen FANCI’s capabilities in detect-
ing mAGDs and proved efﬁciency of our false positive
reduction we present a real world application of FANCI
in the next section.
5.3 Real World
In this section, we present the application of FANCI in
the university network of RWTH Aachen.
Setup. For our real world application test of FANCI
we consider a fresh one-month recording from the cen-
tral DNS resolver of RWTH Aachen University compris-
ing 31 days, more precisely from 13 October 2017 until
12 November 2017, where the data amount is similar to
the recording from Section 5.1. This means that FANCI
has to handle approximately 700 million NXD responses
in total, containing 35 million unique NXDs. FANCI is
used with a single RF classiﬁer trained on a set of size
92,102 containing mAGDs of 59 different DGAs and
bNXD from RWTH Aachen network from the data set
described in Section 5.1. The set contains bNXDs and
mAGDs in equal parts and equal many mAGDs of each
DGA. We applied FANCI by ﬁrst using the classiﬁcation
module on all NXD responses from the fresh recording
and then used the ﬁltering capabilities of the intelligence
module for FP reduction using Alexa’s top 1,000,000.
Results. Applying these two steps we obtained 22,755
unique positive NXDs (∼ 0.065%) that occur in 45,510
NXD responses (∼ 0.0065%) in total. After a semi-
automatic examination of these remaining positives, we
are able to report 405 unknown mAGDs correspond-
ing to ten different groups either indicating an unknown
DGA (UD) or an unknown seed (US). To ﬁnd groups
of unknown mAGDs we make use of the different views
provided via FANCI’s intelligence module as presented
in Section 4.3. Note that unknown, here, means that the
found mAGDs neither are listed in DGArchive nor could
be found via other common sources at the time of writ-
ing. We will submit all ﬁndings to DGArchive. Figure 4
shows representatives of each of the ten groups including
a label indicating if we reckon the group as UD, as US, or
if both seems possible. We carried out the labeling of the
groups with the help of DGArchive, domain knowledge,
and manual research.
By implication, we have seen at most 22,345 unique
FPs in our one-month, real-world test resulting in a
worst-case FPR of approximately 0.00064. As it is hard
to determine correct ground truth in a real-world applica-
tion, this FPR is only of limited signiﬁcance. For state-
ments about the quality of FANCI’s classiﬁcation capa-
bilities, it is more promising to analyze the potential FPs
in more detail. The set of potential FPs is characterized
by a high diversity among the NXDs. Figure 5 shows
twelve potential FPs seen in our real-world evaluation.
They can be classiﬁed into two groups: human-generated
and machine-generated. Where human-generated NXDs
usually exhibit natural language patterns or are very sim-
USENIX Association
27th USENIX Security Symposium    1175
c x o r i i l g . h o s t
dcveyroohhuz . h o s t
k t n o t y b g n q r j v k q . h o s t
ndptbhn . h o s t
q b e w e o n x h z l f l h . h o s t
zwchzomnkersegz . h o s t
blwemxb . ga
y i n n i c . gq
f y r r z x . ml
f h v f b h q . t k
i h r s l r k . c f
x l a j b u . c f
e i s e n b a h n−k u r i r e r . de
rwth−aachend . de
www. c i b c−g l o b a l . hk
h o t m a i l . om
www. d i g i t e x −eu . com
i n f o n e w s 2 4 . org
f s z t a k q w d j f q s c . a s a . a t
i s a t a p . h o s t
ip38 −201−hypermedia . n e t . i d
103−56−7−42−mebd . n e t
1979775309. r s c . cdn77 . org
host37 −252. s w i f t h i g h s p e e d . com
(a) UD1
(b) UD2
(a) Human-Generated
(b) Machine-Generated
a g n g 7 8 s a g d f d k j d t w a 1 0 8 . com
a g n g 7 8 s a g d f d k j d t w a 1 7 7 . com
a g n g 7 8 s a g d f d k j d t w a 2 2 5 . com
a g n g 7 8 s a g d f d k j d t w a 3 1 6 . com
a g n g 7 8 s a g d f d k j d t w a 9 4 8 . com
brn001ba9933850 . n e t
b r n 0 0 1 b a 9 9 f a 1 c 7 . n e t
brw48e244240e9d . n e t
brwc0f8da79205c . n e t
b r w c 4 8 e 8 f b d f a 3 e . n e t
(c) UD3
(d) UD4
a g e i h e h a i o e o a i e g j . e s
r o h g o r u h g s o r h u g i h . hu
s i i i f i b i i e g i i c i i b . i n
i a p g h a h p n p n a p c i p a . mobi
g o i a e g o d b u e b i e i b g . name
a b v a i n v i e n v a i e b a i . i n f o
1917 f71a77 . c l u b
1 a984212aa . c l u b
2 f949298a5 . c l u b
129 a a 1 a 6 f 7 . s p a c e
1459 f4a279 . s p a c e
1 a984212aa . s p a c e
(e) US1 Locky
(f) US2 Infy
539 aa5d47547 . com
646892 f a f 0 4 7 . com
52 dd1bce8b10 . n e t
646892 f a f 0 1 0 . n e t
853 b3eb55b98 . n e t
3 f d q r b n u m 3 f a 2 j 1 . 3 t f r m n 2 7 i . com
c 4 x f 3 3 p 7 n r v o 3 l 0 h . 2 3 b j j 3 a 0 . com
wpdcp7uym0 . up18xtxzouumzd . com
w l h 8 t j 5 5 f x f h . n51ah7y227y −.com
xgs66mu−ui g2u . cjswb3q4m45 . com
(g) US3 PandaBanker
(h) UD5 or US4 of Redyms
a f y o n e s c o r t k i z l a r . xyz
o r d u b a y a n e s c o r t . xyz
k i r i k k a l e b a y a n e s c o r t . xyz
n i g d e b a y a n e s c o r t . xyz
b a y a n e s c o r t b a n d i r m a . xyz
b a y a n e s c o r t b i l e c i k . xyz
a f y o n e s c o r t k i z l a r . xyz
g e t b e a u t i f u l j a c k e d . xyz
e v e l y n m i l l e r . xyz
j u i c e p r e s s . xyz
q u i e t b r a n c h . xyz
t r a c y h e r n a n d e z . xyz
webhostpremium . xyz
w e r t v o l l e b r i l l a n t h o b b y . xyz
(i) UD6 or US5 of GozNym
2nd Stage / Nymaim
(j) UD7 or US6 of GozNym
2nd Stage / Nymaim
Figure 4: Illustration of unknown mAGDs.
ilar to existing domains, machine-generated NXDs tend
to be either of random nature or of technical origin. As-
signing an NXD to one of these classes is not always pos-
sible without additional information, for example con-
sider the potential FP NXD c.ssl-cd.com, which could
belong to each of the classes.
As there is no striking group of similar NXDs among
the set of potential FPs, this allows us to conclude that
FANCI makes no systematic classiﬁcation errors under-
lining FANCI’s extraordinary classiﬁcation performance.
As the network of RWTH Aachen is secured by busi-
ness security software and appliances using blacklists for
known mAGDs, it is not surprising that we could ﬁnd al-
most no known mAGD in our real-world test. To be pre-
cise, using DGArchive we were able to identify only 31
unique known mAGDs.
The application of FANCI in a month-month period
in the university network of RWTH Aachen strikingly
Figure 5: Sample of potential FPs.
illustrates its detection capabilities in real world. Fur-
thermore, this test emphasizes FANCI’s ability to detect
unknown mAGDs as well as known mAGDs. To fur-
ther support FANCI’s applicability in real, large-scale
networks we present a consideration of FANCI’s clas-
siﬁcation speed in the following.
5.4 Training and Classiﬁcation Speed
This section presents a brief overview of
training
and classiﬁcation speeds to demonstrate FANCI’s real-
world applicability. All measurements were performed
single-threaded on a Dell OptiPlex 980 with Intel i7
PI:EMAIL CPU and 16GB RAM running Ubuntu
Linux 16.04. We performed training and classiﬁcation
10 times for each of the mixed sets of size 92,102 used
for our evaluation in Section 5.2. Feature extraction is
included in time measurement.
On average, this results in a training time of 339.71
seconds (5,66 minutes) for an RF.
An RF is able to classify 92,102 unknown samples
within 234.76 seconds. This means that on average per-
forming classiﬁcation of a single unknown sample takes
0.0025 seconds for RFs including feature extraction.
Based on the measurements presented above FANCI is
able to perform classiﬁcation for 400 packets per second
on a general purpose computer using a single thread. As
in the network of RWTH Aachen University as presented
in Section 5.1 on average there are 164 NXD responses
per second with a maximum peak of 900 NXD responses
per second, we can state that FANCI is real-world appli-
cable and is even able to perform live detection in large
networks without sampling.
5.5 Successfully Resolved Domain Names
If a device is detected by FANCI to be infected with a bot
it will ultimately successfully query for the IP address of
its C2 server. If such a successful query can be detected
(e.g., by using FANCI on the successful queries of in-
fected devices after their identiﬁcation), this reveals the
IP address of a C2 server for the botnet in question.
We therefore present a preliminary evaluation of how
well FANCI is able to separate mAGDs from success-
1176    27th USENIX Security Symposium
USENIX Association
ACC
TPR
TNR
FNR
FPR
0.94962
0.00071