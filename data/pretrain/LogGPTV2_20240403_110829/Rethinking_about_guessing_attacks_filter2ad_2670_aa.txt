title:Rethinking about guessing attacks
author:Zhiwei Li and
Weichao Wang
Rethinking about Guessing Attacks
Zhiwei Li
Department of SIS
UNC Charlotte
Charlotte, NC 28223
PI:EMAIL
ABSTRACT
Although various past e(cid:11)orts have been made to character-
ize and detect guessing attacks, there is no consensus on the
de(cid:12)nition of guessing attacks. Such a lack of generic de(cid:12)ni-
tion makes it extremely di(cid:14)cult to evaluate the resilience of
security protocols to guessing attacks.
To overcome this hurdle, we seek a new de(cid:12)nition in this
paper to fully characterize the attacker’s guessing capabili-
ties (i.e., guessability). This provides a general framework
to reason about guessing attacks in a symbolic setting, in-
dependent of speci(cid:12)c intruder models. We show how the
framework can be used to analyze both passive and active
guessing attacks.
Categories and Subject Descriptors
C.2.2 [Computer-Communication Networks]: Network
Protocols|Protocol veri(cid:12)cation; D.2.4 [Software]: Soft-
ware/Program Veri(cid:12)cation|Formal methods
General Terms
Security, Theory, Veri(cid:12)cation
1.
INTRODUCTION
Many security protocols are vulnerable to guessing attack-
s, which aim to obtain a poorly chosen password or data by
trying every possible value for it. Let us consider a simple
one-way authentication protocol:
Message 1.
Message 2.
A → B : {NA}KAB
B → A : {f(NA)}KAB
Here NA is a fresh nonce generated by A and KAB is the
symmetric key shared between A and B, and f is a given
function (e.g., f(NA) = NA + 1). An attacker may obtain
KAB by trying to decrypt both messages with a guessed key
k and then to compare the results, say r1 and r2: if r2 equals
f(r1), then k is the correct guess. Such attacks become more
feasible when one chooses a low entropy secret.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
ASIACCS ’11, March 22–24, 2011, Hong Kong, China.
Copyright 2011 ACM 978-1-4503-0564-8/11/03 ...$10.00.
316
Weichao Wang
Department of SIS and CyberDNA
UNC Charlotte
Charlotte, NC 28223
PI:EMAIL
Starting from the early work of Gong et al. [32, 31], a lot of
e(cid:11)orts have been made either to formulate guessing attacks
or to detect them. Many approaches focus on heuristics to
explore ways of validating a guess [17, 42, 33]. This is usual-
ly done by enumerating rules to determine whether a guess
can be \veri(cid:12)ed", a term widely accepted to characterize a
correct guess. These rules are used to derive an inference
system modeling the guessing capabilities [22], by extending
the standard Dolev-Yao model [25]. Realizing the \incom-
pleteness" of such an inference system in a sense that it may
fail to capture some guessing attacks, Drielsma et al.
[26]
develop a precise formalization of o(cid:11)-line guessing attack-
s, which is independent of any particular intruder model.
However, no automatic procedure is given in [26] and, more
importantly, it only allows guessing atomic values. In [17],
Corin et al. (cid:12)rst use static equivalence from the applied pi
calculus [2] to characterize guessing attacks, which is then
used to derive a procedure for detecting guessing attacks [3].
More recently, Blanchet and Abadi [7] re(cid:12)ne the de(cid:12)nition
by imposing the observational equivalence condition.
Up to now, there is still no clear consensus regarding the
general de(cid:12)nition of guessing attacks, which explains why
some protocol previously shown resistant to guessing attacks
turns out to be vulnerable [40, 32]. There are two main
reasons for this lack of generality.
First, the term \veri(cid:12)able" is not fully understood or for-
malized, while being used implicitly as a synonym for \guess-
able" in all previous approaches. It is fair to mention here
that several de(cid:12)nitions regarding veri(cid:12)ability do exist, al-
though none of them is general enough to be independent of
protocol modeling and/or speci(cid:12)c intruder models. For in-
stance, Lowe [42] presents a group of rules to verify a guess.
Indeed, these rules correctly identify veri(cid:12)able guesses. It
is unclear whether or not the rule set can completely cov-
er all guesses that can actually be veri(cid:12)ed somehow, even
under the Dolev-Yao intruder model. Similarly, Corin et al.
[17] de(cid:12)ne a \veri(cid:12)able" guess based on two conditions of a
\veri(cid:12)er". However, without any intuitive appeal, this def-
inition can fail to capture some practically veri(cid:12)able guess.
Besides, the veri(cid:12)er itself can be very di(cid:14)cult to (cid:12)nd. Corin
[16] then formulate a new de(cid:12)nition of verifying a
et al.
guess using static equivalence [2], which elegantly captures
the essence of verifying a guess. Nonetheless, this de(cid:12)ni-
tion may require the modeling of security protocols by the
applied pi calculus. Moreover, it only considers guesses of
atomic messages.
Second, guessing attacks have been studied from two d-
i(cid:11)erent perspectives: (1) the process perspective [16, 3, 7],
which relies on the modeling of security protocols; and (2)
the attacker’s perspective [17, 22, 42], which emphasizes the
guessing capabilities from a logical point of view. Neither
provides a uni(cid:12)ed view towards guessing attacks.
Our work is therefore geared towards a uni(cid:12)ed framework
for the study of guessing attacks. The primary goal is to
establish an intimate understanding of guessing, which is
intuitive, yet provides a rigorous basis for guessing attacks.
In other words, the new framework should be
• faithful (i.e., (cid:12)ts the common sense of guessing attacks),
• expressive (i.e., accounts for multiple guesses), and
• complete (i.e., captures all guessing attacks in a symbolic
setting).
Unlike most previous work, we treat \guessing" and \at-
tack" separately, because guessing relates closely to the at-
tacker’s ability to reason about its knowledge, whereas at-
tack further exploits the vulnerability of security protocols.
It is worthwhile to reveal the dominant factor of a guessing
attack | the attacker’s guessing capabilities or the interac-
tions between entities.
Contributions.
In this paper, we propose a new de(cid:12)nition to fully charac-
terize the attacker’s guessing capabilities and then show how
it relates to (cid:12)nding guessing attacks in security protocols.
Speci(cid:12)cally, this paper makes the following contributions:
• To uncover relationship between \veri(cid:12)able" and \guess-
able", we formalize the idea of verifying a message in
terms of recognizability [39] | the ability to distin-
guish a message from noise. To our best knowledge,
this is the (cid:12)rst de(cid:12)nition of veri(cid:12)ability that is inde-
pendent of security protocols and/or intruder models.
We show, surprisingly, that a guessable message need-
s NOT to be veri(cid:12)able. In other words, even though
some message is not veri(cid:12)able, it can still be guessed
correctly by the intruder.
• We propose a weaker notion of veri(cid:12)ability to recover
the intuitive understanding of guessing | a message
can be guessed if and only if it is weakly veri(cid:12)able.
This weaker notion thus provides a faithful, expres-
sive, and complete framework for the study of guessing
attacks.
• We introduce a novel way to evaluate the hardness of
guessing. While some guessing attack turns out to be
(computationally) infeasible, the new metric provides
an accurate way to discriminate between feasible and
infeasible guessing attacks, reducing the gap between
formal methods and real implementation. To our best
knowledge, this is the (cid:12)rst explicit measurement about
guessing.
• As a case study, we apply our methodology to (cid:12)nd
passive guessing attacks under the standard Dolev-Yao
intruder model and discuss how to extend this method-
ology to analyze active attacks.
Additional Related Work.
Our work is inspired by previous research e(cid:11)orts on apply-
ing knowledge to security problems, which is often divided
into two groups: deducibility [41] and indistinguishability
[1].
Deducibility is one kind of algorithmic knowledge [35], in
which \knowing what" can be determined by an algorith-
m. The BAN [9] logic, proposed by Burrows, Abadi and
Needham, is probably the (cid:12)rst extensively studied logic in
protocol analysis based on knowledge.
The concept of indistinguishability comes from the clas-
sical possible-worlds approach to model knowledge [30], in
which the actual world is considered to be one of many pos-
sible worlds. Recently, Cohen and Dam [13] provide a gener-
alized Kripke semantics for studying this type of knowledge
in security protocol analysis. They use a static equivalence
[2] to capture the indistinguishability for agents. Abadi and
Cortier [1] examine the decidability of these two notions of
knowledge by studying the underlying equational theories
for deduction and static equivalence.
Organization.
In Section 2, we introduce some background material. In
Section 3, we formalize the idea of verifying a guess and
explain why (strong) veri(cid:12)ability is not a necessary condition
for guessing. After presenting a new knowledge model that
accounts for the attacker’s guessing capabilities in Section
4, we introduce a weaker notion of veri(cid:12)ability that fully
characterizes guessing capabilities in Section 5. In Section 6,
we present our metric to gauge the hardness of guessing. In
Section 7, we move our attention to (cid:12)nding guessing attacks.
Section 8 concludes the paper.
2. PRELIMINARIES
In this section, we brie(cid:13)y review the basic de(cid:12)nitions of
term rewriting systems and the deducibility. We mainly
follow the notations in [23].
2.1 Term Algebra
A signature is a (cid:12)nite set of function symbols F and a
possibly in(cid:12)nite set of constants A. Each function symbol
has an associated arity. We discriminate two types of func-
tion symbols, namely, public and private function symbols,
the sets of which are denoted by F + and F−
, respectively.
Public functions are used to describe operations that can
be freely performed by a principal, such as encryption and
decryption. We need to point out that a decryption oper-
ation is conducted by calling a decryption algorithm even
without the proper decryption key and can be applied to
any message. It can be di(cid:11)erent from the decryption of a
ciphertext.
We de(cid:12)ne the term algebra T (F,A,X ) as the smallest set
containing X and A such that f (t1,··· , tn) ∈ T (F ,A,X )
whenever f ∈ F with arity n, and t1,··· , tn ∈ T (F,A,X ).
Elements of the set T (F,A,X ) are called terms. We will
use l, r, s, t to denote terms and x, y, z to denote variables.
To avoid confusion, syntactic equality of two terms t1 and t2
will be denoted by t1 =s t2. We tend to use the words \term"
and \message" interchangeably in the rest of this paper.
We say s is a subterm of t, written s ⊆ t, if either s =s t
or t =s f (t1,··· , tn) and s is a subterm of ti for some i. We
also write s ⊂ t to mean s ⊆ t and s ̸=s t. A term s occurs
317
in a term set T if s ⊆ u for some u ∈ T . As usual, f v(t) is
de(cid:12)ned as the set of variables that occur in term t. A term
is ground if f v(t) = ∅.
We de(cid:12)ne the length of a term t, notation |t|, as the length
of its binary representation. For convenience, we will use
f f (t) and sub(t), respectively, to denote the outmost func-
tion symbol of t and the immediate subterm set of a term
t1. A context C is a term with exactly a \hole" 2. Then
the term C[t] is C except 2 is replaced by t. Abusing no-
tation slightly, we refer to t[u 7→ v] as t except that every
occurrence of u in t is replaced by v.
def
def
=
∪
A substitution is a (cid:12)nite tuple [t1/x1, ..., tn/xn] mapping
from variables xi to terms ti. The domain and range of a
= {x|xσ ̸=s x} and
substitution σ are de(cid:12)ned by Dom(σ)
{xσ}, respectively. We write σ = θ if
Ran(σ)
Dom(σ) = Dom(θ) and xσ =s xθ for all x. We de(cid:12)ne the
composition of substitutions σ and θ as a new substitution
σ ◦ θ such that tσ ◦ θ =s (tσ)θ.
2.2 Term Rewriting Systems
x∈Dom((cid:27))
An equation is a pair of terms, written s = t and an equa-
tional theory E is presented by a (cid:12)nite set of equations. We
write t1 =E t2 when equation t1 = t2 is a logical consequence
of E.
As is commonplace, the re(cid:13)exive transitive closure of a bi-
nary relation → is denoted by →∗
. A term rewriting system
R consists of a set of rules, l → r. A term rewriting system
R de(cid:12)nes a term rewriting relation →R in a standard way:
C[lσ] →R C[rσ] where C is a context, l → r ∈ R, and σ is
a substitution. Relation ↔R is de(cid:12)ned by s ↔R t i(cid:11) s →R t
or t →R s.
We say that an element p is reducible for → if there is an
element q such that p → q and irreducible otherwise. We
write p →! q if p →∗
R t, then t
is called an R-normal form of s. →R is terminating if there
exists no in(cid:12)nite derivation t0 →R t1 →R ··· and →R is
con(cid:13)uent if there is a term t such that t1 →∗
R t and t2 →∗
R t
whenever t0 →∗
R t2. A term rewriting system
R is convergent if →R is terminating and con(cid:13)uent. Given
an equational theory E, we de(cid:12)ne term rewriting system
= {l → r|l = r ∈ E}. When →RE is convergent,
RE
t1 =E t2 i(cid:11) t1 and t2 have the same RE-normal form[4, 23].
A substitution σ is RE-normal if all terms in Ran(σ) are
RE-normal. We write σ1 =E σ2 to indicate that Dom(σ1) =
Dom(σ2) and xσ1 =E xσ2 for all x ∈ Dom(σ1).
2.3 Modeling Standard Adversaries
q and q is irreducible. If s →!
R t1 and t0 →∗
def
The most straightforward way to model the attacker’s
knowledge is in terms of message deducibility [25, 41]. That
is, given an equational system E and some messages T one
might be able to compute another message t from T under
equational theory E. Formally,
We say that t can be deduced from T , written T ⊢ t, if
T ⊢(n) t for some n. Likewise, t is deduced from T under
E, notation T ⊢E t, if T ⊢(n)
E t for some n. We say that
S and T are equivalent (under E), denoted as S ≡E T , if
S ⊢E t for every t ∈ T and T ⊢E s for every s ∈ S. As we
can see, both ⊢ and ⊢E are closed under substitution. We