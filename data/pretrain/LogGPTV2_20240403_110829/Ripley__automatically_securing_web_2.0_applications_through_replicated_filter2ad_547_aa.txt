title:Ripley: automatically securing web 2.0 applications through replicated
execution
author:K. Vikram and
Abhishek Prateek and
V. Benjamin Livshits
Ripley: Automatically Securing Web 2.0 Applications
Through Replicated Execution
K. Vikram
Cornell University
Abhishek Prateek
IIT Delhi
Benjamin Livshits
Microsoft Research
Ithaca, NY
PI:EMAIL
New Delhi, India
PI:EMAIL
Redmond, WA
PI:EMAIL
ABSTRACT
Rich Internet applications are becoming increasingly distributed, as
demonstrated by the popularity of AJAX or Web 2.0 applications
such as Facebook, Google Maps, Hotmail and many others. A typ-
ical multi-tier AJAX application consists, at the least, of a server-
side component implemented in Java J2EE, PHP or ASP.NET and
a client-side component running JavaScript. The resulting applica-
tion is more responsive because computation has moved closer to
the client, avoiding unnecessary network round trips for frequent
user actions.
However, once a portion of the code has moved to the client,
a malicious user can subvert the client side of the computation,
jeopardizing the integrity of the server-side state. In this paper we
propose RIPLEY, a system that uses replicated execution to auto-
matically preserve the integrity of a distributed computation. RIP-
LEY replicates a copy of the client-side computation on the trusted
server tier. Every client-side event is transferred to the replica of the
client for execution. RIPLEY observes results of the computation,
both as computed on the client-side and on the server side using
the replica of the client-side code. Any discrepancy is ﬂagged as a
potential violation of computational integrity.
We built RIPLEY on top of Volta, a distributing compiler that
translates .NET applications into JavaScript, effectively providing
a measure of security by construction for Volta applications. We
have evaluated the RIPLEY approach on ﬁve representative AJAX
applications built in Volta and also on Hotmail, a large widely-used
AJAX application. Our results so far suggest that RIPLEY provides
a promising strategy for building secure distributed web applica-
tions, which places minimal burden on the application developer at
the cost of a low performance overhead.
Categories and Subject Descriptors
D.4.6 [Operating Systems]: Security and Protection—invasive
software; D.4.7 [Operating Systems]: Organization and Design—
distributed systems;
D.1.2 [Programming Techniques]: Automatic Programming—
program transformation, program modiﬁcation
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’09, November 9–13, 2009, Chicago, Illinois, USA.
Copyright 2009 ACM 978-1-60558-352-5/09/11 ...$10.00.
General Terms
Security, Languages, Design
Keywords
Replication, Tier-splitting, Web applications
1.
INTRODUCTION
Web applications are becoming increasingly distributed, marked
by the emergence of popular AJAX (asynchronous JavaScript and
XML) applications such as Facebook, Google Maps, Hotmail, and
many others. A typical multi-tier AJAX application consists of
a server tier implemented in Java J2EE or Microsoft .NET and a
client tier executing in JavaScript in the browser. The resulting ap-
plication is more responsive, because computation is moved closer
to the client, thus avoiding unnecessary network round trips. Net-
work bandwidth is typically also saved for long-running applica-
tions because the client can make ﬁne-grained data requests instead
of downloading entire HTML ﬁles [3]. Unlike a computation per-
formed entirely on the server, however, once a portion of the code
is moved to the client tier, the overall computation can no longer
be trusted. Indeed, a malicious client can easily manipulate both
the data that resides on and the code that runs within the browser
using one of many readily available proxy- or browser-based data
tampering or debugging tools [27, 29].
The application developer is typically responsible for manually
splitting the application in a way that places all security-sensitive
operations on the server. This is not an easy task because it re-
quires reasoning about the information ﬂow throughout the appli-
cation, an inherently global property that is hard to establish, es-
pecially by manual inspection. While some language-based ap-
proaches have recently been proposed to help reason about secu-
rity [7, 8], these techniques still require a great deal of developer
involvement because code needs to be heavily annotated, making
these techniques difﬁcult to use for large-scale code bases. For in-
stance, one such approach requires about 20–30% of program lines
to be annotated [8]. Moreover, these techniques are challenging to
retroﬁt into existing un-annotated code.
At the same time, manually validating the results computed on
the untrusted client tier, while maintaining responsiveness, is a very
tough approach to get right. Ensuring that these validation checks
are consistently performed on the client (to provide quick feedback
to the user) and on the server (to ensure integrity of validation)
has been challenging, as evidenced by the frequency of cross-site
scripting attacks that are the result of failing to properly sanitize or
ﬁlter all user input consistently [23, 26, 31, 34, 52].
The problem is made much more challenging if the client and
server are expected to exchange arbitrary data structures, whose in-
173Figure 1: Architecture of RIPLEY: user events are delivered to both the JavaScript client-side component C0 and its server-side
replica C. RPCs m and m0 arriving at the server component S are compared by the RIPLEY checker.
tegrity needs to be checked by the server code after each exchange.
The integrity of computation performed by the client code also
needs to be validated.
Imagine a client-server email application
such as Outlook or Hotmail. Suppose the user clicks an image next
to an email message to mark it as spam. As a result, the email mes-
sage is moved to the spam folder and the underlying data structures
such as folder sizes, are updated. Note that a single event leads
to multiple complex operations on the underlying server-side email
database: the email has to be removed to one folder, added to an-
other, the counters need to be updated, rules run, etc., the integrity
checks for which would be scattered across the server code.
While a robust network protocol can be manually designed, in
general, checking that all these actions have been performed prop-
erly and the data structures are updated consistently is not a simple
task. Moreover, if the distributed application is produced using a
distributing compiler such as Links [11] or Volta [36], these in-
tegrity assertions are difﬁcult to synthesize as the partitioning of
the program may often change as a result of application proﬁling
or deployment environment (e.g. desktop vs. mobile devices), thus
invalidating old integrity checks. A distributing compiler automat-
ically partitions the application to be run on multiple machines, of-
ten in different runtime environments, such as JavaScript and .NET.
Similarly, if an online maze game maintains partial game state
and performs logical checks on the client, such as, can a user move
to the right, given the current state of the maze and the user’s lo-
cation within it, such checks can be circumvented by a malicious
user. Re-executing these checks on the server offers a reliable and
conceptually straightforward model for ensuring integrity of server-
side state, no matter how the application is split across tiers.
If it is our ultimate (data integrity) goal to maintain the server-
side email data store in a consistent state, a reliable way to validate
the integrity of this computation is to repeat it on the server side by
replaying the mouse click that initiates the action. RIPLEY effec-
tively restores the level of security that has been lost by moving a
portion of an application to the client. Note that RIPLEY does not
try to enhance the security beyond that: a SQL injection or a cross-
site scripting vulnerability in the original application will persist
in the distributed version; reliance on RIPLEY does not negate the
need for input sanitization.
Architecture of RIPLEY. In this paper we propose RIPLEY, a sys-
tem that uses replicated execution to automatically preserve the in-
tegrity of a distributed computation, such as a typical AJAX appli-
cation. The architecture of RIPLEY is shown in Figure 1. RIP-
LEY replicates the client-side computation on the trusted server
tier. Every user-initiated event is transferred to the replica of the
client for execution. RIPLEY compares results of the computation,
both as computed on the client-side and on the server side using
the replica of the client-side code. Any discrepancy is ﬂagged as a
potential violation of computational integrity.
Our secondary goal is to relieve the application developer of the
burden of ensuring distributed application integrity. RIPLEY auto-
matically provides the developer-intended protection for the appli-
cation without requiring the developer to reason about code place-
ment and trust implications. In line with our security by construc-
tion vision, RIPLEY can be fully integrated with the server cloud so
that replicated deployment is done fully automatically, as a matter
of deployment policy1. RIPLEY performs the following key steps:
1. Capture user events: RIPLEY augments the client to capture
user events within the browser.
2. Transmit events to the server for replay: The client run-
time is modiﬁed to transmit user events to the client’s replica
C for replay.
3. Compare server and client results: The server compo-
nent S is augmented with a RIPLEY checker that compares
arriving RPCs m0 and m received from the client C0 and
server-based client replica C, respectively, looking for dis-
crepancies.
These steps are described in detail in Section 3. In summary, RIP-
LEY relies on re-execution2 to produce the correct result within
replica C based on user events that it receives, effectively ignor-
ing malicious data and code changes that occur on the client. RIP-
LEY does not rely on the integrity of the client computation. Just
as with Web 1.0 applications, the basic assumption throughout this
paper is that anything executing on the server tier is believed to
be un-compromised and trusted, whereas the client tier, including
the browser itself, may be compromised. If the malicious changes
result in different RPCs issued to the server, RIPLEY will ﬂag a
potential exploit and terminate that client’s connection.
As shown in Figure 2, with RIPLEY, a distributed web applica-
tion can combine the best of both worlds: the application is still
responsive because of client-side execution, but the results of this
1Note that RIPLEY is primarily designed to protect the integrity of
distributed applications. RIPLEY does not remove the need for in-
put validation nor does it eliminate conﬁdentiality concerns. Con-
ﬁdentiality and input validation are important orthogonal issues ad-
dressed by prior work [17, 26, 31, 40, 41, 52]. Moreover, while this
is not a panacea, for many applications that expect users to authen-
ticate, conﬁdentiality is often addressed through the use of roles,
which essentially propagates login credentials to the database tier,
in many settings limiting the potential for information leaks.
2Re-execution or replay, hence the name RIPLEY.
C’SCRipley checkerevents = {key=‘a’, id=‘dyn:27’; type=‘keypress’}m'mserver tier (runs in .NET)client tier (runs in JavaScript)174the server needs to support multiple concurrent clients: in this naïve
approach, the memory overhead alone would be about 50 MB per
replica. For efﬁciency and scalability, we run the replica within
a lightweight headless browser emulator instead of a full-ﬂedged
browser. We are careful not to create unnecessary network trafﬁc:
we combine event transfer with existing RPC into the same net-
work packets. While the focus of this paper is full replication,
it is possible to replicate only certain, integrity-critical parts of the
application to cut down the overhead.
Paradoxically, sometimes RIPLEY can even lead to better per-
formance: since the application is replicated on the server, and the
server is typically faster than the client, the client replica running
on the server enables it to anticipate RPCs from the client in ad-
vance. This helps it to prepare and send the reply to the client
ahead of time, using a push technology such as Comet[43]. In the
best case, the client has the illusion of the server taking zero time
for executing the RPC, leading to zero-latency RPCs and further
improvements in responsiveness.
Contributions. This paper makes the following contributions:
• We demonstrate that replication is a practical and effective
solution to the pressing problem of preserving computational
integrity of distributed web applications, all without requir-
ing developer involvement or changes to the development
process.
• We propose a number of performance optimizations that al-
leviate the network, memory, and CPU overhead imposed by
the use of replication. Surprisingly, RIPLEY may make ap-
plications more responsive: because the replica often ﬁnishes
before the client, RPC results can be pro-actively pushed to
the browser, effectively resulting in 0-latency RPCs.
• We evaluate the effectiveness and overhead of RIPLEY on
ﬁve representative security-sensitive Volta applications. To
give a sense of how RIPLEY might scale to larger applica-
tions, we also estimate the overhead of replicating the client-
side portion of Hotmail, an existing widely-used Web 2.0 ap-
plication.
Paper Organization. The rest of the paper is organized as follows.
Section 2 summarizes the threat model and provides an overview of
RIPLEY assurances. Section 3 gives a detailed description of RIP-
LEY implementation choices. Section 4 describes the results of ap-
plying RIPLEY to ﬁve security-sensitive AJAX applications. Sec-
tion 5 presents a discussion of RIPLEY design. Section 6 presents
related work and Section 7 concludes. Appendix A describes our
benchmarks in detail, and Appendix B provides a brief formaliza-
tion of integrity guarantees provided by RIPLEY.
2. THREATS AND ASSURANCES
While distributing compilers [11, 36, 46] propose a powerful
programming model for distributed application development, mov-
ing execution to the untrusted client tier clearly diminishes the secu-
rity of the resulting distributed application compared to the single-
tier original [19]. It is the primary goal of RIPLEY to restore the
level of security that has been lost. Note that RIPLEY does not
try to enhance the security beyond that: a SQL injection [2] or a
cross-site scripting vulnerability [5, 13] in the original application
will persist in the distributed version; reliance on RIPLEY does not
negate the need for input sanitization. However, with RIPLEY, we
ensure that distributing the application will not worsen the appli-
cation security posture. For instance, input sanitization checks are
Figure 2: An informal illustration of the responsiveness vs. in-
tegrity trade-off for the two dominant web application execu-
tion models. RIPLEY aims to combine the best of both.
execution do not have to be trusted because they are replayed on
the server. In other words, the integrity assurance offered by the
application is the same as if it had been run entirely on the server.
Most existing approaches to ensuring integrity of client compu-
tation involve the client sending a proof of certain properties that its
execution state holds. The server efﬁciently validates these proofs
convincing itself of the integrity of the client execution. For in-
stance, the client could periodically send over its stack traces to the
server, and the server could check the traces for any properties it
desires. Or the server could build a model of proper client behav-
ior and ﬂag behavioral violations of this model [16]. While they
are valuable, these techniques only provide a partial enforcement
of integrity.
Feasibility of our approach.
In general, replicating the client-
side component running in JavaScript on the server is far from
easy. We discuss the issues involved in creating a deterministic
replay system [6, 39] in detail in Section 5. While the ideas pro-