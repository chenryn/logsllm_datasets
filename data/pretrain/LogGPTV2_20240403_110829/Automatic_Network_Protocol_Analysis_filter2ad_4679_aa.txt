title:Automatic Network Protocol Analysis
author:Gilbert Wondracek and
Paolo Milani Comparetti and
Christopher Kr&quot;ugel and
Engin Kirda
Automatic Network Protocol Analysis
Gilbert Wondracek§, Paolo Milani Comparetti‡, Christopher Kruegel∗, and Engin Kirda¶
§ Secure Systems Lab
∗ University of California,
‡ Scuola Superiore S.Anna
Technical University Vienna
PI:EMAIL
Santa Barbara
PI:EMAIL
PI:EMAIL
¶Eurecom Institute,
France
PI:EMAIL
Abstract
Protocol reverse engineering is the process of ex-
tracting application-level speciﬁcations for network pro-
tocols. Such speciﬁcations are very helpful in a number
of security-related contexts. For example, they are needed
by intrusion detection systems to perform deep packet in-
spection, and they allow the implementation of black-box
fuzzing tools. Unfortunately, manual reverse engineering
is a time-consuming and tedious task. To address this prob-
lem, researchers have recently proposed systems that help
to automate the process. These systems operate by ana-
lyzing traces of network trafﬁc. However, there is limited
information available at the network-level, and thus, the
accuracy of the results is limited.
In this paper, we present a novel approach to automatic
protocol reverse engineering. Our approach works by dy-
namically monitoring the execution of the application, an-
alyzing how the program is processing the protocol mes-
sages that it receives. This is motivated by the insight that
an application encodes the complete protocol and repre-
sents the authoritative speciﬁcation of the inputs that it can
accept.
In a ﬁrst step, we extract information about the
ﬁelds of individual messages. Then, we aggregate this in-
formation to determine a more general speciﬁcation of the
message format, which can include optional or alternative
ﬁelds, and repetitions. We have applied our techniques to
a number of real-world protocols and server applications.
Our results demonstrate that we are able to extract the for-
mat speciﬁcation for different types of messages. Using
these speciﬁcations, we then automatically generate ap-
propriate parser code.
1 Introduction
Protocol reverse engineering is the process of extract-
ing application-level protocol speciﬁcations. The detailed
knowledge of such protocol speciﬁcations is invaluable for
addressing a number of security problems. For example,
it allows the automated generation of protocol fuzzers [23]
that perform black-box testing of server programs that ac-
cept network input. In addition, protocol speciﬁcations are
often required for intrusion detection systems [25] that im-
plement deep packet inspection capabilities. These sys-
tems typically parse the network stream into segments with
application-level semantics, and apply detection rules only
to certain parts of the trafﬁc. Generic protocol analyz-
ers such as binpac [24] and GAPA [2] also require pro-
tocol grammars as input. Moreover, possessing protocol
information helps to identify and understand applications
that may communicate over non-standard ports or applica-
tion data that is encapsulated in other protocols [14, 19].
Finally, knowledge about the differences in the way that
certain server applications implement a standard protocol
can help a security analyst to perform server ﬁngerprint-
ing [29], or guide testing and security auditing efforts [3].
For a number of protocols (e.g., SMTP, HTTP), spec-
iﬁcations and corresponding protocol parsers are publicly
available. However, there is also a large number of pro-
prietary, closed protocols (e.g., ICQ, SMB) for which such
information does not exist. For these protocols, the tradi-
tional way of determining a speciﬁcation involves a sig-
niﬁcant amount of manual analysis. Obviously, this is a
painful and time-consuming task that can only be justiﬁed
for very popular protocols such as SMB [27].
To address the limitations of manual protocol analysis,
automatic protocol reverse engineering techniques have
been proposed. The goal of these techniques is to auto-
matically generate the speciﬁcation of an application-level
protocol, given as input one of two different sources: The
ﬁrst source is the application program that implements a
particular protocol. So far, researchers have proposed a
static analysis approach that takes as input a binary pro-
gram and outputs the set of inputs that this program ac-
cepts [21]. Beside the fact that it is undecidable to statically
determine the complete set of inputs for a program, this ap-
proach also suffers from signiﬁcant scalability issues. As
a result, in their paper [21], the authors were only able to
extract the protocol for very simple and small prototype
applications that they themselves developed.
The second source of input for automatic protocol re-
verse engineering systems is network trafﬁc. More pre-
cisely, a number of systems [9, 10, 16, 17] have been pro-
posed that analyze network traces generated by recording
the communication between a client and a server. To this
end, the network traces are examined for the occurrence of
common structures or bytes that indicate a special meaning
for the protocol. While experiments have shown that these
systems are able to analyze real-world protocols, their pre-
cision is often limited. Because of the lack of information
that is present in network traces, messages of the same type
are sometimes considered different, and data artifacts are
falsely recognized as being protocol keywords.
In this paper, we present a novel technique for automatic
protocol reverse engineering that aims to combine the pre-
cision of systems that analyze application programs with
the scalability of systems that examine message instances
in network trafﬁc. The basic idea of our approach is to
dynamically monitor the application when it is processing
protocol messages. That is, we observe how a program is
processing protocol messages that it receives. We believe
that our focus on the analysis of the application is reason-
able because the program itself encodes the protocol and
represents the authoritative speciﬁcation of the inputs that
it can accept.
Our proposed system operates directly on binary pro-
grams. The analysis works by monitoring an application
that accepts network input (e.g., a server) while using an-
other program (e.g., a client) to send messages to this ap-
plication. We use dynamic taint analysis to mark the input
data and track how the monitored application propagates
and processes this data. Based on the ways in which tainted
data is used and manipulated, we extract a speciﬁcation of
the received message.
In a second step, the information
obtained from several, individual messages is combined to
determine a protocol speciﬁcation for a particular type of
message. Finally, this speciﬁcation is output as a gram-
mar that we use to generate parsing code. In addition, the
speciﬁcation is augmented with automatically generated,
semantic information that provides a human analyst with
insight into the meaning of different parts of a message.
For our experiments, we analyzed large server programs
(such as apache or samba) that implement complex,
real-world protocols such as HTTP, DNS, or NFS. Our re-
sults demonstrate that we can generate accurate speciﬁca-
tions for different messages types such as HTTP GET re-
quests and DNS queries.
The contributions of this paper are the following:
• We present a novel approach for the automated ex-
traction of protocol information. To this end, we dy-
namically monitor the execution of an application and
analyze how it processes messages that it receives.
• We present techniques to automatically split a single
message into different protocol ﬁelds. Also, we show
how information for individual messages can be com-
bined to obtain a more general and abstract format
speciﬁcation.
• We applied our techniques to a set of real-world server
applications that implement complex protocols such
as HTTP, DNS, SMTP, SMB, and NFS. Our results
show that we can automatically generate speciﬁca-
tions that can be used to parse messages of certain
types.
2 System design
Automatic protocol reverse engineering is a complex
and difﬁcult problem. In the following section, we intro-
duce the problem domain and discuss the speciﬁc problems
that our techniques address. Then, we provide a high-level
overview of the workings of our system.
2.1 Problem scope
In [9], the authors introduce a terminology for common
protocol idioms that allow a general discussion of the prob-
lem of protocol reverse engineering. In particular, the au-
thors observe that most application protocols have a notion
of an application session, which allows two hosts to ac-
complish a speciﬁc task. An application session consists of
a series of individual messages. These messages can have
different types. Each message type is deﬁned by a cer-
tain message format speciﬁcation. A message format spec-
iﬁes a number of ﬁelds, for example, length ﬁelds, cookies,
keywords, or endpoint addresses (such as IP addresses and
ports). The structure of the whole application session is
determined by the protocol state machine, which speciﬁes
the order in which messages of different types can be sent.
Using that terminology, we observe that automatic pro-
tocol reverse engineering can target different levels. In the
simplest case, the analysis only examines a single message.
Here, the goal of the reverse engineering process is to iden-
tify the different ﬁelds that appear in that message. A more
general approach considers a set of messages of a particu-
lar type. An analysis process at this level would produce
a message format speciﬁcation that can include optional
ﬁelds or alternative structures for parts of the message. Fi-
nally, in the most general case, the analysis process oper-
ates on complete application sessions. In this case, it is not
sufﬁcient to only extract message format speciﬁcations, but
also to identify the protocol state machine. Moreover, be-
fore individual message formats can be extracted, it is nec-
essary to distinguish between messages of different types.
While it would be very desirable to have a system that
can work at the application session level, we leave this for
future work. In this paper, we focus on the goal of deter-
mining the format speciﬁcation of a certain type of mes-
sage in a completely automated fashion. That is, we pro-
pose to analyze a set of messages of one type, and extract
the format speciﬁcation for this message type. We believe
that automatically ﬁnding message format speciﬁcations is
an ambitious goal that is valuable in practice. For exam-
ple, it might be sufﬁcient for a fuzzer or an intrusion de-
tection system to understand only messages of a particu-
lar type. Also, extracting message formats is a necessary
building block for a system that performs complete pro-
tocol recovery. Finally, we augment the message format
with additional semantic information that provides useful
information for a human analysts about the way in which
an application uses the data that it receives (e.g., indication
that a certain message ﬁeld is used to hold the name of a
ﬁle that is accessed).
2.2 System overview
The goal of our system is to extract the format speciﬁca-
tion for a certain type of message of an unknown protocol.
To this end, the system executes a number of steps:
Dynamic data tainting.
In the ﬁrst step, a number of
messages are sent to an application that “understands” the
protocol that we are interested in (e.g., a server program
implementing a particular network protocol). This appli-
cation is instrumented, and all instructions that operate on
input data read from protocol messages are recorded. More
precisely, we use dynamic data tainting to track the bytes
of the messages that are read by the application. Similar
to previous systems that use tainting [5, 7, 8], each input
byte receives a unique label. Then, we keep track of each
labeled value as the program execution progresses. As a
result of the dynamic data tainting process, an execution
trace is produced for each message. This trace contains
all operations that have one or more tainted operands. For
more details on dynamic data tainting, please refer to Ap-
pendix B.
Analysis of individual messages.
In the next step, our
system analyzes the individual execution traces that are
produced for each message. The goal is to leverage the
information derived from the way in which the applica-
tion processes its input to identify the constituent parts of
a message. Many protocols make use of delimiter bytes
to group the sequence of input bytes into individual ﬁelds.
Others use length ﬁelds to indicate the length of a target
ﬁeld.
In addition, protocols can also deﬁne a sequence
of ﬁxed-length ﬁelds. In this case, neither delimiters nor
length ﬁelds are necessary for the receiver to correctly
parse a message. Of course, a protocol can make use of
both delimiters and length ﬁelds. Moreover, ﬁelds can be
nested.
By observing how the application processes the mes-
sage, we attempt to identify delimiters and length ﬁelds,
as well as the structure they impose onto the message.
Furthermore, we extract semantic information for differ-
ent ﬁelds. For example, we can determine when a ﬁeld
contains a protocol keyword, is used to access a ﬁle in the
ﬁle system, or is directly echoed back to the party that the
application is communicating with. Our techniques to ana-
lyze single message instances are discussed in detail in the
following Section 3.
Multiple messages and message format speciﬁcation.
In the third and last step, we combine the information de-
rived for messages of one type to generate a more gen-
eral format speciﬁcation. The reason for considering mul-
tiple messages is that it is possible that different messages
of the same type do not always contain exactly the same
number of ﬁelds in exactly the same order. To generate
a general and comprehensive message format speciﬁca-
tion, the differences in the individual messages have to
be “abstracted away.” For this, we compare the results
for multiple runs, using an alignment algorithm from the
bio-informatics community. The goal is to align similar
ﬁelds, thereby identifying alternative parts that vary be-
tween messages, optional ﬁelds, or ﬁelds that appear a dif-
ferent number of times. The result of the alignment step
is a more general speciﬁcation, which would not be possi-
ble to infer from a single message only. This speciﬁcation
is then output as a regular expression that serves as input
for a protocol parser. A more detailed explanation of this
process is given in Section 4.
3 Analysis of a single message
When the monitored application has processed a mes-
sage, the ﬁrst task of our system is to use the execution
trace produced by the dynamic taint analysis to split this
message into its components, or ﬁelds. Most network pro-
tocols use delimiters or length ﬁelds (or a combination of
both) to impose a structure onto the sequence of bytes that
make up the input message. Thus, we have developed two
techniques to locate such delimiter ﬁelds and length ﬁelds
in the message. These techniques are discussed in the two
following subsections. Once a message is decomposed, the
next step is to derive additional semantic information for
the ﬁelds (discussed in Section 3.3).
3.1 Finding delimiters
A delimiter is a byte (sometimes also a sequence of
bytes) with a known value that indicates the end of a pro-
tocol ﬁeld. For example, consider the HTTP GET request
that is shown in Figure 1 below. In this example, the new-
line delimiter ‘\r\n’ divides the GET request into two
lines. Moreover, the space character is used to split the
three components of the ﬁrst line (GET method, requested
resource, and HTTP version). When parsing a message,
the application searches each consecutive byte in the input
stream for the occurrence of a byte with the known delim-
iter value. Once this byte is found, the application recog-
nizes that the end of a ﬁeld is reached, and can continue
accordingly. This observation directly translates into our
approach to identify delimiters.
GET /index.html HTTP/1.1\r\n
Host: 127.0.0.1\r\n\r\n
Figure 1. HTTP GET request.
To ﬁnd delimiters, we examine the execution trace of
the application for operations that compare a tainted input
byte with an untainted value. For each comparison opera-
tion, we record the location of the input byte in the mes-
sage (based on its unique label), as well as the value of
the operand. Based on this information, we can create, for
each of the 256 possible byte values (single characters), a
list that stores the labels that this character was compared
against. In other words, we record, for each possible de-
limiter character, the positions of the bytes in the message
that it was compared against. For example, assume that we
observe that the application compares the ﬁrst three bytes
of the message against character ’a’, and the fourth byte
against ’b’. This fact is recorded by adding the labels 0,
1, and 2 to the list that corresponds to character ’a’, and
by adding label 3 to the list for ’b’. Note that it is possi-
ble for the same input byte to be compared against several
characters. In this case, the same label is added to multiple
lists.
Once all comparison operations are recorded, we tra-
verse each list and check it for the occurrence of consec-
utive labels. Consecutive labels are merged into intervals.
Labels that are not part of any interval are discarded. The
assumption is that an application has to scan at least two
consecutive input bytes for a particular value when this
value is a delimiter. This is because a delimited ﬁeld should
be at least one byte long, and the delimiter itself occupies a
second position. In the example introduced in the previous
paragraph, we would create the interval [0,2] for character