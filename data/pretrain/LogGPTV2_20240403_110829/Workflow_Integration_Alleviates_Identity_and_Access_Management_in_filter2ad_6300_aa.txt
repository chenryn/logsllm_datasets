# Workflow Integration Alleviates Identity and Access Management in Serverless Computing

**Authors:**
- Arnav Sankaran, University of Illinois at Urbana-Champaign
- Pubali Datta, University of Illinois at Urbana-Champaign
- Adam Bates, University of Illinois at Urbana-Champaign

## Abstract

As serverless computing continues to revolutionize the design and deployment of web services, it has become an increasingly attractive target for attackers. These adversaries are developing novel tactics to circumvent the ephemeral nature of serverless functions, exploiting container reuse optimizations and achieving lateral movement by "living off the land" provided by legitimate serverless workflows. Unfortunately, the traditional security controls currently offered by cloud providers are inadequate to counter these new threats.

In this work, we propose **will.iam**, a workflow-aware access control model and reference monitor that satisfies the functional requirements of the serverless computing paradigm. will.iam encodes the protection state of a serverless application as a permissions graph, describing the permissible transitions of its workflows. It associates web requests with a permissions set at the point of ingress based on a graph-based labeling state. By proactively enforcing the permissions requirements of downstream workflow components, will.iam avoids the costs of partially processing unauthorized requests and reduces the attack surface of the application.

We implement the will.iam framework in Go and evaluate its performance against the well-established Nordstrom “Hello, Retail!” application. Our results show that will.iam imposes minimal overhead, averaging 0.51% across representative workflows, but dramatically improves performance when handling unauthorized requests (e.g., DDoS attacks) compared to past solutions. Thus, will.iam demonstrates an effective and practical alternative for authorization in the serverless paradigm.

## CCS Concepts
- Security and privacy → Distributed systems security; Information flow control; Access control.

## Keywords
- Serverless Computing, Access Control, Information Flow Control

### Introduction

Projected to exceed $8 billion per year by 2021, serverless computing has experienced rapid growth and is expected to become the dominant pattern for cloud computing. Also known as Function-as-a-Service (FaaS), serverless computing abstracts away the need to manage physical hardware and the lifecycle of virtual machines. In serverless, the customer is no longer responsible for launching or tearing down virtual machines, provisioning virtual computer clusters, or managing software below the application level. This is achieved through the decomposition of applications into small, discrete, stateless microservices that can be orchestrated into high-level workflows. As a result, developers can focus on the core logic of their application, eliminating the burdens of infrastructure management while enabling rapid prototyping of services.

While serverless is often credited as being intrinsically more secure than prior cloud paradigms, in reality, most common cloud and web insecurities continue to fester. A large-scale analysis of open-source serverless projects revealed that upwards of 20% contained critical vulnerabilities or misconfigurations. Numerous event injection techniques have been demonstrated, and challenges related to cross-tenant side-channels remain in the ecosystem. Despite the stateless and ephemeral nature of serverless functions, attackers have proven capable of surmounting these obstacles. For example, they have exploited the widely used "warm container" reuse optimization, which caches recently invoked function containers in server memory, to transport toolkits into the application and establish quasi-persistence.

The primary mechanisms made available by cloud providers for mitigating these threats are role-based access controls (RBAC), known as Identity and Access Management (IAM) roles in popular services like Amazon Lambda. Using IAM, cloud customers can statically assign each function to a role associated with a set of permissions for accessing other functions, datastores, or the open Internet. However, static RBAC alone is insufficient. Not only are IAM roles often misconfigured, but even when correctly defined, attackers can leverage legitimate function transitions to move laterally through the application. This fundamental mismatch between the abstractions of application developers (inter-function workflows) and the context of individual function transitions leads to unbounded attack opportunities.

In this work, we reconceptualize IAM roles as dynamic, efficient, and workflow-sensitive. We present will.iam, an access control framework that performs authentication and role assignment to web requests at their point of ingress. By carrying this role assignment forward from function to function, will.iam bounds attackers to the permissions associated with a legitimate workflow, significantly reducing the attack surface of the serverless application. will.iam security policies are defined as a directed graph representation of the application’s workflows, with terminal nodes encoding permission requirements for traversing the workflow. This allows for the pre-computation of end-to-end permissions, enabling proactive rejection of requests that cannot satisfy downstream permission requirements.

### Contributions

- **Workflow-Sensitive Access Control:** We present the design of a novel access control model for serverless computing that mediates inter-function information flow as requests are processed. Our approach follows the same design principles as serverless applications while integrating with the notion of IAM-style role-based access controls, avoiding the need for a dramatic reconceptualization of security on cloud platforms.
- **The will.iam Framework:** We implement our access control model for the popular OpenFaaS serverless platform. As a case study, we define and analyze a complete security policy for the canonical “Hello, Retail!” reference application. Our code, policies, and datasets will be made publicly available upon publication.
- **Performance Evaluation:** We rigorously evaluate the performance of will.iam compared to vanilla OpenFaaS and two baseline access control systems from related work (Trapeze and Valve). Our results show that will.iam has much less overhead, with an average workload overhead of just 0.51% compared to vanilla OpenFaaS. Additionally, our performance optimization for proactive authorization of requests reduces wasted computation by 22% when considering a traffic profile with 30% unauthorized requests.

### Background

Commercialized cloud computing began in 2006 with the release of Amazon Elastic Compute Cloud (EC2), providing enterprises with access to unlimited backend infrastructure without the burden of managing it. More recently, serverless computing platforms have emerged to further abstract away the need to manage the software stack running below the application layer. This enables cloud tenants to focus on developing the business logic of their applications while the cloud provider handles load-balancing, auto-scaling of resources, and other management tasks. Tenants are billed according to resource usage (CPU, memory, and network) when their functions are executed.

Serverless application developers implement the business logic as a set of functions that can be chained together to form task-specific workflows. These functions often read or write private data stored in the cloud infrastructure to achieve their operational goals. This necessitates a robust access control mechanism to determine if a function invocation request is properly authenticated and has the required permissions to access a piece of data. Cloud platforms offer access control techniques, such as AWS Identity and Access Management (IAM), which implement traditional role-based access control (RBAC) and attribute-based access control (ABAC) methods. In serverless platforms, roles are attached to functions, allowing them to access other cloud resources according to the access policy and permissions attached to the role. The roles and permissions should be defined to grant the least privilege necessary for a function's operations.

For a traditional monolithic application deployed on the cloud, a single IAM authentication per request suffices to verify the entire application’s adherence to the access policy. However, in a serverless setting, each component function must perform authentication and authorization for every request. This quickly becomes infeasible in a high-throughput production-level application consisting of numerous atomic functions, each requiring various permissions to perform specific data operations. This leads to increased complexity of IAM policies, additional network latency for authentication, and higher billing costs for the cloud tenants. The resulting complex policies are often riddled with misconfigurations and create greater opportunities for attackers. Moreover, attackers can leverage legitimate function transitions to move laterally through the application since each function activation is authorized in isolation, without considering the historic context of the current request. Currently, static function-level IAM policies in serverless platforms do not offer an ideal security-performance trade-off for tenants.

### Motivation

In this section, we describe the limitations of existing IAM policies in the context of serverless computing using the example application, Hello, Retail! [88], an open-source event-driven retail application from Nordstrom Technology. A simplified conceptual architectural diagram of Hello, Retail! is shown in Figure 1.

The application consists of two types of resources: serverless functions and datastores. Functions can be triggered by explicit HTTP requests to an API gateway, other functions, or datastore events (e.g., creation of a new object in a datastore). Functions that expose public REST endpoints through the API gateway are designated as Application Ingress Points and can be invoked through HTTP requests originating from the open Internet. Other functions should only be invoked from another function or a datastore event. For example, f1, f2, f6, f9, and f10 are the application ingress points in this scenario. The internal function f3 can only be executed with necessary permissions, which are associated with the IAM role assigned to f2, and thus cannot be invoked directly through HTTP. Function f7 is invoked by new object creation in datastore D2 and is the only function in Figure 1 that has a datastore event trigger. The functions communicate with datastores D1, D2, D3, and D4 with appropriate permissions to complete their tasks.

The ingress points mark the beginning of different workflows in the application. The five primary workflows are described in Table 1. The → denotes a function invocation. Required datastore communications are also listed.

#### Figure 1: A Reference Architecture of the Serverless Application "Hello, Retail!"

#### Table 1: Summary of Primary Workflows in Hello, Retail!

| Description | Workflow |
|-------------|----------|
| Registration of a photographer in the photographer registry | f1(WD1) → f2(WD3) |
| Creation of a product in the catalog and assigning a photographer to submit a photo of the product | f3(RD1) → f4(WD1) → f5 |
| Receiving a photo from the photographer and updating the assignment status | f6(WD2) → f7 → f8(WD1) |
| Purchasing a product listed in the catalog | f9 → f10(RD2; RD3) → f11(RD3) → f12(RD4) → f13 |
| Catalog browsing | f10(RD2; RD3) |

This example illustrates the need for a more dynamic and workflow-sensitive access control mechanism in serverless computing, which is the motivation behind the development of will.iam.