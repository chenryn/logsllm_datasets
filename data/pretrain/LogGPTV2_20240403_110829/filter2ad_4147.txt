# Title: Supporting Application-Specific In-Network Processing in Data Centres

## Authors:
- Luo Mai, Imperial College London
- Lukas Rupprecht, Imperial College London
- Paolo Costa, Microsoft Research
- Matteo Migliavacca, University of Kent
- Peter R. Pietzuch, Imperial College London
- Alexander L. Wolf, Imperial College London

## Contact Information:
- Luo Mai: [EMAIL]
- Matteo Migliavacca: [EMAIL]
- Lukas Rupprecht: [EMAIL]
- Peter Pietzuch: [EMAIL]
- Paolo Costa: [EMAIL]
- Alexander L. Wolf: [EMAIL]

## Categories and Subject Descriptors
C.2.1 [Network Architecture and Design]: Network Communications; Distributed Networks

## General Terms
Design, Performance

## Keywords
Data Centres, In-network Processing, Network-as-a-Service

## 1. Introduction
Modern data centers (DCs) host a variety of distributed applications that process large datasets, such as Google MapReduce and Microsoft Scope, or respond to user requests for online services like search engines, distributed data stores, and interactive query systems. These applications manage to handle large volumes of data and high numbers of concurrent requests through "scale out" — distributing computation across a large number of machines.

Typically, these applications follow a partition-aggregate paradigm: 
1. **Partition Phase**: A master node partitions a job or user request into sub-tasks, which are scheduled to different worker nodes for concurrent execution. Each worker processes a subset of the data and generates partial results locally.
2. **Aggregate Phase**: The partial results generated by the workers are collected and aggregated by one or more reducers.

During the aggregation phase, many-to-few network flows are generated, which are challenging to support with traditional infrastructures due to network over-subscription in the core (ratios of 1:20 or higher are not uncommon) and limited bandwidth at the end hosts (typically 1 Gbps or 10 Gbps). Recent studies on real-world clusters show that a significant portion of job time is spent on network activity. For example, Facebook's traces indicate that 42% of MapReduce jobs spend more than 50% of their time in the shuffle phase.

Several solutions have been proposed to improve the performance of network-bound applications in DCs. New DC network topologies offer full bisection bandwidth but require complex mechanisms to fully exploit this bandwidth. However, their performance is still limited by the edge bandwidth. Other proposals focus on reducing bandwidth usage by employing overlay networks to distribute data and perform partial aggregation. This approach, however, requires applications to reverse-engineer the physical network topology, which is difficult even with full network visibility.

Recently, the availability of low-cost multi-core CPUs has renewed interest in software-based routers, which replace traditional switch and router operations with custom software implementations. We argue that the flexibility provided by these implementations should be offered to tenants to implement part of the application logic in the network. This approach, referred to as "Network-as-a-Service" (NaaS), exposes networking as a service to the application, enabling in-network data aggregation and content-based routing to improve network usage and mitigate bandwidth scarcity.

By modifying packet content on-path, tenants can implement customized services that are specific to their applications, rather than being application-agnostic. For instance, batch processing jobs like MapReduce can benefit from aggregating mapping results on paths towards reducers, improving processing throughput. Data-intensive web applications, such as distributed search engines, can reduce network traffic by moving the aggregation of partial query results closer to data sources instead of frontend servers.

## 2. On-Going Work
As a first step in this direction, we have developed a general-purpose software platform called NETAGG, which allows users to deploy in-network data aggregation services for partition/aggregate applications. NETAGG leverages the observation that many DC applications can aggregate data more efficiently without introducing bottlenecks at edge machines if they take the network topology into account and aggregate in-network, e.g., along network paths. This allows the aggregation phase to utilize higher link bandwidth available at the upper tiers of network topologies (aggregation and core switches), thereby reducing overall network traffic and improving application performance.

NETAGG provides a programming interface to execute multiple application-specific aggregation functions, allowing it to accommodate multiple applications conducting in-network aggregation concurrently. It schedules the processing of data belonging to different applications at NETAGG boxes, prioritizing latency-sensitive applications such as online services over throughput-sensitive batch data processing applications.

So far, we have enabled NETAGG to improve the throughput of the Apache Hadoop map/reduce framework and the Apache Solr distributed text search engine. For evaluation, NETAGG was deployed on a testbed consisting of a 16-core 2.9 GHz Xeon machine (the NETAGG box) connected to a ToR switch via a 10 Gbps link and 10 edge machines connected to the switch via 1 Gbps links. Evaluation results show that network traffic is significantly reduced, leading to improved application goodput in both scenarios.

## 3. References
[1] Apache Solr. http://lucene.apache.org/solr.
[2] AL-FARES, M., RADHAKRISHNAN, S., RAGHAVAN, B., HUANG, N., AND VAHDAT, A. Hedera: Dynamic Flow Scheduling for Data Center Networks. In NSDI (2010).
[3] CARZANIGA, A., AND WOLF, A. L. Forwarding in a Content-Based Network. In SIGCOMM (2003).
[4] CHOWDHURY, M., ZAHARIA, M., MA, J., JORDAN, M. I., AND STOICA, I. Managing Data Transfers in Computer Clusters with Orchestra. In SIGCOMM (2011).
[5] COSTA, P., DONNELLY, A., ROWSTRON, A., AND O’SHEA, G. Camdoop: Exploiting In-network Aggregation for Big Data Applications. In NSDI (2012).
[6] COSTA, P., MIGLIAVACCA, M., PIETZUCH, P., AND WOLF, A. L. NaaS: Network-as-a-Service in the Cloud. In Hot-ICE (2012).
[7] DOBRESCU, M., EGI, N., ARGYRAKI, K., CHUN, B.-G., FALL, K., IANNACCONE, G., KNIES, A., MANESH, M., AND RATNASAMY, S. RouteBricks: Exploiting Parallelism To Scale Software Routers. In SOSP (2009).
[8] GREENBERG, A., HAMILTON, J. R., JAIN, N., KANDULA, S., KIM, C., LAHIRI, P., MALTZ, D. A., PATEL, P., AND SENGUPTA, S. VL2: A Scalable and Flexible Data Center Network. In SIGCOMM (2009).
[9] GUO, C., LU, G., LI, D., WU, H., ZHANG, X., SHI, Y., TIAN, C., ZHANG, Y., AND LU, S. BCube: A High Performance, Server-centric Network Architecture for Modular Data Centers. In SIGCOMM (2009).
[10] HAN, S., JANG, K., PARK, K., AND MOON, S. PacketShader: A GPU-Accelerated Software Router. In SIGCOMM (2010).
[11] LOGOTHETIS, D., TREZZO, C., WEBB, K. C., AND YOCUM, K. In-situ MapReduce for Log Processing. In USENIX ATC (2011).
[12] MELNIK, S., GUBAREV, A., LONG, J. J., ROMER, G., SHIVAKUMAR, S., TOLTON, M., AND VASSILAKIS, T. Dremel: Interactive Analysis of Web-scale Datasets. In VLDB (2010).
[13] NISHTALA, R., FUGAL, H., GRIMM, S., KWIATKOWSKI, M., LEE, H., LI, H. C., MCELROY, R., PALECZNY, M., PEEK, D., SAAB, P., STAFFORD, D., TUNG, T., AND VENKATARAMANI, V. Scaling Memcached at Facebook. In NSDI (2013).
[14] RAICIU, C., BARRE, S., PLUNTKE, C., GREENHALGH, A., WISCHIK, D., AND HANDLEY, M. Improving Datacenter Performance and Robustness with Multipath TCP. In SIGCOMM (2011).

## Figure 1: An Example Using NETAGG in DC Applications
In our sample setup, a ToR switch is connected to machines in a rack via 1 Gbps links and a collocated NETAGG box via a 10 Gbps link. The master node receives user requests from a client application and dispatches sub-requests to worker machines that index data. The worker responses can generate an aggregation flow back to the master of up to 3 Gbps, but are capped at 1 Gbps due to the over-subscribed edge link. By using NETAGG, the flow is redirected to the NETAGG box through the 10 Gbps link, and only the smaller aggregation results are sent back to the master. This supports the full aggregation bandwidth of the workers and removes the bottleneck to the master.

The design of NETAGG includes the following aspects:
1. **Deployment Cost**: To foster the adoption of in-network aggregation, it should be realized with affordable changes to the DC networking hardware. It should be compatible with existing DC topologies and adaptable to incremental deployment. Since programmable switches are expensive and provide low-level interfaces, we use a software-only approach to custom networking, developing a dedicated in-network machine (NETAGG box) where arbitrary aggregation functions can be easily deployed by users. These boxes are commodity machines connected via high-bandwidth links to switches at the upper levels of a DC network topology. Multiple cooperating NETAGG boxes can form an aggregation tree.
2. **Application Transparency**: A wide range of DC applications should benefit from in-network aggregation without substantial modifications. NETAGG deploys shim-layers at edge machines to transparently intercept application traffic at the socket layer, redirecting it to and processing it by NETAGG boxes.
3. **Aggregation Performance**: To improve application performance, in-network aggregation must process data at rates higher than the link capacity provided by edge machines. For example, in a typical DC network with 1 Gbps edge links, the application can gain performance when the aggregated incoming throughput to a NETAGG box exceeds 1 Gbps. To achieve this, NETAGG minimizes the functionality executed on NETAGG boxes. Shim layers transcode data from application-specific protocols to an efficient binary representation to reduce parsing overhead at NETAGG boxes.