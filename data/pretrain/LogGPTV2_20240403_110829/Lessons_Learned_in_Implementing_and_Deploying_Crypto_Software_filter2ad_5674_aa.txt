title:Lessons Learned in Implementing and Deploying Crypto Software
author:Peter Gutmann
USENIX Association
Proceedings of the
11th USENIX Security
Symposium
San Francisco, California, USA
August 5-9, 2002
Â© 2002 by The USENIX Association
Phone: 1 510 528 8649
FAX: 1 510 548 5738
THE ADVANCED COMPUTING SYSTEMS ASSOCIATION
All Rights Reserved
Email: PI:EMAIL
For more information about the USENIX Association:
WWW: http://www.usenix.org
Rights to individual papers remain with the author or the author's employer.
 Permission is granted for noncommercial reproduction of the work for educational or research purposes.
This copyright notice must be included in the reproduced paper. USENIX acknowledges all trademarks herein.
Lessons Learned in Implementing and Deploying Crypto Software
Peter Gutmann
University of Auckland
Abstract
Although  the  basic  building  blocks  for  working  with
strong encryption have become fairly widespread in the
last few years, experience has shown that implementers
frequently misuse them in a manner which voids their
security  properties.    At  least  some  of  the  blame  lies
with  the  tools  themselves,  which  often  make  it
unnecessarily  easy  to  get  things  wrong.    Just  as  no
chainsaw  manufacturer  would  think  of  producing  a
model without a finger-guard and cutoff mechanism, so
security  software  designers  need  to  consider  safety
features which will keep users from injuring themselves
or  others.    This  paper  examines  some  of  the  more
common  problem  areas  which  exist  in  crypto  security
software,  and  provides  a  series  of  design  guidelines
which  can  help  minimise  damage  due  to  (mis-)use  by
inexperienced  users.    These  issues  are  taken  from
extensive  real-world  experience  with  users  of  security
software,  and  represent  areas  which  frequently  cause
problems when the software is employed in practice.
1. Introduction
In  the  last  five  years  or  so  the  basic  tools  for  strong
encryption  have  become  fairly  widespread,  gradually
displacing the snake oil products which they had shared
the environment with until then.  As a result, it(cid:146)s now
fairly  easy  to  obtain  software  which  contains  well-
established,  strong  algorithms  such  as  triple  DES  and
RSA instead of pseudo one-time-pads.  Unfortunately,
this hasn(cid:146)t solved the snake oil problem, but has merely
relocated it elsewhere.
The determined programmer can produce
snake oil using any crypto tools.
What  makes  the  new  generation  of  dubious  crypto
products  more  problematic  than  their  predecessors  is
that the obvious danger signs which allowed bad crypto
to  be  quickly  weeded  out  are  no  longer  present.    A
proprietary,  patent-pending,  military-strength,  million-
bit-key, one-time pad built from encrypted prime cycle
wheels is a sure warning sign to stay well clear, but a
file encryptor which uses Blowfish with a 128-bit key
seems  perfectly  safe  until  further  analysis  reveals  that
the key is obtained from an MD5 hash of an uppercase-
only 8-character ASCII password.  This type of second-
generation  snake  oil  crypto,  which  looks  like  the  real
thing  but  isn(cid:146)t,  could  be  referred  to  as  naugahyde
crypto,  with  an  appropriately  similar  type  of
relationship to the real thing.
Most  crypto  software  is  written  with  the  assumption
that the user knows what they(cid:146)re doing, and will choose
the most appropriate algorithm and mode of operation,
carefully  manage  key  generation  and  secure  key
storage,  employ  the  crypto  in  a  suitably  safe  manner,
and  do  a  great  many  other  things  which  require  fairly
detailed  crypto  knowledge.    However,  since  most
implementers  are  everyday  programmers  whose
motivation  for  working  with  crypto  is  defined  by  (cid:147)the
boss said do it(cid:148), the inevitable result is the creation of
products  with  genuine  naugahyde  crypto.    Sometimes
this  is  discovered  (for  example  when  encryption  keys
are  generated  from  the  process  ID  and  time,  or  when
the  RC4  keystream  is  re-used  multiple  times  so  the
plaintext  can  be  recovered  with  a  simple  XOR),  but
more frequently it isn(cid:146)t, so that products providing only
illusory  security  may  be  deployed  and  used  for  years
without anyone being any the wiser.
This paper looks at some of the ways in which crypto
software  developers  and  providers  can  work  to  avoid
creating  and  deploying  software  which  can  be  used  to
create  naugahyde  crypto.    Much  of  the  experience
presented  here  comes  from  developing  and  supporting
the  open-source  cryptlib  toolkit  [1][2],  which  has
provided the author with a wealth of information on the
ways in which crypto software is typically misused, and
the principal areas in which users experience problems.
Additional  feedback  was  provided  from  users  and
developers  involved  with  other  open-source  crypto
efforts.
All  of  the  events  reported  here  are  from  real
experiences with users, although the details have been
obscured and anonymised, particularly where the users
in  question  have  more  lawyers  than  the  author(cid:146)s
University  has  staff.    In  addition  a  few  of  the  more
interesting  stories  were  excluded,  but  are  referred  to
indirectly in the text (although no-one would have been
able  to  identify  the  organisations  involved,  it  was  felt
that having the event officially documented rather than
existing only in the memory of a few implementers was
too much of a legal liability).  Although there are less
references to sources than the author usually includes in
his work, the reader should rest assured that all of the
events mentioned here are real, and it(cid:146)s almost certain
that they have either used, or been a part of the use of,
one or more of the products which are not quite referred
to.
2. Existing Work
There exists very little published research on the topic
of  proactively  ensuring  that  crypto  is  used  in  a  secure
manner,  as  opposed  to  patching  programs  up  after  a
problem is found.  Most authors are content to present
the algorithms and mechanisms and leave the rest to the
implementer.    An  earlier  work  on  why  cryptosystems
fail concentrated mostly on banking security [3][4], but
did make the prophetic prediction that as implementers
working  with  crypto  products  (cid:147)lack  skills  at  security
integration  and  management,  they  will  go  on  to  build
systems with holes(cid:148).
Another  paper  examined  user  interface  problems  in
encryption  software  [5],  an  area  which  badly  needs
further work by HCI researchers.  Finally, the author of
a  widely-used  book  on  crypto  went  on  to  write  a
followup  work  designed  to  address  the  problem  that
(cid:147)the world was full of bad security systems designed by
people who read [his first book](cid:148) [6].  Like the author
of  this  paper,  he  found  that  (cid:147)the  weak  points  had
nothing to do with mathematics [...] Beautiful pieces of
mathematics  were  made  irrelevant  through  bad
programming(cid:148).  The followup work examines security
in  a  very  general-purpose  manner  as  a  process  rather
than a product, while this paper limits itself to trying to
address  the  most  commonly-made  errors  which  occur
when non-cryptographers (mis-)apply crypto.
In  addition  to  these  works  there  exist  a  number  of
general-purpose  references  covering  security  issues
which  can  occur  during  application  design  and
implementation  [7][8][9].    These  are  targeted  at
application  developers  and  are  intended  to  cover  (and
hopefully  eliminate)  common  application  security
problems  such  as  buffer  overflows,  race  conditions,
elevation of privileges, access control issues, and so on.
This  work  in  contrast  looks  specifically  at  problems
which  occur  when  end  users  (mis-)use  security
software,  and  suggests  design  guidelines  which  can
help combat such misuse.
3. Crypto Software Problems and Solutions
There  are  many  ways  in  which  crypto  and  security
software can be misused.  The main body of this paper
covers  some  of  the  more  common  problem  areas,
providing  examples  of  misuse  and  suggesting  (if
possible)  solutions  which  may  be  adopted  by
developers of the security software to help minimise the
potential for problems.  While there is no universal fix
for all problems (and indeed some of them have a social
or economic basis which can(cid:146)t be easily solved through
the  application  of  technology),  it  is  hoped  that  the
guidelines presented here will both alert developers to
the existence of certain problem areas and provide some
assistance in combating them.
3.1 Private Keys Aren(cid:146)t
One of the principal design features of cryptlib is that it
never  exposes  private  keys  to  outside  access.    The
single  most  frequently-asked  cryptlib  question  is
therefore  (cid:147)How  do  I  export  private  keys  in  plaintext
form?(cid:148).    The  reasons  given  for  this  are  many  and
varied, and range from the logical ((cid:147)I want to generate a
test key for use with XYZ(cid:148)) to the dubious ((cid:147)We want
to share the same private key across all of our servers(cid:148))
through to the bizarre ((cid:147)I don(cid:146)t know, I just want to do
it(cid:148)).
In some cases the need to spread private keys around is
motivated  by  financial  concerns.    If  a  company  has
spent  $495  on  a  Verisign  certificate  which  was
downloaded  to  a  Windows  machine  then  they  won(cid:146)t
spend that much again for exactly the same thing in a
different format.  As a result, the private key is exported
from the Windows key store (from which any Windows
application can utilise it) into Netscape.  And OpenSSL.
And  BSAFE.    And  cryptlib  (although  cryptlib
deliberately  makes  it  rather  difficult  to  poke  keys  of
unknown  provenance  into  it).    Eventually,  every
encryption-enabled  application  on  the  system  has  a
copy of the key, and for good measure it may be spread
across  a  number  of  systems  for  use  by  different
developers or sysadmins.  Saving CA fees by re-using a
single  private  key  for  everything  seems  to  be  very
popular, particularly among Windows users.
The  amount  of  sharing  of  private  keys  across
applications and machines is truly frightening.  Mostly
this appears to occur because users don(cid:146)t understand the
value of the private key data, treating it as just another
piece  of  information  which  can  be  copied  across  to
wherever it(cid:146)s convenient.  For example a few years ago
a  company  had  developed  a  PGP-based  encrypted  file
transfer system for a large customer.  The system used a
2048-bit  private  key  which  was  stored  on  disk  in
plaintext  form,  since  the  software  was  run  as  a  batch
process and couldn(cid:146)t halt waiting for a password to be
entered.  One day the customer called to say that they(cid:146)d
lost  the  private  key  file,  and  could  the  company(cid:146)s
programmers  please  reconstruct  it  for  them.    This
caused some consternation at the company, until one of
the developers pointed out that there were copies of the
private key stored on a file server along with the source
code,  and  in  other  locations  with  the  application
binaries.    Further  investigation  revealed  that  the
developers  had  also  copied  it  to  their  own  machines
during  the  development  process  for  testing  purposes.
Some  of  these  machines  had  later  been  passed  on  to
new employees, with their original contents intact.  The
file server on which the development work was stored
had had its hard drives upgraded some time earlier, and
the old drives (with the key on them) had been put on a