correction capability at low retention age), the accumulated
read disturb errors are minimal when the block reaches a high
retention age. This makes it much less likely for read disturbs
to generate an uncorrectable error, thus leading to overall ﬂash
lifetime improvement.
To minimize the effect of read disturb, we propose to learn
the minimum pass-through voltage for each block, such that
all data within the block can be read correctly with ECC. Our
learning mechanism works online and is triggered on a daily
basis. Vpass Tuning can be fully implemented within the ﬂash
controller, and has two components:
1. It ﬁrst ﬁnds the size of the ECC margin M (i.e., the unused
correction capability within ECC) that can be exploited to
tolerate additional read errors for each block. In order to do
this, our mechanism discovers the page with approximately
the highest number of raw bit errors (Sec. 4.3).
2. Once it knows the available margin M, our mechanism
calibrates the pass-through voltage Vpass on a per-block
basis to ﬁnd the lowest value of Vpass that introduces no
more than M additional raw errors (Sec. 4.4).
4.3. Identifying the Available ECC Margin
To calculate the available ECC margin M, our mechanism
must ﬁrst approximately discover the page with the highest
error count. While ﬁnding the page in each block with the
exact highest error count can be costly if performed daily, we
can instead statically identify, at manufacture time, a page in
each block that will approximately have the greatest number
of errors. Flash devices generally exhibit two types of errors:
those based on dynamic factors (e.g., retention, read disturb)
and those based on static factors (e.g., process variation). Within
a block, there is likely to be little variation in the number of
errors based on dynamic factors, as all pages in the block are of
similar retention age and experience similar read disturb counts
and P/E cycles. Additionally, modern ﬂash devices randomize
their data internally to improve endurance and encrypt their
contents [9,18], which leads to the stored data values across the
pages to be similar. Therefore, the mitigation mechanism can
be simpliﬁed to identify the page in each block that exhibits
the greatest number of errors occurring due to static factors
(as these factors remain relatively constant over the device
lifetime), which we call the predicted worst-case page.
Fig. 13 provides an exaggerated illustration of how this
unused ECC capability changes over the retention period (i.e.,
the refresh interval). At
the start of each retention period,
there are no retention errors or read disturb errors, as the
data has just been restored. In these cases, the large unused
ECC capability allows us to design an aggressive read disturb
mitigation mechanism, as we can safely introduce correctable
errors. Thanks to read disturb mitigation, we can reduce the
effect of each individual read disturb, thus lowering the total
number of read disturb errors accumulated by the end of the
refresh interval. This reduction in read disturb error count leads
to lower error count peaks at the end of each refresh interval,
as shown in Fig. 13 by the distance between the solid black
line and the dashed red line. Since ﬂash lifetime is dictated
by the number of data errors (i.e., when the total number of
errors exceeds the ECC correction capability, the ﬂash device
has reached the end of its life), lowering the error count peaks
extends lifetime by extending the time before these peaks
exhaust the ECC correction capability.
445445
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:16:06 UTC from IEEE Xplore.  Restrictions apply. 
After manufacturing, we statically ﬁnd the predicted worst-
case page by programming pseudo-randomly generated data to
each page within the block, and then immediately reading the
page to ﬁnd the error count, as prior work on error analysis
has done [2]. (ECC provides an error count whenever a page is
read.) For each block, we record the page number of the page
with the highest error count.
While we ﬁnd the predicted worst-case page only once
for each block after the ﬂash device is manufactured, our
mechanism must still count the number of errors within this
page once daily, to account for the increasing number of errors
due to dynamic factors. It can obtain the error count, which we
deﬁne as our maximum estimated error (M EE), by performing
a single read to this page and reading the error count provided
by ECC (once a day).
Since we only estimate the maximum error count instead
of ﬁnding the exact maximum, and as new retention and read
disturb errors appear within the span of a day, we conservatively
reserve 20% of the spare ECC correction capability in our
calculations. Thus, if the maximum number of raw bit errors
correctable by ECC is C, we calculate the available ECC
margin for a block as M = (1 − 0.2) × C − M EE.
4.4. Tuning the Pass-Through Voltage
The second part of our mechanism identiﬁes the greatest
Vpass reduction that introduces no more than M raw bit errors.
The general Vpass identiﬁcation process requires three steps:
Step 1: Aggressively reduce Vpass to Vpass − Δ, where Δ is
the smallest resolution by which Vpass can change.
Step 2: Apply the new Vpass to all wordlines in the block.
Count the number of 0’s read from the page (i.e., the number
of bitlines incorrectly switched off, as described in Sec. 3.6)
as N. If N ≤ M (recall that M is the extra available ECC
correction margin), the read errors resulting from this Vpass
value can be corrected by ECC, so we repeat Steps 1 and 2
to try to further reduce Vpass. If N > M, it means we have
reduced Vpass too aggressively, so we proceed to Step 3 to roll
back to an acceptable value of Vpass.
Step 3: Increase Vpass to Vpass + Δ, and verify that
the
introduced read errors can be corrected by ECC (i.e., N ≤ M).
If this veriﬁcation fails, we repeat Step 3 until the read errors
are reduced to an acceptable range.
The implementation can be simpliﬁed greatly in practice,
as the error rate changes are relatively slow over time (as seen
in Sec. 3.7).6 Over the course of the seven-day refresh interval,
our mechanism must perform one of two actions each day:
Action 1: When a block is not refreshed, our mechanism
checks once daily if Vpass should increase, to accommodate
the slowly-increasing number of errors due to dynamic factors
(e.g., retention errors, read disturb errors).
Action 2: When a block is refreshed, all retention and read
disturb errors accumulated during the previous refresh interval
are corrected. At this time, our mechanism checks how much
Vpass can be lowered by.
For Action 1, the error count increase over time is low
enough that we need to only increase Vpass by at most a
single Δ per day (see Fig. 12). This allows us to skip Step 1 of
6While we describe and evaluate one possible pass-through voltage tuning
algorithm in this paper, other, more efﬁcient or more aggressive algorithms
are certainly possible, which we encourage future work to explore. For
example, we can take advantage of the monotonic relationship between pass-
through voltage reduction and its resulting RBER increase to perform a binary
search of the optimal pass-through voltage that minimizes the RBER.
our identiﬁcation process when a block is not refreshed, as the
number of errors does not reduce, and only perform Steps 2
and 3 once, to compare the number of errors N from using
the current Vpass and from using Vpass + Δ, thus requiring no
more than two reads per block daily.
For Action 2, we at most need to roll back all the Vpass
increases from Action 1 that took place during the previous
refresh interval, since the number of errors that result from static
factors cannot decrease. Since Action 1 is performed daily for
six days, we only need to lower Vpass from its current value by
at most six Δ, requiring us to perform Steps 1 and 2 no more
than six times, potentially followed by performing Step 3 once.
In the worst case, only seven reads are needed.
Our mechanism repeats the Vpass identiﬁcation process for
each block that contains valid data to learn the minimum pass-
through voltage we can use. This allows it to adapt to the
variation of maximum threshold voltage across different blocks,
which results from many factors, such as process variation and
retention age variation. It also repeats the entire Vpass learning
process daily to adapt to threshold voltage changes due to
retention loss [5, 8]. As such, the pass-through voltage of all
blocks in a ﬂash drive can be ﬁne-tuned continuously to reduce
read disturb and thus improve overall ﬂash lifetime.
Fallback Mechanism. For extreme cases where the additional
errors accumulating between tunings exceed our 20% margin of
unused error correction capability, errors will be uncorrectable
if we continue to use an aggressively-tuned Vpass. If this occurs,
we provide a fallback mechanism that simply uses the default
pass-through voltage (Vpass = 512) to correctly read the page,
as Vpass Tuning does not corrupt the stored data.
4.5. Overhead
Performance. As we described in Sec. 4.3 and 4.4, only a
small number of reads need to be performed for each block on
a daily basis. For Action 1, which is performed six times in
our seven-day refresh period, our tuning mechanism requires
a total of three reads (one to ﬁnd the margin M, and two
more to tune Vpass). For a ﬂash-based SSD with a 512GB
capacity (containing 65,536 blocks, with a 100μs read latency),
this process takes 65536×3×100μs = 19.67 sec daily to tune
the entire SSD. For Action 2, which is performed once at
the beginning of a refresh interval, our mechanism requires a
maximum of eight reads (one to ﬁnd M, and up to seven to
tune Vpass; see Sec. 4.4). Assuming every block within the SSD
is refreshed on the same day, the worst-case tuning latency on
this day is 65536×8×100μs = 52.43 sec for the entire drive.
If we average the daily overhead over all seven days of the
refresh interval (assuming distributed refresh), the average daily
performance overhead for our 512GB SSD is 24.34 sec.
These small latencies can be hidden by performing the
tuning in the background when the SSD is idle. We conclude
that the performance overhead of Vpass Tuning is negligible.
Hardware. Vpass Tuning takes advantage of the existing read-
retry mechanism (used to control the read reference voltage
Vref ) [3, 29] to adjust Vpass, since both Vref and Vpass are
applied to the wordlines of a ﬂash block. As a result, our
mechanism does not require a new voltage generator. The ﬂash
device simply needs to expose an interface by which the Vpass
value can be set by the ﬂash controller (within which our tuning
mechanism is implemented). This interface, like Vref , can be
tuned using an 8-bit value that represents 256 possible voltage
settings.7
7Due to the smaller range of practical voltage values for Vpass, as
discussed in Sec. 3.5, we need to allow the selection of only the highest
256 voltage settings (out of the 512 settings possible).
446446
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:16:06 UTC from IEEE Xplore.  Restrictions apply. 
Our mechanism also requires some extra storage for each
block, requiring one byte to record our 8-bit tuned Vpass setting
and a second byte to store the page number of the predicted
worst-case page (we assume that each ﬂash block contains
256 pages). For our assumed 512GB SSD, this uses a total
of 65536×2B = 128KB storage overhead.
4.6. Methodology
We evaluate Vpass Tuning with I/O traces collected from a
wide range of real workloads with different use cases [17,20,27,
31,34], listed in Table 2. To compute ﬂash chip endurance (the
number of P/E cycles at which the total error rate becomes too
large, resulting in an uncorrectable failure) for both the baseline
and the proposed Vpass Tuning technique, we ﬁrst ﬁnd the block
with the highest number of reads for each trace (as this block
constrains the lifetime), as well as the worst-case read disturb
count for that block. Next, we exploit our results from Sec. 3.7
(Table 1) to determine the equivalent read disturb count for the
block with the worst-case read disturb count after Vpass Tuning.
Finally, we use our results from Sec. 3.3 (Fig. 6) to determine
the endurance. Our results faithfully take into account the effect
of all sources of ﬂash errors, including process variation, P/E
cycling, cell-to-cell program interference, retention, and read
disturb errors.
Table 2.
Simulated workload traces.
Trace
Source
Max. 7-Day Read Disturb
Count to a Single Block
FIU [20]
FIU [20]
FIU [20]
MSR [27]
MSR [27]
MSR [27]
MSR [27]
MSR [27]
MSR [27]
MSR [27]
MSR [27]
MSR [27]
MSR [27]
homes
web-vm
mail
mds
rsrch
prn
web
stg
ts
proj
src
wdev
usr
hm
postmark
Postmark [17]
cello99
websearch
ﬁnancial
prxy
MSR [27]
HP Labs [31]
UMass [34]
UMass [34]
MSR [27]
511
2416
23612
36529
39810
40966
41816
49680
54652
64480
66726
66800
154464
308226
343419
363155
611839
1729028
2950196
4.7. Evaluation
Fig. 14 plots the P/E cycle endurance for
the simu-
lated traces. For read-intensive workloads (postmark, ﬁnancial,
websearch, hm, prxy, and cello99), the overall ﬂash endurance
improves signiﬁcantly with Vpass Tuning. Table 2 lists the
highest read disturb count for any one block within a refresh
interval. We observe that workloads with higher read disturb
counts see a greater improvement (in Fig. 14). As we can see
in Fig. 14, the absolute value of endurance with Vpass Tuning
is similar across all workloads. This is because the workloads
are approaching the minimum possible number of read disturb
errors, and are close to the maximum endurance improvements
that read disturb mitigation can achieve. On average across all
of our workloads, overall ﬂash endurance improves by 21.0%
with Vpass Tuning. We conclude that Vpass Tuning effectively
improves ﬂash endurance without signiﬁcantly affecting ﬂash
performance or hardware cost.
447447
Baseline
Vpass Tuning
Vpass Tuning
12000
10000
8000
6000
4000
2000
0
e
c
n
a
r
u
d
n
E
e
l
c
y
C
E
/
P
Fig. 14. Endurance improvement with Vpass Tuning.
5. Read Disturb Oriented Error Recovery
In this section, we introduce another technique that exploits
our observations from Sec. 3, called Read Disturb Recovery
(RDR). This technique recovers from an ECC-uncorrectable
ﬂash error by characterizing, identifying, and selectively cor-
recting cells more susceptible to read disturb errors.8
5.1. Motivation
In Sec. 3.2, we observed that the threshold voltage shift
due to read disturb is the greatest for cells in the lowest
threshold voltage state (i.e., the erased state). In Fig. 15, we
show example threshold voltage distributions for the erased and
P1 states, and illustrate the optimal read reference voltage (Va)
between these two states, both before and after read disturb.
Before read disturb occurs, the two distributions are separated
by a certain voltage margin, as illustrated in Fig. 15a. In
this case, Va falls in the middle of this margin. After some
number of read disturb operations, the relative threshold voltage
distributions of the erased state and the P1 state shift closer
to each other, eliminating the voltage margin and eventually
causing the distributions to overlap, as illustrated in Fig. 15b.