    - jsonnet files
    - Plain directory of YAML/json manifests
    - Any custom config management tool configured as a config management plugin, for example with [helmfile](#using-helmfile)
    Argo CD automates the deployment of the desired application states in the specified target environments. Application deployments can track updates to branches, tags, or pinned to a specific version of manifests at a Git commit. See tracking strategies for additional details about the different [tracking strategies available](https://argo-cd.readthedocs.io/en/stable/user-guide/tracking_strategies/).
# Operating Systems
## Linux
### [Linux Snippets](linux_snippets.md)
* New: [Force umount nfs mounted directory.](linux_snippets.md#force-umount-nfs-mounted-directory)
    ```bash
    umount -l path/to/mounted/dir
    ```
* New: [Configure fstab to mount nfs.](linux_snippets.md#configure-fstab-to-mount-nfs)
    NFS stands for ‘Network File System’. This mechanism allows Unix machines to share files and directories over the network. Using this feature, a Linux machine can mount a remote directory (residing in a NFS server machine) just like a local directory and can access files from it.
    An NFS share can be mounted on a machine by adding a line to the `/etc/fstab` file.
    The default syntax for `fstab` entry of NFS mounts is as follows.
    ```
    Server:/path/to/export /local_mountpoint nfs  0 0
    ```
    Where:
    * `Server`: The hostname or IP address of the NFS server where the exported directory resides.
    * `/path/to/export`: The shared directory (exported folder) path.
    * `/local_mountpoint`: Existing directory in the host where you want to mount the NFS share.
    You can specify a number of options that you want to set on the NFS mount:
    * `soft/hard`: When the mount option `hard` is set, if the NFS server crashes or becomes unresponsive, the NFS requests will be retried indefinitely. You can set the mount option `intr`, so that the process can be interrupted. When the NFS server comes back online, the process can be continued from where it was while the server became unresponsive.
      When the option `soft` is set, the process will be reported an error when the NFS server is unresponsive after waiting for a period of time (defined by the `timeo` option). In certain cases `soft` option can cause data corruption and loss of data. So, it is recommended to use `hard` and `intr` options.
    * `noexec`: Prevents execution of binaries on mounted file systems. This is useful if the system is mounting a non-Linux file system via NFS containing incompatible binaries.
    * `nosuid`: Disables set-user-identifier or set-group-identifier bits. This prevents remote users from gaining higher privileges by running a setuid program.
    * `tcp`: Specifies the NFS mount to use the TCP protocol.
    * `udp`: Specifies the NFS mount to use the UDP protocol.
    * `nofail`: Prevent issues when rebooting the host. The downside is that if you have services that depend on the volume to be mounted they won't behave as expected.
* New: [Fix limit on the number of inotify watches.](linux_snippets.md#fix-limit-on-the-number-of-inotify-watches)
    Programs that sync files such as dropbox, git etc use inotify to notice changes to the file system. The limit can be see by -
    ```bash
    cat /proc/sys/fs/inotify/max_user_watches
    ```
    For me, it shows `65536`. When this limit is not enough to monitor all files inside a directory it throws this error.
    If you want to increase the amount of inotify watchers, run the following in a terminal:
    ```bash
    echo fs.inotify.max_user_watches=100000 | sudo tee -a /etc/sysctl.conf && sudo sysctl -p
    ```
    Where `100000` is the desired number of inotify watches.
* New: [Get class of a window.](linux_snippets.md#get-class-of-a-window)
    Use `xprop` and click the window.
    Get the current brightness level with `cat /sys/class/backlight/intel_backlight/brightness`. Imagine it's `1550`, then if you want to lower the brightness use:
    ```bash
    sudo echo 500 > /sys/class/backlight/intel_backlight/brightness
    ```
* New: [SSH tunnel.](linux_snippets.md#ssh-tunnel)
    ```bash
    ssh -D 9090 -N -f user@host
    ```
* New: [Fix the SSH client kex_exchange_identification: read: Connection reset by peer error.](linux_snippets.md#fix-the-ssh-client-kex_exchange_identification:-read:-connection-reset-by-peer-error)
    Restart the `ssh` service.
### [aleph](aleph.md)
* New: Add application operations.
    - [How to upgrade it](aleph.md#upgrade-aleph)
    - [Create Aleph admins](aleph.md#create-aleph-admins)
    - [Remove a group](aleph.md#remove-a-group)
### [Anki](anki.md)
* New: [How long to do study sessions.](anki.md#how-long-to-do-study-sessions)
    I have two study modes:
    * When I'm up to date with my cards, I study them until I finish, but usually less than 15 minutes.
    * If I have been lazy and haven't checked them in a while (like now) I assume I'm not going to see them all and define a limited amount of time to review them, say 10 to 20 minutes depending on the time/energy I have at the moment.
    The relief thought you can have is that as long as you keep a steady pace of 10/20 mins each day, inevitably you'll eventually finish your pending cards as you're more effective reviewing cards than entering new ones
* New: [What to do with "hard" cards.](anki.md#what-to-do-with-"hard"-cards)
    If you're afraid to be stuck in a loop of reviewing "hard" cards, don't be. In reality after you've seen that "hard" card three times in a row you won't mark it as hard again, because you will remember. If you don't maybe there are two reasons:
    * The card has too much information that should be subdivided in smaller cards.
    * You're not doing a good process of memorizing the contents once they show up.
### [i3wm](i3wm.md)
* New: [Move the focus to a container.](i3wm.md#move-the-focus-to-a-container)
    Get the container identifier with `xprop` and then:
    ```bash
    i3-msg '[title="khime"]' focus
    i3-msg '[class="Firefox"]' focus
    ```
* New: [Interact with Python.](i3wm.md#interact-with-python)
    Install the `i3ipc` library:
    ```bash
    pip install i3ipc
    ```
    Create the connection object:
    ```python
    from i3ipc import Connection, Event
    i3 = Connection()
    ```
    Interact with i3:
    ```python
    focused = i3.get_tree().find_focused()
    print('Focused window %s is on workspace %s' %
          (focused.name, focused.workspace().name))
    outputs = i3.get_outputs()
    print('Active outputs:')
    for output in filter(lambda o: o.active, outputs):
        print(output.name)
    i3.command('focus left')
    for container in i3.get_tree().find_fullscreen():
        container.command('fullscreen')
    root = i3.get_tree()
    print(root.name)
    for con in root:
        print(con.name)
    def on_workspace_focus(self, e):
        # The first parameter is the connection to the ipc and the second is an object
        # with the data of the event sent from i3.
        if e.current:
            print('Windows on this workspace:')
            for w in e.current.leaves():
                print(w.name)
    def on_window_focus(i3, e):
        focused = i3.get_tree().find_focused()
        ws_name = "%s:%s" % (focused.workspace().num, focused.window_class)
        i3.command('rename workspace to "%s"' % ws_name)
    i3.on(Event.WORKSPACE_FOCUS, on_workspace_focus)
    i3.on(Event.WINDOW_FOCUS, on_window_focus)
    i3.main()
    ```
### [Jellyfin](jellyfin.md)
* New: [Fix Corrupt: SQLitePCL.pretty.SQLiteException: database disk image is malformed.](jellyfin.md#corrupt:-sqlitepcl.pretty.sqliteexception:-database-disk-image-is-malformed)
    If your server log file shows SQLite errors like the following example your jellyfin.db file needs attention.
    ```
    'SQLitePCL.pretty.SQLiteException'
    ```
    Typical causes of this are sudden and abrupt terminations of the Emby server process, such as a power loss, operating system crash, force killing the server process, etc.
    To solve it there are many steps:
    * [Remove Database Locks](jellyfin.md#remove-database-locks)
    * [Check Database Integrity and Recover Database](jellyfin.md#check-database-integrity-and-recover-database)
    * [Reset Library Database & Load Fresh](jellyfin.md#reset-library-database-&-load-fresh)
* New: [Restore watched history.](jellyfin.md#restore-watched-history)
    Jellyfin stores the watched information in one of the `.db` files, there are two ways to restore it:
    * Using scripts that interact with the API like [`jelly-jar`](https://github.com/mueslimak3r/jelly-jar) or [`jellyfin-backup-watched`](https://github.com/jab416171/jellyfin-backup-watched)
    * Running sqlite queries on the database itself.
    The user data is stored in the table `UserDatas` table in the `library.db` database file. The media data is stored in the `TypedBaseItems` table of the same database.
    Comparing the contents of the tables of the broken database (lost watched content) and a backup database, I've seen that the media content is the same after a full library rescan, so the issue was fixed after injecting the missing user data from the backup to the working database through the [importing a table from another database](sqlite.md#import-a-table-from-another-database) sqlite operation.
* New: [Fix ReadOnly: SQLitePCL.pretty.SQLiteException: attempt to write a readonly database.](jellyfin.md#readonly:-sqlitepcl.pretty.sqliteexception:-attempt-to-write-a-readonly-database)
    Some of the database files of Jellyfin is not writable by the jellyfin user, check if you changed the ownership of the files, for example in the process of restoring a database file from backup.
## Android
### [Orgzly](orgzly.md)
* New: Introduce Orgzly.
    [Orgzly](https://orgzly.com/) is an android application to interact with [orgmode](orgmode.md) files.
# Other
* Correction: Update introduction.
    The method was described by David Allen in a book with the same name. It's clear that the book is the corner stone of David's business. He is selling his method on every word, some times to the point of tiresome. It's also repeats the same ideas on different parts of the book, I guess that's good in terms of sticking an idea in the people's mind, but if you're already convinced and are trying to sum up the book it's like, hey, I have 90% of the valuable contents of this chapter already in my summary. It's obvious too the context of the writer, that the book was written a while ago and who does it write to. It talks quite often about assistants, bosses of high firm companies he's helped, preferring low-tech physical solutions over digital ones, a lot of references about parenting... If you're able to ignore all the above, it's actually a very good book. The guy has been polishing the method for more than 30 years, and has pretty nice ideas that can change how you manage your life.
    My idea of this summary is to try to extract the useful ideas removing all those old-fashioned capitalist values from it.
* New: Guides on processing your inbox.
    Remember to follow the next rules while processing the items:
    - Process the top item first: that way you treat each element equally, so the "least" important ones are not left dangling forever in your inbox thus thwarting it's purpose.
    - Process one item at a time.
    - Never put anything back into “in.”
    For each element you need to ask yourself: "What's the next action?".
* New: How to clarify your inbox items.
    If you can do something about the element, you need to think which is the next physical, visible activity that would be required to move the situation towards closure. It's tricky, something like "set meeting" won't do because it's not descriptive of physical behaviour. There is still stuff to decide how, when, with whom, if you don't do it now you won't empty your head and the uncertainty will create a psychological gap that will make you procrastinate, so define the next action now. "Decide what to do about X" doesn't work either, you may need to gather more information on the topic, but deciding doesn't take time.
    Once you have the next action, if it can be done in two minutes or less, do it when you first pick the item up. Even if it is not a high-priority one, do it now if you’re ever going to do it at all. The rationale for the two-minute rule is that it’s more or less the point where it starts taking longer to store and track an item than to deal with it the first time it’s in your hands. Two minutes is just a guideline. If you have a long open window of time in which to process your in-tray, you can extend the cutoff for each item to five or ten minutes. If you’ve got to get to the bottom of all your input rapidly, then you may want to shorten the time to one minute, or even thirty seconds, so you can get through everything a little faster.
    There’s nothing you really need to track about your two-minute actions. Just do them. If, however, you take an action and don’t finish the project with that one action, you’ll need to clarify what’s next on it, and manage that according to the same criteria.
    If the next action is going to take longer than two minutes, ask yourself, “Am I the best person to be doing it?” If not, hand it off to the appropriate person, in order of priority:
    * Send an e-mail.
    * Write a note or an over-note on paper and route it to that person.
    * Send it a instant message.
    * Add it as an agenda item on a list for your next real-time conversation with that person.
    * Talk with her directly, either face-to-face or by phone.
    When you hand it off to someone else, and if you care at all whether something happens as a result, you’ll need to track it. Depending on how active you need to be it can go to your Waiting list or to your tickler.
* Correction: Deprecate pydo.
    I'm happy with orgmode so far, so I'm not going to continue it's
    development