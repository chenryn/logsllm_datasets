0x20 _IO_write_base
0x28 _IO_write_ptr
0x30 _IO_write_end
0x38 _IO_buf_base
0x40 _IO_buf_end
0x48 _IO_save_base
0x50 _IO_backup_base
0x58 _IO_save_end
0x60 _markers
0x68 _chain
0x70 _fileno
0x74 _flags2
0x78 _old_offset
0x80 _cur_column
0x82 _vtable_offset
0x83 _shortbuf
0x88 _lock
0x90 _offset
0x98 _codecvt
0xa0 _wide_data
0xa8 _freeres_list
0xb0 _freeres_buf
0xb8 __pad5
0xc0 _mode
0xc4 _unused2
0xd8 vtable
参考资料
abusing the FILE structure
Play with FILE Structure - Yet Another Binary Exploit Technique
695
4.13 利用 _IO_FILE 结构
696
4.14 glibc tcache 机制
4.14 glibc tcache 机制
tcache
安全性分析
CTF 实例
CVE-2017-17426
参考资料
tcache
tcache 全名 thread local caching，它为每个线程创建一个缓存（cache），从而实
现无锁的分配算法，有不错的性能提升。libc-2.26 正式提供了该机制，并默认开
启，具体可以查看这次 commit。
数据结构
glibc 在编译时使用 USE_TCACHE 条件来开启 tcache 机制，并定义了下面一些东
西：
697
4.14 glibc tcache 机制
#if USE_TCACHE
/* We want 64 entries. This is an arbitrary limit, which tunabl
es can reduce. */
# define TCACHE_MAX_BINS 64
# define MAX_TCACHE_SIZE tidx2usize (TCACHE_MAX_BINS-1)
/* Only used to pre-fill the tunables. */
# define tidx2usize(idx) (((size_t) idx) * MALLOC_ALIGNMENT +
MINSIZE - SIZE_SZ)
/* When "x" is from chunksize(). */
# define csize2tidx(x) (((x) - MINSIZE + MALLOC_ALIGNMENT - 1) /
MALLOC_ALIGNMENT)
/* When "x" is a user-provided size. */
# define usize2tidx(x) csize2tidx (request2size (x))
/* With rounding and alignment, the bins are...
idx 0 bytes 0..24 (64-bit) or 0..12 (32-bit)
idx 1 bytes 25..40 or 13..20
idx 2 bytes 41..56 or 21..28
etc. */
/* This is another arbitrary limit, which tunables can change.
Each
tcache bin will hold at most this number of chunks. */
# define TCACHE_FILL_COUNT 7
#endif
值得注意的比如每个线程默认使用 64 个单链表结构的 bins，每个 bins 最多存放 7
个 chunk。chunk 的大小在 64 位机器上以 16 字节递增，从 24 到 1032 字节。32
位机器上则是以 8 字节递增，从 12 到 512 字节。所以 tcache bin 只用于存放 non-
large 的 chunk。
然后引入了两个新的数据结构， tcache_entry 和
tcache_perthread_struct ：
698
4.14 glibc tcache 机制
/* We overlay this structure on the user-data portion of a chunk
when
the chunk is stored in the per-thread cache. */
typedef struct tcache_entry
{
struct tcache_entry *next;
} tcache_entry;
/* There is one of these for each thread, which contains the
per-thread cache (hence "tcache_perthread_struct"). Keeping
overall size low is mildly important. Note that COUNTS and E
NTRIES
are redundant (we could have just counted the linked list eac
h
time), this is for performance reasons. */
typedef struct tcache_perthread_struct
{
char counts[TCACHE_MAX_BINS];
tcache_entry *entries[TCACHE_MAX_BINS];
} tcache_perthread_struct;
static __thread tcache_perthread_struct *tcache = NULL;
tcache_perthread_struct 包含一个数组 entries，用于放置 64 个 bins，数组 counts
存放每个 bins 中的 chunk 数量。每个被放入相应 bins 中的 chunk 都会在其用户数
据中包含一个 tcache_entry（FD指针），指向同 bins 中的下一个 chunk，构成单
链表。
tcache 初始化操作如下：
699
4.14 glibc tcache 机制
static void
tcache_init(void)
{
mstate ar_ptr;
void *victim = 0;
const size_t bytes = sizeof (tcache_perthread_struct);
if (tcache_shutting_down)
return;
arena_get (ar_ptr, bytes);
victim = _int_malloc (ar_ptr, bytes);
if (!victim && ar_ptr != NULL)
{
ar_ptr = arena_get_retry (ar_ptr, bytes);
victim = _int_malloc (ar_ptr, bytes);
}
if (ar_ptr != NULL)
__libc_lock_unlock (ar_ptr->mutex);
/* In a low memory situation, we may not be able to allocate m
emory
- in which case, we just keep trying later. However, we
typically do this very early, so either there is sufficient
memory, or there isn't enough memory to do non-trivial
allocations anyway. */
if (victim)
{
tcache = (tcache_perthread_struct *) victim;
memset (tcache, 0, sizeof (tcache_perthread_struct));
}
}
使用
700
4.14 glibc tcache 机制
触发在 tcache 中放入 chunk 的操作：
free 时：在 fastbin 的操作之前进行，如果 chunk size 符合要求，并且对应的
bins 还未装满，则将其放进去。
#if USE_TCACHE
{
size_t tc_idx = csize2tidx (size);
if (tcache
&& tc_idx counts[tc_idx] counts[tc_idx] fd;
else
{
REMOVE_FB (fb, pp, tc_victim);
if (__glibc_unlikely (tc_victim == NULL))
break;
}
tcache_put (tc_victim, tc_idx);
}
}
#endif
smallbin 中的情况与 fastbin 相似，双链表中的剩余 chunk 会被填充到
tcache bin 中，直到上限。
702
4.14 glibc tcache 机制
#if USE_TCACHE
/* While we're here, if we see other chunks of the same
size,
stash them in the tcache. */
size_t tc_idx = csize2tidx (nb);
if (tcache && tc_idx counts[tc_idx] bk;
set_inuse_bit_at_offset (tc_victim, nb);
if (av != &main_arena)
set_non_main_arena (tc_victim);
bin->bk = bck;
bck->fd = bin;
tcache_put (tc_victim, tc_idx);
}
}
}
#endif
binning code（chunk合并等其他情况）中，每一个符合要求的 chunk 都
会优先被放入 tcache，而不是直接返回（除非tcache被装满）。寻找结束
后，tcache 会返回其中一个。
703
4.14 glibc tcache 机制
#if USE_TCACHE
/* Fill cache first, return to user only if cache fi
lls.
We may return one of these chunks later. */
if (tcache_nb
&& tcache->counts[tc_idx] entries[tc_idx] != NULL)
{
return tcache_get (tc_idx);
}
DIAG_POP_NEEDS_COMMENT;
#endif
bining code 中，如果在 tcache 中放入 chunk 达到上限，则会直接返回最后一
个 chunk。
#if USE_TCACHE
/* If we've processed as many chunks as we're allowed wh
ile
filling the cache, return one of the cached ones. */
++tcache_unsorted_count;
if (return_cached
&& mp_.tcache_unsorted_limit > 0
&& tcache_unsorted_count > mp_.tcache_unsorted_limit)
{
return tcache_get (tc_idx);
}
#endif
当然默认情况下没有限制，所以这段代码也不会执行：
705
4.14 glibc tcache 机制
.tcache_unsorted_limit = 0 /* No limit. */
binning code 结束后，如果没有直接返回（如上），那么如果有至少一个符合
要求的 chunk 被找到，则返回最后一个。
#if USE_TCACHE
/* If all the small chunks we found ended up cached, r
eturn one now. */
if (return_cached)
{
return tcache_get (tc_idx);
}
#endif
另外还需要注意的是 tcache 中的 chunk 不会被合并，无论是相邻 chunk，还是
chunk 和 top chunk。因为这些 chunk 会被标记为 inuse。
安全性分析
tcache_put() 和 tcache_get() 分别用于从单链表中放入和取出 chunk：
706
4.14 glibc tcache 机制