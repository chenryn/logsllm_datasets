title:The fable of the bees: incentivizing robust revocation decision making
in ad hoc networks
author:Steffen Reidt and
Mudhakar Srivatsa and
Shane Balfe
Incentivizing Robust Revocation Decision Making
The Fable of the Bees:
in Ad Hoc Networks
Steffen Reidt
Royal Holloway,
University of London
PI:EMAIL
Mudhakar Srivatsa
IBM T.J. Watson
Research Center
PI:EMAIL
Shane Balfe
Royal Holloway,
University of London
PI:EMAIL
ABSTRACT
In this paper we present a new key-revocation scheme for ad
hoc network environments with the following characteristics:
• Distributed: Our scheme does not require a permanently
available central authority.
• Active: Our scheme incentivizes rational (selﬁsh but
honest) nodes to revoke malicious nodes.
• Robust: Our scheme is resilient against large numbers
of colluding malicious nodes (30% of the network for a
detection error rate of 15%).
• Detection error tolerant: Revocation decisions funda-
mentally rely on intrusion detection systems (IDS). Our
scheme is active for any meaningful IDS (IDS error rate
< 0.5) and robust for an IDS error rate of up to 29%.
Several schemes in the literature have two of the above four
characteristics (characteristic four is typically not explored).
This work is the ﬁrst to possess all four, making our revoca-
tion scheme well-suited for environments such as ad hoc net-
works, which are very dynamic, have signiﬁcant bandwidth-
constraints, and where many nodes must operate under the
continual threat of compromise.
Categories and Subject Descriptors
C.2.0 [General]: Security and protection
General Terms
Security
Keywords
Partially Available, Trust Authority, Revocation, Incentive,
Game, Reward, Bees, Suicide
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’09, November 9–13, 2009, Chicago, Illinois, USA.
Copyright 2009 ACM 978-1-60558-352-5/09/11 ...$10.00.
1.
INTRODUCTION
Key revocation is the key management operation concerned
with enforcing limitations on a key’s use [11].
In Mobile
Ad hoc NETworks (MANETs) compromised nodes can di-
vert and monitor traﬃc, inﬂuence quorum-based decisions or
spread harmful information. To limit the damage caused by
such nodes, agile revocation schemes that allow rapid im-
peachment of malicious nodes are vital for the security of the
network.
In contrast to wired networks, revocation in MANETs must
operate in a completely distributed fashion. The lack of a
permanently available, global monitoring authority within
a MANET, coupled with the need to quickly react to per-
ceived threats, necessitates that resource-constrained nodes
be granted the operational freedom to make risk-based key
revocation decisions without direct contact with a central net-
work authority. A node, or group of nodes, presented with
possibly incomplete (and/or inaccurate) evidence of malicious
behavior, must (based on probabilistic results of their intru-
sion detection systems) make a decision as to whether to insti-
gate a key revocation operation against another node. Once a
decision to revoke has been reached, a revocation message will
be formulated and either distributed locally within a node’s
neighborhood or ﬂooded throughout the entire network.
To-date, one of the most widely cited methods for achieving
revocation in MANETs has been the use of quorum-based de-
cision making using k-out-of-n threshold signatures [3, 9, 23].
In these schemes, nodes accuse other nodes of malicious be-
havior by casting negative votes against a perceived oﬀender.
Once a predetermined threshold k + 1 of negative votes is
achieved, a signature can be reconstructed and the oﬀend-
ing node will be considered revoked by other members of the
network. Setting this threshold parameter high, whilst intu-
itively an astute security decision, may inadvertently result in
a malicious node never being revoked (as the network density
may not support the required level of collaboration). Setting
it too low may result in a malicious adversary compromising
a relatively small fraction of the total number of nodes and
gaining control of the network by being able to revoke at will
[3].
To avoid the shortcomings of quorum-based revocation, the
concept of node suicide was recently introduced by Clulow et
al.
[5]. Motivated by the observation that many biological
systems exhibit behavior in which individual members of a
group are willing to sacriﬁce themselves to protect the collec-
tive (e.g. honeybees sting in response to a perceived threat
against the hive), their scheme proposes that a single node
291can unilaterally revoke another node at the cost of being re-
voked itself. Unfortunately, for the type of heterogeneous,
coalition networks envisaged in future military or emergency
response scenarios [25], it may be unreasonable to assume
that each node will value the network’s utility more than its
own. Without suﬃcient incentive, selﬁsh1 (rational) nodes
will always defer revocation responsibility to others. This in
turn may result in malicious nodes never being revoked, as
was shown in [23].
It is this observation that leads us to Mandeville’s (in)fa-
mous work, “The Fable of the Bees” [17]. It was Mandeville’s
thesis that altruism doesn’t truly exist in a society. Instead
it is self-interest (and all its attendant vices) that dominates
behavioral norms. However, through skillful and eﬃcacious
management of the individual’s selﬁsh desires, public beneﬁt
may emerge. It is this view of network collaboration that we
adopt in this paper.
In this paper, we present a new revocation scheme for ad
hoc networks which we call karmic-suicide. Our scheme in-
herits the attractive properties of suicide-based revocation
(immediacy and abuse resistance) but overcomes the disin-
centive to sacriﬁce utility for collective gain. To incentivize
nodes to commit suicide, a periodically available Trust Au-
thority2 (TA) rewards a node for a justiﬁed suicide by rein-
carnating (reactivating) and thus rewarding the node for his
actions. If, however, our judgment system is unable to ascer-
tain (to a satisfactory degree) whether a suicide was justiﬁed,
it can reactivate both parties but give no reward or engage in
remedial action with one or more of the parties (possibly by
resetting their conﬁguration). To support this function, we
develop a judgment mechanism that can be used by our TA to
enable it to make probabilisticly correct decisions by posthu-
mously interrogating neighborhood nodes who witnessed (the
events leading to) the suicide. Using a k-means clustering
algorithm, we derive bounds on the diﬀerence in behavior to
eﬀectively partition malicious nodes from honest ones and de-
rive globally optimal strategies for colluding, malicious nodes
attempting to abuse our judgment mechanism. In doing so,
we highlight the interplay between TA-level judgments and
node-level Intrusion Detection Systems (IDSs) and establish
lower bounds on the required accuracy of our judgment sys-
tem for which an adversary cannot abuse our scheme for its
own beneﬁt.
We show that our judgment system is secure (cannot be
abused by an adversary) for node-level IDS error rates of
10,15,20,25%, if the ratio of malicious to honest nodes is at
most 38,31,22,11%, respectively. We furthermore investigate
the relationship between the IDS error rate and the density of
the network in determining the agility (how quickly malicious
nodes can be removed) of our revocation process using game-
theoretic analysis. Our analysis shows how both smaller IDS
errors and a greater network density yield an accelerated re-
vocation process, resulting in a more resilient and reliable
network free from undesirable nodes.
1Whilst nodes themselves are not capable of higher cognitive
processing, we assume nodes are programmed to to maximize
their personal utility (or the utility of their group) over a set
of constraints.
2The presence of a TA to assist in this type of a posteriori
decision review is often ignored in the MANET revocation
literature. This is in stark contrast to the large body of work
that has emerged around the requirements of a key distribu-
tion authority within a MANET [32, 30, 16, 15].
This paper is organized as follows. In Section 2 we review
related work in the area of revocation in MANETs. In Sec-
tion 3 we present the requirements of our revocation scheme,
outline our assumptions and present our adversary model.
In Section 4 we give an overview of our scheme and derive
bounds on the judgment mechanism’s accuracy. In Section 5
we present our judgment mechanism and investigate for which
IDS error rates our lower bounds can be met. In Section 6
we use a game-theoretic analysis to show that our scheme
provides selﬁsh, but honest, nodes with suﬃcient incentive to
revoke malicious nodes whilst disincentivizing colluding mali-
cious nodes from abusing our scheme. We conclude this paper
with Section 7.
2. RELATED WORK
The process of arriving at a revocation decision is the pri-
mary focus of the majority of revocation schemes presented
to-date in the ad hoc networking literature [1, 9, 22, 6, 16, 13,
28, 20, 23, 30, 3, 14, 9, 7, 4, 27]. Assuming that a node has
amassed suﬃcient (read perfect) evidence, various approaches
have been introduced that require diﬀering amounts of partic-
ipation from other nodes in the network. That is, revocation
decision making may be the result of a collaborative, systemic
or a unilateral decision process.
In collaborative schemes, nodes accuse other nodes of mis-
behaving by casting negative votes against them. If a prede-
termined threshold of negative votes are cast, then the oﬀend-
ing node is considered revoked. By contrast, systemic revo-
cation decision making has been proposed for use in Identity-
based Public Key Infrastructures (ID-PKIs) for ad hoc net-
works [9, 18, 31]. As part of an ID-PKI, a validity period can
be expressed in deriving a node’s identiﬁer. Consequently, a
node’s identity will only be valid for a pre-determined period
as speciﬁed by a Trust Authority (TA) with administrative
responsibility for the network. Once a node’s identiﬁer ex-
pires, the node must contact its (possibly distributed) TA
and request a new private key, with a new expiry time. The
TA in turn can decide whether to issue new keys during this
re-enrollment process. In systemic-based decision making the
frequency of renewal (the longevity of an expiry period) is
an important parameter as the higher the turnover, the less
impact a compromised key may have on the network, but the
greater is the eﬀort that must be expended on key issuance
procedures. This approach requires an on-line TA and may
signiﬁcantly increase traﬃc if refreshing is frequent [16].
The concept of unilateral decision making as a method of
revocation was ﬁrst introduced by Rivest in dealing with key
compromise [24] in Public Key Infrastructures (PKIs). A
user, upon detecting that their key has been exposed, de-
clares their key invalid by issuing a signed message using the
compromised key (indicating that this key is no longer to be
trusted). This notion of suicide has recently been extended for
use in ad hoc networks where a node, upon detecting some
malicious behavior, can instigate a “suicide-bombing” on a
(perceived) malicious node [5, 27, 20, 23]. A node commits
suicide by broadcasting a signed instruction to revoke both
its own key and the key of the misbehaving node. Suicide
as a method of revocation in ad hoc networks has a number
of attractive features when compared with collaborative and
systemic decision making. With suicide, nodes can act im-
mediately to a perceived threat. Additionally, suicide, as a
method of revocation, is resistant to abuse due the to high
cost associated with revoking another node.
292The suicide schemes above rely upon a node valuing the
network’s utility more than its own utility as an incentive
to suicide. However, Raya et al.
[23] recently showed that
under such assumptions, nodes tended to defer suicide to an-
other node rather than revoke a malicious node themselves.
To induce a node to suicide Raya et al.
introduce a “social
cost” as a means of incentivizing suicide. However, Raya et
al. give no ﬁrm deﬁnition of what this social cost is or how it
would be introduced, nor do they provide an adversary model
against which their scheme can be shown resilient. It is our
thesis, that a “social cost” cannot provide enough incentive
for a rational node to commit suicide. To this end, we in-
troduce the notion of karmic-suicide, where we, in contrast
to all other revocation schemes, incorporate both false posi-
tives and false negatives in the underlying node-level intrusion
detection mechanisms. This in turn impacts the ability to ef-
fectively reward/punish nodes and we show that our scheme:
1) gives honest nodes suﬃcient incentive to revoke malicious
nodes and 2) is resilient to abuse for large numbers of collud-
ing malicious nodes.
3. PROBLEM DEFINITION
In this section we outline the design requirements that our
karmic-suicide scheme must satisfy, describe the assumptions
that we make about our scheme and outline our adversary
model.
3.1 Design Requirements
Distributed: We require that a network authority responsi-
ble for the administration of the network is only periodically
available and consequently incapable of monitoring the oper-
ational minutiae of the network.
Active: We require a revocation mechanism that encourages
selﬁsh nodes to commit suicide for the good of the network.
That is, nodes should be rewarded for sacriﬁcing a short-term
loss in utility in favor of longer-term gains.
Robustness: We require a scheme that is robust against a
large number of cooperating, malicious nodes.
Detection Error Tolerant: We require a scheme that is ca-
pable of handling realistic errors in the underlying node-level
IDS in detecting malicious behavior.
Agility: We require a scheme that is capable of reacting
quickly to node misbehavior.
Scalability: We require a scheme that works irrespective of
the size and density of the network.
3.2 Assumptions
Node Identiﬁers: We assume that nodes can have several
identiﬁers with corresponding private keys (this could be the
result of either using a public key infrastructure with one or
more public key certiﬁcates, or using an identity-based key
infrastructure with one or more identiﬁer/private key pairs,
per node). Should one of these identiﬁers be revoked, all ben-
eﬁts that have been accrued by this identiﬁer over its lifetime
will be lost. Consequently, if the identiﬁer of a node is re-
voked, and it has one or more redundant identiﬁers, it can
still operate but must start building reputation for this iden-
tiﬁer anew. By default all nodes have a single identiﬁer.
Selﬁshness: We assume that all honest nodes behave self-
ishly and want to maximize their own utility over some (in)ﬁ-
nite horizon.
Network Longevity: We assume that the network will be
in operation for a non-negligible period of time.
Intrusion Detection: We assume that individual nodes are
running intrusion detection systems to provide a node with an
indication of malicious behavior on the part of other nodes.
This assumption is implicit in all ad hoc network revocation
schemes to date.
Network Infrastructure: We assume the presence of a net-
work infrastructure, that facilitates nodes to sign messages
and to send authenticated messages.
3.3 Adversary Model
Key revocation protocols are carried out in the presence
of active adversaries. It is the goal of the adversary in our
model to maximize his overall inﬂuence during the lifetime
of the network. The inﬂuence of our adversary is measured
by the sum of total time periods that each malicious node
attacks the network. The malicious nodes will therefore try
to maximize their attack intensity while considering the risk
of being detected and revoked as a result of their negative
behavior. The adversary can improve his position by getting
more identiﬁers with corresponding private keys. Thus, the
adversary will attempt to abuse the revocation scheme to ob-
tain more identiﬁers. Our adversary will pool the resources
of his nodes, possibly creating wormholes between nodes in
an attempt to overwhelm any quorum-based mechanisms in-
cluding those that attempt to derive the threshold as a frac-
tion of the number of nodes in their neighborhood [1]. We
assume that nodes in our network may be compromised at
any time during the network’s operation but that the adver-
sary always has less than 50 percent of the total number of
identiﬁers (with corresponding private keys) available in the
network.
4. REVOCATION BY KARMIC-SUICIDE
To overcome the barrier of selﬁshness in suicide-based revo-
cation schemes, we propose our scheme that is motivated by
a macabre real-life observation: a belief in “afterlife” can be
an incentive to sacriﬁce oneself if there is a suﬃcient promise
of reward. To this end we present our karmic-suicide scheme.
4.1 Protocol and Parameter Speciﬁcation
Prior to engaging in karmic-suicide, nodes monitor their
neighborhoods using IDS to collect evidence of malicious be-
havior. What constitutes malicious behavior has evolved sig-
niﬁcantly over the years, from originally dealing exclusively
with non-forwarding of packets or wormhole attacks [10], to
recent application layer considerations such as disseminating
fraudulent information [20]. However, irrespective of what
behavior the IDS is conﬁgured to monitor for, it can only pro-
vide probabilistic results about another node’s (mis)behavior.
Many revocation schemes found in the literature to-date make
(incorrect) simplifying assumptions that the detection of un-
desirable behavior is perfect and/or that malicious nodes are
uncoordinated [20]. As part of our scheme we assume all ma-
licious nodes collude and we incorporate the (in)accuracy of
the IDS in our analysis.
We assume that the output of the IDS of node i about a
node j is a normalized score 0 ≤ idsij ≤ 1, where 0.5 means a
neutral score, and a higher score accounts for honesty. Each
node derives an opinion oij from this score. For the sake of