fc = ⌊|M|−1
⌋ and the quorum size is ⌈|M|+fc+1
For any replica pj that requests to join the system, if a
replica pi maintains a higher configuration number, it executes
the sync() function and sends the configuration history to pj.
This is used for pj to directly obtain the latest configuration
of the system.
⌉.
2
3
Fig. 5: Normal-case operation at replica pi.
{view, configuration}
Initialization
v, c
as a replica
func view-change()
upon receiving m = ⟨VIEW-CHANGE, v, c′, C, P, PP, j⟩
v ← v + 1
broadcast m′ = ⟨VIEW-CHANGE, v, c, C, P, PP, i⟩
if c′  c and V erif y(PP, P)
send m to Mc/Mc′
Mc ← Mc′
send ⟨VIEW-CHANGE, v, c, C, P, PP, i⟩ to Mc′ /Mc
as the new leader
upon receiving Qc ⟨VIEW-CHANGE, v, c′, C, P, j⟩
broadcast ⟨NEW-VIEW, v, c, V, O⟩
Fig. 6: View change protocol at replica pi.
Upon the deliver() event, replica pi first delivers regular
requests and then the membership requests. If membership re-
quests are included in the batch, pi installs a new configuration
and increases c by 1. For each ⟨ADD, j, m⟩ message, pi adds pj
to M, and starts state transfer to pj. For each ⟨REMOVE, j, m⟩
message, pi removes pj from M. If pj delivers the REMOVE
request, it leaves the system.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:34:42 UTC from IEEE Xplore.  Restrictions apply. 
91325
Any replica pi
that requests to join the system acts as
a learner that passively learns the results from the normal-
case operation, i.e., it is added to the temporary members
by replicas in the system. Learners process the normal-case
messages following the same rules as existing replicas.After
pi delivers the join request, it waits until it completes state
transfer by accepting 2fc + 1 ⟨HISTORY, s, h,C,P⟩ messages.
After that, pi participates in the normal-case operation. The
state transfer for a new replica to catch up with the execution
history and the maintain proof of delivery for historic requests.
View change. We now sketch the major workflow for view
changes, the pseudocode of which is shown in Fig. 6.To start
view change, each replica pi increments its view number and
broadcasts a ⟨VIEW-CHANGE, v, c, s,C,PP, i⟩, where v is the
view number, c is the configuration number, C is a stable
checkpoint, P is a set of proofs of delivery for requests since
last stable checkpoint, PP is a set of membership requests.
Upon receiving a VIEW-CHANGE message from replica pj,
a replica compares c′ carried in the message with its local
configuration number c. If c′  c, it means that
replica pi has not installed newer configurations. In this case,
pi broadcasts a VIEW-CHANGE message to Mc′. Mc′ can be
obtained from PP and the proof of delivery can be obtained
from P.
Consider that c is the configuration installed by at least
one correct replica and no correct replica has installed a
configuration greater than c, the new leader can be identified
by Mc[v mod |Mc|]. When the designated leader in the new
view collects 2fc + 1 valid VIEW-CHANGE messages, it enters
the new view by broadcasting a ⟨NEW-VIEW, v, c,V,O⟩, where
V is a set of VIEW-CHANGE messages and O is a set of normal-
case operation messages. Replicas then resume normal-case
operation and process messages in O accordingly.
B. Configuration Discovery
Configuration discovery ensures that new replicas and
clients learn the membership of existing system. The approach
we present
in Dyno requires clients and new replicas to
discover newer configurations (if any). In this section, we
first define configuration history. Then we present the self-
discovery approach we use in our protocol by defining the
interface used by the normal-case operation. We describe two
alternative constructions in Appendix B. The proofs for all the
configuration discovery protocols are shown in Appendix C-A.
Configuration history. We define configuration history as a
set of sequentially ordered membership requests according to
the configuration number. The configuration history is a subset
of the entire execution history. A configuration history only
includes batches of requests where each batch consists of at
least one membership request. The corresponding c number in
each message is sequentially ordered. We additional require
every replica to maintain the corresponding proof of delivery
for each membership request, i.e., a message signed by Qc
replicas in Mc. A single configuration history can be verified
by any correct replica to prove the existence of a configuration.
Initialization
c, Mc, chist {current configuration, membership, configuration history}
as a client/new replica
func ObtainConf ig()
broadcast ⟨DISCOVER, c⟩ to Π
start a timer ∆
c, chist′⟩
upon ⟨CONF, c′, M′
if chist′ is valid and c′ > c
chist ← chist′, c ← c′, Mc ← M′
c
upon timeout(∆)
return c, Mc
as a replica
upon ⟨DISCOVER, c′⟩
reply with ⟨CONF, c, Mc, chist⟩
Fig. 7: Configuration discovery: self-discovery.
Self-discovery. By default, we use a self-discovery approach
shown in Fig. 7. To obtain the configuration of the system, a
replica (or a client) pi first sends a ⟨DISCOVER, c⟩ request to
the universe, where c is the latest configuration pi is aware
of. A timer is also started. Upon receiving a ⟨DISCOVER, c′⟩
request, a replica replies with a ⟨CONF, c, Mc, chist⟩, where c
is its current configuration, Mc is the members of configuration
c, chist is the configuration history. Upon receiving a CONF
message with a valid chist, pi updates its local configuration
number, Mc, and chist. Upon time out of ∆, configuration
discovery completes and the current c and Mc are returned.
Theorem VI.1. Under the standard quorum assumption, Dyno
achieves agreement V , total order, liveness, and consistent
delivery.
1, and V ′
1, and V ′
The correctness of Dyno is shown in Appendix C-B.
VII. DYNO WITH STRONGER AGREEMENT PROPERTIES
We study Dyno variants with stronger properties, i.e, V1, V2,
V ′, V ′
2. In this section, we present two approaches for
Dyno to achieve the V1 agreement property. We first show that
Dyno itself can achieve V1 by making a stronger assumption.
We then show Dyno-A, a construction based on Dyno, which
achieves V1 under the standard quorum assumption. Then we
present Dyno-AC, which adds a simple constraint on top of
Dyno-A to achieve V2. We further show that the constructions
of the protocol remain the same for Dyno with V , V1, and V2 to
achieve V ′, V ′
2, separately. The proofs of all protocols
discussed in this section are shown in Appendix C-C.
Dyno with V1 under G-correct assumption. We do not
change the construction of the protocol to achieve the correct-
ness but assume the G-correct assumption in Sec. III. Since
we do not modify the protocol, the total order and liveness
follow that of Dyno. The agreement property, however, can
be greatly simplified.
Theorem VII.1. Under the G-correct assumption, Dyno
achieves agreement V1, total order, liveness, and consistent
delivery.
Dyno-A with V1. The assumption that there always exist at
least f + 1 g-correct replicas is not practical as it requires
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:34:42 UTC from IEEE Xplore.  Restrictions apply. 
101326
one to know max(f0, f1 ··· ), i.e., the maximum number of
faulty replicas in the entire life of the system. Instead, we show
another construction that achieves the V1 agreement property
without having to change the assumption of the system. In
particular, we provide an addendum protocol on top of Dyno
to achieve V1.
{obtain a new configuration if any}
{defined inFig. 6 }
upon timeout
c′, Mc′ ← ObtainConf ig()
if c′ = c, view-change()
else
upon ⟨UPDATE, s, c′, j⟩
if pj ∈ Mc′ and c > c′
send ⟨RESULT, hist⟩ to pj
broadcast ⟨UPDATE, s, c, i⟩ to Mc
upon fc′ + 1 matching ⟨RESULT, hist⟩
deliver requests in hist
{execution history greater than s}
Fig. 8: Dyno-A.
As shown in Fig. 8, we introduce additional procedures
for each replica that falls behind to catch up with replicas
in newer configuration. In particular, during the normal-case
operation, each replica pi still sets up a timer for the first
request in its queue. If the request is not delivered before the
timer expires, instead of directly triggering view changes, the
replica first runs the configuration discovery protocol, obtains
a new configuration number c′, and the list of replicas Mc′.
If c′ = c, the replica starts the view change according to the
procedures in Dyno. Otherwise, if c′ is greater than c, the
replica broadcasts an ⟨UPDATE, s, c, i⟩ message to all replicas
in configuration c′, where s is the sequence number of the
last delivered request and c is its current configuration. When
a replica pi in c′ receives an ⟨UPDATE, s, c′, j⟩ message, it
first verifies whether pj is a valid replica in configuration c′.
If the local execution history of pi is longer (i.e., the sequence
number of its last committed request is greater than s), pi sends
the execution history to pj. Upon receiving fc′ + 1 matching
hist, replica delivers the requests in hist. If a ⟨REMOVE, i⟩
request has been delivered, pi directly leaves the system.
Otherwise, pi continues to participate in the protocol.
Theorem VII.2. Under the standard quorum assumption,
Dyno-A achieves agreement V1,
liveness, and
consistent delivery.
total order,
The motivation of the addendum protocol is for a c-correct
replica to obtain the execution history, even if the replica falls
behind. In the case where a replica times out, it executes the
configuration discovery protocol before it starts view change.
If the replica falls behind, it obtains the execution history from
other replicas. This ensures that any c-correct replica obtains
the execution history and delivers the requests before it leaves
the system (if applicable).
Dyno with V2. Based on Dyno with G-correct assumption or
Dyno-A, we could further add more constraints to replicas so
that the protocol achieves V2, creating Dyno-C and Dyno-AC,
separately. In particular, V2 further requires that any correct
replica in configuration c also delivers a message if a correct
replica in c delivers the messages.
The additional constraint is quite simple: any correct replica
pi leaves the system (if a leave request has been submitted)
only after it delivers a ⟨REMOVE, i⟩ request. 2
The constraint ensures that any correct replica in c delivers
all the messages, even if it is removed immediately after c.
Therefore, we require a replica to discover newer configura-
tion(s) and obtain the execution history if it falls behind. This
ensures that each correct replica delivers all the requests it
should deliver according to the requirements of V2.
Theorem VII.3. Under the G-correct assumption, Dyno-C
achieves agreement V2, total order, liveness, and consistent
delivery. Under the standard quorum assumption, Dyno-AC
achieves agreement V2, total order, liveness, and consistent
delivery.
Dyno with V′, V′
2. There is no need to change the
specification of the protocols to achieve V ′, V ′
1, and V ′
2.
Namely, Dyno achieves V ′, Dyno-A (or Dyno under the G-
correct assumption) achieves V ′
1, and Dyno-C and Dyno-AC
achieve V ′
2.
1, V′
VIII. IMPLEMENTATION AND EVALUATION
Overview. We implement Dyno variants in Go using around
10,000 LOC. We implement an optimization for Dyno where a
replica that joins the system starts to participate in the normal-
case operation after the membership request is delivered. The
state transfer is executed in parallel. All the requests after the
delivery of the membership request, however, are executed
after the state transfer is completed.
Our results show that Dyno-C and Dyno-AC achieve sim-
ilar performance with Dyno, mainly because the additional
constraints and addendum protocol mostly affect the behavior
of replicas joining or leaving the system. Therefore, in this
section, we focus on the performance of Dyno and Dyno-
S. We compare Dyno with BFT-SMaRt [50], an open-source
implementation of a variant of PBFT protocol written in
Java. BFT-SMaRt supports reconfiguration where membership
requests are issued by a separate view manager.
We deploy the protocols in a cluster using up to 30
servers. Each server has 16-core 2.3GHz CPU. We use f to
represent the network size, where we use 3f + 1 replicas in
each experiment. Unlike previous protocols that mostly focus
on benchmarks with small transactions, in our experiments,
we set all
transactions and reply messages to 100 bytes,
as transactions in BFT applications (e.g., blockchains) are
usually at least 100 bytes. Besides the number of replicas,
we also vary the frequencies for garbage collection (i.e.,
checkpoint), denoted as cp, and the number of clients that
submit transactions concurrently to the system. By default,
replicas execute the checkpoint protocol upon delivering every
100 batches of requests.
2It is worth mentioning that the pseudocode for Dyno already enforces such
a constraint. In fact, such a constraint is not necessary in Dyno. According to
the proof, a replica can leave after it is certain that the ⟨REMOVE, i⟩ request
will be delivered, e.g., after it receives a prepare certificate.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:34:42 UTC from IEEE Xplore.  Restrictions apply. 
111327
Agreemment
View-Change
Agreemment
State-Transfer
Transition
Agreemment
State-Transfer
Transition
b=50000
b=10000
b=5000
0
1
3
Latency breakdown (s)
2
b=50000
b=10000
b=5000
0
40
20
80
Latency breakdown (s)
60
cp=500
cp=200
cp=100
0
20
Latency breakdown (s)
(a) Latency breakdown of a join request (excluding
state transfer) for Dyno-S.
(b) Latency breakdown of a join request for Dyno
(latency of agreement in all cases are lower than
100ms and not visible in the figure).
(c) Latency of a join request for Dyno and Dyno-
S (latency of agreement in all cases are lower
than 100ms and not visible in the figure).
)
c
e
S
(
y
c
n
e
t
a
L
4
3
2
1
0
Dyno Dyno-S
3.44
2.31
1.96
f = 1
f = 2
f = 1 (BFT-SMaRt)
f = 5
100
80
60
40
20
)
c
e
s
/
x
t
k
(
t
u
p
h
g
u
o
r
h
T
0.05
0.06
0.1
b = 5000
b = 10000
b = 50000
0
0
200
400
600