title:Collaborative Verification of Information Flow for a High-Assurance
App Store
author:Michael D. Ernst and
Ren&apos;e Just and
Suzanne Millstein and
Werner Dietl and
Stuart Pernsteiner and
Franziska Roesner and
Karl Koscher and
Paulo Barros and
Ravi Bhoraskar and
Seungyeop Han and
Paul Vines and
Edward XueJun Wu
Collaborative veriﬁcation of information ﬂow for a high-assurance app store
Michael D. Ernst, René Just, Suzanne Millstein, Werner M. Dietl,
Stuart Pernsteiner, Franziska Roesner, Karl Koscher, Paulo Barros,
Ravi Bhoraskar, Seungyeop Han, Paul Vines, and Edward X. Wu
UW Computer Science & Engineering
PI:EMAIL
violations of the app store’s terms of service. Finally,
the app store approves and publishes the app. Unfortu-
nately, the process offers few guarantees, as evidenced by
the Trojans that have been approved by every major app
store [3, 15, 38, 40, 47].
We are exploring the practicality of a high-assurance
app store that gives greater understanding of, and con-
ﬁdence in, its apps’ behavior. Such a store would have
different approval requirements to reduce the likelihood
that a Trojan is approved and distributed to unsuspecting
users. Corporations already provide lists of apps approved
for use by employees (often vetted by ad hoc processes).
The U.S. Department of Defense is also actively pursuing
the creation of high-assurance app stores.
Four contributing factors in the approval of Trojans by
existing app stores are: (1) Existing analysis tools are
poorly automated and hard to use: much manual, error-
prone human effort is required. (2) The vendor provides
only a very coarse description of application behavior in
the form of permissions it will access: system resources
such as the camera, microphone, network, and address
book. These properties provide few guarantees about the
application’s behavior. (3) The binary executable lacks
much semantic information that is available in the source
code but has been lost or obfuscated by the process of
compilation. (4) The vendor has little incentive to make
the application easy for the app store to analyze.
We have developed a new approach to verifying apps
that addresses each of these factors. (1) We have created
powerful, ﬂow-sensitive, context-sensitive type system
that veriﬁes information ﬂows. The system is easy to
use and works with with Java and Android. (2) Our ap-
proach provides ﬁner-grained speciﬁcations than current
app stores, indicating not just which resources may be
accessed but which information ﬂows are legal — how
the resources may be used by the program. Our initial
analysis focuses on conﬁdentiality and integrity security
policies that can be expressed in terms of information
ﬂow. Our tools connect information ﬂow security policies
to lightweight speciﬁcations and connect speciﬁcations
to code. (3) Our approach works on source code rather
than binaries, and it aims to prove that an app satisﬁes
information ﬂow properties, rather than to detect some
bugs/malware. An analyst approves or rejects the proper-
ties. Availability of source code fundamentally changes
the veriﬁcation process: it provides more information, en-
Abstract
Current app stores distribute some malware to unsuspect-
ing users, even though the app approval process may be
costly and time-consuming. We propose the creation of
high-integrity app stores that provide certain guarantees
to their customers. Our approach has four key features.
(1) Our analysis is based upon a ﬂow-sensitive, context-
sensitive information-ﬂow type system. (2) We use ﬁner-
grained behavioral speciﬁcations of information ﬂow than
current app stores, along with automated analysis to prove
correctness with respect to the speciﬁcation. (3) Our ap-
proach works on source code rather than binaries and is
based on formal veriﬁcation rather than on bug-ﬁnding.
(4) We use a collaborative veriﬁcation methodology in
which the software vendor and the app store auditor each
do tasks that are easy for them, reducing overall cost.
We have implemented our system for Android apps
written in Java. In an adversarial Red Team evaluation,
we were given 72 apps (576,000 LOC) to analyze for
malware. The 57 Trojans among these had been written
speciﬁcally to defeat a malware analysis such as ours,
and the Red Teams had access to our source code and
documentation. Nonetheless, our information-ﬂow type
system was effective: it detected 96% of malware whose
malicious behavior was related to information ﬂow and
82% of all malware. In practice our toolset would be
combined with other analyses to reduce the chance of
approving a Trojan. The programmer annotation burden
is low: one annotation per 16 lines of code. Every sound
analysis requires a human to review potential false alarms,
and in our experiments, this took 30 minutes per KLOC
for an auditor unfamiliar with the app.
1 Introduction
App stores make it easy for users to download and run
applications on their personal devices. App stores also
provide a tempting vector for an attacker. An attacker can
take advantage of bugdoors (software defects that permit
undesired functionality) or can insert malicious Trojan
behavior into an application and upload the application to
the app store.
For current app stores, the software vendor typically up-
loads a compiled binary application. The app store then
analyzes the binary to detect Trojan behavior or other
1
information to both the analysis and the analyst.
Source code veriﬁcation is relevant for other domains
than high-integrity application stores. One public exam-
ple of inserting malicious behavior into an open source
program is an attempt to insert a backdoor in the Linux
kernel [24]. As another example, Liu et al. developed
proof-of-concept malware as Chrome extensions [26],
which are essentially distributed as source code. We be-
lieve that source code analysis for security will become
increasingly important, so it is worthy of attention from
security researchers.
1.2 Collaborative veriﬁcation model
The app store’s goal is twofold: to prevent approving
malicious applications, and to approve non-malware with
a minimum of cost and delay.
Most app store approval policies assume an adversarial,
or at least non-cooperative, relationship between the de-
veloper and the app store. The developer delivers an app
in binary form, and the app store uses an opaque process
to make a decision about whether to offer the app on the
app store.
We propose a collaborative model (Fig. 1) in which
the application vendor provides more information to the
auditor (an app store employee). This information is
easy for the application vendor to provide, but it would
be difﬁcult for the auditor to infer. The auditor is able to
make a decision more quickly and with greater conﬁdence,
which is advantageous to both parties.
As shown in Fig. 1, the auditor receives two artifacts
from the vendor. The ﬁrst vendor-provided artifact is
the ﬂow policy, a high-level speciﬁcation of the intended
information ﬂows in the program from the user point
of view. In our experiments, this averaged 6 lines long.
For example, it might state that location information is
permitted to ﬂow to the network and that camera images
may be written to the local disk. Any information ﬂow
not stated in the ﬂow policy ﬁle is implicitly forbidden.
The second vendor-provided artifact is the source code,
annotated to show which parts of the program implement
or participate in the information ﬂows. The annotation
burden is low: on average one annotation per 16 lines of
code.
The annotations are untrusted. Our information-ﬂow
type-checker, Information Flow Checker (IFC), automati-
cally ensures that the annotations are both permitted by
the ﬂow policy ﬁle and are an accurate description of the
source code’s behavior (modulo the trusted assumptions).
If not, the app is rejected. Thus, the application vendor
must provide accurate annotations and ﬂow policy.
The auditor has two tasks, corresponding to the two
vendor-provided artifacts. The ﬁrst task is to evaluate the
app’s ﬂow policy. This is a manual step, in which the
Figure 1: The collaborative veriﬁcation model. The ﬂow policy
is a high-level speciﬁcation that expresses application behavior
in terms of user-visible information ﬂows.
ables more accurate and powerful analyses, and enables
an auditor to evaluate warnings. (4) We propose a col-
laborative veriﬁcation methodology in which the vendor
participates in and contributes to the veriﬁcation process,
rather than casting the vendor and the app store in an
antagonistic relationship. Each party provides informa-
tion that is easy for them to provide, thus reducing the
overall cost of veriﬁcation. The developer is not trusted:
all information provided by the developer is veriﬁed.
We report on initial experience with this system, includ-
ing an adversarial Red Team exercise in which 5 corporate
teams (funded externally, not by us) were given insider
access to our source code and design documents then
tasked with creating Trojans that would be difﬁcult to
detect. Our type system detected 82% of the Trojans, and
96% of the Trojans whose malicious behavior was related
to information ﬂow. (We have identiﬁed an enhancement
to our system that would increase that number to 100%.)
It is necessary for a human to investigate tool warnings to
determine whether they are false positives. On average, it
took an auditor unfamiliar with the programs 30 minutes
per KLOC to analyze the information ﬂow policy and the
tool warnings. The annotation burden for programmers is
also low.
Overall, our goal is to make it difﬁcult to write Trojans
and easy to determine when code is not a Trojan. Our
tools cannot catch all malware, but they raise the bar for
malware authors and thus improve security.
1.1 Veriﬁcation of source code
An app store can be made more secure by requiring ven-
dors to provide their applications in source code, and
then performing strong veriﬁcation on that source code.
The app store would analyze the source code, compile
it, and distribute it as a binary (signed by the app store’s
private key) to protect the vendor’s intellectual property.
Availability of source code fundamentally changes the ap-
proval process in favor of veriﬁcation by providing more
2
!""#$%&%’()).java *+#,)-#+./0)!--)1%#2’)-#+./.’1)3’"(#2)-2#4.(’1)!--)1%#2’)-2#4.(’1)50-’$/6’/7’2)&8%#9&:/&++0)4’2.;’1#,)-#+./0)•!!""#%&:#"1)(’1/2.=’)/#(’)=’6&4.#2)?9#(8+#)%281%’()&1189-:#"1@)!--)1%#2’)’9-+#0’’)9&"8&++0)4’2.;’1<)•!!//’-%&=+’)=’6&4.#2)•!!1189-:#"1)&2’)4&+.()auditor compares the ﬂow policy ﬁle to the app’s docu-
mentation and to any app store or enterprise policies. The
app store analyst must approve that the requested ﬂows are
reasonable given the app’s purpose; apps with unreason-
able ﬂow policies are rejected as potential Trojans. The
second task is to verify each trusted assumption, using
the veriﬁcation methodology of his/her choice (e.g., [2]).
Sect. 3.11 further describes the auditing process.
Not every app store will desire to differentiate itself
through increased security, and not every vendor will
desire to participate in high-assurance app stores. But
market forces will enable such stores to exist where there
are appropriate economic incentives — that is, whenever
some organizations or individuals are willing to pay more
for increased security. Large organizations already require
their vendors to provide and/or escrow source code.
It makes economic sense for the vendor to annotate
their code and possibly to be paid a premium: based on
our experience, the effort is much less for the author of
the code than for an auditor who would have to reverse-
engineer the code before writing down the information
about the information ﬂows. The effort is small compared
to overall development time and is comparable to writing
types in a Java program. If the annotations are written
as the code is ﬁrst developed, they may even save time
by preventing errors or directing the author to a better
design.
The U.S. Department of Defense is also interested in
high-assurance app stores, for example through DARPA’s
“Transformative Apps” and “Automated Program Analysis
for Cybersecurity”, along with related software veriﬁca-
tion programs such as “High-Assurance Cyber Military
Systems” and “Crowd-Sourced Formal Veriﬁcation” Our
collaborative veriﬁcation model is novel and differs from
DARPA’s existing programs.
1.3 Threat model
While there are many different types of malicious ac-
tivities, we focus on Trojans whose undesired behavior
involves information ﬂow from sensitive sources to sensi-
tive sinks. This approach is surprisingly general: we have
found that our approach can be adapted to other threats,
such as detecting when data is not properly encrypted, by
treating encryption as another type of resource or permis-
sion.
More speciﬁcally, IFC uses the ﬂow policy as a spec-
iﬁcation or formal model of behavior. If IFC issues no
warnings, then the app does not permit information ﬂows
beyond those in the ﬂow policy — that is, each output
value is affected only by inputs speciﬁed in the ﬂow policy.
Manual checking is required for any trusted assumptions
or IFC warnings. IFC does not perform labor-intensive
full functional veriﬁcation, only information-ﬂow veriﬁ-
cation, which we show can be done at low cost.
Our threat model includes the exﬁltration of personal
or sensitive information and contacting premium services.
However, it does not cover phishing, denial of service, or
side channels such as battery drain or timing. It does not
address arbitrary malware (such as Slammer, Code Red,
etc.). We treat the operating system, our type checker, and
annotations on unveriﬁed libraries as trusted components
— that is, if they have vulnerabilities or errors, then an app
could be compromised even if it passes our type system.
App developers are not trusted.
Our approach is intended to be augmented by comple-
mentary research that focuses on other threats: it raises
the bar for attackers rather than providing a silver bullet.
Sect. 2.10 discusses limitations of our system in greater
detail.
There have been previous studies of the kinds of mal-
ware present in the wild [13, 52]. Felt et al. [13] classify
malware into 7 distinct categories based on behavior. Our
system can catch malware from the 4 most prevalent and
important ones: stealing user information (60%), pre-
mium calls or SMSs (53%), sending SMS advertising
spam (18%), and exﬁltrating user credentials (9%). The
other 3 categories are: novelty and amusement (13%),
search engine optimization (2%), ransom (2%).
1.4 Contributions
The idea of verifying information ﬂow is not new, nor is
using a type system. Rather, our contributions are a new
design that makes this approach practical for the ﬁrst time,
and realistic experiments that show its effectiveness. In
particular, the contributions are:
We have proposed a collaborative veriﬁcation model
that reduces cost and uncertainty, and increases security,
when approving apps for inclusion in an app store. Our
work explores a promising point in the tradeoff between
human and machine effort.
We have extended information-ﬂow veriﬁcation to a
real, unmodiﬁed language (Java) and platform (Android).
Our design supports polymorphism, reﬂection, intents,
defaulting, library annotations, and other mechanisms
that increase expressiveness and reduce human effort.
We have designed a mechanism for expressing infor-
mation ﬂow policies, and we have reﬁned the existing
Android permission system to make it less porous.
We have implemented our design in a publicly-
available system, and we have experimentally evaluated
our work. Our system effectively detected realistic mal-
ware targeted against it, built by skilled Red Teams with
insider knowledge of our system. The effort to use our
system was low for both programmers and auditors: it
is powerful, yet it requires less annotation overhead than
previous systems and is simpler to use and understand.
3
2 Information Flow Checker
This section describes our system Information Flow
Checker, IFC. IFC gives a guarantee that there are no in-
formation ﬂows in a program beyond those expressed in a