safe-shuffle 
In Section 4.1, we first discuss the problems with a straight-for-
ward but naive approach to enforcing spatial diversity in the exe-
cution of the leading and trailing threads. We then continue on in
Section 4.2.  to  describe  our 
shuffles  leading
instructions, borrowing dependence information from the leading
thread, to produce trailing instructions so that spatial diversity is
enforced  while  maintaining  program  correctness  in  the  trailing
thread. In Section 4.3, we describe execution of the trailing thread.
Finally, in Section 4.4, we discuss comparison of the leading and
trailing state, and how we verify the dependence information that
was passed from the leading thread to the trailing thread for safe-
shuffle. This verification is needed so that dependence information
corrupted by a hard error and propagated from the leading thread
to the trailing thread, does not result in the error going undetected. 
4.1 A Naive Approach
A naive approach to forcing the trailing instructions to use dif-
ferent pipeline resources from their leading counterparts, would be
to perform some sort of shuffling on the trailing thread. However,
there is no convenient point in the pipeline at which the trailing
instructions  can  be  shuffled.  One  option  is  to  do  the  shuffling
before rename, but then the trailing thread will not preserve depen-
dencies and will diverge from the leading thread, resulting in loss
of  redundancy.  A  second  option,  is  to  shuffle  after  rename  but
before dispatch (i.e., insertion into the issue queue as done in [9]),
but  this  introduces  two  problems:  (1)  Because  both  leading  and
trailing  threads  are  fetched  from  the  I-cache  and  the  instruction
location within a cache block does not change in leading and trail-
ing threads, both leading and trailing instructions would exercise
the same pipeline-frontend way resulting in zero coverage of the
frontend. (2) The issue queue may undo the shuffling and map the
trailing instructions to the same execution way as the correspond-
ing leading instruction. A third option is shuffling after issue but
this  would  require  updating  issue's  data  structures  to  reflect  the
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 05:37:04 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007 
modified  pipeline  resource  usage  (some  resources  in  use  upon
issue may not be in use upon shuffle, and vice versa). In addition,
although  there  are  enough  resources  to  issue  some  instructions,
spatial diversity may sometimes require that fewer instructions be
issued and the excess be held back. The issue-queue updating and
excess handling would severely complicate the pipeline. The final
option is for shuffle to occur in the timing-critical issue. In this
option, the select logic has to ensure that there is no excess due to
shuffling,  in  addition  to  the  usual  constraints. And  the  mapping
logic has to ensure that spatial diversity is maintained, in addition
to  the  usual  constraints.  These  additional  requirements  would
severely complicate issue.
The  following  sections  contain  descriptions  in  detail  of  how
instructions  are  fetched  out-of-order,  shuffled,  and  checked  at
commit. This  detail  should  not  be  misinterpreted  as  complexity.
Many  common  superscalar  techniques  (e.g.,  renaming)  would
seem complex if described at such fine detail. In addition, Black-
Jack has been carefully designed that all new hardware is off the
critical  path.  Seemingly  simpler  options,  which  we  describe
above, that can not be moved off the critical path will have severe
impact on performance. 
4.2 Safe-Shuffle 
Because we want to cover both the frontend and backend it is
necessary  that  shuffling  be  done  before  the  fetch  of  the  trailing
thread.  Here  we  address  the  problem  that  instruction  dependen-
cies, needed to guarantee the correctness of such shuffling, have
not yet been determined. 
There seems to be a catch-22 that prevents us from covering
the  frontend:  we  cannot  shuffle  the  instructions  without  first
knowing the dependencies among the instructions to be shuffled,
but we cannot know the dependencies without fetching the instruc-
tions in the original program order, yet we cannot fetch the instruc-
tions in program order if we want to cover the frontend. We make
the key observation that because we are executing the same pro-
gram redundantly in the leading and trailing threads and because
there is a slack between the threads, the leading thread has already
determined the dependencies before the trailing execution begins.
Accordingly, in safe-shuffle we borrow the dependence informa-
tion from the leading thread to allow shuffling before the trailing
thread is fetched. 
We implement safe-shuffle in a two-phase process: In the first
phase, we collect information on the leading instructions’ indepen-
dence, rename maps (i.e., logical to physical register maps), and
pipeline-resource-usage. In the second phase, we use the indepen-
dence  and  resource-usage  information  to  shuffle  the  leading
instructions  for  producing  the  trailing  thread  that  is  spatially
diverse  from  the  leading  thread.  Shuffling  produces  the  trailing
thread in the leading thread’s 
. Though issue order pre-
serves true dependencies, it removes false dependencies and over-
laps multiple live ranges of the same logical register. Fortunately,
the leading rename maps correctly identify the live ranges, allow-
ing  the  trailing  thread  to  maintain  program  correctness.  We
describe  the  first  phase  in  Section 4.2.1,  and  the  second  in
Section 4.2.2. 
4.2.1 Collecting Independence Information
issue order
Our  technique  relies  on  the  observation  that  instructions  co-
 cycle are independent and can be shuffled with-
issued in the 
same
out causing correctness problems. As such we use the execution of
packet
the leading thread to record co-issued instructions, called a 
,
and also the pipeline resources used by the instructions and their
rename maps. We collect this information in a simple queue called
the Dependence Trace Queue (DTQ). Each entry contains infor-
mation for one issued leading instruction and the entries are allo-
cated for all issued leading instructions 
. The order
that  entries  are  allocated 
  a  packet  can  be  arbitrary.  The
instructions collect information during execution and record infor-
mation at commit. 
in issue order
within
Leading  instructions  in  a  packet  are  allocated  consecutive
entries, and the last instruction in the packet has a bit set to demar-
cate the end of the packet. Because the allocation of DTQ entries
need be completed only before writeback, the allocation need not
be done in the timing-sensitive select and map logic. When lead-
ing  instructions  are  in  the  pipeline  they  record,  and  carry  with
them until commit, two IDs to identify the pipeline resources that
the instructions used. One ID specifies the frontend-way, and the
other  specifies  the  backend-way. The  instructions  also  carry  the
logical to physical register maps for their source and destination
operands. Upon commit, the leading instruction records its unde-
coded
instruction, its rename maps, and its frontend and backend
IDs in its DTQ entry. Because the DTQ holds only the committed
leading  instructions  (albeit  in  issue  order)  which  are  shuffled  to
produce  the  trailing  thread,  our  trailing  thread  does  not  execute
any misspeculated instructions, as is the case in SRT. 
While the leading thread’s issue order helps us implement safe-
shuffle, we also need the leading thread’s program order to keep
trailing loads and stores in program order in the load/store queue
of the trailing thread’s context, and to commit the trailing thread.
Because the trailing thread is fetched from the DTQ, which is in
issue order and not program order, we also need to record the lead-
ing thread’s program order. One method for recording this order-
ing  would  be  to  actually  allocate  trailing  thread  active  list  and
load/store queue entries in the trailing thread context when each
leading instruction commits, which is well before the correspond-
ing  trailing  instruction  is  fetched.  Such  early  allocation  would
mean that idle instructions in the slack would be consuming trail-
ing thread resources and consequently, slack would be limited by
the  size  of  the  trailing  context  load/store  queue  (which  is  the
smaller of active list and load/store queue). Instead, we allocate
virtual  active  list  and  load/store  queue  entries  at  leading  thread
commit to record the ordering without requiring that instructions
in the slack are actually assigned to any trailing thread resources.
We store these allocations in the DTQ as well. 
Thus,  we  have  borrowed  the  leading  thread’s  issue  order,
rename maps, and program order. Later we will describe how we
verify the correctness of this borrowed data to ensure that a single
error that corrupts both threads identically is still caught. 
4.2.2 Using Independence to Shuffle 
While the leading thread places its packets in the DTQ, shuffle
waits for the packets to reach commit and then shuffles the instruc-
tions 
  a  packet,  one  packet  at  a  time,  producing  shuffled
packets that will be fetched by the trailing thread. 
within
To enforce spatial diversity, Shuffle must satisfy the following
two constraints. First, when the packet is fetched by the trailing
thread, each instruction in the packet must map to a different fron-
tend than was used by the corresponding leading instruction. Sec-
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 05:37:04 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007 
all
no other
 the instructions in the packet are co-issued together in
ond, if 
the same cycle in the trailing thread and 
 (leading or trail-
ing)  instruction  is  co-issued  (Section 4.3.2  describes  why  these
conditions may not be met and what happens then), each trailing
instruction must be issued to a different backend than was used by
the corresponding leading instruction. Therefore, shuffle cannot be
random,  must  be  aware  of  the  policies  used  by  both  fetch  and
instruction map, but can work with any policy as long as the policy
is deterministic. 
We  assume  the  following  policies,  which  afford  the  most
straightforward  implementation  and  are  consequently  the  most-
commonly  used:  direct  mapping  policy  for  fetch  where  the  first
instruction  in  fetch  order  goes  to  first  frontend  way,  the  second
instruction to the second frontend way and so on, and oldest-first
mapping policy for instruction select and map, where the oldest
instruction  goes  to  the  first  free  backend  way  that  matches  the
instructions’ type (e.g., ALU, memory, or branch type), the second
oldest instruction to the second matching backend way and so on. 
With the above policies, if shuffle produces a (shuffled) packet
whose instructions are fetched and co-issued meeting the second
constraint’s conditions, then the packet’s first instruction is guar-
anteed to use the first frontend way and the first matching backend
way, the second instruction is guaranteed to use the second fron-
tend way and the first of the remaining matching backend ways
and  so  on.  Consequently,  to  meet  the  above  two  constraints  for
spatial diversity, Shuffle need only determine an ordering so that
each trailing instruction in a packet uses a different frontend way
and different backend way than the ways used by the correspond-
ing leading instruction. 
To prevent issue and fetch from undoing our shuffle when there
are fewer instructions in a packet than the issue width, we allow
shuffle to insert NOPs. We require that the NOPs remain in the
pipeline  through  writeback  (i.e.,  each  NOP  occupies  a  frontend
and backend way and an issue-queue slot). 
We  use  the  following  simple,  greedy  algorithm  which  works
well in most cases. The algorithm shuffles an input packet into an
output packet. Each instruction in the input packet (in any arbi-
trary order) grabs the first free output-packet slot that is spatially
diverse from the corresponding leading instruction (i.e., does not
map to either the frontend or backend way used by the correspond-
ing leading instruction). At a given output-packet slot, the instruc-
tion’s new frontend way is easy to determine whereas the backend
way is a little more involved: The instruction’s new frontend way
is the output-packet slot number, and the new backend way is the
number of instructions in the packet that have already been allo-
cated to lower slot numbers and use the same type of backend way.
The given output-packet slot is acceptable if the new ways are spa-
tially  diverse  from  the  leading  instructions.  If  allocation  of  an
instruction  passes  over  an  empty  output-packet  slot  that  the
instruction cannot use because the slot maps to the corresponding
leading instruction’s frontend or backend way, the instruction puts
an NOP in the slot and marks the slot with the instruction’s type. 
The process continues with each instruction in the input packet
attempting to grab a free output-packet slot. If an instruction finds
an  acceptable  slot  containing  a  NOP  marked  with  a  matching
instruction type, the instruction can claim the slot and replace the
NOP. This replacement is what allows two instructions of the same
type to swap backend ways as depicted in Figure 2. NOPs created
by one type cannot be replaced by an instruction of another type
inst A Front 0 Back 0
NOP
inst A Front 0 Back 0
inst BFront 1 Back 1
inst BFront 1 Back 1
inst A Front 0 Back 1
slot #
0
1
2
3
0
1
2
3
FIGURE 2: Safe-shuffle swapping resource 
allocations of two like instructions. 
because doing so may require correcting (decrementing, to be pre-
cise) the backend mappings of some previously-allocated instruc-
tions  (those  whose  backend  way  is  larger  than  that  of  the  NOP
being replaced). Such correction would not fit the greedy nature of
the  algorithm  and  would  complicate  the  algorithm.  There  will
never  be  fewer  output-packet  slots  than  instructions  if  the  issue
width  matches  the  frontend  width.  However,  there  may  be  slots
with  NOPs  that  cannot  be  replaced  by  later  instructions  either
because  the  slot  is  not  spatially  diverse  from  the  corresponding
leading instruction or because the NOPs are allocated by a differ-
ent instruction type. If an instruction cannot find a slot, the output
packet is ended and the remaining instructions of the input packet
start a new output packet (the input packet gets broken into two or
more output packets). Breaking an input packet reduces parallel-
ism and its impact on performance is discussed in Section 6.
Because of SRT’s long slack, there are many cycles between
commit of the leading thread and fetch by the trailing thread. Con-
sequently, there is ample time to perform the shuffling, which, if
needed, may be pipelined over multiple cycles. 
The  output  packets  are  placed  in  the  trailing  thread’s  fetch
queue. Because the input packets come from the DTQ and shuf-
fling shuffles only the instructions 
 an input packet, the fetch
queue inherits DTQ’s leading-thread issue order 
4.3 Trailing Thread Execution
4.3.1 Frontend
 packets. 
across
within
The trailing thread fetches the shuffled packets from its fetch
queue  according  to  SRT’s  slack  (Section 3)  as  depicted  in
Figure 3. When given fetch bandwidth, the trailing thread fetches
one packet each cycle. Because of the direct mapping of instruc-
tion fetch to frontend ways, each instruction maps to the frontend
way as intended by safe-shuffle and continues on to be decoded on
different  hardware  than  was  used  to  decode  the  corresponding
leading instruction. 
It is important to note that the trailing-thread fetch is limited to
fetch only one packet per cycle even if the packet is smaller than
the fetch width of the pipeline. If multiple packets were fetched in
one  cycle,  then  the  mapping  of  the  packets’  instructions  to  the
frontend ways may be different than that intended by safe-shuffle,
resulting in loss of spatial diversity. While this restriction ensures
frontend spatial diversity, it potentially lowers the trailing thread’s
fetch bandwidth, degrading performance. 
The  trailing  thread  is  fetched  in  leading  thread’s  issue  order,
which  while  preserving  true  dependencies  removes  false  depen-
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 05:37:04 UTC from IEEE Xplore.  Restrictions apply. 
37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07)0-7695-2855-4/07 $20.00  © 2007i
g
n
d
a
e
L
g
n
i
l
i
a
r
T
Icache Block
F 
F 
F 
F 
D R
D R
D R
D R
I
R
R
R
R
E M
E M
E M
E M
W C
W C
W C
W C
Shuffle
DTQ
FIGURE 3: BlackJack Execution Flow. 
logical
dencies and overlaps multiple live ranges of the same logical reg-
ister. Because of this overlap, the trailing thread renamer cannot
correctly connect consumers to their producers by looking only at
the 
 registers of the instructions. Fortunately, leading thread
rename maps can make this connection. Accordingly, the trailing
thread  renamer  uses  the  leading  thread’s  physical  registers
(sources and destination) as input, instead of the usual logical reg-
isters. That  is,  the  trailing  thread  renamer  renames  the  renamed
leading  instructions!  Though  this  double  renaming  allows  us  to
cover  the  frontend  while  preserving  program  correctness,  the
downside is that our rename tables have more rows because there
are more physical registers than logical registers. 
While there is also an issue with determining in rename which
physical register each instruction should free, the actual freeing is
done at commit, and we address the issue there.
Because the trailing thread fetches from its fetch queue without
any branch prediction, the fact that branches appear in issue order
(i.e., out of program order) in the trailing thread does not matter.
Branches simply flow through the pipeline and execute. We use
their execution to verify the trailing-thread program order which is
borrowed from the leading thread. 
Once  decoded  we  use  the  virtual  active  list  and  load/store
queue  specifiers  in  the  DTQ  (Section 4.2.1)  to  allocate  corre-
sponding physical entries for each fetched instruction. We trans-
late these virtual specifiers to physical load/store queue and active
list entries by keeping the virtual to physical mapping for the head
of the physical structures as a reference. Any virtual index which
j
is 
  greater  than  the  head’s  virtual  index  is  allocated  a  physical
index 
is larger than the size of the struc-
ture, then the frontend is stalled till there is space in the structure.
Combined  with  out-of-order  fetch,  this  allocation  means  that
instructions that are fetched earlier than their commit order will
allocate physical entries leaving the appropriate number of empty
slots ahead of them. 
4.3.2 Dispatch/Issue
away from the head. If
 j 
j 
After rename, register tags correctly encode instruction depen-
dencies and instructions move on to be dispatched into the issue