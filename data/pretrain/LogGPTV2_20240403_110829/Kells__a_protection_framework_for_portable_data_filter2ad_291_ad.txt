No veriﬁcation
1 second veriﬁcation
2 second veriﬁcation
5 second veriﬁcation
10 second veriﬁcation
Run
(secs)
36.1376
36.5768
36.6149
36.3143
36.2113
Read
Throughput
(MB/sec)
14.196
14.025
14.011
14.127
14.167
Overhead
N/A
1.22%
1.32%
0.49%
0.20%
Run
(secs)
35.4375
36.4218
35.9895
35.7969
35.7353
Write
Throughput
(MB/sec)
5.6437
5.4912
5.5572
5.5871
5.5967
Overhead
N/A
2.78%
1.56%
1.01%
0.84%
Table 2: Kells performance characteristics – average throughput over bulk read and write operations
GoodState(H, (t, treq, (l, n)), (tatt, sig)) =
Fresh(t, treq, tatt)
∧ v = Verify((tatt, sig), AIK(H))
∧ Match(v, criteria)
Figure 13: Deﬁnition of Goodstate property.
Fresh (t, treq, tatt) =
(tatt < treq ∧ treq − tatt < ∆t)
∨ (treq < tatt ∧ ¬Reset(H) on [t, ρ])
Figure 14: Deﬁnition of Fresh property.
OMAP3530 processor, which contains a 600 MHz ARM Cortex-
A8 core, along with 128 MB of RAM and 128 MB of NAND ﬂash
memory. An SD card interface provides storage and, most impor-
tantly for us, the board supports a USB 2.0 On-the-Go interface
attached to a controller allowing device-mode operation. The de-
vice runs an embedded Linux Angstrom distribution with a modi-
ﬁed 2.6.28 kernel. Note that an optimized board could be capable
of receiving its power from the bus alone. The TI OMAP-3 pro-
cessor’s maximum power draw is approximately 750 mW, while a
USB 2.0 interface is capable of supplying up to 500 mA at 5 V, or
2.5 W. The recently introduced USB 3.0 protocol will be even more
capable, as it is able to supply up to 900 mA of current at 5 V.
Depicted in Table 2, our ﬁrst set of experiments sought to deter-
mine the overhead of read operations. Each test read a single 517
MB ﬁle, the size of a large video, from the Kells device. We varied
the security parameter ∆t (the periodicity of the host integrity re-
validation) over subsequent experiments, and created a baseline by
performing the read test with a unmodiﬁed DevKit 8000 USB de-
vice and Linux kernel. All statistics are calculated from an average
of 5 runs of each test.
As illustrated in the table, the read operation performance is
largely unaffected by the validation process. This is because the
host preemptively creates validation quotes and delivers them to
the device at or about the time a new one is needed (just prior to a
previous attestation becoming stale). Thus, the validation process
is mostly hidden by normal read operations. Performance, how-
ever, does degrade slightly as the validation process occurs more
frequently. At about the smallest security parameter supportable
by the TPM hardware (∆t = 1 second), throughput is reduced by
only 1.2%, and as little as 0.2% at 10 seconds. This overhead is
due largely to overheads associated with receiving and validating
the integrity proofs (which can be as large as 100KB).
Also depicted in Table 2, the second set of tests sought to charac-
terize write operations. We performed the same tests as in the read
experiments, with the exception that we wrote a 200MB ﬁle. Write
operations are substantially slower on ﬂash devices because of the
underlying memory materials and structure. Here again, the write
stix Overo device. Future work will consider how these devices
may change our performance characteristics.
operations were largely unaffected by the presence of host valida-
tion, leading to a little less than 3% overhead at ∆t = 1 second
and just under 1% at 10 seconds.
Note that the throughputs observed in these experiments are sub-
stantially lower than USB 2.0 devices commonly provide. USB
2.0 advertises maximal throughput of 480Mbps, with recent ﬂash
drives advertising as much as 30MB/sec. All tests are performed on
our proof of concept implementation on the experimental apparatus
described above, and are primarily meant to show that delays are
acceptable. Where needed, a production version of the device and
a further optimized driver may greatly reduce the observed over-
heads. Given the limited throughput reduction observed in the test
environment, we reasonably expect that the overheads would be
negligible in production systems.
7. RELATED WORK
The need to access storage from portable devices and the secu-
rity problems that consequently arise is a topic that has been well
noted. SoulPad [4] demonstrated that the increasing capacity of
portable storage devices allows them to carry full computing stacks
that required only a platform to execute on. DeviceSniffer [35]
further considered a portable USB device that allowed a kiosk to
boot, where the software on the drive provides a root of trust for
the system. As additional programs are loaded on the host, they
are dynamically veriﬁed by the device through comparison with an
on-board measurement list. This architecture did not make use of
trusted hardware and is thus susceptible to attacks at the BIOS and
hardware levels. The iTurtle [17] was a proposal to use a portable
device to attest the state of a system through a USB interface. The
proposal made the case that load-time attestations of the platform
was the best approach for veriﬁcation. This work was exploratory
and postulated questions rather than providing concrete solutions.
further explored these concepts to use a mobile
device to ensure the security of the underlying platform, using it
as a kiosk on which to run virtual machines [10] and providing a
framework for trusted boot. This work makes different assumptions
about how portable devices provide a computing environment; in
the proposed model, a mobile phone is used as authenticator, rely-
ing on a barcode attached to the platform transmitted wirelessly to
the device. Because the veriﬁer is not a storage device, the virtual
machine to be run is encrypted in the cloud.
Garriss et al.
Others have considered trusted intermediaries that establish a
root of trust external to the system, starting with Honeywell’s Project
Guardian and the Scomp system, which provided a secure front-end
processor for Multics [8]. SIDEARM was a hardware processor
that ran on the LOCK kernel, establishing a separate security en-
forcement point from the rest of the system [31]. The ﬁrst attempt
to directly interpose a security processor within a system was the
Security Pipeline Interface [12], while other initiatives such as the
Dyad processor [40] and the IBM 4758 coprocessor [7] provided
a secure boot. Secure boot was also considered by Arbaugh et al.,
whose AEGIS system allows for system startup in the face of in-
239tegrity failure. Numerous proposals have considered how to attest
system state. SWATT [27] attests an embedded device by verifying
its memory through pseudorandom traversal and checksum com-
putation. This requiers veriﬁer to fully know the memory contents.
Recent work has shown that SWATT may be susceptible to return-
oriented rootkits [5] but this work itself is subject to assumptions
about SWATT that may not be valid. Similarly, Pioneer [26] en-
ables software-based attestation through veriﬁable code execution
by a veriﬁcation function, reliant on knowledge of the veriﬁed plat-
form’s exact hardware conﬁguration. A study of Pioneer showed
that because it is based on noticing increases in computation time
in the event of code modiﬁcation, a very long execution time is
required in order to ﬁnd malicious computation as CPU speeds in-
crease [9]. Software genuinity [14] proposed relying on the self-
checksumming of code to determine whether it was running on a
physical platform or inside a simulator; however, Shankar et al.
showed problems with the approach [29].
Augmenting storage systems to provide security has been a topic
of sustained interest over the past decade. Initially, this involved
network-attached secure disks (NASD) [11], an infrastructure where
metadata servers issue capabilities to disks augmented with proces-
sors. These capabilities are the basis for access control, requiring
trust in servers external to the disk. Further research in this vein
included self-securing storage [34], which, along with the NASD
work, considered object-based storage rather than the block-based
approach that we use. Pennington et al. [21] considered the disk-
based intrusion detection, requiring semantically-aware disks [30]
for deployment at the disk level.
8. CONCLUSION
In this paper, we presented Kells, a portable storage device that
validates host integrity prior to allowing read or write access to its
contents. Access to trusted partitions is predicated on the host pro-
viding ongoing attestations as to its good integrity state. Our proto-
type demonstrates that overhead of operation is minimal, with a re-
duction in throughput of 1.2% for reads and 2.8% for writes given a
one-second periodic runtime attestation. Future work will include a
detailed treatment of how policy may be enforced in an automated
way between trusted and untrusted storage partitions, and further
interactions with the OS in order to support and preserve properties
such as data provenance and control of information ﬂow.
9. REFERENCES
[1] IronKey. http://www.ironkey.com, 2009.
[2] K. Butler, S. McLaughlin, T. Moyer, J. Schiffman, P. McDaniel, and
T. Jaeger. Firma: Disk-Based Foundations for Trusted Operating
Systems. Technical Report NAS-TR-0114-2009, Penn State Univ.,
Apr. 2009.
[3] K. R. B. Butler, S. McLaughlin, and P. D. McDaniel.
Rootkit-Resistant Disks. In ACM CCS, Oct. 2008.
[4] R. Cáceres, C. Carter, C. Narayanaswami, and M. Raghunath.
Reincarnating PCs with portable SoulPads. In ACM MobiSys, 2005.
[5] C. Castelluccia, A. Francillon, D. Perito, and C. Soriente. On the
difﬁculty of software-based attestation of embedded devices. In ACM
CCS, Nov. 2008.
[6] A. Datta, J. Franklin, D. Garg, and D. Kaynar. A Logic of Secure
Systems and its Application to Trusted Computing. In IEEE Symp.
Sec. & Priv., May 2009.
[7] J. G. Dyer, M. Lindermann, R. Perez, et al. Building the IBM 4758
Secure Coprocessor. IEEE Computer, 39(10):57–66, Oct. 2001.
[8] L. J. Fraim. Scomp: A solution to the multilevel security problem.
IEEE Computer, 16(7):26–34, July 1983.
[9] R. Gardner, S. Garera, and A. D. Rubin. On the difﬁculty of
validating voting machine software with software. In USENIX EVT,
Aug. 2007.
[20] B. Parno. Bootstrapping trust in a "trusted" platform. In USENIX
Attestation. In ACSAC, 2009.
HotSec, Aug. 2008.
[10] S. Garriss, R. Cáceres, S. Berger, R. Sailer, L. van Doorn, and
X. Zhang. Trustworthy and personalized computing on public kiosks.
In ACM MobiSys, June 2008.
[11] G. A. Gibson, D. F. Nagle, K. Amiri, et al. A Cost-Effective,
High-Bandwidth Storage Architecture. In ASPLOS, 1998.
[12] L. J. Hoffman and R. J. Davis. Security Pipeline Interface (SPI). In
ACSAC, Dec. 1990.
[13] B. Kauer. OSLO: Improving the Security of Trusted Computing. In
Proc. USENIX Security Symp., Aug. 2007.
[14] R. Kennell and L. H. Jamieson. Establishing the Genuinity of Remote
Computer Systems. In Proc. USENIX Security Symp., Aug. 2003.
[15] Kingston Technology. DataTraveler 300: World’s ﬁrst 256 GB Flash
drive. http://www.kingston.com/ukroot/flash/dt300.asp, July 2009.
[16] C. Lomax. Security tightened as secretary blamed for patient data
loss. Telegraph & Argus, 4 June 2009.
[17] J. M. McCune, A. Perrig, A. Seshadri, and L. van Doorn. Turtles all
the way down: Research challenges in user-based attestation. In
USENIX HotSec, Aug. 2007.
[18] Microsoft. BitLocker and BitLocker to Go.
http://technet.microsoft.com/en-us/windows/dd408739.aspx, Jan. 2009.
[19] T. Moyer, K. Butler, J. Schiffman, et al. Scalable Web Content
[21] A. G. Pennington, J. D. Strunk, J. L. Grifﬁn, et al. Storage-based
Intrusion Detection: Watching storage activity for suspicious
behavior. In Proc. USENIX Security, 2003.
[22] P. Porras, H. Saidi, and V. Yegneswaran. An Analysis of Conﬁcker’s
Logic and Rendezvous Points. Technical report, SRI Computer
Science Lab, Mar. 2009.
[23] R. Sailer, X. Zhang, T. Jaeger, and L. van Doorn. Design and
Implementation of a TCG-based Integrity Measurement
Architecture. In Proc. USENIX Security, Aug. 2004.
[24] SanDisk. SanDisk Cruzer Enterprise. http://www.sandisk.
com/business-solutions/enterprise, 2009.
[25] Seagate. Self-Encrypting Hard Disk Drives in the Data Center.
Technology Paper TP583.1-0711US, Nov. 2007.
[26] A. Seshadri, M. Luk, E. Shi, et al. Pioneer: verifying code integrity
and enforcing untampered code execution on legacy systems. In
ACM SOSP, 2005.
[27] A. Seshadri, A. Perrig, L. van Doorn, and P. Khosla. SWATT:
SoftWare-based ATTestation for Embedded Devices. In IEEE Symp.
Sec.& Priv., May 2004.
[28] N. Shachtman. Under Worm Assault, Military Bans Disks, USB
Drives. Wired, Nov. 2008.
[29] U. Shankar, M. Chew, and J. D. Tygar. Side Effects are Not Sufﬁcient
to Authenticate Software. In Proc. USENIX Security, 2004.
[30] M. Sivathanu, V. Prabhakarn, F. I. Popovici, et al.
Semantically-Smart Disk Systems. In USENIX FAST, 2003.
[31] R. E. Smith. Cost proﬁle of a highly assured, secure operating
system. ACM Trans. Inf. Syst. Secur., 4(1):72–101, 2001.
[32] SRN Microsystems. Trojan.adware.win32.agent.bz. http:
//www.srnmicro.com/virusinfo/trj10368.htm, 2009.
[33] L. St. Clair, J. Schiffman, T. Jaeger, and P. McDaniel. Establishing
and Sustaining System Integrity via Root of Trust Installation. In
ACSAC, 2007.
[34] J. Strunk, G. Goodson, M. Scheinholtz, et al. Self-Securing Storage:
Protecting Data in Compromised Systems. In USENIX OSDI, 2000.
[35] A. Surie, A. Perrig, M. Satyanarayanan, and D. J. Farber. Rapid trust
establishment for pervasive personal computing. IEEE Pervasive
Computing, 6(4):24–30, Oct.-Dec. 2007.
[36] TCG. TPM Main: Part 1 - Design Principles. Speciﬁcation Version
1.2, Level 2 Revision 103. TCG, July 2007.
[37] TCG. TCG Storage Security Subsystem Class: Opal. Speciﬁcation
Version 1.0, Revision 1.0. Trusted Computing Group, Jan. 2009.
[38] T. Weigold, T. Kramp, R. Hermann, et al. The Zurich Trusted
Information Channel – An Efﬁcient Defence against
Man-in-the-Middle and Malicious Software Attacks. In Proc.
TRUST, Villach, Austria, Mar. 2008.
[39] R. Wojtczuk and J. Rutkowska. Attacking Intel Trusted Execution
Technology. In Proc. BlackHat Technical Security Conf., Feb. 2009.
[40] B. Yee and J. D. Tygar. Secure Coprocessors in Electronic Commerce
Applications. In Proc. USENIX Wrkshp. Electronic Commerce, 1995.
240