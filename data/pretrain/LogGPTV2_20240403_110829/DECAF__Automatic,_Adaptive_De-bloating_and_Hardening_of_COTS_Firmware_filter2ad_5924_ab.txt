implementation of it in Section 4.3.
3 Pruning Strategy
3.1 Considerations
The selection of a pruning strategy should have two primary
concerns: its runtime and the quality of the results it produces.
The property of a particular pruning strategy that most af-
fects runtime is the number of test iterations that must be
performed. The time required to perform a single test of a par-
ticular pruned state is on the order of minutes, so exhaustive
searches simply aren’t feasible.
As for quality, the number of modules removed is the metric
most directly affected by choice of strategy; any strategy will
remove one module at a time, and the order in which modules
are removed determines how many modules are kept, due
to the nature of inter-module dependencies. Therefore, the
primary metric considered when comparing the results of
different strategies is the number of modules removed. In
Section 3.3, we discuss how other metrics, such as ﬁnal image
size and boot time can be incorporated as search heuristics,
and in some cases may even lead to a reduction in runtime.
In Section 3.2, we present a few different representations
of the search problem, considering factors such as module
inter-dependency and the percentage of modules that can suc-
cessfully be removed from the ﬁrmware. We then compare
the average number of attempts performed and modules re-
moved by a few natural pruning strategies and use the results
to design a suitable pruning workﬂow.
3.2 Comparison of Existing Strategies
Assuming each trial takes a constant amount of time, the
performance of any pruning strategy is proportional to the
number of tests that must be performed.
One could consider subset-based reduction approaches like
those used in delta debugging [46]. Delta debugging is typi-
cally used to ﬁnd bugs rather than minimize software, how-
ever the principle is applicable to minimization. Delta debug-
ging works by ﬁnding the "deltas"–lines changed, functions
added/removed, etc.–between a program that passes a test and
one that fails. The deltas are then recursively divided into sub-
sets and tested in order to ﬁnd a minimal set of deltas required
to get the failing program to pass. In the context of DECAF,
the passing program would be the original ﬁrmware image,
the failing program would be an empty ﬁrmware image, and
the deltas would be the UEFI modules.
However, these approaches rely on spatial coherence in
the input, which in this case is a set of ﬁles in the ﬁrmware
volume whose order have no real correlation to their remov-
ability. Delta debugging works best on well-structured inputs,
and most approaches that utilize it rely on improving the co-
herency of the structure through high-level analysis [28] [40].
Another natural approach is to use a hill-climbing type
algorithm that seeks to incrementally improve an existing
solution by removing more modules and backtracking on
failures. Hill-climbing can easily be used to incrementally
improve the results of other strategies.
Another approach that will be considered as a baseline is
to incrementally build a removal set R, initially empty. We
consider one module m at a time, and if m +R can be removed,
we add m to R. We call this strategy linear removal.
As discussed in Section 2.3, some UEFI modules depend on
others. The dependency graphs are Directed Acyclic Graphs
(DAGs). The structure of the graphs themselves is not very
interesting; they are simply very dense graphs. A few mod-
ules are referenced by nearly all others, and a few have no
edges. However, the presence of these dependencies affects
the runtime and removal level of the previously described
strategies differently.
Consider Figure 2 where the dependency connectivity q
is varied. q refers to a number of DAG edges to be selected
randomly between the p removable modules. Assuming that
roughly 60% of the ﬁrmware modules are removable, it can
be observed that as expected, hill-climbing is able to fully
prune the ﬁrmware regardless of the module connectivity, and
the performance of the linear removal and delta debugging
approaches is inversely proportional to q.
In order to achieve similar levels of module removal, linear
removal methods could take on one of two approaches. They
could repeat until the dependency tree is fully unwound, rais-
ing the complexity on an order of magnitude relative to the
height of the DAG, or they could perform a linear removal
to remove obvious candidates, followed by hill-climbing to
1716    29th USENIX Security Symposium
USENIX Association
clean up the rest of the removable tree.
Figure 2: Average Number of Modules Removed with p=180
Modules Removable of n=300 Modules and Varying
Dependency Connectivity (q)
Figure 3: Average Number of Required Tests to Remove p of
n=300 Modules with Connectivity q=25
Using an estimated value of q = 25 for the connectivity,
a comparison of hill-climbing and linear removal with hill
climbing methods can be seen in Figure 3. The linear removal
with hill climbing is favored because repeatedly applying a lin-
ear removal approach results in repeated, redundant re-testing
of modules that cannot be removed, while hill-climbing opti-
mizes against re-selecting these modules.
3.3 Search Heuristics
Since exhaustive searches are infeasible, DECAF makes use
of search heuristics: each module is assigned a weight that is
updated throughout the runtime of the pipeline.
One can imagine a number of search heuristics that can
be used to improve the runtime or results of a given pruning
strategy. For example, if reduction of the overall image size
is a primary goal, one can assign a higher removal chance
to large ﬁrmware modules. If instead reducing the boot time
of the ﬁnal image is desirable, a module can be assigned a
higher removal chance if removing it is observed to lower the
boot time. This heuristic has the added beneﬁt of reducing
the time for a single trial, reducing overall runtime. Another
potentially interesting heuristic would be one that runs some
form of static analysis on the modules prior to pruning, giving
a high removal chance to modules that are likely to contain
some kind of bug or exploitable code.
One heuristic used to great effect in DECAF involves run-
time UEFI module dependency. As described in 4.3, we inject
two modules into the ﬁrmware image before the pruning pro-
cess that report which modules install which protocols, and
which modules subsequently look up those protocols during
the boot process. This information can be useful in several
ways. For example, a module with no dependencies may be
assigned a high removal chance, while a module with many
dependencies may receive a low one.
DECAF also halves the chance of a module being removed
if a removal set including that module fails to pass the valida-
tion targets. The assumption is that modules that have failed
previously are more likely to fail again. The intuition is as fol-
lows: a module can fail to be removed because (1) it directly
provides functionality needed to boot the image or satisfy the
validation targets or (2) its removal causes another module to
fail, either preventing the image from booting or producing
different validation results. If a module fails because it meets
criteria (1), it will always fail. The potential for a module
to fail because of reason (2) is mitigated by the dependency
analysis and unwinding discussed Section 4.3.
3.4 The DECAF Pruning Strategy
DECAF deploys a single linear pass followed by a few rounds
of hill-climbing, as it produces the best performance for
ﬁrmware that roughly conforms to the model in which mod-
ules are either: removable, not removable, or removable if all
of their dependencies are removed.
The workﬂow is aimed at ﬁnding a minimal image that
passes validation targets. This is done by iterating across
conﬁgurations of the search space until no further changes
can be made (any change would cause validation tests to fail).
The ﬁrst iteration of the pipeline, performed on the vanilla
image (empty removal set) will perform several extra steps:
1. Determine board manufacturer and conﬁgure various
parameters (MAC/IP addresses, login credentials, etc)
2. Boot into an OS with the unmodiﬁed image and deter-
mine the hardware conﬁguration (initial run for valida-
tion component).
3. Inject the dependency discovery modules (further de-
scribed in Section 4.3) and generate the dependency
graph based on runtime analysis.
USENIX Association
29th USENIX Security Symposium    1717
After these tasks are completed, the pruning process can
start. Having the dependency information, the removal proba-
bilities are initialized. Initially, all modules are equally likely
to be selected, excepting those that are present in the depen-
dency graph. Modules that are part of the dependency graph
have a smaller initial removal chance than the rest. The set of
modules is then split in half recursively until the set contains
only one module, at which point module removal is attempted.
Every iteration involves ﬂashing the image to the mother-
board, powering the motherboard, waiting for the OS to boot,
and running the validation targets. If, at any point, a failure
is encountered, the corresponding module’s chance of being
removed again is decreased by half.
After the modules are tried individually, the results are
merged in the following fashion: if only one module set was
removed successfully, return that set. If both succeeded, at-
tempt to remove the union of the sets. If the removal succeeds,
return the union of the sets. If the removal fails, return the
larger of the two sets. The total number of removal attempts
is the geometric sum N + N
4 + ... = 2N.
2 + N
The returned modules are then used as the initial solu-
tion for an incremental high-climbing approach to further
improve the result. Modules are selected for removal based
on a weighted random approach, using the weights calculated
from the module dependency and failure information. This
weighted approach is important because of the nature of de-
pendencies between UEFI modules. A modiﬁed ﬁrmware
image may fail because the removed module was a depen-
dency of some other module, however that dependent module
may not be essential. Further in the execution, the root of
the dependency tree may be removed successfully, and as a
result, all of the leaf modules can now also be removed. It
is necessary to go back and retry modules that have failed
because of this case. The weighting helps to ensure that less
tested modules are more likely to be checked ﬁrst while still
preserving the option to retry previously failed modules.
4 Architecture and Software Stack
An overview of the architecture is in Figure 4. DECAF is
composed of multiple modules, each responsible for a sub-
task of the overall pruning process.
DECAF needs to be capable of managing a physical board
in order to control and monitor power, ﬂash ﬁrmware images,
and monitor overall hardware health. It needs to be able to
prune ﬁrmware images and generate candidates to be tested
during the reduction. These images need to be booted and
validated in order to iteratively converge to a minimal image.
4.1 Workﬂow Engine
The Luigi [39] workﬂow engine (represented by A in Figure
4) was chosen for the high level management of the pruning
process. The use of a workﬂow engine to manage the process
serves a few purposes. It provides a high level task overview
that can be used to monitor and manage the pipeline iterations.
It also provides the ability to link tasks together with cached
target data that is stored on the ﬁle system. This is a long-
running process, which means that failures outside the scope
of the pipeline may occur. A network or power outage are
possible during this period and a recovery option is needed so
that the progress is not lost. Because the workﬂow engine has
the native function of caching its progress, the pruning process
can simply be resumed at any point. Luigi’s native concept
of workers and dependencies also makes parallelization easy
when multiple identical boards are available.
4.2 Firmware Pruning
A modiﬁed version of UEFITool lies at the core of the
ﬁrmware pruning module. UEFITool is a mature UEFI
ﬁrmware image editing application written in C++ with Qt. It
is able to enumerate the contents of UEFI ﬁrmware as well
as manipulate and insert modules and sections into ﬁrmware
volumes. It works and is tested on a wide range of ﬁrmware
across a variety of vendors.
We implemented a scriptable Python layer that utilizes the
C++ backend of UEFITool, allowing for headless traversal
and pruning of ﬁrmware images. This is a powerful tool (rep-
resented by B in Figure 4) for automating what was typically
done meticulously by hand in UEFITool’s user interface. The
Python layer offers support for listing, inserting and removing
modules while producing a structurally valid UEFI image.
4.3 Generating Firmware Dependency Graph
An analysis on the ﬁrmware image needs to be run in order
to determine any dependency information. Our approach to
identify these dependencies involves monitoring the protocol
installations and look-ups in the context of the real system.
Given the structure of an EFI image, modules can not only be
pruned, but also appended to the binary.
DECAF appends two modules to the original image: (i)
dependency probe, and (ii) dependency dump. The result is
the "Dependency discovery image" in step 2 (Figure 4).
Figure 4: Overview of the DECAF platform architecture
1718    29th USENIX Security Symposium
USENIX Association
Dependency probe is used to hijack several protocols that
modules use frequently when interacting with each other
(such as EFI_INSTALL_PROTOCOL_INTERFACE). The
protocols are stored as function pointers in a structure that
is passed to each module’s main function. Overwriting these
pointers very early in the DXE phase will cause all mod-
ules executing after this to use the hijacked functions instead.
The hijacked protocols are simply wrappers over the original
functions that also log the GUID of the calling module.
Collected data is stored in memory. Because the depen-
dency probe is loaded at the earliest possible point in the
boot sequence, right after the DXE Core, there is no way to
transmit the information yet (serial/USB drivers/TCP stack
are not loaded). Instead, the probe publishes its own custom
communication protocol that exposes a pointer to the data.
The dependency dump module is loaded as late as possible,
after the network stack has been initialized. At this point,
most (if not all) module interaction has been recorded via
the hijacked protocols. A look-up is necessary to ﬁnd the
information stored by the ﬁrst probe. This information is then
forwarded to an external server (represented by D in 4).
After the dependency discovery image is successfully
booted and the data is collected (steps 4 and 5 from Figure 4),
a directed graph is built from the module dependencies.
There are multiple approaches that can be taken at this
point. Depending on the desired outcome, modules present in
the graph can be excluded from the pruning process (this will
result in a bigger ﬁnal image, but it would attempt to preserve
the original execution ﬂow as recorded at runtime).
Another approach is to update the removal chance based
on the degree of each node. All nodes found in the graph
are less likely to be removed than modules that we have no
information about (and were not recorded as active at runtime).
Nodes with higher degree are less likely to be removed than
those with smaller degree. The reason behind this it that a
node with many incoming edges (or a module that is looked
up and interacts with many other modules) is very likely to
produce a failure if removed ﬁrst, before the dependent nodes.
Figure 5 shows a zoomed in sample of a dependency graph.
Figure 5: A sample dependency graph
Generally, there is a lot of inter-module interaction, and there
are even some self-loops. This can represent a module that
awaits an event in the environment, and periodically probes
itself. Removing a module that is called by one or more of its
peers will increase the chance of failure. A good strategy for
the pruning process is to ﬁrst remove modules that have no
or only a few incoming edges (such as EventLogsSetupPage
or Ofbd in Figure 5), and only afterwards attempt to remove
nodes that are deeper in the graph.
In this particular case, the graph from Figure 5 is generated
from the ﬁrmware of SuperMicro A1SAi-2550F. The original
image contains 244 modules while the full graph has 147
nodes (modules) and 3881 edges (inter-module interaction).
This leaves 97 modules that have no recorded interactions at
runtime, but they are not necessarily unused: they may not
interact with other modules, or they may only be called during
very early initialization, before our hook is introduced. Out
of the 147 recorded modules, 100 nodes have an in degree of
0 (i.e., no dependents), making them the second best removal
candidates after the modules that have no data recorded. 21
modules have an in degree of 147. These modules are likely to
contain core functionality as they interact with all others. Re-
moving them will likely produce bad images. These statistics
will of course vary for different ﬁrmware images.
Some modules are named, while others are represented by
their associated GUID. Generally, named modules are well
known and provide standard functionality (and are reused
across models/vendors), while the others may be custom. For
example CsmVideo adds graphic support for backwards com-