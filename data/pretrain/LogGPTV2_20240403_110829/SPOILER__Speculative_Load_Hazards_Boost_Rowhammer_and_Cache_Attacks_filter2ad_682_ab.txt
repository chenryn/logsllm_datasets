row again, it is called a row hit, and the request will be served
from the row buffer. Otherwise, it is called a row conﬂict, and
the previous row will be deactivated and copied back to the
original row location, after which the new row is activated.
DRAM cells leak charge over time and need to be refreshed
periodically to maintain the data. A Rowhammer [29] at-
tack causes cells of a victim row to leak faster by activating
the neighboring rows repeatedly. If the refresh cycle fails
to refresh the victim row fast enough, that leads to bit ﬂips.
Once bit ﬂips are found, they can be exploited by placing any
security-critical data structure or code page at that particu-
lar location and triggering the bit ﬂip again [16, 47, 60]. The
Rowhammer attack requires fast access to the same DRAM
cells by bypassing the CPU cache, e.g., using clflush [29].
Additionally, cache eviction based on an eviction set can
also result in access to DRAM cells when clflush is not
available [3, 18]. Efﬁciently building eviction sets may thus
also enhance Rowhammer attacks. For a successful Rowham-
mer attack, it is essential to collocate multiple memory pages
within the same bank and adjacent to each other. A number
of physical address bits, depending on the hardware conﬁgu-
ration, are used to map memory pages to banks [45]. Since
the rows are generally placed sequentially within the banks,
USENIX Association
28th USENIX Security Symposium    623
the TLB for the complete physical address information, which
is time consuming. Additionally, the data cache (DCACHE)
may hold the translated store addresses in a Physical Address
Buffer (PAB) with equal number of entries as the store buffer.
3 Speculative Load Hazards
As we mentioned earlier, memory loads can be executed
out-of-order and before the preceding memory stores. If
one of the preceding stores modiﬁes the content of a lo-
cation in memory, the memory load address is referring to,
out-of-order execution of the load will operate on stale data,
which results in invalid execution of a program. This out-of-
order execution of the memory load is a speculative behavior,
since there is no guarantee during the execution time of the
load that the virtual addresses corresponding to the memory
stores do not conﬂict with the load address after translation
to physical addresses. Figure 2 demonstrates this effect on
a hypothetical processor with 7 pipeline stages. As multiple
stores may be blocked due to limited resources, the execu-
tion of the load and dependent instructions in the pipeline, the
load block, will bypass the stores since the MOB assumes
the load block to be independent of the stores. This specula-
tive behavior improves the memory bottleneck by letting other
instructions continue their execution. However, if the depen-
dency of the load and preceding stores is not veriﬁed, the
load block may be computed on incorrect data which is either
falsely forwarded by store forwarding (false dependency), or
loaded from a stale cache line (unresolved true dependency).
If the processor detects a false dependency before committing
the load, it has to ﬂush the pipeline and re-execute the load
block. This will cause observable performance penalties and
timing behavior.
3.1 Dependency Resolution
Dependency checks and resolution occur in multiple stages
depending on the availability of the address information in the
store buffer. A load instruction needs to be checked against
all preceding stores in the store buffer to avoid false depen-
dencies and to ensure the correctness of the data. A potential
design [20, 31],2 suggests the following stages for the depen-
dency check and resolution, as shown in Figure 3:
1. Loosenet: The ﬁrst stage is the loosenet check where
the page offsets of the load and stores are compared3.
In case of a loosenet hit, the compared load and store
may be dependent and the processor will proceed to the
next check stage.
2The implementation of the MOB used in Intel processors is unpublished
and therefore we cannot be certain about the precise architecture. Our results
agree with some of the possible designs that are described in the Intel patents.
3According to Ld_Blocks_Partial:Address_Alias Hardware Perfor-
mance Counter (HPC) event [24], loosenet is deﬁned by Intel as the mecha-
nism that only compare the page offsets.
Figure 1: The Memory Order Buffer includes circular buffers
SDB, SAB and LB. SDB, SAB and PAB of the DCACHE
have the same number of entries. SAB may initially hold the
virtual address and the partial physical address. MOB requests
the TLB to translate the virtual address and update the PAB
with the translated physical address.
access to adjacent rows within the same bank can be achieved
if we have access to contiguous physical pages.
2.5 Memory Order Buffer
The processor manages memory operations using the Memory
Order Buffer (MOB). MOB is tightly coupled with the data
cache. The MOB assures that memory operations are executed
efﬁciently by following the Intel memory ordering rule [39]
in which memory stores are executed in-order and memory
loads can be executed out-of-order. These rules have been
enforced to improve the efﬁciency of memory accesses, while
guaranteeing their correct commitment. Figure 1 shows the
MOB schematic according to Intel [1, 2]. The MOB includes
circular buffers, store buffer1 and load buffer (LB). A store
will be decoded into two micro ops to store the address and
data, respectively, to the store buffer. The store buffer enables
the processor to continue executing other instructions before
commitment of the stores. As a result, the pipeline does not
have to stall for the stores to complete. This further enables
the MOB to support out-of-order execution of the load.
Store forwarding is an optimization mechanism that sends
the store data to a load if the load address matches any of
the store buffer entries. This is a speculative process, since
the MOB cannot determine the true dependency of the load
on stores based on the store buffer. Intel’s implementation
of the store buffer is undocumented, but a potential design
suggests that it will only hold the virtual address, and it may
include part of the physical address [1, 2, 31]. As a result, the
processor may falsely forward the data, although the physical
addresses do not match. The complete resolution will be de-
layed until the load commitment, since the MOB needs to ask
1Store buffer consists of Store Address Buffer (SAB) and Store Data Buffer
(SDB). For simplicity, we use Store Buffer to mention the logically combined
SAB and SDB units.
624    28th USENIX Security Symposium
USENIX Association
PA [:0]VA [11:0]PA [19:12]VA [:12]...VA [11:0]PA [19:12]VA [:12]...VA [11:0]PA [19:12]VA [:12].........PA [:0]...PA [:0]...DATA...DATA...DATA.........LBSABSDBMOBDATAVA[:0]PA[:0]......PABTLBPMHindex 0index nindex 0index nindex 0index kStored Data μOpStore Address μOpDCACHEFigure 2: The speculative load is demonstrated on a hypothetical processor with 7 pipeline stages: F = Fetch, D = Decode, X1−4 =
Executions, and C = Commit. When the memory stores are blocked competing for resources (State 1), the load will bypass the
stores (State 2). The load block including the dependent instructions will not be committed until the dependency of the address
W versus X,Y ,Z are resolved (State 3). In case of a dependency hazard (State 4), the pipeline is ﬂushed and the load is restarted.
the ﬁnenet check may be implemented based on checking the
partial physical address bits. As we verify later, the depen-
dency resolution logic may fail to resolve the dependency at
multiple intermediate stages due to unavailability of the full
physical address.
4 The SPOILER Attack
The attack model for SPOILER is the same as Rowhammer
and cache attacks where the attacker’s code is needed to be
executed on the same underlying hardware as of the victim.
As described in Section 3, speculative loads may face other
aliasing conditions in addition to the 4K aliasing, due to the
partial checks on the higher address bits. To conﬁrm this, we
design an experiment to observe timing behavior of a specu-
lative load based on higher address bits. For this purpose, we
propose Algorithm 1 that executes a speculative load after
multiple stores and further make sure to ﬁll the store buffer
with addresses that cause 4K aliasing during the execution of
the load. Having w as the window size, the algorithm iterates
over a number of different memory pages, and for each page, it
performs stores to that page and all previous w pages within
a window. Since the size of the store buffer varies between
different processor generations, we choose a big enough win-
dow (w = 64) to ensure that the load has 4K aliasing with
the maximum number of entries in the store buffer and hence
maximum potential conﬂicts. Following the stores, we mea-
sure the timing of a load operation from a different memory
page, as deﬁned by x. Since we want the load to be executed
speculatively, we can not use a store fence such as mfence be-
fore the load. As a result, our measurements are an estimate
of execution time for the speculatively load and nearby mi-
croarchitectural events. This may include a negligible portion
of overhead for the execution of stores, and/or any delay due
to the dependency resolution. If we iterate over a diverse set
of addresses with different virtual and physical page numbers,
but the same page offset, we should be able to monitor any
discrepancy.
Figure 3: The dependency check logic: loosenet initially
checks the least 12 signiﬁcant bits (page offset) and the ﬁnenet
checks the upper address bits, related to the page number. The
ﬁnal dependency using the physical address matching might
still fail due to partial physical address checks.
2. Finenet: The next stage, called ﬁnenet, uses upper ad-
dress bits. The ﬁnenet can be implemented to check the
upper virtual address bits [20], or the physical address
tag [31]. Either way, it is an intermediate stage, and it is
not the ﬁnal dependency resolution. In case of a ﬁnenet
hit, the processor blocks the load and/or forwards the
store data, otherwise, the dependency resolution will go
into the ﬁnal stage.
3. Physical Address Matching: At the ﬁnal stage, the
physical addresses will be checked. Since this stage is
the ﬁnal chance to resolve potential false dependencies,
we expect the full physical address to be checked. How-
ever, one possible design suggests that if the physical ad-
dresses are not available, the physical address matching
returns true and continues with the store forwarding [20].
Since the page offset is identical between the virtual and phys-
ical address, loosenet can be performed as soon as the store
is decoded. [2] suggests that the store buffer only holds bit
19 to 12 of the physical address. Although the PAB holds the
full translated physical address, it is not clear in which stage
this information can be available to the MOB. As a result,
USENIX Association
28th USENIX Security Symposium    625
Hazard store a → X store b → Y store c → Z load  d← W inc    dFDX1X2X3X4CBusyResource Load BlockBypasses StoresDependency CheckBefore Commit(State 1)(State 2)(State 3)(State 4)Flush The PipelineYesNoLoosenet  Hit?NoYesNoFinenet  Hit?YesNoPhysicalAddress  Match?Block Load /  Forward StoreProceed withLoadRedispatchLoad YesNoPartial  Physical  Addr Hit?Algorithm 1 Address Aliasing
for p from w to PAGE_COUNT do
end for
return measure
for i from w to 0 do
data store−−→ bu f f er[(p− i)× PAGE_SIZE]
end for
t1 = rdtscp()
data load←−− bu f f er[x× PAGE_SIZE]
t2 = rdtscp()
measure[p] ← t2 −t1
(a) Step-wise peaks with a very high latency can be observed on some of the
virtual pages
(b) Affected HPC event: Cycle_Activity:Stalls_Ldm_Pending
(c) Affected HPC event: Ld_Blocks_Partial:Address_Alias
Figure 4: SPOILER’s timing measurements and hardware per-
formance counters recorded simultaneously.
4.1 Speculative Dependency Analysis
In this section, we use Algorithm 1 and Hardware Perfor-
mance Counters (HPC) to perform an empirical analysis of
the dependency resolution logic. HPCs can keep track of
low-level hardware-related events in the CPU. The counters
are accessible via special purpose registers and can be used
to analyze the performance of a program. They provide a
powerful tool to detect microarchitectural components that
cause bottlenecks. Software libraries such as Performance
Application Programming Interface (PAPI) [51] simpliﬁes
programming and reading low-level HPC on Intel processors.
Initially, we execute Algorithm 1 for 1000 different virtual
pages. Figure 4(a) shows the cycle count for each iteration
with a set of 4 kB aliased store addresses. Interestingly, we
observe multiple step-wise peaks with a very high latency.
Then, we use PAPI to monitor 30 different performance coun-
ters listed in Table 5 in the appendix while running the same
Figure 5: Correlation with HPCs listed in Table 5 in
the appendix. Ld_Blocks_Partial:Address_Alias and
Cycle_Activity:Stalls_Ldm_Pending (both dotted red)
have strong positive and negative correlations, respectively.
experiment. At each iteration, only one performance counter
is monitored alongside the aforementioned timing measure-
ment. After each speculative load, the performance counter
value and the load time are both recorded. Finally, we obtain
the timings and performance counter value pairs as depicted
in Figure 4.
To ﬁnd any relation between the observed high latency
and a particular event, we compute correlation coefﬁcients
between counters and the timing measurements. Since the
latency only occurs in the small region of the trace where the
timing increases, we only need to compute the correlation on
these regions. When an increase of at least 200 clock cycles
is detected, the next s values from timing and the HPC traces
are used to calculate the correlations, where s is the number
of steps from Table 1 and 200 is the average execution time
for a load.
As shown in Figure 5, two events have a high correla-
tion with the leakage: Cycle_Activity:Stalls_Ldm_Pending
has the highest correlation of 0.985. This event shows
the number of cycles for which the execution is stalled
and no instructions are executed due to a pending load.
Ld_Blocks_Partial:Address_Alias has an inverse correla-
tion with the leakage. This event counts the number of false de-
pendencies in the MOB when loosenet resolves the 4K alias-
ing condition. Separately, Exe_Activity:Bound_on_Stores
increases with more number of stores within the inner
window loop in Algorithm 1, but it does not have a cor-
relation with the leakage. The reason behind this behav-
ior is that the store buffer is full, and additional store op-
erations are pending. However, since there is no correla-
tion with the leakage, this shows that the timing behavior
is not due to the stores delay. We also attempt to proﬁle
any existing counters related to the memory disambigua-
tion. However, the events Memory_Disambiguation.Success
and Memory_Disambiguation.Reset are not available on the
modern architectures that are tested.
626    28th USENIX Security Symposium
USENIX Association
010020030040050060070080090010000200400600Cyclesrdtsc0100200300400500600700800900100005001000CyclesStalls_Ldm_Pending0100200300400500600700800900100001020DependencyAddress_Alias-1-0.500.51Correlation Coefficient051015202530Counter NumberCPU Model
Architecture
Steps
SB Size
Intel Core i7-8650U
Intel Core i7-7700
Intel Core i5-6440HQ
Intel Xeon E5-2640v3
Intel Xeon E5-2670v2
Kaby Lake R
Kaby Lake
Skylake
Haswell
Ivy Bridge EP
Intel Core i7-3770