For example, if a cryptographic key for deobfuscation is computed
in a particular path within a loop, the loop should be iterated suffi-
ciently, and the particular path should be covered. To handle such
issues, we propose Control Flow Trimming.
Specifically, when the execution of malware fails to reveal mali-
cious behaviors due to missing computations in a loop, MalMax
if(!isset($_GET[1]))die(“Nothing to see here.”);if($_GET[1]==$password) {for($i=0; $i200 and $i%11==0)do_malicious();elsedo_benign();}copy_the_malware();12345678910(a) Source code(b) Traces from Dynamic Analysis and Counterfactual Exec.  (Numbers in traces are line numbers and an arrow means a creation of a new isolated execution)12Dyn.12Counterfactual Execution123101234589…123456345…123456345……first executes the loop until the loop count reaches a predefined
threshold (100 in this paper) while measuring how many times each
execution path takes. When we observe a particular path is more
frequently executed than other paths, preventing exploration of
other execution paths, we create a new isolated execution state and
force the new execution to explore the other paths. If the new execu-
tion can discover any new executed statements or execution states
(compared to those in the original execution path), we conclude
that the analysis of the loop is successful.
Figure 2: Control Flow Trimming Example on Fig. 1
Fig. 2-(a) shows the control flow graph of the partial code in
Fig. 1-(a) (Lines 3-10). The label of each node represents its line
number. Edges represent control flows. Note that line 6 with red
color is the call to malicious code. Fig. 2-(b) shows a weighted
control flow graph (CFG) after 100 iterations of the lines 4-8. Note
that edges between the nodes 3, 4, 5, and 8 are thick indicating that
the path is executed frequently. Specifically, we increase a count
for each edge between nodes every time it executes. For instance,
after the 100 iterations, each thick edge (e.g., the edge between 3
and 4) will have 100 for the counter value. When a counter value
reaches a predetermined threshold (100 in this paper), we apply the
control flow trimming method. In particular, for each node that has
an edge with a counter value that reached the threshold, we check
whether there is an alternative path (i.e., edge). If there is one and
the alternative path’s counter value is less than the threshold, we
execute the alternative path. Essentially, we trim the control flow
that reached the threshold, executing unexplored paths.
– Runtime Threshold Adjustment: We observe that there are malware
samples that require a larger threshold to successfully execute ma-
licious behaviors. To handle such cases, MalMax incrementally
increases the threshold by a factor of 2. Fig. 3-(a) shows an example.
The program has a loop (Lines 1-5) and within the loop, it first
executes do_benign() which takes more than 10 seconds (to delib-
erately hinder dynamic analysis) and then updates the decryption
key (Line 4). Then, the key is used to decrypt the malicious code
and execute via eval() (Line 6).
Figure 3: Adjusting Threshold in Control-Flow Trimming
Fig. 3-(b) presents a trace from a naive dynamic analysis. It
iterates the loop 1,000 times, executing the time-consuming code
do_benign() (Line 2) 1,000 times as well. A naive dynamic analysis
will take around 2 hours 46 minutes to reach the malicious code.
Fig. 3-(c) shows a trace from the counterfactual execution. It
quickly reaches the malicious code (Line 6). However, as it skipped
the loop iterations, the decryption key ($key) is not correct, result-
ing in the failed execution at eval() (We consider invalid code
passed to eval() as a failure).
Fig. 3-(d) represents the first attempt of control-flow trimming
with the threshold 100. It iterates the loop 100 times and then tries
to execute the malicious code. However, due to the insufficient
decryption key update, the execution fails.
MalMax then increases the threshold by a factor of 2. Fig. 3-(e)
is a trace from the second attempt with the updated threshold 200.
After the 200 iterations, it executes the malicious code successfully.
Note that the key is only updated during the first 200 iterations.
Our evaluations show that the strong majority of malware expose
their malicious behavior with the default threshold of 100. A handful
of samples triggers the runtime threshold adjustment algorithm,
increasing the trimming threshold up to 800. We manually verified
whether the runtime adjustment is sufficient or not by observing the
analysis results with different default thresholds. Specifically, we
run the experiments with 7 different thresholds: 100, 200, 400, 800,
1,600, 3,200, and unlimited. The experiments show that the threshold
above 800 does not discover any new dynamic code, indicating the
runtime threshold adjustment is effective in discovering dynamic code
without any manual intervention.
Key Points: Control flow trimming (CFT) ensures that analysis
finished in a reasonable time, by first limiting loops to a threshold
of 100 iterations and then increasing the threshold by a factor
of 2 until the execution does not observe any failed statements
(e.g., eval() with a string that contains invalid code). With this
dynamic adjustment of the threshold, MalMax can effectively
and efficiently discover malicious code.
3.2 Cooperative Isolated Execution
MalMax provides a cooperatively isolated execution environment
to (1) isolate each execution path of the program and (2) coopera-
tively share resources resolved in each isolated execution in order
to help discover dynamically loaded code snippets (e.g., through
include). The isolated executions are nested, and for each dynam-
ically generated part of the program, new isolation is created. Each
execution is isolated so that state changes/errors in one execution
would not inadvertently affect the other executions. However, they
are also cooperative to help discover more execution contexts (e.g.,
database connections, configuration variables, function/class defi-
nitions, etc.) which can lead to exposing malicious behavior (e.g.,
malicious code resides in an external module loaded dynamically).
This cooperation enables us to discover more of the application code.
Specifically, without the cooperative isolation scheme, MalMax
covers 36,034 statements of Wordpress whereas MalMax covers
58,786 with the cooperative isolation (Details in Appendix B).
Cooperative Isolations. As each isolation explores a single exe-
cution path, there are artifacts (e.g., variables, resources, constants,
etc.) that are unresolved in one particular isolation while they are
resolved in other isolations. If such artifacts are used in the cre-
ation of dynamic behavior (e.g., used in include or eval), the
3458610(a) Control Flow Graph (CFG)3458610(b) Weighted CFG (after 100 iteration)3458610(c) Trimmed CFG (Help exploring the red paths)for($i=0;	$i<1000;	++$i)	{do_benign();if($i<198)	$key	+=	$table[$i];}eval(	openssl_decrypt($code,	‘AES-256-CBC’,	$key)	);1234	56(a)	Source	code1,	2,3,4,	2,	3,	4,	2,	3,	4,	2,	3,	...(b)	Dynamic	Execution1,	2,3,4,6	(Failed)(c)	Counterfactual	Execution1,	(2,3,4)*100,	6	(Failed)(d)	Control-Flow	Trimming	(1st)1,	(2,	3,	7)*200,	6	(Success)(e)	Control-Flow	Trimming	(2nd)analysis will not be able to resolve them and its results might be
limited. Cooperative isolated execution’s role is to share artifacts
discovered in one isolation with other isolations to provide a reso-
lution for such unresolved artifacts such as dynamically included
files, environment variables, database connections, etc.
– Global Scope Artifacts: Artifacts belonging to the global scope are
shared, such as function definitions, class definitions, constants,
global variables, environment variables, etc. Note that dynamic
languages such as PHP allow redefinition of functions and classes.
The insight for such sharing is that PHP applications commonly
leverage global scope artifacts to implement dynamically loaded
plugin modules. For example, Joomla uses configuration files to
decide which subset of its core modules to load, and Wordpress uses
database values to determine which plugins are active in an instal-
lation, and thus need to be loaded and executed. These global scope
artifacts can further be modified throughout program execution,
resulting in additional modules being loaded and executed. Specifi-
cally, a loaded Wordpress plugin can then use its own configuration
parameters, and load another plugin, or redefine a core function/-
class (Details in Appendix B.1). Note that cooperative isolations do
not share local scope artifacts such as local variables. Intuitively,
local artifacts are not meant to be shared between functions and
modules while global artifacts are often meant to be shared.
Figure 4: Cooperative Isolated Execution
it runs on the system natively without harming the underlying host
system. MalMax achieves this protection via virtualizing access
to external resources such as files, networks, databases, etc. and
redirecting them to emulated resources, while using containers (i.e.,
Docker) to ensure it cannot damage the host.
To implement sandboxing, we override PHP functions that can
alter the system objects (e.g., files and database) to redirect the
accesses to the objects to virtualized system objects. We allow
malware to modify the virtualized objects as they do not harm the
host system and provide more insights into the intent of malware.
In our prototype, 31 functions and classes are explicitly virtu-
alized. For example, fopen() will be proxied (i.e., forwarded to
the original function) if it is in read mode. If it is in write mode,
the file will be duplicated and the file accesses will be redirected
to the duplicated file (i.e., the access is sandboxed). Similarly, the
function unlink() would not remove the actual file in the host.
The file will be duplicated once and unlinked, successfully simulat-
ing unlink(). If there is another attempt to call unlink() on the
same file, as MalMax remembers the file is already duplicated, it
will not duplicate the file again and the unlink() will fail.
Key Points: Cooperative isolated execution allows MalMax to ana-
lyze behaviors of malware within a cooperative sandbox, sharing
artifacts obtained from each isolated execution with other isola-
tions, facilitating path discovery process. With the help of coop-
erative isolated execution, we discover paths containing 22,752
additional (38% of the total code) statements in Wordpress.
3.3 Proof of Concept (PoC) Automated
Malware Detector: PhpMalScan
Fig. 4 shows how MalMax works on a program that establishes a
database connection, then populates a global configuration variable
($config) from the database. Using the populated configuration
variable, the program then loads a plugin which contains function/-
class definitions that include malicious code.
In Fig. 4, there are three isolated executions. Isolated Execution
1 resolves a database connection while Isolated Executions 2 and 3
fail to do so because they take different execution paths, depicted
as different curves in Fig. 4. However, Isolated Executions 2 and 3
cover code that populates the configuration and loads plugins re-
spectively. Without the database connection, even though Isolation
Executions 2 and 3 cover critical parts of the program that might
expose malicious code, they would not be able to load the malicious
plugin due to the unresolved database connection.
With MalMax, Isolated Execution 2 can retrieve the database
connection resolved by Isolated Execution 1. Furthermore, Isolated
Execution 3 is able to load the malicious plugin leveraging the
populated global variable $config from Isolated Execution 2.
Sandboxing. MalMax allows malware to access system resources
(e.g., files or database) while preventing persistent modifications to
the external system state. As a result, malware will be executed as if
In this section, we present our proof of concept malware detec-
tion tool, PhpMalScan, to compare the effectiveness of malware
analysis primitives provided by MalMax with existing state-of-the-
art malware detection tools. PHP was chosen as the target language
for the prototype as it is used by 79% of all websites, and is also
responsible for 71% of all server-side malware [66, 71].
It is important to note that the purpose of this tool is to demon-
strate the effectiveness and practicality of concepts discussed in
this section, rather than proposing a malware detector as a core
contribution of the paper. PhpMalScan is built on top of MalMax,
leveraging advanced malware analysis capabilities such as coop-
erative isolated execution and counterfactual execution. However,
PhpMalScan differs from MalMax as it needs to make a decision
on whether a given program is malicious or not. PhpMalScan
employs several straightforward heuristics for this decision.
Measuring Maliciousness. PhpMalScan categorizes PHP func-
tions into two different types: Potentially Malicious Functions (PMF)
and Safe Functions (SF). Functions that can change system states
(e.g., system(), fwrite(), and unlink()) are classified as PMF.
Functions that do not affect system state such as program state
introspection functions, data (e.g., string) manipulation functions
(e.g., regular expression operations and type casts), and arithmetic
functions are categorized as SF.
We define two metrics for determining whether code is mali-
cious or benign: PMFR (Potentially Malicious Functions Ratio) and
MS (Maliciousness Score). PMFR is the number of potentially mali-
cious functions invoked in the code, divided by the total number of
Isolated Execution 1Isolated Execution 2Isolated Execution 3…123Sharing Global Scope Artifacts(e.g., contexts marked as                   ) between Isolated Executions123Host System Resources(Files, DBs, Networks)Read AccessNo Write AccessDB conn.Configs.Function/Class Defs.Global Scope ArtifactsGlobal Scope ArtifactsGlobal Scope Artifacts123231231LegendResolvedSharedinvoked functions. The threshold for this metric should be low but
cannot be close to 0 as benign applications can also call system state
changing functions (i.e., PMF). MS (Maliciousness Score) is a value
computed based on the amount and intensity of potentially ma-
licious activity. Each function has a maliciousness score between
0 and 2, depending on its parameters and behavior, inspired by
that function’s prevalence among popular malware. For example,
file_get_contents() can fetch a URL, a file, or standard input,
corresponding to the scores of 2, 0 (if the file is within program
directory, otherwise 2) and 1.
Another important aspect of web-server malware is that they
rely on dynamic constructs to decode and execute malicious code,
sometimes nesting several layers of encoding and dynamic evalua-
tion to evade detectors. MS takes such nested execution layers into
account. Each function’s MS is multiplied by the dynamic evalua-
tion nesting depth times 10. Specifically, every time the code uses
eval()-like constructs, the dynamic evaluation nesting depth is
increased by 1. For example, a single use of the function system()
in a normal piece of code will yield a maliciousness score of 1 while
using it inside an eval will yield a malicious score of 10.
Intuitively, a higher PMFR suggests that the program contains
significant malicious behavior compared to benign behavior, sug-
gesting that the program is likely malicious. MS, on the other hand,
is useful in detecting surgical malware, i.e., malware that either
injects itself into a benign code, or malware that does a significant
amount of benign work (e.g., system inspection) before performing
a surgical attack (e.g., a single shell command). Note that Php-
MalScan metrics are defined in a simple, straightforward way, as
the point of this prototype is simply to show the effectiveness of the
analysis techniques in exposing malicious behavior, which can be
detected with more fine-grained metrics as part of future research.
– Defining MS and PMFR Thresholds: PhpMalScan detects a sample
as malware if either MS or PMFR reaches predefined thresholds: 5%
and 20 for PMFR and MS respectively.
The thresholds are obtained by analyzing MS and PMFR from a
set of benign and malware samples. Specifically, we selected 509
malware samples from known malware repositories [6, 44] and
benign samples from benign web applications [39, 46]. The two
repositories for malware are independent collections of malicious
PHP scripts found in the wild, 619 total (April 2016 ∼ April 2019)
retaining 509 samples reported as malicious by VirusTotal.
Figure 5: MS and PMFR Scores of Malware and Benign Sam-
ples (Red: Malware, Blue: Benign).
Then we iteratively select incrementally larger random subsam-
ples, obtaining PMFR and MS values until reaching a fixpoint, where
increasing the random subsample size does not change the thresh-
old anymore. The fixpoint is reached at 400 samples, as depicted
in Fig. 5. X-axis and Y-axis represent MS and PMFR of the samples
respectively. Note that the distribution of each of MS and PMFR are
diverse. Some of the malware have a large MS footprint because
they do significant malicious work, while having low PMFR due to
being injected in the middle of benign programs. Fig. 5 also depicts
how some other malware, contrary to the previous group, have
high PMFR and low MS, as they are relatively small files that do a
focused malicious activity (e.g., copy files) and do not include any
other code, thus their MS remains low.
Observe that most benign samples have both 0 MS and PMFR.
There are two benign samples that have 10 MS values while their
PMFR are 0. Fig. 5 also includes an enlarged graph near the 0 MS
and PMFR to more clearly depict the threshold. Observe that all
malicious samples have either larger than 20 MS value or 5% PMFR.
We also performed a sensitivity analysis on dynamic evaluation
nesting depth coefficient (i.e., 10), and noticed that reducing it to 1
will result in up to 3% false negatives in our datasets, while setting
it at 9 will result in 1.5% false negatives in our evaluations. Setting
the coefficient to 10 and above resulted in no false negatives. False
positives however, were consistently zero in the sensitivity analysis,
most likely because our dataset does not include any obfuscated
code blocks that utilize malicious functions (Details in Appendix C).
Key Points: To evaluate the effectiveness of malware analysis
primitives provided by MalMax in comparison with state-of-the-
art malware detection tools, we built PhpMalScan, a prototype
PHP malware detector based on MalMax. PhpMalScan uses
two metrics, Maliciousness Score (MS) and Potentially Malicious
Function Ratio (PMFR), and we systematically determined the
thresholds of 20 (for MS) and 5% (for PMFR) by iteratively an-
alyzing increasingly larger subsamples of ground truth dataset
until reaching a fixpoint. The thresholds are reconfigurable and
MalMax’s capabilities do not depend on the thresholds.
4 EVALUATION
We evaluated the performance and effectiveness of MalMax
using a large set of real-world website deployments which include
real-world malware samples in the wild (Section 4.2), various mal-
ware samples (Section 4.3), and a set of representative benign PHP
applications (Section 4.4). In addition, we present the performance
of MalMax and PhpMalScan (Section 4.5) and two additional
real-world malware in the wild to demonstrate how MalMax can
effectively analyze them (Section 4.6).
4.1 Experimental Setup
Real-world Website Deployments (Dataset A). To understand
MalMax’s impact in practice, we ran PhpMalScan on a large
dataset of 1 TB of files (consisting of 87 real world websites de-
ployed in the wild). The dataset is provided by a commercial web
hosting company that maintains nightly backups of over 400,000
websites. For each backup, Linux Malware Detector [57] is used
to scan every file in the backup. If any file in a website is flagged
as malware, the entire website (i.e., all files of that website) are
included in the dataset. If no file in the website is flagged as mal-
ware, the website’s files are not included in the dataset. Because
Linux Malware Detector has both false positives and false nega-
tives, flagged files may not be malicious and unflagged files may
be malicious. Consequently, the dataset includes both potentially
benign and malicious files, at least one of which was flagged as
malware by Linux Malware Detector. Section 4.2 provides more
details regarding the diversity of the dataset.
Real-world and Synthesized Malware Samples (Dataset B).
As we do not have ground-truth for Dataset A because they were col-
lected in the wild, we prepared another dataset with ground-truth
to understand the accuracy of MalMax. We collected a benchmark
of 53 real and common PHP malware samples from multiple sources,
including underground networks, official websites, Github collec-
tions and malware encountered throughout the course of authors’
research. Note that the selection of relatively popular malware will