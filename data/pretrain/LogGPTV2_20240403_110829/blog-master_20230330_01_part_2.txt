       ,1,1,1,1,1,1,1,1,1,1  
       ,1,1,1,1,1,1,1,1,1,1  
       ,1,1,1,1,1,1,1,1,1,1  
       ,1,1,1,1,1,1,1,1,1,1  
       ,1,1,1,1,1,1,1,1,1,1  
       ,1,1,1,1,1,1,1,1,1,1  
       ,1,1,1,1,1,1,1,1,1,1  
       ,1,1,1,1,1,1,1,1,1,1  
       ,1,1,1,1,1,1,1,1,1,1  
       ,1,1,1,1,1,1,1,1,1,1  
       ,1,1,1,1,1,1,1,1,1,1  
       ,1,1,1,1,1,1,1,1,1,1  
       ,1,1,1,1,1,1,1,1,1,1  
       ,1,1,1,1,1,1,1,1,1,1  
       ,1,1,1,1,1,1,1,1,1,1  
       ,1,1,1,1,1  
       ]::float4[] FROM generate_series(1, 50000) id;  
CREATE INDEX v_ivfflat_idx ON vectors_ivfflat_test  
       USING  
         pase_ivfflat(vector)  
  WITH  
    (clustering_type = 1, distance_type = 0, dimension = 256, clustering_params = "10,100");  
NOTICE:  vector dimension is huge, parameter (clustering_sample_ratio) should be set to ensure the clustering count lower than 307200  
NOTICE:  parse clustering parameters succeed, clustering_sample_ratio[10], k[100]  
NOTICE:  begin inner kmeans clustering  
NOTICE:  begin, ivfflat index building  
NOTICE:  ivfflat index build done, build tuple number[50000], totalTimeCost[1.402648s], centroidBuildTimeCost[0.722759s], indexBuildTimeCost[0.679889s]  
CREATE INDEX  
SELECT vector  '31111,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1'::pase as distance  
    FROM vectors_ivfflat_test  
    ORDER BY  
    vector  '31111,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1'::pase  
     ASC LIMIT 10;  
 Limit  (cost=0.00..11.68 rows=10 width=4)  
   Output: ((vector  '31111,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1  
,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1  
,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1::'::pase))  
   ->  Index Scan using v_ivfflat_idx on public.vectors_ivfflat_test  (cost=0.00..58392.00 rows=50000 width=4)  
         Output: (vector  '31111,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,  
1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,  
1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1::'::pase)  
         Order By: (vectors_ivfflat_test.vector  '31111,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1  
,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1  
,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1::'::pase)  
(5 rows)  
 distance   
----------  
        0  
        1  
        1  
        4  
        4  
        9  
        9  
       16  
       16  
       25  
(10 rows)  
```  
更多pase使用信息请参考: https://github.com/B-sudo/VecDB-Exp  
例子参考: https://github.com/B-sudo/VecDB-Exp/blob/master/postgresql-11.0/contrib/pase/sql/pase.sql   
包括算法的选择, 算法参数的调整等.  例如图层级别、采样比例、桶的个数、搜索时选择最近的几个桶等等.    
Code of PASE is in the directory postgresql-11.0/contrib/pase.  
- ivfflat: PASE index IVF_FLAT implementation  
- ivfpq: PASE index IVF_PQ implementation  
- hnsw: PASE index HNSW implementation  
- sql: Sample SQL file for PASE  
- type: Data types used in PASE  
- utils: Util functions used in PASE  
We implemented index IVF_PQ in PASE and the code is in postgresql-11.0/contrib/pase/ivfpq.  
## 参考  
https://zhuanlan.zhihu.com/p/415320221   
https://www.showmeai.tech/article-detail/185  
https://madlib.apache.org/docs/latest/group__grp__kmeans.html  
https://milvus.io/docs/install_embedded_milvus.md   
https://github.com/jina-ai/executor-hnsw-postgres   
https://github.com/forrest-2007/PASE  
https://dl.acm.org/doi/abs/10.1145/3318464.3386131  
https://dl.acm.org/doi/pdf/10.1145/3318464.3386131  
https://github.com/B-sudo/VecDB-Exp  
https://github.com/alipay/PASE  
[《如何用 PolarDB 在不确定世界寻找确定答案 (例如图像相似) - vector|pase》](../202212/20221201_02.md)    
[《PostgreSQL 开源 高维向量相似搜索插件 vector - 关联阿里云rds pg pase, cube, 人脸识别》](../202105/20210514_03.md)    
[《PostgreSQL 在资源搜索中的设计 - pase, smlar, pg_trgm - 标签+权重相似排序 - 标签的命中率排序》](../202009/20200930_01.md)    
[《PostgreSQL 向量相似推荐设计 - pase》](../202004/20200424_01.md)    
[《社交、电商、游戏等 推荐系统 (相似推荐) - 阿里云pase smlar索引方案对比》](../202004/20200421_01.md)    
[《PostgreSQL 阿里云rds pg发布高维向量索引，支持图像识别、人脸识别 - pase 插件》](../201912/20191219_02.md)    
[《PostgreSQL + FDW + vector 插件加速向量检索 - 在不确定世界寻找确定答案 (例如图像相似)》](../202203/20220302_01.md)    
[《DuckDB 存储生态: lance(向量存储引擎): Modern columnar data format for ML/超越parquet》](../202303/20230319_01.md)    
[《一种新的向量检索索引 DiskANN: Fast Accurate Billion-point Nearest Neighbor Search on a Single Node》](../202107/20210729_03.md)    
[《为什么向量数据要归一化?》](../202107/20210723_01.md)    
[《《开慧社》第二期《我朋友的创业故事》- Zilliz 向量数据库创始人 星爵 访谈》](../202106/20210623_01.md)    
[《PostgreSQL 应用开发解决方案最佳实践系列课程 - 3. 人脸识别和向量相似搜索》](../202105/20210506_01.md)    
[《PostgreSQL+MySQL 联合解决方案 - 第11课视频 - 多维向量相似搜索 - 图像识别、相似人群圈选等》](../202001/20200115_01.md)    
[《画像系统标准化设计 - PostgreSQL roaringbitmap, varbitx , 正向关系, 反向关系, 圈选, 相似扩选(向量相似扩选)》](../201911/20191128_02.md)    
[《阿里云PostgreSQL 向量搜索、相似搜索、图像搜索 插件 palaemon - ivfflat , hnsw , nsg , ssg》](../201908/20190815_01.md)    
[《PostgreSQL 多维、图像 欧式距离、向量距离、向量相似 查询优化 - cube,imgsmlr - 压缩、分段、异步并行》](../201811/20181129_01.md)    
[《PostgreSQL 相似人群圈选，人群扩选，向量相似 使用实践 - cube》](../201810/20181011_01.md)    
[《HTAP数据库 PostgreSQL 场景与性能测试之 16 - (OLTP) 文本特征向量 - 相似特征(海明...)查询》](../201711/20171107_17.md)    
#### [期望 PostgreSQL|开源PolarDB 增加什么功能?](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")
#### [PolarDB 云原生分布式开源数据库](https://github.com/ApsaraDB "57258f76c37864c6e6d23383d05714ea")
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、内核开发公开课、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")
#### [PostgreSQL 解决方案集合](../201706/20170601_02.md "40cff096e9ed7122c512b35d8561d9c8")
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")