### toLoot

#### Figure 2: Frequency Distribution of Top Instructions in Tanks
The frequency distribution of the top instructions in a sample mining program is analyzed over various sequence intervals. This distribution reflects the temporal mining speed. A baseline average distribution is then computed, representing the average mining speed of the sample program.

At runtime, we compute the distribution of the same top N groups of instructions within a specified detection interval for a WebAssembly (Wasm) thread. We calculate the cosine similarity score between this distribution and the baseline distribution. If the score is close to 1, it indicates that the thread is likely executing similar code in that interval. A threshold parameter \( T_c \) is used to compare the similarity scores.

It is possible for a non-mining thread to execute the same code briefly and then become inactive. To address this, we use the number of executed instructions divided by the detection interval to represent the mining speed, rather than a percentage. We compare this calculated mining speed (\( s \)) with the baseline speed (\( S \)). A negative decision is made if the mining speed is significantly lower than the baseline speed. Specifically, we obtain the standard deviation \( \sigma \) when calculating the baseline average speed. A parameter \( T_\sigma \) controls the absolute detection distance from the baseline speed. A positive decision is made if the following inequality holds:

\[
\text{score} \geq T_c \quad \text{and} \quad s \geq S - T_\sigma \sigma
\]

#### Studying Parameters \( N_{\text{group}} \) and \( N_{\text{inst}} \)
We experiment with different settings of \( N_{\text{group}} \) and \( N_{\text{inst}} \) to study the overhead and accuracy of our method on a small-scale training set. For simplicity, we use another mining program as the positive case and the Tank game as the negative case.

#### Evaluation
In June 2019, we conducted a preliminary experiment on Alexa's top 100K websites using our modified browser. We identified 87 websites that included at least one Wasm script. Our method detected four websites as cryptojacking sites, all of which used the CryptoLoot mining algorithm. Manual verification confirmed the accuracy of our detection, and there were no false negatives, i.e., no other websites running the CryptoLoot algorithm. These results suggest that subsequences of Wasm instruction execution traces can be a reliable feature for identifying similar Wasm cryptojacking programs.

#### Discussion and Future Work
Our evaluation of the method using subsequences of Wasm instruction execution traces to detect Wasm cryptojacking programs shows that the frequency distribution of top instruction groups can effectively represent the intrinsic mining behavior of a Wasm program. However, our approach may not be robust against obfuscation, although Wasm obfuscation is not widely observed yet. Attackers could inject extra instructions, reverse the order of instructions, or break basic blocks into smaller ones to bypass detection. In future work, we aim to improve our methodology to counter potential Wasm obfuscation attacks.

#### Acknowledgment
This work was partly supported by a grant from the Research Grants Council of the Hong Kong Special Administrative Region, China (CUHK 24209418).

#### References
1. 2018. THE ILLICIT CRYPTOCURRENCY MINING THREAT. [Online]. Available: <https://www.cyberthreatalliance.org/wp-content/uploads/2018/09/CTA-Illicit-CryptoMining-Whitepaper.pdf>
2. Shayan Eskandari, Andreas Leoutsarakos, Troy Mursch, and Jeremy Clark. 2018. A first look at browser-based Cryptojacking. In 2018 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW). IEEE, 58–66.
3. Guardian. 2018. [Online]. Available: <https://www.theguardian.com/technology/2017/sep/27/pirate-bay-showtime-ads-websites-electricity-pay-bills-cryptocurrency-bitcoin>
4. Geng Hong, Zhemin Yang, Sen Yang, Lei Zhang, Yuhong Nan, Zhibo Zhang, Min Yang, Yuan Zhang, Zhiyun Qian, and Haixin Duan. 2018. How you get shot in the back: A systematical study about cryptojacking in the real world. In Proceedings of the 22nd ACM Conference on Computer and Communications Security (CCS). Toronto, Canada.
5. Amin Kharraz, Zane Ma, Paul Murley, Charles Lever, Joshua Mason, Andrew Miller, Nikita Borisov, Manos Antonakakis, and Michael Bailey. 2019. Outguard: Detecting In-Browser Covert Cryptocurrency Mining in the Wild. In Proceedings of The Web Conference (WWW). San Francisco, CA.
6. Radhesh Krishnan Konoth, Emanuele Vineti, Veelasha Moonsamy, Martina Lindorfer, Christopher Kruegel, Herbert Bos, and Giovanni Vigna. 2018. Minesweeper: An in-depth look into drive-by cryptocurrency mining and its defense. In Proceedings of the 22nd ACM Conference on Computer and Communications Security (CCS). Toronto, Canada.
7. Hon Lau. 2017. Browser-based cryptocurrency mining makes unexpected return from the dead. Symantec Threat Intelligence (2017).
8. Jan Rüth, Torsten Zimmermann, Konrad Wolsing, and Oliver Hohlfeld. 2018. Digging into browser-based crypto mining. In Proceedings of the Internet Measurement Conference 2018. ACM, 70–76.
9. TrendMicro. 2018. Malvertising campaign abuses Google’s DoubleClick to deliver cryptocurrency miners. [Online]. Available: <https://blog.trendmicro.com/trendlabs-security-intelligence/malvertising-campaign-abuses-googles-doubleclick-to-deliver-cryptocurrency-miners/>
10. Wenhao Wang, Benjamin Ferrell, Xiaoyang Xu, Kevin W Hamlen, and Shuang Hao. 2018. Seismic: Secure in-lined script monitors for interrupting cryptojacks. In European Symposium on Research in Computer Security. Springer, 122–142.
11. Mark Ward. 2018. [Online]. Available: <http://www.bbc.com/news/technology-41518351>

#### Figures and Tables
- **Figure 3**: Overhead for the positive case.
- **Figure 4**: Overhead for the negative case.
- **Table 2**: Similarity score of the positive case.
- **Table 3**: Similarity score of the negative case.

To count the occurrences of the top \( N_{\text{inst}} \) instructions, we insert four extra profiling instructions into the Wasm. We enable the Linux-perf feature to dump the per-thread executed instruction numbers to measure the overhead, which is the ratio of additional instructions executed in a fixed CPU time. As shown in Figure 3, the overhead decreases significantly as \( N_{\text{inst}} \) increases or \( N_{\text{group}} \) decreases for the positive case. For the negative case (Figure 4), the overhead is minimal if a larger \( N_{\text{inst}} \) is selected.

**Table 2: Similarity Score of the Positive Case**

| \( N_{\text{group}} \) | 1    | 3    | 5    | 7    |
|-----------------------|------|------|------|------|
| \( N_{\text{inst}} \)  |      |      |      |      |
| 1                     | 0.930| 0.930| 0.935| 0.932|
| 3                     | 0.934| 0.947| 0.928| 0.929|
| 5                     | 0.948| 0.939| 0.943| 0.941|
| 7                     | 0.929| 0.937| 0.948| 0.946|
| 9                     | 0.945| 0.947| 0.933| 0.928|

**Table 3: Similarity Score of the Negative Case**

| \( N_{\text{group}} \) | 1    | 3    | 5    | 7    |
|-----------------------|------|------|------|------|
| \( N_{\text{inst}} \)  |      |      |      |      |
| 1                     | 1.000| 1.000| 0.000| 0.000|
| 3                     | 0.000| 0.716| 0.519| 0.000|
| 5                     | 0.000| 0.760| 0.558| 0.000|
| 7                     | 0.000| 0.754| 0.542| 0.000|
| 9                     | 0.000| 0.753| 0.534| 0.000|

From the similarity scores in Table 2 and Table 3, we found that as long as both \( N_{\text{inst}} \) and \( N_{\text{group}} \) are greater than 3, we achieve relatively good detection performance in this small-scale experiment. Thus, our method has the potential to perform well in detecting Wasm programs running a known cryptocurrency mining algorithm.