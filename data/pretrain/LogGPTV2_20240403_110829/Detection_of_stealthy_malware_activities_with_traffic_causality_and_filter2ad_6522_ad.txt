Correct (case a-c)
Wrong (case d-f)
Wrong (case g)
Naive Bayes Bayesian Network
(cid:104) 0, 1
(cid:105)
10, 0
(cid:104) 0, 1
(cid:105)
10, 0
SVM
(cid:104) 0, 1
(cid:105)
100, 0
99.94%
0.00%
0.06%
99.94%
0.00%
0.06%
99.37%
0.28%
0.35%
Table 6: Correctness of root triggers in Dataset
I. Cases (a-g) refer to the various predicted root-
trigger outcomes in Figure 4 in the Appendix.
4.3 Abnormal Trafﬁc in Datasets I
4.3.1 Malicious Browser Extension
We wrote a proof-of-concept malicious Firefox extension,
which is a piece of password-stealing spyware. The mal-
45Figure 3: Accuracy and correctness results under various cost matrix conditions for Dataset I (pairwise clas-
siﬁcation accuracy in (a) and root-trigger correctness in (b)) and Dataset II (pairwise classiﬁcation accuracy
in (c) and root-trigger correctness in (d)).
ware sends the username and password when a user clicks
on the Submit button in the browser. This spyware is simi-
lar to the existing spyware such as FormSpy and FFsniff. A
victim user clicks the Submit to log on to various email ser-
vices and Internet forums. The spyware requests, which
contain the username and password in the HTTP request
(/query?id=user_id&ps=password), are sent to its destination
host. With our causality analysis tool, all malicious HTTP
requests are detected by all three classiﬁers, without trig-
gering any FPs and FNs.
4.3.2 Data Exﬁltrating Malware
We write another proof-of-concept data-exﬁltrating mal-
ware. This malware runs as a stand-alone process, simi-
lar to Pony bot.
It sends out the HTTP GET/POST requests
with system information to remote servers. The malware
is programmed to transmit its payload right after the oc-
currence of a user event on the host, attempting to hide
its communication among legitimate outbound traﬃc. The
malicious communication may be a single request or a se-
ries of HTTP requests. Our method successfully detects the
network activities of the malware in that the outbound ma-
licious requests do not have valid triggering relations, i.e.,
the requests lack of any user event as the root-trigger.
4.3.3 Detection of Malicious Trafﬁc in Dataset I
As deﬁned in Section 3.5, vagabond events are those that
do not have any valid user events as their root triggers.
There are total 1.2% vagabond HTTP requests in Dataset
I. Some of them are malicious traﬃc to known blacklisted
websites. Our analysis ﬁnds in Dataset I that among these
vagabond events, there are 169 suspicious requests sent to
36 distinct domains. Manual inspection reveals that these
requests are to tracking sites, malware-hosting or blacklisted
sites, and aggressive adware. They are partly due to users
visiting compromised web sites. For example, some requests
track the user’s cookies and send back to remote hosts with
known blacklisted sites (e.g., 2o7.net, imrworldwide.com, me-
diaplex.com). We analyze the geographic locations of the
malicious servers based on their IP addresses. All of them lo-
cate in the US, except one IP located in Netherlands. Some
of the vagabond requests are false alerts (described in Sec-
tion 4.3.4).
4.3.4 False Alerts
In our model, false alerts refer to the network requests
that are vagabond requests (i.e., requests without proper
triggers), but are legitimate (benign). False alerts in Dataset
I are due to four main reasons:
• Automatic and periodic system and application up-
dates that occur without user triggers. In Dataset I
there are 157 update requests that are sent to 13 well-
known legitimate domains. Whitelisting can be used
to eliminate these alerts.
• Missing or incomplete attributes in the original data
due to server conﬁguration, e.g., redirection without
properly setting the referrer ﬁeld. There are 244 mis-
conﬁgured requests that are sent to 38 diﬀerent do-
mains, usually image/video hosting websites.
• Unconventional attribute values, e.g.,
requests to
googlesyndication.com (for Google Map) usually have
long referrers that our prototype does not expect.
• Requests sent out much later than their parent request
trigger, e.g., requests for favorites or bookmark icons.
Reducing false alerts can be achieved through more so-
phisticated inference methods under incomplete informa-
tion, which will be investigated in our future work.
4.4 Causality Analysis of Datasets II
For dataset II, the goal of the experiment is to ﬁnd the
triggering relation in traﬃc with mixed types, such as DNS
(d) 80 82 84 86 88 90 92 94 96 98 100 92 93 94 95 96 97 98 99 1000110013001500110001200013000150001100099.6099.6299.6499.6699.6899.7099.7299.7499.7699.7899.80Pairwise Accuracy (%)Naïve BayesBayesian NetworkSVM01100130015001100012000130001500011000(a)(b)(c)Cost matrixCost matrixCost matrixCost matrix011001200130015005100310021097.0097.5098.0098.5099.0099.50100.00Pairwise Accuracy (%)Naïve BayesBayesian NetworkSVM0110012001300150051003100210Root-trigger Correctness (%)Root-trigger Correctness (%)46and HTTP requests. Features used for classiﬁcation are
given in Table 9 in the Appendix.
4.4.1 Pairwise Classiﬁcation Accuracy
The pairwise classiﬁcation results on dataset II are pre-
sented in Table 5. All three methods give high pairwise clas-
siﬁcation accuracy, conﬁrming our method’s ability of dis-
covering triggering relations in mixed traﬃc types. Bayesian
network and SVM yield better results than naive Bayes
classiﬁer, indicating that there are dependencies among at-
tributes.
The pairwise classiﬁcation accuracy under various cost
matrices is shown in Figure 3 (c). Bayesian network and
SVM consistently give high classiﬁcation accuracy. In con-
trast, the performance of naive Bayes classiﬁer decreases, as
the cost matrix penalizes FNs more than FPs. We highlight
the pairwise classiﬁcation accuracy results under the cost
matrix
(cid:104)0, 1
(cid:105)
in Table 5.
1, 0
4.4.2 Correctness of Root Triggers
We analyze the root-trigger accuracy for Dataset II, and
show the results in Figure 3 (d). The root-trigger accuracy is
high when using all three classiﬁers, with Bayesian network
and SVM outperform the naive Bayes. We highlight the
root-trigger accuracy results under the cost matrix of
in Table 7.
(cid:104)0, 1
(cid:105)
1, 0
Cost Matrix
Correct (case a-c)
Wrong (case d-f)
Wrong (case g)
Naive Bayes Bayesian Network
(cid:104)0, 1
(cid:105)
1, 0
(cid:104)0, 1
(cid:105)
1, 0
SVM
(cid:104)0, 1
(cid:105)
1, 0
98.44%
1.37%
0.19%
100.00%
0.00%
0.00%
100.00%
0.00%
0.00%
Table 7: Root-trigger results on Dataset II. Cases
(a-g) refer to the various predicted root-trigger out-
comes in Figure 4 in the Appendix.
4.5 DNS Bot Detection
is extremely stealthy and diﬃcult
Botnet command and control channel using DNS tun-
neling [1]
to de-
tect [40]. We write a proof-of-concept bot that commu-
nicates with its bot master by tunneling command and
control messages in DNS traﬃc. The bot generates care-
fully crafted outbound DNS queries whose payload contains
encoded data e.g.,
NBSWY3DPFQQHO33SNRSA000.domain.com,
d1js21szq85hyn.cloudfront.net. These bot queries are mixed
with a 2-hour DNS-HTTP traﬃc dataset, which is then an-
alyzed by our causality tool. Our evaluation conﬁrms that
our method successfully recognizes all the bot DNS queries
as anomalies. These DNS queries do not have the valid user-
event root triggers.
4.6 Causality Analysis of Datasets III
For Dataset III, the goal of the experiment is to ﬁnd
the triggering relation between inbound and outbound TCP
packets by using our machine learning method. The accu-
racy results of pairwise triggering relation are in Table 5. All
three classiﬁcations yield high values for the pairwise classi-
ﬁcation accuracy, with Bayesian network and SVM outper-
forming naive Bayes classiﬁer. The features used for classi-
ﬁcation are shown in Table 10 in the Appendix.
4.7 Precision and Recall
Our methods result in high precision and recall for all
data sets. In addition, the methods produce high pairwise
classiﬁcation accuracy and root-trigger correctness. Of par-
ticular signiﬁcance are Bayesian Network and SVM, which
yield the precision and recall of 1.0, a 100% pairwise clas-
siﬁcation accuracy, and a 100% root-trigger correctness for
Dataset II.
Precision values are slightly lower than recall values in
general, indicating more false positives than false negatives
in the classiﬁcation results.
(False positive means ﬁnding
triggering relations in non-related pairs. False negative is
the failure to discover triggering relations.) The reason for
slightly lower precision values is partly due to the customized
penalty weights in the cost matrix.
4.8 Performance
Runtime results are obtained on a machine with Intel Duo
Processor E8400, 3GB RAM and 250GB HDD. For each
data set, we report the runtime of pairing, training, classi-
ﬁcation, and ﬁnd-root operations. The means reported in
Table 8 are averaged from ﬁve runs. Standard deviations
are negligible and not shown.
Data
Pair
Train
Classify
NB BN SVM
NB
BN
Find
SVM Root
I
II
III
1848
622
14686
0.5
0.8
2.6
1.2
2.1
7.9
79.9
13.4
546
22.7
4.0
431
16.8
2.2
411
14.2
2.1
446
1.7
0.6
–
Table 8: Averaged performance (in seconds) of Pair-
ing, Train, Classiﬁcation, and Find-root operations.
NB and BN stand for Naive Bayes and Bayesian
Network classiﬁers, respectively. Pairing time in-
cludes feature extraction.
According to Table 8, the train, classiﬁcation, and root-
ﬁnding operations are fast. The Pairing operation is the
most time-consuming task in our method. For example, it
can take as long as 4 hours to generate the pairs from 3
million TCP messages (42 days of a server’s TCP data). Our
experiments have determined that on a single day, at most
200MB of pairwise data can be generated from a server’s
TCP packet headers. As for the processing time, generating
the daily pairwise data takes only 6 minutes on average,
indicating that our method is eﬃcient enough for practical
use.
4.9 Summary
We summarize our experimental ﬁndings below.
• Bayesian network gives the best analysis accuracy for
all datasets. The naive Bayes classiﬁer gives the lowest
accuracy, indicating the existence of dependencies in
pairwise features. The accuracy can be improved by
strategically deﬁning the cost matrix.
• Precision and recall metrics are more sensitive to the
quality of the classiﬁcation results than the pairwise
accuracy metric. The fundamental reason for this dif-
ference is the sparsity of the triggering relations, which
results in diﬀerent sizes of the denominators in these
metrics.
• Our causality analysis successfully reveals all the out-
bound traﬃc to 36 malicious domains, i.e., with zero
false negative rate. Our tool also detects the stealthy
47network activities from our proof-of-concept browser
spyware, DNS bot, and stand-alone data-exﬁltrating
malware.
• Limitations In our optimized prototype, Pairing oper-
ation (for extracting pairwise features) has high com-
putational overhead. This overhead is due to the
quadratic complexity in pairing. Heuristics for im-
proving the pairing eﬃciency may result in decreased
analysis accuracy. We will investigate this tradeoﬀ in
our future work.
Our current feature extraction method does not han-
dle well HTTP requests involving incomplete or un-
conventional attributes. The failure of recognizing the
causality in these requests results in false alerts. Ad-
vanced inference techniques are required to improve
this recognition.
5. RELATED WORK
The classiﬁcation and discovery of application or service
dependencies for management and reliability purposes have
been recently reported [7,9,22,23,31,43]. These existing ser-
vice dependency analysis solutions diﬀer from our triggering
relation discovery work in two aspects.
• The semantics of relations to be discovered are diﬀer-
ent, as the dependency in those papers refers to the
reliance on services provided by others, not the trig-
gering relation.
• The granularity of analysis diﬀers, requiring com-
pletely diﬀerent techniques; our request-level trigger-
ing relations is more ﬁne-grained than service- or
application-level dependencies.
Machine learning approaches have been widely adopted
in the security literature, since the work by Lee, Stolfo, and
Mok [26]. The solutions described in [13, 29] use machine
learning techniques to capture characteristics of Javascript
code and identify malicious Javascript code. Xie et al. [39]
proposed to use Bayesian network on justifying the impor-
tant types of uncertainty in real time security analysis. How-
ever, their work is not designed for analyzing request-level
network traﬃc. EXPOSURE [8] is designed to detect do-
mains involved in malicious activities by conducting large-
scale and passive DNS analysis at network level. Authors
extracted 15 features of DNS traﬃc and used J48 classiﬁer
to ﬁnd the malicious domains. EXPOSURE classiﬁes the
DNS request on an individual basis, while we use the ma-
chine learning tools on the pairwise relations. Besides, our
method can be adopted to various types of network traﬃc.
Nguyen and Armitage surveyed on Internet traﬃc classi-
ﬁcation using machine learning methods in [32]. Williams
et al. [38] did an empirical study on summarizing the fea-
tures from payload-independent features. Their work clas-
siﬁes IP traﬃc ﬂows. Besides computer traﬃc classiﬁcation,
learning-based security research includes database intrusion
detection [35], identifying botnet traﬃc [30], and SMS/social
network spam detection [37, 42]. Compared to these afore-
mentioned learning-based security solutions, the uniqueness
of our triggering relation discovery model and technique is
the ability to automatically extract and recognize directional
relations and structures. Our problem is beyond the conven-