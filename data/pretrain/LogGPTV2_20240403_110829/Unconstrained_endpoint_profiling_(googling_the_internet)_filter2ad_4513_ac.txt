82.64.0.0/14
couple of hours in duration while the ﬂow-level trace is almost a
week long. These traces are invaluable for the following two rea-
sons. First, they present the necessary ‘ground truth’ that helps
us evaluate how well does our approach (without using any op-
erational traces) work to discover active IP ranges (Section 3.1)
and classify trafﬁc at given networks (Section 3.2). Second, we
use these traces to understand how our approach can be applied in
the classical trafﬁc classiﬁcation scenarios, both using packet-level
(Section 3.3) and ﬂow-level (Section 3.4) traces.
To preserve privacy of the collaborating ISPs, in Table 3, we
anonymize the appropriate IP ranges by removing the ﬁrst Byte
from the address. We do not anonymize the IP range for the Euro-
pean ISP (Proxad, http://www.free.fr/, AS 12322), sim-
ply because we use no operational network trace. In this case, we
stick with the endpoint approach, and thus only use publicly avail-
able information.
3.1 Revealing Active Endpoints
First, we explore if the Google hits can be used to infer the ac-
tive IP ranges of the target access networks. This knowledge is in-
valuable in a number of scenarios. For example, for Internet-scale
measurement projects (e.g., [32]) knowing which IPs are active in
a given ISP can help direct measurements towards the active parts
of the address space. The approach is particularly useful given that
large-scale active probing and network scanning might trigger a
ban from either the host or the targeted ISP. Indeed, our indirect
approach efﬁciently solves this problem since we get the targeted
active IP subset by simply googling the IP addresses.
To demonstrate the potentials of this approach, we show results
for the XXX.163.0.0/17 network range, which spans 32,767 IP ad-
dresses. As one source of information about active IPs, we google
this IP range. As another source, we extract the active IP ad-
dresses from a packet-level trace we obtained from the correspond-
ing ISP. Necessarily, a relatively short trace does not contain all
active IPs from this network range. The results are as follows. We
extract 3,659 active IPs using Google. At the same time, we extract
Google hits
Actual endpoints
 0
 20
 40
 60
3rd IP byte - last 7 bits
 80  100  120
 100
 50
 0
 250
 200
4th IP byte
 150
Figure 2: Inferring endpoints - XXX.163.0.0/17
2,120 IPs from the trace. The overlap is 593 addresses, or 28%
(593/2120).
By carefully examining the two results, we ﬁnd that spatial cor-
relation is high, i.e., in each trace the active IPs are very close in IP
space. Indeed, to ease network management, network administra-
tors typically assign contiguous IP addresses to hosts in the same
network. To exploit this feature, we proceed as follows. For each
of the active IP addresses (Google- and trace-based), we select a
small IP range window.4 If the distance between 2 IPs is less than
the window size, we denote all IPs between the two as active.
Figure 2 shows the results for both Google- and trace-based ac-
tive hosts obtained in this way. Indeed, the ﬁgure shows high spatial
correlation between the two sets. In particular, enhanced Google-
based trace now has 12,375 IPs, while enhanced network trace has
10,627 IPs. The number of overlapped addresses is as high as
8,137, such that the overlap between the two sets now becomes
77% (8,137/10,627).
We stress once again that the key point of this approach is not to
accurately predict if a given IP address is active or not, but rather to
hint at the highly probable active IP ranges and ease methodologies
that require such information (e.g., [32]). One other observation is
that the active IP coverage obtained with this approach increases
as the studied network range increases. This is because the dis-
tance between active IP clusters increases with the size of the stud-
ied network. Consequently, we note that this approach becomes
even more useful in the context of IPv6. This is because network
ranges will become larger; hence, randomly probing a certain net-
work space might immediately trigger a ban.
3.2 When No Traces are Available
Table 8 (Appendix) shows the comprehensive results (includ-
ing statistics about operating systems, browsers, malicious activity,
p2p, protocols and services, chat, gaming, and most popular sites)
we obtained by applying the unconstrained endpoint approach on
a subset of the IP range belonging to the four ISPs shown in Ta-
ble 3. In particular, we explore approximately 200,000 randomly
chosen IP addresses from each of the four world regions. We em-
phasize that the information in Table 8 is obtained solely using the
Google-based approach, without exploiting any information from
the operational network traces, nor any other sources.
The key question we aim to answer here is how representative are
these results. In particular, can they be used to predict the popular-
ity of a given application in a given world region? Or, is there any
correlation between these results and operational network traces
collected at given networks? We answer these questions by com-
4Numerous experiments on other network ranges corroborate that
the window of 17 shows the best compromise between maximizing
the overlap between Google- and trace-based active IPs and mini-
mizing the size of enriched subsets.
paring results from Table 8 with the ‘ground truth,’ in the form of (i)
traces from operational networks, and (ii) other publicly available
information such as from news articles about endpoint behavior.
Correlation with operational traces. We select the S. Amer-
ican trace to exemplify correlation between the results from Ta-
ble 8 and the network traces. Other network traces (Asia and N.
America) show results consistent with this example, as we explain
below. In particular, we compare the following trafﬁc categories:
p2p, chat, gaming, and browsing. Other characteristics, such as
OS type, browser type, spam, etc., are either hard or impossible to
extract from network-level traces.
We ﬁnd a remarkable correlation between the two sources. Specif-
ically, in three of the four trafﬁc categories, we ﬁnd that the leading
applications shown in Table 8 is also the leading application in the
trace. In particular, Gnutella is the leading p2p system, msn is
the leading chat software, and Google is the leading website in the
trace. Similarly, for all other scenarios where our system detects a
strong application presence (e.g., ppstream and Tencent QQ
software in China), that behavior is inevitably reﬂected in traces as
well.
Necessarily, not always does the information from network traces
and Table 8 stay in the same order. For example, results for gam-
ing applications found in the traces are often not in the same order
as shown in Table 8. The same can happen for the relative or-
der among other applications as well. For example, Orkut comes
before wikipedia in the network trace, contrary to the results
shown in Table 8.
The reasons for this behavior are obvious. The results in Table 8
represent a spatial sample (over the IP space) averaged over time.
On the other hand, results from the trace represent a sample taken in
a short time interval, i.e., a few hours in this particular case (South
American ISP). Still, the key point here is that despite differences
in the nature of the data present in Table 8 and that taken from
operational networks, there is still a remarkably high correlation.
Apparently, when an application is strongly present in a given area,
this result shows up consistently both in network traces and in Table
8.
Correlation with other sources. Here, we compare the results
from Table 8 with other publicly available sources. One example is
the presence of operating systems in different world regions. As we
can see, Windows is the leading operating system in all examined
regions except France where the Debian Linux distribution is
prevalent. This is not a surprise given that French administration
and schools run Linux distributions [10–12]. Note that a similar
trend can be observed in Brazil, where Windows has only a small
advantage over Linux. Again, this is because similar measures to
the ones in France have been implemented in Brazil as well [9]. A
related issue is that of browsers. We can see that Mozilla is more
popular in France and Brazil, as a natural result of the operating
systems popularity.
Another example is p2p activity. Table 8 reveals some previously-
reported locality tendencies, such as torrents and eMule being
widely used in France [39], and p2p streaming software being very
popular in China [5]. Likewise, our results conﬁrm the well-known
‘Googlemania’ phenomenon. They also reveal that wikipedia
is a very popular website all over the world. This is not the case
for China, where the number of hits is low, potentially due to a
ban [17] at some point. Similarly, Orkut, the social network built
by Google, shows hits in Brazil, the region where it is very popu-
lar [1, 14].
Summary. Strong correlation between the data from Table 8 and
those from operational network traces and elsewhere imply that the
unconstrained endpoint proﬁling approach can be effectively used
to estimate application popularity trends in different parts of the
world. We demonstrate that this is possible to achieve in a uni-
ﬁed and methodical way for all different world regions, yet without
using any operational network traces.
3.3 When Packet-Level Traces are Available
Trafﬁc classiﬁcation (based on operational network traces) is an-
other case where the unconstrained endpoint approach can be ap-
plied. Indeed, the state-of-the-art trafﬁc classiﬁcation tools are con-
strained in several ways. To the best of our knowledge, all cur-
rent approaches try to classify trafﬁc by exclusively focusing on
observed packets and connection patterns established by the end-
points. One example is BLINC [29], which uses a graphlet based
approach to classify network trafﬁc. Issues with such an approach
are the following. First, BLINC is primarily an off-line tool that
might be challenging to deploy in the network core. Second, clas-
siﬁcation semantics of such a system is not particularly rich at the
application level. For example, it can classify a ﬂow as p2p, but
cannot say which particular protocol it is. Finally, it relies upon
ad-hoc thresholds, which might produce variable quality results for
different traces, as we show below. For the same reason, the ap-
proach simply falls apart when sampled trafﬁc traces are available,
as we demonstrate later.
Table 4: Determining trafﬁc classes and user behavior
Client tag
Server tag
Trafﬁc class,
User behavior
web user, proxy user
mail server
website
mail server
 node
[abuser] [blocked]
server
n/a
n/a
[streaming node]
affected host
p2p node
[ftp share]
chat server
IRC server
[streaming node]
affected host
p2p node
ftp server
Browsing
Mail
Gaming
Chat
Chat
Streaming
Malware
P2P
Ftp
The unconstrained endpoint approach can be applied in a straight-
forward way to the trafﬁc classiﬁcation problem.
In particular,
there is no reason to constrain ourselves to strictly observing pack-
ets and connection patterns. Indeed, why not use the externally col-
lected information about the endpoints to classify trafﬁc? Contrary
to classiﬁcation in the ‘dark’ approaches (e.g., BLINC), we argue
that the endpoint-centric approach can not only provide superior
classiﬁcation results, but also efﬁciently operate at online speeds.
 100
 80
 60
 40
 20
]
%
[
c
i
f
f
a
r
T
 0
 0
Asian ISP Trace
S. American ISP Trace
N. American ISP Trace
 2
 4
 6
 8
 10
IP Addresses[%]
Figure 3: Trafﬁc destinations
conﬁrms strong endpoint bias for all traces: Asian, S. and N. Amer-
ican. In particular, 1% of endpoints account for more than 60% of
the trafﬁc, and 5% endpoints carry more than 95% of trafﬁc in all
cases.
We apply the endpoint approach to classify trafﬁc for the Asian
and S. American ISPs for which we have packet-level traces.5 In
particular, we do this in two phases. First, we collect the most pop-
ular 5% of IP addresses and tag them by applying the methodology
from Section 2. Next, we use this information to classify the trafﬁc
ﬂows into the classes shown in Column 3 of Table 4. The classiﬁ-
cation rule is simple – if one of the endpoints in a ﬂow is tagged by
a server tag, e.g., as a website, then the ﬂow is classiﬁed appro-
priately, e.g., as Browsing. The detailed classiﬁcation rules are as
shown in the mapping between Column 2 and Column 3 in Table
4.
Table 5 shows the classiﬁcation results relative to BLINC for the
S. American trace. We get similar results for other traces. In all
cases, we manage to classify over 60% of the trafﬁc. At the same
time, BLINC classiﬁes about 52% of trafﬁc in the Asian case, and
29.60% in the S. American case (Figure 5 for x=1 and Table 5).
Also, in addition to outperforming BLINC quantitatively, the end-
point approach provides a much richer semantics quality. For ex-
ample, we are able not only to classify trafﬁc as chat, but accurately
pinpoint the exact type, e.g., msn vs. yahoo vs. usenet.
Since a ﬂow is classiﬁed by the endpoint(s) that it involves, the
correctness of our trafﬁc classiﬁcation is dependent on the correct-
ness of our endpoint proﬁling. We next explore the issue of correct-
ness by comparing the set of endpoints classiﬁed by our approach
versus BLINC. Table 6 shows the percentage breakdown per class
(for S. America trace) in terms of endpoints found by both BLINC
and our approach (B∩U), only by BLINC (B-U) and only by our
approach (U-B). It is clear that our approach uncovers more end-
points and hence classiﬁes more trafﬁc. Moreover, the number of
endpoints that a constrained approach such as BLINC failed to clas-
sify is quite high (100% of streaming, mail and Ftp). Finally, it is
also worth noting that the number of endpoints our approach failed
to classify is fairly limited (7% of chat, 10% of browsing and 8%
of p2p and 0% in others). Infact, as we will explain in detail in the
next subsection, while analyzing sampled trafﬁc, the gap between
BLINC and our approach widens even further; the number of end-
points that only our approach classiﬁes becomes higher than 91%
for all classes.
One last question remains to be answered: why was the endpoint
approach unable to classify the remaining 38% of the trafﬁc? By
carefully examining the traces, we realize that the vast majority of
unclassiﬁed trafﬁc is p2p trafﬁc, either ﬁle sharing or streaming.
The key reason why these p2p ‘heavy hitters’ were not classiﬁed
by the endpoint approach is because information about these IPs
is not available on the web (or at least not found by Google).
Still, these IPs are traceable (e.g., [31]); indeed, we found many
of these unclassiﬁed IP addresses by joining and searching popu-
lar p2p systems (e.g., BitTorrent). This certainly implies that the
trafﬁc classiﬁcation result for the endpoint approach could be fur-
ther improved. Still, we refrain from pursuing that direction at this
point. This is because the information collected from the web is
sufﬁcient to demonstrate the superiority of the endpoint approach
over BLINC, even more so in sampled scenarios as we show below.
The ﬁrst reason that makes this approach online capable is its
ability to classify trafﬁc based on a single observed packet for which
one of the endpoints is revealed (e.g., a web server). The second
reason is a huge bias of trafﬁc destinations (e.g. 95% of trafﬁc is tar-
geted to 5% of destinations [41]). The implication is that it is possi-
ble to accurately classify 95% of trafﬁc by reverse-engineering 5%
of endpoints, which can be cached in the network. Indeed, Figure 3
5Because the N. American trace is a sampled Netﬂow trace, we
discuss it in the next subsection.
6Malware for BLINC indicates scan trafﬁc. However, for our end-
point approach it includes trojans, worms, malware, spyware and
bot infected trafﬁc.
7We do not compare Malware class due to different deﬁnitions be-
tween BLINC and UEP.
Table 5: Trafﬁc classes for S. America
1:100 Sampled trace
(% of sampled ﬂows)
BLINC
Class
Chat
Browsing
P2P
Gaming
Malware6
Streaming
Mail
Ftp
Packet trace
(% of total ﬂows)
BLINC
UEP
3.38
0.398
44.70
23.16