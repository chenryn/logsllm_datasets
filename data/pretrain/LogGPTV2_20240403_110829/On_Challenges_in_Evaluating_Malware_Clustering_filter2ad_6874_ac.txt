Anubis). Results are shown in Table 3. These results again show that the plagiarism
detectors produce comparable clustering results to BCHKK-algo when AV is the refer-
ence, offering generally greater precision, worse recall, and a similar F-measure.
Table 3. Applying plagiarism detectors and malware clustering on VXH-data
prec(C,D) recall(C,D) F-measure(C,D)
D
C
BCHKK-algo
API3Gram
APISeq
API3Gram
APISeq
AV
BCHKK-algo
0.604
0.788
0.704
0.790
0.770
0.659
0.502
0.536
0.826
0.798
0.630
0.613
0.609
0.808
0.784
Surprisingly, however, these measures indicate that both BCHKK-algo and our pla-
giarism detectors perform more poorly on VXH-data than they did on BCHKK-data.
On the face of it, the results in Table 3 do not support the conjecture of Section 3,
i.e., that determining a reference clustering of malware instances based on the concur-
rence of anti-virus engines might bias the reference clustering toward easy-to-cluster
instances. After all, were this the case, we would think that some method (if not all
methods) would do well when AV is used as the reference clustering. Instead, it may
simply be the case that the plagiarism detectors and malware clustering tools leverage
features for clustering that are more prevalent in BCHKK-data than in VXH-data. In
that case, one might thus conclude that these features are not sufﬁciently reliable for
use across a broad range of malware.
Of course, the results of this section must be taken as a bit more speculative, owing
to the different systems (CWSandbox and Anubis) from which the malware traces were
gathered before being consumed by the clustering techniques we consider. It is true that
there is substantial variability in the length and composition of the API sequences gath-
ered by the different tools, in some cases. For example, Figure 1 shows the CDFs of the
248
P. Li et al.
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
F
D
C
0
100
101
Anubis/BCHKK−data
CWSandbox/VXH−data
CWSandbox/BCHKK−data
102
103
Length of API call sequence
104
105
Fig. 1. Lengths of API call sequences extracted from BCHKK-data or VXH-data datasets using
CWSandbox or Anubis. Note that x-axis is log-scale.
API call sequence lengths elicited by the different tools. As can be seen in Figure 1, no
tool was uniformly better than the other in extracting long API call sequences, though
it is apparent that the sequences they induced are very different in length.
Another viewpoint is given in Figure 2, which shows the fraction of malware in-
stances
in each dataset in which certain activities are present. While some noteworthy dif-
ferences exist, particularly in behaviors related to network activity, it is evident that
both tools elicited a range of activities from large portions of the malware datasets.
We suspect that some of the differences in frequencies of network activities (partic-
ularly “send data” and “receive data”) result from the dearth of other malware in-
stances with which to communicate at the time the malware was run in CWSandbox.
Again, and despite these differences, our validation tests reported in Table 2 suggest
that the sequences induced by each tool are similarly effective in supporting clustering
of BCHKK-data.
Activity
Searched Strings
BCHKK-data BCHKK-data VXH-data
(Anubis)
(CWSandbox) (CWSandbox)
create new process
open reg key
query reg value
create reg key
set reg value
create ﬁle
send ICMP packet
try to connect
found no host
send data
receive data
“CreateProcess”
“RegOpenKey”
“RegQueryValue”
“RegCreateKey”
“RegSetValue”
“CreateFile”
“IcmpSendEcho”
“connect”, “WSASocket”
“WSAHOST NOT FOUND”
“AFD SEND”, “socket send”
“AFD RECV”, “socket recv”
100%
100%
100%
98.70%
98.30%
100%
82.10%
85.10%
N/A
83.10%
83.20%
87.40%
95.00%
94.80%
98.20%
97.10%
98.10%
82.60%
89.80%
72.30%
1.50%
1.40%
70.80%
92.90%
89.00%
94.20%
80.40%
80.60%
0.71%
34.70%
9.06%
14.40%
14.90%
Fig. 2. Percentage of malware instances in which listed behavior is observed
On Challenges in Evaluating Malware Clustering
249
The evidence above suggests to us that a different reason for the relatively poor ac-
curacy of BCHKK-algo and our plagiarism detectors on VXH-data is at work. One pos-
sible contributing factor is that BCHKK-data samples within the same reference cluster
tended to produce API-call sequences of more uniform length than did VXH-data sam-
ples in the same reference cluster. For example, the relative standard deviation of the
API sequence lengths per cluster in BCHKK-data, averaged over all clusters, is 23.5%
and 6.9% for traces produced by Anubis and CWSandbox, respectively, while this num-
ber is 130.5% for CWSandbox traces of VXH-data. However, in the following section
we focus our attention on another explanation for the poorer clustering performance on
VXH-data versus BCHKK-data, and that we believe is more generally instructive.
5 Effects of Cluster-Size Distribution
In seeking to understand the discrepancy between the precision and recall of the BCHKK-
algo (and plagiarism-detection) clustering on the BCHKK-data (Section 3) and VXH-
data datasets (Section 4), one attribute of these datasets that stood out to us is the dis-
tribution of cluster sizes in each. Speciﬁcally, the reference clustering for the BCHKK-
data is highly biased, in that it contains two large clusters comprising 48.5% and 27%
of the malware instances, respectively, and remaining clusters of size at most 6.7%. In
contrast, the VXH-data reference dataset is more evenly distributed; the largest cluster
in that dataset comprises only 14% of the instances. Figure 3 shows the cluster size
distribution of the reference clustering of each dataset; note that the x-axis is log-scale.
The reason that cluster size distribution matters can be seen from an example of
clustering 8 points in one of two extreme ways. If when clustering these 8 points, the
reference clustering D comprises two clusters, one of size 7 and one of size 1, then
any other clustering C of these 8 points into two clusters of size 7 and 1 is guaranteed to
yield prec(C,D) and recall(C,D) of at least 7/8. If, on the other hand, D comprises two
clusters of size 4 each, then another clustering C could yield prec(C,D) and recall(C,D)
= 36/70 of such clusterings do so. In this sense,
as low as 4/8, and in fact
(cid:4)
/
(cid:4)(cid:3)
(cid:3)
(cid:3)
(cid:4)
8
4
4
2
4
2
1
0.9
0.8
F
D
C
0.7
0.6
0.5
100
BCHKK−data
VXH−data
101
102
number of instances in one cluster
103
104
Fig. 3. Reference cluster-size distribution of BCHKK-data and VXH-data. Note that x-axis is
log-scale.
250
P. Li et al.
it is considerably “harder” to produce a clustering yielding good precision and recall
in the latter case, and a good precision and recall in the latter case is thus much more
signiﬁcant than in the former.
While providing insight, this combinatorial argument is too simplistic to illustrate
the effect that cluster size distribution plays in the BCHKK-algo clustering of the VXH-
data and BCHKK-data datasets. A more direct, but still coarse, indication of this effect
can be seen by downsampling the large clusters in the BCHKK-data dataset. Specif-
ically, we randomly removed malware instances from the two largest families in the
BCHKK-data reference clustering until they were each of size 200. After re-clustering
the remaining malware instances using BCHKK-algo with the same parameters, the re-
sulting F-measure averaged over 10 downsampling runs was only 0.815 (versus 0.956
before downsampling).
An alternative and more reﬁned view of the effects of signiﬁcance to the cluster-
ing results of BCHKK-algo for the VXH-data and BCHKK-data datasets can be seen
by illustrating the resilience of the clustering results to perturbations in the underly-
ing distance matrix. The heart of the BCHKK-algo clustering technique is the distance
measure that it develops, which is tuned to measure the activities of malware. As such,
one strategy in examining the potential for bias due to cluster-size distribution is to
introduce perturbations into the original BCHKK-algo distance matrices for the VXH-
data and BCHKK-data up to some limit, re-cluster the resulting distance matrix into the
same cluster-size distribution, and evaluate the rate at which the precision and recall
drop. Intuitively, if the precision and recall drop more quickly for the VXH-data than
for the BCHKK-data, then this supports the idea that minor errors in the BCHKK-algo
distance are more ampliﬁed (in terms of the effects on precision and recall) when the
clusters are distributed as in the VXH-data than when they are distributed as in the
BCHKK-data dataset. By the contrapositive, this will show that a high precision and
recall in the VXH-data case is more signiﬁcant.
In attempting to perform this analysis, however, some difﬁculties arise.
– The BCHKK-algo distance matrices for the VXH-data and BCHKK-data datasets
are different in that the VXH-data matrix results in precision and recall far below
that yielded by BCHKK-data. As such, the VXH-data matrix is already “decayed”
more from the best possible precision and recall than is that for the BCHKK-data;
introducing perturbations in an already decayed distance matrix will do little to
demonstrate the sensitivity of a highly accurate distance matrix to perturbations.
In order to start from good precision and recall, then, we adopt the testing VXH-
data matrix and BCHKK-data matrix (i.e., resulting from BCHKK-algo) as the
reference matrices, i.e., so that we start from precision and recall of 1.0. We then