# 17 \| 分布式计算模式之Actor：一门甩锅的艺术你好，我是聂鹏程。今天，我来继续带你打卡分布式核心技术。 我在前两篇文章中，带你一起学习了 MapReduce 和 Stream计算模式，相信你对批处理和流计算也有了一定的了解。虽然这两种计算模式对数据的处理方式不同，但都是以特定数据类型（分别对应静态数据和动态数据）作为计算维度。 在接下来两篇文章中，我将从计算过程或处理过程的维度，与你介绍另外两种分布式计算模式，即Actor和流水线。分布式计算的本质就是在分布式环境下，多个进程协同完成一件复杂的事情，但每个进程各司其职，完成自己的工作后，再交给其他进程去完成其他工作。当然，对于没有依赖的工作，进程间是可以并行执行的。 你是不是想说，分布式进程那么多，如果需要开发者自己去维护每个进程之间的数据、状态等信息，这个开发量可不是一般得大，而且特别容易出错。那么，有没有什么办法可以让开发者只关注自己的逻辑呢？ 答案是肯定的，Actor计算模式就能满足你的需求。也就是说，你可以把数据、状态等都扔给Actor。这是不是"一门甩锅的艺术"呢？ 接下来，我们就一起打卡分布式计算模式中的 Actor模式。 什么是 Actor？在第 10 篇文章"分布式体系结构之非集中式结构：众生平等"中，我曾提到 Akka 框架基于 Actor模型，提供了一个用于构建可扩展的、弹性的、快速响应的应用程序的平台。 其中，Actor 类似于一个"黑盒"对象，封装了自己的状态和行为，使得其他Actor 无法直接观察到它的状态，调用它的行为。多个 Actor之间通过消息进行通信，这种消息类似于电子邮箱中的邮件。Actor接收到消息之后，才会根据消息去执行计算操作。 那么， **Actor模型又是什么呢？**Actor模型，代表一种分布式并行计算模型。这种模型有自己的一套规则，规定了 Actor的内部计算逻辑，以及多个 Actor 之间的通信规则。在 Actor 模型里，每个Actor相当于系统中的一个组件，都是基本的计算单元。 **Actor 模型的计算方式与传统面向对象编程模型（Object-OrientedProgramming，OOP）类似**，一个对象接收到一个方法的调用请求（类似于一个消息），从而去执行该方法。 但是，OOP因为数据封装在一个对象中，不能被外部访问，当多个外部对象通过方法调用方式，即同步方式进行访问时，会存在死锁、竞争等问题，无法满足分布式系统的高并发性需求。而Actor 模型通过消息通信，采用的是异步方式，克服了 OOP的局限性，适用于高并发的分布式系统。 举一个最简单的例子，假如你现在定义了三个对象 A、B 和 C，对象 C中有一个函数 Function，现在对象 A 和对象 B 同时调用对象 C 中的Function，此时对象 C 中的 Function 就成为了我们在第 3篇文章"分布式互斥：有你没我，有我没你slate-object="inline""中提到的共享资源，有可能会存在竞争、死锁等问题。 而对于 Actor 模式，对象 A、B 和 C 对应着 Actor A、Actor B 和 ActorC，当 Actor A 和 Actor B 需要执行 Actor C 中的 Function 逻辑时，Actor A和 Actor B 会将消息发送给 Actor C， Actor C 的消息队列存储着 Actor A 和Actor B 的消息，然后根据消息的先后顺序，执行 Function即可。 也就是说，Actor 模式采用了异步模式，并且每个 Actor封装了自己的数据、方法等，解决了 OOP存在的死锁、竞争等问题。 Actor 计算模式接下来，我们再一起看看 Actor 计算模式吧。如下图所示，描述了具有 3 个Actor 的 Actor 模型。 ![](Images/56eec8968df729091c3c8adbf3cb5163.png)savepage-src="https://static001.geekbang.org/resource/image/3d/11/3d64427315a82ef08f4dd0fc88d9a311.png"}可以看到，**Actor模型的三要素是状态、行为和消息**，有一个很流行的等式：Actor 模型 =（状态 + 行为）+消息。 接下来，我们一起看看这三要素的具体含义吧。 1.  状态（State）。Actor 的状态指的是，Actor 组件本身的信息，相当于    OOP 对象中的属性。Actor 的状态会受 Actor    自身行为的影响，且只能被自己修改。        2.  行为（Behavior）。Actor 的行为指的是，Actor    的计算处理操作，相当于 OOP 对象中的成员函数。Actor    之间不能直接调用其他 Actor 的计算逻辑。Actor    只有收到消息才会触发自身的计算行为。        3.  消息（Mail）。Actor 的消息以邮件形式在多个 Actor    之间通信传递，每个 Actor    会有一个自己的邮箱（MailBox），用于接收来自其他 Actor 的消息，因此    Actor 模型中的消息也称为邮件。一般情况下，对于邮箱里面的消息，Actor    是按照消息达到的先后顺序（FIFO）进行读取和处理的。        了解了 Actor 的三要素后，我们再一起看下 Actor的工作原理吧。 Actor 工作原理为了方便你理解 Actor 的工作原理，我会通过讲述 3 个 Actor之间基于消息和消息队列的工作流程进行说明。这 3 个 Actor的工作流程，如下所示。 ![](Images/a3b6d6884e63ff977ea05bc001c26b39.png)savepage-src="https://static001.geekbang.org/resource/image/ad/7f/addab9026cecd00194755f594b3ab87f.png"}1.       Actor1 和 Actor3 先后向 Actor2 发送消息，消息被依次放入 Actor2 的    MailBox 队列的队尾 ;        2.       Actor2 从 MailBox 队列的队首依次取出消息执行相应的操作，由于    Actor1 先把消息发送给 Actor2，因此 Actor2 先处理 Actor1    的消息；    3.       Actor2 处理完 Actor1 的消息后，更新内部状态，并且向其他 Actor    发送消息，然后处理 Actor3    发送的消息。        了解了 Actor之间的消息交互和处理流程，我再以一个具体案例和你详细解读一下 Actor之间的消息传递过程吧。 ![](Images/a58fa8723244ab74e4bd0313f5979893.png)savepage-src="https://static001.geekbang.org/resource/image/4d/d3/4d1e879439672d2052efd8dca0026dd3.png"}我们已经知道，在系统中，不同的组件 / 模块可以视为不同的Actor。现在有一个执行神经网络的应用，其中有两个组件 A 和B，分别表示数据处理模块和模型训练模块。假设，我们可以将组件 A 和 B看作两个Actor，训练过程中的数据可以通过消息进行传递。如上图所示，完整的消息传输过程为： 1.       组件 A 创建一个 Actor System，用来创建并管理多个    Actor。    2.       组件 A 产生 QuoteRequest 消息（即 mail    消息，比如数据处理后的数据），并将其发送给 ActorRef。ActorRef 是    Actor System 创建的组件 B 对应 Actor    的一个代理。        3.       ActorRef 将消息（经过数据处理后的数据）传输给 Message Dispatcher    模块。Message Dispatcher    类似于快递的中转站，负责接收和转发消息。        4.       Message Dispatcher 将消息（数据处理后的数据）加入组件 B 的    MailBox 队列的队尾。        5.       Message Dispatcher 将 MailBox 加入线程。需要注意的是，只有当    MailBox 是线程时，才能处理 MailBox    中的消息。        6.       组件 B 的 MailBox 将队首消息（数据）取出并删除，队首消息交给组件    B 处理，进行模型训练。        Actor 关键特征通过上面的描述，可以看出 Actor的通信机制与日常的邮件通信非常类似。因此，我们可以进一步总结出 Actor模型的一些特点： 1.  **实现了更高级的抽象。**        我在前面提到过，Actor 与 OOP    对象类似，封装了状态和行为。但是，Actor 之间是异步通信的，多个 Actor    可以独立运行且不会被干扰，解决了 OOP    存在的竞争问题。        2.  **非阻塞性。**        在 Actor 模型中，Actor 之间是异步通信的，所以当一个    Actor 发送信息给另外一个 Actor    之后，无需等待响应，发送完信息之后可以在本地继续运行其他任务。也就是说，Actor    模型通过引入消息传递机制，从而避免了阻塞。        3.  **无需使用锁**        。Actor 从 MailBox    中一次只能读取一个消息，也就是说，Actor    内部只能同时处理一个消息，是一个天然的互斥锁，所以无需额外对代码加锁。        4.  **并发度高。**        每个 Actor 只需处理本地 MailBox 的消息，因此多个 Actor    可以并行地工作，从而提高整个分布式系统的并行处理能力。        5.  **易扩展。**        每个 Actor 都可以创建多个 Actor，从而减轻单个 Actor    的工作负载。当本地 Actor 处理不过来的时候，可以在远程节点上启动    Actor 然后转发消息过去。        虽然 Actor模型有上述的诸多优点，但它并不适用于分布式领域中所有的应用平台或计算框架。因为，Actor模型还存在如下一些不足之处： 1.  Actor 提供了模块和封装，但缺少继承和分层，这使得即使多个 Actor    之间有公共逻辑或代码部分，都必须在每个 Actor    中重写这部分代码，也就是说重用性小，业务逻辑的改变会导致整体代码的重写。        2.  Actor 可以动态创建多个 Actor，使得整个 Actor    模型的行为不断变化，因此在工程中不易实现 Actor 模型。此外，增加    Actor    的同时，也会增加系统开销。        3.  Actor 模型不适用于对消息处理顺序有严格要求的系统。因为在 Actor    模型中，消息均为异步消息，无法确定每个消息的执行顺序。虽然可以通过阻塞    Actor 去解决顺序问题，但显然，会严重影响 Actor    模型的任务处理效率。        尽管 Actor模型在需要同步处理的应用等场景具有局限性，但它在异步场景中应用还是比较广泛的。接下来，我们就一起看看Actor 目前都应用在哪些地方吧。 Actor 模型的应用Actor 模型在 1973年被提出，已广泛应用在多种框架和语言中。可以说，很多框架或语言支持 Actor编程模型，是为了给开发者提供一个通用的编程框架，让用户可以聚焦到自己的业务逻辑上，而不用像面向对象等编程模型那样需要关心死锁、竞争等问题。 那么，到底有哪些框架或语言支持 Actor编程模型呢？将下来，我就和你列举几个典型的框架或语言吧，以方便你参考。 1.  Erlang/OTP。Erlang 是一种通用的、面向并发的编程语言，使用 Erlang    编写分布式应用比较简单，而 OTP 就是 Erlang 技术栈中的标准库。Actor    模型在 Erlang 语言中得到广泛支持和应用，其他语言的 Actor    逻辑实现在一定程度上都是参照了 Erlang 的模式。实现了 Actor    模型逻辑的    Erlang/OTP，可以用于构建一个开发和运行时环境，从而实现分布式、实时的、高可用性的系统。        2.  Akka。Akka 是一个为 Java 和 Scala    构建高度并发、分布式和弹性的消息驱动应用程序的工具包。Akka 框架基于    Actor    模型，提供了一个用于构建可扩展的、弹性的、快速响应的应用程序的平台。通过使用    Actors 和 Streams 技术， Akka    为用户提供了多个服务器，使用户更有效地使用服务器资源并构建可扩展的系统。        3.  Quasar (Java) 。Quasar 是一个开源的 JVM    库，极大地简化了高度并发软件的创建。Quasar 在线程实现时，参考了    Actor 模型，采用异步编程逻辑，从而为 JVM    提供了高性能、轻量级的线程，可以用在 Java 和 Kotlin    编程语言中。        知识扩展：Akka 中 Actor 之间的通信可靠性是通过 Akka 集群来保证的，那么 Akka 集群是如何检测节点故障的呢？在第 10 篇文章"分布式体系结构之非集中式结构：众生平等"中，我与你介绍了 Akka集群是一个去中心化的架构，比如现在集群中有 n 个节点，这 n个节点之间的关系是对等的。节点之间采用心跳的方式判断该节点是否故障，但未采用集中式架构中的心跳检测方法。 Akka 集群中的故障检测方法是，集群中每个节点被 k个节点通过心跳进行监控，比如 k = 3，节点 1 被节点 2、节点 3 和节点 4通过心跳监控，当节点 2 发现节点 1 心跳不可达时，就会标记节点 1为不可达（unreachable），并且将节点 1 为不可达的信息通过 Gossip传递给集群中的其他节点，这样集群中所有节点均可知道节点 1不可达。 其中，k个节点的选择方式是，将集群中每个节点计算一个哈希值，然后基于哈希值，将所有节点组成一个哈希环（比如，从小到大的顺序），最后根据哈希环，针对每个节点逆时针或顺时针选择k 个临近节点作为监控节点。 总结接下来，我们小结一下吧。今天，我与你介绍了分布式计算中，一门甩锅的计算模型，即Actor 模型。 首先，我介绍了什么是 Actor 模型以及 Actor模型的三要素，包括状态、行为和消息。 其次，我介绍了 Actor 的工作原理，并通过实例介绍了 Actor之间通过消息及消息队列进行异步通信的流程，以便于你进一步理解 Actor的工作原理。 最后，我为你介绍了几个当前支持 Actor编程模型的框架和语言，以便于你在需要采用 Actor模型编程时做一个参考。 最后，我再通过一张思维导图来归纳一下今天的核心知识点吧。 ![](Images/992bbc9f6d701ba08b3e84bb79119eaf.png)savepage-src="https://static001.geekbang.org/resource/image/d6/89/d605ba04f0eb88c6cd0910eef6af4489.png"}著名的 Erlang 并发编程语言，以及 Akka 这一分布式计算框架都实现了Actor 模型的计算逻辑。因此，即使你在之前未曾接触过 Actor模型，学习了这篇文章后，你也可以根据开源的 Erlang 或 Akka项目，去更深刻地理解 Actor模型了，加油！ 思考题Actor是否可以采用阻塞方式去运行呢，原因是什么呢？ 我是聂鹏程，感谢你的收听，欢迎你在评论区给我留言分享你的观点，也欢迎你把这篇文章分享给更多的朋友一起阅读。我们下期再会！ ![](Images/c191f391e2aab7575517a886bbd7a681.png)savepage-src="https://static001.geekbang.org/resource/image/a4/8c/a42a16601611a1a72599ecfca434508c.jpg"}
# 18 \| 分布式计算模式之流水线：你方唱罢我登场你好，我是聂鹏程。今天，我来继续带你打卡分布式核心技术。 通过前面几篇文章，我们一起学习了分布式计算模式中的 MapReduce、Stream和Actor，它们各显神通解决了很多实际问题。 但是，在现实生活中，经常还会出现这样的情况，前一个任务的结果是另外一个任务的输入。比如工厂生产一瓶饮料，首先需要往瓶子里装上饮料，待饮料装满后，再封口。如果装饮料和封口分别为子任务，那么前一个任务（装饮料）结束后才可以开始第二个任务（封口）。类似这样的作业，就是我们常说的流水线作业。 在分布式领域中解决类似具有依赖关系的流水线作业的计算模式，叫作流水线计算模式。其实，流水线计算模式是我们在第 1 篇文章slate-object="inline"中提到的数据并行计算的一种形式，就是将一个任务拆分为多个步骤（子任务），然后多个这样的任务通过对步骤（子任务）的重叠执行，以实现数据并行处理的场景。 这种流水线模式在计算机领域中最先用于 CPU指令设计，后来推广到机器学习领域进行数据处理、模型训练等。在流水线计算模式中，由于前一个子任务执行后，会扔给下一个子任务，由下一个子任务去展现自己的能力，因此可以形象地比喻为"你方唱罢我登场"。 接下来，我们就一起打卡分布式计算模式中的流水线模式吧。 什么是流水线模式？其实，分布式领域的流水线计算模式，就是参考了工业生产中的流水作业模式，将一个任务分为多个步骤执行，使得不同任务可以并行执行。此外，你肯定还会想到计算机技术中的流水线计算吧。 计算机中的**流水线（Pipeline）**技术是一种将每条指令拆分为多个步骤，多条指令的不同步骤重叠操作，从而实现几条指令并行处理的技术。现代CPU 指令采用了流水线设计，将一条 CPU指令分为取指（IF）、译码（ID）、执行（EX）、访存（MEM）、回写（WB）五级流水线来执行。 如下图所示，在第一条指令执行译码操作时，第二条指令就可以执行取指操作了，从而实现了多条指令的并行操作。 ![](Images/59d3f60fff0e850d5c6e152e9a373cd6.png)savepage-src="https://static001.geekbang.org/resource/image/75/08/75c9e4c34848d1d6e9bfc77705d7d108.png"}在分布式领域中，**流水线计算模式**也类似，它是将一个大任务拆分为多个步骤执行，不同的步骤可以采用不同的进程执行。这，使得不同任务可以并行执行，从而提高了系统效率。 以机器学习中的数据预处理为例，假设现在有 5个样本数据，每个样本数据进行数据预处理的流程，包括数据去重、数据缺失值处理、数据归一化3个步骤，且需要按照顺序执行。也就是说，数据预处理这个任务可拆分为数据去重---\>数据缺失值处理---\> 数据归一化 3个子任务。 如果现在有 3 个节点，节点 1 执行数据去重，节点 2执行数据缺失值处理，节点 3 执行数据归一化。那么，节点 1 处理完样本 1的数据，将处理后的数据发送节点 2 后，则节点 1 可以继续处理样本 2的数据，同时节点 2 处理样本 1的数据，以此类推，就实现了多任务的并行执行。 接下来，我们再具体看看分布式领域中的流水线计算模式吧。 流水线计算模式流水线计算模式的应用非常广泛，在 AI技术中也非常常见。对流水线计算模式的学习，将有助于你学习 AI技术，因此我接下来会以机器学习为例，为你介绍流水线计算模式。 当然，流水线计算模式的原理是通用的，也可以应用到其他领域，比如通信领域中使用HTTP流水线传输、计算机图形学中的图流水线等。 随着神经网络、深度学习在全世界掀起了 All in AI 的热潮，用于加速的 GPU和 TPU 也被越来越多的人使用。虽然诸如 GPU、TPU之类的加速器可以从根本上减少执行单个训练步骤所需的时间，但**为了达到最佳性能，我们仍然需要高效的输入流水线机制。** 比如，在流水线模式中数据预处理与 GPU/TPU进行模型训练可以重叠进行；再比如，第 N 个样本进行模型训练时，第 N+1个样本可以进行数据预处理，也就是说在第 N+1 个样本进行预处理前，已经将第N个样本处理后的数据提供给了模型训练，进一步减少了整体的数据处理和模型训练时间。 Tensorflow 是 Google开源的一个分布式机器学习框架，已被各大公司采用，比如网易、eBay、Intel等公司。接下来，我就以 TensorFlow的输入流水线模式为例，与你介绍流水线技术模式的原理，并带你了解如何构建机器学习的流水线。 流水线计算模式的原理TensorFlow运用了流水线模式对输入数据进行预处理，因此称为输入流水线（TensorFlowTraining Input Pipelines）。其数据输入流水线主要包含 3个步骤： 1.  **提取（Extract）**        。通过多种途径读取数据，比如内存、本地的 HDD 或    SSD、远程的 HDFS、GCS    等。数据的种类也有很多，比如图像数据、文本数据、视频数据等。        2.  **转换（Transform）**        。使用 CPU    处理器对输入的数据进行解析以及预处理操作，包括混合重排（shuffling）、批处理（batching）,    以及一些特定的转换。比如图像解压缩和扩充、文本矢量化、视频时序采样等。        3.  **加载（Load**        ）。将转换后的数据加载到执行机器学习模型的加速器设备上，比如    GPU 或 TPU。        由于输入流水线包含了提取、转换、加载 3 个步骤，因此 **TensorFlow的数据输入流水线也称为 ETL流水线** 。TensorFlow提供了一个官方 API 也就是tf.data，利用简单、可重用的数据片段构建复杂的输入流水线。 没错，在加速模型训练方面，输入流水线是非常重要的一个模块。由上述流程可知，要执行训练步骤，首先需要提取并使用CPU转换数据，然后将其提供给在加速器上运行的模型。 如果不引入流水线模型的话，当 CPU正在预处理数据时，加速器处于空闲状态。同样，当 GPU/TPU正在训练模型时，CPU 处于空闲状态。因此，训练的用时是 CPU预处理时间和加速器训练时间的总和。 为了帮助你理解，**我们一起看下****TensorFlow官网**  slate-object="inline"**给出的一个示例吧**。这个例子展示了一个不使用流水线技术和使用流水线技术时，CPU、GPU/TPU的训练过程对比。 我们先看看不使用流水线技术的训练过程。如下图所示，Prepare 1 表示 CPU正在对第 1 个样本数据进行预处理操作，Train 1 表示 GPU/TPU 正在训练第 1个样本数据。 ![](Images/e92692e9a4d8068bfa19d6565a7b5f7a.png)savepage-src="https://static001.geekbang.org/resource/image/5a/f2/5ad2604aac06d7ed8448e0b0b7dfd0f2.png"}备注：图片来源为www.tensorflow.org/guideslate-object="inline"。 图中的"idle"指的是空闲时间。可以看出，如果不使用流水线，CPU 和GPU/TPU运作的时间没有重叠，因此在大部分时间都可能处于空闲状态。 接下来，我们再看看使用流水线技术的训练过程。流水线模型可以将训练步骤的数据预处理和数据训练过程重叠到一起。比如，当GPU/TPU 正在训练第 N 个样本数据时，CPU 可以预处理第 N+1个样本数据。这样做不仅可以最大限度地缩短训练的单步用时，还可以缩短提取和转换数据所需的时间，如下图所示： ![](Images/134d9296ac44af737e30efd77639a8d5.png)savepage-src="https://static001.geekbang.org/resource/image/bf/b9/bf19b31ba9dd27cb7b1a6e63019476b9.png"}图片来源：www.tensorflow.org/guide很明显，采用流水线的设计可以充分利用 CPU 和GPU/TPU，从而避免资源闲置，加速训练过程。 **到这里，我们来小结一下吧。** TensorFlow 的输入流水线模式将对数据的操作拆分为提取、转换、加载 3个不重叠的部分。当 CPU 对第 N个样本的数据完成预处理之后，会将预处理后的数据发送给 GPU/TPU，然后 CPU继续对第 N+1 个样本的数据进行预处理，同时 GPU/TPU 对第 N个样本数据进行模型训练。也就是说，这种计算模式实现了多样本数据处理和模型训练的并行执行。 可以看出，在模型训练中引入流水线模式，可以提高 CPU、GPU/TPU的利用率，还可以加速训练过程。 实践: 构建机器学习流水线前面提到在 TensorFlow中，流水线模式主要运用在数据读取阶段。那么，对于一个复杂的机器学习任务，是否也可以构建一套流水线作业呢？ 答案是肯定的。接下来，我们就一起看看，如何构建机器学习流水线。 一个典型的机器学习训练模型按照流水线计算模式拆分，可以包括如下所示的5 个步骤： 1.       **数据输入**        ，指的是从不同的数据源中导入数据。        2.       **数据转换**        ，主要是要把输入的无结构数据转换成合适的格式，以便特征提取。        3.       **特征提取**        ，指的是从数据集中提取特征数据。        4.       **模型训练**        ，包括提供一个算法，并提供一些训练数据让模型可以学习。学习算法会从训练数据中发现模型，并生成输出模型。        5.       **模型验证**        ，指的是通过训练得到的结果，对模型进行错误率验证。比如，图像分类中分类结果的验证，预测中的准确度验证，从而提高模型的准确性。        ![](Images/07cbfb7562e6eeed82e5216cf8c2bd38.png)savepage-src="https://static001.geekbang.org/resource/image/9d/21/9de5f259c32b8f3f3cae6edaf5527821.png"}值得注意的是，在数据输入和数据转换之间，有时需要进行数据清洗。数据清洗主要是剔除错误数据和不重要的数据，从而降低模型训练的错误率。接下来，**我以图像分类为例，带你了解机器学习流水线的流程。**关于图像分类的详细知识点，你可以自行查阅相关资料。如下图所示，假如现在有 10000张小狗照片，需要训练出一个关于小狗的预测模型。![](Images/2aabe4ed15e65b654cee3f4427150966.png)savepage-src="https://static001.geekbang.org/resource/image/4a/d3/4a0022453c24ec07309cf49475919ed3.png"}假设这 10000 张照片中，8000 张作为训练集，2000 张作为测试集，采用 CNN进行模型训练。CNN包括输入层、卷积层、池化层、全连接层，其中输入层为数据输入，卷积层和池化层为特征提取，全连接层是连接所有特征，输出数据到分类器中，以得到训练结果。如上图所示，生成小狗预测模型的流水线可以分为数据输入、数据转换、特征提取、模型训练、模型验证5 部分。具体流程如下：1.       输入数据，也就是输入图像数据，即 8000    张图片，其中图像以像素表示。比如，图片的大小是    480       480，那么图像输入数据格式可以是    480    480\*3    的数组。3 代表的是，RGB    的维度。        2.       数据转换，也就是对输入的图像数据进行解析、正则化处理，消除一些噪声数据，得到格式化的数据。        3.       特征提取，指的是得到格式化的数据之后，就可以对输入图像进行特征提取，通过卷积操作提取小狗的一些轮廓特征，比如耳朵、尾巴、身体等，然后通过池化层识别出主要特征，比如小狗的耳朵、眼睛、舌头等，对特征进行精简。        4.       模型训练。在 CNN    中模型训练其实和特征提取是相辅相成的，也就是特征提取后，实现特征提取的那些参数就是模型参数，而训练过程，会根据梯度下降法等对参数进行调整，以使得在模型验证阶段预测结果逼近真实结果。也就是说，特征提取和模型训练这两步，在    CNN    中是放到一起的，这里我为了方便你理解，才显式地把这两步划分了出来。        5.       模型验证。将带有标签的测试数据集的图像（2000    张）输入到小狗预测模型，将预测结果与实际结果进行对比，如果误差比较大，则对模型参数进行优化并进入下一次迭代训练；如果误差较小，那么得到的结果就是最终的小狗预测模型。        知识扩展：流水线模式和 MapReduce 模式中，都有将大任务拆分为多个子任务，两者的区别是什么？如题目所述，流水线计算模式与分而治之的 MapReduce计算模式（你可以再回顾下第 15 篇文章slate-object="inline"中的相关知识点）有相似之处，都是将一个完整的、大的任务进行划分，但它们**划分的模式**不一样：1.  MapReduce    以任务为粒度，将大的任务划分成多个小任务，每个任务都需要执行完整的、相同的步骤，同一任务能被并行执行，可以说是任务并行的一种计算模式；        2.  而流水线计算模式以步骤为粒度，一个任务拆分为多个步骤，每个步骤执行的是不同的逻辑，多个同类型任务通过步骤重叠以实现不同任务的并行计算，可说是数据并行的一种模式。        此外，它们的子任务（步骤）间的关系不同：1.  在 MapReduce    中，各个子任务可以独立执行，互不干扰，多个子任务执行完后，进行结果合并得到整个任务的结果，因此要求子任务之间是没有依赖关系的；        2.  而在流水线模式中，多个子任务之间是具有依赖关系的，前一个子任务的输出是后一个子任务的输入。        所以，综合来讲，MapReduce计算模式适合任务并行的场景，而流水线计算模式适合同类型任务数据并行处理的场景。总结首先，我与你介绍了什么是分布式计算模式中的流水线模式。它参考了工业生产中的流水作业模式，将一个任务分为多个步骤执行，不同任务之间的步骤可以重叠执行，这使得多个不同任务可以并行执行。然后，我以典型的机器学习流程为例，介绍了机器学习流水线处理流程，以加深你对分布式流水线计算模型的理解。最后，我以 CNN进行小狗分类模型训练为例，通过讲述数据输入、数据处理、特征提取（卷积、池化等操作）、模型训练、模型验证等过程，带你进一步理解了流水线计算模式在实际应用中的原理。现在，我再通过一张思维导图来归纳一下今天的核心知识点吧。![](Images/150061f743a669bda0a5cfa1acc210fa.png)savepage-src="https://static001.geekbang.org/resource/image/43/5e/4329251192d6d77935e0de98ff8ebf5e.png"}流水线计算模式适合同类型任务，且每个任务可以拆分为多个步骤（子任务）进行执行的场景，通过重叠执行多个不同任务间的不同步骤实现数据并行。在实际应用场景中，有很多例子，最常见的就是机器学习。相信你在理解了本文的计算原理之后，一定可以将这种研究方法运用在你的工作中，加油！思考题流水线计算模式和流计算的区别是什么？我是聂鹏程，感谢你的收听，欢迎你在评论区给我留言分享你的观点，也欢迎你把这篇文章分享给更多的朋友一起阅读。我们下期再会！![](Images/c191f391e2aab7575517a886bbd7a681.png)savepage-src="https://static001.geekbang.org/resource/image/a4/8c/a42a16601611a1a72599ecfca434508c.jpg"}