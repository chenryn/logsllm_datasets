3
Trigger
Payload
Fig. 6. Explicit transition to payload with both explicit and non-explicit components.
Explicit Transition to Payload with Explicit and Non-explicit Payload
Components. In this case (case 2 above), we model a backdoor that enables
an attacker to perform computation not part of the developer’s DFSM, without
being in a state that is bug-induced. An example of such a backdoor is shown in
Fig. 6; if the backdoor trigger is satisﬁed, the program will interpret and execute
an input supplied by the user of the backdoor. The trigger condition is a check
to see if a user is requesting access to a speciﬁc path (state 1), if it is, then the
payload is transitioned to (state 1 to 2), where the data sent with the request
(req. data) is used as input to an interpreter (state 2, via run). In this case, the
privileged state (state 3) transitioned to is dynamically constructed as a result
of the input to the interpreter executed in state 2.
void some_function() {
char buf[80];
/* ... */
/* Backdoor activated if len(input)
causes buffer overflow */
strcpy(buf, input); // (1) -> (2)
return;
}
void other_function() {
/* ... */
/* Payload reaches via (2) -> (3) */
g_user._is_admin = true; // (3)
open_control_panel(); // (4)
}
2
1
3
Trigger
Payload
4
Fig. 7. Non-explicit transition to payload, where payload has both explicit and non-
explicit components.
Non-explicit Transition to Payload with Explicit and Non-explicit
Payload Components. In the ﬁnal case (case 3 above), we model backdoors
that have a trigger mechanism that is bug-based, i.e., allows an attacker to
perform computation not part of the developer’s DFSM. We visualise such a
case in Fig. 7; here the trigger consists of an intentional buﬀer overﬂow bug in
some function (state 1), which if exploited – in this case with a ROP-based
payload – transitions (via 1 to 2) to the payload. The payload consists of states
2 and 3, and the transitions from states 2 to 3, and 3 to 4. As a result of the
payload, the user is granted administrative privileges (state 3), and entered into
104
S. L. Thomas and A. Francillon
a (privileged) control panel via open control panel in other function (state
4).
if (strcmp(password, "_BACKDOOR_") == 0 \
|| is_valid_password(password)) {
// Authenticated
} else {
// Not authenticated
}
Trigger
1
strcmp(...
Payload
is valid password(...
Authenticated
2
Not Authenticated
Fig. 8. A backdoor payload composed solely of a state transition.
Single Transition Payloads. We note there is a special case for both cases 1
and 3, namely, where the payload is composed of only a single state transition.
That is, no additional computation is undertaken as part of the payload, rather
the payload shares its state transition with the backdoor trigger, as shown in
Fig. 8. This special case accounts for situations where the backdoor trigger acts
like a trapdoor (state 1), allowing an attacker to bypass a (potentially) more
complex check for user-authentication, and rather provides a direct transition
to a privileged state (the transition from state 1 to 2). The form of the payload
is identical for cases 1 and 3, other than the explicitness of the state transition
(the payload) between the trigger and the privileged state.
4.3.2 Payload Obfuscation
So far, we have not considered how a backdoor implementer might hide a back-
door’s presence – other than by using a bug-based trigger mechanism. While such
a trigger is simple to implement, it oﬀers the implementer no control over how
the backdoor will eventually be used; this control can be regained, by for exam-
ple, limiting the computational freedom of newly created states. In this section
we explore how a backdoor implementer can obfuscate payload components.
Since backdoor payloads that contain only explicit states and state transitions
are obvious and thus, intentional constructs, an obfuscated payload by nature
must be implemented through the use of some degree of abnormal control ﬂow,
i.e., non-explicit states and state transitions. An example of such a payload is
one derived by reusing components of the system it is implemented within to
obscure its execution, e.g., for a program, from static analysis methods. From
an attacker’s perspective, the only way to execute such a backdoor is either
to have prior knowledge of the payload, or solve a puzzle and derive it from
the original system. Andriesse et al. [14] describe such a backdoor (examined in
further detail in Sect. 6), whereby its payload component is composed of multiple
code fragments embedded and distributed throughout a binary which execute
in sequence upon the backdoor being triggered. Figure 7 shows a na¨ıve example
such a payload.
Another example is that where a payload can be derived from attacker con-
trolled data. In the simplest case, this is akin to shellcode often executed as
Backdoors: Deﬁnition, Deniability and Detection
105
a result of successful exploitation of a buﬀer overﬂow vulnerability: it shares
a commonality that it doesn’t rely upon any existing program components. In
more sophisticated cases, such a backdoor payload might take a hybrid approach:
where either user-data is interpreted by the program itself, or components of the
program are used alongside the user input. Figure 6 shows a simple example such
a payload. In both of these examples, the payload components are implemented
in a so-called weird machine as deﬁned by Oakley and Bratus [16].
4.4 Privileged State
Following successful activation of the backdoor trigger and subsequent transi-
tioning from the associated payload, the system will enter into a privileged state.
There are two possibilities for this state: either it can be reached under normal
system execution, or it can only be reached through activation of the backdoor.
If we consider privileged states by how they are added to a RFSM, then one that
is newly created, i.e., is non-explicit, will not be reachable under normal system
execution, meanwhile, one that is explicit, may or may not be reachable under
normal execution: for example, while the privileged state might be explicit, the
only way to reach it might be via the backdoor trigger.
In the case of a privileged state reachable through normal execution, consider
the backdoor presented in Fig. 8, which models a hard-coded credential check.
The privileged state (state 2) of the backdoor is both reachable via the backdoor
trigger (from state 1), and the state labelled is valid password.
For the other case, where the privileged state is not reachable by a legiti-
mate user, it is essentially guarded by the activation of the backdoor. This case
can further be sub-categorised. The ﬁrst variant is where the privileged state is
explicit, as in Fig. 5; the privileged state (state 4) is only reachable through acti-
vation of the backdoor trigger (state 1 and the transition from state 1 to state
2). In this example, the privileged state manifests as an undocumented backdoor
shell, where after entering a speciﬁc username, the attacker is able to perform
additional functionality, not otherwise possible. The other variant is a privileged
state that provides an attacker access to functionality that is not available to
a legitimate user, where that functionality does not explicitly exist within the
system – as shown in Fig. 6. Here the privileged state (state 3) is some function
of attacker input, i.e., the result of run(&req. data).
5 Practical Detection and Deniability
Backdoor detection in practice will happen through, e.g., manually reverse-
engineering a program binary or observing a backdoor’s usage through suspi-
cious system events, such as anomalous network traﬃc. As is, our proposed
framework oversimpliﬁes as it doesn’t model intention. If we knew that a par-
ticular vulnerability was placed intentionally, then there would be no question
that the vulnerability was placed deliberately to act as a backdoor. Thus, in this
section we answer the question: if we have identiﬁed a backdoor-like construct,
106
S. L. Thomas and A. Francillon
can we distinguish it from an accidental vulnerability, and if so, how deniable is
it?
In order to make such a distinction, recall that we can view a system from
four perspectives: its DFSM, AFSM, EFSM, and RFSM. If a backdoor-like con-
struct has been identiﬁed, then it will be present in both the emulator for the
AFSM and the RFSM. To state that the construct is a backdoor – and was
placed intentionally – we must show that it, or some part of it was present
within the DFSM. In some cases, the intent is explicit and hard-coded in the
implementation – i.e., it leaves no ambiguity. The most obvious example of this
is a hard-coded credential check which serves to bypass standard authentica-
tion. Indeed, all cases of backdoor that transition explicitly, i.e., discoverable by
analysis, from the satisfaction of their trigger conditions to their payload can be
considered intentional.
In the other case, where that transition is non-explicit, i.e., bug-based, vari-
ous approaches can be taken. For instance, in the case of software, where version
control logs are available, it is possible to identify the exact point where a back-
door has been inserted as well as its author (e.g., the failed attempt to backdoor
the Linux kernel in 2003 [1]). For binary-only software, where there exists mul-
tiple versions of that software, it is possible to identify the version the backdoor
was introduced in, and reason about its presence by asking the question was
there a legitimate reason for making such a change to the software? Further,
we can consider the explicitness of the backdoor components: for example, if
a code fragment exists within a binary that does nothing more than facilitate
privilege escalation, and it is unreachable by normal program control-ﬂow, then
there is an indication of intent. A similar case can be made if the satisfaction
of the trigger conditions rely on checks discoverable by analysis, as well as a
bug. Unfortunately, all of these approaches have non-technical aspects and rely
on human intuition – thus, do not provide a concrete proof of intent. We are
therefore left with three possible ways to classify backdoor-like constructs:
Deﬁnition 3 Intentional backdoor. Those constructs that can be unambigu-
ously identiﬁed as backdoors: the transition from their trigger satisfaction to
their payload is explicit. Will be present in the DFSM, AFSM, and if found, the
RFSM, but not the EFSM.
Deﬁnition 4 Deniable backdoor. Those constructs that fall into a grey area,
where the transition from their trigger satisfaction to their payload is non-explicit
(i.e., it appears to be a bug), but from a non-technical perspective can be argued
to be intentional. Will be present in the AFSM, if found, the RFSM, but not
the EFSM; we cannot deﬁnitively tell if it is in the DFSM.
Deﬁnition 5 Accidental vulnerability. Those constructs where there is no
evidence – technical, or otherwise – to suggest any intent, and the transition
from their trigger satisfaction to their payload is non-explicit. Will be present in
the AFSM, and if found, the RFSM, but not the DFSM or EFSM.
From a purely technical perspective, a deniable backdoor will be indistin-
guishable from an accidental vulnerability. Consider, for example, a simple buﬀer
Backdoors: Deﬁnition, Deniability and Detection
107
overﬂow vulnerability and its corresponding exploit. If this vulnerability was
deliberately placed then it is a backdoor, otherwise it is just a vulnerability
coupled with an exploit. As we do not know anything about the implementer’s
intention we cannot discern between the two. Thus, a vulnerability can be seen
as an unintentional way to add new state transitions, or states to a system’s
FSM, while an exploit is a set of states and state transitions such that when
combined with a vulnerability within a given FSM, provides a means to compro-
mise the believed security of the system modelled by that FSM. In contrast to
backdoors and vulnerabilities, a construct providing standard privileged access
will be intentional and manifest within the DFSM, AFSM, EFSM, and RFSM
of a system.
6 Discussion and Case-Studies
In order to demonstrate our framework, we provide a number of case studies.
We show examples from both the literature and real-world backdoors, which
have been detected manually. For each backdoor, we reason about if and why
its implementation can be considered deniable in respect to our deﬁnitions and
analyse it by performing a complete decomposition of its implementation using
our framework. Finally, we provide a discussion of how our framework can be
used to reason about methods for detecting backdoors.
Table 1 shows eleven real-world backdoors, each decomposed using our frame-
work. As each backdoor can be modelled with explicit states and state transi-
tions, by Deﬁnition 3, none are deniable, thus, their implementers should be held
accountable. The remainder of this section provides case-study of a complex,
deniable (by Deﬁnition 4) backdoor.
Nginx Bug-Based Backdoor. Andriesse and Bos [14] describe a general
method for embedding a backdoor within a program binary. Their technique
utilises a backdoor trigger based upon an intentional program bug combined with
a hard-coded payload composed of intentionally misaligned instruction sequence
fragments. Their payload is, in a sense, obfuscated, yet ﬁxed; its implementation
exploits the nature of the x86 instruction set, whereby byte sequences represent-
ing instructions can be interpreted diﬀerently when accessed at diﬀerent oﬀsets.
The authors demonstrate their approach by modifying the popular web-
server, Nginx, and embedding a remotely exploitable backdoor. In their imple-
mentation, a would-be attacker provides a crafted input, which serves to satisfy
the backdoor trigger conditions; this input is provided as a malformed HTTP
packet – the input source will therefore be a network socket. Figure 9 provides a
code listing adapted from [14] which contains the backdoor trigger conditions.
Those conditions are: have err == 1, and err handler != NULL, which are set
as a result of the use of uninitialised variables have err and err handler in
the ngx http finalize request function, which take the values of badc and
hash in ngx http parse header line. The bug manifests due to the fact the
two functions stack frames overlap between their invocations. The intended pay-
load states are meant to be those embedded as weird states, however additional
108
S. L. Thomas and A. Francillon
.
k
r
o
w
e
m
a
r
f
g
n