The stash size analysis of Path ORAM breaks down when
operations are asynchronous. Nevertheless, we show that the
stash size of TaORAM running with a sequence of requests
is the same as that of Path ORAM running with a different
but related sequence of requests, which is permuted from the
actual sequence according to the timing of ﬂushing.
D. Further background and related works
It is impossible to cover the huge body of previous works
on ORAM, and its applications. We have already discussed
works implementing multi-client systems and in particular
ObliviStore and PrivateFS – here, we give a short overview of
other works.
a) Hierarchical ORAMs: Hierarchical ORAMs were
ﬁrst proposed by Goldreich and Ostrovsky [17] (referred to as
the GO-ORAM henceforth), to store N elements. Hierarchical
ORAMs organize the memory in log N many levels, consisting
of increasingly many 2i buckets. At any time point, each
logical block is assigned to one random bucket per level, and
stored in exactly one of them. Hierarchical ORAMs require
a regular shufﬂing operation to deal with overﬂowing levels
200200
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:10:10 UTC from IEEE Xplore.  Restrictions apply. 
after oblivious re-insertion of items into the hierarchical data
structure. Subsequent hierarchical ORAMs improve different
aspects of GO-ORAM, such as reduced overhead [32], [25],
[22], [20], [23], [20], faster shufﬂing [19], [20], [25], [43], and
de-amortizing shufﬂing [31], [5], [21], [25], [44].
Tree ORAMs: Tree ORAMs have been proposed rela-
tively recently, ﬁrst by Shi et al. [35] and then soon extended
in a number of works [38], [16], [11], [10]. The current state-
of-the-art construction is Path ORAM [38] which was brieﬂy
reviewed above and will be reviewed in detail below. Other
tree ORAMs share the same overall structure but differ in
important details, for instance, the absence of stash in [35],
[11], [16], varying heights and degrees of the tree in [16],
[10], applying ﬂushing on randomly chosen paths in [11],
[10], or on paths in a ﬁxed deterministic order [16], [33],
reducing the frequency of ﬂushing and changing the tree
bucket structure [33], varying the size of the blocks [38],
[40], and achieving constant communication size by moving
computation to the server [14], [29].
Recent practical constructions: In the past several years,
many practical ORAM schemes have been constructed and
implemented for real-world applications,
like secure (co-
)processor prototypes [15], [26], [27], [34] and secure cloud
storage systems [5], [39], [26], [44], [37], [36], [13]. While
classical ORAM schemes with small client memory apply
directly to the former setting, in cloud applications where a
client wishes to outsource the storage of a large dataset to
a remote server and later access it in an oblivious way, the
client typically has more storage space, capable of storing
N ) blocks or even some per-block meta-data of total size
O(
O(N log N ). The availability of large client storage enables
signiﬁcantly reducing the computation overhead of ORAM
to O(log N ) [20], [23], [42], [41], [44], [37], [36], and
furthermore, reduces the number of client-server interactions
per access to O(1) (instead of O(log N )).
√
Other works on multi-client ORAM: A problem super-
ﬁcially related to ours (but technically different), is that of
Oblivious Parallel RAM (OPRAM), recently introduced by
Boyle, Chung, and Pass [6]. Even though Path ORAM-like
OPRAM schemes have also been proposed [8], OPRAM
clients coordinate their access to the server without a proxy. To
achieve this, they can communicate synchronously with each
other. The resulting schemes are however fairly unpractical.
A recent work by Maffei et al. [28] also considers ORAM in
conjunction with multi-user access, developing a new primitive
called Group ORAM. Their work considers a scenario where
a data owner enforces access-control restrictions on data,
whereas we consider a common address space which can be
accessed by a group of mutually-trusting users. The efﬁciency
of their solution compares to that of single-client, sequential,
ORAM schemes (like Path ORAM), and they do not address
efﬁcient, high-throughput, concurrent access, which is the
focus of our work.
II. ASYNCHRONOUS ORAM SCHEMES: DEFINITIONS AND
ATTACKS
This section addresses the security of ORAM schemes in
asynchronous settings. We give both a formal security model,
and attacks against existing implementations.
A. Security Model
Traditional ORAM security deﬁnitions consider
syn-
chronous and non-concurrent (i.e., sequential) systems. Here,
we introduce the new notion of adaptive asynchronous obliv-
iousness, or aaob-security, for short. The attacker schedules
read/write operation requests (which are possibly concurrent)
at any point in time, and also controls the scheduling of
messages. Moreover, the attacker learns when requests are
answered by the ORAM client (i.e.,
the client returns an
output), which as we see below, is very crucial information
difﬁcult to hide in practice. Note that the deﬁnition of [36]
(which is also used in [4]) does consider asychronicity, but it
is inherently non-adaptive and, even more importantly, does
not reveal response times.
We give an informal (yet self-contained) overview of the
deﬁnition – further formal details are deferred to Appendix A.
We stress that we do not differentiate, at the formal level,
between multi- and single-client scenarios – an ORAM scheme
is what is run by the proxy in our application scenario, but we
think more generally this of it as a single “client” answering
asynchronous requests. Whether these come from multiple
parties or not is orthogonal to our treatment.
b) ORAM Schemes: We think of an asynchronous
ORAM scheme as a pair ORAM = (Encode, OClient), where
Encode takes an initial data set D of N items with a certain
block size B, and produces an encrypted version ˆD to initialize
an untrusted storage sever SS, together with a corresponding
secret key K. In particular, SS gives basic read/write access to
a client accessing it, together with timestamping, i.e., writing
a new item in some location on SS overwrites the current item
only if the timestamp of the new item is larger. OClient is the
actual (stateful) client algorithm which is given K, and can
be invoked at any time with requests for read/write operations,
and eventually answers these requests, after interacting with
SS. Concretely, OClient processes read requests for a certain
block address bid ∈ [N ] to retrieve the value stored in this
block, and write requests to overwrite the value of a certain
block bid (and possibly retrieve the old value). These requests
are denoted as (op, bid, v) where op ∈ {read, write} and
v = ⊥ when op = read. Every such request is terminated
at the point in time by either returning the retrieved value
or (for write operations) simply an acknowledgement to the
caller, and possibly the value which was overwritten.
c) Security deﬁnition: We now proceed with our deﬁni-
tion of aaob security, which is an indistinguishability-based
security notion. Given an attacker A and an ORAM scheme
ORAM = (Encode, OClient), we consider an experiment
ORAM(A) where OClient accesses a storage server SS
Expaaob
via an asynchronous link. The experiment initially samples
201201
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:10:10 UTC from IEEE Xplore.  Restrictions apply. 
a random challenge bit b
follows:
the game runs ( ˆDb, K)
$← {0, 1}, and then proceeds as
• The attacker A initially chooses two equally large
$←
data sets D0, D1. Then,
Encode(Db). As a result, ˆDb is stored on SS, and the
key K is given to OClient.
• The attacker A can, at any point in time, invoke OClient
with a pair of operation requests (opi,0, opi,1), where
both requests can be for arbitrary read/write operations.
Then, operation request opi,b is handed over to OClient.
When the operation completes, the adversary A is noti-
ﬁed, yet it is not told the actual value returned by this
operation.1
• When processing operation requests, OClient commu-
nicates with SS over a channel whose scheduling is
controlled by A. Concretely, when ORAM sends a read or
write request to SS, A is notiﬁed (and given the message
contents), and A can decide to deliver this message to SS
at any point in time. Similarly, A controls the scheduling
of the messages sent back from SS to ORAM, and also
learns their contents. There are no ordering constraints
– A can deliver messages completely out of order, and
even drop messages.
• Finally, when the adversary A is ready, it outputs a guess
b(cid:2) for b, and the experiment terminates. In particular, if
b = b(cid:2), we way that the experiments outputs true, and
otherwise it outputs false.
We deﬁne the aaob-advantage of the adversary A against
ORAM as
(cid:2)
(cid:3)
ORAM(A) ⇒ true
Expaaob
Advaaob
ORAM(A) = 2 · Pr
− 1 .
We say that ORAM is aaob-secure (or simply, secure) if
ORAM(A) is negligible for all polynomial-time adversaries
Advaaob
A (in some understood security parameter λ).
d) Remarks: One key point of our deﬁnition is that the
adversary learns the response times – this was not the case
in [36]. This information is crucial, and in particular it is very
hard to argue an adversary has no access to it. Not only in our
deployment scenario this information is visible by a potential
network intruder (the actual ORAM client is run by a proxy
with network connectivity to its users), but also ORAM users
will most likely have different behaviors triggered by these
responses.
We also note that (out of formal necessity) we do not leak
the contents of operation responses, and only their timing.
Otherwise, A can easily recover the challenge bit b. In the full
version, we discuss stronger simulation-based security notions
allowing this information to be revealed.
e) Correctness: The above discussion did not address the
issue of correctness of the scheme, which is quite subtle given
the concurrent nature of the system. Following the classical
literature on distributed systems, Appendix C deﬁnes atomic
semantics for an asynchronous ORAM scheme as our target
1This restriction is necessary, for otherwise an adversary A could easily
guess the value of b.
Server
Client
op1 = (read, 1, ⊥)
rep1 = D[1]
rep2 = D[1]
op2 = (read, 1, ⊥)
Server
Client
op1 = (read, 1, ⊥)
rep1 = D[1]
op2 = (read, 2, ⊥)
rep2 = D[2]
Fig. 1: Attack against ObliviStore. Comparison of event tim-
ing for repeated access (above) and distinct accesses (below).
Here, we assume constant delays in delivering messages.
Server
Client
op1 = (read, 1, ⊥)
op2 = (read, 1, ⊥)
rep1 = rep2 = D[1]
Server
Client
op1 = (read, 1, ⊥)
op2 = (read, 2, ⊥)
rep2 = D[2]
rep1 = D[1]
Fig. 2: Attack against CURIOUS’s fake-read logic: The
upper ﬁgure represents the timing of the communication
between the client and the server when accessing the same
item twice, and the second access is a “fake read” (in blue).
The ﬁgure below represents the execution when the accesses
are for two distinct items (both “real reads”). The timings of
the responses differ, as in the above case, the client needs to
wait for the actual value to arrive.
correctness notion. This in particular means that operations
appear to take place atomically at some point between their
invocation and their response.
B. Attacks
We present
two attacks – one against ObliviStore, one
against CURIOUS – breaking their aaob-security. We note
that the former attack is just a re-iteration of the key idea
202202
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:10:10 UTC from IEEE Xplore.  Restrictions apply. 
presented in [4]. In contrast, our second attack is novel. We
give a high-level explanation of the attacks, but a formalization
in our framework (given an appropriate formalization of the
scheme) can be obtained easily.
f) Attack against ObliviStore: An attack against Oblivi-
Store can be derived from the weakness already observed
in [4]. In particular, ObliviStore sequentializes accesses on
the same item, and thus an adversary requesting the same
item twice (e.g., issuing two subsequent requests op1,0 =
op2,0 = (read, 1,⊥)) will see only one request being made
to the storage server, with a second request being scheduled
only after the response to the ﬁrst one returns to the client.
In contrast, scheduling requests op1,1 = (read, 1,⊥) and
op2,1 = (read, 2,⊥) for two different addresses will have the
adversary see the client immediately schedule two requests
to retrieve information from the server. This leads to easy
distinguishing. Figure 1 gives two diagrams presenting the two
situations in detail.
We note two things. First off, this attack breaks ObliviStore
even in the model in which it was claimed to be secure,
as response times are not needed to distinguish between the
repeated-access scenario. Also, the attack does not require the
network to be asynchronous – only the ability to schedule
overlapping operations. Second, if response times can be mea-
sured, then the attack is very easy to mount: An independent
experimental validation (with the ObliviStore implementation
provided to us) shows that repeatedly accessing the same item
over and over leads to a performance degradation of up to
50% compared to accessing well-spread loads.
g) Attack against CURIOUS: The overcome this, [4]
suggested an alternative approach based on the idea that a
concurrent operation on the same item should trigger a “fake
read”. We show that
is not sufﬁcient
to achieve aaob-security. We note that our attack does not
contradict security claims in [4], since the model of [36] is
used, which does not leak the timing of responses. (As argued
above, we believe that it is extremely hard to hide these timings
in actual deployment.)
this idea, by itself,
To start with, recall that when two concurrent requests for
the same item are made in CURIOUS (think of these as read
requests for simplicity), the ﬁrst request results in the actual
“real read” access to the server fetching the item, whereas the
second results in a fake access to the storage server SS (a
so-called “fake read”) to hide the repeated access. This “fake
read” looks like an access to an unrelated, independent item
(the details are irrelevant).
The key issue – ultimately allowing us to distinguish –
concerns the timings of the responses given by the ORAM
client. When the fake read operation terminates (i.e.,
the
corresponding data is received by the ORAM client from the
server), the client always returns the item fetched in the real
read if it is available. If the item is not available, then it
needs to wait for the real read to terminate. Note that in the
asynchronous setting, the latter situation can occur – we have
no guarantee whatsoever that the real read terminates before
Trusted Proxy
C1
C2
C3
Ci
Fig. 3: Deployment model of TaoStore
the fake read.2 This is in contrast to the case where the reads
are for two distinct items (and hence both “real”), and the
second request can be answered right away even if the client
has not received the data from the server associated with the
second request.
This gives the attacker a simple mean to break aaob
security, and distinguish the b = 0 from the b =