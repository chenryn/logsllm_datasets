### Stash Size Analysis of Path ORAM in Asynchronous Operations

The stash size analysis of Path ORAM becomes invalid when operations are asynchronous. However, we demonstrate that the stash size of TaORAM, when processing a sequence of requests, is equivalent to that of Path ORAM with a different but related sequence of requests, which is permuted based on the timing of flushing.

### Further Background and Related Works

It is impossible to cover the extensive body of previous work on Oblivious RAM (ORAM) and its applications. We have already discussed works implementing multi-client systems, such as ObliviStore and PrivateFS. Here, we provide a brief overview of other significant contributions.

#### Hierarchical ORAMs

Hierarchical ORAMs were first proposed by Goldreich and Ostrovsky [17], often referred to as GO-ORAM, for storing \( N \) elements. These ORAMs organize memory into \( \log N \) levels, each containing an increasing number of \( 2^i \) buckets. At any given time, each logical block is assigned to one random bucket per level and stored in exactly one of them. Hierarchical ORAMs require regular shuffling to manage overflowing levels after oblivious re-insertion of items. Subsequent hierarchical ORAMs have improved various aspects of GO-ORAM, including reduced overhead [32, 25, 22, 20, 23], faster shuffling [19, 20, 25, 43], and de-amortizing shuffling [31, 5, 21, 25, 44].

#### Tree ORAMs

Tree ORAMs were introduced relatively recently, with the first proposal by Shi et al. [35], followed by several extensions [38, 16, 11, 10]. The current state-of-the-art construction is Path ORAM [38], which was briefly reviewed above and will be discussed in detail below. Other tree ORAMs share the same overall structure but differ in important details, such as the absence of a stash in [35, 11, 16], varying heights and degrees of the tree in [16, 10], applying flushing on randomly chosen paths in [11, 10], or on paths in a fixed deterministic order [16, 33], reducing the frequency of flushing and changing the tree bucket structure [33], varying the size of the blocks [38, 40], and achieving constant communication size by moving computation to the server [14, 29].

#### Recent Practical Constructions

In recent years, many practical ORAM schemes have been constructed and implemented for real-world applications, such as secure (co-)processor prototypes [15, 26, 27, 34] and secure cloud storage systems [5, 39, 26, 44, 37, 36, 13]. While classical ORAM schemes with small client memory apply directly to the former setting, in cloud applications where a client outsources the storage of a large dataset to a remote server, the client typically has more storage space, capable of storing \( O(N) \) blocks or even some per-block metadata of total size \( O(N \log N) \). This additional client storage significantly reduces the computation overhead of ORAM to \( O(\log N) \) [20, 23, 42, 41, 44, 37, 36] and further reduces the number of client-server interactions per access to \( O(1) \) (instead of \( O(\log N) \)).

#### Other Works on Multi-Client ORAM

A problem superficially related to ours, but technically different, is Oblivious Parallel RAM (OPRAM), introduced by Boyle, Chung, and Pass [6]. Although Path ORAM-like OPRAM schemes have been proposed [8], OPRAM clients coordinate their access to the server without a proxy and can communicate synchronously with each other. However, these schemes are generally impractical. A recent work by Maffei et al. [28] also considers ORAM in conjunction with multi-user access, developing a new primitive called Group ORAM. Their work focuses on a scenario where a data owner enforces access-control restrictions on data, whereas we consider a common address space accessible by a group of mutually-trusting users. The efficiency of their solution compares to that of single-client, sequential ORAM schemes like Path ORAM, and they do not address efficient, high-throughput, concurrent access, which is the focus of our work.

### Asynchronous ORAM Schemes: Definitions and Attacks

This section addresses the security of ORAM schemes in asynchronous settings, providing both a formal security model and attacks against existing implementations.

#### Security Model

Traditional ORAM security definitions consider synchronous and non-concurrent (i.e., sequential) systems. Here, we introduce the new notion of adaptive asynchronous obliviousness (aaob-security). The attacker schedules read/write operation requests (which may be concurrent) at any point in time and controls the scheduling of messages. Additionally, the attacker learns when requests are answered by the ORAM client, which is crucial information difficult to hide in practice. Note that the definition in [36] (also used in [4]) does consider asynchronicity but is inherently non-adaptive and does not reveal response times.

We provide an informal yet self-contained overview of the definition; further formal details are deferred to Appendix A. We stress that we do not differentiate, at the formal level, between multi- and single-client scenarios. An ORAM scheme is what is run by the proxy in our application scenario, but we think more generally of it as a single "client" answering asynchronous requests. Whether these come from multiple parties or not is orthogonal to our treatment.

#### ORAM Schemes

We define an asynchronous ORAM scheme as a pair \( ORAM = (Encode, OClient) \), where:
- \( Encode \) takes an initial data set \( D \) of \( N \) items with a certain block size \( B \), and produces an encrypted version \( \hat{D} \) to initialize an untrusted storage server \( SS \), along with a corresponding secret key \( K \). The server \( SS \) provides basic read/write access to a client, with timestamping.
- \( OClient \) is the actual (stateful) client algorithm, given \( K \), and can be invoked at any time with requests for read/write operations. It processes read requests for a certain block address \( bid \in [N] \) to retrieve the value stored in this block, and write requests to overwrite the value of a certain block \( bid \) (and possibly retrieve the old value). These requests are denoted as \( (op, bid, v) \) where \( op \in \{read, write\} \) and \( v = \bot \) when \( op = read \). Each request is terminated by either returning the retrieved value or (for write operations) an acknowledgment to the caller, and possibly the value which was overwritten.

#### Security Definition

We now proceed with our definition of aaob security, which is an indistinguishability-based security notion. Given an attacker \( A \) and an ORAM scheme \( ORAM = (Encode, OClient) \), we consider an experiment \( Exp_{\text{aaob}}^{ORAM}(A) \) where \( OClient \) accesses a storage server \( SS \) via an asynchronous link. The experiment initially samples a random challenge bit \( b \in \{0, 1\} \), and then proceeds as follows:

1. The attacker \( A \) initially chooses two equally large data sets \( D_0, D_1 \). Then, \( ( \hat{D}_b, K ) \leftarrow Encode(D_b) \). As a result, \( \hat{D}_b \) is stored on \( SS \), and the key \( K \) is given to \( OClient \).
2. The attacker \( A \) can, at any point in time, invoke \( OClient \) with a pair of operation requests \( (opi,0, opi,1) \), where both requests can be for arbitrary read/write operations. Then, operation request \( opi,b \) is handed over to \( OClient \). When the operation completes, the adversary \( A \) is notified, but it is not told the actual value returned by this operation.
3. When processing operation requests, \( OClient \) communicates with \( SS \) over a channel whose scheduling is controlled by \( A \). Specifically, when \( ORAM \) sends a read or write request to \( SS \), \( A \) is notified (and given the message contents), and \( A \) can decide to deliver this message to \( SS \) at any point in time. Similarly, \( A \) controls the scheduling of the messages sent back from \( SS \) to \( ORAM \) and learns their contents. There are no ordering constraints—\( A \) can deliver messages completely out of order and even drop messages.
4. Finally, when the adversary \( A \) is ready, it outputs a guess \( b' \) for \( b \), and the experiment terminates. If \( b = b' \), the experiment outputs true; otherwise, it outputs false.

We define the aaob-advantage of the adversary \( A \) against \( ORAM \) as:
\[ \text{Adv}_{\text{aaob}}^{ORAM}(A) = 2 \cdot \Pr[Exp_{\text{aaob}}^{ORAM}(A) \Rightarrow \text{true}] - 1 \]

We say that \( ORAM \) is aaob-secure (or simply secure) if \( \text{Adv}_{\text{aaob}}^{ORAM}(A) \) is negligible for all polynomial-time adversaries \( A \) (in some understood security parameter \( \lambda \)).

#### Remarks

One key point of our definition is that the adversary learns the response times, which was not the case in [36]. This information is crucial and very hard to argue that an adversary has no access to it. In our deployment scenario, this information is visible to a potential network intruder, and ORAM users will likely have different behaviors triggered by these responses.

We also note that (out of formal necessity) we do not leak the contents of operation responses, only their timing. Otherwise, \( A \) can easily recover the challenge bit \( b \). In the full version, we discuss stronger simulation-based security notions allowing this information to be revealed.

#### Correctness

The above discussion did not address the issue of correctness of the scheme, which is subtle given the concurrent nature of the system. Following the classical literature on distributed systems, Appendix C defines atomic semantics for an asynchronous ORAM scheme as our target correctness notion. This means that operations appear to take place atomically at some point between their invocation and their response.

### Attacks

We present two attacks—one against ObliviStore and one against CURIOUS—breaking their aaob-security. We note that the former attack is a re-iteration of the key idea presented in [4], while our second attack is novel. We provide a high-level explanation of the attacks, but a formalization in our framework (given an appropriate formalization of the scheme) can be obtained easily.

#### Attack against ObliviStore

An attack against ObliviStore can be derived from the weakness already observed in [4]. Specifically, ObliviStore sequentializes accesses on the same item, so an adversary requesting the same item twice (e.g., issuing two subsequent requests \( op1,0 = op2,0 = (read, 1, \bot) \)) will see only one request being made to the storage server, with the second request scheduled only after the response to the first one returns to the client. In contrast, scheduling requests \( op1,1 = (read, 1, \bot) \) and \( op2,1 = (read, 2, \bot) \) for two different addresses will have the adversary see the client immediately schedule two requests to retrieve information from the server. This leads to easy distinguishing. Figure 1 provides diagrams presenting the two situations in detail.

We note two things. First, this attack breaks ObliviStore even in the model in which it was claimed to be secure, as response times are not needed to distinguish between the repeated-access scenario. Also, the attack does not require the network to be asynchronous—only the ability to schedule overlapping operations. Second, if response times can be measured, the attack is very easy to mount: independent experimental validation (with the ObliviStore implementation provided to us) shows that repeatedly accessing the same item leads to a performance degradation of up to 50% compared to accessing well-spread loads.

#### Attack against CURIOUS

To overcome this, [4] suggested an alternative approach based on the idea that a concurrent operation on the same item should trigger a "fake read." We show that this idea, by itself, is not sufficient to achieve aaob-security. Our attack does not contradict security claims in [4], since the model of [36] is used, which does not leak the timing of responses. (As argued above, we believe it is extremely hard to hide these timings in actual deployment.)

When two concurrent requests for the same item are made in CURIOUS (think of these as read requests for simplicity), the first request results in the actual "real read" access to the server fetching the item, whereas the second results in a fake access to the storage server \( SS \) (a so-called "fake read") to hide the repeated access. This "fake read" looks like an access to an unrelated, independent item (the details are irrelevant).

The key issue—ultimately allowing us to distinguish—concerns the timings of the responses given by the ORAM client. When the fake read operation terminates (i.e., the corresponding data is received by the ORAM client from the server), the client always returns the item fetched in the real read if it is available. If the item is not available, then it needs to wait for the real read to terminate. In the asynchronous setting, the latter situation can occur—we have no guarantee that the real read terminates before the fake read. This is in contrast to the case where the reads are for two distinct items (and hence both "real"), and the second request can be answered right away even if the client has not received the data from the server associated with the second request.

This gives the attacker a simple means to break aaob security and distinguish \( b = 0 \) from \( b = 1 \).