(more precisely, could have been generated by) the target
template. Each network link will have a degree of similar-
ity to the template that can be used to classify it as being
after the ﬁrst, second or third node on the path of the con-
nection. Similar attacks have also been presented in Fu et
al. [42] and Levine et al. [28].
The obvious problem of these attacks is that, as pre-
sented, the adversary observes all nodes, network links and
is also to be able to record trafﬁc meta-data at a much ﬁner
granularity than required for the disclosure attacks above.
As a result, these attacks use a global passive adversary,
which is not considered within the Tor threat model. At the
same time, it is important to highlight that these attacks are
robust [29]: when less, partial or lower resolution data is
available they will take longer, and require more evidence
until they provide the attacker with the same degree of cer-
tainty, but in the long run they will still work. Therefore, an
attacker that controls part of the network, as Tor assumes,
might still be able to trace some communications at random.
However this is not very appealing to an attacker because of
the amount of interception effort and analysis required.
An attack worth mentioning has been presented by Ser-
jantov et al.
[38]. They notice that by doing simple
packet counting on lone connections, they can follow the
anonymised streams. Their attack is appealing, since packet
counting can be performed easily and cheaply by most rout-
ing equipment. Others have also looked at detecting step-
ping stones (relays) for intrusion detection [7, 41].
3.2 Trafﬁc-analysis of Tor
As we have seen, traditional trafﬁc-analysis techniques
rely on vast amounts of data. The conventional wisdom
has been that such data can only be gathered by a global
passive observer, which lies outside the Tor threat model.
The key contribution of our work is the realisation that such
Proceedings of the 2005 IEEE Symposium on Security and Privacy (S&P’05) 
1081-6011/05 $ 20.00 IEEE
Initiator
Tor Relay 1
Tor Relay 2
Tor Relay 3
Destination
(Victim)
(Corrupt Server)
Measurement
Traffic
Corrupt Tor Node
Figure 1. The attack setup
observation capabilities are not necessary to perform these
attacks. The ability to route over the anonymous commu-
nication network, that anyone has, can be used to estimate
the trafﬁc load on speciﬁc Tor nodes accurately enough to
perform trafﬁc-analysis. Therefore adversaries with very
modest capabilities can still detect the path that target con-
nections are using through the Tor network.
Mix systems rely on the fact that actions, be it relayed
messages, stream cells or connection startups, from differ-
ent users, are processed by one party, the mix, in such a way
that they become unlinkable to their initiator. In the case of
Tor, multiple connections, from different users have to be
relayed by the same Tor node, for any of them to be pro-
vided with any anonymity at all3. Since the relayed streams
are processed and transported over a particular Tor node,
they interfere with each other. This is due to the fact that
they consume shared resources on a single machine – such
as processor time and network bandwidth.
Some mixing strategies try to correlate streams in order
to make them indistinguishable. The best example is the
threshold mix batching strategy that waits until a particu-
lar number of messages have arrived and outputs them all
at once. Tor does not use any particular batching strategy,
since it would increase the latency of the communication.
Instead, cells from different streams are sent out in a round
robin fashion. When a stream has no cells available it is
skipped and the next connection with cells waiting to be de-
livered is used. This means that the load on the Tor node
affects the latency of all connection streams that are routed
through this node. A similar increase in latency is intro-
duced at all layers. As expected, the higher the load on the
node, the higher the latency.
The simple observation that higher load, even due to one
extra connection, on a Tor node will result in higher latency
of all other connections routed through it can be used by
an attacker. By routing a connection through speciﬁc Tor
nodes, and measuring the latency of the messages, the ad-
versary can get an estimate of the trafﬁc load on the Tor
3Acquisti et al. go as far as claiming that a multitude of users that do
not trust each other have incentives to share the same anonymous network
since their trafﬁc is then all mixed together [1].
node, that is, the superposition of the trafﬁc load resulting
from all relayed connections. This, in turn, can be com-
pared with a known trafﬁc pattern to assess if it is present
in, and therefore relayed through the node, using conven-
tional trafﬁc-analysis techniques [14].
Any Tor user can perform these measurements and try to
estimate the load on a Tor server. On the other hand, a Tor
node is not subject to some restrictions that apply to clients
(e.g. bandwidth limits), therefore, without loss of generality,
we consider that the attacker controls a corrupt Tor node.
This is in accordance with the Tor threat model, and allows
us to ignore whether the node to be measured is also an exit
node or not. This corrupt Tor node creates a connection that
passes through another Tor node, whose trafﬁc load is to be
measured. This connection is then ﬁlled with probe trafﬁc,
that measures the latency of the connection and therefore
estimates the load on the target Tor node. This should allow
the detection of transient trafﬁc signals transiting through
the measured Tor node.
The adversary could observe a connection to or from the
Tor network and use the technique outlined above to de-
tect which nodes it is being relayed through. We propose a
more powerful variant of this attack: we assume that the ad-
versary controls a network server that the user to be traced
is accessing. This falls within the Tor threat model, and to
some extent it is its raˆıson d’´etre: users should be able to
access network services, that might be interested in identi-
fying them, in an anonymous manner. This corrupt server
sends to the user, though the Tor connection, data modu-
lated in a very speciﬁc trafﬁc pattern. In our experiments
we have used a pattern that consists of sequences of short
(a few seconds) bursts of data. Since the attacker knows the
input pattern to the Tor network, he can construct a tem-
plate, and use it to detect whether the trafﬁc volume in Tor
nodes is correlated with it.
Figure 1 illustrates the setup necessary for the attacks.
In the next section we will present the results of setting up
and performing such an attack against the operational Tor
network.
3.3 Trafﬁc-analysis methodology
The goal of an attacker is, based on timing data from all
nodes on the network, to identify which nodes are carrying
the trafﬁc with the pattern injected by the corrupt server.
For each node, we performed a test where the stream from
the corrupt server went through the target node, and one
where the stream did not go through the target node. For
the test to be considered a success, the correlation between
the trafﬁc modulation and probe latency in the case where
the victim stream did go through the target node should be
higher than the case where it did not. If this was not the case
then either the victim stream did not sufﬁciently affect the
Proceedings of the 2005 IEEE Symposium on Security and Privacy (S&P’05) 
1081-6011/05 $ 20.00 IEEE
conﬁgured with the TCP NODELAY option to disable the
Nagle algorithm and ensure the data was sent immediately.
Also, the TCP stream establishment and each segment sent
included a nonce, to avoid port scans from interfering with
our results. The probe server recorded the time the seg-
ment was sent, and also when the segment was received, and
saved both to a ﬁle. While this approach limits us to only
probing Tor nodes that allow outgoing TCP streams (exit
nodes), it could be generalised to all nodes if the attacker
controlled a Tor server, even one which was not approved
by the Tor directory server maintainers.
The corrupt server was simulated by a TCP server which
would send pseudorandomly generated data at as fast a rate
as allowed by Tor, for a pseudorandom time period (for our
experiment between 10 and 25 seconds), then stop sending
for another period (between 30 and 75 seconds). The times
at which it stopped and started sending were stored in a ﬁle
for later analysis. The victim was simulated by a TCP client
which would receive data and record the time at which each
buffer of data was received and logged this. We recorded the
receipt of data to evaluate how much the timing signature of
the data was being distorted by Tor, however this data would
not be available to an attacker and so was not used in our
correlation calculations. The Tor Onion Proxy on the victim
node was unmodiﬁed since it would not be controlled by the
attacker. Again socat was used for the interface between
the victim client and Tor. The non time-critical parts of the
experiment, such as the starting and stopping of programs
and the collection of results from the remote machines, were
written in Python. The probe server used was hosted in the
University of Cambridge Computer Laboratory. The victim
and corrupt server were run on PlanetLab [11] nodes in two
separate US institutions. The full layout of our system is
shown in Figure 1.
In each experimental run, targeting nodes in turn, the
procedure was as follows. The probe server would be set
to monitor the target node, then after 4 minutes the vic-
tim stream would be created so that its ﬁrst hop would be
the node monitored (i.e., the furthest away from the corrupt
server, so the timing pattern would be the most distorted).
Monitoring by the probe server would continue for another
4 minutes after the victim stream was closed. In order to
test for false positives, this test was then repeated, except
the victim stream was sent on a path that excluded the tar-
get node.
4.1 Results
Data from probing 13 Tor nodes4 was collected and pro-
cessed as described in section 3.3 using GNU R [34]. The
4Out of the 50 Tor nodes that made up the network, at the time, ﬁve
were not included so as to check for false positives, and the rest did not
carry the probe or victim stream due to being down or because of exit-
policy restrictions.
probe trafﬁc (causing false negatives), or that “echos” of the
victim stream propagated through the network and affected
the probe stream (causing false positives).
The correlation performed was very simple: the template
formed by the modulated trafﬁc from the corrupt server was
multiplied with the probe data and the sum of the result was
evaluated. In more detail, the template function from the
corrupt server S(t) is:
S(t) =
1
0
if server is sending at sample number t
otherwise
(cid:1)
The data from the probe is expressed as L(t) which is the
measured latency of the target Tor node (in µs) at sample t.
L(cid:1)(t) is the normalised version of the probe data, formed by
dividing L(t) by the mean of all samples.
The correlation, c, is the sum of the product between
S(t) and L(cid:1)(t), divided by the number of samples where
the corrupt server was sending:
(cid:2)
c =
(cid:2)
S(t) × L(cid:1)(t)
S(t)
A number of improvements could be made to this tech-
nique, by using better models of the effect on latency. One
obvious addition is to shift the template in time by an esti-
mate of the latency, or to convolve it with an exponential-
decay function. Also, quantities other than simple latency
could be used, such as a moving variance measure. We have
had satisfactory results with the simple technique, and so
we leave the design of efﬁcient and optimal transient signal
detectors for trafﬁc-analysis for future work.
4 Experimental setup and results
In order to validate the feasibility of the trafﬁc-analysis
attacks, we built and evaluated a simple version of our ap-
proach. The probe computer used was a standard 800 MHz
PC running the Debian GNU/Linux 3.0 operating-system.
Tor version 0.0.9 was set up as being a client only (in
Tor terminology, an Onion Proxy) and modiﬁed to choose
routes of length one (not including itself), rather than the
default of three. In addition to the modiﬁed Tor software,
the corrupt Tor node consisted of a TCP client and server,
both written in C and carefully crafted to avoid the timing
properties being interfered with by runtime services such as
garbage collection. The interface between the TCP client
and the Onion Proxy is achieved using socat [37] to con-
nect to the SOCKS interface of Tor. The targeted Tor node
then connects back to TCP server running on the same ma-
chine.
At regular intervals (in our experiment, every 0.2 sec-
onds) the probe client sent data containing the current sys-
tem time in microseconds (as reported by gettimeof-
day()) and optional padding. The TCP socket used was
Proceedings of the 2005 IEEE Symposium on Security and Privacy (S&P’05) 
1081-6011/05 $ 20.00 IEEE
0
0
0
2
0
0
5
1
0
0
0
1
0
0
5
0
)
s
m
(
y
c
n
e
t
a
l
0
200
400
600
800
time (s)
Figure 2. Probe results showing good correlation (Node K)
correlation quality varied, however for all but 2 nodes it
correctly differentiated the case where the node was car-
rying the victim trafﬁc and the case where the trafﬁc ﬂowed
through other nodes.
Figure 2 shows a good correlation between probe data
in victim trafﬁc. The dots indicate the latency of the probes
and the pattern of the victim stream sent is shown at the bot-
tom. The victim stream received is overlaid to show how the
pattern is distorted by the network. Finally, the horizontal
line indicates the mean latency during the sample period. In
contrast, Figure 3(a) shows the same node being monitored
when the victim stream was being routed elsewhere. Fig-
ure 4 shows a summary of the correlation over all nodes.
For each node, the left bar shows the correlation when the
victim stream was travelling though the node (false negative
test) and the right bar shows the correlation when it was not
(false positive test). The two incorrect results (E and M),
where the correlation was higher when the trafﬁc was not
being sent through the nodes, are highlighted with diagonal
shading lines.
None of the results from the false positive test show
any obvious correlation to the trafﬁc pattern, which sug-
gests that “echos” of load are not signiﬁcantly propagated
through the network. This means that it should be possi-
ble to increase the accuracy of the test simply by running
the test for longer than the 6 minutes in our experiments.
Other options would be to increase the sampling frequency
or to improve the correlation function as suggested in Sec-
tion 3.3. There appears to be signiﬁcant room for improve-
ment, as shown in Figure 3(b) which was not correctly iden-
tiﬁed as being correlated, despite showing visible similarity
to the trafﬁc pattern.
5 Discussion
Our experiments clearly show that Tor streams re-
tain their timing characteristics as they travel through the
anonymising network. Furthermore, these characteristics
affect other streams in such a way that it is possible to
observe them without direct access to the Tor nodes. We
have shown that, as a result, it is possible for an attacker to
discover which Tor server is being used to inject the traf-
ﬁc stream, and degrade the anonymity provided into being
equivalent to a collection of simple proxy servers.
The fact that the timing characteristics of streams are not
substantially altered, and can be used to identify the Tor
nodes carrying them, comes as no surprise. The low latency
requirement of Tor does not allow it to shape the trafﬁc in
any way, and would require large amounts of cover trafﬁc
for these characteristics to be hidden. Since the attack relies
on the indirect measurement of the stream trafﬁc charac-
teristics, a simple minded cover trafﬁc strategy – that only
ﬁlled the links with cover trafﬁc – would not work. The
cover trafﬁc should not only ﬁll the links, to confuse a di-
Proceedings of the 2005 IEEE Symposium on Security and Privacy (S&P’05) 
1081-6011/05 $ 20.00 IEEE
0
0
0
2
0
0
5
1
0
0
0
1
0
0
5
0
2
1
1
0
1
1
8
0
1