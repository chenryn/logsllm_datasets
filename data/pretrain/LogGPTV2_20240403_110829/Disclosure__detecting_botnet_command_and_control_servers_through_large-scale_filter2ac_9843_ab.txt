of each server.
Autocorrelation features. Autocorrelation is widely used for
cross-correlating a signal with itself in the signal processing do-
main [7], and is useful for identifying repeating patterns in time
series data. A series of flow sizes Fi,j can be converted to a
time series by ordering sizes by time. Since the autocorrelation
function also requires a time series that is sampled periodically
as input, we segment the time series by fixed intervals and take
the mean over each interval; empirical testing suggested that a
period of 300 seconds is appropriate. Once a periodically sampled
time series ˆFi,j has been derived from Fi,j, the series is processed
by the autocorrelation function, and features are extracted from
the output. Here, we use a discrete autocorrelation coefficient
R ˆFi,j
with lag j normalized by the variance σ2, where
ˆFi,j
(cid:3)n
i=j xixi−j
.
σ2
R ˆFi,j
ˆFi,j
=
The autocorrelation function outputs the correlation results for
each period in the time series. This output is further processed
by taking the mean and standard deviation over these values to
derive the final autocorrelation features.
Unique flow sizes. In addition to the statistical features de-
scribed above, Disclosure also includes features that count the
number of unique flow sizes observed, and performs statistical
measurements of occurrence density for each of them during the
analysis time. Specifically, an array is constructed in which the
elements are the number of occurrences of a specific flow size.
Afterward, statistical features are computed over this flow size
incidence array to measure its regularity.
3.2.2 Client Access Patterns-Based Features
One typical property of botnets is that the bots frequently
establish a connection with the C&C server. These connections
tend to be ephemeral, as longer-lived connections might draw
undue attention to a bot’s presence.
Our basis for selecting features to extract in order to distinguish
malicious client access patterns from benign ones is that all of the
clients of a C&C server (i.e., bots) should exhibit similar access
patterns, whereas the clients of a benign server should not. Since
all bots share the same, or nearly identical, malicious program,
they tend to access C&C servers similarly unless specifically pro-
grammed otherwise. On the other hand, clients of benign services
tend to exhibit much more varied patterns due to the vagaries
of human action. Disclosure extracts two sets of features to
characterize client access patterns typical of C&C servers and
those typical of benign servers.
Regular access patterns. For each server si and client cj, Dis-
closure prepares a time series Ti,j of flows observed during the
analysis period. Then, a sequence of flow inter-arrival times Ii,j
is derived from the time series by taking the difference between
consecutive connections; that is,
n(cid:4)
Ii,j =
k=1
ti,j,k − ti,j,k−1,
where ti,j,k is the kth element of Ti,j. Then, statistical features are
computed over each inter-arrival sequence, including the minimum,
maximum, median, and standard deviation. Finally, we derive the
131
3.3 Building the Detection Models
To build detection models for identifying C&C servers, we
experimented with a number of machine learning algorithms,
including the J48 decision tree classifier [26], support vector ma-
chines [12], and random forest algorithms [23]. Random forest
classifiers, known to be one of the most accurate learning algo-
rithms, combine multiple classification methods to achieve more
predictive results. In particular, the random forest classifier builds
a number of decision trees, where each node in a tree encodes a
decision using one or more features that partition the input data.
The leaves of each decision tree correspond to the set of possible
labels (i.e., {benign, malicious}), and the output of all of the
trees are then ensembled such that the average behavior among
all trees is produced as the final decision. In our testing, the best
ratio between detection rates (DT) and false positive rates (FP)
were produced by the random forest classifier. Furthermore, the
classifier is efficient enough to perform online detection in our
application. Consequently, Disclosure uses the random forest
classifier to build its detection models.
We evaluated our detection models against NetFlow data col-
lected from two networks: a university network (N1) that does
not apply sampling, and a large Tier 1 network (N2) that samples
one out of 10,000 flows. Figure 2 shows the detection rates (DT1
for N1 and DT2 for N2) and false positive rates (F P1 for N1
and F P2 for N2) for individual features sets, and all possible
combinations among different feature sets. The feature sets we
evaluated are the set of statistical features extracted from (i) the
flow size (F1); (ii) the flow size-based features extracted from
the output of the autocorrelation function (F2); (iii) unique flow
sizes for each server (F3); (iv) the combination of all flow size-
based features (Fall); (v) the features for characterizing client
access patterns (C1); (vi) unmatched flow density (C2); (vii) the
combination of all client access pattern-based features (Call);
(viii) temporal features (Tall); (ix) the combination of client access
pattern and flow size-based features (F + C); (x) the combination
of flow size and temporal features (F +T ); (xi) the combination of
client access pattern and temporal features (C + T ); and, finally,
(xii) the combination of all feature sets (F + C + T ).
Figure 2 indicates that individual feature sets are not as effective
as combinations of multiple feature sets. Furthermore, increased
levels of feature aggregation results in better detection rates with
less false positives. Finally, we note that the most promising re-
sults were achieved on both data sets by using all possible feature
sets as input to the classification process. Hence, Disclosure
uses detection models that include all features sets (F + C + T )
to detect botnet C&C channels.
4. FALSE POSITIVE REDUCTION
NetFlow data, by its nature, provides limited information about
the real activities that are carried out in a network. As a con-
sequence, a botnet detection system based only on the analysis
of NetFlow data could produce results that are likely to contain
some false positives (FP).
As we explain in Section 5, Disclosure can be tuned to de-
crease the overall FP rate to 0.5% or below. However, given the vol-
ume of NetFlow data that must be processed every day in large net-
works, even a misclassification rate less than a fraction of a percent
can result in an unacceptably large number of false alarms. Note
that some existing malicious activity detection systems have shown
to be useful for specific classes of malware or attacks. Clearly, it
would be beneficial to correlate the detection results of our system
with the results of some previously built systems. Therefore, in our
architecture, we include a component that has the aim of correlat-
ing the results that Disclosure produces with the public feeds of
other malware analysis or detection platforms. The main insight
here is that by integrating different data sources, it is possible
to further reduce Disclosure’s FP rate to a manageable level.
We have built a reputation-based component for FP reduction
that uses three public services that provide reports about a wide
Figure 2: Detection rates (DT) and false positive (FP)
rates for different feature combinations. We note that
the DT:FP ratio is most favorable when all features
are used in the detection procedure.
final features for each server si by generating statistical features
across the set of clients that accessed si. This allows Disclosure
to not only find regular patterns in clients, but to determine
whether the set of clients accessing a server behave similarly.
Unmatched flow density. When a bot is unable to communi-
cate with a legitimate C&C server, it detaches from the rest of the
botnet and becomes a zombie. This might happen because the
C&C server was shutdown, or its IP address has been blacklisted.
Since the zombie cannot distinguish between these situations and
transient network errors, it continues querying the server. This
can result in a significant number of flows to a server that do
not have a matching flow in the opposite direction. It is also
possible that a benign server is unreachable for a period of time.
However, the behavior of a benign server’s clients is significantly
different than the behavior of bots that lose access to their C&C
servers. This is because when a benign user is aware that a
server is offline, it typically does not insist on continuing to query
the server indefinitely. Therefore, Disclosure extracts statistics
regarding the number of unmatched incoming and outgoing flows
to detect this behavior. Specifically, let Ui,j be the number of
unmatched flows for server si in time interval tj, where
abs (|Fi,j| − |Fj,i|) .
(cid:5)
Ui,j =
j∈C
Then, Disclosure derives the mean and standard deviation over
a time series of Ui,j as a statistical feature.
3.2.3 Temporal Features
Connections to a benign server are subject to diurnal fluctua-
tions representative of the server’s user population. On the other
hand, connections to C&C servers are dictated by the botmaster,
and require no user intervention. As previously mentioned, the
majority of botnets configure their bots to contact the C&C
server periodically and with relatively short intervals. Therefore,
bot-infected machines connect to C&C servers during periods of
the day that benign clients do not. For example, many benign
servers receive a high volume of traffic during the day, and very
little—or nothing—during the night.
To capitalize on this observation, Disclosure extracts a set
of temporal features that characterize the variability of client
flow volume as a function of time, such that the system can
discriminate between uniform client flow distributions indicative
of C&C servers and benign traffic that follows well-known diurnal
patterns. Specifically, Disclosure segments a time series of
client and flow volume by hour-long intervals per server si, and
calculates statistical features over these.
132
range of malicious activities on the Internet. The first service we
make use of is FIRE [3,31]. FIRE is a system that identifies orga-
nizations and ISPs that have been observed to engage in malicious
activities. FIRE’s website reports detailed information about many
autonomous systems (AS), including a maliciousness score, relative
rankings among other ASes, as well as the number of C&C servers,
exploit servers, and spam and phishing servers the AS has been
hosting over time. In our implementation, we separate each type
of information into two time series: one representing the current
year, and one containing previous historical data. Afterward, we
compute statistical features for each time series. For instance, for
the time series built from the number of C&C servers observed be-
fore 2011, we compute the minimum, mean, and maximum values.
After we repeat this step for each time series, we compute a final
score by aggregating all the values together by assigning a weight of
0.8 to the value for the current year, and 0.2 to the previous years.
The second public service we use in our FP reduction compo-
nent is EXPOSURE [2, 5]. EXPOSURE is a system that uses
passive DNS analysis methods to detect malicious domains. EX-
POSURE currently analyzes data obtained from a large number
of recursive DNS servers, and reports its findings on daily basis.
For each domain, it provides the associated IP address list and the
ASes in which they are located. Leveraging this information, we
count the number of malicious domains detected in each AS and
build a reputation score according to the density of maliciousness
for each AS reported by EXPOSURE.
The last source of information we use for FP reduction is
Google Safe Browsing [4], a service that reports maliciousness
information about a large number of web sites. This tool can also
be used to query specific AS numbers to obtain the percentage
of web sites in that AS that host malicious services.
For each IP address that Disclosure labels as a potential
botnet C&C server, the FP reduction component fetches the asso-
ciated AS number and corresponding reputation scores from FIRE,
EXPOSURE, and Google Safe Browsing. Each of these individual
reputation scores are then aggregated using a weighted linear
combination. That is, given the reputation scores r1, r2, r3 and
corresponding weights w1, w2, w3 for FIRE, EXPOSURE, and
Google Safe Browsing such that
i wi = 1, the final reputation
score R is calculated as
(cid:3)
3(cid:5)
R =
wiri,
i=1
where 0 ≤ R ≤ 1. If R is below a tunable threshold we denote
as RepThresh, this indicates that a particular server is located
in a network that is historically not associated with malicious
activities, and the corresponding alert is discarded as a FP.
We are aware of the fact that the FP reduction component can
introduce an opportunity for the attacker to evade our system.
For example, she could place her C&C server in a network with
a high reputation score. However, note that this increases the
burden on the attacker, and forces her to move away from more
vulnerable targets located in ASes with lower reputation scores
towards potentially better-protected networks. Therefore, we
believe that, on a large scale, this is a favorable result.
5. EVALUATION
In this section, we present the design and results of several
experiments we conducted to evaluate Disclosure’s detection
accuracy, false positive (FP) rate, and performance. We also
present deployment considerations, and conclude with a discussion
of resilience to evasion.
The accuracy of Disclosure’s classification procedure greatly
depends upon the environment in which the input NetFlows have
been collected. For example, NetFlow collectors placed in a small
company network versus those placed in a large ISP will likely
observe significantly different volumes of traffic. To bound the
storage requirements at each collector, sampling rates might be con-
figured to match the particular traffic volume specific to each site.
133
Network
University Network (N1)
Tier 1 ISP (N2)
C&C Servers Benign Servers
1489
1742
892
2000
Table 2: IP addresses in our labeled data set derived
from data observed in N1 and N2.
To measure how Disclosure responds to varying levels of
sampling, we evaluated our system in two distinct environments:
a medium-size network connecting multiple universities with no
sampling, and a Tier 1 ISP network configured with a sampling
rate of 1:10,000.
5.1 NetFlow Data Sets
Our NetFlow data sets were drawn from two separate envi-
ronments: a university network located in Europe, and an ISP
network located in the USA and Japan. Hereinafter, we refer to
the university network as N1 and to the Tier 1 ISP network as N2.
Table 1 shows summary statistics for the two data sets. The
N1 data set was collected for a period of 18 days between the 7th
and the 25th of September 2011. The NetFlow data of N1 is not
sampled and, therefore, all network flows present in the monitored
network are represented in the data. The sensor in N1 produced an
average of 1.2 billion network flows per day. During this period, we
collected 22 billion flows between 28 million unique IP addresses.
In contrast, we collected NetFlow data observed at N2 for a
period of 40 days between the 1st of June 2011 and the 10th of
July 2011. The sensors in N2 were configured to sample flows
at a rate of 1:10,000. The data was harvested by 68 sensors, each
of which was responsible for monitoring and forwarding NetFlow
traffic collected from specific autonomous systems (ASs). The
sensors collected approximately 400 million network flows per day
between 50 million unique IP addresses.
5.2 Ground-Truth Data Sets
The accuracy of the classification models generated by a ma-
chine learning algorithm greatly depends on the quality of the
training set [33]. In our case, to train the features used by Dis-
closure, we required a ground-truth list containing both known
C&C servers and known benign servers.
The malicious server data set consisted of 4295 IP addresses
associated with real C&C servers observed in the wild during
approximately three weeks preceding our experiments. The list
of botnet C&C servers was provided to us by a company that