Dependency Analysis
Detection Analysis
Pinpoint Cluster Analysis
0.2
0.4
0.6
0.8
1
False Positive Rate (1 - Precision)
y
c
a
r
u
c
c
A
1
0.8
0.6
0.4
0.2
0
0
1 Component Faults
2 Component Faults
3 Component Faults
4 Component Faults
0.2
0.4
0.6
0.8
1
False Positive Rate (1 - Precision)
Figure 3. Accuracy vs. false positive rate for
single-component faults.
Figure 5. Dependency’s accuracy vs.
false
positive rate for interacting component faults.
similar accuracies.
To better understand how the 3 techniques perform under
latent faults—faults that occur but are not manifested as fail-
ures until a later component is used—we show their ROC
curves as the “fault length” of the latent faults increases,
where fault length is the number of components interact-
ing to cause a failure. Figure 4 shows that Pinpoint has
a very high accuracy and precision for single-component
faults. As we generate latent faults, however, the Pinpoint’s
ROC curve worsens, though it still remains a signiﬁcant im-
provement as compared to Detection and Dependency anal-
ysis.
In Figure 5 we see that the results of Dependency anal-
ysis do not appear to be affected by the fault length. Al-
though it consistently has a high accuracy (up to 100%),
Dependency always has a very low precision of about 15%.
Figure 6 shows that Detection analysis is heavily affected
by the fault length. Detection always has a high precision
of about 30%, but its accuracy varies from 50% at single-
component faults, down to 0% accuracy for three or more
component-faults.
4.4. Performance Impact
We compared the throughput of the PetStore application
hosted on an unmodiﬁed J2EE server with on our version
with logging turned on. We measured a cold server with a
warm ﬁle cache for three 5-minute runs, and found that the
online overhead of Pinpoint to be 8.4%. We did not mea-
sure the overhead of the ofﬂine analysis. The uncompressed
trace ﬁles generated by Pinpoint average about 2.5k per re-
quest. Compressed, however, they average only 100 bytes
per request.
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:20:30 UTC from IEEE Xplore.  Restrictions apply. 
y
c
a
r
u
c
c
A
1
0.8
0.6
0.4
0.2
0
0
1 Component Faults
2 Component Faults
3 Component Faults
4 Component Faults
0.2
0.4
0.6
0.8
1
False Positive Rate (1 - Precision)
Figure 6. Detection’s accuracy vs. false posi-
tive rate for interacting component faults.
5. Discussion
5.1. Pinpoint Limitations
One limitation of Pinpoint is that it cannot distinguish
between sets of components that are tightly coupled and
are always used together. In the PetStore application, we
have found sets of components that are always used with
the components that we injected faults in, shown in Fig-
ure 7. As a result, Pinpoint reports the super set of the ac-
tual faults. To better isolate faulty components and improve
precision, one potential technique is to create synthetic re-
quests that exercise the components in other combinations.
This is similar to achieving good code coverage when gen-
erating test cases for debugging.
Another limitation of Pinpoint, as well as existing ap-
proaches, is that it does not work with faults that corrupt
state and affect subsequent requests. The non-independence
of requests makes it difﬁcult to detect the real faults because
the subsequent requests may fail while using a different set
of components. For example, a user will not be able to login
if the component responsible for creating new accounts has
stored an incorrect password. The state corruption induced
by the account creation request is subsequently discovered
by the login request. One potential solution is to extend
the current tracing of functional components to trace shared
state. For example, Pinpoint could trace the database tables
used by components to ﬁnd out which sets of components
share state. Implementing this extension is part of our cur-
rent plans for extending Pinpoint.
Since Pinpoint monitors at the middleware and has no
application knowledge about the requests, deterministic
failures due to pathological inputs can not be distinguished
from other failures. For example, a user may have bad cook-
ies that consistently cause failures. One possible solution is
Figure 7. No.
of tightly-coupled compo-
nents associated with each of the compo-
nents where faults were injected
to extend Pinpoint to record the requests themselves and use
them as another possible factor in differentiating failed re-
quests from successful ones.
Pinpoint also does not capture “fail-stutter” faults where
components mask faults internally and exhibit only a de-
crease in performance. Fail-stutter examples include trans-
parent hot swaps and disks getting slower as they fail. Tim-
ing information would need to be used to detect fail-stutter
faults and perform problem determination.
5.2. Application Observations
In the J2EE PetStore application the average number of
application components used in requests of static pages is
3. Using our workload, the average for requests of dynamic
pages is 14.2 with a median of 14 and maximum of 23
(shown in Figure 8). The large number of components used
in requests motivate the monitoring of components at the
middleware layer and the importance of using automated
problem determination techniques.
5.3. Related Work
There has been extensive literature on event correlation
systems [24, 4], mostly in the context of network man-
agement. There are also many commercial service man-
agement systems that aid problem determination, such as
HP’s OpenView [9], IBM’s Tivoli [16], and Altaworks’
Panorama [3]. These systems mainly use two approaches.
The ﬁrst approach uses expert systems with rules (or ﬁl-
ters) input by humans or obtained through machine learning
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:20:30 UTC from IEEE Xplore.  Restrictions apply. 
across requests, as well as using timing and performance
logging to diagnose performance degradations in Internet
services. We are also investigating using other statistical
techniques in our analysis. For example, our initial experi-
ences using dependency analysis to discover multiple inde-
pendent faults are promising.
There are also scaling issues that we need to address be-
fore we deploy Pinpoint in a real, large-scale Internet ser-
vice. The current tracing mechanism needs to be extended
to trace across machine boundaries. In addition, techniques
such as request sampling can be used to reduce logging
overhead. We also plan to automate our statistical anal-
ysis process and integrate it with an alert system to pro-
vide on-line analysis of live systems. In addition, we plan
to integrate Pinpoint with other recovery-oriented comput-
ing techniques [10] to further reduce mean time to recovery
(MTTR).
6. Conclusions
This paper presents a new problem determination frame-
work for large, dynamic systems that provides high ac-
curacy in identifying faults and produces relatively few
false positives. This framework, Pinpoint, requires no
application-level knowledge of the systems being moni-
tored or any knowledge of the requests. This makes Pin-
point suitable for use in large and dynamic systems where
this application-level knowledge is difﬁcult to accurately as-
semble and keep current. As such, it is an important im-
provement over existing fault management approaches that
require extensive knowledge about the systems being mon-
itored.
Pinpoint traces requests as they travel through a system,
detects component failures internally and end-to-end fail-
ures externally, and performs data clustering analysis over a
large number of requests to determine the combinations of
components that are likely to be the cause of failures. The
runtime tracing and analysis is necessary for systems that
are large and dynamic, such as today’s Internet systems.
7. Acknowledgements
We are very grateful to Aaron Brown, George Candea,
Kim Keeton, Dave Patterson, and the anonymous reviewers
for their very helpful suggestions.
Figure 8. Histogram of No. of components
used per dynamically generated page request
techniques. The second approach uses dependency models
[25, 6, 13]. However, these systems do not consider how
the required dependency models are obtained.
More recent research has focused on automatically gen-
erating dependency models. Brown et al.
[5] use active
perturbation of the system to identify dependencies and use
statistical modeling of the system to compute dependency
strengths. The dependency strengths can be used to order
the potential root causes, but they do not uniquely iden-
tify the root cause of the problem, whereas our approach
uniquely identiﬁes the root case, and is limited only by the
coverage of the workload. The intrusive nature of their ac-
tive approach also limits its applicability in production sys-
tems. In addition, their approach requires components and
inputs to be identiﬁed before the dependencies can be gen-
erated, which is not required in our approach.
Katchabaw et al.
[19] introduce a set of libraries that
programmers can use to instrument components to report
their health to a central management system. The approach
requires management code to be written for each compo-
nent, and requires the code to be correct and to function
when the component itself is failing. We take a black-box
approach where we instrument application servers to trace
requests without knowing the implementation details of the
components. Our black-box approach enables independent
auditing of the components without the overhead of writing
additional code for each component.
5.4. Future Work
References
We plan on investigating additional factors and tradeoffs
that affect accuracy and precision of problem determination.
In particular, we are exploring ways of loosening our as-
sumption of request independence by tracking state sharing
[1] Network Packet Capture Facility for Java.
http://
[2] TPC-W
jpcap.sourceforge.net/.
Benchmark
http://www.tpc.org/wspec.html.
Speciﬁcation,
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:20:30 UTC from IEEE Xplore.  Restrictions apply. 
[25] A. Yemini and S. Kliger. High Speed and Robust Event
Correlation. IEEE Communication Magazine, 34(5):82–90,
May 1996.
[3] Altaworks.
Panorama.
http://www.altaworks.
com/product/panorama.htm.
[4] A. Bouloutas, S. Calo, and A. Finkel. Alarm Correlation
and Fault Identiﬁcation in Communication Networks. IEEE
Transactions on Communication, 42(2/3/4), 1994.
[5] A. Brown and D. Patterson. An Active Approach to Char-
acterizing Dynamic Dependencies for Problem Determina-
tion in a Distributed Environment. In Seventh IFIP/IEEE In-
ternational Symposium on Integrated Network Management,
Seattle, WA, May 2001.
[6] J. Choi, M. Choi, and S. Lee. An Alarm Correlation and
Fault Identiﬁcation Scheme Based on OSI Managed Object
Classes. In IEEE International Conference on Communica-
tions, Vancouver, BC, Canada, 1999.
[7] G. Corporation. Google. http://www.google.com/.
[8] H. Corporation. HotMail. http://www.hotmail.
com/.
[9] H. P. Corporation. HP Openview. http://www.hp.
com/openview/index.html.
[10] David Patterson et al.
Recovery Oriented Computing
(ROC): Motivation, Deﬁnition, Techniques, and Case Stud-
ies. Technical Report CSD-02-1175, UC Berkeley Com-
puter Science, 2002.
[11] J. Gray.
Dependability
in
the
Internet Era.
http://research.microsoft.com/˜gray/
talks/InternetAvailability.ppt.
[12] A. Group. Log4j Project, 2001. http://jakarta.
apache.org/log4j.
[13] B. Gruschke. A New Approach for Event Correlation based
on Dependency Graphs. In 5th Workshop of the OpenView
University Association: OVUA’98, Rennes, France, April
1998.
[14] J. L. Hennessy and D. A. Patterson. Computer Architecture:
A Quantitative Approach. Morgan Kaufmann, third edition,
2002. Chapter 8.12.
[15] HP. e-Speak, 2001. http://www.e-speak.hp.com/.
[16] IBM. Tivoli Business Systems Manager, 2001. http://
www.tivoli.com.
[17] V. Jacobson, C. Leres, and S. McCanne.
tcpdump, 1989.
ftp://ftp.ee.lbl.gov/.
[18] A. K. Jain and R. C. Dubes. Algorithms for Clustering Data.
Prentice-Hall, 1988.
[19] M. J. Katchabaw, S. L. Howard, H. L. Lutﬁyya, A. D. Mar-
shall, and M. A. Bauer. Making distributed applications
manageable through instrumentation. The Journal of Sys-
tems and Software, 45(2):81–97, 1999.
[20] Microsoft.
.NET, 2001. http://www.microsoft.
com/net/.
[21] S. Microsystems.
Java Pet Store 1.1.2 Blueprint
http://developer.java.
2001.
Application,
sun.com/developer/sampsource/petstore/
petstore1_1%_2.html.
[22] D. Oppenheimer and D. A. Patterson. Architecture opera-
In
tion and dependability of large-scale Internet services.
Submission to IEEE Internet Computing, 2002.
[23] H. C. Romesburg. Cluster Analysis for Researchers. Life-
time Learning Publications, 1984.
[24] I. Rouvellou and G. W. Hart. Automatic Alarm Correla-
tion for Fault Identiﬁcation. In INFOCOM, pages 553–561,
1995.
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:20:30 UTC from IEEE Xplore.  Restrictions apply.