once. Relative to the first implementation, this one trades off
memory efficiency for lower algorithmic complexity. (3) The
third one is the LPM implementation that comes with DPDK,
which implements a hierarchical version of Direct Lookup:
the first 24 bits of the destination IP address are used to index
a first-stage array, which then points to a second-stage array
if any routes with longer IP prefixes exist within the given
/24 IP prefix. Relative to the second implementation, this one
reduces the memory footprint, while also limiting lookup
SIGCOMM ’18, August 20–25, 2018, Budapest, Hungary
L. Pedrosa et al.
procedure to at most two array accesses.
The NAT and LB both store their per-flow state in an asso-
ciative array. For each of these two NF classes, we use four
different associative-array implementations: (1) A standard
hash table of 65, 536 entries that resolves collisions through
separate chaining: elements that hash to the same position
are stored in a linked list referenced by that position. Lookup
of an element involves one hashing operation to pick a po-
sition, then traversing the referenced linked list until we
find a matching element (or reach the end of the list). Hence,
lookup complexity depends on the largest number of stored
elements that happened to hash to the same position. (2)
A standard hash ring, of 16.7M entries, that resolves col-
lisions through open addressing: elements are stored in a
circular array; if an element hashes to an array position that
is already taken, it is stored in the first available subsequent
position. The array is allocated within a single 1GB page,
with each entry cache-aligned for performance. Lookup of
an element involves one hashing operation to pick a posi-
tion, then traversing the occupied positions of the array until
we find a matching element (or traverse the entire array).
Hence, lookup complexity depends on the number of stored
elements. (3) An unbalanced binary tree, where lookup of
an element involves a standard binary search. Without re-
balancing, the tree is susceptible to skew, potentially becom-
ing a linked list. Hence, lookup complexity depends on the
number of stored elements. (4) The STL std::map data struc-
ture, which is a red-black tree, i.e., automatically re-balanced
whenever skew occurs.
Workloads. First, we created generic workloads that we
used across all NFs: (1) 1 Packet consists of the same packet,
replayed in a loop. We use it to assess best-case performance.
(2) Zipfian consists of traffic that is randomly generated ac-
cording to a Zipfian distribution with s = 1.26. The exponent
s was computed from a public dataset [6] which includes
real-world traffic captures from a University network. The
corresponding PCAP file has 100, 005 packets in 6, 674 unique
flows. It represents typical real-world traffic. (3) UniRand
consists of traffic that is randomly generated according to
a uniform distribution. The corresponding PCAP file has
1, 000, 472 packets in 1, 000, 001 unique flows. This kind of
traffic is typically part of denial-of-service attacks and is used
to stress-test NFs.
For the LB NFs, in particular, we did somewhat tailor the
generic workloads to the NF in order to force the only inter-
esting case, where the destination IP is set to the VIP. Any
other traffic is either statically routed or outright dropped
without any data structure access. This did not affect the
resulting packet distribution parameters.
Second, we created NF-specific workloads: (1) CASTAN and
(2) Manual are adversarial workloads generated, respectively,
by CASTAN and by hand. (3) UniRand CASTAN is similar to
379
UniRand, but involves the same number of flows as CASTAN.
We use it for a fair comparison to CASTAN when sheer traffic
volume is what matters for performance.
5.2 Adversarial Memory Access
First, we look at NFs that we expect to be susceptible to adver-
sarial memory access and ask: can we craft workloads that
consist of relatively few packets, yet introduce significant
cache contention?
The NFs we consider are LPM with one-stage and two-
stage Direct Lookup, which map the IP address space to a
small number of large arrays. This approach restricts the
number of instructions per packet to a small, predictable
number, but introduces opportunity for cache contention.
This is normally not a problem, as typical real-world work-
loads follow skewed, cache-friendly distributions, but could
be a problem if an adversary can craft a workload that pur-
posefully causes cache contention, especially if she does it
with relatively few packets, i.e., without even filling the cache.
The last point is important, because the smaller the workload
an adversary needs to have an effect, the harder it is to detect
it with standard entropy-based anomaly detectors.
For these two NFs, CASTAN synthesized workloads consist-
ing of 40 unique packets, each in a different flow. We did
not craft Manual workloads, as we were not able to reverse-
engineer cache behavior by hand. The straightforward way
to stress-test these NFs would be to access as much memory
as possible, which UniRand already does.
Table 1 shows the throughput for the same NF. We see
that CASTAN and UniRand achieve 19% lower throughput
than the other workloads. The micro-architectural analysis
confirms these results: Fig. 5 shows the CDF of the number of
reference cycles consumed per packet, and clearly illustrates
the difference between the typical Zipfian workload and the
Fig. 4 shows the latency CDF for LPM with single-stage
Direct Lookup. This NF uses a single 1GB array, which far
exceeds the size of the 25.6MB L3 cache. First, we see that
the Zipfian workload experiences similar latency as 1 Packet,
indicating an insignificant cache-miss rate. Second, we see
that the UniRand workload triples the latency introduced by
the NF: the median distance between the NOP and UniRand
curves is about three times the median distance between the
NOP and Zipfian/1 Packet curves. This is consistent with the
expectation that uniformly accessing the 1GB array will lead
to a significant cache miss rate.
Most importantly, the 40-packet workload synthesized by
CASTAN experiences similar latency as the 1M-packet Uni-
Rand workload. So, both CASTAN and UniRand triple latency,
but CASTAN does it with four orders of magnitude fewer pack-
ets. UniRand CASTAN, which, in this case, is a UniRand-like
workload that consists of 40 packets, introduces similar la-
tency with Zipfian and 1 Packet.
Automated Synthesis of Adversarial Workloads
for Network Functions
SIGCOMM ’18, August 20–25, 2018, Budapest, Hungary
4:
End-to-end
Figure
latency
CDF for LPM with 1-stage Direct
Lookup.
NF
LPM
1-stage
DL
3.45
NOP
2.59
1 Packet
2.59
Zipfian
UniRand
2.12
UniRand CASTAN 2.59
2.1
CASTAN
Manual
-
LPM
2-stage
DL
3.45
2.87
2.86
2.49
2.87
2.82
-
Figure 5: CPU reference cycles
CDF for LPM with 1-stage Direct
Lookup.
LB
un-
balanced
tree
3.45
2.87
2.7
1.64
2.65
2.69
2.7
LB red-
black
tree
3.45
2.49
2.33
1.32
2.6
2.56
-
NAT un-
balanced
tree
3.45
2.49
2.17
0.95
2.28
2.01
1.9
NAT red-
black
tree
3.45
2.38
1.9
0.95
2.28
2.22
-
LPM
btrie
3.45
2.87
2.87
2.8
2.87
2.65
2.7
NAT
hash
table
3.45
2.44
2.38
0.47
2.33
2.39
-
LB hash
table
3.45
2.87
2.76
1.48
2.87
2.73
-
NAT
hash
ring
3.45
2.44
2.38
1.96
2.44
1.97
-
6:
End-to-end
Figure
latency
CDF for LPM with 2-stage Direct
Lookup.
LB hash
ring
3.45
2.87
2.87
2.65
2.87
2.69
-
LB hash
ring
271
409
409
415
409
409
-
LB hash
ring
1
2
2
3
2
4
-
Table 1: Maximum throughput measured for each NF under each workload (Mpps)
NF
LPM
1-stage
DL
271
NOP
309
1 Packet
309
Zipfian
UniRand
309
UniRand CASTAN 309
309
CASTAN
Manual
-
LPM
2-stage
DL
271
317
317
317
317
317
-
LPM
btrie
271
341
341
341
343
699
699
LB
un-
balanced
tree
271
378
433
1127
422
678
678
NAT un-
balanced
tree
271
549
688
2271
626
1100
1224
LB red-
black
tree
271
469
663
1099
537
559
-
NAT red-
black
tree
271
617
900
2054
703
769
-
NAT
hash
table
271
416
666
1658
593
593
-
LB hash