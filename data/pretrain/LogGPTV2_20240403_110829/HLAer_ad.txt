	After clustering the log data, an overall structure of all the heterogeneous logs is generated. However, patterns within each cluster is still very necessary in order to semantically understand the logs in-depth. The conception of “pattern” is defined here as the layout/format of the log records. For example, in the log record“Jan 8 05:49:14 www httpd[7855]: 108.199.240.249 - - ”GET /images/header/nav-pub-on.gif HTTP/1.1” 200 569”, its pattern is 
	date time www httpd[number]: IP – ”GET URL” number number.
The purpose of pattern recognition is to identify which field of a log record after tokenization is about what specific information.Since within each cluster, the log records have very similar formats due to the definition in Equation 3, pattern recognition is performed within a cluster using the idea of sequence alignment from Bioinformatics research. In specific, all the log records within a cluster are aligned together so as to identify the motifs (i.e, the most conserved and frequent common portion), and thus the common patterns, from the logs. Smith-Waterman algorithm [13] is used to perform pairwise alignment and then Unweighted Pair Group Method with Arithmetic Mean (UPGMA) [14] strategy is used to perform multiple alignment. Note that the pattern recognition is done first in the leaf nodes, where the cluster purity is high and thus the alignment is clear cut, and then the pattern information is backpropagated back from the leaves to the root node.The strategy of first conducting clustering and then performing multiple sequence alignment within clusters is also for computational efficiency purpose. For a dataset of n log records, the multiple sequence alignment on all the n log records requires the calculation of O(n2) pairs of alignment as described later in Section VI-C1. However, if the n logs are clustered into m clusters equally, for example, it only requires O(n2 m) pairs, which can dramatically decrease the computation load. In addition, the alignment task for each cluster is fully decoupled and thus it is trivial to parallel all the alignment tasks.1) Sequence Alignment for Pattern Recognition: The building block of pattern recognition via multiple sequence alignment is pairwise sequence alignment. The basic idea of pairwise sequence alignment is to find an optimal arrangement of two sequences side by side by which the alignment score is maximized. In order to make such alignment, four different operations are available during pairwise alignment: match, mismatch, insert (gaps) and delete. Each of the operations contributes its own score to the alignment, and the alignment score is calculated as the sum of all such scores. Pairwise sequence alignment is typically formulated as an optimization problem in which the objective is to maximize the alignment score, and dynamic programming [8] is a popular method to solve the optimization problem. The Smith-Waterman method is the most popular method that utilizes dynamic programming for pairwise sequence alignment, which requires a scoring function that measures the total score of the alignment.12
Adaptive scoring scheme: similarly as in the situation for fssim, the match score, insert score and delete score are rigid.
However, the scoring scheme can also be adaptive using the idea from active learning. For example, when S1(i) 6= S2(j), the match score between S1(i) and S2(j) can be replaced by their similarity score that is adaptively learned for fssim.Computational efficiency and scalability of sequence alignment: the computational complexity for pairwise sequence alignment for two sequences of length m and n, respectively, is O(mn), which is expensive. The situation is even worse for multiple sequence alignment. However, it can be remedied by the following two options: 1) parallel multiple sequence alignment since parallel algorithms for multiple sequence alignment has been well developed from Bioinformatics research [5]; 2). down-sample the sequences and this can be done starting from the calculation of fssim, that is, if fssim of two sequences (i.e., logs) is close to 1 enough, then only one of them can be sampled and used for further alignment and pattern recognition. The second option is quite practical due to the nature of log data.2) Pattern profiling: After multiple log alignment, from each conserved motifs (i.e., well-aligned segments of multiple logs), two different types of patterns are recognized. The first is application-irrelevant fields such as time stamps, IP addresses, URLs, internet application protocols, etc. Such fields are hard-coded within the source code and will appear regularly within a common log format. The second type is application-specific fields that contain vocabularies only specific to the applications and its runtime.For the first type of patterns, a tag is dedicated to each field. For example, for time stamp “2013-07-08 11:18:10”, tag“time yyyymmdd hhmmss” is used to represent this field. This type of patterns is standard, even though each of them may have a finite set of different formats. For example, for time stamps, the format can be like “2013-07-08 11:18:10” or “11:18:10 07/08/2013”. However, since the formats are limited, each of them can be properly handled. Individual parsers for these formats are implemented. In addition, the information is saved in tree nodes in a histogram so as to keep track of the range.For the second type of patterns, the pattern profile is retained. For all the words that fall in the field, their distribution is calculated and stored in the hierarchical tree structure. Since it is assumed that the log vocabulary is limited and the logs are well formatted, the distribution of all the words in one field is in heavy tail. This nature makes the storage requirement not a particularly critical issue. Also even when in special cases there are many words occurring in a same field, the distribution list can be truncated so as to only keep the top most frequent words in the list.3) Pattern of patterns: As mentioned in Section VI-C, the pattern recognition is done in the leaf node, where relatively the clustering is pure and the patterns are clear. After the pattern recognition is done, the patterns are backpropagated to upper-level nodes from the leaf nodes. The backpropagation is done by aligning the profiles of the patterns based on the idea of profile alignment from Bioinformatics [4], for example, profile Hidden Markov Models can be used to align profiles. However, for simplicity, the most possible sequence from each pattern profile, that is, the sequence of words that are most frequent at each field, is used as a representative of the profile and then sequence alignment is conducted. In each intermediate node, profiles from lower-level nodes are first aligned and then a consensus profile is generated as the profile for this node. In addition, each node has pointers directed to the profiles of its lower-level children nodes. This pattern backpropagation is done in a bottom-up fashion from the leaf nodes up to the root node.D. Indexing
	After the hierarchical clustering of all the logs, the logs are sorted according to the DBScan algorithm and also a tree structure LCT is built. Figure 8 demonstrates a LCT node. In specific, each node in LCT has the following information.••	Log indices: indices of the logs that are clustered as in the corresponding clusters. 	Pattern profile: including the field tag (e.g., timestamp, URL, IP, numerical values etc), word distribution (e.g., as 	in Figure 8, “GET” happens 53% out of all the times in field 5), and a representative log of this cluster.
•	Pointers to the children nodes: the log indices of the children nodes are the subsets of the log indices of the parent node.Figure 3 demonstrates how the indexing is implemented. Basically all the logs are first sorted based on DBScan algorithm. Then in the hierarchical tree structure LCT, each node contains a set of logs after the re-ordering. The LCT structure organizes all the logs such that similar logs are within a same sub-tree. The more similar the logs are, the lower level sub-tree they fall within.VII. 	IMPLEMENTING THE HLAer FUNCTIONALITIES
A. Online pattern recognitionAfter the LCT is constructed, given a new log record, its format can be recognized using LCT in a top-down fashion. In specific, once a log record is routed to an LCT node, the log record is aligned with all the pattern profiles in this node. If the alignment score is higher than a pre-specified score, the log is considered as to have the corresponding pattern. The log-profile alignment is done in a similar fashion as in pairwise sequence alignment (via dynamic programming) except in the scoring function, the profile distribution is also considered, that is, the score is calculated as the sum of all the words happening in the corresponding field weighted by their frequencies.For a given log record, if a cluster is found which has the pattern most similar to the pattern of this log record, this log is considered as normal pattern. Otherwise, this log is considered as abnormal/rare.
13
LCT node
|  |
|---|
|   ||   |
patterns have the field of question. If they do, then the search is routed down to the corresponding children. The organization of all the log records grants the opportunity that the search process can quickly filter out a lot of irrelevant log records. Query on timestamps of various formats has been implemented. Particularly, queries such as all logs before/after a certain timestamp, orwalk-around is to build an indexing on the popular query items, e.g., time, IP, URL, etc, and thus the query can be directed immediately to the right patterns/logs. Figure 9 demonstrates how the query is done in a top-down fashion. The basic idea is at
represents the most complicated queries on single fields. For the fields of numerical values, the four operations as in Table III, that is, =, >, ,2012-7-9 20:50:5 
<,2012-7-9 21:29:53 
in,2012-7-9 20:50:5,2012-7-9 21:29:53
to find all the logs which are recorded at exactly 2012-5-25 5:49:6 
to find all the logs which are recorded after 2012-7-9 20:50:5 
to find all the logs which are recorded before 2012-7-9 21:29:53 