dependency comes from the algorithmic design where (i) every
counter update depends on the key in the bucket (because the
counter should be incremented only if the recorded key matches
that of the arriving packet), but (ii) every key update depends
on the counter in the bucket (because the probability to replace
the key in the bucket depends on its estimated size). To address
this, we simplify the update logic, and put the flow key and the
estimated size into separate stages. Thus, the update process in
one bucket can be pipelined.
By eliminating the circular dependencies both across and within
buckets, CocoSketch can be implemented efficiently in hardware
(e.g., in FPGA, throughput is improved by 5× compared to a naive
implementation with circular dependencies). While removing the
circular dependencies might weaken the accuracy guarantee, our
evaluation in §7.5 demonstrates that the accuracy drop is not sig-
nificant (e.g.,  1: Second, we discuss
the general case of 𝑑 > 1. CocoSketch updates only one of the
mapped buckets. According to Eq. (4), we can derive the variance
increment if we will update the 𝑖𝑡ℎ mapped bucket, and then we can
compare their variance increment and choose one whose increment
is the least to update. If 𝑒𝑖 = 𝑒 𝑗, the increment of variance is 0.
Therefore, we should first update the bucket recording the same flow
of full key. If 𝑒𝑖 ≠ 𝑒 𝑗, the increment of variance is 2𝑤 𝑓𝑗. Therefore,
if there is no bucket recording the same flow, we should find the
bucket with the smallest value field and update it based on Eq. (3).
5.2 Error Bound
Next, we derive the estimation errors of CocoSketch. Let 𝑀 = 𝑑 · 𝑙
be the number of buckets in CocoSketch, where 𝑑 is the number
of arrays and 𝑙 is the number of buckets in each array. We define
𝑅(𝑒) to be the relative error of 𝑒, i.e., 𝑅(𝑒) =
(see Appendix A.2 for the proof) shows the bound of 𝑅(𝑒) for the
(cid:12)(cid:12)(cid:12)(cid:12)(cid:98)𝑓 (𝑒)−𝑓 (𝑒)
hardware-friendly CocoSketch. Here, 𝑓 (𝑒) =𝑒𝑖 ≠𝑒 𝑓 (𝑒𝑖).
(cid:12)(cid:12)(cid:12)(cid:12). Theorem 3
Theorem 3. Let 𝑙 = 3 · 𝜖−2 and 𝑑 = 𝑂(log 𝛿−1). For any flow 𝑒 of
𝑓 (𝑒)
arbitrary partial key 𝑘𝑃 ≺ 𝑘𝐹 ,
(cid:34)
(cid:115)
(cid:35)
𝑓 (𝑒)
𝑓 (𝑒)
Interpretation: The same bound on relative errors holds for any
partial key, including the full key. On the other hand, Theorem 3
shows that the distribution of error 𝑅(𝑒) varies with 𝑑 and 𝑙. For
instance, with a larger 𝑑 (i.e., a smaller 𝛿), the error will be bounded
(by 𝜖 ·(cid:112)𝑓 (𝑒)/𝑓 (𝑒)) with a greater probability, which matches our
experiments in §7.5.
5.3 Recall Rate
Finally, we derive the recall rate (i.e., how likely a flow is recorded)
of the hardware-friendly CocoSketch (see Appendix A.3 for the
proof). Let 𝑍(𝑒) be a 0-1 function, with 𝑍(𝑒) = 1 if and only if flow
𝑒 is recorded in the CocoSketch.
Theorem 4. For any flow 𝑒 of full key 𝑘𝐹 ,
1 + 𝑙 · 𝑓 (𝑒)
𝑓 (𝑒)
P [𝑍(𝑒) = 1] ⩾ 1 −
(cid:18)
(cid:19)−𝑑
(6)
Interpretation: According to this theorem, the lower bound of
the recall rate will increase as the flow size 𝑓 (𝑒) increases. In other
words, larger flows are more likely to be recorded. Moreover, the
lower bound will raise as 𝑑 increases. To put the theorem in practice,
if we want to achieve a 99% recall rate on the heavy hitter that
constitutes at least 1% of the whole traffic, (i.e., 𝑓 (𝑒)/𝑓 (𝑒) = 1/99),
we can set 𝑑 = 2 and 𝑙 = 900 (i.e., in total, 1,800 buckets) in the
sketch.
(1)
P
𝑅(𝑒) ⩾ 𝜖 ·
⩽ 𝛿
(5)
Stochastic variance minimization for 𝑑 = 1: We first discuss
the simplest case when CocoSketch has only one array and one
associated hash function (𝑑 = 1). Suppose that the incoming packet
is (𝑒𝑖, 𝑤), and it is mapped to the bucket whose recorded key and
value are 𝑒 𝑗 and 𝑓𝑗. To optimize Eq. (2), we need to update the
mapped bucket to (𝑒′, 𝑓 ′) in a way that minimizes the increment
of variance for each insertion.
Theorem 1. The solution to optimize Eq. (2) is
𝑤
𝑓𝑗 + 𝑤
𝑓𝑗
𝑓𝑗 + 𝑤
(𝑒𝑖, 𝑓𝑗 + 𝑤), w.p.
(𝑒 𝑗 , 𝑓𝑗 + 𝑤), w.p.
(𝑒′, 𝑓 ′) =
(3)
The proof is in Appendix A.1. Note that regardless of whether 𝑒𝑖
matches 𝑒 𝑗, the value in the mapped bucket will always be incre-