practical security risks to real deployments (in which ages may be top-coded). In Section 3 we discuss
how this impacts the accuracy of our clique-ﬁnding attack.
The only attribute which did not appear in all years (namely not in 2004) of HCUP data was
NCHRONIC. Since we had several other datasets for that attribute and the performance of all attacks
on that attribute was similar across experiments, we were not concerned. We were not able to obtain
the full 2008 NIS, and as a result we did not have MRISK or SEV data for that year. Our attacks
performed well on the 2004 and 2009 MRISK and SEV attributes.
30
# Patient records per hospital
Year # Hospitals Min 25% 50% 75% Max
2004
2008
2009
1004
1056
1050
15
1199
4300
11523
71580
3
1
889
750
3439
11170
117372
3278
10487
121668
Attribute name Abbrev.
Size # Queries 2004 2008 2009
Age (in days)
AGEDAY
Length of stay
Age (years)
LOS
AGE
Admission month
AMONTH
# Chronic condi-
tions
NCHRONIC
NCHRONIC
# Diagnoses
# Procedures
NDX
NDX
NPR
NPR
ZIP code income
quartile
ZIPINC
Mortality risk
MRISK
Disease severity
SEV
365
365
91
12
16
26
16
26
16
26
4
4
4
66795
66795
4186
78
136
351
136
351
136
351
10
10
10
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
Figure 7: (Top) Number of hospitals and quartiles for number of records per hospital for 2004, 2008 and 2009
HCUP data. (Bottom) Attributes used in our experiments, their sizes, abbreviations, and their availability for
each target year.
31
C Analytical Model of the Main Attack
√
In this section, we provide an analytical model for the behavior of our main attack from Section 3. The
goal is to provide insight into the values of relevant quantities, such as the number of volume collisions,
relative to the number of values N and the number of records R. The main takeaway is that the ratio
R/N 2 (or its square root
R/N ) emerges as the critical value that determines whether our main attack
succeeds (this also holds for the update attack from Section 4). This observation aligns well with our
experiments: if the critical value R/N 2 is much below 1 our attacks typically fail; and if it is 1 or higher
our attacks typically succeed easily. The exact cutoﬀ depends on other parameters of the attack, and
especially the underlying data distribution.
For the purpose of our analytical model, we assume that the data is distributed uniformly, i.e.
each record is assigned a uniform and independent value in [1, N ]. As a result, the number of records
matching any particular value (or indeed any range of values) follows a binomial distribution. As
explained in Section 3.2, the main idea behind our model is to approximate the volume of each range as
an independent Poisson variable—the Poisson distribution being a good approximation of the binomial
in our parameter range. This is of course a heuristic assumption, and in general our computations
will aim to provide simple, readable formulas rather than exact ones. This will rely on approximating
some values:
for this purpose, we focus on approximations that hold within the relevant parameter
range where our attack is close to either succeeding or failing; we do not try to cover extreme ranges
(typically R (cid:28) N 2 or R (cid:29) N 2, where our attack always fails or always succeeds, respectively). That
these assumptions and approximations ultimately yield meaningful predictions will be validated by
experiments in Appendix C.4.
Intuitively, the fact that the ratio between R and N 2 is the critical quantity to assess the success
of our attack is not surprising: indeed, our attacks all essentially require that there are relatively few
collisions between the volumes of diﬀerent ranges (where by few collisions we mean that no more than,
say, 1/2 of volumes are in collision—so a constant ratio, rather than a negligible one). From this
(cid:1) ≈ N 2/2; and all volumes must lie within [0, R]. Hence
perspective, the number of possible ranges is(cid:0)N
2
on a rough intuitive level, it makes sense that having relatively few collisions should require that the
ratio R/N 2 should not be too low. The model we now present, and call the Poisson model, will further
support this intuition.
C.1 Number of Volume Collisions
For a given database, we say that two volumes collide iﬀ two distinct range queries have the same volume
(i.e. match the same number of records). As a ﬁrst step, we compute an estimate of the total number of
collisions between volumes. For the purpose of this estimate, we will only count the number of pairwise
collisions, as this provides a good enough estimate within the relevant parameter range. Furthermore
we only count the number of collisions between ranges of the same length:
indeed experiments show
that this case generates the vast majority of collisions. Moreover this simpliﬁcation will allow for easily
readable closed-form formulas, as we shall see.
We now set out to approximate the probability of collision between the volumes of two range queries
of length d. Since each range contains d values, and there are R uniformly distributed records, each
range matches Rd/N records on average. Accordingly, and following the Poisson model outlined in the
introduction of this section, we model the distribution of the corresponding volume as a Poisson variable
with parameter Rd/N .
The diﬀerence between two Poisson variables is equal to a Skellam distribution, and so the probability
that the two volumes collide is exactly the value of the appropriate Skellam distribution at 0. For two
32
Poisson variables with parameter µ = Rd/N , this is:
def
= e
−2µI0(2µ)
p(µ)
where I0 denotes the modiﬁed Bessel function of the ﬁrst kind.
In our parameter range where µ > 1 (and µ is typically much larger), I0(2µ) can be closely approx-
√
imated by e2µ/
4πµ, so that we get:
p(µ) ≈ 1
√
2
πµ
=
2
(cid:112)
1
πRd/N
.
(1)
It may be worth pointing out that the Poisson distribution with parameter µ tends towards a Gaussian
distribution with mean µ and variance µ for larger µ’s, and if we were to use such a Gaussian model
instead of our Poisson model, while it would less closely match the multinomial distribution for smaller
µ’s, it would still yield precisely the same collision probability.
Since there are N + 1 − d ranges of length d, it follows that the total number of volume collisions
can be approximated by:
2
πRd/N
·
1
2
(cid:112)
(cid:18)N + 1 − d
(cid:19)
N(cid:88)
(N − d)2(cid:112)
N(cid:88)
(cid:112)
· (1 − d/N )2
(cid:90) 1
(1 − x)2√
1
N
d/N
d/N
d=1
d=1
x=0
x
N(cid:88)
d=1
√
≈ 1
πR
4
=
N 3
√
4
πR
≈ N 3
√
4
πR
≈ N 3
√
πR
4
where the last line uses the fact that the integral on the right-hand side is equal to 16/15 ≈ 1.
√
In the end, we get that the total number of volume collisions can be approximated by N 3/(4
(cid:1) ≈ N 2/2 possible ranges, it also follows that the ratio of volumes in collision
Since there are(cid:0)N +1
Our experiments in Appendix C.4 show that this is in fact quite a good estimate.
πR).
2
among all possible volumes can be estimated to:
N 3
√
4
πR
· 2
N 2 =
√
N
πR
.
2
√
As foreshadowed in the introduction of this section, we see that the critical quantity for a constant ratio
R. In particular, the model predicts that for R = Ω(N 2), the ratio
of volumes to be collision-free is N/
of collisions among volumes is O(1).
Another relevant observation is that requiring no collision at all between volumes would impose
R = Ω(N 6), which is unreasonable for typical databases. Hence it is crucial that our algorithms should
be tolerant to collisions between volumes, as they indeed are.
It is also interesting as a side note to observe that the database counts C such that C(k) is the
number of records with value k satisﬁes that there are no collision between volumes iﬀ the set of partial
33