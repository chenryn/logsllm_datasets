title:Acoustic Side-Channel Attacks on Printers
author:Michael Backes and
Markus D&quot;urmuth and
Sebastian Gerling and
Manfred Pinkal and
Caroline Sporleder
Acoustic Side-Channel Attacks on Printers
Michael Backes1
,
2, Markus D¨urmuth1, Sebastian Gerling1, Manfred Pinkal3, Caroline Sporleder3
1Saarland University, Computer Science Department, Saarbr¨ucken, Germany
2Max Planck Institute for Software Systems (MPI-SWS)
3Saarland University, Computer Linguistics Department, Saarbr¨ucken, Germany
Abstract
We examine the problem of acoustic emanations of print-
ers. We present a novel attack that recovers what a dot-
matrix printer processing English text is printing based
on a record of the sound it makes, if the microphone is
close enough to the printer. In our experiments, the at-
tack recovers up to 72 % of printed words, and up to
95 % if we assume contextual knowledge about the text,
with a microphone at a distance of 10cm from the printer.
After an upfront training phase, the attack is fully auto-
mated and uses a combination of machine learning, au-
dio processing, and speech recognition techniques, in-
cluding spectrum features, Hidden Markov Models and
linear classiﬁcation; moreover, it allows for feedback-
based incremental learning. We evaluate the effective-
ness of countermeasures, and we describe how we suc-
cessfully mounted the attack in-ﬁeld (with appropriate
privacy protections) in a doctor’s practice to recover the
content of medical prescriptions.
1 Introduction
Information leakage caused by emanations from elec-
tronic devices has been a topic of concern for a long
time. The ﬁrst publicly known attack of this type, pub-
lished in 1985, reconstructed the monitor’s content from
its electromagnetic emanation [36]. The military had
prior knowledge of similar techniques [41, 20]. Related
techniques captured the monitor’s content from the ema-
nations of the cable connecting the monitor and the com-
puter [21], and acoustic emanations of keyboards were
exploited to reveal the pressed key [3, 42, 7]. In this work
we examine the problem of acoustic emanations of dot-
matrix printers.
Dot matrix printers? Didn’t these printers vanish in
the 80s already? Although indeed outdated for private
use, dot-matrix printers continue to play a surprisingly
prominent role in businesses where conﬁdential informa-
tion is processed. We commissioned a representative sur-
vey from a professional survey institute [26] in Germany
on this topic, with the following major lessons learned
(Figure 1 contains additional information from this sur-
vey):
• About 60 % of all doctors in Germany use dot
matrix printers, for printing the patients’ health
records, medical prescriptions, etc. This corre-
sponds to about 190,000 doctors and an average
number of more than 2.4 million records and pre-
scriptions printed on average per day.
• About 30 % of all banks in Germany use dot matrix
printers, for printing account statements, transcripts
of transactions, etc. This corresponds to 14,000
bank branches and more than 1.2 million such doc-
uments printed on average per day.
• Only about 5 % of these doctors and about 8 %
of these banks currently plan to replace dot matrix
printers. The reasons for the continued use of dot-
matrix printers are manifold: robustness, cheap de-
ployment, incompatibility of modern printers with
old hardware, and overall the lack of a compelling
business reason of IT laymen why working IT hard-
ware should be modernized.
• Several European countries
(e.g., Germany,
Switzerland, Austria, etc.) require by law the use
of dot-matrix (carbon-copy) printers for printing
prescriptions of narcotic substances [8].
1.1 Our contributions
We show that printed English text can be successfully
reconstructed from a previously taken recording of the
sound emitted by the printer. The fundamental reason
why the reconstruction of the printed text works is that,
intuitively, the emitted sound becomes louder if more
needles strike the paper at a given time (see Figure 2 for
1
DOCTORS (n=541 ASKED)
BANKS (n=524 ASKED)
Use dot-matrix printers
- for general prescriptions
- for other usages
Printer placed in proximity of patients
Replacement planned
58.4 %
79.4 %
84.5 %
72.2 %
4.7 %
Use dot-matrix printers
- for bank statement printers
- for other usages
Printer placed in proximity of customers
Replacement planned
30.0 %
29.9 %
83.4 %
83.4 %
8.3 %
Figure 1: Main results of the survey on the usage of dot-matrix printers in doctor’s practices and banks [26]. Other
printer usages reported in the survey comprise: “certiﬁcate of incapacity for work, transferal to another doctor, hos-
pitalization, and receipts” for doctors, and “account book, PIN numbers for online banking, supporting documents,
ATMs” for banks.
Overview of the approach. Our work addresses these
challenges, using a combination of machine learning
techniques for audio processing and higher-level infor-
mation about document coherence. Similar techniques
are used in language technology applications, in particu-
lar in automatic speech recognition.
First, we develop a novel feature design that borrows
from commonly used techniques for feature extraction in
speech recognition and music processing. These tech-
niques are geared towards the human ear, which is lim-
ited to approx. 20 kHz and whose sensitivity is logarith-
mic in the frequency; for printers, our experiments show
that most interesting features occur above 20 kHz, and a
logarithmic scale cannot be assumed. Our feature design
reﬂects these observations by employing a sub-band de-
composition that places emphasis on the high frequen-
cies, and spreading ﬁlter frequencies linearly over the
frequency range. We further add suitable smoothing to
make the recognition robust against measurement varia-
tions and environmental noise.
Second, we deal with the decay time and the induced
blurring by resorting to a word-based approach instead of
decoding individual letters. A word-based approach re-
quires additional upfront effort such as an extended train-
ing phase (as a word-based dictionary is larger), and it
does not permit us to increase recognition rates by us-
ing, e.g., spell-checking. Recognition of words based on
training the sound of individual letters (or pairs/triples of
letters), however, is infeasible because the sound emitted
by printers blurs too strongly over adjacent letters. (Even
words that differ considerably on the letter basis may
yield highly similar overall sound features, which com-
plicates the subsequent post-processing, see below.) This
complication was not present in earlier work on acous-
tic emanations of keyboards, since the time between two
consecutive keystrokes is always large enough that blur-
ring was not an issue [42].
Third, we employ speech recognition techniques to in-
crease the recognition rate: we use Hidden Markov Mod-
els (HMMs) that rely on the statistical frequency of se-
quences of words in English text in order to rule out in-
Figure 2: Print-head of an Epson LQ-300+II dot-matrix
printer, showing the two rows of needles.
a typical setting of 24 needles at the printhead). We ver-
iﬁed this intuition and we found that there is a correla-
tion between the number of needles and the intensity of
the acoustic emanation (see Figure 3). We ﬁrst conduct a
training phase where words from a dictionary are printed,
and characteristic sound features of these words are ex-
tracted and stored in a database. We then use the trained
characteristic features to recognize the printed English
text. (Training and recognition on a letter basis, simi-
lar to [42], seems more appealing at ﬁrst glance since it
naturally comprises the whole vocabulary. However, the
emitted sound is strongly blurred across adjacent letters,
rendering a letter-based approach much poorer than the
word-based approach, even if spell-checking is used, see
below).
This task is not trivial. Major challenges include:
(i) Identifying and extracting sound features that suit-
ably capture the acoustic emanation of dot-matrix print-
ers; (ii) Compensating for the blurred and overlapping
features that are induced by the substantial decay time of
the emanations; (iii) Identifying and eliminating wrongly
recognized words to increase the overall percentage of
correctly identiﬁed words (recognition rate).
2
learning. We applied this implementation to four differ-
ent English text documents, using a dictionary of about
1,400 words (including the 1,000 most frequently used
English words and the words that additionally occur in
these documents, see the second assumption above) and a
general-purpose corpus extracted from stable Wikipedia
articles that the HMM-based post-processing relies upon.
The prototype automatically recognizes these texts with
recognition rates of up to 72 %. To investigate the
impact of HMM-based post-processing with a domain-
speciﬁc corpus instead of a general-purpose corpus on
the recognition rate, we considered two additional docu-
ments from a privacy-sensitive domain: living-will dec-
larations. We used publicly available living-will dec-
larations to extract a specialized corpus, thereby also
increasing the dictionary to 2,150 words. Our proto-
type automatically recognized the two target declarations
with recognition rates of about 64 % using the general-
purpose corpus, and increased the recognition rates to
72 % and 95 %, respectively, using the domain-speciﬁc
corpus. This shows that, somewhat expectedly, HMM-
based post-processing is particularly worthwhile if prior
knowledge about the domain of the target document can
be assumed.
We have identiﬁed and evaluated countermeasures that
prevent this kind of attack. We found that fairly simple
countermeasures such as acoustic shielding and ensur-
ing a greater distance between the microphone and the
printer sufﬁce for most practical purposes.
Furthermore, we have successfully mounted the at-
tack in-ﬁeld in a doctor’s practice to recover the con-
tent of medical prescriptions. (For privacy reasons, we
asked for permission upfront and let the secretary print
fresh prescriptions of an artiﬁcial client.) The attack was
observer-blind and conducted under realistic – and ar-
guably even pessimistic – circumstances: during rush
hour, with many people chatting in the waiting room.
1.2 Related work
Military organizations investigated compromising ema-
nations for many years. Some of the results have been de-
classiﬁed: the Germans spied on the French ﬁeld phone
lines in World War I [6], the Japanese spied on Amer-
ican cipher machines using electromagnetic emanations
in 1962 [1], the British spied on acoustic emanation of
(mechanical) Hagelin encryption devices in the Egyptian
embassy in 1956 [39, p. 82], and the British spied on par-
asitic signals leaked by the French encryption machines
in the 1950s [39, p. 109f].
The ﬁrst publicly known attack we are aware of was
published in 1985, and exploited electromagnetic radi-
ation of CRT monitors [36, 16]. Since then, various
forms of emanations have been exploited. Electromag-
y
t
i
s
n
e
t
n
I
Needles
Figure 3: Graph showing the correlation between the
number of needles striking the ribbon and the measured
acoustic intensity.
correct word combinations. The presence of strong blur-
ring, however, requires the use of at least 3-grams on the
words of the dictionary to be effective, causing existing
implementations for this task to fail because of memory
exhaustion. To tame memory consumption, we imple-
mented a delayed computation of the transition matrix
that underlies HMMs, and in each step of the search
procedure, we adaptively removed the words with only
weakly matching features from the search space.
Experiments, underlying assumptions and limita-
tions. Before we describe our experiments, let us be
clear about the underlying assumptions that render our
approach possible.
(i) The microphone (or bug) has
to be (surreptitiously) placed in close proximity (about
10cm) of the printer. (ii) Because our approach is word-
based for the reasons described above, it will only iden-
tify words that have been previously trained; feedback-
based incremental training of additional words is pos-
sible. While this is less a concern for, e.g., recovering
general English text and medical prescriptions, it renders
the attack currently infeasible against passwords or PIN
numbers. In the bank scenario, the approach can still be
used to identify, e.g., the sender, recipient, or subject of a
transaction. (iii) Conducting the learning phase requires
access to a dot matrix printer of the same model. There is
no need to get hold of the actual printer at which the tar-
get text was printed. (iv) If HMM-based post-processing
is used, a corpus of (suitable) text documents is required
to build up the underlying language model. Such post-
processing is not always necessary, e.g., our in-ﬁeld at-
tack in a doctor’s practice described below did not exploit
HMMs to recover medical prescriptions.
We have built a prototypical implementation that can
bootstrap the recognition routine from a database of
featured words that have been trained using supervised
3
Acoustic feature extraction
Database
Signals of
training data
Split recording
Compute raw 
into words
spectrum features
Noise reduction
Features
Language 
model 
computation
(a) Training phase: extract acoustic and linguistic knowledge
Acoustic feature extraction
Unknown
attack data
Split recording
Compute raw 
into words
spectrum features
Noise reduction
Features
Select
candidate 
words
List of
words
HMM based 
reordering
Recovered
text
(b) Recognition phase: recognize printed text using acoustic and linguistic features
Figure 4: Overview of the attack.
netic emanations that constitute a security threat to com-
puter equipment result from poorly shielded RS-232 se-
rial lines [35], keyboards [2], as well as the digital cable
connecting modern LCD monitors [21]. We refer to [22]
for a discussion of the security limits for electromagnetic
emanation. The time-varying diffuse reﬂections of the
light emitted by a CRT monitor can be exploited to re-
cover the original monitor image [19]; compromising re-
ﬂections were studied in [5, 4]. Information leaking from
status LEDs was studied in [25].
Acoustic emanations were shown to divulge text typed
on ordinary keyboards [3, 42, 7], as well as information
about the CPU state and the instructions that are exe-
cuted [33]. Acoustic emanations of printers were brieﬂy
mentioned before [10]; it was solely demonstrated that
the letters “W” and “J” can be distinguished. This study
did not determine whether any other letters can be dis-
tinguished, let alone if a whole text can be reconstructed
by inspection of the recording, or even in an automated
manner.
Several techniques from audio processing are adapted
for use in our system. A central technique is feature ex-
traction. We use features based on sub-band decompo-
sition [27]. Alternative feature designs are based on the
(Short-time) Fast Fourier Transform [34], or on the Cep-
strum transformation [11] which is the basis for Mel Fre-
quency Cepstral Coefﬁcients (MFCC) [23, 15, 9, 24, 30].
1.3 Paper outline
Section 2 presents a high-level description of our new
attack, with full technical details given in Section 3. Sec-
tion 4 presents experimental results. Section 5 describes
the attack we conducted in-ﬁeld. We conclude with some
ﬁnal remarks in Section 6.
2 Attack Overview
In this section, we survey our attack without delving into
the technical details. We consider the scenario that En-
glish text containing potentially sensitive information is
printed on a dot-matrix printer, and the emitted sound is
recorded. We develop a methodology that on input the
recording automatically reproduces the printed text. Fig-
ure 4 presents a holistic overview of the attack.
The ﬁrst phase (Figure 4(a)) constitutes the training
phase that can take place either before or after the attack.
In this phase, a sequence of words from a dictionary is
printed, and characteristic sound features of each word
are extracted and stored in a database. For obtaining the
best results, the setting should be close to the setting in
which the actual attack is mounted, e.g., similar envi-
ronmental noise and acoustics. Our experiments indicate
that creating sufﬁciently good settings for reconstruction
does not pose a problem, see Section 4.3.2. The main
steps of the training phase are as follows:
1. Feature extraction. We use a novel feature design
that borrows from commonly used techniques for
feature extraction in speech recognition and mu-
sic processing. In contrast to these areas, our ex-
periments show that most interesting features for
printed sounds occur above 20 kHz, and that a log-
arithmic scale cannot be assumed for them. We
hence split the recording into single words based on
the intensity of the frequency band between 20 kHz
and 48 kHz, and spread the ﬁlter frequencies lin-