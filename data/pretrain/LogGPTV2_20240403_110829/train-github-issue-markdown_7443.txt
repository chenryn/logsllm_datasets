##### System information (version)
  * OpenCV => 3.3
  * Operating System / Platform => Ubuntu 16.10
  * Compiler => gcc 6.3
##### Detailed description
I created a DNN network in Keras, very similar to LeNet
(Conv->MaxPool->Conv->MaxPool->Conv->MaxPool->Flatten
(Reshape)->Dense->Output(2 classes, Softmax)
The last level of the network was defined in the following way:
        model.add(
            Dense(
                units = 2,
                activation="softmax")
        )
When I tried to export it to TensorFlow, Keras introduced at the last step a
`StridedSlice` operation (I don't really know why).
As this type of layer is not implemented, OpenCV throws an exception when
trying to load the _.pb_ file
Can you implement this layer type to OpenCV?  
Or is there a workaround to eliminate this layer type when creating the
network?
##### Steps to reproduce
The **.pb** final_net.zip file is attached to this report.
Python code to generate the network (very similar to
opencv/opencv_contrib#1241 )
    adam = Adam(lr = l_r)
    model = Sequential()
    #Conv2D
    model.add(
        Conv2D(
            filters = nb_filters[0],
            kernel_size = kernel_size[0],
            strides = (1,1),
            padding = "same",
            activation = "relu",
            kernel_initializer="random_normal",
            input_shape = (x_shape, y_shape,3)
            )
        )
    model.add( Dropout(drop[0]) )
    #MaxPooling2D
    model.add( MaxPooling2D( pool_size = (2,2) ) )
    model.add( Dropout(drop[1]) )
    #Conv2D
    model.add(
        Conv2D(
            filters = nb_filters[1],
            kernel_size = kernel_size[1],
            strides = (1,1),
            padding="same",
            activation="relu",
            kernel_initializer="random_normal")
        )
    model.add( Dropout(drop[2]) )
    #MaxPooling2D
    model.add( MaxPooling2D( pool_size = (2,2) ) )
    model.add( Dropout(drop[3]) )
    #Conv2D
    model.add(
        Conv2D(
            filters = nb_filters[2],
            kernel_size = kernel_size[2],
            strides = (1,1),
            padding="same",
            activation = "relu",
            kernel_initializer="random_normal")
        )
    model.add(Dropout(drop[4]) )
    #MaxPooling2D
    model.add( MaxPooling2D( pool_size = (2,2) )  )
    model.add( Dropout(drop[5]) )
    # Changed Flatten to Reshape 
    model.add( Reshape(1024,) )
    #Output 
    model.add(
        Dense(
            units = 2,
            activation="softmax")
        )
    model.compile(
        optimizer = adam,
        loss = "binary_crossentropy",
        metrics = ["accuracy"])
Code to save the network:
    sess = K.get_session()
    K.set_learning_phase(0)
    net_model = load_model(weight_file_path)
    pred = [None]*num_output
    pred_node_names = [None]*num_output
    for i in range(num_output):
        pred_node_names[i] = prefix_output_node_names_of_final_network+str(i)
        pred[i] = tf.identity(net_model.output[i], name=pred_node_names[i])
    print('output nodes names are: ', pred_node_names)
    constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph.as_graph_def(), pred_node_names)
    graph_io.write_graph(constant_graph, output_fld, output_graph_name, as_text=False)
    print('saved the constant graph (ready for inference) at:',osp.join(output_fld, output_graph_name))