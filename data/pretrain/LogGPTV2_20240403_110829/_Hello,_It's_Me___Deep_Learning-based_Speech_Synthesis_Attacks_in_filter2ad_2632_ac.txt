> AS for non-native speakers.
Table 3: Overview of content- and identity-speciﬁc attribute
experiments (and results) on Resemblyzer and Azure.
In total, our experiments consider 90 target speakers randomly
chosen from three speaker datasets (20 randomly chosen from VCTK,
20 from LibriSpeech test-clean, and 50 from SpeechAccent). For
each target T , we use their speech sample set ST as input to either
SV2TTS or AutoVC to produce fake voices of T that contain arbi-
trary speech content chosen to mimic normal conversation (listed
in Table 10 in the Appendix). Since AutoVC also requires a source
recording, we choose the source of the same gender of the target
speaker as suggested by [67]. For each test, we synthesize 10 spo-
ken phrases per target speaker.
We note that Resemblyzer requires a threshold to detect whether
two speech embeddings are from the same speaker. We conﬁgure
this threshold by ﬁrst enrolling the target speakers in Resemblyzer
using their real speech samples, then computing their embeddings
and choosing the threshold that minimizes Resemblyzer’s equal er-
ror rate (EER) on these speakers, using cosine similarity as the dis-
tance metric. When launching a synthesis attack, the attack is con-
sidered successful if the similarity between the attack and enrolled
embeddings is above the threshold. For each attack, we repeat the
enrollment process 10 times (using diﬀerent speech samples) and
report the average attack success rate and standard deviation.
In total, we test 13,000 synthesized speech instances tar-
Results.
geting 90 speakers on Resemblyzer. The results show that SV2TTS
based attack is highly eﬀective against Resemblyzer, while AutoVC
is ineﬀective. The size and quality of ST , the speaker gender and
accent do impact the attack success rate, but the phonetic similarity
has minimum impact. Next we report these results in more detail.
1) A(cid:31)ack success rate under the default se(cid:31)ing: We start
from “ideal” cases where the attacker targets native English speak-
ers with US or British accents, and has plenty of high-quality speech
samples per target. For this we consider target speakers from VCTK
and LibriSpeech, and conﬁgure ST to include N = 10 utterances
per target. As such, ST includes 30-120 seconds of clean audio,
far more than the amount required to run zero-shot synthesis as
claimed by [41, 67] (roughly 20 seconds). We hereby refer to N as
the number of target speech samples.
Session 1D: Authentication and Click Fraud CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea239Synthesis System
SV2TTS
AutoVC
Dataset
Attack Success
VCTK
LibriSpeech
50.5 ± 13.4% 100 ± 0.0%
VCTK
8.0 ± 5.9%
LibriSpeech
0.0 ± 0.0%
(a) Target speakers are native English speakers (N =10)
100
50
)
%
(
s
s
e
c
c
u
S
k
c
a
t
t
A
SV2TTS, LibriSpeech
SV2TTS, VCTK
AutoVC, VCTK
AutoVC, LibriSpeech
 0
 10
 20
 30
 40
Number of Target Speech Samples
(b) Impact of target speech sample size N
Dataset
Speaker Gender
Attack Success
VCTK
LibriSpeech
Male
Female
Male
Female
43.3 ± 16.1% 61.8 ± 9.4% 100.0 ± 0.0% 100.0 ± 0.0%
(c) Impact of target speaker’s gender (SV2TTS, N =10)
Figure 2: Attack success rate when testing DNN-based syn-
thesize attacks against Resemblyzer.
As shown in Figure 2a, fake speech synthesized by SV2TTS suc-
cessfully fools Resemblyzer, while AutoVC fails. We think that the
success of SV2TTS (particularly on LibriSpeech) is likely because
Resemblyer is trained using the same loss function used by SV2TTS’
speaker encoder [89].
2) Impact of ST size: We repeat the above experiment but vary
the size of target speech samples, i.e., N =1, 5, 10, 20, 30, 40 speech
samples. As Figure 2b shows, the attack success rate for SV2TTS
grows with N but levels oﬀ before N reaches 10. For AutoVC, the
attack remains ineﬀective when varying N .
3) Impact of ST quality: This question has bearing on real-
world attack settings, since an attacker might not always obtain
high-quality audio recordings of the target. To emulate low-quality
data, we add four diﬀerent levels of zero-mean Gaussian noise to
the original clean audio. We vary the signal-to-noise ratio from 4
dB (noise quieter than the speaker’s voice) to −15 dB (noise louder
than the speaker’s voice). We ﬁnd that noisy target speech samples
decimate synthesis attack performance. For both SV2TTS and Au-
toVC, the attack success rate reduces to 0% at all four noise levels.
4) Impact of phonetic similarity between ST and SA: This
factor also has strong real-world implications – if the content simi-
larity aﬀects the attack success rate, the attacker may be largely
constrained by which ST they obtain. Since SV2TTS generates
synthesized speech from arbitrary text, we use it to explore this
question. Details of our experiments are in the Appendix.
Interestingly, we ﬁnd that phoneme similarity of ST and SA
does not have any visible eﬀect – the attack success rate remains
stable as we vary the normalized phoneme similarity from 0 to 1.
5) Impact of target gender: We now consider a target’s per-
sonal attributes which may aﬀect the attack outcome. The ﬁrst is
speaker gender, which can come into play if, for example, synthe-
sis or SR models lack suﬃcient gender diversity. To study this fac-
tor, we separate the results of our SV2TTS experiments by gen-
der. We ﬁnd that synthesized female speakers have higher AS on
average than male speakers (Figure 2c). When we test clean (non-
synthesized) speech from these target speakers on Resemblyzer,
the SR accuracy is 100% for both male and female speakers.
6) Impact of target accent: Most public speech datasets con-
sist of native English speakers with US or UK accents (i.e. VCTK,
LibriSpeech, VoxCeleb 1/2). Speech synthesis systems trained on
these datasets may fail to recreate the unique prosody of speakers
with diﬀerent accents. To test this, we choose 50 target speakers
from the SpeechAccent dataset, including male/female native Eng-
lish speakers and male/female native speakers from the top 21 most
spoken languages.
When comparing results from native/non-native English speak-
ers, we observe a higher attack success rate among native English
speakers (100%) compared to non-native English speakers (65%) for
synthesized speech produced by SV2TTS. As before, attacks using
synthesized speech from AutoVC are unsuccessful.
4.3 Azure (Open API, Real-World SR)
We run the same experiments of §4.2 on Azure, a real-world SR
deployment. Azure’s open API allows us to enroll speakers and run
numerous tests against their enrolled speaker proﬁles. But unlike
§4.2, there is no need to conﬁgure any threshold. We enroll each of
our 90 target speakers from 4.2 into Azure and use these enrolled
proﬁles for all tests. We generate and test 10 synthesized phrases
(as in 4.2) per target for each experiment. Since Azure reports the
SR acceptance result per sample, we report the average success rate
of all synthesized samples in each experiment.
Disclosure. We followed standard disclosure practices and re-
ported the result of DNN-synthesized speech attacks to Microsoft.
Results. We test 13,000 synthesized speech instances targeting
90 speakers on Azure. These results show that Azure is also vul-
nerable to DNN-synthesized speech. Our ﬁndings on the impact
of various factors mirror those from Resemblyzer.
1) A(cid:31)ack success rate under default se(cid:31)ings: Figure 3a lists
the overall attack success rate. We see that DNN-synthesized speech
can easily fool Azure, although the attack success rate is less than
those with Resemblyzer. Interestingly, for 62.5% of target speak-
ers, at least 1 out of 10 synthesized phrases (generated by SV2TTS)
was accepted by Azure as the target speaker. Thus a persistent at-
tacker could make multiple attempts to eventually fool Azure API
(assuming there is no limit on authentication attempts).
Another interesting ﬁnding is that the attack success rate dis-
plays signiﬁcantly higher variance than those observed on Resem-
blyzer. This is particularly visible for SV2TTS. When we dig deeper
to understand this high variance, we ﬁnd that for the above men-
tioned 62.5% targets (with at least 1 success attack instance out
of 10 trials), the attack success rate was 49.2 ± 23.5% for VCTK
speakers and 33.1 ± 21.4% for LibriSpeech speakers. These results
indicate that the attack performance against Azure is non-uniform
across target speakers.
2) Impact of ST size, quality, and phonetic similarity of
ST and SA: Our results from these experiments mirror those of
Resemblyzer: Figure 3b shows that the attack performance levels
oﬀ when N reaches 10; none of the speech synthesized from noisy
versions of ST was accepted by Azure; and the phonetic similarity
of ST and SA does not aﬀect the attack outcome.
Session 1D: Authentication and Click Fraud CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea240Synthesis System
Speaker Source
Attack Success
SV2TTS
AutoVC
VCTK
LibriSpeech
VCTK
29.5 ± 32.0% 21.5 ± 23.5% 14.5 ± 34.1%
LibriSpeech
0.0 ± 0.0%
(a) When target speakers are native English speakers (N =10)
100
50
)
%
(
s
s
e
c
c
u
S
k
c
a
t
t
A
SV2TTS, LibriSpeech
SV2TTS, VCTK
AutoVC, VCTK
AutoVC, LibriSpeech
 0
 10
 20
 30
 40
Number of Target Speech Samples
(b) Impact of target speech sample size N (σ omitted for clarity).
Speaker Source
Speaker Gender
Attack Success
VCTK
LibriSpeech
Male
Female
Male
Female
7.8 ± 13.9% 47.3 ± 32.0% 14.0 ± 22.2% 29.0 ± 23.3%
(c) Impact of target speaker’s gender (SV2TTS, N =10)
Figure 3: Attack success rate when testing DNN-based syn-
thesize attacks against Azure.
3) Impact of target gender: We observe a signiﬁcant diﬀerence
in the attack success rate for male and female targets enrolled in
Azure. Figure 3c reports the results using SV2TTS, where attacks
targeting female speakers are much more eﬀective. Similar trends
are observed on AutoVC (VCTK). Again, when we test Azure with
clean (non-synthesized) speech of our target speakers, the SR ac-
curacy is 100% for both male and female speakers.
4) Impact of target accent: We ﬁnd that SV2TTS-synthesized
samples for SpeechAccent speakers lead to an attack success rate
of 8.8 ± 14.5%. Among them, the attack success rate is 15.0 ± 16.9%
for native English speakers but drops to 7.5 ± 13.9% for non-native
English speakers with accents.
4.4 WeChat and Amazon Alexa (Closed API,
Real-World SR)
Finally, we experiment with two additional real-world SR systems:
WeChat and Amazon Alexa. In contrast to Azure, both employ
closed-API SR, largely limiting our experimental bandwidth. Since
WeChat and Alexa’s SR systems link to individual accounts, we
must test synthesis attacks with real users. Note that our goal is
not to test the (in)security of WeChat or Alexa platforms, but to
use them as case studies of deployed SR systems to illustrate the
potential impact of DNN-based speech synthesis attacks.
Experimental Setup. We conduct an IRB-approved user study
to evaluate synthetic speech attacks (IRB information omitted for
anonymity). Speciﬁcally, we collect speech samples from study par-
ticipants, synthesize speech imitating each participant, and give
these speech samples to each participant to test their WeChat and
Amazon Alexa apps. Given the poor performance of AutoVC on Re-
sembylzer and Azure, we only use SV2TTS for these experiments.
We recruited 14 participants with diﬀerent linguistic background
(1 native Marathi speaker; 1 native Dutch speaker; 3 native Man-
darin speakers; 9 native English speakers) and gender (10 female/4
male). All participants signed written consent forms to participate
in our user study and were compensated $10 for their time. We
asked our participants to submit a small set of their voice record-
ings. Each participant used a voice memo recording app to record
themselves speaking 20 sentences in English from the Rainbow
Passage. The Rainbow Passage is commonly used in linguistic stud-
ies because it contains most of the phoneme combinations in the
English language [30] (the full passage is in the Appendix). In this
study, 7 participants recorded on a Macbook Pro, 4 recorded on an
iPhone 11+ phone, and 1 recorded on a Google Pixel phone.
For each participant T , we use their submitted speech record-
ings as the target speech sample set ST , and input them to SV2TTS
to generate synthetic speech imitating T . The content of the syn-
thetic speech SA is designed to match the context of the SR system,
which we describe below (also see Table 4).
• WeChat uses a text-dependent speaker veriﬁcation system that
asks for stating the same eight-digit login number for each SR
attempt. Each participant consented to share their unique lo-
gin number with our user study administrators, and these were
used to generate synthesized login speech samples. To ensure
participant privacy and security, login numbers were password-
protected, anonymized, and deleted when the study ended. For