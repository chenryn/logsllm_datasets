in the same ciphertext. We will then use the cipher-
texts, properly encoded into a character set allowed by
the SS, as the directory names requested in calls to, e.g.,
SScreate. We note that the choice of encoding as well
as the ciphertext stretch τd mean that the maximum ﬁle-
name length supported by DupLESS will be shorter than
that of the SS. Should this approach prove limiting, an
alternative approach would be to use format-preserving
encryption [21] instead to reduce ciphertext expansion.
All this means that we will be able to search for ﬁle
and directory names and have efﬁcient ﬁle copy and
move operations. That said, this approach does leak the
structure of the plaintext directory hierarchy, the lengths
of individual directory and ﬁle names, and whether two
ﬁles have the same name. While length leakage can be
addressed with padding mechanisms at a modest cost on
storage overhead, hierarchy leakage cannot be addressed
without adversely affecting some operations.
Store requests. To store a ﬁle with ﬁlename F and con-
tents M at path P, the DupLESS client ﬁrst executes the
client portion of the KS protocol (see Section 5). The re-
sult is either a message-derived key K or an error mes-
sage ⊥. The client then runs a check canDedup to
determine whether to use dedupable encryption or non-
dedupable encryption. If K = ⊥ or canDedup returns
false, then a random key is selected and will be used in
place of a message-derived key. In this case the resulting
ciphertext will not be dedupable. We discuss canDedup
more below. The client next encrypts M under K with
CTR[AES] and a ﬁxed IV to produce ciphertext Cdata,
and then wraps K using SIV to produce ciphertext Ckey.
We include the ﬁlename ciphertext Cname and Cdata in or-
der to cryptographically bind together the three cipher-
texts. The client uploads to the SS via the SSput com-
mand the ﬁle “Cname.key” with contents Ckey and Cdata
in ﬁle “Cname.data”. DupLESS encodes the ciphertexts
into character sets allowed by the SS API. Both ﬁles are
uploaded in parallel to the SS. Usually, the SS might re-
quire the client to be authorized, and if this is the case,
the authorization can be handled when the client starts.
The “.data” ﬁle contains only ciphertext Cdata, and can
be deduplicated by the SS assuming K was not replaced
by a random value. The “.key” ﬁle cannot be dedu-
plicated, its contents being essentially uniformly dis-
tributed, but requires only a ﬁxed, small number of bits
equal to k + τd. With our instantiation choices, this is
384 bits, and does not lead to signiﬁcant overheads as
we show in Section 7.
USENIX Association  
22nd USENIX Security Symposium  187
9
(P, F, M)
DLputKdae,Kae,pkks
K $← EvCEvS
Cpath,Cname ← EncPath(Kdae, P, F )
If canDedup(P, F, M) =false then
(pkks, M)
Cdata ← EA(Kae,Cname, M)
SSput(Cpath , Cname  “.data” , Cdata)
Else
If K = ⊥ then K $← {0, 1}k
Cdata ← E(K, M)
Ckey ← ED(Kdae, 1 Cname Cdata, K)
SSput(Cpath , Cname  “.key” , Ckey)
SSput(Cpath , Cname  “.data” , Cdata)
(P, F )
DLgetKdae,Kae
Cpath,Cname ← EncPath(Kdae, P, F )
Cdata ← SSget(Cpath , Cname  “.data”)
Ckey ← SSget(Cpath , Cname  “.key”)
If Ckey = ⊥ then
Return DA(Kae,Cname,Cdata)
Else
K ← DD(Kdae, 1 Cname Cdata,Ckey)
If K = ⊥ then
Ret ⊥
Else
Ret D(K,Cdata)
Figure 6: DupLESS client procedures for storage and retrieval. They use our server-aided MLE scheme DupLESSMLE =
(P, K, E, D), built with RSA-OPRF[G, H] = (Kg, EvC, EvS, Vf, Ev) along with the DAE scheme SIV = (ED, DD), and the AE
scheme EtM = (EA, DA). Instantiations are as described in text. The subroutine canDedup runs dedup heuristics while EncPath
encrypts the path and ﬁle name using SIV.
Dedupability control. The canDedup subroutine en-
ables ﬁne-grained control over which ﬁles end up get-
ting deduplicated, letting clients enforce polices such as
not deduplicating anything in a personal folder, and set-
ting a lower threshold on size. Our current implementa-
tion uses a simple length heuristic: ﬁles less than 1 KB
in size are not deduplicated. As our experiments show
in Section 7, employing this heuristic does not appear to
signiﬁcantly degrade storage savings.
By default, DLput ensures that ciphertexts are of the
same format regardless of the output of canDedup.
However, should canDedup mark ﬁles non-dedupable
based only on public information (such as ﬁle length),
then we can further optimize performance by produc-
ing only a single ciphertext ﬁle (i.e. no Ckey) using an
authenticated-encryption scheme with a key Kae derived
from the client’s secret key. We use AES in CTR mode
with random IVs with HMAC in an Encrypt-then-MAC
scheme. This provides a slight improvement in storage
savings over non-deduped ciphertexts and requires just
a single SSput call. We can also query the KS only if
needed, which is more efﬁcient.
When canDedup’s output depends on private infor-
mation (e.g., ﬁle contents), clients should always interact
with the KS. Otherwise there exists a side channel attack
in which a network adversary infers from the lack of a
KS query the outcome of canDedup.
Retrieval and other commands. The pseudocode for re-
trieval is given in Figure 6. It uses EncPath to recom-
pute the encryptions of the paths and ﬁlenames, and then
issues SSget calls to retrieve both Ckey and Cdata. It then
proceeds by decrypting Ckey, recovering K, and then us-
ing it to decrypt the ﬁle contents. If non-dedupable en-
cryption was used and Ckey was not uploaded, the second
SSget call fails and the client decrypts accordingly.
Other commands are implemented in natural ways,
and we omit pseudocode for the sake of brevity. Dup-
LESS includes listing the contents of a directory (per-
form an SSlist on the directory and decrypt the paths
and ﬁlenames); moving the contents of one directory to
another (perform an SSmove command with encrypted
path names); search by relative path and ﬁlename (per-
form an SSsearch using the encryptions of the relative
path and ﬁlename); create a directory (encrypt the direc-
tory name and then use SScreate); and delete (encrypt
the path and ﬁlename and perform a delete on that).
The operations are, by design, simple and whenever
possible, one-to-one with underlying SS API commands.
The security guarantees of SIV mean that an attacker
with access to the SS cannot tamper with stored data. An
SS-based attacker could, however, delete ﬁles or modify
the hierarchy structure. While we view these attacks as
out of scope, we note that it is easy to add directory hi-
erarchy integrity to DupLESS by having EncPath bind
ciphertexts for a directory or ﬁle to its parent: just in-
clude the parent ciphertext in the associated data during
encryption. The cost, however, is that ﬁlename search
can only be performed on full paths.
In DupLESS, only DLput requires interaction with the
KS, meaning that even if the KS goes down ﬁles are
never lost. Even DLput will simply proceed with a ran-
dom key instead of the message-derived key from the
KS. The only penalty in this case is loss of the storage
savings due to deduplication.
Other APIs. The interface in Figure 5 is based on the
Dropbox API [39]. Google Drive [7] differs by index-
ing ﬁles based on unique IDs instead of names. When a
ﬁle is uploaded, SSput returns a ﬁle ID, which should be
188  22nd USENIX Security Symposium 
USENIX Association
10
provided to SSget to retrieve the ﬁle. The SSlist func-
tion returns a mapping between the ﬁle names and their
IDs. In this case, DupLESS maintains a local map by
prefetching and caching ﬁle IDs by calling SSlist when-
ever appropriate; this caching reduces DLget latency.
When a ﬁle is uploaded, the encrypted ﬁlename and re-
turned ID are added to this map. Whenever a local map
lookup fails, the client runs SSlist again to check for an
update. Hence, the client can start without any local state
and dynamically generate the local map.
Supporting keyword search in DupLESS requires ad-
ditional techniques, such as an encrypted keyword index
as in searchable symmetric encryption [34], increasing
storage overheads. We leave exploring the addition of
keyword search to future work.
7
Implementation and Performance
We implemented a fully functional DupLESS client. The
client was written in Python and supports both Drop-
box [3] and Google Drive [7]. It will be straightforward
to extend the client to work with other services which
export an API similar to Figure 5. The client uses two
threads during store operations in order to parallelize the
two SS API requests. The client takes user credentials
as inputs during startup and provides a command line
interface for the user to type in commands and argu-
ments. When using Google Drive, a user changing di-
rectory prompts the client to fetch the ﬁle list ID map
asynchronously. We used Python’s SSL and Crypto li-
braries for the client-side crypto operations and used the
OPRFv2 KS protocol.
We now describe the experiments we ran to mea-
sure the performance and overheads of DupLESS. We
will compare both to direct use of the underlying SS
API (no encryption) as well as when using a version
of DupLESS modiﬁed to implement just MLE, in par-
ticular the convergent encryption (CE) scheme, instead
of DupLESSMLE. This variant computes the message-
derived key K by hashing the ﬁle contents, thereby avoid-
ing use of the KS. Otherwise the operations are the same.
Test setting and methodology. We used the same ma-
chine as for the KS tests (Section 5). Measurements in-
volving the network were repeated 100 times and other
measurements were repeated 1,000 times. We measured
running times using the timeit Python module. Opera-
tions involving ﬁles were repeated using ﬁles with ran-
dom contents of size 22i KB for i ∈ {0, 1, . . . , 8}, giving
us a ﬁle size range of 1 KB to 64 MB.
Dropbox exhibited signiﬁcant performance variability
in the course of our experiments. For example, the me-
dian time to upload a 1 KB ﬁle was 0.92 seconds, while
the maximum observed was 2.64 seconds, with standard
deviation at 0.22 seconds. That is close to 25% of the
median. Standard deviation decreases as the ﬁle size
increases, for example it is only 2% of the median up-
load time for 32 MB ﬁles. We never observed more than
1 Mbps throughput to Dropbox. Google Drive exhibited
even slower speeds and more variance.
Storage and retrieval latency. We now compare the time
to store and retrieve ﬁles using DupLESS, CE, and the
plain SS. Figure 7 (top left chart) reports the median time
for storage using Dropbox. The latency overhead when
storing ﬁles with DupLESS starts at about 22% for 1 KB
ﬁles and reduces to about 11% for 64 MB ﬁles.
As we mentioned earlier, Dropbox and Google Drive
exhibited signiﬁcant variation in overall upload and
download times. To reduce the effect of these variations
on the observed relative performance between DupLESS
over the SS, CE over the SS and plain SS, we ran the
tests by cycling between the three settings to store the
same ﬁle, in quick succession, as opposed to, say, run-
ning all plain Dropbox tests ﬁrst. We adopted a similar
approach with Google Drive.
We observe that the CE (Convergent Encryption) store
times are close to DupLESS store times, since the
KSReq step, which is the main overhead of DupLESS
w.r.t CE, has been optimized for low latency. For ex-
ample, median CE latency overhead for 1 KB ﬁles over
Dropbox was 15%. Put differently, the overhead of mov-
ing to DupLESS from using CE is quite small, compared
to that of using CE over the base system.
Relative retrieval latencies (bottom left, Figure 7) for
DupLESS over Dropbox were lower than the store laten-
cies, starting at about 7% for 1 KB ﬁles and reducing to
about 6% for 64 MB ﬁles.
Performance with Google Drive (Figure 7, top middle
chart) follows a similar trend, with overhead for Dup-
LESS ranging from 33% to 8% for storage, and 40% to
10% for retrieval, when ﬁle sizes go from 1 KB to 64 MB.
These experiments report data only for ﬁles larger
than 1 KB, as smaller ﬁles are not selected for dedu-
plication by canDedup. Such ﬁles are encrypted with
non-dedupable, randomized encryption and latency over-
heads for storage and retrieval in these cases are negligi-
ble in most cases.
Microbenchmarks. We ran microbenchmarks on DLput
storing 1MB ﬁles, to get a breakdown of the overhead.
We report median values over 100 trials here. Up-
loading a 1 MB ﬁle with Dropbox takes 2700 millisec-
onds (ms), while time for the whole DLput operation
is 3160 ms, with a 17% overhead. The KSReq latency,
from Section 5, is 82 ms or 3%. We measured the total
time for all DLput steps except the two SSput operations
(refer to Figure 6) to be 135 ms, and uploading the con-
tent ﬁle on top of this took 2837 ms. Then, net overhead
USENIX Association  
22nd USENIX Security Symposium  189
11
s
d
n
o
c
e
s
i
l
l
i
m
n
i
e
m
T
i
s
d
n
o
c
e
s
i
l
l
i
m
n
i
e
m
T
i
216
214
212
210
28
20
214
212
210
28
20
DupLESS
Convergent Encryption
Dropbox
24
28
212
216
DupLESS
Dropbox
24
28
212
216
File size (KB)
216