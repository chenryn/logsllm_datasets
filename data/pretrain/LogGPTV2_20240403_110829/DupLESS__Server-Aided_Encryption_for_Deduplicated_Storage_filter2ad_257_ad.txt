### Optimized Text

#### Ciphertext and Directory Names
In the same ciphertext, we will use properly encoded ciphertexts, adhering to the character set allowed by the Storage Service (SS), as directory names in calls to functions like `SScreate`. The choice of encoding and the ciphertext stretch \(\tau_d\) imply that the maximum filename length supported by DupLESS will be shorter than that of the SS. If this approach proves limiting, an alternative would be to use format-preserving encryption [21] to reduce ciphertext expansion.

This method allows for efficient file and directory name searches, as well as copy and move operations. However, it does leak the structure of the plaintext directory hierarchy, the lengths of individual directory and file names, and whether two files have the same name. While length leakage can be mitigated with padding mechanisms at a modest storage overhead, hierarchy leakage cannot be addressed without adversely affecting some operations.

#### Store Requests
To store a file with filename \(F\) and contents \(M\) at path \(P\), the DupLESS client first executes the client portion of the Key Server (KS) protocol (see Section 5). The result is either a message-derived key \(K\) or an error message \(\bot\). The client then runs a `canDedup` check to determine whether to use dedupable or non-dedupable encryption. If \(K = \bot\) or `canDedup` returns false, a random key is selected and used in place of the message-derived key, resulting in a non-dedupable ciphertext. We will discuss `canDedup` further below.

The client encrypts \(M\) under \(K\) using CTR[AES] with a fixed IV to produce ciphertext \(C_{data}\), and wraps \(K\) using SIV to produce ciphertext \(C_{key}\). To cryptographically bind the three ciphertexts, the client includes the filename ciphertext \(C_{name}\) and \(C_{data}\). The client uploads the file "Cname.key" with contents \(C_{key}\) and \(C_{data}\) in the file "Cname.data" to the SS via the `SSput` command. DupLESS encodes the ciphertexts into character sets allowed by the SS API, and both files are uploaded in parallel. Typically, the SS requires client authorization, which is handled when the client starts.

The ".data" file contains only ciphertext \(C_{data}\) and can be deduplicated by the SS if \(K\) was not replaced by a random value. The ".key" file, containing essentially uniformly distributed data, cannot be deduplicated but requires only a fixed, small number of bits equal to \(k + \tau_d\). With our instantiation choices, this is 384 bits, leading to minimal overhead as shown in Section 7.

#### Dedupability Control
The `canDedup` subroutine enables fine-grained control over which files get deduplicated, allowing clients to enforce policies such as not deduplicating anything in a personal folder or setting a lower size threshold. Our current implementation uses a simple length heuristic: files less than 1 KB in size are not deduplicated. As our experiments in Section 7 show, this heuristic does not significantly degrade storage savings.

By default, `DLput` ensures that ciphertexts are of the same format regardless of the `canDedup` output. If `canDedup` marks files non-dedupable based on public information (e.g., file length), performance can be optimized by producing only a single ciphertext file (i.e., no \(C_{key}\)) using an authenticated-encryption scheme with a key \(K_{ae}\) derived from the client’s secret key. We use AES in CTR mode with random IVs and HMAC in an Encrypt-then-MAC scheme. This provides a slight improvement in storage savings and requires just a single `SSput` call. We can also query the KS only if needed, which is more efficient.

If `canDedup`'s output depends on private information (e.g., file contents), clients should always interact with the KS. Otherwise, there exists a side channel attack where a network adversary infers the outcome of `canDedup` from the lack of a KS query.

#### Retrieval and Other Commands
The pseudocode for retrieval is given in Figure 6. It uses `EncPath` to recompute the encryptions of the paths and filenames, and then issues `SSget` calls to retrieve both \(C_{key}\) and \(C_{data}\). The client then decrypts \(C_{key}\), recovers \(K\), and uses it to decrypt the file contents. If non-dedupable encryption was used and \(C_{key}\) was not uploaded, the second `SSget` call fails, and the client decrypts accordingly.

Other commands are implemented in natural ways, and we omit pseudocode for brevity. DupLESS includes:
- Listing the contents of a directory (perform an `SSlist` on the directory and decrypt the paths and filenames).
- Moving the contents of one directory to another (perform an `SSmove` command with encrypted path names).
- Searching by relative path and filename (perform an `SSsearch` using the encryptions of the relative path and filename).
- Creating a directory (encrypt the directory name and use `SScreate`).
- Deleting (encrypt the path and filename and perform a delete).

These operations are designed to be simple and, whenever possible, one-to-one with underlying SS API commands. The security guarantees of SIV mean that an attacker with access to the SS cannot tamper with stored data. An SS-based attacker could, however, delete files or modify the hierarchy structure. While these attacks are out of scope, it is easy to add directory hierarchy integrity to DupLESS by binding ciphertexts for a directory or file to its parent during encryption. The cost is that filename search can only be performed on full paths.

In DupLESS, only `DLput` requires interaction with the KS, meaning that even if the KS goes down, files are never lost. `DLput` will simply proceed with a random key instead of the message-derived key from the KS, with the only penalty being the loss of storage savings due to deduplication.

#### Other APIs
The interface in Figure 5 is based on the Dropbox API [39]. Google Drive [7] differs by indexing files based on unique IDs instead of names. When a file is uploaded, `SSput` returns a file ID, which should be provided to `SSget` to retrieve the file. The `SSlist` function returns a mapping between the file names and their IDs. In this case, DupLESS maintains a local map by prefetching and caching file IDs by calling `SSlist` whenever appropriate; this caching reduces `DLget` latency. When a file is uploaded, the encrypted filename and returned ID are added to this map. Whenever a local map lookup fails, the client runs `SSlist` again to check for an update. Hence, the client can start without any local state and dynamically generate the local map.

Supporting keyword search in DupLESS requires additional techniques, such as an encrypted keyword index as in searchable symmetric encryption [34], increasing storage overheads. We leave exploring the addition of keyword search to future work.

### Implementation and Performance
We implemented a fully functional DupLESS client in Python, supporting both Dropbox [3] and Google Drive [7]. It will be straightforward to extend the client to work with other services that export an API similar to Figure 5. The client uses two threads during store operations to parallelize the two SS API requests. The client takes user credentials as inputs during startup and provides a command-line interface for the user to type in commands and arguments. When using Google Drive, a user changing directory prompts the client to fetch the file list ID map asynchronously. We used Python’s SSL and Crypto libraries for client-side crypto operations and the OPRFv2 KS protocol.

#### Experiments
We ran experiments to measure the performance and overheads of DupLESS, comparing them to direct use of the underlying SS API (no encryption) and a version of DupLESS modified to implement just MLE, specifically the convergent encryption (CE) scheme. This variant computes the message-derived key \(K\) by hashing the file contents, avoiding the KS. Otherwise, the operations are the same.

**Test Setting and Methodology:**
- We used the same machine for the KS tests (Section 5).
- Network measurements were repeated 100 times, and other measurements were repeated 1,000 times.
- Running times were measured using the `timeit` Python module.
- File operations were repeated using files with random contents of size \(2^{2i}\) KB for \(i \in \{0, 1, \ldots, 8\}\), giving a file size range of 1 KB to 64 MB.

**Performance Variability:**
- Dropbox exhibited significant performance variability. For example, the median time to upload a 1 KB file was 0.92 seconds, with a maximum of 2.64 seconds and a standard deviation of 0.22 seconds (close to 25% of the median). Standard deviation decreases with file size, e.g., it is only 2% of the median upload time for 32 MB files. We never observed more than 1 Mbps throughput to Dropbox.
- Google Drive exhibited even slower speeds and more variance.

**Storage and Retrieval Latency:**
- **Dropbox:** The median time for storage using DupLESS starts at about 22% for 1 KB files and reduces to about 11% for 64 MB files. CE store times are close to DupLESS store times, with a median CE latency overhead for 1 KB files of 15%. Relative retrieval latencies for DupLESS over Dropbox start at about 7% for 1 KB files and reduce to about 6% for 64 MB files.
- **Google Drive:** Overhead for DupLESS ranges from 33% to 8% for storage and 40% to 10% for retrieval, when file sizes go from 1 KB to 64 MB. These experiments report data only for files larger than 1 KB, as smaller files are not selected for deduplication by `canDedup`.

**Microbenchmarks:**
- We ran microbenchmarks on `DLput` storing 1 MB files to get a breakdown of the overhead. Uploading a 1 MB file with Dropbox takes 2700 milliseconds (ms), while the total `DLput` operation time is 3160 ms, with a 17% overhead. The `KSReq` latency is 82 ms or 3%. The total time for all `DLput` steps except the two `SSput` operations (refer to Figure 6) is 135 ms, and uploading the content file on top of this took 2837 ms. The net overhead is 17%.

### Conclusion
DupLESS provides a secure and efficient way to store and manage files in cloud storage services, with minimal overhead and robust deduplication capabilities. Future work will explore additional features such as keyword search and further optimizations.