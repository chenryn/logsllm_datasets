speak of “clients” and “tallyers” although the two functions
may occur on the same machines. Each user is assumed to
own a client, so there are n clients. A tallyer computes a
total of client data (transformed from client ratings). For
simplicity, we will assume there are n tallyers which is the
least structured (fully peer-to-peer) case. We assume that
a fraction α > 0.5 of clients are tallyers are trustworthy,
in the sense of correctly following the protocols. However,
no-one is considered trustworthy enough to see unencrypted
user data.
Collaborative ﬁltering methods generally use weighted
combinations of nearest neighbor votes to extrapolate from
a user’s preferences. Call these methods “neighborhood
Proceedings of the 2002 IEEE Symposium on Security and Privacy (S&P(cid:146)02) 
1081-6011/02 $17.00 ' 2002 IEEE 
3
methods”. Neighborhood methods ignore global relation-
ships between user preferences. In fact global linear rela-
tionships between user ratings do exist and were used in the
“eigentaste” algorithm by Goldberg et. al. [6]. The eigen-
taste method is still a neighborhood method, but it uses pro-
jections of actual user ratings into a low-dimensional space.
This space is computed with a singular-value decomposi-
tion of the ratings matrix. Goldberg showed that this projec-
tion before neighbor matching improves performance, and
describes the linear basis vectors as “eigentastes”.
This suggests that rating prediction might be done us-
ing only a global linear approximation to the ratings set.
In practice we have found that this works quite well. On
tests with the “Eachmovie” database, the ratings from the
linear model are as good as the best current algorithms. In
a later section we compare it with neighborhood methods
using surveys from Herlocher [7] and Breese et. al. [2].
We construct the k-dimensional linear space A that
best approximates the user preference matrix P in a
least-squares sense. Assume A is represented as a row-
k×m. Now k ≤ m where m the
orthonormal matrix A ∈ R
number of data items, and the orthonormality condition im-
plies that AAT = I. The projection of P onto A is P AT A.
The residual modeling error is E = P − P AT A and we
want to minimize the sum of squares of the components of
this error matrix, which is e = tr(EET ). This simpliﬁes to
e = tr(P P T ) − tr(P AT AP T ) and the minimum error is
obtained when tr(P AT AP T ) is maximized. The optimiza-
tion problem is then to ﬁnd A such that
A =
sup
tr(P U T U P T )
U : U U T =I
This optimization uses a conjugate gradient scheme which
is discussed in detail in Appendix I. In fact we show that as
well as A, we can obtain a partial singular value decompo-
sition (SVD) of P using encrypted computation. Our algo-
rithm is a straightforward application of the conjugate gra-
dient method, although there is a non-trivial change of basis
at each step. There are more efﬁcient ways to compute an
SVD, but our goal is to compute it in a reasonable amount of
time using a cryptographic homomorphism. The conjugate
gradient scheme allows us to reduce the calculation to series
of vector additions of user data. In practice its convergence
is fast, taking 40-60 iterations on typical data.
2.1 Generating Recommendations
never rated. Underlying our linear approximation is a prob-
abilistic latent variable model. We assume that each user i
has a static preference (row) vector xi ∈ R
k. Let D and V
be the matrices derived from the SVD of P as described in
appendix I. Then each user’s ratings vector is given by
Pi = c1xi(DV T ) + ni
where ni ∈ R
m is a “noise” random vector and c1 is a
constant. Both xi and ni are assumed to have gaussian dis-
tributions. The probability density of a given pair (xi, ni)
is given by
c2exp(−|xi|2/(2σ2
x))exp(−|ni|2/(2σ2
x))
Given a vector of user preferences Pi, the most likely pair
(xi, ni) is the pair that minimizes
|xi|2/(2σ2
x) + |ni|2/(2σ2
n)
where ni = Pi − c1(xT
mization over xi. The solution is easily shown to be
i (DV T )) which is a quadratic mini-
xi = PiBT (I + BBT )−1
(cid:1)
where B is the restriction of c1DV T to the columns con-
taining known preferences for user i. The constant c1 is
k|D|2, and σn can be estimated from the
given by σn
dataset. Given xi, the estimate of the user’s preferences for
other data items is given by c1xi(DV T ).
2.2 Updating the Aggregate
The numerical method for updating the aggregate is de-
rived in appendix I. It is an iterative conjugate-gradient al-
gorithm, using the Polak-Ribiere recurrence [11]. There are
two phases to each iteration. First each user ﬁrst computes
their contribution to the gradient of A, which is
i Pi(I − AT A)
Gi = AP T
(1)
where Pi is the vector of preferences for the ith user, and A
is the aggregate from the previous iteration. Then all users
add their gradient contributions using the protocol discussed
in the next section. This gives a total gradient G =
Gi,
shared by all the users. The next phase of conjugate gradient
is “line minimization,” where each user computes the scalar
quantities:
(cid:2)
ci = −2tr(PiGT AP T
i )
ai = −tr(PiGT GP T
i )
bi = tr(PiAT GGT AP T
i )
(2)
Each user seeking a recommendation will already have
constructed the public matrix A in the course of running the
protocol described in section 4. The user can then gener-
ate recommendations for themselves using A. User i has
a 1 × m matrix of preferences Pi. Many of these will be
missing (represented by zeros in P ) for items the user has
these values are also tallyed using the vector addition pro-
(cid:2)
tocol in the next section to produce global values (c, a, b) =
(ci, ai, bi). Finally, from (c, a, b) the new aggregate is
computed as described in appendix I. There are a few extra
steps implement the Polak-Ribiere method but they do not
require communication. They are covered in the appendix.
Proceedings of the 2002 IEEE Symposium on Security and Privacy (S&P(cid:146)02) 
1081-6011/02 $17.00 ' 2002 IEEE 
4
3 Vector Summation of Encrypted Data
We assume that each of n users has a vector of data Gi ∈
k×m for i = 1, . . . , n representing their contribution to the
R
gradient of A. For convenience, we treat each Gi as a vector
with km coordinates Gi = (Gi1, . . . , Gi(km)). We assume
that every user data item Gij is integer, and restricted to a
small number of bits, say 10 bits. We assume that a fraction
α > 0.5 of clients and tallyers are honest. The goal is to
compute the vector sum G =
i=1 Gi at all the honest
tallyers 2. The privacy goals are that:
(cid:2)n
1. The tallyer should gain no information about an indi-
vidual user’s data Gi, except that:
2. User data is almost surely valid. Almost surely valid
means that |Gi| < L with high probability. This is in
spite of malicious behavior by some tallyers or clients.
3. The total G should be veriﬁed. We will rely on multi-
ple tallyer computations and the trusted coin source to
do this.
For our method to be practical we must meet some efﬁ-
ciency goals:
1. Typical collaborative ﬁltering domains have hundreds
to millions of items (this is the range of m). The di-
mension k is typically less than ten. Secondly, the
number of users could range from 10 to 107. Clearly
Ω(knm) is a lower bound on the total work that must
be done. If each user contributes a processor, then the
lower bound per machine is Ω(km). To be practical,
the work per machine should stay within a polylog fac-
tor of O(km).
2. The validity proof for each user’s data should be
“small” compared to the representation of Gi, and the
time to check it should be small compared to the time
to add Gi to the sum.
3. It should be possible to efﬁciently check the computa-
tion done by the tallyers. This will turn out to be the
most expensive step, and it requires a trusted global
source of random bits.
Our scheme follows the general architecture of the elec-
tion scheme of Cramer, Gennaro, and Schoenmakers [5].
There are several differences between our scheme and
theirs. First, we are computing a sum of vectors of user
preferences instead of binary user votes. Because of this,
the ZKP of vote validity is different. Second, instead of
voters+authorities, we have clients and one or more tally-
ers. In our scheme, a private key is secret-shared among all
2There is also the second phase of totalling the 3-element vectors
(ci, ai, bi) but clearly the ﬁrst phase dominates
Proceedings of the 2002 IEEE Symposium on Security and Privacy (S&P(cid:146)02) 
1081-6011/02 $17.00 ' 2002 IEEE 
5
clients, not just the authorities. Tallyers perform a tallying
function like the authorities, but are not assumed to be se-
cure. So in fact our scheme could be implemented as a pure
peer-to-peer system where clients and tallyers are the same.
As mentioned earlier, we assume the parties share a
blackboard to which they can all write and read, but such
that one party’s data cannot be erased or changed by any-
one (a WORM store). We also assume the existence of a
trusted source of random coin tosses.
3.1 Key Sharing
The goal of this step is to create a globally-known El-
Gamal public key, and a matching private key which is held
by no-one and instead secret-shared among all the clients.
The key generation protocol of Pedersen [9] does this. The
result is that each player has a share si of the decryption key
s, and s can be linearly reconstructed from a sufﬁcient num-
ber of shares. More precisely, let p and q be large primes
such that q|p−1, and let Gq denote the subgroup of Z
∗
p of or-
der q. In normal El-Gamal encryption, a recipient chooses a
g ∈ Gq and a random secret key s, and publishes g, h = gs
as their public key. In our case, we want the secret key to
be held by no-one and instead secret-shared among all the
players. After applying Pedersen’s protocol, each client has
a share si of the decryption key s, and s can be linearly re-
constructed from any set Λ of t + 1 shares via appropriate
Lagrange coefﬁcients:
(cid:4)
j∈Λ,j(cid:5)=i
j
j − i
(cid:3)
i∈Λ
s =
siLi,Λ
Li,Λ =
These shares can also be used for threshold decryption of
messages encrypted with the public key (g, h). We assume
that p, q, g, h are known to all participants after Pedersen’s
protocol, as well as another generator γ ∈ Gq needed for
homomorphisms. We also assume that each user publishes
a public key corresponding to si, which is needed to verify
their decryption of data.
We choose the encryption threshold to be greater than
the number of untrusted users, which is (1 − α)n. Taking
α = 0.8 for instance, gives us a threshold of t = 0.2n which
allows the scheme to work correctly even when a signiﬁcant
fraction of trusted clients are ofﬂine.
3.2 Value Encryption/Homomorphism
Each user has km data values Gij, j = 1, . . . , km.
To encrypt, user i chooses km random values rij, j =
1, . . . , km from Zq. The encryption of the data is then
Γij = (xij, yij) = (grij , γGij hrij )(mod p)
for j = 1, . . . , km. In other words, each value is a standard
El-Gamal encryption of the exponentiation of a vote: γGij .
User i sends these km values to the write-once blackboard.
Notice that this map is a homomorphism. Deﬁne
H : Zq × Zq → Zp × Zp
h(v, r) = (gr, γvhr)(mod p)
h(v1 + v2, r1 + r2) = h(v1, r1) ∗ h(v2, r2)(mod p)
where the multiplication on the right side is element-wise.
We will assume element-wise multiplication from here on.
This homomorphism allows us to compute the encryption
of a sum of votes by simply multiplying the encryptions.
That is:
n(cid:3)
h(
n(cid:3)
n(cid:4)
Gij,
rij) =
h(Gij, rij)(mod p)
i=1
i=1
i=1
for j = 1, . . . , km. This tally and all partial totals are El-
Gamal encryptions, and provide computational hiding of
the data.
3.3 ZK Proof of User Data Validity
Each user should give a ZKP that their encryptions
(Γi1, . . . , Γi(km)) represent a valid input, namely one that
is not “too large”. An expensive way to do this is to give
a ZKP for every element Gij that bounds its size. This is
neither efﬁcient nor desirable. The amount of inﬂuence a
single user has over the aggregate can be bounded by the
2-norm of Gi. The squared 2-norm is just the sum of the
squares of the elements of Gi. We can bound the 2-norm
in zero-knowledge by bounding a single quantity which we
prove is the sum of the squares of the elements of Gi. The
bound uses ideas from [3], suitably adapted as described in
Appendix II.
For each Γij which encrypts a Gij, we ﬁrst generate a
Wij which encrypts G2
ij. The prover and veriﬁer multiply