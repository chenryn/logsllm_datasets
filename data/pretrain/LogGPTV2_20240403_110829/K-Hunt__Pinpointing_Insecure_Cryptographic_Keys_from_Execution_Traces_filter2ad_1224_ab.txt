Next, it checks whether the candidate basic blocks are data sensi-
tive. A basic block is data sensitive if the total amount of execution
for the basic block is proportional to the size of its input data. We
prepare four test suites with inputs of different size magnitude
to test the program, and calculate for each candidate basic block,
the total number of executions of the basic block across all inputs,
the total basic block’s input data size, and the total basic block’s
output data size. Candidate basic blocks for which the number
of executions increases approximately linearly with the ratio of
input/output data size are kept as candidate crypto basic blocks.
Other candidates are discarded.
At this point, our approach has checked the first two conditions
in Definition 1. The last condition checks if the data operated on by
the candidate basic block has high randomness. However, each time
a basic block is executed it only operates on part of the input data.
Thus, our approach accumulates all the data that each candidate
basic block operates on during the entire program execution into
data bundles.
Definition 2. A data bundle is defined as the sequence of all the
data that an operand of an instruction operates on during the entire
execution of the program. The size of a data bundle is the number of
data items it contains.
For example, in Figure 1b the instruction at 0x0040109A has one
memory read operation and is executed 256 times. Therefore, there
will be a data bundle with 256 data items: the sequence of value
read that is from byte_413780[edx]. Our approach focuses on data
bundles that are generated by instructions with memory operands,
since registers have a limited size that does not typically hold a
crypto key. Once the data bundles are built, they are examined
to identify those that contain highly random data. For this, our
approach leverages the ent [40] utility to measure the randomness
of the collected data bundle with both Chi-Square distribution and
Monte Carlo π approximation tests. If ent judges the data bundle
as random, the candidate basic block is considered a crypto basic
block.
In our running example in Figure 1b, the basic block (0x0040108E-
0x004010B2) is the crypto basic block to be identified. It satisfies
the above constraints for a crypto basic block: it utilizes arithmetic
and bitwise instructions to implement the crypto operation, the
number of executions of the basic block is proportional to the size of
the input data, it accesses several memory buffers, and its produced
data has high randomness.
Figure 2: The process of pinpointing crypto keys in binary executables
Step-II: Crypto Key Buffer Identification. Having identified the
crypto basic blocks in Step-I, our approach next identifies the crypto
keys used by those basic blocks. Different types of data may be
handled by a crypto basic block: crypto key, plaintext, ciphertext,
and message to be signed. More concretely, a crypto operation will
take two inputs: crypto key and plaintext for encryption, crypto
key and ciphertext for decryption, and crypto key and message for
digital signature. Thus, the crypto key should always be an input to
the crypto basic block. Therefore, we can exclude the data output
by the crypto basic block and just focus on the input data. Still, our
approach has to separate the crypto key from the other input. And,
it can no longer use randomness for this since both the crypto key
and the ciphertext will have high randomness.
Definition 3. A crypto buffer is defined as all operated memory
addresses in one data bundle of a crypto basic block, and the size of a
crypto buffer is the number of unique memory addresses it contains.
For instance, the memory read data bundle of the instruction
at 0x0040109A in Figure 1b contains 256 items. This bundle, how-
ever, only contains 16 unique memory addresses, thus the size of
corresponding crypto buffer is 16 instead of 256. When we test the
randomness of the data, we use the concept of bundle because a
buffer may be accessed randomly and we should concern about
the access sequence. If the high randomness is discovered, we then
only concern about the range of accessed memory, and thus we use
the concept of buffer to help distinguish key from data.
To identify which input is the crypto key buffer, K-Hunt lever-
ages the following two complementary insights.
• Using the buffer size. Typically, the crypto key buffer is small
compared to the ciphertext/plaintext/message buffer: a key can
be stored in a relatively small buffer but the crypto input often
needs a larger memory buffer. This feature becomes even more
obvious when executing the crypto basic blocks with multiple
inputs: either the key is repeatedly used or it is updated between
different iterations (e.g., the state update of a stream cipher),
and the key is generally stored in a fixed-length memory buffer
whereas the length of the ciphertext/plaintext/message varies
according to the size of the program input.
• Using the execution context. The other insight is that crypto
keys and other input data are typically initialized by different
functions. If we track the execution context of how the data is
initialized, we can easily differentiate them as well. For instance,
the used crypto key buffer is usually initialized by a key deriva-
tion function or from a pseudo-random number generator, while
the plaintext/ciphertext/message is generally directly read from
a file or network socket.
4.2 Detecting Insecure Keys
The second phase of K-Hunt detects the insecure crypto keys.
Unlike the first phase where we perform a lightweight dynamic
binary analysis to collect execution statistics (e.g., the number of
executions for a basic block and the randomness of data bundles),
the second phase requires a heavyweight dynamic binary analysis
to trace how keys are generated and propagated. At a high level,
our analysis is a function-level variant of dynamic taint analysis
(e.g,. [59, 63]) with the following taint policies.
Taint Sources. K-Hunt uses three different taint tags to capture
whether a value has been derived from a local input (i.e., filesystem
or return value from the rand function), a remote input (i.e., the
network), or none of those two (i.e., deterministic value). Thus,
each memory location (i.e., byte) in the shadow memory [63] has
a two-bit taint tag with values 00 for no input, 01 for local input,
and 10 for remote input. At initialization, all memory locations
will be assigned the no-input tag. During program execution, if
K-Hunt observes that a memory location is assigned from local
input (remote input), K-Hunt assigns the local (remote) taint tag
to the memory location. For instance, Key at line 13 in our running
example in Figure 1a will be assigned with a local input tag.
In addition, to quantitatively measure how many of bytes of
information generated for crypto keys, we introduce the concept
of the length of input for the buffer involved for key generation.
Definition 4. The input length (IL) of a buffer is the number of
bytes derived from program inputs.
For instance, in our running example the keygen function initializes
four bytes of the seed buffer using function rand. Then K-Hunt
keeps a 4-byte IL for this buffer.
Taint Propagation. K-Hunt could use a fine-grained taint anal-
ysis (e.g., [59]) to trace each instruction and propagate the taint
tags correspondingly. However, we found such an approach often
incurs high performance overhead to the analyzed program, e.g.,
Crypto Basic BlocksExecuted Basic BlocksData Bundlescrypto basic block identificationdataclusteringKey bufferidentification0040108E mov   eax, [ebp+var_4]00401091 xor   edx, edx00401093 mov   ecx, 10h00401098 div   ecx0040109A movzx edx, byte_413780[edx]004010A1 mov   eax, [ebp+arg_0]004010A4 add   eax, [ebp+arg_4]004010A7 movzx ecx, byte ptr [eax]004010AA xor   ecx, edx004010AC mov   edx, [ebp+arg_0]004010AF add   edx, [ebp+var_4]004010B2 mov   [edx], alBasic Block 2Num of Exec = 10Basic Block 3Num of Exec = 9Basic Block 4Num of Exec = 1Basic Block 1Num of Exec = 1Crypto Key010010010101010101111110101001010101010101010101010101010101000101001101010101010101010101011010100000000000101010111110101010101111011101010101010101010101101010000000000010101011111010101010111101110101010101010101010110101000000000001010101111101010causing a remote peer to close the network socket due to connec-
tion time out, or the GUI freezing for non-networking programs,
e.g., WinRAR. Therefore, we have develop a lightweight, function-
level, taint propagation policy, which propagates taint tags based
only on the memory read and memory write operations inside the
execution context of a function. This propagation is based on the
fact that K-Hunt only requires knowing whether a buffer contains
data from either deterministic, local input, or remote input (i.e., the
three taint tags). Therefore, it does not need to propagate the taint
tags precisely for each instruction. Instead, it can propagate taint
tags at the higher function level, significantly improving efficiency.
More specifically, K-Hunt taints all the data definitions (i.e.,
memory writes) inside a function using the taint tag of the input
data. As such, it only needs to instrument the memory read and
write instructions. The memory read instructions define the taint
source for the function, and the memory write instructions define
the taint tags for the memory data based on the current function’s
taint . If a new taint source to the function is observed, the new
taint tags are unioned with the current function’s taint tag. All
the defined data inside this function will from that point on have
a unioned taint tag (e.g., tag with bits 11 to represent both local
and remote input). In our running example, the seed buffer in the
keygen function will be tainted with local input tag, and thus the
global Key buffer will also be assigned the local input tag.
While propagating the taint tags, we also propagate the IL for
the buffers. Such information is particularly useful for determining
whether a key has sufficient randomness. In particular, for each
function, K-Hunt tracks the total number of IL. Then whenever
there is a memory write information, it propagates the current IL
to this buffer. When the function returns, it recalculates the IL for
each buffer based on both the number of bytes accessed and also the
current IL for this function. Assume that one function accesses two
buffers during its execution. K-Hunt records how many bytes in
each buffer are accessed, respectively. If the number of bytes does
not exceed the IL of the host buffer, K-Hunt adds this number to
the IL of the newly initialized buffer. Otherwise it adds the IL of the
host buffer to the IL of the new buffer. Finally, we check whether
the IL of the new buffer is larger than the size of the buffer. If so,
the IL is adjusted to the size of the buffer. Through performing such
IL propagation, K-Hunt maps the information from input buffer to
the output buffer of one function.
Taint Sinks. With the aforementioned taint sources and taint prop-
agation policy, all the memory locations will have a taint tag show-
ing whether the data comes from local or remote input, or is deter-
ministic. To identify insecure crypto keys, K-Hunt checks the taint
tag of the buffer at the crypto basic block (to check whether the key
is improperly generated) or when the program exits (to check for
key residue). In particular, we use the following policies to detect
the insecure crypto keys.
• Detecting DGK. If a key is not derived from any input, i.e., is
deterministic, then K-Hunt considers that the generation of the
key is flawed. In addition, K-Hunt checks whether the key re-
ceives enough information from non-deterministic inputs. This
is done through an analysis of the key buffer IL. For example, in
our running example the key is initialized in the keygen func-
tion. At the beginning of the function a seed buffer is initialized
with a 4-byte IL. Then the key buffer in the same function is
initialized. At that time, the IL of the key buffer is also assigned
as 4 because the function only accesses one buffer with a 4-byte
IL. As a result, even if the size of the key buffer is 16, it has a
smaller IL of 4-byte. Eventually, if the IL of a key buffer has
the size less than a threshold, 16 bytes (128 bits) in our current
design, we consider the key is insecure. In this case the used
key buffer has a 4-byte IL and is obviously insecure.
• Detecting INK. An insecurely negotiated key is a crypto key
shared between two parties (e.g., a session key between a client
and a server) where the key value is only influenced by one
party [30]. A negotiated key is the symmetric key used for en-
crypting or decrypting network data. If we know there is a
negotiated key but the taint tag for this key includes only local
input tag or remote input tag (not both), K-Hunt considers this
is an insecurely negotiated key.
• Detecting RK. When a crypto operation terminates, all mem-
ory buffers holding involved crypto keys should be cleared [69].
To detect any recoverable keys, K-Hunt searches the memory
to check any partial existences of the keys in memory when the
process terminates. A key is considered recoverable if one third
of its content still exists in memory [49]. Therefore, we cross
check the content of the data bundles, and if one third of the con-
tent still matches with the original key buffer, K-Hunt considers
it a recoverable key. In our running example, the Key buffer is
allocated in the global memory region, and is not cleared after
process termination. K-Hunt therefore detects it is an RK case.
5 IMPLEMENTATION
We have implemented K-Hunt using Intel PIN [56], a popular dy-
namic binary instrumentation (DBI) framework. We use dynamic
analysis instead of static analysis for different reasons. First, we
need to measure execution statistics such as the randomness of the
runtime data and the number of executions of a basic block. Second,
static analysis faces limitations analyzing memory buffers, e.g., due
to indirect memory addressing. Third, the static dentification of
function boundaries, needed for the function-level taint propaga-
tion, is challenging, especially for C++ libraries [28]. Using DBI,
K-Hunt can leverage the runtime information to identify function
boundaries. Finally, DBI is able to handle executables with some
protections (e.g., code packing or VM obfuscation).
We have implemented three Pintools for code profiling, random-
ness testing, and key tracking. In Phase I, the executable is first run
with the code profiling Pintool to find which candidate basic blocks
should be tested for randomness. Then, the program is executed
again with the randomness testing Pintool to collect the runtime
information needed for the randomness test. In Phase II, the key
tracking Pintool is used to check how program inputs affect the
key derivation and how crypto keys are propagated.
To detect the key residue, we should rigorously have imple-
mented a kernel module to monitor all of the process pages be-
longing to the target process right after the process terminates.
Unfortunately, PIN does not provide such kernel-level APIs. In-
stead, we instrument the callback function PIN_AddFiniFunction
in our key tracking pintool to trigger the memory check. This call-
back is invoked right after the execution of all user defined cleanup
functions and before the process terminates.
Labeling Program Inputs. K-Hunt needs to set the input taint
tag when the program receives local or remote input. To this end, it
hooks the system APIs that deal with such inputs (e.g., read, fread,
recv) , as well as APIs related to random number generation (e.g.,
rand()). The local tag is set if the input comes from the filesystem
or a random number generation API, and the remote tag if the input
comes from a network socket.
Differential Testing. K-Hunt can optionally use a differential
analysis step to identify candidate basic blocks in Phase I that are
unrelated to crypto operations, and thus be removed from the can-
didate set. To this end, it compares two traces, obtained by running
the program executable with and without triggering the crypto op-
erations (e.g., executing 7-zip with or without file encryption). Then,
it identifies candidate basic blocks that do not appear in the execu-
tion with crypto operations, as well as candidate blocks that apper
in both executions with and without crypto operations. In both
cases, those candidate basic blocks cannot be crypto basic blocks.
Note that differential analysis is just an optional optimization to
reduce the number of candidate basic blocks to be considered.
On-Demand Tracing. Crypto operations are often CPU-intensive
and a dynamic analysis with large performance overhead could
significantly interfere with the normal program execution. To ad-
dress this, K-Hunt uses on-demand tracing , applying heavyweight
program analysis only on necessary code blocks. For instance, in
the first phase, both the number of executions of candidate basic
blocks and the data randomness are analyzed to determine the
crypto basic blocks. However, the testing of randomness requires a
time-consuming analysis. To reduce this overhead, K-Hunt first
uses code profiling to count the number of candidate basic block
executions and excludes irrelevant candidate basic blocks. In this
manner, it only needs to apply the more expensive randomness test-
ing on the remaining candidate basic blocks. In the second phase of
analysis, K-Hunt only instruments the memory read and memory
write instructions to propagate the taint tag at function level, as
described in §4.2. This significantly reduces the overhead of our
taint analysis.
Entropy Test. A time-consuming step in K-Hunt is the random-
ness test. To speed this step, we conduct a more lightweight entropy
test before, so that the randomness test is only applied to those bun-
dles with high entropy. Note that a bundle with high randomness
must also possess high entropy, while a bundle with high entropy
may not have high randomness [65].
Online Analysis. K-Hunt uses an online analysis approach. It
could also operate on execution traces to reduce the runtime over-
head. Nonetheless, we found an online approach is more suitable to
our goal because offline analysis leads to extremely large execution
traces (often >100GB), which create an I/O bottleneck slowdown.
Library
Version
Category
Protection
Botan [3]
Crypto++ [6]
Libgcrypt [11]
LibSodium [12]
LibTomcrypt [13]
Nettle [16]
GnuTLS [7]
mbedTLS [21]
OpenSSL [17]
WolfSSL [26]
Application
7-Zip [1]
Ccrypt [4]
Cryptcat [5]
Cryptochief [20]
Enpass [2]
Imagine [8]
IpMsg [9]
KeePass [10]
MuPDF [15]
PSCP [18]
Sage [19]
Ultrasurf [22]
WannaCry [23]
Wget [24]
WinRAR [25]
1.10.13
5.6.4
1.6.6
1.0.12
1.17
3.3
3.5.13
2.3.0
1.1.0f
3.9.10
Crypto Libraries
Crypto Libraries
Crypto Libraries
Crypto Libraries
Crypto Libraries
Crypto Libraries
SSL/TLS Libraries
SSL/TLS Libraries
SSL/TLS Libraries
SSL/TLS Libraries
Version
Category
9.20
1.10
1.2.1
1.337
5.6.0
1.1.0
4.60
1.34
1.11
0.62
2.0
15.04
1.0
1.11.4
5.40
File Compressor
File Encryptor
Messenger