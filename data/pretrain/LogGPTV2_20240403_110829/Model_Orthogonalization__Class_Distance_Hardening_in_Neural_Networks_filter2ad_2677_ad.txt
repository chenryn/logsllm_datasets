### 更新学生网络
NAD（神经对抗蒸馏）生成的学生模型作为最终输出。所有训练完成的模型基于其正常的准确率下降被认为是有效的。对于TrojAI模型，我们不考虑UAP（通用对抗扰动），因为从头开始训练大规模模型成本过高。我们在四个标准数据集上的评估已经表明了UAP的无效性（详见第V-B节）。

### 评估指标
在评估过程中，我们考虑以下标准：
- 使用测试集上的预测准确率来衡量正常功能。
- 对于对抗训练的模型，在给定的L∞约束下测量模型鲁棒性。
- 如第三节所述，正交化的目标是增加所有类别对之间的聚合距离。我们使用类别对间距离的相对改进作为度量标准，计算公式如下：

\[
\text{平均相对改进} = \frac{1}{n \times (n - 1)} \sum_{i=1}^n \sum_{\substack{j=1 \\ j \neq i}}^n \frac{\hat{d}_{i \rightarrow j} - d_{i \rightarrow j}}{d_{i \rightarrow j}}
\]

其中，\( n \) 是类别的数量；\( d_{i \rightarrow j} \) 和 \( \hat{d}_{i \rightarrow j} \) 分别表示原始模型和强化模型中从类别 \( i \) 到类别 \( j \) 的距离。我们利用现有的后门生成方法NC [53] 来测量这些距离。具体来说，我们从验证集中随机选择100个样本，并应用NC方法进行1,000轮迭代以生成一个可以将90%的样本翻转到目标类别 \( j \) 的后门。由于后门在生成过程中是随机初始化的，为避免随机性带来的偏差，我们对同一对类别运行三次NC，并使用最小的后门大小作为类别距离。

通过上述过程估算的距离可能具有一定的波动性，因此我们进一步研究了使用不同样本集/数量时测量结果的稳定性。实验结果显示，对于CIFAR-10上的自然训练ResNet20模型，基于100个样本进行100次随机运行测得的距离为57.48，标准差为4.56，这表明测量结果相当稳定。此外，我们也研究了另一种后门生成方法ABS [41] 用于距离测量，结果表明ABS是一个合理的替代方案。详细信息见附录X-B。我们将展示每种方法的平均相对改进、平均类别距离以及训练时间（以分钟计）。

### 标准数据集评估
我们在四个标准数据集上进行了自然训练和对抗训练模型的实验，结果分别列于表I和表II。LISA和GTSRB的结果见附录X-C中的表V和表VI。由于使用UAP进行加固需要从头开始训练模型 [43]，我们仅在自然训练模型上与其他技术进行比较。从表I可以看出，MOTH方法在保持非常小的准确率下降的同时，显著提高了类别距离（最大增幅出现在SVHN数据集上的ResNet32模型，从55.21%提高到190.40%）。我们还评估了CIFAR-10上自然训练ResNet20模型在应用MOTH前后的鲁棒性（使用PGD攻击），发现鲁棒性没有变化。基准UAP方法仅能在少数数据集和模型上增强类别距离。例如，在CIFAR-10上的Network in Network (NiN) 模型上，UAP甚至无法增加类别距离，其平均类别距离（57.56 vs. 60.67）反而小于原始模型，证明UAP在类别距离加固方面无效。使用通用后门训练的方法虽然相对于原始模型有所改进（从18.88%提高到113.92%），但效果仍不如MOTH，平均改进差异为46.68%。Pairwise方法在所有类别对上均等地进行加固，其结果与MOTH类似。

#### 表I：不同方法在自然训练模型上加固类别距离的比较
| 数据集 (D) | 模型 (M) | 训练方法 | 测试准确率 | 训练时间 (分钟) | 平均类别距离 | 相对改进 (%) | 准确率下降 (%) |
| --- | --- | --- | --- | --- | --- | --- | --- |
| ... | ... | ... | ... | ... | ... | ... | ... |

（表格内容省略）

### 结论
通过上述评估，我们可以看到MOTH方法在保持高准确率的同时，显著提高了模型的类别距离，而其他方法如UAP和Pairwise则表现较差。未来工作将进一步探索更多高效的加固方法。