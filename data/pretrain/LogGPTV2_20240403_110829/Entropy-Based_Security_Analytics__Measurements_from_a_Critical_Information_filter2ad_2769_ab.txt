records from proxies. The work [10] uses term weighting to
detect anomalies in the behavior of a program by analyzing
system call frequencies during the execution. The approach
models processes and system calls as documents and words,
respectively. A kNN approach is used to classify the behavior
of a program into normal or intrusive.
Differently from the mentioned work, which addresses
structured and well-formed data sources (e.g.,
time series,
audit/network records and systems calls) our paper deals with
mining unstructured textual alerts through term weighting. For
example, term weighting approaches have been used in [27],
which proposes an unsupervised algorithm to detect anomalies
from supercomputer logs containing 750 million messages and
[28] to ﬁnd faults across syslog data. However, differently from
our work, the focus of the mentioned research is on reliability
rather than security. To the best of our knowledge, this is the
ﬁrst contribution that investigates the use of entropy-based term
weighting for security purposes.
III. PROPOSED METHOD
Our method addresses heterogeneous log sources by means
of a uniform analysis approach. Let us consider a system
composed by the nodes Nj (1≤j≤S), such as shown by Fig. 1.
Overall the nodes emit a given number of event logs, or simply
logs, Li (1≤i≤N). As above-discussed, logs are generated by a
variety of modules, such as applications, middleware, database,
and operating system: no assumption is made on the format
of the source logs. The method is based on two tasks named
log.entropy sampling and collector, respectively.
Sampling is a periodic task that, every T 6 time units,
computes the log.entropy of the new entries in Li generated
during the past T : sampling is done individually for each
Li (i.e., total N sampling tasks, such as in Fig. 1). Periodic
log.entropy sampling encompasses two steps, i.e., terms/counts
extraction and weighting. Given the entries of Li generated
during the past T (i) terms extraction applies some data
preparation steps to the entries, extracts all the terms that com-
pose the entries (a term is a sequence of characters separated
by one(more) whitespace(s)), and the count of the occurrences
of the terms, while (ii) the weighting step computes the
log.entropy based on the counts of the terms. The output is a
log.entropy measurement, i.e., leLi in Fig. 1. Log.entropy is a
numeric score that measures the relevance of the entries in Li:
the higher the log.entropy, the more the entries are interesting.
For example, log.entropy increases if an entry contains one
(more) term(s) that have never historically occurred in Li or
6The method is presented without referring to speciﬁc values of the
parameters; Section VI-A discusses the tuning of the parameters for the
reference system.
Fig. 1: Representation of the proposed method.
381
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:58:24 UTC from IEEE Xplore.  Restrictions apply. 
1
2
3
4
5
6
7
8
[ 0 3 / 1 9 / 1 6 2 3 : 4 8 : 0 0 . 4 9 5 ] MSG : switch : RX msg = 0x40bf9008 userref = LN1_USERREF status = 0 bufsize = 256
MSG : mrlmgact : MTMO clokid [ 4 2 ] actflg [ 1 ]
MSG : mrlmgact : MTMO STOP clokid [ 4 2 ] actflg [ 1 ] state [ 0 ]
MSG : mocmgact : MTMO START 2 clokid [ 4 2 ] actflg [ 1 ] state [ 0 ]
[ 0 3 / 1 9 / 1 6 2 3 : 4 8 : 0 0 . 4 9 6 ] MSG :
msgexec : Rx msg = 0x40bf9008 − MRLMG − des = 0216 spare6 = 0x0 tbn = 0
PAN : CREATEBUFFER msg [ 0 x40bf9008 ] bufid [ 5 5 0 5 ] bufsize [ 2 5 6 ] file [ src / timers / ostimer . cxx ] line [ 4 0 ]
[ 0 3 / 1 9 / 1 6 2 3 : 4 8 : 0 0 . 5 0 0 ] MSG : switch : RX msg = 0x40bf9018 userref = INT_USERREF status = 0 bufsize = 256
PAN : DELETEBUFFER msg [ 0 x40bf9018 ] bufid [ 5 5 0 5 ] bufsize [ 2 5 6 ] file [ src / switch . cxx ] line [ 1 2 1 4 ]
Fig. 2: Examples of entries in a log ﬁle from the case study.
Fig. 3: Log.entropy sampling of Li.
if it contains a term being emitted too many times when
compared to the behavioral baseline of Li.
Collector acquires the most recent log.entropy observa-
tions for all the logs of the system.
In the following, we detail
the sampling task and the
background of the log analysis techniques underlying the
proposed method.
A. Terms/Counts Extraction
Fig. 2 shows real entries found in a log of the system ad-
dressed in this study. For example, the term 23:48:00.495
is a portion of the timestamp of line 1, while 0x40bf9008
is the value of a domain-speciﬁc variable. Terms extraction
applies some data preparation steps to terms, beforehand.
There is a key observation underlying the need for data
preparation. Logs generated under regular system activity are
fraught with very unfrequent terms (often occurring just once),
such as timestamps, value of variables, dumps of entire data
structures and process identiﬁers, as shown by Fig. 2. In fact,
a typical entry consists of invariant and variable ﬁelds. Let us
clarify this concept by means of an example. The entries
MSG: switch: RX msg = 0x40bf9008 userref = LN1_USERREF
MSG: switch: RX msg = 0x40bf9018 userref = INT_USERREF
(i.e., portions of lines 1 and 7 in Fig. 2) share a common
constant structure, denoted as pattern hereinafter, which can
be visualized by removing the variable ﬁelds:
MSG: switch: RX msg = * userref = *
Invariant ﬁelds do not change among the entries with the
same pattern; on the other hand, variable ﬁelds change and the
values they assume are likely to occur very few times across
a log. This might distort the weighting step, whose aim is to
assign larger weights to unfrequent terms caused by interesting
system activity. Unfrequent terms represent a known issue in
dealing with textual logs. For instance, the weighting approach
proposed by [28] discards all the terms in the logs that occur
once, before subsequent analysis; similar considerations are
done in [29].
Given a set of log entries, data preparation aims to mit-
igate such an inherent variability of the terms. This is done
through different steps based on a number of consolidated
to avoid conventional
practices from the information retrieval domain. For example,
terms/counts extraction (i) removes special non-alphanumeric
characters (e.g., #, ?, ;, and %), (ii) implements a stop-
terms, such as names of
word list
days/months and well-known process, and (iii) extracts the
stem of each term by using the algorithm developed by Porter
[30]: whenever two tokens have the same stem, they are treated
as two occurrences of the same term. More important, each
entry is checked against a replacements base7 shown by Fig.
3. The entry is replaced with the corresponding pattern, if the
pattern is available in the base; the entry is left unchanged,
otherwise. Once all
terms
extraction tokenizes the entries, and counts the number of
occurrences of each terms across the entries.
the entries have been prepared,
B. Term Weighting
Term weighting is a consolidated technique in the informa-
tion retrieval domain [32]. It allows computing the relevance
of terms in a textual dataset. We use the logarithmic entropy
(log.entropy) scheme to measure whether interesting entries
occurred in Li every T time unit. This choice is justiﬁed by a
study presenting a comparison of weighting schemes to address
text logs [33]. Log.entropy computation is based on the term-
by-chunk matrix, i.e., a W×M matrix, with W denoting terms,
shown in Fig. 3. The Mth column of the matrix contains the
term counts of the entries in Li generated during the past T
time units, which is supplied by the above-presented step; the
leftmost (M-1) columns contain the term counts obtained from
(M-1) Li chunks of duration T collected under regular system
activity. The term counts of the Mth column are extracted
online, while the counts in the (M-1) columns are set ofﬂine in
a tuning phase done before the method is run. In this respect,
the leftmost (M-1) columns of the matrix are constant, while
the Mth column is overwritten every T time units.
(1≤i≤W, 1≤j≤M) denote the number of
times
in the chunk j. We obtain
the term i occurs
(cid:2)(cid:3)W
log.entropyM , i.e., the log.entropy score of the Mth column,
i=1(ei · log2(1 + xi,M ))2, where ei (with 0 ≤ ei ≤ 1)
as
represents the entropy of the term i across all the M chunks,
and is computed according to Equation 1.
Let xi,j
ei = 1+
1
log2(M )
j=1
pij log2(pij) pi,j = 1+
xi,j(cid:3)M
j=1 xij
(1)
M(cid:4)
As it can be inferred from Equation 1, terms that occur
regularly across the M chunks have a small weight. For
example, a term in the Mth chunk, which has never been
generated by Li under regular activity (again, the leftmost M-1
7The replacements base is populated off-line, i.e., prior the method is run,
during a tuning phase. Patterns belonging to the base are automatically inferred
from event logs produced by the system under regular system activity. To this
objective, we developed a technique based on the considerations in [31].
382
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:58:24 UTC from IEEE Xplore.  Restrictions apply. 
several worker nodes. The master node runs a daemon called
Nimbus, which is responsible for distributing code and tasks
to worker nodes. Worker nodes run a daemon called Supervi-
sor, which waits for tasks and starts/stops worker processes,
accordingly. The basic Storm data processing architecture
consists of data streams ﬂowing through topologies. A data
stream is a set of tuples to analyze. A topology is a directed
graph where the vertices represent computation and the edges
represent
the data streams ﬂow between the computation
components. Computation components are divided into spouts
and bolts. Spouts are the data stream sources for the topology,
such as ﬁles or sockets. Bolts consume input streams, apply
application-speciﬁc processing to them, and might emit new
streams. For example, bolts can process/ﬁlter/aggregate/dupli-
cate streams and forward them to the next set of bolts.
B. Framework implementation
The tasks of the proposed method have been implemented
as Storm spouts/bolts. Fig. 5 shows the topology implementing
the method according to the Storm notation. The topology
consists of ﬁve components: (i) splitter, (ii) replacer, (iii)
column builder, (iv) entropy compute, and (v) collector.
The splitter represents the input stream of the topology
and has been developed as a Storm spout. Given an input log
ﬁle, the splitter samples the ﬁle every T time units, generating
a chunk containing the log entries produced during the past
T . The splitter records the position of the chunk in the log
ﬁle, i.e., the position of the ﬁrst and last entry of the chunk,
to allow tracing back the entries to the raw log. A splitter is
deployed for each log ﬁle analysts wish to analyze.
The replacer is a Storm bolt that performs the preparation
of the entries in the chunk and accesses the replacements base.
If a pattern is available in the base, the replacer replaces the
entry with the corresponding pattern.
The column builder counts the occurrences of each term
in a chunk and builds the corresponding term count column
(i.e., the on-line Mth column of the term-by-chunk matrix used
for computing the log.entropy, as explained in the Section III).
Again, the column builder is a Storm bolt.
The entropy compute is a Storm bolt that computes the
log.entropy of a chunk. This bolt checks the column supplied
by the column builder against the (M-1) off-line columns of
the term-by-chunk matrix.
The collector gathers the log.entropy observations gener-
ated by different entropy compute components. Log.entropy
observations are collected into vectors; each position of the
vector corresponds to a log stream. Each log.entropy obser-
(a) CDFs.
(b) Frequency histograms.
Fig. 4: CDF of the entropy of the terms, and absolute frequency
of the terms by entropy for non prepared data and prepared
data in an example log.
chunks), is assigned a large weight. The result of the weighting
is a new sample of leLi, which is forwarded to the collector.
Let us discuss the value of the data preparation step on
the term entropy computation by means of an example. Fig.
4a shows the cumulative distribution function (CDF) of the
entropy of the terms found in a log of the system under study
before and after data preparation. The point marked with a ×
(non prepared data series) indicates that the probability the
entropy of a term is higher than 0.8 is 0.86 (i.e., 1-0.14); in
other words, almost all non prepared terms occur very few
times, which causes entropy to be high. Upon data preparation,
the probability entropy is higher than 0.8 drops to 0.04, i.e.,
0.96 ×-marked point in Fig. 4a, which means that the logs
have been cleared from the inherent noise of the raw log. Fig.
4b further explores this concept by showing the number of
terms with respect to the value of entropy (by step 0.1): beside
the remarkable difference in the total terms, i.e., 21,215 non
prepared against 973 prepared, it can be noted that almost all
the non prepared terms are in rightmost bucket.
IV. DATA ANALYTICS FRAMEWORK
There exist a number of technical challenges in implement-
ing the proposed method. For example, our proposal would
beneﬁt of low latency and high scalability data processing
capabilities to cope with realistic production requirements.
Current systems generate volumes of unstructured stream data;
moreover, data sources are expected to be distributed across
different nodes of a given system, which means that the above-
described tasks should be easily deployable, replicated and ef-
ﬁciently connected in order to support continuous log.entropy
sampling. We used Apache Storm8 to develop a data analytics
implementation of the method because it well complies with
the mentioned challenges. Storm is a cutting-edge open-source
technology in the ﬁeld of big data analytics in both research
and industry; more than 60 companies are using Storm as their
real-time analytics technology, such as Twitter, Yahoo!, Spotify
and Groupon [34].
In the following we survey the key elements of Storm and
present their use in the context of our implementation.
A. Apache Storm: Overview
The data stream processing provided by Storm is performed
by means of Storm clusters. A cluster consists of a master and
8http://storm.apache.org/
Fig. 5: Method implementation: Storm topology.
383
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 09:58:24 UTC from IEEE Xplore.  Restrictions apply. 
The Monitoring Trajectory (MONT) runs on the MN1
node and provides the ﬂight progress monitoring, triggering
automatic trajectory recalculation when needed, e.g., in case
of conﬂict, or the intervention of the ATC controller when the
automatic recalculation is not allowed.
The Database Management (DBM) runs on the DB1 node
and manages the database used by the ATC system,
i.e.,
DB in Fig. 6. The database contains the data used by the
applications, such as radar parameters, conﬁguration of airports
with runways, and aircrafts performance.
The Controller Working Position (CWP) is the HMI dealing
with the interactive presentation of ﬂight plans, trajectories,
conﬂicts, weather and other support data to the ATC controller
operator. The controller can supply commands to the system
by means of the CWP as per some of the operations presented
in Section V-B; it is deployed on D02.
The communication among the system nodes running the
applications is performed by means of redundant LANs, i.e.,
the grey lines in Fig. 6. A dedicated LAN is also used for
monitoring purposes, i.e., the black line in Fig. 6.
B. System workload
The system is exercised with a workload developed on test
suites, which are used by the industry provider to emulate
the system usage by real CWP operators. Moreover, the ATC