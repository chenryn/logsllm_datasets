向量化（VECTORIZATION）
编码方式：
One-hot Vector/Encoding
输入向量
x(len(sentences), maxlen, len(chars))
输出向量
y(len(sentences),  len(chars))
序列数量
3,803,562
或256（yield）
单序列长度
50
字典长度
96
模型设计
2层LSTM（ LEARN&FUZZ 模型）
2LSTM  summary ...
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_1 (LSTM)                (None, 50, 128)           115200    
_________________________________________________________________
lstm_2 (LSTM)                (None, 128)               131584    
_________________________________________________________________
dense_1 (Dense)              (None, 96)                12384     
_________________________________________________________________
activation_1 (Activation)    (None, 96)                0         
=================================================================
Total params: 259,168
Trainable params: 259,168
Non-trainable params: 0
模型设计
3层LSTM
2层BLSTM
Total params: 505,952
Trainable params: 505,952
Non-trainable params: 0
Total params: 390,752
Trainable params: 390,752
Non-trainable params: 0
模型设计
Total params: 1,856,086
Trainable params: 1,856,086
Non-trainable params: 0
ATTENTION + 2层BLSTM
训练
训练参数：batch_size = 256    epoch = 60    optimizer = adam(lr=1e-4)，loss='categorical_crossentropy'
zit@Zitsec:~/zou/Longma$ python3 pdf_obj_model_training.py 
…….
Using TensorFlow backend.
2018-08-20 09:43:28.161940: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was 
not compiled to use: AVX2 FMA
2018-08-20 09:43:31.231878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: 
name: TITAN Xp COLLECTORS EDITION major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:02:00.0
totalMemory: 11.91GiB freeMemory: 11.74GiB
2018-08-20 09:43:31.231953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0
2018-08-20 09:43:31.623790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge 
matrix:
2018-08-20 09:43:31.623856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 
2018-08-20 09:43:31.623868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N 
2018-08-20 09:43:31.624255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device 
(/job:localhost/replica:0/task:0/device:GPU:0 with 11370 MB memory) -> physical GPU (device: 0, name: TITAN Xp COLLECTORS EDITION, pci bus id: 
0000:02:00.0, compute capability: 6.1)
Epoch 1/60
63232/3042849 [..............................] - ETA: 1:10:50 - loss: 3.6259 - acc: 0.2304
生成（GENERATION）
选取PREFIX STRING，向量化，加载模型，预测生成OBJ，并由OBJ生成PDF
Model
new objs
Attach to 
pdf host
New pdf 
files
Prefix 
string
Structure, parameters
3. Generation
Load 
model
predict
Vectorization
生成（GENERATION）
OBJ生成
PDF生成
样本生成阶段的两个重要的进程池
•
并行加载多个模型进行推断
•
并行生成多批次的obj和PDF样本
•
缩短实验周期，增强模型的可扩展性
Pdf生成主
进程
Model
new objs
new objs
new objs
new pdfs
new pdfs
new pdfs
Structure, parameters
Model
Model
进程池
obj生成主
进程
子进程1
子进程2
子进程n
进程池
子进程1
子进程2
子进程n
OBJ生成
•
若生成完整OBJ，则加入列表中；
•
若生成长度超过阈值，则回退、丢弃已生成的字符，重新从测试集中选择PREFIX生成
max_gen_len = 2000
前缀字符
串Prefix
选取obj前
缀字符串
转换成向
量
预测
Model
加载模型
加入到obj
字符串中
窗口向前移
动一个字符
采样
是否生成完整
obj
否
加入到obj
列表中
是
是否超过限定
长度
是
否
删除已生成的
obj字符串
索引
字典
下一个
字符
new 
objects
测试集
OBJ生成
1.0
0.2
0.5
0.8
1.2
1.5
1.8
概率分布差异性变小，生成文
本随机性变强，趋向于多样性、
随机的数据
概率分布差异性变大，生成
文本有序性变强，更接近真
实值的数据
temperature
采样函数
PDF生成
host
new obj1
new obj2
new objn
Header
Body
Cross-reference table
Trailer
obj
Cross-reference table
Trailer
obj
Cross-reference table
Trailer
obj
Cross-reference table
Trailer
new obj
Host pdf
附加新的obj到
pdf文件末尾
添加新的交
叉引用表
是否达到修改数量
定位host文件
trailer偏移
添加新的
trailer
是
否
以增量更新（Incremental update）的方式把新生成的obj附加到
host文件的末尾，实现对host文件中obj的更新和替换
PDF生成
宿主文件（HOST）
来源：pdfium测试集
大小：317 KB
obj总数：257
obj替换比例：1/10
实验分析
模型训练及样本生成
PDF样本测试
模型训练及样本生成
实验环境
模型训练结果分析
OBJ样本生成结果分析
PDF样本生成结果分析
实验环境
硬件环境
开发环境
前端
后端
Python 3.5
Ubuntu-16.04.2-desktop-amd64
TITAN Xp COLLECTORS EDITION   X4
E5-2683 v4 X2
256G
模型训练结果分析
训练轮次：60
zit@Zitsec:~/zou/Longma/pdf_corpus/saved_models/2BLSTM_epochs60$ ll
total 358568
drwxrwxr-x  2 zit zit
4096 7月 8 05:11 ./
drwxrwxrwx 34 zit zit
4096 8月 15 14:49 ../
-rw-rw-r-- 1 zit zit 6116568 7月 5 12:16 2BLSTM_epoch01.h5
-rw-rw-r-- 1 zit zit 6116568 7月 5 13:20 2BLSTM_epoch02.h5
-rw-rw-r-- 1 zit zit 6116568 7月 5 14:24 2BLSTM_epoch03.h5
-rw-rw-r-- 1 zit zit 6116568 7月 5 15:29 2BLSTM_epoch04.h5
-rw-rw-r-- 1 zit zit 6116568 7月 5 16:33 2BLSTM_epoch05.h5
-rw-rw-r-- 1 zit zit 6116568 7月 5 17:37 2BLSTM_epoch06.h5
-rw-rw-r-- 1 zit zit 6116568 7月 5 18:41 2BLSTM_epoch07.h5
-rw-rw-r-- 1 zit zit 6116568 7月 5 19:46 2BLSTM_epoch08.h5
-rw-rw-r-- 1 zit zit 6116568 7月 5 20:50 2BLSTM_epoch09.h5
-rw-rw-r-- 1 zit zit 6116568 7月 5 21:54 2BLSTM_epoch10.h5
-rw-rw-r-- 1 zit zit 6116568 7月 5 22:58 2BLSTM_epoch11.h5
-rw-rw-r-- 1 zit zit 6116568 7月 6 00:02 2BLSTM_epoch12.h5
-rw-rw-r-- 1 zit zit 6116568 7月 6 01:06 2BLSTM_epoch13.h5
-rw-rw-r-- 1 zit zit 6116568 7月 6 02:10 2BLSTM_epoch14.h5
-rw-rw-r-- 1 zit zit 6116568 7月 6 03:15 2BLSTM_epoch15.h5
-rw-rw-r-- 1 zit zit 6116568 7月 6 04:19 2BLSTM_epoch16.h5
-rw-rw-r-- 1 zit zit 6116568 7月 6 05:23 2BLSTM_epoch17.h5
-rw-rw-r-- 1 zit zit 6116568 7月 6 06:27 2BLSTM_epoch18.h5
-rw-rw-r-- 1 zit zit 6116568 7月 6 07:31 2BLSTM_epoch19.h5
-rw-rw-r-- 1 zit zit 6116568 7月 6 08:36 2BLSTM_epoch20.h5
-rw-rw-r-- 1 zit zit 6116568 7月 6 09:40 2BLSTM_epoch21.h5
-
模型
参数
训练时间
模型文件
大小（M）
2LSTM
259,168
1d 11h 
0m 35s
3.00
3LSTM
390,752
2d 1h 
38m 49s
4.51
2BLSTM
505,952
2d 16h 
54m 57s
5.83
Attention
1,800,786
3d 2h 
49m 5s
21.30
ACC曲线
LOSS曲线
OBJ生成结果分析
单进程生成10,000个obj
共计210,000obj       
时长：≈7小时
单进程总时长：7*21 = 147小时
单个文件大小：≈1.5MB
zit@Zitsec:~/zou/Longma/pdf_corpus/generated_objs/minset3/final_test_1wobj$ ll
total 179956
drwxrwxr-x  4 zit zit   20480 8月 17 11:31 ./
drwxrwxr-x 15 zit zit
4096 8月 15 17:23 ../
-rw-rw-r-- 1 zit zit 731780 8月 16 01:42 2BLSTM_epoch10.h5_diversity0.2.txt
-rw-rw-r-- 1 zit zit 1122762 8月 14 17:42 2BLSTM_epoch10.h5_diversity0.5.txt
-rw-rw-r-- 1 zit zit 1508494 8月 16 10:03 2BLSTM_epoch10.h5_diversity0.8.txt
-rw-rw-r-- 1 zit zit 1784072 8月 15 04:49 2BLSTM_epoch10.h5_diversity1.0.txt
-rw-rw-r-- 1 zit zit 2209887 8月 16 21:15 2BLSTM_epoch10.h5_diversity1.2.txt
-rw-rw-r-- 1 zit zit 2462241 8月 15 13:19 2BLSTM_epoch10.h5_diversity1.5.txt
-rw-rw-r-- 1 zit zit 2828212 8月 17 09:05 2BLSTM_epoch10.h5_diversity1.8.txt
-rw-rw-r-- 1 zit zit 915555 8月 16 02:21 2BLSTM_epoch20.h5_diversity0.2.txt
-rw-rw-r-- 1 zit zit 982013 8月 14 17:44 2BLSTM_epoch20.h5_diversity0.5.txt
-rw-rw-r-- 1 zit zit 1252198 8月 16 10:18 2BLSTM_epoch20.h5_diversity0.8.txt
-rw-rw-r-- 1 zit zit 1229084 8月 14 23:16 2BLSTM_epoch20.h5_diversity1.0.txt
-rw-rw-r-- 1 zit zit 1318517 8月 16 17:46 2BLSTM_epoch20.h5_diversity1.2.txt