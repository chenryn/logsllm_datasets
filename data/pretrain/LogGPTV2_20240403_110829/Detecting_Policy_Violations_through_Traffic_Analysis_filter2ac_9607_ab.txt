### Evaluation of Classification Process

The performance of the classification process is assessed using cross-validation [30] and confusion matrices. Cross-validation is a standard technique for evaluating machine learning algorithms. In this study, we employ 10-fold cross-validation, which involves randomly partitioning the dataset into 10 subsets. One subset is used as the test set, while the remaining nine are used as the training set for classifying the test samples. This process is repeated 10 times, with each subset serving as the test set once. The results from each fold are then combined to form a confusion matrix. The rows of the confusion matrix represent the actual class of an item, and the columns represent the classes to which the classification algorithm assigns the item. Confusion matrices provide insight into how well different classes are distinguished by the classification algorithm. Small variations in the results may occur due to the random partitioning of the dataset.

### Algorithm Description

The classification algorithm follows these steps:

1. **Load Known Data**: Load connection packet size probability distributions and other statistics for connections with known classifications.
2. **Generate Unknown Data Statistics**: Generate similar statistics for connections with unknown classifications.
3. **Measure Distance**: Calculate the "distance" between the statistics of the unknown connection and each known connection.
4. **Sort Scores**: Sort the distances in ascending order.
5. **Assign Class**: Assign the unknown connection to the same class as the majority (at least 3 out of 5) of the closest known connections.

### Frequency Distributions

The maximum packet size varies depending on the physical network medium. Our experiments were conducted on Ethernet networks, where the largest packet size is 1500 bytes, also known as the Maximum Transfer Unit (MTU). However, we only consider the amount of user data in each TCP segment, excluding IP and TCP headers. The user data size is further constrained by the TCP Maximum Segment Size (MSS), which can be influenced by the network MTU and firewall equipment. We set a maximum packet size of 1300 bytes, with larger packets being binned together.

Packets with no user data, such as TCP acknowledgment-only packets, were not included in the analysis. Each data point was assigned to one of 30 bins. This number of bins was chosen to balance the need to capture distribution features without being overly sensitive to minor variations. The bin sizes were kept integral, and any leftovers were distributed evenly across the bins.

After computing the packet size frequencies, the distribution was normalized to form a probability distribution suitable for use with selected distance measures.

### Distance Measures

Several distance measures can be used to compare the closeness of two probability distributions, including variational distance, harmonic mean, and Kullback-Liebler divergence. In this study, we used the Jensen-Shannon divergence [5] and the Bhattacharyya distance [15].

**Bhattacharyya Distance**:
\[ B(P, Q) = \sqrt{\sum_i p_i q_i} \]

**Jensen-Shannon Divergence**:
\[ D_{JS}(P || Q) = \frac{1}{2} \left( \sum_i p_i \log \frac{p_i}{\frac{p_i + q_i}{2}} + \sum_i q_i \log \frac{q_i}{\frac{p_i + q_i}{2}} \right) \]

In both equations, \( P \) and \( Q \) represent the two probability distributions being compared. \( P \) might represent a known distribution, and \( Q \) an unknown distribution. Both measures are symmetric, making the distinction between known and unknown less critical. The Bhattacharyya distance is simpler to compute, while the Jensen-Shannon divergence is symmetric and representative of divergence-type measures.

For each connection, we calculate two distance measures, one for client-sourced and one for server-sourced parts, forming a score vector. The final score is the magnitude of this vector, allowing for the easy incorporation of additional measures if needed.

### Additional Statistics

In addition to the probability distribution distance measures, we compute several other statistics to provide more insight into the type of activity during an SSH session:

1. **Bytes per Second**: For packets with inter-arrival times less than 2 seconds, this statistic captures the amount of data transferred during active periods.
2. **Packets per Second**: Computed similarly to bytes per second.
3. **Bytes per Packet**: A straightforward measure of the average packet size.
4. **Chain Analysis**: 
   - **Largest Number of Packets in Chains**: The packet size that accounts for the most packets in chains of at least 5 packets.
   - **Largest Number of Chains**: The packet size that forms the most chains.

These statistics help identify interactive sessions, as they typically involve many packets of similar size. Logarithms of these values are often used to reduce the range of variation and minimize the impact on other statistics.

### Experiments

#### Data Collection

The data collected includes full header and partial payload information from over 400 SSH sessions and 11.5 million packets, spanning from late 2005 to May 2006. Sessions included interactive, X11, file transfer, and web browsing activities, with some USENET news and Samba SMB/CIFS traffic. Most sessions were manually operated, and traffic was captured using tcpdump on either the source or sink, ensuring no double-counting.

#### Main Categories of Monitored Sessions

- **Interactive Sessions**: Activities like mail reading, programming, and system administration.
- **X11 Applications**: xterm, synaptic, Acrobat Reader, OpenOffice, xdvi, and ImageMagick.
- **Web Browsing**: Access to news sites, corporate sites, and development information.
- **File Transfer**: Small files transferred in both directions.

#### Network Connections

Sessions were established over various network types, including university and home networks, with and without SSH compression enabled. Traffic involving X11 forwarding, NoMachine NX, and Samba was restricted to local networks.

#### Session Identification

A Python script logged session details, including start time and user descriptions, to an SQLite database. This information was used to classify sessions into different categories.

#### Data Processing

Useful information, such as source and destination addresses, ports, TCP flags, and sequence numbers, was extracted and stored in the SQLite database. Connections were identified by SYN-flagged packets, and statistical information was calculated for each classified connection.

#### Results

We used 10-fold cross-validation to generate confusion matrices to evaluate the classification performance. Figures 1, 2, and 3 show sample cumulative probability distributions for interactive, web browsing, and compressed web browsing traffic, respectively. Each figure includes graphs for client-to-server and server-to-client traffic, with lines representing cumulative probabilities.

---

This revised text aims to provide a clear, coherent, and professional description of the classification process, evaluation methods, and experimental setup.