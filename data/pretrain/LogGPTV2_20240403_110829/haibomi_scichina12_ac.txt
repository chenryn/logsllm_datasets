2760 Mi H B, et al. Sci China Inf Sci December 2012 Vol. 55 No. 12| Call sequences | Figure 2 | Figure 2 | Basic structure of tracing logs. | Basic structure of tracing logs. | Basic structure of tracing logs. | Basic structure of tracing logs. | Basic structure of tracing logs. |
|---|---|---|---|---|---|---|---|
| Call sequences |A. Localizing anomalous methods |A. Localizing anomalous methods |A. Localizing anomalous methods |A. Localizing anomalous methods |A. Localizing anomalous methods |B. Localizing anomalous instances |B. Localizing anomalous instances || Call sequences |1). Clustering requests |2). Separating requ-ests to two parts |2). Separating requ-ests to two parts |3). Ranking the sus-picious methods |1). Creating histogram for each instance |1). Creating histogram for each instance |2). Comparing similarity |
| Call sequences |Normal |Normal |Normal |Normal |Normal |Normal |Normal || Call sequences |Abnormal |Abnormal |Instance1:  	 [0.1, 0.3, ..., 0.3]  Instance2: 	 [0.2, 0.1, ..., 0.2] 	 ... Instancen:  	 [0.3, 0.2, ..., 0.1] |Instance1:  	 [0.1, 0.3, ..., 0.3]  Instance2: 	 [0.2, 0.1, ..., 0.2] 	 ... Instancen:  	 [0.3, 0.2, ..., 0.1] |Instance1:  	 [0.1, 0.3, ..., 0.3]  Instance2: 	 [0.2, 0.1, ..., 0.2] 	 ... Instancen:  	 [0.3, 0.2, ..., 0.1] |Instance1:  	 [0.1, 0.3, ..., 0.3]  Instance2: 	 [0.2, 0.1, ..., 0.2] 	 ... Instancen:  	 [0.3, 0.2, ..., 0.1] |Instance1:  	 [0.1, 0.3, ..., 0.3]  Instance2: 	 [0.2, 0.1, ..., 0.2] 	 ... Instancen:  	 [0.3, 0.2, ..., 0.1] || Call sequences |Figure 3 |Figure 3 |Overview of the approach. |Overview of the approach. |Overview of the approach. |Overview of the approach. |Overview of the approach. |of performance problems with the trace logs in one time period. Furthermore, it does not differentiate the importance of invocation methods in call graphs and exhausts all related methods to localize the abnormal ones. Magnifier [27] performs an empirical study on localizing the performance bottlenecks. Troubleshooters are required to instrument the probes conforming to the naming specifications of the system architecture. This paper is free from this restriction.Other existing approaches aim at utilizing system resources [28–31] to learn models to detect per-formance anomalies; whereas, such models cannot detect performance anomalies with finer granularity (e.g., anomalous instances). Furthermore, it takes more time for them to train logs in exchange for the sufficient accuracy of inference.
3 	Sketch of the approachOur tracing mechanism explicitly instruments the target system and associates the activities of requests with global identifiers. Since the execution time of the invoked methods can directly reflect how the system performs a request, we choose to capture such execution time. Once the instrumented methods are invoked, a record with some contextual information will be kept into a log. 	Figure 2 shows the basic structure of the trace logs. Each line contains the current time stamp, the global identifier for the request, the name of the invoked methods, the label signifying the start or end of the invocation, and other redundant information. The call sequence of a user request can be constructed from the distributed trace logs according to the nested relationships of start/end flags. Usually, performance anomalies are directly reflected from the deviation of request latencies. Hence, these trace logs could be utilized to localize the primary causes of performance anomalies.Our approach contains two parts. First, we try to localize the anomalous methods with three sub-steps. Second, we try to localize the anomalous instances of service components with two sub-steps. The workflow of our approach is shown in Figure 3.
3.1 	Localizing anomalous methods
3.1.1 	Clustering requests3.1.1 	Clustering requests
Usually, user requests for the same service may have different types of call sequences. For example, the call sequence of reading files from the cache is different from that of reading files from the disk. Different
Mi H B, et al. Sci China Inf Sci December 2012 Vol. 55 No. 12 2761call sequences reflect different semantics; hence, we first cluster user requests into categories according to their call sequences. The requests within one category have the same method call sequence.
3.1.2 	Separating requests to normal and anomalous setsThe latencies of requests will be influenced when they pass through anomalous methods. 	We hope to localize the anomalous methods through comparing the behavior of normal requests with that of anomalous requests. Therefore, we need to identify anomalous requests within the same category, and then separate the normal and anomalous requests into two sets.
3.1.3 	Ranking suspicious methods3.1.3 	Ranking suspicious methods
Then, for invoked methods, the latency distributions in normal sets are compared with those in abnormal sets. A method is defined to be anomalous if the two latency distributions differ obviously. We pick out all suspicious methods and present the top k to operators.
3.2 	Localizing anomalous instancesThe target of this step is to help operators diagnose whether the behavior of methods becomes abnormal in all replicated instances or it just happens in parts of them. It helps operators further locate the primary causes of problems and understand the extent of the crisis. This process contains two sub-steps: (1) group the latencies of an anomalous method by the host addresses of instances and create histograms for each of them; (2) compare the similarities among these histograms and select the ones whose behaviors are mostly different from those of the others.4 	Localizing anomalous methods
4.1 	Clustering requestsHomogeneous replicated instances provide the same instrumented methods for the public. 	Identical requests may pass through different instances. Although the physical locations (i.e. replicated instances) of instrumented methods are important attributes, we cannot directly consider them during clustering. Suppose a request goes through three instrumented methods. The three methods belong to three kinds of services respectively and each service has one hundred homogenous instances deployed on one hundred 	100× C1 100= 1 × 106 kinds of physical paths, except for the hosts. In total, the request has C1 100× C1 failure paths. Actually, the number of instrumented methods that user requests invoke is far more than three. If the host addresses are involved in the process of clustering, it will cause too much computational complexity. Hence, we first cluster requests without considering the physical information.An incremental clustering algorithm [25] is applied. For a request i, all its relevant methods could be stitched together by the request identifier, and its call sequence Seqi = ⟨(m)ij⟩ can be constructed. within one cluster have the same string representation. The string representations are defined as the Then a corresponding string representation m1m2 · · · mj can be created from the call sequence. Requests centroids for clusters. The distance metric is the string-edit-distance. For a new request, the cluster calculates the distance between the string representation of the request and the centroid of each cluster. The request will be added into the cluster with the zero distance, unless there is no zero distance, in which case a new cluster is created. The whole process of clustering can be finished by traversing all call sequences just one time.4.2 	Separating requests to normal and anomalous sets
When performance anomalies occur, normal and anomalous requests may share the same call sequence and be grouped into one cluster; hence, for each cluster, we hope to first identify the anomalous requests. Since we do not need domain specific knowledge, an unsupervised machine learning algorithm (i.e., principal component analysis) is utilized to achieve the goal.| 2762 | Mi H B, et al. | Mi H B, et al. | Mi H B, et al. | Mi H B, et al. | Sci China Inf Sci | December 2012 Vol. 55 No. 12
1.0 | December 2012 Vol. 55 No. 12
1.0 | December 2012 Vol. 55 No. 12
1.0 | December 2012 Vol. 55 No. 12
1.0 | December 2012 Vol. 55 No. 12
1.0 | December 2012 Vol. 55 No. 12
1.0 | December 2012 Vol. 55 No. 12
1.0 |
|---|---|---|---|---|---|---|---|---|---|---|---|---|| Ratios of Req. number to Seq. length | 100 | 100 | 10 |ListFile  SaveFile ReadFile | 100 |December 2012 Vol. 55 No. 12 1.0 |December 2012 Vol. 55 No. 12 1.0 |December 2012 Vol. 55 No. 12 1.0 |December 2012 Vol. 55 No. 12 1.0 |December 2012 Vol. 55 No. 12 1.0 |December 2012 Vol. 55 No. 12 1.0 |December 2012 Vol. 55 No. 12 1.0 || Ratios of Req. number to Seq. length | 10 | 10 | 10 |ListFile  SaveFile ReadFile | 100 |Cumulative request ratios |0.9 | 1 | 1 | 10 |α = 0.75 | 100 |
| Ratios of Req. number to Seq. length | 10 | 10 | 10 |ListFile  SaveFile ReadFile | 100 |Cumulative request ratios |0.8 | 1 | 1 | 10 |α = 0.75 | 100 |
| Ratios of Req. number to Seq. length | 1 | 1 | 10 |ListFile  SaveFile ReadFile | 100 |Cumulative request ratios |0.7 | 1 | 1 | 10 |ListFile  SaveFile ReadFile | 100 || Ratios of Req. number to Seq. length | 1 | 1 | 10 |ListFile  SaveFile ReadFile | 100 |Cumulative request ratios |0.6 | 1 | 1 | 10 |ListFile  SaveFile ReadFile | 100 |
| Ratios of Req. number to Seq. length | 0.1 | 0.1 | 10 |ListFile  SaveFile ReadFile | 100 |Cumulative request ratios |0.6 | 1 | 1 | 10 |ListFile  SaveFile ReadFile | 100 || Ratios of Req. number to Seq. length | 0.01 	 1 | 0.01 	 1 | 10 |ListFile  SaveFile ReadFile | 100 |Cumulative request ratios |0.4 | 1 | 1 | 10 |ListFile  SaveFile ReadFile | 100 |
| Ratios of Req. number to Seq. length | 0.01 	 1 | 0.01 	 1 | 10 |ListFile  SaveFile ReadFile | 100 |Cumulative request ratios |0.4 | 1 | 1 | 10 |ListFile  SaveFile ReadFile | 100 || Cluster ID |Cluster ID |Cluster ID |Cluster ID |Cluster ID |Cluster ID |Cluster numbers |Cluster numbers |Cluster numbers |Cluster numbers |Cluster numbers |Cluster numbers |Cluster numbers || Figure 4 |Figure 4 |Ratios of the request number in each cluster |Ratios of the request number in each cluster |Ratios of the request number in each cluster |Ratios of the request number in each cluster |Figure 5 |Figure 5 |Figure 5 |Cumulative ratios of the request number in |Cumulative ratios of the request number in |Cumulative ratios of the request number in |Cumulative ratios of the request number in || to the length of corresponding call sequence. |to the length of corresponding call sequence. |to the length of corresponding call sequence. |to the length of corresponding call sequence. |to the length of corresponding call sequence. |to the length of corresponding call sequence. |each cluster to the total requests. |each cluster to the total requests. |each cluster to the total requests. |each cluster to the total requests. |each cluster to the total requests. |each cluster to the total requests. |each cluster to the total requests. |Principal component analysis (PCA) is a useful algorithm for high-dimensional data compression and is widely adopted in anomaly detection [32–34]. Two conditions need to be satisfied for the input data of PCA. First, the number of observations must be greater than or equal to that of their variants, i.e., PCA requires the number of requests to be greater than or equal to the length of the corresponding call sequences. Second, the high-dimensional data should have the low dimensionality. Hence, for each cluster, we have to check whether the trace data satisfies these two conditions.4.2.1 	Checking the characteristic of the clusters
From Figure 4, we can see that the request numbers in most clusters are smaller than the lengths of the corresponding call sequences. It means that most clusters cannot satisfy the first condition. In other words, these clusters cannot be directly utilized by PCA. This figure contains three kinds of applications in our study. The x-axis is the cluster identifier and the y-axis represents the ratio of the request number in a cluster to the length of corresponding call sequence.Although it is statistically meaningless to use PCA for these small clusters, we cannot discard them. These clusters cannot be dropped since the summed effect of the long tail is equally important to those of large clusters. Figure 5 shows that although just a small proportion of clusters (statistically less than 10%) contains over 75% of all requests, the summed request number in left 90% clusters still takes up about 25% of all requests. The x-axis is the cluster number and the y-axis is the cumulative percent ratio. For instance, the ratios of requests for the SaveFile operation in the first two clusters are 0.40 and 0.25 respectively and the sum of the remaining ratios for the other clusters is 0.35, which has a statistically significant influence on the false-negative rate of the diagnosing process (see Section 7). Therefore the clustering result of the step one should be adjusted further in order to utilize all clusters.The target of adjustment is to select major clusters and merge the minor ones into them. Clusters with the large ratios of requests are defined as major clusters and those with the small ratios are defined as minor clusters. There are many algorithms for us to choose; here a simple heuristic algorithm is adopted.(1) Selecting major clusters. First, all clusters are ranked in descending order of sizes (i.e., the ratios of requests). Then, clusters are selected until their summed ratios are larger than a threshold α. These selected clusters are considered as the major clusters.(2) Merging minor clusters into major ones. All the other clusters are traversed in order. The similar-ities between the centroid of each minor cluster and the ones of major clusters are computed. A minor cluster will be merged into the major one with the largest similarity. The measurement of similarity has two standards: first, the string-edit-distance is the nearest; second, the number of invoked methods in minor clusters is larger than or equal to that of major clusters.The detailed algorithm is shown in Algorithm 1. We set the threshold α to adjust the cluster numbers, as shown in Figure 5. In our application, there are on average 3 to 5 major clusters for each kind of user request.
Then, we check if the trace data in major clusters meets the second condition. For each major cluster,
Mi H B, et al. Sci China Inf Sci December 2012 Vol. 55 No. 12 2763Algorithm 1: Adjustment of clusters
Input: Cseq = ⟨(c, n)i⟩, a call sequence list of clusters, where c is the centroid of cluster and n is the 	ratio of requests.
Output: Cmain = ⟨(c, n)i⟩, a call sequence list of main clusters.
Cseq.Sort(reverse = True) 
sum ratio = 0; 
Cmain = []; 
main token = 0; 
/*Selecting */ 
for i in range(len(Cseq)) do
| c ratio = Cseq[i][1]; 
sum ratio+ = c ratio;sum ratio+ = c ratio; 
if sum ratio > α then | c ratio = Cseq[i][1]; 
sum ratio+ = c ratio; 
if sum ratio > α then |
|---|---|
|  |main token = i;  break; |
| end |end |
end 
/*Merging */ 
for i in range(main token + 1,len(Cseq)) do 
	max sim = 0;
	end 	Cmain[token][1]+ = Cseq[i][1];
	end
	max sim = sim; 
	token = j; 
token = 0; 
for j in range(len(Cmain)) do 
	sim = Similarity(Cseq[i][0], Cmain[j][0]);if max sim < sim then
end
we construct a matrix Y with its requests. 	The element Yij denotes the execution time of the jth method in the call sequence of the ith request. We observe that all these matrices have the low intrinsic dimensionality. For example, Figure 6 plots the cumulative variance distribution of the invoked methods for four major clusters in our application. Just as the traffic datasets studied in [35], Figure 6 shows that a small set of principal components captures the large percent of the total variance, which demonstrates that the trace data in major clusters satisfies the requirement of PCA.4.2.2 	Separating requests into two sets
Determining principal components. For a cluster containing m requests, suppose there are n invoked methods for the corresponding call sequence (i.e., the length of this call sequence is n), we can construct an m × n latency matrix Y . The value of each element is the response latency for the method in the corresponding request. Row i is the n-dimensional latency vector for the ith request while column j is the m-dimensional latency vector of the jth method in all call sequences. After adjusting Y to ensure that each column has the zero-mean, we apply PCA to get k principal components (PCs). Along these k PCs, the requests are captured with a majority of total variance.Identifying anomalous requests. The set of principal components can be utilized to construct a matrix P , which represents the norm subspace of the corresponding cluster. On the contrary, the remaining components can form a matrix I − P PTdenoting the anomalous subspace. For each major cluster, we separate their requests into the normal set and the anomalous set according to the distances of| 2764 | Cumulative percent variance |  1.00 | Mi H B, et al. | Mi H B, et al. | Sci China Inf Sci | Sci China Inf Sci | Sci China Inf Sci | December 2012 Vol. 55 No. 12 | December 2012 Vol. 55 No. 12 | December 2012 Vol. 55 No. 12 |  100 |
|---|---|---|---|---|---|---|---|---|---|---|---|
| 2764 |Cumulative percent variance | 1.00 | 10 |Cluster1 |Cluster1 | 100 |Cumulative percent variance | 1.00 | 10 |Cluster2 | 100 || 2764 |Cumulative percent variance | 0.95 | 10 |Cluster1 |Cluster1 | 100 |Cumulative percent variance | 0.95 | 10 |Cluster2 | 100 |
| 2764 |Cumulative percent variance | 0.90 | 10 |Cluster1 |Cluster1 | 100 |Cumulative percent variance | 0.95 | 10 |Cluster2 | 100 |
| 2764 |Cumulative percent variance | 0.85 | 10 |Cluster1 |Cluster1 | 100 |Cumulative percent variance | 0.90 | 10 |Cluster2 | 100 || 2764 |Cumulative percent variance | 0.80 | 10 |Cluster1 |Cluster1 | 100 |Cumulative percent variance | 0.85 | 10 |Cluster2 | 100 |
| 2764 |Cumulative percent variance | 0.75 | 10 |Cluster1 |Cluster1 | 100 |Cumulative percent variance | 0.85 | 10 |Cluster2 | 100 |
| 2764 |Cumulative percent variance | 0.70 | 10 |Cluster1 |Cluster1 | 100 |Cumulative percent variance | 0.80 | 10 |Cluster2 | 100 || 2764 |Cumulative percent variance | 0.65 | 10 |Cluster1 |Cluster1 | 100 |Cumulative percent variance | 0.80 | 10 |Cluster2 | 100 |
| 2764 |Cumulative percent variance | 0.60 	 1 | 10 |Cluster1 |Cluster1 | 100 |Cumulative percent variance | 0.75 	 1 | 10 |Cluster2 | 100 |
| 2764 |Cumulative percent variance | 1.00 |PC numbers |PC numbers |PC numbers |PC numbers |PC numbers |PC numbers |PC numbers |PC numbers | 100 || 2764 |Cumulative percent variance | 1.00 | 10 |Cluster3 |Cluster3 | 100 |Cumulative percent variance | 1.00 | 10 |Cluster4 | 100 |
| 2764 |Cumulative percent variance | 0.95 | 10 |Cluster3 |Cluster3 | 100 |Cumulative percent variance | 0.95 | 10 |Cluster4 | 100 |