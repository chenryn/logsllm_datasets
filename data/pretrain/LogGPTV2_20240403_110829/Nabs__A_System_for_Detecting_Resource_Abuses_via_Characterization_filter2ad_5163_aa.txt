title:Nabs: A System for Detecting Resource Abuses via Characterization
of Flow Content Type
author:Kulesh Shanmugasundaram and
Mehdi Kharrazi and
Nasir D. Memon
Nabs: A System for Detecting Resource Abuses via Characterization
of Flow Content Type
Kulesh Shanmugasundaram
Mehdi Kharrazi
Nasir Memon
PI:EMAIL
PI:EMAIL
PI:EMAIL
Polytechnic University
Brooklyn, NY11201
Abstract
One of the growing problems faced by network ad-
ministrators is the abuse of computing resources by
authorized and unauthorized personnel. The nature
of abuse may vary from using unauthorized applica-
tions to serving unauthorized content. Proliferation of
peer-to-peer networks and wide use of tunnels makes
it diﬃcult to detect such abuses and easy to circum-
vent security policies. This paper presents the design
and implementation of a system, called Nabs, that
characterizes content types of network ﬂows based
solely on the payload which can then be used to iden-
tify abuses of computing resources. The proposed
method does not depend on packet headers or other
simple packet characteristics hence is more robust to
circumvention.
1 Introduction
Abuse of computing resources is one of the growing
problems. Network administrators deal with a vari-
ety of abuses such as, network bandwidth by unau-
thorized application services, and the distribution of
unauthorized content to name a few. Abusers can be
malicious attackers looking for free resources to host
their illegal activities, a malicious insider running a
peer-to-peer hub, or simply an ill informed user unin-
tentionally running an application proxy.
The two most common defenses that are used to
prevent network abuses are ﬁrewalls and Intrusion De-
tection Systems (IDS). An IDS is not useful in de-
tecting many types of abuses where the essence of the
abuse is not captured by a simple set of signatures.
Firewalls, on the other hand, are more eﬀective in pre-
venting abuse. Firewalls use port blocking to thwart
unauthorized application services. For instance, if a
security policy denies the use of web servers inside a
network then a ﬁrewall simply blocks traﬃc to port
80.
However, it is now well known that a ﬁrewall can
be circumvented. For example, most ﬁrewalls do not
block outbound connection requests. A malicious in-
sider or a host inside the network compromised by an
attacker can initiate a connection and transfer unau-
thorized data or make available an unauthorized ser-
vice without being detected by a ﬁrewall. Another
simple way to bypass the ﬁrewall would be to simply
run the unauthorized service on a port that the ﬁre-
wall allows traﬃc on. So for example, if the ﬁrewall
blocks services on port 80 and leaves port 22 open so
that users can telecommute, then a web server can be
conﬁgured to use port 22, thereby circumventing the
security policy. A third way to get past the ﬁrewall
is by tunneling. Tunneling works by encapsulating a
network protocol within packets carried by another
protocol. So in the above example, with the presence
of a suitable proxy on the inside host, web traﬃc could
be tunneled through SSH traﬃc on port 22. Similarly,
there are many other techniques to get past a ﬁrewall,
given a malicious insider or a captured host inside the
target network.
Firewall circumvention techniques give rise to new
challenges in abuse detection. Current state-of-the-
art in abuse detection is to simply use port blocking
or bandwidth throttling. Routers simply monitor the
bandwidth usage of hosts and enforce throttling when
it exceed a preset limit. This is not always an eﬀective
solution as the bandwidth may be used for legitimate
purposes. There have been some research work in
identifying application types in the presence of weak
port binding [4, 13]. However, we believe the knowl-
edge of content carried by network ﬂows gives better
granularity on detecting abuse more robustly than the
methods presently used. Therefore, the method pro-
posed in this paper does not rely on packet header
information for Flow Content Characterization. By
ﬂow content characterization we mean the ability to
classify network packet contents as belonging to one
of a set of data types like audio data, encrypted data,
video data etc. Note that our intention is not to iden-
tify the application being used but to identify the type
of content emanating from a host or a network ﬂow
in general.
A naive method to characterize ﬂow content is to
simply use the media headers of various ﬁle types,
Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC’04) 
1063-9527/04 $ 20.00 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 11:38:35 UTC from IEEE Xplore.  Restrictions apply. 
like the file(1) command on Unix systems. Such
as approach has many problems. First of all, me-
dia headers (like the JPEG headers or MPEG head-
ers) can be modiﬁed easily. Therefore, it is easy to
circumvent a method that relies on the header infor-
mation. On the other hand, not every single packet
contains header information. For instance, suppose
there is a 200KB JPEG image. When transmitted
over network this image will be split into around 200
packets and only one of them contains the header.
A header based monitoring system must be able to
examine each packet on the network for the string
“JFIF” to determine the content type is a JPEG im-
age. Such a method will also result in false positives
as the string “JFIF” could appear in a JPEG image or
in a text ﬁle. In order to minimize such false positives
the method would require some context information
be maintained to properly identify the text. This is
obviously a very expensive process in terms of pro-
cessing power and memory and such an approach is
not viable on large networks where traﬃc volume is
high. Besides, packet drops and asymmetric routing
may result in this method losing the packet that has
the header information rendering it useless. Also note
that some media types do not have headers at all.
For example, plain-text and encrypted content usu-
ally have no headers to indicate their content type.
Hence, the proposed method does not rely on media
headers. The method samples packets from a net-
work, groups them into ﬂows and uses the group of
packets to characterize the ﬂow content based on its
statistical properties.
The rest of the paper is organized as follows:
in
the following section we present an overview of Nabs.
Subsequent sections, Section 3, Section 4, and Sec-
tion 5, discuss various components of the system in
detail.
In Section 6 we discuss deployment and ex-
periences gained while running this system in a live
network. Related work is presented in Section 7 and
we conclude with a summary of current accomplish-
ments and future work in Section 8.
2 Overview of Nabs
Nabs is a tool developed for characterizing the con-
tent types of ﬂows. Information about content types
of ﬂows can signiﬁcantly improve various applications
such as, resource provisioning, QoS policy develop-
ments, traﬃc accounting, and billing. Furthermore, a
system like Nabs also has the potential to be an intru-
sion detection system. In this paper, however, we fo-
cus on its application for detecting abuse of resources.
Abuse can be deﬁned as an act considered unaccept-
able by the community sharing resources. In the pres-
ence of a use policy, which formally deﬁnes acceptable
acts, abuse can be deﬁned precisely as any deviation
from the use policy. Use policies are currently deﬁned
using parameters like bandwidth usage, port numbers,
and type of applications. For instance, a use policy
may state that a user’s net bandwidth limit is 2GB
per month. This leads to inconveniences to users who
use up the bandwidth to download legitimate content.
Besides, these parameters can be easily manipulated
hence use policies that rely on such parameters are
easily subverted. Flow content characterization allows
us to incorporate content types into use policies. It
is more diﬃcult to manipulate content types because
of the diﬃculty in changing the underlying statistical
properties of one content type to another without dis-
torting the original content. Therefore, incorporating
content types makes use policies more expressive and
robust against subversion. Now, we can restate the
above use policy as a user’s net bandwidth on mul-
timedia content (audio, video, images) is limited to
2GB per month, which is more user friendly.
Nabs is currently deployed in our network and mon-
itors all TCP, UDP ﬂows. Figure 1 illustrates an
overview of the system’s design. It collects network
packets and groups them into ﬂows, characterizes the
content of each ﬂow, and stores the results for future
use. It has three major components to achieve these
tasks, which we brieﬂy discuss in the rest of this sec-
tion.
that have
this paper,
Flow Collection & Throttling. For the pur-
a ﬂow is deﬁned as a
poses of
set of packets
identical quine-tuple
P rotocol, SourceIP, DestinationIP, SourceP ort,
DestinationP ort. The ﬂow collection component
sniﬀs the network and captures all traﬃc passing
through a monitoring point. Packet capture and ﬁlter-
ing is accomplished using libpcap and BPF ﬁlters [2].
Packets that pass through the ﬁlter are then grouped
into ﬂows and scheduled in the ﬂow-table to be picked
up for ﬂow characterization.
Flow Characterization. Flow characterization
component constantly sweeps the ﬂow-table for ﬂows
that have accumulated necessary data (16KB of pay-
load, for example). When such a ﬂow is found it is
subsequently removed from the ﬂow-table and pro-
cessed to identify the type of its content. Output from
ﬂow characterization, of the form , is then stored in a
database or used to answer queries in real-time as
described below.
flow-id is the concatenation of
quine-tuple mentioned above, flow-type is the con-
tent type of the ﬂow as determined by the classiﬁer,
and auxiliary-data includes number of packets and
bytes in the ﬂow.
Storage. Output from the classiﬁer can be stored
directly to a database. However, the storage space
required to store this data outweighs the usefulness of
Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC’04) 
1063-9527/04 $ 20.00 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 11:38:35 UTC from IEEE Xplore.  Restrictions apply. 
Figure 1: Architecture of The Proposed System
such ﬁne grained data. Storage requirements can be
eased by summarizing the results without loosing too
much information in the process. Currently we have
implemented a simple summarization technique that
merges duplicate {flow-ids, flow-type} pairs from
the output and stores the resulting data set.
User Interaction & Query Processing. A user
can extract necessary information from the database
via a user interface using a SQL-like query language.
Query processing has two major components. One
of them is dedicated to continuous queries and the
other to instantaneous or one-time queries. Contin-
uous queries process the characterization results as
a stream and updates the results in real-time. Con-
tinuous queries are useful for monitoring networks in
real-time for such information as “What are the top-
k sources of audio in the network now?” or “What
are the type of ﬂows emanating from host x now?”
Instantaneous queries, on the other hand, are carried
out on data stored in the database and are useful for
analysis of events postmortem.
3 Flow Collection & Throttling
Flow characterization requires a certain minimum
amount of payload per ﬂow to determine the con-
tent type. Until the required payload is accumulated
ﬂows are buﬀered in the ﬂow-table. This arrangement
necessitates a garbage collector which prevents ﬂows
that do not carry the required minimum from occupy-
ing precious memory. Two major factors stand in the
way of optimizing memory utilization. First, small
insigniﬁcant ﬂows take up valuable space in the ﬂow-
table preventing interesting ﬂows from being buﬀered.
Second, even among the interesting ﬂows we may not
need to look at every single packet to characterize the
ﬂow. Therefore, packets must go through a mecha-
nism that throttles packets based on a preset strat-
egy. Please note that the system is a passive mon-
itor and when we say “throttle” we mean throttling
ﬂows entering the system and not throttling the ﬂows
themselves. We now describe the throttling strategy
currently used.
Throttling & Lossy Counting. Throttling ﬂows
would require us to keep track of ﬂow rates (pack-
ets per second or bandwidth) of all ﬂows entering the
system. Naive approach of building a table to keep
track of ﬂows consumes too much memory. What we
need is an eﬃcient and ﬂexible way of measuring ﬂow
rates. Over the years various data structures and algo-
rithms have been developed for this purpose. For our
implementation we choose one such algorithm, lossy
counting [6], for the following reasons:
Deterministic: Among the many probabilistic al-
gorithms lossy counting is one of the few deterministic
algorithms that can maintain an -deﬁcient synopsis
of data within the error bounds speciﬁed by user.
It is an one-pass algorithm
Streaming Algorithm:
which means lossy counting computes the necessary
information on a single pass over the data. It is, there-
fore, well suited for network streams.
It is computationally ef-
Eﬃciency & Footprint:
ﬁcient requiring only a few additions and comparisons
per packet. The data structure is easy to maintain,
has small memory footprint, and self pruning.
We now brieﬂy describe lossy counting and refer the
readers to [6] for a detailed description and analysis
of the algorithm and to [8] for an excellent survey on
data stream algorithms in general.
Proceedings of the 20th Annual Computer Security Applications Conference (ACSAC’04) 
1063-9527/04 $ 20.00 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 11:38:35 UTC from IEEE Xplore.  Restrictions apply. 
Lossy Counting. Lossy counting is a streaming al-
gorithm that can deterministically compute approxi-
mate frequency counts of elements exceeding a user-
speciﬁed threshold in a space eﬃcient manner. More
formally, suppose N denotes the length of current
stream and s,  are two user-speciﬁed parameters sup-
port and error respectively, then lossy counting esti-
mates the frequency of elements in the stream whose
true frequency exceeds sN with the guarantee that
the estimated frequencies are utmost N less than the
true frequencies by using utmost 1
 log(N) space.
The algorithm works as follows: the data stream is
conceptually divided into buckets of width w = (cid:1) 1
(cid:2)
elements each. Buckets are labeled with bucket ids
starting with 1 and let current bucket id be bcurrent
whose value is N. A table D of rows of the form
(e, f, ∆) is maintained where e is the element, f is the
frequency, and ∆ is the value of (bcurrent − 1) when
Initially D is empty.
e was inserted into the table.
Whenever an element e arrives , the algorithm ﬁrst
looks up table D to see if the element is listed.
If
so, then frequency f is incremented by one for the
corresponding entry. Otherwise, an entry of the form
(e, 1, bcurrent−1) is inserted into D. Table D is pruned
at bucket boundaries, whenever N ≡ (0 mod w), by
removing entries where f + ∆ ≤ bcurrent. Note that
for an entry e in D, f denotes the exact frequency of e
ever since it is inserted into D. Now to ﬁnd elements
exceeding threshold s we simply walk through entries
in D and extract entries where f ≥ (s − )N.
We use lossy counting to keep track of the ﬂow rate
of each ﬂow and at bucket boundaries we obtain a list
of ﬂows which exceeds the user-speciﬁed threshold s.
All ﬂows that do not satisfy this threshold are dis-
carded and those that satisfy the threshold are put
into the ﬂow-table. For example, setting  = 0.001
and s = 0.01 would result in ﬂows that exceed 1%
of total traﬃc be placed in the ﬂow-table. Since lossy
counting has no false negatives none of the ﬂows above
1% will be missed. However, ﬂows that are between
0.9% and 1% might or might not appear in the stream
and are false positives. This is a good trade-oﬀ be-
tween accuracy and resources as we will never miss
ﬂows that we are interested in (above 1% of total traf-
ﬁc) and will eliminate most of the ﬂows that we are not
interested in (below 0.9%) but only incur some over-
head in processing the false positives (between 0.9%
and 1%).
The above throttling technique and packet ﬁltering
together gives us better control over precisely which
ﬂows should be monitored by the system. For in-
stance, we have the ﬂexibility to specify something
like “consider only TCP or UDP ﬂows to or from
ports above 1024 that occupy more than 1% of total
traﬃc.” This is a considerable advantage when mon-
itoring traﬃc on large networks.
4 Flow Characterization
This component is responsible for determining content
types of ﬂows buﬀered in the ﬂow-table. In order to
distinguish between a variety of ﬂow content types,
we looked at the payload of each packet as a vector of
bytes. Thus, our goal was to come up with a model
that would help us distinguish these vectors based on
their respective statistical signatures. The statistical
measures we used to build the model can be grouped
into three broad categories:
Time Domain. We choose a number of simple
statistical measures from the time domain. Al-
though some of these measures are simple and rudi-
mentary, they help greatly in distinguishing content
types. These measures were, mean, variance, auto-
correlation, and entropy. For example one would ex-
pect that RAW data formats such as, bitmap im-
ages, or .WAV audio, to have lower entropy than com-
pressed or encrypted formats. This is evident in Fig-
ure 2, which shows the average entropy of data frag-
ments for 1000 ﬁles in each of the 8 major content
types. A discussion of the data set used can be found
in Section 4.1. Similar reasoning justiﬁes the use of
variance and auto-correlation as well.
y
p
o
r
t
n
E
.
g
v
A
8
7
6
5
4
3
2
1
0
TXT
BMP
WAV
ZIP
JPG
MP3
MPG
ENC
Figure 2: Average entropy of data vectors from 8 dif-
ferent ﬁle types.
Inspecting the frequency do-
Frequency Domain.