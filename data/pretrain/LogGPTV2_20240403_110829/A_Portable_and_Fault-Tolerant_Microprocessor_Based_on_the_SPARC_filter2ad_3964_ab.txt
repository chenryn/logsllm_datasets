to the processor which will take a corresponding data/
instruction error trap. The taken trap will then always be
‘precise’, and software recovery by roll-back/roll-forward
is simpliﬁed since no instructions have been executed
beyond the error.
4.7  Master/Checker mode
The processor
implements a checker mode, which
allows two LEON processors to operate concurrently in
master/checker conﬁguration. In the checker mode, all out-
puts are disabled and the internal values which should have
been driven are compared to the values which are driven by
the master device. A discrepancy will assert an error output
on the checker device. This feature can be used in applica-
tions with extremely high requirements on error-detection,
but is mostly used during SEU testing [5]. Note that the
correction of register ﬁle or cache memory errors will also
result in a master/checker error since the execution in the
two processor will be skewed. This limits the usage of the
master/checker conﬁguration, since a reset is necessary to
synchronize the two processors.
4.8  Software considerations
The data in caches and register ﬁle is only checked for
errors when accessed, and the probability of undetected
multiple errors will increase if stored data is not regularly
used. Most tasking kernels (such as VxWorks or RTEMS)
writes all active register windows to the stack on each task
switch, which will automatically correct any latent errors in
the process. Error build-up in the register ﬁle should thus
not be a problem. The caches are not ﬂushed on task
switches, but with a reasonably large program, all cache
contents should be regularly replaced or accessed, and any
latent errors over-written. There is however no easy way of
determining for how long a cache line might stay active in
the cache without being accessed. In small programs, a
cache ﬂush could therefore periodically be performed to
force a refresh of all cache contents.
5. Implementation
5.1  Design style and portability
The LEON processor is implemented as a high-level
VHDL model, fully synthesisable with common synthesis
tools such as Synopsys, Synplify and Leonardo. The model
is extensively conﬁgurable through a conﬁguration pack-
age. Options such as cache size and organization, multiplier
implementation, target technology, speed/area trade-off and
fault-tolerance scheme can be set by editing constants in the
conﬁguration package.
The only technology-speciﬁc cells used in the design are
ram mega-cells for cache memories and register ﬁle, and
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:23:37 UTC from IEEE Xplore.  Restrictions apply. 
pads. To keep the design portable, a package with wrappers
is made for each technology, providing a uniform interface
between the processor and the custom technology cells.
Porting LEON to a new target technology only consists of
making a new wrapper package for the target technology.
The design is fully synchronous, has only one clock, and
uses only registered inputs and outputs. This makes synthe-
sis simple, and improves portability further.
5.2  Synthesis overhead - Atmel ATC25
Making the model highly conﬁgurable makes it possible
to quickly analyze the impact of the fault-tolerance func-
tions. In table 1 below, the synthesis results for an FPU-less
LEON conﬁguration is shown for the Atmel ATC25 (0.25
µm) CMOS technology. The the core area is given for a
standard conﬁguration versus a conﬁguration with fault-tol-
erance. The two conﬁgurations are functionally identical
but the fault-tolerant version uses TMR on all ﬂip-ﬂops, 2
parity bits on the cache rams, and 7-bit BCH code on the
register ﬁle.The area overhead for the LEON core without
ram blocks is around 100%. This was expected since a
TMR cell is approximately 4 times the size of a normal ﬂip-
ﬂop (3x ﬂip-ﬂops + voter), and a non-TMR conﬁguration
uses 20% of the area for ﬂip-ﬂops. The overhead including
ram cells is only 39% since the overhead for parity and
BCH checkbits is lower. This particular conﬁguration is
heavily pad-limited on a 0.25 µm process, and if manufac-
tured, the area overhead at chip level would in fact be 0%.
The timing penalty for the fault-tolerant version is the extra
delay through the TMR voter, approximately two gate-
delays or 8% of the cycle time.
TABLE 1. LEON synthesis results on Atmel ATC25
Area
(mm2)
0.86
0.17
0.45
0.19
2.42
4.09
Area incl.
FT
1.61
0.35
0.90
0.24
2.59
5.69
Increase
87%
105%
100%
26%
7%
39%
Module
Integer unit (+ mul/div)
Cache controllers
Peripheral units
Register ﬁle (136x32)
Cache mem. (16 Kbyte)
Total
5.3  LEON-Express
The ﬁrst silicon implementation of LEON was made on
the Atmel ATC35 process. The device was code-named
‘LEON-Express’ and was manufactured in January 2001. A
standard-cell library without any SEU hardening features
was used. The chip is roughly 40 mm2 and operates at 50
MHz (military temperature, worst-case conditions). The
purpose of the LEON-Express device was to validate the
operation of the LEON processor and demonstrate the
implemented fault-tolerance techniques, it will not be com-
mercialized. Figure 4 shows the ﬂoorplan. The device is
pad-limited and to minimize manufacturing costs, only
three metal layers were used.
Figure 4: LEON-Express ﬂoor-plan
6. Heavy-ion error injection
To test the SEU protection methods, the LEON-Express
device was submitted to heavy-ion error injection at the
Louvain Cyclotron Facility in Belgium. The purpose of the
tests was to measure the SEU sensitivity of the device to
ions at different energy levels, and to assess the efﬁciency
of the fault-tolerance logic. A test board with two LEON
devices was designed, connected in master/checker mode.
The built-in master/checker comparators of LEON makes it
possible to run the device at full speed and yet compare the
outputs on each clock cycle. Figure 5 below shows the SEU
test board (checker device not mounted).
Three type of test programs were used: IUTEST that
continuously checks the register ﬁle and caches memories
for errors, PARANOIA that checks the FPU operation, and
CNCF which is based on real spacecraft navigation soft-
ware. Each test program is self-checking and calculates a
checksum of all operations that are made. The register ﬁle
and cache memories are provided with on-chip error-moni-
toring counters that increment automatically after each cor-
rected SEU error. The test software continuously reports
the value of these counters to an external host computer that
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:23:37 UTC from IEEE Xplore.  Restrictions apply. 
counts the number of errors in each ram type, as well as any
software checksum errors.
During the heavy-ion injection, the master device was
submitted to the ion beam while the compare error signal
from the slave was monitored for compare errors. When a
compare error is detected, the current software cycle is
completed and the checksum is veriﬁed to control that cor-
rection has been done successfully. The error counters are
also inspected to verify that the compare error originated
from a correction operation and not from an undetected
(and uncorrected error).
The ﬁrst round of tests were made with effective Linear
Transfer Energies (LET) between 6 and 110 MeV, using ion
ﬂuxes from 75 - 400 ions/s/cm2. During each run, 10E5
particles were injected into the device. The number of
resulting errors are shown in table 2 below. The ITE stands
for instruction cache tag error, IDE for instruction cache
data error, DTE for data cache tag error, DDE for data
cache data error, and RFE for register ﬁle error.
No undetected errors or other anomalies occurred and a
total of 4,500 errors were detected and corrected. The
cross-section (SEU sensitive area) depends on software
activity and ion LET, and the maximum (0.1 cm2) was mea-
sured when running the IUTEST program using an LET of
110 MeV. Compared to the ram size of 10 mm2, this means
that 10% of the ram cell area is sensitive to SEU hits. The
cross-section for the ﬂip-ﬂops could not be measured since
no SEU monitoring capability is implemented in the TMR
cells. Limiting the ﬂux to 400 ions/s/cm2 during the ﬁrst
round of tests was necessary to be able to count all errors
accurately. A reset and re-initialisation of the test system
takes around 50 milli-seconds, and must be signiﬁcantly
lower than the average error rate.
Having obtained data to determine the cross-section,
additional test were made at an ion ﬂux between 2,000 -
5,000 ions/s/cm2 using an LET of 110 MeV. At these levels,
20 - 50 errors/second occurred in the ram cells. Several runs
Table 2: LEON-Express SEU error, runs of 10E5 particles
TEST
IU
IU
IU
IU
IU
IU
IU
PAR
PAR
PAR
PAR
CNCF
CNCF
LET
5.86
8.27
14.1
14.1
28.2
55.9
110
14.1
28.2
55.9
110
14.1
14.1
ITE
10
16
24
33
50
50
83
30
34
45
95
23
28
IDE
35
58
124
142
227
170
318
65
81
94
157
44
49
DTE DDE RFE Total
13
102
176
12
319
31
366
32
59
625
535
53
1015
103
145
13
15
194
242
27
445
50
163
17
27
197
44
84
113
124
245
220
440
12
28
31
67
51
70
0
6
27
35
44
42
71
25
36
45
76
28
23
X-sect
1.02E-03
2.04E-03
3.19E-03
3.66E-03
6.25E-03
5.35E-03
1.02E-2
1.45E-03
1.94E-03
2.42E-03
4.45E-03
1.63E-03
1.97E-03
Figure 5: LEON-Express SEU test board
Figure 6: Cross-section vs. LET, IUTEST
Figure 7: Cross-section vs. LET, PARANOIA
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:23:37 UTC from IEEE Xplore.  Restrictions apply. 
were made using all three test programs, injecting 10E6 and
10E7 particles (10E4 - 10E5 errors) per test run. The CNCF
and PARANOIA test programs executed without undetec-
ted errors, but the IUTEST showed on average 5 error traps
or software failures per 10E7 particles. Ion ﬂuxes below
2,000/s/cm2 did not give any failures, and it is believed that
the undetected errors were due to multiple-error build-up in
the caches. Worst-case condition for ion ﬂux in the space
environment is many magnitudes lower, and this effect is
thus not considered a problem. The cross-section per bit for
the different ram types is plotted in ﬁgure 6 and 7.
7. Alternative implementations
LEON is by no means the ﬁrst implementation of an
fault-tolerant RISC processor, previous implementations
includes the IBM S/390 G5 [11] and the Intel Itanium [12].
The IBM processor solves error-detection by duplicating
the complete pipeline until the last write-stage, in which the
result from the two pipelines is compared. In case of a dis-
crepancy, the state of the processor is not updated and the
pipeline is restarted at the point of the falling instruction.
The area overhead is similar to LEON, 100%. The IBM
scheme is better in the sense that timing is not affected by a
TMR voter and that all types of errors are detected, not only
soft errors in register. The scheme is worse from a real-time
point-of-view since restarting of the pipeline takes several
thousand clock cycles. The scheme can also only be used
where (functional) timing is not important, bus interfaces or
timer units can not use this scheme without loosing their
function.
The Intel implementation a mix of ECC and parity codes
to detect and correct soft errors in caches and TLB memo-
ries. State machine registers are not protected.
8. Conclusion
Well-know error-detection and correction techniques
such as parity, BCH and TMR have been used to implement
an SEU-tolerant processor on a non-hardened semiconduc-
tor process. By choosing the appropriate detection and cor-
rection method for each speciﬁc memory type, the area
overhead has been kept low. Fault-injection using heavy-
ions has proved the efﬁciency of the fault-tolerance con-
cept, although some anomalies were detected at high parti-
cle ﬂuxes. The portable design style and simple synthesis
method insures long-term availability and quick access to
new semiconductor processes.
9. Future directions
During 2002, the LEON processor is planned to be
implemented and manufactured on the Atmel ATC25 pro-
cess (0.25 µm CMOS). The ATC25 device will have larger
caches than the ATC35 version, and include additional
functions such as a PCI interface and an on-chip debug unit.
The ﬁnal die size will be around 20 mm2 (pad-limited) and
the device is planned to operate at 100 MHz.
Although no indications of combinational SEU errors
were seen for the ATC35 device, the separate clock trees for
the TMR cells makes it possible to form a pulse ﬁlter on the
inputs to the ﬂip-ﬂops. By skewing the three clocks, any
pulse shorter than the skew would only be latched by one of
the ﬂip-ﬂops in the cell, and be removed by the voter. The
feasibility of such a scheme will be further investigated.
10. Acknowledgements
The author would like to thank R.Creasey, P.Plancke,
A.Pouponnot (ESA), Prof. J.Torin (Chalmers University),
T.Corbiere, J.Tellier and G.Rouxel (Atmel-Nantes) for their
support and encouragement during this work.
11. References
[1] J.Gaisler, “Concurrent error-detection and modular fault-toler-
ance in an 32-bit processing core for space applications”, FTCS-
24, June 1994 (Austin, USA).
[2] J.Gaisler, “Evaluation of a 32-bit microprocessor with built-in
concurrent error-detection”, FTSC-27, June 1997 (Seattle, USA)
[3] J.Gaisler & T.Vardanega, “Lessons Learned from the Imple-
mentation of On-Board Tolerance to Physical Faults in Ada”, The
International Journal of Computer Systems: Science & Engineer-
ing, January 2000.
[4] P.Linden et al., “On latching probability of particles induced
transients in combinatorial networks”, FTCS-24, 1994.
[5] R.Koga et al., “Techniques of microprocessor testing and SEU
rate prediction”, IEEE Trans Nucl. Sci., NS-32, 1985
[6] “The SPARC Architecture Manual Version 8”, SPARC Interna-
tional, Prentice Hall, 1992
[7] “AMBA Speciﬁcation, version 2.0”, ARM-IHI 0011A, ARM
Limited, 1999.
[8] J.Handy, “The Cache Memory Book”, Academic Press, 1993.
[9] C.L.Chen et al., “Error-correcting codes for Semiconductor
Memory Applications: A-state-of -the-art-review”, IBM J Res De-
velopment, page 124-132, March 1984.
[10] J.A.Zoutendyk et al., “Characterization of Multiple-Bit Errors
from Single-Ion Tracks in Integrated Circuits”, IEEE Trans Nucl.
Sci,. December 1989.
[11] M.A.Check et al. “Custom S/390 G5 and G6 microproces-
sors”, IBM Journal of Research and Dev., Vol 43, No 5/6, 1999.
[12] N.Quach, “High availability and Reliability in Itanium Proc-
essors”, IEEE Micro, Vol 20, No 5, 2000.
Proceedings of the International Conference on Dependable Systems and Networks (DSN’02) 
0-7695-1597-5/02 $17.00 © 2002 IEEE 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 04:23:37 UTC from IEEE Xplore.  Restrictions apply.