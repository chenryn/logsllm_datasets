### EasyChair Preprint
**â„– 7444**

**LogNG: An Online Log Parsing Method Based on N-Gram**

**Authors:**
- Xiangrui Liu
- Shi Ying
- Xinquan Ge
- Shengkang Hu
- Tiangang Li

**Affiliations:**
- School of Computer Science, Wuhan University, Wuhan, China

**Abstract:**
The first step in automatic log analysis is log parsing. With the increase in system size, the volume of logs has exploded, making manual analysis a daunting task. To address this, we propose **logNG**, an online log parsing method based on N-gram that efficiently parses logs in a streaming manner without requiring historical data training. When log messages are input as a stream, we first divide them into different log groups based on their lengths. We assume that if multiple different tokens appear continuously between log messages, these messages belong to different log templates. For each log group, we use N-gram for template matching to further group the log messages. We evaluate and compare logNG with other log parsers on public datasets. The experimental results show that logNG achieves the highest accuracy and efficiency.

**Index Terms:**
- Log parsing
- Online algorithm
- N-gram

---

### I. Introduction

Logs play a crucial role in modern software systems, but extracting valuable information from them remains a significant challenge [1], [2], [3], [4]. Log parsing is the initial step in automatic log analysis, and its quality significantly impacts downstream tasks [5], [6], [7]. The goal of log parsing is to convert unstructured data into structured data [8], [9], separating header information (such as date, time, level) and content (including static text and dynamic variables) [10], [11], [12].

As illustrated in Figure 1, a log record statement generates a raw log message when the system is running. This message typically consists of header information (e.g., "2015-10-18", "18:01:56", "916 INFO") and content (e.g., "Got allocated containers"). Log parsing requires more focus on the content than the header, which can be filtered out using regular expressions. The content includes the static text of the log record statement and its associated dynamic variable. The log template for the message "Got allocated containers 1" would be "Got allocated containers".

In this paper, we introduce **logNG**, an online automatic log parsing method that accurately and efficiently parses raw log messages in a streaming manner. logNG automatically extracts log templates from raw log messages without needing source code or historical log data. We evaluated logNG and other log parsers on real log datasets collected by the LogPai team [14]. logNG achieved the highest results on most datasets and was also very fast in terms of running time.

Our work makes the following contributions:
- **Online Automatic Log Parsing:** logNG divides log messages into different log groups based on their lengths. For each log group, N-gram is used to further group log messages for template matching.
- **No Historical Data Required:** Our method not only automates the process of parsing log templates but also operates online without the need for historical data training.
- **High Accuracy and Efficiency:** Experimental results on real log datasets demonstrate the high accuracy and efficiency of logNG.

### II. Related Work

**Rule-Based Log Parsing:**
Rule-based log parsing relies on heuristic rules (typically in the form of regular expressions) to parse logs. However, this approach is not scalable due to the rapid growth in log sizes [15], [16], [17], [18], [19].

**Source Code-Based Log Parsing:**
Some research supports log parsing based on source code [20], [21]. However, this method is challenging to implement due to the unavailability of source code.

**Data Mining-Based Log Parsing:**
Data mining-based log parsing does not require source code but uses various techniques to separate dynamic variables and static text by analyzing the characteristics of the logs [22].

**LKE:**
LKE [23] is a representative offline parser that hierarchically clusters log messages using weighted edit distance and generates log keys from the clusters. These log keys correspond to log print statements. A finite state automaton is learned from the training log sequence.

**LogMine:**
LogMine [24] is an unsupervised framework that scans log messages once and iteratively generates a pattern hierarchy. It can process millions of log messages in seconds.

**MoLFI:**
MoLFI [25] is a tool for log message format identification. It reformulates the problem as a multi-objective problem and uses an evolutionary method to solve it.

**SHISO:**
SHISO [26] is an online method for mining log formats and retrieving log types and parameters. It creates a structured tree using nodes generated from log messages.

### III. Methodology

#### A. Method Overview

**1. Data Structure:**
A well-designed data structure facilitates efficient analysis. We introduce the **log group** data structure, as shown in Figure 2. Each log group has four attributes: **Template**, **Length**, **TemplateID**, and **LogIDList**. 

- **Template:** The parsed log template.
- **Length:** The number of tokens in the template.
- **TemplateID:** A unique identifier for the log group.
- **LogIDList:** A list of log IDs that match the template.

Initially, the log group list is empty. As log messages are continuously input, logNG creates log groups and adds them to the list. Each attribute plays a specific role. For example, in Figure 2, the length is 4, and the template is "Verification succeeded for".

**2. Hierarchical Structure:**
logNG is organized into four hierarchical layers, as shown in Figure 3:

- **Preprocessing Layer:** Filters out header information and marks fixed format data (e.g., IP addresses, blockIDs) as wildcards to facilitate subsequent parsing.
- **Length Layer:** Divides log messages into different log groups based on their lengths. For example, log messages can be grouped by length less than 3, less than 4, equal to 5, etc.
- **Matching Layer:** Uses N-gram to make judgments on log messages and further divides them into detailed log groups.
- **Processing Layer:** Handles the final processing of the log messages.

When a raw log message is input into logNG, it first passes through the preprocessing layer. The length layer then divides the log messages into different groups based on their lengths. If the length of a log message is less than N, logNG cannot parse it. In such cases, logNG checks if the corresponding log group exists in the log group list. If it does, it adds the log message ID to the LogIDList; otherwise, it creates a new log group.

In the matching layer, logNG uses N-gram to further group log messages. The processing layer handles the final steps of the parsing process.

### Figures

**Figure 1: The Log Parsing Process of a Raw Log Message from Hadoop.**

**Figure 2: Data Structure.**

**Figure 3: Hierarchical Structure.**

---

This revised version aims to improve the clarity, coherence, and professionalism of the original text.