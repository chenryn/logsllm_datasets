FormatGuard [12] transforms source code using a mod-
iﬁed version of cpp (the C Preprocessor) combined with
a wrapper function for the printf function, so that
format-string attacks are detected at runtime.
While these techniques are useful for guarding against
speciﬁc attacks, their drawback is that they can deal with
only a small subset of the total set of memory exploits
shown in Figure 2.
5.2 Runtime Bounds and Pointer Checking
These techniques prevent buffer overﬂows by check-
ing each memory access operation that can potentially
cause a memory error to ensure that it does not hap-
pen. Approaches used to insert the required checks have
included source-to-source translation [25, 5], specially
USENIX Association
12th USENIX Security Symposium 
117
e
f
g
f



7

modiﬁed compilers [36, 22], binary rewriting [19], and
virtual machines/interpreters [24]. All of the above tech-
niques currently suffer from signiﬁcant drawbacks: run-
time overheads that can often be over 100%, restriction
to a subset of C-language, and changes to the memory
model or pointer semantics. In contrast, the focus of this
paper is on techniques that produce very low overheads
and are fully compatible with all C-programs.
5.3 Compile-Time Analysis Techniques
Compile-time analysis techniques [18, 32, 37, 14, 26]
analyze a program’s source code to determine which
array and pointer accesses are safe. While these ap-
proaches are a welcome component of any program-
mer’s debugging arsenal, they generally suffer from one
or more of the following shortcomings: they do not de-
tect all memory errors, they generate many false positive
warnings, and/or they do not scale to large programs.
The focus of our work is the development of techniques
that require no additional effort on the part of program-
mers, and hence can be applied to the vast base of ex-
isting software, in binary form, with no programmer ef-
fort.
Hybrid approaches perform runtime memory-error
checking, but also use static analysis to minimize the
number of checks. CCured [28] and Cyclone [21] are
two recent examples of this approach. One difﬁculty
with these approaches is that they are not 100% com-
patible with existing C-code. Moreover, they disable ex-
plicit freeing of memory, and rely on garbage collection.
5.4 Code Obfuscation
Code obfuscation [38, 10, 4] is a program transforma-
tion technique which attempts to convolute the low-
level semantics of programs without affecting the user-
observable behavior, making obfuscated programs dif-
ﬁcult to understand, and thereby difﬁcult to reverse-
engineer. The key difference between program obfusca-
tion and address obfuscation is that program obfuscation
is oriented towards preventing most static analyses of a
program, while address obfuscation has a more limited
goal of making it impossible to predict the relative or ab-
solute addresses of program code and data. Other anal-
yses, including reverse compilation, extraction of ﬂow
graphs, etc., are generally not affected by address obfus-
cation.
5.5 Randomizing Code Transformations
As mentioned earlier, address obfuscation is an instance
of the broader idea of introducing diversity in nonfunc-
tional aspects of software, an idea suggested by For-
rest, Somayaji, and Ackley [17]. Their implementation
model was called a randomizing compiler, which can
introduce randomness in several non-functional aspects
of the compiled code without affecting the language se-
mantics. As a proof of concept, they developed a mod-
iﬁcation to the gcc compiler to add a random amount
of padding to each stack allocation request. This trans-
formation defeats most stack-smashing attacks prevalent
today, but does not work against the large overﬂow at-
tacks of the sort described in Section 3.
In the past year or two, several researchers [8, 1, 39, 15]
seem to have independently attempted to develop ran-
domization as a practical approach to defeat buffer-
overﬂow and related attacks. Work by Chew and
Song [8] randomizes the base address of the stack, sys-
tem call numbers, and library entry points,
through
a combination of program loader modiﬁcations, ker-
nel system call table modiﬁcations, and binary rewrit-
ing. Xu, Kalbarczyk, and Iyer developed transparent
runtime randomization [39], in which the Linux ker-
nel is modiﬁed to randomize the base address of stack,
heap, dynamically loaded libraries, and GOT. The PaX
project’s address space layout randomization (ASLR)
approach [1] randomizes the base address of each pro-
gram region: heap, code, stack, data. Of these, the
ASLR approach is the most advanced in terms of its
implementation. As noted earlier, ASLR is vulnera-
ble to attacks that rely on adjacency information such
as the relative addresses between variables or code, and
attacks that can provide information about the base ad-
dresses of different memory segments. The introduction
of additional randomization in address obfuscation, in
the form of random-sized gaps within stack frames and
blocks allocated by malloc, reordering of (and ran-
dom padding within) code and static variables, can ad-
dress these weaknesses. Another important difference
between the above works and ours is that our obfusca-
tions are implemented using program transformations,
whereas the other works are implemented using operat-
ing system modiﬁcations. For this reason, our approach
can be more easily ported to different operating systems.
Moreover, it can protect individual (security-critical) ap-
plications without having to make any changes to the rest
of the system.
The PointGuard [13] approach complements ours in that
it randomizes (“encrypts”) stored pointer values, as op-
posed to the locations where objects are stored. The
encryption is achieved by xor’ing pointer values with a
random integer mask generated at the beginning of pro-
gram execution. It shares many of the beneﬁts (such as
broad protection against a wide range of pointer-related
attacks) and weaknesses (susceptibility to attacks that
read victim process memory to identify the mask). The
principal differences are that (a) PointGuard does not
protect against attacks that do not involve pointer values,
118
12th USENIX Security Symposium 
USENIX Association
e.g., attacks that modify security-critical data through a
buffer overﬂow, and (b) probability of successful attacks
is smaller with PointGuard than with address obfusca-
tion since the range of randomization can be as large as
the address space.
It should also be noted that Point-
Guard is dependent on the availability of accurate type
information. Many C-language features, such as the
ability to operate on untyped buffers (e.g., bzero or
memcpy), functions that take untyped parameters (e.g.,
printf), unions that store pointers and integer values
in the same location, can make it difﬁcult or impossible
to get accurate type information, which means that the
corresponding pointer value(s) cannot be protected.
6 Conclusion
We believe that address obfuscation has signiﬁcant
potential to constrain the increasing threat of widely
spread buffer overﬂow-type of attacks. By randomly
re-arranging the memory space that holds a computer
program and its data during execution, the core vulner-
ability that buffer overﬂow attacks have been exploiting
is addressed — namely, the predictable location of con-
trol information and critical data. Unlike many existing
techniques, which deploy attack-speciﬁc mechanisms to
overcome known attack scenarios, address obfuscation
is a generic mechanism that has a broad range of appli-
cation to many memory error-related attacks.
Since each system is obfuscated differently, even if an
attacker successfully subverts one system on a network,
the attack will have to essentially start over from scratch
and make many attempts before a second system can
be subverted. In the context of self-replicating attacks,
this factor will greatly slow down the spread of worms
and viruses. Thus, address obfuscation provides a sim-
ple and effective solution to combat the spread of viruses
and worms which replicate by exploiting memory errors.
Our main goal for the future is to improve the quality of
randomization that can be done at the binary level. In
particular, we are interested in randomizing the relative
distances between objects in all regions of a program,
instead of just the stack and heap, as is the case with our
current implementation. There are basically two avenues
for this work. The ﬁrst is a tool that works with existing
binary ﬁles. Such a tool will be restricted in the types of
obfuscations which can be applied, but will have a wide
potential impact. Addressing relative-distance issues re-
quires both inserting padding between and permuting the
order of data and code, which requires the relocation of
affected addresses. Performing these sorts of relocations
on binaries is not always feasible due to the difﬁculty of
distinguishing pointers from non-pointers, sizes of data
objects, and code from data. We plan on developing
better analysis tools, and combining this with a ﬂexi-
ble transformation strategy that applies as many obfus-
cations as possible within the limits of the analysis.
The second avenue is to augment binaries with an extra
section that contains the information required to safely
perform relocations. This approach requires a relatively
minor change to the compiler infrastructure, as the in-
formation required is similar to the information already
being generated to support the linking of object mod-
ules. Given the extra information, a program can be ob-
fuscated at link- or load-time in a more thorough manner
which will change all relative and absolute addresses in
every program region.
Acknowledgments
This research was supported in part by AFOSR grant
F49620-01-1-0332, ONR University Research Initiative
Grant N00140110967, and NSF grants CCR-0098154
and CCR-0208877.
References
[1] Pax.
Published on World-Wide Web at URL
http://pageexec.virtualave.net, 2001.
[2] Anonymous. Once upon a free . . . . Phrack, 11(57), Au-
gust 2001.
[3] Anonymous. Bypassing pax aslr protection. Phrack,
11(59), July 2002.
[4] D. Aucsmith. Tamper-resistant software: An imple-
mentation.
In Ross Anderson, editor, Information hid-
ing: ﬁrst international workshop, Cambridge, U.K., May
30–June 1, 1996: proceedings, volume 1174 of Lecture
Notes in Computer Science, pages 317–333, Berlin, Ger-
many / Heidelberg, Germany / London, UK / etc., 1996.
Springer-Verlag.
[5] Todd M. Austin, Scott E. Breach, and Gurindar S. Sohi.
Efﬁcient detection of all pointer and array access errors.
In Proceedings of the ACM SIGPLAN’94 Conference
on Programming Language Design and Implementation
(PLDI), pages 290–301, Orlando, Florida, 20–24 June
1994. SIGPLAN Notices 29(6), June 1994.
[6] Arash Baratloo, Navjot Singh, and Timothy Tsai. Trans-
parent run-time defense against stack smashing attacks.
In Proceedings of the 2000 USENIX Annual Techni-
cal Conference (USENIX-00), pages 251–262, Berkeley,
CA, june 2000.
[7] Bulba and Ki13r. Bypassing stackguard and stackshield.
Phrack, 11(56), May 2000.
[8] Monica Chew and Dawn Song. Mitigating buffer over-
ﬂows by operating system randomization. Technical Re-
port CMU-CS-02-197, Carnegie Mellon University, De-
cember 2002.
[9] Tzi-cker Chiueh and Fu-Hau Hsu. Rad: A compile-
time solution to buffer overﬂow attacks. In 21st Interna-
tional Conference on Distributed Computing, page 409,
Phoenix, Arizona, April 2001.
[10] Christian Collberg, Clark Thomborson, and Douglas
Low. Breaking abstractions and unstructuring data struc-
tures. In Proceedings of the 1998 International Confer-
ence on Computer Languages, pages 28–38. IEEE Com-
puter Society Press, 1998.
USENIX Association
12th USENIX Security Symposium 
119
[26] David Larochelle and David Evans. Statically detect-
ing likely buffer overﬂow vulnerabilities. In Proceedings
of the 10th USENIX Security Symposium, Washington,
D.C., August 2001.
[27] Mudge. How to write buffer overﬂows.
Published
on World-Wide Web at URL http://www.insecure.org/
stf/mudge buffer overﬂow tutorial.html, 1997.
[28] George C. Necula, Scott McPeak, and Westley Weimer.
CCured: type-safe retroﬁtting of legacy code. In Sympo-
sium on Principles of Programming Languages (POPL
’02), pages 128–139, Portland, OR, January 2002.
[29] Nergal. The advanced return-into-lib(c) exploits. Phrack,
11(58), Dec 2001.
[30] Mary Lou Nohr. Understanding ELF Object Files and
Debugging Tools. Number ISBN: 0-13-091109-7. Pren-
tice Hall Computer Books, 1993.
[31] Aleph One.
Smashing the stack for fun and proﬁt.
Phrack, 7(49), November 1996.
[32] Radu Rugina and Martin Rinard. Symbolic bounds anal-
ysis of pointers, array indices, and accessed memory re-
gions. In Proceedings of the ACM SIGPLAN ’00 confer-
ence on Programming language design and implementa-
tion, pages 182–195. ACM Press, 2000.
[33] scut.
Exploting format string vulnerabilities.
Pub-
lished on World-Wide Web at URL http://www.team-
teso.net/articles/formatstring, March 2001.
[34] Snort(tm) advisory: Integer overﬂow in stream4. April
Published on World-Wide Web at URL
2003.
http://www.kb.cert.org/vuls/id/JPLA-5LPR9S.
[35] Ssh crc32 attack detection code contains remote integer
overﬂow. 2001. Published on World-Wide Web at URL
http://www.kb.cert.org/vuls/id/945216.
[36] Joseph L. Steffen. Adding run-time checking to the
portable c compiler. Software-Practice and Experience,
22:305–316, April 1992.
[37] David Wagner, Jeffrey S. Foster, Eric A. Brewer, and
Alexander Aiken. A ﬁrst step towards automated detec-
tion of buffer overrun vulnerabilities.
In Network and
Distributed System Security Symposium, San Diego, CA,
2000.
[38] Chenxi Wang, Jack Davidson, Jonathan Hill, and John
Knight. Protection of software-based survivability mech-
anisms. In International Conference on Dependable Sys-
tems and Networks, Goteborg, Sweeden, July 2001.
[39] Jun Xu, Zbigniew Kalbarczyk, and Ravishankar K. Iyer.
Transparent runtime randomization for security. Techni-
cal Report UILU-ENG-03-2207, Center for Reliable and
High-Performance Computing, University of Illinois at
Urbana-Champaign, May 2003.
[40] Lu Xun.
A linux
Masters Thesis,
brary.
http://www.geocities.com/fasterlu/leel.htm.
executable
1999.
editing
available
li-
at
[11] Crispan Cowan, Calton Pu, Dave Maier, Jonathan
Walpole, Peat Bakke, Steve Beattie, Aaron Grier, Perry
Wagle, Qian Zhang, and Heather Hinton. StackGuard:
Automatic adaptive detection and prevention of buffer-
overﬂow attacks. In Proc. 7th USENIX Security Confer-
ence, pages 63–78, San Antonio, Texas, jan 1998.
[12] Crispin Cowan, Matt Barringer, Steve Beattie, and Greg
Kroah-Hartman. Formatguard: Automatic protection
from printf format string vulnerabilities. In USENIX Se-
curity Symposium, 2001.
[13] Crispin Cowan, Steve Beattie, John Johansen, and Perry
Wagle. Pointguard: Protecting pointers from buffer over-
ﬂow vulnerabilities. In Proceedings of the 12th USENIX
Security Symposium, Washington, D.C., August 2003.
[14] Nurit Dor, Michael Rodeh, and Mooly Sagiv. Cleanness
checking of string manipulations in C programs via in-
teger analysis.
In Static Analysis Symposium, volume
2126 of Lecture Notes in Computer Science, pages 194–
?? Springer Verlag, June 2001.
[15] Daniel C. DuVarney, R. Sekar, and Yow-Jian Lin. Benign
software mutations: A novel approach to protect against
large-scale network attacks. Center for Cybersecurity
White Paper (prepared for Airforce Ofﬁce of Scientiﬁc
Research), October 2002.
[16] Hiroaki Etoh and Kunikazu Yoda. Protecting from stack-
smashing attacks. Published on World-Wide Web at URL
http://www.trl.ibm.com/projects/security/ssp/main.html,
June 2000.
[17] Stephanie Forrest, Anil Somayaji, and David H. Ackley.
Building diverse computer systems.
In 6th Workshop
on Hot Topics in Operating Systems, pages 67–72, Los
Alamitos, CA, 1997. IEEE Computer Society Press.
[18] Jeffrey S. Foster, Manuel F¨ahndrich, and Alexander
Aiken. A theory of type qualiﬁers. In ACM SIGPLAN
Conference on Programming Language and Design, At-
lanta, GA, May 1999.
[19] Reed Hastings and Bob Joyce. Purify: A tool for de-
tecting memory leaks and access errors in C and C++
programs. In USENIX Association, editor, Proceedings
of the Winter 1992 USENIX Conference, pages 125–138,
Berkeley, CA, USA, January 1992. USENIX.
[20] Oded Horovitz. Big loop integer protection. Phrack,
11(60), December 2002.
[21] Trevor Jim, Greg Morrisett, Dan Grossman, Micheal
Hicks, James Cheney, and Yanling Wang. Cyclone: a
safe dialect of C. In USENIX Annual Technical Confer-
ence, Monterey, CA, June 2002.
[22] Robert W. M. Jones and Paul H. J. Kelly. Backwards-
compatible bounds checking for arrays and pointers in C
programs. In M. Kamkar and D. Byers, editors, Third In-
ternational Workshop on Automated Debugging. Linkop-
ing University Electronic Press, 1997.
[23] Michel Kaempf. Vudo malloc tricks. Phrack, 11(57),
August 2001.
[24] Stephen Kaufer, Russell Lopez, and Sesha Pratap. Saber-
C — an interpreter-based programming environment for
the C language.
In USENIX Association, editor, Sum-
mer USENIX Conference Proceedings, pages 161–171,
Berkeley, CA, USA, Summer 1988. USENIX.
[25] Samuel C. Kendall. Bcc: run–time checking for c pro-
grams. In Proceedings of the USENIX Summer Confer-
ence, El. Cerrito, California, USA, 1983. USENIX Asso-
ciation.
120
12th USENIX Security Symposium 
USENIX Association