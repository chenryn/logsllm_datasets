sampling mode must be preprocessed to separate events from dif-
ferent sources. In what follows, we assume that the entity con-
trolling the hypervisor (i.e., cloud provider or a malicious tenant
that compromised it) has knowledge of the host operating system.
Given that assumption, we can safely discard all samples from the
known address range of the host kernel. All the remaining samples
then belong to guest VMs. Knowing, for example, that in Linux
the OS kernel is always mapped in the upper 48 bits of the address
Algorithm 2 Matching IBS based fingerprints
1: for all signatures (cid:174)r in R do
2:
3:
for all ri ∈ (r1 . . . rm) do
if All distances in (cid:174)u match sums of consecutive distances starting from ri
Fingerprint (cid:174)u matches application (cid:174)r
then
4:
5:
6:
7: end for
end if
end for
space, samples from the guest kernel can also be discarded. Addi-
tionally, based on the knowledge that binaries and shared libraries
are mapped to distinct memory ranges, the remaining samples can
be further separated. Specifically, we cluster the samples into 32 MB
bins,4 starting from the lowest observed virtual address. Given each
bin, we select the samples containing return instructions and create
an ordered list of their virtual addresses va0 . . . vak. From that list
we generate a fingerprint of the unknown application, u, as a vector
of distances (cid:174)u = (d1 . . . dk) where di = vai − va1. Essentially, this
gives us a peek into the binary layout of an unknown application.
Said another way, we measure distances from some function bound-
ary early on in an application to other function boundaries in later
parts of that application. Note that k varies based on the number of
return instructions observed during the period we collect IBS data.
4.3.2 Application reference set. An application reference describes
the layout of all functions in a given binary. Specifically, we leverage
the distance between function returns to describe the layout. The
reference is a vector (cid:174)r = (r1, r2, . . . , rm) of distances between all
the return instructions in a binary. The size, m, of the reference
depends on the number of functions in an application and can range
from a few up to tens of thousands.
Fingerprint matching. Fingerprint matching proceeds as one
4.3.3
would expect: we identify the unknown image by the sequence
of distances between the observed return instructions collected
using IBS compared with an off-line reference of target applica-
tions curated using binary disassembly. We denote that datastore
containing the full fingerprints for all applications of interests (i.e.,
[(cid:174)r1, . . . , (cid:174)rN ] as R. Essentially, (cid:174)u is a binary-level fingerprint that
captures a small fragment of the unknown application’s structure.
The fingerprint in Figure 6 (in the Appendix) consists of two dis-
tances computed from a set of three addresses of return instructions
in the IBS data.
Inputs: (i) A reference database R of application layouts. Each
layout in R is a vector of distances between successive returns. (ii)
A vector (cid:174)u of distances between the first seen return instruction
and all the other return instructions within a bin. The crux of the
Algorithm 2 lies in line 3, where a comparison is made between
consecutive distances in (cid:174)r and observed distances in (cid:174)u. The search
starts with the first distance, ri =1 from (cid:174)r then adds consecutive
distances from (cid:174)r to test if they can match distances in (cid:174)u. If any
of the distances from (cid:174)u cannot be matched to a sum of distances
from starting position ri, the search restarts at ri +1. The unknown
vector is considered identified if, and only if, all the distances from
(cid:174)u are matched to sums of distances from (cid:174)r. The example presented
in Figure 6 is a positive match: distance d1 is equal to the sum of
r3 + r4 + r5 + r6 and d2 is equal to r6.
4Value derived from an empirical evaluation of the average size of Ubuntu binaries.
Session 2A: SGX-based SecurityAsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand795 EVALUATION
To validate our ideas regarding the underlying weaknesses of a plat-
form where registers are left unencrypted, we first show how we
can efficiently recover data being sent over TLS-protected connec-
tions within the encrypted guest, retrieve the contents of sensitive
data being read from disk by the guest, and inject arbitrary data
within the guest by connecting to the target VM to perform Iago-
style attacks [8]. The latter gives adversaries a foothold on the
target VM, allowing them to inspect it at will. Afterwards, we turn
our attention to application fingerprinting attacks on SEV-ES.
Experimental Platform
All experiments were conducted on commercially available hard-
ware. We used a Silicon Mechanics aNU-12-304 server with dual
Epyc 7301 processors and 256 GB of RAM. The machine runs
Ubuntu 16.04 with a custom 64-bit Linux kernel v4.15. The custom
kernel and QEMU were downloaded from AMD’s code repository.5
Guest VMs were assigned to a single vCPU with 2 GB of RAM,
and run Ubuntu 16.04 with the same kernel as the host. Our VM
introspection mechanism is implemented as an extension of the
KVM kernel modules.
5.1 Attack on SEV: Reading TLS data
To demonstrate the viability of an attack on a network server within
a SEV-enabled enclave, we show how to unveil content served over
HTTPS. We show how given the encrypted memory and encrypted
network traffic, a malicious hypervisor can recover the plaintext
communication. To explain how the attack works, we briefly review
the architecture of Nginx (the sample webserver) and the character-
istics of the spawned process (that we rely on to create triggers used
to extract the information from encrypted network connections).
In Nginx, an initialization process creates new sockets (socket())
and binds to HTTP/HTTPS ports (bind(), listen()). After setting
up the socket, the initialization process clones itself (clone()) to
create the master process. The master process then clones (clone())
itself to create worker processes that handle incoming connections.
The worker process waits for the incoming connections (epoll()),
then accepts an incoming connection (accept()), transfers data to
the client (recvfrom(), writev()), and finally terminates the con-
nection (close()) and returns to the waiting state. We hyper-step
in between the recvfrom() and writev() system calls to recover
the data processed by the server. A pictorial representation is shown
in Figure 5 in Appendix C. In TLS secured connections, the worker
process conducts a handshake [43] and starts transmitting data
when it is complete. The instruction instrumentation is performed
only on the data exchange part of communication to reduce the pro-
cessing overhead. The exchanged data is decrypted and encrypted
using the hardware AES engine that developers can utilize via the
AES-NI instruction set extension. Thus, observation of the XMM
registers allows us to extract the plaintext of the request and the
response as well as the AES keys. In the experiment, the server
used the Diffie-Hellman key exchange protocol and encrypted the
traffic using 128-bit AES in Galois Counter mode. (OpenSSL cipher
suite 0x9e: DHE-RSA-AES128-GCM-SHA256.)
5Available at https://github.com/AMDESE/AMDSEV/.
Figure 3: Abstraction of going from observed register changes to in-
ferred instructions of the encryption loop of the HTTPS response.
The underlined instructions are those inferred using the contextual
information within the scope of the analysis.
When the hypervisor detects the sequence of system calls that
indicate the server is about to receive data from a network socket,
we transition to the second stage of the attack. In stage two, the
interception of the SSL_read function allows us to unmask the in-
structions that process the plaintext of the request and the response
sent over the TLS protected network connections — all via exami-
nation of the general purpose registers. We note that unmasking of
the instructions significantly simplifies the process of recovering
the encrypted data in that it allows us to simply copy the plaintext
from the register when the decryption is complete, rather than sift
through intermediary values of the encryption process.
5.1.1 Under the hood. Recall that our techniques for recovery of
the instructions shown in Figure 3 leverage our instruction identifi-
cation (§4.2.1) methodology and memory access detection (§4.2.2)
technique. For brevity, we skip the bulk of the encryption and focus
the reader’s attention on the sections responsible for loading data
from memory, storing the results, and the loop construct.
Using the memory access tracking, we identify access patterns
of the instructions in the trace. Armed with the knowledge of the
memory accesses one can easily identify mov instructions, where
Recovered InstructionsObserved SequenceRIPDeltaRegister changeMemory Accessloopstart:… repeated encryption routines… vpxor  xmm2,xmm1, [rdi]4xmm2readvaesenc xmm11,xmm11,xmm155xmm11vpxor  xmm0,xmm1, [rdi+0x10]5xmm0readvaesenc xmm12,xmm12,xmm155xmm12vpxor  xmm5,xmm1, [rdi+0x20]5xmm5vaesenc xmm13,xmm13,xmm155xmm13readvpxor  xmm6,xmm1, [rdi+0x30]5xmm6readvaesenc xmm14,xmm14,xmm155xmm14vpxor  xmm7,xmm1,[rdi+0x40]5xmm7readvpxor  xmm3,xmm1,[rdi+0x50]5xmm3readvmovdqu xmm1, [r8]5xmm1readvaesenclast xmm9,xmmv9,xmm25xmm9vmovdqu xmm2, [r11+0x20]6xmm2readvaesenclast xmm10,xmm10,xmm05xmm10vpaddb xmm0,xmm1,xmm24xmm0mov[rsp+0x78],r135writelea    rdi,[rdi+0x60]4RDI+96vaesenclast xmm11,xmm11,xmm55xmm11vpaddb xmm5,xmm0,xmm24xmm5mov[rsp+0x80],r128writelea    rsi,[rsi+0x60]4RSI+96… repeated encryption routines…jmp -0x52b-1323L o a dT r i g g e rSession 2A: SGX-based SecurityAsiaCCS ’19, July 9–12, 2019, Auckland, New Zealand80Table 2: Overhead of the TLS recovery PoC
Size
8k
32k
128k
Baseline (µs)
4539
7604
13801
System call
tracking (µs)
6432
8107
13383
Full PoC
(µs)
6476
8515
14591
the destination operand is memory, and distinguish instructions
that load register contents from memory from those that perform
arithmetic or logical operations. Finally, given that our coarse grain
tracking was used to trigger hyper-stepping, we can use that knowl-
edge to match the recovered set of instructions as the loop of the
CRYPTO_128_unwrap function.
With the acquired knowledge of the code layout, we can set a
new finer-grained trigger point, ∆’ (lea rdi, [rdi+0x60]), to
the location in the loop where accessing the registers will disclose
the plaintext in the XMM registers. The underlined instructions in
Figure 3 are those inferred using the contextual information within
the scope of the instruction under analysis.
To be sure that we reached the critical section of the code where
we can extract the plaintext from the registers, we verify that the
trace observed while hyper-stepping contains the sequence: [RIP+4,
RDI+96; RIP+4, new value of XMM11; RIP+4, new value of
XMM5; RIP+8, memory write; RIP+4,
RSI+96].6 Once verified, we copy the contents of the XMM reg-
isters and reassemble the HTTPS stream.
5.1.2 Results. To gain insights into the run time overhead, we
averaged the processing time of 25 requests for varying sizes of
requested data. The average round trip time for a packet between
the client and the server in our setup was 5ms (5000 µs). Our results
provided in Table 2 show that the user perceived delay is slightly
less than 1ms per 32 kb of data. The overhead would be even lower
if the adversary only needs to instrument the request to obtain the
requested URL, user credentials and any other information that is
necessary to reissue the request.
5.2 Attack on SEV: Injecting Keys
Next, we examine how a malicious hypervisor can thwart the full
disk encryption and the memory encryption that are used by the
guest. To that end we demonstrate how the malicious hypervisor
can intercept data from an encrypted hard drive, and inject faux
data into the datastream. For pedagogical purposes, we focus on
the read() system call and how it is used to provide access to
various devices. For the remaining discussion, it suffices to know
that control flows from the system call entry point through the
Virtual File System (VFS) and the extended file system drivers to
a file system agnostic function (i.e.,copy_user_generic()) that is
responsible for copying the data between kernel space and user
space memory. For all file systems supported in the Linux kernel,
we found that this generic function checks the kernel data structure
for information on the available CPU extensions and based on that
information invokes a specific low level assembly function.
An in-depth analysis of the kernel initialization functions showed
that a single invocation of the CPUID instruction is used only
to specify the processor features for the purpose of selecting the
memory copy instruction. Specifically, the OS can be forced to
use less efficient register-to-register copy operations instead of
fast string operations by masking certain bits in the results of the
CPUID instruction. For example, in the Linux kernel, the decision
to use specific memory copy instructions is based on available CPU
features.7 Moreover, the check of the availability of the CPU specific
features8 can be manipulated by spoofing the value returned by
the CPUID instruction to force the kernel not to use memory to
memory copy (i.e., rep movs instructions).
By augmenting the same approach outlined in §5.1, we show
how a malicious hypervisor can gain arbitrary user access in the
SEV-enabled enclave. The attack we explore is a variation of an
Iago attack [8], which is the term for an attack where the response
from untrusted kernel undermines the security of the user space
process. Rather than modifying the kernel, however, in our case the
malicious hypervisor performs a man in the middle attack between
the user space and kernel.