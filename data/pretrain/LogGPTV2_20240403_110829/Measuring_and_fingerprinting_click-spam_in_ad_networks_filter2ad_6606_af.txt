5.4 Click-spam in Mobile Ads
We next turn our attention to mobile ads, which as we found in
Section 4, are challenging even for reputable ad networks to detect
click-spam in. Figure 8b pictorially shows why. First, because mo-
bile advertising is a relatively new market, large legitimate content
providers have not yet replaced ﬂy-by-night operators that exist to
make a quick buck. Indeed many mobile sites on which our ads
were shown serve primarily adult content; the abundance of these
sites mirrors the state of the web two decades ago when banner ads
ﬁrst started appearing on similar sites. The two large cluster are
different adult entertainment networks, one hosted in Turkey, and
one in Denmark. We do not investigate these clusters.
5.4.1 Mobile Games
Ant-smasher and similar games: At least 2% of clicks on control
ads came from smartphone games that all require the user to tap
the screen close to where the ad is displayed. One such example
is the Ant-smasher iPhone app where ants randomly walk around
the screen up to (and under) where the ad is shown in the game,
and the user must tap the ant before it disappears from the screen
to progress in the game. We installed the games directing the most
trafﬁc and conﬁrmed the following modus operandi.
How it works:
1. A mobile game developer accidentally (or intentionally) places
the in-app advertising control close to where the user must tap, or
drag things to, in order to succeed in the game.
10: Arbitraging click-spam trafﬁc through a fake site
Discussion: As before, this is largely a policy issue. Major ad
network policies for parked domain afﬁliates states that they must
not violate trademarks and copyrights [1]. NetworkSolutions does
reserve for themselves the right to served parked pages for a do-
main (or sub-domain) in its terms-of-service (TOS) that customers
must agree to. It is unclear whether beneﬁting from someone else’s
domain constitutes copyright or trademark infringement, and if it
does, whether it can be overridden by the TOS. This is a loop-hole
NetworkSolutions beneﬁts from.
Who made money: NetworkSolutions made money from major
ad networks if the user clicked a link on the parked domain.
5.3.3 Advertising Arbitrage
dotellall.com family: We next focus on the cluster of dotellall.com
and 20 other related domains that account for 18% of the trafﬁc
for our search control ads. The entire cluster of websites on the
surface appear to be lively social question answer forums (users
ask questions, and post answers), but when we posted questions
and answers on one of the sites, it disappeared after a few days, and
the site was restored to its pristine condition. We noticed that over
time the questions and answers do not change. No question has
the date/time when it was asked or answered. For one of the sites,
we found the content was blatantly copied from other locations on
the web. As best as we can tell, the entire family of sites is an
incredibly elaborate (and realistic) sham.
It was extremely puzzling as to how they attract trafﬁc. Clearly
users wouldn’t frequent a fake social site. We couldn’t ﬁnd links to
malware. The sites weren’t typos of other popular sites (although
one is named livingfrugal.com, which is similar to the popular living-
social.com). Confusing us further, we (initially) couldn’t ﬁnd ads
on their pages. It took us a long time (and a considerable amount
of serendipity) to determine how this family of sites makes money.
How it works:
1. We serendipitously discovered that the family of sites adver-
tises heavily on search and contextual ad networks. It advertises to
the tune of thousands of ads, for a wide spread of (long-tail) key-
words. As a result, they show up on low-popularity searches or
low-quality publishers. On low-quality publishers ad links are al-
most indistinguishable from content. Being the only ad for many
low-popularity searches, their ad is often placed above search re-
sults. Whenever there is competition, however, their ad is typically
ranked much lower (e.g., 7th or 8th position in the sidebar).
This suggests that they likely bid mere pennies for these thousands
of ads, but nevertheless manage to acquire long-tail trafﬁc.
2. When a user clicks one of these ads, he is taken to the site.
The site shows ads only when the user arrives through an ad-click
2. Given the tiny screen real-estate, the user is prone to mistap-
ping. When he does so, the browser navigates to the ad-click URL.
1843. The user may realize his error and switch back to the game.
The browser, which in the mean time has already begun fetching
the ad landing-page, aborts the attempt. As a result, the user will
appear to have spent very little time on the advertiser’s page. We
saw exactly this behavior on our mobile ads — 95% of users spent
less than a second as mentioned earlier.
Discussion: The core issue here is the advertiser being charged
despite the user not spending any time on the landing page. It is
hard for an ad network to know how long the user spent on the
advertiser’s site. If it relied on the advertiser to get this information,
the advertiser could easily lie to get a discount. Solving this without
modifying the browser, and without hurting the user experience is
a non-trivial problem.
One mitigating approach would be to audit games and apps that
trick users into mistapping on the ad. Doing so would likely spark
an arms race for apps intentionally exploiting this loop-hole, but
would at least protect advertisers from apps accidentally triggering
this. Unfortunately, ad networks are making it harder for advertis-
ers and independent third-parties to identify bad apps. During the
course of our study, one major mobile advertising network stopped
sending the application ID in the HTTP Referer.
Who made money: The app made money from the ad network.
5.4.2 WAP Phones
waptrick.com and other sites: There is a sizable number of WAP
phones (phones with a limited browser that access the web via a
WAP proxy) that mobile ads are shown to. Nearly 42.1% of trafﬁc
on our mobile control ads are from these sources. We loaded a
number of implicated sites with our browser’s user-agent set to that
of a WAP browser.
How it works:
1. Sites that cater to WAP users as well as WAP proxies optimize
the page content for display on feature phones, potentially stripping
away icons, colors, or sidebar content that visually differentiates an
ad from a normal link.
2. Combined with the extremely small screen, and clunky (keypad-
based) navigation on non-smart phones, the user clicks a link either
unintentionally, or without knowing that it is an ad.
Discussion: Proxies are the biggest hurdle in tracking down bad
WAP sites that confuse the user. As mentioned, less than 36% of
our clicks had the HTTP Referer we need to track it back to the
originating website and conﬁrm that it intermixed ads with content.
While one might wish for legacy phones to die out, it is unlikely
to do so in developing countries in the near future. Advertisers
wishing to reach a global market will have to contend with click-
spam originating through these vectors.
Who made money: The WAP website made money from the ad
network. For websites that have arrangements with proxies, the
proxy operator potentially made some fraction of that money.
5.5 Epilogue and Future Work
Investigating 26% of clicks on our control ads, we ﬁnd the ﬁve
classes of invalid clicks discussed above. We believe there are more
classes of dubious trafﬁc lurking in our data, and are investigating
more automated means of reconstructing the attacks. In any event,
we ﬁnd that click-spam is by no means a solved problem.
We also ﬁnd that while there is a policy component to many of
the case-studies we presented, there is also an associated technol-
ogy (and research) component to proactively discover attacks.
Mobile is a particularly tricky case where much of the teleme-
try needed for detecting click-spam doesn’t exist. Given the large
role mobile advertising is expected to play in the coming future,
research in this space is both important and timely.
6. RELATED WORK
Related work falls into three distinct categories.
Measuring Trafﬁc Quality: There is surprisingly little past work
in systematically measuring the quality of click trafﬁc. [26] devel-
ops a learning algorithm for estimating the true CTR of an ad in
the presence of click-spam. [41] measures trafﬁc from bulk traf-
ﬁc providers and ﬁnds some providers to be qualitatively worse
than ad networks. Startups including Adometry, Visual IQ and
ClearSaleing that claim to be able to estimate click-spam rates pro-
vide no transparency into the speciﬁcs of their methods; further-
more, these approaches apply only at the granularity of entire ad
networks, which we found is insufﬁcient information for advertis-
ers. Our click-spam estimation approach, which is grounded in
our Bayesian framework and validated through extensive measure-
ments, is the ﬁrst principled approach an advertiser can indepen-
dently apply at the granularity of his individual ads.
Documenting Click-Spam: The second category of related work
is a snapshot-in-time of click-spam attacks, much like the case-
studies presented in this paper. Daswani et. al. [19] give a good
introduction to online advertising, pricing models, and online ad-
vertising fraud. Botnets like Clickbot.A [20], TDL-4 [36] and other
botnets [34] have been used for click fraud. More recent work
describes fraud in ad exchanges [38]. Individual advertisers, and
security researchers have documented many more attacks in blog
posts and white-papers [8,10,13]. Each of these has been an ad-hoc
targeted investigation given a speciﬁc publisher or attack vector.
Our generic clustering and heavy-hitter detection approach instead
starts from raw click logs to automatically identify (and prioritize)
potential publishers/attack vectors for targeted investigations.
Mitigating Click-Spam: The third category of related work aims
to identify individual clicks as click-spam so they can be discounted.
Bluff Ads [25], on which we base our control ad design, are ads
with unrelated targeting information (e.g., dog food ads for cat
lovers). Clicks on Bluff ads are assumed to be click-spam, which
the ad network should discount. While we subscribe to this as-
sumption, we differ in how such ads should be used. [25] sug-
gests blacklisting users that have above-threshold clicks on bluff
ads. There are two problems. First, this only applies to click-spam
driven by malware. In the non-malware scenarios we discovered,
blacklisting the user serves little purpose since the bad publishers
get a steady stream of unwitting users (false-negatives for Bluff
ads); furthermore, the legitimate clicks of blacklisted users on good
publishers would also get discounted (false-positives). The second
problem is that even for click-spam driven by malware, it wouldn’t
work. The malware we analyzed performs one click per day. If
Bluff Ads were to be shown 1% of the time, it would take on the
order of a 100 days to blacklist a user. The cost to the ad network
would be 1% of their revenue (hundreds of millions of dollars for
reputed networks), which would be unacceptably high. We use con-
trol ads in a different way; we use it sparingly to collect data ($1000
represents a negligible fraction of ad network revenue), from which
we then extract click-spam signatures that apply more broadly.
Other approaches to mitigating click-spam include SbotMiner [40],
Sleuth [33] and Detectives [32]. SbotMiner tries to identify bot
activity by using KL-divergence to detect change in query distribu-
tions, followed by pruning of false positives due to ﬂash crowds, by
leveraging heterogenity for genuine users. Sleuth uncovers single
publisher fraud by ﬁnding correlation in multi-dimensional data;
however, they claim that the technique is suitable only when the
185botnet uses tens of hundreds of IP addresses. Detectives detects
coalition hit inﬂation attacks by their similarity seeker algorithm;
it discovers coalitions made by pairs of fraudsters, which is then
enhanced in [31] by ﬁnding groups of fraudsters. All these ap-
proaches apply only to botnet and malware driven click-spam, which
is dwarfed by other sources of click-spam in our data.
Premium Clicks [27], access control gadgets (ACG) [37] and
CDN fraud prevention [30] focus on mitigation strategies that go
beyond botnets. Premium clicks employs economic disincentives
that devalue clicks from non-gold-standard users. ACGs ensure
authentic UI interactions by users clicking a link. CDN fraud pre-
vention proposes a heavy-weight challenge-response protocol for
publisher-payee CDN models. While the ﬁrst assumes an alternate
ad economy, the second and third (applied to ad networks) require
re-architecting the browser, or the ad network infrastructure. None
of these approaches apply to click-spam in existing ad networks.
Focusing squarely on existing ad networks, Camelot [28] is Goo-
gle’s click-fraud penetration system. It can test the susceptibility of
the network to known click-spam signatures, but does not itself de-
tect new signatures. [39] describes the invalid click detection sys-
tem inside Google, without identifying the speciﬁc heuristics that
are used to identify invalid clicks. No heuristic is perfect. Our data
shows click-spam is still an open problem despite these deployed
systems.
7. CONCLUSION
In this paper, we take a systematic look at click-spam. We pro-
pose the ﬁrst methodology for advertisers to independently mea-
sure click-spam rates on their ads. We also develop an automated
methodology for ad networks to proactively ﬁngerprint different
simultaneous click-spam attacks. We validate both methodologies
using data from major ad networks. We then conduct a large-scale
measurement study of click-spam across ten major ad networks and
four types of ads. In the process, we identify and perform in-depth
analysis on seven ongoing click-spam attacks not currently caught
by major ad networks. We conclude that even for the largest ad
networks, click-spam is a serious problem, and is especially ram-
pant in the mobile advertising context. Given the evolving nature of
click-spam, we believe that click-spam is an open problem that re-
quires a concerted effort from the research community to tackle. To
this end we have publicly released the data gathered for this paper
to aid other researchers in the design of novel click-spam defense
techniques.
Acknowledgments
We’d like to thank Jigar Mody, Matt Graham, our shepherd Kir-
ill Levchenko, and our anonymous reviewers. This paper is much
improved thanks to their valuable feedback and suggestions.
8. REFERENCES
[1] AdSense for domains program policies.
[8] Google Click Fraud Inﬂates Conversion Rates and Tricks Advertisers into
Overpaying. http://www.benedelman.org/news/011210-1.html.
[9] Google Redirect Virus: How to Remove.
http://www.pcmag.com/article2/0,2817,2370676,00.asp.
[10] International Cyber Ring That Infected Millions of Computers Dismantled.
http://www.fbi.gov/news/stories/2011/november/malware_110911.
[11] Malware connection report. http://www.malware-control.com/statics-
pages/03aaf7c8e47ef32e8de23dfe9215d4a5.php.
[12] Stealing Clicks. http://www.forbes.com/2007/09/21/google-click-forensics-
tech-secure-cx_ag_0924fraud.html.
[13] Uncovering an advertising fraud scheme. Or “the Internet is for porn”.
http://www.behind-the-enemy-lines.com/2011/03/uncovering-advertising-
fraud-scheme.html.
[14] Upcoming changes in Google’s HTTP Referrer.
http://googlewebmastercentral.blogspot.com/2012/03/upcoming-changes-in-
googles-http.html.
[15] L. V. Ahn, M. Blum, N. J. Hopper, and J. Langford. Captcha: using hard ai
problems for security. EUROCRYPT’03, 2003.
[16] Click Quality Team, Google Inc. How Fictitious Clicks Occur in Third-Party
Click Fraud Audit Reports.
http://www.google.com/adwords/ReportonThird-PartyClickFraudAuditing.pdf.
[17] G. Cormode and S. Muthukrishnan. What’s hot and what’s not: Tracking most
frequent items dynamically. In Proceedings of ACM PODC, July 2003.
[18] G. Cormode and S. Muthukrishnan. Improved data stream summaries: The
count-min sketch and its applications. Journal of Algorithms, 2004.
[19] N. Daswani, C. Mysen, V. Rao, S. Weis, K. Gharachorloo, and
S. Ghosemajumder. Crimeware:Understanding New Attacks and Defenses,
chapter Online Advertising Fraud. 2008.
[20] N. Daswani and M. Stoppelman. The anatomy of clickbot.A. In Proceedings of
HotBots, 2007.
[21] J. R. Douceur. The Sybil Attack. In Proceedings of IPTPS ’02.
[22] C. Estan and G. Varghese. New Directions in Trafﬁc Measurement and
Accounting. In Proceedings of ACM SIGCOMM, Aug. 2002.
[23] A. M. Eugene Rodionov. The evolution of tdl: Conquering x64.
http://go.eset.com/us/resources/white-papers/The_Evolution_of_TDL.pdf.
[24] B. Geddes. Search arbitrage: Web blight or brilliant marketing strategy?
http://searchengineland.com/search-arbitrage-web-blight-or-brilliant-
marketing-strategy-10768.
[25] H. Haddadi. Fighting online click-fraud using bluff ads. SIGCOMM Comput.
Commun. Rev., 2010.
[26] N. Immorlica, K. Jain, M. Mahdian, and K. Talwar. Click Fraud Resistant
Methods for Learning Click-Through Rates. In Proceedings of the Workshop
on Internet and Network Economics (WINE ’05).
[27] A. Juels, S. Stamm, and M. Jakobsson. Combating click fraud via premium
clicks. In Proceedings of 16th USENIX Security Symposium on USENIX
Security Symposium, 2007.
[28] C. Kintana, D. Turner, J.-Y. Pan, A. Metwally, N. Daswani, E. Chin, and
A. Bortz. The goals and challenges of click fraud penetration testing systems.
International Symposium on Software Reliability Engineering, 2009.
[29] H. Lieberman. Letizia: An agent that assists web browsing. In International
Joint Conference on Artiﬁcial Intelligence, 1995.
[30] S. Majumdar, D. Kulkarni, and C. V. Ravishankar. Addressing click fraud in
content delivery systems. In In Proceedings of the 26th IEEE INFOCOM
International Conference on Computer Communications, 2007.
[31] A. Metwally, D. Agrawal, A. El Abbad, and Q. Zheng. On hit inﬂation
techniques and detection in streams of web advertising networks. ICDCS ’07,
2007.
[32] A. Metwally, D. Agrawal, and A. El Abbadi. Detectives: detecting coalition hit
inﬂation attacks in advertising networks streams. WWW ’07, 2007.
[33] A. Metwally, F. Emekçi, D. Agrawal, and A. El Abbadi. Sleuth:
Single-publisher attack detection using correlation hunting. VLDB, 2008.
[34] B. Miller, P. Pearce, C. Grier, C. Kreibich, and V. Paxson. What’s clicking
what? techniques and innovations of today’s clickbots. In Proceedings of the
8th international conference on Detection of intrusions and malware, and
vulnerability assessment, DIMVA’11, 2011.
[35] B. Mordkovich and E. Mordkovich. Click fraud and how to counteract it in ad
campaigns. In Pay-Per-Click Search Engine Marketing Handbook, 2005.
[36] E. Rodionov and A. Matrosov. The evolution of TDL: Conquering x64.
http://support.google.com/adsense/bin/answer.py?answer=96332.
Technical report, 2011.
[2] The adsense revenue share.
http://adsense.blogspot.com/2010/05/adsense-revenue-share.html.
[3] Click Fraud Falls in Q4 2010.
[37] F. Roesner, T. Kohno, A. Moshchuk, B. Parno, H. Wang, and C. Cowan.
User-driven access control Rethinking permission granting in modern
operating systems. IEEE Symposium on Security and Privacy, 2012.
http://searchenginewatch.com/article/2050117/Click-Fraud-Falls-in-Q4-2010.
[38] B. Stone-Gross, R. Stevens, A. Zarras, R. Kemmerer, C. Kruegel, and
[4] Click fraud rampant in online ads, says bing.
http://www.theaustralian.com.au/media/click-fraud-rampant-in-online-ads-
says-bing/story-e6frg996-1226056349034.
[5] Cloaking and Faking the Referrer.
G. Vigna. Understanding fraudulent activities in online ad exchanges. Internet
Measurement Conference, 2011.
[39] A. Tuzhilin. The lane’s gift v. google report.
http://googleblog.blogspot.in/pdf/Tuzhilin_Report.pdf.
http://kbeezie.com/view/cloaking-and-faking-referrer/.
[40] F. Yu, Y. Xie, and Q. Ke. Sbotminer: large scale search bot detection. WSDM
[6] For Impatient Web Users, an Eye Blink Is Just Too Long to Wait.
’10, 2010.
http://www.nytimes.com/2012/03/01/technology/impatient-web-users-ﬂee-
slow-loading-sites.html.
[7] Google AdSense for Domains.
http://www.google.com/domainpark/index.html.
[41] Q. Zhang, T. Ristenpart, S. Savage, and G. M. Voelker. Got trafﬁc?: an
evaluation of click trafﬁc providers. In Proceedings of the 2011 Joint
WICOW/AIRWeb Workshop on Web Quality, WebQuality ’11, 2011.
186