Online
ABY-GMW [34]
ABY-A [34]
Offline
Online
Offline
Online
0.00
10.46
0.00
0.59
11.71
423.82
0.00
11.83
11.90
11.60
11.91
2.73
112.29
0.00
2.34
2.63
2.42
2.49
25.78
174.52
0.00
9.27
17.39
9.11
1.06
4.73
14.25
0.00
0.52
1.63
1.15
0.68
Sharemind [18]
Online
1 µs
17
1 µs
17
2.5 s
5 s
34
Chameleon
Offline
0.00
4.24
0.00
1.50
2.46
1.54
1.52
Online
0.00
0.13
0.00
0.56
1.48
1.09
0.63
Table 3: COMMUNICATION (in kilobytes unless stated otherwise) for different atomic operations and comparison with prior
art. Each experiment is performed for 1,000 operations on 32-bit numbers in parallel. The detailed performance results of the
ABY framework [34] is provided for three modes of operation: GC, GMW, and Additive. Minimum values marked in bold.
TinyGarble [81]
Total
7936
318 K
0
8192
8192
7936
8192
Op
ADD
MULT
XOR
AND
CMP
EQ
MUX
ABY-GC [34]
Offline
Online
992
47649
0
1024
1024
992
1024
0
0
0
0
0
0
0
ABY-GMW [34]
ABY-A [34]
Offline
Online
Offline
Online
0
1280
0
16
3593
37900
0
1028
2851
995
33
76
840
0
16
45
16
8
Sharemind [18]
Total
0
192
0
192
384
Chameleon
Offline
0
8
0
12
23
8
8
Online
0
16
0
8
33
12
4
Table 4: Run-Times (in milliseconds) for conversion opera-
tions and comparison with prior art. Each experiment is per-
formed for 1,000 operations on 32-bit numbers in parallel.
Minimum values marked in bold.
ABY [34]
Chameleon
Offline Online Offline Online
0.00
2.33
1.15
12.91
0.00
3.45
13.24
15.83
0.00
9.47
17.05
19.75
0.00
2.44
1.30
14.03
Op
Y2B
B2A
B2Y
A2Y
Table 5: Communication (in bits) in the setup phase in
Chameleon compared to prior art ABY [34].
OT
B-MT
A-MT (bitlength ℓ = 16)
A-MT (bitlength ℓ = 32)
A-MT (bitlength ℓ = 64)
ABY [34] Chameleon Improvement
-
256×
273×
289×
321×
128
256
4,368
9,248
20,544
128
1
16
32
64
6.1 Deep Learning
We evaluate our framework on Deep Neural Networks (DNNs) and
a more sophisticated variant, Convolutional Deep Neural Networks
(CNNs). Processing both CNNs and DNNs requires the support
for signed fixed-point numbers. We compare our results with the
state-of-the-art Microsoft CryptoNets [35], which is a customized
solution for this purpose based on homomorphic encryption, as
well as other recent solutions.
9
i
Deep Neural Networks. Deep learning is a very powerful
method for modeling and classifying raw data that has gained
a lot of attention in the past decade due to its superb accuracy.
Deep Learning automatically learns complex features using arti-
ficial neural networks. While there are many different DNNs and
CNNs, they all share a similar structure. They are networks of
multiple layers stacked on top of each other where the output of
a layer is the input to the next layer. The input to DNNs is a fea-
ture vector which we denote as x. The input is passed through the
intermediate layers (hidden layers). The output vector of the Lth
layer is shown as x(L) where x (L)
denotes the ith element. The
length of the vector can change after each layer. The length of the
intermediate result vector at layer L is shown as NL = length(x(L) ).
A DNN is composed of a series of (i) Fully Connected (FC) layer: the
output x(L) is the matrix multiplication of input vector x(L−1) and
a matrix weight W, that is, x(L) = x(L−1) · W. In general, the size
of the input and output of the FC layer is shown as FCNL−1×NL .
(ii) Activation layer (Act): which applies an activation function f (.)
on the input vector: x (L)
). The activation function is
usually Rectified Linear Unit (ReLu), Tangent-hyperbolic (Tanh),
or Sigmoid functions [35, 79].
= f (x (L−1)
The input to a CNN is a picture represented as a matrix X where
each element corresponds to the value of each pixel. Pictures can
have multiple color channels, e.g., RGB, in which case the picture
is represented as a multidimensional matrix, a.k.a, tensor. CNNs are
similar to DNNs but they can potentially have additional layers:
(i) Convolution (C) layer which is essentially a weighted sum of
“square region” of size sq in the proceeding layer. To compute the
next output, the multiplication window on the input matrix is
moved by a specific number, called stride (st ). The matrix weight is
i
i
Figure 3: Architecture of our Convolutional Neural Network trained for the MNIST dataset. The upper bar illustrates which
protocol is being executed at each phase of the CNN. The lower bar shows different layers of the CNN from the deep learning
perspective.
called kernel. There can be Nmap (called map count) kernels in the
convolution layer. (ii) Mean-polling (MeP) which is the average of
each square region of the proceeding layer. (iii) Max-polling (MaP)
is the maximum of each square region of the proceeding layer. The
details of all layers are provided in Table 6.
Many giant technology companies such as Google, Microsoft,
Facebook, and Apple have invested millions of dollars in accurately
training neural networks to serve in different services. Clients that
want to use these services currently need to reveal their inputs that
may contain sensitive information to the cloud servers. Therefore,
there is a special need to run a neural network (trained by the cloud
server) on an input from another party (clients) while keeping both
the network parameters and the input private to their respective
owners. For this purpose, Microsoft has announced CryptoNets [35]
that can process encrypted queries in neural networks using homo-
morphic encryption. Next, we compare the performance result of
Chameleon to CryptoNets and other more recent works.
Table 6: Different types of layers in DNNs and CNNs.
Layer
FC
Act
C
MeP
MaP
× x (L−1)
j
=(cid:80)NL−1−1
j=0 W (L−1)
(cid:80)sq−1
=(cid:80)sq−1
b=0 W (L−1)
(i·st +a)(j·st +b )
= Mean(x L−1
(i +a)(j+b ) ), a, b ∈ {1, 2, ..., sq}
= Max(x L−1
(i +a)(j+b ) ), a, b ∈ {1, 2, ..., sq}
Functionality
x (L)
i
x (L)
i
x (L)
ij
x (L)
ij
x (L)
ij
= f (x L−1
i
a=0
× x L−1
ij
)
ab
Comparison with Previous Works. A comparison of recent
works is given in Table 7 and described next. We use the MNIST
dataset [58] (same as Microsoft CryptoNets) containing 60,000 im-
ages of hand-written digits. Each image is represented as 28 × 28
10
pixels with values between 0 and 255 in gray scale. We also train the
same NN architecture using the Keras library [29] running on top
of TensorFlow [1] using 50,000 images. We achieve a similar test ac-
curacy of ∼ 99% examined over 10,000 test images. The architecture
of the trained CNN is depicted in Figure 3 and composed of (i) C
layer with a kernel of size 5×5, stride 2, and map count of 5. (ii) Act
980×100 layer.
layer with ReLu as the activation function. (iii) A FC
100×10 layer. The
(iv) Another ReLu Act layer, and (v) another FC
lower bar in Figure 3 shows the different layers of the CNN while
the upper bar depicts the corresponding protocol that executes each