Reject	
AED	
AE	
The veriﬁcation process starts from checking the validity of the
published Proof of Past Log PPL. To do so, ﬁrst, the auditor decrypts
the SPKc(AED) using the public key of the CSP and he will get the
AED. Then the auditor generates the hash value from the dycrypted
AED. If the generated hash and the H(AED) of the PPL matches,
then the auditor accepts the PPL as a valid proof of log, otherwise
he rejects the veriﬁcation process.
In the next step, the auditor generates the Accumulator Entry
AE for each DBLE. Then, he will check whether the calculated AE
exists in the AED. If exists, then the auditor proceeds towards log
order veriﬁcation process, otherwise he rejects the provided log
information.
Sequence Veriﬁcation: Figure 5 illustrates the log order veriﬁca-
tion process, where we verify whether the current log (DBLE1) is
actually after the previous log (DBLE0) in the original sequence
of log generation. In the ﬁgure 5, ELE0 denotes the Encrypted
Log Entry ELE of the ﬁrst log and ELE1 represents the same for
the second log. To verify the correct order, the auditor calculates
the Log Chain LCa from the ﬁrst Log Chain LC0 and the second
Encrypted Log ELE1 according to the following equation.
LCa =
(6)
If LCa matches with the 2nd Log Chain LC1 then the auditor accepts
the logs, otherwise he rejects it.
Figure 5: Log Order Veriﬁcation Process Flow
5. SECURITY ANALYSIS
As CSPs have control over generating the logs and the proofs,
they can always tamper with the logs. After acquiring logs through
API or management console, investigators can also alter the logs
before presenting it to court. Therefore, here we propose a tamper
evident scheme. Any violation of the integrity and conﬁdentiality
properties, as mentioned in Section 3 can be detected during the
veriﬁcation process.
In our collusion model, there are three entities involved – CSP,
user, and investigator. All of them can be malicious individually
or can collude with each other. We denote an honest CSP as C,
a dishonest CSP as ¯C, an honest user as U, a dishonest user as
¯U, an honest investigator as I, and a dishonest investigator as ¯I.
Hence, there can be total eight possible combinations of collusion.
Table 1 presents all the combinations of collusion, possible attacks
for each collusion, and required security properties to defend that
collusion. Here, we discuss how our proposed system can ensure
all the security properties, which are required to protect collusion
between CSP, user, and investigator.
• I1, I2, I4, I5: A CSP can collude with the cloud user or the
investigator and can remove crucial log information. Also,
while providing logs through the API or the management con-
sole, the CSP can simply hide some crucial log entries. An
Investigator can also hide logs before at the time of present-
ing evidence to court, though he have received correct logs
through the log API. However, at the veriﬁcation stage, our
system can detect any such removal of log entries. Let us
assume that there are three log entries DBLE0, DBLE1, and
DBLE2 and their proof has already been published. Now, if
CSP removes DBLE1 and provides only DBLE0 and DBLE2
to the investigator, then this removal can be easily detected
at the sequence veriﬁcation stage. In this case, the hash of
LC0 and ELE2 will not match with the LC2 because the orig-
inal LC2 was calculated by hashing LC1 and ELE2. In the
same way, an auditor can detect the re-ordering of logs. For
example, while providing the logs to an auditor, if the CSP
or investigator provides the log in DBLE0, DBLE2, DBLE1
order, then using the same technique, the auditor can identify
that DBLE2 does not come after DBLE0 in actual generation
order. A CSP can further try to change the DBLE2 by replac-
ing the original LC2 with a new Log Chain value so that, in
the sequence veriﬁcation process, the order breaking will not
be detected. However, an attempt of changing the DBLE2
will be detected during the individual log entry veriﬁcation
phase. The accumulator entry of the fake DBLE2 will not
exist in the published Proof of Past Log PPL.
• I3, I6: A colluding CSP can plant false log information while
providing the log to the investigator. However, if the CSP
does this after publishing the proof, our system can detect
these phony logs. A dishonest investigator can also try to
frame an honest user by presenting fake logs to the court.
Suppose, DBLEF is the fake log and the auditor generates the
Accumulator Entry AEF for this log. If it’s fake, then AEF
will not be present in the AED of the Proof of Past Log PPL
and the auditor can reject that incorrect log.
• I7: After publishing the proof of past log PPL, CSP cannot
repudiate the published proof as the accumulator entry AED is
signed by CSP’s private key. Nobody other than the CSP can
use that private key to sign the AED. Hence, after decrypting
the signed value and generating hash on the decrypted value,
if it matches with the hashed AED value, the CSP cannot
repudiate the published value. Additionally, if the CSP comes
up with a false PPLf in place of a published PPL, then it will
be easily detected. In that case, the H(AED) of the published
PPL and the H(AEDf) of the false PPLf will not be same. As
the CSP has already signed the AED of the published PPL
using its private key, it cannot deny the published value.
• C1, C2: To store the proof of the logs, we propose to use an
accumulator function, which will ensure the C1 property, i.e.,
from the proof of logs, adversaries cannot recover any log.
We implement our scheme using Bloom ﬁlter and One-Way
Accumulator, which can ensure this property. While storing
the log data in persistent storage, we propose to encrypt some
crucial information e.g., user id, destination IP, etc by using a
common public key of all the investigator agencies. Hence, a
LCa	
Equal?	
No	
ELE0	
LC0	
Reject	
Accept	
Yes	
ELE1	
LC1	
Is Honest?
Notation Attack
Required Security
Properties
CSP User


Investigator






















C U I
¯C U I
C ¯U I
C U ¯I
C ¯U ¯I
¯C U ¯I
¯C ¯U I
¯C ¯U ¯I
No attack
Reveal user activity from logs
Recover other cloud users’ log from published proof
Remove, reorder, and plant fake logs
Remove, reorder, and plant fake logs
Remove, reorder, plant fake logs, and repudiate published PPL
Remove, reorder, plant fake logs, and repudiate published PPL
Remove, reorder, plant fake logs, and repudiate published PPL
None
C2
C1
I4, I5, I6
I4, I5, I6
I1, I2, I3, I4, I5, I6, I7
I1, I2, I3, I7
I1, I2, I3, I4, I5, I6, I7
Table 1: Collusion model, possible attacks and required security properties
6.
malicious cloud employee cannot retrieve plain log informa-
tion from the persistent storage; e.g., identifying the visiting
IPs of a particular user will not be possible by the malicious
cloud employee. In this way, our scheme can ensure the C2
property.
IMPLEMENTATION AND EVALUATION
In this section, we present the implementation of SecLaaS on
OpenStack and performance analysis of the scheme using different
types of accumulators.
6.1
System Setup: We used Openstack1 and Snort for testing and im-
plementation of our project. OpenStack is an open source cloud
computing software and Snort is a free lightweight network intrusion
detection system. We created the virtual environments with Virtu-
alBox (a free virtualization software)2 running on a single Ubuntu
machine. Figure 6 illustrates the system setup and below is the
description of the system:
Implementation
• VirtualBox 4.1.22 r80657 for Ubuntu 12.04 LTS
• Openstack (Essex release, came out by the end of April 2012)
installation in VirtualBox; for simplicity, the system had one
node controller. Conﬁguration of vitualized cloud controller:
Intel 2.5Ghz Dual Core cpu, 8 GB ram and 20 GB hard drive.
Ubuntu 12.04 64-bit Sever edition is used as the Operating
system for Openstack setup.
• In the virtualized environment, the Cloud Controller required
following network adapter conﬁguration in VirtualBox to
work properly:
– Adapter 1: Attached to NAT- eth0 of the Cloud con-
troller is connected here.
– Adapter 2: Host-only network for Public interface- con-
nected with eth1 (IP was set to 172.16.0.254, mask 255.
255.0.0, dhcp disbaled)
– Adapter 3: Host-only network for Private (VLAN) in-
terface connected with eth2 (IP to 11.0.0.1, mask 255.
0.0.0, dhcp disbaled)
• We used RSA (2048 bit) for signature generation and SHA-
2(SHA-256) hash function for hashing.
We set up Snort in node controller to track the network activity of
the virtual machines. We added two virtual machines: the ﬁrst one
had private IP: 11.1.0.3 and public IP: 172.16.1.1; while the other
had private IP: 11.1.0.5 and public IP: 172.16.1.3. Here is a sample
Snort log:
“11/19-13:43:43.222391 11.1.0.5:51215 -> 74.125.130.106:80
TCP TTL:64 TOS:0x0 ID:22101 IpLen:20 DgmLen:40 DF
***A***F Seq: 0x3EA405D9 Ack: 0x89DE7D Win: 0x7210
TcpLen: 20”
Figure 6: Prototype Environment Conﬁguration
[28]
• Host machine’s hardware conﬁguration: Intel Core I7 quad
core CPU, 16 GB ram and 750 GB hard drive. Ubuntu 12.04
LTS 64-bit is used as Host Operating System.
9 1http://www.openstack.org
9 2https://www.virtualbox.org
This log tells that the virtual machine with private IP 11.1.0.5
performed a http request to machine 74.125.130.160. By reverse
engineering Openstack’s “nova” mysql database, it is also possible
to ﬁnd out the static private IP and user information from a public IP.
We used the references among FloatingIps, FixedIps and Instances
tables to resolve the user id for a particular log entry. Figure 7 shows
the relation between these three tables.
We implemented the Proof of Past Log PPL scheme of the Se-
cLaaS using two accumulators. One is BloomFilter [6] and another
VirtualBox VM	
OpenStack	
Tiny VM	
eth0	
Virtual Box	
Nat (Internet)	
Vboxnet0 (Public)	
Vboxnet1 (VLAN)	
eth0	
eth1	
eth2	
Host Machine	
Figure 7: Resolving User ID from Public IP
is One-Way Accumulator [4]. The steps from (g) to (k) will work
differently for the two accumulators.
BloomFilter: A Bloom ﬁlter is a probabilistic data structure with
no false negatives rate, which is used to check whether an element
is a member of a set or not [6]. Bloom ﬁlter stores the membership
information in a bit array. Bloom ﬁlters decrease the element inser-
tion time and membership checking time. The only drawback of the
Bloom ﬁlter is the probability of ﬁnding false positives. However,
we can decrease the false positive probability by using a large bit
array.
To use the Bloom ﬁlter as a proof, we use one bloom ﬁlter for
one static IP for each day. That means, one Bloom ﬁlter stores the
proof of all the logs of one static IP for a particular day. In step (g),
the logger retrieves the bloom ﬁlter from the proof storage, which
holds the bit positions for the previously inserted logs of the day.
In step (h), while creating the accumulator entry AE, the logger
will generate the k number of bit positions for the database entry
DBLE by hashing the log for k times. Then, the logger updates
the previously retrieved Bloom ﬁlter with the newly generated AE
and sends the updated Bloom ﬁlter to the proof storage. At the end
of each day, the CSP will retrieve the Bloom ﬁlter entry of each
static IP AED and create the proof of past log PPL for that day using
equation 5.
In the veriﬁcation phase, after verifying the validity of the pub-
lished proof, the auditor will hash the log entry that he has received
from the API call and calculate the bit positions of the Bloom ﬁlter.
Then he will compare these bit positions with the published AED. If
all the calculated bit positions are set in the published Bloom ﬁlter
AED, then the veriﬁer will be sure about the validity of the log. One
single false bit position means the log entry is not valid.
One-Way Accumulator: A One-Way accumulator is a crypto-
graphic accumulator, which is based on RSA assumption and pro-
vides the functionality of checking the membership of an element
in a set [4]. This scheme works with zero false negative and false
positive probability. Initially, we create the public and private values
for the accumulator. The private values are two large prime numbers
P and Q. The ﬁrst public value is N, where N = P*Q and the second
public value is a large random number which is the initial seed X.
In step (g), the logger retrieves the accumulator entry AE. If there
is no proof entry, i.e., the AE is empty for an IP on a day, then the
AE of the ﬁrst DBLE of the day is generated using the following
equation
AE = XH(DBLE)modN
(7)
where H(DBLE) is a numeric hash value of DBLE. If the retrieved AE
is not empty, then the new AE will be generated using the following
equation
AE = AEH(DBLE)modN
(8)
The logger module then sends the calculate AE to the proof storage.
At the end of the day, the logger retrieves the last accumulator
entry AED and creates the proof of past log PPL for the day using
equation 5. The logger needs to do some additional computation
here comparing with the Bloom ﬁlter. It will generate an identity
for each DBLE and tagged it with the DBLE. If there are k number
of DBLE on a day then the identity ID of the ith DBLE will be
calculated using the following equation
ID = XH(DBLE1) H(DBLE2)... H(DBLEi-1) H(DBLEi+1)....H(DBLEk)
(9)
While verifying the validity of the DBLEi, the veriﬁer computes
IDH(DBLEi)mod N and compares it with AED. If AED = IDH(DBLEi)mod
N, then the veriﬁer will be sure about the validity of the log.
6.2 Evaluation
To evaluate the performance of our scheme we ran our experi-
ment using multiple accumulators. For Bloom ﬁlter, we used two