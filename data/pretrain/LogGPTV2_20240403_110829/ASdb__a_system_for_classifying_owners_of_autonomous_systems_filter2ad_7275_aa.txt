title:ASdb: a system for classifying owners of autonomous systems
author:Maya Ziv and
Liz Izhikevich and
Kimberly Ruth and
Katherine Izhikevich and
Zakir Durumeric
ASdb: A System for Classifying Owners of Autonomous Systems
Maya Ziv
Stanford University
PI:EMAIL
Liz Izhikevich
Stanford University
PI:EMAIL
Kimberly Ruth
Stanford University
PI:EMAIL
Katherine Izhikevich
UC San Diego
PI:EMAIL
Zakir Durumeric
Stanford University
PI:EMAIL
Dun & Bradstreet), website classifiers (e.g., Zvelo), crowdwork (e.g.,
Amazon Mechanical Turk), and our own machine learning clas-
sifiers. Even with the increased granularity, ASdb achieves both
higher coverage and accuracy than prior work with 96% coverage
of all registered ASes and 93% and 75% accuracy on 17 categories
and 95 sub-categories, respectively (Section 2).
ASdb builds on two key observations. First, while there are no
data sources that provide sufficient data about ASes, nearly all ASes
belong to identifiable organizations, and there exists an established
industry that maintains and provides access to business records. Sec-
ond, nearly 90% of ASes have associated domains that host websites
with descriptive text that can be used for classification. We start our
study by evaluating popular business databases, website classifiers,
and existing AS classification datasets against a “gold standard”
dataset curated by a team of expert researchers (Section 3). We
find that in aggregate, business data sources and website classifiers
provide accurate category labels for up to 89% of non-technology
companies, but fail to accurately categorize the two largest classes
of ASes: ISPs and hosting providers.
To fill gaps and arbitrate disagreement between external data
sources, we explore building our own machine learning classifiers
and using crowdwork to categorize ASes (Section 4). We show
that machine learning can correctly classify ISPs and cloud/hosting
providers with 94% and 90% accuracy, respectively. We find that
crowdworkers can both catch ML failures and resolve data source
disagreements with a 98.7% and 94% accuracy, respectively. How-
ever, the monetary cost required to incentivize crowdworker accu-
racy introduces a barrier that ultimately makes crowdwork imprac-
tical for our system.
Building on the strengths of business databases, website classi-
fiers,existing AS databases and our new machine learning classifiers,
we introduce ASdb, a system that continuously maintains a dataset
of Autonomous Systems, their owners, and their industry types
(Section 5). ASdb uses a configurable internal matching algorithm
to unify all components, handling data source inconsistencies and
missing information gracefully. We evaluate ASdb against 620 man-
ually labeled ASes. ASdb provides multi-layer classification for 96%
of all ASes and achieves 93% accuracy for top-level categories and
75% accuracy for sub-categories.
We hope that a high-fidelity AS classification dataset will enable
the research community to answer new research questions. We will
continually release the up-to-date ASdb dataset at
https://asdb.stanford.edu for research use.
ABSTRACT
While Autonomous Systems (ASes) are crucial for routing Internet
traffic, organizations that own them are little understood. Regional
Internet Registries (RIRs) inconsistently collect, release, and update
basic AS organization information (e.g., website), and prior work
provides only coarse-grained classification. Bootstrapping from
RIR WHOIS data, we build ASdb, a system that uses data from es-
tablished business intelligence databases and machine learning to
accurately categorize ASes at scale. ASdb achieves 96% coverage
of ASes, and 93% and 75% accuracy on 17 industry categories and
95 sub-categories, respectively. ASdb creates a more rich, accurate,
comprehensive, and maintainable dataset cataloging AS-owning
organizations. This system, and resulting dataset, will allow re-
searchers to better understand who owns the Internet, and perform
new forms of meaningful analysis and interpretation at scale.
ACM Reference Format:
Maya Ziv, Liz Izhikevich, Kimberly Ruth, Katherine Izhikevich, and Zakir
Durumeric. 2021. ASdb: A System for Classifying Owners of Autonomous
Systems. In ACM Internet Measurement Conference (IMC ’21), November 2–4,
2021, Virtual Event, USA. ACM, Virtual, 17 pages. https://doi.org/10.1145/
3487552.3487853
1 INTRODUCTION
To make sense of the prohibitively large number of Internet hosts
and services, operators and researchers frequently aggregate hosts
and networks by their origin Autonomous System (AS). ASes are a
natural aggregation level—they are typically owned and controlled
by a single organization. Current AS classification systems provide
only coarse categorization of common industries and topological
roles (e.g., ISPs), which fundamentally limits the types of questions
we can ask about hosts. For example, today, it is nearly impossible
to comprehensively ask seemingly simple questions like “Which
utility companies have vulnerable Internet-facing services?” and
“Which industries display the most BGP instability?”
In this work, we introduce ASdb, a system that classifies or-
ganizations into 17 industry categories and 95 sub-categories, by
strategically combining data from external business databases (e.g.,
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
IMC ’21, November 2–4, 2021, Virtual Event, USA
© 2021 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-9129-0/21/11...$15.00
https://doi.org/10.1145/3487552.3487853
703
IMC ’21, November 2–4, 2021, Virtual Event, USA
Maya Ziv, Liz Izhikevich, Kimberly Ruth, Katherine Izhikevich, and Zakir Durumeric
2 BACKGROUND AND RELATED WORK
Regional Internet Registries (RIRs) like ARIN and RIPE maintain ba-
sic AS ownership information (e.g., business name, address, website,
and abuse contacts), which they publish through WHOIS. Unfor-
tunately, WHOIS data is only semi-structured, and, in many cases,
outdated or incomplete. More critically, RIRs do not publish AS
owners’ industry sector, age, revenue, or other firmographic details,
thus obscuring even basic information about whether an AS is used
by an ISP, a cloud hosting provider, or a non-technology company.
While it is typically possible to manually research individual ASes,
it remains an open problem to label ASes at scale.
There have been several attempts to com-
AS Classification.
prehensively categorize the organizations that control ASes. Dim-
itropolous et al. employed text classification on AS WHOIS data
to categorize ASes into six categories (large and small ISP, IXP,
customer, university, network information centers) with a reported
95% coverage and 78% accuracy [33]. Until January 2021, CAIDA
provided a dataset based on Dimitropolous et al.’s methodology,
CAIDA UCSD AS Classification Dataset, which coarsely categorized
ASes as “transit/access,” “enterprise,” or “content” [5]. Due to declin-
ing dataset accuracy over the past 15 years, CAIDA recently phased
out the dataset. We confirmed this finding by manually classifying
150 ASes (using the methodology detailed in Section 3), and found
that the December 2020 CAIDA dataset achieved 72% coverage and
58%, 75%, and 0% accuracy for each category, respectively.
More recently, Baumann and Fabian [27] performed a keyword
analysis of WHOIS data to classify ASes into 10 categories (com-
munication, construction, consulting, education, entertainment, fi-
nance, healthcare, transport, travel, and utilities) with 57% coverage.
They augment their keyword analysis by matching AS names to
U.S. Securities and Exchange Commission (SEC) records and ex-
tracting industry classification codes. This analysis is restricted to
publicly traded companies in the U.S., and they furthermore omit
all SEC search results with multiple matches for any AS, limiting
the augmentation to 469 ASes.
Routing Topology. Cai et al. [31] clustered RIR records belong-
ing to the same organization; CAIDA publishes a dataset based on
the methodology [12]. However, the dataset does not classify the
organizations it identifies. There is also a large body of work on AS
peering relationships and Internet topology (e.g., [34, 46, 48, 57, 59]).
Most relevant, Dhamdhere and Dovrolis [32] use topological prop-
erties of ASes to infer broad AS types (enterprise customers, small
and large transit providers, access/hosting providers, and content
providers) with an accuracy of 76–82%.
PeeringDB [6] is a crowd-sourced data-
Non-Academic Work.
base where operators can voluntarily register ASes as one of six
categories: “Cable/DSL/ISP”, “Network Service Provider”, “Content”,
“Education/Research”, “Enterprise”, and “Non-profit.” As we describe
in Section 3, PeeringDB contains only 15% of ASes but has a 95%
recall. IPinfo.io [13] uses a black-box methodology to provide the
organization name and domain of many ASes as well as a broad
classification into one of 4 categories: ISP, hosting, education, and
business. In Section 3 we show that it has a 30% coverage and
96% recall, making it one of the most accurate datasets.
Website and Business Classification. Our work draws on both
web classification systems and existing business databases. Prior
Source
Business DB
Searchable Name
Industry Domain Bulk
✓
✓
✓
✓
✓
✓
-
NAICS
Custom
NAICS
NAICS*
Custom
Custom
Custom
✓
✓
✓
✓
✓
✓
✓
Paid
Free
Paid
Paid
Free
Paid
Paid
N, W, L
N, W, L
W
D&B
Crunchbase N, W
ZoomInfo
Clearbit
Networking
PeeringDB
IPinfo
A
A
Website Class
Zvelo
W
Table 1: Candidate Data Sources—We catalogue the attributes of
business datasources. Sources are searchable by different metadata
(N = Name, W = Website, L = Location, A = ASN). Only three sources
overlap in their classification system, utilizing NAICS. *Clearbit pro-
vides 2-digit NAICS prefixes and their own custom system. Based on
our Section 3 evaluation, ASdb uses D&B, Crunchbase, PeeringDB,
IPinfo, and Zvelo.
work has examined mechanisms for classifying web domains [24, 30,
47, 53] as well as the difficulty (and sometimes subjectivity) of web-
site classification [51, 60]. Another line of work has looked at the
origins, development, and research impact of business classification
systems [45, 49, 58], as well as biases and disagreement of business
databases that use them [35, 42]. We particularly draw from Phillips
and Ormsby [52] in shaping our classification approach.
3 EVALUATING EXTERNAL DATA SOURCES
While there are no data sources that describe ASes at the granularity,
coverage, and accuracy we seek, we observe that nearly all ASes
belong to identifiable organizations, and there exists an established
industry that maintains and sells access to business records. Often
advertised to sales teams for researching prospective customers,
companies like Dun & Bradstreet [10] and Crunchbase [9] offer
products that allow looking up companies by name, address, and
domain, and, in turn, provide details like business sector, financial
health, and employee count.
In this section, we analyze popular business data sources in depth
under a new standard evaluation framework. We find that exter-
nal business data sources are weak at differentiating technology
companies—the most common AS organizational category—but
strong for non-technology entities. To address these data sources’
weaknesses, we build a machine learning framework in Section 4,
which, in combination with the external data sources analysis, lays
the foundation for our overall system design (Section 5).
3.1 Potential Data Sources
While many datasets provide business data, not all are suitable for
classifying ASes at scale. Some, like LinkedIn [15], do not have ac-
cessible APIs for bulk lookups. Others, like Wikipedia [21], provide
only loosely formatted text and are difficult to parse in an auto-
mated manner. Nonetheless, we find a handful of popular databases
that appear reliable, easily queryable, and allow for bulk access,
which we further investigate (Table 1).
704
ASdb: A System for Classifying Owners of Autonomous Systems
IMC ’21, November 2–4, 2021, Virtual Event, USA
Figure 1: Comparison of Classification Frameworks—The
NAICSlite classification system allows for higher agreement among
human labelers than using NAICS due to less redundancy and
greater specificity in technology related categories. We define com-
plete overlap to mean thats both labels have the exact same set of
codes, while ≥ 1 overlap is defined as having one shared label from
both labelers.
Dun & Bradstreet, Crunchbase, ZoomInfo, and Clearbit provide
firmographic details (e.g., business sector) about organizations. Un-
fortunately, they cannot be directly queried by ASN, but rather are
queried by organization name, address, phone number, and/or do-
main, which are variably present in bulk WHOIS data. (100% of RIR
records have some form of name, 99.7% have a country, 61.7% have
a physical address, 45% have a phone number, and 87.1% contain
some kind of domain.)
We additionally evaluate two networking-oriented datasets—
IPinfo [13] and PeeringDB [6]. These two sources are directly
queryable by ASN, but offer limited information about the owning
organization. Last, we assess the applicability of the website classi-
fiers mentioned in Vallina et al. [60] for our use case. We find Zvelo
to be the most promising option for classifying ASes using their
associated domains.
3.2 Evaluation Methodology
We manually build a “Gold Standard” dataset to have a baseline
against which to compare external data sources (Table 2). Starting
with 150 randomly selected ASes, we assign 60 ASes to each of
five computer-networking researchers each such that each AS is
independently classified by two researchers. We provide researchers
with parsed WHOIS data (Appendix A) and ask them to identify the
owning organization’s name, website, and to classify organizations
using NAICS (North American Industry Classification System),
the de facto U.S. federal standard for classifying industries. We
ask researchers to manually look up ASes in each candidate data
source/service as opposed to performing automated look-ups to
ensure that the correct data source entry is found. Researchers then
meet in pairs to resolve any labeling discrepancies.
Unfortunately, we find that data sources differ in the classifica-
tion systems they use, thereby requiring them to be translated into
a common classification system. For example, Dun & Bradstreet
and ZoomInfo [23] provide the exact NAICS (North American In-
dustry Classification System) [17] code for an organization, while
Clearbit [7], Crunchbase, PeeringDB, and Zvelo provide their own
organization classification systems that describe business type (e.g.,
“bank” or “financial industry”).
NAICS appears to be a potential option, but during our own
classification process, we found that NAICS has several drawbacks.
First, NAICS is exceptionally complex, defined across a 517 page
manual [1] that describes the hierarchical classification system of
over 2,000 categories. Our team found the framework unnecessar-
ily complicated for what we need as a network community (e.g.,
there are 132 different classifications for industries in agriculture
and mining alone). NAICS frequently hampers consensus: 34% of
ASes classified contain no overlap in labelers’ NAICS codes despite
researchers sharing semantic agreement on the type of organiza-
tion. For instance, AS56885 (SUMIDA Romania SRL) was labeled
335911 (Storage Battery Manufacturing) and 334416 (Capacitor, Re-
sistor, Coil, Transformer, and Other Inductor Manufacturing) by
each respective labeler.
In addition, NAICS is not well suited to categorize technology or-
ganizations, making idiosyncratic choices about what to distinguish
in the computer technology category (e.g., “data processing” has
the same NAICS code as “hosting provider” while “software pub-
lishers” and “custom computer programming services” are separate
codes). Further, NAICS omits categories important to the research
community (e.g., NAICS combines ISPs and phone providers in one
code, and has no code for computer security organizations).
NAICSlite Translation Layer. To provide a translation between
classification systems, while compensating for NAICS’ shortcom-
ings, we introduce a simplified version of NAICS:NAICSlite (Appen-
dix C). We build NAICSlite by both collapsing and expanding NAICS
categories as appropriate for Internet Measurement. For example,
NAICSlite collapses 163 NAICS retail categories into 3 NAICSlite
categories and it expands the NAICS information technology cate-
gory to more clearly distinguish between ISPs, software companies,
cloud and hosting providers, and other kinds of technology compa-
nies. NAICSlite eschews NAICS’ 6-digit hierarchical system for a
simpler two-layered approach that offers 17 top-level (“layer 1”) cat-
egories (e.g., “Computer and Information Technology”, “Education
and Research”, “Finance and Insurance”) and up to 9 lower-layer
(“layer 2”) categories per top level. NAICSlite has a total of 95 layer 2
categories; this is tenfold more categories than in prior AS classifi-
cation work [27], but an order of magnitude less than NAICS.
We translate all NAICS categories to NAICSlite and find that
NAICSlite decreases disagreement amongst researchers categoriz-
ing ASes by a factor of two (Figure 1), while still maintaining a rich
suite of 95 categories. We note that although the Gold Standard was