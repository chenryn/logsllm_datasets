means that Alice has asserted in a non-repudiable manner that (cid:11)
holds at Alice—e.g., Alice has digitally signed (cid:11) and sent out a
message whose contents have eventually made their way to Bob.
The logically signed fact “Alice lsigns (cid:11)” in Bob’s KB means that
Bob has nonrepudiable evidence that leads to the conclusion that
Alice would be willing to digitally sign (cid:11), if shown this evidence.
The meaning of directly and logically signed rules is similar: Alice
sends her directly signed rule to Bob to convince him that the logi-
cally signed counterpart of the rule (created by replacing “signs” by
“lsigns” in the rule head) is true at Alice. We assume that whenever
Alice wants to send a message to Bob, she succeeds in sending the
message, Bob receives it successfully, and Bob is able to verify that
its contents have not been tampered with and were actually signed
by their reputed signers.
We present the formal semantics for signs and lsigns in Section
5; for the moment, it sufﬁces to explain the three major character-
istics of signs and lsigns that must hold in every KB interpretation
at every peer:
1. If a directly signed rule is true at a peer Alice, then its logi-
cally signed counterpart is also true at Alice.
2. If facts f1 through fn and the logically signed rule f  
f1 ^ (cid:1) (cid:1) (cid:1) ^ f n are all true at a peer Alice, then f is also true
at Alice.
3. If a rule logically signed by Alice is true at Alice, then so is
its directly signed counterpart.
Before any peer has sent out any message, we require that each
local KB contain only self-signed statements. This ensures that if
Alice’s KB eventually contains a fact directly signed by Bob, then
Bob’s KB does also.
Our running example models the behavior of the Community
Authorization Service (CAS) [19] under several different possi-
ble trust assumptions. CAS is a third-party authorization service
that simpliﬁes the task of making a resource available on a high-
performance computing grid, by ofﬂoading authorization reason-
ing from the resource manager to CAS. For example, consider the
shake table, an earthquake simulation device that is managed by
Bob, under the following possible scenarios.1
Example 1a. In this example, Bob owns and brokers all access
to the shake table, and makes and directly signs his own authoriza-
tion decisions. In particular, Alice will be able to access the shake
table if “Bob signs auth(shaketable, Alice)” is true at Bob. Bob
may store a list of authorized users/groups internally, or he may
delegate his reasoning to CAS as follows:
Bob:
Bob lsigns auth(shaketable, X)   CAS signs auth(shaketable, X)
Bob’s base policy says that he will give Alice access if he has a
statement directly signed by CAS, saying that Alice is authorized.
If Bob’s KB interpretation satisﬁes “Bob lsigns auth(shaketable,
Alice)”, then it also satisﬁes “Bob signs auth(shaketable, Alice)”.
Example 2a. Let us change Bob’s KB by one letter:
Bob:
Bob lsigns auth(shaketable, X)   CAS lsigns auth(shaketable, X)
Now Bob wants a logical signature on CAS’s proof of authoriza-
tion, rather than requiring a direct signature from CAS. In other
1The examples will only be fully meaningful to the reader after
we have presented the PeerAccess formal semantics. Conversely,
the formal semantics will be very hard to follow unless the reader
has an intuition about what PeerAccess is trying to accomplish.
We resolve this impasse by presenting simple examples before the
semantics.
words, Bob is now asking for a proof that would convince CAS
that Alice is authorized to access the shake table. The pieces of the
proof need not come directly from CAS. For example, for greater
protection against attack, CAS could pre-sign its authorization-related
rules and facts off line, and push them to a repository CAS-DB that
does not have access to CAS’s private keys. Then CAS-DB’s base
policies and received messages can be as follows:
CAS-DB:
CAS signs auth(shaketable, X)  
CAS signs authgroup(shaketable, G) ^ CAS signs member(G, X)
CAS signs authgroup(shaketable, earthquake)
CAS signs member(earthquake, Alice)
To convince Bob that Alice can access the shake table, it sufﬁces
to send Bob a message containing CAS-DB’s rule and facts. Once
Bob receives this message and incorporates its contents into his
KB, the three principles outlined earlier guarantee that CAS lsigns
auth(shaketable, Alice) is true at Bob.
Example 3a. If the body of CAS-DB’s rule uses ‘lsigns’ instead
of ‘signs’, then we have the possibility that the proof of group mem-
bership is deﬁned by other rules:
CAS-DB:
CAS signs auth(shaketable, X)  
CAS lsigns authgroup(shaketable, G) ^ CAS lsigns member(G, X)
CAS signs member(G, X)  
O lsigns member(G, X) ^ CAS lsigns owner(G, O)
CAS signs authgroup(R, G)  
O lsigns authgroup(R, G) ^ CAS lsigns owner(R, O)
Here CAS is not responsible for maintaining the lists of current
group members or authorized groups. Instead this task is delegated
to the owners of each group and resource. The group owners may
have cached their signed group membership lists at CAS-DB, or
may provide them on demand to CAS-DB or to the group members,
as discussed later.
4. RELEASE POLICIES
In PeerAccess, peers exchange information by sending messages
to one another. Every fact and rule that a peer Alice sends out in
a message must be true at Alice and must also be releasable. A
release policy signed by peer P gives the conditions under which
P thinks that it is permissible for a fact or rule (cid:30) to be sent in a
message from peer S to peer R. In this paper, we will consider
release policies over the srelease (sticky-release) predicate, which
take the following form, and its logically signed counterpart:
P signs srelease ((cid:30); S; R)   f1 ^ (cid:1) (cid:1) (cid:1) ^ fn,
where P , S, and R are peer names or variables; (cid:30) is a term over
the release policy language (e.g., a base rule or a proof hint (de-
ﬁned later)); and f1 through fn are facts, with n (cid:21) 0. Intuitively,
srelease semantics stipulate that a peer Alice can send peer Carla a
fact or rule (cid:30) directly signed by Bob if (1) (cid:30) is true at Alice, and (2)
“Bob lsigns srelease((cid:30), Alice, Carla)”, “Carla = Alice”, or “Carla
= Bob” is true at Alice. In other words, Alice can only send out
a formula signed by Bob if she is sending it to herself or to Bob,
or she can prove that Bob thinks that it is okay for her to send the
message out. Further, Alice can only send out facts and rules that
she believes to be true.
The srelease policies are sticky: the signer of a particular piece
of information retains control over its future dissemination to other
peers. (Of course, a malicious peer can choose to violate the con-
ditions in a sticky policy, if it is not afraid of the potential legal
and social ramiﬁcations of doing so.) Sticky policies are desir-
able and even legally mandated in many situations, but other sit-
uations may require a graceful approach to declassiﬁcation of in-
formation, or even stronger control over the use of released infor-
mation (e.g., control over the dissemination of conclusions reached
by using that information).
In the PeerAccess framework, addi-
tional release predicates can be deﬁned to ﬁt the needs of a par-
ticular set of peers, including limited forms of declassiﬁcation and
the ability to spread rumors (lsigned and unsigned formulas) and
lies (formulas not true locally). For example, a direct but unsigned
communication “auth(Alice, shaketable)” from CAS might con-
vince Bob that “CAS lsigns auth(Alice, shaketable)” is true, but
CAS could repudiate such a statement, and Bob would be unable
to use CAS’s message to convince a third party that “CAS lsigns
auth(Alice, shaketable)” is true. While these variations are inter-
esting in their own right, in this paper we conﬁne our attention to
the release of directly signed rules.
The three principles given earlier regarding the meaning of sig-
natures on base facts and rules also apply directly to release facts
and rules. We also have two additional principles to govern the re-
lease of srelease policies. In general, release policies may contain
sensitive information and should not be indiscriminately released.
We do not allow the user to deﬁne explicit KB policies governing
the releasability of srelease policies, because srelease is intended to
be so simple to use that peers will never have to deﬁne such poli-
cies. Instead, the releasability of srelease formulas is deﬁned by
two principles, which will be formalized later on. Oversimplifying
slightly, the ﬁrst principle allows Alice to send Carla an srelease
rule (cid:30) that is directly signed by Bob if (cid:30) is true at Alice and (cid:30)’s
head is of the form “Bob signs srelease((cid:11), Carla, -)”, where (cid:11) is di-
rectly signed by Bob. The intuition is that if Bob authorizes Carla to
disseminate a piece of information, Bob should allow Carla to ﬁnd
out that she is authorized to disseminate the information. A second
principle helps with longer dissemination chains: David can send
(cid:30) to Alice if (cid:30) is true at David, (cid:30)’s head has the form given above,
and David knows that Alice can send (cid:30) to Carla.
When a peer Alice receives a message, she checks to see whether
her exposure policies (not discussed in this paper) allow her to re-
ceive each rule in the message. She adds each receivable directly
signed rule to her set of received messages SAlice, and she adds the
logically signed counterpart of that rule to the appropriate section
of her knowledge base.
Let us revisit examples 1-3 to see the effect of release policies.
Example 1b. (Bob makes and signs his own authorization deci-
sions for the resource he owns.) For Bob to be able to tell Alice
that she is authorized, Bob can use rules of the form:
Bob:
Bob lsigns srelease(Bob signs auth(X, Y ), Bob, Y )
Bob lsigns srelease(Bob signs auth(X, Y ), Y , X)
Bob’s ﬁrst release fact says that he will release an authorization
decision to the principal who is authorized by that decision. This
allows Bob to tell Alice that she is authorized to access the shake
table. However, this may not be enough for Alice to be able to use
that authorization, e.g., if she has to present that authorization to
the shake table herself. To do so, Alice must know that Bob says
that it is okay for her to release his authorization decision to the
shake table. Bob’s second release fact accomplishes this goal. By
the principles given above, Bob can send a directly signed version
of his second release fact to Alice. If he sends her his authorization
decision and the release policy, her KB will contain:
Alice:
Bob signs auth(shaketable, Alice)
Bob signs srelease(Bob signs auth(X, Y ), Y , X)
At this point, Alice can access the shake table by sending it “Bob
signs auth(shaketable, Alice)”, because that formula is satisﬁed in
her interpretation and “Bob lsigns release(auth(shaketable, Alice),
Alice, shaketable)” is also.
While Bob’s proposed release rules are a good start, they are in-
sufﬁcient for use on the computational grids that CAS is designed
for. The problem is that on those grids, Alice delegates her author-
ity to a subjob, which in turn delegates its authority to a subjob, and
so on, until eventually a subjob accesses the shake table. The rules
given above only allow Alice to give her decision directly to one
party, who cannot release it further. To allow Alice to release the
authorization to someone who could in turn release it again, Bob
can add the following rule to his release policies:
Bob lsigns srelease(Bob signs auth(X, Y ), Z, W )   Z 6= Bob
The principles outlined earlier imply that Bob can release this new
release policy to anyone. If the policy is too generous for Bob’s
tastes, he could add restrictions on the recipient W to the body of
the rule, e.g., W must be a member of NeesGrid, a friend of Bob,
a proxy of Alice, etc. He could even require that he himself certify
the property in question, e.g., Bob lsigns member(NeesGrid, W ).
Any such restrictions in the policy will also limit the set of peers
that Bob can disclose the policy to.
One weakness of this version of Bob’s release policies is that
he does not allow Alice to impose her own additional controls on
who is allowed to see “Bob signs auth(shaketable, Alice)”. If the
shake table were a sensitive resource, Alice might not want her
authorization to be released to just anyone. To ﬁx this problem,
Bob can replace his third release policy by the following:
Bob:
Bob lsigns srelease(Bob signs auth(X, Y ), Z, W )  
Z 6= Bob ^ Y lsigns condRelease(Bob signs auth(X, Y ), Z; W )
Here Bob’s original srelease condition, Z 6= Bob, has been aug-
mented with a second condition that says that the authorized prin-
cipal (e.g., Alice) must also agree that Bob’s statement can be re-
leased from peer Z to peer W . With this additional restriction,
“Bob signs auth(shaketable, Alice)” can only be sent to additional
peers when both Bob and Alice agree that it can be sent.
Even this new version of Bob’s release policies might not satisfy
Alice, who might wish to unilaterally impose additional release
constraints of her own on the information from Bob that passes
through her hands. For example, if Bob is a child and Alice is his
mother, Bob might be willing to pass his own information on to
anyone. To protect her family’s privacy, however, Alice may wish
to limit the further disclosure of Bob’s information, at least in the
case where that information has passed through her hands. Peers
can impose such controls if we employ a release predicate with
more restrictive semantics than srelease.
Let us now loosen the restriction that Bob makes his own autho-
rization decisions, and have Bob delegate part of that task to CAS.
To accomplish this, we add two additional rules to Bob’s KB: