e
l
p
m
I
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
n
o
i
t
a
c
ﬁ
i
r
e
V
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
g
n
i
t
r
o
p
e
R
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
s
t
n
e
m
i
r
e
p
x
e
f
o
n
g
i
s
e
D
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
(cid:2)
clock period). It iteratively decrements the clock period re-
quirement by 0.5 ns, starting at 15 ns, and returning to the
Translation phase to rerun the implementation with the new
constraint. Once constraints are so tight that the design cannot
be implemented, they are set to the last known value.
Thus, using new modules and/or EDA tools involves the
deﬁnition of new custom Python ﬁles to generate the required
command lines scripts and obtain the data to be processed by
the report management module. After that, conﬁguration ﬁles
can be customized to integrate these tools into the control ﬂow
for any application scenario.
C. Application Scenarios
There exist several scenarios in which DAVOS could be of
assistance, either dependability related or not. Table II lists a
number of feasible scenarios along with the different modules
cooperating to fulﬁl the task at hand.
Next sections will describe an example of the most inter-
esting three scenarios, from a dependability perspective, to
detail the different conﬁguration options, features, and results
provided by DAVOS. All three scenarios will rely on Mentor
Graphic’s ModelSim simulator.
III. DEPENDABILITY ASSESSMENT AND VERIFICATION
The most basic and probably used scenario is that related to
the assessment of dependability-related properties and/or ver-
iﬁcation of a system/IP core. This scenario will be illustrated
by studying the impact of delay faults affecting a LEON3
microprocessor [14] implemented on a Virtex-6 FPGA.
Fig. 3 depicts the architecture of the fault injection module,
which is the keystone for all dependability-related scenarios.
Basically, it consists of a collection of custom Python scripts
that process incoming XML conﬁguration ﬁles and HDL
models to generate the scripts for an off-the-shelf simulator to
i) run the required fault injection experiments, and ii) generate
the required trace ﬁles. As simulating implementation-level
HDL models is very time consuming, common strategies to
Fault Dictionary 
Fault Dictionary 
Configuration  
Configuration  
(xml)
(xml)
macrocell library
macrocell library
RTL model
RTL model
Implementation-level 
Implementation-level 
models 
models 
Initializer (parse & match HDL models)
Initializer (parse & match HDL models)
Injection targets 
Injection targets 
(match groups)
(match groups)
Faultload builder
Faultload builder
Pre-injection Profiler
Pre-injection Profiler
SBFI scripts
SBFI scripts
checkpoints
checkpoints
Experiment 
Experiment 
specification
specification
Trace script
Trace script
Grid SGE (ssh/sftp)
Grid SGE (ssh/sftp)
Multicore (localhost)
Multicore (localhost)
Task & data manager 
Task & data manager 
(scheduler)
(scheduler)
Off-the-shelf simulator
Off-the-shelf simulator
Injection traces 
Injection traces 
& reference
& reference
analyzer
analyzer
SBFI report (Web)
SBFI report (Web)
Data manager
Data manager
SQLite
SQLite
XML/CSV
XML/CSV
Fig. 3: Architecture of the fault injection module
run those experiments in parallel, like exploiting multi-core or
grid capabilities, have been also included into the module.
The deﬁnition of how different fault models are injected
into the considered HDL models has been decoupled from
the module’s code by using a fault dictionary XML ﬁle. By
using an extensible fault dictionary ﬁle, new fault models can
be added without requiring any modiﬁcation of the module’s
code. In this scenario, it is necessary to describe how delay
faults are injected into implementation-level ﬂip-ﬂop and look-
up table models (X FF and X LUT6, for instance) from the
Xilinx’s SIMPRIM library. Fig. 4 depicts the XML description
of delay faults for this particular technology and component.
The fault description section () identiﬁes the de-
scribed fault model for a given manufacturer primitive through
325
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:28:39 UTC from IEEE Xplore.  Restrictions apply. 
#FaultDict.xml: fault descrption section for delay fault model into Xilinx’s X_FF primitive
... ... ... ... ... ... ... ... ... ... ... ... ... ... …
... ... ... ... ... ... ... ... ... ... ... ... ... ... …
......, delay into X_LUT6, bit-flip into X_FF, stuck-at into SIGNAL,......
#Config.xml: fault model section for delay faultload
......, stuck-at faultload, bit-flip faultload, pulse faultload,......
Fig. 4: Excerpt from the fault dictionary ﬁle and conﬁguration
ﬁle describing the delay fault model for a Xilinx’s X FF ﬂip-
ﬂop and a delay faultload, respectively
the model and macrocell attributes, respectively. Speciﬁc tags
identify the basic HDL elements, like SIGNAL in VHDL,
for injection into RTL models. The 
subsection deﬁnes which rules, deﬁned in custom Python
scripts, should be applied to instrument the manufacturer’s
library to enable the injection of this particular fault model.
This procedure is executed before the experimentation. The
 subsection, on the other hand, deﬁnes the
TCL commands that should be issued to the simulator to
actually emulate the occurrence of the desired fault during
simulation. As a result, whenever a different simulator is
used these commands can be adapted accordingly. Finally,
any number of  subsections specify the value
for previously deﬁned placeholders (label beginning with #)
whenever the asserted condition holds true.
The faultload is also deﬁned by means of another XML
conﬁguration ﬁle. The  section deﬁnes a num-
ber of attributes that will be used, by the faultload builder
(see Fig. 3), to generate the scripts required for all the consid-
ered fault injection experiments. The model and target logic
attributes state which fault description rules will be used
for generating these scripts. Likewise, the condition attribute
determines which injection cases will be applied. Finally, the
rest of the attributes hold values for speciﬁc placeholders.
For instance, the faultload depicted in Fig. 4 will generate
the scripts required to inject interconnect delay faults (not
the X FF, X SFF, X LUT5,
propagation delays) into all
and X LUT6 components of the implemented design. One
experiment (and thus one script) will be generated per eligible
target and only one fault will be injected there during the
experiment. The interconnect delay will be increased a 5%
of the system’s clock cycle when experimentation reaches a
&ůŝƉͲ&ůŽƉƐ͗DĞĂŶŽĨ>hdƐ͗DĞĂŶŽĨϬͲƚŽͲϱŝŶƉƵƚƐ;ŝŶƚĞƌĐŽŶŶĞĐƚͿ
&ůŝƉͲ&ůŽƉƐ͗KƵƚƉƵƚƐ;ƉƌŽƉĂŐĂƚŝŽŶͿ
>hdƐ͗KƵƚƉƵƚƐ;ƉƌŽƉĂŐĂƚŝŽŶͿ
й

͕
Ğ
ƚ
Ă
ƌ

Ğ
ƌ
Ƶ
ů
ŝ
Ă
&
ϰϱ
ϰϬ
ϯϱ
ϯϬ
Ϯϱ
ϮϬ
ϭϱ
ϭϬ
ϱ
Ϭ
Ϭй
ϮϬй
ϰϬй
ϲϬй
ϴϬй
ϭϬϬй
ĚĞůĂǇǁŝĚƚŚ͕йĐůŽĐŬƉĞƌŝŽĚ
Fig. 6: Failure rate estimated for varying widths of intercon-
nect and propagation delays injected into a LEON3 implemen-
tation for Xilinx Virtex6
random instant between the 5% and 15% of its total length.
Observation points, which are monitored during each ex-
periment to generate trace ﬁles, are also deﬁned in an XML
conﬁguration ﬁle. Due to space constraints, and as there is
nothing remarkable on this ﬁle structure, no excerpt will be
shown. Obtained trace ﬁles are processed and stored in a
SQLite database for later analysis. Fig. 5 displays the interface
of the interactive web-based report provided by DAVOS.
The main screen (Fig. 5a) of this report displays a summary
of the whole set of experiments,
including failure modes
and latencies, grouped by fault model. It also gives access
to detailed trace information for each particular experiment
(Fig. 5c), and another screen for custom queries. These custom
reports can be tailored according to a number of ﬁlters,
like fault models, target logic, and/or resulting failure mode,
among others. Likewise, the HDL model can be hierarchically
navigated, displaying the results obtained for each of its
constituent parts. For instance, Fig. 5b depicts the failure
modes distribution for permanent interconnect delays affecting
the I port of X FF primitives of the LEON3 microprocessor. A
29.44% of the experiments led to silent data corruption (SDC).
By navigating its hierarchy, we can see that the execute (e) and
exception (x) pipeline stages are the ones contributing the most
to SDC, with 7.83 and 7.61 percentage points, respectively.
Fig. 6 illustrates the kind of graphs that can be obtained
by post-processing the results from these custom queries. It
depicts the observed failure rate with respect to the width
of interconnect (inputs) and propagation (outputs) delays for
ﬂip-ﬂops and look-up tables. Currently, we are working on
automating the generation of these graphs.
IV. DEPENDABILITY BENCHMARKING (SELECTION)
This scenario usually develops when alternative IP cores,
EDA tools, and/or implementation technologies are consid-
ered. The best candidate should be selected according to rele-
vant criteria for its application domain. This scenario will be
illustrated by studying which will be the most suitable choice
of synthesis tool (Xilinx’s XST or Mentor Graphics’ Precision
RTL) and implementation technology (smallest device from
326
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 10:28:39 UTC from IEEE Xplore.  Restrictions apply. 
a
a
b
b
Fig. 5: Interactive web-based report: (a) summary page, (b) query interface, and (c) detailed trace
c
c
Xilinx’s Artix-7, Kintex-7, and Virtex-7 FPGAs) to implement
a MC8051 microcontroller [15] for two different application
domains (automotive and mobile).
Dependability benchmarking scenarios need to deﬁne all the
metrics required to characterise the goodness of the resulting
implementation. These metrics are computed from measure-
ments obtained during implementation and experimentation
and stored in the database. New derived metrics are deﬁned
by customising a conﬁguration ﬁle. The 
section should be extended with additional 
subsections that relate a given derived metric (name) to the
custom Python function that actually computes it (handler).
Any number of parameters can be included as a list of value-
key pairs in the custom arg attribute. Fig. 7 depicts how the
Mean Time to Failure (MTTF) metric is computed as 1/L.
L is computed by considering, for each cell (x lut, x ff ):
two scenario dependent custom arguments (k–a scaling factor
dependent on altitude, longitude, and latitude [16], and ﬁt.cell–
a constant fault rate measured at sea level) and two metrics
extracted from the database (implprop[cell]–the utilisation,
and val–the observed failure rate processed from injectionstat).
After these metrics are derived, MCDM strategies may
be used to rank the different alternatives according to the
characteristics of the application domain. DAVOS implements
the Weighted Sum Method [17], although any other MCDM
could be integrated by extending the corresponding Python
script. In general, MCDMs require the goals (derived metrics)
to be assigned a weight according to their relative importance
in each scenario. This information is provided in the  of the conﬁguration ﬁle. For each
scenario, a  subsection should be added, including
a  subsection for each goal, stating whether it
should be maximised/minimised, and its relative weight. Fig. 7