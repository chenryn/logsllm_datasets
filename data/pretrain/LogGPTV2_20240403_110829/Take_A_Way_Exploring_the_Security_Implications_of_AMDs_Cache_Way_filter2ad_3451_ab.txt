every memory load, the way predictor predicts the cache way of
every memory load based on this µTag. As the virtual address, and
thus the µTag, is known before the physical address, the CPU does
not have to wait for the TLB lookup. Figure 1 illustrates AMD’s
way predictor. If there is no match for the calculated µTag, an early
miss is detected, and a request to L2 issued.
Aliased cache lines can induce performance penalties, i.e., two
different virtual addresses map to the same physical location. As
VIPT caches with a size lower or equal the number of ways multi-
plied by the page size behave functionally like PIPT caches. Hence,
there are no duplicates for aliased addresses and, thus, in such a
case where data is loaded from an aliased address, the load sees an
L1D cache miss and thus loads the data from the L2 data cache [8].
If there are multiple memory loads from aliased virtual addresses,
they all suffer an L1D cache miss. The reason is that every load
updates the µTag and thus ensures that any other aliased address
sees an L1D cache miss [8]. In addition, if two different virtual
addresses yield the same µTag, accessing one after the other yields
a conflict in the µTag table. Thus, an L1D cache miss is suffered,
and the data is loaded from the L2 data cache.
3.2 Hash Function
The L1D way predictor computes a hash (µTag) from the virtual
address, which is used for the lookup to the way-predictor table.
We assume that this undocumented hash function is linear based
on the knowledge of other such hash functions, e.g., the cache-slice
function of Intel CPUs [52], the DRAM-mapping function of Intel,
ARM, and AMD CPUs [5, 60, 71], or the hash function for indirect
branch prediction on Intel CPUs [41]. Moreover, we expect the size
of the µTag to be a power of 2, resulting in a linear function.
We rely on µTag collisions to reverse-engineer the hash function.
We pick two random virtual addresses that map to the same cache
set. If the two addresses have the same µTag, repeatedly accessing
them one after the other results in conflicts. As the data is then
loaded from the L2 cache, we can either measure an increased access
time or observe an increased number in the performance counter
for L1 misses, as illustrated in Figure 2.
Creating Sets. With the ability to detect conflicts, we can build
N sets representing the number of entries in the µTag table. First,
we create a pool v of virtual addresses, which all map to the same
cache set, i.e., where bits 6 to 11 of the virtual address are the same.
We start with one set S0 containing one random virtual address
out of the pool v. For each other randomly-picked address vx , we
measure the access time while alternatively accessing vx and an
address from each set S0...n. If we encounter a high access time,
we measure conflicts and add vx to that set. If vx does not conflict
with any existing set, we create a new set Sn+1 containing vx .
In our experiments, we recovered 256 sets. Due to measurement
errors caused by system noise, there are sets with single entries
that can be discarded. Furthermore, to retrieve all sets, we need to
make sure to test against virtual addresses where a wide range of
bits is set covering the yet unknown bits used by the hash function.
Recovering the Hash Function. Every virtual address, which is in
the same set, produces the same hash. To recover the hash function,
we need to find which bits in the virtual address are used for the
8 output bits that map to the 256 sets. Due to its linearity, each
output bit of the hash function can be expressed as a series of XORs
of bits in the virtual address. Hence, we can express the virtual
addresses as an over-determined linear equation system in finite
field 2, i.e., GF(2). The solutions of the equation system are then
linear functions that produce the µTag from the virtual address.
To build the equation system, we use each of the virtual addresses
in the 256 sets. For every virtual address, the b bits of the virtual
address a are the coefficients, and the bits of the hash function x are
the unknown. The right-hand side of the equation y is the same for
all addresses in the set. Hence, for every address a in set s, we get
an equation of the form ab−1xb−1 ⊕ ab−2xb−2 ⊕ · · · ⊕ a12x12 = ys.
While the least-significant bits 0-5 define the cache line offset,
note that bits 6-11 determine the cache set and are not used for the
µTag computation [8]. To solve the equation system, we used the
Z3 SMT solver. Every solution vector represents a function which
XORs the virtual-address bits that correspond to ‘1’-bits in the
solution vector. The hash function is the set of linearly independent
functions, i.e., every linearly independent function yields one bit
of the hash function. The order of the bits cannot be recovered.
However, this is not relevant, as we are only interested whether
addresses collide, not in their numeric µTag value.
We successfully recovered the undocumented µTag hash func-
tion on the AMD Zen, Zen+ and Zen 2 microarchitecture. The
function illustrated in Figure 3a uses bits 12 to 27 to produce an
8-bit value mapping to one of the 256 sets:
h(v) = (v12 ⊕ v27) ∥ (v13 ⊕ v26) ∥ (v14 ⊕ v25) ∥ (v15 ⊕ v20) ∥
(v16 ⊕ v21) ∥ (v17 ⊕ v22) ∥ (v18 ⊕ v23) ∥ (v19 ⊕ v24)
We recovered the same function for various models of the AMD
Zen microarchitectures that are listed in Table 1. For the Bulldozer
microarchitecture (FX-4100), the Piledriver microarchitecture (FX-
8350), and the Steamroller microarchitecture (A10-7870K), the hash
function uses the same bits but in a different combination Figure 3b.
3.3 Simultaneous Multithreading
As AMD introduced simultaneous multithreading starting with the
Zen microarchitecture, the filed patent [23] does not cover any
Take A Way: Exploring the Security Implications of AMD’s Cache Way Predictors
ASIA CCS ’20, June 1–5, 2020, Taipei, Taiwan
s
t
n
e
m
e
r
u
s
a
e
M
2,000
1,500
1,000
500
0
Non-colliding addresses
Colliding addresses
0
50
100
150
200
Access time (increments)
Figure 2: Measured duration of 250 alternating accesses to
addresses with and without the same µTag.
...
27
26
25
24
23
22
21
20
19
18
17
16
15
14
13
12
...
(a) Zen, Zen+, Zen 2
f1
f2
f3
f4
f5
f6
f7
f8
f1
f2
f3
f4
f5
f6
f7
f8
...
27
26
25
24
23
22
21
20
19
18
17
16
15
14
13
12
...
(b) Bulldozer, Piledriver, Steamroller
Figure 3: The recovered hash functions use bits 12 to 27 of
the virtual address to compute the µTag.
insights on how the way predictor might handle multiple threads.
While the way predictor has been used since the Bulldozer microar-
chitecture [6], parts of the way predictor have only been docu-
mented with the release of the Zen microarchitecture [8]. However,
the influence of simultaneous multithreading is not mentioned.
Typically, two sibling threads can either share a hardware struc-
ture competitively with the option to tag entries or by statically
partitioning them. For instance, on the Zen microarchitecture, ex-
ecution units, schedulers, or the cache are competitively shared,
and the store queue and retire queue are statically partitioned [18].
Although the load queue, as well as the instruction and data TLB,
are competitively shared between the threads, the data in these
structures can only be accessed by the thread owning it.
Under the assumption that the data structures of the way pre-
dictor are competitively shared between threads, one thread could
directly influence the sibling thread, enabling cross-thread attacks.
We validate this assumption by accessing two addresses with the
same µTag on both threads. However, we do not observe collisions,
neither by measuring the access time nor in the number of L1 misses.
While we reverse-engineered the same mapping function (see Sec-
tion 3.2) for both threads, the possibility remains that additional
per-thread information is used for selecting the data-structure entry,
allowing one thread to evict entries of the other.
Hence, we extend the experiment in accessing addresses mapping
to all possible µTags on one hardware thread (and all possible cache
sets). While we repeatedly accessed one of these addresses on one
hardware thread, we measure the number of L1 misses to a single
virtual address on the sibling thread. However, we are not able to
observe any collisions and, thus, conclude that either individual
structures are used per thread or that they are shared but tagged for
each thread. The only exceptions are aliased loads as the hardware
updates the µTag in the aliased way (see Section 3.1).
In another experiment, we measure access times of two virtual
addresses that are mapped to the same physical address. As docu-
mented [8], loads to an aliased address see an L1D cache miss and,
thus, load the data from the L2 data cache. While we verified this
behavior, we additionally observed that this is also the case if the
other thread performs the other load. Hence, the structure used is
searched by the sibling thread, suggesting a competitively shared
structure that is tagged with the hardware threads.
4 USING THE WAY PREDICTOR FOR SIDE
CHANNELS
In this section, we present two novel side channels that leverage
AMD’s L1D cache way predictor. With Collide+Probe, we moni-
tor memory accesses of a victim’s process without requiring the
knowledge of physical addresses. With Load+Reload, while relying
on shared memory similar to Flush+Reload, we can monitor mem-
ory accesses of a victim’s process running on the sibling hardware
thread without invalidating the targeted cache line from the entire
cache hierarchy.
4.1 Collide+Probe
Collide+Probe is a new cache side channel exploiting µTag collisions
in AMD’s L1D cache way predictor. As described in Section 3, the
way predictor uses virtual-address-based µTags to predict the L1D
cache way. If an address is accessed, the µTag is computed, and the
way-predictor entry for this µTag is updated. If a subsequent access
to a different address with the same µTag is performed, a µTag
collision occurs, and the data has to be loaded from the L2D cache,
increasing the access time. With Collide+Probe, we exploit this
timing difference to monitor accesses to such colliding addresses.
Threat Model. For this attack, we assume that the attacker has un-
privileged native code execution on the target machine and runs on
the same logical CPU core as the victim. Furthermore, the attacker
can force the execution of the victim’s code, e.g., via a function call
in a library or a system call.
Setup. The attacker first chooses a virtual address v of the victim
that should be monitored for accesses. This can be an arbitrary
valid address in the victim’s address space. There are no constraints
in choosing the address. The attacker can then compute the µTag
µv of the target address using the hash function from Section 3.2.
We assume that ASLR is either not active or has already been
broken (cf. Section 5.2). However, although with ASLR, the actual
virtual address used in the victim’s process are typically unknown
to the attacker, it is still possible to mount an attack. Instead of
choosing a virtual address, the attacker initially performs a cache
template attack [31] to detect which of 256 possible µTags should
ASIA CCS ’20, June 1–5, 2020, Taipei, Taiwan
Lipp, et al.
be monitored. Similar to Prime+Probe [58], where the attacker
monitors the activity of cache sets, the attacker monitors µTag
collisions while triggering the victim.
Attack. To mount a Collide+Probe attack, the attacker selects a
virtual address v′ in its own address space that yields the same
µTag µv′ as the target address v, i.e., µv = µv′. As there are only
256 different µTags, this can easily be done by randomly choosing
addresses until the chosen address has the same µTag. Moreover,
both v and v′ have to be in the same cache set. However, this is easily
satisfiable, as the cache set is determined by bits 6-11 of the virtual
address. The attack consists of 3 phases performed repeatedly:
Phase 1: Collide. In the first phase, the attacker accesses the
pre-computed address v′ and, thus, updates the way predictor. The
way predictor associates the cache line of v′ with its µTag µv′ and
subsequent memory accesses with the same µTag are predicted to
be in the same cache way. Since the victim’s address v has the same
µTag (µv = µv′), the µTag of that cache line is marked invalid and
the data is effectively inaccessible from the L1D cache.
Phase 2: Scheduling the victim. In the second phase, the vic-
tim is scheduled to perform its operations. If the victim does not
access the monitored address v, the way predictor remains in the
same state as set up by the attacker. Thus, the attacker’s data is still
accessible from the L1D cache. However, if the victim performs an
access to the monitored address v, the way predictor is updated
again causing the attacker’s data to be inaccessible from L1D.
Phase 3: Probe. In the third and last phase of the attack, the
attacker measures the access time to the pre-computed address v′. If
the victim has not accessed the monitored address v, the data of the
pre-computed address v′ is still accessible from the L1D cache and
the way prediction is correct. Thus, the measured access time is fast.
If the victim has accessed the monitored address v and thus changed
the state of the way predictor, the attacker suffers an L1D cache miss
when accessing v′, as the prediction is now incorrect. The data of
the pre-computed address v′ is loaded from the L2 cache and, thus,
the measured access time is slow. By distinguishing between these
cases, the attacker can deduce whether the victim has accessed the
targeted data.
Listing 1 shows an implementation of the Collide+Probe attack
where the colliding address colliding_address is computed be-
forehand. The code closely follows the three attack phases. First,
the colliding address is accessed. Then, the victim is scheduled, il-
lustrated by the run_victim function. Afterwards, the access time
to the same address is measured where the get_time function is
implemented using a timing source discussed in Section 2.3. The
measured access time allows the attacker to distinguish between an
L1D cache hit and an L2-cache hit and, thus, deduce if the victim
has accessed the targeted address. As other accesses with the same
cache set influence the measurements, the attacker can repeat the
experiment to average out the measured noise.
Comparison to Other Cache Attacks. Finally, we want to discuss
the advantages and disadvantages of the Collide+Probe attack in
comparison to other cache side-channel attacks. In contrast to
Prime+Probe, no knowledge of physical addresses is required as
the way predictor uses the virtual address to compute µTags. Thus,
with native code execution, an attacker can find addresses corre-
sponding to a specific µTag without any effort. Another advantage
1 access(colliding_address);
2 run_victim();
3 size_t begin = get_time();
4 access(colliding_address);
5 size_t end = get_time() − begin;
6 if ((end − begin) > THRESHOLD) report_event();
Listing 1: Implementation of the Collide+Probe attack
of Collide+Probe over Prime+Probe is that a single memory load is
enough to guarantee that a subsequent load with the same µTag
is served from the L2 cache. With Prime+Probe, multiple loads
are required to ensure that the target address is evicted from the
cache. In modern Prime+Probe attacks, the last-level cache is tar-
geted [37, 48, 50, 63, 67], and knowledge of physical addresses is
required to compute both the cache set and cache slice [52]. While
Collide+Probe requires knowledge of virtual addresses, they are
typically easier to get than physical addresses. In contrast to Flush+
Reload, Collide+Probe does neither require any specific instruc-
tions like clflush nor shared memory between the victim and the
attacker. A disadvantage is that distinguishing L1D from L2 hits
in Collide+Probe requires a timing primitive with higher precision
than required to distinguish cache hits from misses in Flush+Reload.
4.2 Load+Reload
Load+Reload exploits the way predictor’s behavior for aliased ad-
dress, i.e., virtual addresses mapping to the same physical address.
When accessing data through a virtual-address alias, the data is
always requested from the L2 cache instead of the L1D cache [8]. By
monitoring the performance counter for L1 misses, we also observe
this behavior across hardware threads. Consequently, this allows
one thread to evict shared data used by the sibling thread with a
single load. Although the requested data is stored in the L1D cache,
it remains inaccessible for the other thread and, thus, introduces a
timing difference when it is accessed.
Threat Model. For this attack, we assume that the attacker has
unprivileged native code execution on the target machine. The
attacker and victim run simultaneously on the same physical but
different logical CPU thread. The attack target is a memory location
with virtual address v shared between the attacker and victim, e.g.,
a shared library.
Attack. Load+Reload exploits the timing difference when access-
ing a virtual-address alias v′ to build a cross-thread attack on shared
memory. The attack consists of 3 phases:
Phase 1: Load. In contrast to Flush+Reload, where the targeted
address v is flushed from the cache hierarchy, Load+Reload loads
an address v′ with the same physical tag as v in the first phase.
Thereby, it renders the cache line containing v inaccessible from
the L1D cache for the sibling thread.
Phase 2: Scheduling the victim. In the second phase, the vic-
tim process is scheduled. If the victim process accesses the targeted
cache line with address v, it sees an L1D cache miss. As a result, it
loads the data from the L2 cache, invalidating the attacker’s cache
line with address v′ in the process.
Phase 3: Reload. In the third phase, the attacker measures the
access time to the address v′. If the victim process has accessed the
Take A Way: Exploring the Security Implications of AMD’s Cache Way Predictors
ASIA CCS ’20, June 1–5, 2020, Taipei, Taiwan
cache line with address v, the attacker observes an L1D cache miss
and loads the data from the L2 cache, resulting in a higher access
time. Otherwise, if the victim has not accessed the cache line with
address v, it is still accessible in the L1D cache for the attacker and,
thus, a lower access time is measured. By distinguishing between
both cases, the attacker can deduce whether the victim has accessed
the address v.
Comparison with Flush+Reload. While Flush+Reload invalidates a
cache line from the entire cache hierarchy, Load+Reload only evicts
the data for the sibling thread from the L1D. Thus, Load+Reload is
limited to cross-thread scenarios, while Flush+Reload is applicable
to cross-core scenarios too.
5 CASE STUDIES
To demonstrate the impact of the side channel introduced by the
µTag, we implement different attack scenarios. In Section 5.1, we
implement a covert channel between two processes with a transmis-
sion rate of up to 588.9 kB/s outperforming state-of-the-art covert
channels. In Section 5.2, we break kernel ASLR, demonstrate how