9
29
28
290
1
30
0
52
0
45
1
53
0
31
0
27
0
19
0
30
0
58
0
12
3
54
2
183
18
65
1
62
1
30
1
16
1
6
17
284
4
81
gadgets that can be found in the largest application-speciﬁc
PE ﬁles within our dataset. We observe that the number of
such gadgets is signiﬁcantly smaller from the total number of
available gadgets. Nevertheless, functions of particular interest
to attackers are accessible. The small number of such gadgets
indicates that
it may be possible to develop a mitigation
technique based on completely eliminating the ability to call
sensitive functions through code-reuse.
Size distribution of gadgets. Figures 8 and 9 show the fre-
quency of gadget sizes for gadgets without and with branches
respectively in Internet Explorer 9. Surprisingly, we observe
that there is a signiﬁcant number of smaller gadgets, indicating
that ROP attacks under CFI are closer to conventional ROP
than we thought. Another, interesting observation is that in
Fig. 8, there is a peak for gadgets with 21 instructions. After
investigating, we determined that this occurs due to a block in
the ole32.dll library that has 1021 pointers (JMPs) pointing to
it.
VI. DISCUSSION
A. Other Vulnerable Defenses
kBouncer [34] monitors a process to detect function returns
to addresses not preceded by a call instruction. It leverages
Last Record Branch (LBR), a hardware feature recently in-
troduced in the Intel architecture. kBouncer is able to prevent
conventional ROP attacks because they use small gadgets and
do not attempt to restrict the gadget pool. Gadget chains like
the ones described in the paper would evade detection, since
they exhibit different behavior.
However, kBouncer also introduces a heuristic based on the
observation that ROP attacks perform an excessive number of
returns without calls. This heuristic could certainly detect gad-
get chains consisting entirely of CS-R gadgets. Nevertheless,
we believe that we could potentially bypass it by using CS-F-R
or CS-IC-R gadgets to call a function simply for tricking
kBouncer. More experimentation is required before we can
make any conﬁdent claims in this area.
584
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:01:49 UTC from IEEE Xplore.  Restrictions apply. 
Gadget Sizes found in IE9 without Branches
CS
EP
return addresses stored in the program stack, in a way that
a prospective attacker cannot overwrite them. For instance,
by using segmentation in x86 CPUs, a feature which has
been discontinued in 64-bit CPUs. Even though not without
problems and incurring additional overhead, such a run-time
companion provided higher security guarantees. Unfortunately,
correctly tracking a shadow stack is not trivial, as every call
instruction is not necessarily matched by a ret. For instance,
compiler-applied optimizations, such as the tail-call optimiza-
tion, can end a function with a call, and the called function
is responsible for cleaning up the stack to return directly to
the caller’s parent. Other optimizations also introduce such
asymmetry between the number of calls and returns.
 100000
 10000
 1000
 100
t
n
u
o
C
)
#
(
 10
 1
 0.1
 0
 5
 10
 15
 20
 25
 30
Gadget Length
Fig. 8: Frequency of gadgets without branches in IE9 based
on their length (instruction count).
Gadget Sizes found in IE9 with Branches
CS
EP
 100000
 10000
 1000
 100
t
n
u
o
C
)
#
(
 10
 1
 0.1
 0
 5
 10
 15
 20
 25
 30
Gadget Length
Fig. 9: Frequency of gadgets including paths with branches in
IE9 based on path length (instruction count).
G-free [35] recompiles a program and performs a set
of transformations for eliminating gadgets, enforcing aligned
code, and preventing code from jumping in the middle of a
function. The latter is enforced by setting a random cookie dur-
ing function entrance and checking for the cookie’s integrity at
function exit. This mitigation essentially breaks all CS gadgets
we use throughout this paper, since a CS gadget essentially
transfers control to a call-site, without entering the function
hosting the call site normally. Nevertheless, all EP gadgets
can still work and therefore attacks like ret2libc [13] may be
still possible, depending on the actual vulnerability. Also, our
PoC exploit shows that while chaining EP gadgets is harder, it
is possible. Further research is required to determine if EP-F-*
gadgets could be also used to bypass G-free.
B. Possible Defenses
In their original CFI work Abadi et al. [14] proposed a
shadow call stack [36], [22] that is securely maintained at run
time to harden CFI. The shadow stack keeps a copy of the
585
[37]
ROPDefender
is another approach, also using a
shadow stack, that aims to enforce a call-ret pairing policy,
therefore any ret instructions which have not been triggered
by a call will be detected. However, this approach also suffers
from the problems listed above, while it also incurs non-
negligible overhead.
Another possible defense
is Control-Flow Locking
(CFL) [38] which uses locks to preserve CFG integrity. It im-
plements a lock operation before indirect control-ﬂow transfers
and an unlock operation before valid targets. The locks and
unlocks are paired according to computed key values based
on the links in the CFG which is extracted using source code.
CFL detects violations once a lock or unlock operation fails.
We believe that CFL is a promising direction, and it would be
able to prevent our attack, however it is hard to apply in the
absence of source code.
A more ad-hoc defense would focus on preventing the
application from making its text segment, as well as the
springboard in the case of CCFIR, writable. Even though that
would not prevent the code-reuse part of our attack, it would
raise the bar, as we would no longer be able to inject code.
VII. RELATED WORK
In this section we present related research. We start with a
short survey of how defenses have evolved in the face of more
elaborate attacks, and then we place our work in context with
related CFI research.
A. Advanced Mitigation Techniques
Traditional exploitation through stack smashing and code
injection is considered today hard due to the massive adoption
of stack canaries [3] and Data Execution Prevention (DEP) [2],
respectively, by all of the most popular commodity operating
systems. Most of the modern microprocessor architectures
also support a special MMU feature, well-known under the
generically accepted No eXecute (NX) bit term – although
different brands use their own acronym to refer to the same
technology – to facilitate DEP. Essentially, DEP will force
the process to crash in any attempt to execute code placed
in data. Therefore, since foreign code cannot be introduced,
adversaries can only utilize existing code in the process image.
For example, they can force the program to jump to a particular
function after having prepared the stack accordingly. This
technique is called return-to-libc [13], reﬂecting the classic
idiom of calling a libc function (system or the exec family)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:01:49 UTC from IEEE Xplore.  Restrictions apply. 
for spawning a shell. Leveraging existing code for compro-
mising a program has been generalized in Return-Oriented
Programming (ROP) [9], where short snippets of code called
gadgets are chained together to introduce a new, not initially
intended, control ﬂow. ROP can especially take advantage
of the density of instruction sets in CISC architectures and
the availability of overlapping instructions due to the lack of
instruction alignment. Nevertheless, it has been shown that
ROP is possible in RISC architectures [27], or it can be carried
out without using the ret instruction [11], [12] making defenses
that are based on the emulation of the ret command less
effective [24].
Defenses against ROP are based on randomization of a
process’ layout so that adversaries lack knowledge of where
the program’s code is mapped in the virtual address space.
The most straightforward way to achieve this is by using
Address Space Layout Randomization (ASLR) [4], which
maps processes and dynamically linked libraries in random
addresses each time. Unfortunately, ASLR with low entropy
can be brute-forced [30] and, worse, in the presence of memory
disclosure, attackers are able to leak a few memory addresses
and thus bypass any protection offered by ASLR completely.
As a result, many proposals where introduced for ﬁne grained
randomization in executables by applying in-place randomiza-
tion [39], breaking the linearity of the address-space [40], or
shufﬂing the basic code blocks of a program [41]. Again, in the
presence of powerful exploits that can arbitrarily leak memory,
it has been shown that ﬁne grained randomization techniques
fail in protecting the vulnerable program [5]. In this paper,
although we use the same powerful exploit [5], we do not
take advantage of arbitrarily leaking all process memory.
B. CFI Research
Control-Flow Integrity (CFI) [14] was originally introduced
as a generic methodology for enforcing the integrity of a
program’s control-ﬂow graph, as realized by a compiler or
discovered using static analysis before program execution, by
prohibiting all unseen control ﬂows at run time. Typically, the
program’s code is marked with labels and checks that validate
intended control ﬂows. CFI can be applied in principle in any
system, like for example smarthphones [18], [42]. CFI has two
major limitations. First, discovering the complete control-ﬂow
graph is not always possible – although recent attempts towards
that direction are promising [43], [44] – and, second, applying
complete CFI in a program often incurs high performance
overhead. For this, researchers have attempted to relax CFI
by applying it directly to binaries [16], [17]. In this paper, we
explore how this relaxation degrades the effectiveness of CFI
and how adversaries can take advantage of it for bypassing
CFI protection. CFI can be leveraged for enforcing Software
Fault Isolation [19] and constraint additional program code in a
sandbox. Many popular pure SFI frameworks, like for example
Native Client [45], [46] or SFI-inspired policy frameworks, like
XFI [47] and WIT [48], employ CFI-checks to prevent ﬂows
from escaping the sandbox. On the other hand, ideas from SFI
implementations can be used for enforcing CFI. For example,
CCFIR [16] uses a similar memory layout (Springboard) with
the one used by Native Client (NaCl) [45], [46].
VIII. CONCLUSION
In this paper, we have examined the security implications
of looser notions of control ﬂow integrity (CFI). The looser
notions of CFI are fast, but allow certain control ﬂows in
a program’s execution that were not in its original control-
ﬂow graph. Speciﬁcally, we have shown that such permissible,
but incorrect, ﬂows of control allow attackers to launch ROP
attacks that by their nature are just as powerful as regular
ROP exploits. While the novel ROP chains are based on two
new types of gadget (and thus have gadget sets that are more
limited than regular ROP), we also show that such gadgets
are still widely available and that the gadget set is broad
and powerful. Finally, a proof-of-concept exploitation against
Internet Explorer, that bypasses modern CFI implementations,
demonstrates that our techniques are practical.
As CFI is one of the most powerful defensive measures
currently available against advanced exploitation techniques,
we believe these results to be highly relevant. Speciﬁcally, our
results suggest that a CFI solution based on static analysis
alone may not be sufﬁcient for comprehensive protection
against ROP attacks, and that permitting any additional edges
in the control-ﬂow graph introduces vulnerabilities that may
be exploited. We expect new CFI solutions to utilize static
information as much as possible, but it is unlikely that the
stricter notions of CFI can work without
the use of run-
time information. There is no question that gathering such
information comes at a cost in performance, but neglecting
to do so comes at the cost of security.
ACKNOWLEDGEMENT
We want to express our thanks to anonymous reviewers
for valuable comments. This work was supported by the US
Air Force through Contract AFRL-FA8650-10-C-7024. Any
opinions, ﬁndings, conclusions or recommendations expressed
herein are those of the authors, and do not necessarily reﬂect
those of the US Government, or the Air Force. This work was
also supported in part by the ERC StG project Rosetta, the
FP7-PEOPLE-2010-IOF project XHUNTER, No. 273765, and
EU FP7 SysSec, funded by the European Commission under
Grant Agreement No. 257007.
REFERENCES
[1] N. Joly, “Advanced exploitation of
Internet Explorer 10 / Win-
dows 8 overﬂow (Pwn2Own 2013),” VUPEN Vulnerability Research
Team (VRT) Blog, May 2013, http://www.vupen.com/blog/20130522.
Advanced_Exploitation_of_IE10_Windows8_Pwn2Own_2013.php.
[2] S. Andersen and V. Abella, “Changes to functionality in microsoft
windows xp service pack 2, part 3: Memory protection technologies,
Data Execution Prevention,” Microsoft TechNet Library, September
2004, http://technet.microsoft.com/en-us/library/bb457155.aspx.
[3] C. Cowan, C. Pu, D. Maier, H. Hinton, J. Walpole, P. Bakke, S. Beattie,
A. Grier, P. Wagle, Q. Zhang et al., “Stackguard: Automatic adaptive
detection and prevention of buffer-overﬂow attacks,” in Proceedings of
the 7th USENIX Security Symposium, vol. 81, 1998, pp. 346–355.
[4] PaX Team, “Address Space Layout Randomization (ASLR),” 2003,
http://pax.grsecurity.net/docs/aslr.txt.
[5] K. Z. Snow, L. Davi, A. Dmitrienko, C. Liebchen, F. Monrose, and
A.-R. Sadeghi, “Just-in-time code reuse: On the effectiveness of ﬁne-
grained address space layout randomization,” in Proceedings of the 34th
IEEE Symposium on Security and Privacy, May 2013.
586
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:01:49 UTC from IEEE Xplore.  Restrictions apply. 
[6] R. Strackx, Y. Younan, P. Philippaerts, F. Piessens, S. Lachmund, and
T. Walter, “Breaking the memory secrecy assumption,” in Proceedings
of the 2nd European Workshop on System Security, 2009, pp. 1–8.
[7] F. J. Serna, “CVE-2012-0769, the case of the perfect info leak,” http:
//zhodiac.hispahack.com/my-stuff/security/Flash_ASLR_bypass.pdf.
[8] C. Evans, “Exploiting 64-bit Linux like a bos,” http://scarybeastsecurity.
blogspot.com/2013/02/exploiting-64-bit-linux-like-boss.html.
[9] H. Shacham, “The geometry of innocent ﬂesh on the bone: Return-into-
libc without function calls (on the x86),” in Proceedings of the 14th
ACM conference on Computer and Communications security, October
2007, pp. 552–61.
[10] D. Dai Zovi, “Practical
Boston, 2010.
return-oriented programming,” SOURCE
[11] S. Checkoway, L. Davi, A. Dmitrienko, A.-R. Sadeghi, H. Shacham,
and M. Winandy, “Return-oriented programming without returns,” in
Proceedings of the 17th ACM conference on Computer and Communi-
cations Security, October 2010, pp. 559–72.
[12] T. Bletsch, X. Jiang, V. W. Freeh, and Z. Liang, “Jump-oriented
programming: a new class of code-reuse attack,” in Proceedings of the
6th ASIACCS, March 2011, pp. 30–40.
[13] M. Tran, M. Etheridge, T. Bletsch, X. Jiang, V. Freeh, and P. Ning,
“On the expressiveness of return-into-libc attacks,” in Proceedings of
the 14th international conference on Recent Advances in Intrusion
Detection, 2011, pp. 121–141.
[14] M. Abadi, M. Budiu, U. Erlingsson, and J. Ligatti, “Control-ﬂow
integrity,” in Proceedings of the 12th ACM conference on Computer
and Communications Security, 2005, pp. 340–353.
[15] Z. Wang and X. Jiang, “Hypersafe: A lightweight approach to provide
lifetime hypervisor control-ﬂow integrity,” in Proceedings of the 2010
IEEE Symposium on Security and Privacy, 2010, pp. 380–395.
[16] C. Zhang, T. Wei, Z. Chen, L. Duan, L. Szekeres, S. McCamant,
D. Song, and W. Zou, “Practical control ﬂow integrity and random-
ization for binary executables,” in Proceedings of the 1013 Security
and Privacy Symposium, 2013, pp. 559–573.
[17] M. Zhang and R. Sekar, “Control ﬂow integrity for cots binaries,” in
22nd USENIX Security Symposium, 2013.
[18] L. Davi, A. Dmitrienko, M. Egele, T. Fischer, T. Holz, R. Hund,
S. Nürnberger, and A.-R. Sadeghi, “MoCFI: A framework to mitigate