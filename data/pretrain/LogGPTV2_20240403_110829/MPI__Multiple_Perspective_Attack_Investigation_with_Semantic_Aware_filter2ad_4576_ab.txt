Excessive Units. Partitioning based on event handling
loops works nicely for server programs, in which one
event loop iteration handles an external request and hence
corresponds to a high level task. However, in many com-
plex programs, especially those that heavily use threads
to distribute workloads or involve intensive UI operations,
event loop iterations do not align well with the high level
tasks. As a result, it generates excessive small units that
do not have much meaning. For example, in GUI pro-
grams, units are generated to denote the large number
of GUI events (e.g., key strokes), even though all these
events may serve the same high level task.
Consider the p2p program Transmission. Figure 3
shows its event handling loop in the main function of the
daemon process. After parsing options, loading settings
and torrent files (line 2-3), the daemon goes to a loop
which exits only when the user closes the program (i.e.,
set closing to TRUE). In each iteration of the loop, it
waits for 1 second (line 6), updates the torrent status and
logs some information (line 7). Due to the nature of p2p
protocol, downloading a single file requires thousands of
loop iterations, leading to thousands of units in BEEP.
In many situations, there may not be any system events
within these small units. For example, GUI programs
monitor and handle frequent events such as page scroll.
However, not all of them lead to system calls. Thus BEEP
ends up with many “UNIT_ENTER” and “UNIT_EXIT”
events without any system calls in between. These useless
units waste a lot of space and CPU cycles. While existing
techniques [22, 44, 46, 67] can remove redundant events,
they cannot prevent these events from being generated in
the first place.
These limitations are rooted at the misalignment be-
tween the rigid and low level execution partitioning
scheme based on event loops. Ideally, the units gener-
ated by a partitioning scheme would precisely match with
the high level logic tasks. MPI aims to achieve this goal.
2.4 Our Approach
The overarching idea of this paper is that high level tasks
are reflected as data structures. MPI allows the user to
annotate the data structures that correspond to such tasks.
It then leverages program analysis to instrument a set of
places that indicate switches and inheritances of tasks to
achieve execution partitioning. Note that there may be
multiple perspectives of the high level tasks involved in
an execution, denoted by different data structures. Hence,
MPI allows annotating multiple data structures, each de-
noting an independent perspective. To reduce the annota-
tion efforts, MPI provides a profiler that can automatically
identify the critical data structures ( Figure 3.2). Note
that allowing developers/users to insert logging related
annotations/commands to software source code is a practi-
cal approach for system auditing. The Windows auditing
system, Event Tracing for Windows (ETW), requires the
developers to explicitly plan customized events to their
1114    26th USENIX Security Symposium
USENIX Association
Firefoxt0.torrentt1.torrentt2.torrentt3.torrentt4.torrentobama.mp4.torrentfedora.iso.torrentubuntu.torrentfcopyTranmissionm0.mp4m1.mp4m2.mp4m3.mp4m4.mp4obama.mp4Fedora.isoubuntu.isoa.a.a.aFigure 2: Simplified backtracking causal graph for the case in §2.1 with event loop based partitioning technique. It only shows the
causal relationship within the Firefox process (runs for 5 minutes with 11 tabs and 7 websites). The tool used can be found in [16].
// parse options and session, load torrents
torrents = tr_sessionLoadTorrents(mySession, ctor, NULL);
// event loop
while( !closing ) {
tr_wait_msec( 1000 ); /* sleep one second */
// update and log and so on
1 int main( int argc, char ** argv ) {
2
3
4
5
6
7
8
9
10
11 }
}
// close program and sessions
return 0;
Figure 3: Event handling loop of Transmission (version 2.6)
software before deployment [5, 20]. These commands
generate system events at runtime. In our design, we only
require the developer to annotate (a few) task oriented
data structures, MPI automatically instruments a much
larger number of code places based on the annotations.
Figure 4: Firefox Partitioning perspectives
Figure 4 presents a few possible perspectives of Firefox
execution. By annotating the appropriate data structures,
we can partition a Firefox execution into sub-executions
of various windows (perspective 6), tabs (perspective 5),
websites/domains (perspective 4), website instances (per-
spective 3), individual pages (perspective 2), and even
the sources of individual DOM elements (perspective 1).
Observe that some of the perspectives are cross-cutting.
For instance, a tab may show pages from multiple do-
mains whereas pages from the same domain may appear
in multiple tabs. A prominent benefit of such partitioning
is to expose the high level semantics of the application to
the underlying provenance tracking system.
Figure 5: Simplified MPI causal graph for the case in §2.1 with
Firefox partitioned by tabs
Figure 6: Simplified MPI causal graph for the case in §2.1 with
Firefox partitioned by web sites
Figure 5 shows the causal graph for the attack example
when we partition the execution of Firefox by its tabs
and Transmission by the files being downloaded. Each
rectangle represents the life time of a tab. Observe that the
Bing tab leads to the wordpress tab, which also shows the
forum main page. A number of forum pages are displayed
on separate tabs, each of which leads to the download of
a torrent file through a Transmission unit. In contrast
Figure 6 shows the causal graph when we partition the
execution of Firefox by the websites/domains it visits.
Observe that all the forum tabs are now collapsed to a
single forum node. It clearly indicates that fcopy and
the torrent files are downloaded from the same domain.
Compared to the BEEP graph in Figure 1, these graphs
are much smaller and cleaner, precisely capturing the high
level workflow of the execution. Note that these graphs
cannot be generated by directly querying/operating-on
the BEEP log, which has only very low level semantic
information (i.e., event loop iterations).
Advantages Over Event Loop Based Partitioning. We
can clearly see data structure based partitioning system
MPI addresses the limitations of event loop based parti-
tioning. 1 Units are no longer based on low level loop
iterations. The inspector does not need to manually chain
many such low level units to form a high level view of
the execution. 2 Dependency identification is made easy.
Training is no longer needed. The memory dependencies
that are needed to chain the low level event loop units
are no longer necessary because these low level units are
automatically classified to a high level unit in MPI. The
incidents of missing causality due to incomplete train-
ing can be avoided. For instance, Firefox uses multiple
threads to load and render the many elements on a page,
which induces lots of memory dependencies across event
loop units. But if we look at the execution from the tab
perspective, these memory dependencies are no longer
inter-unit dependencies that need to be explicitly cap-
USENIX Association
26th USENIX Security Symposium    1115
7: Process6: WindowOne Tab3: Website Instance1: Same SourceElementElementPageWebsite InstancePagePage5: One TabWebsite InstancePagePage4: WebsiteElement2: Page6: WindowforumfcopyTransmissionforumubuntu.iso.torrentforumt0.torrentubuntu.isoTransmissionm0.mp4TransmissionforumFedora.iso.torrentFedora.isoTransmissionforumt1.torrentt1.mp4GithubBingtoptenrevieweswordpress, forumCNETﬁle:aDigitaltrendsAddressBarfcopyforumwordpressBingTransmissionubuntu.iso.torrentt0.torrentubuntu.isoTransmissionm0.mp4TransmissionFedora.iso.torrentFedora.isoTransmissiont1.torrentt1.mp4CNETDigitaltrendstoptenreviewesﬁle:aGithubtured. 3 Excessive (small and non-informative) units are
prevented from being generated. All nodes representing
timer event for Transmission will be merged into one
node. Moreover, MPI provides great flexibility for attack
investigation by supporting multiple perspectives. En-
abling these perspectives is impossible if the appropriate
semantic information is not exposed through MPI.
One may argue that event loop based partitioning can
be enhanced by annotating event loops and cross-unit
memory dependencies. However, such annotations are so
low-level that (1) they require a lot of human efforts due to
the large number of places that need to be annotated (e.g.,
the memory dependencies), and (2) they expose low-level
and sometimes non-informative semantics such as mouse
moves and timer events. In addition, the partitioning is
solely based on event handling and hence cannot provide
multiple perspectives.
3 Design
3.1 Overview
The overall process of analysis and instrumentation is
shown in Figure 7. The user first annotates the program
source code to indicate unit related data structures under
the help of the annotation miner, which is essentially a
data structure profiler. The analysis component, imple-
mented as a LLVM pass, takes the annotations and ana-
lyzes the program to determine the places to instrument
(e.g., data structure accesses denoting unit boundaries).
The graph construction is using a standard algorithm, and
details can be found in Appendix B.
Figure 7: MPI workflow
3.2 Annotations
Basic Annotations. Let us review how the Linux kernel
conducts context switching internally, which inspires our
approach to unit switching. Specifically, 1 a task_struct
with a unique pid identifies an individual process; 2 a
variable current is used to indicate the current active pro-
cess. Processes can communicate through inter-process
communication (IPC) channels like pipes. In order to
perform unit switching, we need to identify the unit data
structure that is analogous to task_struct and used to store
per-unit information, a field/expression that can be used to
differentiate unit instances as the identifier, and a variable
that stores the current active unit. Note that there may
not be an explicit task data structure in a program. Any
data structure that allows us to partition an execution to
disjoint autonomous units can serve as a unit data struc-
ture. Also, we need to know the variables that serve as
communication channels between different unit instances.
Thus we need the following types of annotations.
1 @indicator annotates the variable/field that is used
to indicate the possible switches between different unit
data structure instances (similar to the variable current in
Linux kernel). The user can choose to annotate multiple
indicator variables/fields, one for each perspective. A
unique id is assigned to each type of indicator.
2 @identifier is an expression used to differentiate the
instances of a unit data structure (similar to the data field
pid). This expression can be a field in the data structure
or a compound operation over multiple fields. Since an
identifier must be paired up with the corresponding indi-
cator, we allow providing an indicator id as part of the
identifier annotation.
3 @channel annotates the variables/fields that serve as
“IPC channels” between two different unit data structure
instances (similar to pipes). It contains a unique id num-
ber, and a parameter indicating which field stores the data
that induces inter-unit dependencies.
1 // in file src/globals.h
2 @indicator=1
3 EXTERN buf_T*curbuf INIT(= NULL);
4
5 // in file src/structs.h
6 typedef struct file_buffer buf_T;
7 // buffer: structure that holds information about one file
8 @identifier=b_ffname, indicator=1
9 struct file_buffer{
10
11
12
13
14
15
16
17
18
19
20
21
22 }; /* file_buffer */
23
24 // in file src/ops.c
25 @channel=channelID, data=(y_current->array)
26 static struct yankreg *y_current;
// associated memline
memline_T b_ml;
// buffers are orgnized as a linked list
buf_T *b_next;
buf_T *b_prev;
char_u *b_ffname;
// TRUE if the file has been changed and not written out
int b_changed;
// variables for specific commands or local options
char_u *b_u_line_ptr;
int b_p_ai;
// other data field like change time or so
// full path file name
// for ’U’ command
// ’autoindent’, local opts
Figure 8: Vim data structure and our annotation
□ Example. Vim is a tabbed editor with each tab contain-
ing one or multiple windows. Each window is a viewpoint
of a buffer, with each buffer containing the in-memory text
of a file [17]. A file buffer can be shared by multiple win-
dows in the backend, and buffers are organized as a linked
list. A natural way to partition its execution is to partition
according to the file it is working on, each represented
by a file_buffer data structure. Figure 8 shows a piece
of code which demonstrates our annotations. Vim uses
the variable curbuf to represent the current active buffer.
Consequently, we use curbuf as our indicator variable.
1116    26th USENIX Security Symposium
USENIX Association
Source codeProgrammerLLVMPASSCompiler ChainExecutableMinerLine 2 shows the indicator annotation. The annotation
has an id to distinguish different indicators for various
granularities/perspectives. The id is used to match with
the corresponding @identifier annotation. Vim creates a
buffer for each file. We can hence use the absolute file
path in the OS to identify each file buffer instance. Line
8 shows the @identifier annotation. It has two parts: 1
an expression used to differentiate instances; and 2 an
indicator id used to match with the corresponding @in-
dicator annotation. In this case, field b_ffname is the
identifier with id 1. Vim maintains its own clip board to
support internal copy(cut)-and-paste operations. When
the user cuts or copies data from a file_buffer, it sets the
field y_current→array. When the user performs a paste
operation, it reads data from the variable and puts the data
to the expected position. In this case, y_current→array
can be considered as the IPC channel between the two
different file_buffer instances. Line 25 shows the channel
annotation. It contains a unique id for the channel (anal-
ogous to a file descriptor), and the reference path to the
field. Note that this is to support communication using
the Vim clip board. Our system also supports inter- or
intra-process operations through the system clip board by
tracking system level events.
Threading Support. In order to improve responsiveness,
modern complex applications heavily rely on threads to
perform asynchronous sub-tasks. More specifically, the
main thread divides a task into multiple subtasks that can
proceed asynchronously and dispatches them to various
(background) worker threads. A worker thread receives
sub-tasks from the main thread and also other threads
and processes them in the order of reception. It can also
further break a sub-task to many smaller sub-tasks and
dispatch them to other threads, including itself. This ad-
vanced execution model makes partitioning challenging
because we need to attribute the interleaved sub-tasks
to the appropriate top level units. In event loop based
partitioning techniques [43, 46], all the event handling
loops from various threads need to be recognized during
training. More importantly, multiple event loop iterations
(across multiple threads but within an application) may be
causally related as they belong to the same task. The cor-
relations are reflected by memory dependencies. As such,
the training process needs to discover all such dependen-
cies. Otherwise, the provenance may be broken. Unfor-
tunately, memory dependencies are often path-sensitive
and it is very difficult to achieve good path coverage. It
is hence highly desirable to directly recognize the logic
tasks, which are disclosed by corresponding data struc-
tures, instead of chaining low level event loop based units
belonging to a logic task through memory dependencies.
□ Example. Figure 9 illustrates a substantially simplified
example of the Firefox execution model. It corresponds
to an execution that loads two pages (in two respective
Figure 9: Simplified Firefox execution model
tabs). Specifically, each box represents a thread and each
colored bar (inside a box) denotes an iteration of the event
handling loop (and hence a unit in BEEP/ProTracer). Ob-
serve that at step 1 , the loading of tab1 first dispatches
a Domain Name Server (DNS) query to a DNS thread,
and then (step 3 ) posts a connection request to the socket
thread to download the page. At step 4 , the socket thread
informs the main thread that the data is ready. The main
thread leverages other threads such as the image decode
thread, JS helper thread, and compositor thread to de-
code/execute/render the individual page elements. Note
that every thread has interleaved sub-tasks belonging to
various tabs. Edges denote memory dependencies across
sub-tasks that need to be disclosed during training and
instrumented at runtime in BEEP/ProTracer. □
Different from BEEP/ProTracer, our solution is to lever-
age annotations and static analysis to partition directly ac-
cording to the logic tasks (e.g. tabs). In order to precisely
determine the membership of a sub-task. We introduce
the @delegator annotation. This annotation is associated
with a data structure to denote a sub-task (e.g., the HTTP
connection request posted to the socket thread). Intu-
itively, it is a delegator of a top level task (e.g., the HTTP
connection request delegates the unit of its owner tab). At
runtime, upon the dispatching of a delegator data structure
instance (e.g., adding a sub-task to a worker thread event
queue), it inherits the current (top level) unit identification.
Later when the delegator is used (in a worker thread), the
system knows which top level unit the current execution
belongs to. There could be multiple layers of delegation.
Similar to a unit, a delegator data structure also has an
indicator, which is a variable like current whose updates