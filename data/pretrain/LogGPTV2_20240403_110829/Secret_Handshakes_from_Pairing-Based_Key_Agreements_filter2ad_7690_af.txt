where q is the order of G1.
Proceedings of the 2003 IEEE Symposium on Security and Privacy (SP(cid:146)03) 
1081-6011/03 $17.00 ' 2003 IEEE 
The Game “GetPair”:
For a user U we denote by G(U) the group such that
U ∈ G(U). The following game is played similar to the
games outlined in Section 5.1 against the system outlined
on Section 4.2. In particular, there is a universe of users U
where each user U has a list of pseudonyms idU1, . . ., idUt
and corresponding secret points privU1, . . ., privUt satisfying
∀U∀i privUi = sG(U)H1(idUi)
where sG(U) is the group secret of G(U). For simplicity, we
assume t is large enough so that users do not exhaust their
supply of pseudonyms (as discussed previously, pseudonym
exhaustion can be dealt with by having a user contact the
group authority to obtain a new list of pseudonyms.)
An adversary is placed in an environment where it is al-
lowed to interact with users of its choice; it may corrupt a
set of users U
ev-
ery pseudonym idUi and corresponding secret point privUi,
i = 1, . . . ,t.
(cid:11) ⊂ U, obtaining from each user U ∈ U
(cid:11)
We deﬁne the game GetPair as the following:
Step 1: The adversary A obtains interacts with arbitrary
of users; for each U ∈ U
(cid:11)
users and corrupts a set U
,
the adversary obtains all pseudonyms idU1, . . ., idUt
and all secrets privU1, . . ., privUt.
(cid:11)
Step 2: The adversary chooses a target user U
Step 3: The adversary, given idU∗, outputs a pair (idA, e0)
∗) and all i.
for some idA (cid:17)= idUi for all U ∈ U
(cid:11) ∩ G(U
.
∗ (cid:17)∈ U
(cid:11)
We say that A wins the game GetPair if the following equa-
tion holds:
e0 = ˆe(H1(idA), sG(U∗) · H1(idU∗)).
(1)
We deﬁne A’s advantage AdvGetPairA as
AdvGetPairA := Pr[A wins the game GetPair].
∗
This probability is taken over the random choices for xi and
, and all other players in the
the random coin ﬂips of A, U
system.
We denote by QH1 the number of distinct queries A
makes to the random oracle H1. We write e ≈ 2.78 as the
base of the natural logarithm.
Lemma 7 Suppose A is a probabilistic, polynomial time
(PPT) adversary. There exists a probabilistic, polynomial
time algorithm B such that
AdvGetPairA ≤ e QH1
· AdvBDHB + ε,
where ε is negligible as a function of the security parameter.
Proof Sketch: We deﬁne B as follows. B is given an
instance (P, aP, bP, cP) of the BDH problem, and wishes to
use A to compute ˆe(P, P)abc. The algorithm B simulates an
environment in which A operates, using A’s advantage in the
game GetPair to help compute a solution ˆe(P, P)abc to the
BDH problem.
Here is a high-level description of how the algorithm B
will work. B will “cook” the responses to all queries to
the random oracle H1 so that the resulting distribution re-
mains random, but any advantage A has in the game GetPair
will be used to compute a solution to the BDH problem. B
does this by using the point bP to create secret points for all
pseudonyms used in the system; except the pseudonym idA
used by the adversary, whose corresponding secret will be
derived from aP; and, the pseudonym idU∗ used in the last
step, whose corresponding secret will be derived from cP.
(cid:11)
G for
To set up, B picks random auxiliary group secrets s
all groups G.
We must specify how B will answer queries given by A.
On a query H1(x), if a result has already been assigned to
H1(x) it is returned again. Otherwise, B ﬂips a random
biased coin guess(x) ∈ {0,1} biased by some parameter δ
to be determined later:
(cid:2)
guess(x) =
0 with probability δ,
1 with probability 1− δ.
The algorithm B then responds as follows:
• guess(x) = 0:
B picks a uniformly random rx ∈ {1, . . . ,q} and returns
H1(x) := rx · (aP).
• guess(x) = 1:
B picks a uniformly random rx ∈ {1, . . . ,q}. If x is a
pseudonym of an existing user U, then B sets H1(x) :=
G(U)·(bP), otherwise it assigns x to an uncorrupted
rx·s
(cid:11)
user U and return the same.
∈ {1, . . . ,q}, and sets
In the ﬁrst step, A obtains pseudonym/secret lists for
users of its choice. For a corrupted user U and for all
i = 1, . . . ,t, B picks a random values for the idUi, random
values ridUi
H1(idUi) = ridUi
In stage 2, A picks a target user U
In stage 3, B responds with a random value for idU∗ and
· s
G(U) · (bP).
(cid:11)
· s
G(U) · P,
(cid:11)
privUi = ridUi
∗
.
sets H1(idU∗) := cP. Then A outputs (idA, e0).
signed a random value as described above.
If A never queried H1 on input idA, then H1(idA) is as-
Suppose guess(idA) = 0. Then H1(idA) = r · (aP) for
G(U∗))−1
(cid:11)
some value r known to B. B computes w := (rs
mod q and returns (e0)w as its solution to the BDH instance.
It is straightforward to check that if Equation 1 holds then
(e0)w = e(P, P)abc as desired.
Proceedings of the 2003 IEEE Symposium on Security and Privacy (SP(cid:146)03) 
1081-6011/03 $17.00 ' 2003 IEEE 
A detailed analysis shows that if guess(idA) = 0 and
guess(x) = 1 for all queries x (cid:17)= idA to H1, then the execu-
tion environment which B creates for A is indistinguishable
from the actual game GetPair except for an error probability
ε that is a negligible function of the security parameter.
It remains to optimize δ to maximize the success proba-
bility of B. We see
Pr[guess(idA) = 0 and guess(x) = 1
for all x (cid:17)= idA] = δ· (1− δ)QH1 .
(2)
Using standard calculus we optimize δ to ﬁnd δ ≈ 1/QH1;
plugging this back in to equation (2) results in Pr[(2)] ≥
1/(e· QH1
(cid:1)
). The claim follows.
We now restate the security claims for the Pairing-Based
Handshake as Theorems 8 and 9, and Corollary 10. We
outline proofs at the end of the appendix.
We denote by QH2 the number of distinct queries A
makes to the random oracle H2, and we denote by QH1 the
number of distinct queries A makes to the random oracle
H1. We write e ≈ 2.78 as the base of the natural logarithm.
Theorem 8 Suppose A is a probabilistic, polynomial time
adversary. There is an PPT algorithm B such that
AdvMIGA ≤ Pr[ PBH.TraceUser(T ) ∈ U
(cid:11) ∩ G
∗ ]
· AdvGetPairB + ε,
+ QH2
where QH2 is the number of queries A makes to H2, and ε is
negligible in the security parameter.
Proof of Theorem 1:
Lemma 7.
This follows from Theorem 8 and
We now turn our attention to the Member Detection
Game. Using the notation from Section 4, we claim the
following.
Theorem 9 Suppose A is a probabilistic, polynomial time
adversary. There is an PPT algorithm B such that
AdvMDGA ≤ Pr[ PBH.TraceUser(T ) ∈ U
(cid:11) ∩ G(U
∗) ]
+ QH2
· AdvGetPairB + ε,
where QH2 is the number of queries A makes to H2, and ε is
negligible in the security parameter.
Proof of Theorem 4:
Lemma 7.
This follows from Theorem 9 and
Finally, we present the claim of eavesdropper indistin-
guishability for our scheme.
∗
distinguish U
lator would send. The rest of the analysis is similar.
’s messages from the random strings a simu-
(cid:1)
Proof Sketch of Corollary 10:
Suppose A is a PPT adversary with nonzero distinguish-
to play the Member
(cid:11)
ing advantage. We build an algorithm A
Detection Game.
∗
:= U
∗
1 and U
∗
(cid:11)
2 , A
∗
i as the target user.
We begin by starting the adversary A. Any request from
A to interact with users or obtain secrets from users is passed
(cid:11)
, which is in Step 1 of the Member Detection
through by A
picks i ∈ {1,2}
Game. When A picks users U
It then acts as
and requests U
∗
1 and
a “man-in-the-middle” for the interaction between U
∗
2 , and sends the resulting transcript to A. By a standard
U
hybrid argument, a distinguishing advantage AdvDSTA for
A translates to AdvMDGA(cid:11) = (1/2)· AdvDSTA.
Without loss of generality, we will assume i = 2. No-
(cid:11)
∗
2 satisﬁes idA(cid:11) =
tice that the message idA(cid:11) sent by A
to U
(cid:17)∈ U
(cid:11)
∗
∗
So if T is
. By the restriction on A, U
idU
1
∗
(cid:11)
1
the transcript of the interaction of A
with U
2 , we know
PBH.TraceUser(T ) = U
.
∗
1 , implying
Pr[PBH.TraceUser(T ) ∈ U
The bound follows from Theorem 4.
(cid:11) ∩ G(U
∗)] = 0.
(cid:1)
Corollary 10 (PBH Eavesdropper Indistinguishability)
Suppose A is a probabilistic, polynomial time adversary.
There is a PPT algorithm B such that
AdvDSTA ≤ 2· QH2
· AdvGetPairB + ε,
where QH2 is the number of queries A makes to H2, and ε is
negligible in the security parameter.
Proof Sketch of Theorem 8: We construct an algorithm
B that plays the game GetPair. It creates an environment in
which A plays the Member Impersonation Game, and uses
the information from A to gain an advantage in the game
GetPair.
Since we model H2 as a random oracle, B can specify
how to answer queries to H2 as long as the resulting distri-
bution is random. If H2 has been queried for the ﬁrst time
on input x, we generate a random result y, record (x, y), and
return y as the result. If H2(x) has been invoked already, we
ﬁnd an entry (x, y) in the table and return y.
In step 1 of the Member Impersonation Game, A asks for
user secrets. B passes these through to the environment in
step 1 of the game GetPair.
∗
In step 2, the adversary A picks a target group G
and
In step 3, A sends a message (idA, nA,V1) to U
D := e(H1(idA), sG∗ · H1(idU∗))(cid:10)idA(cid:10)idB(cid:10)nA(cid:10)nB(cid:10)0.
. Deﬁne
∗
user U
∗
.
.
(cid:11) ∩ G
∗
Suppose idA = idUi
A wins the Member Impersonation Game exactly when V1 =
H2(D).
(cid:11) ∩ G
∗
Let
∗
T be the transcript of A’s interaction with U
Since
.
idUi was uniquely assigned (with high probability),
(cid:11)∩
PBH.TraceUser(T ) uses idUi to uniquely identify U ∈ U
∗
G
for some U ∈ U
, and we are done.
Now suppose idA (cid:17)= idUi for all U ∈ U
. Since
the string D contains random nonces, with high probability
H2(D) has never appeared in any of A’s interactions with
the system. If A never queried H2 at any point with preﬁx
D, we may assign a random value to H2(D), independent of
A’s view. Then probability that V1 = H2(D) is negligible.
So we assume A queried H2(D) at some point during the
execution of the game. B chooses a random pair (x, y) from
the list of queries to H2, pulls the preﬁx e0 from x, and re-
turns e0 as its guess in the game GetPair. Suppose A made
QH2 queries of the random oracle H2. Then with probabil-
ity 1/QH2, x = D, and B wins the game GetPair. The bound
(cid:1)
follows.
Proof Sketch of Theorem 9:
This follows as in the proof of Theorem 8, with the
following change: Instead of claiming that A must have
queried H2 at the point D in order to construct the message
V1, we claim that A must have queried H2 at D in order to
Proceedings of the 2003 IEEE Symposium on Security and Privacy (SP(cid:146)03) 
1081-6011/03 $17.00 ' 2003 IEEE