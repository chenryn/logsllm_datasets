title:CrowdTarget: Target-based Detection of Crowdturfing in Online Social
Networks
author:Jonghyuk Song and
Sangho Lee and
Jong Kim
CrowdTarget: Target-based Detection of Crowdturﬁng in
Online Social Networks
Jonghyuk Song
Dept. of CSE, POSTECH
Pohang, Republic of Korea
PI:EMAIL
Sangho Lee
Dept. of CSE, POSTECH
Pohang, Republic of Korea
PI:EMAIL
Jong Kim
Dept. of CSE, POSTECH
Pohang, Republic of Korea
PI:EMAIL
Abstract
Malicious crowdsourcing, also known as crowdturﬁng, has
become an important security problem. However, detect-
ing accounts performing crowdturﬁng tasks is challenging
because human workers manage the crowdturﬁng accounts
such that their characteristics are similar with the charac-
teristics of normal accounts.
In this paper, we propose a
novel crowdturﬁng detection method, called CrowdTarget,
that aims to detect target objects of crowdturﬁng tasks (e.g.,
post, page, and URL) not accounts performing the tasks.
We identify that the manipulation patterns of target objects
by crowdturﬁng workers are unique features to distinguish
them from normal objects. We apply CrowdTarget to detect
collusion-based crowdturﬁng services to manipulate account
popularity on Twitter with artiﬁcial retweets. Evaluation
results show that CrowdTarget can accurately distinguish
tweets receiving crowdturﬁng retweets from normal tweets.
When we ﬁx the false-positive rate at 0.01, the best true-
positive rate is up to 0.98.
Categories and Subject Descriptors
C.2.0 [Computer-Communication Networks]: General—
Security and protection; K.4.1 [Computers and Society]:
Public Policy Issues—Abuse and crime involving computers
General Terms
Security
Keywords
Malicious crowdsourcing; Online social networks; Twitter;
Underground services
1.
INTRODUCTION
According to the characteristics of tasks, people can do
certain tasks better than computers in terms of accuracy,
cost, and speed. Crowdsourcing is the process of outsourcing
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
CCS’15, October 12–16, 2015, Denver, Colorado, USA.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-3832-5/15/10 ...$15.00.
DOI: http://dx.doi.org/10.1145/2810103.2813661.
tasks to human workers to exploit such observations while
paying them for the tasks. Various crowdsourcing sites ex-
ist, such as Amazon Mechanical Turk, Microworkers, and
Crowdsource.
Unfortunately, adversaries have become major customers
of crowdsourcing services. They use the services for mali-
cious purposes because human workers can easily circumvent
conventional security systems to detect automated activities
performed by bots. Adversaries can leave various malicious
tasks to human workers belonging to crowdsourcing sites,
such as spreading spam URLs, searching speciﬁc keywords
to manipulate search results, and boosting the popularity
of their accounts in online social networks (OSNs). This
malicious crowdsourcing has both characteristics of crowd-
sourcing and astroturﬁng, so researchers name it crowdturf-
ing [33].
Although researchers propose numerous methods of mali-
cious account detection using account-based features or syn-
chronized group activities, they are inappropriate to detect
crowdturﬁng accounts. First, detection methods based on
account-based features [12, 17, 23, 34, 35] inspect the charac-
teristic of individual account, e.g., the number of friends, the
number of posts, and age. However, recent studies [29, 32]
show that applying the techniques to detect crowdturﬁng
accounts is vulnerable to simple evasion techniques, such as
performing malicious tasks while doing normal behaviors.
Interestingly, our analysis of account popularity, which is
computed by using account features and behaviors, shows
that crowdturﬁng accounts are more popular than normal
accounts (Section 4.1).
Next, identifying synchronized group activities of mali-
cious accounts is state-of-the-art methods of detecting mali-
cious accounts managed by bots [8, 11, 15, 16, 31]. However,
we empirically identify that crowdturﬁng tasks have weak
correlation because human workers perform the tasks ei-
ther without schedule or with ﬂexible schedule (Section 4.2).
Consequently, we demand a novel detection method that re-
lies on neither account characteristics nor program-controlled
behaviors.
In this paper, we propose a novel method of detecting
crowdturﬁng, called CrowdTarget. CrowdTarget aims to dis-
cover target objects that crowdturﬁng customers attempt to
manipulate, e.g., URL, search keyword, and post, by us-
ing their manipulation patterns. Unlike conventional detec-
tion methods using account characteristics, CrowdTarget is
(i) robust against evasive techniques to manipulate account-
based features. Also, it can detect crowdturﬁng tasks per-
793formed by (ii) new accounts or (iii) casual workers who oc-
casionally participate in crowdturﬁng tasks.
Among numerous crowdturﬁng services aiming at various
services, we apply CrowdTarget to collusion-based crowd-
turﬁng services that manipulate account popularity on Twit-
ter by using artiﬁcial retweets. Our goal is to distinguish be-
tween tweets receiving retweets from crowdturﬁng accounts
(we name them crowdturﬁng tweets) and tweets receiving
retweets from normal accounts.
We ﬁrst analyze the diﬀerences in retweet patterns of
the three tweet groups: normal, crowdturﬁng, and black-
market tweet groups. From the analysis, we ﬁnd four new
retweet-based features that allow us to distinguish crowd-
turﬁng tweets from others: (i) retweet time distribution,
(ii) the ratio of the most dominant application, (iii) the
number of unreachable retweeters, and (iv) the number of
received clicks. The ﬁrst feature, retweet time distribu-
tion, consists of four sub-features: mean, standard devia-
tion, skewness, and kurtosis.
Next, we build three classiﬁcation models, Ada Boost,
Gaussian na¨ıve Bayes, and k-nearest neighbors, by using the
retweet-based features and evaluate them with our ground-
truth dataset. Evaluation results show that CrowdTarget
can accurately distinguish crowdturﬁng tweets from normal
tweets; the true-positive rate (TPR) is 0.98 when the false-
positive rate (FPR) is 0.01 with the k-nearest neighbor al-
gorithm.
In summary, the main contributions of this paper are as
follows:
• New detection approach. We detect crowdturﬁng
by analyzing not the characteristics of its accounts but
the characteristics of its targets.
In this paper, the
targets are tweets and the crowdturﬁng task retweets
the tweets. To the best of our knowledge, this is the
ﬁrst approach that detects crowdturﬁng by using the
targets.
• In-depth analysis. We analyze retweets generated
by three account groups: normal, crowdturﬁng, and
black market. This analysis provides insight to under-
stand each group’s behaviors.
• High accuracy. The accuracy of our method is very
high. When we ﬁx the false-positive rate at 0.01, the
true-positive rate is up to 0.98.
The remainder of this paper is organized as follows. In
Section 2 we compare black-market sites and crowdturﬁng
sites.
In Section 3 we explain the details of our dataset.
In Section 4 we analyze the characteristics of crowdturﬁng
workers. In Section 5 we introduce the unique features of
crowdturﬁng targets. In Section 6 we explain how we use
the features to construct our classiﬁers and evaluate their
accuracy. In Section 7 we discuss the robustness of our fea-
tures. In Section 8 we introduce related studies. Lastly, we
conclude this paper in Section 9.
2. BACKGROUND
In this section, we explain black-market sites and crowd-
turﬁng sites for OSNs. Their main diﬀerence is that the
black-market sites only sell malicious services, whereas the
crowdturﬁng sites not only sell malicious services but also
encourage the participation of users in conducting malicious
activities.
Figure 1: Procedure of OSN boosting in a collusion-
based crowdturﬁng service. A customer C posts a
task on the service S. A worker W performs the task
on S and S relays W ’s actions to the target OSN. C
ﬁnally pays virtual money for the tasks that W has
conducted.
2.1 Black-market Site for OSNs
Black-market sites are proposed to satisfy people’s desire:
promoting their popularity in OSNs. The sites provide var-
ious services for the goal, e.g., increasing the number of fol-
lowers, likes, and comments. According to the price, they
oﬀer various plans with deadlines, e.g., $39 for gaining 2,500
Twitter followers within 48 hours.
To provide malicious services, black-market sites usually
operate a large number of bots to perform many tasks by
deadlines. They strive to develop bot accounts that closely
resemble normal accounts because (i) they want to prevent
security teams of OSNs from suspending their accounts and
(ii) their customers want to have human-like followers to
make the popularity of their accounts more realistic.
Although bot accounts resemble normal accounts, they
inevitably have synchronized group activities because they
should perform the same tasks by deadlines. Therefore, re-
cent studies try to detect bot accounts in OSNs by discov-
ering their synchronized group activities [8, 11, 15, 16, 31]. In
Section 4, we also observe synchronized group activities of
black-market accounts.
2.2 Crowdturﬁng Sites for OSNs
Recently, collusion-based crowdturﬁng services specialized
for OSN boosting have appeared, e.g., addmefast.com [1]
and traffup.net [6]. In these services, users exchange their
eﬀorts to achieve their goals, such as increasing the num-
ber of Twitter followers and retweets, the number of Insta-
gram comments, and the number of Facebook likes. Figure 1
shows the procedure of OSN boosting in such services.
x A customer C posts an object (e.g., tweet and page) to
be manipulated to a crowdturﬁng service and speciﬁes
a reward (e.g., an amount of virtual money).
y A worker W performs boosting tasks on the crowd-
turﬁng service (e.g., click an RT button).
z The crowdturﬁng service relays the boosting tasks to
the target OSN.
{ The crowdturﬁng service transfers C’s virtual money
to W .
The collusion-based crowdturﬁng service simpliﬁes the pro-
cess of boosting for both workers and customers. In a con-
WCCrowdturfing service(cid:164)Boosting(cid:163)Crowdturfing task(cid:165)Boosting(cid:166)Payment(virtual money)Online Social NetworkWCpost1post2…postnRT794Table 1: The dataset
Dataset
#Tweets #Retweets #Retweeters
Normal
Without URL
With URL
Total
Crowdturﬁng
Without URL
With URL
Total
Black-market
Total
10,318
15,248
25,566
4,531
14,867
19,398
914,974
1,941,482
2,856,456
576,033
1,866,843
2,442,876
390,275
1,149,563
1,412,632
115,657
110,295
190,800
282
71,858
41,829
ventional crowdsourcing service, a worker performs the boost-
ing in the target OSN and customers should examine whether
the worker has done the task properly. However, the collusion-
based crowdturﬁng service automates the procedures of work-
ers and customers. When a user signs up the crowdturﬁng
service, the user authorizes the crowdturﬁng service’s ap-
plication that manages and monitors overall boosting tasks.
The application monitors how crowdturﬁng workers perform
certain boosting tasks at the crowdturﬁng service and re-
lays the tasks to the target OSN. Thus, the service can be
convinced that the boosting tasks are done properly. This
convenient procedure makes workers easily perform many
crowdturﬁng tasks.
Based on the analysis results in Section 4, we are con-