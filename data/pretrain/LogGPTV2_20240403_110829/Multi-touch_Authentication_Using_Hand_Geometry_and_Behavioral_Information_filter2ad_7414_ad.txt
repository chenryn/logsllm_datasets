be discussed in Section VII-C.  
B.  Effect of Feature Subsets and Classifiers 
to 
In Section III-B, we defined physiological and behavioral 
features to characterize TFST gestures. With feature selection, 
we obtain 4 different feature subsets: (1) physiological subset; 
(2) behavioral subset; (3) the whole set which contains all the 
features in (1) and (2); and (4) selected subset where features 
in (3) are selected by a Fisher Score over 0.5.  
In this  experiment,  we  investigated  the effect of  feature 
subsets and classifiers on the performance of authentication of 
the TFST gesture of 4-finger L swipe. We employed one-class 
SVM and K-Nearest Neighbor classifiers with the inputs set 
to 4 different feature subsets.  
To  select  parameter  k  for  KNN,  multiple  tests  with  k 
ranging from 1 to 20 were performed. The best parameter k = 
3 is selected. For SVM, we employed the radial basis function 
(RBF) kernel after comparative studies of linear, polynomial, 
RBF,  and  sigmoid  kernels  according 
the  average 
classification  accuracy.  The  SVM  parameter  (cid:547)  and  kernel 
parameter (cid:534) (using LibSVM [30]) were set to 0.05 and 0.015 
respectively. 
The size of the training set was set to 30. Subjects with at 
least 30 samples were designated as legitimate users. For each 
legitimate  user,  the  other  160  subjects  were  set  to  be 
imposters. Figure 6 shows the ROC curves for four types of 
feature subsets using different classifiers. 
As shown in Figure 6, the authentication accuracies with 
the physiological subset (1), whole set (3) and selected subset 
(4) are all much higher than with the behavioral subset (2), 
which  suggests  that  our  approach  to  incorporate  hand 
geometry information into multi-touch authentication brings 
significant  improvements  over  a  purely  behavioral  based 
approach. 
Another  observation  is  that  the  performance  of  the 
selected  subset  is  superior  to  the  other  feature  subsets.  It 
indicates  that  the  Fisher  Score  for  feature  selection  is  an 
effective way to fuse physiological and behavioral features. 
The fused feature set performs better than each of individual 
feature  set.  This  provides  evidence  for  our  assumption: 
behavioral  features  may  complement 
in 
discernibility  of  physiological  features  due  to  measurement 
errors resulting from behavioral variances. 
the  decrease 
364
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:28:02 UTC from IEEE Xplore.  Restrictions apply. 
30
25
20
15
10
5
0
(1) Physiological-KNN
(2) Behavioral-KNN
(3) All-KNN
(4) Selected-KNN
0
5
10
15
20
25
30
False Rejection Rate (%)
(a)
30
25
20
15
10
5
0
(1) Physiological-SVM
(2) Behavioral-SVM
(3) All-SVM
(4) Selected-SVM
0
5
10
15
20
25
30
False Rejection Rate (%)
(b)
Fig. 6. ROC curves for 4 types of feature subsets using 2 types of 
classifiers: (a) K-Nearest Neighbor, (b) SVM 
TABLE IV. COMPARISON OF TWO CLASSIFIERS USING MCNEMAR’S TEST 
Fig. 7. EERs for 3 types of feature subsets at varying training set sizes 
Better classifier 
# of cases  Proportion (%) 
126 
6 
12 
87.5 
4.17 
8.33 
KNN 
SVM 
Equivalent 
test 
to  evaluate 
We  employed  McNemar’s 
the 
performance of the classifiers. The significance level (cid:302) is set 
to 0.05. Table IV shows the result. In 12 cases, there is no 
significant difference between the performance of 3-Nearest-
Neighbor  and  SVM;  in  126  cases,  3-Nearest-Neighbor 
outperforms SVM; and SVM has a better performance only in 
6  cases.  This  result  shows  that  the  3-Nearest  Neighbor 
classifier has better performance than SVM in general. This 
may be due to the situation that our training set is small and 
the SVM classifier is trained inadequately, so the few support 
vectors  cannot  describe  the  complex  profile  of  positive 
samples  perfectly. The  3-Nearest Neighbor classifier,  using 
Manhattan distance to measure the distance between samples, 
nonlinearly builds a more reasonable boundary to distinguish 
positive and negative samples. Given the better performance 
of 3-Nearest Neighbor classifier, we will use it as the main 
classifier in the later experiments.  
C.  Effect of Training Set Size 
In the previous experiment, 30 samples from each subjects 
were used as the training dataset for authentication. Next we 
investigated using different training sample sizes. 
We  employed  3-Nearest  Neighbor  as  the  one-class 
classifier in this evaluation, with the input features set to be 
the  physiological  subset,  the  behavioral  subset,  and  the 
selected  subset  respectively.  We  changed  the  size  of  the 
training  set  from  5  to  100  in  a  step  of  5  initially  and  10 
afterwards to investigate the impact of training data size on 4-
finger L swipe authentication. Figure 7 plots the average EERs 
against different sizes of training dataset. 
The result shows that the size of a training set will have a 
significant effect on the performance of authentication. For all 
three input feature subsets, the average EER decreases with 
more  training  data.  A  large  training  set  often  gives  the 
classifier  more  information  and  more  training  samples 
characterize the legitimate user more accurately and lead to 
lower EERs. 
Among  the  three  feature  subsets,  we  observed  that 
the 
physiological and selected feature subsets exhibited a steeper 
learning  curve.  This  showed 
feature  spaces  of 
physiological  and  selected  combined  features  were  more 
compact  so  that  less  training  data  yielded  better  learning 
effects.  The  selected  combined  feature  set  showed  the  best 
learning performance with final EER dropping to 1/3 of the 
initial value (from 5.84% to 1.88%) with enough learning.  
The  result  also  showed  for  the  selected  feature  subset, 
using over 15000 samples from 160 subjects as illegitimate 
testing  samples,  TFST  L  swipe  authentication  is  able  to 
achieve  an  EER  of  5.84%  with  only  5  training  samples, 
compared with an EER of 18.21% for the behavioral feature 
set and an EER of 7.91% for the physiological feature set. This 
demonstrated the effectiveness of fusion of physiological and 
behavioral features for multi-touch authentications. 
In the experiment of Section VII-A, we also investigated 
the effect of different sizes of training data on authentication 
performance of different TFST gestures. From Figure 7, we 
can see that simple 3-finger TFST L swipe authentication can 
also achieve an EER of 9.32% with only 5 training samples 
and an EER of 4.10% with enough training. This suggested 
that 3-finger TFST gestures may provide an easy and relative 
secure authentication method on small screen devices such as 
popular smartphones. 
D.  Behavioral Variability 
Behavioral variability is an important issue for behavioral 
biometric techniques. In this experiment, we focus on long-
term  behavioral  variability  and  its  impact  on  multi-touch 
authentication.  
As  introduced  in  Section  III-C,  we  separated  the  data 
collection process into 6 sessions over about 2 months, with 
sessions separated by more than a week. We also required the 
subjects to participate in every session of data collection. By 
doing  this,  we  recorded  long-term  variations  of  touching 
behaviors  for  each  subject  in  the  collected  dataset.  In  this 
experiment,  the  training  and  testing  datasets  are  organized 
according to sessions to investigate the impact of behavioral 
variability with respect to time. 
The  setting  of  training  and  testing  data  for  each  EER 
calculation of session N is shown in Table V. For each subject, 
there are about 20 samples in one session. We randomly select 
365
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:28:02 UTC from IEEE Xplore.  Restrictions apply. 
TABLE V. TRAINING AND TESTING DATA FOR SESSION N 
Description 
Experimental Datasets 
Training set 
Legitimate Testing set 
Illegitimate Testing set 
5 samples from subject 
in Session 1 
All samples from subject 
in Session N (2~6) 
All imposter samples 
from all sessions 
5 samples in the first session to train the one-class classifier. 
Then  we  use  his  data  in  subsequent  sessions  as  legitimate 
testing data and samples from all other subjects in all sessions 
as illegitimate testing data of imposters. 
We  employed  3-Nearest  Neighbor  as  the  one-class 
classifier in this evaluation, with the input features set to be 
the  physiological  subset,  the  behavioral  subset  and  the 
selected  subset  for  the  4-finger  TFST  L  swipe  gesture 
respectively.  
The  experiment  is  repeated  for  each  subject  as  the 
legitimate user. For each subject, we repeat the experiment 10 
times  to  account  for  the  randomness.  Figure  8  show  the 
average EERs when legitimate data in different sessions are 
used as the legitimate testing data.  
Since  we  only  train  the  one-class  classifier  once,  using 
data from the first session, the performance of the trained one-
class  classifier  on  data  from  later  sessions  demonstrate  the 
applicability  of  the  identity  model  to  the  behavioral  data 
collected after model training. Our dataset allows us to explore 
this  applicability  on  behaviors  recorded  in  subsequent  two 
months.  This  period  likely  captured  substantial  amounts  of 
behavioral variability in the collected dataset. 
  As shown in Figure 8, the EERs for the physiological and 
selected  feature  subsets  do  not  vary  very  much  and  are 
relatively  constant  over  different  sessions.  For  example  for 
physiological  features,  we  only  observe  slight  increases  of 
EERs from 6.38% to 7.51% for session periods from 2 to 6. 
While for behavioral features, the increase of EERs are from 
13.39%  to  22.14%  for  the  same  periods.  This  means 
physiological  features are better  than  behavioral  features  in 
terms of resisting to behavioral variability over time. We also 
noticed,  for  the  selected  combined  features,  the  EER 
performance  is  again  the  best,  with  a  slight  increase  from 
4.46% to 5.58%. This showed that the fusion of behavioral 
information with hand geometry features not only reduce the 
EER  levels,  but  also  leads  to  resistance  to  behavioral 
variability over time. 
VIII. SECURITY ANALYSIS 
In this section, we examine the security of the proposed 
method according to the threat model presented in Section II. 
We perform an experimental study of the security of TFST 
gesture authentication against the so called zero-effort attack, 
smudge attack, shoulder surfing attack and statistical attack. 
A.  Zero-effort Attack 
Zero-effort attack may be the most common type of attack 
against an authentication system where the attacker guesses 
366
)
%
(
e
t
a
R
r
o
r
r
E
l
a
u
q
E
Fig. 8. Long-term EER curves for different feature sets 
the secret or tries the authentication procedure without much 
knowledge of how a legitimate user enters the system. For 
TFST  gesture  authentication,  we  assume  a  zero-effort 
attacker  only  knows  which  gesture  to  perform  and  has  no 
other information.  
In section VII, the investigation performed on the various 
accuracies of TFST gestures is actually an investigation of the 
resilience  to  zero-effort  attack.  For  the  161  subjects  in  our 
evaluation dataset, we designated one of our subjects as the 
legitimate user, and the other 160 subjects as impostors, or 
zero-effort attackers. The results demonstrated the resilience 
of  TFST  gesture  authentication  to  zero-effort  attacks  in 
general. 
Since  hand  geometry  information  is  very  important  in 
TFST  gesture  authentication  and  there  are  chances  that  an 
attacker has a similar handshape as the victim being attacked, 
we  further  investigate  zero-effort  attacks  considering  the 
factor of handshape similarity. To do this, we selected the user 
pairs  with  similar  handshapes  by  calculating  a  similarity 
metric, Sim, based on the recorded hand images in our dataset. 
Sim
ij
= −
1
||
||
v