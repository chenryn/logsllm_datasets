title:A resource-minimalist flow size histogram estimator
author:Bruno F. Ribeiro and
Tao Ye and
Donald F. Towsley
A Resource-minimalist Flow Size Histogram Estimator
Bruno Ribeiro
Computer Science
Department
University of Massachusetts
Amherst, MA, 01003
PI:EMAIL
Tao Ye
Sprint
Burlingame, CA, 94010
PI:EMAIL
Don Towsley
Computer Science
Department
University of Massachusetts
Amherst, MA, 01003
PI:EMAIL
ABSTRACT
The histogram of network ﬂow sizes is an important yet
diﬃcult metric to estimate in network monitoring. It is im-
portant because it characterizes traﬃc compositions and is
a crucial component of anomaly detection methods.
It is
diﬃcult to estimate because of its high memory and com-
putational requirements. Existing algorithms compute ﬁne
grained estimates for each ﬂow size, i.e. 1, 2,. . . up to the
maximum number observed over a ﬁnite time interval. Our
approach instead relies on the insight that, while many ap-
plications require ﬁne grained estimates of small ﬂow sizes,
i.e. {1, 2, . . . , k} with a small k, network operators are of-
ten only interested in coarse grained estimates of larger ﬂow
sizes. Thus, we propose an estimator that outputs a binned
histogram of size distributions. Our estimator computes
this histogram in O(k3 + log W ) operations, where W is the
largest ﬂow size of interest to the network operator, while
requiring only a few bits of memory per measured ﬂow. This
translates into more than 4 fold memory savings and an ex-
ponential speedup in the estimator as compared to previous
works, greatly increasing the possibility of performing on-
line estimation inside a router.
Categories and Subject Descriptors
C.2.3 [Network Operations]: Network monitoring; G.3
[Probability and Statistics]: Nonparametric statistics
General Terms
Design, Measurement
Keywords
Monitoring Systems, Sampling Methods, Data Stream Al-
gorithms, Flow Size Histogram
1.
INTRODUCTION
Measuring the histogram of network ﬂow sizes has been
the subject of a number of recent studies [2–5, 8]. Although
Internet routers handle traﬃc on a packet-by-packet basis at
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
IMC’08, October 20–22, 2008, Vouliagmeni, Greece.
Copyright 2008 ACM 978-1-60558-334-1/08/10 ...$5.00.
the IP layer, the statistics of the underlying ﬂows are vital
to network operators. The histogram of ﬂow sizes, i.e. the
number of ﬂows with i packets, is an important traﬃc metric
that gives insights to network monitoring applications such
as traﬃc proﬁling, and aids fast detection of security attacks.
In this work we refer to this histogram as the size histogram.
Directly computing size histograms requires an often ex-
pensive ﬁrst step of classifying packet traﬃc into ﬂows. Be-
cause as many as half a billion ﬂows arrive every hour at an
Internet core router, this task is extremely resource inten-
sive. Reducing the load by aggressively sampling packets at
random [3] (without much side information) has been shown
to produce inaccurate histogram estimates [8]. Recently a
number of alternative solutions employ data streaming al-
gorithms to solve the histogram problem with more accu-
racy [2, 4, 5]. Kumar et al. [5] proposed sketches to maintain
approximate ﬂow size counts in an array of counters, then
used a computationally intensive Expectation Maximization
(EM) algorithm to compute the estimation from these coun-
ters. The authors advise network operators to use at least
one 32 bit counter per ﬂow in average. We argue that al-
though this EM algorithm yields precise estimates, it is pos-
sible to obtain useful estimates much faster and with much
smaller counters. Cormode et al. [2] computes the histogram
using a sketch that maintains a tuple (ﬂow size counter, ﬂow
id) in memory. It relies on ﬂow ﬁltering (thinning) to com-
pute histogram estimates. The drawback of this method
comes from its high memory requirements, which can be as
high as dozens of bytes per ﬂow. Lu et al. [6] uses a stream-
ing algorithm tailored speciﬁcally to measure heavy tailed
distributions that requires little memory space. Their esti-
mator however needs to compute all ﬂow sizes and use (even
in a best-case scenario) O(W ) time, where W is the largest
ﬂow size of interest to the network operator.
In this work we propose an approach similar to Kumar
et al. [5], using a sketch of ﬂow size counters and a direct
estimator. However, we trade-oﬀ ﬂow size granularity for an
exponentially faster estimator and less than 1/4 of memory
usage (7 bits per ﬂow) compared to [5]. In contrast to Lu
et al. [6], our approach is exponentially faster and does not
assume we know the distribution shape.
Reducing memory consumption. We are motivated by
the following insight of traﬃc monitoring applications. Since
size histogram provides a general overview of the traﬃc,
rather than a direct measurement of usage, typical monitor-
ing applications do not need ﬁne grained counts of all ﬂow
sizes. In security event detection, we are interested in very
small ﬂow sizes (mice) such as 1, 2, but only up to a certain
value k. To measure the impact of medium and elephants
ﬂows, these larger ﬂow sizes can be estimated in a binned
fashion. Therefore we propose a new multi-resolution algo-
rithm to estimate the size histogram with aggregated and
probabilistic counting of large ﬂows, and ﬁne-grained count-
ing for ﬂow sizes up to k packets. As an example, for k = 16,
we maintain per ﬂow counters for each ﬂow sizes 1,..,16, but
ﬂows of sizes from 17 packets to 32 packets, 33 to 64, etc, are
counted probabilistically and estimated together. This al-
lows for a faster estimator with reduced counter sizes, while
still maintaining good accuracy. Using our approach with 6
bit counters and k = 16 we can probabilistically count ﬂows
of sizes up to W ≈ 1014.
Faster estimator. We also provide a simple estimator that
is almost as accurate as a slower maximum likelihood estima-
tor for small ﬂow sizes. For larger ﬂow sizes the second part
of our technique estimates all histogram bins in O(log W )
time, where W is the largest ﬂow size of interest for the
network operator. This is achieved by designing a space
eﬃcient low collision sketch. Our sketch divides and folds
(multiplexes) Z virtual sketches into the physical space of
one sketch. The low ﬂow collision probability allows us to
obtain good histogram estimates with O(k3 + log W ) oper-
ations in total. Note that W and k can be made as small as
the network operator wants with no loss in accuracy. When
faced with very high speed links and relatively low comput-
ing resources for monitoring and statistics gathering, our
simple resource minimalist design makes a strong case for
an in-line inside the router implementation.
The rest of the paper is organized as follows. Section 2
provides an overview of the algorithm. Section 3 illustrates
data structure design and our estimator in details. Exper-
iment results using trace data are shown in Section 4. We
conclude with Section 5.
2. OVERVIEW
We follow a common design of breaking down the packet
stream by measurement epochs.
In each epoch our algo-
rithm contains two phases: upon each packet arrival a data
structure to count ﬂow sizes is updated, at the end of the
epoch we use an estimator to compute the histogram from
this data structure.
The data structure works as follows. Each newly arrived
packet is used to update a counter through a hash func-
tion, where all packets in a ﬂow hash to the same counter.
We keep M of such counters in a vector that we refer as
the sketch. We choose a universal hash function, where a
randomized algorithm is used to generate hash values for
distinct ﬂows. Hence, the collision probability of diﬀerent
ﬂows hashed to the same counter is a simple function of the
number of ﬂows divided by the size of the sketch. We in-
crease counter values probabilistically, in a variation of the
approach in Morris [7]. Counters are incremented by 1 with
probability 1 if the counter value, C, is less than k (a small
constant deﬁned by the network operator). Otherwise, if
C ≥ k we increment the counter with probability 2−C+k−1.
This translates into grouping medium to large ﬂow sizes into
histogram bins Bm = [k + 2m − 1, k + 2m+1 − 1], m =
0, . . . , log2 W − 1, where W is the largest ﬂow size as de-
ﬁned by the network operator. As a result of this binning,
we only need to use tiny counters (our experiments use 7 bit
counters) as compared to other schemes, drastically lowering
memory requirements. Note that this approach is performed
Legend
counter = 0
counter > 0
index  0
index > M
Virtual sketch
Counters 1 to M
Counters M+1 to 2M
1
0
0
M counters
Physical sketch
Counters 1 to M
always win
contetions
Figure 1: Multiplexing a sketch. One extra bit is
used to store ownership in the physical sketch. Note
that counters with index ≤ M in the virtual sketch
always win contentions against counters with index
> M .
entirely in software and does not require specialized hard-
ware. In Section 3 we explain the details and also present a
practical and eﬃcient way to emulate a probabilistic counter
without resorting to (slow) pseudo-random number genera-
tors.
At each sketch update our algorithm also updates a his-
togram of the sketch values. In the estimation phase, our
estimator uses this sketch histogram to estimate the size his-
togram. It is shown in [5] that to estimate a ﬂow of size i we
need at least O(i3) operations to untangle the correspond-
ing hash collisions. This results in a prohibitively high CPU
cost with large maximum ﬂow sizes, W ≫ 1. Thus a fast
estimator depends on a small fraction of hash collisions. For-
tunately, universal hashing allows us to reduce the collision
probability by simply increasing the sketch size, giving us
the opportunity to reduce the estimator complexity.
However, a large sketch size is not desirable due to the
corresponding increase in memory requirements. We there-
fore arrive at the sketch design shown in Figure 1 where
the number of virtual sketches Z = 2. The idea is to use
a virtual sketch that physically occupies half of its virtual
size. Two virtual sketch counters share the same physical
sketch counter if both counters are zero. If one or both vir-
tual counters are not zero we use the contention resolution
algorithm described in Section 3.1.1. Our contention reso-
lution has an overhead of ⌈log Z⌉ bits per physical counter.
Let’s look at an example on contention in Figure 1. Coun-
ters with indexes M and 2M in the virtual sketch contend
for the same physical counter. Virtual counter M wins and
virtual counter 2M is evicted from the virtual sketch.
In
Section 3.1.1 we see that virtual counter eviction is equiv-
alent to ﬂow thinning. In our experiments in Section 4 at
most 15% of the ﬂows are discarded due to counter eviction.
Extra memory space could be used to store these evicted
counters if ﬂow thinning must be avoided. It is important
to note that the extra CPU overhead using this approach
when compared to a regular sketch is negligible.
Small counters with their exponential histogram bin sizes
and small hash collision probabilities allow us to propose a
O(k3 + log W ) histogram estimator. Note that k is a small
constant typically k ≪ W (in our experiments we use k = 16
and W = 1014). In what follows we detail our sketch data
structure and simple estimator.