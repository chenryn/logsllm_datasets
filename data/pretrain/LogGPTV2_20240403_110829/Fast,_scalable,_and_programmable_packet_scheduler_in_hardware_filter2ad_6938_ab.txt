rank, and supports two primitive operations atop the ordered list—
(i) enqueue(f), which inserts an element f into the ordered list, at
the position dictated by f ’s rank, and (ii) dequeue(), which extracts
the element at the head of the ordered list.
Limitations of PIFO. PIFO fundamentally provides the abstrac-
tion of a priority queue, which at any given time, schedules the
"smallest ranked" element in the entire list. [37] shows that this sim-
ple abstraction can express a wide range of scheduling algorithms
which either specify when or specify in what order to schedule each
element. However, PIFO’s abstraction is not sufficient to express a
more general class of scheduling algorithms/policies which specify
both when and in what order to schedule each element — This class
of algorithms/policies schedule the smallest ranked element, but
only from the set of elements that are eligible for scheduling at the
time, which, in principle, could be any arbitrary subset of active
elements4. Hence, they invariably require a primitive that supports
dynamically filtering a subset of elements at dequeue and then
return the smallest ranked element from that subset, something
that PIFO primitive does not support. Such complex packet sched-
uling policies are becoming more common in today’s multi-tenant
cloud networks [38], and a classic example of one such algorithm
is the Worst-case Fair Weighted Fair Queuing (WF2Q) [6]. WF2Q is
the most accurate packet fair queuing algorithm known, making
it an ideal choice for implementing fair queue scheduling policies.
Further, non-work conserving version of WF2Q can very accurately
implement shaping primitives such as rate-limiting [31].
WF2Q+5 (Fig. 2(a)) tries to schedule a packet whenever the link
is idle, which could be at any arbitrary discrete time t. However,
challenge with WF2Q+ is that the eligibility predicate of any arbi-
trary subset of elements can become true at t, as shown in Fig. 2(c),
and hence scheduling the smallest ranked eligible element at time t
becomes challenging. In Fig. 2(d) and (e), we try to express WF2Q+
using PIFO. First, we try using a single PIFO (Fig. 2(d)). It is easy to
see that this is not sufficient—if we order the PIFO by increasing
finish times, it results in wrong scheduling order if some arbitrary
element becomes eligible before the element at the head, and if we
order the PIFO by increasing start times, the right scheduling order
could still be violated if multiple elements become eligible at the
4PIFO could express a special case of such algorithms, where the smallest ranked
element in the entire list is always eligible at dequeue.
5WF2Q+ [5] is the implementation-friendly version of WF2Q [13].
369
amongst all flows f s.t. (virtual_time(t) >= f.start_time):     schedule packet from flow with smallest finish_timeEligible PacketsVirtual TimeVirtual TimeVirtual TimeScheduling OrderScheduling OrderScheduling OrderEligibility PIFORank PIFOTransmitlengthstart timeﬁnish timePacket ID(c)(d)(e)f.start_time = max(f.finish_time, virtual_time)= f.finish_timef.finish_time = f.start_time + L/rvirtual_time(t + x) = max(virtual_time(t) + x, min       # if enqueue in empty ﬂow queue # if dequeue from ﬂow queue(a)(b)# eligibility# orderingf in F(f.start_time))1A10010E250F1500C80D20105D10B100C5220505125E10150501255150101580C05A55B125A5C351080201510110802100203F55105125B1020B2010E310FD20A1050F5E31505150052F15D550105510105D10A125C5B0E100520E101501012510520125AC10150BE20B520580F531001052805015050130122E202803F10105150805125D00C20510010103C10F100325FC10055020D5205010AD1F5A125150A105080B8010050125B100E1D21515052001005501010033201B208015031010105552080D125F210D50C15050510150DF50E2055020E21055150200A5103205FB803BF10125210C805AAD2101005CE5A510100CB510505100A1C11010F5E2030202202002100EB150202100125350EB10155F2010F503D5100805051051510D01051051258051002150201105CDA35080101252010AB5FCC5E2150A3E12510055B110010205F0551AB8031020501502125DD5CEC50E520802010CDABD510205ABC8015500E2010512510F321005201051000E125F321502010A5BC801550105515B0102051501050312520F100C552A80ED105512E102010125F80205C31050A150D50100202020150CD010150B10580255100A53F125105C,D,E,FB,E,FC1520AF5ADD,E,FFB0E,F45E40Ideal AlgorithmCFEDBA2551035020BDC4050AF20ADCFB0E60E55Single PIFO ordered by increasing ﬁnish timeSingle PIFO ordered by increasing start timeDFCABEE,FFE,FC,E,F[ ][ ][ ]BB[ ]D,F,C,E,B[ ]BD54050A4520010CF200E604055Two PIFOs: (1) Eligibility PIFO - ordered by increasing start time (2) Rank PIFO - ordered by increasing ﬁnish timeVirtual TimeScheduling OrderSIGCOMM ’19, August 19–23, 2019, Beijing, China
Vishal Shrivastav
same time, and the element with the smallest finish time is not at the
head of the PIFO. A more promising approach is to use two PIFOs,
ordered by increasing start and finish times respectively, and move
elements between the two PIFOs as and when the elements become
eligible, as demonstrated in Fig. 2(e). However, this approach is also
not sufficient, precisely because an arbitrary number of elements
can become eligible at any given time, e.g., in Fig. 2, C,D,E, and F all
become eligible at t = 5, and ideally C should have been scheduled
as C has the smallest finish time amongst the eligible elements. But
since the eligibility PIFO is ordered by increasing start time, D is
released to rank PIFO before C, resulting in the wrong scheduling
order. In general, O(N) elements (N is PIFO size) could become
eligible at any given time, which in the worst-case could result in
O(N) deviation from the ideal scheduling order for an element.
Further, PIFO primitive does not allow dynamically updating
the attributes (such as rank) of an arbitrary element in the ordered
list, as required by certain scheduling algorithms, e.g., updating
the priority of an element based on it’s age to avoid starvation in a
strict-priority based scheduling algorithm.
Finally, the hardware design of the ordered list used to imple-
ment the PIFO primitive achieves very limited scalability ([37],
Fig. 8). Hence, PIFO scheduler is also not scalable. In principle, one
could use approximate datastructures, such as a multi-priority fifo
queue [1], a calendar queue [10], a timing wheel [40], or a multi-
level feedback queue [4], to implement an approximate version of
the PIFO primitive. These datastructures could approximate the
behavior of a priority queue or an ordered list in a fast and scalable
manner by using multiple FIFO queues. However, by design, they
could only express approximate versions of key packet schedul-
ing algorithms [33, 4], invariably resulting in weaker performance
guarantees [52]. Further, these datastructures also tend to have
several performance-critical configuration parameters, e.g., number
of priority levels in a multi-priority fifo queue, or size and number
of buckets in a calendar queue, which are not trivial to fine-tune.
Universal Packet Scheduling (UPS) [27]. In the same vein as
PIFO, which tries to propose a general packet scheduling primitive,
UPS tries to propose a single scheduling algorithm that can emulate
all other packet scheduling algorithms. While [27] proves that no
such algorithm exists, it also shows that the classical Least Slack
Time First (LSTF) [45] algorithm comes close to being universal.
However, just like PIFO, LSTF also uses a priority queue abstraction
at it’s core, as it always schedules the "smallest slack first", just as
PIFO would schedule the "smallest rank first". As a result, LSTF has
the same limitations as PIFO discussed above.
3 PUSH-IN-EXTRACT-OUT (PIEO)
In this section, we describe the PIEO primitive and present a pro-
gramming framework to program the PIEO scheduler.
3.1 PIEO primitive
PIEO primitive assigns each element an eligibility predicate and
a rank, both of which can be programmed based on the choice of
the scheduling algorithm, and at any given time, it schedules the
"smallest ranked eligible" element. To realize this abstraction, PIEO
maintains an ordered list of elements in the increasing order of
rank, and supports three primitive operations atop the ordered list:
370
(1) enqueue(f): This operation inserts an element f into the or-
dered list, at the position dictated by f ’s rank. This operation
realizes the "Push-In" primitive.
(2) dequeue(): This operation first filters out a subset of el-
ements from the ordered list whose eligibility predicates
are true at the time, and then dequeues the element at the
smallest index in that subset. Hence, this operation always
dequeues the "smallest ranked eligible" element. If there are
multiple eligible elements with the same smallest rank value,
then the element which was enqueued first is dequeued. If
no eligible element exists, NULL is returned. This operation
realizes the "Extract-Out" primitive.
(3) dequeue(f): This operation dequeues a specific element f
from the ordered list. If f does not exist, NULL is returned.
While the enqueue(f) and dequeue() operations are sufficient
to schedule elements according to the PIEO primitive, the addi-
tional dequeue(f) operation provides an added flexibility to asyn-
chronously extract a specific element from the list, to say, dynami-
cally update the scheduling attributes (such as rank) of the element
(and then re-enqueue using enqueue(f)), as illustrated in §4.4.
Limitations on complexity of predicate function. PIEO prim-
itive associates a custom predicate with each element, which is
evaluated at dequeue to filter a subset of elements. However, the
complexity of predicate function is limited by the practical con-
straints of a fast and scalable packet scheduler. In particular, we
want each primitive operation to execute in as few clock cycles
as possible to keep up with increasing link speeds, while encode
the predicate in as few bits as possible for scalability. Fortunately,
for most packet scheduling algorithms, the predicate usually takes
the form (tcurr ent ≥ teliдible), where t could be any monotonic
increasing function of time, and teliдible is when the element be-
comes eligible for scheduling and can be calculated at enqueue
into the ordered list (§4). This allows for a fast and parallel evalu-
ation of predicates at dequeue. Further, one only needs to encode
teliдible for each element as the predicate, thus also ensuring a
small storage footprint, important for scalability. One can poten-
tially use PIEO primitive with more complex predicate functions for
problems where constraints on time and memory are more relaxed.
3.2 PIEO programming framework
In this section, we describe a framework to program the PIEO
scheduler. PIEO assumes that each packet is stored in one of the
flow queues, and that the packets within each flow are scheduled
in a FIFO order, as discussed in §2.1. Hence, each element in the
ordered list refers to a flow, and scheduling a flow f results in the
transmission of the packet at the head of flow queue f .
The programming framework for PIEO scheduler is shown in
Fig. 3. PIEO scheduler comprises an ordered list datastructure that
implements the PIEO primitive (§3.1), and can be programmed
through the rank and predicate attributes assigned to each element.
3.2.1 Programming functions. In this section, we describe three
generic types of functions that the programmers can implement to
program the PIEO scheduler. We also describe the default behavior
of each function, which the programmers can then extend based on
the choice of the scheduling algorithm they intend to program. All
the state needed for scheduling can be stored as either per flow or
Fast, Scalable, and Programmable Packet Scheduler in Hardware
SIGCOMM ’19, August 19–23, 2019, Beijing, China
Figure 3: PIEO programming framework.
global state, and should be accessible by both the control plane and
the programming functions. The control plane can use the memory
to store control states, e.g., per-flow rate-limit value or QoS priority,
while the programming functions can use the memory to store
algorithm-specific state, e.g., virtual finish time in WFQ [13].
Pre-Enqueue and Post-Dequeue functions. Pre-Enqueue func-
tion takes as argument the flow f to be enqueued into the ordered
list, and at the very minimum, assigns f a rank and a predicate
as dictated by the choice of the scheduling algorithm being pro-
grammed. Note that while the predicate is assigned during enqueue
into the list, it is only evaluated during the process of dequeue.
Post-Dequeue function takes as argument a flow f dequeued
from the ordered list, and at the very minimum, transmits the packet
at the head of flow queue f and re-enqueues f back into the ordered
list if f ’s queue is not empty after current packet transmission.
While the Post-Dequeue function is always triggered after each
dequeue() operation on the ordered list, the Pre-Enqueue function
can be triggered in two different ways:
1. Input-triggered model: In this model, the Pre-Enqueue func-
tion is triggered whenever a packet is enqueued into a flow queue.
The behavior of the default implementation of Pre-Enqueue and
Post-Dequeue functions under this model is shown below.
pre-enqueue-func(flow f): { # default
f.curr_pkt.rank = 1
f.curr_pkt.predicate = True
if (pkt enqueue into an empty f.queue):
ordered_list.enqueue(f)
}
post-dequeue-func(flow f): { # default
send(f.queue.head)
if (f.queue not empty):
f.rank = f.queue.head.rank
f.predicate = f.queue.head.predicate
ordered_list.enqueue(f)
}
371
2. Output-triggered model: In this model, the Pre-Enqueue
function is triggered whenever a packet is dequeued from a flow
queue, or whenever a packet is enqueued into an empty flow queue.
The behavior of the default implementation of Pre-Enqueue and
Post-Dequeue functions under this model is shown below.
pre-enqueue-func(flow f): { # default
f.rank = 1
f.predicate = True
ordered_list.enqueue(f)
}
post-dequeue-func(flow f): { # default
send(f.queue.head)
if (f.queue not empty):
pre-enqueue-func(f)
}
Programmers have the flexibility to choose between the two models.
The trade-off is that while the output-triggered model can provide
more precise guarantees for certain shaping policies [37], it also
puts the Pre-Enqueue function on the critical path of scheduling,
which means the complexity of rank and predicate calculations
would affect the overall scheduling rate.
Alarm function and handler. The ability to asynchronously en-
queue and dequeue specific elements to/from the ordered list using
the enqueue(f) and dequeue(f) operations gives programmers the
ability to define custom events which could trigger a custom alarm
function that can asynchronously enqueue or dequeue a particular
flow in or out of the ordered list. Programmers can also define a
custom alarm handler function to operate upon the dequeued flow.
By default, these functions are disabled in PIEO.
async_event e = NULL # default
alarm-func(async_event e): {} # default
alarm-handler(flow f): {} # default
f6f9f3f5f4f7alarmfuncrankdequeue(f9)dequeue()ordered listenqueue(f3)alarm handlerpredpre-enqueuefuncpost-dequeuefuncPIEO scheduler001010Predicate evaluationf3 (smallest ranked eligible ﬂow)async eventf9triggered whenever the link is idleenqueue(f9)Asynchronous functionsinput-triggered pathoutput-triggered pathf3per ﬂowFIFO queuesf1f2f3fnPacketon wiref6.predf9.predf3.predf5.predf4.predf7.predSIGCOMM ’19, August 19–23, 2019, Beijing, China
Vishal Shrivastav
3.2.2
Implementing programming functions. While we present
a programming framework for the PIEO scheduler, the paper does
not focus on a specific programming language to implement the
programming functions used to program the PIEO scheduler. This
would depend upon the underlying architecture of the hardware
device. E.g., for FPGA devices, one could use languages such as
System Verilog [49], Bluespec [8], or OpenCL [46] to implement
the programming functions. In our FPGA prototype, we use Sys-
tem Verilog to implement the programming functions (§6.3). For
ASIC hardware devices with RMT [9] architecture, one could poten-
tially adapt one of the domain-specific languages for programmable
switches such as Domino [36] (used to program the PIFO sched-
uler). We leave the exploration of new programmable hardware
architectures and domain-specific languages (and compliers) for