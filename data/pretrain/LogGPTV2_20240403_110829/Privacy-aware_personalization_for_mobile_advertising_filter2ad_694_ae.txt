estimate is available (such as exercising in Central Park).
Now suppose the ad server wants to deliver ads to a user who
is currently running in Central Park of New York. Due to privacy
concerns, the user discloses to the server only that she is exercising
in New York City ˆc. The server then uses Algorithm 1 (Greedy) to
decide which ads to send to this user. For this, it uses precomputed
values of Pr[c] and (cid:91)CTR(a|c), for all c → ˆc and all ads a that are
displayed in such contexts. Finally the client device selects the best
ad based on the user’s actual context (running in Central Park).
5. EXPERIMENTS
We now empirically answer the following important questions
with a real trace: (1) How strong are the trade-offs between privacy,
efﬁciency, and utility in practice? (i.e., is it possible to achieve
reasonable levels all three design goals simultaneously?) (2) How
does our client-server joint optimization compare with client-only
669Figure 3: Hierarchy over businesses.
Figure 4: Varying the minimum CTR.
Figure 5: Varying communication cost.
or server-only personalization? and (3) How robust is our statistics
gathering algorithm with dynamic population? Before answering
the questions, we ﬁrst describe our experimental setup.
5.1 Experimental Setup
Dataset. Ideally, we would like to evaluate our algorithms with
real usage traces from a context-aware ad service. However, since
no such real systems exist, we emulate such a system by using a
trace of location-aware searches in Microsoft Bing for mobile.6
The trace has a schema: (cid:104)user-ID, query, user-location, business-
ID(cid:105). Each record in the trace describes an event of a user issuing
a query from a location and then clicking on a business. The trace
consists of 1,519,307 records. In our evaluation we focus on clicks
to “Food & Dining” businesses, which constitute the largest cate-
gory of business in the trace. We also ﬁlter out any user with fewer
than three clicks in the trace, as we cannot generate an interest pro-
ﬁle for such a user. This leaves us with 116,432 unique user-IDs.
We use the ﬁrst 90% of the trace as training data and the remain-
der to evaluate our framework and to compute targeted ads (i.e.,
businesses).
Context. We use the above trace to emulate a context-aware ad
service as follows. We assume that each business with id i has an ad
with the same id i, and hence our goal is to deliver target business-
IDs to the users. Ideally, we would like to use context based on the
sensor readings of smart phones for personalization. However, this
information is not present in our trace and we therefore limit our
evaluation to contexts consisting of the following set of attributes.
(cid:73) Location: The user’s location as latitude and longitude.
(cid:73) Interest: A multi-set of business-IDs the user clicked on before.
(cid:73) Query: The search query the user sends.
Attribute Generalization. To limit information disclosure, we let
users generalize context attributes according to ﬁxed hierarchies.
(cid:73) Location: We use ﬁve levels of generalization for user loca-
tion, depending on how many decimal points we truncate from
her latitude and longitude. More speciﬁcally, Level-i location,
0 ≤ i ≤ 5 of a user is her latitude and longitude, after keeping all,
4, 3, 2, 1, and 0 decimal points respectively.
(cid:73) Interest: We generalize user interest using a ﬁxed hierarchy for
the businesses, as shown in Figure 3.
In Level-0, Level-1,
and Level-2, the interest set contains business categories, gen-
eralized business categories, and only the most general business
category (“Food and Dining”), respectively, of the user’s clicks.
(cid:73) Query: Again, we use the business hierarchy to generalize the
query at three levels. Level-0 is the exact query issued by the
user, Level-1 is the business category of the clicked business,
and Level-2 is the generalized category of the business.
For all attributes, Level-i is more general, and hence more
privacy-preserving, than Level-j for i > j. As a short-hand,
we use (x, y, z) to denote (Level-x location, Level-y interest,
Level-z query).
6http://m.bing.com
Context Hierarchy. We combine the attribute hierarchies into
a context hierarchy. We generalize one attribute at a time using
the following sequence: (0, 0, 0) → (0, 0, 1) → (0, 1, 1) →
(1, 1, 1) → (1, 2, 1) → (2, 2, 1) → (3, 2, 1) → (3, 2, 2) →
(4, 2, 2). As an example, consider the context at level (0, 0, 0)
(cid:104)(61.22913, -149.912044), [B-ID2011, B-ID124], “Starbucks”(cid:105).
Generalizing each attribute one level yields, at level (1, 1, 1),
(cid:104)(61.2291, -149.9120), [Peruvian Restaurants, Wine], “Coffee”(cid:105).
Generalization does not just provide privacy, but also helps per-
sonalization with sparse data. For example, in our dataset there are
≈ 100,000 queries that appear only once. It is impossible to per-
sonalize search results for these queries because we have not seen
the same query before. With generalization, we reduce the number
of such queries by an order of magnitude. We address the sparsity
of other context attributes similarly. This increases the coverage.
Metrics. We use the following two metrics for our prediction.
(cid:73) Precision: The fraction of targeted ads in our framework on
which users actually click. Precision is an indicator of relevance.
(cid:73) Coverage: The fraction of contexts for which our framework
computes and displays a targeted business.
The higher the precision and coverage values, the better the per-
formance of our framework. We report average precision and cov-
erage for 1,000 random contexts from the testing data; the averages
become fairly stable after 1,000 predictions.
Parameters. Unless otherwise stated, we use the following default
conﬁguration. For limited information disclosure, we use (4, 2, 2)
generalization. We set the upper bound on communication com-
plexity, k, to be 10, the threshold on click-through rate to be 0.3,
and the threshold on support to be 2.
5.2 Evaluating Trade-offs
Effect of CTR Threshold. The CTR threshold trades off precision
and coverage, see Figure 4. For a high value of the CTR threshold,
an ad will be shown only if it is highly relevant. Thus, this increases
the precision of our algorithm and improves the relevance of the
displayed ads. On the other hand, a high threshold reduces the
number of ads displayed and with that the number of clicks and the
revenue. Interestingly, as we can see, high levels of both precision
(0.48) and coverage (0.47) can be achieved simultaneously.7
Effect of Communication Complexity. Figure 5 shows the ef-
fect of increasing the communication complexity k (i.e. having
the server return more ads to the client) on precision and cover-
age. We expect both to improve with increasing k since the client
can choose an ad from a larger set. The graph shows further that
increasing k has diminishing returns. In the beginning the preci-
sion and coverage increase quickly with every additional ad being
sent, however, as more ads are sent, the increase in precision and
coverage becomes smaller.
7Precisions and coverages close to 0.5 are considered high in pre-
dicting user clicks. Our numbers are higher than the ones reported
for other personalization techniques [46].
Food & Dining Restaurants Groceries European French Italian Mexican Cafes Cheese Vegetables … …  0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1CTR ThresholdPrecisionCoverage 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 0 20 40 60 80 100Precision/CoverageCommunication cost (k)Server-onlyPrecisionCoverage670(a) k = 10
(b) k = 50
Figure 6: Varying information disclosure.
(a) Effect of noise 
(b) Effect of robustness t
Figure 7: Differentially-private estimates.
Effect of Information Disclosure. Figure 6 shows the precision
and coverage (for various CTR thresholds) of our framework with
various levels of generalization. As expected, precision and cov-
erage of our framework increases as more speciﬁc context infor-
mation is sent to the server. Interestingly, limited privacy does not
hurt utility in a signiﬁcant way; as shown in the graph, precision
and coverage values are very close for limited privacy (shown as
(1, 1, 1)) and no privacy (shown as (0, 0, 0)).
Trading-off Constraints. To see how communication overhead
affects the performance of our framework, we increase k from 10
to 50 in Figures 6(a) and (b). The graphs show that privacy can
be improved without hurting utility by a small increase in the com-
munication cost. For example, when k = 10, a privacy level of
(4, 2, 2) does not achieve a precision of at least 0.85 and a cover-
age of at least 0.3. But it does, when increasing k to 50. Overall,
we conclude that reasonable levels of limited information disclo-
sure, efﬁciency, and relevance can be achieved simultaneously.
5.3 Comparison with Other Strategies
Server-only Personalization. Here, the server performs person-
alization based on the limited private information it has and sends
only one ad to the client. As shown in Figure 5, this strategy gives
a precision of 0.12. We can do much better with our optimization:
When instead sending 5 ads and letting the client pick the most
relevant one, the precision rises by 35%.
Client-only Personalization. Here, the client sends only the query
to the server, which then sends k ads matching the query to the
client. The client chooses the best ad based on the exact user con-
text. Precision and coverage of this strategy are also shown in Fig-
ure 6 with the label "Client-side". As shown, our optimization can
provide better utility than the client-only strategy. For example, for
a target precision of 0.75, the client-side strategy can achieve cov-
erage of 0.2, while our framework with (1, 1, 1) generalization can
achieve a coverage of 0.4, an increase of 2×.
5.4 Privacy-Preserving CTRs
In the following experiments, we ﬁx the maximum number of
contributions per user, m = 4. Moreover, we found it beneﬁcial
to limit how far TopDown goes down in the hierarchy. Such a
limit reduces the amount of noise added to each count. This is
(a) N = 10,000
(b) p = 0.0001
Figure 8: Varying user population.
important for training data as small as ours. Therefore, we chose
an aggressive limit of 1.
Efﬁciency. When we run Estimates on our trace, a user has to
send roughly 1MB on average. Many of the count queries can be
batched. On average, a user participates in two batches for all CTR
computations. We feel this communication cost is acceptable.
Accuracy. Figure 7(a) shows how precision and coverage of our
framework degrades when we increase the differential privacy guar-
antee (by decreasing ). We ﬁxed δ = 0.01. As a point of compar-
ison, the ﬁgure also draws the precision and coverage curve when
using the exact, non-private statistics ( = ∞). We can see that
to achieve a precision of 0.6, the coverage of our framework us-
ing non-private statistics is much higher than the coverage of our
framework using the -differentially private statistics (i.e., 0.3 vs
0.1). This is the price we have to pay for a privacy guarantee. The
exact value of the privacy parameter  (1 vs. 0.5) has a minor effect
on the utility. We expect the cost of privacy to decrease with a larger
user population. Moreover, we can avoid such negative impact on
utility by paying the price of privacy in terms of communication
overhead k—as shown in Figure 6, the utility can be improved by
using a higher value of k.
5.5 Robustness of Statistics Gathering
Figure 7(b) shows the effect of varying t (fraction of malicious
or unavailable users) on precision and coverage for  = 1.0. We
see that the parameter t has only a mild effect. Even when 75% of
the users could be unavailable or malicious (t = 0.75) the utility is
almost the same as when all users are available and honest.
We compare our Count protocol with three existing distributed,
differentially-private count protocols: RASTOGI [37], SHI [40],
and ÁCS [1]. Brieﬂy, RASTOGI [37] and SHI [40] start with a setup
phase in which an honest server generates secrets and distributes
them to users such that the secrets of all users add up to a constant.
After this setup phase, a series of count queries can be computed
in a privacy-preserving manner assuming that all available users
in the setup phase participate in the aggregation phase. However,
when a single user becomes unavailable, no further queries can be
answered until a new setup is performed or the user returns. Thus,
for a query to be successfully answered, the setup phase followed
by the aggregation phase must be repeated until they both run on
the same stable set of users. Recently, Ács et al. [1] proposed an
efﬁcient protocol that can tolerate failures of up to a predeﬁned
number of users before running the aggregation phase; however,
the phase must be repeated if any user fails during its execution.
We compare the robustness by modeling users’ unavailability as
a simple random process. Suppose a phase denotes the time it takes
for the server to send a message to all users or for all users to send
messages to the server. Let p denote the probability that a user is
unavailable to participate in a given phase. We measure the average
number of phases required to complete a query, as it indicates the
latency and communication complexity of a protocol.
It should be pointed out, though, that this compares only one as-
 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1PrecisionCoverageClient side(4,2,2)(1,1,1)(0,0,0) 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1CoverageClient side(4,2,2)(1,1,1)(0,0,0) 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1PrecisionCoverageε=∞ε=1.0ε=0.5 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1PrecisionCoveraget=0.00t=0.20t=0.75 1 10 100 1000 0 0.0001 0.0002Avg. # PhasesPr[unavailable] pShiRastogiACSCount 1 10 100 1000 0 5000 10000 15000 20000# of users NShiRastogiACSCount671pect of these protocols. They also widely differ in the assumptions
they make. Our protocol requires two honest-but-curious servers.
RASTOGI and SHI require an honest server for the key set-up, while
ÁCS provides privacy without any such assumptions.
Figure 8 illustrates the effects of unavailability on communica-
tion complexity. We run 1000 queries and report the average num-
ber of phases per query for different protocols. As shown, all the
protocols cost close to their optimal number of phases when the
probability of being unavailable (p) and the number of users (N)
are small. However, unlike our protocol, the costs for all three pro-
tocols increase exponentially with N and p (note the log scale of
the graphs). For p ≥ 0.0001 (corresponding to less than only 10
seconds a day) in (a) or N ≥ 1000 (much fewer than users of pop-
ular online services) in (b) the protocols become impractical. This
shows that unlike our protocol, the three protocols are impractical
for online services with dynamic users.
6. RELATED WORK
Targeted Advertising. Closest to our privacy-aware ad serving
framework are the works of [15, 22, 27]. Repriv [15] veriﬁes that
applications only access the limited information about a user that
was granted and proposes techniques for client only personaliza-
tion. Privad [22] and the work by Juels [27] anonymize user pro-
ﬁles. Neither work explains how ads should be chosen based on
limited user information by the ad server and based on more pri-
vate information on the client. Thus, there is a potential beneﬁt of
integrating our framework into these systems to trade off privacy,
efﬁciency and utility.
Location-Based Services. Several location-based services (LBS)