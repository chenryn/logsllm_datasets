79
238
(cid:63) Total number of relays at s=1%: 67; at s=10%: 652; and at s=30%: 1,948.
† E+G: Relays with both the exit and guard ﬂags ‡ Perf: Benchmark clients
smaller network scales with more accessible resource require-
ments while showing the change in conﬁdence that results
from running networks of different scales. In particular, our
study considers Tor network scales of 1%, 10%, and 30%
(s ∈ {0.01,0.1,0.3}) of the size of the true Tor network. At
each of these network scales, we study the performance ef-
fects of 100% and 120% trafﬁc load ((cid:96) ∈ {1.0,1.2}) using
a process scale factor of p = 0.01, i.e., each TGen process
simulates 1/0.01 = 100 Tor users.
Number of Simulations: Another important consideration in
our evaluation is the number n of simulations to run for each
experiment. As explained in §5, running too few simulations
will result in wider conﬁdence intervals that will limit us to
weaker conclusions. The number n of simulations that should
be run typically depends on the results and the arguments
being made, but in our case we run more than we require to
validate our hypothesis in order to demonstrate the effects of
varying n. As shown in the left part of Table 4, we run a total
of 420 simulations across our 6 experiments (three network
scales and two load factors) using two machine proﬁles: one
proﬁle included 4×8-core Intel Xeon E5-4627 CPUs running
at a max clock speed of 3.3 GHz and 1.25 TiB of RAM; the
other included 8×8-core Intel Xeon E5-4650 CPUs running
at a max clock speed of 2.7 GHz and 1.5 TiB of RAM.
Simulation Conﬁguration: We run each simulation using an
independently sampled Tor network in order to ensure that we
produce informative samples following our guidance from §5.
Each Tor network is generated following our methodology
from §3 using the parameter values described above and Tor
network state ﬁles from January 2019. The resulting network
composition for each scale s is shown in Table 5.
Each simulation was conﬁgured to run for 1 simulated hour.
The relays bootstrapped a Tor overlay network within the ﬁrst
5 minutes; all of the TGen clients and servers started their
USENIX Association
30th USENIX Security Symposium    3425
(a) 1% Network Scale (s = 0.01)
(b) 10% Network Scale (s = 0.1)
(c) 30% Network Scale (s = 0.3)
Figure 7: Time to last byte in seconds of 1 MiB downloads from performance benchmarking clients from experiments with trafﬁc load (cid:96) = 1.0
and (cid:96) = 1.2 in networks of various scale s. The results from each experiment are aggregated from n simulations following §5, and the CDFs are
plotted with tail-logarithmic y-axes in order to highlight the long tail of network performance.
trafﬁc generation process within 10 simulated minutes of the
start of each simulation. TGen streams created by Markov
clients were set to time out if no bytes were transferred in
any contiguous 5 simulated minute period (the default apache
client timeout), or if the streams were not complete within an
absolute time of 10 simulated minutes. Timeouts for streams
created by benchmarking clients were set to 15, 60, and 120
seconds for 50 KiB, 1 MiB, and 5 MiB transfers, respectively.
6.3 Results
During each simulation, we measure and collect the prop-
erties that allow us to understand our hypothesis. Ultimately,
we would like to test if increasing the trafﬁc load on the net-
work by 20% (from (cid:96) = 1.0 to (cid:96) = 1.2) will reduce client
performance. Therefore, we focus this study on client down-
load time and download error rates while noting that it will
very likely be useful to consider additional properties when
studying more complex hypotheses (see Appendix A).
For each experiment, we combine the results from the n
simulations14 following the methodology outlined in §5 and
present the estimated true cumulative distributions with the
associated CIs (as in Figure 4) at α = 95% conﬁdence. We
plot the results for varying values of n as overlapping intervals
(the CIs tighten as n increases) for instructional purposes.
Finally, we compare our results across network scales s to
highlight the effect of scale on the conﬁdence in the results.
Client Download Time: The time it takes to download a cer-
tain number of bytes through Tor (i.e., the time to ﬁrst/last
byte) allows us to assess and compare the overall performance
that a Tor client experiences. We measure download times for
the performance benchmarking clients throughout the simula-
tions. We present in Figure 7 the time to last byte for 1 MiB
ﬁle downloads, while noting that we ﬁnd similar trends for
other ﬁle download sizes as shown in the extended paper [40,
Appendix D]. The CDFs are plotted with tail-logarithmic y-
axes in order to highlight the long tail of network performance
as is typically used as an indication of usability.
14We ignore the results from the ﬁrst 20 simulated minutes of each simula-
tion to allow time for the network to bootstrap and reach a steady state.
Figure 7a shows the result of our statistical analysis from §5
when using a network scale of 1% (s = 0.01). Against our ex-
pectation, our estimates of the true CDFs (i.e., the solid lines)
indicate that the time to download 1 MiB ﬁles actually de-
creased after we increased the trafﬁc load by 20%. However,
notice the extent to which the conﬁdence intervals overlap:
for example, the width of the region of overlap of the (cid:96) = 1.0
and (cid:96) = 1.2 CIs is about 20 seconds at P90 (i.e., at x ∈ [8,28]
seconds) when n = 10, and is about 3 seconds at P90 (i.e.,
at x ∈ [16.5,19.5] seconds) when n = 100. Importantly, the
estimated true CDF for (cid:96) = 1.0 falls completely within the
CIs for (cid:96) = 1.2 and the estimated true CDF for (cid:96) = 1.2 falls
completely within the CIs for (cid:96) = 1.0, even when consider-
ing n = 100 simulations for each experiment. Therefore, it is
possible that the x position of the true CDFs could actually be
swapped compared to what is shown in Figure 7a. If we had
followed previous work and ignored the CIs, it would have
been very difﬁcult to notice this statistical possibility. Based
on these results alone, we are unable to draw conclusions
about our hypothesis at the desired conﬁdence.
Our experiments with the network scale of 10% offer more
reliable results. Figure 7b shows the extent to which the CIs
become narrower as n increases from 5 to 10 to 100. Although
there is some overlap in the (cid:96) = 1.0 and (cid:96) = 1.2 CIs at some
y  1.0, which could help us better understand
how Tor might handle growth as it becomes more popular.
Acknowledgments: We thank our shepherd, Yixin Sun, and
the anonymous reviewers for their valuable feedback. This
work has been partially supported by the Ofﬁce of Naval
Research (ONR), the Defense Advanced Research Projects
Agency (DARPA), the National Science Foundation (NSF)
under award CNS-1925497, and the National Sciences and
Engineering Research Council of Canada (NSERC) under
award CRDPJ-534381. This research was undertaken, in part,
thanks to funding from the Canada Research Chairs program.
This work beneﬁted from the use of the CrySP RIPPLE Facil-
ity at the University of Waterloo.
References
[1] A. Acquisti, R. Dingledine, and P. Syverson. On the Economics
of Anonymity. In 7th International Financial Cryptography
Conference (FC), 2003.
[2] M. AlSabah and I. Goldberg. PCTCP: Per-circuit TCP-over-
IPsec Transport for Anonymous Communication Overlay Net-
works. In ACM Conference on Computer and Communications
Security (CCS), 2013.
[3] M. AlSabah and I. Goldberg. Performance and Security Im-
provements for Tor: A Survey. ACM Computing Surveys
(CSUR), 49(2):32, 2016.