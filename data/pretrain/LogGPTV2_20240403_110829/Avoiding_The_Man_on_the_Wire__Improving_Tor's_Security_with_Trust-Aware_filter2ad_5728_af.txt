.38
.57
6
5
.01 > 7 > 7
.68
.47
.47
7
6
5
.07 > 7 > 7
.71
.48
.49
7
5
.0
.82
6
.25
.61
7
.38
.58
TABLE III: Median time to ﬁrst compromise (in days) and prob-
ability of compromise for three different client behaviors and nine
different actual adversary distributions. Data are from 10,000 simu-
lations of a client in AS 6128 running for 7 days.
Adv.
2a
4
5
Med. TTFC
min./med./max.
Med. Prob.
min./med./max.
.01 > 1 > 1
.01 > 1 > 1
.0
.01
.01
.21
.27
.59
.45
.49
.66
.66
.69
.79
Med. Frac.
min./med./max.
.0
.09
.11
.0
.1
.16
.0
.0
.13
TABLE IV: Statistics (minimum, median, and maximum) on the
median times to ﬁrst compromise (in days), compromise probability,
and fraction of paths compromised over 10,000 trials for each of 401
client locations running for one day each against a selected set of
adversaries. The clients choose paths against The Man; the actual
adversary is shown in the ﬁrst column.
Comparing Table III with Fig. 2, we see that when the
client in AS 6128 chooses paths against The Man, the use of
TAPS increases her security, compared with vanilla Tor, against
adversaries that are related to The Man even though the
client is wrong about the exact nature of the adversary. More
precisely, this is true for all of the adversary types considered
in this section other than Type 5, which is the adversary that
independently compromises each relay and virtual link and is
the only type that does not compromise the network based on
organizations and families. When the adversary is actually of
Type 5, Tables III and IV show that it is able to do quite well
against the client over many locations and client behaviors.
IX. OBTAINING AND PROPAGATING TRUST
We consider as an example how much data must be stored
and communicated to implement The Man policy. First, the
client must be able to determine the cluster of itself and
its destinations. With 46368 ASes in the network map used
for TAPS analysis, 200 client clusters, and 200 destination
clusters, 182 KiB sufﬁce for each client to determine the
needed clusters. Second, to choose guards and exits, the client
needs the ability to determine the AS and IXP organizations
on any virtual link either between their cluster representative
and a guard or between a destination-cluster representative
and an exit. There are only 359 IXPs, and so an AS or IXP
organizations can be speciﬁed in two bytes. For data gathered
December 2013, all guards are within 603 ASes, all exits are
within 962 ASes, and the average number of AS and IXP
organizations on a virtual link is 4.05. Thus a list of the
entities on all the relevant virtual links for a given client is
would be 1.68 MiB. Routing changes could be propagated
daily or weekly with much smaller updates once the full data
is obtained.
X. RELATED WORK
An early proposals to use trust for Tor routing came from
Øverlier and Syverson [30], who suggest choosing guards
14
“based on trust in the node administrator”. However, they do
not develop this idea. A mathematical notion of trust in Tor
was introduced by Johnson and Syverson [20]. They formalize
trust as the probability of compromise of a relay, and they
provide an analysis of end-to-end correlation attacks when
there are just two different levels of trust. This model was
later used by Johnson et al. [21] to produce a “downhill” Tor
path-selection algorithm that can handle arbitrary trust levels at
the relays and is designed to prevent trafﬁc-correlation attacks.
Jaggard et al. [16] greatly expand this probabilistic notion of
trust by describing how to identify compromise factors that
can apply to the links as well as the nodes, such as AS
organizations, legal jurisdictions, and router software. They
focus on expressing such rich trust models, while in this paper
we focus on using these models in a path-selection algorithm
that improves security.
Another approach to trust for anonymous communication
is to explicitly leverage social network relations. Danezis et
al. [11] describe this for interactive but low-volume anonymous
communication. Concentrating on low-volume applications
allowed them to make use of padding, which is generally too
expensive and too ineffective for some of the more popular
applications that use Tor. Mittal et al. [26] describe a social-
network onion-routing architecture designed for Web browsing
and other interactive communications that adds resistance to
an active adversary. This design uses potentially much longer
paths than Tor’s three hops to achieve intended security, and
performance may suffer signiﬁcantly as a result of this and
other features of the design.
The threat of AS adversaries to Tor was ﬁrst recognized
by Feamster and Dingledine [14]. Their analysis shows that
entry and exit paths through the network are likely to be
simultaneously observed by a single AS 10% to 30% of the
time, depending on the locations of the client and destination.
They suggest that clients choose entry and exit nodes to avoid
traversing the same AS upon entry and exit. Edman and
Syverson [12] update this work and show that, despite the
growth of the network from about 30 to about 1300 relays, the
risk of denanonymization by a single AS is not reduced. They
also show how to efﬁciently implement the AS-aware path
selection suggested by Feamster and Dingledine by providing
clients with routing data that enables them to infer AS-level
routing paths. Murdoch and Zieli´nski [28] introduce IXPs as
a potential adversary. They show that an IXP can correlate
trafﬁc even at
low rates of sampling. Link adversaries at
both ASes and IXPs were extended by Johnson et al. [22]
to consider adversaries controlling multiple ASes or IXPs,
such as companies that own many IXPs. Akhoondi et al. [6]
present an alternate method for clients to efﬁciently infer the
ASes between hosts for purposes of choosing Tor paths that
avoid allowing the same AS to observe entry and exit trafﬁc.
Juen [23] presents another method for this purpose, this time
with the addition of inferring IXPs on those paths. All of the
preceding suggestions for AS-aware tor path selection neglect
key details, such as how circuits are reused and how to handle
destinations with no path that avoids putting an AS on both
sides. In addition, Juen et al. [24] show that methods of
AS inference for detecting Tor paths vulnerable to AS-level
compromise suffer from signiﬁcant false-positives and false-
negatives when compared to direct traceroute measurements.
Nithyanand et al. [29] present Astoria, which is the ﬁrst
reasonably-complete network-aware Tor path-selection algo-
rithm. As described in Section II, like other previous work on
network-aware path selection, Astoria is only secure when each
connection is analyzed independently. DeNASA [8], by Barton
and Wright, is another recent and fully-speciﬁed network-
aware Tor path-selection algorithm. DeNASA only considers
as adversaries individual ASes, and chooses to just protect
against the eight ASes that are most likely to be in a position to
deanonymize a connection. DeNASA also doesn’t consider the
speciﬁc destination when constructing a circuit, which allows
it to use pre-built circuits for speed but makes it unable to
protect connections to destinations with paths dissimilar from
the pre-selected set used for exit selection. However, DeNASA
is still vulnerable to leakage about a client’s AS across repeated
connections (assuming its guard and exit-selection algorithms
are jointly used).
Sun et al. [34] show that trafﬁc correlation attacks on Tor
are effective even when the attacker observes paths in different
directions on the entry and exit sides. They also demonstrate
the application of BGP hijacking and interception attacks to
redirect Tor trafﬁc to malicious ASes in order to deanonymize
users. Tan et al. [35] extend this analysis and show that 90%
of Tor’s bandwidth is vulnerable to BGP hijacking, and they
propose as a defense a set of monitors to detect routing attacks
and notify Tor clients to avoid the affected relays.
XI. CONCLUSION
In this paper, we show how previous network-aware Tor
path-selection algorithms are vulnerable to attacks across
multiple Tor connections. We present TAPS, a path-selection
algorithm for Tor that is not vulnerable to such attacks and that
enables clients to avoid trafﬁc-correlation attacks by using trust
that they have in network elements. We present two global-
adversary models, analyze the security and performance of
TAPS against these adversaries, and consider both trust errors
and trust propagation.
Acknowledgments. We thank Ryan Wails for contributing to
the results in Section II. The work at NRL was supported by
ONR. Joan Feigenbaum’s research was supported in part by
NSF grants CNS-1407454 and CNS-1409599, DHS contract
FA8750-16-2-0034, and William and Flora Hewlett Foundation
grant 2016-3834.
REFERENCES
[1]
[2]
[3]
“Shadow Git Repository,” https://github.com/shadow/shadow.
“Shadow Homepage,” http://shadow.github.io/.
“Shadow Tor plug-in Git Repository,” https://github.com/shadow/
shadow-plugin-tor.
“Tor Metrics Portal,” http://metrics.torproject.org/.
“TorPerf,” https://gitweb.torproject.org/torperf.git/.
[4]
[5]
[6] M. Akhoondi, C. Yu, and H. V. Madhyastha, “LASTor: A low-latency
AS-aware Tor client,” in IEEE Symposium on Security & Privacy, 2012.
[7] B. Augustin, B. Krishnamurthy, and W. Willinger, “IXPs: Mapped?” in
Internet Measurement Conference, 2009.
[8] A. Barton and M. Wright, “DeNASA: Destination-naive as-awareness
in anonymous communications,” Proceedings on Privacy Enhancing
Technologies, 2016.
[9] X. Cai, J. Heidemann, B. Krishnamurthy, and W. Willinger, “An
organization-level view of the Internet and its implications (extended),”
USC/ISI, Tech. Rep. ISI-TR-2009-679, 2012.
“The CAIDA UCSD Internet Topology Data Kit - December 2013,”
http://www.caida.org/data/internet-topology-data-kit.
[11] G. Danezis, C. Diaz, C. Troncoso, and B. Laurie, “Drac: An architecture
for anonymous low-volume communications,” in Privacy Enhancing
Technologies Symposium, 2010.
[10]
15
[12] M. Edman and P. Syverson, “AS-awareness in Tor path selection,” in
ACM Conference on Computer and Communications Security, 2009.
[13] N. S. Evans, R. Dingledine, and C. Grothoff, “A practical congestion
attack on Tor using long paths,” in USENIX Security Symposium, 2009.
[14] N. Feamster and R. Dingledine, “Location diversity in anonymity
networks,” in Workshop on Privacy in the Electronic Society, 2004.
J. Geddes, R. Jansen, and N. Hopper, “How low can you go: Balancing
performance with anonymity in Tor,” in Privacy Enhancing Technolo-
gies Symposium, 2013.
[15]
[16] A. D. Jaggard, A. Johnson, S. Cortes, P. Syverson, and J. Feigenbaum,
“20,000 in league under the sea: Anonymous communication, trust,
MLATs, and undersea cables,” Proceedings on Privacy Enhancing
Technologies, 2015.
[17] R. Jansen, J. Geddes, C. Wacek, M. Sherr, and P. Syverson, “Never been
KIST: Tor’s congestion management blossoms with kernel-informed
socket transport,” in USENIX Security Symposium, 2014.
[18] R. Jansen and N. Hopper, “Shadow: Running Tor in a box for accu-
rate and efﬁcient experimentation,” in Network & Distributed System
Security Symposium, 2012.
[19] A.
Johnson, R.
Jansen, A. D.
and
P. Syverson, “Avoiding the man on the wire:
Improving tor’s
security with trust-aware path selection.” [Online]. Available: http:
//arxiv.org/abs/1511.05453
J. Feigenbaum,
Jaggard,
[20] A. Johnson and P. Syverson, “More anonymous onion routing through
trust,” in IEEE Computer Security Foundations Symposium, 2009.
[23]
[21] A. Johnson, P. Syverson, R. Dingledine, and N. Mathewson, “Trust-
based anonymous communication: Adversary models and routing al-
gorithms,” in ACM Conference on Computer and Communications
Security, 2011.
[22] A. Johnson, C. Wacek, R. Jansen, M. Sherr, and P. Syverson, “Users
get routed: Trafﬁc correlation on Tor by realistic adversaries,” in ACM
Conference on Computer and Communications Security, 2013.
J. Juen, “Protecting anonymity in the presence of autonomous system
and internet exchange level adversaries,” Master’s thesis, University of
Illinois at Urbana-Champaign, 2012.
J. Juen, A. Johnson, A. Das, N. Borisov, and M. Caesar, “Defending
tor from network adversaries: A case study of network path prediction,”
Proceedings on Privacy Enhancing Technologies, 2015.
[25] P. Mittal, A. Khurshid,
Juen, M. Caesar, and N. Borisov,
“Stealthy trafﬁc analysis of low-latency anonymous communication
using throughput ﬁngerprinting,” in ACM Conference on Computer and
Communications Security, 2011.
[26] P. Mittal, M. Wright, and N. Borisov, “Pisces: Anonymous communica-
tion using social networks,” in Network & Distributed System Security
Symposium, 2013.
[27] S. J. Murdoch and G. Danezis, “Low-cost trafﬁc analysis of Tor,” in
[24]
J.
IEEE Symposium on Security & Privacy, 2005.
[28] S. J. Murdoch and P. Zieli´nski, “Sampled trafﬁc analysis by Internet-
exchange-level adversaries,” in Privacy Enhancing Technologies Sym-
posium, 2007.
[29] R. Nithyanand, O. Starov, P. Gill, A. Zair, and M. Schapira, “Mea-
suring and mitigating AS-level adversaries against Tor,” in Network &
Distributed System Security Symposium, 2016.
[30] L. Øverlier and P. Syverson, “Locating hidden servers,” in IEEE
Symposium on Security & Privacy, 2006.
[32]
[31] H.-S. Park and C.-H. Jun, “A simple and fast algorithm for K-medoids
clustering,” Expert Systems with Applications, vol. 36, no. 2, 2009.
J. Qiu and L. Gao, “AS path inference by exploiting known AS paths,”
in IEEE GLOBECOM, 2005.
[33]
“University of Oregon route views project,” http://www.routeviews.org/.
[34] Y. Sun, A. Edmundson, L. Vanbever, O. Li, J. Rexford, M. Chiang, and
P. Mittal, “RAPTOR: Routing attacks on privacy in Tor,” in USENIX
Security Symposium, 2015.
[35] H. Tan, M. Sherr, and W. Zhou, “Data-plane Defenses against Routing
Attacks on Tor,” Proceedings on Privacy Enhancing Technologies,
2016.
“Tor directory protocol,” https://gitweb.torproject.org/torspec.git/blob/
HEAD:/dir-spec.txt.
[37] T. Wang and I. Goldberg, “Improved website ﬁngerprinting on Tor,” in
[36]
Workshop on Privacy in the Electronic Society, 2013.