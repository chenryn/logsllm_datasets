critical entities of the system are formalized. The auditing model (L) is necessary
for the model because almost all IDSs are based on the analysis of the audit
trails from operating systems, applications and network components. Detection
rules (R) vary dependent on the IDS. In SHIM, detection rules are speciﬁcations
of normal behaviors of privileged programs. Security Requirements (SR) deﬁne
properties that should be satisﬁed to guarantee the security of the system. As-
sumptions (H) are necessary for the veriﬁcation. Security properties that we are
not sure of and more important, properties that cannot be eﬃciently monitored
will be declared as assumptions (e.g, kernel of the system is not subject to at-
tack). Note that all of our assumptions could be checked by monitoring but at
a substantial performance penalty to the IDS.
V erif ication
S ∪ L ∪ H ∪ R → SR
Security requirements (SR)
Detection rules (R)
Assumptions (H)
Auditing model (L)
Abstract system model (S)
Fig. 1. Veriﬁcation Hierachy
3.2 Formalization of the Model
In this section, we describe how to construct the components of the framework.
We start with the abstract system model.
Formal Reasoning About Intrusion Detection Systems
283
The abstract system model plays an important role in the framework. It pro-
vides a general basis to formalize security requirements, detection rules of IDSs
and assumptions, and makes it possible to verify security properties of detection
rules. To develop a simpliﬁed abstract model, we only formalize security-critical
parts of UNIX-like systems. The model can be deﬁned as a tuple (F, U, E, P,
S ) where F describes a ﬁle system, U shows user and group mechanisms, E
corresponds to environment variables, P describes a list of processes, and S de-
scribes system call interfaces of the kernel. Our preliminary experiment focuses
on the access control mechanism, so we deﬁne access permissions of ﬁle objects
and privileges of subjects.
Because of the importance of the auditing component in IDSs, we formalize
it separately from the abstract system model. We model the auditing component
at the system call level. Assume Σ is a set of all system calls, let B ⊆ Σ
∗ be all
sequences of operations of a program A. A trace b ∈ B presents a sequence of
operations of A. For each operation of a program, we use a tuple (p, f, c, n) to
indicate that a process p invokes a system call c on object f and assigns a new
property n to f (e.g. a new owner for a ﬁle).
Detection rules vary according to diﬀerent IDSs. In a speciﬁcation-based IDS,
detection rules are speciﬁcations which are used to describe normal behaviors
of systems. Conversely, in a signature-based IDS, detection rules are signatures
that identify diﬀerent attacks. In this paper, we focus on the speciﬁcation-based
approach. Suppose the set of all possible behaviors of a program is deﬁned as B,
a speciﬁcation spec() can identify a set of valid behaviors VB where VB ⊆ B
and for any trace b ∈ VB, iﬀ spec(b) = true.
Security requirements are used to describe properties necessary to satisfy
the security of the system. There are basically two ways to present the security
requirements: one is to deﬁne security policies, the other is to describe attack
scenarios. Security policies can map the behavior of a system into two states:
authorized or unauthorized. In this way, a security policy security-policy() sep-
arates the behavior of a system into an authorized behavior set AB and an
unauthorized behavior set UB where AB ⊆ B, UB ⊆ B. For any trace b, b ∈
AB iﬀ security-policy(b) = “authorized”. Attacks are behaviors that violate the
security policy. We can use functions to deﬁne characterizations of attacks. An
attack function attack() can deﬁne a set of dangerous behaviors DB where DB
⊆ B and for any trace b, b ∈ DB iﬀ attack(b)=true.
In the veriﬁcation, we try to answer two questions: Can some security policies
be satisﬁed by IDSs? And can some attacks remain undetected by IDSs? The ﬁrst
question can be formalized as follows. Given speciﬁcation s and security policy
p, is the valid behavior set VB that is deﬁned by s a subset of the “authorized”
behavior set AB deﬁned by p. We describe this relation as VB ⊆ AB or for any
trace b, spec( b) = true implies security-policy(b)=“authorized”. In some cases,
assumptions are introduced in proving whether a security policy is satisﬁed by
a speciﬁcation. The veriﬁcation can be described as: for any trace
b ∈ B, (assumption(b) = true) ∧ (spec(b) = true) (cid:6) (sr(b)=“authorized”).
284
Tao Song et al.
The second question can be formalized as follows. Given an attack ab or a
set of attacks DB, is ab a member of the valid behavior set VB or does DB share
elements with VB. It can be described as ab /∈ VB or DB ∩ VB = φ.
AB
VB
DB
VB
(1) VB ⊆ AB
security policy is satisﬁed
AB
(2) ab /∈ VB and DB ∩ VB = φ.
attacks are detected
Fig. 2. Relationship among security policy, speciﬁcations and attacks
3.3 Mechanization of the Model
ACL2 is used in the mechanization of the framework. Structures and functions in
ACL2 are used to formalize declarative components of the framework, including
an abstract system model, audit data, detection rules of IDSs, assumptions, and
security requirements. To perform the veriﬁcations we deﬁne the appropriate
theorems in ACL2 and prove them using mathematical induction and the other
proof mechanism of ACL2.
Introduction of ACL2. ACL2 is a signiﬁcant extension of Nqthm [1], intended
for large scale veriﬁcation projects. The ACL2 system consists of a programming
language based on Common Lisp, a logic of total recursive functions, and a
mechanical theorem prover [15]. The syntax of ACL2 is that of Common Lisp. In
addition, ACL2 supports the macro facility of Common Lisp. The following data
types are axiomatized: rational and complex numbers, character objects, strings,
symbols and lists. Common Lisp functions on these data types are axiomatized or
deﬁned as functions or macros in ACL2 [9]. Several functions that are used in our
veriﬁcation are listed in table 1. The ACL2 logic is a ﬁrst order logic of recursive
functions providing mathematical induction on the ordinals up to 0 and two
extension principles: one for recursive deﬁnition and one for the constrained
introduction of new function symbols. Each preserves the consistency of the
extended logic.
The ACL2 theorem prover has powerful and eﬀective heuristics controlling
the application of the following proof techniques: preprocessing including tautol-
ogy checking using ordered binary decision diagrams(OBDDs) under user direc-
tion; simpliﬁcation by primitive type checking and rewriting; destructor elimina-
tion; cross-fertilization using equivalence reasoning; generalization; elimination
of irrelevant hypotheses; and mathematical induction.
Formal Reasoning About Intrusion Detection Systems
285
Table 1. Important functions of ACL2
Functions
Descriptions
The empty list or False in Boolean contexts
True
If x not equal to nil, return y, otherwise z
If x and y have the same value, return t, otherwise nil
“And”operation in Boolean contexts
First element of list l
All but the ﬁrst element of list l
Nil
T
(if x y z)
(equal x y)
(and x y)
(car l)
(cdr l)
(consp x l ) Add x onto the front of list l
(implies x y) If x is nil or y is t, return t; otherwise return f
Abstract System Model. The abstract system model is formalized as a struc-
ture sys in ACL2. Security-critical components are deﬁned as ﬁelds of the struc-
ture. For each ﬁeld, asserts are deﬁned to check the integrity of values of the
ﬁelds. A predicate sys-p is deﬁned to recognize values that have the required
structural form and whose ﬁelds satisfy the assertions. The predicate weak-sys-p
is deﬁned to recognize values that have the required structural form, but does
not require the ﬁeld assertions to be satisﬁed. Functions are deﬁned to get, put
or check values from speciﬁc ﬁelds. In our veriﬁcation, we can use instances of
the structure to tell whether a statement is true in a system with speciﬁc set-
tings. On the other hand, the system model can appear in a theorem without
speciﬁc values to indicate a general condition in which the statement is held.
(defstructure sys
(proglist (:assert (and (not (endp proglist))(proglistp proglist))))
;list of programs, e.g. privileged programs
(calllist (:assert (and (not (endp calllist))(calllistp calllist))))
;list of system calls, e.g. open, read, write etc.
(filelist (:assert (and (not (endp filelist))(filelistp filelist))))
;list of files, e.g. /etc/passwd file
(userlist (:assert (and (not (endp userlist))(userlistp userlist))))
;list of system users
(envlist (:assert (and (not (endp envlist))(envlistp envlist)))))
;list of environment variables, e.g. home directories in a UNIX system
Audit Trail. The auditing capability of a system is formalized as a list of
audit records and an audit record is formalized as a structure logrec in ACL2.
We reference Sun Solaris BSM audit subsystem and simplify the audit record
structure to four ﬁelds: process, ﬁle object, system call and new properties to
the ﬁle object.
(defstructure logrec
(pobj (:assert (and (consp pobj)(proc-obj-p pobj))))
;object of the process
(fobj (:assert (and (consp fobj)(file-obj-p fobj))))
;object of the target file
286
Tao Song et al.
(callobj (:assert (and (consp callobj)(syscall-obj-p callobj))))
;object of the system call
(newattrobj (:assert (newattr-obj-p newattrobj))))
;new properties of the target file
Security Requirements. In our veriﬁcation, diﬀerent classes of attacks and
security policies are formalized to analyze detection rules of IDSs.
There are two ways to verify whether an attack can be detected by a speciﬁc
IDS. The ﬁrst method is to formalize possible audit trails, which include the
attack scenarios, and then analyze the audit data according to the speciﬁcation
of the program for the violation. Such veriﬁcation can be used to prove the ca-
pabilities of the speciﬁcations to detect known attacks. A more general way is
to describe the security property that will be violated by the attacks instead of
particular audit trails. Then we develop a proof based on the property that the
formalized speciﬁcations will always result in the system being monitored for
that property. For example, in an ftp-write attack, an attacker takes advantage
of a normal anonymous ftp misconﬁguration. If the ftp directory and its subdi-
rectories are owned by the ftp account or in the same group as the ftp account,
the attacker will be able to add ﬁles (such as the .rhosts ﬁle) and eventually gain
local access to the system.
Security policies are also formalized to allow reasoning about the security
properties of speciﬁcations. Trusted ﬁle access policies are security policies that
we developed to keep trusted ﬁles from unauthorized access. In UNIX systems,
a discretionary access control(DAC) mechanism deﬁnes whether a subject can
access an object or not depending on the privilege of the subject and the access
permission of the object. Some ﬁles are intended to be accessed by speciﬁc users
or using speciﬁc programs. For example, the passwd ﬁle of a UNIX system should
be editable by root using any program or by an ordinary user using the passwd
program. Thus, ﬁle access policies are deﬁned in our format as: (trusted ﬁle,
authorized user, program, access) where trusted ﬁle is the ﬁle to be protected,
authorized user deﬁnes the user that can access the ﬁle with any programs and
program deﬁnes the program that can be used by other users to access the ﬁle.
As an example, the passwd ﬁle access policy is deﬁned as: (/etc/passwd,
root, passwd, (open-wr,create, chmod, chown, rename)). This policy is used in
the veriﬁcations of the next section. The policy is formalized as a function in
ACL2.
Assumptions. Our veriﬁcatio methodology rests on assumptions. A system