User: 使用Python编写一个脚本，定期备份服务器上的数据库并将备份文件上传到云端存储。
Assistant: 以下是Python脚本的示例代码，该脚本可定期备份数据库并将备份文件上传到云端存储（例子中使用了Amazon S3云存储服务）。可以使用crontab在Linux系统上将此脚本设置为定期自动执行。

```python
import os
import time
import boto3
import pymysql

# 数据库连接信息和备份文件路径
database_host = "localhost"
database_user = "root"
database_password = "password"
database_name = "dbname"
backup_path = "/backup"

# S3云存储信息
s3_access_key_id = "YOUR_ACCESS_KEY_ID"
s3_secret_access_key = "YOUR_SECRET_ACCESS_KEY"
s3_bucket_name = "YOUR_S3_BUCKET_NAME"

# 当前时间作为备份文件名
timestamp = time.strftime('%Y%m%d-%H%M%S')
backup_file_name = "backup-{}.sql".format(timestamp)

# 连接数据库，执行备份
db = pymysql.connect(database_host, database_user, database_password, database_name)
cursor = db.cursor()
cursor.execute("SET NAMES utf8mb4")
cursor.execute("SET CHARACTER SET utf8mb4")
cursor.execute("SET character_set_connection=utf8mb4")
sql = "mysqldump --set-gtid-purged=OFF -h %s -u %s -p%s %s > %s/%s" % (database_host, database_user, database_password, database_name, backup_path, backup_file_name)
os.system(sql)

# 链接S3，上传备份文件到S3
s3 = boto3.client("s3", aws_access_key_id = s3_access_key_id, aws_secret_access_key = s3_secret_access_key)
s3.upload_file("{}/{}".format(backup_path, backup_file_name), s3_bucket_name, backup_file_name)
```