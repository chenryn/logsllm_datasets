title:Large-Scale Privacy-Preserving Mapping of Human Genomic Sequences
on Hybrid Clouds
author:Yangyi Chen and
Bo Peng and
XiaoFeng Wang and
Haixu Tang
Large-Scale Privacy-Preserving Mapping of Human Genomic Sequences on
Hybrid Clouds
Yangyi Chen, Bo Peng, XiaoFeng Wang, Haixu Tang
School of Informatics and Computing
Indiana University Bloomington, IN, USA
{yangchen, pengbo, xw7, hatang}@indiana.edu
Abstract
An operation preceding most human DNA analyses is
read mapping, which aligns millions of short sequences
(called reads) to a reference genome. This step involves
an enormous amount of computation (evaluating edit dis-
tances for millions upon billions of sequence pairs) and thus
needs to be outsourced to low-cost commercial clouds. This
asks for scalable techniques to protect sensitive DNA in-
formation, a demand that cannot be met by any existing
techniques (e.g., homomorphic encryption, secure multi-
party computation).
In this paper, we report a new step
towards secure and scalable read mapping on the hybrid
cloud, which includes both the public commercial cloud and
the private cloud within an organization. Inspired by the
famous “seed-and-extend” method, our approach strategi-
cally splits a mapping task: the public cloud seeks exact
matches between the keyed hash values of short read sub-
strings (called seeds) and those of reference sequences to
roughly position reads on the genome; the private cloud ex-
tends the seeds from these positions to ﬁnd right alignments.
Our novel seed-combination technique further moves most
workload of this task to the public cloud. The new approach
is found to work effectively against known inference attacks,
and also easily scale to millions of reads.
1
Introduction
The rapid advance of human genomics technologies has
not only revolutionized life science but also profoundly im-
pacted the development of computing technologies. At the
core of this scientiﬁc revolution is the emergence of the
high-throughput Next Generation Sequencing (NGS) tech-
nologies: today, a single sequencer can generate millions of
short DNA sequences (called reads) with 35 to 250 base-
pairs (bp) long over one billion nucleotides [40]. To in-
terpret these sequences, the most important step is to align
them to a public human DNA sequence (called reference
genome) to identify their genetic positions and other fea-
tures, e.g., whether they belong to human or human mi-
crobes. This operation, known as read mapping, is a pre-
requisite for most DNA sequence analyses [54] (e.g., SNP
discovery, genotyping, personal genomics, etc. [49]).
It
is also a step involving intensive computation, given the
huge size of the reference genome - 6 billion nucleotides,
and the complexity of the mapping operation - calculating
edit distances between reads and all the substrings on the
reference genome. With the fast-growing sequence data
produced by NGS, the demands for mapping such data
are increasingly hard to be met by the computing power
within organizations [52]. A trend widely believed to be
inevitable is outsourcing this computation to low-cost com-
mercial clouds [52]. For example, Amazon Elastic Com-
pute Cloud (EC2) provides different types of computing
instances at a price as low as 0.015 dollar per hour [2].
This development, however, brings in privacy risks: on
the one hand, NGS reads can be used to identify sequence
donors [39], a serious privacy threat that can lead to denying
their access to health/life/disability insurance and educa-
tional/employment opportunities; on the other hand, today’s
cloud providers do not offer high security assurance and
tend to avoid any liability [3]. To protect donors and avoid
legal troubles, the NIH so far disallows any datasets involv-
ing human DNA to be handed over to the public cloud.
Secure computation outsourcing. Addressing this urgent
demand requires the techniques capable of sustaining large-
scale secure computation outsourcing. Unfortunately, none
of the existing approaches are designed for the computa-
tion of such an enormous scale. Particularly, homomorphic
encryption, secret sharing and secure multi-party computa-
tion (SMC) are far too heavyweight to handle read mapping.
For example, a privacy-preserving protocol [17] takes about
5 minutes to calculate the edit distance between two 25-
element sequences through homomorphic encryption and
oblivious transfers. Such a task can be computed much
more efﬁciently by SMC techniques, thanks to the recent
progress in this area [33, 35]. However, even the state-of-
the-art SMC implementation needs about 4 seconds to pro-
cess two 100-element sequences [33]. Also, secret-sharing
based approaches [17,18] all incur data exchanges between
share holders when aligning a single sequence pair. Given
that a mapping task routinely evaluates the edit distances
for 1015 sequence pairs, all these approaches are simply not
up to this job. Alternatively, one may consider anonymiz-
ing the sequence data by aggregating the reads from mul-
tiple individuals or adding noise. These approaches are
known to be vulnerable to statistical re-identiﬁcation at-
tacks [32, 34, 46, 56], a threat that prompted the NIH to re-
move all aggregated DNA data [12] from the public domain.
Special features of the problem. We feel that existing
generic approaches all fail to appreciate the special features
of the problem, which can be leveraged to build a practical
solution. Actually, the edit distance considered in read map-
ping is small, typically no more than 6 for standard 100-bp
reads [29]. This is because human genetic variation is be-
lieved to be small, below 0.5%. In practice, the differences
between a read and its counterpart on the reference genome
mainly come from sequencing errors, whose rate is typi-
cally 2-3%. Therefore, a privacy-preserving technique that
works on small edit distances (caused by the variations and
the errors) should be enough for handling most sequence-
analysis tasks.
The cloud also has distinctive features. It is extremely
good at performing simple operations over a large amount
of data, as evidenced by the pervasiveness of MapReduce-
based computing services [23]. Also interesting is the way
that commercial clouds are used in practice:
they often
serve as a receiving end of the computation “spill-over”
from an organization’s internal system when its comput-
ing resources are about to deplete. This way of computing,
which involves both the private cloud within an organiza-
tion and the public commercial cloud, is called hybrid cloud
computing [26]. The hybrid cloud has already been adopted
by most organizational cloud users and is still undergoing
rapid development. It also presents a new opportunity that
makes practical, secure outsourcing of computation tasks to
untrusted environments possible: for example, we can split
a task, delegating to a commercial cloud a large amount of
relatively simple computation over encrypted data, like ex-
act string matching, while letting the user’s private cloud
work on a small amount of relatively complicated computa-
tion such as calculating edit distances.
Our approach. Given that read mapping is one of the
most important and pervasive operations in DNA sequence
analysis [54], we believe that a special solution is justiﬁed
here to enable secure and practical outsourcing of this com-
putation to the low-cost commercial cloud. In this paper,
we show how the aforementioned features can be used to
serve this purpose. Our idea is based upon the observa-
tion that the edit distance of two sequences can actually be
evaluated by checking the exact matches between some of
their substrings, an operation easy to secure on the pub-
lic cloud, when all we care about is whether the distance
is below a small threshold. This is described by the well-
known seed-and-extend strategy [19], which ﬁrst matches a
seed, a segment of a read with one-(d + 1)th of the read’s
length given an edit distance d, to the substrings on the ref-
erence genome1, and then extends from these substrings to
align the whole read. Our approach splits the mapping task
along these two stages, delegating them to public and pri-
vate clouds respectively: the public cloud searches for the
exact matches between the keyed hash values of seeds and
those of substrings (called l-mers for a substring of length
l) on the reference genome to determine the possible posi-
tions of reads, while the private cloud extends from these
positions to ﬁnd the right alignments of these reads (which
involves calculating edit distances under a threshold [28]).
However, this simple approach cannot guarantee to of-
ﬂoad most of the mapping workload to the public cloud.
This is because the traditional seed-and-extend approach
used in computational genomics [38] has always consid-
ered the situation when seeding and extension happen on the
same system: there has never been a need to move the work-
load from one stage to the other. Particularly, when seeds
are too short, due to a relatively large edit distance (e.g.,
6 for 100-bp reads), they randomly match a large number
of genetic locations on the reference genome. As a result,
a lot of extensions have to be done on the private cloud.
In our research, we come up with a novel solution, which
transforms the computation workload of the private cloud
to the spatial cost for the public cloud. More speciﬁcally,
our approach uses seed combinations to ensure that only a
relatively small number of extensions happen to each read.
We conducted a security analysis of our technique over
the reference genome, particularly on the threat of fre-
quency analysis. This risk is found to be minimum by our
experimental analysis over the whole genome, due to the
special structure of human genome: most of its l-mers be-
come unique when l grows over 20. Our performance eval-
uation on a cross-the-country cloud testbed with real human
microbiome data indicates that the technique is sufﬁciently
practical for real-world use: it mapped 10 million reads to
the whole reference genome in a few hours, outsourced over
97% of the workload to the public cloud and maintained an
acceptable level of overall computational, communication
and spatial overheads.
Contributions. Here we summarize the contributions of
the paper:
• Practical privacy-preserving mapping technique. We
1At least one seed will match a substring on the region within d edits
from the read.
propose a new technique that makes an important step to-
wards secure and scalable DNA sequence mapping. Run-
ning on the hybrid-cloud platform, our approach works ef-
fectively against inference attacks and has the capacity to
process millions of reads with most of the workload being
outsourced to the public cloud. This opens the great po-
tential to use the cheap computing resources of the com-
mercial cloud to meet the urgent demand of analyzing a
large amount of NGS data. Although the technique was de-
signed for read mapping, lessons drawn from this study can
have broader implications: the idea like combining light-
weight cryptography/aggregation and transforming com-
plicated computation to easy-to-protect but data intensive
computation for the cloud could ﬁnd other applications in
the domains that need practical privacy protection.
• Implementation and evaluation. We implemented our
technique over Hadoop, and evaluated the privacy and the
performance of our prototype using real human microbiome
data, on a large-scale, across-the-country cloud testbed.
The focus of our research is conﬁdentiality, as it is the
main hurdle to outsourcing read-mapping computation to
the public cloud and therefore urgently needs practical so-
lutions. Although integrity of cloud computing is no doubt
important, so far people are willing to live with the risk that
their tasks may not be handled correctly by the cloud. This
is evidenced by the fact that mapping of non-human reads
already happened on EC2 [47], while the tasks involving
human data are not allowed to be given to the public cloud.
Roadmap. The rest of this paper is organized as fol-
lows. Section 2 describes security challenges in outsouring
anonymized read data; Section 3 presents our secure map-
ping techniques and analyzes the privacy protection they of-
fer; Section 4 reports an evaluation on the performance of
our approach; Section 5 surveys related prior research and
Section 6 concludes the paper.
2 Backgrounds
2.1 Read Mapping
The DNA data produced by a next generation DNA se-
quencer consists of millions of reads, each typically includ-
ing 35-250 nucleotides. These reads are randomly sam-
pled from a human genome. To interpret them, their ge-
netic locations must be found, which is achieved through
read mapping. Speciﬁcally, given a set of reads, a refer-
ence genome (i.e., a long DNA sequence) and a thresh-
old, the mapping operation aims at aligning each read to
a substring on the reference genome such that the edit dis-
tance between the read and the substring does not exceed a
threshold. This operation positions each read to its genetic
location, which is necessary for most human DNA analy-
ses, including SNP discovery, genotyping, gene expression
proﬁling (e.g. RNA-seq), comparative genomics, personal
genomics and others [49]. It is also a critical step for analyz-
ing the DNA data of human microbes [8], serving to sanitize
such data by removing the DNA contamination from human
hosts.
Figure 1. An Example (two sequences with
edit distance 3)
Seed-and-extend. As discussed before, a prominent feature
of read mapping is that the edit distance is small between
a read and the reference substring it should be aligned to:
since the genetic variation between different humans is typ-
ically below 0.5% and sequencing errors are about 2-3%,
almost all the mapping tasks look at a distance threshold
no more than 6 for standard 100-bp reads [29], which is
sufﬁcient for tolerating both the variations and the errors.
For such a small edit distance, alignments can be efﬁciently
found through seed-and-extend [19], a method that has been
extensively used in high-performance mapping systems like
BLAST [15], BLAT [36], Bowtie [37], RMAP [50, 51] and
CloudBurst [47]. The method is based upon the observa-
tion that for a sequencing read partitioned into d + 1 seg-
ments (seeds) of length l, if it has at most d errors, then
at least one of its d + 1 segments must match a substring
at the genetic location (on the reference genome) the read
should be mapped onto [19]. Therefore, one can use the seg-
ment to roughly locate the read on the reference (the seeding
stage), and then extend from these possible locations to de-
termine where it indeed belongs (the extension stage). Fig-
ure 1 gives an example: one of the 4 seeds of a 16-bp read