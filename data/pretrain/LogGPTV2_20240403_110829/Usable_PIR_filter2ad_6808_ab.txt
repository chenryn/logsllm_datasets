To enforce invariant (i), note also that all buckets must
contain the same number of blocks. For example, if the
bucket scanned at a particular level has no blocks in it, then
the adversary would be able to determine that the desired
block was not at that level. Therefore, each reorder pro-
cess ﬁlls all partially empty buckets up to the top with fake
blocks. Recall that since every block is encrypted with se-
mantic security, the adversary cannot distinguish between
fake and real blocks.
Costs.
Each query requires a total online cost of
O(log2(n)) for scanning the log n-sized bucket on each of
the log n levels, plus an additional, amortized cost due to
intermittent level overﬂows. Using a logarithmic amount
of client storage, reshufﬂing levels in ORAM requires an
amortized cost of O(log3(n)) per query (O(log4(n)) in
practice due to a hidden constant factor around 2100 in the
implementation [17]).
4 A Solution
Our solution deploys new insights based on probabilistic
analyses of data shufﬂing in ORAM allowing a signiﬁcant
improvement of its asymptotic complexity. These results
can be applied under the assumption that clients can afford
a small O(√n) amount of temporary working memory. We
validate this assumption in real settings (e.g., the IBM 4764
SCPU [5] can host up to 64MB of RAM).
4.1 Additional Client(cid:173)side Working Memory
Simply adding storage to ORAM in a straightforward
manner does not improve its complexity. Consider that
there are two stages where additional storage can be de-
ployed. First, the top levels could be stored exclusively on
the client, allowing the bypassing of all reads and writes
to the top levels, as well as the re-shufﬂing of these lev-
els. Since there are log n levels, with sizes 4i for i from
1 to log n, the blocks belonging to the ﬁrst log(c√n) =
log c + 1
2 log n levels can ﬁt in this storage. This however,
would only eliminate a constant fraction of the levels, leav-
ing the most expensive levels operating as before.
Second, as indicated in [17], additional client-side stor-
age can be deployed in the sorting network used in the level
reshufﬂe. The sorting network is the primitive that performs
all the level reordering, requiring O(n log2 n) time for the
client to obliviously sort data on the server (with no client
storage). The ORAM claim of O(log3 n) amortized over-
head requires the use of the impractical AKS sorting net-
work [6] that performs in O(n log n) time (with a hidden
factor of close to 2100).
Then, in the presence of additional storage, the normal
sorting network running time can be improved by perform-
ing comparisons in batches on the client. However, per-
forming batch comparisons with a limited amount of stor-
age does not greatly improve the complexity of the sorting
network. We are not aware of methods to apply this amount
of storage that would result in improvements of more than
a constant factor. While we cannot make a claim of nonex-
istence of such improvements, we can bound the degree of
improvement possible by this approach. Even if the stor-
age is used in a manner that can reduce the time complexity
of the sorting sequence, no amount of storage can cause
the sorting network to do a comparison sort (as required in
Oblivious RAM) better than Ω(n log n) [10]. This still re-
sults in overall amortized overhead of Ω(log3 n).
Our Approach. Instead, we propose to tackle the com-
plexity of the most time-consuming phase of ORAM, the
level reorder step. We take advantage of the consistent na-
ture of uniform random permutations to perform an oblivi-
ous scramble with a low complexity and little client storage.
Our intuition is that given two halves of an array consist-
ing of uniformly randomly permuted sequence of items, the
items will be distributed between the halves almost evenly.
That is, if we pick the permuted items in order, counting the
number of times each array half is accessed, the counts for
each array half remain close for the entire sequence, with
high probability.
This allows us to implement a novel merge sort that hides
the order in which items are being pulled from each half.
Once the two array halves are each sorted and stored on the
server, we can combine them into a sorted whole by reading
from each half into the client buffer, then outputting them
in sorted order without revealing anything about the permu-
tation. By the uniform nature of the random permutation,
for arrays of size n, we show that the running tally of picks
from each array half will never differ by more than c√n,
with high probability. This means that we can pre-set a
read pattern from the server without knowing the permu-
tation, and still successfully perform the permutation! The
pattern of accesses between the two array halves will devi-
ate slightly, but with high probability they will fall within
the window of c√n from the ﬁxed pattern.
This oblivious merge sort is the key primitive that allows
us to implement access pattern privacy with O(log2(n))
overhead. We use it to implement a random scramble, as
well as to remove the fake blocks that are stored in each
level. Being able to do both of those steps efﬁciently, we
can then replace the oblivious permutation used in ORAM
with a more efﬁcient version.
From here on, we will be concerned mainly with the pro-
cess of re-ordering a level, since the rest of our algorithm is
unchanged from ORAM. A level re-ordering entails taking
the entire contents of level i, consisting of 4i buckets sized
log n, containing a total number of real blocks between 4i−1
and 4i, with the remainder ﬁlled with fake blocks, and rear-
ranging them to the new permutation obliviously – without
revealing anything about the new permutation to the server
storing these levels.
4.2 Strawman: client with n blocks of working
memory
Before describing the main result, let us ﬁrst analyze a
strawman algorithm that achieves our desired time com-
plexity, in the presence of enough client-sided storage to
ﬁt the entire database.
Observe that if the client has n ≥ 4i blocks of tem-
porary secure storage, it can perform a level reorder with
(2)(4i)(log n) = O(log n4i) server accesses. By reading
the entire level into the temporary secure storage, throw-
ing out the fake blocks as they were encountered, it can
store all 4i blocks locally. It then performs a comparison
sort on the local secure storage (which is hence done with-
out revealing the new permutation to the server) to permute
these blocks to their new location at a computational cost
of O(4i log(4i)) = O(i4i). The blocks are then all re-
encrypted with new nonces for a cost of O(4i) (so the server
is unable to link old to new blocks). Copying this data back
to the server, while inserting fakes to ﬁll the rest of the buck-
ets, requires writing another (4i)(log n) blocks to the server.
Since each level i overﬂows into level i + 1 once ev-
ery 4i accesses, level i + 1 must be reordered at each such
occurrence. As there are log n levels total, the amortized
communication and computational costs per query of this
level reordering approach, across all levels, can therefore
be approximated by
log n
Xi←1
O(log n4i)
4i−1
=
log n
Xi←1
O(log n) = O(log2 n)
This ofﬂine level reordering cost must be paid in addi-
tion to the online query cost to scan a bucket at each level.
This part of the algorithm is equivalent to ORAM. Since the
buckets have size log n, the online cost of scanning buck-
ets is (log4 n)(log n) = O(log2 n). Thus the average cost
per query, including both online costs and amortized ofﬂine
costs, is O(log2 n).
In summary, in the presence of O(n) client storage the
amortized running time for ORAM can be cut down from
O(log4 n) to O(log2 n). Of course, assuming that the client
has n blocks of local working memory is not necessarily
practical and could even invalidate the entire cost proposi-
tion of server-hosted data. Thus little has been gained so
far.
4.3 Overview:
client with only c√n blocks of
working memory
We will now describe an algorithm for level re-ordering
with identical time complexity, but requiring only c√n lo-
cal working memory from the client. The client’s reordering
of level i is divided into Phases (refer to Figure 1). We now
overview these phases and then discuss details.
1. Removing Fakes. Copy the 4i original data blocks at
level i to a new remote buffer (on the server), oblivi-
ously removing the (log n − 1)4i fake blocks that are
4 4i, 1
2 4i, or 3
interposed. Care must be taken to prevent revealing
which blocks are the fakes – thus copying will also
entail their re-encryption. This decreases the size of
the working set from (log n)4i to 4i if the level is full,
or to 1
4 4i for the ﬁrst, second, and third
reorderings of this iteration of level i. We will as-
sume we are dealing with a full level (fourth reorder-
ing) to make the remainder of this description sim-
pler; earlier reorderings proceed equivalently but with
slightly lesser time and space requirements. The com-
munication/computational complexity of this phase is
O(log n4i). (see section 4.4)
2. Oblivious Merge Sort. Obliviously merge sort the
working set in the remote buffer, placing blocks into
their ﬁnal permutation according to the new hash func-
tion for this level. Perform the merge sort in such a
way that the server can build no correlation between
the original arrangement of blocks and the new permu-
tation. The communication/computational complexity
of this phase is O(log n4i). (see section 4.5)
…
all levels
n items total
Level i: 4i buckets x log(n) blocks
…
…
…
…
…
…
… all levels
Level i: 4i buckets x log(n) blocks
Buffer: 4i items
…
…
…
…
…
…
1
2
Removing 
Fakes
Oblivious 
Merge Sort
3
Adding Fakes
Figure 1. Solution Overview.
Buffer:        items
nc
…
un-trusted
server
ORAM client
3. Add Fakes. Copy the 4i blocks, which were per-
muted by Phase 2 into their correct order, to the ﬁ-
nal remote storage area for level i. They are not in
buckets yet, so we build buckets, obliviously adding
in the (log n − 1)4i fake blocks necessary to guar-
antee all buckets have the same size. The com-
munication/computational complexity of this phase is
O(log n4i). (see section 4.6)
The above algorithm reorders level i into the new per-
mutation, in time O(log n4i). Therefore the derivation of
the amortized overhead is equivalent to the derivation per-
formed for the strawman algorithm, leading to an amortized
overhead of O(log2 n) per query. We now show how to efﬁ-
ciently implement each phase, using only c√n local mem-
ory.
4.4 Phase 1: Remove Fakes
Fake blocks can be removed from level i in a single pass,
without revealing them, by copying into a temporary buffer
that hides the correspondence between read blocks and out-
put blocks (refer to Figure 2 (a)). The client scans the level,
storing the real blocks into a local queue and tossing the
fake blocks. Once the queue is expected to be half full, the
client starts writing blocks from the queue (while also con-
tinuing the scan), at a rate corresponding to the overall ratio
of real to fake blocks. The goal is to keep the queue about
half full until the end.
(The server can observe the total
number of fake and real blocks in a particular level, which
is independent of the data access pattern.) Assuming the
temporary queue never overﬂows or empties entirely until
the end, the exact pattern of reads and writes observed by
the server is dependent only on the number of blocks, and
the ratio of fakes. The server learns nothing of which are the
fake blocks by observing the fake removal scan. We show
in Theorem 1 that, with high probability, a queue of size
c√n will not overﬂow or empty out.
remove f akes f rom level()
s ← maximum size of local queue, c√n
q ← empty queue stored locally, size s
r ← ratio of fake blocks to real blocks
for x = 1 to r*(n+s/2) do
if x < r ∗ n then
t ← decrypt(readNextBlockFromLevel());
if t is a real block then
enqueue(q, t)
end if
end if
if total number of blocks output < x/r − s/2 then
t ← dequeue(q)
writeNextBlockToRemoteBuffer(encrypt(t))
end if
end for
add f akes to level()
s ← size of local queue, c√n
q ← empty queue stored locally, size s
r ← ratio of buckets to real blocks, determined
by the reshufﬂe number for this level.
c ← 0 (total number of buckets output so far)
for x =1 to n + s/2 do
if x ≤ n then
t ← decrypt(readNextBlockFromLevel());
enqueue(q, t)
end if
if c < r ∗ (x − s/2) then
c ← c + 1
items ← Dequeue all items corresponding to bucket c.
(They will be on the end of the queue if there are any)
b ← New bucket, containing those items, and ﬁlled
the rest of the way with fake blocks.
writeNextBucketToRemoteLevel(encrypt(b))
end if
end for
Figure 2. (a) Phase 1: Remove Fakes (b)
Phase 3: Add Fakes
oblivious merge sort(A)
if A is size 1 then
Return A
end if
A1 ← First Half of A
A2 ← Second Half of A
A1 ← ObliviousMergeSort(A1)
A2 ← ObliviousMergeSort(A2)
B ← New remote buffer with the same size as A
s ← size of local queues, c√n
q1 ← empty queue stored locally, size s
q2 ← empty queue stored locally, size s
for x = 1 to s/2 do
Enqueue(q1, decrypt(readNextBlockFrom(A1)));
Enqueue(q2, decrypt(readNextBlockFrom(A2)));
end for
(At this point, each queue will have s/2 blocks)
for x = s/2 to n + s/2 do
if x ≤ n then
Enqueue(q1, decrypt(readNextBlockFrom(A1)));
Enqueue(q2, decrypt(readNextBlockFrom(A2)));
end if
(Now we’ve read 2 blocks; time to output 2 blocks)