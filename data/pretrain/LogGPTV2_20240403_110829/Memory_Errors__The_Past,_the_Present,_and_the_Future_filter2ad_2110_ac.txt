aware of attacks such as SQL injections or Cross Site Scripting (XSS). If so, this
would have raised web security concerns, resulting in better code written.
Similarly, static (code) analysis may have started to be included in the soft-
ware development life-cycle. Static code analysis for security tries to ﬁnd weak-
nesses in a program that might lead to security vulnerabilities. In general, the
 0 400 800 1200 1600199720002003200620092012 0 400 800 1200 1600#Vulnerabilities#ExploitsDateVulnerabilities and ExploitsMem.Err VulnsMem.Err ExploitsWeb VulnsWeb ExploitsTotal VulnsTotal Exploits0%15%30%45%60%75%20002002200420062008201020120%15%30%45%60%75%VulnerabilitiesExploitsDateVulnerabilities and Exploits as a Percentage of Total ReportedMem.Err VulnsMem.Err ExploitsWeb VulnsWeb Exploitsprocess is to evaluate a system (and all its components) based on its form,
structure, content or documentation for non-conformance in access control, in-
formation ﬂow, or application programming interface. Considering the high cost
involved in manual code review, software industry prefers using automated code
analyzers. IBM successfully demonstrated JavaScript analysis [109] by analysing
678 websites (including 178 most popular websites). Surprisingly, 40% of the web-
sites were found vulnerable and 90% of vulnerable applications had 3rd party
code. Another interesting take on static analysis can be observed in the surveys
published by NIST [75,74]. A remarkable number of previously reported vul-
nerabilities were found in popular open-source programs using a combination of
results reported by diﬀerent tools. For instance, [103] reports intriguing ﬁgures
showing the industry has conﬁdence in static analysis. The software and IT in-
dustry are the biggest requester, followed by the ﬁnance sector for independent
security assessments of their applications. Furthermore, 50% of the companies
resubmitted 91–100% of their commercial application (after the ﬁrst submis-
sions revealed security holes) for code analysis. The growing trust of industry in
static analysis could be one of the reasons for a drop in the number of reported
vulnerabilities from the last few years.
To substantiate the second hypothesis (i.e., less bugs are reported), it is
necessary and helpful to have a more social view on the matter. There could be
a number of reasons why people stopped reporting bugs to the community.
Empirical evidence about “no full disclosure due to bounties” advocates this
statement very well. Ten years ago, the discovery of a zero-day vulnerability
would have likely had a patch and a correspondence with the application au-
thors/vendor about the ﬁx, likely on public mailing lists. Today, big companies
like Google and Mozilla give out rewards to bug hunters as long as they do not
disclose the vulnerability [69]. Similarly, bug hunters may choose to not disclose
zero day vulnerabilities in public, but sell them instead to their customers [43].
Where companies send out rewards to ﬁnders of vulnerabilities, useful zero-
days could yield even more in underground and private markets. This business
model suggests that ﬁnancial proﬁt may have potentially been responsible for the
downward trend. While more and more people start buying things online and use
online banking systems, it becomes increasingly interesting for criminals to move
their activities to the Internet as well. Chances that issues found by criminals
are reported as CVEs are negligible.
At the same time, full disclosure [113] as it was meant to be, is being
avoided [50,44]. As an example for this shift in behavior, researchers were threat-
ened for ﬁnding a vulnerability [49], or, as mentioned above, they may well sell
them to third parties on private markets. This was also recently backed up by
Lemos and a 2010-survey that looked at the relative trustworthiness and respon-
siveness of various organizations that buy vulnerabilities [60,42].
In conclusion, it is reasonable to believe that the drop in vulnerabilities is
caused by both previous hypotheses. The software industry has become more
mature during the last decade, which led to more awareness about what poten-
tial damage a vulnerability could cause. Web developers or their audits switched
(a) Vulnerabilities
(b) Exploits
Fig. 3: Memory errors categorized.
to more professional platforms instead of their home-brew frameworks and elim-
inated easy vulnerabilities by simply writing better code. This growing profes-
sionalism of the software industry also contributed to the fact that bugs are no
longer reported to the public, but sold to either the program’s owners or the
underground economy.
3.1 Categorizing Vulnerabilities and Exploits
We further categorized memory error vulnerabilities and exploits in 6 diﬀerent
classes (based on their CVEs descriptions): stack-based, heap-based, integer is-
sues, NULL pointer dereference and format string. Figures 3a and 3b show the
classiﬁcation for vulnerabilities and exploits, respectively.
From Figures 3a and 3b we make the following observations which may help
to draw our ﬁnal conclusions. First, format string vulnerabilities were found all
over the place shortly after they were ﬁrst discovered. Over the years, however,
the number of format string errors dropped to almost zero and it seems that
they are about to get eliminated totally in the near future. Second, integer
vulnerabilities were booming in late 2002, and, despite a small drop in 2006,
they are still out there as of this writing (see [102]). Last, old-fashioned stack
and heap memory errors are still by far (about 90%) the most exploited ones,
counting for about 50% of all the reported vulnerabilities. There is no evidence
to make us believe this will change in the near future.
4 Discussion
To answer the question whether memory errors have become a memory of the
past, a few more observations need to be taken into consideration.
 0 40 80 120 160 2002000200220042006200820102012#VulnerabilitiesDateMemory Corruption Vulnerabilities CategorizedStack VulnsHeap VulnsInteger VulnsPointer VulnsFormat Vulns 0 16 32 48 64 802000200220042006200820102012#ExploitsDateMemory Corruption Exploits CategorizedStack ExploitsHeap ExploitsInteger ExploitsPointer ExploitsFormat ExploitsTable 1: Breakdown of exploited vulnerabilities in popular exploit toolkits.
Pack
Exploits Memory Errors Unspeciﬁed
Other Updated
Nuclear
Incognito
Phoenix
BlackHole
Eleonore
Fragus
Breeding Life
Crimepack
12
9
26
15
31
14
15
19
6 (50%)
4 (44%)
14 (54%)
6 (40%)
18 (58%)
11 (79%)
8 (53%)
10 (53%)
3 (25%)
1 (33%)
7 (27%)
7 (46%)
6 (19%)
1 (7%)
6 (40%)
2 (11%)
0 (0%) Mar. 2012
0 (0%) Mar. 2012
5 (19%) Mar. 2012
2 (13%) Dec. 2011
7 (23%) May. 2011
2 (14%)
2011
?
1 (6%)
Jul. 2010
7 (37%)
All
104
66 (63%)
12 (12%)
26 (25%)
Impact. Let us ﬁrst take a closer look at the impact of memory error vul-
nerabilities. After all, if this turns out to be negligible, then further research on
the topic may just well be a questionable academic exercise. To provide a plau-
sible answer, we analysed diﬀerent exploit packs by studying the data collected
and provided by contagio malware dump3. Table 1 shows the number of exploits
(with percentages too) a given exploit pack supports and it is shipped with. The
column Memory Errors reports those related to memory errors, while Unspeciﬁed
refers to exploit of vulnerabilities that have not been fully disclosed yet (and
chances are that some of these are memory error-related, e.g., CVE-2010-0842).
Conversely, the column Other refers to exploits that are anything but memory
error-related (e.g., an XSS attack).
Table 1 clearly shows that in at least 63% of the cases, memory error exploits
have been widely deployed in exploit packs and have thus a large impact on the
security industry, knowing that these exploit packs are responsible for large-scale
hosts infections.
Support of buﬀer overﬂows by design. Second, we observe that the
number of memory vulnerabilities in a speciﬁc program is highly dependent on
the programming language of choice. Looking closely at the C programming lan-
guage, we observe that it actually needs to support buﬀer overﬂows. Consider,
for example, an array of a simple C struct containing two ﬁelds, as depicted in
Figure 4a. A memset()-like call may indeed overﬂow a record (Figure 4b). In
this case, the overﬂow is not a programming error, but a desired action. Having
such overﬂows by design, makes the programming language more vulnerable and
harder to protect against malicious overﬂows. Considering that unsafe program-
ming languages such as C and C++ are and have been among the most popular
languages in the world for a long time already (as supported by the TIOBE Pro-
3 http://contagiodump.blogspot.com/2010/06/overview-of-exploit-packs-update.
html
(a) Memory layout
(b) Memory layout after memset()
Fig. 4: Buﬀer overﬂow support in C.
gramming Community Indexes), careful attention should be paid by developers
to avoid memory error vulnerabilities.
Deployment of mitigation techniques. Third, we observe that mitiga-
tion techniques are not always deployed by modern OSes. The reasons could be
manifold. For instance, implementing a speciﬁc mitigation technique on legacy
(or embedded) systems may require non-existent hardware support, or it may
incur non-negligible overheads. Similarly, alternative mitigation techniques may
require recompilation of essential parts of a system, which cannot be done due
to uptime requirements or lack of source code.
Patching behaviour. Another issue relates to the patching behaviour. Not
only end users, but also system administrators appear to be lazy when it comes
to patching vulnerabilities or updating to newer software versions. During our
research on exploit kits, we found that even recently updated exploit packs still
come with exploits for quite dated vulnerabilities, going back to 2006. This is
backed up by other studies [59,100].
Motivation. Finally, even when all mitigation techniques are deployed, skilled
and well-motivated attackers can still ﬁnd their way into a system [41,104,106,105].
Looking back at Figure 2a, it is reasonable to say that some form of awareness
has arisen among developers. On the other hand, Figure 2b shows that memory
errors have a market share of almost 20%—a number that did not change much
over the last 15 years, and something of which we have no evidence that it is
about to change in the foreseeable future. The fact that over 60% of all the
exploits reported in Table 1 are memory error-related, does not improve the
scenario either.
4.1 Research Directions
Memory errors clearly still represent a threat undermining the security of our
systems. We would like to conclude by sketching a few research directions that
we consider both important and promising.
Information leakage, function pointer overwrites and heap inconsis-
tencies. Information leakage vulnerabilities are often used to bypass (otherwise
well-functioning) ASLR, enabling an attacker to initiate a return-into-libc or
ROP attack [89]. Function pointer overwrites and heap inconsistencies form a
class of vulnerabilities that cannot be detected by current stack smashing de-
tectors and heap protectors. These vulnerabilities are often exploited to allow
arbitrary code execution [105]. Recent studies try to address these problems by
introducing more randomness at the operating system level[77,48,52] and, to-
gether with future research, will hopefully result in better protections against
these classes of vulnerabilities [14].
Low-overhead bounds checkers. Bounds checking aims at deﬁning the
boundaries of memory objects therefore avoiding overﬂows, which represent
probably the most important class of memory errors. Although state-of-the-art
techniques have drastically lowered the overhead imposed [111,3], the runtime
and memory pressure of such countermeasures are still non-negligible.
Non-control data attacks. While ordinary attacks against control data
are relatively easy to detect, attacks against non-control data can be very hard
to spot. These attacks were ﬁrst described by Chen et al. in [23], but a real-world
scenario (an attack on the Exim mailserver), was recently described by Sergy
Kononenko [57]. Although the attack uses a typical heap overﬂow, it does not
get detected by NX/DEP, ASLR, WˆX, canaries nor system call analysis, as it
does not divert the program’s control ﬂow.
Legacy systems and patching behaviour. As discussed earlier, lazy
patching behaviour and unprotected legacy systems (as well as ﬁnancial gain) are
probably the main reasons of the popularity of exploit kits. Sophisticated patch-
ing schemes, and disincentivizing automatic patch-based exploit generation [18],
should be the focus of further research.
Static and dynamic analysis to detect vulnerabilities. By using novel
analysis techniques on vulnerable code, one may succeed in detecting vulnera-
bilities, and possibly harden programs before the application is deployed in a
production environment. Research on this topic is ongoing [94,95] and may help
to protect buﬀer overﬂow vulnerabilities from being exploited. However, it is nec-