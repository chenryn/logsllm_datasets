replica state. These proposals share the same core idea with one of the tests
introduced further ahead in Chapter 3, that aims at quantifying divergence.
However, in contrast to this thesis, the authors of [71] do not verify nor quantify
divergence in several Internet services.
2.5 Middleware solutions for enforcing
consistency
In this section, we present and discuss the most relevant related work about
systems that introduce a layer that can mediate access to a service, in order to
upgrade the respective consistency guarantees.
Bailis et al. [16] proposed a system called “bolt-on causal consistency” to
provide safety. Their proposal enforces causal consistency by introducing a
layer between the client and an eventually consistent data store. This layer
has a local storage that contains a consistent causal cut of the data, with all
elements requested by the client and their dependencies, and provides two op-
erations: the get operation, to obtain a value given a key and the put operation
that receives the value to write and its dependencies. The put operation makes
the write in the data store with the associated metadata and updates the local
store. The metadata contains a list with the write dependencies and a vector
clock (one entry per client). The get operation obtains the value directly from
the local storage, tells a background procedure to check if a more recent value
for the key is available in the data store, and then returns to the client. The
background procedure is responsible for obtaining new values and to guaran-
teeing that the local store contains a consistent causal cut of the data. This
20
2.5. MIDDLEWARE SOLUTIONS FOR ENFORCING CONSISTENCY
means that this procedure has to ensure that all write dependencies are stored
locally. This approach provides low latency in the read operations, but it may
miss the last value for a key. To address this, it is also proposed an alternative
read operation, that returns more recent data but may take longer to execute,
where the most recent value for a key is obtained from the data store and the
necessary dependencies are stored locally, before returning to the client.
There are two main limitations in this previous work: it does not provide a
ﬁne-grained choice of which session guarantees (i.e., Monotonic Reads, Mono-
tonic Writes, Writes Follow Reads, and Read Your Writes) the application de-
veloper has to ensure so that only the performance penalty that is required for
those particular guarantees is incurred. Second, they assume the underlying
system oﬀers a general read/write storage interface, which gives signiﬁcant
more ﬂexibility in terms of the system design, in contrast to our work, which
is restricted to the APIs provided by Internet services.
Another work that proposes a middleware to guarantee consistency on top
of eventually consistent data stores was conducted by Bermbach et al. [20].
This middleware enforces session guarantees and provides a causal behavior
to the clients. To enforce the consistency guarantees the middleware relies on
vector clocks to track the last value of a key (one entry per application server).
The middleware provides operations to write and read the values of a key and
caches the values. This work is also limited to a generic storage interface and
it does not provide a ﬁne-grained choice to all session guarantees.
In addition to the two previous works, there is also a proposal from Brantner
et al. [22] called “Building a Database on S3”, that proposes the design of a
middleware to be used on top of a data service (Amazon S3) storing mostly
small objects. The middleware provides atomic transactions and can enforce
all sessions guarantees. To achieve this, the middleware has a local storage and
uses the Simple Queueing System (SQS) [8], the system uses several queues.
When a write is committed, the write is sent to the respective queue and a
procedure called checkpoint applies the writes to S3.
In this system each
record is in a page that is stored in S3. To guarantee Monotonic Reads, a
commit timestamp is associated to the page. The idea is to use this timestamp
21
CHAPTER 2. BACKGROUND AND RELATED WORK
to guarantee that the local storage maintains the most recent versions of the
records to return. To guarantee Monotonic Writes the system associates a
counter and a client identiﬁer to the pages. The counter increases every time
the client commits and the order is enforced in the checkpoint procedure. Read
Your Writes is guaranteed if Monotonic Reads is enforced. Writes Follow Reads
is also guaranteed because writes are sent to a queue and processed by the
checkpoint procedure before being sent to S3. The main limitation of this
solution is the overhead of using an external service to enforce the session
guarantees, namely, the Simple Queueing System (SQS).
Terry et al. [64] originally proposed the sessions guarantees, that have been
referenced above, in the work, “Session guarantees for weakly consistent repli-
cated data“. In this work they propose a system that provides the four session
guarantees on top of a multi-master replicated data store that provides even-
tual consistency. The system has a session manager that runs at each client and
provides a simple read/write interface. It is assumed that the data store servers
are responsible to assign a unique identiﬁer for each new write (WID) and that
they must be able to retrieve the set of all WIDs done in each server. For each
session, there is a read-set that contains the WIDs of the relevant writes seen
in the session and a write-set that contains the WIDs of the writes done in
the session. To guarantee Read Your Writes, when a client issues a write, the
associated WID is stored in the write-set, when the client issues a read, the
session manager needs to ﬁnd a server that contains the write-set and then
read from that server. To guarantee Monotonic Reads, the WIDs of all writes
seen in the session are stored in the read-set and, when a client issues a read,
the session manager has to ﬁnd a server that covers the read-set and then reads
from that server. To guarantee Monotonic Writes and Writes Follows Reads,
it is assumed that the writes observed in a server always precede new writes
and that this order is respected while performing replication. Assuming these
constraints, to guarantee Monotonic Writes, when a write is issued, the session
manager has to ﬁnd a server that contains the write-set and then execute the
write in that server. To guarantee Writes Follow Reads, the WIDs of all relevant
writes seen in the session must be stored in the read-set, and, when a write
22
2.5. MIDDLEWARE SOLUTIONS FOR ENFORCING CONSISTENCY
is issued, the session manager has to ﬁnd a server that contains the read-set
and then execute the write in that server. In order to implement the session
guarantees more eﬃciently, the authors propose to replace the sets of WIDs
with vector clocks (one entry per server). This avoids having sets of WIDs that
grow indeﬁnitely. This solution provides ﬁne-grained consistency; however, it
assumes a set of constraints that are hard to achieve when we are working with
online services, where the internal logic of the service cannot be changed (i.e.,
the service is seen as a black box) [44].
To summarize the main limitations of previous work, (1) some solutions do
not provide a ﬁne-grained choice of the session guarantees to developers; (2)
they assume that the underlying system is a data store with a generic read/write
interface, whereas Web APIs have more complex interfaces (e.g. they associate
a list of objects to each key and only return part of that list); (3) the use of
external services as part of the system (i.g., the Simple Queueing System); (4)
they assume several constraints at the server side, such as knowledge of the
internal structure of the data store and direct access to all servers, (5) and they
assume the absence of requests rate limits when writing and reading from the
data store, in contrast, public Web APIs block applications that exceed the
limits imposed by the service.
23
e
t
p
r 3
h
C
a
Measurement Study
The goal of the measurement study presented in this chapter is to characterize
experimentally the consistency oﬀered by online service through their public
APIs. To this end, we designed two tests that probe the service (through the
API) in search of consistency anomalies. A particular challenge in this context
is that there are multiple consistency deﬁnitions, often using diﬀerent nota-
tions. To address this, we deﬁne a number of anomalies that are both precise
and intuitive to understand by programmers and users of online services. Note
that we are not trying to exhaustively deﬁne all anomalies that can occur, nor
to prove that these are equivalent to any of the various existing consistency
deﬁnitions. It is also important to point out that if an anomaly is not observed
in our tests, this does not imply that the implementation disallows for its oc-
currence, since it could have been by chance that it did not surface during the
period of experimental testing.
3.1 Operations
In the following description, we consider that users (or clients) of the service
issue a set of requests, which can be divided into two categories: (1) write re-
quests, which create an event that is inserted into the service state (e.g., posting
25
CHAPTER 3. MEASUREMENT STUDY
a new message), and (2) read requests, which return a sequence of events that
have been inserted into the state (e.g., reading the current sequence of posts).
For simplicity, we assume that read operations return the entire sequence of
writes. In practice, this could be generalized to deﬁne that a read returns a
value that is a function of the sequence of writes according to some service
speciﬁcation, that may not contain the whole sequence, in Chapter 4 we are
going to discuss this in more detail.
3.2 Deﬁning consistency anomalies
Based on write and read operation categories, we now deﬁne the set of anoma-
lies we consider in this study. We split these into three categories:
3.2.1 Session guarantees
The ﬁrst set of anomalies corresponds to violations of session guarantees [64].
In these deﬁnitions we are considering that each client executes in the context
of its own session.
Read Your Writes: This session guarantee requires that a read observes all
writes previously executed by the same client. More precisely, say W is the set
of write operations made by a client c at a given instant, and S a sequence (of
eﬀects) of write operations returned in a subsequent read operation of c, a Read
Your Writes anomaly happens when:
∃x ∈ W : x (cid:60) S
Monotonic Writes: This requires that writes issued by the same client are
observed in the order in which they were issued. More precisely, if W is a
sequence of write operations made by client c up to a given instant, and S is
a sequence of write operations returned in a read operation by any client, a
Monotonic Writes anomaly happens when the following property holds, where
W (x) ≺ W (y) denotes x precedes y in sequence W :
∃x, y ∈ W : W (x) ≺ W (y)∧ y ∈ S ∧ (x (cid:60) S ∨ S(y) ≺ S(x))
26
3.2. DEFINING CONSISTENCY ANOMALIES
Monotonic Reads: This session guarantee requires that all writes reﬂected
in a read are also reﬂected in all subsequent reads performed by the same client.
In comparison to Monotonic Writes, this has the subtle diﬀerence of requiring
that the missing write is ﬁrst observed (i.e., returned by a previous read) by
the client before disappearing. More precisely, a Monotonic Reads anomaly
happens when a client c issues two read operations that return sequences S1
and S2 (in that order) and the following property holds:
∃x ∈ S1 : x (cid:60) S2
Writes Follow Reads: This session guarantee requires that the eﬀects of a
write observed in a read by a given client always precede the eﬀects of writes
that the same client subsequently performs. This precludes the situation where
a client reacts to a write issued by itself or some other client (e.g., after reading
a question that was posed) by issuing another write (e.g., posts a reply), and
subsequently some client observes the second write without observing the ﬁrst
one. More precisely, if S1 is a sequence returned by a read invoked by client
c, w a write performed by c after observing S1, and S2 is a sequence returned
by a read issued by any client in the system; a Writes Follows Reads anomaly
happens when:
∃x ∈ S1 ∧∃w ∈ S2 : x (cid:60) S2
Note that although this last anomaly has been used to exemplify causality
violations in previous papers [5, 49], any of the previous anomalies represent
a diﬀerent form of a causality violation [64].
3.2.2 Divergence
The next two anomalies refer to divergence between the state that is returned
by read operations issued by two independent clients [70].
Content Divergence: A content divergence anomaly captures the case where
two clients issue read operations and there are at least two writes such that
one client sees one but not the other, and for the other client the opposite is
true. More precisely, a content divergence anomaly happens when two reads
27
CHAPTER 3. MEASUREMENT STUDY
issued by clients, c1 and c2, return respectively, sequences S1 and S2, and the
following property holds:
∃x ∈ S1 ∧∃y ∈ S2 : y (cid:60) S1 ∧ x (cid:60) S2
Any system relying on weak consistency protocols is prone to this anomaly,
as this is a consequence of the core property of being able to perform and
complete a write operation by contacting a single replica in the system (i.e.,
without synchronization among replicas).
Order Divergence: The order divergence anomaly refers to writes issued
by diﬀerent clients being seen in distinct orders by diﬀerent clients. More
precisely, an order divergence anomaly happens when two reads issued by two
clients, c1 and c2, return, respectively, sequences S1 and S2, containing a pair
of events occurring in a diﬀerent order at the two sequences:
∃x, y ∈ S1, S2 : S1(x) ≺ S1(y)∧ S2(y) ≺ S2(x)
where the notation S(x) ≺ S(y) denotes that operation x in state S was ordered
before operation y.
3.2.3 Quantitative metrics
The anomalies deﬁned so far are boolean predicates over a trace of the system,
i.e., they either occur in an execution or they do not. In addition to the presence
or absence of these anomalies, we can determine quantitative aspects of the
observed behavior.
Content Divergence Window and Order Divergence Window: When con-
sidering the two divergence anomalies, it is also relevant to understand how
long it takes for the system to converge back to a single coherent state (assum-
ing it eventually does as prescribed by eventual consistency). As such, we can
deﬁne the Content Divergence Window and Order Divergence Window as follows.
When a set of clients issue a set of write operations, the divergence window
is the amount of time during which the condition that deﬁnes the anomaly
(either content or order divergence) remains valid, as perceived by the various
clients.
28
3.3. MEASUREMENT METHODOLOGY
Figure 3.1: Measurement study method overview
3.3 Measurement methodology
In this section, we describe a methodology for testing online services that tries
to expose the previously deﬁned anomalies. In a nutshell, our methodology,
consists of deploying agents in diﬀerent points in the globe, as depicted in
Figure 3.1. The agents perform several black box tests to the online service,
by issuing multiple read and write operations. After the execution of a test,
information about the operations is logged locally and then we perform an
oﬀ-line analysis to detect consistency anomalies.
The notion of a read or a write operation is speciﬁc to each service, but
should adhere to the speciﬁcation in Section 3.1. For the services we consid-
ered in the realization of this work, since they are either social networking or
messaging services, we chose operations that posted a message and listed the
current sequence of posts.
29
AgentServiceServiceServiceAgentAgentAgentAgentAgentCHAPTER 3. MEASUREMENT STUDY
3.3.1 Time synchronization
An important aspect of our tests is that they require the clocks of the machines
where agents are deployed to be loosely synchronized, for two diﬀerent reasons.
First, we use clock readings to compute divergence windows between diﬀerent
agents. As such, a clock synchronization error could introduce an additional
error in the computed values for the divergence windows. Second, some of
the tests require the various agents to issue operations as simultaneously as
possible (namely to maximize the chances of triggering conditions/executions
that maximize the chances of allowing the observation of divergence). As such,
a synchronization error would decrease the chances of triggering divergence,
and therefore make our measurements of this anomaly more conservative. The
synchronization error may reduce the chance of divergence, and thus we expect
our result to represent a lower bound on the divergence experienced by these
systems.
To synchronize clocks, one could rely on a service such as the Network
Time Protocol (NTP) [55]. However, the use of NTP implies releasing the
control over the clock synchronization process, which could introduce errors
in our measurements when the clock is adjusted. Thus, we disabled NTP and
implemented a simple protocol that estimates the time diﬀerence between a
local clock and a reference clock (which resembles Cristian’s algorithm for clock
synchronization [30]). In particular, a coordinator process conducts a series
of queries to the diﬀerent agents to request a reading of their current local
time, and also measures the RTT to fulﬁll that query. The clock deltas are then
calculated by assuming the time spent to send the request and receive the reply
are the same, and taking the average over all the estimates of this delta. The
uncertainty of this computation is half of the RTT values.
3.3.2 Tests
Our goal in designing these tests is twofold: ﬁrst, we want the tests to be