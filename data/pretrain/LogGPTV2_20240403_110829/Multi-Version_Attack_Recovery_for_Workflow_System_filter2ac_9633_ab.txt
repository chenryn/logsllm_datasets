are completed and committed.
Proceedings of the 19th Annual Computer Security Applications Conference (ACSAC 2003) 
1063-9527/03 $17.00 © 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:34:29 UTC from IEEE Xplore.  Restrictions apply. 
3. Theories of Multi-Version Data Object
based Recovery
This section starts by introducing the concept of a revi-
sion history, which keeps all versions of data objects, then
introduces rules for generating correct recovery schemes.
3.1. Revision History
For any data object x written at time tm, we associate tm
with x as its reversion number. We do not call it a times-
tamp since we do not perform recovery in real time. We as-
sume that any two ti and tj, where i (cid:6)= j, are distinguish-
able in the system.
Each data object has a revision history with the form
(cid:8)xv1, xv2 ,··· , xvn(cid:9), where each vi, 1 ≤ i ≤ n is a revi-
sion number of x and vj is later than vi if j > i. If we know
that xvk is corrupted by the attacker than any task that reads
xvk get wrong results.
Please note that it is possible that in x’s revision history,
there is only a speciﬁc version that is corrupted. For exam-
ple, x is generated periodically by a trustable task T and
an attacker only corrupts a speciﬁc version of x, e.g., xvk.
Therefore, we cannot conclude if xvj , where j > k, is dirty
without further analysis.
For a speciﬁc version xvk, when it has a value that it is
not supposed to have, it is dirty. For example, when xvk is
created by an attacker or computed based on dirty data ob-
jects, it is dirty. Otherwise, it is clean.
3.2. Operations on the Revision History
A normal task reads data objects with the highest revi-
sion number, and it writes data objects with the highest re-
vision number in their revision histories. So, a revision his-
tory does not change dependency relations among normal
tasks. It operates just as if multiple versions did not exist.
A recovery task, whether it is an undo or redo task, op-
erates on data objects with the same revision numbers as
it used the ﬁrst time it executed. For example, a undo(Ti)
is implemented by removing all speciﬁc versions from re-
vision histories of data objects written by Ti. A redo(Ti)
will generate data objects with the same revision number
as it executed ﬁrst time. A revision history does not change
dependency relations among recovery tasks either. We can
consider that recovery tasks are for revising part of the his-
tory of the system.
When we ﬁnd a dirty version xvk, there are two possi-
ble ways that the dirty version was generated. One possi-
bility is that xvk should not exist at all, e.g, it was created
by the attacker. Any task that reads xvk is supposed to read
xvk−1 instead of xvk. Another possibility is that xvk has a
dirty value and needs to be recomputed by a redo task. Any
task that reads xvk needs to wait until the redo task has com-
pleted to get a correct value of xvk. In this case, we mark
xvk as xvk
to block possible reading until the redo task is
b
complete.
Multi-version data objects break dependency relations
among recovery tasks and normal tasks, which enable us to
run the recovery tasks and normal tasks concurrently. Ac-
cording to the structure of the revision history, operations
on old versions happen as “in the past.” Therefore, execu-
tion of normal tasks does not corrupt recovery tasks.
Please note that ﬂow dependencies cannot be broken,
which guarantees that the semantics of execution are cor-
rect. From the point of view of recovery tasks (or normal
tasks), there is only a single version for each data object to
ensure correct semantics.
3.3. Axioms and Correctness Criteria
When attackers inject malicious tasks into the workﬂow
management system the malicious tasks generate or corrupt
some data objects directly. In addition, the data dependency
relations and the control dependency relations among work-
ﬂow tasks can further spread the damage to other data ob-
jects. We identify corrupted data objects, dirty data objects,
based on the following two axioms.
Axiom 1 (Generated Dirty Data Objects) Data
ob-
jects generated by the tasks that should not have been
executed are dirty.
Axiom 2 (Spread Dirty Data Objects) If a task computes
using dirty data objects, the results are dirty.
Concluded from the two axioms, Theorem 1 describes
what kind of data should be cleaned within the workﬂow
management system.
Theorem 1 A data object is dirty if, and only if, it was gen-
erated in any of the following ways
1. Generated directly by a malicious task or corrupted di-
rectly by attackers
2. Calculated based on dirty data
3. Generated by a task that should not have been exe-
cuted
4. Generated by a task that references data that is cre-
ated by tasks that should have been executed, but did
not
Theorem 1 describes all possible patterns of damage
spreading. In this paper we use the term bad task to rep-
resent a task that generates dirty data. Bad tasks consist of
malicious tasks and affected tasks.
In Figure 1, task T1 marked with ’B’ was corrupted
directly by attackers. So data that T1 generates are dirty,
which is indicated by item 1 in Theorem 1.
Proceedings of the 19th Annual Computer Security Applications Conference (ACSAC 2003) 
1063-9527/03 $17.00 © 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:34:29 UTC from IEEE Xplore.  Restrictions apply. 
According to our deﬁnition of ﬂow dependency, if Tj
reads data that task Ti writes then Ti →f Tj. In Figure 1,
task T2 marked with ’A’ is data dependent on task T1. T2 is
affected by bad task T1 because it reads dirty data from T1
then creates wrong results which are also dirty. So does task
T4, which reads dirty data from T2. T8 and T10 fall in the
same case, which is described by item 2.
The third situation described in item 3 is shown by task
T3 marked by ’I’ in Figure 1, which is ’innocent’. In Fig-
ure 1 the execution of task T3 is based on the executing re-
sult of task T2. Since task T2 is affected by T1, it is possi-
ble that the selection of executing path is wrong. We need
to redo task T2 and then check whether T3 is still a true suc-
cessor of redo(T2) in the recovered execution. If it is a false
successor of redo(T2) in the recovered execution, then the
data T3 generated before are dirty and T3 needs to be un-
done, although the calculating results of T3 are correct.
For the last case described in Theorem 1, please refer
to the execution of task T6 marked by ’G’ in Figure 1. T6 is
ﬂow dependent on task T5 which was not executed in the at-
tacked execution. When we redo task T2, the workﬂow may
be executed along a new path that continues with T5. Then
T5 may generate different data from what T6 has read in the
attacked execution. Thus T6 will get different results in the
recovered execution. Therefore task T6 produced a wrong
result in the attacked execution and the data it generated are
dirty.
The following deﬁnition describes the correctness crite-
ria for our workﬂow attack recovery scheme.
Deﬁnition 1 Given a set N of normal tasks, the recovery
scheme (cid:8)R,≺s,→c(cid:9) is correct if, and only if, the following
conditions hold.
1. No dirty data exists after executing (cid:8)R,≺s,→c(cid:9)
2. No dirty data is generated by executing (cid:8)R,≺s,→c(cid:9)
3. The execution of normal tasks in N should not gener-
ate dirty data and should not have corrupted recovery
tasks
4. The execution of tasks in N and R do not violate the
deﬁnition of a workﬂow
A correct recovery scheme is not isolated from the work-
ﬂow management system. When we are carrying out the re-
covery there deﬁnitely exist some scheduled preceding re-
lations between the recovery tasks and the normal workﬂow
tasks. Condition 3 states that the execution of normal tasks
should be clean. In other words, if a new task tries to read
dirty data from some unrecovered tasks, it should be sus-
pended for future execution until the data it tries to read are
clean.
3.4. Generate Recovery Tasks
This section describes how to ﬁnd undo and redo tasks.
Since damage is spread by ﬂow-dependencies and control
dependencies, which are not affected by the revision his-
tory, we do not bother with different versions of a speciﬁc
data object in this section.
From Theorem 1 and Deﬁnition 1 we can directly get the
following theorem for undo tasks.
Theorem 2 (Undo tasks) Assume B is a known set of bad
tasks that need be undone. The correctness criteria will not
be violated if, and only if, the following Ti and Tj are un-
done.
1. ∀Ti, Ti ∈ B
2. ∃Ti ∈ B, Ti →∗
3. ∃Ti ∈ B, Tj ∈ L, Ti →∗
4. ∃Ti ∈ B,∃Tk /∈ L, Ti →∗
c Tj, and Tj ∈ SF (redo(Ti))
f Tj, and Tk ∈
c Tk, Tk →∗
f Tj
ST (redo(Ti))
PROOF SKETCH: The objective of undo tasks is to re-
move the dirty data in the workﬂow system. Each item in
the theorem is exactly the formal description of the tasks
that are described within the same numbered item in Theo-
(cid:1)
rem 1.
We call the tasks described by condition 3 and condi-
tion 4 candidate undo tasks because we do not know if they
really should be undone until redo(Ti) is executed.
Consider the problem in Figure 1 again. At the begin-
ning, B = {T1}. Thus T1 should be undone according to
condition 1. T2, T4, T8 and T10 should be undone because
there exists T1 ∈ B, T1 →f T2, T2 →f T4, T1 →f T8
and T8 →f
this point we
know B = {T1, T2, T4, T8, T10}. T3 should be un-
done because ∃T2 ∈ B, T3 ∈ L, T2 →c T3 and
T3 ∈ SF (redo(T2)), which is speciﬁed by the condi-
tion 3. Now B = {T1, T2, T3, T4, T8, T10}. Based on condi-
tion 4, task T6 should be undone due to the fact that T2 ∈ B,
T5 /∈ L, T2 →c T5, T5 →f T6 and T5 ∈ ST (redo(T2)). Fi-
nally, we have B = {T1, T2, T3, T4, T6, T8, T10}.
T10 (condition 2). At
The tasks that have already been undone and are still on
the re-executing path should be redone to meet the speciﬁ-
cation of the workﬂow. Regarding redo tasks, we have the
following theorem.
Theorem 3 (Redo tasks) Assume B is a known set of bad
tasks, Ti ∈ B, then Ti should be redone if, and only if, any
of the following conditions are satisﬁed.
1. (cid:1)Tj ∈ B, Tj →∗
2. ∃Tj ∈ B, Tj →∗
PROOF SKETCH:
c Ti
c Ti, Ti ∈ ST (redo(Tj))
In both cases, Ti has been damaged
and is on the re-executing path. Thus Ti needs to be redone
(cid:1)
to meet the speciﬁcation of the workﬂow.
Proceedings of the 19th Annual Computer Security Applications Conference (ACSAC 2003) 
1063-9527/03 $17.00 © 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 07:34:29 UTC from IEEE Xplore.  Restrictions apply. 
We call the tasks described by condition 2 candidate
redo tasks because we do not know if they really should
be redone until redo(Tj) is executed.
In Figure 1 task T1, T2, T6, T8 and T10 need to be un-
done. Since they are not control dependent on any bad task,
they need to be redone, as stated in case 1 of Theorem 3.
Since neither task T3 nor task T4 meets the requirements of
Theorem 3, they do not need to be redone. They are sim-
ply not on the re-executing path of the workﬂow. Redoing
them will generate dirty data because redoing them does not
meet the speciﬁcation of the workﬂow.
3.5. Partial Orders Caused by Dependency Rela-
tions
Since undo and redo tasks are not deﬁned by workﬂow
speciﬁcations we must create partial order relations among
these tasks and normal workﬂow tasks to guarantee the cor-
rectness of recovery. The following two theorems give the
partial order relations among recovery tasks and new work-
ﬂow tasks.
As we mentioned before, in order to guarantee correct
semantics, from the point of view of recovery tasks, there
is only a single version for each object, so all data depen-
dency relations are not broken among recovery tasks.
Theorem 4 (Partial ordering of recovery tasks) Given
the recovery tasks R and the system log (cid:8)L,≺(cid:9) the follow-
ing rules derive scheduled precedence orders between any
two tasks in R.
1. Ti ≺ Tj ⇒ redo(Ti) ≺s redo(Tj)
2. Ti → Tj ⇒ redo(Ti) ≺s redo(Tj)
3. ∀Ti, undo(Ti) ≺s redo(Ti)
4. Ti →a Tj ⇒ undo(Tj) ≺s redo(Ti)
5. Ti →o Tj ⇒ undo(Tj) ≺s undo(Ti)
6. Ti →c Tj, Tj ∈ ST (Ti) ⇒ redo(Ti) →c redo(Tj) ∧
7. Ti →c Tj, Tj ∈ SF (Ti) ⇒ redo(Ti) →c redo(Tj) ∧
8. Ti ∈ B, Tj ∈ L, Ti →∗
9. Ti ∈ B,∃Tk /∈ L, Ti →∗
redo(Tj) ∈ ST (redo(Ti))
redo(Tj) ∈ SF (redo(Ti))
⇒ redo(Ti) →c redo(Tj)∧undo(Tj) ∈ ST (redo(Ti))
f Tj and Tk ∈
ST (redo(Ti))
⇒ redo(Ti) →c undo(Tj)∧undo(Tj) ∈ ST (redo(Ti))
c Ti, Ti ∈ ST (redo(Tj)) ⇒
redo(Ti) →c redo(Tj) ∧ redo(Tj) ∈ ST (redo(Ti))
10. Ti ∈ B,∃Tj ∈ B, Tj →∗
c Tj and Tj ∈ SF (redo(Ti))
c Tk, Tk →∗
using a single copy of data objects, which means an old
value will be lost after writing.
We have the following theorem using the assumption of
single-version data objects.
Theorem 5 (Partial ordering of normal tasks) Given the
recovery tasks R, new workﬂow tasks N , and the system
log (cid:8)L,≺(cid:9), if every data object has only one copy, the fol-
lowing rules derive scheduled preceding orders for any two
tasks in R ∪ N .
1. Ti ≺ Tj, Ti, Tj ∈ N ⇒ Ti ≺s Tj
2. (Ti →f Tj) ∨ (Ti →a Tj) ∨ (Ti →o Tj) ∨ (Ti →c
f Tj, Tk /∈ L ∪ N , Tj ∈ N ⇒
3. Ti →∗
Tj), Tj ∈ N ⇒ undo(Ti) ≺s redo(Ti) ≺s Tj
undo(Ti) ≺s redo(Ti) ≺s Tj
c Tk, Tk →∗
PROOF: See appendix.
Theorem 5 shows that normal tasks cannot be executed
before the generation of a recovery scheme is complete. In
other words, we can run normal tasks if, and only if, all
malicious tasks reported by the IDS have been processed,
which may cause temporary delay of services when attack-
ing rate is high.
Theorem 5 is derived from the assumption that every
data object has one copy. If the data object was changed
the value would be lost. Theorem 5 tells us that achiev-
ing no stop service cannot without multiple copies (ver-
sions) of data objects and full information about possible
normal tasks and recovery tasks. Multi-version data objects
can solve the problem.
In Theorem 5, rule 1 states that the execution of nor-
mal tasks should abide by the speciﬁcation of workﬂows.
Rule 2 and rule 3 describe restrictions of executing orders
among recovery tasks and normal tasks. With the use of re-
vision histories, anti-ﬂow and output dependencies are bro-
ken while ﬂow and control dependencies are not. From the
proof of Theorem 5 we know that running recovery tasks
and normal tasks in parallel with their corresponding revi-
sion history will not corrupt recovery tasks while we must
take the risks of corrupting normal tasks. Since we can still
chase damage spreading by dependency relations, corrup-
tion of normal tasks is not a problem and damage can be re-
paired later.
4. The Recovery System
4.1. Revision History
PROOF: See appendix.
Usually we prefer not to stop the services of the work-
ﬂow system while carrying out the recovery. For the pur-
pose of running both the recovery tasks and normal work-
ﬂow tasks concurrently, let us see what will happen when