(cid:30)(cid:3)(cid:32)(cid:11)(cid:30)(cid:6)(cid:7)(cid:8)
(cid:8)(cid:2)(cid:29)(cid:32)(cid:28)(cid:6)(cid:7)(cid:8)
(cid:30)(cid:34)(cid:15)(cid:27)(cid:26)(cid:6)(cid:7)(cid:8)
(cid:2)(cid:14)(cid:4)(cid:1)(cid:6)(cid:14)(cid:4)(cid:1)(cid:7)(cid:6)
(cid:6)(cid:1)(cid:6)(cid:4)(cid:13)(cid:14)(cid:4)(cid:14)(cid:3)
(cid:16)(cid:21)(cid:2)(cid:32)(cid:28)(cid:6)(cid:7)(cid:8)
(cid:31)(cid:14)(cid:1)(cid:33)(cid:13)(cid:6)(cid:7)(cid:8)
(cid:29)(cid:27)(cid:15)(cid:22)(cid:21)(cid:6)(cid:7)(cid:8)
(cid:19)(cid:14)(cid:35)(cid:26)(cid:26)(cid:6)(cid:7)(cid:8)
(cid:2)(cid:13)(cid:34)(cid:19)(cid:38)(cid:6)(cid:7)(cid:8)
(cid:18)(cid:27)(cid:13)(cid:8)(cid:21)(cid:6)(cid:7)(cid:8)
(cid:17)(cid:22)(cid:11)(cid:7)(cid:5)(cid:6)(cid:7)(cid:8)
(cid:25)(cid:12)(cid:5)(cid:13)(cid:11)(cid:6)(cid:7)(cid:8)
(cid:32)(cid:15)(cid:14)(cid:1)(cid:18)(cid:6)(cid:7)(cid:8)
(cid:5)(cid:5)(cid:5)(cid:24)(cid:23)(cid:6)(cid:7)(cid:8)
(cid:11)(cid:10)(cid:10)(cid:31)(cid:30)(cid:6)(cid:7)(cid:8)
(cid:4) (cid:1)(cid:34)(cid:38)(cid:35)(cid:6)(cid:7)(cid:8)
(cid:23)(cid:3)(cid:34)(cid:29)(cid:20)(cid:6)(cid:7)(cid:8)
(cid:35)(cid:35)(cid:18)(cid:26)(cid:13)(cid:6)(cid:7)(cid:8)
(cid:24)(cid:19)(cid:38)(cid:32)(cid:36)(cid:6)(cid:7)(cid:8)
(cid:31)(cid:25)(cid:20)(cid:31)(cid:15)(cid:6)(cid:7)(cid:8)
(cid:18)(cid:7)(cid:21)(cid:32)(cid:25)(cid:6)(cid:7)(cid:8)
(cid:1)(cid:2)(cid:3)(cid:4) (cid:5)(cid:6)(cid:7)(cid:8)
(cid:19)(cid:22)(cid:19)(cid:13)(cid:23)(cid:6)(cid:7)(cid:8)
(cid:14)(cid:8)(cid:17)(cid:11)(cid:15)(cid:6)(cid:7)(cid:8)
(cid:22)(cid:2)(cid:18)(cid:15)(cid:35)(cid:6)(cid:7)(cid:8)
(cid:36)(cid:14)(cid:15)(cid:28)(cid:38)(cid:6)(cid:7)(cid:8)
(cid:10)(cid:16)(cid:15)(cid:25)(cid:36)(cid:6)(cid:7)(cid:8)
(cid:31)(cid:33)(cid:33)(cid:4) (cid:12)(cid:6)(cid:7)(cid:8)
(cid:13)(cid:38)(cid:19)(cid:13)(cid:16)(cid:6)(cid:7)(cid:8)
(cid:27)(cid:25)(cid:34)(cid:15)(cid:35)(cid:6)(cid:7)(cid:8)
(cid:30)(cid:21)(cid:12)(cid:20)(cid:22)(cid:28)(cid:6)(cid:7)(cid:8)
(cid:13)(cid:18)(cid:33)(cid:1)(cid:7)(cid:6)(cid:7)(cid:8)
(cid:34)(cid:24)(cid:18)(cid:38)(cid:27)(cid:6)(cid:7)(cid:8)
(cid:4) (cid:5)(cid:24)(cid:28)(cid:2)(cid:6)(cid:7)(cid:8)
(cid:33)(cid:1)(cid:17)(cid:16)(cid:25)(cid:6)(cid:7)(cid:8)
(cid:36)(cid:29)(cid:22)(cid:4) (cid:8)(cid:6)(cid:7)(cid:8)
(cid:25)(cid:10)(cid:5)(cid:7)(cid:26)(cid:6)(cid:7)(cid:8)
(cid:13)(cid:16)(cid:23)(cid:30)(cid:5)(cid:6)(cid:7)(cid:8)
(cid:35)(cid:14)(cid:13)(cid:4) (cid:1)(cid:6)(cid:7)(cid:8)
(cid:14)(cid:21)(cid:26)(cid:7)(cid:12)(cid:6)(cid:7)(cid:8)
(cid:16)(cid:18)(cid:8)(cid:13)(cid:13)(cid:6)(cid:7)(cid:8)
(cid:20)(cid:17)(cid:12)(cid:37)(cid:23)(cid:6)(cid:7)(cid:8)
(cid:20)(cid:30)(cid:8)(cid:15)(cid:19)(cid:6)(cid:7)(cid:8)
(cid:22)(cid:10)(cid:1)(cid:21)(cid:4) (cid:30)(cid:6)(cid:7)(cid:8)
(cid:30)(cid:30)(cid:12)(cid:2)(cid:21)(cid:6)(cid:7)(cid:8)
(cid:26)(cid:24)(cid:15)(cid:7)(cid:7)(cid:28)(cid:6)(cid:7)(cid:8)
(cid:11)(cid:22)(cid:3)(cid:5)(cid:26)(cid:6)(cid:7)(cid:8)
(cid:27)(cid:4) (cid:13)(cid:37)(cid:12)(cid:6)(cid:7)(cid:8)
(cid:8)(cid:24)(cid:18)(cid:1)(cid:37)(cid:6)(cid:7)(cid:8)
(cid:3)(cid:2)(cid:2)(cid:13)(cid:32)(cid:6)(cid:7)(cid:8)
(cid:31)(cid:26)(cid:7)(cid:37)(cid:19)(cid:6)(cid:7)(cid:8)
(cid:7)(cid:38)(cid:4) (cid:4) (cid:31)(cid:6)(cid:7)(cid:8)
(cid:14)(cid:10)(cid:2)(cid:1)(cid:21)(cid:6)(cid:7)(cid:8)
(cid:29)(cid:24)(cid:22)(cid:34)(cid:21)(cid:6)(cid:7)(cid:8)
(cid:20)(cid:36)(cid:21)(cid:4) (cid:8)(cid:6)(cid:7)(cid:8)
(cid:31)(cid:34)(cid:12)(cid:3)(cid:31)(cid:6)(cid:7)(cid:8)
(cid:13)(cid:11)(cid:2)(cid:29)(cid:12)(cid:6)(cid:7)(cid:8)
(cid:33)(cid:33)(cid:5)(cid:3)(cid:10)(cid:6)(cid:7)(cid:8)
(cid:12)(cid:25)(cid:23)(cid:37)(cid:34)(cid:6)(cid:7)(cid:8)
(cid:13)(cid:16)(cid:2)(cid:16)(cid:27)(cid:6)(cid:7)(cid:8)
(cid:25)(cid:3)(cid:23)(cid:21)(cid:10)(cid:6)(cid:7)(cid:8)
(cid:10)(cid:24)(cid:37)(cid:20)(cid:22)(cid:6)(cid:7)(cid:8)
(cid:30)(cid:36)(cid:22)(cid:10)(cid:2)(cid:6)(cid:7)(cid:8)
(cid:16)(cid:30)(cid:4) (cid:4) (cid:2)(cid:17)(cid:6)(cid:7)(cid:8)
(cid:11)(cid:8)(cid:10)(cid:34)(cid:38)(cid:6)(cid:7)(cid:8)
(cid:19)(cid:19)(cid:15)(cid:22)(cid:12)(cid:6)(cid:7)(cid:8)
(cid:36)(cid:35)(cid:17)(cid:31)(cid:5)(cid:6)(cid:7)(cid:8)
(cid:25)(cid:18)(cid:36)(cid:21)(cid:11)(cid:6)(cid:7)(cid:8)
(cid:28)(cid:32)(cid:11)(cid:33)(cid:26)(cid:6)(cid:7)(cid:8)
(cid:15)(cid:10)(cid:13)(cid:33)(cid:26)(cid:37)(cid:6)(cid:7)(cid:8)
(cid:8)(cid:26)(cid:37)(cid:37)(cid:15)(cid:6)(cid:7)(cid:8)
(cid:5)(cid:11)(cid:18)(cid:19)(cid:5)(cid:6)(cid:7)(cid:8)
(cid:11)(cid:20)(cid:25)(cid:36)(cid:3)(cid:20)(cid:6)(cid:7)(cid:8)
(cid:29)(cid:23)(cid:23)(cid:35)(cid:7)(cid:6)(cid:7)(cid:8)
(cid:27)(cid:13)(cid:18)(cid:37)(cid:31)(cid:6)(cid:7)(cid:8)
(cid:5)(cid:30)(cid:24)(cid:31)(cid:19)(cid:6)(cid:7)(cid:8)
(cid:4) (cid:38)(cid:7)(cid:10)(cid:36)(cid:20)(cid:6)(cid:7)(cid:8)
(cid:1)(cid:4) (cid:1)(cid:37)(cid:34)(cid:6)(cid:7)(cid:8)
(cid:20)(cid:19)(cid:22)(cid:22)(cid:4) (cid:6)(cid:7)(cid:8)
(cid:38)(cid:33)(cid:17)(cid:10)(cid:33)(cid:6)(cid:7)(cid:8)
(cid:2)(cid:13)(cid:12)(cid:21)(cid:16)(cid:6)(cid:7)(cid:8)
(cid:4) (cid:11)(cid:38)(cid:18)(cid:7)(cid:6)(cid:7)(cid:8)
(cid:34)(cid:36)(cid:26)(cid:36)(cid:3)(cid:6)(cid:7)(cid:8)
(cid:37)(cid:3)(cid:36)(cid:20)(cid:29)(cid:6)(cid:7)(cid:8)
(cid:27)(cid:32)(cid:5)(cid:19)(cid:22)(cid:6)(cid:7)(cid:8)
(cid:10)(cid:13)(cid:18)(cid:14)(cid:34)(cid:6)(cid:7)(cid:8)
(cid:21)(cid:4) (cid:17)(cid:14)(cid:17)(cid:6)(cid:7)(cid:8)
(cid:12)(cid:31)(cid:13)(cid:37)(cid:15)(cid:6)(cid:7)(cid:8)
(cid:12)(cid:2)(cid:18)(cid:11)(cid:38)(cid:6)(cid:7)(cid:8)
(cid:21)(cid:33)(cid:17)(cid:25)(cid:16)(cid:6)(cid:7)(cid:8)
(cid:37)(cid:11)(cid:16)(cid:21)(cid:19)(cid:6)(cid:7)(cid:8)
(cid:8)(cid:37)(cid:8)(cid:15)(cid:13)(cid:6)(cid:7)(cid:8)
(cid:27)(cid:5)(cid:24)(cid:17)(cid:4) (cid:6)(cid:7)(cid:8)
(cid:17)(cid:38)(cid:26)(cid:4) (cid:30)(cid:6)(cid:7)(cid:8)
(cid:11)(cid:28)(cid:34)(cid:25)(cid:16)(cid:6)(cid:7)(cid:8)
(cid:21)(cid:26)(cid:20)(cid:29)(cid:11)(cid:6)(cid:7)(cid:8)
(cid:7)(cid:8)(cid:9)(cid:2)(cid:10)(cid:11)(cid:12)(cid:13)(cid:8)(cid:14)(cid:6)(cid:15)(cid:16)
(cid:18)(cid:4) (cid:22)(cid:12)(cid:11)(cid:6)(cid:7)(cid:8)
(cid:3)(cid:34)(cid:17)(cid:12)(cid:7)(cid:6)(cid:7)(cid:8)
(cid:19)(cid:34)(cid:33)(cid:5)(cid:31)(cid:6)(cid:7)(cid:8)
(cid:36)(cid:38)(cid:18)(cid:10)(cid:10)(cid:6)(cid:7)(cid:8)
(cid:4) (cid:4) (cid:10)(cid:37)(cid:35)(cid:6)(cid:7)(cid:8)
(cid:6)(cid:6)(cid:8)(cid:22)(cid:23)(cid:24)(cid:8)(cid:6)(cid:12)(cid:12)(cid:15)
(cid:12)(cid:6)(cid:8)(cid:16)(cid:17)(cid:18)(cid:8)(cid:6)(cid:12)(cid:12)(cid:15)
(cid:6)(cid:12)(cid:8)(cid:16)(cid:17)(cid:18)(cid:8)(cid:6)(cid:12)(cid:12)(cid:15)
(cid:6)(cid:7)(cid:8)(cid:19)(cid:20)(cid:21)(cid:8)(cid:6)(cid:12)(cid:12)(cid:15)
(cid:12)(cid:5)(cid:8)(cid:25)(cid:10)(cid:17)(cid:8)(cid:6)(cid:12)(cid:12)(cid:15)
(cid:1)(cid:7)(cid:8)(cid:9)(cid:10)(cid:11)(cid:8)(cid:6)(cid:12)(cid:12)(cid:13)
(cid:6)(cid:7)(cid:8)(cid:9)(cid:10)(cid:11)(cid:8)(cid:6)(cid:12)(cid:12)(cid:13)
(cid:6)(cid:2)(cid:8)(cid:9)(cid:10)(cid:11)(cid:8)(cid:6)(cid:12)(cid:12)(cid:13)
(cid:2)(cid:3)(cid:4)(cid:14)(cid:14)(cid:4)(cid:5)(cid:13)
Fig. 2. Graphical representation of a long lasting, larger campaign
composed of exactly 5 alphanumeric characters, apparently chosen in a random
fashion (wxe3x.cn, owvmg.cn,...), which indicates the use of automated tools
to create those domains. Another noteworthy characteristic of this campaign is
that the registrant responsible for 76% of the domains makes use of a WHOIS
domain privacy protection service (PI:EMAIL), which we have said to
be a commonly observed characteristic in certain rogue campaigns.
Finally, a manual analysis of the domains represented in Figure 2 revealed a
more complex underlying ecosystem. These domains were in fact linking to a fake
scan page hosted on a server belonging to a separate campaign. Such discovery
underlines the existence of complex interrelations in this threat ecosystem, inter-
relations that would have been impossible to discover without the employment
of data mining techniques able to reduce a corpus of thousands of domains to
few, large campaigns carried out by speciﬁc individuals.
PC-Security and PC-Anti-Spyware campaigns. One very good example of
such interrelation can be found when looking at two other distinct clusters iden-
tiﬁed by our approach. The multi-criteria decision algorithm correctly identiﬁed
An Analysis of Rogue AV Campaigns
455
them as two distinct campaigns, as they involve diﬀerent features (diﬀerent tim-
ings, diﬀerent web servers, etc.). However, the analysis of both clusters reveals
a common modus operandi used in both cases.
Indeed, the two clusters were composed of a relatively low number of domains
(16 and 14) that were clearly referring to anti-virus or anti-spyware “products”
(e.g., pcsecurity-2009.com, homeav-2010.com, pc-antispyware2010.com). A num-
ber of similarities could be identiﬁed in their deployment strategy:
– Both clusters use the exact same domain naming scheme, consisting of the in-
sertion of dashes among a set of ﬁxed words (e.g., pc-anti-spyware-2010.com,
pc-anti-spyware-20-10.com, and pc-antispyware-2010.com).
– All of the domains in each cluster use the same registrar (OnlineNIC) and
are serviced by the same two ISPs.
– The email addresses of all domain registrants are in “.ru” domains.
– The servers were on consecutive IP addresses, although the two clusters were
associated to servers in completely diﬀerent networks.
Perhaps even more conclusively, upon manual inspection we found that the con-
tent of each site was identical, with the exception of one diﬀering image. All this
leads us to assume that the deployment of the rogue AV domains was carried out
with a good degree of automation by interacting with a single registrar. It is also
worth noting that both clusters are split between two diﬀerent ISPs, suggesting
an attempt to provide some level of redundancy in case a cluster is taken oﬄine
by the ISP. Finally, we observed that all of the hosting web servers were located
in the US. We refer the interested reader to [25] for a more detailed presentation
of these two results, as well as other interesting ones.
5 Landscape Characteristics
Section 4 provided an in-depth overview of the rogue AV threat landscape, and
showed our ability to identify within such landscape articulated campaigns de-
ployed via a certain level of automation. The speciﬁcity of these characteristics to
the Rogue AV landscape stays although unproved so far. This Section addresses
this problem by performing a comparative analysis of the results obtained for the
Rogue AV landscape with those obtained by looking at a completely diﬀerent
web-borne threat: drive-by downloads. We will show that the complexity of the
identiﬁed campaigns is a very speciﬁc characteristic of the rogue AV landscape,
and we will go further by looking into the economics of this landscape, showing
that the particularly large return on investment largely justiﬁes the complexity
of the observed infrastructure.
5.1 Comparison with Drive-By Downloads
The methodology proposed so far is completely generic, and can be utilized
equivalently to study the characteristics of the infrastructure underlying any
web-borne threat. We have therefore decided to leverage this fact to compare
456
M. Cova et al.
our ﬁndings for the rogue AV threat with those of a speciﬁc type of drive-by
download. To do so, we have constructed a second dataset taking advantage
of data generated by some internal web crawlers and used it as an additional
URL feed for HARMUR. Among all the exposed threats, we have chosen to
focus on all the landing sites (we use “landing site” as in [19] to denote the
site that initiates a drive-by download) that exploited a very speciﬁc weakness,
namely the Internet Explorer ADODB.Stream Object File Installation Weakness
(CVE-2006-0003). We have thus repeated the very same experiment as the one
performed on the rogue AV dataset, collecting information on the very same
network observables and using such information to build domain features for the
multi-criteria analysis technique.
While the multi-criteria approach could successfully identify 127 distinct clus-
ters in the rogue AV dataset, 39 of which accounted for more than 60% of the
domains, the clustering proﬁle is very diﬀerent when looking at the browser
exploits web sites. Only 15 small clusters have been identiﬁed, accounting for
only 201 domains (3.8%). This means that the vast majority of domains (96.2%)
did not end up in any cluster. In other words, the very same approach that
allowed us to identify large correlations within the rogue AV domains seems
to be incapable of detecting any signiﬁcant correlation in the browser exploit
landscape. The reason for this striking diﬀerence can be found in the diﬀerent
modus operandi associated to these two threat classes. Our methodology aims
at identifying correlations indicative of a shared ownership and management of a
set of domains. In rogue security software, the infrastructure in charge of luring
the victims into installing the products is maintained by the criminals them-
selves. This includes both the cost of registering the domains and maintaining
the hardware, but also the eﬀort of attracting the users towards it.
This does not seem to happen in the drive-by downloads threat landscape: in
the vast majority of cases, the landing pages in charge of exploiting the clients
are owned and maintained by uncorrelated individuals. As showed also in [19],
drive-by downloads mainly operate by compromising legitimate domains that
implement weak security practices. What motivates the individuals at the root
of the rogue AV threat infrastructure to sustain the additional cost of directly
deploying and maintaining these domains? Providing an answer to this question
requires a better understanding on the costs and the revenues associated to the
deployment of a rogue AV campaign.
5.2 Rogue AV Monetization
Data collection. The problem of studying the victims of online attacks has
received much attention in the past few years. The crux of the problem is that
attacks and victims are geographically and temporally distributed, and, as a
consequence, there is generally no natural vantage point that researchers can
leverage to perform their monitoring.
One approach to overcome this problem consists of performing passive mea-
surements of the secondary eﬀects of victims’ activity. For example, in the
context of spam botnets, researchers have used spam messages [31] and DNS
An Analysis of Rogue AV Campaigns
457
queries [20,22] as proxy indicators of infected machines. Active approaches are
also possible. For example, in some cases, researchers have been able to inﬁl-
trate part of the attackers’ infrastructure, and, thus, gain visibility of its victims
directly from “the inside” [12,24].
These are interesting approaches, yet sometimes diﬃcult to implement for
practical or legal reasons. Therefore, we decided to use a novel approach to
collect information “remotely from the inside”.
Indeed, we observed that, in a number of cases, the servers hosting rogue AV
sites were conﬁgured to collect and make publicly available statistics about their
usage. These servers were Apache web servers using the mod status module,
which provides a page (by default, reachable at the /server-status location)
with real-time statistics about the server status, such as the number of workers
and the count of bytes exchanged. When the module is conﬁgured to generate
“extended status” information, it also provides information about the requests
being currently processed, in particular, the address of the client issuing a request
and the URL that was requested.
We note that the server status data source has a few limitations. In particular,
it does not give access to the content of the communications between clients and
servers. As a result, we cannot be certain of the outcome of any access: often-
times, we will see that the same web page (URL) is accessed, without knowing if
the access was successful or not. Second, the server status page only provides the
IP address of each victim. It is well known that, mostly due to NAT and DHCP
eﬀects, IP addresses are only an approximate substitute for host identiﬁers, and,
due to the lack of visibility into the client-server traﬃc, we cannot use existing
techniques to mitigate this problem [3,29]. Despite these limitations, the server
status data allows us to gain some visibility into the access behavior of rogue
AV clients.
Victim access dataset. In total, we identiﬁed 30 servers that provided status
information. Of these, 6 also provided information about client requests, which is
critical for our analysis. We continuously sampled the server status pages of each
of these 6 servers over a period of 44 days and stored the access time, source IP
address of the client, and the speciﬁc URL on the server that was accessed. The 6
servers hosted 193 active rogue AV domains, and an additional 4,031 domains, 62
of which were also rogue AV sites but did not receive any traﬃc. The remaining
3,969 co-located domains are a mix of malware-serving and benign sites. We
then removed from our dataset requests that were not directed at rogue AV sites
or that consisted only of probing or scanning attempts. After this ﬁltering, we
identiﬁed 372,096 distinct client IP addresses that interacted with the rogue AV
servers during our observation period.
Localization and server usage. Clients from all around the world interacted with
the rogue AV servers. The countries that were most visiting them were USA
(147,729 distinct client IPs), UK (20,275), and Italy (12,413). Some rogue AV
sites appear to be more popular than others, in terms of the distinct client IP
addresses that were served by each. A number of sites only received a handful of
458
M. Cova et al.
Home page
Email Link
Redirect
Link from other site
Fake scan
Update check
Purchase
Report
Purchase conﬁrmation
Download
Fig. 3. Typical sequence of accesses by client
clients; in fact, 27 of the rogue AV sites were visited by only 1 client (probably
an indication that these sites were no longer, or not yet, actively used). The
average number of distinct client IP addresses per rogue AV site was 2,557, with
a median of 560 and a standard deviation of 5,405. The 10 most popular rogue
AV sites are listed in Table 3.
Access behavior. By clustering the requests issued by the clients according to the
requested URL’s path, we identiﬁed 6 diﬀerent request types: scan, purchase,
purchase conﬁrmation, download, report, and update check. Figure 4 presents
the cumulative count of distinct clients (IP addresses) that were observed issuing
each type of request. (The presence of the same type of requests on diﬀerent sites
is probably an indication that many rogue AV sites are built on top of the same
“rogue AV toolkit.”)
As represented in Figure 3, these requests correspond to distinct phases with
respect to the interaction of victims with rogue AV sites. A user that is somehow
redirected to one of these servers is typically presented with the option to run
Table 3. Most accessed rogue AV sites
Rank
Site
Clients (#)
1 windoptimizer.com
2 inb4ch.com
3 scan6lux.com
4 gobackscan.com
5 pattle.info
6 goscansnap.com
7 goscanback.com
8 tranks.info
9 cherly.info
10 phalky.info
55,889
23,354
21,963
19,057
14,828
14,590
11,347
10,050
9,875
9,836
Fig. 4. Cumulative clients activity
An Analysis of Rogue AV Campaigns
459
a scan (typically perfunctory) of their computer. The goal of the scan is to
scare users into downloading the rogue AV, by reporting that a large number of
malware (viruses, Trojans, etc.) and other threats are present on their computers.
If the scan is successful in this goal, the user will click through to a purchase page,
or to a “free” download page. In the former case, users enter their information,
including payment details (typically a credit card), and are presented with a
purchase conﬁrmation page. If the charge is successful, or for sites that oﬀer a
free “trial” version of rogue AV software, the user is redirected to a download
page. Once it is successfully installed on the user’s computer, the rogue AV
software will periodically check for updates by querying a speciﬁc URL on the
server. In certain cases, it will also report back to the server the occurrence
of speciﬁc events (e.g., the download of new updates). During our monitoring,
each site handled only a few types of requests. More precisely, a large number of
sites were devoted to handling only scan requests, while payment requests were
directed at only 7 sites. We speculate that this separation of tasks simpliﬁes
the management of the campaign: even when a scan site is taken down, the
processing of payments remains unaﬀected.
Monetization. To determine the success rate of rogue AV servers in convincing