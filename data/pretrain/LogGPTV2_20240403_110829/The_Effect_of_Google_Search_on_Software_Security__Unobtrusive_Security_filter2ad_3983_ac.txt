The distribution of insecure results shown in Figure 2, (CIPHER,
ğ‘¡10, red) is not very different from IV and KEY. ğµ(10, 0.077) revealed
a 37.77% chance for at least one result, 14.05% for two, and 3.16%
for three results. We observed very similar probabilities of insecure
results in ğ‘¡5 and ğ‘¡3 as observed for IV and KEY. ğµ(5, 0.089) revealed
a 30.24% chance and ğµ(3, 0.065) a 17.70% chance for one insecure
result to be in ğ‘¡5 and ğ‘¡3, respectively.
Summaryâ€” Study 1 has shown that the distribution of insecure
Stack Overflow results in the top tiers ğ‘¡3, ğ‘¡5, and ğ‘¡10 is significantly
higher than the distribution of secure Stack Overflow results. This
was the case for all three tasks that were performed by our partici-
pants. Moreover, the probability of insecure results to end up in ğ‘¡3
is higher than for lower ranks.
These observations led to the following research questions: Does
the higher ranking of insecure Stack Overflow code examples actu-
ally have a negative impact on code security? Further, does security-
based re-ranking help in mitigating this effect by down-ranking
insecure and up-ranking secure results? We first present our ap-
proach for security-based re-ranking in the following Section 5 and
investigate both research questions in Study 2 in Section 6.
5 SECURITY-BASED RE-RANKING
In Section 4.5, we have shown that Google Search currently up-
ranks Stack Overflow results that provide insecure cryptographic
code. We introduce security-based re-ranking to tackle this problem.
In a nutshell, based on the security label of a webpageâ€™s content
(i. e., source code), its rank is updated by either lowering or raising
it.
This would help developers to start their Web search on a safe
path. In fact, the Web offers secure best-practice examples that
help developers to finish their programming tasks functionally
and securely for a wide range of use cases [18]. Boosting those
examples in Google Search while simultaneously lowering the rank
of insecure results could have a ripple effect on the code security
of production software.
In this section, we describe how we identified secure best-practice
examples in TUM-Crypto and how we re-ranked results based on
security. We continue to use the labeling function ğ‘™ğ‘¡1 to determine
the security of webpages.
5.1 Secure Best-Practice Examples
A secure Stack Overflow webpage is labeled as a best-practice re-
sult if it is secure with respect to ğ‘™ğ‘¡1 and provides at least one
best-practice example for IV or KEY. An example is a code snippet
which gives the complete API usage pattern for how to safely gen-
erate a cryptographic key or an IV (see Figure 9 in the Appendix).
We distinguish secure best-practice from secure examples. A secure
code example is not a best-practice example if the API usage pattern
is incomplete. This means that the example does not show how
to safely implement all necessary dependencies of IV or KEY. For
instance, it does not show how to initialize a secure random number
generator which is necessary to generate a cryptographic key. In
practice, popular (but misleading) examples are code snippets that
show how to encrypt a string using a key that is passed through
a method parameter. Even though these examples may be secure
(in terms of not being insecure), developers will not learn the com-
plete pattern since key generation is missing. We do not make this
differentiation for CIPHER since initializing a CIPHER using the
Java SDK is done within a single statement that does not have any
dependencies.
We will show in later sections that patterns are incomplete for
most secure KEY and IV examples on Stack Overflow. This causes
the following problem: developers may be presented with secure
but unhelpful code. This forces them to continue the code search,
potentially leaving the secure path, ending up reusing insecure code
once again. By up-ranking secure best practices, there is higher
probability that developers start and stay on a safe path.
5.2 Code Embeddings
We have followed a semi-supervised methodology to identify secure
best-practice examples in TUM-Crypto. We first applied DBSCAN,
an unsupervised clustering method to cluster secure API usage
patterns for the use cases KEY and IV. Those provide the most
diverse patterns available in the dataset as shown in [18]. Note, our
clustering method does not separate secure from insecure patterns,
but is solely applied to secure ones to separate best practices from
potentially less helpful examples.
The advantage of DBSCAN is that it does not need to know the
number of expected clusters in advance. Since its clustering method
is performed on input vectors, we need vector representations for
the API usage patterns. In Fischer et al. [18], we have trained a
deep learning model that generated embeddings for API usage
patterns from TUM-Crypto. These embeddings were learned such
that similar patterns are close, and dissimilar ones are far away
from each other in the embedding space, using cosine distance
as the distance metric. The learned embeddings encode data and
control dependencies of code graphs, as well as lexical information
of code statements. We used them as inputs for DBSCAN because it
supports clustering based on cosine distance. Please refer to [18, 54]
for further details on the generation of the embeddings.
5.3 Best-Practice Clustering
DBSCAN automatically creates clusters based on two parameters:
the maximum distance ğœ– of an embedding to the core sample of the
cluster, and the minimum number of embeddings ğ‘šğ‘–ğ‘›ğ‘ƒğ‘¡ğ‘  necessary
to form a cluster. It does not require the number of clusters to be
Session 11C: Software Development and Analysis CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea3075(a) IV, ğ‘¡10
(b) IV, ğ‘¡3
(c) KEY, ğ‘¡10
(d) KEY, ğ‘¡3
Figure 3: Parameter search for boosting results for IV and KEY. The horizontal axis represents boost values and the vertical
axis the probability of a secure best-practice or a secure or insecure result to appear in the top ten results.
known in advance as it is determined based on these parameters.
Embeddings that cannot be assigned to a cluster end up in the noise
cluster ğ‘ .
After we obtained the set of clusters ğ¶ := ğ·ğµğ‘†ğ¶ğ´ğ‘ (ğœ–, ğ‘šğ‘–ğ‘›ğ‘ƒğ‘¡ğ‘ ) \
ğ‘ for a given pair of ğœ– and ğ‘šğ‘–ğ‘›ğ‘ƒğ‘¡ğ‘ , we looked at exactly on rep-
resentative ğ‘ğ‘– for each cluster ğ¶ğ‘– âˆˆ ğ¶ to determine whether it is a
secure best practice, or not. This way manual labeling effort is given
by cardinality |ğ¶|, and its reduction ğ‘Ÿğ‘™ğ‘ğ‘ given by ğ‘Ÿğ‘™ğ‘ğ‘ = 1âˆ’ |ğ¶|/|ğ¸|,
where ğ¸ is the set of embeddings generated from all samples in
TUM-Crypto.
We wanted to keep the manual labeling effort as low as possible
and therefore ğ‘Ÿğ‘™ğ‘ğ‘ close to 1. Additionally, we wanted the clustering
to be as accurate as possible in order not to miss any best-practice
examples. Therefore, the size of the noise cluster |ğ‘ | needs to be
as small as possible, as well as the biggest cluster ğ¶ğ‘šğ‘ğ‘¥ âˆˆ ğ¶. These
three objectives are competing with each other. Smaller |ğ‘ | leads
to more clusters |ğ¶| and to smaller ğ‘Ÿğ‘™ğ‘ğ‘.
It follows that we had to solve the following multi-objective
optimization task: Choose parameters ğœ– and ğ‘šğ‘–ğ‘›ğ‘ƒğ‘¡ğ‘  that maxi-
mize ğ‘Ÿğ‘™ğ‘ğ‘, while minimizing the percentage of the biggest cluster
|ğ¶ğ‘šğ‘ğ‘¥|/|ğ¸|, |ğ¶ğ‘šğ‘ğ‘¥| â‰¥ |ğ¶ğ‘–|,âˆ€ğ¶ğ‘– âˆˆ ğ¶ and the percentage of the noise
cluster |ğ‘ |/|ğ¸|.
The smaller |ğ¶|, the smaller the manual effort ğ‘Ÿğ‘™ğ‘ğ‘. The bigger
ğ¶ğ‘šğ‘ğ‘¥, the higher the chance ğœ– has been chosen too large; thereby
insufficiently differentiating between API patterns. If |ğ‘ | becomes
too large, it might contain best-practice examples that would be
missed since the noise cluster naturally will not be considered for
manual inspection.
5.4 Pareto Optimum
We determined the optimal parameter by performing a grid search
for a Pareto-optimal solution. Thereby, we calculated all values for
labeling effort, noise, and maximum cluster size during the grid
search with the objective to minimize them. The grid was given by
ğœ– âˆˆ [0.0, 0.09] as we observed that |ğ¶| quickly converged to 1 for
bigger cosine distances than 0.09. We searched for ğ‘šğ‘–ğ‘›ğ‘ƒğ‘¡ğ‘  âˆˆ [2, 10],
as we only needed 10 best-practice examples to show in the top
ten tier of the Google Search results. Our search space was very
small. ğœ– was increased by 0.01 for each search, resulting in a grid
with dimension 10 Ã— 9.
We calculated the knee-points for the 3ğ‘‘ Pareto curve for all three
competing objectives and derived the related DBSCAN parameters
for IV and KEY. The results are shown in Table 3 in the Appendix.
Distance ğœ– was similar for both use cases with 0.3 and 0.4 and both
had a minimum cluster size of two. For both use cases, we reached
a noise level of around 10% of the respective example set. Those
examples were not considered for manual labeling.
We randomly selected a representative for each cluster and man-
ually reviewed the source code of the representative to decide
whether it is a best-practice example. If yes, all samples from the
related cluster were added to the set of best-practice examples of
the related class IV or KEY, respectively. The manual labeling effort
was below 10%, which resulted in 65 samples for IV and 114 samples
for KEY.
Finally, we evaluated the precision of the whole process. We
selected a maximum of 50 random samples from each secure best-
practice cluster and manually evaluated whether they were true
positives. We obtained a precision of 0.81 for KEY and 0.98 for IV.
None of the false positives were insecure.
5.5 Re-ranking
We implemented a CSE that updates the rank of Stack Overflow
results based on the security of the content and whether it pro-
vides best-practice examples. The CSE API provides functionality
to influence the ranking of search results. Those modifications are
domain-based. For a given URL, attributes can be defined in order to
boost their rank. For a given Stack Overflow link, our CSE assigns
the search function ğ‘ğ‘ ğ‘’ğ‘ a boost ğ‘ âˆˆ [âˆ’1, 1].
Parameter Searchâ€” Trivially, we set the boost value ğ‘ğ‘ğ‘ for
secure best-practice results to the maximum of ğ‘ğ‘ğ‘ = 1.0 and
for insecure results to the minimum of ğ‘ğ‘– = âˆ’1.0. We performed a
parameter search to find the optimal boost value ğ‘ğ‘  for secure results
that were not best practices. On the one hand, one would expect
those results to obtain a lower rank than secure best practices, since
they may be less helpful. On the other hand, one would require
them to have a higher rank than insecure results.
Therefore, they naturally compete with secure best-practice and
insecure results to obtain ranks in ğ‘¡10. If the boost for secure results
is too high, some secure best-practice results in ğ‘¡10 may be replaced
by secure results. If the boost is too low, some secure results may be
replaced by insecure ones. Therefore, the boost for secure results
has to be high enough to push insecure results further out of ğ‘¡10
while not interfering with secure best-practice results.
To find the optimal boost value for secure results, we repeated
our measurements from Study 1 (see Section 4). We calculated
probabilities ğ‘ = ğ‘Ÿ/ğ‘  for secure best-practice (ğ‘ğ‘ğ‘), secure (ğ‘ğ‘ ), and
Session 11C: Software Development and Analysis CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea3076Figure 4: Binomial distribution of boosted secure best-practice (green), secure (blue), and insecure results (red) for IV, KEY,
and CIPHER over ğ‘¡10. The ğ‘¥-axis represents the observed count of secure best-practice, secure, or insecure results in ğ‘¡10. The
ğ‘¦-axis shows the probability for each observation, i. e., there is a probability of ğ‘¦ that ğ‘¥ results are secure best-practice, secure,
or insecure in ğ‘¡10.
insecure results (ğ‘ğ‘–) to appear in ğ‘¡10. Here, ğ‘Ÿ was either the number
of secure best-practice, secure, or insecure results in ğ‘¡10, and ğ‘  the
total number of results in the respective tier. We calculated these
probabilities for different boost values ğ‘ğ‘  âˆˆ [âˆ’1, 1] for secure results
using an increment of 0.1. Boost values ğ‘ğ‘ğ‘ and ğ‘ğ‘– remained the
same. The results are shown in Figure 3.
Rank Trade-offâ€” For IV, maximum probability ğ‘ğ‘ğ‘ for secure
best-practices to appear in ğ‘¡10 and ğ‘¡3 was given for ğ‘ğ‘  = 0.1 (see
green line in Figure 3b). However, for KEY it was given for ğ‘ğ‘  =
âˆ’0.2 (see the green line in Figure 3c). Therefore, those two values
represented the upper and lower bound of ğ‘ğ‘ . To decide optimal
ğ‘ğ‘  âˆˆ [âˆ’0.2, 0.1] we searched for a point where the probability of
secure results was higher than for insecure results. Figure 3a shows
that ğ‘ğ‘  > 0.0 fulfilled this restriction for both tiers and all three
tasks. Probabilities of insecure results were the lowest in all four
plots. Therefore, we selected ğ‘ğ‘  = 0.1 as it was the next increment
in the interval and the upper bound. This solution led to a small
reduction of probabilities of secure best practices for KEY in ğ‘¡10 and
ğ‘¡3, as shown in Figure 3c and 3d. We considered this loss acceptable
in order to keep insecure probabilities low. Further, this led to an
additional gain for secure KEY results (see the blue line in Figure 3c
and 3d).
Since results for CIPHER are only separated into a secure and
insecure class, we did not have to include them in the parameter
search. Secure CIPHER results obtained ğ‘ğ‘  = 1.0 and insecure
results ğ‘ğ‘– = âˆ’1.0.
5.6 Results
This section provides the results for security best-practice clustering
and the binomial distribution of boosted secure best-practice, secure,
and insecure results in ğ‘¡10.
Secure Best-Practice Clustersâ€” DBSCAN identified 12 best-
practice clusters for IV with overall 92 identified best-practice ex-
amples. The biggest cluster contained 16% of the samples, as shown
in Table 3. We found 46 Stack Overflow webpages that were labeled
secure by ğ‘™ğ‘¡1 (the top answer provides only secure code examples)
and contained at least one best-practice example in the top answer.
For those results, we set the boost to ğ‘ğ‘ğ‘ = 1.0 in ğ‘ğ‘ ğ‘’ğ‘.
Ten best-practice clusters were found for KEY with overall 113
identified best-practice examples. The biggest cluster contained
17% of the samples. We found 11 webpages that were labeled secure
by ğ‘™ğ‘¡1 and provided at least one KEY best-practice example in the
top answer. They also obtained a boost value of ğ‘ğ‘ğ‘ = 1.0 in ğ‘ğ‘ ğ‘’ğ‘.
Binomial Distributionâ€” We computed the binomial distribu-
tion over {ğ‘ğ‘ ğ‘’ğ‘(ğ‘)}ğ‘âˆˆğ‘„ âŠ‚ ğ‘¡10, where ğ‘ğ‘ ğ‘’ğ‘ is the modified Google
Search engine that applies our boosting values ğ‘ğ‘ğ‘, ğ‘ğ‘ , and ğ‘ğ‘–. ğ‘„
are the same queries we collected in Study 1. We calculated the
binomial distribution for IV, KEY, and CIPHER by simulating 10,000
searches.
Task-Independent Resultsâ€” We first measured the binomial
distributions independently from the tasks. ğµ(10, 0.089) of boosted
secure best-practice results revealed a probability of 38.16% for one
result to appear in ğ‘¡10 and 29.36% in ğ‘¡3. Both distributions over ğ‘¡3
and ğ‘¡10 were even higher than the observed distributions of insecure
results in Study 1 (see Figure 2). Further, we saw a 17.11% chance
for two, and 3.85% for three results to appear in ğ‘¡10.
ğµ(10, 0.061) of secure results showed a chance of 36.54% for one
result, 11.59% for two, and 2.28% for three results to appear in ğ‘¡10.
As expected (ğ‘ğ‘  < ğ‘ğ‘ğ‘) is lower than the distribution of secure best
practices.
The distribution of insecure results ğµ(10, 0.008) was finally the
lowest. The probability of one result in ğ‘¡10 was reduced from 36.46%
(as observed in Study 1) to 5.57%. Moreover, we observed near-zero
probability of an insecure result in ğ‘¡3 which was 22.78% in Study 1.
IVâ€” We measured the binomial distribution ğµ(10, 0.084) for
boosted secure best-practice results {ğ‘ğ‘ ğ‘’ğ‘ğ‘ğ‘ (ğ‘)}ğ‘âˆˆğ‘„ğ‘–ğ‘£ over ğ‘¡10. As
shown in Figure 4, (IV, ğ‘¡10, green) the probability of at least one result
to appear in ğ‘¡10 was 38.96%, 18.70% for two results, and for three
results, 6.08%. Comparing this distribution with the distribution
of boosted secure results {ğ‘ğ‘ ğ‘’ğ‘ğ‘  (ğ‘)}ğ‘âˆˆğ‘„ğ‘–ğ‘£ also shown in Figure 2
(see IV, ğ‘¡10, blue), we observed the required higher distribution of
secure best-practice results.
Further, the distribution for boosted secure results shown in
Figure 4, (IV, ğ‘¡10, blue) was higher than the distribution of non-
boosted secure results shown in Figure 2. The probability of at least
one secure result in ğ‘¡10 increased from 22.44% to 25.03%, for two
results from 2.86% to 3.52%, and from 0.19% to 0.3% for three results.
Lastly, we calculated the distribution ğµ(10, 0.010) of boosted
insecure results {ğ‘ğ‘ ğ‘’ğ‘ğ‘– (ğ‘)}ğ‘âˆˆğ‘„ğ‘–ğ‘£ , shown in Figure 4, (IV, ğ‘¡10, red),
and compared it with the distribution of non-boosted insecure
results from Figure 2. Probability decreased from 34.90% to a 9.32%
for at least one insecure result in ğ‘¡10, from 10.43% to 0.32% for two
results, and from 1.65% to 0% for three results. Furthermore, there
Session 11C: Software Development and Analysis CCS â€™21, November 15â€“19, 2021, Virtual Event, Republic of Korea3077was an increase from a 54.74% to a 90.36% chance that none of the