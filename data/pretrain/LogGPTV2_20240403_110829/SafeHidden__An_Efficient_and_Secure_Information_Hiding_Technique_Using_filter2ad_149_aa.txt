title:SafeHidden: An Efficient and Secure Information Hiding Technique Using
Re-randomization
author:Zhe Wang and
Chenggang Wu and
Yinqian Zhang and
Bowen Tang and
Pen-Chung Yew and
Mengyao Xie and
Yuanming Lai and
Yan Kang and
Yueqiang Cheng and
Zhiping Shi
SafeHidden: An Efficient and Secure Information 
Hiding Technique Using Re-randomization
Zhe Wang and Chenggang Wu, State Key Laboratory of Computer Architecture, Institute of 
Computing Technology, Chinese Academy of Sciences, University of Chinese Academy of Sciences; 
Yinqian Zhang, The Ohio State University; Bowen Tang, State Key Laboratory of Computer 
Architecture, Institute of Computing Technology, Chinese Academy of Sciences, University of Chinese 
Academy of Sciences; Pen-Chung Yew, University of Minnesota at Twin-Cities; Mengyao Xie, 
Yuanming Lai, and Yan Kang, State Key Laboratory of Computer Architecture, Institute of Computing 
Technology, Chinese Academy of Sciences, University of Chinese Academy of Sciences; Yueqiang 
Cheng, Baidu USA; Zhiping Shi, The Capital Normal University
https://www.usenix.org/conference/usenixsecurity19/presentation/wang
This paper is included in the Proceedings of the 
28th USENIX Security Symposium.
August 14–16, 2019 • Santa Clara, CA, USA
978-1-939133-06-9
Open access to the Proceedings of the 
28th USENIX Security Symposium 
is sponsored by USENIX.
SafeHidden: An Efﬁcient and Secure Information Hiding Technique
Using Re-randomization
Zhe Wang1,2, Chenggang Wu1,2∗, Yinqian Zhang3, Bowen Tang1,2, Pen-Chung Yew4,
Mengyao Xie1,2, Yuanming Lai1,2, Yan Kang1,2, Yueqiang Cheng5, and Zhiping Shi6
1State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences,
2University of Chinese Academy of Sciences, 3The Ohio State University,
4University of Minnesota at Twin-Cities, 5Baidu USA, 6The Capital Normal University
Abstract
Information hiding (IH) is an important building block for
many defenses against code reuse attacks, such as code-
pointer integrity (CPI), control-ﬂow integrity (CFI) and ﬁne-
grained code (re-)randomization, because of its effectiveness
and performance. It employs randomization to probabilisti-
cally “hide” sensitive memory areas, called safe areas, from
attackers and ensures their addresses are not leaked by any
pointers directly. These defenses used safe areas to protect
their critical data, such as jump targets and randomization
secrets. However, recent works have shown that IH is vul-
nerable to various attacks.
In this paper, we propose a new IH technique called Safe-
Hidden. It continuously re-randomizes the locations of safe
areas and thus prevents the attackers from probing and in-
ferring the memory layout to ﬁnd its location. A new thread-
private memory mechanism is proposed to isolate the thread-
local safe areas and prevent adversaries from reducing the
randomization entropy. It also randomizes the safe areas af-
ter the TLB misses to prevent attackers from inferring the
address of safe areas using cache side-channels. Existing
IH-based defenses can utilize SafeHidden directly without
any change. Our experiments show that SafeHidden not only
prevents existing attacks effectively but also incurs low per-
formance overhead.
1 Introduction
Information hiding (IH) is a software-based security tech-
nique, which hides a memory block (called “safe area”) by
randomly placing it into a very large virtual address space,
so that memory hijacking attacks relying on the data inside
the safe area cannot be performed. As all memory point-
ers pointing to this area are ensured to be concealed, at-
tackers could not reuse existing pointers to access the safe
area. Moreover, because the virtual address space is huge
∗To whom correspondence should be addressed.
and mostly inaccessible by attackers, the high randomiza-
tion entropy makes brute-force probing attacks [45, 47] very
difﬁcult to succeed without crashing the program. Due to its
effectiveness and efﬁciency, IH technique has become an im-
portant building block for many defenses against code reuse
attacks. Many prominent defense methods, such as code-
pointer integrity (CPI), control-ﬂow integrity (CFI) and ﬁne-
grained code (re-)randomization, rely on IH to protect their
critical data. For example, O-CFI [40] uses IH to protect
all targets of indirect control transfer instructions; CPI [30]
uses IH to protect all sensitive pointers; RERANZ [57],
Shufﬂer [59], Oxymoron [4], Isomeron [15] and ALSR-
Guard [36] use IH to protect the randomization secrets.
For a long time, IH was considered very effective. How-
ever, recent advances of software attacks [20, 35, 19, 43, 22]
have made it vulnerable again. Some of these attacks use
special system features to avoid system crashes when scan-
ning the memory space [19, 35]; some propose new tech-
niques to gauge the unmapped regions and infer the location
of a safe area [43]; some exploit the thread-local implemen-
tation of safe areas, and propose to duplicate safe areas by
using a thread spraying technique to increase the probability
of successful probes [20]; others suggest that cache-based
side-channel attacks can be used to infer the location of safe
areas [22]. These attacks have fundamentally questioned the
security promises offered by IH, and severely threatened the
security defenses that rely on IH techniques.
To counter these attacks, this paper proposes a new infor-
mation hiding technique, which we call SafeHidden. Our
key observation is as follows: The security of IH techniques
relies on (1) a high entropy of the location of the safe ar-
eas, and (2) the assumption that no attacks can reduce the
entropy without being detected. Prior IH techniques have
failed because they solely rely on the program crashes to de-
tect attacks, but recent attacks have devised novel methods
to reduce entropy without crashing the programs.
SafeHidden avoids these design pitfalls.
It mediates all
types of probes that may leak the locations of the safe areas,
triggers a re-randomization of the safe areas upon detecting
USENIX Association
28th USENIX Security Symposium    1239
legal but suspicious probes, isolates the thread-local safe ar-
eas to maintain the high entropy, and raises security alarms
when illegal probes are detected. To differentiate acciden-
tal accesses to unmapped memory areas and illegal probing
of safe areas, SafeHidden converts safe areas into trap areas
after each re-randomization, creating a number of trap areas
after a sequence of re-randomization operations. Accesses
to any of these trap areas are captured and ﬂagged by Safe-
Hidden. SafeHidden is secure because it guarantees that any
attempt to reduce the entropy of the safe areas’ locations ei-
ther lead to a re-randomization (restoring the randomness)
or a security alarm (detecting the attack).
SafeHidden is designed as a loadable kernel module,
which is self-contained and can be transparently integrated
with existing software defense methods (e.g., CPI and CFI).
The design and implementation of SafeHidden entail sev-
eral unconventional techniques: First, to mediate all system
events that may potentially lead to the disclosure of safe area
locations, SafeHidden needs to intercept all system call inter-
faces, memory access instructions, and TLB miss events that
may be exploited by attackers to learn the virtual addresses
of the safe areas. Particularly interesting is how SafeHidden
traps TLB miss events: It sets the reserved bits of the page
table entries (PTE) of the safe area so that all relevant TLB
miss events are trapped into the page fault handler. However,
because randomizing safe areas also invalidates the corre-
sponding TLB entries, subsequent benign safe area accesses
will incur TLB misses, which may trigger another random-
ization. To address this challenge, after re-randomizing the
safe areas, SafeHidden utilizes hardware transactional mem-
ory (i.e., Intel TSX [2]) to determine which TLB entries were
loaded before re-randomization and preload these entries to
avoid future TLB misses.
Detecting TLB misses is further complicated by a new
kernel feature called kernel page table isolation (KPTI) [1].
Because KPTI separates kernel page tables from user-space
page tables, TLB entries preloaded in the kernel cannot be
used by the user-space code. To address this challenge, Safe-
Hidden proposes a novel method to temporarily use user-
mode PCIDs in the kernel mode. To prevent the Meltdown
attack (the reason that KPTI is used), it also ﬂushes all kernel
mappings of newly introduced pages from TLBs.
Second, SafeHidden proposes to isolate the thread-local
safe area (by placing it in the thread-private memory) to pre-
vent the attackers from reducing its randomization entropy.
Unlike conventional approaches to achieve thread-private
memory, SafeHidden leverages hardware-assisted extended
page table (EPT) [2]. It assigns an EPT to each thread; the
physical pages in other threads’ thread-local safe area are
conﬁgured not accessible in current thread’s EPT. Compared
to existing methods, this method does not need any modiﬁ-
cation of kernel source code, thus facilitating adoption.
To summarize, this paper makes the following contribu-
tions to software security:
protect the safe areas against all known attacks.
• It proposes the re-randomization based IH technique to
• It introduces the use of thread-private memory to iso-
late thread-local safe areas. The construction of thread-
private memory using hardware-assisted extended page
tables is also proposed for the ﬁrst time.
• It devises a new technique to detect TLB misses, which
is the key trait of cache side-channel attacks against the
locations of the safe areas.
• It develops a novel technique to integrate SafeHidden
with KPTI, which may be of independent interest to sys-
tem researchers.
• It implements and evaluates a prototype of SafeHidden,
and demonstrates its effectiveness and efﬁciency through
extensive experiments.
The rest of the paper is organized as follows. Section 2
reviews information hiding techniques and existing attacks.
Section 3 explains the threat model. Section 4 presents the
core design of SafeHidden. Section 5 details the implemen-
tation of SafeHidden. Section 6 provides the security and
the performance evaluation. Discussion, related work, and
conclusion are provided in Section 7, 8 and 9.
2 Background and Motivation
Information Hiding
2.1
Information hiding (IH) technique is a simple and efﬁcient
isolation defense to protect the data stored in a safe area. It
places the safe area at a random location in a very large vir-
tual address space. It makes sure that no pointer pointing to
the safe area exists in the regular memory space, hence, mak-
ing it unlikely for attackers to ﬁnd the locations of the safe
areas through pointers. Instead, normal accesses to the safe
area are all done through an offset from a dedicated register.
Table 1 lists some of the defenses using the IH technique.
The column “TL” shows whether the safe area is used only
by its own thread or by all threads. The column “AF” shows
how frequent the code accesses the safe area. Because most
accesses to the safe area are through indirect/direct control
transfer instructions, their frequencies are usually quite high.
The column “Content in protected objects” shows the critical
data tried to protect in safe areas. The column “Reg” shows
the designated register used to store the (original) base ad-
dress of the safe area. Some of them use the x86 segmen-
tation register %fs/%gs. Others use the stack pointer reg-
ister on X86 64, %rsp, that originally points to the top of
the stack. They access a safe area via an offset from those
registers. For the %gs register, they often use the follow-
ing formats: %gs:0x10, %gs:(%rax), %gs:0x10(%rax), etc.
For the %rsp register, they often use the following formats:
0x10(%rsp), (%rsp, %rax, 0x8), pushq %rax 1, etc.
1It still conforms to the access model. The designated register is %rsp,
1240    28th USENIX Security Symposium
USENIX Association
Protected Objects
Reg
Bounds Lookup Table
%gs
Real Return Address Table %gs
%gs
Execution diversiﬁer data
%rsp Dynamic code locators stored on the stack, such as return addresses.
%gs
Content in Protected Objects
The address boundaries of basic blocks targeted by an indirect branch instruction.
The table that contains the return addresses pushed by call instructions.
The mapping from the randomized code to the original code.
Defense
O-CFI [40]
RERANZ [57]
Isomeron [15]
ASLR-Guard[36] AG-Stack
Safe-stack
Randomization-agnostic
translation table
Oxymoron [4]
Shufﬂer [59]
CFCI [61]
Code pointer table
Protected Memory
AF
TL
High No
High Yes
Hign No
High Yes
High No
High No
High No
Low No
%fs
%gs
ELF section remapping information and the key of code locator encryption.
The translation table that contains the assigned indexes that are used to replace
all references to code and data.
The table that contains all indexes that are transformed from all function pointers
at their initialization points.
File name and descriptors, and the mapping between ﬁle names and ﬁle descriptors.
High Yes
CPI [30]
High No
Table 1: The list of defenses using information hiding (IH) techniques. AF is short for Access Frequency. TL is short for Thread Local.
through the stack pointer register with a constant offset.
Sensitive pointers and the bounds of target objects pointed by these pointers.
%gs
%rsp Return address, spilled register, and objects accessed within the function
%gs
Safe Stack
Safe Pointer Store
A safe area is usually designed to be very small. For ex-
ample, the size of a safe area shown in Table 1 is usually lim-
ited to be within 8 MB in practice. On today’s mainstream
X86 64 CPUs, the randomization entropy of an 8 MB safe
area is 224. Such a high randomization entropy makes brute
force probing attacks [45, 47] hard to guess its location suc-
cessfully. A failed guess will result in a crash and detected
by administrators.
2.2 Attacks against Information Hiding
Recent researches have shown that the IH technique is vul-
nerable to attacks. To locate a safe area, attackers may either
improve the memory scanning technique to avoid crashes, or
trigger the defense’s legal access to the safe area and infer its
virtual address using side-channels.
area, it uses a binary search method to ﬁnd the exact size
by allocating and freeing a memory region repeatedly. Af-
ter getting the exact size, it will allocate the memory in this
area through the persistent allocation oracle. It then uses the
same method to gauge the second largest unmapped area.
Because a safe area is mostly placed in an unmapped area,
an attacker can probe its surrounding areas to ﬁnd its location
without causing exceptions or crashes.
All probing attacks need to use such covert techniques to
probe the memory many times without causing crashes be-
cause the size of a user’s memory space is very large.
In
[20], it ﬁnds the safe area in many defenses is thread local
(see Table 1). So, it proposes to leverage the thread “spray-
ing” technique to “spray” a large number of safe areas to