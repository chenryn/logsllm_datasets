only by crashing;  as 
servers  is 
is b+ t + 1 rather 
when / = b = t, it 
is the case thatb+2t+1 =3/+1 andb+t+1 =2/+1. 
The benefit of such a hybrid model is that one additional 
fault-tolerance. 
server can provide 
generally, 
b simultaneous 
Byzantine 
arbitrary 
common than crash faults. 
b additional 
faults.) 
A hybrid model suits deployments 
where 
than 3/+ 1, and the quorum size 
than 2/ + 1. Of course, 
due to soft errors, 
some Byzantine 
can tolerate 
such as faults 
faults, 
servers 
or fail 
(More 
are less 
5.1. Checkpointing 
and state transfer 
Log servers 
should checkpoint 
their state periodically 
to 
the log server missed an unlock, 
(Section 
5.1). 
so it initiates 
their request  logs 
truncate 
needed for a full unlock. 
and to limit the amount of work 
The full unlock operation 
acts as 
978-1-4244-7501-8/10/$26.00 
©2010 IEEE 
368 
DSN 2010: Hendricks 
et al. 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:03:40 UTC from IEEE Xplore.  Restrictions apply. 
2010 IEEEIIFIP International 
Conference 
on Dependable 
Systems & Networks (DSN) 
for 
state. 
to execute 
log servers 
techniques 
The simplest 
Thus, upon full unlock, 
mechanism,  because 
a checkpointing 
agreed-upon 
the unlock can be purged. 
is for log servers 
a null object at fixed intervals. 
checkpointing 
protocols, 
If a correct 
reach an 
requests 
checkpoint 
prior to 
protocol 
the full unlock subprotocol 
Zzyzx can also use standard 
found in Zyzzyva [20] and similar 
which may be more efficient. 
client sends a request 
than 
number greater 
number in order, the log server must have 
The log server sends a message to all 3f 
asking for missed requests. Upon receiv­
the next request 
missed a request. 
other log servers, 
ing matching 
values for the missing 
ated MACs from f + 1 log servers, 
missed requests 
log servers  must 
vious requests, at least f + 1 correct 
these requests in their request 
stitute 
and the associ­
replays 
the 
on its local state to catch up. Since 2f + 1 
pre­
have responded 
have 
to each of the client's 
in place of prior requests. 
logs. A log server may sub­
log servers  must 
a checkpoint 
the log server 
requests 
5.2. Optimizations 
Read-only requests: A client 
can read objects 
locked by 
the same value, 
if all3f + 1 log servers 
If 2f + 1 log servers 
another client 
as in Zyzzyva. 
and the object was not modified since the last  checkpoint, 
the client 
the client 
pensive 
can return that value. If the object was modified, 
can request 
return 
return the same value 
than the unlock subprotocol. 
a checkpoint, 
which may be less ex­
Aggressive locking: If an object is locked but never 
there is no need to run the unlock subprotocol. 
just  sends 
the standard 
protocol, 
to the previous 
fetched, 
primary 
substrate 
pertaining 
a large set of objects 
which will deny future fetch requests 
does not lower performance. 
lock. Thus, aggressively 
requests through 
conflicting 
locking 
The 
Pre-serialization: 
Section 
6.S finds that Zzyzx outper­
forms Zyzzyva for contention-free  runs  as 
erations. 
could make the break-even 
The pre-serializer technique 
of Singh et al. [27] 
point even lower. 
short as ten op­
Preferred quorums: As in QIU [1] and HQ [8], Zzyzx 
quorums. 
Rather than send re­
for every operation, 
a client 
if all 2f + 1 servers 
matching  responses. 
of preferred 
takes advantage 
quests to all 3f + 1 log servers 
can send requests to 2f + 1 log servers 
provide 
amount of data sent over the network, 
the network is  bandwidth-
remaining 
cess other tasks or operations 
lowing a factor 
This optimization 
limits 
the 
which is useful 
when 
or when the 
or packet-limited, 
f servers 
to pro­
al­
of up to j!: higher throughput. 
are slow. It also  frees 
in the common case,  thus 
f replicas 
5.3. Scalability 
through log server groups 
There is nothing 
in Section 
used in the Byzantine 
4 that requires 
the group of 
fault-tolerant 
replicated 
state 
replicas 
machine protocol 
servers. 
to be hosted on the same servers 
as the log 
Thus, a system can deploy replicas 
and log servers 
can use multiple 
servers. 
Similarly, 
groups of log servers. 
the protocol 
An operation 
on distinct 
distinct 
tiple log server groups can always be completed 
the substrate 
groups  is 
which far exceeds 
adding servers 
near linear scalability 
The benefit of multiple 
in prior protocols. 
the scalability 
interface. 
that spans mul­
that can be achieved 
by 
through 
log server 
in the number of servers, 
6. Evaluation 
it with that of Zyzzyva and that of an unrepli­
Zyzzyva is measured 
because 
it outperforms 
This section 
evaluates 
the performance 
of Zzyzx and 
compares 
cated server. 
prior Byzantine 
implemented 
is a modified version 
tion, MDS was replaced 
because 
fault-tolerant 
protocols 
[20, 26]. Zzyzx is 
as a module on top of Zyzzyva, 
of the PBFT library 
which in turn 
[7]. For evalua­
with SHAI in Zyzzyva and Zzyzx, 
MDS is no longer considered 
secure [29]. 
Since Zyzzyva does not use Byzantine 
Locking, 
replicas 
requests 
ordering 
than the client 
on order requires 
(rather 
Agreeing 
and send MACs to all 3 f other replicas, 
which 
must agree on the order of requests before a response  is re­
turned to the client 
on locked objects). 
mary generate 
would be expensive 
primary in Zyzzyva accumulates 
fore ordering 
that is sent to all 3f other replicas, 
and cryptographic 
considers 
amortizing 
requests. 
Zyzzyva with batch sizes ofB=l and B=IO. 
if done for every operation. 
a batch of B requests be­
a single set of MACs 
the network 
This section 
them all by generating 
cost over several 
that the 
Thus, the 
pri­
used in Sections  6.2-
a null request 
avoiding 
The micro-benchmark 
workload 
process performing 
Each client 
contention. 
accesses an indepen­
running 
of each client 
a null reply. 
6.4 consists 
and receiving 
dent set of objects, 
Zzyzx locks each object on first access. The workload 
meant to highlight 
well as to provide 
prior experiments. 
tention, 
based workload 
data operations. 
the overhead 
a basis for comparison 
Section 
on a file system that uses Zzyzx for meta­
found in each protocol, 
6.S considers 
6.6 evaluates 
a benchmark 
the effects of con­
and Section 
A client 
and trace­
is 
as 
by reproducing 
6.1. Experimental setup 
All experiment
s are performed 
on a set of 
computers 
that 
of 
network 
bandwidth 
of 96 Gbps (69.3 Mpps). 
card. All comput­
Switch 2848, which 
internal 
runs Linux kernel 2.6.28-7 
each have a 3.0 GHz Intel Xeon processor, 2 gigabytes 
memory, and an Intel PRO/WOO 
ers are connected 
to an HP ProCurve 
has a specified 
Each computer 
working parameters. 
leased by the protocol's  authors, 
mizations. 
After accounting 
SHAI and MDS, the this section's 
agrees with that of Kotla et al. [20]. 
between 
of Zyzzyva 
use the Zyzzyva code re­
Experiments 
evaluation 
configured 
to use all opti­
Both Zyzzyva and Zzyzx use UDP multicast. 
for the performance  difference 
with default net­
978-1-4244-7501-8/10/$26.00 
©201O IEEE 
369 
DSN 2010: Hendricks 
et al. 
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:03:40 UTC from IEEE Xplore.  Restrictions apply. 
U' 
 200 
-.... <J) 
0. 0150 
 '-" 
::; 100 
0. 
.c 
00 50 
::l 0 ..., 
.c  0 
E-<  4 
Z zz va 
6 
Number of responsive 
8 
servers 
Figure  5: 
nearly linearly 
as servers 
are added. 
Throughput vs. servers. Zzyzx's throughput 
scales 
A Zyzzyva replica 
process runs on each of 3f + 1 server 
For Zzyzx, except where noted, one Zyzzyva 
process and one log server process run on each of 
computers. 
replica 
3f + 1 server computers. 
preferred 
beled "Zzyzx") 
beled "Zzyzx-NPQ"). 
quorum optimization 
of Section 
Zzyzx is  measured 
both with the 
5.2 enabled 
(la­
(la­
Each physical 
client 
computer 
runs 10 instances 
of the 
process. This number was chosen so that the client 
does not become processor-bound. 
All exper­
with measurements 
taken 
client 
computer 
iments are run for 90 seconds, 
from the middle 60 seconds. 
reported, 
3% of the mean. 
and the standard 
6.2. Scalability 
The mean of at least 3 runs is 
deviation 
for all results 
is within 
Figure 5 shows the throughput 
of Zzyzx and Zyzzyva as 
the number of servers 
Zyzzyva cannot use additional 
put, so the dashed line repeats 
reference. 
eral shape of the curve applies 
Although 
increases when tolerating 
one fault. 
servers 
its 4-server 
to improve through­
throughput 
for 
data is only shown for f = 1, the gen­
when tolerating 
more faults. 
and with preferred 
quorums disabled 
Figure 7 shows the average 
2010 IEEE/IFIP International 
Conference 
on Dependable 
Systems & Networks (DSN) 
B=l O. Even without 
mum throughput 
to Zzyzx's 
preferred 
Zzyzx's maxi­
is 2.2x that of Zyzzyva with B=lO, due 
quorums, 
lower network and cryptographic 
overhead. 
Due to the preferred 
quorums optimization, 
Zzyzx pro­
vides higher maximum throughput 
server, 
because each log server processes only a fraction (;j!:) 
than the unreplicated 
which simply generates 
and verifies 
a single MAC, 
With preferred 
of the requests. 
NPQ), Zzyzx provides 
cated server due to checkpoint, 
overheads. 
lower throughput 
than the unrepli­
log, and network 
request 
quorums  disabled 
(Zzyzx­
Zzyzx performs 
as well or better 
than Zyzzyva for larger 
sizes. For larger request  sizes, 
and response 
request 
as the 4 kB request 
benchmark 
such 
and null reply found in the 4/0 micro­
of Castro and Liskov [7], Zzyzx provides 
each log 
higher throughput (j!:) than Zyzzyva because 
1.3 x 
processes only a fraction 
of requests. 
server 
6.4. Latency 
latency 
for a single 
one request, 
operation 
Zzyzx ex­
and Zzyzx con­
as load increases. 
The lower 
only 2 one-way message 
computes 
each  server 
lower latency 
is  because 
than Zyzzyva, 
Zzyzx requires 
39-43% lower latency 
to provide 
under varied load. When serving 
hibits 
tinues 
latency 
delays (33%  fewer  than 
fewer MACS, and log servers 
of requests 
to accumulate 
turning 
put, batching 
in Zyzzyva.) 
6.5. Performance under contention 
(Though important 
before executing 
increases latency 
its response. 
Zyzzyva), 
a request 
and re­
for high through­
in Zzyzx never wait for a batch 
of Zzyzx under con­
Figure 8 shows the performance 
each client 
For this workload, 
then procures 
tention. 
a fixed number of times before the object is 
client 
object. 
Zzyzx, i.e., 
which Zzyzx outperforms 
The 
the 
the break-even 
point of 
run for 
The experiment 
identifies 
Zyzzyva. 
unlocked. 
accesses an object 
a new lock and resumes  accessing 
Even with the minimum number of servers 
(4), Zzyzx 
the length of the shortest contention-free 
Zyzzyva by a factor of 2.9x higher through­
outperforms 
put. For Zzyzx, the first 3f + 1 log servers 
with the Zyzzyva replicas. 
dedicated 
volved in each operation 
not need to overlap, 
in nearly linear 
log servers 
run on 
Since only 2f + 1 log servers 
are in­
log server sets do 
the increase 
scalability. 
and independent 
Additional 
computers. 
in usable quorums results 
are co-located 
When batching 
in Zyzzyva is  disabled 
to improve la­
Zyzzyva for contention-free 
runs 
2: 10 operations. 
Zzyzx outperforms 
Zyzzyva 
tency, Zzyzx outperforms 
that average 
when batching 
that average 
top throughput 
is enabled 
2: 20 operations. 
Zzyzx achieves 
(B= 1 0) for contention-free 
runs 
85-90% of its 
for contention-free 
runs of 160 operations. 
6.3. Throughput 
6.6. Postmark and trace-based 
execution 
Figure 6 shows the throughput 
achieved, 
while varying 
are correct 
outperforms 
when tolerating 
and responsive. 
a single fault and 
Zzyzx sig­
the number of clients, 
when all servers 
all Zyzzyva configurations. 
Zzyzx's 
nificantly 
maximum throughput 
is 2.9x that ofZyzzyva's 
and higher still compared to Zyzzyva without 
When Zzyzx is run on f+ 1 additional 
servers 
it's maximum throughput 
is 3.9x that of Zyzzyva with 
a memory-backed 
or Zzyzx for its metadata 
tem metadata 
specialized 
ist [ l3, 16]. Zzyzx completes 
tions per second (TPS) compared to Zyzzyva's 
an increase 
rather than data because 
ex­
batching. 
(6 total), 
for fault-tolerant 
of 60%. Postmark 
block data storage 
566 Postmark 
We  focus 
produces 
storage. 
efficient 
with B=lO, 
on file sys­
344 TPS, 
already 
[18] transac­
protocols 
a workload  with 
To compare Zzyzyva and Zzyzx in a full system, 
we built 
file system that can use either Zzyzyva 
978-1-4244-7501-8/10/$26.00 
©2010 IEEE 