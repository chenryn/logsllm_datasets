如果你有 n 个副本，并且你选择了满足 $w + r > n$ 的 w 和 r，你通常可以期望每次读取都能返回最近写入的值。情况就是这样，因为你写入的节点集合和你读取的节点集合必然有重叠。也就是说，你读取的节点中必然至少有一个节点具有最新值（如 [图 5-11](../img/fig5-11.png) 所示）。
通常，r 和 w 被选为多数（超过 $n/2$ ）节点，因为这确保了 $w + r > n$，同时仍然容忍多达 $n/2$ 个节点故障。但是，法定人数不一定必须是大多数，重要的是读写使用的节点至少有一个节点的交集。其他法定人数的配置是可能的，这使得分散式演算法的设计有一定的灵活性【45】。
你也可以将 w 和 r 设定为较小的数字，以使 $w + r ≤ n$（即法定条件不满足）。在这种情况下，读取和写入操作仍将被传送到 n 个节点，但操作成功只需要少量的成功响应。
较小的 w 和 r 更有可能会读取到陈旧的资料，因为你的读取更有可能未包含具有最新值的节点。另一方面，这种配置允许更低的延迟和更高的可用性：如果存在网路中断，并且许多副本变得无法访问，则有更大的机会可以继续处理读取和写入。只有当可达副本的数量低于 w 或 r 时，资料库才变得不可写入或读取。
但是，即使在 $w + r > n$ 的情况下，也可能存在返回陈旧值的边缘情况。这取决于实现，但可能的情况包括：
* 如果使用宽松的法定人数（见 “[宽松的法定人数与提示移交](#宽松的法定人数与提示移交)”），w 个写入和 r 个读取有可能落在完全不同的节点上，因此 r 节点和 w 之间不再保证有重叠节点【46】。
* 如果两个写入同时发生，不清楚哪一个先发生。在这种情况下，唯一安全的解决方案是合并并发写入（请参阅 “[处理写入冲突](#处理写入冲突)”）。如果根据时间戳（最后写入胜利）挑选出一个胜者，则写入可能由于时钟偏差【35】而丢失。我们将在 “[检测并发写入](#检测并发写入)” 继续讨论此话题。
* 如果写操作与读操作同时发生，写操作可能仅反映在某些副本上。在这种情况下，不确定读取返回的是旧值还是新值。
* 如果写操作在某些副本上成功，而在其他节点上失败（例如，因为某些节点上的磁碟已满），在小于 w 个副本上写入成功。所以整体判定写入失败，但整体写入失败并没有在写入成功的副本上回滚。这意味著一个写入虽然报告失败，后续的读取仍然可能会读取这次失败写入的值【47】。
* 如果携带新值的节点发生故障，需要从其他带有旧值的副本进行恢复，则储存新值的副本数可能会低于 w，从而打破法定人数条件。
* 即使一切工作正常，有时也会不幸地出现关于 **时序（timing）** 的边缘情况，我们将在 “[线性一致性和法定人数](ch9.md#线性一致性和法定人数)” 中看到这点。
因此，尽管法定人数似乎保证读取返回最新的写入值，但在实践中并不那么简单。Dynamo 风格的资料库通常针对可以忍受最终一致性的用例进行最佳化。你可以透过引数 w 和 r 来调整读取到陈旧值的机率，但把它们当成绝对的保证是不明智的。
尤其是，因为通常得不到 “[复制延迟问题](#复制延迟问题)” 中讨论的那些保证（读己之写，单调读，一致字首读），前面提到的异常可能会发生在应用程式中。更强有力的保证通常需要 **事务** 或 **共识**。我们将在 [第七章](ch7.md) 和 [第九章](ch9.md) 回到这些话题。
#### 监控陈旧度
从运维的角度来看，监视你的资料库是否返回最新的结果是很重要的。即使应用可以容忍陈旧的读取，你也需要了解复制的健康状况。如果显著落后，它应该提醒你以便你可以调查原因（例如网路中的问题或过载的节点）。
对于基于领导者的复制，资料库通常会提供复制延迟的测量值，你可以将其提供给监视系统。这之所以能做到，是因为写入是按照相同的顺序应用于主库和从库，并且每个节点对应了复制日志中的一个位置（已经在本地应用的写入数量）。透过从主库的当前位置中减去从库的当前位置，你可以测量复制延迟的程度。
然而，在无主复制的系统中，没有固定的写入顺序，这使得监控变得更加困难。而且，如果资料库只使用读修复（没有反熵过程），那么对于一个值可能会有多陈旧其实是没有限制的 - 如果一个值很少被读取，那么由一个陈旧副本返回的值可能是古老的。
已经有一些关于衡量无主复制资料库中的复制陈旧度的研究，并根据引数 n、w 和 r 来预测陈旧读取的预期百分比【48】。不幸的是，这还不是很常见的做法，但是将陈旧测量值包含在资料库的标准度量集中是一件好事。虽然最终一致性是一种有意模糊的保证，但是从可操作性角度来说，能够量化 “最终” 也是很重要的。
### 宽松的法定人数与提示移交
合理配置的法定人数可以使资料库无需故障切换即可容忍个别节点的故障。它也可以容忍个别节点变慢，因为请求不必等待所有 n 个节点响应 —— 当 w 或 r 个节点响应时它们就可以返回。对于需要高可用、低延时、且能够容忍偶尔读到陈旧值的应用场景来说，这些特性使无主复制的资料库很有吸引力。
然而，法定人数（如迄今为止所描述的）并不像它们可能的那样具有容错性。网路中断可以很容易地将客户端从大量的资料库节点上切断。虽然这些节点是活著的，而其他客户端可能也能够连线到它们，但是从资料库节点切断的客户端来看，它们也可能已经死亡。在这种情况下，剩余的可用节点可能会少于 w 或 r，因此客户端不再能达到法定人数。
在一个大型的丛集中（节点数量明显多于 n 个），网路中断期间客户端可能仍能连线到一些资料库节点，但又不足以组成一个特定的法定人数。在这种情况下，资料库设计人员需要权衡一下：
* 对于所有无法达到 w 或 r 个节点法定人数的请求，是否返回错误是更好的？
* 或者我们是否应该接受写入，然后将它们写入一些可达的节点，但不在这些值通常所存在的 n 个节点上？
后者被认为是一个 **宽松的法定人数（sloppy quorum）**【37】：写和读仍然需要 w 和 r 个成功的响应，但这些响应可能来自不在指定的 n 个 “主” 节点中的其它节点。就好比说，如果你把自己锁在房子外面了，你可能会去敲开邻居的门，问是否可以暂时呆在他们的沙发上。
一旦网路中断得到解决，一个节点代表另一个节点临时接受的任何写入都将被传送到适当的 “主” 节点。这就是所谓的 **提示移交（hinted handoff）**（一旦你再次找到你的房子的钥匙，你的邻居可以礼貌地要求你离开沙发回家）。
宽松的法定人数对写入可用性的提高特别有用：只要有任何 w 个节点可用，资料库就可以接受写入。然而，这意味著即使当 $w + r > n$ 时，也不能确保读取到某个键的最新值，因为最新的值可能已经临时写入了 n 之外的某些节点【47】。
因此，在传统意义上，宽松的法定人数实际上并不是法定人数。它只是一个永续性的保证，即资料已储存在某处的 w 个节点。但不能保证 r 个节点的读取能看到它，除非提示移交已经完成。
在所有常见的 Dynamo 实现中，宽松的法定人数是可选的。在 Riak 中，它们预设是启用的，而在 Cassandra 和 Voldemort 中它们预设是停用的【46,49,50】。
#### 运维多个数据中心
我们先前讨论了跨资料中心复制，作为多主复制的用例（请参阅 “[多主复制](#多主复制)”）。其实无主复制也适用于多资料中心操作，既然它旨在容忍冲突的并发写入、网路中断和延迟尖峰。
Cassandra 和 Voldemort 在正常的无主模型中实现了他们的多资料中心支援：副本的数量 n 包括所有资料中心的节点，你可以在配置中指定每个资料中心所拥有的副本的数量。无论资料中心如何，每个来自客户端的写入都会发送到所有副本，但客户端通常只等待来自其本地资料中心内的法定节点的确认，从而不会受到跨资料中心链路延迟和中断的影响。对其他资料中心的高延迟写入通常被配置为非同步执行，尽管该配置仍有一定的灵活性【50,51】。
Riak 将客户端和资料库节点之间的所有通讯保持在一个本地的资料中心，因此 n 描述了一个数据中心内的副本数量。资料库丛集之间的跨资料中心复制在后台非同步发生，其风格类似于多主复制【52】。
### 检测并发写入
Dynamo 风格的资料库允许多个客户端同时写入相同的键（Key），这意味著即使使用严格的法定人数也会发生冲突。这种情况与多主复制相似（请参阅 “[处理写入冲突](#处理写入冲突)”），但在 Dynamo 风格的资料库中，在 **读修复** 或 **提示移交** 期间也可能会产生冲突。
其问题在于，由于可变的网路延迟和部分节点的故障，事件可能以不同的顺序到达不同的节点。例如，[图 5-12](../img/fig5-12.png) 显示了两个客户机 A 和 B 同时写入三节点资料储存中的键 X：
* 节点 1 接收来自 A 的写入，但由于暂时中断，未接收到来自 B 的写入。
* 节点 2 首先接收来自 A 的写入，然后接收来自 B 的写入。
* 节点 3 首先接收来自 B 的写入，然后从 A 写入。
![](../img/fig5-12.png)
**图 5-12 并发写入 Dynamo 风格的资料储存：没有明确定义的顺序。**
如果每个节点只要接收到来自客户端的写入请求就简单地覆写某个键值，那么节点就会永久地不一致，如 [图 5-12](../img/fig5-12.png) 中的最终获取请求所示：节点 2 认为 X 的最终值是 B，而其他节点认为值是 A 。