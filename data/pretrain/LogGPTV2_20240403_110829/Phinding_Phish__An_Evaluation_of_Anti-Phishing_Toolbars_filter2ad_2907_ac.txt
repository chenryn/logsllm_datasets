**Yue Zhang**
**Phinding Phish: Evaluating Anti-Phishing Tools**

**Authors:** Yue Zhang, Serge Egelman, Lorrie Cranor, and Jason Hong  
**Institution:** Carnegie Mellon University  
**Contact:** {egelman, lorrie, jasonh}@cs.cmu.edu

### Abstract
There are currently numerous freely available tools to combat phishing and other web-based scams, many of which are web browser extensions that warn users when they are browsing a suspected phishing site. We developed an automated test bed for evaluating anti-phishing tools. Using 200 verified phishing URLs from two sources and 516 legitimate URLs, we tested the effectiveness of 10 popular anti-phishing tools. Only one tool was able to consistently identify more than 90% of phishing URLs correctly; however, it also incorrectly identified 42% of legitimate URLs as phish. The performance of the other tools varied significantly depending on the source of the phishing URLs. Of these remaining tools, only one correctly identified over 60% of phishing URLs from both sources. Performance also changed significantly based on the freshness of the phishing URLs tested. Thus, we demonstrate that the source of phishing URLs and the freshness of the URLs tested can significantly impact the results of anti-phishing tool testing. We also show that many of the tools we tested were vulnerable to simple exploits. In this paper, we describe our anti-phishing tool test bed, summarize our findings, and offer observations about the effectiveness of these tools and ways they might be improved.

### 1. Introduction
Over the past few years, there has been an increase in "semantic attacks" — computer security attacks that exploit human vulnerabilities rather than software vulnerabilities. Phishing is a type of semantic attack where victims are sent emails that deceive them into providing account numbers, passwords, or other personal information to an attacker. Typical phishing emails falsely claim to be from a reputable business where victims might have an account. Victims are directed to a spoofed website where they enter information such as credit card numbers or Social Security Numbers. In June 2006 alone, 9,255 unique phishing sites were reported [1]. Billions of dollars are lost each year due to unsuspecting users entering personal information into fraudulent websites.

To respond to this threat, software vendors and companies with a vested interest in preventing phishing attacks have released a variety of "anti-phishing tools." For example, eBay offers a free tool that can positively identify the eBay site, and Google offers a free tool aimed at identifying any fraudulent site [9], [12]. As of September 2006, the free software download site Download.com listed 84 anti-phishing tools. Unfortunately, few empirical studies have been performed to examine the effectiveness of these tools. Thus, while many anti-phishing tools exist, it is not clear how well they actually work.

Previous studies have examined the extent to which users fall for phishing scams and whether users benefit from the information provided by anti-phishing tools. These studies have shown that most users are likely to fall for phishing scams, and that many users ignore warnings provided by anti-phishing tools [7], [8], [13], [25]. However, little empirical data is available on the accuracy of these tools or on the effectiveness of the various approaches to detecting phishing sites.

Towards that end, this paper makes three research contributions:
1. We describe the design and implementation of a test bed for automatically evaluating anti-phishing tools.
2. We describe the results of experiments that assess the accuracy of 10 popular anti-phishing tools that use differing techniques to identify phishing sites.
3. We describe techniques we developed for circumventing many of the tools tested.

Our paper provides the anti-phishing community with insights into the effectiveness of several approaches to combating phishing as well as a methodology for testing anti-phishing tools.

### 2. Overview of Anti-Phishing Tools
There are various methods used to identify a web page as a phishing site, including whitelists (lists of known safe sites), blacklists (lists of known fraudulent sites), heuristics, and community ratings. The tools examined in this study employ different combinations of these methods. We used publicly available information provided on the tool download websites as well as our observations to get a basic understanding of how each tool functions.

#### 2.1. CallingID Toolbar
The CallingID Toolbar, shown in Figure 1, uses 54 different verification tests to determine the legitimacy of a given site. Like many other toolbars, CallingID relies on passive visual indicators. These indicators change from green (known-good site) to yellow (low-risk site) to red (high-risk site, likely a phishing site). Some of the heuristics used include examining the site’s country of origin, length of registration, popularity, user reports, and blacklist data. The CallingID Toolbar runs on Microsoft Windows 98/NT/2000/XP with Internet Explorer [2].

#### 2.2. Cloudmark Anti-Fraud Toolbar
The Cloudmark Anti-Fraud Toolbar, shown in Figure 2, relies on user ratings [4]. When visiting a site, users have the option of reporting the site as good or bad. Accordingly, the toolbar will display a colored icon for each site visited. Green icons indicate that the site has been rated as legitimate, red icons indicate that the site has been determined to be fraudulent, and yellow icons indicate that not enough information is known to make a determination. Additionally, the users themselves are rated according to their record of correctly identifying phishing sites. Each site’s rating is computed by aggregating all ratings given for that site, with each user’s rating of a site weighted according to that user’s reputation. No other heuristics are used in determining a site’s rating. Sites determined to be fraudulent are blocked, and users are redirected to an information page and given the option of overriding the block. The Cloudmark Anti-Fraud Toolbar runs on Microsoft Windows 98/NT/2000/XP with Internet Explorer. After our study began, we learned that Cloudmark is no longer supporting this toolbar. Cloudmark has since removed this toolbar from their website. They now offer a phishing URL feed for other toolbars and similar applications and a tool called Cloudmark Desktop that works in conjunction with the Microsoft Outlook and Microsoft Outlook Express email clients and labels phishing emails based on millions of reports from users each day. We have not tested Cloudmark Desktop.

#### 2.3. EarthLink Toolbar
The EarthLink Toolbar, shown in Figure 3, appears to rely on a combination of heuristics, user ratings, and manual verification. Little information is presented on the EarthLink website; however, we used the toolbar and observed how it functions. The toolbar allows users to report suspected phishing sites to EarthLink. These sites are then verified and added to a blacklist. The toolbar also examines domain registration information such as the owner, age, and country. The toolbar displays a thumb that changes color and position. A green thumbs up represents a verified legitimate site, whereas a gray thumbs up means that the site is not suspicious but has not been verified. The red thumbs down means that a site has been verified to be fraudulent, whereas the yellow thumbs down means that the site is "questionable." Sites determined to be fraudulent are sometimes blocked, in which case users are redirected to an information page and given the option of overriding the block (and a green thumb is displayed on the information page). The EarthLink Toolbar runs under Internet Explorer as well as Firefox [10].

#### 2.4. eBay Toolbar
The eBay Toolbar, shown in Figure 4, uses a combination of heuristics and blacklists [9]. The Account Guard indicator has three modes: green, red, and gray. The icon is displayed with a green background when the user visits a site known to be operated by eBay (or PayPal). The icon is displayed with a red background when the site is a known phishing site. The icon is displayed with a gray background when the site is not operated by eBay and not known to be a phishing site. Known phishing sites are blocked, and a pop-up appears, giving users the option to override the block. The toolbar also gives users the ability to report phishing sites, which will then be verified before being blacklisted. The eBay Toolbar runs under Microsoft Windows 98/ME/NT/2000/XP with Internet Explorer.

#### 2.5. Firefox 2
Firefox 2.0, shown in Figure 5, includes a new feature designed to identify fraudulent websites. Originally, this functionality was an optional extension for Firefox as part of the Google Safe Browsing Toolbar. URLs are checked against a blacklist, which Firefox downloads periodically [15]. The feature displays a popup if it suspects the visited site to be fraudulent and provides users with a choice of leaving the site or ignoring the warning. Optionally, the feature can send every URL to Google to determine the likelihood of it being a scam. According to the Google toolbar download site, the toolbar combines "advanced algorithms with reports about misleading pages from a number of sources [12]." We suspect that this means it uses blacklists as well as heuristics. Firefox 2.0 runs on Microsoft Windows, Apple Mac OS X, and Linux. The Google Safe Browsing Toolbar on which this functionality is based runs on Microsoft Internet Explorer under Windows XP/2000 SP3+, or Firefox on most platforms.

#### 2.6. GeoTrust TrustWatch Toolbar
GeoTrust’s TrustWatch Tool, shown in Figure 6, labels sites as green (verified as trusted), yellow (not verified), or red (verified as fraudulent). GeoTrust works with several third-party reputation services and certificate authorities to verify sites as trusted. GeoTrust’s website provides no information about how TrustWatch determines if a site is fraudulent; however, we suspect that the company compiles a blacklist that includes sites reported by users through a button provided on the tool. The toolbar also lets users store a custom image or bit of text that is constantly displayed so that the user knows that the toolbar is not being spoofed. TrustWatch runs on Microsoft Windows 98/NT/2000/XP with Internet Explorer [11].

#### 2.7. Microsoft Phishing Filter in Windows Internet Explorer 7
The Microsoft Internet Explorer 7 web browser includes a built-in phishing filter, shown in Figure 7 [17]. The tool largely relies on a blacklist hosted by Microsoft. However, it also uses some heuristics when it encounters a site that isn’t on the blacklist. When a suspected phishing website is encountered, the user is redirected to a built-in warning message and asked if they would like to continue visiting the site or close the window. Users also have the option of using this feature to report suspected phishing sites or to report that a site has incorrectly been added to the blacklist.

#### 2.8. Netcraft Anti-Phishing Toolbar
The Netcraft Anti-Phishing Toolbar, shown in Figure 8, uses several methods to determine the legitimacy of a website. The Netcraft website explains that the toolbar “traps suspicious URLs containing characters which have no common purpose other than to deceive,” “enforces display of browser navigation controls (tool & address bar) in all windows, to defend against pop-up windows which attempt to hide the navigational controls,” and “clearly displays sites’ hosting location, including country, helping you to evaluate fraudulent URLs (e.g., the real Citibank.com or Barclays.co.uk sites are unlikely to be hosted in the former Soviet Union)” [18]. The Netcraft toolbar also uses a blacklist, which consists of fraudulent sites identified by Netcraft as well as sites submitted by users and verified by the company. When a user attempts to access a site that is on the blacklist, a pop-up warning recommends that the access be canceled, but provides an override option. The toolbar also displays a risk rating between one and ten as well as the hosting location of the site (gleaned from the registration information for the IP address). Users can also use the toolbar to access a more detailed report on a website. The Netcraft Anti-Phishing Toolbar runs on Firefox on most platforms and on Microsoft Internet Explorer under Windows 2000/XP.

#### 2.9. Netscape Browser 8.1
The Netscape Navigator 8.1 web browser includes a built-in phishing filter, shown in Figure 9 [19]. From our testing, as well as third-party reviews, it appears that this functionality relies solely on a blacklist, which is maintained by AOL and updated frequently [5]. When a suspected phishing site is encountered, the user is redirected to a built-in warning page. Users are shown the original URL and are asked whether or not they would like to proceed. The Netscape Browser runs under Microsoft Windows, Linux, and Mac OS X.

#### 2.10. SpoofGuard
SpoofGuard, shown in Figure 10, is an anti-phishing toolbar developed at Stanford University [2]. Unlike the other tools described here, SpoofGuard does not use whitelists or blacklists. Instead, the toolbar employs a series of heuristics to identify phishing pages. The toolbar first checks the current domain name and compares it with sites that have been recently visited by the user to catch fraudulent websites that have a similar-looking domain name. Next, the full URL is analyzed to detect obfuscation as well as non-standard port numbers. Afterwards, the contents of the page are analyzed, making note of any password fields, embedded links, and images. Following this, SpoofGuard analyzes links in the webpage itself using the heuristics described above. Finally, it examines images on the webpage by hashing them to see if it has found identical images on other sites the user has visited. If two identical images are spotted on different websites, there is a chance that a fraudulent site has copied the images from the legitimate site.

SpoofGuard computes a score for each webpage in the form of a weighted sum of the results of each set of heuristics. Users can change the weights for each set of heuristics in an options menu. If the score surpasses a certain threshold, the toolbar displays a red icon, warning users that the site is a positively identified phishing site. If some of the heuristics are triggered but not enough to exceed the threshold, the icon turns yellow to indicate that it cannot make a determination about the site. If none of the heuristics are triggered, the icon turns green to indicate a safe site. SpoofGuard runs on Microsoft Windows 98/NT/2000/XP with Internet Explorer [2].

### 3. Anti-Phishing Tool Evaluation
We conducted a series of experiments designed to investigate the accuracy of anti-phishing tools. Our first experiment involved manually evaluating five of the tools described above. This gave us a feel for the behavior and effectiveness of the various tools but proved labor-intensive and posed significant logistical difficulties. As a result, we developed an automated testing system and used it to conduct our subsequent experiments. Using our automated testing system, we were able to test how each of the 10 tools responded to a set of URLs multiple times over a 24-hour period, allowing us to observe the effect of blacklist updates and of phishing sites being taken down.

#### 3.1. Manual Evaluation of Anti-Phishing Tools
Our first experiment was conducted using five laptops to simultaneously test five anti-phishing tools. One experimenter was assigned to each laptop. The experimenters manually entered URLs to be tested into web browsers running on each laptop and then observed and recorded the results. This was a slow and labor-intensive process. Once phishing websites are identified, they are often taken down quickly. According to the Anti-Phishing Working Group (APWG), the average time that a phishing site stays online is 4.5 days [1], though our experience suggests that many are taken down within hours. Therefore, it was critical to find a source of freshly reported phishing sites to test in our experiment. We also tried to find a source that was not used by any of the tools we were testing for updating their blacklist, although it was difficult to determine conclusively whether any tools were using the phishing feeds we tried. After experimenting with feeds that consisted of mostly phishing sites that had already been taken down, we obtained access to a feed of phishing URLs provided by an email filtering vendor. Each tool was tested with 50 confirmed phishing URLs identified within the previous 36 hours. Because we generally did not receive more than 20 new phishing URLs each day, we conducted the study during three separate sessions over a two-week period.

#### 3.2. Design and Implementation of an Automated Anti-Phishing Test Bed
Our first experiment was very labor-intensive, making this method infeasible for evaluating larger datasets across longer periods of time. Therefore, we developed an automated test bed for evaluating the effectiveness of anti-phishing tools. This test bed will facilitate the evaluation of new approaches to phish detection and the examination of long-term phishing trends, giving the anti-phishing community a clearer picture of how much progress we are making towards automatically detecting phishing sites. Figure 11 shows the high-level system architecture. Our system includes a task manager and a set of workers, each of which is responsible for evaluating a single tool. Our automated anti-phishing test bed is currently implemented in C# and is comprised of 2000 lines of code. Our implementation also makes use of freely available .NET components, including Compare Images [23], which checks if two images are identical.

**Step 1 – Retrieve Potential Phishing Sites.** First, the task manager obtains a set of phishing URLs to test against. We experimented with automating this process by extracting URLs from a feed of validated phishing URLs or by using our own heuristics to select phishing URLs from a feed of unvalidated phishing email messages. We found that by the time phishing URLs are validated and distributed on a phishing feed, they tend not to be very fresh, and many of the sites have been taken down. Furthermore, some phishing tools update their blacklists using data from validated phishing feeds. Unvalidated phishing URLs or email messages are a better source for fresh phishing URLs; however, use of these sources requires that phishing URLs be manually selected and validated. This process can be partially automated. However, if heuristics are used to select valid phishing URLs, phishing sites that cannot be identified using those heuristics may be excluded from the test and thus the results may be biased in favor of tools that use heuristics similar to the selection heuristics. In order to get large numbers of very fresh phishing URLs without bias, we decided to manually select and validate phishing URLs from a phishing feed and repository, using automated tools only to extract URLs from suspected phishing messages and remove those we had already seen. For our experiments, we labeled a site as a phishing scam only if it impersonates a known brand. This means, for example, that we did not include e-commerce sites that might rip you off or websites for fictitious companies that conduct identity theft by tricking prospective employees into submitting their resumes.

**Step 2 – Send URL to Workers.** In the second step, the task manager sends each URL to a set of workers, each of which is running a separate tool. The workers can be run on the same machine as the task manager or on separate machines. However, running workers on the same machine can be problematic when testing multiple tools that work with the same web browser, as the tests should be run with only one tool installed in the web browser at a time. Virtual machines can reduce the number of test machines needed.

**Step 3 – Worker Evaluates Potential Phishing Site.** In the third step, each worker downloads the specified webpage, examines whether its tool has labeled the webpage as phishing or not, and returns that value back to the task manager. Workers retrieve webpages using the Tor anonymity network [24], thus making it harder for phishing operators to observe that we are evaluating their sites. We have developed a simple image-based approach for workers to check a given tool. Each tool has several known states (e.g., a red icon if it has detected a phishing site and a green icon if it has not), and each tool can be set up to be in a known location in the web browser. Thus, we simply capture screenshots of the tools beforehand and compare relevant portions of those images to screenshots of the current state of the tool. The primary advantage of this image-based approach is that it works for all tools regardless of the programming language in which the tool was written, whether or not the tool provides an explicit API, and what web browser is being used.

**Step 4 – Task Manager Aggregates Results.** In the fourth step, the task manager aggregates all of the results from the workers and tallies overall statistics, including true positives, true negatives, false positives, false negatives, and sites that no longer exist.

#### 3.3. Evaluation of Anti-Phishing Tools
We used our automated anti-phishing test bed to evaluate 10 anti-phishing tools. We tested the built-in phishing filters in Microsoft Internet Explorer 7.0.5700.6, Netscape Navigator 8.1.2, and Firefox 2.0. We used Internet Explorer 6 to test the following tools: CallingID 1.5.0.150, Cloudmark 1.0, EarthLink 3.3.44.0, eBay 2.3.2.0, Netcraft 1.7.0, TrustWatch 3.0.4.0.1.2, and SpoofGuard. We began our experiment using Firefox 1.5.0.6 to test Google Toolbar 2.1. However, when Firefox 2.0 was released, it included the Safe Browsing feature from the Google Toolbar, and we found that when the Google Toolbar was configured with its default settings, it produced the same results as Firefox 2.0 configured with the “Ask Google” option. Thus, we decided to continue our experiment using Firefox 2.0 instead of the Google Toolbar. We also tested McAfee SiteAdvisor 1.7.0.53 in the early part of our experiment but removed it from the experiment when it became apparent that it does not actually detect phishing URLs. After removing McAfee SiteAdvisor from our experiment, we added CallingID. Thus, we did not test CallingID on the complete set of phishing URLs.

We configured all tools with their default settings. However, we tested Firefox 2.0 with the default setting (which uses a blacklist, downloaded approximately every 30 minutes) and with the “Ask Google” option (which sends every URL visited to Google for testing) and report these results separately. The Task Manager was run on a 1.6GHz Toshiba Portege M200 Notebook. The Workers were run on an IBM 1.6GHz ThinkPad T42 Notebook and a 1.7 GHz Compaq Presario v2000 Notebook.

On November 4-5, 2006, we tested 100 phishing URLs extracted from the list of unvalidated phishing reports on phishtank.com. We visited phishtank.com every six hours and retrieved all new suspected phishing URLs that had been submitted within the previous six hours. We manually verified that they were phishing sites and that the sites were still online. We extracted 100 confirmed, active phishing URLs and examined each URL within six hours of its being posted on phishtank.com.

On November 21 and 27, 2006, we tested 100 phishing URLs extracted from the APWG feed of reported phishing emails. We downloaded new messages from the feed every two hours and manually identified and verified active phishing URLs from these messages. We extracted 100 confirmed, active phishing URLs and examined each URL within two hours of its being received on our APWG feed.

Each URL was tested against each tool within one hour of extraction. In addition, each URL was tested against all tools except SpoofGuard 1, 2, 12, and 24 hours later. By testing each URL multiple times, we were able to observe blacklist updates as well as how long it took for phishing sites to be taken down.

During preliminary testing, we observed that SpoofGuard treats all re-visited URLs as legitimate, even if it initially identified them as phishing. Thus, SpoofGuard failed to identify any URLs as phishing URLs on the second and later visits. We discovered that if we cleared the web browser history before testing each URL, this problem goes away. However, as SpoofGuard’s determination is based only on heuristics and not on blacklists, SpoofGuard’s assessment does not change over time. Thus, we decided to test SpoofGuard only once on each URL. The apparent change in accuracy of SpoofGuard over time in our reported results is due entirely to some of the phishing websites being taken down.

We compiled a list of 516 legitimate URLs to test for false positives. The URLs were compiled from the following sources:
- 416 URLs were taken from the list of 500 legitimate URLs compiled by 3Sharp and published in a September 2006 report [22] (the remaining 84 URLs tested by 3Sharp were no longer active).
- 35 URLs were compiled by selecting the login pages of sites that are often attacked by phishers, such as www.citibank.com and www.paypal.com. These pages were selected to see whether tools can distinguish phishing sites from the legitimate sites they commonly spoof.
- 35 URLs were compiled by selecting the most popular web pages reported by Alexa Web Search. These pages were selected to see whether tools label frequently-visited pages correctly.
- 30 pages were compiled by selecting random pages from http://random.yahoo.com/fast/ryl, and manually verifying that they are legitimate. These pages were selected to see whether tools label random legitimate URLs correctly.

#### 3.3.1. Catch Rate
The most important function of an anti-phishing tool is to accurately and conspicuously identify phishing websites that users visit. Since not all of the tools provide the same types of indicators, we had to come up with a standard way of measuring accuracy. Some of the tools provide binary indicators (i.e., either that site is phishing or it is not), while some tools use a ternary system (i.e., a site can be phishing, not phishing, or unknown). We count only positive identification of phishing as a "catch." Most of the tools we tested have only one form of positive identification. However, IE7 and EarthLink can either warn or block when they identify phish, so we count either as a catch. We do not count "unvalidated" ratings or other uncertain ratings as a catch. We define "catch rate" (or true positive rate) as the number of phishing sites positively identified by a tool out of the total number of active phishing sites visited, with sites that had been taken down at the time of testing removed from the denominator. The rationale here is that it makes no difference whether a tool identifies a taken-down site as a phishing site, since a site that has been taken down does no harm to the user.

Table 1, Figure 12, and Figure 13 show the percentage of phishing sites correctly identified over time using the phishtank.com and APWG URLs. After 24 hours, 70 of the phishtank.com URLs and 67 of the APWG URLs remained active. The performance of the tools varies considerably depending on the source of the URLs used for testing. Some tools performed significantly better with URLs from one source or the other, but none of the tools we tested performed well across the board. SpoofGuard had a consistently high catch rate of over 90%, but also had a 42% false positive rate. Of the other tools we tested, only IE7 had a catch rate better than 60% with both sources, but it still missed 25% of the APWG phishing URLs and 32% of the phishtank.com phishing URLs.

When we tested the tools with phishtank.com URLs, SpoofGuard, EarthLink, and Netcraft performed best at identifying phishing sites initially. A chi-square test (p=0.01) demonstrated that SpoofGuard performed significantly better than Netcraft. However, we did not find a statistically significant difference between EarthLink and Netcraft, or SpoofGuard and EarthLink at the initial time period. Google, Cloudmark, and IE7 also did well. TrustWatch was able to only identify about half the phishing sites tested, while eBay identified 28% and Netscape identified 8%. When we tested the tools with the APWG URLs, SpoofGuard was able to identify 96% of the phishing sites. The next best tool, IE7, identified only 75% of the phishing sites initially, and 85% after 24 hours had passed. Netcraft, Firefox/Google, and EarthLink were able to identify 50-60% of phishing sites initially and 70-75% of phishing sites after 24 hours. Firefox, TrustWatch, Netscape, CallingID, and CloudMark all identified less than 50% of phishing sites initially. TrustWatch and Firefox improved to over 65% after 24 hours, while Netscape, CallingID, and CloudMark improved but still remained under 50% after 24 hours. eBay identified 52% of phishing sites initially and did not improve over the 24-hour testing period.

Our results indicate that the source of phishing URLs can have a major impact on test results. Neither of the sources we used lend themselves to use as completely automated feeds, and none of the tools we tested was able to correctly identify all of the phishing URLs from either of the feeds. Therefore, we do not believe that any of the tools were updating their blacklists automatically from either of these sources directly. However, the APWG feed includes data from multiple sources, and some of the tools might update their blacklists using data from some of them. In addition, phishtank.com has a validated phishing URL feed that includes a subset of the URLs that we validated ourselves. It is likely that some of the tested tools use this feed to update their blacklists. We also observed that some types of phishing attacks appeared more frequently in one source than the other. For example, spoofs of eBay-owned brands appeared more often in the APWG feed. Finally, we checked the APWG feed more frequently than we checked phishtank.com, and thus we believe the APWG URLs to be fresher than the phishtank.com URLs.

| **PhishTank** | **APWG** |
|---------------|----------|
| **Time since URL extraction** | **0 hours** | **1 hour** | **2 hours** | **12 hours** | **24 hours** | **0 hours** | **1 hour** | **2 hours** | **12 hours** | **24 hours** |
| **CallingID** | NA | NA | NA | NA | NA | 23 (23%) | 26 (26%) | 25 (27%) | 30 (38%) | 24 (36%) |
| **Cloudmark** | 68 (68%) | 68 (68%) | 68 (69%) | 64 (67%) | 47 (67%) | 22 (22%) | 24 (24%) | 21 (22%) | 25 (31%) | 25 (37%) |
| **EarthLink** | 83 (83%) | 83 (83%) | 81 (82%) | 78 (84%) | 59 (84%) | 54 (54%) | 53 (54%) | 51 (54%) | 51 (64%) | 47 (70%) |
| **eBay** | 28 (28%) | 28 (28%) | 26 (27%) | 24 (26%) | 18 (26%) | 52 (52%) | 52 (53%) | 51 (54%) | 43 (54%) | 35 (52%) |
| **IE7** | 68 (68%) | 68 (68%) | 67 (68%) | 62 (67%) | 47 (67%) | 75 (75%) | 74 (75%) | 72 (77%) | 67 (84%) | 58 (87%) |
| **Firefox** | NA | NA | NA | NA | NA | 28 (28%) | 50 (50%) | 51 (54%) | 47 (59%) | 44 (66%) |
| **Firefox/Google** | 70 (70%) | 70 (70%) | 70 (71%) | 71 (76%) | 59 (84%) | 53 (53%) | 54 (55%) | 56 (60%) | 56 (70%) | 49 (73%) |
| **Netcraft** | 77 (77%) | 77 (77%) | 73 (74%) | 69 (74%) | 56 (80%) | 60 (60%) | 59 (60%) | 57 (61%) | 62 (78%) | 49 (73%) |
| **Netscape** | 8 (8%) | 10 (10%) | 10 (10%) | 9 (10%) | 15 (21%) | 31 (31%) | 31 (31%) | 32 (34%) | 37 (46%) | 30 (45%) |
| **SpoofGuard** | 91 (91%) | 91 (91%) | 89 (91%) | 85 (91%) | 64 (91%) | 96 (96%) | 95 (96%) | 90 (96%) | 78 (98%) | 65 (97%) |
| **TrustWatch** | 49 (49%) | 49 (49%) | 48 (49%) | 45 (48%) | 36 (51%) | 44 (44%) | 43 (43%) | 44 (47%) | 45 (56%) | 45 (67%) |
| **Active URLs** | 100 | 100 | 98 | 93 | 70 | 100 | 99 | 94 | 80 | 67 |

*Note: SpoofGuard's catch rate is estimated after time 0.*

As Table 2 shows, most phishing sites are detected quickly by the tools we tested, but some are detected after several hours or even a day or more after they appear in phishing emails. Some tools improved more than others as our experiment progressed. When using phishtank.com URLs, only five of the tools were able to correctly identify phishing sites in later tests that they incorrectly identified initially. The changes in accuracy observed for the other tools are due entirely to some of the phishing sites being taken down. When using APWG URLs, all tools except SpoofGuard were able to correctly identify phishing sites in later tests that they incorrectly identified initially. The larger changes over time observed when using the APWG URLs are likely due to the APWG URLs being fresher than the phishtank.com URLs. The biggest improvement was seen with Firefox, which correctly identified 23 APWG phishing sites after 1 hour that it had missed initially. As we were testing Firefox, we observed that it initially missed a large number of sites until it automatically downloaded the latest version of its blacklist. This suggests that Firefox test results (without the “ask Google” option) are likely to vary depending on how recently the blacklist has been downloaded.

Interestingly, we also saw that some of the tools initially made a correct identification of a phishing site and later reversed themselves. We observed this only once or twice with most of the tools, but we observed Netcraft make an incorrect reversal 11 times. In general, the differing approaches taken by the tools resulted in their catching different sets of phish. All but one URL from each data set was caught by at least one tool at time 0. For 85% of the APWG phishing URLs we tested, at least three tools identified them correctly when they were first tested, and at least five tools identified them correctly after 24 hours. For 85% of the phishtank.com URLs, at least four tools identified them correctly when they were first tested, and at least five tools identified them correctly after 24 hours. It was rare, even after 24 hours, for eight or more tools to identify a URL correctly. Some phishing URLs were missed by one of the better tools but caught by another, or even caught by one of the tools that did not perform well overall.

#### 3.3.2. False Positive Rates
While the catch rate for real phishing sites is the paramount concern, caution needs to be taken with regard to false positives. False positives pose a major usability problem for any security software. If a user is continually alerted to a pending danger (in this case, phishing) even when the user knows no such danger exists, he or she is most likely to disable or ignore the tool that is creating the alerts. Thus, while a phishing tool must identify phishing sites, it should also be careful not to identify legitimate web pages as phishing. Each tool was tested against 516 legitimate URLs. SpoofGuard erroneously labeled 42% of these URLs as phishing. In addition, it reported that it was unsure about an additional 50% of these URLs. The only other tools to falsely identify any URLs as phishing sites were EarthLink and Cloudmark (which misidentified 1% of the legitimate sites), and CallingID (which misidentified 2% of the legitimate sites). CallingID, Cloudmark, EarthLink, and TrustWatch were also unsure of a large number of sites. The false positives results are summarized in Table 3. Overall, false positives do not appear to be a major problem for most of the tools we tested.

| **Tool** | **Falsely Identified as Phishing** | **Un