title:Spatio-temporal compressive sensing and internet traffic matrices
author:Yin Zhang and
Matthew Roughan and
Walter Willinger and
Lili Qiu
Spatio-Temporal Compressive Sensing and
Internet Trafﬁc Matrices
Yin Zhang⋆ Matthew Roughan‡ Walter Willinger§
Lili Qiu⋆
⋆The University of Texas at Austin
‡University of Adelaide
§AT&T Labs – Research
ABSTRACT
Many basic network engineering tasks (e.g., trafﬁc engineering, ca-
pacity planning, anomaly detection) rely heavily on the availability
and accuracy of trafﬁc matrices. However, in practice it is chal-
lenging to reliably measure trafﬁc matrices. Missing values are
common. This observation brings us into the realm of compressive
sensing, a generic technique for dealing with missing values that
exploits the presence of structure and redundancy in many real-
world systems. Despite much recent progress made in compres-
sive sensing, existing compressive-sensing solutions often perform
poorly for trafﬁc matrix interpolation, because real trafﬁc matrices
rarely satisfy the technical conditions required for these solutions.
To address this problem, we develop a novel spatio-temporal
compressive sensing framework with two key components: (i) a
new technique called SPARSITY REGULARIZED MATRIX FAC-
TORIZATION (SRMF) that leverages the sparse or low-rank nature
of real-world trafﬁc matrices and their spatio-temporal properties,
and (ii) a mechanism for combining low-rank approximations with
local interpolation procedures. We illustrate our new framework
and demonstrate its superior performance in problems involving
interpolation with real trafﬁc matrices where we can successfully
replace up to 98% of the values. Evaluation in applications such
as network tomography, trafﬁc prediction, and anomaly detection
conﬁrms the ﬂexibility and effectiveness of our approach.
Categories and Subject Descriptors
C.2.3 [Computer-Communication Networks]: Network Opera-
tions—Network monitoring
General Terms
Measurement, Performance
Keywords
Compressive Sensing, Trafﬁc Matrix, Interpolation, Tomography,
Prediction, Anomaly Detection
1.
INTRODUCTION
Trafﬁc Matrices (TMs), which specify the trafﬁc volumes be-
tween origin and destination pairs in a network, are critical in-
puts to many network engineering tasks, such as trafﬁc engineer-
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
SIGCOMM’09, August 17–21, 2009, Barcelona, Spain.
Copyright 2009 ACM 978-1-60558-594-9/09/08 ...$10.00.
ing [11,24], capacity planning, and anomaly detection. Due to their
importance, there is now a substantial body of work on TMs, for
instances see [2] and the references therein. The thrust of much of
this research has been on measurement [10,28] and inference [9,17,
25,27,31–34] of TMs, and more recently on topics such as anomaly
detection [13, 14, 21, 29, 30]. A key challenge that lies at the heart
of many of these problems is how to cope with missing values that
frequently arise in real-world TMs. In this paper, we propose novel
interpolation techniques to accurately reconstruct missing values in
TMs based on partial and/or indirect measurements. In the process,
we provide a uniﬁed approach to several common tasks involving
measurement and analysis of trafﬁc matrices; e.g., TM estimation,
prediction, and anomaly detection. Our approach uses the ﬁrst truly
spatio-temporal model of TMs, borrows ideas from the active area
of compressive sensing, and exploits domain knowledge regarding
TMs that has accumulated over the years.
In practice it is challenging to reliably measure TMs
Motivation:
for large networks. First, in many networks the TM is not directly
observable, and can only be estimated through link load measure-
ments. Such measurements, while linearly related to the TM itself,
are not sufﬁcient to unambiguously identify the true TM. Typically,
the problem was posed as an underconstrained linear-inverse prob-
lem, where the solution relied on a prior model of the TM (e.g., the
Poisson model of Vardi [27], the gravity model [31, 33], or the in-
dependent ﬂow model [9]). Second, although many networks now
collect (sampled) ﬂow-level measurements for at least part of their
network, there are still serious impediments to reliable large-scale
collection of TMs: data collection systems can fail, ﬂow collec-
tors often use an unreliable transport protocol, and legacy network
components may not support ﬂow collection or be resource chal-
lenged. Third, scalability requirements may mean that ﬂow-level
collection doesn’t occur at the edge of a network (where we would
wish it for true TM recovery [10]), but often only on some subset
of the routers. Recovery of the actual ingress-egress TM from such
data is non-trivial. Finally, when we ﬁnd an anomaly in a set of
TMs, we often need to know the non-anomaly-related trafﬁc either
for other network tasks, or just so that we can infer the cause of the
anomaly. The result is that any large set of TM measurements has
some, and quite often, a signiﬁcant number of missing values.
Since many network engineering tasks that require TMs are ei-
ther intolerant or highly sensitive to missing data, it is important to
accurately reconstruct missing values based on partial and/or indi-
rect TM measurements. Interpolation is the mathematical term for
ﬁlling in these missing values. Compressive sensing is a generic
methodology for dealing with missing values that leverages the
presence of certain types of structure and redundancy in data from
many real-world systems. Compressive sensing has recently at-
tracted considerable attention in statistics, approximation theory,
information theory, and signal processing. Several effective heuris-
tics have been proposed to exploit the sparse or low-rank nature of
267data [5, 6, 8, 19, 20]. Meanwhile, the mathematical theory of com-
pressive sensing has also advanced to the point where the optimality
of many of these heuristics has been proven under certain technical
conditions on the matrices of interest.
Contributions: Despite much recent progress in the area of com-
pressive sensing, our extensive evaluation of the existing compres-
sive sensing algorithms on real TMs shows that they do not per-
form well for TM interpolation, especially under structured, high
data loss (see Section 4). The main reason is that real TMs often
exhibit characteristics that violate the mathematical conditions un-
der which existing compressive sensing algorithms are designed to
operate and are provably optimal. Speciﬁcally, the optimality re-
sults for existing compressive sensing algorithms often assume that
(i) the matrix elements are drawn from a Gaussian or Gaussian-like
distribution, (ii) the matrix is exactly low-rank, (iii) data loss is in-
dependent for different matrix elements, and (iv) the measurement
constraints on the matrix satisfy a certain technical conditions (e.g.,
the restricted isometry property [19]). Unfortunately, none of these
conditions are likely to hold for real TMs. Real TM elements often
exhibit a highly skewed distribution, where the largest and smallest
elements often differ in size by several orders of magnitude. More-
over, real TMs are only approximately low-rank, and data loss in
real TMs tends to be highly structured — data may be missing ei-
ther spatially (we may be missing entire rows or columns of the
TM), or temporally (we may be missing matrix elements over en-
tire segments in time), or in some combination. Finally, there is no
guarantee that the constraints arising from real-world TM measure-
ments satisfy the required technical condition.
To address the above challenge, we develop in this paper a novel
spatio-temporal compressive sensing framework for TM interpola-
tion. Our framework has two key components:
• We develop SPARSITY REGULARIZED MATRIX FACTORIZA-
TION (SRMF), which ﬁnds sparse, low-rank approximations
of TMs that account for spatial and temporal properties of real
TMs. To the best of our knowledge, SRMF represents the ﬁrst
genuine spatio-temporal model of TMs. In contrast, most past
approaches can be best described as purely spatial (e.g., [9, 13,
14, 31, 33]) or temporal (e.g., [3, 27]). SRMF is also quite gen-
eral; it includes as special cases many of the existing techniques
(e.g., PCA, Tomo-gravity [31, 33] and independent ﬂows [9]),
but admits a much larger variety of algorithms.
• We augment low-rank approximations of TMs with local inter-
polation. In this way, we can leverage additional local struc-
ture and redundancy that are difﬁcult to capture using strictly
low-rank approximations of a TM. For example, there may not
exist any strictly low-rank approximation that can satisfy all the
linear constraints between the link load measurements and the
original TM. Similarly, a strictly low-rank global structure may
be too inﬂexible to capture the local similarity between indi-
vidual TM elements. Our strategy is to use the low-rank ap-
proximation obtained by SRMF as a prior and derive a reﬁned
approximation that is no longer strictly low-rank but is close to
the low-rank prior and can also account for existing local struc-
ture and redundancy.
We use real TMs from three operational networks to evaluate
the effectiveness of our approach. Our most successful algorithm,
SPARSITY REGULARIZED MATRIX FACTORIZATION combined
with local interpolation, has many desirable properties. Its perfor-
mance when applied to real TMs is excellent. We can reconstruct
TMs with up to half their data missing with errors of the order of
10%, and even when 98% of the data points are missing our ap-
proach only has an error of the order of 30%. While it may be
surprising that such good reconstructions are possible with so little
data, our results are an indication of the degree of structure present
in real-world TMs. The fact that we can perform such reconstruc-
tions could change the way TMs are collected. Much as sampling
has enabled network-wide ﬂow collection, reconstructions of this
type can enable truly large-scale collections of TM data.
The technique has been applied to matrices with over 700 thou-
sand entries, and we can process these in only a few seconds. The
algorithm scales linearly with the size of the data so that much
larger datasets can be analyzed. Moreover, tests of the proposed
approach in applications such as network tomography, trafﬁc pre-
diction, and anomaly detection all conﬁrm its effectiveness and ro-
bustness to real-world measurement issues.
Paper organization: The remainder of the paper is organized as
follows. We provide background on trafﬁc matrices and compres-
sive sensing in Section 2. We describe our spatio-temporal com-
pressive sensing framework in Section 3. We present evaluation
results for TM interpolation in Section 4 and for applications of
TM interpolation in Section 5. We conclude in Section 6.
2. BACKGROUND
2.1 Trafﬁc Matrices
A Trafﬁc Matrix (TM) is a non-negative matrix Z(i, j) that de-
scribes volumes of trafﬁc (in bytes, packets, or ﬂows) between a
source i and a destination j. For a network with N locations the
TM is a square N × N matrix. In practice we need a number of
addenda to this simple deﬁnition. First, a TM is typically mea-
sured over some time interval, and the value reported is an average.
So we denote Z(i, j; t) to be the trafﬁc from i to j averaged over
[t, t + ∆t). We call the TM Z(∗, ∗, t) a snapshot despite the fact
that it really represents an interval. Second, although it is common
to speak of “origin-destination” TMs, it is often difﬁcult to accu-
rately map IP addresses present in trafﬁc to the true origin and des-
tination of trafﬁc when we examine a network or Autonomous Sys-
tem (AS). So typically the matrix is aggregated into a router-level
ingress-egress TM, where Z(i, j; t) describes the trafﬁc entering a
network at router i, and leaving at router j.
The TM may be thought of as a 3-dimensional array Z ∈ RN ×
RN × Rm (where there are m time intervals present). It is common
to take a TM snapshot and stack the columns to form a column
vector which we denote xt. We can compile these vectors into
the columns of a larger matrix X ∈ Rn × Rm (where n = N 2),
and this form of the TM is often more convenient for algebraic
manipulation than a 3-dimensional array. Note that the columns of
X represent the TM at different times, while the rows represent the
time evolution of a single element of the TM.
One example of how this notation is useful is in TM inference
(the so-called network tomography problem [27]). In this problem
the TM is related to the more easily measured link loads Y by the
following linear matrix equation
Y = AX,
(1)
where A is the routing matrix, which expresses which links are
used by which routes1. TM inference involves ﬁnding the “best”
solution ˆX to (1) given a set of link-load measurements Y .
More generally, we can combine link measurements with addi-
tional TM measurement strategies, which often yields a better es-
timate of the TM than using each individual type of measurements
by itself [34]. For example, ﬂow-records are typically collected at
ingress routers [10].
In this case, each router sees one row of a
TM snapshot, so over time, router i sees Z(i, ∗, ∗). Missing data
1Typically issues such as changing network topology or routing, or
number of routers are ignored in the mathematical literature, but
such issues have been successfully dealt with in practical instantia-
tions of network tomography algorithms [30, 33].
268from a single router means we will be missing a row of Z, or a
group of rows of X. Flow-records could also be collected at egress
or backbone routers. In this case, although it is difﬁcult to unam-
biguously determine the ingress router for the observed trafﬁc, we
can still form a set of linear constraints on where the trafﬁc could
have originated. An alternative measurement strategy [28, 33] is to
collect local TMs at each router, which can again be represented as
linear constraints on the global TM. In combination we have a set
of linear constraints on the TM, i.e.,
A(X) = B,
(2)
where A(·) is a linear operator, and the matrix B contains the mea-
surements. The operator expresses the information available in our
measurements. Note that the presence of missing data is implicit in
(2); for instance, the operator A could include TM measurements at
ingress routers with no measurement errors (but with missing data),
by writing (2) as
M. ∗ X = M. ∗ D,
(3)
where D(i, j) contains the direct measurements (where available)
and M is a N 2 × m matrix given by
M (i, j) =  0,
1,
if X(i, j) is missing.
otherwise.
(4)
and .∗ denotes an element-wise product, i.e., A = C. ∗ B means
A(i, j) = B(i, j)C(i, j). When both link measurements and di-
rect measurements are available, then constraints (3) will (typi-
cally) be incorporated into (2) to simplify notation.
In addition to the above concerns we note that all data sources
contain errors. Flow-level collection usually involves sampling, of-
ten at quite high rates, and the Simple Network Management Pro-
tocol (SNMP) used for collecting link measurements is often noisy.
We seek an estimated TM ˆX that satisﬁes the conditions im-
posed by the set of measurements. However, as is the case in
many such linear-inverse problems, there may not be enough in-
formation to unambiguously determine X. We call these undercon-
strained linear-inverse problems (in the case of TM estimation from
link data, the problem is very highly underconstrained). To solve
such problems, we can use side information about the nature of the
TM being considered, for instance the gravity model of [31, 33] or
independent-ﬂows model of [9]. Regularization is a process used to
solve such problems in which we “regularize” towards some prior
model of the data in question. The low-rank model we will propose
here is motivated by the recent literature on compressive sensing.
2.2 Compressive Sensing
We have seen that interpolation is necessary because of missing
values in the data we collect. In addition, we can set up missing
data problems deliberately as part of the design of scalable mea-
surement systems. As networks grow, it becomes more difﬁcult
to maintain the associated measurement infrastructure. Methods to
reduce the required infrastructure have started to appear, the most
common of which is sampling. A new idea in signal processing
is that of compressive sensing [6, 8]. The main idea behind com-
pressive sensing is that since many real-world signals or datasets
exhibit some structure or redundancy (i.e., they are not pure noise),
one should be able to utilize this prior knowledge for both acquisi-
tion and reconstruction of the signal or dataset at hand.
Structure and redundancy in data are often synonymous with
sparsity. A sparse vector is simply a vector that has only a few
non-zero elements. Often our vectors of interest might have only a
few large elements, and many small elements. We call such a vector
compressible, in the sense that most of its information is carried in
the larger elements. Note that the majority of work on compressive
sensing has concerned vectors of data, so a naive approach to TMs
might be to compile these into vectors and then apply vector tech-
niques. However, some of the structure of a TM is inherent in the
matrix itself, so there is value in treating our matrix X as a genuine
matrix. In the context of matrices, low rank is analogous to sparsity,
because the spectrum formed by the singular values of a low-rank
matrix is sparse (see below). It is now well known that TMs may
be approximated by matrices of low rank [13, 14], and so this con-
cept ﬁts well here. We explicitly use this type of sparsity as our
approach to resolve the underconstrained nature of the measure-
ment problems we face. In the following section we draw on the
recent matrix compressive-sensing literature [5, 19, 20] to explain