title:Interrupt-oriented bugdoor programming: a minimalist approach to bugdooring
embedded systems firmware
author:Samuel Junjie Tan and
Sergey Bratus and
Travis Goodspeed
Interrupt-oriented Bugdoor Programming:
A Minimalist Approach to Bugdooring Embedded Systems
Firmware
Samuel Junjie Tan
Google, Inc.
Sergey Bratus
Dartmouth College
PI:EMAIL
PI:EMAIL
Travis Goodspeed
Straw Hat
PI:EMAIL
ABSTRACT
We demonstrate a simple set of interrupt-related vulnera-
bility primitives that, despite being apparently innocuous,
give attackers full control of a microcontroller platform. We
then present a novel, minimalist approach to constructing
deniable bugdoors for microcontroller ﬁrmware, and con-
trast this approach with the current focus of exploitation re-
search on demonstrations of maximum computational power
that malicious computation can achieve. Since the intro-
duction of Return-oriented programming, an ever-increasing
number of targets have been demonstrated to unintention-
ally yield Turing-complete computation environments to at-
tackers controlling the target’s various input channels, un-
der ever more restrictive sets of limitations. Yet although
modern OS defensivem easures indeed require complex com-
putations to bypass, this focus on maximum expressive-
ness of exploit programming models leads researchers to
overlook other research directions for platforms that lack
strong defensive measure but occur in mission-critical sys-
tems, namely, microcontrollers. In these systems, common
exploiter goals such as sensitive code and data exﬁltration
or arbitrary code execution do not typically require com-
plex computation; instead, a minimal computation is pre-
ferred and a simple set of vulnerability primitives typically
suﬃces. We discuss examples of vulnerabilities and the new
kinds of tools needed to avoid them in future ﬁrmware.
Categories and Subject Descriptors
K.6 [Management of Computing and Information Sys-
tems]: Miscellaneous; K.6.5 [Management of Comput-
ing and Information Systems]: Security and Protectio-
nUnauthorized access (e.g., hacking, phreaking)
General Terms
Security
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are not
made or distributed for proﬁt or commercial advantage and that copies bear
this notice and the full citation on the ﬁrst page. Copyrights for components
of this work owned by others than ACM must be honored. Abstracting with
credit is permitted. To copy otherwise, or republish, to post on servers or to
redistribute to lists, requires prior speciﬁc permission and/or a fee. Request
permissions from Permissions@acm.org.
ACSAC ’14, December 08 - 12 2014, New Orleans, LA, USA
Copyright
http://dx.doi.org/10.1145/2664243.2664268
978-1-4503-3005-3/14/12...$15.00
2014
ACM
Keywords
ACSAC Proceedings, Security, Hacking, Microprocessor ex-
ploitation
1.
INTRODUCTION
This paper examines what is arguably the most constrain-
ed “weird”1 programming model to date: one using side-
eﬀects of interrupts. This model has, to the best of our
knowledge, been overlooked. Although this model is weaker
than any previous exploit programming models, it is signif-
icant because of the increasing ubiquity of microcontrollers
and the ease with which this novel class of innocent-looking
“bug doors” can be planted into ﬁrmware.
In this paper, we demonstrate this model on synthetic vul-
nerabilities, and provide prototype tools to help locate sim-
ilar vulnerabilities on ﬁrmware in the wild, which we intend
for future work. Moreover, we describe a proof-of-concept
“bugdoor” implemented by making the interrupt handler of
an MSP430 TinyOS-based ﬁrmware application re-entrant.
This “bugdoor” is controlled solely by means of well-timed,
attacker-triggered interrupts.
Bug doors.
Unlike a traditional backdoor, where specialized code is
left in the program to surreptitiously control it, a bugdoor
does not leave undeniably malicious code in the target pro-
gram; it requires the attacker to supply speciﬁc inputs to
the target to insert them alicious program (e.g. shellcode)
and so perform unintended computation. The former type
of vulnerability is easier to detect and trace to the source,
as was the case with Alcatel’s network switch operating sys-
tem telnet backdoor in 2002 [10]. The latter is harder to
discover and to deﬁnitively frame as deliberate exploitation.
With the building blocks featured in our synthetic vul-
nerabilities situated in ﬁrmware, an attacker would have a
deniable bugdoor that involves no common forms ofm emory
corruption and would therefore likely be missed by vulner-
ability scanning tools. Our prototype tools, on the other
hand, show a basic set of tell-tale conditions associated with
such hypothetical bugdoors.
“Two gadgets is all you need”.
In the following two sections we put our programming
model in historical perspective of exploitation programming.
We then discuss the microcontroller threat model, the tar-
1In the sense of “weird machines”, unexpected programming
modes of trusted systems that we discuss later.
(cid:20)(cid:20)(cid:25)
geted processor MSP430, and our “interrupt-oriented pro-
gramming” model itself (a pun on ROP), starting with its
primitives and continuing with the bug door that realizes
it. We then describe our (inconclusive) attempts at ﬁnding
such code in the wild, and wrap up with ideas for follow-on
work.
2. MOTIVATION AND HISTORY:
WHITHER EXPLOITATION?
2.1 Exploitation and its programming models
Research in exploitation techniques traditionally focused
on feature-rich targets such as servers, desktops, and smart
phones, where exploitation co-evolved with protective mea-
sures. Indeed, techniques such as return-to-libc [27], return-
to-PLT [18], which generalized the reuse of code chunks by
chaining stack frames pointing to them [20, 14], emerged
in response to protective measures such as Openwall and
PaX [28, 29] and co-evolved with such measures (e.g., [18,
8, 17]).
Interestingly, the more signiﬁcant the barriers posed to
attackers, the more expressive and general exploit program-
ming models became.
In 2000 [20] Gerardo Richarte ob-
served that chunk chaining techniques could apparently en-
code “any program”; in 2007, Shacham Hovav [24] proved
that x86 stack-based libc end-of-function block chaining was
a Turing-complete programming model, at the same time
coining the term Return-Oriented Programming (ROP) for
such models. Since then, completeness has been shown to
exist with less and less resources, such as with only cer-
tain classes of instructions [6], only constant-length instruc-
tions on platforms such as RISC [5]. Completeness has
also been shown to exist when payloads are restricted to
certain character sets [23]—even to just English dictionary
words [15]—and when the payloads had to work on several
ISAs at once [9].
This co-evolution highlighted the nature of exploits as
programs written for and assisted by certain combinations
of features and bugs in the targets—so-called primitives [21,
22]—used in am anner similar to assembly instructions (e.g.,
[13]). These unusual, emergent target machines and pro-
gramming modes for exploit-programs became known as “we-
ird machines” [4, 7, 2]. Typically, weird machines’ existence
was a surprise for the target’s developers, but deliberate cre-
ation of them to provide a deliberate “debug door” or simply
a “bug door” is also possible.
2.2 The distraction of Turing-completeness
Most weird machines were proved to be Turing-complete,
following in the footsteps of [24]—partly because it pleases
a certain kind of computer scientist to have a theorem like a
cherry on top of a paper, and partly because other kinds of
computer scientists saw oﬀensive papers merely describing
a novel exploit technique as incremental and unscientiﬁc.
Arguably, the original proof of libc-based ROP completeness
was necessary to change the academic view of exploits as
limited and ad-hoc; it certainly made the great step forward
of replacing the outmoded threat model of “malicious code”
(and the unhelpful focus on detecting such code) with the
more relevant model of malicious computation inherent in
most general-purpose systems.
However, the computation performed by an exploit only
needs to be powerful enough to achieve the exploiter’s actual
goals; there are no points awarded for additional expressive
power, nor for extra complexity. The golden rule of exploita-
tion is that when a thing can be reliably accomplished with
minimal means, it should be accomplished with just such
means. However, practical minimality has been overshad-
owed by pursuing techniques with maximum computational
power. This disconnect is the starkest for microcontrollers,
upon which our trusted and mission-critical systems contin-
ually increase their reliance.
2.3 Microcontroller exploitation
It was necessity that drove practical evolution of ROP and
other techniques for feature-rich targets towards more ex-
pressive programming models. Essentially, protective mea-
sures forced exploits to emulate the OS’ native linkers (cf. [3]
on the “Bring Your Own Linker” pattern), which perform
complex computations (e.g., GNU/Linux dynamic linker is
a Turing-complete platform for its metadata considered as a
program [25]). Accordingly, a rich set of primitives adding
up to a computation model in which (nearly) arbitrary al-
gorithms could be expressed helped in practical exploitation
of such targets. In other words, computational power (up
to Turing completeness) helped even when it wasn’t strictly
required.
For microcontrollers, the exploiters’ situation is quite dif-
ferent. In absence of countermeasures, microcontroller vul-
nerability primitives need not provide a computationally rich
environment; they just need to enable typical goals such as
exﬁltration of ﬁrmware code, exﬁltration of sensitive data
such as cryptographic keys or conﬁguration parameters or
code execution in ﬁrmware contexts. Exploit computation
in microcontrollers need not be complex, and the primitives
it requires to succeed may in fact be limited to a single write
to a speciﬁc memory address or a single control ﬂow redi-
rection.
Microcontroller exploitation thus poses a diﬀerent class of
research problems, which, to the best of our knowledge, has
been overlooked. Namely: what are the minimal combina-
tions of primitives that still serve the attacker’s goals (rather
than, as in feature-rich targets, allowing the attacker to en-
code arbitrary algorithms)?
We can pose this question more precisely in the case of
bugdoors, vulnerabilities deliberately introduced into a sys-
tem to provide a deniable backdoor. What is a minimal
patch that would provide such a backdoor and would be
least likely to be spotted by bug-ﬁnding tools looking for
memory corruption bugs?
3. RELATED WORK
Exploitation of computationally rich targets has a rich
history, which was outlined above. The overall direction
of this history has been doing more with less—essentially,
keeping full control of the target and (Turing-)complete ex-
pressiveness of exploit programs with an ever-shrinking set
of primitives. A good history sketch of primitives and at-
tacks can be found in [16]. It turned out that many kinds of
special-purpose data could also drive Turing-complete com-
putations on the respective standard code that interpreted
such data (e.g., [19, 25, 1]).
At the same time, for microcontrollers, the meaning of
exploitation was diﬀerent, reﬂecting the diﬀerence in threat
models.
In servers, etc., exploitation’s typical goal is full
control of the target (“root shell”, for short); in microcon-
(cid:20)(cid:20)(cid:26)
trollers, it is the exﬁltration of ﬁrmware or data. For most
microcontroller deployments, ﬁrmware is the important thing;
once the attacker has the ﬁrmware, the rest of his goals
are easily accomplished. This may or may not be due to
ﬁrmware’s general buggyness and lack of higher-grade pro-
tection such as NX memory or randomization; sometimes
the ﬁrmware even contains passwords or private keys.
Goodspeed and Francillon demonstrated a good example
of advanced microcontroller attacks in [11]. Their “half-
blind” ROP attack circumvents protections of the MSP430,
using only knowledge of the MSP430 Bootstrap Loader (BSL)
code. The BSL is a small program present in ROM or pro-
tected ﬂash of the MSP430 that allows developers to pro-
gram the memory of the MSP430, typically for installing
ﬁrmware updates. BSL operations that read memory are
password protected in order to prevent unauthorized read-
out of code or data.
In this attack, the entry point of a
speciﬁc ROP gadget is guessed at random with a 1% suc-
cess rate, and a buﬀer overﬂow is found by fuzzing. Given
both this ROP gadget entry point and the buﬀer overﬂow
vulnerability, a ROP payload can be deployed to circumvent
protections in the BSL.
4. THREAT MODEL FOR MICROCONTR-
OLLERS
The security architecture of microcontroller was designed
with a speciﬁc threat model in mind. The secrecy of mi-
crocontroller ﬁrmware is crucial to prevent the production
of counterfeit products with identical ﬁrmwares and theft
of service through the alteration of ﬁrmware (e.g. changing
power usage records on a “smart meter” to reduce electric-
ity bills). To preserve the secrecy of ﬁrmware data while
still allowing devices to receive ﬁrmware updates, microcon-
troller manufacturers typically use a bootloader and a com-
bination of “fuses”—special write-once registers that contain
permissions—to enforce access control on read/write opera-
tions on ROM.
An attacker targeting microcontrollers therefore aims to
exﬁltrate data, such as ﬁrmware, from the chip package.
We assume that the attacker controls the processor, i.e., can
slow down the clock, observe General Purpose Input/Output
(GPIO), send signals to any pins, etc. However, we do not
assume that the attacker possesses the capability to carry
out sophisticated hardware attacks such as the one described