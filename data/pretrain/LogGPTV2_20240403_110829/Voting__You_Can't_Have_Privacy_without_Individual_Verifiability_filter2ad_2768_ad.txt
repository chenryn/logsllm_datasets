the last ballot revote policy. However, they can easily be adapted to
the first ballot revote policy and all our results hold in both cases
(as shown in appendix).
The revote policy is either based on the identities or the cre-
dentials. We say that a voting system is id-based if there exists a
a function openid which, given a ballot b, retrieves the associated
identity. Formally, for any id, cred, pk, v,
openid(Vote(id, cred, pk, v)) = id
Similarly, we say that a voting system is cred-based if there exists
a function opencred which, given a ballot b, the election secret key
sk, and a list U of registered voters and credentials, retrieves the
credential cred used by the voter to create the ballot. Formally, for
any id, cred, sk, pk, v,
opencred(Vote(id, cred, pk, v), sk, U) = cred
Oreg(id)
if (id, ∗) ∈ U then
stop
else
credid ← Credential(1λ, id)
U ← U∥(id, credid)
Ocorr(id)
if (id, ∗) (cid:60) U ∨ (id, ∗) ∈ CU then
stop
else
CU ← CU∥(id, credid)
return credid
where (id, credid) ∈ U
Figure 3: Registration and corruption oracles
Note that some schemes are neither id-based nor cred-based,
in particular when the ballots contain no identifier. Such schemes
typically assume that voters do not revote since there is no means
to identify whether two ballots originate from the same voter.
4.2 Security properties
As usual, an adversary is any probabilistic polynomial time Turing
machine (PPTM). We define verifiability and privacy through game-
based properties.
4.2.1 Verifiability. For verifiability, we propose a simple definition,
inspired from [15, 26]. Intuitively, we require that the election re-
sult contains at least the votes of all honest voters. This notion was
called weak verifiability in [15] but we will call it individual verifi-
ability to match the terminology used in symbolic settings. More
sophisticated and demanding definitions have been proposed, for
example controlling how many dishonest votes can be inserted [15]
or tolerating some variations in the result [26]. The main missing
part (in terms of security) is that our definition does not control
ballot stuffing: arbitrarily many dishonest votes may be added to
the result. The reason is that ballot stuffing seems unrelated to
privacy. Moreover, our definition assumes an honest tally, and thus
does not capture universal verifiability aspects. The main reason is
that existing privacy definitions in computational settings assume
an honest tally and we compare the two notions under the same
trust assumptions. We leave as future work to determine how to
extend these two definitions to a dishonest tally, and whether the
implication still holds.
Verifiability is defined through the game ExpverifA (λ) displayed
on Figure 4. In a first step, the adversary may use oracles Oreg(id)
and Ocorr(id) (defined on Figure 3) to respectively register a voter
and get her credential (in this case, the voter is said to be corrupted).
Then the adversary may ask an honest voter id to vote for a given
vote(id, v). In this case, the adversary sees
vote v through oracle Ov
the corresponding ballot and the fact that id voted for v is registered
in the list Voted. The adversary may also cast an arbitrary ballot
b in the name of a dishonest voter id through oracle Ocast(id, b).
Finally, the adversary wins if the election result does not contain
all the honest votes registered in Voted (where only the last vote is
counted).
Definition 4.2 (Individual verifiability). A voting system is indi-
vidually verifiable if for any adversary A,
P(cid:104)
ExpverifA (λ) = 1(cid:105) is negligible.
As mentioned in introduction, [13] shows an impossibility result
between (unconditional) privacy and verifiability. [13] considers
another aspect of verifiability, namely universal verifiability, that
is, the guarantee that the result corresponds to the content of the
ballot, even in presence of a dishonest tally. Interestingly, the same
incompatibility result holds between individual verifiability and
unconditional privacy, for the same reasons. Exactly like in [13],
a powerful adversary (i.e. not polynomial) could tally BB and BB′
where BB′ is the ballot box from which Alice’s ballot has been
removed and infer Alice’s vote by difference. More generally, un-
conditional privacy is lost as soon as there exists a tally function that
is meaningfully related to the result, which is implied by individual
verifiability.
4.2.2 Privacy. For privacy, we consider the old, well established
definition of Josh Benaloh [6]. More sophisticated definitions are
been proposed later (see [7] for a survey and a unifying definition).
They aim in particular at getting rid of the partial tally assumption
(needed in [6]). Note however that they all assume an honest ballot
box. Since we also assume partial tally, the original Benaloh def-
inition is sufficient for our needs. In particular, we do not know
if privacy implies verifiability for counting functions that do not
have the partial tally property. This is left as future work.
Intuitively, a voting system is private if, no matter how honest
voters vote, the adversary cannot see any difference. However, the
adversary always sees the election result, that leaks how the group
of honest voters voted (altogether). Therefore, the election result
w.r.t. the honest voters has to remain the same. More formally, in
a first step, the adversary uses oracles Oreg(id) and Ocorr(id) to
respectively register a voter and get her credential. Then the ad-
versary may request an honest voter id to vote either for v0 or v1
through oracle Op
vote(id, v0, v1). Voter id will vote vβ depending
on the bit β. The adversary may also cast an arbitrary ballot b in
the name of a dishonest voter id through oracle Ocast(id, b). The
election will be tallied, only if the set V0 of votes v0 yields the
same result than the set V1 of votes v1 (where only the last vote is
counted). Finally, the adversary wins if he correctly guesses β. For-
mally, privacy is defined through the game Exppriv, βA (λ) displayed
on Figure 5.
Definition 4.3 (Privacy [6]). A voting system is private if for any
adversary A,
(cid:12)(cid:12)(cid:12)P(cid:104)
A (λ) = 1(cid:105) − P(cid:104)
Exppriv,0
A (λ) = 1(cid:105)(cid:12)(cid:12)(cid:12) is negligible.
Exppriv,1
4.3 Privacy implies individual verifiability
We show that privacy implies individual verifiability and we first
list here our assumptions. As for the symbolic case, we assume the
existence of a neutral vote. We also require that the tally can be per-
formed piecewise, that is, informally, as soon as two boards BB1, BB2
are independant then Tally(BB1 ⊎ BB2) = Tally(BB1) ∗ Tally(BB2).
This property is satisfied by most voting schemes. Formally, we
characterize this notion of “independence” depending on whether
a scheme is id-based or cred-based.
An id-based voting scheme has the piecewise tally property if
for any two boards BB1 and BB2 that contain ballots registered for
8
1
(pk)
ExpverifA (λ)
(pk, sk) ← Setup(1λ)
U, CU ← []
state ← AOreg,Ocorr
BB, Voted ← []
AOv
(state, pk)
2
r ← Tally(BB, sk, U)
if r (cid:44) ⊥ ∧ ∀Vc (finite) . r (cid:44) ρ({vi }1≤i≤k ⊎ Vc) then
return 1
where Voted = {(id1, v1), . . . , (idk, vk)}
vote,Ocast
vote(id, v)
Ov
if (id, ∗) ∈ U\CU then
b ← Vote(id, credid, pk, v)
BB ← BB∥b
Voted ← Voted′∥(id, credid, v)
return b
where (id, credid) ∈ U
and Voted′ is obtained from Voted
by removing all previous instances of (id, ∗)
Ocast(id, b)
if (id, ∗) ∈ CU ∧
Valid(id, b, BB, pk)
then
BB ← BB∥(id, b)
Figure 4: Verifiability
1
(pk)
Exppriv, βA (λ)
(pk, sk) ← Setup(1λ)
U, CU ← []
state1 ← AOreg,Ocorr
BB, V0, V1 ← []
vote,Ocast
state2 ← AOp
if ρ(V0) = ρ(V1) then
r ← Tally(BB, sk, U)
β′ ← A3(state2, pk, r)
return β′
2
(state1, pk)
vote(id, v0, v1)
Op
if (id, ∗) ∈ U\CU then
b ← Vote(id, credid, pk, vβ)
BB ← BB∥b
V0 ← V′
V1 ← V′
return b
0∥(id, v0)
1∥(id, v1)
where (id, credid) ∈ U
and V′
by removing all instances of (id, ∗)
0 (resp. V′
1) is obtained from V0 (resp. V1)
Figure 5: Privacy
Ocast(id, b)
if (id, ∗) ∈ CU ∧
Valid(id, b, BB, pk)
then
BB ← BB∥(id, b)
vote(id, v)
Ovt
if ∃credid .(id, credid) ∈ U\CU then
return Vote(id, credid, pk, v)
different agents and such that BB1 ⊎ BB2 is valid, that is, if
ValidTally(BB1 ⊎ BB2, sk, U) ∧
∀b ∈ BB1. ∀b′ ∈ BB2. openid(b) (cid:44) openid(b′),
then their tally can be computed separately:
Tally(BB1 ⊎ BB2, sk, U) = Tally(BB1, sk, U) ∗ Tally(BB2, sk, U). (*)
We also assume that the tally only counts ballots cast with
registered ids, i.e. ∀BB, sk, U. Tally(BB, sk, U) = Tally(BB′, sk, U)
where BB′ = [b ∈ BB | (openid(b),∗) ∈ U]; and that registering
more voters does not change the tally: if U, U′ have no id in com-
mon and ∀b ∈ BB. (openid(b),∗) (cid:60) U′, then Tally(BB, sk, U) =
Tally(BB, sk, U ∪ U′).
Similarly, a cred-based voting scheme has the piecewise tally
property if for any two boards BB1 and BB2 that contain ballots
associated to different credentials, that is
, sk, U)
∀b ∈ BB1. ∀b
′
′ ∈ BB2. opencred(b, sk, U) (cid:44) opencred(b
then their tally can be computed separately (Property (*)).
We also assume that registering more voters does not change the
tally: if U, U′ share no credentials and∀b ∈ BB. (∗, opencred(b, sk, U∪
U′)) (cid:60) U′, then Tally(BB, sk, U) = Tally(BB, sk, U ∪ U′).
We say that a (id-based) voting scheme is strongly correct if
whatever valid board the adversary may produce, adding a honestly
generated ballot still yields a valid board. This property is formally
(λ) displayed in Figure 6. A
defined through the game ExpValidTally
A
(λ)
A
ExpValidTally
(pk, sk) ← Setup(1λ)
U, CU ← []
state ← AOreg,Ocorr
(BB, id, v) ← AOvt
b ← Vote(id, credid, pk, v)
where (id, credid) ∈ U
(pk)
(state, pk)
vote
1
2
if (id, ∗) ∈ U\CU ∧
(∀b′ ∈ BB. openid(b′) (cid:44) id) ∧
ValidTally(BB, sk, U) ∧
¬ValidTally(BB||b, sk, U) then
return 1
Figure 6: ValidTally game
similar assumption was introduced in [7]. For example, Helios is
strongly correct.
A voter credential typically includes a private part used to gen-
erate a signing key for example. It should not be possible for an
adversary to forge a ballot with an honest credential. Formally, we
say that a voting scheme has non-malleable credentials, if for any
9
Oc(id, v)
if (id, ∗) ∈ U\CU then
b ← Vote(id, credid, pk, v)
L ← L∥b
return b
where (id, credid) ∈ U
1
(pk)
ExpNMA (λ)