### Optimized Text

#### Restartable Images and Phase-Based Reboot
Two types of restartable images were created:
1. **pr-naive**: An image taken before the guest kernel mounted the virtual disk.
2. **pr-opt**: An image taken after the kernel and all daemons were ready, and a log-in prompt appeared.

For comparison, we also measured the downtime of a normal boot and a normal reboot on the guest domain (guest boot and guest reboot). To evaluate the effectiveness of our optimization described in Section IV-A, we performed the phase-based reboot without our snapshot optimization and measured its downtime (pr without snapshot opt).

Downtime measurements began when each operation was triggered and ended when all daemons registered in run level 3 were ready on the domain. We varied the memory size of the guest domain to measure the downtime of each reboot-based recovery.

#### Recovery Scenarios
We considered two scenarios for recovery:
1. **Fail-stop failures**: In this scenario, each reboot-based recovery includes an fsck execution because the Linux kernel runs fsck during boot if the system was shut down without unmounting partitions.
2. **Gradually corrupting failures (e.g., memory leaks)**: In this scenario, no fsck execution is needed, as we assume the virtual disk was correctly unmounted.

#### Downtime Comparison
Tables I and II list the average downtime of each reboot-based recovery. Table I shows that the phase-based reboot had shorter downtime than the guest boot in many cases. Specifically:
- **pr-opt**: Downtime was 75.0% to 86.2% shorter than the guest boot.
- **pr-naive**: Downtime was 34.3% to 60.6% shorter than the guest boot.
- **pr without snapshot opt**: Downtime was shorter than the guest boot when the domain memory size was less than 2 GB.

Table II shows similar results, with the phase-based reboot having shorter downtime than the guest reboot in many cases:
- **pr-opt**: Downtime was 86.1% to 93.6% shorter than the guest reboot.
- **pr-naive**: Downtime was 60.1% to 77.6% shorter than the guest reboot.

#### Downtime Analysis
Figure 4 breaks down the downtime of pr without snapshot opt, pr-naive, and pr-opt. The figure highlights the significant contribution of our snapshot optimization in reducing the downtime of reboot-based recovery. In pr without snapshot opt, the restore time was much longer, especially for larger memory sizes (e.g., 37 seconds for 2 GB and 66 seconds for 4 GB). This is because Xen's snapshot function saves and restores all memory pages, even unused ones. In contrast, the optimized configurations (pr-naive and pr-opt) had a maximum restore time of 5.8 seconds.

Additionally, our snapshot optimization reduced the size of restartable images. For example, with 1024 MB of memory, the optimized snapshot saved only 99 MB, compared to 1050 MB with Xen's snapshot function. By using RAM disks or solid-state drives for these memory checkpoints, we further shortened the downtime of the phase-based reboot.

Omitting the kernel and daemon boot phase also effectively reduced downtime (Figures 4(b) and 4(c)). In pr-naive, the main downtime was due to booting the kernel and daemons, while in pr-opt, the downtime was 61.9% to 67.2% shorter than pr-naive.

#### Finding Restartable Images
To determine which restartable candidate is suitable under a complex workload, we used RUBiS [6], a benchmark that models a real web site. We prepared additional physical machines with the same specifications as previously described, connected via Gigabit Ethernet. One machine ran the RUBiS client emulator, while another ran Xen 3.4.1, hosting three guest domains: a web server (FrontVM), an application server (AppVM), and a database server (DBVM).

We emulated 500 clients and checked whether the restartable candidates were valid images in two ways:
1. Conducting the phase-based reboot after the emulation finished.
2. Conducting the phase-based reboot while the client emulator was running.

Each guest domain was assigned 1.7 GB of memory, based on the small VM configuration in Amazon Elastic Compute Cloud [8].

#### Restartable Points
Restartable points were defined as follows (Figure 5):
- **Point A**: Before mounting the virtual disk.
- **Point B**: After completing the kernel boot.
- **Point C**: When all configured daemons were launched.
- **Point D**: When a log-in prompt appeared.
- **Point E**: After launching Apache, Tomcat, and MySQL.

#### Results
Tables III and IV show the results of the checks:
- **Table III**: Indicates which restartable candidate is valid when the emulation has finished. FrontVM and AppVM can use Point E, but DBVM cannot due to updated files like /var/log/mysqld.log and /var/lib/mysql/ib_logfile.
- **Table IV**: Shows the results when the phase-based reboot is conducted while the client emulator is running. FrontVM and AppVM sometimes cannot use Point E due to updates in /etc/httpd/logs/error_log.

We found that some logs, such as /var/log/mysqld.log and /etc/httpd/logs/error_log, were frequently updated, affecting the validity of the restartable images.