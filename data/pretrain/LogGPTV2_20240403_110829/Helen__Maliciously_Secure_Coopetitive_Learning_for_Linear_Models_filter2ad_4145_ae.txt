2% of the input preparation phase and 22% of Helen’s model
compute phase.
(a) Helen’s scaling as we increase
the number of dimensions. The
number of parties is ﬁxed to be
4, and the number of samples per
party is 100, 000.
(b) Helen’s two phases as we
increase the number of parties.
The dimension is set to be 10,
and the number of samples per
party is 100, 000.
Fig. 3: Helen scalability measurements.
D. Real world datasets
SGD scales linearly in n and d. If the number of samples
per party is doubled, the number of iterations is also doubled.
A similar argument goes for d. SGD scales quadratic in m
because it ﬁrst scales linearly in m due to the behavior of the
MPC protocol. If we add more parties to the computation, the
number of samples will also increase, which in turn increases
the number of iterations needed to scan the entire dataset.
Helen, on the other hand, scales linearly in n only for the
SVD computation. We emphasize that SVD is very fast because
it is executed on plaintext data. The c1 part of the SVD proofs
formula scales linearly in m because each party needs to verify
from every other party. It also scales linearly in d2 because each
proof veriﬁcation requires d2 work. The c2 part of the formula
has d3 scaling because our matrices are d× d), and to calculate
a resulting encrypted matrix requires matrix multiplication on
two d × d matrices.
The coordination phase from Helen’s model compute phase,
as well as the corresponding MPC ofﬂine compute phase, scale
quadratic in m because we need to use MPC to re-scale weight
vectors from each party. This cost corresponds to the c1 part
of the formula. The model compute phase’s d2 cost (c2 part of
the formula) reﬂects the matrix multiplication and the proofs.
The rest of the MPC conversion proofs scale linearly in m and
d (c3 part of the formula).
C. Synthetic datasets
We want to answer two questions about Helen’s scalability
using synthetic datasets: how does Helen scale as we vary
the number of features and how does it scale as we vary the
number of parties? Note that we are not varying the number of
input samples because that will be explored in Section VIII-D
in comparison to the secure SGD baseline.
Fig. 3a shows a breakdown of Helen’s cryptographic com-
putation as we scale the number of dimensions. The plaintext
SVD computation is not included in the graph. The SVD proofs
phase is dominated by the matrix multiplication proofs, which
scales in d2. The MPC ofﬂine phase and the model compute
phase are both dominated by the linear scaling in d, which
corresponds to the MPC conversion proofs.
Fig. 3b shows the same three phases as we increase the
number of parties. The SVD proofs phase scales linearly in the
We evaluate on two different real world datasets: gas sensor
data [29] and the million song dataset [9, 29]. The gas sensor
dataset records 16 sensor readings when mixing two types of
gases. Since the two gases are mixed with random concentration
levels, the two regression variables are independent and we can
simply run two different regression problems (one for each gas
type). For the purpose of benchmarking, we ran an experiment
using the ethylene data in the ﬁrst dataset. The million song
dataset is used for predicting a song’s published year using 90
features. Since regression problems produce real values, the
year can be calculated by rounding the regressed value.
For SGD, we set the batch size to be the same size as the
dimension of the dataset. The number of iterations is equal to
the total number of sample points divided by the batch size.
Unfortunately, we had to extrapolate the runtimes for a majority
of the baseline online phases because the circuits were too big
to compile on our EC2 instances.
Fig. 4 and Fig. 5 compare Helen to the baseline on the two
datasets. Note that Helen’s input preparation graph combines
the three phases that are run during the ofﬂine: plaintext SVD
computation, SVD proofs, and MPC ofﬂine generation. We
can see that Helen’s input preparation phase scales very slowly
with the number of samples. The scaling actually comes from
the plaintext SVD calculation because both the SVD proofs
and the MPC ofﬂine generation do not scale with the number
of samples. Helen’s model compute phase also stays constant
because we ﬁxed the number of iterations to a conservative
estimate. SGD, on the other hand, does scale linearly with the
number of samples in both the ofﬂine and the online phases.
For the gas sensor dataset, Helen’s total runtime (input
preparation plus model compute) is able to achieve a 21.5x
performance gain over the baseline’s total runtime (ofﬂine
plus online) when the number of samples is 1000. When the
number of samples per party reaches 1 million, Helen is able to
improve over the baseline by 20689x. For the song prediction
dataset, Helen is able to have a 9.1x performance gain over
the baseline when the number of samples is 1000. When the
number of samples per party reaches 100K, Helen improves
over the baseline by 911x. Even if we compare Helen to the
baseline’s ofﬂine phase only, we ﬁnd that Helen still has close
to constant scaling while the baseline scales linearly with the
number of samples. The performance improvement compared
(cid:24)(cid:20)(cid:21)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:40:42 UTC from IEEE Xplore.  Restrictions apply. 
Samples per party
sklearn L2 error
Helen L2 error
sklearn MAE
Helen MAE
2000
8937.01
8841.33
57.89
57.23
4000
8928.32
8839.96
58.07
57.44
6000
8933.64
8828.18
58.04
57.46
8000
8932.97
8839.56
58.10
57.44
10K
8929.10
8837.59
58.05
57.47
40K
8974.15
8844.31
58.34
57.63
100K
8981.24
8876.00
58.48
58.25
200K
8984.64
8901.84
58.55
58.38
400K
8982.88
8907.38
58.58
58.36
800K
8981.11
8904.11
58.56
58.37
1M
8980.35
8900.37
58.57
58.40
TABLE II: Select errors for gas sensor (due to space), comparing Helen with a baseline that uses sklearn to train on all plaintext
data. L2 error is the squared norm; MAE is the mean average error. Errors are calculated after post-processing.
Samples per party
sklearn L2 error
Helen L2 error
sklearn MAE
Helen MAE
1000
92.43
93.68
6.86
6.92
2000
91.67
91.8
6.81
6.82
4000
90.98
91.01
6.77
6.77
6000
90.9
90.91
6.78
6.78
8000
90.76
90.72
6.79
6.79
10K
90.72
90.73
6.81
6.81
20K
90.63
90.67
6.80
6.80
40K
90.57
90.57
6.79
6.79
60K
90.55
90.54
6.79
6.80
80K
90.56
90.57
6.80
6.80
100K
90.55
90.55
6.80
6.80
TABLE III: Errors for song prediction, comparing Helen with a baseline that uses sklearn to train on all plaintext data. L2 error
is the squared norm; MAE is the mean average error. Errors are calculated after post-processing.
Fig. 4: Helen and baseline performance on the gas sensor data.
The gas sensor data contained over 4 million data points; we
partitioned into 4 partitions with varying number of sample
points per partition to simulate the varying number of samples
per party. The number of parties is 4, and the number of
dimensions is 16.
Fig. 5: Helen and baseline performance on the song prediction
data, as we vary the number of samples per party. The number
of parties is 4, and the number of dimensions is 90.
Fig. 6: Helen comparison with SGD
to the baseline ofﬂine phase is up to 1540x for the gas sensor
dataset and up to 98x for the song prediction dataset.
In Table II and Table III, we evaluate Helen’s test errors on
the two datasets. We compare the L2 and mean average error
for Helen to the errors obtained from a model trained using
sklearn (a standard Python library for machine learning) on the
plaintext data. We did not directly use the SGD baseline because
its online phase does not compile for larger instances, and using
sklearn on the plaintext data is a conservative estimate. We can
see that Helen achieves similar errors compared to the sklearn
baseline.
IX. RELATED WORK
We organize the related work section into related coopetitive
systems and attacks.
A. Coopetitive systems
Coopetitive training systems. In Fig. 7, we compare Helen to
prior coopetitive training systems [56, 41, 34, 20, 35, 5, 54, 66].
The main takeaway is that, excluding generic maliciously secure
MPC, prior training systems do not provide malicious security.
Furthermore, most of them also assume that the training process
requires outsourcing to two non-colluding servers. At the same
time, and as a result of choosing a weaker security model,
some of these systems provide richer functionality than Helen,
such as support for neural networks. As part of our future
work, we are exploring how to apply Helen’s techniques to
logistic regression and neural networks.
Other coopetitive systems. Other than coopetitive training
systems, there are prior works on building coopetitive systems
for applications like machine learning prediction and SQL
analytics. Coopetitive prediction systems [13, 62, 60, 51, 36, 45]
typically consist of two parties, where one party holds a model
and the other party holds an input. The two parties jointly
(cid:24)(cid:20)(cid:22)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:40:42 UTC from IEEE Xplore.  Restrictions apply. 
Work
Nikolaenko et al. [56]
Hall et al. [41]
Gascon et al. [34]
Cock et al. [20]
Giacomelli et al. [35]
Alexandru et al. [5]
SecureML [54]
Shokri&Shmatikov [66]
Semi-honest MPC [7]
Malicious MPC [27, 37, 11, 2]
Our proposal, Helen: regularized linear models
Functionality
ridge regression
linear regression
linear regression
linear regression
ridge regression
quadratic opt.
linear, logistic, deep
learning
deep learning
any function
any function
n-party?
no
yes
no
no
no
no
no
Maliciously secure?
no
no
no
no
no
no
no
not MPC (heuristic)
yes
yes
yes
no
no
yes
yes
Practical?
–
–
–
–
–