the ﬁle system’s rootkey. While the rootkey allows a user to
launch a NEXUS instance for a particular volume, it does not
automatically grant access to the data stored in that volume. For
that, the NEXUS enclave performs a second step ensuring that
the identity used to authenticate into the volume is authorized
by the access control policies stored in the ﬁle’s metadata.
Cryptographic Notation. We denote a (public, private) keypair
as {pk, sk}, and use PKGEN() to indicate public keypair
generation. SIGN(sk, m) represents a signature over m us-
ing sk, and VERIFY(pk, s) indicates the veriﬁcation of a
signature s using pk. ENC/DEC(k, m) denotes symmetric key
encryption/decryption.
In NEXUS, identity is established using public-private key
pairs, where each authorized user’s public key is stored inside
the supernode metadata ﬁle. Each identity has an associated
user ID that is used in the access control policies maintained
by the dirnodes. To authenticate into a NEXUS volume the
user performs the following challenge-response protocol:
1) The user requests to authenticate by making a call into the
NEXUS enclave with their public key (pku) and the sealed
volume rootkey as arguments.
2) Inside the enclave, the rootkey is unsealed. Then, a random
128-bit nonce is generated, and returned to the calling user.
3) The user then uses their private key to create a signature over
the encrypted supernode structure of the volume and the
enclave nonce. This signature and the encrypted supernode
are then passed to the enclave.
m = SIGN(sku, nonce| ENC(rootkey, supernode))
4) Inside the enclave, the volume rootkey is used to decrypt and
verify the supernode. After ﬁnding the user’s entry inside
the supernode, the enclave then validates the signature with
the user’s public key.
5) On success, the user’s ID is cached inside the enclave.
This protocol establishes that (i) the user as the owner of the
public key stored (via signature veriﬁcation), (ii) the user has
been granted access to the volume (via the presence of their
public key in the supernode), and (iii) the supernode itself has
not been modiﬁed (via metadata protection). Once access is
granted, the volume is mounted, and becomes available.
1) Granting access to other users: Sharing data with
NEXUS is complicated by the fact that SGX generates a
unique sealing key on each machine. This means that a sealed
rootkey cannot simply be passed between enclaves when a
new user is granted permission to access a volume, or when
an authorized user accesses a volume using a new machine.
At the same time, the rootkey cannot be encrypted with a key
available outside of the enclave context (e.g., a user’s public
key) without compromising the volume’s security. To overcome
this challenge, we incorporated a key exchange protocol that
allows a volume’s rootkey to be distributed to remote NEXUS
instances while ensuring that it will only be accessible from
within a NEXUS enclave. This protocol relies on an Elliptical
Curve Difﬁe Hellmann (ECDH) key exchange combined with
parent uuid: mk89ce0chunk 3 keychunk 2 keychunk 1 keyNexus supernoderoot_dirfd21sdwparent uuid: fd21sdwdocsnamep021a21cake.ceQme23auuidparent uuid: fd21sdwmk89ceok2la32wuuidbara.txtname bar/cake.ca.txtdocs/$(NEXUS_ROOT)n44da2(encrypted ﬁle)chunk 3chunk 2chunk 1data ﬁle uuid: n44da2fd21sdw(dirnode)mk89ce0(dirnode)po21a21(ﬁlenode)Fig. 4: Key Exchange protocol diagram for Owen sharing his NEXUS volume rootkey with Alice.
enclave attestation features available in SGX. All messages are
communicated in-band using the underlying storage service to
exchange data between endpoints.
Consider the case where a NEXUS volume owner, Owen,
wishes to grant access to his volume to another user, Alice.
The end result of the protocol will be that Alice has a locally
sealed version of the rootkey for Owen’s NEXUS volume, and
Alice’s public key will be present in list of users stored inside
the volume’s supernode. We assume that Alice’s public key
is available to Owen via some external mechanism (e.g., as
in SSH). The endpoints of the protocol are actual NEXUS
enclaves, and the execution is as follows (Figure 4):
1) Setup: As part of the initialization process of a NEXUS
volume, an ECDH keypair (pke, ske) is generated inside the
NEXUS enclave. The private key is only ever accessible
inside the enclave, and is encrypted with the enclave sealing
key before being stored persistently. To export the public
key, the user generates an enclave quote supplying the public
key as authenticated data. This quote a) identiﬁes the user’s
enclave and b) cryptographically binds the ECDH public to
the enclave. The quote is signed with the owner’s private
key, and then stored on the underlying storage service in a
location that is accessible to the other users in the system.
Q = QUOTE(pke)
m1 = SIGN(sku, Q)| pke
Where {pku, sku} is the volume owner’s public keypair
and Q is the enclave quote with the enclave ECDH public
key, pke, as authentication data.
2) Exchange: Whenever Owen wishes to grant Alice access to
his ﬁle system, he must transfer a copy of his volume rootkey
to Alice. To do this, Owen ﬁrst validates the quote generated
from Alice’s enclave (by checking that the signature matches
Alice’s public key and verifying the quote with Intel) before
extracting the enclosed enclave public key, pkea. Then,
within the enclave, Owen generates an ephemeral ECDH
keypair (pkeph, skeph), and combines it with pkea to derive
a common secret that encrypts his volume rootkey. The
encrypted rootkey and the ephemeral ECDH public key
(the private portion is discarded) are signed using Owen’s
private key and stored on the underlying storage service in
a location that is accessible to Alice.
k ← ECDH_SECRET(skeph, pkea)
h = ENC(k, rootkey)
m2 = SIGN(sko, h)| pkeph
3) Extraction: Alice ﬁrst validates Owen’s signature and then,
using the enclave private key, she derives the ECDH secret
and decrypts the rootkey.
k ← ECDH_SECRET(skea, pkeph)
rootkey = DEC(k, h)
Since the ECDH secret can only be derived within the
enclave, our protocol ensures the rootkey is only accessible
within valid NEXUS enclaves. The rootkey can then be
sealed and stored to Alice’s local disk. Later, once Alice
authenticates, she can decide to mount Owen’s volume using
the corresponding rootkey.
C. Access Control
Even after a user has been granted access to a volume’s
rootkey, access to ﬁles within the volume is further restricted
via access control policies enforced by the NEXUS enclave.
Access control is based on: 1) the user’s identity as speciﬁed
by the private key they authenticated with, 2) the permissions
stored in the respective metadata. With this, access control
enforcement is independent of the server, and because the
metadata is encrypted and sealed, the access policies cannot
be viewed nor undetectably tampered by any attacker.
We implemented a typical Access Control List (ACL) scheme
in which users have unique IDs mapped to (username, public
key) pairs, and permissions apply to all ﬁles (and subdirectories)
within a directory. We leveraged the user list in the supernode
to bind every user to a unique ID, and store the directory ACLs
comprising of (user ID, access right) in the dirnode. Hence, to
enforce access control within a given directory:
• The dirnode metadata is decrypted inside the enclave.
• If the current user is the owner of the volume, permission
is granted to the user and the enclave exits.
• Otherwise, the user’s ID is used to ﬁnd the corresponding
ACL entry inside the dirnode’s ACL. Permission is granted
if the user’s ACL entry satisﬁes the required access rights.
NEXUS denies access by default and automatically grants
administrative rights to the volume owner, who maintains
complete control over their volume. Revoking a user is
performed either by removing them from the user list, or
removing their ACL entry from the dirnode. In both cases,
the process is relatively inexpensive as it only requires re-
encrypting the affected metadata.
V. IMPLEMENTATION
We implemented NEXUS as a Linux service that provides
secure access to protected volumes. We extended OpenAFS [20]
owenserveraliceowen’s keypair: {pk_o, sk_o}{pk_eo, sk_eo} <- PKGEN()Q1 = QUOTE(pk_eo)m1 = SIGN(sk_o, Q1) | pk_eoalice’s keypair: {pk_a, sk_a}{pk_ea, sk_ea} <- PKGEN()Q1’ = QUOTE(pk_ea)m1’ = SIGN(sk_a, Q1’) | pk_eam1owenserverVERIFY_QUOTE(Q1’){pk_eph, sk_eph} <- PKGEN()k <- ECDH_SECRET(sk_eph, pk_a)h = ENC(k, rootkey)m2 = SIGN(sk_a,  h)) | pk_ephm2VERIFY(pk_o, m2)k’ <- ECDH_SECRET(sk_ea, pk_eph)rootkey <- DEC(k’, h)m1’serveralicem1’m2SETUPEXCHANGEEXTRACTION— a widely used opensource distributed ﬁlesystem — to
manage protected volumes on the network, without any
modiﬁcations on the server-side or changes in the user’s typical
ﬁle management workﬂow. Our interface does not make any
internal modiﬁcations to OpenAFS, it simply calls the NEXUS
ﬁlesystem API via a shimlayer. Excluding third party libraries,
our implementation comprises about 22618 SLOC. Integrating
with OpenAFS (90K SLOC) required about 3200 SLOC.
Our prototype acts as a stackable layer interposed between
user applications and the host ﬁlesystem. We split the prototype
into an untrusted portion and a trusted portion. The untrusted
portion (9005 SLOC) mainly (1) forwards requests into the
enclave via the ﬁlesystem API, and (2) facilitates enclave access
to data and metadata on the underlying storage service.
The NEXUS enclave is designed to be minimalistic; with
a codebase size amounting to 9900 SLOC and a 512 KB
binary, its veriﬁcation is well within the reach of modern
model-checking tools. Additionally, this small size ensures that
NEXUS easily ﬁts in enclave-reserved memory (SGX provides
about 96 MB [30]). We included a subset of the MbedTLS
Cryptographic Library [31], which added about 212KB. For
GCM-SIV key wrapping, we used the C-based implementation
provided by Gueron et al. [29, 32]. Our enclave interface
comprises 13 enclave calls (ecalls), and 10 outside calls (ocalls).
Ecalls invoke speciﬁc entrypoints within the enclave, and
are mostly concerned with marshalling I/O requests from the
ﬁlesystem API. Ocalls help with managing untrusted memory
and accessing data/metadata objects. To prevent inadvertent
data leakage, we sanity-check our inputs and employ secure
data serializers on sensitive outputs.
A. Data Consistency
Because NEXUS manages metadata internally, every ﬁlesys-
tem request triggers several I/O requests to the underlying
storage service. As a result, in the situation whereby a ﬁle is
simultaneously accessed by multiple users, a user’s NEXUS
enclave might fetch an older version of the metadata. To
prevent this possible mismatch, on every ﬁlesystem request that
updates metadata (e.g., create, delete, rename), NEXUS locks
metadata structures via the facilities provided by the storage
service. In our OpenAFS-based implementation, this locking
is accomplished by invoking flock() on the metadata ﬁle.
Once both data and metadata are ﬂushed to storage, the lock is
released, allowing users to access the ﬁle. Note that the lock is
not required when accessing metadata ﬁles on read operations.
B. Optimizations
For every ﬁlesystem request to NEXUS, the enclave fetches
one or more metadata objects from the backing store to
complete the request. Because of the network cost, this makes
metadata-intensive operations cost prohibitive. To address this,
we introduced several caches to speedup data access. This in-
cludes a VFS-like directory cache structure (dentry tree) inside
the enclave, and caching the metadata locally (unencrypted in
enclave memory, or encrypted in untrusted memory). This way,
unless a ﬁle is modiﬁed remotely, subsequent access need not
download the ﬁle contents from the server.
To improve performance on larger directories, we split
dirnodes into independently-encrypted buckets. Each bucket
contains a user-conﬁgurable number of directory entries, and
are stored as separate metadata objects. The main bucket stores
the directory’s access control as well as the MAC of each bucket
to prevent rollback attacks at the bucket level. When writing
the dirnode to the underlying storage service, the enclave only
ﬂushes the main bucket, and any dirty buckets.
VI. SECURITY ANALYSIS
Our goal is to provide a secure and scalable ﬁlesystem
in which users maintain complete control over their data.
Against the backdrop of threats outlined in Section III-A, we
now discuss how NEXUS meets its security objectives. By
combining encryption and access control within the enclave,
NEXUS achieves self-protection [33]: the ability to protect
sensitive data from all entities — trusted or untrusted — using
the data’s attached policy. Thus, security guarantees are:
• File and (protected) metadata contents, as well as ﬁle/direc-
tory names are conﬁdential, and only accessible to authorized
users.
• All data and metadata are tamper-evident, and can only be
updated by individuals with the necessary write permissions.
Recall that we consider an attacker who has complete control of
the server, including full access to all packets exchanged with
the client, and a history of the user’s encrypted ﬁles. Further,
to encompass the abilities of a revoked user, we assume that
the attacker once had access to the owner’s volume i.e., the
attacker has a copy of the volume owner’s sealed rootkey, but
their public key is no longer stored in the volume’s supernode.
A. Conﬁdentiality and Integrity
Conﬁdentiality is enforced by encrypting all sensitive data
within the enclave, allowing decryption only after performing
adequate permission checks. The user’s ﬁles are encrypted in
ﬁxed-sized chunks, and are re-encrypted using fresh keys on
every ﬁle content update. These per-ﬁle chunk keys are stored
in the encrypted portion of the ﬁlenode associated with the ﬁle.
To protect directory entries, we replace the original human-
readable ﬁlename (or directory name) with a random name,
and store the correspondence in the encrypted portion of the
dirnode. The metadata are re-encrypted on every update, and
their encryption keys are key-wrapped with the volume rootkey.
Therefore, to read the data, one must obtain access to the
volume rootkey. Moreover, because all encryption is performed
using AEAD cryptographic primitives, data integrity is provided
alongside conﬁdentiality. Hence, any illegal modiﬁcations of
the ciphertext will be detected by the NEXUS enclave.
B. Authorization: Access to keys
Our security guarantees hinge on the secrecy of the rootkey,
which must only be accessible within the enclave and require
validation of the user’s identity before use. At volume creation,
the volume rootkey is generated within the enclave and is
persisted to the local disk using SGX sealed storage. This
ensures that it cannot be accessed outside of a valid NEXUS
enclave running on this particular processor. Before permitting
the use of a volume rootkey, the NEXUS enclave validates the
user’s identity. To accomplish this, the user must demonstrate
proof of knowledge of the private key associated with a public
key stored in the volume’s supernode via a challenge/response
protocol. Therefore, even with a sealed copy of the rootkey,
unless the attacker’s public key is stored within the volume’s
supernode, they will be denied by the enclave.
As shown in Section IV-B, we enable secure ﬁle sharing
by leveraging SGX Remote Attestation to exchange rootkeys
between valid NEXUS enclaves running on genuine SGX
processors. Our construction involves an asynchronous ECDH
key exchange in which the recipient’s NEXUS enclave is
remotely attested before securely transmitting the rootkey
encrypted with the ECDH secret. The ECDH keypairs are
generated within the enclave, and their public keys are used to
create SGX quotes. Since the ECDH private keys never leave
enclave memory, the ECDH secret can only be derived within
the enclave, thereby ensuring that the rootkey is not leaked
unto untrusted storage. However, because we keep long-term
ECDH keypairs ﬁxed and exposed on the remote server, our
key exchange protocol fails to provide perfect forward secrecy.
In the event the attacker reconstructs the matching enclave
ECDH private key, he will be able to extract every rootkey
exchanged with the user. To mitigate this, we propose an
alternative synchronous solution where, both parties generate
ephemeral ECDH keys on every exchange and mutually attest
their enclaves. This approach introduces an additional delay
as it involves multiple rounds to attest the enclaves. Please
note that in practice, the security and convenience tradeoffs of
either approach will be left to the volume owner.
C. Attacking File System Structure