results of simulating more than 106 challenge-response pairs
as replay attempts show that we achieve close to perfect true
reject rates (TRR) of 99.94%. At the same time, very few
legitimate attempts are incorrectly rejected: the evaluation
shows a true accept rate (TAR) of 98.63%, a result of falsely
rejecting only 14 out of 1021 legitimate attempts.
EER:Internal attackers: 6.2%External attackers: 7.3%All attackers: 6.3%FARFRR0.000.250.500.751.000.000.250.500.751.000.000.100.200.000.100.2002550751000255075100Stimulus positions successfully looked at [%]Fraction [%]Replay samples rejected Legitimate samples acceptedTable 2: Comparison to existing biometric authentication systems based on eye-movements
.
f
l
e
v
e
l
-
h
g
i
h
.
f
l
e
v
e
l
-
w
o
l
Analysis of
Scan paths + arch densities
Distribution of areas of interest
Graph matching
Fixation density maps
Stimulus
Human faces
Human faces
Human faces
Movie trailer
Cepstrum transform of raw signal Dot, ﬁxed inter-stimulus
Oculomotor plant model
Dot, horizontal sequence
Scan paths and ﬁxation features Read section of text
Read section of text
Fixation and saccade features
Liveness detection
Dot, horizontal sequence
Fixation features and pupil sizes Click the dot
Fixation and saccade features Dot, interactive
this paper
Ref. Time [s] EER [%]
Notes
[7]
[14]
[35]
[36]
[22]
[27]
[17]
[16]
[28]
[13]
17
10
4
60
8
21
60
60
100
40
5
25
36.1
30
14
N/A
N/A
23
16.5
FAR 2%, FRR 22%
FAR 5.4%, FRR 56.6%
18 Focus on liveness detection
7.8 Continuous authentication
6.3
Replay: FAR 0.06%
Overall, these results show that our system robustly pre-
vents replay attempts for a wide range of thresholds with
very high success rates. Furthermore, taking into account
that the system can detect repeated replay attempts, and
e.g.
lock user’s account after certain number of failed at-
tempts, we ﬁnally conclude that our system can eﬀectively
prevent replay attacks.
8. RELATED WORK
While diﬀerent eye tracking methods have been used in
medical research for over a century, their use in security is
fairly recent. A review paper by Zhang et. al. [43] pro-
vides an overview of authentication methods and systems
proposed before 2010, while Saeed [37] gives a more recent
comparison of methods and results of gaze-based authen-
tication systems proposed up to year 2013. According to
Zhang et. al. [43], existing work in user identiﬁcation and
authentication can be roughly divided into two categories:
1) using gaze tracking as a human-computer interface (con-
trol channel) to support standard security primitives and
2) using characteristics of the gaze patterns to extract in-
dividual biometric traits that enable distinguishing between
diﬀerent users.
In the ﬁrst line of research, individuals use their eyes to
prove their identity by naturally and covertly inputting se-
cret information such as passwords [29, 42, 6] or speciﬁc
patterns on the screen [5, 11, 25]. Using eyes as a con-
trol channel has several advantages, such as prevention of
shoulder-surﬁng and smudge attacks. Unfortunately, these
approaches usually share the negative characteristics of pass-
words, such as requiring the users to learn a procedure or re-
member and recall diﬀerent pieces of information, as well as
still being susceptible to eavesdropping and replay attacks.
Our work belongs to the second, biometric approach that
uses the characteristics of individual’s gaze patterns to dis-
criminate between diﬀerent users. Such authentication sys-
tems usually come with the general beneﬁts, but also chal-
lenges typical of biometrics: they usually require no mem-
orization, prevent sharing of credentials, and oﬀer high us-
ability, but at the same time, they suﬀer from irrevocability,
which renders replay attacks a serious threat if even a single
user’s biometric sample is acquired by an attacker.
Biometric approaches to gaze-based authentication can be
further divided into two subcategories: those that rely on
high-level characteristics of user’s gaze patterns (where and
what the user is looking at), and those that analyze the low-
level traits of how the user’s eyes are moving.
High-level Characteristics. The ﬁrst approach is moti-
vated by hypotheses that users exhibit individual behavior
during certain tasks, and thus extracts high-level charac-
teristics of users’ responses while the users are instructed
to freely look at videos, photos of faces, or other speciﬁc
types of stimuli. Prior work includes analysis of scan paths
and arch densities [7], areas of interest on human faces [14],
graph matching [35] and ﬁxation density maps [36].
As summarized in Table 2, existing work in this cate-
gory mostly achieves Equal Error Rates higher than 15%,
which is likely due to complex features being more depen-
dent on varying cognitive and physiological states of the
user. Furthermore, in order to acquire suﬃcient data to
extract complex features, these systems require often long
authentication times (measured in tens of seconds!), so fur-
ther improvements are needed before they can be applied to
real-world systems.
Low-level Characteristics. On the other hand, moti-
vated by psychological and neurophysiological research [8]
that suggests stable diﬀerences between users [44], several
authors researched systems that use low-level characteris-
tics of users’ eye movements as features for discrimination,
such as eye movement velocity proﬁles, sizes of ﬁxation ar-
eas, saccade latencies, etc.
Kasprowski is one of the ﬁrst authors to start systemati-
cally researching the low-level characteristics of user’s gaze
for authentication. In his initial paper [22] and correspond-
ing PhD thesis [19], he proposes using features such as the
distance between the left and right eye-gaze, Fourier and
wavelet transforms of the raw gaze signal, and average ve-
locity directions. The used stimulus consists of 9 LED lights
arranged in a 3x3 grid, where the position of the single active
light changes according to a ﬁxed, equally timed sequence,
regardless of the user’s gaze. An experimental study showed
half total error rates of close to 12%, but with relatively high
false reject rates of 22%. In relation to our proposal, such
stimulus also leads to eliciting some reﬂexive saccades, but as
Table 2 shows, it results in longer authentication times and
higher error rates. This is likely due to periods of time where
the user has already gazed at the light, but is still waiting
for the position of the active LED to change. Finally, the
authors propose, organize and describe two yearly competi-
tions in eye movements veriﬁcation and identiﬁcation using
their datasets [20, 21], which have further increased the re-
search interest in gaze-based authentication.
Komogortsev proposes modeling the physiological prop-
erties of individuals’ oculomotor plant [27] during multiple
horizontal saccades and using the estimated model parame-
ters as features for classiﬁcation. Related work by Holland
et al. [17] provides an insight into performances of multiple
features such as ﬁxation counts and durations during text
reading and combines these two approaches to achieve an
EER of 23%, while the newer research [16] provides an addi-
tional analysis of 13 classiﬁcation features based on ﬁxations
and saccades and achieves an EER of 16.5%.
In contrast to point-of-entry authentication, Eberz et al. [13]
propose using 21 low-level characteristics of eye movements
to continuously re-authenticate users, regardless of their cur-
rent task. For one parameter combination, the authors achieve
Equal Error Rates of 7.8% when 40 seconds are chosen as a
period before making the ﬁrst decision. Primarily because
of requirement of task independence in a continuous authen-
tication scenario, potential replay attacks remain a serious
vulnerability. If the attacker is able to capture even a very
short recording of legitimate user’s gaze, he can continuously
rewind and replay it back to the gaze tracking device, and
this causes the system to (correctly!) accept the received
eye movements as coming from a legitimate user.
9. DISCUSSION
Advanced Attacks. A more sophisticated attacker could
build a model of a legitimate user’s eye movements to suc-
cessfully respond to a given challenge. However, we argue
that performing such attacks is not straightforward and re-
quires a higher level of complexity than simply replaying a
biometric sample.
Firstly, the adversary is likely to be solving a harder prob-
lem than the system; while the system needs to build a
discriminative model that allows making a binary decision
about user’s identity, the adversary needs to actually gen-
erate eye movements which correspond to the legitimate
user. An indication of the diﬃculty of artiﬁcially creating
eye-movements can be found in work by Komogortsev et
al. [28], which evaluated the complexity of a signiﬁcantly
simpler problem: artiﬁcially generating 1-dimensional eye
movements. The paper showed that those movements could
be distinguished from natural recordings with high accu-
racy; creating realistic 2D eye-movements that correspond
to a speciﬁc user is likely to be signiﬁcantly harder.
Secondly, by using a challenge-response type of protocol,
we ensure that the potential generative model of legitimate
user’s eye movements must be able to output results inter-
actively and in real-time since the stimulus is not known in