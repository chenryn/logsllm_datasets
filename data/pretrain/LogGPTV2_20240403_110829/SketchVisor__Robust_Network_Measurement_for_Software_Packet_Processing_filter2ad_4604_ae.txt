(d) HC Recall
(e) HC Precision
(f) HC Relative error
Figure 7: Accuracy of HH/HC detection.
(a) DDoS Recall
(b) DDoS Precision
(c) DDoS Relative error
(d) SS Recall
(e) SS Precision
(f) SS Relative error
Figure 8: Accuracy of DDoS and SS detection.
Figure 9: Cardinality estimation.
Figure 10: Flow size distribution.
Figure 11: Entropy estimation.
accuracy metrics, we generate the ground truth (with zero error) by
tracking the whole trace with a very large hash table, and compare
the results of each alternative with the ground truth.
HH and HC detection (Figure 7): NR has much lower recall and a
higher relative error than Ideal. For example, in UnivMon, the recall
of NR is only 8.15% in HH detection and 16.43% in HC detection,
while the corresponding relative errors are 98.63% and 102.58%,
respectively. The reason is that NR discards all information in the
fast path. LR improves the overall recall, but is still below 80% as it
underestimates the sizes and changes for many true HHs and HCs.
UR achieves high recall, but at a cost of low precision. In contrast,
SketchVisor achieves close accuracy to Ideal for all three metrics.
DDoS and SS detection (Figure 8): NR, LR, and UR all have low
recall and high relative errors. In particular, NR even cannot detect
any DDoS or superspreader. LR and UR have the same detection
results since DDoS and SS detection concerns the number of hosts
instead of flow size. In contrast, SketchVisor achieves nearly perfect
results in SS detection. For DDoS detection, the accuracy drops
slightly compared to Ideal, but the recall is still above 90% and the
precision is above 84%.
Cardinality estimation (Figure 9): In FM and kMin, the errors
of NR, LR and UR are all nearly twice those in Ideal, while their
errors are around 17% in LC. SketchVisor significantly reduces the
errors and is close to Ideal. The reason is that all the three sketches
estimate cardinality based on non-zero counters. Since the small
hash table in the fast path discards many flows, NR, LR, and UR
end up with many zero counters in the sketch, and thus have poor
accuracy. In contrast, SketchVisor restores non-zero counters with
compressive sensing.
Flow size distribution (Figure 10): For MRAC, all approaches
achieve near-optimal MRD (around 0.2%), since MRAC is fast enough
that only few flows enter the fast path. For FlowRadar, NR, LR, and
051015DeltoidUnivMonTwoLevelRevSketchFlowRadarFMkMinLCMRACThroughput(Gbps)NoFastPath  MGFastPath  SketchVisor01020304050LCTwoLevelDeltoidFlowRadarFMkMinMRACRevSketchUnivMonThroughput(Gbps)NoFastPath  MGFastPath  SketchVisorNR LR UR SketchVisor Ideal0255075100DeltoidRevSketchFlowRadarUnivMonRecall (%)0255075100DeltoidRevSketchFlowRadarUnivMonPrecision (%)0255075100DeltoidRevSketchFlowRadarUnivMonRelative error (%)0255075100DeltoidRevSketchFlowRadarUnivMonRecall (%)0255075100DeltoidRevSketchFlowRadarUnivMonPrecision (%)0255075100DeltoidRevSketchFlowRadarUnivMonRelative error (%)NR LR UR SketchVisor Ideal0255075100TwoLevelRecall (%)0255075100TwoLevelPrecision (%)0255075100TwoLevelRel. error (%)0255075100TwoLevelRecall (%)0255075100TwoLevelPrecision (%)0255075100TwoLevelRel. error (%)0510152025LCFMkMinRelative error (%)NR LR UR SketchVisor Ideal0.00.10.20.3FlowRadarMRACMRD (%)NR LR UR SketchVisor Ideal0510152025FlowRadarUnivMonRelative error (%)NR LR UR SketchVisor IdealSketchVisor: Robust Network Measurement for So(cid:129)ware Packet Processing
SIGCOMM ’17, August 21−25, 2017, Los Angeles, CA, USA
(a) HH recall
(b) HH precision
(c) HH error
(d) Cardinality error
(e) HC recall
(f) HC precision
(g) HC error
(h) Entropy error
Figure 12: Network-wide recovery.
(a) Percentage of flows
(b) Percentage of bytes
Figure 13: Percentage of traffic in the fast path.
UR increase the MRD from 0.0126% in Ideal to 0.1166%, 0.0844%, and
0.0954%, respectively, mainly because they do not consider the miss-
ing small flows dropped by the fast path. In contrast, SketchVisor
reduces the error to 0.0553%.
Entropy estimation (Figure 11): Interestingly, SketchVisor has a
slightly lower error than Ideal, as it can eliminate a small amount of
errors caused by the sketch itself when recovering it using compres-
sive sensing, while Ideal directly returns the sketch that processes
all traffic in the normal path.
7.4 Network-Wide Recovery
We evaluate the network-wide recovery of SketchVisor. To evalu-
ate a large network size, we use our in-memory tester and configure
the control plane to aggregate results from 1 to 128 hosts. Here,
we show the results of HH detection, HC detection, cardinality
estimation, and entropy estimation in Figure 12. The accuracy re-
sults vary across measurement tasks and sketch-based solutions.
Overall, SketchVisor improves accuracy as the number of hosts
increases. For example, the recall of UnivMon increases from 65%
to 81% when the number of hosts increases from one to two. The
recall is even above 99% when the number of hosts exceeds four.
The reason for accuracy improvement is that integrating results
from multiple hosts (i) reduces the number of missing values in
sketch matrices and (ii) increases the number of constraints in our
recovery optimization. Also, some sketches (e.g., kMin in cardinal-
ity estimation) already achieve high accuracy in a single host, and
maintain high accuracy as the number of hosts increases.
7.5 Microbenchmarks
Percentage of traffic in the fast path: Figure 13(a) shows that
SketchVisor redirects more than 20% (resp. 50%) of flows to the
fast path in the testbed (resp. in-memory tester), except for MRAC.
Figure 13(b) shows that the fast path processes more than 50% of
byte counts for most tasks in both testbed and in-memory exper-
iments. The percentage for MRAC is negligible since MRAC is a
simple sketch. Note that our default 8KB fast path only records
around 0.7% of total flows (Figure 13(a)), while contributing to over
20% of byte counts (Figure 13(b)) due to traffic skewness.
We further examine the traffic redirected to the fast path specif-
ically, and find that the top 10% of flows tracked by the fast path
account for over 90% of byte counts for all solutions except MRAC,
and over 80% of byte counts for MRAC; we do not plot the results
in the interest of space.
Impact of fast path size: We configure various sizes for the fast
path: 4KB, 8KB, 16KB, and 32KB. We measure the throughput and
accuracy: HH and cardinality, using the same accuracy metrics in
§7.3. Figure 14(a) shows that the throughput varies by less than 5%
across fast path sizes. The reason is that while a larger hash table
in the fast path implies a longer time to search for small flows to
be kicked out, it also sustains more hash table insertions/updates
before triggering a new kick-out operation. Figures 14(b)-(d) show
the accuracy versus the fast path size. The accuracy improves
remarkably when the fast path size increases from 4KB to 8KB
(e.g., the HH recall of Deltoid increases from 65.17% to 97.21%), and
stabilizes when the fast path size exceeds 8KB.
Computation time of network-wide recovery: The computa-
tion time to solve compressive sensing varies from 0.15 seconds
(for MRAC) to 64 seconds (for Deltoid) in a single CPU core, de-
pending on the number of sketch counters (we omit the figures in
the interest of space). We can reduce the computation time in two
ways. First, some terms in the objective function do not need to be
optimal for some sketches (see discussion in §5.3), so it is possible
to terminate the computation early even though these unnecessary
terms do not converge. We have evaluated this optimization and
607080901001248163264128Number of hostsRecall (%)FlowRadarRevSketchUnivMonDeltoid95969798991001248163264128Number of hostsPrecision (%)FlowRadarRevSketchUnivMonDeltoid010203040501248163264128Number of hostsRelative error (%)FlowRadarRevSketchUnivMonDeltoid0510151248163264128Number of hostsRelative error (%)FMkMinLC50607080901001248163264128Number of hostsRecall (%)FlowRadarRevSketchUnivMonDeltoid607080901001248163264128Number of hostsPrecision (%)FlowRadarRevSketchUnivMonDeltoid010203040501248163264128Number of hostsRelative error (%)FlowRadarRevSketchUnivMonDeltoid051015201248163264128Number of hostsRelative error (%)FlowRadarUnivMon050100DeltoidUnivMonTwoLevelRevSketchFlowRadarFMkMinLCMRACPercentage (%)FastPath(Testbed) HashTable(Testbed) FastPath(InMemory) HashTable(InMemory)050100DeltoidUnivMonTwoLevelRevSketchFlowRadarFMkMinLCMRACPercentage (%)FastPath(Testbed) HashTable(Testbed) FastPath(InMemory) HashTable(InMemory)SIGCOMM ’17, August 21−25, 2017, Los Angeles, CA, USA
Huang et al.
(a) Throughput
(b) Cardinality error
(c) HH Recall
Figure 14: Impact of the fast path size.
(d) HH Precision
Figure 15: CPU overhead of sketch-based solutions.
find that the computation time for Deltoid can decrease from 64 sec-
onds to 11 seconds. Second, our current solver is single-threaded.
Since the recovery across epochs is independent, we can parallelize
network recovery through multiple CPU cores.
Comparison with Misra-Gries’s algorithm: We compare the
fast path of SketchVisor with the original Misra-Gries’s algorithm
(MGFastPath). We consider two metrics: (i) the number of kick-out
operations, which accounts for the major overhead in the fast path,
and (ii) the relative errors of top flows (including both lower and
upper bounds). Figure 16(a) shows that MGFastPath performs an
order of magnitude more kick-out operations than SketchVisor.
This explains why MGFastPath only slightly improves the through-
put compared to NoFastPath (Figure 6). Figure 16(b) shows the
relative errors on both lower bounds and upper bounds of top-k
flows in the fast path for Deltoid. MGFastPath increases the errors
as k grows. For the 100-th flow, the relative error increases to 35%.
In contrast, SketchVisor keeps the errors under 2% as we tighten
the lower and upper bounds using three counters per flow.
CPU overhead for normal path and fast path: We revisit the
CPU overhead of different sketch-based solutions when the fast path
is used. Figure 15 shows the number of CPU cycles for recording a
packet in each sketch-based solution, as well as those for the update
and kick-out operations of the fast path. The number of CPU cycles
varies across sketch-based solutions, from 404 (for MRAC) to 10,454
(for Deltoid). In contrast, the fast path spends only 47 cycles to
record a new flow or update an existing flow in its hash table. While
a kick-out incurs excessive CPU overhead, the fast path limits the
number of kick-outs (Figure 16(a)).
7.6 Comparison with Trumpet
Finally, we show that SketchVisor can approach the performance
and accuracy of simple hash tables [1] (§2.2), while using much less
memory. We consider the recently proposed Trumpet [38], a soft-
ware measurement architecture that tracks per-flow information in
simple hash tables rather than sketches. Specifically, we implement
Trumpet Packet Monitor to monitor traffic in the data plane, and de-
ploy a single trigger to monitor heavy hitters. This trigger requires
a single variable for byte counts and does not contain any predi-
cates to filter traffic. Note that Trumpet deals with hash collisions
by over-provisioning hash tables, but requires substantial memory
to completely eliminate collisions. Therefore, our implementation
(a) Number of flow kick-outs
(b) Errors of top-k flows
Figure 16: Comparison with MGFastPath.
(a) Throughput
Figure 17: Comparison with Trumpet [38].
(b) Memory consumption
allocates a hash table with a small over-provisioning factor and
deals with hash collisions by linked lists. We present the results
with over-provisioning factors 3 and 7, referred to as Trumpet3x
and Trumpet7x, respectively.
Figure 17 compares the throughput and memory consumption of
SketchVisor with Trumpet. SketchVisor achieves similar through-
put as Trumpet (Figure 17(a)). However, the sketches except Deltoid
consume much less memory than Trumpet (Figure 17(b)). The rea-
son is that Trumpet tracks per-flow information in a hash table,
while sketches store information in a fixed number of counters.
Although Trumpet provides perfect monitoring, we have shown
that sketches can also achieve near-optimal accuracy for various
tasks. Thus, SketchVisor provides an efficient alternative for net-
work measurement, especially when the hash table size increases
linearly with the number of flows.
8 RELATED WORK
Our work is related to software-defined measurement. We review
related work in this area.
Sampling: Sampling is widely used in software-defined measure-
ment for low measurement overhead. Sekar et al. [48] combine
flow sampling and sample-and-hold [19] as primitives for various
measurement applications. OpenSample [52] reconstructs flow sta-
tistics based on sampled traffic. Planck [43] mirrors traffic to remote
sites in a best-effort manner. However, sampling inherently misses
information and supports only coarse-grained measurement.
Sketches: Many architectures employ sketches as primitives to
achieve fine-grained measurement for various measurement tasks
1820224k8k16k32kFast path sizeThroughput (Gbps)DeltoidRevSketchFlowRadarUnivMonLCFMkMin05104k8k16k32kFast path sizeRelative error (%)LCFMk−Min607080901004k8k16k32kFast path sizeRecall (%)FlowRadarRevSketchUnivMonDeltoid8590951004k8k16k32kFast path sizePrecision (%)FlowRadarRevSketchUnivMonDeltoid1045443824292385825842403238822764044712332050001000015000DeltoidUnivMonTwoLevelRevSketchFlowRadarFMkMinLCMRACFP UpdateFP KickoutCPU cyclesper packet01000020000300004000050000FlowRadarRevSketchUnivMonDeltoid# of flow kick−outMGFastPathSketchVisor02040600255075100kRelative error (%)Lower(MGFastPath)Upper(MGFastPath)Lower(SketchVisor)Upper(SketchVisor)05101520FlowRadarRevSketchUnivMonDeltoidTrumpet3xTrumpet7xThroughput (Gbps)025005000750010000FlowRadarRevSketchUnivMonDeltoidTrumpet3xTrumpet7xMemory (KB)SketchVisor: Robust Network Measurement for So(cid:129)ware Packet Processing
SIGCOMM ’17, August 21−25, 2017, Los Angeles, CA, USA
(see Table 1). In the context of software-defined measurement,
OpenSketch [56] defines APIs for general sketch-based measure-
ment tasks running in commodity switches. SCREAM [37] ad-
dresses dynamic resource allocation of sketch-based measurement
across multiple switches. However, sketch-based measurement
incurs high computational overhead as shown in our analysis (§2).
Although we can deploy distributed sketch-based measurement
[11, 22] to boost performance, it still needs excessive computational
resources for parallelization.
TCAM: TCAM can be used to achieve high-performance network
measurement. Jose et al. [23] propose a TCAM measurement frame-
work based on OpenFlow [31]. DREAM [36] dynamically allocates
TCAM for high measurement accuracy. PathQuery [39] monitors
path-level traffic with TCAM. In contrast, our work address soft-
ware packet processing without specific hardware support.
Rule matching: Rule matching selectively processes only packets
of interest, thereby reducing measurement overhead. ProgME [57]
and EverFlow [62] filter flows based on pre-defined rules. Net-
Sight [21] leverages SDN to capture packets for specific forwarding
events. MOZART [29] and Trumpet [38] monitor network-wide
events with hash tables to achieve high throughput [1], by match-
ing flows to events and storing only matched flows in hash tables.
However, hash-table-based measurement incurs much higher mem-
ory overhead than sketch-based measurement (§7.6). Note that
rule matching requires careful configuration of matching criteria
to avoid compromising measurement accuracy.
9 CONCLUSION
We design and implement SketchVisor, a robust network-wide
measurement architecture for software packet processing, with a
primary goal of preserving performance and accuracy guarantees
even under high traffic load. SketchVisor employs sketches as basic
measurement primitives, and achieves high data plane performance
with a fast path to offload sketch-based measurement under high
traffic load. It further leverages compressive sensing to achieve
accurate network-wide measurement. Experiments demonstrate
that SketchVisor achieves high performance and high accuracy for
a rich set of sketch-based solutions.
ACKNOWLEDGMENTS
We thank our shepherd, Dina Papagiannaki, and the anonymous
reviewers for their valuable comments. We thank Jennifer Rexford
for comments on the earlier version of the paper.
REFERENCES
[1] O. Alipourfard, M. Moshref, and M. Yu. Re-evaluating Measurement Algorithms
[3] T. Benson, A. Akella, and D. A. Maltz. Network Traffic Characteristics of Data
[2] Z. Bar-Yossef, T. S. Jayram, R. Kumar, D. Sivakumar, and L. Trevisan. Counting
in Software. In Proc. of HotNets, 2015.
Distinct Elements in a Data Stream. In Proc. of RANDOM, 2002.