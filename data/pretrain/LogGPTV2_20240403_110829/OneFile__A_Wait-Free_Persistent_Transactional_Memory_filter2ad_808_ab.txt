5) Open request by assigning it a new transaction identi-
ﬁer newTx, with sequence #oldTx+1 and current tid.
6) Flush write-set to persistent memory, executing one pwb
for every cache line.
7) Commit transaction by CASing curTx from oldTx to
newTx, and ﬂush it with a pwb.
8) Apply transaction, executing one DCAS for every entry
in write-set.
9) Flush modiﬁed words using one pwb for each address.
10) Close request by CASing it to newTx+1.
The algorithm for the STM is similar, minus the pwbs.
C. MCAS Algorithm
We now detail the operation of our new MCAS technique,
shown in Alg. 1. At the beginning of the apply phase,
the write-set has been created with one WriteSetEntry
per modiﬁed word, with a total of numStores entries.
Applying the write-set consists of attempting each DCAS
until all entries have been fully processed (lines 9–16).
Each operation is uniquely identiﬁed by a sequence, with
all modiﬁed words of that operation having this unique seq.
Seen as all update transactions are serialized in the commit
phase, if the seq on a TMType is equal (or higher) than
the seq initially read of the curTx, then some other thread
has already applied that DCAS. This MCAS is ABA-free
because any delayed thread will fail in the execution of its
DCAS due to the seq no longer matching.
Unlike other MCAS algorithms, in our technique no bit
is stolen [22] from the word containing the value or pointer
in TMType, which gives it maximum ﬂexibility and allows
for easy deployment. On the other hand, it does require
hardware support for a DCAS or equivalent
instruction,
which is supported for x86 although not implemented by all
CPU vendors (likely because it was initially not considered
useful for designing synchronization mechanisms [29]).
An alternative to using DCAS exists with a single word,
without the need to steal bits or to use a sequence, if the
store on the value can be made conditional with the load on
curTx. Although is it possible to implement this operation
as a short hardware transaction, e.g., with Intel’s TSX, as it
stands today, such approach does not provide the progress
guarantees necessary in the apply phase of OneFile for
maintaining lock-free progress. The lock-free progress will
hold as long as the hardware transaction implementation
guarantees,
least one thread
will eventually execute its transaction successfully. In our
implementation we opted for CMPXCHG16B instead of TSX.
Pseudo code for the load and store interposing methods
in case of conﬂict,
that at
are also shown in Alg. 1 (lines 22 and 28).
D. Persistent Log and Recovery
Each thread contains a pre-allocated write-set in persistent
memory. Before the commit phase, the write-set is ﬂushed
to persistence by executing one pwb for every four entries,
where each entry of the log occupies two words, addr and
val. On commit, the successful CAS acts as a pfence on
x86, guaranteeing ordering with the prior pwbs and implying
that if the new value of curTx is visible to other threads,
then the write-set of the thread that won the CAS is durable.
For every 64 bit word of modiﬁed data by the user written
to persistent memory, 3 other words are written: two words
for the write-set
log and one more when executing the
DCAS, for the seq in the corresponding TMType. The write
ampliﬁcation [7] in OneFile-PTM is of 300%.
Our PTMs need no recovery method, a characteristic
referred to as null recovery [8]. Either following a failure
154
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:13:27 UTC from IEEE Xplore.  Restrictions apply. 
or during normal execution, other threads will identify the
write-set of the last committed transaction and whether that
transaction is already closed. If the request is still open,
they will attempt to apply the missing DCAS and close the
corresponding request.
Null recovery is possible only if the DCAS instruction
guarantees that both words are written to NVM atomically,
which is the case for x86 because both words are on the same
cache line [30], [31]. In architectures that do not provide
such guarantee, the words must be written in order (val
ﬁrst, then seq), or a recovery method executed upon restart.
Such a recovery method is trivially simple and consists
of applying the values in the write-set using stores, each
followed by a pwb, with a single ﬁnal pfence.
E. Wait-Free PTM
We will now describe the modiﬁcations to the lock-free
PTM required to create a similar PTM with bounded wait-
free progress. Compared to the lock-free OneFile-PTM, the
wait-free implementation has two extra member variables:
an array of pointers to std::function where threads
publish their operation and an array of results where the
result of the operation is stored.
During the transform phase, an update transaction starts
by encapsulating the code pertaining to its transaction in
a std::function object and publishing a pointer to it
in its thread’s entry of the operations array. If there is an
ongoing transaction that was committed but not yet applied,
it will help apply that transaction, otherwise, it will aggregate
all the functions in the operations array and invoke them
one by one, including its own, producing a single write-
set with all these operations. It will then attempt a commit,
similar to the lock-free algorithm. The transform step will
be repeated at most
two times, because by the second
iteration,
its own operation is guaranteed to have been
executed. This approach is inspired by Herlihy’s wait-free
universal construction [32], [33]. Unlike previous universal
constructions, our technique is capable of executing dynamic
transactions.
this signiﬁes that
In our algorithm, the entries of the operations and results
arrays are TMTypes, implying that each has its own se-
quence number. When the sequence number of a function
pointer is equal to the sequence number of the corresponding
result entry,
the function was not yet
committed. This is the state when operations are published.
When the transaction executes, the result of the operation
is written to the result entry using a standard transactional
write. Therefore, when the result is produced during the
apply phase, the sequence number of the result will be
higher than the sequence number of the function pointer.
This indicates that the operation has been committed.
As for read-only transactions, they are similar to the lock-
free algorithm. If the read-only operation fails more than
n attempts (4 in our implementation) then the operation is
2
2
2
3
2
2
2
3
push(c)
null
curTx
2|t1
curTx
3|t2
push(c)
true
curTx
3|t2
m
r
o
f
s
n
a
r
T
t
i
m
m
o
C
l
y
p
p
A
push(d)
true
t3
pop()
true
t1
2
2
t2
1|1
2|9
3|8
3|t1 3|t2
push(d)
true
t3
1|1
2|9
3|8
pop()
2
c
3
t1
t2
1|1
1|1
2|9
2|9
3|8
3|8
3|t1 4|t2
operations
results
addr|val
request
e
m
T
i
stack
b
a
d
b
a
Figure 1: Main components of OneFile wait-free and its 3 phases.
placed on the array of operations as if it was an update,
and then attempt to execute two more times. The algorithm
guarantees that after n+2 failed iterations, one of the threads
executing an update transaction has executed the read-only
transaction and its result is available in the results array, thus
ensuring bounded wait-free progress.
In the OneFile lock-free algorithm threads share their
write-set with other threads, while in the wait-free algorithm
threads share their transactions by encapsulating them in a
std::function. This matches the result by [34] which
shows that wait-freedom for a TM is not possible unless the
code of each transaction is accessible to the other threads.
Their result does not apply to lock-freedom.
To allow a better understanding of the algorithm, Fig. 1
represents the main components when a transaction in
OneFile Wait-Free is used to provide concurrent access
to a sequential implementation of a stack. The stack has
two methods, push() and pop(), that are published by
each thread in the operations array. In this example
there was already an execution of a previous transaction
that pushed element a and b to the stack. For simplicity we
show only 3 threads and each has a writeSet that records
the modiﬁcations required by the update transaction. In this
scenario, all three published operations (push(c), pop(),
and push(d)) are grouped inside a transaction simulated
by thread t2. At the start of the transform phase, the last
committed transaction was simulated by thread t1 with
sequence 2, represented by curTx. Once the simulation of
the transaction is ﬁnished, the request ﬁeld is set to the
next sequence concatenated with t2 identiﬁer.
The next phase is the commit phase, which will allow the
transaction simulated by t2 to take effect.
Finally, the apply phase starts the moment the modiﬁ-
cations recorded on the write-set are effectively written at
the addr memory locations. It is then that the element
d is added to the stack. At the end of the apply phase,
request will transition to sequence 4 concatenated with
t2 identiﬁer, announcing the end of this phase and the end
of the transaction whose sequence is 3.
155
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:13:27 UTC from IEEE Xplore.  Restrictions apply. 
IV. MEMORY MANAGEMENT
Allocating, de-allocating, tracking and reclaiming objects
in dynamic memory are challenging problems, particularly
on NVM. Sequential code de-allocates an object immedi-
ately after removing it from a data structure. In general, lock-
free reclamation requires tracking accesses of other threads
to ensure that an object is safe to de-allocate. Many schemes
have been proposed over the course of the years [35]–[47].
However, most of these are applicable only to some speciﬁc
data structures, require the data structure’s algorithm to be
adapted or rely on blocking code.
Supporting dynamic memory allocation on NVM has to
be carefully considered because a PTM must handle non-
corrupting failures (crashes). If an object is allocated but not
yet inserted into a data structure, it might end up marked
as allocated but unreachable by the application,
leading
to a permanent
leak in the NVM heap. A similar leak
happens if a crash occurs after a object is removed from
a data structure but before it is de-allocated [48]. Although
blocking techniques exist for reclaiming objects in NVM [7],
[48], [49], no lock-free memory reclamation scheme for
NVM has been presented in the literature.
A. Allocation and de-allocation in NVM
To support a wait-free, fault-tolerant, simple memory
reclamation scheme for OneFile, we use a combination
of two ideas: allocating and de-allocating memory inside
a transaction and optimistic access to reclaimed objects.
All allocations and de-allocations are assumed to be part
of a transaction that inserts or removes a node (or object)
from a data structure. The destructor is also invoked as part
of the transaction. In the OneFile PTMs we use our own
sequential implementation of an allocator whose metadata
types have been annotated with TMType. Other sequential
allocator implementations can be used. This design ensures
that memory is never leaked during a crash. However, the
concurrency problem remains: while one thread de-allocates
an object and destructs it, other threads may access the object
inappropriately.
To solve the concurrency issue, we use an optimistic
technique. The main observation is that when a thread
accesses a removed object, its current transaction conﬂicts
transaction and will abort. It remains
with the removal
to show that
the thread aborts its transaction correctly,
despite accessing a removed object. Unlike standard virtual
memory, NVM memory is not returned to the OS after de-
allocation, being instead managed by a PTM-speciﬁc user-
level allocator. Thus, accessing a de-allocated object does
not trigger a page fault. Furthermore, the NVM memory
is accessed only through the PTM interface, preserving the
TMType structure, including the (ever increasing) sequence
numbers. Next, we show that either reading from or writing
to a de-allocated object results in aborting the transaction,
without unexpected side effects.
Proposition 1: If a thread reads from a TMType of a de-
allocated memory block, it either reads the value before de-
allocation or the transaction aborts without returning the
read value.
line 22), T ﬁrst reads F ,
Sketch of proof: Let T be a transaction that accessed
a ﬁeld F on a de-allocated memory block and let R
be the transaction that de-allocated it. Clearly T started
before R committed, since otherwise T would not observe
the de-allocated block. According to the read-interposition
algorithm (Alg. 1,
then read
F ’s sequence number and aborts if it is higher than the
current transaction number. If F was modiﬁed during or after
de-allocation, then F ’s sequence number must be higher
than T ’s transaction number (recall that T started before R
committed), and T would abort without using the content
of F . Notice that the members of the allocated objects
are TMTypes, thus preserving sequence numbers after de-
allocation. On the other hand, if F was not modiﬁed during
or after de-allocation, then the content of F observed by T
is unaffected by de-allocation. Thus, the returned content of
F represents a snapshot of F before the de-allocation.
Proposition 2: A thread never successfully writes to a
TMType if
this write pertains to a transaction that has
already been applied.
Sketch of proof: The contents of a TMType can only be
modiﬁed by a thread calling the apply() method, when
executing a DCAS and only if the sequence number of
the transaction to which the modiﬁcation corresponds is
higher than the sequence currently in that TMType (Alg. 1,
line 14). Consider a transaction Ti that was already applied,
the modiﬁcations of the TMTypes pertaining to Ti now have
a sequence number that is equal to the sequence of Ti,
or higher in the case of TMTypes modiﬁed by subsequent
transactions. Any (delayed) thread T attempting to apply
one of the modiﬁcations pertaining to Ti will fail the DCAS,
because the sequence number currently in the TMType will
be equal to or higher than the sequence of Ti.
Our memory reclamation scheme relies on internal man-
agement of the NVM memory. Despite being de-allocated,
a chunk of NVM memory continues to be managed by the
NVM allocator and does not lose its sequence numbers. In
our technique, the entire NVM region consists of 16-byte
aligned TMType entries, including all allocator metadata
used by our system. In other words, if we were to number
each of the 64-bit words in the memory region starting
at zero, all even-numbered words would be a value and
all odd-numbered words would be a sequence. The only
annotation provided to the user is the TMType, which
means that all data types must have this annotation for safe
concurrent usage and all such object instances must therefore
reside in NVM. This constraint in memory allocation ensures
correctness when a memory block is re-allocated, i.e., the
allocator reuses a memory region previously occupied.
156
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 11:13:27 UTC from IEEE Xplore.  Restrictions apply. 
Proposition 3: A thread never successfully writes to a de-
allocated object.
Sketch of proof: Let T be a transaction that writes to a
TMType ﬁeld F of a de-allocated object and let R be the
transaction that de-allocated the object. If T is attempting
a write to the ﬁeld F ,
then T must be applying the
modiﬁcations from a transaction Q that committed before
R. Otherwise, T cannot observe the de-allocated object.
Since the object was de-allocated, clearly R was committed
successfully. Therefore, Q must have already been applied,
and by proposition 2 the DCASes executed by T in Alg. 1
will fail because the sequence number in F was already
increased when Q was applied.
B. Closure Reclamation
On the wait-free algorithm, each thread publishes its
transaction as a function that other threads can execute, a
std::function. The function is stored as a stream of
executable bytes and might not be anymore executable after
rebooting the machine. Furthermore, the executable byte
stream cannot be stored in TMTypes, so this function must
be allocated in the transient memory. But this object must
also be de-allocated, despite being accessed by (possibly
many) concurrent threads.
To manage transient memory without foiling the wait-
freedom guarantee of our algorithm and without introducing
a high overhead, we use the hazard eras (HE) [41] algorithm.
With HE, each thread publishes an era. All objects that
were alive during this era cannot be reclaimed by concurrent
threads since they might be accessed by the publisher thread.
An object can only be reclaimed if the period of time
during which it was alive does not overlap with the currently
published era of a thread.
The HE scheme inter-operates well with the OneFile
algorithm, utilizing the transaction number (the sequence
number of curTx) as the era number. The thread publishes
the transaction number it is using at the beginning of the
transaction. According to the HE scheme, every object that
is still accessible during this era (i.e., still accessible during
this transaction) must not be reclaimed. Objects that are not
accessible in the current era (i.e., by the current transaction)
of any thread are reclaimed by the HE scheme. When a
thread reads a new pointer to an object,
it ﬁrst checks
whether it was installed by a newer era, in which case it is