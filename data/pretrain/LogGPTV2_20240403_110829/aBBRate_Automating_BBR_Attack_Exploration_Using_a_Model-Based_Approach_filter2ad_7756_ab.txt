min_rtt_ts
probe_ts
rate
rmult
Table 1: Descriptions of variables unique to the BBR ﬁnite-state machine (left), and its events (right).
Description
maximum measured bottleneck bandwidth.
estimated token-bucket drain rate.
boolean indicating when pipe is ﬁlled.
current index into rmult.
minimum measured RTT.
timestamp min_rtt was measured.
timestamp ProbeRTT was entered.
current pace data is sent.
array containing the 8 pacing_gain phases.
Description
recipient of an acknowledgment packet, representing
the highest correct byte received.
new maximum bottleneck bandwidth is observed.
new minimum RTT sample is observed.
new acknowledgment received, acknowledging previ-
ously outstanding data.
TCP packet loss event (3 duplicate ACKs).
outstanding data has not been acknowledged for many
RTTs.
LostPacket
RTO Timeout
Event
ACK
MaxBW
MinRTT
New
ing off from the network. Once an acknowledgment is re-
ceived, the current model is discarded and Startup is entered.
Rate Limited. This state is entered when a token-bucket
policer is detected on the network, as these can lead to high
amounts of packet loss. This state is entered when the packet
loss-to-delivered ratio is greater than 20%, but the throughput
remains steady. BBR sets BtlBw to the estimate token bucket
drain rate and sustains this for 48 round-trips.
3 Automated Attack Exploration in BBR
In order to systematically examine vulnerabilities of TCP
BBR implementation for the Linux kernel TCP stack [8], we
apply a TCP congestion control fuzzer, TCPWN. Below we
describe the attacker model and the changes we had to make
to TCPWN in order to apply it to BBR.
3.1 Attacker Model
We focus on manipulation attacks in the implementation of
BBR, where the attacker targets to mislead the sender’s con-
gestion control about the current network condition. These
attacks are conducted through maliciously crafted acknowl-
edgment packets, which can result in either increasing or
decreasing the throughput of the target ﬂow(s), or in stalling
the target TCP connection.
We support the following acknowledgement-based mali-
cious actions: ACK duplication, ACK stepping (several ac-
knowledgments are dropped and then several let through in a
228    23rd International Symposium on Research in Attacks, Intrusions and Defenses
USENIX Association
Startupcwnd=bw*min_rtt*(2/ln(2))rate=bw*min_rtt*(2/ln(2))bw increasingDraincwnd=bw*min_rtt*(2/ln(2))rate=bw*min_rtt*(ln(2)/2)Drain QueuesProbeBWcwnd = bw*min_rtt*2rmult= [1.25,0.75,1,1,1,1,1,1]rate=bw*min_rtt*rmult[idx]Steady stateProbeRTTcwnd=4rate=bw*min_rtt*1Probe for min RTTRateLimitedcwnd=est_bw*min_rtt*2rate=est_bw*min_rtt*1Recoverycwnd=in_ight*2avoid loss during recoverybw has not increased for 3 rounds--fullbw=1rate=bw*min_rtt*(ln(2)/2)in_ight  10s---save_cwnd=cwndcwnd=4rate=bw*min_rtt*1probe_ts=now()min_rtt_ts  200ms && fullbw>0 && est_bw == 0--cwnd=save_cwndidx=rand(2,7)rate=bw*min_rtt*rmult[idx]LostPacket--save_cwnd=cwndUpdate in_ightcwnd=in_ighthigh_water=last_sentACK && New--Update in_ightcwnd=in_ight*2ACK && New && pkt.ack >= high_water--cwnd=save_cwndExponentialBackocwnd=1loss > 50% && abs(bw-prev_bw)  10s---save_cwnd=cwndcwnd=4rate=bw*min_rtt*1probe_ts=now()ACK && New && MinRTT--rate=bw*min_rtt*1min_rtt_ts=now()min_rtt_ts  200ms && fullbw==0--cwnd=save_cwndrate=bw*min_rtt*(2/ln(2))min_rtt_ts > 10s---save_cwnd=cwndcwnd=4rate=bw*min_rtt*1probe_ts=now()min_rtt_ts  200ms && est_bw > 0--cwnd=save_cwndACK && New && MinRTT--cwnd=bw*min_rtt*2rate=bw*min_rtt*1min_rtt_ts=now()1 round--idx=(idx+1)%8rate=bw*min_rtt*rmult[idx]RateLimitedProbeBWDrainStartupRecoveryExponentialBackoProbeRTTcycle), ACK bursting (acknowledgments are sent in bursts),
optimistic ACK (acknowledge highest byte, dropping dupli-
cates), delayed ACK (delay acknowledgments for a ﬁxed
amount of time), limited ACK (prevent acknowledgment num-
bers from increasing), stretch ACK (forward only every nth
ACK), injecting off-path duplicate acknowledgments, inject-
ing off-path offset acknowledgments, and injecting off-path
incrementing acknowledgments. (Appendix B includes a vi-
sual representation of some actions for additional clarity.)
In order to achieve its goals, the attacker applies an attack
strategy, which is deﬁned as a sequence of acknowledgment-
based malicious actions and the corresponding sender states
when each action is conducted. We focus on TCP ﬂows with
bulk data transfers because they are widespread, and the effect
of the conducted attacks is easy to measure.
We assume that the attacker is interested in causing BBR
to send faster than usual, slower, or stall, and these attacks are
meant to affect servers, clients, or the provider of a bottleneck
link. In the case of sending faster, the goal of the attack can
be to waste/exhaust bandwidth resources, worsening perfor-
mance for all other clients of the server and/or shared bottle-
neck link. In the case of sending slower, the goal is to target
individual connections for performance degradation, which
could selectively cause a service provider’s quality to be poor
(e.g., low resolution video streaming) and/or make more bot-
tleneck bandwidth available for other competing ﬂows. In the
case of stalling a ﬂow, the goal is to disrupt communication
between endpoints indeﬁnitely, without causing an error from
the transport layer to propagate to the application that is using
it, effectively causing a denial of service.
3.2 Modifying TCPWN for BBR
We leverage TCPWN [29], a recent open-source platform
designed to automatically ﬁnd manipulation attacks in TCP
congestion control implementations. We chose TCPWN be-
cause it does not require the source code of the congestion
control implementation, and is designed speciﬁcally for TCP
congestion control implementations.
At the core, TCPWN employs a network protocol fuzzer
to ﬁnd acknowledgment-based manipulation attacks against
TCP congestion control implementations. Instead of applying
random fuzzing, TCPWN guides the fuzzer using a model-
guided technique, where the model is represented as a ﬁnite
state machine (FSM) that captures the main functionality of
several TCP congestion control algorithms.
For fuzzing an actual implementation of TCP congestion
control in its native environment, TCPWN utilizes virtualiza-
tion and proxy-based attack injection. To be effective, these
attacks must be executed at the right time during execution,
and therefore TCPWN monitors network packets exchanged
to infer the current state of the sender in real-time.
While TCPWN is amenable to TCP congestion control al-
gorithms, it assumes that the algorithm is a loss-based model
based on TCP New Reno. Thus, we can not directly apply it
to BBR, as the models are substantially different. We leverage
our own BBR FSM (see Figure 1) to feed it as an input to
TCPWN to generate abstract attack strategies, each of which
speciﬁes a vulnerable path in the FSM that the attacker can
exploit. Each transition on a vulnerable path dictates the net-
work condition that the attacker needs to trigger to mount the
desired attack.
While there are several ways to trigger the necessary net-
work conditions, TCPWN takes the abstract strategies and
converts them into concrete attack strategies consisting of
basic acknowledgement-packet-level actions (e.g., send du-
plicate ACKs). During fuzzing, the attack injector applies
these actions in particular states of the FSM. Although the
generation of attack strategies is fully automated, TCPWN
requires us to provide a manually crafted mapping between
network conditions and basic actions because the mapping
relies on domain knowledge about the underlying model (in
our case, the BBR FSM).
Another change we had to make is changing the state infer-
ence algorithm. TCPWN needs to know what is the state of
the sender in order to inject attacks in the states speciﬁed by
the attack strategy. The state inference available in TCPWN
cannot infer BBR’s states because the algorithm expects the
underlying model (i.e., FSM) to be based on TCP New Reno.
Hence, we develop a new state inference algorithm for BBR
to infer the sender’s state from network trafﬁc alone (§ 3.3).
3.3 State Inference for BBR
We present a novel algorithm to infer the current state of the
sender in real-time by passively observing network trafﬁc.
Our algorithm operates by computing ﬂow metrics on each
round-trip and comparing metrics across intervals to deter-
mine BBR’s state. We compute metrics on each round-trip
because BBR sustains a constant sending behavior for at least
one round-trip.
When our algorithm starts, we begin a round-trip by record-
ing the ﬁrst data packet’s sequence number and end when it
is acknowledged. During round-trips, we collect ﬂow met-
rics and compute average throughput, re-transmission count,
number of data packets sent when the round completes. We
then update the inferred BBR state on each new round by
computing metrics across round-trips. For BBR, the most
revealing metric about its current state is change in average
throughput across round-trips. On each round, we compute
the throughput ratio since the last round. For example, if the
current and last rounds had average throughputs of 30 and 20
Mbit/sec respectively, then the ratio would equal 1.5.
We infer Startup if throughput has increase signiﬁcantly
since the last round-trip. Drain is primarily inferred if the
current state is Startup and we notice throughput has not been
increasing. ProbeBW is inferred if 1.4 > ratio > 0.6, which
allows ProbeBW to be inferred during phases 1 and 2 of gain
USENIX Association
23rd International Symposium on Research in Attacks, Intrusions and Defenses    229
investigate the impact of competing ﬂows during attack, e.g.,
to determine if there was collateral damage.
Attacks in the wild. For an attack to be effective in the
wild, an attacker will need to be able to recognize that TCP
ﬂows are indeed using BBR and to be able to be on the path
(all the attacks we found were from on-path attackers). An
attacker can determine that TCP is using BBR for congestion
control by examining the startup phase of a target connection.
Speciﬁcally, during startup BBR doubles its send rate every
round, even with loss, until the bottleneck bandwidth estimate
is relatively stable. So an on-path attacker could drop a single
packet early in the connection startup to see if the TCP sender
exits exponential growth. If so, this is probably loss-based
congestion control, i.e. not BBR. Being on path can be accom-
plished by compromising a router along the path or inserting
ones self into the path by ARP spooﬁng or similar attacks.
Cross-trafﬁc could also impede the effectiveness of the attack.
We conducted a few experiments where we varied the number
of cross-trafﬁc ﬂows in an attempt to gauge the impact of such
trafﬁc on our attacks. In particular, we varied the number of
background CUBIC ﬂows from 1 to 32 while executing each
of our attacks. We repeated each of these scenarios 10 times
and found that our attacks continue to be effective even with
this signiﬁcant level of background trafﬁc (see Table 3).
Attack strategies. We used TCPWN to execute 30,297 at-
tack strategies for manipulating BBR’s sending rate. After
each attack strategy is executed, it is classiﬁed into one of four
categories: faster, slower, stalled (data transfer did not com-
plete), and benign (no attack was detected). These categories
represent the BBR’s respective sending rate performance. The
attack categorization algorithm is the same as the one used
in [29]. (For convenience, it is shown in Appendix A).
Attack analysis. After all 30,297 attack strategies were
executed, 8,859 were ﬂagged as potential attacks: 14 faster,
4,025 slower and 4,820 stalled. We initially focused on ex-
tracting the strategies that were most effective at manipulating
BBR’s sending rate in each category. To identify which attack
strategies were most effective at impacting BBR’s perfor-
mance, we grouped attack strategies in each category (ignor-
ing attack speciﬁc parameters) and sorted each by average
sending rate.
While this allowed us to understand which exact strategies
were most effective, the limitation with this method is that it
does not reveal if any subset of actions is more effective over
others. Take for instance the following attack strategy that
hypothetically affects sending rate performance:
[(StateA,Action1),(StateB,Action2),(StateC,Action3)].
While it is true that this attack strategy affects sending
rate performance, the above method does not indicate if
performing Action2 in StateB was necessary for causing it.
To ﬁnd which actions were most effective, we generated all
possible attack action subset combinations for each category
and sorted them by their occurrence in the original attack
strategies. This allowed us to see which attack actions the
Figure 2: TCPWN testing environment.
cycling. We also infer ProbeBW when BBR transitions out of
Drain indicated by a signiﬁcant increase in throughput. We
infer ProbeRTT when we observe only 4-5 data packets in the
last round, resulting from cwnd = 4 packets to drain queues,
and exit after 10 data packets have been sent. Recovery is
inferred when re-transmitted segments have been observed
and exits when the highest data sequence (when Recovery was
entered) is acknowledged. Exponential-backoff is inferred
when the estimated RTO has elapsed since the last data packet.
Lastly, we infer RateLimited when more than 16 round-trips
have passed, with small variance in average throughput.
We infer Exponential-backoff, Recovery and Drain without
waiting for a round-trip to complete, as these can be entered
at anytime during the ﬂow. (Readers can refer to Appendix D
for the algorithm’s pseudocode).
4 Experimental Results
In this section we describe and analyze our discovered attacks
on BBR congestion control. We ﬁrst describe the testing
environment used. We then describe how we analyze and
classiﬁed the attacks. Lastly, we discuss and illustrate the
discovered attack classes in detail.
4.1 Experiment Setup
Environment. Our testing environment, shown in Figure 2,
consists of four virtual machines running Ubuntu Linux 17.10
sharing a virtual dumbell network topology. We limit the bot-
tleneck bandwidth to 100Mbits/sec with a 500 packet queue
and a 10 ms. end-to-end latency between either end of the
topology. We conﬁgure the virtual network with reasonably
low latency and high bandwidth, allowing us to isolate the im-
pact of attack strategies on BBR in a “friendly” environment.
For each attack strategy, two TCP ﬂows are instantiated,
a victim and background ﬂow, each transferring an identical
100MB ﬁle over HTTP. The attacker is located between ei-
ther end of the topology. The victim ﬂow uses a Linux TCP
BBR sender, whose ﬂow is injected with attacks where the
background ﬂow is not targeted. We use tcpdump to measure
both ﬂows’ performance, captured between the senders and
the bottleneck. The victim ﬂow is measured to understand the
impact of the attack, and the background ﬂow is measured to
230    23rd International Symposium on Research in Attacks, Intrusions and Defenses
USENIX Association
AttackerVictim TCPBBR SenderStateInferenceBackgroundTCP SenderBackgroundTCP ReceiverVictim TCPReceiverCoordinatorAttackBBR FSMAttackFinder[cwnd, rate]ResultsTable 2: Descriptions of discovered attack classes targeting Linux TCP BBR congestion control.
No. Attack
1
Optimistic ACK
Attacker
On/off-path
2
3
4
5
Delayed ACK
On-path
Repeated RTO
On-path
RTO stall
On-path
Sequence
Number Desync
On/off-path
Description
Acknowledge the highest sent sequence number before it is received, hiding all losses. This causes
an overestimated BtlBw and for data to be send earlier/faster than otherwise.
Delay acknowledgments from reaching the sender from the receiver for a ﬁxed amount of time,
causing BtlBw to be underestimated and data to be sent at a slower pace.
For the entire ﬂow, prevent new data from being acknowledged causing a RTO. Optimistically
acknowledge the lost segment causing Startup to be entered. This causes substantial amounts of
time to be wasted (not sending data) during periods before each RTO.
Prevent new data from ever being acknowledged causing a RTO and exponential backoff to never
exit. This causes the connection to stall as no new data will ever be sent.
Acknowledge the highest sent sequence number before it is received, hiding all losses causing
sequence numbers to desynchronize. Induce RTO causing exponential backoff to be entered. For
each re-transmission, the receiver replies with a lower acknowledgement number than the sender
expects, causing the lost segment to never be acknowledged and exponential backoff to never exit.
Result
Faster
Slower
Slower
Stalled
Stalled
(a) Attack 1
(b) Attack 2
(c) Attack 3
(d) Attack 4
(e) Attack 5
Figure 3: Time-sequence graphs illustrate how each attack manipulates acknowledgments to achieve a faster, slower or stalled sending rate.
The blue lines represent data being sent by TCP BBR (victim) and the green represents acknowledgments being received from the attacker.
Table 3: Avg. throughput (in Mbps) of target BBR ﬂow during
attacks with varying numbers of CUBIC ﬂows as cross-trafﬁc
Background Flows
Attack
None
Attack 1
Attack 2
Attack 3
Attack 4
Attack 5
1
51.7
287.4
3.6