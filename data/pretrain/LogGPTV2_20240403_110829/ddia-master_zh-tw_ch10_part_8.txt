最直接的选择可能是，直接在 Mapper 或 Reducer 中使用你最爱的资料库的客户端库，并从批处理作业直接写入资料库伺服器，一次写入一条记录。它能工作（假设你的防火墙规则允许从你的 Hadoop 环境直接访问你的生产资料库），但这并不是一个好主意，出于以下几个原因：
- 正如前面在连线的上下文中讨论的那样，为每条记录发起一个网路请求，要比批处理任务的正常吞吐量慢几个数量级。即使客户端库支援批处理，效能也可能很差。
- MapReduce 作业经常并行执行许多工。如果所有 Mapper 或 Reducer 都同时写入相同的输出资料库，并以批处理的预期速率工作，那么该资料库很可能被轻易压垮，其查询效能可能变差。这可能会导致系统其他部分的执行问题【35】。
- 通常情况下，MapReduce 为作业输出提供了一个干净利落的 “全有或全无” 保证：如果作业成功，则结果就是每个任务恰好执行一次所产生的输出，即使某些任务失败且必须一路重试。如果整个作业失败，则不会生成输出。然而从作业内部写入外部系统，会产生外部可见的副作用，这种副作用是不能以这种方式被隐藏的。因此，你不得不去操心对其他系统可见的部分完成的作业结果，并需要理解 Hadoop 任务尝试与预测执行的复杂性。
更好的解决方案是在批处理作业 **内** 建立一个全新的资料库，并将其作为档案写入分散式档案系统中作业的输出目录，就像上节中的搜寻索引一样。这些资料档案一旦写入就是不可变的，可以批次载入到处理只读查询的伺服器中。不少键值储存都支援在 MapReduce 作业中构建资料库档案，包括 Voldemort 【46】、Terrapin 【47】、ElephantDB 【48】和 HBase 批次载入【49】。
构建这些资料库档案是 MapReduce 的一种好用法：使用 Mapper 提取出键并按该键排序，已经完成了构建索引所必需的大量工作。由于这些键值储存大多都是只读的（档案只能由批处理作业一次性写入，然后就不可变），所以资料结构非常简单。比如它们就不需要预写式日志（WAL，请参阅 “[让 B 树更可靠](ch3.md#让B树更可靠)”）。
将资料载入到 Voldemort 时，伺服器将继续用旧资料档案服务请求，同时将新资料档案从分散式档案系统复制到伺服器的本地磁碟。一旦复制完成，伺服器会自动将查询切换到新档案。如果在这个过程中出现任何问题，它可以轻易回滚至旧档案，因为它们仍然存在而且不可变【46】。
#### 批处理输出的哲学
本章前面讨论过的 Unix 哲学（“[Unix 哲学](#Unix哲学)”）鼓励以显式指明资料流的方式进行实验：程式读取输入并写入输出。在这一过程中，输入保持不变，任何先前的输出都被新输出完全替换，且没有其他副作用。这意味著你可以随心所欲地重新执行一个命令，略做改动或进行除错，而不会搅乱系统的状态。
MapReduce 作业的输出处理遵循同样的原理。透过将输入视为不可变且避免副作用（如写入外部资料库），批处理作业不仅实现了良好的效能，而且更容易维护：
- 如果在程式码中引入了一个错误，而输出错误或损坏了，则可以简单地回滚到程式码的先前版本，然后重新执行该作业，输出将重新被纠正。或者，甚至更简单，你可以将旧的输出储存在不同的目录中，然后切换回原来的目录。具有读写事务的资料库没有这个属性：如果你部署了错误的程式码，将错误的资料写入资料库，那么回滚程式码将无法修复资料库中的资料。（能够从错误程式码中恢复的概念被称为 **人类容错（human fault tolerance）**【50】）
- 由于回滚很容易，比起在错误意味著不可挽回的伤害的环境，功能开发进展能快很多。这种 **最小化不可逆性（minimizing irreversibility）** 的原则有利于敏捷软体开发【51】。
- 如果 Map 或 Reduce 任务失败，MapReduce 框架将自动重新排程，并在同样的输入上再次执行它。如果失败是由程式码中的错误造成的，那么它会不断崩溃，并最终导致作业在几次尝试之后失败。但是如果故障是由于临时问题导致的，那么故障就会被容忍。因为输入不可变，这种自动重试是安全的，而失败任务的输出会被 MapReduce 框架丢弃。
- 同一组档案可用作各种不同作业的输入，包括计算指标的监控作业并且评估作业的输出是否具有预期的性质（例如，将其与前一次执行的输出进行比较并测量差异） 。
- 与 Unix 工具类似，MapReduce 作业将逻辑与布线（配置输入和输出目录）分离，这使得关注点分离，可以重用程式码：一个团队可以专注实现一个做好一件事的作业；而其他团队可以决定何时何地执行这项作业。
在这些领域，在 Unix 上表现良好的设计原则似乎也适用于 Hadoop，但 Unix 和 Hadoop 在某些方面也有所不同。例如，因为大多数 Unix 工具都假设输入输出是无型别文字档案，所以它们必须做大量的输入解析工作（本章开头的日志分析示例使用 `{print $7}` 来提取 URL）。在 Hadoop 上可以透过使用更结构化的档案格式消除一些低价值的语法转换：比如 Avro（请参阅 “[Avro](ch4.md#Avro)”）和 Parquet（请参阅 “[列式储存](ch3.md#列式储存)”）经常使用，因为它们提供了基于模式的高效编码，并允许模式随时间推移而演进（见 [第四章](ch4.md)）。
### Hadoop与分散式资料库的对比
正如我们所看到的，Hadoop 有点像 Unix 的分散式版本，其中 HDFS 是档案系统，而 MapReduce 是 Unix 程序的怪异实现（总是在 Map 阶段和 Reduce 阶段执行 `sort` 工具）。我们了解了如何在这些原语的基础上实现各种连线和分组操作。
当 MapReduce 论文发表时【1】，它从某种意义上来说 —— 并不新鲜。我们在前几节中讨论的所有处理和并行连线演算法已经在十多年前所谓的 **大规模并行处理（MPP，massively parallel processing）** 资料库中实现了【3,40】。比如 Gamma database machine、Teradata 和 Tandem NonStop SQL 就是这方面的先驱【52】。
最大的区别是，MPP 资料库专注于在一组机器上并行执行分析 SQL 查询，而 MapReduce 和分散式档案系统【19】的组合则更像是一个可以执行任意程式的通用作业系统。
#### 储存多样性
资料库要求你根据特定的模型（例如关系或文件）来构造资料，而分散式档案系统中的档案只是位元组序列，可以使用任何资料模型和编码来编写。它们可能是资料库记录的集合，但同样可以是文字、影象、影片、感测器读数、稀疏矩阵、特征向量、基因组序列或任何其他型别的资料。
说白了，Hadoop 开放了将资料不加区分地转储到 HDFS 的可能性，允许后续再研究如何进一步处理【53】。相比之下，在将资料汇入资料库专有储存格式之前，MPP 资料库通常需要对资料和查询模式进行仔细的前期建模。
在纯粹主义者看来，这种仔细的建模和汇入似乎是可取的，因为这意味著资料库的使用者有更高质量的资料来处理。然而实践经验表明，简单地使资料快速可用 —— 即使它很古怪，难以使用，使用原始格式 —— 也通常要比事先决定理想资料模型要更有价值【54】。
这个想法与资料仓库类似（请参阅 “[资料仓库](ch3.md#资料仓库)”）：将大型组织的各个部分的资料集中在一起是很有价值的，因为它可以跨越以前相互分离的资料集进行连线。MPP 资料库所要求的谨慎模式设计拖慢了集中式资料收集速度；以原始形式收集资料，稍后再操心模式的设计，能使资料收集速度加快（有时被称为 “**资料湖（data lake）**” 或 “**企业资料中心（enterprise data hub）**”【55】）。
不加区分的资料转储转移了解释资料的负担：资料集的生产者不再需要强制将其转化为标准格式，资料的解释成为消费者的问题（**读时模式** 方法【56】；请参阅 “[文件模型中的模式灵活性](ch2.md#文件模型中的模式灵活性)”）。如果生产者和消费者是不同优先顺序的不同团队，这可能是一种优势。甚至可能不存在一个理想的资料模型，对于不同目的有不同的合适视角。以原始形式简单地转储资料，可以允许多种这样的转换。这种方法被称为 **寿司原则（sushi principle）**：“原始资料更好”【57】。
因此，Hadoop 经常被用于实现 ETL 过程（请参阅 “[资料仓库](ch3.md#资料仓库)”）：事务处理系统中的资料以某种原始形式转储到分散式档案系统中，然后编写 MapReduce 作业来清理资料，将其转换为关系形式，并将其汇入 MPP 资料仓库以进行分析。资料建模仍然在进行，但它在一个单独的步骤中进行，与资料收集相解耦。这种解耦是可行的，因为分散式档案系统支援以任何格式编码的资料。
#### 处理模型的多样性
MPP 资料库是单体的，紧密整合的软体，负责磁碟上的储存布局，查询计划，排程和执行。由于这些元件都可以针对资料库的特定需求进行调整和最佳化，因此整个系统可以在其设计针对的查询型别上取得非常好的效能。而且，SQL 查询语言允许以优雅的语法表达查询，而无需编写程式码，可以在业务分析师使用的视觉化工具（例如 Tableau）中访问到。
另一方面，并非所有型别的处理都可以合理地表达为 SQL 查询。例如，如果要构建机器学习和推荐系统，或者使用相关性排名模型的全文搜寻索引，或者执行影象分析，则很可能需要更一般的资料处理模型。这些型别的处理通常是特别针对特定应用的（例如机器学习的特征工程，机器翻译的自然语言模型，欺诈预测的风险评估函式），因此它们不可避免地需要编写程式码，而不仅仅是查询。
MapReduce 使工程师能够轻松地在大型资料集上执行自己的程式码。如果你有 HDFS 和 MapReduce，那么你 **可以** 在它之上建立一个 SQL 查询执行引擎，事实上这正是 Hive 专案所做的【31】。但是，你也可以编写许多其他形式的批处理，这些批处理不必非要用 SQL 查询表示。
随后，人们发现 MapReduce 对于某些型别的处理而言局限性很大，表现很差，因此在 Hadoop 之上其他各种处理模型也被开发出来（我们将在 “[MapReduce 之后](#MapReduce之后)” 中看到其中一些）。只有两种处理模型，SQL 和 MapReduce，还不够，需要更多不同的模型！而且由于 Hadoop 平台的开放性，实施一整套方法是可行的，而这在单体 MPP 资料库的范畴内是不可能的【58】。
至关重要的是，这些不同的处理模型都可以在共享的单个机器丛集上执行，所有这些机器都可以访问分散式档案系统上的相同档案。在 Hadoop 方式中，不需要将资料汇入到几个不同的专用系统中进行不同型别的处理：系统足够灵活，可以支援同一个丛集内不同的工作负载。不需要移动资料，使得从资料中挖掘价值变得容易得多，也使采用新的处理模型容易的多。
Hadoop 生态系统包括随机访问的 OLTP 资料库，如 HBase（请参阅 “[SSTables 和 LSM 树](ch3.md#SSTables和LSM树)”）和 MPP 风格的分析型资料库，如 Impala 【41】。HBase 与 Impala 都不使用 MapReduce，但都使用 HDFS 进行储存。它们是迥异的资料访问与处理方法，但是它们可以共存，并被整合到同一个系统中。