 1
s
t
e
S
n
o
i
i
t
c
v
E
g
n
d
n
F
i
i
 0.8
 0.6
 0.4
f
o
y
t
i
l
i
 0.2
b
a
b
o
r
P
 0
 3  4  5  6  7  8  9  10  11  12  13  14  15  16
Threshold
Fig. 16. The probability of ﬁnding an eviction set under active detection.
Three sample periods are chosen: 16K, 8K and 4K LLC accesses. Each result
is averaged from at least 200 independent experiments.
I
 80
 70
 60
 50
 40
 30
 20
 10
 0
K
P
M
C
L
L
d
e
g
a
r
e
v
A
4
4
4
4
4
4
4
4
4
4
1
1
3.g
0.b
6.g
2
9.
3
3.
m
m
0
0.p
0
0
1.b
rlb
zip
e
c
c
w
a
cf
a
m
v
e
s
e
s
s
2
e
n
c
h
3
3
3
4
4
4
4
4
5
6.c
4.z
ilc
e
u
7.le
ctu
4.n
slie
s
a
5.g
0.s
a
o
o
m
b
d
m
4
4
4
4
5
5
6.h
4.c
ple
alc
5
5
8.sje
9.
m
n
g
m
ulix
e
r
k
x
m
s
p
A
3
d
4
4
4
4
6
6
7
7
2.lib
G
e
m
4.h
1.o
3.a
2
6
q
u
m
n
sta
r
4
r
ef
ntu
etp
p
s
a
F
D
D
M
T
m
D
Fig. 17. MPKI of SPEC CPU 2006 benchmark cases using a static 1024-set
16-way CEASE LLC.
is crucial to the speed and the correctness of the detector. The
detector might leave a small window for a quick attack if a
remap is late due to a large th. However, normal programs
might trigger remaps if th is too small. To choose a proper
th, we run PPT attacks detected by different combinations of
threshold and sample period (4K, 8K and 16K LLC accesses).
As shown in Fig. 16, sampling every 4K LLC accesses and
triggering a remap whenever az ≥ 5 is enough to reduce the
probability of ﬁnding eviction set to almost nil. Although not
shown in the paper, we have veriﬁed that GE attacks cannot
escape detection with the same parameters.
VII. PERFORMANCE
As the performance overhead of randomized caches has
been shown to be acceptable [16]–[18], we analyze only the
performance impact of the newly proposed ideas.
A. Impact on Normal Applications
The SPEC CPU 2006 benchmark suite [38] is used to
evaluate the impact on normal applications. Similar to Scatter-
Cache, performance results are measured without concurrent
processes [18]. As described in Section III-B, we use a
modiﬁed Spike simulator [40] as the evaluation platform. A
processing core has two private L1 data and instruction caches
(16KB, 64-set, 8-way, 64B cache block). A 1024-set 16-way
L2 cache is used as the LLC where all randomized caches
are implemented. All cache levels use the LRU replacement.
Thanks to the fast simulation speed of Spike, we are able to run
100 billion instructions for each benchmark case, which is 100
and 400 times of the instructions simulated in CEASER[16]
and ScatterCache [18]. Fig. 17 shows the number of misses per
K instructions (MPKI) using a static CEASE LLC, which is
used as the baseline for other performance results. The MPKI
ﬁgures match with the result provided in CEASER[16].
Fig. 18 demonstrates the performance overhead of different
remap strategies on a CEASER LLC. The remap period is
1.556
1.219
1.154
ACC-10
EV-10
DT+EV-10
 1.1
 1.08
 1.06
 1.04
 1.02
 1
 0.98
 0.96
I
K
P
M
d
e
z
i
l
a
m
r
o
N
4
4
4
4
4
4
4
4
4
4
0
0
0
1
1
3.g
0.b
6.g
2
9.
3
3.
m
m
0.p
1.b
rlb
zip
e
2
e
c
c
w
a
cf
a
v
m
e
e
s
s
s
4
4
4
4
4
5
3
3
3
6.c
4.z
ilc
e
u
7.le
ctu
4.n
slie
s
a
5.g
0.s
a
o
m
b
d
m
m
s
p
A
3
d
4
4
4
4
4
4
4
4
6
6
7
7
5
5
o
6.h
4.c
ple
alc
5
5
9.
8.sje
m
n
g
m
ulix
e
r
k
x
2.lib
G
e
m
4.h
1.o
3.a
2
6
m
n
q
u
s
a
F
D
4
r
ef
ntu
etp
p
sta
r
n
c
h
D
M
T
m
D
Fig. 18. Normalized MPKI of SPEC CPU 2006 benchmark cases running on
a CEASER LLC. ACC-10: remap every 10 accesses per cache block; EV-10:
remap every 10 evictions per cache block; DT: attack detection. The static
CEASE is used as the baseline.
I
B
P
R
 1200
 1000
 800
 600
 400
 200
 0
 1
I
B
P
R
d
e
z
i
l
a
m
r
o
N
 0.8
 0.6
 0.4
 0.2
 0
ACC-10
EV-10
DT+EV-10
4
4
4
0
0
0
0.p
1.b
rlb
zip
e
2
c
c
e
n
c
h
w
a
cf
a
v
m
e
e
s
s
s