85
11
0
18
67
85
79
47
27
50
62
82
0
21
23
84
44
-
-
-
-
-
-
All Attacks Legitimate
13.00
62.70
48.10
55.30
2.27
20.55
44.82
77.27
53.00
2.78
30.56
52.11
68.11
67.22
57.11
99.43
99.33
99.28
98.95
94.84
94.55
93.11
89.29
91.18
69.70
69.40
68.00
65.40
62.10
65.40
Table 2: Accuracy of Randomized Squeezing (%). Bold values indicate an improvement over corresponding values in Table 1.
Dataset
MNIST
CIFAR-10
ImageNet
Squeezer
L∞ Attacks
L2 Attacks
Name
Parameters
FGSM BIM
CW∞
Next
LL
DeepFool
CW2
Next
LL
CW0
Next
L0 Attacks
JSMA
LL
Next
LL
All Attacks Legitimate
Bit Depth
(δ = 0.2)
Median Smoothing
(δ = 0.5)
Bit Depth
(δ = 0.05)
Median Smoothing
(δ = 0.05)
Non-local Means
(δ = 0.05)
Bit Depth
(δ = 0.1)
Median Smoothing
(δ = 0.1)
Non-local Means
(δ = 0.1)
Pure Randomness
1-bit
2 × 2
3 × 3
5-bit
4-bit
2 × 2
11-3-4
5-bit
4-bit
2 × 2
3 × 3
11-3-4
δ = 0.1
88.98
84.06
98.37
98.26
54.78
58.03
27.33
30.70
25.53
27.61
47.27
51.34
50.70
58.53
71.75
68.89
40.22
52.87
70.89
67.29
47.66
66.23
83.59
85.90
35.27
61.19
88.59
89.39
34.86
35.63
53.44
52.23
32.53
34.70
54.97
56.11
62.49
58.88
55.29
56.33
76.97
76.66
69.11
63.76
78.97
76.91
79.50
78.92
69.09
63.88
81.28
79.58
-
-
-
69.91
67.55
83.70
86.31
70.73
70.91
67.22
62.87
72.92
68.84
77.44
63.19
52.20
61.27
76.90
72.95
84.45
42.21
55.40
75.06
71.08
86.50
1.39
40.65
56.86
26.21
30.25
85.61
0.42
28.27
48.78
23.89
26.60
86.11
49.26
48.41
58.15
77.23
29.84
29.36
78.54
54.05
71.67
22.06
22.14
73.62
91.01
90.52
22.08
24.21
44.05
33.80
79.45
79.11
70.13
64.46
80.31
79.69
69.97
63.91
81.11
81.52
79.05
80.41
67.52
67.40
68.47
63.76
66.02
67.06
67.43
66.48
68.20
64.22
68.71
67.5
-
-
-
-
-
-
-
-
-
-
-
-
60.98
44.68
56.83
49.19
48.92
78.36
60.58
67.97
67.88
66.46
62.00
68.71
67.82
99.31
97.54
97.99
85.03
81.27
86.80
90.90
63.00
61.00
57.00
52.50
64.50
64
must be carefully chosen. Randomized Squeezing can mitigate
the limitation of a weak defense to some extent, as seen in
the case of CIFAR-10 bit depth (5-bit) defense where the accu-
racy over adversarial samples increases by almost 2.5 times.
However, efficacy of the defense is critical to have success in
general.
Figure 7: Increase in target prediction probability and distortion (in normalized L2 distance) as more confident adversarial
samples are synthesized (dashed lines show extrapolated values).
5.3 Whitebox Adversaries
In this section, we study whether randomness influences the
success of whitebox adversaries. We evaluate the BPDA and
EOT attacks proposed by Athalye et al. [1] against Cropping-
Rescaling [16], Region-Based Classification [5],8 and Random-
ized Squeezing with bit-depth reduction as squeezing func-
tion. Beyond tuning the attacks to each defensive technique,
we chose the attack strategies that are best suited for each of
the defenses, as outlined in [1]. Specifically, we consider: a
pure instantiation of EOT against Cropping-Rescaling, as this
defense applies differentiable transformations; the BPDA at-
tack against Region-Based Classification, and a combination of
BPDA and EOT against Randomized Squeezing, so that both
the non-differentiability of squeezing and the input random-
ization are taken into account when generating adversarial
samples. For completeness, we also ran the attacks against the
deterministic bit-depth reduction.
when randomness is not applied, less than 20 iterations are suf-
ficient to achieve a prediction probability of 0.8. In contrast, for
randomized defenses 20 iterations lead to a prediction prob-
ability of only 0.6 in the best case (i.e., Cropping-Rescaling
with crop size 120), and of less than 0.05 in the case of the
seemingly most robust technique (i.e., Randomized Squeez-
ing for δ = 0.2). Comparing among the randomness-based
defenses, we observe that for a prediction probability of 0.6,
the attacks requires about 20, 35, or 50 iterations for Cropping-
Rescaling depending on the crop size, 35 or 100 iterations in
the case of Region-Based Classification for randomness mag-
nitudes δ = 0.1 and δ = 0.2, respectively, and 45 or 140 itera-
tions against Randomized Squeezing for the same values of δ,
indicating that both online defenses outperform Cropping-
Rescaling.
We also illustrate how the target prediction probability
varies with the distortion, measured as normalized L2 dis-
tance (see the rightmost plot in Figure 7). Again, we see that
randomness-based defenses are more robust than their de-
terministic counterparts, as they force the attacker to intro-
duce larger perturbation. Namely, for all deterministic de-
fenses, high-confidence adversarial samples can be generated
with a distortion below 0.02, while larger perturbations are
necessary to defeat randomized defenses. In particular, high-
confidence adversarial samples against Region-Based Clas-
sification and Randomized Squeezing require perturbations
with L2 distance above 0.025 (for δ = 0.1), and above 0.035 (for
δ = 0.2), respectively, with Region-Based Classification pre-
senting slightly higher robustness than Randomized Squeez-
ing according to this metric. Our results support the intuition
that introducing unpredictability to the classification process
makes it computationally expensive to find adversarial pertur-
bations which are successful regardless of the randomness.
We evaluated the defenses against the aforementioned at-
tacks on the same set of 100 images, selected at random from
the ImageNet dataset. Each image was assigned a target class
at random. Figure 7 summarizes the results.
Recall that every attack iteration aims to generate adver-
sarial samples with higher confidence compared to the previ-
ous iteration. Correspondingly, in the leftmost plot we depict
the (average) target prediction probability against the num-