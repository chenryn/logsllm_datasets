to encode bitwise operations will have a high cost since each
individual bit check and operation will have its own instruc-
tion. Therefore, we introduce another opcode. Given three
n-bit integers a, b and c, this opcode veriﬁes that c is either
the bitwise-xor, bitwise-or or bitwise-and of a and b, or any
of their bitwise-negations (12 possibilities in total). In our
circuit, we set n to be 32 (Note that in the evaluation section,
we will evaluate short and long-integer computations that do
not align with 32-bit arithmetic). This opcode can also be
used for range checking, e.g., verify that two operands a and
b are bounded without introducing entries for the individual
bits, which is useful for comparison, division, etc.
To illustrate the savings in the case of a bitwise-OR of two
32-bit values, using opcode 1 only would consume 96 in-
structions for splitting the ﬁrst two operands into bits (64
instructions for booleanity checks and 32 for bits weighted
sums), and 32 instructions for the OR operations, totalling
26× (96 +32) = 3328 constraints. On the other hand, using
a single opcode 2 instruction will cost about 135 constraints.
Note that the bit checks required by the splitting operations
within this opcode are done within its circuit and does not
rely on other opcodes.
• Opcode
3
(Split/Pack Operations,
shift/rotation,
2138    29th USENIX Security Symposium
USENIX Association
weighted sums): This opcode can used to explicitly extract
bit or byte values, or pack them into one value. It can also be
used to support shifting/rotation operations, and weighted
sums of native ﬁeld elements. Note that using opcode 1
or opcode 2 for all bit extractions of a single element will
not result into an efﬁcient implementation. For example,
to split a 32-bit value into bits, using opcode 1 will cost
48 instructions (1248 constraints), while using opcode 2
will require masking several times (32 instructions, costing
4320 constraints). Note that the circuit of opcode 2 does not
introduce entries for the bits used within its circuit. On the
other hand, the circuit of opcode 3 requires 330 constraints
(while enabling other functionalities, like rotation, weighted
sums, etc).
• Opcode 4 (Memory accesses): This opcode is used for
accessing arrays during runtime when the index operand
has an unknown value. Previous compilers use different ap-
proaches for implementing this functionality [3, 4, 9–11]. In
the general case, a permutation network approach is used to
verify permutations in previous work, which costs O(nlogn)
constraints, where n denotes the number of accesses. In our
circuit, we rely on the randomness values we have in the
circuit to get an O(n) circuit instead (this uses a similar idea
to the global permutation check).
Representation of other basic operations. Compared to the
universal circuit in vnTinyRAM’s implementation [46], we
do not have explicit opcodes for other basic operations like
comparisons, divisions and others. These operations can be
implemented using few calls to some of the opcodes above.
For example, performing a 32-bit unsigned integer compari-
son can be implemented using opcodes 1 and 2. Note that in
our evaluation setting, we consider computations that heavily
rely on basic operations not explicitly expressed in our opcode
system, or operations that do not align with 32-bit arithmetic,
such as sorting 16-bit elements, RSA (2048-bit integers) and
AES (8-bit integers).
Opcode distribution. One remaining design decision is how
many times an opcode type should appear in the circuit. Com-
pared to previous work, we have more ﬂexibility in choosing
the distribution of the opcodes as instructions are not veriﬁed
in order (See Figure 1 and Section 5.3). We noticed that hav-
ing the same number of instances per each opcode type will
lead to high waste if the custom computation heavily relies
on the cheapest opcode. As a heuristic way to balance these
factors, we consider the cost of the individual instruction cir-
cuit corresponding to each opcode and the number of basic
operation categories supported by it. For a given bound on the
total number of constraints of the universal circuit B, an even
share is given to each of the ﬁrst three opcodes, while half of
that share is given to the last opcode as it is only speciﬁc to a
single category (memory operations) while the other opcodes
can support different arithmetic and Boolean operations (See
Table 6). More concretely, if the circuit corresponding to each
opcode costs x1,x2,x3,x4 constraints respectively, each will
appear around 2B
times. We believe that choos-
7x1
ing the ideal distribution should be done based on application
analysis, and is left to future work (Section 7).
, 2B
7x3
, 2B
7x2
, B
7x4
5.3 Comparison with vnTinyRAM Circuit
vnTinyRAM follows the von Neumann paradigm, where both
the program and the data are stored in the same address
space [4]. In vnTinyRAM, the program instructions are loaded
and veriﬁed in the circuit, and features like runtime code gen-
eration is supported. While we could integrate the techniques
of MIRAGE directly to make vnTinyRAM’s circuit linear, as
improving the permutation check will make checking both
instructions and data more efﬁcient, we chose to focus on the
circuit representation of computation and not to have explicit
support or speciﬁc opcodes for loading/generating instruc-
tions during runtime. This is because of two main observa-
tions: 1) Loading instructions at runtime implies an ordered
processing of instructions in the circuit, which can lead to
high overhead and much less utilization of the available gates.
This is because when loading unknown instructions during
runtime, the circuit of each step would have to account for
all possible operation types. 2) Looking into many applica-
tions involving zk-SNARKs, we are not aware of common use
cases that heavily rely on runtime code generation. Further-
more, we believe there is a higher need to universal circuits
that provide better performance in practice.
Our universal circuit targets the circuit representation of
programs and differs in the following ways: 1) It uses a ran-
domized check to verify the consistency across the circuit.
This has a linear cost compared to the quasi-linear cost of
vnTinyRAM. 2) It does not require verifying operations in
the order they were executed. This implies a much better
utilization of the circuit, as each computation step known
at the speciﬁcation time only pays for the opcode(s) it uses.
3) On the other hand, targeting the circuit representation of
programs has implications. For example, mapping an if-else
statement to our construction will consume instructions for
both branches. Note that features like jump instructions and
runtime code generation could be supported by specifying
a vnTinyRAM-like circuit as input to our circuit. Although
this would rely on more efﬁcient randomized checks, instruc-
tions resolved during runtime will have a much higher cost
compared to the instructions known at the speciﬁcation time.
6 Evaluation
We implemented our protocol on top of libsnark [46], and
developed a front-end java library that generates the universal
circuit, and allows a programmer to specify a computation.
In the following, we discuss the performance impact of using
our construction for universal circuits in different settings.
Comparison with non-universal and universal circuits.
First, we start by a comparison with vnTinyRAM in terms of
USENIX Association
29th USENIX Security Symposium    2139
Table 3: Comparison between our work and earlier non-universal and universal circuits with respect to the scale of supported
applications when the number of constraints (the total circuit size) is nearly the same
Application
Construction
Universal Circuit?
Supported Parameters
Number of constraints
Unused instructions (%)
Matrix Multiplication
O(m3) operations
Merge Sort
O(mlogm) operations
[10, 11]
vnTinyRAM
This work
xJsnark [11]
vnTinyRAM
This work






m = 188
m = 7
m = 41
m = 600
m = 32
m = 200
6.64 million
6.67 million [10]
6.5 million
5.32 million
5.37 million [10]
5.32 million
33%
34%
Table 4: The cost of representing different primitives using
the non-universal and our universal approaches in terms of the
number of constraints. For the universal approach, we report
the number of constraints used by the consumed instructions
only for this table to study the exact ampliﬁcation cost. Tables
3 and 5 provide end-to-end results involving the upper bounds
on the universal circuit.
Application
xJsnark [11]
(non-universal)
Matrix Mul. (m=10, Native ﬁeld)
Merge Sort (m=64, 16-bit values)
SHA-256 (unpadded)
RSA-2048 ModExp (17-bit Exp.)
AES-128 (Key expansion incl.)
1000
238835
25538
88949
14240
This work
(universal)
Cost of used
instructions
26000 (26×)
558680 (2.33×)
308842 (12×)
1446638 (16×)
214284 (15×)
the scale of the applications that can be supported given the
same circuit size. We use the results reported in the implemen-
tation of the vnTinyRAM speciﬁcation by [10] as a baseline.
For our circuits, we use the multi-opcode circuits, where the
opcodes are distributed according to the criteria presented
earlier. We consider two applications: matrix multiplication
and merge sort which use different basic operations and ran-
dom memory accesses. We also compare with non-universal
circuit generation tools [10, 11].
As shown in Table 3, our universal circuit supports larger-
scale problems than vnTinyRAM, while reducing the gap
between the universal and the non-universal approaches. With
respect to the number of basic operations supported under the
same circuit sizes, our circuit enables orders of magnitude
higher scale compared to the vnTinyRAM circuit. Note that
part of our circuit is also still available to be used by other
operations, as illustrated by the ratio of available instructions.
Cost of universality. Next, we report the ampliﬁcation cost
of certain primitives that use different kinds of operations and
does not necessarily operate in the 32-bit integer space. For
this part of the evaluation, the cost of the used instructions are
only counted to calculate the exact ampliﬁcation cost.
Besides matrix multiplication and merge sort, we consider
three cryptographic primitives, and compare with the opti-
mized non-universal circuits reported by xJsnark [11]. Note
that the chosen primitives span basic operations not directly
covered by the opcodes described in Section 5. For example,
the RSA-2048 modular exponentiation circuit performs mod
operations in the circuit modulo a long integer. Also, the AES-
128 circuit performs random memory accesses and operates
on 8-bit words, while our universal circuit opcodes are for
32-bit words. This required effort to get a concise mapping
from the AES operations to the instructions of our universal
circuit. Note that the optimizations of previous compilers [11]
assume a cost model that is only relevant in the custom circuit
scenario. Table 4 provides the comparison. While there is
an ampliﬁcation factor between 3 and 26× depending on the
application, in comparison vnTinyRAM is expected to have 1
to 2 order of magnitude higher overhead as shown earlier.
Privacy-preserving Smart Contracts. Finally, we evaluate
our system in the context of a practical application involving
smart contracts. In particular, we address the trusted setup per
contract challenge of the HAWK system [16]. In HAWK, the
users’ circuits do not change depending on the computation,
while the manager’s circuit does change per computation. The
manager’s circuit in the HAWK system veriﬁes the correct
execution of a pre-speciﬁed contract code, but on private data.
This circuit relies on commitment and symmetric encryption
gadgets besides the function being supported.
We consider two applications from the HAWK paper in our
evaluation, namely privacy-preserving auctions and crowd-
funding in the case of six participants (In Section 7, we discuss
how to scale the system up to more participants). For this eval-
uation, we ﬁx our universal multi-opcode circuit size to 10
million constraints. We used libsnark’s Groth16 implementa-
tion as the back end for the baseline. The experiments were
conducted on an EC2 machine (c5d.9xlarge instance), using
a single processor, and consuming 36 GB of memory at most
during the keygen/prove stage. Table 5 illustrates the results.
We observe the following:
• The untrusted key derivation phase that happens per con-
tract in our construction just adds one group element to
the veriﬁer’s storage (the contract in our scenario), while
the non-universal approach will generate a separate larger
veriﬁcation key per contract in a trusted manner.
• Our universal approach only adds a small overhead to the
veriﬁcation time and the proof size.
2140    29th USENIX Security Symposium
USENIX Association
Table 5: Comparison between our system and HAWK [16] in the context of privacy-preserving auction and crowdfunding
applications. The number of participants in each application is set to 6 (1 manager, and 5 bidders/participants). The table reports
the setup cost on one machine. In practice, techniques for distributed trusted setup would be used.
System
Trusted setup per app
Proof
App.
Univ. Trusted Setup (once)
Time
VK
PK
Time
PK
VK
Untrusted Key Deriv.
Time
VK+3
Time
Size
Verify
Time
HAWK [16]
N/A