tion. We track the bandwidth utilization for control (Ping and Pong), query
(queries and query hits), and route table update messages. We limit the con-
trol messages only to the basic Ping and Pong messages as they make up the
overwhelming majority of non-query messages. Additionally, by tracking route
table updates separate from the basic control messages, we can determine how
the behavior of the network has evolved with respect to the use of each message
type. Note that we do not show bandwidth consumed by peers for downloading
objects.
We examined bandwidth utilization by tracking the bandwidth requirements
for each message type. Figure 3 shows the bandwidth utilization for each message
type in a 24 hour period for 2003 and 2006 traﬃc respectively. In 2003, query
traﬃc dominates the bandwidth utilization. Further, the amount of query traﬃc
varies at diﬀerent times of the day while control traﬃc remains relatively stable
throughout the entire day. The 2006 traﬃc exhibits diﬀerent properties. First, the
query traﬃc represents signiﬁcantly less bandwidth than in 2003, although out
going query traﬃc is still the dominant consumer of bandwidth. Control traﬃc,
both incoming and outgoing, plays a larger role under the current v0.6 protocol
in 2006 than it did in 2003, as does route table update traﬃc. The changes in
bandwidth throughout the day are most pronounced in incoming and outgoing
48
W. Acosta and S. Chandra
L
T
T
 7
 6
 5
 4
 3
 2
 1
 0
2003 Traffic
2006 Traffic
 0
 5
 10
Hour of Day
 15
 20
(a) TTL left
n
e
k
a
T
s
p
o
H
 7
 6
 5
 4
 3
 2
 1
 0
2003 Traffic
2006 Traffic
 0
 5
 10
Hour of Day
 15
 20
(b) Hops Taken
Fig. 2. Mean hourly TTL and hops taken for incoming query messages in a 24 hour
period for 2003 and 2006 traﬃc
query traﬃc while control traﬃc remains relatively constant throughout the day.
The increase in route table update traﬃc can be attributed to the fact that in
2003, very few clients were using the new v0.6 protocol. As more clients moved
to the new protocol, we see a rise in the number of route table update messages
sent in the system.
The evolution of the Gnutella protocol and network results in traﬃc charac-
teristics that are diﬀerent in 2006 than they were in 2003. First, in 2003, control
and route table updates represent a small percentage of the total bandwidth
utilization. In 2006, however, control traﬃc is signiﬁcantly more prominent with
respect to the percentage of bandwidth utilization. Additionally, route table up-
dates become a non-trivial message category in 2006 whereas these messages
were virtually non-existent in 2003. Finally, the characteristics of query traﬃc
from 2003 to 2006 change dramatically. In 2003, query traﬃc (both incoming
and outgoing) dominates the bandwidth utilization. In 2006, query traﬃc still
consumes a large percentage of the bandwidth. However, only outgoing query
traﬃc consumes a large amount of bandwidth. Incoming query traﬃc uses less
bandwidth than control traﬃc in 2006. This is a result of the evolution of the
protocol speciﬁcation. The v0.6 protocol establishes ultra-peers as peers with
many neighbors. Ultra-peers can collect information about ﬁles shared at their
leaf nodes and use this information to respond to queries. We saw earlier that
message TTL are decreased in the v0.6 protocol, so fewer messages are sent in
the network. Additionally, the v0.6 query routing protocol attempts to minimize
the number of query messages that are sent. Therefore, a node under the current
v0.6 protocol will receive fewer incoming query messages than it would have in
2003. Because ultra-peers have many connections, propagating queries to each
neighbor results in outgoing query traﬃc utilizing a large percentage of the total
bandwidth. Although the outgoing query bandwidth is large in absolute terms,
there is an improvement relative to 2003 since the outgoing query bandwidth
Trace Driven Analysis of the Long Term Evolution
49
 250
 200
)
s
p
b
k
(
h
t
d
i
w
d
n
a
B
 150
 100
 50
 0
 0
In Control Traffic
Out Control Traffic
In Query Traffic
Out Query Traffic
In Other Traffic
Out Other Traffic
 5
 10
 15
 20
Hour of Day
(a) 2003 Traﬃc
 250
 200
)
s
p
b
k
(
h
t
d
i
w
d
n
a
B
 150
 100
 50
 0
 0
In Control Traffic
Out Control Traffic
In Query Traffic
Out Query Traffic
In Other Traffic
Out Other Traffic
 5
 10
 15
 20
Hour of Day
(b) 2006 Traﬃc
Fig. 3. Hourly bandwidth for diﬀerent message types in a 24 hour period for 2003 and
2006 traﬃc. Note that the curves in Figure 3(a) do not wrap around to the same value
at the end of a 24 hour period. This was due to our gathering procedure in 2003 that
required the client to shut down after each 2 hour trace for processing. The client did
not get restarted again for another hour in order to accommodate processing. This
problem was ﬁxed in our later data capturing process.
was reduced from 200 kbps to 100 kbps when the node is an ultra-peer with 30
connections. Leaf peers beneﬁt from this situation as they have fewer connections
and receive very few incoming queries.
4.5 Query Traﬃc Analysis
In the previous section we showed the evolution of bandwidth utilization for
the diﬀerent message types from 2003 to 2006. In this section, we will show
the evolution of query traﬃc. We are interested in examining the relationship
between the number of query messages sent and received and the success rate.
Table 2 shows a summary of the query traﬃc measurements for traces from 2003
and 2006 traﬃc. The values in the table are for a typical 24 hour interval. In
2003, query traﬃc constituted a large component of the bandwidth used. We see
in the table that in 2003, a peer would receive over 5M query messages in a 24
hour interval, or approximately 60 queries per second. In 2006, this number is
signiﬁcantly reduced to 280K queries in a 24 hour interval, or about 3 queries
per second. With a mean query message size of 73.25 bytes for 2003 traﬃc, 60
queries per second corresponds to an incoming data rate of 4.39 KB/s or 35.2
kbps. Such a data rate would overwhelm most home dial-up connections. The
current state of the network has reduced the number of queries received at each
node at the expense of requiring a large number of connections for ultra-peer
nodes. The large number of connections, in turn, results in a large outgoing
bandwidth utilization. On a per query basis, 2003 traﬃc generated 0.285 KB
per query, while 2006 traﬃc generated 4.026 KB per query. In 2003, each query
was propagated to less than 4 peers on average while in 2006, each query was
50
W. Acosta and S. Chandra
Table 2. Query traﬃc summary for a 24 hour trace from 2003 , 2005 and 2006
2003
2005
2006
5,261,064
614,365
279,235
Queries Received
Mean Queries per second
Query Message Size (including header)
Successful Queries
Success Rate
Mean Queue Time (successful queries)
Mean Outgoing Messages per Query
Mean Outgoing Bytes per Query
Mean Outgoing Query Bandwidth
60.89
73.25
184,140
3.5%
62.724 s
7.11
69.04
63,609
10.3%
86.199s
3.23
105.61
19,443
6.9%
5.435 s
38.439
0.285 kB 0.677KB 4.026 kB
3.59
9.81
138.82 kbps 38.5 Kbps 104.03 kbps
propagated to a mean of 38 peers. Note that in 2005, the bandwidth utilization
is much lower compared to both 2003 and 2006. This is because our client was
not able to operate as an ultra-peer and thus only was able to maintain less than
10 connections. However, other metrics such as incoming query rate for 2005 is
consistent with the trend from 2003 to 2006.
Next we investigate the ability of the network to successfully resolve queries.
We see that from 2003 to 2006, the success rate almost doubles from 3.5% in
2003 to 6.9% in 2006. Nevertheless, the success rate is still remarkably low. In
2006, a success rate of 6.9% implies that 93.1% of queries that reach a node
will not be resolved after the node propagates the query. This means that each
node is utilizing bandwidth to process queries but that eﬀort is wasted on over
90% of those queries. In a 24 hour interval, a node receives approximately 280K
queries with an average size of 105 bytes. Each of these queries is propagated
to approximately 38 neighbors resulting in 1.14 GB of outgoing data, of which
93.1%, or 1.03 GB, are wasted since the success rate is only 6.9%.
5 Limitations
The study described in this paper was conducted using a single ultrapeer on our
university’s campus. As such, it may not be representative of the global behav-
ior of Gnutella. We had performed measurements from a peer on a broadband
network using a diﬀerent service provider and observed similar results to as was
reported in this paper. Also, the broadband studies were conducted in 2006; we
do not have any measurement from 2003 or 2005 for this analysis. Hence, we
cannot ascertain the consistency of the results among broadband users.
6 Conclusion
We presented the results of our measurement and analysis of the Gnutella ﬁle-
sharing network. We showed that although the Gnutella architecture changed
from 2003 to 2006 to help alleviate query bandwidth utilization, the success
Trace Driven Analysis of the Long Term Evolution
51
rate of queries has not shown signiﬁcant improvements. Additionally, the band-
width utilization problem is alleviated at low-capacity peers (leaf peers), but
high capacity peers (ultra peers) experience an increase in query bandwidth uti-
lization. The increase in bandwidth occurs due to the large number of neighbors
connected to the ultra peers. These ﬁndings indicate that despite the eﬀorts to
improve the performance of Gnutella, search performance is limited by the design
of the protocol. We are investigating an approach that exploits the underlying
characteristics of the queries and the distribution of objects in the system in
order to improve search performance.
References
1. Gnutella protocol v0.4. http://dss.clip2.com/GnutellaProtocol04.pdf.
2. Gnutella protocol v0.6. http://rfc-gnutella.sourceforge.net/src/rfc-0 6-draft.html.
3. Krishna P. Gummadi, Richard J. Dunn, Stefan Saroiu, Steven D. Gribble, Henry M.
Levy, and John Zahorjan. Measurement, modeling, and analysis of a peer-to-
peer ﬁle-sharing workload. In Proceedings of the nineteenth ACM symposium on
Operating systems principles, pages 314–329. ACM Press, 2003.
4. Daniel Hughes, Geoﬀ Coulson, and James Walkerdine. Free riding on gnutella
revisited: The bell tolls? IEEE Distributed Systems Online, 6(6), June 2005.
5. Kazaa media desktop. http://www.kazaa.com/us/index.htm.
6. Overnet. http://www.overnet.org/.
7. The phex gnutella client. http://phex.kouk.de.
8. Yi Qiao and Fabin E. Bustamante. Structured and unstructured overlays under
the microscope - a measurement-based view of two p2p systems that people use.
In Proceedings of the USENIX Annual Technical Conference, 2006.
9. Amir H. Rasti, Daniel Stutzbach, and Reza Rejaie. On the long-term evolution of
the two-tier gnutella overlay. In IEEE Golbal Internet, 2006.
10. M. Ripeanu, I. Foster, and A. Iamnitchi. Mapping the gnutella network: Proper-
ties of large-scale peer-to-peer systems and implications for system design. IEEE
Internet Computing Journal, 6(1), 2002.
11. Stefan Saroiu, P. Krishna Gummadi, and Steven D. Gribble. A measurement study
of peer-to-peer ﬁle sharing systems. In Proceedings of Multimedia Computing and
Networking 2002 (MMCN ’02), San Jose, CA, USA, January 2002.