improve the quality of our error reports to developers;
we are not aware of previous work on this topic. Such
techniques are vitally important because human time is
the most expensive part of a test infrastructure. Finally,
Metafuzz uses on-demand computing with the Amazon
Elastic Compute Cloud, and we explicitly quantify the
cost of each bug found, which was not done in previous
work.
4 Dynamic Test Generation
We describe the architecture of SmartFuzz, a tool for dy-
namic test generation of x86 binary programs on Linux.
Dynamic test generation on x86 binaries—without ac-
cess to source code—raises special challenges. We dis-
cuss these challenges and motivate our fundamental de-
sign choices.
4
determine if it exhibits a bug. If so, we report the bug;
otherwise, we add the test case to the pool for scoring and
possible symbolic execution. For triage, we use Valgrind
memcheck on the target program with each test case,
which is a tool that observes concrete execution looking
for common programming errors [26]. We record any
test case that causes the program to crash or triggers a
memcheck warning.
We chose memcheck because it checks a variety of
properties, including reads and writes to invalid mem-
ory locations, memory leaks, and use of uninitialized
values. Re-implementing these analyses as part of the
SmartFuzz symbolic execution tool would be wasteful
and error-prone, as the memcheck tool has had the bene-
ﬁt of multiple years of use in large-scale projects such as
Firefox and OpenOfﬁce. The memcheck tool is known
as a tool with a low false positive rate, as well, making
it more likely that developers will pay attention to bugs
reported by memcheck. Given a memcheck error report,
developers do not even need to know that associated test
case was created by SmartFuzz.
We do not attempt to classify the bugs we ﬁnd as ex-
ploitable or not exploitable, because doing so by hand
for the volume of test cases we generate is impracti-
cal. Many of the bugs found by memcheck are mem-
ory safety errors, which often lead to security vulnerabil-
ities. Writes to invalid memory locations, in particular,
are a red ﬂag. Finally, to report bugs we use the Metafuzz
framework described in Section 6.
4.2 Design Choices
Intermediate Representation. The sheer size and com-
plexity of the x86 instruction set poses a challenge for
analyzing x86 binaries. We decided to translate the un-
derlying x86 code on-the-ﬂy to an intermediate repre-
sentation, then map the intermediate representation to
symbolic formulas. Speciﬁcally, we used the Valgrind
binary instrumentation tool to translate x86 instructions
into VEX, the Valgrind intermediate representation [24].
The BitBlaze system works similarly, but with a different
intermediate representation [5]. Details are available in
an extended version of this paper2.
Using an intermediate representation offers several ad-
vantages. First, it allows for a degree of platform inde-
pendence:
though we support only x86 in our current
tool, the VEX library also supports the AMD64 and Pow-
erPC instruction sets, with ARM support under active de-
velopment. Adding support for these additional architec-
tures requires only adding support for a small number of
additional VEX instructions, not an entirely new instruc-
tion set from scratch. Second, the VEX library generates
IR that satisﬁes the single static assignment property and
2http://www.cs.berkeley.edu/~dmolnar/
usenix09-full.pdf
Figure 2: Dynamic test generation includes four stages:
symbolic execution, solving to obtain new test cases,
then triage to determine whether to report a bug or score
the test case for addition to the pool of unexplored test
cases.
4.1 Architecture
The SmartFuzz architecture is as follows: First, we add
one or more test cases to a pool. Each test case in the
pool receives a score given by the number of new basic
blocks seen when running the target program on the test
case. By “new” we mean that the basic block has not
been observed while scoring any previous test case; we
identify basic blocks by the instruction pointer of their
entry point.
In each iteration of test generation, we choose a high-
scoring test case, execute the program on that input, and
use symbolic execution to generate a set of constraints
that record how each intermediate value computed by the
program relates to the inputs in the test case. SmartFuzz
implements the symbolic execution and scoring compo-
nents using the Valgrind binary analysis framework, and
we use STP [12] to solve constraints.
For each symbolic branch, SmartFuzz adds a con-
straint that tries to force the program down a differ-
ent path. We then query the constraint solver to see
whether there exists any solution to the resulting set of
constraints; if there is, the solution describes a new test
case. We refer to these as coverage queries to the con-
straint solver.
SmartFuzz also injects constraints that are satisﬁed if
a condition causing an error or potential error is satis-
ﬁed (e.g., to force an arithmetic calculation to overﬂow).
We then query the constraint solver; a solution describes
a test case likely to cause an error. We refer to these
as bug-seeking queries to the constraint solver. Bug-
seeking queries come in different types, depending on
the speciﬁc error they seek to exhibit in the program.
Both coverage and bug-seeking queries are explored
in a generational search similar to the SAGE tool [14].
Each query from a symbolic trace is solved in turn, and
new test cases created from successfully solved queries.
A single symbolic execution therefore leads to many cov-
erage and bug-seeking queries to the constraint solver,
which may result in many new test cases.
We triage each new test case as it is generated, i.e. we
5
performs other optimizations, which makes the transla-
tion from IR to formulas more straightforward. Third,
and most importantly, this choice allowed us to outsource
the pain of dealing with the minutae of the x86 instruc-
tion set to the VEX library, which has had years of pro-
duction use as part of the Valgrind memory checking
tool. For instance, we don’t need to explicitly model
the EFLAGS register, as the VEX library translates it
to boolean operations. The main shortcoming with the
VEX IR is that a single x86 instruction may expand to
ﬁve or more IR instructions, which results in long traces
and correspondingly longer symbolic formulas.
Online Constraint Generation. SmartFuzz uses online
constraint generation, in which constraints are generated
while the program is running.
In contrast, SAGE (an-
other tool for dynamic test generation) uses ofﬂine con-
straint generation, where the program is ﬁrst traced and
then the trace is replayed to generate constraints [14].
Ofﬂine constraint generation has several advantages: it
is not sensitive to concurrency or nondeterminism in sys-
tem calls; tracing has lower runtime overhead than con-
straint generation, so can be applied to running systems
in a realistic environment; and, this separation of con-
cerns makes the system easier to develop and debug,
not least because trace replay and constraint generation
is reproducible and deterministic. In short, ofﬂine con-
straint generation has important software engineering ad-
vantages.
SmartFuzz uses online constraint generation primarily
because, when the SmartFuzz project began, we were not
aware of an available ofﬂine trace-and-replay framework
with an intermediate representation comparable to VEX.
Today, O’Callahan’s chronicle-recorder could pro-
vide a starting point for a VEX-based ofﬂine constraint
generation tool [25].
Memory Model. Other symbolic execution tools such
as EXE and KLEE model memory as a set of symbolic
arrays, with one array for each allocated memory object.
We do not. Instead, for each load or store instruction,
we ﬁrst concretize the memory address before access-
ing the symbolic heap. In particular, we keep a map M
from concrete memory addresses to symbolic values. If
the program reads from concrete address a, we retrieve
a symbolic value from M(a). Even if we have recorded
a symbolic expression a associated with this address, the
symbolic address is ignored. Note that the value of a is
known at constraint generation time and hence becomes
(as far as the solver is concerned) a constant. Store in-
structions are handled similarly.
While this approach sacriﬁces precision, it scales bet-
ter to large traces. We note that the SAGE tool adopts
a similar memory model. In particular, concretizing ad-
dresses generates symbolic formulas that the constraint
solver can solve much more efﬁciently, because the
solver does not need to reason about aliasing of point-
ers.
Only Tainted Data is Symbolic. We track the taint sta-
tus of every byte in memory. As an optimization, we
do not store symbolic information for untainted memory
locations, because by deﬁnition untainted data is not de-
pendent upon the untrusted inputs that we are trying to
vary. We have found that only a tiny fraction of the data
processed along a single execution path is tainted. Con-
sequently, this optimization greatly reduces the size of
our constraint systems and reduces the memory overhead
of symbolic execution.
Focus on Fuzzing Files. We decided to focus on single-
threaded programs, such as media players, that read a ﬁle
containing untrusted data. Thus, a test case is simply the
contents of this ﬁle, and SmartFuzz can focus on gen-
erating candidate ﬁles. This simpliﬁes the symbolic ex-
ecution and test case generation infrastructure, because
there are a limited number of system calls that read from
this ﬁle, and we do not need to account for concurrent
interactions between threads in the same program. We
know of no fundamental barriers, however, to extending
our approach to multi-threaded and network-facing pro-
grams.
Our implementation associates a symbolic input vari-
able with each byte of the input ﬁle. As a result, Smart-
Fuzz cannot generate test cases with more bytes than are
present in the initial seed ﬁle.
Multiple Cooperating Analyses. Our tool is imple-
mented as a series of independent cooperating analyses
in the Valgrind instrumentation framework. Each analy-
sis adds its own instrumentation to a basic block during
translation and exports an interface to the other analyses.
For example, the instrumentation for tracking taint ﬂow,
which determines the IR instructions to treat as symbolic,
exports an interface that allows querying whether a spe-
ciﬁc memory location or temporary variable is symbolic.
A second analysis then uses this interface to determine
whether or not to output STP constraints for a given IR
instruction.
The main advantage of this approach is that it makes
it easy to add new features by adding a new analysis,
then modifying our core constraint generation instrumen-
tation. Also, this decomposition enabled us to extract our
taint-tracking code and use it in a different project with
minimal modiﬁcations, and we were able to implement
the binary type inference analysis described in Section 5,
replacing a different earlier version, without changing
our other analyses.
Optimize in Postprocessing. Another design choice
was to output constraints that are as “close” as possible to
the intermediate representation, performing only limited
optimizations on the ﬂy. For example, we implement the
“related constraint elimination,” as introduced by tools
6
such as EXE and SAGE [8, 14], as a post-processing
step on constraints created by our tool. We then leave it
up to the solver to perform common subexpression elim-
ination, constant propagation, and other optimizations.
The main beneﬁt of this choice is that it simpliﬁes our
constraint generation. One drawback of this choice is
that current solvers, including STP, are not yet capable
of “remembering” optimizations from one query to the
next, leading to redundant work on the part of the solver.
The main drawback of this choice, however, is that while
after optimization each individual query is small, the to-
tal symbolic trace containing all queries for a program
can be several gigabytes. When running our tool on a
32-bit host machine, this can cause problems with maxi-
mum ﬁle size for a single ﬁle or maximum memory size
in a single process.
5 Techniques for Finding Integer Bugs
We now describe the techniques we use for ﬁnding inte-
ger bugs.
Overﬂow/Underﬂow. For each arithmetic expression
that could potentially overﬂow or underﬂow, we emit a
constraint that is satisﬁed if the overﬂow or underﬂow
occurs.
If our solver can satisfy these constraints, the
resulting input values will likely cause an underﬂow or
overﬂow, potentially leading to unexpected behavior.
Width Conversions. For each conversion between inte-
ger types, we check whether it is possible for the source
value to be outside the range of the target value by adding
a constraint that’s satisﬁed when this is the case and then
applying the constraint solver. For conversions that may
sign-extend, we use the constraint solver to search for a
test case where the high bit of the source value is non-
zero.
Signed/Unsigned Conversions. Our basic approach is
to try to reconstruct, from the x86 instructions executed,
signed/unsigned type information about all integral val-
ues. This information is present in the source code but
not in the binary, so we describe an algorithm to infer
this information automatically.
types for
“Top,”
“Signed,” “Unsigned,” or “Bottom.” Here, “Top” means
the value has not been observed in the context of a signed
or unsigned integer; “Signed” means that the value has
been used as a signed integer; “Unsigned” means the
value has been used as an unsigned integer; and “Bot-
tom” means that the value has been used inconsistently
as both a signed and unsigned integer. These types form
a four-point lattice. Our goal is to ﬁnd symbolic program
values that have type “Bottom.” These values are can-
didates for signed/unsigned conversion errors. We then
attempt to synthesize an input that forces these values to
be negative.
integer values:
Consider
four
We associate every instance of every temporary vari-
7
int main(int argc, char** argv) {
char * p = malloc(800);
char * q = malloc(800);
int n;
n = atol(argv[1]);
if (n > 800)
return;
memcpy(p, q, n);
return 0;
}
Figure 3: A simple test case for dynamic type infer-
ence and query generation. The signed comparison n >
800 and unsigned size t argument to memcpy assign the
type “Bottom” to the value associated with n. When we
solve for an input that makes n negative, we obtain a test
case that reveals the error.
able in the Valgrind intermediate representation with a
type. Every variable in the program starts with type Top.
During execution we add type constraints to the type of
each value. For x86 binaries, the sources of type con-
straints are signed and unsigned comparison operators:
e.g., a signed comparison between two values causes
both values to receive the “Signed” type constraint. We
also add unsigned type constraints to values used as the
length argument of memcpy function, which we can de-
tect because we know the calling convention for x86 and
we have debugging symbols for glibc. While the x86 in-
struction set has additional operations, such as IMUL that
reveal type information about their operands, we do not
consider these; this means only that we may incorrectly
under-constrain the types of some values.
Any value that has received both a signed and un-
signed type constraint receives the type Bottom. After
adding a type constraint, we check to see if the type of
a value has moved to Bottom. If so, we attempt to solve
for an input which makes the value negative. We do this
because negative values behave differently in signed and
unsigned comparisons, and so they are likely to exhibit
an error if one exists. All of this information is present in
the trace without requiring access to the original program
source code.
We discovered, however,
that gcc 4.1.2 inlines
some calls to memcpy by transforming them to rep
movsb instructions, even when the -O ﬂag is not present.
Furthermore,
the Valgrind IR generated for the rep
movsb instruction compares a decrementing counter
variable to zero, instead of counting up and executing an
unsigned comparison to the loop bound. As a result, on
gcc 4.1.2 a call to memcpy does not cause its length argu-
ment to be marked as unsigned. To deal with this prob-
lem, we implemented a simple heuristic to detect the IR
generated for rep movsb and emit the appropriate con-
straint. We veriﬁed that this heuristic works on a small
test case similar to Figure 3, generating a test input that
caused a segmentation fault.
A key problem is storing all of the information re-
quired to carry out type inference without exhausting
available memory. Because a trace may have several mil-
lion instructions, memory usage is key to scaling type
inference to long traces. Furthermore, our algorithm re-
quires us to keep track of the types of all values in the
program, unlike constraint generation, which need con-
cern itself only with tainted values. An earlier version
of our analysis created a special “type variable” for each
value, then maintained a map from IR locations to type
variables. Each type variable then mapped to a type.
We found that in addition to being hard to maintain, this
analysis often led to a number of live type variables that
scaled linearly with the number of executed IR instruc-
tions. The result was that our analysis ran out of memory
when attempting to play media ﬁles in the mplayer me-
dia player.
To solve this problem, we developed a garbage-
collected data structure for tracking type information.
To reduce memory consumption, we use a union-ﬁnd
data structure to partition integer values into equivalence
classes where all values in an equivalence class are re-
quired to have the same type. We maintain one type for
each union-ﬁnd equivalence class; in our implementation
type information is associated with the representative
node for that equivalence class. Assignments force the
source and target values to have the same types, which is
implemented by merging their equivalence classes. Up-
dating the type for a value can be done by updating its
representative node’s type, with no need to explicitly up-
date the types of all other variables in the equivalence
class.
It turns out that this data structure is acyclic, due to the
fact that VEX IR is in SSA form. Therefore, we use ref-
erence counting to garbage collect these nodes. In addi-
tion, we beneﬁt from an additional property of the VEX
IR: all values are either stored in memory, in registers, or
in a temporary variable, and the lifetime of each tempo-
rary variable is implicitly limited to that of a single basic
block. Therefore, we maintain a list of temporaries that
are live in the current basic block; when we leave the
basic block, the type information associated with all of
those live temporaries can be deallocated. Consequently,
the amount of memory needed for type inference at any
point is proportional to the number of tainted (symbolic)
variables that are live at that point—which is a signiﬁcant
improvement over the naive approach to type inference.
The full version of this paper contains a more detailed
speciﬁcation of these algorithms3.
3http://www.cs.berkeley.edu/~dmolnar/
usenix09-full.pdf
6 Triage and Reporting at Scale
Both SmartFuzz and zzuf can produce hundreds to thou-