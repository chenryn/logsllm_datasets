in the AS PATH; this is known as BGP loop detection. So,
all networks included in the poisoned update’s AS PATH -
the poisoned ASes - will ﬁlter it. Poisons can be used for
inbound trafﬁc engineering purposes [42], [41], [20] but we
employ them in Section IV to mimic route leaks transiting the
poisoned AS.
Fig. 2: BGP poisoning. AS 1 originates a route with AS 2
prepended to path (left); AS 2 ﬁlters the update (center), but
AS 3 propagates (right).
III. THE PEERLOCK SYSTEM
The challenge of leak ﬁltering stems from the topological
scope asymmetry between BGP routes and the perspective
of individual AS operators who evaluate them. Routes span
the topology (global scope); operators only know their own
relationships with adjoining ASes (local scope). Filtering
systems built on the RPKI [13] and IRRs [14] partially address
this asymmetry by applying additional
information to the
route evaluation process. However, these existing solutions
have limitations that have hamstrung their deployment. Most
critically, their effectiveness depends on the cooperation of
many unincentivized remote ASes as detailed in Section II-C.
A. Peerlock
Peerlock, ﬁrst detailed by NTT in 2016 [44], [18], is a
leak ﬁltering scheme based on out-of-band information ex-
change between BGP neighbors. Peerlock requires a single AS
(the protected AS) to designate authorized upstreams to their
BGP neighbor (the protector AS). This communication dis-
tributes AS relationship information between peers to decrease
route/ﬁlterer scope asymmetry. The protector AS then rejects
any BGP update whose AS PATH contains the protected AS
unless received 1) directly from the protected AS, or 2) from
an authorized upstream, with the protected AS immediately
following the authorized upstream in the AS PATH. We say
that the protector AS is Peerlocking for the protected AS.
See Fig. 3 for a depiction of the system. In this paper, we
will often refer to a single instance of Peerlock - that is, one
protector/protected pairing - as a Peerlock rule.
Here we describe Peerlock’s beneﬁts and drawbacks
relative to previous leak prevention systems, each of which
is described in detail in Section II-C. These comparisons are
summarized in Table 1.
RPKI/ROV Comparison: Peerlock provides broader leak
type coverage than RPKI/ROV ﬁltering without a trust
infrastructure requirement. However, Peerlock only applies to
leaks that violate conﬁgured topological rules (Types 1-4), so
Fig. 3: Simple Peerlock deployment. Protector AS ﬁlters
updates containing the peer Protected AS from unauthorized
propagators.
Type 5 (re-origination) and Type 6 (internal route) leaks fall
outside its scope. ROAs tie preﬁxes to valid originating ASes,
so ROV ﬁltering can prevent Type 5 leaks. Additionally,
ROAs can be conﬁgured with a max preﬁx length to prevent
some internal route leaks and hijacks, although recent work
has identiﬁed vulnerabilities in this feature [9]. Because
Peerlock and RPKI/ROV ﬁltering cover different leak types,
Peerlock is complementary to ROV ﬁltering rather than a
replacement.
IRR Comparison: IRRs are policy object databases capable
of storing participating networks’ routing intentions with great
detail and ﬁne granularity (preﬁx level). Any AS wishing to
enforce these intentions can automatically derive ﬁlters from
stored objects using software tools, whereas Peerlock rule
conﬁguration requires setup between each protector/protected
AS pair. Unfortunately, IRRs suffer from incentive misalign-
ment, governance, and rule dependency issues as described in
Section II-C. Peerlock rules are self-contained, and changes do
not affect other rules. This encapsulation avoids the cascading
dependency problem exhibited by IRRs, where one AS’s
policy changes may render many other AS’s entries obsolete.
importantly, Peerlock allows the protector AS to
stop leaks that transit the protected network regardless of
the actions of ASes along potential leak paths; the value of
IRR-based ﬁlters depends on many remote networks to store
accurate policy entries. Peerlock’s relatively light cooperation
requirement only requires
that ASes with an existing
relationship communicate information between themselves.
This dynamic enables the best resourced, positioned, and
incentivized networks (i.e., those serving the most customers)
to block route leak propagation regardless of other remote
networks’ actions.
Most
Max Preﬁx Comparison: BGP’s max preﬁx feature enables
networks to limit the number of preﬁxes they will accept
4
System
Coverage
RPKI/ROV
IRR Filtering
Type 5 internal leak,
Type 6 re-origination
Potentially all leak types;
depends on stored policy
object speciﬁcity.
Max Preﬁx
All leak types
Requirements
RPKI trust infrastructure,
local ROA registration &
remote ROV checks
Correct, fresh policy objects &
derived ﬁlters along potential leak
path
Filter with meaningful max preﬁx
limit somewhere on potential leak
path
Notes
Type 5 coverage depends on optional ROA max length
Quality issues, misaligned incentives
Only effective when many preﬁxes are leaked
Table 1: Common leak ﬁltering systems.
over each neighboring AS connection. Mass route leaks
- those involving many preﬁxes - are ﬁltered once preﬁx
volume over an inter-AS link exceeds the preset limit. Max
preﬁx ﬁltering affords broad protection across leak types, but
cannot stop leaks involving few (potentially critical/highly
trafﬁcked) preﬁxes. On the other hand, Peerlock cannot stop
leaks that do not violate established topological constraints
regardless of volume, but is effective against more selective
leaks unprotected by max preﬁx limits.
Other Considerations: Currently, each Peerlock rule must
be manually conﬁgured, although at least one method has
been proposed to automate Peerlock [16]. Peerlock also
lacks a standard to describe how out-of-band information
is exchanged between participants. Without a detailed and
secure protocol for rule conﬁguration, Peerlock is vulnerable
to exploitation; fraudulent rules affect route export, and could
be used to engineer trafﬁc ﬂows. Furthermore, operators must
deﬁne their own ad-hoc protocols for communicating rules
that may not guarantee authenticity and/or conﬁdentiality.
Virtually all leak solutions discussed here, including IRR,
RPKI/ROV, and AS PATH ﬁltering, are recommended by the
best practices group Mutually Agreed Norms for Routing
Security (MANRS) [5].
B. Peerlock-lite
Peerlock-lite [18] (or Tier 1 ﬁlter, "big networks" ﬁlter)
is a related technique, based on the assumption that transit
providers should never receive a route whose AS PATH in-
cludes a Tier 1 AS from a customer. This is a valid assumption
under the valley-free routing model [7], because such an
update implies the customer is providing transit for the Tier 1
AS; otherwise, the customer would not export (leak) the route
to another provider. However, Tier 1 ASes have no providers
by deﬁnition. This logic can be extended heuristically to any
other large non-Tier 1 networks that the provider does not
expect the customer to export.
This simple logic yields an equally simple ﬁltering rule
for transit providers - reject any updates from customers that
contain a Tier 1/large transit ASN. See Fig. 4 for a depiction of
this ﬁltering technique. Peerlock-lite ﬁlters are limited to Tier
1/large transit provider leaks, but they require no out-of-band
information to conﬁgure. Moreover, Tier 1 ASes’ position at
the Internet’s core results in their frequent presence on AS
PATHs of highly disruptive leaks, e.g. the Verizon/Cloudﬂare
leak [23] and the Enzu/AWS/Spotify leak [21].
Fig. 4: Example Peerlock-lite deployment. Provider AS ﬁlters
updates from its customer that include a Tier 1 AS.
IV. MEASURING PEERLOCK DEPLOYMENT
Our initial experiments seek to establish the current state of
Peerlock deployment on the control plane. As discussed in the
previous section, every Peerlock rule is conﬁgured between a
pair of networks: the protector AS and the protected AS. Each
of the experiments in this section works to identify some or
all Peerlock/Peerlock-lite protectors for a targeted AS.
A. Measurement Methodology
Experimental Design: Each set of measurement experiments
in this section is designed to discover Peerlock rules for a
set of potential protected ASes, called target ASes. For each
target AS, we advertise a /24 preﬁx from many points-of-
presence (PoPs) on the control plane. This is the control
advertisement. It is a normal /24 origination in every way,
except that our university AS - which we know not to be
protected by any Peerlock rule - is poisoned (i.e., prepended
to the advertisement’s AS PATH - see Section II-D). We then
listen at varied collection sites, called collectors, for BGP
updates triggered by our advertisement. The AS PATH for each
such update that arrives at collectors lists in encounter order
the ASes that received and re-issued the update as described
in Section II-A.
5
Taken together, the gathered AS PATHs form a directed
acyclic graph (DAG) that describes the control advertisement’s
propagation through the control plane; each AS appearing
on at least one AS PATH forms a node in the DAG, and
AS ordering within paths allows us to form directed edges
between nodes. BGP loop detection prevents cycles as noted
in Section II-D. We call this graph the control DAG. Note that
all of the ASes appearing in the control DAG propagated (and
thus did not ﬁlter) control updates that include a poisoned AS.
We then wait 30 minutes for update propagation before
issuing an explicit withdrawal for the /24 preﬁx. This timing
is built conservatively from empirical measurements of propa-
gation times through the control plane (see update propagation
experiments in appendix). After another waiting period to
ensure the withdrawal has completely propagated, we issue a
leak advertisement for the same /24 preﬁx. This advertisement
matches the control advertisement in every way, except that
the target AS is poisoned. This leak advertisement structure is
designed to mimic a leak for the purposes of Peerlock while
avoiding other common ﬁltering systems. The target AS’s
presence on update paths triggers ﬁltering for any Peerlock
protector ASes.
Finally, we gather all BGP updates for the leak advertise-
ment from our collectors. The ASes that appear on AS PATHs
in any of these updates are added to a set called the leak set.
Since they propagated poisoned updates, we know these ASes
did not ﬁlter the "leak". With the control DAG and leak set
together, we can reason about which ASes are Peerlocking for
the target AS using two techniques: 1) clique inference and 2)
DAG inference.
Fig. 5: Measurement experiment depiction. Inferences are
made about Peerlock deployment based on differences be-
tween normal updates (left) vs. poisoned updates (right) ar-
riving at collectors.
For detecting Tier 1 protector ASes, we use clique inference.
This simple technique relies on the fact that Tier 1 ASes
form a peering clique by deﬁnition. According to the valley-
free routing model [7], ASes share all updates received from
customers with their peers; this maximizes the trafﬁc the AS
transits for its customers (and thus the AS operator’s compen-
sation). Further, ASes should not share a peer’s updates with
another peer, as this is a Type 2 route leak [45]. So, in general,
if a Tier 1 AS is observed propagating an update, all Tier
1s should receive the update via their peering relationships.
Because we observe at least one Tier 1 propagating control
and leak updates across all experiments, we deﬁne a simple
rule for inferring Tier 1 protector ASes: any Tier 1 AS that
appears in the control DAG but not the leak set is Peerlocking
for the target AS.
Inferring other protector ASes requires a more general tech-
nique. Outside the structural guarantees provided by the Tier
1 clique, there is signiﬁcantly more uncertainty about which
networks are ﬁltering leak updates. Speciﬁcally, it is difﬁcult
to distinguish an AS ﬁltering updates from an AS not receiving
updates at all due to ﬁltering by other upstream/downstream
networks. This challenge leads us to make three separate
inferences for these ASes for each leak target.
First and simplest is the max inference set, deﬁned as all
control DAG ASes minus the leak set. This set includes all
ASes who may have ﬁltered leak updates, but also ASes who
did not receive the leak update because it was ﬁltered by an
intermediate AS. Secondly, we build a min inference set. This
set is built by deleting all leak set ASes from the control
DAG, and collecting the root of every weakly connected
component that remains. This isolates the ASes that ﬁltered
leak updates from ASes in their "shadow" who did not receive
the updates. The min inference set contains those ASes who
likely ﬁltered leak updates based on routes we observed. Note
that the min/max inference techniques closely align with those
employed in the long path ﬁltering experiments in Smith et
al.’s study on BGP poisoning as a re-routing primitive [41].
Our last inference set is the likely inference. Because ASes
only export
their best path to our /24 preﬁx, we cannot
observe every edge that should exist in the control DAG (i.e.,
every potential propagation path for updates). So, this set’s
is built like the min inference set, except that we augment
the control DAG with edges from CAIDA’s provider-peer
observed customer cone inference [51]. That is, we add edges
to the control DAG where CAIDA’s data indicates there are
links between ASes that we did not observe due to policy
decisions. This forms a superset of the min inference set and
a subset of the max inference set that contains the most likely
ﬁlterers. This is a novel technique not used to our knowledge
in any prior work on this topic.
These three inference sets are formed for each target
from differences in control and leak update propagation. In
addition to these sets, we also build a min/max/likely poison
ﬁltering set by following the same steps listed above, but
with a unpoisoned advertisement’s updates compared against
the control advertisement’s updates. These sets are built to
explore the prevalence of general poison ﬁltering as in Smith
et al. [41].
Framework Details: The
control-plane measurement
framework for these experiments consists of 1) 13 PoPs to
issue BGP advertisements and 2) 54 BGP collectors to listen
for propagation. We employ the PEERING testbed [36] for
the ﬁrst requirement. PEERING allows us to advertise three
assigned /24 preﬁxes from edge routers at
thirteen PoPs
worldwide. For collecting BGP updates, we used CAIDA’s
BGPStream [51] tool. This tool draws updates from 54
globally distributed collectors, including 30 RouteViews [32]
6
and 24 RIPE RIS [29] collectors. While most of these
collectors are positioned in North America and Europe, every
populated continent is represented by at least one collector.
Measurement Limitations: While our framework allows us
to effectively probe the control plane for evidence of Peer-
lock and related techniques, a number of limitations prevent
complete certainty regarding Peerlock ﬁlter placement. The
most
important of these obstacles are imperfect collector
coverage, topological instability, and the presence of other
ﬁltering systems. Here we discuss each of these factors in
turn.
BGP policies prohibit us from viewing the entirety of the
topology with our framework;
there are few collectors in
stub networks, and stub/remote ASes do not export received
updates back "up" through provider networks. This means our
observation window - the ASes on update paths at collectors
- is biased toward transit networks in the Internet’s core
as in [33]. Fortunately, this is the most important/inﬂuential
region to monitor, as these network’s policies have the widest
impact on the control plane. Altogether, we observed 610 ASes
during our experiments, including 181/605 large ISPs and all
19 Tier 1 networks. Most observed ASes (332) were present
in the observation window during all experiments conducted
from August 2019-May 2020. Note that while we can only
infer protector ASes from our observation window, we can
poison any AS. So, our window does not limit our inference
regarding which ASes are protected.
To account for instability in our observation window, we
limit our ﬁltering inferences to those ASes observed in control