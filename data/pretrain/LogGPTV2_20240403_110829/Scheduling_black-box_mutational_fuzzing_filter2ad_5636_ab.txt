current project globally ﬁxes the mutation ratio at 0.0004,
the default value used in zzuf. Accordingly, we suppress the
third parameter of a fuzz conﬁguration in this paper, eﬀec-
tively equating program-seed pairs with fuzz conﬁgurations.
For further discussion related to the mutation ratio, see §6.6.
2.2 Problem Statement
Given a list of K fuzz conﬁgurations {(p1, s1),··· , (pK , sK)}
and a time budget T , the Fuzz Conﬁguration Scheduling
problem seeks to maximize the number of unique bugs dis-
covered in a fuzz campaign that runs for a duration of length
T . A fuzz campaign is divided into epochs, starting with
epoch 1. We consider two epoch types: ﬁxed-run and ﬁxed-
time. In a ﬁxed-run campaign, each epoch corresponds to
a constant number of fuzz runs; since the time required for
individual fuzz runs may vary, ﬁxed-run epochs may take
variable amounts of time. On the other hand, in a ﬁxed-time
campaign, each epoch corresponds to a constant amount of
time. Thus, the number of fuzz runs completed may vary
across ﬁxed-time epochs.
An online algorithm A for the Fuzz Conﬁguration Schedul-
ing problem operates before each epoch starts. When the
campaign starts, A receives the number K. Suppose the
campaign has completed (cid:96) epochs so far. Before epoch ((cid:96) + 1)
begins, A should select a number i ∈ [1, K] based on the
information it has received from the campaign. Then the
entire epoch ((cid:96) + 1) is devoted to fuzzing (pi, si ). When
the epoch ends, A receives a sequence of IDs representing
the outcomes of the fuzz runs completed during the epoch.
If an outcome is a crash, then the returned ID is the bug
ID computed by the bug triage process, which we assume
is non-zero. Otherwise, the outcome is a proper termina-
tion, and the returned ID is 0. Also, any ID that has never
been encountered by the campaign prior to epoch ((cid:96) + 1)
is marked as new. Notice that a new ID can signify either
the ﬁrst proper termination in the campaign or a new bug
discovered during epoch ((cid:96) + 1). Besides the list of IDs, A
also receives statistical information about the epoch. In a
ﬁxed-run campaign, it receives the time spent in the epoch;
in a ﬁxed-time campaign, it receives the number of fuzz runs
that ended inside the epoch.
Algorithmic Considerations. We now turn to a few techni-
cal issues that we withheld from the above problem statement.
First, we allow A to be either deterministic or randomized.
This admits the use of various existing MAB algorithms,
many of which are indeed randomized.
Second, notice that A receives only the number of conﬁgu-
rations K but not the actual conﬁgurations. This formulation
is to prevent A from analyzing the content of any pi’s or si’s.
Similarly, we prevent A from analyzing bugs by sending it
only the bug IDs but not any concrete representation.
Third, A also does not receive the time budget T . This
forces A to make its decisions without knowing how much
time is left. Therefore, A has to attempt to discover new bugs
as early as possible. While this rules out any algorithm that
adjusts its degree of exploration based on the time left, we
argue that this not a severe restriction from the perspective
of algorithm design. For example, one of the algorithms we
use is the EXP3.S.1 algorithm [2]. It copes with the unknown
time horizon by partitioning time into exponentially longer
periods and picking new parameters at the beginning of each
period, which has a known length.
Fourth, our analysis assumes that the K fuzz conﬁgura-
tions are chosen such that they yield disjoint sets of bugs.
This assumption is needed so that we can consider the bug
arrival process of fuzzing each conﬁguration independently.
While this assumption may be valid when every conﬁguration
involves a diﬀerent program, as in one of our two datasets,
satisfying it when one program can appear in multiple conﬁg-
urations is non-trivial. In practice, it is achieved by selecting
seeds that exercise diﬀerent code regions. For example, in
our other data set, we use seeds of various ﬁle formats to
fuzz the diﬀerent ﬁle parsers in a media player.
Finally, at present we do not account for the time spent
in bug triage, though this process requires considerable time.
In practice, triaging a crash takes approximately the same
amount of time as the fuzz run that initially found the crash.
Therefore, bug triage can potentially account for over half of
the time spent in an epoch if crashes are extremely frequent.
We plan to incorporate this consideration into our project at
a future time.
3 Multi-Armed Bandits
As explained in §1, the Fuzz Conﬁguration Scheduling prob-
lem is an instance of the classic Multi-Armed Bandit (MAB)
problem. This has already been observed by previous re-
searchers. For example, the CERT Basic Fuzzing Framework
(BFF) [14], which supports fuzzing a single program with
a collection of seeds and a set of mutation ratios, uses an
MAB algorithm to select among the seed-ratio pairs during
a fuzz campaign. However, we must stress that recognizing
the MAB nature of our problem is merely a ﬁrst step. In
particular, we should not expect an MAB algorithm with
provably “good” performance, such as one from the UCB [3]
or the EXP3 [2] families, to yield good results in our problem
setting. There are at least two reasons for this.
First, although many of these algorithms are proven to
have optimal regret in various forms, the most common
form of regret does not actually give good guarantees in our
problem setting. In particular, this form of regret measures
the diﬀerence between the expected reward of an algorithm
and the reward obtained by consistently fuzzing the single
best conﬁguration that yields the greatest number of unique
bugs. However, we are interested in evaluating performance
relative to the total number of unique bugs from all K
conﬁgurations, which may be much greater than the number
from one ﬁxed conﬁguration. Thus, the low-regret guarantee
of many MAB algorithms is in fact measuring against a
target that is likely to be much lower than what we desire.
In other words, given our problem setting, these algorithms
are not guaranteed to be competitive at all!
(cid:112)2K(cid:96) ln(K(cid:96)), where S is
Second, while there exist algorithms with provably low
regret in a form suited to our problem setting, the actual re-
gret bounds of these algorithms often do not give meaningful
values in practice. For example, one of the MAB algorithms
we use is the EXP3.S.1 algorithm [2], proven to have an
expected worst-case regret of S+2e√
2−1
a certain hardness measure of the problem instance as de-
ﬁned in [2, §8] and (cid:96) is the number of epochs in our problem
setting. Even assuming the easiest case where S equals to 1
and picking K to be a modest value of 10, the value of this
bound when (cid:96) = 4 is already slightly above 266. However,
as we see in §6, the number of bugs we found in our two
datasets are 200 and 223 respectively. What this means is
that this regret bound is very likely to dwarf the number of
bugs that can be found in real-world software after a very
small number of epochs. In other words, even though we have
the right kind of guarantee from EXP3.S.1, the guarantee
quickly becomes meaningless in practical terms.
Having said the above, we remark that this simply means
such optimal regret guarantees may not be useful in ensuring
good results. As we will see in §6, EXP3.S.1 can still obtain
reasonably good results in the right setting.
4 Algorithms for the FCS Problem
Our goal in this section is to investigate how to design online
algorithms for the Fuzz Conﬁguration Scheduling problem.
We largely focus on developing the design space (§4.4), mak-
ing heavy use of the mathematical foundation we lay out
in §4.1 and §4.3. Additionally, we present two impossibility
results in §4.2, one of which requires a precise condition
that greatly informs our algorithm design eﬀort. We also
present two oﬄine algorithms for our problem. While such
algorithms may not be applicable in practice, a unique aspect
of our project allows us to use them as benchmarks which
we measure our online algorithms against. We explain this
along with the oﬄine algorithms in §4.5.
4.1 Fuzzing as a Weighted CCP
Let us start by mathematically modeling the process of
repeatedly fuzzing a conﬁguration. As we explained in §2,
the output of this process is a stream of crashes intermixed
with proper terminations, which is then transformed into
a stream of IDs by a bug triage process. Since we want to
maximize the number of unique bugs found, we are naturally
interested in when a new bug arrives in this process. This
insight quickly leads us to the Coupon Collector’s Problem
(CCP), a classical arrival process in probability theory.
The CCP concerns a consumer who obtains one coupon
with each purchase of a box of breakfast cereal. Suppose
there are M diﬀerent coupon types in circulation. One basic
question about the CCP is: what is the expected number of
purchases required before the consumer amasses k (≤ M )
unique coupons? In its most elementary formulation, each
coupon is chosen uniformly at random among the M coupon
types. In this setting, many questions related to the CCP—
including the one above—are relatively easy to answer.
Viewing Fuzzing as WCCP with Unknown Weights. Un-
fortunately, our problem setting actually demands a weighted
variant of the CCP which we dub the WCCP. Intuitively, this
is because the probabilities of the diﬀerent outcomes from
a fuzz run are not necessarily (and unlikely to be) uniform.
This observation has also been made by Arcuri et al. [1].
Let (M − 1) be the actual number of unique bugs discov-
erable by fuzzing a certain conﬁguration. Then including
proper termination of a fuzz run as an outcome gives us
exactly M distinct outcome types. We thus relate the pro-
cess of repeatedly fuzzing a conﬁguration to the WCCP by
viewing fuzz run outcomes as coupons and their associated
IDs as coupon types.
However, unlike usual formulations of the WCCP where the
distribution of outcomes across type is given, in our problem
setting this distribution is unknown a priori. In particular,
there is no way to know the true value of M for a conﬁguration
without exhaustively fuzzing all possible mutations. As such,
we utilize statistical estimations of these distributions rather
than the ground-truth in our algorithm design. An important
question to consider is whether accurate estimations are
feasible.
We now explain why we prefer the sets of bugs from diﬀer-
ent conﬁgurations used in a campaign to be disjoint. Observe
that our model of a campaign is a combination of multiple
independent WCCP processes. If a bug that is new to one
process has already been discovered in another, then this
bug cannot contribute to the total number of unique bugs.
This means that overlap in the sets of bugs diminishes the
ﬁdelity of our model, so that any algorithm relying on its
predictions may suﬀer in performance.
WCCP Notation. Before we go on, let us set up some ad-
ditional notation related to the WCCP. In an eﬀort to avoid
excessive indices, our notation implicitly assumes a ﬁxed
conﬁguration (pi, si) that is made apparent by context. For
example, M , the number of possible outcomes when fuzzing a
given conﬁguration as deﬁned above, follows this convention.
(i) Consider the ﬁxed sequence σ of outcomes we obtain
in the course of fuzzing (pi, si) during a campaign. We label
an outcome as type k if it belongs to the kth distinct type of
outcome in σ. Let Pk denote the probability of encountering
a type-k outcome in σ, i.e.,
Pk =
|{x ∈ H(si) : x triggers an outcome of type k}|
. (1)
|H(si)|
(ii) Although both the number and frequency of outcome
types obtainable by fuzzing (pi, si ) are unknown a priori,
during a campaign we do have empirical observations for
these quantities up to any point in σ. Let ˆM ((cid:96)) be the number
of distinct outcomes observed from epoch 1 through epoch
(cid:96). Let nk((cid:96)) be the number of inputs triggering outcomes
of type k observed throughout these (cid:96) epochs. Notice that
over the course of a campaign, the sequence σ is segmented
into subsequences, each of which corresponds to an epoch
in which (pi, si ) is chosen. Thus, the values of ˆM (·) and
nk(·) will not change if (pi, si) is not chosen for the current
epoch. With this notation, we can also express the empirical
probability of detecting a type-k outcome following epoch (cid:96)
as
ˆPk((cid:96)) =
(cid:80) ˆM ((cid:96))
nk((cid:96))
k(cid:48)=1 nk(cid:48) ((cid:96))
.
Impossibility Results
4.2
No Free Lunch. The absence of any assumption on the dis-
tribution of outcome types in the WCCP quickly leads us to
our ﬁrst impossibility result. In particular, no algorithm can
consistently outperform other algorithms for the FCS prob-
lem. This follows from a well-known impossibility result in
optimization theory, namely the “No Free Lunch” theorem by
Wolpert and Macready [22]. Quoting Wolpert and Macready,
their theorem implies that “any two optimization algorithms
are equivalent when their performance is averaged across all
possible problems.” In our problem setting, maximizing the
number of bugs found in epoch ((cid:96) + 1) amounts to, for each
conﬁguration, estimating its P ˆM ((cid:96))+1 in equation (1) using
only past observations from that conﬁguration. Intuitively,
by averaging across all possible outcome type distributions,
any estimation will be incorrect suﬃciently often and thus
lead to suboptimal behavior that cancels any advantage of
one algorithm over another.
While we may consider this result to be easy to obtain
once we have properly set up our problem using §2 and §4.1,
we consider it to be an important intellectual contribution for
the pragmatic practitioners who remain conﬁdent that they
can design algorithms that outperform others. In particular,
the statement of the No Free Lunch theorem itself reveals
precisely how we can circumvent its conclusion—our estima-
tion procedure must assume the outcome type distributions
have particular characteristics. Our motto is thus “there is
no free lunch—please bring your own prior!”
Tight K-Competitiveness. Our second impossibility result
shows that there are problem instances in which the time
spent by any deterministic online algorithm to ﬁnd a given
number of unique bugs in a ﬁxed-time campaign is at least
K times larger than the time spent by an optimal oﬄine
algorithm. Using the terminology of competitive analysis,
this shows that the competitive ratio of any deterministic
online algorithm for this problem is at least K.
To show this, we ﬁx a deterministic algorithm A and
construct a contrived problem instance in which there is only
one bug among all the conﬁgurations in a campaign. Since A
is deterministic, there exists a unique pair (p∗
i ) that gets
chosen last. In other words, the other (K − 1) pairs have all
been fuzzed for at least one epoch when (p∗
i , s∗
i ) is fuzzed for
the ﬁrst time. If the lone bug is only triggered by fuzzing
i , s∗
(p∗
i ), then A will have to fuzz for at least K epochs to
ﬁnd it.
i , s∗
For an optimal oﬄine algorithm, handling this contrived
scenario is trivial. Since it is oﬄine, it has full knowledge