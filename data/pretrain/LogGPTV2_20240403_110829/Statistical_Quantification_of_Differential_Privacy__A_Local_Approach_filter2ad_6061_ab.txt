The relation between speciﬁc databases and privacy has
been previously studied in the context of sensitivity [23].
Given a function F that operates on databases x, one can
achieve DP by adding noise proportional to the global sen-
sitivity (cid:6)F of F to its output F (x). [23] observe that the
local sensitivity (cid:6)F (x) of F around a ﬁxed database x can be
considerably smaller than (cid:6)F , allowing for, in principle, less
noise and higher accuracy. The local sensitivity of F is then
leveraged to arrive at the notion of “smooth sensitivity”, which
admits lower levels of noise than (cid:6)F and can be analytically
determined for some statistically relevant functions.
In the presence of only black box access to the target
function F , [23] avoid computing the sensitivity of F directly
and instead resort to assessing the sensitivity of an aggregation
function operating on outputs of F . In contrast, [24] propose
an approach that provides direct sensitivity estimates of the
target function F that can be used in the privatization process.
As a sampling-based black box method, the approach put
forward in [24] shares some similarities with our methodology,
but also comes with marked differences. The methods in [24]
assist directly in the design of algorithms that conform to
a relaxed version of DP, namely random differential privacy
[25]. We, on the other hand, develop statistical methods
that assess “pure” DP and, given a randomized algorithm,
determine the privacy level x attached to a database x in
retrospect.
This work: Statistically, our approach is based on novel
estimators ˆx,x(cid:2) for the data-speciﬁc privacy violation x,x(cid:2). In
view of the identities (4) and (5), such estimates are natural
building blocks for the assessment of the global privacy pa-
rameter  or its data-centric version x. Contrary to the related
literature, our estimators do not maximize an empirical version
of the loss Lx,x(cid:2), but approximate the supremum x,x(cid:2) directly,
thus avoiding the pitfalls of event selection (see previous part).
Mathematically, these estimates rest on a “local” version of
the privacy loss discussed in Section III. Besides estimators,
we present new tools of statistical inference: In Section IV
we devise the MPL (Maximum Privacy Loss) algorithm,
which generates one-sided conﬁdence intervals [LB,∞) for
the privacy parameters  and x respectively. In this situation,
LB is a statistical lower bound (i.e., it holds with a high
degree of certainty) and approximates the true parameter with
increasing sample size. In particular, if MPL is applied to the
quantiﬁcation of  and outputs LB, the user can be conﬁdent
that algorithm A is at best LB-differentially private. In Section
V we conﬁrm these ﬁndings via experiments.
Main contributions: We give a brief summary of our main
contributions:
• A fully statistical black box procedure for the quantiﬁca-
tion of DP (without parametric assumptions).
• A ﬂexible approach based on data-speciﬁc privacy viola-
tions x,x(cid:2) as building blocks.
• New estimators ˆx,x(cid:2) for the data-speciﬁc privacy viola-
tion that circumvent the problem of event selection and
are proved to converge at a fast rate.
• The MPL algorithm that outputs a conﬁdence interval for
 (or x), which demonstrably includes the parameter of
interest with approximate level of conﬁdence.
• A practical evaluation and validation of our methods.
II. STATISTICAL PRELIMINARIES
In this section, we review the statistical concepts of conﬁ-
dence intervals and kernel density estimation, which serve as
technical background for the remainder of this paper. Readers
who are only interested in discrete algorithms can omit Section
II-B.
A. Conﬁdence Intervals
A conﬁdence interval is a statistical method to localize a
parameter of a probability distribution with a prescribed level
of certainty. More concretely, consider a sample of n obser-
vations X1, .., Xn (random variables), following an unknown
distribution P . If a user is interested in a parameter θ = θ(P )
derived from P (e.g. the expectation θ := EP X1), the sample
of observations can be used to approximately locate θ in an
interval ˆI(X1, ..., Xn) ⊂ R. Notice that the term conﬁdence
interval usually refers to both the output ˆI(X1, ..., Xn), which
is an interval determined by the data, and the underlying
algorithm ˆI(·) itself. Given the randomness in the data, there
is always a risk of mislocating θ, i.e. that θ (cid:3)∈ ˆI(X1, ..., Xn).
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:21:54 UTC from IEEE Xplore.  Restrictions apply. 
404
P(θ ∈ ˆIα(X1, ..., Xn)) = 1 − α,
However, conﬁdence intervals are constructed to guarantee
θ ∈ ˆI(X1, ..., Xn) with a prescribed probability (level of
conﬁdence). To be more precise, ˆI(·) has an additional input
parameter α ∈ (0, 1), such that the conﬁdence level 1 − α
holds:
(6)
where typically α ∈ {0.1, 0.05, 0.01}. Notice that the choice
of α entails a trade-off: On the one hand a smaller α provides
the user with higher certainty that actually θ ∈ ˆIα(X1, ..., Xn),
but on the other hand it translates into a wider conﬁdence
interval, which means less precision with regard to the location
of θ. Besides the choice of α, the sample size n affects the
width of the conﬁdence interval, with larger n leading to
narrower intervals.
In order to construct a conﬁdence interval ˆIα s.t. (6) holds, it is
necessary to have prior knowledge about the underlying distri-
bution of the data sample X1, ..., Xn. For instance, it may be
known that the sample comes from a normal distribution, with
unknown mean and variance, and we want to give a conﬁdence
interval for the mean. In this situation, parametric statistical
theory equips the user with standard tools to construct ˆIα (see
[26]).
Yet in many cases such prior knowledge about the data is
not feasible and therefore a weaker requirement
than (6)
is formulated: It states that the conﬁdence level 1 − α is
approximated with increasing precision, as n grows larger, or
mathematically speaking
n→∞ P(θ ∈ ˆIα(X1, ..., Xn)) = 1 − α.
lim
(7)
If (7) is satisﬁed, we call ˆIα an asymptotic conﬁdence interval
with conﬁdence level 1 − α. The advantages of asymptotic
conﬁdence intervals are their ﬂexibility and robustness against
deviations from a presumed distribution. Common approaches
to prove asymptotic conﬁdence levels include asymptotically
normal estimators, as well as the delta method for differen-
tiable statistics. For details on asymptotic statistical theory, we
refer the interested reader to the monograph of [27].
B. Kernel density estimation
Kernel density estimation is a method to estimate the
d. It
unknown distribution of a data sample X1, ..., Xn on R
can be thought of as the creation of a smoothed, normalized
histogram, where the jumps between the bins are interpolated
continuously (for an introduction see [28]). This procedure is
often preferred to a traditional histogram, particularly if the
data sample is distributed according to a continuous density f
on R
d → R be a continuous, non-negative
More precisely, let K : R
Rd K(u)du = 1. We call K a kernel and
function, such that
n(cid:6)
deﬁne the kernel density estimator (KDE) ˜f for f pointwise
as
d (we write X1, ..., Xn ∼ f).
(cid:8)
(cid:7)
(cid:5)
˜f (t) :=
1
nhd
K
i=1
t − Xi
h
t ∈ R
d,
,
(8)
where h > 0 is the bandwidth, analogue to the bin-width
in a histogram. For details on kernel density estimators as
0.5
0.4
0.3
0.2
0.1
0.0
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
||
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|| |
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
| |
|
|
|
|
|
|
|
|
|
|
|
|
|
||
|
|
|
|
|
||
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
|
||
|
|
|
|
|
|
|
|
|
|
|
|
−5.0
−2.5
0.0
2.5
5.0
Fig. 1: Centered Laplace density (light blue) and kernel density
estimate (red) for N = 200, with Gaussian kernel. On the x-
axis we have plotted the observations X1, ..., X200 (dark blue).
|f (t) − f (s)| ≤ C|t − s|β,
well as generalizations such as multidimensional bandwidths,
we refer to [29]. As the number of observations n increases,
the convergence speed of ˜f to f depends on three distinct
factors: First the smoothness of the true density f, secondly
an adequate choice of the kernel K and thirdly the bandwidth
h.
To quantify smoothness we require f to be H¨older continuous,
i.e. for some β ∈ (0, 1] and C > 0 it holds that
∀t, s ∈ R
(9)
where | · | denotes the Euclidean norm. Notice that β = 1
corresponds to the well known Lipschitz continuity, which
is satisﬁed by the densities corresponding to the Laplace,
Gaussian and versions of the Exponential Mechanism. We also
point out that a density which satisﬁes H¨older continuity for
one β > 0 is H¨older continuous for any other β
The choice of the kernel K is a relatively simple task: To attain
optimal convergence speed, K has to fulﬁll certain regularity
properties (K1) and (K2), that we make precise in Appendix
B. From now on we will always assume that K conforms to
these assumptions. We point out that both of them are satisﬁed
by all commonly used kernels (in particular by the Gaussian
kernel, that we use in our experiments).
(cid:2) ∈ (0, β].
d ,
Finally, the choice of the bandwidth h should depend on the
smoothness level β of f, as well as the sample size n. More
precisely, it can be shown that
(cid:10)
(cid:9)
(cid:11)
sup
t∈Rd
ln(n)
hdn
which implies for the speciﬁc choice h = O(n
− β
| ˜f (t) − f (t)| = OP
(cid:9)(cid:12)
hβ +
| ˜f (t) − f (t)| = OP
ln(n)n
2β+d
− 1
2β+d )
(cid:11)
sup
t∈Rd
,
(10)
.
(11)
Notice that this h minimizes the error rate (except for log-
terms). For details on convergence rates in density estimation
see [30] and for a deﬁnition of the stochastic Landau symbol
OP we refer to the Appendix A.
In practical applications the true smoothness β and hence
the optimal bandwidth is unknown and therefore data-driven