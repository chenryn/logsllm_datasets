√
√
√
√
√
√
√
-
-
-
LM DE
√
√
√
√
√
√
√
√
√
√
-
√
√
√
√
√
√
-
Size
(MB)
381
990
521
448
851.3
819.9
496.7
653.6
878
725
676.5
Log Type (%)
Total
System
Web
DNS
# entity
# event
7,468
97.11%
34,021
98.58%
8,998
96.82%
13,037
97.08%
17,599
96.89%
24,496
97.39%
24,481
99.11%
15,409
98.14%
35,709
98.14%
98.31%
19,666
97.76% 1.46% 0.73% 20,088
2.24%
1.09%
2.43%
2.24%
1.32%
1.36%
0.52%
1.24%
1.24%
0.96%
0.65%
0.33%
0.75%
0.68%
1.32%
1.25%
0.37%
0.62%
0.62%
0.73%
95.0K
397.9K
128.3K
125.6K
251.6K
284.3K
334.1K
258.7K
258.7K
354.0K
249K
† PL: Phishing email link. PA : Phishing email attachment. INJ: Injection. IG: information gathering. BD: backdoor. LM: Lateral movement. DE: Data ex-ﬁltration.
Table 3: Ground-truth information of each implemented at-
tack, including the number of entities, events, sequences and
balanced sequences.
#Non-attack
#Non-attack
#Balanced
#Non-attack
#Attack
Attack
#Attack
Entity
ID
S-1
S-2
S-3
S-4
M-1
M-2
M-3
M-4
M-5
M-6
Avg.
22
12
26
21
28
36
36
28
30
42
28
Entity
7,445
34,008
8,972
13,016
17,565
24,450
24,424
15,378
35,671
19,580
20,051
#Attack
Event
4,598
15,073
5,165
18,062
8,168
34,956
34,979
8,236
34,175
9,994
17,341
Event
90,467
382,879
123,152
107,551
243,507
249,365
299,157
250,512
667,337
344,034
275,796
Seq.
42
43
21
32
83
82
81
79
78
70
61
Seq.
14,243
13,388
8,600
12,238
26,764
27,041
27,525
27,076
25,915
23,473
20,626
Seq.∗
1,388
1,386
2,598
1,244
2,682
2,748
2,710
2,746
2,540
2,598
2,264
* The sampled number of attack and non-attack sequences are identical.
investigation works [11, 25]. We generate the events-based re-
sults by using the identiﬁed attack entities. We iterate through
all events in audit logs, and if an event’s subject or object
matches one of the identiﬁed attack entities, then we label
that event as an attack. Lastly, we compare the number of
classiﬁed attack and non-attack entities and events with their
ground-truth labels and report classiﬁcation metrics.
6.2 Effectiveness
This section presents the effectiveness of ATLAS at identifying
attack entities and events for each attack (Sec. 6.2.1), and
details its individual components (Sec. 6.2.2).
6.2.1 Attack Investigation Results
We report the effectiveness of ATLAS at identifying attack
entities and events for each attack in Table 4. For example,
the ﬁrst row shows the investigation results for S− 1 given
a malicious host as an attack symptom entity. Table 4, Col-
umn “Entity-based Investigation Results” shows that ATLAS
correctly identiﬁes attack entities with an average 91.06%
precision and 97.29% recall. This means that most key en-
tities of the APT attacks are successfully recovered with a
very limited number of false positives. For instance, from
an investigator’s perspective, given 100 attack entities, AT-
LAS recovered around 91 true attack entities, with the other
nine being false positives. Similarly, 97.29% recall means
that ATLAS recovered around 97 attack entities, with three
attack entities remaining undiscovered. We also report the
Figure 7: ROC curves at entity (left) and event (right) level.
identiﬁcation results in terms of events in Table 4 Column
“Event-based investigation Results”. Clearly, since the huge
number of normal entities results in many more normal events
compared to the less-frequently occurring attack events, the
precision of event-level results (99.88%) is much higher than
the entity-level results (91.06%). This means that ATLAS helps
signiﬁcantly reduce the number of suspicious events that need
to be manually checked by an investigator.
Lastly, to show the overall effectiveness of our models, we
present the ROC curves for identifying each attack in Figure 7.
Here, ATLAS achieves on average 97.01% Area Under Curve
(AUC) at the entity-level, and 99.67% AUC at the event-level.
The high precision and recall results indicate that different
attacks share a high-level similarity in terms of attack steps
and sequences generated by those attack entities. For example,
many attacks tend to open a malicious webpage that exploits
a vulnerable browser, then drop and execute backdoors and
extract data of interest. In contrast, normal program execu-
tions in uncompromised hosts rarely perform such activities,
which is clearly reﬂected in the causal sequences generated by
any combinations of their entities. Since each entity could be
associated with multiple events in the audit logs, the number
of false positives and negatives for the event-based results
are much higher than the entity-based results. However, we
note that even in this case, the number of reported false posi-
tives and false negatives identiﬁed by ATLAS are very small
compared to the number of true positives and true negatives.
Analysis of False Positives. False positives are the number
of non-attack (normal) entities and events that ATLAS incor-
rectly classiﬁed as attack (see Table 4, Column 5 and 12).
ATLAS yields on average a 0.01% false positive rate for both
USENIX Association
30th USENIX Security Symposium    3015
(A) ROC Curve (per entitity)(B) ROC Curve (per event)0.00.20.40.60.81.0FalsePositiveRate0.00.20.40.60.81.0S-1S-2S-3S-4M-1M-2M-3M-4M-5M-60.00.20.40.60.81.0FalsePositiveRate0.00.20.40.60.81.0S-1S-2S-3S-4M-1M-2M-3M-4M-5M-6ID
Symptom entity
TP
TN
Table 4: Entity-based and event-based investigation results.
Entity-based Investigation Results
FP
Precision % Recall % F1-score %
TN
FN
TP
Event-based Investigation Results
FP
FN
# Precision % # Recall % F1-score %
S-1
S-2
S-3
S-4
M-1
M-2
M-3
M-4
M-5
M-6
Avg.
malicious host
leaked ﬁle
malicious host
leaked ﬁle
leaked ﬁle
leaked ﬁle
malicious ﬁle
malicious ﬁle
malicious host
malicious host
-
22
12
24
21
28
36
35
24
30
41
27
7,445
34,008
8,972
13,011
17,562
24,445
24,423
15,378
35,665
19,573
20,048
0
2
0
5
3
5
1
0
6
7
3
0
0