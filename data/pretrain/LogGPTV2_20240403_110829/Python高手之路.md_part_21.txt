>>>SIN_MEMOIZED_VALUES =
>>>import math
因此，namedtuple 类工厂的使用同使用带有_slots_
Line #
Filename: namedtuple.py
第10章性能与优化
memoization
23.184 MB
9.895 MB
本电子书仅限学习交流使用，请勿用于商业用途
13.289 MB
0.000MB
IncrementLine Contents
@profile
def main():
 f= [ Foobar(42) for i in range(100000) ]
_的对象一样有效，唯一的不
_make 可以转换已有的
的值被设置成了
---
## Page 156
熊猫爱中国www.xiongmaoi.com
后的。
实现。如果不能对缓存的使用和效用进行衡量，那么使用 memoization是毫无意义的。
当缓存的条目数达到最大时会移除最近最少使用的条目。
器。它提供了同此处描述的 memoization完全一样的功能，其优势在于限定了缓存的条目数，
的情况都有覆盖。
完全正确。PyPI包含了一些通过装饰器实现的 memoization，从简单场景到最复杂且最完备
及更复杂计算的高级函数并不成立。
结果将从这个字典中获取而不需要重新计算。尽管 sin 函数本身计算非常快，但是这对涉
因此需要计算这个值并将其存储在字典中。之后，如果再次以相同的参数值调用这个函数
示例 10.13 是将上面的 memoized_sin 函数的示例用 functools.lru_cache 改写
该模块还提供了对缓存命中、缺失等的统计。在我看来，对于缓存来说它们都是必备的
如果已经了解了装饰器（参见7.1节)，肯定可以想到装饰器用在这里正合适，这么想
(1:0.8414709848078965, 2: 0.9092974268256817)
>>>
0.8414709848078965
>>> memoized_sin(1)
(1:0.8414709848078965,2:0.9092974268256817)
>>>_SIN_MEMOIZED_VALUES
0.9092974268256817
>>> memoized_sin(2)
0.9092974268256817
>>> memoized_sin(2)
(1:0.8414709848078965)
>>> _SIN_MEMOIZED_VALUES
0.8414709848078965
>>> def memoized_sin(x):
_SIN MEMOIZED VALUES
if x not in _SIN MEMOIZED VALUES:
_SIN_MEMOIZED_VALUES[x] = math.sin (x)
本电子书仅限学习交流使用，请勿用于商业用途
10.5memoization
149
---
## Page 157
熊猫爱中国www.xiongmaoi.com
熊猫爱中
是要用 Python 写一个 Python 解释器。随着时间的推移，现在在用 RPython 编写，RPython
威的 Python 实现CPython（这么叫是因为它是用C语言写的）有可能非常慢。PyPy的目的
10.6
示例10.13使用functools.1ru_cache
150
CacheInfo(hits=0, misses=0, maxsize=2, currsize=0)
>>> memoized_sin.cache_info()
>>> memoized sin.cache clear()
CacheInfo(hits=2, misses=3, maxsize=2, currsize=2)
>>> memoized_sin.cache_info()
0.1411200080598672
>>> memoized_sin(3)
CacheInfo(hits=l, misses=3, maxsize=2, currsize=2)
>>> memoized_sin.cache_info()
-0.7568024953079282
>>> memoized_sin(4)
CacheInfo(hits=1, misses=2, maxsize=2,currsize=2)
>>> memoized_sin.cache_info()
0.14 11200080598672
>>> memoized sin(3)
CacheInfo(hits=l, misses=1, maxsize=2, currsize=1)
>>> memoized_sin.cache_info()
0.9092974268256817
>>>memoized sin(2)
CacheInfo(hits=0, misses=l, maxsize=2, currsize=1)
>>> memoized_sin.cache_info()
0.9092974268256817
>>>memoized sin(2)
... def memoized_sin(x):
>>> import math
>>> import functools
第10章性能与优化
PyPy
return math.sin(x)
本电子书仅限学习交流使用，请勿用于商业用途
---
## Page 158
熊猫爱中国www.xiongmaoi.com
3的支持正在开发中。
10.7
系结构上，并且可以运行在不同的操作系统上（Linux、Windows、MacOSX等)。其对Python
Hy项目从项目初期就成功地采用了这一策略。Hy一直支持 PyPy和其他所有 Python 版本。
可能带来的大量工作。
构造虚拟环境，就像CPython2和CPython3一样，所以实现起来还是相当简单的。
需要保证像在CPython上一样在PyPy上测试你的软件。tox（参见6.7节）支持使用PyPy
不错的。达到这一目标只需要与支持的其他 Python 版本保持同样的编码策略，基本上，只
注意
局限性，如可恶的GIL（Global Interpreter Lock，全局解释器锁）。
行充分地测试。
PyPy 声称可以达到3倍的速度。尽管如此，也不要期望太高，PyPy同样有一些CPython 的
代码的速度进行整合从而运行得更快。
包含内置的 JIT（Just-In-Time）编译器。简单来说，就是通过利用解释的灵活性对编译后的
Python.
的代码会被翻译成C代码从而构建解释器，当然RPython也可以用来实现其他语言而不只是
于各种原因不能在PyPy上运行的代码路径和依赖所阻碍，因为它们没有在项目的早期进
且没有任何问题。但是，我们却没能在所有OpenStack项目中这样做，我们正在被一些由
是Python 语言的一个限制性子集。
PyPy与Python 2.7兼容，并且它的 JIT 编译器可以运行在32位和64位x86和ARM体
如果想让你的软件运行在 PyPy上，最好是在项目的初期就开始，以避免在后期支持时
尽管 PyPy 并非一种严格意义上的优化技术，但是将其作为一种支持的 Python 实现还是
RPython对Python语言的限制的主要方式是，要求变量类型能够在编译时推断。RPython
通常程序都需要处理大量的大型字节格式的数组格式的数据。一旦进行复制、分片和修
到底多快呢？看情况，但对于纯算法代码会更快一点。对于普通的代码，大多数情况下
除了技术上的挑战，PyPy吸引人的地方在于目前它是CPython 的更快的替代品。PyPy
通过缓冲区协议实现零复制
本电子书仅限学习交流使用，请勿用于商业用途
10.7
通过缓冲区协议实现零复制
151
---
## Page 159
熊猫爱中国www.xiongmaoi.com
熊猫爱中国
length%d"%
使用情况。
改等操作，以字符串的方式处理如此大量的数据是非常低效的。
152
29.434MB
29.434MB
29.434MB
29.422MB
29.422MB
19.65 6 MB
Mem usage
Filename: memoryview/copy.py
Content length: 10240000, content to write length 10238976
def read_random():
设想一个读取二进制数据的大文件的小程序，并将其部分复制到另一个文件中。这
9.887MB
if
@profile
9.883 MB
第10章性能与优化
read_random()
with open("/dev/null", "wb") as target:
print("Content length: %d, content to write length %d"
with open("/dev/urandom", "rb") as source:
target.write(content_to_write)
(len(content), len(content_to_write)))
content_to_write = content[1024:]
content=source.read（1024*10000)
Increment
9.766MB
9.770MB
0.004 MB
0.000MB
0.000MB
0.000MB
0.000MB
0.012MB
本电子书仅限学习交流使用，请勿用于商业用途
@profile
def read_random () :
Line Contents
'：
:astnos se ("qr 'wopuean/aap/ ) uado uatm
with open("/dev/null", "wb") as target:
print("Content length: %d, content to write
content_to_write = content[1024:]
 content = source.read(1024 * 10000)
target.write(content_to_write)
(len(content),len(content_to_write)))
olo
2
---
## Page 160
熊猫爱中国www.xiongmaoi.com
① 假设整个字符串在一个连续的内存区域。
对象的事实。这意味着它不会复制任何数据，而只是引用了原始数据的一个特定分片，如
0字母b的ASCII码。
memoryview对象，它会引用原始的对象内存。
提供该协议的CAPI。
dev/peps/pep-3118/）定义了缓冲区协议，其中解释了用于为不同数据类型（如字符串类型）
的使用查看数组的某一部分但不复制数组?。
的性能来说，复制内存都是缓慢的。
语言代码，应该知道使用memcpy（）的开销是巨大的，无论是内存的占用还是对通常意义上
写入一个新的字符串对象中。
write 时增长到了约10 MB：事实上，分片操作符会复制全部的内容，减去开始的1KB 后
②复制整块的数据但是减去开始的1KB，因为我们不想将最开始的1KB数据写入目标文件中。
①从/dev/urandom读取10 MB的数据且没有太多其他操作。Python为此要分配约10MB的内存以将该
数据存储为字符串。
在这个例子中，会利用memoryview对象的切片运算符本身返回一个memoryview
示例如下：
在Python中可以使用实现了缓冲区协议的对象。PEP 3118（https://www.python.org/
但是作为C程序员，你应该也知道字符串是字符的数组，完全可以通过基本的指针算法
当处理大量数据时，针对大的字节数组执行此类操作可能会变成一场灾难。如果写过（
这个例子中有意思的地方在于，正如你看到的，内存的使用在构造变量content_to_
>>>bytes(view[1:3])
>>>1imited=view[l:3]
980
>>>view[1]
>>>view=memoryview(s)
>>> s =b"abcdefgh"
本电子书仅限学习交流使用，请勿用于商业用途
10.7通过缓冲区协议实现零复制
153
---
## Page 161
熊猫爱中国www.xiongmaoi.com
熊猫爱中国
对象。
图10-2所示。
154
19.660MB
Filename: memoryview/copy-memoryview.py
Content 1ength: 10240000, content to write 1ength 10238976
这个程序只使用了第一个版本约一半的内存：
def read_random() :
@profile
19.660MB
出于这一点考虑，我们可以重写这个程序，这次对数据的引用将使用memoryview
Mem usage
9.891MB
9.887MB
第10章性能与优化
read_random()
with open("/dev/urandom", "rb") as source:
name
target.write(content_to_write)
content_to_write = memoryview(content) [1024:]
content = source.read(1024 * 10000) :
(len(content),len(content_to_write)))
Increment
0.000MB
9.770MB
0.004MB
0.000MB
本电子书仅限学习交流使用，请勿用于商业用途
limited
图10-2对memoryview对象使用切片
Line Contents
content _to _write = memoryview(content) [1024:] @
content=source.read(1024*10000)0
with open("/dev/urandom", "rb") as source:
def read_random():
@profile
P
e
f
g
h