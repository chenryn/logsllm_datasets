### Optimized Text

To achieve our goal, we will consider the following system of ordinary differential equations (ODEs):

\[
\dot{x}_1 = -\alpha_1 x_1,
\]
\[
\dot{x}_2 = -\alpha_2 x_2.
\]

This system is given by Equation (23). We define the aggregation matrix \( M \) as \( M = (1, 1) \), with a right inverse \(\bar{M} = (a, 1 - a)^T\), where \( a \in [0, 1] \). The ODE that describes the aggregated system is then:

\[
\dot{y} = -(\alpha_1 a + \alpha_2 (1 - a)) y.
\]

This is shown in Equation (24).

By applying Theorem 3, we can deduce that the lumping cannot be exact if \(\alpha_1 \neq \alpha_2\). Suppose now that \(\alpha_1 \neq \alpha_2\), and let us estimate the lumping error using \(\varepsilon\)-lumpability. It is straightforward to show that the vector field is Lipschitz continuous with respect to the parameters. Furthermore, condition (12) holds with \(\varepsilon_1 = (1 - a)(\alpha_2 - \alpha_1)\) and \(\varepsilon_2 = a(\alpha_1 - \alpha_2)\). With these, the system (24) is the exactly lumped ODE by \( M \) of:

\[
\dot{x}^\varepsilon_1 = -(\alpha_1 + \varepsilon_1) x^\varepsilon_1,
\]
\[
\dot{x}^\varepsilon_2 = -(\alpha_2 + \varepsilon_2) x^\varepsilon_2.
\]

This is given by Equation (25).

Perturbation theory considers the case when \(\varepsilon_1\) and \(\varepsilon_2\) are small, and one can approximate the solution of the perturbed system (25) as a power series expansion, for example:

\[
x^\varepsilon_1(t) = A_1(t, \alpha) + B_1(t, \alpha) \varepsilon_1 + O(\varepsilon_1^2),
\]
\[
x^\varepsilon_2(t) = A_2(t, \alpha) + B_2(t, \alpha) \varepsilon_2 + O(\varepsilon_2^2).
\]

These are given by Equation (26), where \(A_1, A_2, B_1, B_2\) are functions to be determined. Substituting these approximations into (25) and equating the coefficients of the same powers of \(\varepsilon_1\) and \(\varepsilon_2\), we obtain the following ODE system for the unknowns \(A_1, A_2, B_1, B_2\):

\[
\dot{A}_1(t, \alpha) = -\alpha_1 A_1(t, \alpha),
\]
\[
\dot{A}_2(t, \alpha) = -\alpha_2 A_2(t, \alpha),
\]
\[
\dot{B}_1(t, \alpha) = -A_1(t, \alpha) - \alpha_1 B_1(t, \alpha),
\]
\[
\dot{B}_2(t, \alpha) = -A_2(t, \alpha) - \alpha_2 B_2(t, \alpha).
\]

We note that the functions \(A_1, A_2\) correspond to the solution of the original ODE system (23).

The lumping error can be expressed as:

\[
|y(t) - (x_1(t) + x_2(t))| = |y(t) - (x_1(t) + x_2(t)) + x^\varepsilon_1(t) + x^\varepsilon_2(t) - x^\varepsilon_1(t) - x^\varepsilon_2(t)|,
\]

where we have used that \(y(t) - (x^\varepsilon_1(t) + x^\varepsilon_2(t)) = 0\). If the error is evaluated using the perturbation-theory approximation (26) instead of Theorem 4, we would obtain:

\[
|x^\varepsilon_1(t) + x^\varepsilon_2(t) - (x_1(t) + x_2(t))| = |\varepsilon_1 B_1(t, \alpha) + \varepsilon_2 B_2(t, \alpha) + O(\|\varepsilon\|^2)|.
\]

However, we notice that the error estimate depends on the solution of an ODE system of the same size as the original one. In this case, attempting to bound the functions \(B_1\) and \(B_2\) appears more difficult than with Theorem 4, because, for example, the sufficient conditions of Proposition 1 do not apply here.

### Figure 4
Figure 4 shows the results for two different choices of the generalized inverse matrix, corresponding to the minimizer and the maximizer of the a-priori error bound (cf. Figure 1). Comparing the two plots reveals that the error statistics are visually indistinguishable. For all values of \(\Delta\), the errors were found to be equal up to the sixth decimal digit, indicating excellent insensitivity to the actual choice of the inverse matrix in practice. The figures also demonstrate robustness to the initial ODE conditions, with all error statistics being of the same order of magnitude. The maximum error attained in these cases, i.e., \(1.36 \times 10^{-5}\), is very satisfactory (being four orders of magnitude smaller than the values of the initial conditions), despite the high degree of heterogeneity in the system with \(\Delta = 20.0\).

### Summary
To summarize, these findings support the hypothesis that ODE systems and aggregation matrices enjoying \(\varepsilon\)-lumpability behave very well a posteriori, with errors that are negligible for all practical purposes, even for sensibly large perturbations of the model parameters.

### Related Work
In performance modeling, the notion of lumpability is well understood for Markov chains, with results dating back to the 1960s, starting with the work of Kemeny and Snell [11], and further researched by others [25, 23, 4]. Approximate lumpability has also been studied, with aggregation errors that can be bounded [4, 7].

For dynamical systems, lumpability has been extensively studied for linear systems (e.g., [31, 13]). In this section, we focus on results concerning nonlinear systems, which are typical models for computing systems. Specifically, the three case studies considered in this paper are all in this form.

Less is known for nonlinear systems in general, so methods have been developed for special classes. Two model-reduction approaches are based on empirical gramians (e.g., [15, 10]) and proper orthogonal decomposition (e.g., [22, 5]). Both techniques, however, require the availability of empirical data from the original model (e.g., through simulation or experimentation). Therefore, unlike our approach, an a-priori bound cannot be obtained. A-priori and a-posteriori bounds are provided in [32], which considers nonlinear systems with dynamics expressible by kernel expansions. However, such a form cannot encode some models of interest.

### Conclusion
The presence of various types of agents in models of computer and communication systems is common. This situation may arise, for instance, when users are connected to a network with links of different capacities, or when certain jobs have different priorities/requirements on a server. Unfortunately, explicitly incorporating heterogeneity in a model comes with increased computational cost. In the context of large-scale systems analyzed by fluid techniques, this paper has studied a class of models for which distinct agent types are structurally similar but their dynamics are associated with rates that can differ. For such a class, model reduction may be achieved by homogenizing different types of agents through a perturbation of the rates. By collapsing their related variables onto a single macro-variable, an approximation error is incurred that is (in the worst case) linear with the degree of heterogeneity. That is, the more different the rates of the agent types, the more error is introduced when aggregating them.

The numerical tests presented in this paper are encouraging regarding the practical usability of \(\varepsilon\)-lumpability. Under a variety of different conditions, we found that the aggregation is very robust in all cases, yielding a-posteriori errors that are negligible for all practical purposes. In this respect, we feel that our most important contribution lies in characterizing sufficient conditions on the vector field and the aggregation scheme for which such robustness with respect to the degree of heterogeneity of the original model exists. We wish to point out that the conditions to be verified for \(\varepsilon\)-lumpability never require the solution of the original system but are essentially based on the structure of its vector field. In particular, we remark that the verification of our fundamental condition in (12) can, in some cases, be easily automated. Specifically, models with dynamics such as multi-class mass-action laws for epidemic spread and generalized processor sharing lead to a system of linear equations to be solved for \(\varepsilon\), which can be straightforwardly implemented, for instance, on a computer algebra system.

### Acknowledgements
This work was supported by the EU project ASCENS, 257414, and by the DFG project FEMPA. The authors wish to thank Max Tschaikowski for discussions and the Leibniz-Rechenzentrum for the computing facilities.

### References
[References remain unchanged as they are already well-structured and complete.]