title:Stealing Webpages Rendered on Your Browser by Exploiting GPU Vulnerabilities
author:Sangho Lee and
Youngsok Kim and
Jangwoo Kim and
Jong Kim
2014 IEEE Symposium on Security and Privacy
Stealing Webpages Rendered on Your Browser by Exploiting GPU Vulnerabilities
Sangho Lee, Youngsok Kim, Jangwoo Kim, and Jong Kim
Department of Computer Science and Engineering
{sangho2, elixir, jangwoo, jkim}@postech.ac.kr
POSTECH, Korea
Abstract—Graphics processing units (GPUs) are important
components of modern computing devices for not only graphics
rendering, but also efﬁcient parallel computations. However,
their security problems are ignored despite their importance
and popularity. In this paper, we ﬁrst perform an in-depth
security analysis on GPUs to detect security vulnerabilities. We
observe that contemporary, widely-used GPUs, both NVIDIA’s
and AMD’s, do not initialize newly allocated GPU memory
pages which may contain sensitive user data. By exploiting
such vulnerabilities, we propose attack methods for revealing
a victim program’s data kept in GPU memory both during its
execution and right after its termination. We further show the
high applicability of the proposed attacks by applying them to
the Chromium and Firefox web browsers which use GPUs for
accelerating webpage rendering. We detect that both browsers
leave rendered webpage textures in GPU memory, so that we
can infer which webpages a victim user has visited by analyzing
the remaining textures. The accuracy of our advanced inference
attack that uses both pixel sequence matching and RGB
histogram matching is up to 95.4%.
I. INTRODUCTION
This work considers how attackers can disclose sensi-
tive data kept in graphics processing unit (GPU) memory.
We aim to obtain rendered webpage textures to uncover
webpages a victim user has visited. We successfully reveal
such data from modern GPUs (e.g., NVIDIA and AMD
GPUs) when we enable GPU-accelerated webpage rendering
of recent web browsers (e.g., Chromium and Firefox). For
example, Figure 1 shows the Google logo image of http://
google.com and a partial dump of rendered webpage textures
extracted from an NVIDIA GPU used by the Chromium
web browser. Although the GPU has rearranged the textures
according to its undocumented hardware characteristics, we
can infer that the dump originates from the webpage because
their color patterns are similar. Especially, our combined
matching attack can successfully infer up to 95.4% of ran-
domly visited 100 front pages of Alexa Top 1000 websites
when a victim uses the Chromium web browser with an
NVIDIA GPU (details are in Section V.)
GPUs are important and powerful components of con-
temporary computing devices. Personal computing devices,
including desktops, laptops, and smartphones, use GPUs
for supporting various graphics applications, e.g., graph-
ical user interface (GUI), multimedia players, and video
games. Large-scale computing devices, including worksta-
tions, servers, and clusters, also use GPUs for energy-
© 2014, Sangho Lee. Under license to IEEE.
DOI 10.1109/SP.2014.9
19
(a) Google logo image.
(b) Partial dump of Google webpage textures.
Figure 1. Google logo and partial dump of Google webpage textures
extracted from the Chromium web browser with an NVIDIA GPU.
efﬁcient, massive parallel computations. GPUs utilize a large
number of processing cores and a large amount of indepen-
dent memory for efﬁciently processing graphics operations
and computational workloads. For example, an NVIDIA
Kepler GPU can have up to 2880 cores and 6 GB of memory,
and its ﬂoating-point operation performance is nine times
better than that of the recent CPUs [1], [2].
Programmers can use two types of application program-
ming interfaces (APIs) to access GPUs: graphics APIs
(e.g., DirectX [3] and OpenGL [4]) and computing APIs
(e.g., CUDA [2] and OpenCL [5]). First, the graphics APIs
provide functions for graphics operations, such as projection,
shading, and texture mapping. Second, the computing APIs
provide functions for non-graphics applications, such as
ﬁnancial, medical, or weather data analyses [6], database
query optimizations [7], [8], packet routing [9], intrusion de-
tection systems [10], [11], and cryptographic engines [12]–
[17].
The most signiﬁcant differences between the graphics
APIs and the computing APIs are sharing and memory man-
ageability. First, the computing APIs allow different users
to share the same GPU, whereas the graphics APIs only
support a single user. A number of users can share the same
GPU using the computing APIs in a time-sharing fashion,
as (1) the computing APIs demand no dedicated screens
and (2) current GPUs only support sequential execution of
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:59:35 UTC from IEEE Xplore.  Restrictions apply. 
different GPU processes [18]. Although some techniques
(e.g., VirtualGL [19]) allow remote users to share the same
GPU when using the graphics APIs, they warn users of
potential security problems (e.g., logging keystrokes and
reading back images through an X server).
Second, while GPU drivers manage GPU memory with
the graphics APIs, programmers can manually manage GPU
memory with the computing APIs, including allocations,
CPU-GPU data transfers, and deallocations. GPUs have
several types of memory (e.g., global, local, and private
memories), and programmers can control them using the
computing APIs except some graphics-related memories
(e.g., framebuffer and z-buffer). In contrast, the graphics
APIs provide no functions to manage such memories while
providing a set of optimized functions to perform memory-
efﬁcient graphics operations.
Unfortunately, the sharing and high memory manageabil-
ity of the computing APIs may incur critical security threats
because GPUs do not
initialize newly-allocated memory
buffers [20]. Although numerous studies consider such an
uninitialized memory problem in operating systems [21]–
[24], no study deals with the uninitialized GPU memory
problem1. If similar security threats exist with the computing
APIs, the threats have much larger impact as multiple users
share the same GPU.
In this paper, we ﬁrst perform an in-depth security analysis
on GPUs regarding their architectures and computing APIs
to reveal any potential security threats. We identify that
the computing APIs have a serious uninitialized memory
problem because they (1) do not clear newly allocated
memory pages, (2) have memory types that programmers
cannot delete, and (3) have in-core memory without security
mechanisms.
Second, we develop effective security attacks on GPUs
applicable to the most widely used GPUs, NVIDIA and
AMD GPUs, by exploiting the revealed security threats. Our
attacks can disclose sensitive data kept in GPU memory of
a victim program both during its execution and right after
its termination.
Third, we demonstrate the high applicability of our attacks
by inferring browsing history of the two most widely used
web browsers, the Chromium and Firefox web browsers.
Both browsers support GPU-accelerated webpage render-
ing acceleration, which uploads webpage textures to GPU
memory to increase rendering speed. Our attacks can extract
rearranged webpage textures of both browsers from NVIDIA
and AMD GPUs.
Lastly, we propose advanced inference attacks which can
correctly infer the original webpage of rearranged webpage
textures with up to 95.4% accuracy. The proposed inference
attacks compare the textures with either known textures or
1We found unpublished [25] and concurrent [26] studies dealing with
similar problems during the camera-ready period.
known webpage snapshots to identify the original webpage
using three matching methods: (1) pixel sequence matching,
(2) RGB histogram matching, and (3) combined matching.
To the best of our knowledge, our work is the ﬁrst security
analysis and attacks targeting GPUs. In summary, our work
makes the following contributions:
• Novel and crucial attack target. Our work expands
the scope of security research to a novel attack target,
GPUs. Despite their popularity and importance, there is
no in-depth and comprehensive study of their security
problems before this work.
• Complete in-depth study. We present a complete in-
depth security analysis on GPUs regarding not only
their architectures, but also their computing APIs. We
identify that all kinds of GPU memories accessible by
the computing APIs has security problems.
• Strong and widely-applicable attacks. We demon-
strate our attacks using the most widely-used GPUs
and GPU-assisted applications: NVIDIA and AMD
GPUs, and the Chromium and Firefox web browsers.
Especially, our attacks accurately infer browsing history
by up to 95.4%.
The remainder of this paper is organized as follows. In
Section II we give an in-depth security analysis on GPUs
and motivate our work. In Section III we explain the threat
model. In Section IV we explain our attacks to disclose
sensitive data remaining in GPU memory. In Section V we
propose our inference attacks that identify browsing history
of web browsers using GPUs. In Section VI we discuss
possible countermeasures against the proposed attacks. In
Section VII we summarize related work of this paper. Lastly,
we conclude the paper in Section VIII.
II. BACKGROUND AND SECURITY CONCERNS
In this section, we ﬁrst give a brief overview on GPUs in
terms of their architectures and programming models. Then,
we motivate our work by presenting inevitable security
concerns rising from the nature of GPUs. We use the
OpenCL terminology [5] throughout the paper.
A. GPU Architecture
A GPU consists of (1) a compute device for executing in-
structions and (2) a compute device memory for storing data
used by the compute device. Figure 2 shows the high-level
diagram of a typical OpenCL-capable GPU architecture. The
compute device consists of several compute units (CUs) and
a global/constant memory data cache shared by all CUs.
Each CU consists of processing elements (PEs), also known
as GPU cores, and per-CU local memory shared by the PEs.
Each PE also has per-PE private memory.
The compute device memory consists of two memory
types: global memory and constant memory. The read-write
global memory is for storing GPU computation results. The
20
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:59:35 UTC from IEEE Xplore.  Restrictions apply. 
can invoke glTexCoord() to coordinate the texture object
while drawing objects.
Textures reside in the global memory, and program-
mers can delete textures no longer used by calling
glDeleteTextures() to increase available global
memory size. This function, however, does not initialize the
corresponding memory blocks. Accordingly, an attacker can
read the uninitialized textures which remain in the global
memory after glDeleteTextures().
D. Security Concerns
We now present three major security concerns of GPUs
based on our analysis on GPU architectures and APIs. We
take advantage of the major security concerns to perform
our attacks presented in Section IV.
1) Lack of Memory Page Initialization Upon New Al-
location: We identify a crucial security problem of GPU
memory—GPUs do not
initialize the contents of newly
allocated memory pages that possibly contain sensitive data.
The new owner can access the sensitive data remaining in
the memory pages if the previous owner does not clear
it. Modern operating systems have suffered from similar
problems, but they solve the problems by ﬁlling new mem-
ory pages with zeros before delivering them to user space
processes [27]. However, we detect that GPUs do not provide
such a countermeasure. Therefore, we deﬁne the lack of
memory page initialization upon new allocation as the ﬁrst
major security concern of GPUs.
2) Unerasable Memory: We identify that a portion of
GPU memory is neither erasable by users nor automatically
erased by GPUs. As explained in Section II-A, GPUs
have several
types of memory. While programmers can
delete the contents of most types of memory, GPUs prevent
programmers from erasing the contents of a few types of
memory containing sensitive data (e.g., constant data, kernel
codes, and call-by-value arguments). Moreover, we detect
that GPUs do not automatically delete such contents even
when they are no longer necessary. Thus, protecting sensitive
data kept in the unerasable memory becomes the second
major security concern of GPUs.
3) Programmer-managed Memory: We identify that
threads originating from a kernel running on a CU can
access the contents of other kernels, stored in the local
and private memories of the CU. GPU computing models
allow programmers to manually manage the local and private
memories to optimize performance [2], [5]. For security,
GPUs should disallow threads of a kernel to access the
contents stored in the local and private memories, written by
threads of other kernels. But we detect that current GPUs
provide no isolation mechanism for the local and private
memories. Regarding that GPU-accelerated applications use
the local and private memories for storing sensitive data
(e.g., secret keys with libgpucrypto [12]), lack of such
Figure 2. High-level architecture of an OpenCL-capable GPU.
read-only constant memory is for storing codes executed by
the compute device and read-only data.
B. GPU Computing Model
In a typical GPU computing model, GPUs run the
programmer-deﬁned GPU contexts, similar to CPUs. Pro-
grammers construct a GPU context by writing kernels, mem-
ory management, and command queues using the computing
APIs. Kernels are the functions written to run on GPUs.
Memory management includes GPU memory allocations,
data transfers between CPU and GPU memories, and GPU
memory deallocations. Command queues hold the com-
mands to be executed on GPUs. Both kernels and memory
management are the commands. A typical execution of a
GPU context is as follows: programmers queue (1) GPU
memory allocation commands, (2) CPU to GPU data transfer
commands, (3) kernel execution commands, (4) GPU to
CPU data transfer commands, and (5) GPU memory deallo-
cation commands in a command queue. When programmers
queue a kernel execution command to the command queue,
a GPU driver passes the pointers of allocated GPU memory
accessible by the kernel to the GPUs through the kernel
arguments. The GPUs execute all commands in a command
queue in the ﬁrst-in, ﬁrst-out (FIFO) manner.
C. OpenGL and Textures
We brieﬂy explain OpenGL, a popular graphics APIs
widely supported by various operating systems, such as