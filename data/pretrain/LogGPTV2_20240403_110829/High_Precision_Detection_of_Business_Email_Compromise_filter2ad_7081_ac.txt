repeatedly impersonated in BEC attacks. For instance, the
CEO is a common target for impersonation. and is often
targeted dozens of times. However, this signal alone is not
3There is no inherent advantage in using multiple content classiﬁers in
terms of the false positive rate or precision. We decided to use two different
content classiﬁers, because it made it easier for us debug and maintain them
separately.
Feature
Sender has corp domain?
Description
Is sender address from corp domain?
Reply-to != sender ad-
dress?
Reply-to and sender addresses different?
Num times
email
sender and
Number of times sender name and email
address appeared
Num times reply-to ad-
dress
Number of times reply-to address ap-
peared
Known reply-to service?
Is reply-to from known web service (e.g.,
LinkedIn)?
Sender name popularity
How popular is sender name
Table 3: Main features used by the impersonation classiﬁer, which
looks for impersonation attempts, including spoofed names and
emails.
Figure 1: Number of unique emails addresses that were observed
for each user in an organization with 44,400 mailboxes. The X
axis is the number of unique email addresses that were observed,
as a percentage (in the Y axis) of the total number of users of the
organization.
sufﬁcient to detect impersonation,. For example, some of the
senders that have a large number of email addresses represent
shared mailboxes (e.g., “IT” or “HR”), and are legitimate.
Hence, several of the features in the impersonation clas-
siﬁer rely on the historical communication patterns of the
organization. This inﬂuenced BEC-Guard’s architecture. In
addition, we maintain a list of known web services that “legit-
imately” send emails with reply-to addresses that are different
than the sender address (e.g., LinkedIn, Salesforce), in order
to capture the response. The original list of commonly-used
services was populated from a list of the domains of the major
web services. We then augmented this list with additional ser-
vices when we encountered them during the labeling process
(in §6 we discuss possible evasion techniques related to this
list of legitimate reply-to senders). The sender name popu-
larity score is computed ofﬂine by maintaining a list of how
frequently names appear across different organizations in our
dataset. The more popular a name, the higher the likelihood
that a name with an email address the employee typically
does not use is another person (a name collision).
Name and nickname matching.
In order to detect name
spooﬁng, the impersonation classiﬁer needs to match the
1296    28th USENIX Security Symposium
USENIX Association
0.00010.0010.010.111 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20Number of Sender Emails AddressesPercentage of Userssender name with a name of an employee. However, names
can be written in various forms. For example: “Jane Smith”
can be written as: “Smith, Jane”, “Jane J. Smith” or “Jane
Jones Smith”. In addition, we need to deal with special char-
acters that might appear in names, such as ì or ä.
To address these problems, BEC-Guard normalizes names.
It stores employee name as  tuples, and
checks all the variants of the sender name to see if it matches
a name of an employee with a corporate email address. These
variants include stripping the middle name or initial, reversing
order of the ﬁrst name and surname, and stripping sufﬁxes.
Sufﬁxes include examples like “Jr.” or when the email address
is sent as part of the sender name. In addition, we match the
ﬁrst name against a publicly available list of nicknames [36],
to catch cases for example when the attacker sends an email
as “Bill Clinton”, and the name of the employee is stored as
“William Clinton”.
Content classiﬁers. Our system uses two content classi-
ﬁers: the text classiﬁer and link classiﬁer. The text classiﬁer
catches attacks similar to Example 1 and 2, and the link classi-
ﬁer stops attacks that are similar to Example 3. By design, the
content classiﬁers are meant to be updated more frequently
than the impersonation classiﬁer, and should be easily re-
trained based on false negatives and false positives reported
by users.
Text classiﬁer.
In BEC attacks similar to Example 1 and 2,
the body contains words that are indicative of a sensitive or
special request, such as “wire transfer” or “urgent”. Therefore,
our ﬁrst iteration of the text classiﬁer was designed to look for
speciﬁc words that might imply a special request or a ﬁnancial
or HR transaction. The features of the classiﬁers described
the position in the text of a list of sensitive words and phrases.
However, over time, we noticed this approach suffered from
several problems. First, a classiﬁer that relies on hard-coded
keywords can miss attacks when attackers slightly vary a
speciﬁc word or phrase. Second, to successfully retrain the
classiﬁer, we had to modify the lists of keywords that it looks
for, which required manually updating the keyword list on a
daily basis.
Instead, we developed a text classiﬁer that learns expres-
sions that are indicative of BEC on its own. The ﬁrst step is to
pre-process the text. BEC-Guard removes information from
the subject and body of the email that would not be useful for
classifying the email. It removes regular expression patterns
that include salutations (“Dear”, “Hi”), pre-canned headers,
as well as footers (“Best,”) and signatures. It also removes all
English stopwords, as well as any names that may appear in
the email.
The second step is to compute the frequency-inverse docu-
ment frequency [42] (TFIDF) score of each word in the email.
TFIDF represents how important each word is in an email,
and is deﬁned as:
num words in email
log(num emails)
num emails with w
IDF(w) =
T F(w) =
num times w appears in email
Where w is a given word in an email. T F(w) · IDF(w)
gives a higher score to a word that appears frequently in a
speciﬁc email, but which is relatively rare in the whole email
corpus. The intuition is that in BEC emails, words for example
that denote urgency or a special request would have a high
TFIDF score, because they appear frequently in BEC emails
but less so in legitimate emails.
When training the text classiﬁer, we compute the TFIDF
score of each word in each email of the training set. We also
compute the TFIDF for pairs of words (bigrams). We store
the global statistics of the IDF as a dictionary, which con-
tains number of emails in the training set that contain unique
phrases encountered in the training of the text classiﬁer. We
limit the dictionary size to 10,000 of the top ranked words (we
evaluate how the size of the dictionary impacts classiﬁcation
precision in §7.2).
The feature vector of each email is equal to the the number
of words in the dictionary, and each number represents the
TFIDF of each one of the words in the dictionary. Words
that do not appear in the email, or that do not appear in the
dictionary have a TFIDF of zero. The last step is to run a
classiﬁer based on these features. Table 4 presents the top
10 phrases (unigram and bigram) in the BEC emails in our
dataset. Note that the top phrases all indicate some form of
urgency.
Top phrases in BEC emails by TFIDF
1. got moment
2. response
3. moment need
4. moment
5. need
6. need complete
7. ASAP
8. urgent response
9. urgent
10. complete task
Table 4: The top 10 phrases of BEC emails, sorted by their TFIDF
ranking from our evaluation dataset (for more information on evalu-
ation dataset see §7.1). The TFIDF was computed for each word in
all of the BEC emails in our evaluation dataset.
Link classiﬁer. The link classiﬁer detects attacks similar
to Example 3. In these attacks, the attacker tries to get the
recipient to follow a phishing link. As we described earlier,
these personalized phishing links are typically not detected by
IP blacklists, and are usually unique to the recipient. In this
case, since the content classiﬁer only classiﬁes emails that
were already classiﬁed as impersonation emails, it can mark
links as “suspicious”, even if they would have a high false
positive rate otherwise. For example, a link that points to a
USENIX Association
28th USENIX Security Symposium    1297
small website, or one that was recently registered, combined
with an impersonation attempt would have a high probability
of being a BEC email.
Feature
Domain popularity
URL ﬁeld length
Domain registration date
Description
How popular is the link’s least popular
domain
Length of least popular URL (long URLs
are more suspicious)
Date of domain registration of least popu-
lar domain (new domains are suspicious)
Table 5: Main features used by the link request classiﬁer, which
stops attacks like in Example 3.
Table 5 describes the main features used by the link request
classiﬁer. The domain popularity is calculated by measur-
ing the Alexa score of the domain. In order to deal with link
shorteners or link redirections, BEC-Guard expands the URLs
before computing their features for the link classiﬁer. In addi-
tion, several of the URL characteristics require determining
information about the domain (popularity and score). For the
domain popularity feature, we cache a list of the top popular
domains, and update it ofﬂine. To determine the domain reg-
istration date, BEC-Guard does a real-time WHOIS lookup.
Note that unlike the impersonation classiﬁer, which needs to
map the distribution of email address per sender name, none
of the features of the text and link classiﬁer are organization-
speciﬁc. This allows us to easily retrain them based on user
reported emails.
4.5 Classiﬁer Algorithm
The impersonation and link classiﬁers use random forest [5]
classiﬁcation. Random forests are comprised of randomly
formed decision trees [40], where each tree contributes a
vote, and the decision is determined by the majority of the
trees. Our system uses random forests rather than individual
decision trees, since we found they provide better precision,
but for ofﬂine debugging and analysis we often visualize
individual decision trees. We decided to use KNN for the text
classiﬁer, because it had slightly better coverage than random
forests. However, we found that since the text classiﬁer uses a
very large number of features (a dictionary of 10,000 phrases),
its efﬁcacy was similar across different classiﬁers. In §7.2 we
evaluate the performance of the different classiﬁer algorithms.
In addition, we have explored deep-learning based tech-
niques, such as word2vec [34] and sense2vec [46], which
expand each word to a vector that represents its different mean-
ings. We currently do not use such deep-learning techniques,
because they are computationally heavy both for training and
online classiﬁcation.
Detecting impersonation of new employees. When a new
employee joins the organization, the impersonation classi-
ﬁer will not have sufﬁcient historical information about that
employee, since they will not have any historical emails. As
that employee receives more emails, BEC-Guard will be start
compiling statistics for the employee. A similar problem may
also arise in organizations that periodically purge their old
emails. In practice, we found that the classiﬁer performs well
after only one month of data.
4.6 Labeling
In order to label the initial training set, we made several as-
sumptions about the BEC attack model. First we assumed
attackers impersonate employees using their name (under a
set of allowed variations, as explained above). Second, we as-
sumed the impersonation does not occur more than 100 times
using the same email address. Third, we assumed the attacker
uses an email address that is different than the corporate ad-
dress, either as the from address or the reply-to address. We
discuss other types of attacks that do not ﬁt these assumptions,
as well as how attackers may evade these assumptions in §6.
Under these constraints, we fully covered all of the possible
attacks and manually labeled them. In addition, we incorpo-
rated missed attacks reported from customers (we discuss this
process in §7.3).
The reason we assumed a BEC email does not impersonate
an employee using the same email address more than 100
times is that BEC-Guard is designed with the assumption
that the organization is already using at a spam ﬁlter, which
provides protection against volume-based attacks (e.g., the
default spam protection of Ofﬁce 365 or Gmail). Therefore, an
attacker that would send an email from an unknown address
more than 100 times to the same recipient would likely be
blocked by the spam ﬁlter. In fact, in our entire dataset, which
is only composed of post spam-ﬁltered emails, we have never
witnessed an attacker using the email address to impersonate
an employee more than 20 times. Note that we only used
this assumption for labeling the original training set, and do
not use it for ongoing retraining (since retraining is based on
customer reported attacks).
Impersonation classiﬁer.
In order to label training data for
the impersonation classiﬁer, we ran queries on the headers of
the raw emails to uncover all emails that might contain BEC
attacks under our labeling assumptions (see above). We then
labeled the results of all the queried emails as impersonation
emails, and all the emails that were not found by the queries
as legitimate emails.
Content classiﬁers. The training dataset for the content
classiﬁers is constructed by running a trained impersonation
classiﬁer on a fresh dataset, which is then labeled manually.
The initial training set we used for the content classiﬁers in-
cluded 300,000 impersonation emails from randomly selected
organizations over a year of data. Even within this training
data set, we were able signiﬁcantly further limit the number
of emails that needed to be manually labeled. This is due to
the fact that the vast majority of these emails were obviously
1298    28th USENIX Security Symposium
USENIX Association
not BEC attacks, because they were due to a legitimate web
services that impersonates a large number of employees (e.g.,
a helpdesk system sending emails on behalf of the IT staff).
After constructing the initial dataset, training content clas-
siﬁers is very straightforward, since we continuously collect
false negative and false positive emails from users and add
them into the training set. Note that we still manually review
these samples before retraining as a measure of quality con-
trol, to ensure that adversaries do not “poison” our training
set, as well as to make sure that users did not label emails
erroneously.
Sampling the dataset. Naïvely training a classiﬁer over an