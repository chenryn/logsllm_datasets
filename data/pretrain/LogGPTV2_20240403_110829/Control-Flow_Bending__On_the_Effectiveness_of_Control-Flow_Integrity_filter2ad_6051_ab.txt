gives the attacker some control over memory. In practice
there may be a set of speciﬁc constraints on what the at-
tacker can write where; however, this is not something
a defender can rely upon. To be a robust defense, CFI
mechanisms must be able to cope with arbitrary memory
corruptions, so in our threat model we allow the attacker
full control over memory once.
Limiting the memory corruption to a single point in
time does weaken the attacker. However, this makes our
attacks all the more meaningful.
Attacker goals. There are three kinds of outcomes an
attacker might seek, when exploiting a vulnerability:
1. Arbitrary code execution: The attacker can execute
arbitrary code and can invoke arbitrary system calls
with arbitrary parameters. In other words, the at-
tacker can exercise all permissions that the appli-
cation has. Code execution might involve injecting
new code or re-using already-existing code; from
the attacker’s perspective, there is no difference as
long as the effects are the same.
2. Conﬁned code execution: The attacker can exe-
cute arbitrary code within the application’s address
space, but cannot invoke arbitrary system calls. The
attacker might be able to invoke a limited set of sys-
tem calls (e.g., the ones the program would usually
execute, or just enough to send information back to
the attacker) but cannot exercise all of the applica-
tion’s permissions. Reading and leaking arbitrary
memory of the vulnerable program is still possible.
3. Information leakage: The attacker can read and leak
arbitrary values from memory.
Ideally, a CFI defense would prevent all three attacker
goals. The more it can prevent, the stronger the defense.
4 Deﬁnition of CFI ﬂavors
Control-Flow Integrity (CFI) [1, 15] adds a stateless
check before each indirect control-ﬂow transfer (indirect
jump/call, or function return) to ensure that the target lo-
cation is in a static set deﬁned by the control-ﬂow graph.
USENIX Association  
24th USENIX Security Symposium  163
3
4.1 Fully-Precise Static CFI
We deﬁne Fully-Precise Static CFI as follows: an in-
direct control-ﬂow transfer along some edge is allowed
only if there exists a non-malicious trace that follows that
edge. (An execution is not malicious if it exercises only
intended program behavior.)
In other words, consider
the most restrictive control-ﬂow graph that still allows all
feasible non-malicious executions, i.e., the CFG contains
an edge if and only if that edge is used by some benign
execution. Fully-precise static CFI then enforces that ex-
ecution follows this CFG. Thus, fully-precise static CFI
enforces the most precise (and most restrictive) policy
possible that does not break functionality.
We know of no way to implement fully-precise static
CFI: real implementations often use static analysis and
over-approximate the CFG and thus are not fully precise.
We do not design a better CFI scheme. The goal of our
work is to evaluate the strongest form of CFI that could
conceptually exist, and attempt to gain insight on its lim-
itations. This notion of fully-precise static CFI allows
us to transcend the recent arms race caused by defenders
proposing forms of CFI [9,28] and then attackers defeat-
ing them [5, 14, 16].
4.2 Practical CFI
Practical implementations of CFI are always limited by
the precision of the CFG that can be obtained. Cur-
rent CFI implementations face two sources of over-
approximation. First, due to challenges in accurate static
analysis,
the set of allowed targets for each indirect
call instruction typically depends only upon the function
pointer type, and this set is often larger than necessary.
Second, most CFI mechanisms use a static points-to
analysis to deﬁne the set of allowed targets for each in-
direct control transfer. Due to imprecisions and lim-
itations of the analysis (e.g., aliasing in the case of
points-to analysis) several sets may be merged, leading
to an over-approximation of allowed targets for individ-
ual indirect control-ﬂow transfers. The degree of over-
approximation affects the precision and effectiveness of
practical CFI mechanisms.
Previous work has classiﬁed practical CFI defenses
into two categories: coarse-grained and ﬁne-grained. In-
tuitively, a defense is ﬁne-grained if it is a close approx-
imation of fully-precise static CFI and coarse-grained if
there are many unnecessary edges in the sets.
4.3 Stack integrity
The seminal work on CFI [1] combined two mecha-
nisms: restricting indirect control transfers to the CFG,
and a shadow call stack to restrict return instructions.
The shadow stack keeps track of the current functions
on the application call stack, storing the return instruc-
tion pointers in a separate region that the attacker cannot
access. Each return instruction is then instrumented so
that it can only return to the function that called it. For
compatibility with exceptions, practical implementations
often allow return instructions to return to any function
on the shadow stack, not just the one on the top of the
stack. As a result, when a protected shadow stack is
in use, the attacker has very limited inﬂuence over re-
turn instructions: all the attacker can do is unwind stack
frames. The attacker cannot cause return instructions to
return to arbitrary other locations (e.g., other call-sites)
in the code.
Unfortunately, a shadow stack does introduce perfor-
mance overhead, so some modern schemes have pro-
posed omitting the shadow stack [9]. We analyze both
the security of CFI with a shadow stack and CFI without
a shadow stack. We assume the shadow stack is protected
somehow and cannot be overwritten; we do not consider
attacks against the implementation of the shadow stack.
5 Evaluating practical CFI
While there has been considerable research on how to
make CFI more ﬁne-grained and efﬁcient, most CFI pub-
lications still lack a thorough security evaluation. In fact,
the security evaluation is often limited to coarse metrics
such as Average Indirect target Reduction (AIR) or gad-
get reduction. Evaluating the security effectiveness of
CFI this way does not answer how effective these poli-
cies are in preventing actual attacks.
In this section, we show that metrics such as AIR and
gadget reduction are not good indicators for the effec-
tiveness of a CFI policy, even for simple programs. We
discuss CFI effectiveness and why it is difﬁcult to mea-
sure with a single value and propose a simple test that
indicates if a CFI policy is trivially broken.
5.1 AIR and gadget reduction
The AIR metric [44] measures the relative reduction in
the average number of valid targets for all indirect branch
instructions that a CFI scheme provides: without CFI, an
indirect branch could target any instruction in the pro-
gram; CFI limits this to a set of valid targets. The gadget
reduction metric measures the relative reduction in the
number of gadgets that can be found at locations that are
valid targets for an indirect branch instruction.
These metrics measure how effectively a CFI imple-
mentation reduces the set of valid targets (or gadgets) for
indirect branch instructions, on average. However, they
fail to capture both (i) the target reduction of individual
locations (e.g., a scheme can have high AIR even if one
164  24th USENIX Security Symposium 
USENIX Association
4
branch instruction has a large set of surplus targets, if
the other locations are close to optimal) and (ii) the im-
portance and risk of the allowed control transfers. Simi-
larly, the gadget reduction metric does not weight targets
according to their usefulness to an attacker: every code
location or gadget is considered to be equally useful.
For example, consider an application with 10MB of
executable memory and an AIR of 99%. An attacker
would still have 1% of the executable memory at their
disposal — 100,000 potential targets — to perform code-
reuse attacks. A successful ROP attack requires only
a handful of gadgets within these potential targets, and
empirically, 100,000 targets is much more than is usu-
ally needed to ﬁnd those gadgets [35]. As this illustrates,
averages and metrics that are relative to the code size can
be misleading. What is relevant is the absolute number of
available gadgets and how useful they are to an attacker.
5.2 CFI security effectiveness
Unfortunately, it is not clear how to construct a sin-
gle metric that accurately measures the effectiveness of
CFI. Ideally, we would like to measure the ability of
CFI to stop an attacker from mounting a control-ﬂow hi-
jack attack. More speciﬁcally, a CFI effectiveness met-
ric should indicate whether control-ﬂow hijacking and
code-reuse attacks are still possible under a certain at-
tacker model or not, and if so, how much harder it is for
an attacker to perform a successful attack in the presence
of CFI. However, what counts as successful exploitation
of a software vulnerability depends on the goals of the
attacker (see Section 3) and is not easily captured by a
single number.
These observations suggest that assessing CFI effec-
tiveness is hard, especially if no assumptions are made
regarding what a successful attack is and what the binary
image of the vulnerable program looks like.
5.3 Basic exploitation test
We propose a Basic Exploitation Test (BET): a simple
test to quickly rule out some trivially broken implemen-
tations of CFI. Passing the BET is not a security guar-
antee, but failing the BET means that the CFI scheme is
insecure.
In particular, the BET involves selecting a minimal
program — a simple yet representative program that con-
tains a realistic vulnerability — and then determining
whether attacks are still possible if that minimal pro-
gram is protected by the CFI scheme under evaluation.
The minimal program should be chosen to use a subset
of common run-time libraries normally found in real ap-
plications, and constructed so it contains a vulnerability
that allows hijacking control ﬂow in a way that is seen
in real-life attacks. For instance, the minimal program
might allow an attacker to overwrite a return address or
the target of an indirect jump/call instruction.
The evaluator then applies the CFI scheme to the mini-
mal program, selects an attacker goal from Section 3, and
determines whether that goal is achievable on the pro-
tected program. If the attack is possible, the CFI scheme
fails the BET. We argue that if a CFI scheme is unable
to protect a minimal program it will also fail to protect
larger real-life applications, as larger programs afford the
attacker even more opportunities than are found in the
minimal program.
5.4 BET for coarse-grained CFI
We apply the BET to a representative coarse-grained CFI
policy. We show that the scheme is broken, even though
its AIR and gadget reduction metrics are high. This
demonstrates that AIR and gadget reduction numbers are
not reliable indicators for the security effectiveness of a
CFI scheme even for small programs. These results gen-
eralize the conclusion of recent work [5,14,16], by show-
ing that coarse-grained CFI schemes are broken even for
trivially small real-life applications.
Minimal program and attacker goals. Our mini-
mal vulnerable program is shown in Figure 1.
It is
written in C, compiled with gcc version 4.6.3 under
Ubuntu LTS 12.04 for x86 32-bit, and dynamically
linked against ld-linux and libc. The program con-
tains a stack-based buffer overﬂow. A vulnerability in
vulnFunc() allows an attacker to hijack the return tar-
get of vulnFunc() and a memory leak in memLeak()
allows the attacker to bypass stack canaries and ASLR.
Coarse-grained CFI policy. The coarse-grained CFI
policy we analyze is a more precise version of several
recently proposed static CFI schemes [43, 44]: each im-
plementation is less accurate than our combined version.
We use a similar combined static CFI policy as used in
recent work [14, 16].
Our coarse-grained CFI policy has three equivalence
classes, one for each indirect branch type. Returns and
indirect jumps can target any instruction following a call
instruction. Indirect calls can target any deﬁned symbol,
i.e., the potential start of any function. This policy is
overly strict, especially for indirect jumps; attacking a
stricter coarse-grained policy makes our results stronger.
Results. We see in Table 1 that our minimal program
linked against its libraries achieves high AIR and gad-
get reduction numbers for our coarse-grained CFI pol-
icy. However, as we will show, all attacker goals from
Section 3 can be achieved.
USENIX Association  
24th USENIX Security Symposium  165
5
# include 
# include 
# define STDIN 0
void memLeak () {
char buf [64];
int nr , i ;
u n s i g n e d int * value ;
value = ( u n s i g n e d int *) buf ;
scanf ( " % d " , & nr );
for ( i = 0; i  Š " );
memLeak ();