title:Privacy through Noise: A Design Space for Private Identification
author:Karsten Nohl and
David Evans
2009 Annual Computer Security Applications Conference
Privacy through Noise:
A Design Space for Private Identiﬁcation
Karsten Nohl
University of Virginia
PI:EMAIL
David Evans
University of Virginia
PI:EMAIL
Abstract—To protect privacy in large systems, users
should be able to authenticate against a central server
without disclosing their identity to others. Private identi-
ﬁcation protocols based on public key cryptography are
computationally expensive and cannot be implemented on
small devices like RFID tags. Symmetric key protocols,
on the other hand, provide only modest levels of privacy,
but can be efﬁciently executed on servers and cheaply
implemented on devices. The privacy of symmetric-key
privacy protocols derives from the fact that an attacker
only ever knows a small fraction of the keys in a system
while the legitimate reader knows all keys. We propose
to amplify this gap in the ability to distinguish users by
adding noise to user responses. We focus on scenarios
where an attacker is not able to acquire multiple different
reads known to be from the same device, and justify this
threat model by proposing a simple modiﬁcation to RFID
tag designs. In such scenarios, we can use noise to blur
the borders between groups of users that the attacker
would otherwise be able to distinguish. We evaluate the
effectiveness and cost of this randomization and ﬁnd that
the information leakage from the tree protocol can be
decreased to two thousandths of its original value with 150
times the number of server-side cryptographic operations
and minimal cost to the tag. Degrees of privacy up to those
achieved by public key protocols can be reached while
staying well below the cost of public key cryptography.
I. INTRODUCTION
The need for an ever-growing number of small de-
vices and tokens to identify or authenticate creates a per-
manent threat to privacy. To preserve privacy, users need
to be able to identify themselves to a legitimate server
without disclosing their identity to unauthorized readers.
Private identiﬁcation can be achieved through public key
cryptography. Public key encryption, however, cannot
be implemented on small devices. Hardware implemen-
tations of public key ciphers are at least six orders of
magnitude larger or slower than symmetric primitives
such as block ciphers, stream ciphers, and hash func-
tions. Radio-readable credit cards are one example of
a large-scale system where lack of privacy protection
has raised some alarm [7]. The resource constraints
of these contactless credit cards and the increasingly
large number of issued cards require a privacy solution
that scales gracefully and comes at little extra cost per
card. However, privacy protocols speciﬁcally designed
to support the area, power, and scalability constraints
of large RFID systems have repeatedly been shown to
disclose too much information [2][19][14][9].
We propose a new threat model for private identiﬁca-
tion systems in which an attacker is not able to interact
with a particular tag for a prolonged period of time.
This assumption is realistic since it is already assumed
that there is no physical security on the tags; an attacker
who acquires physical access to a tag can easily extract
all key material from the tag. In scenarios where it is
safe to assume an attacker cannot knowingly conduct
repeated interactions with the same tag, our randomized
protocol provides design choices on the trade-off curve
between scalability and privacy that lie between current
RFID protocols and public key protocols.
Several RFID privacy protocols have been proposed
for low-security RFID applications such as retail logis-
tics, where readings are frequent and data has to be
available instantly (e.g., [12]). These protocols are cheap
for both the tag and the server. Whether private iden-
tiﬁcation protocols need to be particularly inexpensive
on the server side is an open point of discussion. Ap-
plications such as credit card transactions, for example,
already involve extensive server computation for fraud
detection. Privacy protocols for these applications can
hence be more expensive for the server.
Our protocol improves upon the Molnar-Wagner tree-
based RFID privacy protocol in which each user is
assigned several secrets, many of which are shared with
some of the other users [12]. The tree protocol provides
only modest levels of privacy since an attacker who
steals secrets from one user can distinguish groups of
other users. We improve the privacy of the tree protocol
by ﬂipping a random set of bits in user messages. The
randomization increases the server cost, but never leads
to an incorrect or failed identiﬁcation since it is not done
at the last level of the tree.
The idea of using noise to improve a property of a
cryptographic process is inspired by HB protocols that
use randomization to make a function non-invertible [8].
In our protocol, we add noise to the output of a one-
way function to gain privacy. The ideas are orthogonal
and can be combined by using an HB function as the
1063-9527/09 $26.00 © 2009 IEEE
DOI 10.1109/ACSAC.2009.55
518
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:09:25 UTC from IEEE Xplore.  Restrictions apply. 
one-way function in our protocol.
Contributions. The primary contribution of this
paper is the development and analysis of a new way
of providing privacy for a class of large-scale, low-cost
identiﬁcation systems. In particular:
ࢫ We provide a deﬁnition for private identiﬁcation
protocols and introduce a distinguishability game
for measuring the privacy of a private identiﬁcation
protocol (Section II-B). We provide a metric for
evaluating the privacy of a private identiﬁcation
based on a reﬁnement of a metric that was intro-
duced in [15] (Section II-C).
ࢫ We describe a new threat model for limited inter-
action systems (Section II-A).
ࢫ We introduce the randomized tree protocol (Sec-
tion III), and analyze its privacy properties of the
randomized tree protocol (Section III-A). We also
consider the privacy properties under a stronger
threat model
in which an attacker can perform
multiple reads with a target tag (Section III-C).
ࢫ We present and analyze an alternate version of the
protocol that takes advantage of selective random-
ization (Section III-B).
ࢫ We analyze the costs of the protocol, including
results from simulations and a closed-form approx-
imation of the server workload (Section IV).
II. PRIVATE IDENTIFICATION
In various applications, including radio-enabled credit
cards, protocols are needed to protect the user’s privacy.
These protocols must be efﬁciently implementable on
identiﬁcation tokens and must not lead to prohibitive
computational overhead for the back-end server.
A. Threat Model
We assume an attacker who is motivated to track
individuals based on the tagged items they carry. The
attacker’s goal is to distinguish between tags as accu-
rately as possible to build a proﬁle of individual users.
Attackers do not necessarily need to uniquely identify a
tag to obtain information useful in building a user proﬁle
since they can combine protocol-level information with
contextual information and combine data from multiple
tags carried by the same user. Hence, an attacker can
succeed by distinguishing tags in small groups rather
than by uniquely identifying tags.
The attacker can set up rogue readers at various
locations such as doorways, and can carry a portable
rogue reader in a backpack. In addition, we assume
attackers can acquire many tags and acquire the secrets
stored on those tags. Note that an attacker who can
physically plant a tag on an individual can easily track
that individual; hence, there is little value in designing
a protocol to resist attacks that involve physical access
519
to a tag that returns to the system. We further assume
that the time an attacker can surreptitiously interact with
a isolated tag is limited. An attacker may be able to
interact with a tag for a short while by standing near the
user with a backpack, but would not be able to do this
for a prolonged period without raising some suspicion.
As another example, if privacy paranoid users put their
tag-enabled cards in a Faraday-cage wallet the tags are
only exposed for the short period of time when they are
taken out for use.
Passive RFID tags can easily be designed to impose a
time limit between separate readings so that an attacker
would need prolonged access to an isolated tag to
obtain multiple readings known to come from the same
tag. To prevent an attacker from collecting a large
number of readings, while maintaining the functionality
of the tag, a tag should respond with the same message
when queried multiple times in the same location, but
should respond with different messages when queried
in different locations. This behavior can be achieved
for RFID tags by storing the once-computed and ran-
domized hash in capacitor-backed RAM. When the tag
has left the reader ﬁeld for some time, the capacitor
is depleted and the stored value is lost. A new hash
is then generated on the next query. This behavior will
prevent an attacker from learning several responses that
are known to be from the same user, which is essential
for the randomization technique proposed in this paper
to be effective.
Security researchers are rightfully wary of assump-
tions that limit attacker capabilities, and we must be
careful to not overestimate the security of a solution
in situations where these limits on attackers may not
hold. On the other hand, when such assumptions can
be established they enable new types of solutions. The
approach of assuming restrictions on attacker capabili-
ties to enable otherwise unattainable security properties
was previously used by Bailey, et al. [3]. In their case,
the goal was to ﬁnd a protocol that can provide both
public guarantees that there are no covert channels and
identiﬁcation privacy. The two goals are incompatible,
and it is provably impossible to attain both with a strong
attacker model. By restricting the attacker model to an
attacker who can only sporadically interact with a tag,
they were able to develop a protocol that provides both
identiﬁcation privacy and public guarantees that there
are no covert channels. In our case, limiting the number
of interactions an attacker can have with a known tag
enables a protocol with enhanced privacy at limited cost.
For many scenarios, this threat model is realistic given
the capacitor hardware modiﬁcation; in Section 3.3, we
analyze the impact of relaxing this threat model.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 25,2021 at 13:09:25 UTC from IEEE Xplore.  Restrictions apply. 
with which an attacker can distinguish two different
users on average:
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ࣘ ε
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
B. Deﬁnition
The goal of a private identiﬁcation protocol is to
enable legitimate readers to correctly identify users,
while preventing rogue readers and eavesdroppers from
learning user identities. Private identiﬁcation protocols
should provide low levels of information disclosure and
high levels of indistinguishability among users.
A private identiﬁcation protocol takes two inputs: a
secret key, s, and a random nonce, r, that is produced
on the identiﬁcation token and send to the reader. It
produces an output, h, that can be used by a legitimate
reader to identify the user. The output is typically a
one-way hash that hides the key: h ࢎ P sr.
The legitimate reader has a set of secrets, S, and must
be able to efﬁciently determine s given h and r. Rogue
readers do not have access to S. Without knowledge of
S, obtaining h and r must leak very little information
about s. The legitimate reader secret, S, could be a set of
keys (as in the hash protocols discussed in this paper),
or a single private key (as in a public-key protocol).
The ﬁrst requirement for private identiﬁcation proto-
cols is correctness. A legitimate reader should be able
to efﬁciently and correctly identify the sender, s, given
knowledge of S, h, and r. For scalability, the search for
the correct key should be fast on average and should
grow much slower than linearly in the number of users.
The second requirement is privacy, which we for-
malize using the distinguishability game. A private
identiﬁcation protocol must allow an attacker at most
a small advantage in the following game:
Distinguishability Game. The attacker is given four
values: two input nonces, r0 and r1, and two responses,
x0 and x1. The attacker is then asked to decide between
two different cases for how these values were generated:
1) One secret key, s: h0  Psr0, h1  Psr1.
2) Two secret keys, s0 ࢧ s1: h0  Ps0r0, h1 
Ps1r1.
In the ﬁrst case, the protocol is run twice with the
same key but different nonces. In the second case,
two keys and nonces are randomly chosen and the
protocol is run on different keys and nonces. In each
case,
the distinguisher only gets to see the random
nonces and the protocol output but not the secret keys.
The distinguisher then has to decide whether two given
responses were generated from two different secrets (in