rough understanding of the design of AFL. Generally speaking,
fuzzers from the AFL family have three important components:
(i) the queue, (ii) the bitmap, and (iii) the mutators. The queue
is where all inputs are stored. During the fuzzing process,
an input is picked from the queue, fuzzed for a while, and,
eventually, returned to the queue. After picking one input, the
mutators perform a series of mutations. After each step, the
mutated input is executed. The target is instrumented such that
the coverage produced by the input is written into a bitmap. If
the input triggered new coverage (and, therefore, a new bit
is set in the bitmap), the input is appended to the queue.
Otherwise, the mutated input is discarded. The mutators are
organized in different stages. The ﬁrst stages are called the
deterministic stages. These stages are applied once, no matter
how often the input is picked from the queue. They consist
of a variety of simple mutations such as “try ﬂipping each
bit”. When the deterministic stages are ﬁnished or an input
is picked for the second time, the so called havoc phase is
executed. During this phase, multiple random mutations are
applied at the same time at random locations. Similarly, if the
user provided a dictionary with interesting strings, they are
added in random positions. Linked to the havoc stage is the
splicing stage, in which two different inputs are combined at
a random position.
III.
INPUT-TO-STATE CORRESPONDENCE
In this section, we introduce a novel fuzzing method
based on the insight that programs have a strong input-to-state
correspondence. We observe that—for a very large number of
programs—values from the input are directly used at various
states during the execution. By observing these values, we
can perform educated guesses as to which offsets to replace
(resembling a very lightweight taint tracking) and which value
to use (similar to symbolic execution based approaches). We
can exploit
this relation to deal with challenging fuzzing
problems such as magic bytes and (even nested) checksums.
We explain the different building blocks of our method and
discuss how they address the challenging fuzzing problems
we introduced earlier.
A. Magic Bytes
The ﬁrst roadblock we tackle are magic bytes. A typical ex-
ample for this class of fuzzing problems is shown in Listing 2;
it represents an excerpt of our running example introduced in
Listing 1. It should be noted that—while we use ASCII values
for readability in our example—input-to-state correspondence
is also very applicable to binary formats.
if(u64( input )== u64(" MAGICHDR "))
bug (1);
Listing 2: Fuzzing problem (1): ﬁnding valid input to bypass magic bytes.
These constructs are hard to solve for feedback-driven fuzzers
since they are very unlikely to guess a satisfying input; in
this case the 64-bit input MAGICHDR. Existing approaches [16],
[23], [34], [35], [38], [40] often use taint tracking and symbolic
execution, both of which incur a certain performance overhead.
An orthogonal approach are user-deﬁned dictionaries [43] that
TABLE I: Extracting the set of mutations from a comparison observed at
run-time, using little-endian encoding.
== u64(“MAGICHDR”)
“TestSeedInput”
u64(input)
C-Code
Input
“deeStesT”
Observed (ASCII)
“deeStesT”
Variations for  comparisons
Mutations after little- 
“LAGICHDR”>
“NAGICHDR”>
represent expert knowledge about
the program under test.
Lastly, there are approaches that split multi-byte comparisons
into many one-byte comparisons. Fuzzers are then able to
solve individual bytes. The prime example is LAF-INTEL [2],
which is very efﬁcient at solving multi-byte compares, but
needs source level access to modify the program. Another
tool is STEELIX [31], which does not depend on access to the
source code. Instead, it uses dynamic binary instrumentation to
split large comparisons into smaller ones. Unfortunately, this
approach has a large performance overhead. The authors of
STEELIX reported that LAF-INTEL performs over 7 times as
many executions per second.
We propose the following lightweight approach based on
input-to-state correspondence to handle magic bytes in a fully
automated manner: we exploit the fact that values from the
program state often directly correspond to parts of the input.
Each time we encounter a new path, we hook all compare
instructions and perform a single trace run. If we encounter a
comparison with distinct arguments, we extract both arguments
and create a custom mutation , as we
explain below. The different steps are illustrated in Table I.
i) Tracing. When we start fuzzing a new input (before entering
the deterministic stage of KAFL), we perform a single run
in which we hook all compare instructions and extract the
arguments. This includes some instructions that are emitted by
compilers to replace plain compare instructions or switch-case
structures (by calculating offsets in jump tables). Additionally,
we hook all call instructions, as functions might implement
string comparisons and similar functionality. More details are
given in Section IV.
Example 1. Consider “TestSeedInput” as input for the
code in Listing 2. The compare instruction checks if the ﬁrst 8
bytes from the input, interpreted as an unsigned 64-bit value,
are equal to the 64 bit unsigned interpretation of the string
“MAGICHDR”. As integers are typically encoded in little endian
format, the ASCII representations of the ﬁnal values used in
the comparison are “deeStesT” and “RDHCIGAM”.
ii) Variations. At runtime, we do not know which ﬂags are
checked after the comparison; we cannot distinguish different
comparison operations such as “lower than” and “equal to”.
Therefore, we apply some variations to the compared value
such as addition and subtraction by one. As a side effect of this
heuristic, we empirically found that this approach increases the
probability of triggering off-by-one bugs.
4
Example 2. In this case, we add and subtract 1 to/from
“RDHCIGAM” and obtain “RDHCIGAL” and “RDHCIGAN”.
iii) Encodings. It is likely that the input has been processed in
different ways before reaching the actual comparison. In order
to handle the most common cases of input en-/decoding and
to create more mutation candidates, we apply various different
encodings to the mutation. Examples for these encodings are
inverting zero extensions or endianness conversions.
Example 3. We apply a little-endian encoding to our
current mutations “RDHCIGAM”, “RDHCIGAL” and obtain
“MAGICHDR”, “LAGICHDR” and “NAGICHDR”.
We observe that, generally, only a few primitive encoding
schemes are required. By far the most common occurrence is
a one-to-one mapping between input values and state values.
In detail, the encodings we used in our experiments are:
•
•
•
Zero/Sign Extend(n): the value is interpreted as little
endian integer with zero or sign extension, leading
bytes are stripped to produce a n byte version of
the pattern, if applicable. When no size change takes
place, this encoding is also called plain encoding.
Reverse: all little endian encoding schemes also have
a big endian equivalent.
C-String: the value is a C string, and everything after
the ﬁrst 0 byte is removed.
• Memory(n): the value is treated as an argument to
a function similar to memcmp. Consider only the ﬁrst
n ∈ {4, 5, . . . , 32} bytes.
ASCII: the integer value is encoded as ASCII digits.
•
After manually evaluating the coverage produced by our
fuzzer, we believe that the aforementioned set of encoding
schemes covers the largest part of the common cases in real-
world applications. In the rare cases where these encodings do
not sufﬁce, the set of encodings can also be considered as user
input, similar to the dictionary in other fuzzing systems. In that
case, the user can easily provide own, more speciﬁc encoding
schemes. This step can be seen as a lightweight variant of
a synthesis algorithm used to guess the symbolic state at the
current position. In fact, this approach has one major advantage
compared to other approaches for inferring how the input
inﬂuences the state (such as symbolic execution or program
synthesis); it is very easy to represent complex operations such
as converting decimal ASCII numbers to integers. This is due
to the fact that we only ever need to perform the encoding on
concrete values instead of querying SMT solvers with symbolic
values.
iv) Application. Finally and most importantly, we use the
pattern of a mutation  to identify the
parts of the input that are to be replace with the mutation
repl. In contrast to other approaches such as ANGORA or
STEELIX, we apply the whole pattern at once. This has two
advantages: It works for atomic comparisons without further
modiﬁcation/hooking of the target and it drastically reduces the
number of candidate positions at which to try the replacement.
Example 4. Only the substring “TestSeed” of the input
“TestSeedInput” is compared to “MAGICHDR”. Therefore,
we replace only this part with the generated mutations. This
yields the new testcase “MAGICHDRInput”, and by the vari-
ants introduced to solve inequalities: “LAGICHDRInput” and
“NAGICHDRInput” (as well as potentially more inputs for
other encoding schemes).
v) Colorization. We found that the number of candidate posi-
tions to apply a patch is sometimes rather large. For example,
the smallest valid ext4 ﬁle system image is 64 KB and mostly
consists of long strings of zero bytes. Comparing a single
zero value with some constant will yield more than 60, 000
possible positions. During our evaluation, we found that those
comparisons occur rather frequently. Hence we devised an efﬁ-
cient procedure to increase the number of random bytes in the
input. More entropy in the input reduces the space of possible
positions. Using this “colored” copy of the input drastically
reduces the number of candidate positions, usually by multiple
orders of magnitude. After generating a colorized version, we
only apply mutations where the pattern part was found at
the same offset in both inputs. As a result, the remaining
number of mutations to apply is reduced drastically. In our
evaluation, we found that the number of mutations introduced
by this approach is typically two orders of magnitude smaller
than the number of deterministic mutations performed by AFL
on the same input.
Example
input
“ZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZ” in our running
example. Amongst the mutations, we would ﬁnd . This mutation can be applied at many (24)
different positions. Therefore, we try to replace as many
characters as possible without changing the execution path.
In this case, the colorized version might be any random string
of bytes (such as “QYISLKFYDBYYSYWSIBSXEAXOKHNRUCYU”).
Correspondingly, on a rerun,
the same instruction would
yield the mutation: , which is only
applicable at the ﬁrst position. Thus, we only produce one
candidate at position 0.
that we are
5. Assume
testing the
vi) Strings and Memory. Besides the aforementioned integer
comparisons, programs often use functions to compare two
strings or the content of byte arrays. Similarly, these tests
often pose signiﬁcant challenges to fuzzers. To overcome such
constructs, we also hook all function calls. If the function
takes at least two pointer arguments, we extract the ﬁrst 128
bytes which are pointed to and treat them similarly to integers.
However, we use a different set of encodings for memory
content than for integers, most notably we either assume that
only the ﬁrst n ∈ {4, 5, . . . , 32} bytes are compared (functions
similar to memcmp) or all bytes up to the ﬁrst null byte
(functions from the strcmp family).
vii) Input Speciﬁc Dictionary. Lastly, we add values that
contain many consecutive non-zero or non-0xff bytes to a
speciﬁc dictionary. The strings found this way will only be
used during the havoc phase of the current input. This allows
us to use values passed to functions whose inner workings are
similar to comparisons while using non-trivial algorithms such
as hashtable lookups. In a way, this is a much stronger version
of the well-known trick to extract the output of the strings
tool and use it as a dictionary for the fuzzing run since we
5
include dynamically computed strings, but not strings that are
not relevant on this path.
B. Checksums
Another common challenge for fuzzers is to efﬁciently fuzz
beyond checksums. A typical example for this challenge is
depicted in Listing 3, which again represents an excerpt of
our running example introduced in Listing 1.
if(u64( input )== sum( input +8, len -8))
if(u64( input +8) == sum( input +16 , len -16) )
if( input [16]== ’R’ && input [17]== ’Q’)
bug (2);
Listing 3: Fuzzing problem (2): ﬁnding valid input to bypass checksums.
such
as
Existing
approaches
[18],
TAINTSCOPE [40] or T-FUZZ [34] all rely on the same
idea: remove the hard checks and ﬁx them later. TAINTSCOPE
and T-FUZZ both detect critical checks automatically and,
then, use symbolic execution to ﬁx the checks once interesting
behavior was found.
FLAYER
We propose replacing the taint
tracking and symbolic
execution used in TAINTSCOPE and T-FUZZ with the following
procedure based on input-to-state correspondence: First, we
identify comparisons that appear to be similar to checksum
checks (e.g., one side is an input-to-state corresponding value,
the other side changes regularly). Then, we replace the check
with a comparison that always evaluates to true. Once the
fuzzing process on this patched program produced a seemingly
interesting path, we enter a validation mode. In this mode,
we use the techniques described in the previous section to
correct all patched comparisons. If this succeeds, we continue
as before; otherwise, we learn that one comparison is not under
our control and we remove the patch for this instruction to
avoid performing unnecessary validation steps in the future.
Based on the idea of input-to-state correspondence, we
are able to automatically infer which instructions to patch.
Additionally, we can automatically repair the inputs without
using human intervention or the complex primitives of taint
tracking and symbolic execution. During feedback fuzzing, we
ﬁx any newly found input (in contrast to TAINTSCOPE and
T-FUZZ). This ensures that no false positives are stored in
the queue. As an additional beneﬁt, this allows to share the
queue with other tools. In the following, we discuss details
of the process of selecting, patching, and validating suspected
checksums with a focus on hashes and hash-like computations.
i) Identiﬁcation. The ﬁrst step happens during the processing
of magic bytes, as described in Section III-A. This results
in a list of comparisons and the values compared in all
different colorized versions of the input. We use the following
heuristic to ﬁlter the comparison instructions for interesting
patch candidates related to checksums:
1) We are able to ﬁnd the left-hand side of our mutation
pattern in all inputs using the same encoding.
Neither argument is an immediate value.
pattern changes during the colorization phase (this
is similar to the constraint that TAINTSCOPE uses: the
value depends on many input bytes).
2)
3)
The intuition behind these checks is as follows: We ob-
served that an instruction produced the mutation . Assume pattern is a ﬁeld from the input, and repl
is the hash computed over a part of the input. In a checksum
comparison, the left-hand side should always be part of the
input and replacing large parts of the input with random values
during the colorization should change the hash (and therefore
repl). Similarly, both arguments cannot be immediate values
if pattern is a value from the input and repl is the hash
calculated over some part of the input. Obviously,
this is
an over-approximation and we sometimes ﬁnd checks that
are not part of an actual checksum. Therefore, this approach
has a signiﬁcant drawback: The removed instructions can be
relevant bounds checks and removing them could introduce
false positives (i.e., erroneous new coverage) or even cause the
program to crash later on. We thus introduce a validation phase
to weed out potential false positives and identify compare
instructions that must not be patched. After the fuzzer ﬁnds
a new input and before we store it in the queue, we try to
ﬁx all patched compare instructions. If we identify a patch
that the fuzzer cannot ﬁx automatically, we remove the patch
immediately. Additionally, we discard the input before it ever
reaches the queue. This ensures, that we do not waste time with
patches that we cannot ﬁx easily and that no false positives
are produced: each input is validated with the unmodiﬁed
executable.
ii) Patching. After we identiﬁed a set of suspected hash
checks, we replace the instructions by patches which have
the same side effects of a successful comparison. Obviously,
this may lead to an undesired behavior: we might accidentally
remove bound checks or make paths reachable that cannot
be triggered without our patches. Nonetheless, we continue