model for communication is difficult to express in procedure-based
semantics offered by tools that target game-based proofs.
To overcome these difficulties, we propose a new approach to
machine-checking UC proofs that shares many features of the sim-
plified version of UC proposed by Canetti, Cohen and Lindell in [19].
As in [19], we statically fix the machines/modules in the execution
model and we allow an adversarial entity to control which module
gets to be executed next, rather than allowing machines to pass
control between them more freely as in the original UC execution
model. The crucial difference to the ITM execution model is that the
above interactions are procedure-based, which means that when-
ever the environment passes control to the protocol, the internal
protocol structure will follow a procedure call tree that guarantees
(excluding the possibility of non-terminating code) that control re-
turns to the environment.5 As in [19], we lose some expressiveness,
but we do not go as far as hard-wiring a specific communications
model for protocols based on authenticated channels; instead, we
leave it to the protocol designer to specify the communications
model by using an appropriate module structure. We recover the
authenticated communications model of [19] by explicitly defining
a hybrid real-world, in which concrete modules for ideal authen-
ticated channels are available to the communicating parties. We
discuss the trade-offs associated with our approach more in depth
at the end of this section, drawing a parallel to the work in [20].
5.1 Mechanized Formalization in EasyCrypt
We propose a natural simplification of the UC execution model that
is based on EasyCrypt modules and show that this opens the way
for a lightweight formalization of UC proofs. This formalization
has been conducted in our extension of EasyCrypt (the proofs of
the lemmas and theorems of this section are fully mechanized).
Protocols and Functionalities as EasyCrypt modules. The basic
component in our UC execution model is a module of type PRO-
TOCOL given in Figure 7. Inhabitants of this type represent a full
real-world configuration—a distributed protocol executed by a fixed
number of parties—or an ideal-world configuration—an ideal func-
tionality executing a protocol as a trusted-third party. The type of
a protocol has a fixed interface, but it is parametric on the types of
values exchanged via this interface. The fixed interface is divided
into three parts: i) init allows modeling some global protocol setup;
ii) IO captures the interaction of a higher level protocol using this
5Intuitively, the UC model expresses a single line of execution using a token-passing
mechanism that allows one machine to transfer computational resources to another,
and even to create new machines. In our setting, resource analysis is much simpler. All
modules representing honest and adversarial entities are fixed from the start and the
cost model is concrete: all adversarial entities have a resource usage type, which means
they are known to execute a maximum number of operations and perform a bounded
number of procedure calls. Hence the resources used by any subset of modules in our
formalizations can be expressed as an expression on these type parameters.
Session 10B: Crypto and Protocol Security CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2548module type IO = {
proc inputs (i:inputs) : unit
proc outputs(o:ask_outputs)
: outputs option }.
module type BACKDOORS = {
proc step (m:step) : unit
proc backdoor (m:ask_backdoor)
: backdoor option }.
module type E_INTERFACE = {
include IO
include BACKDOORS }.
module type PROTOCOL = {
proc init() : unit
include E_INTERFACE }.
Figure 7: PROTOCOL type in EasyCrypt.
module UC_emul (E:ENV) (P:PROTOCOL) = {
proc main() = {
var b;
P.init(); b ← E(P).distinguish(); return b; }}.
module CompS(F:IDEAL.PROTOCOL, S:SIMULATOR) : PROTOCOL = {
proc init() = { F.init(); S(F).init(); }
include F [ inputs, outputs]
include S(F) [step, backdoor]}.
Figure 8: Execution model for real/ideal worlds (top) and
composition of functionality with a simulator (bottom).
protocol as a sub-component; and iii) BACKDOORS captures the
interaction of an adversary with the protocol during its execution.
When we define real-world protocols, a module of type PROTO-
COL will be constructed from sub-modules that emulate the various
parties and the communications channels between them. In this
case, BACKDOORS models adversarial power in this communication
model. For ideal-world protocols, a PROTOCOL is typically a flat
description of the ideal computation in a single module; here BACK-
DOORS models unavoidable leakage (e.g., the length of secret inputs
or the states of parties in an interactive protocol) and external in-
fluence over the operation of the trusted-third party (e.g., blocking
the computation to model a possible denial of service attack).6
Execution Model. The real- and ideal-world configurations are
composed by a statically determined set of modules, which com-
municate with each-other using a set of hardwired interfaces. The
execution model is defined by an experiment in which an external
environment interacts with the protocol via its IO and BACKDOORS
interfaces until, eventually, it outputs a boolean value (Figure 8).
The IO interface allows the environment to pass an input to the pro-
tocol using inputs or to retrieve an output produced by the protocol
using outputs. For example in the real-world, the environment can
use these procedures to give input to or obtain an output from one
of the sub-modules that represent the computing parties involved
in the protocol. The BACKDOORS interface allows the environment
to read some message that may be produced by the protocol us-
ing backdoor or make one of the protocol sub-components (parties)
advance in its execution using step to deliver a message.
We describe now the typical sequence of events in a real-world
execution; the ideal-world will become clear when we describe the
6Ideal-world backdoors are used to weaken the security requirements and are usually
tailored to bring the security definition down to a level that can be met by real-world
protocols. Note that the definition of meaningful ideal functionalities is a crucial aspect
of UC security theory; here we just provide a mechanism that permits formalizing
such definitions in EasyCrypt.
notion of UC emulation below. When the adversarial environment
uses the IO interface to pass input to a computing party, this may
trigger the computing party to perform some computations and, in
turn, provide inputs to other sub-modules included in the protocol
description; in most cases this will correspond to sending a message
using an idealized communications channel represented by an ideal
functionality.7 Our convention is that inputs calls do not allow
obtaining information back (the return type is unit). This means
that any outputs produced by parties need to be pulled by the
environment with separate calls to outputs. Similarly, when the
environment asks a party for an output, the party may perform
some computation and call the outputs interface of a hybrid ideal
functionality (e.g., to see if a message has been delivered) before
returning the output to the environment.
The BACKDOORS interface follows these conventions closely.
The backdoor method allows the environment to retrieve leakage
that may be available for it to collect (e.g., the public part of a
party’s state, or a buffered message in an authenticated channel).
The step procedure allows the environment to pass control to any
module inside the protocol; this is important to make sure that the
environment always has full control of the liveness of the execution
model and can schedule the execution of the various processes at
will whenever there are several possible lines of execution.
UC emulation. The central notion to Universal Composability is
called UC-emulation, which is a relation between two protocols π1
and π2: if π1 UC-emulates π2 with small advantage ϵ then π1 can
replace π2 in any context (within a complexity class).
Definition 5.1 (UC emulation). Protocol π1 UC emulates π2 under
complexity restrictions csim and cenv and advantage bound ϵ if
∃S ∈ τ
π1,π2,csim
sim
,∀Z ∈ τ
π1,π2,S,cenv
env
,
| Pr[Z(π1) :⊤] − Pr[Z(⟨π2 ∥ S(π2)⟩) :⊤] | ≤ ϵ
We write this as Advuc
csim,cenv(π1, π2) ≤ ϵ.
The first probability term corresponds to the event that the envi-
ronment returns true in the real-world execution model described
above, i.e., in game UC_emul parameterized with ENV = Z and
P = π1. The second probability term corresponds to the equivalent
event in the ideal-world (or reference) execution model where, as
shown in Figure 9 (right), π2 is typically an ideal functionality;
this corresponds to game UC_emul parameterized with ENV = Z
and a protocol P that results from attaching S to the BACKDOORS
interface of π2. We denote this ideal-world P by ⟨π2 ∥ S(π2)⟩, cor-
responding to the EasyCrypt functor CompS also shown in Figure 8.
UC-emulation imposes that a simulator S is capable to fool any
environment by presenting a view that is fully consistent with the
real-world, while learning only what the BACKDOORS interface
of π2 allows. If such a simulator exists, then clearly π2 cannot be
worse than π1 in the information it reveals to the environment via
its BACKDOORS interface.8 Our UC-emulation definition quanti-
7Real-world settings using ideal functionalities as sub-components are called hybrid.
8The emulation notions in [16, 17] quantify over a restricted class of balanced environ-
ments. Intuitively, such environments must be fair to the simulator in that polynomial-
time execution in the size of its inputs is comparable to the execution time of the
real-world adversary. Without this restriction, the definition would require the exis-
tence of a simulator that uses much less resources than the real-world attacker, which
makes the definition too strong. Balanced environments guarantee that the resources
Session 10B: Crypto and Protocol Security CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2549Lemma 5.1 (Transitivity). For all ϵ1,2, ϵ2,3 ∈ R
+, all protocols
π1, π2 and π3 s.t. the IO interfaces of all three protocols are of the
same type, all cost restrictions csim(1,2), csim(2,3) and all simulators
S1,2 ∈ τ
π1,π2,csim(1,2)
sim
Advuc,S1,2
csim(1,2), ˆcenv(1,2)(π1, π2) ≤ ϵ1,2 ⇒ Advuc,S2,3
, we have that:
, S2,3 ∈ τ
π2,π3,csim(2,3)
sim
csim(2,3), ˆcenv(2,3)(π2, π3) ≤ ϵ2,3
ˆcsim(1,3),cenv(1,3)(π1, π3) ≤ ϵ1,2 + ϵ2,3
⇒ Advuc
of the environment imposed by cenv is of the form:
cenv := compl[intr : c1,π .inputs : c2, π .outputs : c3,
π .backdoor : c4, π .step : c5]
where type refinements can set ci to depend on the types of other
modules in the context.
Warm-up: Transitivity of UC emulation. It is easy to show that
UC-emulation is a transitive relation: if π1 UC-emulates π2 and this,
in turn, UC-emulates π3, then π1 UC-emulates π3. When stating
this lemma in EasyCrypt we move the existential quantifications
over the simulators in the hypotheses to global universal quantifica-
tions; this logically equivalent formulation allows us to refer to the
memory of these simulators when quantifying over all adversarial
environments in the consequence: we quantify only over those
that cannot look inside the simulators that are assumed to exist by
hypothesis, which is a natural (and necessary) restriction. In other
examples we use the same approach. The lemma is stated in Easy-
Crypt as follows (we adapt the Advuc,S·,·
(·,·) notation by indicating
the universally quantified simulator S in superscript).
where ˆcsim(1,3) corresponds to the cost of sequentially composing S1,2
and S2,3, ˆcenv(2,3) must allow for an adversarial environment that
results from converting a distinguisher between π1 and π3 in cenv(1,3)
and composing it with S1,2, and ˆcenv(1,2) = cenv(1,3).
In the statement of the lemma we use notation ˆc to denote the
fact that these cost restrictions are fixed as a function of the costs
of other algorithms: intuitively, the cost of the environment in the
consequence is free and it constrains the costs of environments
in the hypotheses; then, if for some cost restrictions csim(1,2) and
csim(2,3) the hypotheses hold, these in turn fix the cost of the simula-
tor we give as a witness. This pattern is observable in the remaining
examples we give in this section.
From the proof, we get a witness simulatorS1,3 = SeqS(S2,3,S1,2)
that results from plugging together the two simulators implied by
the assumptions: intuitively, S2,3 is able to interact with π3 and
emulate the BACKDOORS of π2, and this is sufficient to enable S1,2
to emulate the BACKDOORS interface of π1, as required. Technically,
the proof shows first that one can break down S1,3 and put π2 in
the place of CompS(π3,S2,3). To show this, we aggregate S1,2 into
the environment to construct a new environment that would break
π2 if such a modification was noticeable, contradicting the second
hypothesis. The proof then follows by applying the first hypothesis.
Note that this proof strategy is visible in the resources used by
S1,3, since they are those required to run the composed module
SeqS(S2,3,S1,2). Moreover, the quantification over the resources of
the environments in the second hypothesis must accommodate an
environment that absorbs simulator S1,2 and runs it internally.
In Appendix A we give a more elaborate example of the proper-
ties of UC emulation definition, by showing that our formalization
Figure 9: Module restrictions. Arrows indicate ability to
make procedure calls via the interface specified as a label;
all other cross-boundary memory access is disallowed.
fies over simulators and environments using types that give a full
characterization of their use of resources, including the ability to
access memory, number and types of procedure calls and intrinsic
computational costs. The memory access restrictions are depicted
in Figure 9, and they can be easily matched to the standard restric-
tions in the UC framework. Not shown are the cost restrictions,
which give explicit bounds for the resources used by various parts
of the execution model; these are crucial for obtaining, not only a
meaningful definition, but also for obtaining meaningful reductions
to computational assumptions, as will be seen below.
Let us examine the types of Z and S in more detail. We first
note that the definition of emulation is parametric in the resource
restrictions csim and cenv. Clearly the IO interface of π2 must match
the type of the IO interface of π1, which is consistent with the goal
that π1 can replace π2 in any context, and this is enforced by our
type system. This need not be the case for the BACKDOORS interface
and, in fact, if π2 is an ideal functionality, the BACKDOORS interface
in the ideal world is of a different nature altogether than the one in
the real world: it specifies leakage and adversarial control that are
unavoidable even when the functionality is executed by a trusted
third-party on behalf of the parties. The type of the simulator S
is given by τ
, which defines the type of modules that has
access to the BACKDOORS interface of π2, exposes the BACKDOORS
interface of π1 and is restricted memory-wise to exclude the mem-
ory of π2 and resource-wise by csim. Note that, if S could look inside
the ideal functionality, then it would know all the information that
is also given to the real-world protocol: a trivial simulator would
always exist and the definition would be meaningless because all
protocols would be secure. The type of the environment is given by
π1,π2,S,cenv
, the type of modules that have oracle access to the IO
τ
env
and BACKDOORS interfaces of π1, and are restricted memory-wise
to exclude the memories of π1, π2 and S, and resource-wise by cenv.
In this case, if the environment could look inside π1, π2 or S it could
directly detect with which world it is interacting, and no protocol
would be secure. For concreteness, the cost restriction on the type
π1,π2,csim
sim
given to the simulator match those given to the real-world adversary; moreover, the
dummy adversary is formally explicit in the real-world to enable this resource ac-
counting. In our setting we deal with this issue differently: the EasyCrypt resource
model is concrete, which means that one can explicitly state in the security definition
which resources are used by the simulator and assess what this means in terms of
protocol security. We refer the interested reader to [16, Section 4.4] for a discussion