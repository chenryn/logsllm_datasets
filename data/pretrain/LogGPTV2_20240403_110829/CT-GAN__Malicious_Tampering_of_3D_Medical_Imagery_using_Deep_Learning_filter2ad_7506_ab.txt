iﬁes the threat of an attacker manipulating 3D medical imagery.
In summary, the contributions of this paper are as follows:
The Attack Model We are the ﬁrst to present how an attacker
can inﬁltrate a PACS network and then use malware
to autonomously tamper 3D medical imagery. We also
provide a systematic overview of the attack, vulnerabilities,
attack vectors, motivations, and attack goals. Finally,
we demonstrate one possible attack vector through a
penetration test performed on a hospital where we covertly
connect a man-in-the-middle device to an actual CT scanner.
By performing this pen-test, we provide insights into the
security of a modern hospital’s internal network.
Attack Implementation We are the ﬁrst to demonstrate
how GANs, with the proper preprocessing, can be used to
efﬁciently, realistically, and automatically inject/remove
lung cancer into/from large 3D CT scans. We also evaluate
how well the algorithm can deceive both humans and
USENIX Association
28th USENIX Security Symposium    463
D, while D is learning to catch every fake sample generated
by G. After training, D is discarded and G is used to generate
new samples.
A cGAN is a GAN which has a generator and discriminator
conditioned on an additional input (e.g., class labels). This
input extends the latent space z with further information
thus assisting the network to generate and discriminate
images better. In [17] the authors propose an image-to-image
translation framework using cGANs (a.k.a. pix2pix). There
the authors showed how deep convolutional cGANs can be
used to translate images from one domain to another. For
example, converting casual photos to a Van Gogh paintings.
One application of the pix2pix framework is in-painting;
the process of completing a missing part of an image. When
using pix2pix to perform in-painting, the generator tries to
ﬁll in a missing part of an image based on the surrounding
context, and its past experience (other images seen during
training). Meanwhile, the discriminator tries to differentiate
between completed images and original images, given the
surrounding context. Concretely, the input to G is a copy of
xr where missing regions of the image are replaced with zeros.
We denote this masked input as x∗
r . The output of G is the
completed image, visually similar to those in X. The input
to D is either the concatenation (x∗
r ,xr) or (x∗
r ;θg)). The
bottom of Fig. 2 illustrates the described cGAN. The process
for training this kind of GAN is as follows:
r ,G(x∗
Training Procedure for cGAN In-painting
Repeat for k training iterations:
1. Pull a random batch of samples xr ∈ X, and mask the
samples with zeros to produce the respective x∗
r .
2. Train D:
2.1. Forward propagate (x∗
2.2. Forward propagate (x∗
r ,xr) through D, compute the
error given the label y =0, and back propagate the
error through D to update θd.
r , G(x∗
r ; θg)) through D,
compute the error given the label y = 1, and back
propagate the error through D to update θd.
3. Train G:
3.1. Forward propagate x∗
r
through G and then
(x∗
r ,G(x∗
r ;θg)) through D, compute the error at the
output of D given the label y = 0, back propagate
the error through D to G without updating θd, and
continue the back propagation through G while
updating θg.
Although pix2pix does not use a latent random input z, it
avoids deterministic outputs by performing random dropouts
in the generator during training. this forces the network to
learn multiple representations of the data.
We note that there is a GAN called a CycleGAN [19] that can
directly translate images between two domains (e.g., benign↔
malign). However, we found that the CycleGAN was unable
to inject realistic cancer into 3D samples. Therefore, we opted
Figure 2: A schematic view of a classic GAN (top) and a
cGAN setup for in-painting.
machines: radiologists and state-of-the-art AI. We also show
how this implementation might be used by an attacker since
it can be automated (in the case of an air gapped system)
and is fast (in the case of an infected DICOM viewer).
Countermeasures We enumerate various countermeasures
which can be used to mitigate the threat. We also provide
the reader with best practices and conﬁgurations which can
be implemented immediately to help prevent this attack.
For reproducibility and further investigation, we have
published our tampered datasets and source code online5
along with a pen-test video.6
The remainder of the paper is organized as follows: First
we present a short background on GANs. Then, in section 3,
we review related works and contrast them ours. In section
4 we present the attack model and demonstrate one of the
attack vectors. In section 5, we present CT-GAN’s neural
architecture, its attack process, and some samples. In section
6 we evaluate the quality of the manipulations and asses the
threat of the attack. Finally, in sections 7 and 8 we present
countermeasures and our conclusion.
2 Background: GANs
The most basic GAN consists of two neural networks: the
generator (G) and discriminator (D). The objective of the
GAN is to generate new images which are visually similar to
real images found in a sample data distribution X (i.e., a set
of images). The input to G is the random noise vector z drawn
from the prior distribution p(z) (e.g., a Gaussian distribution).
The output of G, denoted xg, is an image which is expected
to have visual similarity with those in X. Let the non-linear
function learned by G parametrized by θg be denoted as
xg = G(z;θg). The input to D is either a real image xr ∈ X
or a generated image xg ∈ G(Z;θg). The output of D is the
probability that xg is real or fake. Let the non-linear function
learned by D parametrized by θd be denoted as xd =D(x;θd).
The top of Fig. 2 illustrates the conﬁguration of a classic GAN.
It can be seen that D and G are playing a zero-sum game
where G is trying to ﬁnd better (more realistic) samples to fool
5https://github.com/ymirsky/CT-GAN
6https://youtu.be/_mkRAArj-x0
464    28th USENIX Security Symposium
USENIX Association
(cid:1877)(cid:1878)(cid:10)(cid:1876)(cid:3034)(cid:1876)(cid:3045)(cid:7)(cid:145)(cid:148)(cid:1877)(cid:1876)(cid:3045)(cid:1499)(cid:1876)(cid:3034)(cid:7)(cid:145)(cid:148)(cid:1876)(cid:3045)(cid:1499)(cid:1876)(cid:3045)(cid:1876)(cid:3045)(cid:1499)GANcGANfor in-painting(cid:1878)(cid:817)(cid:1868)(cid:4666)(cid:1878)(cid:4667)(cid:483)Random vector(cid:1876)(cid:3045)(cid:1488)(cid:1850)(cid:483)Real instance(cid:1876)(cid:3034)(cid:483)Fake (generated) instance(cid:1877)(cid:1488)(cid:148)(cid:135)(cid:131)(cid:142)(cid:483)(cid:882)(cid:481)(cid:136)(cid:131)(cid:141)(cid:135)(cid:483)(cid:883)(cid:483)Label(cid:1876)(cid:3045)(cid:1499)(cid:483)(cid:3)(cid:19)(cid:131)(cid:148)(cid:150)(cid:139)(cid:131)(cid:142)(cid:3)(cid:4666)(cid:143)(cid:131)(cid:149)(cid:141)(cid:135)(cid:134)(cid:4667)(cid:3)(cid:139)(cid:143)(cid:131)(cid:137)(cid:135)(cid:1876)(cid:3045)(cid:1488)(cid:1850)(cid:483)(cid:18)(cid:148)(cid:139)(cid:137)(cid:139)(cid:144)(cid:131)(cid:142)(cid:3)image(cid:1876)(cid:3034)(cid:483)Completed image(cid:1877)(cid:1488)(cid:145)(cid:148)(cid:139)(cid:137)(cid:483)(cid:882)(cid:481)(cid:133)(cid:145)(cid:143)(cid:146)(cid:142)(cid:135)(cid:150)(cid:135)(cid:134)(cid:483)(cid:883)(cid:483)Label(cid:10)to use the pix2pix model for in-painting because it produced
much better results. This may be due to the complexity of the
anatomy in the 3D samples and the fact that we had relatively
few training samples. Since labeled datasets contain at most a
few hundred scans, our approach is more likely to be used by an
attacker. Another reason is that in-painting is arguably easier
to perform than ‘style transfer’ when considering different
bodies. Regardless, in-painting ensures that the ﬁnal image can
be seamlessly pasted back into the scan without border effects.
3 Related Work
The concept of tampering medical imagery, and the use of
GANs on medical imagery, is not new. In this section we brieﬂy
review these subjects and compare prior results to our work.
3.1 Tampering with Medical Images
Many works have proposed methods for detecting forgeries
in medical images [20], but none have focused on the attack
itself. The most common methods of image forgery are:
copying content from one image to another (image splicing),
duplicating content within the same image to cover up or add
something (copy-move), and enhancing an image to give it
a different feel (image retouching) [21].
Copy-move attacks can be used to cover up evidence or dupli-
cate existing evidence (e.g., a tumor). However, duplicating evi-
dence will raise suspicion because radiologists closely analyze
each discovered instance. Image-splicing can be used to copy
evidence from one scan to another. However, CT scanners have
distinct local noise patterns which are visually noticeable [22,
23]. The copied patterns would not ﬁt the local pattern and thus
raise suspicion. More importantly, both copy-move and image-
splicing techniques are performed using 2D image editing soft-
ware such as Photoshop. These tools require a digital artist to
manually edit the scan. Even if the attacker has a digital artist, it
is hard to accurately inject and remove cancer realistically. This
is because human bodies are complex and diverse. For exam-
ple, cancers and tumors are usually attached to nearby anatomy
(lung walls, bronchi, etc.) which may be hard to alter accurately
under the scrutiny of expert radiologists. Another consideration
is that CT scans are 3D and not 2D, which adds to the difﬁculty.
It is also important to note that an attacker will likely need to
automate the entire process in a malware since (1) many PACS
are not directly connected to the Internet and (2) the diagnosis
may occur immediately after the scan is performed.
In contrast to the Photoshopping approach, CT-GAN
(1) works on 3D medical imagery, which provide stronger
evidence than a 2D scans, (2) realistically alters the contents
of a 3D scan while considering nearby anatomy, and (3) can be
completely automated. The latter point is important because
(1) some PACS are not directly connected to the Internet,
(2) diagnosis can happen right after the actual scan, (3) the
malware may be inside the radiologist’s viewing app.
3.2 GANs in Medical Imagery
Since 2016, over 100 papers relating to GANs and medical
imaging have been published [24]. These publications mostly
relate image reconstruction, denoising, image generation (syn-
thesis), segmentation, detection, classiﬁcation, and registration.
We will focus on the use of GANs to generate medical images.
Due to privacy laws, it is hard to acquire medical scans
for training models and students. As a result, the main focus
of GANs in this domain has been towards augmenting
(expanding) datasets. One approach is to convert imagery
from one modality to another. For example, in [25] the authors
used cGANs to convert 2D slices of CT images to Positron
Emission Tomography (PET) images. In [26, 27] the authors
demonstrated a similar concept using a fully convolutional
network with a cGAN architecture. In [28], the authors
converted MRI images to CT images using domain adaptation.
In [29], the authors converted MRI to CT images and vice
versa using a CycleGAN.
Another approach to augmenting medical datasets is the
generation of new instances. In [30], the authors use a deep
convolutional GAN (DCGAN) to generate 2D brain MRI
images with a resolution of 220x172. In [31], the authors
used a DCGAN to generate 2D liver lesions with a resolution
of 64x64. In [32], the authors generated 3D blood vessels
using a Wasserstien (WGAN). In [33], the authors use a
Laplace GAN (LAPGAN) to generate skin lesion images with
256x256 resolution. In [34], the authors train two DCGANs
for generating 2D chest X-rays (one for malign and the other
for benign). However, in [34], the generated samples were
down sampled to 128x128 in resolution since this approach
could not be scaled to the original resolution of 2000x3000.
In [35] the authors generated 2D images of pulmonary lung
nodules (lung cancer) with 56x56 resolution. The author’s
motivation was to create realistic datasets for doctors to
practice on. The samples were generated using a DCGAN and
their realism was assessed with help of two radiologists. The
authors found that the radiologists were unable to accurately
differentiate between real and fake samples.
These works contrast to our work in the following ways:
1. We are the ﬁrst to introduce the use of GANs as a way
to tamper with 3D imagery. The other works focused
on synthesizing cancer samples for boosting classiﬁers,
experiments, and training students, but not for malicious
attacks. We also provide an overview of how the attack
can be accomplished in a modern medical system.
2. All of the above works either generate small regions of
a scan without the context of a surrounding body or gen-
erate a full 2D scan with a very low resolution. Samples
which are generated without a context cannot be realis-
tically ‘pasted’ back into any arbitrary medical scan. We
generate/remove content realistically within existing bod-
ies. Moreover, very low-resolution images of full scans
cannot replace existing ones without raising suspicion
(especially if the body doesn’t match the actual person).
USENIX Association
28th USENIX Security Symposium    465
Our approach can modify full resolution 3D scans,7 and
the approach can be easily extended to 2D as well.
3. We are the ﬁrst to evaluate how well a GAN can fool
expert radiologists and state-of-the-art AI in full 3D
lung cancer screening. Moreover, in our evaluation, the
radiologists and AI were able to consider how the cancer
was attached and placed within the surrounding anatomy.
4 The Attack Model
In this section we explore the attack surface by ﬁrst presenting
the network topology and then by discussing the possible
vulnerabilities and attack vectors. We also demonstrate one
of the attack vectors on an actual CT scanner.
4.1 Network Topology
In order to discuss the attack vectors we must ﬁrst present the
PACS network topology. Fig. 3 presents the common network
conﬁguration of PACS used in hospitals. The topology is based
on PACS literature [9, 36–38], PACS enterprise solutions
(e.g., Carestream), and our own surveys conducted on various
hospitals. We note that, private medical clinics may have a
much simpler topology and are sometimes directly connected
to the Internet [8].
The basic elements of a PACS are as follows: