title:A Measurement Study of Scheduler-Based Attacks in 3G Wireless Networks
author:Soshant Bali and
Sridhar Machiraju and
Hui Zang and
Victor Frost
A Measurement Study of Scheduler-Based
Attacks in 3G Wireless Networks
Soshant Bali1, Sridhar Machiraju2, Hui Zang2, and Victor Frost1
1 University of Kansas
{sbali,frost}@ittc.ku.edu
2 Sprint ATL
{Machiraju,Hui.Zang}@sprint.com
Abstract. Though high-speed (3G) wide-area wireless networks have
been rapidly proliferating, little is known about the robustness and se-
curity properties of these networks. In this paper, we make initial steps
towards understanding these properties by studying Proportional Fair
(PF), the scheduling algorithm used on the downlinks of these networks.
We ﬁnd that the fairness-ensuring mechanism of PF can be easily cor-
rupted by a malicious user to monopolize the wireless channel thereby
starving other users. Using extensive experiments on commercial and
laboratory-based CDMA networks, we demonstrate this vulnerability
and quantify the resulting performance impact. We ﬁnd that delay jitter
can be increased by up to 1 second and TCP throughput can be reduced
by as much as 25− 30% by a single malicious user. Based on our results,
we argue for the need to use a more robust scheduling algorithm and
outline one such algorithm.
1 Introduction
Today, the mobile Internet is one of the fastest-growing segments of the Internet.
One of the main reasons for this is the rapid adoption of high-speed (3G) wide-
area wireless networks. The two main 3G standards are Evolution Data Optimized
(EV-DO) [1] and High-Speed Downlink Packet Access (HSDPA). The increasing
use of these networks to access the Internet makes it important that these are well-
engineered, robust and secure. Much work has been done on designing these net-
works [3,7,5] and the algorithms used in them, especially, the wireless scheduling
algorithms [4,11,13]. However, most prior work has focused on improving system
performance assuming cooperative scenarios without malicious users.
In this paper, we make some initial steps towards understanding the impor-
tant issue of 3G robustness from the security viewpoint. We study the scheduling
algorithm since it plays a vital role in deciding system performance and user ex-
perience. Some prior work [9] have studied vulnerabilities associated with FIFO
schedulers that are common on wired IP networks. Since most 3G networks use
the Proportional Fair (PF) algorithm [7] for downlink scheduling, we focus on
it in this paper. PF has been widely deployed because it is simple and increases
system throughput by being channel-aware, i.e., it schedules data transmission
S. Uhlig, K. Papagiannaki, and O. Bonaventure (Eds.): PAM 2007, LNCS 4427, pp. 105–114, 2007.
c(cid:2) Springer-Verlag Berlin Heidelberg 2007
106
S. Bali et al.
to users with good wireless conditions over those who are experiencing fading
(bad channel conditions). Under general conditions, PF maximizes the product
of throughputs received by all users [13]. Moreover, when all users have identical
and independent fading characteristics, PF is known to be fair in the long term.
The main ﬁnding of our study is that the fairness-ensuring mechanism of PF
can easily be corrupted by a malicious user to monopolize the wireless channel
thereby starving other users. Such scheduler-based attacks are possible because
PF does not distinguish between users with outstanding data and those without.
Using extensive measurements on a commercial CDMA network and on a similar
laboratory setup, we show that the performance degradation due to such attacks
is severe - they can increase “jitter” by up to 1 second and cause frequent spurious
TCP timeouts. We also show that the latter can increase ﬂow completion times
and decrease TCP goodput by up to 30%. Our ﬁndings are important not only
because we tackle mechanisms used in 3G networks and possibly, other future
wireless networks, but also because our work (re-)emphasizes the need to consider
security while designing network algorithms.
This paper is organized as follows. Section 2 provides an overview of the
PF scheduling algorithm and describe how it can be attacked. In Section 3, we
conduct initial experiments on a commercial network and motivate the need
to move to a more controlled experimental environment. In Section 4, we use
experiments in our laboratory to quantify the impact of PF-induced attacks
on UDP and TCP-based applications. We also discuss other important issues
including a possible replacement for PF. We conclude and outline future work
in Section 5.
2 The PF Algorithm and Starvation
As with any managed wireless network, access to the wireless channel in 3G
networks is controlled by Base Stations (BSs) to which mobile devices or Access
Terminals (ATs) are associated. Our focus is on Proportional Fair (PF) - the
scheduling algorithm [13] used to schedule transmissions on the downlink in most
3G networks. In these networks, downlink transmission is slotted. For example,
in CDMA-based EV-DO networks, slot size is 1.67ms. BSs have per-AT queues
and employ PF to determine the AT to transmit to, in a time slot.
The inputs to PF are the current channel conditions reported on a per-slot
basis by each AT. Speciﬁcally, each AT uses its current Signal-to-Noise Ratio
(SNR) to determine the required coding rate and modulation type and hence,
the achievable rate of downlink transmission. In the EV-DO system, there are
10 unique achievable data rates (in Kilobits per second) - 0, 38.4, 76.8, 153.6,
307.2, 614.4, 921.6, 1228.8, 1843.2 and 2457.6. Assume that there are n ATs
in the system. Denote the achievable data rate reported by AT i in time slot
t, an
t to be Ri
exponentially-weighted average rate that user i has achieved, i.e.,
t (i = 1 . . . n). For each AT i, the scheduler also maintains Ai
(cid:2)
Ai
t =
t−1(1 − α) + αRi
Ai
t−1(1 − α)
Ai
t
if slot allocated
otherwise
A Measurement Study of Scheduler-Based Attacks in 3G Wireless Networks
107
Slot t is allocated to the AT with the highest ratio Ri
. α is usually around 0.001
t
Ai
t−1
[7] (we veriﬁed this using measurements [2]). Thus, an AT will be scheduled less
often when it experiences fading and more often when it does not. Under general
conditions, PF maximizes the product of per-AT throughputs [13]. Moreover,
if all ATs have identical and independent fading characteristics, all ATs are
allocated equal number of slots in the long term. If diﬀerent ATs experience
non-identical wireless conditions, unequal slot allocation may result [4] in the
long term. Long-term fairness is not our focus here. We show how malicious ATs
can cause short-term unfairness that is severe enough to degrade application
performance.
The basic observation behind our work is that a malicious AT can inﬂuence the
ratio thereby aﬀecting the slot allocation process. An AT can do
value of its Rt
At−1
this simply by receiving data in an on-oﬀ manner. To see why, consider an AT
that receives no data for several slots. Its At would slowly reduce and approach
zero. After several inactive slots, when a new packet destined for that AT arrives
at the base station, that AT has a low value of At and is likely to get allocated the
slot because its ratio is very high. This AT keeps getting allocated slots until its
At increases enough. During this period, all other ATs are starved. A few Prior
work [8] has observed excessive delays with PF. To our knowledge, no prior work
has considered on-oﬀ traﬃc or explored how malicious users can exploit it.
Starvation due to on-oﬀ behavior occurs because PF reduces At during the
oﬀ periods. This implies that PF “compensates” for slots that are not allocated
even when an AT has no data to receive! In the rest of the paper, we study
how a malicious AT (and a cooperating data source to that AT) can exploit this
vulnerability, namely, the inability of PF to distinguish between an AT to which
no data needs to be sent and one that is not allocated a slot.
3 Experimental Setup
We conduct our initial experiments on a commercial EV-DO network in USA.
Our ATs are IBM T42 Thinkpad laptops running Windows XP equipped with
commercially-available PCMCIA EV-DO cards. The laptops have 2GHz proces-
sors and 1GB of main memory. All ATs connect to the same base station and
sector. Data to the ATs is sourced from Linux PCs with 2.4GHz processors and
1GB of memory. All of these PCs are on the same subnet and about 10 − 11
hops away from the ATs.
For our ﬁrst experiment, we use two ATs - AT1 and AT2. AT1 receives a
long-lived periodic UDP packet stream consisting of 1500-byte packets with an
average rate of 600Kbps. AT2 is assigned the role of a malicious AT and hence,
receives traﬃc in an on-oﬀ pattern from its sender. Speciﬁcally, it receives a burst
of 250 packets of 1500 bytes every 6 seconds. We plot the “jitter” experienced by
AT1 in Figure 1. Since our ATs are not time-synchronized with the senders, jitter
is calculated as the excess one-way delays over the minimum delay. Well-deﬁned
increases in jitter are observed whenever a burst is sent to AT2. In contrast, a
base station employing fair queueing would cause almost no increase in “jitter” as
108
S. Bali et al.
l
]
c
e
s
[
y
a
e
D
y
a
w
−
e
n
O
s
s
e
c
x
E
1.2
1
0.8
0.6
0.4
0.2
0
0
10
20
30
40
Time [sec]
50
60
70
Fig. 1. “Jitter” caused by a malicious AT in a commercial EV-DO network
long as the wireless link capacity is not exceeded. These results clearly show that
AT1 experiences extraordinary increase in “jitter”. We observe similar results
with other parameter settings (results not shown). With all of them, however,
the jitter increases vary from 300ms to 1 second. The variability is likely due to
traﬃc to other ATs and queueing eﬀects at other hops. Hence, to understand and
quantify the attack scenarios better, we move to a more controlled laboratory
setup that recreates actual network conditions while eliminating unknowns such
as cross-traﬃc. We describe this setup now.
In our laboratory, we use commercially available equipments that are widely
used in commercial networks to recreate the EV-DO network including the Base
Station, the Radio Network Controller (RNC) and the Packet Data Serving
Node (PDSN) (see [7]). The links between the Base Station, RNC and PDSN
are 1Gbps Ethernet links. The Base Station serves 3 sectors of which we use
one. Our ATs and senders are the same as before. We collect tcpdump [12] traces
at the senders and ATs. Due to the peculiarities of PPP implementation on
Windows XP, the timestamps of received packets are accurate only to 16ms.
However, these inaccuracies are small enough to not aﬀect our results. For TCP-
based experiments, we use tcptrace [12] to analyze the sender-side traces. There
are three main diﬀerences with a commercial network. First, we use lower power
levels than commercial networks due to shorter distances and in the interest
of our long-term health. Since our goal is not to characterize fading and PF’s
vulnerability does not depend on channel characteristics, this does not aﬀect the
validity of our results. Second, we can control the number of ATs connected to
the base station. Third, the number of hops from the senders to the ATs is only
3. This eliminates the additional hops on normal Internet paths and queueing
eﬀects on those hops. We discuss the impact of this in Section 4.2. Moreover,
this is realistic in networks that use split-TCP or TCP-proxy [14].
Our laboratory setup poses a few challenges; we describe two of the more
important challenges now. First, even though we conduct our experiments in
the laboratory, the wireless conditions varied signiﬁcantly. Hence, we conducted
up to 30 runs of each experiment (a particular parameter setting) to calculate a
A Measurement Study of Scheduler-Based Attacks in 3G Wireless Networks
109
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
l
]
c
e
s
[
y
a
e
D
y
a
w
−
e
n
O
s
s
e
c
x
E
0
0
10
20
30
40
Time [sec]
50
60
70
1.4
1.2
1
]
c
e
s
[
r
e
t
t
i
J
0.8
0.6
0.4
0.2
0
0
measured
predicted
0.5
1
AT1 data rate (Mbps)
1.5
2
Fig. 2. (Left) Results of “jitter” experiment performed in the lab setup. We plot the
excess of (unsynchronized) delays. (Right) The maximum amount of “jitter” - measured
and predicted - that can be caused as a function of the data rate of the long-lived ﬂow to
AT1. As noted before, fair queueing would cause negligible “jitter” if channel capacity
is not exceeded.
good estimate of the required performance metric with a small enough conﬁdence
interval. We also interleaved the runs of the diﬀerent parameter settings used to
plot a ﬁgure so that they all experienced the same wireless conditions on average.
A second challenge is that ATs become disassociated with the base station after
around 12 seconds of inactivity. Also, the initial few packets sent to an inactive
AT encountered large delays due to channel setup and other control overhead.
To prevent our ATs from becoming inactive, we use a low rate background data
stream of negligible overhead.
4 Experimental Results
In this section, we use our laboratory setup to quantify the severity of PF-based
attacks. We ﬁrst focus on non-reactive UDP-based applications and then, on
TCP-based applications. We conclude this section by discussing how common
traﬃc patterns can also trigger PF-induced starvation and brieﬂy discuss a pre-
liminary replacement for PF.
4.1 UDP-Based Applications
In Figure 2, we plot the results of a laboratory experiment similar to that of
Figure 1. We send a long-lived UDP ﬂow of average rate 600Kbps to AT1 and
bursts of 150 packets to AT2 every 6 seconds. The results mirror the behavior
observed in the commercial network, namely, large “jitter” whenever a burst is
sent. Notice the reduction in the variability of results due to the absence of other
ATs and queueing at other hops.
Recall that the PF algorithm compares the ratios of all ATs to allocate slots.
Intuitively, the “jitter” of AT1 depends on the value of At of AT1 just before
110
S. Bali et al.
a burst to AT2 starts. This can be analytically derived. Due to lack of space,
we skip the derivation and only provide the ﬁnal expression for the “jitter” J
experienced by AT1 when both ATs experience unchanging wireless conditions
and hence, have constant achievable data rates R1t = R1 and R2t = R2 in
every time slot t. We also assume that A1T = β1T R1 and A2T = β2T R2 are the
moving averages for AT1 and AT2 in time slot T , the last slot before a burst to
(cid:4)
AT2 starts. Then (the derivation can be found in [2]),
(cid:3)
1
1+β1T −β2T
log(1 − α)
)
log(
J =
(1)
In Figure 2 (Right), we plot the predicted value of “jitter” assuming R1 =
1.8Mbps and β2T = 0. We compare this with experiments in which we vary the
rate of AT1’s ﬂow from 100Kbps to 2Mbps. For each experiment, we calculate
the maximum “jitter” experienced by AT1 and plot them in Figure 2. Comparing
the results of these experiments with β2T = 0 makes sense because the bursts
are separated long enough that AT2’s At is close to zero. It is clear that the
experimental results closely follow the analytically predicted values. Also, the
jitter experienced by AT1 increases almost linearly with the entire data rate to
AT1. Thus, an AT1 with a single VoIP application of 100Kbps may experience
only 100ms increase in “jitter” whereas additional concurrent web transfers by
this VOIP user would cause larger “jitter”. As another example, an AT receiving
a medium-rate video streams of 0.6Mbps could experience a jitter increase of
more than 0.5 seconds. This can cause severe degradation in video quality.
4.2 Eﬀect on TCP Flows
We now show that TCP-based applications are also susceptible to PF-induced at-
tacks. We start by conducting an experiment in which we replace the UDP ﬂow to
AT1 with a long-lived TCP transfer of 20MB. As before, we send an on-oﬀ UDP
stream to AT2 in which every burst consists of 150 1500-byte packets once every 3
seconds - an average rate of 600Kbps. We analyze sender-side tcpdump [12] traces
with tcptrace [10] and plot the TCP sequence number of the bytes transmitted ver-
sus time of the ﬂow to AT1 in Figure 3 (Left). The SYN packet is marked at time 0.
The black dots represent transmitted packets (x-value is time of transmission and
y-value is the sequence number). We see periodic retransmissions (blobs of small
Rs) every 3 seconds corresponding to each burst of the ﬂow to AT2. This demon-
strates how a malicious user can easily cause TCP timeouts to other users.
TCP timeouts in the above experiment could be caused due to one of two rea-
sons. The ﬁrst reason is that AT1 is starved long enough that its buﬀer overﬂows
and some packets are dropped. The second reason is that the buﬀer is large enough
but AT1’s packets are delayed long enough that TCP experiences a spurious time-
out. It turns out that per-AT buﬀers in EV-DO base stations are usually 80 to
100KB in size, which is larger than the default receiver window size of 64KB in
Linux and Windows (other versions use 32KB and 16KB [6]). We also veriﬁed this
using sender side tcpdump traces. Due to lack of space, we do not explore scenar-
ios involving multiple ﬂows to the same AT and timeouts caused by the resulting
A Measurement Study of Scheduler-Based Attacks in 3G Wireless Networks
111
sequence offset
.
1500000 
1000000 
500000 
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
3
RRRRRRRRRRRRRRRRRRRRRR
RRRRRR
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
3
RRRRRRRRRRRRRRRRRR
RRRRRRR
RRRRRRRRRRRRRRRRRR(cid:0)
(cid:0)
(cid:0)
(cid:0)
SYN
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
0 
0 
5 s 
(cid:0)
(cid:0)
(cid:0)
RRRRRRRRRRRRRRR
(cid:0)3
RRRRRRR
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)
(cid:0)