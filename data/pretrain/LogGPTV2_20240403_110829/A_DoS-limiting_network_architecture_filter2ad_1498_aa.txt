title:A DoS-limiting network architecture
author:Xiaowei Yang and
David Wetherall and
Thomas E. Anderson
A DoS-limiting Network Architecture
Xiaowei Yang
University of California, Irvine
PI:EMAIL
David Wetherall
University of Washington
PI:EMAIL
Thomas Anderson
University of Washington
PI:EMAIL
ABSTRACT
We present the design and evaluation of TVA, a network archi-
tecture that limits the impact of Denial of Service (DoS) ﬂoods
from the outset. Our work builds on earlier work on capabilities in
which senders obtain short-term authorizations from receivers that
they stamp on their packets. We address the full range of possible
attacks against communication between pairs of hosts, including
spoofed packet ﬂoods, network and host bottlenecks, and router
state exhaustion. We use simulation to show that attack trafﬁc can
only degrade legitimate trafﬁc to a limited extent, signiﬁcantly out-
performing previously proposed DoS solutions. We use a modiﬁed
Linux kernel implementation to argue that our design can run on
gigabit links using only inexpensive off-the-shelf hardware. Our
design is also suitable for transition into practice, providing incre-
mental beneﬁt for incremental deployment.
Categories and Subject Descriptors
C.2.6 [Computer-Communication Networks]: Internetworking
General Terms
Security, Design
Keywords
Denial-of-Service, Internet
1.
INTRODUCTION
Denial of Service (DoS) attacks have become an increasing threat
to the reliability of the Internet. An early study showed that DoS
attacks occurred at a rate of nearly 4000 attacks per week [18]. In
2001, a DoS attack [4] was able to take down seven of the thirteen
DNS root servers. And more recently, DoS attacks have been used
for online extortion [5].
The importance of the problem has led to a raft of proposed so-
lutions. Researchers have advocated ﬁltering to prevent the use of
spoofed source addresses [8], traceback to locate the source of the
disrupting packets [20, 22, 21, 24], overlay-based ﬁltering [12, 1,
14] to protect approaches to servers, pushback of trafﬁc ﬁlters into
the network [16, 10, 3], address isolation to distinguish client and
server trafﬁc [9], and capabilities to control incoming bandwidth [2,
25].
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
SIGCOMM’05, August 22–26, 2005, Philadelphia, Pennsylvania, USA.
Copyright 2005 ACM 1-59593-009-4/05/0008 ...$5.00.
Each of these proposals has merit and provides techniques that
can help address the DoS problem. Yet we argue that each ad-
dresses only an aspect of DoS rather than the overall problem. In
contrast, our goal is to provide a comprehensive solution to the
DoS problem. We require that a DoS-limiting network architecture
ensure that any two legitimate nodes be able to effectively commu-
nicate despite the arbitrary behavior of k attacking hosts. We limit
ourselves to open networks, such as the Internet, where the com-
municating hosts are not known in advance; this rules out statically
conﬁgured networks that, for example, only permit predetermined
legitimate hosts to send packets to each other.
Our solution is the Trafﬁc Validation Architecture (TVA1). TVA
is based on the notion of capabilities that we advocated in earlier
work [2] and which were subsequently reﬁned by Yaar et. al. [25].
Our attraction to capabilities is that they cut to the heart of the DoS
problem by allowing destinations to control the packets they re-
ceive. However, capabilities are currently little understood at a de-
tailed level or leave many important questions unanswered. A key
contribution of our work is the careful design and evaluation of a
more complete capability-based network architecture. TVA coun-
ters a broader set of possible attacks, including those that ﬂood
the setup channel, that exhaust router state, that consume network
bandwidth, and so forth.
We have also designed TVA to be practical in three key respects.
First, we bound both the computation and state needed to process
capabilities. We report on an implementation that suggests our de-
sign will be able to operate at gigabit speeds with commodity hard-
ware. Second, we have designed our system to be incrementally
deployable in the current Internet. This can be done by placing
inline packet processing boxes at trust boundaries and points of
congestion, and upgrading collections of hosts to take advantage of
them. No changes to Internet routing or legacy routers are needed,
and no cross-provider relationships are required. Third, our design
provides a spectrum of solutions that can be mixed and matched
to some extent. Our intent is to see how far it is possible to go
towards limiting DoS with a practical implementation, but we are
pragmatic enough to realize that others may apply a different cost-
beneﬁt tradeoff.
The remainder of this paper discusses our work in more detail.
We discuss related work in Section 2, motivating our approach in
Section 3. Section 4 describes a concrete implementation of our ar-
chitecture and illustrates its behavior. Sections 5, 6 and 7 evaluate
our approach using a combination of simulation, a kernel imple-
mentation, and analysis. Section 8 discusses deployment issues.
Section 9 summarizes our work.
1The name TVA is inspired by the Tennessee Valley Authority,
which operates a large-scale network of dams to control ﬂood dam-
age, saving more than $200 million annually.
2412. BACKGROUND
Our design leverages previous proposals to address DoS attacks.
We discuss this work, using attack scenarios to illustrate its strengths
and weaknesses and to motivate our approach.
Early work in the area of DoS sought to make all sources identiﬁ-
able, e.g., ingress ﬁltering [8] discards packets with widely spoofed
addresses at the edge of the network, and traceback uses routers to
create state so that receivers can reconstruct the path of unwanted
trafﬁc [20, 21, 22]. This is a key step, but it is insufﬁcient as a com-
plete solution. For example, an attacker might ﬂood a link between
a source and a destination. She might then hide her tracks by us-
ing the IP TTL ﬁeld to cause the attack packets to be dropped after
they have done their damage but before they arrive at the destina-
tion. The network then simply appears to be broken from the point
of view of the source and the destination.
One might think that fair queuing [6] would help by ensuring
that each ﬂow gets its fair share of the bottleneck bandwidth. Yet
even if we assume ingress ﬁltering (so there are no spoofed source
addresses) k hosts attacking a destination limit a good connection
to 1/k of the bandwidth. This applies even if the destination knows
it does not want any of the attack trafﬁc. The problem is worse
if fair queuing is performed across source and destination address
pairs. Then, an attacker in control of k well-positioned hosts can
create a large number of ﬂows to limit the useful trafﬁc to only 1/k2
of the congested link. For example, 30 well-placed hosts could cut
a gigabit link to only a megabit or so of usable trafﬁc.
A different tack is for the network to limit communication to
previously established patterns, e.g., by giving legitimate hosts an
authenticator off-line that permits them to send to speciﬁc desti-
nations. SOS [12] and Mayday [1] take this approach. Our goal is
to design an open network, one where any two hosts can commu-
nicate without prior arrangement. Our work can thus be seen as
automating the provision of authenticators.
An insidious aspect of the Internet model is that receivers have
no control over the resources consumed on their behalf: a host can
receive (and have to pay for!) a repetitive stream of packets re-
gardless of whether they are desired. One response is to install
packet ﬁlters at routers upstream from the destination to cause un-
wanted packets to be dropped in the network before they consume
the resources of the destination, e.g., pushback [16, 10] and more
recently AITF [3]. Unfortunately, these ﬁlters will block some le-
gitimate trafﬁc from the receiver because there is no clean way to
discriminate attack trafﬁc from other trafﬁc, given that attackers
can manufacture packets with contents of their choosing. Our work
can be seen as a robust implementation of network ﬁltering.
In earlier work, we proposed the approach of putting a capability,
or token, into each data packet to demonstrate that the packet was
requested by the receiver [2]. Communication takes two steps: ﬁrst,
the sender requests permission to send; after verifying the sender is
good, the receiver provides it with a token. When included in a
packet, this token allows the network to verify that the packet was
authorized by the receiver. By itself, this does not prevent attacks
against the initial request packet, the router state or computation
needed to verify the packet, and so forth. For example, in our ini-
tial work we used a separate overlay for transmitting the request
packets; an attack against this channel would disrupt hosts that had
not yet established a capability to send.
In SIFF, Yaar et. al. reﬁne the capability approach to eliminate
the separate overlay channel for request packets and per-ﬂow state.
Instead, routers stamp packets with a key that reaches the receiver
and is returned to authorize the sender, which uses it on subsequent
packets [25]. This is reminiscent of work in robust admission con-
trol [15]. We adopt this approach, with some enhancements mo-
tivated by weaknesses of the SIFF proposal. First, in SIFF, router
stamps are embedded in normal IP packets, which requires each
router stamp to be extremely short (2 bits), and thus potentially
discoverable by brute-force attack. We show how to combine the
security of long stamps with the efﬁciency of short stamps. Sec-
ond, initial request packets are forwarded with low priority. This
allows attacking hosts to establish “approved” connections purely
amongst themselves and ﬂood a path and prevent any further con-
nections from being established along its congested links. We ad-
dress this through a more careful treatment of request packets. Fi-
nally, routers allow all copies of packets with a valid stamp through
because they have no per-ﬂow state. Thus, an attacker that is in-
correctly granted a capability by a receiver can ﬂood the receiver
at an arbitrary rate until the permission expires. This is problem-
atic because a typical Web server will only know after a connection
starts whether the trafﬁc is legitimate and given the timeout con-
stants suggested in [25], even a small rate of incorrect decisions
would allow DoS attacks to succeed. Our approach is to provide
ﬁne-grained control over how many packets can be sent based on a
single authorization.
In summary, existing proposed DoS solutions have a number of
good ideas but are incomplete. Our goal is to provide a more com-
prehensive solution. We further restrict ourselves to solutions that
might be practically implemented in today’s technology, e.g., with
limited state at each router and with reasonable amount of compu-
tation at each hop.
3. TVA DESIGN OVERVIEW
In this section, we motivate the key components of our design.
Later in Section 4, we describe the protocol and sketch its common
case of operation. The overall goal of TVA is to strictly limit the
impact of packet ﬂoods so that two hosts can communicate despite
attacks by other hosts. To achieve this, we start with standard IP
forwarding and routing. We then extend hosts and routers with the
handling described below, conceptually at the IP level. For sim-
plicity of exposition, we consider a network in which all routers
and hosts run our protocol. However, our design only requires up-
grades at network locations that are trust boundaries or that experi-
ence congestion.
3.1 Packets with Capabilities
To prevent a destination from losing connectivity because of a
ﬂood of unwanted packets, the network must discard those packets
before they reach a congested link. Otherwise the damage has al-
ready been done. This in turn requires that routers have a means
of identifying wanted packets and providing them with preferential
service. To cleanly accomplish this, we require that each packet
carry information that each router can check to determine whether
the packet is wanted by the destination. We refer to this explicit
information as a capability [2].
Capabilities have signiﬁcant potential beneﬁts compared to other
schemes that describe unwanted packets using implicit features [16,
10]. They do not require a difﬁcult inference problem to be solved,
are precise since attackers cannot spoof them, and are not foiled by
end-to-end encryption. However, to be viable as a solution, capa-
bilities must meet several implied requirements. First, they must be
granted by the destination to the sender, so that they can be stamped
on packets. This raises an obvious bootstrap issue, which we ad-
dress shortly. Second, capabilities must be unforgeable and not
readily transferable across senders or destinations. This is to pre-
vent attackers from stealing or sharing valid capabilities. Third,
routers must be able to verify capabilities without trusting hosts.
This ensures malicious hosts cannot spoof capabilities. Fourth, ca-
request
(1)
requests 
path−identifier queue
sender
router
router
dest
response
(2)
Figure 1: A sender obtaining initial capabilities by (1) sending a re-
quest to the destination, to which routers add pre-capabilities; and (2)
receiving a response, to which the destination added capabilities.
pabilities must expire so that a destination can cut off a sender from
whom it no longer wants to receive packets. Finally, to be practical,
capabilities must add little overhead in the common case. The rest
of our design is geared towards meeting these requirements.
3.2 Bootstrapping Capabilities
In our design, capabilities are initially obtained using request
packets that do not have capabilities. These requests are sent from
a sender to a destination, e.g., as part of a TCP SYN packet. The
destination then returns capabilities to the sender if it chooses to
authorize the sender for further packets, e.g., piggybacked on the
TCP SYN/ACK response. This is shown in Figure 1 for a single di-
rection of transfer; each direction is handled independently, though
requests and responses in different directions can be combined in
one packet. Once the sender has capabilities, the communications
is bootstrapped in the sense that the sender can send further packets
with capabilities that routers can validate.
Ignoring legacy issues for the moment, we expect the number of
packets without associated capabilities to be small in most settings.
This is because one capability covers all connections between two
hosts, and new capabilities for a long transfer can be obtained us-
ing the current capability before it expires. Nonetheless, it is crucial
that the initial request channel not open an avenue for DoS attacks,
either by ﬂooding a destination or blocking the requests of legit-
imate senders. The ﬁrst issue is straightforward to address: we
rate-limit requests at all network locations so that they cannot con-
sume all of the bandwidth. Request packets should comprise only
a small fraction of bandwidth. Even with 250 bytes of request for a
10KB ﬂow, request trafﬁc is 2.5% of the bandwidth. This allows us
to rate-limit request trafﬁc to be no more than 5% of the capacity
of each link, with the added margin for bursts.
It is more challenging to prevent requests from attackers from
overwhelming requests from legitimate clients. Ideally, we would
like to use per-source fair queuing to ensure that no source can
overwhelm others, regardless of how many different destinations
it contacts. However, this is problematic because source addresses
may be spoofed, but per-source fair queuing requires an authenti-
cated source identiﬁer. One possibility is ingress ﬁltering, but we
discarded it as too fragile because a single unprotected ingress al-
lows remote spooﬁng. Another possibility is to sign packets using
a public key infrastructure, but we discarded it as too much of a
deployment hurdle.
Instead, we build a path identiﬁer analogous to Pi [24] and use
it as an approximate source locator. Each router at the ingress of
a trust boundary, e.g., AS edge, tags the request with a small (16
bit) value derived from its incoming interface that is likely to be
unique across the trust boundary, e.g., a pseudo-random hash. This
tag identiﬁes the upstream party. Routers not at trust boundaries do
not tag requests as the upstream has already tagged. The tags act as
per−destination queue
regular packets 
capability checking
yes
no
legacy packets
low priority queue
Figure 2: Queue management at a capability router. There are three
types of trafﬁc: requests that are rate-limited; regular packets with
associated capabilities that receive preferential forwarding; and legacy
trafﬁc that competes for any remaining bandwidth.
an identiﬁer for a network path. We then fair-queue requests using
the most recent tag to identify a queue. This is shown in Figure 2.
As a better approximation, earlier tags can be used within a given
queue to break ties.
Queuing based on a path identiﬁer has two beneﬁts. First the
number of queues is bounded because the tag space is bounded.
This in turn bounds the complexity of fair queuing, ensuring that
we will not exhaust router resources. Second, the scheme offers
defense-in-depth because each trust domain such as an AS places
the most trust in the domain that precedes it. Therefore, an attacker
at the edge of the network or a compromised router who writes
arbitrary tags can at most cause queue contention at the next down-
stream trust domain (AS). One consequence of this is that senders
that share the same path identiﬁer share fate, localizing the impact