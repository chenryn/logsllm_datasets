Hence despite the eﬀectiveness of DUET-S against popular
packers, these failed cases demonstrates the necessity and
importance of complementing DUET-S with dynamic anal-
ysis. DUET-S discard binaries that cannot be unpacked to
avoid extracting bogus features from unpcker codes. Thanks
to DUET’s ensemble approach, most of these un-packable bi-
naries can still be clustered by their dynamic features.
Feature Extraction: Since malware programs often un-
dergo changes due to polymorphism and obfuscation, exact
comparison between instructions will not tolerate any syn-
tax variation. At the other extreme, if all forms of vari-
ation are tolerated, correctness is compromised. To strike
a balance, DUET-S exploits the x86 instruction format1 and
uses the opcode as a succinct representation of instruction
semantics. Using opcodes—instead of widely-used features
such as binary sequences [15] or mnemonics i.e.
‘mov’ and
‘add’—oﬀers several beneﬁts. First, by ignoring operands,
opcode allows DUET-S to tolerate low-level mutations and ob-
fuscation among malware variants. Second, comparing with
1In x86, an instruction (e.g., add eax, 4Fh whose binary
form is 83C04F) consists of opcode which speciﬁes the oper-
ation to be performed and operants on which the operation
is performed. In the above example, the opcode is ’83’, the
operation is ’add’ and the operants are ’eax’ and ’4F’.
81
Table 2: Opcodes provide ﬁne-grained representa-
tions of instruction semantics
Instruction
Binary
83 C0 4F
add eax, 4Fh
B8 4F 00 00 00 mov eax, 4Fh
0F 22 C0
mov CR0, ecx
Opcode Mnem
ADD
83
MOV
B8
0F 22
MOV
mnemonics, the opcode sequence oﬀers more precise repre-
sentation of instruction semantics. Mnemonics sometimes
overly generalize underlying CPU operations, leading to ac-
cidental similarity between diﬀerent code sequences. For
instance, in Table 2, although both mov instructions share
the same mnemonic, the underlying semantic is drastically
diﬀerent.
DUET-S represents each malware program as a sequence
of opcodes and applies the standard N -gram analysis [20] to
construct a feature vector V . Each value in V represents the
number of occurrence of a particular opcode N -gram. The
similarity between two programs can then be calculated ge-
ometrically as the Euclidean distance between their feature
vectors in the vector space.
Clustering with N -gram Feature Vectors: DUET-
S employs the prototype-based linear-time clustering algo-
rithm (henceforth referred to as ProtoCluster) developed in
[20]. The main advantage of ProtoCluster is its signiﬁcantly
faster clustering speed achieved by performing most com-
putation on a relatively small set of prototypes and avoid-
ing expensive pair-wise data point comparisons required by
many classical clustering algorithms (e.g., K-mean or hier-
archical clustering). The ﬁrst step of ProtoCluster is to ex-
tract a set of prototypes—data points that are typical for
a group of homogeneous data samples. Because selection of
an optimal set of prototypes is known to be NP-hard, Pro-
toCluster uses a greedy algorithm. It starts with choosing
a random sample as the ﬁrst prototype and then iteratively
selects the next prototype by searching for the sample that
has the largest distance to its nearest prototype. This se-
lection process is terminated when the distance from all the
data points to their nearest prototype is smaller than a pre-
deﬁned threshold Pmax (i.e., all the input data points are
located within a certain radius from some prototype). Then,
ProtoCluster performs standard agglomerative hierarchical
clustering only on the prototypes (rather than the original
input data). First, each prototype form a single-node clus-
ter. The algorithm recursively merges two closest prototype
clusters until the distance between the closest clusters is
larger than a predeﬁned threshold M ind. Prototypes within
the same cluster are assigned the same label and the label
is subsequently propagated to their associated data points
(i.e., those within the Pmax distance to the prototype). The
authors of [20] showed that the runtime complexity of Pro-
toCluster is O(k2log k + kn) where k is the number of pro-
totypes and n the total number of malware samples. Since
k depends only on the distribution of the data (i.e., k is pro-
portional to the number of malware families), with proper
choice of Pmax, the algorithm is linear in the number of in-
put data n. Applying ProtoCluster on the extracted static
features with diﬀerent parameters Pmax and M ind, DUET-
S produces multiple clusterings of input malware samples,
which serve as an input to the ensemble algorithm.
4.2 Malware Clustering Using Run-time Traces
This section brieﬂy describes the dynamic-behavior-based
component of DUET, referred to as DUET-D. DUET-D adopts
Malheur [20], a state-of-the-art tool for automatic cluster-
ing of malware behavior collected from sandbox environ-
ments such as CWSandbox or Anubis. In DUET-D , for bet-
ter scalability and privacy, instead of using existing web-
based malware analysis services as those used in Malheur,
we built our own system call monitor to intercept and record
all API/system calls of malware programs in VMWare vir-
tual machines. This allows DUET-D to take advantage of
the VMWare VIX API to automate and parallelize the run-
ning of malware programs. Each malware program is moni-
tored for 2 minutes, and the virtual machine is reset to the
clean-state snapshot, preventing interference between mal-
ware programs.
Table 3: Examples of encoding system/API calls
File
System
Process
Handling
Category Operation
0x03
0x03
0x0A
0x0A
0x0A
0x0A
0x01
0x02
0x02
0x02
0x02
0x02
System Call
CreateFile
CopyFile
CreateProcess
CreateProcessInternal
CreateProcessAsUserr
NtCreateProcess
The monitor produces a textual format of API/system
call traces. According to [20], we encode each call into a
tuple ’(category, operation)’, where a category represents a
group of calls that operate on a similar type of objects (e.g.,
registry, ﬁle systems, DLLs or processes), and an operation
speciﬁes a particular function. For example, in Table 3, the
tuple ’(0x03, 0x01)’ indicates that the call belongs to the
’File System’ category and is performing the ’CreateFile’ op-
eration. Furthermore, we assign the same operation value to
those calls that can achieve identical results. For instance,
4 system calls that can be used to create a new process are
encoded with the same tuple, ’(0x0A, 0x02)’. This canoni-
calization of function variations enables a more generalized
representation of call traces and also ensures locality of calls
with similar functionalities in the encoded space.
In to-
tal, DUET-D intercepts and encodes 211 windows API/system
calls into 21 categories, covering most frequently used func-
tionalities including ﬁle system, registry, network, mutex,
process, thread, virtual memory, etc.
Because typical malware behavior patterns, such as mod-
ifying the registry keys and ﬁle systems, can be reﬂected in
the system call sequences, DUET-D apply the N -gram anal-
ysis as similar to DUET-S , embedding the encoded system
call sequences into a ﬁxed-length feature vector whose dis-
tance represents the similarity between malware behaviors.
However, one important diﬀerence is that: unlike in DUET-
S where the feature vector elements represent how often a
speciﬁc n-gram of instructions occurs, DUET-D uses binary
features (i.e., 0 or 1) where each feature vector element rep-
resents the absence or presence of a speciﬁc N-gram of the
call traces. Using binary features help DUET-D reduce the in-
ﬂuence of many external factors, such as the length of traces,
the repetition of behavior, etc. For instance, depending on
the monitoring period and system condition, the number of
system calls in a call trace can vary signiﬁcantly, even for
identical malware programs. Some system calls may be exe-
cuted in a loop and produce thousands of repetitions, which
considerably skews the values in the feature vector. To com-
pensate for this bias, DUET-D uses binary features and nor-
malizes the feature vector to ensure that the diﬀerence be-
tween feature vectors depends only on the presence/absence
82
of features. After feature extraction and vector encoding,
DUET-D applies the ProtoCluster algorithm with diﬀerent pa-
rameter settings to generate clusterings as the inputs to the
ensemble algorithm.
5. CLUSTER ENSEMBLE
The goal of using cluster ensemble is to improve the qual-
ity and the robustness of clustering results by exploiting the
diversity of multiple clustering algorithms.
Table 4: Success rate of diﬀerent approaches (DUET-
S and DUET-D ) in extracting malware features
Dynamic approach
Static approach
Both approaches
# of success (%) # of failure (%)
4943 (87.5%)
4799 (84.9%)
5575 (98.72%)
704 (12.4%)
944 (16.7%)
72 (1.28%)
Motivating Examples The respective limitations of dy-
namic and static approaches, when used alone, can render
them ineﬀective for certain types of malware. To illustrate
this, we ran both approaches on a set of 5,647 real-world mal-
ware samples (Table 5 in Section 7 lists the details) to col-
lect N -gram features on their code instructions and dynamic
system-call traces. Table 4 summarizes the number of mal-
ware samples whose features can be successfully extracted by
dynamic, static and both analyses. It demonstrates the ca-
pabilities and shortcomings of these two approaches as well
as their complementary nature. Table 4 shows that the with
a 12 % and 17% failure rate2, neither static nor dynamic
approach alone is able to analyze all the samples. Detailed
investigation revealed that among 12 % samples that failed
dynamic analysis, 645 cannot be executed, and 25 only made
a single system call, i.e., TerminateProcess, due to detection
of the virtual machine environment3. On the other hand, the
disassembler failed to extract any static instructions from
655 binaries (particularly for FakeAV and Gammima) due
to the use of sophisticated obfuscation and packing tech-
niques. By contrast, a combination of dynamic and static
analyses yielded much better results: malware samples that
can be successfully analyzed increased to 98.72%, with only
72 malware samples being able to evade both approaches.
This preliminary experiment demonstrates that aggregating
diﬀerent analysis approaches has the potential for achieving
more robust and complete clustering.
5.1 Formulation of Cluster Ensemble
Consider a set of n malware programs, X = x1, x2, . . . , xn,
and a set of T clusterings of X, C = {C1,C2, . . . , CT}. Each
clustering, Ct, t = 1, 2, . . . , T , is a partition of X into k dis-
joint clusters, i.e., Ct = {C t
i =
j = φ, ∀i (cid:4)= j. Let Lt(x) denote the label
X and C t
of the cluster to which the malware program, x, belongs,
i.e., Lt(x) = j if and only if x ∈ C t
j . With these T cluster-
ings, the cluster ensemble is deﬁned as a consensus function
Γ [2] that maps a set of clusters to an integrated clustering:
Γ : {Ct|t ∈ {1, 2, . . . , T}} → C.
Sk
i=1 C t
k} where
i ∩ C t
2, . . . , C t
1, C t
If the relative importance of each individual clustering is
not known a priori, a natural goal of cluster ensemble is
2
Failure rate is in accordance with observations from previous
work, e.g., [24] reported about 18.7% of their malware set cannot
be analyzed by Anubis
3
Bredolab is one of the top malware families that produce only
one system call. According to [28], it is a botnet program that
terminates if it detects being executed in a virtual environment.
j
to ﬁnd the ﬁnal clustering, C, that shares the most com-
monality with the constituent clusterings [12].4 To measure
the similarity between clusterings, we deﬁne a connectiv-
ity matrix, M (Ct), for each clustering Ct. The connectivity
matrix is an n × n pair-wise matrix deﬁned for all malware
programs and represents the structural information of a par-
ticular clustering. More speciﬁcally,
Mij(Ct) =
Then, the diﬀerence between two clusterings, Ca and Cb, can
be deﬁned as the number of malware pairs for which the two
clusterings disagree [12]:
d(Ca,Cb) =
1 if xi and xj belong to the same cluster
0 Otherwise.
|Mij (Ca) − Mij(Cb)|
di,j(Ca, Cb) =
nX
i,j=1
(Mij(Ca) − Mij(Cb))2.
(1)
nX
nX
i,j=1
=
i,j=1
Cluster ensemble strives to ﬁnd a consensus clustering, ˆC,
that is closest to all of the given clusterings, i.e., that mini-
mizes the average distance between ˆC and {Ct|t ∈ {1, 2, . . . , T}:
TX
T
1
ˆC
t=1
(2)
i,j ( ˆC) = 1
k }.
, . . . , C opt
Copt = arg min
d(Ct, ˆC).
PT
PT
t=1 d(Ct, ˆC) is a convex function, minimization re-
Since
t=1 Mij(Ct) [32].
sults in an optimal matrix M opt
Here M opt represents connectivity relationship between data
samples in the ﬁnal ensemble clusters, and the values of M opt
i,j
ranges between 0 and 1, where 1 (0) means all (none) of the
clusterings agree that xi and xj belong to the same cluster.
Given M opt
i,j , our goal is to derive the ﬁnal ensemble clusters
Copt = {C opt
5.2 Clustering Based on Connectivity Matrix
Several methods have been proposed to generate a ﬁnal
clustering from the optimal connectivity matrix[2, 12]. A
naive approach is to set a threshold such that two sam-
ples are assigned to the same cluster if their connectivity
is greater than the threshold and if these samples belong to
diﬀerent clusters, these clusters are merged. However, the
main drawback of such an approach is that it tends to over-
merge unrelated clusters which have some samples acciden-
tally close to each other, leading to low clustering accuracy.
To address this, in DUET we employ the following algorithms.
The ball algorithm iteratively ﬁnds a set of samples that
are close to each other (i.e. within a ball) and far from
others, removes them from the data set and then contin-
ues clustering with the remaining samples. Because ﬁnding
the globally optimal sequence of clusters is NP-complete, a
greedy algorithm is used to create a bounded approximation.
Viewing the connectivity matrix, M opt, as a graph’s adja-
cency matrix, where each M opt
i,j represents the edge’s weight
connecting xi and xj , the algorithm sorts the samples in de-
creasing order of their edges’ total weights. At each step,
the algorithm chooses the ﬁrst unclustered sample, xu, and
ﬁnds a set of samples, V = xv1, xv1, . . . , xvk whose connec-
tivity to xu is greater than the threshold, β. Then, their
union V ∪ xu forms a cluster.
4
The algorithm can be easily generalized to the case where some
clusterings may carry more weights than others.
83
The agglomerative algorithm starts by placing all sam-
ples as singleton clusters. Then, it recursively merges the
two clusters with the smallest distance until the distance
between any pair of existing clusters is larger than a given
threshold, h.
If h is set to 1/2, the algorithm is guaran-
teed to create clusters where the at least half of the original
clusterings are in agreement.
Hypergraph partition algorithm: Essentially, the clus-
ter ensemble re-partitions the original dataset based on con-
stituent clusterings’ indication of strong connections. There-
fore, it can also be formulated as a hypergraph partition
problem, where each sample is a vertex in the hypergraph,
and the hyperedge between vertices is weighted based on
M opt.
In this case, the goal is to cut the minimum set
of edges such that the remaining subgraphs consist of con-
nected components corresponding to new clusters.
6.