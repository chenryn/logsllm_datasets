# 28丨案例：带宽消耗以及Swap（下）上一篇文章我主要分析了带宽消耗，今天，我们来看一下分析的第二和第三阶段，也就是Swap 分析和数据库分析。 分析的第二阶段Swap 的原理和对 TPS 的影响前面有一个扣，是说 swap 多的问题。要理解 swap为什么是黄的，得先知道什么是swap。我先画个简易的示意图。 ![](Images/31c16a38ba5772db8113e6848fd97e2d.png)savepage-src="https://static001.geekbang.org/resource/image/1f/e5/1fd061cbf986f9cea3509bd4699ddbe5.jpg"}这里先解释一下，对于一个 Linux 系统来说，如果配置并开启了 swap分区，那么默认的 swappiness 参数是60。 当上图中已用内存超过 40%（100%-60%）时，系统就会主动切换 swap 和active 内存中 file 类型的比例。 swappiness 是在内存 reclaim 的时候生效的，而 reclaim方式同时有两个动作：1. 将 file 相关内存进行回收；2. 将 anon 内存交换到swap 分区。 所以 swapiness 值越大，swap分区就用得越多。 对我们现在分析的这个系统来说，来看一下： ![](Images/a82d1649b8210766b3bf68d909a54d51.png)savepage-src="https://static001.geekbang.org/resource/image/e2/7f/e29ec84d980fb9e667e41010b209427f.png"}我们看到这里配置了一个内存为 8G 左右，已经使用了 7G 多了，swappiness配置为 30%。也就是说当内存使用超过 8Gx(100%-30%)=5.6G 时，就会使用 swap分区。 通过 free 看到现在只有 145M 的物理内存剩余，可用内存也只有 254M了，也就是说现在只有 145（剩余物理内存大小）/7821（总物理内存大小）≈1.9%的空闲内存，这个比例已经远远小于 swappiness 的 30%了。 也就是说这系统早就开始用 swap 了。所以上面图中的 swap飘黄也是很合理的喽！ 下面我们就针对应用服务器的 swap来看是不是可优化。 所有人都知道，当 swap被用的时候，性能肯定会下降，所以在我的测试过程中，一般我都建议把 swap直接关掉测试性能，有人说这样有什么问题？ 那就是没有swap，让不常用的对象直接占用物理内存，如果物理内存不够用，就把对象删了，后面再创建，这时会增加的是majorfault，那就增加好了，反正是要性能差的。 说得如此硬气，那在生产中怎么办呢？开还是关？有人觉得关了心里有安稳，有人觉得开着心里会安稳。而一个系统、一个容器、一个节点，如果容量控制的非常好的情况下，我建议关掉。开着它，也只是心里上的安慰，不会有TPS 处理能力上的提升。 瓶颈分析定位既然知道了上面的大概原理。对一个运行 Tomcat应用的服务器来说，那肯定是要先检查一下 JVM 设置为多大。先执行 ps命令，看一下 Java 进程吧。 ![](Images/40c1552608f1205a83fbc5a7073a4582.png)savepage-src="https://static001.geekbang.org/resource/image/8d/ba/8d6525787d1234c738f629389b5da5ba.png"}关键参数如下：     JAVA_OPTS="$JAVA_OPTS -server -Xms2048M -Xmx8192m -XX:PermSize=256M -XX:MaxNewSize=2790m -XX:MaxPermSize=512m -XX:SurvivorRatio=8"JVM 是 1.8.0_65。 这个参数配置有很大的问题。物理内存只有 8 个 G，一个 JVM heap 就配置了8G，这让其他的东西怎么玩得起来？并且 JDK 是 1.8 了，配置 permsize是又为啥呢？ 虽说有多个地方配置不合理，但是我们也得要知道一下应该配置多少是合理的吧。 看参数的时候，JMX也配置上了，那就用工具来看吧。 首先来看一下系统资源。先看一下系统资源在压力下的表现： ![](Images/5411fe3fa2dbbc54869bbb8d3a8c8160.png)savepage-src="https://static001.geekbang.org/resource/image/ef/66/ef8154abc5d60e04752a5d9ea29d4966.png"}1.       队列已经出现，CS 2 万多，in 2    万多，说多不多。我们可以先放着。        2.       I/O 没什么压力，swap    也一直有值，我们要解决的就是它。        3.       us：sy 接近    2：1，这个是不良信号，记在心里，后面再说。        其次再看下 JVM 的情况： ![](Images/be587659d617070bbb056d34c8bb1819.png)savepage-src="https://static001.geekbang.org/resource/image/d8/f1/d84de678e28c64b46b1b69b8b30b77f1.png"}CPU 使用在应用上的时间达到 60%，GC上没耗什么时间，并且从堆的回收能力上来看，比较正常，只是只用到了 3G左右，这里有必要给 8G 吗？ 线程活动的达到347，看起来还是在增加的，这里也可能是个问题点，只是现在我们不用关心，它还没跳出来。 从这个 JVM 状态上来看，它完全用不到 8G。在这种状态下，还有另一个Tomat，并且另一个 Tomcat 中也没有配置 -Xmx -Xms 参数，当没有配置时，默认-Xmx 是物理内存的 1/4。再加上 thread 用的，物理内存很快就会消耗到5.6G，所以 swap飘黄也是吻合的。 优化结果首先，我们把 JVM 配置成最简，JVM 设置为4G。     JAVA_OPTS="$JAVA_OPTS -server -Xms4096M -Xmx4096m"perm 区在 1.8里都没有了，这几个参数也没啥用。在我的习惯中，MaxNewSize也是先看要用到多少，再决定配置不配置。有些应用自己不熟悉，也无法直接给出配置，只有测试之后再配置。 各部分配置为多大，都没有定数，要通过测试看需要多少。 而我们现在最重要的是先把性能调整上去，再考虑这些细节内容。这样修改JVM 就是为了把物理内存使用率低下来，先不修改 swapiness的比例是为了看下结果，如果用不到 swap 就不再调了，如果还是用了swap，再来调它。 当我们把 JVM修改了之后，再执行起来场景。看到内容如下： ![](Images/eef8acbf39bf41d5fd6ffd078b58aac4.png)savepage-src="https://static001.geekbang.org/resource/image/40/44/40116bf5ff367647f3f41143fd47fd44.png"}CPU 使用率相对前面没有什么变化，但是堆 4G 只用到了 1.5G，可见这个堆连4G都用不到。当然我们还是要分析下其他的内容。 还记得我们要解决的是什么问题吧？swap飘黄了！ ![](Images/017ba87999a206fef6f6f035a7ec9092.png)savepage-src="https://static001.geekbang.org/resource/image/d8/1f/d8ec1c105537e046a98440790462f91f.png"}从这张图可以看到 Swapping 不报警了！CPU 占用 70% 左右。说明现在available 的内存是充足的。 这时我们再看一下系统资源，首先是应用服务器系统资源。 应用服务器系统资源 vmstat如下： ![](Images/2ba064860b483bf8b0d82a15267c9ba2.png)savepage-src="https://static001.geekbang.org/resource/image/10/67/1002a324619b0fe3ba5d6a0d7af53e67.png"}应用服务器系统资源 top： ![](Images/628dcc35de072918f0f37e49d7f786a3.png)savepage-src="https://static001.geekbang.org/resource/image/61/41/61b13011e46b803fef61dde5030e4541.png"}应用服务器系统资源 iftop: ![](Images/2a65ddbfafbb08a6266fe53d9958b22b.png)savepage-src="https://static001.geekbang.org/resource/image/41/de/4109d34df75fed3d71cdc842d516d9de.png"}上图中可以看到，对比之前的资源，swap 基本上没有了，CPU使用率多起来了。但是队列依旧长，sy CPU消耗还是有点多了。 应用服务器的 si 已经到了 13.1%了，这个值要关注下，暂时还不能说是问题，但是接着增加下去，肯定会是问题。 网络已经超过 70Mbps 了，峰值上到87Mbps，这是一个好事，它说明现在处理的业务量确定多了。 接下来是数据库服务器系统资源： ![](Images/0df134ed4e99440bafd9eaad79d9eaaa.png)savepage-src="https://static001.geekbang.org/resource/image/85/27/851e322ad9561715a30fc1ce79052027.png"}你可以看到数据库 CPU都用到这么高了？ ![](Images/770c3052d4b963bed3e384980627c39b.png)savepage-src="https://static001.geekbang.org/resource/image/f3/2b/f36982dff7c811cbe9d5ca8d9cf0862b.png"}TPS 能到 259.2 了，较之前的 221.5 没有提升多少。但是我们解决了 swap的问题，还是有了一点点的提升。 那下一个瓶颈在哪里呢？通过上面的数据库资源来看，数据库早就已经被用到了100% 的 CPU，队列也嗖嗖地涨到了好几十，高的都超过 100了。 可见我们在处理应用服务器的时候，数据库这边已经早就吃不消了。那下面，我们就先把应用服务器的优化部分放一下，再去分析下一个短板：数据库。 后续性能工作建议但是这里并不是说应用服务器的优化工作就完成了，还有一些部分需要做的。 1.       优化 JVM    配置参数，至于应该配置成什么值，还需要再测试，可能会有人说，这个测试人员怎么知道呢？请你相信，如果这个值性能测试人员都测试不出来的话，一般的架构师也不可能知道该设置为多少。        2.       通过监控分析确定 swapiness    的值。    3.       网络带宽又快到占满了，如果 TPS    再提高，网络肯定又支撑不了。        这些扣也都放在这里。因为我们主要是找到系统的短板，并一一解决，才能使整体的TPS增加，虽说现在应用服务器上还有优化的空间，但是现在它不是最短的板。 我们在不忘记应用服务器这些问题的同时，再将目光转向数据库。 分析的第三阶段瓶颈分析定位先来看看数据库的系统资源。 ![](Images/982b55969804b191db355630fab6107b.png)savepage-src="https://static001.geekbang.org/resource/image/dc/c4/dc2569aa95f7eab54930c479ee8b04c4.png"}我在很多场合都在强调一个词：证据链。所以基本上分析也会是从 OS层面开始。 但是证据链这个词说起来容易理解，实际上要想真的有链起来的能力，必须具有基础知识，像分析数据库就更明显。因为当我们不了解系统架构时，想说明一个事情就非常困难。 像上面的这个 top，显然 us CPU 使用率非常地高，idle几乎没有了，只有一个 si 占了 5.7%，这个 si并不算高，我们在上一阶段看到的应用服务器的 si 都已经达到了 13%了。 我们说 si的高或者低，倒不是关键，关键的是它有没有成为我们的瓶颈点。在这个系统中，uscpu才是我们要关注的重点，因为它实在是太高了。 对于一个数据库来说，要干的事情就是执行SQL。当分析多了数据库之后，基本上也形成了套路。不管怎么样，还是先看一下基本的监控信息，以下截取一些Spotlight on MySQL的有用的图，如果你没有这个工具，用其他的监控工具也是一样的。 ![](Images/0ccb8fae9eb4ee9ddaa45771ace48d7c.png)savepage-src="https://static001.geekbang.org/resource/image/bd/09/bd2d900a6d737649dcccf53c81584409.png"}从上面的图可以看到，CPU 使用率 99%，Query Cache 是 OFF的。记下这个位置！ ![](Images/4fefb9d0c094efda52b1c4f8ca2c9f6f.png)savepage-src="https://static001.geekbang.org/resource/image/c2/1d/c2c538d0c263c6e87d77b3b78402151d.png"}从上图看到，负载队列非常长，但 Disk I/O 没多少，说明队列和I/O无关，只是 CPU 的队列，非常好！ Network 也不算大，进出每秒 5000多个包，我们再来看一下网络用到多少了？ ![](Images/8b0ef8519334f981f47796c72da8e86b.png)savepage-src="https://static001.geekbang.org/resource/image/3e/c7/3eb362a32b7bcaabce509dbd790286c7.png"}峰值也才 70Mbps 左右，即使是 100Mbps带宽，现在仍然认为有余量（注意！我这里说有余量是因为我同时也检查了网络队列，并没有阻塞，并不是只看了这个值就武断地做了判断）。 ![](Images/9a35b2731ad08956ef995d5c274d9088.png)savepage-src="https://static001.geekbang.org/resource/image/cf/63/cf347ab9406ffcb3a281f1ef4a646263.png"}![](Images/321fb7d893ef5afc0de1703fbf60aa4c.png)savepage-src="https://static001.geekbang.org/resource/image/23/ec/23e8f83c88e76c1c44badabaea44deec.png"}通过上面的图可以看到，每秒执行 2500-3000 的 SQL，Sorts per second达到 800-1000，Sort rows per second 达到8000-10000。 session 用得倒是也不多，但 Miss Rates 在压力过程中 Query Cache 都是在100%，并且从最上面的 summary 中可以看到 Query Cache 也是 OFF的。 为什么没有在看到 Query Cache 是 OFF的时候就敲黑板呢，这是因为在一些应用中，如果不是查询多的话，这个值 OFF也不能说有问题，但是在这个应用中几乎所有的语句都是 select，那这个 QueryCache再不打开就说不过去了呀。这里先记录下这个问题，待会我们的优化动作就是打开Query Cache。 不管怎么说，对一个数据库来说，主要是执行 SQL 嘛，而对 MySQL来说，不看 slowlog，还能看什么呢。 通过整理 slowlog，看到如下内容：     
# Overall: 280 total, 1 unique, 0.59 QPS, 9.53x concurrency ______________    
# Time range: 2019-09-26T13:44:08 to 2019-09-26T13:52:06    