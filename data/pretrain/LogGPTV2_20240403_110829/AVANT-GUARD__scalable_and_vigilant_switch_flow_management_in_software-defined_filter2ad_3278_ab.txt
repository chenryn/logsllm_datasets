the connection to the migration stage. Then, if the target accepts
the handshake, CM notiﬁes the control plane, and the connection
enters the report stage. Finally, if the control plane allows the data
plane to relay packets, CM completes the connection between the
source and target, and the connection is migrated to the relay stage.
Next, we examine the details of each stage.
function1 (i.e., SYN cookie) and returns a TCP SYN/ACK packet
to a peer who sends the TCP SYN packet with the generated se-
quence number. If the packet is not a TCP SYN packet (i.e., TCP
FIN or TCP RST), it is rejected and the data plane can optionally
return a TCP RST package or simply ignore the source.
Figure 3: Flowchart for handling TCP SYN/RST/FIN packets
If the peer sends a TCP ACK packet to the data plane (Figure
4), the data plane follows the handling method shown in Figure
3.
In this case, the data plane ﬁrst checks the ﬂow table to de-
termine whether there exists a matched ﬂow corresponding to the
ACK packet. If so, the device forwards the packet. Otherwise, it
validates the SYN cookie to determine whether this packet com-
pletes a TCP session or was sent unsolicited. If this ACK packet
contains an appropriate SYN cookie, the TCP handshake is estab-
lished. Upon completion of the handshake, the data plane reports
the ﬂow request to the control plane (i.e., step 4 in Figure 5). Oth-
erwise, the connection request is considered an incomplete probe;
a RST is sent, and the access table counters are adjusted.
Figure 2: Stage diagram of connection migration
Classiﬁcation Stage: In this stage, connection migration classi-
ﬁes useful TCP sessions (i.e., established TCP sessions) from con-
nections that would result in client-side timeout (i.e., failed TCP
sessions). Inspired by the SYN cookie algorithm, connection mi-
gration shields the control plan from client-side failed connection
ﬂoods (e.g., which arise from DoS and reconnaissance activities),
as shown in Figure 3 and 4. When the data plane receives a TCP
SYN/RST/FIN packet (Figure 3), the data plane ﬁrst checks if a
matched ﬂow rule exists in a ﬂow table. If so, the data plane imme-
diately forwards the packet. Otherwise, the data plane ﬁrst updates
the access table that contains information on all TCP connection at-
tempts, by increasing the connection attempt counter for an IP ad-
dress (i.e., the access table collects TCP session information). The
data plane then checks whether this packet is a TCP SYN packet,
and if so generates a sequence number for this packet with a hash
Figure 4: Flowchart for handling TCP ACK packets
Report Stage: For each connection validated by the classiﬁca-
tion stage, the report stage ﬁrst determines if there is an existing
ﬂow rule to handle the session. If not, the data plane reports this
ﬂow request to the control plane. The data plane extracts the header
information of a ﬂow representing the TCP session, and sends this
1We use 4-tuple information as inputs for this hash function.
ClassiﬁcationstageReportstageMigrationstageRelaystageTCP sessionsEstablishedTCP sessionsIgnoreFailed TCP sessionsAllowMigrationSuccess orFailureAllowRelayReceive  TCPSYN/RST/FINIn this packet in Flow Table ?Forward packetIncrease the counter of Access TableIn this packet SYN ?Generate SEQ(SYN Cookie)Return TCP RSTReturn TCP SYN/ACK YESNONOYESReceive  TCPACKIn this packet in Flow Table ?Forward packetCheck SYN Cookie,Match?Report to the control planeIncrease the counter of Access TableReturn TCP RSTYESNOYESNO415information to the control plane with a speciﬁc command. The con-
trol plane then decides whether to allow migration of this session.
If so, the connection is transitioned to the migration stage.
Migration Stage: During the migration stage, the CM module
initiates a TCP connection handshake with the connection’s desti-
nation host. If the host responds with a TCP SYN/ACK packet,
the data plane ﬁnalizes this session by sending a TCP ACK packet
to the host. The data plane also reports this information (i.e., es-
tablishment of a TCP session with a real target host) to the control
plane. If the data plane fails to establish the TCP session with des-
tination hosts (due to an unavailable host or closed port), this result
will also be reported to the control plane.
Relay Stage: After the data plane successfully establishes a TCP
session with a real target host, it enters the relay stage where it re-
lays all TCP data packets between a connection source and desti-
nation as occurs during normal TCP sessions.
Example Connection Migration Scenario: To illustrate con-
nection migration, consider the interaction shown in Figure 5. If
the data plane receives a TCP SYN packet from the host A (1) and
this packet does not match an existing ﬂow rule in the device, it au-
tomatically responds with a TCP SYN/ACK packet to host A (2).
Then, if host A sends a TCP ACK packet to complete this TCP
session (3), the switch knows that a TCP session is successfully es-
tablished, and it reports this event to the control plane. Then, the
control plane decides whether to allow the connection to migrate
on to the real destination host (i.e., host B). Assuming the connec-
tion is allowed, the control plane activates a ﬂow rule with what we
propose as the Migrate action. When a migrate action rule is re-
ceived by the data plane it initiates a TCP connection to host B (6)
and completes the connection (7, 8). If the migration is successful,
the device notiﬁes the control plane of this event (9). Finally, the
control plane inserts a Relay action into the data plane, causing it
to relay all packets between host A and B. At this time, the device
need not add a new rule; rather, it only needs to change the action
ﬁeld of the existing ﬂow rule. Hence, the rule will be changed from
(A-1) to (A-2). Operations 1-3 represent the classiﬁcation stage;
4-5 and 9-10 denote the reporting stages, 6-8 refer to the migration
stage, and 11-12 refer to the relay stage.
the OpenFlow network into a whitehole network [9]. From the
source’s perspective, all probes to the ports and IP address ranges
of the OpenFlow network appear to produce a TCP handshake re-
sponse, hindering the source from knowing which IP and port com-
binations are actually alive.
In the case of the ﬂow-rule-ﬂooding problem in the data plane,
connection migration addresses this concern through its adoption of
stateless TCP handshaking with SYN cookies. Because the SYN
cookie algorithm does not require any state management, a device
does not need to store any ﬂow rules for failed or malicious TCP
connection attempts. It can reduce the effect of ﬂow-rule-ﬂooding
problem. Because of this, connection migration enhances an Open-
Flow network’s resilience and scalability to network ﬂooding at-
tacks.
Collecting TCP Session Information: Based on information
from access tables in the data plane, the control plane acquires two
important attributes from each source that contacts the network:
(i) the number of all connection attempts, captured in the access
table (deﬁned as A1) and (ii) the number of established connections
recorded within the connection migration report (deﬁned as A2).
Analysis of the ratio of failed TCP connections of a peer (A1 - A2)
and the number of established TCP connections (A2) can often be
used to detect various ﬂooding and probing behavior.
3.2.1 Delayed Connection Migration
Knowledgeable adversaries may infer the use of connection mi-
gration and attempt to produce ﬂooding packets by establishing
many real TCP sessions. They can use multiple processes, threads,
or many zombie PCs to generate fake TCP connections. However,
for some protocols, such as HTTP, in which the client is expected
to send the ﬁrst data packet, we can extend connection migration to
incorporate delayed connection migration. Here, we operate a vari-
ant of connection migration in which the key difference is that the
classifying stage will delay the transition to the reporting stage un-
til it receives the client’s TCP data packet. This scenario is shown
in Figure 6. As shown in Figure 6, the data plane delays the report-
ing time (5) until it receives more evidence (i.e., data packet) from
a TCP session initiator (4).
Figure 5: Example connection migration scenario
Figure 6: Example delayed connection migration scenario
Impact on Control Plane Saturation: Connection migration
offers an immediate beneﬁt for maintaining control operations in
the presence of well-known adversarial models that engage in both
spoofed and non-spoofed attacks against an OpenFlow network. In
the context of spoofed ﬂooding attacks (e.g., spoofed TCP SYN
ﬂoods that may saturate the control plane with bogus connection
requests), all such ﬂow requests are nulliﬁed at the classiﬁcation
stage. For non-spoofed connection ﬂoods (e.g., those that may
arise from an aggressive scanner), connection migration converts
3.3 Actuating Triggers
We propose to extend OpenFlow with actuating triggers which
enable the data plane to asynchronously report network status and
payload information to the control plane.
In addition, actuating
triggers can be used to activate a ﬂow rule under some predeﬁned
conditions to help the control plane manage network ﬂows with-
out delays. The actuating trigger consists of four main operations.
First, the control plane needs to deﬁne a trafﬁc statistic condition
under which notiﬁcation is warranted. Second, the control plane
(1) TCP SYN(2) TCP SYN/ACK(3) TCP ACK(6) TCP SYN(7) TCP SYN/ACK(8) TCP ACK(4)(5)(9)(10)(11) TCP ACKTCP DATA(12) TCP ACKTCP DATAA-1: A --> B: Migrate A-2: A --> B: Relay Data PlaneClassiﬁcation StageRelay StageRelay StageMigration StageReport StageReport StageControl PlaneAB(1) TCP SYN(2) TCP SYN/ACK(3) TCP ACK(7) TCP SYN(8) TCP SYN/ACK(9) TCP ACK(5)(6)(10)(11)(4) TCP ACKTCP DATA(12) TCP ACKTCP DATAA-1: A --> B: Migrate A-2: A --> B: Relay Data PlaneReport StageReport StageClassiﬁcation StageMigration StageRelay StageABControl Plane416registers this condition to the data plane. Third, the data plane
checks the condition against its current locally collected packet and
ﬂow statistics to determine if the condition is satisﬁed. Fourth,
when the data plane determines that the condition is satisﬁed by
its current statistics, it may 1) trigger a call-back event to the con-
trol plane to indicate that the condition is met, or 2) insert a ﬂow
rule into a speciﬁed ﬂow table.
Next, we discuss this operation in detail. The conceptual dia-
gram of event triggering and its operation sequence are shown in
Figure 7.
Figure 7: Example event triggering scenario
Deﬁning a Condition: AVANT-GUARD supports three types of
actuating trigger conditions: (i) payload-based, (ii) trafﬁc-rate-based,
and (iii) rule-activation. Conditions can be extended in the future.
To deﬁne each type of condition, the control plane uses the follow-
ing format.
{type:
condition: pointer}
The type ﬁeld is a 2-bit data structure representing three condi-
tion types: 00 = payload, 01 = trafﬁc rate, and 10 = rule activation.
The condition ﬁeld varies for each type. For payload, the condi-
tion ﬁeld is a 1-bit Boolean, indicating 1 for payload investigation
required and 0 for no investigation required. For both trafﬁc-rate
and rule-activation conditions, the control plane uses a 22-bit data
structure, which consists of a 2-bit, 4-bit, and 16-bit ﬁeld. The 2-
bit ﬁeld speciﬁes whether the control plane wishes to register for
time-related metrics (e.g., packets per second (PPS) and bytes per
seconds (BPS)), where 10 represents PPS, and 01 represents the
BPS. 00 indicates the control plane has registered for raw counts.
8. The 4-bit data structure represents comparator options and cov-
ers ﬁve different cases. The ﬁrst three are simple: (i) 0001 for
equal, (ii) 0010 for greater than, and (iii) 0100 for less than. If the
control plane wants to deﬁne compound comparators, it can simply
combine (i) and (ii) (i.e., 0011) for greater than or equal to, and
(i) and (iii) for less than or equal to. If the control plane sets the
highest bit as 1 (i.e., 1000), the data plane needs to check PPS or
BPS. The latter 16-bit structure represents the trigger value to be
matched by the current statistics and enables the control plane to
employ trigger ranges from 0 and 65,535.
The pointer part is used when the control plane wants to activate
a predeﬁned ﬂow rule in which the pointer indicates where the ﬂow
rule is stored. If the data plane ﬁnds that a condition deﬁned by the
control plane is satisﬁed and there is a pointer attached to the con-
dition, the data plane follows the pointer and activates the ﬂow rule
into the ﬂow table. We extend the data plane to support a function
that installs the predeﬁned ﬂow rules, which we can implement via
an extension to the dpctl command.
To clarify this idea, we provide an example scenario. We assume
that the control plane wants to deﬁne a conditional ﬂow-rule inser-
tion that will activate when a ﬂow exceeds 32 bytes per second. To
do this, the type ﬁeld is set to 10 to indicate this is a network-status-
based trigger. The 22-bit condition ﬁeld is set as follows: the 2-bit
ﬁeld is set to 10 to indicate a time metric, the 4-bit comparator ﬁeld
is 0010 (for equality), and the 16-bit trigger value ﬁeld is 32.
Condition Registration: When the control plane creates a con-
ditional ﬂow rule, it will be delivered to the data plane through
an existing communication channel (e.g., the OpenFlow network
interface). When the data plane receives this condition, it gets in-
stalled into its ﬂow table.
Trafﬁc Rate Monitoring: Whenever the data plane receives
a packet, it updates statistical information for related ﬁelds (e.g.,
packet count of a ﬂow rule). This is standard functionality in the
implementation of existing OpenFlow switches which we utilized
for our trigger implementation. We augment the data plane logic
by adding a trigger-evaluation function which incorporates its own
counter management logic within the data plane. This counter is
mainly used for our network-status trigger evaluation.
In addition, we add a 16-bit data structure to store time informa-
tion, which we use in our PPS and BPS calculations. These triggers
are particularly useful in security applications for monitoring trafﬁc
and ﬂow rate anomalies. PPS, BPS, and counts, can be computed
on packet arrival or calculated independently based on the internal
clock. The advantage of a clocked-based calculation strategy is that
one can deﬁne less-than-based trigger evaluates (e.g., trigger when
a rate falls below 10 packets per second). Packet-based calculations
support equality and greater-than triggers and are computed when
a trigger interval has been exceeded. For AVANT-GUARD we have
implemented trafﬁc-based rate computation.
Event Notiﬁcation: When the data plane detects a signal satis-
fying a pre-deﬁned condition, it notiﬁes the control plane using a
new “trigger” message extension that we added to OpenFlow.
Selective Packet Payload Delivery to the Control Plane: Packet
delivery to the control plane is controlled by a ﬂag bit (i.e., 1 bit)