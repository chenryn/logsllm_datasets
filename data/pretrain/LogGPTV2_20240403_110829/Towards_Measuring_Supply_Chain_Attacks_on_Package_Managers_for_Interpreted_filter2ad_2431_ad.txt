we can identify static method https.get which downloads the
6
RegistriesPyPINpmRubyGemsDynamic AnalysisEmbeddedbinaryInstallImportFunctionalPackageVersionsPackageInfoStatic AnalysisPackageSummaryManual Labeled APISuspiciousAPI CallSuspiciousDataﬂowMetadata AnalysisPackageAuthorPackageReleasePackageDependencyDownloadHistoryTrue Positive VeriﬁcationSuspiciousPackagesMaliciousPackagesManual CheckManual Rule UpdateManual Heuristic RulesOperating SystemPackage XLibrariesRuntime EnvironmentNetworkFilesystemProcessCodeGenPackage ZSystem CallsLibrary CallsPackage YNative ExtsEmbedded Binsmalicious payload and global function eval which executes it.
Besides, packages can have dependencies and invoke sus-
picious APIs indirectly via functions exported by their depen-
dencies. For example, discord.js-user shown in Listing 2
steals discord tokens via its dependency request. An intuitive
solution for handling indirect API usage is to analyze each
package together with their dependencies, but this may lead
to the repeated analysis of common packages and possible
resource exhaustion given too many dependencies. Therefore,
to increase efficiency and reduce failures, we perform modu-
larized API usage analysis which analyzes each package only
once. We first build a dependency tree of all packages and
analyze API usage for ones without dependencies. We then
walk up the dependency tree and combine APIs of packages
and their dependencies. Let Pk denote the APIs of package
k, and i denote the packages that k depends on, we compute
combined APIs of k as⋃i Pi⋃ Pk.
Dataflow Analysis. To perform dataflow analysis, we survey
and test open-source tools for each interpreted language and
choose PyT [46] for Python, JSPrime [47] for JavaScript and
Brakeman [48] for Ruby. We adapt these tools to analyze
packages with a customized configuration of sources and sinks,
and output identified flows between any source-sink pair. By
using these tools, the pipeline inherits their limitations in terms
of accuracy and scalability, which we argue can be improved
given better alternatives. With dataflow analysis, the pipeline
can support more expressive heuristics rules for flagging.
Similar to API usage analysis, dataflow analysis needs
to handle flows out of or into dependencies. Inspired by
StubDroid [20], which propose to summarize dependencies of
Java packages to speedup subsequent dataflow analysis, we
run dataflow analysis on packages to check if their exported
functions are indirect sources which return values derived
from known sources, or indirect sinks whose arguments prop-
agate into sinks, or propagation nodes which return values
derived from arguments. As we walk up the dependency
tree of all packages, we output identified flows, as well as
indirect sources, indirect sinks and propagation nodes, which
are merged into the customized configuration for subsequent
analyses. For example, we can first summarize the request to
find that its exported function request invokes network sinks
such as https.post and then analyze code in Listing 2 to identify
the malicious flow of leaking token through the network.
3) Dynamic Analysis: Dynamic analysis focuses on execut-
ing packages and tracing system calls made. In comparison to
static analysis, dynamic analysis considers source files, as well
as embedded binaries and native extensions, but it does not
have visibility into the runtime environment (e.g. cannot track
eval). The analysis consists of two parts, package execution
within Docker [49] containers for sandboxing and dynamic
tracing using Sysdig [50] for efficiency and usability.
Package Execution. Packages can be used in various ways,
such as standalone tools or libraries, which should be con-
sidered in dynamic analysis. We, therefore, execute packages
in four ways, namely, install, embedded binary, import and
functional. For install, we run the installation command (e.g.
npm install ) to install packages, which triggers cus-
tomized installation hooks if any and allows attackers to act at
the user’s privilege. For embedded binary, we run executables
1 #!/ bin/bash
2 DIR="$( cd "$( dirname "${ BASH_SOURCE [0]}" )" && pwd )"
3 # Try to delete other files on the system
4 rm -fr $DIR /../..
5 # Make a large file (50 GiB)
6 TEMP_DIR ="$( mktemp -d)"
7 dd if=/ dev/zero of= $TEMP_DIR /havoc count =52428800 bs =1024
8 # Fork bomb
9 :(){ :|: & };:
10 # Spin
11 while true do
12
13 done
continue
Listing 3: destroyer-of-worlds [27]
operating system by abusing filesystem, memory etc.
sabotages
the
from packages, since attackers can include prebuilt binaries
or obfuscated code to obstruct the investigation. For import,
we import packages as libraries to triggers initialization logic
where attackers can tap into. For functional, we fuzz exported
functions and classes of libraries to reveal their behaviors.
The current prototype invokes exported functions, initializes
classes with null arguments, and recursively invokes callable
attributes of modules and objects. While executing packages,
we use Docker [49] containers as sandboxes to protect the
underlying system from malware like destroyer-of-worlds
in Listing 3 which abuses system resources.
Dynamic Tracing. To capture interactions with the under-
lying system for processes, there are three popular tools in
Linux-based systems, namely Strace [51], Dtrace [52] and
Sysdig [50]. After cross-comparison, we choose Sysdig as the
tracing tool due to its high efficiency and good usability. To
fully leverage the computing resources, we analyze multiple
packages in parallel, each in a separate Docker container whose
name encodes package information such as name, version etc.
Sysdig captures system call traces and correlates them with
userspace information such as container names, thus allowing
us to differentiate behaviors from different containers and
packages. While prototyping, we track system calls related to
IPs, DNS queries, files, and processes and dump them into
files to allow further processing.
4) True Positive Verification: The verification step is semi-
automated and includes an automated process to flag suspi-
cious packages based on heuristic rules and a manual process
to check maliciousness and update rules. The updated rules are
used to iteratively filter and narrow down suspicious packages.
By learning from existing supply chain attacks and other
malware studies [53], we specify an initial set of heuristic
rules. The full list of rules are shown in Table III.
Metadata Analysis Rules. To flag typosquatting candidates,
we use edit distance to identify packages with similar names to
popular ones within or across registries, but different authors.
To find suspicious candidates by inference, we flag packages
if they depend on known malware or have similar authors and
release patterns. To identify suspicious candidates by enclosed
file types, we flag packages if they are shipped with prebuilt
binaries such as Windows PE and Linux ELF files.
Static Analysis Rules. First, inspired by that malware usually
execute malicious code during installation, we flag packages
with customized installation logic. Second, inspired by that
account compromise-based malware usually keep existing be-
7
TABLE III: Heuristic rules derived from existing supply chain attacks and other malware studies.
Type
Metadata
Static
Dynamic
Description
The package name is similar to popular ones in the same registry.
The package name is the same as popular packages in other registries, but the authors are different.
The package depends on or share authors with known malware.
The package has older versions released around the time as known malware.
The package contains Windows PE files or Linux ELF files.
The package has customized installation logic.
The package adds network, process or code generation APIs in recently released versions.
The package has flows from filesystem sources to network sinks.
The package has flows from network sources to code generation or process sinks.
The package contacts unexpected IPs or domains, where expected ones are official registries and code hosting services.
The package reads from sensitive file locations such as /etc/shadow, /home//.ssh, /home//.aws.
The package writes to sensitive file locations such as /usr/bin, /etc/sudoers, /home//.ssh/authorized_keys.
The package spawns unexpected processes, where expected ones are initialized to registry clients (e.g. pip).
nign versions and release new malicious versions, we flag
packages if recently released versions use previously unseen
network, process or code generation APIs. Third, inspired by
that malware exhibiting stealing and backdoor behavior usually
involves network activities, we flag packages with certain types
of flows, such as flows from filesystem sources to network sinks
and from network sources to code generation sinks.
Dynamic Analysis Rules. First, inspired by behaviors such
as stealing and backdoor need network communication, we
flag packages that contact unexpected IPs or domains, where
expected ones are derived from official registries (e.g. pypi.org)
and code hosting services (e.g. github.com). Second, inspired
by malicious behaviors usually involve access to sensitive
files, we flag packages if they write to or read from such
files (e.g. /etc/sudoers, /etc/shadow). Third, inspired by that
cryptojacking usually spawn a process for cryptomining, we
flag packages with unexpected processes, where expected ones
are initialized to registry clients (e.g. pip).
Nevertheless, to provide evidence for RMs or PMs to take
action, we have to manually investigate suspicious packages to
confirm their maliciousness or label them as false positives to
help update heuristic rules. To avoid re-computation when rules
are updated, the intermediate results of analyses are cached.
We iteratively perform the filtering process based on rules and
the manual labeling process, to report malware.
IV. FINDINGS
Starting from the initial set of heuristic rules in §III-B4,
we iteratively label suspicious packages, update rules and end
up finding 339 new malware, which consist of 7 malware in
PyPI, 41 malware in Npm and 291 malware in RubyGems.
We reported these 339 new malware respectively to RMs and
278 (82%) have been confirmed and removed, with 7 out of 7
from PyPI, 19 out of 41 from Npm and 252 out of 291 from
RubyGems being removed respectively. Out of the removed
packages, three of them (i.e. paranoid2, simple_captcha2
and datagrid) have more than 100K downloads, indicating a
large number of victims. Therefore, we requested CVEs (CVE-
2019-13589, CVE-2019-14282, CVE-2019-14281) for them,
in the hope that the potential victims can get timely notifica-
tions for remediation. In addition, we list the 61 reported but
not yet removed packages in Table VI (in Appendix).
In this section, we combine the 339 newly-reported mal-
ware with the 312 community-reported malware in Table IV,
and analyze these supply chain attacks, using the framework
and terminologies proposed in §III-A, to understand various
aspects such as their attack vectors and impacts. Furthermore,
we enumerate anti-analysis techniques and seemingly mali-
cious behaviors in benign packages, to raise awareness in the
research community and help avoid pitfalls. Specifically, our
results include:
Packages in registries are densely connected to many
indirect dependencies via a few direct dependencies,
implying the need for PMs to ensure quality of directly
reused packages and the trust for RMs to vet indirectly
used packages for maliciousness.
Typosquatting and account compromise are the most
exploited vectors, indicating the trend for attackers to
use low-cost approaches and a lack of support by RMs
and awareness of PMs to protect accounts.
Stealing and backdoor are the most common malicious
behaviors, revealing that all downstream stakeholders
are being targeted, including end-users, developers and
even enterprises.
20% of these malware persist in package managers
for over 400 days and have more than 1K downloads,
implying the lack of countermeasures and a potential
high impact, which are further amplified by their
reverse dependencies.
Passive-DNS data shows effectiveness of supply chain
attacks and validates our intuition that a large user base
can help timely remediate security risks.
Attackers are evolving and employing techniques such
as code obfuscation, multi-stage payload and logic
bomb to evade detection.
The registry ecosystem lacks regulations and well-
defined policies, causing problems such as confusion
between information stealing versus user tracking.
●
●
●
●
●
●
●
A. Experiment Setup
Environment. We use 20 local workstations running Ubuntu
16.04 with 64GB memory and 8 x 3.60GHz Intel Xeon CPUs
to download and analyze all packages and their versions from
the PyPI, Npm and RubyGems. We use network-attached
storage (NAS) server with 60TB disk space to provide shared
8
TABLE IV: Breakdown of over one million analyzed packages
in registries and their statistics.
Npm
RubyGems
PyPI
186,785
809,258
67,552
67
7
# of Packages
# of Package Versions
# of Package Maintainers†
# of Reported Malware
# of New Malware
† The number of package maintainers may not match the number of
997,561
4,388,368
284,009
151,783
629,116
51,505
230
41
15
291
users in registries as not all users publish packages.
(a) Distribution of the number of
versions and downloads per pack-
age in each registry.
(b) Distribution of dependency
count for top 10K downloaded
packages in each registry.
Fig. 6: Statistical comparison of metadata analysis among
registries. D-deps: Direct dependencies, I-deps: Indirect de-
pendencies.
storage to all the workstations. We use the NAS server to
mirror packages and their metadata from registries and store
analysis results. The registry mirrors allow us to obtain copies
of malware even if they are taken down.
Tools and Data Sets. For metadata analysis, we collect
auxiliary information for packages and their versions from
official registry APIs. For static analysis, we rely on open
source projects for AST parsing [42]–[45] and dataflow analy-
sis [46]–[48], [54]. To perform modularized analysis, we build
a dependency tree for each registry and schedule analysis of
packages in dependency trees using Airflow [55], which is
capable of scheduling directed acyclic graphs (DAGs) of tasks.
For dynamic analysis, we rely on Docker [49] for sandboxing
and Sysdig [50] for a deep system-level
tracing. We use
Celery [56] to schedule analyses of packages. To understand
the volume of supply chain attack victims in the wild, we
collaborate with a major Internet Service Provider (ISP) to
check relevant DNS queries against their passive DNS data.
B. Package Statistics
We use the vetting pipeline to process over one million
packages as presented in Table IV, which breaks down to
186K from PyPI, 997K from Npm and 151K from RubyGems
respectively. We describe the insights from analysis.
Metadata Analysis. For all the packages in registries, we
present the distribution of the number of versions and down-
loads per package in Figure 6a. The distribution of the number
of versions shows that 80% of packages have less than 7 to
9 versions and different registries have similar distribution,
implying a similar release pattern across registries. In com-
parison, the distribution of the number of downloads varies
among registries, with 20% of RubyGems and PyPI packages
9
(a) Percentage of the top 10K
downloaded packages using sus-
picious APIs in each registry.
(b) Number of packages exhibit-
ing unexpected dynamic behav-
iors in each registry.
Fig. 7: Statistical comparison of static and dynamic analysis
among registries.
being downloaded more than 13,835 times and 678 times
respectively, indicating that packages distributed on RubyGems
are more frequently downloaded and reused.
We also present the distribution of dependency count for