title:Bigfoot, sasquatch, the yeti and other missing links: what we don't
know about the as graph
author:Matthew Roughan and
Simon Jonathan Tuke and
Olaf Maennel
Bigfoot, Sasquatch, the Yeti and Other Missing Links:
What We Don’t Know About the AS Graph.
Matthew Roughan
University of Adelaide
SA, Australia
{matthew.roughan,simon.tuke}@adelaide.edu.au
Jonathan Tuke
University of Adelaide
SA, Australia
Olaf Maennel
Tech. Universität Berlin
Deutsche Telekom Labs
PI:EMAIL
ABSTRACT
Study of the Internet’s high-level structure has for some time in-
trigued scientists. The AS-graph (showing interconnections be-
tween Autonomous Systems) has been measured, studied, mod-
elled and discussed in many papers over the last decade. However,
the quality of the measurement data has always been in question.
It is by now well known that most measurements of the AS-graph
are missing some set of links. Many efforts have been undertaken
to correct this, primarily by increasing the set of measurements, but
the issue remains: how much is enough? When will we know that
we have enough measurements to be sure we can see all (or almost
all) of the links. This paper aims to address the problem of estimat-
ing how many links are missing from our measurements. We use
techniques pioneered in biostatistics and epidemiology for estimat-
ing the size of populations (for instance of ﬁsh or disease carriers).
It is rarely possible to observe entire populations, and so sampling
techniques are used. We extend those techniques to the domain of
the AS-graph. The key difference between our work and the bio-
logical literature is that all links are not the same, and so we build
a stratiﬁed model and specify an EM algorithm for estimating its
parameters. Our estimates suggest that a very signiﬁcant number
of links (many of thousands) are missing from standard route mon-
itor measurements of the AS-graph. Finally, we use the model to
derive the number of monitors that would be needed to see a com-
plete AS-graph with high-probability. We estimate that 700 route
monitors would see 99.9% of links.
Categories and Subject Descriptors
C.2.3 [Computer-Communications Networks]: Network Opera-
tions—network monitoring; G.3 [Probability and Statistics]: Prob-
abilistic algorithms
General Terms
Measurement
Keywords
Topology Inference
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
IMC’08, October 20–22, 2008, Vouliagmeni, Greece.
Copyright 2008 ACM 978-1-60558-334-1/08/10 ...$5.00.
1.
INTRODUCTION
Internet topology has drawn interest from areas as diverse as
physics and biology. The discovery of power-law degree in nodes [1]
resulted in a large number of papers. Though the nature of this
power-law has been disputed [2], a more problematic aspect is
whether inadequate measurements of the topology artiﬁcially in-
duce the power law [3]. The central issue is missing links. All
studies reporting measurements of network topologies potentially
have missing links. How do we know if they do? How do we know
how many they miss? These questions seem to be about things we
don’t know, and for this reason appear unanswerable, but here we
show that they are not.
We use techniques developed in biological research for estimat-
ing the population of say ﬁsh. The technique “capture-recapture”
works as follows. One goes into the ﬁeld and catches some ﬁsh.
The captured ﬁsh are tagged and then released. Then, at some later
point in time one repeats the study. The number of tagged ﬁsh that
we recapture, along the number of captured ﬁsh allows us to make
an estimate of the total population.
However, the simple models of capture-recapture assume that all
“ﬁsh” are equally easy (or hard) to catch, so we sample at random
from the population. To paraphrase George Orwell, “All Internet
links are equal, but some are more equal than others.” Some links
are harder to see than others! Although this violates the assump-
tions underlying the simple capture-recapture model, there is a long
literature extending the ideas to many other cases. We draw on this
literature to develop a new model and estimation algorithm speciﬁc
to our problem.
So this paper provides us with a way of estimating what we don’t
know, in this case the number of hidden or missing links in an AS
graph (here AS stands for Autonomous System, not Abominable
Snowman as you might guess from the title). The technique per-
forms well against the best data we have for validation, supplying
supporting evidence for these previous studies.
In addition, this
approach is easily applied (in contrast to previous papers where ex-
tensive efforts were required to clean and combine multiple data
sources), and so we can use it to look at the size of the Internet over
time. We use it to examine the number of links in the AS-graph
over more than four years. From this extended dataset we look for
trends, and our results indicate that the AS-graph is growing at 18.7
links per day.
Finally, by mapping this data to link types: peer-2-peer (p2p),
customer-provider (c-p) and sibling-2-sibling (s2s) we can conﬁrm
the intuition that p2p links are much harder to see than c-p and s2s
links. In fact, the classes in our model have a strong correspondence
to the link types.
However, there are caveats on the results. For instance, it is pos-
sible that there exists a class of links which are never observed. In
absence of any data, our technique obviously cannot estimate the
size of this class of links. Hence, it is still possible that our ap-
proach underestimates the number of links present in the Internet.
There are many possibilities for extending this work. At the mo-
ment we only examine the number of links in the AS-graph, but it
is clearly interesting to examine subsets of this graph, for instance
to examine the node degree problem, or to estimate the number of
backup links. We could also incorporate other data sources, or an
improved model. However, perhaps the greatest potential for these
ideas is in their extension to other Internet measurement problems,
such as estimating the number of hidden anomalies.
agated, or an old one withdrawn. This route exploration process
reveals links that might otherwise be hidden.
In addition, BGP
monitors are unlikely to see a non-existent link (in comparison to
other data sources such as registries or traceroutes) and this is a use-
ful property. In this paper we use data from RouteViews [7] from
Jan 1st 2004 until March 31st 2008. The data consists of all ta-
ble dumps, and routing updates seen from all peers of RouteViews,
grouped into one month periods. One month represents a reason-
able tradeoff between obtaining a more complete view (through
seeing additional updates over time), and the desire to measure dy-
namic properties of the network such as growth rates.
2. BACKGROUND
2.1 Capture-Recapture
Simple capture-recapture can be used as follows.
Imagine an
unknown population E, from which we capture two samples E1
and E2. The initial samples are tagged so that we can also measure
E12 the number recaptured in the second experiment. Assuming
that the two experiments are independent, “ﬁsh” are all the same,
the population remains static, and that tags to not “drop off”, then
we can make an estimate of E using Petersen’s formula [4, 5].
ˆE =
E1E2
E12
.
(1)
The approach can be generalized in various ways [4,5], for instance
by introducing K measurements (often referred to as K-lists), or by
allowing for dependencies between monitors. The typical approach
seems to be to use regression on a K dimensional contingency table
generated from the measurements. Typically these techniques don’t
scale well for large K (given the 2K entries in the table). Hence
we will adopt a different approach in this paper.
2.2 Network Topology Measurements
One of the key ways to look at a network is to examine its con-
nectivity, which can be captured in a graph G = (N ,E ), where N
is a set containing the nodes (or vertices) of the graph. These repre-
sent, for example, routers switches or even whole networks. E is a
set containing the edges of the graph, i.e., the connections between
nodes. We deﬁne the numbers of nodes and edges by N = |N| and
E = |E|.
For instance, consider the case of the AS-graph, where nodes
correspond to Autonomous Systems (ASes). There are many im-
portant details of inter-AS connections (i.e., the nature of the re-
lationships between connected ASes, the behavior of the Border
Gateway Protocol, etc.). Although it is possible to beneﬁt from re-
taining these details [6], the simplicity of a graph based model has
its attractions.
A common mistake in using such data has been to treat the ob-
served data as completely accurate. It isn’t! For example, a major
source of observations of the AS graph comes from BGP moni-
tors [7, 8]. Such monitors participate in the BGP routing protocol.
BGP propagates the AS-path of a route, and this path provides us
with information about the links in the AS-graph. However, BGP
is a path-vector protocol, which means that only “best” routes are
propagated. In contrast to a link-state routing protocol, we do not
see the whole topology of the network, only those routes which are
propagated. Hence, a BGP route monitor gets an incomplete view
of the topology.
There are other sources of data that can be used to infer the struc-
ture of the AS graph. In this paper we will concentrate on BGP
routing data, as this is the most up-to-date source of data. It al-
lows us to see routing changes as they occur, and this is important
because it allows us to see route exploration as a new route is prop-
Each update, or table entry provides us with an AS-path, from
which we can determine a set of links (and nodes) that are observed
or visible. There are also sets of links which are active, but unob-
served, and it is these links which cause all the trouble. We refer to
these links as hidden links. Note that for an AS to be reachable at
all, it must appear in observations, and so with any substantial set of
route monitors the set of hidden nodes should be almost empty [9].
There may be ASes which we don’t observe (private ASes for in-
stance) but as these are not routable from the general Internet they
are of limited interest. There is also the possibility that incorrectly
conﬁgured ﬁlters will restrict our view of some ASes [10], but the
lack of visibility means these ASes are still partitioned from the
rest of the Internet, and so will be unlikely to play a practical role
in the Internet topology.
of edges E (i)
Given K monitors, we observe {E (k)}K
to estimate the observed links is to take
k=1E (k).
Combining all of the observations of one monitor will reveal a set
obs where we drop the obs subscript where it is implied.
k=1. The typical approach
Eobs = ∪K
(2)
Implicit in (2) is the belief that E (k) contains few false positives,
but many false negatives (missing links). BGP measurements gen-
erally fall into this category because the information provided cor-
responds to real routes through the Internet. Exceptions arise where
the protocol is abused, for instance by hackers seeking to hijack ad-
dress space. More importantly, when measurements are taken over
a period of time, they may include links which are not alive for the
entire measurement period. However, it is commonly assumed that
the number of false positives introduced in this way is small.
2.3 A quick and dirty refutation
We can make a quick estimate of Petersen’s formula for the
RouteViews data. A typical monitor for RouteViews (in October
2007) sees of the order of 45,000 links. The typical intersection be-
tween a pair of such monitors is somewhere around 40,000 links.
We can easily calculate Petersen’s formula (1) to be (cid:3) 45, 000 ∗
9/8 (cid:3) 50, 000 links. In fact, equation (2) indicates that at least
57,000 links exist. Though the calculation above is only rough, it is
representative of the real results. Given the estimates fall well be-
low a known lower-bound for the number of links, we know there
is something wrong with this approach as it stands.
We also considered the simple K-list approach [4, 5] for this
problem. Taking K to be the number of monitors produced a prob-
lem with an unrealistically large number of table entries (∼ 240)
to estimate, but smaller values still showed very high variance in
the estimates. For instance, we found that taking three monitors
at a time produced estimates ranging from 10’s of thousands up to
millions of links depending on which three monitors were chosen.
Given the ﬂaws in the above approaches, we seek a better model.
3. A MULTI-CLASS MODEL
The simple capture-recapture approaches described above clearly
fail. How can this be? Petersen’s assumptions are
independence (between measurements)
1.
2. homogeneity (across links)
3.
4.
the population is static (between measurements).
tags do not drop off.
Clearly at least one of these is violated. The forth assumption is
valid for our measurements because we do not physically tag links
– we simply use their unique identiﬁer (the nodes they connect).
The third assumption is also valid, because unlike a typical capture-
recapture experiment, our measurements are all taken at the same
time using different monitors. So the problem lies in the ﬁrst two
assumptions, which are in fact closely coupled (heterogeneity will
introduce correlations).
It has often been postulated, and at least been partially con-
ﬁrmed [9], that some links are harder to see than others. For in-
stance, a link that connects a stub-AS (a non-transit providing, sin-
gle homed AS) to the Internet will always be visible (whenever the
AS itself is visible). It must appear on any observed path originated
by that AS. On the other hand, it has been postulated that the ma-
jority of the missing links are “peering” links. The simple c-p/p2p
model of AS relationships, along with the resulting valley-free rout-
ing policy means that peering links between lower-tier ASes will
only be visible from a small subsection of the AS-graph. Peering
links are therefore considered harder to observe.
Our approach to include these facts is to use a stratiﬁed model.
We assume that there are multiple classes of links, with different
observational properties. This immediately violates the homogene-
ity assumption, and hence invalidates the independence assumption
by introducing correlations between measurements dependent on
class. We are left with a substantially weaker set of assumptions
1. conditional independence
2. homogeneity (across monitors)
The conditional independence assumes that we incorporate the ma-
jority of the correlation structure through the stratiﬁcation of links
into different classes. We do remove monitors with clear depen-
dencies (for instance those monitoring the same AS) to avoid the
majority of graph-structure related dependencies. Other dependen-
cies such as related to “tiering” of the AS-graph, or geographic bias
(because RouteViews is focussed in North America) are incorpo-
rated through the different classes of links. The second assumption
is quite different from the earlier homogeneity condition in that it
says that any monitoring point has the same probability of observ-
ing a particular link. We also remove any monitors which substan-
tially violate this condition, e.g., monitors without a default-free
feed. We are left with between about 30 and 40 route monitors (see
Figure 4 for exact numbers).
We can model the above measurements using the Binomial Mix-