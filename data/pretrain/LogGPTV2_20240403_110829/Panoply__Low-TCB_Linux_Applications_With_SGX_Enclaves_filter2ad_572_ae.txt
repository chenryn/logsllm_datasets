available with the Intel SDK which only ports libcrypto.
Speciﬁcally, we enable the SSL protocol and the support for
executing OpenSSL engines inside the micron. We use the
PANOPLY networking and ﬁle system APIs to achieve this
and change 307 LOC. We test
the OpenSSL library with
its regression suite, and use the speed and tspeed utility
to benchmark the performance of our OpenSSL library. We
observe a total of 8 PANOPLY API calls at run-time along
with 1 inter-micron call.
Comparison to Graphene-SGX. We attempted to port our
4 case-studies to Graphene-SGX, by following the public
instructions [3] available at the time we performed our ex-
periments. We report that we were not able to port 3 out
of 4 applications to Graphene-SGX— the applications either
crash or suspend during execution. Since there is no public
companion report, but only a large-scale system, it is hard to
evaluate the design reasons of why the applications crash. After
further investigation of the Graphene-SGX source-code, we
were able to narrow down 2 cases which are problematic: (1)
the fork semantics break in H2O which launches neverbleed
in a separate process (2) the epoll call does not receive the
socket events, thus the applications such as Tor and FreeTDS
never progress. Thus, our evaluation comparisons are best-
effort. We have informed the authors to implement possible
mitigations in their system for these issues.
C. Reduction in TCB
PANOPLY achieves 2 orders of magnitude lower TCB
as compared to state-of-art approaches such as Graphene-
SGX [52] and Haven [21]. The size of compiled microns in
MB is an orders of magnitude smaller than Graphene-SGX.
PANOPLY TCB. PANOPLY adds an average of 19.62 KLOC
per application which is 5.8% of the original application code.
11
TABLE III.
TCB EVALUATION. THE TABLE SUMMARISES THE TCB COMPONENTS OF PANOPLY AND GRAPHENE-SGX IN TERMS OF LOC AND SIZE OF COMPILED
ENCLAVE BINARIES. COLUMNS 2-5 REPORT THE BREAK-DOWN FOR THE LOC OF EACH COMPONENT INCLUDED IN THE MICRON, AND COLUMN 6 HIGHLIGHTS THE PERCENTAGE
INCREASE IN THE TCB DUE TO PANOPLY. COLUMNS 7-13 REPORT THE LIBRARIES INCLUDED () IN THE COMPILED ENCLAVE BINARY, AND A DENOTES THAT THE MICRONS
DO NOT REQUIRE THE LIBRARY. COLUMN 14 DENOTES THE TOTAL SIZE OF COMPILED MICRONS. COLUMNS 15-18 DENOTE THE COMPILED SIZE OF VARIOUS COMPONENTS
INCLUDED BY GRAPHENE-SGX TCB. COLUMN 19 REPORTS THE TOTAL SIZE OF COMPILED ENCLAVES FOR GRAPHENE-SGX.
Case Study
OpenSSL
H2O
FreeTDS
Tor
Enclave
Logic
256987
414918
297108
436385
PANOPLY TCB in LOC
Boilerplate
PANOPLY
Code
9004
9189
9788
8817
Logic
10425
10425
10425
10425
Total
276416
434532
317321
455627
% Inc
7.56
4.72
6.80
4.41
libssl
(0.765)




libcrypto
(3.7)




Split-up for PANOPLY TCB (in MB)
libz
libyrmcds
libyaml
(0.185)
libevent
(0.579)
(0.137)
(0.06)
















SDK
(0.05)




Enclave
Size
5.88
7.98
6.08
13.18
Graphene (in MB)
Trusted
PAL
1.84
1.84
1.84
1.84
Enclave
0.067
16
1.2
7.0
Libs
64.58
64.70
64.58
63.94
SDK
0.05
0.05
0.05
0.05
Enclave
Size
64.69
80.75
65.83
70.99
TABLE IV.
PERFORMANCE EVALUATION. COLUMNS 2-5 REPORT THE STATISTICS ABOUT PANOPLY MICRONS. COLUMNS 6-9 DENOTE THE CPU CYCLES CONSUMED BY
PANOPLY. COLUMNS 10-12 DENOTE THE EXECUTION TIME FOR EACH CASE STUDY AND THE CONTRIBUTION OF PANOPLY TO THE TOTAL TIME.
Case
Study
No. of
Microns
OpenSSL
H2O
FreeTDS
Tor
2
2
2
6
Inter-
Micron
APIs
1
1
1
30
No. of
OCALLs
No. of
ECALLs
23695
124287
86198
286459
1
5
1
5
Non-Micron
/ SDK
0.25
0.35
0.47
6.65
Create
Delete
6.06
17.08
22.31
11.77
Enclave
Logic
0.11
6.11
0.07
2.58
Total
6.43
23.54
22.64
17.41
Empty
Enclave
2.79
6.56
8.60
4.54
Split-up of CPU Cycles (in billions)
CPU Time (in seconds)
PANOPLY
3.16
8.79
8.74
6.72
Average
Increase
%
13
34
1
48
24
TABLE V.
BREAKDOWN OF LOC AND TCB SIZES OF GRAPHENE-SGX
COMPONENTS. GLIBC LOC AND SIZE COMPUTATION ACCOUNTS FOR THE WHOLE
CODEBASE COMPRISING OF ALL LIBRARIES AND PLATFORM-SPECIFIC CODE.
Component
glibc
libPAL-LinuxSGX
libPAL-enclave
SGX SDK
Total
LOC
1156740
16901
33103
119234
1325978
Size (in MB)
56.9
0.9
0.2
0.5
58.5
Columns 2-5 in Table III shows the LOC split-up for each
case-study. Out of the total LOC included by PANOPLY in
each micron, 9.2 KLOC (46.3%) of code is automatically
generated boilerplate code to facilitate OCALLs and ECALLs
mechanism. This code is generated by the Intel edger8r
tool, which takes in a .edl interface ﬁle and creates stubs
for passing parameters across micron boundaries. We believe
that this code is easy to automatically verify in the future. In
terms of compiled code size, each micron binary includes the
original application logic, corresponding application libraries,
the trusted libraries added by Intel SDK and PANOPLY shim
library. Columns 7-14 in Table III show the split-up for the
micron binary size. Note that PANOPLY selectively adds a
library to a micron, if-and-only-if the micron code needs it.
More importantly, PANOPLY does not include system libraries
such as libc, libdl, libpthread in the micron.
Comparison to Graphene-SGX TCB. We refer to the public
release of Graphene-SGX [3] to compute the total LOC
of system. Table V shows the LOC of each component in
Graphene-SGX, and the corresponding binary size. Graphene-
SGX library comprises of a Platform Adaptation Layer, Linux
library, and system libraries required to support a pico-process.
In terms of LOC, this amounts to an increase of 1.326 MLOC.
When compared with PANOPLY, this amounts to 2 orders of
magnitude (127.19×) larger TCB. Note that the TCB and
binary sizes are dependent on the application. We port our
four case studies to Graphene-SGX and measure the total
size of the binaries, since counting per-binary LoC is more
complicated. Columns 15-19 in Table III lists the breakdown of
size of each component. On an average, Graphene-SGX pico-
process binaries are an order of magnitude larger as compared
to PANOPLY microns. Haven reports a TCB of millions of lines
of code in the paper [21], however we do not have access to
the system to directly compare with PANOPLY.
12
D. PANOPLY Performance
PANOPLY adds a 24% CPU overhead to the application’s
execution time (Table IV) on an average, over the baseline
cost of creating empty enclaves. It achieves comparable perfor-
mance as Graphene-SGX, with PANOPLY’s overheads higher
by 5-10%. PANOPLY strictly prioritizes TCB over perfor-
mance, and does not include any optimizations such as buffer-
ing. However, future systems can improve over PANOPLY by
incrementally adding optimization with careful considerations
for TCB bloat.
Performance Breakdown. We measure the micron execution
bottlenecks as well as the breakdown for the total number of
CPU cycles it consumes. (Table IV) Column 6-9 present the
average number CPU cycles that each application consumes for
various operations during its entire execution. Our preliminary
performance measurements identiﬁed that bulk of the CPU
cycles are spent in the Intel SDK. On further investigation, we
identiﬁed three main factors which contribute to this.
First, the operation of creating and destroying enclaves
takes up 6-7 billion CPU cycles for various sizes of enclaves.
We launch each of the application enclaves and destroy them
without executing any logic inside the enclave. Column 7 in
Table IV denotes the number of cycles to do this for each
speciﬁc case-study. These operations are performed by the Intel
SDK, and are not an artifact of PANOPLY’s design. Thus, 96%
of the CPU cycles are due to enclave launch and tear-down
(Column 7 vs Column 9 in Table IV). Taking this cost as a
baseline, PANOPLY has a 24% overhead.
Second, copying enclave data to-and-from non-enclave
memory contributes to signiﬁcant fraction of CPU cycles
consumed by the application. Speciﬁcally, these operations
involve encryption-decryption of data entering/leaving the en-
clave memory, which consumes CPU cycles. For example, in
the H2O application, the number and volume of such a copy
operation is directly proportional to the size of the served web-
page. To test this aspect, we measure the throughput of H2O
webserver by serving two sizes of web-pages: 200 Bytes, 1
KB, and 6 KB for a total of 100, 000 requests from 100 clients.
As shown in Figure 7, the webserver throughput decreases
as we increase the size of the web-pages. The shaded-region
Fig. 7. PANOPLY Performance for 100000 requests of various page sizes.
Fig. 9. OpenSSL Throughput Performance of PANOPLY & Graphene-SGX.
Fig. 8. LMBench Latency Performance of PANOPLY & Graphene-SGX.
Fig. 10. LMBench Bandwidth Performance of PANOPLY & Graphene-SGX.
of the bar-graph denotes the fraction of execution time spent
in the SDK routine for OCALLs. Thus, larger the number of
OCALLs, the more is the overhead. As we can also see from
Table IV, applications which have less number of OCALLs,
exhibit lower overheads.
Third, all of our case studies use OpenSSL routines for
various operations ranging from SSL connections to cryp-
tographic operations. The OpenSSL library ﬁrst checks if
the underlying hardware supports AES-NI via cpuid. If it