### 试用  
1、运行5条SQL，开2个并行任务  
```  
select * from run_sqls_parallel(  
 -- 并行度  
 parallels := 2,  
 -- SQLs: 将并行执行的SQL放到一个数组里面  
 sqls := array['select pg_sleep(10)', 'select pg_sleep(10)', 'select pg_sleep(10)', 'select count(*) from pg_class where relname ~ ''t''', 'select pg_sleep(10)', 'select pg_sleep(10)'],  
 -- 连接串  
 conn_url := format('hostaddr=%s port=%s user=%s dbname=%s password=%s application_name=', '127.0.0.1', current_setting('port'), current_user, current_database(), 'test123')  
)  
as t(a text);  
NOTICE:  current running tasks: 2, waiting idle conns.  
NOTICE:  current running tasks: 2, waiting idle conns.  
NOTICE:  current running tasks: 2, waiting idle conns.  
NOTICE:  current running tasks: 2, waiting idle conns.  
NOTICE:  current running tasks: 2, waiting idle conns.  
NOTICE:  current running tasks: 2, waiting idle conns.  
NOTICE:  current running tasks: 2, waiting idle conns.  
NOTICE:  current running tasks: 2, waiting idle conns.  
NOTICE:  current running tasks: 2, waiting idle conns.  
NOTICE:  current running tasks: 2, waiting idle conns.  
NOTICE:  current running tasks: 2, waiting idle conns.  
NOTICE:  current running tasks: 2, waiting idle conns.  
NOTICE:  current running tasks: 2, waiting idle conns.  
NOTICE:  current running tasks: 2, waiting idle conns.  
NOTICE:  current running tasks: 2, waiting idle conns.  
NOTICE:  current running tasks: 2, waiting idle conns.  
NOTICE:  current running tasks: 2, waiting idle conns.  
NOTICE:  current running tasks: 2, waiting idle conns.  
NOTICE:  current running tasks: 2, waiting idle conns.  
NOTICE:  current running tasks: 2, waiting idle conns.  
NOTICE:  the last 2 tasks running.  
NOTICE:  the last 1 tasks running.  
NOTICE:  the last 1 tasks running.  
NOTICE:  the last 1 tasks running.  
NOTICE:  the last 1 tasks running.  
NOTICE:  the last 1 tasks running.  
NOTICE:  the last 1 tasks running.  
NOTICE:  the last 1 tasks running.  
NOTICE:  the last 1 tasks running.  
NOTICE:  the last 1 tasks running.  
NOTICE:  whole tasks done.  
 run_sqls_parallel  
-------------------  
(1 row)  
Time: 30070.275 ms (00:30.070)  
```  
每次调用完任务后, 记得释放空闲的dblink连接, 防止连接被打满.  
```  
select dblink_disconnect (n) from unnest(dblink_get_connections ()) n where  dblink_is_busy(n) = 0;  
```  
2、运行10个并行任务，跑6条SQL  
```  
postgres=# select * from run_sqls_parallel(  
 -- 并行度  
 10,  
 -- SQLs: 将并行执行的SQL放到一个数组里面  
 array['select pg_sleep(10)', 'select pg_sleep(10)', 'select pg_sleep(10)', 'select count(*) from pg_class where relname ~ ''t''', 'select pg_sleep(10)', 'select pg_sleep(10)'],  
 -- 连接串  
 conn_url := format('hostaddr=%s port=%s user=%s dbname=%s password=%s application_name=', '127.0.0.1', current_setting('port'), current_user, current_database(), 'test123')  
)  
as t(a text);  
NOTICE:  the last 6 tasks running.  
NOTICE:  the last 5 tasks running.  
NOTICE:  the last 5 tasks running.  
NOTICE:  the last 5 tasks running.  
NOTICE:  the last 5 tasks running.  
NOTICE:  the last 5 tasks running.  
NOTICE:  the last 5 tasks running.  
NOTICE:  the last 5 tasks running.  
NOTICE:  the last 5 tasks running.  
NOTICE:  the last 5 tasks running.  
NOTICE:  whole tasks done.  
 run_sqls_parallel  
-------------------  
(1 row)  
Time: 10050.064 ms (00:10.050)  
```  
完全符合预期。  
每次调用完任务后, 记得释放空闲的dblink连接, 防止连接被打满.  
```  
select dblink_disconnect (n) from unnest(dblink_get_connections ()) n where  dblink_is_busy(n) = 0;  
```  
3、结合前面写的文档，我们如果要创建很多索引，可以使用同样的方法实现并行任务  
```  
create table t1(id int, c1 int,c2 int, c3 int, c4 int, c5 int,c6 int, c7 int, c8 int);  
create table t2(id int, c1 int,c2 int, c3 int, c4 int, c5 int,c6 int, c7 int, c8 int);  
create table t3(id int, c1 int,c2 int, c3 int, c4 int, c5 int,c6 int, c7 int, c8 int);  
```  
```  
do language plpgsql $$  
declare  
  tables name[] := array['t1','t2','t3'];     -- 表名  
  n name;   -- 表名  
  x name;   -- 字段名  
  i int;    -- LOOP值  
  sql text;  
  sqls text[];  
  -- tbs name := 'tbs1';    -- 索引表空间  
begin  
  set maintenance_work_mem='1GB';  
  foreach n in array tables loop  
    i := 1;  
    for x in select attname from pg_attribute where attrelid=n::regclass and attnum>=1 and not attisdropped  
    loop  
      -- 结合自动选择索引接口（btree,hash,gin,gist等）的功能，可以实现更完美的全字段创建索引  
      -- [《自动选择正确索引访问接口(btree,hash,gin,gist,sp-gist,brin,bitmap...)的方法》](../201706/20170617_01.md)  
      -- [《PostgreSQL SQL自动优化案例 - 极简，自动推荐索引》](../201801/20180111_02.md)  
      -- [《PostgreSQL 快速给指定表每个字段创建索引 - 2 (近乎完美)》](../201809/20180903_03.md)  
      -- sql := format('create index on %s (%s) tablespace %s', n, x, tbs);      -- 封装创建索引的SQL , 指定索引表空间  
      sql := format('create index on %s (%s)', n, x);      -- 封装创建索引的SQL , 不指定索引表空间  
      sqls := array_append(sqls, sql);  
      i:=i+1;  
    end loop;  
  end loop;  
  perform * from run_sqls_parallel(  
    parallels := 10,   -- 并行度  
    sqls := sqls,  -- 执行index SQL数组  
    conn_url := format('hostaddr=%s port=%s user=%s dbname=%s password=%s application_name=', '127.0.0.1', current_setting('port'), current_user, current_database(), 'test123')  
  ) as t(a text);  
  foreach n in array tables loop  
    execute format('analyze %s', n);  
  end loop;  
  -- 释放空闲的dblink连接, 防止连接被打满.  
  perform dblink_disconnect (unnest) from unnest(dblink_get_connections ()) unnest where  dblink_is_busy(unnest) = 0;  
end;  
$$;  
```  
完全符合预期。  
## 小结  
本文使用dblink异步调用的功能，增加了一个API函数，可以用于开启N个并行，跑若干条长SQL，例如用来创建索引非常给力。  
接口效果：  
```  
select * from run_sqls_parallel (  
  参数1：并行度,  
  参数2：要执行的SQLs(数组呈现)  
  参数3：连接串  
)  
as t(a text);  
```  
## 参考  
[《自动选择正确索引访问接口(btree,hash,gin,gist,sp-gist,brin,bitmap...)的方法》](../201706/20170617_01.md)  
[《PostgreSQL 快速给指定表每个字段创建索引》](../201808/20180822_01.md)  
[《阿里云RDS PostgreSQL OSS 外部表实践 - (dblink异步调用封装并行) 从OSS并行导入数据》](../201804/20180427_01.md)  
[《在PostgreSQL中跑后台长任务的方法 - 使用dblink异步接口》](../201806/20180621_03.md)  
[《PostgreSQL AB表切换最佳实践 - 提高切换成功率，杜绝雪崩 - 珍藏级》](../201807/20180725_04.md)  
#### [PostgreSQL 许愿链接](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216")  
您的愿望将传达给PG kernel hacker、数据库厂商等, 帮助提高数据库产品质量和功能, 说不定下一个PG版本就有您提出的功能点. 针对非常好的提议，奖励限量版PG文化衫、纪念品、贴纸、PG热门书籍等，奖品丰富，快来许愿。[开不开森](https://github.com/digoal/blog/issues/76 "269ac3d1c492e938c0191101c7238216").  
#### [9.9元购买3个月阿里云RDS PostgreSQL实例](https://www.aliyun.com/database/postgresqlactivity "57258f76c37864c6e6d23383d05714ea")  
#### [PostgreSQL 解决方案集合](https://yq.aliyun.com/topic/118 "40cff096e9ed7122c512b35d8561d9c8")  
#### [德哥 / digoal's github - 公益是一辈子的事.](https://github.com/digoal/blog/blob/master/README.md "22709685feb7cab07d30f30387f0a9ae")  
![digoal's wechat](../pic/digoal_weixin.jpg "f7ad92eeba24523fd47a6e1a0e691b59")  
#### [PolarDB 学习图谱: 训练营、培训认证、在线互动实验、解决方案、生态合作、写心得拿奖品](https://www.aliyun.com/database/openpolardb/activity "8642f60e04ed0c814bf9cb9677976bd4")  
#### [购买PolarDB云服务折扣活动进行中, 55元起](https://www.aliyun.com/activity/new/polardb-yunparter?userCode=bsb3t4al "e0495c413bedacabb75ff1e880be465a")
#### [About 德哥](https://github.com/digoal/blog/blob/master/me/readme.md "a37735981e7704886ffd590565582dd0")