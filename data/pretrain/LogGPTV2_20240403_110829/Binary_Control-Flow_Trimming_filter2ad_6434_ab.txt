fore not useful to monitor). Thus, the edge set includes targets of
conditional branches, indirect (computed) branches, and returns.
Let T1 be a set of program execution traces that exhibit only
software features that must be preserved, and let T2 be a set that in-
cludes traces for both wanted and unwanted features. T1 is provided
by the user, and is assumed to be noise-free; every trace exhibited
during training is a critical one that must be preserved after control-
flow trimming. However, we assume there may be additional critical
traces requiring preservation that do not appear in T1. The learning
algorithm must therefore conservatively generalize T1 in an effort
to retain desired functionalities. T2 is assumed to be unavailable
during training, and is used only for evaluation purposes to assess
whether our training methodology learns accurate policies.
Control-flow contexts are defined as finite-length sub-sequences
of traces. A CCFG policy can therefore be defined as a set of permis-
sible control-flow contexts. While the logic for precisely enforcing
an entire CCFG policy could be large, the logic needed to enforce
the policy at any particular branch origin need only consider the
subset of the policy whose final edge begins at that branch origin.
This distributes and specializes the logic needed to enforce the
policy at any given branch site in the program.
Context lengths are not fixed in our model. While an upper
bound on context lengths is typically established for practical rea-
sons, our approach considers different context lengths at different
e3
γ = 2, λ = 5
e2
γ = 2, λ = 4
e1
γ = 1, λ = 1
e1
γ = 1, λ = 1
e3
γ = 1, λ = 1
e2
γ = 2, λ = 2
e2
γ = 1, λ = 1
Figure 2: Sample decision tree for edge e3
branch sites based on an estimate of the benefits, as measured by
information gain. In our design, we first suppose there is a fixed
size (possibly large) for the contexts, and then proceeded to accom-
modate variable-sized contexts.
To maximize effectiveness, contexts must include as much policy-
relevant control-flow information as possible without being pol-
luted with uninformative edges. Indirect branches and returns are
the primary sources of control-flow hijacks, so are included. Direct
calls and jumps are also included even though they have fixed desti-
nations, because we found that doing so allows the training to learn
a form of call-return matching that improves accuracy. We also
include conditional branch destinations in the contexts, since they
often implement series of tests that conditionally activate software
features that may be targets of trimming.
The learning algorithm is a binary classification that decides
for each control-flow edge whether it is permissible, based on the
last k edges currently in the context. We chose decision trees as
our learning model, since they are relatively simple and efficient
to implement at the binary level. While decision trees can suffer
from overfitting, such overfitting is potentially advantageous for
our problem because every trace in T1 must be preserved. Higher
security therefore results from a conservatively tight model that
can be conditionally relaxed at points of uncertainty.
For a given edge e, the learning algorithm creates a decision tree
as follows: The root is labeled with e and the depth of the tree is k,
where k is the maximum size of the context. Each node at level i ≥ 1
of the tree is labeled with the edge e′ appearing immediately before
the context defined by the path from the node’s parent at level i up
to the root. It is additionally annotated with the number of traces
γ and number of contexts λ in which that particular edge-label
occurs at that context position. These numbers are used during
uncertainty detection and policy relaxation (§3.2).
Every leaf of this tree represents a permissible control-flow his-
tory encoded by the path from it to the root. The feature encoded
by a node at level i + 1 is the i-to-last edge in the context when the
edge labeled at the root is reached. So, given a context χ we can
check whether it is permissible as follows: The last edge in χ must
be a root of some tree in our learned decision tree forest; otherwise
the impending branch is rejected. The penultimate edge in χ should
be one of that root’s children; otherwise the impending branch is
rejected. We continue to check the context edges in χ in reverse
order until we reach a decision tree leaf. Reaching a leaf implies
policy-compliance, and the impending branch is permitted.
To illustrate, consider a hypothetical program with two sam-
ple traces: one containing sub-sequences [e1, e2, e3], [e2, e2, e3] and
[e3, e2, e3]; and the other containing sub-sequences [e2, e1, e3] and
[e2, e2, e3]. Figure 2 shows the decision tree made for edge e3 out of
these sub-traces. The root is labeled with (e3, γ = 2, λ = 5), since
there are 2 traces and 5 histories having edge e3. Edge e2 is the
penultimate edge in 4 of those cases, and e1 is the penultimate edge
in 1 case, causing nodes (e2, γ = 2, λ = 4), and (e1, γ = 1, λ = 1) to
comprise the next level of the tree. In the same way, the nodes at the
bottom level correspond to the antepenultimate edges appearing
in each context. Edges e1, e3, and e2 are antepenultimate when e2
is penultimate, and e2 is antepenultimate when e1 is penultimate.
Observe that the labels are not unique; the same label or edge can
be assigned to some other node of the same tree. In addition, for
any node, λ is the sum of its child λ’s, while γ is not.
non-contextual CFI (i.e., no debloating). Pruning therefore finds a
middle ground between trimming only the developer-unintended
features and over-trimming the consumer-wanted features.
For example, in Figure 2 the confidence score of the root and
the node labeled (e2, γ = 2, λ = 4) are 0.36 and 0.31, respectively. If
our confidence threshold exceeds a node’s confidence score, then
context is disregarded when making policy decisions at that origin.
So in our example, a confidence threshold of 0.35 prunes the tree
after node (e2, γ = 2, λ = 4), making that node a leaf. This refines
the policy by disregarding policy-irrelevant context information.
3.2 CCFG Policy Relaxation
To cope with the inevitable incompleteness of training data that
is assumed to be amassed without guidance from source code, we
next consider the problem of generalizing the decision tree forest to
include more child nodes than were explicitly observed during train-
ing. In general, if training observes many diverse jump destinations
for a specific subtree, that subtree may have a complex behavior
that was not exhaustively covered by training. There is therefore a
high chance that additional consumer-desired destinations for that
branch site exist that were not explicitly observed.
The same is true for diverse collections of contexts. If the con-
textual information at a given tree node is highly diverse and offers
little information gain, this indicates that the context at that po-
sition is not a useful predictor of whether the impending branch
is permissible. For example, the branch may be the start of what
the user considers an independent semantic feature of the software,
in which case the context is reflecting a previous semantic feature
that has little relevance to the permissibility of this branch point.
Thus, nodes with numerous low-frequency child nodes should be
considered with low confidence.
To estimate this confidence level, we use entropy to calculate an
uncertainty metric using the number of times different child nodes
of a node appear in the training. Nodes with diverse children have
higher entropy. The confidence score of a node n is computed as
confidence(n) =
× − 1
2
M
γ
N
λm
λ
logM
(1)
where(e, γ , λ) is node n’s label, M is the number of node n’s children,
(em, γm, λm) is child m’s label, and N is the total number of traces.
This formula combines the probability of a node being in a trace,
the entropy of its children λ, and the number of its children. It
is inversely related to entropy because, for any given number of
children M, we have higher confidence if the distribution of child
frequencies is relatively flat. For example, if we observe two children
with λ’s 5 and 5, we have higher confidence than if we observe
two children with λ’s 1 and 9. The former indicates a well-covered,
predictable behavior, whereas the latter is indicative of a behavior
with rare outliers that were not covered well during training. Fewer
children likewise engender higher confidence in the node.
An ideal confidence threshold t∗ that maximizes accuracy on the
training set is computed using crossfold validation (see §5), and all
children with confidence below t∗ are pruned from the forest. In
the worst case, pruning all the trees to a height of 1 yields a non-
contextual CFG that is the policy that would be enforced by typical
M
m=1
(cid:18) λm
(cid:19)
λ
| χ |
3.3 Enforcing CCFG Policies
In-lining guard code that enforces a highly context-sensitive pol-
icy at every computed branch without incurring prohibitive over-
heads raises some difficult implementation challenges. To track
and maintain contexts, our enforcement must additionally instru-
ment all direct calls, conditional branches, and interrupt handlers
with context-update logic. Space-efficiency is a challenge because
CCFG policies are potentially large—code with b branch sites and
context-length bound k can have CCFG policies of size O(bk) in the
worst case. Time-efficiency is a challenge because policy decisions
for CCFGs potentially require O(k) operations, in contrast to non-
contextual CFG policies, which engender constant-time decisions.
To obtain acceptable overheads in the face of these challenges,
our implementation compactly represents contexts as hash codes,
and represents CCFG policies as sparse hash tables of bits, where
an entry of 1 indicates a permitted context. The hash function need
not be secure since our enforcement protects hash values via access
controls (see §4), but it must be efficiently computable and uniform.
We therefore use the relatively simple hash function given by
i =1
hash(χ) =
((π2 χi) ≪ (|χ| − i)s)
where is xor, |χ| is the length of context χ, π2 χi is the destination
(second projection) of the ith edge in χ, ≪ is bit-shift-left, and s ≥ 0
is a shift constant. This has the advantage of being computable in
an amortized fashion based on the following recursion:
(2)
hash(χe) = (hash(χ) ≪ s) ⊕ (π2e)
(3)
The CCFG hash table is constructed by storing a 1 at the hash of
every policy-permitted context. This can introduce some impreci-
sion in the form of hash collisions, since a policy-violating context
can have the same hash code as a policy-permitted context, causing
both to be accepted. However, this collision rate can be arbitrarily
reduced by increasing shift-constant s and the bit-width w of shift
operation ≪. For example, setting s to the address-width a and
using w = ka guarantees no collisions, at the expense of creating a
large table of size 2ka−3 bytes. On 64-bit architectures, we found
that using s = 1 and w ≈ log2 c where c is the code segment size
works well, since all branch destination offsets (into their respective
code segments) are less than c, and the offset portion of the address
is where the most policy-relevant bits reside. This yields a hash
table of size O(c), which scales linearly with program size.
Table 3: Guard checks for each kind of branch type
Description
Conditional
Jumps
Indirect calls
Rewritten Code
call jcc_fall
.quad l
Original code
jcc l
call r /[m]
mov r /[m], %rax
call indirect_call
Indirect Jumps
jmp r /[m]
Variable Returns
ret n
Returns
ret
mov %rax, -16(%rsp)
mov r /[m], %rax
call indirect_jump
pop %rdx
lea n(%rsp), %rsp
push %rdx
jmp return
mov (%rsp), %rdx
jmp return
4 IMPLEMENTATION
To generate sample traces, we use Pin [46] and DynamoRIO [14]
to track all branches during each run of each test program. We
then apply our machine learning algorithm with the hash function
defined in §3.3 to generate the CCFG hash table. The hash table
is added in a relocatable, read-only data section accessible from
shared libraries while protecting it from malicious corruption.
Table 3 transforms each type of branch instruction (column 2)
to guard code (column 3). To reduce code size overhead, the guard
code is modularized into trampolines that jump to a policy-check
before jumping to each target. This trades smaller code size for
slightly higher runtime overhead. Table 4 shows the details of the
trampoline code called by branch guards (Table 3), which invoke
policy checks and state updates (Table 5).
Guard code for conditional jumps must carefully preserve all
CPU status flags until the branch decision is made. Since sequences
of n consecutive conditional jumps can implement an n-way branch,
we avoid corrupting status flags by updating the context before the
sequence is complete, in-lining only one fall-through trampoline
for the sequence. This is achieved by using another trampoline
jcc_back for the first n − 1 instructions, which fall-through with-
out checking the destination because the guards in Table 5 are the
only parts that affect flags. A similar strategy applies to conditional
branches followed by Intel conditional-moves (setcc and cmovcc).
This results in a maximum of 67 trampolines for all possible condi-
tional jumps (2× 32 for the two directions of each of the 32 possible
conditional jump instructions on x86-64, plus 3 other trampolines
fall_l, back_l, and jump_l).
Table 5 shows the common guard invoked by the trampolines,
which updates the context and consults the hash table to enforce the
policy. Two implementations are provided: the center column uses
SSE instructions, which are widely available on Intel-based pro-
cessors; while the rightmost column provides a more efficient imple-
mentation that leverages SHA-extensions (sha1msg1 and sha1msg2)
that are presently only available on a few processor lines [5]. Our
experiments and the descriptions that follow use the legacy-mode
implementation, but we expect improved performance of our algo-
rithm as SHA extensions become more available.
Table 4: Trampolines used in guards referred in Table 3
Label
indirect_jump:
indirect_call:
return:
jcc_fall:
jcc_back:
jump_l:
fall_l:
back_l:
condition_jump:
Assembly Code
-8(%rsp), %rax
%rax
%rax
push
common-guard
mov
ret
push
common-guard
ret
common-guard
ret
jcc
jmp
jcc
jmp
xchg
mov
jmp
xchg
lea
jmp
xchg
lea
xchg
ret
push
common-guard
pop
xchg
ret
%rax
jump_l
fall_l
jump_l
back_l
(%rsp), %rax
(%rax), %rax
condition_jump
(%rsp), %rax
8(%rax), %rax
condition_jump
(%rsp), %rax
8(%rax), %rax
(%rsp), %rax
%rax
(%rsp), %rax
For efficiency and safety, we store contexts in 128-bit xmm regis-
ters rather than memory. Register %xmm14 maintains a length-4 con-
text as four packed 32-bit unsigned integers, and %xmm15 maintains
the context hash. On entry to the before-check code, %xmm13 con-
tains the section base address and general (64-bit) register r holds
the impending branch target to check. Register r varies depending
on the branch type (%rdx for returns and %rax for others).
This implementation strategy requires the target program to
have at most 12 live xmm registers (out of 16 total) at each pro-
gram point, leaving at least 2 to globally maintain context and
context-hash, plus 2 more for scratch use at each guard site. More
constrained xmm register usage is rare, but can be supported by
spilling xmm registers to general-purpose registers or to memory.
Two of the evaluated programs in §5 require this special treatment
(postgres and postmaster), and exhibited slightly higher than aver-
age overheads of 3% as a result.
Lines 1–2 of before-check calculate the target offset. Line 3
then updates the hash code using Equation 3. After this, %xmm12
and %xmm15 have the target offset and the new hash, respectively.
The check operation implements the policy check. Line 5 trun-
cates the hash value to the size of the hash table. Finally, line 6
finds the bit corresponding to the hash value in the table, and line 7
jumps to the trap in case it is unset, indicating a policy rejection.
The after-check code updates the history in %xmm14 and the
hash code in %xmm15. It does so by extracting the oldest context
entry about to be evicted (line 8), shifting the context left to evict