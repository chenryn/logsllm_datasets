6.3 Side-Channel Discussion
The re-keying of the (authenticated) encryption scheme
guarantees that adversaries are not capable of building suit-
able DPA power models from the observation of ciphertexts
and thus prevents DPA against the key completely.
To prevent the loss of plaintext conﬁdentiality from the
proﬁled, second-order attacks outlined in Section 4, the pro-
posed masking scheme randomizes the plaintext input using
d − 1 random, secret masks. As a result, the scheme requires
adversaries to combine side-channel information from (d + 1)
diﬀerent values to recover the plaintext, i.e., to perform a
(d + 1)-th order DPA. In particular, such DPA requires to
learn side-channel information on the varying key, an inter-
mediate value in the cipher, and the d − 1 masks. On the
other hand, the masking scheme requires to additionally en-
crypt d − 1 masks in each tree node. However, for a properly
chosen encryption scheme EN C, these encryption operations
cannot be exploited in a DPA, because both the masks and
the keys are random and always changed simultaneously on
every write access to the respective tree node.
Note, however, that in order for the masking to protect
Meas also in the presence of hardware glitches, the sum of
plaintext and the masks must be stored in a register prior to
the encryption operation. This is automatically the case if
the masking is implemented in software. Hereby, the result is
stored in a register and may then, e.g., be further processed
in a cryptographic hardware accelerator.
Besides, we also emphasize that proﬁled DPA attacks such
as in Section 4—which are counteracted by the proposed
masking scheme—are quite hard to conduct on state-of-the-
art systems. For example, while the unknown plaintext
697template attack in [19] was performed against software im-
plementations on 8-bit and 32-bit microcontrollers, a proﬁled
DPA will take signiﬁcantly more eﬀort on hardware imple-
mentations embedded in a complex system-on-chip. More-
over, the attack complexity also rises rapidly with the attack
order. As a result, small protection orders will already be
suﬃcient for Meas in practice. However, a detailed analysis
of the side-channel leakage of a device implementing Meas
is indispensable for a proper choice of the protection order.
6.4 Implementation Aspects
The deﬁnite choice of the implemented protection order
allows for various trade-oﬀs inﬂuenced by several parameters:
the cost for storing the masks, the concrete leakage behavior
of the device, and the risk. Hereby, the leakage behavior and
the cost for storing the masks are closely coupled.
A DPA is more likely to be successful on a device the
more side-channel leakage the device gives. Therefore, a
higher protection order is needed the more the device leaks,
which leads to higher storage costs for masks. Alternatively,
the leakage of the device might be reduced by hiding coun-
termeasures [28] in the implementation, such as shuﬄing.
However, such countermeasures can only be built into newly
designed devices. Nevertheless, besides the actual strength
of a potential attacker, the actual leakage behavior of the
device forms the basis for the choice of the protection order
and thus memory cost.
Besides, the choice of the protection order is also strongly
inﬂuenced by the concrete risk of an attack. In more detail, a
trade-oﬀ between the protection order and the risk is possible.
Namely, the higher the risk of an attack to a speciﬁc block,
the better should be the protection of the respective block,
i.e., the higher should be the protection order. Concretely in
Meas, the tree nodes stored in levels closer to the root are
a more interesting target for an attacker since revealing the
keys stored in these nodes would allow to decrypt large parts
of the memory. Therefore, tree nodes closer to the root are at
higher risk and thus need a higher protection order. However,
the number of nodes in one tree level decreases the closer
the respective level is to the root. As a result, increasing
the protection order for tree nodes at higher risk has only
little memory overhead in Meas and thus is an inexpensive
improvement of security against higher-order DPA.
7. EVALUATION
Meas is a novel approach to provide authentic and conﬁ-
dential memory with DPA protection. While there already
exist several concepts for memory encryption and authenti-
cation (cf. Section 2), all of them lack the consideration of
side-channel attacks.
In this section, we compare Meas with these state-of-the-
art techniques regarding security properties, parallelizability,
randomness, and memory overhead. Our methodology to
assess the overheads is independent of any concrete implemen-
tation and allows to precisely state the asymptotic memory
requirements of all schemes for any real-world instance. It
shows that Meas can eﬃciently provide ﬁrst-order DPA-
secure memory encryption and authentication at roughly the
same cost as existing authentication techniques, which, on
the other hand, completely lack the consideration of DPA at
all. Put into numbers, a 4-ary, ﬁrst-order DPA secure Meas
instance for standard hard disks results in a very low memory
overhead of 7.3%. Contrary to that, using DPA-protected
implementations in contemporary memory encryption and
authentication schemes would be impractical due to their
massive implementation overheads.
7.1 Security Properties
Comparing the contestants in Table 1 regarding security
properties shows that only Meas and TEC trees provide
both conﬁdentiality and authenticity in the form of spooﬁng,
splicing and replay protection. DPA security, on the other
hand, is only featured by Meas and Merkle trees. However,
Merkle trees do not provide conﬁdentiality and their DPA
security can be considered a side eﬀect. Namely, the hash
functions used in Merkle trees simply do not use any secret
material, i.e., keys or plaintexts, which is the common target
in DPA attacks.
7.2 Parallelizability
A more performance oriented feature, on which previous
tree constructions typically improved on, is the ability to
compute the cryptographic operations involved in read and
write operations in parallel. Having this property is nice
in theory, but is in practice not the deciding factor to gain
performance. To make use of a scheme’s parallelism, multiple
parallel implementations of the cryptographic primitives as
well as multi-port memory, to read and write various nodes
in parallel, are required. Since these resources are typically
not available, a common, alternative approach to improve
performance is the excessive use of caches.
In Meas, due to the key encapsulation approach used
to achieve its DPA security, parallelizing the computations
within the encryption scheme is not possible. However, this is
not necessarily a problem preventing the adoption of Meas in
practice since on-chip computation is very fast compared to
oﬀ-chip memory accesses. Additionally, like for all authenti-
cation trees, caches for intermediate nodes are a very eﬀective
and important measure to reduce the average latency. In
summary, the performance of any authentication tree (and
Meas) is mainly determined by the tree height, which de-
pends on both the tree arity and the number of blocks in the
authenticated memory, and the cache size. As a result, given
a concrete implementation of the cryptographic primitive,
the actual runtime performance of all authentication trees is
expected to be quite similar.
7.3 Memory Overhead
Table 1 further contains the memory overhead formulas
that have been derived for each scheme. These formulas take
into account the tree arity a, and the sizes for data blocks sb,
nonces snonce, hashes shash, tags stag, and keys skey. The
overhead formulas neglect the inﬂuence of the actual number
of data blocks m given that it vanishes with rising node
counts. The overheads therefore have to be considered as an
upper bound which gets tight with m → ∞. This approach
gives exact and comparable results that are independent
of the actual implementation and that are realistic for any
memory with more than 128 data blocks.
The diﬀerent parameters involved may make the over-
head comparison seem diﬃcult at ﬁrst glance. However,
it gets quite simple when actual instantiations are consid-
ered. Instantiating the trees for a ﬁxed security level with
snonce = stag = skey and shash = 2 · stag, for example, shows
that Merkle trees, PATs, and TEC trees have identical over-
head. The overhead of Meas, on the other hand, is even
698Meas (1st-order DPA security)
Merkle Tree / PAT / TEC Tree
Meas (2nd-order DPA security)
Meas (3rd-order DPA security)
140
120
100
80
60
40
20
]
%
[
d
a
e
h
r
e
v
O
0
512
1024
2048
4096
8192
16384
Block Size [bit]
Figure 3: Memory overhead comparison for 4-ary
trees depending on protection order and block size
with a security level of 128 bits (a = 4, snonce = stag =
skey = 128, shash = 256).
lower, especially with small arity. This is due to the fact
that in Meas only leaf nodes are directly authenticated. On
the other hand, PATs and TEC trees directly protect the
authenticity of every tree node.
The memory overhead of Meas, PATs, Merkle trees, and
TEC trees is also visualized in Figure 3 for diﬀerent block
sizes. For practical instantiations, the block size will be
chosen according to the system architecture, namely, page
size, sector size, or cache line size. Both the sectors of modern
disks as well as memory pages in state-of-the-art systems are
sized 4096 bytes (=32768 bits). Such large block size is out
of scope of Figure 3 as it has negligible memory overhead
in any case. Besides, the memory overhead for a block size
of 4096 bits (sector size in older hard disks) is also very low,
e.g., 7.3% for 4-ary Meas. However, the memory overhead
of Meas for block sizes ﬁtting nowadays cache architectures
is also practical given the security features it provides. While
today’s typical cache line size is 512 bits, modern CPUs often
come with features such as Adjacent Cache Line Prefetch [22],
which eﬀectively double the cache line fetches from memory
to 1024 bits. In a 4-ary Meas, for example, such block size
results in decent 29.2% memory overhead.
Note that these relatively small overheads—quite similar
to existing authentication techniques—in combination with
]
%
[
d
a
e
h
r
e
v
O
140
120
100
80
60
40
20
0
1
binary Meas
4-ary Meas
8-ary Meas
16-ary Meas
2
3
4
5
Protection Order
Figure 4: Memory overhead of Meas depending on
arity and protection order (1024-bit blocks, 128-bit
security).
additional and exclusive DPA protection are the main ad-
vantage of Meas. Using existing memory encryption and
authentication schemes with DPA-protected implementa-
tions, on the other hand, would result in overheads of a
factor of four to a few hundred [4, 7, 33, 35] and thus be far
more expensive, eventually rendering memory encryption
and authentication in many applications impractical.
7.4 Memory Overhead with Masking
The memory overhead of Meas with higher-order DPA
protection additionally depends on the protection order d
and the size of the masks smask which is typically equal
to skey.
In particular, a generalized version of the limit
of the memory overhead as the number of memory blocks
approaches inﬁnity is:
a
a − 1
· skey + (d − 1) · smask
sb
+
stag
sb
.
Figure 3 contains an evaluation of this memory overhead
for a 4-ary tree and 128-bit security, i.e., the keys, the tags,
and the masks are sized 128 bits. It shows that masking adds
multiplicatively to the memory overhead for all block sizes.
However, for larger block sizes, the memory overhead of
Meas becomes negligible regardless of the protection order.
Table 1: Comparison of Meas with other constructions for scalable authentic and/or conﬁdential memory
which oﬀer block wise random access.
Auth. Conf. DPA Security
Parallelizablea
Read Write
Memory Overhead
Meas
PAT
TEC Tree
Merkle Tree
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
aRequires multiple cryptographic implementations and multi-port memory in practice.
a
a
sb
a−1 · skey
+ stag
sb
a−1 · stag +snonce
a−1 · stag +snonce
sb
a
sb