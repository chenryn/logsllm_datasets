节点内存扩容
节点内存不够，但主机存在足够内存
通过configsetmaxmemory在线修改配置参数
1.
搭建新节点
2
添加从节点
单纯增加一个从节点
2.
建立主从关系即可
从节点迁移扩容
节点内存不够，主机内存也不够，通过新机器来承载节点
1.
将新节点加入到集群中
3
由 A->B，A->C 变成 A->B，A->D
2.
下线原有从节点
1
将新节点加入到集群中
节点内存不够，主机内存也不够，通过新机器来承载节点
主节点迁移扩容
2.
将主节点进行强制转移
由A->B，A->C变成 D->B，D->C
3.
下线原有主节点
如何彻底下线从节点？
将每一个sentinel_.conf中的副本节点删除掉
# Generated by CONFIG REwRITE
protected-mode no
user default on nopass sanitize-payload~&*+@all
sentinel myid 784e8752fe6f9ce541f73474d4e8fe0cb2820b81
sentinel
config-epoch mymaster 16
sentinel current-epoch 16
sentinel known-replica mymaster 192.168.128.167 6378
去掉重启后即可彻底下线
sentinel known-sentinel mymaster 192.168.128.167 26379 c7ce1da98183941407cadc9c856fbf27c05c8
entinel known-replica mymaster 192.168.128.167 6380
ntinel26378.conf*33l
1A21
春风阁讲堂出品
136
---
## Page 137
8.6.4.Sentinel 命令
序号
类型名称
命令说明
SENTINEL master mymaster
查看集群的 master
SENTINEL masters
查看所有master（一个 sentinel节点可以我最近多个Redis 主）
3
SENTINEL replicas mymaster
是看某个集群的salves
4
SENTINEL sentinels
查看 sentinel节点信息
5
SENTINEL getmasteraddrbyname mymaster
查看集群的主地址
6
SENTINEL config get *
查询通用配置信息
7
SENTINEL config set [name]
设置通用配置信息
8
SENTINEL set mymaster downaftermi1liseconds 30000
设置 sentinel配置信息
6
SENTINEL CKQUORUM mymaster
用来判断sentinel集群是否可故障转移
10
SENTINEL MONITOR mymaster 192. 168. 128. 167 6379 2
针对某个sentinel节点加入对Redis集群的监控
11
SENTINEL REMOVE
针对某个sentinel节点停止监控（会清空配置信息，慎用）
12
SENTINEL FAILOVER mymaster
强制主服务器转移
春风阁讲堂出品
137
---
## Page 138
9.RedisCluster集群方案
9.1.集群简介
Redis集群实现了一个数据分布式存储、节点水平扩容、故障自动转移的集群方案
1.存储：
Redis集群实现了对Redis的水平扩容，即启动N个Redis节点，将整个数据库分布存储在这N个节点中，每个节点存储总数据的1/N
2.水平扩容：
Redis集群模式用来解决单Redis数据量瓶颈，并且不再需要配置单独的哨兵，可以进行水平扩展
3.故障自动转移：
Redis集群将key通过crc16运算后与16384取模，将key分布到固定16384个槽位（slot）中的一个（0-16383），每个redis分别保管不同
的槽位，不同的Redis子集群分管不同的槽位，每个子集可用一主多从实现，进行故障自动转移
4.注意：
并且集群模式默认使用db0不支持select别的db
春风阁讲堂出品
138
---
## Page 139
9.2.集群核心原理
Redis集群采用了哈希Slot+主从节点实现了一个数据分布式存储、节点水平扩容、故障自动转移的集群方案
为了提高效率，Redis集群客户端维护当前插槽配置的映射，比如像Java实现的JedisCluster
CRC16
0
*.....
5461
5462
10922
10923
16383
Slot
Slot
Slot
Master1
Master1
Master1
Slave1
Slave2
Slave3
Slave1
Slave1
Slave2
Slave3
Slave1
Slave2
春风阁讲堂出品
139
---
## Page 140
9.3.集群环境搭建
9.3.1.集群需求简介
本次的环境需求如下：
序号
端口号
说明
1
6381(主)
2
6382(主)
3
6383(主)
6384(从)
Redis Cluster集群环境(3主3从)
4
5
6385(从)
6386(从)
春风阁讲堂出品
140
---
## Page 141
9.3.2.单节点配置
1.redis.conf单点增加配置
clusterenabled yes
clusterconfigfile nodes (port). conf
2.节点数量
要求节点数量为3*2=6个节点
生产要求至少2台机器，保证挂掉一台机器或者一个节点后，服务仍能正常进行
而且主从不能配对在同一台机器上
[xiangsl@crm167conf]$ pwd
/home/xiangsl/redis/conf
[xiangsl@crml67 conf]$ 11
总用量552
-rw-rw-r--1xiangslxiangsl 93819 4月
25 15:21 redis_6381.conf
-rw-rw-r--1xiangsl xiangsl 93819 4月
25 15:21 redis_6382.conf
-rw-rw-r--1xiangslxiangsl938194月
25 15:22 redis_6383.conf
-rw-rw-r--1xiangslxiangsl938194月
25
515:22 redis_6384.conf
rw-rw-r--
1xiangslxiangsl938194月
25 15:22 redis_6385.conf
-rw-rw-r--1xiangslxiangsl938194月
25 15:23 redis_6386.conf
[xiangsl@crm167conf]$
3.启动所有节点
以cluster模式启动6个redis服务
春风阁讲堂出品
141
---
## Page 142
9.3.3.初始创建集群
1.创建集群 ./redisc1i c1uster create 192. 168. 128.167:6381 192.168.128.167:6382 192.168. 128. 167:6383 192.168.128. 167:6384
192. 168. 128. 167 :6385 192. 168. 128. 167 :6386 --c1uster-rep1icas 1
:6385 192.168.128.167:6386 --cluster-replicas 1
>>Performing hash slots allocation on 6 nodes...
Master[0]->Slots0-5460
Master[1]->Slots 5461-10922
Master[2]->Slots 10923-16383
Adding replica 192.168.128.167:6386 to 192.168.128.167:6382
Adding replica 192.168.128.167:6384 to 192.168.128.167:6383
>>>Trying to optimize slaves allocation for anti-affinity
M:606e79eff17876ed701f4a6ac4c62611dla03e81192.168.128.167:6381
eslaves are in the sa
host as their
slots:[0-5460] (5461 slots) master
M:
33bffa7317297970cf9cddd9b43eaed85b6f4c71 192.168.128.167:6382
slots:[5461-10922](5462 slots) master
79f4c65a5d994957de57139a970a61decd1d5590 192.168.128.167:6383
f6f23c008c97270c786d3a052ce91c8fddaabf79 192.168.128.167:6384
slots:[10923-16383] (5461 slots) master
5:
replicates 33bffa7317297970cf9cddd9b43eaed85b6f4c71
5:
a14add5919698b8cb27803e2e46b2c1a4049a6a8 192.168.128.167:6385
bce32e72c99f77600ad4db337328aa666014d890 192.168.128.167:6386
replicates 79f4c65a5d994957de57139a970a61decd1d5590
S:
replicates 606e79eff17876ed701f4a6ac4c62611dla03e81
2.
数据目录：这时候在数据目录下面会生成集群配置文件
[xiangsl@crm167 data]$ pwd
/home/xiangsl/redis/data
[xiangsl@crm167data]$1l|grepnode
25 18:08 nodes-6381.conf
-rw-r--r--1xiangsl xiangsl 817 4月
25 18:08 nodes-6382.conf
-w-r--r-.
1xiangslxiangsl8174月
25 18:08 nodes-6383.conf
rw-r--r--1xiangslxiangsl8174月
25 18:08 nodes-6384.conf
-rw-r--r--1xiangslxiangsl8174月
25 18:08 nodes-6385.conf
-rw-r--r--1xiangslxiangsl8174月
25 18:08 nodes-6386.conf
[xiangsl@crm167 data]$
春风阁讲堂出品
142
---
## Page 143
9.4.集群健康检查
redis-c1i -cluster info 192. 168. 128. 167:6381
[xiangsl@crm167 bin]$./redis-cli --cluster info 192.168.128.167:6381
192.168.128.167:6381(606e79ef...)->0keys|5461 slots
1slaves.
192.168.128.167:6383 (79f4c65a...)->0keys
5461 slots
1slaves.
192.168.128.167:6382 (33bffa73...)->0 keys
5462 slots
|1slaves.
[0K]0keys in3 masters.
0.00keys perslot onaverage.
redis-c1i -cluster check 192. 168. 128. 167:6381
192.168.128.167:6381(606e79ef...)->0keys|5
5461 slots|1slaves.
192.168.128.167:6383 （79f4c65a...)->0keys
5461 slots|1slaves.
192.168.128.167:6382(33bffa73...)->0keys|5462 slots|1slaves.
[oK]0 keys in 3 masters.
0.oo keys per slot on average.
普通方式登陆单点
redis-c1i h 192. 168. 128. 167 p 6381
集群方式登陆单点（默认开启转发）
redisc1i h 192. 168. 128. 167 p 6381 c
获取集群关系（IP对应）
redisc1i h 192. 168. 128. 167 -p 6381 -c cluster slots xargs -n8 awk *{print $3:"$4">"s6":"s7]' sort -nk2 t ′:'
uniq
春风阁讲堂出品
143
---
## Page 144
9.5.集群高可用验证
1．验证当前集群
采用集群方式登陆：
redisc1i h 192. 168. 128. 167 p 6381 c
分别执行以下4个命令，看节点执行情况
set al 1
set a2 2
set a3 3
set a4 4
我们停掉一个从节点，再次执行，看集群是否正常？
正常
3.
我们停掉一个主节点，再次执行，看集群是否正常？
正常
我们停掉个小集群中的主和所有从，集群是否正常？
不正常
春风阁讲堂出品
144
---
## Page 145
9.6.集群常见管理
9.6.1.扩容-增加Redis节点
1.数据准备
往当前集群，先初始1000条数据，程序参考代码工程redis
2.准备单节点
按集群环境搭建的要求准备好单节点
192. 168. 128. 167 :6387 和 192. 168. 128. 167:6388
3.添加主节点
redisc1i c1uster addnode 192. 168. 128. 167:6387 192. 168. 128. 167:6381
第一个节点为待加入的新节点，后面一个节点为集群中的任意节点
添加节点命令，默认是主节点
4.添加从节点
redis-c1i -cluster add node 192. 168. 128. 167:6388 192. 168. 128. 167:6381 -cluster slave
不指定主节点时，由Redis自动分配，一般会自动加入没有从节点的主下面
redisc1i cluster addnode 192. 168. 128. 167:6388 192. 168. 128. 167:6381 cluster s1ave -cluster-masterid
0d77af6e29a5d11ecb9cadbd6ceb282cceaca2c4
他可以指定主节点，比如将192.168.128.167：6388作为从挂到192.168.128.167：6387下面
春风阁讲堂出品
145
---
## Page 146
9.6.2.扩容-slot自动平衡
当Redis集群中的节点出现新增时，我们需要对数据进行slot重新划配，有两种模式，自动平衡模式和手动划配模式
新增的时候我们一般采用自动平衡处理，这样方便快捷
未平衡前的key分布，我们可以看到6387进程上的keys数量为0
[xiangsl@crml67 bin]$./redis-cli--cluster info 192.168.128.167:6381
192.168.128.167:6381(606e79ef...)->3322 keys|5461slots|1slaves.
192.168.128.167:6383(79f4c65a...)->3340keys|5461 slots|1slaves.
192.168.128.167:6382(33bffa73...)->3338 keys|
5462 slots |1 slaves.
自动平衡命令
/redis-cli --cluster rebalance 192.168.128.167:6381 -cluster-use-empty-masters -cluster-replace
0.61keysper sloton average.
[xiangsl@crml67redis]$./bin/redis-cli--clusteri
info 192.168.128.167:6381
4096 slots|1 slaves.
192.168.128.167:6387 (0d77af6e...)
->
2500keys
4096 slots
1slaves.
192.168.128.167:6383(79f4c65a...)
2500 keys
4096 slots
1slaves.
192.168.128.167:6382 (33bffa73...)
->2500keys
|4096slots|1slaves.
[0K] 10000keys in 4masters.
通过平衡之后，我们可以看到10000个Key进行均衡分布
春风阁讲堂出品
146
---
## Page 147
9.6.3.缩容-slot手动分配
当我们想要对Redis集群进行缩容时，在删除Redis节点前，我们必须对要删除的节点上的数据进行手动划配迁移
缩容前的key分布，我们可以看到所有的Key均衡的分布四个节点上面
0.61keysper slotonaverage.
[xiangsl@crm167redis]$./bin/redis-cli--cluster info 192.168.128.167:6381
192.168.128.167:6381 (606e79ef...)->2500 keys |4096 slots |1 slaves.
192.168.128.167:6387(0d77af6e...)->2500 keys
4096 slots
1slaves.
192.168.128.167:6383(79f4c65a...)->2500keys
4096 slots
1slaves.
192.168.128.167:6382（33bffa73...)
）->2500keys|4096slots
1slaves.
[ok]1ooe0keysin4masters
交互式迁移命令
redis-cli --cluster reshard 192.168.128.167:6381
在输入命令后，会提示要迁移的slot数量，源节点、目标节点
非交互式迁移命令
redis-cli --cluster reshard 192.168.128.167:6381 --cluster-from 0d77af6e29a5d11ecb9cadbd6ceb282cceaca2c4 --cluster-to
606e79eff1 7876ed701f4a6ac4c62611d1a03e81 --cluster-slots 4096 --cluster-yes --cluster-replace
迁移之后，我们可以看到6387上的数据全部被迁移，接下来可以进行删除了
春风阁讲堂出品
147
---
## Page 148
9.6.4.缩容-删除Redis节点
从节点可以随时移除，0slot的孤主节点可以随时移除（无从节点），其它主节点无法删除
红色框节点可以直接删除，1号节点在删除对应的从节点后可以删除，2、3、4号节点需要将数据迁走+删除对应的从节点后可删除
redisc1i -cluster de1node 192. 168. 128. 167:6388 eba6e33d52b8d77832f3590de76ca53b6f78e71a
[xiangsl@crml67 bin]s ./redis-cli --cluster check 192.168.128.167:6381
192.168.128.167:6387 (0d77af6e...)
->0 keys|0slots |1 slaves.
192.168.128.167:6383(79f4c65a...)
->3340 keys|
5461 slots |1 slaves.
192.168.128.167:6382 (33bffa73...)->3338 keys |5462 slots |1 slaves.
[OK] 10000 keys in 4masters.
0.61 keys per slot on average
>>> Performing Cluster Check (using node 192.168.128.167:6381)
M:
606e79eff17876ed701f4a6ac4c62611d1a03e81 192.168.128.167:6381@
slots:[0-5460] (5461 slots) master
1 additional replica(s)