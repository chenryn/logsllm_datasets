title:Community Epidemic Detection Using Time-Correlated Anomalies
author:Adam J. Oliner and
Ashutosh V. Kulkarni and
Alex Aiken
Community Epidemic Detection Using
Time-Correlated Anomalies
Adam J. Oliner, Ashutosh V. Kulkarni, and Alex Aiken
{oliner,ashutosh.kulkarni,aiken}@cs.stanford.edu
Stanford University(cid:2)
Abstract. An epidemic is malicious code running on a subset of a com-
munity, a homogeneous set of instances of an application. Syzygy is an
epidemic detection framework that looks for time-correlated anomalies,
i.e., divergence from a model of dynamic behavior. We show mathemati-
cally and experimentally that, by leveraging the statistical properties of
a large community, Syzygy is able to detect epidemics even under adverse
conditions, such as when an exploit employs both mimicry and polymor-
phism. This work provides a mathematical basis for Syzygy, describes
our particular implementation, and tests the approach with a variety of
exploits and on commodity server and desktop applications to demon-
strate its eﬀectiveness.
Keywords: epidemic detection, anomalies, community.
1 Introduction
Consider a set of instances of an application, which we call a community. Two
examples of communities are all the mail servers in an organization or all the
browsers on a cluster of workstations. Assume some subset of these instances,
or clients, are compromised and are running malicious code. The initial breach
(or breaches) went undetected and the existence of the exploit is unknown, so
the malicious code may continue running indeﬁnitely, perhaps quietly stealing
computing resources (as in a zombie network), spooﬁng content, denying service,
etc. We present a method for detecting such situations by using properties of
the aggregate behavior of the community to reliably identify when a subset of
the community is not behaving properly.
A client is either healthy and exhibits correct behavior or infected and exhibits
incorrect behavior; our method detects epidemics, meaning when a subset of the
community is infected. The user speciﬁes what constitutes correct operation for
individual clients by providing a model, which may be incomplete (omit correct
behaviors), or unsound (admit incorrect behaviors), or both. For example, a
community of web servers may be modeled by the typical distribution of response
times each provides. The class of attacks we want to detect are those that cause
(cid:2) This work was supported in part by NSF grants CCF-0915766 and CNS-050955, and
by the DOE High-Performance Computer Science Fellowship.
S. Jha, R. Sommer, and C. Kreibich (Eds.): RAID 2010, LNCS 6307, pp. 360–381, 2010.
c(cid:2) Springer-Verlag Berlin Heidelberg 2010
Community Epidemic Detection Using Time-Correlated Anomalies
361
undesirable deviation from normal behavior, regardless of the attack vector (e.g.,
buﬀer overrun, insider attack, or hardware tampering). Our focus is on detecting
epidemics in a community composed of instances of a speciﬁc application, rather
than the entire system or individual clients in the community, and this distinction
leads to a diﬀerent approach.
We describe an implementation of an epidemic detector, called Syzygy, that
applies two main insights: (i) even if a single noisy model cannot reliably judge
the health of a client, we can reduce the noise by averaging the judgements of
many independent models and (ii) epidemics exhibit time-correlated behavior
that is impossible to detect on a single client. Our method eﬀectively leverages
the statistical properties of a large community to turn noisy models into reliable
community detectors and uses the temporal properties of an epidemic as a means
for better detecting it.
Syzygy monitors each client’s behavior and reports anomaly scores, which
quantify the divergence of recent behavior from the model. For example, a client
whose recent response times are unusually high may report a score that is above
average (anomalous). Syzygy then computes the numerical average of all clients’
scores and checks whether this community score exceeds a threshold. By doing
these computations properly (see Section 3), we can make strong theoretical
guarantees about our ability to overcome model noise and detect epidemics.
Intuitively, we expect anomalies on individual clients in a large community to
be common, but we do not expect anomaly scores from multiple clients to be
strongly correlated in time, absent an epidemic.
We describe and analyze Syzygy’s detection algorithm mathematically in Sec-
tion 3. In our evaluation, we focus on the following questions:
—Can Syzygy detect epidemics under realistic conditions? In Section 4, we
demonstrate that our method can leverage the community to detect a variety
of epidemics in a cluster of commodity web servers even given noisy, incom-
plete client models. Syzygy does not require source code or specially compiled
binaries.
—How do client and community characteristics aﬀect performance (i.e., false
positives)? In Section 5, we deploy Syzygy on the web browsers of a campus
network and show that, despite very diﬀerent client systems and user behav-
iors, healthy community behavior is a stable, reliable signal that is unlikely to
generate excessive false positives (our deployments generated none). Indeed, as
the community grows, Syzygy approaches a 100% detection rate with no false
positives; given a suﬃciently large training set and community, one can specify
an acceptable false positive rate a priori and with high conﬁdence. Even com-
munities of only a dozen clients exhibit desirable properties. See Sections 3.3,
4.2, and 5.2–5.3.
—What kinds of epidemics can Syzygy detect? In Section 6, we conduct sim-
ulation experiments using commercial, oﬀ-the-shelf software and artiﬁcially
powerful exploits (e.g., capable of nearly perfect mimicry) and demonstrate
that the community enables Syzygy to detect epidemics under a variety of
adverse conditions. Exploits may change their source code, perform diﬀerent
362
A.J. Oliner, A.V. Kulkarni, and A. Aiken
malicious actions, or even use a diﬀerent vector of infection across clients
(see Section 3.2).
—How good must client models be and how easy is it to acquire such models?
Syzygy works on top of existing client-based anomaly detectors, dampening noise
and providing sensitivity to time-correlated behavior. Syzygy requires only that
anomaly scores are mostly independent across healthy clients and higher, on
average, for infected clients; the method is agnostic to what measurements are
used to construct these scores.
Throughout the paper—using math, deployments, and simulations—we show
that, in a large community, even simple, noisy models are suﬃcient for reliable
epidemic detection. We conclude with a discussion of the issues involved with
building a larger-scale deployment (Section 7). Many real security infrastructures
are a constellation of tools; working in concert with other detection and response
tools, and with low overhead and few practical requirements, Syzygy provides
both new and more reliable information about epidemics.
2 Related Work
Syzygy detects malicious software running on clients in a community (epidemics)
even under typical real-world constraints: the client model is incomplete, informa-
tion about communication (network activity) is unavailable, and measurements
are noisy. It may be impossible, given social engineering and insider attacks, to
prevent all security breaches; a strength of Syzygy is that it can detect the bad be-
havior that follows a breach. In situations where the total damage is integral over
time and the size of the infected community—such as when an exploit is stealing
resources—the ability to detect such epidemics is crucial.
Anomaly-based intrusion detection has a long history [5, 27, 28, 29, 31, 35]. A
commonly held view is that anomaly detection is fundamentally limited by the
mediocre quality of the models that can be obtained in practice and therefore
must necessarily generate excessive false positives in realistic settings (see, e.g.,
[2]). We agree with the gist of this argument for single clients, but we show in
this paper that an appropriate use of a community can make strong guarantees
even with noisy models.
Crucial, however, is how the community is used. Most previous systems that
use a community at all use it only to correlate alarms generated locally on each
client—the diﬃculty is that the alarm/no alarm decision is still made on the basis
of a single client. Alert-correlation systems then try to suppress the resulting false
alarms by correlating alarms from other clients or diﬀerent detectors [4, 13, 36].
Other collaborative detection eﬀorts that raise alarms only on individual clients
include heterogeneous network overlays [44] and network anomaly detectors, such
as by using cumulative triggers [15, 16] or alarm aggregation and correlation
[1, 17, 32, 41]. Some work also uses correlation to characterize attack scenarios
and causal ﬂow [19, 26, 34].
Community Epidemic Detection Using Time-Correlated Anomalies
363
Syzygy is fundamentally diﬀerent from all of these systems in that it uses the
aggregate behavior of the community to decide whether to raise an alarm for
the community, not individual clients. The ability to make alert decisions based
on analyzing the combined behavior of multiple clients is what gives Syzygy
strong theoretical and practical properties that are absent from all previous work.
There is prior work for ﬁle systems [43] and peer-to-peer networks [22, 23] that
generate alerts based on aggregate behavior, but these do so without utilizing
the statistical beneﬁts of a large community.
Another category of work uses the community simply to gather data more
quickly or to spread the burden of monitoring among many clients. For example,
the Application Communities project [21] uses the community to distribute work;
everything could be done on a single client, given more time. Syzygy uses the
community in both these ways, as well; in contrast, however, it also looks for
time-correlated deviations from normal behavior, which is not possible on a
single client.
Syzygy was originally a detection component of the VERNIER security archi-
tecture [20]. Syzygy’s role is to monitor instances of a target application for signs
of infection: attacks on the security infrastructure or other applications within
the client system, problem diagnosis, and reaction to the intrusion are all the
responsibility of other VERNIER components. Among the various VERNIER
detectors, Syzygy is speciﬁcally looking for time-correlated activity, as might be
expected from a propagating worm or a coordinated attack. This specialization
allows Syzygy to be small, lightweight, and asymptotically ideal while using the
community in a novel way.
There are also uses of the community for tasks other than detection, such
as diagnosing problems by discovering root causes [39] and preventing known
exploits (e.g., sharing antibodies) [2, 3, 25]. Although other parts of VERNIER
employ such measures, our focus is on detection.
3 Syzygy
Consider a community of n clients in which we wish to detect epidemics. During
training, Syzygy observes the normal operation of the clients and builds a model
(see Section 3.1). It is important to note that the speciﬁc choice of model is
independent from the rest of Syzygy’s operation; the only requirement is that
the model produces an anomaly signal according to the constraints in Section 3.2.
While subsequently in monitoring mode, Syzygy periodically collects the most
recent value of the anomaly signal (the anomaly score) from each client and
checks whether the community’s average anomaly score exceeds a threshold V .
If so, Syzygy reports an epidemic. The properties of the anomaly signal are such
that, given a large community, Syzygy can compute the threshold automatically
at runtime and is insensitive to minor variations in this parameter. We explain
these properties mathematically in Section 3.3 and support them experimentally
in Sections 5.2 and 6.3.
364
A.J. Oliner, A.V. Kulkarni, and A. Aiken
X (healthy)
Y (infected)
δδ
μμX
μμY
y
t
i
s
n
e
D
8
0
.
6
0
.
4
0
.
2
0
.
0
0
.
y
t
i
s
n
e
D
4
0
.
3
0
.
2
0
.
1
0
.
0
0
.
False Positives
V
0
2
4
6
8
10
0
2
4
6
8
10
Anomaly Score
Community Score
Fig. 1. An illustration of anomaly signals.
Neither X nor Y are normally distributed,
but μY > μX , as required. The exploit
may sometimes look “normal”.
Fig. 2. A distribution of healthy commu-
nity scores using hypothetical data. The
threshold V determines what fraction of
scores result in false positives.
3.1 Model
When applying our method to detect epidemics in a community, the user selects
an appropriate client model, which uses some combination of signals that can
be measured on individual clients to quantify how surprising (anomalous) recent
behavior is. We require only that the model generate anomaly scores that are
mostly independent across healthy clients and that it quantify how surprising
recent behavior is, compared with historical behavior or a theoretical baseline.
The model for a community of servers might characterize normal behav-
ior according to performance (see an example using request response times in
Section 4), while the model for a community of web browsers might use code ex-
ecution paths (see examples using system calls in Sections 5 and 6). The example
models used in this paper could easily be reﬁned or replaced with alternatives
to match the attacks we want to detect: call stack content [8], execution traces
[10], call arguments [24], remote procedure calls [12], etc.
3.2 Anomaly Signal
The anomaly signal decouples the choice of model from the rest of the system;
any model that satisﬁes the properties explained in this section may be used
with Syzygy. Each client keeps the server apprised of the client’s anomaly score,
the current value of the client’s anomaly signal. This score is a measure of how
unusual recent behavior is compared to a model of client behavior: a higher score
indicates more surprising behavior than a lower score. (This is sometimes called
the IS statistic [18] or behavioral distance [11].)
The distribution of anomaly scores generated by a healthy client (X) must
have a mean (μX) that is less than the mean (μY ) of the anomaly score distribu-
tion of an infected client (Y ), so we require μY > μX + δ. The larger the δ, the
better, though any positive δ will suﬃce. Figure 1 illustrates two valid anomaly
signal distributions, where X and Y are random variables such that both have
ﬁnite mean and ﬁnite, positive variance.
More generally, let the anomaly scores from healthy client i, denoted ai, be
distributed like Xi (written ai ∼ Xi) and let ai ∼ Yi when client i is infected.
Assume, without loss of generality, that all clients have the same distribution, i.e.,
let Xi ∼ X and Yi ∼ Y . The distributions may be standardized to enforce this
Community Epidemic Detection Using Time-Correlated Anomalies
365
assumption, because only the mean and variance are relevant to our asymptotic
results. If infected behavior does not diﬀer from normal behavior, then δ will be
unacceptably small (even negative); this can be resolved by reﬁning the model
to include more relevant signals or adjusting the model to amplify surprising
behaviors. In this paper, we use two simple models (see Sections 4.1 and 5.1)
that share a similar anomaly score computation (see Section 4.1), and both
provided suﬃciently large δ values to detect a variety of exploits.
3.3 Epidemic Detection
The Syzygy server computes the average anomaly score among the active clients;
this community score C represents the state of the community. If C > V , for a
tunable threshold V , the server reports an epidemic. Consider a healthy commu-
nity of n clients and let ai ∼ X. Then, by the Central Limit Theorem, as n → ∞,
the community scores are distributed normally with mean μX and variance σ2
n :
X
C = averagei(ai) =
1
n
(cid:2)
i
(X) ∼ Norm(μX ,
σ2
X
n ).
When E(|X|3) = ρ  0 such that
∀x, n, |Fn(x) − Φ(x)| ≤ Bρ
√
Consider now when some number of clients d ≤ n of the community have been
exploited. The community score, as n, d → ∞, will be
(n − d)μX + dμY
n−d(cid:2)
d(cid:2)
n.
(cid:4)
(cid:3)
σ3
X
(cid:5)
σX
, (n − d)σ2
X + dσ2
Y
n2
(cid:6)
.
n
C =
1
n
X +
Y
i=1
i=1
∼ Norm
The rate of convergence guarantees that we get this asymptotic behavior at
relatively small values of n and d, and even when d  V , Syzygy reports an epidemic.
Deﬁned as μY − μX . Intuitively, the average distance between anomaly
scores generated by healthy versus infected clients. One kind of mimicry
attack drives δ toward zero.
The rate of a rate-limited mimicry attack: the application appears
healthy a fraction 1 − r of the time and infected a fraction r of the
time.
True positive rate or detection rate. P (E|¬H).
True negative rate. P (¬E|H).
False positive rate, or Type I classiﬁcation error rate. P (E|H).
False negative rate, or Type II classiﬁcation error rate. P (¬E|¬H).
TP
TN
FP
FN
F1 Measure A summary metric with precision and recall weighted equally:
2T P
2T P +F P +F N .
(cid:8)
2π
(cid:9)
(cid:9)
X
n
(cid:8)
√
n
μX , σ2
(V −μH )
σH
(cid:7) ∞
α e− x2
2 dx. Let H ∼ Norm
precisely the value of the parametrized Q-function, the complement of the normal
cdf: Q(α) ≡ 1√
be the distribution of
community scores in a healthy community of size n. The probability that a
randomly selected community score will be a false positive is FP = P (C > V ) =
. Table 1 lists the signiﬁcant terms and metrics used in this paper.
Q
This analysis relies on two modest assumptions. First, the parameters μX and
σX must characterize the future distribution of anomaly scores. A model that
is out-of-date or produced with biased training data, for example, may produce
anomaly scores inconsistent with the expected distribution. In Section 6.4 we
explore the impact of using on one system a model produced for a diﬀerent one
and in Section 5.2 we show that even relatively heterogeneous machines pro-
duce predictable community score distributions. It is straightforward to detect
when observed behavior disagrees with expectation, and the solution is to re-
train the model. Second, during normal operation, client anomaly scores should
be mostly independent. In situations like a network-distributed software upgrade,
Community Epidemic Detection Using Time-Correlated Anomalies
367
innocuous dependencies may cause correlated behavior (i.e., correlated behavior
without a malicious cause, which is our deﬁnition of a false positive). Indeed,
it is indistinguishable from an attack except that one change to the software is
authorized and the other is not. Such false alarms are easily avoided by mak-
ing information about authorized changes to monitored applications available
to Syzygy. Other sources of accidentally correlated behavior are quite rare; we
observed no false alarms at all in a deployment with real users (see Section 5).
4 Detection Experiments
We ﬁrst test Syzygy’s ability to detect epidemics in a community using a cluster
of 22 machines running unmodiﬁed instances of the Apache web server. Each
machine has four cores (two dual core AMD Opteron 265 processors), 7 GB of
main memory, and the Fedora Core 6 distribution of Linux. Each client serves
streams of requests generated by a workload script. The workload generator,
at exponentially distributed random times, makes requests from a list of 178
available HTML and PHP pages that includes several pages that do not exist
and two pages for which the requester does not have read permission. We run
the workload generator for 100,000 requests (∼2.8 hours) to train the model,
then use those same training traces to set V so that we expect to get one false
positive per week (see Section 3.3 for how we do this; also see Section 5.2 for
more on false positives). We use Apache’s existing logging mechanisms to record
measurements (e.g., response times).
For this community, we aim to detect the following classes of attack: denial
of service (DoS), resource exhaustion, content spooﬁng, and privilege escalation.
Thus, we pick a client model that is likely to detect such attacks (see Section 4.1).
We test Syzygy with two DoS attacks that prevent Apache from serving 1%
or 10% of requests, at random, respectively; two resource exhaustion attacks
that allow Apache to continue serving requests but gradually consume memory
or CPU time, respectively; three content spooﬁng attacks that cause (i) PHP
pages to be served in place of previously non-existent pages, (ii) PHP pages to
be served in the place of certain HTML pages, or (iii) HTML pages to be served
in place of certain PHP pages; and a privilege escalation attack that makes all
page accesses authorized (no 403 Errors). We ﬁnd that Syzygy can achieve high
detection rates for these attacks with no false positives (see Section 4.2).
The clients in these experiments are homogeneous; in Section 5, we explore
the eﬀects of heterogenous hardware and varying user behavior with a deploy-
ment using an interactive application (the Firefox web browser). Section 6 con-
tains additional experiments, in a more controlled environment, that explore the
properties of much larger communities (thousands of clients) and more advanced
exploits (capable of various degrees of mimicry).
4.1 Model
Assume that our security goal for this community is to ensure that clients are
serving requests according to expected performance; that is, the request response
368
A.J. Oliner, A.V. Kulkarni, and A. Aiken
behavior should be consistent over time. During training, the model computes
a frequency distribution of request response times and the maximum observed
time between consecutive requests. This is just one choice of model and is not
intrinsic to Syzygy.
When a request is made of the server, the model increments the counter asso-
ciated with the response time s in a table indexed by response times (10 μsecond
precision). From this frequency distribution, we compute a density function Si
by dividing each entry by the total number of observed response times. Thus,
Si(s) is the fraction of times that response time s was observed on client i.
To incorporate timing in the model, which can help identify the absence of
normal behavior (such as during a denial of service attack), we record the time
between the start of each consecutive pair of requests. The model measures
these times only when the application is active. A client is active when it reports
its ﬁrst anomaly score and becomes inactive after reporting an anomaly score
accompanied by the END message. (See below for when this token is generated.)
From these data, we set a silence threshold Ti for each client i, which we initially
pick to be the maximum time between any two consecutive requests.
Monitoring. On the client, Syzygy monitors all requests made to the applica-
tion. In addition, Syzygy may inject two kinds of artiﬁcial measurements into
the sequence. The ﬁrst, called END, indicates that the application has terminated
(switched to inactive); Syzygy generates an END token when the application exits
cleanly, terminates abruptly such as due to an error, or when the Syzygy client
is closed cleanly. If an active client stops reporting scores for longer than the
timeout threshold, currently set to 2Ti seconds, then the Syzygy server marks
that client inactive without fabricating a token. The second artiﬁcial measure-
ment, a hiaton [37] denoted X, indicates that no measurements were generated
for longer than Ti seconds, including any Xs produced via this process. In other
words, at the start of each request, a timer starts; when this timer exceeds Ti,
Syzygy generates a hiaton and resets the timer.
Each client maintains a window of the most recent Wi request response times,
including the fabricated hiatons and END tokens. From this window, we compute
the density function Ri, analogous to Si, above. Thus, Ri(s) is the fraction of
times measurement s appears in the previous Wi measurements on client i.
Anomaly Signal. Let ai be the most recent anomaly score and Wi be the size
of the recent window for client i. The units of ai and Wi may depend on the par-
ticular choice of model, but should be consistent across clients. In this paper, we
measure the anomaly signal in bits and the window size in number of measure-
ments. Our implementation computes ai using Kullback-Liebler (KL) divergence
with a base-2 logarithm. Roughly, this measures the information gained by seeing
the recent window, having already observed the historical behavior. Speciﬁcally,
over the measurements s in the density function for the recent window (s ∈ Ri),
we have ai =
s Ri(s) log Ri(s)
Si(s) .
This computation can be updated incrementally in constant time as one mea-
surement leaves the recent window and another enters it. To prevent division by
(cid:10)
Community Epidemic Detection Using Time-Correlated Anomalies
369
)
C
(
e
r
o
c
S
y
t
i
n
u
m
m
o
C
x
a
M
0
5
.
0
6
4
.
0
2
4
.
0
DoS (1%)
DoS (10%)
Content Spoof (i)
Content Spoof (ii)
Content Spoof (iii)
Privilege Escalation
Memory Thief
CPU Thief
y
t
i
s
n
e
D
5
1
0
1
5
0
Client Scores
Community Scores
Epidemic Threshold (V)
0
5
10
15
20
25
30
Infected Clients (d)
0.30
0.35
0.40
0.45
0.50
0.55
Client or Community Score
Fig. 3. Syzygy detected all of the attacks
once the infection size was suﬃciently
large. The horizontal line is the epidemic
threshold V .
Fig. 4. Our client model
is incomplete
and noisy; anomalous behavior is com-
mon. The community scores, however, are
extremely steady.
zero, the measurements in the recent window are included in the distribution
Si. By default, each client reports this score whenever there is new information
available to the model (e.g., a request or hiaton), but it is straightforward to add
feedback or batching to the client-server protocol to curb communication traﬃc
(we do so in Section 5.3).
4.2 Results
Figure 3 shows the results of our detection experiments; there were no false
positives in these experiments and detection latency was never more than a
couple of seconds. Although some attacks are diﬃcult to detect when only a few