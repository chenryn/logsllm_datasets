# Title: Community Epidemic Detection Using Time-Correlated Anomalies

## Authors
- Adam J. Oliner
- Ashutosh V. Kulkarni
- Alex Aiken

### Abstract
Epidemics, characterized by the presence of malicious code in a subset of a homogeneous community of application instances, pose significant security challenges. Syzygy is an epidemic detection framework that identifies time-correlated anomalies, or deviations from a model of dynamic behavior. This paper provides a mathematical foundation for Syzygy, describes its implementation, and evaluates its effectiveness through various experiments. We demonstrate that Syzygy can detect epidemics even under adverse conditions, such as when an exploit employs both mimicry and polymorphism. By leveraging the statistical properties of a large community, Syzygy can overcome model noise and reliably identify malicious activity.

### Keywords
- Epidemic detection
- Anomalies
- Community

## 1. Introduction
Consider a set of instances of an application, referred to as a community. Examples include all mail servers in an organization or all browsers on a cluster of workstations. Assume some subset of these instances, or clients, are compromised and running malicious code. The initial breach may go undetected, allowing the malicious code to continue running indefinitely, potentially stealing computing resources, spoofing content, or denying service. We present a method for detecting such situations by using the aggregate behavior of the community to reliably identify when a subset of the community is not behaving properly.

A client is either healthy (exhibiting correct behavior) or infected (exhibiting incorrect behavior). Our method detects epidemics, meaning when a subset of the community is infected. The user specifies what constitutes correct operation for individual clients by providing a model, which may be incomplete (omitting correct behaviors), unsound (admitting incorrect behaviors), or both. For example, a community of web servers may be modeled by the typical distribution of response times. We aim to detect attacks that cause undesirable deviations from normal behavior, regardless of the attack vector (e.g., buffer overrun, insider attack, or hardware tampering). Our focus is on detecting epidemics in a community composed of instances of a specific application, rather than the entire system or individual clients, leading to a different approach.

We describe an implementation of an epidemic detector, called Syzygy, which applies two main insights: (i) even if a single noisy model cannot reliably judge the health of a client, we can reduce the noise by averaging the judgments of many independent models, and (ii) epidemics exhibit time-correlated behavior that is impossible to detect on a single client. Syzygy leverages the statistical properties of a large community to turn noisy models into reliable community detectors and uses the temporal properties of an epidemic to enhance detection.

Syzygy monitors each client’s behavior and reports anomaly scores, which quantify the divergence of recent behavior from the model. For example, a client with unusually high recent response times may report a score above average (anomalous). Syzygy then computes the numerical average of all clients' scores and checks whether this community score exceeds a threshold. By doing these computations properly, we can make strong theoretical guarantees about our ability to overcome model noise and detect epidemics. Intuitively, we expect anomalies on individual clients in a large community to be common, but we do not expect anomaly scores from multiple clients to be strongly correlated in time, absent an epidemic.

In Section 3, we mathematically describe and analyze Syzygy's detection algorithm. In our evaluation, we address the following questions:
- Can Syzygy detect epidemics under realistic conditions? (Section 4)
- How do client and community characteristics affect performance (i.e., false positives)? (Section 5)
- What kinds of epidemics can Syzygy detect? (Section 6)
- How good must client models be and how easy is it to acquire such models? (Throughout the paper)

We show that, in a large community, even simple, noisy models are sufficient for reliable epidemic detection. We conclude with a discussion of the issues involved in building a larger-scale deployment (Section 7). Syzygy, working in concert with other detection and response tools, provides new and more reliable information about epidemics with low overhead and few practical requirements.

## 2. Related Work
Syzygy detects malicious software running on clients in a community (epidemics) even under typical real-world constraints: the client model is incomplete, information about communication (network activity) is unavailable, and measurements are noisy. It may be impossible, given social engineering and insider attacks, to prevent all security breaches; a strength of Syzygy is that it can detect the bad behavior that follows a breach. In situations where the total damage is integral over time and the size of the infected community—such as when an exploit is stealing resources—the ability to detect such epidemics is crucial.

Anomaly-based intrusion detection has a long history [5, 27, 28, 29, 31, 35]. A commonly held view is that anomaly detection is fundamentally limited by the mediocre quality of the models that can be obtained in practice and therefore must necessarily generate excessive false positives in realistic settings (see, e.g., [2]). We agree with the gist of this argument for single clients, but we show in this paper that an appropriate use of a community can make strong guarantees even with noisy models.

Crucial, however, is how the community is used. Most previous systems that use a community at all use it only to correlate alarms generated locally on each client—the difficulty is that the alarm/no alarm decision is still made on the basis of a single client. Alert-correlation systems then try to suppress the resulting false alarms by correlating alarms from other clients or different detectors [4, 13, 36]. Other collaborative detection efforts that raise alarms only on individual clients include heterogeneous network overlays [44] and network anomaly detectors, such as by using cumulative triggers [15, 16] or alarm aggregation and correlation [1, 17, 32, 41]. Some work also uses correlation to characterize attack scenarios and causal flow [19, 26, 34].

Syzygy is fundamentally different from all of these systems in that it uses the aggregate behavior of the community to decide whether to raise an alarm for the community, not individual clients. The ability to make alert decisions based on analyzing the combined behavior of multiple clients gives Syzygy strong theoretical and practical properties that are absent from all previous work. There is prior work for file systems [43] and peer-to-peer networks [22, 23] that generate alerts based on aggregate behavior, but these do so without utilizing the statistical benefits of a large community.

Another category of work uses the community simply to gather data more quickly or to spread the burden of monitoring among many clients. For example, the Application Communities project [21] uses the community to distribute work; everything could be done on a single client, given more time. Syzygy uses the community in both these ways, as well; in contrast, however, it also looks for time-correlated deviations from normal behavior, which is not possible on a single client.

Syzygy was originally a detection component of the VERNIER security architecture [20]. Syzygy's role is to monitor instances of a target application for signs of infection: attacks on the security infrastructure or other applications within the client system, problem diagnosis, and reaction to the intrusion are all the responsibility of other VERNIER components. Among the various VERNIER detectors, Syzygy is specifically looking for time-correlated activity, as might be expected from a propagating worm or a coordinated attack. This specialization allows Syzygy to be small, lightweight, and asymptotically ideal while using the community in a novel way.

There are also uses of the community for tasks other than detection, such as diagnosing problems by discovering root causes [39] and preventing known exploits (e.g., sharing antibodies) [2, 3, 25]. Although other parts of VERNIER employ such measures, our focus is on detection.

## 3. Syzygy
### 3.1 Model
When applying our method to detect epidemics in a community, the user selects an appropriate client model, which uses some combination of signals that can be measured on individual clients to quantify how surprising (anomalous) recent behavior is. We require only that the model generate anomaly scores that are mostly independent across healthy clients and that it quantify how surprising recent behavior is, compared with historical behavior or a theoretical baseline.

The model for a community of servers might characterize normal behavior according to performance (see an example using request response times in Section 4), while the model for a community of web browsers might use code execution paths (see examples using system calls in Sections 5 and 6). The example models used in this paper could easily be refined or replaced with alternatives to match the attacks we want to detect: call stack content [8], execution traces [10], call arguments [24], remote procedure calls [12], etc.

### 3.2 Anomaly Signal
The anomaly signal decouples the choice of model from the rest of the system; any model that satisfies the properties explained in this section may be used with Syzygy. Each client keeps the server apprised of the client’s anomaly score, the current value of the client’s anomaly signal. This score is a measure of how unusual recent behavior is compared to a model of client behavior: a higher score indicates more surprising behavior than a lower score. (This is sometimes called the IS statistic [18] or behavioral distance [11].)

The distribution of anomaly scores generated by a healthy client (X) must have a mean (μX) that is less than the mean (μY) of the anomaly score distribution of an infected client (Y), so we require μY > μX + δ. The larger the δ, the better, though any positive δ will suffice. Figure 1 illustrates two valid anomaly signal distributions, where X and Y are random variables such that both have finite mean and finite, positive variance.

More generally, let the anomaly scores from healthy client i, denoted ai, be distributed like Xi (written ai ∼ Xi) and let ai ∼ Yi when client i is infected. Assume, without loss of generality, that all clients have the same distribution, i.e., let Xi ∼ X and Yi ∼ Y. The distributions may be standardized to enforce this assumption, because only the mean and variance are relevant to our asymptotic results. If infected behavior does not differ from normal behavior, then δ will be unacceptably small (even negative); this can be resolved by refining the model to include more relevant signals or adjusting the model to amplify surprising behaviors. In this paper, we use two simple models (see Sections 4.1 and 5.1) that share a similar anomaly score computation (see Section 4.1), and both provided sufficiently large δ values to detect a variety of exploits.

### 3.3 Epidemic Detection
The Syzygy server computes the average anomaly score among the active clients; this community score C represents the state of the community. If C > V, for a tunable threshold V, the server reports an epidemic. Consider a healthy community of n clients and let ai ∼ X. Then, by the Central Limit Theorem, as n → ∞, the community scores are distributed normally with mean μX and variance σ^2/n:

\[ C = \frac{1}{n} \sum_{i=1}^{n} a_i \sim \text{Norm}(\mu_X, \frac{\sigma_X^2}{n}) \]

When E(|X|^3) = ρ < ∞, there exists a constant Bρ such that for all x and n,

\[ |F_n(x) - \Phi(x)| \leq \frac{B_\rho}{\sqrt{n}} \]

Now, consider when some number of clients d ≤ n of the community have been exploited. The community score, as n, d → ∞, will be

\[ C = \frac{1}{n} \left( \sum_{i=1}^{n-d} X_i + \sum_{i=1}^{d} Y_i \right) \sim \text{Norm} \left( \frac{(n-d)\mu_X + d\mu_Y}{n}, \frac{(n-d)\sigma_X^2 + d\sigma_Y^2}{n^2} \right) \]

The rate of convergence guarantees that we get this asymptotic behavior at relatively small values of n and d, and even when d << n. When C > V, Syzygy reports an epidemic.

Table 1 lists the significant terms and metrics used in this paper.

| Term | Definition |
|------|------------|
| δ    | Defined as μY - μX. Intuitively, the average distance between anomaly scores generated by healthy versus infected clients. One kind of mimicry attack drives δ toward zero. |
| r    | The rate of a rate-limited mimicry attack: the application appears healthy a fraction 1 - r of the time and infected a fraction r of the time. |
| TPR  | True positive rate or detection rate. P(E|¬H). |
| TNR  | True negative rate. P(¬E|H). |
| FPR  | False positive rate, or Type I classification error rate. P(E|H). |
| FNR  | False negative rate, or Type II classification error rate. P(¬E|¬H). |
| F1   | F1 Measure: A summary metric with precision and recall weighted equally: \( \frac{2TP}{2TP + FP + FN} \). |

This analysis relies on two modest assumptions. First, the parameters μX and σX must characterize the future distribution of anomaly scores. A model that is out-of-date or produced with biased training data, for example, may produce anomaly scores inconsistent with the expected distribution. In Section 6.4, we explore the impact of using one system's model on a different one, and in Section 5.2, we show that even relatively heterogeneous machines produce predictable community score distributions. It is straightforward to detect when observed behavior disagrees with expectation, and the solution is to retrain the model. Second, during normal operation, client anomaly scores should be mostly independent. In situations like a network-distributed software upgrade, innocuous dependencies may cause correlated behavior (i.e., correlated behavior without a malicious cause, which is our definition of a false positive). Such false alarms are easily avoided by making information about authorized changes to monitored applications available to Syzygy. Other sources of accidentally correlated behavior are quite rare; we observed no false alarms at all in a deployment with real users (see Section 5).

## 4. Detection Experiments
### 4.1 Model
Assume that our security goal for this community is to ensure that clients are serving requests according to expected performance; that is, the request response behavior should be consistent over time. During training, the model computes a frequency distribution of request response times and the maximum observed time between consecutive requests. This is just one choice of model and is not intrinsic to Syzygy.

When a request is made of the server, the model increments the counter associated with the response time s in a table indexed by response times (10 μsecond precision). From this frequency distribution, we compute a density function Si by dividing each entry by the total number of observed response times. Thus, Si(s) is the fraction of times that response time s was observed on client i.

To incorporate timing in the model, which can help identify the absence of normal behavior (such as during a denial of service attack), we record the time between the start of each consecutive pair of requests. The model measures these times only when the application is active. A client is active when it reports its first anomaly score and becomes inactive after reporting an anomaly score accompanied by the END message. (See below for when this token is generated.)

From these data, we set a silence threshold Ti for each client i, which we initially pick to be the maximum time between any two consecutive requests.

### Monitoring
On the client, Syzygy monitors all requests made to the application. In addition, Syzygy may inject two kinds of artificial measurements into the sequence. The first, called END, indicates that the application has terminated (switched to inactive); Syzygy generates an END token when the application exits cleanly, terminates abruptly due to an error, or when the Syzygy client is closed cleanly. If an active client stops reporting scores for longer than the timeout threshold, currently set to 2Ti seconds, then the Syzygy server marks that client inactive without fabricating a token. The second artificial measurement, a hiaton [37] denoted X, indicates that no measurements were generated for longer than Ti seconds, including any Xs produced via this process. In other words, at the start of each request, a timer starts; when this timer exceeds Ti, Syzygy generates a hiaton and resets the timer.

Each client maintains a window of the most recent Wi request response times, including the fabricated hiatons and END tokens. From this window, we compute the density function Ri, analogous to Si, above. Thus, Ri(s) is the fraction of times measurement s appears in the previous Wi measurements on client i.

### Anomaly Signal
Let ai be the most recent anomaly score and Wi be the size of the recent window for client i. The units of ai and Wi may depend on the particular choice of model, but should be consistent across clients. In this paper, we measure the anomaly signal in bits and the window size in the number of measurements. Our implementation computes ai using Kullback-Liebler (KL) divergence with a base-2 logarithm. Roughly, this measures the information gained by seeing the recent window, having already observed the historical behavior. Specifically, over the measurements s in the density function for the recent window (s ∈ Ri), we have

\[ a_i = \sum_{s \in R_i} R_i(s) \log_2 \left( \frac{R_i(s)}{S_i(s)} \right) \]

This computation can be updated incrementally in constant time as one measurement leaves the recent window and another enters it. To prevent division by zero, the measurements in the recent window are included in the distribution Si. By default, each client reports this score whenever there is new information available to the model (e.g., a request or hiaton), but it is straightforward to add feedback or batching to the client-server protocol to curb communication traffic (we do so in Section 5.3).

### 4.2 Results
Figure 3 shows the results of our detection experiments; there were no false positives in these experiments and detection latency was never more than a couple of seconds. Although some attacks are difficult to detect when only a few clients are infected, Syzygy detected all of the attacks once the infection size was sufficiently large. The horizontal line in Figure 3 is the epidemic threshold V.

Figure 4 illustrates that our client model is incomplete and noisy; anomalous behavior is common. However, the community scores are extremely steady, indicating the effectiveness of Syzygy in leveraging the statistical properties of the community.

## 5. Evaluation
### 5.1 Deployment
We deployed Syzygy on the web browsers of a campus network and showed that, despite very different client systems and user behaviors, healthy community behavior is a stable, reliable signal that is unlikely to generate excessive false positives. Indeed, as the community grows, Syzygy approaches a 100% detection rate with no false positives. Even communities of only a dozen clients exhibit desirable properties. See Sections 3.3, 4.2, and 5.2–5.3 for more details.

### 5.2 False Positives
In our deployment, we observed no false positives, demonstrating that Syzygy can maintain a low false positive rate even in a heterogeneous environment. Given a sufficiently large training set and community, one can specify an acceptable false positive rate a priori and with high confidence.

### 5.3 Communication Overhead
To manage communication overhead, we implemented feedback and batching in the client-server protocol. This allowed us to reduce the frequency of score reporting without compromising detection accuracy.

## 6. Advanced Exploits
### 6.1 Simulation Experiments
We conducted simulation experiments using commercial, off-the-shelf software and artificially powerful exploits (e.g., capable of nearly perfect mimicry) and demonstrated that the community enables Syzygy to detect epidemics under a variety of adverse conditions. Exploits may change their source code, perform different malicious actions, or even use a different vector of infection across clients (see Section 3.2).

### 6.2 Mimicry Attacks
Mimicry attacks, where the malicious code attempts to mimic normal behavior, are particularly challenging. Syzygy's ability to detect time-correlated anomalies makes it effective even against such sophisticated attacks. We explored the impact of varying levels of mimicry and found that Syzygy remains robust, especially as the community size increases.

### 6.3 Large-Scale Communities
We also evaluated Syzygy in a more controlled environment with much larger communities (thousands of clients). These experiments confirmed that Syzygy's performance improves as the community size increases, achieving near-perfect detection rates with minimal false positives.

## 7. Conclusion
In conclusion, Syzygy provides a robust and reliable method for detecting epidemics in a community of application instances. By leveraging the statistical properties of a large community and focusing on time-correlated anomalies, Syzygy can overcome the limitations of noisy and incomplete models. Our evaluations demonstrate that Syzygy can detect a wide range of attacks, even under adverse conditions, and maintain a low false positive rate. Future work will focus on scaling Syzygy to even larger deployments and integrating it with other security tools to provide a comprehensive security solution.