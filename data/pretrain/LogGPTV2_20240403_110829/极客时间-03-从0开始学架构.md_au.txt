## 负载均衡分类 {#21.html#-}常见的负载均衡系统包括 3 种：DNS 负载均衡、硬件负载均衡和软件负载均衡。``{=html}**DNS 负载均衡**DNS是最简单也是最常见的负载均衡方式，一般用来实现地理级别的均衡。例如，北方的用户访问北京的机房，南方的用户访问深圳的机房。DNS负载均衡的本质是 DNS 解析同一个域名可以返回不同的 IP 地址。例如，同样是www.baidu.com，北方用户解析后获取的地址是 61.135.165.224（这是北京机房的IP），南方用户解析后获取的地址是 14.215.177.38（这是深圳机房的 IP）。下面是 DNS 负载均衡的简单示意图：![](Images/b7e16bf4a1e93331455d58e17fbb2b7d.png){savepage-src="https://static001.geekbang.org/resource/image/db/2f/dbb61acde016acb2f57212d627d2732f.jpg"}﻿（图片来源：[https://ww3.sinaimg.cn/large/006tNc79gy1fc7x8apfnyj30pk0ma765.jpg）](https://ww3.sinaimg.cn/large/006tNc79gy1fc7x8apfnyj30pk0ma765.jpg）)DNS负载均衡实现简单、成本低，但也存在粒度太粗、负载均衡算法少等缺点。仔细分析一下优缺点，其优点有：-   简单、成本低：负载均衡工作交给 DNS    服务器处理，无须自己开发或者维护负载均衡设备。-   就近访问，提升访问速度：DNS 解析时可以根据请求来源    IP，解析成距离用户最近的服务器地址，可以加快访问速度，改善性能。缺点有：-   更新不及时：DNS 缓存的时间比较长，修改 DNS    配置后，由于缓存的原因，还是有很多用户会继续访问修改前的    IP，这样的访问会失败，达不到负载均衡的目的，并且也影响用户正常使用业务。-   扩展性差：DNS    负载均衡的控制权在域名商那里，无法根据业务特点针对其做更多的定制化功能和扩展特性。-   分配策略比较简单：DNS    负载均衡支持的算法少；不能区分服务器的差异（不能根据系统与服务的状态来判断负载）；也无法感知后端服务器的状态。针对 DNS负载均衡的一些缺点，对于时延和故障敏感的业务，有一些公司自己实现了HTTP-DNS 的功能，即使用 HTTP 协议实现一个私有的 DNS系统。这样的方案和通用的 DNS 优缺点正好相反。**硬件负载均衡**硬件负载均衡是通过单独的硬件设备来实现负载均衡功能，这类设备和路由器、交换机类似，可以理解为一个用于负载均衡的基础网络设备。目前业界典型的硬件负载均衡设备有两款：F5和A10。这类设备性能强劲、功能强大，但价格都不便宜，一般只有"土豪"公司才会考虑使用此类设备。普通业务量级的公司一是负担不起，二是业务量没那么大，用这些设备也是浪费。硬件负载均衡的优点是：-   功能强大：全面支持各层级的负载均衡，支持全面的负载均衡算法，支持全局负载均衡。-   性能强大：对比一下，软件负载均衡支持到 10    万级并发已经很厉害了，硬件负载均衡可以支持 100 万以上的并发。-   稳定性高：商用硬件负载均衡，经过了良好的严格测试，经过大规模使用，稳定性高。-   支持安全防护：硬件均衡设备除具备负载均衡功能外，还具备防火墙、防    DDoS 攻击等安全功能。硬件负载均衡的缺点是：-   价格昂贵：最普通的一台 F5 就是一台"马 6"，好一点的就是"Q7"了。-   扩展能力差：硬件设备，可以根据业务进行配置，但无法进行扩展和定制。**软件负载均衡**软件负载均衡通过负载均衡软件来实现负载均衡功能，常见的有 Nginx 和LVS，其中 Nginx 是软件的 7 层负载均衡，LVS 是 Linux 内核的 4层负载均衡。4 层和 7 层的区别就在于**协议**和**灵活性**，Nginx 支持HTTP、E-mail 协议；而 LVS 是 4层负载均衡，和协议无关，几乎所有应用都可以做，例如，聊天、数据库等。软件和硬件的最主要区别就在于性能，硬件负载均衡性能远远高于软件负载均衡性能。Ngxin的性能是万级，一般的 Linux 服务器上装一个 Nginx 大概能到 5 万 / 秒；LVS的性能是十万级，据说可达到 80 万 / 秒；而 F5 性能是百万级，从 200 万 /秒到 800 万 /秒都有（数据来源网络，仅供参考，如需采用请根据实际业务场景进行性能测试）。当然，软件负载均衡的最大优势是便宜，一台普通的Linux 服务器批发价大概就是 1 万元左右，相比 F5的价格，那就是自行车和宝马的区别了。除了使用开源的系统进行负载均衡，如果业务比较特殊，也可能基于开源系统进行定制（例如，Nginx插件），甚至进行自研。下面是 Nginx 的负载均衡架构示意图：﻿![](Images/ce8f4b8fc178a90362a9157b9f641a78.png){savepage-src="https://static001.geekbang.org/resource/image/13/35/136afcb3b3bc964f2609127eb27a0235.jpg"}软件负载均衡的优点：-   简单：无论是部署还是维护都比较简单。-   便宜：只要买个 Linux 服务器，装上软件即可。-   灵活：4 层和 7    层负载均衡可以根据业务进行选择；也可以根据业务进行比较方便的扩展，例如，可以通过    Nginx 的插件来实现业务的定制化功能。其实下面的缺点都是和硬件负载均衡相比的，并不是说软件负载均衡没法用。-   性能一般：一个 Nginx 大约能支撑 5 万并发。-   功能没有硬件负载均衡那么强大。-   一般不具备防火墙和防 DDoS 攻击等安全功能。
## 负载均衡典型架构 {#21.html#-}前面我们介绍了 3 种常见的负载均衡机制：DNS负载均衡、硬件负载均衡、软件负载均衡，每种方式都有一些优缺点，但并不意味着在实际应用中只能基于它们的优缺点进行非此即彼的选择，反而是基于它们的优缺点进行组合使用。具体来说，组合的**基本原则**为：DNS负载均衡用于实现地理级别的负载均衡；硬件负载均衡用于实现集群级别的负载均衡；软件负载均衡用于实现机器级别的负载均衡。我以一个假想的实例来说明一下这种组合方式，如下图所示。![](Images/0e44b77143c47600eb2962c6cc348a51.png){savepage-src="https://static001.geekbang.org/resource/image/37/e4/3767c5f314bc966491ba0e556c0a63e4.png"}整个系统的负载均衡分为三层。-   地理级别负载均衡：www.xxx.com    部署在北京、广州、上海三个机房，当用户访问时，DNS    会根据用户的地理位置来决定返回哪个机房的 IP，图中返回了广州机房的 IP    地址，这样用户就访问到广州机房了。-   集群级别负载均衡：广州机房的负载均衡用的是 F5 设备，F5    收到用户请求后，进行集群级别的负载均衡，将用户请求发给 3    个本地集群中的一个，我们假设 F5 将用户请求发给了"广州集群 2"。-   机器级别的负载均衡：广州集群 2 的负载均衡用的是 Nginx，Nginx    收到用户请求后，将用户请求发送给集群里面的某台服务器，服务器处理用户的业务请求并返回业务响应。需要注意的是，上图只是一个示例，一般在大型业务场景下才会这样用，如果业务量没这么大，则没有必要严格照搬这套架构。例如，一个大学的论坛，完全可以不需要DNS 负载均衡，也不需要 F5 设备，只需要用 Nginx作为一个简单的负载均衡就足够了。
## 小结 {#21.html#-}今天我为你讲了负载均衡的常见分类以及典型架构，希望对你有所帮助。这就是今天的全部内容，留一道思考题给你吧，假设你来设计一个日活跃用户1000 万的论坛的负载均衡集群，你的方案是什么？设计理由是什么？欢迎你把答案写到留言区，和我一起讨论。相信经过深度思考的回答，也会让你对知识的理解更加深刻。（编辑乱入：精彩的留言有机会获得丰厚福利哦！）![](Images/f2eae62fce5bba3ca5ee38d11da01862.png){savepage-src="https://static001.geekbang.org/resource/image/ba/37/ba6fcd186893b8cc9977d18e1fa5ab37.jpg"}
# 21 \| 高性能负载均衡：算法负载均衡算法数量较多，而且可以根据一些业务特性进行定制开发，抛开细节上的差异，根据算法期望达到的目的，大体上可以分为下面几类。-   任务平分类：负载均衡系统将收到的任务平均分配给服务器进行处理，这里的"平均"可以是绝对数量的平均，也可以是比例或者权重上的平均。-   负载均衡类：负载均衡系统根据服务器的负载来进行分配，这里的负载并不一定是通常意义上我们说的"CPU    负载"，而是系统当前的压力，可以用 CPU    负载来衡量，也可以用连接数、I/O    使用率、网卡吞吐量等来衡量系统的压力。-   性能最优类：负载均衡系统根据服务器的响应时间来进行任务分配，优先将新任务分配给响应最快的服务器。-   Hash 类：负载均衡系统根据任务中的某些关键信息进行 Hash 运算，将相同    Hash 值的请求分配到同一台服务器上。常见的有源地址 Hash、目标地址    Hash、session id hash、用户 ID Hash 等。接下来我介绍一下[负载均衡算法以及它们的优缺点。]{.orange}
## 轮询 {#22.html#-}负载均衡系统收到请求后，按照顺序轮流分配到服务器上。轮询是最简单的一个策略，无须关注服务器本身的状态，例如：``{=html}-   某个服务器当前因为触发了程序 bug 进入了死循环导致 CPU    负载很高，负载均衡系统是不感知的，还是会继续将请求源源不断地发送给它。-   集群中有新的机器是 32 核的，老的机器是 16    核的，负载均衡系统也是不关注的，新老机器分配的任务数是一样的。需要注意的是负载均衡系统无须关注"服务器本身状态"，这里的关键词是"本身"。也就是说，**只要服务器在运行，运行状态是不关注的**。但如果服务器直接宕机了，或者服务器和负载均衡系统断连了，这时负载均衡系统是能够感知的，也需要做出相应的处理。例如，将服务器从可分配服务器列表中删除，否则就会出现服务器都宕机了，任务还不断地分配给它，这明显是不合理的。总而言之，"简单"是轮询算法的优点，也是它的缺点。