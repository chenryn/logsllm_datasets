improve page load time on anonymity networks, and
therefore HTTP/2 did not help. To speed up browsing, we
need to reduce the number of round trips. We also found that
several theoretical issues behind pipelining and HTTP/2 had
no signiﬁcant effect on Tor, including head-of-line blocking,
transfer rate, and potential errors in HTTP/2 connections.
We proposed a series of improvements to speed up brows-
ing focusing on reducing round-trips in two directions: re-
ducing the number of round trips required to load each
resource (TFO, optimistic data, 0-RTT TLS) and reduce the
number of round trips required to load the web page as a
whole (databases for redirection, HTTP/2, and prefetching).
Our simulator predicts that page load times on Tor Browser
would be reduced by 61%, prefetching contributing to roughly
half of the improvement. There are only two trivial sources
of extra bandwidth for Tor in our proposed features:
the
cost to distribute and update page databases for clients (less
than a megabyte with 10,000 pages), and the minor chance
of a prefetching false positive causing unnecessary loading.
All of our proposed changes are client-side, and adoption is
instantaneous and invisible once deployed.
Reproducibility. We publish our code and data at:
github.com/blastpipeline/blastpipeline
The repository includes the following:
• The BLAST logger: a patch to Tor Browser to instrument
it, and Python code to parse those logs into resource trees
and other useful formats.
• The BLAST simulator: Python code to simulate HTTP/1.1
with and without pipelining, HTTP/2, and all six proposed
features.
• Data sets to validate the logger and simulator
for
HTTP/1.1 with pipelining on TB-8.5, HTTP/2 on TB-8.5,
and HTTP/1.1 with pipelining on TB-6.5.
• Prototype implementation of
redirection and server
databases.
REFERENCES
[1] Masoud Akhoondi, Curtis Yu, and Harsha V Madhyastha. Lastor: A
In Proceedings of the 2012 IEEE
low-latency as-aware tor client.
Symposium on Security and Privacy, pages 476–490, 2012.
[2] Mashael AlSabah, Kevin Bauer, Tariq Elahi, and Ian Goldberg. The
path less travelled: Overcoming tors bottlenecks with trafﬁc splitting.
In International Symposium on Privacy Enhancing Technologies Sym-
posium, pages 143–163. Springer, 2013.
[3] Mashael AlSabah, Kevin Bauer, and Ian Goldberg. Enhancing Tor’s
In Proceedings of
performance using real-time trafﬁc classiﬁcation.
the 2012 ACM Conference on Computer and Communications Security,
pages 73–84, 2012.
[4] Mashael AlSabah, Kevin Bauer, Ian Goldberg, Dirk Grunwald, Damon
McCoy, Stefan Savage, and Geoffrey M Voelker. Defenestrator:
Throwing out windows in tor. In International Symposium on Privacy
Enhancing Technologies Symposium, pages 134–154, 2011.
[5] Kevin S Bauer, Micah Sherr, and Dirk Grunwald. ExperimenTor: A
Testbed for Safe and Realistic Tor Experimentation. In CSET, 2011.
[6] Xiang Cai, Rishab Nithyanand, and Rob Johnson. CS-BuFLO: A
Congestion Sensitive Website Fingerprinting Defense. In Proceedings
of the 13th ACM Workshop on Privacy in the Electronic Society, 2014.
[7] R. Dingledine, N. Mathewson, and P. Syverson. Tor: The second-
generation onion router. In Proceedings of the 13th USENIX Security
Symposium, 2004.
[8] Peter Eckersley. How unique is your web browser?
Enhancing Technologies, pages 1–18, 2010.
In Privacy
[10]
[9] Benjamin Fabian, Florian Goertz, Steffen Kunz, Sebastian M¨uller, and
Mathias Nitzsche. Privately waiting–a usability analysis of the tor
anonymity network. In SIGeBIZ track of the Americas Conference on
Information Systems, pages 63–75. Springer, 2010.
Ian Goldberg. Optimistic data for Tor (PETS rump session talk). https:
//thunk.cs.uwaterloo.ca/optimistic-data-pets2010-rump.pdf. Accessed
Jan. 2019.
Jamie Hayes and George Danezis. k-Fingerprinting: A Robust Scalable
Website Fingerprinting Technique. In Proceedings of the 25th USENIX
Security Symposium, 2016.
[11]
[12] Rob Jansen, John Geddes, Chris Wacek, Micah Sherr, and Paul F
Syverson. Never Been KIST: Tor’s Congestion Management Blossoms
In Proceedings of the 23rd
with Kernel-Informed Socket Transport.
USENIX Security Symposium, pages 127–142, 2014.
[13] Rob Jansen and Nicholas Hooper. Shadow: Running Tor in a box
for accurate and efﬁcient experimentation. In Proceedings of the 18th
Network and Distributed System Security Symposium, 2011.
[14] Rob Jansen, Nicholas Hopper, and Yongdae Kim. Recruiting New Tor
relays with BRAIDS. In Proceedings of the 17th ACM Conference on
Computer and Communications Security, pages 319–328, 2010.
[15] Rob Jansen, Marc Juarez, Rafael Galvez, Tariq Elahi, and Claudia
Diaz. Inside job: Applying trafﬁc analysis to measure Tor from within.
In Proceedings of the 25th Network and Distributed System Security
Symposium, 2018.
[16] Marc Juarez, Mohsen Imani, Mike Perry, Claudia Diaz, and Matthew
In
Wright. Toward an Efﬁcient Website Fingerprinting Defense.
Computer Security–ESORICS 2016, pages 27–46. Springer, 2016.
[17] Colm MacC´arthaigh. Security Review of TLS1.3 0-RTT. https://github.
[18]
com/tlswg/tls13-spec/issues/1001. Accessed Jan. 2019.
Jon McLachlan, Andrew Tran, Nicholas Hopper, and Yongdae Kim.
Scalable Onion Routing with Torsk. In Proceedings of the 16th ACM
Conference on Computer and Communications Security, pages 590–
599, 2009.
[19] Andriy Panchenko, Fabian Lanze, Andreas Zinnen, Martin Henze, Jan
Pennekamp, Klaus Wehrle, and Thomas Engel. Website Fingerprinting
at Internet Scale. In Proceedings of the 23rd Network and Distributed
System Security Symposium, 2016.
[20] Mike
Perry.
Fingerprinting.
website-trafﬁc-ﬁngerprinting, September 2011. Accessed Feb. 2015.
for Website Trafﬁc
https://blog.torproject.org/blog/experimental-defense-
Experimental Defense
[21] Vera Rimmer, Davy Preuveneers, Marc Juarez, Tom Van Goethem,
and Wouter Joosen. Automated website ﬁngerprinting through deep
learning. 2018.
14
[22] Payap Sirinam, Mohsen Imani, Marc Juarez, and Matthew Wright. Deep
ﬁngerprinting: Undermining website ﬁngerprinting defenses with deep
In Proceedings of the 25th ACM Conference on Computer
learning.
and Communications Security, pages 1928–1943. ACM, 2018.
[23] Robin Snader and Nikita Borisov. A Tune-up for Tor: Improving
Security and Performance in the Tor Network. In Proceedings of the
15th Network and Distributed System Security Symposium, volume 8,
page 127, 2008.
[24] Chris Wacek, Henry Tan, Kevin S Bauer, and Micah Sherr. An
Empirical Evaluation of Relay Selection in Tor. In Proceedings of the
20th Network and Distributed System Security Symposium, volume 13,
pages 24–27, 2013.
[25] Tao Wang, Kevin Bauer, Clara Forero, and Ian Goldberg. Congestion-
aware path selection for tor. In International Conference on Financial
Cryptography and Data Security, pages 98–113, 2012.
[26] Tao Wang, Xiang Cai, Rishab Nithyanand, Rob Johnson, and Ian
Goldberg. Effective Attacks and Provable Defenses for Website Fin-
gerprinting. In Proceedings of the 23rd USENIX Security Symposium,
2014.
[27] Tao Wang and Ian Goldberg. Walkie-Talkie: An Efﬁcient Defense
Against Passive Website Fingerprinting Attacks. In Proceedings of the
26th USENIX Security Symposium, 2017.
APPENDIX
A. Pipelining implementation issues
We note a number of issues in the implementation of
pipelining in TB-6.5 that delayed page loading:
• Minimum depth. TB-6.5 enforces a minimal length of
three on all pipelines. If there are fewer than three requests
in the pending queue, and at least one active pipeline, the
browser will never send out any resource requests, even
if there are idle connections waiting to send out requests.
This causes unnecessary queue wait times.
• Randomization of resources. TB-6.5 randomly shuf-
ﬂes resources before dispatching. As more important
resources are often parsed ﬁrst, this is disadvantageous to
page loading. This may have been meant to defeat website
ﬁngerprinting attacks [20], but previous work suggests
that this has no effect against any website ﬁngerprinting
attack [26].
• Randomization of pipelines. TB-6.5 randomly chooses
pipelines to dispatch from the set of all valid pipelines.
This causes TB-6.5 to lose possible optimization options
for pipeline selection. For example, pipelines that have
completed TLS negotiation should be prioritized. Among
those, pipelines with fewer dispatched resource requests
should be prioritized to avoid head-of-line blocking.
• Blocking resources. The HTTP server can mark any re-
source as a blocking resource. Before a blocking resource
is fully loaded, no new resource can be dispatched, even
onto pipelines, and no new connection can be created.
This was intended to ensure that certain resources would
be loaded as soon as possible. However, it is not worth
delaying all other resources by round trips to accommo-
date a single resource.
B. Detailed results on correlation of page load time
We calculated the r correlation coefﬁcient with four fea-
tures as described in Section V-A on http2. These four fea-
tures were minRT T , size of page, HTTP/2 usage percentage,
and number of resources. minRT T is calculated by taking
(a)
(b)
(c)
(d)
Fig. 9: Scatter plots for page load times on http2 versus (a) minRTT, (b) Size of page, (c) HTTP/2 usage percentage, and (d)
Number of resources. In each graph, r is the Pearson correlation coefﬁcient between the plotted serieses.
each resource on the path between the last resource and the
root of the resource tree, and adding:
• 3 if the resource is on a new HTTPS connection;
• 2 if the resource is on a new HTTP connection;
• 1 otherwise.
We present the results in Figure 9. minRT T indeed has the
best correlation with page load time, with r = 0.57 compared
to r = 0.45 for number of resources and r = 0.38 for page
size. In addition, from the minRT T plot, we can see that the
page load time was always greater than and often close to
minRT T times 0.38 s, reinforcing the notion that page load
time was often directly caused by round trips.
C. BLAST implementation
1) How BLAST simulates web page loading: BLAST sim-
ulates web page loading by mimicking while simplifying the
logic of Firefox’s connection manager. It maintains two types
of objects, connections and resources. The simulation is event-
driven; the simulation begins with a single event corresponding
to loading the ﬁrst resource, which generates more events,
and the simulation ends when all events have been treated.
Each event has a time, a type, and an attached connection or
resource. We describe the simulator’s logic by explaining how
it deals with each event.
Several events trigger an attempt
to “dispatch all re-
sources”, which checks all connections to see if any is available
to dispatch any resources in the waiting queue, and creates
new connections if allowed to (due to the rules of HTTP/2,
pipelining, or connection limits). We mimic the rules in the
browser regarding which connections to choose to dispatch
on.
Resource events
for the relevant server, and dispatch all resources.
• Resource created: Add the resource to the waiting queue
• Resource dispatched: This happens when a resource is
successfully requested over a connection. Calculate how
long it would take to load such a resource based on round
trips required and bandwidth, declare the connection
occupied, and create a resource completed event after that
time. (Pipelining would alter this calculation.) Create new
resource created events if this resource has any children
in the resource tree after an appropriate time.
• Resource completed: Declare the relevant connection to
be available for further dispatch, and mark the resource
as complete with relevant time statistics. Dispatch all
resources.
Connection events
• Connection created: Simulate TLS and ALPN handshakes
if necessary, then declare TLS ﬁnished and ALPN ﬁnished
after appropriate times.
• TLS ﬁnished: Dispatch all resources.
• ALPN ﬁnished: Mark the connection as allowing HTTP/2
from now on (instead of just HTTP/1.1).
2) How BLAST determines resource parenthood: It is nec-
essary to know the parent of each resource to construct the
resource tree, a crucial data structure used to analyze and
simulate the page loading process. However, the web browser
does not record or output the parent of each resource.
To determine the parent of a resource, BLAST uses browser
logs to examine the context under which it was created as
follows. We start by determining the parent candidates of
every resource: the last resource that was written to before the
examined resource was created, as well as any other resource
written within 0.05 s of that, is a parent candidate. We chose
0.05 s heuristically because we observed that parsing time
usually did not exceed this amount. Then, we set parents in
three loops of all resources:
1) We mark all resources with only one parent candidate as
having such a parent.
2) For the remaining resources, if only one of their parent
candidates was chosen as a parent for some other resource
in step 1, we mark that candidate as the parent.
3) For the remaining resources, we mark the last resource
written to as the parent.
The ﬁnal step ensures that all resources (except the ﬁrst
resource for each page, representing user action to load the
page) will have a parent.
15
 0 10 20 30 40 50 60 0 20 40 60r = 0.57Page load time (s)minRTT 0 10 20 30 40 50 60 0 1x106 2x106 3x106 4x106 5x106r = 0.38Page load time (s)Page size (bytes) 0 10 20 30 40 50 60 0 0.2 0.4 0.6 0.8 1r = -0.08Page load time (s)HTTP/2 usage percentage 0 10 20 30 40 50 60 0 100 200 300 400 500r = 0.45Page load time (s)Number of resources