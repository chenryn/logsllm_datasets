title:Diagnosing network-wide traffic anomalies
author:Anukool Lakhina and
Mark Crovella and
Christophe Diot
Diagnosing Network-Wide Trafﬁc Anomalies
Dept. of Computer Science,
Dept. of Computer Science,
Mark Crovella
Boston University
Anukool Lakhina
Boston University
∗
Christophe Diot
Intel Research
Cambridge, UK
PI:EMAIL
PI:EMAIL
PI:EMAIL
ABSTRACT
Anomalies are unusual and signiﬁcant changes in a network’s traf-
ﬁc levels, which can often span multiple links. Diagnosing anoma-
lies is critical for both network operators and end users.
It is a
difﬁcult problem because one must extract and interpret anomalous
patterns from large amounts of high-dimensional, noisy data.
In this paper we propose a general method to diagnose anoma-
lies. This method is based on a separation of the high-dimensional
space occupied by a set of network trafﬁc measurements into dis-
joint subspaces corresponding to normal and anomalous network
conditions. We show that this separation can be performed effec-
tively by Principal Component Analysis.
Using only simple trafﬁc measurements from links, we study
volume anomalies and show that the method can: (1) accurately
detect when a volume anomaly is occurring; (2) correctly identify
the underlying origin-destination (OD) ﬂow which is the source of
the anomaly; and (3) accurately estimate the amount of trafﬁc in-
volved in the anomalous OD ﬂow.
We evaluate the method’s ability to diagnose (i.e., detect, iden-
tify, and quantify) both existing and synthetically injected volume
anomalies in real trafﬁc from two backbone networks. Our method
consistently diagnoses the largest volume anomalies, and does so
with a very low false alarm rate.
Categories and Subject Descriptors
C.2.3 [Computer-Communication Networks]: Network Opera-
tions
General Terms
Measurement, Performance, Security
∗
This work was performed while M. Crovella was at Laboratoire
d’Informatique de Paris 6 (LIP6), with support from Centre Na-
tional de la Recherche Scientiﬁque (CNRS) France and Sprint
Labs. Part of this work was done when A. Lakhina was at Intel
Research, Cambridge, UK. Data used in the paper was collected
while A. Lakhina was at Sprint Labs. This work was supported in
part by a grant from Sprint Labs, and by NSF grants ANI-9986397
and CCR-0325701.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
SIGCOMM’04, Aug. 30–Sept. 3, 2004, Portland, Oregon, USA.
Copyright 2004 ACM 1-58113-862-8/04/0008 ...$5.00.
Keywords
Anomaly Detection, Network Trafﬁc Analysis
1.
INTRODUCTION
Understanding the nature of trafﬁc anomalies in a network is an
important problem. Regardless of whether the anomalies in ques-
tion are malicious or unintentional, it is important to analyze them
for two reasons:
• Anomalies can create congestion in the network and stress
resource utilization in a router, which makes them crucial to
detect from an operational standpoint.
• Some anomalies may not necessarily impact the network, but
they can have a dramatic impact on a customer or the end
user.
A signiﬁcant problem when diagnosing anomalies is that their forms
and causes can vary considerably: from Denial of Service (DoS)
attacks, to router misconﬁgurations, to the results of BGP policy
modiﬁcations.
Despite a large literature on trafﬁc characterization, trafﬁc anoma-
lies remain poorly understood. There are a number of reasons for
this.
First, identifying anomalies requires a sophisticated moni-
toring infrastructure. Unfortunately, most ISPs only collect simple
trafﬁc measures, e.g., average trafﬁc volumes (using SNMP). More
adventurous ISPs do collect ﬂow counts on edge links, but process-
ing the collected data is a demanding task. A second reason for
the lack of understanding of trafﬁc anomalies is that ISPs do not
have tools for processing measurements that are fast enough to de-
tect anomalies in real time. Thus, ISPs are typically aware of major
events (worms or DoS attacks) after the fact, but are generally not
able to detect them while they are in progress. A ﬁnal reason is that
the nature of network-wide trafﬁc is high-dimensional and noisy,
which makes it difﬁcult to extract meaningful information about
anomalies from any kind of trafﬁc statistics.
In this paper we address the problem of diagnosing trafﬁc anoma-
lies that may span multiple links in a network, using link-based
statistics. Our approach addresses the anomaly diagnosis problem
in three steps: it ﬁrst uses a general method to detect anomalies in
network trafﬁc, then employs distinct methods to identify and quan-
tify them. We believe that this three step approach is appropriate
for addressing the large variety of network trafﬁc anomalies. This is
because the detection step can target different trafﬁc characteristics
such as volume, number of ﬂows, or routing events, while identiﬁ-
cation and quantiﬁcation are speciﬁc to each type of anomaly.
The goal of this paper is not to explain the cause of network
anomalies, but rather to provide a general technique to diagnose
219x 107
x 107
x 108
x 108
x 108
4
2
10
5
1.6
1.4
1.2
1
0.8
0.6
3
2.5
2
2.5
2
1.5
OD flow b−i 
Link f−i 
Link d−f 
Link c−d 
Link b−c 
x 106
15
10
5
x 107
x 107
x 107
x 107
8
6
4
6
4
2
6
4
2
6
4
2
OD flow i−b 
Link c−b
Link d−c
Link f−d
Link i−f
Wed
Thu
Fri
Fri
Sat
Sun
(a) Example 1
(b) Example 2
Figure 1: Examples of anomalies at the OD ﬂow level (top row) that we want to diagnose from link trafﬁc.
trafﬁc anomalies. We believe that a necessary ﬁrst step to discover-
ing the causes of anomalies is the correct detection, identiﬁcation,
and quantiﬁcation of anomalies.
The contributions of this paper are: (i) a general approach to
diagnose anomalies in network trafﬁc, (ii) the application of this
method on simple link trafﬁc statistics to isolate “volume anoma-
lies,” and (iii) the validation of this method using real data collected
on two different backbone networks.
Our method is based on a separation of the space of trafﬁc mea-
surements into normal and anomalous subspaces, by means of Prin-
cipal Component Analysis. We evaluate the approach using trafﬁc
collected from two large backbone networks. We apply the method
to both real and synthetically generated anomalies. Our results
show that our algorithms are effective at detection (with high detec-
tion rate and low false alarm rate); are quite accurate in identifying
the underlying OD ﬂow responsible for the anomaly; and are also
accurate in estimating the number of bytes in the anomaly.
The paper is organized as follows. In Section 2, we introduce a
speciﬁc variant of trafﬁc anomalies called volume anomalies and
explain why they are important. In Section 3, we describe the data
used to illustrate and validate this work. In Section 4, we explain
our general approach, which is to decompose the network operat-
ing conditions in two subspaces: normal and anomalous. In Sec-
tion 5, we show how to diagnose volume anomalies by analyzing
the anomalous subspace. In Section 6, we validate our approach
in two ways: we exploit access to underlying ﬂow data to extract
true anomalies using timeseries methods, against which we eval-
uate detection and false alarm rates and we systematically inject
anomalies across time and ﬂows to thoroughly evaluate the method.
In Section 7, we discuss further extensions and generalizations of
our approach to other types of network anomalies. We contrast our
approach from existing work on trafﬁc anomalies in Section 8 and
conclude in Section 9.
2. VOLUME ANOMALIES
A typical backbone network is composed of nodes (also called
Points of Presence, or PoPs) that are connected by links. We de-
ﬁne an Origin-Destination (OD) ﬂow as the trafﬁc that enters the
backbone at the origin PoP and exits at the destination PoP. The
path followed by each OD ﬂow is determined by the routing tables.
Therefore, the trafﬁc observed on each backbone link arises from
the superposition of these OD ﬂows.
We will use the term volume anomaly to refer to a sudden (with
respect to timestep used) positive or negative change in an OD
ﬂow’s trafﬁc. Because such an anomaly originates outside the net-
work, it will propagate from the origin PoP to the destination PoP.
One could detect volume anomalies by collecting IP ﬂow-level
trafﬁc summaries on all input links at all PoPs, and applying tem-
poral decomposition methods to each OD ﬂow in the manner of
[1, 14].
In general, this is impractical, for a number of reasons.
First, there can be hundreds of customer links in a network. Moni-
toring all input links to collect and aggregate ﬂow level data is ex-
tremely resource intensive; for many ISPs this cost is prohibitive.
Second, each OD ﬂow would need to be processed separately, re-
quiring estimation of associated parameters for each of the (poten-
tially hundreds of) temporal decompositions.
Instead, we develop a simpler and more practical technique for
diagnosing volume anomalies. Given that a volume anomaly prop-
agates through the network, we make use of the fact that we should
be able to observe it on all links it traverses. Thus we identify OD
ﬂow based anomalies by observing only link counts. (If more de-
tailed information about IP source and destination of an anomaly is
then needed, our method can be used as a trigger to indicate which
routers need IP ﬂow-level data collection initiated on temporary
basis.)
In the next section, we illustrate volume anomalies on link time
series taken from a backbone network. Then we propose a diagno-
sis technique in three steps that relies on the link statistics that are
already collected systematically by network operators.
2.1 An Illustration
The difﬁculty of the volume anomaly diagnosis problem stems in
part from the fact that it only uses link data (such as can be collected
via SNMP). From this link data, one must form inferences about
unusual events occurring in the underlying OD ﬂows.
We illustrate this difﬁculty in Figure 1. The top plot on each side
of the ﬁgure shows an OD ﬂow timeseries with an associated vol-
ume anomaly – this information is not available to our algorithms,
but we present it to show the nature of the anomalies we are con-
cerned with. The point at which each anomaly occurs is designated
by a circle on the timeline. Below the timeline are plots of link
trafﬁc on the four links that carry the given OD ﬂow. These four
plots represent the data that is available to our algorithm. Diagno-
sis of the anomaly consists of processing all link data so as to: (1)
correctly detect that at the time shown, the network is experiencing
an anomaly; (2) correctly isolate the four links shown as those ex-
periencing the anomaly; and (3) correctly estimate the size of the
spike in the OD ﬂow.
We make three observations from these examples. First, while
the OD ﬂows have pronounced spikes, the corresponding spike in
the link trafﬁc is dwarfed, and difﬁcult to detect even from visual
inspection. For instance, the trafﬁc volume at the spike time on
links c-d and b-c in Example 1 is barely distinguishable. Second,
the temporal trafﬁc patterns may vary substantially from one link
to another. In Example 2, link i-f has a smooth trend, whereas
the other links for the OD ﬂow have more noisy trafﬁc. Separating
the spike from the noise in the trafﬁc on link c-b is visually more
difﬁcult than separating the spike in link i-f. Thus isolating all the
links exhibiting an anomaly is challenging. Finally, mean trafﬁc
levels vary considerably. In Example 1, the mean trafﬁc level on
link c-d is more than twice that of link f-i. The varying trafﬁc
levels makes it difﬁcult to estimate the size of the volume anomaly
and hence its operational importance.1
2.2 Problem Deﬁnition
The problem of diagnosing a volume anomaly in an OD ﬂow can
be separated into three steps: detection, identiﬁcation and quantiﬁ-
cation.
The detection problem consists of designating those points in
time at which the network is experiencing an anomaly. An effec-
tive algorithm for solving the detection problem should have a high
detection probability and a low false alarm probability.
The identiﬁcation problem consists of selecting the true anomaly
type from a set of possible candidate anomalies. The method we
propose is extensible to a wide variety of anomalies. However, as
a ﬁrst step in this paper, our candidate anomaly set is the set of all
individual OD ﬂows.
Finally, quantiﬁcation is the problem of estimating the number
of additional or missing bytes in the underlying trafﬁc ﬂows. Quan-
tiﬁcation is important because it gives a measure of the importance
of the anomaly.
For a successful diagnosis of a volume anomaly, one must be
able to detect the time of the anomaly, identify the underlying re-
sponsible OD ﬂow, and quantify the size of the anomaly within that
ﬂow.
3. DATA
Our technique operates on link trafﬁc data, of the kind obtained
by SNMP. For validation purposes we also use OD ﬂow data, but
this data is not an input to our algorithms. All these data have been
collected from two backbone networks, Sprint-Europe and Abilene.
Note that our anomaly diagnosis method is not limited to backbone
networks; it can be applied in any network where link counts are
available.
Sprint-Europe (henceforth Sprint) is the European backbone of
a US tier-1 ISP. This network has 13 PoPs and carries commercial
trafﬁc for large customers (companies, local ISPs, etc.). Abilene is
the Internet2 backbone network. It has 11 PoPs and spans the conti-
nental USA. Trafﬁc on Abilene is non-commercial, arising mainly
from major universities in the US.
1Both these examples were successfully diagnosed by the methods
in this paper.
Sprint-1
Sprint-2
Abilene
# PoPs
13
13
11
Period
# Links Time Bin
10 min
Jul 07-Jul 13
10 min Aug 11-Aug 17
Apr 07-Apr 13
10 min
49
49
41
Table 1: Summary of datasets studied.
We collected sampled ﬂow data from each router in both net-
works. For Sprint, we used Cisco’s NetFlow [3] to collect ev-
ery 250th packet (periodic sampling). Packets are aggregated into
ﬂows at the network preﬁx level, and reported in 5 minute bins. On
Abilene sampling is random, capturing 1% of all packets. Sam-
pled packets are then aggregated at the 5-tuple level (IP address
and port number for both source and destination, along with proto-
col type) every minute using Juniper’s Trafﬁc Sampling [22]. We
found good agreement (within 1%-5% accuracy) between sampled
ﬂow byte counts, adjusted for sampling rate, and the correspond-
ing SNMP byte counts on links with utilization more than 1 Mbps.
Most of the links from both networks fall in this category, and so
our sampled ﬂow byte counts are likely to be reasonably accurate.
We aggregated both the Sprint and Abilene ﬂow trafﬁc counts into
bins of 10 minutes to avoid synchronization issues that could have
arisen in the data collection.
Trafﬁc anomalies can last anywhere from milliseconds to hours.
Although our method can be used on data with any time granularity,
in this paper we work with data binned on 10 minute intervals. In
fact, the most prevalent anomalies in our datasets were those that
lasted less than 10 minutes and show up as a pronounced spike at
a single point in time, as depicted in Figure 1. Thus the anomalies
that we detect are those that are signiﬁcant when trafﬁc is viewed at
10 minute intervals. In Section 7 we will discuss some implications
of the particular timescale we use.
To construct OD ﬂows from the raw ﬂows collected, we identify
the ingress and egress PoPs of each ﬂow. The ingress PoP can be
identiﬁed because we collect ﬂows from each ingress link in both
networks. For egress PoP resolution, we use BGP and ISIS routing
tables as detailed in [8]. For Sprint, we supplemented routing ta-
bles with router conﬁguration ﬁles to resolve customer IP address
spaces. Also, Abilene anonymizes the last 11 bits of the destina-
tion IP address. This is not a signiﬁcant concern because there are
few preﬁxes less than 11 bits in the Abilene routing tables, and we
found very little trafﬁc destined to these preﬁxes. Using this pro-
cedure, we collected two weeks of complete OD ﬂow trafﬁc counts
from Sprint and one week from Abilene. Table 1 summarizes our
datasets.
Our diagnosis method operates on link data, so in order to vali-
date against true OD ﬂows we must obtain a set of link trafﬁc counts
consistent with the sampled OD ﬂow data collected. To obtain this,
we follow the method of [25] and construct link counts from OD
ﬂow counts using a routing table taken from the network in opera-
tion.
4. SUBSPACE ANALYSIS OF LINK
TRAFFIC
Effective diagnosis of anomalies in trafﬁc requires the ability to
separate them from normal network-wide trafﬁc. In this section, we
show how to use Principal Component Analysis (PCA) to separate
normal and anomalous network-wide trafﬁc conditions. We begin
by stating the relevant notation. We then introduce the basic ideas
behind PCA and apply it to the ensemble of link trafﬁc timeseries.
Finally, we show how to use PCA to separate the space of link traf-
ﬁc measurements into useful subspaces, representing normal and
anomalous trafﬁc behavior. Our anomaly diagnosis method as de-
scribed in Section 5 builds on the subspace separation developed
here.
4.1 Notation
The trafﬁc observed on each network link arises from the super-
position of OD ﬂows. The relationship between link trafﬁc and OD
ﬂow trafﬁc can be concisely captured in the routing matrix A. The
matrix A has size (# links) × (# OD-ﬂows), where Aij = 1 if OD
ﬂow j passes over link i, and is zero otherwise. Then the vector of
trafﬁc counts on links (y) is related to the vector of trafﬁc counts in
OD ﬂows (x) by y = Ax [23].
Let m denote the number of links in the network and t denote
the number of successive time intervals of interest. We let Y be
the t × m measurement matrix, which denotes the timeseries of
all links. Thus, each column i denotes the timeseries of the i-th
link and each row j represents an instance of all the links at time
j. In this paper t is the number of 10 minute bins in a week long
timeseries (1008) and m is 41 or 49, depending on the network.
While Y denotes the set of links measurements over time, we
will also frequently work just with y, a vector of measurements
from a single timestep. Thus y is an arbitrary row of Y, transposed
to a column vector.
We refer to individual columns of a matrix using a single sub-
script, so the timeseries of measurements of link i is denoted Yi.
All vectors in this paper are column vectors, unless otherwise noted.
Finally, all vectors and matrices will be displayed in boldface;
matrices are denoted by upper case letters and vectors by lower
case letters.
4.2 PCA
PCA is a coordinate transformation method that maps a given
set of data points onto new axes. These axes are called the princi-
pal axes or principal components. When working with zero-mean
data, each principal component has the property that it points in
the direction of maximum variance remaining in the data, given
the variance already accounted for in the preceding components.
As such, the ﬁrst principal component captures the variance of the
data to the greatest degree possible on a single axis. The next prin-
cipal components then each capture the maximum variance among
the remaining orthogonal directions. Thus, the principal axes are
ordered by the amount of data variance that they capture.