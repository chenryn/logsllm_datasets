==== 索引配置对性能的影响
在检索语句本身无可优化的时候，巧妙利用日志易的索引配置，也可以一定程度上缩小获取数据的范围，进而达到优化检索性能的目的。
日志数据天然带有时间戳属性，而常用来检索的日志数据一般都是接近当前时间的热点数据。日志易基于此特点，设计有一个默认优化项：将日志索引按照时间维度切分保存。这样查询当天数据时，就不会从磁盘上读取今天之前的内容。
对于一些很少产生的、且和其他日志在类型用途上也截然不同的日志，日志易支持通过索引配置，改变这部分数据的索引目录，改变索引的切分时间。
比如，系统审计日志，一般量极少，但是会要求留存数年。您可以单独配置一个audit索引，切分时间为1年。然后搜索登录行为时，指定索引名称：
[source,bash]
index=audit login
索引配置的使用流程，参见《日志易使用手册》。
==== 基于定时任务的优化
对于确实需要大范围内数据统计结果的场景，日志易提供了‘定时任务’功能，近似物化视图的以空间换时间的方式，进行性能优化。
基于定时任务结果的性能优化，需要您掌握一定的数学统计常识，才能较好和较合理的得到即快速又精准的结果。以最常见的几个需求为例：
1. 实际想要的是每日的统计报表，那么生成中间结果的定时任务应该至少是间隔每小时运行一次；
2. 实际想要的top 10的统计报表，那么生成中间结果的定时任务应该每次保留top 100的数据；
3. 实际想要的是每天的平均值统计(avg)，那么生成中间结果的定时任务需要计算的不是每小时的平均值(avg)，而是总和(sum)和总数(count)。
以访问日志的平均响应时间趋势报表为例。如果直接使用SPL统计一个月的原始数据，语句如下：
[source,bash]
* | bucket timestamp span=1d as ts | stats avg(apache.request_time) as avgDay by ts
这样需要读取的数据量确实很大，我们可以先拆解成如下这么一个每10分钟运行一次的定时任务，假设任务名称为apache_rt_10min：
[source,bash]
* | stats sum(apache.request_time) as ApacheTimeSum, count(apache.request_time) as ApacheTimeCount
然后将统计一个月的SPL改写成下面这样：
[source,bash]
index=schedule schedule_name:apache_rt_10min | bucket timestamp span=1d as ts | stats sum(ApacheTimeSum) as sumDay,count(ApacheTimeCount) as countDay by ts | eval avgDay = sumDay / countDay | fields avgDay, ts
这样，您既可以得到准确的结果，又避免了过大检索的资源损耗。
此外，由于系统维护、网络异常等原因，定时任务的数据可能没法准确按时的汇总，需要您额外运行回补程序。详细的定时任务配置和回补程序使用说明，见《日志易使用手册》。
== 检索参数
SPL语法中，除了全文检索的部分，还支持一些特定的检索参数，可以限定检索的范围。目前主要包括：index、starttime和endtime。
[NOTE]
====
检索参数必须写在SPL语句的起始位置。
====
=== index
在之前小节已经分别介绍过index参数的两个主要使用场景：分索引存储数据，定时任务记录中间结果。
由于跨索引检索对部分指令的运行模式有一定影响，非必要情况下，不推荐您尝试配置多个index的联合检索。日志易目前也暂不支持这种使用方式。
=== starttime和endtime
除了在搜索界面上，通过手风琴式时间选择器点击生成搜索时间范围以外，您还可以直接在SPL语句中，通过starttime和endtime参数指定本次搜索的时间范围。而且SPL语句中的starttime和endtime参数，优先级高于搜索界面上的时间选择器。
需要手动指定时间范围的场景主要包括两种：
1. 主查询和子查询分别需要处理不同时间范围的数据。而时间选择器只能负责主查询部分。有关子查询的用法讲解，请查看后续子查询小节。
2. 需要定期运行的检索，通常以当前时间为基准，检索范围为当前时间往前一整段时间。
比如，定义一个SPL语句，只检索上一个小时的访问日志数据：
[source,bash]
starttime="-1h/h" endtime="now/h" logtype:apache
又如，定位到一个特定时间点的故障证据，需要保存下来备用：
[source,bash]
starttime=2017-07-18:03:29:12 endtime=2017-07-18:03:29:53 Exception
== 子查询
上一小节已经提到了子查询这个概念。一个子查询常用于作为另外一个SPL查询的参数，子查询被包含在双方括号`[[]]`中，将在外部查询执行之前被执行。所以在搜索界面，您将看到任务进度条一直停留在‘解析中’状态，直到子查询运行完毕，主查询的进度才会显示出来。
image::images/search-job-parsing.png[]
子查询执行的结果将作为外部spl的参数，常用于如下两个场景：
1. 使用子查询的结果作为主查询的搜索过滤条件；
2. 执行一个独立的搜索，将子查询的结果append或者join到主查询的结果中。
第二个场景本手册稍后章节将会专门介绍。本节主要介绍第一个场景。比如，查找访问日志中访问次数最多的IP地址的情况，可以写作：
[source,bash]
logtype:apache AND [[ logtype:apache  | stats count(apache.clientip) by apache.clientip | limit 1 | fields apache.clientip ]]
子查询支持返回多字段过滤，比如我们把上例需求改为：查找访问日志中访问同一URL地址次数最多的前5个IP地址的情况，那么请求要改写成：
[source,bash]
logtype:apache AND [[ logtype:apache  | stats count(apache.clientip) as cnt by apache.clientip, apache.request_path | dedup 1 apache.clientip | sort by cnt | limit 5 | fields apache.clientip, apache.request_path ]]
子查询部分的实际返回是：
image::images/search-example-subquery.png[]
那么附加到主查询之后，实际的过滤效果等于：
[source,bash]
logtype:apache AND ( (apache.clientip:"27.154.61.18" AND apache.request_path:"/api/v0/sources/upload_volum_info/") OR (apache.clientip:"117.87.36.144" AND apache.request_path:"/index/login/") OR (apache.clientip:"58.61.75.234" AND apache.request_path:"/index/login/") OR (apache.clientip:"180.175.172.21" AND apache.request_path:"/api/v0/sources/upload_volum_info/") OR (apache.clientip:"121.35.131.129" AND apache.request_path:"/index/login/") )
从这个例子，您很容易看出，子查询显著的减少了SPL语句的书写工作量；更重要的是：当下一次重复使用时，也不必担心访问IP和URL发生变化，子查询永远都会使用当前查询的最新结果作为过滤条件。
== 统计分析
所谓‘一图胜千言’，在日志分析中，恰当而巧妙地利用统计分析和可视化功能，常常能比阅读日志原文更加有效的发现和突出问题根源。本章将举例说明最常用的一些SPL统计分析场景，以及对应的可视化方式效果。
=== stats与可视化
stats是最常用的SPL统计指令。以最常见和简单的需求为例：计算最近一天访问日志中，每5分钟的平均响应时间走势，SPL写作：
[source,bash]
logtype:apache | bucket timestamp span=5m as ts | stats avg(apache.request_time) by ts
折线图效果如下：
image::images/search-example-line.png[]
如果有多条业务线，那么在一张图上展示不同业务线的平均响应时间走势是非常棒的一种监控方式，这时候只需要在上例的SPL语句最后加一个字段名，非常方便：
[source,bash]
logtype:apache | bucket timestamp span=5m as ts | stats avg(apache.request_time) by ts, apache.domain
image::images/search-example-line-group.png[]
另一类常见需求则是这样：统计今天访问的唯一用户数，也就是UV。日志易提供了专门的去重计数函数，SPL写作：
[source,bash]
logtype:apache | stats dc(apache.clientip)
采用访问IP地址作为用户标识，当然并不是一种很精准的定位方式。如果您的日志中有更合适的sessionid、userid等字段，可以获得更准确的统计结果。
日志易提供单值趋势展示，您可以选择将UV统计值和一天前的数据做一个对比：
image::images/search-example-singlevalue.png[]
另一个对于IT运维人员非常适用的统计函数，是pct_ranks()。运维部门应该都会设定一些关键业务的SLA指标，作为KPI考核的一部分。比如：SLA目标设定为95%的用户充值请求的响应时间小于200毫秒。那么，就可以使用如下SPL语句，统计出来实际数据中，有多少充值请求的响应时间小于200毫秒：
[source,bash]
json.action:recharge| stats pct_ranks(json.req_ms, 200) as sla | eval sla=sla.200/100
对于百分数结果，可以采用日志易专属的水位图展示：
image::images/search-example-liquidfill.png[]
要了解stats支持的全部统计函数，请参阅《日志易搜索参考》。
=== top与饼图
对于一些维度较单一、可选值不多，而且只需要关心大致比例的场景，通常我们称之为top10需求，日志易提供了专属的SPL指令和饼状图可视化效果。
比如：对于访问日志中，响应状态码的百分比统计，查询指令可以写作：
[source,bash]
logtype:apache | top 10 apache.method
请求会输出如下统计表格：
image::images/search-example-top-table.png[]
我们可以使用前两列作图得到如下饼图结果：
image::images/search-example-pie.png[]
注意，绘图上的百分比，是由前端JS程序自行计算的。事实上，上例的语句你可以替换成使用下面这个stats统计：
[source,bash]
logtype:apache | stats count() by apache.method | limit 10
可以看到完全一样的饼图效果。但是却无法在结果表格中看到百分比。对百分比数值敏感的情况，请优先使用top指令。
=== append与多Y轴的相关性对比
在之前章节中，我们已经讲过在一张图片上绘制多条曲线图的方式。不过还有另一类场景，IT人员通常会将来自不同系统的监控数据，层叠在一起，意图观察二者的相关性。比如：将服务器的CPU使用率，和访问日志的平均响应时间叠加起来，就可以知道是否因为负载问题导致访问受影响。
您可以使用append指令，将两个完全不同来源的数据结果连接到一起。上面场景的SPL语句写作：
[source,bash]
logtype:apache | eval apache.req_time=1000*apache.req_time | bucket timestamp span=1m as ts | stats avg(apache.req_time) by ts | append [[ appname:top_info_system_stats | bucket timestamp span=1m as ts | stats avg(json.Load.load1) by ts ]]
由于服务器负载通常在0到50之间，而响应时间(毫秒)通常在0到10000之间，采用单一的Y轴坐标，前者的曲线几乎就处于和X轴重叠的不可见状态。所以我们需要采取专属的多Y轴可视化效果。您还可以定义每个Y轴序列数据专属的展示形态。如下图所示：
image::images/search-example-multi-axies.png[]
同理，您还可以通过append指令叠加第三、第四条序列。不过由于每条Y轴都会占用一定的绘图空间，不建议您叠加过多的Y轴。