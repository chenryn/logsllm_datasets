* New: [Doing the inventory review.](grocy_management.md#doing-the-inventory-review)
    I haven't found a way to make the grocy inventory match the reality because for me it's hard to register when I consume a product. Even more if other people also use them. Therefore I use grocy only to know what to buy without thinking about it. For that use case the inventory needs to meet reality only before doing the groceries. I usually do a big shopping of non-perishable goods at the supermarket once each two or three months, and a weekly shopping of the rest.
    Tracking the goods that are bought each week makes no sense as those are things that are clearly seen and are very variable depending on the season. Once I've automated the ingestion and consumption of products it will, but so far it would mean investing more time than the benefit it gives.
    This doesn't apply to the big shopping, as this one is done infrequently, so we need a better planning.
    To do the inventory review I use a tablet and the [android app](https://github.com/patzly/grocy-android).
    - [ ] Open the stock overview and iterate through the locations to:
      - [ ] Make sure that the number of products match the reality
        - [ ] Iterate over the list of products checking the quantity
        - [ ] Look at the location to see if there are missing products in the inventory
      - [ ] Adjust the product properties (default location, minimum amount)
    - [ ] Check the resulting shopping list and adjust the minimum values.
    - [ ] Check the list of missing products to adjust the minimum values. I have a notepad in the fridge where I write the things I miss.
# Coding
## Languages
### [Bash snippets](bash_snippets.md)
* New: [Show the progresion of a long running task with dots.](bash_snippets.md#show-the-progresion-of-a-long-running-task-with-dots)
    ```bash
    echo -n "Process X is running."
    sleep 1
    echo -n "."
    sleep 1
    echo -n "."
    echo ""
    ```
### [Configure Docker to host the application](lua.md)
* New: [Inspect contents of Lua table in Neovim.](lua.md#inspect-contents-of-lua-table-in-neovim)
    When using Lua inside of Neovim you may need to view the contents of Lua tables, which are a first class data structure in Lua world. Tables in Lua can represent ordinary arrays, lists, symbol tables, sets, records, graphs, trees, etc.
    If you try to just print a table directly, you will get the reference address for that table instead of the content, which is not very useful for most debugging purposes:
    ```lua
    :lua print(vim.api.nvim_get_mode())
    " table: 0x7f5b93e5ff88
    ```
    To solve this, Neovim provides the `vim.inspect` function as part of its API. It serializes the content of any Lua object into a human readable string.
    For example you can get information about the current mode like so:
    ```lua
    :lua print(vim.inspect(vim.api.nvim_get_mode()))
    " {  blocking = false,  mode = "n"}
    ```
* New: [Send logs to journald.](docker.md#send-logs-to-journald)
    The `journald` logging driver sends container logs to the systemd journal. Log entries can be retrieved using the `journalctl` command, through use of the journal API, or using the docker logs command.
    In addition to the text of the log message itself, the `journald` log driver stores the following metadata in the journal with each message:
    | Field |	Description |
    | ---   |  ----  |
    | CONTAINER_ID |	The container ID truncated to 12 characters. |
    | CONTAINER_ID_FULL |	The full 64-character container ID. |
    | CONTAINER_NAME |	The container name at the time it was started. If you use docker rename to rename a container, the new name isn't reflected in the journal entries. |
    | CONTAINER_TAG, | SYSLOG_IDENTIFIER	The container tag ( log tag option documentation). |
    | CONTAINER_PARTIAL_MESSAGE |	A field that flags log integrity. Improve logging of long log lines. |
    To use the journald driver as the default logging driver, set the log-driver and log-opts keys to appropriate values in the `daemon.json` file, which is located in `/etc/docker/`.
    ```json
    {
      "log-driver": "journald"
    }
    ```
    Restart Docker for the changes to take effect.
* New: [Send the logs to loki.](docker.md#send-the-logs-to-loki)
    There are many ways to send logs to loki
    - Using the json driver and sending them to loki with promtail with the docker driver
    - Using the docker plugin: Grafana Loki officially supports a Docker plugin that will read logs from Docker containers and ship them to Loki.
      I would not recommend to use this path because there is a known issue that deadlocks the docker daemon :S. The driver keeps all logs in memory and will drop log entries if Loki is not reachable and if the quantity of `max_retries` has been exceeded. To avoid the dropping of log entries, setting `max_retries` to zero allows unlimited retries; the driver will continue trying forever until Loki is again reachable. Trying forever may have undesired consequences, because the Docker daemon will wait for the Loki driver to process all logs of a container, until the container is removed. Thus, the Docker daemon might wait forever if the container is stuck.
      The wait time can be lowered by setting `loki-retries=2`, `loki-max-backoff_800ms`, `loki-timeout=1s` and `keep-file=true`. This way the daemon will be locked only for a short time and the logs will be persisted locally when the Loki client is unable to re-connect.
      To avoid this issue, use the Promtail Docker service discovery.
    - Using the journald driver and sending them to loki with promtail with the journald driver. This has worked for me but the labels extracted are not that great.
* New: [Solve syslog getting filled up with docker network recreation.](docker.md#syslog-getting-filled-up-with-docker-network-recreation)
    If you find yourself with your syslog getting filled up by lines similar to:
    ```
     Jan 15 13:19:19 home kernel: [174716.097109] eth2: renamed from veth0adb07e
     Jan 15 13:19:20 home kernel: [174716.145281] IPv6: ADDRCONF(NETDEV_CHANGE): vethcd477bc: link becomes ready
     Jan 15 13:19:20 home kernel: [174716.145337] br-1ccd0f48be7c: port 5(vethcd477bc) entered blocking state
     Jan 15 13:19:20 home kernel: [174716.145338] br-1ccd0f48be7c: port 5(vethcd477bc) entered forwarding state
     Jan 15 13:19:20 home kernel: [174717.081132] br-fbe765bc7d0a: port 2(veth31cdd6f) entered disabled state
     Jan 15 13:19:20 home kernel: [174717.081176] vethc4da041: renamed from eth0
     Jan 15 13:19:21 home kernel: [174717.214911] br-fbe765bc7d0a: port 2(veth31cdd6f) entered disabled state
     Jan 15 13:19:21 home kernel: [174717.215917] device veth31cdd6f left promiscuous mode
     Jan 15 13:19:21 home kernel: [174717.215919] br-fbe765bc7d0a: port 2(veth31cdd6f) entered disabled state
    ```
    It probably means that some docker is getting recreated continuously. Those traces are normal logs of docker creating the networks, but as they do each time the docker starts, if it's restarting continuously then you have a problem.
### [Boto3](boto3.md)
* New: [Get running instances.](boto3.md#get-running-instances)
    ```python
    import boto3
    ec2 = boto3.client('ec2')
    running_instances = [
        instance
        for page in ec2.get_paginator('describe_instances').paginate()
        for reservation in page['Reservations']
        for instance in reservation['Instances']]
        if instance['State']['Name'] == 'running'
    ]
    ```
### [SQLite](sqlite.md)
* New: [Order by a column descending.](sqlite.md#order-by-a-column-descending)
    ```sql
    SELECT
       select_list
    FROM
       table
    ORDER BY
        column_1 ASC,
        column_2 DESC;
    ```
### [Python Snippets](python_snippets.md)
* New: [Get unique items between two lists.](python_snippets.md#get-unique-items-between-two-lists)
    If you want all items from the second list that do not appear in the first list you can write:
    ```
    x = [1,2,3,4]
    f = [1,11,22,33,44,3,4]
    result = set(f) - set(x)
    ```
* New: [Pad number with zeros.](python_snippets.md#pad-number-with-zeros)
    ```python
    number = 1
    print(f"{number:02d}")
    ```
* New: [Parse a datetime from an epoch.](python_snippets.md#parse-a-datetime-from-an-epoch)
    ```python
    >>> import datetime
    >>> datetime.datetime.fromtimestamp(1347517370).strftime('%c')
      '2012-09-13 02:22:50'
    ```
### [Inotify](python_inotify.md)
* New: Introduce python_inotify.
    [inotify](https://pypi.org/project/inotify/) is a python library that acts as a bridge to the `inotify` linux kernel which allows you to register one or more directories for watching, and to simply block and wait for notification events. This is obviously far more efficient than polling one or more directories to determine if anything has changed.
    Installation:
    ```bash
    pip install inotify
    ```
    Basic example using a loop:
    ```python
    import inotify.adapters
    def _main():
        i = inotify.adapters.Inotify()
        i.add_watch('/tmp')
        with open('/tmp/test_file', 'w'):
            pass
        for event in i.event_gen(yield_nones=False):
            (_, type_names, path, filename) = event
            print("PATH=[{}] FILENAME=[{}] EVENT_TYPES={}".format(
                  path, filename, type_names))
    if __name__ == '__main__':
        _main()
    ```
    Output:
    ```
    PATH=[/tmp] FILENAME=[test_file] EVENT_TYPES=['IN_MODIFY']
    PATH=[/tmp] FILENAME=[test_file] EVENT_TYPES=['IN_OPEN']
    PATH=[/tmp] FILENAME=[test_file] EVENT_TYPES=['IN_CLOSE_WRITE']
    ```
    Basic example without a loop:
    ```python
    import inotify.adapters
    def _main():
        i = inotify.adapters.Inotify()
        i.add_watch('/tmp')
        with open('/tmp/test_file', 'w'):
            pass
        events = i.event_gen(yield_nones=False, timeout_s=1)
        events = list(events)
        print(events)
    if __name__ == '__main__':
        _main()
    ```
    The wait will be done in the `list(events)` line
### [Pydantic](pydantic.md)
* New: Nicely show validation errors.
    A nice way of showing it is to capture the error and print it yourself:
    ```python
    try:
        model = Model(
            state=state,
        )
    except ValidationError as error:
        log.error(f'Error building model with state {state}')
        raise error
    ```
* New: [Load a pydantic model from json.](pydantic.md#load-a-pydantic-model-from-json)
    You can use the [`model_validate_json`](https://docs.pydantic.dev/latest/api/base_model/#pydantic.main.BaseModel.model_validate_json) method that will validate and return an object with the loaded data.
    ```python