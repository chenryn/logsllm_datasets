be much higher at the player than the arrival rate of the chunk bytes
from the network. We use TCP variables to estimate the download
throughout per-chunk:
throughput = M SS ×
CW N D
SRT T
(3)
To detect chunks with this issue, we detect outliers using stan-
dard deviation: when a chunk is buffered in the download stack, its
DF B is much higher than that of the other chunks — more than
2 · σ greater than the mean — despite other similar latency metrics
(i.e., network and server-side latency are within one σ of the mean).
Also, its T Pinst is much higher — more than 2 · σ greater than the
mean — due to the buffered data being delivered in a shorter time,
while the estimated throughput from server side (using CWND and
SRTT) does not explain the increase in throughput. Equations 4
summarize the detection conditions:
DF Bi > µDF B + 2 · σDF B
T Pinsti > µT Pinst + 2 · σT Pinst
SRT T, Dserver, CW N D 1perfscore1perfscore1perfscore ICWND, (3) no queuing delay
and similar SRTT (we use 60ms  30% drop) when the download
rate is below 1.5 sec
sec and good framerate when download rate is at
least 1.5 sec
sec . About 5.7% of chunks have low rates but good ren-
dering, which can be explained by the buffered video frames that
hide the effect of low rates. Finally, 6.9% of chunks have low fram-
erate despite a minimum download rate of 1.5 sec
sec , not conﬁrming
the hypothesis. However, this could be explained as follows: First,
the average download rate does not reﬂect instantaneous through-
put. In particular, earlier chunks are more sensitive to changes in
throughput, since fewer frames are buffered at the player. Second,
when the CPU on the client machine is overloaded, software ren-
dering can be inefﬁcient irrespective of the chunk arrival rate.
Figure 20 shows a simple controlled experiment, where a player
is running in the Firefox browser on OS X with eight CPU cores,
connected to the server using a 1Gpbs Ethernet link. The ﬁrst bar
represents the per-chunk dropped rate while using GPU decoding
and rendering. Next, we turned off hardware rendering; we see
increase in frame drop rate with background processes using CPU
cores.
2. Higher bitrates have better rendered framerate. Higher bi-
trates contain more data per frame, thus imposing a higher load on
the CPU for decoding and rendering in time. We expect chunks
with higher bitrates to have more dropped frames as a result. We
did not observe this in our data. However, we observed the fol-
lowing trends in the data: (1) higher bitrates are often requested in
connections with lower RTT variation: SRTTVAR across sessions
with bitrates higher than 1Mbps is 5ms lower than the rest. Less
variation may result in fewer frames delivered late. (2) higher bi-
trates are often requested in connections with lower retransmission
rate: the retransmission rate among sessions with bitrates higher
101102103104D_FB (ms)0.00.20.40.60.81.0CDFfirstother508Figure 19: %Dropped frames vs chunk download rate, ﬁrst bar
represents hardware rendering.
Figure 21: Browser popularity and rendering quality in the two
major platforms: Windows vs Mac.
)
%
(
s
e
m
a
r
f
d
e
p
p
o
r
D
10
8
6
4
2
0
<10% 100% 200% 300% 400% 500% 600% 700% 800%
CPU utilization (8 cores)
Figure 20: Dropped frames per CPU load in a controlled ex-
periment.
than 1Mbps is 1% lower than the rest. Lower packet loss rate re-