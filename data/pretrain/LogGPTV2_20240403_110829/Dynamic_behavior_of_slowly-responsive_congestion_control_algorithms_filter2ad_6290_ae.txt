o
r
h
T
)
c
e
s
2
.
0
/
B
K
(
t
u
p
h
g
u
o
r
h
T
140
120
100
80
60
40
20
0
140
120
100
80
60
40
20
0
flow 0, 0.2 sec bins
1 sec bins
drops
0
5
10
15
20
25
30
35
Time
flow 0, 0.2 sec bins
1 sec bins
drops
0
5
10
15
20
25
30
35
Time
Figure 18: TFRC (top) and TCP(1/8) (bottom) with a more
bursty loss pattern.
While the averaging of the loss rate in TFRC gives greater
smoothness in steady-state or in mildly bursty conditions, this same
averaging of the loss rate results in very poor smoothness from
TFRC in other more bursty conditions that exploit TFRC’s slow-
ness to forget about past conditions. Figures 17 and 18 show TFRC
and TCP(1/8) in two carefully designed scenarios intended to illus-
trate the best and the worst, respectively, in TFRC’s smoothness in
the face of bursty packet losses.
The simulations in Figure 17 each show a single ﬂow subjected
to a repeating loss pattern of three losses, each after 50 packet ar-
rivals, followed by three more losses, each after 400 packet arrivals.
For each graph the solid line shows the sending rate averaged over
0.2-second intervals, and the dashed line shows the sending rate av-
eraged over one-second intervals. At the bottom of each graph is a
mark for each packet drop. This loss pattern is designed to ﬁt well
with TFRC’s mechanism of averaging the loss rate over roughly
six successive loss intervals, so that TFRC maintains a steady esti-
mation of the packet loss rate even with this bursty loss pattern.
As Figure 17 shows, TFRC in this environment is considerably
smoother than TCP(1/8), and at the same time achieves a slightly
higher throughput.
In contrast, the more bursty loss pattern in Figure 18 is de-
signed to bring out the worst in TFRC in terms of both smooth-
ness and throughput. These simulations use a repeating loss pattern
of a six-second low-congestion phase where every 200th packet is
dropped, followed by a one-second heavy-congestion phase where
every fourth packet is dropped. The heavy-congestion phase is de-
signed to be just long enough to include six loss intervals, so that
TFRC loses all memory of the earlier low-congestion period. In
contrast, the low-congestion phase is designed to include only three
or four loss intervals, not enough to totally supplant the memory
of the heavy-congestion phase. The consequence is that, for this
scenario, TFRC performs considerably worse than TCP(1/8), and
indeed worse than TCP(1/2), in both smoothness and throughput.
Figure 18 explains why TFRC performed badly in Figure 7, com-
peting against TCP for a scenario with oscillating bandwidth with
a period of four to eight seconds. In Figure 18, TFRC performs
worse relative to TCP than it does in Figure 7. This suggests that
the greatest difference between TCP and TFRC throughput occurs
not when competing with a square-wave CBR source, but with a
CBR source with short ON times and longer OFF times, giving
relatively short periods of high congestion.
An equation-based congestion control mechanism other than
TFRC, with a different algorithm for estimating the loss rate, would
require a different loss pattern to illustrate its worst performance,
but we would conjecture that any equation-based mechanism will
have a corresponding loss pattern that exploits the weaknesses of
the loss estimation algorithm, and for which the equation-based
mechanism will perform badly relative to TCP and to TCP(1/8).
Figure 19 shows IIAD and SQRT congestion control with the
same mildly bursty loss pattern as in Figure 17. Because IIAD re-
duces its window additively and increases its window slowly when
bandwidth becomes available, it achieves smoothness at the cost of
throughput, relative to SQRT.
5. Conclusion
The inappropriateness of TCP’s AIMD for certain classes of ap-
plications, including some streaming media and multicast, has mo-
tivated the development of alternate slowly-responsive congestion
control mechanisms governed by the TCP-compatibility require-
ment. However, this requirement is based on a static notion of
throughput under a steady-state loss rate. Internet conditions are
dynamic, which leads us to ask if the various proposed SlowCC
TCP-compatible algorithms are compatible under dynamic condi-
tions as well. This question is particularly important as there is
some justiﬁed scepticism in the community about the sufﬁciency
of the static requirement in practice.
We evaluated several recent proposals for SlowCC algorithms,
including the equation-based TFRC, AIMD-based mechanisms
with different constants from TCP, binomial algorithms, and RAP
(a rate-based variant of TCP AIMD). We consider several per-
)
c
e
s
2
0
B
K
/
.
(
t
u
p
h
g
u
o
r
h
T
)
c
e
s
.
2
0
B
K
/
(
t
u
p
h
g
u
o
r
h
T
140
120
100
80
60
40
20
0
140
120
100
80
60
40
20
0
flow 0, 0.2 sec bins
1 sec bins
drops
0
2
4
6
8
10
Time
12
14
16
18
20
flow 0, 0.2 sec bins
1 sec bins
drops
0
2
4
6
8
10
Time
12
14
16
18
20
Figure 19: IIAD (top) and SQRT (bottom) with a mildly bursty
loss pattern.
including persistent packet loss rates,
formance metrics,
long-
and short-term fairness properties, bottleneck link utilization, and
smoothness of transmission rates. We ﬁnd that most of the TCP-
compatible algorithms we studied appear to be safe for deployment;
even the more slowly responsive ones can be made to avoid caus-
ing the network to go into persistent overload persistent loss rates
on sudden bandwidth reductions by incorporating a self-clocking
mechanism based on packet conservation. However, we also ﬁnd
that in return for smoother transmission rates, slowly-responsive al-
gorithms lose throughput to faster ones (like TCP) under dynamic
network conditions. Fortunately, this does not detract from their
deployability because they do not take throughput away from the
deployed base of TCP connections. We hope that these ﬁndings
will help overcome some of the scepticism surrounding the behav-
ior of slowly-responsive congestion control algorithms and move
the Internet from an “only-TCP” paradigm to a TCP-compatible
paradigm where multiple congestion control algorithms co-exist.
6. References
[1] ALLMAN, M., BALAKRISHNAN, H., AND FLOYD, S. Enhancing
TCP’s Loss Recovery Using Limited Transmit. Internet Engineering
Task Force, January 2001. RFC 3042.
[2] BANSAL, D., AND BALAKRISHNAN, H. Binomial Congestion
Control Algorithms. In Proceedings of the Conference on Computer
Communications (IEEE Infocom) (Anchorage, AK, April 2001),
pp. 631–640.
[3] CHIU, D.-M., AND JAIN, R. Analysis of the Increase and Decrease
Algorithms for Congestion Avoidance in Computer Networks.
Computer Networks and ISDN Systems 17 (1989), 1–14.
[4] FLOYD, S. Congestion Control Principles. Internet Engineering Task
Force, September 2000. RFC 2914.
[5] FLOYD, S., AND FALL, K. Promoting the Use of End-to-End
Congestion Control in the Internet. IEEE/ACM Trans. on Networking
7, 4 (Aug. 1999), 458–472.
[6] FLOYD, S., HANDLEY, M., PADHYE, J., AND WIDMER, J.
Equation-Based Congestion Control for Unicast Applications. In
SIGCOMM Symposium on Communications Architectures and
Protocols (Stockholm, Sweden, August 2000), pp. 43–56.
[7] FLOYD, S., HANDLEY, M., PADHYE, J., AND WIDMER, J.
Equation-Based Congestion Control for Unicast Applications: The
Extended Version. Tech. Rep. TR-00-03, International Computer
Science Institute, March 2000. Available from
http://www.aciri.org/tfrc/.
[8] FLOYD, S. AND HANDLEY, M. AND PADHYE, J. A Comparison of
Equation-Based and AIMD Congestion Control, May 2000.
Available from http://www.aciri.org/tfrc/.
[9] HANDLEY, M., PADHYE, J., FLOYD, S., AND WIDMER, J. TCP
Friendly Rate Control (TFRC): Protocol Speciﬁcation, May 2001.
draft-ietf-tsvwg-tfrc-02.txt, Internet-Draft,
work-in-progress.
[10] JACOBSON, V. Congestion Avoidance and Control. In SIGCOMM
Symposium on Communications Architectures and Protocols
(Stanford, CA, Aug. 1988), pp. 314–329. An updated version is
available from
ftp://ftp.ee.lbl.gov/papers/congavoid.ps.Z.
[11] MAHDAVI, J., AND FLOYD, S. TCP-Friendly Unicast Rate-Based
Flow Control. Available from http://www.psc.edu/
networking/papers/tcp_friendly.html, January 1997.
[12] ns-2 Network Simulator. http://www.isi.edu/nsnam/ns/,
2001.
[13] OTT, T., KEMPERMAN, J., AND MATHIS, M. The Stationary
Distribution of Ideal TCP Congestion Avoidance. In DIMACS
Workshop on Performance of Realtime Applications on the Internet
(November 1996).
[14] PADHYE, J., FIROIU, V., TOWSLEY, D., AND KUROSE, J.
Modeling TCP Throughput: A Simple Model and its Empirical
Validation. In SIGCOMM Symposium on Communications
Architectures and Protocols (Vancouver, Canada, Aug. 1998),
pp. 303–314.
[15] RAMAKRISHNAN, K., AND FLOYD, S. A Proposal to Add Explicit
Congestion Notiﬁcation (ECN) to IP. Internet Engineering Task
Force, Jan 1999. RFC 2481.
[16] REJAIE, R., HANDLEY, M., AND ESTRIN, D. RAP: An End-to-end
Rate-based Congestion Control Mechanism for Realtime Streams in
the Internet. In Proceedings of the Conference on Computer
Communications (IEEE Infocom) (New York, NY, 1999),
pp. 1337–1345.
[17] RHEE, I., OZDEMIR, V., AND YI, Y. TEAR: TCP Emulation at
Receivers—Flow Control for Multimedia Streaming. Tech. rep.,
NCSU, April 2000. Available from http://www.csc.ncsu.
edu/faculty/rhee/export/tear_page/.
[18] The TCP-Friendly Web Page. http:
//www.psc.edu/networking/tcp_friendly.html.
[19] YANG, Y., KIM, M., AND LAM, S. Transient Behaviors of
TCP-friendly Congestion Control Protocols. In Proceedings of the
Conference on Computer Communications (IEEE Infocom)
(Anchorage, AK, April 2001), pp. 1716–1725.
[20] YANG, Y., AND LAM, S. General AIMD Congestion Control. Tech.
Rep. TR-2000-09, University of Texas at Austin, May 2000.
Available from http://www.cs.utexas.edu/users/lam/
NRL/TechReports/.
Appendix
A. Modeling the Role of Timeouts
As mentioned earlier, TCP’s retransmit timeouts are a key com-
ponent of TCP congestion control, and the relative fairness of
SlowCC congestion control mechanisms relies on their ability to
take into account TCP’s timeouts as well as the AIMD mechanisms.
Here, we show that the exponential backoff of TCP’s retransmit
timers can in fact be viewed as an extension of the AIMD model to
an environment with sending rates less than one packet per RTT.
)
T
T
R
/
s
t
k
P
t
(
e
a
R
g
n
d
n
e
S
i
1000
100
10
1
0.1
0.01
0.001
0.001
pure AIMD
Reno TCP
AIMD with timeouts
0.01
0.1
Loss Rate P
Figure 20: The throughput equation for models with and with-
out timeouts.
The dashed line labeled “Reno TCP” in Figure 20 shows the TCP
throughput equation [14] taking into account the role of retrans-
mit timeouts in Reno TCP without delayed acknowledgments. The
solid line labeled “pure AIMD” in Figure 20 shows the through-
put equation for a pure AIMD scheme without timeouts [5]. The
solid line is derived from a simple deterministic model where, for
a packet drop-rate , one in every 1= packets are dropped, caus-
ing the sending rate to be halved. This “pure AIMD” model of a
sending rate of about1:5= packets/RTT does not apply to TCP
for a sending rate less than one packet per round-trip time (i.e., for
packet drop rates greater than about one-third).
To apply the AIMD model to sending rates less than one packet
per RTT, we assume that only complete packets can be sent, and
that when the sending rate is less than one packet per RTT, the
sender waits for a complete inter-packet interval before sending a
new packet. In this deterministic model with the available band-
width less than one packet/RTT, the sending rate can be determined
as follows. Deﬁne stages such that at state 0 the sending rate is one
packet/RTT, and at state i the sending rate is 1=2i packets/RTT, or
one packet every 2i RTTs. At any stage if a packet is acknowl-
edged the sender returns to stage 0, and immediately sends one
packet. Otherwise, the sender halves its sending rate, waiting 2i1
RTTs before retransmitting a packet. This halving of the sending
rate in response to a packet drop is then equivalent to an exponential
backoff of the retransmit timer.
Under this model of transmission, let the steady-state packet
drop rate be  = 
1 . Thus, the sender sends   1 packets over
21 1 round-trip times, with all but the last packet dropped. This
gives a steady-state sending rate in this model of:
1
1 
1
1    1
  1
21   1
=
2
packets/RTT. For example, for  = 1=2, we have  = 1, and the
sender sends two packets every three round-trip times, for a steady-
state sending rate of 2=3 packets/RTT. This is shown in Figure 20
with the short dashed line labeled “AIMD with timeouts”. We note
that this analysis is only valid for packet drop rates of 50% or more,
while the “pure AIMD” analysis can apply to packet drop rates up
to 33%. The “AIMD with timeouts” line gives an upper bound
for the analytic behavior of TCP, while the “Reno TCP” line gives
a lower bound. The behavior of TCPs with Selective Acknowl-
edgements, Limited Transmit [1], and ECN should fall somewhere
between the two lines.