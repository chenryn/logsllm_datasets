mulations and one subsequent check instead of two expensive
checks.
Using accumulators instead of direct checks is beneﬁcial
for performance: accumulation requires only two additions
instead of several divisions and branches. Moreover, it does
not decrease the error detection capabilities of Δ-encoding,
because the addition operation propagates any erroneous value
to the accumulator. One last non-obvious advantage is that
accumulations are less susceptible to the “who guards the
guardians” problem: a check could be erroneously skipped due
to a single CPU fault, but quietly skipping both accumulator
updates is highly improbable.
D. Fault Coverage
Δ-encoding provides very high fault coverage. Here we
explain how our approach covers all symptoms from the
symptom-based fault model described in Section III. We
provide a quantitative analysis only for the case of modiﬁed
operand due to lack of space; other symptoms can be analyzed
in a similar way.
Modiﬁed operand AN codes guarantee that, given a modiﬁed
operand fault, the probability of a SDC is 1/A ([11]).
In duplicated instructions, given that a random fault
(corrupting a random number of bits) affected both copies
of the operand, the probability of a SDC is 1/2n, where
n is the number of bits of the operand.
With Δ-encoding, given that a fault affected both copies
of the operand, a SDC may happen only if (1) the ﬁrst
copy is a code word and (2) the second copy corresponds
to the ﬁrst copy (i.e., produces the same original value
when decoded). Combining these requirements together
and taking into account that AN codes double the number
of bits in operands, we get the probability of a SDC equal
to
1
A · 22n.
Exchanged operand Since Δ-encoding performs each oper-
ation twice, SDC happens only if two exchanged operand
faults substitute two correct copies with two incorrect but
valid copies. The probability of such chain of events is
negligible.
Faulty operation Two copies of data are encoded differently
(with A1 and A2) in Δ-encoding; thus, two executions of
a faulty operation would work on different operands and
would fail in different ways. This means that the probabil-
ity that two faulty operations produce two corresponding
code words is negligible.
Exchanged operation Since Δ-encoding performs each op-
eration twice, two copies of the operation must be sub-
stituted by two exactly the same non-intended operations.
This scenario is highly improbable.
Lost update In Δ-encoding, two store operations are used
to update two copies of data; thus, two stores must be
omitted to result in a lost update. Such scenario has
negligible probability.
As this analysis shows, Δ-encoding provides high fault
coverage for all types of faults. Notice that modiﬁed operand
faults happen more frequently than other types, because the
underlying hardware errors – memory and CPU register bit-
ﬂips – occur with perceptible regularity. But other types of
faults, however improbable they are, must also be accounted
for in safety-critical systems.
The combination of duplicated instructions, AN codes and
heuristic accumulation of checks also provides high guarantees
against intermittent and permanent errors. For example, using
duplicated instructions alone, it is possible that both copies
of a variable are stored in the same physical CPU register
which experiences a stuck-at fault, and thus the fault remains
undetected. In Δ-encoding, a stuck-at fault in a register results
in an invalid word (with high probability).
Interestingly, the approach of duplicated instructions cannot
detect permanently faulty operations. If the same inputs are
fed to two executions of a faulty operation, both executions
1818
Transformer
foo.c
Δ-encode
foo_enc.c
Compiler
compile & 
link
executable
bar.c
Fig. 2: Δ-encoding implementation.
produce the same incorrect output. In Δ-encoding, the two
copies of data are diverse, leading to two different incorrect
results. Thus, Δ-encoding can detect permanent faults which
would lead to a SDC in the case of simple duplicate execution.
V.
IMPLEMENTATION
We implemented Δ-encoding as a source-to-source C
transformer in Python (see Fig. 2). Original C programs
are encoded at the level of an Abstract Syntax Tree (AST)
built by PycParser5. Our transformer walks through the AST,
substituting all inputs and constants by encoded values and all
original C operators by the corresponding encoded operations.
The transformer also produces function-wrappers to perform
libc/system calls from encoded source (e.g., malloc()) and vice
versa.
Δ-encoded programs preserve the original code structure,
i.e., original control ﬂow as well as variable and function
names. This is possible because our transformer does not
employ any code optimizations, working as close to the
original source as possible. Preserving the original information
greatly facilitates debugging and manual changes in encoded
programs.
The Δ-encoded code emitted by the transformer does not
rely on a speciﬁc compiler and is not inﬂuenced by compiler
optimizations. The structure of Δ-encoding itself prevents the
compiler from optimizing duplicate instructions away6. As
an example, consider the decoding operation from Listing 6:
the compiler has no knowledge of inherent interdependency
between two encoded copies and cannot ﬁgure out that the
two ways of decoding produce the same original value.
The Δ-encoded code can be intermingled with unencoded
the programmer can manually add calls to
sources. First,
unencoded functions in the emitted encoded code (e.g., adding
printf() calls for debug purposes). Second, the transformer gen-
erates wrappers for unencoded functions used by the encoded
code (e.g., libc functions such as malloc() and free()).
A. Encoding Data
Since Δ-encoding expands the original domain of values to
accommodate all encoded values, our implementation restricts
all integer variables to be at most 48 bits wide. We chose
A1 = 8193, A2 = 8191 such that the encoded values never
exceed the 64-bit range, since the maximum encoded value
(248 − 1) · 8193 is less than 64 bits wide.
5https://github.com/eliben/pycparser
6Compiler optimizations are a constant threat for fault-tolerant high-level
transformations, since they can be very efﬁcient at eliminating code and data
redundancy. Some techniques even require all compiler optimizations to be
disabled, as in [21].
In general, original integer types are limited by at most
32-bit data types. 64-bit types are also supported, but the
original program must guarantee that the values never exceed
the 48-bit bound. This is the case for pointer types: on
modern 64-bit systems, pointers are 64 bits wide but virtual
address formats use only the 48 low-order bits [22]. Therefore,
our implementation supports pointer types on current 64-bit
architectures.
The Δ-encoding transformer implements two copies of
variables as two-item arrays. For example, int32 t n is trans-
formed into int64 t n enc[2]. This implementation is not
optimal with respect to fault detection, because the two copies
of the variable are adjacent
to each other, and one fault
changing bits in-between can corrupt both copies. A better
implementation would require separate “shadow” stack and
heap for second copies of data. Unfortunately, such separation
would require compiler support and thus is impossible in our
current C-to-C transformer approach; we leave it as future
work.
One interesting feature of Δ-encoding is the prohibition
of silent
integer over- and underﬂow. AN codes modulo
arithmetic is not isomorphic to the original modulo arithmetic,
e.g., 232 · A would not wrap to 0; Δ-encoding would therefore
require expensive checks to support integer overﬂow behavior.
Wishing to keep Δ-encoded programs as fast as possible,
we disallow all silent under- and overﬂows. If a programmer
wishes to support such wraparounds, she is required to imple-
ment them explicitly. Our decision is also partially justiﬁed by
security reasons: many integer overﬂows are unintended and
can be a source of vulnerabilities [23]. In Δ-encoding, silent
integer over- and underﬂows raise a run-time error.
the compiler has full right
in several occasions we noticed that
There is one subtle issue when encoding local loop vari-
ables. Modern compilers are particularly good at optimizing
loops;
the compiler
removed the second copy of a loop variable, weakening the
protection. Indeed,
to perform
such an aggressive optimization:
it knows an initial value
and the complete data ﬂow of a loop variable and ascertains
uselessness of the second copy. To prevent
the compiler
from removing the variable, we insert inline pseudo-assembly
that clobbers both copies of the loop variable. This example
illustrates how careful one should be when enabling fault
tolerance without changing the compiler behavior.
B. Encoding Operations
Some of the encoded operations were already described
in Section IV-B. The ﬁnal implementations follow closely the
examples from Listings 5 to 9. The Δ-encoding transformer
provides the complete set of encoded C operators, including
arithmetic, comparison, logical, bitwise, member and pointer
operators, casts, etc.
All encoded operations are inlined in the ﬁnal executable.
This enables the compiler to choose the speciﬁc computation
path. For example, the decode() operation from Listing 6 will
be inlined two times in the code (ﬁrst with A1 and then with
A2): ﬁrst time stripped to Line 3, second time – to Line 5.
The code emitted by the Δ-encoding transformer must be
compiled with the SSE extensions disabled. Otherwise the
1919
compiler can glue two move-to-memory instructions of adja-
cent data copies into one SSE-move. If a hardware error affects
this SSE-move, both copies of data are affected, which can
lead to undetected SDCs. This ﬂaw in our data representation,
where variables are encoded as two-item arrays, was already
described in the previous subsection. Note that if copies of
data would be completely decoupled, SSE extensions could
be enabled again.
The AN codes approach is not able to detect incorrect
branching resulting from faults in branching logic. Indeed, the
decision of which branch to take is based on the ﬂag bit values
of a status register. Flag bits cannot be encoded, and a single
bit-ﬂip can lead to an incorrect branch. Fortunately, duplicated
instructions suggest a way to detect errors in branching logic:
our transformer inserts a “shadow” branch for each original
branch. The original branch is encoded to work on the ﬁrst
copy of data, the “shadow” branch works on the second copy.
If the branching decisions differ in the two branches, an error
is detected.
C. Accumulation of Checks
The idea of accumulation was deﬁned in section IV-C; here
we describe some implementation issues.
As explained previously, accumulations are a low-overhead
substitute for checks, such that the frequency of the checks
themselves is signiﬁcantly decreased. In fact, our experiments
showed that checks can be done in the very end of com-
putation, and all intermediate steps are sufﬁciently protected
via accumulations. In the ﬁnal implementation, we introduced
checks only at the end of encoded computations and in wrapper
functions.
In its turn, the frequency of accumulations can be tuned.
Ideally, data ﬂow analysis must be done to pinpoint critical
places. Currently, we adopt a simple strategy: accumulations
are inserted after each assignment in original C code. This
straightforward technique yields satisfactory results. We leave
comprehensive data ﬂow analysis as future work.
As shown in Listing 10, accumulation corresponds to
one addition operation. Accumulators are 128-bit integers7.
It is tempting to use 64-bit accumulators, but they overﬂow
fast; the accumulation operation would require an additional
overﬂow check. We opted for 128-bit accumulators instead.
Since encoded values can be maximum 64 bits wide, 264
accumulations must happen before the accumulators overﬂow
in the worst case. This number of accumulations is enough for
any conceivable program; overﬂow checks are not required for
128-bit accumulators.
Unfortunately, signed 128-bit addition is much slower than
its 64-bit counterpart on modern CPUs. It requires one sign
extension, one 64-bit addition and one 64-bit add-with-carry
– 3 operations in total. Our performance evaluation highlights
this slowdown.
Interestingly, it can be meaningful to remove all accumula-
tions completely and perform only one check in the very end of
the encoded computation. Remember that Δ-encoding (ideally)
7We use int128 t data type provided by gcc. Under the hood, this data type
is treated as two 64-bit integers.
propagates all hardware errors to outputs. One can rely on this
property and get rid of all intermediate accumulations, in the
hope that any error will be detected by the ﬁnal check. Our
evaluation shows that such a trade-off between performance
and fault tolerance is acceptable in some scenarios.
2) Fault Injection Experiments: For fault injection cam-
paigns, we used Intel Pin9 and the BFI plug-in10. BFI is able
to inject random faults and was used in other research [25].
We improved BFI to also inject stuck-at intermittent/permanent
faults.
Moreover, accumulations and checks could be done in
parallel to the program’s execution. The program could send
encoded values for accumulation/check asynchronously and
immediately continue execution. Accumulation/check func-
tionality could run on another CPU core or in the dedicated
hardware module. If the system allows certain latency between
the actual corruption of data and its detection, this parallel
approach could be used. For example, automotive embedded
systems allow for such latency and are usually equipped with
a special hardware watchdog8; it would be reasonable to add
the accumulation/check functionality in the watchdog and run
the encoded program on the main CPU.
VI. EVALUATION
In this section, we evaluate a set of programs encoded with
the Δ-encoding transformer in terms of performance and fault
coverage. The set of programs under test consists of several
microbenchmarks and two use cases. Microbenchmarks give
an estimation of the provided fault coverage versus perfor-
mance slowdown. The ﬁrst use case is taken from the ﬁeld
of distributed systems and exempliﬁes the so-called trusted
modules – small safety-critical parts of applications which
need to be robust against hardware errors. The second use
case comes from the ﬁeld of automotive embedded systems
and exempliﬁes X-by-wire systems, where a program processes
data from sensors and controls actuators such as car brakes.
A. Methodology
1) Performance Experiments: All performance experi-
ments were run on a computer with Intel Core i5-3470 CPU
(Ivy Bridge architecture), 4GB RAM, L1, L2 and L3 caches
of 32KB, 256KB and 6MB. All programs and their variants
(including native) were compiled using gcc version 4.8.2, with
all optimizations enabled except for SSE (ﬂags -O3 -mno-sse).
For all programs, execution time was calculated as the number
of cycles to perform the processing of data. All programs were
run for at least one second, with predeﬁned inputs. The ﬁnal
results are an average of 5 runs. All performance ﬁgures show
a slowdown compared to the native execution.
Each Δ-encoded program was tested in 3 variants: with
128-bit accumulation, without accumulation, and with parallel
accumulation (simulation). These variants were described in
Section V-C. The variant with 128-bit accumulation (Δ-full)
provides full-ﬂedged protection from hardware errors. The
variant with no accumulation (Δ-stripped) reduces fault cov-
erage and increases performance, and can be an appropriate
trade-off for some scenarios. Finally, “parallel accumulation”
(Δ-parallel) is a simulation of hardware-implemented accu-
mulation; we simulate it by moving encoded values to a
predeﬁned memory address instead of adding them to the