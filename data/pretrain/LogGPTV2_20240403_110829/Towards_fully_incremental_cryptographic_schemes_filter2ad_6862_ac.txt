Pi ← pad(Bi);
P ← P0||P1|| . . .||P|u|−1;
t ← Π.T (K(cid:48), P );
return (u, t);
(a) Tranformation
Input: The
cryptographic
form (u, t), a key K(cid:48)(cid:48)
P ← Π.D(K(cid:48)(cid:48), t);
for i = 0 to |u| − 1 do
Bi ← Pi[1, ui];
D ← B0||B1|| . . .||B|u|−1;
return D;
(b) Conjugate (Decryption of
an encryption scheme)
Input: A document D, the crypto-
graphic form (u, t), a key K(cid:48)(cid:48)
m ← 1;
for i = 0 to |u| − 1 do
Pi ← pad(D[m, m+ui−1]);
m = m + ui;
P ← P0||P1|| . . .||P|u|−1;
if Π.V(K(cid:48)(cid:48), P, t) = P then
else
return D;
return ⊥;
Input: A distribution φ, a cryp-
tographic form (u, t), a modi-
ﬁcation operation M(cid:48) ∈ Mb,
the partition D, a key K(cid:48)
(M, u(cid:48)) ← T op(φ, M(cid:48), D, u);
(x1, x2, x3, x4) ← M;
t(cid:48) ← Π.I(K(cid:48), t, M );
v ← (u(cid:48), (ui)i=x3..|u|−1);
v ← ((ui)i=0..x2 , v);
return (v, t(cid:48));
(d) IncUpdate
(c) Conjugate (Veriﬁcation of a
signature scheme)
Figure 2: algorithms of Ξ
length blocks Bi and ﬁnally concatenates all the consecutive blocks
Bi to reconstruct the document D.
The algorithm 2c describes a veriﬁcation algorithm of a signa-
ture scheme. It divides D thanks to the predeﬁned length partition
u, pads each variable length blocks into ﬁxed length blocks and
concatenates all of these to obtain P . The validity of the signa-
ture t when compared to the string P is then checked-out. If this
succeeds, the document D is returned, otherwise ⊥ is returned.
The algorithm 2d describes the incremental update. It converts a
byte-wise modiﬁcation operation into a block-wise operation. The
sequence of length u(cid:48) which is retreived correponds to the partial
repartition which takes into account the modiﬁcation. Excluding
indices x2 and x3 are then retreived: (i) x2 corresponds to the in-
dex up to which the original partition u is unchanged; (ii) in the
same way, x3 corresponds to the index from which the partition is
unchanged. The cryptographic form t is updated in t(cid:48) following
the block-wise operation. The length partition u is updated in v
(between excluded indices x2 and x3). Then the updated crypto-
graphic form returned is (v, t(cid:48)).
3.6 Efﬁciency analysis
Empirical analysis. The choice of the law φ and its parameters
depends certainly on settings of the targeted application. At ﬁrst
glance, one could choose parameters that limit the expansion of
the cryptographic form without addressing the effect on the update
algorithm and the conjugate/tranformation algorithm complexities.
To get an overview of the running time of an update, we have done
simulations by assuming the use of a 16-byte block-based incre-
mental scheme. Such use of block-size corresponds certainly to an
incremental symmetric algorithm, such as for instance rECB [4]
instanciated with AES. We are interested in estimation of perfor-
mances of the extended block-based incremental algorithm. The
statistical observations (Figures 3a, 3b) show the average number of
blocks to insert in function of the size of the data to insert, due to the
translation of an operation M(cid:48) ∈ Mb into an operation M ∈ MB.
Three discrete distributions (uniform, binomial and geometric)
may be suitable for the variable-length ui. One can notice that
for an insertion, the average running time of the update algorithm
seems to be linear in the number of bytes to insert. Besides, as
one might expect, the ranges of optimality are different depending
on the chosen parameters. For example, when size ui follows a
binomial distribution, average results of Figure 3b shows that for
inserts of less than 3 mega-bytes, the number of blocks inserted
seems more interesting when P=0.75 compared to P=0.98.
Since the choice of the parameters of the probability distribution
used for a given document is deﬁnitive, we must know the behav-
ior of the application before making it, particularly regarding the
statistics on the sizes of insertions if the goal is to optimize the com-
putational resources. Indeed, for insertion concerning in average
small sized data, a lower ﬁll rate for the input blocks of the block-
based incremental algorithm will correspond to a lower number
of blocks inserted. Storage resources can also be optimized when
we achieve a high ﬁll rate, but at the counterpart of slower perfor-
mances for insertions of small sized data. These storage ressources
are always a concern, whatever the type of the cryptographic al-
gorithm is. Indeed, more speciﬁcally for incremental encryption,
a low ﬁll rate corresponds to a large padding. Secondly, for in-
cremental and tamper-proof signatures based on non-deterministic
skip list or oblivious tree, the number of labeled nodes increases
when the ﬁll rate decreases. And ﬁnally, the list of variable lengths
u takes more memory space when the ﬁll rate is low.
(a) ∀ i ui ∼ U ([1, N ])
(b) ∀ i ui ∼ B(N − 1, p) + 1
Figure 3: Insertion cost
such that Sn = (cid:80)n
i=1 Xi and Tm = (cid:80)m
Modelization. More precisely, let (Xi)i≥1 and (Yi)i≥1 be the se-
random variables taking values in {1, . . . , N(cid:48)}
quences of i.i.d.
according to the distribution φ. We set the random walks Sn, Tm
i=1 Yi and the random
subset Z of N2 such that Z = {(n, m) ∈ N2 ; Sn − Tm = c}
where c ∈ N. Note that c represents the number of contiguous
bytes to insert. If (n, m) and (n(cid:48), m(cid:48)) are distinct in Z then ei-
ther n  c then
7:
Y
c ← c + Y
8:
go to step 2
9:
φ← {1, . . . , N(cid:48)}
We notice also the followings:
• If c0 > N(cid:48), according to the Wald’s equation [11] the aver-
age number of consecutive executions of the step 3 is upper
bounded by c0/E(X), after which we have c ≤ N(cid:48).
• If c0 ≤ N(cid:48), whenever step 1 (or 7) is executed we have
c ≤ N(cid:48) and then a non-zero probability P (x = c) (or
P (y = X − c) respectively) to terminate. Let us assume that
φ is a uniform law. If we denote d1 the total number of ran-
dom draws (d1 = n1 + m1) then E(n1) ≤ E(d1). It turns
N(cid:48) ,
out that d1 follows a geometric law of parameter p = 1
therefore E(n1) ≤ N(cid:48). Upper bounds are possible for other
cited distributions with a pessimistic approach.
Assuming a uniform distribution and c0 > N(cid:48), let d0 denote the
number of random draws needed to satisfy the predicate c ≤ N(cid:48)
for the ﬁrst time and d1 the number of random draws needed to
terminate the algorithm since the ﬁrst satisfaction of this predicate.
So, we can upper bound E(n1) as follows:
E(n1) ≤ E(d0) + E(d1) ≤ 2c0
1 + N(cid:48) + N
(cid:48)
.
2c0
In more general terms, considering that an insertion can take
place inside a part, we can upper bound the ﬁrst moment (mean)
1+N(cid:48) + N(cid:48) +
of the distribution of n1 by an afﬁne function
for inserting a
2. Therefore the average running time AT inc
bytestring δ in the extended scheme could be described as a
Π (1,|D| /m) where
function AT inc
Π (1,|D| /m) is the running time for inserting one block in the
T inc
block-based incremental scheme and m = E(X).
Ξ (δ,|D|) = (a|δ| + b)T inc
(cid:109)
(cid:108) log N(cid:48)
Ξ
8
The average storage space required for the sequence u de-
pends on the choice of the distribution and is upper bounded by
|D|+N(cid:48)
. That represents, even for a basic distribution
E(X)
such as U([1, N(cid:48)]), a small storage overhead.
For the sake of simplicity and clarity of our subject, we have
considered that blocks lengths are described in a simple sequence
u. With such a sequence a byte index is reached in O(|u|) add
operations. This could be felt for large size documents. The best
solution is to partially accumulate the lengths and organize them
into a self-balancing (and non-deterministic to conserve the perfect
privacy property) data structure, in which case an access to a byte
index, an update or an adding of a length value are all done in
O(log |u|) add operations.
4. SECURITY AND CONCLUSIONS
Whether we consider an updated partition or an original one,
we see a sequence of lengths drawn from a discrete probability
distribution, except the last one (due to the termination condition
in the algorithm). In either case, this term depends on the docu-
ment size and the summation of all previous drawn terms. Assum-
ing that the underlying block-based incremental scheme is obliv-
ious, the outputs of Ξ.IncU pdate and Ξ.T ranf ormation are
still perfectly indistinguishable. Concerning indistinguishability of
ciphertexts/updates (resp. unforgeability), the security of our ex-
tended block-based incremental encryption scheme (resp. signature
scheme) can be reduced in a straightforward way to the security of
the underlying block-based incremental encryption scheme (resp.
signature scheme). Detailed proofs are avalaible in the full paper.
In this paper, we have shown that we can make an incremen-
tal byte-wise cryptographic scheme practical and perfectly private
while conserving a good efﬁciency for many applications based on
workﬂow of slight changes within documents. This opens doors to
new schemes based on non-deterministic modes of operation which
will be presented in a companion paper.
5. REFERENCES
[1] Mihir Bellare, Oded Goldreich, and Shaﬁ Goldwasser.
Incremental cryptography: The case of hashing and signing.
In CRYPTO, 1994.
[2] Mihir Bellare, Oded Goldreich, and Shaﬁ Goldwasser.
Incremental cryptography and application to virus
protection. In Proc. of the 27th Ann. ACM Symp. on the
Theory of Computing, pages 45–56. ACM Press, 1995.
[3] Mihir Bellare and Daniele Micciancio. A new paradigm for
collision-free hashing: incrementality at reduced cost. In In
Eurocrypt97, pages 163–192. Springer-Verlag, 1997.
[4] Enrico Buonanno, Jonathan Katz, and Moti Yung.
Incremental unforgeable encryption. In FSE’01, pages
109–124, 2001.
[5] Reouven Elbaz, David Champagne, Catherine H. Gebotys,
Ruby B. Lee, Nachiketh R. Potlapally, and Lionel Torres.
Hardware mechanisms for memory authentication: A survey
of existing techniques and engines. Transactions on
Computational Science, 4:1–22, 2009.
[6] Marc Fischlin. Lower bounds for the signature size of
incremental schemes. In In 38th Annual Symposium on
Foundations of Computer Science, pages 438–447, 1997.
[7] Bok-Min Goi, M. U. Siddiqi, and Hean-Teik Chuah.
Incremental hash function based on pair chaining & modular
arithmetic combining. In INDOCRYPT, pages 50–61, 2001.
[8] Michael T. Goodrich and Roberto Tamassia. Efﬁcient
authenticated dictionaries with skip lists and commutative
hashing. Technical report, TECH. REP., JOHNS HOPKINS
INFORMATION SECURITY INSTITUTE, 2001.
[9] Yan Huang and David Evans. Private editing using untrusted
cloud services. In ICDCS Workshops, pages 263–272, 2011.
[10] Daniele Micciancio. Oblivious data structures: Applications
to cryptography. In In Proceedings of the 29th Annual ACM
Symposium on the Theory of Computing, pages 456–464.
ACM Press, 1997.
[11] Abraham Wald. Some generalizations of the theory of
cumulative sums of random variables. The Annals of
Mathematical Statistics, 16(3):pp. 287–293, 1945.
510