Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:32:54 UTC from IEEE Xplore.  Restrictions apply. 
5663
0 :movrbx, 137 :  mov[rax], rbx10:  lear8, [rip+8]17:  movedx, [r8]20:  addrdx, r823:  jmprdx25:  .int429:  movr9, [rax]32:  addr8, r935:  jmpr838:  movrax, 6045:  syscallentrypoint0 :jmp907 :  hlt10:  hlt17:  hlt20:  hlt23:  hlt25:  .int429:  hlt32:  hlt35:  hlt38:  hlt45:  hlt90 : [afltrampoline]100:movrbx, 13107: mov[rax], rbx110: lear8, [rip-92]117: movedx, [r8]120: addrdx, r8123: jmprdx0 :jmp907 :  hlt10:  hlt17:  hlt20:  hlt23:  hlt25:  .int429:  jmp12532:  hlt35:  hlt38:  hlt45:  hlt90 : [afltrampoline]100:movrbx, 13107: mov[rax], rbx110: lear8, [rip-92]117: movedx, [r8]120: addrdx, r8123: jmprdx125: [afltrampoline]135: movr9, [rax]138: addr8, r9141: jmpr890 : [afltrampoline]100:movrbx, 13107: mov[rax], rbx110: lear8, [rip-92]117: movedx, [r8]120: addrdx, r8123: jmprdx125: [afltrampoline]135: movr9, [rax]138: addr8, r9141: jmpr8144: [afltrampoline]154: movrax, 60161:syscall0 :jmp907 :  hlt10:  hlt17:  hlt20:  hlt23:  hlt25:  .int429:  movr9, [rax]32:  addr8, r935:  jmpr838:  hlt45:  syscallProb0.00.00.00.00.00.00.10.10.050.010.070.0290 : [afltrampoline]100:movrbx, 13107: mov[rax], rbx110: lear8, [rip-92]117: movedx, [r8]120: addrdx, r8123: jmprdxProb0.00.00.00.00.00.00.10.10.050.010.070.020 :jmp907 :  hlt10:  hlt17:  hlt20:  hlt23:  hlt25:  hlt29:  movr9, [rax]32:  addr8, r935:  jmpr838:  hlt45:  syscall90 : [afltrampoline]100:movrbx, 13107: mov[rax], rbx110: lear8, [rip-92]117: movedx, [r8]120: addrdx, r8123: jmprdxProb0.00.00.00.00.00.00.10.10.050.010.070.020 :jmp907 :  hlt10:  hlt17:  hlt20:  hlt23:  hlt25:  .int429:  movr9, [rax]32:  addr8, r935:  jmpr838:  movrax, 6045:  syscall90 : [afltrampoline]100:movrbx, 13107: mov[rax], rbx110: lear8, [rip-92]117: movedx, [r8]120: addrdx, r8123: jmprdxProb0.00.00.00.00.00.00.10.10.050.010.070.020 :jmp907 :  hlt10:  hlt17:  hlt20:  hlt23:  hlt25:  hlt29:  movr9, [rax]32:  addr8, r935:  jmpr838:  movrax, 6045:  syscall90 : [afltrampoline]100:movrbx, 13107: mov[rax], rbx110: lear8, [rip-92]117: movedx, [r8]120: addrdx, r8123: jmprdxInitialPatchingIncrementalRewritingIncrementalRewritingProbability Analysis& Initial PatchingUnintentional crash at address 123BinaryCleaningNo crashBinaryMutationBinaryMutationIntentional crash at address 38Unintentional crash at address 123LocatingRewritingErrorProbability Recalculation &Incremental Rewriting Intentional crash at address 290 :jmp907 :  hlt10:  hlt17:  hlt20:  hlt23:  hlt25:  .int429:  hlt32:  hlt35:  jmpr838:  jmp12545:  hltProb0.00.00.00.00.00.01.00.070.020.010.00.090 : [afltrampoline]100:movrbx, 13107: mov[rax], rbx110: lear8, [rip-92]117: movedx, [r8]120: addrdx, r8123: jmprdx125: [afltrampoline]135: movrax, 60142: syscall0 :jmp907 :  hlt10:  hlt17:  hlt20:  hlt23:  hlt25:  .int429:  jmp14432:  hlt35:  hlt38:  jmp12545:  hltProb0.00.00.00.00.00.01.00.00.00.00.00.090 : [afltrampoline]100:movrbx, 13107: mov[rax], rbx110: lear8, [rip-92]117: movedx, [r8]120: addrdx, r8123: jmprdx125: [afltrampoline]135: movrax, 60142: syscall144: [afltrampoline]154: movr9, [rax]157: addr8, r9160: jmpr8Case ACase BIntentional crash at address 38Intentional crash at address 290 :jmp907 :  hlt10:  hlt17:  hlt20:  hlt23:  hlt25:  .int429:  jmp12532:  hlt35:  hlt38:  jmp14445:  hlt0 :hlt7 :  hlt10:  hlt17:  hlt20:  hlt23:  hlt25:  .int429:  hlt32:  hlt35:  hlt38:  hlt45:  hltIntentionalcrash at address 0IncrementalRewritingProb0.030.010.00.00.00.00.10.10.050.010.070.020 :hlt7 :  hlt10:  hlt17:  hlt20:  hlt23:  jmprdx25:  hlt29:  movr9, [rax]32:  hlt35:  jmpr838:  movrax, 6045:  hltIntentional crash at address 0ProbabilityRecalculation& IncrementalRewriting Probability Recalculation &Incremental Rewriting 12341234765the crash analyzer, which identiﬁes the new code coverage
indicated by the crash and analyzes the newly discovered code
to collect additional hints for distinguishing data and code. The
hints are passed on to the probability analyzer, which recom-
putes the probabilities and invokes the incremental rewriter to
generate new binaries.
In case three, the execution is terminated by an unintentional
crash (i.e., a crash not caused by hlt). To verify whether the
crash is triggered by some rewriting error, the crash analyzer
notiﬁes the program dispatcher to send a binary that has all
uncertain rewritings removed for execution. If the previous
crash persists, it must be caused by a latent bug in the original
program. Otherwise, the crash is caused by rewriting error. The
crash analyzer further performs delta-debugging to locate the
root cause and repairs it. The repair is passed on as a hint to
the probability analyzer and triggers probabilities updates and
generation of new binaries. In the remainder of this section,
we discuss details of the components.
A. Probability Analyzer
This component computes the probabilities of each address
denoting data or code. Initially (before fuzzing starts),
it
computes the probabilities based on the results of a simple
disassembler that we only use to disassemble at each address
in the binary. During fuzzing, with new observations (e.g.,
indirect call and jump targets) and exposed rewriting errors, it
continuously updates probabilities until convergence. It models
the challenge as a probabilistic inference problem [29]. Specif-
ically, random variables are introduced to denote individual
addresses’ likelihood of being data or code. Prior probabilities,
which are usually predeﬁned constants as in the literature [30]–
[33], are associated with a subset of random variables in-
volved in observable features (e.g., deﬁnition-use relations
that suggest likely code). Random variables are correlated
due to program semantics. The correlations are modeled as
probabilistic inference rules. Prior probabilities are propagated
and aggregated through these rules until convergence using
probabilistic inference algorithms, yielding posterior probabil-
ities. In the following, we explain how we deﬁne the problem
and introduce our lightweight solution.
Deﬁnitions and Analysis Facts. As shown in the top of
Fig. 7, we use a to denote an address, c a constant, and r
a register. The bottom part of Fig. 7 presents the analysis
facts directly collected from the binary. These facts are deter-
ministic (not probabilistic). Inst(a, c) denotes that the c bytes
starting from address a can be encoded as a valid instruction.
ExplicitSucc(a1, a2) denotes the instruction at address a2 is
an explicit successor of the instruction at address a1 along
control ﬂow. RegWrite(a, r) denotes the instruction at a writes
to register r. RegRead denotes the read operation. Str(a, c)
denotes the c bytes starting from address a constitute a
printable null-terminated string.
Initially, STOCHFUZZ disassembles at each address and
collects the analysis facts. It collects more facts than those
in Fig. 7. They are elided due to space limitations.
Fig. 5: Architecture
causing a segfault. The diagnosis and self-correction procedure
is hence invoked (steps 2 - 5 ). Speciﬁcally, the binary cleaning
step 2 removes all the rewritings at uncertain addresses (in
yellow or red shades) and re-executes the program (to the
right of 2 ). The crash at address 123 disappears, indicating
the crash must be induced by a rewriting error. STOCHFUZZ
uses delta debugging and generates two binaries, one with only
25 replaced (i.e., the snippet to the left of 4 ) and the other
with 38 replaced (i.e., the snippet to the left of 5 ). The former
crashes at the same address 123 whereas the latter crashes at
38 (and hence an intentional crash). As such, STOCHFUZZ
determines that the rewriting of address 25 is wrong and ﬁxes
it by marking it as “certainly data” (i.e., with probability
1.0) in the version to the right of
5 . This new hint leads
to probability updates of other addresses (e.g., 29 and 32).
The procedure continues and eventually all addresses have
certain classiﬁcation (i.e., all in green shade) and the program
is properly rewritten. (cid:3)
III. SYSTEM DESIGN
the probability analyzer,
The architecture of STOCHFUZZ is shown in Fig. 5. It
consists of ﬁve components:
the
incremental and stochastic rewriter, the program dispatcher,
the execution engine, and the crash analyzer. The probability
analyzer computes a probability for each address in the given
binary to indicate the likelihood of the address denoting a data
byte. The rewriter rewrites the binary in different forms by
sampling based on the computed probabilities. The program
dispatcher selects a rewritten version to execute, either ran-
domly for a normal execution request or strategically for root
cause diagnosis. The execution engine, a variant of AFL [3],
executes a given binary and monitors for crashes. The crash
analyzer triggers incremental rewriting when it determines a
crash is intentional; otherwise, it analyzes the root cause and
automatically repairs it if the cause is a rewriting error.
STOCHFUZZ has three typical workﬂows. Case one is the
most common. It is similar to the standard AFL. Speciﬁcally,
the execution engine sends a request to the program dispatcher
for a binary. The dispatcher randomly selects a rewritten binary
(from its pool), which is then executed by the engine. The
binary subsequently exits normally without any crash.
In case two, the execution is terminated by an intentional
crash (i.e., a hlt instruction). The crash is reported to
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:32:54 UTC from IEEE Xplore.  Restrictions apply. 
6664
strippedbinarypbinary w/analysis resultProgramDispatcherIncremental& StochasticRewriterExecutionEngine (AFL)ProbabilityAnalyzerSTOCHFUZZrandom rewritten binarycrashCrash Analyzerexecution requesthintanalysis requestrewrittenbinariesanalysis requestExplicitReach(a1, a2) : a1 can explicitly reach a2 along control ﬂow
RegLive(a1, a2, r) : register r written by address a1is live before address a2
IsInst(a)/IsData(a) : the content at address a is an inst/data byte
1(cid:13) ExplicitSucc(a1, a2) −→ ExplicitReach(a1, a2)
2(cid:13) ExplicitReach(a1, a2) ∧ ExplicitSucc(a2, a3) −→ ExplicitReach(a1, a3)
3(cid:13) RegWrite(a1, r) ∧ ExplicitSucc(a1, a2) −→ RegLive(a1, a2, r)
4(cid:13) RegLive(a1, a2, r) ∧ ¬RegWrite(a2, r) ∧ ExplicitSucc(a2, a3) −→
RegLive(a1, a3, r)
pinst↑−−−−−→ IsInst(a1) ∧ IsInst(a2)
5(cid:13) RegLive(a1, a2, r) ∧ RegRead(a2, r)
6(cid:13) IsInst(a1) ∧ ExplicitReach(a1, a2) 1.0−−→ IsInst(a2)
pdata↑−−−−−→ IsData(a2)
7(cid:13) Str(a1, c) ∧ (a1 ≤ a2 < a1 + c)
8(cid:13) IsData(a1) ∧ IsData(a2) ∧ (a1 ≤ a3 ≤ a2 < a1 + D)
pprop↑−−−−−→
IsData(a3)
9(cid:13) IsInst(a) 0.0←−→ IsData(a)
Fig. 8: Predicates and (Probabilistic) Inference Rules. The
predicates with overline are uncertain and rules with proba-
bility on top of −→ denote probabilistic inference.
1.0, 0.0, pinst, pdata, and pprob denote prior probabilities
that are predeﬁned constants. Rules 1 and 2 derive control
ﬂow relations. Intuitively, an instruction can always reach its
explicit successor (rule 1 ), and if a1 can reach a2, it can
reach the successors of a2 (rule 2 ). Rules 3 , 4 , and 5 are
to derive deﬁnition-use relations. Speciﬁcally, rule 3 denotes
that if an instruction writes/deﬁnes a register, the register is live
before the successor. Rule 4 denotes propagation of register
liveness, that is, if a register is live before an instruction and
the instruction does not overwrite the register, it remains live
after the instruction. Rule 5 states that if there is a deﬁnition-
use relation between a1 and a2, both addresses are likely code,
with a prior probability pinst. Rule 6 states that if an address
is likely code, all the addresses reachable from the instruction
(at the address) have at least the same likelihood of being code.
Rule 7 states that all bytes in a printable null-terminated string
are likely data. Rule 8
leverages the continuity property of
data and states that if two data addresses are close enough, the
addresses in between are likely data too. Rule 9 states that
an address cannot be code and data at the same time.
Incremental Fact and Rule Updates. New information can be
derived during fuzzing and allows facts and rules to be
updated. Speciﬁcally, new code coverage would allow deriving
new facts such ExplicitSucc(...) (e.g., newly discovered indirect
control ﬂow). When a rewriting error that replaces a data byte
a with hlt is located, the corresponding predicate IsData(a)
is set to a 1.0 prior probability, meaning “certainly data”.
IsInst(a) can be similarly updated. These updates will be
leveraged by probabilistic inference to update other random
variables and eventually affect stochastic rewriting.
Probabilistic Inference by One-step Sum-product. The
essence of probabilistic inference is to derive posterior prob-
abilities for random variables by propagating and aggregating
prior probabilities (or observations) following inference rules.
A popular inference method is belief propagation [34] which
transforms the random variables (i.e., the uncertain predicates)
and probabilistic inference rules to a factor graph [29], [35],
which is bipartite graph containing two kinds of nodes, a
Fig. 6: Universal Control-ﬂow Graph (UCFG) Example. On
the left, each address is disassembled (with the real
in-
structions in green shade and the real data in yellow). The
corresponding UCFG is in the right.
c ∈ (cid:104)Constant(cid:105) ::= Integer
a ∈ (cid:104)Address(cid:105) ::= Integer
r ∈ (cid:104)Register(cid:105) ::= {rax, rbx, rcx, rdx, · · · }
Inst(a, c) : the c bytes starting from address a can be disassembled as an inst
ExplicitSucc(a1, a2)/ : the inst at a2 is an explicit successor of the one at a1
RegWrite(a, r)/RegRead(a, r) : the inst at a writes/reads data into/from reg r
Str(a, c) : the c bytes starting from addr a can be interpreted as a printable string
Fig. 7: Deﬁnitions for Variables and Analysis Facts
Example. In the left of Fig. 6, STOCHFUZZ disassembles
starting from each (consecutive) address of a binary, with the
ﬁrst column showing the addresses, the second column the
byte value at the address, the third column the instruction size,
and the last column the instruction. For example, the ﬁrst three
bytes “48 31 c9” are disassembled to an xor instruction
and the four bytes starting from address 3 are disassembled
to a cmp instruction. We highlight the true instructions in
green shade, and the true data, an “OK” string, in yellow
shade, for discussion convenience. Note that STOCHFUZZ
does not assume such separation a priori. A simple sound
binary analysis yields the following facts: Inst(7, 2) because
the instruction at 7 is “je 17” whose instruction size is
2, ExplicitSucc(7, 17) as the instruction at 7 jumps to 17,
RegWrite(9, rcx), RegRead(9, rcx), and Str(14, 3). (cid:3)
Predicates. Next, we introduce a set of predicates that de-
scribe inference results. Different from facts that are deter-
ministic, predicates may be uncertain. A random variable is
hence associated with each uncertain predicate, denoting the
likelihood of it being true. A subset of the predicates we use
are presented in the top of Fig. 8 with those having overline
uncertain. ExplicitReach(a1, a2) denotes that address a1 can
reach a2 along control ﬂow. In Fig. 6, the path 0−3−7 leads
to ExplicitReach(0, 7). RegLive(a1, a2, r) denotes that register
r written by address a1 is live before the instruction at a2. As
such, we have RegLive(9, 12, rcx) in Fig. 6. IsInst(a) denotes
the likelihood of address a being code. IsData(a) is similar.
(Probabilistic) Inference Rules. In the bottom of Fig. 8,
we present a subset of our inference rules. Some of them
are probabilistic (i.e.,
those involving uncertain predicates
and having probability on the implication operator). Here,
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:32:54 UTC from IEEE Xplore.  Restrictions apply. 
7665
Inst(0, 3)Inst(3, 4)Inst(7, 2)Inst(9, 3)Inst(12, 2)Inst(17, 1)Inst(1, 2)Inst(2, 1)Inst(4, 3)Inst(5, 1)Inst(6, 5)Inst(8, 3)Inst(10, 2)Inst(11, 3)Inst(13, 1)Inst(14, 1)Inst(15, 3)Inst(16, 2)0 : 48 | [3] xorrcx, rcx1 : 31 | [2] xorecx, ecx2 : c9 | [1] leave3 : 48 | [4] cmprcx, 54 : 83 | [3] cmpecx, 55 : f9 | [1] stc6 : 05 | [5] add eax, 0xff4808747 : 74 | [2] je178 : 08 | [3] or [rax-1], cl9 : 48 | [3] incrcx10: ff| [2] incecx11: c1 | [3] shrebx, 24512: eb| [2] jmp313: f5 | [1] cmc14: 4f | [1] rex.WRXB(O)15: 4b | [3] rex.WXBadd r11b, al (K)16: 00 | [2] add bl, al           (\0)17: c3 | [1] retAddrByte  |[Len]    Decoded Instructionvariable node for each random variable and a factor node for
each probabilistic inference rule. A factor can be considered a
function over variables such that edges are introduced between
a factor node to the variables involved in the rule. Prior
probabilities are then propagated and aggregated through the
factor graph by an algorithm like sum-product [35], which is
an iterative message-passing based algorithm. In each iteration,
each variable node receives messages about its distribution
from the factors connected to the variable, aggregates them
through a product operation and forwards the resulted dis-
tribution through outgoing messages to the connected factor
nodes. Each factor receives messages from its variables and
performs a marginalization operation, or the sum operation.
The posterior probabilities of random variables can be derived
by normalizing the converged variable values.
However, belief propagation is known to be very expensive,
especially when loops are present [36]. Most existing applica-
tions handle graphs with at most hundreds of random variables
and factors [30]–[33]. However in our context, we have tens
of thousands of random variables and factors (proportional
to the number of bytes in the binary). Resolving the proba-
bilities may take hours. We observe that the factor graph is
constructed from program that has a highly regular structure.
The rounds of sum and product operations in the factor graph
can be simpliﬁed to non-loopy explicit operations along the
program structure. We hence propose a one-step sum-product
algorithm that has linear complexity. The algorithm constructs
a universal control ﬂow graph (UCFG) that captures the
control ﬂow relations between the instructions disassembled
at all addresses. Note that
the binary’s real control ﬂow
graph is just a sub-graph of the UCFG. Observations (i.e.,
deterministic facts and predicates that suggest data or code)
are explicitly propagated and aggregated along the UCFG,
instead of the factor graph. In the last step, a simplest factor
graph is constructed for each address to conduct a one-
step normalization (from the observations propagated to this
address) to derive the posterior probability (of the address
holding a data byte). The factor graphs of different addresses
are independent, precluding unnecessary interference.
Universal Control Flow Graph. In UCFG, a node is intro-
duced for each address in the binary regardless of code or
data, denoting the one instruction disassembled from that
address. Edges are introduced between nodes if there is
explicit control ﬂow between them. UCFG is formally deﬁned
as G = (V, E), where V = {a | ∃c s.t. Inst(a, c)} and
E ={(a1, a2) | ExplicitSucc(a1, a2)}. The right side of Fig. 6
presents the UCFG for the binary on the left. Note that only
the shaded sub-graph is the traditional CFG. After UCFG
construction, STOCHFUZZ identiﬁes the strongly connected
components (SCCs) in the UCFG (i.e., nodes involved in
loops). A node not in any loop is an SCC itself. For example
in Fig. 6, Inst(0, 3) itself is a SCC. Inst(3, 4), Inst(7, 2),
Inst(9, 3), and Inst(12, 2) form another SCC. (cid:3)
One-step Sum-product. The overall
inference procedure is
described as follows. STOCHFUZZ ﬁrst performs deterministic
inference (following deterministic rules such as rules 1 - 4 ).
The resulted deterministic predicates such as the antecedents
in rules 5 and 7 are called observations, with the former a
code observation (due to the deﬁnition-use relation) and the
latter a data observation. Prior probabilities pinst and pdata
are associated with them, respectively.
STOCHFUZZ starts to propagate and aggregate these obser-
vations using UCFG. Speciﬁcally, it uses a product operation
to aggregate all the observations in an SCC (i.e., multiplying
their prior probabilities), inspired by the sum-product algo-
rithm that uses a product operation to aggregate information
across factors. All the addresses within the SCC are assigned
the same aggregated value. Intuitively, we consider all the
addresses in an SCC have the same likelihood of being code
because any observation within an SCC can be propagated to
any other nodes in the SCC (through loop). The lower the
aggregated value, the more likely the address being code. We
say the belief is stronger. The aggregated observations are
further propagated across SCCs along control ﬂow, until all
addresses have been reached.
Data observations are separately propagated, mainly follow-
ing rule 8 . Speciﬁcally, STOCHFUZZ scans through the entire
address space in order, if any two data observations are close to
each other (less than distance D), the addresses in between are
associated with a value computed from the prior probabilities
of the two bounding observations.
After propagation, each address a has two values denoting
the aggregated code observation and the aggregated data
observation, respectively. A simple factor graph is constructed
for a as shown in Fig. 9. The circled node a is the variable
node, representing the likelihood of a being data. It has two
factor nodes Fcode and Fdata, denoting the aforementioned
two values. According to the sum-product algorithm [35], the
posterior probability of a is the normalized product of the
two factors as shown in the bottom of the ﬁgure. The detailed
algorithm and its explanation can be found in Appendix X-H.
Comparison with Probabilistic Disassembly. In probabilistic
disassembly [37], researchers use probabilistic analysis to dis-
assemble stripped binaries. It computes probabilities for each
address to denote the likelihood of the address belonging to
an instruction. However, its problem deﬁnition and probability
computation are ad-hoc. Its algorithm is iterative and takes tens
of minutes to compute probabilities for a medium-sized binary.
It has a lot of false positives (around 8%), i.e., recognizing
data bytes as instructions. These make it unsuitable for our
purpose. In contrast, we formulate the problem as probabilistic
inference and propose an algorithm with linear complexity.
Piggy-backing on fuzzing, STOCHFUZZ can achieve precise
disassembly and rewriting with probabilistic guarantees.
B. Incremental and Stochastic Rewriting
The rewriter is triggered initially and then repetitively when
new code is discovered or rewriting errors are ﬁxed. It rewrites
instructions in the shadow space (for better instrumentation
ﬂexibility) and retains data in the original space. And the
original code is replaced with hlt. Its rewriting ensures a
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:32:54 UTC from IEEE Xplore.  Restrictions apply. 
8666