we argue that this is impractical for most services.
3RECAP always uses the same ciphers for simplicity.
4This still preserves anonymity because the registration is not link-
We do note that our solution is not perfect, since one
computer can be shared by multiple users, and one user
can own multiple computers. In particular, well-funded
attackers may be able to purchase such a large number
of computers that blacklisting all of them would be dif-
ﬁcult. Services concerned about this type of adversary
can use a more precise identiﬁer as a unique identity,
such as a driver’s license or passport.
6
Implementation
We implemented RECAP using two cryptographic
libraries: the PBC SIG group signature library [22] that
is a framework for implementing pairing based group
signature schemes, and the XySSL library [34] for im-
plementations of RSA, AES, SHA-1, and HMAC. We
use 256-bit AES keys, HMAC keys, nonces and random
values. RSA keys are 1024-bit. We use the Boneh-
Shacham group signature scheme [8] with a Type-A
pairing. We do not currently implement any local re-
vocation checking for the group signature scheme [8],
although we intend to implement this in future work. In-
stead, we consider the effects of using the O(1)-time
revocation scheme that adds a table-lookup per veriﬁca-
tion, which is unlikely to signiﬁcantly change our per-
formance measurements. We assume that this table-
lookup will have a negligible effect on our measure-
ments. Options for implementing such revocation are
discussed in Section 8.4.
Portions of the code that execute on the user’s and
AS’s platforms constitute the security-sensitive, trusted
components of RECAP. Our implementation uses the
Flicker system [23] to provide the attestation, sealed
storage, and isolation properties speciﬁed in Section 2.2
by using a TPM [30] and hardware-supported dynamic
root of trust [19]. Datta et al. have proven that dy-
namic root of trust systems like Flicker allow a veri-
ﬁer to make strong conclusions about the software state
of an attesting platform. The Trusted Computing Base
(TCB) for security-sensitive RECAP code includes only
the Flicker stub code, and excludes the legacy operating
system, BIOS, and all DMA-capable devices. We ex-
pect the trusted RECAP code to be the same across all
uses of RECAP, i.e., the code will be publicly known
and evaluated to be “known-good” by manual or formal
security analysis. Our implementation bases each user’s
unique identity on the Endorsement Credential found in
each TPM (which is discussed further in Section 5). One
beneﬁt of using the Flicker system is that RECAP can
run on commodity systems that are widely available.
able to future authentications.
The registration and breach phases of RECAP in-
volve processing inside the Flicker isolation environ-
ment, because the protocol requires access to informa-
tion that must be kept secret using sealed storage. How-
ever, Flicker does not support direct access to a network
stack. Therefore, software that directly interfaces with
the network stack must run on the untrusted host operat-
ing system. The untrusted portion of RECAP is respon-
sible for launching the Flicker sessions on the user’s and
AS’s platforms. We note that the untrusted code could
choose not to launch the Flicker session. This is equiv-
alent to the availability attack described in Section 8.2,
but more importantly, the untrusted code cannot imper-
sonate trusted code.
The trusted RECAP components that run in the
Flicker environment are responsible for protecting their
state using TPM SEAL and TPM UNSEAL. Many pro-
tocol messages in the registration and breach phases are
passed as input to the Flicker environment, along with
the sealed copy of any sensitive data that may be re-
quired. The trusted code will then unseal the informa-
tion it needs and create its reply message. It will then
output the reply message to be sent over the network,
and seal and output any updated sensitive state before
returning to the host operating system.
Sealed state on the user’s platform includes RU ,
RAS, K −1
U , KAS, and KU −AS. Sealed state on the AS’s
platform includes, for each registered user Ui: RAS,
RUi , K −1
AS, KUi , KAS−Ui , and the registered users’ en-
dorsement key certiﬁcates (real identities) CEndorse−Ui .
It further includes the entire set of private group signa-
ture keys K −1
GSK [1 . . . n] (i.e., keys for each registered
member, and unused keys that may be assigned to future
members), and the group manager secret key K −1
GMSK .
7 Evaluation
Our test machine is an off-the-shelf Lenovo Thinkpad
T400 with a 2.53 GHz Intel Core 2 Duo processor and
2 GB of RAM. It runs Ubuntu 8.10 with Linux ker-
nel 2.6.24. Our current implementation only utilizes one
core, but a more sophisticated implementation could use
multiple CPUs to improve performance. We perform all
of our experiments on this one machine, i.e., we exe-
cute the SP, AS, and user code on the same machine.
This conﬁguration gives a conservative estimate of the
protocol’s end-to-end running time in a real system (ex-
cluding network latency), since only one Flicker session
can be running in isolation at a time.
7.1 Performance
RECAP
PEREA, K=15
BLAC
 50000
 40000
 30000
 20000
 10000
 0
 0
 100
 200
 300
 400
 500
 600
 700
 800
(a) Anonymous communication throughput at the user.
Blacklist size
RECAP
PEREA, K=30
BLAC
 50000
 40000
 30000
 20000
 10000
)
r
u
o
h
/
s
h
t
u
a
(
t
u
p
h
g
u
o
r
h
T
)
r
u
o
h
/
s
h
t
u
a
(
t
u
p
h
g
u
o
r
h
T
 0
 0
 100
 200
 300
 400
 500
 600
 700
 800
Blacklist size
(b) Anonymous communication throughput at the service provider.
Figure 5. Comparison of anonymous com(cid:173)
munication throughput at the user (5(a))
and service provider (5(b)) for RECAP,
PEREA [32], and BLAC [31]. Note that data
points for BLAC were extrapolated from
ﬁgures in the original publication. We do
not consider the effects of rate limiting in
PEREA and BLAC.
Anonymous Communication Once a contract is es-
tablished, no Flicker sessions are needed to anony-
mously endorse messages by the user. We do not pro-
tect the user’s private group signing key within Flicker
because it is not required for the security of the sys-
tem (although it is the user’s responsibility to safeguard
their keys)5. Consequently, the common-case opera-
tion of RECAP is efﬁcient. On average, message en-
5It is straightforward to put the user’s private group key inside
Flicker at the cost of invoking a Flicker session for every group sig-
nature operation.
dorsement takes 86 ms ± 0.4 ms on the user’s plat-
form, and message veriﬁcation takes 87 ms ± 0.2 ms
on the SP’s platform. Note that our implementation is
not actually checking for revoked users. Thus, these
measurements are very close to what the O(1) revoca-
tion scheme would yield. In this scheme, a small num-
ber of messages are linkable (see Section 8.4). Fig-
ures 5(a) and 5(b) show that the endorsement through-
put of RECAP scales well with the size of the blacklist
|BL| for both the user and SP. Table 1 compares the
asymptotic and empirical performance measurements.
We use the numbers reported in prior works [31, 32].
Note that PEREA and BLAC both require additional
rate limiting not shown in Figures 5(a) and 5(b), which
limits the throughput between a particular user and SP.
For instance, in PEREA, users must be rate-limited to
k authentications per detection time. For k = 30 and a
detection time of one hour, this yields only 30 authenti-
cations per hour. RECAP does not require rate limiting,
and a particular user and SP can authenticate approxi-
mately 40,000 times per hour.
Clearly, there is a performance-unlinkability trade-
off between our implementation of RECAP and exist-
ing systems such as PEREA and BLAC. RECAP scales
extremely well, however it does so in part by utilizing
a O(1) revocation scheme which favors performance
over perfect unlinkability. Thus, existing systems may
be preferable when performance is not an issue, and
when perfect unlinkability is required. RECAP is bet-
ter suited for services with high rates, and in which a
small number of linked messages does not harm the user.
However, subjective-based systems like PEREA and
BLAC suffer from several factors unrelated to perfor-
mance (which have been already discussed in Section 5),
including the lack of guarantees for well-behaved users
and the difﬁculty of ﬁnding practical identiﬁers.
Registration We have measured the end-to-end time
it takes for a user to negotiate a contract using the regis-
tration protocol. Although the contract negotiation pro-
tocol takes O(|BL|) time between the AS and SP to
determine if the user is on the blacklist, the total time
is largely dominated by the time it takes to execute the
TPM SEAL and TPM UNSEAL commands. The black-
list would have to be impractically large for the linear
time component of the runtime to have any impact on
the total runtime. In our implementation, contract nego-
tiation takes 7.99 ± 0.04 s. Although this may seem like
a long time, this protocol only executes when a user reg-
isters to use a new service, or the user and SP negotiate
a new contract.
System
RECAP
PEREA [32]
BLAC [31]
Auth. (U) Auth. (SP) Auth. (U)
86 ms
5900 ms
1450 ms
Auth. (SP)
O(1)
O(1)
O(k|BL|)† O(k)
O(|BL|)
87 ms
160 ms
870 ms
Parameters
kSP = 30, kU = 10
O(|BL|)
Table 1. Comparison of authentication time between RECAP and other systems for reasonable
parameter choices (|BL| = 800). Measurements for PEREA and BLAC are taken from the
relevant works, as we were unable to obtain the source code for these schemes [31, 32]. †:
The amount of computation needed for PEREA is O(k∆|BL|), but the actual time required to
authenticate is O(k|BL|) because of the risk of timing attacks. k is a window parameter used
only in PEREA.
The majority of the time spent during registration is
spent executing the TPM UNSEAL command. Thus, by
batching multiple requests together in a single Flicker
session, the cost of unsealing data can be amortized to
achieve improved throughput. It may also be possible
to replace the use of the TPM’s (relatively slow) sealed
storage with its (relatively fast) non-volatile RAM facil-
ities [23], though our current implementation does not
support TPM NVRAM. We leave this for future work.
Breach Last, we also examine the end-to-end time for
a SP to determine the identity of a misbehaving user.
Our implementation of the breach protocol takes 0.32 ±
0.09 s on average from the time the SP detects a mali-
cious message to the time it receives the user’s identity
from the AS, excluding the time needed to establish the
secure channel as described in Section 4.
7.2 Trusted Computing Base (TCB)
RECAP has a relatively small trusted computing
base that needs to run in the Flicker isolated execution
environment [23]. Table 2 shows the number of lines of
code in the TCB for the user and the AS. The majority
of the code is the PBC cryptographic libraries for im-
plementing group signatures, which also depend on por-
tions of the GNU Multiple Precision Arithmetic Library.
RSA and the symmetric cryptographic functions, as well
as the TPM driver and supporting code for TPM SEAL
and TPM UNSEAL also make signiﬁcant contributions
to code size. The actual logic for RECAP comprises a
relatively small overall portion of the TCB, suggesting
that formal veriﬁcation or manual audit are realistic op-
tions. We also note that we have made no effort to strip
unused content from the cryptographic and mathemat-
ical libraries. Signiﬁcant additional reductions in code
size are readily attainable. Even so, our entire TCB mea-
sures in a few tens of thousands of lines. This is orders
of magnitude less than the TCB for code running on top
of a commodity operating system.
Component
Flicker: User
Flicker: User
Flicker: AS
Flicker: AS
Lang.
.c/.S
.h
.c/.S
.h
Flicker: Shared
Crypto / TPM .c
Crypto / TPM .h
Crypto
.c
.h
Crypto
.c/.S
PBC
.h
PBC
.c/.S
GMP
GMP
.h
SLoC
953
1590
1173
1549
4134
202
2698
1791
11527
1160
4859
5802
Table 2. Lines of code in the trusted com(cid:173)
puting base (TCB) of our implementation
as measured by sloccount [33]. PBC =
pairing based cryptography library. GMP =
GNU multiple precision arithmetic library.
8 Discussion
8.1 RECAP as a Primitive
RECAP provides a mechanism for users to anony-
mously use a service, and thus it is a component in a
larger, overall protocol stack. For example, RECAP
may be run on top of TCP/IP, and as part of a larger
chat protocol.
We only make guarantees about the RECAP com-
ponent. For example, a user who types in their per-
sonal information to a chat service could circumvent
any security otherwise offered from RECAP. Similarly,
the chat protocol could run RECAP on top of TCP/IP,
which may allow chat servers to log IP addresses. Al-
though RECAP does not solve the complete protocol
stack problem, RECAP can be used at each layer of
the stack. For example, Tor is a widely-used network-
level service that is intended to help create network-level
privacy for higher-level services by preventing a net-