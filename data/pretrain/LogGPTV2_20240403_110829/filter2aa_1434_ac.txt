to focus our eﬀorts.
3.1.2
Better support for relay operators
Getting somebody to set up a relay is one thing; getting them to keep it up is another thing entirely. We
lose relays when the operator reboots and forgets to set up the relay to start on boot. We lose relays when
the operator looks through the website and doesn’t ﬁnd the answer to a question.
We’ve been working on a new service for relay operators called Tor Weather2. The idea is that once
you’ve set up your relay, you can subscribe to get an email whenever it goes down. We need to work on the
interface more, for example to let people subscribe to various levels of notiﬁcation, but the basic idea seems
like a very useful one.
With Tor Weather you can also subscribe to watch somebody else’s relay; so this service should tie in well
for the people doing advocacy, to let them focus their follow-ups when a relay they helped set up disappears.
We are also considering setting up a mailing list exclusively for relay operators, to give them a better
sense of community, to answer questions and concerns more quickly, etc.
We should also consider oﬀering paid or subsidized support options so relay operators have a place to go
for help. Corporations and universities running relays could get direct phone, email, or IM support options.
3.1.3
A Facebook app to show oﬀ your relay
We’re currently developing a Facebook application that will allow relay operators to link their Tor relays to
their Facebook proﬁle. Volunteers who desire can therefore publicly get credit for their contribution to the
Tor network. This would raise awareness for Tor, and encourage others to operate relays.
Opportunities for expansion include allowing relay operators to form “teams”, and for these teams to be
ranked on the contribution to the network. (Real world examples here include the SETI screensaver and the
MD5 hash crack challenges.) This competition may give more encouragement for team members to increase
their contribution to the network. Also, when one of the team members has their relay fail, other team
members may notice and provide assistance on ﬁxing the problem.
3.1.4
Look for new ways to get people to run relays
We are not primarily social engineers, and the people that we are good at convincing to set up relays are
not a very huge group.
We need to keep an eye out for more creative ways to encourage a broader class of users to realize that
helping out by operating a relay will ultimately be something they want to do.
3.2
Funding more relays directly
Another option is to directly pay hosting fees for fast relays (or to directly sponsor others to run them).
The main problem with this approach is that the eﬃciency is low: at even cheap hosting rates, the cost
of a signiﬁcant number of new relays grows quickly. For example, if we can ﬁnd 100 non-exit relays providing
1https://www.torproject.org/projects/metrics
2https://weather.torproject.org/
8
Performance Improvements on Tor
1MB/s for as low as $100/mo (and at that price it’d be renting space on a shared server, with all the resource
sharing hassles that comes with), that’s $120k per year. Figure some more for maintenance and coordination,
the overhead to ﬁnd 100 locations that are on suﬃciently diﬀerent networks and administrative zones, etc.
The amount of work involved in running them as exit relays might be a few times this cost, due to higher
hosting fees, more eﬀort involved in establishing and maintaining the right relationships, having lawyers
nearby, etc.
Plus the costs just keep coming, month after month.
Overall, it seems more sustainable to invest in better code, and community outreach and education.
Impact: Medium.
Eﬀort: High.
Risk: Low.
Plan: If we end up with extra funding, sure. Otherwise, I think our time and eﬀort are better spent on
design and coding that will have long-term impact rather than be recurring costs.
3.3
Handling fast Tor relays on Windows
Advocating that users set up relays is all well and good, but if most users are on Windows, and Tor doesn’t
support fast relays on Windows well, then we’re in a bad position.
Nick has been adapting libevent so it can handle a buﬀer-based abstraction rather than the traditional
Unix-style socket-based abstraction. Then we will modify Tor to use this new abstraction. Nick’s blog post3
provides more detail.
Impact: Medium.
Eﬀort: High, but we’re already halfway through.
Risk: Low.
Plan: Keep at it. We’re on schedule to get a test version (one that works for Nick) out in September
2009. Then iterate until it works for everybody.
3.4
Relay scanning to ﬁnd overloaded relays or broken exits
Part of the reason that Tor is slow is because some of the relays are advertising more bandwidth than
they can realistically handle. These anomalies might be due to bad load balancing on the part of the Tor
designers, bad rate limiting or ﬂaky network connectivity on the part of the relay operator, or malicious
intent. Similarly, some exit relays might fail to give back the ‘real’ content, requiring users to repeat their
connection attempts.
Mike has been working on tools to identify these relays: SpeedRacer4 and SoaT5. Once the tools are
further reﬁned, we should be able to ﬁgure out if there are general classes of problems (load balancing,
common usability problems, etc) that mean we should modify our design to compensate. The end goal is
to get our tools to the point where they can automatically tell the directory authorities to leave out certain
misbehaving relays in the network status consensus, and/or adjust the bandwidths they advertise for each
relay.
Impact: Low.
Eﬀort: Medium.
Risk: Low.
Plan: Keep at it. We’re on schedule to get a test version (that works for Mike) out in mid 2009. Then
iterate until it works for everybody.
3https://blog.torproject.org/blog/some-notes-progress-iocp-and-libevent
4https://svn.torproject.org/svn/torflow/trunk/README.PerfMeasurements
5https://svn.torproject.org/svn/torflow/trunk/NetworkScanners/README.ExitScanning
9
Performance Improvements on Tor
3.5
Getting dynamic-IP relays back into the relay list quickly
Currently there is a delay of 2-5 hours between when a relay changes its IP address and when that relay gets
used again by clients. This delay causes two problems: relays on dynamic IP addresses will be underutilized
(contributing less to the total network capacity than they could), and clients waste time connecting to relay
IP addresses that are no longer listening.
There are several approaches that can mitigate this problem by notifying clients sooner about IP address
changes. The ﬁrst approach is to continue on our path of simplifying directory information (see Section 6.1):
if we can put out “diﬀs” of the network status more often than once an hour, clients can get updated
quicker. A second approach is for each relay to estimate how volatile its IP address is, and advertise this in
its descriptor. Clients then ignore relays with volatile IP addresses and old descriptor. Similarly, directory
authorities could prioritise the distribution of updated IP addresses for freshly changed relays.
As a last note here, we currently have some bugs that are causing relays with dynamic IP addresses to
fall out of the network entirely. If a third to half of the relays are running on dynamic IP addresses, that’s
really bad.
Impact: Low-medium.
Eﬀort: Low-medium.
Risk: Low.
Plan: Track down and ﬁx bugs for Tor 0.2.2.x. Continue simplifying directory information so we can
get new info to clients quicker.
3.6
Incentives to relay
Our blog post on this topic6 explains our work to-date on this topic. The current situation is that we have
two designs to consider: one that’s quite simple but has a serious anonymity problem, and one that’s quite
complex.
I think we should move forward with the ﬁrst (simple but ﬂawed) design. There are several pieces to
moving it forward. The ﬁrst phase is changing Tor’s queueing mechanisms to be able to give some circuits
priority over others. This step also ties into the other development items in this document regarding cell-,
circuit-, and connection-priorities. The second phase is then redesigning the “gold star” mechanism so the
priority earned by relays lasts long enough that there’s a suﬃcient anonymity set for them. We’ll need to
look at current and projected network metrics to discover a good upper bound on relay churn. The question
to answer is: “What period of time, taken as a rolling snapshot of which relays are present in the network,
guarantees a suﬃciently large anonymity set for high-priority relays?” Hopefully the answer is something
like 7 or 14 days. There are other missing pieces in there, like “what do we mean by suﬃciently?”, that we’ll
just have to guess about. The third phase is to actually sort out how to construct and distribute gold-star
cryptographic certiﬁcates that entry relays can verify.
Notice that with the new certiﬁcates approach, we can reward users who contribute to the network in
other ways than running a fast public relay – examples might include top sponsors, users who run stable
bridge relays, translators, people who ﬁx bugs, etc.
Impact: Medium-high.
Eﬀort: Medium-high.
Risk: Medium-high: if we screw up the balance of our community-oriented infrastructure, we might end
up hurting more than we help.
Plan: Accomplishing the three phases above will put us in a much better position to decide whether to
deploy this idea. At the same time, the more complex options might become more within reach as other
research teams investigate and reﬁne them, so we should keep an eye on them too.
6https://blog.torproject.org/blog/two-incentive-designs-tor
10
Performance Improvements on Tor
3.7
Reachable clients become relays automatically
Even if we don’t add in an incentive scheme, simply making suitable users into relays by default should do
a lot for our capacity problems.
We’ve made many steps toward this goal already, with automated reachability testing, bandwidth esti-
mation, UPnP support built in to Vidalia, and so on.
There are a few risks here though. First, relaying traﬃc could introduce anonymity vulnerabilities, and
we need to learn more about that ﬁrst. (That’s on the roadmap for 2009.) Second, making clients into relays
by default could make some users upset. Third, this approach could change how sysadmins view Tor. By
putting ourselves into the same category as Skype, we would scale up the “blocking Tor connections” arms
race by a level that’s hard to predict. Also, we need to ﬁnish deployment of Section 3.3 before we can roll
this out, or we’ll just make a bunch of Windows machines crash.
We had originally been avoiding the “everybody a relay” design until we had a better plan for scaling
the directory to be able to distribute tens of thousands of relay addresses. I think these two plans are not as
related as we ﬁrst thought, though. For example, a very simple answer for what to do if we get more relays
than our current directory scheme can handle is to publish only the best relays, for some metric of best that
considers capacity, expected uptime, etc. That should be a perfectly adequate stopgap measure. The step
after that would be to consider splintering the network into two networkstatus documents, and clients ﬂip
a coin to decide which they use. Ultimately, if we are so lucky as to get into the position of having too
many relays, we’ll want to look at the distribution and properties of the relays we have when deciding what
algorithms would best make use of them.
Impact: High.
Eﬀort: Medium, now that we’ve done a lot of hard work already.
Risk: Medium.
Plan: Wrap up our investigations into the anonymity implications of being a relay, at the same time as
working on a plan for exactly how the Tor client should decide if it’s suitable for elevation to relay status.
This is going to happen, it’s just a matter of how soon.
4
Tor clients choose paths imperfectly
Even when we sort out the congestion control issues, the problem of users abusing the network with too
much traﬃc, and the question of overall capacity, we still face a fourth problem. Users need to choose their
paths in such a way that everybody is using the network eﬃciently.
Right now, Tor relays estimate their capacity by observing the largest traﬃc burst they’ve seen themselves
do in the past day. They advertise that bandwidth capacity in the directory information, and clients weight
their path selection by the bandwidth of each relay. For example, a relay that advertises 100KB/s peak
bandwidth will be chosen twice as often as a relay that advertises 50KB/s peak bandwidth.
There are several problems with our current algorithm that are worth ﬁxing.
4.1
We don’t balance traﬃc over our bandwidth numbers correctly
Selecting relays with a probability proportional to their bandwidth contribution to the network may not
be the optimal algorithm. Murdoch and Watson [10] investigated the performance impact of diﬀerent relay
selection algorithms, and came up with a model to describe the optimal path selection strategies based on
how loaded the network is.
Tor’s current selection strategy is optimal when the network is fully loaded. That is, if every single byte
is going to be used, then weighting by capacity is the right way to do it. But if the network is not fully
loaded, then the fast relays end up with less load than the slow relays. To compensate, clients should pick
faster relays with higher probability.
11
Performance Improvements on Tor
In particular, we can estimate the network load because all Tor relays publish both their capacity and
usage in their relay descriptor (but see Section 4.2 for problems that crop up there). The Tor network is
currently loaded at around 50%. This level is much higher than most reasonable networks, indicating that
our plan in Section 3 to get more overall capacity is a good one. But 50% is quite far from 100% when it
becomes to optimal load balancing.
To ﬁnd the optimum relay selection probabilities the model, Steven used a hill-climbing algorithm to
minimize network latency, with a Tor directory snapshot as input. The results (shown in Figure 1 and
Figure 2) depend on the network load relative to overall capacity. As load approaches capacity, the optimum
selection probabilities converge to the one currently used by Tor: relay bandwidth proportional to network
capacity. However, as load drops, the optimized selection algorithm favors slow relays less and faster relays
more; many relays are not used at all.
Anecdotal evidence supports the theory that the fast relays in the Tor network have more spare capacity
than they should. Several users have posted that they get much better Tor performance if they hard-code
their paths to only use the fastest ten relays (and ignore the huge anonymity implications, of course).
The relay selection probabilities in these graphs are tuned to a particular level of network load. Figure 3
shows how average network latency is aﬀected by relay selection probabilities, for diﬀerent levels of network
load. For all load levels examined, the optimized selection probabilities oﬀer lower latency when compared
to Tor’s current selection algorithm. However, there’s a downside to tailoring for a particular load level: if
we see a much heavier load in practice than the one we had in mind when we tuned our selection biases,
then we end up overbalancing the network in the other direction.
Speciﬁcally, each probability distribution has a cut-oﬀ point at which (according to the model) at least
one relay will have a higher load than its capacity, at which its queue length, and hence latency, will become
inﬁnite. For the optimized selection probability distributions, this cut-oﬀ point is a few percent above the
level they were designed to operate at. For Tor’s current selection algorithm, it is when the overall network
capacity equals the overall network load.
In this respect the Tor selection algorithm reaches the theoretical optimum, as no network can operate
at greater than 100% utilization while maintaining ﬁnite latency. However, in a real instantiation of any
of these alternative probability distributions, the network latency would not become inﬁnite; instead a