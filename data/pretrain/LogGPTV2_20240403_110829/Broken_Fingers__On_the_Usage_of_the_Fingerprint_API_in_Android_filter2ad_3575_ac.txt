cryptographic operations if a cryptographic key is unlocked but
never properly used.
B. Decryption Usage
In this case, a cryptographic key is created, stored inside
the TEE, and used to decrypt (once the key is “unlocked” by a
legitimate user touching the fingerprint sensor) locally stored files.
Google’s guidelines suggest using the fingerprint API in this way
when “securing access to databases or offline files.” In practice,
we have seen this method often used to decrypt an authentication
cookie stored in an encrypted vault within the app’s private storage.
This authentication cookie, typically valid for multiple sessions,
can be used by the app to authenticate with the remote server.
We have found two ways in which this mechanism is imple-
mented. The easiest case is when a symmetric key is created and
used to encrypt/decrypt the content of the “encrypted vault.” The
disadvantage of this method is that it requires the user to touch
the sensor (to “unlock” the key) to both read something from the
vault and to write something into it. As a consequence, if, for
instance, the remote backend decides to change the value of the
authentication cookie stored inside the vault, the user would need
to touch the fingerprint sensor to unlock the key.
A more user-friendly way is to use an asymmetric key pair. In
this case, the public key (which does not need to be “unlocked”
before usage), is used to write inside the vault, and the private
key (which requires the user’s touch) is only used to read from
the vault (e.g., when the stored authentication cookie is needed to
authenticate with the app’s backend).
Surprisingly, the example officially provided by Google [25]
about using the fingerprint API together with a symmetric key does
not show how to use cryptography safely. In fact, the provided code
generates a symmetric key and, after the user touches the sensor,
uses it to encrypt a fixed, hardcoded string. Then, the code just
checks whether the encryption operation (performed using the
doFinal API) threw an exception, an indication that the used key
is (still) locked (i.e., it has not been unlocked). While the intent
might have been to verify that the user has touched the sensor, this
particular example code makes the usage of cryptography pointless
because an attacker with “root” privileges can just fake the result of
the decryption operation and clear the thrown exception (as we will
describe better in Section VIII-A2). In practice, in terms of security,
we consider the Google’s example on how to use symmetric keys
as a case of Weak usage of the fingerprint API, rather than a case
of Decryption usage.
The fingerprint API can also be used to implement chal-
lenge/response authentication schemes. This offers significantly
more security over a wide range of attackers, but, unfortunately, it
is rarely used by developers.
In this case, typically during the app’s first usage, a key pair
is generated: the public key is sent to the app’s remote backend
server, whereas the private one is stored within the TEE. When
the app needs to authenticate a user to the remote backend, the
following steps take place:
1)
2)
3)
4)
5)
6)
7)
8)
The remote backend sends a challenge to the app.
The app calls the authenticate API to “unlock” the
previously stored private key.
The legitimate user touches the fingerprint reader sensor,
and the private key is “unlocked” by the TEE.
The onAuthenticationSucceeded method (over-
ridden by the app) is called.
The app uses the now-unlocked private key to sign the
challenge from the app’s backend.
The app sends the signed challenge to the backend.
The backend verifies the signature on the challenge, using
the public key previously obtained from the client.
The backend communicates to the app the result of the
verification and considers the user as authenticated.
D. Sign + Key Attestation Usage
As we discuss in more detail in Section V-C, the “Sign” usage
is vulnerable to an attacker that can perform a man-in-the-middle
attack at the app bootstrap time, when the initial key exchange
takes place. In this attack, the attacker would provide to the
backend her public key (for which she has the associated private
key), and she could then bypass the fingerprint. However, starting
from Android 7, a countermeasure to this attack is possible, since
Android can provide an “attestation” certificate chain, attesting that
a key has been created by a “trusted” TEE. A similar attestation
mechanism is present in the Security Keys protocol [32].
to
call
pair,
has
it,
a
To
enable
creating
developer, when
a
key
the setAttestationChal-
lenge(attestationChallenge) API with a non-NULL
value for attestationChallenge. Then, the app can retrieve
the certificate chain, attesting the generated public key using
the getCertificateChain API. The app’s backend can
then verify that the root of this chain is signed by a trustworthy
Certificate Authority (typically Google). The certificate, among
other pieces of information about properties of the generated keys,
contains the attestationChallenge previously set, allowing
the app’s backend to verify that the retrieved key was created as a
consequence of a specific request.
V. PROTOCOL WEAKNESSES AND ATTACK SCENARIOS
We will now highlight the weaknesses of each usage scenarios
described in Section IV. For each identified weakness, we will also
determine which classes of attacker (as defined in Section III) can
exploit it. Our findings are summarized in Table I.
6
A. Weak Usage: Fake TEE response
In the Weak usage scenario, fingerprint-based authentication
is considered successful as long as the TEE communicates that a
legitimate touch happened. This message is delivered by the OS to
the client app (by invoking the onAuthenticationSucceeded
method). In this case, any entity that can control/impersonate the
OS to deliver such message can successfully authenticate and
authorize any transaction to the server, without having to wait for
the user to present the fingerprint even once. In other words, any
“root” attacker can achieve Full Fingerprint Bypass against Weak
usage by faking OS messages. Additionally, a non-root attacker can
exploit confused deputy problems by mounting UI attacks. Once
again, these attacks are possible because of the lack of trusted UI in
Android. We also note that these attacks are possible independently
from the specific attacker capabilities and from the specific usage
scenario. We refer the reader to Section VI-B for more details.
B. Decryption Usage: Replay Attack
In the Decryption usage scenario, the TEE is used to decrypt
a value (e.g., an authentication cookie), and the same value is
communicated to the client app (and the backend server) for every
attempt to authenticate or authorize a transaction. In this scenario,
an attacker only needs to capture this value once to then be able
to fully authenticate and authorize any transaction any time in the
future, by simply replaying this captured value over and over.
C. Sign Usage: Man-in-the-Middle Attack
In the Sign usage scenario, the TEE is used to protect a private
key used in a challenge/response scheme. In this scenario, a root
attacker cannot easily compromise the system — in a way, she
has similar capabilities as a non-root attacker, and she could thus
attempt to exploit confused deputy problems via UI attacks.
However, we note that an attacker can launch a man-in-the-
middle attack if she can interfere with the “app bootstrap” process,
during the initial key exchange. The attack would work in this way:
at bootstrap, instead of sending to the backend server the real key
output by the TEE, the attacker can use her own key instead. In
this way, the attacker can use the key thus registered to answer any
future challenge (because the attacker knows both the public and
the private key), thus achieving Full Fingerprint Bypass. Clearly,
since this attack requires the attacker to have control over when
the key exchange is carried out, it is only possible for Root-at-
Bootstrap attackers.
D. Sign + Key Attestation Usage: Key Proxying
The “Sign + Key Attestation” usage scenario significantly
raises the bar for attacks, even for a very powerful attacker such
as Root-at-Bootstrap attacker. However, from a conceptual point
of view, it is possible to attack this usage scenario as well, by
performing a so-called cuckoo attack [37]. Specifically, while this
mechanism attests that a key has been created by the TEE on a
user’s device with the goal of preventing an attacker from knowing
its private value, it cannot prevent an attacker from “proxying”
the app’s request for creating a key pair to her attacker-controlled
device and using the TEE of her device. We note that this attack
scenario presents serious practicality and scalability issues for the
attackers. That being said, we will further discuss this aspect in
Section IX-C, where we propose improvements on the current
implementation of this mechanism.
TABLE I.
SUMMARY OF ATTACK POSSIBILITIES WITH RESPECT TO
ATTACKER CAPABILITIES AND FINGERPRINT API USAGE.
Fingerprint API
Usage Weak Decryption
Sign
Attacker
Capabilities
Sign
+
Key Attestation
Non-Root C.D. 1
Full
Full
C.D.
Once
Full
1 “C.D.” stands for Confused Deputy.
Root
Root-at-Bootstrap
C.D.
C.D.
Full
C.D.
C.D.
C.D.
VI. DISCUSSION
This section discusses aspects related to the fingerprint API that
are not strictly related to the API itself or to the specific vulnerable
“usage scenarios” described above.
A. Application Contexts
Typically, the fingerprint API is used as a part of an authentica-
tion scheme. In this section, instead of focusing on how apps use
the fingerprint sensor in terms of API calls and encryption, we will
discuss common functionality apps aim to accomplish when they
use the fingerprint sensor.
“Local-Only” Usage. Some apps use the fingerprint API to
implement the “screen-lock” functionality. For instance, they
prevent access to a list of user-selectable apps, unless the fingerprint
sensor is touched by a legitimate user. In this case, the fingerprint
sensor just constitutes a local Test of User Presence (TUP).
For these apps, only a Weak usage of the fingerprint API is
reasonable. In fact, the app does not have any remote backend to
authenticate with nor it stores any secret data.
Remote User-Authentication. More interestingly, in many cases,
the fingerprint API is used as one part of an authentication scheme.
Upon first usage, apps have to provide a single-factor or multi-
factor user authentication system, since no cryptographic key is
created and stored by the app inside the TEE yet. On subsequent
usages, the app (and the corresponding backend) may require the
user to touch the fingerprint sensor. Some apps can be configured
to require the user to touch the sensor every time the app is opened
and it connects to the remote backend. Others ask for this action
before performing any sensitive operation, such as a payment.
Typically, when the fingerprint functionality is enabled, the app
will allow the use of a fingerprint touch instead of inserting the
account’s password. While this is convenient in term of usability,
it has mixed security consequences. As a security benefit, an
attacker achieving “root” cannot steal the account password, since
the user is not asked to insert it. However, as we will explain
in Section VI-B, even a non-root attacker can potentially lure a
user to touch the fingerprint sensor and, compared to phishing a
password, stealing a fingerprint touch is significantly easier. In fact,
touching the fingerprint sensor is a common action, since it is used,
for instance, very frequently to unlock the phone. Therefore an
attacker can just pretend to be the lock-screen without raising much
suspicion. Secondly, a fingerprint touch requires less user’s effort
and time to be performed and therefore is more likely to happen.
Finally, an attacker does not need to ask for a specific password,
but just to generically touch the sensor.
7
Fig. 1. Overview of the developed static analysis tool
B. Practicality and Impact of UI Attacks
As we mentioned earlier, a malicious app can show maliciously
crafted messages or, more in general, interfere with the device’s
user interface to lure a legitimate user to touch the fingerprint
reader sensor. In particular, we mentioned how several existing
works [34], [14], [9] show the possibility to perform UI attacks,
and that a very recent work, dubbed Cloak & Dagger [21], can
achieve almost complete compromise of the device. In particular,
this last work showed that apps installed from the Play Store are
automatically granted the SYSTEM_ALERT_WINDOW permission
(which allows to create overlays windows on top of any other) and
that it is possible to lure the user to unknowingly grant accessibility
permissions to a malicious app through “clickjacking.”
These attacks are powerful, especially because they can be
performed by any unprivileged app (what we refer to as “non-root
attacker”). However, we note that the fingerprint API might be
one of the few aspects that could, at least in principle, prevent full
compromise: a physical fingerprint “touch” cannot be spoof via
UI-only attacks.
That being said, there are many attacks that one could perform.
These attacks are all instances of a confused deputy problem, and
they are all possible due to one key observation: no “Secure UI” is
currently used by the fingerprint API, and the user does not have
any mechanism to establish with which app she is interacting with.
As a very practical example of these attacks, Zhang et al. [53] show
how an attacker can create a fake “screen lock” to lure the user to
provide her fingerprint: the fingerprint, under the hood, is actually
“passed” to a security sensitive app in the background.
More in general, the lack of “secure UI” allows an attacker
(independently from the fingerprint usage scenarios described in
Section IV) to lure the user to present her fingerprint believing she
is authenticating with app A or authorizing transaction X, while
the fingerprint is actually used to unlock keys for a different app
B or to authorize transaction Y .
These attacks are affected by practicality aspects. First of all,
an attacker needs to solve two issues:
1)
2)
Put the victim app in a state in which, once the fingerprint
sensor is touched, an unwanted malicious action happens.
Lure a legitimate user to touch the sensor.
8
Second, the attacker needs to steal a fingerprint touch every single
time she wants to perform the attack. However, this last challenge
can be easily addressed: since the fingerprint is often used to
perform “screen unlock” and since the “screen unlock” action is
an action that a user is used to perform tens of times every day, it is
straightforward for an app to create a situation for which the user
would provide a fingerprint.
From a technical standpoint, an attacker can exploit this by