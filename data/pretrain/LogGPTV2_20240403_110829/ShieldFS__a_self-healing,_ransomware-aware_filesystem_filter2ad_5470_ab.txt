2.16
3.21
4.60
8.51
-
2.3 Filesystem Activity Comparison
The remarkable diﬀerences in the features distribution shown
in Table 3 conﬁrms ransomware and benign applications are
diﬀerent ﬁlesystem-wise, and motivates us to exploit these
results to create a full-ﬂedged remediation system.
We focus our analysis on user data, that is, the main
target of ransomware attacks. Contrarily, benign programs,
especially system processes (e.g., services, updates manager),
access large portions of ﬁles in dedicated folders, or in the
system folders. For this reason, we separate the IRP logs of
user folders from the IRPs of system folders. In practice, we
compute the features listed in Table 3 twice: ﬁrst on IRP
logs of user paths only (e.g., excluding WINDOWS or Program
Files), and then on all paths.
3 APPROACH AND METHODOLOGY
For clarity, we logically divide our approach into two parts:
ransomware activity detection and ﬁle recovery. Our ﬁle-
recovery approach is inspired by copy-on-write ﬁlesystems
and consists in automatically shadowing a ﬁle whenever the
original one is modiﬁed, as depicted in Figure 1. Benign
modiﬁcations are then asynchronously cleared for space ef-
ﬁciency, and the net eﬀect is that the user never sees the
eﬀects of a malicious ﬁle encryption.
We consider all ﬁles as “decoys,” that is, we assume that the
malware will reveal its behavior because, indeed, it cannot
avoid to access the ﬁles that it must encrypts to fulﬁll its
goal. The features deﬁned in Table 3 summarize the I/O-level
activity recorded on these decoys into quantitative indicators
of compromise. Thus, the detection and ﬁle-recovery parts
of our approach are tightly coupled, in the sense that we rely
on such decoys to both (1) collect data for detection, and (2)
manage the shadowing of the original ﬁles.
3.1 Ransomware FS Activity Detection
Given the results of our preliminary data analysis in Sec-
tion 2.3, and the aforementioned assumptions and design
decisions, we approach the detection problem as a supervised
classiﬁcation task. Speciﬁcally, we propose a custom classiﬁer
trained on the ﬁlesystem activity features deﬁned in Table 3,
extracted from a large corpus of IRP logs obtained from
clean and infected machines. Once trained, this classiﬁer is
leveraged at runtime to decide whether the features extracted
from a live system ﬁt the learned feature distributions (i.e.,
no signs of malicious activity) or not.
Process- and System-centric FS Models. A malware
can perform all its malicious actions on a single process, or
split it across multiple processes (for higher eﬃciency and
lower accountability). For this reason, our custom classiﬁer
adopts several models. One set of models, called process
Table 2: Statistics of the collected low-level I/O data
from 383 ransomware samples.
Ransomware Family
CryptoWall
Crowti
CryptoDefense
Critroni
TeslaCrypt
Total
No. Samples Data #IRPs
Millions
157 (41.0%)
125 (32.6%)
77 (20.1%)
14 (3.7%)
10 (2.6%)
8.0
5.7
4.5
0.6
0.9
383
19.7
286.7
173.1
171.6
3.0
29.2
663.6
Table 3: We use these features for both our preliminary assessment (Section 2) and as the building block of the
ShieldFS detector (Sections 3 4). ShieldFS computes each feature multiple times while monitoring each process, on
various portions of ﬁlesystem activity, as explained in details in Section 3.1. We normalize the feature values according
to statistics of the ﬁle system (e.g., total number of ﬁles, total number of folders). This normalization is useful to
adapt ShieldFS to diﬀerent scenarios and usage habits. The rightmost column shows a comparison of benign (
) vs.
ransomware (
) programs by means of the empirical cumulative distribution, calculated on the datasets summarized
in Table 1 and 2, respectively. We notice that ransomware activity is signiﬁcantly diﬀerent than that of benign programs
according to our features, suggesting that there is suﬃcient statistical power to tell the two types of programs apart.
Feature
Description
Rationale
Comparison
#Folder-
listing
Number of folder-listing operations nor-
malized by the total number of folders in
the system.
Ransomware programs greedily traverse the ﬁlesystem
looking for target ﬁles. Although ﬁlesystem scanners
may exhibit this behavior, we recall that ransomware
programs will likely violate multiple of these features
in order to work eﬃciently.
#Files-
Read
Number of ﬁles read, normalized by the
total number of ﬁles.
Ransomware processes must read all ﬁles before en-
crypting them.
#Files-
Written
Number of ﬁles written, normalized by
the total number of ﬁles in the system.
Ransomware programs typically execute more writes
than benign programs do under the same working
conditions.
#Files-
Renamed
Number of ﬁles renamed or moved, nor-
malized by the total number of ﬁles in the
system.
Ransomware programs often rename ﬁles appending
a random extension during encryption.
type
File
coverage
Total number of ﬁles accessed, normalized
by the total number of ﬁles having the
same extensions.
Ransomware targets a speciﬁc set of extensions and
strives to access all ﬁles with those extensions. Instead,
benign application typically access a fraction of the
extensions in a given time interval.
Write-
Entropy
Average entropy of ﬁle-write operations.
Encryption generates high entropy data. Although
ﬁle compressors are also characterized by high-entropy
write-operations, we show that the combined use of all
these features will mitigate such false positives. More-
over, we notice that our dataset of benign applications
contains instances of ﬁle-compression utilities.
1
0.8
0.6
0.4
0.2
0
1
0.8
0.6
0.4
0.2
0
1
0.8
0.6
0.4
0.2
0
1
0.8
0.6
0.4
0.2
0
1
0.8
0.6
0.4
0.2
0
1
0.8
0.6
0.4
0.2
0
0 0.20.40.60.8 1
0 0.20.40.60.8 1
0 0.20.40.60.8 1
0 0.20.40.60.8 1
0 0.20.40.60.8 1
0 0.20.40.60.8 1
centric, each trained on the processes individually. A second
model, called system centric, trained by considering all the
IRP logs as coming from a single, large “process” (i.e., the
whole system). The rationale is that the system-centric
model has a good recall for multi-process malware, but has
potentially more false positives. For this reason, the system-
centric model is used only in combination to the process-
centric model.
Incremental, Multi-tier Classiﬁcation. Although our
ﬁle-recovery mechanism is conservative, we want to minimize
the time to decision. Moreover, since the decision can change
over time, all processes must be frequently and eﬃciently
monitored. To obtain an acceptable trade oﬀ between speed
and classiﬁcation errors we adopt two orthogonal approaches.
First, (1) instead of running our classiﬁers on the entire
available process data, we split the data in intervals, or ticks.
Ticks are deﬁned by the fraction of ﬁles accessed by the
monitored process—with respect to the total number of ﬁles
in the system. In this way, we obtain an array of incremental,
“specialized” classiﬁers, each one trained on increasingly larger
data intervals. For instance, when a process has accessed 2%
of the ﬁles, we query the “2%-classiﬁer” only, and so on. Our
experiments (Figure 5) show that this technique reduces the
#IRPs required to cast a correct detection by three orders
of magnitude, with a negligible impact on the accuracy.
Secondly, (2) to account for changes during a process’
lifetime, we monitor both the long- and short-term history.
In practice, we organize the aforementioned incremental
classiﬁers in a multi-tier, hierarchical structure (as depicted
in Figure 2), with each tier observing larger spans of data.
At each tick, each tier analyzes the data up to N ticks in the
past, where N depends on the tier level. We label a process
as “ransomware” as soon as at least one of tiers agrees on
the same outcome for K consecutive ticks. In Section 5 we
show that the choice of K has negligible impact on the false
positives.
Figure 2: Example of the use of incremental models.
At each interval, we check simultaneously multiple in-
cremental models at all applicable tiers.
Example (Code Injection). This example explains how
our incremental, multi-tier models handle a typical case. A
benign process (e.g., Explorer) is running, and has accessed
some ﬁles. For the ﬁrst i ticks ShieldFS will classify it as
benign. Now, the Ransomware process injects its code into
Explorer’s code region. Referring to Figure 2, if Ransomware
does code injection after the 3rd tick, the global-tier model
classiﬁes Explorer as benign, because the long-term feature
values are not be aﬀected signiﬁcantly by the small, recent
changes in the ﬁlesystem activity of Explorer. Instead, the
tier-1 model identiﬁes Explorer as malicious, because the tier-
1 features are based only on the most recent IRPs (i.e., those
occurring right after the code injection). The same applies
for tier-2 models after the 4th tick, and so on. If K = 3,
for instance, and all the triggered tiers agree on a positive
detection, the Explorer process is classiﬁed as malicious at
this point in time. This decision, clearly, can change while
more process history is examined.
3.2 Cryptographic Primitives Detection
Detecting traces of a cipher within a suspicious process mem-
ory, in addition to malicious ﬁlesystem activity, is a further
indication of its ransomware nature. The malware authors’
goal is to eﬃciently encrypt large sets of ﬁles, using a single
master key per victim. Thus, instead of relying directly on
asymmetric cryptography, which is resource intensive, the
strategy is to encrypt each ﬁle with a symmetric cipher and
a per-ﬁle random key, each encrypted with an asymmetric
master secret obtained from the attacker’s control server.
Eﬃcient Block Ciphers. The most widespread, eﬃcient
symmetric-encryption algorithms of choice are fast block
ciphers. These ciphers combine the plaintext with a secret
key through a sequence of iterations, known as rounds. In
particular, the key is expanded in a sequence of values, known
as the key schedule, which is employed to provide enough key
material for the combination during all the rounds. Since
the key expansion is deterministic and depends on the key
alone, it can be pre-computed and reused, with a signiﬁcant
performance gain (e.g., 2 to 4× in case of AES-128). Indeed,
all the mainstream cryptographic libraries (e.g., OpenSSL,
mBED TLS) and the vast majority of ransomware families
do pre-compute the key schedule.
Side Eﬀects. The main side eﬀect of such a pre-computation
technique is that the entire key schedule is (and must remain)
materialized in memory during all the encryption procedure.
We leverage this side eﬀect, and perform a scan of the memory
of the running process, checking, at every oﬀset, whether
the content of the memory can be obtained as a result of
a key schedule computation. Due to the tight constraints
present between the key and the expanded key (i.e., sound key
schedules impose a bijection between them) it is extremely
unlikely that a random sequence of bytes accidentally matches
the result of a key expansion, making false positives very
unlikely. False negatives may occur if the key schedule is not
contiguously stored in memory. However, due to the small
size of the involved data (i.e., less than a single 4kiB page),
such an event is unlikely to happen due to memory allocation
fragmentation.
Note. Although this technique has the beneﬁt of recovering
the secret keys used during the encryption, relying exclusively
on this criterion for ﬁle recovery would not be generic and
future-proof: Since each ﬁle may be encrypted with a dedi-
cated symmetric key, to guarantee the recoverability of all
ﬁles, the memory scanning action should be continuous, and
there is the risk that some keys are simply missed. Instead,
by using our dual approach (i.e., ﬁlesystem and memory
analysis) ShieldFS can guarantee the recoverability of all
ﬁles, regardless of how they are encrypted.
3.3 Automatic File Recovery Workﬂow
When ShieldFS is active, any newly created process enters
a so-called “unknown” state. Whenever such a process opens
a ﬁle handle in write or delete mode for the ﬁrst time (only),
ShieldFS copies the ﬁle content in a trusted, read-only
storage area. This storage can be on the main drive or on
a secondary drive. In either case, ShieldFS denies access
to this area from any userland process by discarding any
modiﬁcation request coming from the upper I/O manager.
From this moment on, the process may read or write such
ﬁle, while ShieldFS monitors its activity. When ShieldFS
has collected enough IRPs, the process goes into a “benign,”
“suspicious,” or “malicious” state.
File copies belonging to “benign” processes can be deleted
immediately or, as ShieldFS does, scheduled for asynchronous
deletion. Since storage space is convenient nowadays, leaving
copies available for an arbitrarily long time delay does not
impose high costs. In turns, it greatly beneﬁts the overall
system performance because, by acting as a cache, it limits
the number of copy operations required when the same ﬁles
are accessed (and would need to be copied) multiple times.
For any process that enters the “malicious” state for at least
one tick, ShieldFS checks the presence of ciphers within
the process. If any are found, it immediately suspends the
process and restores the oﬀended ﬁles. Otherwise, it waits
until K positive ticks are reached before suspending the
process, regardless of whether a traces of ciphers are found.
Processes can enter a “suspicious” state when the process-
centric classiﬁer is not able to cast a decision. In this case,
ShieldFS queries the system-centric model. If it gives a
positive outcome, then the process enters the “malicious”
state. Otherwise the process is classiﬁed as “benign.”
4 SHIELDFS SYSTEM DETAILS
We implemented ShieldFS following the high-level archi-
tecture depicted in Figure 3, and the detection loop deﬁned
in Algorithm 1. We focused on Microsoft Windows because
it is the main target of the vast majority of ransomware
families. We argue that the technical implementation details
may change depending on the target ﬁlesystem and OS’s in-
ternals. However, our approach does not require any special
ﬁlesystem nor OS support. Thus, we expect that it could be
ported to other platforms with modest engineering work.
4.1 Ransomware FS Activity Detection
To intercept the IRPs, ShieldFS registers callback functions
through the ﬁlter manager APIs (i.e., FltRegisterFilter).
log  (% accessed files)Model 1Model 1Model 1Model 1Model 1Model 2Model 2Model 3Model 3Model 1Model 2Global ModeltiersLong-termhorizonShort-termhorizonMonitoring Ticks. ShieldFS gives more relevance to small
variations in a feature value when a process has only accessed
a few ﬁles. At the same time it minimizes the total number of
models needed, so as to contain the performance impact. For
these reasons, the size of each tick grows exponentially with
the percentage of ﬁles accessed by a process. After careful
evaluation, we used 28 tiers, for intervals ranging from 0.1
to 100%, each one corresponding to a distinct model tier.
Adding other ticks beyond 28 would yield no improvements in
detection rates, and would instead penalize the performance.
Countermeasure for Buﬀer-ﬁle Abuse. Some versions
of Critroni exploit one single ﬁle as a write-and-encrypt-
buﬀer. Speciﬁcally, the malware moves the target original
ﬁle in a temporary ﬁle, encrypts it, and then overwrites the
original ﬁle with it. As a result, ShieldFS observes many
renaming operations, followed by many read-write operations
on a single ﬁle, thus biasing the feature values.
To counteract this evasion technique, ShieldFS keeps track
of when a ﬁle is read (or written) right after being renamed
(or moved), such that to update the feature values taking
into account the net, end-to-end eﬀect, as if the buﬀer ﬁle
was not used. This mechanism comes at no extra cost, since
ShieldFS already keeps track of ﬁle-renaming operations.
4.2 Cryptographic Primitives Detection
ShieldFS checks the memory of processes classiﬁed as “sus-