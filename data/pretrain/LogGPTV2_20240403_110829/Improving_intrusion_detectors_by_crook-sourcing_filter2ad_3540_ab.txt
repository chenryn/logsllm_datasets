connection to a confined, unpatched decoy [5, 6]. This approach
retains the most complex part of the vendor patch (the security
check) and replaces the remediation code with some boilerplate
forking code [4], making it easy to implement.
Figure 2 demonstrates the approach using pseudo-code for a
buffer-overflow vulnerability, a conventional patch, and a honey-
patch. The honey-patch retains the logic of the conventional patch’s
security check, but replaces its remediation with a deceptive fork
to a decoy environment. The decoy contains no valuable data; its
purpose is to monitor attacker actions, such as shellcode or malware
introduced by the attacker after abusing the buffer overflow to
hijack the software. The infrastructure for redirecting attacker
connections to decoys can remain relatively static, so that honey-
patching each newly discovered vulnerability only entails replacing
the few lines of code in each patch that respond to detected exploits.
This integrated deception offers some important advantages
over conventional honeypots. Most significantly, it observes attacks
against the defender’s genuine assets, not merely those directed
at fake assets that offer no legitimate services. It can therefore
capture data from sophisticated attackers who monitor network
traffic to identify service-providing assets before launching attacks,
who customize their attacks to the particular activities of targeted
victims (differentiating genuine servers from dedicated honeypots),
and who may have already successfully infiltrated the victim’s net-
work before their attacks become detected. We next examine how
deception-enhanced data harvested in this way can be of particular
value to network-level defenses, such as firewalls equipped with
machine learning-based intrusion detection.
3 ARCHITECTURE
DeepDig’s architecture, depicted in Figure 3, leverages application-
level threat data gathered from attacker sessions redirected to
decoys to train and adapt a network-level IDS live. Within this
framework, honey-patches misdirect attackers to decoys that au-
tomatically collect and label monitored attack data. The intrusion
detector consists of an attack modeling component that incremen-
tally updates the anomaly model data generated by honey-patched
servers, and an attack detection component that uses this model to
flag anomalous activities in the monitored perimeter.
3.1 Monitoring & Threat Data Collection
The decoys into which attacker sessions are forked are managed as
a pool of continuously monitored Linux containers. Upon attack de-
tection, the honey-patching mechanism acquires the first available
container from the pool. The acquired container holds an attacker
session until (1) the session is deliberately closed by the attacker,
(2) the connection’s keep-alive timeout expires, (3) the ephemeral
container crashes, or (4) a session timeout is reached. The last two
conditions are common outcomes of successful exploits. In any of
these cases, the container is released back to the pool and undergoes
a recycling process before becoming available again.
After decoy release, the container monitoring component extracts
the session trace (delimited by acquire and release), labels it, and
stores it outside the decoy for subsequent feature extraction. Decoys
only host attack sessions, so precisely collecting and labeling their
traces (at both the network and OS level) is effortless.
DeepDig distinguishes between three input data streams: (1) the
audit stream, collected at the target honey-patched server; (2) attack
traces, collected at decoys; and (3) the monitoring stream, the actual
test stream collected from regular servers. Each of these streams
protected networkhoney-patched serversregular serverspatched or unpatchedUserAttackerintrusiondetectormonitoring streamaudit streamattack tracesACSAC ’19, December 9–13, 2019, San Juan, PR, USA
F. Araujo, G. Ayoade, K. Al-Naami, Y. Gao, K.W. Hamlen, and L. Khan
Table 1: Packet, uni-burst, and bi-burst features
Category
Packet (Tx/Rx)
Uni-Burst (Tx/Rx)
Bi-Burst (Tx-Rx/Rx-Tx)
Features
Packet length
Uni-Burst size
Uni-Burst time
Uni-Burst count
Bi-Burst size
Bi-Burst time
4.1 Network Packet Analysis
Bi-Di (Bi-Directional) extracts features from sequences of pack-
ets and bursts—consecutive same-direction packets (viz., uplinks
from client Tx, or downlinks from server Rx) for network behav-
ior analysis. It uses distributions from individual burst sequences
(uni-bursts) and sequences of two adjacent bursts (bi-bursts), con-
structing histograms using features extracted from packet lengths
and directions. To overcome dimensionality issues associated with
burst sizes, bucketization is applied to group bursts into correlation
sets (e.g., based on frequency of occurrence).
Table 1 summarizes the features used, including features from
prior works [2, 26, 62, 77]. For robustness against encrypted pay-
loads, we here limit feature extraction to packet headers.
Uni-burst features include burst size (the sum of the sizes of all
packets in the burst), time (the duration for the entire burst to be
transmitted), and count (the number of packets in the burst). Taking
direction into consideration, one histogram for each is generated.
Bi-burst features include time and size attributes of Tx-Rx-bursts
and Rx-Tx-bursts. Each is comprised of a consecutive pair of down-
link and uplink bursts. The size and time of each are the sum of the
sizes and times of the constituent bursts, respectively.
Bi-bursts capture dependencies between consecutive TCP packet
flows. Based on connection characteristics, such as network con-
gestion, the TCP protocol applies flow control mechanisms (e.g.,
window size and scaling, acknowledgement, sequence numbers) to
ensure a level of consistency between Tx and Rx. This influences
the size and time of transmitted packets in each direction. Each
packet flow (uplink and downlink) thereby affects the next flow or
burst until communicating parties finalize the connection.
4.2 System Call Analysis
Monitored data also includes system streams comprised of OS
events, each containing multiple fields, including event type (e.g.,
open, read, select), process name, and direction. Our prototype was
developed for Linux x86_64 systems, which exhibit about 314 dis-
tinct system call events. We build histograms from these using
N-Gram, which extracts features from event subsequences. Each
feature type consists of between 1 (uni-events) and 4 (quad-events)
consecutive events, with each event classified as an enter or exit.
Bi-Di and N-Gram differ in feature granularity; the former uses
coarser-grained bursting while the latter uses individual system
call co-occurrences.
4.3 Classification
We evaluate our approach’s practicality using two supervised learn-
ing models: SVM [22] and deep learning [49]. Our main objective
Figure 3: DeepDig system architecture overview
contains network packets and OS events captured at each server en-
vironment. To minimize performance impact, we used two powerful
and highly efficient software monitors: sysdig [73] (to track system
calls and modifications made to the file system), and libpcap [74]
(to monitor ingress and egress of network packets). Specifically,
monitored data is stored outside the decoy environments to avoid
possible tampering with the collected data.
Deployability. Our monitoring and data collection solution is de-
signed to scale for large, distributed on-premise and cloud deploy-
ments. The host-level telemetry leverages a mainstream kernel mod-
ule that implements non-blocking event collection and memory-
mapped event buffer handling for minimal computational overhead.
This architecture allows system events to be safely collected (with-
out system call interposition) and compressed by a containerized
user space agent that is oblivious to other objects and resources
located in the host environment. The event data streams originated
from the monitored hosts are conveniently exported to a high-
performance, distributed S3-compatible object storage server [59],
designed for large-scale data infrastructures.
3.2 Attack Modeling & Detection
Using the continuous audit stream and incoming attack traces as
labeled input data, DeepDig incrementally builds a machine learn-
ing model that captures legitimate and malicious behavior. The raw
training set (viz. the audit stream and attack traces) is piped into a
feature extraction component that selects relevant, non-redundant
features (see §4) and outputs feature vectors—audit data and attack
data—that are grouped and queued for subsequent model update.
Since the initial data streams are labeled and have been prepro-
cessed, feature extraction becomes very efficient and can be per-
formed automatically. This process repeats periodically according
to an administrator-specified policy. Finally, the attack detection
module uses the most recently constructed attack model to detect
malicious activity in the runtime monitoring data.
4 ATTACK DETECTION
To assess our framework’s ability to enhance IDS data streams, we
have designed and implemented two familiar feature set models:
(1) Bi-Di detects anomalies in security-relevant network streams,
and (2) N-Gram finds anomalies in system call traces. Our approach
is agnostic to the particular feature set model chosen; we choose
these two models for evaluation purposes because they are sim-
ple and afford direct comparisons to non-deceptive prior works.
The goal of the evaluation is hence to measure the utility of the
deception for enhancing data streams for intrusion detection, not
to assess the utility of novel feature sets.
honey-patched serverattack detectionattack modelingfeature extractionclassifiermodel updatemonitoring stream (unknown)monitoring dataalertsserver applicationhoney-patcheddecoy 1decoy n...monitoringaudit stream (normal)labeled attack tracesaudit dataattack dataImproving Intrusion Detectors by Crook-sourcing
ACSAC ’19, December 9–13, 2019, San Juan, PR, USA
Algorithm 1: Ens-SVM
Data: training data: T r ainX , testing data: T estX
Result: a predicted label LI for each testing instance I
1 begin
2
3
4
5
6
7
8
9
B ← updateModel(Bi-Di, TrainX);
N ← updateModel(N-Gram, TrainX);
for each I ∈ TestX do
LB ← label(B, I);
LN ← label(N, I);
if LB == LN then
LI ← LB;
else
(cid:32)
LI ← label
10
end
11
12
13 end
end
(cid:33)
confidence(c , I), I
arg max
c∈{B,N}
;
is to show that our deception-enhanced framework facilitates in-
cremental supervised learning for intrusion detection.
Ens-SVM. This method builds SVM models for Bi-Di and N-Gram.
Using convex optimization and mapping non-linearly separated
data to a higher dimensional linearly separated feature space, SVM
separates positive (attack) and negative (benign) training instances
by a hyperplane with the maximum gap possible. Prediction labels
are assigned based on which side of the hyperplane each monitor-
ing/testing instance resides.
We combine the two classifiers into an ensemble that classifies
new input data by weighing the classification outcomes of Bi-Di
and N-Gram based on their individual accuracy indexes. Ensemble
methods tend to exhibit higher accuracy and avoid normalization
issues raised by the alternative (brute force) approach of concate-
nating the dissimilar features into a single feature vector.
Algorithm 1 describes the voting approach for Ens-SVM. For
each instance in the monitoring stream, if both Bi-Di and N-Gram
agree on the predictive label (line 7), Ens-SVM takes the common
classification as output (line 8). Otherwise, if the classifiers disagree,
Ens-SVM takes the prediction with the highest SVM confidence
(line 10). Confidence is rated using Platt scaling [64], which uses
the following sigmoid-like function to estimate confidence:
P(y = 1|x) =
1
1 + exp(Af (x) + B)
(1)
where y is the label, x is the testing vector, f (x) is the SVM out-
put, and A and B are scalar parameters learned using Maximum
Likelihood Estimation (MLE). This yields a probability measure of
a classifier’s confidence in assigning a label to a testing point.
Metric Learning. To classify instances to classes, we use online
adaptive metric learning (OAML) [9, 30]. OAML is better suited
to our task than off-line approaches (e.g., k-nearest neighbors),
which yield weak predictors when the separation between dif-
ferent class instances is small. Online similarity metric learning
(OML) [14, 19, 37, 39, 52] improves instance separation by finding a
new latent space to project the original features, learning similarity
from a stream of constraints. Pairwise and triplet constraints are
Figure 4: OAML network structure. Each layer Li is a linear trans-
formation output to a rectified linear unit (ReLU) activation. Embed-
ding layers Ei connect to corresponding input or hidden layers. Lin-
ear model E0 maps the input feature space to the embedding space.
typically employed: a pairwise constraint takes two dissimilar/sim-
ilar instances, while a triplet constraint (A, B, C) combines similar
instances A and B with a dissimilar instance C.
We choose adaptive OML since non-adaptive OML usually learns
a pre-selected linear metric (e.g., Mahalanobis distance [79]) that
lacks the complexity to learn non-linear semantic similarities among
class instances, which are prevalent in intrusion detection scenarios.
Moreover, it derives its metric model from well-defined input con-
straints, leading to bias towards the training data. OAML overcomes
these disadvantages by adapting its complexity to accommodate
more constraints in the observed data. Its metric function learns a
dynamic latent space from the Bi-Di and N-Gram feature spaces,
which can include both linear and highly non-linear functions.
t )}T
t , x−
t , x−
t (positive) but dissimilar to x−
OAML leverages artificial neural networks (ANNs) to learn a
metric similarity function and can adapt its learning model based on
the complexity of its input space. It modifies common deep learning
architectures so that the output of every hidden layer flows to an
independent metric-embedding layer (MEL). The MELs output an n-
dimensional vector in an embedded space where similar instances
are clustered and dissimilar instances are separated. Each MEL
has an assigned metric weight to determine its importance for the
models generated. The output of this embedding is used as input
to a k-NN classifier. The approach is detailed below.
Problem Setting. Let S = {(xt , x +
t =1 be a sequence of triplet
t } ∈ Rd, and
constraints sampled from the data, where {xt , x +
t (negative).
xt (anchor) is similar to x +
The goal of online adaptive metric learning is to learn a model
F : Rd (cid:55)→ Rd′ such that ||F(xt ) − F(x +
t )||2.
Given these parameters, the objective is to learn a metric model
with adaptive complexity while satisfying the constraints. The
complexity of F must be adaptive so that its hypothesis space is
automatically modified.
Overview. Consider a neural network with L hidden layers, where
the input layer and the hidden layer are connected to an indepen-
dent MEL. Each embedding layer learns a latent space where similar
instances are clustered and dissimilar instances are separated.
Figure 4 illustrates our ANN. Let Eℓ ∈ {E0, E1, E2, . . . , EL} de-
note the ℓth metric model in OAML (i.e., the network branch from
the input layer to the ℓth MEL). The simplest OAML model E0