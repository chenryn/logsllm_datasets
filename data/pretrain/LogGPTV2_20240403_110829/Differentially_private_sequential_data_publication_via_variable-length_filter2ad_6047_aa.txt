title:Differentially private sequential data publication via variable-length
n-grams
author:Rui Chen and
Gergely &apos;Acs and
Claude Castelluccia
Differentially Private Sequential Data Publication
via Variable-Length N-Grams
Rui Chen
∗
Gergely Acs
Claude Castelluccia
Concordia University
Montreal, Canada
PI:EMAIL
INRIA
France
PI:EMAIL
INRIA
France
PI:EMAIL
ABSTRACT
Sequential data is being increasingly used in a variety of
applications. Publishing sequential data is of vital impor-
tance to the advancement of these applications. However,
as shown by the re-identiﬁcation attacks on the AOL and
Netﬂix datasets, releasing sequential data may pose consid-
erable threats to individual privacy. Recent research has
indicated the failure of existing sanitization techniques to
provide claimed privacy guarantees. It is therefore urgent
to respond to this failure by developing new schemes with
provable privacy guarantees. Diﬀerential privacy is one of
the only models that can be used to provide such guarantees.
Due to the inherent sequentiality and high-dimensionality,
it is challenging to apply diﬀerential privacy to sequential
data. In this paper, we address this challenge by employ-
ing a variable-length n-gram model, which extracts the es-
sential information of a sequential database in terms of a
set of variable-length n-grams. Our approach makes use of
a carefully designed exploration tree structure and a set of
novel techniques based on the Markov assumption in order to
lower the magnitude of added noise. The published n-grams
are useful for many purposes. Furthermore, we develop a
solution for generating a synthetic database, which enables
a wider spectrum of data analysis tasks. Extensive exper-
iments on real-life datasets demonstrate that our approach
substantially outperforms the state-of-the-art techniques.
Categories and Subject Descriptors
H.2.7 [Database Administration]:
and protection]; H.2.8 [Database Applications]:
mining]
[Security,
integrity,
[Data
General Terms
Algorithms, Performance, Security
∗This work was done when the ﬁrst author was on an in-
ternship at INRIA.
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’12, October 16–18, 2012, Raleigh, North Carolina, USA.
Copyright 2012 ACM 978-1-4503-1651-4/12/10 ...$15.00.
Keywords
Diﬀerential privacy, sequential data, n-gram model, Markov
assumption
1.
INTRODUCTION
Sequential data (see a formal deﬁnition in Section 3.1),
such as DNA sequences, web browsing histories and mobil-
ity traces, is being increasingly used in a variety of real-life
applications, spanning from genome and web usage analy-
sis to location-based recommendation systems. Publishing
sequential data is important, since they enable researchers
to analyze and understand interesting patterns. For exam-
ple, mobility traces have become widely collected in recent
years and have opened the possibility to improve our under-
standing of large-scale social networks by investigating how
people exchange information, interact and develop social re-
lationships. With billions of handsets in use worldwide, the
amount of sequential data has been gigantic. When aggre-
gated, it can help understand complex processes (e.g., the
spread of viruses), build better transportation systems, and
prevent traﬃc congestion [20]. While the beneﬁts provided
by sequential data are indisputable, it, unfortunately, poses
considerable threats to individual privacy [19]. In fact, se-
quential data might be used by a malicious adversary to dis-
cover potential sensitive information about a record owner,
such as his habits, religion or relationships. Because privacy
is so important to people, companies and researchers are re-
luctant to publish datasets by fear of being held responsible
for potential privacy breaches. As a result, only very few
of them are actually released and available. This limits our
ability to analyze such data to derive information that could
beneﬁt the general public.
Several sequential data sanitization algorithms have been
presented recently [19], [3]. However, their privacy proper-
ties are still dubious, since they rely on privacy models that
are either ad-hoc or considered weak. It is therefore urgent
to respond to the failure of existing sanitization techniques
by developing new schemes with provable privacy guaran-
tees. Diﬀerential privacy [9] is one of the only models that
can be used to provide such guarantees. The main idea of
diﬀerential privacy is to add noise to a dataset so that an
adversary cannot decide whether a particular record (e.g., a
sequence in our case) is included in the dataset or not. Due
to the inherent sequentiality and high-dimensionality of se-
quential data, it is challenging to apply diﬀerential privacy
to sequential data. In particular, naively adding noise to the
occurrence count of each distinct sequence in the dataset
negatively impacts both privacy and utility. First, unless
638we always release the noisy counts of all possible sequences
(whether in or not in the dataset), which is computationally
infeasible in practice, adding a new record will most likely
entail the inclusion of a new sequence that has not been
present in the dataset. This clearly breaks ε-diﬀerential pri-
vacy and requires to relax the privacy model to the weaker
(ε, δ)-diﬀerential privacy [8]. Second, since most sequences
are unique, the added noise will most likely be much larger
than the actual occurrence counts, which reduces data util-
ity considerably.
In this paper, we demonstrate that there is no need to
release the noisy counts of all possible sequences in order
to retain sequentiality information of a sequential dataset.
Instead, we leverage on the well-established n-gram model,
which has been heavily used in natural language process-
ing [14]. With this model, it is often suﬃcient to publish
the most common n-grams (contiguous subsequences of size
n, where n is typically smaller than 5) for accurately “recon-
structing” the original dataset. This fact positively impacts
both privacy and utility. First, the universe of all grams with
a small n value is relatively small (note that our approach
does not even require to explore the entire universe of all n-
grams), and thus we can employ the stronger ε-diﬀerential
privacy model. Second, the counts of shorter grams are often
large enough to resist noise. Finally, the inherent Markov as-
sumption in the n-gram model allows to reduce the injected
noise and therefore further improves utility.
Contributions. The major contributions of this paper are
three-fold:
• For the ﬁrst time, we introduce the n-gram model as an
eﬀective means of achieving diﬀerential privacy in the
context of sequential data. To better suit diﬀerential
privacy, we propose the use of a novel variable-length
n-gram model, which balances the trade-oﬀ between
information of the underlying database retained and
the magnitude of Laplace noise added. The variable-
length n-gram model intrinsically ﬁts diﬀerential pri-
vacy in the sense that it retains the essential infor-
mation of a sequential dataset in terms of a set of
high-quality n-grams whose counts are large enough
to resist Laplace noise.
• We develop a series of techniques to guarantee good
utility under the variable-length n-gram model, includ-
ing an adaptive privacy budget allocation scheme, a
formal choice of a threshold value, and the enforcement
of consistency constraints. These techniques make use
of the inherent Markov assumption in an n-gram model.
In addition, we develop an eﬃcient method to generate
a synthetic dataset from released n-grams, enabling a
wider spectrum of data analysis tasks.
• We conduct an extensive experimental study on the
variable-length n-gram model over real-life datasets,
which provides important insights for future work. In
particular, we demonstrate that our solution substan-
tially outperforms the state-of-the-art techniques [16],
[4] in terms of count query and frequent sequential pat-
tern mining.
The rest of the paper is organized as follows. We provide a
literature review in Section 2. Section 3 presents the prelim-
inaries of our solution. Section 4 discusses our sanitization
solution in detail. Section 5 gives the formal privacy guar-
antee of our solution. Comprehensive experimental results
are reported in Section 6. Finally, we conclude the paper in
Section 7.
2. RELATED WORK
Sequential data could be considered as a special type of
trajectory data. Due to the ubiquitousness of trajectory (se-
quential) data, some recent works [1], [21], [24], [12], [5], [18]
have been done on privacy-preserving trajectory data pub-
lishing. Abul et al. [1] propose the (k, δ)-anonymity model
based on the inherent imprecision of sampling and position-
ing systems, where δ represents the possible location impre-
cision. They propose to modify trajectories by space trans-
lation so that k diﬀerent trajectories co-exist in a cylinder
of the radius δ. Terrovitis and Mamoulis [21] model an
adversary’s background knowledge as a set of projections
of sequences in a sequential database and propose a data
suppression technique to limit the conﬁdence of inferring
the presence of a location. Yarovoy et al. [24] propose to
k-anonymize a moving object database (MOD) by consid-
ering timestamps as the quasi-identiﬁers. Adversaries are
assumed to launch privacy attacks based on attack graphs.
Monreale et al. [18] present an approach based on spatial
generalization in order to achieve k-anonymity. They de-
velop a generalization scheme that depends on the underly-
ing trajectory dataset rather than a ﬁxed grid hierarchy.
Hu et al. [12] present the problem of k-anonymizing a tra-
jectory database with respect to a sensitive event database
with the goal of ensuring that every event is shared by at
least k users. They propose a new generalization mecha-
nism known as local enlargement, which achieves better util-
ity. Chen et al. [5] consider the emerging trajectory data
publishing scenario, in which users’ sensitive attributes are
published with trajectory data, and consequently propose
the (K, C)L-privacy model that thwarts both identity link-
ages on trajectory data and attribute linkages via trajectory
data. They develop a generic solution for various data utility
metrics by use of local suppression. All these approaches [1],
[21], [24], [12], [5], [18] are built based on partition-based pri-
vacy models, and therefore are not able to provide suﬃcient
privacy protection for sequential data. Compared with the
above works, the major contribution of our paper is the use
of diﬀerential privacy, which provides signiﬁcantly stronger
privacy guarantees.
With the recent emergence of diﬀerential privacy, there
has been extensive research on applying it to non-interactive
privacy-preserving data publishing. Blum et al. [2] demon-
strate that it is possible to release synthetic private databases
that are useful for all queries over a discretized domain from
a concept class with polynomial Vapnik-Chervonenkis di-
mension. However, their mechanism is not eﬃcient, taking
runtime complexity of superpoly(|C|, |I|), where |C| is the
size of a concept class and |I| the size of the universe. Dwork
et al. [10] propose a recursive algorithm for generating a syn-
thetic database with runtime complexity of poly(|C|, |I|).
This improvement, however, is still insuﬃcient to handle
real-life sequential datasets due to the exponential size of
|C|. Xiao et al. [23] propose a wavelet-transformation based
approach for relational data to lower the magnitude of noise,
rather than adding independent Laplace noise. Two recent
papers [17], [6] point out that data-dependent approaches
are more eﬃcient and more eﬀective for generating a dif-
639Table 1: Dataset
Rec. # Sequence
1
2
3
4
5
6
7
8
I2 → I3 → I1
I2 → I3
I3 → I2
I2 → I3 → I1
I3 → I2 → I1
I2 → I3 → I1 → I2 → I3
I3 → I2
I3 → I1 → I2 → I3
Table 2: 1-grams
Gram # Pr
I1
I2
I3
0.21
0.38
0.41
5
9
10
Table 3: 2-grams
Gram # Pr Gram # Pr
0
I1 → I1
2
I1 → I2
I1 → I3
0
I1 → & 3
1
I2 → I1
0
I2 → I2
I2 → I3
6
I2 → & 2
0
0.4
0
0.6
0.11
0
0.67
0.22
Gram # Pr
4
0.4
I3 → I1
0.3
3
I3 → I2
0
I3 → I3
0
I3 → & 3
0.3
ferentially private release. Mohammed et al. [17] propose
a generalization-based sanitization algorithm for relational
data with the goal of classiﬁcation analysis. Chen et al. [6]
propose a probabilistic top-down partitioning algorithm for
set-valued data. Both approaches [17], [6] make use of tax-
onomy trees to adaptively narrow down the output domain.
However, these approaches cannot be directly applied to se-
quential data due to its inherent sequentiality.
To our best knowledge, the paper [4] is the only work that
applies diﬀerential privacy to sequential data release. They
make use of the preﬁx tree structure to group sequences
with the identical preﬁx into the same branch. However,
with the growth of the preﬁx tree, the number of sequences
falling into a branch decreases quickly, resulting in poor util-
ity. In addition, though not dedicated to sequential data,
McSherry and Mahajan [16] develop a method for ﬁnding
frequent (sub)strings. This method also makes use of a pre-
ﬁx structure. In contrast, we make use of the variable-length
n-gram model, which achieves signiﬁcantly improved utility.
3. PRELIMINARIES
3.1 Sequential Database
Let I = {I1, I2, · · · , I|I|} be the universe of items, where
|I| is the size of the universe. The semantic meaning of an
item could be diﬀerent from application to application. For
example, an item could be a station in a transportation sys-
tem, a word in a natural language processing application, or
a nucleobase in a DNA sequence. Each record in a sequen-
tial database is a sequence of (time-)ordered items drawn
from the universe. For instance, a sequence can represent
the movement history of a record owner (i.e., his trajectory),
where each item corresponds to a location visited, or a user’s
password, where each item corresponds to a character.
Formally, a sequence S of length |S| is an ordered list of
items S = L1 → L2 → · · · → L|S|, where ∀1 ≤ i ≤ |S|, Li ∈
I. An item may occur multiple times in S, and may occur
consecutively in S. Therefore, S = I1 → I2 → I2 is a valid
sequence. A sequential database D of size |D| is composed
of a multiset of sequences D = {S1, S2, · · · , S|D|}. Table 1
presents a sample sequential database with I = {I1, I2, I3}.
3.2 N-Gram Model
model based on an (n − 1)-order Markov model.
It can
compactly model large-scale sequential data and provide
scalable trade-oﬀ between storage and accuracy. N -gram
models have been proven to be very robust in modeling
sequential data and have been widely used in probability,
communication theory, computational linguistics (e.g., sta-
tistical natural language processing), computational biology
(e.g., biological sequence analysis), and data compression.
N -gram models estimate the probability of the next item
for a given sequence by making use of the Markov indepen-
dence assumption (of order n − 1) that the occurrence of
each item in a sequence depends only on the previous n − 1
items (instead of all previous items), where n is typically a
small value (e.g., 3-5). Let the probability that a sequence
L1 → L2 → . . . → Li, where Lj ∈ I (∀1 ≤ j ≤ i) and i ≥ n,
is followed by Li+1 ∈ I be denoted by P (Li+1|L1 → L2 →
. . . → Li). Then, under the n-gram model, P (Li+1|L1 →
L2 → . . . → Li) :≈ P (Li+1|Li−n+2 → Li−n+3 → . . . → Li).
N -gram models provide a trade-oﬀ between storage and
accuracy: a larger n value retains more information of the
dataset, but it requires more storage and time to process.
For example, Tables 2 and 3 show the set of all unigrams
and 2-grams, respectively, along with their counts and prob-
abilities for the sample dataset in Table 1, where & is a
special symbol representing the termination of a sequence.
Consider the calculation of the (approximate) number of
occurrences of I3 → I1 → I2 → I3, whose true number is
2. Using 2-grams, one possible approximation is #(I3 →
I1) · P (I2|I1) · P (I3|I2) = 4 · 0.4 · 0.67 = 1.07. In contrast, us-
ing 3-grams, a better approximation could be #(I3 → I1 →
I2) · P (I3|I1 → I2) = 2 · 1.0 = 2.0. However, this better
scheme requires to process all 3-grams at the cost of storage
and time.
3.3 Differential Privacy
Dwork proves that absolute privacy protection is impossi-
ble in the presence of background knowledge [7], resulting in
the notion of diﬀerential privacy based on indistinguishabil-
ity. Diﬀerential privacy [9] requires that the outcome of any
computation be insensitive to the change of a single record.
It follows that any information that can be learned from the
database with a record can also be learned from the one
without this record. Consequently, for a record owner, it
means that any privacy breach will not be a result of par-
ticipating in the database.
Definition 3.1
(Differential privacy). A privacy