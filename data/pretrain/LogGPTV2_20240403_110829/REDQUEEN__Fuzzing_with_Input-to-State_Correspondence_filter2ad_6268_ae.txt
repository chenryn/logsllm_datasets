reported a signiﬁcant higher number of crashes. However, most
of these “crashes” were inputs that exceeded the memory limits
set by the fuzzers. We manually validated the crashes found in
objdump and veriﬁed that neither AFLFAST nor LAF-INTEL
found any real bug, while some of the crashes identiﬁed by
REDQUEEN were indeed novel bugs. This indicates that the
common practice of reporting the number of found crashes can
be a misleading indication and a proper bug triage is necessary.
Case Study: objdump. A surprising observation was
complex constraints
that we were
in objdump that used the hashtable
lookup function
bfd get section by name(bfd* obj, char* name)
to test if a section with the given name is present in the input
object ﬁle obj: Since the function was given two pointer
arguments, REDQUEEN automatically extracted the name and
added it to the dynamic dictionary. The havoc stage was later
able to insert it in the right position. Similarly, the reason
that all other fuzzers show a lower performance on ar is
that ar uses a call to strncmp to check that the ﬁrst few
bytes are “!” or “!”. Usually, LAF-INTEL
is able to split such string compares. However, LAF-INTEL
only considers the functions strcmp and memcmp but not the
size-restricted versions. This is a nice example where more
precise approaches need a very detailed environment model.
Both results demonstrate how the simple over-approximations
we use are actually helpful in real-world applications.
Other Targets. To ensure that our tool is able to ﬁnd novel
bugs, we evaluated the bug ﬁnding ability on a diverse set of
real-world targets. The results can be seen in Table IV. In all
cases, we manually triaged and reported the bugs found. We
started with targets commonly used in other papers, namely
libtiff (tiff2ps) [31], [34], [40], imagemagick [34], [40]
and jhead [16], [28], each in the most recent version of
Ubuntu (16.04 LTS) where these previously reported bugs
should be ﬁxed. Even though these tools have been exhaus-
tively tested previously, we found novel bugs which we triaged
and reported. We also evaluated on a set of media ﬁle format
based tools: sam2p, wine and fdk-aac (a part of ffmpg). In
TABLE IV: Reported bugs found by REDQUEEN
Bugs
3
8
2
1
1
11
4
13
2
3
3
1
1
2
1
1
1
9
65
CVEs
-
-
-
1
1
4
-
1
-a
-a
2
1
-a
1
1
-a
1
3
16
Version
binuitils-2.30-15ubuntu1
binuitils-2.30-15ubuntu1
binuitils-2.30-15ubuntu1
binuitils-2.30-15ubuntu1
binuitils-2.30-15ubuntu1
binuitils-2.30-15ubuntu1
libtiff-4.0.9
3.00-6
v0.1.6
7.0.7-29
wine-2.0.2-2ubuntu1
Commit 51614bbddb5...
Commit 5ed411dd145...
Commit 64447609994...
Commit 35e83488505...
5.26.1...
kernel-4.15.0-15.16
kernel-4.15.0-15.16
Application
ld-new
as-new
gprof
nm-new
cxxfilt
objdump
tiff2ps
jhead
fdk-acc
ImageMagick
wine
mruby
sam2p
bash
libxml2
perl
hfs.kob
ntfs.ko
Total
a CVE assignment pending.
b Simultaneously found and reported by syzbot.
the spirit of the original KAFL paper, we used REDQUEEN
two ﬁle system drivers (speciﬁcally hfs.ko and
to target
ntfs.ko) from the most recent Ubuntu release (16.04 LTS).
In both cases, we found and reported multiple memory corrup-
tions. Lastly, in addition to the (mostly) binary focused targets
we evaluated so far, we also tested multiple well known text-
based targets: mruby, perl, bash and libxml2. In nearly all
of the targets we used our uninformaed seed to ﬁnd the bugs.
This experiment demonstrates that our approach is applicable
not only to user-space code but also to kernel-level code.
Case Study: mruby. One very interesting vulnerability we
found was based on an integer overﬂow in mruby. When
resizing a string, the next power of two was chosen as new
allocation size. The computation could overﬂow, resulting in a
negative size. This was prevented by an additional sign check
after the computation. The compiler realized that powers of
two are always positive and, since signed integer overﬂows
are undeﬁned behaviour in C, removed the check. Therefore,
we were able to produce strings with negative length. Since
the new length was smaller than the old length, no allocation
took place, but the strings length was updated to a negative
value. The resulting string then spans the whole memory range.
This behavior was only present in uninstrumented executables
compiled with gcc and optimization level 2. This bug very
nicely demonstrates why it is important to have techniques that
work effectively on binary-only targets. We strongly suspect
that the overﬂowing integer (a 64-bit values with 19 digits)
was found by the ASCII integer encoding.
E. Baseline Evaluation: PNG File Format
We performed the following experiments to demonstrate
that the improvements gained in our experiments are indeed
due to the proposed techniques. We use the lodepng library,
a small library that can easily be linked statically and which
facilitates the loading of PNG ﬁles. The PNG format is an
interesting case study for common fuzzing roadblocks because
it is based on a list of chunks. Each chunk starts with a
header (identiﬁed by a 4-byte magic value) and contains a
CRC32 checksum over the content. The content of the IDAT
12
Fig. 3: Evaluating the impact of REDQUEEN vs KAFL.
Fig. 4: Evaluating the execution speed on our binutils targets.
chunk is the zlib compressed pixel data, together with another
Adler-32 checksum. In each experiment, we performed 15
runs of one hour each and measured the number of basic
blocks found over the time. The results of the experiments are
displayed in Figure 3. The ﬁgure contains the median number
of basic blocks found at each point in time, as well as the
conﬁdence intervals.
First, we validate that magic bytes are successfully solved
by REDQUEEN but not by KAFL. To do so, we disabled the
two checksum checks in the binary and compare the results for
KAFL, KAFL with a dictionary containing all relevant magic
bytes, and REDQUEEN. The results of this experiment are
displayed in the “Checksums Removed” conﬁguration of Fig-
ure 3. It can be seen that the dictionary massively increases the
coverage produced by KAFL compared to the baseline. How-
ever even without a dictionary provided, REDQUEEN is able
to achieve exactly the same coverage—even though it takes
a little more time to do so. For the next experiment, we use
an unmodiﬁed target to demonstrate that REDQUEEN is able
to overcome checksums. Again, KAFL without REDQUEEN
is evaluated both, with and without a dictionary. Since KAFL
is unable to overcome checksums, it only ﬁnds a very small
number of paths, regardless of the dictionary. REDQUEEN, on
the other hand, is able to identify and solve the relevant check-
sums, and thus achieves as much coverage as in the previous
experiment. In fact, it even ﬁnds a few more basic blocks
(the checksum calculation which is now active). This case
study demonstrates that we are able to overcome checksum;
furthermore, it demonstrates how REDQUEEN is able to deal
with these roadblocks in an automated manner. For vanilla
KAFL, we needed to disable checksums (a task not easily
achieved on closed-source targets) and provided a custom
dictionary to obtain interesting coverage. This experiment
indicate that our techniques are as effective as manually ﬁnding
a good dictionary and removing checksums.
F. Performance
In this experiment, we measure the efﬁciency and effective-
ness of our approach. To measure the efﬁciency, we compare
the overall number of executions per second achieved by
REDQUEEN, KAFL, LAF-INTEL, and AFLFAST. We obtain
a measure for effectiveness by considering the percentage
of inputs found by the different mutation engines used in
REDQUEEN. Lastly, we evaluated the prevalence of the pro-
posed encoding schemes. In all cases, we use the data from
the experiment on the binutils suite in Section V-D.
TABLE V: Number of inputs that trigger paths with new coverage per time
spent using different techniques. The time for our input-to-state based mutator
includes tracing, colorization, and execution of all proposed inputs. In most
cases, input-to-state correspondence produces signiﬁcantly more inputs per
time than any other mutation method used.
Mutation
Input-To-State
Deterministic Stages
Havoc
Splice
Radamsa
Target
ar
size
cxxfilt
strings
nm-new
objdump
readelf
as-new
ar
size
cxxfilt
strings
nm-new
objdump
readelf
as-new
ar
size
cxxfilt
strings
nm-new
objdump
readelf
as-new
ar
size
cxxfilt
strings
nm-new
objdump
readelf
as-new
ar
size
cxxfilt
strings
nm-new
objdump
readelf
as-new
#Inputs
67
465
309
315
1016
1189
1616
717
Time Spend (min)
0.7
7.9
11.2
8.0
24.3
30.7
21.1
31.6
#Inputs/min
98.0
58.7
27.7
39.4
41.8
38.8
76.5
22.7
59
578
706
413
1767
2385
2929
884
32
439
4584
381
1748
2619
1161
1769
18
86
1140
95
780
335
251
510
0
2
237
18
5
3
2
69
35.1
148.9
241.2
287.3
179.6
242.7
331.3
437.3
70.9
149.2
133.1
128.2
167.9
164.0
113.7
75.4
64.5
119.5
152.1
115.1
117.3
68.6
61.5
31.1
422.2
166.0
47.2
43.3