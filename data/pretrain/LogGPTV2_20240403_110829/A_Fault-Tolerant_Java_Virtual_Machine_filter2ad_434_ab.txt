methods that use the JNI interface.
3.3. Non-deterministic Read Sets
Shared memory among threads creates the possibility of
deterministic commands reading different read-set values at
different replicas of a given BEE. We call a read set non-
deterministic if it contains at least one shared variable. Java
allows data to be shared both explicitly, by invoking meth-
ods on a shared object, and implicitly, through static data
references. We could keep track of all shared data or per-
form data race detection as in Eraser [6]. Generally the
bookkeeping necessary to determine which objects are ac-
tually shared can result in a signiﬁcant source of overhead:
for example, an order of magnitude in time for Eraser.
We explore two restrictions to make this problem man-
ageable. One is to assume R4A in Table 1, which requires
every access to a shared variable be protected by a moni-
tor (i.e., that the program is free of data races). Another
way to achieve the same result is to assume R4B, which
requires a run-time environment that enforces exclusive ac-
cess to shared variables while a thread is scheduled (e.g., on
a uniprocessor). Relaxing both restrictions for the general
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 06:58:33 UTC from IEEE Xplore.  Restrictions apply. 
case might require a combination of the approaches above
and agreement on the shared data values.
A Java monitor guarantees exclusive access to shared
variables. In practice, the monitor allows the invoking BEE
to transform temporarily a shared variable into a local vari-
able. To a BEE that invokes a monitor and acquires its asso-
ciated lock, however, the values stored in these temporary
local variables appear to be non-deterministic since they
have been last modiﬁed by some arbitrary BEE. One way
to eliminate this non-determinism would be for the replicas
to agree on the values of the variables associated with ev-
ery lock they acquire. This approach is hard to implement,
however, because Java does not express or enforce the asso-
ciation between a lock and the variables it protects, leaving
this responsibility to the programmer through annotations
or using statistical measures.
Our solution is instead to achieve agreement on the se-
quence of BEEs that acquire each lock. Reaching agreement
on a lock acquisition sequence ensures that the correspond-
ing BEEs at the primary and the backup access the variables
associated with the lock in identical order. Combined with
identical initial values, identical lock acquisition sequences
guarantee all commands executed by corresponding BEEs
have identical read-set values.
Unfortunately, many real programs do not satisfy R4A:
even the JRE provided by Sun does not meet this restriction
for all shared data. In particular, static data members are of-
ten shared between threads without explicit shared method
invocations. As BEE replicas reach agreement on the se-
quence of lock acquisitions, these data races can cause the
state of the primary and backup to diverge, even when the
races do not affect the semantics of the program.
Figure 1 shows a use of static data members without
acquiring a lock. Object shared data, a static data
member, is shared by all Example objects. The guard
on line 4 is not protected by a monitor, which allows dif-
ferent thread schedules at the primary and the backup to
invoke synchronized method a different number of
times, preventing agreement on the sequence of lock ac-
quisitions. Testing our implementation of replicated lock
acquisitions required removing these race conditions in the
JRE by hand! Although the code in Figure 1 contains a data
race, we wanted to ﬁnd a less labor-intensive way to handle
this common (mal)practice.
We also consider an approach for handling shared data
that does not rely on R4A, but assumes R4B instead.
It
eliminates non-deterministic read sets by replicating at the
backup the order in which threads are scheduled at the pri-
mary. When R4B holds on a uniprocessor, the BEE whose
thread is being scheduled effectively changes all its shared
variables to local variables because no other BEE is al-
lowed to execute commands. By replicating the order in
which threads are scheduled, our implementation ensures
that when R4B holds the order of access to shared data is
replicated regardless of whether data races exist.
3.4. Output to the Environment
The state machine approach strives to hide replication
from the environment by requiring output to the environ-
ment to be indistinguishable from what a single correct
state machine would produce. To meet this requirement,
we distinguish between output to the environment that af-
fects volatile state (i.e., state that does not survive failure
of the state machine) and stable state (i.e., state that does).
A particular command can produce multiple outputs to the
environment, each of which is either volatile or stable.
Hiding replication of output is easy if the output is either
idempotent or testable. In the former, the output is indepen-
dent of the number of times the corresponding command is
executed, while in the latter the environment can be tested
to ascertain whether the output occurred prior to failure. For
example, seeking to an absolute offset in a ﬁle is an idem-
potent operation, while seeking to a relative offset is not.
If the current offset can be read, a relative seek becomes a
testable operation. Except for these cases, it is impossible
to maintain the “single correct machine” abstraction in the
presence of failures. For instance, in a primary-backup sys-
tem a backup cannot in general determine whether the pri-
mary failed before or after performing an output command,
and executing the command again could produce different
results. This impossibility result forces us to introduce a fur-
ther restriction R5 in Table 1 that requires all native method
output to the environment be either idempotent or testable.
Replication of volatile output might be necessary for cor-
rect operation. For example, the OS underneath the JVM is
considered part of the environment. Opening a ﬁle at the
primary creates OS state that disappears when the primary
fails and that the backup must replicate if it is to execute
correctly. Some volatile state could be restored simply by
replaying the output (i.e., if the methods are idempotent),
but volatile state generally requires special treatment. For
instance, replaying messages on a socket would not recover
the state at the backup because sending messages is in gen-
eral not an idempotent operation. An extra layer must be
added to make sending messages either an idempotent or
testable operation.
Our protocol uses a novel interface, called side effect
handlers, to replicate the lost volatile state of the primary.
Native methods can create volatile state as an effect of pro-
ducing output to the environment. Using JNI, any applica-
tion may call native methods supplied by the application.
Our interface allows an application programmer to include
methods that replicate the volatile state of the primary cre-
ated by the additional native methods. For example, through
the interface we have included methods to handle ﬁle I/O in
the standard JRE libraries. Restriction R6 in Table 1 re-
quires applications to use this interface whenever they in-
voke a native method that creates volatile state.
4.
Implementation
Sun’s JVM provides two implementations of multi-
threading. The native threads version provides thread
scheduling in the underlying OS, while the green threads
version implements a user-level thread library for a unipro-
cessor inside the JVM. Since R4A depends upon the appli-
cation’s use of locks and not the low-level thread implemen-
tation, both libraries can take advantage of techniques that
achieve replica coordination by replicating the sequence of
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 06:58:33 UTC from IEEE Xplore.  Restrictions apply. 
lock acquisitions. Indeed, multi-processor applications run-
ning with native threads on an SMP can take immediate ad-
vantage of the technique described in Section 4.2.
Enforcing R4B, however, requires changes in the thread
library. Since our ﬁrst goal is to maximize portability, we
have focussed on implementing a replicated thread sched-
uler for green threads. Our approach could be extended to
native threads (see [7])—we leave this as future work.
We add two system threads to the JVM. One performs
failure detection to allow the backup to initiate recovery.
The other is concerned with the transfer of logging infor-
mation, either by sending it (at the primary) or by receiving
it (at the backup). These additional threads join the several
system threads that perform tasks such as garbage collec-
tion and ﬁnalizing objects. We next discuss how our imple-
mentation addresses the challenges (non-deterministic com-
mands, non-deterministic read sets, and output to the envi-
ronment) that we identiﬁed in Section 3.
4.1. Nondeterministic Commands
We checked by direct inspection and categorized all na-
tive methods in the standard libraries of the JRE: fewer that
100 native methods are non-deterministic. We store the
signature of these methods, composed of their class name,
method name, and argument types, in a hash table. Gener-
ally, every time a native method is invoked at the primary,
its signature is checked against those stored in the hash ta-
ble.
If there is a match, then the method’s return values
(including arguments, if they are modiﬁed) and the excep-
tions raised are sent to the backup, which keeps an identical
hash table. Before executing a method during recovery, the
backup checks if it is stored in the hash table.
If so, the
backup always uses the corresponding return values and ex-
ceptions, whether or not it actually invokes the method. If
the method is indeed invoked in order to reproduce volatile
output, the backup discards the generated return values and
exceptions. The side effect handlers discussed later provide
an extra layer to handle speciﬁc cases where the return value
may reﬂect volatile environment state (e.g. returning a ﬁle
descriptor from a ﬁle open command).
4.2. Nondeterministic Read Sets
Data races and scheduling differences among the JVM’s
threads can make read sets containing shared variables re-
turn different values at the primary and the backup. We use
two different approaches to make read sets deterministic.
Replicated Lock Synchronization. The ﬁrst approach
relies on the assumption R4A that all shared data is pro-
tected by locks that, if correctly acquired and released, en-
sure mutual exclusion. Under this assumption, we create a
mechanism that guarantees that threads acquire locks in the
same order at the primary and at the backup.
Replicating the order in which threads acquire locks re-
quires identifying the locking thread, the lock, and the rel-
ative order of each lock acquisition. We store this informa-
tion in a lock acquisition record, which is a tuple of the form
(t id, t asn, l id, l asn) where:
t id is the thread id of the locking thread.
t asn is the thread acquire sequence number recording the
number of locks acquired so far by thread t id.
l id is the lock id.
l asn is the lock acquire sequence number recording the
number of times lock l id has been acquired so far.
These records are created by the primary, but they are
used during recovery by the backup. Therefore, for each
thread and lock, the primary needs to generate virtual t ids
and l ids that are unambiguous across replicas. For in-
stance, although in the JVM each lock is uniquely asso-
ciated with an object, the primary cannot simply use the
object’s address as the lock’s l id, because this address is
meaningless at the backup. Further, any scheme that as-
signs ids according to the order in which events—such as
thread and object creation—occur at the primary is danger-
ous, since these events might be scheduled differently at the
primary and the backup.
We then deﬁne recursively the id of a thread t as consist-
ing of two values: i) the id of the parent thread of t (the par-
ent of the ﬁrst thread has by convention t id = 0) and ii) an
integer that represents the relative order in which t is created
with respect to its siblings. This deﬁnition is well founded
because, although the absolute order in which t is created
does depend on the order in which threads are scheduled,
t’s parent spawns its descendants in the same relative order
at the primary and the backup, independent of scheduling.
To assign a lock its l id, we observe that threads execute
deterministic programs. Hence, the sequence of locks ac-
quired by a thread with a given virtual t id is identical at
the primary and the backup. We can then uniquely identify
a lock by specifying the t id and the t asn of the ﬁrst thread
that acquires the lock at the primary. We get an even sim-
pler l id as follows. When the primary acquires a lock for
the ﬁrst time, it assigns to the lock a locally unique value
(our l id is simply a counter); it then creates an id map,
which is a tuple of the form (l id, t id, t asn) that associates
the l id with the appropriate t id and t asn. Each map is
then logged at the backup.
During failure-free execution, whenever the primary ac-
quires lock l id, it generates a corresponding lock acquisi-
tion record and logs it at the backup. If the primary fails,
then the backup’s threads use the logged id maps and acqui-
sition records to reproduce the sequence of lock acquisitions
performed by the corresponding threads at the primary.
When a backup thread t tries to acquire a lock with id l,
it checks if the log contains a lock acquisition record with
t id = t and l id = l, and t asn equal to the current value
of t’s acquire sequence number. If such a record r exists,
then t waits for its turn for acquiring lock l—that is, t waits
until l’s acquire sequence number is equal to the value of
l asn stored in r, acquires the lock, and removes r from the
log. If the log contains no such record, then t waits until the
log contains no more lock acquisition records (indicating
the end of recovery at the backup) before it acquires lock l.
The case in which a backup thread t attempts to acquire
a lock that still has no l id requires special treatment. First,
t checks if it is its responsibility to assign the id to the lock.
The thread looks for an id map with t id = t and match-
ing t asn; a match implies that, before the primary failed,
Proceedings of the 2003 International Conference on Dependable Systems and Networks (DSN’03) 
0-7695-1959-8/03 $17.00 (c) 2003 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 06:58:33 UTC from IEEE Xplore.  Restrictions apply. 
thread t at the primary assigned to that lock the l id stored
in the id map. If a match is found, the corresponding map is
removed from the log and the id of the lock is set to l id.
If a match is not found, then either (i) the lock was as-
signed its l id at the primary by a different thread t(cid:1)
, or (ii)
no primary thread logged an id map for the lock before the
primary failed. Thread t handles these two cases by waiting,
respectively, until either t(cid:1)
assigns the l id at the backup or
until the log contains no more maps, in which case t can
safely assign a new l id to the lock.
This approach only replicates the lock acquisition se-
quence, which may require extra synchronization when or-
dering is important. If multiple threads are interacting with
the environment (e.g., reading or writing a log) and the
interleaved order is important, then synchronization is re-
quired to ensure an identical order between the primary and
the backup even if the synchronization is not required for
correctness at the primary.
Replicated Thread Scheduling. The second approach
relies on the assumption R4B that the scheduling lock pro-
tects all shared data. Whenever the primary interrupts the
execution of a thread t to schedule a new thread, it sends a
thread scheduling record to the backup, which uses it dur-
ing recovery to enforce the primary’s schedule. A record is
comprised of (br cnt, pc off, mon cnt, l asn, t id), where:
br cnt counts the control ﬂow changes (e.g., branches,
jumps, and method invocations) executed.
pc off records the bytecode offset of the PC within the
method currently executed by t.
mon cnt counts the monitor acquisitions and releases per-
formed by t.
l asn records the lock acquisition sequence number when t
is rescheduled while waiting on a lock.
t id is the thread id of the next scheduled thread.
The basic scheme for tracking how much Java code t
executed before being rescheduled is simple, and it is im-
plemented by the ﬁrst two entries in the schedule record.
Rather than counting the number of bytecodes, which would
add overhead to every instruction, we instrumented the JVM
to increment br cnt for each branch, jump, and method in-
vocation. Further, since the program counter address is
meaningless across replicas, we store in pc off the last byte-
code executed by t as an offset within the last method ex-
ecuted by t. Unfortunately, in our implementation this re-
quires an update to the thread object after executing every
bytecode because it is hard to determine, when t is resched-
uled, where the JVM is storing its program counter, whose
value is needed to calculate pc off.
A ﬁrst complication over this simple scheme arises when
t is rescheduled while executing a native method. Native
methods are opaque to the JVM: we have no way of deter-
mining precisely when t is rescheduled. Often this is not a
problem: when repeating t’s schedule during recovery, the
backup reschedules t right before the native method is in-
voked. This is unacceptable, however, if t, while execut-
ing within the native method, acquires one or more locks:
reproducing the lock acquisition sequence is necessary for
correct recovery, because it is this sequence that determines
the value of shared variables. Fortunately, whenever a lock
is acquired or released, control is transferred back inside the
JVM. Our implementation intercepts all such events, inde-
pendent of their origin, allowing us to correctly update the
value stored in mon cnt. In this case, instead of reschedul-
ing t during recovery before invoking the native method, we
allow t to execute within the native method until it performs
the number of lock acquisitions stored by the primary in
mon cnt.
Further complications come from the interaction of ap-
plication threads and system threads. System threads do
not correspond to a BEE executing application code, and
several do not execute Java code at all (e.g., the garbage