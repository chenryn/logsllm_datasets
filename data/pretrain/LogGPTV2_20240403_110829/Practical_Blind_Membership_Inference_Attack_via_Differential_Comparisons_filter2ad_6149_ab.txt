differential comparison. In practice, this atomic step is repeated
until no more samples can be moved: The series of moves
with a ﬁxed d is deﬁned as one iteration. Then, differential
comparison will update d based on new Sprob,k
nonmem
for another iteration until the distance d does not change across
iterations, called convergence.
target and Sprob,k
target and Sprob,k
There are two things worth noting here. First, differential
comparison moves one sample instead of removing it so as
to maximize the distance change. Removal of a sample only
changes the position of Sprob,k
target with regards to the decision
boundary in the hyper-dimensional space (like Figure 1); as
a comparison, moving the sample changes the positions of
both Sprob,k
nonmem, thus improving the algorithm’s
sensitivity. Second, even after convergence, there may still
exist some nonmembers left in Sprob,k
target, i.e., the moving of
these samples does not increase the distance between Sprob,k
target
and Sprob,k
nonmem. This is a lower probability situation, as shown in
our evaluation of differential comparison’s performance, and
that this is as to be expected due to an inherent ambiguity
between members and non-members.
III. DESIGN
In this section, we describe a detailed design of BLINDMI.
A. Overall Attack Procedure
We now describe the overall procedure of BLINDMI in
Figure 2. BLINDMI takes target samples with unknown mem-
bership and outputs a membership result for each individual
sample. Speciﬁcally, BLINDMI ﬁrst generates a non-member
dataset and then queries the target DNN model with the target
and the non-member datasets to obtain the output probabilities.
Then, BLINDMI applies a projection function to select certain
important features from the output probabilities. The next step
depends on different variations of BLINDMI. BLINDMI-DIFF
adopts differential comparison to classify members and non-
members in the target dataset; BLINDMI-1CLASS trains a one-
class model from the selected output probabilities of the non-
member and classiﬁes samples in the target dataset using the
trained model. We list different variations of BLINDMI in
Table III. Both the BLINDMI-DIFF-w/ and BLINDMI-1CLASS
require a generated nonmember set as opposed to BLINDMI-
3
!!"#$%&’&()"*+,!Non-membersMembersd(1)(2)Non-membersMembersd’(1)(2)Non-membersMembersd’’Non-membersMembersd’>dd’’<d!!"#$%&’&()"*+,!!!"#$%&’&(#)*+,+!!!"#$%&’&(#)*+,+!!!"#$%&’&(#)*+,+!!!"#$%&’&()"*+,!CentroidDistanceDecision BoundaryFig. 2. Overall Attack Procedure of BLINDMI
TABLE IV.
Options
METHODS IN GENERATING NON-MEMBERS
Description
Sample transform
Random perpetuation
Random generation
Cross domain
Laplace, Sobel, Scharr, and Canny
Gaussian or Salt Pepper noise
Random feature values
Samples from a different domain
DIFF-w/o that does not require it. The default BLINDMI is
BLINDMI-DIFF-w/. We introduce BLINDMI-DIFF-w/o since
it may be hard to create an effective nonmember set in some
cases and the created set could be contaminated; at the same
time, we introduce BLINDMI-1CLASS more as a baseline to
separate the effectiveness of differential comparison and the
generation of a nonmember set.
Next, we introduce two different modes of BLINDMI:
batch and incremental. The batch mode takes and classiﬁes
a batch of target samples iteratively and the incremental mode
takes one sample, adds to a previous batch, and then classiﬁes
the target. It is worth noting that both modes give the same
inference results for given samples. They are designed to
handle different scenarios: The batch mode for a cluster of
samples and the incremental mode for each individual sample.
B. Dataset Preparation for Differential Comparison
In this subsection, we describe how to generate non-
members for a target model. There are two general directions
of non-member set generation: (i) generating new samples
or transforming existing ones and (ii) roughly separating a
set with existing samples into two with members and non-
members.
1) Generation of Non-members: Let us start from the ﬁrst
direction. This is applicable if an adversary can probe the target
model with arbitrary samples. From a high-level perspective,
because the input space is usually much larger than the training
set, the adversary can generate a new sample, which is likely
not in the training set. We now discuss four generation methods
below and in Table IV.
• Sample Transformation. An adversary applies an operator,
e.g., Laplace, Sobel, Scharr, and Canny, on an existing
sample to obtain a new one. Take Sobel for example: the ad-
versary transforms an image to one emphasising edges. The
advantage of this method is that it usually preserves some
semantics, thus being effective to be distinguishable from
members. Additionally, the generated sample is stealthy as
all the operators are commonly used in image processing.
The down-side of this method is that many operators are
speciﬁc to the image domain.
• Random Perpetuation. An adversary adds random noises,
like Gaussian and Salt Pepper, to an existing sample for the
generation. This method is also effective as many semantics
are preserved, but less stealthy because one may detect noise
levels in the frequency domain.
• Random Generation. An adversary generates a sample
with random features. This method is less effective as the
generated samples, e.g., a random image, may not have any
semantics, and less stealthy as any human can easily spot
the generated sample as a noise.
• Cross-domain Samples. An adversary may adopt samples
from another domain, e.g., a celebrity face dataset for a
model trained with CIFAR-100. This is also effective but less
stealthy, because the probed samples are apparently from a
different domain.
Note that samples generated following Table IV are highly
likely non-members. Therefore, these samples can be used in
both BLINDMI-1CLASS and BLINDMI-DIFF, particularly the
training set of BLINDMI-1CLASS and the comparison set of
BLINDMI-DIFF.
2) Rough Sample Separation: We then describe the second
direction. This is applicable when the adversary does not
have free probing access to the target model, but only obtain
the output probability distribution of a limited dataset. This
scenario may happen if the adversary is only allowed to probe
samples from a certain source, e.g., disease images acquired
at a speciﬁc hospital. There are two different methods used
in such separation: (i) a clustering algorithm like k-means
and agglomerative clustering, and (ii) a separation based on
the highest probability score. The ﬁrst method is to apply
clustering to roughly divide the target dataset into two, one
as members and the other as non-members. The second is to
4
!!"#$%&’&()"*+,!!!"#$%&’&(#)*+,+!!!"#$%&’"()*!!!"#$%&#’()*)""!Batch ModeIncremental Mode!!!!!!!!!!!"#"$%&%""!!!"#$%&’!Target DNNProjection functionDiﬀerential Comparison!!"#$%&’&()"*+("#!!"#$%’&"+,(#∪#!!"#$%’&!"+-%.#./+/#!!!"#$%&’"()*!!!"#$%&’!"()%*#*+(+!after convergencenon-membersmembersTarget SampleTarget DNNprobProjection functionprob,k!!"#$%&’&()"*+("#!!"#$%’&"+,(#∪#$%&’()*+!!!"#$%&’&(#)*+,+!Diﬀerential ComparisonORInputBlindMI-diﬀOutputiteration!!"#$%&’&(#)*+,+!!!"#$%&#’()*)""!!!!!!!!!!!!"#"$%&%""!Target DNNOne-class SVMtraininputORBlindMI-oneclassTarget Sampleprobprob,k{prob, k}roughly select those with high probability score as members
and those with low as non-members. This generation is only
applicable to BLINDMI-DIFF, because the non-member set
may be noisy.
C. Probability Score Projection
We now discuss our probability score projection function
Gprojection,k, which applies on Sprob
target to obtain k different
elements. The high-level idea is that class types, e.g., a bird
vs. a tree, are less important features for an MI attack,
but the ranking of values in different classes determines the
membership. Based on this insight, we design three different
projection functions.
• All probability scores in an order. This projection function
ranks all probability scores from the largest to the smallest,
which removes the class information but only keeps the
relative values.
• Top-k probability scores. This projection function selects
the top-k probability scores to further remove some noisy
ones with small values.
• Top-k + Ground Truth Class. This projection function—
used in the blackbox setting—further includes the value
corresponding to the ground truth class.
D. Differential Comparison
In this section, we describe one key technique, i.e., differ-
ential comparison, in this paper. The ﬁrst task is to calculate
the distance between two sets. Just like all general ML tasks,
it is hard to differentiate member and non-members directly in
the output probability distribution space. Therefore, BLINDMI
maps all probabilities to the Reproducing Kernel Hilbert Space
(RKHS) [4] and then calculates the distance between two
centroids in the kernel space. Speciﬁcally, our distance, based
on Maximum Mean Discrepancy (MMD) [18], is shown in
Equation 1.
(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13) 1
nt
nt(cid:88)
i=1
nn(cid:88)
j=1
(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)ν
D(Sprob,k
target , Sprob,k
nonmem) =
φ(yi) − 1
nn
φ(y(cid:48)
j )
(1)
j ∈ Sprob,k
where yi ∈ Sprob,k
target, y(cid:48)
nonmem, nt and nn are the size of
Sprob,k
nonmem, ν is the dimension of the kernel space,
target and Sprob,k
and φ is a feature space map k (cid:55)→ ν, e.g., a Gaussian kernel
function k(y, y(cid:48)) = (cid:104)φ(y), φ(y(cid:48))(cid:105) = exp(−||y − y(cid:48)||/(2σ2)).
The second task is to perform differential comparison
between two sets. There are two variations of differential com-
parison, single- and bi-directional, which deﬁnes the direction
in moving samples between two sets.
target to Sprob,k
1) Single-directional Differential Comparison:
This
method iteratively moves samples from Sprob,k
nonmem,
compares the distance before and after move, and then
determines the moved sample’s membership. Details of the
method are shown in Algorithm 1. Lines 1–2 of Algorithm 1
prepare some initial variables and then Lines 3–14 are
the iterative algorithm. Speciﬁcally, Line 5 ﬁrst calculates
the distance between two sets and Lines 6–12 go through
all
target. If the updated distance after
moving a sample (Line 7) is larger than the original (Line
8), BLINDMI-DIFF considers it as a non-member. After one
iteration, BLINDMI-DIFF updates Sprob,k
target (Line 13) and starts
the entire process again.
the elements in Sprob,k
5
nonmem, Sprob,k
target
f lag ← f alse
d ← D(Sprob,k
for y ∈ Sprob,k
Algorithm 1 Single-directional Differential Comparison
Input: Sprob,k
Output: Spred,nonmem, Spred,mem
1: Spred,nonmem ← empty
2: f lag ← true
3: while ﬂag do
4:
5:
6:
7:
8:
9:
10:
end if
11:
end for
12:
target ← Sprob,k
Sprob,k
13:
14: end while
15: Spred,mem ← Sprob,k
target − {y})
Spred,nonmem ← Spred,nonmem ∪ y
f lag ← true
nonmem, Sprob,k
target )
target do
d(cid:48) ← D(Sprob,k
if d(cid:48) ≥ d then
target − Spred,nonmem
nonmem ∪ {y}, Sprob,k
target
target2
target2)
target1, Sprob,k
target1 − {y})
f lag ← f alse
d ← D(Sprob,k
for y ∈ Sprob,k
target1 ← Sprob,k
Sprob,k
target2 ← Sprob,k
Sprob,k
f lag ← true
d ← d(cid:48)
target1, Sprob,k
target1 do
d(cid:48) ← D(Sprob,k
if d(cid:48) ≥ d then
target2 ∪ {y}, Sprob,k
target1 − {y}
target2 ∪ {y}
Algorithm 2 Bi-directional Differential Comparison
Input: Sprob,k
Output: Spred,nonmem, Spred,mem
1: f lag ← true
2: while ﬂag do
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
end for
22:
23: end while
24: Spred,mem, Spred,nonmem ← Sprob,k
target1 ∪ {y}, Sprob,k
target2 − {y}
target1 ∪ {y}
target2 ← Sprob,k
Sprob,k
target1 ← Sprob,k
Sprob,k
f lag ← true
d ← d(cid:48)
target2 do
d(cid:48) ← D(Sprob,k
if d(cid:48) ≥ d then
end for
for y ∈ Sprob,k
target2 − {y})
target1, Sprob,k
target2
end if
end if
target2 and Sprob,k
target2 → Sprob,k
target2, and moves samples in both directions,
2) Bi-directional Differential Comparison: This method
works on a roughly divided two datasets, say Sprob,k
target1
and Sprob,k
i.e.,
target1 → Sprob,k
Sprob,k
target1. More speciﬁ-
cally, the method details are shown in Algorithm 2. BLINDMI-
DIFF ﬁrst moves samples from Sprob,k
target2 in Lines
5–13, and then Sprob,k
target1 in Lines 14–22. Then,
BLINDMI-DIFF iterates the entire procedure until it converges.
Note that one major challenge here is to decide whether
target1 or Sprob,k
Sprob,k
target2 contains non-members, as those two sets
are symmetric and look the same. The intuition here is that the
average prediction conﬁdence score of members is higher than
the one of non-members. Therefore, BLINDMI-DIFF compares
the average conﬁdence score for a decision in the end.
target2 to Sprob,k
target1 to Sprob,k
TABLE V.
A DESCRIPTION OF DIFFERENT DATASETS USED IN THE EVALUATION.
Dataset
# of classes Description
Resolution # Epochs (target model) Training set (target model) Training set (shadow model) Target set
Adult
EyePACS
CH-MNIST
Location
Purchase-50
Texas