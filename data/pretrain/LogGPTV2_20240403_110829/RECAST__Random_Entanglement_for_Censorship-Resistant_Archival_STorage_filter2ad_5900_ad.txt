### System Architecture and Deployment

The system is built using Flask [31] (v0.12.13) and exposed through uWSGI [32] (v2.0.15). The storage backends can be commercial cloud storage providers such as Google Drive, Dropbox, Microsoft OneDrive, and Amazon S3, or self-hosted key-value stores like Redis [33] and Minio [34]. For evaluation purposes, we deploy the storage nodes on-premises. To manage metadata access, repair, and replica management processes, we use ZooKeeper [35]. All components are containerized and deployed using Docker [36] (v17.05.0-ce).

### Evaluation

In this section, we evaluate RECAST's performance and resilience to data loss. We first test the prototype's performance, focusing on the raw throughput of the entanglement process in isolation, the metadata storage overhead, and the resulting repair capabilities. Subsequently, we experimentally test the security properties of our architecture against both active and passive adversaries.

#### Micro-benchmark: Encoding/Decoding Throughput

We begin by evaluating RECAST’s throughput for raw encoding and decoding operations. These results were obtained on an Intel Broadwell 64-core machine with 128 GB of RAM running Ubuntu 16.04 (kernel 4.4.0-101). Figure 9 presents the results for six configurations of STEP, each with different numbers of pointers and code rates. Note that some configurations, such as (5,*, 2, 7), are too brittle for practical use but are included to illustrate the impact of STEP tuning on various metrics. We measure the throughput variations across these configurations with three different document sizes: 4 MB, 16 MB, and 64 MB.

While the size of the incoming documents directly affects the performance, especially when codewords fit into low-level caches (e.g., L3-caches on our servers), the most significant factor is the storage overhead. Both in encoding and decoding, results can be grouped according to storage overhead (nu-(1,*, 2, 3) and nu-(5,*, 2, 7)). The number of pointers also impacts throughput, with a predictable slowdown as the number of pointers increases.

For the nu-(1,*, 2, 3) group, the throughput halves every time the number of pointers doubles. For example, to encode a 16 MB document, the throughput drops from 63 MB/s (t = 5) to 36 MB/s (t = 10) and finally to 19 MB/s (t = 20). For the nu-(5,*, 2, 7) group, the slowdown is less pronounced, at 15-20% for each doubling of pointers. For a 16 MB document, the throughput decreases from 297 MB/s (t = 1) to 254 MB/s (t = 2) and finally to 205 MB/s (t = 4).

In conclusion, Figure 9 illustrates the trade-offs in choosing a STEP configuration. It may offer good protection, such as nu-(1, 20, 2, 3), but at the expense of lower throughput (up to 18.84 MB/s when encoding). Alternatively, a very fragile configuration like nu-(5, 1, 2, 7) can achieve up to 690 MB/s.

#### Full System Performance

When integrated into the full system, we compare the performance of our entangled archive against the standard Reed-Solomon (RS) code provided by Intel ISA-L. Using the YCSB [37] framework, we run two workloads of 1000 operations: a read-oriented one based on YCSB’s workloadc and a pure insert one. Both workloads involve 1000 operations with payloads ranging from 4 MB to 16 MB. We deploy a RECAST instance on a single machine (64 cores and 128 GB of RAM) hosting the proxy, coder, metadata, and 16 storage nodes. This experiment is run with 8 concurrent threads from a remote machine connected to the RECAST host via a 1 GB switched network.

As shown in Figure 10, the entanglement process slows down operations by approximately 10x. This can be attributed to the volume of pointers that flow through the system (10 times the size of the original data) and the necessary manipulations of the pointer blocks.

#### Storage Overhead

Next, we examine the storage overhead introduced by our prototype. While the STEP configuration, the number of documents, and their average size affect storage requirements, the metadata growth (Figure 11) is more dependent on our implementation. The differences across STEP configurations are due to the varying number of pointer blocks t: as t increases, so does the protection offered by the archive, leading to an increase in the number of entanglement links to maintain. Better normalization of the metadata database could reduce this overhead.

#### Document Removal

In Figure 12, we study the bandwidth cost of deleting a document from the archive. Deletion involves a three-phase process: finding a complete set S of documents entangled with the target, decoding the documents in S, and re-encoding these documents with other pointers. The accuracy of the first step determines the cost of the actual deletion. We compute the number of documents in set S from the results shown in Figure 6. The cost of the last two steps depends on the RS code used in the STEP-archive. In Figure 12, we present results for a (1, 5, 2, 3)-archive with different entanglement strategies. The block size corresponds to the document size (1 kB in the plot), and we compute 3 parity blocks out of the source and pointers using a RS(9, 6) code. Decoding and re-encoding require fetching 6 and sending 3 blocks per document, respectively. The constant bandwidth required for normal entanglement is determined by the constant protection offered to documents. When using nu-entanglement on an archive of 1 kB documents, erasing d100000 and d500000 from the archive requires the transfer of 2.7 GB and 0.55 GB, respectively.

#### Metadata Reconstruction and Document Availability

Figure 13 shows the system's capacity to rebuild the metadata in case of the metadata server's loss. It depicts the number of documents for which enough metadata has been scraped to be served through the proxy. This result demonstrates how RECAST behaves in two different STEP configurations, each with two different replication factors (none or 3-replication). If all blocks are replicated, we can expect to serve all documents before reading from all storage nodes, as depicted by the full-point lines. Conversely, if no blocks are replicated, a large number of storage nodes need to be crawled to gather sufficient information about the entire system. When running a RECAST instance configured with nu-entanglement and replication management enabled, the number of replicated blocks remains constant as the archive grows. Consequently, the number of nodes that need to be explored to rebuild a functional archive increases over time. With respect to the archive's history, the metadata reconstruction process is initially fast but slows down over time, depending on the number of replicated blocks.