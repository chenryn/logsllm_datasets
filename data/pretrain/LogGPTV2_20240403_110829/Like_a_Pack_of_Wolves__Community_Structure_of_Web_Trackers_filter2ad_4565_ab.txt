V. Kalavri et al.
1.00
0.75
F
D
C
0.50
0.25
0.00
kind
Other
Tracker
1.00
0.75
F
D
C
0.50
0.25
0.00
kind
Other
Tracker
100
Ratio of tracker neighbors over all neighbors
10−1
10−2
10−3
100
Ratio of tracker neighbors over total trackers
10−1
10−3
10−2
(a) Ratio of the projection graph vertices’
neighbors that are trackers.
(b) Ratio of a node’s tracker neighbors over
the total number of trackers in the dataset.
Fig. 4. CDFs of neighborhood compositions for trackers and non-trackers.
Fig. 5. Tracker oriented visualization of the hosts-projection graph from April’s logs.
The visualization includes only edges where at least one end point is a tracker, resulting
in 60 k vertices and 340 k edges. The darker a vertex’s color, the higher its degree. The
community on the right contains trackers and ad servers, where ad servers can be seen
as having a slightly lighter color and being mostly clustered on the left edge of the
community. The left cluster consists of normal webpages and a few popular trackers,
distinguished by their larger size and darker color (Color ﬁgure online).
the other trackers in the graph. This result is likely an artifact of publishers’
tendency to add multiple trackers on their websites in the hope of serving better
targeted ads.
From a privacy standpoint, this result is worrying as it highlights the per-
vasiveness of passive “surveillance” on the web. Even completely blocking any
particular tracker could be somewhat mitigated by collusion. We do note that
because the hosts-projection graph ﬂattens the referer-hosts graph, collusion
would not be enough to regain information on visits to pages where it is uniquely
present.
Our ﬁndings up until now suggest that trackers form a dense community in
the hosts-projection graph. This dense community is quite clearly seen in Fig. 5,
which visualizes the host-projection graph (from April’s logs) focused around
trackers’ positions. We observe that the majority of low-degree trackers indeed
Like a Pack of Wolves: Community Structure of Web Trackers
49
Table 1. New trackers per month
Test records in LCC Trackers in LCC Total new trackers
February 13685
March
April
18313
40465
760
740
747
811
774
792
form a very dense and easily identiﬁable community (the cluster on the right).
On the other hand, there exist a few popular trackers (the large dark nodes in
the left cluster), which are connected to the majority of normal URLs and are
also very well-connected among each other.
4 Classifying Trackers
Our ﬁndings suggest that trackers form a well-connected cluster in the hosts-
projection graph, and are mostly connected to other trackers. In this section,
we leverage these ﬁndings to automatically classify trackers. We show that even
a simple assessment of vertices’ neighbors in the hosts-projection graph can
yield good classiﬁcation results with two methods: (1) a rule-based classiﬁer
which analyzes the ﬁrst-hop neighborhoods of each unlabeled vertex in the hosts-
projection graph, and (2) an iterative label propagation method.
4.1 Classiﬁcation via Neighborhood Analysis
This classiﬁcation method analyzes the ﬁrst-hop neighborhoods of each unla-
beled node in the hosts-projection graph. For each unlabeled node, we count
the number of trackers among its immediate neighbors and make a classiﬁcation
decision based on a conﬁgurable threshold. If the percentage of tracker neighbors
is above the threshold, then the node is labeled as a tracker.
We evaluate our classiﬁer using three subsets of our dataset. For every subset,
we use all the hosts that appear in the last month as the test set and all the
previous months as the training set. Thus, we use, e.g., the logs from November
up to January in order to classify hosts seen in February logs. Hosts in the
training set are labeled as “tracker” or “other” using the EasyPrivacy list as
ground truth. Note that we also ensure that previously labeled vertices are not
included in any future test sets. We use our classiﬁer to tag each of the untagged
nodes as tracker or non-tracker and measure precision, accuracy, false positive
rate (FPR) and recall for each method. We assess classiﬁcation stability, by
randomly choosing test sets out of the complete dataset.
The number of test records and previously unseen trackers per month are
shown in Table 1. We observe around 800 new trackers per month and this num-
ber is independent from the total number of requests to new pages over the
50
V. Kalavri et al.
Fig. 6. Classiﬁer performance for the neighborhood analysis method.
6 months of our dataset1. This indicates that there is enough diversity in the
tracker “ecosystem” that users are constantly exposed to “new-to-them” track-
ers. In turn, this strengthens the need for an automated detection system to
alleviate the load on crowdsourced approaches.
The classiﬁcation results for February, March, and April are shown in Fig. 6.
We assess the impact of threshold selection in the following ways: (a) Unlabeled
nodes take the label of their neighbors’ most common tag (threshold = 0.00),
and (b) The tag appears on at least a given fraction of the vertex’s neighbors.
In all cases, we achieve a classiﬁcation precision that varies from 64 % up to
83 %. We observe that precision increases for higher thresholds: the more tracker
neighbors a node has, the higher the probability that it is a tracker itself. Simi-
larly, FPR and accuracy both improve for higher thresholds, but remain under
2 % and over 97 % in all cases. On the other hand, recall decreases as we increase
the threshold, which means that we might miss a few trackers, but it is above
88 % in all cases.
4.2 Classiﬁcation via Label Propagation
Label Propagation is a scalable iterative algorithm for community detection [11].
It exploits the graph structure to propagate labels and identify densely connected
groups of vertices. Initially, vertices are assigned unique labels. Then, in an
iterative fashion, vertices exchange labels with their neighbors. At each iteration,
a vertex receives a list of labels of its immediate neighbors, adopting the most
frequent label for itself. The algorithm converges when an iteration results in no
label changes.
Figure 7 illustrates how we use this algorithm on the hosts-projection graph.
First, vertices propagate labels until convergence (i=0:4 in Fig. 7a); next vertices
1 We consider a tracker new if our users have not been exposed to it before. Note that
we identify trackers by their unique URLs, without grouping them by domain.
Like a Pack of Wolves: Community Structure of Web Trackers
51
(a) Cluster identiﬁcation with label propagation.
(b) Assigning tags to individual vertices.
(c) Super tag assignment to communities.
Fig. 7. Illustration of label propagation technique for tracker classiﬁcation.
Table 2. Label propagation classiﬁcation results
Precision FPR Accuracy Recall
Monthly test sets February 0.934
0.946
0.922
March
April
Random test sets 5 %
10 %
20 %
30 %
0.923
0.934
0.941
0.939
0.004 0.993
0.002 0.994
0.001 0.997
0.004 0.994
0.004 0.993
0.003 0.994
0.003 0.994
0.932
0.9
0.872
0.958
0.941
0.948
0.951
with the same label are grouped in the same community (i=5 in Fig. 7a). Then,
we use the EasyPrivacy list to identify and tag known trackers inside the clusters,
and tag as non-trackers white-listed vertices (Fig. 7b). Finally, we assign a super
tag to each cluster by choosing the most popular tag among its cluster members
(Fig. 7c). We classify unlabeled nodes by assigning them the super tag of the
cluster in which they belong.
The results for the label propagation method are shown in Table 2. To assess
classiﬁcation stability, we evaluate the classiﬁcation using random sets of test
records of varying sizes. Instead of selecting the test set based on the timestamp
52
V. Kalavri et al.
of the log record, we create test sets from the complete graph, by randomly
choosing log records and marking them as “untagged”. We run this experiment
for test sets of 5 %, 10 %, 20 % and 30 % of the complete dataset and repeat it 3
times.
By exploring further than the ﬁrst-hop neighborhood of nodes, this method
can successfully locate the trackers community and classify test items with
extremely high precision, up to 94 %, in addition to achieving high accuracy
and recall, and lowering FPR. Further, this result does not come at a perfor-
mance cost: the algorithm converged in less than 10 iterations for all the test
sets used. Finally, this method has the advantage of not needing a manually set
threshold.
5 Related Work
A number of studies have empirically analyzed the ecosystem of trackers and
third-parties on the web, focusing on behavioral and network aspects.
TrackAdvisor [8] is a tool that analyzes cookie exchange statistics from HTTP
requests to automatically detect trackers. Similar to us, their goal is to iden-
tify trackers without having to rely on blacklists. They also identify third-party
requests by looking at the referer ﬁeld. Their dataset is created by visiting Alexa
top 10 K pages (not real user data) and is an order of magnitude smaller than
ours (500 k requests in total). Our method does not need to intercept cookie
traﬃc. Our ﬁnding that a tracker appears in multiple pages agrees with their
results. In conclusion, we could call the two methods complementary; they could
be combined to produce a more powerful tool.
Roesner et al. provide a study of web tracking, classifying tracking behaviors
and evaluating defense mechanisms [13] using web traces from AOL search logs
to simulate real user behavior. They build a classiﬁcation framework for distin-
guishing diﬀerent types of trackers, based on their functionality. In contrast, our
classiﬁcation method distinguishes between trackers and non-trackers, while it
is oblivious to the tracker mechanisms and functionality speciﬁcs.
Bau et al. propose a machine learning mechanism for detecting trackers [4].
They evaluate machine learning approaches and present results from a prototype
implementation. They use DOM-like hierarchies from the crawl data HTTP
content headers as the main features. While they achieve precision of 54 % for
1 % FPR, our methods achieve much better precision and lower FRP, while not
relying on page content collection.
Gomer et al. investigate the graph structure of third-party tracking domains
in [6] in the context of search engine results. They obtain their graph by using
searching several popular search engines with a set of pre-deﬁned queries as
opposed to real browsing behavior as we do. Their focus is on how users are
exposed to trackers via normal search behavior and they ﬁnd a 99.5 % chance
of being tracked by all major trackers within 30 clicks on search results. They
further found that the graph structure was similar across geographic regions,
which reduces the concern of bias in our dataset.
Like a Pack of Wolves: Community Structure of Web Trackers
53
In agreement with our ﬁndings, most of the above works also ﬁnd that a small
number of trackers are able to capture the majority of user behavior. However,
our work is, to the best of our knowledge, the ﬁrst to show that using this
community structure as an explicit feature can accurately predict whether an
unknown URL is a tracker or not.
6 Conclusion
In this paper we explored the community structure of trackers using a large-
scale dataset from an explicit web proxy. We transformed user requests into
a 2-mode referer-hosts graph where vertices in the ﬁrst mode represent pages
the user visited and vertices in the second mode represent requests for objects
embedded in those pages. We found that 94 % of trackers were in the largest
connected component of this graph. In order to study how trackers relate to
each other, we collapsed the referer-hosts graph into a 1-mode hosts-projection
graph. From the hosts-projection graph we observed an extremely high degree of
clustering, indicating the formation of tight communities. From this observation,
we demonstrated the eﬀectiveness of two tracker detection mechanisms: (1) a
simple threshold based classiﬁer that examines the number of tracker neighbors
of unknown vertices and (2) a label propagation algorithm that makes implicit
use of the communities trackers form. Both techniques achieved highly surprising
accuracies (over 97 %) and low false positive rates (under 2 %).
We implemented the analysis and classiﬁcation algorithms using Apache
Flink [2]. In the future we intend to port them to a streaming version for deploy-
ment within our explicit web proxy, but even our initial implementations are
quite fast. For example classiﬁcation via the label propagation method was on
the order of minutes when run on a commodity Mac laptop, indicating there are
few scalability concerns for production deployment.
References
1. AdBlock. https://getadblock.com/
2. Apache Flink. http://www.ﬂink.apache.org
3. EasyPrivacy list. https://hg.adblockplus.org/easylist/
4. Bau, J., Mayer, J., Paskov, H., Mitchell, J.C.: A promising direction for web track-
ing countermeasures. In: Web 2.0 Security and Privacy (2013)
5. Englehardt, S., Reisman, D., Eubank, C., Zimmerman, P., Mayer, J., Narayanan,
A., Felten, E.W.: Cookies that give you away: the surveillance implications of web
tracking. In: Proceedings of the 24th international conference on World Wide Web,
WWW 2015 (2015)
6. Gomer, R., Rodrigues, E.M., Milic-Frayling, N., Schraefel, M.C.: Network analysis
of third party tracking: user exposure to tracking cookies through search. In: Pro-
ceedings of the IEEE/WIC/ACM International Joint Conferences on Web Intelli-
gence and Intelligent Agent Technologies, pp. 549–556 (2013)
7. Krishnamurthy, B., Wills, C.: Privacy diﬀusion on the web: a longitudinal perspec-
tive. In: Proceedings of the 18th International Conference on World Wide Web,
WWW 2009, pp. 541–550 (2009)
54
V. Kalavri et al.
8. Li, T.-C., Hang, H., Faloutsos, M., Efstathopoulos, P.: TrackAdvisor: taking back
browsing privacy from third-party trackers. In: Mirkovic, J., Liu, Y. (eds.) PAM
2015. LNCS, vol. 8995, pp. 277–289. Springer, Heidelberg (2015)
9. Melamed, D.: Community structures in bipartite networks: a dual-projection app-
roach. PLoS ONE 9(5), e97823 (2014)
10. Papaodyssefs, F., Iordanou, C., Blackburn, J., Laoutaris, N., Papagiannaki, K.:
Web identity translator: behavioral advertising and identity privacy with WIT.
In: Proceedings of the 14th ACM Workshop on Hot Topics in Networks (to appear),
HotNets 2015 (2011)
11. Raghavan, U.N., Albert, R., Kumara, S.: Near linear time algorithm to detect
community structures in large-scale networks. Phys. Rev. E 76(3), 036106 (2007)
12. Rockefeller, J.D.: Do-Not-Track online act of 2013. US Senate (2013)
13. Roesner, F., Kohno, T., Wetherall, D.: Detecting and defending against third-party
tracking on the web. In: Proceedings of the 9th USENIX Conference on Networked
Systems Design and Implementation, NSDI 2012 (2012)
14. Williams, O.: Adblock extension with 40 million users sells to mystery buyer,
refuses to name new owner (2015). http://thenextweb.com/apps/2015/10/02/
trust-us-we-block-ads/