title:Deadline-Aware Multipath Communication: An Optimization Problem
author:Laurent Chuat and
Adrian Perrig and
Yih-Chun Hu
2017 47th Annual IEEE/IFIP International Conference on Dependable Systems and Networks
Deadline-Aware Multipath Communication:
An Optimization Problem
Laurent Chuat∗, Adrian Perrig∗, Yih-Chun Hu†
∗Department of Computer Science, ETH Zurich, Switzerland
†Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign, USA
rates (which depend on distance and other environmental
conditions) and lower bandwidth.
Abstract—Multipath communication not only allows im-
proved throughput but can also be used to leverage different
path characteristics to best fulﬁll each application’s objective.
In particular, certain delay-sensitive applications, such as real-
time voice and video communications, can usually withstand
packet loss and aim to maximize throughput while keeping
latency at a reasonable level. In such a context, one hard
problem is to determine along which path the data should
be transmitted or retransmitted. In this paper, we formulate
this problem as a linear optimization, show bounds on the
performance that can be obtained in a multipath paradigm,
and show that path diversity is a strong asset for improving
network performance. We also discuss how these theoretical
limits can be approached in practice and present simulation
results.
I. INTRODUCTION
Looking back in history, many computer systems were
initially designed to use only a single resource of each
type (e.g., processor, memory, display) at once. Over time,
to increase the performance of these systems, we have seen
the development of better components (in terms of speed,
capacity, or size) and more efﬁcient algorithms; but these
options are limited by the laws of physics, the ingenuity
of researchers, and the nature of the problem. Parallelism
emerged as the other options faced barriers (as illustrated
by the development of multicore processors, for example).
Oddly, the idea of applying parallelism to network paths (i.e.,
using multipath protocols) has only started to get traction
recently, with Multipath TCP [1] in particular.
There is an ongoing effort to develop new network pro-
tocols and improve existing ones, but even with an optimal
communication strategy, performance depends on the under-
lying medium of data transfer. Among the different physical
means of carrying data that we know of (e.g., optical ﬁber,
electromagnetic radiation, or a pair of conductors), there is
no panacea. Fiber unquestionably allows greater throughput
than copper wires, for example, but microwaves offer an
important advantage for mobility and can signiﬁcantly cut
latency. In fact, the speed of microwaves on the surface of
the earth is close to the speed of light in vacuum, whereas
ﬁber only achieves roughly 2/3 of that speed [2] (even when
assuming a straight line between source and destination).
However, these beneﬁts come at a cost, namely higher loss
In a near
future, we might witness the appearance
of even more heteroclite networks with projects such as
Facebook’s Aquila [3] (based on solar-powered drones),
Google’s Project Loon [4] (based on high-altitude balloons),
or SpaceX’s project to provide Internet with low-orbit satel-
lites [5]. Furthermore, future Internet architectures could
explicitly provide multiple paths to end hosts [6]–[10] and
these paths might also exhibit very diverse properties. As
sending multiple packets over a network in which multiple
paths are available is a parallelizable task by nature, we
claim that it is possible to take advantage of this situation to
accomplish a broad set of application-level objectives, such
as latency-related objectives. Unfortunately, as of today, few
protocols make use of multiple network paths simultane-
ously.
Because most applications are sensitive to latency to
some extent, we distinguish between two main classes of
applications. The ﬁrst class concerns applications that need
a reliable transport protocol—typically TCP or a variant
thereof (possibly with multipath functionalities and/or op-
timized for latency, see Section III). This class encompasses
ﬁle transfers, web browsing, and more. For these applica-
tions latency might be an important concern, but reliability is
the critical requirement. The second class relates to real-time
applications, which typically do not use a reliable protocol.
The reasons for not using a fully reliable service are the
following. By deﬁnition, reliable protocols never discard any
packet before the sender receives an acknowledgment—even
if the packet in question is obsolete from the application’s
perspective. Moreover, ordered byte-stream protocols suffer
from the head-of-line blocking problem, and cannot give any
guarantee regarding the time at which a packet will be deliv-
ered. As a consequence, it is hard to specify strict latency-
related objectives when a reliable protocol such as TCP is
considered; hence real-time applications typically use UDP
instead. The problem when using UDP is that transport-
layer duties (e.g., retransmissions, congestion control) are
delegated to the application layer, thus every application
must re-implement the same mechanisms. Furthermore, as
of today, multipath functionalities are not natively available
to the developers of such applications.
2158-3927/17 $31.00 © 2017 IEEE
DOI 10.1109/DSN.2017.32
487
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:36:58 UTC from IEEE Xplore.  Restrictions apply. 
In this paper, we focus on real-time applications and
consider one particular communication scenario in which
the objective is to deliver as much data as possible before a
deadline across multiple end-to-end paths. After the dead-
line, the data can be discarded (i.e., the communication is
not fully reliable, but gives latency guarantees). There is a
plethora of applications that would beneﬁt from a deadline-
aware protocol: voice communication, videoconferencing,
live video streaming, online gaming, high-frequency trad-
ing, and more. The lifetime of a packet for these various
applications could range from a few milliseconds to several
seconds.1 Therefore, it is crucial that practical techniques
as well as theoretical foundations be developed for partially
reliable multipath communications.
Using multiple paths simultaneously implies that
the
sender might have to make hard decisions regarding packet-
to-path assignments when the available paths have different
properties. It may not be obvious that path diversity can
help improve network performance. Is it preferable to have
identical paths (in which case the packet assignment problem
becomes irrelevant) or diverse ones? Also, if diverse paths
are available, is the optimal strategy to always use only
one of these paths (the most appropriate one from the
application perspective)? Intuitively, diversity allows each
path to specialize in a different task. High-bandwidth paths
can carry the initial data transmission, and low-latency low-
loss paths present advantages for retransmissions and control
data (e.g., acknowledgments). We provide a model
that
allows determining the potential beneﬁts of any given set of
paths and we show in our evaluation that having complemen-
tary paths is beneﬁcial in a deadline-based communication
context to.
II. PROBLEM DESCRIPTION
One typical situation in which two paths are available
is when a smartphone is connected to both a WiFi access
point and a cellular network. This can lead to very different
outcomes depending on which path is selected. Bandwidth
depends on which generation of the technology in question
is used (e.g., 3G, 4G, 802.11a, b, g). Losses depend on con-
gestion, environmental conditions, and more. Finally, delay
is in part inﬂuenced by the signal quality as retransmissions
can be performed at the link layer.
Figure 1 represents a simple instance of the multipath-
related problem that we study in this paper. There are
two paths with contrasting characteristics and the source
generates a constant ﬂow of data that must be delivered,
at the latest, after one second. As the one-way delay of the
high-bandwidth path is 600 ms, it will take 800 ms in total
for an acknowledgment to come back along the low-latency
1Latencies of 20–30 ms are considered as relatively high, although
acceptable, for musical applications; and humans can tap a steady beat with
variations as low as 4 ms [11]. On the other hand, live YouTube streams
can be broadcast with latencies on the order of seconds [12].
path (assumption motivated in Section VIII-C), which leaves
enough time to (potentially) retransmit the data along the
low-latency path. Clearly, if all the generated data is initially
sent along the high-bandwidth path and retransmitted along
the low-bandwidth path, we can expect 100% of the packets
to reach their destination in time. This would not be possible
by using only one of the two paths.
High Bandwidth: 10 Mbps
High Delay:     600 ms
High Loss:      10 %
Dst
Src
Low Bandwidth: 1 Mbps
Low Delay:     200 ms
Low Loss:      0 %
Data rate: 10 Mbps
Lifetime:  1 second
Figure 1. Deadline-based multipath communication scenario.
This instance of the problem is trivial, i.e., an optimal
solution can be found intuitively. However, the problem
becomes hard when more paths are considered or when
the metrics do not naturally produce such a straightforward
solution. The question we will try to answer is the following:
how can the generalization of the problem (to an arbitrary
number of paths with any characteristics) be solved?
III. RELATED WORK
Multipath TCP (MPTCP) [1] is the de-facto standard
multipath transport protocol. It received much attention
when it was adopted by Apple for its personal-assistant
software, Siri. As MPTCP is based on TCP,
it suffers
from the head-of-line blocking problem and other issues we
mention in this paper; hence it is not particularly adapted
to latency-sensitive applications. D2TCP [13], on the other
hand, is an example of deadline-based protocol, but it was
specially designed for data centers, not for general-purpose
settings over inter-domain networks. Moreover, D2TCP is
not a multipath protocol. The partial-reliability extension of
the Stream Control Transmission Protocol (PR-SCTP) [14]
offers the primitive that we examine in this paper, i.e., a
possibility to deﬁne a lifetime parameter. Although PR-SCTP
offers multihoming capabilities, additional IP addresses are
used as a backup in case of failure, so PR-SCTP is not a
fully multipath protocol and does not address the problem
that we describe in this paper [15].
Diverse techniques have been used in recent work to
analyze and leverage the beneﬁts of multipath communica-
tion. Liu et al. [16] used linear programming to evaluate
multipath routing from a trafﬁc engineering perspective.
They presented the somewhat counterintuitive result that
multipath routing offers limited gain compared to single-
path routing in terms of load balancing (under speciﬁc
trafﬁc conditions and for certain types of network topology).
488
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:36:58 UTC from IEEE Xplore.  Restrictions apply. 
However, their work—contrarily to ours—focuses on the
distribution of trafﬁc over the network and does not take
deadlines into account. Soldati et al. [17] addressed the
problem of scheduling and routing packets with deadlines
in a network whose topology is known (represented as a
directed acyclic graph), whereas we only assume end-to-
end paths. The work of Wu et al. [18] might be the closest
to ours, but with one important difference: they propose
a method to assign entire ﬂows (with different data rates
and a deadline) to speciﬁc paths, which does not allow
using an optimal retransmission strategy. Our work falls
into another category: packet-based trafﬁc splitting [19],
[20]. The novelty of our approach is that we leverage linear
programming to ﬁnd an optimal solution to a packet-to-path
assignment problem, from the end-host’s perspective, while
taking cost, retransmissions, and strict latency constraints
into account. Also, we show how to integrate random delays
into our model.
IV. BACKGROUND
In this section, we present our system assumptions and
a few deﬁnitions. We consider a network setup with a set
of paths—each bearing possibly different characteristics—
between one source and one destination. The source gen-
erates a ﬂow of data at a constant bit rate and can split
this data and select the paths along which each part will
be transmitted. In practice, the different paths could, for
example, correspond to different network interfaces (which
is the typical conﬁguration that MPTCP relies on [1]). Each
bit must be delivered before a speciﬁc point in time that we
call the deadline. To avoid any confusion, we distinguish
between a deadline, which must be interpreted as an absolute
time (e.g., 1:23:45 pm GMT), and the data’s lifetime, which
must be interpreted as a relative time (e.g., 500 ms). We
consider the lifetime to be the same for all the data, whereas
the deadline depends on the lifetime and the moment when
the data was generated.
In addition to the standard bandwidth, delay, and loss
characteristics of a network path, we consider the cost
of transmitting one bit along each path and set a user-
selectable upper bound on the total usage cost per unit time.
A cost can be seen, intuitively, as an amount of money that
the user must pay to utilize the path, but it can also be
used to model other consequences of using a path, such as
power consumption. A system is hence characterized by the
parameters presented in Table I.
Moreover, we deﬁne dmin (seconds) as the shortest delay
of all paths, i.e.,
dmin = min
i
di.
(1)
Losses are modeled by a binary erasure channel. This
the
choice is motivated by the fact
transport
layer where checksums are usually employed.
When the veriﬁcation of a checksum fails, the packet is
that we operate at
489
Table I
NETWORK CHARACTERISTICS
Description
number of independent paths
data rate generated by the application
data lifetime
upper bound on total cost per second
bandwidth of path i
one-way delay of path i
probability of bit erasure on path i
cost of sending one bit along path i
n
λ
δ
μ
bi
di
τi
ci
dropped without notifying the receiver, which is equivalent
to a bit erasure. However, we do not consider a speciﬁc
packet size; instead, we use general characteristics such as
the average loss rate.
V. MODEL
We now propose a model whose purpose is to capture the
optimal multipath sending strategy for the scenario presented
above. This model can be used to provide theoretical upper
bounds on the performance of an ideal protocol under
speciﬁc conditions, but it can also be used to design an
actual protocol (if combined with different techniques and
heuristics, as described in the following sections).
The problem under study is to determine what ratio of
the trafﬁc generated by the application should be trans-
mitted/retransmitted along each path, so that the maximal
amount of data arrives in time at the destination. Because
we take latency into account, the paths for initial transmis-
sion and for retransmission must be considered jointly. We
call this pair of transmission/retransmission paths a path
combination. The objective is to ﬁnd optimal values for the
variables contained in the following matrix:
x: matrix of size n-by-n, where xi,j is the proportion of
data to send along path i and then, if needed, along
path j (for a retransmission).
We then rearrange these variables into a vector, so that
the problem can be solved with a standard form of linear
programming:
x(cid:2): vector of size n2, given by the vectorization of x.
Only one retransmission is considered here in order to
avoid a cumbersome notation, but this model can clearly
be adapted to an arbitrary number of retransmissions, al-
though the complexity of solving the problem will naturally
increase with the number of retransmissions considered, as
discussed in Section VIII-B. We envision that, in most real
cases, the problem would be solved for a maximum of 2–3
retransmissions, for two reasons. First, unless the loss rate
is particularly high on all paths, having to send the same
data 4 times or more is a very rare event. Second, the time
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 13:36:58 UTC from IEEE Xplore.  Restrictions apply. 
it takes to perform many retransmissions is likely to exceed
the lifetime.
an optimal strategy. Therefore, we deﬁne our main metric,
which we call communication quality, as
A. Network metrics
We deﬁne several metrics to measure the outcomes of
choosing certain values of x for a given network. This
will help to deﬁne conditions and objectives in the linear
program. The metrics notation that we use is summarized in
Table II.
Table II
NETWORK METRICS
Description
bit rate sent along path i
Si
G goodput, i.e., useful received data rate
Q communication quality (ratio of G to λ)
C
total cost per second (sum of all paths)
First, the amount of data sent on a certain path is obtained
by considering both the data that is sent for the ﬁrst time on
that path (whatever the path along which the same data might
then be retransmitted) and the data that is retransmitted on
that path (which depends on the reliability of the initial path).
Therefore, we have
n−1(cid:2)
n−1(cid:2)
Si =
xi,j · λ +
xj,i · λ · τj.
j=0
j=0
This must be bounded by the available bandwidth on the
corresponding path:
Si ≤ bi ∀ i ∈ {0, 1, . . . , n − 1}.
(2)
(3)
Because we assume that the delay is ﬁxed (relaxed in
Section VI) and that an acknowledgment always comes
back on the path with the shortest delay (discussed in
Section VIII-C), when data is sent along path i, the sender
sets a retransmission timeout to
ti = di + dmin.
(4)
We deﬁne goodput as the amount of application data that
arrives at the destination before the deadline each second.
Again, we must consider both data that arrives on the ﬁrst
attempt, and retransmitted data. As a result, the goodput is
deﬁned as
(cid:2)
i:di≤δ
n−1(cid:2)
(cid:2)
j=0
G =
+
i,j:di+dmin+dj≤δ