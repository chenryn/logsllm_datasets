# 对英雄属性之间的关系进行可视化分析
# 设置 plt 正确显示中文plt.rcParams['font.sans-serif']=['SimHei'] 
# 用来正常显示中文标签plt.rcParams['axes.unicode_minus']=False 
# 用来正常显示负号
# 用热力图呈现 features_mean 字段之间的相关性corr = data[features].corr()plt.figure(figsize=(14,14))
# annot=True 显示每个方格的数据sns.heatmap(corr, annot=True)plt.show() 
# 相关性大的属性保留一个，因此可以对属性进行降维features_remain = [u'最大生命', u'初始生命', u'最大法力', u'最高物攻', u'初始物攻', u'最大物防', u'初始物防', u'最大每 5 秒回血', u'最大每 5 秒回蓝', u'初始每 5 秒回蓝', u'最大攻速', u'攻击范围']data = data_ori[features_remain]data[u'最大攻速'] = data[u'最大攻速'].apply(lambda x: float(x.strip('%'))/100)data[u'攻击范围']=data[u'攻击范围'].map({'远程':1,'近战':0})
# 采用 Z-Score 规范化数据，保证每个特征维度的数据均值为 0，方差为 1ss = StandardScaler()data = ss.fit_transform(data)
# 构造 GMM 聚类gmm = GaussianMixture(n_components=30, covariance_type='full')gmm.fit(data)
# 训练数据prediction = gmm.predict(data)print(prediction)
# 将分组结果输出到 CSV 文件中data_ori.insert(0, '分组', prediction)data_ori.to_csv('./hero_out.csv', index=False, sep=',')运行结果如下：![](Images/1ba4483d47fc28f03eb5b97d29703e2d.png){savepage-src="https://static001.geekbang.org/resource/image/db/fb/dbe96b767d7f3ff2dd9f44b651cde8fb.png"}    [28 14  8  9  5  5 15  8  3 14 18 14  9  7 16 18 13  3  5  4 19 12  4 12 12 12  4 17 24  2  7  2  2 24  2  2 24  6 20 22 22 24 24  2  2 22 14 20 14 24 26 29 27 25 25 28 11  1 23  5 11  0 10 28 21 29 29 29 17同时你也能看到输出的聚类结果文件hero_out.csv（它保存在你本地运行的文件夹里，程序会自动输出这个文件，你可以自己看下）。我来简单讲解下程序的几个模块。**关于引用包**首先我们会用 DataFrame 数据结构来保存读取的数据，最后的聚类结果会写入到CSV 文件中，因此会用到 pandas 和 CSV工具包。另外我们需要对数据进行可视化，采用热力图展现属性之间的相关性，这里会用到matplotlib.pyplot 和 seaborn 工具包。在数据规范化中我们使用到了 Z-Score规范化，用到了 StandardScaler 类，最后我们还会用到 sklearn 中的GaussianMixture 类进行聚类。**数据可视化的探索**你能看到我们将 20个英雄属性之间的关系用热力图呈现了出来，中间的数字代表两个属性之间的关系系数，最大值为1，代表完全正相关，关系系数越大代表相关性越大。从图中你能看出来"最大生命""生命成长"和"初始生命"这三个属性的相关性大，我们只需要保留一个属性即可。同理我们也可以对其他相关性大的属性进行筛选，保留一个。你在代码中可以看到，我用features_remain 数组保留了特征选择的属性，这样就将原本的 20个属性降维到了 13 个属性。**关于数据规范化**我们能看到"最大攻速"这个属性值是百分数，不适合做矩阵运算，因此我们需要将百分数转化为小数。我们也看到"攻击范围"这个字段的取值为远程或者近战，也不适合矩阵运算，我们将取值做个映射，用1 代表远程，0 代表近战。然后采用 Z-Score 规范化，对特征矩阵进行规范化。**在聚类阶段**我们采用了 GMM 高斯混合模型，并将结果输出到 CSV 文件中。这里我将输出的结果截取了一段（设置聚类个数为 30）：![](Images/e52b12fae04a9f3cbc7c333ad2585418.png){savepage-src="https://static001.geekbang.org/resource/image/5c/ce/5c74ffe6741f1bf1bfdf7711932d47ce.png"}\第一列代表的是分组（簇），我们能看到张飞、程咬金分到了一组，牛魔、白起是一组，老夫子自己是一组，达摩、典韦是一组。聚类的特点是相同类别之间的属性值相近，不同类别的属性值差异大。因此如果你擅长用典韦这个英雄，不防试试达摩这个英雄。同样你也可以在张飞和程咬金中进行切换。这样就算你的英雄被别人选中了，你依然可以有备选的英雄可以使用。
## 总结今天我带你一起做了 EM 聚类的实战，具体使用的是 GMM高斯混合模型。从整个流程中可以看出，我们需要经过数据加载、数据探索、数据可视化、特征选择、GMM聚类和结果分析等环节。聚类和分类不一样，聚类是无监督的学习方式，也就是我们没有实际的结果可以进行比对，所以聚类的结果评估不像分类准确率一样直观，那么有没有聚类结果的评估方式呢？这里我们可以采用Calinski-Harabaz 指标，代码如下：    from sklearn.metrics import calinski_harabaz_scoreprint(calinski_harabaz_score(data, prediction))指标分数越高，代表聚类效果越好，也就是相同类中的差异性小，不同类之间的差异性大。当然具体聚类的结果含义，我们需要人工来分析，也就是当这些数据被分成不同的类别之后，具体每个类表代表的含义。另外聚类算法也可以作为其他数据挖掘算法的预处理阶段，这样我们就可以将数据进行降维了。![](Images/582eedce2bacb73bad1813388213e847.png){savepage-src="https://static001.geekbang.org/resource/image/43/d7/43b35b8f49ac83799ea1ca88383609d7.png"}\最后依然是两道思考题。针对王者荣耀的英雄数据集，我进行了特征选择，实际上王者荣耀的英雄数量并不多，我们可以省略特征选择这个阶段，你不妨用全部的特征值矩阵进行聚类训练，来看下聚类得到的结果。第二个问题是，依然用王者荣耀英雄数据集，在聚类个数为3 以及聚类个数为 30 的情况下，请你使用 GMM高斯混合模型对数据集进行聚类，并得出 Calinski_Harabaz 分数。欢迎在评论区与我分享你的答案，也欢迎点击"请朋友读"，把这篇文章分享给你的朋友或者同事。![](Images/8b75105190797b2e4f7be2536b6543db.png){savepage-src="https://static001.geekbang.org/resource/image/48/96/48cb89aa8c4858bbc18df3b3ac414496.jpg"}