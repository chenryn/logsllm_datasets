# Title: SoK: Quantifying Cyber Risk

## Authors:
- Daniel W. Woods, University of Innsbruck, Innsbruck, Austria
- Rainer Böhm, University of Innsbruck, Innsbruck, Austria

## Abstract
This paper introduces a causal model inspired by structural equation modeling (SEM) to explain cyber risk outcomes in terms of latent factors measured using reflexive indicators. We use the model to classify empirical studies on cyber harm and discover that cyber harms are not exceptional in terms of typical or extreme losses. The increasing frequency of data breaches is contested, and stock market reactions to cyber incidents are becoming less damaging over time. Focusing solely on harms can breed fatalism; the causal model is most useful for evaluating the effectiveness of security interventions. We demonstrate how simple statistical relationships can lead to spurious results, such as more security spending or applying updates being associated with greater rates of compromise. When accounting for threat and exposure, indicators of security are shown to be important factors in explaining the variance in rates of compromise, especially when multiple indicators of the security level are used.

## Index Terms
- Cyber risk
- Security metrics
- Cyber harm
- Control effectiveness
- Science of security
- Causal model
- Structural equation modeling

## 1. Introduction
Unsupported claims about the increasing risk of cyber attacks are common in introductions to security talks and papers. Organizations are often expected to invest more in security, even though research has inconsistently demonstrated the effectiveness of such interventions. This situation leads to the perception that cyber risk management is more art than science.

Our paper aims to systematize what is known about quantifying cyber risk. Accurate risk estimates can justify additional resources for mitigation or guide post-incident response. While the term "cyber" may be contentious within the security community, it is the preferred concept for policymakers and business leaders who make many of the decisions that security research should influence. These decisions are based on foundational questions such as:

- **RQ1:** How much harm results from cyber incidents?
- **RQ2:** Which security interventions effectively reduce harm?
- **RQ3:** Have these answers changed over time?

While security vendors often provide self-interested answers with questionable methodologies [7, 82], this paper finds answers in empirical studies of real-world security outcomes. We systematize the literature using a causal model linking latent variables for security, exposure, and threat to security outcomes. The proposed model captures empirical cyber risk research ranging from machine learning models predicting web server compromise to finance studies quantifying shareholder losses resulting from cyber incidents.

We focus on classifying studies that quantify cyber risk in organizations. The term "cyber risk" consists of two components: risk, which describes possible negative consequences (harm) weighted by the probability of occurrence, and "cyber," which restricts our scope to incidents caused by logical (as opposed to physical) force [17]. For example, a fire (physical force) in a data center (information harm) is not a cyber risk, whereas fire damage (physical harm) caused by compromised control systems (logical force) would be. Incidents within scope include denial of service attacks, machine and web-resource compromise, and organizational incidents. Associated harms range from lost shareholder value to ransomware payments to wasted time.

Our literature search identified relevant works in top security conferences and the Workshop on the Economics of Information Security. We used backward and forward reference searches to identify additional relevant works until saturation was reached. This process captured relevant studies from disciplines including law, information systems, finance, and physics. We included studies that empirically measure real-world compromise or harm affecting organizations, which is a minority approach within the science of security [60, p. 12]. Studies providing promising ways of measuring security, exposure, or threat were also included, even when harm was not considered. For aggregate estimates of cybercrime costs, see Anderson et al. [7]; for cyber risk transfer research, see Dambra et al. [32].

Section II introduces the causal model. Section III surveys harm studies addressing RQ1. Section IV identifies mitigation studies that address RQ2. Temporal trends are identified throughout (RQ3). Section V discusses progress towards RQ1–3, model limitations, and future work.

## 2. A Causal Model of Cyber Risk
Risk is unobservable but can be indirectly measured through realized losses. Figure 1 uses artificial data to illustrate the stochastic relationship; the highest observed loss has multiple twins with similar security levels but much smaller losses.

### Naive Security Effectiveness Regressions
High-threat populations and low-threat populations exhibit different security effectiveness. Regression analysis is designed to explore relationships in the presence of statistical noise. The Appendix contains a brief tutorial on regression analysis, but the confident reader may continue. Fitting a linear model where security is the only explanatory variable (the blue line) suggests that increasing security is associated with greater losses. This result has been found empirically—higher IT security budgets are associated with a greater frequency of data breaches [105]. Research designs based on observational data are vulnerable to confounding variables, so we need to add relevant variables to the regression model.

Adding threat level leads to a better fit (see the Appendix for more detail) and provides insights into cross-dependencies. In Figure 1, the red dotted line slopes downwards, while the green dashed line has a (not statistically significant) upward slope, suggesting that security only reduces harm when implemented by high-threat populations. Threat is the only necessary condition for harm to occur. Therefore, security should be conceptualized as moderating the relationship between threat and harm, such that more security translates into less expected harm.

### Exposure
The intuition that security effectiveness depends on the threat level is baked into risk management. If security is a form of mitigation in risk management, then a third variable, exposure, is analogous to the amount of risk acceptance. More exposure means more vectors can be used to gain access (surface exposure) and a greater value of assets can be compromised (asset exposure), both of which amplify the effect of threat on expected harm. Figure 2 represents the relationship between threat level and expected harm, moderated by security and exposure. The notation E(+) denotes a positive relationship, where more exposure amplifies the link between threat and harm, and S(−) denotes a negative relationship. Many research designs fail to account for all three variables.

Measuring these abstract variables is challenging in practice. Reported losses ignore the full spectrum of harms [2], and harm is often avoided thanks to luck alone. The effect of security in moderating the stochastic relationship between threat and harm is even more difficult to measure. No single indicator captures the sum of preventive and reactive measures across an organization's technology, processes, and people. Modeling security as a latent variable overcomes this issue by linking noisy, observable indicators to the high-level concept.

Figure 2 shows this graphically, with the latent variable for security having reflexive indicators I1, ..., Ik, which can be measured with mi. The arrows flow from security to the indicators Ii because the indicators do not cause security; rather, the security level influences the likelihood of a given measurement mi. The latent variable must be inferred from these reflexive indicators.

Although Figure 2 describes the ideal research design, relationships like S(−) can still represent statistical models comprised of manifest variables, where variables like security or threat are assumed to be directly measurable. This allows us to systematize a diverse body of literature on cyber risk quantification and show which factors determining risk outcomes are under consideration.

Very few studies directly link security interventions to harm outcomes. It is useful to introduce a mediating factor, compromise, which may or may not result in harm. Studies investigating the effectiveness of security controls tend to focus on an indicator of compromise without quantifying the resulting harm, whereas studies quantifying harm tend to sample exclusively from compromised entities (C = 1 in our model). This approach cannot quantify how preventative security affects incident likelihood because C = 1 for all firms.

Often, these studies explore how harm varies based not on the threat level, which is stochastic and difficult to measure, but on the threat actor (e.g., ransomware gang) who caused an incident. While this provides some information about the threat level (e.g., a more sophisticated actor suggests a higher threat level), it cannot be measured for firms that were not compromised (C = 0). We denote this special case as T|C, the type of threat conditioned on compromise. Figure 3 shows the extended model using SEM notation.

To make this concrete, a 2017 study [116] is illustrated in Figure 3 using red arrows and indicators Ix. The authors argue that although indicators of security (e.g., hiding version numbers or SSL configuration) correlate with less abuse when aggregated across web hosting providers, these variables do not directly cause security improvements. Rather, the indicators are assumed to be reflexive indicators of an unobservable security level. The authors [116] construct four latent variables for preventive security Sp to explain website compromise C when controlling for surface exposure Es. Table VI (in the Appendix) describes the corresponding technical indicators.

The rest of this paper systematizes the literature on cyber risk according to which of the relationships depicted in Figure 3 are explored. We focus on the statistical tests in the main contribution and ignore preliminary results or tables. This will be summarized in Table III. Our classification requires a fair amount of interpretation because assumptions are often unstated. For example, many data breach studies do not control for the size or industry of the victim, which we suggest is an implicit assumption that threat and exposure are constant.