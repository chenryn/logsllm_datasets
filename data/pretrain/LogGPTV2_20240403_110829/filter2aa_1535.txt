Comparing Application Security Tools
Defcon 15 - 8/3/2007
Eddie Lee
Fortify Software
Agenda
Intro to experiment
Methodology to reproduce experiment on your own
Results from my experiment
Conclusions
Introduction
Tools Used
“Market Leading” Dynamic Testing Tools
A Static Code Analyzer
Dynamic Test Tracing Tool
The Application
Open source Java based Blog
http://pebble.sourceforge.net
Reasons for choosing this application
The Experiment
Out of the box scans
Compared findings from each tool
How The Tools Work
Dynamic Testing Tools
Fuzz web form input
Signature and Behavioral Matching
Modes of Scanning 
Auto-crawl
Manual crawl
Static Code Analyzer
Data flow
Control flow
Semantic
Dynamic Test Tracing Tool
Bytecode instrumentation
Monitor data coming in and out of the application
Run in conjunction with other dynamic testing tools
Methodology
How to reproduce experiments on your own (Dynamic Testing Tools)
Download source code
Build & Deploy Application
Figure out how to cleanly undeploy the application
Clear database or stored files
Run scanner in mode auto-crawl mode
Make sure the application doesn’t break during your scans
If the app breaks, figure out why the scanner breaks the app. 
Configure scanner to ignore the parameter(s) causing app to break
Note the parameter(s) won’t be tested for vulnerabilities and the existence of a 
DoS vulnerability
Undeploy and Redeploy the application
Repeat 
Save the results from your last clean run
Repeat for scanner in mode manual-crawl mode
Verify the results
Verify results through manually testing
Record false positive rate
Normalize results
Record source file and line number information where vulnerabilities occur
How to reproduce experiments on your own (Static Testing Tool)
Not much to it
Point the scanner at code and tell it where it can find needed libraries
Scan the same code you use in other tests
Verify results are true positives and weed out false positives
Verify results through manually testing on running application
Record false positive rate
Normalize the results
How to reproduce experiments on your own (Dynamic Tracing Tool)
Instrument the compiled code
Deploy instrumented code
Start recording
Perform dynamic testing
Stop recording
Verify results are true positives and weed out false positives
Verify results through manually testing on running application
Record false positive rate
Normalize the results
Setup and Result Quantification
Tool Configuration and Setup 
Dynamic Testing Tools
Modes of operation: Auto Crawl & Manual Crawl
Minor tweaking for the application
Quantification of Results
Tools report vulnerabilities in different units
Standardized on location in source code where vulnerability occurs
Normalized reported numbers
Use the normalized vulnerability counts for comparison among tools
Results
Results: Overview
X-Unique to 
Tool
X-Multiple 
Tools
Results: Overview
XSS
title
saveBlogEntry.secureaction
16
blogEntry.jsp
Category
Parameter
URL
Line #
File
X
X
Tool #5a
Tool #4a
Tool #3a
Tool #2b
Tool #2a
Tool #1b
Tool #1a
Results: Overview
X-Unique to 
Tool
X-Multiple 
Tools
Results: Exploit Examples
Cross-Site Scripting
Error.jsp:18
Code:
Request URI : ${pageContext.request.requestURI}
Attack:
http://host/pebble//createDirectory.secureaction?type=blogFile
viewResponses.jsp:31
Code:
Attack: 
http://host/pebble/viewResponses.secureaction?type=">
Results: Exploit Examples
Path Manipulation
DefaultSecurityRealm.java:213
Code:
return new File(getFileForRealm(), username + ".properties");
Attack: 
http://host/pebble/saveUser.secureaction?username=../../../../../../../../etc/passwd%00&n
ewUser=true&name=joe&emailAddress=PI:EMAIL&website=blah.com
Arbitrary URL Redirection
RedirectView.java:85
Code:
response.sendRedirect(getUri());
Attack:
http://host/pebble/logout.action?redirectUrl=http://www.attacker.com
Results: Manual Audit
Vulnerabilities not detected by any tool (from just one file)
Cross-Site Scripting Detection By Tool
Tool 1b
Tool 1b and Tool 2b
Tool 2b
Not 
detected by 
any tool
Tool 5a
Detected by 
all tools
*1a, 2a, 3a and 4a not shown because findings were not significant
Conclusions
A single tool doesn’t cut it
Using multiple tools significantly increases vulnerabilities found
Little overlap between tools
Tools alone aren’t enough
Run these tests on your own apps to see how they perform in 
your environment
Fuzzing tools break shit
Takes a long time to scan and troubleshoot the application
Don’t expect these tests to be quick
Q&A
Thanks!