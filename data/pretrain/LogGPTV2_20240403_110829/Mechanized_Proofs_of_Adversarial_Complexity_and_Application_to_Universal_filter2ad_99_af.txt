two oracle systems, and is explicitly quantified by the resources of
an adversary. State-separating proofs [15] pursue similar goals, us-
ing a notion of package. Packages have the expressivity of modules,
but additionally support private functions. Our modules can emu-
late private functions using restrictions. At present, there is no tool
support for state-separating proofs. [31] introduces the notion of
interface, which is similar to module, for formalizing cryptography.
7 CONCLUSION
We have developed an extension of the EasyCrypt proof assistant to
support reasoning complexity claims. The extension captures reduc-
tionist statements that faithfully match the cryptographic literature
and supports compositional reasoning. As a main example, we have
shown how to formalize key results from Universal Composability,
a long-standing goal of computer-aided cryptography.
REFERENCES
[1] Elvira Albert, Puri Arenas, Samir Genaim, Miguel Gómez-Zamalloa, German
Puebla, D. Ramírez, G. Román, and Damiano Zanardini. 2009. Termination and
Cost Analysis with COSTA and its User Interfaces. Electr. Notes Theor. Comput.
Sci. 258, 1 (2009), 109–121.
[2] José Bacelar Almeida, Manuel Barbosa, Gilles Barthe, Matthew Campagna, Ernie
Cohen, Benjamin Grégoire, Vitor Pereira, Bernardo Portela, Pierre-Yves Strub,
and Serdar Tasiran. 2019. A Machine-Checked Proof of Security for AWS Key
Management Service. In Proceedings of the 2019 ACM SIGSAC Conference on
Computer and Communications Security, CCS 2019, London, UK, November 11-15,
2019, Lorenzo Cavallaro, Johannes Kinder, XiaoFeng Wang, and Jonathan Katz
(Eds.). ACM, 63–78. https://doi.org/10.1145/3319535.3354228
[3] José Bacelar Almeida, Cecile Baritel-Ruet, Manuel Barbosa, Gilles Barthe, François
Dupressoir, Benjamin Grégoire, Vincent Laporte, Tiago Oliveira, Alley Stoughton,
and Pierre-Yves Strub. 2019. Machine-Checked Proofs for Cryptographic Stan-
dards: Indifferentiability of Sponge and Secure High-Assurance Implementations
of SHA-3. In Proceedings of the 2019 ACM SIGSAC Conference on Computer and
Communications Security, CCS 2019, London, UK, November 11-15, 2019, Lorenzo
Cavallaro, Johannes Kinder, XiaoFeng Wang, and Jonathan Katz (Eds.). ACM,
1607–1622. https://doi.org/10.1145/3319535.3363211
[4] Manuel Barbosa, Gilles Barthe, Karthikeyan Bhargavan, Bruno Blanchet, Cas
Cremers, Kevin Liao, and Bryan Parno. 2021. SoK: Computer-Aided Cryptography.
In 2021 2021 IEEE Symposium on Security and Privacy (SP). IEEE Computer Society,
Los Alamitos, CA, USA, 777–795. https://doi.org/10.1109/SP40001.2021.00008
[5] Manuel Barbosa, Gilles Barthe, Benjamin Grégoire, Adrien Koutsos, and Pierre-
Yves Strub. 2021. Mechanized Proofs of Adversarial Complexity and Application
to Universal Composability.
https:
//eprint.iacr.org/2021/156
IACR Cryptol. ePrint Arch. (2021), 156.
[6] Gilles Barthe, Marion Daubignard, Bruce M. Kapron, and Yassine Lakhnech. 2010.
Computational indistinguishability logic. In Proceedings of the 17th ACM Confer-
ence on Computer and Communications Security, CCS 2010, Chicago, Illinois, USA,
October 4-8, 2010, Ehab Al-Shaer, Angelos D. Keromytis, and Vitaly Shmatikov
(Eds.). ACM, 375–386. https://doi.org/10.1145/1866307.1866350
[7] Gilles Barthe, François Dupressoir, Benjamin Grégoire, César Kunz, Benedikt
Schmidt, and Pierre-Yves Strub. 2013. EasyCrypt: A Tutorial. In Foundations of
Security Analysis and Design VII - FOSAD 2012/2013 Tutorial Lectures (Lecture
Notes in Computer Science), Alessandro Aldini, Javier López, and Fabio Martinelli
(Eds.), Vol. 8604. Springer, 146–166. https://doi.org/10.1007/978-3-319-10082-1_6
[8] Gilles Barthe, Marco Gaboardi, Benjamin Grégoire, Justin Hsu, and Pierre-Yves
Strub. 2016. A Program Logic for Union Bounds. In 43rd International Colloquium
on Automata, Languages, and Programming, ICALP 2016, July 11-15, 2016, Rome,
Italy (LIPIcs), Ioannis Chatzigiannakis, Michael Mitzenmacher, Yuval Rabani,
and Davide Sangiorgi (Eds.), Vol. 55. Schloss Dagstuhl - Leibniz-Zentrum für
Informatik, 107:1–107:15. https://doi.org/10.4230/LIPIcs.ICALP.2016.107
[9] Gilles Barthe, Benjamin Grégoire, and Santiago Zanella Béguelin. 2009. Formal
certification of code-based cryptographic proofs. In Proceedings of the 36th ACM
SIGPLAN-SIGACT Symposium on Principles of Programming Languages, POPL
2009, Savannah, GA, USA, January 21-23, 2009, Zhong Shao and Benjamin C.
Pierce (Eds.). ACM, 90–101. https://doi.org/10.1145/1480881.1480894
[10] Gilles Barthe, Benjamin Grégoire, Sylvain Heraud, and Santiago Zanella Béguelin.
2011. Computer-Aided Security Proofs for the Working Cryptographer. In Ad-
vances in Cryptology - CRYPTO 2011 - 31st Annual Cryptology Conference, Santa
Barbara, CA, USA, August 14-18, 2011. Proceedings (Lecture Notes in Computer
Science), Phillip Rogaway (Ed.), Vol. 6841. Springer, 71–90. https://doi.org/10.
1007/978-3-642-22792-9_5
[11] David A. Basin, Andreas Lochbihler, and S. Reza Sefidgar. 2020. CryptHOL:
Game-Based Proofs in Higher-Order Logic. J. Cryptology 33, 2 (2020), 494–566.
https://doi.org/10.1007/s00145-019-09341-z
[12] Mihir Bellare and Phillip Rogaway. 1993. Random Oracles are Practical: A Para-
digm for Designing Efficient Protocols. In CCS ’93, Proceedings of the 1st ACM Con-
ference on Computer and Communications Security, Fairfax, Virginia, USA, Novem-
ber 3-5, 1993, Dorothy E. Denning, Raymond Pyle, Ravi Ganesan, Ravi S. Sandhu,
and Victoria Ashby (Eds.). ACM, 62–73. https://doi.org/10.1145/168588.168596
[13] Bruno Blanchet. 2006. A Computationally Sound Mechanized Prover for Security
Protocols. In 2006 IEEE Symposium on Security and Privacy (S&P 2006), 21-24
May 2006, Berkeley, California, USA. IEEE Computer Society, 140–154. https:
Session 10B: Crypto and Protocol Security CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2553[14] Marc Brockschmidt, Fabian Emmes, Stephan Falke, Carsten Fuhs, and Jürgen
Giesl. 2014. Alternating Runtime and Size Complexity Analysis of Integer Pro-
grams. In Tools and Alg. for the Constr. and Anal. of Systems - 20th Int. Conf.
(TACAS’14). 140–155.
[15] Chris Brzuska, Antoine Delignat-Lavaud, Cédric Fournet, Konrad Kohbrok, and
Markulf Kohlweiss. 2018. State Separation for Code-Based Game-Playing Proofs.
In Advances in Cryptology - ASIACRYPT 2018 - 24th International Conference on
the Theory and Application of Cryptology and Information Security, Brisbane, QLD,
Australia, December 2-6, 2018, Proceedings, Part III (Lecture Notes in Computer
Science), Thomas Peyrin and Steven D. Galbraith (Eds.), Vol. 11274. Springer,
222–249. https://doi.org/10.1007/978-3-030-03332-3_9
[16] Ran Canetti. 2000. Universally Composable Security: A New Paradigm for
Cryptographic Protocols. Cryptology ePrint Archive, Report 2000/067. (2000).
https://eprint.iacr.org/2000/067.
[17] Ran Canetti. 2001. Universally Composable Security: A New Paradigm for Cryp-
tographic Protocols. In 42nd Annual Symposium on Foundations of Computer
Science, FOCS 2001, 14-17 October 2001, Las Vegas, Nevada, USA. IEEE Computer
Society, 136–145. https://doi.org/10.1109/SFCS.2001.959888
[18] Ran Canetti. 2001. Universally composable security: a new paradigm for cryp-
tographic protocols. In Proceedings 42nd IEEE Symposium on Foundations of
Computer Science. 136–145.
[19] Ran Canetti, Asaf Cohen, and Yehuda Lindell. 2015. A Simpler Variant of Univer-
sally Composable Security for Standard Multiparty Computation. In Advances
in Cryptology – CRYPTO 2015, Rosario Gennaro and Matthew Robshaw (Eds.).
Springer Berlin Heidelberg, Berlin, Heidelberg, 3–22.
[20] Ran Canetti, Alley Stoughton, and Mayank Varia. 2019. EasyUC: Using EasyCrypt
to Mechanize Proofs of Universally Composable Security. In 32nd IEEE Computer
Security Foundations Symposium, CSF 2019, Hoboken, NJ, USA, June 25-28, 2019.
IEEE, 167–183. https://doi.org/10.1109/CSF.2019.00019
[21] The EasyCrypt development team. 2021. Source code of our EasyCrypt. (Sep-
tember 2021). https://github.com/EasyCrypt/easycrypt.
//doi.org/10.1109/SP.2006.1
[22] Sumit Gulwani, Krishna K. Mehra, and Trishul Chilimbi. 2009. SPEED: Precise and
Efficient Static Estimation of Program Computational Complexity. In Proceedings
of the 36th Annual Symposium on Principles of Programming Languages (POPL
’09). 127–139.
[23] Helene Haagh, Aleksandr Karbyshev, Sabine Oechsner, Bas Spitters, and Pierre-
Yves Strub. 2018. Computer-Aided Proofs for Multiparty Computation with
Active Security. In 31st IEEE Computer Security Foundations Symposium, CSF
2018, Oxford, United Kingdom, July 9-12, 2018. IEEE Computer Society, 119–131.
https://doi.org/10.1109/CSF.2018.00016
[24] Shai Halevi. 2005. A plausible approach to computer-aided cryptographic proofs.
https://doi.org/10.1016/0022-0000(85)90012-1
IACR Cryptol. ePrint Arch. 2005 (2005), 181. http://eprint.iacr.org/2005/181
[25] Benjamin Lucien Kaminski, Joost-Pieter Katoen, Christoph Matheja, and Fed-
erico Olmedo. 2016. Weakest Precondition Reasoning for Expected Run-Times of
Probabilistic Programs. In Programming Languages and Systems - 25th European
Symposium on Programming, ESOP 2016, Held as Part of the European Joint Confer-
ences on Theory and Practice of Software, ETAPS 2016, Eindhoven, The Netherlands,
April 2-8, 2016, Proceedings (Lecture Notes in Computer Science), Peter Thiemann
(Ed.), Vol. 9632. Springer, 364–389. https://doi.org/10.1007/978-3-662-49498-1_15
[26] Dexter Kozen. 1985. A Probabilistic PDL. J. Comput. Syst. Sci. 30, 2 (1985), 162–178.
[27] Kevin Liao, Matthew A. Hammer, and Andrew Miller. 2019.
ILC: a calculus
for composable, computational cryptography. In Proceedings of the 40th ACM
SIGPLAN Conference on Programming Language Design and Implementation, PLDI
2019, Phoenix, AZ, USA, June 22-26, 2019, Kathryn S. McKinley and Kathleen
Fisher (Eds.). ACM, 640–654. https://doi.org/10.1145/3314221.3314607
[28] Carroll Morgan, Annabelle McIver, and Karen Seidel. 1996. Probabilistic Predicate
Transformers. ACM Trans. Program. Lang. Syst. 18, 3 (1996), 325–353. https:
//doi.org/10.1145/229542.229547
[29] Hanne Riis Nielson. 1987. A Hoare-Like Proof System for Analysing the
Computation Time of Programs. Sci. Comput. Program. 9, 2 (1987), 107–136.
https://doi.org/10.1016/0167-6423(87)90029-3
[30] Adam Petcher and Greg Morrisett. 2015. A Mechanized Proof of Security for
Searchable Symmetric Encryption. In IEEE 28th Computer Security Foundations
Symposium, CSF 2015, Verona, Italy, 13-17 July, 2015, Cédric Fournet, Michael W.
Hicks, and Luca Viganò (Eds.). IEEE Computer Society, 481–494.
[31] Mike Rosulek. 2020. The Joy of Cryptography.
[32] Asankhaya Sharma, Shengyi Wang, Andreea Costea, Aquinas Hobor, and Wei-
Ngan Chin. 2015. Certified Reasoning with Infinity. In FM 2015: Formal Methods -
20th International Symposium, Oslo, Norway, June 24-26, 2015, Proceedings (Lecture
Notes in Computer Science), Nikolaj Bjørner and Frank S. de Boer (Eds.), Vol. 9109.
Springer, 496–513. https://doi.org/10.1007/978-3-319-19249-9_31
Appendix Outline. We quickly outline the structure of the appen-
dix. We show that the standard dummy adversary theorem holds
in our UC modeling in Appendix A. We present the type system
module type ADV(B : BACKDOORS) = {
include NONDUMMY.BACKDOORS }.
module A_PROTOCOL(A : ADV, P : PROTOCOL)
: NONDUMMY.PROTOCOL = {
proc init() : unit = { P.init(); }
include P [inputs, outputs]
include A(P) [step,backdoor] }.
Figure 12: Real-world protocol with adversary.
for our programming language and module system in Appendix B.
Then, we present the semantics of our module system. This module
semantics takes the form of a module resolution mechanism, which
describe how module expressions are evaluated, and is given in
Appendix C. Then, we define the semantics of our programming
language and of the cost judgment in Appendix D. Finally, we
present the full set of rules of our Hoare logic for cost and prove
their soundness in Appendix E.
A long version of this paper can be found here [5].
A THE DUMMY ADVERSARY IN UC
The standard notion of UC emulation [16, 17] enriches the real-
world with an explicit adversary A representing an attacker that
has access to the real-world BACKDOORS interface and colludes
with the environment to break the protocol. In this case, the real-
and ideal- world execution models become structurally identical, in
that the environment interacts with the BACKDOORS interface via
adversarial entities in both worlds.10 The order of the quantifiers in
the emulation definition is crucial for its compositional properties:
it requires that, for all adversaries A, there exists a simulator S
such that, for all environments Z, the real- and ideal- worlds are
indistinguishable. We now show that the same result holds in our
setting.
Consider the functor in Figure 12, which extends any real-world
protocol with abstract adversary A (A in EasyCrypt notation) at
its BACKDOORS interface. The type of A is parametric in the BACK-
DOORS offered by the protocol in our basic execution model, and
it fixes the type of the BACKDOORS interface in the extended exe-
cution model NONDUMMY.PROTOCOL. This means that when we
quantify over such adversaries, we quantify also over the potential
forms of environment-to-adversary information exchange. The fol-
lowing theorem shows that we do not lose generality by working
with an (implicit) dummy adversary in our execution model.
Theorem A.1 (Dummy Adversary). UC emulation is equivalent
to UC emulation with an explicit real-world adversary. More precisely:
• Emulation with an implicit dummy adversary implies emu-
lation with an explicit arbitrary adversary: For all ϵ ∈ R
+,
all protocols π1 and π2 with IO interfaces of the same type,
all complexity restrictions csim, cenv and all simulators S ∈
π1,π2,csim
τ
sim
Advuc,S
csim,cenv(π1, π2) ≤ ϵ ⇒
, we have
∀A ∈ τadv, Advuc
ˆcsim,cenv(⟨π1 ∥ A(π1)⟩, π2) ≤ ϵ
10For this reason the simulator is often called an ideal world adversary; we do not adopt
this terminology here to avoid confusion.
Session 10B: Crypto and Protocol Security CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2554where ˆcsim allows for a simulator S′ that combines adversary
A and simulator S.
• Emulation with an implicit dummy adversary is implied by
emulation with an explicit arbitrary adversary: For all ϵ ∈ R
+,
all protocols π1 and π2 with IO interfaces of the same type, all
complexity restrictions csim, cenv and all simulator memory
spaces M, we have
Name
Γ(p) = _ : M
Γ ⊢ p : M
Module path typing Γ ⊢ p : M.
Compnt
Γ ⊢ p : sig S1; module x : M; S2 restr θ end
Γ ⊢ p.x : M
FuncApp
Γ ⊢ p : func(x : M′) M
Γ ⊢ p′ : M′
Γ ⊢ p(p′) : M[x (cid:55)→ memΓ(p′)]
∀A ∈ τadv, Advuc,M
csim,cenv(⟨π1 ∥ A(π1)⟩, π2) ≤ ϵ ⇒
Advuc,M
csim,cenv(π1, π2) ≤ ϵ
where τadv accommodates the dummy adversary.
Our proof gives a simulator S′ for the first part of the theorem
that joins together simulator S and adversary A: intuitively the
new simulator uses the existing one to fool the (non-dummy) real-
world adversary into thinking it is interacting with the real-world
protocol and, in this way, it can offer the expected BACKDOORS
view generated by A to the environment. The resources used by S′
are those required to run the composition of S and A. The proof of
the second part of the theorem is more interesting: we construct an
explicit dummy adversary and use this to instantiate the hypothesis
and obtain a simulator for this adversary, which we then show must
also work when the dummy adversary is only implicit: this second
step is an equivalence proof showing that, if the simulator matches
the explicit dummy adversary which just passes information along,
then it is also good when the environment is calling the protocols’
BACKDOORS interface directly. The resulting simulator is therefore
guaranteed to belong to the same cost-annotated type over which
we quantify existentially in the hypothesis.
We note a technicality in the second part of the theorem: since
the hypothesis quantifies over adversaries before quantifying exis-
tentially over simulators, we cannot use the approach adopted in
the transitivity proof and in the first part of the theorem, where we
use global universal quantifications over hypothesized simulators.
Instead, we quantify globally over a memory space M, restrict
simulators in the hypothesis to only use M, and prevent other
algorithms to interfere with this memory space where appropriate
(we abuse notation by indicating M in Advuc to denote this).
B TYPING RULES
B.1 Program and Module Typing
We now present the core rules of our module type system, which
are summarized in Figure 13 and Figure 14. The rest of the rules are
postponed to Appendix B.2. For clarity of presentation, our module
type system requires module paths to always be long modules
paths, from the root of the program to the sub-module called (we
give a simple example in Figure 15). This allows to have a simpler
module resolution mechanism, by removing any scoping issues.
This is done without loss of generality: in practice, one can always
replace short module paths with long module paths when parsing
a program.
A typing environment Γ is a list of typing declarations. A typing
declaration, denoted δ, is either a variable, module, abstract module
Module expression typing Γ ⊢p m : M.
We omit the rules Γ ⊢ M to check that a module signature M is well-formed.
Γ ⊢p,θ st : S