In this section, we discuss the threat to the validity of our paper.External validity. In this work, we evaluate Logram on 16 log datasets from an existing benchmark [21]. Logram achieves a parsing accuracy higher than 0.9 on about half of the datasets. We cannot ensure that Logram can achieve high accuracy on other log datasets not tested in this work. Nevertheless, through an evaluation on logs produced by 16 different systems from different domains (e.g., big data applications and operation systems), we show that Logram achieves similar accuracy as the best existing log parsing approaches with a much faster speed. Future work can improve our approach to achieve high accuracy on more types of log data.Internal validity. Logram leverages n-grams to parse log data. n-grams are typically used to model natural languages or source code that are written by humans. However, logs are different from natural languages or source code as logs are produced by machines and logs contain static and dynamic information. Nevertheless, we show that n-grams can help us effectively distinguish static and dynamic information in log parsing. Future work may use n-grams to11
model log messages in other log-related analysis. We use an automated approach to determine the threshold for iden-tifying statically and dynamically generated tokens. Such automatically generated thresholds may not be optimal, i.e., by further optimizing the thresholds, our approach may achieve even higher accuracy; while our currently reported accuracy may not be the highest that our approach can achieve.Construct validity. In the evaluation of this work, we com-pare Logram with six other log parsing approaches. There exists other log parsing approaches (e.g., LKE [8]) that are not evaluated in this work. We only consider five existing approaches as we need to manually verify the parsing accuracy of each approach which takes significant human efforts. Besides, the purpose of the work is not to provide a benchmark, but rather to propose and evaluate an inno-vative and promising log parsing approach. Nevertheless, we compare Logram with the best-performing log parsing approaches evaluated in a recent benchmark [21]. Our re-sults show that Logram achieves better parsing accuracy and much faster parsing speed compared to existing state-of-the-art approaches.8 	CONCLUSIONIn this work, we propose Logram, an automated log parsing approach that leverages n-grams dictionaries to parse log data in an efficient manner. The nature of the n-gram dictionaries also enables one to construct the dictionaries in parallel without sacrificing any parsing accuracy and update the dictionaries online when more logs are added (e.g., in log streaming scenarios). Through an evaluation of Logram on 16 public log datasets, we demonstrated that Lo-gram can achieve high accuracy and efficiency while parsing logs in a stable and scalable manner. In particular, Logram outperforms the state-of-the-art log parsing approaches in efficiency and achieves better parsing accuracy than existing approaches. Finally, We demonstrate that Logram can effec-tively supports online parsing when logs are continuously generated as a stream with similar parsing results and efficiency to the offline mode. This is the fist work that uses n-grams in log analysis, which demonstrates a success on leveraging a mix of the (un)natural characteristics of logs. Logram can benefit future research and practices that rely on automated log parsing to achieve their log analysis goals.REFERENCES
[1]
[2]
[3]
[4] T. Barik, R. DeLine, S. M. Drucker, and D. Fisher, “The bones of the system: a case study of logging and telemetry at microsoft,”in Proceedings of the 38th International Conference on Software Engi-neering, ICSE 2016, Austin, TX, USA, May 14-22, 2016 - Companion Volume, 2016, pp. 92–101.J. Cito, P. Leitner, T. Fritz, and H. C. Gall, “The making of cloud applications: an empirical study on software development for the cloud,” in Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering, ESEC/FSE 2015, Bergamo, Italy, August 30 -September 4, 2015, 2015, pp. 393–403.A. J. Oliner and J. Stearley, “What supercomputers say: A study of five system logs,” in The 37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks, DSN 2007, 25-28 June 2007, Edinburgh, UK, Proceedings, 2007, pp. 575–584.
B. Schroeder and G. A. Gibson, “Disk failures in the real world: What does an MTTF of 1, 000, 000 hours mean to you?” in 5th USENIX Conference on File and Storage Technologies, FAST 2007, February 13-16, 2007, San Jose, CA, USA, 2007, pp. 1–16.[5]
[6]
[7]
[8]
[9] W. Xu, L. Huang, A. Fox, D. A. Patterson, and M. I. Jordan,“Detecting large-scale system problems by mining console logs,”in Proceedings of the 22nd ACM Symposium on Operating Systems Principles 2009, SOSP 2009, Big Sky, Montana, USA, October 11-14, 2009, 2009, pp. 117–132.
——, “Online system problem detection by mining patterns of console logs,” in ICDM 2009, The Ninth IEEE International Confer-ence on Data Mining, Miami, Florida, USA, 6-9 December 2009, 2009, pp. 588–597.J. Lou, Q. Fu, S. Yang, Y. Xu, and J. Li, “Mining invariants from console logs for system problem detection,” in 2010 USENIX Annual Technical Conference, Boston, MA, USA, June 23-25, 2010, 2010.
Q. Fu, J. Lou, Y. Wang, and J. Li, “Execution anomaly detection in distributed systems through unstructured log analysis,” in ICDM 2009, The Ninth IEEE International Conference on Data Mining, Miami, Florida, USA, 6-9 December 2009, 2009, pp. 149–158.Z. M. Jiang, A. E. Hassan, G. Hamann, and P. Flora, “Automatic identification of load testing problems,” in 24th IEEE International Conference on Software Maintenance (ICSM 2008), September 28 -October 4, 2008, Beijing, China, 2008, pp. 307–316.
[10] Q. Fu, J. Lou, Q. Lin, R. Ding, D. Zhang, and T. Xie, “Contextual analysis of program logs for understanding system behaviors,”in Proceedings of the 10th Working Conference on Mining Software Repositories, MSR ’13, San Francisco, CA, USA, May 18-19, 2013, 2013, pp. 397–400.[11] “Automated 	root 	cause 	an										
[12] K. Nagaraj, C. E. Killian, and J. Neville, “Structured comparative analysis of systems logs to diagnose performance problems,” in Proceedings of the 9th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2012, San Jose, CA, USA, April 25-27, 2012, 2012, pp. 353–366.[13] M. Chow, D. Meisner, J. Flinn, D. Peek, and T. F. Wenisch, “The mystery machine: End-to-end performance analysis of large-scale internet services,” in 11th USENIX Symposium on Operating Systems Design and Implementation, OSDI ’14, Broomfield, CO, USA, October 6-8, 2014., 2014, pp. 217–231.[14] W. Shang, Z. M. Jiang, H. Hemmati, B. Adams, A. E. Hassan, and P. Martin, “Assisting developers of big data analytics applications when deploying on hadoop clouds,” in 35th International Confer-ence on Software Engineering, ICSE ’13, San Francisco, CA, USA, May 18-26, 2013, 2013, pp. 402–411.[15] Y. Dang, Q. Lin, and P. Huang, “Aiops: real-world challenges and research innovations,” in Proceedings of the 41st International Conference on Software Engineering: Companion Proceedings, ICSE 2019, Montreal, QC, Canada, May 25-31, 2019., 2019, pp. 4–5.[16] Q. Lin, K. Hsieh, Y. Dang, H. Zhang, K. Sui, Y. Xu, J. Lou, C. Li, Y. Wu, R. Yao, M. Chintalapati, and D. Zhang, “Predicting node failure in cloud service systems,” in Proceedings of the 2018 ACM Joint Meeting on European Software Engineering Conference and Sym-posium on the Foundations of Software Engineering, ESEC/SIGSOFT FSE 2018, Lake Buena Vista, FL, USA, November 04-09, 2018, 2018, pp. 480–490.[17] S. He, Q. Lin, J. Lou, H. Zhang, M. R. Lyu, and D. Zhang,“Identifying impactful service system problems via log analysis,”in Proceedings of the 2018 ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/SIGSOFT FSE 2018, Lake Buena Vista, FL, USA, November 04-09, 2018, 2018, pp. 60–70.[18] N. El-Sayed, H. Zhu, and B. Schroeder, “Learning from failure across multiple clusters: A trace-driven approach to understand-ing, predicting, and mitigating job terminations,” in 37th IEEE International Conference on Distributed Computing Systems, ICDCS 2017, Atlanta, GA, USA, June 5-8, 2017, 2017, pp. 1333–1344.[19] P. Huang, C. Guo, J. R. Lorch, L. Zhou, and Y. Dang, “Capturing and enhancing in situ system observability for failure detection,”in 13th USENIX Symposium on Operating Systems Design and Imple-mentation, OSDI 2018, Carlsbad, CA, USA, October 8-10, 2018., 2018, pp. 1–16.
[20] P. He, J. Zhu, S. He, J. Li, and M. R. Lyu, “An evaluation study on log parsing and its use in log mining,” in 2016 46th Annual IEEE/IFIP International Conference on Dependable Systems and Net-works (DSN), June 2016, pp. 654–661.12
[21] J. Zhu, S. He, J. Liu, P. He, Q. Xie, Z. Zheng, and M. R. Lyu,“Tools and benchmarks for automated log parsing,” in Proceedings of the 41st International Conference on Software Engineering: Software Engineering in Practice, ICSE (SEIP) 2019, Montreal, QC, Canada, May 25-31, 2019, 2019, pp. 121–130.[22] P. He, J. Zhu, Z. Zheng, and M. R. Lyu, “Drain: An online log parsing approach with fixed depth tree,” in 2017 IEEE International Conference on Web Services, ICWS 2017, Honolulu, HI, USA, June 25-30, 2017, 2017, pp. 33–40.
[23] Z. M. Jiang, A. E. Hassan, G. Hamann, and P. Flora, “An au-tomated approach for abstracting execution logs to execution events,” Journal of Software Maintenance, vol. 20, no. 4, pp. 249–267, 2008.[24] W. Shang, Z. M. Jiang, B. Adams, A. E. Hassan, M. W. Godfrey, M. Nasser, and P. Flora, “An exploratory study of the evolution of communicated information about the execution of large software systems,” Journal of Software: Evolution and Process, vol. 26, no. 1, pp. 3–26, 2014.
[25] D. Yuan, S. Park, and Y. Zhou, “Characterizing logging practices in open-source software,” in 34th International Conference on Software Engineering, ICSE 2012, June 2-9, 2012, Zurich, Switzerland, 2012, pp. 102–112.[26] B. Chen and Z. M. J. Jiang, “Characterizing logging practices in java-based open source software projects - a replication study in apache software foundation,” Empirical Software Engineering, vol. 22, no. 1, pp. 330–374, 2017.
[27] M. Lemoudden and B. E. Ouahidi, “Managing cloud-generated logs using big data technologies,” in International Conference on Wireless Networks and Mobile Communications, WINCOM 2015, Mar-rakech, Morocco, October 20-23, 2015, 2015, pp. 1–7.[28] H. Li, T. P. Chen, A. E. Hassan, M. N. Nasser, and P. Flora,“Adopting autonomic computing capabilities in existing large-scale systems: an industrial experience report,” in Proceedings of the 40th International Conference on Software Engineering: Software Engineering in Practice, ICSE (SEIP) 2018, Gothenburg, Sweden, May 27 - June 03, 2018, 2018, pp. 1–10.[29] H. Li, W. Shang, Y. Zou, and A. E. Hassan, “Towards just-in-time suggestions for log changes,” Empirical Software Engineering, vol. 22, no. 4, pp. 1831–1865, 2017.
[30] W. B. Cavnar, J. M. Trenkle et al., “N-gram-based text catego-	rization,” in Proceedings of the 3rd annual symposium on document 	analysis and information retrieval, SDAIR ’94, vol. 161175. 	Citeseer, 	1994.[31] M. Siu and M. Ostendorf, “Variable n-grams and extensions for conversational speech language modeling,” IEEE Trans. Speech and Audio Processing, vol. 8, no. 1, pp. 63–75, 2000.
[32] S. Nessa, M. Abedin, W. E. Wong, L. Khan, and Y. Qi, “Software fault localization using n-gram analysis,” in Wireless Algorithms, Systems, and Applications, Third International Conference, WASA 2008, Dallas, TX, USA, October 26-28, 2008. Proceedings, 2008, pp. 548–559.[33] A. Tomovic, P. Janicic, and V. Keselj, “n-gram-based classification and unsupervised hierarchical clustering of genome sequences,”Computer Methods and Programs in Biomedicine, vol. 81, no. 2, pp. 137–153, 2006.
[34] C. Lin and E. H. Hovy, “Automatic evaluation of summaries using n-gram co-occurrence statistics,” in Human Language Technology Conference of the North American Chapter of the Association for Com-putational Linguistics, HLT-NAACL 2003, Edmonton, Canada, May 27- June 1, 2003, 2003.[35] P. F. Brown, V. J. D. Pietra, P. V. de Souza, J. C. Lai, and R. L. Mercer,“Class-based n-gram models of natural language,” Computational Linguistics, vol. 18, no. 4, pp. 467–479, 1992.
[36] E. Charniak, Statistical language learning. 	MIT press, 1996.[37] A. Hindle, E. T. Barr, Z. Su, M. Gabel, and P. Devanbu, “On the 	naturalness of software,” in Proceedings of the 34th International 	Conference on Software Engineering, ser. ICSE’12, 2012, pp. 837–847. [38] M. Rahman, D. Palani, and P. C. Rigby, “Natural software revis-	ited,” in Proceedings of the 41st International Conference on Software 	Engineering, ser. ICSE ’19. 	Piscataway, NJ, USA: IEEE Press, 2019, 	pp. 37–48.[39] T. T. Nguyen, A. T. Nguyen, H. A. Nguyen, and T. N. Nguyen,	“A statistical semantic language model for source code,” in Pro-	ceedings of the 2013 9th Joint Meeting on Foundations of Software 	Engineering, ser. ESEC/FSE 2013. 	New York, NY, USA: ACM, 	2013, pp. 532–542.
[40] S. Bird, E. Klein, and E. Loper, Natural Language Processing with
Python. 	O’Reilly, 2009.Python. 	O’Reilly, 2009.
[41] R. Vaarandi, “Simple event correlator for real-time security log
monitoring,” Hakin9 Magazine, vol. 1, no. 6, pp. 28–39, 2006.
[42] C. V. Damasio, P. Fr¨ohlich, W. Nejdl, L. M. Pereira, and
M. Schroeder, “Using extended logic programming for alarm-
correlation in cellular phone networks,” Applied Intelligence,
vol. 17, no. 2, pp. 187–202, 2002.vol. 17, no. 2, pp. 187–202, 2002.
[43] S. E. Hansen and E. T. Atkins, “Automated system monitoring and
notification with swatch.” in LISA, vol. 93, 1993, pp. 145–152.
[44] R. Ramati, “A beginners guide to logstash grok,” https://logz.io/
blog/logstash-grok, (Accessed on 08/14/2019).
[45] L. 	Bennett,	“Lessons 			
[46] 					