0.060 0.008 0.014 80.87 0.657 0.138 0.215 96.17
Ensemble
99.18
wEnsemble
99.00
0.048 0.008 0.015
95.90
0.156 0.029 0.066
33.22 1.000 1.000
0.00
7.015 0.985 0.992
0.00
33.22 1.000 1.000
0.00
33.22 1.000 1.000
0.00
33.22 1.000 1.000
0.00
33.22 1.000 1.000
0.00
33.22 1.000 1.000
0.00
8.871 0.996 0.998
0.00
33.22 1.000 1.000
0.00
33.22 1.000 1.000
0.00
33.22 1.000 1.000
0.00
33.22 1.000 1.000
0.00
0.773 0.116 0.148
85.45
85.45
0.536 0.105 0.165
93.55 0.273 0.048 0.074
0.592 0.117 0.180
84.00
90.64
0.366 0.068 0.129
0.309 0.057 0.111
93.00
2.331 0.298 0.341
66.03
1.717 0.285 0.345
66.03
67.30
2.066 0.272 0.330
1.996 0.250 0.292
71.31
80.05
0.776 0.151 0.232
training, 8.33% for validation (8.33% is the average percentage of
APKs emerging in each month of 2014), and 8.33% for testing.
Figure 6 plots the balanced accuracy (bAccuracy), balanced NLL
(bNLL) and balanced BSE (bBSE) under temporal covariate shift
(more results are presented in the appendix materials). We make the
following observations. (i) Malware detectors encounter a signifi-
cantly decreasing of accuracy and increasing of bNLL and bBSE with
newer test data. This can be attributed to the natural software evolu-
tion that Google gradually updates Android APIs and practitioners
upgrade their APKs to support new services. In particular, Droide-
tec suffer a lot from temporal covariate shift and exhibits a low
detection accuracy. As mentioned earlier, this may be that Droidetec
is permitted to learn from a limited number of APIs, which inhibits
handling the APKs with a broad range of APIs. (ii) Temp scaling
has the same effect as the vanilla model in terms of bAccuracy; En-
semble enhances the vanilla models (DeepDrebin, MultimodalNN,
and DeepDroid) at the start of several months but then this en-
hancement diminishes; VBI makes MultimodalNN to achieve the
highest robustness under data evolution (but only achieves ∼80%
bAccuracy). (iii) Ensemble methods benefit calibration in terms of
bNLL and bBSE when compared with the vanilla model; VBI in-
corporating DeepDrebin or MultimodalNN achieves an impressive
result.
Figure 7a plots the accuracy (at the upper half) and the balanced
accuracy (at the lower half) after excluding the examples for which
the detectors have entropy values greater than a threshold τ. Fig-
ure 7b plots the sample density of predictive entropy. We observe
that (i) either accuracy or balanced accuracy decreases dramati-
cally when the entropy increases, which is particularly true for
DeepDroid and Droidetec. (ii) MultimodalNN incorporating VBI
seems to work very well in terms of accuracy, but not necessary for
balanced Accuracy. This is because the model classifies most benign
samples correctly but not malicious ones until the threshold value is
approach 0.9. Moreover, it is interesting to see that MultimodalNN
incorporating VBI achieves the best bAccuracy without consider-
ing uncertainty (cf. Figure 6, which is in sharp contrast to Figure
7a). The reason behind this is that MultimodalNN incorporating
VBI correctly classifies a portion of examples with high entropy
value, as shown in Figure 7b. (iii) DeepDrebin incorporating VBI
outperforms the other Drebin-based models, which resonates the
results obtained in our second group of experiments (cf. Figure
4b in Section 4.3). (iv) Figure 7b says that for all of the malware
detectors except MultimodalNN incorporating VBI and DeepDrebin
incorporating VBI, most examples tend to have a small entropy.
This suggests ineffective calibrations of malware detectors under
temporal covariate shifts and a lack of good calibration method.
605Can We Leverage Predictive Uncertainty to Detect Dataset Shift and Adversarial Examples in Android Malware Detection?ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Insight 3. Calibrated malware detectors cannot cope with tempo-
ral datashit shift effectively, but VBI is promising for calibration and
generalization under temporal covariate shift.
4.5 Answering RQ4
In order to quantify the predictive uncertainty of malware detectors
under adversarial evasion attacks, we wage transfer attacks and
generate adversarial APKs via a surrogate DeepDrebin model. We do
not include adversarial APKs with respect to MultimodalNN, Deep-
Droid, and Droidetec because we do not find effective solutions.
The surrogate DeepDrebin model consists of two fully-connected
layers of 160 neurons with the ReLU activation function. We learn
the model using the Adam optimizer with learning rate 0.001, batch
size 128, and 150 epochs. We then generate adversarial examples
against the surrogate model to perturb the 1,112 malicious APKs
in the test dataset. Specifically, by following a recent study [27],
we first perturb the feature vectors of the APKs using the “max”
PGDs+GDKDE attack and the Mimicry attack, and then obtain ad-
versarial APKs by using obfuscation techniques. In total, we obtain
1100 perturbed APK files for both attacks, respectively.
Table 3 summarizes the results of the malware detectors under
the “max” PGDs+GDKDE attack and the Mimicry attack. Because
the test dataset contains malware samples solely, we consider the
Accuracy, NLL, BSE and ECE rather than their balanced versions.
We observe that (i) the “max” PGDs+GDKDE attack renders Deep-
Drebin and MultimodalNN models useless, regardless of the calibra-
tion methods. Nevertheless, DeepDroid is robust against this attack
because opcode are not used by the DeepDrebin and thus is unfo-
cused by the attacker. However, DeepDroid still suffers somewhat
from this attack because of the opcode manipulations is leveraged
for preserving the malicious functionality. (ii) Under the Mimicry
attack, VBI makes DeepDrebin and MultimodalNN achieve the best
accuracy and the lowest calibration error (in terms of NLL and
BSE), while weighted Ensemble makes both obtain the worst re-
sults. However, this situation is changed in regards to DeepDroid
and Droidetec. This might be that DeepDrebin and MultimodalNN
are more sensitive to Mimicry attack than DeepDroid and Droide-
tec, leading to that an ensemble of vulnerable models decreases the
robustness against the attack.
Insight 4. Adversarial evasion attacks can render calibrated mal-
ware detectors, and therefore the quantified predictive uncertainty,
useless, but heterogeneous feature extraction does improve the robust-
ness of malware detectors against the transfer attacks.
5 CONCLUSION
We empirically quantified the predictive uncertainty of four deep
malware detectors with six calibration strategies (i.e., 24 detectors
in total). We found that the predictive uncertainty of calibrated
malware detectors is useful except for adversarial examples. We
hope this study will motivate and inspire more research in quanti-
fying the uncertainty of malware detectors, which is of paramount
importance in practice but it is currently little understood.
ACKNOWLEDGMENTS
Q. Li is supported in part by the National Key R&D Program of
China under Grants 2020YFB1804604 and 2020YFB1804600, the
2020 Industrial Internet Innovation and Development Project from
Ministry of Industry and Information Technology of China, the
Fundamental Research Fund for the Central Universities under
Grants 30918012204 and 30920041112, the 2019 Industrial Internet
Innovation and Development Project from Ministry of Industry and
Information Technology of China. S. Xu is supported in part by NSF
Grants #2122631 (#1814825) and #2115134, ARO Grant #W911NF-
17-1-0566, and Colorado State Bill 18-086.
REFERENCES
[1] Martín Abadi, Ashish Agarwal, and et al. 2015. TensorFlow: Large-Scale Machine
Learning on Heterogeneous Systems. https://www.tensorflow.org/ Software
available from tensorflow.org.
[2] Martín Abadi, Paul Barham, et al. 2016. Tensorflow: A system for large-scale
machine learning. In OSDI’ 16. USENIX Association, Savannah, GA, USA, 265–
283.
[3] Kevin Allix, Tegawendé F. Bissyandé, et al. 2016. AndroZoo: Collecting Millions
of Android Apps for the Research Community. In International Conference on
MSR (Austin, Texas). ACM, NY, USA, 468–471. https://doi.org/10.1145/2901739.
2903508
[4] Daniel Arp, Michael Spreitzenbarth, et al. 2014. Drebin: Effective and explainable
detection of android malware in your pocket. In NDSS, Vol. 14. The Internet
Society, San Diego, California, USA, 23–26.
[5] Umang Bhatt, Yunfeng Zhang, and et al. 2020. Uncertainty as a Form of
Transparency: Measuring, Communicating, and Using Uncertainty. CoRR
abs/2011.07586 (2020). https://arxiv.org/abs/2011.07586
[6] Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. 2015.
Weight Uncertainty in Neural Network. In Proceedings of the 32nd International
Conference on Machine Learning, Vol. 37. PMLR, Lille, France, 1613–1622. https:
//proceedings.mlr.press/v37/blundell15.html
[7] Glenn W Brier. 1950. Verification of forecasts expressed in terms of probability.
Monthly weather review 78, 1 (1950), 1–3.
[8] K. H. Brodersen, C. S. Ong, K. E. Stephan, and J. M. Buhmann. 2010. The Balanced
Accuracy and Its Posterior Distribution. In 2010 20th International Conference on
Pattern Recognition. IEEE Computer Society, Istanbul, Turkey, 3121–3124.
[9] Joaquin Quiñonero Candela, Carl Edward Rasmussen, Fabian H. Sinz, Olivier
Bousquet, and Bernhard Schölkopf. 2005. Evaluating Predictive Uncertainty
Challenge. In Machine Learning Challenges, Evaluating Predictive Uncertainty,
Visual Object Classification and Recognizing Textual Entailment, First PASCAL
Machine Learning Challenges Workshop, Vol. 3944. Springer, Southampton, UK,
1–27.
[10] Lingwei Chen, Yanfang Ye, and Thirimachos Bourlai. 2017. Adversarial Machine
Learning in Malware Detection: Arms Race between Evasion Attack and Defense.
In EISIC’2017. IEEE Computer Society, Athens, Greece, 99–106.
secure! a case study on android malware detection.
711–724.
[11] Forensics Corvus. 2020. VirusShare. https://virusshare.com/
[12] Ambra Demontis, Marco Melis, et al. 2017. Yes, machine learning can be more
IEEE TDSC 16, 4 (2017),
[13] Anthony Desnos. 2020. Androguard. https://github.com/androguard/androguard
[14] Pang Du, Zheyuan Sun, Huashan Chen, Jin-Hee Cho, and Shouhuai Xu. 2018.
Statistical Estimation of Malware Detection Metrics in the Absence of Ground
Truth. IEEE Trans. Inf. Forensics Secur. 13, 12 (2018), 2965–2980.
[15] Yarin Gal and Zoubin Ghahramani. 2016. Dropout as a bayesian approximation:
Representing model uncertainty in deep learning. In international conference on
machine learning. JMLR.org, NY, USA, 1050–1059.
[16] Alex Graves. 2011. Practical Variational Inference for Neural Networks. In
Advances in Neural Information Processing Systems 24: 25th Annual Conference
on Neural Information Processing Systems 2011. Curran Associates Inc., Granada,
Spain, 2348–2356.
[17] Kathrin Grosse, Nicolas Papernot, et al. 2017. Adversarial examples for malware
detection. In ESORICS. Springer, Oslo, Norway, 62–79.
[18] Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q. Weinberger. 2017. On Calibration
of Modern Neural Networks. In Proceedings of the 34th International Conference on
Machine Learning, ICML (Proceedings of Machine Learning Research, Vol. 70), Doina
Precup and Yee Whye Teh (Eds.). PMLR, Sydney, NSW, Australia, 1321–1330.
[19] T. H. Huang and H. Kao. 2018. R2-D2: ColoR-inspired Convolutional NeuRal
Network (CNN)-based AndroiD Malware Detections. In 2018 IEEE International
Conference on Big Data (Big Data). IEEE, Seattle, WA, USA, 2633–2642.
[20] Roberto Jordaney, Kumar Sharad, et al. 2017. Transcend: Detecting Concept Drift
in Malware Classification Models. In USENIX Security 17. USENIX Association,
Vancouver, BC, 625–642. https://www.usenix.org/conference/usenixsecurity17/
technical-sessions/presentation/jordaney
[21] Alex Kendall and Yarin Gal. 2017. What uncertainties do we need in bayesian
deep learning for computer vision?. In NeurIPS. Curran Associates Inc., Long
606ACSAC ’21, December 6–10, 2021, Virtual Event, USA
D. Li, T. Qiu, S. Chen, Q. Li, and S. Xu
[48] Yanfang Ye, Tao Li, and et al. 2017. A Survey on Malware Detection Using Data
Mining Techniques. ACM Comput. Surv. 50, 3 (2017), 41:1–41:40.
[49] Xiaohan Zhang, Yuan Zhang, and et al. 2020. Enhancing State-of-the-Art Clas-
sifiers with API Semantics to Detect Evolved Android Malware. In CCS 2020
(Virtual Event, USA). Association for Computing Machinery, New York, USA,
757–770.
[50] Indr˙e Žliobait˙e, Mykola Pechenizkiy, and João Gama. 2016. An Overview of
Concept Drift Applications. Springer International Publishing, Cham, 91–114.
A EXPERIMENTAL RESULTS ON THE
VIRUSSHARE DATASET
Figure 8 plots the balanced accuracy on the VirusShare dataset
with decision referral. We observe that Figure 8 exhibit the trends
that are similar to what are exhibited by Figure 4b, except for
Temp scaling on DeepDrebin and MultimodalNN. This is because
the model predicts benign examples accurately, but do not predict
malicious examples accurately.
B EXPERIMENTAL RESULTS ON THE
ANDROOZOO DATASET
Figure 9 plots the Accuracy, NLL and BSE of malware detectors
under temporal covariate shifts. We observe that the Accuracy, NLL,
and BSE are smaller than their balanced counterparts plotted in
Figure 6, owing to the data imbalance exhibited by the Androzoo
dataset, despite that they all exhibit a similar trend.
Beach, CA, USA, 5574–5584.
[22] T. Kim, B. Kang, et al. 2019. A Multimodal Deep Learning Method for Android
Malware Detection Using Various Features. IEEE Trans. Info. Forensics and Sec.
14, 3 (2019), 773–788.
[23] Yoon Kim. 2014. Convolutional Neural Networks for Sentence Classification.
In Proceedings of the 2014 Conference on Empirical Methods in Natural Language
Processing, EMNLP, Alessandro Moschitti, Bo Pang, and Walter Daelemans (Eds.).
ACL, Doha, Qatar, 1746–1751.
[24] Kaspersky Lab. 2020. Kaspersky. https://www.kaspersky.com
[25] Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. 2017. Simple
and scalable predictive uncertainty estimation using deep ensembles. In NeurIPS.
Curran Associates Inc., Long Beach, CA, USA, 6402–6413.
[26] Christian Leibig, Vaneeda Allken, Murat Seçkin Ayhan, Philipp Berens, and
Siegfried Wahl. 2017. Leveraging uncertainty information from deep neural
networks for disease detection. Scientific reports 7, 1 (2017), 1–14.
[27] Deqiang Li and Qianmu Li. 2020. Adversarial Deep Ensemble: Evasion Attacks
and Defenses for Malware Detection. IEEE Trans. Info. Forensics and Sec. 15 (2020),
3886–3900.
[28] Jie Lu, Anjin Liu, Fan Dong, Feng Gu, João Gama, and Guangquan Zhang. 2019.
Learning under Concept Drift: A Review. IEEE Trans. Knowl. Data Eng. 31, 12
(2019), 2346–2363.
[29] Zhuo Ma, Haoran Ge, Zhuzhu Wang, Yang Liu, and Ximeng Liu. 2020. Droidetec:
Android malware detection and malicious code localization through deep learning.
CoRR abs/2002.03594 (2020). https://arxiv.org/abs/2002.03594
[30] Niall McLaughlin, Jesus Martinez del Rincon, et al. 2017. Deep Android Malware
Detection. In CODASPY ’17 (Scottsdale, Arizona, USA). ACM, NY, USA, 301–308.
https://doi.org/10.1145/3029806.3029823
[31] Mahdi Pakdaman Naeini, Gregory Cooper, and Milos Hauskrecht. 2015. Obtain-
ing well calibrated probabilities using bayesian binning. In Twenty-Ninth AAAI
Conference on Artificial Intelligence. AAAI Press, Austin, Texas, USA, 2901–2907.
[32] André T. Nguyen, Edward Raff, Charles Nicholas, and James Holt. 2021. Leverag-
ing Uncertainty for Improved Static Malware Detection Under Extreme False Pos-
itive Constraints. CoRR abs/2108.04081 (2021). https://arxiv.org/abs/2108.04081
[33] Alexandru Niculescu-Mizil and Rich Caruana. 2005. Predicting good probabilities
with supervised learning. In ICML. ACM, Bonn, Germany, 625–632.
[34] Tim Pearce, Felix Leibfried, et al. 2020. Uncertainty in Neural Networks: Approx-
imately Bayesian Ensembling. In AISTATS. PMLR, Online [Palermo, Sicily, Italy],
234–244.
[35] Feargus Pendlebury, Fabio Pierazzi, et al. 2019. TESSERACT: Eliminating Experi-
mental Bias in Malware Classification across Space and Time. In USENIX Security
19. USENIX Association, Santa Clara, CA, 729–746. https://www.usenix.org/
conference/usenixsecurity19/presentation/pendlebury
[36] Marcus Pendleton, Richard Garcia-Lebron, Jin-Hee Cho, and Shouhuai Xu. 2016.
A Survey on Systems Security Metrics. ACM Comput. Surv. 49, 4 (Dec. 2016),
1–35.
[37] Joaquin Quionero-Candela, Masashi Sugiyama, Anton Schwaighofer, and Neil D.
Lawrence. 2009. Dataset Shift in Machine Learning. The MIT Press, Cambridge,
MA.
[38] Hispasec Sistemas. 2020. VirusTotal. Alphabet, Inc. https://www.virustotal.com
[39] Jasper Snoek, Yaniv Ovadia, Emily Fertig, Balaji Lakshminarayanan, Sebastian
Nowozin, D Sculley, Joshua Dillon, Jie Ren, and Zachary Nado. 2019. Can you
trust your model’s uncertainty? Evaluating predictive uncertainty under dataset
shift. In Advances in Neural Information Processing Systems. Curran Associates
Inc., Vancouver, BC, Canada, 13969–13980.
[40] Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan
Salakhutdinov. 2014. Dropout: a simple way to prevent neural networks from
overfitting. The journal of machine learning research 15, 1 (2014), 1929–1958.
[41] Trias Thireou and Martin Reczko. 2007. Bidirectional long short-term mem-
ory networks for predicting the subcellular localization of eukaryotic proteins.
IEEE/ACM transactions on computational biology and bioinformatics 4, 3 (2007),
441–446.
[42] Connor Tumbleson and Ryszard Wiśniewski. 2020. Apktool. https://ibotpeaches.
[43] Juozas Vaicenavicius, David Widmann, Carl R. Andersson, Fredrik Lindsten, Jacob
Roll, and Thomas B. Schön. 2019. Evaluating model calibration in classification. In
The 22nd International Conference on Artificial Intelligence and Statistics, AISTATS,
Vol. 89. PMLR, Naha, Okinawa, Japan, 3459–3467.
[44] Cheng Wang, Carolin Lawrence, and Mathias Niepert. 2021. Uncertainty Estima-
tion and Calibration with Finite-State Probabilistic RNNs. In 9th International
Conference on Learning Representations. OpenReview.net, Virtual Event, Austria.
[45] Max Welling and Yee W Teh. 2011. Bayesian learning via stochastic gradient
Langevin dynamics. In ICML. Omnipress, Madison, WI, USA, 681–688.
Drift and Hidden Contexts. Mach. Learn. 23, 1 (1996), 69–101.
[47] Li Xu, Zhenxin Zhan, Shouhuai Xu, and Keying Ye. 2014. An evasion and counter-
evasion study in malicious websites detection. In IEEE Conference on Communi-
cations and Network Security (CNS’2014). IEEE, San Francisco, CA, USA, 265–273.
[46] Gerhard Widmer and Miroslav Kubat. 1996. Learning in the Presence of Concept
github.io/Apktool
607Can We Leverage Predictive Uncertainty to Detect Dataset Shift and Adversarial Examples in Android Malware Detection?ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Figure 8: The balanced accuracy on the VirusShare dataset after excluding the examples for which the detector has high
uncertainties (i.e., the examples for which the predictive entropy is above a pre-determined threshold τ). For each curve, a
shadow region is obtained from the 95% confidence interval using a bootstrapping with 103 repetitions and sampling size
being the number of examples in the VirusShare dataset.
Figure 9: Illustration of accuracy, NLL, BSE under temporal covariate shift on the Androzoo dataset. A shadow region is ob-
tained from the 95% confidence interval using a bootstrapping with 103 repetitions and sampling size being the number of
APKs in per month (cf. Figure 2).
0.00.20.40.60.81.0Threshold 0.70.80.91.0bAccuracy on  examples w/ entropyDeepDrebin0.00.20.40.60.81.0Threshold MultimodalNN0.00.20.40.60.81.0Threshold DeepDroid0.00.20.40.60.81.0Threshold DroidetecVanillaTemp scalingMC dropoutVBIEnsemblewEnsemble0.800.850.900.951.00AccuracyDeepDrebinMultimodalNNDeepDroidDroidetec0.001.002.003.00NLLVBIEnsemblewEnsembleTest set2015-022015-042015-062015-082015-102015-122016-022016-042016-062016-082016-102016-120.000.050.100.150.20BSETest set2015-022015-042015-062015-082015-102015-122016-022016-042016-062016-082016-102016-12VanillaTemp scalingMC dropoutTest set2015-022015-042015-062015-082015-102015-122016-022016-042016-062016-082016-102016-12Test set2015-022015-042015-062015-082015-102015-122016-022016-042016-062016-082016-102016-12608