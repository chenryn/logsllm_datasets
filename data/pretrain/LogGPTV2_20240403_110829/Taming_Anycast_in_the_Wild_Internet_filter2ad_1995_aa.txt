title:Taming Anycast in the Wild Internet
author:Stephen McQuistin and
Sree Priyanka Uppu and
Marcel Flores
Taming Anycast in the Wild Internet
Stephen McQuistin
University of Glasgow
Glasgow, UK
PI:EMAIL
Sree Priyanka Uppu
Verizon Digital Media Services
Los Angeles, CA, USA
PI:EMAIL
Marcel Flores
Verizon Digital Media Services
Los Angeles, CA, USA
PI:EMAIL
ABSTRACT
Anycast is a popular tool for deploying global, widely available
systems, including DNS infrastructure and content delivery net-
works (CDNs). The optimization of these networks often focuses on
the deployment and management of anycast sites. However, such
approaches fail to consider one of the primary configurations of
a large anycast network: the set of networks that receive anycast
announcements at each site (i.e., an announcement configuration).
Altering these configurations, even without the deployment of
additional sites, can have profound impacts on both anycast site
selection and round-trip times.
In this study, we explore the operation and optimization of any-
cast networks through the lens of deployments that have a large
number of upstream service providers. We demonstrate that these
many-provider anycast networks exhibit fundamentally different
properties when interacting with the Internet, having a greater
number of single AS hop paths and reduced dependency on each
provider, compared with few-provider networks. We further exam-
ine the impact of announcement configuration changes, demon-
strating that in nearly 30% of vantage point groups, round-trip time
performance can be improved by more than 25%, solely by manipu-
lating which providers receive anycast announcements. Finally, we
propose DailyCatch, an empirical measurement methodology for
testing and validating announcement configuration changes, and
demonstrate its ability to influence user-experienced performance
on a global anycast CDN.
CCS CONCEPTS
• Networks → Network architectures; Network performance
evaluation; Network experimentation; Network measurement;
ACM Reference Format:
Stephen McQuistin, Sree Priyanka Uppu, and Marcel Flores. 2019. Taming
Anycast in the Wild Internet. In Internet Measurement Conference (IMC ’19),
October 21–23, 2019, Amsterdam, Netherlands. ACM, New York, NY, USA,
14 pages. https://doi.org/10.1145/3355369.3355573
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than ACM
must be honored. Abstracting with credit is permitted. To copy otherwise, or republish,
to post on servers or to redistribute to lists, requires prior specific permission and/or a
fee. Request permissions from permissions@acm.org.
IMC ’19, October 21–23, 2019, Amsterdam, Netherlands
© 2019 Association for Computing Machinery.
ACM ISBN 978-1-4503-6948-0/19/10...$15.00
https://doi.org/10.1145/3355369.3355573
Figure 1: Anycast networks may feature either few (left) up-
stream network providers, or many (right).
1 INTRODUCTION
IP anycast is widely used for providing high-availability and low-
latency network services, including DNS and CDNs. With IP any-
cast, network operators announce the same IP prefixes from multi-
ple geographically-distributed sites. While each site provides the
same service, the performance experienced by end-users can vary
significantly based on the site selected and the path taken. How-
ever, BGP has no notion of latency or load, and may be heavily
influenced by arbitrary network policy, further complicating the
situation. Moreover, anycast networks do not have direct control
over inbound routing: this is largely determined by the policies of
upstream providers. Here, we specifically take providers to mean
transit, paid, and exchange peers, as well as any network intercon-
nection that provides client connectivity.
A significant portion of the prior work on anycast performance
has focused on assessing the performance of anycast networks
based on geographic distance, or the comparative performance of
unicast addresses. However, such comparisons create unrealistic
goals: in the absence of new meta-information or routing techniques
(e.g., [27]), it is unlikely that such performance gains can be realized.
Instead, we argue that the approaches with the greatest potential are
those that can be deployed using the existing routing infrastructure.
We further argue that, in the case of many-provider networks
with broad and diverse peering links, the correct mechanism for
influencing routing decisions is through the announcements them-
selves, by altering the set of providers that receive them. However,
doing so requires careful measurement to enable the attribution of
observed changes.
In this paper, we demonstrate that anycast networks with more
providers interact directly with a larger share of the Internet than
networks with fewer providers. We show that having a large num-
ber of providers results in a greater proportion of short paths, with
up to 86% of publicly visible paths consisting of only a single AS
hop. We also demonstrate that such networks feature lower AS
hegemony, a measure of the variety seen on inbound paths [19],
AnycastSitesProvidersFew ProvidersMany ProvidersThe InternetIMC ’19, October 21–23, 2019, Amsterdam, Netherlands
Stephen McQuistin, Sree Priyanka Uppu, and Marcel Flores
showing the complexity and potential power of many-provider
configurations.
Moreover, we examine how manipulating inbound routes alters
the end-user performance of anycast. We demonstrate that these
announcement changes may induce significant changes to both
the site selected, as explored in previous work [15, 27], as well as
changes in the route taken. 49.5% of vantage point groups shift
site catchment (i.e. route to a different site), producing an over 25%
reduction in round-trip time (RTT) for 30% of groups. However,
adding or removing announcements to providers does not always
result in improved RTT performance, and indeed indiscriminately
announcing to new providers results in reduced performance in
nearly 40% of networks.
To allow for the purposeful management of configurations, we
present DailyCatch, a methodology for managing announcement
configurations using routine empirical measurements. DailyCatch
captures the performance changes induced by modifications to
anycast announcement configurations, allowing operators to assess
and weigh the impacts of any change. We further show, using
measurements from a large, global, anycast CDN, that DailyCatch
exposes a number of provider policies that confirm that managing
provider configurations is highly non-trivial. While many large
anycast networks have been studied previously, we believe we are
the first study of the performance impacts of anycast configuration
manipulation in a production, many-provider anycast network.
Previous studies have explored techniques for managing anycast
networks, including proposals to use only a single provider [10],
focusing on effective deployment at site level [15], working around
poor anycast performance using DNS routing [12], and deploying
new BGP communities [27]. While many of these approaches are
effective in context, they may not be applicable in scenarios where
many providers are necessary for scale and reliability, certain site
choices are not available, significant rearchitecting is not possible,
or upstream providers are unlikely to provide support for new
communities. We therefore focus on the existing environment, in
which having many providers is necessary and where many of those
providers are non-cooperative. We further focus on solutions that
can realistically be implemented in an existing, real-world network.
To this end, we perform our measurements and analysis in the
context of a global, commercial CDN that relies on anycast for its
site selection. Despite our focus on anycast, many of our findings
further apply to unicast deployments with similar many-provider
arrangements.
We structure the remainder of this paper as follows. In Section 2,
we provide an overview of anycast networks and structural in-
sight into how such networks interact with the wider Internet at
the BGP level. Next, in Section 3, we examine the specific impacts
of announcement configuration changes on RTT performance. In
Section 4, we present DailyCatch, and provide some examples of
its measurements from the perspective of a global CDN provider.
In Section 5, we examine some of the trade-offs of our design, in-
cluding the challenges of performing active measurements. Finally,
Section 6 describes related work and in Section 7, we conclude.
2 ANYCAST AND BGP
IP anycast is a technique for deploying distributed services. An
operator announces the same IP prefixes from multiple physical
locations, or anycast sites. Site selection is then performed by routers
employing BGP in the process of routing traffic. The catchment of
a given site is the set of clients that are routed to that site [28, 30].
Commonly deployed anycast networks consist of clusters of servers
that service requests from end-users, e.g., DNS root servers or HTTP
servers in a CDN. In addition to the benefits of automatic site
selection, anycast enables easy failover (i.e., a site can go offline
simply by withdrawing its routes, and BGP will determine new
paths to alternative sites). In many cases, it also allows services to
easily increase capacity by adding more sites, without having to
scale up load balancing infrastructure. Finally, by deploying sites
in diverse geographic locations with a diverse set of providers,
operators can add significant robustness to their networks.
However, by pushing site selection into BGP, which has no notion
of performance or load, anycast operators essentially cede control
of their inbound traffic to upstream networks. Doing so exposes
the anycast network to the impacts of upstream decisions: different
transit providers may make different routing decisions and may
apply different re-announcement policies. Other providers may
re-announce only in specific regions or in other conditions. As
described in previous work [15, 16, 27], these external decisions are
difficult to predict, and they change not only where traffic arrives
(i.e., the site the traffic arrives at, and the catchment to which each
user belongs), but also how traffic arrives at that site (i.e., the AS
path taken).
These challenges are further complicated by the need for many-
provider anycast networks. While anycast networks often have
complex networking configurations, consisting of both globally
visible and local-network configurations [3], their specific use cases
may determine their use of upstream providers. The frequent use
of anycast for end-user facing services encourages operators to
connect to a large number of networks [22]. This increased con-
nectivity provides an opportunity for greater capacity (particularly
in the case of CDNs) and greater reliability and fault-tolerance,
balancing both provider and site failures. While previous work has
demonstrated that using only a single provider may produce the
most predictable results [10, 27], such a configuration is not feasible
for large deployments, as noted in [27]. Indeed, directly connecting
to networks offers significant potential to improve performance
and reduce costs.
The complexity of configuring who receives anycast announce-
ments, and where (i.e., at which sites), however, creates opportunity
for optimization. In having a large number of upstream providers,
the anycast operator has a configuration space in which to manip-
ulate their anycast configuration. By changing the set of providers
that their anycast prefixes are announced to, operators may elicit a
change in how a particular client reaches their network, either by
influencing the site they are served by, or the path that their traffic
takes to the same site. While we focus on anycast, our conclusions
largely apply to unicast networks with many-providers.
In this paper, we investigate an approach for determining the
impact that a particular set of announcements has on performance.
First, however, we examine the observable structural differences
Taming Anycast in the Wild Internet
IMC ’19, October 21–23, 2019, Amsterdam, Netherlands
between networks with relatively few providers, and those with
more providers.
2.1 Choice of Anycast Networks
In order to develop an understanding of many-provider anycast, we
examine multiple large anycast networks. As our first measurement
target, we consider the DNS root servers. The DNS roots have been a
common measurement target when studying anycast [15, 27]. They
are appealing targets due to the relative availability of information
on their deployments [3], as well as the fact that they are managed
by multiple organizations with differing deployment strategies.
Next, we consider measurements from a large, globally deployed
commercial content delivery network (CDN). This network features
over one hundred sites spread across the world, with thousands
of interconnects. Its large footprint and aggressive peering strat-
egy provide an important viewpoint from an operational anycast
network. From a BGP announcement perspective, the CDN oper-
ates multiple, independent anycast networks from the same AS.
In particular, different announcements are restricted to particu-
lar physical locations in a region. In this study, we treat these as
entirely separate entities, which we label CDN-1 through CDN-
4. When serving end-users, DNS is used to map requests to the
appropriate anycast network, providing a single global network.
We note that ultimately this arrangement dampens some effects of
many-provider networks, as each network has a limited scope.
Finally, we consider Google DNS (8.8.8.8, which we label GDNS)
as it also represents a large, global, high-traffic anycast network.
Each of these networks is designed to service different traffic
patterns, with the root servers providing service to DNS resolvers,
the CDN servicing HTTP requests, and GDNS acting as a local
resolver. We aim not to assess the performance of any particular
approach, but to instead demonstrate that the differences between
them create the opportunity for optimization based on announce-
ment configurations.
2.2 Many-Provider Networks
In this section, we demonstrate that, fundamentally, large, many-
provider networks interact more directly with a larger portion of the
Internet than those that operate with only a few providers. These
structural differences change the way in which anycast must be
managed and increase the need for direct, evidence-based anycast
management. This further emphasizes the need to study both the
resulting catchments, as in previous work [15], and the need for
determining how (i.e., which path) clients take to the network.
We examine public BGP data from a set of RouteViews [4] col-
lectors1. While BGP reveals many of the structural relationships
that exist, it is important to note that the data used here may un-
derestimate the effects that some of these relationships have. This
is due to the nature of public BGP collectors and the presence of
private peering links that may not be visible in public BGP data.
However, such limitations are well known [32], and do not affect
the generality of our conclusions.
1
route-views.{2, 3, 4, 6, eqix, isc, telxatl, nwax, sfmix, chicago,
flix, kixp, jinx, linx, soxrs, napafrica, wide, sydney, sg, saopaulo,
chile}
Figure 2: Counts of unique AS neighbors for DNS root
servers (excl. G and H), the CDN, and GDNS.
Neighbors Figure 2 shows counts of the unique AS neighbors2
for each of the DNS roots, the CDN, and Google’s DNS service. As
shown, the aggressive peering policies of both the CDN and GDNS
are apparent, as they have significantly more AS neighbors than
all but the K root. This view presents us with two broad groups:
those with few AS neighbors (fewer than 10 upstream providers),
and those with many neighbors (10 or more providers). While
neighbor counts alone do not determine routing behavior, they
provide insight into how many possible routes a client may take to
the anycast network. We acknowledge that the boundary between
the few and many provider classes (of 10 providers) is somewhat
arbitrary. However, the goal of this classification is not to determine
a precise boundary between each class, but to use these classes to