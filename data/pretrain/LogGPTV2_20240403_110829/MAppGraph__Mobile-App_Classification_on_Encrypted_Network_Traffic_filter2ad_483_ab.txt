3.2.1 Graph Convolution Layers. Given a graph G := (V, E), let
A be the adjacency matrix of G such that A is a symmetric binary
matrix with the assumption that the graph has no self-loops. The
node feature matrix is defined as X ∈ Rn×d where n = |V|. A
graph convolution layer computes node latent representation as
Z = σ( ˜D−1 ˜AXW ) where ˜A := A + I is the adjacency matrix with
added self-loops, ˜D is the diagonal degree matrix of the graph such
˜Ai, j, W ∈ Rd×d is a matrix of trainable graph
that ˜Di,i
convolution parameters that are shared among nodes, σ is a non-
linear activation function, and Z ∈ Rn×d is the output activation
matrix.
:= 
j
Intuitively, nodes in a graph are defined by their neighbors and
connections. Thus, the latent representation of a node is also af-
fected by that of its neighbors. The graph convolution layers reflect
this rationale by starting from node features (XW ), allow informa-
tion to propagate between neighboring nodes by the product of
node features and adjacency matrix ( ˜AXW ). To compute multi-
scale node latent representation, multiple graph convolution layers
can be stacked. The final node latent representation is computed as
Z l +1 = σ( ˜D−1 ˜AZ lW l) where l = 0 . . . L − 1, Z 0 := X, Z l ∈ Rn×dl
is the output of the lth graph convolution layer; dl is the number
Figure 2: Information Propagation Between Nodes with Mul-
tiple Convolution Layers.
of the output channels of the lth layer (i.e., the number of features
of each graph node extracted at the lth layer); W l ∈ Rdl×dl +1 is
trainable parameters of the lth layer. In Figure 2, we illustrate how
the features of a node are propagated to its neighbors during the
convolution process given the graph example depicted in Figure 1.
After the completion of the convolution process through all convo-
lution layers, we obtain node latent representation that can learn
from the entire graph topology.
3.2.2 Pooling Layers. Given node latent representation obtained
from the first stage through graph convolution layers, the pool-
ing layers aim at combining latent representation of all the nodes
into a vector with a predefined order and size. The output of the
pooling layers is a latent representation of a graph. There exist
several pooling approaches such as global pooling [15] and hier-
archical pooling [21, 48]. Global pooling is the simplest approach
that takes the mean and max of the final node latent representation.
Hierarchical pooling step-by-step reduces the number of nodes
(after one or multiple graph convolution layers) either by merging
similar nodes to super-nodes [48] or selecting the most significant
nodes [21] until a single super-node is found. In DGCNN [49], the
authors developed SortPooling algorithm for sorting nodes by the
sum of node features at the Lth layer, which is the last layer in
the graph convolution stage. If two nodes have the same value at
the lth layer, the sum of node features at the (l − 1)th layer is used
until ties are broken. Since the number of nodes in each graph is
heterogeneous, pooling layers also perform truncation or extension
of the graph latent representation to a predefined size, which is
then fed to the third/last stage of the graph classification process.
Given a predefined size of the graph latent representation (say k), if
there are more than k values in the graph latent representation vec-
tor, truncation is performed. Otherwise, zero-padding is performed.
The value of k is defined heuristically based on the input data. For
instance, k is defined such that 90% of graph nodes will be used to
construct the graph latent representation vector so as to avoid loss
of node features in the final graph latent representation.
3.2.3 Neural Network Layers. After pooling layers, each graph
is represented by a latent vector. To further learn the local pat-
tern of graphs, one or multiple 1-dimensional convolution layers
associating with MaxPooling layers are applied before using fully-
connected layers followed by a softmax layer to predict the class.
3.3 Network Traffic Collection
We assume that mobile traffic collection can be done by network
operators using available network monitoring tools [20], which
capture the traffic without interfering with app functionalities. As
our technique does not require the payload, it can be discarded to
ACDEBFFeature vectorFeature vector243125Feature vectorFeature vectorFeature vectorFeature vector...Layer 0Layer 1ECBFADLayer 2ECBFADE1028MAppGraph: Mobile-App Classification on Encrypted Network Traffic using Deep Graph Convolution Neural Networks ACSAC ’21, December 6–10, 2021, Virtual Event, USA
reduce the storage space needed. To prepare the training dataset
for the classifier, a large amount of traffic needs to be collected and
processed. While this task can be done in an offline manner, the
inference phase needs to be done in real-time so as to react to the
abnormal behavior of mobile apps. After being analyzed by the
classifier, the traffic samples collected during the inference phase
can also be discarded or stored to enrich the training dataset.
4 MOBILE-APP CLASSIFICATION USING
DEEP GRAPH CONVOLUTION NEURAL
NETWORKS
(a)
(b)
(c)
Figure 3: Examples of Traffic Behavior Graphs of Facebook
(a and b) and Spotify (c) Constructed by Our Approach.
We now present MAppGraph, a novel technique that adopts DGCNN
to cybersecurity for the problem of mobile-app classification. We
first present the most important task that is the construction of
graphs of mobile-app traffic behavior and node feature extraction.
We then present the DGCNN architecture used in our work.
4.1 Construction of Traffic Behavior Graphs
4.1.1 Construction of Graph Topology. Given that network traffic
of mobile apps is captured with a predefined time window (Twindow),
say 5 minutes, the construction of a traffic behavior graph involves
node and edge determination to correlate nodes and weight com-
putation for the edges. It should be noted that the longer the time
window, the more the traffic is captured and the diverse the app
behavior is observed. Obviously, the longer the time window, the
longer the time needed before the app is classified. This may af-
fect the security of the networks or mobile service platform as the
app can exhibit malicious behavior that needs to be detected as
soon as possible. At first glance, a naive solution is to construct a
traffic behavior graph by considering the IP addresses (including
the IP address of the device) as graph nodes and connecting those
nodes based on traffic flows exchanged among them. However, this
makes all the graphs in the star form where the device IP address
is the central node that has connections to all the remaining nodes.
Furthermore, as mobile apps share third-party services, the star-
formed graphs of many apps will be similar with the same number
of nodes.
To overcome this issue and produce a better graph represen-
tation of the traffic behavior of mobile apps, we define a graph
node by a tuple of a destination IP address and the port number of
the service that the app connects to. Multiple third-party services
may be deployed under the same server (i.e., the same IP address)
but with different port numbers. For instance, SMTP Email and
DNS services may have the same IP address but using different
port numbers (587 for the secure email service and 53 for the DNS
service). It is to be noted that third-party services are usually de-
ployed in multiple servers (with different IP addresses) to provide
load balancing. The requests from mobile apps will be distributed
to a specific service based on their load. For this reason, using a
rule-based classification approach with the destination IP address
may not work well. Nevertheless, the port number does not change
and the number of destination nodes remain unchanged.
The challenging issue is how to determine whether two nodes are
correlated such that an edge between them needs to be established.
To achieve this goal, we adopt the temporal correlation concept pre-
sented in [44], which is in turn based on the cross-correlation [32]
t =1 ai(t) · aj(t).
node j during T slices is defined as Ci, j =T
between activities of all node pairs. Given the traffic captured in a
time window that results in the list of graph nodes determined as
discussed above, the time window is further divided into multiple
slices with a predefined slice duration (tslice, say 10 seconds). Let T
denote the number of slices. During each slice, we consider a node
(i.e., a pair of a destination IP address and a port number) is active
if the mobile app has sent or received at least one traffic packet
to the service deployed at the destination IP address and the port
number. Let ai(t) be a binary variable indicating whether node i
is active at time slice t or not such that ai(t) = 1 if node i is active
and ai(t) = 0, otherwise. The cross-correlation between node i and
The cross-correlation between two nodes (Ci, j) is high if they
have a lot of activities in the same time slices. Otherwise, Ci, j is
low or even equal to zero if there is no correlation between them.
Using cross-correlation, we can establish edges among nodes and
set the weight for the edges accordingly. If Ci, j (cid:44) 0, an edge be-
tween node i and node j is established with the weight Ci, j. To
avoid the feature bias when feeding graphs to DCGNN for train-
ing and prediction, we can normalize the cross-correlation to the
range [0, 1] using a min-max scaler. Using the graph construction
technique presented above, we achieve the graph representation of
communication behavior of mobile apps as shown in Figure 3 with
three example graphs of Facebook and Spotify. The thickness of
the edge between two nodes indicates the weight of the edge (i.e.,
the cross-correlation between the nodes).
4.1.2 Extraction of Node Features. We need to construct a feature
vector for each node in the graphs. Since a mobile app connects to
various services, each being represented by a node in the graph as
a tuple of an IP address and a port, the behavior of traffic from the
mobile device to the server of each service may be different in terms
of various traffic features such as packet size, number of packets,
flow duration, etc. To generalize our technique (MAppGraph) to
both encrypted and unencrypted traffic, we extract information
only from packet headers without analyzing packet payloads. Apart
from packet features, we also consider flow features such as the
number of flows, mean number of packets in each flow and mean
flow size in bytes. In this work, we consider only TCP and UDP flows
and we rely on Wireshark to collect traffic features. In practical
scenarios, an online traffic feature extraction tool such as [43] is
needed to process the traffic stream on the fly. It is also to be noted
that a flow is different from a TCP session, which is defined with
TCP flags and can last for a long duration. As defined in [43], a
flow is a sequence of packets that have the same tuple of source IP,
1144228833556677992233114455667788991029ACSAC ’21, December 6–10, 2021, Virtual Event, USA
T.-D. Pham et al.
Figure 4: Architecture and Parameters of MAppGraph Model for Mobile App Classification.
destination IP, source port destination port and protocol, and the
inter-arrival time between two consecutive packets is shorter than
a predefined threshold (e.g., 3 seconds). From the basic features,
we derive statistical features that are useful for DGCNN to learn
the communication behavior of mobile apps. There is a total of
63 features, which are extracted and derived from the traffic. We
classify these features into 4 categories.
tion, the mean and standard deviation of flow duration.
• Aggregated features: These are the features computed as
sum, total count, max and min values of basic features over
the time window of traffic capture (e.g., 5 minutes). These
include the total number of packets, the total number of
bytes and the total number of flows.
• Temporal features: Temporal features include the flow dura-
• Statistical features: These are the mean, median absolute
deviation (MAD), variance, skew, kurtosis and standard de-
viation (in the short stand. dev.) of packet size (in bytes),
number of packets, number of bytes, flow size (in bytes)
over the time window of traffic capture (e.g., 5 minutes).
We separate incoming and outgoing packets and extract fea-
tures before aggregating them all together to provide more
statistical features.
• Categorical features: Categorical features such as transmis-
sion protocol and IP address need to be factorized before
being fed to MAppGraph. Each IP address is factorized and
normalized into 4 features, each representing a component
of the address. For instance, the IP address 223.12.45.68 is
factorized as 4 features (223/255, 12/255, 45/255, 68/255).
In Table 1, we summarize the list of traffic features used for attribut-
ing graph nodes. Instead of performing feature selection and using
only important features for attributing graph nodes, we leverage
the capability of deep learning that can learn latent characteristics
of data and feed all the possible features to MAppGraph. On one
hand, this implicitly relieves the effort of feature engineering and
selection. On the other hand, this provides maximum information
that can be collected from network traffic to achieve the highest
performance in mobile app classification.
4.2 MAppGraph Model Architecture
In Figure 4, we present the architecture and detailed parameters of
the MAppGraph model obtained after a parameter tuning process.
We employ 3 graph convolution layers, each having the size of 1024.
The SortPooling layer that follows the graph convolution layers
Table 1: Traffic features used for attributing graph nodes
No.
1
2
3
4
5
6
7
8
9
10-18
19-37
38-56
57
58
59
60
61
62
63
Feature
Number of incoming packets
Max of incoming packet size
Min of incoming packet size
Mean of incoming packet size
MAD of incoming packet size
Stand. dev. of incoming packet size
Variance of incoming packet size
Skew of incoming packet size
Kurtosis of incoming packet size
10 − 90 percentile of incoming packet size
Features 1-18 for outgoing packets
Features 1-18 on both types of packets
Mean flow size (in bytes)
Mean flow duration (in seconds)
Stand. dev. of flow duration (in seconds)
Total number of flows
Mean number of packets in each flow
Transmission protocol
IP address of the node
Category
Aggregate
Aggregate
Aggregate
Statistical
Statistical
Statistical
Statistical
Statistical
Statistical
Statistical
Statistical
Temporal
Temporal
Aggregate
Statistical
Categorical
Categorical
has the size of 512. The activation function used in graph convolu-
tion layers and the SortPooling layer is tanh. In the classification
stage, we employ two traditional 1-dimensional convolution lay-
ers, between them a MaxPooling layer is integrated. The output of
the 1-dimensional convolution layers is flattened before being fed
to a fully-connected layer with a size of 1024 with a ReLU activa-
tion function. Before the softmax layer for classification, a Dropout
layer with a dropout probability of 0.25 is used to prevent the model
from overfitting. We use Adam optimizer [19] during the training
of MAppGraph.
5 EXPERIMENTS
5.1 Data Collection
There exist several datasets that contain encrypted traffic of mobile
apps such as ReCon [34], Cross Platform [33] and ANDRUBIS [23].
These datasets contain the traffic of a large number of mobile apps
on various platforms such as Android and iOS, i.e., up to 512 mobile
apps. However, the duration of traffic capture for each mobile app is
not long enough (the longest average duration is 339.4 seconds [44])
for observing diverse behavior and various functionalities of the
apps. We note that existing work such as [44] needs at least 300 sec-
onds of traffic capture to create fingerprints of an app. Furthermore,
these pre-processed datasets do not provide all features required in
SortPoolingConv1D (256)MaxPoolingConv1D (512)Dense (1024, relu)Dropout (0.25)Dense (Out)GCN (1024, tanh)GCN (1024, tanh)GCN (1024, tanh)GCN (512, tanh)1030MAppGraph: Mobile-App Classification on Encrypted Network Traffic using Deep Graph Convolution Neural Networks ACSAC ’21, December 6–10, 2021, Virtual Event, USA
our technique. Thus, to capture the traffic of diverse user behavior
and various functionalities of mobile apps, we decided to carry out
our own traffic data collection.
We focused on Android apps, which can run on various brands
of smartphones such as Samsung, Xiaomi, Google Pixel, etc. Our
research team along with a recruited team of 10 students (see Ap-
pendix A) carried out traffic collection within 6 months with 8
smartphones. We setup a controlled data collection environment,
in which the smartphones are connected to a WiFi router where we
mirror the traffic to a desktop with sufficient storage space. All the
mobile apps are accessible within the university campus through
the university network. On each mobile device, apart from the core
Android apps of the OS, only one app (among 101 mobile apps men-
tioned in Appendix B) is in use. All the traffic generated from the
mobile device is labeled with the in-use app. Many mobile devices
can be used at the same time to collect traffic from different apps.
We recognize them based on the IP address of the mobile devices.
During the project lifetime, multiple data collection sessions
have been carried out. In each session (around 3-4 hours), the vol-
unteering students (the number of students who join in each session
varies) will get a smartphone (provided by the research team) and
access one of the apps in the list (presented in Appendix B). With
this randomness, we believe the collected traffic reflects the com-
mon user behavior in using common apps (of course maybe some
apps will not be accessed by the user or the user behavior change
will access some personal services) and all users may not have the
same usage behavior. Nevertheless, we believe it is a very challeng-
ing problem in controlled experiments using mobile apps when
users volunteer to do the pilot. This is out of our control.
As a result, we managed to collect the traffic for 101 mobile apps,
which are popular (testified by the number of installs) in Google
Play. For each app, we intentionally captured more than 30 hours
of traffic stored in PCAP files, each belonging to a particular app. In
Table 6 of Appendix B, we present all the mobile apps that we have
collected their traffic. With the PCAP files, we performed graph con-
struction for each mobile app with a sliding window of Twindow = 5
minutes (if not stated otherwise). To provide more graphs to train
the MAppGraph model, we set an overlapping duration window
to 3 minutes. This results in at least 800 graphs for each mobile
app in our experiments. In Figure 5, we present data pre-processing
to construct graphs and the workflow for experiments and perfor-
mance comparison. We randomly split these graphs into training
and test sets with a ratio 80 : 20.
5.2 Performance Metrics and Comparison
We use conventional performance metrics of machine learning for
a multi-class classification problem such as Precision, Recall, F1-
Score and Accuracy. We compare the performance of MAppGraph
with three following techniques.
5.2.1 Multilayer Perceptron (MLP). We aggregate features of graph
nodes into a single vector. Due to the heterogeneity in the number of
nodes in the graphs, we fixed the number of nodes, which have the
highest number of traffic packets to construct the feature vectors.
The selected nodes are sorted in the descending order based on
the number of traffic packets to construct the feature vector. We
define this parameter as N in the experiments presented hereafter.