predominantly included anti-LGBT symbolism in our
dataset, such as portraying certain LGBT symbols in
a derogatory manner, or defacing such symbols.
Detecting such social factors in images is a complex
task and currently there are no detectors that can
satisfactorily detect these factors. Thus, we directly
label the images that contained such symbolism in
our dataset, based on online information about this
topic [14], [11]. However, we note that this factor
category maybe very vast, and we only consider the
social factors that we observe in our collected dataset
in this work.
In our dataset, we also ﬁnd that some cyberbullying images,
such as the ones depicting the social factor, do not have a
person. For these images, we represent the feature vectors for
these factors as zero vectors, indicating the absence of people
in these images. For example, since the body-pose factor is
dependent on a person being present in the image, we represent
the body-pose feature vector with the zero vector when the
image does not contain a person.
D. Measurement of Machine Learning Models for Classiﬁca-
tion of Cyberbullying in Images
Feature Selection.
In computer vision applications,
deep neural networks
(such as Convolutional Neural
Networks (CNNs) have enabled the automatic selection of
image features. Previous works [86] have shown that
the
convolutional
layers of a CNN learn to identify various
features, such as edges, objects, and body parts, to compute
a prediction. Although this approach has yielded signiﬁcantly
accurate results in speciﬁc computer vision tasks (such as
object detection), such an approach cannot be directly applied
to a complex task, such as detection of cyberbullying in
images, due to the presence of several contextual factors.
Therefore, to detect cyberbullying in images, we ﬁrst need
to identify the factors that determine cyberbullying. In our
work, we catalog ﬁve factors of cyberbullying based on the
images in our dataset. Furthermore, we study the importance
of each factor towards the effective detection of cyberbullying
in images.
Classiﬁer Models. To demonstrate the effectiveness of
the factors identiﬁed in this work, we use machine learning
models to predict cyberbullying vs. non-cyberbullying in
images. Our main focus is to examine which of the machine
learning models can achieve high accuracy of detection
of cyberbullying in images. Although we demonstrate the
effectiveness of the identiﬁed visual factors, we are also
interested in learning at what level of abstraction the factors
have the most predictive power. Thus, we have built several
classiﬁers at different levels of abstractions, spanning from the
raw image consisting of lowest level features to the high-level
factors identiﬁed in this work. We have evaluated all
the
models using 5-fold cross-validations. This study would also
allow us to investigate if the classiﬁcation of cyberbullying in
images can be trivially solved using simple features. Below,
we explain these different classiﬁer models.
1) Baseline model. As a baseline model, we directly train
a deep CNN with the low level image features. Our intuition
behind choosing this baseline model is because we want to
include use cases that are common among most of existing
detectors, which are all based on CNNs. Another reason for
choosing CNN is that it is still the most effective model for
image-based tasks. All images were resized to 224 × 224
pixels and then fed into a VGG16 untrained model, which
is a popular 16 layer deep CNN for computer vision tasks.
This represents a model that is trained on the most concrete
set of features, i.e., the raw pixel values of the images.
2) Factors-only model. This model that we formulate is
based on a multi-layer perceptron network with only the factors
identiﬁed in this work as inputs. Our objective is to investigate
whether the factors identiﬁed alone could be used with no
image features to classify images as cyberbullying vs. non-
cyberbullying.
3) Fine-tuned pre-trained model. Fine-tuning a pre-trained
model allows us to transfer the knowledge in one task to
perform the task of cyberbullying classiﬁcation in images. This
process is analogous to how humans use knowledge learned
in one task to solve new problems. We ﬁne-tune the 16 layer
VGG16 model that is trained on the object detection task
using the ImageNet dataset [34], which consists of over 14
million images. In our factors analysis, we ﬁnd that certain
object categories, such as person, gun, and knife, could be
responsible for causing cyberbullying. This intuition leads us
to choose a model trained for object detection as a baseline pre-
trained model. To ﬁne-tune this pre-trained model, we replace
the ﬁnal linear layer with a linear layer that outputs two values
followed by the Sigmoid activation function, in order to predict
cyberbullying vs. non-cyberbullying. We only train the linear
layers and keep the other layers ﬁxed as it is the norm in ﬁne
tuning.
Fig. 7: Multimodal model used in our approach.
4) Multimodal model. In this model, we combine the low
level
image features (Figure 7, “Image”) with the factors
identiﬁed in this work (Figure 7, “Visual Factors”). To achieve
this, we need a method to combine these visual factors
and image features. We combine these features using feature
fusion techniques, such as early and late fusion [64]. We use
the VGG16 pre-trained model for image features (Figure 7,
“CNN”) and use a multi-layer perceptron model (Figure 7,
“MLP”) for the factors related features, and combine the
feature vectors from both these models using late fusion. The
9
Visual FactorsImageMLPCNNFeature FusionFully Connected LayersCyberbullying ScoreFeature MapsAdaptive PoolingFeature VectorVGG16 model produces an output of 512 convolutional feature
maps of dimension 7 × 7. We ﬂatten the convolutional feature
maps using adaptive pooling into one-dimensional vector of
512 and fuse it (Figure 7, “Feature Fusion”) with the output
of the MLP network. We train this model in a joint manner
(Figure 7, “Fully Connected Layers”) to classify images as
cyberbullying vs. non-cyberbullying. Ideally, we expect this
model to perform the best among all models discussed, since
this model is presented with low level as well as high level
features (i.e., the visual factors).
IMPLEMENTATION AND EVALUATION
VI.
In this section, we ﬁrst discuss the implementation of the
machine learning models used in our work, followed by ex-
periments to evaluate our approach from different perspectives.
The major goals of our evaluation are summarized as follows.
•
•
•
•
•
•
•
Understanding the effectiveness of factors of cyberbul-
lying in images by using exploratory factors analysis
(Section VI-B).
Demonstrating the effectiveness of our factors in accu-
rately predicting cyberbullying in images, using four
classiﬁer models (Figure 10 and Table IX).
Studying the performance overhead of our model
when integrated in mobile devices (Section VI-D).
Evaluating the false positives of our model on the
images depicting the American Sign Language (Sec-
tion VI-E).
Validation of our cyberbullying factors with a wider
audience (Section VI-F).
Studying the representativeness of our cyberbullying
images dataset (Section VI-G).
Analyzing the capabilities of the state-of-the-art offen-
sive image detectors with respect to the cyberbullying
factors (Section VI-H).
A. Implementation
In this section, we discuss the implementation details of
the classiﬁer models for cyberbullying in images. We use the
PyTorch framework [66] to train and deploy these models.
In our work, we use the VGG-16 network [74] for feature
extraction in the models. We use the VGG-16 model that is
pre-trained on ImageNet dataset [59] for the purpose of transfer
learning. Following PyTorch naming conventions, we remove
the last fully connected layer of the VGG-16 network (named
“fc1”). For the multimodal model, we add a fully connected
layer having 2 units for classiﬁcation. Next, we add a sigmoid
activation function on the output of classiﬁcation. We train all
the models for the same number of epochs.
B. Understanding the Effectiveness of Cyberbullying Factors
In this section, we study in detail the factors of cyber-
bullying in images identiﬁed in this work in terms of their
effectiveness in characterizing cyberbullying in images.
We ﬁrst study the most frequently occurring visual fac-
tors that characterize cyberbullying images, as depicted in
Table VII. For cyberbullying images, we note that Body-pose
#
1
2
3
4
5
6
7
8
Factor
Body-pose
Joy
Sorrow
Anger
Surprise
Gesture
Object
Social
Cyberbullying
Frequency
76.91%
11.41%
0.06%
0.83%
0.51%
50.6%
10.58%
0.53%
Non-cyberbullying
Frequency
31.41%
5.97%
0.06%
0.19%
0.26%
10.76%
0.42%
0.00%
TABLE VII: Frequencies of factors responsible for labeling an
image as cyberbullying or non-cyberbullying.
#
1
2
3
4
5
6
7
8
Factor
Body-pose
Joy
Sorrow
Anger
Surprise
Gesture
Object
Social
Spearman ρ
0.39
0.08
0.00
0.04
0.02
0.42
0.26
0.06
TABLE VIII: Correlation coefﬁcient (Spearman ρ) between
visual factors and cyberbullying label. The coefﬁcients are
signiﬁcant at p < 0.001 level.
accounts for 76.91% frequency, which indicates that it is an
important cyberbullying factor. Gesture (50.6%) is the next
most frequent factor, which indicates that in cyberbullying
in images, subjects may deliberately use gestures to convey
harmful meaning to a viewer. Among the facial emotions,
we observe that the predominant emotion in cyberbullying
images is joy (11.41%). This is an interesting observation
that indicates that subjects may be expressing joyful facial
expressions to mock a viewer. The next most frequent factor
is observed to be object (10.58%). A signiﬁcant portion of
the cyberbullying images involved the subject showing certain
threatening objects such as guns and knives to potentially
directly intimidate a viewer.
The factors frequencies in non-cyberbullying images are
depicted in Table VII. In comparison to cyberbullying images,
we observed that body-pose factor plays a signiﬁcantly less
important part in non-cyberbullying images (31.41%). Same
observation is made about the gesture factor (10.76%). We
observe that
the gestures in non-cyberbullying images are
predominantly harmless, such as the victory sign and the
thumbs up sign. The joy facial emotion is higher than other
emotions in these images too (5.97%), although it is found to
be lower than in cyberbullying images.
Next, we conduct a study to understand the associations
between human level annotations on images and the identiﬁed
factors. Table VIII depicts the correlations (Spearman ρ) for
visual factors and cyberbullying images. In Table VIII, signif-
icant correlation coefﬁcients suggest an association between
the factors and the rationale of human annotators about cyber-
bullying images. A strong association of 0.39 is observed in
case of the body-pose, indicating that annotators tend to agree
that a subject in a cyberbullying image intentionally poses at
a viewer. Similarly, strong association is observed for gesture
(0.42) and object (0.26), indicating that annotators generally
10
considered that photos depicting these factors are generally
cyberbullying. These associations may imply that annotators
may consider those images as cyberbullying, which depict
clear meaning and context, as the strongly associated factors
(body-pose, gesture, and object) imply most clear meanings
among all the other factors.
Fig. 8: Scree plot showing proportions of variance and cumu-
lative proportion of variance explained by each component.
In our next study, we are interested in studying those
subsets of uncorrelated visual factors that are most effec-
tive in distinguishing cyberbullying images from the non-
cyberbullying images. We conduct Exploratory Factor Analysis
(EFA) to discover the uncorrelated factor sets. The Scree
plot depicted in Figure 8 suggests the number of factors 5
to extract. The point of inﬂection in the Scree plot after
the second factor may suggest that two factor subsets can
represent the cyberbullying in the data. Figure 9 exhibits the
factor loadings after a ‘varimax’ rotation. We omit loadings
that are too low. A feature is associated with the factor, with
which it has a higher loading than the other, and also that
features associated with the same factor are grouped together
for certain descriptive categories. More speciﬁcally, the facial
emotions sorrow, surprise and anger are grouped together, and
characterized by lower loadings. The object category grouped
with these emotions reveals a characteristic observation that
facial expression are generally more negative when coupled
with threatening object. However, the joy emotion is away from
these indicating it is an important uncorrelated factor. Body-
pose and gesture are also uncorrelated factors. From these
observations,
intuitively cyberbullying in images could be
related to the facial expression of a person and the overall body
(pose, object in hand and gesture) of a person. Thus, based
on our analysis, cyberbullying in images could be intuitively
characterized with two social constructs: “Pose Context” (pose
related factors, such as pose and gesture) and “Intent Context”
(e.g. an image depicts an intent using facial emotion or object).
C. Effectiveness Evaluation of Classiﬁer Models
To understand the effectiveness of the classiﬁer models