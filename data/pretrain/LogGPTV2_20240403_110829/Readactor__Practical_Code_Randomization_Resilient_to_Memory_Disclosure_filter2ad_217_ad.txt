methods. Since the code cache is continually updated, JIT
compilers typically allocate the code cache on pages with
RWX permissions. This means that, unlike statically generated
code, there is no easy way to eliminate reads and writes
to dynamically generated code without
incurring a high
performance impact.
We apply the Readactor approach to dynamically generated
code in two steps. First, we modify the JIT compilers to separate
code and data in their output. Other V8 security extensions [5,
46, 60] require this separation as well to prevent code injection
attacks on the code cache, and Ansel et al. [5] also implement
it. Second, with code and data separated on different pages, we
then identify and modify all operations that require reads and
writes of generated code. The following sections discuss these
two steps in greater detail. Figure 9 shows the permissions of
the code cache over time after we modiﬁed the V8 engine. Our
changes to the V8 JavaScript engine adds a total of 1053 new
lines of C++ code across 67 different source ﬁles.
A. Separating Code and Data
The unmodiﬁed V8 JIT compiler translates one JavaScript
function at a time and places the results in a code cache
770
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:06:24 UTC from IEEE Xplore.  Restrictions apply. 
Legacy JIT Code
V8 Code object
map_ptr
Readacted JIT Code
V8 Code object
return map_ptr
code header
return code_hdr_ptr
code
code
Map object
CodeHeader object
Readable-writable-executable
Readable-writable
Execute-only
Map object
Figure 10: Transforming V8 Code objects to separate code
and data.
backed by pages with RWX permissions. Each translated
function is represented by a Code object in V8 as shown
on the left side of Figure 10. Each Code object contains
the generated sequence of native machine instructions, a code
header containing information about the machine code, and a
pointer to a Map object common to all V8 JavaScript objects.
To store Code objects on execute-only memory pages, we
move their data contents to separate data pages and make
this data accessible by adding new getter functions to the
Code object. To secure the code header, we move its contents
into a separate CodeHeader object located on page(s) with
RW permissions. We add a getter method to Code objects
that returns a pointer (code_hdr_ptr) to the CodeHeader
object. Similarly, we replace the map pointer (map_ptr) with
a getter that returns the map pointer when invoked. These
changes eliminate all read and write accesses to Code objects
(except during object creation and garbage collection) so they
can now be stored in execute-only memory; a transformed
Code object is shown on the right side of Figure 10.
B. Switching Between Execute-Only and RW Permissions
With this separation between code and data inside Code
objects, we guarantee that no JavaScript code needs to modify
the contents of executable pages. However, the JIT compiler
still needs to change code frequently. As Figure 9 shows,
execution alternates between the compiler and JavaScript
code, and changes to code can only come from the compiler.
Completely eliminating code writes from the compiler would
require a signiﬁcant refactoring of V8 (due to extensive use
of inline caches, relocations and recompilation, which are
hard to completely eliminate), as well as incur a signiﬁcant
performance hit. Instead, we observe that the generated code is
either executed or suspended so that it can be updated. During
execution, we map code with execute-only permissions, and
when execution is suspended, we temporarily remap it with
RW permissions. For both performance and security reasons,
we minimize the number of times we re-map pages, as well as
the length of time a page stays accessible. Each time a Code
object becomes writable, it provides a window for the attacker
to inject malicious code into that object.
Song et al. [60] recently demonstrated that an attack during
this window is feasible. They propose a defense based on
process separation, where the JIT compiler is located in a
separate process from the untrusted browser, and only the JIT
process can write to the generated code. This successfully
protects against code injection attacks against the code cache,
but not against disclosure of the generated code. In the untrusted
process,
the generated code is mapped as read-only and
executable, but could instead be mapped as execute-only for use
with Readactor. We believe their solution is fully compatible
with and complementary to ours, and can be used to protect
the JIT from code injection.
IX. SECURITY EVALUATION
The main goal of Readactor is to prevent code-reuse attacks
constructed using either direct or indirect disclosure vulnerabil-
ities. Thus, we have analyzed and tested its effectiveness based
on ﬁve different variants of code-reuse attacks, namely (i) static
ROP attacks using direct and indirect disclosure, (ii) just-in-
time ROP attacks using direct disclosure, (iii) just-in-time ROP
attacks using indirect disclosure, (iv) ROP attacks on just-in-
time generated code, and (v) return-into-libc attacks. We present
a detailed discussion on each type of code-reuse attack and then
evaluate the effectiveness of Readactor using a sophisticated
proof-of-concept JIT-ROP exploit.
a) Static ROP: To launch a traditional ROP attack [14,
58], the adversary must know the runtime memory layout of
an application and identify ROP gadgets based on an ofﬂine
analysis phase. To defeat regular ASLR the adversary needs to
leak a single runtime address through either direct or indirect
disclosure. Afterwards, the addresses of all target gadgets can
be reliably determined.
Since Readactor performs ﬁne-grained randomization using
function permutation, the static adversary can only guess the
addresses of the target gadgets. In other words, the underlying
ﬁne-grained randomization ensures that an adversary can no
longer statically determine the addresses of all gadgets as offsets
from the runtime address of a single leaked function pointer.
In addition, we randomize register allocation and the ordering
of stack locations where registers are saved to ensure that the
adversary cannot predict the runtime effects of gadgets. Using
these ﬁne-grained diversiﬁcations, Readactor fully prevents
static ROP attacks.
b) JIT-ROP with direct disclosure: JIT-ROP attacks by-
pass ﬁne-grained code randomization schemes by disassembling
code pages and identifying ROP gadgets dynamically at runtime.
One way to identify a set of useful gadgets for a ROP attack is
to exploit direct references in call and jump instructions [59].
Readactor prevents this attack by marking all code pages as non-
readable, i.e., execute-only. This differs from a recent proposal,
XnR [7], that always leaves a window of one or more pages
readable to the adversary. Readactor prevents all reading and
disassembly of code pages by design.
c) JIT-ROP with indirect disclosure: Preventing JIT-
ROP attacks that rely on direct disclosure is insufﬁcient,
since advanced attacks can exploit indirect disclosure, i.e.,
771
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:06:24 UTC from IEEE Xplore.  Restrictions apply. 
harvesting code pointers from the program’s heap and stack
(see Section III). Readactor defends against these attacks with
a combination of ﬁne-grained code randomization and code-
pointer hiding. Recall that pointer hiding ensures that the
adversary can access only trampoline addresses but cannot
disclose actual runtime addresses of functions and call sites
(see Section V). Hence, even if trampoline addresses are leaked
and known to the adversary, it is not possible to use arbitrary
gadgets inside a function because the original function addresses
are hidden in execute-only trampoline pages. As discussed in
Section VII-C, code-pointer hiding effectively provides at least
the same protection as coarse-grained CFI, since only valid
address-taken function entries and call-sites can be reused by
an attacker. However, our scheme is strictly more secure, since
the adversary must disclose the address of each trampoline
from the stack or heap before he can reuse the function or call-
site. In addition, we strengthen our protection by employing
ﬁne-grained diversiﬁcations to randomize the dataﬂow of this
limited set of control-ﬂow targets.
Speciﬁcally, when exploiting an indirect call (i.e., using
knowledge of a trampoline address corresponding to a function
pointer), the adversary can only redirect execution to the tram-
poline but not to other gadgets located inside the corresponding
function. In other words, we restrict the adversary who has
disclosed a function pointer to whole-function reuse.
On the other hand, disclosing a call trampoline allows
the adversary to redirect execution to a valid call site (e.g.,
call-preceded instruction). However, this still does not allow
the adversary to mount the same ROP attacks that have been
recently launched against coarse-grained CFI schemes [13, 20,
29, 55], because the adversary only knows the trampoline
address and not the actual runtime address of the call site.
Hence, leaking one return address does not help to determine
the runtime addresses of other useful call sites inside the address
space of the application. Furthermore, the adversary is restricted
to only those return trampoline addresses that are leaked from
the program’s stack. Not every return trampoline address will
be present on the stack, only those that are actually used and
executed by the program are potentially available. This reduces
the number of valid call sites that the adversary can target, in
contrast to the recent CFI attacks, where the adversary can
redirect execution to every call site in the address space of the
application without needing any disclosure.
Finally, to further protect call-site gadgets from reuse
through call trampolines, we use two ﬁne-grained diversi-
ﬁcations proposed by Pappas et al. [49] to randomize the
dataﬂow between gadgets: register allocation and stack slot
randomization. Randomizing register allocation causes gadgets
to have varying sets of input and output registers, thus disrupting
how data can ﬂow between gadgets. We also randomly reorder
the stack slots used to preserve registers across calls. The
program’s application binary interface (ABI) speciﬁes a set of
callee-saved registers that functions must save and restore before
returning to their caller. In the function epilogue, the program
restores register values from the stack into the appropriate
registers. By randomizing the storage order of these registers,
we randomize the dataﬂow of attacker-controlled values from
the stack into registers in function epilogues.
d) ROP on just-in-time generated code: In contrast to
many other recent defenses (e.g., [6, 7, 44]), Readactor also
applies its protection mechanisms to dynamically-generated
code. This coverage is important since many well-known
programs feature scripting facilities with just-in-time (JIT)
code generation (e.g., Internet Explorer, Firefox, Adobe Reader,
and Microsoft Word). Typically, dynamic code is of particular
interest to the adversary, as it is usually mapped as read-write-
executable (RWX).
Hence, several exploits use a technique called JIT-
spraying [11]. In this attack, the adversary writes a script
(e.g., JavaScript) that emits shellcode as unintended instruction
sequences into the address space of an application. A well-
known example is the XOR instruction that can be exploited to
hide shellcode bytes as an immediate value. Google’s V8 JIT
engine mitigates this speciﬁc instantiation of JIT-spraying by
XOR’ing random values with the immediate values. However,
another way to exploit JIT-compiled code (RWX) memory
is to disclose its address, overwrite the existing code with
shellcode, and execute it. The adversary sprays a large number
of shellcode copies abusing the JIT compiler. After the shellcode
has been emitted, the adversary simply needs to exploit a
vulnerability and redirect execution to the shellcode through
memory corruption.
Readactor prevents this classic JIT-spraying attack as well
as any attack that attempts to identify useful code in the JIT-
compiled code area through direct memory disclosure. We
achieve this by marking the JIT code area as execute-only
and use V8’s built-in coarse-grained randomization (similar to
ASLR). Hence, the adversary can neither search for injected
shellcode nor ﬁnd other useful ROP code sequences. On the
other hand, given V8’s coarse-grained randomization, it is still
possible for the adversary to guess the address of the injected
shellcode. To tackle guessing attacks, we are currently working
on integrating ﬁne-grained randomization inside V8 (inspired
by the ideas used in librando [33]).
We also tested whether indirect disclosure of JIT-compiled
code is feasible. Our experiments revealed that V8’s JIT code
cache contains several code pointers referencing JIT-compiled
code. Hence, the adversary could exploit these pointers to infer
the code layout of the JIT memory area. To protect against
such attacks, these code pointers need to be indirected through
execute-only trampolines (our standard jump trampolines). We
can store these trampolines in a separate execute-only area away
from the actual code. To add support for code-pointer hiding,
we would need to modify both the JITted code entry points from
the JavaScript runtime and all JavaScript-to-JavaScript function
calls to call trampolines instead. This work is an engineering
effort that is currently ongoing, as it requires porting our LLVM
compiler changes over to the V8 JIT.
e) Return-into-libc: Most of the papers dealing with
code-reuse attacks do not provide a security analysis of classic
return-into-libc attacks [45], i.e., attacks that only invoke entire
functions rather than short ROP code sequences. In general,
it is very hard to prevent return-into-libc attacks, since they
target legitimate addresses, such as exported library functions.
In Readactor, we limit the attack surface for return-into-libc
attacks.
To launch a return-into-libc attack, the adversary needs to
identify code pointers to functions of interest, e.g., system
or mprotect on Linux. Typically, this is done by disclosing
772
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:06:24 UTC from IEEE Xplore.  Restrictions apply. 
the function address from a known position within either code
or data sections. We prevent disclosure from code because
Readactor maps code pages as execute-only. On the other
hand, code pointers in data sections, e.g. pointers in the import
address table (IAT) in Windows or the global offset table
(GOT) in Linux which are used for shared library calls, can
be exploited in an indirect disclosure attack. Since Readactor
hides code pointers in trampolines and also performs function
permutation, the adversary cannot exploit a IAT/GOT entry to
determine the address of a function of interest in a readacted
library. However, if the function of interest is imported by
the program then the adversary can exploit the GOT entry
containing the corresponding trampoline addresses to directly
invoke the function.
In summary, Readactor provides a high degree of protection
against code reuse attacks of all kinds, while being practical
and efﬁcient at the same time, as we demonstrate in the next
subsection. First, we describe our protection against proof-of-
concept exploit targeting the JavaScript JIT.
f) Proof-of-concept exploit: To demonstrate the ef-
fectiveness of our protection, we introduced an artiﬁcial
vulnerability into V8 that allows an attacker to read and write
arbitrary memory. This vulnerability is similar to a vulnerability
in V82 that was used during the 2014 Pwnium contest to
get arbitrary code execution in the Chrome browser. In an
unprotected version of V8, the exploitation of the introduced
vulnerability is straightforward. From JavaScript code, we
ﬁrst disclose the address of a function that resides in the
JIT-compiled code memory. Next, we use our capability to
write arbitrary memory to overwrite the function with our
shellcode. This is possible because the JIT-compiled code
memory is mapped as RWX in the unprotected version of
V8. Finally, we call the overwritten function, which executes
our shellcode instead of the original function. This attack fails
under Readactor because the attacker can no longer write
shellcode to the JIT-compiled code memory, since we set all
JIT-compiled code pages execute-only. Further, we prevent
any JIT-ROP like attack that ﬁrst discloses the content of JIT-
compiled code memory, because that memory is not readable.
We tested this by using a modiﬁed version of the attack that
reads and discloses the contents of a code object. Readactor
successfully prevented this disclosure by terminating execution
of the JavaScript program when it attempted to read the code.
X. PERFORMANCE EVALUATION
We rigorously evaluated the performance impact of Readac-
tor on both the SPEC CPU2006 benchmark suite and a
large real-world application, the Chromium browser. We also
evaluated our changes to the V8 JavaScript engine using
standard JavaScript benchmarks.
1) SPEC CPU2006: The SPEC CPU2006 benchmark suite
contains CPU-intensive programs which are ideal to test the
worst-case overhead of our compiler transformations and
hypervisor. To fully understand the impact of each of the
components that make up the Readactor system, we measured
and report their performance impact independently.
We performed all evaluations using Ubuntu 14.04 with
Linux kernel version 3.13.0. We primarily evaluated SPEC
2CVE-2014-1705
on an Intel Core i5-2400 desktop CPU running at 3.1 GHz
with dynamic voltage and frequency scaling (Turbo Boost)
enabled. We also independently veriﬁed this evaluation using
an Intel Xeon E5-2660 server CPU running at 2.20 GHz with
Turbo Boost disabled, and observed identical trends and nearly
identical performance (within one percent on all averages). We
summarize our SPEC measurements in Figure 11. Overall, we
found that Readactor, with all protections enabled, incurs an
average performance overhead of just 6.4% for SPEC CPU2006.
a) Code-Data Separation: First we evaluated the perfor-
mance overhead of separating code from data by rewriting how
the compiler emits switch tables in code (see Section VII-B).
We found the impact of transforming switch table data into