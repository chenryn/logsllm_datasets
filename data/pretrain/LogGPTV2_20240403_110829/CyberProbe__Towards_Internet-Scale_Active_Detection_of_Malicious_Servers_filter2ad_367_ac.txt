our target set.
Scan rate. Nowadays, a well-designed scanner running on
commodity hardware can send fast enough to saturate a 1 Gbps
link (i.e., 1.4 Mpps) [14] and some work enables commodity
hardware to saturate even 10 Gbps links [45]. Thus, a scanner
often needs to be rate-limited to avoid saturating its uplink,
disconnecting other hosts in the same network. In this work,
for good citizenship we limit each horizontal and UDP scanner
host to a maximum of 60,000 packets per second (26 Mbps),
and each appTCP scanner host to a rate of 400 connections
per second.
Scan order. Our horizontal and UDP scanners select which
target
to probe next using a random permutation of the
target address space. Drawing targets uniformly at random
from the target ranges mixes probes to different subnets over
time, avoiding the overload of speciﬁc subnets [51]. To scan
in random order, without needing to keep state about what
addresses have already been scanned or are left to be scanned,
our horizontal and UDP scanners use a linear congruential
generator (LCG) [24]. Since the IP addresses output by the
horizontal scanner are not sequential, the appTCP scanner does
not use a LCG but simply randomizes the order of the target
IP addresses.
Whitelisting. The LCG iterates over a single consecutive
address range. However, the BGP ranges to be scanned may not
be consecutive. Also, we may need to exclude certain ranges,
e.g., those whose owners request so. To address these issues,
before probing a target, the horizontal and UDP scanners check
if the target’s IP is in a whitelist of IP addresses to scan,
otherwise they skip it. The whitelist is implemented using a
512 MB bit array, where each bit indicates if the corresponding
IP address needs to be probed. This ensures that checks are
done in O(1). Since most commodity hardware has a few GBs
of memory this is a good tradeoff of memory for efﬁciency. For
the appTCP scanner, which does not use an LCG, we simply
remove IP addresses that should not be probed from the input
target list.
Scanner placement. Multiple scanners can be used to dis-
tribute a scan. Since a single scanner may be able to saturate its
uplink it is typically not needed to use multiple scanners on the
same network. It is preferable to add them in separate networks
with independent uplinks. All scanners use the same generator
for the LCG. To split the target hosts between scanners, we
assign each scanner a unique index from zero to the number
of scanners minus one. All scanners iterate over the targets in
the same order, but at each iteration only the scanner whose
index matches the target IP modulo the number of scanners
sends the probe.
B. Horizontal Scanner
An efﬁcient horizontal scanner is fundamental to perform
fast and resource-efﬁcient scans because the large majority
of IP addresses (97%–99% depending on the port) do not
send responses to probes. Two important characteristics of
our horizontal scanner are the lack of scanning state and the
asynchronous sending of probes and receiving of responses.
Our horizontal scanner performs TCP SYN (or half-open)
scans. While there exists different types of TCP scans [39],
TCP SYN scans are arguably the most popular one because
they can efﬁciently determine if a target host is listening on a
port. They are also called half-open scans because they never
complete a full TCP handshake. A SYN packet is sent to a
target and if a SYNACK response is received, the scanner
marks the target as alive and sends it a RST packet, which
avoids creating state on the scanner or the target. A single SYN
packet is sent to each target without retransmissions, which
prior work has shown as a good tradeoff between accuracy (low
packet loss on the backbone) and efﬁciency (avoiding doubling
or tripling the number of probes) [28]. The horizontal scanner
is implemented using 1,200 lines of C code and runs on Linux.
It comprises a sender and a receiver module. Both modules are
independent and can be run on the same or different hosts. We
describe them next.
Sender. The sender uses raw sockets to send the probes. Raw
sockets bypass the kernel network stack so that no state is kept
for a probe. They prevent the kernel from doing route and ARP
lookups, and bypass the ﬁrewall. When a SYNACK packet is
received, the kernel automatically sends a RST packet since
it is unaware of the connection. On initialization the sender
creates a buffer for a raw Ethernet request. It ﬁlls all ﬁelds
in the Ethernet, IP, and TCP headers except the destination
IP address, source port, sequence number, and TCP and IP
checksums. Using a single buffer and caching most ﬁeld values
reduces memory accesses, increasing performance. The source
IP is the IP address of the receiver. If the receiver runs on a
separate host the sender spoofs the receiver’s IP address. To
enable the receiver to identify valid responses, the sequence
number is ﬁlled with the XOR of the target IP and a secret
shared between the sender and the receiver. The checksums
can be computed on software or outsourced to the network
card if it supports checksums on raw sockets.
The sender implements rate limiting by enforcing an inter-
probe sleeping time. The Linux kernel does not provide ﬁne-
grained timers by default, so OS functions like usleep or
nanosleep are too coarse for microsecond sleeps. Instead, the
scanner deactivates CPU scaling, computes the sleeping time
in ticks, and then busy-waits using the rdtsc instruction until
it is time to send the next probe.
Receiver. The receiver is implemented using libpcap [31] and
set to sniff all SYNACK packets. Note that the number of
received packets is much smaller than the number of probes,
e.g., only 2.6% of the advertised IPs listen on 80/tcp. Thus
performance is less critical in the receiver than in the sender.
Once the sender completes, the receiver keeps listening for a
predeﬁned time of 5 minutes to capture delayed responses. The
receiver uses the shared secret, the acknowledgment number,
and the source IP to check if the SYNACK corresponds to
a valid probe. If so, it outputs the source IP to a log ﬁle of
live hosts. There is no need to keep state about which IPs
have already responded. Once the scan completes, duplicated
entries due to multiple SYNACKs are removed from the log.
C. AppTCP & UDP Scanners
The appTCP and UDP scanners need to be able to send
probes from different ﬁngerprints, which may capture different
application-layer protocols and message types. The probe
construction function in a ﬁngerprint abstracts the speciﬁcities
of probe building from the scanner. Each probe construction
function comprises two C functions. The ﬁrst function is called
during initialization and builds a default probe. Then, for each
target host the appTCP or UDP scanner passes the target IP to
the second function, which returns the TCP or UDP payload
for the probe (e.g., updating the default probe with target-
speciﬁc ﬁeld values).
Both scanners can apply the ﬁngerprint by running Snort on
the received trafﬁc. In addition, they can collect the responses
into a network trace and then run Snort ofﬂine on the trace. In
7
our experiments we store the responses to enable post-mortem
analysis and for collecting benign responses to enhance the
benign trafﬁc pool.
AppTCP scanner. The appTCP scanner is implemented using
the libevent [30] library for asynchronous events, which is able
to handle thousands of simultaneous non-blocking connections.
It comprises 600 lines of C code plus the code that implements
the probe construction functions for each ﬁngerprint. It takes as
input the list of live hosts identiﬁed by the horizontal scanner.
To limit the connection rate the appTCP scanner operates on
batches and the batch size limits the maximum number of
simultaneously open connections. Reception is asynchronous,
i.e., each received packet triggers a callback that reads the
content from the socket. It sets a maximum size for a response
since most classiﬁcation functions operate on the early parts
of a response. The default is 1MB but can be modiﬁed for
any ﬁngerprint. This limit is needed for servers that respond
to any request with a large stream of data. For example,
SHOUTCast [48] radio streaming servers may send a 1GB
stream in response to an HTTP request for a random ﬁle.
UDP scanner. The UDP scanner uses the same architecture as
the horizontal scanner, but builds instead UDP probes using
the ﬁngerprint’s probe construction function. It comprises
800 lines of C code. The sender component also uses raw
sockets, but embeds the secret in the source port instead of the
sequence number. Similar to the appTCP scanner, the receiver
component sets the maximum size of a response to 1MB.
V. EVALUATION
This section presents the evaluation results for adversarial
ﬁngerprint generation (Section V-A), our scanning setup (Sec-
tion V-B), scanning results (Sections V-C to V-E), and detailed
analysis of selected operations (Section V-F).
A. Adversarial Fingerprint Generation Results
from two
different
We
obtain malware
sources:
VirusShare [55] and the MALICIA dataset [33]. We run
the malware on our infrastructure to produce the network
traces used as input to the ﬁngerprint generation. VirusShare
malware is not classiﬁed, so we use a trafﬁc clustering
algorithm to split
the executables into families [43]. The
MALICIA dataset contains malware distributed through drive-
by downloads, already classiﬁed into families, so clustering
is not needed. For the exploit servers, we use network traces
of the honeyclients collecting the malware in the MALICIA
dataset. In addition, we add another exploit server family not
present in MALICIA that we identify in URLQuery [54] and
use a honeyclient to collect the network traces.
Table II summarizes the results of adversarial ﬁngerprint
generation. It shows the type and source of the network traces,
the number of malicious families, the number of network traces
processed, the RRPs in those traces, the RRPs replayed after
ﬁltering, and the number of seeds and ﬁngerprints output.
Overall, CyberProbe produces 23 ﬁngerprints for 13 families:
3 exploit server families and 10 malware families. Of those,
one ﬁngerprint uses UDP and the rest use HTTP. The number
of generated ﬁngerprints is low compared to the number of
network traces processed because some families have many
traces (e.g., 700 for winwebsec) and because much malware
connects to dead servers, which have likely been replaced by
newer ones.
8
B. Scanning Setup
For the localized horizontal and UDP scans we use a single
scanner at one of our institutions. This machine has 4 CPU
cores running at 3.30GHz, a network connection at 1Gbps
and 4GB of RAM. To distribute the Internet-wide horizontal
and UDP scans across different hosts and locations we also
rent 4 large instances in a cloud hosting provider. For the
HTTP scans, we rent smaller virtual machines on virtual
private server (VPS) providers and also use two dedicated
hosts installed at one of our institutions. For the VPSes we
select the cheapest instance type offered by each provider
that satisﬁes the following minimum requirements: 1GHz,
512RAM, 100Mbps link, and 15GB hard drive.
Different providers may offer different virtualization tech-
nologies (e.g., XEN, OpenVZ, VMWare). The cheapest ones
are often based on OpenVZ technology (starting at $4/month).
In total we spent close to $600 on cloud hosting for the
experiments in this paper. The selected instances on different
providers have different resources and those resources are
sometimes not well speciﬁed. For example, some providers
only specify the maximum amount of network trafﬁc the
instance can send over the rental period (e.g., 1TB/month), but
do not specify the network interface bandwidth and whether
they perform some additional rate-limiting of the VMs. To
address the resource differences across VMs we split
the
target addresses proportionally to the hard drive and network
bandwidth (when known) of the rented instances. This may
result in some scanners being assigned larger ranges than
others, e.g., 3 scanner hosts being used one with 50% and
each of the other two with 25% of the total target addresses.
C. Horizontal Scanning
For TCP ﬁngerprints, CyberProbe ﬁrst performs a horizon-
tal scan of the desired target ranges to identify hosts listening
on the target port. Table III summarizes our horizontal scans.
It shows the scan type, i.e., localized-reduced (R), localized-
extended (E), or Internet-wide (I); the date of the scan; the
target port; the number of target IP addresses scanned; the
number of scanners used (SC); the sending rate for each scan-
ner; the duration of the scan; and the number (and percentage)
of live hosts found.
The ﬁrst 9 scans are localized scans, targeting small ranges
from 4,096 to 19 million IP addresses, and performed at very
low scan rates. The goal of these localized scans was to test our
scanning infrastructure, and to perform an initial evaluation of
whether our hosting provider locality hypothesis holds (next
subsection). The last 4 are Internet-wide scans, three on 80/tcp
and one on 8080/tcp. Using 5 scanner hosts at a rate of 50,000
packets per second (pps), or 4 scanners at 60,000pps, it takes
less than 3 hours for CyberProbe to perform an Internet-wide
horizontal scan.
The Internet-wide scans found 2.6% of all advertised IP
addresses listening on 80/tcp and 0.01% on port 8080. The
80/tcp scan on April 30th found 67.7 million hosts, the scan
on July 1st 65.5 million, and the August 5th scan 63.5 million.
The 8080/tcp scan found 239K live hosts. The difference on
live hosts found between the 80/tcp scans is due to changes
on the total size of the BGP advertised routes on the scan
days. The live hosts intersection between the April 30th and
July 1st 80/tcp scans is 43.9 million IPs (67%). That is, two
Type
Source
Families
Pcaps
RRPs
Seeds
Fingerprints
VirusShare
Malware
Malware
MALICIA
Honeyclient MALICIA
Honeyclient UrlQuery
TABLE II.
152
9
6
1
918
1,059
1,400
4
1,639
764
42,160
11
ADVERSARIAL FINGERPRINT GENERATION RESULTS
RRPs
Replayed
193
602
9,497
11
19
2
5
1
18
2
2
1
HID Type
1
2
3
4
5
6
7
8
9
10
11
12
13
E
R
E
R
E
E
E
R
R
I
I
I
I
Start Date
2013-03-12
2013-03-26
2013-04-08
2013-04-14
2013-04-15
2013-04-17
2013-04-20
2013-04-23
2013-04-28
2013-04-30
2013-04-30
2013-07-01
2013-08-05
Port
8080
80
80
80
80
80
8080
80
80
80
8080
80
80
TABLE III.
Targets
13,783,920
4,096
7,723,776
24,576
32,768
1,779,965
19,018,496
105,472
668,672
2,612,160,768
2,612,160,768
2,510,340,631
2,459,631,240
SC Rate(pps)
300
1
60
1
1
125
200
1
200
1
125
1
900
1
1
250
5,000
1
50,000
4
50,000
4
50,000
5
4