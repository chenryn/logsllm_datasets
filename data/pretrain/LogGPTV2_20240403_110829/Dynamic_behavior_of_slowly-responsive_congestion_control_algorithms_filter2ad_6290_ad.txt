Figure 11 shows the number of ACKs needed for a Æ-fair alloca-
tion for various values of b for Æ = 0:1 and  = 0:1; other values of
 give almost identically shaped curves. Note that the above anal-
ysis applies to TCP only for moderate to low loss probabilities, as
it does not include retransmit timeouts or accurately model TCP’s
behavior when multiple packets are lost from a window of data.
from 0.14 to 0.28 packets/sec, depending on whether a TFRC op-
tion called history discounting has been invoked [7].
In this section we consider some of the implications of the
low aggressiveness of SlowCC mechanisms in environments with
a sudden increase in the available bandwidth. The fundamen-
tal underlying tradeoff in SlowCC mechanisms is that, in return
for a smooth sending rate during times of steady-state conditions,
SlowCC mechanisms are slow to take advantage of a sudden in-
crease in the available bandwidth, relative to TCP. The slower the
SlowCC mechanism, the more sluggish it will be in taking advan-
tage of a sudden increase in the available bandwidth. This does not
in any way interfere with competing trafﬁc in the network, but we
believe this sluggishness will be a compelling reason for applica-
tions not to use extremely slow congestion control mechanisms.
To make this concrete, we consider scenarios with long-lived
ﬂows where the bandwidth available to those ﬂows is suddenly dou-
bled. We deﬁne f k as the average link utilization (expressed as
a fraction) over the ﬁrst k round-trip times after the bandwidth has
doubled. This link utilization is a function not only of the conges-
tion control mechanism and the number of round-trip times k, but
also of the round-trip time and the link bandwidth in packets/sec.
)
(
f
)
(
f
1
0.95
0.9
0.85
0.8
0.75
0.7
0.65
0.6
0.55
0.5
1
0.95
0.9
0.85
0.8
0.75
0.7
0.65
0.6
0.55
0.5
1
1
f(200) for TCP(1/x)
f(200) for SQRT(1/x)
f(20) for TCP(1/x)
f(200) for SQRT(1/x)
10
100
1000
1/b factor for TCP(b) and SQRT(b)
f(200) for TFRC(x)
f(20) for TFRC(x)
10
100
1000
b in TFRC(b)
Figure 11 shows that for values of b >(cid:25) 0:2 and a drop
rate of 10%, 0.1-fair convergence is achieved fairly rapidly, while
for smaller values of b convergence takes exponentially longer.
This suggests that for transient fairness, AIMD(b) for values of
b >(cid:25) 0:2 could give acceptable transient fairness, while signif-
icantly lower values for b would give unacceptably-long conver-
gence times.
In Figure 12, we plot the 0.1-fair convergence times for TFRC(b)
ﬂows for different values of b. As this ﬁgure shows, the 0.1-fair
convergence time does not increase as rapidly with increased slow-
ness of TFRC ﬂows. This can be explained by the fact that unlike
multiplicative decrease in TCP, TFRC relies on a ﬁxed number of
loss intervals to adjust its sending rate to the available rate.
4.2.3 Loss in Throughput in a Time of Plenty
The slow increase rate of SlowCC can result in a loss of through-
put, as compared to TCP, when there is a sudden increase in the
bandwidth available to a ﬂow. The aggressiveness of a congestion
control mechanism has been deﬁned as the maximum increase in
the sending rate in one round-trip time, in packets per second, given
the absence of congestion [8]. For TCP(a, b), the aggressiveness is
simply the parameter a, while for TFRC the aggressiveness ranges
Figure 13: Average link utilization f 20 and f 200 for vari-
ous SlowCCs, for a link bandwidth of 10 Mbps and a round-trip
time of 50 ms.
To evaluate f k, we use a simulation scenario with ten identi-
cal ﬂows, all using the same congestion control mechanism, shar-
ing a bottleneck link of 10 Mbps. At time 500 sec., ﬁve ﬂows
are stopped, effectively doubling the bandwidth available to the re-
maining ﬁve ﬂows. Figure 13 shows f 20 and f 200, the link
utilization in the ﬁrst 20 and 200 round-trip times, respectively,
after the ﬁrst ﬁve ﬂows stopped, for TCP(1=b), SQRT(1=b), and
TFRC(b) for a range of parameters b. Figure 13 shows that for this
scenario, while TCP achieves about 86% utilization after the ﬁrst
20 round-trip times, TCP(1/8) and TFRC(8) achieve 75% and 65%
utilization respectively, showing the cost paid by SlowCC mecha-
nisms in failing to make prompt use of the newly-available band-
width.
Although slower congestion control mechanisms such as
TCP(1=b) or TFRC(b) for b > 8 have not been proposed for de-
ployment, we investigate them to illustrate the extreme sluggish-
ness of such mechanisms in reacting of an increase in the available
bandwidth. TCP(1/256) and TFRC(256) both receive only 60%
utilization after 20 round-trip times, and after 200 round-trip times
have only increased the link utilization to 65-70%. We note that, for
TFRC, these simulations use the TFRC implementation in the NS
simulator with history discounting (a conﬁgurable option, turned
on by default) turned off, and that this makes TFRC’s performance
somewhat worse than it would be otherwise. This allows us to fo-
cus solely on the part of TFRC that responds to packet loss rates
and sets the transmission rate accordingly.
For a particular congestion control mechanism, f k can be de-
rived directly from the aggressiveness metric. Consider TCPa; b
when the link bandwidth has been increased from (cid:21) to 2(cid:21) pack-
ets/sec, and let the RTT be Rs. After k round-trip times with-
out congestion, TCPa; b will have increased its sending rate
from (cid:21) to (cid:21)  ka=R packets/sec, for an average sending rate of
(cid:21)  ka=2R packets/sec. Therefore, f k can be approximated
by 1=2  ka=4R(cid:21) for TCP(a,b).
4.2.4 Loss in Throughput in a Time of Oscillations
Section 4.2.1 considered the relative long-term fairness between
TCP and SlowCC in an environment with sharp changes in the
available bandwidth, and Section 4.2.3 showed the penalty paid
by SlowCC in being slow to take advantage of a sudden increase
in the available bandwidth. In this section, we consider the over-
all link utilization in an environment of rapidly-changing available
bandwidth when all of the ﬂows use the same congestion control
mechanism. We show that in such a dynamic environment, if all
of the trafﬁc consisted of long-lived ﬂows using SlowCC, the over-
all link utilization can be somewhat lower than it would be with
long-lived TCP ﬂows in the same environment, depending on the
nature of the changes in the available bandwidth. We do not present
this as a reason not to deploy SlowCC, but as an exploration of the
possible costs of SlowCC in extreme environments.
)
d
e
z
i
l
a
m
r
o
n
(
h
t
d
w
d
n
a
B
i
square wave (results from three different simulations)
1
0.8
0.6
0.4
0.2
0
0.01
TCP
TCP(1/8)
TFRC
0.1
1
10
100
Length of high/low bw (15Mb/5Mb) period
Figure 14: Effect of varying bandwidth on link utilization.
square wave (results from three different simulations)
t
e
a
r
p
o
r
D
0.14
0.12
0.1
0.08
0.06
0.04
0.02
0
0.01
TCP
TCP-1/8
TFRC
0.1
1
10
100
Length of high/low bw (15Mb/5Mb) period
Figure 15: The corresponding packet loss rate.
To study this loss in throughput for SlowCC in an environment
with changing network conditions, we use a simulation scenario
with ten identical congestion-controlled ﬂows competing with an
ON/OFF CBR source. The bandwidth available to the congestion-
controlled ﬂows varies from 15 Mbps and 5 Mbps (i.e., a 3:1 ratio)
as the CBR ﬂow is OFF and ON respectively. We do not pretend
that this is a realistic scenario; however, this simple scenario can
provide insight into the dynamics of TCP and of SlowCC in an
environment of changing network conditions.
Figure 14 shows the effect of the changing available bandwidth
on the overall throughput. Three separate simulation sets were
run, using TCP(1/8), TCP, and TFRC(6) respectively. The x-axis
shows the length of the ON and the OFF periods for the compet-
ing CBR ﬂow in seconds, and the y-axis shows the throughput of
the congestion-controlled ﬂows, as a fraction of the average avail-
able bandwidth. Each column shows the results of three separate
simulations, using TCP(1/8), TCP, and TFRC(6). For each simula-
tion, the graph shows the bandwidth of each ﬂow (as a fraction of
its bandwidth share), as well as the average bandwidth. Figure 15
shows the packet drop rate for the simulations in Figure 14.
As we can see from the Figure 14, the period of the compet-
ing CBR ﬂow has a signiﬁcant impact on the overall throughput of
the congestion-controlled ﬂows. For example, when the CBR ﬂow
has ON and OFF times of 50 ms, throughput is high for TCP(1/8),
TCP, and for TFRC(6). This shows that short bursts of compet-
ing trafﬁc are not harmful to TCP or to SlowCC, as these short
bursts can be effectively accommodated by the active queue man-
agement at the congested router. In contrast, when the CBR ﬂow
has ON and OFF times of 200 ms, four times the round-trip time,
a congestion-controlled ﬂow receives less than 80% of the overall
available bandwidth, whether the ﬂow is using TCP(1/8), TFRC, or
TCP.
)
d
e
z
i
l
a
m
r
o
n
(
h
t
d
w
d
n
a
B
i
1
0.8
0.6
0.4
0.2
0
0.01
Square wave (results from three simulation sets)
TCP-1/8
TCP
TFRC
0.1
1
10
100
Length of high/low bw (15Mb/1.5Mb) period
Figure 16: Effect of 10:1 oscillations in network bandwidth on
bandwidth utilization of various congestion control algorithms.
Figure 16 shows that in a more extreme environment with re-
peated 10:1 changes in the available bandwidth, none of the three
congestion control mechanisms are particularly successful, but for
certain frequencies of change in the underlying bandwidth, TFRC
performs particularly badly relative to TCP. This underlies the point
that although TCP and SlowCC mechanisms might perform some-
what similarly in a steady-state environment, this is not necessar-
ily the case in more extreme conditions with rapid changes.
In
particular, an environment with varying load may result in lower
throughput (and hence, lower link utilization) with SlowCCs than
with TCPs.
4.3 “The Good”: Potential Beneﬁts of Slowly-
Responsive Algorithms
The main motivation for the development and deployment of
SlowCC mechanisms has been that their sending rate is smoother
than that of TCP in a steady-state environment with a reason-
ably smooth packet loss process. The smoothness metric is de-
ﬁned as the largest ratio between the sending rates in two consec-
utive round-trip times. In a steady-state environment with a peri-
odic packet drop rate, TFRC has a perfect smoothness metric of 1,
while TCP(b) congestion control has a smoothness metric of 1   b;
congestion control mechanisms that reduce their window or rate
in response to a single drop cannot have perfect smoothness [8].
The focus of this section is to consider the smoothness of SlowCC
mechanisms in environments with bursty loss patterns. With such
bursty packet loss patterns the relative smoothness of various TCP-
compatible congestion controls become considerably more com-
plex.
)
c
e
s
2
0
B
K
/
.
(
t
u
p
h
g
u
o
r
h
T
)
c
e
s
.
2
0
B
K
/
(
t
u
p
h
g
u
o
r
h
T
140
120
100
80
60
40
20
0
140
120
100
80
60
40
20
0
flow 0, 0.2 sec bins
1 sec bins
drops
0
2
4
6
8
10
Time
12
14
16
18
20
flow 0, 0.2 sec bins
1 sec bins
drops
0
2
4
6
8
10
Time
12
14
16
18
20
Figure 17: TFRC (top) and TCP(1/8) (bottom) with a mildly
bursty loss pattern.
)
c
e
s
2
.
0
/
B
K
(
t
u
p
h
g
u