to(cid:1)o to generate time gaps between bursts. In this section, we
show our hyperparameter tuning process for the former and
how we model the time gap distribution for the latter.
1) Hyperparameter Tuning for the GAN: How well the
GAN is trained depends a lot on the hyperparameters. We
perform a search for the hyperparameters by trying out differ-
ent combinations of hyperparameter values. We observe the
change of LG, the estimated Wasserstein distance between
real and fake data, as well as the accuracy of the observer
O. A good-enough set of hyperparameters should make LG
smoothly decrease to near zero.
Dataset. We build our dataset DSgan for GAN training
based on Rimmer’s dataset [20], the largest known WF dataset
collected in 2018. The dataset has 900 classes, each with 2500
instances. We randomly pick 100 classes as our morphing
targets, and for each class, we only use 1000 instances to
reduce the training cost.
Tuning Results. Table II shows the search space and the
ﬁnal values we choose for the model. The length of both
input and output burst sequences is ﬁxed at 1400 since most
of the burst sequences have a length below this value in
DSgan. The learning rate for our model is ﬁxed at 0.0002.
A small learning rate (e.g., 0.0001) fails to reduce LG (i.e.,
the estimated Wasserstein distance) to less than 0.1 even after
more than 1000 epochs. A large learning rate, on the other
hand, could make the training unstable where the loss curves
for L∗
D ﬂuctuate wildly over epochs. α helps balance
G and L∗
e
z
i
S
t
s
r
u
B
n
a
e
M
e
z
i
S
t
s
r
u
B
n
a
e
M
20
0
−20
−40
−60
20
0
-20
-40
-60
real
fake
0
100 200 300 400 0
100 200 300 400
Burst Index
Burst Index
Fig. 5: Visualization of real and fake center traces. We only
show the ﬁrst 400 outgoing and incoming bursts since the sizes
of the last 300 bursts are all close to 0. Incoming bursts are
represented in negative values.
the weights of the two losses in L∗
G. In our case, we should
set α to a relatively small value since we observe that the
magnitude of LG is much smaller than LO. We only apply
dropouts and activation functions to D to avoid overﬁtting
problems. On the generator side, we ﬁnd that adding batch
normalization in each hidden layer improves the performance.
ncritic adjusts the update frequency of D relative to that of
G. We ﬁnd that ncritic = 3 yields the best results. The best
generator we get can lead to an estimated Wasserstein distance
of 0.016 and a 90% accuracy on the observer; higher accuracy
indicates that the fake traces are convincing.
Visualization. Besides observing a low Wasserstein dis-
tance, we want to conﬁrm that our trained generators are
effective using visualization to show the similarity between
trained and generated traces. To do so, we compare the
center traces of the same webpage for real and fake data.
A center trace is computed by taking the mean of each burst
in the trace over a group of traces. The center trace for this
class should be relatively stable since it reveals the sizes of
objects in the webpage. Using center traces rather than single
traces for visualization better reﬂects generator quality because
individual
traces even of the same webpage can be very
different from each other due to network and page randomness.
We randomly pick four classes (webpages indexing 80, 84,
33, and 81 in our dataset) for illustration. Their center traces
are shown in Figure 5. We use positive values to represent
outgoing bursts and negative values to represent incoming
bursts. We only show the ﬁrst 400 outgoing and incoming
bursts since the sizes of the last 300 bursts are all close to 0.
As we can see, in each class, the real and fake center traces
are shown to be quite close to each other, indicating that our
generator successfully learns the unique features.
Fitting Other Datasets. To show that our GAN can eas-
ily adapt to mimicking different webpages, we train a new
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:35:20 UTC from IEEE Xplore.  Restrictions apply. 
1564
1
0.8
0.6
0.4
0.2
0
0
1
−1
−2
−3
Time Gap (seconds, in log scale)
−4
Fig. 6: Probability Density Function of to(cid:1)o.
2
generator with another widely-used dataset DS95 collected
by Sirinam et al. [5]. The dataset has 95 classes, each with
1000 instances. The large number of instances for each class
guarantees fast convergence for our trace generation task. We
use the same hyperparameters in Table II to train the model.
We ﬁnd that the model converges after only 253 epochs on
DS95, leading to an estimated Wasserstein distance of 0.023
and a 90% accuracy on the observer. We also investigate the
center traces for real and fake data and ﬁnd that they are all
very close to each other, showing that the generator is well-
trained. We include some examples to show the quality of
generated traces in Appendix B.
2) Time Gap Modeling: In our defense, we let R sample
time gaps (i.e., to(cid:1)o) from a time gap distribution between
bursts. To correctly capture the characteristics of to(cid:1)o, we learn
such a distribution from real data. We collect over 25,000,000
time gaps from DSgan and estimate the data distribution using
FFTKDE which is one of the fastest implementations of KDE.
To avoid sampling a negative to(cid:1)o, we instead model the dis-
tribution of log to(cid:1)o. Figure 6 shows the distribution we learnt
from DSgan. We observe that log to(cid:1)o roughly follows a normal
distribution. The mean gap sampled from this distribution is
about 42 ms.
V. DEFENSE EVALUATION
In this section, we evaluate Surakav in several aspects.
We ﬁrst describe the experiment setup and the datasets we
collected. Then we compare Surakav with the state-of-the-
art defenses to show its effectiveness. We also analyze the
overhead required to deploy our defense onto the Tor network.
Lastly, we explore the impact of setting different parameter
values on Surakav.
A. Experiment Setup
We evaluate Surakav using implementation instead of sim-
ulation because implementation is more accurate than simula-
tion in evaluating the effectiveness of a defense. Many of the
mechanisms in Surakav cannot be accurately simulated with
current methods. We compare our defense with two state-of-
the-art defenses of two different categories, Tamaraw [13] and
FRONT [9], using real defended traces.
1) Implementation Overview: We
extended WFDef-
Proxy [41], a framework for WF defense evaluation, and im-
plemented Surakav as a pluggable transport (PT). Gong et al.
have already successfully implemented several WF defenses
such as FRONT [9], Tamaraw [13] and Random-WT [10] (a
variation of Walkie-Talkie) in the framework. Each defense
serves as a PT that obfuscates the trafﬁc between the client
and the entry node according to the defense protocol. The
implementation excludes the entry node as a potential WF
attacker; we will discuss this limitation in Section VII.
2) Deployment Details: We rent three servers on Microsoft
Azure to conduct the experiments. One server is used as our
private bridge (i.e., the entry node) on which we deploy the
defenses. On the other two servers, we create in total ten
docker containers acting as ten independent clients to visit
webpages in parallel. They will all connect to our private
bridge as the ﬁrst node of their circuits. The client servers
and the bridge server are placed in two different areas in the
world; the exact locations are scrubbed for blind review.
The bridge is conﬁgured to have 1 CPU core (2.3 GHz)
and 2 GB of memory. The Tor version running on the bridge
is 0.4.4.5 in Debian 9.11. The client servers are conﬁgured
to have 4 CPU cores (2.3 GHz) and 16 GB memory, running
on Ubuntu 18.04.4 LTS, to support multiple client processes.
For each client, we use a customized Tor Browser to visit
webpages. It is based on version 10.0.15 and incorporates three
WF defense PTs. It has an initial user proﬁle to avoid being
detected as a bot by web servers. To visit a webpage, every
client will launch a new instance of this Tor Browser so that
no browser caches are kept. Each trace is collected over a
different circuit. Each visit is given at most a 80 s session to
load the page, and we wait for an extra 5 s on the page after
a loading process ﬁnishes, and then terminate the browser.
To allow Tor Browser to run on Azure servers, we set the
variable MOZ_HEADLESS to True, so that Tor Browser runs
in headless mode while still rendering the webpage. Since
Azure servers could have unlimited bandwidth and may not
correctly represent a normal Tor user at home, we further limit
the connection bandwidth for each client at 120 Mbits, accord-
ing to the global average bandwidth estimated by Speedtest in
July 2021 [42].
3) Dataset: We collected open-world and close-world
datasets. Each open-world dataset contains in total 70,000
instances with 100 monitored sites (each loaded 100 times) and
60,000 non-monitored sites (each loaded once). Each closed-
world dataset only contains 10,000 monitored instances. To
compare different defenses, we directly evaluate the defenses
with open-world datasets (Section V-B). We use closed-world
datasets instead of open-world datasets for parameter tuning
to reduce the otherwise prohibitive amount of time to collect
datasets (Section V-D) as each parameter setting requires a
new dataset. In total, we had 15 closed-world datasets and 5
open-world datasets.
We collect data on the Tranco top 1 million [43] sites. The
list was generated on 21st January 2021. Duplicated URLs
directing to the same page or related to website localization
are removed in advance. The ﬁrst 100 URLs in the list are
the monitored sites. The 60,000 URLs starting from the 201st
are the non-monitored sites. We crawl the monitored sites in
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 12:35:20 UTC from IEEE Xplore.  Restrictions apply. 
1565
TABLE III: Attack results on the implemented defenses in the open-world scenario. Each dataset (100 × 100 + 60,000) is
collected in the live Tor network. All values are in percentages.
Defense
None
FRONT [9]
Tamaraw [13]
Surakav-light
Surakav-heavy
Overhead
Data
Time
0
97
121
55
81
0
0
26
16
17
kFP
TPR
73.62
0.92
0.36
0.85
0.01
FPR
0.18
0.01
0.03
0.02
0
CUMUL
TPR
74.23
3.78
1.91
11.24
2.74
FPR
3.50
9.55
8.99
8.79