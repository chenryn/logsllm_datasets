if (%al == 1)
VON NEUMANN
else
HARVARD
1
2
3
4
5
6
7
movb $1, A+1
movb A+1, %al
A: andb $1, %al
if (%al == 1)
VON NEUMANN
else
HARVARD
Figure 6. Self-modifying code to detect mem-
ory architecture, described in Section 3.
ory. The checksum sequences, however, read and verify the
unchanged but never executed code from the data memory.
By creating a virtual Harvard architecture, the attack suc-
cessfully modiﬁes code executed by the program without
detection by code checksumming functions.
3. Memory Architecture Detection
Processes can identify the underlying main memory ar-
chitecture using self-modifying code.
Intuitively, detec-
tion works by modifying code in the program and then
both reading the code and executing the code. If the value
read disagrees with the code executed, then either the data
read or the instruction fetch retrieved the unmodiﬁed code,
which occurs only when memory is Harvard (Figure 5).
The process performs the following steps:
1. Overwrite an existing instruction I1 with a new instruc-
tion I2. The code change from I1 to I2 must alter execu-
tion in a noticeable way.
2. Read back the instruction using data memory reads.
3. Execute the instruction.
If memory is von Neumann, then the memory write in step 1
will be visible to both data reads and instruction fetches. As
a result, the value read in step 2 and the instruction executed
in step 3 will both be the new instruction I2. If memory is
Harvard, then step 1 changes only data memory. Step 2 will
read I2, but step 3 will execute I1. The requirement that
I2 changes execution in a noticeable way exists precisely
so that we can detect which instruction is fetched simply by
executing the instruction. By a symmetric argument, we can
likewise detect writes that change only instruction memory.
Figure 6 shows a pseudo-code sequence that performs
memory architecture detection. For clarity, we show a mix
of AT&T-style x86 assembly code with C-style branching.
In the AT&T syntax, the rightmost operand of an assem-
bly code instruction is the destination of any output value.
This code is self-modifying. The instruction in line 1 per-
forms step 1 of architecture detection by overwriting the
Figure 7. Code of Figure 6 following self-
modiﬁcation on a von Neumann machine. Ex-
ecution of line 1 changed the immediate value
used in line 3 from 0 to 1.
memory location one byte past the label A. This location
corresponds to the immediate operand of the bitwise andb
in line 3. Figure 7 shows the resulting altered code on a
von Neumann machine. In this example, instruction I1 is
“andb $0, %al” and I2 is “andb $1, %al”.
Lines 2 and 3 exercise both a data read and an instruction
fetch of the location A+1. Line 2 is detection step 2: the
mov instruction reads the byte using a data memory read,
storing the value in register %al. Line 3 triggers an instruc-
tion fetch for an instruction that includes address A+1 and
performs a bitwise and of the byte read from data mem-
ory against the byte fetched from instruction memory. The
register %al is 1 only when both the data read and the in-
struction fetch retrieved data rewritten by the earlier code
modiﬁcation. If either the data read or the fetch read from
the original code of Figure 6, then %al has value 0.
The branching of lines 4 through 7 encode the ﬁnal de-
tection logic. A von Neumann memory will write the code
alteration of line 1 to the shared store accessed by both data
reads and instruction fetches. The self-modifying detection
code will compute the value 1 for register %al. A Harvard
memory updates the data memory but does not write the
code change through to the instruction memory. Register
%al then takes value 0. Hence, this mechanism provides
processes a way to identify whether the main memory is
von Neumann or Harvard.
3.1. Strengthening Self-Checksumming
This memory architecture detection technique can
strengthen existing self-checksumming algorithms. These
algorithms require the von Neumann assumption to hold be-
fore any checksum computation can meaningfully verify a
code sequence. By identifying properties of the underly-
ing hardware, self-checksumming algorithms can verify the
veracity of the von Neumann assumption and take appropri-
ate action when the hardware violates the assumption. This
detection holds even when software creates a virtual Har-
vard architecture on commodity von Neumann machines, as
done by the page-replication attack of Wurster et al. [28].
1
2
3
4
5
6
7
8
9
10
11
...
R1: movb $1, A+1
call checksum(R1, R2)
A: andb $0, %al
movb $0, A+1
if (%al != 1)
call failed_license()
call verify_license()
if (%al != 1)
call failed_license()
R2: ...
Figure 8. Self-checksumming augmented
with von Neumann assumption veriﬁcation.
Figure 8 shows how veriﬁcation of the von Neumann
assumption can be integrated into a pre-existing checksum
computation. Line 2 overwrites the immediate operand of
the bitwise andb in line 4, as in Figure 6. The checksum
computation in line 3 returns the value 1 in register %al
if the checksum calculated for the modiﬁed code matches
a precomputed value. If the data reads performed by the
checksum function read the original code from line 4
rather than the rewritten value, the checksum computation
will fail. Subsequent execution of line 4 will exercise an
instruction fetch of the modiﬁed code. Only when both
the data read by the checksum function and the instruc-
tion fetch retrieve the modiﬁed data will register %al take
value 1. The virtual Harvard memory created by the page-
replication attack results in the value 0 and subsequent at-
tack detection handling at lines 6 and 7. This veriﬁcation
code can detect a page-replication attack that segregates
memory into code and data pages and then modiﬁes or re-
moves the verify license call from the code page.
3.2. Construction of Self-Modifying Code
Our self-modifying code is not itself a checksumming
routine but augments existing self-checksumming algo-
rithms so that they detect the page-replication attack. Al-
though we have not yet developed the custom compiler tools
that automatically produce tamper-resistant programs con-
taining memory architecture detection, we foresee straight-
forward implementation. Given an existing checksumming
routine checksum that operates over the range of program
points [R1, R2), memory architecture detection could be
implemented as follows:
• an instruction sequence S1 ∈ [R1, R2) that computes
some value x,
• an instruction sequence S2 that overwrites instructions
in S1 such that the the overwritten S1 computes a value
y 6= x and the checksum of the overwritten S1 is different
than the checksum of the original S1, and
• an instruction sequence S3 that ﬁrst executes S1 to check
if the value computed by S1 equals y, and then overwrites
S1 to restore the original instruction sequence.
The checksum function is altered so that
the hard-
coded expected checksum value matches the checksum of
[R1, R2) subsequent to the overwrite of S1. We insert the
code sequence S2 before the checksum computation so that
checksum reads from the modiﬁed code sequence and
veriﬁes that the writes to code are written to data pages.
We add the sequence S3 after the computation to verify that
the writes to code are written to code pages. The memory
region [R1, R2) has integrity only when both the checksum
veriﬁcation succeeds and execution of S3 indicates that the
code sequence S1 computes the value y.
This generic algorithm allows for a wide variety of code
sequences to be used as building blocks, such as the code
used in Figure 8, and makes this protection mechanism
amenable to automatic construction. For example, opaque
predicates [8] can serve as sequences S1 and S3, while also
providing a layer of obfuscation to the veriﬁcation mecha-
nism. As with code obfuscation, the self-modifying code
can be added to a program at the end of the development
cycle (at release time), and hence will not interfere with de-
bugging.
3.3. Cache Coherence
Modern systems use a hierarchy of memories that con-
tains intermediate caches between the processor and the
main memory. For efﬁciency, these caches are often write-
back rather than write-through, meaning that a value writ-
ten to a cache is not propagated to the next layer of memory
until the cache entry is ﬂushed. Caches close to the proces-
sor, frequently termed “L1” and “L2” caches, use a Harvard
architecture to better exploit locality differences in instruc-
tion fetches and data reads and writes. A self-modifying
program writes generated code using standard data writes,
which the processor transmits through the L1 data cache (D-
cache). The program requires cache coherency between the
D-cache and the instruction cache (I-cache) to ensure that
stale instructions cached in the I-cache are not subsequently
executed. Otherwise, the architecture detection might er-
roneously conclude that a von Neumann main memory is
Harvard when I-caches and D-caches are not coherent.
Fortunately, the highly prevalent x86 processors have
maintained cache coherency since at least the Pentium Pro
processor [4, 14]. These processors detect writes to the D-
cache of instructions already present in the I-cache. They
will automatically invalidate the I-cache entry and ﬂush any
modiﬁed instructions that may have already entered the pro-
cessor’s pipeline. The correctness of a self-modifying pro-
gram’s execution is assured by the x86 hardware.
However, not all commodity processors in use today
are cache coherent [17, 20]. Some processors require self-
modifying programs to issue special instructions, such as
flush, that ﬂush dirty D-cache entries and invalidate stale
I-cache instructions following code modiﬁcation. This
presents no particular onus to self-modifying programs;
however, these cache ﬂush instructions are not commonly
used by programs that are not self-modifying. Adding ar-
chitecture detection code containing ﬂush instructions to a
self-checksumming program provides sentinel instructions
that an attacker can use to locate and remove the checksum
calculations. As execution of cache ﬂush instructions does
not affect the execution correctness of code that is not self-
modifying, an obfuscator can add arbitrary ﬂush instruc-
tions throughout the original program code, forcing the at-
tacker to determine which ﬂushes occur due to architecture
detection and which are irrelevant.
4. Evaluation
We evaluate the robustness and performance of our
memory architecture detection technique. First, we con-
sider the possible attacks that a malicious user with knowl-
edge of our technique could mount and conclude that an
attacker can evade detection only by expending signiﬁcant
resources: a high runtime overhead or the design and con-
struction of specialized hardware. Second, we examine the
interactions between our detection algorithm and other se-
curity mechanisms. Third, we evaluate the performance of
architecture detection and show that, in the worst case, one
memory architecture detection check has cost similar to an
average system call. This performance number can be used
by a software producer as guidance when inserting checks
in various parts of the program. Finally, we argue that
the memory architecture detection can be combined with
any self-checksumming scheme for any hardware platform,
making it applicable in a wide variety of settings where tam-
per resistance is required.
4.1. Resistance to a Knowledgeable Attacker
The page-replication attack executes code from a mod-
iﬁed memory page B while forcing self-checksumming
to complete correctly by reading data from the original
memory page A. An attacker with knowledge that a self-
checksumming program employs memory architecture de-
tection may adjust the page-replication attack in an attempt
to evade detection. We show that we can detect any attack
that does not violate Assumptions 1 and 2 of Section 2.1 by
analyzing the possible destinations of a memory write when
the destination page has been replicated: writes that update
both pages A and B, writes that update only A, and writes
that update only B. The fourth case of writes that update
some other page or no page at all is nonsensical and not
considered further.
First, the attacker could redirect writes that target code
to both the code and data memory pages A and B in the vir-
tual Harvard architecture. This requires interpretive emula-
tion of write instructions, as commodity processors provide
no hardware mechanism by which one write instruction up-
dates two different physical memory locations. The attacker
can leverage page-level memory protections by marking
code pages executable but non-writable. Every time the
self-modifying code attempts to write to a code page, the
processor raises a hardware fault that the malicious operat-
ing system then handles. In the operating system, the at-
tacker can emulate the write and update both the code and
data memories.
Second, the attack may have altered operating system
data structures so that writes execute at full speed and up-
date page A, the page containing the original program code.
Consider the effect of executing our memory architecture
detection algorithm on such a page. The checksum com-
putation will calculate the correct value, but execution of
the self-modiﬁed code will detect the virtual Harvard ar-
chitecture because the code page B was not updated. To
defeat this detection, the attacker needs execution of the
self-modifying code to fetch from A, but all other program
execution to fetch from B. This requires both violation of
Assumption 1 and emulation of instruction fetches.
Finally, memory writes may update page B, the page
altered by the attacker. This may cause outright program
failure, as the self-modifying code may be overwriting un-
known instructions inserted by the attacker. At the least,
checksum computation will fail, as the data page A read
by the checksum function will not have been updated and
the checksum veriﬁcation compares against a stored check-
sum of the code following self-modiﬁcation. An attacker
requires reads speciﬁcally of self-modiﬁed code to be re-
trieved from B, but all other reads to retrieve from A so that
the checksum is correctly computed. This attack requires
emulation of read instructions.
Successful attacks in all three cases rely upon interpre-
tive emulation of instructions on memory pages containing
self-modifying code. The attacker can take advantage of
the expectation that the number of code modiﬁcations per-
formed by memory architecture detection will remain low,
and hence interpret a limited number of writes, fetches, or
reads with a small overall performance cost. We consider
the case of emulated writes, although symmetric arguments
hold for fetches and reads as well.
Our suggested defense increases the cost of trapped and
emulated writes by forcing the attacker to emulate all writes
rather than just the infrequent writes to code. The tra-
P4
P3
P2
P1
Data
Heap
    

    

    

    

    

    

    

    

    

    

    

    

    

    

Code
Code
P3
P4
 Code
 
 

 

 Data
 
 
 


Code
Code 

 

 

 

 

 

 
 


Heap
 

 

 

 