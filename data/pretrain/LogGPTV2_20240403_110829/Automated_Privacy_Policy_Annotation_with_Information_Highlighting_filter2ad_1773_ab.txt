common words that do not add meaning, are removed. Then, Word-
Net Lemmatizer is used for words lemmatization and stemming. This
process removes the generic words and words/sub-words that do
not contribute to the meaning or context of the paragraph, making
the learning process more efficient and accurate.
Paragraph Representation. To find a suitable highly discrimina-
tive representation for each category, various text representation
techniques are used in TLDR: word mapping, count vectorizer, TF-
IDF, Doc2Vec, Universal Sentence Encoder (USE), and WordPiece.
Preprocessing and feature representation are critical in TLDR im-
plementation to unveil the hidden patterns within each paragraph
without the need for human labor or manual annotation.
Learning Algorithms. TLDR trains an ensemble of learning algo-
rithms for associating paragraphs with their corresponding privacy
policy categories. Doing so reveals the abstract content of the pri-
vacy policy without the need for reading such content. We leverage
six machine and deep learning algorithms for privacy policy detec-
tion, including, Logistic Regression (LR), Support Vector Machine
(SVM), Random Forest (RF), Convolutional Neural Networks (CNN),
Deep Neural Network (DNN), and Bidirectional Encoder Represen-
tations from Transformers (BERT), evaluating their effectiveness
in detecting various paragraph-level categories.
Acknowledging that privacy policy categories are unique, TLDR
leverages the best performing data representation for category clas-
sification. The wide range of explored representations and learning
Figure 2: Alexa Top-10,000 data collection and paragraph ex-
traction pipeline.
algorithms is due to the diversity of categories, where treating them
indiscriminately results in reduced performance.
3 EVALUATION AND DISCUSSION
3.1 Annotation Results of TLDR
Experimental Setup. We used document-based splitting, where
80% of the documents in OPP-115 dataset are used for training
the ensemble while the remaining 20% of the documents are used
for validation. For deep learning architectures, we adopt the archi-
tecture by Harkous et al. [5] for our CNN model, and replace the
convolutional layers with fully connected layers to build the DNN
model. We configure the BERT model with a 512 maximum number
of words, with the number of features in the range of [1,000, 5,000]
with an increment of 1,000.
Annotation Results. Table 1 shows the best performing archi-
tecture for each category used for analysis. Similarly, we report
the best performing evaluation results of Wilson et al. [9], Hark-
ous et al. [5], and Liu et al. [6], on the OPP-115 dataset using the
ùêπ1 score. As shown, except for ‚ÄúSpecific Audiences‚Äù and ‚ÄúDo Not
Track‚Äù categories, TLDR outperforms its counterparts by a large
margin, particularly for ‚ÄúData Retention‚Äù.
3.2 Alexa Top-10,000 Websites Analysis
We used TLDR to analyze the Alexa [2] top-10,000 websites privacy
policies practices. The Alexa top-10,000 represents the most visited
websites by users worldwide. Analyzing such websites uncovers the
common practices of popular websites and their service providers,
targeting a large portion of the Internet users.
Privacy Policy Extraction. We start by obtaining the privacy
policies of the websites among the Alexa top-10,000 websites list.
Using Selenium [8], the privacy policies were crawled between Nov.
4 and Nov. 8 of 2020. Then, the privacy policies are extracted by
searching the webpages within a website for terms, e.g., privacy
policy, and privacy. Among the top-10,000 websites, we successfully
extracted the policies of 5,598 websites. The remaining websites
are either (1) non-English or (2) do not directly link to their privacy
policy on the website. Validation. To validate the correctness of
the extraction process, we manually inspect 1,000 extracted privacy
policies, and verified that 95.8% of them are correctly extracted. The
process of website crawling and cleaning is shown in Figure 2.
Session 8: Poster & Demo Session CCS ‚Äô21, November 15‚Äì19, 2021, Virtual Event, Republic of Korea2379Data Preprocessing & Representation. The extracted paragraphs
(345,920) are then preprocessed and represented in a way similar
to OPP-115 [9]. We removed the stop-words, then the words in
the paragraph were lemmatized and stemmed. We limit the hyper-
parameters configurations to the best performing within the feature
representations and learning algorithms.
Evaluation & Discussion. We used TLDR to extract existing pri-
vacy practices within Alexa top-10,000 websites. Figure 3 shows
the percentage of websites containing information regarding the
policy categories for both OPP-115 and Alexa top-10,000 websites.
Overall, the ‚Äúfirst-party use‚Äù and ‚Äúthird party sharing‚Äù categories
are the most common within the privacy policies, with 95% of the
websites containing first-party use information, and 90% of them
including information regarding third-party sharing. On the other
hand, the ‚Äúdo not track‚Äù category is the least common within the
privacy policies, with only 20% of the websites reporting informa-
tion associated with it. Given that the ensemble achieves an ùêπ1
score of 100% on this category, the results are of high confidence.
Missing Information. By examining the ensemble results, we
found that a large number of websites‚Äô privacy policies miss key
information and attributes, by not covering important areas includ-
ing data security and user tracking. This comes as a surprise, given
that the extracted privacy policies are from the top-visited websites
as of November 2020, which are potentially the subject of great
interest, and their policies are the subject of great scrutiny.
Future Direction: Per Topic Analysis. To better understand the
privacy policy practices disclosure by the website provides, the next
step is to conduct per topic analysis of the reported practices. This
can be done using Webshrinker [4], a machine learning-powered
domain data and threat classifier, to obtain the categorization of
the domains of the websites. This step is essential to draw deep
observations on the trends among the most popular websites.
3.3 User Study: Information Highlighting
We conduct a user study with a total of 20 participants to investigate
the effectiveness of TLDR in information highlighting. Removing
unnecessary policy information reduces the efforts required to un-
derstand the privacy practices of the service providers. However,
omitting important privacy policy aspects can be critical by reduc-
ing the users awareness of the reported practices.
Each participant is assigned three policies of different lengths.
For each policy, two instances were initiated, the original and the
TLDR filtered policies (after removing all paragraphs with no asso-
ciated privacy policy information). The participant then read the
two instances of each privacy policy in a random order, and is not
aware of the filtering process nor the objective of this study. The
participant is expected to keep a record of the reading time of each
policy, and answer a survey after reading each privacy policy.
Results. According to 82% of the participants, the privacy policies
are understandable and suitable upon applying the TLDR filtering
process. This is surprising, as only 69% of the participants indi-
cated the original privacy policies are understandable. This may
be a result of removing unnecessary (legal) information that does
not necessarily contribute to the practices. The participants also
reported a reduced reading time for TLDR filtered policies, i.e., an
average of 39.14% time reduction in comparison with the original
Figure 3: Percentage of websites with positive paragraphs
per category for Alexa top-10,000 and OPP-115 websites.
policy. As noted, removing important information may result in
missing critical data collection and sharing practices. According to
the participants‚Äô responses, only 23% of the policies include critical
information that is not reported in the TLDR filtered instance.
4 CONCLUDING REMARKS
In this work, we revisit the automated privacy policy annotation
problem by exploring and improving the accuracy of annotation
through various learning and representation techniques. In partic-
ular, we propose TLDR, a pipeline employing deep representation
techniques and an ensemble of machine and deep learning-based
models to automatically and accurately categorize each paragraph
in the privacy policy to its corresponding high-level content cate-
gory, achieving an average ùêπ1 score of 91%. Our user study shows
the effectiveness of TLDR in highlighting privacy policy practices
to reduce the reading time and increase the understandability.
Acknowledgement. This work is supported by NRF under grant
2016K1A1A2912757 and a seed grant from CyberFlorida. The full
version of this work appears in ACM WPES‚Äô21 [1].
REFERENCES
[1] Abdulrahman Alabduljabbar, Ahmed Abusnaina, Ulku Meteriz-Yildiran, and
David Mohaisen. 2021. TLDR: Deep Learning-Based Automated Privacy Policy
Annotation with Key Policy Highlights. In The 20th Workshop on Privacy in the
Electronic Society (WPES ‚Äô21).
[2] Amazon. 2020. Alexa top websites. https://www.alexa.com/topsites
[3] Lorrie Faith Cranor. 2002. Web privacy with P3P - the platform for privacy prefer-
ences. O‚ÄôReilly.
[4] Developers. 2020. Webshrinker. https://www.webshrinker.com/.
[5] Hamza Harkous, Kassem Fawaz, R√©mi Lebret, Florian Schaub, Kang G Shin, and
Karl Aberer. 2018. Polisis: Automated analysis and presentation of privacy policies
using deep learning. In 27th USENIX Security Symposium (USENIX Security 18).
531‚Äì548.
[6] Frederick Liu, Shomir Wilson, Peter Story, Sebastian Zimmeck, and Norman
Sadeh. 2018. Towards automatic classification of privacy policy text. School of
Computer Science Carnegie Mellon University (2018).
[7] Aleecia M McDonald and Lorrie Faith Cranor. 2008. The cost of reading privacy
policies. Isjlp 4 (2008), 543.
[8] Selenium. 2020. SeleniumHQ Browser Automation. https://www.selenium.dev/
[9] Shomir Wilson, Florian Schaub, et al. 2016. The Creation and Analysis of a
Website Privacy Policy Corpus. In Proceedings of the 54th Annual Meeting of the
Association for Computational Linguistics (Volume 1: Long Papers).
[10] Razieh Nokhbeh Zaeem, Rachel L. German, and K. Suzanne Barber. 2018. Pri-
vacyCheck: Automatic Summarization of Privacy Policies Using Data Mining.
ACM Trans. Internet Techn. 18, 4 (2018), 53:1‚Äì53:18.
Session 8: Poster & Demo Session CCS ‚Äô21, November 15‚Äì19, 2021, Virtual Event, Republic of Korea2380