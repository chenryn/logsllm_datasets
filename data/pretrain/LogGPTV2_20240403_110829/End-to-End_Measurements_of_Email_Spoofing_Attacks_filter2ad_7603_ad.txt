0.03
0.03
0.03
1.00
1.00
1.00
0.79
Table 2: The ratio of emails that reached the inbox (inbox rate). We break down the inbox rate for emails with different
conﬁguration parameters (sender IP, the SPF/DKIM/DMARC proﬁle of the sender address, and the email content).
addresses), and then repeat the experiments for 5 times.
Each email service receives 300 × 5 = 1,500 emails
(52,500 emails in total). We shufﬂed all the emails and
send them in randomized orders. We also set a sending
time interval of 10 minutes (per email service) to mini-
mize the impact to the target mail server. The experiment
was conducted in December 2017– January 2018. Note
the volume of emails in the experiment is considered
very low compared to the hundreds of billions of emails
sent over the Internet every day [5]. We intentionally
limit our experiment scale so that the experiment emails
would not impact the target services (and their email ﬁl-
ters) in any signiﬁcant ways. The randomized order and
the slow sending speed helps to reduce the impact of the
earlier emails to the later ones in the experiments.
After the experiment, we rely on IMAP/POP to re-
trieve the emails from the target email provider. For a
few providers that do not support IMAP or POP, we use
a browser-based crawler to retrieve the emails directly
through the web interface. As shown in Table 2, we
group email providers based on the supported authen-
tication protocols. Within each group, we rank email
providers based on the inbox rate, which is the ratio of
emails that arrived the inbox over the total number of
emails sent. Emails that did not arrive the inbox were ei-
ther placed in the spam folder or completely blocked by
the email providers.
Ratio of Emails in the Inbox.
Table 2 shows that the
vast majority of email services can be successfully pen-
etrated. 34 out of the 35 email services allowed at least
one forged email to arrive the inbox. The only exception
is Hotmail which blocked all the forged emails. 33 out
of 35 services allowed at least one phishing email to get
into the inbox. In particular, the phishing email has pen-
etrated email providers that perform full authentications
(e.g., Gmail, iCloud, Yahoo Mail) when spooﬁng sender
domains that do not have a strict reject DMARC policy.
In addition, providers such as juno.com, t-online.de,
and excite.com did not block forged emails at all with
a 100% inbox rate. juno.com actually checked both
SPF and DKIM. This suggests that even though the email
providers might have detected the email forgery, they still
deliver the email to the user inbox.
Impact of Receiver’s Authentication.
Table 2 shows
that email providers’ authentication methods affect the
spooﬁng result. For email providers that perform no
authentication, the aggregated inbox rate is 94.2%.
In
comparison, the aggregated inbox rate is much lower
for email providers that perform a full authentication
USENIX Association
27th USENIX Security Symposium    1101
(a) Sender IP
(b) Sender Address SPF/DK./DMA. Proﬁle
(c) Email Content
Figure 5: The aggregated rato of emails that reached the user inbox (inbox rate). The legend displays the 3 authenti-
cation groups of the receivers. Each subﬁgure shows the breakdown results for emails with speciﬁc conﬁgurations.
(39.0%) and email providers that just perform SPF/D-
KIM (39.3%). To examine the statistical signiﬁcance of
the differences, we apply Chi-Squared test on emails sent
to the three types of email providers. The result con-
ﬁrms that emails are more likely to reach the inbox of
“no-authentication” providers compared to the two other
groups with statistical signiﬁcance (both p  actually sent this message (and not a spam-
mer)”. The red lock icon is not related to spooﬁng, but
to indicate the communication between MX servers is
unencrypted. On the other hand, services like naver,
163.com and protonmail use explicit text messages to
warn users.
Mobile Client.
Even fewer mobile email apps have
adopted security indicators. Out of the 28 email services
with a dedicated mobile app, only 4 services have mo-
bile security indicators including naver, protonmail,
Gmail, and google inbox. The other services removed
the security indicators for mobile users. Compared to the
web interface, mobile apps have very limited screen size.
Developers often remove “less important” information to
keep a clean interface. Unfortunately, the security indi-
cators are among the removed elements.
USENIX Association
27th USENIX Security Symposium    1103
(c) 163.com, 126.com (Web)(b) Naver.com (Web and Mobile) (a) Gmail.com (Web and Mobile), Google Inbox (Mobile)(f) Protonmail.com (Web, same-domain spooﬁng)(h) Gmail.com (Web, same-domain spooﬁng)(i) Hotmail.com (Web, spooﬁng existing contact)(g) Daum.net (Web, same-domain spooﬁng)(d) Protonmail.com (Web and Mobile)(e) Mail.ru (Web)Misleading UI
Sender Photo (6)
Name Card (17)
Email History (17)
Email Providers (25 out of 35)
G-Inbox, Gmail, zoho, icloud∗, gmx†,
mail.com†
yahoo, hotmail, tutanota, seznam.cz,
fastmail, gmx, mail.com, Gmail∗,
sina∗, juno∗, aol∗, 163.com†,
126.com†, yeah.net†, sohu†, naver†,
zoho†
hotmail, 163.com, 126.com, yeah.net, qq,
zoho, mail.ru, yahoo∗, Gmail∗,
sina∗, naver∗, op.pl∗, interia.pl∗,
daum.net∗ gmx.com∗, mail∗, inbox.lv∗
Table 4: Misleading UI elements when the attacker
spoofs an existing contact. (∗) indicates web interface
only. (†) indicates mobile only.
Third-party Client.
Finally, we check emails using
third-party clients including Microsoft Outlook, Apple
Mail, and Yahoo Web Mail. We test both desktop and
mobile versions, and ﬁnd that none of them provide se-
curity indicators for the forged emails.
5.4 Misleading UI Elements
We ﬁnd that attackers can trigger misleading UI elements
to make the forged email look realistic.
Spooﬁng an Existing Contact.
When an at-
tacker spoofs an existing contact of the receiver, the
forged email can automatically load misleading UI el-
ements such as the contact’s photo, name card, or pre-
vious email conversations. We perform a quick experi-
ment as follows: First, we create an “existing contact”
(PI:EMAIL) for each receiver account in the 35
email services, and add a name, a proﬁle photo and a
phone number (if allowed). Then we spoof this contact’s
address (PI:EMAIL) to send forged emails. Ta-
ble 4 shows the 25 email providers that have mislead-
ing UIs. Example screenshots are shown in Appendix
C. We believe that these designs aim to improve the us-
ability of the email service by providing the context for
the sender. However, when the sender address is actually
spoofed, these UI elements would help attackers to make
the forged email look more authentic.
In addition, spooﬁng an existing contact allows forged
emails to penetrate new email providers. For example,
Hotmail blocked all the forged emails in Table 2. How-
ever, when we spoof an existing contact, Hotmail deliv-
ers the forged email to the inbox and adds a special warn-
ing sign as shown in Figure 6(i).
Same-domain Spooﬁng.
Another way to trigger
the misleading UI element is to spoof an email address
that belongs to the same email provider as the receiver.
For example, when spooﬁng  to
send an email to , the proﬁle photo
of the spoofed sender will be automatically loaded. Since
Figure 7: Seznam.cz displays a “trusted address” sign on
a forged address.
the spoofed sender is from the same email provider, the
email provider can directly load the sender’s photo from
its own database. This phenomenon applies to Google
Inbox and Gmail (mobile) too. However, email providers
also alert users with special security indicators. As
shown in Figure 6(f)-(h), related email providers include
protonmail, Gmail and daum.net. Together with pre-
viously observed security indicators, there are in total 9
email providers that provide at least one type of security
indicators.
False Security Indicators.
One email provider
seznam.cz displays a false security indicator to users.
seznam.cz performs full authentications but still deliv-
ers spoofed emails to the inbox. Figure 7 shows that
seznam.cz displays a green checkmark on the sender
address even though the address is forged. When users
click on the icon, it displays “trusted address”, which is
likely to give users a false sense of security.
6 Effectiveness of Security Indicators
As an end-to-end study, we next examine the last hop
— how users react to spooﬁng emails. Our result so far
shows that a few email providers have implemented vi-
sual security indicators on the email interface to warn
users of the forged emails.
In the following, we seek
to understand how effective these security indicators are
to improve user efﬁcacy in detecting spoofed phishing
emails.
6.1 Experiment Methodology
To evaluate the effectiveness of security indicators, we
design an experiment where participants receive a phish-
ing email with a forged sender address. By controlling
the security indicators on the interface, we assess how
well security indicators help users to handle phishing
emails securely.
Implementing this idea faces a key challenge, which
is to capture the realistic user reactions to the email.
Ideally, participants should examine the phishing email
without knowing that they are in an experiment. How-
ever, this leads to practical difﬁculties to set up the user
study and obtain the informed user consent up front. To
1104    27th USENIX Security Symposium
USENIX Association
False security cuethis end, we introduce deception to the study methodol-
ogy. At the high level, we use a distractive task to hide
the true purpose of the study before and during the study.
Then after the study is completed, we debrief the users to
obtain the informed consent. Working closely with our
IRB, we have followed the ethical practices to conduct
the phishing test.
Procedure.
We frame the study as a survey to un-
derstand users’ email habits. The true purpose is hidden
from the participants. This study contains two phases.
Phase1 is to set up the deception and phase 2 carries out
the phishing experiment.
Phase1: The participants start by entering their own
email addresses. Then we immediately send the partici-
pants an email and instruct the participants to check this
email from their email accounts. The email contains a
tracking pixel (a 1×1 transparent image) to measure if
the email has been opened. After that, we ask a few ques-
tions about the email (to make sure they actually opened
the email). Then we ask other distractive survey ques-
tions about their email usage habits. Phase1 has three
purposes: (1) to make sure the participants actually own
the email address; (2) to test if the tracking pixel works,
considering some users may conﬁgure their email ser-
vice to block images and HTML; (3) to set up the decep-
tion. After phase1, we give the participants the impres-
sion that the survey is completed (participants get paid
after phase1). In this way, participants would not expect
the second phishing email.
Phase2: We wait for 10 days and send the phishing
email. The phishing email contains a benign URL point-
ing to our own server to measure whether the URL is
clicked. In addition, the email body contains a tracking
pixel to measure if the email has been opened. As shown
in Figure 8, we impersonate the tech-support of Ama-
zon Mechanical Turk (PI:EMAIL) to send the
phishing email that informs some technical problems.
This email actually targeted our own institution before.
The phishing email is only sent to users whose email ser-
vice is not conﬁgured to block HTML or tracking pixels