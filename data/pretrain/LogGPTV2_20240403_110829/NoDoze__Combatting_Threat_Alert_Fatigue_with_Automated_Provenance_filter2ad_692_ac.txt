Event Frequency Database that periodically stores and updates
events frequency in the whole enterprise. A detailed discussion
regarding the construction of such database will be provided
in §VII.
Let’s
consider
event E1
an alert
:= from Fig. 2a. We ﬁrst calculate
F req(E1) by counting the number of events that have
happened in our frequency event database where SRC ∈
dropper.exe , DST ∈ y.y.y.y:445 and REL is IP Write. Then,
we will calculate F reqsrc rel(E1) by counting the number of
events where SRC ∈ dropper.exe and REL is IP Write while
DST could be any entity node. Details regarding how these
functions are implemented will be provided in §VII.
Transition probability for a given event tells us the fre-
quency with which a particular source ﬂows to a particular
destination; however, we are ultimately going to propagate
this value through the graph, but when we do so we want to
account for the total amount of data ﬂowing out of the source,
and the total amount of data ﬂowing into the destination.
For this, we calculate IN and OU T score vectors for each
entity in the dependency graph G. The IN and OU T scores
represent the importance of an entity as an information receiver
and sender respectively. In other words, IN and OU T scores
measure the degree of fanout in either direction for each entity
in the graph. For example, in the motivating attack (§II), the
IExplorer.exe process entity has both high IN and OU T scores,
as it frequently reads and writes to socket connections. On the
other hand, dropper.exe process entity has a high OU T score as
it frequently writes to socket connections but has low IN since
it does not read anything. We provide a detailed algorithm to
calculate these vectors in §VI-C.
6
Algorithm 1: GETPATHANOMALYSCORE
Inputs : Alert Event Eα;
Max Path Length Threshold τl
Output: List L of dependency path and score pairs.
1 Gα = GETDEPENDENCYGRAPH(Eα)
2 Vsrc ← GETSRCVERTEX(Eα)
3 Vdst ← GETDSTVERTEX(Eα)
4 Lb ← DFSTRAVERSALBACKWARD(Gα,Vsrc,τl)
5 Lf ← DFSTRAVERSALFORWARD(Gα,Vdst,τl)
/* Combine Backward and Forward Dependency Paths
6 Lp ← COMBINEPATHS(Lb,Lf )
/* Generate a transition matrix of an input graph using Eq. 1
7 M = GETTRANSITIONMATRIX(G)
8 foreach P ∈ Lp do
9
/* Calculate Path anomaly score using Eq. 2 and Eq. 3
AS ← CALCULATESCORE(P ,M)
/* Append path and its anomaly score to a list
L ← L ∪ 
10
11 end
12 return L
*/
*/
*/
*/
Once the transition probability matrix and IN and OU T
scores calculation are done, we calculate the regularity (nor-
mal) score of each dependency path. Given a dependency path
P = (ε1, ..., εl) of length l, the regularity score RS(P ) is
calculated as follows:
l(cid:89)
i=1
RS(P ) =
IN (SRCi) × M (εi) × OU T (DSTi)
(2)
where IN and OU T are the sender and receiver vectors, and
M is calculated by Equation 1. In Equation 2, IN (SRCi) ×
M (εi) × OU T (DSTi) measures the regularity of the event
ε that SRCi sends information to DSTi entities. After cal-
culating regularity score, we calculate the anomaly score as
follows:
AS(P ) = 1 − RS(P )
(3)
According to this equation, if any path that involves at least
one abnormal event, it will be assigned a high anomaly score as
it will be propagated to the ﬁnal score. In Algorithm 1, func-
tion CALCULATESCORE generates anomaly scores of given
dependency paths.
C. IN and OUT Scores Calculation
As mentioned above, Equation 2 requires the IN and OU T
score vectors for each entity in the dependency graph. We
populate IN and OU T score for each entity, based on its type
as follows:
Process Entity Type. To assign IN and OU T score to a
candidate process entity we check the historical behaviour of
candidate process entity globally in the enterprise and calculate
its scores as follows: Let v be the candidate process entity
in the dependency graph and m is a ﬁxed time window
length. The period from the time v is added to the dependency
graph (T0) to the current timestamp (Tn) is partitioned into a
sequence of time windows T = {T0, T1, ..., Tn}, where Ti is
a time window of length m. If there is no new edge from/to
vertex v in window Ti, then Ti is deﬁned as a stable window.
The vertex v’s IN and OU T score is calculated using Equation 4
f rom| is the count of
and Equation 5 respectively where |T (cid:48)
7
stable windows in which no edge connects from v, |T (cid:48)
to| is the
count of stable windows in which no edge connects to v, and
|T| is the total number of windows.
IN (v) =
|T (cid:48)
to|
|T|
(4)
OU T (v) =
|T (cid:48)
f rom|
|T|
(5)
To understand the intuition of these equations, consider an
example where a process vertex constantly have new edges
going out from it while there is no edge going in. In such
a case, the vertex has very low IN score, its OU T score will
be high. If there is suddenly an edge going in the vertex, it
is abnormal. The range of process entity IN and OU T score
∈ [0, 1], when a node has no stable window, i.e., the node
always has new edges in every window, its score is 0. If all the
windows are stable, the node stability is 1. Through repeated
experimentation, we typically set the window length 24 hours.
Hence the stability of a node is determined by the days that
the node has no new edges and the total number of days.
Data Entities. Data entity type consists of ﬁle and socket
entities. Data entities cannot be assigned global scores like
Process entity as mentioned-above because the behaviour of
data entity various from host to host in the enterprise. We
deﬁne local values in terms of low and high IN and OU T
scores for data entities. To assign IN and OU T scores for ﬁle
entity vertices, we divide the ﬁle entities into three types and
based on the type, we assign IN and OU T scores. 1) Temporary
Files: All the ﬁle entities which are only written and never
read in the dependency graph are considered as temporary ﬁles
as suggested by [47]. We give temporary ﬁles as high IN and
OU T scores since they usually do not contribute much in attack
anomaly score. 2) Executable Files: Files which are executable
(execute bit is 1) are given low IN and OU T since they are
usually used in the attack vector thus important sender and
receiver of information. 3) Known malicious extensions: We
use an online database [9] of known malicious ﬁle extensions
to assign low IN and OU T to such ﬁles since they are highly
anomalous. All the other ﬁles are given IN and OU T score
of 0.5. To assign IN and OU T scores for socket connection
entities, we use domain-knowledge. We use an online database
of malicious IP [10] address to assign low IN and OU T score.
D. Anomaly Score Normalization
For each alert causal path P , we calculate the anomaly
score using Eq. 2 and Eq. 3. However, it is easy to see that
longer paths would tend to have higher anomaly scores than
the shorter paths. To eliminate the scoring bias from the path
length, we normalize the anomaly scores so that the scores of
paths of different lengths have the same distribution.
We use a sampling-based approach to ﬁnd the decay factor
which will progressively decrease the score in Equation 2.
To calculate decay factor α, we ﬁrst take a large sample
of false alert events. Then, for each alert we generate the
dependency paths of different max lengths τl and generate
anomaly score for those paths. Then we generate a map M
which contains average anomaly scores for each path length.
Using this map, we calculate the ratio at which the score
increases with increasing length from the baseline length k
and use this ratio decay factor α. The complete algorithm to
calculate the decay factor α using the sampling method is
Algorithm 2: CALCULATEDECAYFACTOR
Algorithm 3: DEPENDENCY PATHS MERGE
Inputs : List of false alert causal events LE ;
Baseline length k;
Max. Path Length Threshold τl
Output: Decay Factor α
3
4
1 M = KeyValue Store of Path Length and Avg. Anomaly Score
2 foreach E ∈ LE do
for i ← 0 to τl do
max path length
/* Use Algorithm 1 to generate anomaly score for given event and
*/
L = GETPATHANOMALYSCORE(E,i)
/* Takes the average of anomaly scores for each path length and
M [i] ← AVERAGESCORE(L,M [i])
store in map
*/
end
5
6
7 end
8 α ← GETDECAYFROMBASELINE(M ,k)
9 return α
/* Returns the ratio at which score increases with length from the baseline */
l(cid:89)
shown in Algorithm 2. Once the decay factor is calculated,
the regularity score Equation 2 becomes as follows:
RS(P ) =
IN (SRCi) × M (εi) × OU T (DSTi) × α
(6)
i=1
This equation returns a normalized anomaly score for a
given dependency path P of length l.
E. Paths Merge
As attacks are usually performed in multiple steps, it is
not possible to capture the complete causality of a true alert
event by returning the single dependency path that is most
anomalous. Likewise, returning the full dependency graph
(comprised of all paths) to cyber analysts is inaccurate because
it contains both anomalous paths as well as benign paths that
are unrelated to the true alert. To strike a balance between
these two extremes, we introduce a merging step that attempts
to build an accurate true alert dependency graph by including
only dependency paths with high anomaly scores.
A na¨ıve approach to this problem would be to return the
top k paths when ranked by anomaly score; this solution is not
acceptable because not all attacks contain the same number of
steps, which could lead to the admission of benign paths or
the exclusion of truly anomalous paths. Instead, we present
an algorithm that uses a best effort approach to merge paths
together in order to create an optimally anomalous subgraph.
Through experimentation with NODOZE, we found that there
is an orders of magnitude difference between the scores of
benign paths and truly anomalous paths. Because of this, we
are able to introduce a merge threshold τm which quantiﬁes
the difference between the two. Algorithm 3 shows how to
merge dependency paths based on the merge threshold τm.
At a high level, this algorithm keeps merging high anomaly
score paths until the difference is greater than τm. In order
to calculate an acceptable value for τm, we use a training
phase to calculate the average difference between anomalous
and benign paths. While the availability of labeled training
data that features true attacks may seem prohibitive, recall that
NODOZE is designed for enterprise environments that already
employ trained cyber analysts; thus, the availability of training
8
Inputs : LP S List of dependency path P and score S pairs;
Merge Threshold τm
Output: Alert Dependency Graph G
/* Sort list by anomaly scores
1 LP S = SORTBYSCORE(LP S)
2 for i ← 0 to SIZEOF(LP S ) − 1 do
/* Path and its anomaly score pair
 ← LP S [i]
 ← LP S [i + 1]
if S1 − S2 < τm then
G ← G ∪ P1
G ← G ∪ P2
3
4
5
6
7
8
9 end
10 return G
end
*/
*/
data is a natural artifact of their work. We also note that, based
on our experience, the τm threshold only needs to be calculated
once per deployment.
F. Decision
The main goal of NODOZE is to rank all the alerts in
a given timeline. However, we can also calculate a decision
or a cut-off threshold τd, which can be used to decide if a
candidate threat alert is a true attack or a false alarm with
high conﬁdence. If anomaly score of a threat alert is greater
than the decision threshold than it is categorized as a true
alert otherwise a false alarm. To this end, calculating τd require
training dataset with true attacks and false alarms and its value
depends on the current enterprise conﬁguration such as the
number of hosts and system monitoring events.
G. Time Complexity of our Algorithm
The dependency paths search for an alert event is done
with D depth-bounded Depth-ﬁrst search traversal. We execute
DFS twice for each alert, once forward and once backward to
generate both forward tracing and backward tracing depen-
dency paths. So time complexity is O(|bD|) where b is the
branching factor of the input dependency graph. Equation 2
runs for each path so time complexity is O(|P D|) where P is
the total number of dependency paths for the alert event.
VII.
IMPLEMENTATION
We implement NODOZE for an enterprise environment.
We collected system event logs in PostgreSQL database using
Windows ETW [1] and Linux Auditd [11]. Our implementation
consists of 3 major modules: a) Event Frequency Database
Generator, b) Alert Triage & Graph Generator, and c) Visual-
ization Module.
A. Event Frequency Database
In order to calculate the transition probability matrix M,
IN score vector, and OU T score vector for Equation 2, we
implemented Event Frequency Database in 4K lines of Java