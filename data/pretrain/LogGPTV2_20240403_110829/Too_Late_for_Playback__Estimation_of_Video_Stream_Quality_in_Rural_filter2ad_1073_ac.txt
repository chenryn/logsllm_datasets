We now present the learning models we used for the learning problem, our model
training approach, and the method for addressing the inherent class-imbalance.
Learning Models: We trained a wide range of oﬀ-the-shelf classiﬁers for this
learning problem in order to identify the classiﬁer that strikes the best bal-
ance between performance (precision, recall, etc.) and generalizability. First, we
trained simpler classiﬁers, such as gradient boosting [29], bagging [13], random
forest [14], ARIMA [12], AdaBoost [30], etc. These classiﬁers oﬀer better general-
izability at the cost of performance. We also trained neural-network (NN)-based
classiﬁers, such as a convolutional neural network (CNN) [41] and recurrent neu-
ral network (RNN) [37] (in particular, LSTMs [35] and GRUs [23]), that oﬀer
higher accuracy but require considerable training data to avoid over-ﬁtting.
Setup: We ran all the classiﬁers on a local machine that runs Ubuntu 18.04, pow-
ered by a 4-core i7-7700 CPU (3.60 GHz) with 64,GB RAM and 8 GB NVIDIA
RTX 2080 GPU. We implemented the simpler classiﬁers using the scikit-learn
0.21 [56] library of Python, and NN-based models using Keras with Tensorﬂow
backend [24]. We used four fully-connected layers for the NN-based classiﬁers.
For RNN-LSTM-Focal (see Table 4), the network utilized 64, 32, and then 16
hidden neurons, in addition to a ﬁnal output layer with hyperbolic tangent activa-
tion function. We used Grid Search [25] to determine the ideal hyper-parameter
conﬁguration for each neural network. To avoid over-ﬁtting, we use a dropout
of 0.4 while training with the Adam gradient descent optimizer [39]. We ran the
RNN-LSTM model for 120 iterations with a batch size of 64.
Class-Imbalance Problem: As rebuﬀering and changes in the resolution are
rare, most of our data points are normal, i.e., they do not have any rebuﬀering
or resolution switching events. As a result, our dataset has the class-imbalance
problem, typical for most anomaly detection problems. To address this issue, we
applied the sampling technique SMOTE [19] to balance the classes artiﬁcially.
However, such an approach reduces the number of data points that we can use
for training the classiﬁer, which in turn aﬀects the accuracy. With SMOTE, we
observed no improvements in accuracy with simpler learning models (e.g., SVM,
random forest, etc.), and lower accuracy for NN-based classiﬁers. Therefore, for
the NN-based classiﬁers, we adapted a new technique that has proven to increase
classiﬁcation accuracy in datasets that suﬀer from the class-imbalance issue for
the object detection problem [42]. This technique addresses the class-imbalance
problem by reshaping the standard cross entropy loss in such a way that it lowers
the weights for the majority class [42]. It also introduces the concept of focal loss
150
V. Adarsh et al.
that prevents the majority class from overwhelming the classiﬁer during training.
The focal loss can be represented as:
F L(pj) = α(1 − pj)γlog(pj)
(1)
Here, F L is the focal loss function, and pj is the softmax probability of the jth
class for a particular observation. α and γ are two regularizing parameters. This
loss function adds more importance when the network predicts a minority sample
as opposed to the overly represented sample—making it ideal for performing
classiﬁcation on an imbalanced dataset.
3.3 Results
We now present the performance of the diﬀerent classiﬁers we used for this learn-
ing problem. For those that performed well, we also quantify their performance
across diﬀerent locations and video types. Finally, we quantify the contribution
of an LTE-speciﬁc QoS metric, RSRP, in improving the accuracy of our learning
models.
Table 4. Performance metrics of the classiﬁcation models.
Models
Boosting
Bagging
Random Forest
ARIMA
Decision Trees
Extra Randomized Tree
AdaBoost
Support Vector Machine
K-nearest neighbors
CNN
CNN - Focal
RNN - LSTM
RNN - LSTM - Focal
RNN - GRU
RNN - GRU - Focal
Rebuﬀering Events
Accuracy
Precision
Recall
Resolution Switching
Accuracy
Precision
Recall
0.87
0.80
0.85
0.81
0.80
0.77
0.62
0.72
0.60
0.72
0.84
0.82
0.89
0.82
0.86
0.88
0.82
0.87
0.81
0.80
0.78
0.60
0.72
0.56
0.73
0.85
0.83
0.89
0.82
0.86
0.88
0.82
0.86
0.81
0.98
0.77
0.63
0.73
0.62
0.73
0.84
0.83
0.89
0.84
0.85
0.84
0.71
0.79
0.77
0.75
0.72
0.51
0.70
0.58
0.68
0.81
0.80
0.86
0.80
0.83
0.85
0.73
0.80
0.78
0.75
0.73
0.55
0.71
0.57
0.69
0.81
0.79
0.86
0.82
0.84
0.84
0.72
0.80
0.78
0.75
0.72
0.53
0.70
0.49
0.69
0.81
0.80
0.87
0.82
0.84
Performance: We analyze the performance of learning models in terms of accu-
racy, precision, recall, and training time. Table 4 summarizes the performance of
all classiﬁers we explored. We observe that the accuracy of the rebuﬀering-event
classiﬁer is better than the resolution-switching one, as depicted in Fig. 2. This
diﬀerence is attributable to the smaller number of anomalous data points (resolu-
tion switches) in the data (see Table 3). In terms of accuracy, RNN-LSTM-Focal
performs best. This is expected as this model makes the best use of the sequence
of throughput and RSRP values and is best suited to handle the class imbal-
ance problem. On the other hand, though RNN-LSTM-Focal has the highest
accuracy, the accuracy gains are marginal when compared to simpler learning
models, especially Boosting. Given these marginal gains and the complexity of
training NN-based classiﬁers (5 vs. 214 s), we use the Boosting classiﬁer to char-
acterize the performance across diﬀerent network and video types.
Too Late for Playback
151
a. Rebuﬀering events
b. Resolution switching
Fig. 2. Performance of Boosting across diﬀerent locations.
Generalizability: We now quantify the generalizability of the Boosting classi-
ﬁer. First, we show how its performance varies across diﬀerent network types.
Figure 2 depicts the performance of inferring video rebuﬀering using Boosting
at each location. We observe that the performance diﬀerences across diﬀerent
network types are marginal (<2% deviation between categories). We saw similar
trends for the Boosting-based classiﬁer when inferring resolution switching.
Our initial measurements only collected the QoE metrics for the Looney
Tunes video. To verify that our results generalize for other video types, we col-
lected the QoS/QoE data for 108 additional video streaming sessions (a total
of 48,825 new data points) at our research facility (baseline-urban). We selected
18 diﬀerent videos from seven genres: action (trailers/movie clips), music videos,
sports, online learning content, news, documentary, and animation (including the
original Looney Tunes video) [16]. We selected top trending videos for each genre.
Given that the videos were of varying duration, we capped each measurement to
a maximum of ten minutes. We streamed each video over three diﬀerent telecom
providers (AT&T, T-Mobile, and Verizon); we were not able to obtain Sprint
measurements because of closures of Sprint retail outlets due to the COVID-19
pandemic. Figure 3 shows the performance of Boosting for both video rebuﬀering
and resolution switching. We observe marginal variations (<1.5% and <3% devi-
ation for rebuﬀering and resolution switching, respectively) in accuracy across
diﬀerent video genres, implying that our learning model generalizes reasonably
well to diﬀerent video types. Note that we do not claim that these results gen-
eralize for other video players (e.g., Hulu, Netﬂix), client platforms or devices;
we plan to quantify the performance of our learning models for other platforms,
devices and non-YouTube videos in the future. Finally, we do not claim to have
developed models that generalize across other locations or network conditions –
rather we use this study to demonstrate the feasibility of inferring video QoE at
scale within a limited, but diverse, dataset.
152
V. Adarsh et al.
a. Rebuﬀering events
b. Resolution switching
Fig. 3. Performance of Boosting across diﬀerent video genres.
Fig. 4. Inferring video rebuﬀering using Boosting with and without RSRP as an input
feature.
Ablation Study: To better understand the impact of an LTE-speciﬁc metric
(i.e., RSRP) in inferring QoE metrics, we performed an ablation study. Figure 4
compares the accuracy of the Boosting classiﬁer in inferring rebuﬀer events with
and without the RSRP values. We observe that the average increase in accuracy,
with RSRP as an input, is 9.28%, while the maximum gain is 18.61%. This result
could be attributed to the exposition of the relationship, by the non-linear mod-
els, between RSRP and throughput to identify the target metrics at any given
location successfully. This study highlights the importance of LTE-speciﬁc RSRP
measurements in accurate prediction of rebuﬀering and resolution switching.
4 Related Work
Prior work most similar to ours, which focuses on quantifying the user experience,
typically infers the QoE of video streaming from QoS of ﬁxed broadband net-
works [22,31,38]. In contrast, our work focuses on mobile broadband, which often
exhibits a wide variation in performance over time and space. Some past work
on mobile broadband, such as [3,11,20,54], has examined metrics solely from