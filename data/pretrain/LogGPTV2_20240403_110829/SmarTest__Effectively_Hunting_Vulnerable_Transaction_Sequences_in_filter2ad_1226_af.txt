n/a
19
3
n/a
Line
#G
51
n/a
n/a
n/a
19
3
#V
51
n/a
n/a
n/a
n/a
n/a
#Fail
#TO
0
1
7
n/a
0
46
0
-
0
n/a
0
4
Analysis Cost. The runtime costs of each tool for ob-
taining the results on CVE dataset (Table 1 and 2) are:
SMARTEST (6h 7m), MYTHRIL (6h 5m), and MANTI-
CORE (4h 35m). The costs of each tool for obtaining the
results on the second dataset (Table 3) are: SMARTEST (2h
4m), ILF (22h 49m), MAIAN (2h 28m), TEETHER (2h 20m),
MYTHRIL (2h 5m), and MANTICORE (2h 21m).
Learning Cost. On average, the training time on CVE dataset
can be computed as about 4.5 hours; the total time for running
4 folds with basic symbolic execution (Section 3.1) took about
6 hours (6h 8m) and 3 folds are used as training data for
obtaining n-gram counts (i.e., 6 hours * 3/4). Similarly, the
average learning time on Leaking-Suicidal dataset can be
calculated as 1.5 hours, where the total running time on all
four folds with basic symbolic execution is about 2 hours (2h
4m). Note that, given n-gram counts, computing vulnerable
probabilities (Section 3.2) is done on demand during symbolic
execution and thus requires no additional training time.
5.2 Effectiveness of Using Language Model
Figure 5 shows the performance of SMARTEST with and with-
out language models. In Figure 5(a) (resp., (b)), the meaning
of a point at (x,y) is as follows: from the 443 (resp., 104)
contracts, y vulnerable transaction sequences were found in
total when each contract was analyzed with the testing budget
of x seconds. The two ﬁgures show that the learned language
models greatly help to ﬁnd more vulnerable transaction se-
quences in a short time. For example, on CVE dataset, while
the basic symbolic execution took 1,817 seconds to ﬁnd 2,178
vulnerable transaction sequences, our language model-guided
symbolic execution took 68 seconds to ﬁnd the same number
of vulnerable transaction sequences.
Discussion. SMARTEST can be effective when it is trained
and tested on contracts with vulnerabilities whose patterns
of vulnerable transaction sequences are similar. However,
SMARTEST may not be effective when trained and tested on
(a) CVE dataset
(b) Leaking-Suicidal dataset
Figure 5: SMARTEST with vs. without language model.
vulnerabilities whose typical patterns of vulnerable sequences
are substantially different. We discuss our limitation with fol-
lowing experiments: training on CVE dataset for four types
of vulnerabilities in Table 1 and testing on Leaking–Suicidal
dataset for two types of vulnerabilities in Table 3, and vice
versa. For each experiment, we observed a language model
trained on one dataset degrades the performance of our basic
symbolic execution when tested on the other dataset: 2,084
vulnerable transaction sequences (vs. 2,178) for the ﬁrst ex-
periment (trained on Leaking-Suicidal dataset and tested on
CVE dataset), 149 sequences (vs. 155) for the second experi-
ment (trained on CVE dataset and tested on Leaking-Suicidal
dataset). One possible reason for these results may be that,
typical patterns of vulnerable transaction sequences that ap-
pear in each dataset are rather different (e.g., Section 5.3). We
believe generalizing to vulnerabilities with different sequence
patterns is challenging and further research is needed for it.
5.3 Learned Insight
We present case studies that can help to understand how our
learned language models improve the speed of symbolic exe-
cution. We have inspected learned conditional probabilities
that are commonly high ranked in each model, where we con-
sidered top-6 types in each training phase (i.e., k = 6, see
Section 3.2.1). For CVE dataset, we observed that prioritizing
transactions without proper arithmetic guard statements is
USENIX Association
30th USENIX Security Symposium    1373
02505007501000125015001750time budget (s) per contract050010001500200025003000# of found vulnerable sequencesbaseline3-gram02505007501000125015001750time budget (s) per contract020406080100120140160# of found vulnerable sequencesbaseline3-gramimportant for quickly ﬁnding arithmetic vulnerabilities. For
example, consider the conditional probability below:
P((cid:104)110000001000000(cid:105) | (cid:104)s(cid:105)·(cid:104)i(cid:105))
where mapping(address => uint) and uint are the top
two variable types. We note that one possible implementation
corresponding to (cid:104)110000001000000(cid:105) is mintToken func-
tion (e.g., Figure 3), where 1st and 2nd elements are set to
1 (i.e., variables with the top two types may be deﬁned) and
7th and 8th elements are set to 0 (i.e., corresponding guard
statements do not exist). For Leaking-Suicidal dataset, we
observed that ﬁnding transactions involved with unprotected
ownership is critical for ﬁnding those two types of vulnerabil-
ities. One example is the following conditional probability:
P((cid:104)000000100000010(cid:105) | (cid:104)i(cid:105)·(cid:104)110000000000000(cid:105))
is
the
address
top ranked variable
where
type.
(cid:104)110000000000000(cid:105) may indicate a transaction that
enables to change contract’s owners without checking access
privileges (the 1st and 7th elements are set to 1 and 0) and
(cid:104)000000100000010(cid:105) may be a transaction that includes a
safety-critical instruction that sends Ethers (the 14th element
is set to 1), which makes contracts leak Ethers to anyone.
5.4 Finding Zero-day Bugs in the Wild
We conducted an experiment to evaluate SMARTEST for ﬁnd-
ing unknown bugs from smart contracts in the wild. In Novem-
ber 2019, we collected 2,743 smart contracts with an open-
source license from Etherscan6 and ran SMARTEST (trained
on CVE dataset) on the contracts with timeout 10 minutes for
each contract. To ease our manual inspection on found bugs,
we ran SMARTEST with an option to detect ERC20 standard
violations only. We then manually inspected 142 automati-
cally validated vulnerable transaction sequences (from 89 con-
tracts) to judge the signiﬁcance of found bugs. Below, we re-
port two most signiﬁcant bug patterns that SMARTEST found
from 7 contracts, excluding benign and uncertain cases. We do
not provide concrete addresses of vulnerable smart contracts
to prevent abuse.
Pattern 1 (Mistakenly Named Constructor). Consider the
code snippet below:
contract AToken {
/* Constructor function */
function BToken ( ) public {
balance [msg. sender ] = 10000000000;
totalSupply = 10000000000; } ... }
where we deliberately modiﬁed the names of the contract
and the function but included a part of the original com-
ment (“Constructor function”). In old versions of Solidity
(≤ v.0.4.26), a function whose name is equal to the name of
the contract was considered a constructor. Based on the com-
ment in the code, we conjecture that the developer mistakenly
named the constructor function. Due to this ﬂaw, anyone can
6https://etherscan.io/
have 10000000000 tokens for free by invoking the BToken
function. We found this type of vulnerabilities in 4 contracts
with vulnerable transaction sequences of depths 3–4 generated
by SMARTEST, by detecting violations of ERC20 standard
invariants (Appendix C).
Pattern 2 (Unrestricted Token Transfer). Consider the
transferFrom implementation below:
function transferFrom (address from , address to ,
uint value ) public returns (bool) {
require ( balance [ from ] >= value );
require( balance [ to ] + value >= balance [ to ]) ;
balance [ from ] -= value ;
balance [ to ] += value ;
return true; }
According to the description of the ERC20 standard inter-
face [2], the transferFrom function should raise an excep-
tion if the original token holder (from) did not authorize a
transaction sender (msg.sender). However, the above imple-
mentation does not impose any restrictions on transaction
senders, i.e., there are no guard statements such as the one
at line 29 of Figure 2. As a result, anyone can send money
from one’s account (balance[from]) to another’s account
(balance[to]) without any restrictions, if there are some
balances in the from’s account. SMARTEST found these vul-
nerabilities with this pattern in 3 contracts by generating trans-
actions of depth 1, each of which violates the speciﬁcation of
standrad transferFrom (Appendix C).
Note that, once the vulnerabilities described above are ex-
ploited in smart contracts that high market values, it can lead
to considerable economic loss to existing token holders. For
example, if the vulnerabilities in Pattern 1 are exploited, hack-
ers can have large amounts for nothing. Moreover, due to
these unrestricted token supplies, the market prices of the
tokens may get lower, resulting in considerable economic loss
to existing token holders.
5.5 Discussion
Limitations and Scope. As discussed in Section 5.2, our
technique may not be effective when the training and test
datasets contain different types of vulnerabilities. Another
limitation is that our technique assumes a sufﬁcient amount
of vulnerable contracts for learning but such data may not be
always readily available for some types of vulnerabilities.
Below we describe limitations and scope of our experi-
ments in terms of covered vulnerabilities, and discuss po-
tential extensions related to them. While we showed the ef-
fectiveness of our technique on six types of vulnerabilities,
its effectiveness on vulnerabilities not covered in our exper-
iments remains to be seen. In particular, in our evaluation,
we did not consider vulnerabilities that require analysis of
the interaction of multiple contracts to demonstrate the ﬂaws
(e.g., reentrancy). To support those types of vulnerabilities,
we should be able to precisely handle external function calls
1374    30th USENIX Security Symposium
USENIX Association
(Section 4), possibly involving synthesis of unknown, inter-
acting contracts. Moreover, to apply our technique to those
types of vulnerabilities, we may need to extend our transac-
tion representation method for identifying and prioritizing
certain transactions that involve external function calls and
are likely to reveal those types of vulnerabilities.
Exploitability of Vulnerabilities. While vulnerabilities
found by SMARTEST include exploitable ones (e.g.,
batchOverﬂow vulnerability in CVE-2018-10299) but they
would not be always immediately exploitable (e.g., CVE-
2018-13085 where overﬂows can happen by a misuse of a
contract owner rather than an arbitrary user). Nevertheless, we
believe that our technique for effectively ﬁnding vulnerabili-
ties (i.e., transaction sequences that violate safety conditions)
is useful, because violations of safety conditions would be
undesirable for safety-critical smart contracts. To precisely
ﬁnd immediately exploitable vulnerabilities, we need to for-
mally specify the notion of exploitability in terms of logical
formulas.
Threats to Validity. We describe potential sources of threats
to validity that may be introduced in our experiments. Firstly,
the benchmarks used in our experiments (443 contracts from
CVE reports and 104 leaking and suicidal contracts from [14]
and us) may not be representative and may be biased, al-
though we tried hard for objective evaluation (e.g., collecting
benchmarks from existing vulnerability databases, evaluat-
ing on trustful ground truths for vulnerabilities). Thus, when
evaluated with other dataset whose regularities for vulner-
able sequence patterns are rather different, results may be
different. Secondly, comparing the vulnerability-ﬁnding capa-
bilities among tools may be unfair in several aspects, despite
our signiﬁcant effort for a fair comparison (e.g., providing
tool-speciﬁc constraints, giving more time budgets to other
tools).
We describe concrete examples for the second point. As
one example, we empirically found that modeling of leaking
vulnerabilities differs in each tool. Speciﬁcally, we observed
that MAIAN, TEETHER, MANTICORE, and ILF aim to ﬁnd
transaction sequences that leak Ethers to arbitrary addresses,
assuming a test contract can have positive amounts of Ethers
somehow (e.g., receiving Ethers from other killed contracts).
Note that adopting this assumption may affect the effective-
ness and the ground truth for vulnerabilities. As for the effec-
tiveness aspect, following the assumption, a tool may be able
to detect leaking vulnerabilities more quickly, since the vul-
nerabilities may be detected with shorter transactions without
explicitly invoking payable functions. As for ground truth
aspect, consider a simple contract without payable functions:
contract NoPayable {
function sendEther () public {
msg. sender . transfer (address(this). balance ) ;}}
Observe that this contract has a leaking vulnerability with the
assumption but does not have the vulnerability without the as-
sumption (since the invariant address(this).balance ==
0 holds). MAIAN, TEETHER, MANTICORE, and ILF report
the vulnerability for the above contract which does not have
payable functions, while MYTHRIL does not. Regarding
ground truths and SMARTEST’s detection for leaking vulner-
abilities, we followed the four tools’ assumption, because we
believe reporting issues related to improper access-controls
would be beneﬁcial rather than not reporting them. As another
example for the second point, tools (TEETHER, ILF) that re-
quire additional inputs other than source code may yield better
results if more sophisticated inputs are provided from users.
6 Related Work
Analysis of Smart Contracts. There is a large body of works
on analysis of smart contracts, which we classify into four
groups: symbolic execution [3,17,25,28,30,31,37,38], static
analysis [9,10,16,39], formal veriﬁcation [6,18,24,32,34,36],
and fuzzing [19, 22, 27].
Symbolic execution, which SMARTEST builds upon, is per-
haps the most popular approach for ﬁnding bugs in smart
contracts. In particular, MYTHRIL [3], MANTICORE [30],
MAIAN [31], TEETHER [25], and ETHBMC [17] are closely
related to SMARTEST in that they also use symbolic execu-
tion and are able to generate vulnerable transaction sequences.
MYTHRIL and MANTICORE are well-known and actively-
maintained tools for ﬁnding a range of security vulnerabil-
ities. MAIAN and TEETHER are tools for ﬁnding relatively
high-level safety violations such as Ether-leaking and suicidal
vulnerabilities. ETHBMC [17] focuses on precise modeling
of EVM internals (e.g., cryptographic hash functions) for
accurate analysis. Our focus is on improving the speed of
symbolic execution with language models, where we believe
our core idea is applicable to existing tools as well (possibly
with some adjustments on transaction representation method
for EVM bytecode). Other symbolic execution tools such as
OYENTE [28], OSIRIS [37], and HONEYBADGER [38] do not
automatically provide trace information of found bugs.
Static analysis and program veriﬁcation have been also pop-
ular for smart contract security. Vandal [10], SECURIFY [39],
and Ethainter [9] use Datalog-based static analysis for ﬁnd-
ing security vulnerabilities such as reentrancy. Slither [16]
is a security checker that performs static analyses includ-
ing data dependency analysis. ZEUS [24] is a veriﬁer based
on abstract interpretation. SMTCHECKER [6] and SOLC-
VERIFY [18] are modular veriﬁcation tools where each func-
tion is analyzed in isolation. VERISMART [36] automatically
infers transaction invariants and uses them for precise veriﬁca-
tion. VERX [32] supports veriﬁcation of temporal properties.
eThor [34] is a provably sound veriﬁer for EVM bytecode.
However, unlike SMARTEST, these tools are inappropriate for
generating transaction sequences due to abstractions.
Fuzzing is a simple yet effective method for analyzing
smart contracts. ContractFuzzer [22] and REGUARD [27] are
USENIX Association
30th USENIX Security Symposium    1375
randomized fuzz testing tools for ﬁnding common vulnerabili-
ties such as reentrancy. ILF [19] is an imitation learning-based
fuzzer that aims to learn fuzzing policies from training se-
quences generated from symbolic execution.
Machine Learning for Symbolic Execution. There exist a
few prior works that use machine learning to improve sym-
bolic execution [11, 12, 26, 35, 40]. For example, MLB [26]
uses machine learning to accelerate constraint solving in
symbolic execution. To our knowledge, SMARTEST is the
ﬁrst that combines symbolic execution and language models
to more effectively ﬁnd vulnerabilities, although language
models have been used in other contexts (e.g., code comple-
tion [33]).
7 Conclusion
We presented a new technique for effectively ﬁnding vulner-
able transaction sequences in smart contracts. The key idea
is to learn a statistical model from known vulnerable transac-
tion sequences and use it to steer symbolic execution towards