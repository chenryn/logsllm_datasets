ters. The tools write a log of the ongoing computation
and output ﬁles with aggregate results for each time win-
dow. The keystore holds certiﬁcates of trusted input and
privacy peers to establish SSL connections. It is possible
to delay the start of a computation until a minimum num-
ber of input and privacy peers are online. This gives the
input peers the ability to deﬁne an acceptable level of pri-
vacy by only participating in the computation if a certain
number of other input/privacy peers also participate.
SEPIA is written in Java to provide platform indepen-
dence. The source code of the basic library and the four
ShamirSharing sharing = new ShamirSharing();
sharing.setFieldPrime(1401085391); // 31 bit
sharing.setNrOfPrivacyPeers(nrOfPrivacyPeers);
sharing.init();
// Secret1: only a single value
long[] secrets = new long[]{1234567};
long[][] shares = sharing.generateShares(secrets);
// Send shares to each privacy peer
for(int i=0; i<nrOfPrivacyPeers; i++) {
connection[i].sendMessage(shares[i]);
}
Figure 8: Example code for an input peer that shares a
secret, e.g., a millionaire sharing his amount of wealth.
CLI tools is available under the LGPL license on the
SEPIA project web page [39]. The web page also pro-
vides pre-conﬁgured examples for the CLI tools and a
user manual. The user manual describes usage and con-
ﬁguration of the CLI tools and includes a step-by-step
tutorial on how to use the library API to develop new
protocols.
In the library API, all operations and sub-
protocols implement a common interface IOperation
and are easily composable. The class Protocol-
Primitives allows to schedule operations and takes
care of performing them in parallel, keeping track of
operation states. A base class for privacy peers imple-
ments the doOperations() method, which runs all
the necessary computation rounds and synchronizes data
between privacy peers in each round. Fig. 8 shows exam-
ple code for input peers that want to privately compare
their secrets. First, each input peer generates shares of
its secret. The shares are then sent to the PPs, for which
example code is shown in Fig. 9. The PPs ﬁrst schedule
and execute lessThan comparisons for all combinations
of input secrets. In a second step, they run the recon-
struction operations and output the results.
Future Work Note that with Shamir shares, reconstruc-
tion of results is assured as long as t + 1 PPs are on-
line and responsive. This can be used directly to extend
SEPIA protocols with robustness against node failures.
Also, weak nodes slowing down the entire computation
could be excluded from the computation. We leave this
as a future extension.
The protocols support any number of input and pri-
vacy peers. Also, the item set sizes/events per input peer
are conﬁgurable and thus only limited by the available
CPU/bandwidth resources. However, running the net-
work statistics protocols (e.g., distinct count) on very
large distributions, such as the global IP address range,
requires to use sketches as proposed in [37] or binning
(e.g., use address preﬁxes instead of addresses). As an
example, we have recently used sketches in combination
with SEPIA to efﬁciently compute top-k reports for dis-
... // receive all the shares from input peers
ProtocolPrimitives primitives = new ProtocolPrimitives(fieldPrime, ...);
// Schedule comparisons of all the input peer’s secrets
int id1=1, id2=2, id3=3; // consecutive operation IDs
primitives.lessThan(id1, new long[]{shareOfSecret1, shareOfSecret2});
primitives.lessThan(id2, new long[]{shareOfSecret2, shareOfSecret3});
primitives.lessThan(id3, new long[]{shareOfSecret1, shareOfSecret3});
doOperations(); // Process operations and sychronize intermediate results
// Get shares of the comparison results
long shareOfLessThan12 = primitives.getResult(id1);
long shareOfLessThan23 = primitives.getResult(id2);
long shareOfLessThan13 = primitives.getResult(id3);
// Schedule and perform reconstruction of comparisons
primitives.reconstruct(id1, new long[]{shareOfLessThan12});
primitives.reconstruct(id2, new long[]{shareOfLessThan23});
primitives.reconstruct(id3, new long[]{shareOfLessThan13});
doOperations();
boolean secret1_lessThan_secret2 = (primitives.getResult(id1)==1);
boolean secret2_lessThan_secret3 = (primitives.getResult(id2)==1);
boolean secret1_lessThan_secret3 = (primitives.getResult(id3)==1);
Figure 9: Example code for a PP receiving shares of secrets from 3 input peers. It then compares the secrets privately,
e.g., to ﬁnd which of the millionaires is the richest.
tributed IP address distributions with up to 180,000 dis-
tinct addresses [10].
As part of future work, we also plan to investigate
the applicability of polynomial set representation to our
statistics protocols, to reduce the linear dependency on
the input set domain. Polynomial set representation, in-
troduced by Freedman et al. [18] and extended by Kiss-
ner et al. [22], represents set elements as roots of a poly-
nomial and enables set operations that scale only loga-
rithmically with input domain size. However, these solu-
tions use homomorphic public-key cryptosystems, which
come with signiﬁcant overhead for basic operations. Fur-
thermore, they do not trivially allow to separate roles
into input and privacy peers, as each input provider is re-
quired to perform certain non-delegable processing steps
on its own data.
7 Applications
We envision four distinct aggregation scenarios us-
ing SEPIA. The ﬁrst scenario is aggregating informa-
tion coming from multiple domains of one large (inter-
national) organization. This aggregation is presently not
always possible due to privacy concerns and heteroge-
neous jurisdiction. The second scenario is analyzing pri-
vate data owned by independent organizations with a mu-
tual beneﬁt in collaborating. Local ISPs, for example,
might collaborate to detect common attacks. A third sce-
nario provides access to researchers for evaluating and
validating trafﬁc analysis or event correlation prototypes
over multi-domain network data. For example, national
research, educational, and university networks could pro-
vide SEPIA input and/or privacy peers that allow analyz-
ing local data according to submitted MPC scripts. Fi-
nally, one last scenario is the privacy-preserving analy-
sis of end-user data, i.e., end-user workstations can use
SEPIA to collaboratively analyze and cross-correlate lo-
cal data.
7.1 Application Taxonomy
Based on these scenarios, we see three different
classes of possible SEPIA applications.
Network Security Over the last years, considerable re-
search efforts have focused on distributed data aggrega-
tion and correlation systems for the identiﬁcation and
mitigation of coordinated wide-scale attacks.
In par-
ticular, aggregation enables the (early) detection and
characterization of attacks spanning multiple domains
using data from IDSes, ﬁrewalls, and other possible
sources [2, 16, 26, 49]. Recent studies [21] show that
coordinated wide-scale attacks are prevalent: 20% of the
studied malicious addresses and 40% of the IDS alerts
accounted for coordinated wide-scale attacks. Further-
more, strongly correlated groups proﬁting most from col-
laboration have less than 10 members and are stable over
time, which is well-suited for SEPIA protocols.
In order to counter such attacks, Yegneswaran et
al. [49] presented DOMINO, a distributed IDS that en-
ables collaboration among nodes. They evaluated the
performance of DOMINO with a large set of IDS logs
from over 1600 providers. Their analysis demonstrates
the signiﬁcant beneﬁt that is obtained by correlating the
data from several distributed intrusion data sources. The
major issue faced by such correlation systems is the lack
of data privacy. In their work, Porras et al. survey exist-
ing defense mechanisms and propose several remaining
research challenges [32]. Speciﬁcally, they point out the
need for efﬁcient privacy-preserving data mining algo-
rithms that enable trafﬁc classiﬁcation, signature extrac-
tion, and propagation analysis.
Proﬁling and Performance Analysis A second cate-
gory of applications relates to trafﬁc proﬁling and perfor-
mance measurements. A global proﬁle of trafﬁc trends
helps organizations to cross-correlate local trafﬁc trends
and identify changes. In [38] the authors estimate that
50 of the top-degree ASes together cover approximately
90% of global AS-paths. Hence, if large ASes col-
laborate, the computation of global Internet statistics is
within reach. One possible statistic is the total trafﬁc vol-
ume across a large number of networks. This statistic, for
example, could have helped [37] in the dot-com bubble
in the late nineties, since the trafﬁc growth rate was over-
estimated by a factor of 10, easing the ﬂow of venture
capital to Internet start-ups.
In addition, performance-
related applications can beneﬁt from an “on average”
view across multiple domains. Data from multiple do-
mains can also help to locate a remote outage with higher
conﬁdence, and to trigger proper detour mechanisms. A
number of additional MPC applications related to perfor-
mance monitoring are discussed in [36].
Research Validation Many studies are obliged to avoid
rigorous validation or have to re-use a small number of
old trafﬁc traces [13, 43]. This situation clearly under-
mines the reliability of the derived results. In this con-
text, SEPIA can be used to establish a privacy-preserving
infrastructure for research validation purposes. For ex-
ample, researchers could provide MPC scripts to SEPIA
nodes running at universities and research institutes.
7.2 Case Study: The Skype Outage
The Skype outage in August 2007 started from a
Windows update triggering a large number of system
restarts. In response, Skype nodes scanned cached host-
lists to ﬁnd supernodes causing a huge distributed scan-
ning event lasting two days [35]. We used NetFlow traces
of the actual up- and downstream trafﬁc of the 17 biggest
customers of the SWITCH network. The traces span 11
days from the 11th to 22nd and include the Skype outage
(on the 16th/17th) along with other smaller anomalies.
We ran SEPIA’s total count, distinct count, and entropy
protocols on these traces and investigated how the orga-
nizations can beneﬁt by correlating their local view with
the aggregate view.
We ﬁrst computed per-organization and aggregate
timeseries of the UDP ﬂow count metric and applied a
simple detector to identify anomalies. For each time-
7e+06
4e+06
Org1
1e+06
Org2
4e+06
1e+06
4e+06
1e+06
1e+06
1e+06
1e+07
Org3
Org4
Org5
Org6
ALL
08/11
21:00
08/13
09:00
08/14
21:00
08/16
09:00
08/17
21:00
08/19
09:00
08/20
21:00
08/22
09:00
Figure 10: Flow count in 5’ windows with anomalies
for the biggest organizations and aggregate view (ALL).
Each organization sees its local and the aggregate trafﬁc.
100%
100%
80%
80%
60%
60%
40%
40%
20%
20%
0%
Global only
Global only
Matching
Matching
Local only
Local only
i
i
s
s
w
w
o
o
d
d
n
n
w
w
s
s
u
u
o
o
a
a
m
m
o
o
n
n
A
A
l
l
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17
Organization
Figure 11: Correlation of local and global anomalies for
organizations ordered by size (1=biggest).
series, we used the ﬁrst 4 days to learn its mean µ and
standard deviation σ, deﬁned the normal region to be
within µ ± 3σ, and detected anomalous time intervals. In
Fig. 10 we illustrate the local timeseries for the six largest
organizations and the aggregate timeseries. We rank or-
ganizations based on their decreasing average number of
daily ﬂows and use their rank to identify them. In the
ﬁgure, we also mark the detected anomalous intervals.
Observe that in addition to the Skype outage, some orga-
nizations detect other smaller anomalies that took place
during the 11-day period.
Anomaly Correlation Using the aggregate view, an or-
ganization can ﬁnd if a local anomaly is the result of
a global event that may affect multiple organizations.
Knowing the global or local nature of an anomaly is im-
portant for steering further troubleshooting steps. There-
fore, we ﬁrst investigate how the local and global anoma-
lous intervals correlate. For each organization, we com-
pared the local and aggregate anomalous intervals and
measured the total time an anomaly was present: 1) only
in the local view, 2) only in the aggregate view, and 3)
both in the local and aggregate views, i.e., the matching
anomalous intervals. Fig. 11 illustrates the correspond-
ing time fractions. We observe a rather small fraction,
i.e., on average 14.1%, of local-only anomalies. Such
anomalies lead administrators to search for local targeted
attacks, misconﬁgured or compromised internal systems,
misbehaving users, etc. In addition, we observe an aver-
age of 20.3% matching anomalous windows. Knowing
an anomaly is both local and global steers an affected
organization to search for possible problems in popular
services, in widely-used software, like Skype in this case,
or in the upstream providers. A large fraction (65.6%) of
anomalous windows is only visible in the global view.
In addition, we observe signiﬁcant variability in the pat-
terns of different organizations. In general, larger organi-
zations tend to have a larger fraction of matching anoma-
lies, as they contribute more to the aggregate view. While
some organizations are highly correlated with the global
view, e.g., organization 3 that notably contributes only
7.4% of the total trafﬁc; other organizations are barely
correlated, e.g., organizations 9 and 12; and organization
2 has no local anomalies at all.
Anomaly Troubleshooting We deﬁne relative anomaly
size to be the ratio of the detection metric value during an
anomalous interval over the detection threshold. Organi-
zations 3 and 4 had relative anomaly sizes 11.7 and 18.8,
which is signiﬁcantly higher than the average of 2.6. Us-
ing the average statistic, organizations can compare the
relative impact of an attack. Organization 2, for instance,
had anomaly size 0 and concludes that there was a large