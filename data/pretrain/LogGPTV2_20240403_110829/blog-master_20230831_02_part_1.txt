## 沉浸式学习PostgreSQL|PolarDB 10: 社交、刑侦等业务, 关系图谱搜索  
### 作者  
digoal  
### 日期  
2023-08-31  
### 标签  
PostgreSQL , PolarDB , 数据库 , 教学  
----  
## 背景  
欢迎数据库应用开发者参与贡献场景, 在此[issue](https://github.com/digoal/blog/issues/121)回复即可, 共同建设《沉浸式数据库学习教学素材库》, 帮助开发者用好数据库, 提升开发者职业竞争力, 同时为企业降本提效.  
- 系列课程的核心目标是教大家怎么用好数据库, 而不是怎么运维管理数据库、怎么开发数据库内核. 所以面向的对象是数据库的用户、应用开发者、应用架构师、数据库厂商的产品经理、售前售后专家等角色.  
本文的实验可以使用永久免费的阿里云[云起实验室](https://developer.aliyun.com/adc/scenario/exp/f55dbfac77c0467a9d3cd95ff6697a31)来完成.  
如果你本地有docker环境也可以把镜像拉到本地来做实验:  
x86_64机器使用以下docker image:  
- [《amd64 image》](../202307/20230710_03.md)  
ARM机器使用以下docker image:  
- [《arm64 image》](../202308/20230814_02.md)  
## 业务场景1 介绍: 社交、刑侦等业务, 关系图谱搜索 - 营销、分销、流量变现、分佣、引爆流行、裂变式传播、家谱、选课、社交、人才库、刑侦、农产品溯源、药品溯源  
图式搜索是PolarDB | PostgreSQL在（包括流计算、全文检索、图式搜索、K-V存储、图像搜索、指纹搜索、空间数据、时序数据、推荐等）诸多特性中的一个。  
采用CTE语法，可以很方便的实现图式搜索（N度搜索、最短路径、点、边属性等）。  
其中图式搜索中的：层级深度，是否循环，路径，都是可表述的。  
可以使用图式搜索(递归查询)的业务场景如下:  
- 营销、分销业务系统:  
    - 多层分佣, 递归关系  
    - 短视频工会, 联盟等分级体系.  
    - 喜马拉雅这类音频的工会、联盟等分级体系.  
    - 网约车运营公司、联盟等分级体系.  
- 流量变现系统  
    - 裂变传播, 按裂变递归分组统计分析裂变效果  
- 分佣例如类保险行业  
    - 多层分佣, 递归关系  
- 引爆流行系统  
    - 类似裂变传播, 按裂变层级设置积分规则, 刺激裂变  
- 家谱  
    - 树状关系数据  
- 选课  
    - 选了A课的同学还选了其他哪些课(并按热度TOP返回). 用于图谱推荐.  
- 社交关系  
    - like了A的人还like哪些人. 用于图谱推荐.  
    - 一度关系, N度关系  
    - 两个用户之间的最短关系路径  
- 人才库人脉系统  
    - 一度关系, N度关系  
    - 两个用户之间的最短关系路径  
- 刑侦系统  
    - 一度关系, N度关系  
    - 两个相关人之间的最短关系路径  
- 金融风控  
    - 一度关系, N度关系  
- 农产品溯源  
    - 递归追溯源头  
- 药品溯源  
    - 递归追溯源头  
### 实现和对照  
创建20万用户，每5万作为一个有牵连的群体，平均每个用户牵连500个用户，形成1亿的大规模关系网。  
在此基础上，演示如下业务需求:  
- 1、如何实现N度搜索，边的属性查看，以及最短路径搜索等需求。  
- 2、如何去除循环点，如何控制深度，如何展示路径等。  
- 3、如何生成绘图数据。  
1、建表，表结构如下，可以描述点、边。  
```  
drop table if exists a;  
-- 为了加快数据生成速度, 使用unlogged table.  
create unlogged table a(  
  c1 int,                -- 点1  
  c2 int,                -- 点2  
  prop jsonb,            -- 点1,2对应的边的属性，使用JSON存储，包括权重，关系等等。  
  primary key (c1,c2)    -- 主键  
);  
-- 为了加快数据生成速度, 关闭表的autovacuum, 全部写入完成再执行 vacuum analyze a;  
alter table a set (autovacuum_enabled =off);  
alter table a set (toast.autovacuum_enabled =off);  
-- 如果不需要查权重, 可以不用加以上索引, c1是驱动列, c1的过滤查询会直接走PK.  
create index on a(c1, COALESCE(((prop ->> 'weight'::text))::float8, 0));  
```  
2、生成测试数据：  
```  
-- 20万用户每5万隔离成一个有连接的群体, 总共分成4个独立bucket区间,  -- ((width_bucket(:id,1,200001,4)-1)*50000 + (random()*50000)::int)  
postgres=# select width_bucket(1,1,200001,4);  
 width_bucket  
--------------  
            1  
(1 row)  
postgres=# select width_bucket(50000,1,200001,4);  
 width_bucket  
--------------  
            1  
(1 row)  
postgres=# select width_bucket(50001,1,200001,4);  
 width_bucket  
--------------  
            2  
(1 row)  
postgres=# select width_bucket(200001,1,200001,4);  
 width_bucket  
--------------  
            5  
(1 row)  
postgres=# select width_bucket(200000,1,200001,4);  
 width_bucket  
--------------  
            4  
(1 row)  
这条sql 一次生成1个ID的500条关系.  -- generate_series(1,500)  
```  
```  
drop sequence seq;  
create sequence seq INCREMENT 1 START 1 ;  
vi t.sql  
select nextval('seq') as id \gset  
insert into a select :id, ((width_bucket(:id,1,200001,4)-1)*50000 + ceil(random()*50000)::int) from generate_series(1,500) on conflict (c1,c2) do nothing;  
```  
开始生成数据  
```  
10个并发, 每个执行20000次刚好覆盖20万用户.  
200000/10 = 20000  
pgbench -M prepared -n -r -P 5 -f ./t.sql -c 10 -j 10 -t 20000  
```  
生成结果  
```  
transaction type: ./t.sql  
scaling factor: 1  
query mode: prepared  
number of clients: 10  
number of threads: 10  
number of transactions per client: 20000  
number of transactions actually processed: 200000/200000  
latency average = 4.657 ms  
latency stddev = 1.981 ms  
initial connection time = 22.792 ms  
tps = 2142.670807 (without initial connection time)  
statement latencies in milliseconds:  
         0.323  select nextval('seq') as id  
         4.334  insert into a select :id, ((width_bucket(:id,1,200001,4)-1)*50000 + ceil(random()*50000)::int) from generate_series(1,500) on c  
postgres=# select count(*) from a;  
  count  
----------  
 99502172  
(1 row)  
postgres=# select c1,count(*) from a where c1 in (1,2,3,5000) group by c1;  
  c1  | count  
------+-------  
    1 |   498  
    2 |   497  
    3 |   499  
 5000 |   499  
(4 rows)  
postgres=# \dt+  
                                   List of relations  
 Schema | Name | Type  |  Owner   | Persistence | Access method |  Size   | Description  
--------+------+-------+----------+-------------+---------------+---------+-------------  
 public | a    | table | postgres | unlogged    | heap          | 3441 MB |  
(1 row)  
postgres=# \di+  
                                              List of relations  
 Schema |       Name        | Type  |  Owner   | Table | Persistence | Access method |  Size   | Description  
--------+-------------------+-------+----------+-------+-------------+---------------+---------+-------------  
 public | a_c1_coalesce_idx | index | postgres | a     | unlogged    | btree         | 3255 MB |  
 public | a_pkey            | index | postgres | a     | unlogged    | btree         | 3101 MB |  
(2 rows)  
```  
3、数据约`3.4GB`  
#### 传统方法 设计和实验  
传统数据库不支持递归查询语法, 以下请求无法实现.  
- 1、N度搜索，边的属性查看，以及最短路径搜索等需求。  
- 2、去除循环点，如何控制深度，如何展示路径等。  
- 3、生成绘图数据。  
#### PolarDB|PG新方法1 设计和实验  
演示如下业务需求:  
- 1、如何实现N度搜索，边的属性查看，以及最短路径搜索等需求。  
- 2、如何去除循环点，如何控制深度，如何展示路径等。  
- 3、如何生成绘图数据。  
##### 如何去除循环点、控制深度、展示路径  
当路径中重复出现某个点时，说明发生了关系的闭环, 如果不控制, 会导致递归查询死循环。 解决方法:  
- 1、每递归一次，深度加1。  
- 2、使用数组存储路径(点组成的数组)。单列数组，或多列（ROW数组），多列路径参考:  https://www.postgresql.org/docs/14/static/queries-with.html  
- 3、判断新出现的点是否存在于路径中.  如果存在, 说明有闭环存在, 不返回这条关系即可避免递归查询死循环.  
SQL如下：  
```  
\set v_root_id 2  
\set v_depth_limit 3  
\set v_row_limits 1000  
```  
```  