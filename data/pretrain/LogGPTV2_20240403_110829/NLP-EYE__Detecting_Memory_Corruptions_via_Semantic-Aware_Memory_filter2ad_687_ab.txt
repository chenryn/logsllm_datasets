Feature extraction component of NLP-EYE is built on top of
Clang Static Analyzer plugin [1], which provides an interface
for users to scan the declaration of each function. Given the
source code, NLP-EYE uses this plugin to extract all function
prototypes in the format of "Type@Name", including those
functions that are imported from other libraries. For comments
from source code, NLP-EYE uses regular expressions to
match comment symbols in C language.
3.1.2 Corpus Generation
After collecting those comments, NLP-EYE constructs an
adaptive corpus to perform adaptive lexical analysis. The
adaptive corpus includes three parts, that are Google Web
Trillion Word Corpus (GWTWC) [7], MSDN library API
names [21] [20], and comments from source code.
The GWTWC is a popular corpus created by Google, con-
taining more than one trillion words extracted from public
web pages. It can be applied to identify common words used
in natural languages. With the help of MSDN library API
names and comments, NLP-EYE can process programming
languages. The MSDN library provides normalized APIs
in Camel-Case format. Therefore, it is easy to divide each
function name into words/abbreviations through capital let-
ters. For example, function GetProcAddress can be divided
into ["Get","Proc","Address"]. While processing comments
from source code, NLP-EYE ﬁrst ﬁlters the symbol char-
acters (e.g., #%!), and then splits text by applying regular
expressions. Numbers and words appeared in GWTWC are
excluded.
Since abbreviations are commonly used in programming,
we set the appearance frequency of MSDN APIs to be higher
than the appearance frequency of comments, to provide them
a higher priority. We further assume that a word, who is a
Feature ExtractionSouce CodeCorpus GenerationFunction Prototype MatchingFunc1Func2Func3Ref1Ref2......Function Matching ListFunction LabelingSymbolic ExecutionFunction MisusesMisuse1Misuse2Misuse3...PreprocessingSemantics ExtractionVulnerability DetectionReport12Adaptive CorpusFunction PrototypesFunction Prototype Segmentation3334312          22nd International Symposium on Research in Attacks, Intrusions and DefensesUSENIX Associationsubstring of another word in MSDN API names, should have
a lower frequency than its parent word. For example, arm
in function mallocWithAlarm is a substring of Alarm, obvi-
ously Alarm is to be regarded as a whole; then we assign a
lower frequency for arm than for Alarm.
the taxonomy information. Words in the context corpus are
then represented by sets of vectors in Word2vec [34] model.
The cosine distance between two words positively related to
their semantic similarity, and a higher cosine distance repre-
sents a higher similarity between two words.
3.2 Semantics Extraction
NLP-EYE compares each function prototype with a set of
reference functions (e.g., malloc, free), and generates a func-
tion matching list. When a match was found in the function
matching list, we can infer the semantics from the function
prototype that it has the similar semantics with the reference
function.
NLP-EYE processes the data type and the function name,
arguments name separately to identify memory operation
functions in two steps. First, it divides the function name and
arguments name into a serial of words. Next, it performs NLP-
based comparison to select the potential function prototypes
with memory operation functionalities and conﬁrm the results
by applying type comparison.
3.2.1 Function Prototype Segmentation
To proceed function prototype segmentation, NLP-EYE ap-
plies Segaran et al.’s word segmentation algorithm [39] to
select the segmentation list with the highest list frequency.
Given a function prototype (FP), with n letters, NLP-EYE
ﬁrst creates 2n−1 possible combinations of these letters and
constructs 2n−1 segmentation lists. Each segmentation list
reserves the original order of these letters appeared in the FP.
NLP-EYE then computes the list frequency for each seg-
mentation list. It compares each word (wi) in a segmentation
list (SL) with words in the adaptive corpus, and returns the
following list frequency (LF):
|SL|
∏
i = 1
f req(wi)
LF =
where |SL| represents how many words are contained in
SL, and f req(wi) is the frequency of wi in the adaptive corpus.
Finally, NLP-EYE considers the segmentation list with the
highest list frequency as its segmentation result.
3.2.2 Function Prototype Matching
Due to the diversity of type declaration, NLP-EYE processes
names (i.e., function names and argument names) and types
(i.e., return types and argument types) separately. It performs
NLP-based comparison to identify those names that are re-
lated to memory operation functionalities. NLP-EYE then
applies type comparison to determine memory operation func-
tions and generates a function matching list.
NLP-based Comparison. Natural
language processing
(NLP) has been widely used to identify the connection be-
tween two words for semantic similarity matching. To mea-
sure the word similarity, a context corpus is required to extract
To extract the semantic meaning of an unknown name, we
generates a set of reference functions manually, which con-
tains standard memory operation functions provided by C/C++
and other known memory operation functions. Having those
reference functions, NLP-EYE compares the name of an un-
known function with the names of the reference functions and
calculate their similarity scores. If a similarity score is higher
than a threshold, NLP-EYE labels this unknown function as
similar to the reference function, that is, the corresponding
function is a potential memory operation function.
We address function names and argument names individ-
ually, since the comparison results of function names and
argument names may interfere each other while applying the
NLP-based comparison. Consider a function with only abbre-
viations for function names, but complete words for argument
names, its similarity score may not achieve the threshold.
Although the similarity score of the argument names is the
highest, the total similarity score will be impacted by the
low similarity of function names. Therefore, we set different
similarity threshold, fn-similarity and arg-similarity, as the
threshold of function names and argument names, respectively.
Only when fn-similarity and arg-similarity are both satisﬁed,
NLP-EYE will label the function. For function arguments,
NLP-EYE compares each argument of the reference func-
tion with every argument of the target function and generates
similarity score. Then NLP-EYE chooses the most similar
one as the corresponding arguments regardless of the number
of arguments.
Type Comparison. Given the potential memory operation
functions and their matched reference functions, NLP-EYE
compares their data types correspondingly. We use Clang
Static Analyzer to classify the data types into several cate-
gories to address the type diversity.
First, NLP-EYE normalizes data types. Some data types
are re-deﬁned as aliases by typedef. Thus, NLP-EYE uses
the original data types to replace those aliases. Second, we
deﬁne some coarse grained categories based on the basic data
types in C programming. NLP-EYE ﬁnally suggests the cor-
rect category for each data type. For example, unsigned int
and signed short are assigned to the category of Integer.
void * and char * belong to the category of pointer.
We compare the return type and corresponding argument
types of the potential memory operation function with data
types of the matched reference function. If their types are
assigned to the same category, the unknown function is a
memory operation function, and it is assumed to have the
same semantics as the corresponding reference function. Each
pair of a function prototype and its matched reference function
is inserted to the function matching list.
USENIX Association        22nd International Symposium on Research in Attacks, Intrusions and Defenses 3133.3 Vulnerability Detection
NLP-EYE creates a vulnerability report for each source code
by comparing the usages of memory operation functions with
the pre-deﬁned function misuses. NLP-EYE ﬁrst labels mem-
ory operation functions in the source code; then, NLP-EYE
checks whether there exists any function misuse.
3.3.1 Function Labeling
NLP-EYE takes the function matching list as an inputs to
identify memory operation functions. It compares functions
in the source code with the functions in the function matching
list. If a function appears in the function matching list, NLP-
EYE labels this function as a memory operation function.
3.3.2 Symbolic Execution
The code, that can be compiled independently, is regarded as
an unit. NLP-EYE ﬁrst generates the call graph for each unit
and then executes each unit from top to bottom one by one by
adopting symbolic execution.
The output of semantics extraction is a function matching
list which maps the standard memory operation functions and
its corresponding customized memory operation functions.
Given this function matching list, NLP-EYE dynamically
instruments stubs before function calls memory operation
and memory access points in advance to record and revise
memory region states. NLP-EYE identiﬁes memory opera-
tion function calls by simply comparing the called function
name and the function names in the function matching list.
The stubs are extra code snippets that are executed before
the symbolic execution engine measuring the instrumented
statements. We manually made up a coarse function misuse
list which contains general function misuse implementations,
such as a memory region can not be released more than once
and a memory region can not be accessed after being released.
Given this list, once symbolic execution reaches any memory
access point or any function call site of a memory opera-
tion function, NLP-EYE executes the instrumented stub and
checks misuses. If it meets a misuse, NLP-EYE will report
this misuse as a vulnerability. Otherwise, the correspond-
ing memory state will be updated (i.e., allocated or released)
based on the function call of the memory operation function.
For instance, the source code in ﬁgure 1, NLP-EYE instru-
ments before line 18, 23 and 28 since the called functions
are identiﬁed as memory operation functions. Then during
symbolic execution, NLP-EYE records that a memory region
is allocated in line 18 and released in line 23. When symbolic
execution reaches line 28, it recognizes that a memory region
(i.e., buf) is to be released twice which is one of the given
function misuses, therefore NLP-EYE reports a double-free
vulnerability.
Lines of code
# of
functions
# of memory
operation functions
Vim-8.1 [17]
ImageMagick-7.0.8-15 [9]
CPython-3.8.0a0 [3]
Git-2.21.0 [4]
GraphicsMagick-1.3.31 [8]
GnuTLS-3.6.5 [6]
LibTIFF-4.0.10 [11]
Total
468,133
514,472
556,950
289,532
369,569
488,654
85,791
2,773,101
16,012
14,636
12,000
8,788
7,406
5,433
1,326
65,601
73
79
66
32
29
11
4
294
Table 1: Lines of code, number of functions and number of
memory operation functions collected from each library/pro-
gram.
4 Evaluation
In this section, we report the results of four experiments. The
ﬁrst experiment assesses the performance of function proto-
type segmentation. The second demonstrates the accuracy of
NLP-EYE while identifying memory operation functions,
and whether the context corpus has any impact on the identiﬁ-
cation accuracy. The third experiment looks into the vulnera-
bility detection ability of NLP-EYE, and the last experiment
discusses its runtime performance.
4.1 Experiment Setup
Dataset. We collected the latest version of seven popular open
source libraries and programs written in C/C++ programming
language with a total of 65,601 functions by December 2018
(see Table 1 for more details).
Due to the lack of open source labeled memory operation
functions, we created our benchmarks. For identifying mem-
ory operation functions, we asked a team of annotators (3
programmers), all with more than seven years of program-
ming experience in C/C++ to examine the implementations of
memory operation functions. We ﬁrst required team members
to label memory operation functions independently, and then
all members checked the results together. If there were any
function with different labels, team members would discuss
an agreement to label this function before it could be included
in the dataset. In this procedure, we found 294 memory oper-
ation functions in total.
Implementation. We evaluated NLP-EYE on a Ubuntu
16.04 x64 workstation with an Intel Core i7-6700 CPU (four
cores, 3.40 GHz) and 64 GB RAM. For the function proto-
type segmentation, we used NLTK [32], a natural language
processing toolkit, to create the adaptive corpus for segmen-
tation. We used the WordSegment [15] module in Python to
split function prototypes. Gensim [37] is set up for NLP-based
comparison, which conducts the similarity comparison based
on the context corpus. Finally, we adopted Clang Static Ana-
lyzer [1] to perform type comparison and symbolic execution.
Clang Static Analyzer is a a source code analysis tool which
adopts symbolic execution to analyze each translation unit. It
provides a framework that developers can intercept the sym-
bolic execution process at speciﬁc points such as function call
and memory access. In addition, Clang Static Analyzer provide
314          22nd International Symposium on Research in Attacks, Intrusions and DefensesUSENIX Associationuseful programming interfaces that can be used by developers
to interact with the data type.
4.1.1 Experiment Design
To evaluate the effectiveness and efﬁciency of NLP-EYE, we
present the designed four experiments in details below.
EX1 (Prototype Segmentation). To evaluate the effective-
ness of prototype segmentation, we measured the Levenshtein-
inspired distance [45] [38] of the segmentation results as our
evaluation metrics. The distance between two segmentation
lists i and j of string s is given by di j, which can be calculated
as:
di j =
(veci[k]
xor
vec j[k])
|s|−1
∑
k=1
where |s| represents the length of string s. Segmentation
lists i and j are converted into vectors, veci and vec j. In each
vector, zero is regarded as “without split”, and one is “split”.
For the Levenshtein-inspired distance, a lower distance with
the correct one indicates that the segmentation list requires
fewer edit operations (i.e., split and merge) to be adjusted
to the correct one. Thus, a lower distance speciﬁes a better
segmentation result.
EX2 (Memory Operation Function Identiﬁcation). NLP-
EYE identiﬁes memory operation functions by using NLP-
based comparison and type comparison. We evaluated the
function identiﬁcation performance by using precision, recall
and F-measure as the evaluation metrics.
EX3 (Vulnerability Detection). We targeted on typical mem-
ory corruption vulnerabilities in this paper, i.e., double-free,
use-after-free, and null pointer de-reference against real world
software products such as Vim and CPython. To evaluate the
effectiveness of NLP-EYE, we further compared it with the
other four vulnerability detection tools (MallocChecker [13],
Cppcheck [2], Infer [10] and SVF [42]), and counted the number
of vulnerabilities that are correctly detected.
EX4 (Runtime Performance). We evaluated the average
time cost of each phase in NLP-EYE, including preprocess-
ing, semantics extraction, and vulnerability detection.
4.2 Ex1: Prototype Segmentation
Before we start, we manually split the function names we col-
lected as the ground truth. We counted the number of function
names that are correctly segmented, and then calculated the
Levenshtein-inspired distance to evaluate the performance of
each segmentation. Further, we compared the segmentation
results that are generated by the adaptive corpus of NLP-
EYE with the corresponding results generated by Google
Web Trillion Word Corpus (GWTWC). It assesses the result
accuracy while applying the adaptive corpus.
NLP-EYE correctly segments 230 out of 350 function
names. Levenshtein-inspired distances of those function
names are zero. Figure 4 demonstrated the average dis-