to specialize a computation, reducing its complexity. Speciﬁcally,
let the set of sensitive nucleotides on α be {α[yτ ]}, and the set for
β be {β[xt]}. These nucleotides are all marked as symbols on the
sequences. Performing a mixed execution on them, the DC can ac-
quire a query q with {α[yτ ]} and {β[xt]} as inputs. Such a query is
typically much more efﬁcient than the original program, as demon-
strated in our experimental studies (Section 4). To seek the answer
for q, the DC converts it into a circuit Q and further encrypts it to
create a “garbled circuit” Q(cid:2)
, the DC and the DP can run
an SMC to compute the answer to the query. Compared with the
prior work [34], our approach is much more efﬁcient, as Q(cid:2)
can
be very small, and therefore can handle a computation task with a
much larger scale (on the order of tens of thousands of nucleotides).
A problem here is that SMC does not offer protection to the in-
formation revealed by the outcome of a computation. A solution
can be to let the DP evaluate the unencrypted circuit Q without ac-
cess to {α[yτ ]} before SMC happens. This is feasible because α
is usually very short, involving only a few hundreds of nucleotides,
and as a result, typically no more than 5 of them are SNP [43].
Therefore, the DP can check all 45 possible combinations of these
nucleotides to ensure that none of them will cause the answer for q
to violate privacy policies, for example, exposing more nucleotides
than permitted by a threshold. In the case that the size of {α[yτ ]}
is large, a solution could be randomly sampling some of combina-
tions for policy veriﬁcation. Note that we can hide the outcome of
such a computation from the DP, which eliminates the concern of
leaking the DC’s data to the DP through the outcomes. The effec-
tiveness of such an approach, however, needs to be further studied
in the future research.
3. PROGRAM TRANSFORMATION
This section describes a tool for transforming legacy biocom-
puting code into a new program to perform mixed executions on
sanitized genome sequences. Our current design is for converting
Java programs, but the idea behind it can work on the programs in
other languages. We also implemented a prototype using Java.
To transform a Java program, our tool takes the following steps.
It ﬁrst runs a transformation tool such as Java2XML [3] to convert
the source code into an abstract syntax tree (AST) that describes
the structure of the program [12]. The AST representation clearly
indicates different elements of the program, including variables and
statements, and their relations, in particular execution ﬂows, over
which a taint analysis is performed to ﬁnd out all the elements
tainted by sensitive nucleotides. These elements are further in-
strumented with specialization code to support mixed executions.
Finally, the transformed AST is converted into a new Java program
through XSLT stylesheet [12].
3.1 Taint Analysis
The objective of taint analysis is to identify all statements and
variables affected by sensitive nucleotides. The statements in a pro-
gram that import these data are manually annotated as taint sources.
Starting from them, our approach statically analyzes the propaga-
tion of tainted data on the AST in accordance with a set of propaga-
tion rules. Such a rule is in the form of (s,i,o,e), in which s is
a statement, i and o represent the input and the output of the state-
ment respectively, and e is a Boolean value that indicates whether
execution of the statement will cause taint to be propagated from i
to o. For instance, the rule (=, value, variable, true)
speciﬁes that an assignment statement (“=”) will propagate taint
from its input (value) to its output (variable).
Let V be the set of tainted variables and S be the set of tainted
statements. These sets include only the taint sources at the begin-
ning of an analysis. During the analysis, our analyzer checks every
element on the AST according to the execution ﬂow of the program,
identify tainted variables and the statements that operate on these
variables using propagation rules, and put them to V and S respec-
tively. Some statements need special treatment. Speciﬁcally, our
analyzer forks threads to explore different branches of a branching
statement to the point where they converge. For a loop statement,
we need to consider the propagation of taint across different iter-
ations. Consider the example in Figure 2 from Line 15 to 18 of
P 1, in which min(a, b, c) is computed by ﬁrst comparing a and b
to ﬁnd the smaller one and then comparing it with c. These opera-
tions are embedded in the loop from Line 2 and 7. An interesting
observation is that if c is tainted, the ﬁrst iteration of the loop only
taints the statement at Line 17 and array D. However, the next iter-
ation sees the statement at Line 16 also become tainted because this
time, D is tainted. Our solution to the problem is to statically an-
alyze the loop iteration by iteration, until no new tainted variables
or statements are discovered.
Another important issue we had to deal with is propagation of
taint through control ﬂow. This happens when a branch condition
becomes tainted. As a result, sensitive inputs could affect the use
of the statements and variables within the scope [5] of the branch-
ing, that is, part of the program between the condition and the pro-
gram location where all branches converge. For example, the score
function S1 in Figure 2 contains a branch that a comparison be-
tween two nucleotides, one of which can be sensitive, determines
the score it returns. In this case, we taint all the variables within the
scope of the branching to be used posterior to the statement. For
the example in Figure 2, the output of S1 is tainted.
3.2 Code Instrumentation
Figure 4: Integer variable transformation.
Tainted program elements need to be transformed to enable a
mixed execution. This was achieved in our research through replac-
ing a tainted variable with a class that accepts both concrete val-
ues and a symbolic expression, and transforming tainted statements
into the forms that can work on these variables. Figure 4 presents
an example, in which an integer variable I is converted into a new
type IntSymbol, a class accepting both concrete and symbolic
values. To perform an operation on such a variable, proper instru-
mentation needs to be done to operators, such as assignment and
addition. In Figure 4, an assignment of a value to I is modiﬁed
to be performed by assign(),the method of IntSymbol: the
method does the normal assignment when its input is concrete, and
maintains and reduces an expression when the input is symbolic.
A tainted statement is replaced with a code snippet according
to its type, as described in Section 2.2. A problem is that a pro-
gram could call a function from other libraries whose source code
may not be available. This is tackled by our instrumentation tool
through redirecting such a call to a wrapper of the function being
called. The wrapper checks the parameters of the call: if any of
them is symbolic, it returns a new symbol to enable the follow-up
343operations and residualizes the call; otherwise, it passes the param-
eters to the callee.
4. EVALUATION
This section reports an empirical study of the techniques we pro-
pose. The genome sequences used in our study came from the hu-
man genome dataset in UCSC Genome Browser [39], the latest
Build 36.1 assembled on March 2006. We extracted segments from
the dataset and truncated them into sequences of different sizes
for our experiments. These sequences were sanitized by replacing
their SNP nucleotides, as indicated by the International HapMap
Project [27], with symbols.
4.1 Program Transformation
We ran our program-transformation prototype on 7 Java-based
DPA implementations, including 3 bioinformatics libraries and 4
synthesized programs, as illustrated in Table 1. Our prototype trans-
formed all synthesized programs and most part of the libraries. The
new programs and the queries they generated were evaluated using
genome data, and their outcomes were found to be identical with
those produced by running the original programs on unprotected
sequences. This indicates that the transformation was sound. Fol-
lowing we describe our experiences with the Java libraries.
NeoBio [22] is a Java library including three pair-wise alignment
algorithms, Needleman-Wunsch [56], Smith-Waterman [64], and
Crochemore-Landau-Ziv-Ukelson [21]. Our tool failed to trans-
form the last one because it intensively uses tainted addresses: it
performs computation upon a double-linked list constructed based
on the values of individual nucleotides. As a result, our analyzer
found that nearly all the statements of the algorithm had to be resid-
ualized. This problem comes from the limit support our current de-
sign offers for symbolic addresses, which will be addressed in our
follow-up research.
Argo genome browser [1] includes 48 class ﬁles to support both
global and local alignment algorithms. Most of the classes, how-
ever, are different designs of score functions, which can be residual-
ized without incurring noticeable performance overheads to a query
program. The library was successfully converted by our prototype
and evaluated in our experiments. The same success also happened
to JAligner [2], a Java implementation of the Smith-Waterman al-
gorithm with Gotoh’s improvement. An interesting property of this
algorithm is that it maintains a (n+1)×(m+1) matrix to record the
neighbor of each cell that contributes to its value. This simpliﬁes
the “backtracking” process for identifying the optimal path. During
the program’s runtime, our specialization code assigned symbols to
cells after unknown nucleotides were encountered. The concrete
values of these cells were calculated from the DP’s answer to the
query exported by the program, which included the intersections
between the optimal path and unknown columns, and the symbolic
expressions contributing to the values of these intersections.
4.2 Performance
We ran the transformed programs on real genome sequences to
study their performance. Our experiments were conducted on two
laptops, each with a 1.8G Intel Core 2 Duo CPU and 2 GB memory.
One of these laptops was used as the DP, and the other as DC.
They communicated with each other through a local network. In
the experiments, we measured the computation time and memory
use for both mixed executions on sanitized data that happened on
the DC side, and executions of the queries generated thereby on the
DP side. Such information was compared with the computational
and spatial overheads for directly running the original programs on
unprotected data, which served as baselines. We also recorded the
communicational overheads incurred by the interactions between
the DP and the DC.
Table 2 illustrates the experimental results, in which the problem
sizes are described as (n, m), where n and m represent the sizes of
α (the DC’s sequence) and β (the DP’s sequence) respectively. Our
experiments include an edit distance (row 1), 2 global alignments
(row 2 and 3), 4 local alignments (row 4 to 7), longest common
sequence (LCS) identiﬁcation (row 8) and 1 multiple alignment.
The multiple alignment algorithm computes over three sequences.
The last one belongs to the DP and contains one SNP. The problem
sizes we chose ranged from hundreds of nucleotides to a million
of nucleotides. The number of sensitive nucleotides on β varied
according to the problem sizes, from a single one to 1056. In the
table, the baseline results are labeled as “Native”.
The table shows that the mixed execution did take a noticeable
toll on the DC’s performance. Compared with the baseline, trans-
formed programs were typically one order of magnitude slower and
consumed more memory. Such a raise of overheads culminated in
the experiment involving the Needleman-Wunsch algorithm from
the NeoBio library, which brought in a slow down factor of 64
and used 28 times more memory. However, the DC’s cost seems
to be compensated by the huge performance gain on the DP side:
the query programs generated by the DC were so efﬁcient that they
were at least 10000 times faster than the baseline and typically con-
sumed much less memory. Actually, computing the answer for a
query never took more than 100 microseconds. Particularly, the
transformed Divide-and-Conquer algorithm (row 8) even enabled
the DC to accomplish the computation without querying the DP at
all. This is because in that experiment, the constant in Equation 2
was found to be below the value ranges of all symbolic expressions,
and as a result, a concrete outcome ensued. Note this would not
be possible without specialization. Moreover, the communication
overheads were also found to be very low. This is in a stark con-
trast with the conservative estimate made in our theoretic analysis
(Section 2.3), which predicts much higher overheads.
4.3
Information Leaks
We also evaluated the information leaks that can be caused by
releasing the outcomes of query programs, using a query auditor
built upon a constraint solver [25]. The outcomes are shown in Ta-
ble 3. This study was conducted under three scenarios: an answer
includes only a value (e.g., an edit distance), a path for optimal
alignment or both. From the table, we can see that the amount of
information disclosed by answers is pretty low: ranging from 0% to
1.8%. The performance of constraint solving was also reasonable:
from 0.001 to 0.3 seconds.
4.4 Secure Multi-party Computation
We studied how our specialization techniques could facilitate se-
cure multi-party computation when the DC’s sequence α also con-
tains sensitive nucleotides.
In our experiment, we ran the trans-
formed edit-distance program on the sanitized sequences α and β,
whose SNP nucleotides were replaced by symbols. This produced a
query program, which was converted into a “garbled circuit” using
a tool we developed. After that, the DP and the DC ran an SMC
protocol [34] to evaluate the circuit. In the experiment, we mea-
sured the accumulated computation time and memory use on the
DC side, including those for program specialization and running
the SMC protocol, as well as the overheads on the DP side for per-
forming its part of the protocol. These results were compared with
the overheads of running an optimized SMC protocol [34] directly
on α and β. The optimized SMC protocol we used is an implemen-
tation of Protocol 3 proposed in the prior work [34]. The protocol
is recommended for computing large-size problems, as it strikes a
344Program Name
NeoBio
Argo genome browser
JAligner
Edit Distance
Blast
Divide-and-Conquer
Multiple Alignment
Source
library
library
library
synthesized
synthesized
synthesized
synthesized
Table 1: Transformed programs.
# of Class Files
Included Algorithms
22
48
16
1
2
2
1
Needleman-Wunsch,Smith-Waterman,Crochemore-Landau-Ziv-Ukelson
Global Alignment, Local Alignment
Smith-Waterman algorithm with Gotoh’s improvement
Edit Distance
Blast
Divide-and-Conquer
Multiple Alignment