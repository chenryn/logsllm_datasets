title:Cache Telepathy: Leveraging Shared Resource Attacks to Learn DNN
Architectures
author:Mengjia Yan and
Christopher W. Fletcher and
Josep Torrellas
Cache Telepathy: Leveraging Shared Resource 
Attacks to Learn DNN Architectures
Mengjia Yan, Christopher W. Fletcher, and Josep Torrellas, 
University of Illinois at Urbana-Champaign
https://www.usenix.org/conference/usenixsecurity20/presentation/yan
This paper is included in the Proceedings of the 29th USENIX Security Symposium.August 12–14, 2020978-1-939133-17-5Open access to the Proceedings of the 29th USENIX Security Symposium is sponsored by USENIX.Cache Telepathy: Leveraging Shared Resource Attacks
to Learn DNN Architectures
Mengjia Yan
PI:EMAIL
University of Illinois at
Urbana-Champaign
Christopher W. Fletcher
cwﬂPI:EMAIL
University of Illinois at
Urbana-Champaign
Josep Torrellas
PI:EMAIL
University of Illinois at
Urbana-Champaign
Abstract
Deep Neural Networks (DNNs) are fast becoming ubiq-
uitous for their ability to attain good accuracy in various
machine learning tasks. A DNN’s architecture (i.e., its hyper-
parameters) broadly determines the DNN’s accuracy and per-
formance, and is often conﬁdential. Attacking a DNN in the
cloud to obtain its architecture can potentially provide major
commercial value. Further, attaining a DNN’s architecture
facilitates other existing DNN attacks.
This paper presents Cache Telepathy: an efﬁcient mech-
anism to help obtain a DNN’s architecture using the cache
side channel. The attack is based on the insight that DNN
inference relies heavily on tiled GEMM (Generalized Matrix
Multiply), and that DNN architecture parameters determine
the number of GEMM calls and the dimensions of the matri-
ces used in the GEMM functions. Such information can be
leaked through the cache side channel.
This paper uses Prime+Probe and Flush+Reload to attack
the VGG and ResNet DNNs running OpenBLAS and Intel
MKL libraries. Our attack is effective in helping obtain the
DNN architectures by very substantially reducing the search
space of target DNN architectures. For example, when attack-
ing the OpenBLAS library, for the different layers in VGG-16,
it reduces the search space from more than 5.4× 1012 archi-
tectures to just 16; for the different modules in ResNet-50, it
reduces the search space from more than 6× 1046 architec-
tures to only 512.
1 Introduction
For the past several years, Deep Neural Networks (DNNs)
have increased in popularity thanks to their ability to attain
high accuracy and performance in a multitude of machine
learning tasks — e.g., image and speech recognition [26, 63],
scene generation [45], and game playing [51]. An emerging
framework that provides end-to-end infrastructure for using
DNNs is Machine Learning as a Service (MLaaS) [2, 19].
In MLaaS, trusted clients submit DNNs or training data to
MLaaS service providers (e.g., an Amazon or Google data-
center). Service providers host the DNNs, and allow remote
untrusted users to submit queries to the DNNs for a fee.
Despite its promise, MLaaS provides new ways to under-
mine the privacy of the hosted DNNs. An adversary may be
able to learn details of the hosted DNNs beyond the ofﬁcial
query APIs. For example, an adversary may try to learn the
DNN’s architecture (i.e., its hyper-parameters). These are
the parameters that give the network its shape, such as the
number and types of layers, the number of neurons per layer,
and the connections between layers.
The architecture of a DNN broadly determines the DNN’s
accuracy and performance. For this reason, obtaining it often
has high commercial value. Furthermore, once a DNN’s
architecture is known, other attacks are possible, such as the
model extraction attack [55] (which obtains the weights of the
DNN’s edges), and the membership inference attack [39, 49]
(which determines whether an input was used to train the
DNN).
Yet, stealing a DNN’s architecture is challenging. DNNs
have a multitude of hyper-parameters, which makes brute-
force guesswork unfeasible. Moreover, the DNN design space
has been growing with time, which is further aggravating the
adversary’s task.
This paper demonstrates that despite the large search space,
attackers can quickly reduce the search space of DNN ar-
chitectures in the MLaaS setting using the cache side chan-
nel. Our insight is that DNN inference relies heavily on tiled
GEMM (Generalized Matrix Multiply), and that DNN archi-
tecture parameters determine the number of GEMM calls
and the dimensions of the matrices used in the GEMM func-
tions. Such information can be leaked through the cache side
channel.
We present an attack that we call Cache Telepathy. It is
the ﬁrst cache side channel attack targeting modern DNNs
on general-purpose processors (CPUs). The reason for target-
ing CPUs is that CPUs are widely used for DNN inference
in existing MLaaS platforms, such as Facebook’s [25] and
Amazon’s [4].
USENIX Association
29th USENIX Security Symposium    2003
We demonstrate our attack by implementing it on a state-
of-the-art platform. We use Prime+Probe and Flush+Reload
to attack the VGG and ResNet DNNs running OpenBLAS
and Intel MKL libraries. Our attack is effective at helping
obtain the architectures by very substantially reducing the
search space of target DNN architectures. For example, when
attacking the OpenBLAS library, for the different layers in
VGG-16, it reduces the search space from more than 5.4×
1012 architectures to just 16; for the different modules in
ResNet-50, it reduces the search space from more than 6×
1046 architectures to only 512.
This paper makes the following contributions:
1. It provides a detailed analysis of the mapping of DNN
hyper-parameters to the number of GEMM calls and their
arguments.
2. It implements the ﬁrst cache-based side channel attack to
extract DNN architectures on general purpose processors.
3. It evaluates the attack on VGG and ResNet DNNs running
OpenBLAS and Intel MKL libraries.
2 Background
2.1 Deep Neural Networks
Deep Neural Networks (DNNs) are a class of Machine Learn-
ing (ML) algorithms that use a cascade of multiple layers of
nonlinear processing units for feature extraction and transfor-
mation [35]. There are several major types of DNNs in use
today, two popular types being fully-connected neural net-
works (or multi-layer perceptrons) and Convolutional Neural
Networks (CNNs).
DNN Architecture The architecture of a DNN, also called
the hyper-parameters, gives the network its shape. DNN
hyper-parameters considered in this paper are:
a) Total number of layers.
b) Layer types, such as fully-connected, convolutional, or
pooling layer.
c) Connections between layers, including sequential and non-
sequential connections such as shortcuts. Non-sequential
connections exist in recent DNNs, such as ResNet [26].
For example, instead of directly using the output from a
prior layer as the input to a later layer, a shortcut involves
summing up the outputs of two prior layers and using the
result as the input for a later layer.
d) Hyper-parameters for each layer. For a fully-connected
layer, this is the number of neurons in that layer. For a
convolutional layer, this is the number of ﬁlters, the ﬁlter
size, and the stride size.
e) The activation function in each layer, e.g., relu and
sigmoid.
DNN Weights The computation in each DNN layer in-
volves many multiply-accumulate operations (MACCs) on
input neurons. The DNN weights, also called parameters,
specify operands to these multiply-accumulate operations.
In a fully-connected layer, each edge out of a neuron is a
MACC with a weight; in a convolutional layer, each ﬁlter is a
multi-dimensional array of weights, which is used as a sliding
window that computes dot products over input neurons.
DNN Usage DNNs usage has two distinct phases: training
and inference. In training, the DNN designer starts with a net-
work architecture and a training set of labeled inputs, and tries
to ﬁnd the DNN weights to minimize mis-prediction error.
Training is generally performed ofﬂine on GPUs and takes a
relatively long time to ﬁnish, typically hours or days [12, 25].
In inference, the trained model is deployed and used to make
real-time predictions on new inputs. For good responsiveness,
inference is generally performed on CPUs [4, 25].
2.2 Prior Privacy Attacks Need the DNN Ar-
chitecture
To gain insight into the importance of DNN architectures, we
discuss prior DNN privacy attacks [39, 49, 55, 59]. There are
three types of such attacks, each with a different goal. All
of them require knowing the victim’s DNN architecture. In
the following, we refer to the victim’s network as the oracle
network, its architecture as the oracle DNN architecture, and
its training data set as the oracle training data set.
In the model extraction attack [55], the attacker tries to
obtain a network that is close enough to the oracle network. It
assumes that the attacker knows the oracle DNN architecture
at the start, and tries to estimate the weights of the oracle
network. The attacker creates a synthetic data set, requests
the classiﬁcation results from the oracle network, and uses
such results to train a network that uses the oracle architecture.
The membership inference attack [39, 49] aims to infer
the composition of the oracle training data set, which is ex-
pressed as the probability of whether a data sample exists in
the training set or not. This attack also requires knowledge
of the oracle DNN architecture. Attackers create multiple
synthetic data sets and train multiple networks that use the
oracle architecture. Then, they run the inference algorithm
on these networks with some inputs in their training sets and
some not in their training sets. They then compare the results
to ﬁnd the patterns in the output of the data in the training
sets. The pattern information is used to infer the composition
of the oracle training set. Speciﬁcally, given a data sample,
they run the inference algorithm of the oracle network, obtain
the output and check whether the output matches the pattern
obtained before. The more the output matches the pattern, the
more likely the data sample exists in the oracle training set.
The hyper-parameter stealing attack [59] steals the loss
function and regularization term used in ML algorithms, in-
2004    29th USENIX Security Symposium
USENIX Association
cluding DNN training and inference. This attack also relies
on knowing the oracle DNN architecture. During the attack,
attackers leverage the model extraction attack to learn the
DNN’s weights. They then ﬁnd the loss function that mini-
mizes the training misprediction error.
2.3 Cache-based Side Channel Attacks
In a cache-based side channel attack, the attacker infers
a secret from the victim by observing the side effects of
the victim’s cache behavior. Recently, multiple variations
of cache-based side channel attacks have been proposed.
Flush+Reload [69] and Prime+Probe [38, 43] are two pow-
erful ones. Flush+Reload requires that the attacker share
security-sensitive code or data with the victim. This sharing
can be achieved by leveraging the page de-duplication tech-
nique. In an attack, the attacker ﬁrst performs a clflush
operation to the shared cache line, to push it out of the cache.
It then waits to allow the victim to execute. Finally, it re-
accesses the same cache line and measures the access latency.
Depending on the latency, it learns whether the victim has
accessed the shared line.
Prime+Probe does not require page sharing. It is more
practical than Flush+Reload as most cloud providers disable
page de-duplication for security purposes [58]. The attacker
constructs a collection of addresses, called conﬂict addresses,
which map to the same cache set as the victim’s line. In
an attack, the attacker ﬁrst accesses the conﬂict addresses
to cause cache conﬂicts with the victim’s line, and evict it
from the cache. After waiting for an interval, it re-accesses
the conﬂict addresses and measures the access latency. The
latency is used to infer if the victim has accessed the line.
2.4 Threat Model
This paper develops a cache-timing attack that quickly reduces
the search space of DNN architectures. The attack relies on
the following standard assumptions.
Black-box Access We follow a black-box threat model in
an MLaaS setting similar to [55]. In a black-box attack, the
DNN model is only accessible to attackers via an ofﬁcial
query interface. Attackers do not have prior knowledge about
the target DNN, including its hyper-parameters, weights and
training data.
Co-location We assume that the attacker process can use
techniques from prior work [7,8,14,46,57,66,73] to co-locate
onto the same processor chip as the victim process running
DNN inference. This is feasible, as current MLaaS jobs are
deployed on shared clouds. Note that recent MLaaS, such as
Amazon SageMaker [3] and Google ML Engine [18] allow
users to upload their own code for training and inference,
instead of using pre-deﬁned APIs.
In this case, attackers
can disguise themselves as an MLaaS process and the cloud
scheduler will have difﬁculty in separating attacker processes
from victim processes.
Code Analysis We also assume that the attacker can an-
alyze the ML framework code and linear algebra libraries
used by the victim. These are realistic assumptions. First,
open-source ML frameworks are widely used for efﬁcient
development of ML applications. The frameworks supported
by Google, Amazon and other companies, including Tensor-
ﬂow [1], Caffe [32], and MXNet [6] are all public. Our analy-
sis is applicable to almost all of these frameworks. Second, the
frameworks’ backends are all supported by high-performance
and popular linear algebra libraries, such as OpenBLAS [64],
Eigen [23] and MKL [60]. OpenBLAS and Eigen are open
sourced, and MKL can be reverse engineered, as we show in
Section 6.
3 Attack Overview
The goal of Cache Telepathy is to substantially reduce the
search space of target DNN architectures. In this section,
we ﬁrst discuss how our attack can assist other DNN privacy
attacks, and then give an overview of the Cache Telepathy
attack procedure.
Cache Telepathy’s Role in Existing DNN Attacks
In set-
tings where DNN architectures are not known, our attack
can serve as an essential initial step for many existing DNN
privacy attacks, including model extraction attacks [55] and
membership inference attacks [49].
Figure 1: Cache Telepathy assists model extraction attacks.
Figure 1 demonstrates how Cache Telepathy makes the
model extraction attack feasible. The ﬁnal goal of the model
extraction attack is to obtain a network that is close enough
to the oracle network (Section 2.2). The attack uses the fol-
lowing steps. First, the attacker generates a synthetic training
data set (x). This step can be achieved using a random feature
vector method [55] or more sophisticated techniques, such
as hill-climbing [49]. Next, the attacker queries the oracle
network via inference APIs provided by MLaaS providers to
get labels or conﬁdence values (y). The synthetic data set