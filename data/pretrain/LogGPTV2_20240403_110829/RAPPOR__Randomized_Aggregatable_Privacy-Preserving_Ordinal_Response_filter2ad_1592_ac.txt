times improves privacy protection, but, on its own, it is not
suﬃcient nor necessary to provide -diﬀerential privacy.
3.2 Differential Privacy of the Instantaneous
Randomized Response
With a single data collection from each client, the attacker’s
knowledge of B must come directly from a single report S
generated by applying the randomization twice, thus, pro-
viding a higher level of privacy protection than under the
assumption of complete knowledge of B(cid:48).
Because of a two-step randomization, probability of ob-
serving a 1 in a report is a function of both q and p as well
as f .
Lemma 1. Probability of observing 1 given that the un-
derlying Bloom ﬁlter bit was set is given by
∗
q
= P (Si = 1|bi = 1) =
f (p + q) + (1 − f )q.
1
2
Probability of observing 1 given that the underlying Bloom
ﬁlter bit was not set is given by
= P (Si = 1|bi = 0) =
f (p + q) + (1 − f )p.
p
∗
1
2
We omit the proof as the reasoning is straightforward that
probabilities in both cases are mixtures of random and true
responses with the mixing proportion f .
Theorem 2. The Instantaneous randomized response (Step
3 of RAPPOR) satisﬁes 1-diﬀerential privacy, where 1 =
h log
and q∗ and p∗ as deﬁned in Lemma 1.
(cid:16) q∗(1−p∗)
p∗(1−q∗)
(cid:17)
Proof. The proof is analogous to Theorem 1. Let RR1
be the ratio of two conditional probabilities, i.e., RR1 =
P (S∈R|B=B1)
P (S∈R|B=B2) . To satisfy the diﬀerential privacy condition,
this ratio must be bounded by exp(1).
P (S ∈ R|B = B1)
P (S ∈ R|B = B2)
RR1 =
=
≤ max
sj∈R
(cid:80)
(cid:80)
sj∈R P (S = sj|B = B1)
sj∈R P (S = sj|B = B2)
(cid:20) q∗(1 − p∗)
P (S = sj|B = B1)
P (S = sj|B = B2)
p∗(1 − q∗)
(cid:21)h
(cid:18) q∗(1 − p∗)
p∗(1 − q∗)
(cid:19)
.
1 = h log
=
and
The above proof naturally extends to N reports, since
each report that is not changed contributes a ﬁxed amount to
the total probability of observing all reports and enters both
nominator and denominator in a multiplicative way (because
of independence). Since our diﬀerential privacy framework
considers inputs that diﬀer only in a single record, j, (reports
set D1 becomes D2 diﬀering in a single report Sj), the rest
of the product terms end up canceling out in the ratio
P (S1 = s1, S2 = s2, . . . , Sj = sj, . . . , SN = sN|B1)
P (S1 = s1, S2 = s2, . . . , Sj = sj, . . . , SN = sN|B2)
(cid:81)N
(cid:81)N
i=1 P (Si = si|B1)
i=1 P (Si = si|B2)
=
P (Sj = sj|B1)
P (Sj = sj|B2)
.
=
Computing n for the nth collection cannot be made with-
out additional assumptions about how eﬀectively the at-
tacker can learn B(cid:48) from the collected reports. We continue
working on providing these bounds under various learning
strategies. Nevertheless, as N becomes large, the bound
approaches ∞ but always remains strictly smaller.
4 High-utility Decoding of Reports
In most cases, the goal of data collection using RAPPOR is
to learn which strings are present in the sampled population
and what their corresponding frequencies are. Because we
make use of the Bloom ﬁlter (loss of information) and pur-
posefully add noise for privacy protection, decoding requires
sophisticated statistical techniques.
To facilitate learning, before any data collection begins
each client is randomly assigned and becomes a permanent
member of one of m cohorts. Cohorts implement diﬀer-
ent sets of h hash functions for their Bloom ﬁlters, thereby
reducing the chance of accidental collisions of two strings
across all of them. Redundancy introduced by running m
cohorts simultaneously greatly improves the false positive
rate. The choice of m should be considered carefully, how-
ever. When m is too small, then collisions are still quite
likely, while when m is too large, then each individual co-
hort provides insuﬃcient signal due to its small sample size
(approximately N/m, where N is the number of reports).
Each client must report its cohort number with every sub-
mitted report, i.e., it is not private but made private.
We propose the following approach to learning from the
collected reports:
• Estimate the number of times each bit i within cohort
j, tij, is truly set in B for each cohort. Given the
number of times each bit i in cohort j, cij was set in
a set of Nj reports, the estimate is given by
tij =
cij − (p + 1
2 f q − 1
(1 − f )(q − p)
2 f p)Nj
.
Let Y be a vector of tij’s, i ∈ [1, k], j ∈ [1, m].
• Create a design matrix X of size km × M where M is
the number of candidate strings under consideration.
X is mostly 0 (sparse) with 1’s at the Bloom ﬁlter
bits for each string for each cohort. So each column
of X contains hm 1’s at positions where a particular
candidate string was mapped to by the Bloom ﬁlters in
all m cohorts. Use Lasso [26] regression to ﬁt a model
Y ∼ X and select candidate strings corresponding to
non-zero coeﬃcients.
• Fit a regular least-squares regression using the selected
variables to estimate counts, their standard errors and
p-values.
• Compare p-values to a Bonferroni corrected level of
α/M = 0.05/M to determine which frequencies are
Figure 2: Recall versus precision depending on choice of parameters k, h, and m. The ﬁrst panel shows the
true population distribution from which RAPPOR reports were sampled. The other three panels vary one
of the parameters while keeping the other two ﬁxed. Best precision and recall are achieved with using 2 hash
functions, while the choices of k and m do not show clear preferences.
statistically signiﬁcant from 0. Alternatively, control-
ling the False Discovery Rate (FDR) at level α using
the Benjamini-Hochberg procedure [3], for example,
could be used.
4.1 Parameter Selection
Practical implementation of the RAPPOR algorithm requires
speciﬁcation of a number of parameters. p, q, f and the num-
ber of hash functions h control the level of privacy for both
one-time and longitudinal collections. Clearly, if no longi-
tudinal data is being collected, then we can use One-time
RAPPOR modiﬁcation. With the exception of h, the choice
of values for these parameters should be driven exclusively
by the desired level of privacy .  itself can be picked de-
pending on the circumstances of the data collection process;
values in the literature range from 0.01 to 10 (see Table 1 in
[15]).
Bloom ﬁlter size, k, the number of cohorts, m, and h must
also be speciﬁed a priori. Besides h, neither k nor m are re-
lated to the worst-case privacy considerations and should be
selected based on the eﬃciency properties of the algorithm
in reconstructing the signal from the noisy reports.
We ran a number of simulations (averaged over 10 repli-
cates) to understand how these three parameters eﬀect de-
coding; see Figure 2. All scenarios assumed  = ln(3) pri-
vacy guarantee. Since only a single report from each user
was simulated, One-time RAPPOR was used. Population
sampled is shown in the ﬁrst panel and contains 100 non-
zero strings with 100 strings that had zero probability of
occurring. Frequencies of non-zero strings followed an expo-
nential distribution as shown in the ﬁgure.
In the other three panels, the x-axis shows the recall rate
and the y-axis shows the precision rate. In all three pan-
els, the same set of points are plotted and are only labeled
diﬀerently depending on which parameter changes in a par-
ticular panel. Each point represents an average recall and
precision for a unique combination of k, h, and m. For ex-
ample, the second panel shows the eﬀect of the Bloom ﬁlter
size on both precision and recall while keeping both h and m
ﬁxed. It is diﬃcult to make deﬁnitive conclusions about the
optimal size of the Bloom ﬁlter as diﬀerent sizes perform
similarly depending on the values of h and m. The third
panel, however, shows a clear preference for using only two
hash functions from the perspective of utility, as the decrease
in the number of hash functions used increases the expected
Population Used in ExperimentsFrequency0.000.020.040.060.08●●●●●●●●●●●●●●●●0.450.500.550.600.650.840.860.880.900.920.94Varying the Bloom Filter Sizesrecall (true positive / population)precision (true positive / detected)●1282565121024●●●●●●●●●●●●●●●●0.450.500.550.600.650.840.860.880.900.920.94Varying the Number of Hash Functionsrecall (true positive / population)precision (true positive / detected)●24816●●●●●●●●●●●●●●●●0.450.500.550.600.650.840.860.880.900.920.94Varying the Number of Cohortsrecall (true positive / population)precision (true positive / detected)●8163264use of Bloom ﬁlter. Details of the calculations are shown in
the Appendix.
While providing ln(3)-diﬀerential privacy for one time col-
lection, if one would like to detect items with frequency 1%,
then one million samples are required, 0.1% would require a
sample size of 100 million and 0.01% items would be identi-
ﬁed only in a sample size of 10 billion.
Eﬃciency of the unmodiﬁed RAPPOR algorithm is sig-
niﬁcantly inferior when compared to the Basic One-time
RAPPOR (the price of compression). Even for the Ba-
sic One-time RAPPOR, the provided bound can be theo-
retically achieved only if the underlying distribution of the
strings’ frequencies is uniform (a condition under which the
smallest frequency is maximized). With the presence of sev-
eral high-frequency strings, there is less probability mass
left for the tail and, with the drop in their frequencies, their
detectability suﬀers.
5 Experiments and Evaluation
We demonstrate our approach using two simulated and two
real-world collection examples. The ﬁrst simulated one uses
the Basic One-time RAPPOR where we learn the shape of
the underlying Normal distribution. The second simulated
example uses unmodiﬁed RAPPOR to collect strings whose
frequencies exhibit exponential decay. The third example is
drawn from a real-world dataset on processes running on a
set of Windows machines. The last example is based on the
Chrome browser settings collections.
5.1 Reporting on the Normal Distribution
To get a sense of how eﬀectively we can learn the underlying
distribution of values reported through the Basic One-time
RAPPOR, we simulated learning the shape of the Normal
distribution (rounded to integers) with mean 50 and stan-
dard deviation 10. The privacy constraints were: q = 0.75
and p = 0.5 providing  = ln(3) diﬀerential privacy (f = 0).
Results are shown in Figure 4 for three diﬀerent sample sizes.
With 10,000 reports, results are just too noisy to obtain a
good estimate of the shape. The Normal bell curve begins
to emerge already with 100,000 reports and at one million
reports it is traced very closely. Notice the noise in the left
and right tails where there is essentially no signal. It is re-
quired by the diﬀerential privacy condition and also gives a
sense of how uncertain our estimated counts are.
5.2 Reporting on an Exponentially-distributed
Set of Strings
The true underlying distribution of strings from which we
sample is shown in Figure 5. It shows commonly encoun-
tered exponential decay in the frequency of strings with sev-
eral “heavy hitters” and the long tail. After sampling 1 mil-
lion values (one collection event per user) from this popu-
lation at random, we apply RAPPOR to generate 1 million
reports with p = 0.5, q = 0.75, f = 0.5, two hash functions,
Bloom ﬁlter size of 128 bits and 16 cohorts.
After the statistical analysis using the Bonferroni cor-
rection discussed above, 47 strings were estimated to have
counts signiﬁcantly diﬀerent from 0. Just 2 of the 47 strings
were false positives, meaning their true counts were truly 0
but estimated to be signiﬁcantly diﬀerent. The top-20 de-
tected strings with their count estimates, standard errors,
p-values and z-scores (SNR) are shown in Table 1. Small
Figure 3: Sample size vs the upper limit on the
strings whose frequency can be learned. Seven col-
ored lines represent diﬀerent cardinalities of the can-
didate string set. Here, p = 0.5, q = 0.75 and f = 0.
recall. The fourth panel, similarly to the second, does not
deﬁnitively indicate the optimal direction for choosing the
number of cohorts.
4.2 What Can We Learn?
In practice, it is common to use thresholds on the number of
unique submissions in order to ensure some privacy. How-
ever, arguments as to how those thresholds should be set
abound, and most of the time they are based on a ‘feel’ for
what is accepted and lack any objective justiﬁcation. RAP-
POR also requires , a user-tunable parameter, which by the
design of the algorithm translates into limits on frequency
domain, i.e., puts a lower limit on the number of times a
string needs to be observed in a sample before it can be reli-
ably identiﬁed and its frequency estimated. Figure 3 shows
the relationship between the sample size (x-axis) and the
theoretical upper limit (y-axis) on how many strings can
be detected at that sample size for a particular choice of
p = 0.5 and q = 0.75 (with f = 0) at a given conﬁdence
level α = 0.05.
It is perhaps surprising that we do not learn more at very
large sample sizes (e.g., one billion). The main reason is that
as the number of strings in the population becomes large,
their frequencies proportionally decrease and they become
hard to detect at those low frequencies.
We can only reliably detect about 10,000 strings in a sam-
ple of ten billion and about 1,000 with a sample of one hun-
N /10, where N
dred million. A general rule of thumb is
is the sample size. These theoretical calculations are based
on the Basic One-time RAPPOR algorithm (the third mod-
iﬁcation) and are the upper limit on what can be learned
since there is no additional uncertainty introduced by the
√
1e+021e+041e+061e+081e+10110100100010000Sample SizeMaximum Number of Discoverable StringsM = 10000M = 1e+05M = 1e+06M = 1e+07M = 1e+08M = 1e+09Figure 4: Simulations of learning the normal distribution with mean 50 and standard deviation 10. The
RAPPOR privacy parameters are q = 0.75 and p = 0.5, corresponding to  = ln(3). True sample distribution
is shown in black; light green shows the estimated distribution based on the decoded RAPPOR reports. We
do not assume a priori knowledge of the Normal distribution in learning. If such prior information were
available, we could signiﬁcantly improve upon learning the shape of the distribution via smoothing.
String
V 1
V 2
V 5
V 7
V 4
V 3
V 8
V 6
V 10
V 9
V 12
V 11
V 14
V 19
V 13
V 15
V 20
V 18
V 17
V 21
Est.
48803
47388
41490
40682
40420
39509
36861
36220
34196
32207
30688
29630
27366
23860
22327
21752
20159
19521
18387
18267
Stdev
2808
2855
2801
2849
2811
2882
2842
2829