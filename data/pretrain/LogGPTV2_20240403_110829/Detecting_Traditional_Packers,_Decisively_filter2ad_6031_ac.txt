result appears to be of only theoretical interest. But all is not lost. Researchers in
areas of computer security, such as cryptography, have long recognized that even
malevolent adversaries must have bounded computational resources, particularly
time resources.
3.6 Time Bounded RASP
Our formalization is similar to the space bounded case.
Deﬁnition 7 (Time bounded RASP). Let ∆ : N → N be a computable
function. A ∆-time bounded RASP program is a RASP program that uses time at
most ∆(n) on all inputs of size n. A ∆-time bounded RASP is one that executes
only ∆-time bounded programs. It executes programs in exactly the same way as
a RASP except that on inputs of size n, if a program ever attempts to use more
than time ∆(n), the ∆-time bounded RASP will halt.
Deﬁnition 8 (Time Bounded Unpacking Problem.). Given: ∆-time bounded
RASP program P and integer k > 0. Question: Is there an input x with l(x) ≤ k
such that P unpacks on input x?
Theorem 5. The Time Bounded Unpacking Problem is decidable.
Proof. The proof is completely trivial. P is always guaranteed to halt within
time ∆(n) for all x of size n = l(x) ≤ k. Run P on all such x’s to see if it
(cid:117)(cid:116)
exhibits unpacking behavior.
Why should we bother to include such an obvious result? The reason is that
the restricted version of this very question is the one that the malware analysis
community should be considering.
So far we have shown that, when suitably restricted, detecting unpacking for
RASP machines is decidable. The restrictions we imposed are realistic: in reality,
the attacker has a ﬁnite amount of space or time to do damage.
It is diﬃcult to grasp how these results can be applied. Malware does not
come with a computable function ∆ and it would be time consuming to express
the cost of each instruction on a real architecture, such as the x86. We also do
not generally know the input size. Therefore, we formulate a restricted version
of Theorem 5 that is in terms of the number of steps (i.e., machine instructions)
used.
Here t is an integer, rather than a function of the input size. It is customary
in complexity theory to express results of this type using unary notation for the
bound. That is, the integer t is represented as
(cid:124) (cid:123)(cid:122) (cid:125)
11··· 1
t times
or, more succinctly, 1t. The reason we use this is so that algorithms of polynomial
time complexity in t are expressed asymptotically as O(tk) instead of O((lg t)k)
for some k > 0.
Deﬁnition 9 (Time Guarantee Unpacking Problem). Given: RASP pro-
gram P and unary integer 1t. Question: Is there an input x with such that P
unpacks on input x within time t?
Notice that we may also assume that l(x) ≤ t in this problem since input
cost is one of the terms summed to derive execution time for P .
Theorem 6. The Time Guarantee Unpacking Problem is NP-complete.
Proof. The proof has two steps: we show that the bounded unpacking problem
is in NP and exhibit a reduction from 3-sat to it.
Bounded unpacking behavior is in NP. We simply execute P under Rasputin for
up to time t. Whenever Rasputin requires an input integer, we nondeterminis-
tically generate an integer j with l(j) ≤ t. After each step of the emulation,
we check for unpacking behavior. This is a nondeterministic polynomial time
algorithm.
Bounded unpacking behavior is NP-hard. We reduce (in polynomial time) 3-sat
to the Time Guarantee Unpacking Problem. 3-sat is the problem of deciding if a
given 3-cnf Boolean formula ϕ is satisﬁable. A conjunctive normal form (CNF)
formula is a conjunction of clauses; a clause is a disjunction of literals; a literal
is a Boolean variable x or its negation ¬x. In a 3-cnf formula, each clause has
exactly three disjuncts.
In order to satisfy a 3-sat formula ϕ, we need an assignment. An assign-
ment α is a function from ϕ’s variables into {0, 1}. A negative literal ¬x is
satisﬁed if α(x) = 0, and unsatisﬁed otherwise. A positive literal x is satis-
ﬁed if α(x) = 1, and unsatisﬁed otherwise. A clause is satisﬁed if any of its
literals are satisﬁed. And a formula is satisﬁed if all of its clauses are satis-
ﬁed. For example, a satisfying assignment of the following Boolean formula is
α(x1) = 1, α(x2) = 0, α(x3) = 0, α(x4) = 1.
(x1 ∨ x2 ∨ ¬x3) ∧ (¬x1 ∨ x3 ∨ x4) ∧ (x2 ∨ x3 ∨ x4)
(2)
Let ϕ be an arbitrary 3-sat formula whose variables are x1, x2, . . . , xn. We
can encode ϕ as follows:
– Each variable xi is represented as a positive integer i.
– Each negated variable ¬xi is represented as a negative integer −i.
– A 3-cnf formula is represented by a sequence of integers representing its
literals in the order they occur in the list of clauses, followed by a terminating
0. For example, formula 2 above is represented as
1, 2,−3,−1, 3, 4, 2, 3, 4, 0.
Since each clause has exactly three literals, this is an unambiguous represen-
tation.
Now it is a fairly simple task to write a polynomial time RASP program, which
we dub Raspberry, to check satisﬁability of 3-cnf formulas. Raspberry takes as
input a sequence (cid:104)ϕ, w(cid:105) consisting of the representation of ϕ, followed by a 0,
followed by a sequence of n 0s and 1s representing an assignment to the Boolean
variables x1, x2, . . . , xn, followed by a −1. Raspberry stores these integers in con-
secutive memory locations and then cycles through the integers representing ϕ
to verify that in each clause at least one literal is satisﬁed.
Just as we turned Rasputin to the dark side by transforming it into Evil
Rasputin, we transform Raspberry, an innocent program, into Wild Raspberry, a
program that unpacks if it determines that w is a satisfying truth assignment
for ϕ. Finally, for each Boolean formula ϕ, we create a RASP program Wild
Raspberryϕ, where ϕ is hard coded into the data set. The mapping from ϕ to
Wild Raspberryϕ is polynomial time computable, and ϕ is satisﬁable if and only
if Wild Raspberryϕ exhibits unpacking behavior within time t, where t is deter-
mined by the polynomial time bound for Raspberry. This is a reduction from an
NP-complete problem 3-sat to the Time Guarantee Unpacking Problem, thus
(cid:117)(cid:116)
proving NP-completeness of that problem.
We have shown that the bounded unpacking problem is not only decid-
able, but NP-complete. A natural reaction to these results is, “Undecidable,
NP-complete – doesn’t matter. Either way we can’t solve it!” The next section
challenges this idea by reviewing approaches to intractable problems from other
disciplines.
4 Approaching the Intractable
Intractable problems are encountered in many disciplines; we might therefore
expect a large diversity of approaches to solving these problems. Indeed, there
are many diﬀerent algorithms and models, but eﬀective approaches exploit a
combination of optimization and parallelism. Important recent breakthroughs
in computer science and computational science are made possible by exactly
these techniques:
– Special-purpose hardware was built for Anton, a molecular dynamics simu-
lation machine [33].
– Stevens et al. demonstrate chosen-preﬁx collisions in the MD5 cryptographic
hash algorithm, computed in 6 months with thousands of machines [34].
Problems from many disciplines have been proven NP-complete [35]. In the
particular domain of hardware veriﬁcation, NP-complete problems have been a
central topic of investigation for the past three decades. The focus of much of the
work has been in increasingly clever search strategies. In the following section,
we examine this ﬁeld in depth in order to gather some lessons learned.
4.1 Formal Hardware Veriﬁcation and the Intractable
Formal modeling and veriﬁcation of complex hardware and software systems has
advanced signiﬁcantly over the past three decades, and formal techniques are
increasingly seen as a critical complement to traditional veriﬁcation approaches,
such as simulation and emulation. The foundational work was established in the
early 1980s with the introduction of model checking (MC) as a framework for
reasoning about the properties of transition systems [36, 37]. A model checker’s
fundamental goal is to prove that states that violate a given speciﬁcation f
cannot be reached from M ’s initial (reset) states or to provide a counterexample
trace (a state sequence) that serves as a witness for how f can be violated.
Computationally, to verify the query “does M satisfy f ” a model checker needs
to perform some sort of (direct or indirect) reachability analysis in the state
space of M . Since a transition system with n state elements (e.g., ﬂip-ﬂops) has
2n states, model checkers have had to cope with the so-called state explosion
problem, and much of the research in MC over the past thirty years has been
primarily focused on attacking this problem [38]. MC for these properties (e.g.,
“X is true in all states” or “we shall not reach state Y”) is NP-complete [39].
The next few paragraphs review some signiﬁcant milestones along this journey.
The EMC model checker [40], developed in the early 1980s, was based on an
explicit representation of the state transition system. This system was able to
handle up to about 105 states or roughly 16 ﬂip-ﬂops. The system was based on
a naive enumeration of each state.
Subsequent checkers leveraged the key insight of implicit state representa-
tions. The use of binary decision diagrams (BDDs) to represent sets of states
by characteristic Boolean functions enabled MC to scale to about 1020 states or
about 66 ﬂip-ﬂops [41]. The key insight here was to reason about sets of related
states as a unit, rather than as individuals.
The development of modern conﬂict-driven clause-learning (CDCL) Boolean
satisﬁability (SAT) solvers in the mid 1990s [42–44] provided another opportu-
nity to scale model checkers to larger design sizes. This use of SAT solvers to
perform MC was dubbed bounded model checking (BMC) [45] to contrast it
with the unbounded BDD-based MC and it proved extremely useful for ﬁnding
“shallow bugs.” BMC extended the range of designs that could be handled to
those containing several hundred ﬂip-ﬂops and relatively short counterexamples
(10 steps or less) [46]. The key insight of this approach was to trade completeness
(it would miss bugs) for scalability (it would ﬁnd shallow bugs quickly).
An orthogonal attack on complexity was based on abstracting the underly-
ing transition system. Abstraction methods create an over-approximation of the
transition relation with the hope of making it more tractable for analysis. The
technique was popularized by Clarke et al. [47, 48] who showed its eﬀectiveness
in scaling symbolic MC by verifying a hardware design containing about 500 ﬂip-
ﬂops. The key insight was a system absent of some of its details was sometimes
suﬃcient for proving the properties of interest.
The latest development to address the state explosion problem in MC is a
clever deployment of incremental SAT solving to check the property f without
the need to unroll the transition relation. The original idea was described by
Bradley et al. [49, 50] and implemented in the IC3 tool. IC3 is able to solve
systems with around 5,000 ﬂip-ﬂops. The key insight here was to summarize
important facts about program state transitions on demand as the search pro-
gresses.
We have seen a variety of clever search strategies that help increase the de-
sign sizes for which we can prove properties. Implicit and over-approximate state
representations, more intelligent underlying solvers, and on-demand characteri-
zation of important facts all contributed to current methods that can precisely
analyze systems with thousands of ﬂip-ﬂops.
5 Malware analysis, Reprise
We have shown, under realistic assumptions about victim machines and attacker
resources, that several important malware analysis questions are decidable rather
than undecidable, as previously thought. The above example in hardware veriﬁ-
cation highlights a sequence of approaches for dealing with intractabile problems.
In general, when optimization [51] and parallelization [52] reach their limits, we
employ a variety of approaches to coping with intractability [53]:
– Finding good average case algorithms rather than worse case algorthims (i.e.,
those algorithms which are fast most of the time);
– Using approximate algorithms (i.e., algorithms that provide bounds on qual-
ity and speed, but are not optimal);
– Qualitatively changing the amount of computation available (i.e, using FP-
GAs and GPUs or more radically, and more speculatively, quantum comput-
ing);
– Examining parameterization of the problems for which solutions are possible
(i.e., acknowledging that an algorithm may not need to work on all inputs);
– The use of heuristics (i.e., algorithms that ﬁnd solutions which are “good
enough”).
An important consequence of our results is the ability to derive ground truth
for the community. Even if precise systems do not scale to realistic malware
rates (tens of thousands per day), they still can be used to evaluate more scalable
techniques by providing ground truth. It should be possible to construct a system
where, if malware A and B are variants of one another, the system always tells
you so. It might take an inordinate amount of time to do so, but, when it ﬁnally
does, one has very high conﬁdence in the result. We are investigating exactly
this question.
Limitations. It is important to note that we do not address virtualization ob-
fuscators [31, 54]; we only address traditional unpacking mechanisms. We have
not found a crisp deﬁnition of what it means for a program to be virtualization-
obfuscated that does not depend on the particular details of the obfuscation
mechanism. If we address a particular virtualization obfuscator, we may be able
to formulate detection problems that are decidable under assumptions similar
to those presented here.
Conclusion. We have shown that by either restricting the space or the time
that a program is allowed, we can decide whether a program unpacks; indeed,
it is NP-complete. A natural question to ask is: for how many steps should
we execute? While we do not yet have a deﬁnitive answer for the question,
we instead oﬀer the following vision of the future. Imagine a world where you
download an untrusted executable and your personal anti-virus (AV) product
performs a combined static and dynamic analysis on your laptop. In a minute or
two, the AV product says, “Program this-is-definitely-not-a-virus.exe
will not unpack, nor does it evolve into a known virus for the next 6 months.”
This would be a fantastic guarantee!
Although this situation seems far from reality, it is not out of the question.
If – with a combination of abstraction, reﬁnement, clever search strategies, and
perhaps even special purpose hardware – we can produce time-based guarantees
of (a lack of) malicious behavior, we will have reached an important milestone
in the automated analysis of malicious software.
References
1. Royal, P., Halpin, M., Dagon, D., Edmonds, R., Lee, W.: PolyUnpack: Automating
the hidden-code extraction of unpack-executing malware. In: Annual Computer
Security Applications Conference, IEEE Computer Society (2006) 289–300
2. Christodorescu, M., Jha, S., Seshia, S.A., Song, D.X., Bryant, R.E.: Semantics-
aware malware detection. In: Security and Privacy, IEEE Computer Society (2005)