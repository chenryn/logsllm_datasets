```
# Read metrics about swarm tasks and services
[[inputs.swarm]]
  # Docker Endpoint
  #   To use TCP, set endpoint = "tcp://[ip]:[port]"
#   To use environment variables (ie, docker-machine), set endpoint = 
 "ENV"
  endpoint = "unix:///var/run/docker.sock"
  timeout = “10s”
```
首先，按如下方式设置一个 InfluxDB 实例:
```
 $ docker run -d \
 -p 8083:8083 \
 -p 8086:8086 \
 --expose 8090 \
 --expose 8099 \
 -e PRE_CREATE_DB=telegraf \
 --name influxsrv
 tutum/influxdb
```
然后，设置一个 Grafana 实例，如下所示:
```
docker run -d \
 -p 80:3000 \
 -e HTTP_USER=admin \
 -e HTTP_PASS=admin \
 -e INFLUXDB_HOST=$(belt ip influxdb) \
 -e INFLUXDB_PORT=8086 \
 -e INFLUXDB_NAME=telegraf \
 -e INFLUXDB_USER=root \
 -e INFLUXDB_PASS=root \
 --name grafana \
 grafana/grafana
```
在我们设置了 Grafana 的实例之后，我们可以从以下 JSON 配置创建仪表板:
[https://objects-us-west-1 . dream . io/swarm 2k/swarm 2k _ final _ grafana _ dashboard . JSON](https://objects-us-west-1.dream.io/swarm2k/swarm2k_final_grafana_dashboard.json)
要将仪表板连接到 InfluxDB，我们必须定义默认数据源，并将其指向 InfluxDB 主机端口`8086`。下面是定义数据源的 JSON 配置。将`$INFLUX_DB_IP`替换为您的英菲尼克斯数据库实例。
```
{
 "name":"telegraf",
 "type":"influxdb",
 "access":"proxy",
 "url":"http://$INFLUX_DB_IP:8086",
 "user":"root",
 "password":"root",
 "database":"telegraf",
 "basicAuth":true,
 "basicAuthUser":"admin",
 "basicAuthPassword":"admin",
 "withCredentials":false,
 "isDefault":true
}
```
将所有内容链接在一起后，我们会看到一个如下所示的仪表板:
![Telegraf Swarm plugin](img/image_04_007.jpg)
# Swarm3k
Swarm3k 是第二个试图用 Swarm 模式形成一个非常大的 Docker 集群的合作项目。该项目于 2016 年 10 月 28 日启动，超过 50 名个人和公司加入了该项目。
Sematext 是最早通过提供 Docker 监控和日志解决方案来帮助我们的公司之一。它们成为了 Swarm3k 的官方监控系统。斯特凡、奥蒂斯和他们的团队从一开始就为我们提供了极好的支持。
![Swarm3k](img/image_04_008.jpg)
*Sematext Dashboard*
Sematext 是目前唯一一家允许我们将监控代理部署为全球 Docker 服务的 Docker 监控公司。这种部署模式大大简化了监控过程。
## 群集 3k 设置和工作负载
我们的目标是 3000 个节点，但最终，我们成功地形成了一个工作的、地理上分布的 4700 节点 Docker Swarm 集群。
管理人员的规格是同一数据中心的高内存 128GB 数字海洋节点，每个节点有 16 个虚拟存储库。
集群初始化配置包括一个未记录的“KeepOldSnapshots”，它告诉 Swarm 模式不要删除，而是保留所有数据快照供以后分析。每个管理器的 Docker 守护程序都是在 DEBUG 模式下启动的，以便随时获取更多信息..
正如我们在上一节中所展示的，我们使用 belt 来设置经理，并等待贡献者加入他们的员工。
Docker 1.12.3 用于经理，而 workers 是 1.12.2 和 1.12.3 的混合。我们在*入口*和*覆盖*网络上组织服务。
我们计划了以下两种工作负载:
*   带有 Wordpress 集群的 MySQL
*   C1M(100 万容器)
25 个节点旨在形成一个 MySQL 集群。首先，我们创建了一个覆盖网络`mydb`:
```
$ docker network create -d overlay mydb
```
然后，我们准备了以下`entrypoint.sh`脚本:
```
#!/bin/bash
ETCD_SUBNET=${ETCD_SUBNET:-10.0.0.0}
ETCD_HOST=$(ip route get $ETCD_SUBNET | awk 'NR==1 {print $NF}')
/usr/local/bin/etcd \
 -name etcd0 \
 -advertise-client-urls 
       http://${ETCD_HOST}:2379,http://${ETCD_HOST}:4001 \
 -listen-client-urls http://0.0.0.0:2379,http://0.0.0.0:4001 \
 -initial-advertise-peer-urls http://${ETCD_HOST}:2380 \
 -listen-peer-urls http://0.0.0.0:2380 \
 -initial-cluster-token etcd-cluster-1 \
 -initial-cluster etcd0=http://${ETCD_HOST}:2380 \
 -initial-cluster-state new
```
然后，我们将为我们的特殊版本的 Etcd 准备一个新的 Dockerfile，如下所示:
```
FROM quay.io/coreos/etcd
COPY entrypoint.sh /usr/local/bin/entrypoint.sh
RUN  chmod +x /usr/local/bin/entrypoint.sh
ENTRYPOINT ['/usr/local/bin/entrypoint.sh'] 
```
开始使用前别忘了用`$ docker build -t chanwit/etcd.`来打造。
第三，我们启动了一个 Etcd 节点，作为 MySQL 集群的中心发现服务，如下所示:
```
$ docker service create --name etcd --network mydb chanwit/etcd
```
通过检查 Etcd 的虚拟 IP，我们将获得如下服务 VIP:
```
$ docker service inspect etcd -f "{{ .Endpoint.VirtualIPs }}"
[{... 10.0.0.2/24}]
```
有了这些信息，我们创建了我们的`mysql`服务，它可以在任何程度上扩展。看看下面的例子:
```
docker service create \
--name mysql \
-p 3306:3306 \
--network mydb \
--env MYSQL_ROOT_PASSWORD=mypassword \
--env DISCOVERY_SERVICE=10.0.0.2:2379 \
--env XTRABACKUP_PASSWORD=mypassword \
--env CLUSTER_NAME=galera \
--mount "type=bind,src=/var/lib/mysql,dst=/var/lib/mysql" \
perconalab/percona-xtradb-cluster:5.6
```
由于 Libnetwork 错误，我们在 mynet 和入口网络中都遇到了一些 IP 地址问题；查看[https://github.com/docker/docker/issues/24637](https://github.com/docker/docker/issues/24637)了解更多信息。我们通过将集群只绑定到一个*单个*覆盖网络`mydb.`来解决这个问题
现在，我们尝试了一个 WordPress 容器的复制因子为 1 的`docker service create`。我们故意没有控制 Wordpress 容器将被安排在哪里。然而，当我们试图将这个 Wordpress 服务连接到 MySQL 服务时，连接多次超时。我们的结论是，对于这种规模的 Wordpress + MySQL 组合，最好对集群施加一些限制，使所有服务在同一个数据中心一起运行。
## 大规模群体表现
您还从这个问题中了解到，覆盖网络的性能在很大程度上取决于每台主机上网络配置的正确调整。正如一位 Docker 工程师所建议的，当 ARP 请求太多(网络很大)并且每台主机都无法回复时，我们可能会遇到“邻居表溢出”错误。这些是我们在 Docker 主机上增加的可调参数，用于修复以下行为:
```
net.ipv4.neigh.default.gc_thresh1 = 30000 
    net.ipv4.neigh.default.gc_thresh2 = 32000    
    net.ipv4.neigh.default.gc_thresh3 = 32768
```
这里，`gc_thresh1`是期望的主机数量，`gc_thresh2`是软限制，`gc_thresh3`是硬限制。
因此，当 MySQL + Wordpress 测试失败时，我们改变了计划，在路由网格上实验 NGINX。
入口网络设置有/16 池，因此最多可容纳 64，000 个 IP 地址。根据亚历克斯·埃利斯的建议，我们从 4000 英镑(4000 英镑！)集群上的 NGINX 容器。在这个测试中，节点仍然进进出出。最终，几分钟后，NGINX 服务启动，路由网格形成。即使某些节点不断出现故障，它也能正常工作，因此该测试验证了 1.12.3 中的路由网格是坚如磐石的，并且已经为生产做好了准备。然后我们停止了 NGINX 服务，开始测试尽可能多的容器的调度，目标是 100 万个，一百万个。
因此，我们创建了一个“高山之巅”服务，就像我们为 Swarm2k 所做的那样。但是，这次的调度速度稍微慢了一点。我们在大约 30 分钟内到达了 47，000 个容器。因此，我们预计用 1，000，000 个容器填满集群大约需要 10.6 小时。
由于预计这需要太多时间，我们决定再次改变计划，购买 7 万个容器。
![Swarm performance at a scale](img/image_04_009.jpg)
调度大量容器(**Docker 规模 alpine=70000** )使集群不堪重负。这创建了一个巨大的调度队列，在所有 70，000 个容器完成调度之前，该队列不会提交。因此，当我们决定关闭管理器时，所有的调度任务都消失了，集群变得不稳定，因为 Raft 日志被破坏了。
在途中，我们希望通过收集 CPU 配置文件信息来检查的最有趣的事情之一是查看哪些 Swarm 原语正在更多地加载集群。
![Swarm performance at a scale](img/image_04_010.jpg)
在这里，我们可以看到只有 0.42%的 CPU 花在了调度算法上。我们通过一些近似得出结论，1.12 版本中的 Docker Swarm 调度算法相当快。这意味着有机会引入更复杂的调度算法，通过增加一些可接受的开销，可以在 Swarm 的未来版本中获得更好的资源利用率。
![Swarm performance at a scale](img/image_04_011.jpg)
此外，我们发现大量的 CPU 周期花费在节点通信上。在这里，我们可以看到 list 成员列表层。它使用了大约 12%的总 CPU。
![Swarm performance at a scale](img/image_04_012.jpg)
然而，似乎主要的 CPU 消费者是 Raft，它也在这里显著地调用了 Go 垃圾收集器。这使用了大约 30%的总 CPU。
# Swarm2k 和 Swarm3k 的经验教训
以下是你从这些实验中学到的总结:
*   对于一大群工人来说，管理者需要大量的 CPU。每当 Raft 恢复过程开始时，CPU 就会激增。
*   如果领先的管理器死亡，最好在那个节点上停止 Docker，等待集群再次变得稳定，使用 n-1 个管理器。
*   尽可能减少快照保留。默认的 Docker Swarm 配置就可以了。持久化 Raft 快照会使用额外的 CPU。
*   数千个节点需要管理大量资源，包括 CPU 和网络带宽。尝试保持服务和管理器的拓扑在地理上紧凑。
*   数十万个任务需要高内存节点。
*   现在，为了稳定的生产设置，建议最多使用 500-1000 个节点。
*   如果经理们似乎被卡住了，等待；他们最终会康复的。
*   `advertise-addr`参数是路由网格工作所必需的。
*   将计算节点尽可能靠近数据节点。覆盖网络很棒，需要对所有主机的 Linux 网络配置进行调整，以使其发挥最佳作用。
*   DockerSwarm 体模式是稳健的。即使不可预测的网络将这个巨大的集群连接在一起，也没有任务失败。
对于 Swarm3k，我们要感谢所有的英雄:`@FlorianHeigl`；`@jmaitrehenry`来自 PetalMD`@everett_toews`来自泰国互联网 Rackspace`@squeaky_pl`、`@neverlock`、`@tomwillfixit`来自 Demonware`@sujaypillai`来自贾比尔；`@pilgrimstack`来自 OVH；`@ajeetsraina`来自 Collabnix`@AorJoa`和`@PNgoenthai`来自艾雅拉集群；`@GroupSprint3r`、`@toughIQ`、`@mrnonaki`、`@zinuzoid`来自 HotelQuickly`@_EthanHunt_`；`@packethost`来自 Packet.io`@ContainerizeT-ContainerizeThis`、大会；`@_pascalandy`来自 FirePress@来自 TRAXxs 的 lucjuggery@ alexellisuk@来自湖里的斯维加；@ BretFisher`@voodootikigod`来自新兴技术顾问；`@AlexPostID`；`@gianarb`出自 ThumpFlow`@Rucknar`、`@lherrerabenitez`；`@abhisak`来自帕尼科技；和耐克威集团的`@djalal`。
我们还要再次感谢 Sematext 提供了一流的 Docker 监控系统；和数字海洋为我们提供所有资源。
# 总结
在这一章中，我们向您展示了如何使用传送带在数字海洋上部署两个巨大的 Swarm 集群。这些故事给了你很多可以学习的东西。我们总结了经验教训，并概述了运行大规模生产群的一些技巧。在旅途中，我们还引入了一些 Swarm 特性，例如服务和安全性，并讨论了管理器的拓扑结构。在下一章中，我们将详细讨论如何管理 Swarm。包括的主题将是使用皮带、脚本和 Ansible 部署工人、管理节点、监控和图形界面。