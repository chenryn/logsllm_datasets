### Label Propagation and Static Analysis in Sensitive Data Handling

The label of an identifier, such as `name[x]`, where `x` is an index variable, is considered sensitive if the array `name` is known to be sensitive. The sensitivity of `x` can only be determined through static analysis. If any element of `name` is sensitive, the label should be propagated to the entire expression. For complex expressions, all attributes are deemed sensitive if any part of the expression is sensitive. This approach, while sometimes overly cautious, is generally acceptable and often aligns with legitimate use cases, as observed in our study (Section 4).

However, issues arise when statements involve sub-expressions that are not statically identifiable as sensitive. In such cases, the static analysis may fail to propagate the correct labels, leading to potential data leaks. For example, if a script contains a function call or a DOM operation that involves sensitive data, and the static analysis does not recognize this, it may not apply the appropriate label.

### Handling Eval() and Sensitive Data

The `eval()` function runs a string as code, which can read or write any variables, including those carrying sensitive information. Prior work [26] found that most legitimate uses of `eval()` do not include sensitive data. Our approach, inspired by the Bell-LaPadula (BLP) model, treats all outputs of `eval()` as sensitive. This ensures that, in most cases, our analysis remains robust, even if it introduces some false positives.

### Rule Generation for Data-Leak Detection

After identifying a statement that could leak sensitive information, the Data-Rule Generator (DRG) builds a tree that fingerprints individual paths with sequences of function calls and DOM operations. Once a data-leaking path is found, the DRG records its sequence, along with the hash value of the script, in a database. Each sequence is annotated with the program location where sensitive data is read and the output function where the data flows out of the script.

### Evaluation of Techniques

Our experimental study aims to evaluate the effectiveness of our techniques in controlling information flows within mashups. We tested our prototype on 10 real client-side mashups, including popular ones like Google Gmail Gadget, Facebook Gadget, and Google Finance Portfolios. These mashups have tens of thousands, or even millions, of users.

#### Effectiveness

To evaluate the effectiveness of our prototype, we first used our labeling tool to mark sensitive items, such as login boxes and user inputs. We then performed a differential analysis, executing each mashup twice with different contents. A Firefox add-on, Firebug, intercepted and recorded all traffic generated by the browser, including HTML requests and XMLHttpRequests.

In the experiment, we checked the Firebug log to determine if the recipient of the data was in the same domain as the labeled object. If the recipient was in a different domain, our prototype blocked the attempt to transfer sensitive data. We also checked for false positives and false negatives.

#### Findings

For each mashup, our prototype successfully identified and controlled sensitive data flows. Among the 10 mashups, seven transferred sensitive information to the same domains, and one was found to leak information to a different domain. Our prototype blocked this leak, resulting in zero false positives and false negatives.

### Performance Evaluation

We evaluated the performance of our prototype under three scenarios: "native" (without our implementation), "analysis and monitor" (analyzing and monitoring scripts), and "monitor only" (re-executing previously analyzed scripts). The results, shown in Table 2, indicate that the overhead ranges from 50% to 500% when a script is first encountered. However, for frequently used scripts, the overhead is typically below 20%.

### Related Work

Access control in mashups is a critical issue due to the cross-domain nature of these applications, which contradicts the Same-Origin Policy. Recent solutions include MashupOS [39], OMash [22], and SMash [31]. These approaches use abstractions and mediated cross-domain access to protect both content providers and integrators. Our model extends these ideas by incorporating a more comprehensive rule generation and enforcement mechanism.