When the number of layers in the GRU and the number of layers in the hidden
size do not match, the GPU throws an error while the CPU does not.
The following snippet to illustrates the same:
          rnn = torch.nn.GRU(input_size=5,hidden_size=4)
          x = torch.randn(3, 4, 5)
          hidden = torch.autograd.Variable(torch.randn(2, 4, 4))
          x = torch.autograd.Variable(x)
          if torch.cuda.is_available():
            rnn = rnn.cuda()
            x = x.cuda()
            hidden = hidden.cuda()
          rnn(x, hidden)