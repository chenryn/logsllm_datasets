## PostgreSQL 流式数据处理(聚合、过滤、转换...)系列 - 6          
### 作者                                                                   
digoal                                                                    
### 日期                                                                   
2017-01-05                                                                        
### 标签                                                                  
PostgreSQL , 流式 , 函数 , 流式处理 , 异步统计 , count , group , agg , 触发器 , xid , 事务隔离 , 异步气泡 , gap , function , 串行处理
----                                                                  
## 背景               
2013年帮朋友做的方案。写了一些列文档来解决当时某个大数据BI平台的异步流式数据处理的功能。            
逐步优化，化繁为简。               
在业务层面，统计，数据的过滤，数据的清洗，数据的事件触发等。是比较常见的需求。                
比如以COUNT就是一个很典型的例子。            
在9.2以前全表的count只能通过扫描全表来得到, 即使有pk也必须扫描全表.            
9.2版本增加了index only scan的功能, count(*)可以通过仅仅扫描pk就可以得到.            
但是如果是一个比较大的表, pk也是很大的, 扫描pk也是个不小的开销.            
到了9.6，开始支持并行查询，通过并行，一张1亿的表，COUNT可能只需要几百毫秒。这是一个质的飞跃。（但是还有很多时候用并行并不是最好的）            
另外社区也除了一个流式处理的数据库，pipelineDB，但是它的社区版本限制了一个DATABASE只能使用1024个流视图，在编码的地方使用了1BYTE存储CV。            
那么回到postgresql数据库本身，有没有办法来优化count全表的操作呢, 如果你的场景真的有必要频繁的count全表, 那么可以尝试一下使用以下方法来优化你的场景.            
## 正文            
前五篇关于PostgreSQL实时和非实时数据统计的案例如下 :   
http://blog.163.com/digoal@126/blog/static/163877040201331252945440/  
http://blog.163.com/digoal@126/blog/static/16387704020133151402415/  
http://blog.163.com/digoal@126/blog/static/16387704020133155179877/  
http://blog.163.com/digoal@126/blog/static/16387704020133156636579/  
http://blog.163.com/digoal@126/blog/static/16387704020133218305242/  
本文主要添加一个动态的新增统计维度的功能.  
## 详细的实施过程  
测试表 :   
```  
create table log   
(  
  id serial primary key,   
  xid int8 default txid_current() not null,   
  c1 int not null,   
  c2 int not null,   
  c3 int not null,   
  c4 text not null,   
  crt_time timestamp default now()  
);  
create index idx_log_1 on log(xid);  
```  
存放count(*)的表, 假设经常需要按log.c1以及log.crt_time分天, 周, 月, 年进行count(*)  
```  
create table log_c1_cnt_day (c1 int, cnt int8, stat_time text, primary key(c1,stat_time));  
create table log_c1_cnt_week (c1 int, cnt int8, stat_time text, primary key(c1,stat_time));  
create table log_c1_cnt_month (c1 int, cnt int8, stat_time text, primary key(c1,stat_time));  
create table log_c1_cnt_year (c1 int, cnt int8, stat_time text, primary key(c1,stat_time));  
```  
存放count(*)的表, 假设经常需要按log.c2, log.c3以及log.crt_time分天, 周, 月, 年进行count(*)  
```  
create table log_c2_c3_cnt_day (c2 int, c3 int, cnt int8, stat_time text, primary key(c2,c3,stat_time));  
create table log_c2_c3_cnt_week (c2 int, c3 int, cnt int8, stat_time text, primary key(c2,c3,stat_time));  
create table log_c2_c3_cnt_month (c2 int, c3 int, cnt int8, stat_time text, primary key(c2,c3,stat_time));  
create table log_c2_c3_cnt_year (c2 int, c3 int, cnt int8, stat_time text, primary key(c2,c3,stat_time));  
```  
插入测试数据  
```  
insert into log (c1,c2,c3,c4) values (1,1,1,1);  
insert into log (c1,c2,c3,c4) values (2,2,2,2);  
```  
验证  
```  
digoal=# select * from log;  
 id |    xid    | c1 | c2 | c3 | c4 |          crt_time            
----+-----------+----+----+----+----+----------------------------  
  1 | 480125659 |  1 |  1 |  1 | 1  | 2013-04-21 20:55:45.907713  
  2 | 480125660 |  2 |  2 |  2 | 2  | 2013-04-21 20:55:46.286933  
(2 rows)  
```  
创建分析注册表, 记录每个明细表每次分析的截止xid, xip.  
xid 记录统计到哪个xid了, xip记录当前活动事务, 不计入当前统计范畴. 避免气泡问题.  
```  
create table log_read   
(  
tablename name not null,   
xid int8 not null,   
xip int8[],   
xip_res int8[],  -- 用于与xid比对的数据. 必须保留所有>=xid的xip信息.  
mod_time timestamp,   
primary key (tablename)  
);  
```  
插入初始记录, 表的初始记录xid取值范围( >=0 and  0 .';  
    return;  
  end if;  
  -- 串行处理, 如果不能获得锁则直接退出. 确保v_advisory_xact_lock全局唯一.  
  v_advisory_xact_lock := 1;  
  if not pg_try_advisory_xact_lock(v_advisory_xact_lock) then  
    raise notice 'Another function is calling, this call will exit.';  
    return;  
  end if;  
  -- 生成统计维度, 没有则直接退出  
  perform 1 from log_read_func where tablename='log' limit 1;  
  if not found then  
    raise notice 'No func in log_read_func with tablename:%.', 'log';  
    return;  
  else  
    select array_agg(func) into v_func_agg from log_read_func where tablename='log';  
  end if;  
  -- 生成 xid snapshot 数据.  
  v_xid_snap := txid_current_snapshot();  
  v_xmin := txid_snapshot_xmin(v_xid_snap);  
  v_xmax := txid_snapshot_xmax(v_xid_snap);  
  select array_agg(t) into v_xip from txid_snapshot_xip(v_xid_snap) g(t);  
  -- 取v_log_read_log_xid截止值, v_log_read_log_xip数组.  
  select xid,xip,xip_res into v_log_read_log_xid,v_log_read_log_xip,v_log_read_log_xip_res from log_read where tablename='log';  
  if not found then  
    raise notice 'log_read no log entry. please add it in log_read table first.';  
    return;  
  end if;  
  -- 生成v_log_read_func_xip.  
  -- 必须放在更新log_read之前, 否则取到的就是更新后的数据了.  
  v_log_read_func_xip := array_cat(v_log_read_log_xip, v_xip);  
  -- 取log1(取非xip中的数据, 隔离log2操作)  
  -- 取xid临界点  
  select max(xid) into v_log_read_log_xid_update from (select xid from log where xid > v_log_read_log_xid and xid  v_log_read_log_xid and xidv_log_read_log_xid_update;  
  -- 生成log do数组  
  select array_agg(log) into v_log_doxip from log where xid in (select * from unnest(v_log_read_log_xip_do));  
  -- 更新log_read(tablename=log)  
  update log_read set   
    xip=v_log_read_log_xip_update,   
    xid=v_log_read_log_xid_update,   
    xip_res=v_log_read_log_xip_res_update,  
    mod_time=now()   
  where tablename='log';  
  -- raise notice 'log_read.oldxip(log): %.', v_log_read_log_xip;  
  -- raise notice 'log_read.newxip(log): %.', v_log_read_log_xip_update;  
  -- raise notice 'log_read.newxipres(log): %.', v_log_read_log_xip_res_update;  
  -- 分析函数可以另外写, 在此调用.  