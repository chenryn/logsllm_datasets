collected without any injected noise. PESQ is a significant indicator
of potential speech leakage, and the results for our samples suggest
the quality of speech that can be acquired via our attack model (to
achieve speech recognition) is on par with an actual microphone.
7 CLASSIFICATION RESULTS
In this section we will discuss the accuracies we achieved for speech
(digit) recognition, speaker identification, and gender identification
tasks. We attempt each of these tasks under a few different pa-
rameter settings. Table 3 summarizes the classification accuracies
observed for each speech task, feature set, and speech loudness
(SPL) that we consider.
Digit Recognition: For digit recognition, 40% classification accu-
racy was achieved when the model was trained on the full set of
144 features and an 80:20 split. When the feature set was filtered to
the 17 most significant features, we observe an increased maximum
accuracy of 46% for the 90:10 split. Interestingly, both of these accu-
racies were observed for the 65 dB speech data. Although 46% may
not sound impressive, if we consider that random guessing has a
10% classification accuracy (for classifying the 10 digits), we see that
the accuracies observed in our experiments are an improvement.
The 10-fold Cross Validation results confirm that the classification
accuracy increases as the source speech loudness is increased past
60 dB. Interestingly, the results show that the 65 dB and 70 dB
source speech have similar classification results, with the 65 dB
speech achieving a slightly better classification accuracy with the
filtered feature set. This may suggest the Alexa noise cancellation
that is applied is similarly effective for both speech SPLs, and that
there is no significant benefit for the loudest speech level (70 dB).
Speaker Identification: The speaker identification accuracies that
we see are also an improvement on the 10% accuracy of random
guessing (for classifying the 10 speaker). When we trained our
model on the full set of features we see a maximum classification
accuracy of 51% for the 80:20 split. Similarly, we observed a maxi-
mum accuracy of 50% for the 90:10 split when the model was trained
on the filtered set of features. 10-fold Cross Validation revealed a
422ACSAC ’21, December 6–10, 2021, Virtual Event, USA
Payton Walker and Nitesh Saxena
different pattern of success for speaker identification compared to
what we observed for digit recognition. The results show that the 65
dB source speech had the best classification results for both feature
sets. This indicates that Alexa noise cancellation is able to preserve
more speech frequencies (e.g., those needed for speaker identifi-
cation) when the speech is around 65 dB. It’s possible that louder
volume speech may produce frequencies at power levels that can
be confused with that of noise, and are therefore removed during
noise cancellation (inline with observations from digit recognition).
Gender Identification: We observe decent classification accura-
cies for the gender recognition task for both feature sets. When we
trained on the full set of features, we achieved 80% classification ac-
curacy for both train/test data splits. And when we used the filtered
set of features, we observed a maximum accuracy of 78% for the
90:10 data split. This is a significant improvement to the 50% accu-
racy achieved through random guessing (classifying two genders),
indicating the clear potential for successful gender recognition by
an attacker. 10-fold Cross Validation for the gender identification
task revealed the best classification results were achieved when
speech was at the lower volumes (60, 65 dB). Similar to our previous
observations, these results suggest that gender-specific information
is better preserved at volumes lower than the maximum we tested
(70 dB). Again, at the louder volume level the power of the speech
frequencies may be confused with noise and get removed. And a
5%+ decrease in classification accuracy (for both feature sets) when
the speech was at 70 dB suggests important speech information
required for gender identification is lost at that volume.
Song Recognition: Lastly, we conducted a small evaluation of
song recognition potential using the recovered and processed sam-
ples from Alexa Voice History. We played two songs and isolated
short clips (5 seconds) from the beginning, middle, and end of each
song. These samples consisted of a mix of music with and without
spoken lyrics. To evaluate these samples we used the Shazam song
recognition app which employs an efficient, scalable, noise and
distortion resistant song identification algorithm [44]. We found
that all song samples that were prepared could be successfully iden-
tified. Each sample was tested five times and we observed 100%
song recognition accuracy for all samples. Song recognition can be
considered one of the easier tasks to accomplish that can still reveal
sensitive information. An attacker could use already available tools,
or even design their own customized song recognition algorithm.
The algorithm used for our work performs a combinatorially hashed
time-frequency analysis of the audio to recognize a song with very
small samples of the original audio. Further, songs can be easily
identified with snippets of either instrumental music or lyrics being
sung. In regards to privacy, song recognition can reveal the user’s
unique and personal interests.
8 DISCUSSION
Increased Potential for Compromising Speech: Through our
experiments, we determined that a RandomForest classifier can be
used to improve the potential for certain speech recognition tasks
(beyond the accuracies obtained from random guessing). Our results
demonstrate the clear potential for an attacker to compromise user
speech, to some extent, even when under the protection of a PJD. We
found that full speech (digit) recognition and speaker identification
are more challenging, while successful gender recognition seems
more likely in a real-world attack scenario. Further, an attacker with
more extensive knowledge of signal processing, or with improved
techniques, could achieve even better classification accuracies.
Speech SPL Observation: The classification results we observed
for each speech task and feature set revealed an interesting pat-
tern. In all scenarios we find that the maximum accuracies were
achieved using source speech at 65 dB. This is unexpected as we
would think that the 70 dB source speech data would produce the
greatest results for speech classification tasks. Through the process
of collecting the Alexa voice history recordings we noticed that
some noise cancellation is already applied. However, the success of
this noise cancellation was not consistent and resulted in samples
recorded under the same settings having different levels of noise
still present. Therefore, we speculate that one reason for the im-
proved classification success of the 65 dB samples could be better
noise cancellation performance on user speech that is closer to 65
dB. So noise cancellation may be less effective on user speech that is
70 dB because it is furthest from the range of normal human speech.
Speech related features could be filtered because the increased SPL
(power) of the speech signal is mistaken as noise.
9 CONCLUSION
In this work we look to explore the effectiveness of Protection Jam-
ming Devices (PJD) that use GWN for masking user speech from
eavesdropping attacks. These devices are used to continuously in-
ject a masking sound into the microphones of VA smart speakers in
order to block the device from accepting the user’s commands. An
assumption is that this hinders any potential VA speaker eavesdrop-
ping attacks. However, with current signal processing techniques
(i.e., noise reduction, speech enhancement) there exists a potential
for the user’s speech to be compromised by an attacker that can
access smart speaker recordings. Through a process of data collec-
tion, post-processing, feature extraction, and model training, we
were able to demonstrate greater classification accuracies (than ran-
dom guessing) of 46%, 51%, and 80% for speech (digit) recognition,
speaker identification, and gender identification, respectively.
Future Work: As this work provides a first exploration of PJDs
(using GWN) effectiveness for masking speech recorded by a smart
speaker device, we could not feasibly test all possible experimental
parameters. Therefore, a few key directions remain that we can
explore in the future to further develop this work (and our overall
understanding of PJD device effectiveness). First, we decided on a
Gaussian white noise for our jamming signal for its popular use
in other speech masking solutions. Aside from GWN, there are
other jamming signal types that we would like to explore including
chatter noise and ultrasonic sound. These signal types can provide
more diversity in the jamming noise or even affect the performance
of the microphone mechanics. Next, we would like to test other
PJD configurations such as using 6 tiny speakers to inject noise
in the microphone array (like Home Wave), or encasing all of the
components in a housing shell (like Project Alias). Lastly, we would
like to explore new or more extensive signal processing techniques
to improve the noise cancellation and speech enhancement.
423Evaluating the Effectiveness of PJDs in Mitigating Smart Speaker Eavesdropping Attacks Using GWN
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
ACKNOWLEDGMENTS
We would like to give special thanks to the set of anonymous
reviewers for their valuable feedback on this paper. This work is
partially supported by the National Science Foundation (NSF) under
the grants: CNS-1714807, CNS-2030501, CNS-2139358.
REFERENCES
[1] Speech Masking 2016. Our Technology.
Speech Masking.
https://
www.speechmasking.com/Technology
[2] 2020. Data security and privacy on devices that work with Assistant. https:
//support.google.com/googlenest/answer/7072285?hl=en
[3] Amazon 2020. Echo Dot (3rd Gen) - Smart speaker with Alexa. Amazon. https:
//www.amazon.com/Echo-Dot/dp/B07FZ8S74R
[4] Google 2020. Google Home Mini. Google. https://store.google.com/us/
config/googlehomemini
[5] Consumer Watchdog 2020.
How Google and Amazon are ’spying’ on
you. Consumer Watchdog. https://www.consumerwatchdog.org/privacy-
technology/how-google-and-amazon-are-spying-you
[6] 2020. Is Alexa Recording? https://www.amazon.com/is-alexa-recording-
conversations/b?ie=UTF8&node=21219697011
[7] NPR 2020. NPR and Edison Research Report. NPR. https://www.npr.org/about-
npr/794588984/npr-and-edison-research-report-60m-u-s-adults-18-
own-a-smart-speaker
[8] 2020. Paranoid Home Devices - Home Wave. https://paranoid.com/products
[9] Sound Management Group 2020. Sound Masking for Offices. Sound Management
Group. https://soundmanagementgroup.com/products/sound-masking/
[10] University of Waikato 2020. WEKA: The workbench for machine learning. Univer-
sity of Waikato. https://www.cs.waikato.ac.nz/ml/weka/index.html
[11] Pro Acoustics 2021.
Sound Masking Systems.
Pro Acoustics.
https:
//www.proacousticsusa.com/complete-sound-systems/commercial-
sound-systems/sound-masking-systems.html
[12] Alina Bradford. 2020. Paranoid prevents smart speakers from eavesdropping
on you. Digital Trends. https://www.digitaltrends.com/home/paranoid-
prevents-smart-speakers-from-eavesdropping/#:~:text=Paranoid%
20is%20a%20device%20that, %E2%80%9CParanoid%E2%80%9D%20before%
20each%20command.
[13] April White. 2018. A Brief History of Surveillance in America. Smithsonian
https://www.smithsonianmag.com/history/brief-history-
Magazine.
surveillance-america-180968399/
[14] Bjorn Karmann. 2018.
Project Alias.
https://bjoernkarmann.dk/
projectalias
[15] Bjorn Karmann. 2018.
Project Alias.
Instructables Circuits.
https://
www.instructables.com/id/Project-Alias/
[16] Brittany Vance. 2020.
New device stops your
smart
speaker
listening without a safe word.
//theamericangenius.com/gadgets/new-device-stops-your-smart-
speaker-from-listening-without-a-safe-word/
The American Genius.
from
https:
[17] Mike Brookes. 2017. VOICEBOX: Speech Processing Toolbox for MATLAB. http:
//www.ee.ic.ac.uk/hp/staff/dmb/voicebox/voicebox.html
[18] Y. Chen, Huiying Li, Shan-Yuan Teng, S. Nagels, Zhijing Li, Pedro Lopes, B. Zhao,
and H. Zheng. 2020. Wearable Microphone Jamming. Proceedings of the 2020 CHI
Conference on Human Factors in Computing Systems (2020).
[19] P. Cheng, I. E. Bagci, J. Yan, and Utz Roedig. 2018. Towards Reactive Acoustic
Jamming for Personal Voice Assistants. Proceedings of the 2nd International
Workshop on Multimedia Privacy and Security (2018).
[20] Chris Matyszczyk. 2020. This weird new gadget stops Amazon’s Alexa spying on
you. ZDNet. https://www.zdnet.com/article/this-weird-new-gadget-
stops-amazons-alexa-spying-on-you/
[21] Dan Ellis. 2003.
Clean Digits.
Columbia University.
https://
www.ee.columbia.edu/~dpwe/sounds/tidigits/
[22] Danny Bradbury. 2020. Smart speakers mistakenly eavesdrop up to 19 times
a day. https://nakedsecurity.sophos.com/2020/02/25/smart-speakers-
mistakenly-eavesdrop-up-to-19-times-a-day/
[23] Don Sweeney. 2019. Here’s how to stop Amazon employees from eavesdropping
on your Alexa conversations. https://www.sacbee.com/news/nation-world/
national/article229121874.html
[24] Eric Limer. 2019. This Brilliant Home Assistant Add-On Makes Eavesdropping Com-
pletely Impossible. Popular Mechanics. https://www.popularmechanics.com/
technology/security/a25894138/amazon-echo-google-home-project-
alias-white-noise-eavesdropping-defense/
[25] J. Fingas. 2019. Florida police obtain Alexa recordings in murder investigation. en-
gadget. https://www.engadget.com/2019-11-02-florida-police-obtain-
alexa-recordings-in-murder-case.html
[26] Mark D. Fletcher, Sian Lloyd Jones, Paul R. White, Craig N. Dolder, Timothy G.
Leighton, and Benjamin Lineton. 2018. Effects of very high-frequency sound
and ultrasound on humans. Part I: Adverse symptoms after exposure to audible
very-high frequency sound. The Journal of the Acoustical Society of America 144,
4 (2018), 2511–2520. https://doi.org/10.1121/1.5063819
[27] Sidney Fussell. 2020. Meet the Star Witness: Your Smart Speaker. Wired. https:
//www.wired.com/story/star-witness-your-smart-speaker/
[28] Geoffrey A. Fowler. 2020. Alexa has been eavesdropping on you this whole
time. The Washington Post. https://www.consumerwatchdog.org/privacy-
technology/how-google-and-amazon-are-spying-you
[29] Mordechai Guri, Yosef Solewicz, Andrey Daidakulov, and Yuval Elovici. 2017.
SPEAKE(a)R: Turn Speakers to Microphones for Fun and Profit. In Proceedings
of the 11th USENIX Conference on Offensive Technologies (WOOT’17). USENIX
Association, USA, 13.
[30] Jason Cohen. 2020.
Smart Speaker Sales Soar as Owners Buy Multiple
https://www.pcmag.com/news/smart-speaker-sales-soar-as-
Devices.
owners-buy-multiple-devices
[31] Jeffrey Lang. 2020. Yes, your smart devices are spying on you. Which ones
are the worst? https://movietvtechgeeks.com/yes-your-smart-devices-
are-spying-on-you-which-ones-are-the-worst/
[32] Yeongseok Kim and Youngjin Park. 2017. Effect of active noise control and
masking sound on speech intelligibility. Applied Acoustics 123 (2017), 152–157.
https://doi.org/10.1016/j.apacoust.2017.02.021
[33] Alexey Krasnov, Edward R Green, Bret Engels, and Barry Corden. 2019. Enhanced
speech privacy in office spaces. Building Acoustics 26, 1 (2019), 57–66. https:
//doi.org/10.1177/1351010X18798105
[34] L. Li, Manni Liu, Yuguang Yao, Fan Dang, Zhichao Cao, and Y. Liu. 2020. Pa-
tronus: Preventing Unauthorized Speech Recordings with Support for Selective
Unscrambling. Proceedings of the 18th Conference on Embedded Networked Sensor
Systems (2020).
[35] ludlows. 2019. PESQ (Perceptual Evaluation of Speech Quality) Wrapper for Python
Users (narrow band and wide band). GitHub. https://github.com/ludlows/
python-pesq
[36] Mark Wilson. 2019.
Google Home hack.
90290703/this-is-the-first-truly-great-amazon-alexa-and-
google-home-hack?partner=rss&utmsource=feedburner&utmmedium=
feed&utmcampaign=feedburner+fastcompany&utmcontent=feedburner
truly great Amazon Alexa and
https://www.fastcompany.com/
This is the first
Fast Company.
[37] C. Phunruangsakao, P. Kraikhun, S. Duangpummet, J. Karnjana, M. Unoki, and
W. Kongprawechnon. 2020. Speech Privacy Protection based on Controlling
Estimated Speech Transmission Index. In 2020 17th International Conference on
Electrical Engineering/Electronics, Computer, Telecommunications and Information
Technology (ECTI-CON). 628–631.
[38] Shannon Liao. 2019. This project hacks Amazon Echo and Google Home to protect
https://www.theverge.com/circuitbreaker/
your privacy. The Verge.
2019/1/15/18182214/amazon-echo-google-home-privacy-protection-
project-white-noise
[39] Bożena Smagowska and Małgorzata Pawlaczyk-Łuszczyńska. 2013. Effects of
Ultrasonic Noise on the Human Body—A Bibliographic Review. International
Journal of Occupational Safety and Ergonomics (JOSE) 19, 2 (2013), 195–202.
https://doi.org/10.1080/10803548.2013.11076978
[40] Spencer Ackerman. 2012. CIA Chief: We’ll Spy on You Through Your Dishwasher.
Wired. https://www.wired.com/2012/03/petraeus-tv-remote/
[41] Ken Sun, Chen Chen, and Xinyu Zhang. 2020. “Alexa, Stop Spying on Me!":
Speech Privacy Protection Against Voice Assistants.
[42] Harshavardhan Sundar, Weiran Wang, Ming Sun, and Chao Wang. 2020. Raw
Waveform Based End-to-end Deep Convolutional Network for Spatial Local-
ization of Multiple Acoustic Sources. In 2020 IEEE International Conference on
Acoustics, Speech and Signal Processing (ICASSP’20). 4642–4646.
[43] Trevor Timm. 2016. The government just admitted it will use smart home devices for
spying. The Guardian. https://www.theguardian.com/commentisfree/2016/
feb/09/internet-of-things-smart-devices-spying-surveillance-us-
government
[44] Avery Wang. 2003. An Industrial Strength Audio Search Algorithm. In 4th
International Conference on Music Information Retrieval (ISMIR’03).
[45] Zack Whittaker. 2018. Judge orders Amazon to turn over Echo recordings in double
murder case. TechCrunch. https://techcrunch.com/2018/11/14/amazon-
echo-recordings-judge-murder-case/
[46] Minhua Wu, Kenichi Kumatani, Shiva Sundaram, Nikko Ström, and Björn
Hoffmeister. 2019. Frequency Domain Multi-channel Acoustic Modeling for
Distant Speech Recognition. In 2019 IEEE International Conference on Acoustics,
Speech and Signal Processing (ICASSP’19). 6640–6644.
[47] Jun Yang. 2018. Multilayer Adaptation Based Complex Echo Cancellation and
Voice Enhancement. 2131–2135.
424