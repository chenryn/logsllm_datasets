### gitDigger: Creating Useful Wordlists from GitHub

**Presenters: WiK & Mubix**

#### Introduction
- **Project:** Constructocat by Jason Costello - [GitHub](https://github.com/jsncostello)
- **Tool:** gitDigger
- **Objective:** Generate useful wordlists from GitHub repositories.

#### Presentation Overview
- We acknowledge that visualizing concepts can be challenging, so we aim to make this presentation as clear and engaging as possible.

#### The Researcher – WiK
- **Contact:** @jaimefilson

**Background:**
- We were not the first to explore this area. A relevant blog post is available [here](http://www.mavitunasecurity.com/blog/svn-digger-better-lists-for-forced-browsing/).

**Challenges:**
- Finding a service that is "friendly" to research.
- Scraping GitHub for data is difficult due to the lack of an "all repos" list.

**Initial Solution:**
- **Tools Used:**
  - `os`
  - `urllib`
  - `urllib2`
  - `sqlite3`
- **Process:**
  - Python WGET to download repositories.
  - Manual review and processing using `os.walk()`, `sort`, `grep`, and `awk`.
  - Focused on "TOP" repositories.
  - 17 hours of manual processing to generate wordlists.

**Issues:**
- Only "TOP" repositories were processed.
- SQLite transactions were slow.
- Manual labor was extensive.
- Storage became a significant issue.

#### Addressing the Problems
**First Problem: Storage**
- **Options:**
  - **Cheap Storage ($99 USD/year):**
    - Pros: Built-in indexing.
    - Cons: Windows-only, frequent crashes, slow encryption.
  - **Local Storage:**
    - Pros: Central, fast.
    - Cons: Expensive.
- **Solution:**
  - Use multiple USB HDDs for storage.

**Second Problem: Python WGET and GitHub API**
- **Solution:**
  - Utilize the GitHub API for more efficient data retrieval.

**Third Problem: SQLite Performance**
- **Solution:**
  - Replace SQLite with MySQL for better performance.

#### Putting It All Together
**Upgrades:**
- **Modes:**
  - **Downloader:** Fetches repositories.
  - **Processor:** Generates wordlists.
- **Threading:** Added for improved performance.
- **Database Tables:**
  - Password Table
  - Username Table
  - Email Table
  - Projects Table
  - Directories Table
  - Files Table
  - Last Seen ID Table
- **Scripts:**
  - `add2database.py` to add items to the database.
  - `.sh` script for manual cleanup.
  - `grep/egrep` for text processing.

**Updated Results:**
- **Good News:**
  - Now retrieving all public repositories.
  - Wordlist generation is automated and takes minutes instead of hours.
  - Data can be stored across multiple USB HDDs.
- **Bad News:**
  - Manual work is still required for extracting usernames, passwords, and emails.
  - Requires a large amount of storage (estimated 30TB uncompressed).

#### The Attacker – Mubix
- **Contact:** @mubix

**Use Cases:**
- **Wordlists for Forced Browsing:**
  - Similar to the SVN digger project.
- **Default Passwords List:**
  - Small, but useful.
- **Static Salts:**
  - Found within GitHub projects.
- **File Parsing:**
  - Analyzing every file in the Git revision history.
  - Mass static code analysis for vulnerabilities.
  - Parsing `.gitignore` files of production targets.
  - Verifying directories with HTTP 403 responses.

**Advanced Techniques:**
- **OCR on Image Files:**
  - Extracting text from images.
- **Intelligence Gathering:**
  - Using `.txt` files for gathering information.
- **Email Extraction:**
  - Grep out all email addresses.

#### Conclusion
- **Link to Project:** [gitdigger](http://github.com/wick2o/gitdigger)
- **Contact:** PI:EMAIL @jaimefilson
- **Link to Wordlists:** [Wordlists](http://github.com/wick2o/gitdigger)

Thank you for your attention!