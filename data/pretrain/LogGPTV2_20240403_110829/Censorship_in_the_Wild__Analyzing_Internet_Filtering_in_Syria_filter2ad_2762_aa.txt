title:Censorship in the Wild: Analyzing Internet Filtering in Syria
author:Chaabane Abdelberi and
Terence Chen and
Mathieu Cunche and
Emiliano De Cristofaro and
Arik Friedman and
Mohamed Ali Kâafar
Censorship in the Wild: Analyzing Internet Filtering in Syria
Abdelberi Chaabane
INRIA Rhône-Alpes
Montbonnot, France
Emiliano De Cristofaro
University College London
London, United Kingdom
Terence Chen
NICTA
Sydney, Australia
Sydney, Australia
Arik Friedman
NICTA
Mathieu Cunche
University of Lyon & INRIA
Lyon, France
Mohamed Ali Kaafar
NICTA & INRIA Rhône-Alpes
Sydney, Australia
ABSTRACT
Internet censorship is enforced by numerous governments world-
wide, however, due to the lack of publicly available information,
as well as the inherent risks of performing active measurements, it
is often hard for the research community to investigate censorship
practices in the wild. Thus, the leak of 600GB worth of logs from
7 Blue Coat SG-9000 proxies, deployed in Syria to ﬁlter Internet
trafﬁc at a country scale, represents a unique opportunity to provide
a detailed snapshot of a real-world censorship ecosystem.
This paper presents the methodology and the results of a measure-
ment analysis of the leaked Blue Coat logs, revealing a relatively
stealthy, yet quite targeted, censorship. We ﬁnd that trafﬁc is ﬁltered
in several ways: using IP addresses and domain names to block
subnets or websites, and keywords or categories to target speciﬁc
content. We show that keyword-based censorship produces some
collateral damage as many requests are blocked even if they do not
relate to sensitive content. We also discover that Instant Messag-
ing is heavily censored, while ﬁltering of social media is limited
to speciﬁc pages. Finally, we show that Syrian users try to evade
censorship by using web/socks proxies, Tor, VPNs, and BitTorrent.
To the best of our knowledge, our work provides the ﬁrst analytical
look into Internet ﬁltering in Syria.
Categories and Subject Descriptors
K.5.2 [Legal Aspects of Computing]: Governmental Issues—Cen-
sorship; K.4.1 [Computers and Society]: Public Policy Issues—
Privacy
Keywords
Censorship; Internet Filtering; Measurements
1.
INTRODUCTION
As the relation between society and technology evolves, so does
censorship—the practice of suppressing ideas and information that
certain individuals, groups or government ofﬁcials may ﬁnd objec-
tionable, dangerous, or detrimental. Censors increasingly target
access to, and dissemination of, electronic information, for instance,
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
IMC’14, November 5–7, 2014, Vancouver, BC, Canada.
Copyright 2014 ACM 978-1-4503-3213-2/14/11 ...$15.00.
http://dx.doi.org/10.1145/2663716.2663720.
aiming to restrict freedom of speech, control knowledge available
to the masses, or enforce religious/ethical principles.
Even though the research community dedicated a lot of attention
to censorship and its circumvention, knowledge and understanding
of ﬁltering technologies is inherently limited, as it is challenging and
risky to conduct measurements from countries operating censorship,
while logs pertaining to ﬁltered trafﬁc are obviously hard to come by.
Prior work has analyzed censorship practices in China [14, 15, 20,
29, 30], Iran [2, 4, 26], Pakistan [18], and a few Arab countries [10],
however, mostly based on probing, i.e., inferring what information
is being censored by generating requests and observing what content
is blocked. While providing valuable insights, these methods suffer
from two main limitations: (1) only a limited number of requests can
be observed, thus providing a skewed representation of the censor-
ship policies due to the inability to enumerate all censored keywords,
and (2) it is hard to assess the actual extent of the censorship, e.g.,
what kind/proportion of the overall trafﬁc is being censored.
Roadmap. In this paper, we present a measurement analysis of
Internet ﬁltering in Syria: we study a set of logs extracted from
7 Blue Coat SG-9000 proxies, which were deployed to monitor,
ﬁlter and block trafﬁc of Syrian users. The logs (600GB worth of
data) were leaked by a “hacktivist” group, Telecomix, in October
2011, and relate to a period of 9 days between July and August
2011 [23]. By analyzing the logs, we provide a detailed snapshot of
how censorship was operated in Syria. As opposed to probing-based
methods, the analysis of actual logs allows us to extract information
about processed requests for both censored and allowed trafﬁc and
provide a detailed snapshot of Syrian censorship practices.
Main Findings. Our measurement-based analysis uncovers several
interesting ﬁndings. First, we observe that a few different techniques
are employed by Syrian authorities: IP-based ﬁltering to block
access to entire subnets (e.g., Israel), domain-based to block speciﬁc
websites, keyword-based to target speciﬁc kinds of trafﬁc (e.g.,
ﬁltering-evading technologies, such as socks proxies), and category-
based to target speciﬁc content and pages. As a side-effect of
keyword-based censorship, many requests are blocked even if they
do not relate to any sensitive content or anti-censorship technologies.
Such collateral damage affects Google toolbar’s queries as well as a
few ads delivery networks that are blocked as they generate requests
containing the word proxy.
Also, the logs highlight that Instant Messaging software (like
Skype) is heavily censored, while ﬁltering of social media is limited
to speciﬁc pages. Actually, most social networks (e.g., Facebook
and Twitter) are not blocked, but only certain pages/groups are (e.g.,
the Syrian Revolution Facebook page). We ﬁnd that proxies have
specialized roles and/or slightly different conﬁgurations, as some
of them tend to censor more trafﬁc than others. For instance, one
particular proxy blocks Tor trafﬁc for several days, while other
285proxies do not. Finally, we show that Syrian Internet users not
only try to evade censorship and surveillance using well-known
web/socks proxies, Tor, and VPN software, but also use P2P ﬁle
sharing software (BitTorrent) to fetch censored content.
Our analysis shows that, compared to other countries (e.g., China
and Iran), censorship in Syria seems to be less pervasive, yet quite
targeted. Syrian censors particularly target Instant Messaging, in-
formation related to the political opposition (e.g., pages related to
the “Syrian Revolution”), and Israeli subnets. Arguably, less evident
censorship does not necessarily mean minor information control
or less ubiquitous surveillance. In fact, Syrian users seem to be
aware of this and do resort to censorship- and surveillance-evading
software, as we show later in the paper, which seems to conﬁrm
reports about Syrian users enganging in self-censorship to avoid
being arrested [3, 5, 19].
Contributions. To the best of our knowledge, we provide the ﬁrst
detailed snapshot of Internet ﬁltering in Syria and the ﬁrst set of
large-scale measurements of actual ﬁltering proxies’ logs. We show
how censorship was operated via a statistical overview of censorship
activities and an analysis of temporal patterns, proxy specializations,
and ﬁltering of social network sites. Finally, we provide some details
on the usage of surveillance- and censorship-evading tools.
Remarks. Logs studied in this paper date back to July-August 2011,
thus, our work is not intended to provide insights to the current
situation in Syria as censorship might have evolved in the last two
years. According to Bloomberg [22], Syria has invested $500K in
surveillance equipment in late 2011, thus an even more powerful
ﬁltering architecture might now be in place. Starting December
2012, Tor relays and bridges have reportedly been blocked [24].
Nonetheless, our analysis uncovers methods that might still be in
place, e.g., based on Deep Packet Inspection. Also, Blue Coat
proxies are reportedly still used in several countries [17].
Our work serves as a case study of censorship in practice: it
provides a ﬁrst-of-its-kind, data-driven analysis of a real-world
censorship ecosystem, exposing its underlying techniques, as well
as its strengths and weaknesses, which we hope will facilitate the
design of censorship-evading tools.
Paper Organization. The rest of this paper is organized as follows.
The next section reviews related work. Then, Section 3 provides
some background information and introduces the datasets studied
throughout the paper. Section 4 presents a statistical overview of
Internet censorship in Syria based on the Blue Coat logs, while Sec-
tion 5 provides a thorough analysis to better understand censorship
practices. After focusing on social network sites in Section 6 and
anti-censorship technologies in Section 7, we discuss our ﬁndings
in Section 8. The paper concludes with Section 9.
2. RELATED WORK
Due to the limited availability of publicly available data, there is
little prior work analyzing logs from ﬁltering devices. A fairly large
body of work, which we overview in this section, has focused on
understanding and characterizing censorship processes via probing.
By contrast, our work is really the ﬁrst to analyze trafﬁc observed by
actual ﬁltering proxies and to provide a detailed measurement-based
snapshot of Syria’s censorship infrastructure.
Ayran et al. [4] present measurements from an Iranian ISP, analyz-
ing HTTP host-based blocking, keyword ﬁltering, DNS hijacking,
and protocol-based throttling, and conclude that the censorship in-
frastructure heavily relies on centralized equipment. Winter and
Lindskog [29] conduct some measurements on trafﬁc routed through
Tor bridges/relays to understand how China blocks Tor. Also, Dain-
otti et al. [9] analyze country-wide Internet outages, in Egypt and
Libya, using publicly available data such as BGP inter-domain rout-
ing control plane data.
Another line of work deals with ﬁngerprinting and inferring cen-
sorship methods and equipments. Researchers from the Citizen
Lab [17] focus on censorship/surveillance performed using Blue
Coat devices and uncover 61 Blue Coat ProxySG devices and 316
Blue Coat PacketShaper appliances in 24 different countries. Dalek
et al. [10] use a conﬁrmation methodology to identify URL ﬁltering
using, e.g., McAfee SmartFilter and Netsweeper, and detect the use
of these technologies in Saudi Arabia, UAE, Qatar, and Yemen.
Nabi [18] uses a publicly available list of blocked websites in
Pakistan, checking their accessibility from multiple networks within
the country. Results indicate that censorship varies across websites:
some are blocked at the DNS level, while others at the HTTP level.
Furthermore, Verkamp and Gupta [26] detect censorship technolo-
gies in 11 countries, mostly using Planet Labs nodes, and discover
DNS-based and router-based ﬁltering. Crandall et al. [8] propose
an architecture for maintaining a censorship “weather report” about
what keywords are ﬁltered over time, while Leberknight et al. [16]
provide an overview of research on censorship resistant systems and
a taxonomy of anti-censorship technologies.
Also, Knockel et al. [15] obtain a built-in list of censored key-
words in China’s TOM-Skype and run experiments to understand
how ﬁltering is operated, while King et al. [14] devise a system to
locate, download, and analyze the content of millions of Chinese
social media posts, before the Chinese government censors them.
Finally, Park and Crandall [20] present results from measure-
ments of the ﬁltering of HTTP HTML responses in China, which is
based on string matching and TCP reset injection by backbone-level
routers. Xu et al. [30] explore the AS-level topology of China’s
network infrastructure, and probe the ﬁrewall to ﬁnd the locations
of ﬁltering devices, ﬁnding that even though most ﬁltering occurs in
border ASes, choke points also exist in many provincial networks.
3. DATASETS DESCRIPTION
This section overviews the dataset studied in this paper, and
background information on the proxies used for censorship.
3.1 Data Sources
On October 4, 2011, a “hacktivist” group called Telecomix an-
nounced the release of log ﬁles extracted from 7 Syrian Blue Coat
SG-9000 proxies (aka ProxySG) [23]. The initial leak concerned
15 proxies but only data from 7 of them was publicly released. As
reported by the Wall Street Journal [25] and CBS news [28], Blue
Coat openly acknowledged that at least 13 of its proxies were used
in Syria, but denied it authorized their sale to the Syrian govern-
ment [6]. These devices have allegedly been used by the Syrian
Telecommunications Establishment (STE backbone) to ﬁlter and
monitor all connections at a country scale. The data is split by proxy
(SG-42, SG-43,. . ., SG-48) and covers two periods: (i) July 22, 23,
31, 2011 (only SG-42), and (ii) August 1–6, 2011 (all proxies). The
leaked log ﬁles are in csv format (comma separated-values) and
include 26 ﬁelds, such as date, time, ﬁlter action, host and URI
(more details are given in Section 3.3).
Given the nature of the dataset, one could question the authenticity
of the logs. However, Blue Coat conﬁrmed the use of its devices in
Syria [25, 28] and a few ﬁndings emerging from the analysis of the
logs actually correspond to events and facts that were independently
reported before. Also, this leak is not the ﬁrst censorship-related
project carried out by Telecomix. Thus, we are conﬁdent that the
datasets studied in this paper provide an accurate snapshot of Syrian
censorship activities in Summer 2011.
2863.2 Blue Coat SG-9000 Proxies
The Blue Coat SG-9000 proxies perform ﬁltering, monitoring,
and caching of Internet trafﬁc, and are typically placed between
a monitored network and the Internet backbone. They can be set
as explicit or transparent proxies: the former setting requires the
conﬁguration of the clients’ browsers, whereas transparent proxies
seamlessly intercept trafﬁc (i.e., without clients noticing it), which
is the case in this dataset.
Monitoring and ﬁltering of trafﬁc is conducted at the application
level. Each user request is intercepted and classiﬁed as one of the
following three labels (as per the sc-ﬁlter-result ﬁeld in the logs):
• OBSERVED – request is served to the client.
• PROXIED – request has been found in the cache and the
• DENIED – request is not served to the client because an
outcome depends on the cached value.
exception has been raised (might be redirected).
The classiﬁcation reﬂects the action that the proxy needs to per-
form, rather than the outcome of a ﬁltering process. OBSERVED
means that content needs to be fetched from the Origin Content
Server (OCS), DENIED that there is no need to contact the OCS,
and PROXIED – that the outcome is in the proxy’s cache. According
to Blue Coat’s documentation [27], ﬁltering is based on multiple cri-
teria: website categories, keywords, content type, browser type and
date/time of day. The proxies can also cache content, e.g., to save
bandwidth, in the “bandwidth gain proﬁle” (see page 193 in [1]).
3.3 Datasets and Notation
Throughout the rest of this paper, our analysis will use the follow-
ing four datasets:
1. Full Logs (Df ull): The whole dataset (i.e., extracted from all
logs) is composed of 751,295,830 requests.
2. Sample Dataset (Dsample): Most of the results shown in
this paper rely on the full extraction of the relevant data
from Df ull , however, given the massive size of the log ﬁles
(∼600GB), we sometimes consider a random sample cover-
ing 4% of the entire dataset. This dataset (Dsample) is only
used to illustrate a few results, speciﬁcally, for a few summary
statistics. According to standard theory about conﬁdence in-
tervals for proportions (see [13], Equation 1, Chapter 13.9.2),
for a sample size of n = 32M, the actual proportion in the full
data set lies in an interval of ±0.0001 around the proportion
p observed in the sample with 95% probability (α = 0.05).
3. User Dataset (Duser): Before the data release, Telecomix
suppressed user identiﬁers (IP addresses) by replacing them
with zeros. However, for a small fraction of the data (July
22-23), user identiﬁers were replaced with the hash of the IP
addresses, thus making user-based analysis possible.
4. Denied Dataset (Ddenied): This dataset contains all the re-
quests that resulted in exceptions (x-exception-id (cid:54)= ‘-’), and
hence are not served to the user.
In Table 1, we report, for each dataset, the number of requests in
it, corresponding dates, and number of proxies. Then, in Table 2,
we list a few ﬁelds from the logs that constitute the main focus
of our analysis. The s-ip ﬁeld logs the IP address of the proxy
that processed each request, which is in the range 82.137.200.42
– 48. Throughout the paper we refer to the proxies as SG-42 to
SG-48, according to the sufﬁx of their IP address. The sc-ﬁlter-
result ﬁeld indicates whether the request has been served to the
client. In the rest of the paper, we consider as denied all requests
Dataset
Full
Sample (4%)
User
Denied
# Requests
751,295,830
32,310,958
6,374,333
47,452,194
Period
July 22-23,31, 2011