Miscellaneous jobs with malicious intentions
Count
769
265
138
100
177
22
19
14
195
53
20
61
25
8
33
41
32
21
17
10
1
35
%
38.5
13.2
6.9
5.0
8.8
1.1
0.9
0.7
9.8
2.6
1.0
3.0
1.2
0.4
1.7
2.1
1.6
1.1
0.9
0.5
0.1
1.8
Table 2: Distribution of 2,000 random, manually-labeled projects into job categories. Referenced sections of the appendix include
examples of jobs in the corresponding category.
the job details; private postings, however, will sometimes
contain enough data to determine their intent. In our
manually labeled corpus, we were unable to determine
the intent of 5.4% of the jobs. The remaining 29.2% of
the jobs correspond to various kinds of “dirty” jobs, rang-
ing from delivering phone-veriﬁed Craigslist accounts
in bulk to a wide variety of search-engine optimization
(SEO) tasks.
We then focused on identifying jobs in the entire Free-
lancer corpus that fall into “dirty” categories. Since we
could not manually classify all jobs, we used keyword
matching to generate training sets and supervised learn-
ing to train classiﬁers for each category. We then applied
the classiﬁers to each job to determine the dirty category
it falls into, if any.
To ﬁnd positive examples for each classiﬁer, we used
keywords associated with the job type to conservatively
identify jobs that fall into each category. For example,
to locate jobs about CAPTCHA solving, we searched
job postings for the terms “CAPTCHA” and “type” or
“solve”. For negative examples, we randomly chose jobs
from the other orthogonal job types. For features, we
computed the well-known tf-idf score (term frequency-
inverse document frequency) of each word present in the
title, description, and keywords associated with jobs in
the training sets. We then used svm-light [9] to train clas-
siﬁers speciﬁc to each category.
Table 3 shows the results of applying these classiﬁers
to all Freelancer jobs. We focus on just those dirty job
categories that had at least 1,000 jobs. Although the clas-
siﬁers are not perfect (e.g., some jobs placed in the “link
building” categories might be better placed in the more
generic “SEO” category), they sufﬁciently capture the set
of jobs in each category and greatly increase the number
of jobs we can conﬁdently analyze. Note that we did not
attempt to be complete in the categorization of the post-
ings: there are likely jobs that should be in a category
that we have missed. However, such jobs are also likely
not well-marketed to workers, since they most likely lack
the typical keywords and phrases commonly used in jobs
under those categories.
We focus on the jobs comprising these categories in
the analyses we perform in the subsequent sections.
3.4 Posting Job Listings
Pricing information is a crucial aspect of our study, since
it represents the economic value of an abusive activity to
attackers. Both job descriptions and bids contain pricing
info, often at odds with each other. To determine which
source of pricing info to use, we performed an experi-
ment where we posted jobs on Freelancer and solicited
bids. In the process, bidders posted public bids and, in
some cases, sent private messages to our user account.
SEO
Class
Accounts
Job Type
Account Registrations
Human CAPTCHA Solving
Veriﬁed Accounts
SEO Content Generation
Link Building (Grey Hat)
Link Building (White Hat)
Ad Posting
Bulk Mailing
OSN Linking OSN Linking
Spamming
Count %
0.7
6,249
0.6
4,959
0.4
3,120
72,912
8.7
1.9
16,403
1.3
10,935
1.3
11,190
0.4
3,062
11,068
1.3
Table 3: Freelancer jobs categorized using the classiﬁers.
These private messages occasionally reveal the external
Web store fronts operated by Freelancer workers, in addi-
tion to the tools, services, and methods they use to com-
plete each type of job. We posted 15 job listings repre-
sentative of the categories for which we have classiﬁers.
We also randomly posted half of the jobs as a “featured”
listing to determine whether this increased the quantity
of bids we received (which it did).
Table 4 summarizes the results of our job posting ex-
periments. Of the 228 total bids we received, 47 were
commensurate with market rates for these projects. Most
of the remaining bids, however, were simply minimum
bids used as “place holders”. The actual bid amount was
either included in a private message to our buyer account,
or the bidder provided an email address to negotiate a
price outside of the Freelancer site to avoid the Free-
lancer fee.
Because many prices in the public bids severely un-
derestimate market prices, we use the prices in job de-
scriptions by buyers in our studies in Section 4. Even
so, we note that the pricing data has some inherent bi-
ases. They are advertised prices and not necessarily the
ﬁnal prices that may have been negotiated with selected
workers. Further, we use prices that were systematically
extracted from the job descriptions. Even with hundreds
of hand-crafted regular expressions, we were only able
to extract pricing data from about 10% of the jobs. Job
descriptions are notoriously unstructured, ungrammati-
cal, and unconventional. These biases notwithstanding,
the pricing data is still useful for comparing the relative
value of jobs, as well as trends over time.
4 Case Studies
This section features case studies of the four groups of
abuse-related Freelancer jobs summarized in Table 2.
4.1 Accounts
Accounts on Web services are the basic building blocks
of an abuse workﬂow. Because they are the main mech-
anism for access control and policy enforcement (e.g.,
limits on number of messages per day), circumventing
these limits requires creating additional accounts, often
Class
Accounts
[§B.1]
SEO
[§B.2]
Job Type
Craigslist PVA
Gmail Accounts
Hotmail Accounts*
Facebook Accounts*
Blog Backlinks*
Linking (White Hat)*
Forum Backlinks
Social Bookmarks*
Bulk Article Writing
Spamming Bulk Mailing
[§B.3]
OSN
Linking
[§B.4]
Craigslist Posting
Facebook Friends*
Facebook Fans
MySpace Friends
Twitter Followers*
Bids
10 (4)
6 (5)
21 (12)
24 (10)
10 (5)
17 (8)
12 (9)
44 (21)
29 (23)
10 (5)
10 (3)
11 (4)
5 (5)
2 (2)
7 (6)
Cost
$4.25
$0.07
$0.007
$0.07
$0.30
$0.81
$0.50
$0.13
$3.00
0.075¢
$0.60
$0.026
$0.039
$0.037
$0.02
Table 4: Results from posting job listings to Freelancer. A “*”
indicates the post was featured, the number within the “()” is
the number of bids that included prices. All prices in the cost
column are for the smallest unit of service (i.e., per one account,
backlink, email, post, and 500-word article).
at scale. Thus account creation has become the primary
battleﬁeld in abuse prevention.
Accounts primarily enable a wide variety of spamming
and scamming. For Web mail services like Gmail and Ya-
hoo, spammers use accounts to send email spam, taking
advantage of the reputation of the online service to im-
prove their conversion rate. For online social networks
like Facebook and Twitter, spammers use accounts to
spam friends and followers (Section 4.2), taking advan-
tage of relationships to improve conversion. For classi-
ﬁed services like Craigslist, spammers use accounts to
create highly-targeted lists, post high-ranking advertise-
ments for a variety of scams, recruit money laundering
and package handling mules, advertise stolen goods, etc.
Further, accounts on some services easily enable paired
accounts on related services (e.g., creating a YouTube ac-
count from a Gmail account), further extending the op-
portunities for spamming.
4.1.1 Account Creation Insights
In the context of another research effort, we obtained
approval from a major Web mail provider to purchase
fraudulently-created accounts on their service. We pur-
chased 500 such accounts from a retail site selling ac-
counts, gave them to the provider, and in return received
registration metadata for the supplied email accounts, in-
cluding account creation times and the IP addresses used
to register the accounts. We later discovered that the sup-
plier we contacted was a very active member of Free-
lancer.com; this worker is responsible for account set IN1
in Table 5.
The supplier had bid on 2,114 projects, had been cho-
Name Rating Tested Valid (%) Age (Days)
0.4
IN1*
25.7
UK1
24.7
BD1
9.7
IN2
78.6
PK1
82.6
PK2
414.7
PK3
30.7
IN3
CA1**
21.7
500
3,500
6,999
5,015
4,999
4,000
4,013
6,200
508
9.8
9.9
10
9.8
10
9.8
9.9
9.9
9.6
100.0
99.9
99.6
99.6
99.4
95.4
77.3
76.2
15.7
Table 5: Summary of the results from purchasing email ac-
counts. The names of the account sets embed the worker
countries: IN is India, UK is the United Kingdom, BD is
Bangladesh, PK is Pakistan, and CA is Canada. The rating col-
umn refers to the average rating of the selected worker. Notes:
*We purchased IN1 in 2010, the rest in 2011. **The worker
responsible for CA1 repeatedly copied and pasted 508 accounts
to meet the 5k requirement.
sen as a selected worker on 147 projects, and served as
a buyer on 84 projects. Interestingly, the supplier acted
as a buyer for 25 jobs that involved the creation of other
Web mail account types. The supplier contracted out this
task at a rate of $10–20 per 1,000 accounts, and yet the
supplier charged $20 per 100 accounts on the retail Web
site, an order of magnitude more.
The accounts we purchased were created an average
of only 2.8 seconds apart, suggesting the use of either
automated software or multiple human account creation
teams in parallel.5 Such automation would be one way
to earn money bidding on account jobs for this particular
worker. Further, 81% of the IP addresses used to register
the accounts were on the Spamhaus blacklist, suggesting
the use of IP addresses from compromised hosts to defeat
IP-based rate limiting of account creation.
4.1.2 Experience Purchasing Accounts
In 2011, we commissioned a job to purchase additional
email accounts for the same Web mail provider in quan-
tities ranging from 3,500–7,000. We selected nine dif-
ferent workers, of which eight ultimately produced ac-
counts, listed in Table 5 after IN1. Once given the ac-
counts and the corresponding passwords, we logged into
the accounts and downloaded the newest and oldest in-
box pages (assuming the account was valid). Table 5
shows the results of the purchasing and account check-
ing. Of the eight email sets, seven consisted of largely
valid accounts, with over 75% of the tested email ac-
counts yielding a successful login. IN3 was particularly
interesting; the worker previously used the email ad-
dresses to create Facebook and Craigslist logins and
posts, then resold the accounts to us. Also, four of the
5We know that an effective automated CAPTCHA solver existed at
this time for this Web mail provider, so automation is the likely suspect.
Figure 2: Median monthly prices offered by buyers for
1,000 CAPTCHA solves (top) and the monthly volume of
CAPTCHA solving posts (bottom), both as functions of time.
The solid vertical price bars show 25% to 75% price quartiles.
account batches are relatively old (as determined by the
date of their oldest emails), with the median age of the
accounts between two months and over one year. These
ages indicate that workers are likely sitting upon a stock-
pile of email accounts. Lastly, the worker ratings do not