### Miscellaneous Jobs with Malicious Intentions

**Table 2: Distribution of 2,000 Random, Manually-Labeled Projects into Job Categories**

| Count | %   |
|-------|-----|
| 769   | 38.5|
| 265   | 13.2|
| 138   | 6.9 |
| 100   | 5.0 |
| 177   | 8.8 |
| 22    | 1.1 |
| 19    | 0.9 |
| 14    | 0.7 |
| 195   | 9.8 |
| 53    | 2.6 |
| 20    | 1.0 |
| 61    | 3.0 |
| 25    | 1.2 |
| 8     | 0.4 |
| 33    | 1.7 |
| 41    | 2.1 |
| 32    | 1.6 |
| 21    | 1.1 |
| 17    | 0.9 |
| 10    | 0.5 |
| 1     | 0.1 |
| 35    | 1.8 |

Referenced sections of the appendix include examples of jobs in the corresponding categories.

### Job Details and Intent Determination

In our manually labeled corpus, we were unable to determine the intent of 5.4% of the jobs. The remaining 29.2% of the jobs correspond to various kinds of "dirty" jobs, ranging from delivering phone-verified Craigslist accounts in bulk to a wide variety of search engine optimization (SEO) tasks.

### Identifying "Dirty" Jobs in the Freelancer Corpus

To identify "dirty" jobs in the entire Freelancer corpus, we used keyword matching to generate training sets and supervised learning to train classifiers for each category. We then applied these classifiers to each job to determine the dirty category it falls into, if any.

#### Training Set Generation

To find positive examples for each classifier, we used keywords associated with the job type to conservatively identify jobs that fall into each category. For example, to locate jobs about CAPTCHA solving, we searched job postings for the terms "CAPTCHA" and "type" or "solve." For negative examples, we randomly chose jobs from other orthogonal job types. For features, we computed the well-known tf-idf score (term frequency-inverse document frequency) of each word present in the title, description, and keywords associated with jobs in the training sets. We then used svm-light [9] to train classifiers specific to each category.

### Results of Applying Classifiers

**Table 3: Freelancer Jobs Categorized Using the Classifiers**

| Class            | Count  | %   |
|------------------|--------|-----|
| Accounts         | 6,249  | 0.7 |
| Human CAPTCHA Solving | 4,959 | 0.6 |
| Verified Accounts| 3,120  | 0.4 |
| SEO Content Generation | 72,912 | 8.7 |
| Link Building (Grey Hat) | 16,403 | 1.9 |
| Link Building (White Hat) | 10,935 | 1.3 |
| Ad Posting       | 11,190 | 1.3 |
| Bulk Mailing     | 3,062  | 0.4 |
| OSN Linking      | 11,068 | 1.3 |

Although the classifiers are not perfect (e.g., some jobs placed in the "link building" categories might be better placed in the more generic "SEO" category), they sufficiently capture the set of jobs in each category and greatly increase the number of jobs we can confidently analyze. Note that we did not attempt to be complete in the categorization of the postings; there are likely jobs that should be in a category that we have missed. However, such jobs are also likely not well-marketed to workers, since they most likely lack the typical keywords and phrases commonly used in jobs under those categories.

### Posting Job Listings

Pricing information is a crucial aspect of our study, as it represents the economic value of an abusive activity to attackers. Both job descriptions and bids contain pricing info, often at odds with each other. To determine which source of pricing info to use, we performed an experiment where we posted jobs on Freelancer and solicited bids. In the process, bidders posted public bids and, in some cases, sent private messages to our user account.

These private messages occasionally reveal the external Web store fronts operated by Freelancer workers, in addition to the tools, services, and methods they use to complete each type of job. We posted 15 job listings representative of the categories for which we have classifiers. We also randomly posted half of the jobs as a "featured" listing to determine whether this increased the quantity of bids we received (which it did).

**Table 4: Results from Posting Job Listings to Freelancer**

| Class            | Bids (with prices) | Cost (per unit) |
|------------------|--------------------|-----------------|
| Craigslist PVA   | 10 (4)             | $4.25           |
| Gmail Accounts   | 6 (5)              | $0.07           |
| Hotmail Accounts | 21 (12)            | $0.007          |
| Facebook Accounts| 24 (10)            | $0.07           |
| Blog Backlinks   | 10 (5)             | $0.30           |
| Linking (White Hat) | 17 (8)          | $0.81           |
| Forum Backlinks  | 12 (9)             | $0.50           |
| Social Bookmarks | 44 (21)            | $0.13           |
| Bulk Article Writing | 29 (23)        | $3.00           |
| Spamming         | 10 (5)             | 0.075¢          |
| Bulk Mailing     | 10 (3)             | $0.60           |
| Craigslist Posting | 11 (4)          | $0.026          |
| Facebook Friends | 5 (5)              | $0.039          |
| Twitter Followers| 2 (2)              | $0.037          |
| MySpace Friends  | 7 (6)              | $0.02           |

Of the 228 total bids we received, 47 were commensurate with market rates for these projects. Most of the remaining bids, however, were simply minimum bids used as "place holders." The actual bid amount was either included in a private message to our buyer account, or the bidder provided an email address to negotiate a price outside of the Freelancer site to avoid the Freelancer fee.

Because many prices in the public bids severely underestimate market prices, we use the prices in job descriptions by buyers in our studies in Section 4. Even so, we note that the pricing data has some inherent biases. They are advertised prices and not necessarily the final prices that may have been negotiated with selected workers. Further, we use prices that were systematically extracted from the job descriptions. Even with hundreds of hand-crafted regular expressions, we were only able to extract pricing data from about 10% of the jobs. Job descriptions are notoriously unstructured, ungrammatical, and unconventional. These biases notwithstanding, the pricing data is still useful for comparing the relative value of jobs, as well as trends over time.

### Case Studies

This section features case studies of the four groups of abuse-related Freelancer jobs summarized in Table 2.

#### 4.1 Accounts

Accounts on Web services are the basic building blocks of an abuse workflow. Because they are the main mechanism for access control and policy enforcement (e.g., limits on the number of messages per day), circumventing these limits requires creating additional accounts, often at scale. Thus, account creation has become the primary battlefield in abuse prevention.

Accounts primarily enable a wide variety of spamming and scamming. For Web mail services like Gmail and Yahoo, spammers use accounts to send email spam, taking advantage of the reputation of the online service to improve their conversion rate. For online social networks like Facebook and Twitter, spammers use accounts to spam friends and followers (Section 4.2), taking advantage of relationships to improve conversion. For classified services like Craigslist, spammers use accounts to create highly-targeted lists, post high-ranking advertisements for a variety of scams, recruit money laundering and package handling mules, advertise stolen goods, etc. Further, accounts on some services easily enable paired accounts on related services (e.g., creating a YouTube account from a Gmail account), further extending the opportunities for spamming.

##### 4.1.1 Account Creation Insights

In the context of another research effort, we obtained approval from a major Web mail provider to purchase fraudulently-created accounts on their service. We purchased 500 such accounts from a retail site selling accounts, gave them to the provider, and in return received registration metadata for the supplied email accounts, including account creation times and the IP addresses used to register the accounts. We later discovered that the supplier we contacted was a very active member of Freelancer.com; this worker is responsible for account set IN1 in Table 5.

The supplier had bid on 2,114 projects, had been chosen as a selected worker on 147 projects, and served as a buyer on 84 projects. Interestingly, the supplier acted as a buyer for 25 jobs that involved the creation of other Web mail account types. The supplier contracted out this task at a rate of $10–20 per 1,000 accounts, and yet the supplier charged $20 per 100 accounts on the retail website, an order of magnitude more.

The accounts we purchased were created an average of only 2.8 seconds apart, suggesting the use of either automated software or multiple human account creation teams in parallel. Such automation would be one way to earn money bidding on account jobs for this particular worker. Further, 81% of the IP addresses used to register the accounts were on the Spamhaus blacklist, suggesting the use of IP addresses from compromised hosts to defeat IP-based rate limiting of account creation.

##### 4.1.2 Experience Purchasing Accounts

In 2011, we commissioned a job to purchase additional email accounts for the same Web mail provider in quantities ranging from 3,500–7,000. We selected nine different workers, of which eight ultimately produced accounts, listed in Table 5 after IN1. Once given the accounts and the corresponding passwords, we logged into the accounts and downloaded the newest and oldest inbox pages (assuming the account was valid). Table 5 shows the results of the purchasing and account checking. Of the eight email sets, seven consisted of largely valid accounts, with over 75% of the tested email accounts yielding a successful login. IN3 was particularly interesting; the worker previously used the email addresses to create Facebook and Craigslist logins and posts, then resold the accounts to us. Also, four of the account batches are relatively old (as determined by the date of their oldest emails), with the median age of the accounts between two months and over one year. These ages indicate that workers are likely sitting upon a stockpile of email accounts. Lastly, the worker ratings do not correlate strongly with the quality of the accounts provided.

**Table 5: Summary of the Results from Purchasing Email Accounts**

| Name  | Rating | Tested Valid (%) | Age (Days) |
|-------|--------|------------------|------------|
| IN1*  | 25.7   | 100.0            | 100        |
| UK1   | 24.7   | 99.9             | 9.9        |
| BD1   | 9.7    | 99.6             | 10         |
| IN2   | 78.6   | 99.6             | 9.8        |
| PK1   | 82.6   | 99.4             | 10         |
| PK2   | 414.7  | 95.4             | 9.9        |
| PK3   | 30.7   | 77.3             | 9.9        |
| IN3   | 21.7   | 76.2             | 9.6        |
| CA1** | 21.7   | 15.7             | 100        |

Notes:
*We purchased IN1 in 2010, the rest in 2011.
**The worker responsible for CA1 repeatedly copied and pasted 508 accounts to meet the 5k requirement.