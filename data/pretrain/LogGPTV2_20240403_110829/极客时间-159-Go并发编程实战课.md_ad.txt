# 01 \| Mutex：如何解决资源并发访问问题？你好，我是鸟窝。今天是我们 Go并发编程实战课的第一讲，我们就直接从解决并发访问这个棘手问题入手。说起并发访问问题，真是太常见了，比如多个 goroutine并发更新同一个资源，像计数器；同时更新用户的账户信息；秒杀系统；往同一个buffer中并发写入数据等等。如果没有互斥控制，就会出现一些异常情况，比如计数器的计数不准确、用户的账户可能出现透支、秒杀系统出现超卖、buffer中的数据混乱，等等，后果都很严重。这些问题怎么解决呢？对，用互斥锁，那在 Go 语言里，就是**Mutex。**这节课，我会带你详细了解互斥锁的实现机制，以及 Go 标准库的互斥锁Mutex 的基本使用方法。在后面的 3 节课里，我还会讲解 Mutex的具体实现原理、易错场景和一些拓展用法。好了，我们先来看看互斥锁的实现机制。互斥锁的实现机制互斥锁是并发控制的一个基本手段，是为了避免竞争而建立的一种并发控制机制。在学习它的具体实现原理前，我们要先搞懂一个概念，就是**临界区**。在并发编程中，如果程序中的一部分会被并发访问或修改，那么，为了避免并发访问导致的意想不到的结果，这部分程序需要被保护起来，这部分被保护起来的程序，就叫做临界区。可以说，临界区就是一个被共享的资源，或者说是一个整体的一组共享资源，比如对数据库的访问、对某一个共享数据结构的操作、对一个I/O设备的使用、对一个连接池中的连接的调用，等等。如果很多线程同步访问临界区，就会造成访问或操作错误，这当然不是我们希望看到的结果。所以，我们可以**使用互斥锁，限定临界区只能同时由一个线程持有**。当临界区由一个线程持有的时候，其它线程如果想进入这个临界区，就会返回失败，或者是等待。直到持有的线程退出临界区，这些等待线程中的某一个才有机会接着持有这个临界区。![](Images/5bf73fdf81a00d7e7c245988dec0f365.png)savepage-src="https://static001.geekbang.org/resource/image/44/b8/44c08abdd0aff633ca932fc89386ebb8.jpg"}你看，互斥锁就很好地解决了资源竞争问题，有人也把互斥锁叫做排它锁。那在Go 标准库中，它提供了 Mutex来实现互斥锁这个功能。根据 2019 年第一篇全面分析 Go 并发 Bug的论文 [UnderstandingReal-World Concurrency Bugs inGo  slate-object="inline"，**Mutex是使用最广泛的同步原语**（Synchronizationprimitives，有人也叫做**并发原语**。我们在这个课程中根据英文直译优先用同步原语，但是并发原语的指代范围更大，还可以包括任务编排的类型，所以后面我们讲Channel或者扩展类型时也会用并发原语）。关于同步原语，并没有一个严格的定义，你可以把它看作解决并发问题的一个基础的数据结构。在这门课的前两个模块，我会和你讲互斥锁 Mutex、读写锁RWMutex、并发编排 WaitGroup、条件变量 Cond、Channel等同步原语。所以，在这里，我先和你说一下同步原语的适用场景。1.  共享资源。并发地读写共享资源，会出现数据竞争（data    race）的问题，所以需要 Mutex、RWMutex    这样的并发原语来保护。        2.  任务编排。需要 goroutine 按照一定的规律执行，而 goroutine    之间有相互等待或者依赖的顺序关系，我们常常使用 WaitGroup 或者    Channel 来实现。        3.  消息传递。信息交流以及不同的 goroutine    之间的线程安全的数据交流，常常使用 Channel    来实现。        今天这一讲，咱们就从公认的使用最广泛的 Mutex开始学习吧。是骡子是马咱得拉出来遛遛，看看我们到底可以怎么使用Mutex。 Mutex 的基本使用方法在正式看 Mutex 用法之前呢，我想先给你交代一件事：Locker接口。 在 Go 的标准库中，package sync 提供了锁相关的一系列同步原语，这个package 还定义了一个 Locker 的接口，Mutex就实现了这个接口。Locker的接口定义了锁同步原语的方法集：    type Locker interface {        Lock()        Unlock()    }可以看到，Go定义的锁接口的方法集很简单，就是请求锁（Lock）和释放锁（Unlock）这两个方法，秉承了Go 语言一贯的简洁风格。但是，这个接口在实际项目应用得不多，因为我们一般会直接使用具体的同步原语，而不是通过接口。我们这一讲介绍的 Mutex 以及后面会介绍的读写锁 RWMutex 都实现了 Locker接口，所以首先我把这个接口介绍了，让你做到心中有数。下面我们直接看 Mutex。简单来说，**互斥锁 Mutex 就提供两个方法 Lock 和Unlock：进入临界区之前调用 Lock 方法，退出临界区的时候调用 Unlock方法**：      func(m *Mutex)Lock()      func(m *Mutex)Unlock()**当一个 goroutine 通过调用 Lock 方法获得了这个锁的拥有权后，其它请求锁的 goroutine 就会阻塞在 Lock方法的调用上，直到锁被释放并且自己获取到了这个锁的拥有权。**看到这儿，你可能会问，为啥一定要加锁呢？别急，我带你来看一个并发访问场景中不使用锁的例子，看看实现起来会出现什么状况。在这个例子中，我们创建了 10 个goroutine，同时不断地对一个变量（count）进行加 1 操作，每个 goroutine负责执行 10 万次的加 1 操作，我们期望的最后计数的结果是 10 \* 100000 =1000000 (一百万)。     import (            "fmt"            "sync"        )                func main() {            var count = 0            // 使用WaitGroup等待10个goroutine完成            var wg sync.WaitGroup            wg.Add(10)            for i := 0; i >mutexWaiterShift == 0 || old&(mutexLocked|mutexWoken) != 0 { // 没有等待者，或者有唤醒的waiter，或者锁原来已加锁                    return                }                new = (old - 1>mutexWaiterShift != 0 &&                            atomic.CompareAndSwapInt32(&m.state, old, old|mutexWoken) {                            awoke = true                        }                        runtime_doSpin()                        iter++                        continue // 自旋，再次尝试请求锁                    }                    new = old + 1>mutexWaiterShift != 0 &&                        atomic.CompareAndSwapInt32(&m.state, old, old|mutexWoken) {                        awoke = true                    }                    runtime_doSpin()                    iter++                    old = m.state // 再次获取锁的状态，之后会检查是否锁被释放了                    continue                }                new := old                if old&mutexStarving == 0 {                    new |= mutexLocked // 非饥饿状态，加锁                }                if old&(mutexLocked|mutexStarving) != 0 {                    new += 1  starvationThresholdNs                    old = m.state                    // 如果锁已经处于饥饿状态，直接抢到锁，返回                    if old&mutexStarving != 0 {                        if old&(mutexLocked|mutexWoken) != 0 || old>>mutexWaiterShift == 0 {                            throw("sync: inconsistent mutex state")                        }                        // 有点绕，加锁并且将waiter数减1                        delta := int32(mutexLocked - 1>mutexWaiterShift == 1 {                            delta -= mutexStarving // 最后一个waiter或者已经不饥饿了，清除饥饿标记                        }                        atomic.AddInt32(&m.state, delta)                        break                    }                    awoke = true                    iter = 0                } else {                    old = m.state                }            }        }                func (m *Mutex) Unlock() {            // Fast path: drop lock bit.            new := atomic.AddInt32(&m.state, -mutexLocked)            if new != 0 {                m.unlockSlow(new)            }        }                func (m *Mutex) unlockSlow(new int32) {            if (new+mutexLocked)&mutexLocked == 0 {                throw("sync: unlock of unlocked mutex")            }            if new&mutexStarving == 0 {                old := new                for {                    if old>>mutexWaiterShift == 0 || old&(mutexLocked|mutexWoken|mutexStarving) != 0 {                        return                    }                    new = (old - 1> mutexWaiterShift //得到等待者的数值        v = v + (v & mutexLocked) //再加上锁持有者的数量，0或者1        return int(v)    }这个例子的第 14 行通过 unsafe 操作，我们可以得到 state 字段的值。第15 行我们右移三位（这里的常量 mutexWaiterShift 的值为3），就得到了当前等待者的数量。如果当前的锁已经被其他 goroutine持有，那么，我们就稍微调整一下这个值，加上一个 1（第 16行），你基本上可以把它看作是当前持有和等待这把锁的 goroutine的总数。 state这个字段的第一位是用来标记锁是否被持有，第二位用来标记是否已经唤醒了一个等待者，第三位标记锁是否处于饥饿状态，通过分析这个state字段我们就可以得到这些状态信息。我们可以为这些状态提供查询的方法，这样就可以实时地知道锁的状态了。    // 锁是否被持有    func (m *Mutex) IsLocked() bool {        state := atomic.LoadInt32((*int32)(unsafe.Pointer(&m.Mutex)))        return state&mutexLocked == mutexLocked    }    // 是否有等待者被唤醒    func (m *Mutex) IsWoken() bool {        state := atomic.LoadInt32((*int32)(unsafe.Pointer(&m.Mutex)))        return state&mutexWoken == mutexWoken    }    // 锁是否处于饥饿状态    func (m *Mutex) IsStarving() bool {        state := atomic.LoadInt32((*int32)(unsafe.Pointer(&m.Mutex)))        return state&mutexStarving == mutexStarving    }我们可以写一个程序测试一下，比如，在 1000 个 goroutine并发访问的情况下，我们可以把锁的状态信息输出出来：    func count() {        var mu Mutex        for i := 0; i =0)修改为负数（readerCount-rwmutexMaxReaders），让这个字段保持两个含义（既保存了reader 的数量，又表示当前有writer）。 我们来看下下面的代码。第 5 行，还会记录当前活跃的 reader数量，所谓活跃的 reader，就是指持有读锁还没有释放的那些reader。     func (rw *RWMutex) Lock() {        // 首先解决其他writer竞争问题        rw.w.Lock()        // 反转readerCount，告诉reader有writer竞争锁        r := atomic.AddInt32(&rw.readerCount, -rwmutexMaxReaders) + rwmutexMaxReaders        // 如果当前有reader持有锁，那么需要等待        if r != 0 && atomic.AddInt32(&rw.readerWait, r) != 0 {            runtime_SemacquireMutex(&rw.writerSem, false, 0)        }    }如果 readerCount 不是 0，就说明当前有持有读锁的 reader，RWMutex需要把这个当前 readerCount 赋值给 readerWait 字段保存下来（第 7 行），同时，这个 writer 进入阻塞等待状态（第 8行）。 每当一个 reader 释放读锁的时候（调用 RUnlock 方法时），readerWait字段就减 1，直到所有的活跃的 reader 都释放了读锁，才会唤醒这个writer。 Unlock当一个 writer 释放锁的时候，它会再次反转 readerCount字段。可以肯定的是，因为当前锁由 writer 持有，所以，readerCount字段是反转过的，并且减去了 rwmutexMaxReaders这个常数，变成了负数。所以，这里的反转方法就是给它增加 rwmutexMaxReaders这个常数值。 既然 writer 要释放锁了，那么就需要唤醒之后新来的reader，不必再阻塞它们了，让它们开开心心地继续执行就好了。 在 RWMutex 的 Unlock返回之前，需要把内部的互斥锁释放。释放完毕后，其他的 writer才可以继续竞争这把锁。     func (rw *RWMutex) Unlock() {        // 告诉reader没有活跃的writer了        r := atomic.AddInt32(&rw.readerCount, rwmutexMaxReaders)                // 唤醒阻塞的reader们        for i := 0; i   > A RWMutex is a reader/writer mutual exclusion> lock.> >>  > The lock can be held by any number of readers or a single writer,> and> >>  > a blocked writer also blocks new readers from acquiring the> lock.> >这个描述是相当精确的，它指出了 RWMutex 可以被谁持有，以及 writer比后续的 reader有获取锁的优先级。 虽然 RWMutex 暴露的 API 也很简单，使用起来也没有复杂的逻辑，但是和Mutex一样，在实际使用的时候，也会很容易踩到一些坑。接下来，我给你重点介绍 3个常见的踩坑点。 RWMutex 的 3 个踩坑点坑点 1：不可复制前面刚刚说过，RWMutex是由一个互斥锁和四个辅助字段组成的。我们很容易想到，互斥锁是不可复制的，再加上四个有状态的字段，RWMutex就更加不能复制使用了。 不能复制的原因和互斥锁一样。一旦读写锁被使用，它的字段就会记录它当前的一些状态。这个时候你去复制这把锁，就会把它的状态也给复制过来。但是，原来的锁在释放的时候，并不会修改你复制出来的这个读写锁，这就会导致复制出来的读写锁的状态不对，可能永远无法释放锁。 那该怎么办呢？其实，解决方案也和互斥锁一样。你可以借助 vet工具，在变量赋值、函数传参、函数返回值、遍历数据、struct初始化等时，检查是否有读写锁隐式复制的情景。 坑点 2：重入导致死锁读写锁因为重入（或递归调用）导致死锁的情况更多。 我先介绍第一种情况。因为读写锁内部基于互斥锁实现对 writer的并发访问，而互斥锁本身是有重入问题的，所以，writer 重入调用 Lock的时候，就会出现死锁的现象，这个问题，我们在学习互斥锁的时候已经了解过了。     func foo(l *sync.RWMutex) {        fmt.Println("in foo")        l.Lock()        bar(l)        l.Unlock()    }    func bar(l *sync.RWMutex) {        l.Lock()        fmt.Println("in bar")        l.Unlock()    }    func main() {        l := &sync.RWMutex{}        foo(l)    }运行这个程序，你就会得到死锁的错误输出，在 Go运行的时候，很容易就能检测出来。 第二种死锁的场景有点隐蔽。我们知道，有活跃 reader 的时候，writer会等待，如果我们在 reader 的读操作时调用 writer 的写操作（它会调用 Lock方法），那么，这个 reader 和 writer 就会形成互相依赖的死锁状态。Reader想等待 writer 完成后再释放锁，而 writer 需要这个 reader释放锁之后，才能不阻塞地继续执行。这是一个读写锁常见的死锁场景。 第三种死锁的场景更加隐蔽。 当一个 writer 请求锁的时候，如果已经有一些活跃的reader，它会等待这些活跃的 reader完成，才有可能获取到锁，但是，如果之后活跃的 reader 再依赖新的 reader的话，这些新的 reader 就会等待 writer释放锁之后才能继续执行，这就形成了一个环形依赖： **writer依赖活跃的 reader -\> 活跃的 reader 依赖新来的 reader -\> 新来的 reader依赖 writer**。 ![](Images/9b71245dcbc14ea2a34565e3ba5097e1.png)savepage-src="https://static001.geekbang.org/resource/image/c1/35/c18e897967d29e2d5273b88afe626035.jpg"}这个死锁相当隐蔽，原因在于它和 RWMutex的设计和实现有关。啥意思呢？我们来看一个计算阶乘 (n!)的例子：     func main() {        var mu sync.RWMutex        // writer,稍微等待，然后制造一个调用Lock的场景        go func() {            time.Sleep(200 * time.Millisecond)            mu.Lock()            fmt.Println("Lock")            time.Sleep(100 * time.Millisecond)            mu.Unlock()            fmt.Println("Unlock")        }()        go func() {            factorial(&mu, 10) // 计算10的阶乘, 10!        }()                select {}    }    // 递归调用计算阶乘    func factorial(m *sync.RWMutex, n int) int {        if n  活跃的 reader 依赖新来的 reader -\> 新来的 reader依赖writer"的死锁条件，所以就导致了死锁的产生。 所以，使用读写锁最需要注意的一点就是尽量避免重入，重入带来的死锁非常隐蔽，而且难以诊断。 坑点 3：释放未加锁的 RWMutex和互斥锁一样，Lock 和 Unlock 的调用总是成对出现的，RLock 和 RUnlock的调用也必须成对出现。Lock 和 RLock多余的调用会导致锁没有被释放，可能会出现死锁，而 Unlock 和 RUnlock多余的调用会导致 panic。在生产环境中出现 panic是大忌，你总不希望半夜爬起来处理生产环境程序崩溃的问题吧？所以，在使用读写锁的时候，一定要注意，**不遗漏不多余**。 流行的 Go 开发项目中的坑好了，又到了泡一杯宁夏枸杞加新疆大滩枣的养生茶，静静地欣赏知名项目出现Bug 的时候了，这次被拉出来的是 RWMutex 的Bug。 Dockerissue 36840issue 36840修复的是错误地把 writer 当成 reader的 Bug。这个地方本来需要修改数据，需要调用的是写锁，结果用的却是读锁。或许是被它紧挨着的findNode 方法调用迷惑了，认为这只是一个读操作。可实际上，代码后面还会有changeNodeState 方法的调用，这是一个写操作。修复办法也很简单，只需要改成Lock/Unlock 即可。 ![](Images/de34e5552d6039a0d37c731f3294d487.png)savepage-src="https://static001.geekbang.org/resource/image/e4/4b/e4d153cb5f81873a726b09bc436b8a4b.png"}Kubernetesissue 62464issue 62464slate-object="inline"就是读写锁第二种死锁的场景，这是一个典型的 reader导致的死锁的例子。知道墨菲定律吧？"凡是可能出错的事，必定会出错"。你可能觉得我前面讲的RWMutex 的坑绝对不会被人踩的，因为道理大家都懂，但是你看，Kubernetes就踩了这个重入的坑。 这个 issue 在移除 pod的时候可能会发生，原因就在于，GetCPUSetOrDefault方法会请求读锁，同时，它还会调用 GetCPUSet 或 GetDefaultCPUSet方法。当这两个方法都请求写锁时，是获取不到的，因为 GetCPUSetOrDefault方法还没有执行完，不会释放读锁，这就形成了死锁。 ![](Images/bd4fc818ebefa04c07fd7bbe0f766867.png)savepage-src="https://static001.geekbang.org/resource/image/06/c2/062ae5d2a6190f86cb7bf57db643d8c2.png"}总结在开发过程中，一开始考虑共享资源并发访问问题的时候，我们就会想到互斥锁Mutex。因为刚开始的时候，我们还并不太了解并发的情况，所以，就会使用最简单的同步原语来解决问题。等到系统成熟，真正到了需要性能优化的时候，我们就能静下心来分析并发场景的可能性，这个时候，我们就要考虑将Mutex 修改为RWMutex，来压榨系统的性能。 当然，如果一开始你的场景就非常明确了，比如我就要实现一个线程安全的map，那么，一开始你就可以考虑使用读写锁。 正如我在前面提到的，如果你能意识到你要解决的问题是一个readers-writers 问题，那么你就可以毫不犹豫地选择RWMutex，不用考虑其它选择。那在使用 RWMutex时，最需要注意的一点就是尽量避免重入，重入带来的死锁非常隐蔽，而且难以诊断。 另外我们也可以扩展 RWMutex，不过实现方法和互斥锁 Mutex差不多，在技术上是一样的，都是通过 unsafe来实现，我就不再具体讲了。课下你可以参照我们上节课学习的方法，实现一个扩展的RWMutex。 这一讲我们系统学习了读写锁的相关知识，这里提供给你一个知识地图，帮助你复习本节课的知识。 ![](Images/076b07ebb4c4351aa2691cfcbded810a.png)savepage-src="https://static001.geekbang.org/resource/image/69/42/695b9aa6027b5d3a61e92cbcbba10042.jpg"}思考题请你写一个扩展的读写锁，比如提供 TryLock，查询当前是否有writer、reader 的数量等方法。 欢迎在留言区写下你的思考和答案，我们一起交流讨论。如果你觉得有所收获，也欢迎你把今天的内容分享给你的朋友或同事。 