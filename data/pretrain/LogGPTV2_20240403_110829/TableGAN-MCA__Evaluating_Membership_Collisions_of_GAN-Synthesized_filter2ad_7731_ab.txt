𝐽 (𝐷)(cid:16)
E𝒛𝐷(𝐺(𝑧)),
(1)
(2)
In this work, we use its weight clipping version (WGAN-WC) [2],
Gradient Penalty version (WGAN-GP) [15] and CTGAN (state-of-
the-art) [46]. We also include TVAE from [46] for its comparable
performance as CTGAN. Following [46], all three GANs uses re-
current networks in the generator. For categorical features, we use
the gumble-softmax activation in the output of the generator. For
numerical features, we use the sigmoid or the tanh activation in
the output of the generator based on value range. The architecture
and parameters of GANs are broken down in Appendix 5.1.
3 PROBLEM FORMULATION
In this section, we formulate our membership collisions problem,
followed by the description of the threat model according to adver-
sary’s goals, capabilities and background knowledge. We introduce
all the notations used throughout the paper in Table 2.
3.1 Membership Collision Problem
We let 𝐷𝑡 = {x} be a training set sampled from an implicit data
distribution P𝑟 . Each private entry takes the form as x = (𝑥, 𝑦) ∈ X×
Y, where 𝑥 represents the features and 𝑦 represents the class label.
A data release mechanism GAN trains on the training set 𝐷𝑡 and
outputs a well learned generator 𝐺. Generator 𝐺 is a deterministic
function that maps a prior distribution, i.e., Gaussian distribution
P𝑧, to the generated distribution P𝑔 that mimic real distribution
P𝑟 . Then, a synthetic dataset 𝑆 ∼ P𝑔 is published and serves as a
sanitized version of 𝐷𝑡. We formalize the membership collisions
as : a published synthetic datasets 𝑆 ∼ P𝑔 collide with its training
set 𝐷𝑡 ∼ P𝑟 and result in a colliding member set 𝐼 = 𝑆 ∩ 𝐷𝑡. Notice
that a data point x ∈ 𝐼 result in x ∈ 𝐷𝑡. Similarly, a synthetic data
point x ∉ 𝐼 result in x ∉ 𝐷𝑡.
We aim to study how much an adversary A increases its ability to
assert whether a synthetic data point x ∼ 𝑆 belongs to the colliding
member set 𝐼 by estimating the generated distribution P𝑔 via the
published synthetic dataset 𝑆. Formally,
Definition 3.1 (Membership Collision Attack). Given a synthetic
dataset 𝑆 produced by a generative model 𝐺(P𝑧, 𝐷𝑡) that contains
a colliding member set 𝐼 = 𝑆 ∩ 𝐷𝑡 and an attack algorithm A(x)
that outputs 1 if it outputs the synthetic data x ∈ 𝐼, we say the
Figure 3: Comparisons of sample frequency between mem-
bers and non-members. The x-axis represents all possibili-
ties of {#x𝑖} in published synthetic datasets and y-axis rep-
resents log of the number of eligible data points.
generative model 𝐺 is subject to membership collision inference
attack if there exists an entry x ∈ 𝑆 such that
Pr[A(x, P𝑔) = 1] − Pr[A(x) = 1] > 𝛼,
(3)
where 𝛼 is a non-negligible value.
In this work, we consider that the prior advantage of the attacker
is random guess, that is, Pr[A(x) = 1] = Pr[x ∈ 𝐼]. Thus, we
evaluate the posterior advantage of the attacker thereafter.
Note that Def. 3.1 differs from the membership inference defini-
tion [43] by changing the goal of arbitrary membership inference
with membership collision inference of synthetic data. The pro-
posed TableGAN-MIA is an instance of MCA in GAN-synthesized
table releasing.
3.2 Threat Model
In the context of GAN-synthesized data sharing, adversaries are
external parties that wish to learn the statistics of the sensitive
dataset by querying data owners or curators. In existing MIAs
against GANs [7, 20, 21, 35], the adversary’s knowledge is: (1) hav-
ing only limited synthetic data, (2) accessing a black-box generator
API (unlimited synthetic data), (3) accessing a black-box generator
plus a discriminator oracle, (4) accessing a white-box GAN. Our
study focus on the most strict attack model: (1) and (2) (which is
similar to the threat model in MC [21] and “Full Black-box Genera-
tor" assumption in GAN-Leaks [7]). The attacker does not know the
priori of the model’s structure, including meta-parameters, training
data and any target data to infer membership. In TableGAN-MCA,
the adversary’s goal is to recover the value of some members of the
training set from the published synthetic datasets that may unin-
tentionally contain colliding members. In this paper, we evaluate
TableGAN-MCA under two threat models:
Attack model (1): accessible to limited synthetic data. We assume
the adversary has one copy of synthetic dataset 𝑆 following P𝑔, of
size |𝑆| = |𝐷𝑡| = 𝑛.
Attack model (2): accessible to unlimited synthetic data. We as-
sume the adversary has 𝑁𝑠 (𝑁𝑠 is a positive integer) synthetic copies
{𝑆1, 𝑆2, . . . , 𝑆𝑁𝑠 }, each of which has size |𝑆𝑖| = |𝐷𝑡| = 𝑛.
Session 7A: Privacy Attacks and Defenses for ML CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea20984 MEMBERSHIP RECOVERY FRAMEWORK
AGAINST GAN-SYNTHESIZED TABLES
In this section, we propose a membership indicator for inferring
membership collisions from the statistics of the published table.
Based on the membership indicator, we propose the TableGAN-
MCA to recover the value of the training set of GAN-synthesized
tables in the black-box setting.
4.1 Membership Indicator
The membership indicator is triggered by two observations. First,
the released GAN-synthesized tables often overlap the training
dataset of the GAN model. Second, such synthetic data points ap-
pearing frequently in the published GAN-synthesized data are more
likely to be the colliding member of the training dataset. That is,
Pr[x ∈ 𝐷𝑡|P𝑔] ∝ Pr[x|P𝑔]. Fig. 3 depicts the observations from
three datasets used in this paper, where we count the numbers of
members and non-members, given numbers of appearance of the
data points in the released synthetic tables. In Fig. 3 (left), approx-
imately 96% of synthetic data with a sampled frequency of more
than three are colliding members. Conversely, almost 91% unique
synthetic data are non-colliding members in the Adult dataset. Thus,
sample frequency is highly correlated with membership collisions
and can be treated as an indicator to indicate membership. Formally,
we estimated the membership indicator by the following equation.
Pr(cid:2)x𝑖 | 𝑃𝑔(cid:3) ≈ E
1(cid:0)x𝑖 = x𝑗(cid:1) =
x𝑗 ∈𝑆
1(cid:0)x𝑖 = x𝑗(cid:1) ,
𝑛
𝑗=1
1
𝑛
(4)
where an indicator function 1(·) outputs 1 if its argument is true,
𝑆 is the synthetic datasets available to the adversary following P𝑔,
of size |𝑆| = 𝑛.
To date, the adversary can launch a data reconstruction attack by
setting a threshold for the value of a membership collisions indicator
of Eq. (4), similar to [7]. The adversary then claims that the synthetic
data, having collisions indicators greater than a given threshold,
are the recovered data. However, choosing an optimal threshold is
a non-trivial task for an adversary without background knowledge
about training data except the published synthetic data. To deal
with it, we additionally leverage shadow model techniques [43]
to enhance the knowledge of adversaries to construct a robust
TableGAN-MCA framework.
4.2 TableGAN-MCA
In a nutshell, TableGAN-MCA combines the membership collisions
indicator and the shadow models [43] to train an attack model
to learn the relation between membership collisions (labels) and
indicator values (features) in released GAN-synthesized tables. Fig. 4
depicts the framework of TableGAN-MCA and Alg. 1 shows the
detailed implementation. Each step in Alg. 1 corresponds to the
step index in Fig. 4. In summary, steps 2, 3, 4 and 5 train an attack
classifier by giving synthetic data. Steps 1 and 6 infer membership
collisions to recover training data.
In Steps 1 and 4, {#x} represents estimated sample frequency
following from Eq. 4. They are concatenated (“⊲⊳”) to 𝑆𝑖 (Step 1) and
(cid:101)𝑆𝑖 (Step 4) as an extra feature.
Figure 4: The overview of the procedures of TableGAN-MCA
against the black-box generator in data synthesis.
ALGORITHM 1: TableGAN-MCA.
Input: {𝑆1, 𝑆2, ..., 𝑆𝑁𝑠 }: Released synthetic datasets; |𝐷𝑡 |: Size of the
training dataset;
Output: 𝑅: Recovered data from 𝐷𝑡
while 𝑖 : 1 → 𝑁𝑠 do
end
𝑁𝑠 } ;
x′
;
𝑖=1{𝑦′
Ground truth label 𝑦′
𝑖 ← 1
Step 4:
Frequency {#x′
Eq. (4);
Step 1:
Frequency {#x𝑖 } ← Estimate frequency for each x𝑖 ∈ 𝑆𝑖 by
Eq. (4);
𝑆𝑖 ← 𝑆𝑖 ⊲⊳ {#x𝑖 };
𝑖 } ← Count the frequency for each x′
𝑖 };
Step 2: Shadow GAN generator(cid:101)𝐺𝑖 ← Train on 𝑆𝑖;
Step 3: Shadow set(cid:101)𝑆𝑖 ← Sample from(cid:101)𝐺𝑖, |(cid:101)𝑆𝑖 | = 𝑁𝑠 × |𝐷𝑡 |.
𝑖 ∈(cid:101)𝑆𝑖 by
(cid:101)𝑆𝑖 ←(cid:101)𝑆𝑖 ⊲⊳ {#x′
(cid:16)
Step 5: TableGAN-MCA attack model 𝑓 (·) ← Train on(cid:13)(cid:13)𝑁𝑠
member/non-member labels(cid:13)(cid:13)𝑁𝑠
(cid:13)(cid:13)𝑁𝑠
collisions in shadow datasets. For a shadow dataset(cid:101)𝑆𝑖 such that
𝑆𝑖 ∩(cid:101)𝑆𝑖 =(cid:101)𝐼𝑖, a membership collisions label for each data x′
(cid:17)
𝑖 ∈(cid:101)𝐼𝑖
𝑖 }, where(cid:13)(cid:13)𝑁𝑠
𝑖=1(cid:101)𝑆𝑖 with
𝑖=1(cid:101)𝑆𝑖 =(cid:101)𝑆1∥ . . . ∥(cid:101)𝑆𝑁𝑠 ;
1}∥ . . . ∥{𝑦′
𝑖 } = {𝑦′
𝑖=1{𝑦′
Step 6: 𝑅A ← 𝑓 ({𝑆𝑖 });
return 𝑅A
In Step 4, a label function is required to claim membership
.
x′
𝑦′
𝑖 = 1
In Step 6, attack model 𝑓 (·) outputs the predicted probability
about whether a synthetic data is colliding member. Adversaries
then expose a data set 𝑅A that with high prediction scores.
For attack model (2) (unlimited synthetic data) such that 𝑁𝑠 > 1,
the adversary repeat the Step1 to Step 4 𝑁𝑠 times and gets 𝑁𝑠 labeled
𝑁𝑠 × |𝐷𝑡|. Then the adversary concat (“∥”) all shadow datasets
together to train the attack model.
shadow datasets {(cid:101)𝑆1,(cid:101)𝑆2, ...,(cid:101)𝑆𝑁𝑠 } such that each of them with size
Note that in the worst-case (to the adversary), where the inter-
section between the training set and the synthetic dataset could be
empty, the adversary of TableGAN-MCA cannot recover anything
𝑖 will be
(cid:16)
(cid:17)
𝑖 ∈(cid:101)𝐼𝑖
Inference Data……sampletrainAttack Training Data…trainInference56NsNs1…………x(2)x(n)x(1)x(n)x(1)x(2)x(n)x(1)#x(2)#x(1)#x(n)y′(1)x′(n)x′(1)x′(2)#x′(2)#x′(n)#x′(1)y′(n)y′(2)x(2)sample{!Si}{Si}34f(·)G(Pz,Dt)!G(Pz,Si)2Target modelShadow modelSession 7A: Privacy Attacks and Defenses for ML CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2099from the private training data. To avoid such a case, we would dis-
cretize the synthetic dataset to generalize the range of each feature
such that there is a non-empty intersection. In this way, we could (at
least) recover coarse-grained information regarding the members
within the training data. We show the details of the discretization
operation in Section 5.2.
5 EVALUATION
In this section, we first introduce the methods of tabular data syn-
thesis, then introduce the evaluation metrics. Next we show the
attack performance of TableGAN-MCA as well as the comparisons
with recent works.
5.1 Network Structure and Parameters
WGAN-GP, WGAN-WC shares the same network architecture. We
set the Generator as Recurrent Neural Networks (RNNs). According
to our experiments, the RNN has a positive effect on stabilizing the
generator’s outputs. Eq. (5) represents the Generator networks and
Eq. (6) represents the Discriminator networks.
ℎ1 = ReLU(BN(FC|𝑧|→256(𝑧)))
ℎ2 = ReLU(BN(FC|𝑧|+256→256(𝑧 ⊕ ℎ1)))
𝐺(·)𝑐𝑜𝑛 = gumbel0.2(FC|𝑧|+512→|𝑟 |(ℎ2))
𝐺(·)𝑐𝑎𝑡 = tanh(FC|𝑧|+512→1(ℎ2))
 ℎ1 = dropout0.5(leakyReLU0.2(FC|𝑟 |→256(𝑟)))
ℎ2 = dropout0.5(leakyReLU0.2(FC256→256(ℎ1)))
𝐷(·) = FC256→1(ℎ2))
(6)
(5)
For TVAE and CTGAN, we applies the module CTGANSynthesizer
and TVAESynthesizer of the SDGym [5]. Thus, the structures and
hyper-parameters are exactly same as the originals’ [46].
Hyper-parameters. For Adult and Lawschool datasets, we train
300 epochs and set batch size to 500. For Compas dataset, we train
600 epochs and set batch size to 100. Since the Compas dataset
is much smaller than others, we find that less iterations could
incur under-fitting. Additionally, balancing the number of D and G
training sessions also helps to converge faster.
5.2 Dataset Synthesis
We perform experimental evaluations on three commonly used [3,
8, 35, 40, 46] real-world tables, Adult [39], Lawschool [38] and
Compas [22].
Adult: The US Adult Census dataset is a repository of 48842 entries
extracted from 1994 US Census dataset, where 45222 entries have
complete information. After pre-processing, it remains 1 numerical
feature, 12 categorical features and 1 binary label.
Lawschool: This dataset comes from the Law School Admission
Council’s National Longitudinal Bar Passage Study. It contains ap-
plication records for 25 different law schools with 86022 individuals.
It has 2 numerical features, 5 categorical features and 1 binary label.
Compas: COMPAS recidivism risk score and criminal history data
is collected by ProPublica in 2016. After pre-processing, it remains
5278 entries with 4 numerical features, 6 categorical features and 1
binary labels.
Table 3: Dataset Statistics for GAN synthesis. Pr[#x = 1]:
unique training data proportion; Pr[#x ≤ 3]: Proportion of
training data with frequency less than 3.
# of Train 𝐷𝑡 (70%)
# of Test 𝐷𝑠 (30%)
Pr[#x = 1]
Pr[#x ≤ 3]
Adult
31655
13567
79.39%
86.07%
Lawsch Compas
60215
25807
71.28%
81.85%
3694
1584
63.72%
74.28%
Note that unlike MIAs attacking classifiers that produce pre-
dicted labels with probability, generative models only output syn-
thetic samples. The labels in generated datasets serve as an ordinary
feature like other features when training attack models. Therefore,
for simplicity, we use the three binary-labeled datasets in our ex-
periments.
Tabular data synthesis. For training generative models, we apply
Tabular Variational Autoencoder (TVAE) [46], CTGAN [46], WGAN-
GP [15] and WGAN-WC [2] for their superior modeling quality in
tabular synthesis. To facilitate data synthesis, we have the following