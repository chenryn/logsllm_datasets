for particular programming languages. (2) Applications us-
ing certiﬁcate pinning to verify the integrity of ﬁles when
stored under external control (cloud storage), including ver-
sion control systems like Git. (3) Package managers that use
GnuPG for integrity protection of software packages.
We found vulnerable software in all three categories, but
due to the large number of libraries and applications using
GnuPG, we could not yet perform an extensive review. Also,
we found that the available code search engines are not a
good match for the task of identifying applications calling an
external application through a shell interface. We therefore
fear that there may still be a signiﬁcant number of vulnerable
applications using GnuPG out there.
Python-GnuPG Python-gnupg18 is a library interface to
GnuPG for the Python language. It uses the status line inter-
face and conﬂates it with the logging messages, making 717
applications using it19 potentially susceptible to the embed-
ded ﬁlename injection attack described above, depending on
how and in which context they use the Python library.
Bitcoin Source Code Repository Integrity The Bitcoin
project uses the Git version control system, which supports
signatures on individual software patches to verify the in-
tegrity of the whole repository as it changes over time. A
shell script using GnuPG to verify the integrity of all com-
mits is included in the distribution.20 This script uses the
status line API and does not anchor the regular expressions,
making it susceptible to the malicious user ID injection at-
tack described above. An attacker who can inject arbitrary
keys into the keyring of the user can simply re-sign modiﬁed
source code commits and thus bypass the veriﬁcation script.
The Bitcoin source code is frequently used as the basis for
other crypto-currencies,21 and thus this error may propagate
to many other similar projects such as Litecoin.
Signature Bypass in Simple Password Store Pass22, a
popular password manager for UNIX, uses the GnuPG status
line API to encrypt password ﬁles and digitally sign conﬁg-
uration ﬁles and extension plugins. It does not anchor the
regular expressions, making it susceptible to the malicious
18V. Sajip, python-gnupg – A Python wrapper for GnuPG,
https://pythonhosted.org/python-gnupg/
19According to libraries.io, https://libraries.io/pypi/python-gnupg/usage
20Bitcoin Source Code, https://github.com/bitcoin/bitcoin/
blob/master/contrib/verify-commits/gpg.sh
21According to GitHub the Bitcoin code has 21379 forks as of Nov. 2018
22J. A. Donenfeld, pass, https://www.passwordstore.org/
USENIX Association
28th USENIX Security Symposium    1025
user ID injection attack described above. If pass is used to
synchronize passwords over untrusted cloud storage, an at-
tacker with control over that storage can add their public key
to the conﬁguration, which causes pass to transparently re-
encrypt the passwords to the attackers key (in addition to the
user’s key) over time. Also, if extension plugins are enabled,
the attacker can get remote code execution. This ﬁnding is
documented as CVE-2018-12356.
Yarn Package Manager Yarn is a package manager by
Facebook for the JavaScript runtime Node.js. The Yarn in-
staller script23 primarily relies on TLS to secure the integrity
of the installation package itself. However, it also attempts to
use GnuPG signature veriﬁcation, presumably to secure the
integrity of the installer from the build server to the down-
load server, which can be different from the server that hosts
the installer script (e.g., for nightly builds).
Unfortunately, Yarn fails to do any form of certiﬁcate pin-
ning or trust management, and will accept any valid signature
by any key in the local keyring, even by untrusted keys. If
the attacker can inject a public key into the user’s keyring,
and perform a MiTM attack against one of Yarn’s download
servers, the attacker can replace the installation package with
one containing a backdoor, thereby gaining remote code ex-
ecution on the user’s machine. This ﬁnding is documented
as CVE-2018-12556.
7.6 Unsuccessful Cryptograpic Attacks
We analyzed 19 of 20 OpenPGP email clients from Table 2
(all but Airmail, which we could not test, see subsection 7.2)
and all 22 email clients supporting S/MIME signatures from
Table 3 if they are vulnerable to well-known attacks on the
PKCS#1v1.5 signature scheme for RSA with exponent e = 3.
Speciﬁcally, we checked for mistakes in the handling of the
padding [16] and ASN.1 structures [17]. All tested clients
resisted our attempts.
8 Related Work
The OpenPGP standard [6] only deﬁnes how to sign the
email body. Critical headers such as SUBJECT and FROM are
not signed if no further extensions, such as Memory Hole
[12], Secure Header Fields [18] or XML-based techniques
as described in [19], are applied. Levi et al. [20] developed a
GUI for users to better understand the limitations of S/MIME
digital signatures for emails, i.e., showing which parts of the
email are actually signed by whom. Usability papers such
as [21] discuss the difﬁculties that inexperienced users have
to manually verify the validity of a signature and understand
the different PGP trust levels.
23Yarn installer script, https://yarnpkg.com/install.sh
It is well known that messages signed by a certain en-
tity can be reused in another context. For example, a ma-
licious former employer in possession of a signed “I quit
my job” message by Alice can simply re-send this mes-
sage to Alice’s new employer. Such attacks have been re-
ferred to as “surreptitious forwarding” in 2001 by Davis [22]
who also showed how to strip signatures in various encryp-
tion schemes. Gillmor [23] touches upon the problems of
partially-signed Inline PGP messages as well as non-signed
attachments and the UI challenge such constructs present for
MUAs. Furthermore, he demonstrates a message tampering
attack through header substitution: by changing the encod-
ing, a signed message with the content e13/week can be pre-
sented as £13/week, while the signature remains valid.
Recently, Poddebniak et al. [9] described two attacks to
directly exﬁltrate the plaintext of OpenPGP encrypted mes-
sages. One works by wrapping the ciphertexts into attacker-
controlled MIME parts. This is related to our MIME wrap-
ping attacks on signatures, as both techniques exploit miss-
ing isolation between multiple MIME parts. However, we
present attacks which do not require mail clients to put
trusted and untrusted input into the same DOM, using ad-
vanced approaches such as cid: URI scheme references.
GnuPG had signature spooﬁng bugs in the past. In 2006,
it was shown that arbitrary unsigned data can be injected into
signed messages [14]. Until 2007, GnuPG returned a valid
signature status for a message with arbitrary text prepended
or appended to an Inline PGP signature, allowing an attacker
to forge the contents of a message without detection [24].
In 2014, Klafter et al. [15] showed practical collisions in
32-bit PGP key IDs, named the “Evil 32” attack, which can
be dangerous in case a client requests a PGP key from a key-
server using the 32-bit ID. Collisions with 64-bit IDs are also
feasible but require more computing power, therefore only
full 160-bit ﬁngerprints should be used.
“Mailsploit” [25] enables attackers to send spoofed
emails, even if additional protection mechanism like DKIM
are applied, by abusing techniques to encode non-ASCII
chars inside email headers as described in RFC 1342.
In
2017, Ribeiro [26] demonstrated that CSS rules included in
HTML emails can be loaded from a remote source, leading
to changes in the appearance of—potentially signed—emails
after delivery.
Our partial ((cid:71)(cid:35)) and weak ((cid:35)) forgery attacks can poten-
tially be detected by carefully inspecting the GUI or manu-
ally clicking to receive more signature details. A user study
analyzing user behavior would be necessary to reveal the real
impact of such inconsistencies. Lausch et al. [27] reviewed
existing cryptographic indicators used in email clients and
performed a usability study. With their 164 “privacy-aware”
participants they were able to select the most important in-
dicators. They argue that further research with participants
with general skills should be performed in the future work.
It would be intersting to extend this user study with speciﬁc
1026    28th USENIX Security Symposium
USENIX Association
corner cases from our paper. Similar studies were performed
to analyze the usage of TLS indicators in web browsers.
Schechter et al. performed laboratory experiments where
they analyzed user behavior in respect to different browser
warnings [28]. For example, they found out that all 63 tested
users used their banking credentials on banking websites de-
livered over pure HTTP. Sunshine et al. [29] performed a
study on SSL warning effectiveness. Their conclusion is that
blocking unsafe connections and minimizing TLS warnings
would improve the warning effectiveness and user security.
Felt et al. studied TLS indicators in different browsers, in-
cluding Chrome, Firefox, Edge, and Safari [30]. They per-
formed a user study with 1329 participants to select the most
appropriate indicators reporting positive as well as negative
TLS status. The selected indicators have then been adopted
by Google Chrome. Other researchers concentrated on spe-
cial cases like the evaluation of Extended Validation certiﬁ-
cates [31] or TLS indicators in mobile browsers [32].
9 Future Work
User Study On most clients the evaluation results were ob-
vious. In the case of perfect or partial forgery, little to no
discussion is needed because it should be clear that a user
can not distinguish between a valid and a spoofed signature.
However, some clients displayed conﬂicting information, for
example, an erroneous seal and a success dialog. Other
clients expect a more elaborate workﬂow from the user, such
as clicking through the UI.
We currently classify a weak forgery as "not vulnerable"
because the user has at least a chance to detect it and we did
not measure if users actually detected it. A user study could
clarify whether our weak forgery ﬁndings (e.g., conﬂicting
security indicators) would convince email users, and answer
the following research questions: Do users pay attention to
email security indicators in general? Do users examine digi-
tal signature details (in particular for partial forgeries)? How
do users react once they detect broken signatures?
We believe that such a study would help to understand the
current email security ecosystem and our paper lays the foun-
dations for such a study.
S/MIME Signatures in AS2 Applicability Statement 2
(AS2) as described in RFC 4130 is an industry standard for
secure Electronic Data Interchange (EDI) over the Internet.
It relies on HTTP(S) for data transport and S/MIME to guar-
antee the authenticity and integrity of exchanged messages.
As critical sectors such as the energy industry heavily rely
on AS2 for their business processes, it would be interesting
to evaluate if our attacks (e.g., in the CMS class) can be ap-
plied to AS2. Unfortunately, we did not have the opportunity
to test commercial AS2 gateways yet.
Email Security Fuzzing As described in subsection 7.1,
our tests with different attack vectors led to unintentional
crashes in several email applications. More rigorous test-
ing and systematic fuzzing with MIME, S/MIME and PGP
structures could uncover further vulnerabilities.
10 Conclusion
We demonstrated practical email signature spooﬁng attacks
against many OpenPGP and S/MIME capable email clients
and libraries. Our results show that email signature checking
and correctly communicating the result to the user is sur-
prisingly hard and currently most clients do not withstand a
rigorous security analysis. While none of the attacks directly
target the OpenPGP or S/MIME standards, or the underlying
cryptographic primitives, they raise concerns about the prac-
tical security of email applications and show that when deal-
ing with applied cryptography, even if the cryptosystem itself
is considered secure, the overall system needs to be looked
at and carefully analyzed for vulnerabilities. Implementing
countermeasures against these vulnerabilities is very chal-
lenging and, thus, we recommend that OpenPGP, MIME,
and S/MIME offer more concrete implementation advices
and security best practices for developing secure applications
in the future.
Acknowledgements
The authors would like to thank Kai Michaelis and Benny
Kjær Nielsen for insightful discussions about GnuPG and its
secure integration into the email ecosystem, and our anony-
mous reviewers for many insightful comments.
Juraj Somorovsky was supported through the Horizon
2020 program under project number 700542 (FutureTrust).
Jens Müller was supported by the research training group
‘Human Centered System Security’ sponsored by the state
of North-Rhine Westfalia.
References
[1] J. Postel, “Simple Mail Transfer Protocol,” August
1982. RFC0821.
[2] D. Crocker, “Standard for the format of ARPA internet
text messages,” August 1982. RFC0822.
[3] H. Hu and G. Wang, “End-to-end measurements of
email spooﬁng attacks,” in 27th USENIX Security
Symposium (USENIX Security 18), (Baltimore, MD),
pp. 1095–1112, USENIX Association, 2018.
[4] J. Callas, L. Donnerhacke, H. Finney, and R. Thayer,
1998.
format,” November
“OpenPGP message
RFC2440.
USENIX Association
28th USENIX Security Symposium    1027
[5] B. Ramsdell, “S/MIME version 3 message speciﬁca-
tion,” June 1999. RFC2633.
[6] J. Callas, L. Donnerhacke, H. Finney, D. Shaw, and
R. Thayer, “OpenPGP message format,” November
2007. RFC4880.
[7] R. Housley, “Cryptographic Message Syntax (CMS),”
September 2009. RFC5652.
[8] P. Resnick, “Internet message format,” October 2008.
RFC5322.
J. Müller, F.
Ising,
[9] D. Poddebniak, C. Dresen,
J. Somorovsky, and
S. Schinzel, S. Friedberger,
J. Schwenk, “Efail: Breaking S/MIME and OpenPGP
email encryption using exﬁltration channels,” in 27th
USENIX Security Symposium (USENIX Security 18),
(Baltimore, MD), pp. 549–566, USENIX Association,
2018.
[10] B. Ramsdell and S. Turner, “Secure/Multipurpose In-
ternet Mail Extensions (S/MIME) version 3.2 message
speciﬁcation,” January 2010. RFC5751.
[11] F. Strenzke,
tacks against S/MIME,” Feb. 2016.
//cryptosource.de/posts/smime_mta_
improved_en.html.
“Improved message
takeover
at-
https:
[12] D. K. Gillmor, “Memory Hole spec and docu-
https://github.com/autocrypt/
mentation.”
memoryhole, 2014.
[13] “CVE-2013-4402.” Available from MITRE, 2013.
[14] “CVE-2006-0049.” Available from MITRE, 2006.
[15] R. Klafter and E. Swanson, “Evil 32: Check your GPG
ﬁngerprints.” https://evil32.com/, 2014.
[16] D. Bleichenbacher, “Forging some RSA signatures
with pencil and paper.” Presentation in the rump Ses-
sion CRYPTO 2006, Aug. 2006.
[17] A. Furtak, Y. Bulygin, O. Bazhaniuk, J. Loucaides,
A. Matrosov, and M. Gorobets, “BERserk: New RSA
signature forgery attack.” Presentation at Ekoparty 10,
2014.
[18] B. Ramsdell, “S/MIME version 3 certiﬁcate handling,”
June 1999. RFC2632.
[19] L. Liao, Secure Email Communication with XML-
based Technologies. Europ. Univ.-Verlag, 2009.
[20] A. Levi and C. B. Güder, “Understanding the limita-
tions of S/MIME digital signatures for e-mails: A GUI
based approach,” computers & security, vol. 28, no. 3-
4, pp. 105–120, 2009.
[21] A. Whitten and J. D. Tygar, “Why Johnny can’t en-
crypt: A usability evaluation of PGP 5.0,” in Proceed-
ings of the 8th Conference on USENIX Security Sym-
posium - Volume 8, SSYM’99, (Berkeley, CA, USA),
pp. 14–14, USENIX Association, 1999.
[22] D. Davis, “Defective sign & encrypt
in S/MIME,
PKCS#7, MOSS, PEM, PGP, and XML,” in Proceed-
ings of the General Track: 2001 USENIX Annual Tech-
nical Conference, (Berkeley, CA, USA), pp. 65–78,
USENIX Association, 2001.
[23] D. K. Gillmor,
“Inline PGP signatures consid-
ered harmful.” https://dkg.fifthhorseman.net/
notes/inline-pgp-harmful/, 2014.
[24] “CVE-2007-1263.” Available from MITRE, 2007.
[25] S. Haddouche, “Mailsploit.” https://mailsploit.
com/, 2017.
[26] F. Ribeiro, “The ROPEMAKER email exploit,” 2017.
[27] J. Lausch, O. Wiese, and V. Roth, “What is a secure
email?,” in European Workshop on Usable Security
(EuroUSEC), 2017.
[28] S. E. Schechter, R. Dhamija, A. Ozment, and I. Fischer,
“The emperor’s new security indicators,” in 2007 IEEE
Symposium on Security and Privacy (SP ’07), pp. 51–
65, May 2007.
[29] J. Sunshine, S. Egelman, H. Almuhimedi, N. Atri, and
L. F. Cranor, “Crying wolf: An empirical study of SSL
warning effectiveness,” in Proceedings of the 18th Con-
ference on USENIX Security Symposium, SSYM’09,
(Berkeley, CA, USA), pp. 399–416, USENIX Associa-
tion, 2009.
[30] A. P. Felt, R. W. Reeder, A. Ainslie, H. Harris,
M. Walker, C. Thompson, M. E. Acer, E. Morant,
and S. Consolvo, “Rethinking connection security in-
dicators,” in Twelfth Symposium on Usable Privacy
and Security (SOUPS 2016), (Denver, CO), pp. 1–14,
USENIX Association, 2016.
[31] R. Biddle, P. C. van Oorschot, A. S. Patrick, J. Sobey,
and T. Whalen, “Browser interfaces and extended val-
idation SSL certiﬁcates: An empirical study,” in Pro-
ceedings of the 2009 ACM Workshop on Cloud Com-
puting Security, CCSW ’09, (New York, NY, USA),
pp. 19–30, ACM, 2009.
[32] C. Amrutkar, P. Traynor, and P. C. van Oorschot, “Mea-
suring SSL indicators on mobile browsers: Extended
life, or end of the road?,” in Information Security
(D. Gollmann and F. C. Freiling, eds.), (Berlin, Heidel-
berg), pp. 86–103, Springer Berlin Heidelberg, 2012.
1028    28th USENIX Security Symposium
USENIX Association