ysis,” in Annual International Cryptology Conference.
Springer, 1999, pp. 388–397.
[27] A. Das, S. Gollapudi, R. Kumar, and R. Panigrahy, “On
the learnability of deep random networks,” CoRR, vol.
abs/1904.03866, 2019.
[28] D. Mahajan, R. Girshick, V. Ramanathan, K. He,
M. Paluri, Y. Li, A. Bharambe, and L. van der Maaten,
“Exploring the limits of weakly supervised pretraining,”
[29] P. Micaelli and A. Storkey, “Zero-shot knowledge trans-
fer via adversarial belief matching,” arXiv preprint
arXiv:1905.09768, 2019.
[30] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and
I. Sutskever, “Language models are unsupervised multi-
task learners,” OpenAI Blog, vol. 1, no. 8, 2019.
[31] A. Sharif Razavian, H. Azizpour, J. Sullivan, and
S. Carlsson, “Cnn features off-the-shelf: an astounding
baseline for recognition,” in Proceedings of the IEEE
conference on computer vision and pattern recognition
workshops, 2014, pp. 806–813.
[32] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova,
“Bert: Pre-training of deep bidirectional transform-
for language understanding,” arXiv preprint
ers
arXiv:1810.04805, 2018.
[33] D. Angluin, “Queries and concept learning,” Machine
learning, vol. 2, no. 4, pp. 319–342, 1988.
[34] A. Blum and T. Mitchell, “Combining labeled and un-
labeled data with co-training,” in Proceedings of the
eleventh annual conference on Computational learning
theory. Citeseer, 1998, pp. 92–100.
[35] S. Song, D. Berthelot, and A. Rostamizadeh, “Com-
bining mixmatch and active learning for better
accuracy with fewer labels,” 2020. [Online]. Available:
https://openreview.net/forum?id=HJxWl0NKPB
[36] O. Siméoni, M. Budnik, Y. Avrithis, and G. Gravier,
“Rethinking deep active learning: Using unlabeled
data at model training,” 2020. [Online]. Available:
https://openreview.net/forum?id=rJehllrtDS
[37] X. Zhai, A. Oliver, A. Kolesnikov, and L. Beyer,
“S4l: Self-supervised semi-supervised learning,” arXiv
preprint arXiv:1905.03670, 2019.
[38] D. Berthelot, N. Carlini, I. Goodfellow, N. Papernot,
A. Oliver, and C. Raffel, “Mixmatch: A holistic ap-
proach to semi-supervised learning,” arXiv preprint
arXiv:1905.02249, 2019.
[39] Y. Netzer, T. Wang, A. Coates, A. Bissacco, B. Wu, and
A. Y. Ng, “Reading digits in natural images with unsu-
pervised feature learning,” 2011.
[40] A. Krizhevsky et al., “Learning multiple layers of fea-
tures from tiny images,” Citeseer, Tech. Rep., 2009.
[41] D. Sculley, G. Holt, D. Golovin, E. Davydov, T. Phillips,
D. Ebner, V. Chaudhary, M. Young, J.-F. Crespo, and
USENIX Association
29th USENIX Security Symposium    1359
D. Dennison, “Hidden technical debt in machine learn-
ing systems,” in Advances in neural information pro-
cessing systems, 2015, pp. 2503–2511.
[42] B. Lakshminarayanan, A. Pritzel, and C. Blundell, “Sim-
ple and scalable predictive uncertainty estimation using
deep ensembles,” in Advances in Neural Information
Processing Systems, 2017, pp. 6402–6413.
[43] H. Xiao, K. Rasul, and R. Vollgraf. (2017) Fashion-
mnist: a novel image dataset for benchmarking machine
learning algorithms.
[44] N. Carlini, U. Erlingsson, and N. Papernot, “Prototypical
examples in deep learning: Metrics, characteristics, and
utility,” 2019. [Online]. Available: https://openreview.
net/forum?id=r1xyx3R9tQ
[45] Y. LeCun, L. Bottou, Y. Bengio, P. Haffner et al.,
“Gradient-based learning applied to document recog-
nition,” Proceedings of the IEEE, vol. 86, no. 11, pp.
2278–2324, 1998.
[46] Google, “Jax,” https://github.com/google/jax, 2019.
[47] C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Er-
han, I. Goodfellow, and R. Fergus, “Intriguing properties
of neural networks,” arXiv preprint arXiv:1312.6199,
2013.
[48] A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and
A. Vladu, “Towards deep learning models resistant to
adversarial attacks,” arXiv preprint arXiv:1706.06083,
2017.
[49] T. Lee, B. Edwards, I. Molloy, and D. Su, “Defending
against model stealing attacks using deceptive perturba-
tions,” arXiv preprint arXiv:1806.00054, 2018.
[50] I. M. Alabdulmohsin, X. Gao, and X. Zhang, “Adding
robustness to support vector machines against adver-
sarial reverse engineering,” in Proceedings of the 23rd
ACM International Conference on Conference on Infor-
mation and Knowledge Management. ACM, 2014, pp.
231–240.
[51] M. Juuti, S. Szyller, A. Dmitrenko, S. Marchal, and
N. Asokan, “Prada: protecting against dnn model steal-
ing attacks,” arXiv preprint arXiv:1805.02628, 2018.
[52] M. Kesarwani, B. Mukhoty, V. Arya, and S. Mehta,
“Model extraction warning in mlaas paradigm,” in Pro-
ceedings of the 34th Annual Computer Security Appli-
cations Conference. ACM, 2018, pp. 371–380.
[53] B. Wang and N. Z. Gong, “Stealing hyperparameters in
machine learning,” in 2018 IEEE Symposium on Secu-
rity and Privacy (SP).
IEEE, 2018, pp. 36–52.
[54] J. Zhang, Z. Gu, J. Jang, H. Wu, M. P. Stoecklin,
H. Huang, and I. Molloy, “Protecting intellectual prop-
erty of deep neural networks with watermarking,” in
Proceedings of the 2018 on Asia Conference on Com-
puter and Communications Security. ACM, 2018, pp.
159–172.
[55] Y. Uchida, Y. Nagai, S. Sakazawa, and S. Satoh, “Em-
bedding watermarks into deep neural networks,” in Pro-
ceedings of the 2017 ACM on International Conference
on Multimedia Retrieval. ACM, 2017, pp. 269–277.
[56] B. Barak, O. Goldreich, R. Impagliazzo, S. Rudich,
A. Sahai, S. Vadhan, and K. Yang, “On the (im) possi-
bility of obfuscating programs,” in Annual international
cryptology conference. Springer, 2001, pp. 1–18.
[57] M. Barni, C. Orlandi, and A. Piva, “A privacy-preserving
protocol for neural-network-based computation,” in Pro-
ceedings of the 8th workshop on Multimedia and secu-
rity. ACM, 2006, pp. 146–151.
[58] G. Katz, C. Barrett, D. L. Dill, K. Julian, and M. J.
Kochenderfer, “Reluplex: An efﬁcient smt solver for
verifying deep neural networks,” in International Con-
ference on Computer Aided Veriﬁcation.
Springer,
2017, pp. 97–117.
A Formal Statements for Section 3.3
Here, we give the formal arguments for the difﬁculty of model
extraction to support informal statements from Section 3.3.
Theorem 1. There exists a class of width 3k and depth 2
neural networks on domain [0,1]d (with precision p numbers)
with d ≥ k that require, given logit access to the networks,
Θ(pk) queries to extract.
In order to prove Theorem 1, we introduce a family of
functions we call k-rectangle bounded functions, which we
will show satisﬁes this property.
Deﬁnition A.1. A function f on domain [0,1]d with range R
is a rectangle bounded function if there exists two vectors a,b
such that f (x) (cid:54)= 0 =⇒ a (cid:22) x (cid:22) b, where (cid:22) denotes element-
wise comparison. The function f is a k-rectangle bounded
function if there are k indices i such that ai (cid:54)= 0 or bi (cid:54)= 1.
Intuitively, a k-rectangle function only outputs a non-zero
value on a multidimensional rectangle that is constrained
in only k coordinates. We begin by showing that we can
implement k-rectangle functions for any a,b using a ReLU
network of width k and depth 2.
Lemma 1. For any a,b with k indices i such that ai (cid:54)= 0 or
bi (cid:54)= 1, we can construct a k-rectangle bounded function for
a,b with a ReLU network of width 3k and depth 2.
1360    29th USENIX Security Symposium
USENIX Association
Proof. We will start by constructing a 3-ReLU gadget with
output ≥ 1 only when ai ≤ xi ≤ bi. We will then show how
to compose k of these gadgets, one for each index of the
k-rectangle, to construct the k-rectangle bounded function.
The 3-ReLU gadget only depends on xi, so weights for
all other ReLUs will be set to 0. Observe that the func-
tion Ti(x;a,b) = ReLU(x−a)+ReLU(xi−bi)−2ReLU(xi−
(ai + bi)/2) is nonzero only on the interval (ai,bi). This is
easier to see when it is written as
ReLU(xi − ai)− ReLU(xi − (ai + bi)/2)
− (ReLU(xi − (ai + bi)/2)− ReLU(xi − bi)).
The function ReLU(x − x1) − ReLU(x − x2) with x1  k−1. This is simply because each
term Ti(x;ai,bi) ≤ 1, so unless all k such terms are > 0, the
inequality cannot hold.
Now that we know how to construct a k-rectangle bounded
function, we will introduce a set of pk disjoint k-rectangle
bounded functions, and then show that any one requires pk
queries to extract when the others are also possible functions.
Lemma 2. There exists a family of k-rectangle bounded func-
tions F such that extracting an element of F requires pk
queries in the worst case.
Here, p is the feature precision; images with 8-bit pixels
have p = 256.
p , i
Proof. We begin by constructing F . The following p ranges
are clearly pairwise disjoint: {( i−1
i=1. Then pick any k
indices, and we can construct pk distinct k-rectangle bounded
functions - one for each element in the Cartesian product of
each index’s set of ranges. Call this set F .
p )}p
The set of inputs with non-zero output is distinct for each
function, because their rectangles are distinct. Now consider
the information gained from any query. If the query returns
a non-zero value, the function is learned. If not, at most one
function from F is ruled out - the function whose rectangle
was queried. Then any sequence of n queries to an oracle
can rule out at most n of the functions of F , so that at least
|F | = pk queries are required in the worst case.
Figure 5: Fidelity is easier on more prototypical examples.
Putting Lemma 1 and 2 together gives us Theorem 1.
receive
Suppose we
Theorem 2. Checking whether two networks with domains
{0,1}d are functionally equivalent is NP-hard.
Proof. We prove this by reduction to subset sum. A similar
reduction (reducing to 3-SAT instead of Subset Sum) for a
different statement appears in [58].
sum instance
T, p, [v1,v2,··· ,vd] - the set is v, the target sum is T ,
and the problem’s precision is p. We will construct networks
f1 and f2 such that checking if f1 and f2 are functionally
equivalent is equivalent to solving the subset sum instance.
We start by setting f1 = 0 - it never returns a non-zero value.
We now construct a network f2 that has nonzero output only
if the subset sum instance can be solved (and ﬁnding an input
with nonzero output reveals the satisfying subset).
subset
a
The network f2 has three hidden units in the ﬁrst layer with
incoming weight for the ith feature equal to vi. This means
the dot product of the input x with weights will be the sum of
the subset {i|xi = 1}. We want to force this to accept iff there
is an input where this sum is T . To do so, we use the same
3-ReLU gadget as in the proof of Theorem 1:
f2(x;T, p,v) = ReLU(x· v− (T − p/2))
+ ReLU(x· v− (T + p/2))− 2ReLU(x· v− T ).
As before, this will only be nonzero in the range [T − p/2,T +
p/2], and we are done.
B Prototypicality and Fidelity
We know from Section 5 that learning strategies struggle to
achieve perfect ﬁdelity due to non-determinism inherent in
learning. What remains to be understood is whether some
USENIX Association
29th USENIX Security Symposium    1361
samples are more difﬁcult than others to achieve ﬁdelity on.
We investigate using recent work on identifying prototypical
data points. Using each metric developed in Carlini et al. [44],
we can rank the Fashion-MNIST test set in order of increas-
ing prototypicality. Binning the prototypicality ranking into
percentiles, we can measure how many of the 90 models we
trained for Section 5 agree with the oracle’s prediction. The
intuition here is that more prototypical examples should be
more consistently learnable, whereas more outlying points
may be harder to consistently classify. Indeed, we ﬁnd that
this is the case - all metrics ﬁnd a correlation between proto-
typicality and model agreement (ﬁdelity), as seen in Figure 5.
Interestingly, the metrics which do not use ensembles of mod-
els (adversarial distance and holdout-retraining) have the best
correlation with the model agreement metric—roughly the top
50% of prototypical examples by these metrics are classiﬁed
the same by nearly all 90 models.
C Supplement for Section 6
Accuracies for the oracles in Section 6 are found in Table 9.
MNIST
CIFAR-10
Parameters Accuracy
49,000
94.3%
98,000
95.6%
196,000
97.2%
393,000
97.7%
98.0%
786,000
98.3% 1,572,000
Parameters Accuracy
29.2%
34.2%
40.3%
42.6%
43.1%
45.9%
12,500
25,000
50,000
100,000
200,000
400,000
Table 9: Statistics for the oracle models we train to extract.
Figure 6 shows a distribution over the bits of precision in
the difference between the logits (i.e., pre-softmax prediction)
of the 16 neuron oracle neural network and the extracted
network. Formally, we measure the magnitude of the gap
| fθ(x)− f ˆθ(x)|. Notice that this is a different (and typically
stronger) measure of ﬁdelity than used elsewhere in the paper.
D Query Complexity of Functionally Equiva-
lent Extraction
In this section, we brieﬂy analyze the query complexity of
the attack from Section 6. We assume that a simulated partial
derivative requires O(1) queries using ﬁnite differences.
1. Critical Point Search. This step is the most nontrivial to
analyze, but fortunately this was addressed in [19]. They
found this step requires O(hlog(h)) gradient queries,
which we simulate with O(hlog(h)) model queries.
2. Weight Recovery. This piece is signiﬁcantly compli-
cated by not having access to gradient queries. For each
Figure 6: For a 16-neuron MNIST model the attack works.
Plotted here is number of bits of precision on the logits nor-
malized by the value of the lot as done in the prior ﬁgure.
ReLU, absolute value recovery requires O(d) queries
and weight sign recovery requires an additional O(d),
making this step take O(dh) queries total.
3. Global Sign Recovery. For each ReLU, we require only
three queries. Then this step is O(h).
4. Last Layer Extraction. This step requires h queries to
make the system of linear equations full rank (although
in practice we reuse previous queries here, making this
step require 0 queries).
Overall, the algorithm requires O(hlog(h) + dh + h) =
O(dh) queries. Extraction requires Ω(dh) queries without
auxillary information, as there are dh parameters in the model.
Then the algorithm is query-optimal up to a constant factor,
removing logarithmic factors from Milli et al. [19].
1362    29th USENIX Security Symposium
USENIX Association
51015Bits of precision in logits0100200300400500Frequency