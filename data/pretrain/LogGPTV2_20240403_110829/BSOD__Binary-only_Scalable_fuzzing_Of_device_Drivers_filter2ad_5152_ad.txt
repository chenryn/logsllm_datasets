device, the memory addresses, order of MMIO operations, interrupt
timings, and context switches change.
Non-Determinism Hinders Fuzzer Development. As valuable im-
provement during development, we eliminate non-determinism
by recording the execution of the operating system for repeatable
analysis on top of PANDA, a QEMU-fork [10]. We can use the
QEMU’s VFIO device to pass through real hardware devices to
PANDA. When starting a recording, PANDA relies on the snap-
shot capabilities of QEMU, which require devices to be migratable,
but migration is not possible with the VFIO device. We defined
the device to be migratable so that it is added to the snapshot and
stubbed out the device initialization routines that are called when
a snapshot is loaded. With these changes in place, the record and
replay capabilities of PANDA with the VFIO device are working
as expected for MMIO operations and interrupts, except for DMA
transfers. Virtual devices typically use a specific function to map
memory for DMA transfers, and PANDA adds these addresses to
the watchlist. This method does not work for real hardware devices,
which means the DMA pages need to be collected differently.
BSOD Panda Plugins. To cover the recording of the missing DMA
operations without customizing PANDA itself, we implemented a
PANDA plugin. During recording, the plugin tracks the allocated
DMA pages by using PANDA’s memory callbacks [10]. The plugin
directly hooks the functions responsible for allocating the DMA
buffers inside the kernel driver module to retrieve the page ad-
dresses. Furthermore, an event is registered that triggers before
any memory read access occurs by using the PANDA_CB_PHYS_MEM_
BEFORE_READ callback. Whenever a read access relates to a moni-
tored DMA page, the plugin checks whether the content changed by
comparing the checksum of the current bytes with the previously
stored checksum. If the content is changed, the page is dumped
and stored together with the current instruction counter. During
replay, the plugin also uses the previously used callback to write
changed pages due to DMA just-in-time before the driver accesses
the data according to the stored instruction counter. This eliminates
nondeterminism and improves debugging by having GDB attached
54RAID ’21, October 6–8, 2021, San Sebastian, Spain
Toepfer and Maier
Figure 5: Memory replay
during replay. Furthermore, it enables the use of expensive analysis
plugins that no longer influence the execution.
Next, we created a plugin that intercepts ioctl system calls di-
rected to the driver. It is realized by hooking the related ioctl handler
function in the driver to dump the request parameters and passed
data structures of any performed ioctl system call during the replay
into files. It also supports taint analysis [9, 38] by labeling the input
bytes to the ioctl system call invocation to track the propagation of
the data. We can determine the influenced program locations by
using the tainted branch and tainted instruction plugins.
4.2 BSOD-fakedev
To remove the hardware device dependency for the fuzzing process,
we implement a virtual replay device, BSOD-fakedev, that can be
plugged into any QEMU instance. We determine the properties by
reading out the PCI configuration space of the device. The lspci
utility allows showing the information in a human-friendly readable
format. First, we determine the values for the vendor ID, device ID,
and class ID, and specify them in the class properties of our device
implementation. Then, we must determine the layout of the Base
Address Registers (BARs) with its sizes and access properties. In
our QEMU device implementation, we define appropriately sized
memory areas and IO operations for each BAR. Afterward, we
define an IO memory region for each BAR with the respective size
and IO operations by using QEMU’s defined memory_region_init_
io function. Furthermore, we define the BAR for our device with
the respective access types and bind it to the respective memory
region by using QEMU’s pci_register_bar function.
At this point, we have created our virtual device according to the
device properties without implementing any functionality. For the
handling of memory events, we need to implement the handlers of
the IO operations for read and write accesses. To approximate the
device’s functionality, we implement a memory replay logic that
works on previously captured trace data. We define the memory
access length to 4 bytes and classify each addressable memory
location to be either of type read-only, read-writable, or sequential.
To demonstrate the concept, Figure 5 shows an exemplary ex-
cerpt of device memory. For read-only memory locations, our imple-
mentation discards any writing attempt so that they will always re-
main the initial value. Read-writeable memory locations are treated
as typical memory and served from the allocated memory areas
of the virtual device. For memory locations of type sequential, we
implemented a special treatment that serves read accesses with
sequential data. Here, successive read events return the values ac-
cording to the previously captured trace data, and write attempts
are discarded. Interrupts are bound to the previously occurred read
or write event and triggered after the event occurred.
We link our implementation to the handler functions of the
IO operations for the memory regions. The handler functions are
extendable to implement more device-specific custom logic, which
is useful when the replay concept does not work for single memory
addresses.
For the data collection, we use our presented experimental setup
shown in Figure 3 in section 3. We use the VFIO device, located
between the physical device and the guest, as a proxy to intercept
Memory-Mapped I/O (MMIO) events and interrupts by leveraging
its tracing capabilities. We set the VFIO option x-no-mmap=true,
which disables the direct mapping of the device memory regions
into the guest to enable the trace events vfio_region_read and
vfio_region_write that trigger on each memory access into the
BARs. Furthermore, we enable the option x-no-kvm-intx=true
to collect interrupts in KVM mode. Then, we boot our virtual ma-
chine and trigger device actions, such as executing an exemplary
application that interacts with the device.
Afterward, we analyze the trace data in the following way:
(1) Preprocess trace data
In the first step, we parse the QEMU trace log and extract
the data of the occurred memory and interrupt events.
(2) Split memory regions
In the next step, we split the preprocessed events into the
respective memory regions.
(3) Extract initial RAM image
Then, we extract an initial RAM image for every memory
region. For each memory address, the value of the first read
event indicates the initial value.
(4) Identify register types
In the following, we assign the appropriate class for each
memory address of the memory region.
Read-Only: We consider a memory address read-only when
the read value never changes throughout the trace for that
region, regardless of whether there were write accesses with
different values to the address.
Read-Writable: We consider a memory address read-writable
when the read value always represents the last written value.
Sequencial: We consider a memory address sequential when
we observe two successive read events that return different
values or when we notice a read value that does not reflect
the last written value to that address.
We consider memory addresses that don’t appear in the trace
data as read-writeable.
After we have specified the device properties and prepared the
trace data, we can add the virtual device model via the QEMU
command line as a replacement for the VFIO device. The device
model will prototypically act as the physical device while it serves
memory read and write operations and interrupts according to the
traced data. Read-only memory locations can hold fixed data, such
as device properties or binary data like the BIOS. More interestingly,
they could implement some functionality that is triggered when
they are written with a specific value but effectively, from a memory
perspective, not store the value. Read-writeable memory locations
are independent of the captured trace data and could diverge across
executions when they are not related to the sequential registers.
0x100x100x100x410x41...0x640x100x100x100x200x200x10......r/or/wseqR  0x10W 0x20R 0x10R 0x10W 0x20R 0x20R 0x10W 0x20R 0x4155BSOD: Binary-only Scalable fuzzing Of device Drivers
RAID ’21, October 6–8, 2021, San Sebastian, Spain
Memory locations identified as sequential could implement coun-
ters or timers, provide status information, or deliver data streams
similar to pipes.
A simple device model and replay will never accurately emulate
the full functionality of a complex device like the graphics card.
Different branches in the driver may lead to non-recorded behavior.
Nevertheless, it is sufficient to drive deterministic parts properly,
such as driver initialization and other functionalities, as long as
the read access event order remains the same for the sequential
addresses. Therefore, we must verify our findings whether they
also occur with the physical hardware device.
5 EVALUATION
During this chapter, we evaluate our presented fuzzing approaches
by creating different experiments. The results of the experiments
respond to the following questions:
(1) Performance
What are the fuzzing throughput and reached coverage achieved
of both approaches?
(2) Scaling
(3) Findings
How well do the approaches scale to make efficient use of
available system resources?
Can real-world bugs be found with the approaches?
(4) Emulated device model
Does the achieved coverage differ when using the device
model compared to the physical hardware device?
We performed the evaluation on a host system with an Intel Core
i5-4570 and 8 GB RAM across the experiments. The QEMU guests
are started with the options -cpuhost,kvm=off,migratable=off
and -snapshot. The host option specifies to copy the host’s CPU
configuration, which is best practice and results in the highest
performance [5].
Harnessing NVIDIA drivers for BSOD. The NVIDIA driver per-
forms simple hypervisor detection and refuses to initialize for de-
vices that are not certified to run virtualized. It is actually no tech-
nical restriction since the more expensive device counterparts are
using the same chipsets. We hide the KVM hypervisor by using the
kvm=off option to bypass the virtualization detection of the driver.
By default, QEMU ensures the migratability of guest VMs, whereby
incompatible CPU features are turned off and lower the possible
performance. It enables creating snapshots of the VMs that could be
loaded for quick initialization and state restore when crashes occur.
However, we decided to set the migratable=off flag to disable
this feature in favor of higher throughput and take the costs of re-
initialization by rebooting the guests. Furthermore, when fuzzing
with real hardware via the VFIO device, migration is not supported
anyway, which would prevent comparability during the evaluation.
The -snapshot option allows using the file system in a copy-on-
write manner, which effectively discards any performed changes
during the execution after stopping the guest. Another advantage
of this option is the ability to boot multiple Virtual Machine (VM)
instances using the same file system image [5].
For interface recovery, we utilized available information from
the envytools [20] repository together with tracing and analyzing
exemplary applications.
Figure 6: Syzkaller fuzzing executions for KCOV/bp-
edge/bp-block coverage modes.
Figure 7: Syzkaller fuzzing throughput for KCOV/bp-
edge/bp-block coverage modes.
Based on the information, we created a test-harness for AFL and
use the collected ioctl data structures extracted from an exemplary
execution replay as meaningful initial test cases.
For Syzkaller, we have to provide the target’s system call in-
terface descriptions by transforming the previously implemented
structures for the harness into equivalent Syzkaller descriptions.
For both setups, we start the fuzzing guests with either the
physical hardware device using PCI pass-through via VFIO, or with
the derived device model, to bring the driver into a working state.
Table 1 shows our test matrix of targets per fuzzing setup and
operating system. For Linux, the fuzzing has been performed inside
guests, running an at the time of writing up-to-date installation of
Arch Linux together with a custom kernel where we enabled Kernel
Address Sanitizer (KASAN) to identify memory corruption bugs
in kernel space. We installed the target NVIDIA kernel modules
via the nvidia-dkms package, which builds the most recent driver
version 460.56 against the running kernel. We configured the guest
to print kernel logs to serial output and enabled Secure Shell (SSH)
for interaction.
For preparing the target driver at system boot, we built a startup
routine that creates the device files by using the mknod utility. Since
the device initialization takes a significant amount of time when
an application opens the GPU’s device descriptor the first time, we
open it in the startup routine and keep it open. New file descriptors
can now instantly be created and used in conjunction with other
system calls, which increases the throughput.
5.1 Performance
BSOD-Syzkaller. To determine the overhead of our used coverage
method, we compare the throughput of Syzkaller when using KCOV
and breakpoint coverage. Since KCOV only supports open-source
targets, we chose to target the closely related nouveau driver for
this experiment together with the physical hardware device. We
further compare the breakpoint coverage throughput when using
edge and block modes.
02000040000600008000010000012000014000000:0000:1500:3000:4501:0001:1501:3001:4502:00execstimekcovbp-blockbp-edge010002000300040005000600000:0000:1500:3000:4501:0001:1501:3001:4502:00throughput in execs/mintimekcovbp-blockbp-edge56RAID ’21, October 6–8, 2021, San Sebastian, Spain
Toepfer and Maier
Setup / OS
BSOD-AFL
BSOD-Syzkaller
Windows
nvlddmkm.sys
-
Linux
nvidia
nvidia, nvidia-modeset, nvidia-drm, nvidia-uvm, nouveau
FreeBSD
nvidia
nvidia, nvidia-modeset
Table 1: Test matrix
total progs
mean progs/min