Reducing PMTU: ineffective for DNS forwarder attacks.
We ﬁrst consider borrowing from PMTU-based defragmen-
tation attacks, where an attacker lowers PMTU to force re-
sponse fragmentation. According to our attack model, the
DNS response needs to be fragmented between the recursive
resolver and the DNS forwarder (see Figure 4, step 3b), thus
an attacker should attempt to lower the MTU of the upstream
recursive resolver. Using the same approach as in [33] (i.e.,
sending ICMP fragmentation needed error messages), we
perform a measurement on 2M open DNS resolvers in the
wild. In the end, as also shown in Figure 2, the results turn
out to be unsatisfying: only 0.3% resolvers can reduce their
packet size to below 512 bytes, and less than 37% reduce to
below 600 bytes.
DNSSEC-based fragmentation:
even less effective
against DNS forwarders. We already know that leveraging
DNSSEC is very limited as it only works for a limited range
of domains and servers. In addition, DNS forwarders in this
case also need to support DNSSEC. Otherwise, the upstream
recursive resolver will not even send DNSSEC responses.
Solution: oversized DNS response using CNAME. As
mentioned earlier, an attacker-controlled authoritative name
server can intentionally create an oversized DNS response
larger than the Ethernet MTU (i.e., larger than 1,500 bytes),
such that it will always be fragmented at the recursive re-
solver.
As shown in Figure 5, the method to create such large
responses is through a chain of CNAME records, followed
by one ﬁnal A record. When handling this query, recur-
sive resolvers will query the aliases in the chain (see Fig-
ure 4, step 2d) and aggregate the CNAME records into the
ﬁnal response. The attacker ﬁlls the chain with enough
580    29th USENIX Security Symposium
USENIX Association
IPID prediction.
IP identiﬁcation (IPID) is a 16-bit ﬁeld
in the IP header, which is used to determine which data-
gram a fragment belongs to. For successful defragmentation,
the IPIDs of the spoofed 2nd fragment and the legitimate
1st fragment (from the upstream resolver) should agree. As
such, an attacker should be able to predict the IPID assign-
ment of the upstream resolver (see Figure 4, step 1). In gen-
eral, this is a well studied topic in the literature and a number
of techniques have been proposed [28, 49]. We give a sum-
mary below on how we can take advantage of predictable
IPID assignment and then conduct a measurement to show
how most DNS resolvers in the wild can be exploited.
IPID assignment algorithms. There are three major IPID
assignment algorithms: global IPID counter, hash-based
IPID counter [44], and random IPID assignment. Global
IPID counter increases by one for every sent packet, which is
highly predictable [55]. Hash-based IPID counter algorithms
ﬁrst use a hash function to map an outgoing packet to one
in an array of IPID counters, and then increase the selected
counter by a random amount, chosen from a uniform distri-
bution between 1 and the number of system ticks (typically
milliseconds) since the last packet transmission that used the
same counter [28]. If the two probes are sent close enough in
time, then the IPID increments from the responses are very
predictable. In fact, since the defragmentation cache can typ-
ically buffer 64 fragments [56], an attacker can make a pre-
diction on a range of IPID values instead of a single one. The
hash function determines which IPID counter is used, based
on the source and destination IP address of the sent packet
(the same source and destination IP pair will therefore al-
ways result in the same IPID counter getting selected). In
our attack, an attacker can ﬁrst probe for the current IPID
value of the upstream resolver, and use one or more pre-
dicted IPIDs to place the spoofed 2nd fragment. The probing
response (see Figure 4, step 0b) and the 1st fragment (see
Figure 4, step 3b) are both sent to the “NAT-ed” public ad-
dress of the LAN, so they are guaranteed to use the same
IPID counter on the upstream resolver. As the attacker ini-
tiates the entire sequence of packets and controls the timing
of these packets, it can make sure that the gap between the
initial IPID and the later one (in the resolver’s response) is
small enough and hence predictable (because they are gener-
ated close in time, e.g., a few milliseconds apart).
Operating systems. As reported by previous studies [28,
33, 55, 71], early versions of Windows (prior to Windows 8)
use global IPID counters, and recent Windows and Linux
versions use hash-based IPID counters. By setting up vir-
tual machines and probe their IPID assignments, we conﬁrm
that the latest versions of Windows 10 (Professional, Ver-
sion 1909 (18363.657)) and Ubuntu (5.3.0-29-generic) both
use hash-based IPID counters. Since most servers (including
recursive resolvers) on the Internet are equipped with Win-
dows or Linux, we believe this technique covers most of the
ground.
Figure 5: Oversized DNS response using CNAME
dummy CNAME records to make the ﬁnal response larger
than the Ethernet MTU, such that it will always be frag-
mented at the recursive resolver. In the spoofed 2nd frag-
ment (sent to the DNS forwarder), the attacker “tampers”
with the last CNAME record by pointing it to a victim do-
main (victim.com), and the last A record by pointing it to
a rogue address (a.t.k.r). After the response is defrag-
mented at the forwarder, the rogue A record will be cached.
The key here is that the recursive resolver sees only a legit-
imate oversized response from the authoritative name server
(Figure 5(a)), without violating bailiwick rules. Therefore,
it will attempt to relay this response as a whole back to
the forwarder, with fragmentation. However, what the for-
warder sees on its end is actually a tampered response (Fig-
ure 5(b)), due to the spoofed 2nd fragmented injected ahead
of time. Had the resolver seen such a response (where the
attacker.com eventually points to victim.com), it will reject
the response during recursive queries of the aliases. This is
exactly the reason our attack targets DNS forwarders as they
are not in the position to perform validations.
The use of oversized DNS responses requires that all
DNS servers in our attack model support Extension Mech-
anisms for DNS (EDNS(0)) [37]. As an important DNS
feature, EDNS(0) provides support to transfer DNS packets
larger than 512 bytes over UDP, and is being increasingly
supported by software vendors and DNS operators. Cur-
rently it has been implemented by mainstream DNS software
(e.g., BIND [25], Knot DNS [13], Unbound [27] and Pow-
erDNS [18]) and supported by most recursive resolvers [61].
To indicate EDNS(0) support, servers use one OPT record in
the additional section of a DNS packet to carry EDNS op-
tions.
4.3 Crafting Spoofed Fragments
For fragmented DNS responses, only the 1st fragment con-
tains DNS and UDP headers (see Appendix A for more back-
ground of IP fragmentation). As a result, to craft a spoofed
2nd fragment, an attacker does not need to predict ephemeral
port numbers and DNS transaction IDs. However, for suc-
cessful defragmentation, an attacker needs to craft the fol-
lowing IP header ﬁelds of the spoofed 2nd fragment.
USENIX Association
29th USENIX Security Symposium    581
Table 1: IPID assignment of egress resolvers
IPID
# Tested
Resolvers
Assignment
Name
Address
Hash-based
IPID counters
(Exploitable)
Random
Cloudﬂare
Quad9
Comodo
OpenDNS
Norton
Google
Verisign
1.1.1.1
9.9.9.9
8.26.56.26
208.67.222.222
199.85.126.10
8.8.8.8
64.6.64.6
64
8
2
14
2
15
24
Open DNS resolvers. We leverage the open DNS resolver
scanning result of Censys [38] on Jan 8, 2020. For each re-
solver in the list, we send three DNS queries in a row of our
own domain name, and check whether the IPIDs in the cor-
responding DNS response packets are increased by a ﬁxed
value. As a result, 4,988,186 resolvers respond to all three
queries, and 4,235,342 (84.9%) use incremental IPID coun-
ters which can be exploited in the attack.
Popular public DNS services. Public DNS services often
use anycast for load balancing. For example, DNS queries
to Google’s 8.8.8.8 can exit from hundreds of “egress” re-
solvers (e.g., 74.125.19.*). From a client’s perspective, be-
cause DNS responses come from different egress resolvers,
the public DNS services appear to use random IPID assign-
ment. However, in our defragmentation attack, because the
authoritative server is under an adversary’s control, an at-
tacker can break the load balancing by responding to only
one selected egress resolver address. If the selected egress
resolver uses incremental IPID counters, the attack is still
possible.
To begin our measurement, we build a custom au-
thoritative server
for our own domain name (termed
as echo.dnsaddr). On receiving a DNS query (e.g.,
[nonce].echo.dnsaddr), the authoritative server records
the source IP address of the DNS query (i.e., egress re-
solver address), and echoes the resolver address through an
A record in the DNS response2. Using this technique, we can
separate DNS responses sent from different egress resolvers,
and observe their IPID assignment respectively.
We choose 7 popular public DNS services for our tests:
Cloudﬂare [2], Google [10], Quad9 [19], OpenDNS [1],
Verisign [22], Comodo [3] and Norton [16]. Our vantage
points send DNS queries of [nonce].our.domain (to avoid
caching) to each public DNS service and capture the DNS
response packets.
As shown in Table 1, we ﬁnd that ﬁve public DNS ser-
vices use hash-based IPID counters on their egress resolvers,
which can be exploited in the attack. Google and Verisign
2Our authoritative server is similar to Akamai’s whoami.akamai.net
tool [12]. The difference is that our server replies to *.echo.dnsaddr,
while Akamai’s tool does not support queries of arbitrary subdomain.
use unpredictable IPIDs, which are not exploitable. Due to
space limit, we put more detailed results in Appendix B. To
conﬁrm that the public DNS services are exploitable, in Sec-
tion 5 we also launch real attacks using a public DNS service
as upstream resolver.
Other header ﬁelds. For successful defragmentation of
the 1st fragment and the spoofed 2nd fragment, the attacker
should also craft the following header ﬁelds in the spoofed
2nd fragment.
Fragment offset. The fragment offset in the spoofed 2nd
fragment should indicate its correct position in the original
datagram. Since contents of the oversized DNS response are
fully controlled by the attacker (see Figure 5), the offset of
the 2nd fragment can be calculated.
IP source address. The spoofed 2nd fragment should
come from a spoofed address of the upstream recursive re-
solver. To learn the address of the upstream recursive re-
solver, an attacker can leverage the echo.dnsaddr method
in our public DNS service measurement (i.e., send a query of
echo.dnsaddr to the DNS forwarder, and check the resolver
address encoded in the DNS response). An attacker may also
setup an authoritative server of a controlled domain, query
the DNS forwarder for the domain name, and observe the up-
stream recursive resolver address at the authoritative server.
In networks of residential devices (i.e., LAN), IP spooﬁng is
generally allowed.
Fitting the UDP checksum. The UDP checksum (in the le-
gitimate 1st fragment) is calculated from the IP header, UDP
header and the entire UDP payload. Tampering with records
in the spoofed 2nd fragment produces a checksum mismatch,
so an attacker should also adjust other bytes in the spoofed
2nd fragment to ﬁt the original checksum. In fact this task
is easy, as in our model the contents of the DNS response
are fully controlled by the attacker, thus the original check-
sum of the DNS response is already sknown. As a result, the
attacker can adjust other bytes in the spoofed 2nd fragment
with simple calculation (as in [33]) to ﬁt the UDP checksum.
4.4 Conditions of Successful Attacks
Driven from our threat model, a DNS forwarder should sat-
isfy the following conditions to be successfully attacked.
EDNS(0) support. EDNS(0) allows large DNS packets over
UDP. As an important DNS feature, we expect that it is being
increasingly supported by software vendors and DNS opera-
tors.
No truncation of DNS response. Despite supporting
EDNS(0), several of our tested forwarder implementations
actively truncate large DNS responses, even when they do
not reach the Ethernet MTU (e.g., truncate all responses at
512 or 1,280 bytes, see Table 2 in Section 5). In such case,
the truncated DNS responses are not fragmented, thus the
defragmentation attack will fail.
582    29th USENIX Security Symposium
USENIX Association
No veriﬁcation of DNS response. The aggregated over-
sized DNS response consists of a CNAME chain, and the
attacker tampers with the last two records. To detect the
rogue records, a possible solution is for the DNS forwarder
to “re-query” the domains and aliases (i.e., *.attacker.com
and victim.com) in the aggregated response (i.e., perform
recursive queries). Alternatively, if the victim domain is
DNSSEC-signed, it can also perform full DNSSEC valida-
tion. However, this defeats the purpose of a forwarder as it
is signiﬁcantly increasing the amount of workload.
DNS caching by record. From the smallest unit of each
DNS cache entry, we ﬁnd DNS forwarders cache the answers
either by response as a whole (i.e., the entire response forms
one cache entry) or by record (i.e., each resource record
forms individual cache entries). For example, when the de-
fragmented DNS response in Figure 5(b) is cached by re-
sponse, it only forms one cache entry for a.attacker.com.
As a result, querying victim.com does not hit the cache, so
the spoofed record will not be returned. In contrast, when
it is cached by record, querying any name in the response
(e.g., y.attacker.com and victim.com) will hit the cache.
Because the victim domain is located only in the last record
of the response, the attack requires that the DNS forwarder
cache by record. Caching by record has a performance ad-
vantage as more records will be cached in a single response.
5 Vulnerable DNS Forwarder Software
In this section, we ﬁrst measure the DNS forwarding behav-
iors of home routers and DNS software, to check whether
they ﬁt our defragmentation attack conditions. We then per-
form actual defragmentation attacks to conﬁrm their vulner-
abilities.
5.1 Home Routers
A number of DNS forwarders have been recognized to run
on residential network devices. In a typical setting, the de-
vices receive DNS requests from clients, and forward them to
upstream recursive resolvers. As a very representative case,
we start from testing the prevalent home routers, which com-
monly support DNS forwarding.
We perform our tests on real home router models that we
purchase from their ofﬁcial online stores. According to a re-
port on the home router market [60], we select models from
leading vendors including TP-Link [21], D-Link [5], NET-
GEAR [15], Huawei [11] and Linksys [4], as well as other
prominent players like Tenda [20], ASUS [23], Gee [9] and
Xiaomi [14]. In total, we perform tests on 16 router models
from different vendors. For each router, we test if it ﬁts all
attack conditions proposed in Section 4.4.
Test results. Table 2 presents the DNS forwarding behav-
iors of home routers. Among 16 router models, we ﬁnd that 8
Table 2: DNS forwarding behaviors of home routers. The
ﬁrst eight models are conﬁrmed vulnerable by real attacks.
Cache by
Record Vulnerable
EDNS(0) No Tru-
ncation
Brand
Model
RT-AC66U B1
D-Link DIR 878
ASUS
Linksys WRT32X
Motorola M2
Xiaomi
3G
GEE
Gee 4 Turbo
Wavlink A42
Volans VE984GW+
Huawei Honor router 2
Tenda AC1206
FAST
TP-Link TL-WDR5660
Mercury D128
NetGear R6800
FER1200G
RV320
H3C MSR830-WiNet
Cisco
1 DNS caching not supported.
2 Truncate at 512 bytes.
3 Truncate at 1280 bytes.




