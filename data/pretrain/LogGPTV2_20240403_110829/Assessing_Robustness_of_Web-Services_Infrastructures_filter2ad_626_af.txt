results.
As seen in Figure 4, 65% of the studies either lack evaluation or have a small academic
evaluation. From the total of 144 studies, 13% are evaluated in either a small industrial project or
a large open source system. The results are considered medium-strong from the evaluation point
of view. The remaining 21% of the studies are evaluated either in larger industrial contexts or in
large academic projects which typically work on commercial systems. Furthermore, 86% of the
studies with strong evaluation focus on veriﬁcation and validation. These numbers suggest that
there are very few overall results in software robustness, especially in areas other than veriﬁcation
and validation.
22
5. Discussion
This systematic review gives an overview of the ﬁeld of software robustness. According to
the results, we can conclude that the research contributions in some areas of software robustness
are very limited. The main gap we identiﬁed was the lack of studies on elicitation and speciﬁca-
tion of robustness requirements. Veriﬁcation and validation in the form of testing is the largest
focus area, followed by design and architecture solutions to improve robustness. Fault injection,
automated robustness testing tool, and random interface testing are the main practices used for
robustness testing. None of the studies focused on other veriﬁcation and validation activities than
testing.
Almost all the studies focus on robustness issues caused by invalid inputs, and they ignore
other aspects of robustness included in the IEEE deﬁnition. More complex aspects of robustness
that we discuss in [146], such as time out, interrupts, unexpected events, and stressful execution
environment are rarely considered in these studies.
Robustness focuses on the states and events that should not happen in a system, rather than
how the system should function in ordinary cases. It is cumbersome or even impossible in many
systems to create a complete speciﬁcation of all the possible events and states. Therefore, most
academic and industrial projects neglect robustness requirement elicitation and speciﬁcation.
This neglect in many cases results in unawareness of the potential robustness risks among the
developers and testers and decreases the overall robustness of the system. As mentioned, it can be
uneconomical and even impossible for companies to create a complete requirement speciﬁcation,
which considers all the robustness risks. Nevertheless, the companies should be aware of these
risks in a systematic manner, and consider specifying the most crucial risks with the largest
potential negative impact.
Most identiﬁed design and architecture studies focus on interface wrappers that encapsulate
external component interfaces from the rest of the system. This method is mainly used when
working with COTS or third-party applications and services. Wrappers ﬁlter the input and output
data from the external modules. Another popular design method to achieve robustness is graceful
degradation. Since the developers are not always able to predict or intercept robustness issues it
can be necessary to degrade the functionality of the system in a controlled manner.
The majority of the published studies on robustness focus on veriﬁcation and validation of
the system in the presence of input with faulty value. Most methods and tools introduced in this
regard generate random test cases based on a simple model of the system. Although this method
can discover robustness risks in the system, the high level of randomness and lack of structure
and traceability with the requirements in most of these studies prevent us from guaranteeing the
complete robustness of the system. The reason for this is that in order to prove the robustness
of the system a more structured approach considering every possible state of the system should
be taken. Randomly testing some parts of the systems can make us more comfortable with the
robustness of the system but does not necessarily eliminate all potential robustness risks.
The automated robustness testing methods can only be viewed as complementary to other
types of testing. It can not replace unit testing, system testing, overall functionality testing or even
testing of other quality attributes. The reason for the popularity of the automated testing methods
is the fact that they are to a large extent automated and do not require a large development and
testing eﬀort. Although this might be enough for smaller systems, for more complex and safety-
critical systems or systems with requirement on high safety and availability a more systematic
method is required to ensure or improve robustness.
We can draw many interesting conclusions based on the statistics provided in this paper.
23
Other than the majority of the paper with a general system focus, there are studies that speciﬁ-
cally focus on web applications, COTS and operating systems. Since robustness is an especially
important attribute for embedded systems, more studies with this speciﬁc system focus can be
valuable to the practitioners.
Looking at the quality of studies, the conclusion is that many studies introduce new ideas and
solutions to problems regarding software robustness but fail to evaluate their contributions prop-
erly and show their validity in larger contexts. Furthermore, given our ﬁndings in [147], many of
the results are not usable for the industrial projects and remain pure academic contributions. One
reason for this is lack of industrial validation and the fact that studies remain in a lab or academic
context and never take the step to be evaluated in an industrial setting. Another reason is that
academic results tend to be context-speciﬁc and hard to generalize. Therefore, they cannot be
applied to many industrial situations. The strongest results with strong evaluation found in this
review are focused on testing of large systems such as operative systems. These tests are mostly
randomly generated test cases based on the structure of the system under test. We recommend the
use of statistical and evidence-based methods as described in [11, 91] for design and evaluation
of future studies in the ﬁeld. This will provide more scientiﬁc, and repeatable results which are
more useful for the industry.
6. Conclusion
This paper presents a review of the state of knowledge in the ﬁeld of software robustness
based on a systematic literature review. In total, we analyzed 9193 primary studies from the three
well-known, scientiﬁc, digital libraries: ISI Web of Knowledge, IEEE Xplore and Engineering
Village (Compendex & Inspec). Another 350 most relevant results were browsed from ACM
digital library to ensure the completeness of our search.
A total of 601 papers were chosen based on primary title exclusion. After another title exclu-
sion and abstract and full-text exclusion phases, 144 studies were selected. Based on the research
questions, each study was classiﬁed based on development phase focus, system focus and quality
of the research and evaluation.
The results indicate that in the ﬁeld of software robustness there are many studies on robust-
ness testing of COTS and operating systems, but very few studies about requirement elicitation
and speciﬁcation of robustness. Fault injection and automated testing tools based on fault in-
jection are the main areas for contributions on robustness testing. The main contributions for
improving robustness on the design and architecture level, the second largest area of contribu-
tions, focus on the use of wrappers and encapsulation of existing software components. Another
ﬁnding was that most studies focus on a very narrow deﬁnition of robustness. Most studies only
consider the invalid input aspect of robustness and neglect other more complex aspects like time
outs, interrupts and robustness problems related to the execution environment of the software.
The quality of the studies included in this review varied. In total, 65% of the papers have weak
or no evaluation, while only 21% of the contributions are strongly evaluated in large academic
or industrial contexts. Therefore, there is a clear need to conduct stronger research in the areas
where there is a gap of knowledge or where the existing solutions are not evaluated enough to be
useful in industrial contexts.
Finally, we think that there is more research needed on eliciting and specifying robustness
requirements. Stronger evaluation, especially industrial evaluation, of the studies is also strongly
recommended in the future. Another issue that needs to be addressed is to consider more types
24
of issue that can lead to robustness problems. Today, most of the studies focus on robustness
in presence of input with faulty value but areas such as robustness in presence of input with
unexpected timing or in presence of stressful environmental conditions has not been research as
actively.
7. References
[1] , 1990. IEEE Standard Glossary of Software Engineering Terminology, IEEE Std 610.12-1990.
[2] Abie, H., Savola, R. M., Dattani, I., November 2009. Robust, secure, self-adaptive and resilient messaging mid-
dleware for business critical systems. In: 2009 Computation World: Future Computing, Service Computation,
Cognitive, Adaptive, Content, Patterns (ComputationWorld 2009). IEEE, Piscataway, NJ, USA, pp. 153–160.
[3] Acharya, M., Sharma, T., Xu, J., Tao, X., September 2006. Eﬀective generation of interface robustness properties
for static analysis. In: Proceedings of the 21st IEEE International Conference on Automated Software Engineer-
ing. IEEE Computer Society, Los Alamitos, CA, USA, p. 4.
[4] Acharya, M., Tao, X., Jun, X., November 2006. Mining interface speciﬁcations for generating checkable ro-
bustness properties. In: 2006 17th IEEE International Symposium on Software Reliability Engineering. IEEE
Computer Society, Los Alamitos, CA, USA, p. 10.
[5] Afzal, W., Torkar, R., Feldt, R., 2009. A systematic review of search-based testing for non-functional system
properties. Information and Software Technology 51 (6), 957 – 976.
[6] Ait-Ameur, Y., Bel, G., Boniol, F., Pairault, S., Wiels, V., 2003. Robustness analysis of avionics embedded
systems. In: 2003 ACM SIGPLAN Conference on Languages, Compilers, and Tools for Embedded Systems
(LCTES’03), 11-13 June 2003. Vol. 38 of SIGPLAN Not. (USA). ACM, USA, pp. 123–132.
[7] Al-Khanjari, Z. A., Woodward, M. R., Kutti, N. S., Ramadhan, H., Shibab, K., 2003. Masking errors through
software robustness. In: International Conference on Internet Computing - IC’03, 23-26 June 2003. Vol. 2 of
International Conference on Internet Computing - IC’03. CSREA Press, USA, USA, pp. 809–817.
[8] Albinet, A., Arlat, J., Fabre, J.-C., jun. 2004. Characterization of the impact of faulty drivers on the robustness of
the linux kernel. Dependable Systems and Networks, 2004 International Conference on, 867 – 876.
[9] Allen, J., 2005. Towards robust agent-based dialogue systems. In: 2005 IEEE Workshop on Automatic Speech
Recognition and Understanding, 27 Nov.-1 Dec. 2005. IEEE, Piscataway, NJ, USA, p. 4.
[10] Ambriola, V., Gervasi, V., February 1998. Representing structural requirements in software architecture. In: Pro-
ceedings of IFIP TC2 WG2.4 Working Conference on Systems Implementation 2000: Languages, Methods and
Tools. Chapman &amp; Hall, London, UK, pp. 114–127.
[11] Arcuri, A., Briand, L., 2011. A practical guide for using statistical tests to assess randomized algorithms in
software engineering. In: Proceeding of the 33rd international conference on Software engineering. ACM, pp.
1–10.
[12] Arunchandar, V., Memon, A. M., 2004. Aspire: automated systematic protocol implementation robustness evalua-
tion. In: Proceedings of the 2004 Australian Software Engineering Conference, 13-16 April 2004. IEEE Computer
Society, Los Alamitos, CA, USA, pp. 241–250.
[13] Avizienis, A., Laprie, J., Randell, B., 2001. Fundamental Concepts of Dependability. Tech. Rep. 1145, University
of Newcastle.
[14] Bak, S., Chivukula, D., Adekunle, O., Sun, M., Caccamo, M., Sha, L., apr. 2009. The system-level simplex archi-
tecture for improved real-time embedded system safety. Real-Time and Embedded Technology and Applications
Symposium, 2009. RTAS 2009. 15th IEEE, 99–107.
[15] Barbosa, R., Silva, N., Duraes, J., Madeira, H., 2007. Veriﬁcation and Validation of (Real Time) COTS Prod-
ucts using Fault Injection Techniques. In: The 6th International IEEE Conference on Commercial-oﬀ-the-Shelf
(COTS)-Based Software Systems, 2007. ICCBSS ’07. pp. 233–242.
[16] Baudry, B., Le Traon, Y., Jezequel, J. M., 2001. Robustness and diagnosability of OO systems designed by
contracts. In: Proceedings of the 7th International Software Metrics Symposium. METRICS 2001, 4-6 April
2001. IEEE Computer Society, Los Alamitos, CA, USA, pp. 272–284.
[17] Belcastro, C., Chang, B.-C., 2002. Uncertainty modeling for robustness analysis of failure detection and accom-
modation systems. Proceedings of the 2002 American Control Conference 6, 4776–4782.
[18] Belli, F., Hollmann, A., Wong, W. E., 2010. Towards scalable robustness testing. In: Secure Software Integration
and Reliability Improvement (SSIRI), 2010 4th International Conference on. pp. 208–216.
[19] Bennani, M., Menasce, D., may. 2004. Assessing the robustness of self-managing computer systems under highly
variable workloads. Proceedings of the International Conference on Autonomic Computing, 62–69.
[20] Berztiss, A. T., 1994. Safety-critical software: a research agenda. International Journal of Software Engineering
and Knowledge Engineering 4, 165–181.
25
[21] Biolchini, J., Mian, P., Natali, A., Travassos, G., 2005. Systematic review in software engineering. System Engi-
neering and Computer Science Department COPPE/UFRJ, Technical Report ES 679 (05).
[22] Boehm, B., 1978. Characteristics of software quality. North-Holland.
[23] Boehm, B., Brown, J., Lipow, M., 1976. Quantitative evaluation of software quality. In: Proceedings of the 2nd
international conference on Software engineering. IEEE Computer Society Press, pp. 592–605.
[24] Brito, P., de Lemos, R., Rubira, C. M. F., 2008. Veriﬁcation of exception control ﬂows and handlers based on
architectural scenarios. In: High Assurance Systems Engineering Symposium, 2008. HASE 2008. 11th IEEE. pp.
177–186.
[25] Brito, P. H. S., de Lemos, R., Martins, E., Moraes, R., Rubira, C. M. F., 2009. Architectural-based validation of
fault-tolerant software. In: The 4th Latin-American Symposium on Dependable Computing, 2009. LADC ’09.
pp. 103–110.
[26] Byung-Hoon, S., Hudak, J., Siewiorek, D., Segall, Z., 1992. Development of a benchmark to measure system
robustness: experiences and lessons learned. In: Proceedings of the 3rd International Symposium on Software
Reliability Engineering (Cat. No.92TH0486-1), 7-10 Oct. 1992. IEEE Computer Society, Los Alamitos, CA,
USA, pp. 237–245.
[27] Calas, G., Boklund, A., Mankefors-Christiernin, S., 2006. A First Draft of RATF: A Method Combining Robust-
ness Analysis and Technology Forecasting. In: Information Technology: New Generations, 2006. ITNG 2006.
3rd International Conference on. pp. 72–77.
[28] Calori, L. C., Stalhane, T., Ziemer, S., 2007. Robustness analysis using FMEA and BBN - Case study for a
web-based application. In: WEBIST 2007: Proceedings of the 3rd International Conference on Web Information
Systems and Technologies, Vol IT - INTERNET TECHNOLOGY.
[29] Chan, H. A., 2004. Accelerated stress testing for both hardware and software. In: Proceedings of the Annual
Reliability and Maintainability Symposium, 26-29 Jan. 2004. Proceedings of the Annual Reliability and Main-
tainability Symposium. 2004 (IEEE Cat. No.04CH37506C). IEEE, Piscataway, NJ, USA, pp. 346–351.
[30] Chattopadhyay, J., 2006. Methodology to test the robustness of a fault tolerant system to meet realtime require-
ments. Journal of Aerospace Quality and Reliability 2 (Copyright 2009, The Institution of Engineering and Tech-
nology), 81–88.
[31] Cheng-Ying, M., Yan-Sheng, L., 2005. Improving the robustness and reliability of object-oriented programs