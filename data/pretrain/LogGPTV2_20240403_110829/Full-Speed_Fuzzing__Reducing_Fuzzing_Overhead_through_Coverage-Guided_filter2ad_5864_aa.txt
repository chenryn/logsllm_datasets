title:Full-Speed Fuzzing: Reducing Fuzzing Overhead through Coverage-Guided
Tracing
author:Stefan Nagy and
Matthew Hicks
(cid:19)(cid:17)(cid:18)(cid:26)(cid:1)(cid:42)(cid:38)(cid:38)(cid:38)(cid:1)(cid:52)(cid:90)(cid:78)(cid:81)(cid:80)(cid:84)(cid:74)(cid:86)(cid:78)(cid:1)(cid:80)(cid:79)(cid:1)(cid:52)(cid:70)(cid:68)(cid:86)(cid:83)(cid:74)(cid:85)(cid:90)(cid:1)(cid:66)(cid:79)(cid:69)(cid:1)(cid:49)(cid:83)(cid:74)(cid:87)(cid:66)(cid:68)(cid:90)
Full-speed Fuzzing: Reducing Fuzzing Overhead
through Coverage-guided Tracing
Stefan Nagy
Virginia Tech
PI:EMAIL
Matthew Hicks
Virginia Tech
PI:EMAIL
(1)
its three main components:
Abstract—Coverage-guided fuzzing is one of the most suc-
cessful approaches for discovering software bugs and security
vulnerabilities. Of
test case
generation, (2) code coverage tracing, and (3) crash triage, code
coverage tracing is a dominant source of overhead. Coverage-
guided fuzzers trace every test case’s code coverage through either
static or dynamic binary instrumentation, or more recently, using
hardware support. Unfortunately, tracing all test cases incurs
signiﬁcant performance penalties—even when the overwhelming
majority of test cases and their coverage information are dis-
carded because they do not increase code coverage.
To eliminate needless tracing by coverage-guided fuzzers,
we introduce the notion of coverage-guided tracing. Coverage-
guided tracing leverages two observations: (1) only a fraction of
generated test cases increase coverage, and thus require tracing;
and (2) coverage-increasing test cases become less frequent over
time. Coverage-guided tracing encodes the current frontier of
coverage in the target binary so that it self-reports when a
test case produces new coverage—without tracing. This acts
as a ﬁlter for tracing; restricting the expense of tracing to
only coverage-increasing test cases. Thus, coverage-guided tracing
trades increased time handling coverage-increasing test cases for
decreased time handling non-coverage-increasing test cases.
To show the potential of coverage-guided tracing, we create an
implementation based on the static binary instrumentor Dyninst
called UnTracer. We evaluate UnTracer using eight real-world
binaries commonly used by the fuzzing community. Experiments
show that after only an hour of fuzzing, UnTracer’s average
overhead is below 1%, and after 24-hours of fuzzing, UnTracer
approaches 0% overhead, while tracing every test case with
popular white- and black-box-binary tracers AFL-Clang, AFL-
QEMU, and AFL-Dyninst incurs overheads of 36%, 612%, and
518%, respectively. We further integrate UnTracer with the state-
of-the-art hybrid fuzzer QSYM and show that in 24-hours of
fuzzing, QSYM-UnTracer executes 79% and 616% more test
cases than QSYM-Clang and QSYM-QEMU, respectively.
Keywords—Fuzzing, software security, code coverage.
I.
INTRODUCTION
Software vulnerabilities remain one of the most signiﬁcant
threats facing computer and information security [1]. Real-
world usage of weaponized software exploits by nation-states
and independent hackers continues to expose the suscepti-
bility of society’s infrastructure to devastating cyber attacks.
For defenders, existing memory corruption and control-ﬂow
safeguards offer incomplete protection. For software develop-
ers, manual code analysis does not scale to large programs.
Fuzzing, an automated software testing technique, is a popular
approach for discovering software vulnerabilities due to its
speed, simplicity, and effectiveness [2], [3], [4], [5].
At a high level, fuzzing consists of (1) generating test
cases, (2) monitoring their effect on the target binary’s ex-
ecution, and (3) triaging bug-exposing and crash-producing
test cases. State-of-the-art fuzzing efforts center on coverage-
guided fuzzing [5], [4], [6], [7], [8], [9], which augments
execution with control-ﬂow tracking apparatuses to trace test
cases’ code coverage (the exact code regions they execute).
Tracing enables coverage-guided fuzzers to focus mutation on
a small set of unique test cases (those that reach previously-
unseen code regions). The goal being complete exploration of
the target binary’s code.
term that
Code coverage is an abstract
takes on three
concrete forms in fuzzing literature: basic blocks, basic block
edges, and basic block paths. For white-box (source-available)
binaries, code coverage is measured through instrumentation
inserted at compile-time [4], [5], [6]. For black-box (source-
unavailable) binaries, it is generally measured through instru-
mentation inserted dynamically [5], [7] or statically through bi-
nary rewriting [10], or through instrumentation-free hardware-
assisted tracing [11], [12], [4].
Tracing code coverage is costly—the largest source of time
spent for most fuzzers—and the resulting coverage information
is commonly discarded, as most test cases do not increase
coverage. As our results in Section VI show, AFL [5]—one
of the most popular fuzzers—faces tracing overheads as high
as 1300% for black-box binaries and as high as 70% for
white-box binaries. These overheads are signiﬁcant because,
as experiments in Section III-B show, over 90% of the time
spent fuzzing involves executing and tracing test cases. The
problem with spending all this effort on coverage tracing is that
most test cases and their coverage information are discarded;
because, for most benchmarks in our evaluation, less than 1
in 10,000 of all test cases are coverage-increasing. Thus, the
current practice of blindly tracing the coverage of every test
case is incredibly wasteful.
This paper introduces the idea of coverage-guided tracing,
and its associated implementation UnTracer, targeted at re-
ducing the overheads of coverage-guided fuzzers. Coverage-
guided tracing’s goal is to restrict tracing to test cases guar-
anteed to increase code coverage. It accomplishes this by
transforming the target binary so that it self-reports when a
test case increases coverage. We call such modiﬁed binaries
interest oracles. Interest oracles execute at native speeds be-
cause they eliminate the need for coverage tracing. In the
event that the interest oracle reports a test case is coverage-
increasing,
the test case is marked as coverage-increasing
and conventional tracing is used to collect code coverage.
Portions of the interest oracle are then unmodiﬁed to reﬂect
the additional coverage and the fuzzing process continues.
By doing this, coverage-guided tracing pays a high cost for
handling coverage-increasing test cases (about 2x the cost of
tracing alone in our experiments), for the ability to run all test
(cid:165)(cid:1)(cid:19)(cid:17)(cid:18)(cid:26)(cid:13)(cid:1)(cid:52)(cid:85)(cid:70)(cid:71)(cid:66)(cid:79)(cid:1)(cid:47)(cid:66)(cid:72)(cid:90)(cid:15)(cid:1)(cid:54)(cid:79)(cid:69)(cid:70)(cid:83)(cid:1)(cid:77)(cid:74)(cid:68)(cid:70)(cid:79)(cid:84)(cid:70)(cid:1)(cid:85)(cid:80)(cid:1)(cid:42)(cid:38)(cid:38)(cid:38)(cid:15)
(cid:37)(cid:48)(cid:42)(cid:1)(cid:18)(cid:17)(cid:15)(cid:18)(cid:18)(cid:17)(cid:26)(cid:16)(cid:52)(cid:49)(cid:15)(cid:19)(cid:17)(cid:18)(cid:26)(cid:15)(cid:17)(cid:17)(cid:17)(cid:23)(cid:26)
(cid:24)(cid:25)(cid:24)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:42:59 UTC from IEEE Xplore.  Restrictions apply. 
Fuzzer component
Test case generation
Execution monitoring
Grammar-based
Mutational
Black-box
White-box
Grey-box
dharma [13]
gramfuzz [14]
Peach [15]
Directed
Coverage-guided
TaintScope [16]
AFL [5]
honggfuzz [4]
libFuzzer [6]
VUzzer [7]
Autodafe [17]
dharma [13]
Peach [15]
Driller [18]
QSYM [19]
KLEE [20]
Mayhem [21]
S2E [22]
SAGE [23]
TaintScope [16]
AFL [5]
honggfuzz [4]
libFuzzer [6]
VUzzer [7]
TriforceAFL [24]
Fig. 1. A taxonomy of popular fuzzers by test case generation and program analysis approaches.
cases (initially) at native speed. To validate coverage-guided
tracing and explore its tradeoffs on real-world software, we
implement UnTracer. UnTracer leverages the black-box binary
instrumentor Dyninst [25] to construct the interest oracle and
tracing infrastructure.
We evaluate UnTracer alongside several coverage tracers
used with the popular fuzzer AFL [5]. For tracing black-box
binaries, we compare against the dynamic binary rewriter AFL-
QEMU [5], and the static binary rewriter AFL-Dyninst [25].
For tracing white-box binaries, we compare against AFL-
Clang [5]. To capture a variety of target binary and tracer
behaviors, we employ a set of eight real-world programs of
varying class and complexity (e.g., cryptography and image
processing) that are common to the fuzzing community. In
keeping with previous work, we perform evaluations for a 24-
hour period and use 5 test case datasets per benchmark to
expose the effects of randomness. Our results show UnTracer
outperforms blindly tracing all test cases: UnTracer has an
average run time overhead of 0.3% across all benchmarks,
while AFL-QEMU averages 612% overhead, AFL-Dyninst
averages 518% overhead, and AFL-Clang averages 36% over-
head. Experimental results also show that the rate of coverage-
increasing test cases rapidly approaches zero over time and
would need to increase four orders-of-magnitude to ameliorate
the need for UnTracer—even in a white-box tracing scenarios.
We further integrate UnTracer with the state-of-the-art hybrid
fuzzer QSYM [19]. Results show that QSYM-UnTracer aver-
ages 79% and 616% more executed test cases than QSYM-
Clang and QSYM-QEMU, respectively.
test cases across eight real-world applications.
In summary, this paper makes the following contributions:
• We introduce coverage-guided tracing: an approach
for reducing fuzzing overhead by restricting tracing
to coverage-increasing test cases.
• We quantify the infrequency of coverage-increasing
• We show that, for two coverage-guided fuzzers of
different type: AFL (“blind” test case generation) and
Driller (“smart” test case generation), they spend a
majority of their time on tracing test cases.
• We implement and evaluate UnTracer; UnTracer is
our coverage-guided tracer based on the Dyninst
black-box binary instrumentor. We evaluate UnTracer
against three popular, state-of-the-art white- and black-
box binary fuzzing tracing approaches: AFL-Clang
(white-box), AFL-QEMU (black-box, dynamic binary
rewriting), and AFL-Dyninst (black-box, static binary
rewriting), using eight real-world applications.
• We integrate UnTracer with the state-of-the-art hybrid
fuzzer QSYM, and show that QSYM-UnTracer out-
performs QSYM-Clang and QSYM-QEMU.
• We open-source our evaluation benchmarks [26], ex-
perimental infrastructure [27], and an AFL-based im-
plementation of UnTracer [28].
II. BACKGROUND
In this section, we ﬁrst discuss fuzzers’ deﬁning character-
istics, and how they relate to UnTracer. Second, we provide a
detailed overview of coverage-guided fuzzing and how current
fuzzers measure code coverage. Third, we discuss related
work on the performance of coverage tracing for fuzzing. We
conclude with our guiding research questions and principles.
A. An Overview of Fuzzing
Fuzzing is one of the most efﬁcient and effective techniques
for discovering software bugs and vulnerabilities. Its simplicity
and scalability have led to its widespread adoption among both
bug hunters [5], [4] and the software industry [2], [3]. Funda-
mentally, fuzzers operate by generating enormous amounts of
test cases, monitoring their effect on target binary execution
behavior, and identifying test cases responsible for bugs and
crashes. Fuzzers are often classiﬁed by the approaches they use
for test case generation and execution monitoring (Figure 1).
Fuzzers generate test cases using one of two approaches:
grammar-based [29], [13], [14], [15] or mutational [30], [5],
[4], [7], [6]. Grammar-based generation creates test cases
constrained by some pre-deﬁned input grammar for the target
binary. Mutational generation creates test cases using other test
cases; in the ﬁrst iteration, by mutating some valid “seed” input
accepted by the target binary; and in subsequent iterations,
by mutating prior iterations’ test cases. For large applications,
input grammar complexity can be burdensome, and for pro-
prietary applications, input grammars are seldom available.
For these reasons, most popular fuzzers are mutational. Thus,
coverage-guided tracing focuses on mutational fuzzing.
Most mutational fuzzers leverage program analysis to
strategize which test cases to mutate. Directed fuzzers [31],
[32] aim to reach speciﬁc locations in the target binary; thus
they prioritize mutating test cases that seem to make progress
toward those locations. Coverage-guided fuzzers [5], [4], [7],
[6] aim to explore the entirety of the target binary’s code; thus
they favor mutating test cases that reach new code regions.
As applications of directed fuzzing are generally niche, such
as taint tracking [16] or patch testing [31], coverage-guided
(cid:24)(cid:25)(cid:25)
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:42:59 UTC from IEEE Xplore.  Restrictions apply. 







		


	
	

	
	
		



	



	

	

	


		




		




Fig. 2. High-level architecture of a coverage-guided mutational fuzzer.
fuzzing’s wider scope makes it more popular among the
fuzzing community [5], [6], [4], [3]. Coverage-guided tracing
is designed to enhance coverage-guided fuzzers.
Fuzzers are further differentiated based on the degree
of program analysis they employ. Black-box fuzzers [17],
[13], [15] only monitor input/output execution behavior (e.g.,
crashes). White-box fuzzers [33], [23], [21], [18], [16], [20],
[22] use heavy-weight program analysis for ﬁne-grained ex-
ecution path monitoring and constraint solving. Grey-box
fuzzers [5], [4], [7], [6], [24], [31], [8] are a tradeoff between
both—utilizing lightweight program analysis (e.g., code cov-
erage tracing). Coverage-guided grey-box fuzzers are widely
used in practice today; examples include VUzzer [7], Google’s
libFuzzer [6], honggfuzz [4], and AFL [5]. Our implementa-
tion of coverage-guided tracing (UnTracer) is built atop the
coverage-guided grey-box fuzzer AFL [5].
B. Coverage-Guided Fuzzing
1)
2)
3)
4)
Coverage guided fuzzing aims to explore the entirety of the
target binary’s code by maximizing generated test cases’ code
coverage. Figure 2 highlights the high-level architecture of a
coverage-guided mutational fuzzer. Given a target binary and
some initial set of input seeds, S, fuzzing works as follows:
Queue all initial seeds1 s ∈ S for mutation.
test case generation: Select a queued seed and
mutate it many times, producing test case set T .
Execution monitoring: For all test cases t ∈ T , trace
their code coverage and look for crashes.
If a test case is coverage-increasing, queue it as a
seed, and prioritize it for the next round of mutation.
Otherwise, discard it.
Crash triage: Report any crashing test cases.
Return to step 2 and repeat.
5)
6)
Coverage-guided fuzzers trace code coverage during execu-
tion via binary instrumentation [5], [6], [4], system emulation