,
.
E
n
m
sup
PX Y
These bounds indicate that the error in (17) vanishes much faster
than the error in (18) and thus, the size of the training set, in general,
should be kept larger than the size of the validation set, i.e., n ! m.
3.4 Sample complexity
We now study how large the validation set should be in order to get
a good estimation. For ε, δ ą 0, we define the sample complexity
as the set of smallest integers Mpε, δq and Npε, δq sufficient to
guarantee that the gap between the true д-vulnerability and the
˘
mq is at most ε with at least 1 ´ δ probability:
estimatedpVnpf ‹
Definition 3.3. For ε, δ ą 0, let all pairs
be the
set of smallest pm, nq sizes of training and validation sets such that:
(19)
”
|Vд ´pVnpf ‹
`
Mpε, δq, Npε, δq
ı
mq| ą ε
ď δ .
P
sup
PX Y
Next result says that we can bound the sample complexity in
terms of ε, δ, σ, and |b ´ a| (see Appendix B.3 for the proof).
mq ´ Vpf ‹
The theoretical results of this section are very general and cannot
take full advantage of the specific properties of a particular model
or data distribution. In particular, it is important to emphasize that
the upper bound in (11) is independent of the learned function
f ‹
cause of (39), and thus these bounds are independent of the spe-
cific algorithm and training sets in used to solve the optimization
m because |pVnpf ‹
mq| ď maxf PH |pVnpf q ´ Vpf q| and be-
in (8). Furthermore, the f maximizing |Vpf q ´pVnpf q| in those
in-equations is not necessarily what the algorithm would choose.
Hence the bounds given in Theorem 3.2 and Corollary 3.4 in gen-
eral are not tight. However, these theoretical bounds provide a
worst-case measure from which learnability holds for all data sets.
In the next section, we will propose an approach for selecting
f ‹
m and estimating Vд. The experiments in Section 5 suggest that
our method usually estimates Vд much more accurately than what
is indicated by Theorem 3.2.
4 FROM д-VULNERABILITY TO BAYES
VULNERABILITY VIA PRE-PROCESSING
m to estimate Vд.
This is the core section of the paper, which describes our approach
to select the f ‹
In principle one could train a neural network to learn f ‹
m by
training samples (cfr. Equation 8). However, this would require
using ´pVmpf q as the loss function, and minimizing it over the m
pVmpf q to be a differentiable function of the weights of the neural
propagation. Now, the problem is that the д component ofpVmpf q
network, so that its gradient can be computed during the back-
is essentially a non-differentiable function, so it would need to be
approximated by a suitable differentiable (surrogate) function, (e.g.,
as it is the case of the Bayes error via the cross-entropy). Finding an
adequate differentiable function to replace each possible д may be a
challenging task in practice. If this surrogate does not preserve the
original dynamic of the gradient of д with respect to f , the learned
f will be far from being optimal.
In order to circumvent this issue, we propose a different approach,
which presents two main advantages:
(1) it reduces the problem of learning f ‹
m to a standard classifi-
cation problem, therefore it does not require a different loss
function to be implemented for each adversarial scenario;
(2) it can be implemented by using any universally consistent
learning algorithm (i.e., any ML algorithm approximating
the ideal Bayes classifier).
The reduction described in the above list (item 1) is based on
the idea that, in the д-leakage framework, the adversary’s goal is
not to directly infer the actual secret x, but rather to select the
optimal guess w about the secret. As a consequence, the training
of the ML classifier to produce f ‹
m should not be done on pairs of
type px, yq, but rather of type pw, yq, expressing the fact that the
best guess, in the particular run which produced y, is w. This shift
from px, yq to pw, yq is via a pre-processing and we propose two
distinct and systematic ways to perform this transformation, called
data and channel pre-processing, respectively. The two methods are
illustrated in the following sections.
We remind that, according to section 3, we restrict, wlog, to non-
negative д’s. If д takes negative values, then it can be shifted by
adding ´ minw,x дpw, xq, without consequences for the д-leakage
value (cfr. [2, 4]). Furthermore we assume that there exists at least
a pair px, wq such that πx ¨ дpw, xq ą 0. Otherwise Vд would be 0
and the problem of estimating it will be trivial.
4.1 Data pre-processing
The data pre-processing technique is completely black-box in the
sense that it does not need access to the channel. We only assume
the availability of a set of pairs of type px, yq, sampled according to
πŻC, the input-output distribution of the channel. This set could
be provided by a third party, for example. We divide the set in Dm
(training) and Tn (validation), containing m and n pairs, respectively.
For the sake of simplicity, to describe this technique we assume
that д takes only integer values, in addition to being non-negative.
The construction for the general case is discussed in Appendix C.3.
Algorithm 1: Algorithm for data pre-processing
Input: Dm; Output: D1
1. D1
2. For each x, y, let uxy be the number of copies of px, yq in Dm;
3. For each x, y, w, add uxy ¨ дpw, xq copies of pw, yq to D1
m1.
m1:“ H;
m1;
The idea behind the data pre-processing technique is that the
effect of the gain function can be represented in the transformed
dataset by amplifying the impact of the guesses in proportion to
their reward. For example, consider a pair px, yq in Dm, and assume
that the reward for the guess w is дpw, xq “ 5, while for another
guess w1 is дpw1, xq “ 1. Then in the transformed dataset D1
m1
this pair will contribute with 5 copies of pw, yq and only 1 copy of
pw1, yq. The transformation is described in Algorithm 1. Note that
in general it causes an expansion of the original dataset.
Estimation of Vд. Given Dm, we construct the set D1
pw, yq according to Algorithm 1. Then, we use D1
sifier f ‹
classifier. As proved below, f ‹
as the optimal empirical rule f ‹
we use f ‹
with f replaced by f ‹
m.
Correctness. We first need some notation. For each pw, yq, define:
(22)
m1 of pairs
m1 to train a clas-
m1, using an algorithm that approximates the ideal Bayes
m1 gives the same mapping Y Ñ W
m on Dm (cfr. subsection 3.2). Finally,
m and Tn to compute the estimation of Vдpπ , Cq as in (7),
πx ¨ Cxy ¨ дpw, xq ,
Upw, yq def“
ÿ
x
which represents the “ideal” proportion of copies of pw, yq that
D1
m1 should contain. From Upw, yq we can now derive the ideal
ÿ
joint distribution on W ˆ Y and the marginal on W:
PW Ypw, yq def“ Upw, yq
, where
def“
α
Upw, yq , (23)
(note that α ą 0 because of the assumption on π and д),
y,w
The channel of the conditional probabilities of y given w is:
α
ÿ
y
def“
ξw
PW Ypw, yq.
def“ PW Ypw, yq
.
ξw
Ewy
(24)
(25)
Note that PW Y “ ξŻE. By construction, it is clear that the D1
m1
generated by Algorithm 1 could have been generated, with the same
probability, by sampling ξŻE. The following theorem, whose proof
is in Appendix C.1, establishes that the д-vulnerability of πŻC is
equivalent to the Bayes vulnerability of ξŻE, and hence it is correct
to estimate f ‹
m1 trained on D1
m1.
Theorem 4.1 (Correctness of data pre-processing). Given a
m as an empirical Bayes classifier f ‹
prior π, a channel C, and a gain function д, we have
Vдpπ , Cq “ α ¨ Vдidpξ , Eq ,
where α, ξ and E are those defined in (23), (24) and (25), respectively,
and дid is the identity function (cfr. section 2), i.e., the gain function
corresponding to the Bayesian adversary.
Estimation error. To reason about the error we need to consider
the optimal empirical classifiers. Assuming that we can perfectly
match the Upw, yq above with the uxy of Algorithm 1, we can repeat
the same reasoning as above, thus obtainingpVmpf q “ α ¨pVm1pf q,
where Vmpf q is the empirical functional defined in (8), andpVm1pf q
is the corresponding empirical functional for дid evaluated in Dm1:
(26)
pVm1pf q def“ 1
f pyq, w
ÿ
`
˘
дid
m1
pw,yqPDm1
pVm1pf q.
pVm1pf q “ f ‹
f PH
f PH
def“ arg max
f PH
pα ¨pVm1pf qq “ arg max
f ‹
m1 is the maximizer of this functional, i.e. f ‹
m1
Therefore we have:
f ‹
m “ arg max
m1 .
f PH
A bound on the estimation error of this method can therefore be
obtained by using the theory developed in previous section, applied
to the Bayes classification problem. Remember that the estimation
error is f ‹
mq|. With respect to the estimation error
of the corresponding Bayes classifier, we have a magnification of a
factor α as shown by the following formula, wherepVn1 represents
|Vд ´pVnpf ‹
m1q| “ α ¨ |Vдid ´pVn1pf ‹
pVmpf q “ arg max
m is |Vд ´pVnpf ‹
mq| “ |α ¨ Vдid ´ α ¨pVn1pf ‹
m1q|.
However, the normalized estimation error (cfr. section 5) remains
the same because both numerator and denominator are magnified
by a factor α.
the empirical functional for the Bayes classifier:
Concerning the probability that the error is above a certain
threshold ε, we have the same bound as those for the Bayes classifier
in Proposition 3.1 and the other results of previous section, where
2
σ
2 by α
ε is replaced by αε, m, n by m1, n1, σ
2, and |b ´ a| “ 1
(because it’s a Bayes classifier). It may sounds a bit surprising that
the error for the estimation of the д-vulnerability is not much worse
than for the estimation of the Bayes error, but we recall that we
are essentially solving the same problem, only every quantity is
magnified by a factor α. Also, we are assuming that we can match
perfectly Uxy by uxy. When д ranges in a large domain this may
not be possible, and we should rather resort to the channel pre-
processing method described in the next section.
4.2 Channel pre-processing
For this technique we assume black-box access to the system, i.e.,
that we can execute the system while controlling each input, and
collect the corresponding output.
ř
x πx ¨ дpw, xq
The core idea behind this technique is to transform the input of
C into entries of type w, and to ensure that the distribution on the
w’s reflects the corresponding rewards expressed by д.
More formally, let us define a distribution τ on W as follows:
πx ¨ дpw, xq , (27)
(note that β is strictly positive because of the assumptions on д and
π), and let us define the following matrix R from W to X:
where β
ÿ
def“
def“
x,w
τw
β
Rwx
def“ 1
β
¨ 1
τw
¨ πx ¨ дpw, xq .
(28)
It is easy to check that R is a stochastic matrix, hence the composi-
tion RC is a channel. It is important to emphasize the following:
Remark In the above definitions, β, τ and R depend solely on д
and π, and not on C.
The above property is crucial to our goals, because in the black-
box approach we are not supposed to rely on the knowledge of
C’s internals. We now illustrate how we can estimate Vд using the
pre-processed channel RC.
Estimation of Vд. Given RC and τ, we build a set D2
m2 consisting
of pairs of type pw, yq sampled from τŻRC. We also construct a set
Tn of pairs of type px, yq sampled from πŻC. Then, we use D2
m2
to train a classifier f ‹
m, using an algorithm that approximates the
ideal Bayes classifier. Finally, we use f ‹
m and Tn to compute the
estimation of Vдpπ , Cq as in (7), with f replaced by f ‹
m.
Alternatively, we could estimate Vдpπ , Cq by computing the em-
pirical Bayes error of f ‹
m on a validation set Tn of type pw, yq sam-
pled from τŻRC, but the estimation would be less precise. Intuitively,
this is because RC is more “noisy” than C.
Correctness. The correctness of the channel pre-processing method
is given by the following theorem, which shows that we can learn
f ‹
m by training a Bayesian classifier on a set sampled from τŻRC.
Theorem 4.2 (Correctness of channel pre-processing). Given
a prior π and a gain function д, we have that, for any channel C:
Vдpπ , Cq “ β ¨ Vдidpτ , RCq
for all channels C.
where β, τ and R are those defined in (27) and (28).
Interestingly, a result similar to Theorem 4.2 is also given in [6],
although the context is completely different from ours: the focus
of [6], indeed, is to study how the leakage of C on X may induce
also a leakage of other sensitive information Z that has nothing to
do with C (in the sense that is not information manipulated by C).
We intend to explore this connection in the context of a possible
extension of our approach to this more general scenario.
Estimation error. Concerning the estimation error, the results are
essentially the same as in previous section (with α replaced by β).
As for the bound on the probability of error, the results are worse,
2 is magnified by the channel pre-
because the original variance σ
processing, which introduces a further factor of randomness in the
sampling of training data in 12, which means that in practice this
bound is more difficult to estimate.
4.3 Pros and cons of the two methods
The fundamental advantage of data pre-processing is that it allows
to estimate Vд from just samples of the system, without even black-
box access. In contrast to channel pre-processing, however, this
method is particularly sensitive to the values of the gain function д.
Large gain values will increase the size of D1
m1, with consequent in-
crease of the computational cost for estimating the д-vulnerability.
Moreover, if д takes real values then we need to apply the technique
described in Appendix C.3, which can lead to a large increase of the
dataset as well. In contrast, the channel pre-processing method has
the advantage of controlling the size of the training set, but it can be
applied only when it is possible to interact with the channel by pro-
viding input and collecting output. Finally, from the precision point
of view, we expect the estimation based on data pre-processing to
be more accurate when д consists of small integers, because the
channel pre-processing introduces some extra noise in the channel.
5 EVALUATION
In this section we evaluate our approach to the estimation of д-
vulnerability. We consider four different scenarios:
(1) X is a set of (synthetic) numeric data, the channel C consists
of geometric noise, and д is the multiple guesses gain function,
representing an adversary that is allowed to make several
attempts to discover the secret.
(2) X is a set of locations from the Gowalla dataset [1], C is
the optimal noise of Shokri et al. [37], and д is one of the
functions used to evaluate the privacy loss in [37], namely a
function anti-monotonic on the distance, representing the
idea that the more the adversary’s guess is close to the target
(i.e., the real location), the more he gains.
(3) X is the Cleveland heart disease dataset [24], C is a differen-
tially private (DP) mechanism [25, 26], and д assigns higher
values to worse heart conditions, modeling an adversary that
aims at discovering whether a patient is at risk (for instance,
to deny his application for health insurance).
(4) X is a set of passwords of 128 bits and C is a password checker
that leaks the time before the check fails, but mitigates the
timing attacks by applying some random delay and the buck-
eting technique (see, for example, [31]). The function д rep-
resents the part of the password under attack.
For each scenario, we proceed in the following way:
‚ We consider 3 different samples sizes for the training sets
that are used to train the ML models and learn the Y Ñ
W remapping. This is to evaluate how the precision of the
estimate depends on the amount of data available, and on its
relation with the size of |Y|.
‚ In order to evaluate the variance of the precision, for each
training size we create 5 different training sets, and
‚ for each trained model we estimate the д-vulnerability using
50 different validation sets.