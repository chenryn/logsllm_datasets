the above mentioned advanced functions involve a special kind of
ﬁle operations: frequent modiﬁcations to a ﬁle.
In § 4 and § 5, we have studied various simple ﬁle operations
that are each performed at once. On the contrary, frequent modiﬁ-
cations imply that a ﬁle is modiﬁed in a frequent and incremental
manner. Thus, they exhibit diverse data update patterns in terms of
data update size and rate. The large-scale trace collected by Dra-
go et al. [12] reveals that for 8.5% of Dropbox users, more than
10% of their sync trafﬁc is caused by frequent modiﬁcations [36].
Further, frequent modiﬁcations may well incur abundant overhead
trafﬁc that far exceeds the amount of useful data update trafﬁc sen-
t by the user client over time, which is referred to as the trafﬁc
overuse problem [36]. Besides, in this section we will elaborate
on client locations, network environments, and hardware conﬁgu-
rations, because the TUE of frequent ﬁle modiﬁcations is largely
inﬂuenced by these factors.
6.1 Sync Deferment
[Experiment 6] : To experiment with frequent ﬁle modiﬁcations,
we append X random kilobytes to an empty ﬁle inside the sync
folder every X seconds, until the total appended bytes reach a cer-
tain size C (typically C = 1 MB). This is denoted as the “X KB/X
 1.1 1.12 1.14 1.16 1.18 1.2 1.22 1.24Deduplication RatioBlock Size128 KB256 KB512 KB1 MB2 MB4 MB8 MB16 MBFull file123Figure 6: TUE of the six cloud storage services in response to controlled frequent ﬁle modiﬁcations. Note that the subﬁgures have
distinct Y-axes, and the (b) OneDrive subﬁgure has a different X-axis.
sec” appending experiment. We use random bytes since they are
difﬁcult to compress, thus preventing ﬁle compression from inﬂu-
encing our measurements of TUE.
Our goal is three folds by doing this experiment: 1) We observe
and understand the sync trafﬁc and TUE in response to frequent
modiﬁcations; 2) We aim to discover whether the cloud storage
service has used the sync deferment in order to avoid or mitigate
the trafﬁc overuse problem; and 3) If the sync deferment is adopted,
we want to measure how long the sync deferment is.
All the experiments in this section are performed using M1 @
MN (refer to Table 4) with 20 Mbps of bandwidth, and the latency
(between M1 and each cloud) is between 42 msec and 77 msec.
In terms of service access method, we only examine the PC client,
because almost all the frequent modiﬁcations are generated from
PC clients in practice 6. Experiments with other benchmarks will
be presented in § 6.2.
First, to investigate the impact of frequent ﬁle modiﬁcations on
TUE, we examine the cases for X ∈ {1, 2,··· , 19, 20}. As depict-
ed in Figure 6, the six mainstream cloud storage services exhibit
diverse and interesting phenomena:
• Frequent modiﬁcations to a ﬁle often lead to large TUE (the
aforementioned “trafﬁc overuse problem”). As for the six
mainstream services, the maximum TUE can reach 260, 51,
144, 75, 32, and 33, respectively.
• We observe (except in the sync defer cases: Figure 6 (a), 6
(b), and 6 (f)) that TUE generally decreases as the modiﬁ-
X ) decreases. The reason is straight-
cation frequency (= 1024
forward: though the total data update size is always C = 1
MB, a lower data update frequency implies fewer data sync
events, and thus the overhead trafﬁc is reduced.
A natural question is: Why are the maximum TUE values of
Google Drive (260), OneDrive (51), Ubuntu One (144), and Box
(75) much larger than those of Dropbox (32) and SugarSync (33)?
The answer can be found from their data sync granularity (refer
to § 4.3): Google Drive, OneDrive, Ubuntu One, and Box employ
full-ﬁle sync, while Dropbox and SugarSync employ block-level
6The UIs (user interfaces) of web browser and mobile apps for
cloud storage services are usually not ﬁt for performing frequent
modiﬁcations to a ﬁle.
incremental sync which signiﬁcantly improves the network-level
trafﬁc efﬁciency.
On the other hand, there do exist a few cases (in Figure 6 (a),
6 (b), and 6 (f)) where TUE is close to 1.0. According to our ob-
servations, (a) Google Drive, (b) OneDrive, and (f) SugarSync deal
with the trafﬁc overuse problem by batching ﬁle updates using a
ﬁxed sync deferment: T seconds (which cannot be re-conﬁgured by
users). Figure 6 (a), 6 (b), and 6 (f) indicate that TGoogleDrive ∈
(3, 5) sec, TSugarSync ∈ (4, 6) sec, and TOneDrive ∈ (10, 11)
sec. Moreover, to ﬁgure out a more accurate value of T , we fur-
ther tune X from integers to ﬂoats. For example, we experiment
with X = 3.1, 3.2, ··· , 4.9 for TGoogleDrive, and then ﬁnd that
TGoogleDrive ≈ 4.2 sec. Similarly, we ﬁnd that TSugarSync ≈ 6
sec and TOneDrive ≈ 10.5 sec.
One may have the following question: Is it possible that the de-
ferred data synchronization of (a) Google Drive, (b) OneDrive, and
(f) SugarSync is triggered by a byte counter or an update counter
rather than the time threshold (T )? In other words, the three con-
cerned services may trigger the data synchronization once the num-
ber of uncommitted bytes or updates exceeds a certain value. This
question can be addressed in two cases:
• Case 1: If the data synchronization is triggered by a byte
counter, the resulting TUE would be close to 1.0 according
to our previous study on the byte-counter based “efﬁcien-
t batched synchronization” (UDS) [36]. This is clearly not
true as illustrated by Figure 6 (a), 6 (b), and 6 (f).
• Case 2: If the data synchronization is triggered by an update
counter, the resulting TUE in Figure 6 (a), 6 (b), and 6 (f)
would linearly decrease as the modiﬁcation period (X sec)
increases. Obviously, this is not true, either.
Therefore, we conclude that the deferred data synchronization is
not triggered by a byte counter or an update counter.
Unfortunately, ﬁxed sync deferments are limited in terms of us-
age scenarios. As shown in Figures 6 (a), 6 (b), and 6 (f), the trafﬁc
overuse problem still occurs when X > T .
To overcome the limitation of ﬁxed sync deferments, we propose
an adaptive sync defer (ASD) mechanism. ASD adaptively tunes
its sync deferment (Ti) to follow the latest (say, the i-th) data up-
date. In other words, when data updates happen more frequently,
Ti gets shorter; when data updates happen less frequently, Ti gets
 0 50 100 150 200 25012345678910TUEX KB/X sec appending(a) Google Drive 0 10 20 30 40 50 5 10 15 20TUEX KB/X sec appending(b) OneDrive 0 20 40 60 80 100 120 14012345678910TUEX KB/X sec appending(c) Ubuntu One 0 10 20 30 40 50 60 70 8012345678910TUEX KB/X sec appending(d) Box 0 5 10 15 20 25 3012345678910TUEX KB/X sec appending(e) Dropbox 0 5 10 15 20 25 30 3512345678910TUEX KB/X sec appending(f) SugarSync124Figure 7: TUE of (a) OneDrive, (b) Box, and (c) Dropbox on handling the “X KB/X sec” appending experiment, in Minnesota (MN)
and Beijing (BJ), respectively.
Figure 8: TUE of Dropbox on handling the (a) “1 KB/sec” appending experiment with variable bandwidths, (b) “1 KB/sec” appending
experiment with variable latencies, and (c) “X KB/X sec” appending experiment with distinct hardware conﬁgurations.
longer. In either case, Ti tends to be slightly longer than the lat-
est inter-update time, so that frequent modiﬁcations can be proper-
ly batched for synchronization (without harming user experience).
Speciﬁcally, Ti can be adapted in such an iterative manner:
Ti = min (
Ti−1
2
+
∆ti
2
+ , Tmax)
(2)
where ∆ti is the inter-update time between the (i-1)-th and the i-th
data updates, and  ∈ (0, 1.0) is a small constant that guarantees
Ti to be slightly longer than ∆ti in a small number of iteration
rounds. Tmax is also a constant representing the upper bound of
Ti, as a too large Ti will harm user experience by bringing about
intolerably long sync delay.
If Google Drive would utilize ASD on handling the “X KB/X
sec” (X > TGoogleDrive) appending experiments, the resulting
TUE will be close to 1.0 rather than the original 260 (X = 5), 100
(X = 6), 83 (X = 7), and so forth. The situation is similar for
OneDrive and SugarSync. More detailed performance evaluation
of ASD can be found in our previous work [37].
6.2 Impact of Network and Hardware
In this subsection, we ﬁrst study the impact of network and hard-
ware on TUE, and then explore why they impact TUE.
[Experiment 7, Network environment] : To study the impact of
network environment (including both bandwidth and latency) on
TUE, we conduct the following two batches of experiments.
The ﬁrst batch of experiments are performed on B1 @ BJ. It
represents a relatively poor network environment: low bandwidth
(nearly 1.6 Mbps) and long latency (between 200 msec and 480 m-
sec) relative to the cloud, because the six mainstream cloud storage
services are mainly deployed in US. After repeating Experiments
1 – 6 in this network environment, we compare the results with
the corresponding results by using M1 @ MN with abundant band-
width (nearly 20 Mbps) and short latency (between 42 msec and 77
msec), which represents a good network environment.
The second batch of experiments are performed by using M1 @
MN with controlled bandwidth (between 1.6 Mbps and 20 Mbp-
s) and latency (between 40 msec and 1000 msec), so that we are
able to get ﬁne-grained results about how the network environment
impacts TUE.
From the two batches of experiments, we mainly get the follow-
ing ﬁndings and implications:
• TUE of a simple ﬁle operation is usually not affected by net-
work environment.
• However, in the case of frequent ﬁle modiﬁcations, a user
client with relatively low bandwidth or long latency can save
more sync trafﬁc.
Speciﬁcally, for the ﬁrst batch of experiments, we plot the TUE
of (a) OneDrive, (b) Box, and (c) Dropbox on handling the “X
KB/X sec” appending experiment in Minnesota and Beijing in Fig-
ure 7 (a), 7 (b), and 7 (c), respectively. The situation of Google
Drive and SugarSync is similar to Figure 7 (a), and the situation
of Ubuntu One looks like Figure 7 (b). In each subﬁgure, the two
curves (“@ MN” vs. “@ BJ”) clearly illustrate that poor network
environment leads to smaller TUE, especially when the modiﬁca-
tion period (X sec) is short (excluding the sync defer cases).
For the second batch of experiments, as a typical example, we
plot the TUE of Dropbox on handling the “1 KB/sec” appending
experiment with variable bandwidths and latencies in Figure 8 (a)
and Figure 8 (b), respectively. In Figure 8 (a), the latency is ﬁxed
to around 50 msec and the bandwidth is tuned from 1.6 Mbps to
20 Mbps. In Figure 8 (b), the bandwidth is ﬁxed to around 20 Mbps
and the latency is tuned from 40 msec to 1000 msec. Obviously,
higher bandwidth or shorter latency leads to larger TUE.
[Experiment 7’, Hardware conﬁguration] : Next, we examine
the impact of hardware conﬁguration on TUE by repeating Experi-
ments 1 – 6 with distinct client machines: M1 (a typical machine),
M2 (an outdated machine), and M3 (an advanced machine). Their
detailed hardware information is listed in Table 4. All the experi-
ments are performed in Minnesota with abundant bandwidth (near-
ly 20 Mbps) and short latency (between 42 msec and 77 msec).
Through the Experiment 7’ results, we observe that TUE of a
simple ﬁle operation generally has no relation with hardware con-
 0 10 20 30 40 50 5 10 15 20TUEX KB/X sec appending(a) OneDrive @ MN@ BJ 0 10 20 30 40 50 60 70 8012345678910TUEX KB/X sec appending(b) Box@ MN@ BJ 0 5 10 15 20 25 3012345678910TUEX KB/X sec appending(c) Dropbox@ MN@ BJ 20 22 24 26 28 30 32 34 36 0 5 10 15 20TUEBandwidth (Mbps)(a)Dropbox 5 10 15 20 25 30 0 200 400 600 800 1000TUELatency (msec)(b)Dropbox 0 5 10 15 20 25 30 35 40 4512345678910TUEX KB/X sec appending(c)Dropbox-MN-M3Dropbox-MN-M1Dropbox-MN-M2125ﬁguration, but TUE of frequent ﬁle modiﬁcations is actually affect-
ed by hardware conﬁguration. As a typical example, in Figure 8
(c) we plot the TUE of Dropbox on handling the “X KB/X sec”
appending experiment with M1, M2, and M3. The three curves
clearly demonstrate that slower hardware incurs less sync trafﬁc.
Why do network environment and hardware conﬁguration im-
pact TUE? To explore the reason why network environment and
hardware conﬁguration impact TUE, we analyze the communica-
tion packets of data synchronization, in particular the TCP data
ﬂows. The analysis reveals that in the presence of frequent modiﬁ-
cations to a ﬁle, the user client does not always synchronize every
ﬁle modiﬁcation to the cloud separately. Instead, the user client
often batches multiple ﬁle modiﬁcations for data synchronization.
Speciﬁcally, a new ﬁle modiﬁcation (or a sequence of new ﬁle mod-
iﬁcations) is synchronized to the cloud when at least the following
two conditions are both satisﬁed:
• Condition 1: The previous ﬁle modiﬁcation (or the previ-
ous batch of ﬁle modiﬁcations) has been completely synchro-
nized to the cloud.
• Condition 2: The client machine has ﬁnished calculating the
latest metatata of the modiﬁed ﬁle.
As to Condition 1, when the network environment is relatively
poor, synchronizing the previous ﬁle modiﬁcation (or the previous
batch of ﬁle modiﬁcations) takes more time, so the client needs to
wait for a longer period of time to synchronize the new ﬁle modi-
ﬁcation. As to Condition 2, when the client runs on top of slower
hardware, calculating the latest metatata (which is computation-
intensive) also requires a longer period of time. Because the failure
of either condition will cause the new ﬁle modiﬁcation (or the se-
quence of new ﬁle modiﬁcations) to be naturally batched, poor net-
work environment or poor hardware increases the probability that
a ﬁle modiﬁcation gets batched, and thereby optimizes the TUE.
Finally, combining all the ﬁndings in this subsection, we get the
following implication:
• In the case of frequent ﬁle modiﬁcations, today’s cloud stor-
age services actually bring good news (in terms of TUE) to
those users with relatively poor hardware or Internet access.
7. DISCUSSION
While this paper mainly focuses on the trafﬁc costs of cloud stor-
age services, we keep in mind that the total costs of running a cloud
storage service also involves the computation costs, storage costs,
operation costs, and so forth. Therefore, we would like to fur-
ther study and understand the trafﬁc usage from an insider’s point
of view. In particular, we want to quantify the tradeoff between
TUE and other system metrics. For example, regarding data sync
granularity, incremental synchronization is a double-edge sword:
It effectively saves trafﬁc and storage compared with full-ﬁle syn-
chronization, but it also puts more computational burden on both
service providers and end users. Likewise, determining the best
data compression level to achieve a good balance between trafﬁc,
storage, and computation deserves further research efforts.
Speciﬁcally, studying the aforementioned system tradeoffs would
require at least the following three-fold information from cloud s-
torage providers:
• The user device composition (i.e., the percentages of PCs,
tablets, and smartphones) is the most important information
required. For PCs, it is generally ﬁne to sacriﬁce computa-
tion, storage, and/or network-level efﬁciency for better ser-
vice quality (e.g., faster synchronization of ﬁle operations).
For example, PC clients usually maintain a local sync fold-
er that stores a copy for almost every synchronized ﬁle at
the cloud side. On the other hand, smartphones are sensitive
to computation cost, storage space, and sometimes network
overhead (in 2G/3G/4G modes). Accordingly, mobile apps
usually maintain a small-size local folder that caches only a
few most recently accessed ﬁles.
• The logical interfaces of the storage infrastructure decides
the implementation difﬁculty and working efﬁciency of ID-
S (incremental data sync) for ﬁle modiﬁcations. The logical
interfaces mainly include the RESTful (full-ﬁle level) inter-
faces, ﬁle-level interfaces, and block-level interfaces. For ex-
ample, Microsoft Azure, Amazon S3, and OpenStack Swift
provide RESTful interfaces, and thus implementing IDS on
top of them is not an easy job. On the contrary, implement-
ing IDS on top of a NFS-based infrastructure (with ﬁle-level
interfaces) is quite straightforward. In addition, as GFS and
HDFS provide seemingly ﬁle-level interfaces based on block-
level infrastructure, the corresponding implementation difﬁ-
culty and working efﬁciency of IDS lie between those with
RESTful and ﬁle-level interfaces. Finally, the logical stor-
age interfaces also impact the working efﬁciency of BDS
(batched data sync) for small ﬁles.
• The physical devices of the storage infrastructure have non-
negligible inﬂuence on the working efﬁciency and imple-
mentation (monetary) costs of a cloud storage service. Obvi-
ously, a single SSD is faster while much more expensive than
a single HDD, but up to now it is still not clear which is the
most cost-effective among an SSD cluster, an HDD cluster, a