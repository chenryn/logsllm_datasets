JDK中的Jconsole工具可以帮助我们查看JVM中运行的MBeans信息，使我们很方便地浏览Hadoop中的监控信息。很多第三方监控和调整系统（Nagios和Hyperic等）可用于查询MBeans，这样JMX自然就成为我们监控Hadoop系统的最好工具。但是，需要设置支持远程访问的JMX，并且设置一定的安全级别，包括密码权限、SSL链接及SSL客户端权限设置等。为了使系统支持远程访问，JMX要求对一些选项进行更改，其中包括设置Java系统的属性（可以通过编辑Hadoop的conf/hadoop-env.sh文件实现）。下面的例子展示了如何通过密码远程访问NameNode中的JMX（在SSL不可用的条件下）：
export HADOOP_NameNode_OPTS="-Dcom.sun.management.jmxremote
-Dcom.sun.management.jmxremote.ssl=false
-Dcom.sun.management.jmxremote.password.file=$HADOOP_CONF_DIR/jmxremote.password
-Dcom.sun.management.jmxremote.port=8004$HADOOP_NameNode_OPTS"
jmxremote. password文件以纯文本的格式列出了所有的用户名和密码。JMX文档有关于jmxremote.password文件的更进一步的格式信息。
通过以上的配置，我们可以使用JConsole工具浏览远程NameNode中的MBean监控信息。事实上，我们还有很多其他方法实现这个功能，比如通过jmxquery（一个命令行工具，具体信息可查看http：//code.google.com/p/jmxquery/）来检索低于副本要求的块：
./check_jmx-U service：jmx：rmi：///jndi/rmi：//NameNode-host：8004/jmxrmi-O\
hadoop：service=NameNode, name=FSNamesystemState-A UnderReplicatedBlocks\
-w 100-c 1000-username monitorRole-password secret
JMX OK-UnderReplicatedBlocks is 0
通过jmxquery命令创建一个JMX RMI链接，链接到NameNode主机地址上，端口号为8004。它会读取对象名为hadoop：service=NameNode, name=FSNamesystemState的UnderReplicatedBlocks属性，并将读出的值写入终端。-w、-c选项定义了警告和数值的临界值，这个临界值的选定要在我们运行和维护集群一段时间以后才能选出比较合适的经验值。
需要注意的是，尽管我们可以通过JMX的默认配置看到Hadoop的监控信息，但是它们不会自动更新，除非更改MetricContext的具体实现。如果JMX是我们使用的监控系统信息的唯一方法，那么就可以把MetricContext的实现更改为NullContextWithUpdateThread。
通常大多数人会使用Ganglia和另外一个可选的系统（比如Nagios）来进行Hadoop集群的检测工作。Ganglia可以很好地完成大数据量监控信息的收集和图形化工作，而Nagios及类似的系统则更擅长处理小规模的监控数据，并且在监控信息超出设定的监控阈值时发出警告。管理者可以根据需求选择合适的工具。下一节我们就对Ganglia的使用配置进行详细讲解。
10.2.5 Ganglia
Ganglia是UC Berkeley发起的一个开源集群监视项目，用于测量数以千计的节点集群。Ganglia的核心包含两个Daemon（分别是客户端Ganglia Monitoring Daemon（gmond）和服务端Ganglia Meta Daemon（gmetad），以及一个Web前端。Daemon主要是用来监控系统性能，如CPU、memory、硬盘利用率、I/O负载、网络流量情况等；Web前端页面主要用于获得各个节点工作状态的曲线描述。Ganglia可以帮助我们合理调整、分配系统资源，为提高系统整体性能起到了重要作用。
处于监控状态下的每台位于节点上的计算机都需要运行一个收集和发送度量数据的名为gmond的守护进程。接收所有度量数据的主机可以显示这些数据，并且可以将这些数据传递到监控主机中。gmond带来的系统负载非常少，它的运行不会影响用户应用进程的性能。多次收集这些数据则会影响节点性能。网络中的“抖动”发生在大量小消息同时出现时，可以通过将节点时钟保持一致来避免这个问题。
gmetad可以部署在集群内任一台位于节点上的或通过网络连接到集群的独立主机中，它通过单播路由的方式与gmond通信，收集区域内节点的状态信息，并以XML数据的形式保存在数据库中。最终由RRDTool工具处理数据，并生成相应的图形显示，以Web方式直观地提供给客户端。这个服务器可以被看做是一个信息收集的装置，可以同时监控多个客户端的系统状况，并把信息显示在Web界面上。通过Web端连接这个服务器，就可以看到它所监控的所有机器状态。
1.服务器端的安装与配置
首先需要在服务器端安装下列包：ganglia-gmetad-3.0.3-1.fc4.i386.rpm（从各个网段获取汇总监控信息），rrdtool-1.2.18-1.el4.rf.i386.rpm（显示图像的工具），rrdtool-devel-1.2.18-1.el4.rf.i386.rpm, ganglia-web-3.0.3-1.noarch.rpm（Ganglia的Web程序），perl-rrdtool-1.2.18-1.el4.rf.i386.rpm。使用#rpm-ivh软件包.rpm可以安装这些包。
安装完成之后，找到Ganlia服务端的配置文档：/etc/gmetad.conf，可以根据不同的需求进行配置。在这里只简单介绍一下如何添加或修改要监控的系统。先通过#vi/etc/gmetad.conf命令（进入编辑），找到data_source“Login FARM”10.77.20.111：8651 10.77.20.111：8699（后面的这些IP地址就是要监控的主机，冒号后跟的是要监听的端口号，这个端口号将在介绍客户端的配置时提到）。其他属性保持默认配置即可。
配置完成后要重启gmetad服务：#service gmetad restart。下面我们来配置虚拟主机，设置路径DocumentRoot为"/var/www/html/ganglia"：
#配置虚拟主机
＜Directory"/var/www/html/ganglia"＞
Options Indexes FollowSymLinks
AllowOverride None
Order allow, deny
Allow from all
＜/Directory＞
然后重启httpd服务：service httpd restart，即完成服务器端的安装和配置。
2.客户端的安装与配置
在客户端安装Ganglia，是为了收集本机的信息，并通过设置好的端口把信息传给服务器端，因此我们需要在所有节点上进行相应的安装和配置。下面我们来讲解如何进行客户端的安装。
首先在客户端安装软件包：ganglia-gmond-3.0.3-1.fc4.i386.rpm。安装完成后，找到它的配置文档/etc/gmond.conf并打开编辑（#vi/etc/gmond.conf）。接着找到配置文件中如下部分并按照所给出的例子进行配置。
/*You can specify as many tcp_accept_channels as you like to share
an xml description of the state of the cluster*/
tcp_accept_channel{
port=8699/*注释：这个是端口，通过它来传送系统信息。注意要和服务器端监听的端口一致*/
acl{
default="deny"
access{
ip=10.77.20.111/*注释：这里是服务器的IP地址*/
mask=32
action="allow"
}}}
完成配置后，重启gmond服务（#service gmond restart）即可。至此Ganglia在服务器端和客户端的安装完成，我们可以查看它的运行状态，如图10-2所示。
图 10-2 Ganglia的监控页面
事实上，有很多其他可以扩展Hadoop监控能力的工具比如本书第17章介绍的Chukwa，它是一个数据收集和监控系统，构建于HDFS和MapReduce之上，也是可供管理员选择的监控工具。Chukwa可以统计分析日志文件，从而提供给管理员想要的信息。
10.2.6 Hadoop管理命令
在了解扩展的监控管理工具的同时，也不能忘记Hadoop本身为我们提供了相应的系统管理工具，本节我们就对相关的工具进行介绍。
1.dfsadmin
dfsadmin是一个多任务的工具，我们可以使用它来获取HDFS的状态信息，以及在HDFS上执行的管理操作。管理员可以在终端中通过Hadoop dfsadmin命令调用它，这里需要使用超级用户权限。dfsadmin相关的命令如表10-2所示。
2.文件系统验证（fsck）
Hadoop提供了fsck工具来验证HDFS中的文件是否正常可用。这个工具可以检测文件块是否在DataNode中丢失，是否低于或高于文件副本要求。下面给出使用的例子：
hadoop fsck/
……Status：HEALTHY
Total size：511799225 B
Total dirs：10
Total files：22
Total blocks（validated）：22（avg.block size 23263601 B）
Minimally replicated blocks：22（100.0%）
Over-replicated blocks：0（0.0%）
Under-replicated blocks：0（0.0%）
Mis-replicated blocks：0（0.0%）
Default replication factor：3
Average block replication：3.0
Corrupt blocks：0
Missing replicas：0（0.0%）
Number of data-nodes：4
Number of racks：1
The filesystem under path'/'is HEALTHY
fsck会递归遍历文件系统的Namespace，从文件系统的根目录开始检测它所找到的全部文件，并在它验证过的文件上标记一个点。要检查一个文件，fsck首先会检索元数据中文件的块，然后查看是否有问题或是否一致。这里需要注意的是，fsck验证只和NameNode通信而不和DataNode通信。
以下是几种fsck的输出情况。
（1）Over-replicated blocks
Over-replicated blocks用来指明一些文件块副本数超出了它所属文件的限定。通常来说，过量的副本数存在并不是问题，HDFS会自动删除多余的副本。
（2）Under-replicated blocks
Under-replicated blocks用来指明文件块数未达到所属文件要求的副本数量。HDFS也会自动创建新的块直到该块的副本数能够达到要求。可以通过hadoop dfsadmin-metasave命令获得正在被复制的块信息。
（3）Misreplicated blocks
Misreplicated blocks用来指明不满足块副本存储位置策略的块。例如，假设副本因子为3，如果一个块的所有副本都存在于一个机器中，那么这个块就是Misreplicated blocks。针对这个问题，HDFS不会自动调整。我们只能通过手动设置来提高该文件的副本数，然后再将它的副本数设置为正常值来解决这个问题。
（4）Corrupt blocks
Corrupt blocks用来指明所有的块副本全部出现问题。只要块存在的副本可用，它就不会被报告为Corrupt blocks。NameNode会使用没有出现问题的块进行复制操作，直到达到目标值。
（5）Missing replicas
Missing replicas用来表明集群中不存在副本的文件块。
Missing replicas及Corrupt blocks被关注得最多，因为出现这两种情况意味着数据的丢失。fsck默认不去处理那些丢失或出现问题的文件块，但是可以通过命令使其执行以下操作：
通过-move，将出现问题的文件放入HDFS的/lost+found文件夹下。
通过-delete选项将出现问题的文件删除，删除后即不可恢复。
3.找到某个文件的所有块
fsck提供一种简单的方法用于查找属于某个文件的所有块，代码如下：
hadoop fsck/user/admin/In/hello.txt-files-blocks-racks
/user/admin/In/hello.txt 13 bytes，1 block（s）：OK
0.blk_-8114668855310504639_1056 len=13 repl=1[/default-rack/127.0.0.1：50010]
Status：HEALTHY
Total size：13 B
Total dirs：0
Total files：1
Total blocks（validated）：1（avg.block size 13 B）
Minimally replicated blocks：1（100.0%）
Over-replicated blocks：0（0.0%）
Under-replicated blocks：0（0.0%）
Mis-replicated blocks：0（0.0%）
Default replication factor：1
Average block replication：1.0
Corrupt blocks：0
Missing replicas：0（0.0%）
Number of data-nodes：1
Number of racks：1
The filesystem under path'/user/admin/In/hello.txt'is HEALTHY
从以上输出中可以看到：文件hello.txt由一个块组成，并且命令也返回了它所在的DataNode。fsck的选项如下：
-files，显示文件的文件名称、大小、块数量及是否可用（是否存在丢失的块）；
-blocks，显示每个块在文件中的信息，一个块用一行显示；
-racks，展示了每个块所处的机架位置及DataNode的位置。
运行fsck命令，如果不加选项，则执行以上所有指令。
4.DataNode块扫描任务
每个DataNode都会执行一个块扫描任务，它会周期性地验证它所存储的块，这就允许有问题的块能够在客户端读取时被删除或修整。DataBlockScanner可维护一个块列表，它会一个一个地扫描这些块，并进行校验和验证。
进行块验证的周期可以通过dfs.DataNode.scan.period.hours属性值来设定，默认为504小时，即3周。出现问题的块将会被报告给NameNode进行处理。
也可以通过访问DataNode的Web接口获得块验证的信息：http：//datanodeIP：50075/block ScannerReport。下面是一个报告的样本。
Total Blocks：32
Verified in last hour：1
Verified in last day：1
Verified in last week：12
Verified in last four weeks：31
Verified in SCAN_PERIOD：31
Not yet verified：1
Verified since restart：2
Scans since restart：2
Scan errors since restart：0
Transient scan errors：0
Current scan rate limit KBps：1024
Progress this period：8%
Time left in cur period：99.96%
通过附加后缀listblocks（http：//datanodeIP：50075/blockScannerReport?listblocks），报告会在前面这个DataNode中加入所有块的最新验证状态信息。
5.均衡器（balancer）
由于HDFS不间断地运行，隔一段时间可能就会出现文件在集群中分布不均匀的情况。一个不平衡的集群会影响系统资源的充分利用，所以我们要想办法避免这种情况。
balancer程序是Hadoop的守护进程，它会通过将文件块从高负载的DataNode转移到低使用率的DataNode上，即进行文件块的重新分布，以达到集群的平衡。同时还要考虑HDFS的块副本分配策略。balancer的目的是使集群达到相对平衡，这里的相对平衡是指每个DataNode的磁盘使用率和整个集群的资源使用率的差值小于给定的阈值。我们可以通过这样的命令运行balancer程序：start-balancer.sh。-threshold参数设定了多个可以接受的集群平衡点。超过这个平衡预置就要进行平衡调整，对文件块进行重分布。这个参数值在大多数情况下为10%，当然也可通过命令行设置。balancer被设计为运行于集群后台中，不会增加集群运行负担。我们可以通过参数设置来限制balancer在执行DataNode之间的数据转移时占用的带宽资源。这个属性值可以通过hdfs-site.xml配置文件中的dfs.balance.bandwidthPerSec属性进行修改，默认为1MB。
10.3 Hadoop集群的维护
 10.3.1 安全模式
当NameNode启动时，要做的第一件事情就是将映像文件fsimage加载到内存，并应用edits文件记录编辑日志。一旦成功重构和之前文件系统一致且居于内存的文件系统元数据，NameNode就会创建一个新的fsimage文件（这样就可以更高效地记录检查点，而不用依赖于Secondary NameNode）和一个空的编辑日志文件。只有全部完成了这些工作，NameNode才会监听RPC和HTTP请求。然而，如果NameNode运行于安全模式下，那么文件系统只能对客户端提供只读模式的视图。
文件块的位置信息并没有持久化地存储在NameNode中，这些信息都存储在各DataNode中。在文件系统的常规操作期间，NameNode会在内存中存储一个块位置的映射。在安全模式下，需要留给DataNode一定的时间向NameNode上传它们存储块的列表，这样NameNode才能获得充足的块位置信息，才会使文件系统更加高效。如果NameNode没有足够的时间来等待获取这些信息，那么它就会认为该块没有足够的副本，进而安排其他DataNode复制。这在很多情况下显然是没有必要的，还浪费系统资源。在安全模式下，NameNode不会处理任何块复制和删除指令。
当最小副本条件达到要求时，系统就会退出安全模式，这需要延期30秒（这个时间由dfs.safe-mode.extension属性值确定，默认为30，一些小的集群（比如只有10个节点），可以设置该属性值为0）。这里所说的最小副本条件是指系统中99.9%（这个值由dfs.safemode.threshold.pct属性确定，默认为0.999）的文件块达到dfs.replication.min属性值所设置的副本数（默认为1）。
当格式化一个新的HDFS时，NameNode不会进入安全模式，因为此时系统中还没有任何文件块。
使用以下命令可以查看NameNode是否已进入安全模式：
hadoop dfsadmin-safemode get
Safe mode is ON
在有些情况下，需要在等待NameNode退出安全模式时执行一些命令，这时我们可以使用以下命令：
hadoop dfsadmin-safemode wait