该模型将初始化为Seq2Seq类的实例，该类的构造函数参数为：
    batch_size：一个批量中包含的样本数
    embed_size：嵌入空间的维度（应小于词汇量）
    hidden_size：lstm中隐藏状态的数量
    num_layers：lstm构造块的数量
    checkpoints：检查点目录的路径
    std_factor：用于定义模型阈值的stds数
    dropout：每个元素被保留的概率
    vocab：Vocabulary对象
之后，初始化自编码器的各个层。首先，来看看编码器的初始化：
    # Encoder
      cells = [self._lstm_cell(args['hidden_size']) for _ in range(args['num_layers'])]
      multilstm = tf.contrib.rnn.MultiRNNCell(cells, state_is_tuple=True)
      _, enc_state = tf.nn.dynamic_rnn(
          multilstm,
          enc_embed_input,
          sequence_length=self.lengths,
          swap_memory=True,
          dtype=tf.float32)
然后，看看解码器的初始化：
    # Decoder
    output_lengths = tf.reduce_sum(tf.to_int32(tf.not_equal(self.targets, 1)), 1)
    helper = tf.contrib.seq2seq.TrainingHelper(
        dec_embed_input,
        output_lengths,
        time_major=False)
    cells = [self._lstm_cell(args['hidden_size']) for _ in range(args['num_layers'])]
    dec_cell = tf.contrib.rnn.MultiRNNCell(cells, state_is_tuple=True)
    decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell, helper, enc_state)
    dec_outputs = tf.contrib.seq2seq.dynamic_decode(
        decoder,
        output_time_major=False,
        impute_finished=True,
        maximum_iterations=self.max_seq_len, swap_memory=True)
由于我们要解决的问题是异常检测，因此目标值和输入值是相同的。因此，我们的feed_dict会是下面的样子：
    feed_dict = {
      model.inputs: X,
      model.targets: X,
      model.lengths: L,
      model.dropout: self.dropout,
      model.batch_size: self.batch_size,
      model.max_seq_len: seq_len}
每训练一轮之后，最佳模型都被保存为检查点，这样一来，完成训练后，就可以通过加载相应的检查点来进行预测了。为了进行测试，我们建立了一个实时Web应用程序，并使用我们的模型为其提供保护，这样就可以测试真实攻击是否成功。
受注意力机制效果的鼓舞，我们尝试将其应用于自编码器，结果发现，从最后一层输出的概率能更好地找出给定请求的异常部分。
在我们的样品测试阶段，得到了非常好的结果：精确率和召回率都接近0.99。ROC曲线直接奔1而去。这看起来棒极了！
最终代码可以从这里[下载](https://github.com/PositiveTechnologies/seq2seq-web-attack-detection "下载")。
**测试结果**
* * *
实验结果证明，我们提出的Seq2Seq自编码器模型能够高精度地检测HTTP请求中的异常部分。
这个模型的工作方式更像人类：它只学习对Web应用程序而言是“正常”的用户请求。它能够检测请求中的异常部分，并突出显示请求中被视为异常部分的确切位置。我们利用针对测试应用程序的一些攻击数据对该模型的性能进行了评估，结果让人倍受鼓舞。例如，上图描绘了我们的模型如何检测到SQL注入分为两个Web表单参数。这种SQL注入技术被称为“分段化”，即攻击的有效载荷部分通过若干HTTP参数进行传递，这使得传统的、基于规则的WAF难以检测出这种情况，因为它们通常单独地检查每个参数。另外，我们的模型代码和训练/测试数据是以Jupyter笔记本的形式进行发布的，因此，任何人都可以重现我们的结果并提出改进建议。
**总结与展望**
* * *
当然，这里仍有许多不足之处有待改进。
首先，第一个问题是尝试对攻击进行分类。我们不妨回顾一下人类专家是如何发现网络攻击的：首先，他会注意到一些异常的事实，然后，他会开始推理，如果这是网络攻击的话，那么是什么类型的攻击。我们的模型能够完成第一步，它会在请求中查找异常序列。既然我们已经将所有重要的异常数据压缩为小型的字符序列，使得所有特定于应用程序的请求部分看起来都不像异常数据，那么，如果我们尝试在其上运行分类器的话，结果会如何呢？这看起来可以重现人类推理的第二步，即我们正在处理的攻击属于哪种类型。
第二个问题是可以用来逃避这种检测方法的对抗性示例。近年来，涌现出许多对抗性ML的研究论文，研究表明，人们能够让模型“看到”他们想要它看到的任何东西。显然，如果夏娃试图逃避我们的检测模型，那么，她可能会想出一些对抗技术来达到目的。
第三个问题是性能。现在，在两个GPU上训练我们的小数据集都需要几天时间，所以，目前根本不具备可扩展性。
尽管如此，我们仍然认为这项工作提出了一种有趣的方法来构建用于检测Web应用程序攻击的模型。在本研究中，最重要的贡献之一是试图以无人监督但具备可解释性的方式来模仿人类专家的推理过程。值得注意的是，我们可以清楚地看到这项研究将来的发展步骤，而且每一步都是非常合理，并极可能实现的。我们希望这项工作能够激发其他团队和研究人员对于深度学习在安全攻击检测方面的兴趣，并热切期待能够与他们进行广泛深入的合作。
**参考资料**
* * *
[1][ Understanding LSTM
networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/ "
Understanding LSTM networks")
[2] [Attention and Augmented Recurrent Neural
Networks](https://distill.pub/2016/augmented-rnns/ "Attention and Augmented
Recurrent Neural Networks")
[3] [Attention is all you need](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html "Attention is all you need")
[4][ Attention is all you need
(annotated)](https://nlp.seas.harvard.edu/2018/04/03/attention.html "
Attention is all you need \(annotated\)")
[5] [Neural Machine Translation (seq2seq)
Tutorial](https://github.com/tensorflow/nmt "Neural Machine Translation
\(seq2seq\) Tutorial")
[6]
[Autoencoders](http://ufldl.stanford.edu/tutorial/unsupervised/Autoencoders/
"Autoencoders")
[7] [Sequence to Sequence Learning with Neural
Networks](https://arxiv.org/abs/1409.3215 "Sequence to Sequence Learning with
Neural Networks")
[8] [Building autoencoders in Keras](https://blog.keras.io/building-autoencoders-in-keras.html "Building autoencoders in Keras")