to predict the sender’s signal.
out sensitive information to a partition that
is not allowed
to obtain it through authorized channels. In this section, we
show how hierarchical scheduling can be exploited by real-time
partitions to create such a hidden information ﬂow. As shown
in Fig. 2, a sender partition tries to transmit a binary signal (0
or 1) by modulating the way it consumes its budget depending
on each signal. The sender’s varying behavior affects how/when
the receiver partition consumes its budget. The receiver decodes
its local observation to infer the sender’s signal. The presence
of other partitions, which share the CPU time with the sender
and receiver, induces errors in the receiver’s interpretation.
a) Strategy and pre-conditions: Fig. 3 illustrates a strat-
egy for forming a covert timing channel between real-time
partitions. The sender and receiver partitions have an agreed-
upon time at which they start the proﬁling phase, during which
the sender sends bits 0 and 1 alternately. When the sender wants
to signal bit 1, it uses up its budget. Otherwise, it consumes its
budget as little as possible. Meanwhile, the receiver observes
how its local tasks execute. Unlike the mechanism used in [11]
that requires coordination between two local tasks (as shown
in Fig. 18 in Sec. V-C), a single task of the receiver partition
measures times it takes to execute a block of code, i.e., response
times (from arrival to ﬁnish). Hence, if it observes a relatively
long response time, the sender partition has likely consumed
its budget and thus has signaled bit 1. They may even form
a multi-bit channel by dividing the response time range into
multiple levels. Furthermore, the receiver could instead collect
richer information about its execution (e.g., Fig. 4(b)) and apply
a machine learning method, as will be explained shortly.
Although it is easy to coordinate the start time, their execution
frequencies should be chosen in consideration of the budget con-
straints. Suppose that the replenishment periods of the sender
and receiver partitions are TS and TR, respectively, where
TS  Pr(R = r|X = 1).
Pr(R|X)·Pr(X)
d) Learning-based approach: As an alternative ap-
proach, we also present a learning-based scheme that learns
patterns of when the receiver executes. For this, the receiver
divides its monitoring window into M micro intervals and
monitors if it was able to use the CPU during the ith interval.
Speciﬁcally, for each monitoring window, an execution vector,
v = (v1, v2, . . . , vM ), is created, where each vi is set to 1 if
the receiver executed during the ith interval, or 0 otherwise.
The receiver collects a training set through the proﬁling phase.
Each of the execution vectors in the training set is labeled as
either 0 or 1 (i.e., sender’s signal). Fig. 4(b) shows the 0/1
heatmap of execution vectors of length M = 150 collected over
500 monitoring windows. The receiver can apply a supervised
learning method (e.g., Support Vector Machine, Random Forest)
to train a model that can predict the sender’s signal given a
newly-observed execution vector in the communication phase.
e) Motivating scenario: To exemplify a scenario in which
real-time partitions can communicate over the covert timing
channel explained above, we deployed an implementation of
the techniques on an experimental 1/10th-scale self-driving car
platform composed of 4 partitions as shown in Fig. 5. We
chose a Linux-based RTOS, LITMUSRT [19], as the hierar-
chical scheduler because Linux-based RTOSes are increasingly
adopted by high-end real-time systems. The local real-time
tasks run as ROS (Robot Operating System) [25] nodes. Hence,
explicit inter-partition communication is only allowed through
the ROS’ publish-subscribe channels over TCP/IP, which can
easily be monitored. The vision-based steering control (Π2)
publishes a steering command, and the path planner (Π3), which
computes a series of waypoints from the current position to a
destination, publishes a navigation command, both of which are
subscribed by the top-level behavior controller (Π1) to compute
and send out a driving command to the actuators. These data
are also sent to the logging partition (Π4) for post-debugging.
However, the precise location, which is a sensitive data item
processed by the planner (Π3), is not published to any partition.
Now, using the prototype system, we consider a scenario
in which an ill-intentioned system operator collects the trace
of the vehicle’s precise location by leaking it out from the
path planning partition (Π3) to the logging partition (Π4)
Application
Behavior control
Vision-based steering
Path planning
Data logging
Ti
10 ms
20 ms
30 ms
50 ms
Bi
1 ms
10 ms
3 ms
5 ms
Π1
Π2
Π3
Π4
Fig. 5: Prototype 1/10th-scale self-driving car platform.
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:27:56 UTC from IEEE Xplore.  Restrictions apply. 
455
over a covert channel. For this, we applied the learning-based
technique presented above. In particular, the planning task in
Π3 uses the period of 50 ms and modulates its execution
length every three arrivals. At the receiver task in Π4, we
collected 3000 samples for training and evaluated its accuracy
against 2000 test samples. Under this setting, the pair was able
to achieve channel accuracy of 95.23%. However, it should
be noted that an engineering effort would be required when
applying these techniques to a full-scale system because it
would create a higher level of channel noise. This demonstration
highlights that systems that employ priority-based hierarchical
scheduling can be vulnerable to covert timing channels.
f) Feasibility test: To show the feasibility of the scenarios
presented above in a general setting, we run an example system
of ﬁve synthetic partitions, Π = {Πi : 1 ≤ i ≤ 5}, on the
same platform. The parameters are shown in Table I in Sec. V.
The partitions are assigned different replenishment periods to
represent various base-rate groups and also to remove potential
bias due to the particular selection of the periods. Each partition
is assigned a budget of size Bi = 0.16Ti, hence the total CPU
utilization equals 80%. Π2 is the sender and Π4 is the receiver.
The tasks in the other three partitions create unpredictable noise
on the channel by varying their periods and execution times
randomly (by up to 20%).
The receiver task measures its response time every 150 ms
(i.e., 3 · T4) and thus executes a code block that would take
three full budget-replenishments of Π4 in the worst-case. The
sender partition consumes its budget as much (resp. little) as
possible for three consecutive times to signal bit 1 (resp. 0).
Fig. 4(c) shows that under this setting, the accuracy of the
covert channel reaches about 95.7%. Also, such a high accuracy
can be achieved without requiring a large number of samples
for proﬁling. Higher accuracy can be achieved if the system is
lightly loaded and thus creates less noise on the channel. We
performed a similar experiment as the base setting above but
with a half utilization: partition budgets and task execution times
are cut by half. As shown in Fig. 4(c), the channel achieves
98.6% accuracy. In fact, as will be shown in later sections, our
solution is more effective in such a scenario that is advantageous
to the adversary.
We also evaluated the learning-based approach. Upon collect-
ing a training set of execution vectors, the receiver applies the
Support Vector Machine (SVM) [26] with Radial Basis Function
kernel to train a classiﬁer that can predict the sender’s signal
from an execution vector of the receiver. The learning-based
approach achieves improved accuracy for both conﬁgurations,
as shown in Fig. 4(c) ((cid:3) markers). This is because an execution
vector embeds more information than a response time; in fact,
the latter can be derived from the former.
g) Adversary model: We assume any partition can be
malicious and able to control the timing of its local tasks pre-
cisely. For instance, tasks can be launched at precise times using
facilities originally intended to manage precedence constraints
among tasks and to align task arrivals with certain events such
as periodic retrieval of sensor data. With such capabilities, the
adversary can maximize the chance for successful communi-
cation over the covert channel. In addition, we do not address
microarchitectural timing channels [27]–[29]. The algorithmic
timing channel addressed in this paper can exist even if the
microarchitectural timing channels were completely removed.
h) Objective of the paper: The covert timing channel
presented above can be removed by a static time partitioning,
such as the table-driven scheduling in IMA (Integrated Modular
Avionics) architecture of ARINC 653 standard [1], because no
two partitions can be active at any given instant. However, as
studied in [11], [14], static partitioning schemes suffer from low
CPU utilization. To remove the covert timing channel between
non-static time partitions, (physical) time passage due to one’s
execution must not be observable by another. BLINDER [11]
is based on a strong assumption that all sources of physical
time are removed. However, in modern computer systems, many
precise time sources are available, and hence it is difﬁcult to
eliminate every source of physical time. The goal of this paper is
thus to reduce the capacity of the covert timing channel between
real-time applications that (i) are dynamically partitioned and
(ii) run in an environment where it is impossible to eliminate
every source of physical time, (iii) while guaranteeing the real-
time requirements (i.e., schedulability) of the partitions.
IV. SCHEDULABILITY-PRESERVING PARTITION SCHEDULE
RANDOMIZATION
The covert timing channel presented in Sec. III is made
possible by the priority relation between the sender and receiver
partitions — the former, who has a higher priority, can affect the
latter’s execution in whatever way it wants. Hence, our solution,
the TIMEDICE algorithm, is to invert the relationship randomly
on the ﬂy while preserving the partition-level schedulability;
partitions are schedulable (Deﬁnition 1) if they were so before
any randomization. Fig. 6 shows actual schedule traces for an
example conﬁguration when (a) partitions are scheduled by a
ﬁxed-priority policy (i.e., no randomization) and (b) they are
randomized by TIMEDICE during run-time.
A. TIMEDICE Algorithm
The TIMEDICE algorithm picks a partition in a non-
deterministic way instead of selecting the highest-priority par-
tition. This priority inversion, however, could make some parti-
tions unschedulable (i.e., missing their deadlines, thus under-
using their budgets) if the candidates are chosen in an un-
principled way. Nonetheless, partition schedule should not be
conservatively randomized. Hence, the key challenge lies in
determining (a) which partitions are allowed to execute, and
(b) how long a priority inversion is allowed. The TIMEDICE
algorithm, shown in Algorithm 1, consists of two steps: (i)
candidate search, which forms a list of candidate partitions
(cid:4)(cid:1)(cid:2)(cid:3)
(cid:5)(cid:1)(cid:2)(cid:3)
(cid:6)(cid:1)(cid:2)(cid:3)
(cid:7)(cid:1)(cid:2)(cid:3)
(cid:8)(cid:1)(cid:2)(cid:3)
(cid:9)(cid:1)(cid:2)(cid:3)
(cid:10)(cid:1)(cid:2)(cid:3)
(cid:11)(cid:1)(cid:2)(cid:3)
(cid:12)(cid:1)(cid:2)(cid:3)
(cid:4)(cid:1)(cid:1)(cid:2)(cid:3)
(cid:4)(cid:4)(cid:1)(cid:2)(cid:3)
(cid:4)(cid:5)(cid:1)(cid:2)(cid:3)
(cid:4)(cid:6)(cid:1)(cid:2)(cid:3)
(cid:4)(cid:7)(cid:1)(cid:2)(cid:3)
(cid:4)(cid:8)(cid:1)(cid:2)(cid:3)
(cid:4)(cid:9)(cid:1)
(a) Without TIMEDICE.
(cid:4)(cid:1)(cid:2)(cid:3)
(cid:5)(cid:1)(cid:2)(cid:3)
(cid:6)(cid:1)(cid:2)(cid:3)
(cid:7)(cid:1)(cid:2)(cid:3)
(cid:8)(cid:1)(cid:2)(cid:3)
(cid:9)(cid:1)(cid:2)(cid:3)
(cid:10)(cid:1)(cid:2)(cid:3)
(cid:11)(cid:1)(cid:2)(cid:3)
(cid:12)(cid:1)(cid:2)(cid:3)
(cid:4)(cid:1)(cid:1)(cid:2)(cid:3)
(cid:4)(cid:4)(cid:1)(cid:2)(cid:3)
(cid:4)(cid:5)(cid:1)(cid:2)(cid:3)
(cid:4)(cid:6)(cid:1)(cid:2)(cid:3)
(cid:4)(cid:7)(cid:1)(cid:2)(cid:3)
(cid:4)(cid:8)(cid:1)(cid:2)(cid:3)
(cid:4)(cid:9)(cid:1)
Fig. 6: Actual schedule trace for a 3-partition example.
(b) With TIMEDICE.
(cid:12)(cid:12)(cid:1)
(cid:2)(cid:3)(cid:18)
(cid:12)(cid:12)(cid:6)
(cid:2)(cid:3)(cid:18)
(cid:12)(cid:12)(cid:9)
(cid:2)(cid:3)(cid:18)
(cid:1)(cid:5)(cid:5)
(cid:2)(cid:3)(cid:18)
(cid:1)(cid:6)(cid:1)
(cid:2)(cid:3)(cid:18)
(cid:1)(cid:6)(cid:6)
(cid:2)(cid:3)(cid:18)
(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:3)(cid:1)(cid:3)(cid:1)(cid:2)(cid:1)(cid:3)(cid:1)(cid:3)(cid:1)(cid:4)(cid:1)(cid:2)(cid:1)(cid:4)(cid:1)(cid:3)
(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:3)(cid:1)(cid:3)(cid:1)(cid:2)(cid:1)(cid:3)(cid:1)(cid:3)(cid:1)(cid:4)(cid:1)(cid:2)(cid:1)(cid:4)(cid:1)(cid:3)
(cid:1)(cid:2)(cid:3)
(cid:6)
(cid:3)(cid:18)
(cid:9)
(cid:3)(cid:18)
(cid:12)
(cid:3)(cid:18)
(cid:5)
(cid:3)(cid:18)
(cid:8)
(cid:3)(cid:18)
(cid:11)
(cid:3)(cid:18)
(cid:1)(cid:2)(cid:3)
Authorized licensed use limited to: Tsinghua University. Downloaded on August 07,2022 at 13:27:56 UTC from IEEE Xplore.  Restrictions apply. 
456
Algorithm 1: TimeDice(Π, t)
Lt = (Π(1), Π(2), . . . ,Π (n), ΠIDLE ) // active partitions
Step 1 – Candidate Search
LC ← {Π(1)}