of several hundred hosts, as shown in [8]. In this paper, we eval-
uate the speed of the second phase.
B. Simulation Methodology
We consider the following dimensions for simulation.
(cid:129) Topology type: We experiment with three types of BRITE
[24] router-level topologies—Barabasi–Albert, Waxman,
and hierarchical models—as well as with a real router
topology with 284 805 nodes [9].
(cid:129) Topology size: the number of nodes ranges from 1000 to
20 000. This node count includes both internal nodes (i.e.,
routers) and end-hosts.
(cid:129) Fraction of end-hosts on the overlay network: We deﬁne
end-hosts to be the nodes with the least degree. We then
choose 50 to 300 end-hosts at random to be on the overlay
network. We prune the graphs to remove the nodes and
links that are not referenced by any path on the overlay
network.
(cid:129) Link loss rate distribution: 95% of the links are classi-
ﬁed as “good” and the rest as “bad.” We focus on di-
rected graphs, so the bidirectional links between a pair of
nodes are assigned separate loss rates. We use two different
models for assigning loss rate to links, as in [5]. In the ﬁrst
, the loss rate for good links is selected
model
uniformly at random in the 0%–0.2% range and the rate for
bad links is chosen in the 5%–10% range. In the second
model
, the loss rate ranges for good and bad
links are 0%–0.2% and 0.2%–100%, respectively. Given
space limitations, most results discussed are under model
except for Section VI-C4.
(cid:129) Loss model: After assigning each directional link a loss
rate, we use either a Bernoulli or Gilbert model to simulate
the loss processes at each link in the same manner as in [5]
and [8]. The Gilbert model is more likely to generate bursty
losses than the Bernoulli model. The state transition proba-
bilities are selected so that the average loss rate matches the
loss rate assigned to the link. We found that the results for
the Bernoulli and the Gilbert models are similar. Since the
Gilbert loss model is more realistic, all results presented in
the paper are based on this model.
We repeated our experiments ﬁve times for each simulation
conﬁguration unless noted otherwise, where each repetition has
a new topology and new loss rate assignments. The path loss
rate is simulated based on the transmission of 10 000 packets.
Using the loss rates of selected paths as input, we compute
then the loss rates of all the MILSs.
C. Simulation Results
In this section, we discuss the results of our simulations. For
all three types of synthetic topologies in our study, we found our
system had similar accuracy. Barabasi–Albert topologies have
the smallest MILSs, but also the shortest path lengths, while
hierarchical topologies have both the longest MILSs and path
lengths. Barabasi–Albert topologies have the largest ratios of
1732
IEEE/ACM TRANSACTIONS ON NETWORKING, VOL. 17, NO. 6, DECEMBER 2009
Fig. 9. Accuracy of MILSs on lossy paths: (top) cumulative distribution of absolute errors and (bottom) error factors under the Gilbert model for various topologies.
diagnosis granularity to average path length, while hierarchical
topologies have the smallest such ratios. Thus, we only show the
Barabasi–Albert and hierarchical topology results and omit the
results of Waxman topology because of limited space.
1) Accuracy of MILSs: For all topologies in Section VI-B, we
achieved highly accurate estimates of the MILS loss rates. Since
our goal is to diagnose lossy paths, we evaluate the accuracy of
the estimates of loss rates only for MILSs on the lossy paths.
The results are even better when we consider the MILSs on all
paths.
We plot the cumulative distribution functions (cdfs) of abso-
lute errors and error factors with the Gilbert model in Fig. 9.
The results on Waxman and hierarchical topologies are similar
to those on Barabasi–Albert topologies, and so we omit them in
the interest of space.
The errors come from the measurement noise and the approx-
imation of the good path algorithm. The accumulated error is a
potential problem for inference in a large network. However, our
simulation results show it is not severe at all in our system. For
all the conﬁgurations, 90% of the absolute errors are less than
0.006, and 90% of the error factors are less than 1.6. This shows
that errors introduced by the good path algorithm and measure-
ments do not accumulate in the matrix computations.
2) Granularity of MILSs: Table II shows the granularity of
MILSs and related statistics under hierarchical BRITE topolo-
gies and the real-world Mercator topology. We ﬁrst prune the
topology so that it only contains the links on the paths among the
random selected end-hosts. Then, we merge the links without
branching points into one virtual link. We select a basis set
for monitoring, which is again much smaller than the total
number of paths. After that, we remove the good paths and good
links inferred from these good paths from and obtain
. The
number of lossy paths and the number of links in the lossy paths
, as shown in this table. The loss rate esti-
gives the size of
mation of MILSs is actually based on
about 30%–50% of the size of
of
.
, of which the size is
for the loss rate distribution
The MILS identiﬁcation and loss rate calculation are based
on virtual links to reduce the computational cost. Thus, the
length of lossy paths and MILSs in the rightmost two columns
of Table II are computed based on virtual links. The average
lengths in terms of physical links are given in parentheses. The
average length of the MILSs is quite small, less than two virtual
links and less than three physical links. The last column of
Table II shows the diagnosis granularity in length of both virtual
links and links. Most diagnosis granularity is less than two
virtual links, which is quite close to the diagnosis upper bound
of pure end-to-end approaches (i.e., diagnosing every virtual
link). Clearly, the diagnosis granularity becomes ﬁner as more
hosts are employed. This shows that the granularity of MILSs is
very small, and we can effectively locate the congestion/failure
points.
3) Inﬂuencing Factors of the MILS Granularity: In this sub-
section, we study two factors that inﬂuence MILS length: the
size of overlay network and loss rate distributions of links.
Fig. 10 (top) shows the length of MILSs with different sizes
of overlay network under the Mercator topology and
loss rate distribution. Link merging in the ﬁgure means to merge
consecutive link sequences without branching into virtual links.
When the overlay network size is very small, less than 50, there
is not much path sharing, so the MILSs are long. With more
hosts and paths, sharing becomes signiﬁcant, and the MILSs are
dramatically shorter.
Fig. 10 (bottom) shows the lengths of MILSs for an overlay of
100 end-hosts under the Mercator topology with different per-
centage of links to be lossy links. Again, the loss rate distribution
is
. The lengths of the MILSs almost grow linearly with
the percentage of lossy links. Usually the percentage of lossy
ZHAO et al.: TOWARDS UNBIASED END-TO-END NETWORK DIAGNOSIS
1733
SIMULATION RESULTS FOR HIERARCHICAL BRITE TOPOLOGY AND A REAL ROUTER TOPOLOGY. OL MEANS THE OVERLAY NETWORK.
PL MEANS THE PATH LENGTH. NUMBER OF LINKS SHOWS THE NUMBER OF LINKS AFTER PRUNING (I.E., REMOVING THE NODES
AND LINKS THAT ARE NOT ON THE OVERLAY PATHS). NUMBER OF VLS (VIRTUAL LINKS) GIVES THE NUMBER OF LINKS
AFTER MERGING CONSECUTIVE LINKS WITHOUT BRANCHING POINT. LP STANDS FOR LOSSY PATHS.
THE RIGHTMOST FOUR COLUMNS ARE COMPUTED USING THE VIRTUAL LINKS AFTER MERGING.
THE CORRESPONDING LENGTH VALUES BEFORE MERGING ARE GIVEN IN THE PARENTHESES
TABLE II
model, but also with the
MILS is, the more likely it is to be lossy. Thus, the diagnosis
granularity may be larger than the average length of all MILSs.
4) Results for Different Link Loss Rate Distribution and Run-
ning Time: We have run all the simulations above not only with
model. The results
the
in the latter case are very similar to those of
, except that
with larger loss rates and the same percentage of lossy links, the
length of MILSs on the lossy paths has been increased by a bit.
Given space limitations, we only show the lossy path inference
with the Barabasi–Albert topology model and the Gilbert loss
model in Table III.
and
The running times for
are similar, as in
Table III. All speed results in this paper are based on a 3.2-GHz
Pentium 4 machine with 2 GB memory. Note that it takes about
45 min to setup (select the measurement paths) for an overlay
of 300 end-hosts, but less than 1 min for an overlay of size
100. Note that the setup only needs to run once, and there are
when there are
efﬁcient schemes to incrementally update
routing changes or adding/removing links [8]. Meanwhile, the
continuous monitoring, inference, and diagnosis are very fast,
for all cases. Even for the large overlay with 300 end-hosts,
89 700 paths, and more than 20 000 links, we can diagnose all
trouble spots within 1 min. This shows that we can achieve near
real-time diagnosis.
Fig. 10.
(bottom) different percentage of links as lossy links.
(top) Granularity of MILSs with different network sizes and
links in the Internet is very small—2% or even less. Therefore,
the lengths of the MILSs are very small, which we also verify
in the Internet experiment described in Section VII.
The average length of lossy MILSs is always higher than that
of good MILSs. This is not surprising because the longer the
5) Results for Dynamic Changes: Because routes change in
the Internet, and because end-hosts may join or leave the overlay
network, our monitoring system must allow for dynamic up-
dates. In this section, we describe two common scenarios: a
change to the routing or a new host that joins the overlay. We
show that the updates required by these changes can be ex-
pressed in terms of four primitive types of updates provided by
the LEND system. In Section IV-D, we analyze the complexity
of these updates. Here, we describe the performance of the up-
date algorithms in simulations with a real Internet topology [9].
Adding Nodes: We start with an overlay network of 90
random end-hosts. Then, we randomly add an end-host to join
the overlay, and repeat the process until the size of the overlay
1734
IEEE/ACM TRANSACTIONS ON NETWORKING, VOL. 17, NO. 6, DECEMBER 2009
SIMULATION RESULTS WITH MODEL LLRD USING BARABASI–ALBERT TOPOLOGIES
TABLE III
Fig. 11.
(left) Absolute error and (right) relative error factor of Gibbs sampling and LEND.
reaches 100. Averaged over three runs, the average running time
for adding a node is 0.21 s.
Routing Changes: Changes in network routing tables can
substantially change the paths between hosts in the overlay net-
work. To study the cost to update the LEND system after a
routing change, we created an overlay network with 100 ran-
domly chosen end-hosts. Then, we removed one of the links
used by the overlay and recomputed the routes. In order to up-
date the LEND system in this instance, we may require all four
of the primitive updates described in Section IV-D. Averaged
over three runs, the time to change a routing path (deleting one
path and adding a new one) is about 1.2 s. This time is com-
parable to the time to recompute all the matrices from scratch,
which is about 2.3 s. This is because the topology is relatively
small (only 100 end-hosts) and because we tuned the perfor-
mance of the initialization algorithm.
6) Comparison With Gibbs Sampling: In [5], Padmanabhan
et al. propose three statistical methods to infer the loss rate of
links using end-to-end measurement. We also implemented the
Gibbs sampling algorithm, which was shown to be the most ac-
curate approach in [5]. Note that in [5], the object is only to ﬁnd
out which virtual links are lossy; the method does not give an
estimate of the loss rate. We modiﬁed the algorithm to use the
average loss rate of all the samplings as the estimate of the loss
rate of the virtual links.
Fig. 11 shows the absolute and relative errors of the infer-
ence of virtual links or MILSs. In this experiment, we use the
real Mercator topology measured in [9] with Gilbert loss model
and
distribution. There are 50 end-hosts and, thus, 4950
paths in total. Fig. 11 clearly shows that the accuracy of MILSs
is much better than that of Gibbs sampling on virtual links. We
note that the false positives and false negatives in Gibbs sam-
pling are relatively frequent (about 10% in total), and thus for
.
some virtual links, the absolute error is quite high
Fig. 11 also shows that Gibbs sampling inference based on our
MILSs is more accurate than that based on end-to-end paths.
This may be because MILSs have ﬁner granularity and reduce
the interaction between identiﬁed MILSs in the inference. The
relative error factor results in Fig. 11 show the same trends we
see in the absolute errors. As for running speed, Gibbs sampling
based on the whole paths takes about ﬁve times longer than
Gibbs sampling based on the MILS set when using the same
running environment (i.e., the same machine and Matlab tool).
VII. INTERNET EXPERIMENTS
Shortest path routing is often violated in the Internet, a phe-
nomenon known as path inﬂation [25]. In addition, the loss be-
havior of real links may be more complicated than the behavior
in synthetic models. Therefore, we deployed and evaluated our
LEND system on the PlanetLab [26], and we discuss our results
in this section.
A. Methodology
We deployed our monitoring system on 135 PlanetLab hosts
around the world (see Table IV). Each host is from a different
institution. About 60% of the hosts are in US, and the others are
located mostly in Europe and Asia. There are altogether
end-to-end paths among these end-hosts. In our
experiments, we measured all the paths for validation. However,
in practice, we only need to measure the basis set of on average
5706 end-to-end paths. The measurement load can be evenly
distributed among the paths with the technique in [8] so that
each host only needs to measure about 42 paths.
First, we measured the topology among these sites by simul-
taneously running “traceroute” to ﬁnd the paths from each host
to all others. Each host saves its destination IP addresses for
sending measurement packets later. Then, we measured the loss
rates between each pair of hosts. Our measurement consists of
ZHAO et al.: TOWARDS UNBIASED END-TO-END NETWORK DIAGNOSIS
1735
DISTRIBUTION OF SELECTED PLANETLAB HOSTS
TABLE IV
TABLE V
INTERNET EXPERIMENT RESULTS. THE LAST TWO ROWS ARE COMPUTED
USING THE VIRTUAL LINKS. THE CORRESPONDING LENGTH VALUE
USING PHYSICAL LINKS ARE GIVEN IN THE PARENTHESIS
300 trials, each of which lasts 300 ms. During a trial, each host
sends a 40-byte UDP packet to every other host. The packet con-
sists of 20-byte IP header, 8-byte UDP header, and 12-byte data
on sequence number and sending time. For each path, the re-
ceiver counts the number of packets received out of 300 to cal-
culate the overall loss rate. We used the sensitivity test similar
to that of [8] to choose these parameters so that measurement
packets will not cause additional congestion.
To prevent any host from receiving too many packets simul-
taneously, each host sends packets to other hosts in a different
random order. Furthermore, any single host uses a different per-
mutation in each trial so that each destination has equal op-
portunity to be sent later in each trial. This is because when
sending packets in a batch, the packets sent later are more likely
to be dropped than received. Such random permutations are pre-
generated by each host. To ensure that all hosts in the network
take measurements at the same time, we set up sender and re-
ceiver daemons, then use a well-connected server to broadcast
a “START” command.
B. Experiment Results
In April 2005, we ran the experiments 10 times at different
times of night and day. We report the average results from the
10 experiments.
1) Granularity of MILSs and Diagnosis: Of the
end-to-end paths, 65.5% were good paths, and these
paths contained about 70.5% of the links. After removing good
paths, only 6450 paths remained. The average length of lossy
MILSs on these bad paths is 3.9 links or 2.3 virtual links (see
Table V).
The diagnosis granularity of lossy paths is a little high:
3.8. However, we believe this is reasonable and acceptable for