SMARTS 
3.84%
3.03%
7.77%
2.76%
61.44%
32.24%
68.17%
286.06%
1.77 
4.85 
2.23 
7.02 
1.41 
3.37 
2.77 
1.15 
0.068 
0.147 
0.173 
0.194 
0.866 
1.087 
1.888 
3.290 
are unlikely  to cause significant  changes in FIT estimation. 
Note that all results shown in this paper were gathered with 
seed=1.  
CV  estimation:  We  estimated  the  CV  with  a  range  of 
sampling rates from 1% to 20%. The variations in estimated 
CVs  differ  only  by  3%  on  average.  We  conclude  that 
profiling can be efficiently done from sampling experiments 
(even  with  a  sampling  rate  lower  than  10%)  without 
introducing significant bias in the estimation of the CV. CV 
estimation  error  can  easily  be  compensated  by  simply 
increasing  estimated  CV  by  3%,  as  higher  CV  guarantees 
higher sampling rate which again guarantees lower sampling 
bias. 
Effect of cache size variations: Table III shows the average 
FIT  errors  and  slowdowns  of  various  sampling  schemes 
with  256KB,  1MB  and  4MB  UL2  cache.  LIM-2X  for  a 
4MB  cache  has  very  small  FIT  errors  because  the  data 
structure  has  an  8MB  memory  footprint.  Due  to  the  larger 
memory  footprint  unfortunately  the  slowdown  balloons  to 
64.98. FIT errors increase both in SimPoint and SMARTS-
INT  when  the  size  of  L2  increases.  For  most  benchmarks 
the  distribution  of VCs  changes  dramatically  with different 
cache  sizes,  but  the  CPI  variance  or  the  basic  block 
execution  sequence  does  not  vary  significantly.  By 
capturing  the  changes  in  VC  distribution  accurately  PHYS 
estimates the FIT well across all cache sizes. 
VI.  SUMMARY OF RESULTS  
Table IV summarizes and compares the results obtained 
from various schemes explored in this paper. The FIT error 
column  gives  the  FIT  estimation  error  for  SDCs  of  an 
unprotected  cache  due  to  sampling.  In  the  last  column,  we 
show  the  rank  order  of  all  schemes  based  on  FIT  error 
multiplied  by  the  slowdown  factor,  sorted  in  ascending 
order.  Hybrid,  set  and  interval  samplings  with  10% 
sampling  rates  have  good  balance  between  FIT  error  and 
slowdown  and  all  three  schemes  perform  equally  well 
according  to  the  metric.  LIM-0.2X  and  SMARTS  have 
fairly  high  FIT  errors.  SimPoint  with  one  50M  detailed 
instruction  window has lower  FIT  error  than  SMARTS  but 
the  error  is  still  significantly  higher  than  any  of  our 
proposed  sampling  approaches.  In  summary,  PHYS  shows 
the best result – the average FIT error is under 4% and the 
slowdown is around 2 in all cases.  
Last  but  not  least,  PHYS  is  the  only  scheme  that 
provides statistical confidence on the FIT estimate. 
Model 
AVF (SBU/NA) 
SDC FIT 
SimPoint-
100M 
198.9 
PHYS 
155.5 
PARMA (SBU/SECDED) 
6.7E-30 
2.1E-28 
PHYS 
Sampling 
Rate 
0.07% 
3.93% 
MACAU 
(spatial 3BU/TECQED) 
7.0E-17 
7.7E-16 
7.35% 
VII.  SIMULATIONS OF FULL SPEC2K SUITE 
We  show  the  profiling  and  simulation  results  for  the 
entire SPEC 2K suite with the reference input sets in Table 
V.  Here  we  consider  not  only  AVF  but  also  PARMA  and 
MACAU  reliability  simulations.    For  the  AVF  model,  we 
estimate  the  SDC  FIT  rate  due  to  SBUs  in  an  unprotected 
cache.  For  the  PARMA  model,  we  estimate  the  SDC  FIT 
rate due to temporal MBUs caused by SBUs in a SECDED 
protected  cache.  For  the  MACAU  model,  we  estimate  the 
SDC  FIT  rate  due  to  spatial  MBUs  with  up  to  3BUs  in  a 
Triple  Error  Correction/Quadruple  Error  Detection 
(TECQED)  protected  cache.  In  the  case  of  AVF,  profiling 
results  reveal  that  a  sampling  rate  of  less  than  0.1%  is 
sufficient  on  average.  PARMA  and  MACAU  need  higher 
sampling  rates  overall  because  they  need  to  address  the 
temporal overlapping of SEUs. Using PHYS, we were able 
to  finish  the  reliability  simulations  of  the  entire  SPEC2K 
benchmark  suite  within  a  month.  By  contrast,  without 
sampling, it was impossible to finish AVF simulations (even 
in  parallel)  of  the  entire  SPEC2K  benchmark  suite  even 
after 40 days; PARMA or MACAU run much slower.  
As  an  example,  art,  which  takes  2.02  days  to  finish  for 
base  sim-outorder  takes  2.16  days  for  AVF  with  PHYS. 
However in the absence of sampling art does not finish AVF 
simulations  after  one  month.  We  were  not  able  to  include 
the detailed results due to the space limit, but the results in 
[21]  show  the  importance  of  simulating  entire  benchmarks 
with reference inputs. Thus using reduced data sets is not a 
good approach to solve the reliability simulation slowdown 
problem. For seven benchmarks the discrepancy is between 
40  and  234%  and  for  six  benchmarks  it  is  between  10  and 
40%.  A  major  advantage  of  PHYS  is  that  the  results  are 
statistically guaranteed to be within 10% of the error margin. 
Inaccurate FIT rates obtained from SimPoint may lead to 
wrong design decision on how to protect the L2 cache. More 
specifically, 
ten 
benchmarks  had  more  than  40%  FIT  rate  difference  and 
seven  benchmarks  had  more  than  15%  FIT  rate  difference 
between  the  results  obtained  with  PHYS  and  the  results 
obtained with 100M SimPoints for SDC FIT rates for AVF. 
Note  that  the  FIT  estimation  results  with  PHYS  are 
statistically guaranteed to be within 10% of the error margin. 
This  demonstrates  the  need  for  reliability-aware  sampling. 
Turnaround  time  of  the  SimPoint  simulations  was  much 
faster,  achieving  a  slowdown  of  less  than  1  for  many 
workloads.  However,  the  advantage  of  a  faster  simulation 
turnaround time does not compensate for the large reliability 
estimation error as shown in [21].  
among  26  SPEC2K  benchmarks, 
11
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:38:09 UTC from IEEE Xplore.  Restrictions apply. 
VIII.  CONCLUSION  
Model-based  reliability  benchmarking  in  architecture 
studies  starts  with  reliability-lifetime  analysis.  The  large 
memory  overhead  for  reliability-lifetime  analysis  coupled 
with  random  accesses  to  the  data  structures  slows  down 
reliability  simulations  by  huge  factors  as  compared  to 
traditional  cycle-accurate  performance  simulations.  We 
emphasized 
that  slowdowns  cannot  be  avoided  by 
optimizing  the  size  of  data  structures  that  track  reliability-
lifetime  since  the  problem  of  random  accesses  to  these 
structures still persists.  
We  showed  that  conventional  sampling  methods  for 
performance  studies  fail  in  reliability  studies.  To  address 
this problem, we proposed a new reliability-aware sampling 
approach called PHYS, which has low FIT error rates while 
reducing  simulation  turnaround  time  significantly.  The 
usefulness of PHYS was demonstrated by  showing that the 
average slowdown of reliability simulations is negligible on 
the  entire  SPEC2K  suite  with  reference  inputs.  Our  results 
point to a novel approach to enable reliability benchmarking 
of target systems for full benchmark suites. 
ACKNOWLEDGMENTS 
This work was supported by  NSF grants NSF-1219186, 
NSF-CAREER-0954211, NSF-0834798 and NSF-0834799. 
REFERENCES 
[1]  G.  van  Belle  and  D.  C.  Martin.  Sample  Size  as  a  Function  of 
Coefficient  of  Variation  and  Ratio  of  Means.  The  American 
Statistician, Vol. 47, No. 3. 165-167, 1993 
[2]  D. R. Bellhouse . The Central Limit Theorem Under Simple Random 
Sampling. The American Statistician Vol. 55, No. 4, 352-357, 2001 
[3]  A.  Biswas, P. Racunas, R. Cheveresan,  J. Emer, S. Mukherjee, and 
R.  Rangan.  Calculating  Architectural  Vulnerability  Factors  for 
Address-Based  Structures.  In  Proceedings  of  the  International 
Symposium on Computer Architecture, 532-543, 2005 
[4]  D. Burger and T. M. Austin. The SimpleScalar Tool Set Version 2.0. 
Technical Report 1342, Computer  Sciences  Department, University 
of Wisconsin—Madison, 1997 
[5]  L. Eeckhout, R. H. Bell Jr., B. Stougie, K. De Bosschere, and L. K. 
John. Control  Flow Modeling in Statistical Simulation  for Accurate 
and  Efficient  Processor  Design  Studies.  In  Proceedings  of  the 
International Symposium on Computer Architecture, 350-360, 2004 
[6]  DARPA/IPTO  Study.  ExaScale  Computing  Study:  Technology 
Systems. 
Challenges 
http://users.ece.gatech.edu/mrichard/ExascaleComputingStudyRepor
ts/exascale_final_report_100208.pdf, 2009 
Achieving 
Exascale 
in 
[7]  X.  Fu,  T.  Li  and  J.  Fortes.  Sim-SODA:  A  Unified  Framework  for 
Architectural  Level  Software  Reliability  Analysis.  In  Workshop  on 
Modeling, Benchmarking and Simulation, 2006 
[8] 
Intel  Xeon 
http://www.intel.com/content/dam/www/public/us/en/documents/dat
asheets/xeon-e7-8800-4800-2800-families-vol-2-datasheet.pdf  
Processor 
product 
E7 
family 
datasheet: 
[9] 
Intel  Vtune  Amplifier  XE  2011:  http://software.intel.com/en-
us/articles/intel-vtune-amplifier-xe/ 
[10]  S.  M.  Khan,  D.  A.  Jim´enez,  B.  Falsafi,  and  Doug  Burger.  Using 
dead  blocks  as  a  virtual  victim  cache.  In  Proceedings  of  the 
International Conference on Parallel Architectures and Compilation 
Technologies, 2010 
[11]  K. Kelley. Sample size planning for the coefficient of variation from 
the  accuracy  in  parameter  estimation  approach.  Behavior  Research 
Methods, (39), 755-766, 2007 
[12]  A.  J.  KleinOsowski,  and  D.  J.  Lilja.  MinneSPEC:  A  New  SPEC 
Benchmark  Workload  for  Simulation-Based  Computer  Architecture 
Research. IEEE Computer Architecture. Letters. (1)1, 2002 
[13]  X. Li, S. Adve, P. Bose, and J.A. Rivers. SoftArch: An Architecture 
Level Tool for Modeling and Analyzing Soft Errors. In Proceedings 
of  the  International  Conference  on  Dependable  Systems  and 
Networks, 2005 
[14]  L.  Liu,  J.  K.  Peir.  Cache  sampling  by  sets,  IEEE  Transactions  on 
Very Large Scale Integration (VLSI) Systems, (1)2, 98-105, 1993 
[15]  S.  S.  Mukherjee.  Architecture  Design  for  Soft  Errors,  1st  Edition, 
Morgan Kauffman 
[16]  S. S. Mukherjee, C. Weaver, J. Emer, S.K. Reinhardt, and T.Austin. 
A systematic methodology to compute the architectural vulnerability 
factors for a high-performance microprocessor. In Proceedings of the 
International Symposium on Microarchitecture, 29-40, 2003 
[17]  A. A. Nair, S. Eyerman, L. Eeckhout , and L. K. John. A First-Order 
Mechanistic  Model  for  Architectural  Vulnerability  Factor.  In 
Proceedings  of 
International  Symposium  on  Computer 
Architecture, 273-284, 2012 
the 
[18]  Semiconductor  Industries  Association.  International  Technology 
Roadmap for Semiconductors. 2007.  
[19]  S.  K.  Thompson.  Sampling,  2nd  edition.  A  Wiley-Interscience 
Publication, p13. 
[20]  T.  Sherwood,  E.  Perelman,  G.  Hamerly  and  B.  Calder. 
Automatically  Characterizing  Large  Scale  Program  Behavior,  In 
Proceedings  of  the  International  Conference  on  Architectural 
Support for Programming Languages and Operating Systems, 45-57, 
2002 
[21]  J.  Suh  “Models  for  Soft  Errors  in  Low-level  Caches”,  Ph.D. 
dissertation, University of Southern California, 2012 
[22]  J.  Suh,  M.  Manoochehri,  M.  Annavaram,  M.  Dubois.  “Soft  error 
benchmarking  of  L2  caches  with  PARMA,”  In  Proceedings  of  the 
ACM SIGMETRICS joint international  conference on  Measurement 
and modeling of computer systems, 2011 
[23]  J. Suh, M. Annavaram, M. Dubois: “MACAU: A Markov model for 
reliability  evaluations  of  caches  under  Single-bit  and  Multi-bit 
Upsets,”  In  Proceedings  of  the  IEEE  International  Symposium  on 
High-Performance Computer Architecture, 1-12, 2012 
[24]  K.  R.  Walcott,  G.  Humphreys,  and  S.  Gurumurthi.  Dynamic 
prediction  of  architectural  vulnerability  from  microarchitectural 
state. In  Proceedings  of  the  International  Symposium  on  Computer 
Architecture, 2007, 516-527, 2007 
[25]  B. P. Welford. Note on a Method for Calculating Corrected Sums of 
Squares and Products. Technometrics, (4)3 419-420, 1962. 
[26]  R.  E.  Wunderlich,  T.  F.  Wenisch,  B.  Falsafi,  and  J.  C.  Hoe. 
SMARTS:  accelerating  microarchitecture  simulation  via  rigorous 
statistical sampling. In Proceedings of the International Symposium 
on Computer Architecture, 84-97, 2003 
12
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 07:38:09 UTC from IEEE Xplore.  Restrictions apply.