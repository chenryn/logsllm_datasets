0.3
0.2
0.1
0
SAID A       
piggybacking
50
100
150
200
com m unication overhead (bytes)
Figure 5. Authentication lower bounds.
The  lower  bound  for  the  piggybacking  scheme  is
derived in a similar manner and is given below (see [10]
for derivation):
j
q
−
P
i
q
)
1(
−−−
1
jb
 if  ,
received
)
−−
1
j
′++>
bi
z
 verifiabl
 | e
b
i
{
x
bb
i
Pr(
P
i
≥ ∑′
z
=
0
j
′++≤
=
1
,
,1
z
=′
min
where 
ib  denote
ix  and 
z
the maximum number and the maximum size of the bursts
that  can  be  tolerated,  respectively.  Note  that  this  lower
bound was derived assuming that the signature packet was
 if
i
 Parameters 
}.
,
i
i
1
b
received,  whereas  the  lower  bound  for  SAIDA  was
derived without this assumption.
In Figure 5, we plotted the lower bounds of the two
schemes  as  the  communication  overhead  (per  packet)  is
increased.  Because  the  lower  bound  changes  with  the
position of the packet, the average lower bound (among n
packets) was used. The following parameters were used:
•  signature size = 128 bytes, hash size = 16 bytes
•  n = 128, b = 4, q = 0.2, 
•  Parameter 
ix   is  increased  from  one  to  twelve  in
ib = 48
increments of one.
•  values for  m: {67, 45, 34, 28, 23, 20,  17,  16,  14,  13,
12, 11}
5. Performance evaluation
5.1. Overhead comparison
Our  main  focus  is  minimizing  the  size  of  the
overhead  required  to  authenticate  multicast  packets.  For
our comparison, we consider only schemes that amortize
a  signature  over  multiple  packets—in  general,  this  class
of schemes is more space efficient than other approaches.
We  compare  our  solution  with  four  other  previously
proposed 
EMSS,
augmented chain, and piggybacking scheme.
•  Sender  delay: delay on the sender side (in number  of
data packets) before the first packet in the block can be
transmitted.
schemes—authentication 
•  Receiver delay: delay on the receiver side (in number
of data packets) before verification of the  first packet
in the block is possible.
•  Computation  overhead:  number  of  hashes  and
tree, 
signatures computed by the sender per block.
•  Communication  overhead 
(bytes): 
size  of 
the
authentication information required for each packet.
•  Verification  probability:  number  of  verifiable  packets
of  the  entire  stream  divided  by  the  total  number  of
received packets of the stream.
Proceedings of the 2002 IEEE Symposium on Security and Privacy (S&P(cid:146)02) 
1081-6011/02 $17.00 ' 2002 IEEE 
Table 1  summarizes  the  five  authentication  schemes
based  on  the  performance  criteria  explained  above.  Its
values were obtained based on the following assumptions:
•  All five schemes employ a block size of n packets.
•  Communication  overhead  of  the  authentication  tree
was obtained for a tree of degree two (i.e., each node
of the tree has two children) and assuming a signature
size of σ and a hash size of h.
•  The  augmented  chain  is  parameterized  by  the  integer
variables a and p, where 
p < .
n
•  For SAIDA, n is the number of encoded pieces, and m
is the minimum number needed for decoding.
Note that the verification probability for the schemes
EMSS,  augmented  chain,  piggybacking,  and  SAIDA  is
not constant and actually depends on the communication
overhead.  The  authentication  tree  technique  has  the
favorable  property  of  guaranteeing  the  verification  of
every  received  packet,  but  at  the  cost  of  a  larger
communication  overhead—an  overhead  on  the  order  of
several  hundred  bytes  would  be  required  for  practical
block sizes. The authentication tree technique can also be
converted  to  a  probabilistic  method  by  simply  inserting
the block signature in a subset of the packets instead of all
the packets within the block. Even with this variation, the
authentication 
larger
communication  overhead  compared  to  SAIDA,  because
each  packet  must  include  several  hash  values  needed  to
compute the authentication tree.
tree  method 
requires 
a 
in 
In 
of 
the 
delay 
terms 
involved 
the
authentication/verification  process,  it  is  evident  that
EMSS, authentication tree, and the piggybacking scheme
have  an  advantage  over  the  other  two  schemes.  The
authentication  tree  and  piggybacking  scheme  do  not
require any delay for verification—each packet is verified
as soon as it is received. EMSS requires no buffering on
the  sender  side—each  packet  can  be  transmitted  as  soon
as it is ready without the need to buffer other packets. The
augmented chain technique requires the sender to buffer p
packets,  which  is  less  than  that  required  by  SAIDA,  the
authentication tree scheme, and the piggybacking scheme.
The  receiver  delay  for  SAIDA  is  not  fixed—it  could  be
anywhere  in  the  interval  [m,  n].  It  should  be  noted  that
SAIDA’s advantage over the other schemes is the ability
to  obtain  high  verification  probabilities  with  minimal
communication  overhead  (see  Subsection  5.2).  By
strategy,  it  trades  off  increased  delay  for  increased
verification probability.
There is no significant difference in the computation
overhead required for the four schemes. All five schemes
compute  only  one  signature  per  block  of  packets.  The
authentication  tree  technique  puts  a  slightly  heavier
computation  burden  on  the  sender  by  requiring  the
computation  of  the  authentication  tree  for  each  block  of
packets.
Proceedings of the 2002 IEEE Symposium on Security and Privacy (S&P(cid:146)02) 
1081-6011/02 $17.00 ' 2002 IEEE 
5.2. Verification probability vs. space overhead
then 
the 
is  relaxed, 
As  mentioned  earlier, 
requirement  on
if 
individual  packet  verification 
the
communication overhead can be reduced substantially. In
this type of an approach, verification of each packet is not
guaranteed  and 
is  assured  with  a  certain
probability.  EMSS,  augmented  chain,  piggybacking,  and
SAIDA fall into this category, and as expected, there is a
trade-off 
and
communication overhead for these schemes.
verification 
probability 
between 
instead 
to 
increase 
For the augmented chain method, the number of hash
chains  per  packet  is  not  a  variable  parameter.  However,
multiple  copies  of  the  signed  packet  can  be  transmitted
(for  each  block) 
the  probability  of
verification—copies would be sent with delayed intervals,
because  packet  loss  is  correlated.  Obviously,  the  size  of
the  authentication 
in
accordance  with the  number of copies  sent  per  block.  In
SAIDA, higher verification probabilities can be achieved
by increasing the amount of redundancy added to the data
(i.e.,  adjusting  the  parameters  m  and  n).  The  tradeoff
between  performance  and  communication  overhead  in
EMSS was already discussed in Subsection 3.1.
information  would 
increase 
In Figure 6, we show the verification probability (i.e.,
the  fraction  of  verifiable  packets)  for  three  probabilistic
authentication  schemes—augmented  chain,  EMSS,  and
SAIDA. To simulate a bursty loss environment,  we used
the  2-MC  loss  model  defined  in  Subsection  4.1  with  a
packet  loss  probability  of  0.2.  The  choice  of  0.2  as  the
loss probability was motivated by the fact that, in general,
the receiver loss rate is greater for multicast compared to
unicast.  In  [19],  the  authors,  using  actual  network
measurements,  showed  that  the  loss  rates  for  multicast
sessions are much higher (more than twice) compared to
their  corresponding  unicast  sessions.  Some  multicast
sessions were observed to have loss rates exceeding 20%
[YaK96,  YaM99].  The  following  simulation  parameters
were used:
General parameters
•  Packet loss probability: 0.2
•  Average length of burst loss: 8 packets
•  Block size: 128 packets
•  Length of hash: 16 bytes
•  Length of signature: 128 bytes
Parameters for EMSS
•  Length  of  hash  chain:  uniformly  distributed  over  the
interval 
,1[
127
]
p
a
=
=
,6
Parameters for the augmented chain
• 
Parameters for SAIDA
•  values for m: {90, 80, 60, 42, 32, 26}
15
The solid and dashed curves represent the verification
probabilities  of  SAIDA  and 
the  augmented  chain,
respectively.  For  EMSS,  verification  probabilities  were
obtained  by  simulating  numerous  combinations  of  the
three factors discussed in Subsection 3.1. The two clusters
of  markers  represent  the  simulation  results  for  EMSS—
the  left  cluster  represents  EMSS  implemented  with  two
hashes  appended  per  data  packet  and  the  right  cluster
represents EMSS implemented  with  four. Each cluster is
composed  of  three  types  of  markers—circle  markers
represent implementations  with  a  single  signature  packet
per  block,  while  the  triangle  and  asterisk  markers
represent  implementations  with  two  and  three  signature
packets per block, respectively. Each type of marker was
used  several  times  to  represent  the  different  number  of
hashes appended  in  the  signature  packet.  The  number  of
hashes appended in the signature packet was varied from
fifteen to 90 in increments of fifteen.
SAIDA
1
augmented chain
l
s
t
e
k
c
a
p
e
b
a
i
f
i
r
e
v
f
o
n
o
i
t
c
a
r
f
0.95
0.9
0.85
0.8
0.75
0.7
20
30
EMSS with
2 hashes per
data packet
EMSS with
4 hashes per
data packet
40
90
communication overhead per packet (byte)
50
60
70
80
100
110
Figure 6. Verification probability.
It is apparent from the figure that SAIDA can achieve
higher verification probabilities with less communication
overhead, compared to the other two schemes. Unlike the
schemes  shown  in  Figure  6,  the  authentication  tree
technique can guarantee the verification of every received
packet,  but  at  the  cost  of  a  much  larger  communication
overhead.  A  tree  of  degree  two  would  require  248  bytes
of  communication  overhead  if  the  block  size,  hash  size,
and signature size are set to the  same values  used  in  the
simulations of Figure 6.
When  multicast  packets  (via  UDP)  are  sent  across
networks  with heavy congestion or route failures, packet
loss can be high. Furthermore, conditions for the network
can change abruptly during a relatively short time period.
Even  if  the  verification  probability  for  the  packets  was
satisfactory  at  the  start  of  reception,  it  could  deteriorate
rapidly  as  the  loss  rate  increases  in  the  network.  We
performed experiments to examine the effect of increased
packet  loss  on  the  robustness  of  the  authentication
scheme.  Figure  7  shows  the  change  in  verification
probability  as  the  communication  overhead  is  kept
Proceedings of the 2002 IEEE Symposium on Security and Privacy (S&P(cid:146)02) 
1081-6011/02 $17.00 ' 2002 IEEE 
constant (communication overhead for the three schemes
is the same), and the packet loss probability is increased.
The  authentication  overhead  per  packet  was  fixed  at  34
bytes.  Again,  the  2-MC  loss  model  is  used  to  simulate
bursty loss patterns. The following parameters were used:
General parameters
•  Block size: 128 packets
•  Average length of burst loss: 8 packets
•  Length of hash output: 16 bytes
•  Length of signature: 128 bytes
Parameters for EMSS
•  Length  of  hash  chain:  uniformly  distributed  over  the
interval 
]64,1[
•  Number of hashes in a signature packet: 5
•  Number of hashes per data packet: 2
•  Number of signature packets per block: 1
Parameters for augmented chain
•  Number of signature packets per block: 1
• 
Parameters for SAIDA
• 
15
,6
=
=
=
=
a
p
65
n
,128
m
1
0.9
0.8
0.7
0.6
0.5
s
t
e
k
c
a
p
e
l
b
a
i
f
i
r
e
v
f
o
n
o
i
t
c
a
r
f
S A ID A           
E M S S            
augm ented chain
0.4
0.05
0.1
0.15
packet loss probability
0.2
0.25
0.3
0.35
Figure 7. Verification probability with increasing loss.
In  the  figure,  curves  for  EMSS  and  the  augmented
chain  drop  steeply  to  unacceptable  levels  when  the  loss
rate is increased. In contrast, the curve for SAIDA drops
much  more  moderately,  maintaining  a  verification
probability of over 0.91 when the packet loss rate is 0.35.
6. Conclusions
Through  our  results,  we  showed  that  SAIDA  is  an
efficient  method  of  authentication  that  is  highly  robust
same  amount  of
against  packet 
communication  overhead, 
the  highest
the  probabilistic
verification  probability  among  all 
authentication schemes that were examined.
it  achieved 
loss.  For 
the 
[10] S.  Miner  and  J.  Staddon,  “Graph-based  authentication  of
digital streams,” IEEE Symposium on Security and Privacy,
May 2001, pp. 232–246.
[11] A. Perrig, R. Canetti, J. D. Tygar, and D. Song, “Efficient
authentication and signing of multicast streams over lossy
channels,” IEEE Symposium on Security and Privacy, May
2000, pp. 56–73.
[12] M. Rabin, “Efficient dispersal of information  for  security,
load balancing,  and  fault  tolerance,”  Journal of  the  ACM,
Vol. 36, No. 2, Apr. 1989, pp. 335–348.
[13] P.  Rohatgi,  “A  compact  and  fast  hybrid  signature  scheme
for multicast packet authentication,” 6th ACM  Conference
on  Computer  and  Communications  Security,  Nov.  1999,
pp. 93–100.
[14] S. Ross, Stochastic Processes, 2nd Edition, John Wiley and
Sons, Inc., 1996.
[15] G.  J.  Simmons,  “Authentication  theory  /  coding  theory,”
Advances  in  Cryptology  (CRYPTO  ’84),  Aug.  1984,  pp.
411–431.
[16] H.  Weatherspoon,  C.  Wells,  P.  Eaton,  B.  Zaho,  and  J.
Kubiatowicz,  Silverback:  a  global-scale  archival  system,
Technical  Report  UCB/CSD-01-1139,  Computer  Science
Division, University of California, Berkeley, Mar. 2001, 15
pp.
[17] C.  Wong  and  S.  Lam,  Digital  Signatures  for  Flows  and
Multicasts,  Technical  Report  TR-98-15,  Department  of
Computer  Sciences,  University  of  Texas  at  Austin,  May
1998, 25 pp.
[18] M.  Yajnik,  J.  Kurose,  and  D.  Towsley,  “Packet  loss
correlation in the Mbone multicast network,” IEEE Global
Internet Conference, Nov. 1996.
[19] M.  Yajnik,  S.  Moon,  J.  Kurose,  and  D.  Towsley,
“Measurement  and  modeling  of  the  temporal  dependence
in packet loss,” IEEE INFOCOM ’99, Mar. 1999, pp. 345–
352.
in  all  aspects.  Depending  on 
Table 1 suggests that there is no single scheme that is
superior 
the  delay,
computation, and communication-overhead requirements,
different 
for  different
applications. We expect that our scheme’s high tolerance
for  packet 
low  communication  overhead
requirement  will  make  it  useful  in  many  multicast
applications—especially 
in  bandwidth-
limited  environments  (e.g.,  authenticated  audio/video
broadcasts in congested networks with high loss rates).
applications 
appropriate 
schemes 
are 
loss  and 
As  already  mentioned,  SAIDA  might  not  be
appropriate  in  situations  where  the  data  to  be  sent  is
generated  in  real  time,  and  immediate  broadcast  of  it  is
crucial.  Our  scheme  will  be  most  useful  in  cases  where
the sender has a priori knowledge of at least a portion of
the  data  to  be  broadcast  (e.g.,  broadcast  of  prerecorded
material).
References
[1] D. Boneh, G. Durfee, and M. Franklin, “Lower bounds for
multicast  message  authentication,”  Eurocrypt  2001,  May
2001, pp. 437–452.
[2] R. Canetti, J. Garay, G. Itkis, D. Micciancio, M. Naor, and
B.  Pinkas,  “Multicast  security:  a  taxonomy  and  some
efficient constructions,” IEEE INFOCOM ’99, Mar. 1999,
pp. 708–716.
[3] Y.  Desmedt,  Y.  Frankel,  and  M.  Yung,  “Multi-
receiver/multi-sender 
efficient
authenticated  multicast/feedback,”  IEEE  INFOCOM  ’92,
May 1992, pp. 2045–2054.
security: 
network 
[4] S. Floyd, V. Jacobson, C. Liu, S. McCanne, and L. Zhang,
“A  reliable  multicast  framework  for  light-weight  sessions
and  application  level  framing,”  IEEE/ACM  Transactions
on Networking, Vol. 5, No. 6, Dec. 1997, pp. 784–803.
[5] R. Gennaro and P. Rohatgi, “How to sign digital streams,”
Advances  in  Cryptology  (CRYPTO  ’97),  Aug.  1997,  pp.
180–197.
[6] P. Golle and N. Modadugu, “Authenticating streamed data
in  the  presence  of  random  packet  loss,”  Network  and
Distributed  System  Security  Symposium  (NDSS  ’01),  Feb.
2001, pp. 13–22.
[7] A.  Koifman  and  S.  Zabele,  “RAMP:  A  reliable  adaptive
multicast protocol,” IEEE  INFOCOM  ’96, Mar. 1996, pp.
1442–1451.
[8] M. Luby, M. Mitzenmacher, M. Shokrollahi, D. Spielman,
and  Stemann,  “Practical 
loss-resilient  codes,”  ACM
Symposium on Theory of Computing, May 1997, pp. 150–
159.
[9] R.  Merkle,  “A  certified  digital  signature,”  Advances  in
Cryptology (CRYPTO ’89), Aug. 1989, pp. 218–238.
Proceedings of the 2002 IEEE Symposium on Security and Privacy (S&P(cid:146)02) 
1081-6011/02 $17.00 ' 2002 IEEE