result = [([0]*cols) for i in range (rows)]
start = t.time()
for i in range(len(x)):
for j in range(len(y[0])):
for k in range(len(result)):
result[i][j] += x[i][k] * y[k][j]
print(result)
print(“Time = “, t.time()-start)
Time = 0.0015912055969238281
```
```
FOR_SEARCH:
Elapsed CPU time: 16.420260511 seconds
matches: 550
Elapsed CPU time: 16.140975079 seconds
matches: 550
Elapsed CPU time: 16.49639576 seconds
matches: 550
IN:
Elapsed CPU time: 6.446583343 seconds
matches: 550
Elapsed CPU time: 6.216615487 seconds
matches: 550
Elapsed CPU time: 6.296716556 seconds
matches: 550
```
从以上结果来看，在 Julia 中使用循环和运算符并不会产生显著的时间差异。但是在 Python 中循环几乎比运算符 IN 多花了三倍的时间。有趣的是，在这两种情况下，Julia 都比 Python 快得多。
### 线性回归
下一个实验是测试机器学习算法。我们选择了以一种最常见和最简单的机器学习算法，使用简单数据集的线性回归。我们使用了一个包含 237 条数据的数据集 “Head Brain”，数据集的两列分别为 “HeadSize” 和 “BrainWeight”。接下来，我们使用 “head size” 数据去计算 “brain weight”。在 Python 和 Julia 中我们都没有使用第三方库，而是从零实现了线性回归算法。
Julia：
```
GC.gc()
@CPUtime begin
linear_reg()
end
elapsed CPU time: 0.000718 seconds
```
Python：
```
gc.collect()
start = process_time()
linear_reg()
end = process_time()
print(end-start)
elapsed time: 0.007180344000000005
```
上面给出了 Julia 和 Python 所花费的时间。
### 逻辑回归
接下来，我们使用两种语言的库对最常见的机器学习算法（即逻辑回归）进行了实验。对于 Python 我们使用最常见的库 `sklearn`；对于 Julia，我们使用 `GLM` 库。我们在这里用到的数据集是有关银行客户的信息，其中包含 10,000 个数据条目。目标变量是一个二元变量，区分消费者是否继续使用银行账户。
下面给出了 Julia 进行逻辑回归所花费的时间：
```
@time log_rec()
0.027746 seconds (3.32 k allocations: 10.947 MiB)
```
下面给出了 Python 进行逻辑回归所花费的时间：
```
gc.collect()
start = process_time()
LogReg()
end = process_time()
print(end-start)
Accuracy : 0.8068
0.34901400000000005
```
### 神经网络
在各种程序和数据集上测试这两种语言后，我们在神经网络上使用 MNIST 数据集继续测试它们。该数据集包含从零到九的手绘数字的灰度图像。每张图像为 28×28 像素。每个像素值表示该像素的亮度或暗度，该值是包含 0 到 255 之间的整数。该数据还包含一个标签列，该列表示在相关图像中绘制的数字。
![Figure 1: Example of MNIST data set](/data/attachment/album/202210/02/122546koode2smh35so0qy.jpg)
图 1 是 MNIST 数据集的示例。
对两种语言我们都建立了一个简单的神经网络来测试它们耗费的时间。神经网络的结构如下：
```
Input ---> Hidden layer ---> Output
```
该神经网络包含了一个输入层、隐层还有输出层。为了避免神经网络的复杂度过高，我们对数据集没有进行任何的预处理工作。在 Julia 和 Python 中我们都进行了40次训练并比较它们的时间差异。
![Figure 2: Julia takes 5.76 seconds in a neural network](/data/attachment/album/202210/02/122546mkx442k7pjaegef7.jpg)
在 Julia 中，`Flux` 库通常被用于建立神经网络；在 Python 中我们常使用 `Keras` 库。图 2 展示了 Julia 在神经网络上的耗时。图 3 展示了 Python 的神经网络经过了若干次训练的耗时。
![Figure 3: Python takes 110.3 seconds in a neural network](/data/attachment/album/202210/02/122546au5duhu5d5adhnbk.jpg)
这个结果展示了 Julia 和 Python 在处理神经网络时存在巨大的时间差异。
表 1 总结了此次实验的测试结果并计算了 Julia 和 Python 时间差异的百分比。
| 实验 | Julia（秒） | Python（秒） | 时间差（%） |
| --- | --- | --- | --- |
| 矩阵乘法（不使用库） | 0.000001 | 0.0015 | 99.9 |
| 矩阵乘法（使用库） | 0.000017 | 0.0013 | 98.69 |
| 线性搜索（使用循环） | 0.42 | 16.4 | 97.43 |
| 线性搜索（使用 IN 操作符） | 0.43 | 6.2 | 93.06 |
| 线性回归 | 0.000718 | 0.00718 | 90 |
| 逻辑回归 | 0.025 | 0.34901 | 92.83 |
| 神经网络 | 5.76 | 110.3 | 94.77 |
我们进行的所有实验都表明，随着程序复杂性以及数据集大小的增加，Julia 和 Python 之间的执行时间差异也会增加。由这个结果我们可以推断，Julia 是一门更适合机器学习和神经网络的编程语言。
---
via: 
作者：[B Thangaraju](https://www.opensourceforu.com/author/b-thangaraju/) 选题：[lkxed](https://github.com/lkxed) 译者：[Return7g](https://github.com/Return7g) 校对：[wxy](https://github.com/wxy)
本文由 [LCTT](https://github.com/LCTT/TranslateProject) 原创编译，[Linux中国](https://linux.cn/) 荣誉推出