drops dramatically as history window becomes longer. In contrast,
LSTM-based approach is more stable as shown in Section 5.1.4.
Figure 6b investigates the top-❕ approach used by DeepLog’s
prediction algorithm. Let Dt be the set of top-❕ log key values
predicted by DeepLog at t, and mt be the actual log key value
appeared in the data at t. To see the impact of this strategy, we
study the CDF of Pr[mt ∈ Dt] for di(cid:130)erent ❕ values. Among over
11,000,000 log keys (that are labeled as normal) to predict, 88.9%
of DeepLog’s top prediction matches mt exactly; and 96.1% mt ’s
are within DeepLog’s top 2 predictions. When ❕ = 5, 99.8% of
normal mt ’s are within Dt , meanwhile the anomaly detection rate
is 99.994% (only one anomalous session was undetected).
Figure 7a shows the performance over OpenStack data set. (cid:140)e
PCA approach shows reasonable performance on this data set but
with low precision (only 77%), whereas even though IM has achieved
a perfect recall in this case, it has very poor precision of only 2%
(almost all VM instances are detected as abnormal executions).
(cid:140)is is because that OpenStack logs were generated randomly as
described in Section 5.1.2. Note that how many times that log keys
like (Stop Start) may appear in a life cycle of a VM (de(cid:128)ned by a
pair of Create and Delete) is uncertain. (cid:140)is makes it really hard for
IM to (cid:128)nd the “stable small invariants” for anomaly detection.
To test this hypothesis, we generated a second data set with
a deterministic pa(cid:138)ern like (Create Delete)+, resulting in a total of
5,544 normal VM executions and 170 anomalous ones. We denote
this data set as OpenStack II and the result is shown in Figure 7b.
IM performs very well on this data set with more regular pa(cid:138)erns.
However the recall for the PCA method drops to only 2% in this
case because the normal pa(cid:138)ern in the data is too regular, rendering
PCA method which detects anomalies by variance not working.
On the other hand, DeepLog demonstrates excellent performance
on both OpenStack logs with a F-measure of 98% and 97% respec-
tively. Lastly, it is also important to note that PCA and IM are o(cid:132)ine
methods, and they cannot be used to perform anomaly detection
per log entry. (cid:140)ey are only able to detect anomaly at session level,
but the notion of session may not even exist in many system logs.
5.1.4 Analysis of DeepLog. We investigate the performance im-
pact of various parameters in DeepLog including: ❕, h, L, and α. (cid:140)e
results are shown in Figure 8. In each experiment, we varied the
values of one parameter while using the default values for others.
Figure 6: Evaluation on HDFS log.
Figure 7: Evaluation on OpenStack log.
In general, the performance of DeepLog is fairly stable with respect
to di(cid:130)erent values, i.e., it is not very sensitive to the adjustment of
any one or combinations of these parameter values. (cid:140)is makes
DeepLog easy to deploy and use in practice. (cid:140)e results are fairly
intuitive to understand as well. For example, Figure 8c shows that
a larger ❕ value leads to higher precision but lower recall. (cid:140)us,
❕ could be adjusted to achieve higher true positive rate or lower
false positive rate. Lastly, DeepLog’s prediction cost per log entry
is only around 1 millisecond on our standard workstation, which
could be further improved by be(cid:138)er hardware such as using a GPU.
Figure 8: DeepLog performance with di(cid:130)erent parameters.
5.2 Parameter value and performance anomaly
To evaluate the e(cid:130)ectiveness of DeepLog at detecting parameter
value and performance (including elapsed time between log entries)
PrecisionRecallF-measure(a) Accuracy on HDFS.0.50.60.70.80.91.01.10.980.670.790.880.950.910.920.960.940.950.960.96PCAIMN-gramDeepLogg=1g=3g=5g=7g=9g=11(b) Cumulative probability of top g predictions.0.860.880.900.920.940.960.981.000.8890.9610.9810.9930.9980.99940.9998PrecisionRecallF-measure(a) Accuracy on OpenStack I.0.00.20.40.60.81.00.770.990.870.021.00.050.911.00.950.961.00.98PrecisionRecallF-measure(b) Accuracy on OpenStack II.0.00.20.40.60.81.01.00.020.030.831.00.910.831.00.910.940.990.97PCAIMN-gramDeepLog12345(a) Number of layers: L.0.50.60.70.80.91.03264128192256(b) Number of memory units: ®.0.50.60.70.80.91.0g=7g=8g=9g=10g=11g=12(c) Top g predictions as normal.0.50.60.70.80.91.05678910(d) Window size: h.0.50.60.70.80.91.0PrecisionRecallF-measureanomalies, we used system logs from the OpenStack VM creation
task. (cid:140)is data set includes both types of anomalies: performance
anomaly (late arrival of a log entry) and parameter value anomaly
(a log entry with a much longer VM creation time than others).
Experiment setup. As before, we deployed an OpenStack exper-
iment on CloudLab, and wrote a script to simulate that multiple
users are constantly requesting VM creations and deletions. During
OpenStack VM creation, an important procedure is to copy the
required image from controller node to a compute node (where the
VM will be created). To simulate a performance anomaly which
could be possibly caused by a DoS a(cid:138)ack, we thro(cid:138)le the network
speed from the controller to compute nodes at two di(cid:130)erent points,
to see if these anomalies could be detected by DeepLog.
Anomaly detection. As described in Section 3.2, we separate log
entries into two sets, one set is for model training and the other
set (called the validation set) is to apply the model to generate the
Gaussian distribution of MSEs (mean square error). In subsequent
online detection phase, for every incoming parameter value vector
v , DeepLog checks if the MSE between −→
−→
v and the predication
output (a vector as well) from its model is within an acceptable
con(cid:128)dence interval of the Gaussian distribution of MSEs from the
validation set.
Figure 9 shows the detection results for the parameter value
vectors of di(cid:130)erent log keys, where x-axis represents the id of the
VM being created (i.e., di(cid:130)erent VM creation instances), and y-axis
represents the MSE between the parameter value vector and the
prediction output vector from DeepLog. (cid:140)e horizontal lines in each
(cid:128)gure are the con(cid:128)dence interval thresholds for the corresponding
MSE Gaussian distributions. Figure 9a and 9b represent two log keys
where their parameter value vectors are normal during the entire
time. Figure 9c and 9d illustrate that the parameter value vectors
for keys 53 and 56 are successfully detected as being abnormal at
exactly the two time instances where we thro(cid:138)led the network
speed (i.e., injected anomalies).
For each abnormal parameter value vector detected, we identi-
(cid:128)ed the value that di(cid:130)ers the most with the prediction, to identify
the abnormal column (feature). We found out that the two abnor-
mal parameter value vectors for key 53 are due to unusually large
elapsed time values. On the other hand, key 56 is “Took * seconds to
build instance.”, and not surprisingly, its two abnormal parameter
value vectors were caused by unusually large values (for seconds).
Figure 9: Anomaly detection for parameter value vectors with dif-
ferent con(cid:128)dence intervals (CIs).
entries, of which 348,460 entries are labeled as anomalies. We chose
this data set because of an important characteristic: many log keys
only appeared during a speci(cid:128)c time period. (cid:140)is means that the
training data set may not contain all possible normal log keys, let
alone all possible normal execution pa(cid:138)erns.
5.3.2 Evaluation results. We conducted two experiments, one
uses the (cid:128)rst 1% normal log entries as training data and the other
uses the (cid:128)rst 10% log entries for training. In both se(cid:138)ings, the
remaining 99% or 90% entries are used for anomaly detection. We
set L = 1, α = 256, ❕ = 6, h = 3.
5.3 Online update and training of DeepLog
Section 5.1 has demonstrated that DeepLog requires a very small
training set (less than 1% of the entire log) and does not require
user feedback during its training phase. But it is possible that a
new system execution path may show up during detection stage,
which is also normal, but is detected as anomalous since it was not
re(cid:131)ected by the training data. To address this issue, this section
evaluates the e(cid:130)ectiveness of DeepLog’s online update and training
module as described in Section 3.3. We demonstrate this using
the di(cid:130)erence in detection results with and without incremental
updates, in terms of both e(cid:130)ectiveness and e(cid:129)ciency.
5.3.1 Log data set. (cid:140)e log data set used in this section is Blue
Gene/L supercomputer system logs 1, which contains 4,747,963 log
1CFDR Data, h(cid:138)ps://www.usenix.org/cfdr-data
Figure 10: Evaluation on Blue Gene/L log.
Figure 10 shows the results for without and with online training
for both experiments. In the case of “without online training”, we
run DeepLog to test incoming log entries without any incremental
update. While for the case of “with online training”, we assume
there is an end user who reports if a detected anomaly is a false
positive. If so, DeepLog uses that sample (now a labeled record)
to update its model to learn this new pa(cid:138)ern. Figure 10 shows
that without online training, with only 1% o(cid:132)ine training data,
this results in many false positives (hence very low Precision rate).
(cid:140)ough increasing its training data to 10% slightly increases the
Precision, its performance is still unsatisfactory. On the other hand,
DeepLog with online training signi(cid:128)cantly improves its Precision,
and hence F-measure scores. With a true positive rate of 100%
(perfect recall) in both se(cid:138)ings, online training reduces false positive
050100150200250300VM id(a) Value vectors for log key 250.00.51.01.52.0MSECI=99%CI=99.9%CI=98%050100150200250300VM id(b) Value vectors for log key 450.00.51.01.5MSECI=99%CI=99.9%CI=98%050100150200250300VM id(c) Value vectors for log key 530123456MSECI=99%CI=99.9%CI=98%050100150200250300VM id(d) Value vectors for log key 560123456MSECI=99%CI=99.9%CI=98%!70.843#0.,
20,8:70 , 789/,9,80914797,330.00.20.40.60.81.00.161.000.270.821.000.90!70.843#0.,
20,8:70 - 789
/,9,80914797,330.00.20.40.60.81.00.161.000.280.881.000.93without online trainingwith online trainingrate from 40.1% to 1.7% for 1% training data, and from 38.2% to 1.1%
for 10% training data, respectively.
Table 5 shows the amortized cost to check each log entry. For
the online training case, we reported time taken for both detection
and online update (if an update is triggered). (cid:140)e results show that
online update and training does increase the amortized cost per log
entry, but only slightly. (cid:140)is is because many log entries will not
trigger an update. Note that online update and online detection can
be executed in parallel; an update is carried out while the model is
using the current weights to continue performing detection.
Table 5: Amortized cost to check each log entry
10%
training data percentage
without online training (milliseconds)
1.11
2.46
with online training (milliseconds)
1%
1.06
3.48
5.4 Security log case studies
Anomalies having log keys that never showed up in normal logs
used for training (e.g., “ERROR” or “exception” log messages) are
easy to detect. DeepLog can e(cid:130)ectively detect much more subtle
cases. For example, in HDFS log, “Namenode not updated a(cid:135)er
deleting block” anomaly is shown as a missing log key in a session;
and “Redundant addStoredBlock” anomaly is shown as an extra log
key. (cid:140)is means that for any a(cid:138)ack that may cause any change of
system behavior (as re(cid:131)ected through logs), it can be detected. In
what follows, we investigate system logs containing real a(cid:138)acks to
demonstrate the e(cid:130)ectiveness of DeepLog.
5.4.1 Network security log. Network security is of vital impor-
tance. Both (cid:128)rewall and intrusion detection system (IDS) produce
logs that can be used for online anomaly detection.
To test the performance of DeepLog on network security logs, we
used the VAST Challenge 2011 data set, speci(cid:128)cally, Mini Challenge
2 — Computer Networking Operations [1]. (cid:140)is challenge is to
manually look for suspicious activities by visualization techniques.
It comes with ground truth for anomalous activities. For all anom-
alies in the ground truth, Table 6 shows the results of DeepLog. (cid:140)e
only suspicious activity not being detected is the (cid:128)rst appearance
of an undocumented computer IP address.
Table 6: VAST Challenge 2011 network security log detec-
tion
suspicious activity
Day 1: Denial of Service a(cid:138)ack
Day 1: port scan
Day 2: port scan 1
Day 2: port scan 2
Day 2: socially engineered a(cid:138)ack
Day 3: undocumented IP address No
detected?
Yes, log key anomaly in IDS log
Yes, log key anomaly in IDS log
Yes, log key anomaly in IDS log
Yes, log key anomaly in IDS log
Yes, log key anomaly in (cid:128)rewall log
(cid:140)e only false positive case happened when DeepLog reported a
log message that repeatedly appeared many times in a short period
as an anomaly. (cid:140)is is due to an event that suddenly became bursty
and printed the same log message many times in a short time range.
(cid:140)is is not identi(cid:128)ed by the VAST Challenge as a suspicious activity.
5.4.2 BROP a(cid:130)ack detection. Blind Return Oriented Program-
ming (BROP) a(cid:138)ack [5] leverages a fact that many server applica-
tions restart a(cid:137)er a crash to ensure service reliability. (cid:140)is kind
of a(cid:138)ack is powerful and practical because the a(cid:138)acker neither
relies on access to source code nor binary. A stack bu(cid:130)er over(cid:131)ow
vulnerability, which leads server to crash, is su(cid:129)cient to carry out
this a(cid:138)ack. In a BROP exploit, the a(cid:138)acker uses server crash as a
signal to help complete a ROP a(cid:138)ack which achieves executing a
shellcode. However, the repeated server restarting activities leave
many atypical log messages in kernel log as shown below, which is
easily detected by DeepLog.
nginx[*]: segfault at * ip * sp * error * in nginx[*]
nginx[*]: segfault at * ip * sp * error * in nginx[*]
nginx[*]: segfault at * ip * sp * error * in nginx[*]
......
5.5 Task separation and work(cid:131)ow construction
We implemented the proposed methods in Section 4 and evaluated
on a log with various OpenStack VM-related tasks. Both LSTM
approach and density-based clustering approach could successfully
separate all tasks. (cid:140)e (cid:128)rst method requires LSTM; it is a supervised
method which requires training data to be provided. (cid:140)e second
method uses clustering on co-occurrences of log keys within a cer-
tain distance threshold, which is an unsupervised method. Hence,
it doesn’t require training, but it does require parameter τ as the
distance threshold.
Speci(cid:128)cally, for density-based clustering approach, with a suf-
(cid:128)ciently large threshold value τ ∈ [0.85, 0.95], there is a clear
separation of all tasks. Note that the value of τ cannot be too large
(e.g., se(cid:138)ing τ = 1), as a background process may produce log en-
tries at random locations that will break log entries from the same
task apart.
Next we use a part of the VM creation work(cid:131)ow, to show how it
provides useful diagnosis of the performance anomaly in Section 5.2.
Recall in Section 5.2, parameter value vector anomaly is identi(cid:128)ed
on the time elapsed value of log key 53, and on the parameter
position of log key 56 (which represents how many seconds to build
instance). As shown in Figure 11, once an anomaly is detected by