discuss each defense and how our attacks apply in the following.
PointGuard [14] protects all pointers stored in memory by
masking them with an XOR key. It therefore prevents leakage
of code addresses via pointers. However, indirect leakage of
encrypted pointers and direct leakage attacks remain possible.
Oxymoron [4] attempts to prevent JIT-ROP attacks by
adding a layer of indirection to instructions such as branches
that reference other code pages. While Oxymoron thwarts the
recursive disassembly step of the original JIT-ROP attack, it
does not protect all pointers to code. Davi et al. [17] show an
attack against Oxymoron, exploiting indirect address leakage.
They then propose Isomeron that combines execution-path
randomization with code randomization to build indirect leakage
resistance. Neither of these techniques prevent direct code reads.
XnR [3] and HideM [22] perform permission checks on
memory accesses to implement execute-only, thus preventing
TLB-mediated code reads. They, however, do not check non-
TLB-mediated code reads. They are also vulnerable to indirect
leakage attacks, since code pointers are not hidden or protected
in any way during execution. Leakage of return addresses or
function pointers from the stack or heap remains possible during
execution.
Readactor [15] utilizes Extended Page Table permissions to
enforce execute-only permission and adds a layer of indirection
(trampolines) to prevent indirect leaks. Therefore, it prevents
TLB-mediated direct code reads and indirect leaks of code
pointers (e.g., return addresses and function pointers). Its
permissions, however, do not apply to non-TLB-mediated
accesses as demonstrated in Section VI. Moreover, leakage
of trampoline pointers (i.e., indirect code pointers) are possible
as demonstrated by our AOCR attack against Apache and
Nginx.
Heisenbyte [58] and NEAR [61] prevents executable region
leakages by making any code-area read destructive. Therefore,
these techniques can only mitigate TLB-mediated direct leakage.
Non-TLB-mediated memory accesses do not cause a byte
destruction; thus, they are not mitigated. Indirect leakages
also remain possible because code pointers are not protected
in any way.
ASLR-Guard [38] provides leakage resistant ASLR by
decoupling code and data, storing code locators in a secure
region of memory, and encrypting code locators that are stored
in observable memory. As a result, code locators themselves
cannot leak because they are encrypted whenever placed in
regular memory. However, the encrypted forward pointers can
be proﬁled and reused by an attacker. This is hinted at in the
paper itself: “... attackers may reused [sic] the leaked encrypted
code locators to divert control ﬂow.” Direct code reads, whether
they are through TLB (e.g., buffer over-reads) or not, also
remain possible in ASLR-Guard.
TASR [7] re-randomizes code regions at every I/O system
call pair to mitigate any potential information leakage. It also
ﬁxes the code pointers on the stack and heap for every re-
randomization. It can potentially mitigate all classes of remote
leakage attacks, but it requires source code for compilation
and it cannot mitigate leakages within the application boundary
(e.g., in JIT-ROP attacks).
VIII. MITIGATING ADDRESS-OBLIVIOUS CODE REUSE
Since AOCR attacks induce unintended control ﬂows,
enforcing control-ﬂow integrity is one way to mitigate them.
Isolating indirect code pointers using code-pointer integrity is
another option. These mitigations, however, come with their
own set of performance and security challenges, so we only
consider ways to extend leakage-resilient diversity to counter
AOCR in this section.
Although our variant of code reuse is oblivious to the code
layout, it is not oblivious to the data layout. In particular, it
makes assumptions on the layout of structures as well as the
layout of global variables. Therefore, one might argue that these
areas need randomization too. Techniques to do so are well
known in the literature [13, 23, 36]. However, this would not
11
prevent adversaries from reading and writing the data structures
after diversiﬁcation so our attacks could, at least in theory, be
extended to leak the data layout.
Perhaps a better strategy is to extend the code pointer
indirection layer with an authentication step to prevent misuse.
One way to instantiate this idea is to have every calling function
store a cookie in a register before using an indirect pointer and
have the callee function check the register for the expected
cookie value (after which the cookie register must be cleared
to avoid spills to the stack [35]). Cookies would simply be
random values stored as immediate operands in execute-only
code to prevent leakage. This scheme would prevent abuse
of trampolines for direct calls but would not prevent abuse
of indirect calls or returns because we may not know their
control-ﬂow targets at compile time [19].
To protect indirect calls and returns from abuse, we can
still verify that the function pointer used in an indirect call or
return was correctly stored and not forged without having to
compute the control-ﬂow graph at compile time. To do so, we
can leverage the recently proposed cryptographically-enforced
control ﬂow integrity, CCFI, technique by Mashtizadeh, et
al. [40]. In Readactor, an indirect code pointer is simply the
address of the forward trampoline; to prevent AOCR, we can
associate each indirect pointer and return address with a hash-
based message authentication code, HMAC. Note that if we use
the storage location of the indirect code pointer (not the address
it points to) as input to the HMAC function, copying the indirect
pointer from one storage location to another (as our AOCR
requires) will cause the HMAC check to fail. CCFI uses an
128-bit AES-based HMACs and stored the AES key in SIMD
registers. This led to high performance overheads (52% on
average on SPEC CPU2006), especially relative to conventional
CFI approaches, but has the undeniable advantage of enforcing
a very precise CFI policy without the need for complicated and
brittle static analysis. Moreover, future hardware will likely
include hardware support for protection of return addresses,
which would simplify our task to protection of forward pointers.
Our work adds to the growing body of evidence showing that
it is nigh impossible to avoid all types of information leakage.
If given the choice between randomizing more implementation
aspects or incorporating (or switching to) enforcement-based
mitigations, the latter seems like a better choice w.r.t. attainable
security. Enforcement-based mitigations also have important
practical advantages in that they naturally do not interfere
with code signing, distribution, memory de-duplication, or
debugging; code diversity engines must be carefully designed
to avoid interference in these areas.
IX. RELATED WORK
Our work mainly relates to memory corruption vulnera-
bilities and mitigation thereof. The literature in these areas
is vast. We refer the interested reader to the relevant sur-
veys [12, 34, 43, 52, 57] and focus on closely related work.
Early work on the effectiveness of ASLR found that 32-
bit address spaces do not allow sufﬁcient entropy in the
layout to prevent brute force guessing [51]. A decade later, it
became clear that not even 64-bit ASLR implementations are
impervious to brute-force attacks [8] and exploits now routinely
bypass ASLR using a variety of techniques [42, 49, 56]. This
motivated ﬁne-grained diversity approaches [34] that randomize
at the level of individual code pages [4], functions [31], basic
blocks [60], or single instructions [25, 27, 45]. The emergence
of JIT-ROP [53] and side-channel attacks [5, 28, 48] that
directly or indirectly disclose the randomized code layout
undermined the assumption that these ﬁner-grained diversity
techniques address the shortcomings of ASLR [26]. These
ﬁndings led to work on leakage-resilient code randomization
defenses. We already discussed these defenses and how their
security is impacted by AOCR attacks in Section VII. For the
sake of brevity, we do not repeat that discussion here.
Davi, et al. [17] demonstrated the ﬁrst attack against leakage-
resilient diversity approaches. In particular, they showed that
execute-only memory (on its own) does not provide sufﬁcient
protection against all JIT-ROP attacks. This inspired subse-
quent work on code pointer hiding [15, 38]. Maisuradze, et
al. [39] then demonstrated that the predictability of dynamically
compiled code provides another way to bypass execute-only
defenses without directly disclosing the code. However, our
AOCR attacks are strictly more powerful as none of these
earlier attacks are fully oblivious to the code layout. The attack
by Davi, et al., requires that the code is either readable or that
the code is not randomized below the page level. The attack by
Maisuradze, et al. assumes that i) pointers into JIT compiled
code are not protected against indirect leakage, and ii) that
JIT compiled code is not randomized below the function level.
Since we only rely on the high-level semantics of the code, our
bypass is not even stopped by instruction-level randomization.
In work closely related to ours, Snow, et al. [54] evaluated
the effectiveness of leakage-resilience techniques relying on
destructive reads such as Heisenbyte [58] and NEAR [61]. Their
main ﬁnding was that destructive reads can be bypassed using
so called constructive reloads. Such reloads exploit the fact that
multiple copies of the same code are often loaded into the same
process which means that adversaries can disclose one copy
and reuse code from another, thereby avoiding any gadgets
destroyed by adversarial reads. However, the constructive read
techniques are limited to bypassing leakage-resilience defenses
relying on destructive reads while our techniques generalize to
all of the defenses listed in Table I.
Gawlik, et al. [21] reported that the security assumptions of
leakage-resilient defenses can be weakened by using crash resis-
tant exploitation primitives. These primitives allow adversaries
to scan memory without crashing when trying to read execute-
only memory or accessing unmapped memory. However, as
the authors note, crash-resilience techniques cannot bypass the
Readactor++ [16] system, unlike our AOCR attacks.
G¨oktas¸, et al. [24] demonstrated that malicious thread
spraying can, in certain instances, be used to ﬁnd even very
small hidden memory regions associated with a particular
thread (the safe stack). However, malicious thread spraying
does not disclose the code layout in our threat model since
we assume perfect use of code pointer hiding and ﬁne-grained
randomization.
Memory deduplication between processes or between virtual
machines in a public cloud poses another threat to information
hiding. Early work demonstrated how to leak the base address
of 64-bit ASLR in a cloud environment [5]. Subsequent work
showed how to leak entire pages [9, 46]. These techniques
12
rely on timing side channels induced by the copy-on-write
semantics of deduplicated, writable pages and thus do not help
leak the contents of read-only or execute-only memory pages.
X. CONCLUSION
In this paper, we evaluated the effectiveness of leakage-
resilient code randomization. We presented a generic class
of attacks, Address-Oblivious Code Reuse (AOCR), that can
bypass ideal execute-only defenses including the state-of-the
art system, Readactor, and showed two new attack techniques
to facilitate AOCR. We demonstrated that AOCR is a realistic
threat with three concrete attacks against Nginx and Apache.
We also discussed two important implementation challenges that
practitioners must address to correctly deploy leakage-resilient
defenses.
Our ﬁndings add to the mounting body of evidence that
preventing information leaks without addressing the root causes
of memory corruption vulnerabilities is ﬁendishly hard if not
downright impossible. As long as the adversaries can observe
and swap code pointers (or their encrypted/indirect equivalents),
code reuse attacks remain possible. Our main contribution is
to show, for the ﬁrst time, that such attacks can be constructed
without any knowledge of the randomized code addresses. Thus,
we conclude that i) the research community is running up
against the limits of leakage-resilient diversity techniques and
that ii) enforcement techniques seem like the most attractive
way to further raise the bar against exploitation.
ACKNOWLEDGMENTS
This material is based upon work partially supported by
the Defense Advanced Research Projects Agency (DARPA)
under contracts FA8750-15-C-0124, FA8750-15-C-0085, and
FA8750-10-C-0237, by the National Science Foundation under
award number CNS-1513837 as well as gifts from Mozilla,
Oracle and Qualcomm.
Any opinions, ﬁndings, and conclusions or recommenda-
tions expressed in this material are those of the authors and
do not necessarily reﬂect the views of the Defense Advanced
Research Projects Agency (DARPA), its Contracting Agents,
the National Science Foundation, or any other agency of the
U.S. Government.
This work was supported in part by the German Science
Foundation (project S2, CRC 1119 CROSSING), the European
Unions Seventh Framework Programme (609611, PRACTICE),
and the German Federal Ministry of Education and Research
within CRISP.
REFERENCES
[1] M. Abadi, M. Budiu, ´U. Erlingsson, and J. Ligatti. Control-ﬂow
integrity. In ACM Conference on Computer and Communications
Security, CCS, 2005.
[2] J. P. Anderson. Computer security technology planning study.
volume 2. Technical report, DTIC Document, 1972.
[3] M. Backes, T. Holz, B. Kollenda, P. Koppe, S. N¨urnberger, and
J. Pewny. You can run but you can’t read: Preventing disclosure
exploits in executable code. In ACM Conference on Computer
and Communications Security, CCS, 2014.
[4] M. Backes and S. N¨urnberger. Oxymoron: Making ﬁne-grained
memory randomization practical by allowing code sharing. In
23rd USENIX Security Symposium, USENIX Sec, 2014.
13
[5] A. Barresi, K. Razavi, M. Payer, and T. R. Gross. CAIN: Silently
Breaking ASLR in the Cloud. In WOOT, 2015.
[6] V. Bartenev.
in nginx boost perfor-
mance 9x, 2015, https://www.nginx.com/blog/thread-pools-boost-
performance-9x/.
Thread pools
[7] D. Bigelow, T. Hobson, R. Rudd, W. Streilein, and H. Okhravi.
Timely rerandomization for mitigating memory disclosures. In
ACM Conference on Computer and Communications Security,
CCS, 2015.
[8] A. Bittau, A. Belay, A. J. Mashtizadeh, D. Mazi`eres, and
D. Boneh. Hacking blind. In 35th IEEE Symposium on Security
and Privacy, S&P, 2014.
[9] E. Bosman, K. Razavi, H. Bos, and C. Giuffrida. Dedup est
machina: Memory deduplication as an advanced exploitation
vector. In 37th IEEE Symposium on Security and Privacy, 2016.
[10] T. Bowden, B. Bauer, J. Nerin, S. Feng, and S. Seibold. The
/proc ﬁlesystem. Linux Kernel Documentation, 2009.
[11] K. Braden, S. Crane, L. Davi, M. Franz, P. Larsen, C. Liebchen,
and A.-R. Sadeghi. Leakage-resilient layout randomization for
mobile devices. In 23rd Annual Network and Distributed System
Security Symposium, NDSS, 2016.
[12] N. Burow, S. A. Carr, S. Brunthaler, M. Payer, J. Nash, P. Larsen,
and M. Franz. Control-ﬂow integrity: Precision, security, and
performance. CoRR, abs/1602.04056, 2016.
[13] P. Chen, J. Xu, Z. Lin, D. Xu, B. Mao, and P. Liu. A practical
approach for adaptive data structure layout randomization. In
20th European Symposium on Research in Computer Security,
ESORICS, 2015.
[14] C. Cowan, S. Beattie, J. Johansen, and P. Wagle. Pointguard:
protecting pointers from buffer overﬂow vulnerabilities. In 12th
USENIX Security Symposium, USENIX Sec, 2003.
[15] S. Crane, C. Liebchen, A. Homescu, L. Davi, P. Larsen, A.-R.
Sadeghi, S. Brunthaler, and M. Franz. Readactor: Practical code
In 36th IEEE
randomization resilient to memory disclosure.
Symposium on Security and Privacy, S&P, 2015.
[16] S. Crane, S. Volckaert, F. Schuster, C. Liebchen, P. Larsen,
L. Davi, A.-R. Sadeghi, T. Holz, B. D. Sutter, and M. Franz. It’s a
TRaP: Table randomization and protection against function-reuse
attacks. In ACM Conference on Computer and Communications
Security, CCS, 2015.
[17] L. Davi, C. Liebchen, A.-R. Sadeghi, K. Z. Snow, and F. Monrose.
Isomeron: Code randomization resilient to (Just-In-Time) return-
oriented programming. In 22nd Annual Network and Distributed
System Security Symposium, NDSS, 2015.
[18] I. Evans, S. Fingeret, J. Gonzalez, U. Otgonbaatar, T. Tang,
H. Shrobe, S. Sidiroglou-Douskos, M. Rinard, and H. Okhravi.