### Discussion of Defenses and Their Vulnerabilities to Our Attacks

#### PointGuard
PointGuard [14] protects all pointers stored in memory by masking them with an XOR key, thereby preventing the leakage of code addresses via pointers. However, this defense does not address indirect leakage of encrypted pointers or direct leakage attacks, which remain possible.

#### Oxymoron
Oxymoron [4] aims to prevent Just-In-Time Return-Oriented Programming (JIT-ROP) attacks by adding a layer of indirection to instructions such as branches that reference other code pages. While this approach thwarts the recursive disassembly step of JIT-ROP, it does not protect all pointers to code. Davi et al. [17] demonstrated an attack against Oxymoron, exploiting indirect address leakage. They then proposed Isomeron, which combines execution-path randomization with code randomization to build resistance against indirect leakage. However, neither of these techniques prevent direct code reads.

#### XnR and HideM
XnR [3] and HideM [22] implement execute-only permissions through permission checks on memory accesses, thus preventing Translation Lookaside Buffer (TLB)-mediated code reads. However, they do not check non-TLB-mediated code reads and are vulnerable to indirect leakage attacks because code pointers are not hidden or protected during execution. Leakage of return addresses or function pointers from the stack or heap remains possible during execution.

#### Readactor
Readactor [15] uses Extended Page Table permissions to enforce execute-only permissions and adds a layer of indirection (trampolines) to prevent indirect leaks. This prevents TLB-mediated direct code reads and indirect leaks of code pointers (e.g., return addresses and function pointers). However, its permissions do not apply to non-TLB-mediated accesses, as demonstrated in Section VI. Additionally, leakage of trampoline pointers (i.e., indirect code pointers) is possible, as shown by our Address-Oblivious Code Reuse (AOCR) attack against Apache and Nginx.

#### Heisenbyte and NEAR
Heisenbyte [58] and NEAR [61] prevent executable region leakages by making any code-area read destructive. These techniques can only mitigate TLB-mediated direct leakage. Non-TLB-mediated memory accesses do not cause byte destruction and thus are not mitigated. Indirect leakages also remain possible because code pointers are not protected in any way.

#### ASLR-Guard
ASLR-Guard [38] provides leakage-resistant Address Space Layout Randomization (ASLR) by decoupling code and data, storing code locators in a secure region of memory, and encrypting code locators stored in observable memory. This ensures that code locators themselves cannot leak because they are encrypted whenever placed in regular memory. However, the encrypted forward pointers can be profiled and reused by an attacker, as hinted at in the paper: “... attackers may reuse the leaked encrypted code locators to divert control flow.” Direct code reads, whether through TLB (e.g., buffer over-reads) or not, also remain possible in ASLR-Guard.

#### TASR
TASR [7] re-randomizes code regions at every I/O system call pair to mitigate potential information leakage. It also fixes code pointers on the stack and heap for every re-randomization. This approach can potentially mitigate all classes of remote leakage attacks but requires source code for compilation and cannot mitigate leakages within the application boundary (e.g., in JIT-ROP attacks).

### Mitigating Address-Oblivious Code Reuse

Since AOCR attacks induce unintended control flows, enforcing control-flow integrity (CFI) is one way to mitigate them. Isolating indirect code pointers using code-pointer integrity is another option. These mitigations, however, come with their own set of performance and security challenges. Therefore, we consider ways to extend leakage-resilient diversity to counter AOCR in this section.

Although our variant of code reuse is oblivious to the code layout, it is not oblivious to the data layout. Specifically, it makes assumptions about the layout of structures and global variables. Thus, randomizing these areas might be necessary. Techniques for such randomization are well known in the literature [13, 23, 36]. However, this would not prevent adversaries from reading and writing the data structures after diversification, so our attacks could, at least in theory, be extended to leak the data layout.

A better strategy might be to extend the code pointer indirection layer with an authentication step to prevent misuse. One way to implement this is to have every calling function store a cookie in a register before using an indirect pointer and have the callee function check the register for the expected cookie value. Cookies would be random values stored as immediate operands in execute-only code to prevent leakage. This scheme would prevent abuse of trampolines for direct calls but would not prevent abuse of indirect calls or returns, as their control-flow targets may not be known at compile time [19].

To protect indirect calls and returns from abuse, we can verify that the function pointer used in an indirect call or return was correctly stored and not forged without having to compute the control-flow graph at compile time. We can leverage the recently proposed cryptographically-enforced CFI (CCFI) technique by Mashtizadeh et al. [40]. In Readactor, an indirect code pointer is simply the address of the forward trampoline; to prevent AOCR, we can associate each indirect pointer and return address with a hash-based message authentication code (HMAC). If we use the storage location of the indirect code pointer (not the address it points to) as input to the HMAC function, copying the indirect pointer from one storage location to another will cause the HMAC check to fail. CCFI uses 128-bit AES-based HMACs and stores the AES key in SIMD registers, leading to high performance overheads (52% on average on SPEC CPU2006), especially relative to conventional CFI approaches. However, it enforces a very precise CFI policy without the need for complicated and brittle static analysis. Future hardware support for protection of return addresses would simplify this task.

Our work adds to the growing body of evidence showing that it is nearly impossible to avoid all types of information leakage. If given the choice between randomizing more implementation aspects or incorporating (or switching to) enforcement-based mitigations, the latter seems like a better choice regarding attainable security. Enforcement-based mitigations also have important practical advantages, as they naturally do not interfere with code signing, distribution, memory de-duplication, or debugging; code diversity engines must be carefully designed to avoid interference in these areas.

### Related Work

Our work primarily relates to memory corruption vulnerabilities and their mitigation. The literature in these areas is vast, and we refer the interested reader to relevant surveys [12, 34, 43, 52, 57] and focus on closely related work.

Early work on the effectiveness of ASLR found that 32-bit address spaces do not allow sufficient entropy in the layout to prevent brute force guessing [51]. A decade later, it became clear that even 64-bit ASLR implementations are not impervious to brute-force attacks [8], and exploits now routinely bypass ASLR using various techniques [42, 49, 56]. This motivated fine-grained diversity approaches [34] that randomize at the level of individual code pages [4], functions [31], basic blocks [60], or single instructions [25, 27, 45]. The emergence of JIT-ROP [53] and side-channel attacks [5, 28, 48] that directly or indirectly disclose the randomized code layout undermined the assumption that these finer-grained diversity techniques address the shortcomings of ASLR [26]. These findings led to work on leakage-resilient code randomization defenses. We already discussed these defenses and how their security is impacted by AOCR attacks in Section VII. For the sake of brevity, we do not repeat that discussion here.

Davi et al. [17] demonstrated the first attack against leakage-resilient diversity approaches, showing that execute-only memory (on its own) does not provide sufficient protection against all JIT-ROP attacks. This inspired subsequent work on code pointer hiding [15, 38]. Maisuradze et al. [39] then demonstrated that the predictability of dynamically compiled code provides another way to bypass execute-only defenses without directly disclosing the code. However, our AOCR attacks are strictly more powerful, as none of these earlier attacks are fully oblivious to the code layout. The attack by Davi et al. requires that the code is either readable or not randomized below the page level. The attack by Maisuradze et al. assumes that pointers into JIT-compiled code are not protected against indirect leakage and that JIT-compiled code is not randomized below the function level. Since we rely only on the high-level semantics of the code, our bypass is not stopped by instruction-level randomization.

In work closely related to ours, Snow et al. [54] evaluated the effectiveness of leakage-resilience techniques relying on destructive reads, such as Heisenbyte [58] and NEAR [61]. Their main finding was that destructive reads can be bypassed using so-called constructive reloads. Such reloads exploit the fact that multiple copies of the same code are often loaded into the same process, allowing adversaries to disclose one copy and reuse code from another, thereby avoiding any gadgets destroyed by adversarial reads. However, constructive read techniques are limited to bypassing leakage-resilience defenses relying on destructive reads, while our techniques generalize to all the defenses listed in Table I.

Gawlik et al. [21] reported that the security assumptions of leakage-resilient defenses can be weakened by using crash-resistant exploitation primitives. These primitives allow adversaries to scan memory without crashing when trying to read execute-only memory or accessing unmapped memory. However, as the authors note, crash-resilience techniques cannot bypass the Readactor++ [16] system, unlike our AOCR attacks.

Göktaş et al. [24] demonstrated that malicious thread spraying can, in certain instances, be used to find even very small hidden memory regions associated with a particular thread (the safe stack). However, malicious thread spraying does not disclose the code layout in our threat model, as we assume perfect use of code pointer hiding and fine-grained randomization.

Memory deduplication between processes or between virtual machines in a public cloud poses another threat to information hiding. Early work demonstrated how to leak the base address of 64-bit ASLR in a cloud environment [5]. Subsequent work showed how to leak entire pages [9, 46]. These techniques rely on timing side channels induced by the copy-on-write semantics of deduplicated, writable pages and thus do not help leak the contents of read-only or execute-only memory pages.

### Conclusion

In this paper, we evaluated the effectiveness of leakage-resilient code randomization. We presented a generic class of attacks, Address-Oblivious Code Reuse (AOCR), that can bypass ideal execute-only defenses, including the state-of-the-art system, Readactor. We also showed two new attack techniques to facilitate AOCR and demonstrated that AOCR is a realistic threat with three concrete attacks against Nginx and Apache. We discussed two important implementation challenges that practitioners must address to correctly deploy leakage-resilient defenses.

Our findings add to the mounting body of evidence that preventing information leaks without addressing the root causes of memory corruption vulnerabilities is extremely difficult, if not impossible. As long as adversaries can observe and swap code pointers (or their encrypted/indirect equivalents), code reuse attacks remain possible. Our main contribution is to show, for the first time, that such attacks can be constructed without any knowledge of the randomized code addresses. Thus, we conclude that i) the research community is reaching the limits of leakage-resilient diversity techniques, and ii) enforcement techniques seem like the most attractive way to further raise the bar against exploitation.

### Acknowledgments

This material is based upon work partially supported by the Defense Advanced Research Projects Agency (DARPA) under contracts FA8750-15-C-0124, FA8750-15-C-0085, and FA8750-10-C-0237, by the National Science Foundation under award number CNS-1513837, and gifts from Mozilla, Oracle, and Qualcomm. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of DARPA, its Contracting Agents, the National Science Foundation, or any other agency of the U.S. Government.

This work was supported in part by the German Science Foundation (project S2, CRC 1119 CROSSING), the European Union's Seventh Framework Programme (609611, PRACTICE), and the German Federal Ministry of Education and Research within CRISP.

### References

[1] M. Abadi, M. Budiu, Ú. Erlingsson, and J. Ligatti. Control-flow integrity. In ACM Conference on Computer and Communications Security, CCS, 2005.
[2] J. P. Anderson. Computer security technology planning study. volume 2. Technical report, DTIC Document, 1972.
[3] M. Backes, T. Holz, B. Kollenda, P. Koppe, S. Nürnberger, and J. Pewny. You can run but you can’t read: Preventing disclosure exploits in executable code. In ACM Conference on Computer and Communications Security, CCS, 2014.
[4] M. Backes and S. Nürnberger. Oxymoron: Making fine-grained memory randomization practical by allowing code sharing. In 23rd USENIX Security Symposium, USENIX Sec, 2014.
[5] A. Barresi, K. Razavi, M. Payer, and T. R. Gross. CAIN: Silently breaking ASLR in the Cloud. In WOOT, 2015.
[6] V. Bartenev. Thread pools in nginx boost performance 9x, 2015, https://www.nginx.com/blog/thread-pools-boost-performance-9x/.
[7] D. Bigelow, T. Hobson, R. Rudd, W. Streilein, and H. Okhravi. Timely rerandomization for mitigating memory disclosures. In ACM Conference on Computer and Communications Security, CCS, 2015.
[8] A. Bittau, A. Belay, A. J. Mashtizadeh, D. Mazières, and D. Boneh. Hacking blind. In 35th IEEE Symposium on Security and Privacy, S&P, 2014.
[9] E. Bosman, K. Razavi, H. Bos, and C. Giuffrida. Dedup est machina: Memory deduplication as an advanced exploitation vector. In 37th IEEE Symposium on Security and Privacy, 2016.
[10] T. Bowden, B. Bauer, J. Nerin, S. Feng, and S. Seibold. The /proc filesystem. Linux Kernel Documentation, 2009.
[11] K. Braden, S. Crane, L. Davi, M. Franz, P. Larsen, C. Liebchen, and A.-R. Sadeghi. Leakage-resilient layout randomization for mobile devices. In 23rd Annual Network and Distributed System Security Symposium, NDSS, 2016.
[12] N. Burow, S. A. Carr, S. Brunthaler, M. Payer, J. Nash, P. Larsen, and M. Franz. Control-flow integrity: Precision, security, and performance. CoRR, abs/1602.04056, 2016.
[13] P. Chen, J. Xu, Z. Lin, D. Xu, B. Mao, and P. Liu. A practical approach for adaptive data structure layout randomization. In 20th European Symposium on Research in Computer Security, ESORICS, 2015.
[14] C. Cowan, S. Beattie, J. Johansen, and P. Wagle. PointGuard: protecting pointers from buffer overflow vulnerabilities. In 12th USENIX Security Symposium, USENIX Sec, 2003.
[15] S. Crane, C. Liebchen, A. Homescu, L. Davi, P. Larsen, A.-R. Sadeghi, S. Brunthaler, and M. Franz. Readactor: Practical code randomization resilient to memory disclosure. In 36th IEEE Symposium on Security and Privacy, S&P, 2015.
[16] S. Crane, S. Volckaert, F. Schuster, C. Liebchen, P. Larsen, L. Davi, A.-R. Sadeghi, T. Holz, B. D. Sutter, and M. Franz. It’s a TRaP: Table randomization and protection against function-reuse attacks. In ACM Conference on Computer and Communications Security, CCS, 2015.
[17] L. Davi, C. Liebchen, A.-R. Sadeghi, K. Z. Snow, and F. Monrose. Isomeron: Code randomization resilient to (Just-In-Time) return-oriented programming. In 22nd Annual Network and Distributed System Security Symposium, NDSS, 2015.
[18] I. Evans, S. Fingeret, J. Gonzalez, U. Otgonbaatar, T. Tang, H. Shrobe, S. Sidiroglou-Douskos, M. Rinard, and H. Okhravi.