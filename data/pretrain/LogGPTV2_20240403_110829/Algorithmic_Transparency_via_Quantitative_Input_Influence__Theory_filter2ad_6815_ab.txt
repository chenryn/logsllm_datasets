tribution π. Over this expanded probability space, the random
variable X(x, ui) = x represents the original feature vector.
600600
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:16:24 UTC from IEEE Xplore.  Restrictions apply. 
The random variable X−iUi(x, u) = x|N\{i}ui, represents the
random variable with input i replaced with a random sample.
Deﬁning this expanded probability space allows us to switch
between the original distribution, represented by the random
variable X, and the intervened distribution, represented by
X−iUi. Notice that both these random variables are deﬁned
from X ×X , the expanded probability space, to X . We denote
the set of random variables of the type X ×X → X as R(X ).
We can now deﬁne probabilities over this expanded space.
For example, the probability over X remains the same:
Pr(X = x) =
=
(cid:3)
⎛
⎝ (cid:3)
{(x(cid:2),u(cid:2))|x(cid:2)=x}
)
˜π(x(cid:3), u(cid:3)
⎞
⎠(cid:8)(cid:3)
π(x(cid:3)
)
(cid:9)
π(u(cid:3)
)
{x(cid:2)|x(cid:2)=x}
u(cid:2)
In the example above, for a classiﬁer A, the quantity of
interest, the fraction of women (represented by the set W ⊆
X ) with positive classiﬁcation, can be expressed as follows:
QA(·) = E(A(·) = 1 | X ∈ W),
and the inﬂuence of input i is:
ι(i) = E(A(X) = 1 | X ∈ W)−E(A(X−iUi) = 1 | X ∈ W).
When A is clear from the context, we simply write Q rather
than QA. We now instantiate this deﬁnition with different
quantities of interest to illustrate the above deﬁnition in three
different scenarios.
= π(x)
A. QII for Individual Outcomes
Similarly, we can deﬁne more complex quantities. The
following expression represents the expectation of a classiﬁer
c evaluating to 1, when i is randomly intervened on:
(cid:3)
E(c(X−iUi) = 1) =
˜π(x, ui).
{(x,u)|c(xN\iui)=1}
Observe that the expression above computes the probability
of the classiﬁer c evaluating to 1, when input i is replaced
with a random sample from its probability distribution πi(ui).
{(x,u)|c(xN\iui)=1}
˜π(x, ui)
(cid:3)
(cid:3)
(cid:3)
(cid:3)
x
x
=
=
π(x)
π(x)
(cid:3)
(cid:3)
π(u)
{u|ui=u(cid:2)
i}
πi(u(cid:3)
i)
{u(cid:2)
i|c(xN\iu(cid:2)
i)=1}
{u(cid:2)
i|c(xN\iu(cid:2)
i)=1}
We can also deﬁne conditional distributions in the usual
way. The following represents the probability of the classiﬁer
evaluating to 1 under the randomized intervention on input i
of X, given that X belongs to some subset Y ⊆ X :
E(c(X−iUi) = 1 ∧ X ∈ Y)
E(X ∈ Y)
E(c(X−iUi) = 1 | X ∈ Y) =
.
Formally, for an algorithm A, a quantity of interest QA(·) :
R(X ) (cid:6)→ R is a function of a random variable from R(X ).
Deﬁnition 1 (QII). For a quantity of interest QA(·), and an
input i, the Quantitative Input Inﬂuence of i on QA(·) is
deﬁned to be
ιQA (i) = QA(X) − QA(X−iUi).
601601
One intended use of QII is to provide personalized trans-
parency reports to users of data analytics systems. For exam-
ple, if a person is denied a job application due to feedback
from a machine learning algorithm, an explanation of which
factors were most inﬂuential for that person’s classiﬁcation
can provide valuable insight into the classiﬁcation outcome.
For QII to quantify the use of an input for individual
outcomes, we deﬁne the quantity of interest to be the classiﬁ-
cation outcome for a particular individual. Given a particular
ind(·) to be E(c(·) = 1 | X = x).
individual x, we deﬁne Qx
The inﬂuence measure is therefore:
ind(i) = E(c(X) = 1 | X = x) − E(c(X−iUi) = 1 | X = x)
ιx
(3)
the probability of
positive classiﬁcation but the classiﬁcation that x actually
received, a slight modiﬁcation of the above QII measure is
more appropriate:
When the quantity of interest
is not
ind-act(i) = E(c(X) = c(x) | X = x)
ιx
−E(c(X−iUi) = c(x) | X = x)
= 1 − E(c(X−iUi) = c(x) | X = x)
= E(c(X−iUi) (cid:7)= c(x) | X = x)
(4)
The above probability can be interpreted as the probability
that feature i is pivotal to the classiﬁcation of c(x). Computing
the average of this quantity over X yields:
(cid:10)
x∈X Pr(X = x)E(i is pivotal for c(X) | X = x)
= E(i is pivotal for c(X)).
(5)
We denote this average QII for individual outcomes as
deﬁned above, by ιind-avg(i), and use it as a measure for
importance of an input towards classiﬁcation outcomes.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:16:24 UTC from IEEE Xplore.  Restrictions apply. 
B. QII for Group Outcomes
III. SET AND MARGINAL QII
As in the running example, the quantity of interest may
be the classiﬁcation outcome for a set of individuals. Given a
grp(·) to be E(c(·) =
group of individuals Y ⊆ X , we deﬁne QY
1 | X ∈ Y). The inﬂuence measure is therefore:
grp(i) = E(c(X) = 1 | X ∈ Y) − E(c(X−iUi) = 1 | X ∈ Y)
ιY
(6)
C. QII for Group Disparity
Instead of simply classiﬁcation outcomes, an analyst may
be interested in more nuanced properties of data analytics
systems. Recently, disparate impact has come to the fore as a
measure of unfairness, which compares the rates of positive
classiﬁcation within protected groups deﬁned by gender or
race. The ‘80% rule’ in employment which states that the
rate of selection within a protected demographic should be
at least 80% of the rate of selection within the unprotected
demographic. The quantity of interest in such a scenario is
the ratio in positive classiﬁcation outcomes for a protected
group Y from the rest of the population X \ Y.
E(c(X) = 1 | X ∈ Y)
E(c(X) = 1 | X (cid:7)∈ Y)
However, the ratio of classiﬁcation rates is unstable at at
low values of positive classiﬁcation. Therefore, for the com-
putations in this paper we use the difference in classiﬁcation
rates as our measure of group disparity.
disp(·) = |E(c(·) = 1 | X ∈ Y) − E(c(·) = 1 | X (cid:7)∈ Y)|
QY
(7)
The QII measure of an input group disparity, as a result is:
ιY
disp(i) = QY
disp(X) − QY
disp(X−iUi).
(8)
More generally, group disparity can be viewed as an as-
sociation between classiﬁcation outcomes and membership
in a group. QII on a measure of such association (e.g.,
group disparity) identiﬁes the variable that causes the associ-
ation in the classiﬁer. Proxy variables are variables that are
associated with protected attributes. However, for concerns
of discrimination such as digital redlining, it is important
to identify which proxy variables actually introduce group
disparity. It is straightforward to observe that features with
high QII for group disparity are proxy variables, and also cause
group disparity. Therefore, QII on group disparity is a useful
diagnostic tool for determining discriminiation. The use of QII
in identifying proxy variables is explored experimentally in
Section VII-B. Note that because of such proxy variables,
simply ensuring that protected attributes are not
to
the classiﬁer is not sufﬁcient to avoid discrimination (see
also [12]).
input
602602
In many situations, intervention on a single input variable
has no inﬂuence on the outcome of a system. Consider, for
example, a two-feature setting where features are age (A) and
income (I), and the classiﬁer is c(A, I) = (A = old ) ∧ (I =
high). In other words, the only datapoints that are labeled 1
are those of elderly persons with high income. Now, given
a datapoint where A = young, I = low, an intervention on
either age or income would result in the same classiﬁcation.
However, it would be misleading to say that neither age nor
income have an inﬂuence over the outcome: changing both the
states of income and age would result in a change in outcome.
Equating inﬂuence with the individual ability to affect the
outcome is uninformative in real datasets as well: Figure 1 is a
histogram of inﬂuences of features on outcomes of individuals
for a classiﬁer learnt from the adult dataset [13]2. For most
individuals, all features have zero inﬂuence: changing the state
of one feature alone is not likely to change the outcome of
a classiﬁer. Of the 19537 datapoints we evaluate, more than
half have ιx(i) = 0 for all i ∈ N, Indeed, changes to outcome
are more likely to occur if we intervene on sets of features.
In order to get a better understanding of the inﬂuence of a
feature i ∈ N, we should measure its effect when coupled
with interventions on other features. We deﬁne the inﬂuence
of a set of inputs as a straightforward extension of the inﬂuence
of individual inputs. Essentially, we wish the inﬂuence of a set
of inputs S ⊆ N to be the same as when the set of inputs is
considered to be a single input; when intervening on S, we
draw the states of i ∈ S based on the joint distribution of the
states of features in S, πS(uS), as deﬁned in Equation (1).
i∈S Xi,
We can naturally deﬁne a distribution over X ×(cid:2)
naturally extending (2) as:
˜π(x, uS) = π(x)πS(uS).
(9)
We also deﬁne the random variable X−SUS(x, uS) =
x|N\SuS; X−S(x, uS) has the states of features in N \ S
ﬁxed to their original values in x, but features in S take on
new values according to uS.
Deﬁnition 2 (Set QII). For a quantity of interest Q, and an
input i, the Quantitative Input Inﬂuence of set S ⊆ N on Q
is deﬁned to be
(S) = Q(X) − Q(X−SUS).
ιQ
Considering the inﬂuence of a set of inputs opens up a
number of interesting questions due to the interaction between
inputs. First among these is how does one measure the
individual effect of a feature, given the measured effects of
interventions on sets of features. One natural way of doing so
is by measuring the marginal effect of a feature on a set.
2The adult dataset contains approximately 31k datapoints of users’ personal
attributes, and whether their income is more than $50k per annum; see
Section VII for more details.
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:16:24 UTC from IEEE Xplore.  Restrictions apply. 
10000
8000
6000
4000
2000
s
l
a
u
d
v
d
n
i
i
i
f
o
r
e
b
m
u
N
0
0.0
0.2
0.4
0.6
0.8
1.0
Maximum Influence of some input
Fig. 1: A histogram of the highest speciﬁc causal inﬂuence
for some feature across individuals in the adult dataset. Alone,
most inputs alone have very low inﬂuence.
Deﬁnition 3 (Marginal QII). For a quantity of interest Q, and
an input i, the Quantitative Input Inﬂuence of input i over a
set S ⊆ N on Q is deﬁned to be
(i, S) = Q(X−SUS) − Q(X−S∪{i}US∪{i}).
ιQ
Notice that marginal QII can also be viewed as a difference
in set QIIs: ιQ(S ∪ {i}) − ιQ(S). Informally, the difference
between ιQ(S ∪ {i}) and ιQ(S) measures the “added value”
obtained by intervening on S ∪ {i}, versus intervening on S
alone.
The marginal contribution of i may vary signiﬁcantly based
on S. Thus, we are interested in the aggregate marginal
contribution of i to S, where S is sampled from some
natural distribution over subsets of N \ {i}. In what follows,
we describe a few measures for aggregating the marginal
contribution of a feature i to sets, based on different methods
for sampling sets. The primary method of aggregating the
marginal contribution is the Shapley value [14]. The less
theoretically inclined reader can choose to proceed to Section
V without a loss in continuity.
A. Cooperative Games and Causality
In this section, we discuss how measures from the theory of
cooperative games deﬁne measures for aggregating marginal
inﬂuence. In particular, we observe that the Shapley value [14]
is characterized by axioms that are natural in our setting.
However, other measures may be appropriate for certain input
data generation processes.
Deﬁnition 2 measures the inﬂuence that an intervention on
a set of features S ⊆ N has on the outcome. One can naturally
think of Set QII as a function v : 2N → R, where v(S) is the
inﬂuence of S on the outcome. With this intuition in mind,
one can naturally study inﬂuence measures using cooperative
game theory, and in particular, prevalent inﬂuence measures in
cooperative games such as the Shapley value, Banzhaf index
and others. These measures can be thought of as inﬂuence
aggregation methods, which, given an inﬂuence measure v :
2N → R, output a vector φ ∈ R
n, whose i-th coordinate
corresponds in some natural way to the aggregate inﬂuence,
or aggregate causal effect, of feature i.
The original motivation for game-theoretic measures is
revenue division [15, Chapter 18]: the function v describes
the amount of money that each subset of players S ⊆ N can
generate; assuming that the set N generates a total revenue of
v(N ), how should v(N ) be divided amongst the players? A
special case of revenue division that has received signiﬁcant
attention is the measurement of voting power [16]. In voting
systems with multiple agents with differing weights, voting
power often does not directly correspond to the weights of the
agents. For example, the US presidential election can roughly
be modeled as a cooperative game where each state is an agent.
The weight of a state is the number of electors in that state (i.e.,
the number of votes it brings to the presidential candidate who
wins that state). Although states like California and Texas have
higher weight, swing states like Pennsylvania and Ohio tend
to have higher power in determining the outcome of elections.
A voting system is modeled as a cooperative game: players
are voters, and the value of a coalition S ⊆ N is 1 if S
can make a decision (e.g. pass a bill, form a government,
or perform a task), and is 0 otherwise. Note the similarity
to classiﬁcation, with players being replaced by features. The
game-theoretic measures of revenue division are a measure
of voting power: how much inﬂuence does player i have
in the decision making process? Thus the notions of voting
power and revenue division ﬁt naturally with our goals when
deﬁning aggregate QII inﬂuence measures: in both settings,