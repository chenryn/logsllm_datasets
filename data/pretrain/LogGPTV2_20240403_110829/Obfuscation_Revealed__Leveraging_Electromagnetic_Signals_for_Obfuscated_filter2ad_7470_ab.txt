users are malware analysts who are unrestricted to set-up malware
initiators or choosing the appropriate device. The malware initiator
is only executed at the beginning of the analysis to trigger the
oscilloscope once while malware/benign samples as well as the
OS are kept untouched. This monitor scheme also means that our
approach does not require data synchronization which is common
in side channel analysis.
5.3 Data analysis and preprocessing
The second step in our complete framework preprocesses the col-
lected (noisy) EM measurements (see Figure 1). This step is manda-
tory as the CPU of an electronic device executes programmed in-
structions every clock cycle, that will provoke variations in its
internal circuitry. Moreover, modern target devices have multi-core
architectures, thus the recorded EM activity is a mixture of various
processes and it is impractical to identify correctly the process re-
sponsible for each observed variations from the electromagnetic
trace itself. The strong signals existing in the system, like processor
or memory clock, will act as a carrier, that will be amplitude or
frequency modulated by the executed instructions [29]. This modu-
lation will cause EM emanation, that leaks from any elements of
the device.
It has been shown [34] that it is possible to monitor the EM
spectrum to profile a program execution on the system. Each ex-
ecuted program has a specific loop pattern, that is revealed by
peaks in frequency. This is why we preprocess the raw EM data
to represent the fluctuations of the frequency content during the
measurement time of the traces. For this purpose, we computed the
spectrogram of the signal by taking the magnitude squared of the
n=0 x(n)w(n − m)e−jωn|2. A STFT
breaks the signal into small segments of equal length, and performs
a Fourier transform on each of the segments. Here, x(n) represents
STFT: spectro{x(n)}(m, ω) = |N
the input signal at time n, ω the frequency, m the segment index,
N the number of recording points, and w the window function. In
our case, the window function splits the signal in chunks of length
M, with an overlap O.
Even though the spectrogram is improving our data representa-
tion in terms of noise reduction, it also highly increases the amount
of data. Using the full spectrogram will drastically increase the
amount of time and space resources needed for classification, if
even possible. We therefore apply feature extraction on the spectro-
gram using NICV (see Section 3.1). In particular, we apply the NICV
on the spectrograms in order to identify the frequency bandwidths
that may real behavioral information about the binary.
Let us denote X as a spectrogram of dimension D×F with D being
the number of time features and F being the number of frequency
bandwidths. Let Y be the label, e.g. the type of the malware. The
computation of NICV(X , Y) results in a matrix of dimension D × F
(see Eq. (3.1)). Next, from the NICV matrix, we select the ϵ frequency
bands corresponding to the highest mean over D:
Fextract = {argmaxϵ( 1
[(NICV(X , Y))F
d]}
(1)
with argmaxϵ being a function that returns the ϵ indexes with the
highest values and (·)F
d represents the dth column of the matrix
over all frequencies. Accordingly, Fextract contains the list of the
ϵ indexes of the conserved frequencies. Note that, we extract the
complete frequency band of the spectrogram instead of multiple
chunks, which is mainly motivated by possible time delays or de-
synchronizations of unseen data in feature extraction process due
to the absence of an exact triggering process.
D−1
d =0
D
5.4 Malware classification
Given the most informative spectrogram bands, our main objec-
tives are to analyse to which extend a malware analyst is able to:
(i) retrieve the type or family of the malicious binary, (ii) identify
precisely which binary was being executed, (iii) classify the obfus-
cation technique, and (iv) classify the malware family even with
an previously unknown obfuscation technique. Based on that, we
assume that the analyst has a dataset of labeled malware binaries
on which he can build supervised classification models.
Neural networks are particularly effective for computer vision
and pattern recognition, and that is the reason to investigate on
their efficiency to classify the spectrograms of monitored device’s
EM activity. We defined two distinct neural networks architectures
(see Table 4,5 in appendix), and compared their efficiency on our
classification tasks. The first architecture is a simple MLP, which
takes as input flattened spectrogram bandwidths. Our CNN archi-
tecture is a bit more complex, but still rather simple compared with
the state-of-the-art networks used for image recognition. It is con-
stituted of a stack of three atomic blocks where each block is made
with one or two convolution layer(s), followed by a Max Pooling
layer.
We furthermore study the effectiveness of more simplistic and
less resource demanding machine learning tools like Naive Bayes
(NB) and Support Vector Machines (SVM). As NB and SVM (or in
general most machine learning algorithms) are prone to the curse
of dimensionality [4], meaning that they do not scale well with
the number of input features, we do not take as input the selected
711Obfuscation Revealed: Leveraging Electromagnetic Signals for Obfuscated Malware Classification
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
bandwidths as for the neural network models, but perform feature
transformation on the spectrogram using LDA (see 3.1). LDA is a
commonly used tool together with machine learning algorithms
that allows to (drastically) reduce data dimension. Note that, on the
other hand in most cases, LDA (or any feature transformation) is
not suitable for neural network models, as features are transformed
into different feature spaces and dependencies between features (in
particular shapes and patterns) may be disconnected and harder to
learn.
6 EXPERIMENTS
6.1 Data aquisition components
Figure 2: Overview of the proposed infrastructure: Experi-
mental setup of malware testbed and data acquisition.
6.1.1 Target device. Evaluation of target device is critical for EM
side-channel analysis. We determine three main requirements: (i)
It must be a multi-purpose embedded device to support as many
collected malware as possible rather than a specific set of malware
or device; (ii) Its CPU must be a prominent architecture to avoid the
lack of support of emerging IoT malware; (iii) It must be vulnerable
to EM side-channel attacks.
We select Raspberry Pi 2B as a target device with 900 MHz quad-
core ARM Cortex A7, 1 GB memory. Since its ARM architecture, size,
power consumption and cost effective, make it a good candidate
for any kinds of embedded and IoT scenarios including prototypes
and developments. Our research focuses on a very general malware
classification challenge rather than a narrowed solution to any
specific device, in particular, as related works did not show diversity
in results or analysis techniques across multiple devices (e.g. [33]).
It has been shown in previous works [13, 36] that cryptographic
and anomaly activities are successfully distinguished by leveraging
EM signals from the Raspberry Pi 2B. By not limiting the capabili-
ties of the infrastructure with restricted bare-metal firmware, the
Raspberry Pi is deployed with a fully-functioning Raspbian Buster
OS of Linux 4.19.57-v7+ armv7l. A device under test with a fully
functioning OS and multiple cores is to answer if it is possible to
handle malware in more complex scenarios where malware is mixed
with background processes, services and interrupts thus noisy EM
traces.
To prevent the detection of any artificial artifacts by evasion
techniques and keep a realistic environment, all background ser-
vices are kept to their default with more than 100 running processes
and services. Additionally, no adjustments, overclocking, or tuning
of the processor clock rate are applied to the processor.
6.1.2 Malware testbed environment. To generate a practical victim
environment that can trigger real malware, we applied different
tools and techniques. We created honeypot directories under root
folder, home folder, etc. Each malware execution will have a ran-
dom initialized environment consisting of different valid files and
extensions to assure that ransomware will be properly executed
while not biased towards the recorded traces.
Besides, most IoT botnets architectures consist of one command
and control server (C&C) which is continuously connected (except
peer-to-peer botnet). To support our malware dataset, consist of Mi-
rai and Bashlite, we implement a synthetic environment of central
spoofed C&C server model. C&C servers are adopted to randomly
deliver different commands to the botnet client in multiple attack
scenarios (Fig. 2). To trigger a broad range of malicious activities, in
each experiment the following commands are delivered: network
scanner, flood targeted victim network in TCP/UDP, hibernation,
or self-terminate etc. Furthermore, we installed multiple virtual
machines in the same local network for absorbing network attacks
coming from malware. The nature of malware samples, the execu-
tion coverage on software level in the device under testing are not
altered, so that we presume no anti-analysis evasion techniques
can survive during the bare-metal malware analysis.
6.1.3 Electromagnetic signal acquisition. We monitor the Raspberry
Pi under the execution of benign and malicious dataset using a low
to mid-range measurement setup. It consists of an oscilloscope
with 1GHz bandwidth (Picoscope 6407) connected to a H-Field
Probe (Langer RF-R 0.3-3), where the EM signal is amplified using a
Langer PA-303 +30dB (Figure 3). To capture long-time execution of
malware in the wild, the signals were sampled at 2MHz sampling
rate.
The activity of the Raspberry Pi, when executing malware or gen-
erating benign activity, was recorded with a sample rate of 2MHz
during 2.5 seconds. It has been chosen empirically based on (but
not limited to) the constraints of the data acquisition components:
imprecise trigger, and malware characteristics (e.g. sleep time with
no activity of Mirai). The duration of 2.5 seconds is enough to obtain
exploitable features for classification.
We collected 3 000 traces each for 30 malware binaries and 10 000
traces for benign activity. Thus, in total 100 000 traces were recorded,
then we computed their short term Fourier transformation, as de-
scribed in part 5.3.
The feature selection process with NICV on the spectrogram
is illustrated in Figure 4. The left side shows the NICV where the
right side highlights the selected frequencies that correspond to
the twenty frequencies with the highest NICV mean over time (D).
712ACSAC ’21, December 6–10, 2021, Virtual Event, USA
D.P. Pham and D. Marion et al.
dataset to assess the efficiency of the model on unseen data, and a
training dataset. We kept by default 20% of the dataset for testing
and used the 80% remaining for training and validation.
6.2.2 Training procedure. The neural network models have been
trained over 50 epochs, where we stored the model according to
the highest validation accuracy. In our setup using one RTX 2080
Ti GPU, CNN took around 50s per epoch, which gives 50 × 50s =
2500s = 41 min of training time, MLP performed 1 epoch within
9s, that gives 50 × 9s = 2500s = 7min. Testing one sample takes
roughly 0.75s for MLP and 0.27s for CNN. NB and SVM are much
less resource demanding than neural network models, and can be
computed using standard CPU computation systems. On our system
with an Intel(R) Xeon(R) Silver 4214 @2.20GHz with 24 cores and
128GB RAM, NB took 0.14s to train, and SVM 18.90s. The testing
of one sample took for NB around 1µs, and for SVM between 1ms
and 6ms depending on the number of features considered.
Results were obtained using the Keras backend of tensorflow run-
ning on one RTX 2080 Ti GPU for MLP/CNN and scikit-learn [27]
library (version 0.23.2) for NB/SVM/LDA.
7 RESULTS AND DISCUSSION
7.1 Experimental results
A synthesis of the results we obtained can be found in Table 3.
The first column indicates the name of the scenario. In the second
column we state the number of outputs (i.e. classes) of the network.
Finally, the other columns show the accuracy with the optimal
number of bandwidths as well as precision and recall of the two
neural network models, and the two machine learning algorithms
on the test dataset. Details about the construction of the scenarios
can be found in Table 6 in the Appendix.
Type classification. We used traces measured during the activity
of 30 malware samples, plus traces of benign activities (random,
video, music, picture, camera activities), both in a random user
environment to avoid biases. As explained in Section 4, the malware
binaries are variations of five families: gonnacry, keysniffer, maK_It,
mirai and bashlite, including seven different obfuscation techniques.
In this scenario, we aim to retrieve the type of malware (if any)
infecting the device at the time of the recording. This gives us a 4-
class classification problem: ransomware, rootkit, DDoS, and benign.
All models are very efficient for this problem (> 98% accuracy), and
clearly obfuscation does not hinder type classification. We can
observe that CNN (99.82%) is slightly more accurate than MLP, NB,
and SVM. The confusion matrix is illustrated in Figure 5a, which
illustrates the predicted classes (predicted label) from the network
per executed binary (true label). The darker the color, the higher
the proportion of correctly predicted labels. We can observe no
confusion for the benign and rootkit class to any other class, and a
minor confusion between DDos and ransomware in both directions.
Family classification. In this scenario, we classify into the mal-
ware family plus benign class, which gives six classes: bashlite,
mirai, gonnacry, keysniffer, maK_it, and benign. CNN gives the
highest accuracy with 99.61%, but also MLP and ML provide re-
sults > 97%. The confusion matrix is illustrated in Figure 5b, which
shows that all classes are mostly correctly classified with a small
Figure 3: Probe setup consists of a H-Field probe placed 45
degree above the system processor.
Figure 4: NICV (center) and in red the 20 selected frequencies
(ϵ = 20) on the mean over the time (right) and the mean over
the frequencies (top)
6.2 Classification framework
6.2.1 Model input. In Section 5.3, we described how we generate
the spectrograms from the EM activity recorded by the oscilloscope.
We measure 500 000 points to get a 2.5s recording with a sampling
rate of 2MHz, which is about 8MB per trace. As explained above,
it was necessary to generate tens of thousands of spectrograms to
train our neural network models. We choose (M, O) = (8192, 4096)
as parameters for the STFT. To reduce the dimension of the analyzed
data and reduce the noise, we apply the feature extraction process
described in Subsection 3.1 to conserve only ϵ different bandwidths.
We tested ϵ ∈ {4 × i}0 92%, with CNN
99.38%. Accordingly, even unseen variations in the training phase
do not hinder our methodology.
Virtualization and packer identification. In next two scenarios,
we test if the binary is protected with virtualization or packing,
which results to two (two-class) detection problems. For each of
them, we used the traces of the original malware (mirai, bashlite
and gonnacry) as well as the traces of the corresponding protected
variation. We see that virtualization is slightly easier to detect than
packing, with CNN performing with the highest accuracy of 95.83%
and 94.96% respectively.
Obfuscation classification. Here we are interested in classifying
into the 7 obfuscation techniques: Opaque predicates, bogus control
flow, control-flow flattening using O-LLVM or Tigress, instruction
substitution, virtualization, or packing. Both of the network models
714ACSAC ’21, December 6–10, 2021, Virtual Event, USA
D.P. Pham and D. Marion et al.
classification problem of 35 classes (including distinct benign activ-
ities), identifying the family and variant with possible obfuscation
of the malware. For the number of classes and the closeness of
the underlying executions, all models get very good results, where
CNN is more effective with 82.28% vs a random guess of only 2.86%.
The confusion matrix of the CNN binary classification is given
in Figure 6. As we can see, if confusions between classes happen, it
happens between binaries that belong to the same family (squared
in red in the figure). In addition, we observe that in most of the
cases, the "darkest" color appears on the diagonal, which means
that the highest score (output of the CNN) occurs for the true class
label. So, in most cases, obfuscation does not hinder exact binary
profiling.
However, we still observe groups of binaries which are harder
to distinguish and one misclassification. More precisely, one can
observe that bashlite_cfflatten, bashlite_upx, bashlite_bcf, and bash-
lite have (nearly) no confusion to other binaries, which means that
the obfuscation does not mask the behavior of the binary and the
obfuscation technique itself is visible and distinguishable; bash-
lite_addopaque is misclassified as bashlite_flatten which is inline
with our previous explanation on similarities of the underlying
techniques, and there is a confusion between bashlite_flatten and
bashlite_virtualize.
For mirai and its variants we see a much smaller effect of the
obfuscation techniques on the classification outcome as for bashlite
and gonnacry. Meaning that the obfuscation technique is clearly
identifiable and does not mask the behavior of mirai itself.
For gonnacry we have several distinct groups:
(1) gonnacry-des-upx, gonnacry-des: only a very minor confusion
can be visible between the packed and unpacked version
using des. Interestingly, there is no confusion using des with
the version of aes and blowfish and their packed variants.
(2) gonnacry, gonnacry-aes: gonnacry and gonnacry-aes are slightly
(3) gonnacry-des and gonnacry-des-upx are not confused with
confused.
any other binary;
(4) gonnacry and gonnacry-aes have a slight confusion, which
means that in some cases the encryption with blowfish and
aes are not clearly distinguishable;
(5) this effect is even more present when the binaries are packed,
i.e. for gonnacry-upx and gonnacry-aes-upx;
(6) again, like for bashlite, we see a slight confusion between
gonnacry_flatten and gonnacry_virtualize.
(7) gonnacry_addopaque, gonnacry_bcf, gonnacry_sub,
gonnacry_cfflatten: we observe only nearly no confusion
between these four obfuscation techniques.
We see nearly no confusion when predicting maK_it and keysnif-
fer. Finally, as before the benign binaries show no confusion with
any other malicious binaries, and there is no confusion between
each of the benign classes.
7.2 Discussion
Novel malware. The results we obtained show that our approach
is successful to classify various malware samples into their types,
families, exact binaries, and identify/classify obfuscation. The close-
ness between accuracy, recall, and precision of each experiment
Figure 6: Confusion matrix of a CNN classification into 35
binaries from left to right (with and without obfuscation).
(1) bashlite_cfflatten, bashlite_upx, bashlite_bcf, bashlite,
bashlite_addopaque, bashlite_sub, bashlite_flatten, bash-
lite_virtualize;
(2) mirai_sub, mirai_bcf, mirai_cfflatten, mirai, mirai_upx,
mirai_addopaque, mirai_flatten, mirai_virtualize;
(3)
gonnacry_aes,
gonnacry_flatten,
gonnacry_addopaque,
gonnacry_cfflatten;
(4) keysniffer, maK_It;
(5) benign: encode video, play audio, take picture, record
camera, random.
gonnacry,
gonnacry_upx,
gonnacry_virtualize,
gonnacry_sub,
gonnacry_des_upx,
gonnacry_aes_upx,
gonnacry_des,
gonnacry_bcf,
were able to learn to differentiate obfuscation techniques inde-
pendently of the five underlying malware families. CNN is more
efficient achieving 82.70% (vs a random guess of 14.29%). Again,
MLP was slightly worse and ML techniques show a gap of around
10%. The confusion matrix is illustrated in Figure 5c, which shows
that for each obfuscation technique CNN predicted the correct label
(the darkest color/highest number on the diagonal). Some confusion
can be observed between addopaque, virtualize, and flatten, which
are executed using Tigress, and indeed they share similar options2.
This result shows that our methodology is not only able to dis-
tinguish between malicious activities, but even focus solely on
behavioral features independent from the underlying binary execu-
tion.
Executable classification. This scenario is a straightforward exe-
cutable identification, where the model is trying to profile exactly
the binary that generated the spectrogram. This translates into a
2 http://tigress.cs.arizona.edu/transformPage/docs/flatten/index.html
715Obfuscation Revealed: Leveraging Electromagnetic Signals for Obfuscated Malware Classification
ACSAC ’21, December 6–10, 2021, Virtual Event, USA
indicates robustness and no overfitting to any specific class. We
are able to classify malware variations unseen during the training
phase which is particularly relevant in practical scenarios when
considering the evolution of malware. Furthermore, we realized the
measurements in a stable lab environment, still no exact triggering,
nor any restriction on the (background) processes of the target
device have been done, which corresponds to a setup a malware
analyst could exploit.
Obfuscation resiliency. In this paper, we examined 7 obfusca-
tion techniques including packers and virtualization, which have
been used by real-world malware as a growing trend to exploit
cryptors and packers to hide the true intent of malware samples.
While previous solutions such as signature-based packer detection
can be evaded, our results show that we can distinguish between
obfuscation techniques solely based on EM traces, which gives the
opportunity to analyze the evolution of IoT malware since new
obfuscation techniques will be reformed to thwart detection.
ML algorithms. From our results, we can observe that the ac-
curacy of SVM and NB are close for more straightforward classifi-
cation problems like type and family, but the gap gets bigger when
consider more complex scenarios (i.e. executable, obfuscation).
Note that, all our results have been obtained by considering that
the malware analyst measures only one trace per binary to predict
the correct class. However, it could be possible that he has the re-
sources to measure multiple times the same binary execution and
to reduce noise, computes the mean over each of these execution
traces. Results using this approach are given in Figure 7 in the
Appendix for SVM and NB, which shows a drastic improvement
in many scenarios. For example, NB could reach > 80% for binary
classification and 100% in type and novelty classification. Interest-
ingly, we could not observe an improvement for MLP and CNN,
which is discussed in more detail in the Appendix.
Malware evasion. From our results, one can observe that mal-
ware evasion (i.e. prevention from our methodology) is not straight-
forward. Particularly, we derived that our system is robust against
various code transformation/obfuscation, including random junk
insertion, packing, and virtualization, even when the transforma-
tion is previously not known to the system. Another approach of
evasion, instead of obfuscating malicious behavior, could be to hide
exploitable information by lowering the signal-to-noise ratio. This
could, for example, be achieved by forcing highly parallel/multi-core
executions. However, as our methodology relies on EM emanation,
that can be observed on a local and global scale, and on frequency
transformation with filtering, it is unclear if hiding exploitable
information is (easily) achievable at all. Even more, unexpected
highly parallel/multi-core activities can be more easily detected
as abnormal behavior, which is not in the interest of malware de-
signers. We therefore see the topic of malware evasion against
physical side-channel information as a new open direction with
nonstraightforward solutions.
8 CONCLUSIONS AND PERSPECTIVES
We have demonstrated in this paper that by using simple neural net-
work models, it is possible to gain considerable information about
the state of a monitored device, by observing solely its EM emana-
tions. We were indeed able to not only detect, but also determine
the type of real-world malware infecting a Raspberry Pi running a
full Linux OS, with an accuracy of 99.89% on a test dataset including
20 000 traces from 30 different malware samples (and five differ-
ent benign activities). We demonstrated that software obfuscation
techniques do not hinder our classification approach, even if the
obfuscation technique was not known to the analyst before. Even
more, we showed that it is possible to detect a particular obfuscation
and classify between them (or groups of obfuscation techniques),
and classify the family with its exact variant/obfuscation labels.
Given our experimental results, malware analysts therefore profit
from our robust methodology to gain a better understanding about
the variant, type/family, forensic, and/or evolution of malware
groups and campaigns, particularly in the context when software
systems fail (due to malware evasion) or cannot be applied (due to
restricted resources or update processes on the embedded device).
Another interesting direction could be the investigation of other
architectures and devices, to assess in which measure the knowl-
edge learned by a model on one device can be transferred to another
one. Our work can be considered as a first step towards (detailed)
behavioral analysis through electromagnetic emanation opening a
new research direction for future work.
ACKNOWLEDGMENTS
The work was supported by the French Agence Nationale de la
Recherche (ANR) under reference ANR-18-CE39-0001 (AHMA). We
thank our colleague Ronan Lashermes who provided hardware and
side-channel insights that greatly assisted this work.
REFERENCES
[1] 10 evil user tricks for bypassing anti-virus 2013. https://blog.netspi.com/10-evil-
user-tricks-for-bypassing-anti-virus/.
[2] Amin Azmoodeh, Ali Dehghantanha, Mauro Conti, and Kim-Kwang Raymond
Choo. 2018. Detecting crypto-ransomware in IoT networks based on energy
consumption footprint. Journal of Ambient Intelligence and Humanized Computing
9, 4 (Aug. 2018), 1141–1152. https://doi.org/10.1007/s12652-017-0558-5
[3] Donabelle Baysa, Richard M Low, and Mark Stamp. 2013. Structural entropy and
metamorphic malware. Journal of computer virology and hacking techniques 9, 4
(2013), 179–192.
[4] Richard Bellman. 1957. Dynamic Programming (1 ed.). Princeton University
Press, Princeton, NJ, USA. http://books.google.com/books?id=fyVtp3EMxasC&
pg=PR5&dq=dynamic+programming+richard+e+bellman&client=firefox-a#v=
onepage&q=dynamic%20programming%20richard%20e%20bellman&f=false
[5] Shivam Bhasin, Jean-Luc Danger, Sylvain Guilley, and Zakaria Najm. 2014. NICV:
Normalized Inter-Class Variance for Detection of Side-Channel Leakage. In Inter-
national Symposium on Electromagnetic Compatibility (EMC ’14 / Tokyo). IEEE.
eprint version: https://eprint.iacr.org/2013/717.pdf.
[6] Nikhil Chawla, Harshit Kumar, and Saibal Mukhopadhyay. 2021. Machine Learn-
ing in Wavelet Domain for Electromagnetic Emission Based Malware Analysis.
IEEE Transactions on Information Forensics and Security 16 (2021), 3426–3441.
https://doi.org/10.1109/TIFS.2021.3080510
[7] Shane S. Clark, Benjamin Ransford, Amir Rahmati, Shane Guineau, Jacob Sor-
ber, Wenyuan Xu, and Kevin Fu. 2013. WattsUpDoc: Power Side Channels to
Nonintrusively Discover Untargeted Malware on Embedded Medical Devices.
In 2013 USENIX Workshop on Health Information Technologies (HealthTech 13).
USENIX Association, Washington, D.C. https://www.usenix.org/conference/
healthtech13/workshop-program/presentation/clark
[8] Christophe Clavier, Jean-Luc Danger, Guillaume Duc, M. Abdelaziz Elaabid,
Benoît Gérard, Sylvain Guilley, Annelie Heuser, Michael Kasper, Yang Li, Vic-
tor Lomné, Daisuke Nakatsu, Kazuo Ohta, Kazuo Sakiyama, Laurent Sauvage,
Werner Schindler, Marc Stöttinger, Nicolas Veyrat-Charvillon, Matthieu Walle,
and Antoine Wurcker. 2014. Practical improvements of side-channel attacks on
AES: feedback from the 2nd DPA contest. J. Cryptogr. Eng. 4, 4 (2014), 259–274.
https://doi.org/10.1007/s13389-014-0075-9
[9] Christian Collberg, Sam Martin, Jonathan Myers, Bill Zimmerman, Petr Krajca,
Gabriel Kerneis, Saumya Debray, and Babak Yadegari. [n.d.]. The Tigress C Diver-
sifier/Obfuscator. http://tigress.cs.arizona.edu/index.html
716ACSAC ’21, December 6–10, 2021, Virtual Event, USA
D.P. Pham and D. Marion et al.
2019), 49–58. https://doi.org/10.1109/MSP.2018.2888893
[32] Tobias Schneider and Amir Moradi. 2016. Leakage assessment methodology -
Extended version. J. Cryptogr. Eng. 6, 2 (2016), 85–99. https://doi.org/10.1007/
s13389-016-0120-y
[33] N. Sehatbakhsh, A. Nazari, M. Alam, F. Werner, Y. Zhu, A. Zajic, and M. Prvulovic.
2020. REMOTE: Robust External Malware Detection Framework by Using Elec-
tromagnetic Signals. IEEE Trans. Comput. 69, 3 (2020), 312–326.
[34] Nader Sehatbakhsh, Alireza Nazari, Alenka Zajic, and Milos Prvulovic. 2016.
Spectral profiling: Observer-effect-free profiling by monitoring EM emanations.
In 2016 49th Annual IEEE/ACM International Symposium on Microarchitecture
(MICRO). IEEE, 1–11.
[35] Baljit Singh, Dmitry Evtyushkin, Jesse Elwell, Ryan Riley, and Iliano Cervesato.
2017. On the Detection of Kernel-Level Rootkits Using Hardware Performance
Counters. In Proceedings of the 2017 ACM on Asia Conference on Computer and
Communications Security (ASIA CCS ’17). ACM, New York, NY, USA, 483–493.
https://doi.org/10.1145/3052973.3052999 event-place: Abu Dhabi, United Arab
Emirates.
[36] Xiao Wang, Quan Zhou, Jacob Harer, Gavin Brown, Shangran Qiu, Zhi Dou,
John Wang, Alan Hinton, Carlos Aguayo Gonzalez, and Peter Chin. 2018. Deep
learning-based classification and anomaly detection of side-channel signals. In
Cyber Sensing 2018, Vol. 10630. International Society for Optics and Photonics,
1063006.
[37] Akira Yokoyama, Kou Ishii, Rui Tanabe, Yinmin Papa, Katsunari Yoshioka, Tsu-
tomu Matsumoto, Takahiro Kasama, Daisuke Inoue, Michael Brengel, Michael
Backes, and Christian Rossow. 2016. SandPrint: Fingerprinting Malware Sand-
boxes to Provide Intelligence for Sandbox Evasion. In Research in Attacks, Intru-
sions, and Defenses, Fabian Monrose, Marc Dacier, Gregory Blanc, and Joaquin
Garcia-Alfaro (Eds.). Springer International Publishing, Cham, 165–187.
[38] Alenka Zajic, Milos Prvulovic, Haider Adnan Khan, and Monjur Alam. 2018.
Detailed tracking of program control flow using analog side-channel signals: a
promise for IoT malware detection and a threat for many cryptographic imple-
mentations. In Cyber Sensing 2018, Peter Chin and Igor V. Ternovskiy (Eds.). SPIE,
Orlando, United States, 5. https://doi.org/10.1117/12.2304382
[10] Christian Collberg, Clark Thomborson, and Douglas Low. 1997. A taxonomy of
obfuscating transformations.
[11] Emanuele Cozzi, Mariano Graziano, Yanick Fratantonio, and Davide Balzarotti.
2018. Understanding Linux Malware. In 2018 IEEE Symposium on Security and
Privacy (SP). 161–175. https://doi.org/10.1109/SP.2018.00054 ISSN: 2375-1207.
[12] Fei Ding, Hongda Li, Feng Luo, Hongxin Hu, Long Cheng, Hai Xiao, and Rong
Ge. 2020. DeepPower: Non-intrusive and Deep Learning-based Detection of
IoT Malware Using Power Side Channels. In Proceedings of the 15th ACM Asia
Conference on Computer and Communications Security. 33–46.
[13] Ibraheem Frieslaar and Barry Irwin. 2017. Recovering AES-128 encryption
keys from a Raspberry Pi. In Southern Africa Telecommunication Networks and
Applications Conference (SATNAC). 228–235.
[14] Benedikt Gierlichs, Kerstin Lemke-Rust, and Christof Paar. 2006. Templates
vs. Stochastic Methods. In Cryptographic Hardware and Embedded Systems -
CHES 2006, 8th International Workshop, Yokohama, Japan, October 10-13, 2006,
Proceedings (Lecture Notes in Computer Science, Vol. 4249), Louis Goubin and
Mitsuru Matsui (Eds.). Springer, 15–29. https://doi.org/10.1007/11894063_2
[15] Annelie Heuser and Michael Zohner. 2012.
Intelligent Machine Homicide -
Breaking Cryptographic Devices Using Support Vector Machines. In Constructive
Side-Channel Analysis and Secure Design - Third International Workshop, COSADE
2012, Darmstadt, Germany, May 3-4, 2012. Proceedings (Lecture Notes in Computer
Science, Vol. 7275), Werner Schindler and Sorin A. Huss (Eds.). Springer, 249–264.
https://doi.org/10.1007/978-3-642-29912-4_18
[16] Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2014. An
Introduction to Statistical Learning: With Applications in R. Springer Publishing
Company, Incorporated.
[17] Pascal Junod, Julien Rinaldini, Johan Wehrli, and Julie Michielin. 2015. Obfuscator-
LLVM – Software Protection for the Masses. In Proceedings of the IEEE/ACM 1st
International Workshop on Software Protection, SPRO’15, Firenze, Italy, May 19th,
2015, Brecht Wyseur (Ed.). IEEE, 3–9. https://doi.org/10.1109/SPRO.2015.10
[18] Stefan Katzenbeisser, Johannes Kinder, and Helmut Veith. 2011. Malware Detection.
Springer US, Boston, MA, 752–755. https://doi.org/10.1007/978-1-4419-5906-
5_838
[19] H. A. Khan, N. Sehatbakhsh, L. N. Nguyen, R. L. Callan, A. Yeredor, M. Prvulovic,
and A. Zajic. 2019. IDEA: Intrusion Detection through Electromagnetic-Signal
Analysis for Critical Embedded and Cyber-Physical Systems. IEEE Transactions
on Dependable and Secure Computing (2019), 1–1.
[20] Haider A. Khan, Nader Sehatbakhsh, Luong N. Nguyen, Milos Prvulovic, and
Alenka G. Zajic. 2019. Malware Detection in Embedded Systems Using Neural
Network Model for Electromagnetic Side-Channel Signals. J. Hardware and
Systems Security 3, 4 (2019), 305–318. https://doi.org/10.1007/s41635-019-00074-
w