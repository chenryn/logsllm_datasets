### Non-array Objects
We do not track non-array objects that are not involved in pointer arithmetic, such as `int`-typed objects. Performing bounds checking or untagging for pointers to these objects is redundant. We filter out simple, easily recognizable cases from being checked. In general, determining if a pointer is untagged at compile time is non-trivial, as it requires whole-program static analysis to back-trace the pointer's assignment.

### Safe Pointer Arithmetic
Instead of full bounds checks, we only strip off tags for pointers involved in pointer arithmetic and those statically proven to be in-bounds for simple cases. For pointers where the bounds can be determined statically, we check if the index is smaller than the number of elements. Some SPEC benchmarks contain statically proven out-of-bound accesses, but we do not report memory errors for these, as they may be unreachable. We insert a termination instruction to report errors at runtime when execution reaches the point of the out-of-bound access.

### Hoisting Run-time Checks Outside Loops
Loop-invariant expressions can be hoisted out of loops, improving run-time performance by executing the expression only once rather than at each iteration. We modified SAFECode’s loop optimization passes to apply hoisting checks to monotonic loops, pulling loop invariants and scalars to the pre-header of each loop. This pass works on each loop, handling inner loops first. During each loop iteration, including inner loops, we determine if the pointer is hoistable. If a pointer is hoistable, we place its scalar evolution expression and run-time checks outside the loop, and delete the checks inside the loop.

### Inlining Function Calls in the Loop
Inlining functions can improve performance, but it can also degrade performance due to increased code size (runtime checks are called at every memory access). Currently, we only inline bounds checks inside loops to minimize code size.

### Evaluation
We measured the performance of FRAMER on C benchmarks from Olden [7], Ptrdist [4], and SPEC CPU 2006 [18]. For each benchmark, we measured four binary versions: uninstrumented, store-only checked, full (both load and store checking enabled) on FRAMER, and ASan (one of the most widely used sanitizers). We disabled ASan’s memory leak detection at runtime and halt-on-error to measure overheads in the same setting as FRAMER. Binaries were compiled with LLVM-clang version 4.0 at optimization level -O2. Measurements were taken on an Intel® Xeon® E5-2687W v3 CPU with 132 GB of RAM. Results were gathered using `perf`. Table 2 summarizes the average metrics of the baseline and the two instrumented tests.

#### Memory Overhead
Our metadata header was 16 bytes per object. The large-frame array had 48 elements for each 16-frame division, with each element being 8 bytes to hold the full address of the header. The header size and the number of elements in each division array can be reduced. Currently, we mandate 16-byte alignment for compatibility with the `llvm.memset` intrinsic function. Despite the larger headers and division array entries, FRAMER’s space overheads are low, at 1.22 and 1.23, as shown in Fig. 9. These measurements reflect code inflation for instrumenting both loads and stores.

FRAMER’s memory overheads are low and stable compared to other approaches [32, 39]. ASan’s average normalized overheads are 8.84 for the same working set, with the highest overhead being 4766% for `hmmer`. The average memory overhead of FRAMER is 22% to 23% for both store-only and full checking, with only `perlbench.2` (84%) and `yacr2` (116%) recording higher growth. These tests produce many small-sized objects, such as `perlbench` allocating many 1-byte-sized heap objects. Attaching a 16-byte-sized header to all 1-byte-sized objects increases the overhead. However, FRAMER’s overheads for these benchmarks are still much lower than ASan’s: 2808% for `perlbench.2` and 714% for `yarc2`.

#### Slowdown
Fig. 8 reports the slowdown per benchmark (relative number of additional cycles). The average is 70% for store-only and 223% for full checking. For full checking, `anagram` (410%) and `ks` (452%) stand out for high overheads, mostly due to heavy recursion and excessive allocations causing a significant increase in executed instructions (674% for `anagram`, 812% for `ks`). However, cache misses are moderately decreased (76% for `anagram`, 81% for `ks`) compared to the average (decreased by 63%). Conversely, `mcf` recorded the highest instruction overheads (1097%), but the largest decreases in cache (91%) and branch misses (92%) among all tests, so the runtime overhead did not grow proportionally with the increased instruction count. `perlbench` and `bzip` sets’ overheads are high in both FRAMER and ASan, producing many objects, especially `bzip` with much higher growth in executed instructions.

Performance was impacted less than expected from the additional dynamic instruction count (metric columns 2 and 3 in Table 2). The rise in IPC (column 4) is considerable on average, although the figure varies greatly by benchmark. The original IPC ranged from 0.22 to 3.20, but after instrumentation, there was half as much variation.

The slowdown is mainly due to increased dynamic instructions to calculate metadata location. We measured runtime overheads for metadata management/retrieval (excluding bounds checking) of benchmarks with the highest runtime overheads by forcing or preventing inline hooks. As shown in Fig. 10, the fluctuations in proportion are negligible. Benchmarks with low runtime overheads showed a similar pattern.

Slowdown is dominated by Calculation (69.66%)—ALU operations to derive the header address at memory access and generate a tag at memory allocation. Hardware acceleration in a future ISA would largely resolve this overhead. We isolated tag-cleaning from Calculation to show the cost of using tagged pointers without hardware support. Its cost (6.07%) would be removed on current ARM that ignores top spare bits. The cost of generating tags was negligible, as it is performed only at allocation.

The remaining 3 components cannot be resolved with simple ISA changes. Branch checking for tagged/untagged and small/large-framed contributes 10.19% of the total overheads of metadata management. Current FRAMER encoding avoids any restriction on object alignment, but we are open to manipulating the memory manager to remove large-framed objects in future designs. Accessing a header takes more time than accessing an entry, contributing around 25% of the overhead of metadata management and retrieval.

The remaining part of the total runtime overhead, not included in the measurement shown in Fig. 10, is bounds checking performing arithmetic operations with loaded metadata, which can be resolved by ISA.

#### Data Cache Misses
One of the goals of FRAMER is to allow flexible relationships between object and header locality to minimize additional cache misses from metadata access. We do not analyze L1 instruction cache miss rate, as it generally has a negligible performance effect on modern processors, despite our slightly inflated code. To explain the measured increase in IPC, we analyze L1 D-cache misses.