Non-array Objects. We do not track non-array objects that are
not involved with pointer arithmetic, e.g., int-typed objects. It is
redundant to perform bounds checking or untagging for pointers
to them. We filter out simple cases, easily recognised, from being
checked. In the general case, it is not trivial to determine if a pointer
is untagged at compile time, since back-tracing the assignment for
the pointer requires whole-program static analysis.
Safe Pointer Arithmetic. Instead of full bounds checks, we only
strip off tags for pointers involved in pointer arithmetic and stati-
cally proven in-bound for simple cases. For pointers where the
bounds can be determined statically, we checks if the index is
smaller than the number of elements.
In some SPEC benchmarks, there are statically proven out-of-
bound accesses, but we do not report memory errors since they
may be unreachable. We inserted a termination instruction for this
case so that it can report errors at runtime, when the execution
reaches the point.
Hoist Run-time Checks Outside Loops. Loop-invariant expressions
can be hoisted out of loops, thus improving run-time performance
by executing the expression only once rather than at each iteration.
We modified SAFECode’s [12, 41] loop optimisation passes. We
apply hoisting checks to monotonic loops, and pull loop invariants
that do not change throughout the loop, and scalars to the pre-
header of each loop. This pass works on each loop and if there
are inner loops, it handles them first. While iterating our run-time
checks inside each loop including inner loops, we determine if the
pointer is hoistable. If a pointer is hoistable, we place its scalar
evolution expression along with its run-time checks outside the
loop, and delete the checks inside loop.
Inlining Function Calls in the Loop. Inlining functions can im-
prove performance, however it can bring more performance degra-
dation due to the bigger size of the code (runtime checks are called
basically at every memory access). Currently, we only inline bounds
checks that are inside loops to minimise code size.
7 EVALUATION
We measured the performance of FRAMER on C benchmarks from
Olden [7], Ptrdist [4], and SPEC CPU 2006 [18]. For each bench-
mark we measured four binary versions: uninstrumented, only
store-checked and full (both load and store checking enabled) on
FRAMER, and ASan – one of the most widely used sanitizers. We dis-
abled ASan’s memory leak detection at run-time and halt-on-error
to measure overheads in the same setting as FRAMER. Binaries
were compiled with the regular LLVM-clang version 4.0 at opti-
misation level -O2. Measurements were taken on an Intel® Xeon®
E5-2687W v3 CPU with 132 GB of RAM. Results were gathered
Table 2: Summary averages over all benchmarks (first three columns normalised)
Memory
footprint
1.00
1.22
1.23
Runtime
(cycles)
1.00
1.70
3.23
Dynamic
instructions
1.00
2.24
5.25
IPC
1.70
2.17
2.54
Load
D-cache
density MPKI
0.28
24.85
12.27
0.20
0.14
5.28
Branch
B-cache
density MPKI
0.19
2.85
1.34
0.15
0.17
0.86
Baseline
Store-only
Full check
Myoung Jin Nam, et al.
using perf. Table 2 summarises the average of metrics of the
baseline and the two instrumented tests.
In this text, cache and branch misses refer to L1 D-cache misses
and branch prediction misses both per 1000 instructions (MPKI),
respectively.
7.1 Memory Overhead
Our metadata header was a generous 16 bytes per object. The large-
frame array had 48 elements for each 16-frame (division) in use
where the element size was 8 bytes to hold full address of the header.
The header size and the number of elements of each division array
can be reduced. Currently we mandate 16 alignment for compati-
bility with the llvm.memset intrinsic function that sometimes
assumes this alignment. Despite inflation of space using larger
than needed headers and division array entries and some changes
of alignment, we see FRAMER’s space overheads are very low at
1.22 and 1.23 as shown in Fig. 9. These measurements reflect code
inflation for instrumenting both loads and stores.
The memory overheads of FRAMER are low and stable com-
pared to other approaches [32, 39]. ASan’s average normalised
overheads are 8.84 for the same working set in our experiments,
and the highest overhead is 4766% for hmmer. The average mem-
ory overhead of FRAMER is 22% ∼ 23% for both store-only and full
checking, and only two tests, perlbench.2 (84%) and yacr2
(116%) recorded comparably higher growth than other tests. The two
tests produce many small-sized objects, for example, perlbench
allocates many 1-byte-sized heap objects. Currently FRAMER in-
struments every heap object, so attaching a 16-byte-sized header
to all the 1-byte-sized objects made the increase higher. FRAMER’s
overheads for those benchmarks are still much lower than ASan’s:
2808% for perlbench.2 and 714% for yarc2.
7.2 Slowdown
Fig. 8 reports the slowdown per benchmark (relative number of
additional cycles). The average is 70% for store-only and 223% for full
checking. For full-checking, anagram (410%) and ks (452%) stand
out for high overheads despite its smaller program size, mostly due
to heavy recursion and excessive allocations causing big growth
in executed instructions (674% for anagram, 812% for ks) as
shown in Fig. 12, but decreases in cache misses are moderate (76%
for anagram, 81% for ks) compared to average (decreased by
63%). On contrast, mcf recorded the highest instruction overheads
(1097%), but cache (91%) and branch misses (92%) are dropped the
biggest among all the tests, so run-time overhead did not grow
in proportion to increased instruction count. perlbench and
bzip sets’ overheads are high in both FRAMER and ASan. Both
tests produce many objects, and especially bzip recorded much
higher growth in executed instructions than perlbench and
others.
Performance was impacted far less than would naively be ex-
pected from the additional dynamic instruction count (metric columns
2 and 3 in Table 2). The rise in IPC (column 4) is quite considerable
on average, although the figure varies greatly by benchmark. The
original IPC ranged from 0.22 to 3.20 but after instrumentation
there was half as much variation.
Our slowdown is mainly due to increased dynamic instructions
to calculate metadata location. We measured runtime overheads
for metadata management/retrieval (excluding bounds checking)
of benchmarks with the highest runtime overheads by forcing or
preventing inline our hooks. As shown in Fig. 10, the fluctuations in
proportion is negligible. Benchmarks with low runtime overheads
showed a similar pattern.
Slowdown is dominated by Calculation (69.66%) – ALU oper-
ations to (1) derive the header address at memory access and (2)
generate a tag at memory allocation. Hardware acceleration in a
future ISA would largely resolve this overhead. We isolated tag-
cleaning from Calculation to show the cost of using tagged pointers
without hardware support. Its cost (6.07%) would be removed on
current ARM that ignores top spare bits. The cost of generating
tags was negligible, since it is performed only at allocation.
The remaining 3 components cannot be resolved with simple
ISA changes. Branch checking for tagged/untagged and small/large-
framed contributes 10.19% of the total overheads of metadata man-
agement. Current FRAMER encoding avoided any restriction on
object alignment, however, we are open to manipulate memory
manager to remove large-framed objects for the future design. Ac-
cessheader and Accessentry represent ratios of overheads to access
a header and entry, once their addresses are calculated from tagged
pointers. Accessing a header takes more time than accessing an
entry, since it is performed on both types of objects. Excluding the
overhead of arithmetic operations, the cost is around 25% of that of
metadata management and retrieval.
The remaining part of the total runtime overhead that is not
included in the measurement shown in Fig. 10 is bounds checking
performing arithmetic operations with loaded metadata, which can
be resolved by ISA.
7.3 Data Cache Misses
One of the goals of FRAMER is to allow flexible relationships be-
tween object and header locality to minimise additional cache
misses from metadata access. We do not analyse L1 instruction
cache miss rate since this generally has negligible performance
effect on modern processors, despite our slightly inflated code. To
explain the measured increase in IPC we analyse L1 D-cache misses
FRAMER: A Tagged-Pointer Capability System with Memory Safety Applications
Store-only
Full
ASan
6
4
2
0
10
5
2
1
h
b
r
o
b i s
e m 3
a l
e
h
t
m s
r i
e
p
o w
p
a
e
e
r
t
p
s
t
o
r
o
v
g
a
n
a
c
b
ft
s
k
r
c
a
y
r l 1
e
p
r l 2
e
p
r l 3
e
p
r l 4
e
p
1
z i p
b
2
z i p
b
3
z i p
b
c
c
g
f
m c
h m m s j e
g
n
q
l i b
4
6
2
h
Figure 8: Normalised runtime overheads
14.0 20.3
16.6
15.1 29.1 12.5
17.5
48.7
17.1
h
b
o
b i s
e m 3
a l
e
h
t
m s
r i
e
p
o w
p
e
e
r
t
p
s
t
o
r
o
v
g
a
n
a
c
b
ft
s
k
r
c
a
y
r l 1
e
p
r l 2
e
p
r l 3
e
p
r l 4
e
p
1
z i p
b
2
z i p
b
3
z i p
b
c
c