stances of the attacks to be dropped before they compromise
the integrity or availability of the protected process.
2.1 Behavior Model
Our approach is based on inferring program context that can
be used in making ﬁltering decisions. We employ a program
behavior model to guide the search for useful program con-
text. Many of the recent approaches for extracting automata
models of programs [9, 10, 28, 35] can potentially be used
for this purpose. We have used the ﬁnite-state automaton
(FSA) technique of [28] due to its simplicity.
Figure 2 illustrates the FSA approach. The FSA model
is very similar to a control-ﬂow graph of a program. How-
ever, the FSA only captures security-sensitive operations
(S1 through S5 in the ﬁgure) made by the program, while
leaving out the details of its internal computation. The states
in the FSA correspond to program locations (i.e., memory
addresses) from which these operations are invoked, while
the edges are labeled with operation names. (For readabil-
ity, line numbers are used in place of memory addresses in
Figure 2.) There is an edge from a state L1 to state L2 in
the FSA labeled with the call e whenever the program in-
vokes e from location L2, and the previous call made by
the program was from location L1. We point out that such
an FSA model can be constructed from the sequence of li-
brary calls intercepted by our system, without any access to
source code. (Further details about the learning technique
can be found in [28].)
2.2 Logger
The logger records information regarding intercepted oper-
ations for subsequent use by the analyzer. Following infor-
mation is logged in our current implementation: the call-
ing context for the operation, which includes the set of
all callers on the runtime stack at the point of call; return
code from the operation; and the values of integer-type ar-
guments. For input operations, the fraction of binary (i.e.,
non-ASCII) characters in the input is also logged.
Since the logger operates within the process space of the
protected server, a server crash can lead to loss or corruption
of buffered log data. To protect against this possibility, the
logger ﬂushes the buffer after each input operation.
2.3 Input Filter
Signatures generated by ARBOR are deployed within the
input ﬁlter. Any input that matches a deployed signature
will be dropped, and an error code of (cid:0)1 returned to the
process. The external variable errno is set to EIO to indi-
cate an input/output error. Since servers are built to expect
network errors, they invoke appropriate recovery actions to
quickly (and fully) recover from the error and proceed to
process the next request.
If a server uses TCP, reporting an error to the server with-
out notifying the client may lead to inconsistencies caused
by violation of reliable message delivery semantics of TCP.
To avoid this problem, the input ﬁlter closes the TCP con-
nection on which the bad input was received. (ARBOR can
determine whether a ﬁle descriptor is associated with a net-
work connection using fstat and getsockopt calls.)
2.4 Detector
The detector monitors the execution status of the protected
process. On an intrusion attempt, it raises an alert and ter-
minates the process. Our approach uses an existing tech-
nique, address space randomization (ASR)
[3], to imple-
ment the detector. With ASR, the addresses of all program
objects (including code and data objects) are randomized.
All buffer overﬂow attacks reported so far have been based
on overwriting pointer values, e.g., the return address on the
stack. Due to ASR, the attacker does not know the value to
be used for the overwrite, as she does not know the location
of any of the objects (e.g., the code injected by the attacker)
in memory. As a result, attacks cause programs to crash due
to invalid memory access.
Note that ASR itself needs to be deployed within the pro-
tected process. The detector component shown in Figure 1
does not denote ASR, but an external process that intercepts
signals received by the protected process. In our implemen-
tation, it uses the ptrace mechanism in Linux. When the
detector intercepts a memory access related signal (SIGBUS,
SIGSEGV and SIGILL), it reports an attack.
Note that ASR interacts with the FSA behavior models
in some ways. In particular, since the base addresses of var-
ious code segments are randomized, the absolute memory
locations associated with the FSA states will change from
one execution of the server to the next. To compensate for
this, the FSA technique needs to decompose each memory
address into a pair (name; of f set), where name identiﬁes
the segment (e.g., the name of an executable or a shared
library) and of f set denotes the relative distance from the
base of this segment. By the nature of ASR described in
[1, 3], this quantity remains invariant across all executions
of an ASR-protected server.
2.5 Analyzer
The analyzer generates signatures to distinguish attack-
bearing inputs from benign ones. The two main aspects of
signature generation in ARBOR are discussed below.
2.5.1 Obtaining Context Information
ARBOR relies on two types of contexts: current context and
historical context. The current context for an input opera-
tion captures the calling context for that operation. It helps
distinguish among different input operations used by a pro-
gram. For example, in Figure 2, even if S4 and S5 are both
read operations, their purpose may be different, as they are
invoked from different parts of the program. In our imple-
mentation, current context is deﬁned by the program loca-
tion from which the input operation is performed (which is
the same as the state of the FSA model), and a sequence
of return addresses (up to 20 in our implementation) on the
top of the program’s stack. Moreover, instead of explicitly
remembering the list of all callers, we compute and use a
single 32-bit hash-value from them. (Recall that in order to
cope with ASR, all absolute addresses are decomposed into
(segment; of f set) pairs before they are used.)
Historical context takes into account the FSA states that
precede an input operation. The rationale for using histori-
cal context is as follows. Often, network protocols involve
a sequence of steps. An attack may be based on sending an
unexpected sequence of messages, where each message, in
isolation, is indistinguishable (to ARBOR) from legitimate
messages previously seen. Historical context enables us to
utilize program context information across these steps, and
hence recognize unexpected sequences of messages.
In addition to providing the ability to handle truly multi-
step attacks, historical context also helps ARBOR handle
some cases where the attack is really delivered in the last
step, while all previous steps are legitimate. Typically, this
happens due to the fact that a server program performs all its
input actions from a single location, regardless of the type of
request being read. This can happen with a server that uses
“wait-read-process” loop structure, where the server waits
for the availability of any input, and then uses a read call to
read the entire input in one step into an internal buffer, and
then uses internal code to parse the contents of this buffer
and carry out the request. Since the current context remains
the same for all input operations made by such servers, all
types of messages will be lumped together into a single cat-
egory, thereby decreasing the likelihood of deriving a length
or character distribution based signature. This problem can
be mitigated using historical context. Speciﬁcally, note that
even though all input actions occur from the same program
location, the processing of these requests is almost sure to
be carried out by different functions, or more generally, dif-
ferent sections of code. It is also quite likely that the pro-
cessing step will involve one or more function calls that
are intercepted by ARBOR, thereby allowing it to distin-
guish between different types of messages. Now, consider a
server protocol where a message M1 is always followed by
a message of type M2 or M3. Although ARBOR cannot tell
whether it is M2 or M3 at the time of reading the message,
historical context seen during the processing of request M1
enables it to avoid confusing these two types of messages
with other message types. This factor, in turn, can enable
signature discovery.
2.5.2 Synthesizing Signatures
Inputs received closest to the time of detection are the ones
most likely to be attack-bearing. For this reason, the sig-
nature generation algorithm searches for a suspect input in
the reverse temporal order among recent inputs. (ASR typ-
ically detects attacks within a millisecond timeframe, so
the search can be limited to the previous 10ms for most
servers.) This search is carried out in two stages. The ﬁrst
stage uses current context. If this fails, a historical context
is used in the second stage.
In the ﬁrst stage, the analyzer ﬁrst identiﬁes the current
context for each recent input, and compares the input length
and binary character percentage for this context with all the
past inputs received in the same context. To speed up this
process, the FSA model already stores the maximum input
size and maximum fraction of binary characters seen among
all previous benign input actions in the same context. As a
result, ARBOR generates current context based signatures
within 10ms.
Unlike current context, an input operation can have mul-
tiple historical contexts. Part of signature discovery is to
identify the particular historical context that yields the best
signature. In general, a historical context can represent a
path in the FSA, but for simplicity, we have limited our cur-
rent implementation to refer to just a single context that pre-
cedes an input operation by k steps, for some k > 1. Our
technique starts with k = 1, and keeps incrementing k until
a historical context that can distinguish benign inputs from
attack input is identiﬁed, or k exceeds a certain threshold
(20 in our implementation). Note that this search requires
an examination of the information about previous benign
inputs that was recorder by the input logger.
After an input I is identiﬁed as malicious under a con-
text C, if its size a is signiﬁcantly larger than the maximum
size bmax of benign inputs seen so far in C, then a size-
based signature is generated.
Initially, the signature may
specify a size threshold of a (cid:0) 1 in order to minimize the
likelihood of false positives. However, such an approach
can be exploited by an attacker to send a series of attacks
of successively smaller size, requiring our system to gener-
ate many signatures. To tackle this problem, the approach
can be made more adaptive, e.g., by setting a threshold of
max(a (cid:0) 2k; bmax + 1) after k attack attempts. Signature
generation based on percentage of binary characters is done
in a similar way. The format of signatures is as follows:
At @(name, offset, hash)
[Distance  @(name,
offset, hash)]
[Size ] [Bin% ]
“At” and “Distance” specify the program context;“Size”
and “Bin%” specify the conditions characterizing an attack.
We illustrate signature formats with two examples.
(cid:15) At read@(S1,0xBFE0,0x3A4561FE) Bin% 0
Meaning: if a read operation is invoked from the S1 seg-
ment of the program at offset 0xBFE0 (from the base of
this segment), and the set of return addresses on the stack
hash to the value 0x3A4561FE, and the fraction of non-
ASCII characters in the input returned by this read is
non-zero, it needs to be dropped.
(cid:15) At read@(S2,0xB2FE,0xF3928621)
Distance 5 time@(S2,0x2CD0,0x9823A53B) Size 500
Meaning:
if a read operation is invoked at offset
0xB2FE in S2 segment of the program, and the set of re-
turn addresses on the stack hash to the value 0xF3928621,
and if time function was called from offset 0x2CD0 of
the same segment ﬁve steps earlier, and the return ad-
dresses on the stack hash to the value 0x9823A53B, an
input larger than 500 bytes must be dropped.
3 Evaluation
In this section, we experimentally evaluate the effectiveness
of ARBOR, its runtime overheads and availability. All ex-
periments were carried out on Red Hat Linux 7.3, except
those on lshd which used Red Hat Linux 8.0. Finally we
discuss false positives and false negatives.
3.1 Effectiveness in Signature Generation
In this evaluation, our focus was on real-world attacks.
Since developing exploit programs involves signiﬁcant
amount of effort, we limited our selection to attacks with
working exploit code available on our OS platform, Red
Hat Linux. We selected eleven such programs shown in Fig-
ure 3. Six of them were chosen because they were widely
Program
Vulnerability
Effective?
wu-ftpd
apache ssl
ntpd
ircd
lshd
gtkftpd
samba
epic4
cvs
passlogd
oops
CVE-2000-0573
CAN-2002-0656
CVE-2001-0414
CAN-2003-0864
CAN-2003-0826
BugTraq ID 8486
CAN-2003-0201
CAN-2003-0328
CAN-2004-0396
BugTraq ID 7261
CAN-2001-0029
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
Yes
No
Attack
Length
Max Benign Input size
All
Contexts
Current Historical
Context
Context
Attack to
Benign
Size Ratio
Attack to
Benign
BIN% Ratio
473
419
500
490
5025
260
2080
1024
1024
916
1392
8192
815
1024
8191