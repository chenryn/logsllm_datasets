Bundle ID
Device Brand
User-Agent (UA) The user agent of the http request
Description
Source IP
A globally unique id of the requested ad slot
IMEI MD5 value
Android ID raw/MD5 value
IDFA MD5 value
Operating system of the device
Real-time GPS coordinates of the device
The time when the request was sent
Bundle ID of the app generating the request
The brand of the device
Table 2: Datasets used in this paper; ⇡CA08= and ⇡C4BC are extracted from ⇡2020.
Name Labeled? Devices
B
Used in Purpose
Log
Duration
Fraudulent devices measurement
Sec. 4
Sec. 6 Training of EH
EH evaluation
Sec. 6
Click farm investigation
Sec. 7
Backtracking the largest click farm;
Cheating strategy investigation
Sec. 7
Sec. 8
In-the-wild detection & validation
⇡2020
⇡CA08=
⇡C4BC
⇡2018
⇡2019
⇡2021
Y
Y
Y
N
N
N
F
2M 0.2M 82M May 6 - June 5, 2020
120k 113k 4.3M May 6 - May 15, 2020
125k 124k 4.9M May 16 - May 25, 2020
290M
63M
53M
290M Mar 21 - Mar 30, 2018
63M Mar 6 - Mar 15, 2019
117M
Jan 13, 2021
and IDFA. All of them are hashed by MD5. IMEI and Android ID
are used in Android devices while IDFA is for iOS devices. The OS in-
dicates the operating system of the mobile device, either Android or
iOS. The Location represents the device’s geo-location at the time
of ad request generation. The Timestamp refers to the time when
the request is sent. The Bundle ID indicates from what app the ad
request is originated. The Device Brand represents the brand of
the device. The User-Agent (UA) refers to the user agent of the
ad HTTP request. All the elds, except for IP and Timestamp, are
reported in ad request parameters by the app.
3.2 Overview of Datasets
We use 6 dierent datasets in this paper, which are described in
Table 2. All the datasets contain ad bid logs generated by mobile
devices during a certain period. Here we briey introduce each
dataset, and more details will be provided in later sections where
they are in use.
J2020. ⇡2020 is a labeled dataset containing ad bid request logs
recorded from May 6, 2020, to June 5, 2020. The dataset contains
82 million logs, generated by 2 million fraudulent devices and 0.19
million benign devices. We use it as a ground-truth dataset tond
distinct features for fraudulent devices (Sec. 4).
Jtrain and Jtest. ⇡CA08= and ⇡C4BC are extracted from ⇡2020. They
serve as a training set and a test set for the evaluation of E
H (Sec. 6). Moreover, ⇡C4BC is used to perform click farm
investigation in Sec. 7.
J2018 and J2019. After identifying a few click farms in ⇡C4BC, we
pick the largest click farm and trace back to two 10-day datasets
in 2018 and 2019 to identify devices that share the same charac-
teristics (Sec. 7). These click farm-related devices in 2018 and 2019
form ⇡2018 and ⇡2019. We use these two datasets to investigate the
general cheating strategies of click farms (Sec. 7).
J2021. To evaluate the practicality to deploy EH in the
real world, we use ⇡2021 as a validation dataset, which contains
1-day’s data without labels in 2021.
Ground-truth labels. In ⇡2020, the fraudulent devices are col-
lected from a distributed blockchain system, where a group of lead-
ing industrial trac verication companies work together to report
highly suspicious devices. They identify the suspicious devices with
auxiliary information collected by their own SDKs. Each of these
companies regularly uploads fraudulent device information found
by itself to this blockchain platform for majority voting: one device
is deemed to be fraudulent if more than two members upvote it,
and it will be added to the blacklist. Each blacklisted device will be
blocked by them for several months, until being removed from the
blacklist after a certain time. On the other hand, benign devices are
collected by Company A using some incentives to encourage users
to upload some evidence (e.g., photos of surroundings) to prove that
they are human. These pieces of evidence are examined by Com-
pany A manually to ensure that they are real. Both fraudulent and
benign devices are double-checked by Company A’s commercial
rule-based system, which takes into consideration other aspects of
the devices, such as the account activeness of the device in social me-
dia, the physical trace of the device. We extract the involved ad bid
logs of the fraudulent devices and benign devices as dataset ⇡2020.
4 MEASURING FRAUDULENT DEVICES
Ad bid requests not only record the ad transaction history between
the organic (benign) users but also serve as snapshots of evidence
related to ad fraud. This provides us with the opportunity to capture
the fraudulent devices and screen out the invalid trac. In this
section, we rst use a real-world ad bid log dataset (⇡2020) to study
the features of fraudulent devices. These measurement results serve
as the basis of EH. It is observed that fraudulent devices
exhibit dierent patterns, e.g., they are likely to adopt more IPs to
generate ad bid requests for one or two ad slots. Here we take several
examples to show the dierences between fraudulent devices and
benign devices as shown in Fig. 3.
Statistical Number: # unique IP addresses.
Observation 1: Fraudulent devices bind to more IP addresses.
The numbers of unique IP addresses used by fraudulent devices and
benign devices are shown in Fig. 3a. As seen from Fig. 3a, fraudulent
devices bind to more IPs than benign ones. 67.9% of benign devices
use 1 IP address, and 4.9% of them use more than 10 dierent IP
addresses. In contrast, 48.0% of fraudulent devices use more than 5
dierent IP addresses and 3.5% of them correspond to 50 dierent
IPs. This phenomenon is perhaps due to the extensive usage of
commercial residential IP proxy services, well aligned with the
previous study [25].
Entropy: ad slot IDs.
Observation 2: Fraudulent devices have lower ad slot entropy.
We compare the entropy of ad slot IDs in Fig. 3b. As shown in Fig. 3b,
91.9% of fraudulent devices have an entropy of 0, meaning that they
only had one unique ad slot ID. Intuitively, the fraudulent devices
target the specic ad slot ID to make prots. However, benign de-
vices usually request more than one ad slot IDs to enjoy the various
Session 1D: Authentication and Click Fraud CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea290(a) # of unique IPs.
(e) Android OS version.
Figure 3: The comparison of dierent features between fraudulent devices and benign devices in ⇡2020. The lines in Fig. 3b and
Fig. 3c represent kernel density estimations across devices.
(b) Entropy of ad slot IDs.
(c) Active hours per day.
(d) # of device brands.
services. This leads to an interesting phenomenon that benign users
have a higher value in terms of ad slot entropy. It is observed that
there are 41.9% benign devices with an entropy larger than 0.5, in
contrast to the fraudulent devices with the proportions of 2.2%.
Temporal: active hours.
Observation 3: Fraudulent devices are more active.
We extract the active hours for the devices in both labels. From
Fig. 3c, we can learn that most of the benign devices (99.9%) have
less than 12 active hours per day in the dataset. In contrast, there
are 11.0% of the fraudulent devices being active for more than 15
hours per day in the dataset. Even worse, 1.5% of them are active
for more than 20 hours per day, which is unbelievable for humans.
The potential reason behind this is that the attackers exhibit a high
incentive to generate more invalid trac within a specic period
to gain more economic revenue.
Inconsistency: # device brand names.
Observation 4: Fraudulent devices use multiple brand names while
benign devices usually use one brand.
The number of device brands is shown in Fig. 3d. More than 95% of
benign devices only used one brand name regardless of the datasets;
only 16.8% used two brand names. However, 16.8% of fraudulent
devices used two brand names; roughly 5.6% of them used more
than 5 brand names. More brands for fraudulent devices may occur
when attackers frequently change the device’s brand in lieu of
device IDs.
Android version.
Observation 5: Fraudulent Android devices run lower OS versions.
As shown in Fig. 3e, we observe that fraudulent devices are in-
stalled on lower Android versions in comparison to benign devices.
9% (resp. 84%) of fraudulent (resp. benign) devices are on Android
8, 9, and 10. 79.7% of fraudulent devices are running Android 4 or
lower, which is not installed by any benign devices in 2020. Hence,
we conclude that fraudulent devices run lower Android versions
than benign devices do. The potential reasons are two-fold: (i) Us-
ing Android phones on lower versions is more cost-eective for
attackers to mount a larger scale mobile ad fraud campaign. (ii)
The phones with earlier Android versions are much easier to gain
full access to the root permission, enabling fraudulent tasks such
as auto-clicking with ease. This resonates with the fact that some
mobile phone manufacturers (such as Huawei) ban users from un-
locking the bootloader on high Android version devices, serving as
a requisite for root access acquisition [44].
5 EVILHUNTER
In this section, we present the detailed design and implementation
of EH. The basic insight of EH is contingent on
the cluster-level features rather than any individual device features
to identify the fraudulent devices. The main goal of EH is
to detect malicious device clusters (click farms) besides identifying
fraudulent devices.
In general, EH is comprised of three stages (see Fig. 4).
1) In the classication stage (Stage 1), based on a series of features
discussed in the previous section, EH designs a device
classier to distinguish fraudulent devices and benign devices by
exploiting the features extracted from the ad bid logs; 2) In the
clustering stage (Stage 2), EH proposes a Top-App based
Clustering Algorithm, which builds the device graph based on the
connectivity features among devices, and then identies the closely
connected device clusters. 3) In the aggregation stage (Stage 3),
we classify each cluster by performing majority voting based on
the device labels within the cluster and then relabel the devices
based on the cluster’s classication result, i.e., all devices inside a
fraudulent cluster will be labeled as fraudulent. The output of E
H is ([id], label) pairs, indicating which devices are grouped
into clusters and whether these clusters are fraudulent or benign.
5.1 Stage 1: Classication
The device classier stage is a general machine learning classica-
tion process. The input is a bunch of ad bid logs while the output
is the predicted score B34E for each device, ranging from 0~1. 0
means a high condential benign score of a device and 1 means
a fraudulent one. Device classier consists of three components:
Log-Device Mapper, Device Feature Extractor, and Device Score Predictor.
Module 1.1: Log-Device Mapper. Log-Device Mapper constructs the
log-device mapping from the ad bid logs. It then takes the ad bid
logs as input and outputs a device-log mapping M, which maps each
device ID (id) to the corresponding logs generated by this device.
To retrieve the unique id for each device, given an Android device,
Log-Device Mapper uses the combination of the MD5 values of IMEI
and Android ID. Since both IMEI and Android ID may be an empty
value caused by strict permission control enforcement, we use a
combination of them to cover more devices in the ecosystem. On
the other hand, since Apple restricts the tracking for iOS devices:
all iOS apps must have a user’s permission to access their IDFAs
after iOS 14.5 [7], and therefore the detection of invalid trac for
iOS devices is beyond the scope of this paper.
Module 1.2: Device Feature Extractor. The Device Feature Extractor
extracts representative features that can reect the characteristics
00.10.20.30.40.50.60.70.80.91.0Ad Slot Entropy0102030405060708090100Percentage%Benign Device Fraudulent DeviceSession 1D: Authentication and Click Fraud CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea291Figure 4: The workow of EH.
Table 3: Features extracted by Device Feature Extractor.
Feature Categories
(a) Statistical Features
Feature Name
Number of logs
Number of unique IP addresses
Number of unique ad slot IDs
Log entropy
IP entropy
Ad slot ID entropy
Maximum speed
Number of brands
Fake brand ratio
Non-browser UA ratio
(b) Entropy Features
(c) Spatial-Temporal Features Number of active hours
(d) Inconsistency Features
of fraudulent devices. To achieve this, we dened 11 features that
capture the nature of fraudulent devices covering all the elds of the
ad bid logs (Table 1), and group these features into four categories
(Table 3). These features are extracted as follows.
(a) Statistical features. Device Feature Extractor extracts the statistical
features of a device, including the number of log entries, unique IP
addresses, and unique ad slot IDs. Intuitively, all these numerical
features should be within a certain range, since a normal user
cannot use too many dierent IP addresses or generate too many
ad requests.
(b) Entropy features. Device Feature Extractor calculates the entropy of
the three features shown in category (b) in Table 3, which measures
the uncertainty of the features: higher entropy indicates higher un-
certainty. Device Feature Extractor adapts the normalized entropy [29]
to compute the features as follows:
[(-) =  
=’8=1
?(G8) log2(?(G8))
log2(#)
,
(1)
where G1, . . . ,G = are = possible results of a feature - (e.g., IP ad-
dress); ?(G8) is the ratio of G8 in all # logs generated by this device.
Device Feature Extractor applies Eqn. 1 on logs, IPs, and ad slot IDs
to compute the normalized entropy for them.1 Note that if # = 1,
[(-) = 0.
(c) Spatial-temporal features. Spatial-temporal features are broken
down to a given device’s active hours and the maximum moving
speed. The number of active hours for a device is the total quantity
of hours when there was at least one ad bid request sent during that
hour. To compute the maximum speed, for each device, Device Fea-
ture Extractor uses the location and timestamp elds to compute
the average speed between every two consecutive ad bid requests
in the logs and selects the maximum value. To avoid the inuence
of default location values, we ignore those values including (0,0)
and high-frequency locations far away from the target area.
(d) Inconsistency features. Inconsistency features aim to capture the
inconsistencies in the logs. The rst feature in the category (iv) is
the number of device brands for each device. Normally, a device
should only have one brand name. So if a device has too many
brand names, it may be a signal of fraud. However, the brandelds
of a device may be incorrectly reported by app developers in the
ad request parameter; to address this issue, Device Feature Extractor
extracts another feature, called fake brand ratio, to measure the ratio
of fake brands for each device. Device Feature Extractor compares the
brand names with two whitelists obtained online,2 which contain
269 real brand names. If a brand does not appear in any of the two
whitelists, Device Feature Extractor considers it as fake. The third
feature is the non-browser User-Agent ratio. Normally, the UA
eld in a log reects the Browser or Webview information of the
OS running on the device. The UA is either ‘Mozilla’ or ‘Dalvik’.
However, for fraudulent devices, the UA may be forged (e.g., ‘Go-
http-client’), as it is not a real device. Therefore, Device Feature
Extractor uses the non-browser UA ratio as a feature.
Module 1.3: Device Score Predictor. The Device Score Predictor uses
traditional machine learning models to perform the training and
testing on the features. Particularly, any feature-based classier (e.g.,
logistic regression, decision tree, kNN, SVM, and neural network)
may potentially be used. However, we note that deep learning is
hard to interpret the semantics (or representation) of the features
extracted by Device Feature Extractor. In summary, the output of
Device Score Predictor is the predicted score B34E for every device.
5.2 Stage 2: Top-App Based Clustering
In Sec. 5.1, we have proposed a novel classier to distinguish fraud-
ulent devices from benign ones based on the ad bid logs. However,
in practice, such individual classication results may be aected by
the noisy data or the intentional manipulations of the attackers. To
address this problem, in Stage 2, we group the devices into various
clusters and then exploit the cluster-level features to determine