vector x, namely:
(
m∏
f (x | n; (cid:14)) =
ni!
xi!(ni − xi)!
i=1
)
(1 − (1 − (cid:14))i)xi (1 − (cid:14))i(ni(cid:0)xi)
(7)
The model represented by Equation 7 comprises a family
of probability density functions that are indexed by (cid:14), given
that data vectors x and n lie in the data sample under sta-
tistical analysis. Recall that the data sample consists of a
small random selection of nodes along with speciﬁcations of
whether or not those nodes are positive. Thus, diﬀerent val-
ues of the parameter (cid:14) produce diﬀerent probability density
functions for the data vector x. We are interested in that
speciﬁc probability density function for the data vector x
that is more likely to have produced the data in our sample.
Once we identify such probability density function, we will
have an estimate of its parameter (cid:14).
Given that the data sample regards nodes randomly se-
lected from the population of nodes in the network of ref-
erence, we can conclude that our estimations at the level of
the data sample have validity over the entire population of
nodes in that network. Thus, the parameter (cid:14) that indexes
the probability density function for the data vector x, which
is more likely to have produced the data in our sample, is
indeed an estimate of the network vulnerability rate in the
case of network vulnerability rate estimation, and an esti-
mate of the network infection rate in the case of network
infection rate estimation.
2.3 Calculating the Most Likely Estimates
We now analyze the statistical relation between the model
represented by Equation 7 and the data sample through the
lens of MLE. Let the likelihood function L((cid:14) | n; x) denote
the likelihood of parameter (cid:14) given the data vectors n and x,
which we can observe from the data sample. The likelihood
function L((cid:14) | n; x) is a function of parameter (cid:14), therefore a
speciﬁc value of parameter (cid:14) fed to the likelihood function
in question results in a speciﬁc likelihood or unnormalized
probability of that speciﬁc value of (cid:14) itself. Thus, diﬀerent
values of parameter (cid:14) have diﬀerent likelihoods.
Finding that speciﬁc probability density function for data
vector x in the model represented by Equation 7 which is
more likely to be at the origin of the data sample, is equiva-
lent to ﬁnding a speciﬁc value of parameter (cid:14) that maximizes
the likelihood function L((cid:14) | n; x), i.e. ﬁnding the speciﬁc
value of parameter (cid:14) that has the highest likelihood given
data vectors n and x. From probability theory we derive
that the likelihood function L((cid:14) | n; x) can be deﬁned as in
the equation below:
L((cid:14) | n; x) = f (x | n; (cid:14))
(8)
By plugging Equation 7 into Equation 8 we reach the fol-
lowing more detailed formulation of our likelihood function:
(
m∏
L((cid:14) | n; x) =
ni!
xi!(ni − xi)!
i=1
(1 − (1 − (cid:14))i)xi (1 − (cid:14))i(ni(cid:0)xi)
(9)
Maximizing the likelihood function L((cid:14) | n; x) is equiv-
alent to maximizing the log-likelihood function ln L((cid:14) |
n; x) as those two functions are monotonically related to one
another. We work with the log-likelihood function rather
than the likelihood function mainly because of computation-
al convenience. By applying the natural logarithm to both
sides of Equation 9 we obtain the log-likelihood function as
shown below:
)
)
(
m∑
ln L((cid:14) | n; x) =
ni!
ln
xi!(ni − xi)!
i=1
510
(1 − (1 − (cid:14))i)xi (1 − (cid:14))i(ni(cid:0)xi)
(10)
ln L((cid:14) | n; x) =
m∑
(ln(
i=1
ni!
xi!(ni − xi)!
) + ln((1 − (1 − (cid:14))i)xi )+
+ ln((1 − (cid:14))i(ni(cid:0)xi)))
(11)
In Equation 11 we apply the transformation rule that re-
gards the logarithm of powers, and thus obtain the following
reﬁnement of the log-likelihood function:
m∑
(ln(ni!) − ln(xi!) − ln((ni − xi)!)+
ln L((cid:14) | n; x) =
i=1
+ xi ln(1 − (1 − (cid:14))i) + i(ni − xi) ln(1 − (cid:14)))
(12)
We can omit the ﬁrst three terms of Equation 12, namely
ln(ni!) − ln(xi!) − ln((ni − xi)!), as they do not depend on
parameter (cid:14), and therefore have no eﬀects on the speciﬁc val-
ue of parameter (cid:14) that maximizes the log-likelihood function
ln L((cid:14) | n; x). According to the MLE principle, an existing
value of parameter (cid:14) that maximizes the log-likelihood func-
tion meets the requirement that the ﬁrst derivative of the
log-likelihood function should be equal to zero, as shown in
the likelihood equation given below:
d ln L((cid:14) | n; x)
= 0
(13)
d(cid:14)
This likelihood equation is an ordinary diﬀerential equa-
tion as the parameter vector that maximizes the log-likelihood
function contains only one element, namely parameter (cid:14). By
plugging the pertinent part of Equation 12 into Equation 13
we get a formulation of the likelihood equation as the fol-
lowing ordinary diﬀerential equation:
d
m
i=1(xi ln(1 − (1 − (cid:14))i) + i(ni − xi) ln(1 − (cid:14)))
∑
By applying in Equation 10 the transformation rule that
regards the logarithm of products, we reach the following
form of the log-likelihood function:
d(cid:14)
= 0
(14)
The estimate of parameter (cid:14) is obtained by solving the
ordinary diﬀerential equation 14. The requirement repre-
sented by the likelihood equation in 13 and hence in 14 is
due to the fact that the maximum or minimum of the log-
likelihood function ln L((cid:14) | n; x) by deﬁnition imply that
its ﬁrst derivative converges to zero at the values of param-
eter (cid:14) that maximize or minimize the log-likelihood func-
tion in question. This means that the estimate of (cid:14) that we
have found may be a minimum of the log-likelihood function
ln L((cid:14) | n; x), i.e. it minimizes that log-likelihood function
instead of maximizing it.
Always according to the MLE principle, we can validate
that our estimate of parameter (cid:14) maximizes the log-likelihood
function ln L((cid:14) | n; x) by checking that its second derivative
evaluated at our estimate of parameter (cid:14) is negative. Thus,
for our estimate of (cid:14) to be a valid measure of network vul-
nerability or infection rate, its value along with data vectors
n and x observed from the data sample should satisfy the
equation below:
∑
d2
m
i=1(xi ln(1 − (1 − (cid:14))i) + i(ni − xi) ln(1 − (cid:14)))
d(cid:14)2
< 0
(15)
511
If that is not the case, we search the parameter space
further to identify a suitable estimate of parameter (cid:14) that
indeed maximizes the log-likelihood function ln L((cid:14) | n; x).
3. EXPERIMENTAL VALIDATION
We implemented the estimation approach in the Matlab
language, and thus tested its eﬀectiveness experimentally
in relation to simulated botnet propagation dynamics in a
Georgia Tech Network Simulator (GTNetS) [4]. The GT-
NetS tool enabled us to simulate moderate to large scale
networks. We mostly worked with simulated networks whose
size had an order of magnitude of 3x105 possible nodes and
105 actual nodes. The topology of each one of those simulat-
ed networks was a random tree as provided by the GTNetS
tool. The distribution of nodes throughout constituent sub-
networks was also conducted by the GTNetS tool in a ran-
dom fashion. The GTNetS tool provides for simulation of
worms over simulated networks. We used that functionality
to simulate botnet propagation dynamics in various simu-
lated networks.
We modiﬁed the GTNetS code such as to simulate tech-
niques for vulnerability scanning and botnet membership
assessment. That additional code allowed us to log the prop-
erties of each node in a sample of nodes from each simulated
network of reference, i.e. determine whether or not the node
is vulnerable and whether or not the node is infected. We
also developed code within GTNetS to randomly generate a
sample of nodes from each simulated network of reference,
and thereafter randomly distribute those nodes into pools.
In that code, we could programmatically set both the sam-
ple size and the number of pools. The GTNetS tool itself
allowed for setting the vulnerability rate in each simulated
network of reference. In this paper we refer to that rate as
true vulnerability rate.
After botnet propagation dynamics were simulated long
enough to aﬀect the whole simulated network, the true vul-
nerability rate became true infection rate as at that point in
time each vulnerable node became an infected node. Thus,
estimating the vulnerability rate at the beginning of each
simulation was equivalent to estimating the infection rate at
the end of that simulation as both of those true rates had
the same value. We tried the Matlab implementation of the
estimation approach in practice in relation to a large number
of experiments with various simulation parameters, namely
true vulnerability and infection rates, actual network sizes,
sample sizes, and numbers of pools. In empirical terms, the
estimation approach proved to support a ratio of the sample
size to the actual network size of up to 1:1000.
The outcome of each experiment was an estimate of the
vulnerability or infection rate, which we compared to the
true rate that was in place during that experiment in order
to derive the corresponding estimation error. The ratios of
the sample size to the actual network size employed varied
from 1:100 to 1:1000, while the numbers of pools employed
varied from a few, namely 11, to as many as 1200. Clearly
if defenders could inspect each or almost each actual node
for vulnerability or infection in a network of reference in an
amount of time that meets botnet mitigation requirements,
the random sampling would not apply and moreover the cal-
culation of network vulnerability and infection rates would
have been straightforward.
Because of that postulate, we deemed that given the order
of magnitude of the employed actual network size, the lower
Figure 1: Comparison between estimated rates and true rates (left), and estimation errors observed for those
true rates (right), for a ratio of the sample size to the actual network size of 1:1000.
bound 1:100 was approximately a minimum ratio of the sam-
ple size to the actual network size for the random sampling
to ﬁnd applicability in our problem domain. The motive for
the upper bound 1:1000 is its representation of a ceiling ra-
tio of the sample size to the actual network size, which the
estimation approach can support reliably. The sample sizes
employed in the experiments are a direct derivation from the
actual network sizes and the aforementioned ratios. We fol-
lowed ratios of the numbers of pools to the sample sizes from
1:1 to 1:10, which explains the numbers of pools employed,
namely from 11 to 1200. The overall highest estimation er-
rors observed during these experiments regard a ratio of the
sample size to the actual network size of 1:1000.
This comes natural as for such ratio the number of nodes
in the sample is considerably small with respect to the whole
population of nodes in a network of reference. The estima-
tion errors diminish as we move towards lower ratios of the
sample size to the actual network size. Figure 1 shows a
direct comparison between estimated rates and true rates
for a ratio of the sample size to the actual network size of
1:1000. For lower ratios of the sample size to the actual net-
work size, the estimated rates line follows more closely the
true rates line on the left part of Figure 1, while the corre-
sponding estimation error line on the right part of Figure 1
ﬂuctuates closer to zero as it moves along the true rates that
we tried in these experiments.
4. CONCLUSIONS
In this paper we discussed our research on botnet viru-
lence estimation. This research was motivated by the fac-
t that concrete measures of botnet virulence contribute to
the practicality of mathematical models of botnet propaga-
tion dynamics, and hence to their applicability to mitigation
of real world botnets. The approach we propose draws on
epidemiological models in biology, is based on random sam-
pling, and overall consists in a novel application of statistical
learning and inference. We fully implemented that approach
in the Matlab programming language. We validated the ef-
fectiveness of our approach in relation to botnet propaga-
512
tion dynamics simulated on a GTNetS network simulation
platform. We elaborated on empirical results as obtained
from practical experiments, which overall indicate that our
approach has the computational intelligence of producing
workable estimates of botnet virulence.
5. REFERENCES
[1] G. K. Bhattacharyya, M. G. Karandinos, and G. R.
DeFoliart. Point estimates and conﬁdence intervals for
infection rates using pooled organisms in epidemiologic
studies. American Journal of Epidemiology,
109(2):124–131, 1979.
[2] C. L. Chiang and W. C. Reeves. Statistical estimation
of virus infection rates in mosquito vector populations.
American Journal of Hygiene, 75:377–391, May 1962.
[3] Y.-H. Choi, L. Li, P. Liu, and G. Kesidis. Worm
virulence estimation for the containment of local worm
outbreak. Computers & Security, 29(1):104–123,
February 2010.
[4] G. F. Riley, M. I. Sharif, and W. Lee. Simulating
Internet worms. In Proceedings of the 12th International
Workshop on Modeling, Analysis, and Simulation of
Computer and Telecommunication Systems, pages
268–274, Vollendam, Netherlands, October 2004.
[5] K. H. Thompson. Estimation of the proportion of
vectors in a natural population of insects. Biometrics,
18(4):568–578, December 1962.
[6] S. D. Walter, S. W. Hildreth, and B. J. Beaty.
Estimation of infection rates in populations of
organisms using pools of variable size. American
Journal of Epidemiology, 112(1):124–128, July 1980.
[7] P. Wang, S. Sparks, and C. C. Zou. An advanced hybrid
peer-to-peer botnet. IEEE Transactions on Dependable
and Secure Computing, 7(2):113–127, April-June 2010.