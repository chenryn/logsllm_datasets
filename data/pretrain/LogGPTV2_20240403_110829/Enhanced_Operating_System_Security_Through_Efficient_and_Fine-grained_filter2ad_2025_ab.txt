72]. Unfortunately, the situation is completely differ-
ent inside the OS. First, there are several possible entry
points and a larger leakage surface than user applications.
For instance, a recent study has shown that uninitialized
data leading to information leakage is the most common
vulnerability in the Linux kernel [18]. In addition, the
common combined user/kernel address space design al-
lows arbitrary memory writes to easily become a vector
of information leakage for attacker-controlled applica-
tions. To make things worse, modern operating systems
often disclose sensitive information to unprivileged ap-
plications voluntarily, in an attempt to simplify deploy-
ment and debugging. An example is the /proc ﬁle sys-
tem, which has already been used in several attacks that
exploit the exposed information in conventional [56] and
nonconventional [76] ways. For instance, the /proc im-
plementation on Linux discloses details on kernel sym-
bols (i.e., /proc/kallsyms) and slab-level memory in-
formation (i.e., /proc/slabinfo). To compensate for
the greater chances of information leakage, ASR at the
ﬁnest level of granularity possible and continuous reran-
domization become both crucial to minimize the knowl-
edge acquired by an attacker while probing the system.
Brute forcing. Prior work has shown that many ex-
isting application-level ASR solutions are vulnerable to
simple brute-force attacks due to the low randomization
entropy of shared libraries [67]. The attack presented
in [67] exploits the crash recovery capabilities of the
Apache web server and simply reissues the same return-
into-libc attack with a newly guessed address after ev-
ery crash. Unlike many long-running user applications,
crash recovery cannot be normally taken for granted in-
side the OS. An OS crash is normally fatal and imme-
diately hinders the attack while prompting the attention
of the system administrator. Even assuming some crash
recovery mechanism inside the OS [43, 27], brute-force
attacks need to be far less aggressive to remain unno-
ticed.
In addition, compared to remote clients hiding
their identity and mounting a brute-force attack against
a server application, the source of an OS crash can be
usually tracked down.
In this context, blacklisting the
offensive endpoint/request becomes a realistic option.
4 A design for OS-level ASR
Our ﬁne-grained ASR design requires conﬁning differ-
ent OS subsystems into isolated event-driven compo-
nents. This strategy is advantageous for a number of
reasons. First, this enables selective randomization and
rerandomization for individual subsystems. This is im-
portant to fully control the randomization and rerandom-
ization process with per-component ASR policies. For
example, it should be possible to retune the rerandomiza-
tion frequency of only the virtual ﬁlesystem after notic-
ing a performance impact under particular workloads.
Second, the event-driven nature of the OS components
greatly simpliﬁes synchronization and state management
at rerandomization time. Finally, direct intercomponent
control transfer can be more easily prevented, thus limit-
ing the freedom of a control-ﬂow attack and reducing the
number of potential ROP gadgets by design.
Our ASR design is currently implemented by a
microkernel-based OS architecture running on top of the
MINIX 3 microkernel [32]. The OS components are con-
ﬁned in independent hardware-isolated processes. Hard-
ware isolation is beneﬁcial to overcome the problems of
a combined user/kernel address space design introduced
earlier and limit the options of an attacker. In addition,
the MMU-based protection can be used to completely
sandbox the execution of the untrusted rerandomization
code. Our ASR design, however, is not bound to its cur-
rent implementation and has more general applicability.
For example, our ASR design can be directly applied
to other component-based OS architectures, including
microkernel-based architectures used in common em-
bedded OSes—such as L4 [41], Green Hills Integrity [7],
and QNX [33]—and research operating systems using
software-based component isolation schemes—such as
Singularity [36]. Commodity operating systems, in con-
Figure 1: The OS architecture for our ASR design.
trast, are traditionally based on monolithic architectures
and lack well-deﬁned component boundaries. While this
does not prevent adoption of our randomization tech-
nique, it does eliminate the ability to selectively reran-
domize speciﬁc parts of the OS, yielding poorer ﬂexibil-
ity and longer rerandomization times to perform whole-
OS state migration. Encouragingly, there is an emerging
trend towards allowing important commodity OS subsys-
tems to run as isolated user-space processes, including
ﬁlesystems [6] and user-mode drivers in Windows [50]
or Linux [16]. Our end-to-end design can be used to pro-
tect all these subsystems as well as other operating sys-
tem services from several classes of attacks. Note that,
while running in user space, operating system services
are typically trusted by the kernel and allowed to per-
form a variety of critical system operations. An example
is udev, the device manager for the Linux kernel, which
has already been target of several different exploits [17].
Finally, given the appropriate run-time support, our de-
sign could also be used to improve existing application-
level ASR techniques and offer better protection against
memory error exploits for generic user-space programs.
Figure 1 shows the OS architecture implementing our
ASR design. At the heart lies the microkernel, providing
only IPC functionalities and low-level resource manage-
ment. All the other core subsystems are conﬁned into
isolated OS processes, including drivers, memory man-
agement, process management, scheduling, storage and
network stack. In our design, all the OS processes (and
the microkernel) are randomized using a link-time trans-
formation implemented with the LLVM compiler frame-
work [42]. The transformation operates on prelinked
LLVM bitcode to avoid any lengthy recompilation pro-
cess at runtime. Our link-time strategy avoids the need
for ﬁne-grained load-time ASR, eliminating delays in the
boot process and the run-time overhead introduced by the
indirection mechanisms adopted [14]. In addition, this
strategy reduces the instrumentation complexity to the
bare minimum, with negligible amount of untrusted code
exposed to the runtime. The vast majority of our ASR
MicrokernelIPCHw interfaceProc Mgr...SchedMem MgrStorageRM...Networkrand()rand()Disk Driver...KBD DriverNIC Driverrand()User applicationstransformations are statically veriﬁed by LLVM at the
bitcode level. As a result, our approach is also safer than
prior ASR solutions relying on binary rewriting [39].
As pointed out in [14], load-time ASR has a clear
advantage over alternative strategies: the ability to cre-
ate self-randomizing binaries distributed to every user in
identical copies, thus preserving today’s software distri-
bution model. Fortunately, our novel live rerandomiza-
tion strategy can fully address this concern. In our model,
every user receives the same (unrandomized) binary ver-
sion of the OS, as well as the prelinked LLVM bitcode
of each OS component. The bitcode ﬁles are stored in a
protected disk partition inaccessible to regular user pro-
grams, where a background process periodically creates
new randomized variants of the OS components using
our link-time ASR transformation (and any valid LLVM
backend to generate the ﬁnal binary). The generated vari-
ants are consumed by the randomization manager (RM),
a special component that periodically rerandomizes ev-
ery OS process (including itself). Unlike all the existing
solutions, rerandomization is applied transparently on-
line, with no system reboot or downtime required. The
conclusion is that we can directly leverage our live reran-
domization technique to randomize the original OS bi-
nary distributed to the user. This strategy retains the ad-
vantages of link-time ASR without affecting the software
distribution model.
When the OS boots up for the ﬁrst time, a full reran-
domization round is performed to relinquish any unran-
domized code and data present in the original binary. To
avoid slowing down the ﬁrst boot process, an option is
to perform the rerandomization lazily, for example re-
placing one OS process at the time at regular time in-
tervals. After the ﬁrst round, we continuously perform
live rerandomization of individual OS components in the
background. Currently, the microkernel is the only piece
of the OS that does not support live rerandomization.
Rerandomization can only be performed after a full re-
boot, with a different variant loaded every time. While it
is possible to extend our current implementation to sup-
port live rerandomization for the microkernel, we believe
this should be hardly a concern. Microkernel implemen-
tations are typically in the order of 10kLOC, a vastly
smaller TCB than most hypervisors used for security en-
forcement, as well as a candidate for formal veriﬁcation,
as demonstrated in prior work [40].
Our live rerandomization strategy for an OS process,
in turn, is based on run-time state migration, with the en-
tire execution state transparently transferred to the new
randomized process variant. The untrusted rerandomiza-
tion code runs completely sandboxed in the new variant
and, in case of run-time errors, the old variant immedi-
ately resumes execution with no disruption of service or
state loss. To support live migration, we rely on another
LLVM link-time transformation to embed relocation and
type information into the ﬁnal process binary. This infor-
mation is exposed to the runtime to accurately introspect
the state of the two variants and migrate all the random-
ized memory objects in a layout-independent way.
5 ASR transformations
The goal of our link-time ASR transformation is to ran-
domize all the code and data for every OS component.
Our link-time strategy minimizes the time to produce
new randomized OS variants on the deployment plat-
form and automatically provides randomization for the
program and all the statically linked libraries. Our trans-
formation design is based on ﬁve key principles: (i) min-
imal performance impact; (ii) minimal amount of un-
trusted code exposed to the runtime; (iii) architecture-
independence; (iv) no restriction on compiler optimiza-
tions; (v) maximum randomization granularity possible.
The ﬁrst two principles are particularly critical for the
OS, as discussed earlier. Architecture-independence en-
hances portability and eliminates the need for complex
binary rewriting techniques. The fourth principle dictates
compiler-friendly strategies, for example avoiding indi-
rection mechanisms used in prior solutions [12], which
inhibit a number of standard optimizations (e.g., inlin-
ing). Eliminating the need for indirection mechanisms
is also important for debuggability reasons. Our trans-
formations are all debug-friendly, as they do not signif-
icantly change the code representation—only allocation
sites are transformed to support live rerandomization, as
detailed later—and preserve the consistency of symbol
table and stack information. Finally, the last principle is
crucial to provide lower predictability and better security
than existing techniques.
Traditional ASR techniques [1, 68, 12] focus on ran-
domizing the base address of code and data regions. This
strategy is ineffective against all the attacks that make
assumptions only about relative distances/alignments be-
tween memory objects, is prone to brute forcing [67], and
is extremely vulnerable to information leakage. For in-
stance, many examples of application-level information
leakage have emerged on Linux over the years, and expe-
rience shows that, even by acquiring minimal knowledge
on the memory layout, an attacker can completely bypass
these basic ASR techniques [24].
To overcome these limitations, second-generation
ASR techniques [14, 39, 72] propose ﬁne-grained strate-
gies to permute individual memory objects and random-
ize their relative distances/alignments. While certainly
an improvement over prior techniques, these strategies
are still vulnerable to information leakage, raising seri-
ous concerns on their applicability at the OS level. Un-
like traditional ASR techniques, these strategies make it
normally impossible for an attacker to make strong as-
sumptions on the locations of arbitrary memory objects
after learning the location of a single object. They are
completely ineffective, however, in inhibiting precise as-
sumptions on the layout of the leaked object itself. This
is a serious concern inside the OS, where information
leakage is the norm rather than the exception.
To address all the challenges presented, our ASR
transformation is implemented by an LLVM link-time
pass which supports ﬁne-grained randomization of both
the relative distance/alignment between any two memory
objects and the internal layout of individual memory ob-
jects. We now present our transformations in detail and
draw comparisons with state-of-the-art techniques.
Code randomization. The code-transformation pass
performs three primary tasks. First, it enforces a ran-
dom permutation of all the program functions. In LLVM,
this is possible by shufﬂing the symbol table in the in-
tended order and setting the appropriate linkage to pre-
serve the permutation at code generation time. Second, it
introduces (conﬁgurable) random-sized padding before
the ﬁrst function and between any two functions in the
bitcode, making the layout even more unpredictable. To
generate the padding, we create dummy functions with a
random number of instructions and add them to the sym-
bol table in the intended position. Thanks to demand
paging, even very large padding sizes do not signiﬁcantly
increase the run-time physical memory usage. Finally,
unlike existing ASR solutions, we randomize the inter-
nal layout of every function.
To randomize the function layout, an option is to per-
mute the basic blocks and the instructions in the function.
This strategy, however, would hinder important compiler
optimizations like branch alignment [75] and optimal in-
struction scheduling [49]. Nonoptimal placements can
result in poor instruction cache utilization and inadequate
instruction pipelining, potentially introducing signiﬁcant
run-time overhead. To address this challenge, our pass
performs basic block shifting, injecting a dummy basic
block with a random number of instructions at the top of
every function. The block is never executed at runtime
and simply skipped over, at the cost of only one addi-
tional jump instruction. Note that the order of the origi-
nal instructions and basic blocks is left untouched, with
no noticeable impact on run-time performance. The off-
set of every instruction with respect to the address of the
function entry point is, however, no longer predictable.
This strategy is crucial to limit the power of an attacker
in face of information leakage. Suppose the attacker ac-
quires knowledge on the absolute location of a number of
kernel functions (e.g., using /proc/kallsyms). While
return-into-kernel-text attacks for these functions are still
conceivable (assuming the attacker can subvert control
ﬂow), arbitrary ROP-based computations are structurally
prevented, since the location of individual gadgets is no
longer predictable. While the dummy basic block is in a
predictable location, it is sufﬁcient to cherrypick its in-