Weaponizing data science for social engineering:  
Automated E2E spear phishing on Twitter 
John Seymour and Philip Tully 
{jseymour, ptully}@zerofox.com 
Introduction and Abstract 
Historically, machine learning for information security has prioritized defense: think intrusion 
detection systems, malware classification and botnet traffic identification. Offense can benefit 
from data just as well. Social networks, especially Twitter with its access to extensive personal 
data, bot­friendly API, colloquial syntax and prevalence of shortened links, are the perfect 
venues for spreading machine­generated malicious content. 
We present a recurrent neural network that learns to tweet phishing posts targeting specific 
users. The model is trained using spear phishing pen­testing data, and in order to make a 
click­through more likely, it is dynamically seeded with topics extracted from timeline posts of 
both the target and the users they retweet or follow. We augment the model with clustering to 
identify high value targets based on their level of social engagement such as their number of 
followers and retweets, and measure success using click­rates of IP­tracked links. Taken 
together, these techniques enable the world's first automated end­to­end spear phishing 
campaign generator for Twitter. 
Contents 
Introduction and Abstract 
1 
Background 
Machine Learning: An Offensive Approach 
High­level Description of Tool 
Target Discovery 
Automated Spear Phishing 
Conclusion 
References 
2 
3 
3 
4 
4 
5 
6 
1 
Background 
Historically, the security community has used Machine Learning (ML) in a defensive manner, for 
example in classifying malicious binaries or finding anomalous network traffic. Even now, 
startups continue to spring up advertising novel techniques for detecting inbound threats. But 
much of InfoSec is dedicated to identifying critical weaknesses and vulnerabilities through 
offense. While tools such as Metasploit [1] exist for automating Red­Team activities, there has 
been little work toward using ML as a weapon. 
Social engineering, particularly phishing, is one of the oldest yet still most effective weapons for 
exploitation. Early phishing attempts took a shotgun approach: only a few targets out of millions 
needed to bite in order for an attack to succeed. Spear phishing introduced specificity into this 
process by narrowing the target base to fewer people, enabling attackers to focus efforts on 
high value targets. It increased the likelihood of success by preemptively gathering personal 
information and using it to gain the target’s trust.  
Today, phishing attacks span across a variety of platforms. A prime example is social media, 
which exposes this vulnerability with its ever­expanding user base, high usage statistics, and 
strong incentive to disclose personal data. The challenge is how to exploit these natural 
weaknesses at scale, combining the shotgun approach of phishing campaigns with the 
specificity and success of targeted spear phishing. 
Enter Machine Learning. 
Machines have been successfully fooling humans since the first AI chatbot ELIZA in 1966 [2]. At 
a high level, ML is a statistical tool: given enough data, it can detect patterns that reveal 
information about unencountered samples. Natural Language Processing (NLP) is a use case of 
ML where raw text is the data source from which patterns are extracted. NLP has been 
successfully used for many applications, a significant application being spam detection [3]. 
Phishing is particularly amenable to the NLP approach because recurring patterns of text can be 
utilized to identify topics the target is interested in and generate sentences the target might 
respond to. 
The Social­Engineer Toolkit [4] is the gold standard for automating Social Engineering attack 
payloads, but users still have to gather their own data and write the “front­end” email delivery 
service. If we could automatically churn through unorganized personal data and generate a 
personalized phishing message, we can automate the spear phishing process completely and 
operate at a much larger scale with higher success rates. 
2 
Machine Learning: An Offensive Approach 
A proof of concept for automatically generating phishing emails, Honey­Phish, was first 
demonstrated at Shmoocon 2016 [5]. It targeted phishers themselves and attempted to trick 
them into clicking a link. Since a corpus of phishing emails was unavailable, Honey­Phish used 
a Markov Model [6] trained on Reddit posts from /r/personalfinance. But the model­generated 
English was noticeably different than what a human would write, so only 2 phishers responded 
out of 41 phishing emails generated. 
We make this approach viable by switching the social environment: we post on Twitter instead 
of sending an email. This allows us to scale both on the number of targets and on accuracy by 
tailoring the messages using personal data. Furthermore, on Twitter, the culture readily accepts 
broken English (we call this Twitterese) because of its 140­character limit. 
Twitterese has several interesting side effects that can be utilized for ML. Because short 
messages are the norm, messages produced by the model have decreased probability of 
grammatical error. Furthermore, to adapt to this constraint, links on Twitter are almost always 
shortened. This can be used to obfuscate a phishing domain, increasing the rate of 
clickthroughs. Other useful quirks of Twitterese include the abundant use of emojis, and the fact 
that victims disclose an absurd amount of personal data. These factors can all be used to 
generate more human­like messages and avoid suspicion. 
High­level Description of Tool 
The tool takes in a list of twitter usernames (e.g. from Twitter’s User Streaming API endpoint), 
then triages the users based on probability of success, which is determined from their account 
details and their posted personal information. If the user is relatively more vulnerable or has a 
high value, it selects them as a target, then automatically sends them a message with an 
embedded “phishing” link. 
When a target is selected, the tool extracts a topic and the timing history for that user’s tweets 
and replies in order to seed the phishing tweet generation. This is the bottleneck for our tool 
because the Twitter API rate limits retrieval to 180 timelines consisting of 200 posts per 15 
minutes. Modifications can be made to allow scaling laterally with respect to runtime using 
intelligent API token swapping strategies. We allow for tuning the tradeoff of throughput and 
accuracy by providing a parameter which defines the number of timeline calls per user. We 
found that the most frequently occuring words, excluding stopwords like common prepositions, 
were the most effective seeds for the tool. We bucketize the posts by the hour they were 
posted, and we schedule the phishing tweet to be sent at a random minute within the hour that 
the user historically posts most frequently. 
3 
We pre­train a neural network for generating tweets using a combination of spear phish 
pen­testing data, Reddit submissions, and tweets. We also allow for Markov models trained 
using the target’s recent posts. We measure two types of successful phishing results: responses 
from questions in the DEFCON SECTF [7] as a proxy for successful information exfiltration and 
clicks from an IP­traced shortened link to simulate a successful pwn. 
A powerful aspect of our method is that it generalizes across different languages and 
demographics out­of­the­box, since generated tweets simply reflect content that’s publicly 
available on the target’s timeline.  
Target Discovery 