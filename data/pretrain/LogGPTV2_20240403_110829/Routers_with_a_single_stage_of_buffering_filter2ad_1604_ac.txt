,
,
,
,
,
,
,
,
,
The conflict-free permutation changes the departure time of a
packet by at most
time slots. To ensure that packets departs
at the right time, we need a small coordination buffer at each out-
put to hold up to
k 1–
time slots later than planned.
packets. Packets may now depart at most
k 1–
k
We can now see how a Parallel Shared Memory can emulate a
shared memory router with PIFO queues. First we modify the
departure schedule using the conflict-free permutation above.
Next, we apply Constraint Sets to the modified schedule to find the
memory bandwidth needed for emulation using the new con-
straints. The emulation is not quite as precise as before: the Paral-
lel Shared Memory router can lag the ideal shared memory router
by up to
time slots.
k 1–
Theorem 2: (Sufficiency) With a total memory bandwidth of
4NR a Parallel Shared Memory router can emulate a PIFO shared
memory router, within
time slots.
k 1–
Proof: (Using Constraint Sets). See Appendix A. (cid:1)
III. DISTRIBUTED SHARED MEMORY ROUTERS
Up until now we have considered only the Parallel Shared Mem-
ory router. While this router architecture is interesting, it has the
drawback that all k memories are in a central location. In a com-
mercial router, we would prefer to add memories only as needed,
along with each new linecard. And so we now turn our attention to
the Distributed Shared Memory router shown in Figure 5. We
assume that the router is physically packaged as shown in Figure
256Switching Fabric
e.g.: Bus or Crossbar
MMA
Backplane
Port1
Distributed
Shared Memory
N Ports on
a backplane
Path of a packet
in the switch
Linecards
MMA
Crossbar
Linecards
Figure 5: (a) Physical view of the DSM router. The switch fabric
can be either a backplane or a crossbar. The memory on a sin-
gle linecard can be shared by packets arriving from other line-
cards.
Figure 5: (b) Logical view of the DSM router. An arriving
packet can be buffered in the memory of any linecard, say x. It
is later read by the output port from the intermediate linecard
x.
Figure 5: The Distributed Shared Memory router.
5a and each linecard contains some memory buffers (like in an
input queued router). But the memories on a linecard don’t neces-
sarily hold packets that arrived to or will depart from that linecard.
In fact, the N different memories (one on each linecard) can be
thought of as collectively forming one large shared memory. When
a packet arrives, it is transferred across the switch fabric (which
could be a shared bus backplane, a crossbar switch or some other
kind of switch fabric) to the memory in another linecard. When it
is time for the packet to depart, it is read from the memory and
passed across the switch fabric again, and sent through its outgoing
linecard directly onto the output line.
Notice that each packet is buffered in exactly one memory, and
so the router is an example of a Single Buffered router. The Dis-
tributed Shared Memory router is logically equivalent to a Parallel
Shared Memory as long as the shared bus has sufficient capacity.
Instead of all the memories being placed centrally, they are moved
to the linecards. Therefore, the theorems for the PSM router also
apply to the Distributed Shared Memory router.
While these results might be interesting, the bus bandwidth is
too large. For example, a 160Gb/s router would require a shared
multidrop broadcast bus with a capacity of 480Gb/s (or 640Gb/s).
This is not practical with today’s serial link and connector technol-
ogy.
IV. CROSSBAR-BASED DSM ROUTER
N N×
We can replace the shared broadcast bus with an
crossbar
switch, then connect each linecard to the crossbar switch using a
short point-to-point link. This is similar to the way input queued
routers are built today, although in a Distributed Shared Memory
router every packet traverses the crossbar switch twice.
The crossbar switch needs to be configured each time packets
are transferred, and so we need a scheduling algorithm that will
pick each switch configuration. (Before, when we used a broadcast
bus, we didn’t need to pick the configuration as there was suffi-
cient capacity to broadcast packets to the linecards). In what fol-
lows we’ll see that there are several ways to schedule the crossbar
switch, each with its pros and cons. We will find different algo-
rithms; and for each, we will find the speed that the memories and
crossbar need to run at.
We will define the bandwidth of a crossbar to be the speed of the
connection from a linecard to the switch, and will assume that the
link bandwidth is the same in both directions. So for example, just
to carry every packet across the crossbar fabric twice, we know
that each link needs a bandwidth of at least 2R. We find that, in
general, we need a higher bandwidth than this in order to emulate a
shared memory router. The additional bandwidth serves three pur-
poses: (1) It provides additional bandwidth to write into (read
from) the memories on the linecards to overcome the memory con-
straints, (2) It relaxes the requirements on the scheduling algorithm
that configures the crossbar, and (3) Because the link bandwidth is
the same in both directions, it allocates a bandwidth for the peak
transfer rate in one direction, even though we don’t usually need
the peak transfer rate in both directions at the same time.
A. A Crossbar-based DSM router can emulate
an FCFS shared memory router
We start by showing trivially sufficient conditions for a Cross-
bar-based DSM router to emulate an FCFS shared memory router.
We will follow this with some tighter results which show how the
crossbar bandwidth can be reduced at the cost of either increased
memory bandwidth, or a more complex crossbar scheduling algo-
rithm.
Lemma 1: A Crossbar-based DSM router can emulate an
FCFS shared memory router with a total memory bandwidth of
3NR and a crossbar speed of 6R.
257Request graph, G
Inputs, I
Outputs, J
Request Matrix
1
2
3
4
(a)
1
2
3
4
1
1
0
0
0
1
2
1
0
1
0
0
1
0
0
0
(b)
Figure 6: A request graph and a request matrix resulting
from the MMA for an
switch.
N N×
Proof: Consider operating the crossbar in two phases: first, read all
departing packets from memory and transfer them across the cross-
bar. From Theorem 1, this requires at most three transfers per line-
card per time slot. In the second phase, write all arriving packets to
memory, requiring at most three more transfers per linecard per
time slot. This corresponds to running the link connecting the line-
card to the crossbar at a speed of 6R. (cid:1)
Lemma 2: A Crossbar-based DSM router can emulate a PIFO
shared memory router with a total memory bandwidth of 4NR and
a crossbar speed of 8R within a relative delay of
time slots.
2N 1–
Proof: This will follow directly from Theorem 2 and the proof of
Lemma 1. How the crossbar is scheduled is described in the proof
of Theorem 4. (cid:1)
B. Minimizing the bandwidth of the crossbar
We can represent the set of memory operations in a time slot
using a bipartite graph with 2N vertices, as shown in Figure 6a. An
edge connecting input i to output j represents an (arriving or
departing) packet that needs to be transferred from i to j. In the
case of an arrival, the output incurs a memory write; and in the
case of a departure, the input incurs a memory read. The degree of
each vertex is limited by the number of packets that enter (leave)
the crossbar from (to) an input (output) linecard. Recall that for an
FCFS router, there are no more than three memory operations at
any given input or output. Given that each input (output) vertex
can also have an arrival (departure), the maximum degree of any
vertex is four.
Theorem 3: (Sufficiency) A Crossbar-based DSM router can
emulate an FCFS shared memory router with a total memory
bandwidth of 3NR and a crossbar speed of 4R.
Proof: From the above discussion, the degree of the bipartite
request graph is at most 4. From [28] and Theorem 1, a total mem-
ory bandwidth of 3NR and a crossbar speed of 4R is sufficient. (cid:1)
Theorem 4: (Sufficiency) A Crossbar-based DSM router with
a total memory bandwidth of 4NR and a crossbar speed of 5R, can
emulate a PIFO shared memory router within a relative delay of
2N 1–
time slots.
Proof: The proof is in two parts. First we shall prove that a con-
flict-free permutation schedule
over N time slots can be sched-
uled with a crossbar bandwidth 5R. Unlike the Crossbar-based
Distributed Shared Memory switch, the modified conflict-free per-
mutation schedule
cannot be directly scheduled on the cross-
bar, because the conflict-free permutation schedules N cells to
Π'
Π'
each output per time slot. However, we know that the memory
management algorithm schedules no more than 4 memory accesses
to any port per time slot. Since each input (output) port can have
no more than N arrivals (departures) in the N time slots, the total
out-degree per port in the request graph for
(over N time slots),
. From König’s method, there exists
is no more than
a schedule to switch the packets in
, with a crossbar bandwidth
of 5R.
4N N+
5N=
Π'
Π'
,
)
(
(
a1
2N 1–
a1 aN
Now we show that a packet may incur a relative delay of no
time slots when the conflict-free permutation
more than
Π'
is scheduled on a crossbar. Assume that the crossbar is config-
ured to schedule cells departing between time slots
(and
these configurations are now final) and that other cells prior to that
have departed. The earliest departure time of a newly arriving
packet is time slot
. However, a newly arriving cell cannot be
, since the crossbar is
granted a departure time between
will
already being configured for that time interval. Hence,
)
, and the cell
give the cell a departure time between
a2N
(
)
,
will leave the switch sometime between time slots
.
a2N
aN 1+
2N 1–
Hence the maximum relative delay that a cell can incur is
time slots. From Theorem 2, the memory bandwidth required is no
more than 4NR. (cid:1)
C. A tradeoff between crossbar bandwidth
and scheduler complexity
,
aN 1+
a1 aN
Π'
)
(
,
Theorem 3 is the lowest bound that we have found for the cross-
bar bandwidth (4R) and we suspect that it is a necessary condition
to emulate an FCFS shared memory router. Unfortunately, edge-
coloring has complexity
[29], and is too complex to
implement at high speed. We now explore a more practical algo-
rithm which also needs a crossbar bandwidth of 4R, but requires
the memory bandwidth to be increased to 4NR.
∆log
O N
(
)
The crossbar is scheduled in two phases: 1) Write-Phase: Arriv-
ing packets are transferred across the crossbar switch to memory
on a linecard, and 2) Read-Phase: Departing packets are trans-
ferred across the crossbar from memory to the egress linecard.
Theorem 5: (Sufficiency) A Crossbar-based DSM router can
emulate an FCFS shared memory router with a total memory
bandwidth of 4NR and a crossbar speed of 4R.
Proof: (Using Constraint Sets). See Appendix B. (cid:1)
Theorem 6: (Sufficiency) A Crossbar-based DSM router can
emulate a PIFO shared memory router within a relative delay of
N 1–
time slots, with a total memory bandwidth of 6NR and a
crossbar speed of 6R.
Proof: (Using Constraint Sets) See Appendix B. (cid:1)
In summary, we have described three different results. Let’s
compare them based on memory bandwidth, crossbar bandwidth,
and the complexity of scheduling the crossbar switch, when the
router is emulating an ideal FCFS shared memory router. First, we
can trivially schedule the crossbar-with a memory bandwidth of
3NR and a crossbar bandwidth of 6R (Lemma 1). With a more
complex scheduling algorithm, we can schedule the crossbar with
a memory bandwidth of 4NR and a crossbar bandwidth of 4R (The-
orem 5). But our results suggest that although possible, it is com-
plicated to schedule the crossbar when the memory bandwidth is
2583NR and the crossbar bandwidth is 4R. We now describe a schedul-
ing algorithm for this case, although we suspect there is a simpler
algorithm that we have been unable to find.
The bipartite request graph used to schedule the crossbar has
several properties that we can try to exploit:
1. The total number of edges in the graph cannot exceed 2N, i.e.
. This is also true for any subset of vertices; if I
Theorem 7: If a request matrix S is ordered, then any maximal
matching algorithm that gives strict priority to entries with lower
indices, such as the WFA [11], can find a conflict-free schedule.
Proof: See Appendix A. (cid:1)
This algorithm is arguably simpler than edge-coloring, although
row and col-
it depends on the method used to perform the
umn permutations.
2N 1–
subsets
of
indices
1 2 … N
{ ,
}
,
,
,
then
V. ROUTERS WITH PARALLEL AND
DISTRIBUTED SHARED MEMORY
2N≤
Rij
∑
i
∑
j
and
J
are
≤
I
Rij
J+
∑
J∈
j
. We complete the request graph by add-
∑
I∈
i
ing requests so that it has exactly 2N edges.
In the complete graph, the degree of each vertex is at least one,
2.
and is bounded by four. i.e.
1
≤
Rij
4
and
1
≤
≤
∑
i
≤
4
.
Rij
∑
j
3. The maximum number of edges between an input and an out-
. We call such a pair of edges a double
2≤
put is 2, i.e.
edge.
Rij
4. Each vertex can have at most one double edge, i.e., if
Rij
2=
,
<
j≠(
2 k
)
and
Rik
then
In a complete request graph, if an edge connects to a vertex
with degree one, the other vertex it connects to must have a
Rkj
.
<
i≠(
2 k
)
5.
The DSM router architecture assumes that there is one memory
device on each linecard. For line-rates up to 10Gb/s, this seems
reasonable today using a single commercially available DRAM on
each linecard. For line-rates above 10Gb/s, we need multiple mem-
ories on each linecard to achieve the bandwidth we need. In other
words, each linecard is now similar to the Parallel Shared Memory
router in Section II. We can use Constraint Sets to determine how
many memory devices are needed.
Theorem 8: A set of
running in
parallel can emulate a memory of rate R in an FCFS DSM router.
memories of rate
2h 1–
R h⁄
Proof: The analysis is similar to Theorem 1. However the read and
write constraints at the current time collapse into a single con-
straint, resulting in requiring only
2h 1–
Theorem 9: A set of
3h 2–
memories of rate
running in
memories. (cid:1)
R h⁄
degree greater than one. This means, if
Rmj
=
Rmn
=
1
,
∑
j
2≥
; if
Rin
then
∑
i
∑
i
Rin
=
Rmn
=
1
, then,
2≥
. To
Rmj
∑
j
see why this is, suppose an edge connects input i, which has
degree one, and output j. This edge represents a packet arriving
at i and stored at j. But j has a departure which initiates another
request, thus the degree of j is greater than one. By symmetry,
the same is true for an edge connecting an output of degree
one.
Our goal is to exploit these properties so as to find a crossbar
scheduling algorithm that can be implemented on a wave-front