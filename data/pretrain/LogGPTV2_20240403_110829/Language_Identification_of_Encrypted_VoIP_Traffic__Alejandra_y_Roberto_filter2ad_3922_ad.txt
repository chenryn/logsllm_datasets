Improvement
vs Random
13.8x
13.0x
5.7x
5.7x
1.4x
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
F
D
C
Effect of Padding on Accuracy
No Padding
128 bit
192 bit
256 bit
512 bit
Random
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21
Rank
Table 2: Tradeoff of effectiveness versus overhead in-
curred for padding VoIP packets to various block sizes.
Figure 12: The effect of padding on classifier accuracy.
5 Related Work
Some closely related work is that of Wang et al. [31] on
tracking VoIP calls over low-latency anonymizing net-
works such as Tor [9]. Unlike our analysis, which is en-
tirely passive, the attack in [31] requires that the attacker
be able to actively inject delays into the stream of pack-
ets as they traverse the anonymized network. Other re-
cent work has explored extracting sensitive information
from several different kinds of encrypted network con-
nections. Sun et al. [27], for example, examined World
Wide Web trafﬁc transmitted in HTTP over secure (SSL)
connections and were able to identify a set of sensitive
websites based on the number and sizes of objects in
each encrypted HTTP response. Song et al. [26] used
packet interarrival times to infer keystroke patterns and
ultimately crack passwords typed over SSH. Zhang and
Paxson [36] also used packet timing in SSH trafﬁc to
identify pairs of connections which form part of a chain
of “stepping stone” hosts between the attacker and his
eventual victim. In addition to these application-specific
attacks, our own previous work demonstrates that packet
size and timing are indicative of the application protocol
used in SSL-encrypted TCP connections and in simple
forms of encrypted tunnels [34].
Techniques for autmatically identifying spoken lan-
guages were the subject of a great deal of work in the
mid 1990’s [18, 38]. While these works used a wide
range of features extracted from the audio data and em-
ployed many different machine learning techniques, they
all represent attempts to mimic the way humans differ-
entiate between languages, based on differences in the
sounds produced. Because our classiﬁer does not have
direct access to the acoustic data, it is unrealistic to ex-
pect that it could outperform a modern language recog-
nition system, where error rates in the single digits are
not uncommon. Nevertheless, automatic language iden-
tiﬁcation is not considered a solved problem, even with
access to full acoustic data, and work is ongoing in the
speech community to improve recognition rates and ex-
plore new approaches (see, e.g., [32, 8, 1]).
6 Conclusions
In this paper, we show that despite efforts devoted to se-
curing conversations that traverse Voice over IP, an ad-
versary can still exploit packet lengths to discern con-
siderable information about the underlying spoken lan-
guage. Our techniques examine patterns in the output of
Variable Bit Rate encoders to infer characteristics of the
encoded speech. Using these characteristics, we evalu-
ate our techniques on a large corpus of trafﬁc from dif-
ferent speakers, and show that our techniques can clas-
sify (with reasonable accuracy) the language of the tar-
get speaker. Of the 21 languages we evaluated, we are
able to correctly identify 14 with accuracy greater than
90%. When tasked with distinguishing between just two
languages, our average accuracy over all language pairs
is greater than 86%. These recognition rates are on par
with early results from the language identiﬁcation com-
munity, and they demonstrate that variable bit rate cod-
ing leaks signiﬁcant information. Moreover, we show
that simple padding is insufﬁcient to prevent leakage of
information about the language spoken. We believe that
this information leakage from encrypted VoIP packets is
a signiﬁcant privacy concern. Fortunately, we are able to
suggest simple remedies that would thwart our attacks.
Acknowledgments
We thank Scott Coull for helpful conversations through-
out the course of this research, as well as for pointing out
52
16th USENIX Security Symposium
USENIX Association
the linphone application [17]. We also thank Patrick Mc-
Daniel and Patrick Traynor for their insightful comments
on early versions of this work. This work was funded in
part by NSF grants CNS-0546350 and CNS-0430338.
Notes
1Note that our classifier is not a true instance of a χ2
classifier
as the probability distributions over each n-gram are not indepedent.
Essentially, we just use the χ2
function as a multi-dimensional distance
metric.
2Due to problems with the data, recordings from the French speak-
ers are unavailable.
References
[1] NIST language recognition evaluation. http://www.nist.
gov/speech/tests/lang/index.htm.
[2] S. Andersen, A. Duric, H. Astrom, R. Hagen, W. Kleijn, and
Internet Low Bit Rate Codec (iLBC), 2004. RFC
J. Linden.
3951.
[3] R. Barbieri, D. Bruschi, and E. Rosti. Voice over IPsec: Analysis
and solutions. In Proceedings of the 18th Annual Computer Se-
curity Applications Conference, pages 261–270, December 2002.
[4] M. Baugher, D. McGrew, M. Naslund, E. Carrara, and K. Nor-
rman. The secure real-time transport protocol (SRTP). RFC 3711.
[5] F. Beritelli. High quality multi-rate CELP speech coding for wire-
less ATM networks. In Proceedings of the 1998 Global Telecom-
munications Conference, volume 3, pages 1350–1355, November
1998.
[6] P. Biondi
and F. Desclaux.
In BlackHat Europe, 2006.
Skype.
blackhat.com/presentations/bh-europe-06/
bh-eu-06-biondi/bh-e%u-06-biondi-up.pdf.
Silver needle
in the
http://www.
[7] M. Blaze. Protocol failure in the escrowed encryption standard.
In Proceedings of Second ACM Conference on Computer and
Communications Security, pages 59–67, 1994.
[8] L. Burget, P. Matejka, and J. Cernocky. Discriminative training
techniques for acoustic language identiﬁcation. In Proceedings
of the 2006 IEEE International Conference on Acoustics, Speech,
and Signal Processing, volume 1, pages I–209–I–212, May 2006.
[9] R. Dingledine, N. Mathewson, and P. Syverson. Tor: The second-
In Proceedings of the 13th USENIX
generation onion router.
Security Symposium, pages 303–320, August 2004.
[10] International Telecommunications Union.
Recommendation
G.711: Pulse code modulation (PCM) of voice frequencies, 1988.
Recommendation
P.1010: Fundamental voice transmission objectives for VoIP ter-
minals and gateways, 2004.
[11] International Telecommunications Union.
[12] International Telecommunications Union.
Recommendation
G.729: Coding of speech at 8 kbits using conjugate-structure
algebraic-code-excited linear prediction (CS-ACELP), 2007.
[13] W. Jiang and H. Schulzrinne. Modeling of packet loss and delay
and their effect on real-time multimedia service quality. In Pro-
ceedings of the 10th International Workshop on Network and Op-
erating System Support for Digital Audio and Video, June 2000.
[14] D. R. Kuhn, T. J. Walsh, and S. Fries. Security considerations
for voice over IP systems. Technical Report Special Publication
008-58, NIST, January 2005.
[15] T. Lander, R. A. Cole, B. T. Oshika, and M. Noel. The OGI
22 language telephone speech corpus. In EUROSPEECH, pages
817–820, 1995.
[16] S. McClellan and J. D. Gibson. Variable-rate CELP based on
subband ﬂatness. IEEE Transactions on Speech and Audio Pro-
cessing, 5(2):120–130, March 1997.
[17] S. Morlat. Linphone, an open-source SIP video phone for Linux
and Windows. http://www.linphone.org/.
[18] Y. K. Muthusamy, E. Barnard, and R. A. Cole. Reviewing auto-
matic language identiﬁcation. IEEE Signal Processing Magazine,
11(4):33–41, October 1994.
[19] J. Navr´atil. Spoken language recognition—a step toward mul-
IEEE Transactions on Speech
tilinguality in speechprocessing.
and Audio Processing, 9(6):678–685, September 2001.
[20] E. Paksoy, A. McCree, and V. Viswanathan. A variable rate mul-
timodal speech coder with gain-matched analysis-by-synthesis.
In Proceedings of the 1997 IEEE International Conference on
Acoustics, Speech, and Signal Processing, volume 2, pages 751–
754, April 1997.
[21] N. Provos. Voice over misconﬁgured internet telephones. http:
//vomit.xtdnet.nl.
[22] L. Rabiner and B. Juang. Fundamentals of Speech Recognition.
Prentice Hall, 1993.
[23] J. Rosenberg, H. Schulzrinne, G. Camarillo, A. Johnston, J. Pe-
terson, R. Sparks, M. Handley, and E. Schooler. SIP: Session
initiation protocol. RFC 3261.
[24] M. R. Schroeder and B. S. Atal. Code-excited linear predic-
tion(CELP): High-quality speech at very low bit rates. In Pro-
ceedings of the 1985 IEEE International Conference on Acous-
tics, Speech, and Signal Processing, volume 10, pages 937–940,
April 1985.
[25] H. Schulzrinne, S. Casner, R. Frederick, and V. Jacobson. RTP:
A transport protocol for real-time applications. RFC 1889.
[26] D. Song, D. Wagner, and X. Tian. Timing analysis of keystrokes
In Proceedings of the 10th USENIX
and SSH timing attacks.
Security Symposium, August 2001.
[27] Q. Sun, D. R. Simon, Y.-M. Wang, W. Russell, V. N. Padman-
abhan, and L. Qiu. Statistical identiﬁcation of encrypted web
browsing trafﬁc. In Proceedings of the IEEE Symposium on Se-
curity and Privacy, pages 19–30, May 2002.
[29] J.-M. Valin and C. Montgomery.
[28] J.-M. Valin. The Speex codec manual. http://www.speex.
org/docs/manual/speex-manual.pdf, August 2006.
Improved noise weighting in
CELP coding of speech - applying the Vorbis psychoacoustic
model to Speex. In Audio Engineering Society Convention, May
2006. See also http://www.speex.org.
[30] S. V. Vaseghi. Finite state CELP for variable rate speech cod-
IEE Proceedings I Communications, Speech and Vision,
ing.
138(6):603–610, December 1991.
[31] X. Wang, S. Chen, and S. Jajodia. Tracking anonymous peer-to-
peer VoIP calls on the Internet. In Proceedings of the 12th ACM
conference on Computer and communications security, pages
81–91, November 2005.
[32] C. White, I. Shafran, and J.-L. Gauvain. Discriminative classi-
ﬁers for language recognition. In Proceedings of the 2006 IEEE
International Conference on Acoustics, Speech, and Signal Pro-
cessing, volume 1, pages I–213–I–216, May 2006.
[33] E. Wong, T. Martin, T. Svendsen, and S. Sridharan. Multilin-
gual phone clustering for recognition of spontaneous indonesian
speech utilising pronunciation modelling techniques. In Proceed-
ings of the 8th European Conference on Speech Communication
and Technology, pages 3133–3136, September 2003.
USENIX Association
16th USENIX Security Symposium
53
[34] C. V. Wright, F. Monrose, and G. M. Masson. On inferring appli-
cation protocol behaviors in encrypted network trafﬁc. Journal
of Machine Learning Research, 7:2745–2769, December 2006.
Special Topic on Machine Learning for Computer Security.
[35] L. Zhang, T. Wang, and V. Cuperman. A CELP variable rate
speech codec with low average rate. In Proceedings of the 1997
IEEE International Conference on Acoustics, Speech, and Signal
Processing, volume 2, pages 735–738, April 1997.
[36] Y. Zhang and V. Paxson. Detecting stepping stones. In Proceed-
ings of the 9th USENIX Security Symposium, pages 171–184,
August 2000.
[37] P. Zimmermann, A. Johnston, and J. Callas. ZRTP: Extensions
to RTP for Difﬁe-Hellman key agreement for SRTP, March 2006.
IETF Internet Draft.
[38] M. A. Zissman. Comparison of four approaches to automatic
language identiﬁcation of telephone speech. IEEE Transactions
on Speech and Audio Processing, 4(1), January 1996.
A Data Set Breakdown
The empirical analysis performed in this paper is based
on one of the most widely used data sets in the lan-
guage recognition community. The Oregon Graduate In-
stitute CSLU 22 Language corpus provides speech sam-
ples from 2,066 native speakers of 21 distinct languages.
Indeed, the work of Zissman [38] that we analyze in Sec-
tion 4 used an earlier version of this corpus. Table 3 pro-
vides some statistics about the data set.
Language
Arabic
Br. Portuguese
Cantonese
Czech
English
Farsi
German
Hindi
Hungarian
Indonesian
Italian
Japanese
Korean
Mandarin
Polish
Russian
Spanish
Swahili
Swedish
Tamil
Vietnamese
Abbr.
AR
BP
CA
CZ
EN
FA
GE
HI
HU
IN
IT
JA
KO
MA
PO
RU
SP
SW
SD
TA
VI
Speakers
Minutes
per Speaker
100
100
93
100
100
100
100
100
100
100
100
100
100
100
100
100
100
73
100
100
100
2.16
2.52
2.63
2.02
2.51
2.57
2.33
2.74
2.81
2.45
2.25
2.33
2.58
2.75
2.64
2.55
2.76
2.26
2.23
2.12
1.96
Table 3: Statistics about each language in our data
set [15]. Minutes of speech is measured how many of
minutes of speech we used during our tests.
54
16th USENIX Security Symposium
USENIX Association