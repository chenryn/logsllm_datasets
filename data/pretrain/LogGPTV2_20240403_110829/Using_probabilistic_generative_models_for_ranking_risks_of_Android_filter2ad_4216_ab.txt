tains meta-information that keeps track of information pertaining
to the application (e.g., name, category, version, size, prices) and
its usage statistics (e.g., rating, number of installs, user reviews).
This information is used by users when they are deciding to install
a new application.
Google recently started the Bouncer [3] service, which provides
automated scanning of applications on Google Play for potential
malware. Once an application is uploaded, the service immedi-
ately [3] starts analyzing it for known malware, spyware and tro-
jans. It also looks for behaviors that indicate an application might
be misbehaving, and compares it against previously analyzed apps
to detect possible red ﬂags. Bouncer runs every application on their
cloud in an attempt to detect hidden, malicious behavior, and ana-
lyzes developer accounts to block malicious developers.
Bouncer does not fully solve the security and privacy prob-
lems of Android. First, the line between malicious apps and non-
malicious apps is very blurred. The behavior of many apps cannot
be classiﬁed as malicious, yet many users will ﬁnd them risky and
intrusive. Bouncer has to be conservative when identifying apps
as malicious to prevent legitimate complaints from developers and
backlash from users for instrumenting a walled garden. Second,
details about Bouncer are fairly unknown to the security commu-
nity. At the time of writing this paper, except for the ofﬁcial blog
post by Google [3], there are no details about how Bouncer works
nor what algorithms it uses to detect malicious apps. Third, re-
searchers have found multiple ways to bypass Bouncer and upload
malware on Google Play. For example, a malicious app can try
to detect that it is running on Bouncer’s emulated Android device,
and refrain from performing any malicious activity, or malware can
perform malicious activities only when triggered by certain condi-
tions, such as time.
Other third party app websites exist, e.g., Amazon Appstore for
Android, GetJar, SlideMe Market, etc. Currently, these third-party
app stores have varying degrees of security associated with them.
2.2 In-Place Security and its Limitations
The Android system’s in-place defense against malware consists
of two parts: sandboxing each application and warning the user
about the permissions that the application is requesting. Speciﬁ-
cally, each application runs with a separate user ID, as a separate
process in a virtual machine of its own, and by default does not
have permissions to carry out actions or access resources which
might have an adverse effect on the system or on other apps, and
have to explicitly request these privileges through permissions.
In tandem with the sandboxing approach is a risk communica-
tion mechanism that communicates the risks of installing an app to
a user, hoping/trusting that the user will make the right decision.
When a user downloads an app through the Google Play website,
the user is shown a screen that displays the permissions requested
by the application and the warnings about the potential damages
when these permissions are misused. These warnings are worded
with a high degree of seriousness (See Table 1 for Android’s warn-
ings of some permissions). This provides a ﬁnal chance to verify
that the user is allowing the application access to the requested re-
sources. Installing the application means granting the application
all the requested permissions. A similar interface exists when a
user is browsing applications from a mobile device.
Despite its serious-wording, Android’s current permission warn-
ing approach has been largely ineffective. In [15], Felt et al. ana-
lyzed 100 paid and 856 free Android applications, and found that
“Nearly all applications (93% of free and 82% of paid) ask for at
least one ‘Dangerous’ permission, which indicates that users are
accustomed to installing applications with Dangerous permissions.
The INTERNET permission is so widely requested that users cannot
consider its warning anomalous. Security guidelines or anti-virus
programs that warn against installing applications with access to
both the Internet and personal information are likely to fail be-
cause almost all applications with personal information also have
INTERNET.”
Felt et al. argued “Warning science literature indicates that fre-
quent warnings de-sensitize users, especially if most warnings do
not lead to negative consequences [29, 17]. Users are therefore
not likely to pay attention to or gain information from install-time
permission prompts in these systems. Changes to these permission
systems are necessary to reduce the number of permission warnings
shown to users.”
While such ineffectiveness has been identiﬁed and criti-
cized [15, 29, 17], no alternative has been proposed. We argue
that a promising alternative is to present relative or comparative
risk information. This way, users can select apps based on easy-to-
consume risk information. Hopefully this will provides incentives
to developers to better follow the least-privilege principle and
request only necessary permissions.
Comparison with UAC: There is a parallel between Android’s
permission warning and Windows’ User Account Control (UAC).
Both are designed to inform the user of some potentially harmful
action that is about to occur. In UAC’s case, this happens when a
process is trying to elevate it’s privileges in some way, and in An-
droid’s case, this happens when a user is about to install an app that
will have all the requested permissions.
Recent research [19] suggests the ineffectiveness of UAC in en-
forcing security. Motiee et al. [19] reported that 69% of the sur-
vey participants ignored the UAC dialog and proceeded directly to
use the administrator account. Microsoft itself concedes that about
90% of the prompts are answered as “yes”, suggesting that “users
are responding out of habit due to the large number of prompts
rather than focusing on the critical prompts and making conﬁdent
decisions” [12].
According to [12] in the ﬁrst several months after Vista was
available for use, people were experiencing a UAC prompt in 50%
of their “sessions” - a session is everything that happens from lo-
gon to logoff or within 24 hours. With Vista SP1 and over time,
this number has been reduced to about 30% of the sessions. This
suggests that UAC has been effective in incentivizing application
developers to write programs without elevated privileges unless
necessary. An effective risk communication approach for Android
could have similar effects.
2433. DATASETS
In this section, we describe the two types of datasets we used
in our study of Android app permissions. Below we describe the
datasets and their characteristics.
3.1 Datasets Description
Market Datasets: We have collected two datasets from Google
Play spaced one year apart. Market2011, the ﬁrst dataset, consists
of 157,856 apps available on Google Play in February 2011. Mar-
ket2012, the second dataset, consists of 324,658 apps and has been
collected in February 2012. For each app, we have the applica-
tion meta-information consisting of the developer name, its cate-
gory and the set of permissions that the app requests. We assume
that apps in these two datasets are mostly benign. While we believe
that a small number of malicious apps may be present in them, we
assume that these datasets are dominated by benign ones. We lever-
age the Market2011 dataset for our model generation and testing,
use Market2012 dataset for validation and market evolution analy-
sis.
Malware Dataset: Our malware dataset consists of 378 unique
.apk ﬁles that are known to be malicious. We obtained this dataset
from the authors of [31]. For each malware sample, we extract the
permissions requested using the AndroidManifest.xml ﬁle present
inside the package ﬁle. For these malicious apps we do not have
their category information.
3.2 Data Cleansing
In the two market datasets, we have observed the presence of
thousands of apps that have similar characteristics. This kind of
“duplication” can occur due to the following reasons:
• Slight Variations (R1): One developer may release hun-
dreds or even thousands of nearly identical apps that provide
the same functionality with slight variation. A few examples
include wallpaper apps, city or country speciﬁc travel apps,
weather apps, or themed apps (i.e., a new app with essentially
the same functionalities can be written for any celebrity, in-
terest group,etc.) such as the one presented in Table 1 in
Section 6.
• App Maker Tools (R2): There are a number of tools [1, 2]
that enable non-programmers to create Android apps. Often
times many apps that are generated by these tools have sim-
ilar app names and the same set of permissions. This occurs
when the developer just uses the default settings in the tool.
We decided to consolidate duplicate apps from the same devel-
oper (R1) into a single instance in the dataset to prevent any single
developer from having a large impact on the generated probabilistic
model. We detect apps due to R1 by looking for instances where
apps belonging to the same developer have the same set of per-
missions. This is a likely indication that developers are uploading
many applications with minor variations in the app content.
We decided to keep apps due to R2 unchanged in the datasets.
We do this because: (1) we observed instances where apps due to
R2 have different functionality and many developers using these
tools do modify the permissions given to their app and (2) the
line between such apps and all apps that use a speciﬁc ad-network
which require a certain set of permissions is blurry.
After cleansing is complete we have 71,331 apps in the 2011
market dataset, and 136,534 apps in the 2012 market dataset. This
represents a reduction of around 55%, and demonstrates the preva-
lence of apps that are slight variations of other apps, justifying our
(a) The top 20 most used permissions in the datasets as a per-
cent of apps that request those permissions. Due to overlap in
the most used permissions, we need to show 26 permissions
to cover the most used in all datasets. 21st for Market 2012,
and last 5 for Malware.
(b) The percent of apps that request a speciﬁc number of per-
missions for each dataset.
(c) The percent of apps that request a speciﬁc number of per-
missions in the market datasets. Apps that only appear in
2011, only in 2012, and the intersection of those two datasets
Figure 1: Permission information for various data sets
INTERNETACCESS_NETWORK_STATEWRITE_EXTERNAL_STORAGEREAD_PHONE_STATEACCESS_FINE_LOCATIONACCESS_COARSE_LOCATIONVIBRATEWAKE_LOCKREAD_CONTACTSACCESS_WIFI_STATECALL_PHONECAMERARECEIVE_BOOT_COMPLETEDSEND_SMSWRITE_SETTINGSRECEIVE_SMSWRITE_CONTACTSGET_TASKSRECORD_AUDIOREAD_SMSACCESS_LOCATION_EXTRAWRITE_SMSINSTALL_PACKAGESCHANGE_WIFI_STATEREAD_HISTORY_BOOKMARKSWRITE_HISTORY_BOOKMARKS 0 20 40 60 80 100Percent of Apps Requesting Permission Market2011Market2012Malware    0 5 10 15 20 2501234567891011121314151617181920212223242526272829Percent of Apps Requesting X permissionsNumber of PermissionsPermission DistributionMarket2011Market2012Malware 0 5 10 15 20 25012345678910111213141516171819202122232425262728293031Percent of Apps Requesting X permissionsNumber of PermissionsPermission Distribution2011-NoOverlap2012-NoOverlapOverlap244decision to combine these so as not to allow one developer to overly
inﬂuence any model.
For some experiments, we break up market dataset into three
sets. The intersection of the 2011 and 2012 data is called ‘over-
lap’, this contains 38,024 apps which have the same name and per-
missions in the two datasets. Then we have 2011-NoOverlap, the
2011 dataset with this overlap removed, containing 33,307 apps,
and 2012-NoOverlap, the 2012 dataset with this overlap removed,
containing 98,510 apps.
3.3 Dataset Discussion
The top 20 most frequently requested permissions in each
dataset are presented in Figure 1(a). There are 26 permissions
in this table, which represent the top 20 for all 3 datasets. AC-
CESS_LOCATION_EXTRA_COMMANDS was added for Mar-
ket2012, and the last 5 were added for the malware dataset. For
some permissions, the percentage of malware apps requesting a
speciﬁc permission is much higher than those in the market dataset.
For example, READ_SMS is requested by 59.78% of the malicious
apps, but only 2.33% from Market2011, and 1.98% from Mar-
ket2012. This might be due to the fact that a class of malware
apps attempt to intercept messages between a mobile phone and a
bank for out-of-band authentication.
Another observation from Figure 1(a) is that for almost every
permission a higher percent of apps in Market2012 request it when
compared to the Market2011 dataset. This shows a trend that pro-
portionally more applications are requesting sensitive permissions.
The one notable exception to this is related to SMS, where Mar-
ket2012 actually saw a slight decrease for all permissions related
to SMS.
Figure 1(b) shows the percent of apps that request different num-
bers of permissions. From this graph, we observe in general, ma-
licious apps are requesting more permissions than the ones in the
market datasets. However, there are many market dataset apps that
are requesting many permissions as well. Between Market2011 and
Market2012, we also see a conﬁrmation that apps are requesting
a greater number of permissions on average. With proportionally
fewer apps requesting 0 or 1 permissions in Market2012, and then
for two permissions and greater, we see slight gains in the percent
of apps requesting permissions over Market2011. Overall, this in-
formation is an indication that the malicious apps are requesting
permissions in different ways then normal apps, and leads us to be-
lieve that looking at permission information is in fact promising. It
also shows that there may be a slow evolution in the market dataset.
Figure 1(c) shows a similar graph when we divide the datasets
into the overlap dataset and the two datasets with overlapping apps
removed. Interestingly, apps in the overlap dataset, which are the
“long-living” and stable apps generally request fewer permissions
than other apps.
4. MODELS
We aim at coming up with a risk score for apps based on their
requested permission sets and categories. Let the i’th app in the
dataset be represented by ai = (ci, xi = [xi,1, . . . , xi,M ]), where
ci ∈ C is the category of the i’th app, M is the number of per-
missions, and xi,m ∈ {0, 1} indicates whether the i’th app has
the m’th permission. Our goal is to come up with a risk function
rscore : C ×{0, 1}M → R such that it satisﬁes the following three
desiderata. First, the risk function should be monotonic. This con-
dition requires that removing a permission always reduces the risk
value of an app, formalized by the following deﬁnition.
DEFINITION 1
(MONOTONICITY). We say that a risk scoring
function rscore is monotonic if and only if for any ci ∈ C and any
xi, xj such that
∃k (xi,k = 0 ∧ xj,k = 1 ∧ ∀m(m (cid:54)= k ⇒ xi,m = xj,m))
⇒ rscore(ci, xi) < rscore(ci, xj).
The second desideratum is that malicious apps generally have
high risk scores. And the third is that the risk scoring function is
simple to understand.
Given any risk function, we can assign a risk ranking for each
app relative to a set A of reference apps, which can be, e.g., the set
of all apps available in Google Play:
rrank(ai) =
|{a ∈ A | rscore(a) ≥ rscore(ai)}|
|A|
If an app has a risk ranking of 1%, this means that the app’s risk
score is among the highest 1 percent.