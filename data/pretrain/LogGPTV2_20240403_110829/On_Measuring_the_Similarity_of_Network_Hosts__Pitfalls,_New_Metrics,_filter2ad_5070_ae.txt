### Average Rank in Groups with Expected Behavioral Changes

In groups where behavioral changes are anticipated, such as the DHCP, APC, or CLASS groups, and where rankings are likely to improve by chance due to minor activity variations, we observe the following:

(a) Day 1
(b) Day 2
**Figure 6.** Privacy neighborhood sizes for different distance radius settings.

### 5.3 Applications

To conclude our evaluation of the proposed DTW (Dynamic Time Warping) behavioral metric, we discuss its potential applications. The robust, semantically meaningful notion of host behavioral similarity provided by our metric makes it a strong foundation for various network analysis tasks, such as anomaly detection and host classification. The cluster analysis technique described earlier can be seen as a form of host classification and anomaly identification. Additionally, there are non-obvious forms of network data analysis that may benefit from our more formalized approach. One such application is using the DTW metric to analyze the privacy of hosts within anonymized network data.

#### Anonymized Network Data and Privacy

Anonymized network data is a transformation of data collected on a computer network, designed to hide sensitive information while maintaining general utility for researchers and analysts. Sensitive information includes the real identities of hosts, which are often replaced with pseudonyms (e.g., prefix-preserving anonymization [23, 12]). One of the most challenging aspects of network data anonymization is the lack of applicable privacy definitions, primarily because rigorously defining host behavior and its changes remains an open problem. Although previous works, including our own, have attempted to define privacy analysis techniques for anonymized data [7, 25], these methods, based on metrics like L1 distance, tend to provide a rather loose privacy analysis.

We argue that the DTW metric, with its unique ability to capture a robust notion of host behavior and embed this behavior in a well-defined metric space, holds promise for bringing formal privacy definitions to the field of anonymized network data.

#### (c, t)-Isolation in Anonymized Data

We illustrate this point by examining how a privacy analysis for network data can be built around the definition of (c, t)-isolation, as proposed by Chawla et al. in the context of multidimensional, real-valued spaces [6]. This privacy notion states that any "anonymized" point should have t real points from the original data within a ball of radius proportional to c centered at the anonymized point. Essentially, each anonymized point should have a conserved neighborhood of real points that it can "blend in" with, providing some level of uncertainty about the point's real identity. This definition can be used as the basis for an analysis methodology by examining the distribution of neighborhood sizes for each anonymized point at increasing radius sizes. Such information can help a data publisher determine the relative risk of publishing the anonymized data in its current form. The distribution can be visualized via a cumulative distribution function showing the percentage of points with a number of neighbors (i.e., neighborhood size) less than the given value for a specified radius.

To adapt this definition and analysis methodology for network hosts, we consider the entire time series for the hosts as a "point" and use the DTW metric to calculate the radius. **Figure 6** shows examples of this privacy analysis methodology applied to hosts within two days of our CSE dataset, assuming none of the six fields in our metric have been altered by the anonymization process. One way to interpret this analysis is that the radius bounds the potential error in the adversary's knowledge of the host's behaviors, while the number of hosts within the neighborhood provides a sense of the privacy of that host. For example, if a data publisher assumes the adversary could gain significant knowledge of a host's behaviors, perhaps derived from publicly available information, it would be prudent to consider the neighborhood sizes when the radius is relatively small. As shown in **Figure 6(a)**, even for a radius of 0.5, over 80% of the hosts in the data have neighborhoods of size 20 or greater, indicating potentially significant privacy for those hosts. This is contingent upon the assumptions made about the adversary's "view" of the data via the metric definitions.

A downside of this approach is the difficulty in interpreting the semantics of the overall DTW distances. Understanding what exactly a radius of 0.5 means with respect to the underlying behaviors can be challenging. One way to address this issue is to provide distributions of distances for each dimension computed during the time warping process, in addition to the Euclidean distance. Additionally, the semantically-meaningful metric spaces for each field may need to be altered to accommodate measuring behavioral distance between fields that have been altered by the anonymization process in the anonymized network data and those in the original (e.g., comparing prefix-preserving IP pseudonyms to the original IPs). However, we believe that the fact that our approach allows for such changes to the underlying semantics is a significant contribution.

### 6. Conclusion

Many types of network data analysis rely on well-known distance metrics to capture meaningful notions of behavioral similarity among network hosts. Despite their importance, there has been relatively little research on the impact of using generic distance metrics and ignoring long-term temporal characteristics on analysis tasks. Instead, distance metrics used in practice often take a simplistic view of network data, assuming they inherit the semantics of their syntactic representation (e.g., 16- or 32-bit integers), or that those values have no relationship at all. They also examine network activities in isolation or within short windows (e.g., n-gram distributions), which removes much of the long-term causal information found in the data. Consequently, these approaches are likely to provide brittle or unrealistic metrics for host behavior.

In this paper, we explored an alternative approach to defining host similarity that incorporates semantically meaningful spatial analysis of network activities and long-term temporal sequencing information into a single, unified metric space that describes host behaviors. We developed metric spaces for several prevalent network data types, showed how to combine the metric spaces to measure the spatial characteristics of individual network data records, and proposed a method of measuring host behavior using dynamic time warping (DTW) methods. At each stage in the development of this framework, we highlighted potential pitfalls and attempted to explain the unique requirements surrounding the analysis of network data, including the need to carefully define normalization procedures and consider assumptions about the data made in developing the metrics. Our proposed metric was evaluated against the well-known L1 distance metric, which ignores both semantic and temporal characteristics of the data, by applying cluster analysis techniques to a dataset containing a variety of realistic network host activities. Despite the admitted simplicity of our example metrics, the results of these experiments showed that our approach provides more consistent and useful characterizations of host behavior than the L1 metric.

Overall, these results indicate that it is useful to consider long-term temporal characteristics of network hosts, as well as the semantics of the underlying network data when measuring behavioral similarity. Furthermore, our results point toward several potentially interesting areas of future work. In the short term, one may consider the development of more refined distance metrics, including fine-grained metric spaces for a wider range of data types and time warping methods that allow for localized reordering of points. The results also call for a study of the performance of our DTW metric when applied to non-TCP protocols and to network objects other than hosts, such as web pages. More generally, a more formal method for characterizing behaviors, which may be used as the basis for provable network data anonymization techniques or robust traffic generation methods, seems warranted.

### Data Access

To encourage continued research on general network data similarity metrics, we have made the complete dataset used in our study available to the public via the PREDICT data repository [24] as "Departmental-Netflow-Trace-1" (Hosted By: Merit Network, Inc., Keywords: NetFlow).

### Acknowledgments

This work was supported by the U.S. Department of Homeland Security Science & Technology Directorate under Contracts FA8750-08-2-0147 and NBCHC080037, and by the National Science Foundation under Grant No. 0937060 that was awarded to the Computing Research Association for the CIFellows Project.

### References

[References listed here as per the original text]

---

This revised version aims to improve clarity, coherence, and professionalism while maintaining the technical accuracy and detail of the original text.