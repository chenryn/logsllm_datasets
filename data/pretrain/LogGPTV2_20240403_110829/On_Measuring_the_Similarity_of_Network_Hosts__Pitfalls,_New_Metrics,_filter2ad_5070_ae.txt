erage rank in groups where changes in behavior are ex-
pected, such as the DHCP, APC, or CLASS groups, and
where the the rankings are likely to improve by chance
due simply to tiny changes in activities.
(a) Day 1
(b) Day 2
Figure 6. Privacy neighborhood sizes for different distance radius settings.
5.3 Applications
To conclude our evaluation of the proposed DTW
behavioral metric, we discuss its potential applications.
Certainly, the fact that our proposed metric provides a
robust, semantically meaningful notion of host behav-
ioral similarity means that it may be a good foundation
for a number of network analysis tasks, such as anomaly
detection or host classiﬁcation. In fact, the cluster anal-
ysis technique described above can be thought of as a
form of host classiﬁcation and an anomaly identiﬁcation
method. There are, however, some non-obvious forms of
network data analysis which may beneﬁt from our more
formalized approach. One such application is the use of
the DTW metric as the basis for analyzing the privacy of
hosts within anonymized network data.
Roughly speaking, anonymized network data is sim-
ply a transformation of data collected on a computer net-
work such that certain sensitive information is not re-
vealed to those who use the data, but the data remains
generally useful to researchers and network analysts.
This sensitive information includes learning the real
identities of hosts found within the data despite those
identities being replaced with a pseudonym (e.g., preﬁx-
preserving anonymization [23, 12]). One of the most
difﬁcult parts of achieving network data anonymization
is the lack of applicable privacy deﬁnitions upon which
these transformations can be based, due primarily to the
fact that rigorously deﬁning the behavior of hosts and
the ways these behaviors may change remains an open
problem. Although prior works (including our own)
have attempted to deﬁne privacy analysis techniques for
anonymized data [7, 25], their methods have been based
upon techniques like the L1 distance metric evaluated
above, and consequently are likely to provide a rather
loose privacy analysis. We argue that given the DTW
metric’s unique ability to capture a robust notion of
host behavior and the fact that it embeds this behavior
in a well-deﬁned metric space, it holds good promise
in bringing formal privacy deﬁnitions to the ﬁeld of
anonymized network data.
We illustrate this point by examining one way in
which a privacy analysis for network data may be built
around the deﬁnition of (c, t)-isolation put forth by
Chawla et al. in the context of multidimensional, real-
valued spaces [6]. This privacy notion essentially states
that any “anonymized” point should have t real points
from the original data within a ball of radius propor-
tional to c centered at the anonymized point. That is,
each anonymized point should have a conserved neigh-
borhood of real points that it may “blend in” with,
and therefore provide the potential adversary with some
level of uncertainty about the point’s real identity. The
deﬁnition can be used as the basis of an analysis method-
ology simply by looking at the distribution of neigh-
borhood sizes for each anonymized point at increasing
radius sizes – such information may be used by a data
publisher to, for instance, determine the relative risk of
publishing the anonymized data in its current form. The
distribution may be visualized via a cumulative distribu-
tion function that shows the percentage of points with a
number of neighbors (i.e., neighborhood size) less than
the given value for a speciﬁed radius.
To adapt the deﬁnition and analysis methodology for
network hosts, we simply consider the entire time series
for the hosts to be a “point” and use the DTW metric
to calculate the radius. Figure 6 shows examples of this
privacy analysis methodology applied to hosts within the
the two days of our CSE dataset under the assumption
that none of the six ﬁelds in our metric have been altered
by the anonymization process. One way of interpreting
this analysis is that the radius bounds the potential er-
ror in the adversary’s knowledge of the host’s behaviors,
while the number of hosts within the neighborhood pro-
 0 0.2 0.4 0.6 0.8 1 20 40 60 80 100 120 140% of HostsNeighborhoodSizeRadius0.250.500.751.0 0 0.2 0.4 0.6 0.8 1 20 40 60 80 100 120 140% of HostsNeighborhoodSizeRadius0.250.500.751.0vides a sense of the privacy of that host. Therefore, if a
data publisher assumes the adversary could gain signiﬁ-
cant knowledge of a host’s behaviors, perhaps derived
from publicly available information, it would be pru-
dent to consider the neighborhood sizes when the radius
is relatively small. As Figure 6(a) shows, for example,
even for a radius of 0.5, well over 80% of the hosts in the
data have neighborhoods of size 20 or greater, thereby
indicating potentially signiﬁcant privacy for those hosts.
Of course, as discussed earlier in Section 4.1, this is
contingent upon the assumptions made about the adver-
sary’s “view” of the data via the metric deﬁnitions.
An obvious downside of this approach is that it is
difﬁcult to interpret the semantics of the overall DTW
distances. That is, understanding what exactly a radius
of 0.5 means with respect to the underlying behaviors
may be difﬁcult. One way to address this issue is to pro-
vide distributions of distances for each dimension com-
puted during the time warping process, in addition to
the Euclidean distance. Additionally, the semantically-
meaningful metric spaces for each ﬁeld may also need
to be altered to accommodate for measuring behav-
ioral distance between ﬁelds that have been altered by
the anonymization process in the anonymized network
data and those in the original (e.g., comparing preﬁx-
preserving IP pseudonyms to the original IPs). However,
we believe that the fact that our approach allows for such
changes to the underlying semantics is a contribution in
and of itself.
6 Conclusion
Many types of network data analysis rely on well-
known distance metrics to adequately capture a mean-
ingful notion of the behavioral similarity among network
hosts. Despite the importance of these metrics in ensur-
ing sound analysis practices, there has been relatively
little research on the impact of using generic distance
metrics and ignoring long-term temporal characteristics
on analysis tasks. Rather, distance metrics used in prac-
tice tend to take a simplistic view of network data by as-
suming they inherit the semantics of its syntactic repre-
sentation (e.g., 16- or 32-bit integers), or that those val-
ues have no relationship at all. Moreover, they examine
network activities in isolation or within short windows
(e.g., n-gram distributions), which removes much of the
long-term causal information found in the data. Conse-
quently, these approaches are likely to provide brittle or
unrealistic metrics for host behavior.
In this paper, we explored an alternative approach
to deﬁning host similarity that attempts to incorporate
semantically meaningful spatial analysis of network ac-
tivities and long-term temporal sequencing information
into a single, uniﬁed metric space that describes host be-
haviors. To accomplish this goal, we developed metric
spaces for several prevalent network data types, showed
how to combine the metric spaces to measure the spatial
characteristics of individual network data records, and
ﬁnally proposed a method of measuring host behavior
using dynamic time warping (DTW) methods. At each
stage in the development of this framework, we brought
to light potential pitfalls and attempted to explain the
unique requirements surrounding the analysis of net-
work data, including the need to carefully deﬁne nor-
malization procedures and consider assumptions about
the data made in developing the metrics. Our proposed
metric was evaluated against the well-known L1 dis-
tance metric, which ignores both semantic and temporal
characteristics of the data, by applying cluster analysis
techniques to a dataset containing a variety of realistic
network host activities. Despite the admitted simplic-
ity of our example metrics, the results of these experi-
ments showed that our approach provides more consis-
tent and useful characterizations of host behavior than
the L1 metric.
As a whole, these results indicate that it is useful to
consider long-term temporal characteristics of network
hosts, as well as the semantics of the underlying net-
work data when measuring behavioral similarity. Fur-
thermore, our results point toward several potentially in-
teresting areas of future work.
In the short term, one
may consider the development of more reﬁned distance
metrics, including ﬁne-grained metric spaces for a wider
range of data types and time warping methods that al-
low for localized reordering of points. The results also
call for a study of the performance of our DTW metric
when applied to non-TCP protocols and to network ob-
jects other than hosts, such as web pages. More gener-
ally, a more formal method for characterizing behaviors,
which may be used as the basis for provable network
data anonymization techniques or robust trafﬁc genera-
tion methods, seems warranted.
Data Access To encourage continued research on gen-
eral network data similarity metrics, we have made
the complete dataset used in our study available to
the public via the PREDICT data repository [24] as
“Departmental-Netﬂow-Trace-1” (Hosted By: Merit
Network, Inc., Keywords: NetFlow).
Acknowledgments This work was supported by the
U.S. Department of Homeland Security Science & Tech-
nology Directorate under Contracts FA8750-08-2-0147
and NBCHC080037, and by the National Science Foun-
dation under Grant No. 0937060 that was awarded to
the Computing Research Association for the CIFellows
Project.
References
[1] D. Arthur and S. Vassilvitskii. k-Means++: The Advan-
In Proceedings of the 18th
tages of Careful Seeding.
Annual ACM-SIAM Symposium on Discrete Algorithms,
pages 1027–1035, January 2007.
[2] T. Auld, A. W. Moore, and S. F. Gull. Bayesian Neural
Networks for Internet Trafﬁc Classiﬁcation. IEEE Trans-
action on Neural Networks, 18:223–239, 2007.
[3] L. Bernaille, R. Teixeira, I. Akodkenou, A. Soule, and
K. Salamatian. Trafﬁc Classiﬁcation on the Fly. SIG-
COMM Computer Communications Review, 36(2):23–
26, 2006.
[4] M. Bezzi. An Entropy-based Method for Measuring
Anonymity. In Proceedings of the 3rd International Con-
ference on Security and Privacy in Communications Net-
works and the Workshops, pages 28–32, 2007.
[5] V. Chandola, A. Banerjee, and V. Kumar. Anomaly de-
tection: A survey. ACM Computing Surveys, 41(3):15,
2009.
[6] S. Chawla, C. Dwork, F. McSherry, A. Smith, and
H. Wee. Toward privacy in Public Databases. In Proceed-
ings of the 2nd Annual Theory of Cryptography Confer-
ence, pages 363–385, 2005.
[7] S. E. Coull, C. V. Wright, A. D. Keromytis, F. Monrose,
and M. K. Reiter. Taming the Devil: Techniques for Eval-
uating Anonymized Network Data. In Proceedings of the
15th Network and Distributed Systems Security Sympo-
sium, pages 125–135, 2008.
[8] M. Crotti, M. Dusi, F. Gringoli, and L. Salgarelli. Trafﬁc
Classiﬁcation Through Simple Statistical Fingerprinting.
SIGCOMM Computer Communications Review, 37(1):5–
16, 2007.
[9] J. Early, C. Brodley, and C. Rosenberg. Behavioral
In Proceedings of the
authentication of server ﬂows.
19th Annual Computer Security Applications Confer-
ence, pages 46–55, December 2003.
[10] J. Erman, M. Arlitt, and A. Mahanti. Trafﬁc Classiﬁ-
In Proceedings of
cation using Clustering Algorithms.
the 2006 SIGCOMM Workshop on Mining Network Data,
pages 281–286, 2006.
[11] E. Eskin, A. Arnold, M. Prerau, L. Portnoy, and S. Stolfo.
A Geometric Framework for Unsupervised Anomaly De-
tection. In Applications of Data Mining in Computer Se-
curity, pages 77–92, 2002.
[12] J. Fan, J. Xu, M. Ammar, and S. Moon. Preﬁx-preserving
IP Address Anonymization: Measurement-based Secu-
rity Evaluation and a New Cryptography-based Scheme.
Computer Networks, 46(2):263–272, October 2004.
[13] V. Frias-Martinez, S. J. Stolfo, and A. D. Keromytis.
Behavior-Proﬁle Clustering for False Alert Reduction in
Anomaly Detection Sensors. In Proceedings of the An-
nual Computer Security Applications Conference, pages
367–376, 2008.
[14] T. Karagiannis, K. Papagiannaki, and M. Faloutsos.
BLINC: Multilevel Trafﬁc Classiﬁcation in the Dark. In
Proceedings of ACM SIGCOMM, pages 229–240, August
2005.
[15] T. Karagiannis, K. Papagiannaki, N. Taft, and M. Falout-
sos. Proﬁling the End Host. In Proceedings of the Pas-
sive and Active Network Measurement Conference, pages
186–196, 2007.
[16] A. Kounine and M. Bezzi. Assessing Disclosure Risk in
Anonymized Datasets. In Proceedings of FloCon, 2008.
[17] A. McGregor, M. Hall, P. Lorier, and J. Brunskill. Flow
Clustering Using Machine Learning Techniques. In Pro-
ceedings of the Passive and Active Network Measurement
Conference, pages 205–214, 2004.
[18] A. W. Moore and D. Zuev. Internet Trafﬁc Classiﬁcation
Using Bayesian Analysis Techniques. In Proceedings of
ACM SIGMETRICS, pages 50–60, June 2005.
[19] J. Munkres. Topology. Prentice-Hall Englewood Cliffs,
NJ, 2000.
[20] Nagios IT Infrastructure Monitoring. http://www.
nagios.org/.
[21] Nessus Vulnerability Scanner.
http://www.
nessus.org.
[22] T. Nguyen and G. Armitage. A survey of techniques
for internet trafﬁc classiﬁcation using machine learning.
IEEE Communications Surveys & Tutorials, 10(4):56–
76, 2008.
[23] R. Pang, M. Allman, V. Paxson, and J. Lee. The Devil
and Packet Trace Anonymization. ACM Computer Com-
munication Review, 36(1):29–38, January 2006.
[24] M. Ramadas, S. Ostermann, and B. Tjaden. Detecting
Anomalous Network Trafﬁc with Self-Organizing Maps.
In Proceedings of Recent Advances in Intrusion Detection
Conference, pages 36–54, 2003.
[25] B. Ribeiro, W. Chen, G. Miklau, and D. Towsley. An-
alyzing Privacy in Enterprise Packet Trace Anonymiza-
tion. In Proceedings of the 15th Network and Distributed
Systems Security Symposium, to appear, 2008.
[26] H. Sakoe and S. Chiba. Dynamic Programming Algo-
rithm Optimization for Spoken Word Recognition. IEEE
Transactions on Acoustics, Speech, and Signal Process-
ing, 26:43–49, 1978.
[27] R. Sekar, A. Gupta, J. Frullo, T. Shanbhag, A. Tiwari,
H. Yang, and S. Zhou. Speciﬁcation-based Anomaly De-
tection: A New Approach for Detecting Network Intru-
In Proceedings of the 9th ACM Conference on
sions.
Computer and Communications Security, pages 265–274,
2002.
[28] Y. Song, A. Keromytis, and S. Stolfo. Spectrogram:
A Mixture-of-Markov-Chains Model for Anomaly De-
In Proceedings of the 16th An-
tection in Web Trafﬁc.
nual Network and Distributed System Security Sympo-
sium, pages 121–136, 2009.
[29] S. Wei, J. Mirkovic, and E. Kissel. Proﬁling and Cluster-
ing Internet Hosts. In Proceedings of the 2006 Interna-
tional Conference on Data Mining, pages 269–275, 2006.
[30] N. Williams, S. Zander, and G. Armitage. A Preliminary
Performance Comparison of Five Machine Learning Al-
gorithms for Practical IP Trafﬁc Flow Classiﬁcation. SIG-
COMM Computer Communications Review, 36(5):5–16,
2006.
[31] C. Wright, F. Monrose, and G. M. Masson.
On
Inferring Application Protocol Behaviors in Encrypted
Journal of Machine Learning Re-
Network Trafﬁc.
search, Special Topic on Machine Learning for Computer
Security(7):2745–2769, December 2006.
[32] K. Xu, Z. Zhang, and S. Bhattacharyya. Proﬁling Internet
Backbone Trafﬁc: Behavior Models and Applications. In
Proceedings of ACM SIGCOMM, pages 169–180, August
2005.