(cid:22)(cid:23)(cid:27)(cid:19)(cid:1)(cid:14)(cid:12)(cid:27)(cid:19)(cid:23)(cid:22)
(cid:10)(cid:18)(cid:16)(cid:1)(cid:21)(cid:23)(cid:22)(cid:19)(cid:27)(cid:23)(cid:25)(cid:1)(cid:17)(cid:23)(cid:25)(cid:1)(cid:12)(cid:22)(cid:1)(cid:28)(cid:22)(cid:19)(cid:27)
(cid:14)(cid:12)(cid:22)(cid:1)(cid:13)(cid:16)(cid:1)(cid:24)(cid:20)(cid:12)(cid:14)(cid:16)(cid:15)(cid:1)(cid:23)(cid:22)(cid:1)(cid:12)(cid:22)(cid:30)
(cid:23)(cid:22)(cid:2)(cid:14)(cid:18)(cid:19)(cid:24)(cid:1)(cid:28)(cid:22)(cid:19)(cid:27)
(cid:7)(cid:28)(cid:27)(cid:24)(cid:28)(cid:27)(cid:1)(cid:16)(cid:29)(cid:16)(cid:22)(cid:27)
(cid:22)(cid:23)(cid:27)(cid:19)(cid:1)(cid:14)(cid:12)(cid:27)(cid:19)(cid:23)(cid:22)
(cid:6)(cid:23)(cid:22)(cid:19)(cid:27)(cid:23)(cid:25)
(cid:8)(cid:25)(cid:16)(cid:15)(cid:19)(cid:14)(cid:27)(cid:23)(cid:25)
(cid:11)(cid:22)(cid:19)(cid:27)
(cid:9)(cid:16)(cid:12)(cid:14)(cid:27)(cid:23)(cid:25)
(cid:11)(cid:22)(cid:19)(cid:27)
(cid:8)(cid:25)(cid:16)(cid:15)(cid:19)(cid:14)(cid:27)(cid:23)(cid:25)(cid:3)(cid:1)(cid:4)(cid:22)(cid:30)(cid:1)(cid:28)(cid:22)(cid:19)(cid:27)(cid:1)(cid:27)(cid:18)(cid:12)(cid:27)
(cid:26)(cid:28)(cid:24)(cid:24)(cid:20)(cid:19)(cid:16)(cid:26)(cid:1)(cid:19)(cid:22)(cid:24)(cid:28)(cid:27)(cid:26)(cid:1)(cid:27)(cid:23)(cid:1)(cid:27)(cid:18)(cid:16)
(cid:1)(cid:21)(cid:23)(cid:22)(cid:19)(cid:27)(cid:23)(cid:25)(cid:16)(cid:15)(cid:1)(cid:28)(cid:22)(cid:19)(cid:27)
(cid:6)(cid:23)(cid:22)(cid:19)(cid:27)(cid:23)(cid:25)(cid:16)(cid:15)
(cid:11)(cid:22)(cid:19)(cid:27)
(cid:9)(cid:16)(cid:12)(cid:14)(cid:27)(cid:23)(cid:25)(cid:3)(cid:1)(cid:4)(cid:22)(cid:30)(cid:1)(cid:28)(cid:22)(cid:19)(cid:27)(cid:1)(cid:27)(cid:18)(cid:12)(cid:27)
(cid:25)(cid:16)(cid:14)(cid:16)(cid:19)(cid:29)(cid:16)(cid:26)(cid:1)(cid:23)(cid:28)(cid:27)(cid:24)(cid:28)(cid:27)(cid:1)(cid:17)(cid:25)(cid:23)(cid:21)(cid:1)
(cid:27)(cid:18)(cid:16)(cid:1)(cid:21)(cid:23)(cid:22)(cid:19)(cid:27)(cid:23)(cid:25)(cid:16)(cid:15)(cid:1)(cid:28)(cid:22)(cid:19)(cid:27)
Overview of the TRUSTNET and DATAWATCH monitoring
Fig. 3.
scheme.
177
target. The predictor unit can be any unit that sees events
before they reach the decode unit, for example the fetch unit
(IFU). The fetch unit sees every instruction before it reaches
the decode unit. The reactor unit can be any unit that sees
events after they pass through the target. For example,
it
can be the execution unit (EXU), because that unit always
receives information about instructions after they pass through
the decode unit. The monitor itself can reside anywhere on-
chip. The IFU knows each cycle whether or not it has fetched a
new instruction. The EXU knows at each cycle whether or not
a valid instruction is advancing through the pipeline. Having
these two sources of knowledge corroborate prevents the
IDU from ever inserting bogus instructions into the pipeline.
Nothing extra has to be computed, since this knowledge is
already represented by signals in the respective units.
A vital aspect of this design is that the target unit never com-
municates with the monitor. Therefore, even if the designer of
unit X knows the design of the monitor (which is likely), the
designer is unable to corrupt the monitor of X. For this reason,
it is important that the monitor of X should not be physically
part of unit X.
Recall the assumption from Section III that only one sub-
team is corrupt, and so an attacker cannot corrupt two in-
dependent units on-chip. This assumption guarantees that our
system is secure against the attack space. Consider the monitor
set up to watch some unit X. There are four items in play -
the predictor of X, which we will call P; the reactor to X,
which we will call R; X itself; and the monitor of X, which
we will call M. The attacker must choose one and only one
of these items to corrupt.
In order to cause a conﬁdentiality
or integrity attack in X, the attacker would have to choose to
corrupt X itself. However, in that case P, R, and M are all
untampered with, and the attack is caught at runtime by the
P-R-M monitor. The attacker could instead tamper with P or R
(but not both), but in either case that attack would be caught
at runtime, since P and R would disagree with each other.
The last choice is to corrupt M to cause an availability attack.
However, since M contains only one (or a few) logic gates, it is
too small to contain a cheat code or ticking time bomb. M has
so few states (usually none) and input bits (usually two) that
it can easily be veriﬁed statically by exhaustive enumeration.
B. Control Corrupter Backdoor Protection
Recall that control corrupters change the semantics of an in-
struction in ﬂight. The same predictor/reactor scheme, used to
catch emitter attacks, works to detect control corrupter attacks,
since these attacks either cause reactions (microarchitectural
transactions) that are not predicted or prevent transactions that
are predicted. To this end, we present DATAWATCH, the natural
extension of TRUSTNET. DATAWATCH uses the same triangle
scheme as TRUSTNET. However, instead of transmitting indi-
vidual bits to monitors, signatures (e.g., hashes, parity bits,
slices) are passed to monitors that check for equivalence. For
example, in the case of the decoder, a two bit signature is
enough to deﬁne whether an instruction involves a load, a
store, both, or neither (two bits for four cases). An equality
COMPARISON OF TRUSTNET, DATAWATCH, AND SMART
DUPLICATION FOR SIMPLE, IN-ORDER MICROPROCESSORS
TABLE I
Corrupter
Attribute
Data
Detection
Control Corrupter
Detection
Emitter Detection
False Positives
Stalls Processor
Area Cost
On-Chip Trafﬁc
Off-chip memory
Backdoor source
TRUSTNET DATAWATCH
Smart Duplic.
No
No
Yes
No
No
Negligible
No
Yes
Yes
No
No
Low
Yes
Yes
Yes
No
Possibly
Moderate
Increases
No effect
Can be identiﬁed
check on the signatures from the predictor and the reactor
is enough to conﬁrm an on-chip invariant, namely that the
number of each type of regular memory operation that enters
the IDU equals the number of each type of memory operation
that exit the IDU. This prevents, for instance, an attack that
exﬁltrates data by converting no ops into store instructions.
Data corrupter attacks change only the data that is sent in
on-chip communications. These backdoors are fundamentally
different from the types previously discussed because the
amounts and types of communications between units during
the execution of an instruction is identical to that of a correctly
functioning chip. The monitor triangle, while very efﬁcient for
recognizing amounts and types of transactions, does not work
well for this case, because data corrupter attacks cannot be rec-
ognized without duplicating some of the computational logic
that has been corrupted. For example, if the EXU (execution
unit) produces an incorrect sum, the fact that the sum is wrong
cannot be known without duplicating (or otherwise performing
the job of) the ALU (arithmetic/logic unit).
However, this type of attack has some similarities with
transient errors that can occur in microprocessors. Signif-
icant work has been done toward transient error detec-
tion [25][55][71][23] and fault tolerance, and we draw on
the principles of some of this prior work. It is sufﬁcient in
many cases to duplicate select computational logic in order to
protect the RTL design, since standard memory structures (e.g.,
RAMs) are not susceptible to RTL level attacks. We propose
that this type of minimal duplication, which we call ‘smart
duplication,’ can be used in a case-by-case way to protect
any units (e.g., memory control unit) that are not covered by
the DATAWATCH system or any units that may be considered
vulnerable to data corrupter attacks. This partial duplication
allows for protection against data corrupter attacks. However,
it does this at the possible cost of processor stalls and extra
area, and as explained previously(Sec. III-C), in most domains
data corrupter attacks would likely be considered infeasible
due to the requisite of knowing the binaries that will be run
in the future during the RTL design phase. Therefore, this
technique may only be useful in a few select domains or not
at all.
Table I summarizes some of the attributes of the offered
solutions. None of the proposed solutions have a problem
178
instructions as opposed to whole cache lines. While the whole
line is loaded into the I-Cache from the L2, the I-Cache knows
when individual instructions are being fetched into the IFU.
• #3 LSU: The load-store unit (LSU) handles memory refer-
ences between the SPARC core, the L1 data cache and the L2
cache. Predicted by the IDU and reacted to by the D-Cache,
this monitor conﬁrms each cycle that a memory action (load
or store) is requested if and only if a memory instruction was
fed into the LSU. This catches shadow load or shadow store
attacks in the LSU. Our microprocessor uses write merging,
which could have been a problem, since several incoming
write requests are merged into a single outgoing write request.
However, there is still a signal each cycle stating whether or
not a load/store is being initiated, so even if several writes are
merged over several cycles, there is still a signal each cycle
for the monitoring system.
• #4 I-Cache: Predicted by the IFU and reacted to by
the uniﬁed L2 Cache, this conﬁrms each cycle that an L2
instruction load request is received in the L2 Cache if and only
if that load corresponds to a fetch that missed in the I-Cache.
The IFU can predict this because it receives an ‘invalid’ signal
from the I-Cache on a miss. An I-Cache miss immediately
triggers an L2 request and stalls the IFU, so there is no issue
with cache line size. The IFU buffers this prediction until the
reaction is received from the L2 Cache. This catches shadow
instruction loads in the I-Cache.
• #5 D-Cache: Predicted by the LSU and reacted to by the
L2 Cache, this is the same as the monitor #4 but watches data
requests instead of instruction requests.
• #6 L2 Cache: Predicted by the I-Cache and reacted to by
MMU, this is the same as monitor #4 but is one level higher
in the cache hierarchy.
• #7 L2 Cache: Predicted by the D-Cache and reacted to by
the MMU, this is the same as monitor #5 but is one level
higher in the cache hierarchy.
• #8 D-Cache: Predicted by the LSU and reacted to by the
L2 Cache, this is the same as monitor #5 but watches writes
instead of reads. It is necessary that two separate monitors
watch reads and writes; if a single monitor counted only
the total number of reads and writes, then an attacker could
convert a write into a read unnoticed. This would cause old
data to be loaded into the cache and prevent the new value
from being written.
• #9 L2 Cache: Predicted by the D-Cache and I-Cache and
reacted to by the MMU, this conﬁrms that line accesses in
the MMU correspond to line accesses issued by the level 1
caches. This monitor prevents shadow loads/stores executed
by the L2 Cache.
The following are the DATAWATCH monitoring triangles we
implemented, categorized by the unit being monitored:
• #10 IFU: Predicted by the IDU and reacted to by the I-
Cache, this conﬁrms each cycle that if the I-Cache receives
a valid PC value it is the same as the value computed in the
IFU. This required some duplication of PC logic but did not
Fig. 4. Units and communication in the hypothetical inorder processor used
in this study.
with false positives (false alarms) because they use invariants
that can be easily determined statically in non-speculative,
in-order microprocessors. Extending this solution to designs
with advanced speculative techniques, such as prefetching,
may make false positive avoidance non-trivial. False negatives
(missed attacks) are only a problem if multiple signals in
the DATAWATCH technique are hashed to save space, because
two different values may hash to the same key, thus tricking
the equality checker. However, hashing is an implementation
option, which we chose to avoid because the space requirement
of the baseline DATAWATCH system is fairly low.
C. A Case Study
To demonstrate the principles of
the TRUSTNET and
DATAWATCH techniques we describe how they can be applied
to a hypothetical non-speculative,
in-order microprocessor.
The in-order microprocessor used in this study closely mod-
els the cores and cache hierarchy of the OpenSPARC T2
microprocessor with the exception of the cross bar network
between core and memory system, the thread switching unit,
and the chip system units such as the clock and test units.
For this study, the units in the processor core are partitioned
as described in the OpenSPARC T2 documentation and we
used the open source RTL code to identify the predictors
and reactors for each unit. The following are the TRUSTNET
monitoring triangles we implemented, categorized by the unit
being monitored:
• #1 IDU: The primary responsibility of the IDU is to decode
instructions. Predicted by the IFU and reacted to by the EXU,
the IDU monitor conﬁrms each cycle that a valid instruction
comes out of the IDU if and only if a valid instruction entered
the IDU. This monitor detects any attack wherein the IDU
inserts spurious instructions into the stream. In the case of
branch and jump instructions, which do not go all the way
through the pipeline, the information travels far enough for the
EXU to know that a branch or jump is occurring. This monitor
can be extended to support a speculative microprocessor if the
monitor can reliably identify speculative instructions.
• #2 IFU: The primary responsibility of the IFU is to fetch
instructions. Predicted by the I-Cache and reacted to by the
IDU, this monitor conﬁrms each cycle that a valid instruction
comes out of the IFU if and only if an instruction was fetched
from the I-Cache. This invariant catches any attack wherein
the IFU sneaks instructions into the stream that did not come
from the I-Cache. The monitor operates on the level of single
179
(cid:3)(cid:11)(cid:22)(cid:1)(cid:7)(cid:17)(cid:13)(cid:11)(cid:16)(cid:1)
(cid:5)(cid:19)(cid:11)(cid:10)(cid:12)(cid:9)(cid:20)(cid:17)(cid:19)(cid:1)(cid:7)(cid:17)(cid:13)(cid:11)(cid:16)
(cid:4)(cid:21)(cid:20)(cid:18)(cid:21)(cid:20)(cid:1)
(cid:7)(cid:16)(cid:14)(cid:10)(cid:15)
(cid:3)(cid:18)(cid:18)(cid:20)(cid:10)
(cid:4)(cid:16)(cid:12)(cid:13)(cid:8)
(cid:7)(cid:16)(cid:14)(cid:10)(cid:15)
(cid:2)(cid:20)(cid:11)(cid:11)(cid:10)(cid:17)(cid:18)
(cid:6)(cid:17)(cid:10)(cid:9)(cid:13)(cid:8)(cid:19)(cid:16)(cid:17)
(cid:20)(cid:15)(cid:13)(cid:19)
(cid:5)(cid:19)(cid:11)(cid:10)(cid:12)(cid:9)(cid:20)(cid:17)(cid:19)(cid:1)(cid:7)(cid:17)(cid:13)(cid:11)(cid:16)(cid:1)
(cid:3)(cid:1)(cid:2)
(cid:2)(cid:14)(cid:8)(cid:19)(cid:15)
(cid:6)(cid:11)(cid:8)(cid:9)(cid:20)(cid:17)(cid:19)(cid:1)(cid:7)(cid:17)(cid:13)(cid:11)(cid:16)