### The Limitations of Challenge Questions and the Need for Improved Registration Ceremonies

Using challenge questions for authentication is often no more secure than relying solely on passwords. To fully leverage the benefits of machine authentication, we need to develop more robust registration ceremonies.

### 4. Conditioned-Safe Ceremonies

A natural response to the weaknesses of challenge questions and passwords is to design ceremonies that eliminate user conditioning, automatic responses, and rule-based decision-making. However, this approach has its drawbacks. Rule-based decision-making is a fundamental aspect of human behavior, enabling us to complete routine tasks efficiently. Users may be willing to invest extra time and effort to learn a new security mechanism, but if it is not easy to use, they will likely become frustrated and either disable or circumvent it [22, 24, 60]. Some level of conditioning is necessary for users to psychologically accept security mechanisms.

Since users tend to adopt rules that minimize conscious effort, we should not fight their tendency to use rule-based decision-making. Instead, we should design ceremonies that condition users to act in ways that protect them from attacks. We introduce the concept of a conditioned-safe ceremony, which deliberately conditions users to reflexively act in ways that enhance security. We propose two design principles for building conditioned-safe ceremonies:

1. **Condition Safe Rules**: Conditioned-safe ceremonies should only condition rules that are harmless to apply in the presence of an adversary.
2. **Condition Immunizing Rules**: Conditioned-safe ceremonies should condition at least one immunizing rule, which, when applied during an attack, causes the attack to fail. We discuss immunizing rules further in Section 4.1.

These principles also imply what conditioned-safe ceremonies should avoid:

- **Avoid Risky Decisions**: Conditioned-safe ceremonies should not condition rules that require users to decide whether it is safe to apply them. Many users are unreliable at recognizing risky situations and should not need to refrain from conditioned behavior to resist attacks.
- **Avoid Unreliable Actions**: Conditioned-safe ceremonies should not assume users will reliably perform actions that: 1) the ceremony has not conditioned them to perform, or 2) are voluntary. Satisficing users will learn to omit optional and voluntary actions, so ceremonies should not rely on such actions.

For example, a ceremony should not condition the rule "if (legitimate-looking login form) then (enter username/password)" because it can lead to a security failure if applied in the presence of an adversary. To determine if it is safe to apply this rule, a user must verify the URL bar, the siteâ€™s SSL certificate, and other security indicators. This burden is unsatisfactory. In a conditioned-safe ceremony, a user should be able to resist an attack even if they are unaware of the risk and perform the same actions as usual under benign conditions.

### 4.1 Forcing Functions

A forcing function is a type of behavior-shaping constraint designed to prevent human error [38]. It works by preventing a user from progressing in their task until they perform a specific action whose omission would result in a failure or accident. Because users must take this action during every instance of the task, the forcing function conditions users to always perform this action. With an effective forcing function, after a user performs the associated action, many mistakes become difficult or impossible to make. For example, a door that can only be locked from the outside with keys in hand trains the user to take their keys whenever they leave home, reducing the likelihood of being locked out.

Forcing functions have two main benefits:
1. **Prevent Errors of Omission**: They help prevent errors where a user skips an important, protective step.
2. **Condition Correct, Safe Behavior**: Users cannot normally proceed without performing the required action.

To be effective, the cognitive and physical effort required to comply with a forcing function must be less than the effort required to circumvent it. Otherwise, users may routinely attempt to bypass the forcing function, diminishing its benefits.

Forcing functions have been useful in safety-critical environments, and we hypothesize they can also help prevent errors during social engineering attacks. However, designing forcing functions that resist social engineering attacks is challenging. In conventional safety-critical environments, the risk elements rarely try to subvert protection mechanisms. Designing electrical safety equipment would be much trickier if electricity had malicious intent. Additionally, deployability considerations, such as no custom hardware, often require forcing functions to be implemented entirely in software, which affords attackers many opportunities for mimicry.

One previous application of software-based forcing functions in computer security is the concept of a secure attention key (SAK). A SAK is a mandatory special key combination users must type before taking a security-critical action, such as submitting their password. On Windows NT systems, users must type Control-Alt-Delete to get a login prompt. The SAK diverts control to the OS kernel, foiling any user-level spoofed login prompts. Since typing the SAK is mandatory, the hope is that users will learn to always enter the SAK before submitting their password.

Unfortunately, a simple attack against many SAKs is to induce an error of omission. On Windows NT systems, an adversary can display a spoofed login prompt and hope users skip the SAK before entering their passwords. This attack creates a conflict between two conditioned responses: SAK systems condition users to first type the SAK, but all password systems condition users to enter their passwords when they see a login form. Whether the attack succeeds depends on which conditioned response is stronger in a particular user.

Since social engineering attacks can misrepresent the state of a system and create the illusion that a forcing function has already been activated or disabled, ceremonies that fail solely due to errors of omission are suboptimal. Errors of omission are easy to make and hard to detect, even during routine tasks. Research suggests that users frequently do not notice when they have omitted routine procedural steps [3], and omission errors represent one of the most common causes of human performance problems [39].

To resist social engineering attacks, conditioned-safe ceremonies need defense in depth. Designers should build conditioned-safe ceremonies that have two levels of protection: an attack should fail unless a user both omits the conditioned action required by a forcing function and makes an error of commission. An error of commission is an anomalous user action not normally used in the ceremony. If the user omits the action required by the forcing function but does not otherwise deviate from the ceremony, an attack should fail. Likewise, if the user performs the required action but then makes an error of commission, the attack should also fail. With this approach, the action conditioned by the forcing function acquires an immunizing quality, as subsequent errors of commission will not compromise the ceremony.

The conditioned action required by the forcing function must be easy for users to perform; it should be easier to perform than any unsafe error of commission. Since humans are conditioned to work around buggy software, a user may willingly make an effortless error of commission if she feels it will complete the security task and allow her to continue with her primary task.

### 4.2 Analysis and Discussion

Although a designer can choose the rules conditioned by a ceremony, an attacker can affect which rules a user chooses to apply by manipulating environmental stimuli. Research by psychologists and human reliability specialists suggests that users mainly rely on two processes to determine the most appropriate rule to apply in a given situation: similarity-matching and frequency-gambling [41].

With similarity-matching, a user compares the situation's environmental cues against cues contained in the calling conditions of previously learned rules. If she finds a unique match, she performs the associated action. If the environmental cues are underspecified and partially match several rules, she will tend to "gamble" in favor of the useful, high-frequency candidates, i.e., the "good" rules that have been most frequently applied in the past.

These tendencies suggest that conditioned-safe ceremonies will better resist the currently successful attack strategy of blatantly initiating a ceremony with the victim and presenting familiar environmental cues, e.g., spoofing a trusted website. Since a forcing function requires a user to perform the immunizing action every time (whether under attack or not), the forcing function will condition a high-frequency, "good" rule (namely, perform the immunizing action) that is likely to be routinely applied in the future, even when under attack. Mimicking a conditioned-safe ceremony becomes less advantageous to an adversary; if a user recognizes they are participating in the ceremony, they will tend to perform the conditioned, immunizing action, which thwarts attacks. This presents an attacker with two options:
1. **Obviously Initiate the Ceremony**: Try to induce an error of commission before the user performs the immunizing action.
2. **Surreptitiously Initiate the Ceremony**: Try to induce an error of commission without the user realizing they are participating in the ceremony.

If attackers resort to the first option, they must prevent the human tendency to use rule-based decision-making, which is often difficult. If attackers resort to the second option, they will need to present unfamiliar situations to prevent users from recognizing the ceremony. Unfamiliar situations require additional cognitive effort to analyze and may cause feelings of suspicion and discomfort. Users often reject unfamiliar experiences in favor of more familiar ones. For example, studies suggest that some users distrust phishing warnings because the familiar experience presented by the adversary appears more trustworthy [16, 58]. Conditioned-safe ceremonies turn the tables and force adversaries to present awkward and unfamiliar experiences.

**Limitations**: We acknowledge that conditioned-safe ceremonies have their limits. Adversaries may try to convince users to disable protective mechanisms or take actions outside the scope of a ceremony that violate certain security assumptions. For example, if a user chooses to install malware, most ceremonies will be compromised. However, if we can design ceremonies that are so unproductive to attack directly that adversaries must resort to convincing users to install malware, it would be a significant step forward.

### 5. A Conditioned-Safe Registration Ceremony Using Email

In this section, we describe a conditioned-safe registration ceremony for machine authentication using email. When a user attempts to log in from an unregistered computer, the website sends an email containing a single-use HTTPS URL with an unpredictable component, for example:

```
https://www.xyz.com/reg.php?url_id=r
```

where `r` is a 160-bit random number generated by the website. We call this URL a registration link. The email includes instructions to click on the link. The website stores `r` in a database, along with the associated user ID, an expiration time, and a validity bit. When the user clicks on the registration link, if `r` is still valid and has not expired, the website sets a persistent authentication cookie on the user's computer and invalidates `r`. A user only needs to complete this ceremony once at each computer. For subsequent logins, they only need to complete any supplementary login procedures, such as entering their username and password. Several researchers have proposed using email in a similar way to help initialize authentication credentials [2, 6, 21, 23, 48].

**Security Analysis**: Consider the threat model of a phisher, an adversary who lures unsuspecting Internet users to a website posing as a trustworthy business. We assume a phisher has the following capabilities: 1) complete control of a web server with a public IP address; 2) ability to send communications such as emails and instant messages to potential victims; and 3) ability to mount application-layer man-in-the-middle attacks, representing a legitimate server to the victim and proxying input from the victim to the real server as needed.

Against the phishing threat model, we argue that email registration follows the principles of a conditioned-safe ceremony. The phisher can solicit the user's login name and password, but since the phisher's computer is unregistered, the site will not allow it to access the user's account without submitting a valid registration link. The attacker can trick the website to send the user a registration link, but to compromise the ceremony, the attacker must steal and use the registration link before the user submits it herself.

The registration link acts as a forcing function. Under normal conditions, a user must click on the link to proceed. Although there may be other ways of submitting the link, such as copying and pasting it in the URL bar, clicking generally requires less effort, and sites can embed the URL of the link in an HTML element to make the alternatives more difficult. Clicking on the registration link is an immunizing action; after the website invalidates the link, it is useless to an attacker.

Email-based registration has defense in depth. To compromise the ceremony, an attacker must:
1. **Prevent the User from Clicking the Link** (i.e., omit the forcing function action).
2. **Trick the User into Revealing the Link** (i.e., make an error of commission).

One possible attack strategy would be to inform the user that they must register their computer but, due to "technical problems," they should not click on the link and instead give the link to the attacker. Two compelling and straightforward attacks of this kind are:
1. Ask the user to copy and paste the registration link into a text box.
2. Ask the user to forward the registration email to an address with a similar domain name as the target site.

If a user does not notice the attacker's instructions and believes they are participating in the "normal" registration ceremony, they will likely resist these attacks. Email registration conditions users to click on the registration link, and if they click the link, they will resist the attack.

Alternatively, if the user notices the attacker's instructions to deviate from the ceremony, they will be safe as long as they click on the link before doing anything else. Since:
1. The website has conditioned the user to click on the registration link.
2. The credible repercussions of clicking on the link are probably limited.
3. Clicking on the registration link is arguably at least as easy as complying with the instructions.

The theory of rule-based decision-making suggests that users will first tend to try clicking on the registration link before complying with the adversary's instructions.

The key question is the strength of users' tendencies to click the registration link rather than comply with the adversary's instructions. To help answer this question, we conducted a user study to estimate how well email registration helps users resist social engineering attacks against it. In the next section, we describe this study.

### 6. A User Study of Email Registration

In this section, we describe a user study we conducted to compare the security of email registration to the security of registration using challenge questions. Our study simulated man-in-the-middle (MITM) social engineering attacks against users of each of the ceremonies. Our hypothesis is that email registration is significantly more resistant to MITM social engineering attacks than registration using challenge questions. We previously published a workshop paper describing the design of our study, but it did not present any results [33].

#### 6.1 Study Overview

Ecological validity is crucial: our study must realistically simulate experiences users have in the real world. This raises several challenges, including simulating the experience of risk for users without crossing ethical boundaries [31].