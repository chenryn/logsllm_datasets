mony using challenge questions is hardly more secure than
using passwords alone. We need better registration cere-
monies to realize the beneﬁts of machine authentication.
4 Conditioned-safe ceremonies
One natural response to the weaknesses of challenge
questions and passwords is to design ceremonies which try
to eliminate user conditioning, click-whirr responses, and
rule-based decision making. This approach is problematic.
Rule-based decision making is fundamental to human be-
havior: it helps us complete routine tasks quickly and easily.
Users may be willing to invest extra time and effort to learn
a new security mechanism, but if they cannot learn how to
use it efﬁciently, they will become frustrated and disable or
circumvent the offending mechanism [22, 24, 60]. Some
degree of conditioning may be necessary for the psycholog-
ical acceptance of security mechanisms by users.
Since users will tend to adopt rules for completing a cer-
emony that minimize conscious effort, we should not ﬁght
users’ tendencies to use rule-based decision making, but
take advantage of these tendencies to help users resist so-
cial engineering attacks. We should prudently design cer-
emonies to condition rules that beneﬁt security rather than
undermine it. Towards achieving this goal, we introduce
the notion of a conditioned-safe ceremony. A conditioned-
safe ceremony is one that deliberately conditions users to
reﬂexively act in ways that protect them from attacks. We
propose two design principles for building conditioned-safe
ceremonies:
• Conditioned-safe ceremonies should only condition
safe rules, i.e., rules that are harmless to apply in the
presence of an adversary.
• Conditioned-safe ceremonies should condition at least
one immunizing rule, i.e., a rule which when applied
during an attack causes the attack to fail. We discuss
immunizing rules further in Section 4.1.
These principles also have important consequences on what
conditioned-safe ceremonies should not do:
• Conditioned-safe ceremonies should not condition
rules that require users to decide whether it is safe to
apply them. Since many users are unreliable at recog-
nizing risky situations, users should not need to refrain
from conditioned behavior to resist attacks.
• Conditioned-safe ceremonies should not assume users
will reliably perform actions that: 1) the ceremony has
not conditioned her to perform, or 2) are voluntary.
Satisﬁcing users will learn to omit optional and volun-
tary actions, so ceremonies should not rely upon users
to perform such actions.
(legitimate looking login form)
For example, a ceremony should not condition the rule
“if
then (enter user-
name/password)” because it causes a security failure when
applied in the presence of an adversary. To determine if it
is safe to apply this rule, a user must ﬁrst verify the URL
bar, the site’s SSL certiﬁcate, and other security indicators.
Burdening users with these decisions is unsatisfactory. Ide-
ally, in a conditioned-safe ceremony, a user should be able
to resist an attack even if she has no idea she is at risk and
performs the same actions as she usually performs under
benign conditions.
However, user behavior is unpredictable and an adver-
sary may try to trick users into deviating from their normal,
conditioned behavior in a way that causes a security fail-
ure. Conditioned-safe ceremonies need safeguards to resist
these attacks. In the human reliability community, designers
often introduce constraints called forcing functions to help
prevent errors in safety-critical environments. We argue that
forcing functions can also be useful for conditioned-safe
ceremonies, and we discuss them further in the next section.
4.1 Forcing functions
A forcing function is a type of behavior-shaping con-
straint designed to prevent human error [38]. Forcing func-
tions usually work by preventing a user from progressing in
her task until she performs a particular action whose omis-
sion would result in a failure or accident. Because users
must take this action during every instance of the task, the
forcing function conditions users to always perform this ac-
tion. With an effective forcing function, after a user per-
forms the function’s associated action, many mistakes be-
come difﬁcult or impossible to make. For example, con-
sider the error of locking your keys in your residence. A
potential forcing function in this situation is a door that can
only be locked from the outside, keys in hand. This trains
you to take your keys with you whenever you leave home,
making it less likely you will be locked out in the future.
Forcing functions often have two beneﬁts: 1) they help
prevent errors of omission, where a user skips an important,
protective step in a task, and 2) they condition correct, safe
behavior, since users cannot normally proceed otherwise.
To be effective, the cognitive and physical effort required to
comply with a forcing function must be less than the effort
required to circumvent it. Otherwise, users may routinely
attempt to circumvent the forcing function, diminishing its
beneﬁts.
Since forcing functions have been useful for prevent-
ing errors in safety-critical environments, we hypothesize
they can also help prevent errors during social engineering
attacks. However, designing forcing functions that resist
social engineering attacks is challenging. In conventional
safety-critical environments, the risk elements rarely try to
intentionally subvert protection mechanisms and cause er-
rors. Designing electrical safety equipment would be a
much trickier business if electricity had malicious intent.
Also, deployability considerations for many ceremonies,
e.g., no custom hardware, often require forcing functions
to be implemented entirely in software. Software environ-
ments afford attackers many opportunities for mimicry.
One previous application of software-based forcing
functions in computer security is the concept of a secure
attention key (SAK). A SAK is a mandatory special key
combination users must type before they can take a security-
critical action, e.g., submitting their password. On Window
NT systems, users must type Control-Alt-Delete to get a
login prompt. The SAK diverts control to the OS kernel,
foiling any user-level spoofed login prompts. Since typing
the SAK is mandatory, the hope is that users will learn to
always enter the SAK before submitting their password.
Unfortunately, a simple attack against many SAKs is to
induce an error of omission. On Windows NT systems,
an adversary can display a spoofed login prompt and hope
users skip the SAK before entering their passwords. This
attack creates a conﬂict between two click-whirr responses:
SAK systems condition users to ﬁrst type the SAK, but all
password systems condition users to enter their passwords
when they see a login form. Whether the attack succeeds
depends on which click-whirr response is stronger in a par-
ticular user.
Since social engineering attacks can often misrepresent
the state of a system and create the illusion that a forcing
function has already been activated or disabled, ceremonies
which fail solely due to errors of omission are suboptimal.
Errors of omission are easy to make and hard to detect,
even during routine tasks. Research suggests that users fre-
quently do not notice when they have omitted routine pro-
cedural steps [3], and omission errors represent one of the
most common causes of human performance problems [39].
To resist social engineering attacks, we argue that
conditioned-safe ceremonies need defense in depth. De-
signers should build conditioned-safe ceremonies that have
two levels of protection: an attack should fail unless a user
both omits the conditioned action required by a forcing
function and makes an error of commission. We consider
an error of commission to be an anomalous user action not
normally used in the ceremony. If the user omits the action
required by the forcing function, but does not otherwise de-
viate from the ceremony, an attack should fail. Likewise,
if the user performs the required action, but then makes an
error of commission, the attack should also fail. With this
approach, the action conditioned by the forcing function ac-
quires an immunizing quality, since after a user performs
this action, subsequent errors of commission will not com-
promise the ceremony.
We emphasize that the conditioned action required by
the forcing function must be easy for users to perform; in
particular, it should easier to perform than any unsafe er-
ror of commission. Since humans have been conditioned to
work around buggy software, a user may willingly make an
effortless error of commission if she feels it will complete
the security task and allow her to continue with her primary
task.
4.2 Analysis and discussion
Although a designer can choose the rules conditioned
by a ceremony, an attacker can affect which rules a user
chooses to apply by manipulating the environmental stim-
uli. Research by psychologists and human reliability spe-
cialists suggests that users mainly rely on two processes to
determine the most appropriate rule to apply in a given sit-
uation: similarity-matching and frequency-gambling [41].
With similarity-matching, a user compares the situation’s
environmental cues against cues contained in the calling
conditions of previously learned rules. If she ﬁnds a unique
match, she performs the associated action. If the environ-
mental cues are underspeciﬁed and partially match several
rules, she will tend to “gamble” in favor of the useful, high
frequency candidates, i.e., the “good” rules which have been
most frequently been applied in the past.
These tendencies suggest that conditioned-safe cere-
monies will better resist the currently successful attack
strategy of blatantly initiating a ceremony with the victim
and presenting familiar environmental cues, e.g., spooﬁng a
trusted Web site. Since a forcing function requires a user to
perform the immunizing action every time (whether under
attack or not), the forcing function will condition a high-
frequency, “good” rule (namely, perform the immunizing
action) that is likely to be routinely applied in the future
– even when under attack. Mimicking a conditioned-safe
ceremony becomes less advantageous to an adversary; if
a user recognizes she is participating in the ceremony, she
will tend to perform the conditioned, immunizing action,
which thwarts attacks. This presents an attacker two op-
tions: 1) obviously initiate the ceremony and try to induce
an error of commission before the user performs the im-
munizing action, or 2) surreptitiously initiate the ceremony
and try to induce an error of commission without the user
realizing she is participating in the ceremony.
If attackers resort to the ﬁrst option, adversaries must
prevent the human tendency to use rule-based decision mak-
ing, rather than encourage it, as current attacks do. This
creates a disadvantage for adversaries; preventing human
tendencies is often difﬁcult. If attackers resort to the sec-
ond option, we hope adversaries will need to present un-
familiar situations to prevent users from recognizing the
ceremony. Otherwise, users will tend to react with con-
ditioned responses, i.e., apply safe rules and perform im-
munizing actions. This approach also disadvantages adver-
saries. Unfamiliar situations require additional cognitive ef-
fort to analyze and may cause feelings of suspicion and dis-
comfort. User often reject unfamiliar experiences in favor
of more familiar ones. For example, studies suggest that
some users distrust phishing warnings because the familiar
experience presented by the adversary appears more trust-
worthy [16, 58]. Conditioned-safe ceremonies turn the ta-
bles and force adversaries to be the ones required to present
an awkward and unfamiliar experience.
Limitations. We acknowledge conditioned-safe cere-
monies have their limits. Adversaries may try to convince
users to disable protective mechanisms or take actions out-
side the scope of a ceremony which violate certain security
assumptions. For example, with the conﬁguration of many
current computer systems, if a user chooses to install mal-
ware at any point, most ceremonies will be compromised.
However, if we can design ceremonies that are so unpro-
ductive to attack directly that adversaries must resort to con-
vincing users to install malware, it would be a tremendous
step forward.
5 A conditioned-safe registration ceremony
using email
In this section, we describe a conditioned-safe regis-
tration ceremony for machine authentication using email.
When a user attempts to log in from an unregistered com-
puter, the Web site sends her an email containing a single-
use HTTPS URL with an unpredictable component, for ex-
ample:
https://www.xyz.com/reg.php?url_id=r
where r is a 160 bit random number generated by the Web
site.2 We call this URL a registration link. The email in-
cludes instructions to click on the link. The Web site stores
r in a database, along with the associated user ID, an ex-
piration time, and validity bit. When the user clicks on the
registration link, if r is still valid and has not expired, the
Web site sets a persistent authentication cookie on the user’s
computer and invalidates r. A user only needs to complete
this ceremony once at each computer. For subsequent lo-
gins, she only needs to complete any supplementary login
procedures, e.g., enter her username and password. Several
researchers have proposed using email in a similar way to
help initialize authentication credentials [2, 6, 21, 23, 48].
Security analysis. Consider the threat model of a phisher,
an adversary which lures unsuspecting Internet users to a
Web site posing as a trustworthy business with which the
users have a relationship [4]. We assume a phisher has the
following capabilities: 1) complete control of a Web server
with a public IP address; 2) ability to send communications
such as emails and instant messages to potential victims;
and 3) ability to mount application-layer man-in-the-middle
attacks [5, 36, 51, 52], representing a legitimate server to the
victim and proxying input from the victim to the real server
as needed.
Against the phishing threat model, we argue email reg-
istration follows the principles of a conditioned-safe cer-
emony we propose in Section 4. The phisher can solicit
the user’s login name and password, but since the phisher’s
computer is unregistered, the site will not allow it to access
the user’s account without submitting a valid registration
link. The attacker can trick the Web site to send the user
2We assume the user has previously given the Web site her email ad-
dress, e.g., during the account creation process.
a registration link, but to compromise the ceremony, an at-
tacker must steal and use a registration link before the user
submits it herself. 3
The registration link acts as forcing function. Under nor-
mal conditions, a user must click on the link to proceed.
Although there may be other ways of submitting the link,
e.g., by copying and pasting it in the URL bar, clicking gen-
erally requires less effort, and sites can embed the URL of
the link in an HTML element to make the alternatives more
difﬁcult. Also, clicking on the registration link is an immu-
nizing action; after the Web site invalidates the link, it is
useless to an attacker.
Email based registration has defense in depth. To com-
promise the ceremony an attacker must 1) prevent the user
from clicking on the link (i.e., omit the forcing function
action), and 2) trick the user into revealing the link (i.e.,
make an error of commission). One possible attack strat-
egy would be to inform the user that she must register her
computer, but due to “technical problems” she should not
click on the link and instead give the link to the attacker.
We identify two compelling and straightforward attacks of
this kind: 1) ask the user to copy and paste the registration
link into a text box, or 2) ask the user to forward the regis-
tration email to an address with a similar domain name as
the target site. If a user does not notice the attacker’s in-
structions and believes she is participating in the “normal”
registration ceremony, we hypothesize she will likely resist
these attacks. Email registration conditions users to click
on the registration link, and if she clicks the link, she will
resist the attack.
Alternatively, if the user notices the attacker’s instruc-
tions to deviate from the ceremony, she will be safe as long
as she clicks on the link before doing anything else. Since:
1) the Web site has conditioned the user to click on the reg-
istration link; 2) the credible repercussions of clicking on
link are probably limited; and 3) clicking on the registra-
tion link is arguably at least as easy as complying with the
instructions, the theory of rule-based decision making sug-
gests that users will ﬁrst tend to try clicking on the regis-
tration link before complying with the adversary’s instruc-
tions.
The key question is the strength of users’ tendencies to
click the registration link rather than comply with the adver-
sary’s instructions. To help answer this question, we con-
ducted a user study to estimate how well email registration
helps users resist social engineering attacks against it. In
the next section, we describe this study.
3We do not consider attacks which enable adversaries to steal users’
authentication cookies after they have been set, e.g., cross-site scripting
attacks or malware. This problem is orthogonal to registration and requires
a different solution.
6 A user study of email registration
In this section, we describe a user study we conducted
to compare the security of email registration to the security
of registration using challenge questions. Our study simu-
lated man-in-the-middle (MITM) social engineering attacks
against users of each of the ceremonies. Our hypothe-
sis is that email registration is signiﬁcantly more resistant
to MITM social engineering attacks than registration us-
ing challenge questions. We previously published a work-
shop paper describing the design of our study, but it did not
present any results [33].
6.1 Study overview
Ecological validity is crucial: our study must realisti-
cally simulate experiences users have in the real world. This
raises a number of challenges, including:
• Simulating the experience of risk for users without
crossing ethical boundaries [31].