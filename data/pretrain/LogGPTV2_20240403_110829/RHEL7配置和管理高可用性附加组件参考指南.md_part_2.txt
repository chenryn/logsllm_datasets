# yum install lvm2-cluster gfs2-utils
```
::: {.warning style="margin-left: 0.5in; margin-right: 0.5in;"}
### 警告 {.title}
在安装 the Red Hat High Availability Add-On
软件包后，需要确定设置了软件更新首选项，以便不会自动安装任何软件。在正在运行的集群上安装可能会导致意外行为。
:::
:::
::: section
::: titlepage
# []{#ch-overview-HAAR.html#s1-firewalls-HAAR}配置 iptables 防火墙以允许集群组件 {.title}
:::
::: {.note style="margin-left: 0.5in; margin-right: 0.5in;"}
### 注意 {.title}
集群组件的理想防火墙配置取决于本地环境，您可能需要考虑节点是否有多个网络接口或主机外防火墙是否存在。在此示例中打开
Pacemaker 集群通常所需的端口，您需要根据具体情况进行修改。
:::
[表 1.1
"为高可用性附加组件启用的端口"](#ch-overview-HAAR.html#tb-portenable-HAAR "表 1.1. 为高可用性附加组件启用的端口"){.xref}
显示要为红帽高可用性附加组件启用的端口，并解释该端口的用途。您可以通过执行下列命令，通过利用
[**firewalld**]{.command} 守护进程启用所有这些端口：
``` screen
# firewall-cmd --permanent --add-service=high-availability
# firewall-cmd --add-service=high-availability
```
::: table
[]{#ch-overview-HAAR.html#tb-portenable-HAAR}
**表 1.1. 为高可用性附加组件启用的端口**
::: table-contents
+--------------------+------------------------------------------------+
| 端口               | 什么时候需要                                   |
+====================+================================================+
| TCP 2224           | [**所有节点上都需要（pcsd**]{.command} Web UI  |
|                    | 需要且节点到节点的通信需要）                   |
|                    |                                                |
|                    | 打开端口 2224 非常重要，从而使来自任何节点的   |
|                    | [**pcs**]{.command}                            |
|                    | 可以                                           |
|                    | 与群集中的所有节点（包括自身）进行通信。当使用 |
|                    | Booth 集群票据管理程序或一个 quorum            |
|                    | 设备时，您必须在所有相关主机上打开端口         |
|                    | 2224，比如 Booth abiter 或者 quorum 设备主机。 |
+--------------------+------------------------------------------------+
| TCP 3121           | 如果集群有 Pacemaker                           |
|                    | 远程节点，则所有节点都需要这个端口             |
|                    |                                                |
|                    | 完整集群节点上的 Pacemaker 的 `crmd`{.literal} |
|                    | 守护进程将在端口 3121 联系 Pacemaker           |
|                    | 远程节点上的 `pacemaker_remoted`{.literal}     |
|                    | 守护进程。如果使用一个单独的接口用于集群通     |
|                    | 信，则该端口只需要在那个接口上打开。至少应该在 |
|                    | Pacemaker                                      |
|                    | 远程                                           |
|                    | 节点上完整集群节点打开这个端口。由于用户可以在 |
|                    | 完整节点和远程节点之间转换主机，或使用主机的网 |
|                    | 络在容器内运行远程节点，因此打开所有节点的端口 |
|                    | 会很有用。不需要向节点以外的任何主机打开端口。 |
+--------------------+------------------------------------------------+
| TCP 5403           | 当使用带有 `corosync-qnetd`{.literal}          |
|                    | 的仲裁设备时，quorum                           |
|                    | 设备主机上需要此项。可以使用                   |
|                    | [**corosync-qnetd**]{.command} 命令的          |
|                    | `-p`{.option} 选项更改默认值。                 |
+--------------------+------------------------------------------------+
| UDP 5404           | 如果为多播 UDP 配置                            |
|                    | `corosync，则 corosync`{.literal} 节点需要     |
+--------------------+------------------------------------------------+
| UDP 5405           | 所有 corosync 节点上都需要（corosync 需要      |
|                    | `）`{.literal}                                 |
+--------------------+------------------------------------------------+
| TCP 21064          | 如果群集包含任何需要 DLM 的资源（如            |
|                    | `clvm`{.literal} 或                            |
|                    | `GFS                                           |
|                    | 2`{.literal}），则在所有节点上都需要这个端口。 |
+--------------------+------------------------------------------------+
| TCP 9929, UDP 9929 | 需要在所有集群节点上打开，并在使用 Booth       |
|                    | ticket                                         |
|                    | 管理器建                                       |
|                    | 立多站点集群时引导节点从这些相同节点进行连接。 |
+--------------------+------------------------------------------------+
:::
:::
:::
::: section
::: titlepage
# []{#ch-overview-HAAR.html#s1-configfileoverview-HAAR}集群和 Pacemaker 配置文件 {.title}
:::
红帽高可用性附加组件的配置文件是 `corosync.conf`{.filename} 和
`cib.xml`{.filename}。
`corosync.conf`{.filename} 文件提供了 `corosync（Pacemaker`{.literal}
构建的集群管理器）使用的集群参数。通常，您不应该直接编辑
`corosync.conf`{.filename}，而是使用 [**pcs**]{.command} 或
[**pcsd**]{.command}
接口。但是，在某些情况下，您可能需要直接编辑此文件。有关编辑
`corosync.conf`{.filename} [文件的详情，请参考在 Red Hat Enterprise
Linux 7 中编辑 corosync.conf
文件](https://access.redhat.com/articles/3185291){.ulink}。
`cib.xml`{.filename} 文件是一个 XML
文件，它代表群集的配置和群集中所有资源的当前状态。Pacemaker
的集群信息基础(CIB)使用此文件。CIB
的内容在整个群集间自动保持同步，请勿直接编辑 `cib.xml`{.filename}
文件；改为使用 [**pcs 或**]{.command} [**pcsd**]{.command} 接口。
:::
::: section
::: titlepage
# []{#ch-overview-HAAR.html#s1-configconsider-HAAR}集群配置注意事项 {.title}
:::
在配置 Red Hat High Availability Add-On 集群时，您必须考虑以下事项：
::: itemizedlist
-   红帽不支持 RHEL 7.7（及更高版本）的集群部署超过 32
    个节点。但是，通过运行 `pacemaker_remote`{.literal}
    服务的远程节点，有可能超出这一限制。有关
    `pacemaker_remote`{.literal} 服务的详情请参考 ["pacemaker_remote
    服务"一节](#ch-advancedresource-HAAR.html#pacemaker_remote "pacemaker_remote 服务"){.xref}。
-   不支持使用动态主机配置协议(DHCP)在 `corosync`{.literal}
    守护进程使用的网络接口上获取 IP 地址。DHCP
    客户端可以在地址续订期间定期删除 IP 地址并重新为其分配接口重新添加
    IP 地址。这将导致 `corosync 检测`{.literal}
    连接失败，这将导致对群集中其他任何节点进行 `心跳`{.literal}
    连接的隔离活动。
:::
:::
::: section
::: titlepage
# []{#ch-overview-HAAR.html#s1-upgradeconsider-HAAR}更新红帽企业 Linux 高可用性集群 {.title}
:::
可使用以下两种通用方法之一更新组成 RHEL High Availability 和 Resilient
Storage 附加组件的软件包：
::: itemizedlist
-   [*滚动更新*]{.emphasis}：从服务中删除一个节点，更新其软件，然后将其重新集成到集群中。这可让集群在更新每个节点时继续提供服务和管理资源。
-   [*更新整个集群*]{.emphasis}：停止整个集群，对所有节点应用更新，然后重新启动集群。
:::
::: {.warning style="margin-left: 0.5in; margin-right: 0.5in;"}
### 警告 {.title}
在为 Red Hat Enterprise LInux High Availability 和 Resilient Storage
集群执行软件更新步骤时，您必须确保在更新启动前，任何进行更新的节点都不是集群的活跃成员。
:::
[有关每个方法以及更新的步骤的完整描述，请参阅将软件更新应用到 RHEL High
Availability
或弹性存储集群的建议实践](https://access.redhat.com/articles/2059253/){.ulink}。
:::
::: section
::: titlepage
# []{#ch-overview-HAAR.html#s1-migratinghavmsHAAR}RHEL 集群中实时迁移虚拟机的问题 {.title}
:::
有关使用虚拟化集群成员的 RHEL [高可用性集群支持政策的信息，请参阅 RHEL
高可用性集群的支持政策 -
虚拟化集群成员的一般条件](https://access.redhat.com/articles/3131111){.ulink}。如前所述，红帽不支持在虚拟机监控程序或主机间实时迁移活跃集群节点。如果需要执行实时迁移，首先需要停止虚拟机上的集群服务从集群中删除该节点，然后在执行迁移后启动集群备份。
以下步骤概述了从集群中删除虚拟机、迁移虚拟机以及将虚拟机恢复到集群的步骤。
::: {.note style="margin-left: 0.5in; margin-right: 0.5in;"}
### 注意 {.title}
执行此步骤前，请考虑删除集群节点对集群仲裁的影响。例如，如果您有一个三个节点集群，并且删除了一个节点，则集群只能有一个节点失败。如果三个节点群集中的一个节点已经停机，删除第二个节点将丢失仲裁。
:::
::: orderedlist
1.  如果需要在停止或移动虚拟机上运行的资源或软件进行迁移前进行准备，请执行这些步骤。
2.  将任何受管资源移出虚拟机。如果应当重新定位资源的具体要求或首选项，请考虑创建新的位置限制，以将资源放置在正确的节点上。
3.  将虚拟机置于待机模式以确保它不被视为服务，并导致任何剩余的资源重新定位到其他位置或停止。
    ``` screen
    # pcs cluster standby VM
    ```
4.  在虚拟机上运行以下命令来停止虚拟机上的集群软件。
    ``` screen
    # pcs cluster stop
    ```
5.  执行虚拟机的实时迁移。
6.  在虚拟机上启动集群服务。
    ``` screen
    # pcs cluster start
    ```
7.  将虚拟机移出待机模式。
    ``` screen
    # pcs cluster unstandby VM
    ```
8.  如果您在将虚拟机置于待机模式之前创建了任何临时位置限制，请调整或删除这些限制，以允许资源返回到通常首选的位置。
:::
:::
:::
[]{#ch-pcsd-HAAR.html}
::: chapter
::: titlepage
# []{#ch-pcsd-HAAR.html#ch-pcsd-HAAR}第 2 章 pcsd Web UI {.title}
:::
本章概述了使用 [**pcsd**]{.command} Web UI 配置红帽高可用性群集。
::: section
::: titlepage
# []{#ch-pcsd-HAAR.html#s1-guisetup-HAAR}pcsd Web UI 设置 {.title}
:::
要将您的系统设置为使用 [**pcsd**]{.command} Web UI
配置群集，请使用以下步骤：
::: orderedlist
1.  安装 Pacemaker 配置工具，如 ["安装 Pacemaker
    配置工具"一节](#ch-overview-HAAR.html#s1-installation-HAAR "安装 Pacemaker 配置工具"){.xref}
    所述。
2.  在将成为群集一部分的每个节点上，使用 [**passwd**]{.command}
    命令设置用户 `hacluster`{.literal}
    的密码，并且在每个节点上使用相同的密码。
3.  在每个节点中启动并启用 [**pcsd**]{.command} 守护进程：
    ``` screen
    # systemctl start pcsd.service
    # systemctl enable pcsd.service
    ```
4.  在集群的一个节点上，使用以下命令验证组成集群的节点。执行此命令后，系统将
    `提示您输入`{.literal} `用户名和密码`{.literal}。将
    `hacluster`{.literal} 指定为 `Username`{.literal}。
    ``` screen
    # pcs cluster auth node1 node2 ... nodeN
    ```
5.  在任意系统上，打开浏览器到以下
    URL，指定您授权的一个节点（请注意，这使用 `https`{.literal}
    协议）。这将调出 [**pcsd**]{.command} Web UI 登录屏幕。
    ``` screen
    https://nodename:2224
    ```
6.  以用户 `hacluster`{.literal}
    身份登录。[此时会出现管理集群页面]{.guilabel}，如 [图 2.1
    "管理集群页面"](#ch-pcsd-HAAR.html#fig-manage-cluster "图 2.1. 管理集群页面"){.xref}
    所示。
    ::: figure
    []{#ch-pcsd-HAAR.html#fig-manage-cluster}
    **图 2.1. 管理集群页面**
    ::: figure-contents
    ::: mediaobject
    ![管理集群页面](images/manageclusters.png)
    :::
    :::
    :::
:::
:::
::: section
::: titlepage
# []{#ch-pcsd-HAAR.html#s1-guiclustcreate-HAAR}使用 pcsd Web UI 创建集群 {.title}
:::
在 [Manage Clusters]{.guimenu}
页面中，您可以创建新集群，将现有集群添加到 Web UI 中，或者从 Web UI
中删除集群。
::: itemizedlist
-   要创建集群，请点击 [Create New]{.guilabel}
    并输入要创建的集群的名称以及组成集群的节点。您还可以在此屏幕中配置高级集群选项，包括集群通信的传输机制，如
    ["高级集群配置选项"一节](#ch-pcsd-HAAR.html#s2-advancedclustergui-HAAR "高级集群配置选项"){.xref}
    所述。输入集群信息后，点 [Create Cluster]{.guibutton}。
-   要将现有集群添加到 Web UI 中，请点击 [Add
    Existing]{.guilabel}，并输入您要使用 Web UI
    管理的集群中的节点的主机名或 IP 地址。
:::
[创建或添加集群后，会在管理集群页面中显示集群名称]{.guimenu}。选择集群会显示有关集群的信息。
::: {.note style="margin-left: 0.5in; margin-right: 0.5in;"}
### 注意 {.title}
当使用 [**pcsd**]{.command} Web UI
配置集群时，您可以将鼠标移到文本描述中，以作为 `工具提示`{.literal}