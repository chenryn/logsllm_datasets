title:On the Latency Impact of Remote Peering
author:Fabr&apos;ıcio M. Mazzola and
Pedro de B. Marcos and
Ignacio Castro and
Matthew Luckie and
Marinho P. Barcellos
On the Latency Impact of Remote
Peering
Fabricio Mazzola1(B), Pedro Marcos2, Ignacio Castro3, Matthew Luckie4,
and Marinho Barcellos4
1 UFRGS, Porto Alegre, Brazil
PI:EMAIL
2 FURG, Rio Grande, Brazil
PI:EMAIL
3 QMUL, London, UK
PI:EMAIL
4 University of Waikato, Hamilton, New Zealand
PI:EMAIL, PI:EMAIL
Abstract. Internet Exchange Points (IXPs) play an essential role in the
Internet, providing a fabric for thousands of Autonomous Systems (ASes)
to interconnect. Initially designed to keep local traﬃc local, IXPs now
interconnect ASes all over the world, and the premise that IXP routes
should be shorter and faster than routes through a transit provider may
not be valid anymore. Using BGP views from eight IXPs (three in Brazil,
two in the U.S., and one each in London, Amsterdam, and Johannes-
burg), a transit connection at each of these locations, and latency mea-
surements we collected in May 2021, we compare the latency to reach the
same addresses using routes from remote peers, local peers, and transit
providers. For four of these IXPs, at least 71.4% of preﬁxes advertised by
remote peers also had a local peering route, BGP generally preferred the
remote route due to its shorter AS path, but the local route had lower
latency than the remote route in the majority of cases. When a remote
route was the only peering route available at an IXP, it had slightly lower
latency than a corresponding transit route available outside the IXP for
>57.6% of the preﬁxes for seven of the eight IXPs.
1 Introduction
How to deliver traﬃc is an increasingly complex aspect of the Internet today
as many applications generate large volumes of traﬃc and have strict service
requirements. As a consequence, Autonomous Systems (ASes) are constantly
increasing their interconnection capacities and expanding their footprint. Inter-
net Exchange Points (IXPs) are key elements of this process, as they can shorten
Internet paths and reduce interconnection cost [4,10,17,31]. As of May 2021,
there were more than 800 IXPs deployed worldwide [22,29,46]. The largest IXPs
have surpassed 1000 members [32,35,36] and 10 Tbps of peak traﬃc [7,16,19,36].
An original motivation of IXPs was to keep local traﬃc local by having ASes
physically present at an IXP facility. However, IXPs no longer only interconnect
c(cid:2) The Author(s), under exclusive license to Springer Nature Switzerland AG 2022
O. Hohlfeld et al. (Eds.): PAM 2022, LNCS 13210, pp. 367–392, 2022.
https://doi.org/10.1007/978-3-030-98785-5_16
368
F. Mazzola et al.
members physically present at IXP facilities. Remote peering – where an AS is not
physically present at an IXP facility and reaches the IXP through a layer-2 provider
– allows ASes to widen their peering footprint with a quicker setup, no additional
hardware, and lower installation costs compared to local peering [9,15,20]. For
example, ASes from 85 diﬀerent countries connect to LINX remotely [36] as of May
2021. To cope with the demand for peering, IXPs and remote peering resellers have
expanded their oﬀerings [12,25,48] with some IXPs having up to 55 oﬃcial part-
ners selling remote peering services [8,32,37]. Network operators prefer to steer
traﬃc through IXPs instead of transit providers because of the reduced transit
and operational costs [18,21]. However, the ability to interconnect with remote
members at IXPs adds complexity to traﬃc engineering choices.
Given the public debate about remote peering performance [1,2,5,6,34,41,
43], which is currently data-poor, and to understand the latency properties of
BGP routes at IXPs, we analyze latency and latency variability when using
diﬀerent interconnection methods (remote peering, local peering, and transit)
to reach addresses in preﬁxes announced by remotely connected members in
eight IXPs identiﬁed in Table 1. These eight IXPs include six of the world’s ten
largest IXPs by membership, and are deployed in ﬁve countries (three in Brazil,
two in the U.S., and one each in London, Amsterdam, and Johannesburg). Our
contributions are as follows.
First, we ﬁnd that inferring remote ASes using the state-of-the-art method-
ology [42] based on latency and colocation data is insuﬃcient for some IXPs
(Sect. 3). Incomplete and/or inaccurate colocation data in regions, such as Latin
America, yields a high number of unknown inferences (more than 68.6% for
three IXPs). Because we need to infer which ASes are remotely connected to
a given IXP in order to identify preﬁxes announced by remote ASes, we infer
geographically distant remote ASes [15] and complement these inferences with
ground-truth data (Sect. 4). We found that at least 26.2% of all ASes connected
to major IXPs, such as PTT-SP and AMS-IX, were remotely connected mem-
bers in May 2021. These remotely connected members announced fewer than
≈15% of the preﬁxes visible at the IXP, for most IXPs.
Next, we classify preﬁxes announced by remote ASes in BGP data collected
from PCH and IXP looking glass servers. We focus our analysis on preﬁxes that
had routes available through both remote and local ASes (Sect. 5). We found
that for 82.5% of these preﬁxes, on average, the AS path for the route from
the remote peer was shorter or had the same length as the route from the local
peer in the four IXPs with most of these preﬁxes (LINX, AMS-IX, Eq-Ash, and
Eq-Chi). Using BGP views from RouteViews peers, we conﬁrmed that remote
routes tended to preferred by BGP. However, our latency measurements indicate
that the local route had a lower latency in most cases.
Finally, we examine the preﬁxes announced exclusively by remote members
at IXPs (Sect. 6). Our ﬁndings suggest that remote routes can have lower latency
to reach addresses in preﬁxes announced by remote ASes when compared with
a transit route, though not by a considerable margin for six out of eight IXPs:
using the remote route or the transit had a latency diﬀerence no higher than
5 ms for 78.1% of the measured preﬁxes. However, for NAPAfrica in South Africa,
On the Latency Impact of Remote Peering
369
Table 1. The eight IXPs analyzed in our study, along with the availability of BGP
VPs and ground truth data on remote peering.
IXP
Location
Observed BGP VPs Reseller
Interfaces LG PCH Ground Truth
Sao Paulo, BR
London, UK
Amsterdam, NL
PTT-SP
LINX
AMS-IX
NAPAfrica Johannesburg, ZA
Rio de Janeiro, BR
PTT-RJ
Fortaleza, BR
PTT-CE
Ashburn, VA, US
Eq-Ash
Chicago, IL, US
Eq-Chi
2,169
911
907
542
462
395
365
259
(cid:2)
(cid:2)
(cid:2)
✗
(cid:2)
(cid:2)
✗
✗
✗
(cid:2)
(cid:2)
(cid:2)
✗
✗
(cid:2)
(cid:2)
(cid:2)
(cid:2)
✗
✗
(cid:2)
(cid:2)
✗
✗
remote peering routes had a lower latency than transit routes, with a latency
beneﬁt of more than 40 ms for 81.4% of the measured preﬁxes.
2 Measurement Architecture
In this section, we discuss the measurement architecture we used. First, we
present the IXPs we measured (Sect. 2.1). Next, we describe the datasets we used
in our work, including the IXP ground truth and BGP routing data (Sect. 2.2).
Finally, we characterize the vantage points (VPs) along with the active measure-
ments we performed (Sect. 2.3).
2.1 Peering Infrastructure Selection
To identify networks connected via remote peering, and preﬁxes and routes
announced via remote peering, we need peering infrastructures that have (1) pub-
licly available BGP routing data, and (2) an active measurement VP attached to
the IXP switching fabric. Table 1 presents the eight selected IXPs where we had
both BGP routing data and active measurement capability. These IXPs include
six of the world’s ten largest IXPs by membership [22,29] and are deployed in
ﬁve diﬀerent countries. The three Brazilian IXPs (i.e., PTT sites) are part of the
largest ecosystem of public IXPs in the world (IX.br) and are the leading Latin
American IXPs in terms of average traﬃc volumes (≈12.9, 9.2, and 1.4 Tbps,
respectively) [3,13,14]. The eight IXPs together comprise 3466 unique ASes.
2.2 Datasets
Remote Peering Reseller Ground Truth Data. We obtained ground truth
information for the ASes remotely connected via resellers for four of the analyzed
IXPs: LINX, PTT-SP, PTT-RJ, and PTT-CE. The data set contains information
370
F. Mazzola et al.
about the ASN and IP interface of remote ASes reaching the IXPs through shared
ports or VLANs associated with resellers. For the PTT IXPs, we obtained the
ground truth data from their operators on the 20th April 2021. The set of ASes
reaching LINX through resellers or locally connected to the IXP is publicly avail-
able at their member portal [37] (collected on 5th May 2021). LINX representatives
conﬁrmed that ASes with Port Type labeled as ConneXions correspond to ASes
using resellers. The ground truth for the four IXPs comprise a list of 1634 unique
ASes using remote peering through resellers.
Membership and Interface Addresses. To identify the peering router’s IP
and ASN of all members at each IXP, we combine multiple public data sources
for all IXPs except for LINX, which publishes this information through their
member portal [37]. We collected membership data and subnet information from
Euro-IX [22] and the publicly available databases of Hurricane Electric (HE) [29],
PeeringDB (PDB) [46], and Packet Clearing House (PCH) IXP Directory [44]. In
cases of conﬂicts, we followed the preference ordering described in [42]: Euro-IX
> HE > PDB > PCH.
BGP Datasets and Sanitization. We used two sources of routing data: (i)
Looking Glass (LG) of the IXP which observes routes from the IXP’s Route
Server and (ii) routes from the archive collected by PCH [45]. For IXPs with
both PCH and LG views, we used data archived by PCH because it has greater
visibility of routes advertised by IXP members. For example, when comparing
both datasets for AMS-IX and LINX, we observed 3.4–3.9x more routes and 1.9–
2.0x more preﬁxes from PCH than from LG views. As our goal is to understand
the latency diﬀerence between routes announced at IXPs by diﬀerent peering
types (i.e., remote and local peering), we prefer the dataset from PCH whenever
it is available, as it provides us with better visibility of the IXP routes (PCH
> LG). On IXPs with only LG views (PTT sites), we have observed that LGs
are conﬁgured to output only the best routes at the time of our BGP routing
data collection, lowering the number of cases with multiple routes for the same
preﬁx. Additionally, we collected BGP data from RouteViews collectors at each
IXP to understand the types of routes that RouteViews peers actually chose. For
each IXP, we obtained a BGP snapshot corresponding to the same period our
measurements were performed (5–6 May 2021). We discarded: (i) routes with
artifacts, such as reserved/unassigned ASes [30] and loops; (ii) preﬁxes shorter
than /8 or longer than /24.
2.3 Data Plane Measurements
Vantage Points. At each IXP listed in Table 1, we used RouteViews collectors
which were directly connected to the IXP LAN to conduct active measurements
using scamper [38]. Figure 1 illustrates the measurement architecture of each
RouteViews collector and how we used them to conduct active measurements.
Measurement Types. We conducted two types of measurements. In the ﬁrst,
we measured the latency to each IXP member’s peering router. These mea-
surements use the IP address that the collector has in the IXP LAN (X.2), so
On the Latency Impact of Remote Peering
371
Fig. 1. Architecture of our data plane measurements. We used RouteViews collectors
with an interface connected to a transit provider and an interface in the IXP LAN as
VPs for data plane measurements. Delay measurements to the peering router of each
IXP member (e.g., X.3) used the collector’s IP address in the IXP LAN (X.2), so the
probes and responses crossed the IXP LAN. Other measurements used the Transit IP
address T.1 as the source address, and were delivered to each IXP member using the
layer-2 address corresponding to their IXP LAN IP address (e.g., X.4).
that probes and responses cross the IXP LAN, as in when we probe X.3 in
Fig. 1. In the second, we measured the path and latency to IP addresses within
preﬁxes announced by each IXP member. Note that these preﬁxes are peering
routes, and not transit routes. These measurements go out via a selected IXP
member (e.g. AS B, using the layer-2 address of X.4 in Fig. 1) but used the
collector’s Transit IP address T.1 as the source address, so that we could receive
a response. This strategy allowed us to maintain the same return path from