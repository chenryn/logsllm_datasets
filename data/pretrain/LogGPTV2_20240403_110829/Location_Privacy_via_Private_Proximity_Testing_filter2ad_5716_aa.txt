title:Location Privacy via Private Proximity Testing
author:Arvind Narayanan and
Narendran Thiagarajan and
Mugdha Lakhani and
Michael Hamburg and
Dan Boneh
Location Privacy via Private Proximity Testing
Arvind Narayanan
Narendran Thiagarajan Mugdha Lakhani
Michael Hamburg
Dan Boneh∗
Stanford University
Abstract
We study privacy-preserving tests for proximity: Alice
can test if she is close to Bob without either party reveal-
ing any other information about their location. We describe
several secure protocols that support private proximity test-
ing at various levels of granularity. We study the use of
“location tags” generated from the physical environment
in order to strengthen the security of proximity testing. We
implemented our system on the Android platform and re-
port on its effectiveness. Our system uses a social network
(Facebook) to manage user public keys.
1
Introduction
Location-aware devices, mainly smartphones, are ubiq-
uitous. While the number of location-based services has
mushroomed, adoption remains stagnant [52]. Privacy con-
cerns are a major factor holding up the growth of this mar-
ket [38, 40]. Users take location privacy seriously because
of the possibility of physical harm [42]. For an analysis of
the prevalence of location data on the Internet and the dan-
gers posed by it, see [14].
Current location-based services require the user to con-
stantly transmit their location to a server (or at least when-
ever services are required). Users have accepted being
tracked by the carriers, and there is some regulatory over-
sight over this; however, they are far more reluctant to share
location information with third party services whose repu-
tation is unknown. It would therefore be of great beneﬁt to
design practical location-based services in a way that mini-
mizes the information transmitted to the service provider.
We consider the problem of proximity testing with
privacy, which is an important and burgeoning type of
location-based service in social networking1. Private prox-
imity testing enables a pair of friends to be notiﬁed when
they are within a threshold distance of each other, but other-
wise reveal no information about their locations to anyone.
Location-based social networking is broader than just
proximity detection. Users may want location based gam-
∗Supported by NSF, MURI, and the Packard Foundation.
1Foursquare and Facebook Places are two prominent examples.
ing, activity streams ﬁltered by location, etc. We seek
to construct the fundamental cryptographic primitives on
top of which such functionality can be built in a privacy-
preserving way. While proximity detection by itself covers
a broad range of use cases (we give several examples be-
low), our solutions are also useful for the techniques that
can be used to construct other types of privacy-preserving
functionality.
Our contributions:
1. We put forth a set of desiderata for privacy-preserving
proximity testing. This is tricky because there are sev-
eral desirable security and efﬁciency properties that
conﬂict with each other. We aim for rigorous cryp-
tographic security deﬁnitions. In Section 6 we explain
why this is necessary and why more ad-hoc deﬁnitions
are inadequate.
2. We reduce private proximity testing to the underly-
ing cryptographic problem of private equality testing
(PET). We consider this problem in two different set-
tings: with or without the involvement of the server.
The server-mediated setting is more efﬁcient, but is
not secure against the collusion of the server with the
user’s friends. While PET has been considered before,
we design efﬁcient protocols in both settings that use
less bandwidth than older designs.
3. We show how to use location tags to enhance the se-
curity of private proximity testing. A location tag
is an ephemeral, unpredictable nonce associated with
a location and can be derived from various electro-
magnetic signals available in the environment, such as
WiFi and Bluetooth. It can be thought of as a shared
pool of entropy between all users at a given location at
a given time. The location tags we use are a variant of
the concept introduced by Qiu et al. [37, 36].
4. We describe a prototype that we have built for the An-
droid platform. One component of our system estab-
lishes shared keys between pairs of users and we take
a novel approach to this problem. We designed and
implemented a key agreement system using a social
network as a key-distribution mechanism, instead of
traditional PKI. Our system binds the user’s public key
to the user’s social network account (the current im-
plementation uses Facebook). We argue that using a
social network is a simpler and potentially more user-
friendly alternative to traditional PKI for managing
user public keys.
Motivation. Let us consider several applications of prox-
imity testing, keeping in mind that different applications re-
quire different proximity granularity.
• Alice and Bob are friends, and are serendipitously no-
tiﬁed that they are shopping in the same mall. They
meet and have a pleasant time together. Alternatively,
Alice and Bob ﬁrst meet online, but later decide to
meet in person at a coffee shop. Alice arrives ﬁrst and
is notiﬁed when Bob arrives.
• Alice would like to get dinner with her friend Bob who
travels a lot. Using privacy-preserving proximity test-
ing, Alice can check if Bob is town before calling him.
Note that for this application the proximity granularity
is a wide geographic area.
• Bob, a student lands at his college airport and wants
to check if anyone from his college is currently at the
airport and can give him a ride to campus.
• Alice is a manager who wants to automatically record
who is present at her daily meetings. However, her
employees do not want their location tracked. Privacy-
preserving proximity testing over this well organized
group allows satisfying both requirements.
Using our system, existing location-based social net-
works such as Loopt and Google Latitude could offer a ba-
sic or ‘lite’ version with limited functionality but respect-
ing privacy. This may spur adoption by privacy-conscious
users, and make the product more useful overall due to the
positive network externality (i.e., even the users who don’t
care about privacy beneﬁt from having more friends in the
system).
As discussed above, proximity detection is particularly
useful for group meetings, either ad-hoc groups or well or-
ganized groups such as project teams. More esoteric appli-
cations may include unit detection in ground combat. Pri-
vacy ensures that in case of capture, the proximity test does
not reveal the location of all combat units.
2 Model
All communication in our system takes place over the In-
ternet, i.e., we do not use direct physical channels between
nearby devices such as Bluetooth. All location-based ser-
vices today operate this way. We argue in Section 6 that
a peer-to-peer communication model does not support the
functionality we want.
Our system requires the existence of a social network,
i.e., a graph that captures trust relationships between users.
Our protocols allow detection of proximity between any two
users connected by an edge and we assume the existence of
shared secret keys between connected users (more details
on this are in Section 5.1).
The reason we only allow proximity testing between ad-
jacent nodes in a social network is that proximity detection
between strangers is a useful functionality, but is impossible
to do efﬁciently and privately in a client-server model. The
reason is that either the server will need to learn some infor-
mation about users’ locations, or it will need to treat every
pair of users identically, resulting in overall bandwidth re-
quirements quadratic in the number of users, unless limited
to pairs of friends. As we discuss in Section 6, revealing
even a minimal amount of information about users’ loca-
tions (e.g., the single-bit outcome of proximity testing be-
tween pairs of users) to the server results in an unacceptable
privacy leak when aggregated over time and users.
The ideal functionality of our model is in Section 2.5.
When location tags are available, the model is somewhat
different, and the ideal functionality is in Section 4. But
ﬁrst let us discuss some of the desiderata that will motivate
our model.
2.1 Desiderata: Functionality
Asymmetry. Proximity testing is asymmetric: one party
will learn if the other party is nearby whereas the other party
learns nothing. This is necessary because asymmetric edges
are common in social networks — Alice may be willing to
let Bob test proximity to her, but not vice versa. Of course,
if an edge is symmetric, then it can be treated as a pair of
directed edges, and we can execute the protocol twice in
either direction.
One important side-beneﬁt of asymmetry is the some of
our protocols can be executed in an asynchronous manner.
This has the potential to greatly decrease the communica-
tion cost. We explain this in more detail in Section 2.4.
Proximity threshold. The distance threshold for proxim-
ity detection should not be globally ﬁxed but instead con-
ﬁgurable by each user. This is because a larger threshold
is neither strictly worse nor strictly better than a smaller
one, either from the security or the functionality perspec-
tive. With a larger threshold, the user is easier to locate but
in case of a match their location is revealed less accurately.
Ideal functionality. The obvious way to deﬁne the “ideal
functionality” is as follows: whenever Alice and Bob are
within a distance δ (deﬁned by Alice) of each other, Bob
outputs 1, otherwise he outputs 0. However, there is a prob-
lem with this deﬁnition: even when δ is large, Bob can de-
termine Alice’s exact location by moving around and apply-
ing “triangulation” (assuming Alice is stationary).2
Since the natural ideal functionality is ﬂawed, we must
necessarily “quantize” the space of locations. We describe
our quantization technique in Section 2.5.
2.2 Desiderata: Security
The adversary might be law enforcement coercing the
service provider into revealing the user’s location, or it
might be someone colluding with the service provider. It
could also be one of the user’s friends — either because
the friend’s account has been compromised, or the attacker
set up a fake proﬁle, or simply because friendship on social
networks does not imply a high level of trust. Stalking is an
example of the threat from this type of adversary.
Broadly, these break down into untrusted server and un-
trusted friend(s). Our overall goal is to reveal as little as
possible to each party while enabling proximity testing. We
now discuss each threat in more detail.
Honest-but-curious friend. The space of possible loca-
tions has low entropy, and is therefore vulnerable to a brute-
force or dictionary attack. Suppose that the threshold dis-
tance for proximity detection is 10 meters; this results in
a search space of roughly 1010, which is less than 34 bits.
Therefore, the only meaningful way to deﬁne privacy is in
a manner analogous to semantic security or indistinguisha-
bility in cryptography; roughly, the protocol should reveal
no information other than the output of the computation.
Malicious friend. If the attacker has some background in-
formation about the user, the search space becomes smaller.
In the extreme case, the attacker might only be interested
in answering a binary question, e.g., whether the user is at
home or at work, in which case the search space is only 1
bit.
This shows another weakness of the ideal functionality:
even a protocol that reveals nothing but the output of the
computation is vulnerable to an online guessing attack by a
malicious friend (who is willing to lie about his own loca-
tion). Resisting such an attack is not critical: as we explain
in the next subsection, protocols in our system are naturally
rate-limited. Nevertheless, it is a useful desideratum.
In
Section 4 we explain how to resist online attacks using lo-
cation tags.
Server. In some of our protocols, the server is treated as
just a router of messages between users. These protocols
are secure against a malicious server due to the existence of
2Loopt has reported that users often carry out this attack on their sys-
tem.
shared secret keys between friends, which are used to es-
tablish an encrypted and authenticated channel between the
parties. The server can of course refuse to deliver messages,
but can do no other harm.
In our most efﬁcient protocols the server acts as a partic-
ipant. Here, we require that the server be able to learn no
information about users’ locations, even if it may be able to
cause the users to compute an incorrect answer.
Collusion. Malicious friends may collude with each other;
the security requirements should ideally still hold. As for
the server, in protocols where it acts a router security should
hold even if it colludes with any of the user’s friends. On the
other hand, when the server is a participant in the protocol,
we do not expect to have privacy against the collusion of
the server with a friend (indeed, it is this very relaxation
that allows efﬁciency gains in this model).
2.3 Desiderata: Efﬁciency
Mobile devices are resource-constrained, so we would
like to construct solutions that minimize computation and
bandwidth. Since we have an eye toward implementation,
we go beyond asymptotic analysis and also focus on opti-
mizing the constant factors involved.
Computation. While any two-party functionality can be
securely computed by expressing it as a special case of Yao
garbled-circuit evaluation [49], this can be too inefﬁcient for
use in practice. In general, we seek to minimize the number
of modular exponentiations and other expensive operations.
Protocols that avoid the use of large groups altogether are
particularly attractive.
Bandwidth is perhaps the most constrained resource, and
we would like to minimize the bandwidth required per edge.
It is an intriguing question whether we can use amortiza-
tion to design a protocol whose bandwidth requirement is
asymptotically smaller than the number of edges. It does
not appear to be possible to do so unless we compromise on
the security requirements.
Number of connections. Proximity testing needs to be car-
ried out between each pair of friends; however, executing
an instance of the protocol independently for each friend
would involve opening multiple connections to the server
(one for each edge in the system) and quickly becomes in-
feasible.
Instead, in our system, each user (say Alice) sends a
single message to the server that encapsulates her mes-
sages from all the instances of the protocol — one for each
friend. The server de-multiplexes these messages and then
re-multiplexes them by recipient. In this manner, the num-
ber of connections grows asymptotically as the number of
nodes in the system.
There are added subtleties in the case of synchronous
protocols; details are in Section 2.4.
2.4 Synchronous vs. asynchronous execution
A proximity testing protocol with a synchronous com-
munication pattern requires both parties to be online at the
same time. The role of the server is merely message pass-
ing.
In the synchronous pattern, the execution of the protocol
needs to happen at globally ﬁxed time intervals (say once
every 5 minutes). We call these intervals epochs. Each pro-
tocol round is executed synchronously by all users partici-
pating in the system, so that the multiplexing of messages
described in Section 2.3 can happen.
On the other hand, the communication pattern in some
protocols is asynchronous, which means that the two parties
do not have to be online at the same time. In other words,