title:EvilCoder: automated bug insertion
author:Jannik Pewny and
Thorsten Holz
EvilCoder: Automated Bug Insertion
Horst Görtz Institut (HGI)
Jannik Pewny
Ruhr-Universität
Bochum, Germany
PI:EMAIL
Horst Görtz Institut (HGI)
Thorsten Holz
Ruhr-Universität
Bochum, Germany
PI:EMAIL
ABSTRACT
The art of ﬁnding software vulnerabilities has been covered
extensively in the literature and there is a huge body of work
on this topic. In contrast, the intentional insertion of ex-
ploitable, security-critical bugs has received little (public)
attention yet. Wanting more bugs seems to be counterpro-
ductive at ﬁrst sight, but the comprehensive evaluation of
bug-ﬁnding techniques suﬀers from a lack of ground truth
and the scarcity of bugs.
In this paper, we propose EvilCoder, a system to auto-
matically ﬁnd potentially vulnerable source code locations
and modify the source code to be actually vulnerable. More
speciﬁcally, we leverage automated program analysis tech-
niques to ﬁnd sensitive sinks which match typical bug pat-
terns (e.g., a sensitive API function with a preceding san-
ity check), and try to ﬁnd data-ﬂow connections to user-
controlled sources. We then transform the source code such
that exploitation becomes possible, for example by remov-
ing or modifying input sanitization or other types of security
checks. Our tool is designed to randomly pick vulnerable lo-
cations and possible modiﬁcations, such that it can generate
numerous diﬀerent vulnerabilities on the same software cor-
pus. We evaluated our tool on several open-source projects
such as for example libpng and vsftpd, where we found
between 22 and 158 unique connected source-sink pairs per
project. This translates to hundreds of potentially vulner-
able data-ﬂow paths and hundreds of bugs we can insert.
We hope to support future bug-ﬁnding techniques by sup-
plying freshly generated, bug-ridden test corpora so that
such techniques can (ﬁnally) be evaluated and compared in
a comprehensive and statistically meaningful way.
1.
INTRODUCTION
Many diﬀerent kinds of software vulnerabilities exist, rang-
ing from simple buﬀer overﬂows [1] over integer overﬂows [8]
to temporal errors [3] or even errors introduced by the com-
piler due to undeﬁned behavior [35]. Numerous approaches
exist for ﬁnding such vulnerabilities and there is a huge body
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
ACSAC ’16, December 05-09, 2016, Los Angeles, CA, USA
c⃝ 2016 ACM. ISBN 978-1-4503-4771-6/16/12. . . $15.00
DOI: http://dx.doi.org/10.1145/2991079.2991103
of work on this topic. Such techniques are based on an anal-
ysis of the source code (e.g., [15, 22, 36]) or based on binary
analysis (e.g., [24, 34]), while others leverage fuzz testing
(e.g., [10, 12, 25]) or other techniques (e.g., [6, 33]).
We think that evaluating diﬀerent approaches for ﬁnding
vulnerabilities is a hard problem in practice for two main
reasons: ﬁrst, security vulnerabilities are scarce. That is not
to say that there are not too many of them, but for a sta-
tistically meaningful evaluation, they are simply spread too
thin and do not expose all facets of the underlying problem.
The second reason stems from the current practice to regard
ﬁnding new vulnerabilities as the most convincing argument
for a newly proposed technique. While this is the sole rea-
son as to why we develop such techniques, we argue that it
should not be how we evaluate bug-ﬁnding techniques.
In this work, we thus focus on the opposite problem: in-
stead of ﬁnding or ﬁxing vulnerabilities, we study the inser-
tion of security-critical bugs in complex software systems.
Compared to the volume of source code or binary code, vul-
nerabilities are relatively rare and tend to be ﬁxed once they
are found, which makes statistical evaluation complicated at
best. Having public bug-ridden test corpora with known bug
locations would help immensely to evaluate diﬀerent tech-
niques in an objective manner. For example, the ﬁeld of
machine-learning proceeds like this for years, having a few
standard corpora (like the Texas Instruments-MIT speech
corpus [11] or the Wall Street Journal corpus [32]), which
are widely used to compare new methods. We are con-
vinced that having freshly generated test corpora is crucial
for bug-ﬁnding techniques, as it prohibits memorizing the
bug database and forces any approach to abstract from the
details of the individual bugs. This may be one of the rea-
sons why the available static test corpora (e.g., [20, 30, 31])
are so seldom used in evaluating new techniques. Note that
by generating the bugs, one achieves ground truth for the
test corpus, as the full vulnerable path is known. Further-
more, such inserted bugs form a lower bound for the number
of bugs every bug-ﬁnding approach has to ﬁnd. This can be
understood in two ways: First, the approach could obvi-
ously ﬁnd more bugs in the test corpus, as the program may
have had vulnerabilities to begin with. Second, as these
ground-truth bugs are generated in an automatic way, they
are especially important to ﬁnd, given that they could the-
oretically be inserted by any attacker without much eﬀort.
Having the ability to check for places where a certain bug-
class might instantiate could also be used to assess two very
important data points: First, the number of places where it
could occur in the wild, which immediately gives a hint on
214
the exoticness of that class. Second, an estimation of the
ratio of how often it could occur and how often it does oc-
cur. This in turn could help to prioritize aid for developers
to prevent those mistakes that are made very often.
Our approach of automatically inserting exploitable soft-
ware vulnerabilities in the source code of a given application
works as follows. In a ﬁrst step, we analyze the source code
in order to ﬁnd sensitive sinks, which match our supported
bug patterns, and try to ﬁnd data-ﬂow connections stem-
ming from user-controlled sources. Then, we trace the con-
trol ﬂow between each source and sink connected by the data
ﬂow, which eﬀectively points us to locations which might
hinder exploitation (e. g., input sanitization routines or secu-
rity checks). If our analysis indicates that we indeed found
a potential location for a vulnerability, we transform the
source code such that exploitation becomes possible. Usu-
ally, there is more than one such location and the trans-
formation can happen in more than one way. Hence, we
can randomly choose a variant, which leads to a large set
of possible bugs. Note that we will often use the word bug
when referring to a vulnerability, although, one vulnerabil-
ity may necessitate the insertion of multiple bugs and, in
general, not every bug is security critical. Nevertheless, the
bugs we introduce are meant to be exploitable. However,
as the automated creation of proof-of-concept exploits is a
very complicated matter on its own, we take care to make
the bugs security critical and potentially exploitable by de-
sign, without checking the general satisﬁability of exploita-
tion conditions.
We implemented a tool called EvilCoder that demon-
strates the practical feasibility of our bug insertion tech-
niques. To this end, we extended Joern, an open-source
platform for robust C/C++ analysis by Yamaguchi et al. [36],
to facilitate interprocedural analysis and our bug insertion
techniques. In the current prototype, we focus on the gen-
eration of taint-style vulnerabilities [36], which cover many
vulnerability categories such as buﬀer overﬂows, integer over-
ﬂows, information leaks, and format string vulnerabilities.
However, we deem generating bug patterns for temporal vul-
nerabilities such as race condition or use-after free vulnera-
bilities to be possible as well.
We evaluate our tool by applying it to four diﬀerent open-
source projects, where we found between 22 and 158 unique
connected source-sink pairs per project. Since each such pair
can be connected with multiple data ﬂows, each such pair
usually accounts for dozens of potential locations to insert
vulnerabilities. Including our varying source-code modiﬁca-
tions, this could lead to hundreds of test cases for a bug-
ﬁnding tool. To justify our claim of generating potentially
exploitable bugs, we re-generated the vulnerability of a non-
trivial exploitable CVEs from the patched version of the
program. We plan to publish our tool and artiﬁcially bug-
infested corpora to encourage both the creation of public
benchmarks for future bug-ﬁnding research and new models
for automated bug insertion.
In summary, our main contributions in this paper are:
critical bugs into complex software systems.
• We present a method to automatically insert security-
• We implemented a prototype of our techniques called
EvilCoder, which can insert taint-style vulnerabili-
ties using six diﬀerent classes of instrumentation.
• We empirically demonstrated the capabilities of our
tool by ﬁnding between 22 and 158 unique, connected
source-sink pairs in four open-source projects, which
translates to hundreds of potential bugs. Furthermore,
we show that we can automatically re-generate the vul-
nerability in a non-trivial exploitable CVE from the
patched version of the program.
2. APPROACH
In this section, we deﬁne our goals and explain the design
and workﬂow of our approach to automatically add security-
critical bugs to arbitrary applications.
2.1 Purpose and Scope
Ultimately, we want to insert security-critical bugs into
an application. As noted above, we focus on generating test
corpora for bug-ﬁnding techniques. Since we do not want
to exclude techniques which rely on source code, we chose
to work on the source code level. Note that this does not
limit binary-based approaches, as the instrumented source
code can be compiled to generate a binary executables for
diﬀerent processor architectures.
This choice entails the need to choose a programming lan-
guage which we want to support for a prototype implemen-
tation. Because of its widespread use in important software
and its aﬃnity for security-critical bugs, we opted for the C
programming language. However, we think that the general
idea is applicable to other programming languages as well.
2.2 Supported Vulnerability Classes
Naturally, both ﬁnding potentially vulnerable source code
locations and instrumenting them to be actually security-
critical, are speciﬁc to the class of the vulnerability we want
to cover. We opted to focus on taint-style vulnerabilities [36]
because they account for many diﬀerent types of vulnerabil-
ities, mainly from the spatial domain. These vulnerabilities
are essentially characterized by an improperly secured data
ﬂow from a user-controlled source to a sensitive sink.
While we think that supporting taint-style vulnerabilities
is suﬃcient for a prototype, our system can be extended to
support other kinds of vulnerabilities in future work. Espe-
cially temporal vulnerabilities such as security-critical race
conditions or use-after-free vulnerabilities would require ad-
ditional reasoning about the life cycle of resources and ob-
jects, but we are convinced that our approach and imple-
mentation take a large step towards reaching this goal.
Note that the models we use for our supported vulnera-
bility classes are not exhaustive. For example, there will be
instances of buﬀer overﬂow vulnerabilities which are not cov-
ered by our model, and which we (as a consequence) cannot
generate. While we do not think that the models could ever
be exhaustive in practice, they can certainly be extended to
cover more cases by extending our current heuristics.
2.3 Supported Instrumentations
Given that taint-style vulnerabilities are deﬁned by im-
properly secured data ﬂows and that we start with an appli-
cation which we assume to be secure1, our task is essentially
to identify and then modify the security mechanisms.
The instrumentation can fall in one of two categories:
1During development, we actually encountered situations
where we could not locate the security mechanism between
source and sink for the simple reason that the code was al-
ready vulnerable.
215
n
r
e
o
J
o
t
n
i
t
r
o
p
m
I
I
n
s
t
r
u
m
e
n
t
r
e
t
e
m
a
r
a
P
s
s
e
s
s
A
n
o
i
t
a
c
i
f
i
d
o
m
I
n
s
t
r
u
m
e
n
t
a
t
i
o
n
s
C
h
o
o
s
e
p
o
s
s
i
b
e
l
Figure 1: Workﬂow of Automatic Bug Insertion
s
h
t
a
p
e
b
a
r