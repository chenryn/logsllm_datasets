delete n1, n2 & check if b(n1) or b(n2) decay,
sort blocks
sort blocks
a)
b)
c)
a)
b)
c)
proposed bfs needs to be conceived. For all kinds of graph
structures, the new heuristic should preferably ﬁnd an ordering
which leads to a maximal frontier with lower or at most equal
size in comparison to the bfs-heuristic. In case the cardinality
of the maximal frontier set is equal for both heuristics, the
cardinalities of all frontier sets Fk obtained from the new
heuristic should be less than or equal to those from the bfs-
heuristic.
At each level k of the factoring order (the number of levels
equals the number of edges of the input graph G), we have a
certain set of frontier nodes Fk. The cardinality of Fk highly
depends on the previous choices of edges to be factored and
is at least two. To keep the frontier size as small as possible,
we must focus on adding as few vertices as possible to Fk and
getting rid of as many vertices as possible from Fk at each
iteration of the edge choice (see Procedure 2). By choosing an
edge to factor, at most two new vertices can be added to the
current frontier Fk. This is done by choosing an edge which
is not adjacent to Fk. Hence, a better choice must be an edge
adjacent to Fk. Each time an edge is chosen, it is deleted from
G. Procedure 2 ends when all edges are deleted from G. The
candidate for our ﬁrst priority choice must be an edge which
connects two vertices n1, n2 ∈ Fk. In case this choice can be
made, the chosen edge is added to the variable order list order
and deleted from G (see Procedure 2 line 8). The size of Fk
would at least remain constant or at most decrease by two.
Everytime a choice is made, we subsequently have to check
whether the affected nodes n1, n2 must be added or removed
from Fk and subsequently update Fk. This fact is considered
in lines 9, 15 and 20 of Procedure 2. The maximal size of Fk
is updated after each iteration in line 5.
Otherwise, if the set of Fk-adjacent edges does not contain
any edge e = (n1, n2) with n1, n2 ∈ Fk, we decide for an
edge e = (nmin, n2) adjacent to the frontier node of lowest
deg(n), whereas the neighborhood of
degree nmin := arg min
n2, N (n2), contains at least one node from the current frontier
set Fk excluding nmin (second priority choice, see Procedure
2 line 12). If there are several nodes nmin meeting the second
priority and having the same degree, we randomly decide for
one of them. Otherwise, if there is no edge which meets the
second priority, we make our choice according to the third
priority: among the set of frontier nodes with minimal degree
J, we choose the egde with end vertex n2 which is from the
n∈Fk
532
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:01:15 UTC from IEEE Xplore.  Restrictions apply. 
neighborhood of J and has minimal degree (see Procedure 2
line 18) If the choice is not clear, we again randomly decide
for one possibility.
The reason behind this choice is that we expect nodes that are
still contained in Fk and nodes that will be added to Fk to
leave Fk as early as possible in one of the following iterations.
This also means that we needed at least deg(v)− 1 more edge
decisions for a recently added node v to leave the frontier set.
Finally, the variable order is returned as an ordered list of
edges order. The variable order and the size of the maximal
frontier set |Fmax| depends on the initial input node n. So
f indV arOrder is conducted for all nodes of v ∈ G and the
order is taken for the initial node n that gives the lowest size
for Fmax.
Complexity discussion: In Procedure 2, we decide |E| times
for an edge. In the worst case, there are no matches for the
ﬁrst and second priority choice in each iteration k. Since
each of the three priority choices implies the analysis of the
neighborhood N (Fk) of boundary set Fk, we have a worst
case complexity of O
for each iteration k,
where N (Fk) := {v /∈ Fk : (u, v) ∈ Ek, u ∈ Fk}. Deﬁne
Nmax to be the maximal cardinality neighborhood among all
frontier sets: Nmax := maxk |N (Fk)|. Overall, the worst case
. Note that
runtime complexity is O
Nmax ≤ |V | − |Fk(cid:2)|, with k
Procedure 2 f indV arOrder
Require: node n, Graph G
(cid:2)
1: Choose an edge (n, n
(cid:6)
(cid:5)|V | · |E| · |Fmax| · Nmax
|N (Fk)|.
(cid:5)|Fk| · |N (Fk)|(cid:6)
) := e ∈ E with n
(cid:2) ∈ {v ∈ N (n) :
:= arg maxk
(cid:2)
arg min deg(v)}
(cid:2)
)
2: order.add(e), G.delete(e)
3: F0.add(n), F0.add(n
4: while Fk (cid:2)= ∅ do
5:
6:
7:
8:
9:
10:
11:
12:
order.add(e), G.delete(e)
Update Fk
Update size of Fmax
//1st priority choice
for all edges (n1, n2) =: e ∈ Ek with n1, n2 ∈ Fk do
end for
//2nd priority choice
(cid:6)(cid:7)
Choose an edge e = (n1, n2) according to H :=
Fk \ {n1}(cid:5) ∩ N (n2)
arg min deg(n1) ∩ (cid:3)(cid:4)
(cid:4)
Fk \ {n1}(cid:5) ∩ N (n2) (cid:2)= ∅ then
if
(cid:2)
n1 ∈ Fk :
order.add(e), G.delete(e)
Update Fk
else
//3rd priority choice
Choose an edge e = (n1, n2) with
n1 ∈ J := {v ∈ Fk : arg min deg(v)}, n2 ∈ {v ∈ N (J) :
arg min deg(v)}
order.add(e), G.delete(e)
Update Fk
13:
14:
15:
16:
17:
18:
19:
20:
end if
21:
22: end while
23: return order
complete N-node network, and three irregular networks, the
”ARPANET 1979”8, ”DGN” and ”FNW”9.










Fig. 4. Fan network
a) Fan network: For the recurrent structure called ”Fan”
the new heuristic ﬁnds a variable
graph (see Figure 4),
ordering of |Fmax| = 3 with regard to the initial nodes
n ∈ S := {s, t, 1, 2, N − 1, N}. Otherwise, the new heuristic
yields |Fmax| = 4 for all n ∈ V \ S.
For n ∈ {s, t} the bfs-heuristic yields |Fmax| = N or
|Fmax| = N + 1. With respect to initial nodes in V \ {s, t},
the bfs-heuristic yields 3 ≤ |Fmax| ≤ N + 2 depending on the
order of the bfs-traversal.
For the bfs-heuristic, we have a huge difference of N − 1 for
|Fmax| between the worst and the best case, while the differ-
ence of |Fmax| values is only one for the new heuristic. For
this particular network, we obtain a better variable ordering
with the new heuristic.















Fig. 5. N-node complete graph (two-level bfs recursion)
b) Complete Graph: Applying the bfs heuristic to a
complete N-node graph yields a variable ordering which leads
to a sequence of frontier sets with the following cardinalities:
2, 3, . . . , N − 1
, N − 1, . . . , N − 1
(cid:7)
(cid:7)
(cid:10)
(cid:10)
,
N − 2, . . . , N − 2
(cid:7)
(cid:10)
, . . . , 4, 4, 4, 3, 3, 2
(cid:8)(cid:9)
(cid:8)(cid:9)
N−2 levels
N−2 levels
(cid:8)(cid:9)
N−3 levels
(1)
So we have in level one of the BDD-tree a frontier set F1
with size two, in level two |F2| = 3 and so forth, whereas
the last level is omitted, since the size of the last frontier set
equals zero. The accomplishment of this sequence is clariﬁed
by Figure 5. It shows the two recursion levels of the bfs. In the
ﬁrst level N-1 edges are consecutively chosen. Since they are
deleted together with node 0 (after being visited), each of the
remaining N-1 nodes has N-2 neighbors10. Again, N-2 edges
which are adjacent to one of the remaining nodes are chosen
and deleted from the graph. In the same way the choices are
C. Application on Example Graphs
In the following, we compare the results of both heuristics
based on two general regular networks, a Fan network and a
8The structure of the ARPANET 1979 is given in [28].
9Networks ”DGN” and ”FNW” are illustrated in [29].
10N (FN−1) is the neighborhood of FN−1.
533
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:01:15 UTC from IEEE Xplore.  Restrictions apply. 
made for the rest. Applying the new heuristic to the complete
graph, yields the reverse order of sizes of frontier sets. In
this sense, Expression 1 is mirrored. This gives |F1| = 2,
|F2| = 3, |F3| = 3, and so on. In total, the sum of frontier
sizes are equal and in addition to that the maximal frontier
size is N-1 for both. One would be left with the impression
that both heuristics should lead to the same performance of the
decomposition algorithm. However, this is not the case: though
frontier sizes in one of the ﬁrst levels are higher for the bfs
heuristic, the number of possible children in each BDD-level
l, l ∈ N, are limited to 2l due to the binary structure of the
BDD. In contrast to this, the higher frontier set cardinalities
obtained by the new heuristic for the last levels l, can lead to
a dramatic increase of the BDD width, since l has increased.
This fact is conﬁrmed by measurements for the complete 10-
node graph in Section IV. So for complete graphs, it is better
to utilize the bfs heuristic.
c) Irregular networks from the literature: Nevertheless,
we have found that
the new heuristic generally delivers
much better results for irregular graph structures such as the
”ARPANET 1979”: applying Procedure 2 to node 30 we obtain
|Fmax| = 6. Otherwise, the bfs-heuristic yields |Fmax| = 16.
Considering that for |K| = 2, there are at most 810 different
partitions for |Fmax| = 6 and around 41,92 billion partitions
for |Fmax| = 16, one can roughly guess the huge difference
in time and memory requirement claimed by the computation.
Similar results are obtained for ”DGN” and ”FNW” when
applying Procedure 2 to node 20 and 24 respectively. Not
only |Fmax| is vastly larger w.r.t bfs, also the cardinalities
for all frontier sets are signiﬁcantly higher. Consequently, this
inevitably leads to a huge difference in runtime and memory
demand approved by results of the following section. Further-
more, we have observed that in most cases of regular graph
structures - such as grid networks - it is of no matter which
heuristic to use . For those structures we cannot expect any
improvements since both heuristics deliver variable orderings
which have the same size of Fmax. Moreover, we have not yet
found any counterexamples where the new heuristic produces
variable orderings with higher |Fmax| than the current bfs-
heuristic. Our experimental results will show that the new
heuristic ﬁnds for many graphs - especially irregular graphs -
a better variable ordering with a signiﬁcantly lower cardinality
of Fmax than the bfs-heuristic.
IV. EXPERIMENTAL RESULTS
To prove the relevance of our proposal, we have compared
the decomposition and KLY method with respect to the current
bfs and the new heuristic. For further background and imple-
mentational details of the KLY method, we refer to a closely
related work [30]. The algorithms were benchmarked on 12
sample networks (see Figure 6) and two randomized sets of
networks. Nw. 1, 2, 3 are from [10], [31], Nw. 9 from [27], Nw.
10 from [24] and Nw. 11 (”DGN”), 12 (”FNW”) from [29].
In order to allow for a better comparison, the two-terminal
reliability was computed for all networks. The two terminals
s and t are marked in black. The networks 5-7 are also
known as street networks with parameter N, where N stands
for the number of horizontal edges in each row and N − 1
edges are in each column. To cover as many different graph
structures as possible and to realise a fair comparison, we
have additionally created different sets of randomized network
structures: Nw.13 and 14. The two methods were implemented
in C++ programming language and the experiments were run
on an Intel Xeon 5670 (Westmere EX) 2.93GHz machine
with 12MB L3 Cache and 40GB of RAM. For effectively
applying logic operations on ROBDDs, we have incorporated
the BuDDy BDD library [32] into the KLY method. The size
of the BDD depends on the bfs ordering and since the order
of this edge traversal is ambiguous, we might not obtain the
same BDDs as in [10] for the same input networks. However,
according to the bfs or new ordering the resulting BDDs
are the same for either of our implemented approaches. The
resulting BDDs only differ in their size, since the BDDs
obtained from the KLY approach are reduced OBDDs. For
the decomposition approach we do not necessarily need to
perform reductions as the BDDs are iteratively constructed
and no manipulations are taking place. For the reason of
comparability, all edges are assumed to fail with probability
of 0.1. In fact the failure probabilities can be arbitrary and in
addition they do not have any inﬂuence on the performance
of the algorithm.
A. Generation of randomized graphs
Based on the work in [33], we have used the GenGraph
tool to generate connected randomized networks whose degree
distribution follows the power-law. According to [33], the
power-law distribution for the node degree seems to give a
good replication of the Internet or real-world communication
network structures. The generated graphs depend on a set of
four parameters: N (the number of nodes), α (the exponent of
the power law distribution), mindeg (the minimal node out-
degree) and maxdeg (the maximal out-degree). In order to
make the computation feasible in a reasonable amount of time,
we have generated two sets of moderate-sized networks. Thus,
we have chosen the following parameter conﬁguration for
• Nw.13 : |V | = 66, α = 3, mindeg=2, maxdeg=4,
• Nw.14 : |V | = 45, α = 2, mindeg=2, maxdeg=4.
In the ﬁeld of fault-tolerant systems, it is realistic to assume
double, triple or quad redundancy justifying our choice for
mindeg and maxdeg. The parameter α determines the inter-
lacement of the network: the graph structure turns out to be
more ”planar” and less complex with increasing α. Since
the network gets more complex with a lower α, we had to
decrease the number of nodes to maintain the computation
feasible in short time. Each result listed for Nw.13 and 14 is
an average made up over 100 randomized samples × number
of all different s-t-pairs which equals 100 ×
B. Evaluation of results
(cid:11)(cid:2)|V |−1
(cid:12)
i=1
i
.
The results are captured in four tables: number of BDD-
nodes and reliability values are shown in Table VI, runtime
and speedup in Table VIII, peak memory consumption and the
534
Authorized licensed use limited to: Tsinghua University. Downloaded on March 19,2021 at 08:01:15 UTC from IEEE Xplore.  Restrictions apply. 
RELIABILITY VALUES AND NUMBER OF BDD-NODES GENERATED BY DECOMPOSITION & KLY METHOD W.R.T. NEW(1) AND BFS(2)
TABLE VI
|BDDD1|
|BDDD2|
|BDDKLY 1|
|BDDKLY 2|
Reliability
0.99712
0.987428
1.000000