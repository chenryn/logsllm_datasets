9
10
11
12
13
14 }
15 int main (int argc, char **argv) {
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31 }
Figure 1: An illustrative example for the runtime information gath-
ered by SNAP. The code abstracts demangling in cxxfilt.
static char mbuffer[32767];
unsigned i = 0;
int c = getchar();
// try to read a mangled name
while (c != EOF && ISALNUM(c) && i  0) demangle_it(mbuffer);
if (c == EOF) break;
mbuffer[i++] = c;
c = getchar();
}
return 0;
Algorithm 1: Edge encoding by AFL
: BBsr c → BBdst , pr evLoc
Input
1 cur Loc = Random(BBdst)
2 bitmap[cur Loc ˆ pr evLoc] += 1
3 pr evLoc = cur Loc ≫ 1
Output:pr evLoc – hash value for the next branch
with extra execution semantics. In particular, to achieve context
awareness, some fuzzers record additional execution paths if nec-
essary [13, 19, 26, 28], while others track data-flow information
[3, 12, 18, 43, 52, 60] that helps to bypass data-driven constraints.
These techniques enrich the coverage feedback and help a fuzzer
approach the bugs in Figure 1 sooner; yet they can be expensive and
are thus limited. For example, traditional dynamic taint analysis
can under-taint external calls and cause tremendous memory over-
head. Although lightweight taint analysis for fuzzing [18] tries to
reduce the overhead by directly relating byte-level input mutations
to branch changes without tracing the intermediate data flow, it can
still incur an additional 20% slowdown in the fuzzing throughput
of AFL across tested benchmarks.
2.3 Typical CPU Workflow
To motivate how hardware support can minimize the overhead
of fuzzing, we explain the typical CPU workflow. When a CPU
runs a program, it fetches and executes the instructions stored in
memory and constantly updates its program counter (PC), which
points to the current location being executed. A typical CPU core
consists of multiple pipeline stages, such as fetch, decode, execute,
and memory stages. Every instruction is processed in a specific way
throughout the pipeline stages based on its type. Among various in-
struction types, branch and jump instructions are notable since they
can change the control flow of a program and thus alter the execu-
tion order of instructions. To handle the control-flow instructions
Session 7B: FuzzingCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2216%rdx, (%rsp)
%rcx, 0x8(%rsp)
%rax, 0x10(%rsp)
1 # [Basic Block]:
2 # saving register context
3 mov
4 mov
5 mov
6 # bitmap update
7 mov
8 callq __afl_maybe_log
9 # restoring register context
10 mov
11 mov
12 mov
0x10(%rsp), %rax
0x8(%rsp), %rcx
(%rsp), %rdx
(a) AFL-gcc
$0x40a5, %rcx
%rax, %r14
%rbp
%r15
%r14
1 # preparing 8 spare registers
2 push
3 push
4 push
5 ...
6 mov
7 # [Basic Block]: bitmap update
8 movslq %fs:(%rbx), %rax
9 mov
10 xor
11 addb
12 movl
0xc8845(%rip), %rcx
$0xca59, %rax
$0x1, (%rcx,%rax,1)
$0x652c, %fs:(%rbx)
(b) AFL-clang
Figure 2: Source-instrumented assembly inserted at each basic block
between compilers.
while achieving high performance, modern computer architectures
adopt speculative execution, which allows the CPU to predict the
branch target instruction and proceed with the program execution
based on the prediction result instead of stalling the pipeline until
a destination directed by a control-flow instruction is decided. If
the branch prediction turns out to be wrong, the CPU flushes its
pipeline to discard the execution on the wrong path and restores
the previous architecture states. Such a design reveals that every
control-flow divergence during program execution is observed and
appropriately managed inside the CPU pipeline. Considering that
one essential task of fuzzing is to monitor control-flow transfer and
manage code-coverage information, we discuss how to view fuzzing
from a hardware perspective and benefit from possible advantages
available at the hardware level in §4.
3 DISSECTING AFL’S TRACING OVERHEAD
In this section, we provide a detailed examination of AFL, a state-
of-the-art coverage-guided fuzzer, on its excessive coverage tracing
overhead as a motivating example. Among the existing coverage-
guided fuzzers, AFL [61] is the most iconic one and has inspired
numerous fuzzing projects [10, 17, 45]. Despite the differences in the
adopted strategies for prioritizing seeds and generating testcases,
coverage-guided fuzzers mostly choose to monitor code coverage
at edge granularity. In general, edge coverage is preferred over
basic block coverage because of the additional semantics it embeds
to represent the program space. Specifically, a piece of code will
be injected at each branch location of the program to capture the
control-flow transfer between a pair of basic blocks, along with
coarse-grained hit counts (i.e., number of times the branch is taken)
for repetitive operations (e.g., loops) if necessary. Algorithm 1 de-
picts the tracing logic adopted by AFL.
AFL injects the logic into a target program in two different ways
based on the scenarios. When source code is available, AFL utilizes
the compiler or the assembler to directly instrument the program.
Otherwise, AFL relies on binary-related approaches such as DBI
and binary rewriting. While source code instrumentation is typi-
cally preferred due to its significantly lower tracing overhead com-
pared to binary-related approaches, previous research indicates that
AFL can still suffer from almost a 70% slowdown under the tested
benchmarks [48]. Table 1 shows that the situation can worsen for
CPU-bound programs, with an average tracing overhead of 60%
from source code instrumentation and 260% from DBI (i.e., QEMU).
In the worst case, DBI incurs a 5× slowdown. The tracing overhead
from DBI mostly comes from the binary translation of all applicable
instructions and trap handling for privileged operations. On the
Name
perlbench
bzip2
gcc
mcf
gobmk
hmmer
sjeng
libquantum
h264ref
omnetpp
astar
xalancbmk
Mean
Size (MB)
Runtime Overhead (%)
instrumented AFL-clang AFL-QEMU
376.65
211.14
257.76
92.52
224.27
340.03
261.04
186.63
542.73
186.35
124.93
317.63
260.14
6.56
1.20
15.73
0.95
8.11
2.57
1.38
1.23
3.43
7.31
1.39
49.56
8.29 (207.04%)
105.79
63.66
57.15
66.30
44.80
39.34
47.36
47.95
49.32
48.97
43.57
107.64
60.15
baseline
2.58
0.95
4.51
0.89
4.86
1.51
1.04
1.10
1.70
3.72
1.10
8.49
2.70
Table 1: The cost of program size and runtime overhead for tracing
on an x86 platform across the SPEC benchmarks.
other hand, the overhead of source code instrumentation results
from the instructions inserted at each basic block that not only
profiles coverage but also maintains the original register values to
ensure that the instrumented program correctly runs. Figure 2a
depicts the instrumentation conducted by afl-gcc, which requires
assembly-level rewriting. Due to the crude assembly insertion at
each branch, the instructions for tracing (line 7-8) are wrapped
with additional instructions for saving and restoring register con-
text (line 3-5 and line 10-12). Figure 2b shows the same processing
done by afl-clang, which allows compiler-level instrumentation
through intermediate representation (IR). The number of instruc-
tions instrumented for tracing can thus be minimized (line 8-12)
thanks to compiler optimizations. Nevertheless, the instructions
for maintaining the register values still exist and blend into the
entire workflow of the instrumented program (line 2-6). Table 1
lists the increased program sizes resulting from instrumentation
by afl-clang, suggesting an average size increase of around 2×.
The increase of program size and the runtime overhead given by
afl-gcc can be orders of magnitude larger [62].
4 SNAP
Motivated by the expensive yet inevitable overhead of existing
coverage-tracing techniques, we propose SNAP, a customized hard-
ware platform that implements hardware primitives to enhance the
performance and precision of coverage-guided fuzzing. A fuzzer
coached by SNAP can achieve three advantages over traditional
coverage-guided fuzzers.
1 Transparent support of fuzzing. Existing fuzzers instrument
each branch location to log the control-flow transfer, as explained
in §3. When source code is not available, the fuzzer has to adopt
slow alternatives (e.g., Intel PT and AFL QEMU mode) to conduct
coverage tracing, a much less favored scenario compared to source
code instrumentation. By sitting in the hardware layer, SNAP helps
fuzzers to construct coverage information directly from the proces-
sor pipeline without relying on any auxiliary added to the target
program. SNAP thus enables transparent support of fuzzing any
binary, including third-party libraries or legacy software, without
instrumentation, making fuzzing universally applicable.
2 Efficient hardware-based tracing. At the hardware level,
many useful resources are available with low or zero cost, most of
Session 7B: FuzzingCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea2217(a) Overview of SNAP.
(b) Architecture of the RISC-V BOOM core.
Figure 3: Overview of SNAP with its CPU design. The typical workflow involves the components from userspace, kernel, and hardware. The architecture
highlights the modified pipeline stages for the desired features, including trace decision logic, Bitmap Update Queue (BUQ), and Last Branch Queue (LBQ).
which are not exposed to higher levels and cause excessive over-
head to be obtained through the software stack. For example, SNAP
provides the control-flow information by directly monitoring each
branch instruction and the corresponding target address that has
already been placed in the processor execution pipeline at runtime,
eliminating the effort of generating such information that is unavail-
able in the original program execution from a software perspective.
This allows fuzzers to avoid program size increase and significant
performance overhead due to the instrumentation mentioned in
Table 1. In addition, SNAP utilizes idle hardware resources, such as
free cache bandwidth, to optimize fuzzing performance.
3 Richer feedback information. To collect richer information
for better precision of coverage, many existing fuzzers require
performance-intensive instrumentation. Surprisingly, we observe
that the micro-architectural state information already embeds rich
execution semantics that are invisible from the software stack with-
out extra data profiling and processing. In addition to code coverage,
SNAP exposes those hidden semantics to construct better feedback
that can more precisely approximate program execution states with-
out paying extra overhead. Currently, SNAP provides the records
of last-executed branches and the prediction results to infer imme-
diate control-flow context and approximated data flows. We leave
the support of other micro-architectural states as future work.
Figure 3a shows an overview of SNAP in action, which includes
underlying hardware primitives, OS middleware for software sup-
port, and a general fuzzer provided by the user. While running on
SNAP, a fuzzer is allowed to configure the hardware and collect
desired low-level information to construct input feedback through
interfaces exposed by the OS. In addition, the fuzzer coached by
SNAP can perform other fuzzing adjustments directly through the
hardware level, such as defining code regions for dedicated test-