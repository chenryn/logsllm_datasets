title:Detecting Manipulated Remote Call Streams
author:Jonathon T. Giffin and
Somesh Jha and
Barton P. Miller
USENIX Association
Proceedings of the
11th USENIX Security
Symposium
San Francisco, California, USA
August 5-9, 2002
© 2002 by The USENIX Association
Phone: 1 510 528 8649
FAX: 1 510 548 5738
THE ADVANCED COMPUTING SYSTEMS ASSOCIATION
All Rights Reserved
Email: PI:EMAIL
For more information about the USENIX Association:
WWW: http://www.usenix.org
Rights to individual papers remain with the author or the author's employer.
 Permission is granted for noncommercial reproduction of the work for educational or research purposes.
This copyright notice must be included in the reproduced paper. USENIX acknowledges all trademarks herein.
Detecting Manipulated Remote Call Streams
Jonathon T. Giffin
Somesh Jha
Barton P. Miller
Computer Sciences Department
University of Wisconsin, Madison
{giffin,jha,bart}@cs.wisc.edu
Abstract
In the Internet, mobile code is ubiquitous and includes such examples as browser plug-ins, Java applets, and document macros. In
this paper, we address an important vulnerability in mobile code security that exists in remote execution systems such as Condor,
Globus, and SETI@Home. These systems schedule user jobs for execution on remote idle machines. However, they send most of
their important system calls back to the local machine for execution. Hence, an evil process on the remote machine can manipulate
a user’s job to send destructive system calls back to the local machine. We have developed techniques to remotely detect such
manipulation.
Before the job is submitted for remote execution, we construct a model of the user’s binary program using static analysis. This
binary analysis is applicable to commodity remote execution systems and applications. During remote job execution, the model
checks all system calls arriving at the local machine. Execution is only allowed to continue while the model remains valid. We begin
with a ﬁnite-state machine model that accepts sequences of system calls and then build optimizations into the model to improve its
precision and efﬁciency. We also propose two program transformations, renaming and null call insertion, that have a signiﬁcant
impact on the precision and efﬁciency. As a desirable side-effect, these techniques also obfuscate the program, thus making it harder
for the adversary to reverse engineer the code. We have implemented a simulated remote execution environment to demonstrate how
optimizations and transformations of the binary program increase the precision and efﬁciency. In our test programs, unoptimized
models increase run-time by 0.5% or less. At moderate levels of optimization, run-time increases by less than 13% with precision
gains reaching 74%.
1 Introduction
Code moves around the Internet in many forms, includ-
ing browser plug-ins, Java applets, document macros,
operating system updates, new device drivers, and
remote execution systems such as Condor [26], Globus
[13,14], SETI@Home [32], and others
[1,11,35].
Mobile code traditionally raises two basic trust issues:
will the code imported to my machine perform mali-
cious actions, and will my remotely running code exe-
cute without malicious modiﬁcation? We are addressing
an important variant of the second case: the safety of my
code that executes remotely and makes frequent service
requests back to my local machine (Figure 1). In this
case, we are concerned that a remotely executing pro-
This work is supported in part by Ofﬁce of Naval Research grant
grants DE-FG02-
and DE-FG02-01ER25510, Lawrence Livermore
N00014-01-1-0708, Department
93ER25176
National Lab grant B504964, and NSF grant EIA-9870684.
of Energy
The U.S. Government is authorized to reproduce and distribute
reprints for Governmental purposes, notwithstanding any copyright
notices afﬁxed thereon.
The views and conclusions contained herein are those of the
authors and should not be interpreted as necessarily representing the
ofﬁcial policies or endorsements, either expressed or implied, of the
above government agencies or the U.S. Government.
cess can be subverted to make malicious requests to the
local machine.
The popular Condor remote scheduling system [26]
is an example of a remote execution environment. Con-
dor allows a user to submit a job (program), or possibly
many jobs, to Condor to run on idle machines in their
local environment and on machines scattered world-
wide. Condor jobs can execute on any compatible
machine with no special privilege, since the jobs send
their ﬁle-access and other critical system calls to execute
on their home machines. The home or local machine
acts as a remote procedure call (RPC) server for the
remote job, accepting remote call requests and process-
ing each call in the context of the user of the local sys-
tem. This type of remote execution, with frequent
interactions between machines, differs from execution
of “mobile agents” [17,30], where the remote job exe-
cutes to completion before attempting to contact and
report back to the local machine.
If the remote job is subverted, it can request the
local machine to perform dangerous or destructive
actions via these system calls. Subverting a remote job
is not a new idea and can be done quickly and easily
with the right tools [16,27]. In this paper, we describe
techniques to detect when the remote job is making
requests that differ from its intended behavior. We are
Local Host
Remote Host
Local
Agent
Remote
System Calls
Application
Process
Figure 1: Remote execution with system calls being
executed on home (local) machine.
addressing the issue of the local host’s safety; we are not
protecting the remote job from inappropriate access to
its data nor are we detecting modiﬁcation of its calcu-
lated result (beyond those which would appear as inap-
propriate remote system calls).
A local machine that accepts calls as valid without
ﬁrst verifying that the remote job generated the calls
during correct execution is vulnerable to maliciously
generated calls. Conventional authentication methods
using secret data fail in this inherently risky environ-
ment. An attacker knows everything present
in the
remote code, including an authentication mechanism or
key, and can manipulate this code at will. Thus,
although the local machine must distrust calls from
remotely executing code, it has little ability to validate
these requests. This vulnerability currently exists in the
thousands of machines worldwide running Condor, Glo-
bus, Java applets, and similar systems. Our techniques
address this deﬁciency.
Our basic approach to detecting malicious system
call streams is to perform a pre-execution static analysis
of the binary program and construct a model represent-
ing all possible remote call streams the process could
generate. As the process executes remotely, the local
agent operates the model incrementally, ensuring that
any call received remains within the model. Should a
call fall outside the set of expected next calls determined
by the model, we consider the remote process manipu-
lated. Reasonably, a precise model should closely mirror
the execution behavior of the application.
As others have noticed [23,36,37], speciﬁcation of a
program’s intended behavior can be used for host-based
intrusion detection. Our approach brings four beneﬁts to
these intrusion detection systems:
•
•
•
•
We further address an important new source of vulnera-
bilities: request veriﬁcation when even cryptographic
authentication mechanisms cannot be trusted.
Direct operation on binary code.
Automated construction of speciﬁcations.
Elimination of false alarms.
Protection against new types of attacks.
Any program model representing sequences of
remote system calls is valid. Previous model construc-
tion techniques include human speciﬁcation [22] and
dynamic analysis. A dynamic analyzer completes train-
ing runs over multiple execution traces to build proba-
bility distributions indicating the likelihood of each call
sequence [12,15,39]. False alarms occur if the training
runs do not exercise all possible program control ﬂows.
Static analysis produces non-probabilistic models repre-
senting all control ﬂow paths through an executable.
These models are conservative, producing no false
alarms [36,37] but potentially accepting an attack
sequence as valid.
Our models are ﬁnite-state machines. We use con-
trol ﬂow graphs generated from the binary code under
analysis to construct either a non-deterministic ﬁnite-
state automaton or a push-down automaton to mirror the
ﬂow of control in the executable. Automata are natural
structures to represent sequences of remote call names,
with push-down automata being more precise. We
develop several optimizations to further increase preci-
sion while maintaining run-time efﬁciency.
We evaluate our program models using two metrics:
precision and efﬁciency. Precision measures how tightly
the model ﬁts the application it represents. Improving
precision reduces the opportunity for an attack to be
accepted as valid by the model. Efﬁciency rates the run-
time impact of model operation. To evaluate our tech-
niques and models, we built a prototype static analyzer
and model builder for a simulated remote execution
environment. We read binary programs on SPARC
Solaris machines and produce a model for operation by
a simulated local agent. The agent receives notiﬁcations
from the application when system calls are encountered
during execution and operates the model accordingly.
Our models are efﬁcient. Non-deterministic ﬁnite-
state automaton (NFA) models add 0.5% or less to the
run-times of our test applications. In the less precise
NFA models, optimizations become invaluable. Moder-
ate optimization levels improve precision up to 74%
while keeping run-time overheads below 13%. Opti-
mized push-down automaton models are more precise,
but keep overheads as low as 1%. The precision values
of these optimized models approach zero, indicating lit-
tle opportunity for an adversary to begin an attack.
Other strategies have been used to counter mobile
code manipulation exploits. Generally orthogonal, one
ﬁnds the greatest security level when incorporating
components of all three areas into a solution.
Replication. A form of the Byzantine agreement
[24], a remote call will be accepted as genuine if a
majority of replicated processes executing on different
machines generate the identical call. Sometimes used to
verify the results returned by mobile agents [31], such
techniques appear limited in an environment with fre-
quent system call interactions over a wide network.
Obfuscation. A program can be transformed into
one that is operationally equivalent but more difﬁcult to
analyze [7,8,30,38]. We are applying a variant of such
techniques to improve our ability to construct precise
state machines and hamper an adversary’s ability to
understand the semantics of the program. Even though it
has been popular in recent years to discount obfuscation
based upon Barak et. al. [5], in Section 3.4.2 we discuss
why their theoretical results do not directly apply in our
context.
Sandboxing. Running a program in an environment
where it can do no harm dates back to the early days of
the Multics operating system project [29]. CRISIS, for
example, maintains per-process permissions that limit
system access in WebOS [6]. Our techniques could be
considered a variety of sandboxing, based on strong
analysis of the binary program and construction of a
verifying model to support that analysis.
This paper makes contributions in several areas:
Binary analysis. We target commodity computa-
tional Grid environments where the availability of
source code for analysis cannot be assumed. Further, our
analysis is not restricted to a particular source language,
so our techniques have wide applicability.
Model optimizations. We develop and use tech-
niques to increase the precision of
the ﬁnite-state
machines we generate, limiting the opportunities for an
attacker to exploit a weakness of the model. In particu-
lar, we reduce the number of spurious control ﬂows in
the generated models with dead automata removal,
automata inlining, the bounded stack model, and the
hybrid model. Argument recovery reduces opportunities
for exploit. We also present a linear time e -reduction
algorithm to simplify our non-deterministic state
machines.
Reduced model non-determinism with obfuscatory
beneﬁts. Many different call sites in a program generate
requests with the same name. (All opens, for example.)
Our technique of call site renaming gives us a great abil-
ity to reduce the non-determinism of our models by
uniquely naming every call site in the program and
rewriting the executable. We further insert null calls–
dummy remote system calls–at points of high non-deter-
minism to provide a degree of context sensitivity to the
model. Call site renaming and null call insertion addi-
tionally obfuscate the code and the remote call stream.
With binary rewriting, other obfuscation techniques are
likewise possible.
Context-free language approximations. In general,
the language generated by the execution trace of a pro-
Local Host
Remote Host
Malicious
Remote Calls
Local
Agent
Application
Process
Lurker
Figure 2: Grid environment exploit. A lurker process
attaches to the remote job, inserting code that takes control of
the network link.
gram is context-free. A push-down automaton–a ﬁnite-
state machine that includes a run-time stack–deﬁnes a
context-free language. However, such automata are pro-
hibitively expensive to operate incrementally [36,37]
and stack growth potentially consumes all system
resources. We use stack abstractions that over-approxi-
mate a context-free language with a regular language.
Our push-down automata with bounded run-time stack
are less expensive to operate and require ﬁnite
resources.
We provide background on the Condor system,
remote execution in the computational Grid environ-
ment, and security exploits in Section 2. Section 3 pre-
sents our analysis techniques in an algorithmic fashion.
Experimental results are found in Section 4 and compar-
ison to previous work in Section 5. Related work can be
found in Section 6. We conclude in Section 7 with
descriptions of several areas of continuing work.
2 Threats
Remote execution is becoming a common scenario. An
important class of remotely executing jobs require a
communication path back to the local machine that orig-
inated the job; the job sends its critical system calls,
such as those for ﬁle access or network communication,
back to the local machine to execute in the context of the
submitting user. This type of remote execution occurs in
the Condor distributed scheduling system [26], Globus
computational Grid infrastructure [13,14], and Java
applets.
The implementation associated with our research
takes place in the context of Condor. Condor schedules
jobs on hosts both within the originator’s organization
and on machines belonging to other organizations. In
addition to scheduling these remote jobs, Condor check-
points and migrates the jobs as necessary for reliability
and performance reasons. It is possible for a given job to
execute, at different times, on several hosts in several
different administrative domains.
Condor is a prevalent execution environment, par-
ticularly for scientiﬁc research. For example, in the year
2000, researchers used Condor to solve a 32-year-old
unsolved combinatorial optimization problem called
nug30 [2]. Remote jobs ran on 2510 processors across
the United States and Italy and outside the administra-
tive control of the program’s authors. Furthermore, the
network path between each remote process and its origi-
nating host included public Internet links. A malicious
third party with access to either the execution machines
or network links could have manipulated the originating
machine, as we now detail.
Remote system calls in Condor are simply a variant
of a remote procedure call (RPC). A client stub library is
linked with the application program instead of the stan-
dard system call library. The stub functions within this
library package the parameters to the call into a mes-
sage, send the message over the network to the submit-
ting machine, and await any result. A local agent on the
submitting machine services such calls, unpacking the
request, executing the call, and packaging and sending
any result back to the remote machine.
This RPC model exposes the submitting machine to
several vulnerabilities. These vulnerabilities have the
common characteristic that a malicious entity on the
remote machine can control the job, and therefore con-
trol its remote system call stream. This malicious system
call stream could cause a variety of bad things to be
done to the submitting user. The simplest case of a mali-
cious remote host is when the host’s owner (with admin-
istrative privileges) takes control of the remote job.
More complex and harder-to-track cases might be
caused by previous malicious remote jobs. A previously
discovered vulnerability in Condor had this characteris-
tic [27]. When a remote job executes, it is typically run
as a common, low privilege user, such as “nobody.” A
malicious user could submit a job that forks (creates a
new process) and then terminates. The child process
remains running, but it appears to Condor as if the job
has terminated. When a new job is scheduled to run on
that host, the lurking process detects the newly arrived
job and dynamically attaches to the job and takes con-
trol of it. The lurker can then generate malicious remote
calls that will be executed to the detriment of the
machine that originated the innocent job (see Figure 2).
results are possible with less unusual
attacks. If the call stream crosses any network that is not
secure, a machine on the network may impersonate the
application process, generating spoofed calls that may
be treated by the local host as genuine. Imposter applets
have successfully used impersonation attacks against the
Similar
Binary
Program
Analyzer
Checking
Agent
Modiﬁed
Application
Figure 3: Our static analyzer reads a binary program and
produces a local checking agent and a modiﬁed application
that executes remotely. The checking agent incorporates a
model of the application.
servers with whom the original applets communicate
[16].
3 Generating Models Using Static Analysis
We start with the binary program that is submitted for
execution. Before execution, we analyze the program to
produce two components: a checking agent and a modi-
ﬁed application (see Figure 3). The checking agent is a
local agent that incorporates the model of the applica-
tion. As the agent receives remote system calls for exe-
cution, it ﬁrst veriﬁes the authenticity of each call by
operating the model. Execution continues only while the
model remains in a valid state. The modiﬁed application
is the original program with its binary code rewritten to
improve model precision while also offering a modicum
of obfuscation. The modiﬁed application executes
remotely, transmitting its remote system calls to the
checking agent.
Our various models are ﬁnite-state machines: non-
deterministic ﬁnite automata (NFA) and push-down
automata (PDA). Each edge of an automaton is labeled
with an alphabet symbol–here the identity of a remote
system call. The automaton has ﬁnal states, or states
where operation of the automaton may successfully
cease. The ordered sequences of symbols on all con-
nected sequences of edges from the entry state to a ﬁnal
state deﬁne the language accepted by the automaton.
For a given application, the language deﬁned by a per-
fect model of the application is precisely all possible
sequences of remote system calls that could be gener-
ated by the program in correct execution with an arbi-
trary input.
Construction of the automaton modeling the appli-
cation progresses in three stages:
1. A control ﬂow graph (CFG) is built for each proce-
dure in the binary. Each CFG represents all possible
execution paths in a procedure.
main (int argc, char **argv) {
main:
if (argc > 1) {
write(1,argv[1],10);
line(1);
end(1);
} else {
write(1,“none\n”,6);
close(1);
}
}
line (int fd) {
write(fd, “\n”, 1);
}
end (int fd) {
line(fd);
close(fd);
}
save
cmp %i0, 1
ble L1main
mov 1, %o0
ld [%i1+4], %o1
call write
mov 10, %o2
call line
mov 1, %o0
call end
mov 1, %o0
b L2main
nop
L1main:
sethi %hi(Dnone), %o1
or %o1, %lo(Dnone), %o1
call write
mov 6, %o2
call close
mov 1, %o0
L2main:
ret
restore
Figure 4: Code Example. (a) This C code writes to stdout a command line argument as text or the string “none\n” if no
argument is provided. (b) The SPARC assembly code for main. We do not show the assembly code for line or end.
(a)
(b)
CFG ENTRY
save
cmp %i0, 1
ble
mov 1, %o0
sethi %hi(Dnone), %o1
or %o1, %lo(Dnone), %o1
call write
mov 6, %o2
write
call close
mov 1, %o0
ld [%i1+4], %o1
call write
mov 10, %o2
write
call line
mov 1, %o0