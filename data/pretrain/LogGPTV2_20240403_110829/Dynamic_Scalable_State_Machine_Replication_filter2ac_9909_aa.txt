title:Dynamic Scalable State Machine Replication
author:Long Hoang Le and
Carlos Eduardo Benevides Bezerra and
Fernando Pedone
Optimistic Parallel State-Machine Replication
Parisa Jalili Marandi
University of Lugano
Switzerland
Fernando Pedone
University of Lugano
Switzerland
4
1
0
2
r
p
A
7
2
]
C
D
.
s
c
[
1
v
1
2
7
6
.
4
0
4
1
:
v
i
X
r
a
Abstract—State-machine replication, a fundamental approach
to fault tolerance, requires replicas to execute commands de-
terministically, which usually results in sequential execution of
commands. Sequential execution limits performance and under-
uses servers, which are increasingly parallel (i.e., multicore). To
narrow the gap between state-machine replication requirements
and the characteristics of modern servers, researchers have
recently come up with alternative execution models. This paper
surveys existing approaches to parallel state-machine replication
and proposes a novel optimistic protocol that inherits the scalable
features of previous techniques. Using a replicated B+-tree ser-
vice, we demonstrate in the paper that our protocol outperforms
the most efﬁcient techniques by a factor of 2.4 times.
I.
INTRODUCTION
State-machine replication (SMR) is a fundamental ap-
proach to designing fault-tolerant services [1], [2]. In this
technique, to preserve consistency replicas of a service execute
a unique ordered sequence of commands deterministically. If
some of the replicas fail, the service remains available to
clients through the operational replicas. Determinism prevents
replicas from exploiting multithreading and is contrary to the
nature of modern servers, which are essentially parallel (i.e.,
multicore architectures). Therefore, services replicated with the
state-machine approach cannot beneﬁt from parallelism.
Requiring replicas to execute commands sequentially limits
performance. This limitation is acknowledged by the depend-
ability community and some approaches have been proposed
to enable multithreaded replicas in state-machine replication—
we survey these techniques in Section III. One prominent
approach is to exploit application semantics [3], [4], [5].
The idea is to allow independent commands to execute in
parallel and serialize the execution of dependent commands.
Independent commands are those that access disjoint sections
of the replica’s state and therefore do not interfere with each
other [2]. Dependent commands are those that access and
modify common sections of the state; executing dependent
commands concurrently may result in unpredictable and in-
consistent states across replicas.
This paper builds on Parallel State-Machine Replication
(P-SMR) [5], a scalable multithreaded model for replication.
Its scalability stems from the absence of any centralized
component in the execution path of independent commands.
P-SMR replaces atomic broadcast,
typically used in state-
machine replication to order commands, by atomic multicast.
Atomic multicast creates the abstraction of groups (i.e., disjoint
ordered sequences of commands), and threads in a replica can
subscribe to different groups. Clients multicast commands to
one or more groups, where the groups are chosen using a
deterministic mapping that depends on the command and its
parameters. The mapping is such that (a) independent com-
mands are likely mapped onto different groups and (b) any two
dependent commands are mapped onto at least one common
group. Consequently, independent commands multicast to dis-
joint groups can be executed concurrently by different threads
in a replica, and dependent commands are synchronized by
their common group and executed by a single thread.
Despite its highly scalable execution model, P-SMR’s
Achilles heel is its conservative strategy to map commands
to groups. Clients decide on the group that a command
is multicast
to based only on the command type and its
parameters. Since clients lack access to service state, they
must choose groups conservatively to avoid the concurrent
execution of potentially dependent commands, even if in the
end these commands do not access any common service state
(i.e., a false positive). For example, consider two commands
to insert an item in a B-tree. Since these commands may
lead to common structural changes in the tree, in P-SMR they
must be declared dependent, even though when executed they
modify different tree nodes. False positives protect the integrity
of the service at the cost of reducing its performance with
unnecessary serialization.
In this paper, we present opt-PSMR, an approach that
replaces P-SMR’s conservative strategy by a more aggres-
sive optimistic strategy. In opt-PSMR, when uncertain about
command interdependencies, clients identify the commands
as independent. Replicas are augmented with additional logic
to check whether concurrent execution of commands risks
corrupting the replica’s state (i.e., the optimistic assumption
does not hold). If two commands deemed independent turn
out to be dependent, they are multicast again using P-SMR’s
conservative strategy. Using a B+-tree service, we demonstrate
in the paper that opt-PSMR with its optimistic strategy out-
performs P-SMR by a factor of 2.4 times.
Several optimistic (and speculative) replication protocols
have been proposed in the literature, typically with the goal of
reducing latency (i.e., the delay between the submission of a
command and the receipt of its answer). These protocols can
be broadly divided into two classes. One class of protocols
reduces latency by shortening the protocol execution when the
optimistic assumption holds. For example, when order happens
spontaneously, an optimistic atomic broadcast protocol can
deliver messages in fewer steps than a conservative protocol
(e.g., [6], [7], [8]). Another class of protocols reduces latency
by overlapping the ordering of commands with their execution
(e.g., [9], [10], [11]). If the optimistic assumption does not
hold, command’s execution must be rolled back. opt-PSMR
differs from these protocols in that optimism is used to increase
throughput without penalizing latency.
This paper makes the following contributions: (a) it surveys
parallel approaches to state-machine replication, (b) it proposes
opt-PSMR, a novel approach that overcomes P-SMR’s short-
comings, and (c) it assesses the performance of opt-PSMR and
compares it to other replication techniques.
The rest of the paper is structured as follows. Section II de-
scribes our system model and assumptions. Section III reviews
parallel approaches to SMR. Sections IV and V present and
experimentally evaluate opt-PSMR, respectively. Section VI
overviews related work and Section VII concludes the paper.
II. SYSTEM MODEL AND ASSUMPTIONS
We assume a distributed system composed of intercon-
nected processes. There is an unbounded set C = {c1, c2, ...}
of client processes and a bounded set S = {s1, s2, ..., sn}
of server processes. The system is asynchronous: there is no
bound on message delays and on relative process speeds. We
assume the crash failure model and exclude malicious and
arbitrary behavior (e.g., no Byzantine failures). Processes are
either correct,
if they never fail, or faulty, otherwise. We
assume f faulty servers, out of n = f + 1 servers.
Processes communicate by message passing, using either
one-to-one or one-to-many communication. One-to-one com-
munication is through primitives send(m) and receive(m),
where m is a message. If sender and receiver are correct,
then every message sent is eventually received. One-to-many
communication is based on atomic multicast. Atomic multicast
is deﬁned by the primitives multicast(γ, m) and deliver(m),
where γ is a group of destinations. Let relation < be deﬁned
such that m < m(cid:48) iff there is a process that delivers m before
m(cid:48). Atomic multicast ensures that (i) if a process delivers m,
then all correct processes in γ deliver m (agreement); and
(ii) relation < is acyclic (order). The order property implies
that if processes p and q deliver messages m and m(cid:48), then they
deliver them in the same order.
Atomic multicast is typically available to applications as a
library (encapsulated as an agreement layer) and implemented
using one-to-one communication and additional system as-
sumptions [12], [13]. Atomic broadcast is a special case of
atomic multicast where there is only one group to which all
the destinations belong.
Our consistency criterion is linearizability. A system is
linearizable if there is a way to reorder the client commands
in a sequence that (i) respects the semantics of the commands,
as deﬁned in their sequential speciﬁcations, and (ii) respects
the real-time ordering of commands across all clients [14].
III. A SURVEY ON PARALLEL SMR
In this section we review the basics of state-machine repli-
cation and survey proposals that have adapted state-machine
replication to multicore architectures.
A. Non-replicated setup
A typical way for clients to interact with a (non-replicated)
server is by means of remote procedure invocations [15], [16].
Clients access the service by invoking service commands with
the appropriate parameters. Client proxies intercept client in-
vocations and turn them into requests that include a command
identiﬁer and the marshaled parameters. Requests are delivered
by the server proxies, which re-assemble invocations and issue
them against the local service. Similarly to remote procedure
calls, the client and client proxy (respectively, server and server
proxy) can be implemented as a single process, sharing a
common address space. The command’s response follows the
reverse path to the client using one-to-one communication.
As depicted in Figure 1 (a), in a non-replicated service: (i)
client requests are communicated to the server directly, without
passing through an agreement layer, and (ii) execution of client
requests at the server can be multithreaded.
B. Sequential SMR
State-machine replication provides clients with the illusion
of a non-replicated service, that is, replication is transparent
to the clients. A command issued by a client
is handled
by the client proxy, which multicasts the command to all
replicas and waits for the response from one replica (see
Figure 1 (b)). Before requests can be executed on the replicas
they are ordered by the agreement layer. Since replicas execute
commands deterministically and in the same order, every
replica produces the same response after the execution of
the same command. Differently from a non-replicated service,
clients remain oblivious to failures, as the service remains
operational despite the failure of some of its replicas. In failure-
free scenarios, however, a non-replicated service is often more
efﬁcient than a replicated service since in the replicated case
requests reach the servers through an agreement layer and
execution is single-threaded.
C. Pipelined SMR
imply that
Having replicas execute commands sequentially by a sin-
the whole replica’s logic
gle thread does not
must be single-threaded; multiple threads on a replica can
cooperatively handle the requests. For example, one thread
receives the requests, another executes the requests, and a third
thread responds to the clients. In [17], the authors propose
a pipelined architecture to exploit the processing power of
multicore servers. The agreement layer (atomic broadcast) and
the replicas are organized as a collection of modules connected
through shared message queues where messages are totally
ordered (see Figure 1 (c)). Although staging improves the
throughput of state-machine replication, there is always only
one thread sequentially executing the commands.
D. Sequential Delivery-Parallel Execution (SDPE)
Replicas in classic state-machine replication, execute all the
commands sequentially by adhering to the order decided by the
agreement layer. It has been observed that a replica can execute
commands that access disjoint variables (independent com-
mands) concurrently without jeopardizing consistency [2]. The
notion of command interdependency is application-speciﬁc and
must be provided by the application developer or automatically
extracted from the service code. Recently, several replication
models have exploited command dependencies to parallelize
the execution on replicas. We discuss these techniques in this
and the next two sections.
To understand the concept of dependencies among com-
mands, consider a service composed of three objects x, y, and
Fig. 1. Architecture differences among (a) non-replicated service, (b) sequential state-machine-replication, (c) pipelined state-machine replication, (d) sequential
delivery-parallel execution (SDPE), (e) execute-verify, and (f) parallel delivery-parallel execution. Agreement layer and replicas are fault-tolerant.
z and assume commands Cx, Cy, Cz, Cxy, where the indices
indicate the objects accessed and modiﬁed by the commands.
Commands Cx, Cy, and Cz access disjoint objects. Thus, they
are independent and can be executed in parallel at each replica.
Command Cxy depends on commands Cx and Cy and must