### User Study and Model Comparison

We conducted a user study to compare our style-transfer models at two operating points, 0.5 F1-score and 0.66 F1-score, to evaluate human judgments at different levels of privacy effectiveness, as shown in Table VI. The results indicate that the CycML+Lang model outperforms the other two models at both operating points. Specifically, CycML+Lang wins 50.74% of the time (excluding ties) at the 0.5 F1-score operating point and 57.87% of the time at the 0.66 F1-score operating point. These findings, combined with the quantitative evaluation discussed in Section 6.1, confirm that the cyclic ML loss combined with the language model loss provides the best trade-off between semantic similarity and privacy effectiveness.

### Comparative Analysis with Google Machine Translation

We further conducted a user study comparing the CycML+Lang model, operating at 0.79, with the Google machine translation baseline using a 3-hop process. The operating point was chosen to ensure that both models are closest in terms of privacy effectiveness and METEOR score. As shown in Table VII, our model outperformed the GoogleMT baseline by approximately 16% (59.46% vs. 43.76% rank-1) in terms of semantic similarity, as judged by human evaluators, while maintaining better privacy effectiveness. This is largely due to the A4NT model's ability to avoid unnecessary changes to the input text if it is already ambiguous for the attribute classifier, making modifications only when necessary. In contrast, the changes made by the GoogleMT round trip are not optimized for maximizing privacy gain and can alter the input text even when no change is needed.

### Absolute Semantic Similarity Evaluation

In addition to the relative evaluation, we conducted a separate user study to assess the semantic similarity of both the A4NT CycML+Lang model and the GoogleMT baseline on an absolute scale. This study, conducted on a human-evaluation test set of 745 sentences using the Amazon Mechanical Turk (AMT) platform, involved presenting each human judge with the input sentence and the output from either model. Judges were asked to rate the similarity to the input on a Likert scale from 0 to 5, where 0 indicates no semantic relation and 5 indicates equivalence in meaning. The instructions for rating were based on those used in the SemEval task [57]. Each input-output pair was evaluated by three human judges, and the mean score and standard deviation are reported in Table VII. Our model achieved a higher overall score of 4.51/5.0 compared to 4.16 for the GoogleMT baseline, indicating that the A4NT model generally preserves the meaning of the input sentence by making semantically equivalent changes to fool the authorship classifier.

### Qualitative Analysis

#### Examples of Style Transfer for Anonymization

Table VIII shows examples of style transfer applied to sentences in the blog-age setting, demonstrating the common changes made by the A4NT CycML+Lang model. The examples are categorized into three types:

1. **Using Synonyms**: The model frequently uses synonyms to change the style, such as replacing "yeh" with "ooh" and "would" with "will" when transforming from teen to adult, and "funnily enough" with "haha besides" and "work out" with "go out" when changing from adult to teen. These changes are context-dependent and do not significantly alter the meaning of the sentence but effectively fool the attribute classifiers.

2. **Replacing Slang Words**: When converting from teen to adult, the model replaces slang or misspelled words with standard English, such as "wad" (what) with "definitely" and "wadeva" with "perhaps." Conversely, when changing from adult to teenager, it introduces slang like "diz" (this) and "relized" (realized). These changes are learned from the data and would be challenging to encode in a rule-based system due to the variety of slangs and spelling mistakes.

3. **Semantic Changes**: One limitation of the A4NT model is its handling of sentences with significant bias towards the author's class. For example, the model might replace "wife" with "crush," altering the meaning. Common entity pairs where this occurs include (school↔work), (class↔office), (dad↔husband), and (mum↔wife). In such cases, it is difficult to mask the author's identity without altering these biased content words.

#### Performance Across Input Difficulty

Figure 8 compares the attribute classifier scores on the input and A4NT output. Ideally, all A4NT outputs should score below the decision boundary and not increase the classifier score compared to the input text. The "ideal score" is shown as a grey solid line. The CycML and CycML+Lang models generally stay below or close to this ideal line, providing significant improvement over the input text (a drop in classifier score of about 0.45).

Figure 9 plots the METEOR score against input difficulty, showing that the A4NT network maintains high semantic similarity for easier sentences but lower for more difficult ones, indicating that the network effectively learns to apply the appropriate level of change.

### Conclusion

The A4NT network offers a novel, data-driven approach to authorship obfuscation, capable of adapting to new attack methods and datasets. Experiments on age, gender, and identity attributes demonstrate that the A4NT network effectively fools attribute classifiers in all settings and performs well against multiple unseen classifier architectures. The method is likely to be effective against previously unknown NLP adversaries. The A4NT network can be operated at different points on the privacy-effectiveness and semantic-similarity trade-off curve, offering flexibility to users. However, on challenging data with very distinct styles, such as political speeches, the method may alter the semantics of the input text to achieve effective anonymization.

### Acknowledgment

This research was supported in part by the German Research Foundation (DFG CRC 1223). We also thank Yang Zhang, Ben Stock, and Sven Bugiel for their valuable feedback.

### References

[1] P. Juola et al., “Authorship attribution,” Foundations and Trends® in Information Retrieval, 2008.
[2] E. Stamatatos, “A survey of modern authorship attribution methods,” Journal of the Association for Information Science and Technology, 2009.
[3] S. Ruder, P. Ghaffari, and J. G. Breslin, “Character-level and multi-channel convolutional neural networks for large-scale authorship attribution,” arXiv preprint arXiv:1609.06686, 2016.
[4] S. Argamon, M. Koppel, J. W. Pennebaker, and J. Schler, “Automatically profiling the author of an anonymous text,” Communications of the ACM, 2009.
[5] R. Overdorf and R. Greenstadt, “Blogs, twitter feeds, and reddit comments: Cross-domain authorship attribution,” Proceedings on Privacy Enhancing Technologies, 2016.
[6] A. Narayanan, H. Paskov, N. Z. Gong, J. Bethencourt, E. Stefanov, E. C. R. Shin, and D. Song, “On the feasibility of internet-scale author identification,” in Security and Privacy (SP), 2012 IEEE Symposium on. IEEE, 2012.