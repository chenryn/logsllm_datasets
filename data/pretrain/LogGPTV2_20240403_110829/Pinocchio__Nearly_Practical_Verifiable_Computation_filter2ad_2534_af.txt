12.5ms
319.1µs
12.2ms
55.9MB
640B
288B
Reduction
61%
-2%
83%
65%
59%
64%
70%
60%
18%
30%
18%
47%
0%
18%
Figure 9: Improving GGPR [30]. Performance for the multi-
variate polynomial application. Pinocchio’s high-level operations
are 2.6x, 2.8x, and 1.2x faster than the original. (N = 10,σ ≤ 3%).
Impact of Our Optimizations
5.4
In Figure 9, we break down Pinocchio’s protocol overhead for
the large multivariate polynomial example application, to bet-
ter identify the major bottlenecks. For comparison, we also
measure the performance of our implementation of GGPR’s
scheme [30], using the same underlying cryptographic and
polynomial libraries.
The results indicate that our protocol improvements had a
signiﬁcant impact. KeyGen and Compute are more than twice
as fast, and even veriﬁcation is 18% faster. Of Pinocchio’s re-
maining KeyGen overhead, the majority comes from encod-
ing the evaluations of the QAP’s polynomials in the gener-
ator’s exponent. For Compute, the multi-exponentiation re-
quired to compute the QAP’s polynomials in the exponent
still dominate, but the overhead of solving for h(x) is non-
trivial as well.
248
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:52:11 UTC from IEEE Xplore.  Restrictions apply. 
Pinocchio also drastically reduces the size of the evaluation
key and even manages to reduce the size of GGPR’s already
svelte 9 element proof to 8 elements.
5.5 QSPs versus QAPs
Finally,
to conﬁrm our theoretical prediction that QAPs
would outperform QSPs (§3.2), we compared the two on our
SHA-1 application, which performs numerous bitwise oper-
ations, and hence should favor QSPs. The resulting QSP’s
size was 38.6× that of the QAP, and the degree was 55.5×
as large. Not surprisingly, the QSP’s KeyGen took 35.2× and
Compute took 55.4× as long as those of the QAP; the veriﬁ-
cation times were comparable.
6 Related Work
Much of the prior work in this area focuses on verifying spe-
ciﬁc functions via auditing or special properties of the func-
tions [2–6]. Other systems rely on replication, and hence as-
sume failures are uncorrelated [1, 7, 8, 55]. A large body of
work veriﬁes computation by assuming the worker employs
secure hardware [9–15].
While the theory and cryptography community has long
studied the problem of general-purpose proof systems [16–
23], until recently, this work was largely regarded as highly
impractical, to the point where no one bothered to implement
it. Much of this work [16–20, 56] relied on Probabilisti-
cally Checkable Proofs (PCPs), which offer impressive the-
oretical performance, but which can take trillions of years to
verify in practice [27]. Other work [22, 23] relies on fully-
homomorphic encryption (FHE) [24], which, despite contin-
uing advances [53], remains highly impractical.
Recently, security and systems researchers have started to
develop techniques to make theoretical cryptographic proto-
cols practical. Secure multiparty computation, for example,
has seen tremendous progress [57–59]. However, since the
primary focus is on secrecy, not outsourcing, both parties typ-
ically perform work equal to evaluating the function.
With regard to implementing veriﬁed computation, in the
last year, two parallel efforts have emerged, both using opti-
mized PCP-based arguments. One effort [25, 26] builds on
the PCP-based arguments of Goldwasser et al. [20] (GKR).
They target a streaming setting where the client cannot store
all of the data it wishes to compute over; the system currently
requires the function computed to be highly parallelizable.
On the plus side, it does not require cryptography, and it is
secure against computationally unbounded adversaries.
Setty et al. produced a second line of PCP-based systems
called Pepper [27] and Ginger [28]. They build on a particular
type of PCP called a linear PCP [52], in which the proof can
be represented as a linear function. This allows the worker
to use a linearly-homomorphic encryption scheme to create a
commitment to its proof while relying only on standard cryp-
tographic assumptions. Through a combination of theoretical
and systems-level improvements, this work made tremendous
progress in making PCP-based systems practical. Indeed, for
applications that can tolerate large batch sizes, the amortized
costs of veriﬁcation can be quite low.
A few downsides remain, however. Because the work
builds on the Hadamard PCP [56], the setup time, network
overhead, and the prover’s work are quadratic in the size of
the original computation, unless the protocol is hand-tailored.
To achieve efﬁciency, the veriﬁer must outsource computa-
tions in batches, which means it cannot verify the results un-
til the full batch returns. The scheme is designated veriﬁer,
meaning that third parties cannot verify the results of out-
sourced computations without sharing the client’s secret key,
and hence opening the possibility for fraud. The scheme also
does not support zero-knowledge proofs.
Concurrent work [60] also builds on the quadratic pro-
grams of Gennaro et al [30]. They observe that QAPs can be
viewed as linear PCPs and hence can ﬁt into Ginger’s crypto-
graphic framework [28]. Their work shows worker computa-
tion improvements similar to those of Pinocchio. Additional
concurrent work [61] adapts GKR’s protocol to the batching
model and develops a compiler that chooses amongst three
PCP-based backends. Both systems retain PCPs and Ginger’s
cryptographic protocol, so they rely on simpler cryptographic
assumptions than Pinocchio, but they must still batch compu-
tations to obtain an efﬁcient veriﬁer. They also remain desig-
nated veriﬁer and do not support zero-knowledge proofs.
Previous systems either did not offer a compiler [25–27], or
compiled from a subset of an academic language, SFDL [28,
60]. In contrast, we compile from a subset of C, which should
ease the development burden for verifying computation.
Several systems provide compilers for zero-knowledge
(ZK) proofs [62–64]. Both the systems of Almeida et al. [62]
and Meiklejohn et al. [63] adopt an approach based on Σ-
protocols [65]. The former provides functionality for prov-
ing knowledge in arbitrary groups, AND and OR composi-
tions, and linear relations. The latter focuses on functionali-
ties for cryptographic protocols, e.g., e-cash, blind signatures,
or veriﬁable encryption. The compiler of Backes et al. [64]
uses Groth-Sahai ZK proofs [66] and handles logical formu-
las. Rial and Danezis [32] propose a system for privacy-
preserving smart metering in which clients use a ZK protocol
to prove correctness of the billing computation they perform
on meter readings. In general, these systems are likely to ex-
hibit better performance than Pinocchio for their particular
subset of functionality, but they do not possess the same level
of efﬁcient generality.
7 Conclusion and Future Work
We have presented Pinocchio, a system for public veriﬁ-
able computing. Pinocchio uses quadratic programs, a new
method for encoding computation, combined with a highly
efﬁcient cryptographic protocol to achieve both asymptotic
and concrete efﬁciency. Pinocchio produces 288-byte proofs,
regardless of the size of the computation, and the proofs can
be veriﬁed rapidly, typically in tens of milliseconds, beating
native execution in several cases. This represents ﬁve to seven
249
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:52:11 UTC from IEEE Xplore.  Restrictions apply. 
orders of magnitude performance improvement over prior
work. The worker also produces the proof 19-60× faster.
Pinocchio even slashes the cost of its underlying protocol,
cutting the cost of both key and proof generation by more
than 60%. The end result is a natural cryptographic protocol
for efﬁciently signing computations. Combined with a com-
piler for real C programs, Pinocchio brings veriﬁable compu-
tation much closer to practicality.
Nonetheless gaps still remain. We hope that additional the-
oretic improvements, combined with efforts to expand our
toolchain, e.g., to support ﬂoating point or parallel execu-
tion (via standard techniques [25, 28, 43]), will continue to
advance us towards truly practical veriﬁable computing.
Acknowledgements
The authors gratefully thank: Peter Montgomery, Michael
Naehrig, and Patrick Pierola for assisting us with the crypto-
graphic library used by Pinocchio; Chris Hawblitzel for his
sage guidance on compiler development; Rosario Gennaro
for valuable discussions; and the anonymous reviewers for
their helpful comments. Mariana Raykova was supported by
NSF Grant No. 1017660.
References
[1] D. P. Anderson, J. Cobb, E. Korpela, M. Lebofsky, and D. Werthimer,
“SETI@Home: An experiment in public-resource computing,” Com-
munications of the ACM, vol. 45, no. 11, 2002.
[2] F. Monrose, P. Wyckoff, and A. Rubin, “Distributed execution with
remote audit,” in Proc. of ISOC NDSS, 1999.
[3] P. Golle and S. G. Stubblebine, “Secure distributed computing in a
commercial environment,” in Proc. of Financial Cryptography, 2002.
[4] W. Du and M. T. Goodrich, “Searching for high-value rare events with
uncheatable grid computing,” in ACNS, 2005.
[5] P. Golle and I. Mironov, “Uncheatable distributed computations,” in
Proc. of CT-RSA, 2001.
[6] R. Sion, “Query execution assurance for outsourced databases,” in The
Very Large Databases Conference (VLDB), 2005.
[7] M. Castro and B. Liskov, “Practical Byzantine fault tolerance and
proactive recovery,” ACM Trans. on Comp. Sys., vol. 20, no. 4, 2002.
[8] B. Carbunar and R. Sion, “Uncheatable reputation for distributed com-
putation markets,” in Financial Cryptography, 2006.
[9] R. Sailer, X. Zhang, T. Jaeger, and L. van Doorn, “Design and im-
plementation of a TCG-based integrity measurement architecture,” in
Proc. of the USENIX Security, 2004.
[10] L. Chen, R. Landfermann, H. L¨ohr, M. Rohe, A.-R. Sadeghi, and
C. St¨uble, “A protocol for property-based attestation,” in Proc. of the
ACM Workshop on Scalable Trusted Computing (STC), 2006.
[11] B. Parno, J. M. McCune, and A. Perrig, Bootstrapping Trust in Modern
Computers. Springer, 2011.
[12] A. Seshadri, M. Luk, E. Shi, A. Perrig, L. VanDoorn, and P. Khosla,
“Pioneer: Verifying integrity and guaranteeing execution of code on
legacy platforms,” in Proc. of the ACM SOSP, 2005.
[13] R. B. Lee, P. Kwan, J. P. McGregor, J. Dwoskin, and Z. Wang, “Archi-
tecture for protecting critical secrets in microprocessors,” in Proc. of
the International Symposium on Computer Architecture (ISCA), 2005.
[14] D. Lie, C. A. Thekkath, M. Mitchell, P. Lincoln, D. Boneh, J. C.
Mitchell, and M. Horowitz, “Architectural support for copy and tamper
resistant software,” in Proc. of the ACM ASPLOS, 2000.
[15] A.-R. Sadeghi, T. Schneider, and M. Winandy, “Token-based cloud
computing: secure outsourcing of data and arbitrary computations with
lower latency,” in TRUST, 2010.
[16] S. Goldwasser, S. Micali, and C. Rackoff, “The knowledge complexity
of interactive proof systems,” SIAM J. Comput., vol. 18, no. 1, 1989.
[17] S. Arora and S. Safra, “Probabilistic checking of proofs: A new char-
acterization of NP,” J. ACM, vol. 45, no. 1, pp. 70–122, 1998.
[18] J. Kilian, “A note on efﬁcient zero-knowledge proofs and arguments
(extended abstract),” in STOC, 1992.
[19] S. Micali, “Computationally sound proofs,” SIAM J. Comput., vol. 30,
no. 4, pp. 1253–1298, 2000. Extended abstract in FOCS ’94.
[20] S. Goldwasser, Y. T. Kalai, and G. N. Rothblum, “Delegating compu-
tation: Interactive proofs for muggles,” in STOC, 2008.
[21] J. Groth, “Short pairing-based non-interactive zero-knowledge argu-
ments,” in ASIACRYPT, 2010.
[22] R. Gennaro, C. Gentry, and B. Parno, “Non-interactive veriﬁable com-
puting: Outsourcing computation to untrusted workers,” 2010.
[23] K.-M. Chung, Y. T. Kalai, and S. P. Vadhan, “Improved delegation of
computation using fully homomorphic encryption,” in CRYPTO, 2010.
[24] C. Gentry, A fully homomorphic encryption scheme. PhD thesis, Stan-
ford University, 2009. crypto.stanford.edu/craig.
[25] J. Thaler, M. Roberts, M. Mitzenmacher, and H. Pﬁster, “Veriﬁable
computation with massively parallel interactive proofs,” in USENIX
HotCloud Workshop, 2012.
[26] G. Cormode, M. Mitzenmacher, and J. Thaler, “Practical veriﬁed com-
putation with streaming interactive proofs,” in ITCS, 2012.
[27] S. Setty, R. McPherson, A. J. Blumberg, and M. Walﬁsh, “Making ar-
gument systems for outsourced computation practical (sometimes),” in
Proceedings of the ISOC NDSS, 2012.
[28] S. Setty, V. Vu, N. Panpalia, B. Braun, A. J. Blumberg, and M. Wal-
ﬁsh, “Taking proof-based veriﬁed computation a few steps closer to
practicality,” in Proc. of USENIX Security, 2012.
[29] B. Parno, M. Raykova, and V. Vaikuntanathan, “How to delegate and
verify in public: Veriﬁable computation from attribute-based encryp-
tion,” in IACR Theory of Cryptography Conference (TCC), 2012.
[30] R. Gennaro, C. Gentry, B. Parno, and M. Raykova, “Quadratic span
programs and succinct NIZKs without PCPs,” in EUROCRYPT, 2013.
Originally published as Cryptology ePrint Archive, Report 2012/215.
[31] M. Blum, A. D. Santis, S. Micali, and G. Persiano, “Noninteractive
zero-knowledge,” SIAM J. on Computing, vol. 20, no. 6, 1991.
[32] A. Rial and G. Danezis, “Privacy-preserving smart metering,” in Proc.
of the ACM WPES, 2011.
[33] N. Pippenger and M. J. Fischer, “Relations among complexity mea-
sures,” J. ACM, vol. 26, no. 2, 1979.
[34] D. Boneh and M. Franklin, “Identity-based encryption from the Weil
pairing,” Proceedings of IACR CRYPTO, 2001.
[35] D. Boneh, X. Boyen, and E.-J. Goh, “Hierarchical identity based en-
cryption with constant size ciphertext,” in EUROCRYPT, 2005.
[36] D. Boneh, C. Gentry, and B. Waters, “Collusion resistant broadcast
encryption with short ciphertexts and private keys,” in CRYPTO, 2005.
[37] M. Naor, “On cryptographic assumptions and challenges,” in Proceed-
ings of IACR CRYPTO, 2003.
[38] M. Bellare and A. Palacio, “The knowledge-of-exponent assumptions
and 3-round zero-knowledge protocols,” in CRYPTO, 2004.
[39] C. Gentry and D. Wichs, “Separating succinct non-interactive argu-
ments from all falsiﬁable assumptions,” in STOC, 2011.
[40] “Veriﬁable
computation:
Pinocchio.” http://research.
microsoft.com/verifcomp/, Mar. 2013.
[41] I. Damg˚ard, “Towards practical public key systems secure against cho-
sen ciphertext attacks,” in IACR CRYPTO, 1991.
[42] D. A. Wheeler, “SLOCCount.” http://www.dwheeler.com/
sloccount/.
[43] M. Aliasgari, M. Blanton, Y. Zhang, and A. Steele, “Secure computa-
tion on ﬂoating point numbers,” in Proc. of ISOC NDSS, 2013.
[44] A. Holzer, M. Franz, S. Katzenbeisser, and H. Veith, “Secure two-party
computations in ANSI C,” in Proc. of ACM CCS, 2012.
[45] M. Naehrig, R. Niederhagen, and P. Schwabe, “New software speed
records for cryptographic pairings,” in Proc. of LATINCRYPT, 2010.
[46] P. S. L. M. Barreto and M. Naehrig, “Pairing-friendly elliptic curves of
prime order,” in Selected Areas in Cryptography (SAC), 2006.
[47] N. Pippenger, “On the evaluation of powers and related problems (pre-
liminary version),” in Proc. of FOCS, 1976.
[48] A. Aho, J. Hopcroft, and J. Ulman, The Design and Analysis of Com-
puter Algorithms. Addison-Wesley, 1974.
250
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:52:11 UTC from IEEE Xplore.  Restrictions apply. 
[49] G. Adomavicius and A. Tuzhilin, “Toward the next generation of rec-
ommender systems: A survey of the state-of-the-art and possible exten-
sions,” Trans. Knowledge and Data Engineering, vol. 17, no. 6, 2005.
[50] D. A. Wolf-Gladrow, Lattice-Gas Cellular Automata and Lattice Boltz-
mann Models: An Introduction. Springer, 2005.
[51] R. Motwani and P. Raghavan, Randomized Algorithms. Cambridge
University Press, 1995.
[52] Y. Ishai, E. Kushilevitz, and R. Ostrovsky, “Efﬁcient arguments without
short PCPs,” in IEEE Conference on Computational Complexity, 2007.
[53] C. Gentry, S. Halevi, and N. Smart, “Homomorphic evaluation of the
AES circuit,” in Proceedings of CRYPTO, 2012.
[54] Y. Chen and R. Sion, “To cloud or not to cloud? Musings on costs and
viability,” in Proc. of the ACM Symposium on Cloud Computing, 2011.
[55] G. O. Karame, M. Strasser, and S. Capkun, “Secure remote execution
of sequential computations,” in Intl. Conf. on Information and Commu-
nications Security, 2009.
[56] S. Arora, C. Lund, R. Motwani, M. Sudan, and M. Szegedy, “Proof ver-
iﬁcation and the hardness of approximation problems,” J. ACM, vol. 45,
no. 3, 1998.
[57] D. Malkhi, N. Nisan, B. Pinkas, and Y. Sella, “Fairplay—a secure two-
party computation system,” in Proc. of USENIX Security, 2004.
[58] Y. Huang, D. Evans, J. Katz, and L. Malka, “Faster secure two-party
computation using garbled circuits,” in USENIX Security, 2011.