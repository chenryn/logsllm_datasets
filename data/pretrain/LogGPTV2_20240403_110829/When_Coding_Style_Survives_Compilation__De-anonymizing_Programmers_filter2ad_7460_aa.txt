title:When Coding Style Survives Compilation: De-anonymizing Programmers
from Executable Binaries
author:Aylin Caliskan and
Fabian Yamaguchi and
Edwin Dauber and
Richard E. Harang and
Konrad Rieck and
Rachel Greenstadt and
Arvind Narayanan
To appear at the 2018 Network and Distributed System Security Symposium (NDSS).
When Coding Style Survives Compilation:
De-anonymizing Programmers from Executable
Binaries
7
1
0
2
c
e
D
8
1
]
R
C
.
s
c
[
3
v
6
4
5
8
0
.
2
1
5
1
:
v
i
X
r
a
Richard Harang§, Konrad Rieck¶, Rachel Greenstadt‡ and Arvind Narayanan∗
Aylin Caliskan∗, Fabian Yamaguchi†, Edwin Dauber‡,
∗Princeton University, {aylinc@, arvindn@cs}.princeton.edu
‡Drexel University, {egd34, rachel.a.greenstadt}@drexel.edu
†Shiftleft Inc, PI:EMAIL
§Sophos, Data Science Team, PI:EMAIL
¶TU Braunschweig, PI:EMAIL
Abstract—The ability to identify authors of computer pro-
grams based on their coding style is a direct threat to the privacy
and anonymity of programmers. While recent work found that
source code can be attributed to authors with high accuracy,
attribution of executable binaries appears to be much more
difﬁcult. Many distinguishing features present in source code, e.g.
variable names, are removed in the compilation process, and com-
piler optimization may alter the structure of a program, further
obscuring features that are known to be useful in determining
authorship. We examine programmer de-anonymization from the
standpoint of machine learning, using a novel set of features that
include ones obtained by decompiling the executable binary to
source code. We adapt a powerful set of techniques from the
domain of source code authorship attribution along with stylistic
representations embedded in assembly, resulting in successful de-
anonymization of a large set of programmers.
We evaluate our approach on data from the Google Code
Jam, obtaining attribution accuracy of up to 96% with 100 and
83% with 600 candidate programmers. We present an executable
binary authorship attribution approach, for the ﬁrst time, that
is robust to basic obfuscations, a range of compiler optimization
settings, and binaries that have been stripped of their symbol
tables. We perform programmer de-anonymization using both
obfuscated binaries, and real-world code found “in the wild”
in single-author GitHub repositories and the recently leaked
Nulled.IO hacker forum. We show that programmers who would
like to remain anonymous need to take extreme countermeasures
to protect their privacy.
I.
INTRODUCTION
If we encounter an executable binary sample in the wild,
what can we learn from it? In this work, we show that the
programmer’s stylistic ﬁngerprint, or coding style, is preserved
Network and Distributed Systems Security (NDSS) Symposium 2018
18-21 February 2018, San Diego, CA, USA
ISBN 1-1891562-49-5
http://dx.doi.org/10.14722/ndss.2018.23304
www.ndss-symposium.org
in the compilation process and can be extracted from the
executable binary. This means that it may be possible to infer
the programmer’s identity if we have a set of known potential
candidate programmers, along with executable binary samples
(or source code) known to be authored by these candidates.
Programmer de-anonymization from executable binaries
has implications for privacy and anonymity. Perhaps the creator
of a censorship circumvention tool distributes it anonymously,
fearing repression. Our work shows that such a programmer
might be de-anonymized. Further, there are applications for
software forensics, for example to help adjudicate cases of
disputed authorship or copyright.
The White House Cyber R&D Plan states that “effective
deterrence must raise the cost of malicious cyber activities,
lower their gains, and convince adversaries that such activities
can be attributed [42].” The DARPA Enhanced Attribution calls
for methods that can “consistently identify virtual personas
and individual malicious cyber operators over time and across
different endpoint devices and C2 infrastructures [25].” While
the forensic applications are important, as attribution methods
develop, they will threaten the anonymity of privacy-minded
individuals at least as much as malicious actors.
We introduce the ﬁrst part of our approach by signiﬁcantly
overperforming the previous attempt at de-anonymizing pro-
grammers by Rosenblum et al. [39]. We improve their accuracy
of 51% in de-anonymizing 191 programmers to 92% and then
we scale the results to 83% accuracy on 600 programmers.
First, whereas Rosenblum et al. extract structures such as
control-ﬂow graphs directly from the executable binaries, our
work is the ﬁrst to show that automated decompilation of exe-
cutable binaries gives additional categories of useful features.
Speciﬁcally, we generate abstract syntax trees of decompiled
source code. Abstract syntax trees have been shown to greatly
improve author attribution of source code [16]. We ﬁnd that
syntactical properties derived from these trees also improve
the accuracy of executable binary attribution techniques.
Second, we demonstrate that using multiple tools for dis-
assembly and decompilation in parallel increases the accuracy
of de-anonymization by generating different representations of
code that capture various aspects of the programmer’s style.
We present a robust machine learning framework based on
entropy and correlation for dimensionality reduction, followed
by random-forest classiﬁcation, that allows us to effectively use
disparate types of features in conjunction without overﬁtting.
These innovations allow us to de-anonymize a large set
of real-world programmers with high accuracy. We perform
experiments with a controlled dataset collected from Google
Code Jam (GCJ), allowing a direct comparison to previous
work that used samples from GCJ. The results of these
experiments are discussed in detail in Section V. Speciﬁcally;
we can distinguish between thirty times as many candidate
programmers (600 vs. 20) with higher accuracy, while utilizing
less training data and much fewer stylistic features (53) per
programmer. The accuracy of our method degrades gracefully
as the number of programmers increases, and we present
experiments with as many as 600 programmers. Similarly, we
are able to tolerate scarcity of training data: our accuracy for
de-anonymizing sets of 20 candidate programmers with just a
single training sample per programmer is over 75%.
Third, we ﬁnd that traditional binary obfuscation, enabling
compiler optimizations, or stripping debugging symbols in
executable binaries results in only a modest decrease in
de-anonymization accuracy. These results, described in Sec-
tion VI, are an important step toward establishing the practical
signiﬁcance of the method.
The fact that coding style survives compilation is unintu-
itive, and may leave the reader wanting a “sanity check” or an
explanation for why this is possible. In Section V-J, we present
several experiments that help illuminate this mystery. First, we
show that decompiled source code is not necessarily similar
to the original source code in terms of the features that we
use; rather, the feature vector obtained from disassembly and
decompilation can be used to predict, using machine learning,
the features in the original source code. Even if no individual
feature is well preserved, there is enough information in the
vector as a whole to enable this prediction. On average, the
cosine similarity between the original feature vector and the re-
constructed vector is over 80%. Further, we investigate factors
that are correlated with coding style being well-preserved, and
ﬁnd that more skilled programmers are more ﬁngerprintable.
This suggests that programmers gradually acquire their own
unique style as they gain experience.
All
these experiments were carried out using the GCJ
dataset; the availability of this dataset is a boon for research
in this area since it allows us to develop and benchmark
our results under controlled settings [39], [9]. Having done
that, we present
the ﬁrst ever de-anonymization study on
an uncontrolled real-world dataset collected from GitHub in
Section VI-D. This data presents difﬁculties, particularly noise
in ground truth because of library and code reuse. However,
we show that we can handle a noisy dataset of 50 programmers
found in the wild with 65% accuracy and further extend our
method to tackle open world scenarios. We also present a
case study using code found via the recently leaked Nulled.IO
hacker forum. We were able to ﬁnd four forum members who,
in private messages, linked to executables they had authored
(one of which had only one sample). Our approach correctly
attributed the three individuals who had enough data to build
a model and correctly rejected the fourth sample as none of
the previous three.
We emphasize that research challenges remain before pro-
grammer de-anonymization from executable binaries is fully
ready for practical use. For example, programs may be au-
thored by multiple programmers and may have gone through
encryption. We have not performed experiments that model
these scenarios which require different machine learning and
segmentation techniques and we mainly focus on the privacy
implications. Nonetheless, we present a robust and principled
programmer de-anonymization method with a new approach
and for the ﬁrst time explore various realistic scenarios. Ac-
cordingly, our effective framework raise immediate concerns
for privacy and anonymity.
The remainder of this paper is structured as follows.
We begin by formulating the research question investigated
throughout this paper in Section II, and discuss closely related
work on de-anonymization in Section III. We proceed to
describe our novel approach for binary authorship attribution
based on instruction information, control ﬂow graphs, and
decompiled code in Section IV. Our experimental results are
described in Section V, followed by a discussion of results in
Section VII. Finally, we shed light on the limitations of our
method in Section VIII and conclude in Section IX.
II. PROBLEM STATEMENT
In this work, we consider an analyst interested in deter-
mining the author of an executable binary purely based on its
style. Moreover, we assume that the analyst only has access
to executable binary samples each assigned to one of a set of
candidate programmers.
Depending on the context, the analyst’s goal might be
defensive or offensive in nature. For example, the analyst
might be trying to identify a misbehaving employee that
violates the non-compete clause in his company by launching
an application related to what he does at work. By contrast, the
analyst might belong to a surveillance agency in an oppressive
regime who tries to unmask anonymous programmers. The
regime might have made it unlawful for its citizens to use
certain types of programs, such as censorship-circumvention
tools, and might want to punish the programmers of any such
tools. If executable binary stylometry is possible, it means
that compiled and cryptic code does not guarantee anonymity.
Because of its potential dual use, executable binary stylometry
is of interest to both security and privacy researchers.
In either (defensive or offensive) case, the analyst (or ad-
versary) will seek to obtain labeled executable binary samples
from each of these programmers who may have potentially
authored the anonymous executable binary. The analyst pro-
ceeds by converting each labeled sample into a numerical
feature vector, and subsequently deriving a classiﬁer from these
vectors using machine learning techniques. This classiﬁer can
then be used to attribute the anonymous executable binary to
the most likely programmer.
Since we assume that a set of candidate programmers
is known, we treat our main problem as a closed world,
supervised machine learning task. It is a multi-class machine
learning problem where the classiﬁer calculates the most likely
2
author for the anonymous executable binary sample among
multiple authors. We also present experiments on an open-
world scenario in Section VI-E.
Stylistic Fingerprints. An analyst is interested in identify-
ing stylistic ﬁngerprints in binary code to show that compiling
source code does not anonymize it. The analyst engineers
the numeric representations of stylistic properties that can be
derived from binary code. To do so, the analyst generates
representations of the program from the binary code. First,
she uses a disassembler to obtain the low level features in
assembly code. Second, she uses a decompiler to generate the
control ﬂow graph to capture the ﬂow of the program. Lastly,
she utilizes a decompiler to convert the low level instructions
to high level decompiled source code in order to obtain abstract
syntax trees. The analyst uses these three data formats to nu-
merically represent the stylistic properties embedded in binary
code. Given a set of labeled binary code samples with known
authors, the analyst constructs the numeric representation of
each sample. The analyst determines the set of stylistic features
by calculating how much entropy each numeric value has
in correctly differentiating between authors. She can further
analyze how programmers’ stylistic properties are preserved
in a transformed format after compilation. Consequently, the
analyst is able to quantify the level of anonymization and the
amount of preserved stylistic ﬁngerprints in binary code that
has gone through compilation.
Additional Assumptions. For our experiments, we assume
that we know the compiler used for a given program binary.
Previous work has shown that with only 20 executable binary
samples per compiler as training data, it is possible to use
a linear Conditional Random Field (CRF) to determine the
compiler used with accuracy of 93% on average [41], [27].
Other work has shown that by using pattern matching, library
functions can be identiﬁed with precision and recall between
0.98 and 1.00 based on each one of three criteria; compiler
version, library version, and linux distribution [23].
In addition to knowing the compiler, we assume to know
the optimization level used for compilation of the binary.
Past work has shown that toolchain provenance, including
compiler family, version, optimization, and source language,
can be identiﬁed with a linear CRF with accuracy of 99% for
language, compiler family, and optimization and with 92% for
compiler version [40]. Based on this success, we make the
assumption that these techniques will be used to identify the
toolchain provenance of the executable binaries of interest and
that our method will be trained using the same toolchain.
III. RELATED WORK
Any domain of creative expression allows authors or cre-
ators to develop a unique style, and we might expect that there
are algorithmic techniques to identify authors based on their
style. This class of techniques is called stylometry. Natural-
language stylometry,
is well over a century
old [31]. Other domains such as source code and music
also have stylistic features, especially grammar. Therefore
stylometry is applicable to these domains as well, often using
strikingly similar techniques [45], [10].
in particular,
Linguistic stylometry. The state of the art in linguistic
stylometry is dominated by machine-learning techniques [6],
[32], [7]. Linguistic stylometry has been applied successfully
to security and privacy problems, for example Narayanan et
al. used stylometry to identify anonymous bloggers in large
datasets, exposing privacy issues [32]. On the other hand,
stylometry has also been used for forensics in underground
cyber forums. In these forums, the text consists of a mixture
of languages and information about forum products, which
makes it more challenging to identify personal writing style.
Not only have the forum users been de-anonymized but also
their multiple identities across and within forums have been
linked through stylometric analysis [7].
Authors may deliberately try to obfuscate or anonymize
their writing style [12], [6], [30]. Brennan et al. show how
stylometric authorship attribution can be evaded with adver-
sarial stylometry [12]. They present two ways for adversarial
stylometry, namely obfuscating writing style and imitating
someone else’s writing style. Afroz et al. identify the stylistic
changes in a piece of writing that has been obfuscated while
McDonald et al. present a method to make writing style
modiﬁcation recommendations to anonymize an undisputed
document [6], [30].
Source code stylometry. Several authors have applied
similar techniques to identify programmers based on source
code [16], [34], [15]. Source code authorship attribution has
applications in software forensics and plagiarism detection1.
The features used for machine learning in source code
authorship attribution range from simple byte-level [20] and