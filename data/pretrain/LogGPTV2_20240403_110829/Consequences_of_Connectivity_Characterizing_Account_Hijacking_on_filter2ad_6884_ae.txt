meme
Figure 10: Delay between the onset t0 of a cluster and
each user’s participation at ti.
F
D
C
100%
75%
50%
25%
0%
0.01
1.00
Duration (in days)
100.00
compromise
fraudulent
meme
Figure 11: Duration of clusters measured from the ﬁrst
clustered tweet t0 to the last tweet tn.
5.4 Rate of Spread
To understand how rapidly contagions spread, we compare
the delay between each compromised user’s ﬁrst spam tweet
ti to the onset of the contagion t0, estimated as the ﬁrst
tweet in the cluster. For comparison, we repeat this process
for every meme participant and fraudulent account. Our re-
sults are shown in Figure 10. We ﬁnd that compromise is the
slowest process, with 30% of victims posting in the ﬁrst day
compared to 44% of meme participants. Spam campaigns
reliant on fake accounts are the most condensed, with 65% of
accounts posting within a day of the campaign’s onset. The
long tail for fraudulent accounts results from fresh accounts
joining campaigns over time, with multiple campaigns be-
ing merged due to overlapping participants. Our ﬁndings
indicate that, contrary to Internet worms [24], social conta-
gions are slow moving due to the requirement that victim’s
interact with harmful content.
5.5 Campaign Duration
Despite the quick reaction time of compromised users to
unwarranted content in their feeds (discussed in Section 4.2),
contagions are nevertheless able to spread and last for mul-
tiple days. The median compromise cluster—shown in Fig-
ure 11—measured from its ﬁrst tweet t0 to its last tweett n,
is 9 days in duration. For comparison, memes last a median
of 5 days and spam campaigns conducted via fraudulent ac-
counts only last 1 day. The long duration of compromise
campaigns indicates that even batch jobs for detecting com-
promise contagions can reduce the number of victims im-
497●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
Scam Type
Weight Loss Supplements
Gain Followers
Survey Leads
221
779
1
4,758,207
3,704,314
994,563
Contagions Victims Spam Tweets Duration API Sources Distinct URLs
2,158,837
3,270,720
1,219
11,552,045
42,082,699
2,512,330
229 days
234 days
31 days
439
4,344
1
Table 3: Summary of the most prevalent monetization techniques spammed by criminals via compromised accounts.
pacted. If Twitter detected and remedied social contagions
within 24 hours, it would result in 70% fewer compromises.
6. MONETIZING HIJACKED ACCOUNTS
Proﬁt is the ultimate goal of account hijacking. We ex-
plore the three dominant monetization strategies that crim-
inals rely on once they gain access to compromised creden-
tials. Table 3 shows a summary of each strategy and its
impact on Twitter. These monetization schemes are similar
to previous Twitter spam campaigns that rely on fraudulent
accounts [28], though the challenge of reaching an audience
is vastly simpliﬁed by account hijacking.
6.1 Weight Loss
Easy weight loss nutraceuticals were the most proliﬁc
ploys that criminals used to monetize compromised ac-
counts. We identify 221 campaigns in our dataset contain-
ing roughly 4.7 million unique victims (34% of all compro-
mised accounts). Despite the short lifetime of individual
campaigns (an average of 6 days), weight loss schemes per-
sisted for 229 days—nearly the entirety of our data collection
period. We ﬁnd that criminals relied on stolen credentials
to author spam tweets; miscreants composed 98% of the
advertisements for weight loss via Twitter owned and op-
erated clients where a username and password is required.
The largest single contagion in this set used 1.1 million com-
promised accounts to advertise “its been 2 weeks and i lost
20 lbs thanks to garcinia, try it for free...”, linking to nearly
70,000 distinct URLs over a 23 day period.
Such scams generate a proﬁt through visitors voluntar-
ily providing criminals their credit card details and subse-
quently purchasing garcinia, green coﬀee, acai berry, rasp-
berry ketone, or some other nutraceuticals (often advertised
with a misappropriation of the “Dr Oz” brand). Merchants
fulﬁlling these orders have recently come under target by the
FTC for deceptive practices [31], while graymarket advertis-
ers on Facebook have also had their ads pulled for running
afoul of advertisement rules [11]. The reliance of criminals
on compromised accounts to reach a wide audience can thus
be viewed as merely an evolution in the long battle against
weight loss scams.
6.2 Gain Followers & Retweets
Fake follower schemes where victims unwittingly (or will-
ingly) provide their credentials to criminals in return for pur-
portedly gaining more followers (or alternatively retweets)
are the second largest source of compromises on Twitter. We
identify 779 of these schemes that netted roughly 3.7 million
users (27% of all compromised accounts). Victims advertise
“easy way to get free followers...” and “¨ucretsiz takip¸ci kazan”
(Earn free followers), with the most popular advertisements
appearing in English (47%), Turkish (22%), and Indonesian
(19%). Contrary to weight loss, 88% of spam tweets were
authored via a long tail of 4,343 OAuth applications and
the remaining 12% via the web. These applications include
Retweetlr, BestFollowers App, and a slew of throw away
OAuth credentials that criminals automatically generate to
withstand Twitter disabling their app.
Fake follower schemes both spread and generate a proﬁt
by victims installing their application. Criminals use com-
promised accounts to advertise services such as http://
followrush.org/ where miscreants can buy 20,000 followers
for $40 and 5,000 retweets and 5,000 favorites for $40—all of
which are sourced from the compromised accounts. Alterna-
tive monetization strategies rely on tiered pricing between
free membership and premium membership to fake follower
rings [25]. One example of this appearing in our dataset is
PlusFollower, where free members must follow all premium
users and send a promotional tweet as frequently as every 4
hours, in return receiving an unspeciﬁed number of follow-
ers. Premium members on the other hand pay a fee (starting
at £10) to gain followers, in turn avoiding the requirement
to follow other users or advertise the service.
Fake follower rings on Twitter have persisted since 2010,
with criminals advertising both “real accounts” and fraud-
ulent accounts as the source of follows [16, 25, 30]. While
perhaps some victims willingly participate in these scams,
we argue that they should nevertheless be considered com-
promised. In particular, users lose control of their accounts
and have no oversight capability over the subsequent spam
advertisements, retweets, favorites, and follows that occur.
Even if victims wish to leave the service they must go
through the same mechanism to restore account control as
compromised victims. Finally, the monetization of these
participants is clearly criminal and in violation of Twitter’s
Terms of Service.
6.3 Lead Generation
The ﬁnal monetization strategy we highlight is lead gener-
ation, where criminals entice victims into ﬁlling out surveys
for a nominal payment or trick victims into paying a “one-
time fee” before they can be paid for their work. We ﬁnd
only one contagion relying on this approach, but it alone
consisted of nearly 1 million victims and lasted 31 days.
Criminals used hijacked credentials to tweet an automated
template loosely matching “Sweeeet!!
I earned $157.18 this
week ﬁlling out a couple of surveys”, with all posts originating
from the web where a username and password is required.
Surprisingly, all of the URLs that criminals used to mone-
tize clicks lead to Facebook applications that are no longer
operational, hinting the contagion may have existed both on
Twitter and Facebook. While sleuthing through the broken
Facebook applications, we found an embedded iFrame that
linked back to at least one live site, getcashforsurveys.com,
which advertises a quick cash program through completing
surveys with an upfront enrollment fee of $74.
7. SUMMARY
Our work illuminates the threat of large-scale compromise
in social networks, and in concrete terms we identify 13 mil-
498lion hijacked victims on Twitter. Our measurements capture
the underlying social component of compromise and how it
operates at scale. This includes: the human cost of 21% of
victims losing access to their account and 57% of victims be-
coming more isolated from friends; the ability of miscreants
to generate social cascades that propagate as virulently as
media sensations, with the single largest contagion infecting
1.1 million users; and the ﬁnding that user vulnerability to
compromise appears independent of user savviness.
Our results indicate that compromise is dominated by so-
cial contagions—phishing and malware campaigns that prey
on user trust—as opposed to weak passwords or lax site secu-
rity. The underlying social process that drives compromise
mirrors that of information diﬀusion for benign memes and
viral content. Consequently, a user with 20 compromised
neighbors is 10x more likely to become compromised com-
pared to a user with one compromised neighbor.
To combat the threat of wide-spread hijacking, we ob-
serve that in addition to better account-hijacking detection
signals, existing victims can serve as early detectors for at-
tacks. We ﬁnd that a median user deletes an errant spam
tweet posted by a hijacker within one hour of its appear-
ance. If Twitter detected social contagions within 24 hours
of their outbreak via correlated deletion events (similar to
the detection scheme outlined in this paper), they could pro-
tect 70% of future potential victims. In particular, we em-
phasize that the centralized control aﬀorded to online social
networks provides an opportunity to inoculate victims to ar-
rest the spread of contagions in a way that has never been
possible for Internet worms.
8. ACKNOWLEDGMENTS
We would like to thank James Fowler for his helpful com-
ments on our research and its development. This work was
supported in part by the National Science Foundation un-
der grant 1237265, by the Oﬃce of Naval Research under
MURI grant N000140911081, and by a gift from Google.
Any opinions, ﬁndings, and conclusions or recommendations
expressed in this material are those of the authors and do
not necessarily reﬂect the views of the sponsors.
9. REFERENCES
[1] Eytan Bakshy, Brian Karrer, and Lada A Adamic.
Social inﬂuence and the diﬀusion of user-created
content. In Proceedings of the 10th ACM conference
on Electronic commerce, 2009.
[6] Nicholas A Christakis and James H Fowler. The
spread of obesity in a large social network over 32
years. New England Journal of Medicine, 2007.
[7] Dan Cosley, Daniel P Huttenlocher, Jon M Kleinberg,
Xiangyang Lan, and Siddharth Suri. Sequential
inﬂuence models in social networks. In Proceedings of
the International Conference of Weblogs and Social
Media, 2010.
[8] Anupam Das, Joseph Bonneau, Matthew Caesar,
Nikita Borisov, and XiaoFeng Wang. The tangled web
of password reuse. In Symposium on Network and
Distributed System Security (NDSS), 2014.
[9] Munmun De Choudhury, Yu-Ru Lin, Hari Sundaram,
K Selcuk Candan, Lexing Xie, and Aisling Kelliher.
How does the data sampling strategy impact the
discovery of information diﬀusion in social media? In
Proceedings of the International Conference of
Weblogs and Social Media, 2010.
[10] Manuel Egele, Gianluca Stringhini, Christopher
Kruegel, and Giovanni Vigna. COMPA: Detecting
Compromised Accounts on Social Networks. In
Proceedings of the Network and Distributed System
Security Symposium (NDSS), 2013.
[11] Facebook. Guidelines for advertised products &
services.
https:// www.facebook.com/ help/ 399392800124391/ ,
2014.
[12] Hongyu Gao, Yan Chen, Kathy Lee, Diana Palsetia,
and Alok Choudhary. Towards online spam ﬁltering in
social networks. In Symposium on Network and
Distributed System Security (NDSS), 2012.
[13] Hongyu Gao, Jun Hu, Christo Wilson, Zhichun Li,
Yan Chen, and Ben Y Zhao. Detecting and
characterizing social spam campaigns. In Proceedings
of the 10th ACM SIGCOMM conference on Internet
measurement. ACM, 2010.
[14] Sharad Goel, Duncan J Watts, and Daniel G
Goldstein. The structure of online diﬀusion networks.
In Proceedings of the 13th ACM Conference on
Electronic Commerce, 2012.
[15] C. Grier, L. Ballard, J. Caballero, N. Chachra, C.J.
Dietrich, K. Levchenko, P. Mavrommatis, D. McCoy,
A. Nappa, A. Pitsillidis, et al. Manufacturing
compromise: The emergence of exploit-as-a-service. In
Proceedings of the ACM Conference on Computer and
Communications Security (CCS), 2012.
[2] Eytan Bakshy, Itamar Rosenn, Cameron Marlow, and
[16] C. Grier, K. Thomas, V. Paxson, and M. Zhang.
Lada Adamic. The role of social networks in
information diﬀusion. In Proceedings of the 21st
international conference on World Wide Web, 2012.
[3] Andrei Z Broder. On the resemblance and
containment of documents. In Compression and
Complexity of Sequences 1997. Proceedings, 1997.
[4] Chris Brook. Github resets users’ passwords following
brute force attack. http:// threatpost.com/
github-resets-users-passwords-following-brute-force-attack/
102983 , 2013.
[5] M. Cha, H. Haddadi, F. Benevenuto, and K.P.
Gummadi. Measuring User Inﬂuence in Twitter: The
Million Follower Fallacy. In Proceedings of the 4th
International Conference on Weblogs and Social
Media, 2010.
@spam: The Underground on 140 Characters or Less.
In Proceedings of the ACM Conference on Computer
and Communications Security (CCS), 2010.
[17] Brian Krebs. Adobe breach impacted at least 38
million users. http:// krebsonsecurity.com/ 2013/ 10/
adobe-breach-impacted-at-least-38-million-users/ ,
2013.
[18] Jure Leskovec, Jon Kleinberg, and Christos Faloutsos.
Graphs over time: densiﬁcation laws, shrinking
diameters and possible explanations. In Proceedings of
the eleventh ACM SIGKDD international conference
on Knowledge discovery in data mining, 2005.
[19] Miller McPherson, Lynn Smith-Lovin, and James M
Cook. Birds of a feather: Homophily in social
networks. Annual review of sociology, 2001.
499[20] Fred Morstatter, Jurgen Pfeﬀer, Huan Liu, and
Kathleen M Carley. Is the Sample Good Enough?
Comparing Data from Twitter’s Streaming API with
Twitter’s Firehose. In Proceedings of the International
Conference of Weblogs and Social Media, 2013.
[21] Mark EJ Newman. Spread of epidemic disease on
networks. Physical review E, 2002.
[26] Fred Tanneau. Twitter hacked! 250,000 user accounts
breached. http:// www.cnbc.com/ id/ 100343530 , 2013.
[27] Ke Tao, Fabian Abel, Claudia Hauﬀ, Geert-Jan
Houben, and Ujwal Gadiraju. Groundhog day:
Near-duplicate detection on Twitter. In Proceedings of
the 22nd international conference on World Wide
Web, 2013.
[22] Nicole Perlroth. Lax Security at LinkedIn Is Laid
[28] K. Thomas, C. Grier, V. Paxson, and D. Song.
Bare. http:// nyti.ms/ 1fRQIl4 , 2012.
[23] Daniel M Romero, Brendan Meeder, and Jon
Kleinberg. Diﬀerences in the mechanics of information
diﬀusion across topics: Idioms, political hashtags, and
complex contagion on Twitter. In Proceedings of the
20th international conference on World wide web,
2011.
Suspended Accounts In Retrospect: An Analysis of
Twitter Spam. In Proceedings of the Internet
Measurement Conference, November 2011.
[29] Kurt Thomas and David M. Nicol. The Koobface
botnet and the rise of social malware. In Proceedings
of The 5th International Conference on Malicious and
Unwanted Software (Malware 2010), 2010.
[24] Stuart Staniford, Vern Paxson, and Nicholas Weaver.
[30] C. Yang, R. Harkreader, J. Zhang, S. Shin, and
How to 0wn the Internet in Your Spare Time. In
USENIX Security Symposium, 2002.
[25] Gianluca Stringhini, Gang Wang, Manuel Egele,
Christopher Kruegel, Giovanni Vigna, Haitao Zheng,
and Ben Y Zhao. Follow the Green: Growth and
Dynamics in Twitter Follower Markets. In Proceedings
of the 2013 conference on Internet measurement
conference, 2013.
G. Gu. Analyzing Spammers’ Social Networks for Fun
and Proﬁt: a Case Study of Cyber Criminal
Ecosystem on Twitter. In Proceedings of the 21st
International Conference on World Wide Web, 2012.
[31] Alison Young. FTC takes action against deceptive
weight-loss products. http:// www.usatoday.com/
story/ news/ nation/ 2014/ 01/ 07/
ftc-charges-deceptive-weight-loss-products/ 4354669/ ,
2014.
500