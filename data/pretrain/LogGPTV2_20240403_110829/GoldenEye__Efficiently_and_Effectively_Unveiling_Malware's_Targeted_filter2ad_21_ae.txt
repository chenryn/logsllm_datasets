GetKeyboardLayout and automatically extracts malware’s intention of not infect-
ing the system with Ukrainian keyboard [43]. For some variants of Bifrost[2], GOLDEN-
EYE ﬁnds they query the system language to check whether the running OS is Chinese
system or not, which is their targeted victim environment. For these cases, GOLDEN-
EYE can intelligently change the query result of APIs, such as GetKeyboardLayout,
to make malware believe they are running in their targeted machine/location.
User Credentials. We found several malware samples target at user credentials to
conduct their malicious activities. For example, we found that Neloweg[19] will ac-
cess registry at Microsoft/Internet Account Manager/Accounts key,
which stores users’ outlook credentials. Similar examples also include Koobface[8],
which targets at user’s facebook credentials. GOLDENEYE successfully captures these
malicious intentions by providing fake credentials/ﬁle/registry to malware and allowing
the malware to continue execution. While the malware’s further execution may fail be-
cause GOLDENEYE may not provide the exact correct content of the credential, GOLD-
ENEYE can still provide enough targeted environment information to malware analysts.
System Invariants. In our test, GOLDENEYE extracted one mutex from Sality [12]
whose name is uxJLpe1m. In the report, we found that the existence of such mutex
may disable Sality’s execution. This turns out to be some common logic for a set of
malware to prevent multiple infections. Similar logic has also been found in Zeus [21]
and Conﬁcker [43]. For these cases, even though the clean environment, which does not
contain the mutex, is the ideal environment for analysis, we can still see that GOLDEN-
40
Z. Xu et al
EYE’s extracted information is useful, potentially for malware prevention, as discussed
in [48].
Displayed Windows and Installed Library. iBank [7] Trojan is one example that is
sensitive to certain displayed windows and installed library. In particular, GOLDENEYE
detects that IBank tries to ﬁnd the window " AVP.Root", which belongs to Kasperky
software. Meanwhile, it also detects that IBank accesses avipc.dll in the home path
of Avira Anti-virus software. Our GOLDENEYE further detects if such library or win-
dow exists, the malware exhibits more behaviors by calling the function AvIpcCall
in the library to kill the AV-tools. IBank samples tell us that if our analysis is performed
in an environment without AV tools installed, we will miss these anti-AV behaviors.
Hence, as a side effect, GOLDENEYE could be a good automatic tools for analysts to
detect malware’s anti-AV behaviors.
Others. Last but not least, we always assume exposing more malicious behaviors is bet-
ter. However, detecting some path with less malicious behaviors may be also interesting.
One example we ﬁnd in our dataset is Qakbot [11]. The malware exhibits some behav-
iors related to some registry entry. This malware tries to write qbothome qbotinj.
exe into a common start up registry key CurrentVersion\Run. The further logic
for Qakbot needs to check the existence of such registry entry and if it fails, malware
goes to sleep routine without directly exhibiting some malicious behaviors. This case
is interesting for us because we ﬁnd that by changing environment setting, we could
even observe some hidden dormant functionality. Discovering such hidden dormant
functionality may help defenders to make some schemes for slowing down the fast-
spreading of certain malware.
6.6 Experiment on Distributed Deployment of GOLDENEYE
Finally, we evaluate the performance overhead of our distributed deployment of GOLD-
ENEYE. In this experiment, we measure three cases:
– Case I: Generate a parallel task for all environment-sensitive branches.
– Case II: Generate a parallel task only when the branch evaluation cannot decide a
branch after measuring the branch selection heuristics.
– Case III: Do not generate a parallel task and do not conduct rolling back, i.e., using
a single machine instead of distributed deployment (for undetermined paths, we
select the default environment as desired).
We use additional four worker (virtual) machines for this measurement (Case I and
II). Each virtual machine installs original unpatched Windows XP SP1 operating sys-
tem. We randomly select 100 malware samples and run each sample for at most 300
seconds in each conﬁguration. We compare performance with the baseline case, which
is running each malware in the default environment.
The result is summarized in Figure 6. As seen in the ﬁgure, we study the effectiveness
by measuring the increased ratio of native APIs. As expected, Case I and II expose
over 30% more behaviors than Case III. However, the standard deviation of Case I is
higher than Case II. It shows that, with the same analysis time, the ﬁrst approach may
not outperform the second case because exploring all environment-sensitive paths is
GOLDENEYE: Efﬁciently and Effectively Unveiling Malware’s Targeted Environment
41
120.00%
100.00%
80.00%
60.00%
40.00%
20.00%
0.00%
Increased Native API
Utilization Ratio
Case I
Case II
Case III
Fig. 6. Measurement of Distributed GOLDENEYE
not efﬁcient enough. We also measure the utilization ratio of the analysis machine(s),
which is deﬁned as the percentage of time for an analysis machine to run the analysis
task within the given 300 seconds. The average utilization ratio from VMs in Case I
is over 90%, which is much higher than Case II. In short, we conclude that Case II
conﬁguration of GOLDENEYE, i.e., combining the branch selection scheme with the
distributed deployment, seems to achieve the best balance between effectiveness and
resource consumption among the three cases.
7 Discussion
Exposing malicious behaviors of environment-targeted malware is a challenging re-
search task for the whole malware defense community. As a new step towards system-
atic environment-targeted malware analysis, our solution is not perfect and not targeting
to completely solve the problem. We now discuss limitations/evasions below.
Correctness of Path Selection/Prediction. One limitation of our approach is that the
correctness of our branch evaluation depends on whether malware’s behavior ﬁts our
heuristics. One solution for this problem is to explore all possible branches by multi-
round snapshot-and-recover analysis, as in [37]. However, this scheme may cause much
higher overhead because of the path explosion problem. Hence, to trade off the per-
formance, we choose to apply snapshot-and-recover only when we cannot apply the
heuristics. Other dynamic analysis approaches such as previous work [39,41] can also
be applied to make the analysis more efﬁcient.
Possible Problems of Taint Analysis. In our scheme, we apply taint analysis at the
stages of preprocessing and speculative execution. For preprocessing, taint analysis can
help us ﬁlter out the malware which are not sensitive to the environment. For specula-
tive execution, taint analysis helps to save execution overhead from multiple aspects.
However, as discussed in related work [22], taint analysis could have limitations of
over-tainting and under-tainting. Even though it may cause the problem of imprecise
results, for our cases, the limitation can seldom affect our analysis. This is because: (1)
Even though over-tainting costs more overhead for speculative execution, our scheme
is still more lightweight than existing approaches. (2) The under-tainting problem may
42
Z. Xu et al
mislead our branch prediction. However, by using stricter branch selection criteria, we
could avoid such wrong branch. Meanwhile, conducting more roll-backing operations
on some critical branches can also improve the overall accuracy. (3) Our analysis can be
independently conducted even without taint analysis. In this case, our speculative execu-
tion engine has to be executed at all branches to truncate undesired environments. Even
though it may cause more overhead, we believe it still outperforms other approaches
because it prevents unnecessary rolling-back.
Evasion through Misleading the Analysis. The implementation GOLDENEYE is built
upon on binary instrumentation, and because of the similar limitation as VMM-based
approaches[28], it is possible for malware to detect the existence of GOLDENEYE.
By knowing our heuristics for branch selection, the attacker could mislead our analy-
sis through injecting some certain APIs in the branches. However, some heuristics (e.g.,
environment interaction, process termination) are relatively hard to be evaded because
otherwise they will be against the malware’s execution intention. We note that even in
the worst case (we have to rewind to explore another branch, similar to existing multi-
path solutions), our solution is still better than a blind multi-path exploration scheme.
Another way to evade the analysis is to query environment information and process
it at a very later time. To handle this issue, we could increase the capacity of parallel
spaces and track the tainted environment elements throughout the whole analysis by
paying a little more analysis overhead.
Malware can insert some dormant functions such as sleep because GOLDENEYE
may not prefer to choose branches in which malware could enter a dormant status.
To handle such cases, GOLDENEYE can examine more code blocks in the foreseeing
operation in order to make a more accurate branch selection or could simply generate a
parallel task for another worker machine.
Last but not least, current implementation of GOLDENEYE does not handle implicit
control ﬂow, a common issue to many dynamic analysis systems. Hence, malware au-
thors may evade the analysis by including implicit control ﬂow. However, this issue
could be partially solved by conducting symbolic execution on indirect branches. We
leave it as our future work.
Environment-Uniqueness Malware. A recent study [27] discussed a novel anti-analysis
technique, which applies environment primitives as the decryption key for the malware
binary. In the real world, ﬂashback [18] malware has exhibited similar interesting at-
tributes. To the best of our knowledge, there is no research or tool can automatically
analyze such kind of malware. Even though our approach cannot provide correct analy-
sis environment for the captured sample, we believe our analysis can still discover more
information than traditional automatic analysis techniques. For example, our approach
can detect malware’s query for system environment and deduce what are likely environ-
ment elements that compose the decryption key. We leave the analysis of such malware
to our future work.
8 Conclusion
In this paper, we have presented a new dynamic analysis system, GOLDENEYE, to fa-
cilitate targeted malware analysis by efﬁciently and effectively exposing its targeted
environments. To achieve our goal, we design several new dynamic analysis techniques
GOLDENEYE: Efﬁciently and Effectively Unveiling Malware’s Targeted Environment
43
based on speculative execution, such as parallel environment spaces construction and
branch evaluation, to solve the technical challenges faced by targeted malware analysis.
To further improve the accuracy and efﬁciency, we deploy GOLDENEYE onto a dis-
tributed computing model. In the evaluation, we show that our scheme can work on a
large real-world malware corpus and achieve a better performance trade-off compared
with existing approaches. While not perfect, we believe this is a right step towards an
interesting new topic, i.e., targeted threat analysis and defense, which needs further
research from the community.
Acknowledgments. This material is based upon work supported in part by the Na-
tional Science Foundation under Grant CNS-0954096 and the Air Force Ofﬁce of Sci-
entiﬁc Research under Grants FA9550-13-1-0077 and FA-9550-12-1-0077. Any opin-
ions, ﬁndings, and conclusions or recommendations expressed in this material are those
of the authors and do not necessarily reﬂect the views of NSF and AFOSR.
References
1. Anubis: Analyzing unknown binaries, http://anubis.iseclab.org/
2. Bifrost,
http://www.symantec.com/security_response/writeup.jsp?
docid=2004-101214-5358-99
3. Disassembler library for x86/amd64, http://code.google.com/p/distorm/
4. Duqu,
http://www.kaspersky.com/about/press/major_malware_outbreaks/
duqu
5. DynamoRIO,
http://dynamorio.org/
6. Flame,
http://en.wikipedia.org/wiki/Flame_malware
7. IBank,
http://www.sophos.com/en-us/threat-center/threat-analyses/
viruses-and-spyware/Troj˜IBank-B/detailed-analysis.aspx
8. Koobface,
http://www.symantec.com/security_response/writeup.jsp?
docid=2008-080315-0217-99&tabid=2
9. NuclearRAT,
http://en.wikipedia.org/wiki/Nuclear_RAT
10. Offensive Computing, http://www.offensivecomputing.net/
11. Qakbot,
http://www.symantec.com/connect/blogs/w32qakbot-under-surface
12. Sality,
http://www.symantec.com/security_response/writeup.jsp?
docid=2006-011714-3948-99
13. Stuxnet, http://en.wikipedia.org/wiki/Stuxnet
14. Symantec intelligence quarterly,
http://www.symantec.com/threatreport/quarterly.jsp
15. Symantec: Triage analysis of
targeted attacks, http://www.symantec.com/
threatreport/topic.jsp?id=malicious_code_trend
44
Z. Xu et al
16. The Nitro Attacks: Stealing Secrets from the Chemical
Industry, http://www.
symantec.com/security_response/whitepapers.jsp
17. Trends in targeted attacks,
http://www.trendmicro.com/cloud-content/us
18. Trojan BackDoor.Flashback,
http://en.wikipedia.org/wiki/Trojan_BackDoor.Flashback
19. Trojan.Neloweg,
http://www.symantec.com/security_response/writeup.jsp?
docid=2012-020609-4221-99
20. Virustotal, https://www.virustotal.com/
21. Zeus Trojan horse,
http://www.symantec.com/security_response/writeup.jsp?
docid=2010-011016-3514-99
22. Avgerinos, T., Schwartz, E., Brumley, D.: All you ever wanted to know about dynamic taint
analysis and forward symbolic execution (but might have been afraid to ask). In: Proc. of
IEEE S&P 2010 (2010)
23. Balzarotti, D., Cova, M., Karlberger, C., Kruegel, C., Kirda, E., Vigna, G.: Efﬁcient detection
of split personalities in malware. In: Proc of NDSS 2010 (2010)
24. Bilge, L., Dumitras, T.: Before we knew it: An empirical study of zero-day attacks in the real
world. In: Proc. of CCS 2012 (2012)
25. Brumley, D., Hartwig, C., Liang, Z., Newsome, J., Poosankam, P., Song, D., Yin, H.: Auto-
matically identifying trigger-based behavior in malware. In: Lee, W., Wang, C., Dagon, D.
(eds.) Botnet Analysis and Defense. AIS, vol. 36, pp. 65–88. Springer, Heidelberg (2008)
26. Brumley, D., Jager, I., Avgerinos, T., Schwartz, E.J.: BAP: A binary analysis platform. In:
Gopalakrishnan, G., Qadeer, S. (eds.) CAV 2011. LNCS, vol. 6806, pp. 463–469. Springer,
Heidelberg (2011)
27. Royal, P., Song, C., Lee, W.: Impeding automated malware analysis with environment-
sensitive malware. In: Proc. of HotSec 20 12 (2012)
28. Chen, X., Andersen, J., Mao, M., Bailey, M., Nazario, J.: Towards an Understanding of Anti-
Virtualization and Anti-Debugging Behavior in Modern Malware. In: Proc. of DSN 2008
(2008)
29. Comparetti, P.M., Salvaneschi, G., Kirda, E., Kolbitsch, C., Krugel, C., Zanero, S.: Identify-
ing dormant functionality in malware programs. In: Proc. of S&P 2010 (2010)
30. Dinaburg, A., Royal, P., Sharif, M., Lee, W.: Ether: Malware analysis via hardware virtual-
ization extensions. In: Proc of CCS 2008 (2008)
31. Gonzlez, J., Gonzlez, A.: Speculative execution via address prediction and data prefetching.
In: Proc. of ICS 1197 (1997)
32. Graziano, M., Leita, C., Balzarotti, D.: Towards network containment in malware analysis
systems. In: Proc. of ACSAC 2012 (December 2012)
33. Kolbitsch, C., Milani Comparetti, P., Kruegel, C., Kirda, E., Zhou, X., Wang, X.: Effective
and efﬁcient malware detection at the end host. In: Proc. of USENIX Security 2009 (2009)
34. Kolbitsch, C., Kirda, E., Kruegel, C.: The power of procrastination: Detection and mitigation
of execution-stalling malicious code. In: Proc. of CCS 2011 (2011)
35. Kolbitsch, C., Livshits, B., Zorn, B., Seifert, C.: Rozzle: De-cloaking internet malware. In:
Proc. of S&P 2012 (2012)
36. Lindorfer, M., Kolbitsch, C., Milani Comparetti, P.: Detecting Environment-Sensitive Mal-
ware. In: Sommer, R., Balzarotti, D., Maier, G. (eds.) RAID 2011. LNCS, vol. 6961, pp.
338–357. Springer, Heidelberg (2011)
37. Moser, A., Kruegel, C., Kirda, E.: Exploring Multiple Execution Paths for Malware Analysis.
In: Proc. of S&P 2007 (2007)
GOLDENEYE: Efﬁciently and Effectively Unveiling Malware’s Targeted Environment
45
38. Moser, A., Kruegel, C., Kirda, E.: Limits of static analysis for malware detection. In: Proc.
of ACSAC 2007 (2007)
39. Nadji, Y., Antonakakis, M., Perdisci, R., Lee, W.: Understanding the Prevalence and Use of
Alternative Plans in Malware with Network Games. In: Proc. of ACSAC 2011 (2011)
40. Nappa, A., Xu, Z., Raﬁque, M.Z., Caballero, J., Gu, G.: Cyberprobe: Towards internet-scale
active detection of alicious servers. In: Proc. of NDSS 2014 (2014)
41. Neugschwandtner, M., Comparetti, P.M., Platzer, C.: Detecting Malware’s Failover C&C
Strategies with SQUEEZE. In: Proc. of ACSAC 2011 (2011)
42. Peng, F., Deng, Z., Zhang, X., Xu, D., Lin, Z., Su, Z.: X-force: Force-executing binary pro-
grams for security applications. In: Proceedings of the 2014 USENIX Security Symposium,
San Diego, CA (August 2014)
43. Porras, P., Saidi, H., Yegneswaran, V.: An Analysis of Conﬁcker’s Logic and Rendezvous
Points (2009), http://mtc.sri.com/Conficker/
44. Shin, S., Xu, Z., Gu, G.: Effort: Efﬁcient and effective bot malware detection. In: Proc. of
INFOCOM 2012 Mini-Conference (2012)
45. Sikorski, M.: Practical Malware Analysis: The Hands-On Guide to Dissecting Malicious
Software (2012) (No Starch Press)
46. Wilhelm, J., Chiueh, T.-c.: A forced sampled execution approach to kernel rootkit identiﬁ-
cation. In: Kruegel, C., Lippmann, R., Clark, A. (eds.) RAID 2007. LNCS, vol. 4637, pp.
219–235. Springer, Heidelberg (2007)
47. Xu, Z., Chen, L., Gu, G., Kruegel, C.: PeerPress: Utilizing enemies’ p2p strength against
them. In: Proc.of CCS 2012 (2012)
48. Xu, Z., Zhang, J., Gu, G., Lin, Z.: AUTOVAC: Towards automatically extracting system
resource constraints and generating vaccines for malware immunization. In: Proc. of ICDCS
2013 (2013)