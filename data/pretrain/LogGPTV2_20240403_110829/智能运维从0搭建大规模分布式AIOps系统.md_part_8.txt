合，
的真正原因。[2]
故障分析（Root Cause Analysis），是指通过分析观测到的征兆（Symptom），找出产生这些征兆
直停留在规划阶段，尤其是大公司，部门之间的鸿沟是技术人员无法跨越的。
中若想用某个“体系”来一统天下，则基本不可能，因为各种非技术因素可能会让这种努力一
如果想定位故障和发现问题，在各个系统中就必须有一个可追踪、共性的东西。然而，在现实
成微服务化并没有降低业务的复杂度（当然结构肯定变清晰了)。
能掌控全局的人)，即使这样有时得出的结论也不见得各方都认可。
成本较高，需要多部门合作，开发、运维人员相互配合分析（现在的大规模系统很难找到一个
2.4
一定的支持，
只能取决于实践中的效果了。
所以，下面给出的几种简单方法和技术，既能在异构系统中建立某种关联，为智能化提供
在这里，又不得不强调工程能力的重要性。在复杂、异构和各种技术栈混杂的业务系统中，
在开发层面，应对复杂业务的一般思路是采用SOA、微服务化等，但从运维的角度讲，完
需要注意的是，并不是用了人工智能或机器学习，故障定位的效果就一定很好，这取决于
还有很多方法，但笔者也在探索中，所以无法推荐一个“最佳”方法。究竟什么算法更适
在实践中通常用于故障定位的机器学习算法有关联规则和决策树。
故障定位又称为告警关联（AlarmCorrelation）、问题确定（Problem Determination）或根源
当这些工程（自动化、标准化）的水平达到一定高度后，我们才有望向智能化方向发展。
业务模型（或系统部署结构）复杂带来的最直接影响就是定位故障很困难，发现根源问题
有些方法属于工程方法，有些方法属于人工智能或机器学习的范畴。
O
C
复杂业务模型下的故障定位
速比”来衡量系统健康度。
SLA规范化：采用统一的SLA约定，比如都用“响应时间”来约定性能指标，用“慢
全链路追踪：TraceID 或者RequestID 应该能从发起方透传到后端，标识唯一请求。
日志标准化：日志包含所约定的内容、格式，能标识自己的业务线、服务层级等
又不要求开发人员改变技术栈或开发框架。
第2章智能运维
---
## Page 49
2.6
上会遇到的问题。
都给出了经过实践证明的解决方案和思路，
析、处理，多维度，多数据源，信息过载，
2.5
这句话：智能化的效果不仅仅取决于算法，工程能力也很重要，而且好的数据胜过好的算法。
很多因素，比如特征工程、算法模型、参数调整、数据清洗等，
22
本章介绍了智能运维的定义和发展现状，智能运维需要解决的问题有：海量数据存储、分
[2]张成，廖建新，朱晓民．基于贝叶斯疑似度的启发式故障定位算法
参考文献
本章小结
智能运维：从O搭建大规模分布式AIOps 系统
仅供非商业用途或交流学习使用
同时也说明了为什么要这么做，以及在工程和算法
，复杂业务模型下的故障定位。在每一类问题后面，
需要不断地调整和学习。还是
---
## Page 50
属于Google 机器智能研究机构）的研究员和工程师开发出来的，用于机器学习和深度神经网络
个或多个CPU（或 GPU）、服务器、移动设备等。TensorFlow最初是由Google大脑小组（隶
组，即张量（Tensor）。其灵活的架构让你可以在多种平台上展开计算，例如台式计算机中的一
件库。在图中节点（Node）表示数学操作，线（Edge）则表示在节点间相互联系的多维数据数
PadlePaddle 等。TensorFlow是一个采用数据流图（Data Flow Graph），用于数值计算的开源软
的大规模分布式图计算问题。
则是大规模分布式图计算平台，专门用来解决网页链接分析、社交数据挖掘等实际应用中涉及
秒的时间里处理 1PB 的数据查询请求。Apache 后来开源的 Drill 就是 Dremel 的开源版本。Pregel
大量的数据。Dremel设法将海量的数据分析与对数据的深入挖掘进行有机的结合，可在大约
站索引系统中。Dremel是一种分析信息的方式，Dremel可跨越数千台服务器运行，允许“查询”
Caffeine 是Google 出于自身需求的设计，使Google 能够更迅速地将新的链接添加到大规模的网
了Caffeine、Dremel 和 Pregel，它们被视为新时期的“三驾马车”，用于处理更大规模的数据。
联网企业产生了极大的影响。随着数据规模的扩大，以及对性能的更高要求，后来Google 发布
MapReduce 和 BigTable 的三篇论文），以及其在开源界对应的 HDFS、Hadoop 和 HBase，对互
施，更多地关注业务，而不需要从零开始开发类似的工具和框架。
维开发工程师更多的是要学习和掌握这些技术及工具，站在巨人肩上，利用这些优秀的基础设
应用到各个企业中时，运维技术也进入了高速的发展阶段。在众多优秀的开源框架基础上，运
变革，所涉及的技术也非常多，而且很多技术已经发展成熟，尤其是当开源项目逐渐被大规模
都需要积累。运维技术也在不断创新积累，在这个过程中经历了从工具到平台再到智能的巨大
又如，在 AI 时代，有非常多的开源机器学习平台，如 Google 的 TensorFlow、百度的
比如,在大数据存储和分析处理方面,Google 的“三驾马车"(Google 公开发布了关于GFS、
“不积趾步，无以至千里；不积小流，无以成江海。”荀子在《劝学篇》里讲到，任何学问
站在巨人肩上：智能运维基础设施
第2篇
---
## Page 51
处理、分析和计算，并结合一些应用案例逐渐展开。本篇主要分为以下几个章节：
类似的开源工具和平台也被逐渐集成在云平台中作为大型云服务企业的基础服务，逐渐被工程
式全功能深度学习框架，支持海量图像识别分类、机器翻译和自动驾驶等多个领域的业务需求。
深度学习技术方面比较领先，百度也开源了自己的深度学习平台PaddlePaddle，它是并行分布
方面的研究，但这个系统的通用性使其也可广泛用于其他计算领域。在国内，百度在机器学习、
化，
：同时极大地降低了开发工程师的学习门槛。
○第9章机器学习框架
〇第3章开源数据采集技术
工欲善其事，必先利其器。第2篇我们将重点系统介绍如何使用开源框架进行大数据存储
〇第8章时序数据分析框架
○第7章实时计算框架
O
O
智能运维：从0搭建大规模分布式AIOps系统
第6章大规模数据离线计算分析
第5章大数据存储技术
第4章分布式消息队列
仅供非商业用途或交流学习使用
---
## Page 52
的工具就成了我们的首要工作。如表3-1所示，对比了几个开源日志收集工具。
Scribe等，而从中选择一个高可靠、高性能、占用系统资源少，以及符合业务应用场景等特性
具来收集这些数据。现在市面上的日志收集工具琳琅满目，常见的有Flume、Filebeat、Logstash、
3.1
扩展性
理的工具与框架，开发者极易根据自己的业务需求和不同场景来选择或者进行二次开发。
为数据采集和分析增加了极大的难度。值得庆幸的是，开源界出现了大量用于数据采集和预处
甚至是二进制文件，还可能是图片、视频或者音频文件。类似这样的结构化和非结构化数据，
和Linux的系统日志(一般在/var/log路径下),而业务数据可能是JSON格式的，也可能是HTML,
日志过滤
占用系统资源
们经常接触到的日志数据有WebServer的日志（如Nginx或者Apache的access 和error日志）
日志解析
语言
通过对比可以发现，Logstash 虽然功能更加强大，但是占用系统资源较多，而 Filebeat 则更
数据是监控报警的基石，因此我们在实现海量数据的分析监控前，就需要有一个顺手的工
对业务指标的监控本质上是对数据的监控，
数据采集工具对比
不支持
支持
Java
Flume
一般
表3-1
不支持
支持
好
Go
Filebeat
开源日志收集工具对比
所以说智能运维是建立在数据基础之上的。我
开源数据采集技术
支持
好
支持
Ruby
Logstash
不支持
不支持
差
++
Scribe
般
---
## Page 53
如图3-1所示。
到Libbeat,Libeat 会聚合接收到的事件，并把聚合后的数据发送给配置文件中指定的 Output,
到的每个文件都会启动一个Harvester。每个Harvester都读取一个文件，并把文件中的数据发送
3.2.1
发送到Elasticsearch 中
不错的选择。
需要采集，同时又不想占用太多的机器资源，以避免影响线上服务的运行时，Filebeat就是一个
3.2
加轻量级，占用系统资源较少。因此，本章我们选择Filebeat作为日志收集工具进行详细介绍。
26
Filebeat 启动一个或者多个 Prospector去配置文件中指定日志路径下的勘查文件，对于勘查
Filebeat 监控客户端的指定目录或者指定文件、跟踪文件，并将它们转发到Kafka 或者直接
Filebeat是Elastic开源Beats系列采集器中的轻量级日志采集器。当我们面对海量的日志
轻量级采集工具Filebeat
智能运维：从0搭建大规模分布式AIOps系统
Filebeat工作原理
Prospector 2:
/var/log/apache2/*
/var/1og/*.1og
wif.log
system.log
Harvester
Harvester
Harvester
Filebeat
图3-1
仅供非商业用途或交流学习使用
Filebeat收集数据流程图
Spooler
8
Redis
Kafka
Elastics
---
## Page 54
件中读取到内存中，Harvester 就知道从哪里开始收集文件中的内容了。
中，当出现异常导致 Filebeat 退出或者需要重新启动 Filebeat 时，文件状态信息将从 Registry 文
状态，直到Output 恢复可用时才会继续读取文件。文件状态信息被每个 Prospector 保存在内容
移量，如果 Output 如 Elasticsearch 或者Kafka 等变得不可用时，Filebeat 将跟踪最后一次发送的
个状态就是 Harvester 读取的文件内容，并确保所有内容都被发送出去时记录的是最后一行的偏
所导致的。
释放，磁盘的可用空间会越来越少。这是因为 Harvester 占用文件描述符，文件没有被真正删除
时不建议设置太长的时间，如果时间设置得太长，Harvester收集的文件描述符将一直不能得到
默认设置为5分钟，也就是说，Harvester 会释放在5分钟内没有更新的文件。在配置这个参数
描述符，Harvester 会在经过 scan_frequency 指定的时间周期后重新启动收集数据。close_inactive
如果文件在经过close_inactive 参数指定的时间后还没有更新，Harvester 将关闭，同时释放文件
取新增加的数据，不会再去收集已经收集过的数据。
数据，并且已经关闭，那么当这个文件大小发生改变后，新的 Harvester将被启动，并且只会获
Harvester 已经在运行，或者这个文件是否被忽略。如果一个文件之前已经通过 Harvester 收集过
被定义多次。log 勘查会检查文件以确定是否需要启动一个 Harvester 来收集数据、是否有一个
-type:log
filebeat.prospectors:
下面的示例分别展示了从一个指定目录匹配文件收集数据和从一个指定文件收集数据。
Prospector在磁盘上找出所有匹配指定全局路径的所有文件,并为每个文件启动一个Harvester。
Prospector 和 Harvester 具体是怎么一起工作，将数据收集起来并发送出去的呢？
paths:
Filebeat 通过固定周期将文件状态存储在磁盘的 Registry 文件中来记录每个文件的状态。这
3.Filebeat如何保持文件状态
Harvester 负责打开文件,开始逐行读取单个文件的内容,并将读取到的数据发送到Output。
2. Harvester
Filebeat 当前支持两种勘查类型：log 和 stdin。在同一个配置文件中，每种勘查类型都能够
-"/var/log/origin-*"
Prospector 负责管理Harvester，并发现所有可读的数据。如果输入的文件类型是 log，那么
"/var/log/error.log"
1.Prospector
在上面的描述中可以发现，Filebeat 有两个重要的组件：Prospector 和 Harvester。那么
第3章开源数据采集技术
---
## Page 55
${path.data}中指定。
3.2.2
将会持续发送；设置为-1，表示需要等待Kafka所有副本确认接收信息后，才继续发送。
们也可以通过设置 required_acks 参数来提高Filebeat 发送数据的效率，required_acks 默认值为
置 Filebeat关闭前等待的时间。
少被接收一次。所以在Output 端可能会出现重复的数据。我们可以通过 shutdown_timeout 来设
常退出而关闭，那么在 Filebeat 重启后，将会把上一次发送的数据再发送一遍，以确保数据至
给 Filebeat 确认接收信息为止。
的Output 端没有返回确认信息，Filebeat 将会继续尝试发送上一次的数据，直到Output 端返回
我们可以通过 clean_removed 和 clean_inactive 这两个参数来控制 Registry 文件的大小。
1，表示等待Kafka接收副本返回确认信息；设置为0，表示Kafka不返回确认接收信息，Filebeat
通过一个唯一标识来识别其是否已经被Harvester收集过。
其他地方，或者被重命名，所以通过文件名和路径不能辨认一个文件，Filebeat 对每个文件都会
28
registry_file：存储文件状态的文件，如果给出的是相对路径，那么文件所在的目录在
5.性能特性
当使用Kafka 作为 Output 时，如果不要求数据的完整性，则可以容忍少量的丢失数据。我
当向Output 端发送数据，或者还没有接收到Output 端返回的确认信息时，如 Filebeat 因异
Filebeat 通过将每次发送的数据状态都存储在 Registry 文件中来确保数据不丢失。如果发送
4.Filebeat如何确保数据不丢失
如果每天都有大量的新文件被创建，那么 Registry 文件很快就会变得很大，在Filebeat 中,
每个 Prospector 都会记录它扫描到的每个文件的收集状态信息，因为一个文件会被移动到
1．配置一般选项
O
智能运维：从O 搭建大规模分布式 AIOps 系统
稳定可靠：Filebeat会记录每次读取日志的offset 值，如果出现异常导致进程中断，那
Filebeat的安装与配置
正常后，Filebeat 将继续读取日志并发送给Kafka 或者 Elasticsearch 等接收端。
理数据缓慢，Filebeat 将自动减缓读取日志的速度，以免造成日志拥堵。当接收端恢复
自动流控：当 Filebeat 向 Kafka 或者 Elasticsearch 等接收端写入数据时，如果接收端处
么恢复后，Filebeat可以从中断前的位置继续读取，从而保证数据不会丢失。
---