title:Weak leakage-resilient client-side deduplication of encrypted data
in cloud storage
author:Jia Xu and
Ee-Chien Chang and
Jianying Zhou
Weak Leakage-Resilient Client-side Deduplication
of Encrypted Data in Cloud Storage ∗
Jia Xu
Ee-Chien Chang
Jianying Zhou
Institute for Infocomm Research
1 Fusionopolis Way
Singapore, 138632
PI:EMAIL
National University of Singapore
21 Lower Kent Ridge Road
Singapore, 119077
Institute for Infocomm Research
1 Fusionopolis Way
Singapore, 138632
PI:EMAIL
PI:EMAIL
Abstract
Recently, Halevi et al. (CCS ’11) proposed a cryptographic
primitive called proofs of ownership (PoW) to enhance secu-
rity of client-side deduplication in cloud storage. In a proof
of ownership scheme, any owner of the same ﬁle F can
prove to the cloud storage that he/she owns ﬁle F in a ro-
bust and efﬁcient way, in the bounded leakage setting where
a certain amount of efﬁciently-extractable information about
ﬁle F is leaked. Following this work, we propose a secure
client-side deduplication scheme, with the following advan-
tages:
• our scheme protects data conﬁdentiality (and some partial
information) against both outside adversaries and honest-
but-curious cloud storage server, while Halevi et al. trusts
cloud storage server in data conﬁdentiality;
• our scheme is proved secure w.r.t. any distribution with
sufﬁcient min-entropy, while Halevi et al. (the last and
the most practical construction) is particular to a speciﬁc
type of distribution (a generalization of “block-ﬁxing”
distribution) of input ﬁles.
The cost of our improvements is that we adopt a weaker leak-
age setting: We allow a bounded amount one-time leakage
of a target ﬁle before our scheme starts to execute, while
Halevi et al. allows a bounded amount multi-time leakage of
the target ﬁle before and after their scheme starts to execute.
To the best of our knowledge, previous works on client-side
deduplication prior Halevi et al. do not consider any leakage
setting.
∗ Funded by A*Star project SecDC-112172014.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. To copy otherwise, to republish, to post on servers or to redistribute
to lists, requires prior speciﬁc permission and/or a fee.
ASIA CCS’13, May 8–10, 2013, Hangzhou, China.
Copyright c(cid:13) 2013 ACM 978-1-4503-1767-2/13/05. . . $10.00
Categories and Subject Descriptors H.3.5 [Information
Systems]: Information storge and retrieval—On-line infor-
mation services; E.3 [Data Encryption]
General Terms Algorithms, Security
Keywords Cloud Storage, Client-side Deduplication, Proofs
of Ownership, Privacy, Leakage-Resilient, Universal Hash
Introduction
1.
Cloud storage service is gaining popularity in recent years.
To reduce resource consumption in both network bandwidth
and storage, many cloud storage services including Drop-
box 1 and Wuala 2 employs client-side deduplication [21,
39]. That is, when a user tries to upload a ﬁle to the server,
the server checks whether this particular ﬁle is already in
the cloud (uploaded by some user previously), and saves the
uploading process if it is already in the cloud storage. In
this way, every single ﬁle will have only one copy in the
cloud (i.e. Single Instance Storage). SNIA white paper [34]
reported that the deduplication technique can save up to 90%
storage, dependent on applications.
According to Halevi et al. [20] and Dropship [17], an
existing implementation of client-side deduplication is as
below: Cloud user Alice tries to upload a ﬁle F to the cloud
storage. The client software of the cloud storage service
installed on Alice’s computer, will compute and send the
hash value hash(F ) to the cloud server. The cloud server
maintains a database of hash values of all received ﬁles,
and looks up the value hash(F ) in this database. If there
is no match found, then ﬁle F is not in the cloud storage
yet. Alice’s client software will be required to upload F
to the cloud storage, and the hash value hash(F ) will be
added into the look-up database. If there is a match found,
then ﬁle F is already in the cloud storage, uploaded by
other users or even by the same user Alice before. In this
case, uploading of ﬁle F from Alice’s computer to the cloud
storage is saved, and the cloud server will allow Alice to
1 http://www.dropbox.com/
2 http://www.wuala.com/
access the ﬁle F in its cloud storage. We may refer to the
above client-side deduplication method as “hash-as-a-proof”
method. In this method, the hash value hash(F ) serves two
purposes: (1) it is an index of ﬁle F , used by the cloud
server to locate information of F among a huge number of
ﬁles; (2) it is treated as a “proof” that Alice owns ﬁle F .
Previously, Dropbox3 applied the above “hash-as-a-proof”
method on block-level cross-users deduplication [20][17].
If the client software of the cloud storage service is trusted
and the hash function hash(·) is collision-resistant, then the
“hash-as-a-proof” method is sufﬁciently secure. However,
malicious users may develop their own version of client
software using public API4 of the cloud service, so that they
can send any manipulated messages (e.g. manipulated hash
output) to the cloud server. Therefore, a more sophisticated
solution without trusting the client software is required.
1.1 Security Concerns
Different users may possess some identical sensitive ﬁles for
many reasons, even if they have no knowledge on each other.
For example they may receive a classiﬁed or copyright-
protected ﬁle directly or indirectly from the same source.
Partial information of these sensitive ﬁles could be leaked
via various channels [20, 21] by some owners intentionally
or unintentionally. Despite its signiﬁcant beneﬁts in saving
resource, client-side deduplication may bring in new security
vulnerability and lead to leakage of users’ sensitive ﬁles,
especially when a certain amount of partial information of
these ﬁles have already been leaked.
1.1.1 Data Privacy against Outside Adversaries
Recently, an attack on “hash-as-a-proof” method in popular
cloud storage service like Dropbox and MozyHome is pro-
posed [17, 20]: If the adversary somehow has the short hash
value of a ﬁle stored in the cloud storage, he/she could fool
the cloud server that he has the ﬁle by presenting only the
hash value as “proof” in the client-side deduplication pro-
cess, and thus gain access to that ﬁle via the cloud. This at-
tack is practical and does not require the adversary to ﬁnd a
collision of the hash function, since client software of cloud
service could be bypassed.
1.1.2 Data Privacy against Inside Adversaries (Cloud
Storage Servers)
Conﬁdentiality of users’ sensitive data against the cloud stor-
age server itself is another important security concern that is
not addressed by Halevi et al. [20]. As long as it is possible,
3 In Feb 2012, we noticed that Dropbox disabled the deduplication across
different users, probably due to recent vulnerabilities discovered in their
original cross-user client-side deduplication method. This also indicates the
importance and urgency in the study of security in client-side deduplication.
4 Dropbox provides public API. Furthermore, this issue can not be elim-
inated just by hidding API, since the adversary could perform reverse-
engineering attack to guess the communication protocol of the cloud ser-
vice. Note the effect of obfuscating is limited [6].
prudent users hope to ensure that the cloud storage server
is technically unable to access their data. Dropbox claims
they protect users’ data with AES encryption. However, the
encryption keys are chosen and kept by Dropbox itself. It
is reported that, Dropbox mistakenly kept all user accounts
unlocked for almost 4 hours, due to a new bug in their soft-
ware [40]. If users’ data are encrypted on client side and the
encryption keys are kept away from Dropbox, then there will
be no such single point of failure of privacy protection of
all users’ data, even if Dropbox made such mistakes or was
hacked in. Very recently, a bug in Twitter’s client software
is discovered [37], which allows adversary to access users’
private data.
It is worth noting that, cloud storage service providers,
including Amazon (S3), Apple (iCloud), Dropbox, Google
(Drive) and Microsoft (SkyDrive), explicitly or implicitly
declare that they reserve rights to access users’ ﬁles, in their
ofﬁcial statements of privacy policy [2, 10, 16, 19, 22, 25].
1.1.3 Divide and Conquer Attack
Let us consider an example: A classiﬁed document consists
of many pages. Although the whole document has sufﬁcient
min-entropy to the view of adversaries, the ﬁrst page has
very low min-entropy, say 1 bit min-entropy which indicates
“Acceptance” or “Rejection”. Suppose this classiﬁed docu-
ment is stored in a cloud storage, which supports block-level
cross-user deduplication. Then the adversary could recover
the 1 bit unknown information in the ﬁrst page, through the
block-level deduplication5. This is because: (1) deduplica-
tion inevitably provides adversaries a way to do brute force
search for unknown information, and (2) block-level dedu-
plication that divides a ﬁle into blocks and applies dedupli-
cation on each block, will isolate min-entropy of each block,
and allow adversaries to do brute force search in a much
smaller search space. It is not unusual that a ﬁle with high
min-entropy contains some part, which has very low min-
entropy compared to its bit-length. Deterministic encryption
scheme also need resolve this issue [26]. We emphasize that
block-level cross-user client-side deduplication should not
be applied over sensitive ﬁles.
Very recently, Ng et al. [28] proposed a scheme, which
aimed to support PoW over encrypted data. However, their
work [28] did not address the above issue and consequently
is secure only if every block of the ﬁle of interest has suf-
ﬁcient min-entropy. We will discuss this work later in the
related work section.
1.1.4 Poison Attack
When a ﬁle F is encrypted on client side with randomly cho-
sen encryption key, the cloud server may not be able to verify
consistency between the ciphertext and meta-data of ﬁle F
5 Users can ﬁnd whether deduplication occurs by timing the uploading time
or monitoring communication packet between the cloud client software and
cloud server, or develop a custom cloud client software using public API.
Here we assume each block contains only one page.
uploaded by a user. For example, given a tuple (HF , CF ),
the cloud server is unable to verify whether there exists a
ﬁle F and an encryption key k such that HF = hash(F )
and CF = Enck(F ). A malicious user may substitute the
valid ciphertext CF with an equal size poisoned ﬁle before
uploading it to the cloud. Suppose a subsequent user Carol
tries to upload the same ﬁle F to the cloud. She will be told
that F is already in cloud and uploading of F is saved. She
may delete her local copy of F to save local storage, and will
retrieve ﬁle F from the cloud when required in the future.
However, what she can retrieve from the cloud is a poisoned
ﬁle—her ﬁle F is lost! This attack is also known as Target
Collision attack [36]. We remark that this attack does not re-
quire to ﬁnd a collision of the underlying hash function, and
could be practical if the client-side deduplication over en-
crypted data is not properly implemented. For example, the
“hash-as-a-proof” method suffers from such poison attack,
if the cloud server does not verify the hash computation in
order to save computation burden.
1.1.5 Plausible Approaches
Convergent Encryption. Intuitively, convergent encryp-
tion [14, 15] together with PoW might provide a solution for
client-side deduplication of encrypted ﬁles: Encrypt ﬁle F to
generate ciphertext CF with hash value hash(F ) as encryp-
tion key and then apply PoW scheme over CF . Indeed, cloud
storage service provider Wuala adopts convergent encryp-
tion to encrypt users ﬁles on client side and supports cross-
user deduplication. However, the threat models of PoW and
convergent encryption are incompatible. In the setting of
PoW where a bounded amount of efﬁciently-extractable in-
formation about the ﬁle F can be leaked, convergent en-
cryption is insecure, since its short encryption key is gen-
erated from the input ﬁle in a deterministic way and could
be leaked. Roughly speaking, convergent encryption is as
insecure as “hash-as-a-proof” method (i.e using hash value
hash(F ) as a proof of ownership of ﬁle F ), in the presence
of leakage. Therefore, all existing works on applying con-
vergent encryption method to implement deduplication of
encrypted data (e.g. [3, 24, 36]) are insecure in the bounded
leakage setting.
Per-User Encryption Key. Another approach is that each
cloud user chooses his/her own per-user encryption key, and
all ﬁles uploaded to the cloud by the same user will be de-
terministically encrypted under this user’s encryption key. If
a single user uploads the same ﬁle more than once to the
cloud, the subsequent upload will be saved. This approach
only allows deduplication of ﬁles that belong to the same
user, which will severely whittle down the effect of dedupli-
cation. In this paper, we are interested in the deduplication
cross different users, that is, identical duplicated ﬁles from
different uses will be detected and removed safely.
1.1.6 Current states of various Cloud Storage Services
We collect some technique information about various cloud
storage services (Dropbox, SpiderOak 6 and Wuala) in Ta-
ble 1. All information comes from public ofﬁcial blogs,
white papers, private communication with these cloud stor-
age service providers, or through simple experiments with
their public service. We notice that Microsoft SkyDrive and
Google Drive do not provide client-side deduplication func-
tion, even within a single user account. We conjecture that
all cloud storage service with simple web access support (i.e.
without requiring special browser plug-in) either do not en-
crypt users’ data or encrypt users’ data on server side only.