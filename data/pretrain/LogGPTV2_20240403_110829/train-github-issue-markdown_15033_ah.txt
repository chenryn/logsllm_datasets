    14:53:07 Feb 29 14:53:06.834: INFO: kube-proxy-gke-jenkins-e2e-f1ec7fe0-node-l2sf started at  (0 container statuses recorded)
    14:53:07 Feb 29 14:53:06.834: INFO: nginx-controller-uub6h started at  (0 container statuses recorded)
    14:53:07 Feb 29 14:53:06.834: INFO: mutability-test-0u77q started at  (0 container statuses recorded)
    14:53:07 W0229 14:53:07.022426   14313 request.go:627] Throttling request took 186.69363ms, request: https://104.197.114.165/api/v1/proxy/nodes/gke-jenkins-e2e-f1ec7fe0-node-l2sf:10250/metrics
    14:53:07 Feb 29 14:53:07.136: INFO: ERROR kubelet_docker_errors{operation_type="info"} => 1 @[0]
    14:53:07 Feb 29 14:53:07.137: INFO: ERROR kubelet_docker_errors{operation_type="inspect_image"} => 47 @[0]
    14:53:07 Feb 29 14:53:07.137: INFO: ERROR kubelet_docker_errors{operation_type="list_containers"} => 65 @[0]
    14:53:07 Feb 29 14:53:07.137: INFO: ERROR kubelet_docker_errors{operation_type="list_images"} => 15 @[0]
    14:53:07 Feb 29 14:53:07.137: INFO: ERROR kubelet_docker_errors{operation_type="pull_image"} => 24 @[0]
    14:53:07 Feb 29 14:53:07.137: INFO: ERROR kubelet_docker_errors{operation_type="stop_container"} => 35 @[0]
    14:53:07 Feb 29 14:53:07.137: INFO: ERROR kubelet_docker_errors{operation_type="version"} => 54 @[0]
    14:53:07 Feb 29 14:53:07.137: INFO: 
    14:53:07 Latency metrics for node gke-jenkins-e2e-f1ec7fe0-node-l2sf
    14:53:07 Feb 29 14:53:07.137: INFO: {Operation: Method:pod_start_latency_microseconds Quantile:0.99 Latency:3m40.295878s}
    14:53:07 Feb 29 14:53:07.137: INFO: {Operation:create Method:pod_worker_latency_microseconds Quantile:0.99 Latency:55.520147s}
    14:53:07 Feb 29 14:53:07.137: INFO: {Operation:SyncPod Method:container_manager_latency_microseconds Quantile:0.99 Latency:55.43854s}
    14:53:07 Feb 29 14:53:07.137: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.99 Latency:53.258439s}
    14:53:07 Feb 29 14:53:07.137: INFO: {Operation:create Method:pod_worker_latency_microseconds Quantile:0.9 Latency:46.526966s}
    14:53:07 Feb 29 14:53:07.137: INFO: {Operation: Method:pod_start_latency_microseconds Quantile:0.9 Latency:38.751172s}
    14:53:07 Feb 29 14:53:07.137: INFO: {Operation:update Method:pod_worker_latency_microseconds Quantile:0.99 Latency:30.51282s}
    14:53:07 Feb 29 14:53:07.137: INFO: {Operation:stop_container Method:docker_operations_latency_microseconds Quantile:0.99 Latency:30.13602s}
    14:53:07 Feb 29 14:53:07.137: INFO: {Operation:pull_image Method:docker_operations_latency_microseconds Quantile:0.99 Latency:28.482251s}
    14:53:07 Feb 29 14:53:07.137: INFO: {Operation:SyncPod Method:container_manager_latency_microseconds Quantile:0.9 Latency:28.406635s}
    14:53:07 Feb 29 14:53:07.137: INFO: {Operation:pull_image Method:docker_operations_latency_microseconds Quantile:0.9 Latency:11.708849s}
    14:53:07 Feb 29 14:53:07.137: INFO: {Operation:sync Method:pod_worker_latency_microseconds Quantile:0.9 Latency:11.355813s}
    14:53:07 Feb 29 14:53:07.137: INFO: Waiting up to 1m0s for all nodes to be ready
    14:53:07 W0229 14:53:07.222367   14313 request.go:627] Throttling request took 85.009715ms, request: https://104.197.114.165/api/v1/nodes
    14:53:07 STEP: Destroying namespace "e2e-tests-deployment-1groa" for this suite.
    14:53:07 W0229 14:53:07.422390   14313 request.go:627] Throttling request took 192.807145ms, request: https://104.197.114.165/api/v1/namespaces/e2e-tests-deployment-1groa
    14:53:07 W0229 14:53:07.622370   14313 request.go:627] Throttling request took 193.305092ms, request: https://104.197.114.165/api/v1/namespaces/e2e-tests-deployment-1groa
    14:53:07 W0229 14:53:07.822382   14313 request.go:627] Throttling request took 198.041997ms, request: https://104.197.114.165/api/v1/namespaces/e2e-tests-deployment-1groa/pods
    14:53:07 
    14:53:07 
    14:53:07 â€¢ Failure [474.984 seconds]
    14:53:07 Deployment
    14:53:07 /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/deployment.go:72
    14:53:07   RollingUpdateDeployment should delete old pods and create new ones [It]
    14:53:07   /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/deployment.go:47
    14:53:08 
    14:53:08   Expected error:
    14:53:08       : {
    14:53:08           s: "failed to wait for pods running: [gave up waiting for pod 'nginx-controller-hpovs' to be 'running' after 5m0s]",
    14:53:08       }
    14:53:08       failed to wait for pods running: [gave up waiting for pod 'nginx-controller-hpovs' to be 'running' after 5m0s]
    14:53:08   not to have occurred
    14:53:08 
    14:53:08   /go/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/deployment.go:264
    14:53:08 ------------------------------
This appears to be a different error then the one tracked in issue #21753,
hence I'm opening a separate issue to track it. Feel free to resolve as
duplicate if that is not the case.
Assigning to @bgrant0607 for triage