o
T
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
MySQL
BlindSeer
MySQL
BlindSeer
)
s
c
e
s
(
e
m
i
t
y
r
e
u
q
l
a
t
o
T
300
250
200
150
100
50
0
int−id
single
int−star
single
str−id
single
str−star
single
int−id
2−10
int−star
2−10
str−id
2−10
str−star
2−10
0
1000
2000
Number of results
3000
4000
5000
Figure 5. Comparison with MySQL for single-term queries that have a single
result (ﬁrst four bar groups) and 2 to 10 results (last four bar groups). The
search terms are either strings (str) or integers (int) and the returned result is
either the id or the whole record (star).
Figure 6. Comparison of the scaling factor with respect to the result set
size, using single-term queries. Both MySQL and Blind Seer scale linearly,
however, Blind Seer’s constant factor is 15× worse (mostly due to increased
network communication).
what the performance cost of providing private search is. We
then generalize the performance expectations of our system by
performing a theoretical analysis based on the type of queries.
Dataset. The dataset we use in all of our tests for the ﬁrst
part of the evaluation is a generated dataset using learned
probability distributions from the US census data and text
excerpts from “The Call of the Wild”, by Jack London. Each
record in our generated database contains personal information
generated with similar distributions to the census. It also
contains a globally unique ID, four ﬁelds of random text
excerpts ranging from 10 − 2000 bytes from “The Call of the
Wild”, and a “ﬁngerprint” payload of random data ranging
from 50000 to 90000 bytes. The payload is neither searchable
nor compressible, and is included to emulate reasonable data
transfer costs for real-world database applications. The census
data ﬁelds are used to enable various types of single-term
queries such as term matching and range queries, and the text
excerpts for keyword search queries.
Testbed. Our tests were run on a four-computer testbed
that Lincoln Labs set up and programmed for the purpose
of testing our system and comparing it to MySQL. Each
server was conﬁgured with two Intel Xeon 2.66 Ghz X5650
processors, 96GB RAM (12x8 GB, 1066 MHz, Dual Ranked
LV RDIMMs), and an embedded Broadcom 1GB Ethernet
NICS with TOE. Two servers were equipped with a 50TB
RAID5 array, and one with a 20TB array. These were used
to run the owner and index server. MySQL was conﬁgured
to build separate indices for each ﬁeld. DB queries were not
known in advance for MySQL or for our system.
A. Querying Performance
Single term queries with a small result set. Figure 5
shows a comparison of single term queries against MySQL.
We expect the run time for both our system and MySQL to
depend primarily on the number of results returned. The ﬁrst
four pairs show average and standard deviation for query time
on queries with exactly one result in the entire database, and
the latter four for queries with a few (2-10) results. Queries
are further grouped into those which are run on integer ﬁelds
(int) and string ﬁelds (str), and those which return only record
ids (id) and those which return full record content (star). For
each group, we executed 200 different queries to avoid caching
effects in MySQL.
As we can see, for single result set queries, our system
is very consistent. Unlike with MySQL, the type of query
has no effect on performance, since all
types are stored
and queried the same way in the underlying Bloom ﬁlter
representation. Also, the average time is dominated by the
average number of results, which is slightly larger for integer
terms. Unexpectedly, there is also no performance difference
for returning record ids versus full records. This is likely
because for a single record, the performance is dominated
by other factors like circuit evaluation, tree traversal and key
handling, rather than record transfer time. Overall, aside from
some bad-case scenarios, we are generally less than 2× slower.
Variation in performance of our system is much larger when
returning a few results. This is because the amount of tree
traversal that occurs depends on how much branching must
occur. This differs from single result set queries, where each
tree traversal is a single path. With the larger result sets, we
can also begin to see increased query time for full records as
opposed to record ids, although it remains a small portion of
the overall run time.
Scaling with result set size. Figure 6 expands on both
systems’ performance scaling with the number of results
returned. This experiment is also run with single term queries,
but on a larger range of return result set sizes. As one would
expect, the growth is fairly linear for both systems, although
our constant factor is almost 15× worse. This indicates that for
queries with a small result set, the run time is dominated by
additive constant factors like connection setup for which we
are not much slower than MySQL. However, the multiplicative
constant factors involved in our interactive protocol are much
larger, and grow to dominate run time for longer running
queries. This overhead is mostly due to increased network
communication because of the interactiveness of the search
368
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:00:22 UTC from IEEE Xplore.  Restrictions apply. 
MySQL
BlindSeer
1000
)
c
e
s
(
e
m
i
t
y
r
e
u
q
l
a
t
o
T
100
10
1
0
andï1ï1
andï1ï100
andï1ï10K
dnfïmon
dnfïneg
Figure 7. Boolean queries having a few results (< 10). The ﬁrst three are
two-term AND queries where one of the terms has a single result and the
other varies from 1 to 10K results. The fourth group includes monotonic DNF
queries with 4-9 terms, the last includes 5-term DNF queries with negations.
protocol. Although this is inherent, we believe that there is
room for implementation optimizations that could lower this
constant factor.
Boolean queries. Figure 7 shows our performance on various
Boolean queries. The ﬁrst three groups show average query
time for 2-term AND queries. In each case, one term occurs
only once in the database, resulting in the overall Boolean
AND having only one match in the database. However, the
second term increases up to 10000 results in the database.
As we can see, our query performance does not suffer; as
long as at least one term in a Boolean is infrequent we will
perform well. The next two groups are more complex Boolean
queries issued in disjunctive normal form, the latter including
negations. The ﬁrst one includes queries with 4-9 terms, and
the second one, with 5 terms. These incur a larger cost, as
the number of a results is larger and possibly a bigger part
of the tree is explored. As we can see, MySQL incurs a
proportionally similar cost.
We note that the relatively large variation shown in the graph
is due to the different queries used in our test. Variation is
much smaller when we run the same query multiple times.
Parallelization. We have implemented a basic form of
parallelization in our system, which enables it
to execute
multiple queries concurrently. As there are no critical sections
or concurrent modiﬁcations of shared data structures during
querying, we saw the expected linear speedup when issuing
many queries up to a point where the CPU might not be
the bottleneck anymore. In our 16-core system, we achieved
approximately factor 6x improvement due to this crude paral-
lelization.
Discussion. We note several observations on our system,
performance, bottlenecks, etc.
Firstly, we note that our experiments are run on a fast local
network. A natural question is how this would be translated
into the higher-latency lower bandwidth setting. Firstly, there
will be performance degradation proportional to bandwidth
reduction, with the following exception. We could use the
slightly more computationally-expensive, but much less com-
munication intensive GESS protocol of [34] or its recent
extension sliced-GESS [35], instead of Yao’s GC. In reduced-
bandwidth settings, where bandwidth is the bottleneck, sliced-
GESS is about 3x more efﬁcient than most efﬁcient Yao’s
GC. Further, we can easily scale up parallelization factor to
mitigate latency increases. Looking at this in a contrapositive
manner,
improving network bandwidth and latency would
make CPU the bottleneck.
All search structures in our system are RAM-resident. Only
the record payloads are stored on disk. Thus, disk should not
be a bottleneck in natural scenarios.
B. Other Operations
Although querying is the main operation of our system, we
also include some results of other operations. First, we start
with the performance of the setup phase (preprocessing). Blind
Seer took roughly two days to index and encrypt the 10TB
data. As mentioned before, this phase is executed in parallel
and is computationally efﬁcient enough to be IO-bounded in
our testbed. We note that the corresponding setup of MySQL
took even longer.
Policy enforcement was another feature for which we
wanted to measure overhead. However, in our current imple-
mentation, it cannot be disabled (instead, we use a dummy
policy). We experimentally measured the overhead of enforc-
ing the dummy policy versus more complex ones, but there
was no noticeable difference. We plan to add the functionality
to totally disable policy enforcement – because it is an optional
feature – and measure its true performance overhead. Our
expectation is that it will be minimal.
Finally, we performed several measurements for the sup-
ported modiﬁcation commands: insert, update and delete. All
of them execute in constant time in the order of a few hundred
microseconds. The more expensive part though is the periodic
re-indexing of the data that merges the temporary Bloom ﬁlter
list in the tree (see Section V-C). In our current prototype,
we estimated this procedure to take around 17 minutes, while
avoiding re-reading the entire database. This can be achieved
by letting the server store some intermediate indexing data
during the initial setup and reusing it later when constructing
the Bloom ﬁlter tree.
C. Theoretical Performance Analysis
In this section, we discuss the system performance for various
queries by analyzing the number of visited nodes in the search
tree. Let α1, . . . , αk be k single term queries, and for each
i ∈ [k], let ri be the number of returned records for the query
αi, and n be the total number of records.
OR queries. Our system shows great performance with OR
queries. In particular, consider a query α1 ∨ ··· ∨ αk. The
number of visited nodes in the search tree is at most r log10 n,
where r = r1 + . . . + rk is the number of returned records.
Therefore, performance scales with the size of the result set,
just like single term queries.
AND queries. The performance depends on the best con-
stituent term. For the AND query α1∧···∧αk, the number of
369
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:00:22 UTC from IEEE Xplore.  Restrictions apply. 
visited nodes in the search tree is at most min(r1, . . . , rk) ·
log10 n. Note that the actual number of returned records may
be much smaller than ris. In the worst case, it may even be
0; consider a database where a half of the records contain α
(but not β) and the other half β (but not α). The running
time for the query α∧β in this case will probably be linear
in n. However, we stress that this seems to be inherent, even
without any security. Indeed, without setting up an index, every
algorithm currently known runs in linear time to process this