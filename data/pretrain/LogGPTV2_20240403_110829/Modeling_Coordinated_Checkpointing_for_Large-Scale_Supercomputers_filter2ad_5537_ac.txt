Correlated failures due to error propagation. When an 
independent failure occurs in the system, with some probabil-
ity pe there is a conditional probability of a second failure due 
to the first. This results in an increased failure rate. We com-
pute this failure rate increase for all nodes by multiplying the 
independent  failure  rate  with  a  constant  parameter  called 
frate_correlated_factor.
Figure  3  shows  the  birth-death  Markov  process  of  corre-
lated  failures  due  to  error  propagation.  (cid:540)i and  (cid:540)c denote  the 
rates of the system-wide independent failures and successive 
correlated  failures,  respectively.  (cid:540) is  the  independent  failure 
rate of a single node. µ denotes the recovery rate of the sys-
tem.  Fi is  the  system  state  in  which  i  failures  have  occurred 
before  a  successful  recovery  (three  states,  F0,  F1 and  F2, are
shown as examples in Figure 3). As we assume that any suc-
cessful  recovery  wipes  off  all  latent  errors,  all  the  Fi  states 
transit directly to F0 with the recovery rate. It is also assumed 
that  the  failure  rates  at  all  the  Fi  states  (i  >  0)  are  the  same. 
So,  the  conditional  probability  of  another  failure  occurrence 
provided that a failure occurs is, 
p= (cid:540)c/( (cid:540)c +µ)    =>    (cid:540)c=pµ/(1-p).
Let n denote the number of nodes, and r denote the multi-
ple frate_correlated_factor. Then according to the model, 
(cid:540)c=(cid:540)i+rn(cid:540)=n(cid:540)(1+r)    =>    r=pµ/((1-p)n(cid:540))-1. 
(cid:540)
r, 
For 
a  given 
and  µ, 
set  of  n,
i.e. 
frate_correlated_factor,  actually  represents  the  conditional 
probability p. As long as (cid:540)c>(cid:540)i, r can be chosen independently 
to  study  a  range  of  correlated  failure  effects.  For  example, 
when  n=1024, p=0.3,  MTTR=10min,  and  MTTF=25yrs,  r  is
about 600. 
(cid:540)i
µ
F0
(cid:540)c
(cid:540)c
F1
µ
F2
µ
Figure 3: Birth-death Markov process of correlated failures 
Failure rate of the entire system 
(cid:540)s 
(cid:540)si  Rate of independent failures in the system 
(cid:540)sc  Rate of correlated failures in the system 
(cid:540) 
r 
(cid:545) 
n 
Independent failure per node 
Increased failure rate due to correlated failures 
Correlated failure coefficient 
Number of nodes 
7. Experimental Setup and Results 
We  use  the  Mobius  modeling  environment  [21]  to  create 
and  simulate  the  SANs.  Steady-state  simulation  is  used  with 
an  initial  transient  period  of  1000  hours  to  allow  the  system 
to enter the steady state. The confidence level is 95%. Unless 
otherwise  specified,  the  parameter  values  are  as  in  Table  3. 
These  parameters  are  based  on  field  data  or  projections  of 
future systems. 
As  the  modeled  system  is  complicated  and  multiple 
mechanisms/parameters  are  present,  we  study  the  system  by 
analyzing the effect of one feature at a time. Hence, the base 
model  without  coordination  or  correlated  failures  (but  with 
failures during checkpointing and recovery) is first studied to 
understand the basic system behavior. Then we study the ef-
fects  of  coordination  and  correlated  failures.  The  following 
two metrics are used to evaluate system performance.   
• Useful work fraction: Fraction of time the system makes 
forward  progress  towards  the  completion  of  the  job.  It  does 
not include work that is repeated due to failures. 
• Total useful work: The product of the useful work frac-
tion and the number of compute processors. It indicates how 
many processors of the same kind are required to achieve the 
same performance, assuming failure-free computation. 
7.1 Study of Base Model 
For  the  base  model,  we  assume  independent  failures  and 
consider the coordination time to be a fixed quiesce time. The 
system  performance  is  analyzed  for  a  range  of  parameters, 
including  the  number  of  processors,  checkpoint  interval, 
MTTF per node, and MTTR of the system, as follows:   
• Number of processors per node: 8 
• MTTF per node: 1 year 
• MTTR of the system: 10 minutes2
• Number of processors: 64K 
• Checkpoint interval: varied from 15 minutes to 4 hours 
2 If permanent failures are considered, the overhead of the system 
reconfiguration will result in a larger MTTR. 
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Table 3: Model Parameters
Parameter 
Checkpoint interval 
MTTF (Mean Time 
To Failure per node) 
Value 
/Range 
15 min to 
4 hr 
1 – 25 yr 
MTTR (sys-
tem-wide Mean 
Time To Recovery 
of compute nodes) 
MTTR of IO nodes 
Number of compute 
processors 
MTTQ (per-node 
Mean Time to Qui-
esce) 
Broadcast overhead 
Software overhead 
for transmission 
Period of I/O – 
compute cycle in 
application 
Fraction of compu-
tation 
Timeout value 
Probability of   
correlated failure 
Correlated failure 
rate 
Correlated failure 
window 
10 min 
1 min 
8K to 
256K 
0.5-10 s 
1 ms 
1 ms 
3 min 
0.88 – 1.0 
20 sec to 
2 min 
0 to 0.2 
1/MTTF* 
(100~160
0)   
3 min 
System reboot time 
1 hr 
Aggregate band-
width between 
compute nodes and 
one I/O node 
Number of compute 
nodes per I/O node 
File system band-
width per I/O node 
Checkpoint size per 
node 
Average size of I/O 
data per node 
350 MBps 
64
1 Gbps 
256 MB 
10 MB 
Comments 
Derived from other studies [1], and 
private communication with vendors 
Including software and hardware fail-
ures recovered from checkpoint. 1 year 
for ASCI Q and 25 years for IBM 
mainframes 
Average time for all compute nodes to 
read checkpoint and reinitialize them-
selves 
Time to restart the I/O nodes 
Projection of current and future super-
computers 
Time to close I/O and network file 
handles, clean up states, and perform 
computation until reaching a safe point 
E.g. data for hardware broadcast trees 
in Blue-Gene/L [1] 
Measurement of message latency in 
TCP/IP and UDP 
Experimental data on I/O characteris-
tics of parallel applications [15] 
Experimental data on I/O characteris-
tics of parallel applications [1] 
The period for the master to timeout 
and cancel the checkpointing 
Experimental data on correlated fail-
ures, e.g., [6 ] 
Projections on error propagation within 
a locally-federated cluster of nodes in 
the supercomputer 
Experimental data for persistence of 
correlated failures in the system due to 
error propagation 
Anecdotal evidence for startup time of 
a large cluster 
E.g., Blue-Gene/L field data [1] 
Experimental data on typical charac-
teristics of parallel applications [15] 
We  report  results  for  the  number  of  processors,  not  the 
number  of  nodes,  so  that  they  can  be  easily  scaled  to  a  dif-
ferent number of processors per node. The major results are: 
(cid:151) For  a  given  checkpoint  interval  (30  min),  MTTR  (10 
min), and MTTF (1 yr per node), there is an optimum number 
of processors (128 K) for which total useful work done by the 
system  is  maximized.  Adding  more  processors  than  this  op-
timum  value  will  hurt  system  performance  due  to  failure  ef-
fects3.  The  range  of  processors  considered  in  this  analysis  is 
from  8K  to  256K,  and  the  optimum  value  of  the  number  of 
processors  varies  from  128K  to  32K  as  the  MTTR  varies 
from 10 minutes to 80 minutes. 
3  Elnozahy  et  al.  [11]  also  make  a  conjecture  that  increasing  the 
number of nodes beyond a certain extent hurts performance, but they 
do not quantify the extent of the performance loss.
(cid:151) For  the  system  to  be  scalable,  checkpoints  should  be 
taken  on  the  granularity  of  minutes  (15-30  min),  rather  than 
hours, as is the current practice [26]. While in theory there is 
an  optimal  checkpoint  interval,  for  any  practical  range  there 
is no optimal checkpoint interval for which the useful work is 
maximized,  contrary  to  what  several  other  studies  have 
shown [7, 8]. This is because the overhead of checkpointing 
is  relatively  low  in  our  system,  as  the  checkpoint  writing  is 
done in the background, and  the effect of failures dominates 
the effect of taking checkpoints frequently.   
(cid:151) Even  when  the  useful  work  is  maximized,  the  overall 
useful  work  fraction  is  no  more  than  50%  for  an  MTTF  per 
node  of  1  year.  Hence,  more  than  50%  of  system  resources 
are spent in checkpointing and recovering from failure. 
(cid:151) If the number of processors per node is increased to 32 
from  8  and  the  per-node  MTTF  is  maintained  the  same  as  1 
year,  it  is  possible  to  increase  the  total  useful  work  for  the 
same number of nodes. This is because more compute power 
is provided per node, while maintaining the same failure rate. 
The optimum  number of processors is in the range of 500K. 
However, the useful work fraction is unaltered, as the system 
failure rate, which depends only on the number of nodes and 
the per-node failure rate, is the same. 
Variation  of  total  useful  work  with  number  of  proces-
sors.  Figure  4a,  c,  and  e  show  the  variation  of  total  useful 
work  with  different  number  of  processors.  In  all  the  three 
figures,  there  is  an  optimum  value  of  the  number  of  proces-
sors for which total useful work is maximized. The rationale 
behind this is as follows: On one hand, more processors pro-
vide higher computing power for the job; on the other hand, 
more processors incur more frequent failures and hence more 
computation  is  wasted  due  to  failures.  For  small  numbers  of 
processors, the former factor dominates, while for sufficiently 
large numbers of processors, the latter outweighs the former. 
Consider how the optimum number of processors varies with 
the MTTF, MTTR, and checkpoint interval.   
• The optimum value decreases with smaller MTTFs, as 
shown in Figure 4a (from 128K processors for an MTTF of 1 
year  per  node  to  64K  processors  for  an  MTTF  of  0.5  years 
per node).   
• The  optimum  value  decreases  with  larger  MTTRs 
(from  128K  processors  for  an  MTTR  of  20  minutes  to  64K 
processors for an MTTR of 40 minutes), as shown in Figure 
4c.
• The  optimum  value  decreases  with  larger  checkpoint 
intervals, as shown in Figure 4e (from 128K processors for a 
checkpoint  interval  of  30  minutes  to  64K  processors  for  a 
checkpoint interval of 60 minutes).   
This  is  because,  smaller  MTTFs  increase  the  failure  rate, 
larger MTTRs increase the penalty of a failure, and the larger 
checkpoint intervals cause  more  work to be  lost  upon a  fail-
ure.  All  the  three  aggravate  the  effects  of  failures,  thus  low-
ering the equilibrium point between the computing power and 
the failure effect.   
Variation of total useful work with checkpoint intervals. 
Figure 4b, d, and f show the variation of total useful work for 
different  checkpoint  intervals.  The  results  indicate  that  for  a 
large-scale supercomputing system there is no optimum value 
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
of the checkpoint interval  within  the range of  values consid-
ered (15 minutes to 4 hours). This contradicts previous stud-
ies  [7,  8],  which  have  shown  the  existence  of  an  optimum 
value  of  the  checkpoint  interval.  This  is  because  the  loss  of 
job  computation  due  to  failures  in  large-scale  systems  out-
weighs  the  overhead  of  frequent  checkpointing,  as  our 
checkpoint  overhead  is  low.  The  theoretical  optimum  value 
of  the  checkpointing  interval  is  less  than  15  minutes.  How-
ever,  checkpoint  intervals  less  than  15  minutes  are  not  con-
sidered  because  checkpoints  as  frequent  as  that  may  over-
whelm  the  I/O  subsystem  and  network  and  hence  are  not 
practical.
Useful Work Vs Number of Processors for 
different MTTFs   (MTTR = 10 mins hrs, 
checkpoint interval = 30 mins)
Useful Work Vs Checkpoint Interval for different 
numbers of processors  (MTTF per node=1 yrs, 
MTTR = 10 mins)
k
r
o
W
l
u
f
e
s
U
l
a
t
o
T
120000
100000
80000
60000
40000
20000
0
81 92
16 384
32 768
65 536
13 1072
26 2144
Number of Processors
 MTTF (yrs) =  0.125
 MTTF (yrs) =  0.5
 MTTF (yrs) =  2
 MTTF (yrs) =  0.25
 MTTF (yrs) =  1
(a)
 Useful Work Vs Number of Processors for 
different MTTRs  (MTTF per node =1 yr , 
chkpt_interval=30 mins)
k
r
o
W
l
u
f
e
s
U