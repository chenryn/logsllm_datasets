𝐾 different rules (in the first
FSM) at most for the same feedback state (in the second FSM), to
ensure that the expectation of query accuracy rate is 100%.
Proof of Corollary 1. According to Theorem 2, the expectation
of query accuracy rate is 100% if |𝑅| 2,000 FPs when using the modified version of Kitsune. In
contrast to 79 FPs (recall in Figure 8), we confirm the occurrence of
concept drift. In Figure 9, we choose 1,000 FPs to put into Distiller
for concept drift detection, and use another 1,000 FPs for testing.
C.4 Evaluation Metrics
We introduce the definition of metrics for the evaluation of Distiller
omitted in the main body, including f1-micro/f1-macro/UACC in
§6.5 and TPR/FPR in §6.6. The detection performance of binary
classification tasks can be measured by firstly counting its true
positives (TP), true negatives (TN), false positives (FP), and false
negatives (FN). In this context, we can define the evaluation metrics:
𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 =
, TPR = 𝑅𝑒𝑐𝑎𝑙𝑙 =
FPR =
𝑇 𝑃
𝐹 𝑃
𝑇 𝑃 + 𝐹 𝑃
𝐹 𝑃 + 𝑇 𝑁
F1-Score =
𝑇 𝑃
𝑇 𝑃 + 𝑇 𝑁
𝑇 𝑃 + 𝐹 𝑁
,
𝑇 𝑃 + 𝐹 𝑁 + 𝑇 𝑁 + 𝐹 𝑃
,
, ACC =
2 × 𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 × 𝑅𝑒𝑐𝑎𝑙𝑙
𝑃𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 + 𝑅𝑒𝑐𝑎𝑙𝑙
.
UACC is just ACC of treating the unknown class as positive. As
for f1-micro/f1-macro, they are f1-score for multi-class evaluation.
Specifically, f1-micro calculates metrics globally by counting the
total TP, FN, and FP, while f1-macro calculates metrics for each
label, and finds their unweighted mean.
D ADVERSARIAL ROBUSTNESS OF
INTERPRETER
Below, we provide details of adaptive attacks for adversarial ro-
bustness evaluation of the Interpreter in §6.2. We show the strong
adversarial robustness of DeepAID and analyze the reasons. As
mentioned in §6.2, we evaluate two types of adversarial attacks,
including optimization-based attack and distance-based attacks.
D.1 Robustness against optimization-based
attack
Attack Methodology. As mentioned in §6.2, we borrow the ideas
from existing adversarial attacks against B.P. based interpreters
[18, 60] to develop the following adaptive attack on DeepAID:
argmax ˜𝒙◦∥D𝑡𝑎𝑏( ˜𝒙◦; ˜𝒙◦) − D𝑡𝑎𝑏(𝒙◦; 𝒙◦)∥𝑝 s.t. ∥ ˜𝒙◦ − 𝒙◦∥𝑝 < 𝛿𝑎,
(16)
where D𝑡𝑎𝑏 is the objective function of optimization (7). As men-
tioned in §4.2, our Interpreter iteratively optimizes (7) to find a
better reference. However, such iterative optimization is hard for
attackers to gain the overall gradients. From the perspective of
Session 12A: Applications and Privacy of ML CCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea3214attackers, we simplify Interpreter into solving (7) only once. Hence,
the optimization for interpretation is transformed into single-step
gradient descent for D𝑡𝑎𝑏 with the input of anomaly 𝒙◦. Formally,
𝒙∗ ≈ 𝒙◦ − 𝛼∇𝒙◦D𝑡𝑎𝑏(𝒙◦; 𝒙◦). Then, the interpretation result is
𝒙◦ − 𝒙∗ ≈ 𝛼∇𝒙◦D𝑡𝑎𝑏(𝒙◦; 𝒙◦). In this context, the objective func-
tion of optimization-based attack in (16) is transformed into:
argmax ˜𝒙◦∥𝛼∇ ˜𝒙◦D𝑡𝑎𝑏( ˜𝒙◦; ˜𝒙◦) − 𝛼∇𝒙◦D𝑡𝑎𝑏(𝒙◦; 𝒙◦)∥𝑝 .
(17)
Here we set 𝑝 = 2 for simplicity (𝑝 = 1, 2 in [18]). This problem can
be easily solved by gradient-based methods. Like [18], to limit ˜𝒙◦
and 𝒙◦ to be close, we only modify top-K dimensions of ˜𝒙◦ in each
iteration and clip ˜𝒙◦ to make ∥ ˜𝒙◦ − 𝒙◦∥2 < 𝛿𝑎.
Robustness Evaluation and Analysis. The results of DeepAID
Interpreter against optimization-based attack have been shown
in the main body (Figure 5 in §6.2). We conclude that DeepAID
Interpreter is naturally robust against such attacks and becomes
more robust with I.R.N.. In §4.2, we have analyzed the reason why
DeepAID is naturally robust is due to iterative optimization and
search-based idea. And I.R.N. can further improve the robustness