detection: 
33 ms
Noising:  
8 µs
ROI 
detection: 
80 ms
30
25
)
z
H
30
25
20
15F
(
e
t
a
r
e
m
a
r
15
20
Noising Context proc.
(a) Latency breakdown 
of individual modules
4
8
16
1
2
Context update rate (Hz) 
(b) Performance impact with 
varying context update rates
Figure 8: Scores obtained in different conditions.
as a 7-item Likert scale, the game score, and the qualitative
feedback.
After the four randomized settings, the objective of Kaleido
was revealed, and the participants were offered an adjustable
knob to control the tradeoff between privacy and utility. We
asked each participant to interact with the control knob; we
observed how frequently they adjusted the knob and solicited
qualitative feedback about their experience. This part of the
study follows a technology-probe-based approach [36]. Our
objective is to probe the participants to elicit their opinion
about the missing design elements that need to be introduced.
Results. We asked the participants to report their subjective
experience to evaluate the validity of our game’s adaptation.
To this end, we asked each participant to report their level
of agreement (or disagreement) with this statement: “You en-
joyed the game in this session.” on a 7-item Likert scale with
1 being “Strongly Agree” and 7 being “Strongly Disagree”.
Figure 8(a) shows that for all of the game settings, the partici-
pants enjoyed their experience – at least 82% of them reported
a score of 3 or lower.
Next, we study the effect of the privacy level on the partic-
ipants’ game scores. Figure 8(b) shows these scores for the
different settings. We observe that the game scores decrease
with a stronger privacy guarantee. However, the decrease in
the score is not signiﬁcant from the no privacy (NOPV) set-
ting to the low privacy (LPHU) setting (only 3.2%). Even the
decrease from the NOPV setting to the high privacy (HPLU)
setting is modest (12.0%). These results show that Kaleido’s
noise does not adversely affect users’ utility in this scenario.
The qualitative feedback that we obtained from the users
aligned with our quantitative observations. Some participants
were unable to distinguish between the LPHU and NOPV
settings – (P8: “The second (NOPV) and third (LPHU) conﬁgurations
are almost the same for me.”) The majority of the participants
found the highest privacy (HPLU) setting to be the hardest to
control. Some participants had a surprisingly different view.
For example, P7 enjoyed the conditions with higher noise
because it was more challenging to play.
Finally, we performed a preliminary analysis of the privacy
control knob (setting: CNTL). In the last task of the study,
we introduced the control knob to the participants and asked
them to control the privacy level as per their desired level of
utility. Figure 8(b) shows that the adjustment of the control
Figure 9: Performance breakdown and trend. ROI detection
is the most expensive operation. The frame rate remains rela-
tively steady even for a high context update rate of 8 Hz.
knob does not affect the game scores. However, we ﬁnd a
large variation in the frequency of knob adjustment and the
privacy level (e) across the participants.
The qualitative feedback also indicated that while such a
knob might be useful, they had some suggestions for improve-
ment. For example, P8 and P11 proposed adding ﬂexibility for
an ofﬂine calibration of the privacy level for each application.
Other participants commented that frequently adjusting the
knob during intense gameplay is suboptimal.
7.2 System Performance
We evaluate Kaleido’s real-time performance and measure its
processing delay on a commodity PC with an Intel i7-7700
CPU and Nvidia GTX 1080 GPU. Figure 9 shows the latency
overheads incurred by the three main operations of Kaleido:
noisy gaze generation (noising), keyframe detection, and ROI
detection. We run 100 trials for each of the operations and
report the average running time. The latency of the noising
operation is only 8 µs, and thus, has no discernible impact on
the user’s real-time experience.
ROI detection takes 80 ms on average, but it only runs when
a new keyframe is detected. Based on our ofﬂine game cali-
bration, a new keyframe is detected only every 2.3 s (similar
to the timing from the VR videos dataset). Thus, the overall
impact of ROI detection in Kaleido is not signiﬁcant.
Keyframe detection takes 33 ms on average. The frequency
of keyframe detection (context update rate) is comparatively
higher (2 Hz in our implementation). Figure 9(b) shows its
performance impact on effective frame rates of the game used
in the study. We observe that, even with a high context update
rate of 8 Hz, the frame rate degrades only slightly to 25 Hz.
In this paper, we evaluate a research prototype of Kaleido,
which shows its real-world potential. Nevertheless, to deploy
in scale, Kaleido can leverage various performance optimiza-
tions, such as GPU ofﬂoading, model compression, and re-
source sharing. These optimizations would enable fast context
processing even on resource-constrained platforms.
7.3 Effectiveness Against Attacks
Recall that post-processing operations on the outputs of a DP
algorithm do not result in additional privacy loss (Theorem
3). Thus, Kaleido’s formal DP guarantee for the spatial in-
formation of gaze streams holds for every attacker (even for
one with full knowledge of Kaleido’s protocols). However,
Kaleido does not provide a formal guarantee on the tempo-
ral information of gaze streams (Section 4.3.2). Hence, we
perform a trace-based evaluation to study the effectiveness
of Kaleido against spatio-temporal attacks using the datasets
in Table 1. These attacks exploit the spatio-temporal features
of gaze streams, such as ﬁxation durations and saccade ve-
locity [31, 74]. We select two representative analyses of gaze
streams: (1) similarity and outlier analysis of a scanpath for
an individual, and (2) biometric inferences. We use (1) Multi-
Match [20] for computing the scanpath similarity scores, and
(2) F1 score, which considers both precision and recall, to
measure attackers’ classiﬁcation accuracy.
Note that the attackers considered in this section are knowl-
edgeable; they have complete knowledge of the target visual
scenes and Kaleido’s noise generation protocols. Further, they
use a noise-robust ﬁxation detection [31]. Additionally, all
the classiﬁers used in this section are trained on noisy gaze
streams from Kaleido (for the same privacy conﬁgurations).
7.3.1 Similarity and Outlier Analysis of Scanpath
Given a dataset of gaze streams for single scenes, this attack
constructs a feature vector of the scanpath for each individ-
ual in the dataset. Since the visual stimulus is the same, the
hypothesis is that the differences in the scanpath features
arise from distinguishing psychophysiological traits. Thus,
this type of analysis aims at distinguishing individuals based
on their scanpath features [9].
Setup. We use the image datasets (the ﬁrst three rows of
Table 1: natural, web page, and human) to evaluate the distin-
guishability of the scanpath features on static image frames.
This evaluation assesses the accuracy of the analysis of raw
and noisy gaze streams. For each stream, we extract the scan-
paths using an ofﬂine algorithm [31]. Next, we perform simi-
larity analysis and outlier identiﬁcation as follows.
Similarity analysis. The adversary here has a priori knowl-
edge of a user’s scanpath on a certain image. It attempts to
re-identify the user by measuring the similarity between this
scanpath and a newly observed one formed on the same image.
For each dataset, we compute the similarity between the scan-
paths of the same user, before and after adding noise. We use
the standardized similarity metric, MultiMatch [20], which
ranges from 0 to 1. This score measures scanpath similarity
by considering features about the shape (the length, shape,
and direction of saccade vectors) and the spatial distribution
(position and duration of aligned ﬁxations) of gaze data.
Outlier identiﬁcation. In this attack, the adversary tries to
identify the outlier users whose scanpath features are signif-
w=2 s
w=0.5 s
l
l
a
m
s
y
t
i
r
a
l
i
m
S
i
r
)
a
(
1
1
0.8
0.6
0.6
0.8
e
g
r
a
l
r
)
b
(
y
t
i
r
a
l
i
m
S
i
1
1
0.8
0.6
0.6
0.8
3
3
0.5
1.5
ε
0.5
1.5
ε
Natural
1
1
0.8
0.6
0.6
0.8
1
1
0.8
0.6
0.6
0.8
Inter-subject
3
3
0.5
1.5
ε
0.5
1.5
ε
Web page
1
1
0.8
0.6
0.6
0.8
1
1
0.8
0.6
0.6
0.8
Random scanpath
3
3
0.5
1.5
ε
0.5
1.5
ε
Human
Figure 10: Similarity scores between noisy and raw scan-
paths. Kaleido reduces the similarity scores to be close to
the inter-subject threshold (black lines) even at low privacy
conﬁgurations (rsmall). The scores are reduced further to be
close to the random scanpath baseline (red dash lines) at high
privacy conﬁgurations (e = 0.5, rlarge, and w = 2 s).
icantly different from that of the rest. This attack utilizes a
density-based clustering model DBSCAN [28], where inter-
scanpath distances are computed via dynamic time warping
(DTW) over the scanpaths on a single image. We use the
F1 score to report the attacker’s success in identifying the
outlier users from the dataset containing noisy gaze streams.
We show the F1 scores of outlier identiﬁcation compared to
random guessing as a baseline (“Random guess”).
l
l
a
m
s
1
F
r
)
a
(
e
g
r
a
l
r
)