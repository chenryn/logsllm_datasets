title:CoSMeDis: A Distributed Social Media Platform with Formally Verified
Confidentiality Guarantees
author:Thomas Bauereiß and
Armando Pesenti Gritti and
Andrei Popescu and
Franco Raimondi
2017 IEEE Symposium on Security and Privacy
CoSMeDis: A Distributed Social Media Platform
with Formally Veriﬁed Conﬁdentiality Guarantees
Thomas Bauereiß∗, Armando Pesenti Gritti†, Andrei Popescu‡§, Franco Raimondi‡
∗German Research Center for Artiﬁcial Intelligence (DFKI) Bremen, Germany
†Global NoticeBoard, UK
‡Department of Computer Science, Middlesex University London, UK
§Institute of Mathematics Simion Stoilow of the Romanian Academy
Abstract— We present the design, implementation and in-
formation ﬂow veriﬁcation of CoSMeDis, a distributed social
media platform. The system consists of an arbitrary number
of communicating nodes, deployable at different locations over
the Internet. Its registered users can post content and establish
intra-node and inter-node friendships, used to regulate access
control over the posts. The system’s kernel has been veriﬁed
in the proof assistant Isabelle/HOL and automatically extracted
as Scala code. We formalized a framework for composing a
class of information ﬂow security guarantees in a distributed
system, applicable to input/output automata. We instantiated this
framework to conﬁdentiality properties for CoSMeDis’s sources
of information: posts, friendship requests, and friendship status.
I.
INTRODUCTION
Recent years have seen an explosion of web-based systems
aimed at sharing information between multiple users in a con-
venient, but controlled fashion. Examples include enterprise
systems, social networks, e-commerce sites and cloud services.
These systems often deal with conﬁdential information, such
as credit card details, medical data, location information and
sensitive documents. Unfortunately, most of these systems
offer no guarantees concerning the prevention of unintended
ﬂow of information. Programming errors or ambiguous policy
speciﬁcations leading to information leakage can have different
degrees of severity and can affect many users [2,3].
Such errors are difﬁcult to prevent, or even understand,
because information ﬂow security is a complex, global prop-
erty of a program. The problem is aggravated by the heavy
inter-connectivity of today’s web applications. Sensitive user
information in cloud storage systems, such as Amazon, may
be shared with social media platforms, such as Twitter or
Facebook, and web-based email systems, such as Gmail. While
often the information sharing occurs via intuitively secure
protocols, it is far more difﬁcult to foresee the conﬁdentiality
issues arising synergistically in a network of applications. What
is needed is a solid, mathematically grounded understanding
of how local conﬁdentiality guarantees can be composed to
deliver guarantees for the entire distributed system.
In this paper, we develop such a theory of compositionality
(i.e., the notion of composing local guarantees to form global
guarantees) and apply it to a major case study: a distributed
social media platform. We employ a notion of information
ﬂow security introduced by Kanav et al. [38], called Bounded
Deducibility (BD) Security. The appeal of BD Security for
dealing with web applications rests in its versatile mechanism
for specifying rich security policies, inspired by epistemic
logic. This notion has been formalized in the proof assistant
Isabelle/HOL [53] and then utilized in conﬁdentiality guaran-
tees for two running web applications:
• CoCon [1] (introduced as a case study by the BD Security
authors), a conference management system that has been
deployed for two veriﬁcation-friendly conferences [14,23];
• CoSMed ([7], Section II), a social media platform that we
developed in previous work [12] as a prototype aimed at
eventually serving the functionality and security needs of a
charity organization [6].
The attacker models in these works (Section III) consider an
arbitrary but ﬁxed set of users, called observers, who interact
with the system and from whom secret information should
be protected. It is veriﬁed that the systems do not leak more
information about the secret than speciﬁed by given policies.
In this paper, we design and implement a distributed
version of CoSMed, which we call CoSMeDis, and extend its
formal security guarantees. The extension consists of a com-
munication infrastructure (Section IV), which introduces new
security-critical aspects: (1) the ability to share secrets, namely,
restricted-access post contents, between different nodes and
(2) the ability to dynamically assign secret-sharing roles, by
the designation of friends from remote nodes. The attacker
model is lifted to sets of observing users at each node of the
distributed system. Moreover, we assume that network trafﬁc
between the nodes is also observable, with the exception of
the conﬁdential content of communication. This is in line with
assuming a Dolev-Yao-style network attacker [25], who can
inspect communication without breaking encryption.
After a detailed analysis of how to cope compositionally
with the security of CoSMeDis’s features (Section V), we
formulate a solution in abstract terms: as a framework for com-
posing information ﬂow security guarantees of input/output
(I/O) automata (Section VI). At its heart lies a formal theorem
for composing locally veriﬁed BD Security instances to a
global BD Security property of the entire distributed system.
The theorem is policy-agnostic, in that it composes policies
without restrictions on their content, but requires a unique
source node for each secret.
We instantiate the theorem for extending to CoSMeDis
all the previously established CoSMed guarantees about the
conﬁdentiality of posts and friendship information and to
prove a new guarantee about remote friendship (Section VII).
CoSMeDis is a large piece of formal engineering, integrating
© 2017, Thomas Bauereiß. Under license to IEEE.
DOI 10.1109/SP.2017.24
729
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:28:13 UTC from IEEE Xplore.  Restrictions apply. 
speciﬁcation, code generation and veriﬁcation. We discuss the
scope of our veriﬁcation (Section VIII) and compare our work
with results from the literature (Section IX). The CoSMeDis
homepage [5] has links to the formal proofs, the source code,
documentation, and sample running nodes.
II. THE ORIGINAL COSMED
This section recalls the original CoSMed system. It is a
social media platform loosely inspired by platforms such as
Facebook. It allows users to register and post information
and to restrict access to this information based on friendship
relationships established between users. For example, the user
Alice can log into the web site and browse through posts
made by other users. She can create new posts herself, e.g.,
a comment on a sports event. By default, this post is visible
to her friends only. She can add new friends by looking up
their proﬁle, e.g., the proﬁle of Bob, and requesting friendship
by optionally entering a greeting text and clicking the submit
button. When Bob approves the request, they become friends,
and Bob can now see Alice’s sports comment. Alice can also
edit her posts and set their visibility level—either friends-
only or public—at any time. The system has one user with
special powers, the admin, who is responsible for approving
the creation of users.
A. System Model
State. CoSMed has a mutable state, storing information
on users, posts and friendships. For example: A user ID has
an associated name, email address and info; a post ID has
an associated title, text, image, owner ID and visibility; a
friendship request is identiﬁed by two user IDs (the sender
and the recipient) and has an associated greeting text created
by the sender; the friendship status (“friend” or “not friend”)
is stored as a symmetric association between user IDs.
Actions. Users interact with the system via actions for
creating, deleting, updating and reading items in the system,
where an item can be a user, a post, a friendship request or
a friendship status. There are also actions for listing items
according to various ﬁlters or criteria—e.g., a user can list all
posts, or all posts of a given friend, or all his friends, or all
the friends of a given friend, etc. Each action a also contains
the user ID of its issuer, denoted by userOf(a).
Outputs. When a user requests an action, the system ﬁrst
checks if the action is allowed, in which case the action is
applied and the output is returned to the user; otherwise, an
error message is emitted and the state remains unchanged.
B. Formalization and Implementation
The above behavior is formalized in Isabelle/HOL as an I/O
automaton Aut = (State, Act, Out, σ0, →), where σ0 ∈ State
is the (empty) initial state and → ⊆ State× Act× Out× State
is the transition relation. The inputs of the automaton are
called actions. For example, an action that updates the con-
tent of a post has the form (updatePost, uid, pid, pst). Here,
updatePost is a label indicating the particular type of action,
uid is the ID of the acting user, pid is the ID of the post, and
pst is the new content. σ a−→
σ(cid:6) has the following reading: if
a user takes action a while the system is in state σ, the system
responds producing output o and changing the state to σ(cid:6).
o
A system transition is a tuple trn = (σ, a, o, σ(cid:6)) such that
σ a−→
σ(cid:6) holds. The states σ and σ(cid:6) are called the transition’s
o
source and target. The transition’s action a is also denoted by
actOf(trn). A system trace is a sequence tr = (cid:7)trn1, . . . , trnn(cid:8)
of transitions such that the source of the ﬁrst transition (if
any) is σ0 and the target of each transition is the source of
its successor in the sequence. The end state of a trace tr,
written endState(tr), is the target state of tr’s last transition if
tr is non-empty, and the initial state σ0 otherwise. Note that
a system trace interleaves transitions containing actions from,
and outputs to, different users. We let Trans denote the set of
transitions and Trace the set of traces.
CoSMed’s transition relation is deterministic, and in fact is
represented as an executable function Act× State → State×
Out. This function is automatically extracted into Scala code
using Isabelle’s code generator [32], forming CoSMed’s ker-
nel. Around the extracted code, we implemented manually, in
the Scalatra web framework [61], a layer of web-speciﬁc code
that provides CoSMed’s user interface, invoking kernel actions
in response to user requests [12, §2.2].
III. SECURITY MODEL: BD SECURITY
Previously [12], we proved for CoSMed conﬁdentiality
properties of the form: Only under the circumstances speciﬁed
by a given policy may users learn information on the system’s
documents. Our running example in this paper will be:
(P1) A group of users can learn nothing about the updates to
a post content beyond the existence of an update unless one
of them is the admin or the post’s owner, or becomes friends
with the owner, or the post is marked as public.
Let us analyze what (P1) expresses and how this is formal-
ized. It focuses on the conﬁdentiality of the content of a given
post by a CoSMed user. It does not describe a policy for access
control to this data, but rather a policy for information ﬂow
control. Indeed, it does not state that the post content cannot
be accessed, but something stronger: that information about it
cannot ﬂow. Hence we write “learn” instead of “access.”
∗
The (partial) secret that (P1) refers to is the content of a
particular post, say, stored in the system under the ID PID.
Since the content can be updated by the owner several times,
we need to speak of a sequence of secrets: all the updates to
the content, corresponding to all its versions held in the state
during a system run. Formally, one deﬁnes a domain Sec of
secrets, a ﬁlter isSec : Trans → Bool and a secret-producing
function getSec : Trans → Sec. This yields a function SgetSec
:
Trace → Sec
that extracts a sequence of secrets from a
trace transition-wise, by ﬁltering with isSec and then applying
getSec to each of the trace’s transitions. For example, consider
the trace tr = (cid:7)trn1, trn2, trn3(cid:8) where isSec is only true for
(tr) = (cid:7)getSec(trn1), getSec(trn3)(cid:8).
trn1 and trn3, then SgetSec
isSec
For (P1), Sec is obviously taken to consist of post contents.
Moreover, isSec (σ, a, o, σ(cid:6)) holds if a is a post-update action
for PID, i.e., has the form (updatePost, uid, PID, pst) for some
uid, pst, and the transition is successful, as signaled by an
“OK” output. The function getSec for (P1) extracts the post
content from a: getSec (σ, a, o, σ(cid:6)) = pst.
isSec
The observers (possible attackers) are here a group of users,
say, with their IDs in a ﬁxed (but arbitrary) set UIDs. Formally,
730
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:28:13 UTC from IEEE Xplore.  Restrictions apply. 
: Trace → Obs
∗
observations are managed similarly to the secrets. One deﬁnes
the observation domain Obs, the ﬁlter isObs : Trans → Bool
and the production function getObs : Trans → Obs, and then
deﬁnes OgetObs
by ﬁltering with isObs and
isObs
applying getObs transition-wise. For (P1), Obs is taken to be
the set of all action-output pairs. isObs (σ, a, o, σ(cid:6)) is true just
in case the action is issued by one of the designated observers
(userOf(a) ∈ UIDs), and getObs retrieves the action and output
from the transition (getObs (σ, a, o, σ(cid:6)) = (a, o)). Note that
this includes failed actions, i.e., errors must not leak secrets.
So what can the observers learn about the secrets? Accord-
ing to (P1), nothing beyond the (non-)existence of at least one
update. This is formalized as a bound, i.e., a binary relation B
between sequences of secrets. We require sequences of secrets
related by B to be exchangeable, without
interfering with
the observations. Intuitively, given the sequence of secrets sl
(cid:6))} represents
produced by a system trace, the set {sl
the amount of uncertainty of the observers: for what they
in this set. Hence, B describes a
know, sl could be any sl
lower bound on the uncertainty, i.e., an upper bound on the
declassiﬁcation (i.e., controlled release of designated secrets
(cid:6)) is deﬁned as “sl
to designated observers). For (P1), B(sl, sl
empty.” Thus, the only piece of information
empty implies sl
that can ﬂow to the observers is a harmless one: that no update
has been performed yet (possibly because the post has not been
created yet).
(cid:6) | B(sl, sl
(cid:6)
(cid:6)
(P1) also prescribes a legitimate way out of the declas-
siﬁcation bound: if one of the observers has or acquires a
role (system admin, post owner or owner’s friend) or an
intended declassiﬁcation happens (the post is made public).
This is formalized as a trigger, a unary predicate T on system
transitions. The bound B is only imposed unless the trigger
T occurs. Here, T (σ, a, o, σ(cid:6)) is deﬁned as a property of
the transition’s target state σ(cid:6): that the system’s admin is in
UIDs (admin(σ(cid:6)) ∈ UIDs), the registered owner of PID is in
UIDs (owner(σ(cid:6), PID) ∈ UIDs) or has a user in UIDs as a
PID) (cid:10)= /0) or
registered friend (UIDs ∩ friendIDs(σ(cid:6), owner σ(cid:6)
the visibility of PID is public (visPost(σ(cid:6), PID) = public). This
formalizes the unless part of (P1).
The above concepts apply generally, to any I/O automaton:
Deﬁnition 1. An attacker model consists of
• a secrecy infrastructure (Secret, isSec, getSec) and
• an observation infrastructure (Obs, isObs, getObs).
A security policy is speciﬁed by
• a declassiﬁcation trigger T and
• a declassiﬁcation bound B.
A BD security property [38] (P) is speciﬁed by an attacker
model and a security policy (as above).
An I/O automaton Aut satisﬁes the BD security property
(P) if, for all traces tr in which T never holds for any transition
(cid:6))
(cid:6)
such that B(SgetSec
(tr), sl
and for all sequences of secrets sl
(cid:6)
holds, there exists a system trace tr(cid:6) such that SgetSec
(tr(cid:6)) = sl
isSec
and OgetObs
isObs
(tr(cid:6)) = OgetObs
(tr).
isObs
isSec
Intuitively, BD Security states that OgetObs
isObs