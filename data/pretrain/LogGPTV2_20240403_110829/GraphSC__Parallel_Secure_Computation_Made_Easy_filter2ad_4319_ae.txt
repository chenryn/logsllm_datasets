(d) ALS
Fig. 7: Computation time for increasing number of processors, showing an almost linear decrease with the number of processors.
The lines correspond to different input lengths. For PageRank, gradient descent and ALS, the computation time refers to the
time required for one iteration.
)
c
e
s
(
e
m
T
i
215
212
29
26
23
212
214
216
Input length
)
c
e
s
(
e
m
T
i
215
212
29
26
23
212
214
216
Input length
)
c
e
s
(
e
m
T
i
215
212
29
26
210
)
c
e
s
(
e
m
T
i
215
212
29
26
26
28
210
Input length
212
212
214
Input length
(a) Histogram
(b) PageRank
(c) Gradient Descent
(d) ALS
Processors
4
8
16
32
Baseline
Nikolaenko et al.
Fig. 8: Computation time for increasing input size, showing an almost-linear increase with the input size, with a small log2
factor incurred by the bitonic sort. The lines correspond to different input lengths. For PageRank, gradient descent and ALS, the
computation time refers to the time required for one iteration. In Figure 8a, the baseline is a sequential ORAM-based baseline
using Circuit ORAM [53]. The ORAM-based implementation is not amenable to parallelization as explained in Section V-G.
Figure 8c compares our performance with the performance of Nikolaenko et al. [3] who implemented the circuit using FastGC [5]
and parallelized at the circuit level using 32 processors.
o
i
t
a
r
s
e
t
a
g
D
N
A
#
1.12
1.09
1.06
1.03
1.00
22
32K
64K
128K
256K
512K
24
25
23
Processors
26
o
i
t
a
r
s
e
t
a
g
D
N
A
#
1.12
1.09
1.06
1.03
1.00
22
4K
8K
16K
32K
64K
24
25
23
Processors
26
o
i
t
a
r
s
e
t
a
g
D
N
A
#
1.08
1.06
1.04
1.02
1.00
22
2K
4K
8K
16K
32K
24
25
23
Processors
26
o
i
t
a
r
s
e
t
a
g
D
N
A
#
1.021.02
1.01
1.00
22
256
512
1K
2K
4K
24
25
23
Processors
26
(a) Histogram
(d) ALS
(b) PageRank
(c) Gradient Descent
Fig. 9: Total work in terms of # AND gates, normalized such that the 4 processor case is 1×. The different curves correspond to
different input lengths. Plots are in a log-log scale, showing the expected small increase to the number of processors P . Recall
that our theoretical analysis suggests that the total amount of work is O(P log P + M ), where M := |V| + |E| is the graph size.
In practice, since we use bitonic sort, the actual total work is O(P log2 P + M ).
expected, adding more processors increases the total commu-
nication between garblers, following log2 P (where P is the
number of processors), due to the bitonic sort. Figure 10b
shows the communications per-processor (dividing the results
of Figure 10a by P ). This helps understand overheads in our
setting, where, for example, a cloud provider that provides
secure computation services (garbling or evaluating) is inter-
ested in the communication costs of its facility rather than the
total costs. As the number of processors increase, the “out-
going” communication (e.g., a provider running garblers see
the communication with evaluators as “out-going” communi-
cation) decreases. The GG communication (or EE communi-
cation) remains roughly the same (following log2 P/P ), and
signiﬁcantly lower than the “out-going” communication.
Practical Optimizations. The optimization discussed in Sec-
tion III-E decreases the amount of computation for the prop-
agate and aggregate operations. We analyze the decrease in
computation as a result of this optimization.
Figure 11 shows the number of (computed analytically)
aggregate operation performed on an input length of 2048,
using two scenarios: (a) one processor simulating multiple
389389
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:05:55 UTC from IEEE Xplore.  Restrictions apply. 
)
B
M
(
m
m
o
C
l
a
t
o
T
214
212
210
28
GE comm
GG comm
22
24
25
23
Processors
26
)
B
M
(
r
o
s
s
e
c
o
r
p
/
m
m
o
C
215
212
29
26
22
GE comm
GG comm
24
25
23
Processors
26
(a) Total Communication
(b) Communication per processor
Fig. 10: Communication of garbler-evaluator (GE) and garbler-
garbler (GG) for gradient descent (input length 2048).
s
n
o
i
t
i
d
d
a
#
215
213
211
29
21
23
w/o optimization
with optimization
27
29 211
25
Processors
Fig. 11: Total number of aggregate operation (additions) on an
input length of 2048, with and without optimization.
processors, (b) the optimization discussed in Section III-E
is used. As can be seen in ﬁgure, the number of additions
with optimization is much lower than the scenario where one
processor simulates multiple processors. The optimized version
performs worse than the single-processor version only when
the number of processor comes close to the input size, a setting
which is extremely unlikely for any real-world problem.
Comparison with a Cleartext Baseline. To better under-
stand the overhead that is incurred from cryptography, we
compared GraphSC’s execution time with GraphLab [9], [12],
[72], a state-of-the-art framework for running graph-parallel
algorithms on clear text. We compute the slowdown relative
to an insecure baseline, assuming that the same number of
processors is employed for GraphLab and GraphSC. Using
both frameworks, we ran Matrix Factorization using gradient
descent with input length of 32K. For the cleartext experi-
ments, we ran 1000 iterations of gradient descent 3 times, and
computed the average time for a single iteration.
Figure 12 shows that GraphSC is about 200K - 500K
times slower than GraphLab when run on 2 to 16 processors.
Since GraphLab is highly optimized and extremely fast, such
a large discrepancy is expected. Nevertheless, we note that
increasing parallelism decreases this slowdown, as overheads
and communication costs impact both systems.
Accuracy. Figures 13a and 13b show the relative error of
running the secure version of PageRank compared to the
)
c
e
s
(
e
m
T
i
218
212
26
20
−6
21
2
Secure
Cleartext
Slowdown
700K
400K
100K
24
22
23
Processors
n
w
o
d
w
o
l
S
Fig. 12: Comparison with cleartext
GraphLab for gradient descent (input length 32K)
implementation on
r
o
r
r
e
e
v
i
t
a
l
e
r
g
v
A
−2
−3
−4
−5
−6
−7
−8
0
10
10
10
10
10
10
10
20
24
28