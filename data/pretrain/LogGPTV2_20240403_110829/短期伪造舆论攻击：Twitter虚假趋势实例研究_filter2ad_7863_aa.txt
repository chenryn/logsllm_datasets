# 短期伪造舆论攻击：Twitter虚假趋势实例研究
|
##### 译文声明
本文是翻译文章，文章原作者 Karl Aberer，Tugrulcan Elmas，Ahmed Furkan Ozkalay，Rebekah
Overdorf，文章来源：arxiv.org
原文地址：
译文仅供参考，具体内容表达以及含义原文为准。
本研究在社交媒体平台的流行机制中发现了一个以前未知的、正在进行的攻击：短期伪舆论攻击（Ephemeral Astroturfifing Attack）。
在此攻击中，通过协同的和不真实的活动来人为地推广了选定的关键字或主题，使其流行起来，关键的是其中的恶意活动作为攻击的一部分被删除。观察到此类对Twitter趋势主题（Trend）的攻击，发现这些攻击不仅成功，而且无处不在。检测到108,000个帐户造成了超过19,000个唯一的虚假Trend，不仅包括虚假帐户，而且还包括雇佣/受害帐户（compromised
account），其中许多仍处于活跃状态并继续参与攻击。
这些攻击所造成的Trend至少占全球十大趋势中的20％。短期伪舆论威胁着社交媒体平台上热门流行机制的完整性，并进一步威胁平台的完整性。
## 1\. Introduction
社交媒体平台部署的用于显示热门流行内容的机制是平台增加参与度的主要载体。 如Facebook的newsfeed算法；
Reddit的“r/popular”；Twitter的趋势主题Trend是平台功能和基础业务模型不可或缺的组成部分。
这些机制很有价值，因为它们确定了哪些内容对用户最可见。 Twitter的Trend可以等同于传统的广告渠道，并且可以用于营销。
这种流行机制的完整性是社交媒体生态系统不可或缺的部分。
用户期望他们显示的受欢迎内容是平台上真实活动的结果，合法的民间运动期望他们的内容将得到公平考虑，而平台希望显示受欢迎的内容会增加参与度。
在更下游，广告商期望流行机制的作用是增加参与度，从而增加收入。
更进一步，那些使用Trend来研究社会和社交媒体的人，即研究人员和新闻工作者，期望趋势能够准确反映出公众讨论的流行主题。
由于这些流行机制具有如此巨大的影响力和创收潜力，因此对于希望其非法内容被许多用户看到的攻击者来说，它们是一个有吸引力的目标。 例如，“点赞水军”（like
farm）被用来在Facebook上产生虚假点赞，以将推文增加到用户的新闻馈送顶部，而机器人可以在Reddit上人为地“like”推文以提高其可见度。
在Twitter趋势的情况下，有时有组织的攻击者会增强虚假信息和阴谋论的趋势，使它们成为Trend，以便进一步放大，例如QAnon追随者劫持Trend
#SaveTheChildren的情况。 由于这一事件，许多人在Twitter上呼吁通过使用#UntrendOctober标签来遏制Trend。
对流行机制的攻击依赖于不真实的内容或有动机的行为。
一旦暴露出来，伪舆论攻击就会破坏用户对平台的信任。了解这些攻击是确保平台对用户安全和对广告客户有价值，从而维护平台商业模式的关键部分。
在本文中，对学术界中尚未研究的一种新型伪舆论攻击进行了深入的分析，称其为短期伪舆论攻击。短期伪舆论不同于传统的造势，它的活动参与者在成功执行伪舆论攻击时隐藏了恶意活动，使某些内容更加可见，同时使本应可见的内容不可见
。
通过删除有关攻击的证据，短期伪舆论攻击在三个关键方面胜过其他方法：（i）能够使用活跃的、雇佣/受害帐户作为来源进行交互，从而加速普及；（ii）逃避正常用户，平台和学术研究的检测；以及（iii）阻止用户将恶意活动报告为垃圾信息，因此传统的垃圾信息分类器无法阻止未来的攻击。
本研究将重点放在虚假Twitter
Trend案例上，以调查短期伪舆论攻击。Twitter是一个受欢迎的平台，可用于许多重要讨论，包括政治辩论，并通过提供适当的数据进行研究：Twitter官方API的删除通知（deletion
notice）和Trend。 观察到在与土耳其当地的热门事件有关的Twitter
Trend都曾受到短期伪舆论攻击，这影响了土耳其的1180万活跃用户以及全球Trend。 准确地说，发现Twitter
Trend上的短期伪舆论攻击始于2015年，至少占土耳其前五名每日Trend的47％，至少占全球十大Trend的20％。
研究发现，在确定哪些关键字成为Trend并因此容易受到短期攻击时，Twitter不会考虑在其中是否有一条推文被故意删除。
当前确定Twitter趋势的算法的设计可以实现短期伪舆论攻击。Trend每5分钟刷新一次，以一定时间间隔内已发布的推文为准。
尽管Trend列表的完整性很重要，但是该算法不会检查那些推文是否仍然可用或已被删除。此漏洞可以表示为一种“检查时间-可用时间”（TOCTOU，Time-of-Check-Time-of-Use）攻击，原因是在使用“可用”数据确定趋势时，与“检查”时有所不同， 因为它已被删除。 换句话说，当使用安全关键输入（
security-critical input，即推文）更新平台的关键资产时，此攻击违反了完整中介原则（complete mediation
principle）。
由于攻击的严重性，研究者已于2019年7月和2020年6月再次通知Twitter，并提供了有关攻击和所涉及帐户的详细说明。
在第一个通知之后，他们承认攻击确实存在（2019年7月），在第二个通知（2020年6月）之后，他们答复说他们会将攻击转发给相关团队进行处理。
此后研究团队一直在保持追踪，但尚未收到任何进展的迹象。 到2021年2月，对Twitter Trend的攻击仍在继续。
## 2\. Background
**社交媒体操纵：**
社交媒体平台的广泛采用吸引了旨在针对其自身目的大规模操纵用户的攻击者。这些操纵攻击的范围从大规模数据收集到目标赞助的有针对性广告、宣传、垃圾邮件，热度提升和主题标签（hashtag）劫持。由于通常会广泛部署，因此许多操纵攻击都采用了僵尸机器人和僵尸网络来作为必需组件。
本研究专注于此类机器人辅助操纵攻击。
在研究中，观察到了政治宣传（不一定是亲政府）和非法广告，它们本身并非通过hashtag劫持来表现出来（通常也是这样），而是通过直接的Trend操纵来表现出来的。
手动识别或自动识别机器人变得越来越困难。社交机器人旨在模仿社交媒体上的人类用户；他们复制真实身份（个人图片，推文），模仿人类的昼夜生活规律，互相关注以获得大量关注者，并制造混入恶意内容的推文。
在某些情况下，用户使用使其成为僵尸网络一部分的恶意应用程序注册其帐户。短期伪舆论攻击使攻击者能够使用达成协议的雇佣/受害用户，这些用户继续与攻击者并行使用帐户。攻击者通过删除攻击推文来藏身于合法用户之中。由于这些是良性用户，他们可能会迷惑监管方。由于它们与其他良性帐户相关联，因此它们还会迷惑基于图形的检测系统。尽管雇佣/受害账户受到雇用或欺骗，但是用于检测恶意雇佣帐户的系统在相关推文被删除后无法检测到它们，因为检测系统不考虑内容删除行为。
现有的机器人检测方法无法检测到在此描述的机器人行为，因为它们很少考虑内容删除。例如，
检测系统Botometer处理的是快照而不是实时活动，因此恶意活动被迅速删除时它无法检测到本研究中帐户的疑似机器人活动（bot-like
activity）。即使以内容删除作为机器人特征，但如果用户最近的发推率很高而总发推数较少，这可能会导致系统捕获旧推文的删除，而不是快速删除的推文。
另一种检测系统Debot基于Twitter流进行的关键字过滤，Twitter流不会给出删除通知，并且如果在攻击之前未提供被攻击的关键字，则不会收集相关数据，这对于仅流行一次的关键字是不可能的。
在本文中，使用机器人创建虚假Trend的特征行为对它们进行分类，即删除和生成的内容。
**伪舆论和虚假Trend：**
尽管沙特和土耳其的新闻媒体已经简要报道了使用机器人攻击Trend和操纵虚假Trend的伪舆论事件，但学术界仍未对此进行研究。
这项工作是首次系统地大规模研究操纵Twitter
Trend功能的研究。本文研究了旨在将某些关键字直接推到Trend列表同并逃避检测的行为，以及用于此类操作的帐户。
## 3\. Ephemeral Astroturfifing
**定义依据：** 要定义短期伪舆论，可以关注一个针对土耳其Twitter