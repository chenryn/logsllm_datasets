—
—
3.93%
—
1.60%
—
—
—
—
—
—
—
—
—
—
—
—
—
—
—
—
—
—
—
—
—
—
—
—
—
—
—
—
—
—
—
—
—
—
—
—
—
—
7.63%
9.32%
4.15%
1.84%
7.56%
7.79%
Benchmark
OCFI+namd
SS+hmmer
OCFI+bzip2
AG+sjeng
CPI+xalan
OCFI+gobmk
Overhead
Type-1: MPX>MPK>SEIMI
19.11% > 0.12% > 0.04%
100.00% > 3.23% > 1.61%
Type-2: MPK>MPX>SEIMI
31.46% > 20.15% > 15.17%
22.22% > 20.30% > 12.74%
Type-3: MPK>SEIMI >MPX
118.71% > 82.01% > 66.19%
84.48% > 47.42% > 21.94%
CFreq.
SFreq.
1,657,879
1,058,448
9
1,165
1,765,116
3,302,912
14,979
7,467
49,443
991,377
19,137
36,119
C. Real-world Applications Evaluation
Web servers. We used ApacheBench (ab) to simulate 10
concurrent clients constantly sending 10,000 requests; each
request asks the server to transfer a file remotely (over a 5m
long CAT 5e cable). We also vary the size of the requested
file, i.e., {1K, 5K, 20K, 100K, 200K, 500K}, to represent
different configurations. Table VII shows the performance
overhead (geo_mean) of web servers under protection of the
four defenses with the IH/MPX/MPK/SEIMI-based schemes.
As the requested file size increases, the overheads of all schemes
decline. From the table, we can see that SEIMI is slower than
MPX only when protecting Lighttpd with OCFI. For all other
cases, SEIMI is more performant than MPX and MPK.
Databases. Since different databases have different bench-
marks, we evaluated them by using the corresponding bench-
marks which are consistent with prior works: (1) For MySQL,
we evaluated its latency with the sysbench utility [3]. MySQL
was configured with 4 tables of 100,000 rows on which a
read-write workload was executed with 4 threads; (2) For
Redis, we evaluated its SET and GET throughput with the
redis-benchmark tool, which is released together with Redis;
(3) For Memcached, we evaluated it with twemperf [4]. We
created 1,000 connections and 10 calls per second, and the
item size is set to 400 KBytes; (4) For SQLite, we evaluated
its latency by inserting 2,000 rows and selecting 2,000 times.
From the table, we can see that SEIMI is slower than MPX
only when using OCFI and SS. For all other cases, SEIMI is
more performant than MPX/MPK on average.
JS engines. We evaluated the four JS engines with the Kraken
benchmark [2] from Mozilla, which is widely used to test
realistic workloads. We evaluated each of the 14 test suites in
Fig. 7: Performance comparison of MPK and SEIMI.
of bound-checks per millisecond and SFreq as the number of
permission switches per millisecond.
SEIMI vs. MPX. Figure 6 reveals how CFreq and SFreq
affect the performance when applying the four defenses with
MPX and SEIMI. In this figure, each point represents one
benchmark; the x-axis is CFreq/SFreq, and the y-axis is the
ratio of the benchmark’s overhead when it is protected by a
defense and two different isolation schemes. The green solid
line is the power trendline of the MPX overhead divided by
the SEIMI overhead. The points within the black dotted box
are drawn by adopting unequal interval scale because the
frequency ratio is too large. The points above the dotted red
line indicate the cases in which MPX has a higher overhead
than SEIMI. Specifically, SEIMI outperforms MPX in 56.92%
of benchmarks. Statistically, when CFreq/SFreq is larger than
51.88, 86.21% of benchmarks have a lower overhead with
SEIMI, compared to MPX. That is, when the bound-checking
frequency is 52 times of the access permission switching
frequency, SEIMI is more efficient than MPX in most cases.
SEIMI vs. MPK. Figure 7 reveals how SFreq affects the
performance when applying the four defenses with MPK
and SEIMI. It shows that, compared to MPK, as the access
permission switching frequency increases, the performance
gain of SEIMI becomes more apparent. This is expected
because switching SMAP using STAC/CLAC is much faster
than switching MPK using WRPKRU (shown in Table I).
Case study. Table VIII shows six representative cases in three
categories. We can see that when the bound-checking frequency
is much larger than access permission switching frequency, the
domain-based isolation is better. Since the domain-switching
overhead in SEIMI is lower than MPK, SEIMI has more
performance advantage than MPK when compared with MPX.
12
0%100%200%300%400%500%600%0.0E+005.0E+041.0E+051.5E+052.0E+05OverheadSwitches/msOH(MPK)OH(SEIMI)Trandline(MPK)Trandline(SEIMI)Kraken and calculated the geo_mean of the overheads. From
the table, we can see that SEIMI is more performant than
MPX/MPK in most cases (except protecting JavaScriptCore
with OCFI). Moreover, we can see that neither address-
based schemes nor domain-based schemes are suitable for
JavaScriptCore due to the significant performance overhead.
VII. DISCUSSION
Overloading the AC flag. The AC flag in the RFLAGS register
is designed to enable/disable the alignment checking of data
accesses when used in the U-mode; it is re-purposed for control-
ling SMAP when used in the S-mode. As such, SEIMI cannot
rely on the AC flag for alignment checking. However, this does
not limit the application of SEIMI, because for compatibility
issues, such alignment checking is actually disabled by default
in both most Linux and Windows applications. For example, the
memcpy library function is highly optimized by using unaligned
data accesses in glibc.
Nested virtualization. SEIMI requires VT-x. As a result,
it cannot be used inside a VM unless the target hypervisor
supports nested VT-x [8]. To evaluate the performance char-
acteristics of such a configuration, we did two experiments:
(1) running SPEC on SEIMI, and SEIMI runs on a KVM;
(2) running the process-related benchmark (the worst cases in
SEIMI) in lmbench on SEIMI + KVM similarly. We found
that for SPEC, compared to native, the KVM incurs an overhead
of 10.24% on average, and SEIMI + KVM only incurs 12.11%
on average. But for lmbench, compared to native, the KVM
incurs an overhead of 23.14% on average, and SEIMI + KVM
incurs 6.07X slowdown on average. This is because the VM
exit is highly expensive in nested virtualization. So how to
promote the performance of SEIMI in nested virtualization is
an interesting topic of future consideration.
Possible incompatibility with future instructions. In §IV-B,
we proposed multiple techniques to identify and intercept
the privileged instructions. When new instructions are to
be supported by the processors, SEIMI would require extra
effort to support these extensions. We believe supporting new
instructions in SEIMI is possible: First, almost all instructions
have execution conditions, therefore we could destroy these
conditions to avoid the normal execution of these instructions;
Second, processors usually provided the control of hardware
support for the more recent released instructions in the control
registers and model-specific registers,
therefore we could
configure such registers of the guest to disable the support.
Transient execution attacks. Recent attacks [13] have
demonstrated that transient execution attacks are practical in
extracting private data from isolated memory regions. Both
address-based and domain-based isolation mechanisms are
subject to Meltdown-type attacks [13]. For instance, Meltdown-
MPX [13, 28] and Meltdown-PK [13] attacks successfully
break the isolation based on Intel MPX and MPK. Recently,
Xiao et al. [57] shown that SMAP is bypassable. Therefore,
we anticipate SEIMI would be vulnerable to Meltdown-type
attacks as well unless the hardware is patched. Beside the
Meltdown-type attacks, the newly disclosed Microarchitectural
Data Sampling (MDS) attacks (such as RIDL [49], Fallout [14],
and ZombieLoad [45]) can also leak private data by exploiting
CPU-internal buffers (e.g., Line Fill Buffers, Load Ports, and
Store Buffers) [1]. To mitigate the MDS attacks, Intel updated
microcode to modify/extend the VERW instruction to clear these
buffers [1] (although it has been proven has flaws [50]). In
SEIMI, VERW will fail to execute due to the descriptor load
segment violation. However, the internal buffers will still be
overwritten even with such a violation [1]. Therefore, SEIMI
does not affect this new functionality of VERW.
VIII. RELATED WORK
Leveraging privileged hardware for user code. Dune [7]
is the only work we are aware of that also leverages the Intel
VT-x virtualization technology to provide user-level programs
with system privileges. It runs a user-level process in ring 0
of the VMX non-root mode, allowing the process to manage
the exceptions, the descriptor tables, and the page tables. It
however requires that the code running in ring 0 is secure and
trusted. For the untrusted code, such as a plugin in the browser,
Dune runs a sandbox in ring 0 and confines the untrusted
code in ring 3. Compared to Dune, an inherent difference is
that SEIMI allows an untrusted code to run in ring 0, which
brings significant challenges but, on the other hand, ensures the
efficiency—running untrusted code in ring 3 will incur frequent
context switching thus significant performance overhead.
In addition, SEIMI has various innovative system designs.
For example, SEIMI uses SMAP to realize an efficient
intra-process memory isolation and designs a new memory
virtualization method that translating the guest virtual address
to the host physical address directly, thus avoiding the memory
virtualization overhead (incurred by the TLB misses) in
traditional two-dimensional paging mechanisms2 [52].
Address-based memory isolation. SFI [51] guarantees that
the target code cannot read or write outside of designated
sections of the memory space, which could be used to realize
the intra-process memory isolation. Except the aforementioned
MPX-based method, Isboxing [20] overwrites the instruction
prefixes to change the default operation size to limit the
size of the address space, which however allows only up to
4GB address space. Segmentation also provides intra-process
memory isolation [44] by requiring the code to possess a
descriptor to address a particular section of memory. However,
segmentation is only supported in 32-bit mode [29].
Domain-based memory isolation. Similar to Intel MPK,
ARM also supports the memory domains [5], which is available
only on 32-bit processors. VT-x introduces an instruction,
VMFUNC, that enables fast switches between EPTs in virtualiza-
tion. Recent works [25, 30, 34] use this feature to realize intra-
process memory isolation by setting double-EPT which contains
mappings corresponding to the isolated memory region.
2 The guest virtual address is first translated into the guest physical address
through the guest page table, which is then translated to the host physical
address through the extended page table (EPT).
13
Hardening information hiding. Some works have been
proposed to harden IH. In particular, ProbeGuard [10] detects
probing attacks that try to derandomize information hiding
and patches the vulnerable code to prevent probing. SafeHid-
den [54], on the other hand, employs runtime monitoring,
continuous randomization, and thread memory localization to
maintain the entropy of information hiding.
Marking as sensitive pages. The outcoming control-flow
enforcement technology (CET) [27] provides the isolation for
the shadow stack by marking as the shadow stack page in
the page tables. The shadow stack page cannot be accessed
by normal memory access instructions. Unfortunately, CET is
tailored towards CFI and cannot be easily repurposed for other
mitigations [21]. IMIX [21] and MicroStache [38] provides a
similar but more generic method for the sensitive data, which
however requires modifying hardware.
Tagged architectures. Recent research has revisited tagged
architectures [46, 56], in which the hardware associates a “tag”
with each byte in memory that encodes a security policy. Tags
can be used to, for example, grant call instructions exclusive
rights for writing to certain memory regions, preventing return
addresses from being overwritten [46]. More generally, such
architectures can readily be leveraged for intra-process memory
isolation, by assigning access permissions to each instruction
in the code section, and each byte in memory. However, such