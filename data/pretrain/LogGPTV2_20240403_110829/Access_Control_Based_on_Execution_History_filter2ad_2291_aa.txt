title:Access Control Based on Execution History
author:Mart&apos;ın Abadi and
C&apos;edric Fournet
Access Control based on Execution History
Mart´ın Abadi
University of California at Santa Cruz
C´edric Fournet
Microsoft Research
Abstract
Security is a major, frequent concern in extensible soft-
ware systems such as Java Virtual Machines and the Com-
mon Language Runtime. These systems aim to enable
simple, classic applets and also, for example, distributed
applications, Web services, and programmable networks,
with appropriate security expectations. Accordingly, they
feature elaborate constructs and mechanisms for associ-
ating rights with code, including a technique for determin-
ing the run-time rights of a piece of code as a function of
the state of the execution stack. These mechanisms pre-
vent many security holes, but they are inherently partial
and they have proved difﬁcult to use reliably.
We motivate and describe a new model for assigning
rights to code: in short, the run-time rights of a piece
of code are determined by examining the attributes of
any pieces of code that have run (including their origins)
and any explicit requests to augment rights. This history-
based model addresses security concerns while avoiding
pitfalls. We analyze the model in detail; in particular, we
discuss its relation to the stack-based model and to the
policies and mechanisms of underlying operating systems,
and we consider implementation techniques. In support
of the model, we also introduce and implement high-level
constructs for security, which should be incorporated in
libraries or (even better) in programming languages.
1 Introduction
In the access control model of security, an access con-
trol matrix associates rights for operations on objects with
subjects. The objects may for example be ﬁles and de-
vices; the subjects may for example be users; the oper-
ations may be reading and writing. In systems that rely
on access control for security (and most do), a frequent,
delicate issue is the association of rights with code. For
example, a piece of code may be given the rights of the
subject who executes the code, those of the author of the
code, or some combination of the two. These rights deter-
mine whether the code can perform sensitive operations
(e.g., reading and writing ﬁles).
Runtime environments such as Java Virtual Machines
(JVMs) [13, 9] and the Common Language Runtime
(CLR) [5, 2, 12] provide rich support for associating rights
with code, under conﬁgurable security policies. These
environments aim to enable simple mobile code (classic
applets) and also, for example, distributed applications,
Web services, and programmable networks, with appro-
priate security expectations. They feature elaborate con-
structs and mechanisms for managing rights, including a
technique for determining the run-time rights of a piece
of code as a function of the state of the execution stack,
and an associated requirement that programmers code cer-
tain security checks. These run-time mechanisms prevent
many security holes, but they are inherently partial, and
remain blind to any interaction not recorded on the cur-
rent execution stack. These mechanisms also have perfor-
mance and usability costs: for most programmers, their
effects are difﬁcult to predict (and even to interpret).
In this paper, we motivate and describe a new model and
practical techniques for assigning rights to code at run-
time. In short, the run-time rights of a piece of code are
determined by examining the attributes of any pieces of
code that have run (including their origins) and any ex-
plicit requests to modify rights. Our model addresses se-
curity concerns while simplifying the tasks of program-
mers and thereby avoiding security pitfalls. Although
widely applicable, it is particularly motivated by the char-
acteristics and needs of JVMs and of the CLR: it is largely
compatible with the existing stack-based model, but it pro-
tects sensitive operations more systematically, and it also
enables a smoother integration with the security mecha-
nisms of an underlying operating system (such as secu-
rity tokens in NT and its descendants). Our model can
be implemented efﬁciently using a small amount of aux-
iliary state. In addition, we introduce constructs for high-
level languages (such as Java or C]) that facilitate security-
aware programming within the model.
The rest of this paper is organized as follows. In Sec-
tion 2, we review some aspects of associating rights with
code, and in particular stack-based access control. In Sec-
tion 3, we present our history-based access control ap-
proach. In Sections 4 and 5, we give some examples and
we sketch a high-level language extension in the context
of C]. In Sections 6 and 7, we further relate our approach
to stack-based techniques and system security. We close
with a discussion of related work and some brief conclu-
sions. An appendix provides some additional code.
Throughout, when we rely on the precise context of a
system, we focus mainly on the CLR. (We do not assume
a detailed knowledge of the existing CLR security model
and of the corresponding mechanisms.) In this concrete
context, we emphasize design, but also investigate imple-
mentation techniques.
In particular, we have pieces of
code that embody parts of our model, and we have stud-
ied matters of performance and of compatibility with ex-
isting libraries. However, we have yet to attempt a full
development and integration into the CLR (or Rotor, a
shared-source implementation [20]). This integration is
likely to be a substantial task. In particular, this integration
could include enabling optimizations currently illegal be-
cause of the stack-based model; removing data-structure
customizations for that model; and compiler support for
the new history-based model. We suspect that it is not
too meaningful to conduct detailed performance measure-
ments without this integration work.
2 Associating Rights with Code and
Stack Inspection
In an extensible software system where subjects and
pieces of code are trusted to varying degrees, it is both
important and challenging to manage the permissions of
running programs in order to avoid security holes.
Type safety provides a base line of protection and en-
ables ﬁne-grained access control. Although type safety is
crucial for security in JVMs, the CLR, and related sys-
tems (such as SPIN [1]), it is not by itself sufﬁcient. In
this section, assuming type safety, we discuss some secu-
rity problems that type safety does not solve, as well as a
popular, stack-based technique for addressing these prob-
lems. We point out some shortcomings of this technique
(of which some, but not all, are well known), thus moti-
vating history-based rights computation.
One particular difﬁculty that has attracted considerable
attention is the so-called “confused deputy” problem [10],
which goes as follows. Suppose that a piece of un-
trusted code calls a piece of trusted code, such as a li-
brary function, perhaps passing some unexpected values
as arguments to the call, or in an unexpected execution
state. Later, the trusted code may invoke some sensitive,
security-critical operations, for example operations on an
underlying ﬁle system. It is crucial that these operations
be invoked with the “correct” level of privilege, taking
into account that the call is the result of actions of un-
trusted code. Moreover, this security guarantee should be
achieved under the constraint that we would not expect ev-
ery library function to be rewritten; only a fraction of the
code may ever be security-aware.
One approach to addressing this problem is the tech-
nique called stack inspection, which is presently embod-
ied in JVMs and in the CLR. Following this technique,
an upper bound on its permissions is associated statically
(that is, before execution) with each piece of code, typi-
cally by considering the origin of the piece of code. For
example, whenever a piece of code is loaded from an un-
trusted Internet site, it may be decided that this piece will
have at most the right to access temporary ﬁles, but will
have no other rights during execution. At run-time, the
permissions of a piece of code are the intersection of all
the static permissions of the pieces of code on the stack.
Thus, the run-time permissions associated with a request
made by a trusted piece of code when it is called by an
untrusted piece of code include only permissions granted
statically to both pieces of code. An exception to this pol-
icy is made for situations in which a trusted piece of code
explicitly ampliﬁes the run-time permissions. Such ampli-
ﬁcations are dangerous, so they should be done only after
adequate checking.1
Although the stack inspection technique has been
widely deployed, it has a number of shortcomings. One
of the main ones is that it attempts to protect callees from
their callers, but it ignores the fact that, symmetrically,
callers may be endangered by their callees. (Similar is-
sues arise in connection with exception handling, multi-
ple threads, shared mutable data structures, callbacks, and
higher-order programming.) If A calls B, B returns (per-
haps with an unexpected result or leaving the system in
an unexpected state), and then A calls C, the call to C de-
pends on the earlier call to B, and security may depend on
tracking this dependency, which stack inspection ignores.
(See Section 4 for programming examples.) In theory, one
could argue that A should be responsible for checking that
B is “good” or that it does not do anything “bad”. How-
ever, this checking is difﬁcult and impractical, for a vari-
ety of reasons. In particular, A may be a library function,
which was coded without these security concerns in mind,
and which we may not like to recode—indeed, one of the
appeals of stack inspection is that it avoids some secu-
rity problems without the need to recode such functions.
Moreover, the call to B may be a virtual call (that is, a
dynamically dispatched call), whose target (B) is hard to
determine until run-time.
This shortcoming of stack inspection is a source of er-
rors with serious security ramiﬁcations. From a more fun-
damental perspective, stack inspection is a partial protec-
tion mechanism, which addresses only one aspect of the
1The details of stack inspection and of the operations that deal with
permissions vary across systems. In particular, the operation that per-
forms ampliﬁcations is coarser-grained in the JDK 1.2 than in earlier
JVMs and than in the CLR. In the CLR, on which we focus, this opera-
tion can give individual permissions, and another operation can remove
individual permissions.
“confused deputy” problem. Other techniques are needed
in order to achieve a more complete solution, with satis-
factory practical and theoretical properties.
Stack inspection is also a source of performance con-
cerns, and these concerns can in turn contribute to er-
rors. In a naive implementation of stack inspection, each
security decision requires “walking” the execution stack
and testing permissions. These operations can be expen-
sive.2 Therefore, programmers that think more about ef-
ﬁciency than about security often replace stack inspection
with riskier but faster operations, such as LinkDemand
in the CLR [12, page 73]. At least in principle, these
performance concerns could partly be addressed through
“security-passing style” implementation techniques [21].
Stack inspection presents other difﬁculties because of
its somewhat exotic, ad hoc character. It is a unique mech-
anism, largely motivated by an implementation idea, sep-
arate and distinct from other security mechanisms such as
may be provided by an underlying operating system, or by
a distributed environment. As a result, it is hard to trans-
late the security state of a runtime that uses stack inspec-
tion into a corresponding state that would be meaningful at
the operating system level. Such a translation is often de-
sirable when a thread in the runtime makes an external call
(a local system call, or even a call across a network). In
another direction, it is hard to relate stack inspection to ex-
ecution models for certain high-level languages that target
these runtimes. For example, programmers in functional
languages such as Haskell are not encouraged to think in
terms of stacks, so the runtime stacks are not an appropri-
ate abstraction for their understanding of security. Finally,
stack inspection is directly related to a particular stack-
based execution strategy. Although this strategy might be
reasonable in the context of an interpreter, it is not always
satisfactory in the context of a compiler. Stack inspec-
tion complicates and hinders compiler optimizations that
would affect the stack, such as tail-call elimination and
method inlining.
In light of these difﬁculties and shortcomings, we
should look for alternatives to stack inspection. An in-
teresting idea is to rely on information-ﬂow control, of
the kind studied in the security literature, particularly in
the context of multilevel security [4]. Unfortunately, de-
spite recent progress (e.g., [14]), information-ﬂow control
is often too restrictive and impractical for general-purpose
runtimes. Nevertheless, it provides an interesting point of
comparison and theoretical background; the work of Four-
net and Gordon explores the application of techniques di-
rectly based on information-ﬂow control [8].
2Debuggers and garbage collectors also perform stack walks, for con-
structing traces and for ﬁnding pointers into the heap, respectively. How-
ever, their algorithms are quite different from those for stack-based se-
curity, at least in the CLR, and they are subject to different performance
constraints.
We propose another alternative to stack inspection: we
rely on the execution history (rather than the stack, which
is an imperfect record of the history) for security, as ex-
plained below.
3 History-Based Rights Computation
Next, we detail our design and mechanisms for assign-
ing rights to code at run-time.
In short, the run-time rights of a piece of code are de-
termined systematically by examining the attributes of the
pieces of code that have run before and any explicit re-
quests to augment rights. The pieces of code that have run
include those on the stack but also those that have been
called and returned.
In our basic example—A calls B,
B returns, then A calls C—the run-time rights in effect
within C will in general depend on the fact that A, B,
and C have executed. The attributes in question include
in particular the origins of the pieces of code (whether
they come from the local disk, digitally signed by a trusted
party, from an untrusted Internet site, . . . ); they may also
include properties that can be determined by automated
code analysis. Thus, the general idea of our approach is
to remember the history of the computation (or some ab-
straction of this history) in computing run-time rights.
An important way to compute run-time rights is as the
intersection of rights associated with each of the pieces
of code that have run. Speciﬁcally, our approach is as
follows:
1. Static rights: We associate some rights with each
piece of code, statically (at compile time or load
time). We refer to these rights as static rights.
2. Current rights: At run-time, we associate current
rights with each execution unit at each point in time.
3. Checking: These current rights are the ones consid-
ered by default when security decisions need to be
taken or when security information needs to be com-
municated to other system components.
4. Storage: These current rights are stored in such a way
that programs can read them and update them (sub-
ject to the conditions given next). In particular, an
ordinary variable can represent these current rights.
5. Automatic updates: Whenever a piece of code exe-
cutes, the current rights are updated: the new current
rights are the intersection of the old current rights
with the static rights of this code.
6. Explicit modiﬁcations: At its discretion, a piece of
code may invoke a special operation to modify the
current rights. This operation will at most restore the
static rights of this code, and it may be further con-
strained.
7. Syntax: The controlled modiﬁcation of rights results
in some useful programming patterns. These patterns
can be supported with special syntax for “granting”
rights and “accepting” results after running untrusted
code.
We expand on each of these points in what follows.
First, however, we illustrate some of them with a triv-
ial example, the following tiny program fragment from a
trusted library:
m (); File . Delete(s );
At run-time, the call m() may affect the value of the pa-
rameter s (for example, if s is an instance variable and
m is an overridden method that sets s). Independently of
m’s behavior, if the static rights of m do not include the
right to delete ﬁles, then the set of current rights after m()
will not include that right either, so File . Delete(s) will
be prevented.
3.1 Static Rights and Current Rights
Concerning point 1 (Static rights), the static rights of a
piece of code typically depend on the origin and the prop-
erties of the code, as explained above. They represent the
maximal rights for that code. They do not change once the
code is loaded. Each piece of code can read its associated
static rights (but not update them).
This point is fairly standard, and is also a prerequisite
for stack inspection mechanisms. In fact, the details can
be worked out so as to keep compatibility with the existing
mechanisms. In particular, we can represent rights by col-
lections of objects that implement a standard Permission
interface (which we may informally call permissions), and
we can rely on existing methods for expressing the se-
curity policies that associate pieces of code with permis-
sions.
Concerning point 2 (Current rights), there are imple-
mentation and usability issues in choosing the size of exe-
cution units. The execution unit will typically be a thread.
In that case, whenever a thread is forked, it should start
with the current rights of its parent, by default. When two
threads join, their current rights should be intersected. As
usual, shared mutable memory should be treated with cau-
tion. Alternatively, with appropriate synchronization, the
execution unit may be a collection of threads, such as an
application domain in the CLR, possibly a complete pro-
cess containing many related threads.
According to point 3 (Checking), the current rights are
the ones used by default in security decisions, in calls on
services of an underlying operating system, and in calls
to execution environments on remote machines (see Sec-