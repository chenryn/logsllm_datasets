title:Assured Reconfiguration of Fail-Stop Systems
author:Elisabeth A. Strunk and
John C. Knight and
M. Anthony Aiello
Assured Reconfiguration of Fail-Stop Systems
Elisabeth A. Strunk
John C. Knight
M. Anthony Aiello
Department of Computer Science, University of Virginia
151 Engineer’s Way, Charlottesville, VA 22904-4740
{strunk | knight | aiello}@cs.virginia.edu
Abstract
Hardware  dependability  improvements  have  led  to  a
situation  in  which  it  is  sometimes  unnecessary  to
employ  extensive  hardware  replication  to  mask  hard-
ware  faults.  Expanding  upon  our  previous  work  on
assured reconfiguration for single processes and build-
ing upon the fail-stop model of processor behavior, we
define a framework that provides assured reconfigura-
tion for concurrent software. This framework can pro-
vide  high  dependability  with  lower  space,  power,  and
weight  requirements  than  systems  that  replicate  hard-
ware to mask all anticipated faults. We base our assur-
ance  argument  on  a  proof  structure  that  extends  the
proofs for the single-application case and includes the
fail-stop  model  of  processor  behavior.  To  assess  the
feasibility  of  instantiating  our  framework,  we  have
implemented a hypothetical avionics system that is rep-
resentative  of  what  might  be  found  on  an  unmanned
aerial vehicle.
1. Introduction
Schlichting and Schneider introduced the concept of
fail-stop processors as a building block for safety-criti-
cal  systems,  and  they  presented  a  programming
approach  based  on  fault-tolerant  actions  (FTAs)  in
which  software  design  takes  advantage  of  fail-stop
semantics [8]. Their approach enables the construction
of  dependable  logical  machines  composed  of  less
dependable  physical  components.  Since  their  original
work, the dependability of off-the-shelf hardware com-
ponents has risen substantially; also, in many systems,
weight and power are still limiting factors, even though
capability has increased significantly. In this paper, we
extend 
reconfiguration
semantics  so  that  they  can  contribute  to  system
dependability  without  adding  extra  hardware.  We  do
this  by:  (1)  allowing  the  recovery  protocol  to  specify
that  the  system  will  reconfigure  rather  than  complete
the  action;  and  (2)  allowing  FTAs  to  span  multiple
fail-stop  processors  with 
applications so that faults which would normally have
to be masked can be dealt with by changing the func-
tionality  of  the  system  as  a  whole.  System  service  is
restricted during reconfiguration, although briefly.
System reconfiguration is currently used for a vari-
ety of purposes in safety-critical systems: for example,
to  effect  changes  in  functionality  between  different
mission  phases  for  spacecraft  or  between  different
operating  modes  for  aircraft.  Also,  although  the  vast
majority  of  equipment  failures  in  safety-critical  sys-
tems are dealt with by masking their effects using repli-
cated  components,  reconfiguration  is  sometimes  used
to cope with the failure of specialized equipment such
as sensors. In addition, it can be used to cope with the
failure of computing equipment, as in the Boeing 777,
where replication is used to mask many effects of com-
puter  and  data  bus  failures,  but  where  the  system  can
be  reconfigured  to  provide  reduced  functionality  if
more than the expected number of failures occurs [12].
We claim that reconfiguration of a system built with
fail-stop processors can be used effectively to tolerate
many  faults  in  dependable  systems  that  would  be
expensive  or  impossible  to  deal  with  through  replica-
tion alone, and that it can become the heart of the archi-
tecture of a safety-critical system. If reconfiguration is
to  be  given  a  central  role  in  system  dependability,  its
assurance  becomes  paramount.  The  reconfiguration
protocols currently used in practice are system-specific
and  are  built,  in  large  measure,  using  whatever  archi-
tectural facilities are already provided by the system. In
an  earlier  paper  [10],  we  presented  an  approach  to
assured reconfiguration for a single application process
that  consisted  of  multiple  modules.  In  this  paper,  we
extend our previous work, introducing an approach to
the assured reconfiguration of a set of application pro-
cesses.  To  this  end,  we  present  a  system  architecture
and  verification  framework  in  which  the  reconfigura-
tion  logic  is  a  customizable  mechanism  that  will:  (1)
accept  component-failure  signals;  (2)  determine  the
configuration  to  which  the  system  should  move;  and
(3)  send  configuration  signals  to  the  individual  pro-
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:09:48 UTC from IEEE Xplore.  Restrictions apply. 
cesses to cause them to respond properly to component
failure.  To  meet  our  assurance  goal,  we  have  shown
that  our  architecture  satisfies  a  generalized  version  of
the single-application properties.
To illustrate the ideas that we describe, we have built
part of a hypothetical avionics system that is typical of
what might be found on a modern general-aviation air-
craft or an unmanned aerial vehicle (UAV). The system
includes  a  flight  control  application,  an  electrical
power generation monitoring application, and an auto-
pilot. The parts of these applications that are relevant to
our  research  have  been  implemented,  although  the
functionality is merely representative.
In section 2 we review related work, and in section 3
we introduce our system architecture. Assumptions are
listed section 4. We review Schlichting and Schneider’s
work  in  section  5.  In  section  6  we  present  our  formal
model  of  reconfiguration.  Our  example  avionics  sys-
tem is described in section 7. Section 8 concludes.
2. Related work
Other researchers have proposed the use of reconfig-
uration to increase system dependability in a variety of
contexts. Shelton and Koopman have studied the iden-
tification and application of useful alternative function-
alities  that  a  system  might  provide  in  the  event  of
hardware component failure [9]. Their work is focused,
however,  more  on  reconfiguration  requirements  than
effecting  the  reconfigurations  themselves.  Sha  has
studied  the  implementation  of  reconfiguration  in  fault
tolerance  for  control  systems [7],  although  his  work
does not focus on assurance. Likewise, Garlan et al. [2]
have  proposed  the  use  of  software  architectural  styles
as a general method of error detection and reconfigura-
tion  execution  to  improve  dependability,  but  they  do
not present a method of assuring their styles.
In  large  networked  systems,  reconfiguration  in
response  to  failures  is  known  as  information  system
survivability.  Informally,  a  survivable  system  is  one
that  has  facilities  to  provide  one  or  more  alternative
services  (degraded,  less  dependable,  or  otherwise  dif-
ferent)  in  a  given  operating  environment [4].  For  net-
worked systems, the loss of a single component or even
a  moderate  number  of  randomly-distributed  compo-
nents  must  be  expected.  System  reconfiguration  is
employed only in the event of damage with significant
consequences, or if moderate numbers of failures sug-
gest a common cause. The main challenge of reconfig-
uration in these systems is managing system scale.
Our work is part of a framework for using reconfig-
uration in embedded real-time systems. The embedded
system reconfiguration requirements are similar to the
networked system requirements, with three key differ-
ences: (1) the system is much smaller than large-scale
information systems and thus can be tightly controlled;
(2)  the  system  might  be  expected  to  respond  much
more quickly to a failure and thus have hard real-time
reconfiguration  requirements;  and  (3)  a  failure  of  any
application  to  carry  out  a  reconfiguration  can  have  a
much  greater  impact  on  the  system,  and  so  the  assur-
ance  requirements  of  a  functional  transition  are  much
more demanding.
3. System architecture overview
To  introduce  the  elements  of  our  architecture  and
show how they fit together, we begin with an overview,
illustrated in Figure 1. The architecture assumes a dis-
tributed computing platform consisting of an unspeci-
Application 1
Application N
Application interaction
Reconfiguration
signals
Application fault and 
reconfiguration status signals
Reconfiguration
signals
System Control Reconfiguration Analysis and Management Kernel
System
calls
Hardware fault signals
Real-Time Operating System
System
calls
Computing Platform: Processing Units, Communications Facilities, Network Support, Sensors, Etc.
Figure 1. Logical System Architecture
Proceedings of the 2005 International Conference on Dependable Systems and Networks (DSN’05) 
0-7695-2282-3/05 $20.00 © 2005 IEEE
Authorized licensed use limited to: Tsinghua University. Downloaded on March 20,2021 at 12:09:48 UTC from IEEE Xplore.  Restrictions apply. 
fied number of processing elements that communicate
via an ultra-dependable, real-time data bus. Each pro-
cessing  element  consists  of  a  fail-stop  processor  with
associated  volatile  and  stable  storage  that  executes  a
real-time  operating  system.  An  example  fail-stop pro-
cessor might be a self-checking pair; an example data
bus  might  be  one  based  on 
time-triggered
architecture [5];  and  an  example  operating  system
might  be  one  that  complies  with  the  ARINC  653
specification [1]. Sensors and actuators that are used in
typical  control  applications  are  connected  to  the  data
bus via interface units that employ the communications
protocol required by the data bus.
the 
The system that the architecture supports consists of
a set of applications, each of which operates as an inde-
pendent process with no assumptions on how processes
are mapped to platform nodes except that the mapping
is statically determined. Applications communicate via
message  passing  or  by  sharing  state  through  the  pro-
cessors’ stable storage.
provides 
an 
for 
interface 
Each application implements a set of specifications
internal
and 
reconfiguration [6].  Each  specification  for  each  appli-
cation is defined by domain experts; certain specifica-
tion combinations, denoted configurations and defined
in a reconfiguration specification [11], provide accept-
able  services.  Reconfiguration  is  the  transition  from
one  configuration  to  another.  Reconfiguration  and  its
assurance are the heart of our architecture.
System  reconfiguration  is  effected  by  the  System
Control  Reconfiguration  Analysis  and  Management
(SCRAM) kernel. This kernel implements the external
reconfiguration [6]  portion  of  the  architecture  by
receiving  component  failure  signals  when  they  occur
and  determining  necessary  reconfiguration  actions
based on a statically-defined set of valid system transi-
tions. Component failures are detected by conventional
means such as activity, timing, and signal monitors. A
detected  component  failure  is  communicated  to  the
SCRAM  via  an  abstract  signal,  and  the  kernel  effects
reconfiguration  by  sending  sequences  of  messages  to
each application’s reconfiguration interface.
The reconfiguration message sequence causes oper-
ating applications to stop executing their current speci-
fication,  establish  a  postcondition  from  which  a  new
specification can be started, and initiate operation in a
pre-determined  new  specification.  Each  application
meets  prescribed  time  bounds  for  each  stage  of  the
reconfiguration  activity,  thereby  ensuring  that  recon-
figuration is always completed in bounded time.
The  time  and  service  guarantees  that  our  architec-
ture provides hinge on the correct and timely operation
of  the  SCRAM.  A  dependable  implementation  of  this
function could be created in various ways, such as dis-
tributing  it  over  multiple  processors  and  protecting  it
against failure of a subset of those processors, or allo-
cating it to a fail-stop processor so that any faults in its
hardware will be masked. We  do not  address the  spe-
cifics of the SCRAM implementation in this paper.
4. System assumptions