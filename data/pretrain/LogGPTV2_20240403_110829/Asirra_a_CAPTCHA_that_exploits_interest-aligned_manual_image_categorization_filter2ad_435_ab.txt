is has a database of less than 100 manually selected kitten photos.
An attacker can (indeed, already has [12]) expose the database by
manually solving the KittenAuth challenge a few dozen times. An
arbitrary number of challenges can then be solved using an image
comparator robust to simple image distortions.
3. ASIRRA
Asirra surmounts the image-generation problem in a novel way:
by forming a partnership with Petﬁnder.com [9], the world’s largest
web site devoted to ﬁnding homes for homeless pets. Asirra gen-
erates challenges by displaying 12 images from a database of over
three million photographs that have been manually classiﬁed as cats
or dogs. Nearly 10,000 more are added every day by volunteers at
animal shelters throughout the United States and Canada. The size
and accuracy of this database is fundamental to the security pro-
vided by Asirra; it is what differentiates our work from previously
proposed image-based CAPTCHAs.
In exchange for access to Petﬁnder’s database, Asirra provides
an unobtrusive “Adopt me” link beneath each photo. This promotes
Petﬁnder’s primary mission of exposing adoptable pets to potential
new owners. To maximize the probability of successful adoptions,
Asirra will employ IP geolocation to determine the user’s approx-
imate region, and preferentially displays pets that are nearby. The
security implications of this feature are discussed in Section 3.2.1.
Asirra has several attractive features:
• Humans can solve it quickly (§3.1.2) and accurately (§3.1.3).
• Computers can not solve it easily (§3.2).
• Unlike many image-based CAPTCHAs which are abstract
or subjective, Asirra’s challenges are concrete, inoffensive
(cute, by some accounts), require no specialized or cultur-
ally biased knowledge, and have deﬁnite ground truth. This
makes Asirra less frustrating for humans. Some beta-testers
found it fun. The four-year-old child of one asked several
times to “play the cat and dog game again.”
• It promotes an additional social beneﬁt: ﬁnding homes for
homeless animals.
Asirra also has several disadvantages:
• Most CAPTCHAs are implemented as stand-alone program
libraries that can be integrated into a web site without intro-
ducing external dependencies. In contrast, Asirra, like PIX,
is both an algorithm and a database; there is only one in-
stance of it. Therefore, Asirra must be implemented as an
administratively centralized web service that generates and
veriﬁes CAPTCHAs on-demand for all users. (Our scalable
implementation is described in Section 5.)
• Asirra may abruptly lose its security if the database is com-
promised. For example, an attacker may hire cheap labor to
classify all three million images. If this does happen, we may
not even be aware of the attack.
• A typical Asirra challenge requires more screen space than a
traditional text-based CAPTCHA.
• Like virtually all other CAPTCHAs, Asirra is not accessible
to those with visual impairments (§3.3).
Average Accuracy as a function of Image Area
Median Response Time as a function of Image Area
y
c
a
r
u
c
c
A
e
g
a
r
e
v
A
1
0.95
0.9
0.85
0.8
0.75
0.7
0.65
)
s
m
(
i
e
m
T
e
s
n
o
p
s
e
R
n
a
i
d
e
M
1500
1400
1300
1200
1100
1000
900
800
0
5000
10000
15000
20000
25000
30000
0
5000
10000
15000
20000
25000
30000
Image Area (pixels2)
Image Area (pixels2)
Figure 3: Size of an individual image vs. classiﬁcation accuracy in our
test population.
Figure 4: Size of an individual image vs. time required to classify it in
our test population.
3.1 Usability
To quantitatively evaluate Asirra, we performed several user stud-
ies. We also collected data from our live Asirra deployment, which
is described in Section 5.
The user studies, in total, displayed 23,208 cat and dog images to
332 test subjects. The subjects were Microsoft employees, friends,
and family, recruited via postings to internal mailing lists. Our
experiment displayed a random sequence of cat and dog images,
one at a time. Users were asked to identify the species depicted in
each image as it appeared. We used 300 random images from the
Petﬁnder database, each scaled to a random size as described in the
next section. The users’ response time and accuracy were recorded.
To match the conditions of a real CAPTCHA, we implemented the
experiment in the web browser using HTML and JavaScript, and
asked users to participate from their own home or ofﬁce comput-
ers.
The real Asirra web service went live in March of 2007. In the
subsequent 6 weeks, it served about 100,000 challenges. Most of
these were from our own web page that demonstrates Asirra. How-
ever, several dozen web sites (blogs, free services, etc.) have ex-
perimented with integrating Asirra and were responsible for about
13,000 “real” challenges.
In following sections, we characterize various aspects of Asirra’s
performance, based on both the outcome of our user experiments
and data from our deployment.
3.1.1 Best Image Size
Our ﬁrst design question was, “What is the best image size to dis-
play?” We expected larger images to exhibit higher accuracy and
faster response time. However, smaller images have the advantage
of taking up less screen space, making Asirra easier to integrate vi-
sually with the rest of a web page. Smaller images are also faster to
download, which especially important for users with slow Internet
connections.
To ﬁnd the best image size, our ﬁrst user experiment randomly
varied the size of the images from a minimum of 225 total pixels
(about 15x15 pixels square) to a maximum of 30,000 pixels (about
175x175 pixels square). We used total pixels instead of linear di-
mension as our metric because most images are not square. We
collected data from 18,311 displays of images to 185 users.
Figure 3 plots image size vs. average accuracy. Each graph seg-
ment depicts the average of 1/100th (183) of our data points. 10,000
pixels seems to be the sweet spot: larger images show no improve-
ment. (We quantify classiﬁcation accuracy in Section 3.1.3).
3.1.2 Typical Response Time
We also used our ﬁrst experiment to evaluate the effect of image
size on response time. Figure 4 shows the results. We plot the me-
dian response time because it is robust against outliers (e.g., when a
subject receives a phone call during the experiment). 10,000 pixel
images are typically classiﬁed in about 900msec. There does seem
to be a slight (50msec) speed beneﬁt to displaying images larger
than 10,000 pixels. It is also interesting to note from Figures 3 and
4 that smaller images cause degradation in both response time and
accuracy. That is, users spend longer looking at an image but still
end up getting it wrong.
Budgeting 900msec per image, plus a few extra seconds to un-
derstand the task, we expect most users will spend about 15 seconds
solving a single, 12-image Asirra challenge.
3.1.3 Classiﬁcation Accuracy
After our ﬁrst experiment made the best image size clear, we ran
a second user experiment focusing exclusively on images scaled to
10,000 pixels. Our goal was to collect a large number of samples
at our target image size. We collected data from 4,717 displays of
images to 147 users. The overall accuracy rate was 98.5%.
The Asirra challenge has 12 images. Based on a 98.5% per-
image accuracy, 83.4% of users should be able to pass Asirra after
one challenge, 97.2% after two challenges, and 99.5% after three.
However, Asirra uses a novel scheme called the Partial Credit Al-
gorithm, described in Section 4.1, which signiﬁcantly increases the
probability of users passing Asirra while only marginally improv-
ing the yield of a bot. With PCA, we expect 99.6% of users will
solve Asirra after two challenges.
Extracting a good estimate of users’ error rates in the wild is
somewhat more difﬁcult. In our controlled experiment, users were
focused exclusively on image categorization, so errors were clearly
attributable to task difﬁculty. In contrast, the deployed CAPTCHA
is integrated into web forms with many other ﬁelds and informa-
tion. Any click of the form’s “Submit” button causes Asirra to
score the challenge, even if the user had some other intent in mind;
26% of scoring requests received by our server had no response
at all (no cats selected). Of non-null responses scored, 66% were
scored as correct. Note that in this accounting, a user who success-
fully solves Asirra on her second try counts as 50% accuracy (one
right plus one wrong response). In addition, since Asirra is new,
users may sometimes be tinkering: “Oh, what happens if I get one
wrong?”
scribes it as being either a cat or dog. However, this is not ac-
tually a security hole. The adopt-me links are not direct links to
Petﬁnder.com; they lead to the Asirra web service. Asirra provides
a redirection to Petﬁnder.com only after it has marked the challenge
as invalid. (A new challenge is then fetched and displayed.) Asirra
rejects attempts to solve invalidated challenges. In addition, Asirra
only permits redirection for a single adopt-me link per 12-image
challenge. The number of allowed redirections per IP address per
day is also limited, to prevent adopt-me from becoming a vector for
revealing large portions of the database.
Adoption links also have a second, more subtle effect on secu-
rity. Currently, the images shown as a challenge are selected at
random from the entire database of pet images. To maximize its
utility to Petﬁnder, we would ultimately like to restrict the chal-
lenge to pets that are close to the user based on IP geolocation,
and currently available for adoption. These constraints reduce the
usable database for a given user to just a few thousand images,
small enough to be easily exploitable. Our plan, therefore, is to
allow the ﬁrst few challenges per day from an IP address to use
the restricted database; subsequent challenges will be drawn from
the complete collection. We have not yet implemented this feature,
so our challenges currently draw images from Petﬁnder’s complete
image pool, including the history of pets previously available for
adoption.
3.2.2 Brute Force
The simplest attack on Asirra is brute force: Give a random so-
lution to challenges until one succeeds. If an attacker has no basis
for a decision (that is, a 50% probability of success for each image)
brute force will succeed with probability 1/4,096 for a 12-image
challenge. This is a large enough slowdown that it becomes easy
to detect and evade such an attack. We use a token bucket scheme,
described in detail in Section 4.2. Brieﬂy, the scheme penalizes IP
addresses that get many successive wrong answers by forcing them
to answer two challenges correctly within 3 attempts before gain-
ing a ticket. With this scheme in place, attackers can expect only
one service ticket per 5.6 million guesses.
3.2.3 Machine Vision Attacks
While random guessing is the easiest form of attack, various
forms of image recognition can allow an attacker to make guesses
that are better than random. Asirra’s strength, however, comes not
only in the size of its image database, but its diversity. Photos
have a wide variety of backgrounds, angles, poses, lighting, and
so forth—factors that make accurate automatic classiﬁcation difﬁ-
cult. As Figure 6 demonstrates, the variations between photos are
large, but visual differences between cats and dogs are often subtle.
Based on a survey of machine vision literature and vision ex-