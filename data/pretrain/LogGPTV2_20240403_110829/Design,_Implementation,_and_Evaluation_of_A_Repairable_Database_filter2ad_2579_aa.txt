title:Design, Implementation, and Evaluation of A Repairable Database
Management System
author:Tzi-cker Chiueh and
Dhruv Pilania
Design, Implementation, and Evaluation of A Repairable
Database Management System
Tzi-cker Chiueh Dhruv Pilania
Rether Networks Inc.
99 Mark Tree Road, Suite 301, Centereach, NY 11720
PI:EMAIL
Abstract
Although conventional database management sys-
tems are designed to tolerate hardware and to a
lesser extent even software errors, they cannot
protect themselves against syntactically correct
and semantically damaging transactions, which
could arise because of malicious attacks or honest
mistakes. The lack of fast post-intrusion or post-
error damage repair in modern DBMSs results in
a longer Mean Time to Repair (MTTR) and some-
times permanent data loss that could have been
saved by more intelligent repair mechanisms. In
this paper, we describe the design and implemen-
tation of Phoenix - a system that signiﬁcantly im-
proves the efﬁciency and precision of a database
damage repair process after an intrusion or oper-
ator error and thus, increases the overall database
system availability. The two key ideas underly-
ing Phoenix are (1) maintaining persistent inter-
transaction dependency information at run time
to allow selective undo of database transactions
that are considered “infected” by the intrusion or
error in question and (2) exploiting information
present in standard database logs for fast selec-
tive undo. Performance measurements on a fully
operational Phoenix prototype, which is based on
the PostgreSQL DBMS, demonstrate that Phoenix
incurs a response time and a throughput penalty
of less than 5% and 8%, respectively, under the
TPC-C benchmark, but it can speed up the post-
intrusion database repair process by at least an or-
der of magnitude when compared with a manual
repair process.
1 Introduction
Database management systems are an indispensable com-
ponent of modern Internet services and are typically re-
sponsible for storing and providing access to mission-
critical data. As DBMSs become more accessible over the
network, they are also more susceptible to malicious at-
tacks from remote sites, e.g., SQL Slammer [19]. On the
other hand, because DBMS holds information that is criti-
cal to the continuous functioning of Internet services, high
DBMS availability is absolutely essential. Although the
original motivation for this work is survivability, i.e., ability
to quickly recover from malicious security break-ins, the
same mechanism is equally effective for repairing database
damage caused by human errors. However, for the rest of
this paper, we will focus only on intrusion damage.
There is a fundamental difference between a security
breach and a hardware failure: Unlike a hardware failure, a
security breach cannot always be detected immediately. the
interval between when an intrusion takes place The detec-
tion window is the interval between when an intrusion takes
place and when it is detected. Data entered during the de-
tection window and not infected by the intrusion should not
be affected by the post-intrusion repair process. We use the
word “repair” rather than “recover” to emphasize the ad-
ditional, often manual, efforts required to preserve useful
data in the process of restoring the database back to normal
operation.
Today, system administrators have two choices when it
comes to repairing a database corrupted by an intrusion.
First, they can restore the entire database back to the state
before the intrusion took place. This approach is simple
and fast, but could lead to loss of non-infected data cre-
ated during the detection window. Alternatively, they can
attempt to preserve the non-infected data as much as possi-
ble by manually removing all the side effects of the intru-
sion. However, this approach is labor-intensive, and thus
time-consuming and error-prone. A repairable DBMS can
minimize the post-intrusion repair time while preserving as
much non-infected data as possible, thus achieving the best
of both worlds.
Availability is deﬁned as the ratio between mean time
to failure (MTTF) and the sum of MTTF and mean time to
repair (MTTR) (availability = M T T F/M T T R), where
failure in this case corresponds to a successful attack. To
maximize the availability metric, one can either increase
Proceedings of the 21st International Conference on Data Engineering (ICDE 2005) 
1084-4627/05 $20.00 © 2005 IEEE
the MTTF to inﬁnity or decrease the MTTR to zero.
In
contrast to most traditional database security mechanisms,
which aim at maximizing the MTTF, the approach de-
scribed in this paper attempts to minimize the MTTR, or
fast repair of database damage left by security breaches,
thus improving a DBMS’s dependability by increasing it’s
availability.
There are two justiﬁcations for the MTTR minimization
approach toward highly available DBMS. First, the effec-
tiveness of existing database security mechanisms, such as
integrity constraints, embedded rules in transactions, SQL
and OS-based access control etc., is reaching a plateau.
Consequently, it is becoming more and more difﬁcult and
expensive to further improve the MTTF. Comparatively, the
MTTR minimization approach receives relatively less at-
tention. Second, it is generally believed that there is no
such thing as an unbreakable system. For example, attacks
based on social engineering, password stealing, or insider
information, are almost impossible to prevent. When these
attacks occur, the best one can hope for is to restore the
system back to normal operation as quickly as possible.
Attacks on DBMSs fall into two categories: transaction
level or OS level. In a transaction level attack, the attacker
assaults a DBMS through database transactions that per-
form syntactically correct but semantically damaging up-
dates. An OS level attack exploits security weaknesses in
the underlying operating system – networking and ﬁle sys-
tem – on which a DBMS runs, and compromises database
images directly. Between the two, transaction level attacks
are more difﬁcult to detect because they look exactly the
same as normal database transactions. An example transac-
tion level attack is to extend a user-input SQL query string
with some other damaging queries that eventually delete
that user’s entire database tables.
After an intrusion, currently the only option that
database administrators have is to manually determine the
“damage perimeter” and erase all the identiﬁed corrupted
data. Unfortunately, given the highly complex interactions
among database transactions, especially in a high-volume
E-service site, it is next to impossible to determine how the
transactions issued by intruders impact the database before
the intrusion is detected. As a result, a common approach
that database administrators take to repair intrusion dam-
age is to roll the database back to where it was before the
start of the ﬁrst intruder transaction. While this approach is
conceptually simple and does eliminate all damage caused
by malicious transactions, it also throws away all the useful
work produced between the occurrence of an attack and its
detection.
A more desirable alternative is to determine the exact
extent of intrusion damage, and undo only those transac-
tions that are considered corrupted by the attack. Phoenix
takes exactly this approach both to increase the amount of
useful work preserved across intrusion and to speed up the
repair process. More speciﬁcally, Phoenix tracks and main-
tains inter-transaction dependency at run time to determine
the exact extent of damage caused by an intrusion, and ex-
ploits standard database logs to support single-assignment
update semantics and thus the ability to roll back commit-
ted transactions.
We have built a fully operational Phoenix prototype
based on PostgreSQL, which was chosen because Phoenix
requires modiﬁcations to the DBMS kernel. PostgreSQL
is currently the most advanced open-source DBMS with
transaction support and is now a part of Red Hat’s Linux
distribution.
It supports all the features of a fully func-
tional commercial DBMS including ACID guarantees for
transactions, write ahead logging, complex object types,
ODBC/JDBC interfaces, etc.
The rest of this paper is organized as follows. In Sec-
tion 2 we review previous research in the area of intrusion-
resilient data systems in general, and intrusion-resilient
DBMS in particular. Section 3 describes the system archi-
tecture of Phoenix. Section 4 presents the software archi-
tecture and implementation details of the current Phoenix
prototype. Section 5 provides the results of a detailed per-
formance study of the Phoenix prototype based on the TPC-
C workload. Section 6 summarizes this paper with its main
contributions and an outline of on-going work.
2 Related Work
Oracle 9i supports a feature called Flashback query [1] that
allows end users to post a query against a database state
at a particular point in time in the past. This feature is
built upon the WAL log and can be used for building self-
correcting applications that need to undo effects of cer-
tain transactions without point-in-time rollback. The Ingres
database system from Computer Associates Inc. supports
point-in-time rollback and roll-forward using journal-based
recovery [2].
In this approach, journal ﬁles containing
changes to database tables are maintained and analyzed to
reconstruct the database state at the time point in question.
Although these two commercial database features provide
nice “history query” capabilities, they themselves do not
allow intrusion tolerance for two reasons. First, they do
not support selective undo of database transactions that take
place between the current time and the time point of inter-
est. Second, they do not solve the problem of determining
which transactions to undo, or the extent of database dam-
age due to an attack.
There have been several research projects on post-
intrusion database damage repair. Ammann et al. [4] pro-
posed a transaction model and associated protocols that
allow normal transactions to proceed against a database
whose portions are known to be damaged as a result of
an intrusion. The proposal is largely a theoretical exercise
without detailed system-level considerations. Peng Liu et
al. [5] [6] described a concrete intrusion tolerant database
system called ODAM, which can continue its transaction
Proceedings of the 21st International Conference on Data Engineering (ICDE 2005) 
1084-4627/05 $20.00 © 2005 IEEE
processing service even in the presence of active attacks.
ODAM logs database updates in terms of SQL-based trans-
actions. Instead of keeping track of inter-transaction depen-
dencies at run time as Phoenix does, ODAM identiﬁes them
at the repair time by analyzing the SQL log. To support
continuous operation, ODAM incorporated several concur-
rency control schemes to detect, assess and repair damaged
databases on the ﬂy without completely stopping the pro-
cessing of new incoming transactions. However, during the
repair time, the effective throughput of the DBMS is de-
graded. ODAM requires both a write log and a read log.
Although a write log is quite common in modern DBMS,
maintaining a read log poses a serious performance over-
head and therefore is not supported in existing DBMS.
ODAM obtains transaction read information by using pre-
deﬁned templates of reads for each transaction. These read
templates are instantiated at the time a transaction runs by
parsing the SQL statements associated with the transaction.
In contrast, Phoenix maintains an inter-transaction depen-
dency graph and thus does not need any read log for re-
covery purpose. Consequently, our approach does not re-
quire any prior knowledge of the transactions and is more
accurate. At present, Phoenix only supports off-line post-
intrusion database repair, but can be extended to support
on-the-ﬂy database repair with proper concurrency control
as in ODAM.
The Repairable File System (RFS) project [11] aims to
improve the speed and precision of post-intrusion damage
repair for NFS servers. Traditionally, ﬁle system recov-
ery uses signatures generated by systems such as Tripwire
[14] to determine corrupted system ﬁles or complete point
in time restoration from backups. Instead, RFS maintains
ﬁle system operation logs and carries out dependency anal-
ysis to provide fast and accurate repair of damage caused
by NFS operations issued by attackers. Phoenix applies
the same set of principles used in RFS to build intrusion-
resilient database systems.
Finally, it should be noted that Phoenix is different from
standard database back-up systems in that it backs up ev-
ery database update and keeps track of inter-transaction
dependencies at run time. Phoenix is also different from
data mirroring/replication systems because the latter sim-
ply make the same mistake twice in the presence of intru-
sion or errors, and do nothing to improve the accuracy or
performance of post-intrusion damage repair.
The Recovery Oriented Computing (ROC) project
[15] [16] advocates a radical shift from a performance-
dominated research focus to the focus of improving sys-
tem availability by reducing MTTR and eventually the
overall system ownership cost. One of the applications
that is currently being pursued, an undoable email system
[15], shares a similar approach with Phoenix, but focuses
speciﬁcally on email message protection rather than gen-
eral databases.
The Dali system [18] from Bell Labs took a similar
inter-transaction dependency tracking approach to elimi-
nate transactions that have been corrupted by an application
which runs in the same address space as the database. The
Dali approach keeps track of the read-dependency set of
each transaction and is mainly for main memory database
management.
3 The Phoenix Approach
The ultimate goal of the Phoenix project is to develop a
modular system that can be plugged into an existing DBMS
and makes it intrusion-resilient without any modiﬁcation
to the host DBMS. Whether this goal is attainable depends
on the availability and ﬂexibility of the “hooks” existing
DBMSs support. Fundamentally, to convert a standard
DBMS into one that is intrusion-resilient, one needs to add
to the DBMS the following capabilities:
• The ability to maintain the before images of all
database updates so that each database update is un-
doable, and
• The ability to keep track of the dependencies among
transactions, so that it is possible to determine pre-
cisely the extent of database damage induced by one
or a set of attack transactions.
3.1 Maintaining Before Image
Every modern DBMS supports database transactions, and
maintains some sort of before image on disk for every
database update, at least after the associated transaction
is committed.
In write-ahead logging, for example, the
undo/redo log records associated with a transaction must
be written to disk before the transaction can be committed.
Theoretically Phoenix can use these “undo” log records
as before images in the damage repair process. However,
there are two issues that make the picture less than ideal.
First, undo log records are usually kept for a shorter period
of time than Phoenix needs. For example, if the protection
window of Phoenix, which is the maximal interval between
an attack and its detection that the system allows and still
is able to support lossless repair, is set to one month, undo
log records need to be kept for one month. Although these
undo records could be kept in the archive log to survive
disk failure, increasing use of disk mirroring and replica-
tion renders archive logs less and less popular in practice.
The second issue is that there is no standardized pro-
gramming interface to access the transaction log and to
apply the log records therein to undo already committed
transactions. One possibility is to automatically derive a
compensating transaction for a transaction that needs to
be undone, and submit the compensating transaction to the
DBMS through its standard access interface. This way no
modiﬁcation to the DBMS is required to support transac-
tion rollback.
Proceedings of the 21st International Conference on Data Engineering (ICDE 2005) 
1084-4627/05 $20.00 © 2005 IEEE
3.2 Tracking Inter-Transaction Dependency
Today, to repair intrusion damage on a database, admin-
istrators have no choice but to manually go through the
set of transactions that take place between when an attack
occurs and when it is detected, if they need to eliminate
the effects of those and only those transactions that are af-
fected by the attack. This is obviously a labor-intensive,
error-prone, and time-consuming process, and is also why
MTTR for database damage cannot be signiﬁcantly re-
duced. Phoenix addresses this problem by keeping track
of inter-transaction dependency at run time; therefore at re-
pair time, Phoenix can accurately and automatically deter-
mine the set of transactions that are potentially corrupted
by the intruder’s transaction(s). Presented with these trans-
actions identiﬁed by Phoenix, database administrators can
either choose to reﬁne them further or to rollback their ef-
fects directly.
The notion of inter-transaction dependency is far from
obvious. The most sophisticated deﬁnition of transactional
dependency calls for the semantic analysis of the appli-
cations in which transactions are embedded. For exam-
ple, suppose Transaction A is embedded in Application 1
and Transaction B is embedded in Application 2. At run
time Transaction A retrieves a record that is last updated
by Transaction B. In this case, although there is an inter-
transaction dependency between Transaction A and Trans-
action B, there may not be a real dependency between Ap-
plication 1 and Application 2, because Application 1 never
uses the record that Transaction A retrieves in its applica-
tion logic. Therefore, this inter-transaction dependency can
be safely ignored.
Conversely, even when two transactions do not access
common records, it does not necessarily mean that there
is no dependency between them, because it is possible for
an application to access Record X through Transaction A,
compute a value from Record X, and use the resulting value
to update Record Y through Transaction B. In this case, al-
though Transaction A and B do not share any data, there is
an implicit inter-transaction dependency between Transac-
tion A and Transaction B through the common embedding
application. In the most extreme case, Transaction A is em-
bedded in a different application than Transactions B, but