cuter, in order to better understand where the bottle-necks are.
We believe there are many possible directions for improving Quin-
Executer and therefore we want to get the exact weight of its
performance compared to the protocol’s overall performance.
Since our goal is to check practicality of the protocol in real-
world scenarios, we experimented with live cloud providers, Ama-
zon EC2 and Rackspace Cloud, which are currently among the
largest cloud providers. For our experiments we used the follow-
ing setup: 1) Laptop installed with Windows Vista, Intel 2.2 GHz
CPU, 1 GB of RAM. 2) EC2 virtual machines installed with Win-
dows 2008 32bit, 5 EC2 compute units, 1.7 GB RAM and 160 GB
storage. All are located in Amazon’s Virginia region. 3) Rackspace
virtual machines installed with Windows 2008 32bit, 2 GB RAM,
80 GB storage and default CPU. All are located in Rackspace’s
Chicago datacenter. The average round-trip time between the lap-
top and the clouds was 380ms (for packets of size 10K bytes).
As for the delegated program, we used a simple but very useful
program, Determinant.exe, that computes the determinant of
a given matrix. Although there are algorithms for computing deter-
minant that run in time O(n3) (for n∗ n matrix), we used the naive
algorithm that runs in time O(n!), and uses O(n3) space.
4.4.1 QuinExecuter Performance
In order to isolate the overhead of the QuinExecuter itself,
we ran the following experiments:
1. Execution of the delegated program, Det_quin.exe, which
is Determinant.exe wrapped with our wrapper func-
tion. The overhead of our wrapper function itself is negli-
gible.
2. Execution of PIN with Det_quin.exe, without any instru-
mentation (i.e., pin -- Det_quin.exe). Since PIN is
a dynamic instrumentation tool that uses dynamic transla-
tion (JIT), this gives us an estimation of the overhead of this
translation (the PIN VM).
3. Execution of PIN with Det_quin.exe, with our PIN-tool
(i.e., pin -t quin.dll -- Det_quin.exe). This is
an execution of Det_quin.exe when we only count the
number of executed instructions (by adding instrumentation
code).
4. Execution of PIN with Det_quin.exe, with our PIN-tool,
for N steps (i.e., pin -t quin.dll -- Det_quin
.exe -n N). This is an execution of Det_quin.exe for
N steps when we count the number of executed instructions
and compare it to N. N is the total number of steps of the
execution of Det_quin.exe. This is the heaviest instru-
mentation we use in the protocol since it adds code both
for counting the number of executed instructions and for the
comparison to N.
We ran the above experiments on an Amazon EC2 virtual ma-
chine and on a Rackspace Cloud virtual machine. The left side of
Table 1 shows the results for those experiments. Each experiment
was executed three times. The numbers in the table represent the
average running times in seconds on Amazon EC2 and Rackspace
Cloud, respectively, separated by slashes.
452Matrix
Size
10
11
12
Exp. 1
Exp. 2
Exp. 3
Exp. 4
Quin Total Overhead
2/1
21/19
252/230
3/3
23/21
256/242
7/7
69/67
829/803
15/15
156/143
1899/1720
381
694
2243
Factor
190
33
8
Table 1: Evaluation results of PIN-tool experiments and Quin performance
We can observe (from experiment 2) that PIN itself introduces
an overhead of at least 1-2 seconds. This overhead is very inﬂuenc-
ing for the protocol since Quin executes PIN for each round of the
binary search and for many short executions, so we get that for x
rounds of the binary search we already have an overhead of at least
x seconds, and in most cases this overhead is much larger.
Furthermore, we can see that adding even few instrumentation
instructions increases the running time by large factors.
Those performance results are important, since it gives us a good
estimation of the protocol performance. The protocol starts with
executing Det_quin.exe and counting the number of steps, and
then, continues to an execution of the heavier instrumentation for
overall time that is proportional to the running time of the program
once. So, in theory (without considering network latency, servers’
overheads, etc) we expect that the protocol performance would be
something that is proportional to the sum of the fourth and the ﬁfth
columns. (Note that these sums are bigger by factors of 10 − 20
than the plain execution.)
4.4.2 Performance of the Protocol
We executed several experiments of the full protocol. For each
experiment we ran the protocol several times with one cheating
cloud that cheats on one out of three randomly chosen states. Those
states were chosen to be close to the end of the computation (around
80%−85% of the total number of steps). We added to QuinServer
a code that, when asked, tries to cheat on all conﬁgurations from
some given step. Note that we focus on the efﬁciency of the clouds
since the client’s running time is very small (he just sends short
TCP messages to each cloud, and receives short answers that are
several hundreds of bytes for each round and around 5Kbyte for
the last round).
After evaluating the performance of QuinServer and notic-
ing that its execution is very expensive, we decided to modify the
If (nb − ng) is greater than
underlying protocol as following:
some threshold (e.g., 50M), instead of asking for conﬁguration
(nb−ng)/2+ng the client asks for conﬁguration (nb−ng)/4+ng.
The rest of the protocol is the same. This change is essentially a
tradeoff between the number of rounds (that is increased) and the
number of executed instructions on the cloud (that is decreased pro-
portionally to the distance of the last ng conﬁguration from the last
conﬁguration).
We used one virtual machine on each cloud provider (as our two
clouds) and the laptop as our client. In the right side of Table 1
we show the average running times of the protocol for the program
Determinant.exe. The numbers represent the total Quin run-
ning times as recorded by the client (where only few seconds, com-
bined, are from the client work or from communication latency).
We remark that there are major performance differences, both be-
tween Amazon EC2 and Rackspace Cloud and between different
times of the day. The overhead factors are over the running times
of Det_quin.exe from experiment 1.
We can observe that the overhead of the protocol is reduced when
the original computation time grows. This suggests that the over-
head of the protocol itself is lower, and there are many implemen-
tation overheads. E.g., the PIN VM overhead that adds at least 1-2
seconds for each round and the PIN-tool large overheads we saw
in the previous section. We believe that a product-level implemen-
tation those parts can get much smaller overheads, presumably a
factor of 10-20 times slower on average for all computations.
Recall that the protocol from Section 3 has no overhead for the
servers in case both of them are honest. Therefore, since most of
the time both servers are honest, a more efﬁcient solution would be
that the client starts by simply asking both servers for their answers,
and only in case of inconsistent answers he proceeds to the full
execution of Quin. This gives a solution with no overhead in case
both servers are honest.
4.5 Restrictions and Further Improvements
Adding function stubs. Since the program has to be fully deter-
ministic, it can not call any non-deterministic external libraries or
OS APIs. This restriction can be overcome (to some extent) by
adding function stubs that hide the OS non-deterministic factors.
E.g., fopen() returns a pointer FILE* that points to some non
deterministic address. One could implement the functions ex_fo-
pen() and ex_fread() that instead of working with FILE*,
they work with some ﬁle identiﬁers that are generated determinis-
tically. Those functions use an internal table to translate that iden-
tiﬁer to a matching FILE* pointer and call the required fopen()
or fread(). Last, QuinExecuter should treat calls to ex_fo-
pen() or ex_fread() as single instructions. Note that this
workaround can work only for functions that are non-deterministic
because of the OS implementation, and it can not work with func-
tions that are non-deterministic by deﬁnition (e.g., functions that
return current time or a packet from the network).
Different Operating Systems. Currently Quin runs only on Win-
dows because we make use of some of the Windows Loader low-
level properties. Since PIN supports Windows and Linux, under
minor changes to our PIN-tool, QuinExecuter can be used also
in Linux. As the delegated program is a plain stand-alone C pro-
gram that can be executed on any OS, and since QuinClient
and QuinServer are OS independent, an interesting improve-
ment would be to generalize QuinExecuter to be OS indepen-
dent.
Support any X86 executable. Our current prototype requires build-
ing the delegated executable with our supplied makeﬁle. We stress
that it is a design decision since our future goal is to replace the
use of our makeﬁle (that adds the wrapper function) with another
binary instrumentation, in a way that our PIN-tool could work di-
rectly with any stand-alone executable (e.g. commodity software).
Static Instrumentation instead of Dynamic Instrumentation. The
functionalities we need from PIN can be achieved by static instru-
mentation, which is much more efﬁcient for cases of instrument
once, run many times. We saw in our evaluation that QuinExecut-
er adds the largest overhead of the implementation, therefore, any
performance improvement of it will dramatically improve the per-
formance of the overall protocol.
There are several static instrumentation frameworks for Linux
453environments (e.g., DynInst [2], PEBIL [16]), but we did not ﬁnd a
convenient framework that works also for Windows executables.
Using several computers in each cloud. Since the main bottle-
neck of our implementation is the executions of QuinExecuter,
we can use the following trick to reduce the overheads. Instead of
running QuinExecuter separately for each query, the cloud can
use several computers (or other CPU cores) and execute different
executions of QuinExecuter in parallel. E.g., when queried for
conﬁguration i, the cloud executes QuinExecuter for i steps on
one machine, but also QuinExecuter for i + (nb− i)/2 steps on
a second machine. Then, if the next query is for step i+(nb−i)/2,
the cloud could answer with the result sooner than in the sequential
protocol.
Also, using parallel executions of QuinExecuter, we can ef-
ﬁciently reduce the number of rounds to logt+1 T + 3 as described
in Section 3.4.
Implementation for Interpreted Languages. As discussed be-
fore, interpreted languages such as Java and Python have complex
interpreters that usually maintain an internal state that depends on
many factors other then the program itself (e.g., garbage collector’s
tables). However, those interpreters already do many operations
that we can use (e.g., most interpreters do just-in-time compilation,
or have stubs for system calls). Therefore, if we could modify them
to be more deterministic, we might gain a very efﬁcient solution.
During our work we have investigated several interpreters and we
believe that the above can be done.
Another environment that is potentially relevant for our proto-
col is the Platform as a Service (e.g., Google App Engine), which
usually provides kind of a stand-alone computation delegation ser-
vice for one process and a restricted set of “system calls”. Imple-
mentation of our protocol for interpreted languages may be very
appealing for such services.
5. REFERENCES
[1] BOINC, Validation and replication. http://boinc.
berkeley.edu/trac/wiki/ValidationSummary.
[2] DynInst, an application program interface for runtime code
generation. http://www.dyninst.org.
[3] PyEmu, a python IA-32 emulator.
http://code.google.com/p/pyemu.
[4] Quin’s source code.
http://www.cs.tau.ac.il/~benriva/quin.
[5] B. Applebaum, Y. Ishai, and E. Kushilevitz. From secrecy to
soundness: efﬁcient veriﬁcation via secure computation. In
Proceedings of the 37th international colloquium conference
on Automata, languages and programming, pages 152–163.
Springer-Verlag, 2010.
[6] S. Arora and S. Safra. Probabilistic checking of proofs: a
new characterization of NP. J. ACM, 45:70–122, January
1998.
[7] L. Babai, L. Fortnow, L. A. Levin, and M. Szegedy.
Checking computations in polylogarithmic time. In
Proceedings of the twenty-third annual ACM symposium on
Theory of computing, pages 21–32. ACM, 1991.
[8] M. Ben-Or, S. Goldwasser, J. Kilian, and A. Wigderson.
Multi-prover interactive proofs: how to remove intractability
assumptions. In Proceedings of the twentieth annual ACM
symposium on Theory of computing, pages 113–131. ACM,
1988.
[9] K. M. Chung, Y. Kalai, and S. Vadhan. Improved delegation
of computation using fully homomorphic encryption. In
Proceedings of the 30th annual conference on Advances in
cryptology, pages 483–501. Springer-Verlag, 2010.
[10] U. Feige and J. Kilian. Making games short (extended
abstract). In Proceedings of the twenty-ninth annual ACM
symposium on Theory of computing, pages 506–516. ACM,
1997.
[11] R. Gennaro, C. Gentry, and B. Parno. Non-interactive
veriﬁable computing: outsourcing computation to untrusted
workers. In Proceedings of the 30th annual conference on
Advances in cryptology, pages 465–482. Springer-Verlag,
2010.
[12] S. Goldwasser, Y. T. Kalai, and G. N. Rothblum. Delegating
computation: interactive proofs for muggles. In Proceedings
of the 40th annual ACM symposium on Theory of computing,
pages 113–122. ACM, 2008.
[13] P. Golle and I. Mironov. Uncheatable distributed
computations. In Proceedings of the 2001 Conference on
Topics in Cryptology: The Cryptographer’s Track at RSA,
pages 425–440. Springer, 2001.
[14] A. Haeberlen, P. Kuznetsov, and P. Druschel. PeerReview:
Practical accountability for distributed systems. In
Proceedings of the 21st ACM Symposium on Operating
Systems Principles, pages 175–188. ACM, 2007.
[15] J. Kilian. A note on efﬁcient zero-knowledge proofs and
arguments (extended abstract). In Proceedings of the
twenty-fourth annual ACM symposium on Theory of
computing, pages 723–732. ACM, 1992.
[16] M. Laurenzano, M. M. Tikir, L. Carrington, and A. Snavely.
PEBIL: Efﬁcient static binary instrumentation for linux. In
ISPASS, pages 175–183, 2010.
[17] C. K. Luk, R. Cohn, R. Muth, H. Patil, A. Klauser,
G. Lowney, S. Wallace, V. J. Reddi, and K. Hazelwood. Pin:
building customized program analysis tools with dynamic
instrumentation. In Proceedings of the 2005 ACM SIGPLAN
conference on Programming language design and
implementation, pages 190–200. ACM, 2005.
[18] J. M. McCune, B. J. Parno, A. Perrig, M. K. Reiter, and
H. Isozaki. Flicker: an execution infrastructure for tcb
minimization. In Proceedings of the 3rd ACM
SIGOPS/EuroSys European Conference on Computer
Systems 2008, pages 315–328. ACM, 2008.
[19] R. C. Merkle. A digital signature based on a conventional
encryption function. In A Conference on the Theory and
Applications of Cryptographic Techniques on Advances in
Cryptology, pages 369–378. Springer-Verlag, 1988.
[20] S. Micali. Computationally sound proofs. SIAM J. Comput.,
30:1253–1298, October 2000.
[21] F. Monrose, P. Wycko, and A. D. Rubin. Distributed
execution with remote audit. In Proceedings of the 1999
ISOC Network and Distributed System Security Symposium,
pages 103–113. The Internet Society, 1999.
[22] E. Shi, A. Perrig, and L. V. Doorn. Bind: A ﬁne-grained
attestation service for secure distributed systems. In
Proceedings of the 2005 IEEE Symposium on Security and
Privacy, pages 154–168. IEEE Computer Society, 2005.
454