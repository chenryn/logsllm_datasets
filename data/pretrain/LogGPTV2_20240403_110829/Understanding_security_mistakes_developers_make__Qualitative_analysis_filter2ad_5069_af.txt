study of 94 program submissions to a secure-programming
contest, each implementing one of three non-trivial, security-
relevant programming problems. Over about six months, we
labeled 182 unique security vulnerabilities (some from the
866 exploits produced by competitors, some we found our-
selves) according to type, attacker control, and exploitability,
using iterative open coding. We also coded project features
aligned with security implementation. We found implementa-
tion mistakes were comparatively less common than failures
in security understanding—78% of projects failed to imple-
ment a key part of a defense, or did so incorrectly, while
21% made simple mistakes. Our results have implications for
improving secure-programming APIs, API documentation,
vulnerability-ﬁnding tools, and security education.
Acknowledgments
We thank the anonymous reviewers who provided helpful
comments on drafts of this paper. This project was supported
by gifts from Accenture, AT&T, Galois, Leidos, Patriot Tech-
nologies, NCC Group, Trail of Bits, Synposis, ASTech Con-
sulting, Cigital, SuprTek, Cyberpoint, and Lockheed Martin;
by NSF grants EDU-1319147 and CNS-1801545; and by
the U.S. Department of Commerce, National Institute for
Standards and Technology, under Cooperative Agreement
70NANB15H330.
References
[1] R. Abu-Salma, M. A. Sasse, J. Bonneau, A. Danilova, A. Naiakshina,
and M. Smith. Obstacles to the adoption of secure communication
tools. In IEEE Symposium on Security and Privacy, pages 137–153,
May 2017.
[3] Yasemin Acar, Michael Backes, Sascha Fahl, Doowon Kim, Michelle L
Mazurek, and Christian Stransky. You get where you’re looking for:
The impact of information sources on code security. In IEEE Sympo-
sium on Security and Privacy, pages 289–305. IEEE, 2016.
[4] Yasemin Acar, Christian Stransky, Dominik Wermke, Michelle L
Mazurek, and Sascha Fahl. Security developer studies with github
In Symposium on Usable
users: Exploring a convenience sample.
Privacy and Security, pages 81–95, 2017.
[5] Nuno Antunes and Marco Vieira. Comparing the effectiveness of pene-
tration testing and static code analysis on the detection of sql injection
In IEEE Paciﬁc Rim International
vulnerabilities in web services.
Symposium on Dependable Computing, pages 301–306, Washington,
DC, USA, 2009. IEEE Computer Society.
[6] Philippe Arteau, Andrey Loskutov, Juan Dodero, and Kengo Toda.
Spotbugs. https://spotbugs.github.io/, 2019.
[7] Steven Arzt, Siegfried Rasthofer, Christian Fritz, Eric Bodden, Alexan-
dre Bartel, Jacques Klein, Yves Le Traon, Damien Octeau, and Patrick
McDaniel. Flowdroid: Precise context, ﬂow, ﬁeld, object-sensitive and
lifecycle-aware taint analysis for android apps. ACM SIGPALN Notices,
49(6):259–269, 2014.
[8] Hala Assal and Sonia Chiasson. Security in the software development
lifecycle. In Symposium on Usable Privacy and Security, pages 281–
296, Baltimore, MD, 2018. USENIX Association.
[9] Andrew Austin and Laurie Williams. One technique is not enough:
A comparison of vulnerability discovery techniques. In International
Symposium on Empirical Software Engineering and Measurement,
pages 97–106, Washington, DC, USA, 2011. IEEE Computer Society.
[10] Dejan Baca, Bengt Carlsson, Kai Petersen, and Lars Lundberg. Improv-
ing software security with static automated code analysis in an industry
setting. Software: Practice and Experience, 43(3):259–279, 2013.
[11] Yoav Benjamini and Yosef Hochberg. Controlling the False Discovery
Rate: A Practical and Powerful Approach to Multiple Testing. Journal
of the Royal Statistical Society. Series B (Methodological), 57(1):289–
300, 1995.
[12] Diana Burley, Matt Bishop, Scott Buck, Joseph J. Ekstrom, Lynn
Futcher, David Gibson, Elizabeth K. Hawthorne, Siddharth Kaza, Yair
Levy, Herbert Mattord, and Allen Parrish. Curriculum guidelines for
post-secondary degree programs in cybersecurity. Technical report,
ACM, IEEE, AIS, and IFIP, 12 2017.
[13] Cristian Cadar, Daniel Dunbar, and Dawson Engler. Klee: Unassisted
and automatic generation of high-coverage tests for complex systems
programs. In USENIX Conference on Operating Systems Design and
Implementation, pages 209–224. USENIX Association, 2008.
[14] Cristiano Calcagno and Dino Distefano. Infer: An automatic program
veriﬁer for memory safety of c programs. In Mihaela Bobaru, Klaus
Havelund, Gerard J. Holzmann, and Rajeev Joshi, editors, NASA Formal
Methods, pages 459–465. Springer Berlin Heidelberg, 2011.
[15] A Colin Cameron and Pravin K Trivedi. Regression Analysis of Count
Data, volume 53. Cambridge University Press, 2013.
[16] Ryan Camille.
Computer and internet use in the united
states:2016. https://www.census.gov/library/publications/
2018/acs/acs-39.html, 2018.
[17] Center for Cyber Safety and Education. Global information security
workforce study. Technical report, Center for Cyber Safety and Educa-
tion, Clearwater, FL, 2017.
[18] Pravir Chandra. Software assurance maturity model. Technical report,
Open Web Application Security Project, 04 2017.
[2] Yasemin Acar, Michael Backes, Sascha Fahl, Simson Garﬁnkel,
Doowon Kim, Michelle L Mazurek, and Christian Stransky. Com-
paring the usability of cryptographic apis. In IEEE Symposium on
Security and Privacy, pages 154–171. IEEE, 2017.
[19] Yung-Yu Chang, Pavol Zavarsky, Ron Ruhl, and Dale Lindskog. Trend
analysis of the cve for software vulnerability management. In Inter-
national Conference on Social Computing, pages 1290–1293. IEEE,
2011.
122    29th USENIX Security Symposium
USENIX Association
[20] Steve Christey and Robert A Martin. Vulnerability type distribu-
tions in cve. https://cwe.mitre.org/documents/vuln-trends/
index.html, 2007.
[37] William R. Harris, Somesh Jha, Thomas W. Reps, and Sanjit A. Seshia.
Program synthesis for interactive-security systems. Formal Methods
System Design, 51(2):362–394, November 2017.
[21] J. Cohen. Statistical Power Analysis for the Behavioral Sciences.
Lawrence Erlbaum Associates, 1988.
[22] Harald Cramér. Mathematical Methods of Statistics (PMS-9), volume 9.
Princeton University Press, 2016.
[23] Felix Dörre and Vladimir Klebanov. Practical detection of entropy
loss in pseudo-random number generators. In ACM Conference on
Computer and Communications Security, pages 678–689, 2016.
[24] Adam Doupé, Marco Cova, and Giovanni Vigna. Why johnny can’t
pentest: An analysis of black-box web vulnerability scanners. In In-
ternational Conference on Detection of Intrusions and Malware, and
Vulnerability Assessment, pages 111–131, Berlin, Heidelberg, 2010.
Springer-Verlag.
[25] Anne Edmundson, Brian Holtkamp, Emanuel Rivera, Matthew Finifter,
Adrian Mettler, and David Wagner. An empirical study on the ef-
fectiveness of security code review. In International Conference on
Engineering Secure Software and Systems, pages 197–212, Berlin, Hei-
delberg, 2013. Springer-Verlag.
[26] Manuel Egele, David Brumley, Yanick Fratantonio, and Christopher
Kruegel. An empirical study of cryptographic misuse in android ap-
plications. In ACM Conference on Computer and Communications
Security, pages 73–84. ACM, 2013.
[27] William Enck, Peter Gilbert, Seungyeop Han, Vasant Tendulkar, Byung-
Gon Chun, Landon P. Cox, Jaeyeon Jung, Patrick McDaniel, and An-
mol N. Sheth. Taintdroid: An information-ﬂow tracking system for
realtime privacy monitoring on smartphones. ACM Transactions on
Computer Systems, 32(2):5:1–5:29, 2014.
[28] Sascha Fahl, Marian Harbach, Thomas Muders, Lars Baumgärtner,
Bernd Freisleben, and Matthew Smith. Why eve and mallory love
android: An analysis of android ssl (in)security. In ACM Conference
on Computer and Communications Security, pages 50–61. ACM, 2012.
[29] Matthew Finifter and David Wagner. Exploring the relationship be-
tween web application development tools and security. In USENIX
Conference on Web Application Development, 2011.
[30] FIRST.org. Common vulnerability scoring system. https://www.
first.org/cvss/calculator/3.0, 2016. (Accessed 12-19-2016).
[31] Ronald A Fisher. On the interpretation of χ2 from contingency tables,
and the calculation of p. Journal of the Royal Statistical Society,
85(1):87–94, 1922.
[32] Karl Pearson F.R.S. On the criterion that a given system of deviations
from the probable in the case of a correlated system of variables is
such that it can be reasonably supposed to have arisen from random
sampling. Philosophical Magazine, 50(302):157–175, 1900.
[33] Martin Georgiev, Subodh Iyengar, Suman Jana, Rishita Anubhai, Dan
Boneh, and Vitaly Shmatikov. The most dangerous code in the world:
Validating ssl certiﬁcates in non-browser software. In ACM Conference
on Computer and Communications Security, pages 38–49, New York,
NY, USA, 2012. ACM.
[34] Jennifer Goldbeck, Jonathan Katz, Michael Hicks, and Gang Qu.
Coursera cybersecurity specialization. https://www.coursera.org/
specializations/cyber-security, 2019.
[35] Matthew Green and Matthew Smith. Developers are not the enemy!:
The need for usable security apis. IEEE Security & Privacy, 14(5):40–
46, 2016.
[36] Julie M. Haney, Mary Theofanos, Yasemin Acar, and Sandra Spickard
Prettyman. “we make it a big deal in the company”: Security mindsets
in organizations that develop cryptographic products. In Symposium
on Usable Privacy and Security, pages 357–373, Baltimore, MD, 2018.
USENIX Association.
[38] Andrew F Hayes and Klaus Krippendorff. Answering the call for a
standard reliability measure for coding data. Communication Methods
and Measures, 1(1):77–89, 2007.
[39] Mariana Hentea, Harpal S Dhillon, and Manpreet Dhillon. Towards
changes in information security education. Journal of Information
Technology Education: Research, 5:221–233, 2006.
[40] David Hovemeyer and William Pugh. Finding bugs is easy. ACM
SIGPLAN Notices, 39(12):92–106, December 2004.
[41] IEEE.
IEEE spectrum: The top programming languages
2018. https://spectrum.ieee.org/static/interactive-the-
top-programming-languages-2018, 2018.
[42] Melanie Jones. Why cybersecurity education matters.
https:
//www.itproportal.com/features/why-cybersecurity-
education-matters/, 2019.
[43] Vasileios P. Kemerlis, Georgios Portokalidis, Kangkook Jee, and An-
gelos D. Keromytis. Libdft: Practical dynamic data ﬂow tracking
for commodity systems. In ACM Conference on Virtual Execution
Environments, pages 121–132, 2012.
[44] Nick Kolakowski. Software developer jobs will increase through
https://insights.dice.com/2019/01/03/software-
2026.
developer-jobs-increase-2026/, 2019.
[45] Stefan Krüger, Johannes Späth, Karim Ali, Eric Bodden, and Mira
Mezini. CrySL: An Extensible Approach to Validating the Correct
Usage of Cryptographic APIs. In Todd Millstein, editor, European Con-
ference on Object-Oriented Programming, pages 10:1–10:27, Dagstuhl,
Germany, 2018. Schloss Dagstuhl–Leibniz-Zentrum fuer Informatik.
[46] David Lazar, Haogang Chen, Xi Wang, and Nickolai Zeldovich. Why
does cryptographic software fail?: A case study and open problems. In
Asia-Paciﬁc Workshop on Systems, page 7. ACM, 2014.
[47] Timothy C Lethbridge, Jorge Diaz-Herrera, Richard Jr J LeBlanc, and
J Barrie Thompson. Improving software practice through education:
Challenges and future trends. In Future of Software Engineering, pages
12–28. IEEE Computer Society, 2007.
[48] Gary McGraw, Sammy Migues, and Brian Chess. Software security
framework | bsimm, 2009. (Accessed 05-22-2018).
[49] Gary McGraw and John Steven. Software [in]security: Comparing
apples, oranges, and aardvarks (or, all static analysis tools are not cre-
ated equal. http://www.informit.com/articles/article.aspx?
p=1680863, 2011. (Accessed 02-26-2017).
[50] A. Meneely, H. Srinivasan, A. Musa, A. R. Tejeda, M. Mokary, and
B. Spates. When a patch goes bad: Exploring the properties of
vulnerability-contributing commits. In International Symposium on
Empirical Software Engineering and Measurement, pages 65–74, Oct
2013.
[51] Andrew Meneely, Alberto C Rodriguez Tejeda, Brian Spates, Shannon
Trudeau, Danielle Neuberger, Katherine Whitlock, Christopher Ketant,
and Kayla Davis. An empirical investigation of socio-technical code
review metrics and security vulnerabilities. In International Workshop
on Social Software Engineering, pages 37–44. ACM, 2014.
[52] Andrew Meneely and Oluyinka Williams. Interactive churn metrics:
Socio-technical variants of code churn. ACM Software Engineering
Notes, 37(6):1–6, 2012.
[53] Microsoft. Microsoft security development lifecycle practices.
https://www.microsoft.com/en-us/securityengineering/
sdl/practices, 2019.
[54] MITRE. Cve. https://cve.mitre.org/, 2019.
[55] MITRE. Cwe: Common weakness enumeration. https://cwe.mitre.
org/data/definitions/1000.html/, 2019.
USENIX Association
29th USENIX Security Symposium    123
[56] Alena Naiakshina, Anastasia Danilova, Eva Gerlitz, Emanuel von
Zezschwitz, and Matthew Smith. “if you want, i can store the encrypted
password”: A password-storage ﬁeld study with freelance developers.
In Conference on Human Factors in Computing Systems, pages 140:1–
140:12, New York, NY, USA, 2019. ACM.
[57] Alena Naiakshina, Anastasia Danilova, Christian Tiefenau, Marco Her-
zog, Sergej Dechand, and Matthew Smith. Why do developers get
password storage wrong?: A qualitative usability study. In ACM Con-
ference on Computer and Communications Security, pages 311–328.
ACM, 2017.
[58] Alena Naiakshina, Anastasia Danilova, Christian Tiefenau, and
Matthew Smith. Deception task design in developer password studies:
Exploring a student sample. In Symposium on Usable Privacy and
Security, pages 297–313, Baltimore, MD, 2018. USENIX Association.
[59] William Newhouse, Stephanie Keith, Benjamin Scribner, and Greg
Witte. Nist special publication 800-181, the nice cybersecurity work-
force framework. Technical report, National Institute of Standards and
Technology, 08 2017.
[60] Daniela Seabra Oliveira, Tian Lin, Muhammad Sajidur Rahman, Rad
Akeﬁrad, Donovan Ellis, Eliany Perez, Rahul Bobhate, Lois A. DeLong,
Justin Cappos, and Yuriy Brun. API blindspots: Why experienced
developers write vulnerable code. In Symposium on Usable Privacy and
Security, pages 315–328, Baltimore, MD, 2018. USENIX Association.
[61] OWASP. Top 10-2017 top 10. https://www.owasp.org/index.
php/Top_10-2017_Top_10, 2017.
[62] Henning Perl, Sergej Dechand, Matthew Smith, Daniel Arp, Fabian
Yamaguchi, Konrad Rieck, Sascha Fahl, and Yasemin Acar. Vccﬁnder:
Finding potential vulnerabilities in open-source projects to assist code
audits. In ACM Conference on Computer and Communications Security,
pages 426–437, New York, NY, USA, 2015. ACM.
[63] Adrian E Raftery. Bayesian model selection in social research. Socio-
logical Methodology, pages 111–163, 1995.
[64] Bradley Reaves, Nolen Scaife, Adam M Bates, Patrick Traynor, and
Kevin RB Butler. Mo (bile) money, mo (bile) problems: Analysis of
branchless banking applications in the developing world. In USENIX
Security Symposium, pages 17–32, 2015.
[65] Tony Rice, Josh Brown-White, Tania Skinner, Nick Ozmore, Nazira
Carlage, Wendy Poland, Eric Heitzman, and Danny Dhillon. Funda-
mental practices for secure software development. Technical report,
Software Assurance Forum for Excellence in Code, 04 2018.
[66] Andrew Ruef, Michael Hicks, James Parker, Dave Levin, Michelle L.
Mazurek, and Piotr Mardziel. Build it, break it, ﬁx it: Contesting secure
development. In ACM Conference on Computer and Communications
Security, pages 690–703, New York, NY, USA, 2016. ACM.
[67] Nick Rutar, Christian B. Almazan, and Jeffrey S. Foster. A comparison
of bug ﬁnding tools for java. In International Symposium on Software
Reliability Engineering, pages 245–256, Washington, DC, USA, 2004.
IEEE Computer Society.
[68] J. H. Saltzer and M. D. Schroeder. The protection of information in
computer systems. In Symposium on Operating System Principles,
pages 1278–1308, Sep. 1975.
[69] Riccardo Scandariato, James Walden, and Wouter Joosen. Static analy-
sis versus penetration testing: A controlled experiment. In International
Symposium on Software Reliability Engineering, pages 451–460. IEEE,
2013.
[70] K Serebryany.
html, 2015.
libfuzzer.
https://llvm.org/docs/LibFuzzer.
[71] Y. Shoshitaishvili, R. Wang, C. Salls, N. Stephens, M. Polino,
A. Dutcher, J. Grosen, S. Feng, C. Hauser, C. Kruegel, and G. Vigna.
Sok: (state of) the art of war: Offensive techniques in binary analysis.
In IEEE Symposium on Security and Privacy, pages 138–157, 2016.
[72] Yan Shoshitaishvili, Michael Weissbacher, Lukas Dresel, Christopher
Salls, Ruoyu Wang, Christopher Kruegel, and Giovanni Vigna. Rise
of the hacrs: Augmenting autonomous cyber reasoning systems with
human assistance. In ACM Conference on Computer and Communica-
tions Security. ACM, 2017.
[73] Jacek ´Sliwerski, Thomas Zimmermann, and Andreas Zeller. When do
changes induce ﬁxes? ACM Software Engineering Notes, 30(4):1–5,
May 2005.
[74] Anselm Strauss and Juliet Corbin. Basics of Qualitative Research,
volume 15. Newbury Park, CA: Sage, 1990.
[75] Larry Suto. Analyzing the effectiveness and coverage of web applica-
tion security scanners. Technical report, BeyondTrust, Inc, 2007.
[76] Larry Suto. Analyzing the accuracy and time costs of web application
security scanners. Technical report, BeyondTrust, Inc, 2010.
[77] Patrick Thibodeau.
India to overtake u.s. on number of devel-
https://www.computerworld.com/article/
opers by 2017.
2483690/it-careers/india-to-overtake-u-s--on-number-
of-developers-by-2017.html, 2013.
[78] Tyler W. Thomas, Madiha Tabassum, Bill Chu, and Heather Lipford.
Security during application development: An application security ex-
In Conference on Human Factors in Computing
pert perspective.
Systems, pages 262:1–262:12, New York, NY, USA, 2018. ACM.
[79] D. Votipka, R. Stevens, E. Redmiles, J. Hu, and M. Mazurek. Hackers
vs. testers: A comparison of software vulnerability discovery processes.
In IEEE Symposium on Security and Privacy, pages 374–391, May
2018.
[80] Arnold D Well and Jerome L Myers. Research Design & Statistical
Analysis. Psychology Press, 2nd edition, 2003.
[81] Michal Zalewski. American fuzzing lop (aﬂ). http://lcamtuf.