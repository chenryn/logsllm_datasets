then dumped a hidden malicious library and modiﬁed the .bashrc
ﬁle to setup environment variable LD_PRELOAD such that the ma-
licious library would be injected into all processes the user invoked
from shell. Worse, if the user has administrative privileges, the
viewer can also create an alias on sudo, such that a rootkit would
be installed silently when user performs an administrative action.
Although the viewer still got compromised on our system, the
user was not inconvenienced: while she could view the document,
modiﬁcation attempts on .bashrc were denied, and hence malware
attempts to subvert and/or infect the system were thwarted.
5.4 Performance
Benign
Overhead
σ
0.01%
2.61%
1.43%
4.57%
openssl
Firefox
Untrusted
Overhead
-0.06%
4.42%
σ
0.70%
5.14%
Figure 7: Runtime overhead for Firefox and OpenSSL.
Figure 7 shows the overhead of openssl and Firefox when
compared with unprotected systems. We obtained the statistics us-
ing speed option in openssl. As for Firefox, we used pageloader
addon to measure the page load time. Pages from top 1200 Alexa
sites were fetched locally such that overheads due to networking
is eliminated. The overhead on openssl benchmark is negligible.
The average overhead for Firefox is less than 5%.
Figure 8 shows the SPEC2006 benchmark with the highest over-
heads. The overhead is less than 1% for CPU intensive operations.
403.gcc
456.hmmer
458.sjeng
462.libquantum
433.milc
Average
Unprotected
Time (s)
541.2
982.7
933.8
995.4
882.5
Benign
Overhead
-1.99%
0.36%
0.49%
-0.17%
0.85%
-0.10%
Untrusted
Overhead
0.82%
-0.13%
0.51%
0.33%
-2.66%
-0.28%
Figure 8: Highest 5 overhead in SPEC2006, ref input size
226
Unprotected
Time (s)
Benign
Overhead
eclipse
evolution
F-spot
Firefox
gedit
gimp
sofﬁce
6.16
2.44
1.61
1.32
0.82
3.63
1.56
1.99%
2.44%
2.11%
3.24%
5.02%
1.90%
0.33%
Untrusted
Overhead
10.23%
5.04%
6.80%
10.08%
6.09%
4.32%
7.08%
Figure 9: Latency for starting and closing GUI programs
Figure 9 shows the latency for some GUI programs. We mea-
sured the time between starting and closing the applications with-
out using them.
6. Related Work
System-call interposition and sandboxing.
Two of the most popular mechanisms for secure policy enforce-
ment are Linux Security Modules (LSM) [27] and ptrace [19]. The
drawbacks of kernel-based approaches (e.g., LSM) have been elo-
quently argued [12, 10]: kernel programming is more difﬁcult,
leads to less portable code, and creates deployment challenges. Ap-
proaches such as ptrace avoid these drawbacks by enabling pol-
icy enforcement to be performed in a user-level monitoring pro-
cess. However, it poses performance problems due to the frequent
context switches between the monitored and monitoring processes.
More importantly, TOCTTOU attacks are difﬁcult to prevent [9].
Ostia [10] avoided most of these drawbacks by developing a del-
egating architecture for system-call interposition. It used a small
kernel module that permits a subset of “safe” system calls (such as
read and write) for monitored processes, and forwards the remain-
ing calls to a user-level process. Our system’s use of a user-level
helper process was inspired by Ostia. While their approach still re-
quires kernel modiﬁcations, our design is implemented entirely at
user-level by repurposing user access control mechanisms.
While many techniques have been focused on the mechanisms
for conﬁnement, the problem of developing effective policies has
not received as much attention. Some works such as SELinux [17],
Systrace [20] and AppArmor [6] were focused on protecting be-
nign code, and typically rely on a training phase to create a policy.
Such training-based approach is inappropriate for untrusted code.
So Mapbox [3] develops policies based on expected functionality
by dividing applications into various classes. Model-carrying code
[22] provides a framework in which code producers and code con-
sumers can effectively collaborate to come up with good policies.
While it represents a signiﬁcant advance over purely manual de-
velopment of policies, it still does not scale to large numbers of
applications. Supporting entire OS distributions, such as the work
presented in this paper, would require a very large amount of effort.
Both our system and Plash [2] conﬁne untrusted programs by ex-
ecuting them with a userid that has limited accesses in the system.
Additional accesses are granted by a helper process. However, our
focus is on providing compatibility with a wide range of software,
while protecting the integrity of benign processes. We achieve this
goal by systematically sandboxing all code, whereas Plash sand-
boxes only untrusted code with least privilege policies.
Isolation-based Approaches.
Applying two-way isolation for desktop OSes is particularly chal-
lenging because of how applications interact. Fragmented names-
pace, and excessive efforts needed to maintain multiple working
environments make two-way isolation less attractive.
227
In contrast, two-way isolation is particularly popular for app
model (e.g., Windows 8, Mac OS X, iOS, and Android) because
apps only require limited interactions. Android relies on user per-
mission to achieve two-way isolation, and this has some similarity
with our reliance on user permissions to realize the inner sandbox.
A difference is that the Android model introduces a new user for
each application, whereas we introduce a new (untrusted) user for
each existing user. Another important difference between the app
model and our approaches is that in the apps world, composition of
applications is the exception, whereas in our system, it is the norm.
While the app models protect malicious code from subverting other
apps directly, they do not protect against malicious data. Once data
sharing takes place, there is no more security guarantees. We al-
low safe interactions to take place by running benign applications
inside untrusted sandbox.
One-way isolation techniques, exempliﬁed by Alcatraz [15], en-
forces a single, simple policy on all applications: they are permit-
ted to read any thing on the system, but their effects are contained
within an isolated environment. This simpliﬁes the maintenance of
the isolated environment. However, the approach has two signiﬁ-
cant drawbacks. First, if the results of isolated execution need to be
used, it needs to be brought out of isolation, at which the system is
potentially exposed to malware attacks. Second, almost none of the
actions of untrusted code are denied by Alcatraz. This can be ex-
ploited by malware to quickly compromise all applications running
in isolation, thus making the environment less than useful.
Information ﬂow techniques.
Our approach can be regarded as an instance of classical infor-
mation ﬂow [8, 5], with group ownership standing for integrity la-
bels. The closest to our work is PPI [25]: Our formulation of in-
tegrity is similar, both approaches are designed to provide integrity
by design, and both approaches focus on automating policies. But
there are several important advances we make in this work over
PPI. First, we provide a portable implementation that has no kernel
component, whereas the bulk of PPI resides in the kernel. Second,
PPI approach for policy inference requires exhaustive training, the
absence of which can lead to failures of benign processes. Specif-
ically, incomplete training can lead to a situation where a critical
benign process is unable to execute because some of its inputs have
become untrusted. The approach presented in this paper avoids this
problem by preventing any benign ﬁle from being overwritten with
untrusted content. On the other hand, PPI provides some features
that we don’t: the ability to run untrusted applications with root
privilege and dynamic context switch from high to low integrity.
We do not provide these features because they do signiﬁcantly com-
plicate system design and implementation.
UMIP [14] focuses on protecting against network attackers. Un-
like UMIP, which uses the sticky bit to encode untrusted data, our
approach repurposes DAC permission to allow us to track untrusted
data. Furthermore, in the desktop context, compromise of user ﬁles
is an important avenue for malware propagation, but UMIP does
not attempt to protect the integrity of user ﬁles. IFEDAC [18] ex-
tends UMIP to protect against untrusted users as well. Both UMIP
and IFEDAC require additional code in kernel to enforce policy.
Our approach avoids the need for kernel code. Another difference
is that we sandox both benign and untrusted processes while they
do not constrain benign processes. Speciﬁcally, it is possible in
IFEDAC for a benign process to be accidentally downgraded due to
the consumption of untrusted input, and this can cause all its future
accesses to be denied, including writes to ﬁles that were opened
before consuming untrusted input. Our approach avoids this self-
revocation problem [8].
[11] I. Goldberg, D. Wagner, R. Thomas, and E. A. Brewer. A
Secure Environment for Untrusted Helper Applications
(Conﬁning the Wily Hacker). In USENIX Security, 1996.
[12] K. Jain and R. Sekar. User-Level Infrastructure for System
Call Interposition: A Platform for Intrusion Detection and
Conﬁnement. In NDSS, 2000.
[13] M. Krohn, A. Yip, M. Brodsky, N. Cliffer, M. F. Kaashoek,
E. Kohler, and R. Morris. Information Flow Control for
Standard OS Abstractions. In SOSP, 2007.
[14] N. Li, Z. Mao, and H. Chen. Usable Mandatory Integrity
Protection for Operating Systems . In S&P, 2007.
[15] Z. Liang, W. Sun, V. N. Venkatakrishnan, and R. Sekar.
Alcatraz: An Isolated Environment for Experimenting with
Untrusted Software. In TISSEC 12(3), 2009.
[16] P. Loscocco and S. Smalley. Integrating Flexible Support for
Security Policies into the Linux Operating System. In
USENIX ATC, 2001.
[17] P. Loscocco and S. Smalley. Meeting Critical Security
Objectives with Security-Enhanced Linux. In Ottawa Linux
symposium, 2001.
[18] Z. Mao, N. Li, H. Chen, and X. Jiang. Combining
Discretionary Policy with Mandatory Information Flow in
Operating Systems. In TISSEC 14(3), 2011.
[19] P. Padala. Playing with ptrace, Part I,
http://www.linuxjournal.com/article/6100.
[20] N. Provos. Improving Host Security with System Call
Policies. In USENIX Security, 2003.
[21] R. Sekar. An Efﬁcient Black-box Technique for Defeating
Web Application Attacks. In NDSS, 2009.
[22] R. Sekar, V. N. Venkatakrishnan, S. Basu, S. Bhatkar, and
D. C. DuVarney. Model-Carrying Code: A Practical
Approach for Safe Execution of Untrusted Applications. In
SOSP, 2003.
[23] W. Sun, Z. Liang, V. N. Venkatakrishnan, and R. Sekar.
One-Way Isolation: An Effective Approach for Realizing
Safe Execution Environments. In NDSS, 2005.
[24] W. Sun, R. Sekar, Z. Liang, and V. N. Venkatakrishnan.
Expanding Malware Defense by Securing Software
Installations. In DIMVA, 2008.
[25] W. Sun, R. Sekar, G. Poothia, and T. Karandikar. Practical
Proactive Integrity Preservation: A Basis for Malware
Defense. In S&P, 2008.
[26] W. K. Sze. Portable Integrity Protection System (PIP).
http://www.seclab.cs.sunysb.edu/seclab/pip.
[27] C. Wright, C. Cowan, S. Smalley, J. Morris, and
G. Kroah-Hartman. Linux Security Modules: General
Security Support for the Linux Kernel. In USENIX Security,
2002.
[28] N. Zeldovich, S. Boyd-Wickizer, E. Kohler, and D. Mazières.
Making Information Flow Explicit in HiStar. In OSDI, 2006.
Another set of works focus on Decentralized Information Flow
Control (DIFC) [13, 28, 7]. Instead of centrally specifying what
is high integrity, DIFC allows applications to create their own in-
tegrity levels. As compared to our approach, DIFC approaches
enable the enforcement of more expressive and ﬂexible policies.
Their downside is that they require nontrivial changes to the OS
and/or applications to achieve security beneﬁts, whereas our em-
phasis is on avoiding any changes to the OS and application code,
while still achieving robust defense from malware.
7. Summary and Conclusions
We presented a new approach that provides principled protec-
tion from malware attacks: as long as untrusted content isn’t mis-
labeled as benign, malware attacks are stopped, regardless of mal-
ware sophistication or the skills of its developers. Through exper-
imental results, we showed that our approach achieves strong pro-
tection without signiﬁcantly impacting the usability of benign and
untrusted applications. To achieve this, we developed a novel dual
sandboxing architecture that decomposes policies into two parts,
one that is enforced on untrusted processes, and another on benign
processes. A minimal policy is used to conﬁne untrusted processes,
making untrusted processes more usable. This policy is comple-
mented by the policy enforced on benign applications. The two
policies work together to provide strong separation between benign
and untrusted contexts.
We also presented detailed policies that are enforced by each
sandbox, and an inference procedure that serves to automate the
identiﬁcation of which policies are to be applied to which ﬁles.
Our implementation has been greatly simpliﬁed by a design that
achieves most enforcement in a cooperative setting with the pro-
cesses on which the policies are being enforced. This enabled our
our implementation to be compact, as well as portable. Our system
introduces low performance overheads. An open-source software
implementation of our system is available on the web [26].
8. References
[1] Packet storm, http://packetstormsecurity.com.
[2] Plash, http://plash.beasts.org/contents.html.
[3] A. Acharya, M. Raje, and A. Raje. MAPbox: Using
Parameterized Behavior Classes to Conﬁne Applications. In
USENIX Security, 2000.
[4] A. V. Aho and M. J. Corasick. Efﬁcient String Matching: An
Aid to Bibliographic Search. In Communications of the ACM
18(6), 1975.
[5] K. J. Biba. Integrity Considerations for Secure Computer
Systems. In Technical Report ESD-TR-76-372, USAF
Electronic Systems Division, Hanscom Air Force Base,
Bedford, Massachusetts, 1977.
[6] C. Cowan, S. Beattie, G. Kroah-Hartman, C. Pu, P. Wagle,
and V. Gligor. SubDomain: Parsimonious Server Security. In
LISA, 2000.
[7] P. Efstathopoulos, M. Krohn, S. VanDeBogart, C. Frey,
D. Ziegler, E. Kohler, D. Mazières, F. Kaashoek, and
R. Morris. Labels and Event Processes in the Asbestos
Operating System. In SOSP, 2005.
[8] T. Fraser. LOMAC: Low Water-Mark Integrity Protection for
COTS Environments. In S&P, 2000.
[9] T. Garﬁnkel. Traps and Pitfalls: Practical Problems in System
Call Interposition Based Security Tools. In NDSS, 2003.
[10] T. Garﬁnkel, B. Pfaff, and M. Rosenblum. Ostia: A
Delegating Architecture for Secure System Call Interposition.
In NDSS, 2004.
228