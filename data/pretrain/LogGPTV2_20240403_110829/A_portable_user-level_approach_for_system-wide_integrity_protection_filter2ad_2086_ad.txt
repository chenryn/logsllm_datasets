### Malware Injection and System Compromise

The attacker dumped a hidden malicious library and modified the `.bashrc` file to set the `LD_PRELOAD` environment variable. This modification ensures that the malicious library is injected into all processes invoked by the user from the shell. If the user has administrative privileges, the attacker can also create an alias for `sudo`, allowing a rootkit to be silently installed when the user performs an administrative action. Although the system was compromised, the user did not experience any inconvenience: while she could view the document, attempts to modify the `.bashrc` file were denied, thus thwarting the malware's attempts to subvert or infect the system.

### 5.4 Performance

#### Benign Overhead
- **σ**: 0.01%
- **2.61%**
- **1.43%**
- **4.57%**

#### Untrusted Overhead
- **σ**: -0.06%
- **4.42%**

**Figure 7: Runtime overhead for Firefox and OpenSSL.**

Figure 7 illustrates the overhead of `openssl` and Firefox compared to unprotected systems. We obtained the statistics using the speed option in `openssl`. For Firefox, we used the PageLoader add-on to measure page load times. Pages from the top 1200 Alexa sites were fetched locally to eliminate network overhead. The overhead on `openssl` benchmarks is negligible, and the average overhead for Firefox is less than 5%.

**Figure 8: Highest 5 overheads in SPEC2006, ref input size**

- **403.gcc**: 541.2 seconds, Benign Overhead: -1.99%, Untrusted Overhead: 0.82%
- **456.hmmer**: 982.7 seconds, Benign Overhead: 0.36%, Untrusted Overhead: -0.13%
- **458.sjeng**: 933.8 seconds, Benign Overhead: 0.49%, Untrusted Overhead: 0.51%
- **462.libquantum**: 995.4 seconds, Benign Overhead: -0.17%, Untrusted Overhead: 0.33%
- **433.milc**: 882.5 seconds, Benign Overhead: 0.85%, Untrusted Overhead: -2.66%

The overhead for CPU-intensive operations is less than 1%.

**Figure 9: Latency for starting and closing GUI programs**

- **eclipse**: 6.16 seconds, Benign Overhead: 1.99%, Untrusted Overhead: 10.23%
- **evolution**: 2.44 seconds, Benign Overhead: 2.44%, Untrusted Overhead: 5.04%
- **F-spot**: 1.61 seconds, Benign Overhead: 2.11%, Untrusted Overhead: 6.80%
- **Firefox**: 1.32 seconds, Benign Overhead: 3.24%, Untrusted Overhead: 10.08%
- **gedit**: 0.82 seconds, Benign Overhead: 5.02%, Untrusted Overhead: 6.09%
- **gimp**: 3.63 seconds, Benign Overhead: 1.90%, Untrusted Overhead: 4.32%
- **soffice**: 1.56 seconds, Benign Overhead: 0.33%, Untrusted Overhead: 7.08%

Figure 9 shows the latency for starting and closing various GUI programs. The time between starting and closing the applications was measured without using them.

### 6. Related Work

#### System-Call Interposition and Sandboxing

Two popular mechanisms for secure policy enforcement are Linux Security Modules (LSM) [27] and `ptrace` [19]. Kernel-based approaches, such as LSM, have several drawbacks: kernel programming is more difficult, leads to less portable code, and creates deployment challenges. Approaches like `ptrace` avoid these issues by enabling policy enforcement in a user-level monitoring process but suffer from performance problems due to frequent context switches. TOCTTOU attacks are also challenging to prevent [9].

Ostia [10] addressed many of these drawbacks by developing a delegating architecture for system-call interposition. It uses a small kernel module to permit a subset of "safe" system calls (like read and write) for monitored processes and forwards the remaining calls to a user-level process. Our system's use of a user-level helper process was inspired by Ostia. While their approach still requires kernel modifications, our design is implemented entirely at the user level by repurposing user access control mechanisms.

While many techniques focus on confinement mechanisms, developing effective policies has received less attention. SELinux [17], Systrace [20], and AppArmor [6] protect benign code and typically rely on a training phase to create a policy. Such training-based approaches are inappropriate for untrusted code. Mapbox [3] develops policies based on expected functionality by dividing applications into classes. Model-carrying code [22] provides a framework for code producers and consumers to collaborate on policy development. Although this represents a significant advance over manual policy development, it does not scale to large numbers of applications. Supporting entire OS distributions, as in our work, would require a substantial effort.

Both our system and Plash [2] confine untrusted programs by executing them with a user ID that has limited system access. Additional accesses are granted by a helper process. However, our focus is on providing compatibility with a wide range of software while protecting the integrity of benign processes. We achieve this by systematically sandboxing all code, whereas Plash only sandboxes untrusted code with least-privilege policies.

#### Isolation-Based Approaches

Applying two-way isolation to desktop OSes is challenging due to the interactions between applications. Fragmented namespaces and the effort required to maintain multiple working environments make two-way isolation less attractive. In contrast, two-way isolation is popular in app models (e.g., Windows 8, Mac OS X, iOS, and Android) because apps require limited interactions. Android relies on user permissions to achieve two-way isolation, similar to our reliance on user permissions for the inner sandbox. A key difference is that Android introduces a new user for each application, while we introduce a new (untrusted) user for each existing user. Another difference is that in the app model, application composition is the exception, whereas in our system, it is the norm.

While app models protect against direct subversion by malicious code, they do not protect against malicious data. Once data sharing occurs, security guarantees are lost. We allow safe interactions by running benign applications inside an untrusted sandbox.

One-way isolation techniques, exemplified by Alcatraz [15], enforce a single, simple policy: applications can read anything on the system, but their effects are contained within an isolated environment. This simplifies maintenance but has two significant drawbacks. First, if the results of isolated execution need to be used, they must be brought out of isolation, potentially exposing the system to malware. Second, almost none of the actions of untrusted code are denied by Alcatraz, which can be exploited by malware to quickly compromise all applications in isolation, making the environment less useful.

#### Information Flow Techniques

Our approach can be seen as an instance of classical information flow [8, 5], with group ownership representing integrity labels. The closest work to ours is PPI [25]: both approaches aim to provide integrity by design and focus on automating policies. However, we make several important advances. First, we provide a portable implementation with no kernel component, whereas PPI resides mostly in the kernel. Second, PPI's policy inference requires exhaustive training, and incomplete training can lead to failures of benign processes. Our approach prevents any benign file from being overwritten with untrusted content, avoiding this problem. PPI offers features we do not, such as running untrusted applications with root privilege and dynamic context switching from high to low integrity. We do not provide these features to avoid complicating the system design and implementation.

UMIP [14] focuses on protecting against network attackers. Unlike UMIP, which uses the sticky bit to encode untrusted data, our approach repurposes DAC permissions to track untrusted data. In the desktop context, compromising user files is a significant avenue for malware propagation, but UMIP does not protect the integrity of user files. IFEDAC [18] extends UMIP to protect against untrusted users but requires additional kernel code to enforce policies. Our approach avoids the need for kernel code and sandboxes both benign and untrusted processes, preventing the self-revocation problem [8].

### 7. Summary and Conclusions

We presented a new approach that provides principled protection from malware attacks: as long as untrusted content isn't mislabeled as benign, malware attacks are stopped, regardless of the malware's sophistication or the skills of its developers. Experimental results show that our approach achieves strong protection without significantly impacting the usability of benign and untrusted applications. We developed a novel dual-sandboxing architecture that decomposes policies into two parts: one enforced on untrusted processes and another on benign processes. A minimal policy confines untrusted processes, making them more usable, while the policy enforced on benign applications complements this. The two policies work together to provide strong separation between benign and untrusted contexts.

We also presented detailed policies enforced by each sandbox and an inference procedure to automate the identification of which policies apply to which files. Our implementation is compact and portable, achieved by enforcing most policies in a cooperative setting with the processes. Our system introduces low performance overheads, and an open-source implementation is available [26].

### 8. References

[1] Packet storm, http://packetstormsecurity.com.
[2] Plash, http://plash.beasts.org/contents.html.
[3] A. Acharya, M. Raje, and A. Raje. MAPbox: Using Parameterized Behavior Classes to Conﬁne Applications. In USENIX Security, 2000.
[4] A. V. Aho and M. J. Corasick. Efﬁcient String Matching: An Aid to Bibliographic Search. In Communications of the ACM 18(6), 1975.
[5] K. J. Biba. Integrity Considerations for Secure Computer Systems. In Technical Report ESD-TR-76-372, USAF Electronic Systems Division, Hanscom Air Force Base, Bedford, Massachusetts, 1977.
[6] C. Cowan, S. Beattie, G. Kroah-Hartman, C. Pu, P. Wagle, and V. Gligor. SubDomain: Parsimonious Server Security. In LISA, 2000.
[7] P. Efstathopoulos, M. Krohn, S. VanDeBogart, C. Frey, D. Ziegler, E. Kohler, D. Mazières, F. Kaashoek, and R. Morris. Labels and Event Processes in the Asbestos Operating System. In SOSP, 2005.
[8] T. Fraser. LOMAC: Low Water-Mark Integrity Protection for COTS Environments. In S&P, 2000.
[9] T. Garﬁnkel. Traps and Pitfalls: Practical Problems in System Call Interposition Based Security Tools. In NDSS, 2003.
[10] T. Garﬁnkel, B. Pfaff, and M. Rosenblum. Ostia: A Delegating Architecture for Secure System Call Interposition. In NDSS, 2004.