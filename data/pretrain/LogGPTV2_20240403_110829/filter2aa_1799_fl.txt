cial secure memory that is internal to the processor. ACMs are invoked using a special  instruc-
tion. There are two types of ACMs BIOS and SINIT. While BIOS ACM measures the BIOS and performs 
some BIOS security functions, the SINIT ACM is used to perform the measurement and launch of the 
Operating System TCB (TBOOT) module. Both BIOS and SINIT ACM are usually contained inside the 
System BIOS image (this is not a strict requirement), but they can be updated and replaced by the OS if 
needed (refer to the “Secure Launch” section later in this chapter for more details).
The ACM is the core root of trusted measurements. As such, it operates at the highest security level 
and must be protected against all types of attacks. The processor microcode copies the ACM module in 
the secure memory and performs different checks before allowing the execution. The processor verifies 
that the ACM has been designed to work with the target chipset. Furthermore, it verifies the ACM in-
tegrity, version, and digital signature, which is matched against the public key hardcoded in the chipset 
fuses. The  instruction doesn’t execute the ACM if one of the previous checks fails.
Another key feature of Secure Launch is the support of Dynamic Root of Trust Measurement (DRTM) 
by the TPM. As introduced in the previous section, Measured Boot, 16 different TPM PCR registers (0 
through 15) provide storage for boot measurements. The Boot Manager could extend these PCRs, but 
it’s not possible to clear their contents until the next platform reset (or power up). This explains why 
these kinds of measurements are called static measurements. Dynamic measurements are measure-
ments made to PCRs that can be reset without resetting the platform. There are six dynamic PCRs 
(actually there are eight, but two are reserved and not usable by the OS) used by Secure Launch and 
the trusted operating system.
In a typical TXT Boot seuence, the boot processor, after having validated the ACM integrity, ex-
ecutes the ACM startup code, which measures critical BIOS components, exits ACM secure mode, and 
jumps to the UEFI BIOS startup code. The BIOS then measures all of its remaining code, configures the 
platform, and verifies the measurements, executing the  instruction. This TXT instruction loads 
the BIOS ACM module, which performs the security checks and locks the BIOS configuration. At this 
stage the UEFI BIOS could measure each option ROM code (for each device) and the Initial Program 
Load (IPL). The platform has been brought to a state where it’s ready to boot the operating system 
(specifically through the IPL code). 
The TXT Boot seuence is part of the Static Root of Trust Measurement (SRTM) because the trusted 
BIOS code (and the Boot Manager) has been already verified, and it’s in a good known state that will 
never change until the next platform reset. Typically, for a TXT-enabled OS, a special TCB (TBOOT) 
module is used instead of the first kernel module being loaded. The purpose of the TBOOT module is to 
initialize the platform for secure mode operation and initiate the Secure Launch. The Windows TBOOT 
CHAPTER 12 Startup and shutdown
807
module is named TcbLaunch.exe. Before starting the Secure Launch, the TBOOT module must be veri-
fied by the SINIT ACM module. So, there should be some components that execute the  instruc-
tions and start the DRTM. In the Windows Secure Launch model, this component is the boot library.
Before the system can enter the secure mode, it must put the platform in a known state. (In this 
state, all the processors, except the bootstrap one, are in a special idle state, so no other code could 
ever be executed.) The boot library executes the  instruction, specifying the  operation. 
This causes the processor to do the following 
1.
Validate the SINIT ACM module and load it into the processor’s secure memory.
2.
Start the DRTM by clearing all the relative dynamic PCRs and then measuring the SINIT ACM.
3.
Execute the SINIT ACM code, which measures the trusted OS code and executes the Launch
Control Policy. The policy determines whether the current measurements (which reside in some
dynamic PCR registers) allow the OS to be considered trusted.
When one of these checks fails, the machine is considered to be under attack, and the ACM issues 
a TXT reset, which prevents any kind of software from being executed until the platform has been 
hard reset. Otherwise, the ACM enables the Secure Launch by exiting the ACM mode and jumping 
to the trusted OS entry point (which, in Windows is the n function of the TcbLaunch.exe mod-
ule). The trusted OS then takes control. It can extend and reset the dynamic PCRs for every measure-
ment that it needs (or by using another mechanism that assures the chain of trust). 
Describing the entire Secure Launch architecture is outside the scope of this book. Please refer to 
the Intel manuals for the TXT specifications. Refer to the Secure Launch section, later in this chapter, 
for a description of how Trusted Execution is implemented in Windows. Figure 12-7 shows all the com-
ponents involved in the Intel TXT technology.
CPU
BIOS
TPM
v1.2
Tools
IOH/PCH
TPM by third party
(TCG* compliant)
SINIT AC Module
BIOS AC Module
Third-party
software:
MLE, hosted
OS, apps, etc.
VT-x and TXT support
CPU
VT-x and TXT support
(VMX+SMX)
TXT and
VT-d support in IOH
TPM support
AC modules
and platform
initialization
FIGURE 12-7 Intel TXT (Trusted Execution Technology) components.
808 
CHAPTER 12 Startup and shutdown
The Windows OS Loader
The Windows OS Loader (Winload) is the boot application launched by the Boot Manager with the goal 
of loading and correctly executing the Windows kernel. This process includes multiple primary tasks 
I 
Create the execution environment of the kernel. This involves initializing, and using, the kernel’s
page tables and developing a memory map. The EFI OS Loader also sets up and initializes the
kernel’s stacks, shared user page, GDT, IDT, TSS, and segment selectors.
I 
Load into memory all modules that need to be executed or accessed before the disk stack is
initialized. These include the kernel and the AL because they handle the early initialization of
basic services once control is handed off from the OS Loader. Boot-critical drivers and the regis-
try system hive are also loaded into memory.
I 
Determine whether yper-V and the Secure Kernel (VSM) should be executed, and, if so, cor-
rectly load and start them.
I 
Draw the first background animation using the new high-resolution boot graphics library
(BGFX, which replaces the old Bootvid.dll driver).
I 
Orchestrate the Secure Launch boot seuence in systems that support Intel TXT. (For a com-
plete description of Measured Boot, Secure Launch, and Intel TXT, see the respective sections
earlier in this chapter). This task was originally implemented in the hypervisor loader, but it has
moved starting from Windows 10 October Update (RS5).
The Windows loader has been improved and modified multiple times during each Windows release. 
Osln is the main loader function (called by the Boot Manager) that (re)initializes the boot library 
and calls the internal Oslpn. The boot library, at the time of this writing, supports two different 
execution contexts
I 
Firmware context means that the paging is disabled. Actually, it’s not disabled but it’s provided by 
the firmware that performs the one-to-one mapping of physical addresses, and only firmware ser-
vices are used for memory management. Windows uses this execution context in the Boot Manager.
I 
Application context means that the paging is enabled and provided by the OS. This is the con-
text used by the Windows Loader.
The Boot Manager, just before transferring the execution to the OS loader, creates and initializes the 
four-level x64 page table hierarchy that will be used by the Windows kernel, creating only the self-map 
and the identity mapping entries. Osln switches to the Application execution context, just before 
starting. The Oslreprere routine captures the boot/shutdown status of the last boot, reading 
from the bootstat.dat file located in the system root directory. 
When the last boot has failed more than twice, it returns to the Boot Manager for starting the 
Recovery environment. Otherwise, it reads in the SSTEM registry hive, WindowsSystem32Config
System, so that it can determine which device drivers need to be loaded to accomplish the boot. (A hive 
is a file that contains a registry subtree. More details about the registry were provided in Chapter 10.) 
Then it initializes the BGFX display library (drawing the first background image) and shows the 
Advanced Options menu if needed (refer to the section The boot menu earlier in this chapter). One 
CHAPTER 12 Startup and shutdown
809
of the most important data structures needed for the NT kernel boot, the Loader Block, is allocated 
and filled with basic information, like the system hive base address and size, a random entropy value 
(queried from the TPM if possible), and so on. 
Oslnleerl contains code that ueries the system’s ACPI BIOS to retrieve basic device 
and configuration information (including event time and date information stored in the system’s 
CMOS). This information is gathered into internal data structures that will be stored under the 
KLM ARDWAREDESCRIPTION registry key later in the boot. This is mostly a legacy key that exists 
only for compatibility reasons. Today, it’s the Plug and Play manager database that stores the true 
information on hardware.
Next, Winload begins loading the files from the boot volume needed to start the kernel initializa-
tion. The boot volume is the volume that corresponds to the partition on which the system directory 
(usually Windows) of the installation being booted is located. Winload follows these steps
1.
Determines whether the hypervisor or the Secure Kernel needs to be loaded (through the
ypersrlunype BCD option and the VSM policy) if so, it starts phase 0 of the hypervisor
setup. Phase 0 pre-loads the V loader module (vloader.dll) into RAM memory and executes
its HvlLoadHypervisor initialization routine. The latter loads and maps the hypervisor image
(vix64.exe, vax64.exe, or vaa64.exe, depending on the architecture) and all its dependen-
cies in memory.
2.
Enumerates all the firmware-enumerable disks and attaches the list in the Loader Parameter
Block. Furthermore, loads the Synthetic Initial Machine Configuration hive (Imc.hiv) if specified
by the configuration data and attaches it to the loader block.
3.
Initializes the kernel Code Integrity module (CI.dll) and builds the CI Loader block. The Code
Integrity module will be then shared between the NT kernel and Secure Kernel.
4.
Processes any pending firmware updates. (Windows 10 supports firmware updates distributed
through Windows Update.)
5.
Loads the appropriate kernel and AL images (Ntoskrnl.exe and al.dll by default). If Winload
fails to load either of these files, it prints an error message. Before properly loading the two
modules’ dependencies, Winload validates their contents against their digital certificates and
loads the API Set Schema system file. In this way, it can process the API Set imports.
6.
Initializes the debugger, loading the correct debugger transport.
7. 
Loads the CPU microcode update module (Mcupdate.dll), if applicable.
8.
Oslpllulesfinally loads the modules on which the NT kernel and AL depend, ELAM
drivers, core extensions, TPM drivers, and all the remaining boot drivers (respecting the load
orderthe file system drivers are loaded first). Boot device drivers are drivers necessary to
boot the system. The configuration of these drivers is stored in the SSTEM registry hive. Every
device driver has a registry subkey under KLMSSTEMCurrentControlSetServices. For
example, Services has a subkey named rdyboost for the ReadyBoost driver, which you can see in
Figure 12-8 (for a detailed description of the Services registry entries, see the section Services
in Chapter 10). All the boot drivers have a start value of OO (0).
810 
CHAPTER 12 Startup and shutdown
9.
At this stage, to properly allocate physical memory, Winload is still using services provided
by the EFI Firmware (the llees boot service routine). The virtual address translation is
instead managed by the boot library, running in the Application execution context.
FIGURE 12-8 ReadyBoost driver service settings.
10. Reads in the NLS (National Language System) files used for internationalization. By default,
these are lintl.nls, C1252.nls, and C437.nls.
11. If the evaluated policies reuire the startup of the VSM, executes phase 0 of the Secure Kernel
setup, which resolves the locations of the VSM Loader support routines (exported by the
vloader.dll module), and loads the Secure Kernel module (Securekernel.exe) and all of its
dependencies.
12. For the S edition of Windows, determines the minimum user-mode configurable code integrity
signing level for the Windows applications.
13. Calls the Oslrperneleupse routine, which performs the memory steps required for
kernel transition, like allocating a GDT, IDT, and TSS mapping the AL virtual address space
and allocating the kernel stacks, shared user page, and USB legacy handoff. Winload uses the
UEFI GetMemoryMap facility to obtain a complete system physical memory map and maps
each physical page that belongs to EFI Runtime Code/Data into virtual memory space. The
complete physical map will be passed to the OS kernel.
14. Executes phase 1 of VSM setup, copying all the needed ACPI tables from VTL0 to VTL1 memory.
(This step also builds the VTL1 page tables.)
15. The virtual memory translation module is completely functional, so Winload calls the
ExitBootServices UEFI function to get rid of the firmware boot services and remaps all
the remaining Runtime UEFI services into the created virtual address space, using the
erulressp UEFI runtime function.
16. If needed, launches the hypervisor and the Secure Kernel (exactly in this order). If successful,
the execution control returns to Winload in the context of the yper-V Root Partition. (Refer to
Chapter 9, Virtualization technologies, for details about yper-V.)
17. Transfers the execution to the kernel through the Oslrrnserernel routine.
CHAPTER 12 Startup and shutdown
811
Booting from iSCSI
Internet SCSI (iSCSI) devices are a kind of network-attached storage in that remote physical disks are 
connected to an iSCSI ost Bus Adapter (BA) or through Ethernet. These devices, however, are differ-
ent from traditional network-attached storage (NAS) because they provide block-level access to disks, 
unlike the logical-based access over a network file system that NAS employs. Therefore, an iSCSI-
connected disk appears as any other disk drive, both to the boot loader and to the OS, as long as the 
Microsoft iSCSI Initiator is used to provide access over an Ethernet connection. By using iSCSI-enabled 
disks instead of local storage, companies can save on space, power consumption, and cooling.
Although Windows has traditionally supported booting only from locally connected disks or 
network booting through PXE, modern versions of Windows are also capable of natively booting 
from iSCSI devices through a mechanism called iSCSI Boot. As shown in Figure 12-9, the boot loader 
(Winload.efi) detects whether the system supports iSCSI boot devices reading the iSCSI Boot Firmware 
Table (iBFT) that must be present in physical memory (typically exposed through ACPI). Thanks to the 
iBFT table, Winload knows the location, path, and authentication information for the remote disk. If the 
table is present, Winload opens and loads the network interface driver provided by the manufacturer, 
which is marked with the OOOO (0x1) boot flag.
Additionally, Windows Setup also has the capability of reading this table to determine bootable 
iSCSI devices and allow direct installation on such a device, such that no imaging is reuired. In combi-
nation with the Microsoft iSCSI Initiator, this is all that’s required for Windows to boot from iSCSI.
Boot
parameter
driver
iBF
Table
EFI
UNDI
NIC
iSCSI initiator
TCPIP
NDIS
NDIS miniport
NIC
Pre-boot      Windows
Microsoft iSCSI
Microsoft Windows
Vendor
FIGURE 12-9 iSCSI boot architecture.
The hypervisor loader
The hypervisor loader is the boot module (its file name is vloader.dll) used to properly load and start 
the yper-V hypervisor and the Secure Kernel. For a complete description of yper-V and the Secure 
Kernal, refer to Chapter 9. The hypervisor loader module is deeply integrated in the Windows Loader 
and has two main goals
I 
Detect the hardware platform load and start the proper version of the Windows ypervisor
(vix64.exe for Intel Systems, vax64.exe for AMD systems and vaa64.exe for ARM64 systems).
I 
Parse the Virtual Secure Mode (VSM) policy load and start the Secure Kernel.
812 
CHAPTER 12 Startup and shutdown
In Windows 8, this module was an external executable loaded by Winload on demand. At that time 
the only duty of the hypervisor loader was to load and start yper-V. With the introduction of the VSM 
and Trusted Boot, the architecture has been redesigned for a better integration of each component.
As previously mentioned, the hypervisor setup has two different phases. The first phase begins in 
Winload, just after the initialization of the NT Loader Block. The vLoader detects the target platform 
through some CPUID instructions, copies the UEFI physical memory map, and discovers the IOAPICs 
and IOMMUs. Then vLoader loads the correct hypervisor image (and all the dependencies, like the 
Debugger transport) in memory and checks whether the hypervisor version information matches the 
one expected. (This explains why the vLoader couldn’t start a different version of yper-V.) vLoader 
at this stage allocates the hypervisor loader block, an important data structure used for passing system 
parameters between vLoader and the hypervisor itself (similar to the Windows loader block). The 
most important step of phase 1 is the construction of the hypervisor page tables hierarchy. The just-
born page tables include only the mapping of the hypervisor image (and its dependencies) and the 
system physical pages below the first megabyte. The latter are identity-mapped and are used by the 
startup transitional code (this concept is explained later in this section). 
The second phase is initiated in the final stages of Winload the UEFI firmware boot services have 
been discarded, so the vLoader code copies the physical address ranges of the UEFI Runtime Services 
into the hypervisor loader block captures the processor state disables the interrupts, the debugger, 
and paging and calls lprnserypersrrnsnpeto transfer the code execution to 
the below 1 MB physical page. The code located here (the transitional code) can switch the page tables, 
re-enable paging, and move to the hypervisor code (which actually creates the two different address 
spaces). After the hypervisor starts, it uses the saved processor context to properly yield back the code 
execution to Winload in the context of a new virtual machine, called root partition (more details avail-
able in Chapter 9). 
The launch of the virtual secure mode is divided in three different phases because some steps are 
reuired to be done after the hypervisor has started. 
1.
The first phase is very similar to the first phase in the hypervisor setup. Data is copied from the
Windows loader block to the just-allocated VSM loader block the master key, IDK key, and
Crashdump key are generated and the SecureKernel.exe module is loaded into memory.
2.
The second phase is initiated by Winload in the late stages of OslPrepareTarget, where the
hypervisor has been already initialized but not launched. Similar to the second phase of the
hypervisor setup, the UEFI runtime services physical address ranges are copied into the VSM