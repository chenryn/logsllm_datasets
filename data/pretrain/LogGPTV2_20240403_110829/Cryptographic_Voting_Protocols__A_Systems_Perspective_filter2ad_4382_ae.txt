based on who seems to be willing the race. If the adver-
sary’s preferred candidate is winning, the adversary need
do nothing. Otherwise, the adversary might try to disrupt
or ruin the election, forcing a re-election and giving her
preferred candidate a second chance to win the election,
or at least raising questions about the winner’s mandate
and reducing voters’ conﬁdence in the process.
There are many ways that selective DoS attacks might
be mounted:
• If an outsider has a control channel to malicious
DREs, the outsider could look at the polls and com-
municate a DoS command to the DREs.
• An autonomous DRE could look at the pattern of
votes cast during the day, and fail (deleting all votes
cast so far at that DRE) if that pattern leans towards
the undesired candidate. This would disrupt votes
cast only in precincts leaning against the attacker’s
preferred candidate.
• If trustees’ software is malicious, it could collude to
see how the election will turn out, then cause DoS
if the result is undesirable. Note that if all trustees
are running the same tallying software, this attack
would require only a single corrupted programmer.
Selective DoS attacks are perhaps the most troubling
kind of DoS attack, because they threaten election in-
tegrity and because attackers may have a real motive to
launch them.
6.2 Mitigation Strategies and Election Re-
covery
Note that in all these attacks, non-malicious hardware or
software failures could cause the same problems. This
may make it hard to distinguish purposeful attacks from
unintentional failures.
The above attacks create irrecoverable situations be-
cause voters’ legitimate ballots are lost or corrupted, the
bulletin board contains unidentiﬁable illegitimate ballots
submitted by malicious DREs, or both. In this section,
we evaluate two recovery mechanisms for these DoS at-
tacks: revoting and a voter veriﬁed paper audit trail.
Revoting. One recovery strategy is to allow cheated
voters to revote. Depending on the scope of the attack
or failure, this could range from allowing only partic-
ular voters to revote to completely scrapping the elec-
tion and starting over. However, revoting is problem-
atic. Redoing the entire election is the most costly coun-
termeasure. Alternatively, election ofﬁcials could allow
only those voters who have detected cheating to revote.
Unfortunately, this is insufﬁcient. Less observant voters
who were cheated may not come forward, and it may be
hard to identify and remove illegitimate ballots added by
46
14th USENIX Security Symposium
USENIX Association
a malicious DRE. Revoting does not help with selective
DoS.
Voter veriﬁed paper audit trail. A voter veriﬁed pa-
per audit trail (VVPAT) system produces a paper record
veriﬁed by the voter before her electronic ballot
is
cast [19]. This paper record is cast into a ballot box. The
paper trail is an ofﬁcial record of the voter’s vote but is
primarily intended for use in recounts and auditing.
It would not be hard to equip cryptographic voting sys-
tems with a VVPAT. This would provide a viable mecha-
nism for recovering from DoS attacks. In addition to pro-
viding an independent record of all votes cast, VVPAT
enables recovery at different granularities.
If election
ofﬁcials conclude the entire electronic record is ques-
tionable, then the entire VVPAT can be counted. Al-
ternatively, if only a single precinct’s electronic record
is suspect, then this precinct’s VVPAT record can be
counted in conjunction with the other precincts’ elec-
tronic records. This approach enables ofﬁcials to keep
the universal veriﬁability of the uncorrupted precincts
while recovering the legitimate record of the corrupted
precinct.
A third beneﬁt of VVPAT is that it provides an inde-
pendent way to audit that the cryptography is correctly
functioning. This would be one way to help all voters,
even those who do not understand the mathematics of
these cryptographic schemes, to be conﬁdent that their
vote will be counted correctly.
7 Implementing Secure Cryptographic
Voting Protocols
A secure implementation of Neff and Chaum’s protocol
will still need to resolve many issues. In this section, we
outline important areas that Neff and Chaum have not yet
speciﬁed. These parts of the system need to be fully de-
signed, implemented, and speciﬁed before one can per-
form a comprehensive security review. Also, we list three
open research problems which we feel are important to
the viability of these schemes.
7.1 Underspeciﬁcations
Bulletin board. Both protocols rely on a public bul-
letin board to provide anonymous, read only access to
the data. The data must be stored robustly, overcoming
software and mechanical failures as well as malicious at-
tacks. Further, only authenticated parties should be able
to append messages to the bulletin board. An additional
requirement is to ensure that the system delivers the same
copy of the bulletin board contents to each reader. If the
bulletin board were able to discern a voter’s identity, say
by IP address, it could make sure the voter always saw
a mix transcript that included a proof that their vote was
counted. But, for the ofﬁcial transcript, the mix net and
bulletin board could collude to omit the voter’s ballot. In
this scenario, the voter would think her vote had been
counted but in reality it was not.
Neff and Chaum have not yet elaborated on a proposed
bulletin board architecture or the properties they require.
We imagine that the principles of distributed storage sys-
tems, such as Farsite, CFS, or OceanStore [1, 7, 27],
might be applicable in the bulletin board setting. How-
ever, without a further speciﬁcation of exactly which ar-
chitecture would be used, we cannot evaluate the sys-
tem’s security.
BSN assignment. Neff’s and Chaum’s schemes do not
specify how to assign BSNs to voters’ ballots. BSNs
could be assigned externally by a smartcard initializer
which authorizes a voter to use a DRE, or be assigned by
DREs, say by a monotonically increasing counter pre-
ﬁxed by the DRE machine ID.4 Clever BSN assignment
combined with careful auditing and sign-in procedures
could help limit the scope of some of the DoS attacks in
Section 6, but since DREs can always erase or corrupt a
voter’s electronic ballot after she casts it, we still must
consider recovery mechanisms.
User interfaces. The attacks presented in Section 5 re-
quire a malicious programmer to modify the DRE’s soft-
ware and present a different user interface from the cor-
rect version. A related attack would be a malicious DRE
neglecting to present a valid candidate to the voter.
Clever user interfaces may be able to overcome such
attacks, by making it plainly obvious to the voter that
thing are amiss. We don’t know of any user interface
speciﬁcation or architecture for Neff’s or Chaum’s voting
system.
Tallying software. Both Neff’s and Chaum’s schemes
treat the tallying software as a black box. We surmise,
that it, too, has stringent requirements on its correct im-
plementation. If all trustees use tallying software from
a single source, then this software might collude with-
out the trustees’ knowledge and invalidate the system’s
integrity guarantees. Though n-version programming
might be able to counter this threat, it makes software de-
velopment very expensive and requires detailed interface
speciﬁcations to ensure that all versions of the software
will interoperate. We have not seen any details on how
to ensure that the tallying software cannot collude.
4David Chaum later conveyed to us that he intended his scheme to
use a counter to assign BSNs [6].
USENIX Association
14th USENIX Security Symposium
47
7.2 Open Research Problems
Subliminal channels. Developing cryptographic pro-
tocols that address subliminal channels would help resist
privacy and coercion attacks. Subliminal channels in the
ballots subvert the conﬁdentiality guarantees provided by
encryption. We present some techniques in Section 4 to
eliminate subliminal channels in encrypted ballots, but
we believe this is still an area for future research.
Mix net security models. We would like to see a def-
inition of security for mix nets that is comprehensive
for the voting setting. Such a deﬁnition must be nat-
ural enough to inspire conﬁdence that it is the correct
model. For instance, Jakobsson illustrates a subtle pri-
vacy violation if the encryption used in the mixes do
not provide non-malleability [11], and others have shown
similar results [26]. This illustrates the importance and
non-triviality of formulating a correct security model for
mix nets. We believe the security of cryptographic vot-
ing systems would beneﬁt from a thorough study of the
relationship between the mix net requirements and those
of the rest of the system.
Humans as protocol participants. These voting pro-
tocols require voters to not just use a cryptographic sys-
tem, but also to participate in a cryptographic proto-
col. Cryptographic protocols are fragile to deviations and
mistakes in their implementation, and humans have been
known to make mistakes. A high level understanding of
the protocol is not sufﬁcient; to minimize errors, voters
often need to understand how the protocol works. Al-
ternatively, voting protocols must be designed to be as
foolproof as possible to “faulty” implementations in the
average voter. Voter education could help, but this raises
an important human-computer interaction problem: how
do we educate voters about these issues without discour-
aging them that these systems are too complicated to se-
curely use?
8 Conclusion
We laud Neff’s and Chaum’s ambitious goal: developing
a coercion free, privacy preserving voter-veriﬁable elec-
tion system. Their systems represent a signiﬁcant secu-
rity improvement over current DRE-based paperless sys-
tems. Neff’s and Chaum’s schemes also strive to limit
reliance on trusted software and hardware. Most notably,
these schemes do not require voters to trust DREs since
voters can detect malicious behavior.
Neff’s and Chaum’s schemes are fully speciﬁed at the
cryptographic protocol level, but they are underspeci-
ﬁed from the systems and human interaction level. Due
in part to this underspeciﬁcation, we have discovered a
number of potential weaknesses which only became ap-
parent when considered in the context of an entire voting
system. We expect that a well designed implementation
and deployment may be able to mitigate or even elimi-
nate the impact of these weaknesses.
We found solutions for some of these weaknesses, but
we also identiﬁed new challenges and open problems
for electronic voting systems. First, subliminal chan-
nels have the potential to erode voter privacy and enable
voter coercion. Any system that uses a public bulletin
board must ensure that the ballots it posts have a unique
representation. Second, these voting protocols present a
new research challenge by placing human voters directly
within an interactive cryptographic protocol. Protocol
designers have previously assumed participants are in-
fallible computer agents, but voting protocols must cope
with human error and ignorance.
Despite these challenges, we are optimistic about the
future prospects of these voting systems.
Acknowledgments
We would like to thank Andrew Neff and David Chaum
for helping us understand their voting protocols.
Joe
Hall, David Molnar, Rob Johnson, Umesh Shankar, and
Monica Chew gave invaluable feedback on earlier drafts
of this work. This work was supported in part by the
NSF under grant CCR-0093337, by the Knight Founda-
tion under a subcontract through the Caltech/MIT Voting
Technology Project, and by the US Postal Service.
References
[1] Atul Adya, William Bolosky, Miguel Castro, Gerald Cer-
mak, Ronnie Chaiken, John Douceur, Jon Howell, Jacob
Lorch, Marvin Theimer, and Roger Wattenhofer. FAR-
SITE: Federated, available, and reliable storage for a in-
completely trusted environment.
In 5th Symposium on
Operating System Design and Implementation (OSDI),
pages 1–14, December 2002.
[2] Ross Anderson. Security Engineering: A Guide to Build-
ing Dependable Distributed Systems, chapter 3, “Pass-
words”, pages 35–50. John Wiley and Sons, Inc., 2001.
[3] Jonathan Bannet, David W. Price, Algis Rudys, Justin
Singer, and Dan S. Wallach. Hack-a-vote: Demonstrating
security issues with electronic voting systems. IEEE Se-
curity and Privacy Magazine, 2(1):32–37, Jan./Feb. 2004.
[4] Jeremy Bryans and Peter Ryan. A dependability analysis
of the Chaum digital voting scheme. Technical Report
CS-TR-809, University of Newcastle upon Tyne, July
2003.
[5] David Chaum.
Secret-ballot receipts: True voter-
veriﬁable elections. IEEE Security & Privacy Magazine,
2(1):38–47, Jan.–Feb. 2004.
[6] David Chaum, February 2005. Personal Communication.
48
14th USENIX Security Symposium
USENIX Association
[21] C. Andrew Neff. A veriﬁable secret shufﬂe and its appli-
cation to e-voting. In 8th ACM Conference on Computer
and Communications Security (CCS 2001), pages 116–
125, November 2001.
[22] C. Andrew Neff, October 2004. Personal Communica-
tion.
[23] C. Andrew Neff. Practical high certainty intent veriﬁca-
tion for encrypted votes. http://www.votehere.
net/vhti/documentation, October 2004.
[24] C. Andrew Neff. Veriﬁable mixing (shufﬂing) of El-
Gamal pairs. http://www.votehere.net/vhti/
documentation, April 2004.
[25] Peter G. Neumann.
Principled assuredly trustworthy
composable architectures.
Final report for Task 1
of SRI Project 11459, as part of DARPA’s Compos-
able High-Assurance Trustworthy Systems (CHATS) pro-
gram, 2004.
[26] Birgit Pﬁtzmann and Andreas Pﬁtzmann. How to break
the direct RSA-implementation of MIXes. In Advances in
Cryptology – EUROCRYPT 1989, volume 434 of Lecture
Notes in Computer Science, pages 373–381. Springer-
Verlag, April 1989.
[27] Sean Rhea, Patrick Eaton, Dennis Geels, Hakim Weath-
the
erspoon, Ben Zhao, and John Kubiatowicz. Pond:
OceanStore prototype.
In 2nd USENIX Conference on
File and Storage Technologies (FAST ’03), pages 1–14,
March 2003.
[28] Bruce Schneier. Secrets and Lies, chapter 17, “The Hu-
man Factor”, pages 255–269. John Wiley and Sons, Inc.,
2000.
[29] Poorvi Vora. David Chaum’s voter veriﬁcation using en-
crypted paper receipts. Cryptology ePrint Archive, Report
2005/050, February 2005. http://eprint.iacr.
org/.
[30] Alma Whitten and J.D. Tygar. Why Johnny can’t encrypt:
A usability evaluation of PGP 5.0. In 8th USENIX Secu-
rity Symposium, pages 169–184, August 1999.
[7] Frank Dabek, M. Frans Kaashoek, David Karger, Robert
Morris, and Ion Stoica. Wide-area cooperative storage
with CFS. In Proceedings of the 18th ACM Symposium
on Operating Systems Principles (SOSP ’01), pages 202–
215, October 2001.
[8] Shaﬁ Goldwasser and Silvio Micali. Probabilistic en-
Journal of Computer and System Sciences,
cryption.
28(2):270–299, April 1984.
[9] Shaﬁ Goldwasser, Silvio Micali, and Charles Rackoff.
The knowledge complexity of interactive proof systems.
In SIAM Journal on Computing, volume 18, pages 270–
299, 1984.
[10] Nevin Heintze and J. D. Tygar. A model for secure pro-
Software Engineering,
tocols and their compositions.
22(1):16–30, January 1996.
[11] Markus Jakobsson. A practical mix. In Advances in Cryp-
tology – EUROCRYPT 1998, volume 1403 of Lecture
Notes in Computer Science, pages 448–461. Springer-
Verlag, May/June 1998.
[12] Markus Jakobsson, Ari Juels, and Ronald Rivest. Mak-
ing mix nets robust for electronic voting by randomized
partial checking. In 11th USENIX Security Symposium,
pages 339–353, August 2002.
[13] Arthur Keller, David Mertz, Joseph Hall, and Arnold
Urkin. Privacy issues in an electronic voting machine.
In ACM Workshop on Privacy in the Electronic Soci-
ety, pages 33–34, October 2004. Full paper available
at http://www.sims.berkeley.edu/˜jhall/
papers/.
[14] Paul Kocker and Bruce Schneier.
Insider risks in elec-
tions. Communications of the ACM, 47(7):104, July 2004.
[15] Tadayoshi Kohno, Adam Stubbleﬁeld, Aviel D. Rubin,
and Dan S. Wallach. Analysis of an electronic voting sys-
tem. In IEEE Symposium on Security and Privacy, pages
27–40, May 2004.
[16] Matt Lepinski, Silvio Micali, and abhi shelat. Collusion-
free protocols. In Proceedings of the 37th ACM Sympo-
sium on Theory of Computing, May 2005.
[17] Matt Lepinski, Silvio Micali, and abhi shelat. Fair zero
knowledge. In Proceedings of the 2nd Theory of Cryp-
tography Conference, February 2005.
[18] Heiko Mantel. On the composition of secure systems. In
IEEE Symposium on Security and Privacy, pages 88–101,
May 2002.
[19] Rebecca Mercuri. A better ballot box? IEEE Spectrum,
39(10):46–50, October 2002.
[20] Deirdre Mulligan and Joseph Hall.
Preliminary
analysis of e-voting problems highlights need for
heightened standards and testing.
A whitepaper
submission to the NRC’s Committee on Electronic
http://www7.nationalacademies.
Voting,
org/cstb/project_evoting_mulligan.pdf,
December 2004.
USENIX Association
14th USENIX Security Symposium
49