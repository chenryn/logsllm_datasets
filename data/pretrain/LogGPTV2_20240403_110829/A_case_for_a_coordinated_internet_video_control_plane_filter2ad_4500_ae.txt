rate. The hybrid strategy has a small but non-zero failure rate; the
reason is that some clients may use high bitrates so that a small
number of clients are rejected.
CDN variability:
In this scenario, in epochs 20–60, the pre-
viously best CDN experiences a huge degradation with the aver-
age rebuffering ratio going to 13%, before eventually recovering at
epoch 60. Figure 9(b) shows how different strategies respond to
CDN variability. In this case, global coordination still maintains
zero failure rate (which is possible because of our normalization)
 0 20 40 0 10 20 30 40 50 60 70 80Average Utility (min.)Epoch 0 25 50 75 100Failure rate (%)Global coordinationBaselineHybrid 0 20 40 0 10 20 30 40 50 60 70 80Average Utility (min.)Epoch 0 25 50 75 100Failure rate (%)Global coordinationBaselineHybrid 0 20 40 0 10 20 30 40 50 60 70 80Average Utility (min.)Epoch 0 25 50 75 100Failure rate (%)Global coordinationBaselineHybrid01234567Time (day)02468101214Buffering ratio (%)Observed (2.91)Projected (1.41)Historical (1.64)01234567Time (day)02468101214Buffering ratio (%)CDN1 (2.11)CDN2 (2.62)CDN3 (3.27)368performance variation and ﬂash crowd.
6.4 Summary of results
• Global control plane works well in all scenarios, including CDN
• A hybrid approach of using the coordinator only at startup time
and relying on pure client-side adaptation may work quite well
in common scenarios.
• However, such a hybrid approach could suffer performance degra-
dation under CDN variability and ﬂash crowds. In such cases, a
control plane can implement more ﬂexible policies. For exam-
ple, under ﬂash crowd it maintains a zero failure rate by reduc-
ing all client bitrates.
• The beneﬁts of a control plane can be realized with simple ex-
trapolation by using predictions from previous epochs.
7. DISCUSSION
Next, we present preliminary insights on how we can address
issues such as scalability, the interactions between such a control
plane and CDNs, and interactions across multiple such controllers.
Scalability: A concern with global optimization is scalability vs.
number of clients and the time to respond to network events. Our
unoptimized implementation in Java takes ≈ 30s to run the global
optimization for 10, 000 clients, 4 CDNs, and 5 bitrates. We specu-
late that typical video utility functions will possess a natural dimin-
ishing property [23]. Intuitively, this means that the incremental
utility in going from a 10% buffering ratio to a 5% buffering ra-
tio will be higher than the increment going from 6% to 1%.
In
this case, there are known techniques to speed up the greedy step
via “lazy evaluation” [30]. Beyond such algorithm optimizations,
we also envision scaling the control plane by logically partitioning
different geographical regions and running one instance per region.
Switching tolerance: A natural question is how much bitrate
switching can users tolerate? Controlled studies suggest users are
sensitive both to frequent switches (e.g., [18]) and also to sudden
changes in bitrate (e.g., [35]). We do not, however, have a good
quantitative understanding on the tradeoff between switching vs.
the desire to maintain high bitrate and low buffering. As this trade-
off becomes clearer with future measurement studies, this can be
incorporated into the control plane optimization function as well.
Interaction with CDNs: One question is whether CDNs can do
(are doing) such optimizations themselves today. While we cannot
speculate about their internal policies, measurement studies sug-
gest that CDNs are largely optimizing for latency [27]. Further-
more, content providers increasingly use multiple CDNs and thus
no single CDN can provide the required cross-CDN optimization.
We do note, however, that the techniques we develop apply equally
well in the context of individual CDNs.
Another concern is whether there can be undesirable interactions
between such higher-level optimization and CDNs’ optimizations.
Of particular concern are possible oscillations caused by such in-
teractions. Unfortunately, it is hard to answer this question due
to the limited visibility we have into CDN policies. Nonetheless,
we hope that this potential problem will be alleviated in the future,
as we envision new generation architectures where CDNs expose
APIs to content providers and such controllers. For example, more
ﬁne-grained information on the available capacity of the CDNs or
current load for different geographical regions can inform better
control plane optimization strategies.
Finally, an emerging direction is the concept of federated CDNs [19,
37]. A federated CDN incorporates a technology integration and
business partnership between carriers and CDNs to provide a uni-
ﬁed CDN offering that has a global presence and beneﬁts to both
CDNs and content providers. For example, a federated CDN elim-
inates the need for the content provider to publish to each CDN.
The global coordinator proposed in this paper is complementary to
a federated CDN and can be used to enable high quality video dis-
tribution across a federated CDN. In fact, we believe a coordinator
is essential to delivering high quality in a federated CDN.
Multiple controllers: So far, we implicitly assumed a simple
model, in which the different controllers are independent, and that
one controller’s decisions will have limited impact on others. In
the future, we expect such controllers to expose APIs to exchange
performance data and policy constraints/preferences, similar to the
way ISPs use BGP to coordinate.
8. RELATED WORK
Client side measurements: The variability in client-side throughput–
across ISPs, within a given viewing session and across multiple
sessions–have been well documented in past measurement studies
(e.g., [26,42]). The natural solution in a video streaming context is
to adapt the video bitrate in response to changing bandwidth con-
ditions to ensure an uninterrupted viewing experience.
Client-side adaptation: Several commercial products today per-
form some form of client-side adaptation to adapt to changing band-
width conditions (e.g., [1,4]) and there are ongoing standardization
efforts in this respect [7]. The key difference here is that these focus
purely on bitrate adaptation. Recent analysis of commercial play-
ers suggest that there is room for improvement in client-adaptation
strategies [17, 39]. As we saw in earlier sections, there is signif-
icant variability in network and CDN performance [31]. Further-
more, there is an inherent need for coordination under overload
which means that even near-ideal client-side mechanisms will not
be sufﬁcient. A global control plane can alleviate these concerns
by coordinating actions across multiple viewers.
Video Coding: Layered coding and multiple description coding
offer alternatives for graceful degradation of video quality (e.g.,
[15, 34]). While these are attractive in theory, they impose sig-
niﬁcantly higher complexity on the provider, delivery, and player
infrastructure. We do note that if these solutions do get deployed,
a video control plane is well-positioned to leverage the additional
ﬂexibility that these offer as it can more smoothly degrade perfor-
mance instead of having to choose from a discrete set of bitrates.
CDN and server selection: Server selection strategies within a
CDN are based on proprietary algorithms, but measurement stud-
ies suggest that these are largely based on proximity and latency
(e.g., [27]). Similarly, in the context of video delivery, the details of
how particular providers choose CDNs or direct clients to different
CDNs are proprietary. Preliminary measurements, however, sug-
gest that the strategies are largely statically conﬁgured (e.g., [41])
and that there appears to be no concerted effort to choose CDNs
either at startup (e.g., [10]) or midstream (e.g., [11]). In making a
case for a global video control plane, our goal is not to pinpoint the
inefﬁciency of particular providers’ selection strategies. Rather, we
want to design a general framework for high-quality video delivery.
Other video measurements: Given the growing dominance of
video trafﬁc, there have been many measurement studies of de-
ployed systems that focus on: content popularity and access pat-
terns (e.g., [16]), the user’s desire for high quality and how it im-
pacts play time (e.g., [21]), user viewing patterns (e.g., [9,22]), and
extreme scenarios such as ﬂash crowds (e.g., [43]). These works
have been instrumental in exposing performance bottlenecks and
implications of user behavior on system design. However, these do
not directly focus on optimizing video quality by intelligent choice
of CDNs and bitrates, which is the focus of our work.
3699. CONCLUSIONS
User expectations of high quality video delivery—low buffer-
ing, low startup delays, and high bitrates— are continuously rising.
While HTTP-based adaptive streaming technologies have dramat-
ically decreased the barrier for content providers to reach a wide
audience, the network and delivery infrastructure these rely on is
fundamentally unreliable. Our measurements from over 200 mil-
lion sessions conﬁrm that this is indeed the case: more than 20% of
sessions suffer quality issues such as more than 10% buffering or
more than 5 seconds startup delay.
Our motivating question was whether it is possible to deliver
high-quality video in such a dynamic environment. Given the sig-
niﬁcant variability in ISP and CDN performance, we argued the
case for a video control plane that uses measurement-driven per-
formance feedback to dynamically adapt video parameters such as
the CDN and bitrate to improve the video quality. We established
the potential for improvement using measurement-driven extrapo-
lation and ﬁnd that optimal CDN selection can improve the buffer-
ing ratio by up to 2× in normal scenarios and more than 10× under
more extreme scenarios. We further augmented these results using
trace-driven simulations and conﬁrm the potential beneﬁts of such
a control plane.
In making a case for a video control plane, our work follows in
the spirit of approaches for CDN and ISP management that show
the beneﬁt of network-wide views. There are several challenges
that need to be addressed before these beneﬁts can be realized in
practice: scalability, interaction with CDNs, issues surrounding
multiple providers and controllers among others.
Acknowledgments
We thank our shepherd Sujata Banerjee and the anonymous review-
ers for their feedback that helped improve the ﬁnal version of the
paper. We also thank Ganesh Ananthanarayanan and Justin Ma for
providing comments on early drafts.
10. REFERENCES
[1] Akamai HD Adaptive Streaming.
http://wwwns.akamai.com/hdnetwork/demo/index.html.
[2] Cisco forecast.
http://blogs.cisco.com/sp/comments/cisco\_visual\
_networking\_index\_forecast\_annual\_update/.
[3] Driving Engagement for Online Video.
http://events.digitallyspeaking.com/akamai/mddec10/
post.html?hash=ZDlBSGhsMXBidnJ3RXNWSW5mSE1HZz09.
[4] Microsoft Smooth Streaming.
http://www.microsoft.com/silverlight/smoothstreaming.
[5] Move networks. http://www.movenetworks.com/.
[6] Video quality metrics. http:
//www.akamai.com/html/solutions/stream_analyzer.html.
[7] I. Sodagar. The MPEG-DASH Standard for Multimedia Streaming Over the
Internet. IEEE Multimedia, 2011.
[8] K. Chen, C. Huang, P. Huang, C. Lei. Quantifying Skype User Satisfaction. In
Proc. SIGCOMM, 2006.
[9] L. Plissonneau and E. Biersack. A Longitudinal View of HTTP Video
Streaming Performance. In Proc. MMSys, 2012.
[10] V. K. Adhikari, Y. Chen, S. Jain, and Z.-L. Zhang. Where Do You Tube?
Uncovering YouTube Server Selection Strategy. In Proc. ICCCN, 2011.
[11] V. K. Adhikari, Y. Guo, F. Hao, V. Hilt, , and Z.-L. Zhang. A Tale of Three
CDNs: An Active Measurement Study of Hulu and Its CDNs. In Proc. IEEE
Global Internet Symposium, 2012.
[12] K. Andreev, B. M. Maggs, A. Meyerson, and R. Sitaraman. Designing Overlay
Multicast Networks for Streaming. In Proc. SPAA, 2003.
[13] D. Applegate, A. Archer, V. Gopalakrishnan, S. Lee, and K. K. Ramakrishnan.
Optimal Content Placement for a Large-Scale VoD System. In Proc. CoNext,
2010.
[14] R. E. Bellman. Adaptive control processes: A guided tour. Princeton University
Press.
[15] J. Byers, M. Luby, and M. Mitzenmacher. A digital fountain approach to
asynchronous reliable multicast. IEEE JSAC, Oct. 2002.
[16] M. Cha, H. Kwak, P. Rodriguez, Y.-Y. Ahn, and S. Moon. I Tube, You Tube,
Everybody Tubes: Analyzing the World’s Largest User Generated Content
Video System. In Proc. IMC, 2007.
[17] L. D. Cicco and S. Mascolo. An Experimental Investigation of the Akamai
Adaptive Video Streaming. In Proc. USAB, 2010.
[18] N. Cranley, P. Perry, and L. Murphy. User perception of adapting video quality.
International Journal of Human-Computer Studies, 2006.
[19] D. Rayburn. Telcos and Carriers Forming new Federated CDN Group called
OCX (Operator Carrier Exchange). June 2011. StreamingMediaBlog.com.
[20] D. P. de Farias and N. Megiddo. Exploration-Exploitation Tradeoffs for Experts
Algorithms in Reactive Environments. In Proc. NIPS, 2004.
[21] F. Dobrian, V. Sekar, A. Awan, I. Stoica, D. A. Joseph, A. Ganjam, J. Zhan, and
H. Zhang. Understanding the impact of video quality on user engagement. In
Proc. SIGCOMM, 2011.
[22] A. Finamore, M. Mellia, M. Munafo, R. Torres, and S. G. Rao. Youtube
everywhere: Impact of device and infrastructure synergies on user experience.
In Proc. IMC, 2011.
[23] G. Nemhauser, L. Wosley, and M. Fisher. An analysis of the approximations for
maximizing submodular set functions. Mathematical Programming,
14:265–294, 1978.
[24] A. George, W. B. Powell, S. R. Kulkarni, and S. Mahadevan. Value function
approximation using multiple aggregation for multiattribute resource
management. http://www.scientiﬁccommons.org/53756787, 2009.
[25] I. Ryzhov and W. B. Powell. Bayesian Active Learning with Basis Functions. In
Proc. IEEE Workshop on Adaptive Dynamic Programming and Reinforcement
Learning, 2011.
[26] C. Kreibich, B. N. V. Paxson, and N. Weaver. Netalyzr: Illuminating The Edge
Network. In Proc. IMC, 2010.
[27] R. Krishnan, H. V. Madhyastha, S. Jain, S. Srinivasan, A. Krishnamurthy,
T. Anderson, and J. Gao. Moving Beyond End-to-End Path Information to
Optimize CDN Performance. In Proc. IMC, 2009.
[28] L. De Cicco, S. Mascolo, and V. Palmisano. Feedback Control for Adaptive
Live Video Streaming. In Proc. of MMSys, 2011.
[29] H. Liu, Y. Wang, Y. R. Yang, A. Tian, and H. Wang. Optimizing Cost and
Performance for Content Multihoming. In Proc. SIGCOMM, 2012.
[30] M. Minoux. Accelerated Greedy Algorithms for Maximizing Submodular Set
Functions. In Proc. of 8th IFIP Conference, Springer-Verlag, 1977.
[31] M. Venkataraman and M. Chatterjee. Effects of Internet Path selection on Video
QoE. In Proc. MMSys, 2011.
[32] A. Mahimkar, Z. Ge, A. Shaikh, J. Wang, J. Yates, Y. Zhang, and Q. Zhao.
Towards Automated Performance Diagnosis in a Large IPTV Network. In Proc.
SIGCOMM, 2009.
[33] A. K. Mccallum. Learning to use selective attention and short-term memory in
sequential tasks. In Proc. Conference on Simulation of Adaptive Behavior,
1996.
[34] S. McCanne, M. Vetterli, and V. Jacobson. Low-complexity video coding for
receiver-driven layered multicast. IEEE JSAC, Aug. 1997.
[35] R. K. P. Mok, E. W. W. Chan, X. Luo, and R. K. C. Chang. Inferring the QoE of
HTTP Video Streaming from User-Viewing Activities . In Proc. SIGCOMM
W-MUST, 2011.
[36] R. S. Peterson and E. G. Sirer. Antfarm: Efﬁcient Content Distribution with
Managed Swarms. In Proc. NSDI, 2009.
[37] R. Powell. The Federated CDN Cometh. May 2011. TelecomRamblings.com.
[38] I. Ryzhov, P. Frazier, and W. Powell. The knowledge gradient algorithm for a
general class of online learning problems. http:
//www.princeton.edu/~iryzhov/journal/online7.pdf, 2011.
[39] S. Akhshabi, A. Begen, C. Dovrolis. An Experimental Evaluation of Rate
Adaptation Algorithms in Adaptive Streaming over HTTP. In Proc. MMSys,
2011.
[40] H. H. Song, Z. Ge, A. Mahimkar, J. Wang, J. Yates, Y. Zhang, A. Basso, and
M. Chen. Q-score: Proactive Service Quality Assessment in a Large IPTV
System. In Proc. IMC, 2011.
[41] R. Torres, A. Finamore, J. R. Kim, M. Mellia, M. M. Munafo, and S. Rao.
Dissecting Video Server Selection Strategies in the YouTube CDN. In Proc.
ICDCS, 2011.
[42] M. Watson. HTTP Adaptive Streaming in Practice. http:
//web.cs.wpi.edu/~claypool/mmsys-2011/Keynote02.pdf.
[43] H. Yin, X. Liu, F. Qiu, N. Xia, C. Lin, H. Zhang, V. Sekar, and G. Min. Inside
the Bird’s Nest: Measurements of Large-Scale Live VoD from the 2008
Olympics. In Proc. IMC, 2009.
370