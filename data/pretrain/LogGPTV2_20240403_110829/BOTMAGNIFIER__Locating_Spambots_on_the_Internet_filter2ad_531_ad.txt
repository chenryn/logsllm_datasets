MAGNIFIER has been assigning the right label to the var-
ious spam campaigns (i.e., the name of the botnet that
generated them). Tagging the campaigns that we ob-
served in our honeypot environment was trivial, while for
the others we used the clustering techniques described in
Section 5. In total, we observed 1,475 spam campaigns.
We tried to assign a botnet label to each cluster, and ev-
ery time two clusters were assigned the same label, we
merged them together. After this process, we obtained
38 clusters. Seven of them were large botnets, which
generated 50,000 or more bot IP addresses in our magni-
ﬁcation results. The others were either smaller botnets,
campaigns carried out by dedicated servers (i.e., not car-
ried out by botnets), or errors produced by the clustering
process.
We could not assign a cluster to 107 campaigns (≈ 7%
of all campaigns), and we magniﬁed these campaigns
independently from the others. Altogether, the magni-
ﬁed sets of these campaigns accounted for 20,675 IP ad-
dresses (≈ 2% of the total magniﬁed hosts). We then
studied the evolution over time and the spamming capa-
bilities of the botnets we were able to label.
6.2.3 Analysis of Magniﬁcation Results
Table 1 shows some results from our tracking. For each
botnet, we list the number of IP addresses we obtained
Interestingly, Lethic,
from the magniﬁcation process.
with 887,852 IP addresses, was the largest botnet we
found. This result is in contrast with the common be-
lief in the security community that, at the time of our
experiment, Rustock was the largest botnet [18]. How-
ever, from our observation, Rustock bots appeared to be
more aggressive in spamming than the Lethic bots. In
fact, each Rustock bot appeared, on average, 173 times
per day on our DNSBL mirror logs, whereas each Lethic
bot showed up only 101 times.
For each botnet population we grew, we distinguished
between static and dynamic IP addresses. We considered
an IP address as dynamic if, during the testing period, we
observed that IP address only once. On the other hand, if
we observed the same IP address multiple times, we con-
sider it as static. The fraction of static versus dynamic
IP addresses for the botnets we tracked goes from 15%
for Rustock to 4% for MegaD. Note that smaller botnets
exceeded the campaign size thresholds required by BOT-
MAGNIFIER (see Section 5) less often than larger bot-
nets, and therefore it is possible that our system under-
estimates the number of IP addresses belonging to the
MegaD and Waledac botnets.
Figures 2(a) and 2(b) show the growth of IP addresses
over time for the magniﬁcation sets belonging to Lethic
and Rustock (note that we experienced a downtime of
the system during November 2010). The ﬁgures show
that dynamic IP addresses steadily grow over time, while
static IP addresses reach saturation after some time. Fur-
thermore, it is interesting to notice that we did not ob-
serve much Rustock activity between December 24, 2010
and January 10, 2011. Several sources reported that the
botnet was (almost) down during this period [14, 37].
BOTMAGNIFIER conﬁrms this downtime of the botnet,
which indicates that our approach can effectively track
the activity of botnets. After the botnet went back up
Botnet
Total # of IP addresses
# of dynamic IP addresses
# of static IP addresses
# of events per bot
Lethic
Rustock
Cutwail
MegaD
Waledac
887,852
676,905
319,355
68,117
36,058
770,517
572,445
285,223
65,062
32,602
117,335
104,460
34,132
3,055
3,450
Table 1: Overview of the BOTMAGNIFIER results
(per day)
101
173
208
112
140
(a) Growth of Lethic IP addresses
(b) Growth of Rustock IP addresses
Figure 2: Growth of the dynamic and static IP address populations for the two major botnets
again in January 2011, we observed a steady growth in
the number of Rustock IP addresses detected by BOT-
MAGNIFIER.
Figures 3(a) and 3(b) show the cumulative distribu-
tion functions of dynamic IP addresses and static IP ad-
dresses tracked during our experiment for the ﬁve largest
botnets. It is interesting to see that we started observing
campaigns carried out by Waledac on January 1, 2011.
This is consistent with the reports from several sources,
who also noticed that a new botnet appeared at the same
time [17, 31]. We also observed minimal spam activities
associated with MegaD after December 7, 2011. This
was a few days after the botmaster was arrested [30].
6.3 Application of Results
False positives.
In Section 4, we showed how the pa-
rameter k minimizes the ratio between true positives and
false positives. We initially tolerated a small number of
false positives because these do not affect the big picture
of tracking large botnet populations. However, we want
to quantify the false positive rate of the results, i.e., how
many of the bot candidates are actually legitimate ma-
chines. This information is important, especially if BOT-
MAGNIFIER is used to inform Internet Service Providers
or other organizations about infected machines. Further-
more, if we want to use the results to improve spam ﬁl-
tering systems, we need to be very careful about which
IP addresses we consider as bots. We use the same tech-
niques outlined in Section 6.1 to check for false posi-
tives. We remove each IP address that matches any of
these techniques from the magniﬁed sets.
We ran this false positive detection heuristic on all the
magniﬁed IP addresses identiﬁed during the evaluation
period. This resulted in 35,680 (≈1.6% of the total) IP
addresses marked as potential false positives. While this
might sound high at ﬁrst, we also need to evaluate how
relevant this false positive rate is in practice: our results
can be used to augment existing systems and thus we can
tolerate a certain rate of false positives. In addition, while
deploying BOTMAGNIFIER in a production system, one
could add a ﬁlter that applies the techniques from Sec-
tion 6.1 to any magniﬁed pool, and obtain clean results
that he could use for spam reduction.
Improving existing blacklists. We wanted to under-
stand whether our approach can improve existing black-
lists by providing information about spamming bots that
are currently active. To achieve this, we analyzed the
email logs from the UCSB computer science department
over a period of two months, from November 30, 2010
to February 8, 2011. As a ﬁrst step, the department mail
server uses Spamhaus as a pre-ﬁltering mechanism, and
therefore the majority of the spam gets blocked before
01000002000003000004000005000006000007000008000002010-09-272010-10-072010-10-172010-10-282010-11-072010-12-052010-12-152010-12-252011-01-042011-01-142011-01-242011-02-03Daysdynamic IPsstatic IPs01000002000003000004000005000006000002010-09-272010-10-072010-10-172010-10-282010-11-072010-12-052010-12-152010-12-252011-01-042011-01-142011-01-242011-02-03Daysdynamic IPsstatic IPs(a) CDF for the dynamic IP addresses
(b) CDF for the static IP addresses
Figure 3: Cumulative Distribution Function for the bot populations grown by BOTMAGNIFIER
being processed. For each email whose sender is not
blacklisted, the server runs SpamAssassin [3] for content
analysis, to ﬁnd out if the message content is suspicious.
SpamAssassin assigns a spam score to each message, and
the server ﬂags it as spam or ham according to that value.
These two steps are useful to evaluate how BOTMAGNI-
FIER performs, for the following reasons:
• If a mail reached the server during a certain day, it
means that at that time its sender was not blacklisted
by Spamhaus.
• The spam ratios computed by SpamAssassin pro-
vide a method for the evaluation of BOTMAGNI-
FIER’s false positives.
During the analysis period, the department mail server
logged 327,706 emails in total, sent by 228,297 distinct
IP addresses. Of these, 28,563 emails were considered
as spam by SpamAssassin, i.e., they bypassed the ﬁrst
ﬁltering step based on Spamhaus. These mails had been
sent by 10,284 IP addresses. We compared these IP ad-
dresses with the magniﬁed sets obtained by BOTMAG-
NIFIER during the same period: 1,102 (≈ 10.8%) ap-
peared in the magniﬁed sets. We then evaluated how
many of these IP addresses would have been detected be-
fore reaching the server if our tool would have been used
in parallel with the DNSBL system. To do this, we an-
alyzed how many of the spam sender IP addresses were
detected by BOTMAGNIFIER before they sent spam to
our server. We found 295 IP addresses showing this be-
havior. All together, these hosts sent 1,225 emails, which
accounted for 4% of the total spam received by the server
during this time.
We then wanted to quantify the false positives in the
magniﬁed pools generated by BOTMAGNIFIER. To do
this, we ﬁrst searched for those IP addresses that were
in one of the magniﬁcation pools, but had been consid-
ered sending ham by SpamAssassin. This resulted in 28
matches. Of these, 15 were blacklisted by Spamhaus
when we ran the tests, and therefore we assume they are
false negatives by SpamAssassin. Of the remaining 13
hosts, 12 were detected as legitimate servers by the ﬁl-
ters described in Section 6.1. For the remaining one IP
address, we found evidence of it being associated with
spamming behavior on another blacklist [23]. We there-
fore consider it as a false negative by SpamAssassin as
well.
In summary, we conclude that BOTMAGNIFIER can
be used to improve the spam ﬁltering on the department
email server: the server would have been reached by 4%
less spam mails, and no legitimate emails would have
been dropped by mistake within these two months. Hav-
ing access to more Spamhaus mirrors would allow us to
increase this percentage.
Resilience to evasion.
If the techniques introduced by
BOTMAGNIFIER become popular, spammers will mod-
ify their behavior to evade detection. In this section, we
discuss how we could react to such evasion attempts.
The ﬁrst method that could be used against our system
is obfuscating the email subject lines, to prevent BOT-
MAGNIFIER from creating the seed pools. If this was the
case, we could leverage previous work [22,40] that takes
into account the body of emails to identify emails that are
sent by the same botnet. As an alternative, we could use
different methods to build the seed pools, such as clus-
tering bots based on the IPs of the C&C servers that they
contact.
Another evasion approach spammers might try is to re-
duce the number of bots associated with each campaign.
The goal would be to stay under the threshold required
by BOTMAGNIFIER (i.e., 1,000) to work. This would re-
quire more management effort on the botmaster’s side,
since more campaigns would need to be run. Moreover,
we could use other techniques to cluster the spam cam-
00.20.40.60.812010-09-272010-10-072010-10-172010-10-282010-11-072010-12-052010-12-152010-12-252011-01-042011-01-142011-01-242011-02-03Dayslethicrustockcutwailmegadwaledac00.20.40.60.812010-09-272010-10-072010-10-172010-10-282010-11-072010-12-052010-12-152010-12-252011-01-042011-01-142011-01-242011-02-03Dayslethicrustockcutwailmegadwaledacpaigns. For example, it is unlikely that the spammers
would set up a different website for each of the small
campaigns they create. We could then cluster the cam-
paigns by looking at the web sites the URLs in the spam
emails point to.
Other evasion techniques might be to assign a single
domain to each spamming bot, or to avoid evenly dis-
tributing email lists among bots. In the ﬁrst case, BOT-
MAGNIFIER would not be able to unequivocally identify
a bot as being part of a speciﬁc botnet. However, the at-
tribution requirement could be dropped, and these bots
would still be detected as generic spamming bots. The
second case would be successful in evading our current
systems. However, this behavior involves something that
spammers want to avoid: having the same bot sending
thousands of emails to the same domain within a short
amount of time would most likely result in the bot being
quickly blacklisted.
6.4 Universality of k
In Section 4, we introduced a function to determine the
optimal N value according to the size of the seed pool’s
target |T (pi)|. To do this, we analyzed the data from two
C&C servers of the Cutwail botnet. One could argue that
this parameter will work well only for campaigns carried
out by that botnet. To demonstrate that the value of k
(and subsequently of N) estimated by the function pro-
duces good results for campaigns carried out by other
botnets, we ran the same precision versus recall tech-
nique we used in Section 4 on other datasets. Speciﬁ-
cally, we analyzed 600 campaigns observed in the wild,
that had been carried out by the other botnets we stud-
ied (Lethic, Rustock, Waledac, and MegaD). Since we
did not have access to full ground truth for these cam-
paigns, we used the IP addresses from the seed pools as
true positives, and the set of IP addresses not blacklisted
by Spamhaus as false positives. For the purpose of this
analysis, we ignored any other IP address returned by
the magniﬁcation process (i.e., magniﬁed IP addresses
already blacklisted by Spamhaus).
The results are shown in Figure 4. The ﬁgure shows
the function plot of k in relation to the size of |T (pi)|.
The dots show, for each campaign we analyzed, where
the optimal value of k lies. As it can be seen, the func-
tion of k we used approximates the optimal values for
most campaigns well. This technique for setting k might
also be used to set up BOTMAGNIFIER in the wild, when
ground truth is not available.
Data stream independence.
In Section 2.2, we
claimed that BOTMAGNIFIER can work with any kind of
transaction log as long as this dataset provides informa-
tion about which IP addresses sent email to which des-
tination email servers at a given point in time. To con-
ﬁrm this claim, we ran BOTMAGNIFIER on an alterna-
Figure 4: Analysis of our function for k compared to the
optimal value of k for 600 campaigns
Figure 5: Precision vs. Recall functions for ﬁve cam-
paigns observed in the netﬂow dataset
tive dataset, extracted from netﬂow records [7] collected
by the routers of a large Internet service provider. The
netﬂow data is collected with a sampling rate of 1 out
of 1,000. To extract the data in a format BOTMAGNI-
FIER understands, we extracted each connection directed
to port 25 TCP, and considered the timestamp in which
the connection initiated as the time the email was sent.
On average, this transaction log contains 1.9 million en-
tries per day related to about 194,000 unique sources.
To run BOTMAGNIFIER on this dataset, we ﬁrst need
to correctly dimension k. As explained in Section 4, the
equation for k is stable for any transaction log. How-
ever, the value of the constants kb and α changes for
each dataset. To correctly dimension these parameters,
we ran BOTMAGNIFIER on several campaigns extracted
from the netﬂow records. The P R(k) analysis is shown
in Figure 5. The optimal point of the campaigns is lo-
cated at a lower k for this dataset compared to the ones
analyzed in Section 4. To address this difference, we
set kb to 0.00008 and α to 1 when dealing with netﬂow
records as transaction logs. After setting these param-
 0 0.002 0.004 0.006 0.008 0.01 10000 20000 30000 40000 50000 60000 70000 80000k|T(Pi)|k functionoptimal k 0 0.2 0.4 0.6 0.8 1 0 0.0002 0.0004 0.0006 0.0008 0.001 0.0012 0.0014PR(k)kcampaign with 23,524 dest.campaign with 14,439 dest.campaign with 12,054 dest.campaign with 10,348 dest.campaign with 3,048 dest.eters, we analyzed one week of data with BOTMAGNI-
FIER. The analysis period was between January 20 and
January 28, 2011. During this period, we tracked 94,894
bots. Of these, 36,739 (≈ 38.7%) belonged to the mag-
niﬁed sets of the observed campaigns. In particular, we
observed 40,773 Rustock bots, 20,778 Lethic bots, 6,045
Waledac bots, and 1,793 Cutwail bots.
7 Related Work
Spam is one of the major problems on the Internet, and as
a result, has attracted a considerable amount of research.
In this section, we brieﬂy review related work in this area
and discuss the novel aspects of BOTMAGNIFIER.
Botnet Tracking. A popular method to gain deeper in-
sights into a particular botnet is botnet tracking, i.e., an
attempt to learn more about a given botnet by analyzing
its inner workings in detail [1, 8]. There are several ap-
proaches to conduct the actual analysis, for example by
taking over the C&C infrastructure and then performing
a live analysis [26,33]. An orthogonal approach is to take