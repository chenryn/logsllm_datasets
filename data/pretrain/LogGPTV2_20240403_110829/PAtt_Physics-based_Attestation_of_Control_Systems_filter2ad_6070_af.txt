### References

1. **For Computing Platforms: Caring about Properties, Not Mechanisms**. In *Proceedings of the 2004 Workshop on New Security Paradigms (NSPW '04)*, pages 67–77, New York, NY, USA, 2004. ACM.

2. **A.-R. Sadeghi, I. Visconti, and C. Wachsmann**. Enhancing RFID Security and Privacy by Physically Unclonable Functions. In *Towards Hardware-Intrinsic Security*, pages 281–305. Springer, 2010.

3. **S. Schüppen, D. Teubert, P. Herrmann, U. Meyer, and S. Sch**. Fanci: Feature-Based Automated NXDOMAIN Classification and Intelligence. In *Proceedings of the 27th USENIX Conference on Security Symposium*, pages 1165–1181. USENIX Association, 2018.

4. **A. Seshadri, M. Luk, A. Perrig, L. V. Doorn, and P. Khosla**. SCUBA: Secure Code Update By Attestation in Sensor Networks. In *ACM WiSec*, 2006.

5. **A. Seshadri, M. Luk, A. Perrig, L. van Doorn, and P. Khosla**. Using FIRE & ICE for Detecting and Recovering Compromised Nodes in Sensor Networks. *Technical Report, DTIC Document*, 2004.

6. **A. Seshadri, M. Luk, E. Shi, A. Perrig, L. Van Doorn, and P. Khosla**. Pioneer: Verifying Code Integrity and Enforcing Untampered Code Execution on Legacy Systems. In *ACM SIGOPS OSR*, 2005.

7. **U. Shankar, M. Chew, and J. D. Tygar**. Side Effects Are Not Sufficient to Authenticate Software. In *USENIX Security*, May 2004.

8. **A. K. Sikder, H. Aksu, and A. S. Uluagac**. 6thsense: A Context-Aware Sensor-Based Attack Detector for Smart Devices. In *USENIX Security*, 2017.

9. **R. P. Stanley**. *Enumerative Combinatorics, Volume 1*. Cambridge University Press, second edition, 2012. Pages 64-67.

10. **K. Stouffer, J. Falco, and K. Scarfone**. Guide to Industrial Control Systems (ICS) Security. *NIST Special Publication*, 800(82):16–16, 2011.

11. **R. Strackx, F. Piessens, and B. Preneel**. Efficient Isolation of Trusted Subsystems in Embedded Systems. In *SecureComm*. Springer, 2010.

12. **D. I. Urbina, J. A. Giraldo, A. A. Cardenas, N. O. Tippenhauer, J. Valente, M. Faisal, J. Ruths, R. Candell, and H. Sandberg**. Limiting the Impact of Stealthy Attacks on Industrial Control Systems. In *Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security*, pages 1092–1105. ACM, 2016.

13. **J. Valente, C. Barreto, and A. A. Cárdenas**. Cyber-Physical Systems Attestation. In *2014 IEEE International Conference on Distributed Computing in Sensor Systems (DCOSS)*, pages 354–357. IEEE, 2014.

14. **O. Willers, C. Huth, J. Guajardo, and H. Seidel**. MEMS Gyroscopes as Physical Unclonable Functions. In *Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security*, pages 591–602. ACM, 2016.

15. **I. H. Witten, E. Frank, M. A. Hall, and C. J. Pal**. *Data Mining: Practical Machine Learning Tools and Techniques*. Morgan Kaufmann, 2016.

### Appendices

#### 10.1 The Aging Effect on Classification Performance

The aging effect has been reported in many PUF applications at the semiconductor level [38, 46]. However, such an effect is not common in mechanical actuators (the preciseness guarantee of the actuators can be found in their datasheets). We evaluated the aging effect by considering two datasets: one from 6 months ago (old dataset) and a recent dataset. As shown in Table 4, the tuned classifier provided better classification results. We recommend performing the tuning of the classifier by including recent normal traces during the idle time of the CPS. However, the performance of the classifier built using the old dataset is sufficient for the robot arm use-case evaluated in this paper. Figure 6 shows the true positive rate (sensitivity) against the false positive rate (1-precision), considering the aging effect. As seen in Figure 6, the classification performance of the classifiers with the old and recent sensor traces are close to each other.

#### 10.2 Performance Metrics

To evaluate the performance of the proposed method, we used eight performance metrics:

- **True Positive (TP)**: The number of retrieved relevant instances.
- **False Positive (FP)**: The number of retrieved non-relevant instances.
- **True Negative (TN)**: The number of not retrieved non-relevant instances.
- **False Negative (FN)**: The number of not retrieved relevant instances.

**Sensitivity (Recall)**:
\[ \text{Sensitivity} = \frac{\text{TP}}{\text{TP} + \text{FN}} \]

**Precision (Specificity)**:
\[ \text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}} \]

**False Positive Rate (FPR)**:
\[ \text{FPR} = \frac{\text{FP}}{\text{FP} + \text{TN}} \]

**False Negative Rate (FNR)**:
\[ \text{FNR} = \frac{\text{FN}}{\text{FN} + \text{TP}} \]

**False Discovery Rate (FDR)**:
\[ \text{FDR} = \frac{\text{FP}}{\text{FP} + \text{TP}} \]

**Accuracy**:
\[ \text{Accuracy} = \frac{\text{TP} + \text{TN}}{\text{TP} + \text{TN} + \text{FP} + \text{FN}} \]

**F1-Score**:
\[ \text{F1-Score} = \frac{2 \times \text{Sensitivity} \times \text{Precision}}{\text{Sensitivity} + \text{Precision}} \]

**Matthews Correlation Coefficient (MCC)**:
\[ \text{MCC} = \frac{\text{TP} \times \text{TN} - \text{FP} \times \text{FN}}{\sqrt{(\text{TP} + \text{FP}) \times (\text{TP} + \text{FN}) \times (\text{TN} + \text{FP}) \times (\text{TN} + \text{FN})}} \]

#### 10.3 Decoding ROC

Our ROC curve (true positive rate (sensitivity) against the false positive rate (1-precision)) for the decoding classifiers is presented in Figure 7.

#### 10.4 An Example of Path Strategy

Figure 8 represents the path strategy for the sequences 10100010 (red) and 00000111 (dashed green). The number of unique paths \( u \) in an \( x \times y \) grid can be computed as follows [57]:
\[ u = \frac{(x + y)!}{x! \cdot y!} \]

Thus, we can enumerate all possible paths and use an integer between 1 and \( u \) as an index to represent a specific path strategy in an \( x \times y \) grid.

### Figures and Tables

**Table 4: Performance Comparison of Different Classifiers with Various Metrics**

| Algorithm | Sensitivity | Specificity | Precision | FPR | FNR | Accuracy | F1-Score | MCC |
|-----------|-------------|-------------|-----------|-----|-----|----------|----------|-----|
| RF (old)  | 0.9857      | 0.9913      | 0.9912    | 0.0087 | 0.0143 | 0.9885   | 0.9770   |     |
| MLP (old) | 0.9952      | 0.9826      | 0.9827    | 0.0174 | 0.0048 | 0.9889   | 0.9779   |     |
| RF (recent)| 0.9912      | 0.9897      | 0.9897    | 0.0103 | 0.0088 | 0.9905   | 0.9810   |     |
| MLP (recent)| 0.9881      | 0.9905      | 0.9904    | 0.0095 | 0.0119 | 0.9893   | 0.9786   |     |

**Figure 6: ROC Curve of True Positive Rate (Sensitivity) Against False Positive Rate (1-Precision)**

**Figure 7: ROC Curve of True Positive Rate (Sensitivity) Against False Positive Rate (1-Precision) for Decoding Classifiers**

**Figure 8: Two Examples of Path Strategies: Red=10100010, Dashed Green=00000111**