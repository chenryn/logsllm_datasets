collection runs (since most objects are short-lived, their
space can be reclaimed very quickly), but it is also very
convenient for Fuzz, as we shall see below.
Note that Fuzz uses the ZAM runtime to run only pro-
grams that it has previously translated from Fuzz pro-
grams. Thus, we can safely ignore features of the ZAM
runtime (such as reference cells) that Fuzz does not use.
Our threat model assumes that the adversary can submit
only Fuzz programs, so he or she is unable to access any
of these features.
7.2 Bounded deallocation
When a microquery times out, Fuzz must be able, within
a bounded amount of time, to release all of the resources
the microquery may have allocated. To this end, our im-
plementation performs a minor collection at the begin-
ning of each macroquery, which clears the young zone
of the heap, and it conﬁnes any additional memory al-
locations during microqueries to the young zone. Thus,
we can simply discard the entire young zone after each
microquery, which requires only a single instruction. If
the microquery completes normally (without a timeout),
it writes its result into a special ﬁxed-size buffer that is
not part of young zone. If this buffer is empty after the
microquery or contains only a partial result, the macro-
query uses the default value instead.
Discarding the entire young zone is safe because, after
a microquery, there cannot be any outside references to
objects in that zone. Any new memory allocations must
be in the young zone, any new values on the stacks are
discarded as well, and the only objects in the old zone
10
that could be modiﬁed in place are reference cells, which
translated Fuzz programs cannot use. Note that discard-
ing the young zone is faster than a minor collection, so
this particular modiﬁcation (which is only possible for
Fuzz programs, not for arbitrary Caml programs) actu-
ally results in a speedup.
7.3 Preemptability
Fuzz must be able to preempt a running microquery af-
ter a speciﬁed time, with high precision. To this end, our
implementation creates a second thread that continuously
spins on the CPU’s timestamp counter (TSC).3 When a
microquery is started, the interpreter sets a shared vari-
able to the time at which the preemption should occur;
when that point is reached, the second thread sends a sig-
nal to the interpreter thread. To prevent the two threads
from slowing each other down, each is pinned to a dif-
ferent CPU core. If the microquery terminates before the
timeout, it simply spins until the preemption occurs.
Preemptions can occur at arbitrary points in the run-
time code. To avoid inconsistencies, our implementation
checkpoints all mutable state before each microquery;
when the signal is raised, it uses longjmp to return to the
macroquery and then restores the runtime state from the
checkpoint. We exclude from the checkpoint any state
that either is immutable or is discarded anyway – includ-
ing both zones of the heap and any existing values on the
stacks. This leaves just a handful of variables, such as
the ZAM’s stack pointers and the code pointer.
7.4 Isolation
Fuzz must ensure that a microquery cannot interfere with
the rest of the computation in any way, other than con-
tributing its return value. In the previous two sections,
we have already seen that the states of the ZAM runtime
before and after a microquery are logically equivalent,
since any changes (other than the result value) are either
discarded or rolled back. To avoid direct timing inter-
ference between microqueries, Fuzz also pads the run-
time of the preemption code to ∆a + ∆d. However, Fuzz
must also avoid indirect timing interference through the
garbage collector, or from the rest of the system.
invocations of
Fuzz prevents data-dependent
the
garbage collector by padding all database rows to con-
sume the same amount of memory, and by padding all
database objects to have the same number of rows. For
databases that result from a split, Fuzz adds an appro-
priate number of dummy rows that consume memory and
computation time but do not contribute to the result. Fuzz
also disables the garbage collector during microqueries;
if a microquery attempts to allocate more space than is
3There are many other ways of implementing preemptions, such as
periodic TSC checks in the interpreter loop, or using the CPU’s perfor-
mance counters.
11
available in the young zone of the heap, Fuzz stops it and
forces it to time out. Thus, from the perspective of the
macroquery (and the garbage collector), memory usage
does not depend on un-noised values from the database.
To prevent page faults and context switches, Fuzz pre-
allocates and pins all of its memory pages, and it as-
signs itself a real-time scheduling priority. In our experi-
ments, this was sufﬁcient to control the timing variations
to within a a few microseconds.
7.5 Implementation effort
Altogether, we added or modiﬁed 6,256 lines of code, in-
cluding 4,887 lines of C++ for the typechecker/translator,
1,119 lines of C++ and Caml code for our implemen-
tation of predictable transactions, 186 lines of C++ for
benchmarking support, and 64 lines of Fuzz code for
common library functions. For comparison, the entire
Caml Light codebase consists of 29,984 lines of code.
This supports our claim that Fuzz can be retroﬁtted into
existing runtimes.
7.6 Limitations
Despite all our precautions, some potential sources of
variability remain. For example, our current implemen-
tation does not freeze or ﬂush the CPU’s caches (since in-
structions like wbinvd are not available from user level),
and it is designed to run on a commodity Linux kernel.
We believe that these sources would be difﬁcult to exploit
because the adversary cannot control the memory lay-
out or force the runtime to invoke system calls; also, any
exploitable variation would have to be large enough to
cause the ∆a + ∆d padding to be overrun. An implemen-
tation with at least some kernel support could remove
some or all of these sources, and thus use a less conser-
vative padding.
8 Evaluation
Our evaluation has two primary goals. First, we need
to demonstrate that Fuzz is practical, in the sense that
it is sufﬁciently fast and expressive to process realis-
tic queries. Second, we need to demonstrate that our
Fuzz implementation is effective, i.e., that it prevents all
the covert-channel attacks that are possible in our threat
model (Section 3.1).
8.1 Non-adversarial queries
To demonstrate that Fuzz is powerful enough to support
useful queries, we implemented three example queries
that were motivated in prior work [4, 6, 12]. The weblog
query is intended to run on the log of an Apache web
server; it computes a histogram of the number of web
requests that came from speciﬁc subnets. The kmeans
query clusters a set of points and returns the three cluster
Name
kmeans
census
weblog
Type
Clustering
Aggregation
Histogram
LoC Inspired by
119
50
45
[4]
[6]
[12]
Table 3: Examples of non-adversarial Fuzz queries.
centers, and the census query runs on census data and
reports the income differential between men and women.
Table 3 reports the lines of code needed for each query.
The queries are small because programmers only need to
specify the actual data processing; parsing and I/O are
handled by Fuzz. Also, the queries use a small library of
generic primitives, such as lists and a fold operator, that
consists of 64 lines written directly in the Fuzz language.
Note that Fuzz can automatically certify queries as dif-
ferentially private and perform sensitivity analysis dur-
ing typechecking, so even non-experts can easily write
differentially private queries.
8.2 Experimental setup
To evaluate the performance and effectiveness of Fuzz,
we performed experiments using a setup consistent with
our model from Section 3.1. We installed Fuzz on a ded-
icated machine, a Dell Optiplex 780 with a 3.06 Ghz In-
tel Core 2 Duo E7600 processor and 4 GB of memory.
The machine was running a 32-bit Ubuntu Linux 11.04
with a 2.6.38-8 kernel. For our timing measurements,
we used the CPU’s timestamp counter, which is cycle-
accurate. To minimize interference, we disabled CPU
power management and the ﬂush daemon, we kept all
mutable data in a ramdisk and mounted all other ﬁle sys-
tems read-only, and we terminated all other processes on
the machine, leaving Fuzz as the only running process
(recall our assumption that the machine is dedicated to
Fuzz). As discussed in Section 7.6, there are sources of
timing variability that we could not disable, such as the
periodic timer interrupt, which takes about 3 µs to han-
dle in this setup, but these cannot be inﬂuenced by an
adversary, so they merely add noise to the query comple-
tion time without leaking information. The padding time,
which corresponds to ∆a + ∆d, was set to 10 µs; this set-
ting was chosen to be the highest preemption latency we
observed, plus a generous safety margin.
To estimate the overhead of our implementation, we
also prepared a version of the three translated Fuzz
queries that can run on the original Caml Light runtime.
Since the original runtime does not support P-TRANS or
a ﬁxed-size memory representation for databases, this
required small modiﬁcations to the Caml code; for ex-
ample, the modiﬁed queries invoke microqueries with-
out any timeouts, and they keep the database in ordinary
Caml lists. These modiﬁcations do not affect the data
output of the queries. We used the modiﬁed Caml code
Original runtime
Fuzz (no padding)
Fuzz
)
s
(
e
m
l
i
t
n
o
i
t
e
p
m
o
c
y
r
e
u
Q
 14
 12
 10
 8
 6
 4
 2
 0
kmeans
census
weblog
Figure 5: Performance for non-adversarial queries.
only for experiments with the original Caml Light run-
time; all other experiments directly use the Caml code
that is output by the Fuzz front-end.
8.3 Macrobenchmarks
To estimate the performance of Fuzz, we ran each of the
example queries from Table 3 over a synthetic dataset
and measured the query completion time. Using syn-
thetic data rather than real private data does not affect
our measurements because, by design, the completion
time does not depend on the contents of the database.
However, the data format was based on realistic data—
speciﬁcally, the weblog input was based on an Apache
server log and the census input was based on U.S. census
data from [14]. The synthetic database in each case had
10,000 rows. We set the microquery timeouts for each
map and split by ﬁrst running the query over example
data with timeouts and padding disabled, measuring the
maximum time taken by any of the map or split’s mi-
croqueries, and then setting the timeout to be 10% above
that. We veriﬁed that no timeouts occurred during our
measurements.
Figure 5 shows the query completion time for three
different conﬁgurations:
the original Caml Light run-
time, the Fuzz runtime with both timeouts and padding
disabled, and the Fuzz runtime with all features en-
abled. As expected, Fuzz takes more time to com-
plete the queries than the original runtime; for our three
queries, the slowdown was between 2.5x (census) and
6.8x (kmeans). However, in absolute terms, the com-
pletion times were not unreasonable: the most expensive
query (kmeans) took 12.7s to complete, which seems low
enough to be practical.
Figure 5 also shows that, with timeouts and padding
disabled, Fuzz’s performance is roughly comparable to
that of the original Caml Light runtime. This is not an
apples-to-apples comparison; for example, the ﬁxed-size
memory representation for databases costs performance,
whereas erasing the young zone after each microquery is
actually faster than garbage-collecting it. Nevertheless,
12
Time padding (P4)
Storing results (P3)
Waiting for preemption (P2)
Microqueries (P1)
)
s
(
e
m
T
i
 14
 12
 10
 8
 6
 4
 2
 0
l
s
a
i
r
t
f
o
n
o
i
t
c
a
r
F
100 %
80 %
60 %
40 %
20 %
0 %
Without padding
With padding
kmeans
census
weblog
-200 -150 -100
-50
 0
 50
 100  150  200
Deviation from the median (microseconds)
Figure 6: Time spent in different phases of query pro-
cessing.
Figure 7: Variation of completion time for the weblog-
delay query.
the numbers suggest that most of the overhead comes
from padding and timeouts. Next, we examine this in
more detail.