### 3.2 Training Data

To ensure a fair comparison of cracking approaches, we used the same training data for each. However, it is important to note that each algorithm utilizes this data differently, making perfectly equivalent comparisons impossible.

Our training data consisted of leaked passwords and dictionaries. The passwords were sourced from breaches at MySpace, RockYou, and Yahoo! (excluding the 30,000 passwords analyzed in Appendix A.4). Using leaked passwords raises ethical concerns, but we believe our use is justifiable because these password sets are already publicly available, and we have excluded personally identifiable information such as usernames. Additionally, malicious actors often use these sets in attacks [23], and ignoring them in our analysis could give attackers an advantage over those working in defensive security.

Previous research has shown that including natural-language dictionaries improves performance compared to using only passwords [31, 69]. We used the following dictionaries, which have been found to be most effective:
- All single words in the Google Web corpus [26]
- The UNIX dictionary [1]
- A 250,000-word inflection dictionary [55]

The combined set of passwords and dictionaries contained 19.4 million unique entries. For cracking approaches that require only a wordlist without frequency information, we ordered the wordlist by descending frequency and removed duplicates. For other approaches, we included frequency information.

### 3.3 Simulating Password Cracking

To investigate how the choice of cracking algorithm can bias research results and to compare automated approaches with real-world attacks, we evaluated two cracking tools and two probabilistic algorithms. Our selection was based on their popularity in academic literature and the password-cracking community, as well as their conceptual distinctness. We also contracted a computer security firm specializing in password cracking to conduct a real-world attack.

Most cracking approaches do not natively provide guess numbers, and instrumenting them to calculate guessability is typically non-trivial. This instrumentation enabled the comparisons in this paper and can support future research. We include detailed information about this instrumentation in this section. Additionally, in Section 5, we introduce a Password Guessability Service to allow other researchers to leverage our instrumentation and computational resources.

For each approach, we made as many guesses as computationally feasible, ranging from 100 trillion (10^14) guesses for some approaches to ten billion (10^10) guesses for the most resource-intensive approach. Except for Hashcat, we filtered out guesses that did not comply with the password set's composition policy. For example, a LongComplex password’s guess number excludes guesses with fewer than 12 characters or fewer than 3 character classes.

We define Minauto as the minimum guess number (and therefore the most conservative security result) for a given password across our automated cracking approaches. This number approximates the best researchers can expect with well-configured automation.

In the following subsections, we detail the configuration (and terminology) of the five approaches we tested. We ran CPU-based approaches (JTR, PCFG, Markov) on a 64-core server with AMD Opteron 6274 processors running at 1.4 GHz, 256 GB of RAM, and 15 TB of disk. Despite its market value of over $10,000, we faced significant resource limitations generating Markov guesses. We ran Hashcat (specifically, oclHashcat) on a machine with six AMD R9 270 GPUs, 2 GB of RAM, and a dual-core processor.

#### Probabilistic Context-Free Grammar (PCFG)

Weir et al.’s probabilistic context-free grammar (PCFG) [70] has been widely discussed in recent years. We used Komanduri’s implementation of PCFG [32], which improves upon Weir et al.’s work by assigning letter strings probabilities based on their frequency in the training data and assigning unseen strings a non-zero probability. This implementation is a newer version of Kelley et al.’s implementation of PCFG as a lookup table for quickly computing guess numbers, rather than enumerating guesses [31].

Based on initial testing, we prepended our training data, ordered by frequency, before PCFG’s first guess to improve performance. As a result, we did not use Komanduri’s hybrid structures [32], which serve a similar purpose. We weighted passwords 10 times more heavily than dictionary entries. We were able to simulate 10^12 guesses for Complex passwords and 10^14 guesses for the other three sets.

#### Markov Model

We evaluated the Markov-model password guesser presented by Ma et al. [40], which implemented several variants differing by order and smoothing approaches. We used the order-5 Markov-chain model, which they found most effective for English-language test sets. We tried using both our combined training data (dictionaries and passwords) with the same weighting as with PCFG, as well as only the passwords from our training data. The combined training data and passwords-only training data performed nearly identically. We report only on the combined training data, which was slightly more effective for Basic passwords and is most consistent with the other approaches.

We used Ma et al.’s code [40] to enumerate a list of guesses in descending probability and a separate program to remove guesses that did not conform to the given password-composition policy. This approach is extremely resource-intensive, both conceptually (traversing a very large tree) and in its current implementation. We simulated over 10^10 guesses for Basic passwords, similar to Ma et al. [40].

#### John the Ripper (JTR)

We tested variants of a mangled wordlist attack implemented in two popular software tools. The first tool, John the Ripper (JTR), has been used in several prior studies as a security metric. In most cases, these prior studies used JTR with its stock mangling rules. However, pairing the stock rules with our 19.4-million-word wordlist produced only 10^8 guesses for Basic passwords. To generate more guesses, we augmented the stock rules with 5,146 rules released for DEF CON’s “Crack Me If You Can” (CMIYC) password-cracking contest in 2010 [35]. Specifically, we used Trustwave SpiderLabs’ reordering of these rules for guessing efficiency [64].

Instrumenting JTR to calculate precise guess numbers was an involved process. We used john-1.7.9-jumbo with the --stdout flag to output guesses to standard out and piped these guesses into a program we wrote to perform a regular expression check, filtering out guesses that do not conform to the given password policy. This program then used GNU gperf [27] for fast hash table lookups to quickly evaluate whether a guess matches a password in our dataset. Using this method, we achieved a throughput speed of 3 million guesses per second and made more than 10^13 guesses for Basic passwords.

#### Hashcat

While Hashcat is conceptually similar to JTR, we included it in our tests for two reasons. First, we discovered in our testing that JTR and Hashcat iterate through guesses in a very different order, leading to significant differences in the efficacy of guessing specific passwords. JTR iterates through the entire wordlist using one mangling rule before proceeding to the subsequent mangling rule. Hashcat, in contrast, iterates over all mangling rules for the first wordlist entry before continuing to the subsequent wordlist entry.

Second, the GPU-based oclHashcat, which is often used in practice [23, 24, 36, 51], does not permit users to filter guesses that do not meet password-composition requirements except for computationally expensive hash functions. We accept this limitation because it represents the actual behavior of a popular closed-source tool and because, for fast hashes like MD5 or NTLM, guessing without filtering cracks passwords faster in practice than applying filtering.

Unlike JTR, Hashcat does not have a default set of mangling rules, so we evaluated several. We generally report on only the most effective set, but detail our tests of four different rule sets in Appendix A.3. The most effective rule set, which we term Hashcat throughout the paper, resulted from our collaboration with a Hashcat user and password researcher from MWR InfoSecurity [25, 44], who shared his mangling rules for the purpose of this analysis. We believe such a configuration represents a typical expert configuration of Hashcat.

We used oclHashcat-1.21. While, like JTR, Hashcat provides a debugging feature that streams guesses to standard output, we found it extremely slow in practice relative to Hashcat’s very efficient GPU implementation. In support of this study, Hashcat’s developers added a feature to oclHashcat to count how many guesses it took to arrive at each password it cracked. This feature is activated using the --outfile-format=11 flag in oclHashcat-1.20 and above. We hashed the passwords in our datasets using the NTLM hash function, which was the fastest for Hashcat to guess in our benchmarks. We then used Hashcat to crack these passwords while counting guesses, with a throughput of roughly 10 billion guesses per second on our system. We made more than 10^13 guesses for Basic passwords, along with nearly 10^15 guesses for some alternate configurations reported in Appendix A.3.

#### Professional Cracker

An open question in measuring password guessability using off-the-shelf, automated tools is how these attacks compare to an experienced, real-world attacker. Such attackers manually customize and dynamically update their attacks based on a target set’s characteristics and initial successful cracks.

To address this, we contracted KoreLogic (termed Pros), an industry leader in professional password recovery services, to attack the password sets we studied. We believe KoreLogic is representative of expert password crackers because they have organized the DEF CON “Crack Me If You Can” password-cracking contest since 2010 [36] and perform password-recovery services for many Fortune-500 companies [38]. For this study, they instrumented their distributed cracking infrastructure to count guesses.

Like most experienced crackers, the KoreLogic analysts used tools including JTR and Hashcat with proprietary wordlists, mangling rules, mask lists, and Markov models optimized over 10 years of password auditing. They also dynamically updated their mangling rules (termed freestyle rules) as additional passwords were cracked. To unpack which aspects of a professional attack (e.g., proprietary wordlists and mangling rules, freestyle rules, etc.) give experienced crackers an advantage, we first had KoreLogic attack a set of 4,239 Complex passwords (distinct from those reported in our other tests) in artificially limited configurations.

We then had the professionals attack the Complex, LongBasic, and LongComplex passwords with no artificial limitations. An experienced password analyst wrote freestyle rules for each set before cracking began, and again after 10^13 guesses based on the passwords guessed to that point. They made more than 10^14 guesses per set.

LongBasic and LongComplex approaches are rare in corporate environments and thus relatively unfamiliar to real-world attackers. To mitigate this unfamiliarity, we randomly split each set in two and designated half for training and half for testing. We provided analysts with the training half (in plaintext) to familiarize them with common patterns in these sets. Because we found that automated approaches can already crack most Basic passwords, rendering them insecure, we chose not to have the professionals attack Basic passwords.

### 3.4 Computational Limitations

As expected, the computational cost of generating guesses in each approach proved a crucial limiting factor in our tests. In three days, oclHashcat, the fastest of our approaches, produced 10^15 guesses using a single AMD R9 290X GPU (roughly a $500 value). In contrast, the Markov approach (our slowest) required three days on a roughly $10,000 server (64 AMD Opteron 6274 CPU cores and 256 GB of RAM) to generate 10^10 guesses without computing a single hash. In three days on the same machine as Markov, PCFG simulated 10^13 guesses.

The inefficiency of Markov stems partially from our use of a research implementation. Even the most efficient implementation, however, would still face substantial conceptual barriers. Whereas Hashcat and JTR incur the same performance cost generating the quadrillionth guess as the first guess, Markov must maintain a tree of substring probabilities. As more guesses are desired, the tree must grow, increasing the cost of both storing and traversing it. While Markov produced a high rate of successful guesses per guess made (see Section 4.2), the cost of generating guesses makes it a poor choice for computing guessability beyond billions of guesses.

Further, our automated approaches differ significantly in how well they handle complex password-composition policies. For PCFG, non-terminal structures can be pruned before guessing starts, so only compliant passwords are ever generated. As a result, it takes about equal time for PCFG to generate Basic passwords as LongComplex passwords. In contrast, Markov must first generate all passwords in a probability range and then filter out non-compliant passwords, adding additional overhead per guess. JTR has a similar generate-then-filter mechanism, while Hashcat (as discussed above) does not allow this post-hoc filtering at all for fast hashes. This means that Markov and JTR take much longer to generate valid LongComplex guesses than Basic guesses, and Hashcat wastes guesses against the LongComplex set.

As a result of these factors, the largest guess is necessarily unequal among approaches we test, and even among test sets within each approach. To account for this, we only compare approaches directly at equivalent guess numbers. In addition, we argue that these computational limitations are important in practice, so our findings can help researchers understand these approaches and choose among them appropriately.

### 4. Results

In Section 4.1, we show that for each automated guessing approach we evaluated, different seemingly reasonable configurations produce very different cracking results, and that out-of-the-box configurations commonly used by researchers substantially underestimate password vulnerability.

In Section 4.2, we examine the relative performance of the four automated approaches. We find they are similarly effective against Basic passwords. They have far less success against the other password sets, and their relative effectiveness also diverges.

For the three non-Basic sets, we also compare the automated approaches to the professional attack. Pros outperform the automated approaches, but only after a large number of guesses. As Pros crack more passwords, their manual adjustments prove quite effective; automated approaches lack this feedback mechanism. We also find that, at least through 10^14 guesses, automated approaches can conservatively approximate human password-cracking experts, but only if a password is counted as guessed when any of the four automated approaches guesses it. A single approach is not enough.

In Section 4.3, we explore the degree to which different cracking approaches overlap in which particular passwords they guess. While multiple approaches successfully guess most Basic passwords, many passwords in the other classes are guessed only by a single approach. We also find that different cracking approaches provide systematically different results based on characteristics like the number of character classes in a password.

In Section 4.4, we revisit how the choice of guessing approach impacts research questions at a high level (e.g., how composition policies impact security) and lower level (e.g., if a particular password is hard to guess). While we find analyses on large, heterogeneous sets of passwords to be fairly robust, security estimates for a given password are very sensitive to the approach used.

### 4.1 The Importance of Configuration

We found that using any guessing approach naively performed far more poorly, sometimes by more than an order of magnitude, than more expert configurations.

#### Stock vs. Advanced Configurations

We experimented with several configurations each for Hashcat and JTR, including the default configurations they ship with, and observed stark differences in performance. We detail a few here; others are described in Appendices A.2 and A.3.

For example, Hashcat configured with the (default) Best64 mangling rules guessed only about 2% of the Complex passwords before running out of guesses. Using the mangling rules described in Section 3, it made far more guesses, eventually cracking 30% (Figure 1).

Similarly, JTR guessed less than 3% of Complex passwords before exhausting its stock rules. The larger set of rules described in Section 3 enabled it to guess 29% (see Appendix A.2 for details). We found similar configuration effects for LongComplex passwords, and analogous but milder effects for the Basic and LongBasic sets.

We also compared the PCFG implementation we use throughout the paper [32] with our approximation of the originally published algorithm [70], which differs in how probabilities are assigned (see Section 3). As we detail in Appendix A.1, the newer PCFG consistently outperforms the original algorithm; the details of the same conceptual approach greatly impact guessability analyses.

#### Choices of Training Data

The performance of PCFG and Markov depends heavily on the quality of training data. Our group previously found that training with closely related passwords improves performance [31].

For our non-basic password sets, however, closely matched data is not available in publicly leaked sets. In tests reported in Appendix A.1, we incorporated closely matched data via cross-validation, in which we iteratively split the test set into training and testing portions. Using cross-validation improved guessing efficiency for three of the four password sets, most dramatically for LongBasic. This result demonstrates that an algorithm trained with generic training data will miss passwords that are vulnerable to an attacker who has training data that closely matches a target set. To minimize differences across approaches, however, PCFG results in the body of the paper use generic training data only.

#### Actionable Takeaways

Together, these results suggest that a researcher must carefully manage guessing configuration before calculating password guessability. In particular, tools like JTR and Hashcat will "out of the box" systematically underestimate password guessability. Unfortunately, many existing research studies rely on unoptimized configurations [11, 14, 15, 20, 21, 28, 34, 71]. While we report on the configurations we found most effective in extensive testing, we argue that the research community should establish configuration best practices, which may depend on the password sets targeted.

### 4.2 Comparison of Guessing Approaches

We first show that automated approaches differ in effectiveness based on the nature of the password sets being cracked and the number of guesses at which they are compared. We then compare these automated approaches to cracking by an expert attacker making dynamic updates, finding that the expert lags in initial guessing efficiency yet becomes stronger over time. We find the minimum guess number across automated approaches can serve as a conservative proxy for guessability by an expert attacker.

#### 4.2.1 Guessing by Automated Approaches

On some password sets and for specific numbers of guesses, the performance of all four approaches was similar (e.g., at 10^12 guesses, all but Markov had guessed 60-70% of Basic passwords). In contrast, on other sets, their performance was inconsistent at many points that would be relevant for real-world cracking (e.g., PCFG cracked 20% of Complex passwords by 10^10 guesses, while Hashcat and JTR had cracked under 3%).

As shown in Figure 2, all four automated approaches were quite successful at guessing Basic passwords, the most widely used of the four classes. Whereas past work has found that, for password sets resembling our Basic passwords, PCFG often guesses more passwords than JTR [16] or that Markov performs significantly better than PCFG [40], good configurations of JTR, Markov, and PCFG performed somewhat similarly in our tests. Hashcat was less efficient at generating successful guesses in the millions and billions of guesses, yet it surpassed JTR by 10^12 guesses and continued to generate successful guesses beyond 10^13 guesses.

The four automated approaches had far less success guessing the other password sets. Figure 3 shows the guessability of the Complex passwords under each approach. Within the first ten million guesses, very few passwords were cracked by any approach. From that point, the performance of the different approaches diverged significantly.