2
8
examine 990 LongComplex passwords, also collected
for research [56], that needed to contain 12+ characters,
including characters from 3 or more character classes.
3.2 Training Data
To compare cracking approaches as directly as possible,
we used the same training data for each. That said, each
algorithm uses training data differently, making perfectly
equivalent comparisons impossible.
Our training data comprised leaked passwords and dic-
tionaries. The passwords were from breaches of MyS-
pace, RockYou, and Yahoo! (excluding the aforemen-
tioned 30,000 passwords analyzed in Appendix A.4).
Using leaked passwords raises ethical concerns. We be-
lieve our use of such sets in this research is justiﬁable
because the password sets are already available publicly
and we exclude personally identiﬁable information, such
as usernames. Furthermore, malicious agents use these
sets in attacks [23]; failure to consider them in our analy-
ses may give attackers an advantage over those who work
in defensive security.
Prior research has found including natural-language
dictionaries to work better than using just passwords [31,
69]. We used the dictionaries previously found most ef-
fective: all single words in the Google Web corpus [26],
the UNIX dictionary [1], and a 250,000-word inﬂec-
tion dictionary [55]. The combined set of passwords
and dictionaries contained 19.4 million unique entries.
For cracking approaches that take only a wordlist, with-
out frequency information, we ordered the wordlist by
descending frequency and removed duplicates. We in-
cluded frequency information for the other approaches.
3.3 Simulating Password Cracking
To investigate the degree to which research results can
be biased by the choice of cracking algorithm, as well
as how automated approaches compare to real attacks,
we investigated two cracking tools and two probabilistic
algorithms. We selected approaches based on their popu-
larity in the academic literature or the password-cracking
community, as well as their conceptual distinctness. We
also contracted a computer security ﬁrm specializing in
password cracking for the real-world attack.
Most cracking approaches do not natively provide
guess numbers, and instrumenting them to calculate
guessability was typically far from trivial. Because this
instrumentation enabled the comparisons in this paper
and can similarly support future research, we include
many details in this section about this instrumentation.
Furthermore,
in Section 5, we introduce a Password
Guessability Service so that other researchers can lever-
age our instrumentation and computational resources.
For each approach, we analyze as many guesses
as computationally feasible, making 100 trillion (1014)
guesses for some approaches and ten billion (1010)
guesses for the most resource-intensive approach. With
the exception of Hashcat, as explained below, we ﬁlter
out guesses that do not comply with a password set’s
composition policy. For example, a LongComplex pass-
word’s guess number excludes guesses with under 12
characters or fewer than 3 character classes.
We deﬁne Minauto as the minimum guess number
(and therefore the most conservative security result)
for a given password across our automated cracking
approaches. This number approximates the best re-
searchers can expect with well-conﬁgured automation.
In the following subsections, we detail the conﬁgura-
tion (and terminology) of the ﬁve approaches we tested.
We ran CPU-based approaches (JTR, PCFG, Markov) on
a 64-core server. Each processor on this server was an
AMD Opteron 6274 running at 1.4Ghz. The machine
had 256 GB of RAM and 15 TB of disk. Its market value
is over $10,000, yet we still faced steep resource limita-
tions generating Markov guesses. We ran Hashcat (more
precisely, oclHashcat) on a machine with six AMD R9
270 GPUs, 2 GB of RAM, and a dual-core processor.
Probabilistic context-free grammar Weir et al.’s
probabilistic context-free grammar (termed PCFG) [70]
has been widely discussed in recent years. We use
Komanduri’s implementation of PCFG [32], which im-
proves upon the guessing efﬁciency of Weir et al.’s
work [70] by assigning letter strings probabilities based
on their frequency in the training data and assigning un-
seen strings a non-zero probability. This implementa-
tion is a newer version of Kelley et al.’s implementation
of PCFG as a lookup table for quickly computing guess
numbers, rather than enumerating guesses [31].
Based on our initial testing, discussed further in Sec-
tion 4.1, we prepend our training data, ordered by fre-
quency, before PCFG’s ﬁrst guess to improve perfor-
mance. As a result, we do not use Komanduri’s hy-
brid structures [32], which serve a similar purpose. We
weight passwords 10× as heavily as dictionary entries.
USENIX Association  
24th USENIX Security Symposium  467
5
We were able to simulate 1012 guesses for Complex pass-
words and 1014 guesses for the other three sets.
throughput speed of 3 million guesses per second and
made more than 1013 guesses for Basic passwords.
Markov model Second, we evaluated the Markov-
model password guesser presented by Ma et al. [40],
which implemented a number of variants differing by or-
der and approaches to smoothing. We use the order-5
Markov-chain model, which they found most effective
for English-language test sets. We tried using both our
combined training data (dictionaries and paswords) us-
ing the same weighting as with PCFG, as well as only the
passwords from our training data. The combined training
data and passwords-only training data performed nearly
identically. We report only on the combined training
data, which was slightly more effective for Basic pass-
words and is most consistent with the other approaches.
We used Ma et al.’s code [40], which they shared with
us, to enumerate a list of guesses in descending proba-
bility. We used a separate program to remove guesses
that did not conform to the given password-composition
policy. Because this approach is extremely resource-
intensive, both conceptually (traversing a very large tree)
and in its current implementation, we were not able to
analyze as many guesses as for other approaches. As
with PCFG, we found prepending the training data im-
proved performance, albeit only marginally for Markov.
Therefore, we used this tweak. We simulated over 1010
guesses for Basic passwords, similar to Ma et al. [40].
John the Ripper We also tested variants of a man-
gled wordlist attack implemented in two popular soft-
ware tools. The ﬁrst tool, John the Ripper (termed JTR),
has been used in a number of prior studies as a security
metric, as described in Section 2. In most cases, these
prior studies used JTR with its stock mangling rules.
However, pairing the stock rules with our 19.4-million-
word wordlist produced only 108 guesses for Basic pass-
words. To generate more guesses, we augment the stock
rules with 5,146 rules released for DEF CON’s “Crack
Me If You Can” (CMIYC) password-cracking contest in
2010 [35]. Speciﬁcally, we use Trustwave SpiderLabs’
reordering of these rules for guessing efﬁciency [64].
Our JTR tests therefore use the stock mangling rules fol-
lowed by the Spiderlabs rules. For completeness, Ap-
pendix A.2 presents these rules separately.
Instrumenting JTR to calculate precise guess numbers
was an involved process. We used john-1.7.9-jumbo
with the --stdout ﬂag to output guesses to standard out.
We piped these guesses into a program we wrote to per-
form a regular expression check ﬁltering out guesses that
do not conform to the given password policy. This pro-
gram then does a fast hash table lookup with GNU gperf
[27] to quickly evaluate whether a guess matches a pass-
word in our dataset. Using this method, we achieved a
Hashcat While Hashcat is conceptually similar to JTR,
we chose to also include it in our tests for two reasons.
First, we discovered in our testing that JTR and Hashcat
iterate through guesses in a very different order, leading
to signiﬁcant differences in the efﬁcacy of guessing spe-
ciﬁc passwords. JTR iterates through the entire wordlist
using one mangling rule before proceeding to the subse-
quent mangling rule. Hashcat, in contrast, iterates over
all mangling rules for the ﬁrst wordlist entry before con-
tinuing to the subsequent wordlist entry.
Second, the GPU-based oclHashcat, which is often
used in practice [23, 24, 36, 51], does not permit users
to ﬁlter guesses that do not meet password-composition
requirements except for computationally expensive hash
functions. We accept this limitation both because it rep-
resents the actual behavior of a popular closed-source
tool and because, for fast hashes like MD5 or NTLM,
guessing without ﬁltering cracks passwords faster in
practice than applying ﬁltering.
Unlike JTR, Hashcat does not have a default set of
mangling rules, so we evaluated several. We generally
report on only the most effective set, but detail our tests
of four different rule sets in Appendix A.3. This most
effective rule set, which we term Hashcat throughout
the paper, resulted from our collaboration with a Hash-
cat user and password researcher from MWR InfoSecu-
rity [25, 44], who shared his mangling rules for the pur-
pose of this analysis. We believe such a conﬁguration
represents a typical expert conﬁguration of Hashcat.
We used oclHashcat-1.21. While, like JTR, Hash-
cat provides a debugging feature that streams guesses to
standard output, we found it extremely slow in practice
relative to Hashcat’s very efﬁcient GPU implementation.
In support of this study, Hashcat’s developers generously
added a feature to oclHashcat to count how many guesses
it took to arrive at each password it cracked. This fea-
ture is activated using the ﬂag --outfile-format=11
in oclHashcat-1.20 and above. We therefore hashed
the passwords in our datasets using the NTLM hash func-
tion, which was the fastest for Hashcat to guess in our
benchmarks. We then used Hashcat to actually crack
these passwords while counting guesses, with throughput
of roughly 10 billion guesses per second on our system.
We made more than 1013 guesses for Basic passwords,
along with nearly 1015 guesses for some alternate con-
ﬁgurations reported in Appendix A.3.
Professional cracker An open question in measur-
ing password guessability using off-the-shelf, automated
tools is how these attacks compare to an experienced,
real-world attacker. Such attackers manually customize
6
468  24th USENIX Security Symposium 
USENIX Association
and dynamically update their attacks based on a target
set’s characteristics and initial successful cracks.
To this end, we contracted an industry leader in profes-
sional password recovery services, KoreLogic (termed
Pros), to attack the password sets we study. We believe
KoreLogic is representative of expert password crackers
because they have organized the DEF CON “Crack Me If
You Can” password-cracking contest since 2010 [36] and
perform password-recovery services for many Fortune-
500 companies [38]. For this study, they instrumented
their distributed cracking infrastructure to count guesses.
Like most experienced crackers, the KoreLogic ana-
lysts used tools including JTR and Hashcat with propri-
etary wordlists, mangling rules, mask lists, and Markov
models optimized over 10 years of password audit-
ing. Similarly, they dynamically update their mangling
rules (termed freestyle rules) as additional passwords are
cracked. To unpack which aspects of a professional
attack (e.g., proprietary wordlists and mangling rules,
freestyle rules, etc.) give experienced crackers an advan-
tage, we ﬁrst had KoreLogic attack a set of 4,239 Com-
plex passwords (distinct from those reported in our other
tests) in artiﬁcially limited conﬁgurations.
We then had the professionals attack the Complex,
LongBasic, and LongComplex passwords with no artiﬁ-
cial limitations. An experienced password analyst wrote
freestyle rules for each set before cracking began, and
again after 1013 guesses based on the passwords guessed
to that point. They made more than 1014 guesses per set.
LongBasic and LongComplex approaches are rare in
corporate environments and thus relatively unfamiliar
to real-world attackers. To mitigate this unfamiliarity,
we randomly split each set in two and designated half
for training and half for testing. We provided analysts
with the training half (in plaintext) to familiarize them
with common patterns in these sets. Because we found
that automated approaches can already crack most Ba-
sic passwords, rendering them insecure, we chose not to
have the professionals attack Basic passwords.
3.4 Computational Limitations
As expected,
the computational cost of generating
guesses in each approach proved a crucial limiting factor
in our tests. In three days, oclHashcat, the fastest of our
approaches, produced 1015 guesses using a single AMD
R9 290X GPU (roughly a $500 value). In contrast, the
Markov approach (our slowest) required three days on
a roughly $10,000 server (64 AMD Opteron 6274 CPU
cores and 256 GB of RAM) to generate 1010 guesses
without computing a single hash. In three days on the
same machine as Markov, PCFG simulated 1013 guesses.
The inefﬁciency of Markov stems partially from our
use of a research implementation. Even the most efﬁ-
cient implementation, however, would still face substan-
tial conceptual barriers. Whereas Hashcat and JTR incur
the same performance cost generating the quadrillionth
guess as the ﬁrst guess, Markov must maintain a tree of
substring probabilities. As more guesses are desired, the
tree must grow, increasing the cost of both storing and
traversing it. While Markov produced a high rate of suc-
cessful guesses per guess made (see Section 4.2), the cost
of generating guesses makes it a poor choice for comput-
ing guessability beyond billions of guesses.
Further, our automated approaches differ signiﬁcantly
in how well they handle complex password-composition
policies.
For PCFG, non-terminal structures can be
pruned before guessing starts, so only compliant pass-
words are ever generated. As a result, it takes about equal
time for PCFG to generate Basic passwords as Long-
Complex passwords. In contrast, Markov must ﬁrst gen-
erate all passwords in a probability range and then ﬁl-
ter out non-compliant passwords, adding additional over-
head per guess. JTR has a similar generate-then-ﬁlter
mechanism, while Hashcat (as discussed above) does not
allow this post-hoc ﬁltering at all for fast hashes. This
means that Markov and JTR take much longer to gener-
ate valid LongComplex guesses than Basic guesses, and
Hashcat wastes guesses against the LongComplex set.
As a result of these factors, the largest guess is nec-
essarily unequal among approaches we test, and even
among test sets within each approach. To account for
this, we only compare approaches directly at equivalent
guess numbers. In addition, we argue that these compu-
tational limitations are important in practice, so our ﬁnd-
ings can help researchers understand these approaches
and choose among them appropriately.
4 Results
We ﬁrst show, in Section 4.1, that for each automated
guessing approach we evaluated, different seemingly
reasonable conﬁgurations produce very different crack-
ing results, and that out-of-the-box conﬁgurations com-
monly used by researchers substantially underestimate
password vulnerability.
Next, in Section 4.2, we examine the relative perfor-
mance of the four automated approaches. We ﬁnd they
are similarly effective against Basic passwords. They
have far less success against the other password sets, and
their relative effectiveness also diverges.
For the three non-Basic sets, we also compare the
automated approaches to the professional attack. Pros
outperform the automated approaches, but only after a
large number of guesses. As Pros crack more pass-
words, their manual adjustments prove quite effective;
automated approaches lack this feedback mechanism.
We also ﬁnd that, at least through 1014 guesses, auto-
USENIX Association  
24th USENIX Security Symposium  469
7
mated approaches can conservatively approximate hu-
man password-cracking experts, but only if a password
is counted as guessed when any of the four automated
approaches guesses it. A single approach is not enough.
In Section 4.3, we explore the degree to which differ-
ent cracking approaches overlap in which particular pass-
words they guess. While multiple approaches success-
fully guess most Basic passwords, many passwords in
the other classes are guessed only by a single approach.
We also ﬁnd that different cracking approaches provide
systematically different results based on characteristics
like the number of character classes in a password.
In Section 4.4, we revisit how the choice of guessing
approach impacts research questions at a high level (e.g.,
how composition policies impact security) and lower
level (e.g., if a particular password is hard to guess).
While we ﬁnd analyses on large, heterogeneous sets of
passwords to be fairly robust, security estimates for a
given password are very sensitive to the approach used.
4.1 The Importance of Conﬁguration
We found that using any guessing approach naively per-
formed far more poorly, sometimes by more than an or-
der of magnitude, than more expert conﬁgurations.
Stock vs advanced conﬁgurations We experimented
with several conﬁgurations each for Hashcat and JTR, in-
cluding the default conﬁgurations they ship with, and ob-
served stark differences in performance. We detail a few
here; others are described in Appendices A.2 and A.3.
For example, Hashcat conﬁgured with the (default)
Best64 mangling rules guessed only about 2% of the
Complex passwords before running out of guesses. Us-
ing the mangling rules described in Section 3, it made far
more guesses, eventually cracking 30% (Figure 1).
Similarly, JTR guessed less than 3% of Complex pass-
words before exhausting its stock rules. The larger set of
rules described in Section 3 enabled it to guess 29% (see
Appendix A.2 for details). We found similar conﬁgura-
tion effects for LongComplex passwords, and analogous
but milder effects for the Basic and LongBasic sets.
We also compared the PCFG implementation we use
throughout the paper [32] with our approximation of the
originally published algorithm [70], which differs in how
probabilities are assigned (see Section 3). As we detail
in Appendix A.1, the newer PCFG consistently outper-
forms the original algorithm; the details of the same con-
ceptual approach greatly impact guessability analyses.
Choices of training data The performance of PCFG
and Markov depends heavily on the quality of training
data. Our group previously found that training with
closely related passwords improves performance [31].
8
30%
20%
10%
d
e
s
s
e
u
g
t
n
e
c
r
e
P
0%
HC−MWR
HC−Generated2
HC−SpiderLabs
HC−Best64
101
103
105
107
Guesses
109
1011
1013
Figure 1: Results of Hashcat conﬁgured using the same
wordlist, but different sets of mangling rules (described
in Appendix A.3), to guess Complex passwords.
For our non-basic password sets, however, closely
matched data is not available in publicly leaked sets.
In tests reported in Appendix A.1, we thus incorpo-
rated closely matched data via cross-validation, in which
we iteratively split the test set into training and testing
portions. Using cross-validation improved guessing efﬁ-
ciency for three of the four password sets, most dramati-
cally for LongBasic. This result demonstrates that an al-
gorithm trained with generic training data will miss pass-
words that are vulnerable to an attacker who has training
data that closely matches a target set. To minimize differ-
ences across approaches, however, PCFG results in the
body of the paper use generic training data only.
Actionable takeaways Together, these results suggest
that a researcher must carefully manage guessing conﬁg-
uration before calculating password guessability. In par-
ticular, tools like JTR and Hashcat will “out of the box”
systematically underestimate password guessability. Un-
fortunately, many existing research studies rely on unop-
timized conﬁgurations [11, 14, 15, 20, 21, 28, 34, 71].
While we report on the conﬁgurations we found most
effective in extensive testing, we argue that the research
community should establish conﬁguration best practices,
which may depend on the password sets targeted.
4.2 Comparison of Guessing Approaches
We ﬁrst show that automated approaches differ in effec-
tiveness based on the nature of the password sets be-
ing cracked and the number of guesses at which they
are compared. We then compare these automated ap-
proaches to cracking by an expert attacker making dy-
namic updates, ﬁnding that the expert lags in initial
guessing efﬁciency, yet becomes stronger over time. We
ﬁnd the minimum guess number across automated ap-
proaches can serve as a conservative proxy for guessabil-
ity by an expert attacker.
470  24th USENIX Security Symposium 
USENIX Association
4.2.1 Guessing by Automated Approaches
80%
On some password sets and for speciﬁc numbers of
guesses, the performance of all four approaches was sim-
ilar (e.g., at 1012 guesses all but Markov had guessed
60-70% of Basic passwords). In contrast, on other sets,
their performance was inconsistent at many points that
would be relevant for real-world cracking (e.g., PCFG
cracked 20% of Complex passwords by 1010 guesses,
while Hashcat and JTR had cracked under 3%).
As shown in Figure 2, all four automated approaches
were quite successful at guessing Basic passwords, the
most widely used of the four classes. Whereas past
work has found that, for password sets resembling our
Basic passwords, PCFG often guesses more passwords
than JTR [16] or that Markov performs signiﬁcantly
better than PCFG [40], good conﬁgurations of JTR,
Markov, and PCFG performed somewhat similarly in our
tests. Hashcat was less efﬁcient at generating successful
guesses in the millions and billions of guesses, yet it sur-
passed JTR by 1012 guesses and continued to generate
successful guesses beyond 1013 guesses.
The four automated approaches had far less success
guessing the other password sets. Figure 3 shows the
guessability of the Complex passwords under each ap-
proach. Within the ﬁrst ten million guesses, very few
passwords were cracked by any approach. From that