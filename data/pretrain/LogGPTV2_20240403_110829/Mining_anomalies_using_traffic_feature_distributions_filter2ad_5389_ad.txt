### 6.2 Manual Inspection

To gain a clearer understanding of the nature of the anomalies detected using entropy, we manually inspected each of the 444 anomalies identified in the Abilene dataset. Our inspection process involved several strategies:

1. **Heavy-Hitter Analysis**: We extracted the top few heavy-hitters in each feature.
2. **Port and Address Usage Patterns**: We examined the patterns of port and address usage across the set of anomalous flows, checking for sequentially increasing, sequentially decreasing, or apparently random values.
3. **Packet Size Inspection**: We analyzed the sizes of packets involved in the anomaly.
4. **Specific Feature Values**: We looked for specific values of the features, especially ports, involved in the anomaly.

Our goal was to classify each anomaly into one of the categories listed in Table 1. Here are some key observations from our manual classification:

- **Alpha Flows**: These were high-rate flows from a single source to a single destination. Most of these corresponded to routine bandwidth measurement experiments run by SLAC. However, some high-bandwidth flows were malicious, such as bandwidth DOS attacks. We used port information to distinguish between these two types.
- **DOS Attacks**: DOS attacks often use recognizable ports and can be spoofed. Anomalies with no dominant source but a dominant destination were labeled as DOS.
- **Flash Crowd Events**: These were classified as traffic originating from multiple sources, not appearing to be spoofed, and directed to a single destination at a well-known port.
- **Outage-Related Events**: Some anomalies showed sharp dips in traffic volume, corresponding to outages, which we cross-verified with Abilene operations reports.

Our manual classification was largely successful, but there were some anomalies that could not be classified. For example, some anomalies showed no substantial deviation in any entropy or volume time series. If they also did not show unusual characteristics at the flow level, we labeled them as false alarms. Additionally, there were anomalies that showed some sort of unusual behavior but were difficult to classify. Some of these unknowns appear to be multiple anomalies co-occurring in the same time bin, while others correspond to anomaly structures we were not aware of during manual inspection.

The results of our manual inspection are summarized in Table 3, which shows that certain types of anomalies are more likely to be detected in entropy than in volume. For instance, port scans, network scans, and point-to-multipoint transfers were only detected using entropy. These low-volume anomalies are important to operators, even though they involve little traffic volume. For example, some of the 28 low-volume network scans detected in entropy were destined for port 1433, indicating they were likely scanning probes from hosts infected with the MS-SQL Snake worm.

Table 3 also provides insight into the false alarm rate. In three weeks of data, only 43 anomalies were clearly false alarms. This is a minimum value, as some anomalies in the unknown category might be considered false alarms if their nature were fully understood. Thus, we conclude that the false alarm rate is generally low (on the order of 10% of detections) for distribution-based detection.

### 6.3 Detecting Known Anomalies

The previous section demonstrated that entropy-based anomaly detection has a low false alarm rate and is sensitive to detecting low-volume anomalies. However, we were unable to directly measure the method's detection rate because we only worked with anomalies present in our traces. To test the detection rate more directly, we conducted controlled experiments involving known anomalies at varying intensities.

#### 6.3.1 Methodology

We decided to use packet traces containing well-studied anomalies, extract the anomalies from these traces, and superimpose them onto our Abilene data in a realistic manner. The steps involved are as follows:

1. **Trace Selection**: We used traces of three anomalies of varying intensity:
   - A single-source bandwidth attack on a single target destination.
   - A multi-source distributed denial of service attack on a single target.
   - A worm scan.

2. **Anomaly Extraction**: We extracted the anomaly packets from the DOS attacks by identifying the victim and extracting all packets directed to that address. The worm scan trace was already annotated, making extraction straightforward.

3. **Transformation**: We mapped header fields in the extracted packets to appropriate values for the Abilene network by zeroing out the last 11 bits of the address fields and applying a random mapping from the addresses and ports seen in the attack trace to those seen in the Abilene data.

4. **Injection and Detection**: We injected the transformed anomaly traffic into a randomly selected time bin in the Abilene data that did not contain an anomaly. We then applied the multiway subspace method to determine whether the injected anomaly was detected, allowing us to compute a detection rate over OD flows.

5. **Varying Intensities**: To evaluate our methods on varying anomaly intensities, we thinned the original trace by selecting 1 out of every \( n \) packets, then extracted the anomaly and injected it into the Abilene OD flows. The resulting intensity of each anomaly for the various thinning rates is shown in Table 4.

#### 6.3.2 Results

The detection rates from injecting single OD flow anomalies are shown in Figure 5. Each figure shows results from the multiway subspace method for two different detection thresholds (\( \alpha = 0.995 \) and \( \alpha = 0.999 \)). We used these high detection thresholds to make our results as conservative as possible. Lower detection thresholds would generate higher detection rates. The figures also show results for detection based on volume metrics alone (bytes and packets) and volume metrics combined with entropy. The difference between the curves for entropy and volume highlights the effectiveness of combining both metrics.

Figure 5: Detection Results from Injecting Real Anomalies
- **Single DOS Attack**
- **Multi DOS Attack**
- **Worm Scan**

Table 4: Varying Anomaly Intensities
- **Thinning Factor**
- **Single DOS Intensity**
- **Multi DOS Intensity**
- **Worm Scan Intensity**

These results demonstrate the effectiveness of our entropy-based approach in detecting known anomalies, even at varying intensities.