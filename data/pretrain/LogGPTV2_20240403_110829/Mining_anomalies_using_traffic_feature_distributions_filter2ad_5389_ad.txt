in detecting anomalies.
6.2 Manual Inspection
To gain a clearer understanding of the nature of the anomalies
detected using entropy, we manually inspected each of the 444
anomalies detected in the Abilene dataset. Our manual inspection
involved looking at the trafﬁc in each anomalous timebin at the IP
ﬂow level, and employed a variety of strategies. First, we extracted
the top few heavy-hitters in each feature. Second, we examined
the patterns of port and address usage across the set of anomalous
ﬂows; in particular, we checked for either sequentially increasing,
sequentially decreasing, or apparently random values (which are
relatively easy to spot) in each feature. Third, we inspected the
sizes of packets involved in the anomaly. And last, we looked for
speciﬁc values of the features, especially ports, involved.
Our goal was to try to place each anomaly into one of the classes
in Table 1. In the process, we made use of some general obser-
vations. First, anomalies labeled Alpha were high-rate ﬂows from
a single source to a single destination [31]. In our data, most of
these correspond to routine bandwidth measurement experiments
run by SLAC [27, 33]. However, many high bandwidth ﬂows are
in fact malicious in intent, e.g., bandwidth DOS attacks.
In or-
der to separate these DOS attacks from typical alpha ﬂows, we
made use of port information; both bandwidth measurement ex-
periments and many DOS attacks use recognizable ports. In addi-
tion, DOS attacks can be spoofed, and so anomalies with no dom-
inant source but a dominant destination were also labeled as DOS.
To distinguish ﬂash crowd events from DOS attacks, we used a
simpliﬁed version of the heuristics in [12]: we labeled as a ﬂash
event trafﬁc originating from a set of sources that did not appear
to be spoofed, and directed to a single destination at a well known
destination port. Some anomalies had no dominant features, but
showed sharp dips in trafﬁc volume. These anomalies correspond
to outage-related events, and we cross-veriﬁed them with Abilene
operations reports [1].
Our manual classiﬁcation was largely successful, but there were
a number of anomalies that could not be classiﬁed. First, there
were some anomalies that showed no substantial deviation in any
entropy or volume timeseries. We checked each of these to see if
they showed unusual characteristics at the ﬂow level. If not, we
Anomaly Label
Alpha Flows
DOS
Flash Crowd
Port Scan
Network Scan
Outage Events
Point to Multipoint
Unknown
False Alarm
Total
# Found
in Volume
# Additional
in Entropy
84
16
6
0
0
4
0
19
23
152
137
11
3
30
28
11
7
45
20
292
Table 3: Range of anomalies in Abilene (classiﬁed manually).
labeled each such anomaly as a false alarm.
Second, there was a set of anomalies that we simply could not
classify with certainty. These all showed some sort of unusual
behavior at the IP ﬂow level, but the nature of that behavior was
hard to classify. Some of these unknowns appear to be multiple
anomalies co-occurring in the same timebin. A large set of these
unknowns simply correspond to anomaly structures that we were
not aware of when we manually inspected them. We will show in
Section 7 that many of these unknown anomalies in fact correspond
to a peculiar new class of anomalies, whose structure was exposed
by our automatic classiﬁcation methods.
The results of our manual inspection are listed in Table 3. The
table shows that certain types of anomalies are much more likely
to be detected in entropy than in volume. In fact, none of the port
scans, network scans or point-to-multipoint transfers were detected
via volume metrics; these types of anomalies were only detected
using entropy. These types of anomalies are predominantly low-
volume, and therefore difﬁcult to detect by volume-based methods,
conﬁrming the observations in Figure 4.
It is important to note
that even though these anomalies involve little trafﬁc volume, they
are important to an operator. For example, some of the 28 low-
volume network scans detected in entropy were destined to port
1433, which indicates that they were likely to be scanning probes
from a host or hosts infected with the MS-SQL Snake worm.
We note that although these low-volume anomalies are “buried”
within a large mass of normal trafﬁc, they have properties that make
them easy to detect using the multiway subspace method. These
low-volume anomalies induce strong simultaneous changes across
multiple trafﬁc features. Referring back to Figure 3, these simulta-
neous changes (signiﬁed by the common spike in each of the four
features for a single ﬂow) combine to make the detection problem
easier. For example, a port scan induces a dispersal in destination
ports and simultaneously concentrates the destination IP distribu-
tion. Even though the individual shifts in entropy may be small,
the subspace method combines them into a single large, detectable
change in the state vector.
Table 3 also sheds light on false alarm rate. The table shows
that in three weeks of data, only 43 anomalies were clearly false
alarms. This is a minimum value, because some anomalies in the
unknown category might be considered false alarms if their nature
were completely understood; but from our inspection, it does not
appear that this is true in most cases. Thus we conclude that the
false alarm rate is generally low (on the order of 10% of detections)
for distribution-based detection.
6.3 Detecting Known Anomalies
The last section showed that entropy-based anomaly detection
has low false alarm rate, and appears to be sensitive in its abil-
ity to detect low-volume anomalies. However, we were not able
to directly measure the method’s detection rate because we were
working only with anomalies actually present in our traces. To
test detection rate more directly, we need controlled experiments
involving known anomalies at varying intensities. To do this we
make use of a set of traces taken from documented attacks and in-
fections (which are described next).
6.3.1 Methodology
To test detection rate we considered generating synthetic anoma-
lies — packet traces speciﬁcally constructed to mimic certain
anomalies. However we rejected this approach because we did not
want to inadvertently inject bias into our results. Instead we de-
cided to make use of packet traces containing well-studied anoma-
lies, to extract the anomalies from these traces, and to superimpose
the anomalies onto our Abilene data in a manner that is as realistic
as possible. This involved a number of steps which we describe
below.
We used traces of three anomalies of varying intensity. The ﬁrst
is a single-source bandwidth attack on a single target destination
described in [11]. The second trace is a multi-source distributed
denial of service attack on a single target, also described in [11].
Both these traces were collected by the Los Nettos regional ISP in
2003. The third trace is a worm scan, described in [32]. This trace
was collected from an ISP in Utah, in April 2003. All three traces
consist of packet headers without any sampling.
In all three traces, the anomaly trafﬁc was mixed with back-
ground trafﬁc. We extracted the anomaly packets from the DOS
attacks by identifying the victim, and extracting all packets directed
to that address. The worm scan trace was already annotated, mak-
ing extraction straightforward. We then mapped header ﬁelds in the
extracted packets to appropriate values for the Abilene network.
We did this by zeroing out the last 11 bits of the address ﬁelds
to match the Abilene anonymization, and then applying a random
mapping from the addresses and ports seen in the attack trace to
addresses and ports seen in the Abilene data.
Having extracted and appropriately transformed the anomaly
trafﬁc, we then injected it into our trafﬁc data. We selected a ran-
dom timebin, which did not contain an anomaly. Then, we inject
the anomaly in turn into each OD ﬂow in the Abilene data. After
each injection, we applied the multiway subspace method to deter-
mine whether the injected anomaly was detected. This allowed us
to compute a detection rate over OD ﬂows.
In order to evaluate our methods on varying anomaly intensities,
we thinned the original trace by selecting 1 out of every  pack-
ets, then extracted the anomaly and injected it into the Abilene OD
ﬂows. For the particular timebin we selected, the average trafﬁc in-
tensity of an Abilene OD ﬂow was 2068 packets per second (recall
that our Abilene data is itself sampled with a factor of 100). The
resulting intensity of each anomaly for the various thinning rates is
shown in in Table 4. The table also shows the percent of all packets
in the resulting OD ﬂow that was due to the injected anomaly.
6.3.2 Results
The resulting detection rates from injecting single OD ﬂow
anomalies are shown in Figure 5. In each ﬁgure, we show results
from the multiway subspace method for two different detection
thresholds ((cid:11) = 0.995 and (cid:11) = 0.999). We use these relatively high
detection thresholds to make our results as conservative as possible;
lower detection thresholds would generate higher detection rates.
Each ﬁgure also shows results for detection based on volume met-
rics alone (bytes and packets) and volume metrics combined with
entropy. The difference between the curves for entropy and vol-
1
0.8
0.6
0.4
0.2
e
t
a
R
n
o
i
t
c
e
t
e
D
Volume Alone(99.9)
Entropy and Volume (99.9)
Volume Alone (99.5)
Entropy and Volume (99.5)
1
0.8
0.6
0.4
0.2
e
t
a
R
n
o
i
t
c
e
t
e
D
Volume Alone(99.9)
Entropy and Volume (99.9)
Volume Alone (99.5)
Entropy and Volume (99.5)
1
0.8
0.6
0.4
0.2
e
t
a
R
n
o
i
t
c
e
t
e
D
Volume Alone(99.9)
Entropy and Volume (99.9)
Volume Alone (99.5)
Entropy and Volume (99.5)
0
0
10
100
1000
Thinning Factor
(a) Single DOS
10000
100000
0
0
10
10000
100000
0
0
100
1000
Thinning Factor
(b) Multi DOS
10
100
Thinning Factor
(c) Worm scan
500
1000
Figure 5: Detection Results from Injecting Real Anomalies.
Thinning
Factor
Single DOS
Intensity
Multi DOS
Intensity
Worm Scan
Intensity
0
10
100
500
1000
10K
100K
pps
3.47e5
3.47e4
3.47e3
–
347
34.7
3.47
%
99%
94%
62%
–
pps
2.75e4
2.75e3
275
–
%
93%
57%
12%
–
27.5
14%
1.6%
2.59
0.16% 0.392
1.3%
0.13%
0.013%
pps
141
14.1
1.44
0.251
0.0979
–
–
%