to frustrate some of the most obvious ways to defeat the key
escrow ﬁeld, called the LEAF (“Law Enforcement Access
Field”).
The details of the LEAF were classiﬁed. We knew it was a
128 bit structure containing enough information for law en-
forcement recovery of the session key with the cooperation
of the agencies holding the escrowed unit key database. We
were told that the LEAF package contained a 32 bit unique
unit identiﬁer (the serial number of the chip that gener-
ated the LEAF), the current 80 bit session key (encrypted
with the device’s unit key) and a 16 bit LEAF checksum.
The entire structure was encrypted with a “family key” to
produce the ﬁnal LEAF package. All cryptographic oper-
ations in LEAF creation were based on symmetric (secret)
key techniques using the Skipjack cipher and other (unspec-
iﬁed) algorithms. The family key was global, shared by all
interoperable key escrow devices (but not published). The
Skipjack algorithm, the family key, the encryption modes
used to encrypt the unit key and the LEAF message, and
the details of the checksum algorithm were not made public
(and all were protected against reverse engineering by Clip-
per’s tamper-resistant hardware)2. Externally, the LEAF
was presented as an opaque 128 bit package.
To decrypt escrowed traﬃc, a law enforcement agency ﬁrst
must intercept the LEAF and the traﬃc itself using some
sort of data wiretapping technology. The LEAF could then
be decrypted with the family key, revealing the chip serial
number, the unit key-encrypted session key and the LEAF
checksum. The target’s serial number would then be pro-
vided by the agents to two “key escrow agencies,” which
would each return a “share” of the escrowed unit key associ-
ated with the given serial number. The two unit key shares
would then be combined (by bitwise exclusive-or) to produce
the full unit key, which the law enforcement agency could
then use to decrypt the session key. This session key could
in turn decrypt the actual intercepted traﬃc.
1Tessera was an unfortunate name.
It turned out to be
a registered trademark of a company that made PCMCIA
cards and that wanted nothing to do with key escrow. The
NSA eventually had to change the code name to Fortezza.
2In 1998, after Clipper was abandoned, the NSA declassiﬁed
and published the Skipjack algorithm. I believe it was, and
remains, the only NSA-designed symmetric-key encryption
algorithm ever publicly released.
The key escrow system thus relied on the availability of
the LEAF along with the encrypted traﬃc. To force appli-
cations to send the LEAF on the same channel as the traﬃc,
key escrow devices would not decrypt data until they had
received a valid LEAF for the current session key. Presum-
ably, the chips on each end would perform various integrity
checks on received LEAFs prior to accepting them.
To provide a convenient application interface for LEAF
management, the devices generated and loaded LEAFs as
part of the process of generating and loading the initial-
ization vectors (IVs) for each cryptographic session. The
Clipper and Capstone chips provided generateIV and loadIV
functions that operated on 192 bit parameters instead of the
usual 64 bits. This “IV” parameter was actually a two part
structure containing the standard 64 bit IV concatenated
with the 128 bit encrypted LEAF. The loadIV operation
would fail if the LEAF did not pass an integrity check.
Most details of the LEAF creation method, encryption
modes, and data structures, beyond those mentioned above,
were classiﬁed and were therefore unknown to me. In partic-
ular, the key escrow standard did not specify the mechanism
that enforced the transmission of the correct LEAF as part
of the ciphertext stream. However, I was able to perform a
number of simple experiments on my Tessera card to con-
ﬁrm and expand what we knew about the LEAF’s internal
structure and the way it was used. I found:
• LEAF integrity was veriﬁed via redundancy in its in-
ternal checksum ﬁeld. In general, attempts to load an
incorrect LEAF failed. This must have been due en-
tirely to the checksum ﬁeld and not through direct ver-
iﬁcation of the unit ID or encrypted session key ﬁelds;
the receiving chip could not conﬁrm the correctness of
those ﬁelds since it would have no way of knowing the
unit ID or unit key of its peer. Therefore, the LEAF
must have been testable based entirely on session in-
formation known to the receiver (such as the cleartext
session key and IV) and that must have been included
in the LEAF checksum computation.
• LEAF checksum computation included (implicitly or
explicitly) the current IV. The LEAF changed when-
ever a new IV was generated even when the session key
remained the same. Since the IV was not included di-
rectly as one of the LEAF ﬁelds, the only ﬁeld it could
aﬀect would be the LEAF checksum. Furthermore, re-
ceiving devices would refuse to load a LEAF with the
wrong IV.
• LEAF checksum computation must have included the
cleartext of the current session key. Attempting to
load an otherwise valid LEAF (and corresponding IV)
from a previous session key failed.
It was therefore
not possible to “re-use” a LEAF generated from an old
session key, even though such a LEAF would itself be
internally consistent.
• The LEAF integrity check included every bit of the
LEAF. Attempts to load an otherwise valid LEAF with
a single bit inverted anywhere in the 128 bit structure
always failed.
• The LEAF encryption method diﬀused its input across
the entire 128 bit structure. The LEAF structure or
encryption mode was apparently not exactly as speci-
ﬁed in publicly released documents. Generating a new
IV for a given session key caused changes across the
entire LEAF. Since the Skipjack cipherblock size was
64 bits, encryption of the LEAF would have to in-
volve at least two block encryption operations. Since
the IV aﬀected only the checksum, and the checksum
appeared at the end of the LEAF structure in public
documents, we could conclude that at least one of the
following was true:
– The LEAF was encrypted with a non-standard
mode in which cleartext in “late” blocks aﬀects
the early ciphertext.
– The LEAF was encrypted with a standard forward-
chaining or stream mode but the checksum ap-
pears in the ﬁrst cipherblock of the LEAF.
– The LEAF was encrypted with a standard forward-
chaining or stream mode but the current session
IV was itself used to initialize it.
• The LEAF checksum was, in fact, 16 bits long. A
brute-force search of the LEAF space for a valid LEAF
required about 216 operations.
That last point turned out to be interesting. It meant that
it was possible to use 216 Clipper or Capstone chip opera-
tions as an “oracle” to generate apparently valid, acceptable
LEAFs for the current IV and session key that would actu-
ally be useless for escrowed decryption.
So the safeguards that required transmission of a valid
LEAF weren’t very strong after all. With only access to the
chip’s standard interface, one could easily create a “rogue”
device that could happily interoperate with legitimate es-
crowed peers, enjoy the use of the strong Skipjack cipher,
but be impervious to the key escrow back door. The only
thing stopping you was a 16 bit exhaustive search, a very
low barrier even in 1993.
In April, 1994, I wrote a paper about all this, “Protocol
Failure in the Escrowed Encryption System”. I circulated it
to a few colleagues, and, not wanting to blindside anyone,
also sent a copy to my contacts at NSA. They were, I must
say, extremely good natured about it.
Eventually I submitted the paper to the upcoming 1994
ACM Computer and Communications Security Conference,
which would be held in November. But some time in May,
someone (I never found out who) sent a copy to John Markoﬀ,
the technology reporter at the New York Times who had
broken the key escrow story the previous year. He called
me to tell me he was writing a story about my paper for his
paper, and wondered if I had any comment.
2.3 No Such Thing As Bad PR?
After the Times called, it occurred to me that I was in
what could be considered an uncomfortable position, an em-
ployee of the research division of the same company in whose
product I was ﬁnding ﬂaws. And it was all based on a con-
troversial wiretapping system created by a secretive govern-
ment intelligence agency. And now the New York Times
was about to write about it. And there I was, right at the
center of the story. It seemed like a good time to involve
management.
I feared that the company might not be completely de-
lighted with my discoveries, or with my writing a paper
were relaxed a decade ago, we might expect law enforcement
wiretap rooms to have become quiet, lonely places.
But maybe not. The latest wiretap report identiﬁes a total
of just six (out of 3194) cases last year in which encryption
was encountered, and this prevented recovery of evidence a
grand total of zero times.
What’s going on here? Shouldn’t all this encryption be
aﬀecting government eavesdroppers at least a little bit more
than the wiretap report suggests? Do the police know some-
thing about cryptanalysis that the rest of us don’t, enabling
them to eﬀortlessly decrypt criminal messages in real time
without batting an eye? Is AES (the federally-approved al-
gorithm that won an open international competition for a
new standard block cipher in 2001) part of an elaborate
conspiracy to lull us into a sense of complacency while en-
abling the government to secretly spy on us? Perhaps, but
the likely truth is far less exciting, and ultimately, probably
more comforting.
The answer is that faced with encryption, capable investi-
gators in federal and local law enforcement have done what
they have always done when new technology comes around:
they’ve adapted their methods in order to get their work
done. Widespread encryption, rather than shutting down
police wiretaps, has actually pushed them in a more reliable
– and accountable – direction.
This is because while traﬃc encryption is highly eﬀective
at preventing wholesale, un-targeted interception, it does re-
markably little to prevent targeted government eavesdrop-
ping in the complex architectures of modern computing and
communication technologies. Yes, today’s encryption algo-
rithms are believed to be eﬀectively secure in practice, in
the sense that they make it infeasible for even an adversary
with the resources of a government to obtain cleartext from
ciphertext without access to the key. But government eaves-
droppers doesn’t have to limit themselves to that scenario
for their wiretap targets. They can instead exploit the real-
ity that the cleartext (or the keys to decrypt it) for almost all
encrypted traﬃc today is typically available, somewhere, on
a general-purpose computer that is exposed to government
access, either explicitly or through surreptitious means. And
as systems become more sophisticated and incorporate more
features, the exposure of cleartext and keys to third party
access tends to increase correspondingly. All without Clip-
per chips or any other kind of key escrow systems, mandated
or not.
If only we had understood that in 1993. We could have
saved ourselves a quite a bit of trouble, and maybe spent a
bit more time actually making things more secure.
on the subject. And indeed, executives in parts of AT&T
couldn’t understand why some kid in the troublemaking,
out-of-control research lab would even think that it was a
good idea to publish such things. But the Bell Labs man-
agement shined. They actively defended the importance of
publishing and fully supported me as a member of the pub-
lic research community, no matter the eﬀect it might have
on sales of the TSD or the company’s relationship with the
government. Our job as scientists, they argued, was to tell
the truth. I was never prouder to work there.
Eventually, Markoﬀ called me to let me know that his
story would be running in the Times the next day. But when
I got my copy of the paper, I couldn’t ﬁnd any mention of
it. It was only later that I noticed the story in the one place
I didn’t look: the top of the front page, under the headline
Flaw Found in Federal Plan for Wiretapping. Apparently
cryptography was bigger news than I thought. More likely,
it was a slow news day.
3. POSTSCRIPT
Clipper and key escrow eventually faded away. While my
paper may have helped accelerate its demise, key escrow
would not have been likely to succeed even if the Clipper
escrow mechanism had been more robust than it was.
Fundamental problems with the government’s vision for
key escrow made it inherently unworkable, regardless of the
implementation details. First, of course, was the problem of
securing a growing database of end-user keys, a very attrac-
tive target for unauthorized eavesdroppers who might seek
to intercept escrowed traﬃc themselves. Then there was the
economic problem: communications cryptography was, by
the 1990’s, becoming an essentially zero-marginal-cost tech-
nology, something that could often be implemented in soft-
ware more easily than by adding specialized hardware. But
Clipper required the use of hardware cryptography, taking
something that was becoming inherently cheap and turn-
ing it back into something expensive. The market would
ultimately never accept this, even if the trust issues and
technical problems could have been worked out.
Over the next few years there were attempts to revive
key escrow under various new proposed schemes (the name
eventually changed to “key recovery”). By the end of the
decade, however, the government gave up. The export rules
– the government’s main leverage in promoting key escrow
– were relaxed to allow mass-market products to use strong
cryptography without a special license, and eventually, cryp-
tography started to become integrated into more and more
products, software, and protocols. Key escrow was ﬁnally
dead.
It’s probably worth asking whether this was a good thing.
Law enforcement, after all, warned that unfettered access to
cryptography would make it easier for criminals, spies, and
terrorists to cover their tracks.
Fortunately, the worst fears of law enforcement haven’t
come to pass. Every year since the Nixon administration,
the federal government has issued a report on legal wire-
taps, giving the number of intercepts, the types of crimes
being investigated and other statistics. Since 2002, the re-
port has included another statistic: the number of cases in
which encryption encountered on a legal wiretap prevented
law enforcement from getting the evidence it was seeking.
With the increasing proliferation of eavesdrop-thwarting
encryption built in to our infrastructure since export laws