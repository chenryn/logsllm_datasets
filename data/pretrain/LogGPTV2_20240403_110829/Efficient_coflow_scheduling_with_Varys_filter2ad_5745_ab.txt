sizes within the same coﬂow (Figure 4c), which underpins the pos-
sible improvements from inter-coﬂow scheduling – e.g., the opti-
mal schedule in Figure 2 outperforms the rest, primarily because it
exploits the skew in C1. Note that we rounded up ﬂow sizes to 1
MB to calculate skew in Figure 4c to ignore small variations.
Both coﬂows end!
2!
Time!
(c) WSS [15]
4!
2!
Time!
4!
(d) The optimal schedule
2!
Time!
P1!
P2!
P3!
P1!
P2!
P3!
Figure 2: Allocation of ingress port capacities (vertical axis) using different
C2 ends!
mechanisms for the coﬂows in Figure 1. Each port can transfer one unit of
data in one time unit. The average FCT and CCT for (a) per-ﬂow fairness
are 3.4 and 4 time units; (b) per-ﬂow prioritization are 2.8 and 3.5 time
units; (c) Weighted Shufﬂe Scheduling (WSS) are 3.6 and 4 time units; and
(d) the optimal schedule are 3 and 3 time units.
Both coﬂows end!
4!
to help the reader follow the measurements of coﬂows in produc-
tion clusters (§4), analysis and design of inter-coﬂow scheduling
2!
algorithms (§5), and Varys’s design details (§6).
3.1 Problem Statement
When improving performance, given a coﬂow with information
about its individual ﬂows, their size, and endpoints, Varys must
decide when to start its ﬂows and at what rate to serve them to
minimize the average CCT of the cluster. It can preempt existing
coﬂows to avoid head-of-line blocking, but it must also avoid star-
vation. Information about a coﬂow is unknown prior to its arrival.
When optimizing predictability, Varys must admit a new coﬂow
if it can be completed within its deadline without violating deadline
guarantees of the already-admitted ones.
Time!
Time!
2!
4!
Irrespective of the objective, the inter-coﬂow scheduling prob-
lem is NP-hard (§5). Varys implements a scheduler that exploits
the variations in coﬂow characteristics (§4) to perform reasonably
well in realistic settings.
3.2 Architectural Overview
Varys master schedules coﬂows from different frameworks using
global coordination (Figure 3). It works in two modes: it either
tries to minimize CCT or to meet deadlines. For the latter, it uses
admission control, and rejected coﬂows must be resubmitted later.
Frameworks use a client library to interact with Varys to register
and deﬁne coﬂows (§6.1). The master aggregates all interactions to
create a global view of the network and determines rates of ﬂows
in each coﬂow (§6.2) that are enforced by the client library.
Varys daemons, one on each machine, handle time-decoupled
coﬂows, where senders and receivers are not simultaneously ac-
tive. Instead of hogging the CPU, sender tasks (e.g., mappers) of
data-intensive applications often complete after writing their out-
put to the disk. Whenever corresponding receivers (e.g., reducers)
are ready, Varys daemons serve them by coordinating with the mas-
ter. Varys daemons use the same client library as other tasks. Addi-
tionally, these daemons send periodic measurements of the network
usage at each machine to Varys master. The master aggregates them
Coﬂow%Length%
Coﬂow%Width%(NumFlows)%
!
s
w
o
ﬂ
o
C
f
o
.
c
a
r
F
!
s
w
o
ﬂ
o
C
1!
0.8!
0.6!
0.4!
0.2!
0!
1.E+06! 1.E+08! 1.E+10!
1!
0.8!
0.6!
0.4!
0.2!
0!
1.E+00!1.E+04!1.E+08!
Coﬂow%Skew%(CoV)%
Bytes!
Number of Flows!
(b) Coﬂow width
f
o
.
c
a
r
F
Coﬂow%M/R%
1!
0.8!
0.6!
0.4!
0.2!
0!
1!
Coﬂow%Size%VS%Total%Size%
100!
4!
2!
f
o
.
c
a
r
F
!
s
w
o
ﬂ
o
C
(a) Coﬂow length
1!
0.8!
0.6!
0.4!
0.2!
0!
6!
0!
Coﬂow%Size%
Coeff. of Var. of Flows!
(c) Coﬂow skew
1!
0.8!
0.6!
0.4!
0.2!
0!
1.E+06! 1.E+10! 1.E+14!
!
s
w
o
ﬂ
o
C
A
m
o
r
f
s
e
t
y
B
.
c
a
r
F
l
a
t
o
T
0.01!
l
l
f
o
!
s
w
o
ﬂ
o
C
f
o
.
c
a
r
F
!
s
w
o
ﬂ
o
C
f
o
.
c
a
r
F
Bytes!
Sender-to-Receiver Ratio!
(d) Coﬂow bottlenecks
1!
0.8!
0.6!
0.4!
0.2!
0!
1.E+06!1.E+10!1.E+14!
Coﬂow Size (Bytes)!
(e) Coﬂow size
(f) Coﬂow footprint
Figure 4: Coﬂows in production vary widely in (a) length, (b) width, (c)
skew of ﬂow sizes, (c) bottleneck locations, and (e) total size. Moreover, (f)
numerous small coﬂows have tiny network footprint.
Identifying bottlenecks and exploiting them is the key to im-
provements. Figure 4d shows that the ratio of sender and receiver
ports/machines2 can be very different across coﬂows, and senders
can be bottlenecks in almost a third of the coﬂows.
We found that length and width of a coﬂow have little correla-
tion; a coﬂow can have many small ﬂows as well as few large ﬂows.
However, as Figure 4b and Figure 4c suggest, width and skew are
indeed correlated – as width increases, the probability of variations
among ﬂows increases as well. We also observed large variation in
coﬂow size (Figure 4e).
4.2 Heavy-Tailed Distribution of Coﬂow Size
Data-intensive jobs in production clusters are known to follow
heavy-tailed distributions in terms of their number of tasks, size of
input, and output size [10,17]. We observe the same for coﬂow size
as well. Figure 4f presents the fraction of total coﬂows contributed
by coﬂows of different size. Comparing it with Figure 4e, we see
that almost all trafﬁc are generated by a handful of large coﬂows –
98% (99.6%) of the relevant bytes belong to only 8% (15%) of the
coﬂows that are more than 10 GB (1 GB) in size. This allows Varys
to focus only on scheduling large coﬂows, where gains signiﬁcantly
outweigh coordination overheads.
5 Coﬂow Scheduling: Analytical Results
The inter-coﬂow scheduling problem is NP-hard. In this section,
we provide insights into its complexity (§5.1) and discuss desir-
able properties of an ideal scheduler along with associated tradeoffs
(§5.2). Based on our understanding, we develop two inter-coﬂow
scheduling algorithms: one to minimize CCTs (§5.3) and another
to guarantee coﬂow completions within their deadlines (§5.4).
Detailed analysis and proofs can be found in the appendix.
2One machine can have multiple tasks of the same coﬂow.
5.1 Problem Formulation and Complexity
We consider two objectives for optimizing data-intensive commu-
nication: either minimizing the average CCT or improving pre-
dictability by maximizing the number of coﬂows that meet dead-
lines (§A). Achieving either objective is NP-hard, even when
1. all coﬂows can start at the same time,
2. information about their ﬂows are known beforehand, and
3. ingress and egress ports have the same capacity.
We prove it by reducing the concurrent open-shop scheduling prob-
lem [34] to inter-coﬂow scheduling (Theorem A.1).
The online inter-coﬂow scheduling problem is even harder be-
cause of the following reasons:
1. Capacity constraints. Ingress and egress ports of the datacenter
fabric have ﬁnite, possibly heterogeneous, capacities. Hence,
the optimal solution must ﬁnd the best ordering of ﬂows to dis-
patch at each ingress port and simultaneously calculate the best
matching at the egress ports. Furthermore, when optimizing
predictability, it must decide whether or not to admit a coﬂow.
2. Lack of future knowledge. Arrival times and characteristics of
new coﬂows and their ﬂows cannot be predicted.
Because the rate of any ﬂow depends on its allocations at both
ingress and egress ports, we refer to the inter-coﬂow scheduling
problem as an instance of the concurrent open shop scheduling with
coupled resources (Remark A.2). To the best of our knowledge,
this variation of the problem – with ordering and matching require-
ments – has not appeared in the literature prior to this work.
5.2 Desirable Properties and Tradeoffs
Efﬁcient scheduling (minimizing completion times) and pre-
dictable scheduling (guaranteeing coﬂow completions within their
deadlines) are inherently conﬂicting. The former requires preemp-
tive solutions to avoid head-of-line blocking. Shortest-remaining-
time-ﬁrst (SRTF) for optimally scheduling ﬂows on a single link is
an example [25]. Preemption, in the worst case, can lead to star-
vation; e.g., SRTF starves long ﬂows. The latter, on the contrary,
requires admission control to provide guarantees.
We expect an ideal scheduler to satisfy the following goals in
addition to its primary objective.
1. Starvation freedom. Coﬂows, irrespective of their characteris-
tics, should not starve for arbitrarily long periods.
2. Work-conserving allocation. Available resources should be
used as much as possible.
The former ensures eventual completion of coﬂows irrespective
of system load. The latter avoids underutilization of the network,
which intuitively should result in lower CCTs and higher admis-
sions. However, both are at odds with our primary objectives (§B).
Predictable scheduling has an additional goal.
3. Guaranteed completion. If admitted, a coﬂow must complete
within its deadline.
In the following, we present algorithms that achieve high net-
work utilization, and ensure starvation freedom when minimizing
CCT (§5.3) and guarantees completion of admitted coﬂows when
maximizing predictability (§5.4).
5.3
Given the complexity, instead of ﬁnding an optimal algorithm, we
focus on understanding what an ofﬂine optimal schedule might
look like under simplifying assumptions. Next, we compute the
minimum time to complete a single coﬂow. We use this result as
a building block to devise a scheduling heuristic and an iterative
Inter-Coﬂow Scheduling to Minimize CCT
2!
3!
3!
3!
Time!
C2 ends!
P1!
P2!
P1!
P3!
P2!
P3!
P1!
P2!
P3!
C1 ends!
1!
1!
2!
2!
3!
4!
Time!
3!
7!
(b) SCF/NCF/TCF
C2 ends!
C2 ends!
C1 ends!
C1 ends!
7!
7!
3!
Time!
3!
Time!
(c) SEBF
3!
3!
2!
3!
2!
3!
1!
1!
2!
2!
2!
3!
3!
2!
3!
(a) Input
3!
7!
7!
P1!
P2!
P1!
P3!
P2!
P3!
4!
Time!
4!
Time!
C1 ends!
C1 ends!
C2 ends!
C2 ends!
Figure 5: Allocations of egress port capacities (vertical axis) for the coﬂows
in (a) on a 3 × 3 fabric for different coﬂow scheduling heuristics (§5.3.2).
bandwidth allocation algorithm. We conclude by presenting the
necessary steps to transform our ofﬂine solution to an online one
with guarantees for starvation freedom and work conservation.
5.3.1 Solution Approach
Consider the ofﬂine problem of scheduling |C| coﬂows (C =
{C1, C2, . . . , C|C|}) that arrived at time 0. The optimality of the
shortest-processing-time-ﬁrst (SPTF) heuristic on a single link sug-
gests that shortest- or smallest-ﬁrst schedules are the most effective
in minimizing completion times [8, 25]. However, in the multi-link
scenario, links can have different schedules. This makes the search
space exponentially large – there are ((|C|P )!)P possible solutions
when scheduling |C| coﬂows with P 2 ﬂows each on a P ×P fabric!
If we remove the capacity constraints from either ingress or
egress ports, under the assumptions of Section 5.1, the coﬂow
scheduling problem simpliﬁes to the traditional concurrent open
shop scheduling problem, which has optimal permutation sched-
ules [30]; meaning, scheduling coﬂows one after another is sufﬁ-
cient, and searching within the |C|! possible schedules is enough.
Unfortunately, permutation schedules can be suboptimal for cou-
pled resources (Theorem C.1), which can lead to ﬂow preemptions
at arbitrary points in time – not just at coﬂow arrivals and comple-
tions (Remark C.2). To avoid incessant rescheduling, we restrict
ourselves to permutation schedules.
5.3.2 The Smallest-Effective-Bottleneck-First Heuristic
Once scheduled, a coﬂow can impact the completion times of all
other coﬂows scheduled after it. Our primary goal is to minimize
the opportunity lost in scheduling each coﬂow.
Given the optimality of the shortest- or smallest-ﬁrst policy in
minimizing the average FCT [8, 25], a natural choice for schedul-
ing coﬂows would be to approximate that with a Shortest-Coﬂow-
First (SCF) heuristic. However, SCF does not take into account
the width of a coﬂow. A width-based alternative to SCF is the
Narrowest-Coﬂow-First (NCF) heuristic, but NCF cannot differen-
tiate between a short coﬂow from a long one. A smallesT-Coﬂow-
First (TCF) heuristic is a better alternative than the two – while SCF
can be inﬂuenced just by a single long ﬂow (i.e., coﬂow length) and
NCF relies only on coﬂow width, TCF responds to both.
However, the completion time of coﬂow actually depends on
its bottleneck. A coﬂow C must transfer!j dij amount of data
) and!i dij through each egress
), where dij is the amount of data to transfer from P in
through each ingress port i (P in
port j (P out
to P out
j
at rate rij. The minimum CCT (Γ) becomes
i
i
j