### Optimized Text

#### Network Performance and Queue Management
Improperly managed paths can significantly degrade network performance. Effective queue management strategies have been proven to eliminate deadlocks by organizing multiple independent priority queues within each switch and incrementally increasing packet priorities at each hop [6, 20, 35]. The core principle is to ensure that no circular buffer dependency (CBD) exists within the same priority class. A similar queue management strategy is also employed in InfiniBand [40]. However, as the network scale increases, so does the number of required priority queues, which poses a significant scalability challenge since commodity switches typically support only a limited number of priorities.

**Tagger [25]** operates on the same principle but further leverages the structural features of topologies. It increases a packet's priority only when the routing rule is at risk of generating CBD. This approach reduces the number of required priority queues. Nevertheless, if the number of priorities is insufficient, Tagger will drop the corresponding packets, thereby compromising the lossless property of the network.

#### Deadlock Recovery
Deadlock recovery solutions [2, 3, 36, 38, 48, 52] generally consist of two key components:
1. **Interacting Status Information:** Switches exchange status information to heuristically detect the occurrence of deadlocks.
2. **Packet Handling:** Packets involved in CBD are either dropped or temporarily rerouted to recover from the deadlock. Recently, SPIN proposed the idea of synchronously draining packets on the CBD to expedite the recovery process [48]. However, these recovery solutions are reactive and do not address the root cause of deadlocks, thus failing to prevent their recurrence.

#### Conclusion
This paper introduces a novel perspective on understanding and solving network deadlocks by avoiding the "hold and wait" condition. We propose Gentle Flow Control (GFC) to manage the sending rate at a fine granularity, ensuring that the sending and draining rates match without triggering the "hold and wait" condition, thereby preventing deadlocks. Our theoretical analysis demonstrates that GFC can completely avoid deadlocks, and we provide a detailed implementation strategy for mainstream lossless networks with minimal modifications. Both testbed experiments and packet-level simulations confirm that GFC effectively avoids deadlocks with negligible side effects.

#### Acknowledgments
The authors are grateful to the shepherd Kai Chen and the anonymous reviewers for their constructive comments. This work was partially supported by the National Key Research and Development Program of China (No.2018YFB1700103) and the National Natural Science Foundation of China (NSFC) under Grant 61872208.

#### References
[References remain unchanged]

---

### Appendix: Proof of Theorem 4.1
The straightforward approach to eliminating the "hold and wait" condition is to determine the worst-case queue length \( q(t) \) and ensure it never exceeds \( B_m \) (i.e., \( q_{\max} \leq R_d(t) \)).

In congestion scenarios, \( q(t) \) reaches its maximum \( q_{\max} \) only when the input rate \( R_i(t) \) continuously decreases to the draining rate \( R_d(t) \). Consider the general buffer evolution depicted in Figure 21. Suppose \( q_{\max} \) is approached at time \( t_b \). We focus on the continuous increase of \( q(t) \) starting from \( t_a \) and ending at \( t_b \). The starting instant \( t_a \) is chosen based on the following criteria:
1. During \( (t_a, t_b) \), \( q(t) \) increases monotonically.
2. \( q(t_a) = B_0 \) or \( q(t_a - \delta) \geq q(t_a) \), where \( \delta \to 0^+ \).

We consider the time sequence \( \{t_k = k\tau + t_0 | k \in [0, n]\} \), where \( t_a \leq t_0 < t_a + \tau \) and \( t_n = t_b \). Accordingly, we have:
\[ q(t_0) \geq B_0 \]
\[ q(t_{n-1}) = B_m - R_d \]
\[ q(t_n) = q_{\max} \]
\[ C \geq \frac{B_m - B_0}{\tau} \]

For any instant \( t \in [t_k, t_{k+1}] \) (where \( k = 1, \ldots, n-1 \)):
\[ \frac{B_m - q(t_{k-1})}{B_m - B_0} \cdot C \tau - \int_{k\tau}^{(k+1)\tau} R_d(t) \, dt \]

The queue increase can be represented as:
\[ q(t_{k+1}) - q(t_k) \leq \frac{B_m - q(t_{k-1})}{B_m - B_0} \cdot C \tau - \int_{k\tau}^{(k+1)\tau} R_d(t) \, dt \]

This ensures that the queue length never exceeds the buffer capacity, thereby preventing deadlocks.