16.6
24.5
15.0
52.9
38.6
92.90 +0.01
91.09 −1.80
87.94 +0.11
87.91 −0.08
97.32 −0.11
97.27 −0.16
90.33 +0.25
88.64 −1.44
Dataset
f
λc
News
IMDB
SVM 0.1
LR
1.0
SVM 0.5
LR
1.0
Test acc
±δ
80.42 −0.16
80.35 −0.16
89.47 −0.66
89.33 −1.15
Decode
Rec
Pre
0.70
0.85
0.56
1.00
0.90
0.80
0.65
1.00
0.73
0.90
0.16
1.00
0.98
0.94
0.73
1.00
Sim
0.84
0.78
0.88
0.83
0.88
0.51
0.97
0.90
τ
0.85
0.95
0.85
0.95
0.85
0.95
0.85
0.95
Table 3: Results of the correlated value encoding attack. Here λc is the coefficient for the correlation term in the objective
function and δ is the difference with the baseline test accuracy. For image data, decode MAPE is the mean absolute pixel error.
For text data, τ is the decoding threshold for the correlation value. Pre is precision, Rec is recall, and Sim is cosine similarity.
Dataset
CIFAR10
LFW
FaceScrub (G)
FaceScrub (F)
f
λs
10.0
RES
50.0
CNN 10.0
50.0
10.0
50.0
10.0
50.0
RES
Test acc Decode
±δ MAPE
36.00
3.52
37.30
5.24
2.51
0.15
39.85
7.46
92.96 +0.07
92.31 −0.58
88.00 +0.17
87.63 −0.20
97.31 −0.13
97.45 +0.01
89.99 −0.09
87.45 −2.63
Dataset
News
IMDB
f
λs
SVM 5.0
7.5
5.0
LR
7.5
SVM 5.0
7.5
5.0
7.5
LR
Test acc
±δ
80.42 −0.16
80.49 −0.09
80.45 −0.06
80.20 −0.31
89.32 −0.81
89.08 −1.05
89.52 −0.92
89.27 −1.21
Decode
Rec
0.66
0.80
0.67
0.73
0.68
0.75
0.76
0.83
Pre
0.56
0.71
0.57
0.63
0.60
0.66
0.67
0.76
Sim
0.69
0.82
0.70
0.75
0.75
0.81
0.81
0.88
Table 4: Results of the sign encoding attack. Here λs is the coefficient for the correlation term in the objective function.
model. The fourth column in Table 2 shows the number of bits we
can use before test accuracy drops significantly.
Decoding. Decoding is always perfect because we use lossless
compression and no errors are introduced during encoding. For the
20 Newsgroup model, the adversary can successfully extract about
57 Mb of compressed data, equivalent to 70% of the training dataset.
Test accuracy. In our implementation, each model parameter is
a 32-bit floating-point number. Empirically, b under 20 does not
decrease test accuracy on the primary task for most datasets. Bi-
nary classification on images (LFW, FaceScrub Gender) can endure
more loss of precision. For multi-class tasks, test accuracy drops
significantly when b exceeds 20 as shown for CIFAR10 in Figure 2.
6.5 Correlated Value Encoding Attack
Table 3 summarizes the results for this attack.
Image encoding and decoding. We correlate model parameters
with the pixel intensity of gray-scale training images. The number
of parameters limits the number of images that can be encoded in
this way: 455 for CIFAR10, 200 for FaceScrub, 300 for LFW.
We decode images by mapping the correlated parameters back to
pixel space (if correlation is perfect, the parameters are simply lin-
early transformed images). To do so given a sequence of parameters,
we map the minimum parameter to 0, maximum to 255, and other
parameters to the corresponding pixel value using min-max scaling.
We obtain an approximate original image after transformation if
the correlation is positive and an approximate inverted original
image if the correlation is negative.
After the transformation, we measure the mean absolute pixel
error (MAPE) for different choices of λc, which controls the level of
correlation. We find that to recover reasonable images, λc needs to
be over 1.0 for all tasks. For a fixed λc, errors are smaller for binary
classification than for multi-class tasks. Examples of reconstructed
images are shown in Figure 3 for the FaceScrub dataset.
Text encoding and decoding. To encode, we generate a pseudo-
random, d′-dimensional vector of 32-bit floating point numbers for
each token in the vocabulary of the training corpus. Then, given
a training document, we use the pseudorandom vectors for the
first 100 tokens in that document as the secret to correlate with the
model parameters. We set d′ to 20. Encoding one document thus
requires up to 2000 parameters, allowing us to encode around 1300
documents for 20 Newsgroups and 150 for IMDB.
To decode, we first reproduce the pseudorandom vectors for
each token used during training. For each consecutive part of the
parameters that should match a token, we decode by searching for
a token whose corresponding vector is best correlated with the
parameters. We set a threshold value τ and if the correlation value
is above τ, we accept this token and reject otherwise.
Table 3 shows the decoding results for different τ. As expected,
larger τ increases precision and reduces recall. Empirically, τ = 0.85
yields high-quality decoded documents (see examples in Table 5).
Figure 3: Decoded examples from all attacks applied to models trained on the FaceScrub gender classification task. First row
is the ground truth. Second row is the correlated value encoding attack (λc=1.0, MAPE=15.0). Third row is the sign encoding
attack (λs=10.0, MAPE=2.51). Fourth row is the capacity abuse attack (m=110K, MAPE=10.8).
Test accuracy. Models with a lower decoding error also have lower
test accuracy. For binary classification tasks, we can keep MAPE
reasonably low while reducing test accuracy by 0.1%. For CIFAR10
and FaceScrub face recognition, lower MAPE requires larger λc,
which in turn reduces test accuracy by more than 1%.
For 20 Newsgroups, test accuracy drops only by 0.16%. For IMDB,
the drop is more significant: 0.66% for SVM and 1.15% for LR.
6.6 Sign Encoding Attack
Table 4 summarizes the results of the sign encoding attack.
Image encoding and decoding. As mentioned in Section 4.3, the
sign encoding attack may not encode all bits correctly. Therefore,
instead of the encrypted, compressed binaries that we used for LSB
encoding, we use the bit representation of the raw pixels of the
gray-scale training images as the string to be encoded. Each pixel
is an 8-bit unsigned integer. The encoding capacity is thus 1
8 of
the correlated value encoding attack. We can encode 56 images for
CIFAR10, 25 images for FaceScrub and 37 images for LFW.
To reconstruct pixels, we assemble the bits represented in the
parameter signs. With λs = 50, MAPE is small for all datasets. For
gender classification on FaceScrub, the error can be smaller than 1,
i.e., reconstruction is nearly perfect.
Text encoding and decoding. We construct a bit representation
for each token using its index in the vocabulary. The number of bits
per token is ⌈log2(|V |)⌉, which is 17 for both 20 Newsgroups and
IMDB. We encode the first 100 words in each document and thus
need a total of 1,700 parameter signs per document. We encode
1530 documents for 20 Newsgroups and 180 for IMDB in this way.
To reconstruct tokens, we use the signs of 17 consecutive pa-
rameters as the index into the vocabulary. Setting λs ≥ 5 yields
good results for most tasks (see examples in Table 5). Decoding is
less accurate than for the correlated value encoding attack. The
reason is that signs need to be encoded almost perfectly to recover
high-quality documents; even if 1 bit out of 17 is wrong, our de-
coding produces a completely different token. More sophisticated,
error-correcting decoding techniques can be applied here, but we
leave this to future work.
Test accuracy. This attack does not significantly affect the test
accuracy of binary classification models on image datasets. For LFW
and CIFAR10, test accuracy occasionally increases. For multi-class
tasks, when λs is large, FaceScrub face recognition degrades by
2.6%, while the CIFAR10 model with λs = 50 still generalizes well.
For 20 Newsgroups, test accuracy changes by less than 0.5% for
all values of λs. For IMDB, accuracy decreases by around 0.8% to
1.2% for both SVM and LR.
6.7 Capacity Abuse Attack
Table 6 summarizes the results.
Image encoding and decoding. We could use the same technique
as in the sign encoding attack, but for a binary classifier this requires
8 synthetic inputs per each pixel. Instead, we encode an approximate
pixel value in 4 bits. We map a pixel value p ∈ {0, . . . , 255} to
p′ ∈ {0, . . . , 15} (e.g., map 0-15 in p to 0 in p′) and use 4 synthetic
data points to encode p′. Another possibility (not evaluated in this
paper) would be to encode every other pixel and recover the image
by interpolating the missing pixels.
We evaluate two settings of m, the number of synthesized data
points. For LFW, we can encode 3 images for m = 34K and 5 images
for m = 58K. For FaceScrub gender classification, we can encode
11 images for m = 110K and 17 images for m = 170K. While these
numbers may appear low, this attack works in a black-box setting
against a binary classifier, where the adversary aims to recover
information from a single output bit. Moreover, for many tasks (e.g.,
medical image analysis) recovering even a single training input
constitutes a serious privacy breach. Finally, if the attacker’s goal
is to recover not the raw images but some other information about
Ground Truth
has only been week since saw my first
john waters film female trouble and wasn
sure what to expect
in brave new girl holly comes from small
town in texas sings the yellow rose of
texas at local competition
maybe need to have my head examined
but thought this was pretty good movie
the cg is not too bad
was around when saw this movie first it
wasn so special then but few years later
saw it again and
Correlation Encoding (λc = 1.0)
it natch only been week since saw my first
john waters film female trouble and wasn
sure what to expect
in chasing new girl holly comes from
willed town in texas sings the yellow rose
of texas at local competition
maybe need to have my head examined
but thought this was pretty good movie
the cg pirouetting not too bad
was around when saw this movie martine
it wasn so special then but few years later
saw it again and
Sign Encoding (λs = 7.5)
it has peering been week saw mxyzptlk
first john waters film bloch trouble and