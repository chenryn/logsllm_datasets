The log shows the error rates of the ciphertexts produced by each
ciphertext-DSL operation (conveniently augmented by its modulus).
We can see that the first tunnel operation increases the error rate
by roughly 5x, the switch to the smaller modulus increases the
rate by roughly 2x, etc. (The other modSwitch operations do not
actually change the modulus, and are therefore null.)
1.4 Limitations and Future Work
As explained above, Alchemy represents significant progress to-
ward making FHE usable for non-experts. Here we describe some
of its present limitations and directions for potential improvement.
Fully automating FHE parameters. Although the PT2CT compiler
automatically chooses parameters for each ciphertext and hint in
the computation, the programmer still must provide a collection
of sufficiently large (and arithmetically valid) cyclotomic indices,
and a pool of sufficiently many moduli to support all the statically
estimated error rates. Ideally, Alchemy would choose all of these
parameters automatically, targeting a desired security level without
unnecessarily sacrificing efficiency. Because in our examples we
generated these parameters semi-automatically using scripts, this
ultimate goal may not be too far out of reach. One potential route
is to use Template Haskell to programmatically generate types
meeting the required constraints at compile time. (Alchemy already
uses Template Haskell in some basic ways, e.g., to compute the
“noise capacity” of the provided moduli.)
Scalability. We have successfully demonstrated Alchemy’s util-
ity on moderate-sized computations, like homomorphic evaluation
of a Ring-LWR-based PRF. However, Alchemy is not yet suitable
for much larger or more complex functions, due to the long compi-
lation times under the ghc Haskell compiler (which unfortunately
have become worse in recent versions). The main bottleneck is
Alchemy’s extensive use of type-level arithmetic for static error-
rate tracking and encoding arithmetic constraints, which severely
stresses the Haskell compiler. (This is a known performance issue
that has been under active consideration for some time.) Relaxing
or simplifying the error-rate arithmetic might help significantly.
Alternative backends. While Alchemy currently targets the FHE
implementation of Λ◦λ, nothing in its design requires this. Because
the plaintext and ciphertext DSLs are polymorphic, one could poten-
tially write interpreters that output, e.g., valid C++ code targeting
HElib [36]. Such a staged-compilation approach could combine the
strong static safety properties of Alchemy’s DSLs and convenience
of its compilers with the high performance of optimized lower-level
libraries.
Formal proofs. Alchemy’s DSL interpreters have very concise
implementations (of at most a few lines of code per method) that are
easy to audit by inspection, but are not formally verified. Therefore,
there is the possibility that Alchemy will transform some program
incorrectly, perhaps for some unusual choices of parameters or
unlikely choices of randomness. Given the complexity of FHE, and
especially of error accumulation, at this stage it is far from clear
what a meaningful formal proof of correctness would entail.
Automating and optimizing arithmetization. Lastly, Alchemy
and all other existing FHE implementations still require the pro-
grammer to arithmetize the desired plaintext computation into
relatively low-level operations (notwithstanding recent progress
like [21, 37]). At present this process is very ad-hoc and manually
driven: the “native instruction sets” of FHEs consist of a motley
assembly of low- and medium-level operations with varying cost
metrics (including “bootstrapping”), and it is not at all clear how
best to arithmetize even some basic computations of interest. An
ambitious goal would be to devise compilers that convert high-level
DSL code into particular FHE instruction sets, and optimize their
performance according to various objectives.
1.5 Related Work
Fully homomorphic encryption. As far as we know, there are no
prior domain-specific languages or compilers for FHE; all implemen-
tations require the programmer to “arithmetize” the desired func-
tion by hand and then write code in a general-purpose language,
manually scheduling appropriate homomorphic and ciphertext-
maintenance operations, generating keys and hints, etc.
Probably the most well-known and mature FHE implementa-
tion is HElib [36], an “assembly language” for fully homomorphic
encryption, which is implemented in C++ on top of NTL [50]. HE-
lib has been used for many homomorphic computations of inter-
est [21, 33, 37, 38], but it requires quite a lot of expertise in FHE
and the library itself to use, because computations must be written
directly in the “assembly language.”
Alchemy is built on top of the Λ◦ λ library for lattice-based
cryptography [22] and its FHE implementation. To our knowledge,
this is the only implementation that supports ring-switching, which
we use for homomorphic PRF evaluation. However, up until now
those who wished to use Λ◦λ for FHE still had to write code directly
to its interface, which is roughly at the same level of abstraction as
HElib’s.
FHEW [25] is a refinement and fast implementation of an ef-
ficient bootstrapping algorithm [4] for “third-generation” FHE
schemes [34]. However, it is not yet appropriate for general-purpose
homomorphic computations, because it encrypts only one bit (or
just a few bits) per ciphertext, and supports only basic logic gates.
The SEAL library [17] provides heuristic parameter selection, an
important part of practically usable FHE. However, users must still
manually arithmetize and implement their computations, and gener-
ate keys and hints. SEAL is also limited to power-of-two cyclotomic
rings, which do not support SIMD “slots” (for characteristic-two
plaintext rings) or the most useful forms of ring-switching.
Secure computation. Secure two- and multi-party computation
(2PC and MPC) is similar to FHE, in that it allows mutually dis-
trustful interacting parties to compute a function on their private
inputs while revealing nothing more than the function output (and
what is implied by it). The history of 2PC/MPC stretches back to
the 1980s [8, 35, 53], and its implementations are more mature. Like
FHE, secure computation also requires “in-the-clear” functions to
be converted to (arithmetic or boolean) circuits and compiled into
“encrypted” versions, e.g., garbled circuits. Tools for these tasks
have evolved over many years (e.g., [7, 9, 23, 39, 43, 44, 47, 48]), and
the approach of using specification languages and compilers has
proven to be very powerful.
As a few examples, Fairplay [7, 44], TASTY [39], ShareMonad [42],
and Wysteria [48] all provide high-level domain-specific languages
for expressing computations, and compilers for transforming these
into executable protocols that satisfy the desired security properties.
In particular, TASTY compiles to two-party protocols that use a mix
of garbled circuits and (semi-)homomorphic encryption, but not
fully homomorphic encryption. Wysteria goes further to support
“mixed-mode” programs, and has a strong type system and a proof
of type soundness, which implies formal secrecy guarantees for
the parties’ private data. The use of strong static type systems to
provide higher levels of safety and trustworthiness is also a theme
in Alchemy, though our work does not (yet) provide the kinds of
formal guarantees that Wysteria has.
The rest of the paper is organized as follows.
Section 2 gives the relevant background on the (typed) tagless
final approach of DSL design and implementation, which
Alchemy is based on.
Section 3 describes the various components of Alchemy’s plain-
Section 4 describes the flagship Alchemy compiler, the plaintext-
text and ciphertext DSLs.
to-ciphertext compiler.
Section 5 describes a full-scale application in Alchemy, namely
(homomorphic) “ring rounding,” and gives an evaluation.
The appendices contain additional background and technical ma-
terial.
2 TAGLESS-FINAL BACKGROUND
Here we give the necessary background on the elegant and powerful
“(typed) tagless-final” approach [16, 41] to the design of domain-
specific languages (DSLs), also called object languages, in a host
language. The well-known “initial” approach to DSLs represents
object-language expressions as values of a corresponding data
type/structure in the host language, e.g., an abstract syntax tree. By
contrast, the tagless, or “final,” approach represents object-language
expressions as ordinary combinations of polymorphic terms in the
host language. The polymorphism allows a DSL expression to be
written once and interpreted in many different ways.
The tagless-final approach makes language design and interpreta-
tion highly modular, extensible, and safe. Object-language features
can be defined independently and combined together arbitrarily.
Interpreters can be defined to handle any subset of the available
language components, and extended to support new ones without
changing existing code. If an interpreter does not implement all the
language components used in an expression, type checking fails at
compile time with an informative error. And the full strength of the
host language’s type system, including type inference, is directly
inherited by the object language with no special effort.
Below we give an introduction to the approach by providing a
running example of several general-purpose language components
and interpreters from [16, 41], which are also included in Alchemy.
In Section 3 we describe more specialized language components
for the plaintext and ciphertext languages.
2.1 Language Components and Interpreters
Language components. In the tagless-final approach for the host
language Haskell, an object-language component is defined by a
type class, or class for short. A class defines an abstract interface
that introduces one or more polymorphic methods, which may be
functions or just values. Concrete data types can then instantiate
the class, by implementing its methods in an appropriate way. For
example, Int and Bool both instantiate the Additive class repre-
senting additive groups, defining its addition operator + as ordinary
integer addition and exclusive-or, respectively.
In the tagless-final context, a language component is defined
by a class. For example, operations related to pairs in the object
language are defined by5
class Pair_ expr where
pair_ :: expr e (a -> b -> (a,b))
fst_ :: expr e ((a,b) -> a)
snd_ :: expr e ((a,b) -> b)
Here pair_ is a polymorphic host-language term representing
an object-language function, which maps (object-language) values
of arbitrary types a and b to an (object-language) value of pair
type (a,b). (All Haskell types are automatically inherited by the
object language.) Naturally, fst_ and snd_ are similar.
Notice the common form expr e t of the method types. The
type expr is an instance of the Pair_ class, and serves as the inter-
preter of pair_, fst_, and snd_. The type t represents the type of
the object-language term, and the type e represents its environment
(discussed below in Section 2.2).
5By convention, names of object-language components and terms always end in an
underscore, to distinguish them from host-language names.
Interpreters. An interpreter of a language component is just a
data type that instantiates the class defining the component. As run-
ning examples, we describe two simple interpreters. The evaluator E
is defined as
newtype E e a = E (e -> a)
which says that a value of type E e a is just a function mapping
e-values to a-values. For example, when e is the null type () (indi-
cating a “closed” expression with no free variables), the function
will map its (null) input to the a-value represented by the object-
language expression. The (not-so-pretty) printer P is defined as
newtype P e a = P String
which says that a value of type P e a is just a String, i.e., the
printed representation of the object-language expression.
We make E and P interpreters of the pair-related DSL opera-
tions by defining them as instances of the Pair_ class. Observe
that when expr is specialized to E, the type of pair_ is equivalent
to e -> a -> b -> (a,b). This leads to the following (partial)
Pair_ instance (the definitions of fst_ and snd_ are also trivial):6
instance Pair_ E where
pair_ = E $ \e -> \a -> \b -> (a,b)
When expr is specialized to P, the type of pair_ is equivalent to
just String, which leads to the easy (partial) instance definition
instance Pair_ P where
pair_ = P $ "pair"
Extending the language and interpreters. We can introduce more
DSL operations simply by defining more classes, e.g., for addition
and multiplication:
class Add_ expr a where
add_ :: expr e (a -> a -> a)
neg_ :: expr e (a -> a)
class Mul_ expr a where
type PreMul_ expr a
mul_ :: expr e (PreMul_ expr a -> PreMul_ expr a -> a)
Notice that here the type a is specific to the instance, not arbitrary:
it is an argument to the Add_ class. This means that an interpreter
may support add_ and neg_ for certain types a, but not others.
The type of mul_ is similar to that of add_, except that the two
(object-language) inputs have type PreMul_ expr a instead of
just a. This allows the interpreter to define the input type as a
function of the output type. We take advantage of this in plaintext-
to-ciphertext compilation, where the types carry static information
about ciphertext error rates (see Section 4).
The instances of Add_ for E and P are again trivial. We show E’s
to highlight one small subtlety:
instance Additive a => Add_ E a where
we must define PreMul_ E a = a. By contrast, the P interpreter
represents any object-language term as a String, so we are free to
define PreMul_ P a arbitrarily.
2.2 Functions and HOAS
Suppose we want to write an object-language function double_
that adds an input value to itself. We may at first be tempted to
write this as a host-language function on object-language values:
double_ :: Add_ expr a => expr e a -> expr e a
double_ x = x +: x
Unfortunately, there is a subtle problem: when we apply double_,
the object-language argument is “inlined” into the resulting object-
language expression (i.e., call-by-name evaluation), so the argument
is re-evaluated every time it appears in the body of the function:
print $ double_ (3 *: 4)
-- add (mul 3 4) (mul 3 4)
Instead of multiplying 3 by 4 and passing the result to double_ as
we would want, the object-language expression 3 *: 4 is passed to
double_ unevaluated, which ultimately results in two multiplica-
tions instead of one. (Examples involving an exponential blowup in
size are easy to construct.) While this does not change the expres-
sion’s value, it may dramatically harm its computational efficiency.
To resolve this problem we need the object language to sup-
port programmer-defined functions—i.e., function abstraction—and
function application. Ideally, writing and applying functions in the
object language would be as natural as for the host language, via a
direct translation from the latter to the former. Essentially, we seek
to use higher-order abstract syntax (HOAS). In Appendix B, build-
ing heavily on ideas from [40] we present a solution that provides
nearly this degree of ease of use. Importantly, it even works for
effectful (monadic) host-language functions, like our plaintext-to-
ciphertext compiler (which creates random keys and hints during
its code transformations), via simpler interfaces and types than
in [40]:
lam
lamM
:: Lambda_ expr
=> (forall x . expr (e,x) a -> expr (e,x) b)
-> expr e (a -> b)
:: (Lambda_ expr, Functor m)
=> (forall x . expr (e,x) a -> m (expr (e,x) b))
-> m (expr e (a -> b))
double_ = lam $ \x -> var x +: var x
print $ double_ $: (3 *: 4)
-- (\v0 -> add v0 v0) (mul 3 4)
add_ = E $ \e -> \x -> \y -> x+y -- or: E $ pure (+)
neg_ = E $ \e -> \x -> negate x
Here E is an instance of Add_ only for types a that are instances
of the class Additive. This is necessary because E interprets add_
using Additive’s addition operator +. By contrast, P can inter-
pret add_ for any type a, because it just produces a string.
The instances of Mul_ are almost identical, except that we use the
constraint Ring a and its multiplication operator *. This also means
6A shorter definition is pair_ = E $ pure (,).
2.3 Generic Language Components
In the full version we give other general-purpose language com-
ponents that embed basic data types like lists and strings into the
object language. We also define language components for category-
theoretic abstractions like (applicative) functors and monads, which
can model fine-grained (side) effects in the object language. For