Passive DNS (PDNS) [69] captures trafﬁc by sensors coop-
eratively deployed in various DNS hierarchy locations. For
example, Farsight PDNS data [32] utilizes sensors deployed
behind DNS resolvers and provides aggregate information
about domain resolutions. In our research, we use Farsight
PDSN DB to extract PDNS related features for our classiﬁers.
Among other information, the PDNS DB contains a set of
summarized records for each FQDN. Each summarized record
contains the time of ﬁrst seen and last seen (i.e., timestamps
of the ﬁrst and the latest resolution of an FQDN), the number
of times the FQDN is queried, resolved IP addresses, and the
authoritative name servers. We can extract important hosting
features from the PDNS DB, as described in Section 5, to
train our classiﬁers.
USENIX Association
30th USENIX Security Symposium    3723
Figure 2: Overall Workﬂow of Labeling Malicious Websites
2.4 Other Blacklists/Scanners
In addition to VT, we further utilize four major blacklists
and reputation systems: Google Safe Browsing (GSB) [16],
Phishtank [51], Anti-Phishing Working Group (APWG) [3],
and McAfee Site Advisor (SA) [18]. While Phishtank only
focuses on phishing websites, the other three systems provide
a reputation on any type of malicious websites. Phishtank
and APWG maintain a list of manually veriﬁed phishing web-
sites. We utilize these websites’ results to manually label our
dataset as most of these blacklists provide additional textual
information about the details of the malicious activities on a
website.
2.5 Naive Approaches
After identifying and ﬁltering public domains, one of our
work’s primary goals is to categorize malicious websites as
hosted on compromised or attacker-owned apex domains. A
seemingly compelling approach is to take domain popularity,
such as Alexa ranking [22] into consideration. It is generally
understood that compromised domains have some residual
reputation and are long-lived, whereas attacker-owned do-
mains have a low reputation and are short-lived. However,
our analysis of the malicious websites in VT shows that such
observations do not always hold. While there are compro-
mised domains that have high Alexa ranking and long lifetime
(e.g., linode.com, cleverreach.com), a worrying fact we
observe is that there exist many other likely abandoned or
little maintained domains with low or no Alexa ranking (e.g.,
gemtown88.com, vanemery.com) that are compromised by
attackers to launch their attacks. Further, newly created benign
domains possess neither of the above properties, making them
likely mislabeled as attacker-owned when they are, in fact,
compromised. On the other hand, though it is certainly true
that many domains created by attackers are short-lived with
very low Alexa rankings, sophisticated attackers nowadays in-
creasingly utilize long-lived domains, for example, by creating
and parking those domains for a while (e.g., crackarea.com,
estilo.com.ec) to evade detection. Additionally, attackers
can artiﬁcially inﬂate the popularity of their domains, at least
Table 1: VT URL stats for the two datasets
Dataset
DS1
DS2
#scanners = 0
47,182,496
37,323,778
#scanners ≥ 1
7,330,850
9,797,649
#scanners ≥ 5
3,434,226
4,398,584
in the short term, without requiring much investment [58].
Therefore, relying on the popularity and/or lifetime alone
does not accurately classify compromised and attacker-owned
domains.
One may wonder whether VT reports contain sufﬁcient
information to classify the types of hosting domains. We ana-
lyze the features built from VT reports, and observe that only
with those features a classiﬁer could not achieve sufﬁcient
accuracy.
3 Overview
Figure 2 illustrates our overall workﬂow of labeling mali-
cious websites as hosted on public or private apexes, then as
compromised or attacker-owned for each category. We explain
each step in the workﬂow in detail.
3.1 VT URL Feed
VT URL scans issued from all over the world are aggregated
into hourly feed ﬁles. Our system pulls these hourly ﬁles,
parse them and build proﬁles for each apex/FQDN observed
over time (VT NOD/NOH). While we primarily utilize VT
URL feed as the input data source, one may utilize other
blacklists as the starting point as demonstrated in Section 6.1.
On average, there are 4.8M unique URLs each day in the VT
URL feed, out of which a vast majority (89.7%) are likely
benign ( #scanners = 0, i.e., none of the scanners mark them
as malicious). We select two different datasets, DS1 (Aug.
01, 2019 to Aug. 19, 2019) and DS2 (Oct 01 2019 to Oct 14
2019) that are temporally disjoint and of different window
sizes to train machine learning models on different datasets
and show their generalizability. Table 1 summarizes the VT
URL statistics of the two datasets.
3724    30th USENIX Security Symposium
USENIX Association
VT ReportParserMalicious URLFilter(#Scanners >= 5)Public/PrivateDomainClassiﬁerPublic DomainClassiﬁer Private DomainClassiﬁer Compromised DomainsAttacker OwnedDomainsCompromisedApexesAttacker OwnedApexesVT URLFeedPrivatePublicVTNOD/NOHTable 2: Malicious domain stats for the two datasets
Dataset
DS1
DS2
Malicious URLs
#public
1,669,033
2,137,711
#private
1,765,192
2,260,872
Malicious Apexes
#private
#public
369,758
3,480
3,195
355,567
3.2 Malicious URLs Filter
Out of all URLs marked by at least one scanner (i.e., #scan-
ners ≥ 1), we identify a subset of URLs that are highly likely
to be malicious for this study. In order to decide what thresh-
old of #scanners should be used to deem a URL malicious, we
take a random sample of 500 of these VT URLs and manually
check if they are malicious. Based on this experiment, we
identify that VT URLs with 5 or scanners assessing them as
malicious are highly likely to be malicious, which is in fact
reinforced by prior research ﬁndings [59, 68]. Thus, we set
the #scanners to 5 or more to extract malicious URLs for the
next stage of the pipeline.
3.3 Public/Private Domain Classiﬁer
Malicious URLs identiﬁed in the previous step are fed to
our public/private domain classiﬁer, which we describe in de-
tail in Section 5.1. This classiﬁer identiﬁes and labels URLs
hosted on public and private apex domains with high accu-
racy. Table 2 shows in each of the two datasets the number of
malicious (i.e. those with #scanners ≥ 5) public and private
URLs and the number of unique public and private apex do-
mains hosting these URLs. Notice that though the number of
unique public apex domains are low, the number of malicious
URLs they host is close to that of those hosted by private
apex domains, as each public domain hosts a huge number of
malicious URLs.
3.4 Private Apex Classiﬁer
In one of the two ﬁnal stages of the pipeline, we label the
identiﬁed private apex domains as either compromised or
attacker-owned. We train a machine learning model utilizing
features from several disparate sources, detailed in Section 5.2.
We achieve an accuracy of 96.4% with 99.1% precision and
92.6% recall. We extract the features for each URL under
consideration and feed them to the trained machined learning
model to predict its label.
3.5 Public Domain Classiﬁer
In this ﬁnal stage, we label identiﬁed public domains as either
compromised or attacker-owned. Even though some of the
features used in the private domain classiﬁer are not appli-
cable (e.g., those related to apex domains), with additional
content-agnostic features, we are able to achieve an accuracy
of 97.2% with 97.2% precision and 98.1% recall.
Figure 3: Daily Unique Scan and URL Counts from VT URL
Feed for all, #scanners = 0) and #scanners > 0
4 VT URL Feed Dataset and Its Characteris-
tics
In this section, we characterize and share insights into the
VT URL Feed dataset, which inspires us to design some of
the features used in our classiﬁers.
4.1 Daily Volumes
The VT URL Feed dataset contains 814,678,956 unique
URLs from Aug. 1, 2019 to Nov. 18, 2019. Figure 3 shows
the worldwide daily volume of unique scans and URLs in
VT during our study period. Note that the same URL may
be scanned multiple times in a given day. Each scan that
generates a report with a new scan ID is considered a different
one. However, if VT is simply queried multiple times only to
retrieve an existing report instead of triggering new scans, it
does not change the scan ID. Hence, such multiple reports
with the same scan ID are considered as one record. It is
interesting to note that the daily average of observed likely
benign scans (i.e., #scanners = 0) is 89.3% of the total number
of scans, which is around 4.8M. However, at the start of our
study period (weeks 3-4 and weeks 5-8), we see an interesting
spike in likely malicious scans and URLs (i.e., #scanners
> 0). We inspect the domains marked malicious during
this early period, and identify that 5 compromised domains
(gticng.com,
clinique-veterinaire-gembloux.be,
advancedimoveis.com, harikaindustries.co.in and
cos.pt) are used to host hundreds of thousands of malicious
javascripts that resulted in the spike. Excluding these outlier
domains, we observe that on average malicious URLs are
scanned 6 times during the above period while benign
URLs are scanned only twice. This follows the general user
behavior where the more suspicious the URLs are, the more
they are checked. Another interesting observation is that
the daily average scan count is roughly twice the average
URL count. We consider these observations when designing
features for our classiﬁers in Section 5.
Next, we assess the coverage of malicious websites in our
dataset compared to popular blacklists and reputation services.
USENIX Association
30th USENIX Security Symposium    3725
Figure 4: Weekly Unique Scan Counts with #scanners marked
URLs as Malicious
Figure 4 shows the weekly distribution of #scanners counts 1,
2, 3, 4, 5, and more than 5. While there are many VT reports
with 1 or 2 #scanners, on average, 45.7% among these scans
have 5 or more #scanners (i.e., the top two areas in the Figure).
In our work, we focus on categorizing scans with 5 or more
#scanners, which corresponds to 1659K weekly malicious
reports on average, or 276K malicious websites per week on
average, out of which 120K are newly observed. In compar-
ison, Google Transparency Report [17] and Phishtank [51]
report around 30K and 4K per week, respectively. This shows
that our study covers a much larger set of malicious websites
than popular blacklists and thus has a higher impact.
4.2 Attack Types
VT scanners assign each malicious URL one of the follow-
ing class labels: malicious, malware, phishing, mining, and
suspicious. Since VT scanners often assign conﬂicting class
labels, we use a simple majority voting heuristic to derive the
ﬁnal class label for a malicious website. We take a random
sample of 100 websites of each class type and manually cross-
check them against several publicly available blacklists or
APIs, including Phishtank, GSB and SA. Our manual inspec-
tion showed that more than 98% of the labels using majority
voting are in agreement with external intelligence, validat-
ing our heuristic. Figure 5 shows the count of attack types
of malicious URLs during our study period. While malware
and phishing dominate the reported malicious websites, there
are only a few malicious mining and suspicious websites in
our dataset. Hence, they are not shown in Figure 5. Further,
malware websites are approximately 3 times more prevalent
than phishing ones.
#FQDNs per Apex
4.3
Figure 6 shows the CDF of the number of FQDNs per apex
during our study period for likely benign domains (i.e. #scan-
ners = 0) and likely malicious domains (i.e. #scanners > 0).
Due to the highly skewed distribution, we omit the long tail
of those apexes with more than 500 FQDNs. 90.2% of the
Figure 5: Attack Types
Figure 6: #FQDNs per Apex
apexes in the benign category have only one FQDN whereas
only 12.3% of the apexes in the malicious category have only
one FQDN. Further, as shown in Figure 6, around 40% of
malicious apex domains have more than 40 FQDNs whereas
only 5% of benign apex domains have more than 40 FQDNs.
These observations show that attackers create many subdo-
mains to launch their attacks in a similar fashion as fast-ﬂux
networks [36, 53]. In Section 5.2, we proﬁle all VT reports
corresponding to each apex domain and utilize the variations
in the VT reports to design our compromised/attacker-owned
classiﬁer.
Another interesting observation is that there is a long tail
of apex domains having more than 500 FQDNs, with some
having millions. For example, blogspot.com (blogging),
coop.it (URL shortener), mcafee.com (mcafee endpoint
hosts) and opendns.com (Cisco open DNS) have over 1M
FQDNs. We use the number of FQDNs observed as a feature
in our public/private apex classiﬁer as the higher this number
is, the more likely the domain is public.
5 Construction of Classiﬁers
In this section, we describe the three classiﬁers that
we design, the public/private apex classiﬁer, the attacker-
owned/compromised private apex classiﬁer and the attacker-
3726    30th USENIX Security Symposium
USENIX Association
owned/compromised public website classiﬁer 1.
5.1 Public/Private Apex Domain Classiﬁer
The goal of this classiﬁer is to accurately predict if the apex
domains of malicious URLs are public or private.
5.1.1 Ground Truth Collection
We collect a tentative public domain ground truth data set
in three ways. First, we aggregate publicly available lists:
the public sufﬁx list [11], popular web hosting providers and
CDN lists [5,15], and dynamic DNS lists [6,9] and take the in-
tersection with apex domains in datasets DS1 and DS2, which
results in 439 apex domains. Second, we identify potential
public domains by searching over our datasets for the key-
words likely to be used by public apex domains such as host-
ing, free, web, share, upload, drop, cdn, ﬁle, photo, and proxy.
The manual inspection results in another 97 apexes. Third,
we take random samples of 500 apex domains from DS1 and
DS2 respectively and ﬁnd additional 26 public apexes through
manual inspection. Altogether, there are 562 unique public
apexes across the two datasets.
We collect a tentative private domain ground truth data
by randomly selecting 2000 apex domains from each dataset
(DS1 and DS2) that are mutually exclusive from the tentative
public dataset. We then do manual veriﬁcation to create the
ﬁnal ground truth sets: for each apex domain, we assign a con-
ﬁdence score between 50 and 100 to indicate how conﬁdent