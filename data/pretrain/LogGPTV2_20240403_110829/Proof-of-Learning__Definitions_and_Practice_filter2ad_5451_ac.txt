Require: V’s public key K pubV
Require: E, S, k (cid:46) Number of epochs, steps per epoch, checkpointing
interval
M0 ← ζ
W0 ← init(ζ)
I ← getBatches(D, S)
for s ← 0, . . . , S − 1 do
Optional: W0, ζ
1: W ← {}, I ← {}, H ← {}, M ← {}
2: if W0 = ∅ then
3:
4:
5: for e ← 0, . . . , E − 1 do
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17: A ← {M}
18: R ← enc((W, I, H, A), K pubV )
19: return R, h
t = e · S + s
Wt+1 ← update(Wt, D[Is], Mt)
I.append(It)
H.append(h (D[It]))
M.append(Mt)
if t mod k = 0 then
W.append(Wt)
W.append(nil)
(cid:16)R, K privT
(cid:17)
else
(cid:46) Initialization weight and strategy
(cid:46) Training epochs
(cid:46) steps per epoch
In Algorithm 1, we present
the concrete mechanism to
create PoL P(fWT ). W is a ﬂattened list of all recorded
weights across all epochs indexed by the proof step t. The
mapping from training step s to the proof step t is t = e·S +s,
where S is the number of training steps per epoch and e
is the epoch counter (of a total of E epochs). We only
append a weight Wt every kth step of the training, and
otherwise add ⊥ at that index. Observe that checkpointing
is commonly performed as part of training and adds limited
overhead (G5). k is a parameter which we call checkpointing
k is then the checkpointing frequency. Increasing
interval; 1
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:16:15 UTC from IEEE Xplore.  Restrictions apply. 
1043
k helps optimize storage costs (refer § V-D2). T may use
additional hyperparameters and optimizer speciﬁcations (e.g.,
learning rate schedules, etc.), which we denote as metadata
Mt (to be included in M). To make sure that weights in W
will be veriﬁed on the same data samples fWT was originally
trained on, we require that P(fWT ) include a signature of the
training data, i.e., h (D[It]) in H along with the data indices
which are themselves included in I.
In Algorithm 1, init() is a method that initializes the
weights according to an initialization strategy ζ before training
commencement. In scenarios where the initial model state is
obtained from elsewhere, we require that a PoL be provided
for the initial model state itself as well (see § V-D3). In
a similar vein, getBatches() randomly assigns a set of
data indices (over the entire dataset) to each batch. Thus, the
output of the method is a list of T sets of indices. Finally,
the method update() performs an update to the model
parameters using a suitable optimizer implementing one of
the variants of gradient descent as in Equation (1).
k |W| where |W| indicates
Storage Cost. The proof size is ES
the size of a set of model weights i.e., a single checkpoint
(G6). We note that if the prover would like to delay the veriﬁ-
cation until requested (see §V-D1) then they should maintain a
copy of the dataset, which adds |D| to the storage cost, where
|D| is the size of the dataset. Increasing the checkpointing
interval linearly decreases the storage cost, however this can
come at the cost of veriﬁcation accuracy (see §V-C). Storage
costs are discussed in detail in § VI-C4.
C. PoL Veriﬁcation
Algorithm 2 summarizes the veriﬁcation algorithm. Every
PoL starts from a set of weights either sampled from the
claimed initialization distribution, or from previously trained
model weights. In the latter case, the prover needs to pro-
vide a valid PoL for the pre-trained model weights, i.e., P 0
(referenced in encrypted form in Algorithm 2 as R0). In the
case of sampling from the claimed initialization distribution,
a statistical test is conducted to verify the claim. We discuss
these requirements and their importance in more detail in
§ V-D3 and § V-D4, respectively. After this initial veriﬁcation
step, we store the distance between each consecutive pair of
weights captured in W in a new list mag using d1 which is a
distance measure in a metric space (such as the p-norm). Once
every epoch, we sort mag to ﬁnd the largest model updates
which we verify using the VERIFYEPOCH procedure. To
verify, V loads up the index corresponding to the largest model
t. Next, V performs a series of k
update into its own model W (cid:48)
updates to arrive at W (cid:48)
t+k which is compared to the purported
t+k, Wt+k) ≤ δ, where
Wt+k in the PoL. We tolerate d2(W (cid:48)
d2 is a distance measure (possibly different from d1). δ is a
slack parameter that should be calibrated before veriﬁcation
starts, as it depends on hardware, model architecture, dataset,
checkpointing interval, and the learning hyperparameters. Al-
ternatively, acceptable ranges for δ may be mandated by law
and enforced by the veriﬁer. Since the purpose of δ is to upper
bound the randomness in training, one heuristic is to set δ as
the average of a few gradient updates during training. We note
at a new (cid:99)W (see § VII-C1), We assume that the veriﬁer V
that for an honest T who has obtained all intermediate model
weights, the particular choice of k is immaterial. Also since
δ is chosen to account for hardware and software tolerances,
Algorithm 2 will correctly verify such an honest proof (G1).
Why only verify the largest updates? We verify the largest
model updates because valid updates tend to have small mag-
nitude (to avoid overshooting during gradient descent), and
we want to save computational cost of V. More importantly,
any estimation error introduced by an adversary A wishing
to recreate a proof at a smaller computational cost would be
easier to detect for these large model updates. This may be
because the adversary tried to spoof a valid PoL by ﬁne-tuning
models at large learning rates for few epochs, or because they
attempt to spoof a PoL with signiﬁcant discontinuity to arrive
can verify at most Q · E largest updates (i.e., Q per epoch),
which we denote as V’s veriﬁcation budget. Similar to the
slack parameter δ, Q is also a veriﬁcation hyper-parameter
which should be calibrated, and can be mandated by law.
Time Complexity. The complexity of veriﬁcation is O(E·Q·
k·C|W|) where C|W| is the time-complexity of one update step
of the training loop with parameter size |W| (G3). Figure 7
in Appendix E shows a visualization of the bound.
Veriﬁcation Success. We deﬁne the veriﬁcation success rate
(VSR) of veriﬁer V on a PoL P as:
VSR (V,P(fWT )) := Pr[VERIFY[P(fWT )] = Success], (2)
where P(fWT ) = P(T , fWT ) = (W, I, H, A) and VERIFY
is a simpliﬁed notation for the same function in Algorithm
2. Veriﬁcation success can be described as the probability
that the veriﬁer accepts a PoL. Note that by nature of the
veriﬁcation Algorithm 2, the probability of acceptance by the
veriﬁer depends on the probability of:
1) W (cid:48)
t+k (i.e., calculated update from Wt by the veriﬁer)
achieved within a δ-ball of the purported weights Wt+k.
2) V obtaining W (cid:48)
Here, t = idx[q − 1], denotes the step with the qth largest
k-step update in the given epoch e. As the update for each t
in the veriﬁcation procedure is calculated separately and the
value of Wt is directly obtained, these events for different
values of t are independent. To ease the notation assume that
I is reindexed so that j is the index corresponding to the qth
largest update. We re-write Equation (2) with ‘Success’ as 1,
and φ = (I, H, M),
t+k from initial weights Wt in k steps.
Pr[VERIFY[W, φ] = 1] =
Q(cid:89)
E(cid:89)
E(cid:89)
Q(cid:89)
q=1
e=1
=
Pr[T re,q,k ∧ diste,q+k ≤ δ | φ]
Pr[diste,q+k ≤ δ | φ] · Pr[T re,q,k | φ],
e=1
q=1
where (a) diste,(q)+k = d2(W (cid:48)
e,(q)+k, We,(q)+k) denotes the
distance measurement, and (b) T re,(q),i := We,(q) ⇒ W (cid:48)
indicates the updates calculated by V of the i ≤ k steps in
the qth largest k-step update in epoch e and has achieved
W (cid:48)
e,(q)+i. We also have used the fact that the distance between
e,(q)+i
Authorized licensed use limited to: Tsinghua University. Downloaded on February 25,2022 at 12:16:15 UTC from IEEE Xplore.  Restrictions apply. 
1044
Algorithm 2 Verifying a PoL
1: function VERIFY(R,R0, K privV
W, I, H, M ← dec(R, K privV
if R0 = ∅ then
)
PoLs, V’s private key, model, dataset, query budget, slack parameter
, f, D, Q, δ)
(cid:46) encrypted
if VERIFYINITIALIZATION(W0) = FAIL then
return FAIL
return FAIL
else if VERIFYINITPROOF(R0) = FAIL then
e ← 0
mag ← {}
for t ← 0, . . . , T − 1 do
(cid:46) Epoch counter
(cid:46) List of model update magnitudes
(cid:46) training step
mag.append(d1(Wt − Wt−k))
if t mod k = 0 ∧ t (cid:54)= 0 then
S(cid:99)
et = (cid:98) t
if et = e + 1 then
(cid:46) Recovering the epoch number
(cid:46) New epoch started. Verify the last epoch
idx ← sortedIndices(mag,↓)
(cid:46) get indices for decreasing order of magnitude
if VERIFYEPOCH(idx) = FAIL then
e ← et, mag ← {}
return FAIL
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30:
31:
32:
33:
34:
return Success
function VERIFYEPOCH(idx)
for q ← 1, . . . , Q do
t = idx[q − 1]
Ht ← Ht, It ← It
VERIFYDATASIGNATURE(Ht, D[It])
t ← Wt
W (cid:48)
for i ← 0, . . . , k − 1 do
It+i ← It+i, Mt+i ← Mt+i
t+i+1← update(W (cid:48)
W (cid:48)
(cid:46) index of q’th largest update
t+i, D[It+i], Mt+i)
t+k, Wt+k) > δ then
(cid:46) Dist. func. d2
Wt+k ← Wt+k
if d2(W (cid:48)
return FAIL
return Success
the purported and the calculated updates is independent from
We,(q) ⇒ W (cid:48)
e,(q)+k. Additionally, due to the Markovian
nature of the gradient descent process (see § VI), the updates
⇒ W (cid:48)
W (cid:48)
e,(q)+i+1 are independent of each other. Com-
bining the last two factors, we have:
e,(q)+i
=
Q(cid:89)
E(cid:89)
VSR (V,P(fWT )) = Pr[VERIFY[W, φ] = 1]
Q(cid:89)
E(cid:89)
k−1(cid:89)
Pr[diste,(q)+k ≤ δ | φ]
Pr[diste,(q)+k ≤ δ | φ] · Pr[T re,(q),k | φ]
Pr[T re,(q)+i,1 | φ]
e=1
q=1
=
(3)
e=1
q=1
i=0
e,(q)+0 = We,(q), as V is given these
Note that in above W (cid:48)
weights, so no noise is introduced by reproduced computation.
We observe that decreasing the checkpointing interval or in-
creasing the query budget per epoch Q adds to the probability
terms in the product, therefore, if there is any uncertainty
regarding intermediate updates, their effect is compounded,
which in turn makes for a more stringent veriﬁcation process.
This comes at a trade-off with storage cost (see §V-B).
D. Practical Considerations
Here, we discuss practical considerations to be made when
implementing the mechanism we described so far.
1) Private Datasets & Lazy Veriﬁcation: So far we have
assumed that the dataset used to train a model is public,
so that V can use batch indices I in P(fWT ) to verify
model updates. It is also possible to use our PoL scheme for
private datasets. To do so, in addition to P(fWT ), T needs
to publish a signature of their datapoints h (D[It]) , It ∈ I
but not
the veriﬁcation can be
delayed until necessary (i.e., lazy veriﬁcation), at which time
T should reveal D[It] to V who additionally has to verify their
signatures with the published record.
the dataset. In this setup,
2) Amount of Data Needed: With lazy veriﬁcation, the
expected amount of data required to be transferred to the
veriﬁer V can be expressed as a function of S, E, k, and Q
(for simplicity here we assume Q is the same for all epochs).
Let ci denotes the Binomial random variable representing the
number of times data points i is sampled by VERIFYEPOCH
in Algorithm 2 (thus there are E trials). We assume each data
point is equally likely to be chosen such that in a certain trial