8.3  BPF Tools
299
bpftrace
The following is the code for the bpftrace version:
#1/usr/local/bin/bpftrace
include 
BEGIX
printf (**6s 16s Bs esn*, *PID*, *0oxH*, *AGE (ns)*, *FILE*)
kprobe:vfs_create,
kprobe:securi ty_inode_creste
Bbirth[argl] = nsecs
kprobe:vfs_un11nk 
/Bbieth [arg1] /
$dux = nsecs - Bbieth[argl]
delete (@birth(arg1]1=
$dentey = (struct dentry *)arg1;
printf (*46d 116s sBd 4s^n", pld, conm, $dur / 1000000,
str ($dent.ry=>d_name .name) 1 
Newer kernels may not use vfs_create(), so file creation can also be fetched via security_inode,
create(), the access-control hook (LSM) for inode creation (if both events occur for the same file,
then the birth timestamp is overwritten, but this should not noticeably affect the file lifespan
measurement). The birth timestamp is stored keyed on arg1 of those functions, which is the
struct dentry pointer, and is used as a unique ID. The filename is also fetched from struct dentry.
8.3.8 vfsstat
vfsstat(8)l# is a BCC and bpftrace tool to summarize statistics for some common VFS calls:
reads and writes (I/O), creates, opens, and fsyncs. This provides the highest-level workload
characterization of virtual file system operations. The following shows vfsstat(8) from BCC on a
36-CPU production Hadoop server:
+ vfsstat
TIME
READ/s
MRITE/s CREATE/s
OPEN/s
FSYKC/s
02 :41: 23 :
1715013
38717
5379
U
02 :41 :24 :
947879
E060E
Q
10547
15 Origin: 1 first created this for BCC on 14-Aug-2015 and for bpf
on 6-Sep-2018.
---
## Page 337
300
Chapter S File Systems
02 :41: 25 :
1064800
34387
57883
02:41:26:
115084T
0
36104
5105
D
02 :41 : 27 :
1281686
33610
31496
0
2703
 0
02 :41 : 28 :
1075975
口
6204
02 :41 : 29 :
868243
34139
0
5090
 0
02 :41 : 30 :
889394
31388
2730
02:41:31:
1124013
35483
0
8121
17:21 : 47:
11443
7876
507
D
[..]
This output shows a workload reaching over one million reads/second. A surprising detail is the
number of file opens per second: over five thousand. These are a slower operation, requiring path
name lookups by the kernel and creating file descriptors, plus additional file metadata structs if
they weren’t already cached. This workload can be investigated further using opensnoop(8) to
find ways to reduce the number of opens.
vfsstat(8) works by using kprobes for the functions: vfs_read(), vfs_write(), vfs_fsync0), vfs_open(),
and vfs_create(), and printing them as per-second summaries in a table. VFS functions can be very
frequent, as shown by this real-world example and, at rates of over one million events per second,
the overhead of this tool is expected to be measurable (e.g, 13% at this rate) This tool is suited for
axd hoc investigations, not 24x7 monitoring, where we’d prefer the overhead to be less than 0.1%.
This tool is only useful for the beginning of your investigation. VFS operations include file
systems and networking, and you will need to drill down using other tools (e.g., the following
vfssize(8)) to differentiate between them.
BCC
Command line usage:
vfsstat[interval[count|]
This is modeled on other traditional tools (vmstat(1)).
bpftrace
There is a bpftrace version of vfsstat(8) which prints the same data:
+1 /usr/local/bin/bpftrace
BEGIN
1
printf(*Tracing key VFs calls.., Hit Ctrl-C to end. n*1 ;
kprobe:vfs_read*,
kprobe:vfs_vrite*,
kprobe :vfs_fs ync,
kprobe:vfs_open,
kprobe:vfs_create
---
## Page 338
8.3 BPF Tools
301
e[func] = count(1
interval:s:1
t.ime () ;
print (81
clear (8) 
END
clear (81
This outputs every one second, formatted as a list of counts. Wildcards have been used to match
variants of vfs_read() and vfs_write(): vfs_readv(), etc. If desired, this could be enhanced to use
positional parameters to allow a custom interval to be specified.
8.3.9vfscount
Instead of these five VFS functions counted by vfsstat(8), you can count all of them (there are
over 50) and print a frequency count of their calls using the vfscount(8)1 tool in BCC and
bpftrace. For example, from BCC:
 vfscount
Tracing... Ctel-C to end.
^C
ACOR
FUNIC
COUNT
rfrrrrrrbe473d01 vfs_fallocate
ffffffffbe49d301 vfs_kern_mount
1
1
rffrffrfbs4bo8s1vfs_fsync_range
2
ffffffffbe487271 vfs_nknod
3
rfrrfrrfb487101 vfs_symlink
68
ffffffffbB488231 vfs_unlink
376
rfrrrrrfbe478161 vfs_vritev
525
ffffffffb8486d51 vfs_rmdir
638
rffrffrfbe487971 vfs_renane
T62
ffffffffbe4874cl vfs_nkdir
768
rfrrtrrbe4a2ds1 vfs_getxattr
894
ffffffffbeida761 vfs_lock_file
1601
rfrrffrfbs48cB61 vfs_readlink
60CE
16 Origin: Ifirst ereated this for BCC on 14-Aug-2015 and bpftrace on 6-Sep-2018.
---
## Page 339
302
Chapter S File Systems
ffffffffb8ab2451 vfs_statfs
18346
rfrerrcrbs475eal vfs_open
108173
ffffffffb847dbf1 vfs_statx_fd
193851
rffrffrfbe47dc71 vfs_statx
274022
fffffffbe47dbbl vfs_getattr
330689
rfrrrrrfbe47db2l vfs_getattr_nosec
99LTEE
ffffffffbe4790al vfs_vrite
355960
rfffffrfbe478dfl vfs_read
712610
While tracing, vfs_read() was most frequent with 712,610 calls, and vfs_fallocate() was called once.
The overhead of this tool, like vfsstat(8), can become noticeable at high rates of VFS calls.
Its functionality can also be implemented using funccount(8) from BCC, and bpftrace(8) directly:
 funccount *vfs_*'
(: ()qunco =[oung] e ) ga:eqoxdx,- eoexgdq +
Counting VFS calls like this is only useful as a high-level view, before digging deeper. These calls
can be for any subsystem that operates via VFS, including sockets (networking), /dev files, and
/proc. The fsrwstat(8) tool, covered next, shows one way to separate these types.
8.3.10 vfssize
vfssize(8) is a bpftrace tool that shows VFS read and write sizes as histograms, broken down by
:auas Idv uogonposd d-gp e tuou indno ajduexg ad6 so aureua[g sdA pue atueu ssaooud
Attach.ing 5 pzobes...
e[tomscat=exec=393, toncat_access,log] :
[8K, 16K)
31 18ee88e88e88 88ee8ee8ee8ee8ee88e88e88 88ee88e88e8ee881
[...]
[kafka-producer-, TCP] 
[4, B] 
2061 leeeeeeeee88ee8ee8ee8eeeeeeeeeeeeeeeeee8eeeeeeeeeeeee1
[8, 16}
0 1
[16, 32)
[32, 64)
2032 1869888 886 8888888988988988988988 888e88e88988981
9 [EVCACHE
FIF0] :
[1]
6376 leeeeeeeeeeeee8eeeeeeeeeeeeeeeeeeee8ee8eeeeeeeeeeeeee1
[..-]
1.7 0rigin: I created it for this book on 17-Apr-201.9.
---
## Page 340
8.3 BPF Tools
303
[gcpc-default-vo, TCP]:
[4, B]
101 |
[8, 16}
[16, 32)
8217 188e88e88e888 888e8ee8６e8ee8６e88e88e8
[32, 64)
7459 188988 88 888 88898898898898898898
[64, 128]
5488 188e88e88e888888e88e88e8
[128, 256}
2567 188988988988
[256, 512}
11030 eee88e8ee88e88ee8ee8ee8ee8ee8ee8ee88e88ee8eeee
[512, 1K]
9022 18 e88e88e88e 88ee8ee8ee8ee8ee88e888808
[18, 23]
6131 188e88e88e888888e88e88e86e8
[2K, 4K)
6276 1869889889886 886988986986988
[4K, 83)
88688881 1852
[8K, 16K]
95018898
[gcpc-default-vo, FIro] :
[1]
266897 1e8e88e88e888888e88e88e88e88e88e88e888888e88e88e8ee881
This highlights how VFS handles networking and FIFO as well. Processes named *grpc-default-wo*
(truncated) did 266,897 one-byte reads or writes while tracing: this sounds like an opportunity for
a performance optimization, by increasing the I/O size. The same process names also performed
many TCP reads and writes, with a bi-modal distribution of sizes. The output has only a single
example of a file system file, *tomcat_access.log,* with 31 total reads and writes by tomcat-exec-393.
Source for vfssize(8):
#1/usr/loeal/bin/bpftrace
include 
kprobe:vfs_read,
kprobe :vfs_readv,
kprobe:vfs_write,
kprobe :vfs_vr I tev
grile [tid] = argo;
kretprobe:vfs_read,
kzetprobe:vfs_readv,
kretprobe:vfs_write,
kzetprobe:vfs_writev
/8file [tid]/
if (retval >= 0) 
$nane = $file->f_path.dentry->d_nane -nane,
---
## Page 341
304
 Chapter S File Systems
if (f_inode>i_node >> 12)& 15)== DT_FIF0){
[conm, “FIFO*] = hlst {retva1)
)else ↑
[conm, str (Snane)] = hiat [zetval) :
1
delete (efile [tid]}
END
clear (8fi1e) :
This fetches the struet file from the first argument to vfs_readO, vfs_readv(, vfs_write(), and
vfs_writev0, and gets the resulting size from the kretprobe. Fortunately, for network protocols,
the protocol name is stored in the filename. (This originates from struct proto: see Chapter 10 for
more about this.) For FIFOs, there is nothing currently stored in the filename, so the text *FIFO°
is hardcoded in this tool.
vfssize(8) can be enhanced to include the type of call (read or write) by adding *probe* as a key,
the process ID (*pid°), and other details as desired.
8.3.11 fsrwstat
ndno adltuexg ad uass ag atg apnou os (g)essa aztuogsno oy mouq smous s(g)eqsmis
fsrwstat
Attach.ing 7 probes...
Tracing VFs reads and wrltes... Hit Ctl-C to end.
18 :29 : 27
[sockfs, vfs_vrite]: 1
e[sysfs, vfs_zead] : 4
[sockfs, vfs_read] : 5
e[devtnpfs, vfs_read] : 5T
[pipefs, vfs_vrite]: 156
e[pipefs, vfs_read] : 160
[anon_inodefs, vfs_read] : 164
e[sockfs, vfs_vritev]: 223
[anon_inodefs, vfs_write]: 292
e[devpts, vfs_write] : 2634
18 0rigin: 1 created it for this book on 1-Feb-2019, i
---
## Page 342
8.3 BPF Tools
305
[ext4, vfs_vrite] : 104268
e[ext4, vfs_read] : 10495
[. - -]
This shows the different file system types as the first column, separating socket I/O from ext4
file system I/O. This particular output shows a heavy (over 100,000 IOPS) ext4 read and write
workload.
Source for fsrwstat(8):
+1 /usr/locsl/bin/bpf trace
include 
BEGIN
printf(*Tracing Vrs reads and xrites... Hit Ctel-C to end.n*):
kprobe:vfs_read,
kprobe:vfs_resdv,
kprobe:vfs_vr1te,
kprobe:vfs_vritev
 [str (( lstruct file *) arg0) >f_inode=>i_sb>s_type>nane) , func] =
count (1 
interval:s11
1
t.ime I) : print (9) = clesr (8) =
1
END
clear (81
1
The program traces four VFS functions and frequency counts the file system type and the
function name. Since struct file * is the first argument to these functions, it can be cast from argo,
and then members walked until the file system type name is readl. The path walked is file > inode
-> superblock -> file_system_type -> name. Because it uses kprobes, this path is an unstable inter-
face, and will need to be updated to match kernel changes.
fsrwstat(8) can be enhanced to include other VFS calls, so long as there is a path to the file system
type from the instrumented function arguments (from arg0, or arg1, or arg2, etc.).
---
## Page 343
306
Chapter S File Systems
8.3.12
fileslower
fileslower(8)9 is a BCC and bpftrace tool to show synchronous file reads and writes slower than a
given threshold. The following shows fileslower(8) from BCC, tracing reads/writes slower than
10 milliseconds (the default threshold), on a 36-CPU production Hadoop server:
Tracing ayne
+ fileslower
read/vrites slowex than 10 ns
TIME (s)
COMM
T10
D BYTES
LAT (ns) FILEKAME
0.142
java
111264 R. 4096
25.53 part-00762-37a00f8d..
0,417
java
7122
R 65536
22.80 file,out.index
1,809
Java
70560R 8192
21.71 tenp_loca1_3c9f655b..
2,592
java
47861 ￥ 64512
10.43 b13_2191482458
2, 605
Java
58LL1
ZTSD9 
34.45 b1k_2191481297
4 , 454
java
47799￥ 64512
10.36 part-00762-37d00f8d..
24.84 b1k_2191482039
4.987
Java
111264 R. 4096
5, 091
java