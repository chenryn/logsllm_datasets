title:Analysis-Resistant Malware
author:John Bethencourt and
Dawn Song and
Brent Waters
Analysis-Resistant Malware
John Bethencourt∗
Dawn Song†
University of California, Berkeley / Carnegie Mellon University
Brent Waters‡
SRI International
Abstract
Traditionally, techniques for computing on encrypted
data have been proposed with privacy preserving applica-
tions in mind. Several current cryptosystems support a ho-
momorphic operation, allowing simple computations to be
performed using encrypted values. This is sufﬁcient to real-
ize several useful applications, including schemes for elec-
tronic voting [16, 12, 17] and single server private infor-
mation retrieval (PIR) [19, 9]. In this paper, we introduce
an alternative application for these techniques in an unex-
pected setting: malware. We point out the counterintuitive
possibility of malware which renders some aspects of its be-
havior provably resistant to forensic analysis, even with full
control over the malware code, its input, and its execution
environment. While methods for general purpose computa-
tion on encrypted data have not yet been realized, we ex-
plore the potential use of current techniques. Speciﬁcally,
we consider in depth the possibility of malware which em-
ploys private information retrieval techniques to ﬁnd and
retrieve speciﬁc pieces of sensitive information from com-
promised hosts while hiding its search criteria. Through an
evaluation of the goals of attackers and the constraints un-
der which they operate, we determine that PIR techniques
are an attractive technology to malware authors with the
potential to increase the threat of targeted espionage. We go
on to demonstrate the present feasibility of PIR-based mal-
ware through a series of experiments with a full implemen-
tation of a recent private stream searching scheme. Through
the example of PIR-based malware, we highlight the more
general possibilities of computing on encrypted data in a
malicious setting.
1
Introduction
Malware analysis is an important process which can help
guide an appropriate response to a security breach or re-
∗Supported by a US DoD NDSEG Fellowship and NSF CNS-0716199.
†Supported by NSF CNS-0716199.
‡Supported by NSF CNS-0524252, CNS-0716199, and the US Army
Research Ofﬁce under the CyberTA Grant No. W911NF-06-1-0316.
veal the motivations of the malware author. Currently, mal-
ware authors employ a host of methods to frustrate anal-
ysis, thereby extending the malware lifespan and conceal-
ing their aims. These analysis resistance techniques include
code obfuscation, self-checking and self-modifying code,
polymorphism, and metamorphism [11, 21]. A number of
worms speciﬁcally attempt to detect the presence of debug-
ging tools and alter or terminate operation [30]. These tech-
niques have triggered an arms race between increasingly
powerful analysis and reverse engineering tools [30] and
ever more clever techniques on the part of malware authors.
Despite the sophistication exhibited by many pieces of
recent malware, theoretical results suggest that malware au-
thors are ﬁghting a losing battle in this arms race. Secure
obfuscation for general programs is not possible due (at
least) to contrived classes of programs that are impossible
to obfuscate [2], and recent results have further shown that
many natural, interesting classes of programs are also im-
possible to obfuscate [14].
However, an alternative approach exists for malware to
hide certain aspects of its behavior. Several related crypto-
graphic notions known variously as public key program ob-
fuscation [22] and cryptocomputing [26] concern the trans-
formation of a program into an “encrypted” representation
that provably hides the function it computes while still al-
lowing execution of the program. The key difference in this
model is that the output of the encrypted program is unintel-
ligible to the party executing the program, and can only be
transformed into the actual output with the help of an auxil-
iary private key (kept by the originator of the program). The
negative results on program obfuscation do not apply in this
case, since they require an obfuscated program to produce
the same output as the original.
Unlike current methods [11] for program obfuscation,
which at best delay analysis, schemes within the public
key obfuscation model allow provable security. While gen-
eral purpose public key program obfuscation is an unsolved
problem and current methods for cryptocomputing are only
effective for small circuits, efﬁcient solutions to more spe-
cialized problems are available. In particular, a number of
schemes based on homomorphic encryption have been pro-
posed for the problem of single server private information
M
Menc
Menc
x1, x2, ...xk
K
M (x1, ...xk)
Menc(x1, ...xk)
Figure 1. Malicious usage of public key program obfuscation.
retrieval (PIR), which may be viewed as a special case of
public key obfuscation. A PIR scheme allows a client to
retrieve an entry xi from a database (x1, x2, . . . xn) on an
untrusted server while preventing the server from learning
which entry i they retrieved. This may be trivially accom-
plished by sending the entire database to the client, but PIR
√
schemes generally provide reduced communication com-
plexity (e.g., O(
n) or O(log n) rather than O(n)). Further
extensions and variations allow keyword based search and
retrieval of documents [10] and operation within a stream-
ing model [22]. From the malware author’s perspective,
such schemes may be useful for retrieving sensitive docu-
ments or system information by keyword while hiding the
search criteria. In this case, the malware author would play
the role of the client, and the compromised host would act
as the server.
Contributions.
In this paper, we introduce the general
threat of public key program obfuscation or cryptocomput-
ing techniques employed in a malicious setting, considering
in particular PIR-based malware as an example of currently
feasible techniques within this model. Speciﬁcally, we pro-
vide the following contributions.
• The introduction of the possibility of public key pro-
gram obfuscation techniques employed in a malicious
setting.
• A detailed evaluation of the goals of targeted malware
authors which suggests that PIR-based malware is at-
tractive for malicious purposes.
• The ﬁrst publicly released implementation of a pri-
vate stream searching system and experimental results
demonstrating its use is currently feasible.
• Additional results on the potential for distributed use
of PIR by worms.
Organization.
In Section 2 we discuss the general crypto-
graphic framework and tools available to a malware author,
including public key obfuscation, cryptocomputing, homo-
morphic encryption, and PIR. In Section 3 we explore the
goals of the malware author and evaluate the utility of PIR-
based malware in particular, and in Section 4 we give ex-
perimental results demonstrating the present technical fea-
sibility of PIR-based malware. In Section 5 we give a high-
level discussion of the implications of these possibilities and
countermeasures before concluding in Section 6. Related
work is given throughout, especially in Section 2. We also
give consideration to an additional, more speculative sce-
nario for malicious use of PIR in Appendix C; reading this
section is not essential for understanding the rest of the pa-
per.
2 Analysis Resistance via Cryptography
We now survey several cryptographic deﬁnitions and
tools and discuss how they may be used by malware authors
interested in preventing analysis of their malware.
2.1 Framework: Public Key Obfuscation
When deﬁning the problem of private stream search-
ing, Ostrovsky and Skeith also introduced the more gen-
eral problem of public key program obfuscation [22]. Infor-
mally, we may consider a scheme for public key obfuscation
to consist of a space of relevant programs C and two prob-
abilistic algorithms Compile and Decrypt. The Compile al-
gorithm takes a program A ∈ C and returns an “encrypted”
version Aenc along with a private key K. The Decrypt al-
gorithm processes an output from the encrypted program
using the private key to “decrypt” the output. We require
two properties:
Correctness
Let A ∈ C and (Aenc, K) = Compile(A). Then for all
x, we require that Decrypt(Aenc(x), K) = A(x).
documents, sniffed traffic,configuration files, etc.(not encrypted)local modifications to host(not encrypted)Malicious HostNetworkDecryptprivate keyencrypted outputCompileunencrypted output"encrypted" programmalware programCompromised HostHiding
In the absence of K, Aenc should reveal nothing about
A beyond that it is in C. More precisely, we deﬁne a
game between an adversary B and a challenger C.
them to C.
1. B chooses two programs A0, A1 ∈ C and sends
2. C ﬂips a coin b ∈ {0, 1}, computes (Aenc, K) =
3. B outputs a guess b0.
Compile(Ab), and sends Aenc to B.
We deﬁne the advantage of an adversary B as a func-
tion of the security parameter k (elsewhere omitted
from the notation) to be AdvB(k) = |Pr(b = b0) − 1
2|.
We require that AdvB(k) be a negligible function for
all PPT’s B.
Note that in order for the hiding property to be satisﬁed, it
is essential that Compile be a probabilistic algorithm with
many potential encrypted representations for each program.
For more rigorous deﬁnitions the reader should refer to [22];
these intuitive notions will sufﬁce for our purposes. The in-
terested reader may also wish to review the largely equiva-
lent notion of cryptocomputing [26].
Example. This framework is depicted in a malicious con-
text in Figure 1. Here, M ∈ C is a piece of malware that is
encrypted to produce Menc, which is run on a compromised
machine. The algorithm Compile hides certain character-
istics of M; namely, those that distinguish it from other
members of C. However, in the process the output is ren-
dered unusable. This output Menc(x1, . . . xn) must now be
returned to the malware author and given to Decrypt along
with K before the actual output M(x1, . . . xn) may be dis-
cerned. Note that Menc may also be permitted to produce
some unencrypted outputs, provided every other member of
C produces them in the exact same way.
As an example, one may imagine M to be a host-based
vulnerability scanner. The program M inspects various as-
pects of the host’s conﬁguration, then processes this infor-
mation according to a list of rules for detecting various soft-
ware and conﬁguration vulnerabilities, ultimately produc-
ing a concise summary of the resulting discoveries. In this
case, the malware author may wish to hide the scanning cri-
teria and vulnerability detection logic to ensure the contin-
ued secrecy of valuable 0-day vulnerabilities.
Discussion.
It is important to remain clear on the relation-
ship between C, the output and behavior of Menc, and pre-
cisely which characteristics of M are hidden. In the exam-
ple of the vulnerability scanner, an analyst observing Menc
will certainly see which data x1, . . . xn it reads on the re-
mote host. The best we can do, then, is to take C to be the
set of programs which read this data, perform some compu-
tation, and return resulting values (of a particular size) over
the the network, and then we will hide the nature of the
computation which M performs. This ability could be sur-
prisingly useful. If x1, . . . xn is an extremely large, general
set of inputs (e.g., the contents of all program binaries, li-
braries, the kernel, conﬁguration ﬁles, and sniffed network
trafﬁc), the malware analyst observing Menc will have es-
sentially no information about the vulnerabilities the mal-
ware may have been looking for. If M had run, however,
the analyst would ﬁnd the same vulnerabilities on the sys-
tem that M had, and be able to respond by patching them. In
general, one should keep in mind that it will not be possible
to hide any characteristics of the malware that inherently
must affect its control ﬂow or output that is not to be re-
turned to the author (i.e., local changes to the compromised
host).
Another point to understand is that a scheme for pub-
lic key obfuscation provides malware with genuinely new
abilities, beyond what is possible through other approaches.
One may imagine malware taking the more simplistic ap-
proach of reading its inputs and performing the necessary
computations in the clear, then encrypting the output with
an embedded public key before sending it over the network.
The source of the malware (who has the corresponding pri-
vate key) would be able to decrypt the returned output. In
this case, the output of the malware would be hidden from
anyone monitoring the network. However, this approach
does nothing to prevent an analyst with access to the host
on which the malware is running from observing what it is
computing and sending back. A malware author who in-
tends to hide the information they seek and how it is to be
derived from data on the compromised host must assume
that the malware’s code and execution environment will be
analyzed upon detection.
2.2 Present Techniques: Homomorphic Encryp-
tion
Public key obfuscation schemes for fully general classes
of programs C do not yet exist. However, methods are avail-
able for more specialized classes. We now discuss these
methods and what may be accomplished using them.
Essentially all work in this framework so far has been
based upon the use of homomorphic cryptosystems. Sup-
pose for some public key cryptosystem we have a space of
plaintexts P , a space of ciphertexts C, and an encryption
function (for a particular public key) E : P → C. Then
we say that the cryptosystem supports a homomorphism
f : P n → P if there exists an operation f0 : C n → C
such that
f0(E(x1), E(x2), . . . E(xn)) = E(f(x1, x2, . . . xn))
for all x1, . . . xn ∈ P . More precisely, we should say that
D(f0(E(x1), E(x2), . . . E(xn))) = f(x1, x2, . . . xn) ,
since E will typically be a probabilistic function. Here D :
C → P is the private decryption algorithm corresponding
to E.
Such a homomorphism allows one to perform the opera-
tion f on encrypted values and obtain an encryption of the
result, thus enabling computation on encrypted data. This
provides the essential building block for realizing schemes
in the framework of public key obfuscation. Generally
speaking, the algorithm Menc may encrypt its input values
with an embedded public key, and then perform its compu-
tations by using an operation f0 : C k → C on them along
with (already encrypted) embedded constants.
Several cryptosystems support a single homomorphic
group operation,
including ElGamal [13], Goldwasser-
Micali [15], and Paillier [25]. The more sophisticated cryp-
tosystem of Boneh, Goh, and Nissim supports arbitrary ad-
ditions of plaintexts and a single multiplication [6]. Un-
fortunately, no known cryptosystem supports homomorphic
operations that are sufﬁcient to realize general computa-
tion on encrypted data [24]; ﬁnding such a cryptosystem
or demonstrating that they do not exist is a long standing
and important open problem. A notable partial exception
is the scheme of Sander, Young, and Yung, which supports
both boolean OR and NOT, which are sufﬁcient for general
computation [26]. However, in this scheme the ciphertext
size doubles after every operation, so only small numbers
of operations are feasible.
Cryptosystems supporting a single homomorphic group
operation are, however, sufﬁcient for a number of useful
applications. In particular, they are sufﬁcient to solve the
√
problem of private information retrieval. As an example, we
give in Appendix A a simple PIR scheme with O(
n) com-
munication complexity using a generic construction given
in [23], instantiated with the Paillier cryptosystem. The
example serves to illustrate the usage of homomorphic en-
cryption and shares the ﬂavor of more advanced construc-
tions for PIR. Readers that have not previously seen a con-
struction for PIR may ﬁnd it enlightening. The example
also provides a more concrete illustration of the deﬁnitions
for public key program obfuscation.
More sophisticated approaches to PIR allow search
based on keywords rather than array indices [10] and
operation on a sequence of documents with no a priori
bound [22], dubbed private stream searching. Throughout
the rest of the paper, we will generally assume the use of
a scheme for keyword based private stream searching, as
this variant of PIR offers more ﬂexibility. A query will then
take the form of a list of keywords rather than an index i,
and we will assume that it can be matched against an ar-
bitrary number of documents one by one, updating a ﬁxed
length, encrypted buffer of current results after each.
2.3 Properties Offered
In both the general case of public key obfuscation and
the speciﬁc problem of PIR, it is possible to trivially achieve
the hiding property by simply retrieving the entire set of in-
puts x1, x2, . . . xn and running the original program M lo-
cally on the machine of the malware author. The only use-
ful schemes for public key obfuscation are then those that
reduce the communication to something closer to the size
of the actual output M(x1, . . . xn). What such a scheme
offers, then, is the combination of two properties: low com-
munication and program hiding. Either one may be trivially