has made this technique ineffective, unless the entire IP
ranges of such platforms are banned; new IP addresses can
be easily obtained, e.g. by restarting instances on Amazon
EC2.
it
B. Efﬁcient harvesting of Tor HS descriptors
It is of a particular interest
to collect the descriptors
of all hidden services deployed in Tor. We will show
how an attacker can use this collection to opportunistically
deanonymize any hidden service which chose one of the
attacker’s nodes as one of its entry guards. The IP addresses
of these hidden services can be revealed in a matter of
seconds using a trafﬁc correlation attack, as we will show
later.
It is clear that an attacker can operate several hidden
service directories and collect hidden service descriptors
over a long period of time. However, since there were more
than 1200 hidden service directories at the time of this
writing it can take the attacker signiﬁcant amount of time to
collect enough hidden service descriptors.
To collect the descriptors of all hidden services in a short
period of time, a na¨ıve attack requires to run many Tor relays
from a non-negligible number of IP addresses. Assume that
a hidden service descriptor’s ID falls into some gap8 on the
ﬁngerprint circle. The hidden service uploads its descriptor
to the three hidden service directories with the next greater
ﬁngerprints. This means that each hidden services directory
receives descriptors with identiﬁers falling into two gaps
preceding the hidden service directory’s ﬁngerprint. This in
turn means that the attacker needs to inject a hidden service
directory into every second gap in the ﬁngerprint circle
to collect all hidden service descriptors. Thus she would
need to run more than 600 Tor relays for 27 hours. This
requires more than 300 IP addresses, given that the attacker
is allowed to run only 2 Tor relays on a single IP address.
However, given the observations in the previous section,
we can collect the hidden service descriptors much more
efﬁciently. In this subsection, we show how to reduce the
number of IP addresses to approximately 50 (depending on
the exact number of hidden service directories in the con-
sensus). Our approach is based on shadow relays described
in the previous section. An attacker can use this artifact of
Tor’s design as follows. She can rent 50 IP addresses and
run 24 relays on each of them for 25 hours thus running
1200 Tor instances in total; 100 of them should appear in
the consensus. The ﬁngerprints of the public keys of the
relays should fall into every second gap in the ﬁngerprint
circle. At the end of 25 hour time period all of the relays
will have HSDir ﬂags but only 100 of them will appear in
the consensus and the rest will be shadow relays. The idea
is to gradually make active relays unreachable to the Tor
authorities so that shadow relays become active and thus
gradually cover all gaps in the circular list during 24 hours.
It should be noted that the descriptor IDs of hidden ser-
vices (and hence the responsible hidden service directories)
change once per 24 hours and the time of the day when
they change can be different for different hidden services.
Since each hour the attacker covers only a fraction of the
gaps on the ﬁngerprint circle, the location of the descriptor
can change from a gap not yet covered by the attacker to a
gap already covered. Thus, if the attacker makes only one
pass over the ﬁngerprint circle during the day, she may not
catch some descriptors. It will not happen if the attacker
makes two passes during the day. Those descriptors location
of which changed during the ﬁrst pass to already covered
gaps will be collected during the second pass (since they
can change the location once per 24 hours only).
Another important point is that consensus document re-
mains valid for a client for 3 hours, starting from its publi-
cation. According to the current implementation the clients
can download the new consensus in (FU + 45 mins;VA
- 10 mins) interval. Hence a hidden service can skip the
consensus document which immediately follows its current
consensus. This means the hidden service directories of the
7Note that this countermeasure is not implemented in Tor, however.
8A gap is deﬁned to be an interval in the circular list of ﬁngerprints
between two consecutive HS directories
86
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:51:23 UTC from IEEE Xplore.  Restrictions apply. 
attacker should be in at least two consecutive consensus
documents in order for the hidden service to learn about
them.
Taken into account the aforementioned the attacker would
12∗2 IP addresses, where N is the
need to control R = N
number of hidden service directories in the Tor network.
Note that all the relays run by the attacker can be cheap
since they do not have to provide high performance. Thus
the attacker will have to pay only for the additional IP
addresses and very little for the trafﬁc. The IP addresses
can be acquired from Amazon EC2 accounts. This results
in a low-resource attack.
C. Experimental results
We performed the attack using 50 EC2 virtual instances.
During the experiment we received 59130 publication re-
quests for different descriptor IDs. We also fetched the
descriptors from the memory of running Tor instances and
obtained 58389 descriptors in total9. Out of them there were
24703 descriptors with unique public keys. The fraction of
encrypted descriptors among them was approximately 1.5%.
When computing onion addresses from the descriptors,
we found the botnet C&C addresses, DuckDuckGo’s hidden
service and the Silk Road onion address in that set – as
expected. However, we also found what looked like backup
or phishing onion addresses for Silk Road, namely onion
addresses with the same 8 letter preﬁx:
silkroadrlzm5thj.onion
silkroadvb5piz3r.onion
silkroadvlsu5apk.onion
silkroad5hq52m36.onion
not
able
to
We
were
to
however
silkroadrlzm5thj.onion,
and
both
to
silkroad5hq52m36.onion
silkroadvb5piz3r.onion which is an onion-address for
Silk Road that is publicly known.
silkroadvlsu5apk.onion
redirected
connect
us
In order to verify the completeness of the harvested data
we collected a sample of 120 running hidden services from
public sources. Our data set missed 4 relays from this sample
set. By extrapolating this result we conclude that we could
have lost about 3% of hidden descriptors.
We launched a second experiment on another date in order
to reduce the costs of the attack. Because of the increased
number of hidden services directories on that date, we used
58 EC2 instances. We also used an improved harvesting
script: in addition to storing descriptors posted by hidden
services we also initiated descriptors fetches from other
responsible hidden services directories if a client’s request
was received for an unknown descriptor. At the end of the
experiment we collected 39824 unique onion addresses.
9Note that we fetched the descriptors from memory 3 hours after the
end of the experiment. This means that by that time some of our Tor relays
removed a small portion of the descriptors from their memory
In order to reduce the experiments’ costs we used the
following. First both shadow and active relays had reported
bandwidth of 0 Bytes/sec or 1 Bytes/sec. Since the granular-
ity of the bandwidth values in the consensus is 1 kBytes/sec,
all relays used in our attack were assigned bandwidth 0
kBytes/sec in the consensus. This means that the relays used
in the attack should never be chosen by clients for purposes
other than hidden services descriptors fetches. This has cut
the trafﬁc costs expenses. Secondly, we launched Tor relays
participating in the harvesting from cheaper EC2 instances.
In the second experiment, we used EC2 micro instances
which is the cheapest option. In combination with reductions
in trafﬁc costs, this allowed us to reduce the overall price
down to 57 USD.
Falling back to micro instances created performance prob-
lems however. Due to limited amount of RAM, at the end
of the experiment, we could not establish SSH connections
to some of EC2 instances and we had to reboot them to
retrieve the data. The log ﬁles indicated that system clock
jumped for several times which means that we could loose
some hidden services descriptors.
This experiment had inadvertent but important side-effect
on the ﬂag calculation of Tor, of which we were notiﬁed by
the Tor developers; see the Appendix for more details.
VI. OPPORTUNISTIC DEANONYMISATION OF HIDDEN
SERVICES
The fact that an attacker always controls one side of
the communication with a hidden service means that it is
sufﬁcient to sniff/control a guard of the hidden service in
order to implement a trafﬁc correlation attack and reveal
the actual location of the hidden service. In particular, an
attacker can:
• Given the onion address of a hidden service with
unencrypted list of introduction points determine if her
guard nodes are used by this hidden service.
• Determine the IP addresses of those hidden services
that use the attacker’s guard nodes.
• Determine if the attacker’s guard nodes are used by any
of the hidden services, even if the list of introduction
points is encrypted.
A. Unencrypted descriptors
In order to conﬁrm that an attacker controls a guard
node of a hidden service she needs to control at least one
more Tor non-Exit relay. In the attack, the hidden service is
forced to establishes rendezvous circuits to the rendezvous
point (RP) controlled by the attacker. Upon receiving a
RELAY_COMMAND_RENDEZVOUS1 cell with the attacker’s
cookie, the RP generates trafﬁc with a special signature.
This signature can be identiﬁed by the attacker’s middle
node. We note that a special PADDING cell mechanism in Tor
simpliﬁes generation of a signature trafﬁc which is discarded
at the recipient side, and is thus unnoticeable to the hidden
87
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:51:23 UTC from IEEE Xplore.  Restrictions apply. 
service. The steps of the attack are shown in Figure 5 and
are as follows:


















  !"
	


	


Figure 5. Revealing the guards
• The attacker sends a RELAY_COMMAND_INTRODUCE1
cell to one of the hidden service’s introduction points
(IP) indicating the address of the rendezvous point.
• The introduction point
in a
RELAY_COMMAND_INTRODUCE2 cell to the hidden ser-
vice.
forwards the content
• Upon receiving the RELAY_COMMAND_INTRODUCE2
cell,
the hidden service establishes a three-hop cir-
cuit to the indicated rendezvous point and sends it a
RELAY_COMMAND_RENDEZVOUS1 cell.
• when the rendezvous point controlled by the attacker
receives the RELAY_COMMAND_RENDEZVOUS1 cell, it
sends 50 PADDING cells back along the rendezvous
circuit which are then silently dropped by the hidden
service.
Whenever
rendezvous
• the rendezvous point sends a DESTROY cell down the
rendezvous circuit leading to the closure of the circuit.
a
RELAY_COMMAND_RENDEZVOUS1 with the same cookie as
the attacker sent in the RELAY_COMMAND_INTRODUCTION1
cell it logs the reception. At the same time, the attacker’s
the circuits passing through it.
guard node monitors
Whenever it receives a DESTROY cell over a circuit
it
checks:
receives
the
point
1) whether the cell was received just after the rendezvous
point received the RELAY_COMMAND_RENDEZVOUS1
cell;
2) the number of the forwarded cells: 3 cells up the
circuit and 53 cells down the circuit. Three cells
more come from the fact
the hidden ser-
vice established a circuit
to the rendezvous point
the attacker’s guard node had to forward
thus
(2×RELAY_COMMAND_EXTEND + 1×RENDEZVOUS1)
cells up and (2×RELAY_COMMAND_EXTENDED +
1×DESTROY) cells down. This is very important for
that
our trafﬁc signature since it allows us to distinguish
the case when the attacker’s node was chosen as the
guard from the case when it was chosen as the middle.
If all the conditions are satisﬁed, the attacker decides
that her guard node was chosen for the hidden service’s
rendezvous circuit and marks the previous node in the circuit
as the origin of the hidden service.
In order to estimate the reliability of the trafﬁc signature,
we collected a statistics on the number of forwarded cells
per circuit. We examined 748,846 circuits on our guard node.
None of the circuit exhibited the trafﬁc pattern of 3 cells up
the circuit and 53 cells down the circuit. This means that
the proposed trafﬁc signature is highly reliable.
We implemented the approach to attack our own hidden
service. We used a relay with a bandwidth of 500 Kbytes/s
according to the consensus as the guard node and were
scanning for the aforementioned trafﬁc signature. For each
RELAY_COMMAND_RENDEZVOUS1 cell receive events we col-
lected the corresponding trafﬁc pattern and got no false
positives.
B. Encrypted descriptors
If the list of introduction points is encrypted, an attacker
will not be able to establish a connection to the hidden
service. Hence the attack described in the previous section
does not apply. However, we can use a different method to
determine if some of those encrypted hidden services use a
guard node controlled by us. We will not be able distinguish
between hidden services with encrypted introduction points
though. On the other hand, note that results from Section
V show that the number of hidden services which encrypt
their introduction points is comparatively small.
To achieve this goal we do the following:
• On our guard node we look for a trafﬁc pattern charac-
teristic for introduction circuits (we describe this trafﬁc
pattern and how unique it is later in this section).
• We discard introduction circuits which originate at the
same IP address as any of the hidden services with
unencrypted descriptors.
• For all remaining introduction circuits, we mark their
origins as possible locations of an encrypted hidden
services.
Let us describe the characteristics exhibited by introduc-
tion circuits: The main difference between general-purpose
circuits and introduction circuits is their duration. General
Tor circuit stays alive either for ten minutes (if they were
used by any stream), for one hour (if they did not carry
any data trafﬁc) or as long as any trafﬁc is carried over
them (this implies an open stream). In contrast, introduction
circuits stay alive much longer, namely until some hop in
the circuit fails or the hidden service closes the connection.
The second important difference is that after an introduc-
tion circuit is established, it does not transmit cells from the
88
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 11:51:23 UTC from IEEE Xplore.  Restrictions apply. 
origin. On the other hand, general-purpose circuits usually
transmit trafﬁc back and forth.
Thirdly, we can use the fact that introduction circuits are
always multi-hop while some general-purpose circuits are
one-hop.
In order to check how good these ﬁlters are, we launched
a hidden service which established two introduction circuits
through a non-guard relay controlled by us. By collecting
the circuit statistics on this node for 24 hours we were
able to identify our introduction circuits while having no
false positives. We also did measurements on our guard
node during 24 hours and identiﬁed 14 potential introduction
circuits. However, we did not check if they belonged to
hidden services with unencrypted introduction points.
C. Success rate and pricing for targeted deanonymizations
In early 2012 we operated a guard node that we rented
from a large European hosting company (Server4You, prod-
uct EcoServer Large X5) for EUR 45 (approx. USD 60) per
month. Averaging over a month and taking the bandwidth
weights into account we calculated that the probability for
this node to be chosen as a guard node was approximately
0.6% on average for each try a Tor client made that month.
As each hidden service chooses three guard nodes initially,
we expect over 450 hidden services to have chosen this node
as a guard node10. Running these numbers for a targeted
(non-opportunistic) version of the attack described in Section
VI-A shows us that by renting 23 servers of this same type
would give us a chance of 13.8% for any of these servers to
be chosen. This means that within 8 months, the probability
to deanonymize a long-running hidden service by one of
these servers becoming its guard node is more than 90%,
for a cost of EUR 8280 (approximately USD 11,000).
Take into account that this scales well: Attacking multiple
hidden services can be achieved for the same cost once the
infrastructure is running.
VII. REVEALING GUARD NODES OF HIDDEN SERVICES
As mentioned in the background section, each hidden
service keeps a list of guard nodes. Revealing the guards
does not immediately allow an attacker to reveal the location
of the hidden service but gives her the next point of attack.
This can be dangerous for a hidden service since it
is
supposed to be online for a long11 time. This gives an
attacker sufﬁcient amount of time either to take control over
the guard nodes or to start snifﬁng network trafﬁc near the
guards. Given that guard nodes are valid for more than a
month, this may also be sufﬁcient to mount a legal attack to
recover trafﬁc meta data for the guard node, depending on
the jurisdiction the guard node is located in.
In this section we present an attack to reveal the guard
nodes of a hidden service when the list of the introduction
10Assuming the current number of hidden services
11Silk Road’s hidden service is already running for almost two years.
points in the HS descriptor is not encrypted (for the case
when the list of introduction points in encrypted see Ap-
pendix B).
To do this, we use a technique similar to that presented
in section VI; control over at least two Tor non-Exit relays
is needed to carry it out. In the attack, the hidden service
is forced to establishes many rendezvous connections to the