licious (but non-cooperative with respect to the server).
803Setup and inputs: Each party Pi has an mi-bit input while the server has no input. Let m =Pi∈[n] mi. The server S holds a
secret key K for a pseudo-random function F . s is a statistical security parameter. C is the circuit that computes f .
Distributed OT :
For all ℓ ∈ [s1]:
1. S computes rℓ := FK (ℓ). All the coins used by S for the ℓth circuit will be derived from rℓ,
2. S computes Wℓ := GI(m; rℓ) and for all i ∈ [m], (σ0
n,i) ← Share(n, w0
i ) and (σ1
1,i, . . . , σ0
1,i, . . . , σ1
n,i) ← Share(n, w1
i ),
3. S then samples a n × m binary matrix Pℓ uniformly at random and generates the n × m matrix Sℓ deﬁned as:
Sℓ =
ij(cid:19),
Pℓ
ij , v1−Pℓ
where Pℓ
ij(cid:2)v0, v1(cid:3) def
= (cid:18)v
Pℓ
11(cid:20)σ0
n1(cid:20)σ0
1,1, σ1
.
..
n,1, σ1
1,1(cid:21)
n,1(cid:21)
Pℓ
. . .
. . .
Pℓ
1m(cid:20)σ0
nm(cid:20)σ0
Pℓ
.
..
1,m(cid:21)
n,m(cid:21)
,
1,m, σ1
n,m, σ1
4. S then constructs the n × m matrix Cℓ such that Cℓ
the ath element of the pair stored at location ij of Sℓ,
ij =(cid:18)Com(cid:0)Sℓ
ij [1](cid:1), Com(cid:0)Sℓ
ij[2](cid:1)(cid:19), where Sℓ
ij[a] for a ∈ {1, 2} denotes
5. for all i ∈ [n],
(a) S sends the ith rows of Sℓ and Cℓ and the associated decommitments to Pi,
(b) if the decommitments are invalid Pi accuses S and aborts,
(c) for all j ∈ inp(Pi), S sends the jth column of Pℓ to Pi,
6. S sends to all parties Qℓ
0 := Com(ω0
ℓ ) and Qℓ
1 := Com(ω1
ℓ ), and, H(ω0
ℓ ) and H(ω1
ℓ ) permuted in a random order, where
(ω0
ℓ , ω1
Cut-and-choose :
ℓ ) := GO(rℓ).
1. For all ℓ ∈ [s1], S sends eCℓ := GC(C; rℓ) to P1.
$
← [s1] to S.
2. P1 sends e
3. S sends {ri}i∈[s1]−e to P1 who in turn sends it to all the parties.
4. All parties verify that all the values received from S in the previous steps were constructed properly from the appropriate
randomness. If not, they accuse S and abort.
Input label reconstruction for Pi :
For all j ∈ inp(Pi)
1. for all i′ 6= i:
(a) Pi sends bi′ j := xj ⊕ Pe
i′j [bi′j ] (recall that Pi′ received the i′th row from S in step 5(a) of th distributed OT phase).
(b) Pi′ returns Se
xj
j using the n shares obtained in the previous steps.
i′ j to P ′
2. Pi reconstructs w
i
Commitment consistency check :
For all i ∈ [n], j ∈ inp(Pi) and i′ 6= i:
1. S sends Ce
i′j to Pi,
2. Pi and Pi′ check that they have the same commitments (simply by sending them to each other). If not, they accuse S
and abort. More precisely:
(a) for all j ∈ inp(Pi) ∪ inp(Pi′ ) they check that they both received the same commitments Ce
ij or Ce
i′ j (depending on
who owns wire j),
(b) they check that they received the same Qe
0 and Qe
1,
3. Pi′ sends to Pi decommitments to Ce
i′j [bi′j ]. If any decommitment is invalid, Pi accuses Pi′ and aborts.
Garbled circuit evaluation :
1. All the parties send their input labels for eCe to P1.
2. P1 evalautes eCe and returns the garbled output z to all the parties.
Revealing the output :
1. Each party Pi computes a hash of z and veriﬁes that it matches one of the two hashes H(ω0
e ) and H(ω1
e ) the server
sent earlier. If so, it sends an ACK message to the server.
2. After receiving an ACK messages from all players, S sends the decommitments to Qe
0 and Qe
1 to all parties.
3. Using the decommitments and z, each party can determine the output bit.
Figure 1: Protocol 1 - Covert Server
804Setup and inputs: Each party Pi has an mi-bit input while the server has no input. Let m = Pi |mi|. All the parties share a
secret key K. s and λ are statistical security parameters.
Setup shared randomness :
1. For all ℓ ∈ [s], the players compute rℓ = FK (ℓ) (these will be used to garble s circuits).
2. The players compute γ0 := FK (s + 1) and γ1 := FK (s + 2) (these will be used to decode the ﬁnal output).
Circuit Garbling :
For all ℓ ∈ [s], P1 sends eCℓ := GC(C; rℓ) to S.
Garbled Circuit Veriﬁcation :
1. S picks a set T ⊂ [s] of size s − λ at random, and sends T to P1.
2. P1 sends to rℓ for all ℓ ∈ T , to S.
3. For all ℓ ∈ T , S checks that eCℓ was created using rℓ. If so, it sends rℓ to all the parties who verify that it is equal to
the randomness they computed earlier.
Input label transfer :
Let E = [n] − T be the set of indices of non-veriﬁed circuits. Each party Pi computes Wℓ := GI(m; rℓ) for all ℓ ∈ E. It then
sends all its input labels to S. Denote by wℓ,j the label S receives for the jth input wire of the ℓth circuit.
Input label consistency check :
For j ∈ [m]:
1. All the players send the hash values hw,b = H(wb
ℓ1 ,j| · · · |wb
ℓλ,j) for b ∈ {0, 1} in a random order, where ℓ1, . . . , ℓλ ∈ E.
2. S checks that it receives the same hash values from all the players.
3. S checks that one of the hashes equals H(wℓ1,j | · · · |wℓλ,j ).
Garbled circuit evaluation :
S evaluates the circuits eCℓ for all ℓ ∈ E. Denote the output of eCℓ by zℓ.
Majority output :
For all ℓ ∈ E:
1. each party sends the two ciphertexts Enc(ω0
GO(rℓ),
ℓ , γ0) and Enc(ω1
ℓ , γ1) to S permuted in a random order, where (ω0
ℓ , ω1
ℓ ) :=
2. S checks that the pairs of encryptions it receives from all the players are identical and aborts otherwise,
3. S decrypts the two ciphertexts using zℓ and recovers γℓ and γ′
ℓ.
S sends to all parties the value W that appears the most among the set {γℓ, γ′
ℓ}ℓ∈E.
Output recovery :
Players output the bit b such that γb = W .
Figure 2: Protocol 2 - Malicious Server
3.3 Pipelining with Malicious Garblers
As demonstrated in [29, 42], pipelining the execution of gar-
bled circuits (i.e., garbling and evaluation) can lead to better
running times and less memory consumption. In a pipelined
execution, each gate is garbled and evaluated “on the ﬂy”and
the result of the evaluation is only stored while still needed
for future gates. This results in better running times since
the evaluator can start the evaluation while the garbler is
still garbling the circuit. Furthermore, there is no need to
store the entire garbled circuit (which can be several Giga-
bytes large) at any point during the execution, which leads
to better memory usage.
Unfortunately, the pipelining technique is not applicable
in the malicious setting and particularly when one applies
cut-and-choose techniques. The diﬃculty with pipelning
when one uses cut-and-choose is that for the evaluator to
verify/evaluate a garbled gate he needs to know from the be-
ginning of the execution either the circuit’s randomness (for
veriﬁcation) or the garbler’ s label (for evaluation). How-
ever, if the garbler can determine which circuits will be ver-
iﬁed and which will be evaluated while the execution is oc-
curring then he can easily cheat, e.g., by sending an invalid
garbled circuit for those being evaluated and valid circuits
for those being veriﬁed.
Our solution to this problem is to let the evaluator learn
the required information obliviously in the beginning of the
protocol, without giving it any information. This is done by
executing an OT protocol for each circuit, where the garbler
plays the sender in the OT and has two inputs: (1) the ran-
domness used to garble the circuit; and (2) its input labels
for the circuit. The evaluator plays the receiver in the OT
and decides whether it wants to either learn the randomness
and verify the garbled circuit, or learn the garbler’s labels
and evaluate the circuit. Transforming our protocols to use
this technique is straightforward. For example, for our sec-
ond protocol, we replace the Garbled Circuit Veriﬁcation
and Input Label Transfer stages with the following: for each
ℓ ∈ [s], all players share an input key Kℓ. Before the Circuit
Garbling stage, all players send their inputs to all circuits,
encrypted under the input keys. Then, the above OT is
executed, where P1’s inputs are the pairs (rℓ, Kℓ), and S’s
inputs are its choices in the cut-and-choose. Now, P1 sends
the garbled circuits and S can either evaluate or verify them
805on-the-ﬂy. Last, S reveals its choices and they continue the
rest of the protocol.
While we use this new pipelining technique in the server-
aided setting, the same approach can be used in the standard
SFE setting against malicious adversaries.
4 Evaluation
To evaluate the performance of our protocols we designed
and built a framework on top of which we can implement
any server-aided (and even standard 2SFE) protocol.
4.1 Our Framework
Our framework consists of the following modules:
Circuit generator - Generates a textual representation of
a boolean circuit. The circuit can be speciﬁed using the
FairPlay format [43], or using object-oriented python
code similarly to [29, 42].
Crypto library - Provides implementations of hash func-
tions, pseudo-random functions, commitments and sym-
metric encryption. These are all based on the JAVA
SHA-1 and SHA-256 implementations as suggested in
[52]. It also includes our implementation of the Peik-
ert, Vaikuntanathan and Waters OT protocol [50] built
on top of the JAVA BigInteger package.
Garbled circuit - Given a circuit representation and a PRF
key, it garbles the circuit using randomness generated
by the PRF. Given input labels and a garbled circuit,
it evaluates the circuit and returns the result. Given
a garbled circuit and a key to a PRF, it veriﬁes that
the given circuit was generated properly using that
key. All these functionalities are designed to work in
a pipelined fashion (more details below).
Communication library - Handles communication between
a set of parties, either peer-to-peer or broadcast.
Since the focus of our work is on eﬃciency, we do not
consider the cost of generating circuit representations. Our
design allows us to use any circuit generator, even ones that
generate circuits “on-the-ﬂy” such as [29, 42].
Circuit representation. The particular circuit represen-
tation we use is similar to FairPlay’s format [43] where each
gate has a unique identiﬁer and the circuit is represented by
specifying the identiﬁers of the inputs for each gate. As an
example, the string "354 120 380 AND" represents an AND
gate with identiﬁer 354 that uses inputs from gates 120 and
380. We slightly augment the FairPlay format with infor-
mation that is needed for pipelining the circuits. This is
because during pipelining we have to determine in realtime
whether a gate is needed to evaluate future gates or not
(in which case we can free the memory used for storing its
value).
Pipelining. We now discuss how pipelining is implemented.
Note that the work of garbler is fairly simple and space-
eﬃcient. It goes over the circuit speciﬁcation and, for each
gate, uses the PRF to generate the labels for the input and
output wires of the gate. Similar work is done by the eval-
uator when verifying a circuit.
If, on the other hand, the evaluator evaluates the circuit,
pipelining becomes more diﬃcult since it needs to store in-
termediate values. We can view the pipelining process as a
topological ordering of the gates that minimizes the number
of live gates (i.e., gates that are still needed) in each part of
the ordering. Obviously, the optimal ordering can be pre-
computed during a pre-processing phase so we assume that
the circuit representation is already ordered optimally. Dur-
ing the protocol execution, the evaluator maintains a list of
all live gates. When a gate is not needed anymore, the gar-
bler notiﬁes the evaluator that it can free that gate. As a
result, the evaluator maintains only the required intermedi-
ate values for the rest of the process.
Free XOR. Finally, we mention that we also use the free
XOR technique of Kolesnikov and Schneider [35] that is now
standard in any garbled circuit implementation. This tech-
nique allows us to construct a circuit in such a way that XOR
operations are “free” in the sense that they do not require
any cryptographic operations.
4.2 Experimental Results
We use two circuits in our experiments: (1) a circuit that
given a 128-bit message and a 1408-bit (expanded) key, com-
putes the AES encryption of the message under the key 2;
and (2) a circuit that computes the edit distance of two 50
character strings of 8 bit characters. The size of the AES
circuit is 31512 gates of which 13904 are non-XOR gates.
We generated the edit distance circuit according to the sug-
gestions of [29]. The size of that circuit is 254930 gates,
94472 of which are non-XOR gates.
For our experiments we used two Intel Core 2 Duo 3GHz
machines with 4GB RAM connected through a switched
LAN. The ﬁrst was used for executing the protocol of S,
and the second one for P1 and the rest of the parties. As
suggested in [52] we use a security level of 2−40 for the ma-