# Encore: Lightweight Measurement of Web Censorship with Cross-Origin Requests

## Authors
- Sam Burnett, School of Computer Science, Georgia Tech, PI:EMAIL
- Nick Feamster, Department of Computer Science, Princeton, PI:EMAIL

## Statement from the SIGCOMM 2015 Program Committee
The SIGCOMM 2015 Program Committee (PC) recognized the technical contributions of this paper but found it controversial due to ethical concerns raised by the experiments. The controversy stems from the lack of widely accepted ethical guidelines for measuring online censorship in the networking research community. According to the SIGCOMM 2015 submission guidelines, if the authors had not engaged with their Institutional Review Boards (IRBs) or if the IRBs had deemed the research unethical, the PC would have rejected the paper without review. However, the authors did engage with their IRBs, which did not flag the research as unethical. The PC hopes that the discussion of these ethical concerns will advance the development of ethical guidelines in this area. Future guidelines should include a core principle that researchers should not subject users to substantial harm without informed consent. The PC neither endorses the experimental techniques described in this paper nor the experiments conducted by the authors.

## Abstract
Despite the widespread nature of Internet censorship, there is limited data on its extent, mechanisms, and evolution. Measuring censorship is challenging, requiring continuous reachability tests to many target sites from diverse vantage points. Amassing suitable vantage points for longitudinal measurement is difficult, and existing systems have only achieved small, short-lived deployments. We observe that most Internet users access content via web browsers, and the design of websites allows browsers to make requests to domains with different origins than the main web page. We present Encore, a system that leverages cross-origin requests to measure web filtering from a diverse set of vantage points without requiring users to install custom software, enabling longitudinal measurements from many vantage points. We explain how Encore induces web clients to perform cross-origin requests to measure web filtering, design a distributed platform for scheduling and collecting these measurements, demonstrate the feasibility of a global-scale deployment through a pilot study and an analysis of potentially censored web content, identify several cases of filtering in six months of measurements, and discuss the ethical concerns that arise with widespread deployment.

## Categories and Subject Descriptors
- Networks → Network measurement; Web protocol security
- Social and professional topics → Technology and censorship

## Keywords
Web censorship, network measurement, web security

## 1. Introduction
Internet censorship is pervasive, with nearly 60 countries restricting internet communication in some way. As more citizens in repressive regimes gain internet access, government controls are likely to increase. Collecting longitudinal measurements to understand the evolving nature and extent of internet censorship is crucial.

Researchers, activists, and citizens aim to understand what, where, when, and how governments and organizations implement internet censorship. This knowledge can inform government censorship policies and guide the development of new circumvention techniques. While drastic actions like country-wide outages are easily observable, more common forms of censorship are subtle and challenging to measure. Censorship typically targets specific domains, URLs, keywords, or content, varies over time, and can be indistinguishable from application errors or poor performance. Detecting nuanced forms of censorship requires frequent measurements from many varied vantage points.

Consistently and reliably gathering these measurements is extremely difficult. The biggest obstacle is obtaining access to a diverse, globally distributed set of vantage points, particularly in regions most likely to experience censorship. Achieving widespread deployment in these locations often requires overcoming language and cultural barriers and convincing users to install measurement software. Although researchers have developed custom tools (e.g., OONI, Centinel), widespread deployment remains a challenge. Instead, researchers have resorted to informal data collection (e.g., user reports) or collection from a small number of non-representative vantage points (e.g., PlanetLab nodes, virtual private networks).

This paper takes an alternate approach: rather than asking each user to deploy custom censorship measurement software, we use existing features of the web to induce unmodified browsers to measure web censorship. Many users access the internet with a web browser, so inducing these browsers to perform censorship measurements will enable us to collect data from a larger, more diverse, and more representative set of vantage points than is possible with custom tools.

Our system, Encore, uses web browsers on nearly every internet-connected device as potential vantage points for collecting data about what, where, and when web filtering occurs. Encore relies on a relatively small number of webmasters to install a one-line embedded script that attempts to retrieve content from third-party websites using cross-origin requests. The Encore script induces every visitor of these modified pages to request an object from a URL that Encore wishes to test for filtering. Although same-origin policies in browsers prohibit many kinds of requests, we demonstrate that the cross-origin requests that browsers do allow are sufficient to collect information and draw conclusions about web filtering. A major contribution of our work is to show that meaningful conclusions about web filtering can be drawn from the side channels that exist in cross-origin requests.

Encore’s simplicity comes at the cost of significant limitations on the types of measurements it can collect and the conclusions we can draw from its measurements. First, Encore’s measurements must operate within the constraints of the cross-origin requests that web browsers permit. For example, the `img` HTML directive yields the most conclusive feedback about whether an object fails to load, but it can only be used to test images, not general URLs. This limitation means that while it may be useful for detecting the filtering of an entire DNS domain, it cannot test the reachability of specific (non-image) URLs. Encore’s design must recognize which cross-origin requests browsers permit and use combinations of these requests to draw inferences with higher confidence. Second, because Encore requires webmasters to augment their existing web pages, it must be easy to install and incur minimal performance overhead on the websites where it is deployed. Finally, great care is required when measuring censorship because accessing sensitive sites may endanger users in repressive countries. Our research focuses on Encore’s design and implementation, and is not a measurement study per se.

Encore can detect whether certain URLs are filtered, but it cannot determine how they are filtered. Subtle forms of filtering (e.g., degrading performance by introducing latency or packet loss) are difficult to detect, and detecting content manipulation (e.g., replacing a web page with a block page, or substituting content) using Encore is nearly impossible. Thus, Encore may complement other censorship measurement systems, which can perform detailed analysis but face much higher deployment hurdles. Ultimately, neither Encore nor other censorship analysis tools can determine human motivations behind filtering, or even whether filtering was intentional; they only provide data to policy experts who make such judgments.

## 2. Related Work
We summarize existing censorship measurement techniques, previous studies of internet censorship, other policy reports, and efforts to perform measurements from clients using advertisements or embedded images. Although we broadly survey internet censorship practices, Encore focuses on web filtering.

### Censorship Measurement Tools
The prevailing mode for measuring internet censorship is to develop custom measurement software and identify users willing to install the software or host a measurement device. Existing tools include OONI, Centinel, and CensMon. Both OONI and Centinel can be deployed on end hosts and perform detailed analysis of how censors implement blocking, but they have seen only limited deployment, likely because they require recruitment of users willing to install and maintain the software. CensMon was only deployed for a brief period on PlanetLab, a global network of servers hosted in academic networks, and such measurements are unlikely to be representative. At this point, we are not aware of any censorship measurement system that continuously collects measurements from a global set of vantage points; this is the gap that Encore aims to fill.

### Censorship Measurement Studies
Several researchers have performed "first look" studies of censorship in various countries, such as Pakistan, Iran, and China. Zittrain et al.’s study of censorship in China performed web requests to hundreds of thousands of sites but did so from only a handful of dialup modems. Crandall, Clayton, and Ensaﬁ exploit symmetric behavior of the Chinese firewall to measure it from clients outside China, but this technique does not work in all countries. The studies of censorship in Iran and Pakistan were more limited, performing measurements from a single vantage point for only two months. Each of these studies offers a useful snapshot into a country’s filtering practices at a particular point in time, but data collection is neither widespread nor continuous. The OpenNet Initiative has conducted the only long-term study to date, but its data collection is sporadic, making it difficult to compare filtering practices across countries and time.

### Sources of Block Lists
Some policy organizations publish reports concerning censorship practices around the world. The Open Network Initiative routinely publishes qualitative reports based on measurements from a limited number of vantage points, with scant insight into how censorship evolves over short timescales or what exactly is being filtered. Other projects such as Herdict, GreatFire, and Filbaan maintain lists of domains that may be blocked. These services and reports can serve as initial lists of URLs to test using Encore.

### Cross-Origin Requests for Client Measurement
Bortz et al. use timing information from cross-site requests to infer various information, such as whether a user is logged into a particular site or has previously visited a web page. Karir et al. use embedded JavaScript with cross-origin requests to measure IPv6 reachability and performance from large numbers of clients. Other systems have used cross-origin requests to determine information such as network latency between a client and some other internet destination. Casado and Freedman quantified the prevalence of clients behind NATs and proxies by delivering measurement code to clients in a manner similar to Encore. Puppetnets exploits weaknesses in browser security to coerce browsers to unwittingly participate in denial-of-service attacks. These tools use similar techniques as Encore, but they primarily aim to measure network performance or past user behavior based on the timing of successful cross-origin requests. They do not infer reachability of domains, IP addresses, or URLs based on the success (or lack thereof) of cross-origin requests.

## 3. Background
We discuss web filtering and threats that may interfere with attempts to measure it. We also explain cross-origin requests.

### 3.1 Threat Model
To implement web filtering, smaller countries often have centralized traffic filters on a national backbone, while larger countries require each ISP to implement a censorship policy. Some countries, like China, do both. Web filtering typically takes place during the initial DNS lookup, when the client attempts to establish a TCP connection to the web server, or in response to a specific HTTP request or response.

Our goal is to observe instances of web filtering and report them to a central authority (e.g., researchers) for analysis. We assume an adversary that can reject, block, or modify any stage of a web connection to filter web access for subsets of clients, although we assume the adversary uses a blacklist and is unwilling to filter all web traffic, or even significant fractions of all web traffic. This adversary influences Encore’s design in three ways: (1) the main goal of Encore is to measure this adversary’s web filtering behavior; (2) the adversary may attempt to filter clients’ access to Encore itself, preventing them from collecting or contributing measurements; and (3) the adversary may attempt to distort Encore’s filtering measurements by allowing measurement traffic but denying other access to the same site. This paper considers all three aspects of the adversary.

### 3.2 Cross-Origin Requests
Web browsers' same-origin policies restrict how a web page from one origin can interact with resources from another. An origin is defined as the protocol, port, and DNS domain ("host"). In general, sites can send information to another origin using links, redirects, and form submissions, but they cannot receive data from another origin. Browsers restrict cross-origin reads from scripts to prevent attacks such as cross-site request forgery. However, cross-origin embedding is typically allowed and can leak some read access. The cornerstone of Encore’s design is to use information leaked by cross-origin embedding to determine whether a client can successfully load objects from another origin.

Various mechanisms allow web pages to embed remote resources using HTTP requests across origins. Some forms of cross-origin embedding are not subject to the same types of security checks as other cross-origin reads.