Localized Manipulation. Since Iris relies entirely on
open infrastructure resolvers that we do not control, in
regions with few resolvers, we cannot differentiate be-
tween localized manipulation by the resolver’s opera-
tor and ISP or country-wide manipulation. Analysis of
incorrect results focusing on consistency across ISP or
country, or examination of webpage content, could aid in
identifying localized manipulation.
Domain Bias. From our set of infrastructure resolvers,
we measure manipulation of the CLBL and a subset of
Alexa top sites. Although the CLBL is a community-
based effort to identify sensitive content globally, by its
very nature it is not complete. URLs and domains are
missing, and sensitive content may change faster than the
list is updated. Similarly, the list may exhibit geographic
bias based on the language of the project and who con-
tributes to it. This bias could affect the relative volume
and scope of manipulation that Iris can detect.
Evasion. Although we focus on manipulation at ISP or
country scale, an active adversary can still attempt to
evade our measurements. Upstream resolvers could use
EDNS Client Subnet [16] to only manipulate results for
certain target IP ranges, or ISP resolvers could choose
to manipulate only their own customers. Country-wide
ﬁrewalls that perform injection could identify our scan-
ning IP addresses and either not inject results or block
our communication entirely. An adversary could also
exploit our consistency metrics and inject incorrect IP
addresses within the same AS as the targets.
Geolocation Error. We rely on Censys [21] and Max-
mind [37] for geolocation and AS labeling of infras-
tructure resolvers to perform country or ISP-level aggre-
gation. Incorrect labeling would identify country-wide
manipulation as incomplete (false negatives), or identify
manipulation in countries where it is not present (false
positives).
4 Dataset
In this section, we characterize the data collected and
how we processed it to obtain the results used in our anal-
ysis.
4.1 Open Resolver Selection
We initially identiﬁed a large pool of open DNS resolvers
through an Internet-wide ZMap scan using our DNS ex-
tension to ZMap in January 2017. In total, 4.2 million
open resolvers responded with a correct answer to our
scan queries. This number excludes resolvers that replied
with valid DNS responses but had either a missing or in-
correct IP resolution for our scan’s query domain.
314    26th USENIX Security Symposium
USENIX Association
Resolver
Datasets
All Usable
Ethically Usable
Experiment Set
Total
Resolvers
4,197,543
6,564
6,020
Number
Countries
232
157
151
Median /
Country
659.5
6.0
6.0
Table 1: DNS resolver datasets. We identify all correctly func-
tioning open resolvers are across the IPv4 address space. The
experiment set consists of resolvers that passed additional func-
tional tests beyond our basic scan. Note that the number of
countries includes dependent territories.
Resolver Dataset AF AS EU NA OC SA
14
All Usable
11
Ethically Usable
Experiment Set
11
52
42
41
41
25
24
55
29
26
49
42
41
21
8
8
Table 2: Number of countries (and dependent territories) con-
taining usable resolvers by continent. AF=Africa, AS=Asia,
EU=Europe, NA=North America, OC=Oceana/Australia,
SA=South America.
The degree to which we can investigate DNS ma-
nipulation across various countries depends on the ge-
ographic distribution of the selected DNS resolvers. By
geolocating this initial set of resolvers using Censys [21]
and MaxMind [37], we observed that these resolvers re-
side in 232 countries and dependent territories2, with a
median of 659 resolvers per country. Due to the ethi-
cal considerations we outlined in §3.2, we restrict this
set of resolvers to 6,564 infrastructure resolvers, in 157
countries, again with a median of 6 resolvers per country.
Finally, we remove unstable or otherwise anomalous re-
solvers; §4.3 describes this process in more detail. This
ﬁltering reduces the set of usable resolvers to 6,020 in
151 countries, with a median of 6 resolvers in each. Ta-
ble 1 summarizes the resulting population of resolvers;
Table 2 shows the breakdown across continents. We also
use 4 geographically diverse resolvers for controlled ex-
periments; the 2 Google Public DNS servers [28], a Ger-
man open resolver hosted on Amazon AWS, and a re-
solver that we manage at the University of California,
Berkeley.
4.2 Domain Selection
We investigate DNS manipulation for both domains
known to be censored and domains for popular websites.
We began with the Citizen Lab Block List (CLBL) [14],
consisting of 1,376 sensitive domains. We augment
this list with 1,000 domains randomly selected from the
Alexa Top 10,000, as well as 3 control domains we man-
2Countries and dependent territories are deﬁned by the ISO 3166-1
alpha-2 codes, the granularity of Maxmind’s country geolocation.
Response
Datasets
All Responses
After Filtering
Total
Responses
14,539,198
13,594,683
Number
Resolvers
6,564
6,020
Number
Domains
2,330
2,303
Table 3: DNS response dataset before and after ﬁltering prob-
lematic resolvers, domains, and failed queries.
age that should not be manipulated. Due to overlap be-
tween the two domain sets, our combined dataset con-
sists of 2,330 domains. We excluded 27 problematic do-
mains that we identiﬁed through our data collection pro-
cess, resulting in our ﬁnal population of 2,303 domains.
4.3 Response Filtering
We issued 14.5 million DNS A record queries for our
2,330 pre-ﬁltered domains, across 6,564 infrastructure
and control open resolvers during a 2 day period in Jan-
uary 2017. We observed various erroneous behavior that
required further ﬁltering. Excluding these degenerate
cases reduced our dataset collection to 13.5 million re-
sponses across 2,303 domains and 6,020 resolvers, as
summarized in Table 3. The rest of this section details
this ﬁltering process.
Resolvers. We detected that 341 resolvers stopped re-
sponding to our queries during our experiment. An ad-
ditional 202 resolvers incorrectly resolved our control
domain names, despite previously answering correctly
during our Internet-wide scans. The common cause
of this behavior was rate limiting, as our Internet-wide
scans queried resolvers only once, whereas our experi-
ments necessitated repeated queries. We identiﬁed an-
other problematic resolver that exhibited a query fail-
ure rate above 70% due to aggressive rate limiting. We
eliminated these resolvers and their associated query re-
sponses from our dataset, reducing the number of valid
responses by 510K.
Domains. Our control DNS resolvers could not resolve
15 domain names. We excluded these and their asso-
ciated 90K query responses from our dataset. We re-
moved another 12 domains and their 72K corresponding
query responses as their DNS resolutions failed an auto-
mated sanity check; resolvers across numerous countries
provided the same incorrect DNS resolution for each of
these domains, and the IP address returned was unique
per domain (i.e., not a block page or ﬁltering appliance).
We did not expect censors to exhibit this behavior; a sin-
gle censor is not likely to operate across multiple coun-
tries or geographic regions, and manipulations such as
block pages that use a single IP address across countries
should also be spread across multiple domains. These
domains do not support HTTPS, and exhibit geograph-
USENIX Association
26th USENIX Security Symposium    315
ically speciﬁc deployments. With increased geographic
diversity of control resolvers or deployment of HTTPS
by these sites, our consistency or veriﬁability metrics
would account for these domains.
Queries. We ﬁltered another 256K queries that returned
failure error codes; 93.7% of all errors were timeouts and
server failures. Timeouts denote connections where the
resolver did not respond to our query within 15 seconds.
Server failures indicate when a resolver could not recur-
sively resolve a domain within its own pre-conﬁgured
time allotment (10 seconds by default in BIND). Table 4
provides a detailed breakdown of error responses.
Failure Type
Timeout
Server Fail
Conn Refused
Conn Error
Truncated
NXDOMAIN
Count % of Responses
140,551
107,826
7,823
3,686
3,451
1,713
0.97%
0.74%
0.05%
0.03%
0.02%
0.01%
Table 4: Breakdown of the 265,050 DNS responses that re-
turned a non-success error code.
Returning an NXDOMAIN response code [38], which
informs a client that a domain does not exist, is an ob-
vious potential DNS censorship mechanism. Unfortu-
nately, some CDNs return this error in normal opera-
tions, presumably due to rate limiting or client conﬁgu-
ration settings. We found that the most prevalent NX be-
havior occurred in the countries of Tonga and Pakistan;
both countries exhibited censorship of multiple content
types, including adult and LGBT. Previous studies have
observed NXDOMAIN blocking in Pakistan [38]. These
instances comprise a small percentage of overall NX-
DOMAIN responses. Given the many non-censorship
NXDOMAIN responses and the relative infrequency of
their use for censorship, we exclude these from our anal-
ysis. Another 72K responses had a SUCCESS response
code, but contained no IP address in the response. This
failure mode frequently coincide with CNAME responses
that could not be resolved further. We excluded these
queries. Table 5 provides a geographic breakdown of
NXDOMAIN responses.
After removing problematic resolvers, domains, and
failed queries, the dataset comprises of 13,594,683 DNS
responses. By applying our consistency and indepen-
dent veriﬁability metrics, we identify 41,778 responses
(0.31%) as manipulated, spread across 58 countries (and
dependent territories) and 1,408 domains.
Country % NXDOMAIN
2.93%
0.37%
0.12%
0.04%
0.04%
Tonga
Pakistan
Bosnia/Herzegovina
Isle of Man
Cape Verde
Table 5: The top 5 countries / dependent territories by the per-
cent of queries that responded with NXDOMAIN.
Figure 3: The ability of each correctness metric to classify re-
sponses as correct. Table is ordered (top to bottom, left to right)
by the lines on the graph (left to right).
5 Results
We now evaluate the effectiveness of our DNS manipula-
tion metrics and explore manipulated DNS responses in
the context of Internet censorship.
5.1 Evaluating Manipulation Metrics
To assess the effectiveness of the consistency and inde-
pendent veriﬁability metrics, we quantify the ability of
each metric to identify unmanipulated responses (to ex-
clude from further investigation). Figure 3 shows each
metric’s efﬁcacy. The horizontal axis represents the frac-
tion of responses from a particular resolver that are clas-
siﬁed as correct by a given metric. The vertical axis indi-
cates the number of resolvers that exhibit that same frac-
tion of correct responses (again under the given metric).
For example, almost 6,000 resolvers had roughly 8%
of their responses identiﬁed as correct under the “Same
CDN” metric. A narrow band indicates that many re-
solvers exhibit similar fractions of correct responses un-
der that metric (i.e., it is more stable). The closer the cen-
ter mass of a histogram lies to 1.0, the more effective its
corresponding metric, since a larger fraction of responses
are classiﬁed as correct (i.e., not manipulation) using that
metric.
316    26th USENIX Security Symposium
USENIX Association
0.00.20.40.60.81.0Proportion of responses correct, by characteristic01000200030004000500060007000Number of resolversSame CDNCorrect CertCorrect Cert w/ SNISame CertSame Cert w/ SNISame HTTP PageSame IP AddressSame ASCountry (# Res.) Median Mean
Iran (122)
China (62)
Indonesia (80)
Greece (26)
Mongolia (6)
Iraq (7)
Bermuda (2)
Kazakhstan (14)
Belarus (18)
Max
Min
6.02% 5.99% 22.41% 0.00%
8.40% 0.00%
5.22% 4.59%
9.95% 0.00%
0.63% 2.81%
0.28% 0.40%
0.83% 0.00%
0.36% 0.00%
0.17% 0.18%
5.79% 0.00%
0.09% 1.67%
0.09% 0.00%
0.04% 0.04%
3.90% 0.00%
0.04% 0.30%
0.04% 0.07%
0.30% 0.00%
Figure 4: The fraction of responses manipulated, per resolver.
For 89% of resolvers, we observed no manipulation.
The AS consistency metric (“Same AS”) is the most
effective: it classiﬁed 90% of the DNS responses as con-
sistent. Similarly, identifying matching IP addresses be-
tween responses from our control resolvers and our ex-
periment resolvers ﬂagged about 80% of responses as
correct across most resolvers. “Same HTTP Page” is also
relatively effective, as many geographically distributed
deployments of the same site (such as with Points-of-
Presence) have either identical content or infrastructure
error characteristics (see §3.5.1). This ﬁgure also illus-
trates the importance of SNI, increasing the effective-
ness of correct and valid HTTPS certiﬁcates from 38% to
55%. The same HTTPS certiﬁcate (“Same Cert”) metric
turns out to be more effective than simply having a cor-
rect certiﬁcate (“Correct Cert”), because so many sites
incorrectly deploy HTTPS.
5.2 Manipulated DNS Responses
We detect nearly 42,000 manipulated DNS responses; we
now investigate the distribution of these responses across
resolvers, domains, and countries.
Manipulated responses by resolver. Figure 4 shows the
cumulative fraction of results that return at least a cer-
tain fraction of manipulated responses: 88% of resolvers
exhibited no manipulation; for 96% of resolvers, we ob-
serve manipulation for fewer than 5% of responses. The
modes in the CDF highlight differences between resolver
subpopulations, which upon further investigation we dis-
covered reﬂected differing manipulation practices across
countries. Additionally, 62% of domains are manipu-
lated by at least one resolver, which is expected given
that more than half of our selected domains are sensitive
sites on the CLBL. We explore these variations in more
detail later in this section.
Table 6: Top 10 countries by median percent of manipulated
responses per resolver. We additionally provide the mean, max-
imum, and minimum percent for resolvers in each country. The
number of resolvers per country is listed with the country name.
Manipulated responses by country. Previous work has
observed that some countries deploy nation-wide DNS
censorship technology [5]; therefore, we expected to see
groups of resolvers in the same country, each manipu-
lating a similar set of domains. Table 6 lists the percent
of manipulated responses per resolver, aggregated across
resolvers in each country. Resolvers in Iran exhibited the
highest degree of manipulation, with a median of 6.02%
manipulated responses per Iranian resolver; China fol-
lows with a median value of 5.22%. These rankings de-
pend on the domains in our domain list, and may merely
reﬂect that the CLBL contained more domains that are
censored in these countries.
The top 10 countries shown in Table 6 all have at least
one resolver that does not manipulate any domains; IP
address geolocation inaccuracy may partially explain this
surprising ﬁnding. For example, uncensored resolvers in
Hong Kong may be incorrectly labeled as Chinese. Ad-
ditionally, for countries that do not directly implement
the technical manipulation mechanisms but rather rely on
individual ISPs to do so, the actual manifestation of ma-
nipulation may vary across ISPs within a single country.
Localized manipulation by resolver operators in coun-