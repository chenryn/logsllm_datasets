timestamp accuracy. Since all campus traﬃc must
traverse these links, we can observe all post name-
resolution events for any arbitrary domain and
determine whether TCP connections are made for
that resolved name. For two ﬁve-day periods dur-
ing the monitoring timeframe, we also captured
all incoming and outgoing network traﬃc from
the campus during peak hours. In this case, only
packet headers are collected, and all client ad-
dresses were anonymized in a consistent fashion
with the DNS traces. Our collection servers were
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:43:14 UTC from IEEE Xplore.  Restrictions apply. 
DNS Server Poolns1ns2ns3All TrafﬁcCollectionDNS TrafﬁcCollectionDAGEdgeInternetCampus Network63Average Queries per day
Average Unique Clients per day
Average Cache Miss rate per day
All clients
Internal clients
Fall
Fall
Summer
42.4M
242,676
20.8%±4.5% 22.0% ±4.3% 57.1% ±5.1% 55.2% ±3.1% 73.2% ±5.6% 69.1% ±4.1%
Summer
32.1M
26,100
63.3M
330,665
51.4M
44,026
Internal browser clients
Fall
Summer
20.3M
18,905
31.3M
38,400
Summary statistics for the Summer and Fall 2010 datasets
Table I
that all the queries for the extracted domains will
arrive at the name server within a small timeframe.
googleads) and were fairly easily identiﬁable by the
preﬁx used in the query (e.g., img, ads, cdn). Having
identiﬁed these preﬁxes, we took special care to
eliminate them as part of any prefetching groups in
which they appeared, since we considered them to
be “required” elements for rendering the webpage
in question. We validated the correctness of this
step by comparing the DNS queries we deemed
as being necessary for rendering a page to the
actual observance of http/https connections in
the campus trace. We found that 96.7% of the
required queries were mapped to subsequent Web
connections. To be clear, we do not count these
required queries in the prefetching overheads.
IV. On the Impact of Prefetching
Figure 2.
Identifying and labeling prefetching events.
We validated this observation by extracting all
http/https connections in the campus trace dur-
ing peak periods for 10 days. The related DNS
queries were extracted for each web request using
the connection’s destination address, and queries
that did not match any web connection were la-
beled as ‘extraneous’. Close inspection of the query
inter-arrival times (not shown) revealed that for a
given client a valid query would be followed by a
set of extraneous ones, and the inter-arrival time
for 95% of these sets was less than 1 second. We
take advantage of this observation to implement a
straightforward approach for identifying prefetch-
ing events (see Figure 2).
A ﬁnal task is to identify legitimate queries
that are needed to successfully render a page,
and separate them from extraneous queries within
each event. Using our data generation framework,
we rendered each webpage for Alexa’s Top-1000
websites and studied the DNS query patterns with
prefetching turned oﬀ. We found that most pages
induced queries for locating elements such as im-
ages, multimedia components, advertisements and
trackers. Furthermore, these queries were usually
to a select few domains (e.g., akamai, doubleclick,
Before exploring the security and privacy im-
plications of DNS pre-resolution, we ﬁrst analyze
the overhead it imposes on the name servers in
our study. Table I summarizes some of the key
statistics of our datasets. Note the increase in traﬃc
in the Fall dataset, which corresponds to increased
campus population with the start of the school
year. The cache miss rate in Table I is calculated by
observing whether the name server has to make
an upstream query in order to satisfy a client’s
request. The overall low cache miss rate when
considering “all clients” is due to the fact that most
queries from external clients result in cache hits
because the vast majority of such queries are for
authoritative records. The high cache-miss rate for
internal request by browser clients, however, sug-
gests a power-law distribution for domain name
accesses. We return to this observation later in
Section IV-A and Section VI.
Figures 3(a) and 3(b) depicts the load pattern
for the internal UNC clients in 1-minute intervals
for the Summer and Fall datasets, respectively. The
graph shows that the weekly query load follows a
diurnal pattern with most of activity happening
during a workday. Peak requests hovered around
40,000 queries over the Summer and over 68,000
queries during the Fall semester with the inﬂux of
returning students.
Approximately 60% of the internal requests seen
in the Fall are due to browser-related queries. We
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:43:14 UTC from IEEE Xplore.  Restrictions apply. 
WindowInter-ArrivalTimePacket CountSlide WindowAppend to Cluster> 1s threshold (10)Cluster Packet CountTimePrefetch EventNormal browser eventDNS Query Packets64(a) Query Load in July, 2010 (Summer)
Figure 4.
existent (NX) answers observed per minute over 3 weeks
Box-and-Whisker plots for the number of non-
related queries with peaks near 55%. Interestingly,
this increased load is not due solely to the in-
creased student population, but could also have
been inﬂuenced by the launch of ‘Instant Search’
by Google in October 2010. Instant search provides
dynamically updating results as a user types in
the search box—all the while pre-resolving on each
new update to the search results. Overall, the
induced load from prefetching is a disturbing sign,
especially given the fact that the browser with over
60% market share (Internet Explorer) has yet to
turn on DNS pre-resolution.
For ease of presentation, for the remainder of
this section we present analysis for a representative
week of data from the Fall dataset.
Typed-in Navigation: As eluded to earlier, some
modern browsers try to guess the site the user
is trying to visit, providing suggestions along the
way to get her to the intended destination quickly.
As the browser attempts to guess the user’s inten-
tion, DNS queries are created — most times after
only a few characters are typed; For example, if
a user starts to type www.cnn.com in a browser’s
location bar, the browser attempts to autocomplete
the user’s intended site generating queries such as
www.cn., www.cnn.co. and in some extreme cases
w., ww., www.. While some of these queries can
be easily discarded as non-existent (NX) domains
(w., ww., www.), several will trigger queries to
nameservers since the queries inadvertently con-
tain valid domains hosted in Colombia or China.
As a cursory examination, we studied the pre-
resolutions that occur during typed-in navigation
(b) Query Load in October, 2010 (Fall)
Figure 3.
contribution of prefetching traﬃc for both datasets
Query load in 1-minute intervals, including the
then identiﬁed prefetching events for the browser
queries using the approach outlined in Figure 2.
During the summer they constitute, on average,
35% of the browser related queries, with peaks
near 44%. Several spikes in the browser-related
load over the summer can be attributed to searches
for ‘hot topics’ (e.g., the peak during the FIFA
world-cup ﬁnal on 7/11) using Google’s search
engine — in this case, a dynamic results page with
real-time scrolling feeds is returned, wherein pre-
resolution was performed.
As expected, prefetching activity increased in
the Fall, and contributes over 45% of the browser
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:43:14 UTC from IEEE Xplore.  Restrictions apply. 
 0 10000 20000 30000 40000 50000 60000 7000007/0607/0707/0807/0907/1007/1107/12Queries/MinTimeAll Internal QueriesBrowser QueriesBrowser Prefetching QueriesFIFA worldcup ﬁnal 0 10000 20000 30000 40000 50000 60000 7000010/1910/2010/2110/2210/2310/2410/25Queries/MinTimeAll Internal QueriesBrowser QueriesBrowser Prefetching Queriescocnmoneindbi02004006008001000Country Code TLDQueries/minute(Columbia)(China)(Macau)(Niger)(India)(Burundi)65(a) TTL distribution
(b) Domain Reuse for Prefetched data
Figure 5. Domain Reuse Patterns and TTL distribution for common TTL value ranges
in Chrome. For the most part, the majority of the
prefetches result in non-existent (NX) responses,
or valid domains for sites other than the intended
domain. Moreover, certain top-level domains are
unduly aﬀected by this practice, and receive the
majority of these bogus queries. Figure 4 shows the
responses per minute for browser auto-completion
during a three week period. The box plot shows
the mean, lower and upper quartiles, while the
whiskers cover the min and max values. Circles
denote outliers. Here we only consider a prefetch-
ing event as being related to auto-completion if
it is followed by queries to the same name, but
with a diﬀerent gTLD, in a short window of time.
Notice that for certain gTLDs (.co and .cn) the
rate is very high (nearing 1000 queries/min in some
cases); most are autocompletions for a user intend-
ing to visit a website with a .com TLD. Similar
NX responses are generated from gTLDs shown in
Figure 4 for users intending to visit websites with
.mobi,.net,.info and .biz TLDs.
A. Impact on Caching
One would expect that active pre-resolving of
domains on a per-client basis might not only im-
prove user-perceived latency, but possibly have
beneﬁt to other clients. Such beneﬁt would arise if
the records fetched as part of a prefetching event
remain in the server’s cache for extended periods
of time. Figure 5(a) plots the TTL values of A and
CNAME records in the Fall dataset. As we can see,
67.2% of the A records have TTL values of less than
5 minutes. Even worse, 31.2% of the records have
TTLs less than 20 seconds. The use of such low TTL
values can be attributed to content distribution
networks (CDNs). CDNs often set the TTL value
for their A records on the order of minutes as a
means of supporting dynamic load balancing [19].
Figure 5(a) also shows that CNAMEs, on the
other hand, can reside in cache for long periods
of time. CNAMEs are often used for redirection to
a CDN, e.g.  might redirect to . Figure 5(a) shows that 37% of the CNAME
records have TTLs of atleast 1 hour, and over 7%
of the records last longer than a day. A side eﬀect
of this is that CNAMEs oﬀer many hints as to a
site’s topical classiﬁcation, and their high lifetime
enables remote cache inspection attacks [16].
To explore the caching beneﬁts of prefetching,
we analyzed the reuse for domain names requested
in prefetching events. The reuse value for a domain
is computed based on the access frequency of all
clients requesting that name. Figure 5(b) shows a
Zipf-like reuse distribution, with 98% of the do-
main names accessed less than 10 times. However,
from a caching perspective, an entry is only valid
within its TTL window, so we normalized the
access frequencies to take TTLs into consideration.
The result shows that the overall usage pattern
(even for popular domains) falls by about 40%.
This means that for many of these domains, by
the time they are requested again (if at all), the
entry has already expired in the cache; thus the
prefetched domains are of little value to others.
Authorized licensed use limited to: Tsinghua University. Downloaded on March 18,2021 at 14:43:14 UTC from IEEE Xplore.  Restrictions apply. 
 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 1 10 100 1000 10000 100000 1e+06 1e+07CDFTTL (seconds)A RRCNAME RR20 sec5 min1 hour 0 5000 10000 15000 20000 25000 30000 35000 40000 45000 1 10 100 1000 10000 100000 1e+06 1e+07No of Unique ClientsUnique Domain NameDomain ReuseDomain Reuse w TTL Normalization66V. Impact on DNS Security Extensions
Over the past few years there has been steady
progress in eﬀorts to deploy DNSSEC, partly in
response to highly visible cache poisoning attacks.
Although common wisdom suggests that the over-
head of DNSSEC is non-trivial, we examine the
impact that prefetching can have on its deploy-
ment [3]. Speciﬁcally, we examine the additional
overhead imposed by prefetching, particularly as
it relates to the veriﬁcation of responses for extra-
neous requests.
Before discussing the details of our analysis, we
brieﬂy review some key elements of DNSSEC. In
short, DNSSEC extends the existing DNS archi-
tecture to use public key cryptography for secur-
ing the transactions between servers and clients.
Essentially, each response in a DNSSEC enabled
zone must be authenticated by building a “chain of
trust” to a trusted anchor. These zones are signed
using a Zone Signing Key (ZSK). The key is au-
thenticated by traversing the zone hierarchy until
a trusted anchor is reached. For a DNS response to
be considered authentic, each step in the veriﬁca-
tion chain must succeed. The key elements [20] of
DNSSEC pertinent to how veriﬁcation works (and
implemented in our simulator) are:
• a Resource Record Set (RRSet): A set of DNS
Resource Records (RR) of the same type and
TTL. In DNSSEC, signatures are created for
the entire RRSet included in a response.
• a DNSKEY: The public key of the zone that
• a RRSIG: A signed digest of a RRSet.
• a Delegation Signer (DS): A record that con-
signed the RRSet.
tains the digest of a child zones’ DNSKEYs.
To study the impact of prefetching, we designed
and implemented a cache simulator that performs
trace driven simulations using the datasets de-