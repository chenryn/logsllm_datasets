Figure 9: False Positive Detection Rate v.s. µ.
e
g
a
t
n
e
c
r
e
P
60%
40%
20%
0%
0.60
0.65
0.70
0.75
0.80
ingerprint 
0.90
0.95
1.00
0.85
  )
Figure 10: Fingerprint distribution of all identiﬁed
stable hijackings (µ = 0.6).
T is set as 10 seconds, no anomaly is ever falsely identiﬁed
as a hijacking.
If the 3988 alarms with IRR route origin
records are used as the validation set, only 0.3% alarms are
falsely identiﬁed as hijackings when µ = 0.5, and the error
decreases to 0.2% when µ = 0.6, as represented by the line
with squares. Since IRR records are often outdated and not
guaranteed to be correct, the real error should be even s-
maller. For comparison, the dash line represents the results
using ROAs but without ﬁltering the alarms by their du-
ration (i.e., when T = 1). If µ = 0.5, there are four cases
misclassiﬁed as hijackings, and when µ = 0.6, there is no
false identiﬁcation.
Fig. 10 plots the ﬁngerprint distribution of all identiﬁed
stable hijackings when we use the default threshold µ = 0.6
and T = 10. It is clear that most stable hijackings have a
ﬁngerprint much larger than 0.6, as indicated by the peak
near 1.0. This conﬁrms our conjecture that the control-plane
route status Ct and the data-plane reachability Dt has a very
high positive correlation when hijacking happens.
Fig. 11 shows the cumulative distribution function (CDF)
of the duration of all suspicious hijacking alarms (i.e., when
the ﬁngerprint Ft > µ). Many alarms are transient with
a short lifetime, and the distributions do not change much
when µ varies from 0.6 to 0.9.
In practice, we use T =
10 seconds to ﬁlter those non-stable route events that may
cause µ temporarily high. Even If they are real hijackings,
100%
C
s
m
r
a
l
a
80%
60%
40%
  µ= 0.9
  µ= 0.8
  µ= 0.7
  µ= 0.6
0
20
40
D uration 
60
80
( seconds)
100
120
Figure 11: Duration of suspicious alarms (CDF).
21 
R
(
T
R
(
T
=
I
R
R
(
T
F
F
(
F
t
%
(
D
F
)
d
1.5%
1.0%
0.5%
0.0%
e
t
a
r
e
v
i
t
i
s
o
p
e
s
l
a
0
10
20
30
40
50
60
( seconds)
6%
4%
2%
0%
e
t
a
r
e
v
i
t
i
s
o
p
e
s
l
a
O A 
O A 
= 1)
= 10)
= 10)
5
10
15
20
25
30
35
40
Figure 12: False Positive Detection Rate v.s. T .
Figure 14: False positive detection rate v.s. #eyes.
100%
80%
60%
40%
20%
0%
C
s
m
r
a
l
a
  Stable  hij ackings
  Non-stable  suspicious  alarms
0
5
10
15
20
25
30
  polluted 
Figure 13: The numbers of polluted eyes in stable
hijackings and non-stable suspicious alarms.
they can do little harm to the Internet since the routes can
hardly converge in such a short time.
Fig. 12 shows how the FPR decreases with T , under a
default µ = 0.6. Since there is no false identiﬁcation when
the ROA records are used, this curve is plotted using the
IRR records as the validation set. When T > 10, the false
rate is less than 0.2%, while if we do not use such a duration
threshold, the false rate will increase to 1.1%.
To illustrate the eﬀectiveness of T , we compare the num-
bers of eyes that are polluted by the 220 stable hijackings
and the 570 non-stable suspicious alarms in Fig. 13. The
distributions show that, non-stable hijackings usually aﬀect
a much fewer number of eyes than stable hijackings. For
example, in 81% cases, less than ﬁve eyes are aﬀected if the
alarm duration d  T . We note that, it rarely
happens that more than 40 eyes are aﬀected, even for stable
hijackings, and we will elaborate on this point later.
Fig. 14 presents how the false positive rate decreases when
more eyes are used, where the 266 anomalies with ROAs
and the 3988 anomalies with IRR records are used as the
validation set, respectively. It is clear that using more than
40 eyes achieves a fair accurate result, while less than ten
eyes may bring a few errors.
Fig. 15 reports the cumulative distribution of the detec-
tion delay (i.e., from when the ﬁrst anomalous BGP UP-
DATE is received to when the ﬁrst time that Ft exceeds
µ), for the 790 suspicious hijacking alarms and 220 stable
hijackings, respectively. About 50% suspicious alarms, and
60% stable hijacking have a detection delay of no more than
10 seconds. This is considered as much faster than existing
data-plane based hijacking detection methods, which cost at
least a few minutes.
We note that, the speed of Argus can be further improved,
since this delay includes the time used for logging in to the
eyes and the delay of route propagation, which are in aver-
age 6.4 and 4.6 seconds. They can be eﬀectively reduced by
putting Argus in a network of better quality, and by using
more eyes. If these latencies are deducted from the detection
100%
C
s
m
r
a
l
a
80%
60%
40%
20%
0%
( identification  delay)
( identification  delay)
  Stable  hij ackings 
  All  suspicious  alarms 
  Stable  hij ackings 
  All  suspicious  alarms 
( detection  delay)
( detection  delay)
0
20
40
D elay 
60
( seconds)
80
100
120
Figure 15: Hijacking detection delay (CDF).
delay, the real identiﬁcation delay costs less than 10 second-
s in 70% suspicious alarms and 80% stable hijackings, and
costs less than one second in 35% suspicious alarms and
50% stable hijackings. In this manner, we claim that Argus
achieves realtime detection.
5.2 Do we miss many real hijackings?
It is very hard to judge whether Argus can detect all or at
least a large fraction of blackholing preﬁx hijackings in the
Internet, since no one knows the ground truth. We make
several eﬀorts to improve its detection capability.
The BGP UPDATEs from BGPmon [3] is considered to
cover a large portion of the Internet [33]. For example, the
number of peers from which BGPmon collected live data
ranged from 110 to 130 in the last year, and these peers
were distributed in more than 70 ASes. To handle the rel-
ative large data volume 11, we used a server with a six-core
Intel Xeon CPU and 16G memory, and experienced no data
loss in the whole year. 12 In these UPDATEs, the anomaly
monitoring module monitors three types of anomalies, in-
cluding OA, AA and PA. To the best of our knowledge, we
are the ﬁrst to monitor hijackings which utilize forged adja-
cency or policy, although they have been theoretically stud-
ied before [15]. The successful detection of such hijackings
demonstrates the superior capabilities of Argus.
Our identiﬁcation method depends on the reachability to a
live host in the target preﬁx. If no such a host can be found,
we just guess one and probe it from our eyes. However,
if no eye can reach it, a possible hijacking may be missed,
and we say this is a blindfolded case. We improve the live-
IP retrieving module by collecting live IPs from multiple
sources, and the number of blindfolded cases decreases from
58% to 19% 13. We also consider the sub-preﬁx problem
11The peak volume exceeded 10MB/s.
12On average, we handled around 10GB BGP data each day,
and the peak volume exceeded 20Mbps.
13This is just an upper bound for missing hijackings, since
22 
I
R
R
F
T
%
(
D
F
)
#
e
y
e
s
R
(
T
R
(
T
I
R
R
(
T
F
#
e
y
e
s
%
(
D
F
)
12
9
6
3
0
s
g
n
i
k
c
a
i
h
e
l
b
a
t
s
O A 
  AA
  PA
0
8
16
24
32
40
48
Time 
( week)
(a) Stable hijackings
s
e
i
l
a
m
o
n
a
e
t
u
o
r
2k
1k
0
0
O A 
  AA
  PA
8
16
24
32
40
48
Time 
( week)
24
18
12
6
0
s
m
r
a
l
a
s
u