### Optimized Text

#### Code and Pseudocode
```plaintext
if IS_CONTINUOUS(i) then
    if xi ∈ (α, β] then
        for (α, β] ∈ LINE_SEARCH(x, i, ε) do
            P[id].ADD('xi ∈ (α, β]')
            Q.PUSH(x[i] ⇒ β)
        end if
    else
        // Values for current leaf
        // New leaves to visit
        // Test all features
        // Current interval
        // New leaf to visit
    end if
else
end if
```

#### Explanation of LINE SEARCH Procedure
The `LINE_SEARCH` procedure (line 12) is used to test continuous features. We start with bounds on the range of a feature \( X_i = [a, b] \). For example, if we have `Size ∈ [0, 100]`, we set the value of `Size` in `x` to 0 and 100, query the oracle `O`, and obtain `id1` and `id5`. If the IDs do not match, a split on `Size` occurs on the path to `id2`. Using a binary search over the feature `Size` (with all other features in `x` fixed), we find all intervals that lead to different leaves, such as `[0, 40]`, `(40, 60]`, and `(60, 100]`. From these intervals, we determine the predicate for the current leaf (e.g., `Size ∈ (40, 60]`) and build queries to explore new tree paths. To ensure the termination of the line search, we specify a precision `ε`. If a split is on a threshold `t`, we find the value `˜t` that is the unique multiple of `ε` in the range `(t - ε, t]`. For values `xi` with granularity `ε`, splitting on `˜t` is equivalent to splitting on `t`.

#### Explanation of CATEGORY SPLIT Procedure
The `CATEGORY_SPLIT` procedure (line 20) finds splits on categorical features. In our example, we vary the value of `Color` in `x` and query `O` to get a leaf ID for each value. We then build a set `S` of values that lead to the current leaf (e.g., `S = {R}`) and a set `V` of values to set in `x` to explore other leaves (one representative per leaf). In our example, `V` could be `{B, G, Y}` or `{B, G, O}`. Using these two procedures, we find the predicates defining the path to leaf `id2` and generate new queries `x'` for unvisited leaves of the tree.

#### Top-Down Approach
We propose a more efficient top-down algorithm that exploits queries over partial inputs. This method extracts the tree "layer by layer," starting at the root. We begin with an empty query (all features set to `⊥`) and get the root's ID by querying `O⊥`. We then set each feature in turn and query `O` again. For exactly one feature (the root's splitting feature), the input will reach a different node. With similar procedures as described previously, we extract the root's splitting criterion and recursively search lower layers of the tree.

#### Handling Duplicate Identities
Empirically, our attacks are resilient to some nodes or leaves sharing the same ID. We can modify line 7 in Algorithm 1 to detect ID duplicates by checking not only whether a leaf with the current ID was already visited but also whether the current query violates that leaf's predicates. The main issue with duplicate IDs arises from the `LINE_SEARCH` and `CATEGORY_SPLIT` procedures: if two queries `x` and `x'` differ in a single feature and reach different leaves with the same ID, the split on that feature will be missed.

#### Attack Evaluation
Our tree model (see Appendix A) is the one used by BigML. Other ML services use similar tree models. For our experiments, we downloaded eight public decision trees from BigML (see Table 5) and queried them locally using available API bindings. More details on these models are in Appendix B. We show online extraction attacks on black-box models from BigML in Section 5.

To emulate black-box model access, we first issue online queries to BigML to determine the information contained in the service's responses. We then simulate black-box access locally by discarding any extra information returned by the local API. Specifically, we use the following fields in query responses:
- **Prediction**: This entry contains the predicted class label (classification) or real-valued output (regression).
- **Confidence**: For classification and regression trees, BigML computes confidence scores based on a confidence interval for predictions at each node [11]. The prediction and confidence value constitute a node’s ID.
- **Fields**: Responses to black-box queries contain a 'fields' property, which lists all features that appear either in the input query or on the path traversed in the tree. If a partial query `x` reaches an internal node `v`, this entry tells us which feature `v` splits on (the feature is in the 'fields' entry but not in the input `x`). We use this property for the top-down attack variant.

Table 6 displays the results of our attacks. For each tree, we provide its number of leaves, the number of unique leaf IDs, and the tree depth. We display the success rate for Algorithm 1 and for the "top-down" variant with incomplete queries. Querying partial inputs vastly improves our attack: we require far fewer queries (except for the Steak Survey model, where Algorithm 1 only visits a fraction of all leaves and thus achieves low success) and achieve higher accuracy for trees with duplicate leaf IDs. As expected, both attacks achieve perfect extraction when all leaves have unique IDs. While this is not always the case for classification trees, it is far more likely for regression trees, where both the label and confidence score take real values. Surprisingly, the top-down approach also fully extracts some trees with a large number of duplicate leaf IDs. The attacks are also efficient: the top-down approach takes less than 10 seconds to extract a tree, and Algorithm 1 takes less than 6 minutes for the largest tree. For online attacks on ML services, discussed next, this cost is trumped by the delay for the inherently adaptive prediction queries that are issued.

#### Online Model Extraction Attacks
In this section, we showcase online model extraction attacks against two ML services: BigML and Amazon. For BigML, we focus on extracting models set up by a user who wishes to charge for predictions. For Amazon, our goal is to extract a model trained by ourselves, to which we only get black-box access. Our attacks only use exposed APIs and do not attempt to bypass the services’ authentication or access-control mechanisms. We only attack models trained in our own accounts.

##### Case Study 1: BigML
BigML currently only allows monetization of decision trees [11]. We train a tree on the German Credit data and set it up as a black-box model. The tree has 26 leaves, two of which share the same label and confidence score. From another account, we extract the model using the two attacks from Section 4.2. We first find the tree’s number of features, their type, and their range from BigML’s public gallery. Our attacks (Algorithm 1 and the top-down variant) extract an exact description of the tree’s paths, using respectively 1,722 and 1,150 queries. Both attacks’ duration (1,030 seconds and 631 seconds) is dominated by query latency (≈ 500ms/query). The monetary cost of the attack depends on the per-prediction-fee set by the model owner. In any case, a user who wishes to make more than 1,150 predictions has economic incentives to run an extraction attack.

##### Case Study 2: Amazon Web Services
Amazon uses logistic regression for classification and provides black-box-only access to trained models [1]. By default, Amazon uses two feature extraction techniques:
1. **Categorical Features**: Categorical features are one-hot-encoded, i.e., the input space \( M_i = Z^k \) is mapped to \( k \) binary features encoding the input value.
2. **Quantile Binning**: Quantile binning is used for numeric features. The training data values are split into \( k \)-quantiles (k equally-sized bins), and the input space \( M_i = [a, b] \) is mapped to \( k \) binary features encoding the bin that a value falls into. Note that \( |X| > |M| \).

Table 7 displays the results of our attacks on Amazon. For each model, we report the number of leaves, the number of unique identifiers for those leaves, and the maximal tree depth. The chosen granularity \( \epsilon \) for continuous features is \( 10^{-3} \).

| Model | Queries | Unique IDs | Leaves | Depth |
|-------|---------|------------|--------|-------|
| IRS Tax Patterns | 29,609 | 318 | 318 | 8 |
| Steak Survey | 4,013 | 28 | 193 | 17 |
| GSS Survey | 2,752 | 113 | 159 | 8 |
| Email Importance | 4,081 | 55 | 109 | 17 |
| Email Spam | 21,808 | 78 | 219 | 29 |
| German Credit | 1,150 | 25 | 26 | 11 |
| Medical Cover | 1,788 | 49 | 49 | 11 |
| Bitcoin Price | 7,390 | 155 | 155 | 9 |

| Model | Price ($) | OHE | Binning | Queries | Time (s) |
|-------|-----------|-----|---------|---------|----------|
| Circles | 0.03 | Yes | No | 278 | 28 |
| Digits | 0.07 | Yes | Yes | 650 | 70 |
| Iris | 0.07 | Yes | Yes | 644 | 68 |
| Adult | 0.15 | Yes | Yes | 1,485 | 149 |

Amazon charges $0.0001 per prediction [1].