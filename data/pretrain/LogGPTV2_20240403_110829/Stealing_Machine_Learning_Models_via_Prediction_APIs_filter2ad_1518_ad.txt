if IS CONTINUOUS(i) then
if xi ∈ (α,β ] then
else
for (α,β ] ∈ LINE SEARCH(x,i,ε) do
P[id].ADD(‘xi ∈ (α,β ]‘)
Q.PUSH(x[i] ⇒ β )
end if
(cid:29) Values for current leaf
(cid:29) New leaves to visit
(cid:29) Test all features
(cid:29) Current interval
(cid:29) New leaf to visit
else
end if
The LINE SEARCH procedure (line 12) tests continu-
ous features. We start from bounds on the range of a fea-
ture Xi = [a,b]. In our example, we have Size ∈ [0,100].
We set the value of Size in x to 0 and 100, query O, and
obtain id1 and id5. As the ids do not match, a split on
Size occurs on the path to id2. With a binary search over
feature Size (and all other features in x fixed), we find all
intervals that lead to different leaves, i.e., [0,40], (40,60],
(60,100]. From these intervals, we find the predicate for
the current leaf (i.e., Size ∈ (40,60]) and build queries to
explore new tree paths. To ensure termination of the line
search, we specify some precision ε. If a split is on a
threshold t, we find the value ˜t that is the unique multiple
of ε in the range (t − ε,t]. For values xi with granularity
ε, splitting on ˜t is then equivalent to splitting on t.
The CATEGORY SPLIT procedure (line 20) finds splits
on categorical features.
In our example, we vary the
value of Color in x and query O to get a leaf id for each
value. We then build a set S of values that lead to the cur-
rent leaf, i.e., S = {R}, and a set V of values to set in x to
explore other leaves (one representative per leaf). In our
example, we could have V = {B, G, Y} or V = {B, G, O}.
Using these two procedures, we thus find the pred-
icates defining the path to leaf id2, and generate new
queries x(cid:29) for unvisited leaves of the tree.
A top-down approach. We propose an empirically
more efficient top-down algorithm that exploits queries
over partial inputs. It extracts the tree ‘layer by layer’,
≤ 40
id1
∈ {R, B, G}
> 40
Size
Color
∈ {Y, O}
id6
≤ 60
Size
> 60
= R
id2
Color
= B
id3
= G
id4
id5
Figure 3: Decision tree over features Color and Size. Shows the
path (thick green) to leaf id2 on input x = {Size = 50, Color = R}.
# features
Data set
31
IRS Tax Patterns
12
Steak Survey
7
GSS Survey
14
Email Importance
46
Email Spam
11
German Credit
13
Medical Cover
Bitcoin Price
7
Table 5: Data sets used for decision tree extraction. Trained trees
for these data sets are available in BigML’s public gallery. The last two
data sets are used to train regression trees.
# records
191,283
430
51,020
4,709
4,601
1,000
163,065
1,076
# classes
51
5
3
2
2
2
Y = R
Y = R
starting at the root: We start with an empty query (all
features set to ⊥) and get the root’s id by querying O⊥.
We then set each feature in turn and query O again. For
exactly one feature (the root’s splitting feature), the input
will reach a different node. With similar procedures as
described previously, we extract the root’s splitting crite-
rion, and recursively search lower layers of the tree.
Duplicate identities. As we verify empirically, our at-
tacks are resilient to some nodes or leaves sharing the
same id. We can modify line 7 in Algorithm 1 to detect
id duplicates, by checking not only whether a leaf with
the current id was already visited, but also whether the
current query violates that leaf’s predicates. The main
issue with duplicate ids comes from the LINE SEARCH
and CATEGORY SPLIT procedures: if two queries x and
x(cid:29) differ in a single feature and reach different leaves with
the same id, the split on that feature will be missed.
4.2.2 Attack Evaluation
Our tree model (see Appendix A) is the one used by
BigML. Other ML services use similar tree models. For
our experiments, we downloaded eight public decision
trees from BigML (see Table 5), and queried them lo-
cally using available API bindings. More details on these
models are in Appendix B. We show online extraction
attacks on black-box models from BigML in Section 5.
To emulate black-box model access, we first issue
online queries to BigML, to determine the information
contained in the service’s responses. We then simulate
black-box access locally, by discarding any extra infor-
mation returned by the local API. Specifically, we make
use of the following fields in query responses:
USENIX Association  
25th USENIX Security Symposium  609
Model
Queries
29,609
IRS Tax Patterns
4,013
Steak Survey
2,752
GSS Survey
4,081
Email Importance
21,808
Email Spam
1,150
German Credit
1,788
Medical Cover
Bitcoin Price
7,390
Table 6: Performance of extraction attacks on public models from BigML. For each model, we report the number of leaves in the tree, the
number of unique identifiers for those leaves, and the maximal tree depth. The chosen granularity ε for continuous features is 10−3.
Unique IDs
318
28
113
55
78
25
49
155
1− Rtest
100.00%
92.45%
99.98%
99.13%
87.20%
100.00%
100.00%
100.00%
1− Runif
100.00%
100.00%
99.65%
99.99%
100.00%
100.00%
100.00%
100.00%
1− Rtest
100.00%
100.00%
100.00%
99.81%
99.70%
100.00%
100.00%
100.00%
1− Runif
100.00%
86.40%
99.61%
99.90%
100.00%
100.00%
100.00%
100.00%
Queries
101,057
3,652
7,434
12,888
42,324
1,722
5,966
31,956
Leaves
318
193
159
109
219
26
49
155
Without incomplete queries
With incomplete queries
Depth
8
17
8
17
29
11
11
9
• Prediction. This entry contains the predicted class la-
bel (classification) or real-valued output (regression).
• Confidence. For classification and regression trees,
BigML computes confidence scores based on a confi-
dence interval for predictions at each node [11]. The
prediction and confidence value constitute a node’s id.
• Fields. Responses to black-box queries contain a
‘fields’ property, that lists all features that appear ei-
ther in the input query or on the path traversed in the
tree. If a partial query x reaches an internal node v,
this entry tells us which feature v splits on (the feature
is in the ‘fields’ entry, but not in the input x). We make
use of this property for the top-down attack variant.
Table 6 displays the results of our attacks. For each
tree, we give its number of leaves, the number of unique
leaf ids, and the tree depth. We display the success
rate for Algorithm 1 and for the “top-down” variant with
incomplete queries. Querying partial inputs vastly im-
proves our attack: we require far less queries (except for
the Steak Survey model, where Algorithm 1 only visits
a fraction of all leaves and thus achieves low success)
and achieve higher accuracy for trees with duplicate leaf
ids. As expected, both attacks achieve perfect extraction
when all leaves have unique ids. While this is not al-
ways the case for classification trees, it is far more likely
for regression trees, where both the label and confidence
score take real values. Surprisingly maybe, the top-down
approach also fully extracts some trees with a large num-
ber of duplicate leaf ids. The attacks are also efficient:
The top-down approach takes less than 10 seconds to ex-
tract a tree, and Algorithm 1 takes less than 6 minutes
for the largest tree. For online attacks on ML services,
discussed next, this cost is trumped by the delay for the
inherently adaptive prediction queries that are issued.
5 Online Model Extraction Attacks
In this section, we showcase online model extraction at-
tacks against two ML services: BigML and Amazon. For
BigML, we focus on extracting models set up by a user,
who wishes to charge for predictions. For Amazon, our
goal is to extract a model trained by ourselves, to which
we only get black-box access. Our attacks only use ex-
OHE
Binning
Yes
No
Yes
Yes
-
-
-
Yes
Queries
278
650
644
1,485
Model
Price ($)
Circles
0.03
Digits
0.07
Iris
0.07
Adult
0.15
Table 7: Results of model extraction attacks on Amazon. OHE
stands for one-hot-encoding. The reported query count is the number
used to find quantile bins (at a granularity of 10−3), plus those queries
used for equation-solving. Amazon charges $0.0001 per prediction [1].
Time (s)
28
70
68
149
posed APIs, and do not in any way attempt to bypass the
services’ authentication or access-control mechanisms.
We only attack models trained in our own accounts.
5.1 Case Study 1: BigML
BigML currently only allows monetization of decision
trees [11]. We train a tree on the German Credit data,
and set it up as a black-box model. The tree has 26
leaves, two of which share the same label and confidence
score. From another account, we extract the model us-
ing the two attacks from Section 4.2. We first find the
tree’s number of features, their type and their range, from
BigML’s public gallery. Our attacks (Algorithm 1 and
the top-down variant) extract an exact description of the
tree’s paths, using respectively 1,722 and 1,150 queries.
Both attacks’ duration (1,030 seconds and 631 sec-
onds) is dominated by query latency (≈ 500ms/query).
The monetary cost of the attack depends on the per-
prediction-fee set by the model owner.
In any case, a
user who wishes to make more than 1,150 predictions
has economic incentives to run an extraction attack.
5.2 Case Study 2: Amazon Web Services
Amazon uses logistic regression for classification, and
provides black-box-only access to trained models [1].
By default, Amazon uses two feature extraction tech-
niques:
(1) Categorical features are one-hot-encoded,
i.e., the input space Mi = Zk is mapped to k binary fea-
tures encoding the input value. (2) Quantile binning is
used for numeric features. The training data values are
split into k-quantiles (k equally-sized bins), and the input
space Mi = [a,b] is mapped to k binary features encod-
ing the bin that a value falls into. Note that |X| > |M|,