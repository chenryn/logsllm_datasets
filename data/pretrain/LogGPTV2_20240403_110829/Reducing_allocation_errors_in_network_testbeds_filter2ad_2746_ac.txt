A resource allocation may fail for a number of reasons such as a
syntax error in the user’s request, a testbed software failure, a policy
violation by a user’s request, etc. In this paper we only investigate
resource allocation failures that occur due to temporary shortage of
testbed resources. This means that the same virtual topology would
successfully allocate on an empty testbed. We will call these TEMP
failures and classify them into the following categories:
1. FIXED: Virtual topology speciﬁed a ﬁxed mapping of some
virtual nodes to speciﬁc physical nodes but testbed could not
obtain access to these nodes.
2. TYPE: Virtual topology had node type constraint that could
not be met by the testbed.
3. OS: Virtual topology had OS constraint that could not be met
by the testbed.
4. CONNECT: The testbed could not ﬁnd a node with sufﬁ-
cient interfaces.
5. INTERSWITCH: The allocation algorithm found a solution
but the projected interswitch bandwidth usage exceeded link
capacity.
4996. TESTBED: There is a problem in the testbed’s software that
only becomes evident during resource allocation. One such
problem occurs when assign [20] – the current allocation
algorithm – fails to ﬁnd a solution even though one exists.
Categories FIXED, TYPE, OS, CONNECT and INTERSWITCH
stem directly from the way testbeds address the testbed mapping
problem (see the previous Section) – a failure to satisfy user or test-
bed constraints will fall into one of these ﬁve categories. In our
analysis of TEMP failures on DeterLab we further ﬁnd that bugs in
testbed conﬁguration and software occasionally lead to TEMP fail-
ures, when in reality there are available resources to satisfy user
and testbed constraints. This leads us to create the TESTBED cat-
egory. One could view TEMP failures that fall into TESTBED cat-
egory as false TEMP failures, since they do not occur due to a tem-
porary resource shortage.
We ﬁrst investigate why TEMP failures occurred historically on
the DeterLab’s testbed. We start with the records from the Deter-
Lab’s database that contain experiment identiﬁer, time and alleged
cause of each failure, as well as the error message generated by the
testbed software. The database only has records for failures that oc-
curred after April 13, 2006. There are 24,206 records, out of which
11,176 have their cause classiﬁed as TEMP in the database. We
use the error messages to classify these TEMP failures into the cat-
egories above. We ﬁnd that 47.5% are TYPE failures, 18.5% are
FIXED failures, 15.7% are OS failures, 3.8% are CONNECT fail-
ures and only 0.5% are INTERSWITCH failures. In 13.5% of cases
the error message indicates that mapping failed, but does not give
the speciﬁc reason. Finally there are 0.2% of failures that occur due
to a policy violation or a semantic problem in the experimenter’s
request but are misclassiﬁed as TEMP failures.
While the above analysis offers a glimpse into why speciﬁc al-
locations failed, we would like to know how many failures occur
due to true overload – there are not enough nodes on the testbed –
and how many occur due to perceived overload – there are enough
nodes on the testbed but experimenter or testbed constraints are vio-
lated. Cases of perceived overload could be eliminated either by re-
laxing experimenter’s constraints or by improving testbed software.
To answer these questions we need to match each TEMP failure to
the virtual topology and the testbed state snapshot that were given
to assign so we could mine the desired and the available number
of resources. We perform this matching in the following way:
1. We link each TEMP failure to a resource allocation log ﬁle
showing details of the allocation process, by matching the
time of the TEMP failure with the timestamp of the ﬁle.
2. From the log ﬁle we mine the ﬁle names of the virtual topol-
ogy and the testbed state snapshots that were used by the re-
source allocation software, i.e. the assign algorithm.
3. In 2007, DeterLab testbed stopped saving the virtual topol-
ogy and the testbed state ﬁles for failed allocations so we
must infer them from other data. To infer the virtual topology
we identify the testbed event (swapmod or swapin) that led
to that speciﬁc TEMP failure. For failures that occurred on
a swapin event, we attempt to ﬁnd a previous successful
swapmod or swapin of the same experiment and link it to
a virtual topology using the same process from steps 1 and
2. We associate this topology with the TEMP failure. To
infer the testbed state at the time of TEMP failure, we pro-
cess the testbed state snapshots chronologically up to the time
of the failure and infer from those the physical node features
and testbed architecture (connections and bandwidth between
nodes and switches). We also take the last testbed snapshot
created before the TEMP failure and extract the list of avail-
able nodes at the time. We then process any swapout events
between the time of the last snapshot and the TEMP failure,
and add the released nodes to the available pool. This gives
us the testbed state at the time of TEMP failure. Then we
combine all this information and generate the testbed snap-
shot in the format required by the assign algorithm. This
inference process may result in an incorrect testbed state only
if some of the available nodes become unavailable in the time
between the last testbed snapshot and the TEMP failure. This
can happen due to a hardware error, a manual reservation by
the testbed staff, or because some of the nodes released by the
swapout events in that short time interval failed to reload
the default OS and required manual intervention by testbed
staff. While hardware errors and manual reservations are rare
on DeterLab, reload failures occur daily but usually affect a
handful of nodes. We thus believe that most of our inferred
testbed snapshots are correct.
We were able to match 9,066 out of 11,176 TEMP failures in
this manner – they form the matched-failure set that we analyze
further. We focus only on demand and availability of general PC
nodes, since only a small fraction of instances request special hard-
ware. Only 1,679 of TEMP errors or 18.5% occur because of a true
overload, meaning that there are less PCs than desired. This means
that 81.5% of TEMP errors could potentially be reduced or elim-
inated by improving testbed software or by educating users how
to minimize their use of constraints. To identify TESTBED errors
we run both the assign and our assign+ allocation algorithm
(described in the Section 8.2) on the remaining 7,387 pairs in the
matched-failure set.
We next modify virtual topologies in the matched-failure set to
remove ﬁxed mappings, because they seem to often harm alloca-
tions, as evidenced by a high number of FIXED failures. In many
cases ﬁxed mappings are inserted not by a user but by the testbed
software when a running instance is being modiﬁed, e.g. by adding
or removing nodes. This enables the testbed to keep the currently
allocated nodes associated with the instance and just drop some (in
case of removing nodes) or add a few more. However, if some of
the allocated nodes become unresponsive the entire resource alloca-
tion fails. We believe that this is an incorrect model, and the testbed
should fall back to the strategy of releasing all nodes and allocat-
ing from the entire available node pool. Another reason for ﬁxed
mappings occurs in a case when nodes of a given type may dif-
fer based on their location, and a user prefers some locations over
others. We argue that these cases would be better handled through
node features or through creation of location-speciﬁc node types,
since ﬁxed mappings allow users to select only one out of several
possible node choices.
We ﬁnd that assign+ can successfully allocate resources in
1,392 cases, or 15.3% of our matched-failures set. We further ﬁnd
that both assign and assign+ succeed in 2,251 or 24.8% of
cases. It is possible that the original failure, recorded in the database,
was a “bad run of the luck” event for assign, due to its random-
ized search strategy (see Section 8.1 for more details). It is further
possible that the original failure occurred due to a failure of some
other testbed software and was recorded as a TEMP failure. Either
way, we classify these failures as TESTBED failures. Finally, we
ﬁnd that in 456 cases or 5% allocation failed due to a spelling error
in the database in some switch names. These entries are used when
testbed snapshots are created, and a spelling error leads to a dis-
connected testbed. We thus conclude that 3,288 or 36.3% of TEMP
errors occur due to experimenter’s constraints, 4,099 or 45.2% oc-
cur due to testbed software and 1,679 or 19.5% occur due to true
500overload. There are thus three ways of addressing the allocation
problem: (1) helping users understand and reduce the constraints on
their topologies, (2) designing better resource allocation algorithms
and (3) enforcing some fair sharing of resources. We explore each
of these strategies in the following sections.
Suggestion 3: Testbeds should develop automated self-checking
software that detects events such as spelling errors in the database
records, real switch and node disconnections, etc., well before they
lead to resource allocation failures.
7. RELAXING USER CONSTRAINTS
We now explore how much user constraints inﬂuence allocabil-
ity of instances on DeterLab. We ﬁrst match all the successfully
allocated instances in our dataset with their virtual topology and
the state of the empty testbed that existed at the time of their al-
location. For each topology, we simulate the checks in the testbed
mapping software for node type, OS and connectivity constraints
on this empty testbed. We limit our checks only to those nodes in
the virtual topology that can be allocated on general PCs, and the
testbed state only includes these PCs. For each node we record the
nodescore, showing the percentage of testbed that can satisfy this
node’s constraints. For example, if a user asked for a node of type
A or B with OS 1 and if there are 30 nodes of type A, 30 of type
B and 20 of type C in the testbed, with OS 1 supported on A and
C, the nodescore for this node would be 30/80 = 0.375 because
it can only be allocated to nodes of type A. We then calculate the
topscore, averaging all the nodescore’s in the virtual topology.
Original
ALTTYPE
NOTYPE
NOOS-NOTYPE
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
f
I
d
c
e
c
n
a
t
s
n
 0
 0
 0.2
 0.4
 0.6
Topscore (0-1)
 0.8
 1
Figure 4: Topscore values when we vary type restrictions
The red line in the Figure 4 shows the cumulative distribution
function (cdf) of all the topscores in the original topologies. There
are 30% of topologies that can allocate on less than 80% of the
testbed, 20% can allocate on less than half of the testbed and 10%
can allocate on less than 20% of the testbed. To identify the effect
of the node type, OS and connectivity constraints on the allocabil-
ity we modify virtual topologies in the following ways: (1) ALT-
TYPE: We allow use of alternative node types that have similar
or better hardware features than the user-speciﬁed node type; these
are described in more detail in Section 8.4, (2) NOTYPE: We com-
pletely remove the node type constraint, (3) NOOS-NOTYPE: We
remove both the node type and the OS constraints; the OS con-
straint can be removed by users upgrading their experiments to use
newer OS versions that are supported by all testbed hardware. Ef-
fect of these strategies on the allocability is also shown in Figure
4. Use of alternative types improves the allocability, especially of
Original
NOOS
NOOS-ALTTYPE
NOOS-NOTYPE
 1
 0.9
 0.8
 0.7
 0.6
 0.5
 0.4
 0.3
 0.2
 0.1
f
d
c
e
c
n
a
t
s
n
I
 0
 0
 0.2
 0.4
 0.6
Topscore (0-1)
 0.8
 1
Figure 5: Topscore values when we vary OS restrictions
those topologies that were previously severely restricted. There are
now 15% of topologies now allocate on less than half of the testbed
and only 2% allocate on less than 20% of the testbed. Removal of
node type constraints has a profound effect. Only 11% of topolo-
gies now allocate on less than 80% of the testbed, only 3% on less
than half of the testbed and only 0.1% on less than 20% of the test-
bed. Finally, removing all node type and OS constraints leads to
only 0.3% of topologies to allocate on less than 80% of the testbed.
We next explore the effect of (1) NOOS: Removing OS restric-
tions, (2) NOOS-ALTTYPE: Removing OS restrictions and using
alternative node types. The effect of these strategies is shown in
Figure 5. Removal of OS constraints leads to 23% of topologies
that can allocate on less than 80% of the testbed, 17% can allocate
on less than half of the testbed and 10% can allocate on less than
20% of the testbed. If we add to this use of alternative types, 21%
of topologies that can allocate on less than 80% of the testbed, 12%
can allocate on less than half of the testbed and only 2% can allocate
on less than 20% of the testbed.
We do not explore how changing connectivity would inﬂuence
allocability, because connectivity constraints only affect a small
number of topologies, and lower the allocability by a small value.
This is reﬂected in NOOS-NOTYPE line in Figure 5 where it de-
parts from 1 to values 0.9–1 for about 15% of topologies.
This section has laid out strategies that users can deploy them-
selves to improve allocability of their topologies. But, how likely
is this to happen, i.e. are users ﬂexible about their constraints? To
answer this, we try to characterize evolution of virtual topologies in
our dataset by ﬁrst pairing failed allocations with the ﬁrst following
successful allocation in the same experiment and then comparing
their topologies. We manage to pair 2,124 out of our 9,066 virtual
topologies from the matched-failures set. In 956 of those pairs the
topologies differ: in 639 cases a user has modiﬁed node type or OS
constraint, and in 322 cases a user has reduced the topology’s size.
We conclude that users naturally relax their constraints when faced
with an allocation failure about half of the time. When we examine
how long it takes a user to converge to a “good” set of constraints
we ﬁnd that half of the users discover the constraint set that leads
to successful allocation within one hour, 66% within 4 hours, and
78% within a day. But this distribution is heavy-tailed with the tail
going into year-long values, possibly due to the user abandoning
the experiment and returning to it much later.
Having automated tools that identify and propose alternative con-
straints to users would improve this convergence time, and would
501improve user experience. We believe that such an interactive dia-
logue with the user would work better then letting users specify how
important certain constraints are to them, since this more actively
engages the user and informs them about possible trade-offs.
Suggestion 4: Testbeds need tools that help users evaluate trade-
offs between different constraint sets and automatically suggest mod-
iﬁcations that improve allocability. This could be done prior to the
actual attempt to allocate resources.
8.
IMPROVING RESOURCE ALLOCATION
We now explain how assign algorithm works and how we im-
prove it in assign+.
8.1 assign
In [20] Ricci et al. propose and evaluate the assign algorithm
as a solver for the testbed mapping problem. Because this prob-
lem is NP-hard, Ricci et al. propose to solve it using simulated
annealing [14] – a heuristic that performs a cost-function-guided
exploration of a solution space. Simulated annealing starts from
a random solution and scores it using a custom cost function that
evaluates its quality. It then perturbs the solution using a generation
function to create the next one. If this solution is better than the pre-
vious one it is always accepted; otherwise it is accepted with some
small probability, controlled by temperature. This helps the simu-
lated annealing to get out of the locally optimal solutions and ﬁnd
the global optimum. At the beginning of the search, the tempera-
ture is set to a high value, leading to most solutions being accepted.
Over time the temperature is lowered, following a custom cooling
schedule, making the algorithm converge to a single “best” solution.
There is no guarantee that the algorithm will ﬁnd the best solution
but it should ﬁnd one that is much better than a random assignment,
and fairly close to the best one. Obviously, as algorithm runs longer
its chance of ﬁnding the global optimum increases but so does the
runtime. To guarantee time-bounded operation, assign’s runtime
is limited, which may sometimes make it miss a possible solution.
To condense the search space, Ricci et al. introduce the concept
of pclasses – sets of nodes that have the same node types, features,
network interfaces and switch connections. In Figure 3 we iden-
tify four pclasses. Virtual nodes are then mapped to pclasses. The
assign algorithm starts from the set of all pclasses and precom-
putes for each virtual node a list of pclasses that are acceptable
candidates. It then moves all the virtual nodes into unassigned list
and, at each step, tries to map one node from this list to a pclass.
When all the nodes have been assigned, the algorithm tries in each
step to remap one randomly selected virtual node to another pclass.
Each solution is scored by calculating a penalty for used interswitch
bandwidth and for unwanted features. The actual scoring function
is quite complex but it approximately adds up unwanted feature
weights and ﬁxed link penalties. A lower score denotes a better