its analysis, we refer the reader to the full version. Note that
1071
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:47:08 UTC from IEEE Xplore.  Restrictions apply. 
the ﬁrst step does not sacriﬁce any values: this is necessary
only to break the reﬂection symmetry.
The idea underpinning the attack is natural: a given query
distribution (in this case, the uniform distribution) induces a
distribution on the probability that each value is hit by a range
query. By measuring that probability empirically, the value of a
record can be inferred. More precisely, for a value k ∈ [1, N ],
let Ak denote the set of ranges in [1, N ] that contain k. Observe
that there are |[1, k] × [k, N ]| = k(N + 1 − k) such ranges.
We also assimilate Ak with the event that a uniform range
falls within Ak, i.e. contains the value k. Since there are
N (N + 1)/2 possible (non-empty) ranges in total, we have:
2
k(N + 1 − k).
p(k) def= Pr(Ak) =
(1)
We note that x (cid:55)→ p(x) is quadratic and reaches its maximum
at x = (N + 1)/2. It is symmetric about that value, as implied
by the reﬂection symmetry of the setting.
N (N + 1)
The algorithm simply measures p(x) empirically for each
record by counting how many times that record is hit by a
query, and dividing by the number of queries. It then infers
the symmetric value of the record by choosing k such that
p(k) is as close as possible to the empirical measurement.
Pseudo-code is provided in Algorithm 1 in Appendix D.
We now turn to the analysis of the algorithm: how many
queries are required to achieve sacriﬁcial -ADR? Because
the function p used to infer record values is quadratic and ﬂat
around (N + 1)/2, getting an error of  on the input of p,
i.e., on record values, requires an error bounded by O(2) on
the output of p. That is, for -ADR to succeed, the difference
between the empirical estimate c/Q for a record r and its
expectation p(val(r)) should be O(2). See the full version
for the formal proof.
Hence what we want is that the empirical probability of
each event Ak should be within O(2) of its expected value,
for all values k. If we were to naively apply a union bound,
since there are N distinct values k, we would get a dependency
on N. Instead, a direct application of VC theory shows that
O(−4 log −1) queries sufﬁce, with no dependency on N. To
see this, the idea is to deﬁne the ground set X as the set of all
ranges in [1, N ], and the concept set C as the Ak’s, i.e., each
Ak is a concept. Then what we want is exactly a Ω(2)-sample
on that concept class.
Proposition III.1. The growth function of (X, C) is 2n, and
its VC dimension is 2.
The proof of Proposition III.1 is given in the full version.
As a direct consequence, we can apply the -sample theorem
(Theorem A.4), with Ω(2) playing the role of the  in the
statement of the theorem, to conclude that
O(cid:0)−4 log −1 + −4 log δ−1(cid:1)
queries sufﬁce for Algorithm 1 to recover the symmetric value
of all records within N, except with probability at most δ.
Thus for any ﬁxed probability of success η = 1 − δ  vA.
k(N + 1 − vA)
vA(N + 1 − k)
d(vA, k) def=
N (N + 1)
(cid:40)
2
·
The second step of the ApproxValue algorithm is to use
the function x (cid:55)→ d(vA, x) exactly as we used x (cid:55)→ p(x) in
the previous section to estimate a record’s value. The crucial
point is that while x (cid:55)→ p(x) was quadratic, x (cid:55)→ d(vA, x) is
piecewise linear (with a single bend at vA). This avoids the
ﬁrst squaring discussed earlier.
The third and ﬁnal step of ApproxValue is to use p
once again to break the symmetry around vA inherent to the
mapping x (cid:55)→ d(vA, x) used in the previous step. However,
this limited use of p does not incur a new square factor. In the
end, we obtain the following result.
Theorem III.2. Let  < 1/4. Assume the database under
attack satisﬁes hypothesis h1. Then after O(−2 log −1 +
−2 log δ−1) queries, ApproxValue achieves sacriﬁcial -
ADR with probability of success at least 1 − δ.
A formal proof is given in the full version. Given any con-
stant probability of success η < 1, ApproxValue achieves
sacriﬁcial -ADR within O(−2 log −1) queries.
D. Experimental Results
to
the
For
attack
succeed,
The ApproxValue attack achieves
-ADR within
O(−2 log −1) queries (for any given constant probability of
success η < 1). We experimentally evaluate the tightness of
this bound for a ﬁxed number of records, R, and various
numbers of possible values, N, so that we generate both dense
and sparse databases. Record values are sampled uniformly at
random, so hypothesis h1 was satisﬁed with high probability.
Our results are averaged over 500 databases, each with 500
randomly sampled queries.
difference
|est-val(r) − val(r)| should be at most N for
records
at least N away from the endpoints. The records whose
values are near the endpoints may have been placed on the
wrong side of N/2 relative to the anchor record. The bottom
group of lines in Figure 2 shows, after every 10 queries, the
maximum symmetric value of such misclassiﬁed records. As
discussed in Section III-A, sacriﬁcing reconstruction of some
records is necessary. Nevertheless, we see that our practical
results are even better than Theorem III.2 suggests: the upper
bound on the maximum symmetric value of a sacriﬁced
record still holds when we take it with all constants set to 1 –
in particular, taking the VC dimension to be 1, not taking into
account the success probability, and taking any multiplicative
constant hidden by the O() notation to be 1.
the
Fig. 2. Maximum symmetric errors of all records and maximum symmetric
values of records that were sacriﬁced. Results averaged over 500 databases
satisfying h1 for each value of N.
arises in the proof of the -sample theorem (e.g., as in [11,
Lemma 14.17]) is when using the growth function to upper
bound the number of subsamples induced in the so-called
double sample. Tightening this bound is possible, for instance,
with sample-based growth functions [12]. A beneﬁt of running
experiments is that they allow us to estimate the constant in
practice: in our experiments, simply setting all constants to 1
provided a reasonable estimation of the attack’s success.
In addition to limiting the sacriﬁced values’ distance from
the endpoints, a successful -ADR attack must correctly
estimate the other records’ values within N, up to global
reﬂection. The upper group of lines in Figure 2 is the
maximum error of the symmetric values, i.e., the maximum
difference |min{est-val(r), N + 1 − est-val(r)} − symval(r)|
over all records r, as a fraction of N. The reason we plot
the symmetric error rather than the absolute error is that it
allows us to present results for all records at once—even
sacriﬁced records. It also gives an upper bound on the er-
rors |est-val(r) − val(r)| for records that were not sacriﬁced.
Overall, we see that experimental results behave in the manner
predicted by the theory, including scale-freeness, and that the
O() upper bound derived by the theory holds in practice, even
when setting the hidden multiplicative constant to just 1.
IV. APPROXIMATE ORDER RECONSTRUCTION
In this section, to remove the requirements that the query
distribution should be i.i.d. (which we view as unrealistic)
and known to the adversary, we turn our attention to sacri-
ﬁcial -approximate order reconstruction (sacriﬁcial -AOR),
deﬁned in Section IV-A. In Section IV-B, we explain our
ApproxOrder algorithm for sacriﬁcial -AOR, based on
PQ-trees, and its analysis. In Section IV-C, we experimentally
evaluate the bounds. In Section IV-D we show how the attack
The primary reason this “no-constants” bound holds is
because the bound in Theorem III.2 inherits the looseness of
the -sample theorem (cf. Theorem A.4): while VC theory is
a good predictor of asymptotic behavior, constants are noto-
riously loose. In particular, one point where loss of tightness
1073
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:47:08 UTC from IEEE Xplore.  Restrictions apply. 
0100200300400500Numberofqueries0.0000.0250.0500.0750.1000.1250.1500.1750.200Symmetricvalue/error(asafractionofN)Max.sacriﬁcedsymmetricvalueN=100N=1000N=10000N=100000Max.symmetricerrorN=100N=1000N=10000N=100000−2log−1−2log−1ApproxValueexperimentalresultsR=1000,comparedtotheoretical-sampleboundcan be extended to recover approximate record values, rather
than just their order, and present experimental results.
A. Deﬁnition of Sacriﬁcial -AOR
Sacriﬁcial -approximate order reconstruction (sacriﬁcial -
AOR) asks to recover the order of records, except for records
that are within N of each other (“approximate” recovery), and
for records within N of the endpoints 1 and N (“sacriﬁced”
records).
We ﬁrst introduce some notation: if A is a set of records,
then the diameter of A is the largest difference between the
values of any two records in A, i.e.: diam(A) def= max{val(b)−
val(a) : a, b ∈ A}. We let < denote the order on records
induced by their values, i.e. r < s iff val(r) < val(s). For
two sets of records A and B, we write A < B to denote
∀a ∈ A, b ∈ B, a < b.
An algorithm is said to achieve sacriﬁcial -AOR iff it
outputs disjoint subsets of records A1, . . . , Ak such that:
1) ∀i, diam(Ai) < N.
2) A1 < ··· < Ak holds up to reﬂection.
3) For all r (cid:54)∈(cid:83) Ai, val(r) ∈ [1, N [∪]N + 1 − N, N ].
The deﬁnition implies that the algorithm reveals the order of
the values of any two records, as soon as they are at least N
apart; except possibly for records whose value is within N
of 1 or N. If we set  = 1/N, sacriﬁcial -AOR is equivalent
to recovering the exact order of all records.
B. The ApproxOrder Attack
Our attack makes use of PQ-trees [13], a special structure
that makes it possible to represent the set of all orders on
records compatible with the access pattern leakage. The leaves
of a PQ-tree are labeled by records. Each leaf corresponds to
a distinct record. Internal nodes constrain how their children
may be ordered: P-nodes allow any ordering, while Q-nodes
order their children up to reﬂection (i.e. only two orderings are
possible). A more detailed presentation of PQ-trees is provided
in Appendix B.
Pseudo-code for the ApproxOrder attack is given in
Algorithm 3 in Appendix D. The idea is to ﬁrst build the
PQ-tree induced by the query access pattern leakage. The
algorithm then locates the deepest node T in the tree such that
the leaves below T contain a strict majority of all records. The
algorithm returns as its output the set Ai of leaves below each
child Ci of T , in the order of the children of T . Thus, the
order between two records is learned by the adversary iff they
appear below distinct children of T , and the order between
the two records matches the order of the children of T below
which they appear.
Analytically, our main result is as follows. The theorem
assumes hypotheses h2 and h3, which will be presented below,
and a uniform query distribution.
Theorem IV.1. Let  < 1/4. Assume the database under at-
tack satisﬁes hypotheses h2 and h3. Then after O(−1 log −1+
−1 log δ−1) queries, ApproxOrder achieves sacriﬁcial -
AOR with probability of success at least 1 − δ.
The proof of Theorem IV.1 is given in the full version. For
any ﬁxed constant probability of success, the algorithm suc-
ceeds using only O(−1 log −1) queries. As a direct corollary
(setting  = 1/N), the expected number of queries before
the PQ-tree collapses into a single Q-node, thus completely
revealing the order up to reﬂection, is O(N log N ).
The overall idea is that after that number of queries, with
high probability there exist certain queries whose endpoints
partition [1, N ] into sufﬁciently small buckets while revealing
the order between these buckets. By properties of PQ-trees,
this situation implies the existence of a node within the
PQ-tree that essentially directly reveals -approximate order
(and that node can be easily located as the deepest node
covering a majority of records). Moreover, the existence of
the aforementioned queries inducing the partition is implied
by an -net, so that ultimately the query complexity required
for those queries to exist is directly derived from the -net
theorem of VC theory.