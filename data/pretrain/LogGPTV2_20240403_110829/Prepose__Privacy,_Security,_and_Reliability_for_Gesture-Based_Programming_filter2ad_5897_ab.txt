click, double-click, etc. in regular applications1. While, for
instance, the Kinect SDK already includes a number of
default gestures, developers typically need to add their
own. Diﬀerent applications often require diﬀerent sets of
gestures, and, as such, building new gestures is a funda-
mental part of software development.
Gesture development is a tricky process, which often
depends on machine learning techniques requiring large
volumes of training data [7]. These heavyweight meth-
ods are both expensive and time-consuming for many
developers, resulting in mostly large game studios being
able to aﬀord gesture development. Therefore, making
gesture development easier would unlock the creativity of
a larger class of developers. Prepose aids this with sound
static analyses for reliability properties of gestures, such
as whether the gesture deﬁnition is self-contradictory.
Prepose language and runtime: This paper proposes
Prepose, a language and a runtime for authoring and
checking gesture-based applications. For illustration, a
code snippet supported by our system in shown in Fig-
ure 3. This code is translated into logical formulas which
are checked at runtime against the user’s actual positions
using an SMT solver.
Prepose is built as a library on top of the released
Kinect SDK. Applications link against this library. The
source code of Prepose is available on Github (URL omit-
ted for anonymity). Prepose lowers the cost of developing
1To quote a blog entry: “After further experimenting with the
Kinect SDK, it became obvious what needed to come next. If you
were to create an application using the Kinect SDK, you will want to
be able to control the application using gestures (i.e. waving, swiping,
motions to access menus, etc.).” [25]
124124
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:14:45 UTC from IEEE Xplore.  Restrictions apply. 
.app 
gesture file
Z3 theorem 
prover
static checking
triage 
Fig. 5: Checking submissions to a gesture store. Submissions are marked as safe (green), unsafe (red), or need human attention (blue).
new gestures by exposing new primitives to developers
that can express a wide range of natural gestures.
Application domains implemented in Prepose: To
demonstrate the expressiveness of Prepose, we experi-
ment with three domains that involve diﬀerent styles of
gestures: physical therapy, dance, and tai-chi. Given the
natural syntax of Prepose and a ﬂat learning curve, we
believe that other domains can be added to the system
quite easily. For each of these gestures, we then performed
a series of analyses enabled by Prepose, including conﬂict
detection, as well as safety, security, and privacy checks.
Monitoring applications in Prepose: We discovered
that Prepose is particularly well-suited to what we call
monitoring applications which can be implemented with
Prepose gestures and a small amount of “bookkeeping”
code. For example, Kinect Sports includes a tai-chi trainer,
which instructs users to struck tai-chi poses and gives
real-time feedback on how well they do, which is easily
captured by Prepose and supported by the runtime we
have built. For another example, Atlas5D is a startup
that installs multiple sensors in the homes of seniors
and monitors seniors for any signs of a fall or another
emergency. Another example of such an application for
physical therapy is shown in Figure 8a or can be seen in a
video at http://reflexionhealth.com. These applications
can run, concurrently, for weeks on end, with only minimal
needs to report results (such as completing a certain level
within the tai-chi application) to an external server.
1.6 Contributions
Our paper makes the following contributions:
• Prepose. Proposes a programming language and a
runtime for a broad range of gesture-based immer-
sive applications designed from the ground up with
security and privacy in mind. Prepose follows the
principle of privacy by construction to eliminate the
majority of privacy attacks.
• Static analysis. We propose a set of static anal-
ysis algorithms designed to soundly ﬁnd violations
of important security and reliability properties. This
analysis is designed to be run within a gesture App
Store to prevent malicious third-party applications
from aﬀecting the end-user.
• Expressiveness. To show the expressiveness of Pre-
pose, we encode 28 gestures for 3 useful application
domains: therapy, dance, and tai-chi.
• Performance evaluation. Despite being written in
a domain-speciﬁc language (DSL), Prepose-based
gesture applications pay a minimal price for the extra
security and privacy guarantees in runtime overhead;
tasks like pose matching take milliseconds. Our static
analysis scales well in practice: safety checking is un-
der 0.5 seconds per gesture; average validity checking
time is only 188 ms; lastly, for 97% of the cases, the
conﬂict detection time is below 5 seconds, with only
one query taking longer than 15 seconds.
1.7 Paper Organization
The rest of the paper is organized as follows. Section 2
provides some background on gesture authoring. Section 3
gives an overview of Prepose concepts and provides some
motivating examples. Section 4 describes our analysis for
security and privacy in detail. Section 5 contains the
details of our experimental evaluation. Sections 7 and 8
describe related work and conclude.
2 Background
Today, developers of immersive, sensor-based applications
pursue two major approaches to creating new gesture
recognizers. First, developers write code that explicitly
encodes the gesture’s movements in terms of the Kinect
Skeleton or other similar abstraction exposed by the plat-
form. Second, developers use machine learning approaches
to synthesize gesture recognition code from labeled exam-
ples. We discuss the pros and cons of each approach each
in turn.
Manually written: In this approach, the developer ﬁrst
thinks carefully about the gesture movements in terms of
an abstraction exposed by the platform. For example, the
Kinect for Windows platform exposes a “skeleton” that
encodes a user’s joint positions. The developer then writes
custom code in a general-purpose programming language
such as C++ or C# that checks properties of the user’s
position and then sets a ﬂag if the user moves in a way to
perform the gesture. For example, the Kinect for Windows
white paper on gesture development [16] contains code for
a simple punch gesture, shown in Figure 6.
The code checks that the user’s hand is “far enough”
away from the shoulder, that the hand is moving “fast
enough,” that the elbow is also moving “fast enough,” and
that the angle between the upper and lower arm is greater
125125
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:14:45 UTC from IEEE Xplore.  Restrictions apply. 
// Punch Gesture
if ( vHandPos.z-vShoulderPos.z>fThreshold1 &&
fVelocityOfHand > fThreshold2 ||
fVelocityOfElbow > fThreshold3 &&
DotProduct(vUpperArm, vLowerArm) > fThreshold4)
{
}
bDetect = TRUE;
Fig. 6: A simple punch gesture.
than a threshold. If all these checks pass, the code signals
that a punch gesture has been detected.
Manually-written poses require no special tools, data
collection, or training, which makes them easy to start
with. Unfortunately, they also have signiﬁcant drawbacks.
• First, the code is hard to understand because it
typically reasons about user movements at a low level.
For example, the code uses a dot-product to check the
angle between the lower and upper arm instead of an
abstraction that directly returns the angle.
• Second, building these gestures requires a trained
programmer and maintaining code requires manually
tweaking threshold values, which may or may not
work well for a wider range of users. Third,
it is
diﬃcult to statically analyze this code because it is
written in a general purpose programming language,
so gesture conﬂicts or unsafe gestures must be de-
tected at runtime.
• Finally, the manually coded gesture approach requires
the application to have access to sensor data for the
purpose of recognizing gestures. This raises privacy
problems, as we have discussed: a malicious devel-
oper may directly embed some code to capture video
stream or skeleton data to send it to http://evil.com.
Machine learning: The leading alternative to manually-
coded gesture recognizers is to use machine learning ap-
proaches. In machine learning approaches, the developer
ﬁrst creates a training set consisting of videos of people
performing the gesture. The developer then labels the
videos with which frames and which portions of the depth
or RGB data in the frame correspond to the gesture’s
movements.
Finally, the developer runs an existing machine learning
algorithm, such as AdaBoost, to synthesize gesture recog-
nition code that can be included in a program. Figure 7
shows the overall workﬂow for the Visual Gesture Builder,
a machine learning gesture tool that ships with the Kinect
for Windows SDK. The developer takes recordings of many
diﬀerent people performing the same gesture, then tags the
recordings to provide labeled data. From the labeled data,
the developer synthesizes a classiﬁer for the gesture. The
classiﬁer runs as a library in the application.
Machine learning approaches have important beneﬁts
compared to manually-written poses. If the training set
contains a diverse group of users, such as users of diﬀerent
sizes and ages, the machine learning algorithm can “auto-
matically” discover how to detect the gesture for diﬀerent
users without manual tweaking. In addition, improving the
gesture recognition becomes a problem of data acquisition
and labeling, instead of requiring manual tweaking by a
trained programmer. As a result, many Kinect developers
today use machine learning approaches.
On the other hand, machine learning has drawbacks as
well. Gathering the data and labeling it can be expensive,
especially if the developer wants a wide range of people in
the training set. Training itself requires setting multiple
parameters, where proper settings require familiarity with
the machine learning approach used. The resulting code
created by machine learning may be diﬃcult to interpret
or manually “tweak” to create new gestures. Finally, just
as with manually written gestures, the resulting code is
even more diﬃcult to analyze automatically and requires
access to sensor data to work properly.
3 Overview
We ﬁrst show a motivating example in Section 3.1. Next,
we discuss the architecture of Prepose and how it pro-
vides security and privacy beneﬁts (3.2). We then intro-
duce basic concepts of the Prepose language and discuss
its runtime execution (3.3). Finally, we discuss the security
and privacy issues raised by an App Store for gestures, and
show how static analysis can address them (3.4).
3.1 Motivating Example
Existing application on Kinect: Figure 8a shows a
screen shot from the Reﬂexion Health physical therapy
product. The reader is strongly encouraged to watch the
video at http://reflexionhealth.com for more context.
Here, a Kinect for Windows is pointed at the user. An
on-screen animation demonstrates a target gesture for the
user. Along the top of the screen, the application gives
an English description of the gesture. Also on screen is
an outline that tracks the user’s actual position, enabling
the user to compare against the model. Along the top,
the program also gives feedback in English about what
movements the user must make to properly perform the
therapy gesture.
Reﬂexion is an example of a broader class of trainer
applications that continually monitor a user and give
feedback on the user’s progress toward gestures. The key
point is that trainer applications all need to continuously
monitor the user’s position to judge how well the user
performs a gesture. This monitoring is explicit in Reﬂexion
Health, but in other settings, such as Atlas5D’s eldercare,
the monitoring may be implicit and multiple gestures may
be tracked at once.
Encoding existing poses: We now drill down into an
example to show how applications can encode gesture
recognizers using the Prepose approach. Figure 8b shows
a common ballet pose, taken from an instructional book on
ballet. The illustration is accompanied by text describing
the pose. The text states in words that ankles should be
crossed, that arms should be bent at a certain angle, and
so on.
126126
Authorized licensed use limited to: IEEE Xplore. Downloaded on March 18,2021 at 12:14:45 UTC from IEEE Xplore.  Restrictions apply. 
Fig. 7: Workﬂow for machine-learning based gesture recognition creation in the Kinect Visual Gesture Builder [16].
Gestures in Prepose: Figure 8 shows the Prepose code
which captures the ballet pose. Because of the way we
have designed the Prepose language, this code is close to
the English description of the ballet pose. A ballet trainer
application would include this code, which is then sent to
the Prepose runtime for interpretation.
3.2 Architectural Goals
Figure 4 shows the architecture of Prepose. Multiple
applications run concurrently. Each application has one
or more gestures written in the Prepose language. These
applications are not trusted and do not have access to
raw sensor data. Instead, applications register their gesture
code with a trusted Prepose runtime. This runtime is
responsible for interpreting the gestures given access to
raw depth, video, or other data about the user’s position.
When a gesture is recognized, the runtime calls back to
the application which registered the gesture.
We draw a security boundary between the trusted
component and untrusted applications. Only Prepose
code crosses this boundary from untrusted applications to
trusted components. In our implementation, the trusted
component is written in managed C#, which makes it
diﬃcult for an untrusted application to cause a memory
safety error. Our design therefore provides assurance that
untrusted applications will not be able to access private
sensor data directly, while still being able to deﬁne new
gesture recognizers.
Prepose has been designed for analyzability. Develop-
ers submit code written in the Prepose language to a
gesture App Store. During submission, we can aﬀord to
spend signiﬁcant time (say, an hour or two) on performing
static analyses. We now describe the speciﬁc security and
privacy properties we support, along with the analyses
needed to check them.
3.3 Basic Concepts in Prepose
In contrast to the approaches above, Prepose deﬁnes a
domain speciﬁc language for writing gesture recognizers.
The basic unit of the Prepose language is the pose. A
pose may contain transformations that specify the target
position of the user explicitly, or it may contain restric-
tions that specify a range of allowed positions. A pose
composes these transformations and restrictions to specify
a function that takes a body position and decides if the
position matches the pose. At runtime, Prepose applies
this function to determine if the user’s current body
position matches the pose. For poses that consist solely of
transformations, Prepose also at runtime synthesizes a
target position for the user, enabling Prepose to measure
how close the user is to matching the pose and provide
real time feedback to the user on how to match the pose.
A gesture speciﬁes a sequence of poses. The user must
match each pose in the sequence provided. The gesture is
said to match when the last pose in the sequence matches.
At runtime, Prepose checks the user’s body position to
see if it matches the current pose.
In our current implementation, Prepose poses and
gestures are written in terms of the Kinect skeleton. The
Kinect skeleton is a collection of body joints, which are
distinguished points in a three-dimensional coordinate
space that correspond to the physical location of the user’s
head,
left and right arms, and other body parts. Our
approach, however, could be generalized to other methods
127127