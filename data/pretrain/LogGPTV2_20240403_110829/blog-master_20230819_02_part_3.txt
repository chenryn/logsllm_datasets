  select # hll_union_agg(users) as users from tbl_hll where rid=v_rid and ds >= v_begin_cts1 and ds = v_begin_cts1 and ds = v_begin_cts2 and ds = v_begin_cts1 and ds = v_begin_cts1 and ds = v_begin_cts2 and ds < v_end_cts2)  
select (# (t1.users || t2.users)) - (# t1.users) from t1,t2;  
$$ language sql strict;  
select * from get_uv_incr_appro ('2023-01-01', '2023-01-08', '2023-01-08', '2023-01-15');  
```  
耗时: 31.634 ms  
#### 性能对比结果  
test case | 原始方法耗时(ms) | HLL耗时(ms) | HLL性能提升倍数  
---|---|---|---  
1 | 5263.209 | 57.250 | 91.93  
2 | 超过 249922.704  | 179.204 | 超过 1394.63  
3 | 4824.847  | 50.841 | 94.90  
4 | 41003.313  | 51.931 | 789.57  
5 | 18654.469 | 99.657 | 187.19  
6 | 超过 294874.983 | 121.010 | 超过 2436.78  
7 | 10757.619  | 52.649 | 204.33  
8 | 38512.642 | 51.668 | 745.39  
9 | 560.176 | 6.021 | 93.04  
10 | 889.635 | 8.934 | 99.58  
11 | 915.000 | 18.035 | 50.73  
12 | 2147.770 | 31.634 | 67.89  
## 业务场景介绍2: 短视频去重、过滤已观看视频  
例如有一个短视频业务, 用户看过的视频都会被标记.  当根据用户喜好推送给用户视频, 需要从推荐列表中过滤掉用户已经看过的视频. (允许近似值, 要求高性能)   
### 实现和对比  
设计表结构:    
```  
drop table if exists tbl;   
create unlogged table tbl (  -- 用户已读视频列表, 为了减轻测试负担, 使用unlogged table    
  id serial8 primary key,  -- 主键    
  uid int8,  -- 用户ID    
  vid int8,  -- 已读视频ID    
  cts timestamp  -- 用户行为时间    
);      
alter sequence tbl_id_seq cache 1000;     
create index on tbl (uid) include (vid);  -- 加速根据uid查询已读视频   
```  
设计测试数据, 要求:    
- vid 取值范围1到1万. 高斯分布, 突出一些经常被观看的热门视频.   
- uid 取值范围1到1万. 高斯分布, 突出一些经常看视频的活跃用户.  
使用pgbench生成1000万条用户已读视频列表的记录.  
```    
vi ~/t.sql     
\set uid random_gaussian(1, 10000, 2.5)     
\set vid random_gaussian(1, 10000, 2.5)     
insert into tbl (uid,vid,cts) values (:uid, :vid, clock_timestamp());     
```   
```    
pgbench -M prepared -n -r -P 1 -f ~/t.sql -c 10 -j 10 -t 1000000      
```    
```  
scaling factor: 1  
query mode: prepared  
number of clients: 10  
number of threads: 10  
number of transactions per client: 1000000  
number of transactions actually processed: 10000000/10000000  
latency average = 0.058 ms  
latency stddev = 0.079 ms  
initial connection time = 20.551 ms  
tps = 171765.018858 (without initial connection time)  
statement latencies in milliseconds:  
         0.000  \set uid random_gaussian(1, 100000, 2.5)     
         0.000  \set vid random_gaussian(1, 100000, 2.5)     
         0.058  insert into tbl (uid,vid,cts) values (:uid, :vid, clock_timestamp());  
```  
结果查看    
```  
postgres=# select * from tbl limit 10;   
  id  | uid  | vid  |            cts               
------+------+------+----------------------------  
    1 | 5380 | 5321 | 2023-08-21 08:53:53.074514  
    2 | 7611 | 7945 | 2023-08-21 08:53:53.074845  
 1001 | 6841 | 2507 | 2023-08-21 08:53:53.074857  
 2001 | 7956 | 4567 | 2023-08-21 08:53:53.074925  
 1002 | 5728 | 4210 | 2023-08-21 08:53:53.075087  
 3001 | 4560 | 1588 | 2023-08-21 08:53:53.075333  
 1003 | 5197 | 5662 | 2023-08-21 08:53:53.07549  
 1004 | 5125 | 3827 | 2023-08-21 08:53:53.075528  
 4001 | 6815 | 4758 | 2023-08-21 08:53:53.075496  
 1005 | 4002 | 8575 | 2023-08-21 08:53:53.075567  
(10 rows)  
postgres=# select count(*) from tbl;    
  count     
----------  
 10000000  
(1 row)  
postgres=# \dt+  
                                   List of relations  
 Schema | Name | Type  |  Owner   | Persistence | Access method |  Size  | Description   
--------+------+-------+----------+-------------+---------------+--------+-------------  
 public | tbl  | table | postgres | unlogged    | heap          | 575 MB |   
(1 row)  
postgres=# \di+  
                                            List of relations  
 Schema |      Name       | Type  |  Owner   | Table | Persistence | Access method |  Size  | Description   
--------+-----------------+-------+----------+-------+-------------+---------------+--------+-------------  
 public | tbl_pkey        | index | postgres | tbl   | unlogged    | btree         | 344 MB |   
 public | tbl_uid_vid_idx | index | postgres | tbl   | unlogged    | btree         | 301 MB |   
(2 rows)  
postgres=# vacuum ANALYZE tbl;    
VACUUM  
```  
#### 传统数据库设计和试验  
test case1:   
从4900-5100号段热门vid随机生成100个推荐视频, 从4900-5100号段随机获取活跃uid, 从用户已读列表中过滤该UID已读的vid, 返回未读的UID.   
编写压测脚本  
```  
vi ~/test.sql  
\set uid random(4900, 5100)    
with t as (  
  select 4900+(random()*200)::int as vid from generate_series(1,100)  
)  
select t.vid from t where not exists   
  (select 1 from tbl where uid=:uid and tbl.vid=t.vid)  
;  
```  
压测  
```  
pgbench -M prepared -n -r -P 1 -f ~/test.sql -c 10 -j 10 -T 120  
scaling factor: 1  
query mode: prepared  
number of clients: 10  
number of threads: 10  
duration: 120 s  
number of transactions actually processed: 2469063  
latency average = 0.486 ms  
latency stddev = 0.183 ms  
initial connection time = 22.914 ms  
tps = 20578.539756 (without initial connection time)  
```  
tps: 20578.539756   
#### hll数据库设计和试验  
创建聚合表, 每个UID存储一条聚合后的hll value.      
```  
drop table if exists tbl_hll;   
create table tbl_hll (  
  uid int8 unique,   
  vids hll   
);  
```  
聚合  
```  
insert into tbl_hll select uid, hll_add_agg(hll_hash_bigint(vid)) from tbl group by 1;    
INSERT 0 10000  
```  
查看聚合表, 只占用了11MB左右.    
```    
postgres=# \dt+  
                                    List of relations  
 Schema |  Name   | Type  |  Owner   | Persistence | Access method |  Size  | Description   
--------+---------+-------+----------+-------------+---------------+--------+-------------  
 public | tbl     | table | postgres | unlogged    | heap          | 575 MB |   
 public | tbl_hll | table | postgres | permanent   | heap          | 11 MB  |   
(2 rows)  
```    
近似情况对比:    
```  
uid=5000实际已读vid数  
postgres=# select count(distinct vid) from tbl where uid=5000;  
 count   
-------  
  1807  
(1 row)  
uid=5000的hll里可能存在的vid数  
postgres=# select # vids from tbl_hll where uid=5000;  
      ?column?        
--------------------  
 1758.0590520300507  
(1 row)  
```  
true, false 测试:   
使用原始表取出uid=5000的vid, 在hll值中判断是否已读, 2081 条全部已读, 判断已读是绝对准确的, 原理参考本文知识点的部分.   
```  
with tmp as (  
  select   
    tbl.uid,   
    tbl.vid,   
    ( vids || hll_hash_bigint(vid) ) = vids as is_readed   -- 是否已读  
  from tbl_hll join tbl  
  on (tbl_hll.uid=tbl.uid)  
  where   
  tbl.uid=5000  
  and tbl_hll.uid=5000  
)  
select is_readed, count(*) from tmp group by 1;  
 is_readed | count   
-----------+-------  
 t         |  2081  