cannot access the kernel memory, so an exception is generated by the processor. The exception is 
caught by the application. Otherwise, it would result in the termination of the process. However, due to 
the out-of-order execution, the CPU has already executed (but not retired, meaning that no architec-
tural effects are observable in any CPU registers or RAM) the instructions following the illegal memory 
The malicious application then probes the entire cache by measuring the time needed to access each 
which is taken from the original Meltdown research paper (available at the https://meltdownattack.com/ 
Access time
(cycles)
500
400
300
200
0
50
100
150
200
250
Page
FIGURE 8-6 CPU time employed for accessing a 1 MB probe array.
data can be read one byte per time and one byte can have only 256 values, knowing the exact page in 
the array that led to a cache hit allows the attacker to know which byte is stored in the kernel memory.
Spectre
explained in the previous section, but the main CPU components exploited by Spectre are the branch 
predictor and branch target predictor. Two variants of the Spectre attack were initially presented. 
Both are summarized by three phases:
CHAPTER 8 System mechanisms
15
1.
In the setup phase, from a low-privileged process (which is attacker-controlled), the attacker
performs multiple repetitive operations that mistrain the CPU branch predictor. The goal is to
indirect branch.
2.
In the second phase, the attacker forces a victim high-privileged application (or the same pro-
cess) to speculatively execute instructions that are part of a mispredicted branch. Those instruc-
channel (usually the CPU cache).
3.
-
tion stored in the CPU cache (microarchitectural channel) by probing the entire cache (the same
methods employed in the Meltdown attack). This reveals secrets that should be secured in the
victim high-privileged address space.
(which can be the same or different than the address space that the attacker controls), by forcing the CPU 
branch predictor to execute the wrong branch of a conditional branch speculatively. The branch is usu-
ally part of a function that performs a bound check before accessing some nonsecret data contained 
in a memory buffer. If the buffer is located adjacent to some secret data, and if the attacker controls 
the offset supplied to the branch condition, she can repetitively train the branch predictor supplying 
that implements the bound check branch. The CPU branch predictor is trained to always follow the 
initial legit path. However, this time, the path would be wrong (the other should be taken). The instruc-
tions accessing the memory buffer are thus speculatively executed and result in a read outside the 
boundaries, which targets the secret data. The attacker can thus read back the secrets by probing the 
entire cache (similar to the Meltdown attack).
The second variant of Spectre exploits the CPU branch target predictor; indirect branches can be 
poisoned by an attacker. The mispredicted path of an indirect branch can be used to read arbitrary 
memory of a victim process (or the OS kernel) from an attacker-controlled context. As shown in 
-
ing the CPU to build enough information in the BTB to speculatively execute instructions located at 
an address chosen by the attacker. In the victim address space, that address should point to a gad-
get. A gadget is a group of instructions that access a secret and store it in a buffer that is cached in a 
controlled way (the attacker needs to indirectly control the content of one or more CPU registers in the 
victim, which is a common case when an API accepts untrusted input data).
a service provided by the target higher-privileged entity (a process or the OS kernel). The code that 
implements the service must implement similar indirect branches as the attacker-controlled process. 
The CPU branch target predictor in this case speculatively executes the gadget located at the wrong 
target address. This, as for Variant 1 and Meltdown, creates microarchitectural side effects in the CPU 
cache, which can be read from the low-privileged context.
16 
CHAPTER 8 System mechanisms
kernelbase.dll
Attacker process
(low privileged)
CPU Branch
Predictor
0x105F0 + ∆
0x110BC + ∆
0x2147A + ∆
_imp_NtSetEvent:
dl @ntdll!gadget
SetEvent:
call [_imp_NtSetEvent]
ntdll.dll
0x24026 + ∆
gadget:
ret
NtSetEvent:
mov
eax,0Eh
sysenter
CALL
kernelbase.dll
Victim process
(high privileged)
0x105F0 + Ω
0x110BC + Ω
0x2147A + Ω
_imp_NtSetEvent:
dl @ntdll!NtSetEvent
SetEvent:
call [_imp_NtSetEvent]
ntdll.dll
0x24026 + Ω
gadget:
mov eax, array$[esp-4]
mov d1, [eax+ecx*4]
   mov eax, _array2$[esp-4] 
NtSetEvent:
mov
eax,0Eh
sysenter
Speculate
CPU
FIGURE 8-7 A scheme of Spectre attack Variant 2.
Other side-channel attacks
After Spectre and Meltdown attacks were originally publicly released, multiple similar side-channel 
hardware attacks were discovered. Even though they were less destructive and effective compared to 
Meltdown and Spectre, it is important to at least understand the overall methodology of those new 
side-channel attacks.
Speculative store bypass (SSB) arises due to a CPU optimization that can allow a load instruction, 
which the CPU evaluated not to be dependent on a previous store, to be speculatively executed before 
the results of the store are retired. If the prediction is not correct, this can result in the load operation 
reading stale data, which can potentially store secrets. The data can be forwarded to other operations 
executed during speculation. Those operations can access memory and generate microarchitectural 
side effects (usually in the CPU cache). An attacker can thus measure the side effects and recover the 
secret value.
The Foreshadow (also known as L1TF) is a more severe attack that was originally designed for 
stealing secrets from a hardware enclave (SGX) and then generalized also for normal user-mode 
speculative execution engine of modern CPUs. In particular:
I 
Speculation on inaccessible virtual memory. In this scenario, when the CPU accesses some data
stored at a virtual address described by a Page table entry (PTE) that does not include the pres-
ent bit (meaning that the address is is not valid) an exception is correctly generated. However,
if the entry contains a valid address translation, the CPU can speculatively execute the instruc-
tions that depend on the read data. As for all the other side-channel attacks, those instructions
are not retired by the processor, but they produce measurable side effects. In this scenario, a
user-mode application would be able to read secret data stored in kernel memory. More seri-
ously, the application, under certain circumstances, would also be able to read data belonging
CHAPTER 8 System mechanisms
17
to another virtual machine: when the CPU encounters a nonpresent entry in the Second Level 
Address Translation table (SLAT) while translating a guest physical address (GPA), the same side 
effects can happen. (More information on the SLAT, GPAs, and translation mechanisms are pres-
ent in Chapter 5 of Part 1 and in Chapter 9, “Virtualization technologies”).
I 
more than one execution pipeline per physical core, which can execute in an out-of-order way
multiple instruction streams using a single shared execution engine (this is Symmetric multi-
threading, or SMT, as explained later in Chapter 9.) In those processors, two logical processors
(LPs) share a single cache. Thus, while an LP is executing some code in a high-privileged context,
the other sibling LP can read the side effects produced by the high-privileged code executed
by the other LP. This has very severe effects on the global security posture of a system. Similar to
even spoil secrets stored in another high-security virtual-machine just by waiting for the virtual
is part of the Group 4 vulnerabilities.
Microarchitectural side effects are not always targeting the CPU cache. Intel CPUs use other 
intermediate high-speed buffers with the goal to better access cached and noncached memory 
and reorder micro-instructions. (Describing all those buffers is outside the scope of this book.) The 
Microarchitectural Data Sampling (MDS) group of attacks exposes secrets data located in the following 
microarchitectural structures:
I 
Store buffers While performing store operations, processors write data into an internal tem-
porary microarchitectural structure called store buffer, enabling the CPU to continue to execute
instructions before the data is actually written in the cache or main memory (for noncached
memory access). When a load operation reads data from the same memory address as an ear-
lier store, the processor may be able to forward data directly from the store buffer.
I 
Fill buffers 
-
mediary between the CPU cache and the CPU out-of-order execution engine. They may retain
data from prior memory requests, which may be speculatively forwarded to a load operation.
I 
Load ports Load ports are temporary internal CPU structures used to perform load opera-
tions from memory or I/O ports.
Microarchitectural buffers usually belong to a single CPU core and are shared between SMT threads. 
This implies that, even if attacks on those structures are hard to achieve in a reliable way, the specula-
tive extraction of secret data stored into them is also potentially possible across SMT threads (under 
In general, the outcome of all the hardware side-channel vulnerabilities is the same: secrets will be 
spoiled from the victim address space. Windows implements various mitigations for protecting against 
Spectre, Meltdown, and almost all the described side-channel attacks.
18 
CHAPTER 8 System mechanisms
Side-channel mitigations in Windows
This section takes a peek at how Windows implements various mitigations for defending against side-
channel attacks. In general, some side-channel mitigations are implemented by CPU manufacturers 
through microcode updates. Not all of them are always available, though; some mitigations need to 
be enabled by the software (Windows kernel).
KVA Shadow
-
tween the kernel and user page tables. Speculative execution allows the CPU to spoil kernel data when 
the processor is not at the correct privilege level to access it, but it requires that a valid page frame 
number be present in the page table translating the target kernel page. The kernel memory targeted 
by the Meltdown attack is generally translated by a valid leaf entry in the system page table, which 
indicates only supervisor privilege level is allowed. (Page tables and virtual address translation are cov-
page tables for each process:
I 
The kernel page tables map the entire process address space, including kernel and user pages.
In Windows, user pages are mapped as nonexecutable to prevent kernel code to execute mem-
ory allocated in user mode (an effect similar to the one brought by the hardware SMEP feature).
I 
The User page tables (also called shadow page tables) map only user pages and a minimal set
of kernel pages, which do not contain any sort of secrets and are used to provide a minimal
functionality for switching page tables, kernel stacks, and to handle interrupts, system calls, and
other transitions and traps. This set of kernel pages is called transition address space.
In the transition address space, the NT kernel usually maps a data structure included in the proces-
shadow
Administrator-level privileges) in processes that do not have mapped any kernel page that may contain 
secrets. The Meltdown attack is not effective anymore; kernel pages are not mapped as valid in the 
happen. When the user process invokes a system call, or when an interrupt happens while the CPU is 
executing code in the user-mode process, the CPU builds a trap frame on a transition stack, which, as 
of the shadow trap handler that handles the interrupt or system call. The latter normally switches to 
the kernel page tables, copies the trap frame on the kernel stack, and then jumps to the original trap 
executed with the entire address space mapped.
CHAPTER 8 System mechanisms
19
Initialization
The NT kernel determines whether the CPU is susceptible to Meltdown attack early in phase -1 of its 
initialization, after the processor feature bits are calculated, using the internal KiDetectKvaLeakage 
KiKvaLeakage variable to 1 for 
all Intel processors except Atoms (which are in-order processors).
In case the internal KiKvaLeakage
KiEnableKvaShadowing
stacks. Transition stacks (which are 512 bytes in size) are prepared by writing a small data structure, 
linked against its nontransition kernel stack (accessible only after the page tables have been switched), 
thread has a proper kernel stack. The scheduler set a kernel stack as active by linking it in the processor 
PRCB when a new thread is selected to be executed. This is a key difference compared to the IST stacks, 
which exist as one per processor.
Transition Space
0
+ 0x200
+ 0x5FE0
+ 0x6000
+ 0x6000
+ 0x5FE0
+ 0x6000
0
0
0
BASE/TOP
BASE
TOP
BASE
TOP
BASE
TOP
+ 0x200
+ 0x200
Processor’s TSS
Kernel Space
+
Memory
IST
Transition
Stack
KTHREAD
KIST_BASE_FRAME
KIST_LINK_FRAME
IST Stack
IST
Transition
Stack
KIST_BASE_FRAME
RSP 0
…
IST 0
…
IST 2
…
IoMapBase
0
+ 0x1D0
0
+ 0x1D0
Transition
Stack
BASE
TOP
BASE/TOP
KIST_LINK_FRAME
IST Stack
Kernel Stack*
FIGURE 8-8 
The KiEnableKvaShadowing
algorithm (explained later in this section). The result of the determination (global entries or PCIDs) is 
stored in the global KiKvaShadowMode
KiShadowProcessorAllocation, which maps the per-processor shared data structures in the shadow page 
shadow page tables are created (and the IRQL is dropped to passive level). The shadow trap handlers are 
Shadow page tables
Shadow (or user) page tables are allocated by the memory manager using the internal MiAllocate 
ProcessShadow
for the new process are initially created empty. The memory manager then copies all the kernel 
shadow top-level page table entries of the SYSTEM process in the new process shadow page table. 
20 
CHAPTER 8 System mechanisms
This allows the OS to quickly map the entire transition address space (which lives in kernel and is 
KiShadowProcessorAllocation routine, which uses memory manager services to map individual chunks 
of memory in the shadow page tables and to rebuild the entire page hierarchy.
can write in the process page tables to map or unmap chunks of memory. When a request to allocate 
or map new memory into a user process address space, it may happen that the top-level page table 
entry for a particular address would be missing. In this case, the memory manager allocates all the 
pages for the entire page-table hierarchy and stores the new top-level PTE in the kernel page tables. 
top-level PTE on the shadow page table. Otherwise, the address will be not present in the user-map-